{"title": "Document Context Neural Machine Translation with Memory Networks", "abstract": "We present a document-level neural machine translation model which takes both\nsource and target document context into account using memory networks. We model\nthe problem as a structured prediction problem with interdependencies among the\nobserved and hidden variables, i.e., the source sentences and their unobserved\ntarget translations in the document. The resulting structured prediction\nproblem is tackled with a neural translation model equipped with two memory\ncomponents, one each for the source and target side, to capture the documental\ninterdependencies. We train the model end-to-end, and propose an iterative\ndecoding algorithm based on block coordinate descent. Experimental results of\nEnglish translations from French, German, and Estonian documents show that our\nmodel is effective in exploiting both source and target document context, and\nstatistically significantly outperforms the previous work in terms of BLEU and\nMETEOR.", "published": "2017-11-10 04:35:14", "link": "http://arxiv.org/abs/1711.03688v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integrating User and Agent Models: A Deep Task-Oriented Dialogue System", "abstract": "Task-oriented dialogue systems can efficiently serve a large number of\ncustomers and relieve people from tedious works. However, existing\ntask-oriented dialogue systems depend on handcrafted actions and states or\nextra semantic labels, which sometimes degrades user experience despite the\nintensive human intervention. Moreover, current user simulators have limited\nexpressive ability so that deep reinforcement Seq2Seq models have to rely on\nselfplay and only work in some special cases. To address those problems, we\npropose a uSer and Agent Model IntegrAtion (SAMIA) framework inspired by an\nobservation that the roles of the user and agent models are asymmetric.\nFirstly, this SAMIA framework model the user model as a Seq2Seq learning\nproblem instead of ranking or designing rules. Then the built user model is\nused as a leverage to train the agent model by deep reinforcement learning. In\nthe test phase, the output of the agent model is filtered by the user model to\nenhance the stability and robustness. Experiments on a real-world coffee\nordering dataset verify the effectiveness of the proposed SAMIA framework.", "published": "2017-11-10 05:27:44", "link": "http://arxiv.org/abs/1711.03697v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Skill Transfer from Supervised Language Tasks to Reading\n  Comprehension", "abstract": "Reading comprehension is a challenging task in natural language processing\nand requires a set of skills to be solved. While current approaches focus on\nsolving the task as a whole, in this paper, we propose to use a neural network\n`skill' transfer approach. We transfer knowledge from several lower-level\nlanguage tasks (skills) including textual entailment, named entity recognition,\nparaphrase detection and question type classification into the reading\ncomprehension model.\n  We conduct an empirical evaluation and show that transferring language skill\nknowledge leads to significant improvements for the task with much fewer steps\ncompared to the baseline model. We also show that the skill transfer approach\nis effective even with small amounts of training data. Another finding of this\nwork is that using token-wise deep label supervision for text classification\nimproves the performance of transfer learning.", "published": "2017-11-10 10:13:51", "link": "http://arxiv.org/abs/1711.03754v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "YEDDA: A Lightweight Collaborative Text Span Annotation Tool", "abstract": "In this paper, we introduce \\textsc{Yedda}, a lightweight but efficient and\ncomprehensive open-source tool for text span annotation. \\textsc{Yedda}\nprovides a systematic solution for text span annotation, ranging from\ncollaborative user annotation to administrator evaluation and analysis. It\novercomes the low efficiency of traditional text annotation tools by annotating\nentities through both command line and shortcut keys, which are configurable\nwith custom labels. \\textsc{Yedda} also gives intelligent recommendations by\nlearning the up-to-date annotated text. An administrator client is developed to\nevaluate annotation quality of multiple annotators and generate detailed\ncomparison report for each annotator pair. Experiments show that the proposed\nsystem can reduce the annotation time by half compared with existing annotation\ntools. And the annotation time can be further compressed by 16.47\\% through\nintelligent recommendation.", "published": "2017-11-10 10:18:02", "link": "http://arxiv.org/abs/1711.03759v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards the Use of Deep Reinforcement Learning with Global Policy For\n  Query-based Extractive Summarisation", "abstract": "Supervised approaches for text summarisation suffer from the problem of\nmismatch between the target labels/scores of individual sentences and the\nevaluation score of the final summary. Reinforcement learning can solve this\nproblem by providing a learning mechanism that uses the score of the final\nsummary as a guide to determine the decisions made at the time of selection of\neach sentence. In this paper we present a proof-of-concept approach that\napplies a policy-gradient algorithm to learn a stochastic policy using an\nundiscounted reward. The method has been applied to a policy consisting of a\nsimple neural network and simple features. The resulting deep reinforcement\nlearning system is able to learn a global policy and obtain encouraging\nresults.", "published": "2017-11-10 15:14:49", "link": "http://arxiv.org/abs/1711.03859v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improved Twitter Sentiment Analysis Using Naive Bayes and Custom\n  Language Model", "abstract": "In the last couple decades, social network services like Twitter have\ngenerated large volumes of data about users and their interests, providing\nmeaningful business intelligence so organizations can better understand and\nengage their customers. All businesses want to know who is promoting their\nproducts, who is complaining about them, and how are these opinions bringing or\ndiminishing value to a company. Companies want to be able to identify their\nhigh-value customers and quantify the value each user brings. Many businesses\nuse social media metrics to calculate the user contribution score, which\nenables them to quantify the value that influential users bring on social\nmedia, so the businesses can offer them more differentiated services. However,\nthe score calculation can be refined to provide a better illustration of a\nuser's contribution. Using Microsoft Azure as a case study, we conducted\nTwitter sentiment analysis to develop a machine learning classification model\nthat identifies tweet contents and sentiments most illustrative of\npositive-value user contribution. Using data mining and AI-powered cognitive\ntools, we analyzed factors of social influence and specifically, promotional\nlanguage in the developer community. Our predictive model was a combination of\na traditional supervised machine learning algorithm and a custom-developed\nnatural language model for identifying promotional tweets, that identifies a\nproduct-specific promotion on Twitter with a 90% accuracy rate.", "published": "2017-11-10 20:04:23", "link": "http://arxiv.org/abs/1711.11081v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Breaking the Softmax Bottleneck: A High-Rank RNN Language Model", "abstract": "We formulate language modeling as a matrix factorization problem, and show\nthat the expressiveness of Softmax-based models (including the majority of\nneural language models) is limited by a Softmax bottleneck. Given that natural\nlanguage is highly context-dependent, this further implies that in practice\nSoftmax with distributed word embeddings does not have enough capacity to model\nnatural language. We propose a simple and effective method to address this\nissue, and improve the state-of-the-art perplexities on Penn Treebank and\nWikiText-2 to 47.69 and 40.68 respectively. The proposed method also excels on\nthe large-scale 1B Word dataset, outperforming the baseline by over 5.6 points\nin perplexity.", "published": "2017-11-10 18:29:00", "link": "http://arxiv.org/abs/1711.03953v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Depression Severity Estimation from Multiple Modalities", "abstract": "Depression is a major debilitating disorder which can affect people from all\nages. With a continuous increase in the number of annual cases of depression,\nthere is a need to develop automatic techniques for the detection of the\npresence and extent of depression. In this AVEC challenge we explore different\nmodalities (speech, language and visual features extracted from face) to design\nand develop automatic methods for the detection of depression. In psychology\nliterature, the PHQ-8 questionnaire is well established as a tool for measuring\nthe severity of depression. In this paper we aim to automatically predict the\nPHQ-8 scores from features extracted from the different modalities. We show\nthat visual features extracted from facial landmarks obtain the best\nperformance in terms of estimating the PHQ-8 results with a mean absolute error\n(MAE) of 4.66 on the development set. Behavioral characteristics from speech\nprovide an MAE of 4.73. Language features yield a slightly higher MAE of 5.17.\nWhen switching to the test set, our Turn Features derived from audio\ntranscriptions achieve the best performance, scoring an MAE of 4.11\n(corresponding to an RMSE of 4.94), which makes our system the winner of the\nAVEC 2017 depression sub-challenge.", "published": "2017-11-10 12:47:52", "link": "http://arxiv.org/abs/1711.06095v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Reinforcement Learning of Speech Recognition System Based on Policy\n  Gradient and Hypothesis Selection", "abstract": "Speech recognition systems have achieved high recognition performance for\nseveral tasks. However, the performance of such systems is dependent on the\ntremendously costly development work of preparing vast amounts of task-matched\ntranscribed speech data for supervised training. The key problem here is the\ncost of transcribing speech data. The cost is repeatedly required to support\nnew languages and new tasks. Assuming broad network services for transcribing\nspeech data for many users, a system would become more self-sufficient and more\nuseful if it possessed the ability to learn from very light feedback from the\nusers without annoying them. In this paper, we propose a general reinforcement\nlearning framework for speech recognition systems based on the policy gradient\nmethod. As a particular instance of the framework, we also propose a hypothesis\nselection-based reinforcement learning method. The proposed framework provides\na new view for several existing training and adaptation methods. The\nexperimental results show that the proposed method improves the recognition\nperformance compared to unsupervised adaptation.", "published": "2017-11-10 04:42:44", "link": "http://arxiv.org/abs/1711.03689v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Joint Sentiment/Topic Modeling on Text Data Using Boosted Restricted\n  Boltzmann Machine", "abstract": "Recently by the development of the Internet and the Web, different types of\nsocial media such as web blogs become an immense source of text data. Through\nthe processing of these data, it is possible to discover practical information\nabout different topics, individuals opinions and a thorough understanding of\nthe society. Therefore, applying models which can automatically extract the\nsubjective information from the documents would be efficient and helpful. Topic\nmodeling methods, also sentiment analysis are the most raised topics in the\nnatural language processing and text mining fields. In this paper a new\nstructure for joint sentiment-topic modeling based on Restricted Boltzmann\nMachine (RBM) which is a type of neural networks is proposed. By modifying the\nstructure of RBM as well as appending a layer which is analogous to sentiment\nof text data to it, we propose a generative structure for joint sentiment topic\nmodeling based on neutral networks. The proposed method is supervised and\ntrained by the Contrastive Divergence algorithm. The new attached layer in the\nproposed model is a layer with the multinomial probability distribution which\ncan be used in text data sentiment classification or any other supervised\napplication. The proposed model is compared with existing models in the\nexperiments such as evaluating as a generative model, sentiment classification,\ninformation retrieval and the corresponding results demonstrate the efficiency\nof the method.", "published": "2017-11-10 09:17:02", "link": "http://arxiv.org/abs/1711.03736v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Object Referring in Visual Scene with Spoken Language", "abstract": "Object referring has important applications, especially for human-machine\ninteraction. While having received great attention, the task is mainly attacked\nwith written language (text) as input rather than spoken language (speech),\nwhich is more natural. This paper investigates Object Referring with Spoken\nLanguage (ORSpoken) by presenting two datasets and one novel approach. Objects\nare annotated with their locations in images, text descriptions and speech\ndescriptions. This makes the datasets ideal for multi-modality learning. The\napproach is developed by carefully taking down ORSpoken problem into three\nsub-problems and introducing task-specific vision-language interactions at the\ncorresponding levels. Experiments show that our method outperforms competing\nmethods consistently and significantly. The approach is also evaluated in the\npresence of audio noise, showing the efficacy of the proposed vision-language\ninteraction methods in counteracting background noise.", "published": "2017-11-10 13:04:55", "link": "http://arxiv.org/abs/1711.03800v2", "categories": ["cs.CV", "cs.CL", "cs.HC"], "primary_category": "cs.CV"}
{"title": "Bayesian Paragraph Vectors", "abstract": "Word2vec (Mikolov et al., 2013) has proven to be successful in natural\nlanguage processing by capturing the semantic relationships between different\nwords. Built on top of single-word embeddings, paragraph vectors (Le and\nMikolov, 2014) find fixed-length representations for pieces of text with\narbitrary lengths, such as documents, paragraphs, and sentences. In this work,\nwe propose a novel interpretation for neural-network-based paragraph vectors by\ndeveloping an unsupervised generative model whose maximum likelihood solution\ncorresponds to traditional paragraph vectors. This probabilistic formulation\nallows us to go beyond point estimates of parameters and to perform Bayesian\nposterior inference. We find that the entropy of paragraph vectors decreases\nwith the length of documents, and that information about posterior uncertainty\nimproves performance in supervised learning tasks such as sentiment analysis\nand paraphrase detection.", "published": "2017-11-10 18:09:15", "link": "http://arxiv.org/abs/1711.03946v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Kernelized Hashcode Representations for Relation Extraction", "abstract": "Kernel methods have produced state-of-the-art results for a number of NLP\ntasks such as relation extraction, but suffer from poor scalability due to the\nhigh cost of computing kernel similarities between natural language structures.\nA recently proposed technique, kernelized locality-sensitive hashing (KLSH),\ncan significantly reduce the computational cost, but is only applicable to\nclassifiers operating on kNN graphs. Here we propose to use random subspaces of\nKLSH codes for efficiently constructing an explicit representation of NLP\nstructures suitable for general classification methods. Further, we propose an\napproach for optimizing the KLSH model for classification problems by\nmaximizing an approximation of mutual information between the KLSH codes\n(feature vectors) and the class labels. We evaluate the proposed approach on\nbiomedical relation extraction datasets, and observe significant and robust\nimprovements in accuracy w.r.t. state-of-the-art classifiers, along with\ndrastic (orders-of-magnitude) speedup compared to conventional kernel methods.", "published": "2017-11-10 23:42:42", "link": "http://arxiv.org/abs/1711.04044v7", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Within-Class Covariance Analysis for Robust Audio Representation\n  Learning", "abstract": "Convolutional Neural Networks (CNNs) can learn effective features, though\nhave been shown to suffer from a performance drop when the distribution of the\ndata changes from training to test data. In this paper we analyze the internal\nrepresentations of CNNs and observe that the representations of unseen data in\neach class, spread more (with higher variance) in the embedding space of the\nCNN compared to representations of the training data. More importantly, this\ndifference is more extreme if the unseen data comes from a shifted\ndistribution. Based on this observation, we objectively evaluate the degree of\nrepresentation's variance in each class via eigenvalue decomposition on the\nwithin-class covariance of the internal representations of CNNs and observe the\nsame behaviour. This can be problematic as larger variances might lead to\nmis-classification if the sample crosses the decision boundary of its class. We\napply nearest neighbor classification on the representations and empirically\nshow that the embeddings with the high variance actually have significantly\nworse KNN classification performances, although this could not be foreseen from\ntheir end-to-end classification results. To tackle this problem, we propose\nDeep Within-Class Covariance Analysis (DWCCA), a deep neural network layer that\nsignificantly reduces the within-class covariance of a DNN's representation,\nimproving performance on unseen test data from a shifted distribution. We\nempirically evaluate DWCCA on two datasets for Acoustic Scene Classification\n(DCASE2016 and DCASE2017). We demonstrate that not only does DWCCA\nsignificantly improve the network's internal representation, it also increases\nthe end-to-end classification accuracy, especially when the test set exhibits a\ndistribution shift. By adding DWCCA to a VGG network, we achieve around 6\npercentage points improvement in the case of a distribution mismatch.", "published": "2017-11-10 21:39:12", "link": "http://arxiv.org/abs/1711.04022v2", "categories": ["cs.LG", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
