{"title": "Are Language Models More Like Libraries or Like Librarians?\n  Bibliotechnism, the Novel Reference Problem, and the Attitudes of LLMs", "abstract": "Are LLMs cultural technologies like photocopiers or printing presses, which\ntransmit information but cannot create new content? A challenge for this idea,\nwhich we call bibliotechnism, is that LLMs generate novel text. We begin with a\ndefense of bibliotechnism, showing how even novel text may inherit its meaning\nfrom original human-generated text. We then argue that bibliotechnism faces an\nindependent challenge from examples in which LLMs generate novel reference,\nusing new names to refer to new entities. Such examples could be explained if\nLLMs were not cultural technologies but had beliefs, desires, and intentions.\nAccording to interpretationism in the philosophy of mind, a system has such\nattitudes if and only if its behavior is well explained by the hypothesis that\nit does. Interpretationists may hold that LLMs have attitudes, and thus have a\nsimple solution to the novel reference problem. We emphasize, however, that\ninterpretationism is compatible with very simple creatures having attitudes and\ndiffers sharply from views that presuppose these attitudes require\nconsciousness, sentience, or intelligence (topics about which we make no\nclaims).", "published": "2024-01-10 00:05:45", "link": "http://arxiv.org/abs/2401.04854v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attendre: Wait To Attend By Retrieval With Evicted Queries in\n  Memory-Based Transformers for Long Context Processing", "abstract": "As LLMs have become capable of processing more complex types of inputs,\nresearchers have recently studied how to efficiently and affordably process\npossibly arbitrarily long sequences. One effective approach is to use a FIFO\nmemory to store keys and values of an attention sublayer from past chunks to\nallow subsequent queries to attend. However, this approach requires a large\nmemory and/or takes into the consideration the specific LM architecture.\nMoreover, due to the causal nature between the key-values in prior context and\nthe queries at present, this approach cannot be extended to bidirectional\nattention such as in an encoder-decoder or PrefixLM decoder-only architecture.\nIn this paper, we propose to use eviction policies, such as LRA and LFA, to\nreduce the memory size and adapt to various architectures, and we also propose\nthe Attendre layer, a wait-to-attend mechanism by retrieving the key-value\nmemory (K/V memory) with evicted queries in the query memory (Q memory). As a\nfirst step, we evaluate this method in the context length extension setup using\nthe TriviaQA reading comprehension task, and show the effectiveness of the\napproach.", "published": "2024-01-10 02:20:48", "link": "http://arxiv.org/abs/2401.04881v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-User Chat Assistant (MUCA): a Framework Using LLMs to Facilitate\n  Group Conversations", "abstract": "Recent advancements in large language models (LLMs) have provided a new\navenue for chatbot development. Most existing research, however, has primarily\ncentered on single-user chatbots that determine \"What\" to answer. This paper\nhighlights the complexity of multi-user chatbots, introducing the 3W design\ndimensions: \"What\" to say, \"When\" to respond, and \"Who\" to answer.\nAdditionally, we proposed Multi-User Chat Assistant (MUCA), an LLM-based\nframework tailored for group discussions. MUCA consists of three main modules:\nSub-topic Generator, Dialog Analyzer, and Conversational Strategies Arbitrator.\nThese modules jointly determine suitable response contents, timings, and\nappropriate addressees. This paper further proposes an LLM-based Multi-User\nSimulator (MUS) to ease MUCA's optimization, enabling faster simulation of\nconversations between the chatbot and simulated users, and speeding up MUCA's\nearly development. In goal-oriented conversations with a small to medium number\nof participants, MUCA demonstrates effectiveness in tasks like chiming in at\nappropriate timings, generating relevant content, and improving user\nengagement, as shown by case studies and user studies.", "published": "2024-01-10 02:22:21", "link": "http://arxiv.org/abs/2401.04883v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can AI Write Classical Chinese Poetry like Humans? An Empirical Study\n  Inspired by Turing Test", "abstract": "Some argue that the essence of humanity, such as creativity and sentiment,\ncan never be mimicked by machines. This paper casts doubt on this belief by\nstudying a vital question: Can AI compose poetry as well as humans? To answer\nthe question, we propose ProFTAP, a novel evaluation framework inspired by\nTuring test to assess AI's poetry writing capability. We apply it on current\nlarge language models (LLMs) and find that recent LLMs do indeed possess the\nability to write classical Chinese poems nearly indistinguishable from those of\nhumans. We also reveal that various open-source LLMs can outperform GPT-4 on\nthis task.", "published": "2024-01-10 06:21:47", "link": "http://arxiv.org/abs/2401.04952v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Whose wife is it anyway? Assessing bias against same-gender\n  relationships in machine translation", "abstract": "Machine translation often suffers from biased data and algorithms that can\nlead to unacceptable errors in system output. While bias in gender norms has\nbeen investigated, less is known about whether MT systems encode bias about\nsocial relationships, e.g., \"the lawyer kissed her wife.\" We investigate the\ndegree of bias against same-gender relationships in MT systems, using generated\ntemplate sentences drawn from several noun-gender languages (e.g., Spanish) and\ncomprised of popular occupation nouns. We find that three popular MT services\nconsistently fail to accurately translate sentences concerning relationships\nbetween entities of the same gender. The error rate varies considerably based\non the context, and same-gender sentences referencing high\nfemale-representation occupations are translated with lower accuracy. We\nprovide this work as a case study in the evaluation of intrinsic bias in NLP\nsystems with respect to social relationships.", "published": "2024-01-10 07:33:32", "link": "http://arxiv.org/abs/2401.04972v2", "categories": ["cs.CL", "I.2.7; K.4.1"], "primary_category": "cs.CL"}
{"title": "Aligning Translation-Specific Understanding to General Understanding in\n  Large Language Models", "abstract": "Large Language models (LLMs) have exhibited remarkable abilities in\nunderstanding complex texts, offering a promising path towards human-like\ntranslation performance. However, this study reveals the misalignment between\nthe translation-specific understanding and the general understanding inside\nLLMs. This understanding misalignment leads to LLMs mistakenly or literally\ntranslating some complicated concepts that they accurately comprehend in the\ngeneral scenarios (e.g., QA). To align the translation-specific understanding\nto the general one, we propose a novel translation process, DUAT (Difficult\nwords Understanding Aligned Translation), explicitly incorporating the general\nunderstanding on the complicated content incurring inconsistent understanding\nto guide the translation. Specifically, DUAT performs cross-lingual\ninterpretation for the difficult-to-translate words and enhances the\ntranslation with the generated interpretations. Furthermore, we reframe the\nexternal tools to improve DUAT in detecting difficult words and generating\nhelpful interpretations. We conduct experiments on the self-constructed\nbenchmark Challenge-WMT, consisting of samples that are prone to\nmistranslation. Human evaluation results on high-resource and low-resource\nlanguage pairs indicate that DUAT significantly facilitates the understanding\nalignment, which improves the translation quality (up to +3.85 COMET) and\nreduces the literality of the translation by -25% to -51%.", "published": "2024-01-10 11:03:53", "link": "http://arxiv.org/abs/2401.05072v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BELHD: Improving Biomedical Entity Linking with Homonoym Disambiguation", "abstract": "Biomedical entity linking (BEL) is the task of grounding entity mentions to a\nknowledge base (KB). A popular approach to the task are name-based methods,\ni.e. those identifying the most appropriate name in the KB for a given mention,\neither via dense retrieval or autoregressive modeling. However, as these\nmethods directly return KB names, they cannot cope with homonyms, i.e.\ndifferent KB entities sharing the exact same name. This significantly affects\ntheir performance, especially for KBs where homonyms account for a large amount\nof entity mentions (e.g. UMLS and NCBI Gene). We therefore present BELHD\n(Biomedical Entity Linking with Homonym Disambiguation), a new name-based\nmethod that copes with this challenge. Specifically, BELHD builds upon the\nBioSyn (Sung et al.,2020) model introducing two crucial extensions. First, it\nperforms a preprocessing of the KB in which it expands homonyms with an\nautomatically chosen disambiguating string, thus enforcing unique linking\ndecisions. Second, we introduce candidate sharing, a novel strategy to select\ncandidates for contrastive learning that enhances the overall training signal.\nExperiments with 10 corpora and five entity types show that BELHD improves upon\nstate-of-the-art approaches, achieving the best results in 6 out 10 corpora\nwith an average improvement of 4.55pp recall@1. Furthermore, the KB\npreprocessing is orthogonal to the core prediction model and thus can also\nimprove other methods, which we exemplify for GenBioEL (Yuan et al, 2022), a\ngenerative name-based BEL approach. Code is available at: link added upon\npublication.", "published": "2024-01-10 12:45:18", "link": "http://arxiv.org/abs/2401.05125v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DCR: Divide-and-Conquer Reasoning for Multi-choice Question Answering\n  with LLMs", "abstract": "Large language models (LLMs) have shown impressive performance in reasoning\nbenchmarks with the emergence of Chain-of-Thought (CoT), particularly in\nmulti-choice question (MCQ). However, current works equally resolve questions\nregardless of the problem-solving difficulty, leading to an excessive focus on\nsimple items while insufficient attention on intricate ones. To address this\nchallenge, we propose a simple yet effective strategy, Divide and Conquer\nReasoning (DCR), to enhance the reasoning capability of LLMs for MCQs, as\ninspired by human beings using heuristics to first categorize tasks and then\nhandle them separately. In particular, we first categorize questions into two\nsubsets based on confidence score ($\\mathcal{CS}$), which is estimated by\nstatistical frequency of generated answers. Subsequently, we propose Filter\nChoices based Reasoning (FCR) to improve model performance on MCQs with low\n($\\mathcal{CS}$). Our experiments demonstrate that the proposed strategy only\ncosts 85% of SOTA, while still achieves average accuracy improvement of 1.56%\nacross nine datasets including arithmetic, commonsense, and logic reasoning\ntasks. The code is at \\url{https://github.com/AiMijie/Divide-and-Conquer}", "published": "2024-01-10 14:38:46", "link": "http://arxiv.org/abs/2401.05190v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CASA: Causality-driven Argument Sufficiency Assessment", "abstract": "The argument sufficiency assessment task aims to determine if the premises of\na given argument support its conclusion. To tackle this task, existing works\noften train a classifier on data annotated by humans. However, annotating data\nis laborious, and annotations are often inconsistent due to subjective\ncriteria. Motivated by the definition of probability of sufficiency (PS) in the\ncausal literature, we proposeCASA, a zero-shot causality-driven argument\nsufficiency assessment framework. PS measures how likely introducing the\npremise event would lead to the conclusion when both the premise and conclusion\nevents are absent. To estimate this probability, we propose to use large\nlanguage models (LLMs) to generate contexts that are inconsistent with the\npremise and conclusion and revise them by injecting the premise event.\nExperiments on two logical fallacy detection datasets demonstrate that CASA\naccurately identifies insufficient arguments. We further deploy CASA in a\nwriting assistance application, and find that suggestions generated by CASA\nenhance the sufficiency of student-written arguments. Code and data are\navailable at https://github.com/xxxiaol/CASA.", "published": "2024-01-10 16:21:18", "link": "http://arxiv.org/abs/2401.05249v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TrustLLM: Trustworthiness in Large Language Models", "abstract": "Large language models (LLMs), exemplified by ChatGPT, have gained\nconsiderable attention for their excellent natural language processing\ncapabilities. Nonetheless, these LLMs present many challenges, particularly in\nthe realm of trustworthiness. Therefore, ensuring the trustworthiness of LLMs\nemerges as an important topic. This paper introduces TrustLLM, a comprehensive\nstudy of trustworthiness in LLMs, including principles for different dimensions\nof trustworthiness, established benchmark, evaluation, and analysis of\ntrustworthiness for mainstream LLMs, and discussion of open challenges and\nfuture directions. Specifically, we first propose a set of principles for\ntrustworthy LLMs that span eight different dimensions. Based on these\nprinciples, we further establish a benchmark across six dimensions including\ntruthfulness, safety, fairness, robustness, privacy, and machine ethics. We\nthen present a study evaluating 16 mainstream LLMs in TrustLLM, consisting of\nover 30 datasets. Our findings firstly show that in general trustworthiness and\nutility (i.e., functional effectiveness) are positively related. Secondly, our\nobservations reveal that proprietary LLMs generally outperform most open-source\ncounterparts in terms of trustworthiness, raising concerns about the potential\nrisks of widely accessible open-source LLMs. However, a few open-source LLMs\ncome very close to proprietary ones. Thirdly, it is important to note that some\nLLMs may be overly calibrated towards exhibiting trustworthiness, to the extent\nthat they compromise their utility by mistakenly treating benign prompts as\nharmful and consequently not responding. Finally, we emphasize the importance\nof ensuring transparency not only in the models themselves but also in the\ntechnologies that underpin trustworthiness. Knowing the specific trustworthy\ntechnologies that have been employed is crucial for analyzing their\neffectiveness.", "published": "2024-01-10 22:07:21", "link": "http://arxiv.org/abs/2401.05561v6", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A General-purpose AI Avatar in Healthcare", "abstract": "Recent advancements in machine learning and natural language processing have\nled to the rapid development of artificial intelligence (AI) as a valuable tool\nin the healthcare industry. Using large language models (LLMs) as\nconversational agents or chatbots has the potential to assist doctors in\ndiagnosing patients, detecting early symptoms of diseases, and providing health\nadvice to patients. This paper focuses on the role of chatbots in healthcare\nand explores the use of avatars to make AI interactions more appealing to\npatients. A framework of a general-purpose AI avatar application is\ndemonstrated by using a three-category prompt dictionary and prompt improvement\nmechanism. A two-phase approach is suggested to fine-tune a general-purpose AI\nlanguage model and create different AI avatars to discuss medical issues with\nusers. Prompt engineering enhances the chatbot's conversational abilities and\npersonality traits, fostering a more human-like interaction with patients.\nUltimately, the injection of personality into the chatbot could potentially\nincrease patient engagement. Future directions for research include\ninvestigating ways to improve chatbots' understanding of context and ensuring\nthe accuracy of their outputs through fine-tuning with specialized medical data\nsets.", "published": "2024-01-10 03:44:15", "link": "http://arxiv.org/abs/2401.12981v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language\n  Models In Chinese Domain", "abstract": "Recently, various Large Language Models (LLMs) evaluation datasets have\nemerged, but most of them have issues with distorted rankings and difficulty in\nmodel capabilities analysis. Addressing these concerns, this paper introduces\nANGO, a Chinese multi-choice question evaluation benchmark. ANGO proposes\nKeypoint categorization standard for the first time, each question in ANGO can\ncorrespond to multiple keypoints, effectively enhancing interpretability of\nevaluation results. Base on performance of real humans, we build a quantifiable\nquestion difficulty standard and divide ANGO questions into 9 difficulty\nlevels, which provide more precise guidance for model training. To minimize\ndata leakage impact and fully leverage ANGO's innovative features, we have\nengineered exclusive sampling strategies and a new evaluation framework that\nsupport swift testset iteration. Our experiments demonstrate that ANGO poses a\nstronger challenge to models and reveals more details in evaluation result\ncompared to existing benchmarks.", "published": "2024-01-10 02:59:49", "link": "http://arxiv.org/abs/2401.04898v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Impact of Reasoning Step Length on Large Language Models", "abstract": "Chain of Thought (CoT) is significant in improving the reasoning abilities of\nlarge language models (LLMs). However, the correlation between the\neffectiveness of CoT and the length of reasoning steps in prompts remains\nlargely unknown. To shed light on this, we have conducted several empirical\nexperiments to explore the relations. Specifically, we design experiments that\nexpand and compress the rationale reasoning steps within CoT demonstrations\nwhile keeping all other factors constant. We have the following key findings.\nFirst, the results indicate that lengthening the reasoning steps in prompts,\neven without adding new information into the prompt, considerably enhances\nLLMs' reasoning abilities across multiple datasets. Alternatively, shortening\nthe reasoning steps, even while preserving the key information, significantly\ndiminishes the reasoning abilities of models. This finding highlights the\nimportance of the number of steps in CoT prompts and provides practical\nguidance to make better use of LLMs' potential in complex problem-solving\nscenarios. Second, we also investigated the relationship between the\nperformance of CoT and the rationales used in demonstrations. Surprisingly, the\nresult shows that even incorrect rationales can yield favorable outcomes if\nthey maintain the requisite length of inference. Third, we observed that the\nadvantages of increasing reasoning steps are task-dependent: simpler tasks\nrequire fewer steps, whereas complex tasks gain significantly from longer\ninference sequences. The code is available at\nhttps://github.com/MingyuJ666/The-Impact-of-Reasoning-Step-Length-on-Large-Language-Models", "published": "2024-01-10 04:37:38", "link": "http://arxiv.org/abs/2401.04925v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk", "abstract": "Large language models (LLMs) are powerful dialogue agents, but specializing\nthem towards fulfilling a specific function can be challenging. Instructing\ntuning, i.e. tuning models on instruction and sample responses generated by\nhumans (Ouyang et al., 2022), has proven as an effective method to do so, yet\nrequires a number of data samples that a) might not be available or b) costly\nto generate. Furthermore, this cost increases when the goal is to make the LLM\nfollow a specific workflow within a dialogue instead of single instructions.\nInspired by the self-play technique in reinforcement learning and the use of\nLLMs to simulate human agents, we propose a more effective method for data\ncollection through LLMs engaging in a conversation in various roles. This\napproach generates a training data via \"self-talk\" of LLMs that can be refined\nand utilized for supervised fine-tuning. We introduce an automated way to\nmeasure the (partial) success of a dialogue. This metric is used to filter the\ngenerated conversational data that is fed back in LLM for training. Based on\nour automated and human evaluations of conversation quality, we demonstrate\nthat such self-talk data improves results. In addition, we examine the various\ncharacteristics that showcase the quality of generated dialogues and how they\ncan be connected to their potential utility as training data.", "published": "2024-01-10 09:49:10", "link": "http://arxiv.org/abs/2401.05033v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generating Diverse and High-Quality Texts by Minimum Bayes Risk Decoding", "abstract": "One of the most important challenges in text generation systems is to produce\noutputs that are not only correct but also diverse. Recently, Minimum\nBayes-Risk (MBR) decoding has gained prominence for generating sentences of the\nhighest quality among the decoding algorithms. However, existing algorithms\nproposed for generating diverse outputs are predominantly based on beam search\nor random sampling, thus their output quality is capped by these underlying\nmethods. In this paper, we investigate an alternative approach -- we develop\ndiversity-promoting decoding algorithms by enforcing diversity objectives to\nMBR decoding. We propose two variants of MBR, Diverse MBR (DMBR) and\n$k$-medoids MBR (KMBR), methods to generate a set of sentences with high\nquality and diversity. We evaluate DMBR and KMBR on a variety of directed text\ngeneration tasks using encoder-decoder models and a large language model with\nprompting. The experimental results show that the proposed method achieves a\nbetter trade-off than the diverse beam search and sampling algorithms.", "published": "2024-01-10 10:23:41", "link": "http://arxiv.org/abs/2401.05054v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hierarchical Classification of Transversal Skills in Job Ads Based on\n  Sentence Embeddings", "abstract": "This paper proposes a classification framework aimed at identifying\ncorrelations between job ad requirements and transversal skill sets, with a\nfocus on predicting the necessary skills for individual job descriptions using\na deep learning model. The approach involves data collection, preprocessing,\nand labeling using ESCO (European Skills, Competences, and Occupations)\ntaxonomy. Hierarchical classification and multi-label strategies are used for\nskill identification, while augmentation techniques address data imbalance,\nenhancing model robustness. A comparison between results obtained with\nEnglish-specific and multi-language sentence embedding models reveals close\naccuracy. The experimental case studies detail neural network configurations,\nhyperparameters, and cross-validation results, highlighting the efficacy of the\nhierarchical approach and the suitability of the multi-language model for the\ndiverse European job market. Thus, a new approach is proposed for the\nhierarchical classification of transversal skills from job ads.", "published": "2024-01-10 11:07:32", "link": "http://arxiv.org/abs/2401.05073v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Yes, this is what I was looking for! Towards Multi-modal Medical\n  Consultation Concern Summary Generation", "abstract": "Over the past few years, the use of the Internet for healthcare-related tasks\nhas grown by leaps and bounds, posing a challenge in effectively managing and\nprocessing information to ensure its efficient utilization. During moments of\nemotional turmoil and psychological challenges, we frequently turn to the\ninternet as our initial source of support, choosing this over discussing our\nfeelings with others due to the associated social stigma. In this paper, we\npropose a new task of multi-modal medical concern summary (MMCS) generation,\nwhich provides a short and precise summary of patients' major concerns brought\nup during the consultation. Nonverbal cues, such as patients' gestures and\nfacial expressions, aid in accurately identifying patients' concerns. Doctors\nalso consider patients' personal information, such as age and gender, in order\nto describe the medical condition appropriately. Motivated by the potential\nefficacy of patients' personal context and visual gestures, we propose a\ntransformer-based multi-task, multi-modal intent-recognition, and medical\nconcern summary generation (IR-MMCSG) system. Furthermore, we propose a\nmultitasking framework for intent recognition and medical concern summary\ngeneration for doctor-patient consultations. We construct the first multi-modal\nmedical concern summary generation (MM-MediConSummation) corpus, which includes\npatient-doctor consultations annotated with medical concern summaries, intents,\npatient personal information, doctor's recommendations, and keywords. Our\nexperiments and analysis demonstrate (a) the significant role of patients'\nexpressions/gestures and their personal information in intent identification\nand medical concern summary generation, and (b) the strong correlation between\nintent recognition and patients' medical concern summary generation\n  The dataset and source code are available at https://github.com/NLP-RL/MMCSG.", "published": "2024-01-10 12:56:47", "link": "http://arxiv.org/abs/2401.05134v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Convergences and Divergences between Automatic Assessment and Human\n  Evaluation: Insights from Comparing ChatGPT-Generated Translation and Neural\n  Machine Translation", "abstract": "Large language models have demonstrated parallel and even superior\ntranslation performance compared to neural machine translation (NMT) systems.\nHowever, existing comparative studies between them mainly rely on automated\nmetrics, raising questions into the feasibility of these metrics and their\nalignment with human judgment. The present study investigates the convergences\nand divergences between automated metrics and human evaluation in assessing the\nquality of machine translation from ChatGPT and three NMT systems. To perform\nautomatic assessment, four automated metrics are employed, while human\nevaluation incorporates the DQF-MQM error typology and six rubrics. Notably,\nautomatic assessment and human evaluation converge in measuring formal fidelity\n(e.g., error rates), but diverge when evaluating semantic and pragmatic\nfidelity, with automated metrics failing to capture the improvement of\nChatGPT's translation brought by prompt engineering. These results underscore\nthe indispensable role of human judgment in evaluating the performance of\nadvanced translation tools at the current stage.", "published": "2024-01-10 14:20:33", "link": "http://arxiv.org/abs/2401.05176v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Monte Carlo Tree Search for Recipe Generation using GPT-2", "abstract": "Automatic food recipe generation methods provide a creative tool for chefs to\nexplore and to create new, and interesting culinary delights. Given the recent\nsuccess of large language models (LLMs), they have the potential to create new\nrecipes that can meet individual preferences, dietary constraints, and adapt to\nwhat is in your refrigerator. Existing research on using LLMs to generate\nrecipes has shown that LLMs can be finetuned to generate realistic-sounding\nrecipes. However, on close examination, these generated recipes often fail to\nmeet basic requirements like including chicken as an ingredient in chicken\ndishes. In this paper, we propose RecipeMC, a text generation method using\nGPT-2 that relies on Monte Carlo Tree Search (MCTS). RecipeMC allows us to\ndefine reward functions to put soft constraints on text generation and thus\nimprove the credibility of the generated recipes. Our results show that human\nevaluators prefer recipes generated with RecipeMC more often than recipes\ngenerated with other baseline methods when compared with real recipes.", "published": "2024-01-10 14:50:46", "link": "http://arxiv.org/abs/2401.05199v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Novel Prompt-tuning Method: Incorporating Scenario-specific Concepts\n  into a Verbalizer", "abstract": "The verbalizer, which serves to map label words to class labels, is an\nessential component of prompt-tuning. In this paper, we present a novel\napproach to constructing verbalizers. While existing methods for verbalizer\nconstruction mainly rely on augmenting and refining sets of synonyms or related\nwords based on class names, this paradigm suffers from a narrow perspective and\nlack of abstraction, resulting in limited coverage and high bias in the\nlabel-word space. To address this issue, we propose a label-word construction\nprocess that incorporates scenario-specific concepts. Specifically, we extract\nrich concepts from task-specific scenarios as label-word candidates and then\ndevelop a novel cascade calibration module to refine the candidates into a set\nof label words for each class. We evaluate the effectiveness of our proposed\napproach through extensive experiments on {five} widely used datasets for\nzero-shot text classification. The results demonstrate that our method\noutperforms existing methods and achieves state-of-the-art results.", "published": "2024-01-10 15:02:35", "link": "http://arxiv.org/abs/2401.05204v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Pre-trained Large Language Models for Financial Sentiment Analysis", "abstract": "Financial sentiment analysis refers to classifying financial text contents\ninto sentiment categories (e.g. positive, negative, and neutral). In this\npaper, we focus on the classification of financial news title, which is a\nchallenging task due to a lack of large amount of training samples. To overcome\nthis difficulty, we propose to adapt the pretrained large language models\n(LLMs) [1, 2, 3] to solve this problem. The LLMs, which are trained from huge\namount of text corpora,have an advantage in text understanding and can be\neffectively adapted to domain-specific task while requiring very few amount of\ntraining samples. In particular, we adapt the open-source Llama2-7B model\n(2023) with the supervised fine-tuning (SFT) technique [4]. Experimental\nevaluation shows that even with the 7B model (which is relatively small for\nLLMs), our approach significantly outperforms the previous state-of-the-art\nalgorithms.", "published": "2024-01-10 15:27:41", "link": "http://arxiv.org/abs/2401.05215v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language-based Valence and Arousal Expressions between the United States\n  and China: a Cross-Cultural Examination", "abstract": "While affective expressions on social media have been extensively studied,\nmost research has focused on the Western context. This paper explores cultural\ndifferences in affective expressions by comparing valence and arousal on\nTwitter/X (geolocated to the US) and Sina Weibo (in Mainland China). Using the\nNRC-VAD lexicon to measure valence and arousal, we identify distinct patterns\nof emotional expression across both platforms. Our analysis reveals a\nfunctional representation between valence and arousal, showing a negative\noffset in contrast to traditional lab-based findings which suggest a positive\noffset. Furthermore, we uncover significant cross-cultural differences in\narousal, with US users displaying higher emotional intensity than Chinese\nusers, regardless of the valence of the content. Finally, we conduct a\ncomprehensive language analysis correlating n-grams and LDA topics with\naffective dimensions to deepen our understanding of how language and culture\nshape emotional expression. These findings contribute to a more nuanced\nunderstanding of affective communication across cultural and linguistic\ncontexts on social media.", "published": "2024-01-10 16:32:25", "link": "http://arxiv.org/abs/2401.05254v5", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "INACIA: Integrating Large Language Models in Brazilian Audit Courts:\n  Opportunities and Challenges", "abstract": "This paper introduces INACIA (Instru\\c{c}\\~ao Assistida com Intelig\\^encia\nArtificial), a groundbreaking system designed to integrate Large Language\nModels (LLMs) into the operational framework of Brazilian Federal Court of\nAccounts (TCU). The system automates various stages of case analysis, including\nbasic information extraction, admissibility examination, Periculum in mora and\nFumus boni iuris analyses, and recommendations generation. Through a series of\nexperiments, we demonstrate INACIA's potential in extracting relevant\ninformation from case documents, evaluating its legal plausibility, and\nformulating propositions for judicial decision-making. Utilizing a validation\ndataset alongside LLMs, our evaluation methodology presents a novel approach to\nassessing system performance, correlating highly with human judgment. These\nresults underscore INACIA's potential in complex legal task handling while also\nacknowledging the current limitations. This study discusses possible\nimprovements and the broader implications of applying AI in legal contexts,\nsuggesting that INACIA represents a significant step towards integrating AI in\nlegal systems globally, albeit with cautious optimism grounded in the empirical\nfindings.", "published": "2024-01-10 17:13:28", "link": "http://arxiv.org/abs/2401.05273v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "I am a Strange Dataset: Metalinguistic Tests for Language Models", "abstract": "Statements involving metalinguistic self-reference (\"This paper has six\nsections.\") are prevalent in many domains. Can current large language models\n(LLMs) handle such language? In this paper, we present \"I am a Strange\nDataset\", a new dataset for addressing this question. There are two subtasks:\ngeneration and verification. In generation, models continue statements like\n\"The penultimate word in this sentence is\" (where a correct continuation is\n\"is\"). In verification, models judge the truth of statements like \"The\npenultimate word in this sentence is sentence.\" (false). We also provide\nminimally different metalinguistic non-self-reference examples to complement\nthe main dataset by probing for whether models can handle metalinguistic\nlanguage at all. The dataset is hand-crafted by experts and validated by\nnon-expert annotators. We test a variety of open-source LLMs (7B to 70B\nparameters) as well as closed-source LLMs through APIs. All models perform\nclose to chance across both subtasks and even on the non-self-referential\nmetalinguistic control data, though we find some steady improvement with model\nscale. GPT 4 is the only model to consistently do significantly better than\nchance, and it is still only in the 60% range, while our untrained human\nannotators score well in the 89-93% range. The dataset and evaluation toolkit\nare available at https://github.com/TristanThrush/i-am-a-strange-dataset.", "published": "2024-01-10 18:06:27", "link": "http://arxiv.org/abs/2401.05300v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Print Debugging to Improve Code Generation in Large Language\n  Models", "abstract": "Large language models (LLMs) have made significant progress in code\ngeneration tasks, but their performance in tackling programming problems with\ncomplex data structures and algorithms remains suboptimal. To address this\nissue, we propose an in-context learning approach that guides LLMs to debug by\nusing a \"print debugging\" method, which involves inserting print statements to\ntrace and analysing logs for fixing the bug. We collect a Leetcode problem\ndataset and evaluate our method using the Leetcode online judging system.\nExperiments with GPT-4 demonstrate the effectiveness of our approach,\noutperforming rubber duck debugging in easy and medium-level Leetcode problems\nby 1.5% and 17.9%.", "published": "2024-01-10 18:37:59", "link": "http://arxiv.org/abs/2401.05319v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks", "abstract": "In this paper, we introduce InfiAgent-DABench, the first benchmark\nspecifically designed to evaluate LLM-based agents on data analysis tasks.\nThese tasks require agents to end-to-end solving complex tasks by interacting\nwith an execution environment. This benchmark contains DAEval, a dataset\nconsisting of 257 data analysis questions derived from 52 CSV files, and an\nagent framework which incorporates LLMs to serve as data analysis agents for\nboth serving and evaluation. Since data analysis questions are often open-ended\nand hard to evaluate without human supervision, we adopt a format-prompting\ntechnique to convert each question into a closed-form format so that they can\nbe automatically evaluated. Our extensive benchmarking of 34 LLMs uncovers the\ncurrent challenges encountered in data analysis tasks. In addition, building on\ntop of our agent framework, we develop a specialized agent, DAAgent, which\nsurpasses GPT-3.5 by 3.9% on DABench. Evaluation datasets and toolkits for\nInfiAgent-DABench are released at https://github.com/InfiAgent/InfiAgent .", "published": "2024-01-10 19:04:00", "link": "http://arxiv.org/abs/2401.05507v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Source Code Classification Effectiveness via Prompt Learning\n  Incorporating Knowledge Features", "abstract": "Researchers have investigated the potential of leveraging pre-trained\nlanguage models, such as CodeBERT, to enhance source code-related tasks.\nPrevious methodologies have relied on CodeBERT's '[CLS]' token as the embedding\nrepresentation of input sequences for task performance, necessitating\nadditional neural network layers to enhance feature representation, which in\nturn increases computational expenses. These approaches have also failed to\nfully leverage the comprehensive knowledge inherent within the source code and\nits associated text, potentially limiting classification efficacy. We propose\nCodeClassPrompt, a text classification technique that harnesses prompt learning\nto extract rich knowledge associated with input sequences from pre-trained\nmodels, thereby eliminating the need for additional layers and lowering\ncomputational costs. By applying an attention mechanism, we synthesize\nmulti-layered knowledge into task-specific features, enhancing classification\naccuracy. Our comprehensive experimentation across four distinct source\ncode-related tasks reveals that CodeClassPrompt achieves competitive\nperformance while significantly reducing computational overhead.", "published": "2024-01-10 20:49:59", "link": "http://arxiv.org/abs/2401.05544v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reinforcement Learning for Optimizing RAG for Domain Chatbots", "abstract": "With the advent of Large Language Models (LLM), conversational assistants\nhave become prevalent for domain use cases. LLMs acquire the ability to\ncontextual question answering through training, and Retrieval Augmented\nGeneration (RAG) further enables the bot to answer domain-specific questions.\nThis paper describes a RAG-based approach for building a chatbot that answers\nuser's queries using Frequently Asked Questions (FAQ) data. We train an\nin-house retrieval embedding model using infoNCE loss, and experimental results\ndemonstrate that the in-house model works significantly better than the\nwell-known general-purpose public embedding model, both in terms of retrieval\naccuracy and Out-of-Domain (OOD) query detection. As an LLM, we use an open\nAPI-based paid ChatGPT model. We noticed that a previously retrieved-context\ncould be used to generate an answer for specific patterns/sequences of queries\n(e.g., follow-up queries). Hence, there is a scope to optimize the number of\nLLM tokens and cost. Assuming a fixed retrieval model and an LLM, we optimize\nthe number of LLM tokens using Reinforcement Learning (RL). Specifically, we\npropose a policy-based model external to the RAG, which interacts with the RAG\npipeline through policy actions and updates the policy to optimize the cost.\nThe policy model can perform two actions: to fetch FAQ context or skip\nretrieval. We use the open API-based GPT-4 as the reward model. We then train a\npolicy model using policy gradient on multiple training chat sessions. As a\npolicy model, we experimented with a public gpt-2 model and an in-house BERT\nmodel. With the proposed RL-based optimization combined with similarity\nthreshold, we are able to achieve significant cost savings while getting a\nslightly improved accuracy. Though we demonstrate results for the FAQ chatbot,\nthe proposed RL approach is generic and can be experimented with any existing\nRAG pipeline.", "published": "2024-01-10 02:57:20", "link": "http://arxiv.org/abs/2401.06800v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generative AI Meets Semantic Communication: Evolution and Revolution of\n  Communication Tasks", "abstract": "While deep generative models are showing exciting abilities in computer\nvision and natural language processing, their adoption in communication\nframeworks is still far underestimated. These methods are demonstrated to\nevolve solutions to classic communication problems such as denoising,\nrestoration, or compression. Nevertheless, generative models can unveil their\nreal potential in semantic communication frameworks, in which the receiver is\nnot asked to recover the sequence of bits used to encode the transmitted\n(semantic) message, but only to regenerate content that is semantically\nconsistent with the transmitted message. Disclosing generative models\ncapabilities in semantic communication paves the way for a paradigm shift with\nrespect to conventional communication systems, which has great potential to\nreduce the amount of data traffic and offers a revolutionary versatility to\nnovel tasks and applications that were not even conceivable a few years ago. In\nthis paper, we present a unified perspective of deep generative models in\nsemantic communication and we unveil their revolutionary role in future\ncommunication frameworks, enabling emerging applications and tasks. Finally, we\nanalyze the challenges and opportunities to face to develop generative models\nspecifically tailored for communication systems.", "published": "2024-01-10 09:56:36", "link": "http://arxiv.org/abs/2401.06803v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ChatGPT, Let us Chat Sign Language: Experiments, Architectural Elements,\n  Challenges and Research Directions", "abstract": "ChatGPT is a language model based on Generative AI. Existing research work on\nChatGPT focused on its use in various domains. However, its potential for Sign\nLanguage Translation (SLT) is yet to be explored. This paper addresses this\nvoid. Therefore, we present GPT's evolution aiming a retrospective analysis of\nthe improvements to its architecture for SLT. We explore ChatGPT's capabilities\nin translating different sign languages in paving the way to better\naccessibility for deaf and hard-of-hearing community. Our experimental results\nindicate that ChatGPT can accurately translate from English to American (ASL),\nAustralian (AUSLAN), and British (BSL) sign languages and from Arabic Sign\nLanguage (ArSL) to English with only one prompt iteration. However, the model\nfailed to translate from Arabic to ArSL and ASL, AUSLAN, and BSL to Arabic.\nConsequently, we present challenges and derive insights for future research\ndirections.", "published": "2024-01-10 13:39:49", "link": "http://arxiv.org/abs/2401.06804v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Exploring the Reasoning Abilities of Multimodal Large Language Models\n  (MLLMs): A Comprehensive Survey on Emerging Trends in Multimodal Reasoning", "abstract": "Strong Artificial Intelligence (Strong AI) or Artificial General Intelligence\n(AGI) with abstract reasoning ability is the goal of next-generation AI. Recent\nadvancements in Large Language Models (LLMs), along with the emerging field of\nMultimodal Large Language Models (MLLMs), have demonstrated impressive\ncapabilities across a wide range of multimodal tasks and applications.\nParticularly, various MLLMs, each with distinct model architectures, training\ndata, and training stages, have been evaluated across a broad range of MLLM\nbenchmarks. These studies have, to varying degrees, revealed different aspects\nof the current capabilities of MLLMs. However, the reasoning abilities of MLLMs\nhave not been systematically investigated. In this survey, we comprehensively\nreview the existing evaluation protocols of multimodal reasoning, categorize\nand illustrate the frontiers of MLLMs, introduce recent trends in applications\nof MLLMs on reasoning-intensive tasks, and finally discuss current practices\nand future directions. We believe our survey establishes a solid base and sheds\nlight on this important topic, multimodal reasoning.", "published": "2024-01-10 15:29:21", "link": "http://arxiv.org/abs/2401.06805v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AugSumm: towards generalizable speech summarization using synthetic\n  labels from large language model", "abstract": "Abstractive speech summarization (SSUM) aims to generate human-like summaries\nfrom speech. Given variations in information captured and phrasing, recordings\ncan be summarized in multiple ways. Therefore, it is more reasonable to\nconsider a probabilistic distribution of all potential summaries rather than a\nsingle summary. However, conventional SSUM models are mostly trained and\nevaluated with a single ground-truth (GT) human-annotated deterministic summary\nfor every recording. Generating multiple human references would be ideal to\nbetter represent the distribution statistically, but is impractical because\nannotation is expensive. We tackle this challenge by proposing AugSumm, a\nmethod to leverage large language models (LLMs) as a proxy for human annotators\nto generate augmented summaries for training and evaluation. First, we explore\nprompting strategies to generate synthetic summaries from ChatGPT. We validate\nthe quality of synthetic summaries using multiple metrics including human\nevaluation, where we find that summaries generated using AugSumm are perceived\nas more valid to humans. Second, we develop methods to utilize synthetic\nsummaries in training and evaluation. Experiments on How2 demonstrate that\npre-training on synthetic summaries and fine-tuning on GT summaries improves\nROUGE-L by 1 point on both GT and AugSumm-based test sets. AugSumm summaries\nare available at https://github.com/Jungjee/AugSumm.", "published": "2024-01-10 18:39:46", "link": "http://arxiv.org/abs/2401.06806v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An EcoSage Assistant: Towards Building A Multimodal Plant Care Dialogue\n  Assistant", "abstract": "In recent times, there has been an increasing awareness about imminent\nenvironmental challenges, resulting in people showing a stronger dedication to\ntaking care of the environment and nurturing green life. The current $19.6\nbillion indoor gardening industry, reflective of this growing sentiment, not\nonly signifies a monetary value but also speaks of a profound human desire to\nreconnect with the natural world. However, several recent surveys cast a\nrevealing light on the fate of plants within our care, with more than half\nsuccumbing primarily due to the silent menace of improper care. Thus, the need\nfor accessible expertise capable of assisting and guiding individuals through\nthe intricacies of plant care has become paramount more than ever. In this\nwork, we make the very first attempt at building a plant care assistant, which\naims to assist people with plant(-ing) concerns through conversations. We\npropose a plant care conversational dataset named Plantational, which contains\naround 1K dialogues between users and plant care experts. Our end-to-end\nproposed approach is two-fold : (i) We first benchmark the dataset with the\nhelp of various large language models (LLMs) and visual language model (VLM) by\nstudying the impact of instruction tuning (zero-shot and few-shot prompting)\nand fine-tuning techniques on this task; (ii) finally, we build EcoSage, a\nmulti-modal plant care assisting dialogue generation framework, incorporating\nan adapter-based modality infusion using a gated mechanism. We performed an\nextensive examination (both automated and manual evaluation) of the performance\nexhibited by various LLMs and VLM in the generation of the domain-specific\ndialogue responses to underscore the respective strengths and weaknesses of\nthese diverse models.", "published": "2024-01-10 19:06:35", "link": "http://arxiv.org/abs/2401.06807v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "User Embedding Model for Personalized Language Prompting", "abstract": "Modeling long histories plays a pivotal role in enhancing recommendation\nsystems, allowing to capture user's evolving preferences, resulting in more\nprecise and personalized recommendations. In this study we tackle the\nchallenges of modeling long user histories for preference understanding in\nnatural language. Specifically, we introduce a new User Embedding Module (UEM)\nthat efficiently processes user history in free-form text by compressing and\nrepresenting them as embeddings, to use them as soft prompts to a LM. Our\nexperiments demonstrate the superior capability of this approach in handling\nsignificantly longer histories compared to conventional text based prompting\nmethods, yielding substantial improvements in predictive performance. The main\ncontribution of this research is to demonstrate the ability to bias language\nmodels with user signals represented as embeddings.", "published": "2024-01-10 00:35:52", "link": "http://arxiv.org/abs/2401.04858v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Analysis of User Behaviors for Objectively Evaluating Spoken Dialogue\n  Systems", "abstract": "Establishing evaluation schemes for spoken dialogue systems is important, but\nit can also be challenging. While subjective evaluations are commonly used in\nuser experiments, objective evaluations are necessary for research comparison\nand reproducibility. To address this issue, we propose a framework for\nindirectly but objectively evaluating systems based on users' behaviors. In\nthis paper, to this end, we investigate the relationship between user behaviors\nand subjective evaluation scores in social dialogue tasks: attentive listening,\njob interview, and first-meeting conversation. The results reveal that in\ndialogue tasks where user utterances are primary, such as attentive listening\nand job interview, indicators like the number of utterances and words play a\nsignificant role in evaluation. Observing disfluency also can indicate the\neffectiveness of formal tasks, such as job interview. On the other hand, in\ndialogue tasks with high interactivity, such as first-meeting conversation,\nbehaviors related to turn-taking, like average switch pause length, become more\nimportant. These findings suggest that selecting appropriate user behaviors can\nprovide valuable insights for objective evaluation in each social dialogue\ntask.", "published": "2024-01-10 01:02:26", "link": "http://arxiv.org/abs/2401.04867v2", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Real-time and Continuous Turn-taking Prediction Using Voice Activity\n  Projection", "abstract": "A demonstration of a real-time and continuous turn-taking prediction system\nis presented. The system is based on a voice activity projection (VAP) model,\nwhich directly maps dialogue stereo audio to future voice activities. The VAP\nmodel includes contrastive predictive coding (CPC) and self-attention\ntransformers, followed by a cross-attention transformer. We examine the effect\nof the input context audio length and demonstrate that the proposed system can\noperate in real-time with CPU settings, with minimal performance degradation.", "published": "2024-01-10 01:09:55", "link": "http://arxiv.org/abs/2401.04868v1", "categories": ["cs.CL", "cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Learning Audio Concepts from Counterfactual Natural Language", "abstract": "Conventional audio classification relied on predefined classes, lacking the\nability to learn from free-form text. Recent methods unlock learning joint\naudio-text embeddings from raw audio-text pairs describing audio in natural\nlanguage. Despite recent advancements, there is little exploration of\nsystematic methods to train models for recognizing sound events and sources in\nalternative scenarios, such as distinguishing fireworks from gunshots at\noutdoor events in similar situations. This study introduces causal reasoning\nand counterfactual analysis in the audio domain. We use counterfactual\ninstances and include them in our model across different aspects. Our model\nconsiders acoustic characteristics and sound source information from\nhuman-annotated reference texts. To validate the effectiveness of our model, we\nconducted pre-training utilizing multiple audio captioning datasets. We then\nevaluate with several common downstream tasks, demonstrating the merits of the\nproposed method as one of the first works leveraging counterfactual information\nin audio domain. Specifically, the top-1 accuracy in open-ended language-based\naudio retrieval task increased by more than 43%.", "published": "2024-01-10 05:15:09", "link": "http://arxiv.org/abs/2401.04935v1", "categories": ["cs.MM", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "MuTox: Universal MUltilingual Audio-based TOXicity Dataset and Zero-shot\n  Detector", "abstract": "Research in toxicity detection in natural language processing for the speech\nmodality (audio-based) is quite limited, particularly for languages other than\nEnglish. To address these limitations and lay the groundwork for truly\nmultilingual audio-based toxicity detection, we introduce MuTox, the first\nhighly multilingual audio-based dataset with toxicity labels. The dataset\ncomprises 20,000 audio utterances for English and Spanish, and 4,000 for the\nother 19 languages. To demonstrate the quality of this dataset, we trained the\nMuTox audio-based toxicity classifier, which enables zero-shot toxicity\ndetection across a wide range of languages. This classifier outperforms\nexisting text-based trainable classifiers by more than 1% AUC, while expanding\nthe language coverage more than tenfold. When compared to a wordlist-based\nclassifier that covers a similar number of languages, MuTox improves precision\nand recall by approximately 2.5 times. This significant improvement underscores\nthe potential of MuTox in advancing the field of audio-based toxicity\ndetection.", "published": "2024-01-10 10:37:45", "link": "http://arxiv.org/abs/2401.05060v2", "categories": ["cs.SD", "cs.CL", "eess.AS", "I.2.7"], "primary_category": "cs.SD"}
{"title": "Noise-robust zero-shot text-to-speech synthesis conditioned on\n  self-supervised speech-representation model with adapters", "abstract": "The zero-shot text-to-speech (TTS) method, based on speaker embeddings\nextracted from reference speech using self-supervised learning (SSL) speech\nrepresentations, can reproduce speaker characteristics very accurately.\nHowever, this approach suffers from degradation in speech synthesis quality\nwhen the reference speech contains noise. In this paper, we propose a\nnoise-robust zero-shot TTS method. We incorporated adapters into the SSL model,\nwhich we fine-tuned with the TTS model using noisy reference speech. In\naddition, to further improve performance, we adopted a speech enhancement (SE)\nfront-end. With these improvements, our proposed SSL-based zero-shot TTS\nachieved high-quality speech synthesis with noisy reference speech. Through the\nobjective and subjective evaluations, we confirmed that the proposed method is\nhighly robust to noise in reference speech, and effectively works in\ncombination with SE.", "published": "2024-01-10 12:21:21", "link": "http://arxiv.org/abs/2401.05111v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Do Vision and Language Encoders Represent the World Similarly?", "abstract": "Aligned text-image encoders such as CLIP have become the de facto model for\nvision-language tasks. Furthermore, modality-specific encoders achieve\nimpressive performances in their respective domains. This raises a central\nquestion: does an alignment exist between uni-modal vision and language\nencoders since they fundamentally represent the same physical world? Analyzing\nthe latent spaces structure of vision and language models on image-caption\nbenchmarks using the Centered Kernel Alignment (CKA), we find that the\nrepresentation spaces of unaligned and aligned encoders are semantically\nsimilar. In the absence of statistical similarity in aligned encoders like\nCLIP, we show that a possible matching of unaligned encoders exists without any\ntraining. We frame this as a seeded graph-matching problem exploiting the\nsemantic similarity between graphs and propose two methods - a Fast Quadratic\nAssignment Problem optimization, and a novel localized CKA metric-based\nmatching/retrieval. We demonstrate the effectiveness of this on several\ndownstream tasks including cross-lingual, cross-domain caption matching and\nimage classification. Code available at github.com/mayug/0-shot-llm-vision.", "published": "2024-01-10 15:51:39", "link": "http://arxiv.org/abs/2401.05224v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of\n  Video", "abstract": "The Internet's wealth of content, with up to 60% published in English,\nstarkly contrasts the global population, where only 18.8% are English speakers,\nand just 5.1% consider it their native language, leading to disparities in\nonline information access. Unfortunately, automated processes for dubbing of\nvideo - replacing the audio track of a video with a translated alternative -\nremains a complex and challenging task due to pipelines, necessitating precise\ntiming, facial movement synchronization, and prosody matching. While end-to-end\ndubbing offers a solution, data scarcity continues to impede the progress of\nboth end-to-end and pipeline-based methods. In this work, we introduce\nAnim-400K, a comprehensive dataset of over 425K aligned animated video segments\nin Japanese and English supporting various video-related tasks, including\nautomated dubbing, simultaneous translation, guided video summarization, and\ngenre/theme/style classification. Our dataset is made publicly available for\nresearch purposes at https://github.com/davidmchan/Anim400K.", "published": "2024-01-10 18:32:38", "link": "http://arxiv.org/abs/2401.05314v1", "categories": ["eess.AS", "cs.CL", "cs.CV", "cs.SD"], "primary_category": "eess.AS"}
{"title": "From Pampas to Pixels: Fine-Tuning Diffusion Models for Ga\u00facho\n  Heritage", "abstract": "Generative AI has become pervasive in society, witnessing significant\nadvancements in various domains. Particularly in the realm of Text-to-Image\n(TTI) models, Latent Diffusion Models (LDMs), showcase remarkable capabilities\nin generating visual content based on textual prompts. This paper addresses the\npotential of LDMs in representing local cultural concepts, historical figures,\nand endangered species. In this study, we use the cultural heritage of Rio\nGrande do Sul (RS), Brazil, as an illustrative case. Our objective is to\ncontribute to the broader understanding of how generative models can help to\ncapture and preserve the cultural and historical identity of regions. The paper\noutlines the methodology, including subject selection, dataset creation, and\nthe fine-tuning process. The results showcase the images generated, alongside\nthe challenges and feasibility of each concept. In conclusion, this work shows\nthe power of these models to represent and preserve unique aspects of diverse\nregions and communities.", "published": "2024-01-10 19:34:52", "link": "http://arxiv.org/abs/2401.05520v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Useful Blunders: Can Automated Speech Recognition Errors Improve\n  Downstream Dementia Classification?", "abstract": "\\textbf{Objectives}: We aimed to investigate how errors from automatic speech\nrecognition (ASR) systems affect dementia classification accuracy, specifically\nin the ``Cookie Theft'' picture description task. We aimed to assess whether\nimperfect ASR-generated transcripts could provide valuable information for\ndistinguishing between language samples from cognitively healthy individuals\nand those with Alzheimer's disease (AD).\n  \\textbf{Methods}: We conducted experiments using various ASR models, refining\ntheir transcripts with post-editing techniques. Both these imperfect ASR\ntranscripts and manually transcribed ones were used as inputs for the\ndownstream dementia classification. We conducted comprehensive error analysis\nto compare model performance and assess ASR-generated transcript effectiveness\nin dementia classification.\n  \\textbf{Results}: Imperfect ASR-generated transcripts surprisingly\noutperformed manual transcription for distinguishing between individuals with\nAD and those without in the ``Cookie Theft'' task. These ASR-based models\nsurpassed the previous state-of-the-art approach, indicating that ASR errors\nmay contain valuable cues related to dementia. The synergy between ASR and\nclassification models improved overall accuracy in dementia classification.\n  \\textbf{Conclusion}: Imperfect ASR transcripts effectively capture linguistic\nanomalies linked to dementia, improving accuracy in classification tasks. This\nsynergy between ASR and classification models underscores ASR's potential as a\nvaluable tool in assessing cognitive impairment and related clinical\napplications.", "published": "2024-01-10 21:38:03", "link": "http://arxiv.org/abs/2401.05551v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Hierarchical Knowledge Distillation on Text Graph for Data-limited\n  Attribute Inference", "abstract": "The popularization of social media increases user engagements and generates a\nlarge amount of user-oriented data. Among them, text data (e.g., tweets, blogs)\nsignificantly attracts researchers and speculators to infer user attributes\n(e.g., age, gender, location) for fulfilling their intents. Generally, this\nline of work casts attribute inference as a text classification problem, and\nstarts to leverage graph neural networks (GNNs) to utilize higher-level\nrepresentations of source texts. However, these text graphs are constructed\nover words, suffering from high memory consumption and ineffectiveness on few\nlabeled texts. To address this challenge, we design a text-graph-based few-shot\nlearning model for attribute inferences on social media text data. Our model\nfirst constructs and refines a text graph using manifold learning and message\npassing, which offers a better trade-off between expressiveness and complexity.\nAfterwards, to further use cross-domain texts and unlabeled texts to improve\nfew-shot performance, a hierarchical knowledge distillation is devised over\ntext graph to optimize the problem, which derives better text representations,\nand advances model generalization ability. Experiments on social media datasets\ndemonstrate the state-of-the-art performance of our model on attribute\ninferences with considerably fewer labeled texts.", "published": "2024-01-10 05:50:34", "link": "http://arxiv.org/abs/2401.06802v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Grounded learning for compositional vector semantics", "abstract": "Categorical compositional distributional semantics is an approach to\nmodelling language that combines the success of vector-based models of meaning\nwith the compositional power of formal semantics. However, this approach was\ndeveloped without an eye to cognitive plausibility. Vector representations of\nconcepts and concept binding are also of interest in cognitive science, and\nhave been proposed as a way of representing concepts within a biologically\nplausible spiking neural network. This work proposes a way for compositional\ndistributional semantics to be implemented within a spiking neural network\narchitecture, with the potential to address problems in concept binding, and\ngive a small implementation. We also describe a means of training word\nrepresentations using labelled images.", "published": "2024-01-10 22:12:34", "link": "http://arxiv.org/abs/2401.06808v1", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
{"title": "AutoAct: Automatic Agent Learning from Scratch for QA via Self-Planning", "abstract": "Language agents have achieved considerable performance on various complex\nquestion-answering tasks by planning with external tools. Despite the incessant\nexploration in this field, existing language agent systems still struggle with\ncostly, non-reproducible data reliance and face the challenge of compelling a\nsingle model for multiple functions. To this end, we introduce AutoAct, an\nautomatic agent learning framework for QA that does not rely on large-scale\nannotated data and synthetic planning trajectories from closed-source models\n(e.g., GPT-4). Given limited data with a tool library, AutoAct first\nautomatically synthesizes planning trajectories without any assistance from\nhumans or strong closed-source models. Then, AutoAct leverages a\ndivision-of-labor strategy to automatically differentiate based on the target\ntask information and synthesized trajectories, producing a sub-agent group to\ncomplete the task. We conduct comprehensive experiments with different LLMs,\nwhich demonstrates that AutoAct yields better or parallel performance compared\nto various strong baselines. Further analysis demonstrates the effectiveness of\nthe division-of-labor strategy, with the trajectory quality generated by\nAutoAct generally outperforming that of others. Code will be available at\nhttps://github.com/zjunlp/AutoAct.", "published": "2024-01-10 16:57:24", "link": "http://arxiv.org/abs/2401.05268v4", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Sleeper Agents: Training Deceptive LLMs that Persist Through Safety\n  Training", "abstract": "Humans are capable of strategically deceptive behavior: behaving helpfully in\nmost situations, but then behaving very differently in order to pursue\nalternative objectives when given the opportunity. If an AI system learned such\na deceptive strategy, could we detect it and remove it using current\nstate-of-the-art safety training techniques? To study this question, we\nconstruct proof-of-concept examples of deceptive behavior in large language\nmodels (LLMs). For example, we train models that write secure code when the\nprompt states that the year is 2023, but insert exploitable code when the\nstated year is 2024. We find that such backdoor behavior can be made\npersistent, so that it is not removed by standard safety training techniques,\nincluding supervised fine-tuning, reinforcement learning, and adversarial\ntraining (eliciting unsafe behavior and then training to remove it). The\nbackdoor behavior is most persistent in the largest models and in models\ntrained to produce chain-of-thought reasoning about deceiving the training\nprocess, with the persistence remaining even when the chain-of-thought is\ndistilled away. Furthermore, rather than removing backdoors, we find that\nadversarial training can teach models to better recognize their backdoor\ntriggers, effectively hiding the unsafe behavior. Our results suggest that,\nonce a model exhibits deceptive behavior, standard techniques could fail to\nremove such deception and create a false impression of safety.", "published": "2024-01-10 22:14:35", "link": "http://arxiv.org/abs/2401.05566v3", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG", "cs.SE"], "primary_category": "cs.CR"}
{"title": "Comparison of linear and nonlinear methods for decoding selective\n  attention to speech from ear-EEG recordings", "abstract": "Many people with hearing loss struggle to comprehend speech in crowded\nauditory scenes, even when they are using hearing aids. It has recently been\ndemonstrated that the focus of a listener's selective attention to speech can\nbe decoded from their electroencephalography (EEG) recordings, raising the\nprospect of smart EEG-steered hearing aids which restore speech comprehension\nin adverse acoustic environments (such as the cocktail party). To this end, we\nhere assess the feasibility of using a novel, ultra-wearable ear-EEG device to\nclassify the selective attention of normal-hearing listeners who participated\nin a two-talker competing-speakers experiment.\n  Eighteen participants took part in a diotic listening task, whereby they were\nasked to attend to one narrator whilst ignoring the other. Encoding models were\nestimated from the recorded signals, and these confirmed that the device has\nthe ability to capture auditory responses that are consistent with those\nreported in high-density EEG studies. Several state-of-the-art auditory\nattention decoding algorithms were next compared, including\nstimulus-reconstruction algorithms based on linear regression as well as\nnon-linear deep neural networks, and canonical correlation analysis (CCA).\n  Meaningful markers of selective auditory attention could be extracted from\nthe ear-EEG signals of all 18 participants, even when those markers were\nderived from relatively short EEG segments of just five seconds in duration.\nAlgorithms which related the EEG signals to the rising edges of the speech\ntemporal envelope (onset envelope) were more successful than those which made\nuse of the temporal envelope itself. The CCA algorithm achieved the highest\nmean attention decoding accuracy, although differences between the performances\nof the three algorithms were both small and not statistically significant when\nEEG segments of short durations were employed.", "published": "2024-01-10 14:35:14", "link": "http://arxiv.org/abs/2401.05187v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Full-frequency dynamic convolution: a physical frequency-dependent\n  convolution for sound event detection", "abstract": "Recently, 2D convolution has been found unqualified in sound event detection\n(SED). It enforces translation equivariance on sound events along frequency\naxis, which is not a shift-invariant dimension. To address this issue, dynamic\nconvolution is used to model the frequency dependency of sound events. In this\npaper, we proposed the first full-dynamic method named full-frequency dynamic\nconvolution (FFDConv). FFDConv generates frequency kernels for every frequency\nband, which is designed directly in the structure for frequency-dependent\nmodeling. It physically furnished 2D convolution with the capability of\nfrequency-dependent modeling. FFDConv outperforms not only the baseline by 6.6%\nin DESED real validation dataset in terms of PSDS1, but outperforms the other\nfull-dynamic methods. In addition, by visualizing features of sound events, we\nobserved that FFDConv could effectively extract coherent features in specific\nfrequency bands, consistent with the vocal continuity of sound events. This\nproves that FFDConv has great frequency-dependent perception ability.", "published": "2024-01-10 07:43:33", "link": "http://arxiv.org/abs/2401.04976v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Self-supervised speech representation and contextual text embedding for\n  match-mismatch classification with EEG recording", "abstract": "Relating speech to EEG holds considerable importance but is challenging. In\nthis study, a deep convolutional network was employed to extract spatiotemporal\nfeatures from EEG data. Self-supervised speech representation and contextual\ntext embedding were used as speech features. Contrastive learning was used to\nrelate EEG features to speech features. The experimental results demonstrate\nthe benefits of using self-supervised speech representation and contextual text\nembedding. Through feature fusion and model ensemble, an accuracy of 60.29% was\nachieved, and the performance was ranked as No.2 in Task 1 of the Auditory EEG\nChallenge (ICASSP 2024). The code to implement our work is available on Github:\nhttps://github.com/bobwangPKU/EEG-Stimulus-Match-Mismatch.", "published": "2024-01-10 07:11:36", "link": "http://arxiv.org/abs/2401.04964v2", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Singer Identity Representation Learning using Self-Supervised Techniques", "abstract": "Significant strides have been made in creating voice identity representations\nusing speech data. However, the same level of progress has not been achieved\nfor singing voices. To bridge this gap, we suggest a framework for training\nsinger identity encoders to extract representations suitable for various\nsinging-related tasks, such as singing voice similarity and synthesis. We\nexplore different self-supervised learning techniques on a large collection of\nisolated vocal tracks and apply data augmentations during training to ensure\nthat the representations are invariant to pitch and content variations. We\nevaluate the quality of the resulting representations on singer similarity and\nidentification tasks across multiple datasets, with a particular emphasis on\nout-of-domain generalization. Our proposed framework produces high-quality\nembeddings that outperform both speaker verification and wav2vec 2.0\npre-trained baselines on singing voice while operating at 44.1 kHz. We release\nour code and trained models to facilitate further research on singing voice and\nrelated areas.", "published": "2024-01-10 10:41:38", "link": "http://arxiv.org/abs/2401.05064v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VI-PANN: Harnessing Transfer Learning and Uncertainty-Aware Variational\n  Inference for Improved Generalization in Audio Pattern Recognition", "abstract": "Transfer learning (TL) is an increasingly popular approach to training deep\nlearning (DL) models that leverages the knowledge gained by training a\nfoundation model on diverse, large-scale datasets for use on downstream tasks\nwhere less domain- or task-specific data is available. The literature is rich\nwith TL techniques and applications; however, the bulk of the research makes\nuse of deterministic DL models which are often uncalibrated and lack the\nability to communicate a measure of epistemic (model) uncertainty in\nprediction. Unlike their deterministic counterparts, Bayesian DL (BDL) models\nare often well-calibrated, provide access to epistemic uncertainty for a\nprediction, and are capable of achieving competitive predictive performance. In\nthis study, we propose variational inference pre-trained audio neural networks\n(VI-PANNs). VI-PANNs are a variational inference variant of the popular\nResNet-54 architecture which are pre-trained on AudioSet, a large-scale audio\nevent detection dataset. We evaluate the quality of the resulting uncertainty\nwhen transferring knowledge from VI-PANNs to other downstream acoustic\nclassification tasks using the ESC-50, UrbanSound8K, and DCASE2013 datasets. We\ndemonstrate, for the first time, that it is possible to transfer calibrated\nuncertainty information along with knowledge from upstream tasks to enhance a\nmodel's capability to perform downstream tasks.", "published": "2024-01-10 19:55:44", "link": "http://arxiv.org/abs/2401.05531v2", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
