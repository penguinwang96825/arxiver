{"title": "From English To Foreign Languages: Transferring Pre-trained Language\n  Models", "abstract": "Pre-trained models have demonstrated their effectiveness in many downstream\nnatural language processing (NLP) tasks. The availability of multilingual\npre-trained models enables zero-shot transfer of NLP tasks from high resource\nlanguages to low resource ones. However, recent research in improving\npre-trained models focuses heavily on English. While it is possible to train\nthe latest neural architectures for other languages from scratch, it is\nundesirable due to the required amount of compute. In this work, we tackle the\nproblem of transferring an existing pre-trained model from English to other\nlanguages under a limited computational budget. With a single GPU, our approach\ncan obtain a foreign BERT base model within a day and a foreign BERT large\nwithin two days. Furthermore, evaluating our models on six languages, we\ndemonstrate that our models are better than multilingual BERT on two zero-shot\ntasks: natural language inference and dependency parsing.", "published": "2020-02-18 00:22:54", "link": "http://arxiv.org/abs/2002.07306v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Annotating and Extracting Synthesis Process of All-Solid-State Batteries\n  from Scientific Literature", "abstract": "The synthesis process is essential for achieving computational experiment\ndesign in the field of inorganic materials chemistry. In this work, we present\na novel corpus of the synthesis process for all-solid-state batteries and an\nautomated machine reading system for extracting the synthesis processes buried\nin the scientific literature. We define the representation of the synthesis\nprocesses using flow graphs, and create a corpus from the experimental sections\nof 243 papers. The automated machine-reading system is developed by a deep\nlearning-based sequence tagger and simple heuristic rule-based relation\nextractor. Our experimental results demonstrate that the sequence tagger with\nthe optimal setting can detect the entities with a macro-averaged F1 score of\n0.826, while the rule-based relation extractor can achieve high performance\nwith a macro-averaged F1 score of 0.887.", "published": "2020-02-18 02:30:03", "link": "http://arxiv.org/abs/2002.07339v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A New Clustering neural network for Chinese word segmentation", "abstract": "In this article I proposed a new model to achieve Chinese word\nsegmentation(CWS),which may have the potentiality to apply in other domains in\nthe future.It is a new thinking in CWS compared to previous works,to consider\nit as a clustering problem instead of a labeling problem.In this model,LSTM and\nself attention structures are used to collect context also sentence level\nfeatures in every layer,and after several layers,a clustering model is applied\nto split characters into groups,which are the final segmentation results.I call\nthis model CLNN.This algorithm can reach 98 percent of F score (without OOV\nwords) and 85 percent to 95 percent F score (with OOV words) in training data\nsets.Error analyses shows that OOV words will greatly reduce performances,which\nneeds a deeper research in the future.", "published": "2020-02-18 09:58:59", "link": "http://arxiv.org/abs/2002.07458v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue", "abstract": "Knowledge-grounded dialogue is a task of generating an informative response\nbased on both discourse context and external knowledge. As we focus on better\nmodeling the knowledge selection in the multi-turn knowledge-grounded dialogue,\nwe propose a sequential latent variable model as the first approach to this\nmatter. The model named sequential knowledge transformer (SKT) can keep track\nof the prior and posterior distribution over knowledge; as a result, it can not\nonly reduce the ambiguity caused from the diversity in knowledge selection of\nconversation but also better leverage the response information for proper\nchoice of knowledge. Our experimental results show that the proposed model\nimproves the knowledge selection accuracy and subsequently the performance of\nutterance generation. We achieve the new state-of-the-art performance on Wizard\nof Wikipedia (Dinan et al., 2019) as one of the most large-scale and\nchallenging benchmarks. We further validate the effectiveness of our model over\nexisting conversation methods in another knowledge-based dialogue Holl-E\ndataset (Moghe et al., 2018).", "published": "2020-02-18 11:59:59", "link": "http://arxiv.org/abs/2002.07510v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Deep Learning Techniques for Neural Machine Translation", "abstract": "In recent years, natural language processing (NLP) has got great development\nwith deep learning techniques. In the sub-field of machine translation, a new\napproach named Neural Machine Translation (NMT) has emerged and got massive\nattention from both academia and industry. However, with a significant number\nof researches proposed in the past several years, there is little work in\ninvestigating the development process of this new technology trend. This\nliterature survey traces back the origin and principal development timeline of\nNMT, investigates the important branches, categorizes different research\norientations, and discusses some future research trends in this field.", "published": "2020-02-18 12:49:14", "link": "http://arxiv.org/abs/2002.07526v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning by Semantic Similarity Makes Abstractive Summarization Better", "abstract": "By harnessing pre-trained language models, summarization models had rapid\nprogress recently. However, the models are mainly assessed by automatic\nevaluation metrics such as ROUGE. Although ROUGE is known for having a positive\ncorrelation with human evaluation scores, it has been criticized for its\nvulnerability and the gap between actual qualities. In this paper, we compare\nthe generated summaries from recent LM, BART, and the reference summaries from\na benchmark dataset, CNN/DM, using a crowd-sourced human evaluation metric.\nInterestingly, model-generated summaries receive higher scores relative to\nreference summaries. Stemming from our experimental results, we first argue the\nintrinsic characteristics of the CNN/DM dataset, the progress of pre-trained\nlanguage models, and their ability to generalize on the training data. Finally,\nwe share our insights into the model-generated summaries and presents our\nthought on learning methods for abstractive summarization.", "published": "2020-02-18 17:59:02", "link": "http://arxiv.org/abs/2002.07767v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpretable Multi-Headed Attention for Abstractive Summarization at\n  Controllable Lengths", "abstract": "Abstractive summarization at controllable lengths is a challenging task in\nnatural language processing. It is even more challenging for domains where\nlimited training data is available or scenarios in which the length of the\nsummary is not known beforehand. At the same time, when it comes to trusting\nmachine-generated summaries, explaining how a summary was constructed in\nhuman-understandable terms may be critical. We propose Multi-level Summarizer\n(MLS), a supervised method to construct abstractive summaries of a text\ndocument at controllable lengths. The key enabler of our method is an\ninterpretable multi-headed attention mechanism that computes attention\ndistribution over an input document using an array of timestep independent\nsemantic kernels. Each kernel optimizes a human-interpretable syntactic or\nsemantic property. Exhaustive experiments on two low-resource datasets in the\nEnglish language show that MLS outperforms strong baselines by up to 14.70% in\nthe METEOR score. Human evaluation of the summaries also suggests that they\ncapture the key concepts of the document at various length-budgets.", "published": "2020-02-18 19:40:20", "link": "http://arxiv.org/abs/2002.07845v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conditional Self-Attention for Query-based Summarization", "abstract": "Self-attention mechanisms have achieved great success on a variety of NLP\ntasks due to its flexibility of capturing dependency between arbitrary\npositions in a sequence. For problems such as query-based summarization (Qsumm)\nand knowledge graph reasoning where each input sequence is associated with an\nextra query, explicitly modeling such conditional contextual dependencies can\nlead to a more accurate solution, which however cannot be captured by existing\nself-attention mechanisms. In this paper, we propose \\textit{conditional\nself-attention} (CSA), a neural network module designed for conditional\ndependency modeling. CSA works by adjusting the pairwise attention between\ninput tokens in a self-attention module with the matching score of the inputs\nto the given query. Thereby, the contextual dependencies modeled by CSA will be\nhighly relevant to the query. We further studied variants of CSA defined by\ndifferent types of attention. Experiments on Debatepedia and HotpotQA benchmark\ndatasets show CSA consistently outperforms vanilla Transformer and previous\nmodels for the Qsumm problem.", "published": "2020-02-18 02:22:31", "link": "http://arxiv.org/abs/2002.07338v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Multi-Turn Response Selection Models with Complementary\n  Last-Utterance Selection by Instance Weighting", "abstract": "Open-domain retrieval-based dialogue systems require a considerable amount of\ntraining data to learn their parameters. However, in practice, the negative\nsamples of training data are usually selected from an unannotated conversation\ndata set at random. The generated training data is likely to contain noise and\naffect the performance of the response selection models. To address this\ndifficulty, we consider utilizing the underlying correlation in the data\nresource itself to derive different kinds of supervision signals and reduce the\ninfluence of noisy data. More specially, we consider a main-complementary task\npair. The main task (\\ie our focus) selects the correct response given the last\nutterance and context, and the complementary task selects the last utterance\ngiven the response and context. The key point is that the output of the\ncomplementary task is used to set instance weights for the main task. We\nconduct extensive experiments in two public datasets and obtain significant\nimprovement in both datasets. We also investigate the variant of our approach\nin multiple aspects, and the results have verified the effectiveness of our\napproach.", "published": "2020-02-18 06:29:01", "link": "http://arxiv.org/abs/2002.07397v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Model to Measure the Spread Power of Rumors", "abstract": "With technologies that have democratized the production and reproduction of\ninformation, a significant portion of daily interacted posts in social media\nhas been infected by rumors. Despite the extensive research on rumor detection\nand verification, so far, the problem of calculating the spread power of rumors\nhas not been considered. To address this research gap, the present study seeks\na model to calculate the Spread Power of Rumor (SPR) as the function of\ncontent-based features in two categories: False Rumor (FR) and True Rumor (TR).\nFor this purpose, the theory of Allport and Postman will be adopted, which it\nclaims that importance and ambiguity are the key variables in rumor-mongering\nand the power of rumor. Totally 42 content features in two categories\n\"importance\" (28 features) and \"ambiguity\" (14 features) are introduced to\ncompute SPR. The proposed model is evaluated on two datasets, Twitter and\nTelegram. The results showed that (i) the spread power of False Rumor documents\nis rarely more than True Rumors. (ii) there is a significant difference between\nthe SPR means of two groups False Rumor and True Rumor. (iii) SPR as a\ncriterion can have a positive impact on distinguishing False Rumors and True\nRumors.", "published": "2020-02-18 13:57:10", "link": "http://arxiv.org/abs/2002.07563v5", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Text Classification with Lexicon from PreAttention Mechanism", "abstract": "A comprehensive and high-quality lexicon plays a crucial role in traditional\ntext classification approaches. And it improves the utilization of the\nlinguistic knowledge. Although it is helpful for the task, the lexicon has got\nlittle attention in recent neural network models. Firstly, getting a\nhigh-quality lexicon is not easy. We lack an effective automated lexicon\nextraction method, and most lexicons are hand crafted, which is very\ninefficient for big data. What's more, there is no an effective way to use a\nlexicon in a neural network. To address those limitations, we propose a\nPre-Attention mechanism for text classification in this paper, which can learn\nattention of different words according to their effects in the classification\ntasks. The words with different attention can form a domain lexicon.\nExperiments on three benchmark text classification tasks show that our models\nget competitive result comparing with the state-of-the-art methods. We get\n90.5% accuracy on Stanford Large Movie Review dataset, 82.3% on Subjectivity\ndataset, 93.7% on Movie Reviews. And compared with the text classification\nmodel without Pre-Attention mechanism, those with Pre-Attention mechanism\nimprove by 0.9%-2.4% accuracy, which proves the validity of the Pre-Attention\nmechanism. In addition, the Pre-Attention mechanism performs well followed by\ndifferent types of neural networks (e.g., convolutional neural networks and\nLong Short-Term Memory networks). For the same dataset, when we use\nPre-Attention mechanism to get attention value followed by different neural\nnetworks, those words with high attention values have a high degree of\ncoincidence, which proves the versatility and portability of the Pre-Attention\nmechanism. we can get stable lexicons by attention values, which is an\ninspiring method of information extraction.", "published": "2020-02-18 14:40:20", "link": "http://arxiv.org/abs/2002.07591v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Decidability of cutpoint isolation for probabilistic finite automata on\n  letter-bounded inputs", "abstract": "We show the surprising result that the cutpoint isolation problem is\ndecidable for Probabilistic Finite Automata (PFA) where input words are taken\nfrom a letter-bounded context-free language. A context-free language\n$\\mathcal{L}$ is letter-bounded when $\\mathcal{L} \\subseteq a_1^*a_2^* \\cdots\na_\\ell^*$ for some finite $\\ell > 0$ where each letter is distinct. A cutpoint\nis isolated when it cannot be approached arbitrarily closely. The decidability\nof this problem is in marked contrast to the situation for the (strict)\nemptiness problem for PFA which is undecidable under the even more severe\nrestrictions of PFA with polynomial ambiguity, commutative matrices and input\nover a letter-bounded language as well as to the injectivity problem which is\nundecidable for PFA over letter-bounded languages. We provide a constructive\nnondeterministic algorithm to solve the cutpoint isolation problem, which holds\neven when the PFA is exponentially ambiguous. We also show that the problem is\nat least NP-hard and use our decision procedure to solve several related\nproblems.", "published": "2020-02-18 15:47:14", "link": "http://arxiv.org/abs/2002.07660v2", "categories": ["cs.FL", "cs.CL", "68Q45", "F.1.1; F.1.2"], "primary_category": "cs.FL"}
{"title": "Neural Relation Prediction for Simple Question Answering over Knowledge\n  Graph", "abstract": "Knowledge graphs are widely used as a typical resource to provide answers to\nfactoid questions. In simple question answering over knowledge graphs, relation\nextraction aims to predict the relation of a factoid question from a set of\npredefined relation types. Most recent methods take advantage of neural\nnetworks to match a question with all predefined relations. In this paper, we\npropose an instance-based method to capture the underlying relation of question\nand to this aim, we detect matching paraphrases of a new question which share\nthe same relation, and their corresponding relation is selected as our\nprediction. The idea of our model roots in the fact that a relation can be\nexpressed with various forms of questions while these forms share lexically or\nsemantically similar terms and concepts. Our experiments on the SimpleQuestions\ndataset show that the proposed model achieves better accuracy compared to the\nstate-of-the-art relation extraction models.", "published": "2020-02-18 16:41:24", "link": "http://arxiv.org/abs/2002.07715v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Gradient-Based Adversarial Training on Transformer Networks for\n  Detecting Check-Worthy Factual Claims", "abstract": "We present a study on the efficacy of adversarial training on transformer\nneural network models, with respect to the task of detecting check-worthy\nclaims. In this work, we introduce the first adversarially-regularized,\ntransformer-based claim spotter model that achieves state-of-the-art results on\nmultiple challenging benchmarks. We obtain a 4.70 point F1-score improvement\nover current state-of-the-art models on the ClaimBuster Dataset and CLEF2019\nDataset, respectively. In the process, we propose a method to apply adversarial\ntraining to transformer models, which has the potential to be generalized to\nmany similar text classification tasks. Along with our results, we are\nreleasing our codebase and manually labeled datasets. We also showcase our\nmodels' real world usage via a live public API.", "published": "2020-02-18 16:51:05", "link": "http://arxiv.org/abs/2002.07725v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Studying the Effects of Cognitive Biases in Evaluation of Conversational\n  Agents", "abstract": "Humans quite frequently interact with conversational agents. The rapid\nadvancement in generative language modeling through neural networks has helped\nadvance the creation of intelligent conversational agents. Researchers\ntypically evaluate the output of their models through crowdsourced judgments,\nbut there are no established best practices for conducting such studies.\nMoreover, it is unclear if cognitive biases in decision-making are affecting\ncrowdsourced workers' judgments when they undertake these tasks. To\ninvestigate, we conducted a between-subjects study with 77 crowdsourced workers\nto understand the role of cognitive biases, specifically anchoring bias, when\nhumans are asked to evaluate the output of conversational agents. Our results\nprovide insight into how best to evaluate conversational agents. We find\nincreased consistency in ratings across two experimental conditions may be a\nresult of anchoring bias. We also determine that external factors such as time\nand prior experience in similar tasks have effects on inter-rater consistency.", "published": "2020-02-18 23:52:39", "link": "http://arxiv.org/abs/2002.07927v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Assessing the Memory Ability of Recurrent Neural Networks", "abstract": "It is known that Recurrent Neural Networks (RNNs) can remember, in their\nhidden layers, part of the semantic information expressed by a sequence (e.g.,\na sentence) that is being processed. Different types of recurrent units have\nbeen designed to enable RNNs to remember information over longer time spans.\nHowever, the memory abilities of different recurrent units are still\ntheoretically and empirically unclear, thus limiting the development of more\neffective and explainable RNNs. To tackle the problem, in this paper, we\nidentify and analyze the internal and external factors that affect the memory\nability of RNNs, and propose a Semantic Euclidean Space to represent the\nsemantics expressed by a sequence. Based on the Semantic Euclidean Space, a\nseries of evaluation indicators are defined to measure the memory abilities of\ndifferent recurrent units and analyze their limitations. These evaluation\nindicators also provide a useful guidance to select suitable sequence lengths\nfor different RNNs during training.", "published": "2020-02-18 08:07:23", "link": "http://arxiv.org/abs/2002.07422v1", "categories": ["cs.LG", "cs.CL", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Hierarchical Transformer Network for Utterance-level Emotion Recognition", "abstract": "While there have been significant advances in de-tecting emotions in text, in\nthe field of utter-ance-level emotion recognition (ULER), there are still many\nproblems to be solved. In this paper, we address some challenges in ULER in\ndialog sys-tems. (1) The same utterance can deliver different emotions when it\nis in different contexts or from different speakers. (2) Long-range contextual\nin-formation is hard to effectively capture. (3) Unlike the traditional text\nclassification problem, this task is supported by a limited number of datasets,\namong which most contain inadequate conversa-tions or speech. To address these\nproblems, we propose a hierarchical transformer framework (apart from the\ndescription of other studies, the \"transformer\" in this paper usually refers to\nthe encoder part of the transformer) with a lower-level transformer to model\nthe word-level input and an upper-level transformer to capture the context of\nutterance-level embeddings. We use a pretrained language model bidirectional\nencoder representa-tions from transformers (BERT) as the lower-level\ntransformer, which is equivalent to introducing external data into the model\nand solve the problem of data shortage to some extent. In addition, we add\nspeaker embeddings to the model for the first time, which enables our model to\ncapture the in-teraction between speakers. Experiments on three dialog emotion\ndatasets, Friends, EmotionPush, and EmoryNLP, demonstrate that our proposed\nhierarchical transformer network models achieve 1.98%, 2.83%, and 3.94%\nimprovement, respec-tively, over the state-of-the-art methods on each dataset\nin terms of macro-F1.", "published": "2020-02-18 13:44:49", "link": "http://arxiv.org/abs/2002.07551v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "An enhanced Tree-LSTM architecture for sentence semantic modeling using\n  typed dependencies", "abstract": "Tree-based Long short term memory (LSTM) network has become state-of-the-art\nfor modeling the meaning of language texts as they can effectively exploit the\ngrammatical syntax and thereby non-linear dependencies among words of the\nsentence. However, most of these models cannot recognize the difference in\nmeaning caused by a change in semantic roles of words or phrases because they\ndo not acknowledge the type of grammatical relations, also known as typed\ndependencies, in sentence structure. This paper proposes an enhanced LSTM\narchitecture, called relation gated LSTM, which can model the relationship\nbetween two inputs of a sequence using a control input. We also introduce a\nTree-LSTM model called Typed Dependency Tree-LSTM that uses the sentence\ndependency parse structure as well as the dependency type to embed sentence\nmeaning into a dense vector. The proposed model outperformed its type-unaware\ncounterpart in two typical NLP tasks - Semantic Relatedness Scoring and\nSentiment Analysis, in a lesser number of training epochs. The results were\ncomparable or competitive with other state-of-the-art models. Qualitative\nanalysis showed that changes in the voice of sentences had little effect on the\nmodel's predicted scores, while changes in nominal (noun) words had a more\nsignificant impact. The model recognized subtle semantic relationships in\nsentence pairs. The magnitudes of learned typed dependencies embeddings were\nalso in agreement with human intuitions. The research findings imply the\nsignificance of grammatical relations in sentence modeling. The proposed models\nwould serve as a base for future researches in this direction.", "published": "2020-02-18 18:10:03", "link": "http://arxiv.org/abs/2002.07775v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "SentenceMIM: A Latent Variable Language Model", "abstract": "SentenceMIM is a probabilistic auto-encoder for language data, trained with\nMutual Information Machine (MIM) learning to provide a fixed length\nrepresentation of variable length language observations (i.e., similar to VAE).\nPrevious attempts to learn VAEs for language data faced challenges due to\nposterior collapse. MIM learning encourages high mutual information between\nobservations and latent variables, and is robust against posterior collapse. As\nsuch, it learns informative representations whose dimension can be an order of\nmagnitude higher than existing language VAEs. Importantly, the SentenceMIM loss\nhas no hyper-parameters, simplifying optimization. We compare sentenceMIM with\nVAE, and AE on multiple datasets. SentenceMIM yields excellent reconstruction,\ncomparable to AEs, with a rich structured latent space, comparable to VAEs. The\nstructured latent representation is demonstrated with interpolation between\nsentences of different lengths. We demonstrate the versatility of sentenceMIM\nby utilizing a trained model for question-answering and transfer learning,\nwithout fine-tuning, outperforming VAE and AE with similar architectures.", "published": "2020-02-18 15:34:29", "link": "http://arxiv.org/abs/2003.02645v5", "categories": ["cs.CL", "cs.LG", "stat.ML", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Investigating an approach for low resource language dataset creation,\n  curation and classification: Setswana and Sepedi", "abstract": "The recent advances in Natural Language Processing have been a boon for\nwell-represented languages in terms of available curated data and research\nresources. One of the challenges for low-resourced languages is clear\nguidelines on the collection, curation and preparation of datasets for\ndifferent use-cases. In this work, we take on the task of creation of two\ndatasets that are focused on news headlines (i.e short text) for Setswana and\nSepedi and creation of a news topic classification task. We document our work\nand also present baselines for classification. We investigate an approach on\ndata augmentation, better suited to low resource languages, to improve the\nperformance of the classifiers", "published": "2020-02-18 13:58:06", "link": "http://arxiv.org/abs/2003.04986v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Multitask Learning with Capsule Networks for Speech-to-Intent\n  Applications", "abstract": "Voice controlled applications can be a great aid to society, especially for\nphysically challenged people. However this requires robustness to all kinds of\nvariations in speech. A spoken language understanding system that learns from\ninteraction with and demonstrations from the user, allows the use of such a\nsystem in different settings and for different types of speech, even for\ndeviant or impaired speech, while also allowing the user to choose a phrasing.\nThe user gives a command and enters its intent through an interface, after\nwhich the model learns to map the speech directly to the right action. Since\nthe effort of the user should be as low as possible, capsule networks have\ndrawn interest due to potentially needing little training data compared to\ndeeper neural networks. In this paper, we show how capsules can incorporate\nmultitask learning, which often can improve the performance of a model when the\ntask is difficult. The basic capsule network will be expanded with a\nregularisation to create more structure in its output: it learns to identify\nthe speaker of the utterance by forcing the required information into the\ncapsule vectors. To this end we move from a speaker dependent to a speaker\nindependent setting.", "published": "2020-02-18 09:43:54", "link": "http://arxiv.org/abs/2002.07450v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Workshop Report: Detection and Classification in Marine Bioacoustics\n  with Deep Learning", "abstract": "On 21-22 November 2019, about 30 researchers gathered in Victoria, BC,\nCanada, for the workshop \"Detection and Classification in Marine Bioacoustics\nwith Deep Learning\" organized by MERIDIAN and hosted by Ocean Networks Canada.\nThe workshop was attended by marine biologists, data scientists, and computer\nscientists coming from both Canadian coasts and the US and representing a wide\nspectrum of research organizations including universities, government\n(Fisheries and Oceans Canada, National Oceanic and Atmospheric Administration),\nindustry (JASCO Applied Sciences, Google, Axiom Data Science), and\nnon-for-profits (Orcasound, OrcaLab). Consisting of a mix of oral\npresentations, open discussion sessions, and hands-on tutorials, the workshop\nprogram offered a rare opportunity for specialists from distinctly different\ndomains to engage in conversation about deep learning and its promising\npotential for the development of detection and classification algorithms in\nunderwater acoustics. In this workshop report, we summarize key points from the\npresentations and discussion sessions.", "published": "2020-02-18 15:33:06", "link": "http://arxiv.org/abs/2002.08249v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
