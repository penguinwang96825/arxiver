{"title": "Automated Word Prediction in Bangla Language Using Stochastic Language\n  Models", "abstract": "Word completion and word prediction are two important phenomena in typing\nthat benefit users who type using keyboard or other similar devices. They can\nhave profound impact on the typing of disable people. Our work is based on word\nprediction on Bangla sentence by using stochastic, i.e. N-gram language model\nsuch as unigram, bigram, trigram, deleted Interpolation and backoff models for\nauto completing a sentence by predicting a correct word in a sentence which\nsaves time and keystrokes of typing and also reduces misspelling. We use large\ndata corpus of Bangla language of different word types to predict correct word\nwith the accuracy as much as possible. We have found promising results. We hope\nthat our work will impact on the baseline for automated Bangla typing.", "published": "2016-02-25 05:35:16", "link": "http://arxiv.org/abs/1602.07803v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recurrent Neural Network Grammars", "abstract": "We introduce recurrent neural network grammars, probabilistic models of\nsentences with explicit phrase structure. We explain efficient inference\nprocedures that allow application to both parsing and language modeling.\nExperiments show that they provide better parsing in English than any single\npreviously published supervised generative model and better language modeling\nthan state-of-the-art sequential RNNs in English and Chinese.", "published": "2016-02-25 02:42:58", "link": "http://arxiv.org/abs/1602.07776v4", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Data Cleaning for XML Electronic Dictionaries via Statistical Anomaly\n  Detection", "abstract": "Many important forms of data are stored digitally in XML format. Errors can\noccur in the textual content of the data in the fields of the XML. Fixing these\nerrors manually is time-consuming and expensive, especially for large amounts\nof data. There is increasing interest in the research, development, and use of\nautomated techniques for assisting with data cleaning. Electronic dictionaries\nare an important form of data frequently stored in XML format that frequently\nhave errors introduced through a mixture of manual typographical entry errors\nand optical character recognition errors. In this paper we describe methods for\nflagging statistical anomalies as likely errors in electronic dictionaries\nstored in XML format. We describe six systems based on different sources of\ninformation. The systems detect errors using various signals in the data\nincluding uncommon characters, text length, character-based language models,\nword-based language models, tied-field length ratios, and tied-field\ntransliteration models. Four of the systems detect errors based on expectations\nautomatically inferred from content within elements of a single field type. We\ncall these single-field systems. Two of the systems detect errors based on\ncorrespondence expectations automatically inferred from content within elements\nof multiple related field types. We call these tied-field systems. For each\nsystem, we provide an intuitive analysis of the type of error that it is\nsuccessful at detecting. Finally, we describe two larger-scale evaluations\nusing crowdsourcing with Amazon's Mechanical Turk platform and using the\nannotations of a domain expert. The evaluations consistently show that the\nsystems are useful for improving the efficiency with which errors in XML\nelectronic dictionaries can be detected.", "published": "2016-02-25 05:49:36", "link": "http://arxiv.org/abs/1602.07807v2", "categories": ["cs.DB", "cs.CL", "stat.ML", "I.5.1; I.5.4; G.3; I.2.7; I.2.6"], "primary_category": "cs.DB"}
{"title": "PCA Method for Automated Detection of Mispronounced Words", "abstract": "This paper presents a method for detecting mispronunciations with the aim of\nimproving Computer Assisted Language Learning (CALL) tools used by foreign\nlanguage learners. The algorithm is based on Principle Component Analysis\n(PCA). It is hierarchical with each successive step refining the estimate to\nclassify the test word as being either mispronounced or correct. Preprocessing\nbefore detection, like normalization and time-scale modification, is\nimplemented to guarantee uniformity of the feature vectors input to the\ndetection system. The performance using various features including spectrograms\nand Mel-Frequency Cepstral Coefficients (MFCCs) are compared and evaluated.\nBest results were obtained using MFCCs, achieving up to 99% accuracy in word\nverification and 93% in native/non-native classification. Compared with Hidden\nMarkov Models (HMMs) which are used pervasively in recognition application,\nthis particular approach is computational efficient and effective when training\ndata is limited.", "published": "2016-02-25 21:48:56", "link": "http://arxiv.org/abs/1602.08128v1", "categories": ["cs.SD", "cs.CL", "cs.LG"], "primary_category": "cs.SD"}
