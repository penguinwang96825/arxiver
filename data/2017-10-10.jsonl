{"title": "MoNoise: Modeling Noise Using a Modular Normalization System", "abstract": "We propose MoNoise: a normalization model focused on generalizability and\nefficiency, it aims at being easily reusable and adaptable. Normalization is\nthe task of translating texts from a non- canonical domain to a more canonical\ndomain, in our case: from social media data to standard language. Our proposed\nmodel is based on a modular candidate generation in which each module is\nresponsible for a different type of normalization action. The most important\ngeneration modules are a spelling correction system and a word embeddings\nmodule. Depending on the definition of the normalization task, a static lookup\nlist can be crucial for performance. We train a random forest classifier to\nrank the candidates, which generalizes well to all different types of\nnormaliza- tion actions. Most features for the ranking originate from the\ngeneration modules; besides these features, N-gram features prove to be an\nimportant source of information. We show that MoNoise beats the\nstate-of-the-art on different normalization benchmarks for English and Dutch,\nwhich all define the task of normalization slightly different.", "published": "2017-10-10 09:41:46", "link": "http://arxiv.org/abs/1710.03476v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Very Low Resource Language Speech Corpus for Computational Language\n  Documentation Experiments", "abstract": "Most speech and language technologies are trained with massive amounts of\nspeech and text information. However, most of the world languages do not have\nsuch resources or stable orthography. Systems constructed under these almost\nzero resource conditions are not only promising for speech technology but also\nfor computational language documentation. The goal of computational language\ndocumentation is to help field linguists to (semi-)automatically analyze and\nannotate audio recordings of endangered and unwritten languages. Example tasks\nare automatic phoneme discovery or lexicon discovery from the speech signal.\nThis paper presents a speech corpus collected during a realistic language\ndocumentation process. It is made up of 5k speech utterances in Mboshi (Bantu\nC25) aligned to French text translations. Speech transcriptions are also made\navailable: they correspond to a non-standard graphemic form close to the\nlanguage phonology. We present how the data was collected, cleaned and\nprocessed and we illustrate its use through a zero-resource task: spoken term\ndiscovery. The dataset is made available to the community for reproducible\ncomputational language documentation experiments and their evaluation.", "published": "2017-10-10 10:39:20", "link": "http://arxiv.org/abs/1710.03501v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Confidence through Attention", "abstract": "Attention distributions of the generated translations are a useful bi-product\nof attention-based recurrent neural network translation models and can be\ntreated as soft alignments between the input and output tokens. In this work,\nwe use attention distributions as a confidence metric for output translations.\nWe present two strategies of using the attention distributions: filtering out\nbad translations from a large back-translated corpus, and selecting the best\ntranslation in a hybrid setup of two different translation systems. While\nmanual evaluation indicated only a weak correlation between our confidence\nscore and human judgments, the use-cases showed improvements of up to 2.22 BLEU\npoints for filtering and 0.99 points for hybrid translation, tested on\nEnglish<->German and English<->Latvian translation.", "published": "2017-10-10 17:47:41", "link": "http://arxiv.org/abs/1710.03743v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Galactic Dependencies Treebanks: Getting More Data by Synthesizing\n  New Languages", "abstract": "We release Galactic Dependencies 1.0---a large set of synthetic languages not\nfound on Earth, but annotated in Universal Dependencies format. This new\nresource aims to provide training and development data for NLP methods that aim\nto adapt to unfamiliar languages. Each synthetic treebank is produced from a\nreal treebank by stochastically permuting the dependents of nouns and/or verbs\nto match the word order of other real languages. We discuss the usefulness,\nrealism, parsability, perplexity, and diversity of the synthetic languages. As\na simple demonstration of the use of Galactic Dependencies, we consider\nsingle-source transfer, which attempts to parse a real target language using a\nparser trained on a \"nearby\" source language. We find that including synthetic\nsource languages somewhat increases the diversity of the source pool, which\nsignificantly improves results for most target languages.", "published": "2017-10-10 22:12:46", "link": "http://arxiv.org/abs/1710.03838v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Rank Question-Answer Pairs using Hierarchical Recurrent\n  Encoder with Latent Topic Clustering", "abstract": "In this paper, we propose a novel end-to-end neural architecture for ranking\ncandidate answers, that adapts a hierarchical recurrent neural network and a\nlatent topic clustering module. With our proposed model, a text is encoded to a\nvector representation from an word-level to a chunk-level to effectively\ncapture the entire meaning. In particular, by adapting the hierarchical\nstructure, our model shows very small performance degradations in longer text\ncomprehension while other state-of-the-art recurrent neural network models\nsuffer from it. Additionally, the latent topic clustering module extracts\nsemantic information from target samples. This clustering module is useful for\nany text related tasks by allowing each data sample to find its nearest topic\ncluster, thus helping the neural network model analyze the entire data. We\nevaluate our models on the Ubuntu Dialogue Corpus and consumer electronic\ndomain question answering dataset, which is related to Samsung products. The\nproposed model shows state-of-the-art results for ranking question-answer\npairs.", "published": "2017-10-10 07:26:50", "link": "http://arxiv.org/abs/1710.03430v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Contaminated speech training methods for robust DNN-HMM distant speech\n  recognition", "abstract": "Despite the significant progress made in the last years, state-of-the-art\nspeech recognition technologies provide a satisfactory performance only in the\nclose-talking condition. Robustness of distant speech recognition in adverse\nacoustic conditions, on the other hand, remains a crucial open issue for future\napplications of human-machine interaction. To this end, several advances in\nspeech enhancement, acoustic scene analysis as well as acoustic modeling, have\nrecently contributed to improve the state-of-the-art in the field. One of the\nmost effective approaches to derive a robust acoustic modeling is based on\nusing contaminated speech, which proved helpful in reducing the acoustic\nmismatch between training and testing conditions.\n  In this paper, we revise this classical approach in the context of modern\nDNN-HMM systems, and propose the adoption of three methods, namely, asymmetric\ncontext windowing, close-talk based supervision, and close-talk based\npre-training. The experimental results, obtained using both real and simulated\ndata, show a significant advantage in using these three methods, overall\nproviding a 15% error rate reduction compared to the baseline systems. The same\ntrend in performance is confirmed either using a high-quality training set of\nsmall size, and a large one.", "published": "2017-10-10 12:36:45", "link": "http://arxiv.org/abs/1710.03538v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
