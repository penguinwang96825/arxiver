{"title": "LEWIS: Levenshtein Editing for Unsupervised Text Style Transfer", "abstract": "Many types of text style transfer can be achieved with only small, precise\nedits (e.g. sentiment transfer from I had a terrible time... to I had a great\ntime...). We propose a coarse-to-fine editor for style transfer that transforms\ntext using Levenshtein edit operations (e.g. insert, replace, delete). Unlike\nprior single-span edit methods, our method concurrently edits multiple spans in\nthe source text. To train without parallel style text pairs (e.g. pairs of +/-\nsentiment statements), we propose an unsupervised data synthesis procedure. We\nfirst convert text to style-agnostic templates using style classifier attention\n(e.g. I had a SLOT time...), then fill in slots in these templates using\nfine-tuned pretrained language models. Our method outperforms existing\ngeneration and editing style transfer methods on sentiment (Yelp, Amazon) and\npoliteness (Polite) transfer. In particular, multi-span editing achieves higher\nperformance and more diverse output than single-span editing. Moreover,\ncompared to previous methods on unsupervised data synthesis, our method results\nin higher quality parallel style pairs and improves model performance.", "published": "2021-05-18 00:08:30", "link": "http://arxiv.org/abs/2105.08206v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BookSum: A Collection of Datasets for Long-form Narrative Summarization", "abstract": "The majority of available text summarization datasets include short-form\nsource documents that lack long-range causal and temporal dependencies, and\noften contain strong layout and stylistic biases. While relevant, such datasets\nwill offer limited challenges for future generations of text summarization\nsystems. We address these issues by introducing BookSum, a collection of\ndatasets for long-form narrative summarization. Our dataset covers source\ndocuments from the literature domain, such as novels, plays and stories, and\nincludes highly abstractive, human written summaries on three levels of\ngranularity of increasing difficulty: paragraph-, chapter-, and book-level. The\ndomain and structure of our dataset poses a unique set of challenges for\nsummarization systems, which include: processing very long documents,\nnon-trivial causal and temporal dependencies, and rich discourse structures. To\nfacilitate future work, we trained and evaluated multiple extractive and\nabstractive summarization models as baselines for our dataset.", "published": "2021-05-18 00:22:46", "link": "http://arxiv.org/abs/2105.08209v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distantly Supervised Relation Extraction via Recursive\n  Hierarchy-Interactive Attention and Entity-Order Perception", "abstract": "Wrong-labeling problem and long-tail relations severely affect the\nperformance of distantly supervised relation extraction task. Many studies\nmitigate the effect of wrong-labeling through selective attention mechanism and\nhandle long-tail relations by introducing relation hierarchies to share\nknowledge. However, almost all existing studies ignore the fact that, in a\nsentence, the appearance order of two entities contributes to the understanding\nof its semantics. Furthermore, they only utilize each relation level of\nrelation hierarchies separately, but do not exploit the heuristic effect\nbetween relation levels, i.e., higher-level relations can give useful\ninformation to the lower ones. Based on the above, in this paper, we design a\nnovel Recursive Hierarchy-Interactive Attention network (RHIA) to further\nhandle long-tail relations, which models the heuristic effect between relation\nlevels. From the top down, it passes relation-related information layer by\nlayer, which is the most significant difference from existing models, and\ngenerates relation-augmented sentence representations for each relation level\nin a recursive structure. Besides, we introduce a newfangled training\nobjective, called Entity-Order Perception (EOP), to make the sentence encoder\nretain more entity appearance information. Substantial experiments on the\npopular (NYT) dataset are conducted. Compared to prior baselines, our RHIA-EOP\nachieves state-of-the-art performance in terms of precision-recall (P-R)\ncurves, AUC, Top-N precision and other evaluation metrics. Insightful analysis\nalso demonstrates the necessity and effectiveness of each component of\nRHIA-EOP.", "published": "2021-05-18 00:45:25", "link": "http://arxiv.org/abs/2105.08213v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Annotated Commodity News Corpus for Event Extraction", "abstract": "Commodity News contains a wealth of information such as sum-mary of the\nrecent commodity price movement and notable events that led tothe movement.\nThrough event extraction, useful information extracted fromcommodity news is\nextremely useful in mining for causal relation betweenevents and commodity\nprice movement, which can be used for commodity priceprediction. To facilitate\nthe future research, we introduce a new dataset withthe following information\nidentified and annotated: (i) entities (both nomi-nal and named), (ii) events\n(trigger words and argument roles), (iii) eventmetadata: modality, polarity and\nintensity and (iv) event-event relations.", "published": "2021-05-18 00:52:47", "link": "http://arxiv.org/abs/2105.08214v3", "categories": ["cs.CL", "68T99", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Emotion Eliciting Machine: Emotion Eliciting Conversation Generation\n  based on Dual Generator", "abstract": "Recent years have witnessed great progress on building emotional chatbots.\nTremendous methods have been proposed for chatbots to generate responses with\ngiven emotions. However, the emotion changes of the user during the\nconversation has not been fully explored. In this work, we study the problem of\npositive emotion elicitation, which aims to generate responses that can elicit\npositive emotion of the user, in human-machine conversation. We propose a\nweakly supervised Emotion Eliciting Machine (EEM) to address this problem.\nSpecifically, we first collect weak labels of user emotion status changes in a\nconversion based on a pre-trained emotion classifier. Then we propose a dual\nencoder-decoder structure to model the generation of responses in both positive\nand negative side based on the changes of the user's emotion status in the\nconversation. An emotion eliciting factor is introduced on top of the dual\nstructure to balance the positive and negative emotional impacts on the\ngenerated response during emotion elicitation. The factor also provides a\nfine-grained controlling manner for emotion elicitation. Experimental results\non a large real-world dataset show that EEM outperforms the existing models in\ngenerating responses with positive emotion elicitation.", "published": "2021-05-18 03:19:25", "link": "http://arxiv.org/abs/2105.08251v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KECRS: Towards Knowledge-Enriched Conversational Recommendation System", "abstract": "The chit-chat-based conversational recommendation systems (CRS) provide item\nrecommendations to users through natural language interactions. To better\nunderstand user's intentions, external knowledge graphs (KG) have been\nintroduced into chit-chat-based CRS. However, existing chit-chat-based CRS\nusually generate repetitive item recommendations, and they cannot properly\ninfuse knowledge from KG into CRS to generate informative responses. To remedy\nthese issues, we first reformulate the conversational recommendation task to\nhighlight that the recommended items should be new and possibly interested by\nusers. Then, we propose the Knowledge-Enriched Conversational Recommendation\nSystem (KECRS). Specifically, we develop the Bag-of-Entity (BOE) loss and the\ninfusion loss to better integrate KG with CRS for generating more diverse and\ninformative responses. BOE loss provides an additional supervision signal to\nguide CRS to learn from both human-written utterances and KG. Infusion loss\nbridges the gap between the word embeddings and entity embeddings by minimizing\ndistances of the same words in these two embeddings. Moreover, we facilitate\nour study by constructing a high-quality KG, \\ie The Movie Domain Knowledge\nGraph (TMDKG). Experimental results on a large-scale dataset demonstrate that\nKECRS outperforms state-of-the-art chit-chat-based CRS, in terms of both\nrecommendation accuracy and response generation quality.", "published": "2021-05-18 03:52:06", "link": "http://arxiv.org/abs/2105.08261v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoMAE: A Multi-factor Hierarchical Framework for Empathetic Response\n  Generation", "abstract": "The capacity of empathy is crucial to the success of open-domain dialog\nsystems. Due to its nature of multi-dimensionality, there are various factors\nthat relate to empathy expression, such as communication mechanism, dialog act\nand emotion. However, existing methods for empathetic response generation\nusually either consider only one empathy factor or ignore the hierarchical\nrelationships between different factors, leading to a weak ability of empathy\nmodeling. In this paper, we propose a multi-factor hierarchical framework,\nCoMAE, for empathetic response generation, which models the above three key\nfactors of empathy expression in a hierarchical way. We show experimentally\nthat our CoMAE-based model can generate more empathetic responses than previous\nmethods. We also highlight the importance of hierarchical modeling of different\nfactors through both the empirical analysis on a real-life corpus and the\nextensive experiments. Our codes and used data are available at\nhttps://github.com/chujiezheng/CoMAE.", "published": "2021-05-18 07:13:33", "link": "http://arxiv.org/abs/2105.08316v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relation Classification with Entity Type Restriction", "abstract": "Relation classification aims to predict a relation between two entities in a\nsentence. The existing methods regard all relations as the candidate relations\nfor the two entities in a sentence. These methods neglect the restrictions on\ncandidate relations by entity types, which leads to some inappropriate\nrelations being candidate relations. In this paper, we propose a novel\nparadigm, RElation Classification with ENtity Type restriction (RECENT), which\nexploits entity types to restrict candidate relations. Specially, the mutual\nrestrictions of relations and entity types are formalized and introduced into\nrelation classification. Besides, the proposed paradigm, RECENT, is\nmodel-agnostic. Based on two representative models GCN and SpanBERT\nrespectively, RECENT_GCN and RECENT_SpanBERT are trained in RECENT.\nExperimental results on a standard dataset indicate that RECENT improves the\nperformance of GCN and SpanBERT by 6.9 and 4.4 F1 points, respectively.\nEspecially, RECENT_SpanBERT achieves a new state-of-the-art on TACRED.", "published": "2021-05-18 09:42:40", "link": "http://arxiv.org/abs/2105.08393v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DRILL: Dynamic Representations for Imbalanced Lifelong Learning", "abstract": "Continual or lifelong learning has been a long-standing challenge in machine\nlearning to date, especially in natural language processing (NLP). Although\nstate-of-the-art language models such as BERT have ushered in a new era in this\nfield due to their outstanding performance in multitask learning scenarios,\nthey suffer from forgetting when being exposed to a continuous stream of data\nwith shifting data distributions. In this paper, we introduce DRILL, a novel\ncontinual learning architecture for open-domain text classification. DRILL\nleverages a biologically inspired self-organizing neural architecture to\nselectively gate latent language representations from BERT in a\ntask-incremental manner. We demonstrate in our experiments that DRILL\noutperforms current methods in a realistic scenario of imbalanced,\nnon-stationary data without prior knowledge about task boundaries. To the best\nof our knowledge, DRILL is the first of its kind to use a self-organizing\nneural architecture for open-domain lifelong learning in NLP.", "published": "2021-05-18 11:36:37", "link": "http://arxiv.org/abs/2105.08445v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting Additive Compositionality: AND, OR and NOT Operations with\n  Word Embeddings", "abstract": "It is well-known that typical word embedding methods such as Word2Vec and\nGloVe have the property that the meaning can be composed by adding up the\nembeddings (additive compositionality). Several theories have been proposed to\nexplain additive compositionality, but the following questions remain\nunanswered: (Q1) The assumptions of those theories do not hold for the\npractical word embedding. (Q2) Ordinary additive compositionality can be seen\nas an AND operation of word meanings, but it is not well understood how other\noperations, such as OR and NOT, can be computed by the embeddings. We address\nthese issues by the idea of frequency-weighted centering at its core. This\npaper proposes a post-processing method for bridging the gap between practical\nword embedding and the assumption of theory about additive compositionality as\nan answer to (Q1). It also gives a method for taking OR or NOT of the meaning\nby linear operation of word embedding as an answer to (Q2). Moreover, we\nconfirm experimentally that the accuracy of AND operation, i.e., the ordinary\nadditive compositionality, can be improved by our post-processing method (3.5x\nimprovement in top-100 accuracy) and that OR and NOT operations can be\nperformed correctly.", "published": "2021-05-18 15:13:04", "link": "http://arxiv.org/abs/2105.08585v2", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "Self-interpretable Convolutional Neural Networks for Text Classification", "abstract": "Deep learning models for natural language processing (NLP) are inherently\ncomplex and often viewed as black box in nature. This paper develops an\napproach for interpreting convolutional neural networks for text classification\nproblems by exploiting the local-linear models inherent in ReLU-DNNs. The CNN\nmodel combines the word embedding through convolutional layers, filters them\nusing max-pooling, and optimizes using a ReLU-DNN for classification. To get an\noverall self-interpretable model, the system of local linear models from the\nReLU DNN are mapped back through the max-pool filter to the appropriate\nn-grams. Our results on experimental datasets demonstrate that our proposed\ntechnique produce parsimonious models that are self-interpretable and have\ncomparable performance with respect to a more complex CNN model. We also study\nthe impact of the complexity of the convolutional layers and the classification\nlayers on the model performance.", "published": "2021-05-18 15:19:59", "link": "http://arxiv.org/abs/2105.08589v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LCP-RIT at SemEval-2021 Task 1: Exploring Linguistic Features for\n  Lexical Complexity Prediction", "abstract": "This paper describes team LCP-RIT's submission to the SemEval-2021 Task 1:\nLexical Complexity Prediction (LCP). The task organizers provided participants\nwith an augmented version of CompLex (Shardlow et al., 2020), an English\nmulti-domain dataset in which words in context were annotated with respect to\ntheir complexity using a five point Likert scale. Our system uses logistic\nregression and a wide range of linguistic features (e.g. psycholinguistic\nfeatures, n-grams, word frequency, POS tags) to predict the complexity of\nsingle words in this dataset. We analyze the impact of different linguistic\nfeatures in the classification performance and we evaluate the results in terms\nof mean absolute error, mean squared error, Pearson correlation, and Spearman\ncorrelation.", "published": "2021-05-18 18:55:04", "link": "http://arxiv.org/abs/2105.08780v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Text-to-Text Transformers for English to Hinglish Machine\n  Translation with Synthetic Code-Mixing", "abstract": "We describe models focused at the understudied problem of translating between\nmonolingual and code-mixed language pairs. More specifically, we offer a wide\nrange of models that convert monolingual English text into Hinglish (code-mixed\nHindi and English). Given the recent success of pretrained language models, we\nalso test the utility of two recent Transformer-based encoder-decoder models\n(i.e., mT5 and mBART) on the task finding both to work well. Given the paucity\nof training data for code-mixing, we also propose a dependency-free method for\ngenerating code-mixed texts from bilingual distributed representations that we\nexploit for improving language model performance. In particular, armed with\nthis additional data, we adopt a curriculum learning approach where we first\nfinetune the language models on synthetic data then on gold code-mixed data. We\nfind that, although simple, our synthetic code-mixing method is competitive\nwith (and in some cases is even superior to) several standard methods\n(backtranslation, method based on equivalence constraint theory) under a\ndiverse set of conditions. Our work shows that the mT5 model, finetuned\nfollowing the curriculum learning procedure, achieves best translation\nperformance (12.67 BLEU). Our models place first in the overall ranking of the\nEnglish-Hinglish official shared task.", "published": "2021-05-18 19:50:25", "link": "http://arxiv.org/abs/2105.08807v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Effective Attention Sheds Light On Interpretability", "abstract": "An attention matrix of a transformer self-attention sublayer can provably be\ndecomposed into two components and only one of them (effective attention)\ncontributes to the model output. This leads us to ask whether visualizing\neffective attention gives different conclusions than interpretation of standard\nattention. Using a subset of the GLUE tasks and BERT, we carry out an analysis\nto compare the two attention matrices, and show that their interpretations\ndiffer. Effective attention is less associated with the features related to the\nlanguage modeling pretraining such as the separator token, and it has more\npotential to illustrate linguistic features captured by the model for solving\nthe end-task. Given the found differences, we recommend using effective\nattention for studying a transformer's behavior since it is more pertinent to\nthe model output by design.", "published": "2021-05-18 23:41:26", "link": "http://arxiv.org/abs/2105.08855v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Wizard of Search Engine: Access to Information Through Conversations\n  with Search Engines", "abstract": "Conversational information seeking (CIS) is playing an increasingly important\nrole in connecting people to information. Due to the lack of suitable resource,\nprevious studies on CIS are limited to the study of theoretical/conceptual\nframeworks, laboratory-based user studies, or a particular aspect of CIS (e.g.,\nasking clarifying questions). In this work, we make efforts to facilitate\nresearch on CIS from three aspects. (1) We formulate a pipeline for CIS with\nsix sub-tasks: intent detection (ID), keyphrase extraction (KE), action\nprediction (AP), query selection (QS), passage selection (PS), and response\ngeneration (RG). (2) We release a benchmark dataset, called wizard of search\nengine (WISE), which allows for comprehensive and in-depth research on all\naspects of CIS. (3) We design a neural architecture capable of training and\nevaluating both jointly and separately on the six sub-tasks, and devise a\npre-train/fine-tune learning scheme, that can reduce the requirements of WISE\nin scale by making full use of available data. We report some useful\ncharacteristics of CIS based on statistics of WISE. We also show that our best\nperforming model variant isable to achieve effective CIS as indicated by\nseveral metrics. We release the dataset, the code, as well as the evaluation\nscripts to facilitate future research by measuring further improvements in this\nimportant research direction.", "published": "2021-05-18 06:35:36", "link": "http://arxiv.org/abs/2105.08301v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Divided We Rule: Influencer Polarization on Twitter During Political\n  Crises in India", "abstract": "Influencers are key to the nature and networks of information propagation on\nsocial media. Influencers are particularly important in political discourse\nthrough their engagement with issues, and may derive their legitimacy either\nsolely or in large part through online operation, or have an offline sphere of\nexpertise such as entertainers, journalists etc. To quantify influencers'\npolitical engagement and polarity, we use Google's Universal Sentence Encoder\n(USE) to encode the tweets of 6k influencers and 26k Indian politicians during\npolitical crises in India. We then obtain aggregate vector representations of\nthe influencers based on their tweet embeddings, which alongside retweet graphs\nhelp compute their stance and polarity with respect to these political issues.\nWe find that influencers engage with the topics in a partisan manner, with\npolarized influencers being rewarded with increased retweeting and following.\nMoreover, we observe that specific groups of influencers are consistently\npolarized across all events. We conclude by discussing how our study provides\ninsights into the political schisms of present-day India, but also offers a\nmeans to study the role of influencers in exacerbating political polarization\nin other contexts.", "published": "2021-05-18 08:38:16", "link": "http://arxiv.org/abs/2105.08361v2", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Parallel Attention Network with Sequence Matching for Video Grounding", "abstract": "Given a video, video grounding aims to retrieve a temporal moment that\nsemantically corresponds to a language query. In this work, we propose a\nParallel Attention Network with Sequence matching (SeqPAN) to address the\nchallenges in this task: multi-modal representation learning, and target moment\nboundary prediction. We design a self-guided parallel attention module to\neffectively capture self-modal contexts and cross-modal attentive information\nbetween video and text. Inspired by sequence labeling tasks in natural language\nprocessing, we split the ground truth moment into begin, inside, and end\nregions. We then propose a sequence matching strategy to guide start/end\nboundary predictions using region labels. Experimental results on three\ndatasets show that SeqPAN is superior to state-of-the-art methods. Furthermore,\nthe effectiveness of the self-guided parallel attention module and the sequence\nmatching module is verified.", "published": "2021-05-18 12:43:20", "link": "http://arxiv.org/abs/2105.08481v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Understanding the Properties of Minimum Bayes Risk Decoding in Neural\n  Machine Translation", "abstract": "Neural Machine Translation (NMT) currently exhibits biases such as producing\ntranslations that are too short and overgenerating frequent words, and shows\npoor robustness to copy noise in training data or domain shift. Recent work has\ntied these shortcomings to beam search -- the de facto standard inference\nalgorithm in NMT -- and Eikema & Aziz (2020) propose to use Minimum Bayes Risk\n(MBR) decoding on unbiased samples instead.\n  In this paper, we empirically investigate the properties of MBR decoding on a\nnumber of previously reported biases and failure cases of beam search. We find\nthat MBR still exhibits a length and token frequency bias, owing to the MT\nmetrics used as utility functions, but that MBR also increases robustness\nagainst copy noise in the training data and domain shift.", "published": "2021-05-18 13:31:05", "link": "http://arxiv.org/abs/2105.08504v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improved Ackermannian lower bound for the Petri nets reachability\n  problem", "abstract": "Petri nets, equivalently presentable as vector addition systems with states,\nare an established model of concurrency with widespread applications. The\nreachability problem, where we ask whether from a given initial configuration\nthere exists a sequence of valid execution steps reaching a given final\nconfiguration, is the central algorithmic problem for this model. The\ncomplexity of the problem has remained, until recently, one of the hardest open\nquestions in verification of concurrent systems. A first upper bound has been\nprovided only in 2015 by Leroux and Schmitz, then refined by the same authors\nto non-primitive recursive Ackermannian upper bound in 2019. The exponential\nspace lower bound, shown by Lipton already in 1976, remained the only known for\nover 40 years until a breakthrough non-elementary lower bound by\nCzerwi{\\'n}ski, Lasota, Lazic, Leroux and Mazowiecki in 2019. Finally, a\nmatching Ackermannian lower bound announced this year by Czerwi{\\'n}ski and\nOrlikowski, and independently by Leroux, established the complexity of the\nproblem.\n  Our primary contribution is an improvement of the former construction, making\nit conceptually simpler and more direct. On the way we improve the lower bound\nfor vector addition systems with states in fixed dimension (or, equivalently,\nPetri nets with fixed number of places): while Czerwi{\\'n}ski and Orlikowski\nprove $F_k$-hardness (hardness for $k$th level in Grzegorczyk Hierarchy) in\ndimension $6k$, our simplified construction yields $F_k$-hardness already in\ndimension $3k+2$.", "published": "2021-05-18 14:36:25", "link": "http://arxiv.org/abs/2105.08551v4", "categories": ["cs.FL", "cs.CL"], "primary_category": "cs.FL"}
{"title": "Query Interpretations from Entity-Linked Segmentations", "abstract": "Web search queries can be ambiguous: is \"source of the nile\" meant to find\ninformation on the actual river or on a board game of that name? We tackle this\nproblem by deriving entity-based query interpretations: given some query, the\ntask is to derive all reasonable ways of linking suitable parts of the query to\nsemantically compatible entities in a background knowledge base. Our suggested\napproach focuses on effectiveness but also on efficiency since web search\nresponse times should not exceed some hundreds of milliseconds. In our\napproach, we use query segmentation as a pre-processing step that finds\npromising segment-based \"interpretation skeletons\". The individual segments\nfrom these skeletons are then linked to entities from a knowledge base and the\nreasonable combinations are ranked in a final step. An experimental comparison\non a combined corpus of all existing query entity linking datasets shows our\napproach to have a better interpretation accuracy at a better run time than the\npreviously most effective methods.", "published": "2021-05-18 15:07:51", "link": "http://arxiv.org/abs/2105.08581v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "WOVe: Incorporating Word Order in GloVe Word Embeddings", "abstract": "Word vector representations open up new opportunities to extract useful\ninformation from unstructured text. Defining a word as a vector made it easy\nfor the machine learning algorithms to understand a text and extract\ninformation from. Word vector representations have been used in many\napplications such word synonyms, word analogy, syntactic parsing, and many\nothers. GloVe, based on word contexts and matrix vectorization, is an\nef-fective vector-learning algorithm. It improves on previous vector-learning\nalgorithms. However, the GloVe model fails to explicitly consider the order in\nwhich words appear within their contexts. In this paper, multiple methods of\nincorporating word order in GloVe word embeddings are proposed. Experimental\nresults show that our Word Order Vector (WOVe) word embeddings approach\noutperforms unmodified GloVe on the natural lan-guage tasks of analogy\ncompletion and word similarity. WOVe with direct concatenation slightly\noutperformed GloVe on the word similarity task, increasing average rank by 2%.\nHowever, it greatly improved on the GloVe baseline on a word analogy task,\nachieving an average 36.34% improvement in accuracy.", "published": "2021-05-18 15:28:20", "link": "http://arxiv.org/abs/2105.08597v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Stylized Story Generation with Style-Guided Planning", "abstract": "Current storytelling systems focus more ongenerating stories with coherent\nplots regard-less of the narration style, which is impor-tant for controllable\ntext generation. There-fore, we propose a new task, stylized story gen-eration,\nnamely generating stories with speci-fied style given a leading context. To\ntacklethe problem, we propose a novel generationmodel that first plans the\nstylized keywordsand then generates the whole story with theguidance of the\nkeywords. Besides, we pro-pose two automatic metrics to evaluate theconsistency\nbetween the generated story andthe specified style. Experiments\ndemonstratesthat our model can controllably generateemo-tion-driven\norevent-driven stories based onthe ROCStories dataset (Mostafazadeh et\nal.,2016). Our study presents insights for stylizedstory generation in further\nresearch.", "published": "2021-05-18 15:55:38", "link": "http://arxiv.org/abs/2105.08625v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Automated Method to Enrich Consumer Health Vocabularies Using GloVe\n  Word Embeddings and An Auxiliary Lexical Resource", "abstract": "Background: Clear language makes communication easier between any two\nparties. A layman may have difficulty communicating with a professional due to\nnot understanding the specialized terms common to the domain. In healthcare, it\nis rare to find a layman knowledgeable in medical terminology which can lead to\npoor understanding of their condition and/or treatment. To bridge this gap,\nseveral professional vocabularies and ontologies have been created to map\nlaymen medical terms to professional medical terms and vice versa.\n  Objective: Many of the presented vocabularies are built manually or\nsemi-automatically requiring large investments of time and human effort and\nconsequently the slow growth of these vocabularies. In this paper, we present\nan automatic method to enrich laymen's vocabularies that has the benefit of\nbeing able to be applied to vocabularies in any domain.\n  Methods: Our entirely automatic approach uses machine learning, specifically\nGlobal Vectors for Word Embeddings (GloVe), on a corpus collected from a social\nmedia healthcare platform to extend and enhance consumer health vocabularies\n(CHV). Our approach further improves the CHV by incorporating synonyms and\nhyponyms from the WordNet ontology. The basic GloVe and our novel algorithms\nincorporating WordNet were evaluated using two laymen datasets from the\nNational Library of Medicine (NLM), Open-Access Consumer Health Vocabulary (OAC\nCHV) and MedlinePlus Healthcare Vocabulary.\n  Results: The results show that GloVe was able to find new laymen terms with\nan F-score of 48.44%. Furthermore, our enhanced GloVe approach outperformed\nbasic GloVe with an average F-score of 61%, a relative improvement of 25%.\nFurthermore, the enhanced GloVe showed a statistical significance over the two\nground truth datasets with P<.001.", "published": "2021-05-18 20:16:45", "link": "http://arxiv.org/abs/2105.08812v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Training Heterogeneous Features in Sequence to Sequence Tasks: Latent\n  Enhanced Multi-filter Seq2Seq Model", "abstract": "In language processing, training data with extremely large variance may lead\nto difficulty in the language model's convergence. It is difficult for the\nnetwork parameters to adapt sentences with largely varied semantics or\ngrammatical structures. To resolve this problem, we introduce a model that\nconcentrates the each of the heterogeneous features in the input sentences.\nBuilding upon the encoder-decoder architecture, we design a latent-enhanced\nmulti-filter seq2seq model (LEMS) that analyzes the input representations by\nintroducing a latent space transformation and clustering. The representations\nare extracted from the final hidden state of the encoder and lie in the latent\nspace. A latent space transformation is applied for enhancing the quality of\nthe representations. Thus the clustering algorithm can easily separate samples\nbased on the features of these representations. Multiple filters are trained by\nthe features from their corresponding clusters, and the heterogeneity of the\ntraining data can be resolved accordingly. We conduct two sets of comparative\nexperiments on semantic parsing and machine translation, using the Geo-query\ndataset and Multi30k English-French to demonstrate the enhancement our model\nhas made respectively.", "published": "2021-05-18 21:42:41", "link": "http://arxiv.org/abs/2105.08840v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploiting Adapters for Cross-lingual Low-resource Speech Recognition", "abstract": "Cross-lingual speech adaptation aims to solve the problem of leveraging\nmultiple rich-resource languages to build models for a low-resource target\nlanguage. Since the low-resource language has limited training data, speech\nrecognition models can easily overfit. In this paper, we propose to use\nadapters to investigate the performance of multiple adapters for\nparameter-efficient cross-lingual speech adaptation. Based on our previous\nMetaAdapter that implicitly leverages adapters, we propose a novel algorithms\ncalled SimAdapter for explicitly learning knowledge from adapters. Our\nalgorithm leverages adapters which can be easily integrated into the\nTransformer structure.MetaAdapter leverages meta-learning to transfer the\ngeneral knowledge from training data to the test language. SimAdapter aims to\nlearn the similarities between the source and target languages during\nfine-tuning using the adapters. We conduct extensive experiments on\nfive-low-resource languages in Common Voice dataset. Results demonstrate that\nour MetaAdapter and SimAdapter methods can reduce WER by 2.98% and 2.55% with\nonly 2.5% and 15.5% of trainable parameters compared to the strong full-model\nfine-tuning baseline. Moreover, we also show that these two novel algorithms\ncan be integrated for better performance with up to 3.55% relative WER\nreduction.", "published": "2021-05-18 08:30:37", "link": "http://arxiv.org/abs/2105.11905v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Relative Positional Encoding for Transformers with Linear Complexity", "abstract": "Recent advances in Transformer models allow for unprecedented sequence\nlengths, due to linear space and time complexity. In the meantime, relative\npositional encoding (RPE) was proposed as beneficial for classical Transformers\nand consists in exploiting lags instead of absolute positions for inference.\nStill, RPE is not available for the recent linear-variants of the Transformer,\nbecause it requires the explicit computation of the attention matrix, which is\nprecisely what is avoided by such methods. In this paper, we bridge this gap\nand present Stochastic Positional Encoding as a way to generate PE that can be\nused as a replacement to the classical additive (sinusoidal) PE and provably\nbehaves like RPE. The main theoretical contribution is to make a connection\nbetween positional encoding and cross-covariance structures of correlated\nGaussian processes. We illustrate the performance of our approach on the\nLong-Range Arena benchmark and on music generation.", "published": "2021-05-18 09:52:32", "link": "http://arxiv.org/abs/2105.08399v2", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A time-domain nearfield frequency-invariant beamforming method", "abstract": "Most existing beamforming methods are frequency-domain methods, and are\ndesigned for enhancing a farfield target source over a narrow frequency band.\nThey have found diverse applications and are still under active development.\nHowever, they struggle to achieve desired performance if the target source is\nin the nearfield with a broadband output. This paper proposes a time-domain\nnearfield frequency-invariant beamforming method. The time-domain\nimplementation makes the beamformer output suitable for further use by\nreal-time applications, the nearfield focusing enables the beamforming method\nto suppress an interference even if it is in the same direction as the target\nsource, and the frequency-invariant beampattern makes the beamforming method\nsuitable for enhancing the target source over a broad frequency band. These\nthree features together make the beamforming method suitable for real-time\nbroadband nearfield source enhancement, such as speech enhancement in room\nenvironments. The beamformer design process is separated from the sound field\nmeasurement process, and such that a designed beamformer applies to sensor\narrays with various structures. The beamformer design process is further\nsimplified by decomposing it into several independent parts. Simulation results\nconfirm the performance of the proposed beamforming method.", "published": "2021-05-18 01:22:11", "link": "http://arxiv.org/abs/2105.08219v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Handling Structural Mismatches in Real-time Opera Tracking", "abstract": "Algorithms for reliable real-time score following in live opera promise a lot\nof useful applications such as automatic subtitles display, or real-time video\ncutting in live streaming. Until now, such systems were based on the strong\nassumption that an opera performance follows the structure of the score\nlinearly. However, this is rarely the case in practice, because of different\nopera versions and directors' cutting choices. In this paper, we propose a\ntwo-level solution to this problem. We introduce a real-time-capable,\nhigh-resolution (HR) tracker that can handle jumps or repetitions at specific\nlocations provided to it. We then combine this with an additional\nlow-resolution (LR) tracker that can handle all sorts of mismatches that can\noccur at any time, with some imprecision, and can re-direct the HR tracker if\nthe latter is `lost' in the score. We show that the combination of the two\nimproves tracking robustness in the presence of strong structural mismatches.", "published": "2021-05-18 14:00:03", "link": "http://arxiv.org/abs/2105.08531v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Federated Learning With Highly Imbalanced Audio Data", "abstract": "Federated learning (FL) is a privacy-preserving machine learning method that\nhas been proposed to allow training of models using data from many different\nclients, without these clients having to transfer all their data to a central\nserver. There has as yet been relatively little consideration of FL or other\nprivacy-preserving methods in audio. In this paper, we investigate using FL for\na sound event detection task using audio from the FSD50K dataset. Audio is\nsplit into clients based on uploader metadata. This results in highly\nimbalanced subsets of data between clients, noted as a key issue in FL\nscenarios. A series of models is trained using `high-volume' clients that\ncontribute 100 audio clips or more, testing the effects of varying FL\nparameters, followed by an additional model trained using all clients with no\nminimum audio contribution. It is shown that FL models trained using the\nhigh-volume clients can perform similarly to a centrally-trained model, though\nthere is much more noise in results than would typically be expected for a\ncentrally-trained model. The FL model trained using all clients has a\nconsiderably reduced performance compared to the centrally-trained model.", "published": "2021-05-18 14:35:55", "link": "http://arxiv.org/abs/2105.08550v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Correlation Analysis for Audio-EEG Decoding", "abstract": "The electroencephalography (EEG), which is one of the easiest modes of\nrecording brain activations in a non-invasive manner, is often distorted due to\nrecording artifacts which adversely impacts the stimulus-response analysis. The\nmost prominent techniques thus far attempt to improve the stimulus-response\ncorrelations using linear methods. In this paper, we propose a neural network\nbased correlation analysis framework that significantly improves over the\nlinear methods for auditory stimuli. A deep model is proposed for intra-subject\naudio-EEG analysis based on directly optimizing the correlation loss. Further,\na neural network model with a shared encoder architecture is proposed for\nimproving the inter-subject stimulus response correlations. These models\nattempt to suppress the EEG artifacts while preserving the components related\nto the stimulus. Several experiments are performed using EEG recordings from\nsubjects listening to speech and music stimuli. In these experiments, we show\nthat the deep models improve the Pearson correlation significantly over the\nlinear methods (average absolute improvements of 7.4% in speech tasks and 29.3%\nin music tasks). We also analyze the impact of several model parameters on the\nstimulus-response correlation.", "published": "2021-05-18 13:09:10", "link": "http://arxiv.org/abs/2105.08492v2", "categories": ["eess.AS", "cs.SD", "eess.SP", "q-bio.QM"], "primary_category": "eess.AS"}
