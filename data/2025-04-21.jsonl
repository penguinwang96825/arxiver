{"title": "Seeing from Another Perspective: Evaluating Multi-View Understanding in MLLMs", "abstract": "Multi-view understanding, the ability to reconcile visual information across\ndiverse viewpoints for effective navigation, manipulation, and 3D scene\ncomprehension, is a fundamental challenge in Multi-Modal Large Language Models\n(MLLMs) to be used as embodied agents. While recent MLLMs have shown impressive\nadvances in high-level reasoning and planning, they frequently fall short when\nconfronted with multi-view geometric consistency and cross-view correspondence.\nTo comprehensively evaluate the challenges of MLLMs in multi-view scene\nreasoning, we propose All-Angles Bench, a benchmark of over 2,100 human\ncarefully annotated multi-view question-answer pairs across 90 diverse\nreal-world scenes. Our six tasks (counting, attribute identification, relative\ndistance, relative direction, object manipulation, and camera pose estimation)\nspecifically test model's geometric correspondence and the capacity to align\ninformation consistently across views. Our extensive experiments, benchmark on\n27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and\nGPT-4o against human evaluators reveals a substantial performance gap,\nindicating that current MLLMs remain far from human-level proficiency. Through\nin-depth analysis, we show that MLLMs are particularly underperforming under\ntwo aspects: (1) cross-view correspondence for partially occluded views and (2)\nestablishing the coarse camera poses. These findings highlight the necessity of\ndomain-specific refinements or modules that embed stronger multi-view\nawareness. We believe that our All-Angles Bench offers valuable insights and\ncontribute to bridging the gap between MLLMs and human-level multi-view\nunderstanding. The project and benchmark are publicly available at\nhttps://danielchyeh.github.io/All-Angles-Bench/.", "published": "2025-04-21 17:59:53", "link": "http://arxiv.org/abs/2504.15280v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "An LMM for Efficient Video Understanding via Reinforced Compression of Video Cubes", "abstract": "Large Multimodal Models (LMMs) uniformly perceive video frames, creating\ncomputational inefficiency for videos with inherently varying temporal\ninformation density. This paper present \\textbf{Quicksviewer}, an LMM with new\nperceiving paradigm that partitions a video of nonuniform density into varying\ncubes using Gumbel Softmax, followed by a unified resampling for each cube to\nachieve efficient video understanding. This simple and intuitive approach\ndynamically compress video online based on its temporal density, significantly\nreducing spatiotemporal redundancy (overall 45$\\times$ compression rate), while\nenabling efficient training with large receptive field. We train the model from\na language backbone through three progressive stages, each incorporating\nlengthy videos on average of 420s/1fps thanks to the perceiving efficiency.\nWith only 0.8M total video-text samples for training, our model outperforms the\ndirect baseline employing a fixed partitioning strategy by a maximum of 8.72 in\naccuracy, demonstrating the effectiveness in performance. On Video-MME,\nQuicksviewer achieves SOTA under modest sequence lengths using just up to 5\\%\nof tokens per frame required by baselines. With this paradigm, scaling up the\nnumber of input frames reveals a clear power law of the model capabilities. It\nis also empirically verified that the segments generated by the cubing network\ncan help for analyzing continuous events in videos.", "published": "2025-04-21 17:57:21", "link": "http://arxiv.org/abs/2504.15270v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction", "abstract": "We design a suite of minimal algorithmic tasks that are a loose abstraction\nof open-ended real-world tasks. This allows us to cleanly and controllably\nquantify the creative limits of the present-day language model. Much like\nreal-world tasks that require a creative, far-sighted leap of thought, our\ntasks require an implicit, open-ended stochastic planning step that either (a)\ndiscovers new connections in an abstract knowledge graph (like in wordplay,\ndrawing analogies, or research) or (b) constructs new patterns (like in\ndesigning math problems or new proteins). In these tasks, we empirically and\nconceptually argue how next-token learning is myopic and memorizes excessively;\ncomparatively, multi-token approaches, namely teacherless training and\ndiffusion models, excel in producing diverse and original output. Secondly, in\nour tasks, we find that to elicit randomness from the Transformer without\nhurting coherence, it is better to inject noise right at the input layer (via a\nmethod we dub hash-conditioning) rather than defer to temperature sampling from\nthe output layer. Thus, our work offers a principled, minimal test-bed for\nanalyzing open-ended creative skills, and offers new arguments for going beyond\nnext-token learning and softmax-based sampling. We make part of the code\navailable under https://github.com/chenwu98/algorithmic-creativity", "published": "2025-04-21 17:47:46", "link": "http://arxiv.org/abs/2504.15266v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation", "abstract": "C-to-Rust transpilation is essential for modernizing legacy C code while\nenhancing safety and interoperability with modern Rust ecosystems. However, no\ndataset currently exists for evaluating whether a system can transpile C into\nsafe Rust that passes a set of test cases. We introduce CRUST-Bench, a dataset\nof 100 C repositories, each paired with manually-written interfaces in safe\nRust as well as test cases that can be used to validate correctness of the\ntranspilation. By considering entire repositories rather than isolated\nfunctions, CRUST-Bench captures the challenges of translating complex projects\nwith dependencies across multiple files. The provided Rust interfaces provide\nexplicit specifications that ensure adherence to idiomatic, memory-safe Rust\npatterns, while the accompanying test cases enforce functional correctness. We\nevaluate state-of-the-art large language models (LLMs) on this task and find\nthat safe and idiomatic Rust generation is still a challenging problem for\nvarious state-of-the-art methods and techniques. We also provide insights into\nthe errors LLMs usually make in transpiling code from C to safe Rust. The best\nperforming model, OpenAI o1, is able to solve only 15 tasks in a single-shot\nsetting. Improvements on CRUST-Bench would lead to improved transpilation\nsystems that can reason about complex scenarios and help in migrating legacy\ncodebases from C into languages like Rust that ensure memory safety. You can\nfind the dataset and code at https://github.com/anirudhkhatry/CRUST-bench.", "published": "2025-04-21 17:33:33", "link": "http://arxiv.org/abs/2504.15254v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Evaluating Judges as Evaluators: The JETTS Benchmark of LLM-as-Judges as Test-Time Scaling Evaluators", "abstract": "Scaling test-time computation, or affording a generator large language model\n(LLM) extra compute during inference, typically employs the help of external\nnon-generative evaluators (i.e., reward models). Concurrently, LLM-judges,\nmodels trained to generate evaluations and critiques (explanations) in natural\nlanguage, are becoming increasingly popular in automatic evaluation. Despite\njudge empirical successes, their effectiveness as evaluators in test-time\nscaling settings is largely unknown. In this paper, we introduce the Judge\nEvaluation for Test-Time Scaling (JETTS) benchmark, which evaluates judge\nperformance in three domains (math reasoning, code generation, and instruction\nfollowing) under three task settings: response reranking, step-level beam\nsearch, and critique-based response refinement. We evaluate 10 different judge\nmodels (7B-70B parameters) for 8 different base generator models (6.7B-72B\nparameters). Our benchmark shows that while judges are competitive with outcome\nreward models in reranking, they are consistently worse than process reward\nmodels in beam search procedures. Furthermore, though unique to LLM-judges,\ntheir natural language critiques are currently ineffective in guiding the\ngenerator towards better responses.", "published": "2025-04-21 17:33:23", "link": "http://arxiv.org/abs/2504.15253v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MR. Guard: Multilingual Reasoning Guardrail using Curriculum Learning", "abstract": "Large Language Models (LLMs) are susceptible to adversarial attacks such as\njailbreaking, which can elicit harmful or unsafe behaviors. This vulnerability\nis exacerbated in multilingual setting, where multilingual safety-aligned data\nare often limited. Thus, developing a guardrail capable of detecting and\nfiltering unsafe content across diverse languages is critical for deploying\nLLMs in real-world applications. In this work, we propose an approach to build\na multilingual guardrail with reasoning. Our method consists of: (1) synthetic\nmultilingual data generation incorporating culturally and linguistically\nnuanced variants, (2) supervised fine-tuning, and (3) a curriculum-guided Group\nRelative Policy Optimization (GRPO) framework that further improves\nperformance. Experimental results demonstrate that our multilingual guardrail\nconsistently outperforms recent baselines across both in-domain and\nout-of-domain languages. The multilingual reasoning capability of our guardrail\nenables it to generate multilingual explanations, which are particularly useful\nfor understanding language-specific risks and ambiguities in multilingual\ncontent moderation.", "published": "2025-04-21 17:15:06", "link": "http://arxiv.org/abs/2504.15241v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Values in the Wild: Discovering and Analyzing Values in Real-World Language Model Interactions", "abstract": "AI assistants can impart value judgments that shape people's decisions and\nworldviews, yet little is known empirically about what values these systems\nrely on in practice. To address this, we develop a bottom-up,\nprivacy-preserving method to extract the values (normative considerations\nstated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit\nin hundreds of thousands of real-world interactions. We empirically discover\nand taxonomize 3,307 AI values and study how they vary by context. We find that\nClaude expresses many practical and epistemic values, and typically supports\nprosocial human values while resisting values like \"moral nihilism\". While some\nvalues appear consistently across contexts (e.g. \"transparency\"), many are more\nspecialized and context-dependent, reflecting the diversity of human\ninterlocutors and their varied contexts. For example, \"harm prevention\" emerges\nwhen Claude resists users, \"historical accuracy\" when responding to queries\nabout controversial events, \"healthy boundaries\" when asked for relationship\nadvice, and \"human agency\" in technology ethics discussions. By providing the\nfirst large-scale empirical mapping of AI values in deployment, our work\ncreates a foundation for more grounded evaluation and design of values in AI\nsystems.", "published": "2025-04-21 17:13:16", "link": "http://arxiv.org/abs/2504.15236v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fully Bayesian Approaches to Topics over Time", "abstract": "The Topics over Time (ToT) model captures thematic changes in timestamped\ndatasets by explicitly modeling publication dates jointly with word\nco-occurrence patterns. However, ToT was not approached in a fully Bayesian\nfashion, a flaw that makes it susceptible to stability problems. To address\nthis issue, we propose a fully Bayesian Topics over Time (BToT) model via the\nintroduction of a conjugate prior to the Beta distribution. This prior acts as\na regularization that prevents the online version of the algorithm from\nunstable updates when a topic is poorly represented in a mini-batch. The\ncharacteristics of this prior to the Beta distribution are studied here for the\nfirst time. Still, this model suffers from a difference in scale between the\nsingle-time observations and the multiplicity of words per document. A\nvariation of BToT, Weighted Bayesian Topics over Time (WBToT), is proposed as a\nsolution. In WBToT, publication dates are repeated a certain number of times\nper document, which balances the relative influence of words and timestamps\nalong the inference process. We have tested our models on two datasets: a\ncollection of over 200 years of US state-of-the-union (SOTU) addresses and a\nlarge-scale COVID-19 Twitter corpus of 10 million tweets. The results show that\nWBToT captures events better than Latent Dirichlet Allocation and other SOTA\ntopic models like BERTopic: the median absolute deviation of the topic presence\nover time is reduced by $51\\%$ and $34\\%$, respectively. Our experiments also\ndemonstrate the superior coherence of WBToT over BToT, which highlights the\nimportance of balancing the time and word modalities. Finally, we illustrate\nthe stability of the online optimization algorithm in WBToT, which allows the\napplication of WBToT to problems that are intractable for standard ToT.", "published": "2025-04-21 16:46:07", "link": "http://arxiv.org/abs/2504.15220v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EvalAgent: Discovering Implicit Evaluation Criteria from the Web", "abstract": "Evaluation of language model outputs on structured writing tasks is typically\nconducted with a number of desirable criteria presented to human evaluators or\nlarge language models (LLMs). For instance, on a prompt like \"Help me draft an\nacademic talk on coffee intake vs research productivity\", a model response may\nbe evaluated for criteria like accuracy and coherence. However, high-quality\nresponses should do more than just satisfy basic task requirements. An\neffective response to this query should include quintessential features of an\nacademic talk, such as a compelling opening, clear research questions, and a\ntakeaway. To help identify these implicit criteria, we introduce EvalAgent, a\nnovel framework designed to automatically uncover nuanced and task-specific\ncriteria. EvalAgent first mines expert-authored online guidance. It then uses\nthis evidence to propose diverse, long-tail evaluation criteria that are\ngrounded in reliable external sources. Our experiments demonstrate that the\ngrounded criteria produced by EvalAgent are often implicit (not directly stated\nin the user's prompt), yet specific (high degree of lexical precision).\nFurther, EvalAgent criteria are often not satisfied by initial responses but\nthey are actionable, such that responses can be refined to satisfy them.\nFinally, we show that combining LLM-generated and EvalAgent criteria uncovers\nmore human-valued criteria than using LLMs alone.", "published": "2025-04-21 16:43:50", "link": "http://arxiv.org/abs/2504.15219v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus LLM Judges", "abstract": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to\ngenerate answers with citations from source documents containing \"ground\ntruth\", thereby reducing system hallucinations. A crucial factor in RAG\nevaluation is \"support\", whether the information in the cited documents\nsupports the answer. To this end, we conducted a large-scale comparative study\nof 45 participant submissions on 36 topics to the TREC 2024 RAG Track,\ncomparing an automatic LLM judge (GPT-4o) against human judges for support\nassessment. We considered two conditions: (1) fully manual assessments from\nscratch and (2) manual assessments with post-editing of LLM predictions. Our\nresults indicate that for 56% of the manual from-scratch assessments, human and\nGPT-4o predictions match perfectly (on a three-level scale), increasing to 72%\nin the manual with post-editing condition. Furthermore, by carefully analyzing\nthe disagreements in an unbiased study, we found that an independent human\njudge correlates better with GPT-4o than a human judge, suggesting that LLM\njudges can be a reliable alternative for support assessment. To conclude, we\nprovide a qualitative analysis of human and GPT-4o errors to help guide future\niterations of support assessment.", "published": "2025-04-21 16:20:43", "link": "http://arxiv.org/abs/2504.15205v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "On true empty category", "abstract": "According to Chomsky (1981, 1986), empty categories consist of PRO, pro,\ntrace, and variable. However, some empty object positions seem to be\nincompatible with extant empty categories. Given this, Li (2007a, 2007b, 2014)\nand Li & Wei (2014) raise the true empty category hypothesis, which holds that\ntrue empty category is only an empty position with category and Case features.\nAs a last resort option, it is used mainly to meet the subcatgorization of a\nverb. This assumption is ingenious, and if proved to be true, it will exert a\ngreat impact on the study of UG. In this paper, we evaluate their evidence from\ntopicalization and demonstrate that it can be accounted for without invoking\ntrue empty category.", "published": "2025-04-21 15:22:21", "link": "http://arxiv.org/abs/2504.15168v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Synthetic Imputation Approach: Generating Optimal Synthetic Texts For Underrepresented Categories In Supervised Classification Tasks", "abstract": "Encoder-decoder Large Language Models (LLMs), such as BERT and RoBERTa,\nrequire that all categories in an annotation task be sufficiently represented\nin the training data for optimal performance. However, it is often difficult to\nfind sufficient examples for all categories in a task when building a\nhigh-quality training set. In this article, I describe this problem and propose\na solution, the synthetic imputation approach. Leveraging a generative LLM\n(GPT-4o), this approach generates synthetic texts based on careful prompting\nand five original examples drawn randomly with replacement from the sample.\nThis approach ensures that new synthetic texts are sufficiently different from\nthe original texts to reduce overfitting, but retain the underlying substantive\nmeaning of the examples to maximize out-of-sample performance. With 75 original\nexamples or more, synthetic imputation's performance is on par with a full\nsample of original texts, and overfitting remains low, predictable and\ncorrectable with 50 original samples. The synthetic imputation approach\nprovides a novel role for generative LLMs in research and allows applied\nresearchers to balance their datasets for best performance.", "published": "2025-04-21 15:07:26", "link": "http://arxiv.org/abs/2504.15160v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking", "abstract": "Entity linking (EL) aligns textual mentions with their corresponding entities\nin a knowledge base, facilitating various applications such as semantic search\nand question answering. Recent advances in multimodal entity linking (MEL) have\nshown that combining text and images can reduce ambiguity and improve alignment\naccuracy. However, most existing MEL methods overlook the rich structural\ninformation available in the form of knowledge-graph (KG) triples. In this\npaper, we propose KGMEL, a novel framework that leverages KG triples to enhance\nMEL. Specifically, it operates in three stages: (1) Generation: Produces\nhigh-quality triples for each mention by employing vision-language models based\non its text and images. (2) Retrieval: Learns joint mention-entity\nrepresentations, via contrastive learning, that integrate text, images, and\n(generated or KG) triples to retrieve candidate entities for each mention. (3)\nReranking: Refines the KG triples of the candidate entities and employs large\nlanguage models to identify the best-matching entity for the mention. Extensive\nexperiments on benchmark datasets demonstrate that KGMEL outperforms existing\nmethods. Our code and datasets are available at:\nhttps://github.com/juyeonnn/KGMEL.", "published": "2025-04-21 14:38:44", "link": "http://arxiv.org/abs/2504.15135v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language Models", "abstract": "In this paper, we introduce EasyEdit2, a framework designed to enable\nplug-and-play adjustability for controlling Large Language Model (LLM)\nbehaviors. EasyEdit2 supports a wide range of test-time interventions,\nincluding safety, sentiment, personality, reasoning patterns, factuality, and\nlanguage features. Unlike its predecessor, EasyEdit2 features a new\narchitecture specifically designed for seamless model steering. It comprises\nkey modules such as the steering vector generator and the steering vector\napplier, which enable automatic generation and application of steering vectors\nto influence the model's behavior without modifying its parameters. One of the\nmain advantages of EasyEdit2 is its ease of use-users do not need extensive\ntechnical knowledge. With just a single example, they can effectively guide and\nadjust the model's responses, making precise control both accessible and\nefficient. Empirically, we report model steering performance across different\nLLMs, demonstrating the effectiveness of these techniques. We have released the\nsource code on GitHub at https://github.com/zjunlp/EasyEdit along with a\ndemonstration notebook. In addition, we provide a demo video at\nhttps://zjunlp.github.io/project/EasyEdit2/video for a quick introduction.", "published": "2025-04-21 14:33:55", "link": "http://arxiv.org/abs/2504.15133v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Kuwain 1.5B: An Arabic SLM via Language Injection", "abstract": "Enhancing existing models with new knowledge is a crucial aspect of AI\ndevelopment. This paper introduces a novel method for integrating a new\nlanguage into a large language model (LLM). Our approach successfully\nincorporates a previously unseen target language into an existing LLM without\ncompromising its prior knowledge. We trained a tiny model with 1.5 billion\nparameters named Kuwain by injecting the Arabic language into a small\nopen-source model mainly trained in English. Our method demonstrates\nsignificant improvements in Arabic language performance, with an average 8%\nimprovement across various benchmarks, while retaining the model's existing\nknowledge with a minimum amount of the original model's data. This offers a\ncost-effective alternative to training a comprehensive model in both English\nand Arabic. The results highlight the potential for efficient, targeted\nlanguage model expansion without extensive retraining or resource-intensive\nprocesses.", "published": "2025-04-21 14:17:25", "link": "http://arxiv.org/abs/2504.15120v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rethinking the Potential of Multimodality in Collaborative Problem Solving Diagnosis with Large Language Models", "abstract": "Detecting collaborative and problem-solving behaviours from digital traces to\ninterpret students' collaborative problem solving (CPS) competency is a\nlong-term goal in the Artificial Intelligence in Education (AIEd) field.\nAlthough multimodal data and advanced models are argued to have the potential\nto detect complex CPS behaviours, empirical evidence on their value remains\nlimited with some contrasting evidence. In this study, we investigated the\npotential of multimodal data to improve model performance in diagnosing 78\nsecondary school students' CPS subskills and indicators in authentic\neducational settings. In particular, text embeddings from verbal data and\nacoustic embeddings from audio data were used in a multimodal classification\nmodel for CPS diagnosis. Both unimodal and multimodal transformer-based models\noutperformed traditional models in detecting CPS classes. Although the\ninclusion of multimodality did not improve the performance of traditional\nunimodal models, its integration into transformer-based models demonstrated\nimproved performance for diagnosing social-cognitive CPS classes compared to\nunimodal transformer-based models. Based on the results, the paper argues that\nmultimodality and the selection of a particular modelling technique should not\nbe taken for granted to achieve the best performance in the automated detection\nof every CPS subskill and indicator. Rather, their value is limited to certain\ntypes of CPS indicators, affected by the complexity of the labels, and\ndependent on the composition of indicators in the dataset. We conclude the\npaper by discussing the required nuance when considering the value of LLMs and\nmultimodality in automated CPS diagnosis, highlighting the need for human-AI\ncomplementarity, and proposing the exploration of relevant model architectures\nand techniques to improve CPS diagnosis in authentic educational contexts.", "published": "2025-04-21 13:25:55", "link": "http://arxiv.org/abs/2504.15093v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rhythm of Opinion: A Hawkes-Graph Framework for Dynamic Propagation Analysis", "abstract": "The rapid development of social media has significantly reshaped the dynamics\nof public opinion, resulting in complex interactions that traditional models\nfail to effectively capture. To address this challenge, we propose an\ninnovative approach that integrates multi-dimensional Hawkes processes with\nGraph Neural Network, modeling opinion propagation dynamics among nodes in a\nsocial network while considering the intricate hierarchical relationships\nbetween comments. The extended multi-dimensional Hawkes process captures the\nhierarchical structure, multi-dimensional interactions, and mutual influences\nacross different topics, forming a complex propagation network. Moreover,\nrecognizing the lack of high-quality datasets capable of comprehensively\ncapturing the evolution of public opinion dynamics, we introduce a new dataset,\nVISTA. It includes 159 trending topics, corresponding to 47,207 posts, 327,015\nsecond-level comments, and 29,578 third-level comments, covering diverse\ndomains such as politics, entertainment, sports, health, and medicine. The\ndataset is annotated with detailed sentiment labels across 11 categories and\nclearly defined hierarchical relationships. When combined with our method, it\noffers strong interpretability by linking sentiment propagation to the comment\nhierarchy and temporal evolution. Our approach provides a robust baseline for\nfuture research.", "published": "2025-04-21 13:02:30", "link": "http://arxiv.org/abs/2504.15072v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "The Great Nugget Recall: Automating Fact Extraction and RAG Evaluation with Large Language Models", "abstract": "Large Language Models (LLMs) have significantly enhanced the capabilities of\ninformation access systems, especially with retrieval-augmented generation\n(RAG). Nevertheless, the evaluation of RAG systems remains a barrier to\ncontinued progress, a challenge we tackle in this work by proposing an\nautomatic evaluation framework that is validated against human annotations. We\nbelieve that the nugget evaluation methodology provides a solid foundation for\nevaluating RAG systems. This approach, originally developed for the TREC\nQuestion Answering (QA) Track in 2003, evaluates systems based on atomic facts\nthat should be present in good answers. Our efforts focus on \"refactoring\" this\nmethodology, where we describe the AutoNuggetizer framework that specifically\napplies LLMs to both automatically create nuggets and automatically assign\nnuggets to system answers. In the context of the TREC 2024 RAG Track, we\ncalibrate a fully automatic approach against strategies where nuggets are\ncreated manually or semi-manually by human assessors and then assigned manually\nto system answers. Based on results from a community-wide evaluation, we\nobserve strong agreement at the run level between scores derived from fully\nautomatic nugget evaluation and human-based variants. The agreement is stronger\nwhen individual framework components such as nugget assignment are automated\nindependently. This suggests that our evaluation framework provides tradeoffs\nbetween effort and quality that can be used to guide the development of future\nRAG systems. However, further research is necessary to refine our approach,\nparticularly in establishing robust per-topic agreement to diagnose system\nfailures effectively.", "published": "2025-04-21 12:55:06", "link": "http://arxiv.org/abs/2504.15068v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Testing LLMs' Capabilities in Annotating Translations Based on an Error Typology Designed for LSP Translation: First Experiments with ChatGPT", "abstract": "This study investigates the capabilities of large language models (LLMs),\nspecifically ChatGPT, in annotating MT outputs based on an error typology. In\ncontrast to previous work focusing mainly on general language, we explore\nChatGPT's ability to identify and categorise errors in specialised\ntranslations. By testing two different prompts and based on a customised error\ntypology, we compare ChatGPT annotations with human expert evaluations of\ntranslations produced by DeepL and ChatGPT itself. The results show that, for\ntranslations generated by DeepL, recall and precision are quite high. However,\nthe degree of accuracy in error categorisation depends on the prompt's specific\nfeatures and its level of detail, ChatGPT performing very well with a detailed\nprompt. When evaluating its own translations, ChatGPT achieves significantly\npoorer results, revealing limitations with self-assessment. These results\nhighlight both the potential and the limitations of LLMs for translation\nevaluation, particularly in specialised domains. Our experiments pave the way\nfor future research on open-source LLMs, which could produce annotations of\ncomparable or even higher quality. In the future, we also aim to test the\npractical effectiveness of this automated evaluation in the context of\ntranslation training, particularly by optimising the process of human\nevaluation by teachers and by exploring the impact of annotations by LLMs on\nstudents' post-editing and translation learning.", "published": "2025-04-21 12:21:37", "link": "http://arxiv.org/abs/2504.15052v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "RainbowPlus: Enhancing Adversarial Prompt Generation via Evolutionary Quality-Diversity Search", "abstract": "Large Language Models (LLMs) exhibit remarkable capabilities but are\nsusceptible to adversarial prompts that exploit vulnerabilities to produce\nunsafe or biased outputs. Existing red-teaming methods often face scalability\nchallenges, resource-intensive requirements, or limited diversity in attack\nstrategies. We propose RainbowPlus, a novel red-teaming framework rooted in\nevolutionary computation, enhancing adversarial prompt generation through an\nadaptive quality-diversity (QD) search that extends classical evolutionary\nalgorithms like MAP-Elites with innovations tailored for language models. By\nemploying a multi-element archive to store diverse high-quality prompts and a\ncomprehensive fitness function to evaluate multiple prompts concurrently,\nRainbowPlus overcomes the constraints of single-prompt archives and pairwise\ncomparisons in prior QD methods like Rainbow Teaming. Experiments comparing\nRainbowPlus to QD methods across six benchmark datasets and four open-source\nLLMs demonstrate superior attack success rate (ASR) and diversity\n(Diverse-Score $\\approx 0.84$), generating up to 100 times more unique prompts\n(e.g., 10,418 vs. 100 for Ministral-8B-Instruct-2410). Against nine\nstate-of-the-art methods on the HarmBench dataset with twelve LLMs (ten\nopen-source, two closed-source), RainbowPlus achieves an average ASR of 81.1%,\nsurpassing AutoDAN-Turbo by 3.9%, and is 9 times faster (1.45 vs. 13.50 hours).\nOur open-source implementation fosters further advancements in LLM safety,\noffering a scalable tool for vulnerability assessment. Code and resources are\npublicly available at https://github.com/knoveleng/rainbowplus, supporting\nreproducibility and future research in LLM red-teaming.", "published": "2025-04-21 12:04:57", "link": "http://arxiv.org/abs/2504.15047v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DistilQwen2.5: Industrial Practices of Training Distilled Open Lightweight Language Models", "abstract": "Enhancing computational efficiency and reducing deployment costs for large\nlanguage models (LLMs) have become critical challenges in various\nresource-constrained scenarios. In this work, we present DistilQwen2.5, a\nfamily of distilled, lightweight LLMs derived from the public Qwen2.5 models.\nThese distilled models exhibit enhanced instruction-following capabilities\ncompared to the original models based on a series of distillation techniques\nthat incorporate knowledge from much larger LLMs. In our industrial practice,\nwe first leverage powerful proprietary LLMs with varying capacities as\nmulti-agent teachers to select, rewrite, and refine instruction-response pairs\nthat are more suitable for student LLMs to learn. After standard fine-tuning,\nwe further leverage a computationally efficient model fusion approach that\nenables student models to progressively integrate fine-grained hidden knowledge\nfrom their teachers. Experimental evaluations demonstrate that the distilled\nmodels possess significantly stronger capabilities than their original\ncheckpoints. Additionally, we present use cases to illustrate the applications\nof our framework in real-world scenarios. To facilitate practical use, we have\nreleased all the DistilQwen2.5 models to the open-source community.", "published": "2025-04-21 11:26:02", "link": "http://arxiv.org/abs/2504.15027v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs as Data Annotators: How Close Are We to Human Performance", "abstract": "In NLP, fine-tuning LLMs is effective for various applications but requires\nhigh-quality annotated data. However, manual annotation of data is\nlabor-intensive, time-consuming, and costly. Therefore, LLMs are increasingly\nused to automate the process, often employing in-context learning (ICL) in\nwhich some examples related to the task are given in the prompt for better\nperformance. However, manually selecting context examples can lead to\ninefficiencies and suboptimal model performance. This paper presents\ncomprehensive experiments comparing several LLMs, considering different\nembedding models, across various datasets for the Named Entity Recognition\n(NER) task. The evaluation encompasses models with approximately $7$B and $70$B\nparameters, including both proprietary and non-proprietary models. Furthermore,\nleveraging the success of Retrieval-Augmented Generation (RAG), it also\nconsiders a method that addresses the limitations of ICL by automatically\nretrieving contextual examples, thereby enhancing performance. The results\nhighlight the importance of selecting the appropriate LLM and embedding model,\nunderstanding the trade-offs between LLM sizes and desired performance, and the\nnecessity to direct research efforts towards more challenging datasets.", "published": "2025-04-21 11:11:07", "link": "http://arxiv.org/abs/2504.15022v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stay Hungry, Stay Foolish: On the Extended Reading Articles Generation with LLMs", "abstract": "The process of creating educational materials is both time-consuming and\ndemanding for educators. This research explores the potential of Large Language\nModels (LLMs) to streamline this task by automating the generation of extended\nreading materials and relevant course suggestions. Using the TED-Ed Dig Deeper\nsections as an initial exploration, we investigate how supplementary articles\ncan be enriched with contextual knowledge and connected to additional learning\nresources. Our method begins by generating extended articles from video\ntranscripts, leveraging LLMs to include historical insights, cultural examples,\nand illustrative anecdotes. A recommendation system employing semantic\nsimilarity ranking identifies related courses, followed by an LLM-based\nrefinement process to enhance relevance. The final articles are tailored to\nseamlessly integrate these recommendations, ensuring they remain cohesive and\ninformative. Experimental evaluations demonstrate that our model produces\nhigh-quality content and accurate course suggestions, assessed through metrics\nsuch as Hit Rate, semantic similarity, and coherence. Our experimental analysis\nhighlight the nuanced differences between the generated and existing materials,\nunderscoring the model's capacity to offer more engaging and accessible\nlearning experiences. This study showcases how LLMs can bridge the gap between\ncore content and supplementary learning, providing students with additional\nrecommended resources while also assisting teachers in designing educational\nmaterials.", "published": "2025-04-21 10:35:48", "link": "http://arxiv.org/abs/2504.15013v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Pretraining Length Scaling", "abstract": "Recent advances in large language models have demonstrated the effectiveness\nof length scaling during post-training, yet its potential in pre-training\nremains underexplored. We present the Parallel Hidden Decoding Transformer\n(\\textit{PHD}-Transformer), a novel framework that enables efficient length\nscaling during pre-training while maintaining inference efficiency.\n\\textit{PHD}-Transformer achieves this through an innovative KV cache\nmanagement strategy that distinguishes between original tokens and hidden\ndecoding tokens. By retaining only the KV cache of original tokens for\nlong-range dependencies while immediately discarding hidden decoding tokens\nafter use, our approach maintains the same KV cache size as the vanilla\ntransformer while enabling effective length scaling. To further enhance\nperformance, we introduce two optimized variants: \\textit{PHD-SWA} employs\nsliding window attention to preserve local dependencies, while\n\\textit{PHD-CSWA} implements chunk-wise sliding window attention to eliminate\nlinear growth in pre-filling time. Extensive experiments demonstrate consistent\nimprovements across multiple benchmarks.", "published": "2025-04-21 09:41:26", "link": "http://arxiv.org/abs/2504.14992v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating LLMs on Chinese Topic Constructions: A Research Proposal Inspired by Tian et al. (2024)", "abstract": "This paper proposes a framework for evaluating large language models (LLMs)\non Chinese topic constructions, focusing on their sensitivity to island\nconstraints. Drawing inspiration from Tian et al. (2024), we outline an\nexperimental design for testing LLMs' grammatical knowledge of Mandarin syntax.\nWhile no experiments have been conducted yet, this proposal aims to provide a\nfoundation for future studies and invites feedback on the methodology.", "published": "2025-04-21 08:56:23", "link": "http://arxiv.org/abs/2504.14969v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speaker Fuzzy Fingerprints: Benchmarking Text-Based Identification in Multiparty Dialogues", "abstract": "Speaker identification using voice recordings leverages unique acoustic\nfeatures, but this approach fails when only textual data is available. Few\napproaches have attempted to tackle the problem of identifying speakers solely\nfrom text, and the existing ones have primarily relied on traditional methods.\nIn this work, we explore the use of fuzzy fingerprints from large pre-trained\nmodels to improve text-based speaker identification. We integrate\nspeaker-specific tokens and context-aware modeling, demonstrating that\nconversational context significantly boosts accuracy, reaching 70.6% on the\nFriends dataset and 67.7% on the Big Bang Theory dataset. Additionally, we show\nthat fuzzy fingerprints can approximate full fine-tuning performance with fewer\nhidden units, offering improved interpretability. Finally, we analyze ambiguous\nutterances and propose a mechanism to detect speaker-agnostic lines. Our\nfindings highlight key challenges and provide insights for future improvements\nin text-based speaker identification.", "published": "2025-04-21 08:44:33", "link": "http://arxiv.org/abs/2504.14963v1", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Learning to Reason under Off-Policy Guidance", "abstract": "Recent advances in large reasoning models (LRMs) demonstrate that\nsophisticated behaviors such as multi-step reasoning and self-reflection can\nemerge via reinforcement learning (RL) with simple rule-based rewards. However,\nexisting zero-RL approaches are inherently ``on-policy'', limiting learning to\na model's own outputs and failing to acquire reasoning abilities beyond its\ninitial capabilities. We introduce LUFFY (Learning to reason Under oFF-policY\nguidance), a framework that augments zero-RL with off-policy reasoning traces.\nLUFFY dynamically balances imitation and exploration by combining off-policy\ndemonstrations with on-policy rollouts during training. Notably, we propose\npolicy shaping via regularized importance sampling to avoid superficial and\nrigid imitation during mixed-policy training. Remarkably, LUFFY achieves an\nover +7.0 average gain across six math benchmarks and an advantage of over +6.2\npoints in out-of-distribution tasks. It also substantially surpasses\nimitation-based supervised fine-tuning (SFT), particularly in generalization.\nAnalysis shows LUFFY not only imitates effectively but also explores beyond\ndemonstrations, offering a scalable path to train generalizable reasoning\nmodels with off-policy guidance.", "published": "2025-04-21 08:09:13", "link": "http://arxiv.org/abs/2504.14945v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework", "abstract": "Large language models (LLMs) increasingly serve as educational tools, yet\nevaluating their teaching capabilities remains challenging due to the\nresource-intensive, context-dependent, and methodologically complex nature of\nteacher-student interactions. We introduce EducationQ, a multi-agent dialogue\nframework that efficiently assesses teaching capabilities through simulated\ndynamic educational scenarios, featuring specialized agents for teaching,\nlearning, and evaluation. Testing 14 LLMs across major AI Organizations\n(OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13\ndisciplines and 10 difficulty levels reveals that teaching effectiveness does\nnot correlate linearly with model scale or general reasoning capabilities -\nwith some smaller open-source models outperforming larger commercial\ncounterparts in teaching contexts. This finding highlights a critical gap in\ncurrent evaluations that prioritize knowledge recall over interactive pedagogy.\nOur mixed-methods evaluation, combining quantitative metrics with qualitative\nanalysis and expert case studies, identifies distinct pedagogical strengths\nemployed by top-performing models (e.g., sophisticated questioning strategies,\nadaptive feedback mechanisms). Human expert evaluations show 78% agreement with\nour automated qualitative analysis of effective teaching behaviors, validating\nour methodology. EducationQ demonstrates that LLMs-as-teachers require\nspecialized optimization beyond simple scaling, suggesting next-generation\neducational AI prioritize targeted enhancement of specific pedagogical\neffectiveness.", "published": "2025-04-21 07:48:20", "link": "http://arxiv.org/abs/2504.14928v1", "categories": ["cs.AI", "cs.CE", "cs.CL", "cs.CY", "cs.HC"], "primary_category": "cs.AI"}
{"title": "CRAVE: A Conflicting Reasoning Approach for Explainable Claim Verification Using LLMs", "abstract": "The rapid spread of misinformation, driven by digital media and AI-generated\ncontent, has made automatic claim verification essential. Traditional methods,\nwhich depend on expert-annotated evidence, are labor-intensive and not\nscalable. Although recent automated systems have improved, they still struggle\nwith complex claims that require nuanced reasoning. To address this, we propose\nCRAVE, a Conflicting Reasoning Approach for explainable claim VErification,\nthat verify the complex claims based on the conflicting rationales reasoned by\nlarge language models (LLMs). Specifically, CRAVE introduces a three-module\nframework. Ambiguity Elimination enchanced Evidence Retrieval module performs\nambiguity elimination and entity-based search to gather relevant evidence\nrelated to claim verification from external sources like Wikipedia. Conflicting\nPerspective Reasoning and Preliminary Judgment module with LLMs adopts LLMs to\nreason rationales with conflicting stances about claim verification from\nretrieved evidence across four dimensions, i.e., direct evidence, semantic\nrelationships, linguistic patterns, and logical reasoning and make a\npreliminary judgment. Finally, Small Language Model (SLM) based Judge module is\nfine-tuned to make use of preliminary judgment from LLMs to assess the\nconfidence of the conflicting rationales and make a final authenticity\njudgment. This methodology allows CRAVE to capture subtle inconsistencies in\ncomplex claims, improving both the accuracy and transparency of claim\nverification. Extensive experiments on two public claim verification datasets\ndemonstrate that our CRAVE model achieves much better performance than\nstate-of-the-art methods and exhibits a superior capacity for finding relevant\nevidence and explaining the model predictions. The code is provided at\nhttps://github.com/8zym/CRAVE.", "published": "2025-04-21 07:20:31", "link": "http://arxiv.org/abs/2504.14905v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VLM as Policy: Common-Law Content Moderation Framework for Short Video Platform", "abstract": "Exponentially growing short video platforms (SVPs) face significant\nchallenges in moderating content detrimental to users' mental health,\nparticularly for minors. The dissemination of such content on SVPs can lead to\ncatastrophic societal consequences. Although substantial efforts have been\ndedicated to moderating such content, existing methods suffer from critical\nlimitations: (1) Manual review is prone to human bias and incurs high\noperational costs. (2) Automated methods, though efficient, lack nuanced\ncontent understanding, resulting in lower accuracy. (3) Industrial moderation\nregulations struggle to adapt to rapidly evolving trends due to long update\ncycles. In this paper, we annotate the first SVP content moderation benchmark\nwith authentic user/reviewer feedback to fill the absence of benchmark in this\nfield. Then we evaluate various methods on the benchmark to verify the\nexistence of the aforementioned limitations. We further propose our common-law\ncontent moderation framework named KuaiMod to address these challenges. KuaiMod\nconsists of three components: training data construction, offline adaptation,\nand online deployment & refinement. Leveraging large vision language model\n(VLM) and Chain-of-Thought (CoT) reasoning, KuaiMod adequately models video\ntoxicity based on sparse user feedback and fosters dynamic moderation policy\nwith rapid update speed and high accuracy. Offline experiments and large-scale\nonline A/B test demonstrates the superiority of KuaiMod: KuaiMod achieves the\nbest moderation performance on our benchmark. The deployment of KuaiMod reduces\nthe user reporting rate by 20% and its application in video recommendation\nincreases both Daily Active User (DAU) and APP Usage Time (AUT) on several\nKuaishou scenarios. We have open-sourced our benchmark at\nhttps://kuaimod.github.io.", "published": "2025-04-21 07:20:19", "link": "http://arxiv.org/abs/2504.14904v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.SI"}
{"title": "Retrieval Augmented Generation Evaluation in the Era of Large Language Models: A Comprehensive Survey", "abstract": "Recent advancements in Retrieval-Augmented Generation (RAG) have\nrevolutionized natural language processing by integrating Large Language Models\n(LLMs) with external information retrieval, enabling accurate, up-to-date, and\nverifiable text generation across diverse applications. However, evaluating RAG\nsystems presents unique challenges due to their hybrid architecture that\ncombines retrieval and generation components, as well as their dependence on\ndynamic knowledge sources in the LLM era. In response, this paper provides a\ncomprehensive survey of RAG evaluation methods and frameworks, systematically\nreviewing traditional and emerging evaluation approaches, for system\nperformance, factual accuracy, safety, and computational efficiency in the LLM\nera. We also compile and categorize the RAG-specific datasets and evaluation\nframeworks, conducting a meta-analysis of evaluation practices in high-impact\nRAG research. To the best of our knowledge, this work represents the most\ncomprehensive survey for RAG evaluation, bridging traditional and LLM-driven\nmethods, and serves as a critical resource for advancing RAG development.", "published": "2025-04-21 06:39:47", "link": "http://arxiv.org/abs/2504.14891v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural Fingerprints of Large Language Models", "abstract": "Large language models (LLMs) often exhibit biases -- systematic deviations\nfrom expected norms -- in their outputs. These range from overt issues, such as\nunfair responses, to subtler patterns that can reveal which model produced\nthem. We investigate the factors that give rise to identifiable characteristics\nin LLMs. Since LLMs model training data distribution, it is reasonable that\ndifferences in training data naturally lead to the characteristics. However,\nour findings reveal that even when LLMs are trained on the exact same data, it\nis still possible to distinguish the source model based on its generated text.\nWe refer to these unintended, distinctive characteristics as natural\nfingerprints. By systematically controlling training conditions, we show that\nthe natural fingerprints can emerge from subtle differences in the training\nprocess, such as parameter sizes, optimization settings, and even random seeds.\nWe believe that understanding natural fingerprints offers new insights into the\norigins of unintended bias and ways for improving control over LLM behavior.", "published": "2025-04-21 05:48:52", "link": "http://arxiv.org/abs/2504.14871v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OTC: Optimal Tool Calls via Reinforcement Learning", "abstract": "Tool-integrated reasoning (TIR) augments large language models (LLMs) with\nthe ability to invoke external tools, such as search engines and code\ninterpreters, to solve tasks beyond the capabilities of language-only\nreasoning. While reinforcement learning (RL) has shown promise in improving TIR\nby optimizing final answer correctness, existing approaches often overlook the\nefficiency and cost associated with tool usage. This can lead to suboptimal\nbehavior, including excessive tool calls that increase computational and\nfinancial overhead, or insufficient tool use that compromises answer quality.\nIn this work, we propose Optimal Tool Call-controlled Policy Optimization\n(OTC-PO), a simple yet effective RL-based framework that encourages models to\nproduce accurate answers with minimal tool calls. Our method introduces a\ntool-integrated reward that jointly considers correctness and tool efficiency,\npromoting high tool productivity. We instantiate this framework within both\nProximal Policy Optimization (PPO) and Group Relative Preference Optimization\n(GRPO), resulting in OTC-PPO and OTC-GRPO. Experiments with Qwen-2.5 and\nQwen-Math across multiple QA benchmarks show that our approach reduces tool\ncalls by up to 73.1\\% and improves tool productivity by up to 229.4\\%, while\nmaintaining comparable answer accuracy. To the best of our knowledge, this is\nthe first RL-based framework that explicitly optimizes tool-use efficiency in\nTIR.", "published": "2025-04-21 05:40:05", "link": "http://arxiv.org/abs/2504.14870v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "AlignRAG: An Adaptable Framework for Resolving Misalignments in Retrieval-Aware Reasoning of RAG", "abstract": "Retrieval-augmented generation (RAG) has emerged as a foundational paradigm\nfor knowledge-grounded text generation. However, existing RAG pipelines often\nfail to ensure that the reasoning trajectories align with the evidential\nconstraints imposed by retrieved content. In this paper, we reframe RAG as a\nproblem of retrieval-aware reasoning and identify a core challenge: reasoning\nmisalignment-the mismatch between a model's reasoning trajectory and the\nretrieved evidence. To address this challenge, we propose AlignRAG, a novel\ntest-time framework that mitigates reasoning misalignment through iterative\nCritique-Driven Alignment (CDA) steps. In contrast to prior approaches that\nrely on static training or post-hoc selection, AlignRAG actively refines\nreasoning trajectories during inference by enforcing fine-grained alignment\nwith evidence. Our framework introduces a new paradigm for retrieval-aware\nreasoning by: (1) constructing context-rich training corpora; (2) generating\ncontrastive critiques from preference-aware reasoning trajectories; (3)\ntraining a dedicated \\textit{Critic Language Model (CLM)} to identify reasoning\nmisalignments; and (4) applying CDA steps to optimize reasoning trajectories\niteratively. Empirical results demonstrate that AlignRAG consistently\noutperforms all baselines and could integrate as a plug-and-play module into\nexisting RAG pipelines without further changes. By reconceptualizing RAG as a\nstructured reasoning trajectory and establishing the test-time framework for\ncorrecting reasoning misalignments in RAG, AlignRAG provides practical\nadvancements for retrieval-aware generation.", "published": "2025-04-21 04:56:47", "link": "http://arxiv.org/abs/2504.14858v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Transparentize the Internal and External Knowledge Utilization in LLMs with Trustworthy Citation", "abstract": "While hallucinations of large language models could been alleviated through\nretrieval-augmented generation and citation generation, how the model utilizes\ninternal knowledge is still opaque, and the trustworthiness of its generated\nanswers remains questionable. In this work, we introduce Context-Prior\nAugmented Citation Generation task, requiring models to generate citations\nconsidering both external and internal knowledge while providing trustworthy\nreferences, with 5 evaluation metrics focusing on 3 aspects: answer\nhelpfulness, citation faithfulness, and trustworthiness. We introduce RAEL, the\nparadigm for our task, and also design INTRALIGN, an integrated method\ncontaining customary data generation and an alignment algorithm. Our\nexperimental results show that our method achieves a better cross-scenario\nperformance with regard to other baselines. Our extended experiments further\nreveal that retrieval quality, question types, and model knowledge have\nconsiderable influence on the trustworthiness in citation generation.", "published": "2025-04-21 04:50:16", "link": "http://arxiv.org/abs/2504.14856v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Completing A Systematic Review in Hours instead of Months with Interactive AI Agents", "abstract": "Systematic reviews (SRs) are vital for evidence-based practice in high stakes\ndisciplines, such as healthcare, but are often impeded by intensive labors and\nlengthy processes that can take months to complete. Due to the high demand for\ndomain expertise, existing automatic summarization methods fail to accurately\nidentify relevant studies and generate high-quality summaries. To that end, we\nintroduce InsightAgent, a human-centered interactive AI agent powered by large\nlanguage models that revolutionize this workflow. InsightAgent partitions a\nlarge literature corpus based on semantics and employs a multi-agent design for\nmore focused processing of literature, leading to significant improvement in\nthe quality of generated SRs. InsightAgent also provides intuitive\nvisualizations of the corpus and agent trajectories, allowing users to\neffortlessly monitor the actions of the agent and provide real-time feedback\nbased on their expertise. Our user studies with 9 medical professionals\ndemonstrate that the visualization and interaction mechanisms can effectively\nimprove the quality of synthesized SRs by 27.2%, reaching 79.7% of\nhuman-written quality. At the same time, user satisfaction is improved by\n34.4%. With InsightAgent, it only takes a clinician about 1.5 hours, rather\nthan months, to complete a high-quality systematic review.", "published": "2025-04-21 02:57:23", "link": "http://arxiv.org/abs/2504.14822v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "On Self-improving Token Embeddings", "abstract": "This article introduces a novel and fast method for refining pre-trained\nstatic word or, more generally, token embeddings. By incorporating the\nembeddings of neighboring tokens in text corpora, it continuously updates the\nrepresentation of each token, including those without pre-assigned embeddings.\nThis approach effectively addresses the out-of-vocabulary problem, too.\nOperating independently of large language models and shallow neural networks,\nit enables versatile applications such as corpus exploration, conceptual\nsearch, and word sense disambiguation. The method is designed to enhance token\nrepresentations within topically homogeneous corpora, where the vocabulary is\nrestricted to a specific domain, resulting in more meaningful embeddings\ncompared to general-purpose pre-trained vectors. As an example, the methodology\nis applied to explore storm events and their impacts on infrastructure and\ncommunities using narratives from a subset of the NOAA Storm Events database.\nThe article also demonstrates how the approach improves the representation of\nstorm-related terms over time, providing valuable insights into the evolving\nnature of disaster narratives.", "published": "2025-04-21 02:17:19", "link": "http://arxiv.org/abs/2504.14808v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "68T50, 68T07", "I.2.6; I.2.7; H.3.3"], "primary_category": "cs.CL"}
{"title": "Automatic Evaluation Metrics for Document-level Translation: Overview, Challenges and Trends", "abstract": "With the rapid development of deep learning technologies, the field of\nmachine translation has witnessed significant progress, especially with the\nadvent of large language models (LLMs) that have greatly propelled the\nadvancement of document-level translation. However, accurately evaluating the\nquality of document-level translation remains an urgent issue. This paper first\nintroduces the development status of document-level translation and the\nimportance of evaluation, highlighting the crucial role of automatic evaluation\nmetrics in reflecting translation quality and guiding the improvement of\ntranslation systems. It then provides a detailed analysis of the current state\nof automatic evaluation schemes and metrics, including evaluation methods with\nand without reference texts, as well as traditional metrics, Model-based\nmetrics and LLM-based metrics. Subsequently, the paper explores the challenges\nfaced by current evaluation methods, such as the lack of reference diversity,\ndependence on sentence-level alignment information, and the bias, inaccuracy,\nand lack of interpretability of the LLM-as-a-judge method. Finally, the paper\nlooks ahead to the future trends in evaluation methods, including the\ndevelopment of more user-friendly document-level evaluation methods and more\nrobust LLM-as-a-judge methods, and proposes possible research directions, such\nas reducing the dependency on sentence-level information, introducing\nmulti-level and multi-granular evaluation approaches, and training models\nspecifically for machine translation evaluation. This study aims to provide a\ncomprehensive analysis of automatic evaluation for document-level translation\nand offer insights into future developments.", "published": "2025-04-21 02:08:42", "link": "http://arxiv.org/abs/2504.14804v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PLANET: A Collection of Benchmarks for Evaluating LLMs' Planning Capabilities", "abstract": "Planning is central to agents and agentic AI. The ability to plan, e.g.,\ncreating travel itineraries within a budget, holds immense potential in both\nscientific and commercial contexts. Moreover, optimal plans tend to require\nfewer resources compared to ad-hoc methods. To date, a comprehensive\nunderstanding of existing planning benchmarks appears to be lacking. Without\nit, comparing planning algorithms' performance across domains or selecting\nsuitable algorithms for new scenarios remains challenging. In this paper, we\nexamine a range of planning benchmarks to identify commonly used testbeds for\nalgorithm development and highlight potential gaps. These benchmarks are\ncategorized into embodied environments, web navigation, scheduling, games and\npuzzles, and everyday task automation. Our study recommends the most\nappropriate benchmarks for various algorithms and offers insights to guide\nfuture benchmark development.", "published": "2025-04-21 00:02:50", "link": "http://arxiv.org/abs/2504.14773v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning", "abstract": "Process reward models (PRMs) have proven effective for test-time scaling of\nLarge Language Models (LLMs) on challenging reasoning tasks. However, reward\nhacking issues with PRMs limit their successful application in reinforcement\nfine-tuning. In this paper, we identify the main cause of PRM-induced reward\nhacking: the canonical summation-form credit assignment in reinforcement\nlearning (RL), which defines the value as cumulative gamma-decayed future\nrewards, easily induces LLMs to hack steps with high rewards. To address this,\nwe propose PURE: Process sUpervised Reinforcement lEarning. The key innovation\nof PURE is a min-form credit assignment that formulates the value function as\nthe minimum of future rewards. This method significantly alleviates reward\nhacking by limiting the value function range and distributing advantages more\nreasonably. Through extensive experiments on 3 base models, we show that\nPRM-based approaches enabling min-form credit assignment achieve comparable\nreasoning performance to verifiable reward-based methods within only 30% steps.\nIn contrast, the canonical sum-form credit assignment collapses training even\nat the beginning! Additionally, when we supplement PRM-based fine-tuning with\njust 10% verifiable rewards, we further alleviate reward hacking and produce\nthe best fine-tuned model based on Qwen2.5-Math-7B in our experiments,\nachieving 82.5% accuracy on AMC23 and 53.3% average accuracy across 5\nbenchmarks. Moreover, we summarize the observed reward hacking cases and\nanalyze the causes of training collapse. Code and models are available at\nhttps://github.com/CJReinforce/PURE.", "published": "2025-04-21 17:59:02", "link": "http://arxiv.org/abs/2504.15275v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Leveraging Language Models for Automated Patient Record Linkage", "abstract": "Objective: Healthcare data fragmentation presents a major challenge for\nlinking patient data, necessitating robust record linkage to integrate patient\nrecords from diverse sources. This study investigates the feasibility of\nleveraging language models for automated patient record linkage, focusing on\ntwo key tasks: blocking and matching. Materials and Methods: We utilized\nreal-world healthcare data from the Missouri Cancer Registry and Research\nCenter, linking patient records from two independent sources using\nprobabilistic linkage as a baseline. A transformer-based model, RoBERTa, was\nfine-tuned for blocking using sentence embeddings. For matching, several\nlanguage models were experimented under fine-tuned and zero-shot settings,\nassessing their performance against ground truth labels. Results: The\nfine-tuned blocking model achieved a 92% reduction in the number of candidate\npairs while maintaining near-perfect recall. In the matching task, fine-tuned\nMistral-7B achieved the best performance with only 6 incorrect predictions.\nAmong zero-shot models, Mistral-Small-24B performed best, with a total of 55\nincorrect predictions. Discussion: Fine-tuned language models achieved strong\nperformance in patient record blocking and matching with minimal errors.\nHowever, they remain less accurate and efficient than a hybrid rule-based and\nprobabilistic approach for blocking. Additionally, reasoning models like\nDeepSeek-R1 are impractical for large-scale record linkage due to high\ncomputational costs. Conclusion: This study highlights the potential of\nlanguage models for automating patient record linkage, offering improved\nefficiency by eliminating the manual efforts required to perform patient record\nlinkage. Overall, language models offer a scalable solution that can enhance\ndata integration, reduce manual effort, and support disease surveillance and\nresearch.", "published": "2025-04-21 17:41:15", "link": "http://arxiv.org/abs/2504.15261v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Bringing Diversity from Diffusion Models to Semantic-Guided Face Asset Generation", "abstract": "Digital modeling and reconstruction of human faces serve various\napplications. However, its availability is often hindered by the requirements\nof data capturing devices, manual labor, and suitable actors. This situation\nrestricts the diversity, expressiveness, and control over the resulting models.\nThis work aims to demonstrate that a semantically controllable generative\nnetwork can provide enhanced control over the digital face modeling process. To\nenhance diversity beyond the limited human faces scanned in a controlled\nsetting, we introduce a novel data generation pipeline that creates a\nhigh-quality 3D face database using a pre-trained diffusion model. Our proposed\nnormalization module converts synthesized data from the diffusion model into\nhigh-quality scanned data. Using the 44,000 face models we obtained, we further\ndeveloped an efficient GAN-based generator. This generator accepts semantic\nattributes as input, and generates geometry and albedo. It also allows\ncontinuous post-editing of attributes in the latent space. Our asset refinement\ncomponent subsequently creates physically-based facial assets. We introduce a\ncomprehensive system designed for creating and editing high-quality face\nassets. Our proposed model has undergone extensive experiment, comparison and\nevaluation. We also integrate everything into a web-based interactive tool. We\naim to make this tool publicly available with the release of the paper.", "published": "2025-04-21 17:38:50", "link": "http://arxiv.org/abs/2504.15259v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "FlowReasoner: Reinforcing Query-Level Meta-Agents", "abstract": "This paper proposes a query-level meta-agent named FlowReasoner to automate\nthe design of query-level multi-agent systems, i.e., one system per user query.\nOur core idea is to incentivize a reasoning-based meta-agent via external\nexecution feedback. Concretely, by distilling DeepSeek R1, we first endow the\nbasic reasoning ability regarding the generation of multi-agent systems to\nFlowReasoner. Then, we further enhance it via reinforcement learning (RL) with\nexternal execution feedback. A multi-purpose reward is designed to guide the RL\ntraining from aspects of performance, complexity, and efficiency. In this\nmanner, FlowReasoner is enabled to generate a personalized multi-agent system\nfor each user query via deliberative reasoning. Experiments on both engineering\nand competition code benchmarks demonstrate the superiority of FlowReasoner.\nRemarkably, it surpasses o1-mini by 10.52% accuracy across three benchmarks.\nThe code is available at https://github.com/sail-sg/FlowReasoner.", "published": "2025-04-21 17:35:42", "link": "http://arxiv.org/abs/2504.15257v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SuoiAI: Building a Dataset for Aquatic Invertebrates in Vietnam", "abstract": "Understanding and monitoring aquatic biodiversity is critical for ecological\nhealth and conservation efforts. This paper proposes SuoiAI, an end-to-end\npipeline for building a dataset of aquatic invertebrates in Vietnam and\nemploying machine learning (ML) techniques for species classification. We\noutline the methods for data collection, annotation, and model training,\nfocusing on reducing annotation effort through semi-supervised learning and\nleveraging state-of-the-art object detection and classification models. Our\napproach aims to overcome challenges such as data scarcity, fine-grained\nclassification, and deployment in diverse environmental conditions.", "published": "2025-04-21 17:33:02", "link": "http://arxiv.org/abs/2504.15252v1", "categories": ["cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A Self-Improving Coding Agent", "abstract": "We demonstrate that an LLM coding agent, equipped with basic coding tools,\ncan autonomously edit itself, and thereby improve its performance on benchmark\ntasks. We find performance gains from 17% to 53% on a random subset of SWE\nBench Verified, with additional performance gains on LiveCodeBench, as well as\nsynthetically generated agent benchmarks. Our work represents an advancement in\nthe automated and open-ended design of agentic systems, and provides a\nreference agent framework for those seeking to post-train LLMs on tool use and\nother agentic tasks.", "published": "2025-04-21 16:58:18", "link": "http://arxiv.org/abs/2504.15228v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Genetic Fuzzy-Enabled Framework on Robotic Manipulation for In-Space Servicing", "abstract": "Automation of robotic systems for servicing in cislunar space is becoming\nextremely important as the number of satellites in orbit increases. Safety is\ncritical in performing satellite maintenance, so the control techniques\nutilized must be trusted in addition to being highly efficient. In this work,\nGenetic Fuzzy Trees are combined with the widely used LQR control scheme via\nThales' TrUE AI Toolkit to create a trusted and efficient controller for a\ntwo-degree-of-freedom planar robotic manipulator that would theoretically be\nused to perform satellite maintenance. It was found that Genetic Fuzzy-LQR is\n18.5% more performant than optimal LQR on average, and that it is incredibly\nrobust to uncertainty.", "published": "2025-04-21 16:57:56", "link": "http://arxiv.org/abs/2504.15226v1", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "M$^2$AD: Multi-Sensor Multi-System Anomaly Detection through Global Scoring and Calibrated Thresholding", "abstract": "With the widespread availability of sensor data across industrial and\noperational systems, we frequently encounter heterogeneous time series from\nmultiple systems. Anomaly detection is crucial for such systems to facilitate\npredictive maintenance. However, most existing anomaly detection methods are\ndesigned for either univariate or single-system multivariate data, making them\ninsufficient for these complex scenarios. To address this, we introduce\nM$^2$AD, a framework for unsupervised anomaly detection in multivariate time\nseries data from multiple systems. M$^2$AD employs deep models to capture\nexpected behavior under normal conditions, using the residuals as indicators of\npotential anomalies. These residuals are then aggregated into a global anomaly\nscore through a Gaussian Mixture Model and Gamma calibration. We theoretically\ndemonstrate that this framework can effectively address heterogeneity and\ndependencies across sensors and systems. Empirically, M$^2$AD outperforms\nexisting methods in extensive evaluations by 21% on average, and its\neffectiveness is demonstrated on a large-scale real-world case study on 130\nassets in Amazon Fulfillment Centers. Our code and results are available at\nhttps://github.com/sarahmish/M2AD.", "published": "2025-04-21 16:57:46", "link": "http://arxiv.org/abs/2504.15225v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Position: Bayesian Statistics Facilitates Stakeholder Participation in Evaluation of Generative AI", "abstract": "The evaluation of Generative AI (GenAI) systems plays a critical role in\npublic policy and decision-making, yet existing methods are often limited by\nreliance on benchmark-driven, point-estimate comparisons that fail to capture\nuncertainty and broader societal impacts. This paper argues for the use of\nBayesian statistics as a principled framework to address these challenges.\nBayesian methods enable the integration of domain expertise through prior\nelicitation, allow for continuous learning from new data, and provide robust\nuncertainty quantification via posterior inference. We demonstrate how Bayesian\ninference can be applied to GenAI evaluation, particularly in incorporating\nstakeholder perspectives to enhance fairness, transparency, and reliability.\nFurthermore, we discuss Bayesian workflows as an iterative process for model\nvalidation and refinement, ensuring robust assessments of GenAI systems in\ndynamic, real-world contexts.", "published": "2025-04-21 16:31:15", "link": "http://arxiv.org/abs/2504.15211v1", "categories": ["cs.AI", "stat.AP"], "primary_category": "cs.AI"}
{"title": "Integrating Symbolic Execution into the Fine-Tuning of Code-Generating LLMs", "abstract": "Code-generating Large Language Models (LLMs) have become essential tools in\nmodern software development, enhancing productivity and accelerating\ndevelopment. This paper aims to investigate the fine-tuning of code-generating\nLLMs using Reinforcement Learning and Direct Preference Optimization, further\nimproving their performance. To achieve this, we enhance the training data for\nthe reward model with the help of symbolic execution techniques, ensuring more\ncomprehensive and objective data. With symbolic execution, we create a custom\ndataset that better captures the nuances in code evaluation. Our reward models,\nfine-tuned on this dataset, demonstrate significant improvements over the\nbaseline, CodeRL, in estimating the quality of generated code. Our\ncode-generating LLMs, trained with the help of reward model feedback, achieve\nsimilar results compared to the CodeRL benchmark.", "published": "2025-04-21 16:29:07", "link": "http://arxiv.org/abs/2504.15210v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "A Causal Convolutional Low-rank Representation Model for Imputation of Water Quality Data", "abstract": "The monitoring of water quality is a crucial part of environmental\nprotection, and a large number of monitors are widely deployed to monitor water\nquality. Due to unavoidable factors such as data acquisition breakdowns,\nsensors and communication failures, water quality monitoring data suffers from\nmissing values over time, resulting in High-Dimensional and Sparse (HDS) Water\nQuality Data (WQD). The simple and rough filling of the missing values leads to\ninaccurate results and affects the implementation of relevant measures.\nTherefore, this paper proposes a Causal convolutional Low-rank Representation\n(CLR) model for imputing missing WQD to improve the completeness of the WQD,\nwhich employs a two-fold idea: a) applying causal convolutional operation to\nconsider the temporal dependence of the low-rank representation, thus\nincorporating temporal information to improve the imputation accuracy; and b)\nimplementing a hyperparameters adaptation scheme to automatically adjust the\nbest hyperparameters during model training, thereby reducing the tedious manual\nadjustment of hyper-parameters. Experimental studies on three real-world water\nquality datasets demonstrate that the proposed CLR model is superior to some of\nthe existing state-of-the-art imputation models in terms of imputation accuracy\nand time cost, as well as indicating that the proposed model provides more\nreliable decision support for environmental monitoring.", "published": "2025-04-21 16:27:16", "link": "http://arxiv.org/abs/2504.15209v1", "categories": ["cs.LG", "cs.AI", "68T07 (Primary) 62M10, 65C60 (Secondary)", "I.2.7"], "primary_category": "cs.LG"}
{"title": "Compute-Optimal LLMs Provably Generalize Better With Scale", "abstract": "Why do larger language models generalize better? To investigate this\nquestion, we develop generalization bounds on the pretraining objective of\nlarge language models (LLMs) in the compute-optimal regime, as described by the\nChinchilla scaling laws. We introduce a novel, fully empirical Freedman-type\nmartingale concentration inequality that tightens existing bounds by accounting\nfor the variance of the loss function. This generalization bound can be\ndecomposed into three interpretable components: the number of parameters per\ntoken, the loss variance, and the quantization error at a fixed bitrate. As\ncompute-optimal language models are scaled up, the number of parameters per\ndata point remains constant; however, both the loss variance and the\nquantization error decrease, implying that larger models should have smaller\ngeneralization gaps. We examine why larger models tend to be more quantizable\nfrom an information theoretic perspective, showing that the rate at which they\ncan integrate new information grows more slowly than their capacity on the\ncompute-optimal frontier. From these findings we produce a scaling law for the\ngeneralization gap, with bounds that become predictably stronger with scale.", "published": "2025-04-21 16:26:56", "link": "http://arxiv.org/abs/2504.15208v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Zero-Shot, But at What Cost? Unveiling the Hidden Overhead of MILS's LLM-CLIP Framework for Image Captioning", "abstract": "MILS (Multimodal Iterative LLM Solver) is a recently published framework that\nclaims \"LLMs can see and hear without any training\" by leveraging an iterative,\nLLM-CLIP based approach for zero-shot image captioning. While this MILS\napproach demonstrates good performance, our investigation reveals that this\nsuccess comes at a hidden, substantial computational cost due to its expensive\nmulti-step refinement process. In contrast, alternative models such as BLIP-2\nand GPT-4V achieve competitive results through a streamlined, single-pass\napproach. We hypothesize that the significant overhead inherent in MILS's\niterative process may undermine its practical benefits, thereby challenging the\nnarrative that zero-shot performance can be attained without incurring heavy\nresource demands. This work is the first to expose and quantify the trade-offs\nbetween output quality and computational cost in MILS, providing critical\ninsights for the design of more efficient multimodal models.", "published": "2025-04-21 16:16:19", "link": "http://arxiv.org/abs/2504.15199v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.PF"], "primary_category": "cs.CV"}
{"title": "Breast density in MRI: an AI-based quantification and relationship to assessment in mammography", "abstract": "Mammographic breast density is a well-established risk factor for breast\ncancer. Recently there has been interest in breast MRI as an adjunct to\nmammography, as this modality provides an orthogonal and highly quantitative\nassessment of breast tissue. However, its 3D nature poses analytic challenges\nrelated to delineating and aggregating complex structures across slices. Here,\nwe applied an in-house machine-learning algorithm to assess breast density on\nnormal breasts in three MRI datasets. Breast density was consistent across\ndifferent datasets (0.104 - 0.114). Analysis across different age groups also\ndemonstrated strong consistency across datasets and confirmed a trend of\ndecreasing density with age as reported in previous studies. MR breast density\nwas correlated with mammographic breast density, although some notable\ndifferences suggest that certain breast density components are captured only on\nMRI. Future work will determine how to integrate MR breast density with current\ntools to improve future breast cancer risk prediction.", "published": "2025-04-21 16:01:51", "link": "http://arxiv.org/abs/2504.15192v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Synergistic Weak-Strong Collaboration by Aligning Preferences", "abstract": "Current Large Language Models (LLMs) excel in general reasoning yet struggle\nwith specialized tasks requiring proprietary or domain-specific knowledge.\nFine-tuning large models for every niche application is often infeasible due to\nblack-box constraints and high computational overhead. To address this, we\npropose a collaborative framework that pairs a specialized weak model with a\ngeneral strong model. The weak model, tailored to specific domains, produces\ninitial drafts and background information, while the strong model leverages its\nadvanced reasoning to refine these drafts, extending LLMs' capabilities to\ncritical yet specialized tasks. To optimize this collaboration, we introduce a\ncollaborative feedback to fine-tunes the weak model, which quantifies the\ninfluence of the weak model's contributions in the collaboration procedure and\nestablishes preference pairs to guide preference tuning of the weak model. We\nvalidate our framework through experiments on three domains. We find that the\ncollaboration significantly outperforms each model alone by leveraging\ncomplementary strengths. Moreover, aligning the weak model with the\ncollaborative preference further enhances overall performance.", "published": "2025-04-21 15:57:33", "link": "http://arxiv.org/abs/2504.15188v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Existing Industry Practice for the EU AI Act's General-Purpose AI Code of Practice Safety and Security Measures", "abstract": "This report provides a detailed comparison between the measures proposed in\nthe EU AI Act's General-Purpose AI (GPAI) Code of Practice (Third Draft) and\ncurrent practices adopted by leading AI companies. As the EU moves toward\nenforcing binding obligations for GPAI model providers, the Code of Practice\nwill be key to bridging legal requirements with concrete technical commitments.\nOur analysis focuses on the draft's Safety and Security section which is only\nrelevant for the providers of the most advanced models (Commitments II.1-II.16)\nand excerpts from current public-facing documents quotes that are relevant to\neach individual measure.\n  We systematically reviewed different document types - including companies'\nfrontier safety frameworks and model cards - from over a dozen companies,\nincluding OpenAI, Anthropic, Google DeepMind, Microsoft, Meta, Amazon, and\nothers. This report is not meant to be an indication of legal compliance nor\ndoes it take any prescriptive viewpoint about the Code of Practice or\ncompanies' policies. Instead, it aims to inform the ongoing dialogue between\nregulators and GPAI model providers by surfacing evidence of precedent.", "published": "2025-04-21 15:44:01", "link": "http://arxiv.org/abs/2504.15181v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "An Efficient Aerial Image Detection with Variable Receptive Fields", "abstract": "Aerial object detection using unmanned aerial vehicles (UAVs) faces critical\nchallenges including sub-10px targets, dense occlusions, and stringent\ncomputational constraints. Existing detectors struggle to balance accuracy and\nefficiency due to rigid receptive fields and redundant architectures. To\naddress these limitations, we propose Variable Receptive Field DETR (VRF-DETR),\na transformer-based detector incorporating three key components: 1) Multi-Scale\nContext Fusion (MSCF) module that dynamically recalibrates features through\nadaptive spatial attention and gated multi-scale fusion, 2) Gated Convolution\n(GConv) layer enabling parameter-efficient local-context modeling via depthwise\nseparable operations and dynamic gating, and 3) Gated Multi-scale Fusion (GMCF)\nBottleneck that hierarchically disentangles occluded objects through cascaded\nglobal-local interactions. Experiments on VisDrone2019 demonstrate VRF-DETR\nachieves 51.4\\% mAP\\textsubscript{50} and 31.8\\% mAP\\textsubscript{50:95} with\nonly 13.5M parameters. This work establishes a new efficiency-accuracy Pareto\nfrontier for UAV-based detection tasks.", "published": "2025-04-21 15:16:13", "link": "http://arxiv.org/abs/2504.15165v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Landmark-Free Preoperative-to-Intraoperative Registration in Laparoscopic Liver Resection", "abstract": "Liver registration by overlaying preoperative 3D models onto intraoperative\n2D frames can assist surgeons in perceiving the spatial anatomy of the liver\nclearly for a higher surgical success rate. Existing registration methods rely\nheavily on anatomical landmark-based workflows, which encounter two major\nlimitations: 1) ambiguous landmark definitions fail to provide efficient\nmarkers for registration; 2) insufficient integration of intraoperative liver\nvisual information in shape deformation modeling. To address these challenges,\nin this paper, we propose a landmark-free preoperative-to-intraoperative\nregistration framework utilizing effective self-supervised learning, termed\n\\ourmodel. This framework transforms the conventional 3D-2D workflow into a\n3D-3D registration pipeline, which is then decoupled into rigid and non-rigid\nregistration subtasks. \\ourmodel~first introduces a feature-disentangled\ntransformer to learn robust correspondences for recovering rigid\ntransformations. Further, a structure-regularized deformation network is\ndesigned to adjust the preoperative model to align with the intraoperative\nliver surface. This network captures structural correlations through geometry\nsimilarity modeling in a low-rank transformer network. To facilitate the\nvalidation of the registration performance, we also construct an in-vivo\nregistration dataset containing liver resection videos of 21 patients, called\n\\emph{P2I-LReg}, which contains 346 keyframes that provide a global view of the\nliver together with liver mask annotations and calibrated camera intrinsic\nparameters. Extensive experiments and user studies on both synthetic and\nin-vivo datasets demonstrate the superiority and potential clinical\napplicability of our method.", "published": "2025-04-21 14:55:57", "link": "http://arxiv.org/abs/2504.15152v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Behavioral Universe Network (BUN): A Behavioral Information-Based Framework for Complex Systems", "abstract": "Modern digital ecosystems feature complex, dynamic interactions among\nautonomous entities across diverse domains. Traditional models often separate\nagents and objects, lacking a unified foundation to capture their interactive\nbehaviors. This paper introduces the Behavioral Universe Network (BUN), a\ntheoretical framework grounded in the Agent-Interaction-Behavior (AIB)\nformalism. BUN treats subjects (active agents), objects (resources), and\nbehaviors (operations) as first-class entities, all governed by a shared\nBehavioral Information Base (BIB). We detail the AIB core concepts and\ndemonstrate how BUN leverages information-driven triggers, semantic enrichment,\nand adaptive rules to coordinate multi-agent systems. We highlight key\nbenefits: enhanced behavior analysis, strong adaptability, and cross-domain\ninteroperability. We conclude by positioning BUN as a promising foundation for\nnext-generation digital governance and intelligent applications.", "published": "2025-04-21 14:50:28", "link": "http://arxiv.org/abs/2504.15146v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "C2RUST-BENCH: A Minimized, Representative Dataset for C-to-Rust Transpilation Evaluation", "abstract": "Despite the effort in vulnerability detection over the last two decades,\nmemory safety vulnerabilities continue to be a critical problem. Recent reports\nsuggest that the key solution is to migrate to memory-safe languages. To this\nend, C-to-Rust transpilation becomes popular to resolve memory-safety issues in\nC programs. Recent works propose C-to-Rust transpilation frameworks; however, a\ncomprehensive evaluation dataset is missing. Although one solution is to put\ntogether a large enough dataset, this increases the analysis time in automated\nframeworks as well as in manual efforts for some cases. In this work, we build\na method to select functions from a large set to construct a minimized yet\nrepresentative dataset to evaluate the C-to-Rust transpilation. We propose\nC2RUST-BENCH that contains 2,905 functions, which are representative of\nC-to-Rust transpilation, selected from 15,503 functions of real-world programs.", "published": "2025-04-21 14:48:45", "link": "http://arxiv.org/abs/2504.15144v1", "categories": ["cs.CR", "cs.AI", "cs.PL"], "primary_category": "cs.CR"}
{"title": "Neural ATTF: A Scalable Solution to Lifelong Multi-Agent Path Planning", "abstract": "Multi-Agent Pickup and Delivery (MAPD) is a fundamental problem in robotics,\nparticularly in applications such as warehouse automation and logistics.\nExisting solutions often face challenges in scalability, adaptability, and\nefficiency, limiting their applicability in dynamic environments with real-time\nplanning requirements. This paper presents Neural ATTF (Adaptive Task Token\nFramework), a new algorithm that combines a Priority Guided Task Matching\n(PGTM) Module with Neural STA* (Space-Time A*), a data-driven path planning\nmethod. Neural STA* enhances path planning by enabling rapid exploration of the\nsearch space through guided learned heuristics and ensures collision avoidance\nunder dynamic constraints. PGTM prioritizes delayed agents and dynamically\nassigns tasks by prioritizing agents nearest to these tasks, optimizing both\ncontinuity and system throughput. Experimental evaluations against\nstate-of-the-art MAPD algorithms, including TPTS, CENTRAL, RMCA, LNS-PBS, and\nLNS-wPBS, demonstrate the superior scalability, solution quality, and\ncomputational efficiency of Neural ATTF. These results highlight the\nframework's potential for addressing the critical demands of complex,\nreal-world multi-agent systems operating in high-demand, unpredictable\nsettings.", "published": "2025-04-21 14:25:32", "link": "http://arxiv.org/abs/2504.15130v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "A General Infrastructure and Workflow for Quadrotor Deep Reinforcement Learning and Reality Deployment", "abstract": "Deploying robot learning methods to a quadrotor in unstructured outdoor\nenvironments is an exciting task. Quadrotors operating in real-world\nenvironments by learning-based methods encounter several challenges: a large\namount of simulator generated data required for training, strict demands for\nreal-time processing onboard, and the sim-to-real gap caused by dynamic and\nnoisy conditions. Current works have made a great breakthrough in applying\nlearning-based methods to end-to-end control of quadrotors, but rarely mention\nthe infrastructure system training from scratch and deploying to reality, which\nmakes it difficult to reproduce methods and applications. To bridge this gap,\nwe propose a platform that enables the seamless transfer of end-to-end deep\nreinforcement learning (DRL) policies. We integrate the training environment,\nflight dynamics control, DRL algorithms, the MAVROS middleware stack, and\nhardware into a comprehensive workflow and architecture that enables\nquadrotors' policies to be trained from scratch to real-world deployment in\nseveral minutes. Our platform provides rich types of environments including\nhovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and\nplanning in unknown environments, as a physical experiment benchmark. Through\nextensive empirical validation, we demonstrate the efficiency of proposed\nsim-to-real platform, and robust outdoor flight performance under real-world\nperturbations. Details can be found from our website\nhttps://emnavi.tech/AirGym/.", "published": "2025-04-21 14:25:23", "link": "http://arxiv.org/abs/2504.15129v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Contemplative Wisdom for Superalignment", "abstract": "As artificial intelligence (AI) improves, traditional alignment strategies\nmay falter in the face of unpredictable self-improvement, hidden subgoals, and\nthe sheer complexity of intelligent systems. Rather than externally\nconstraining behavior, we advocate designing AI with intrinsic morality built\ninto its cognitive architecture and world model. Inspired by contemplative\nwisdom traditions, we show how four axiomatic principles can instil a resilient\nWise World Model in AI systems. First, mindfulness enables self-monitoring and\nrecalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal\nfixation and relaxes rigid priors. Third, non-duality dissolves adversarial\nself-other boundaries. Fourth, boundless care motivates the universal reduction\nof suffering. We find that prompting AI to reflect on these principles improves\nperformance on the AILuminate Benchmark using GPT-4o, particularly when\ncombined. We offer detailed implementation strategies for state-of-the-art\nmodels, including contemplative architectures, constitutions, and reinforcement\nof chain-of-thought. For future systems, the active inference framework may\noffer the self-organizing and dynamic coupling capabilities needed to enact\nthese insights in embodied agents. This interdisciplinary approach offers a\nself-correcting and resilient alternative to prevailing brittle control\nschemes.", "published": "2025-04-21 14:20:49", "link": "http://arxiv.org/abs/2504.15125v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A triple-branch network for latent fingerprint enhancement guided by orientation fields and minutiae", "abstract": "Latent fingerprint enhancement is a critical step in the process of latent\nfingerprint identification. Existing deep learning-based enhancement methods\nstill fall short of practical application requirements, particularly in\nrestoring low-quality fingerprint regions. Recognizing that different regions\nof latent fingerprints require distinct enhancement strategies, we propose a\nTriple Branch Spatial Fusion Network (TBSFNet), which simultaneously enhances\ndifferent regions of the image using tailored strategies. Furthermore, to\nimprove the generalization capability of the network, we integrate orientation\nfield and minutiae-related modules into TBSFNet and introduce a Multi-Level\nFeature Guidance Network (MLFGNet). Experimental results on the MOLF and MUST\ndatasets demonstrate that MLFGNet outperforms existing enhancement algorithms.", "published": "2025-04-21 13:54:33", "link": "http://arxiv.org/abs/2504.15105v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "NeuGaze: Reshaping the future BCI", "abstract": "Traditional brain-computer interfaces (BCIs), reliant on costly\nelectroencephalography or invasive implants, struggle with complex\nhuman-computer interactions due to setup complexity and limited precision. We\npresent NeuGaze, a novel webcam-based system that leverages eye gaze, head\nmovements, and facial expressions to enable intuitive, real-time control using\nonly a standard 30 Hz webcam, often pre-installed in laptops. Requiring minimal\ncalibration, NeuGaze achieves performance comparable to conventional inputs,\nsupporting precise cursor navigation, key triggering via an efficient skill\nwheel, and dynamic gaming interactions, such as defeating formidable opponents\nin first-person games. By harnessing preserved neck-up functionalities in\nmotor-impaired individuals, NeuGaze eliminates the need for specialized\nhardware, offering a low-cost, accessible alternative to BCIs. This paradigm\nempowers diverse applications, from assistive technology to entertainment,\nredefining human-computer interaction for motor-impaired users. Project is at\n\\href{https://github.com/NeuSpeech/NeuGaze}{github.com/NeuSpeech/NeuGaze}.", "published": "2025-04-21 13:49:17", "link": "http://arxiv.org/abs/2504.15101v1", "categories": ["cs.HC", "cs.AI", "cs.ET"], "primary_category": "cs.HC"}
{"title": "Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training of GAN", "abstract": "Up to now, the training processes of typical Generative Adversarial Networks\n(GANs) are still particularly sensitive to data properties and hyperparameters,\nwhich may lead to severe oscillations, difficulties in convergence, or even\nfailures to converge, especially when the overall variances of the training\nsets are large. These phenomena are often attributed to the training\ncharacteristics of such networks. Aiming at the problem, this paper develops a\nnew intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which\nemploys reinforcement learning in the training process of GANs to make training\neasier. Specifically, this paper allows the training step size to be controlled\nby an agent to improve training stability, and makes the training process more\nintelligent with variable learning rates, making GANs less sensitive to step\nsize. Experiments have been conducted on three benchmark datasets to verify the\neffectiveness of the developed FSCO.", "published": "2025-04-21 13:41:09", "link": "http://arxiv.org/abs/2504.15099v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Federated Latent Factor Model for Bias-Aware Recommendation with Privacy-Preserving", "abstract": "A recommender system (RS) aims to provide users with personalized item\nrecommendations, enhancing their overall experience. Traditional RSs collect\nand process all user data on a central server. However, this centralized\napproach raises significant privacy concerns, as it increases the risk of data\nbreaches and privacy leakages, which are becoming increasingly unacceptable to\nprivacy-sensitive users. To address these privacy challenges, federated\nlearning has been integrated into RSs, ensuring that user data remains secure.\nIn centralized RSs, the issue of rating bias is effectively addressed by\njointly analyzing all users' raw interaction data. However, this becomes a\nsignificant challenge in federated RSs, as raw data is no longer accessible due\nto privacy-preserving constraints. To overcome this problem, we propose a\nFederated Bias-Aware Latent Factor (FBALF) model. In FBALF, training bias is\nexplicitly incorporated into every local model's loss function, allowing for\nthe effective elimination of rating bias without compromising data privacy.\nExtensive experiments conducted on three real-world datasets demonstrate that\nFBALF achieves significantly higher recommendation accuracy compared to other\nstate-of-the-art federated RSs.", "published": "2025-04-21 13:24:30", "link": "http://arxiv.org/abs/2504.15090v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Empowering AI to Generate Better AI Code: Guided Generation of Deep Learning Projects with LLMs", "abstract": "While large language models (LLMs) have been widely applied to code\ngeneration, they struggle with generating entire deep learning projects, which\nare characterized by complex structures, longer functions, and stronger\nreliance on domain knowledge than general-purpose code. An open-domain LLM\noften lacks coherent contextual guidance and domain expertise for specific\nprojects, making it challenging to produce complete code that fully meets user\nrequirements.\n  In this paper, we propose a novel planning-guided code generation method,\nDLCodeGen, tailored for generating deep learning projects. DLCodeGen predicts a\nstructured solution plan, offering global guidance for LLMs to generate the\nproject. The generated plan is then leveraged to retrieve semantically\nanalogous code samples and subsequently abstract a code template. To\neffectively integrate these multiple retrieval-augmented techniques, a\ncomparative learning mechanism is designed to generate the final code. We\nvalidate the effectiveness of our approach on a dataset we build for deep\nlearning code generation. Experimental results demonstrate that DLCodeGen\noutperforms other baselines, achieving improvements of 9.7% in CodeBLEU and\n3.6% in human evaluation metrics.", "published": "2025-04-21 13:09:25", "link": "http://arxiv.org/abs/2504.15080v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Mitigating Degree Bias in Graph Representation Learning with Learnable Structural Augmentation and Structural Self-Attention", "abstract": "Graph Neural Networks (GNNs) update node representations through message\npassing, which is primarily based on the homophily principle, assuming that\nadjacent nodes share similar features. However, in real-world graphs with\nlong-tailed degree distributions, high-degree nodes dominate message passing,\ncausing a degree bias where low-degree nodes remain under-represented due to\ninadequate messages. The main challenge in addressing degree bias is how to\ndiscover non-adjacent nodes to provide additional messages to low-degree nodes\nwhile reducing excessive messages for high-degree nodes. Nevertheless,\nexploiting non-adjacent nodes to provide valuable messages is challenging, as\nit could generate noisy information and disrupt the original graph structures.\nTo solve it, we propose a novel Degree Fairness Graph Transformer, named\nDegFairGT, to mitigate degree bias by discovering structural similarities\nbetween non-adjacent nodes through learnable structural augmentation and\nstructural self-attention. Our key idea is to exploit non-adjacent nodes with\nsimilar roles in the same community to generate informative edges under our\naugmentation, which could provide informative messages between nodes with\nsimilar roles while ensuring that the homophily principle is maintained within\nthe community. To enable DegFairGT to learn such structural similarities, we\nthen propose a structural self-attention to capture the similarities between\nnode pairs. To preserve global graph structures and prevent graph augmentation\nfrom hindering graph structure, we propose a Self-Supervised Learning task to\npreserve p-step transition probability and regularize graph augmentation.\nExtensive experiments on six datasets showed that DegFairGT outperformed\nstate-of-the-art baselines in degree fairness analysis, node classification,\nand node clustering tasks.", "published": "2025-04-21 13:03:40", "link": "http://arxiv.org/abs/2504.15075v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Chinese-LiPS: A Chinese audio-visual speech recognition dataset with Lip-reading and Presentation Slides", "abstract": "Incorporating visual modalities to assist Automatic Speech Recognition (ASR)\ntasks has led to significant improvements. However, existing Audio-Visual\nSpeech Recognition (AVSR) datasets and methods typically rely solely on\nlip-reading information or speaking contextual video, neglecting the potential\nof combining these different valuable visual cues within the speaking context.\nIn this paper, we release a multimodal Chinese AVSR dataset, Chinese-LiPS,\ncomprising 100 hours of speech, video, and corresponding manual transcription,\nwith the visual modality encompassing both lip-reading information and the\npresentation slides used by the speaker. Based on Chinese-LiPS, we develop a\nsimple yet effective pipeline, LiPS-AVSR, which leverages both lip-reading and\npresentation slide information as visual modalities for AVSR tasks. Experiments\nshow that lip-reading and presentation slide information improve ASR\nperformance by approximately 8\\% and 25\\%, respectively, with a combined\nperformance improvement of about 35\\%. The dataset is available at\nhttps://kiri0824.github.io/Chinese-LiPS/", "published": "2025-04-21 12:51:54", "link": "http://arxiv.org/abs/2504.15066v1", "categories": ["cs.MM", "cs.AI"], "primary_category": "cs.MM"}
{"title": "Mining Characteristics of Vulnerable Smart Contracts Across Lifecycle Stages", "abstract": "Smart contracts are the cornerstone of decentralized applications and\nfinancial protocols, which extend the application of digital currency\ntransactions. The applications and financial protocols introduce significant\nsecurity challenges, resulting in substantial economic losses. Existing\nsolutions predominantly focus on code vulnerabilities within smart contracts,\naccounting for only 50% of security incidents. Therefore, a more comprehensive\nstudy of security issues related to smart contracts is imperative. The existing\nempirical research realizes the static analysis of smart contracts from the\nperspective of the lifecycle and gives the corresponding measures for each\nstage. However, they lack the characteristic analysis of vulnerabilities in\neach stage and the distinction between the vulnerabilities. In this paper, we\npresent the first empirical study on the security of smart contracts throughout\ntheir lifecycle, including deployment and execution, upgrade, and destruction\nstages. It delves into the security issues at each stage and provides at least\nseven feature descriptions. Finally, utilizing these seven features, five\nmachine-learning classification models are used to identify vulnerabilities at\ndifferent stages. The classification results reveal that vulnerable contracts\nexhibit distinct transaction features and ego network properties at various\nstages.", "published": "2025-04-21 12:42:59", "link": "http://arxiv.org/abs/2504.15063v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "OPO: Making Decision-Focused Data Acquisition Decisions", "abstract": "We propose a model for making data acquisition decisions for variables in\ncontextual stochastic optimisation problems. Data acquisition decisions are\ntypically treated as separate and fixed. We explore problem settings in which\nthe acquisition of contextual variables is costly and consequently constrained.\nThe data acquisition problem is often solved heuristically for proxy objectives\nsuch as coverage. The more intuitive objective is the downstream decision\nquality as a result of data acquisition decisions. The whole pipeline can be\ncharacterised as an optimise-then-predict-then-optimise (OPO) problem.\nAnalogously, much recent research has focused on how to integrate prediction\nand optimisation (PO) in the form of decision-focused learning. We propose\nleveraging differentiable optimisation to extend the integration to data\nacquisition. We solve the data acquisition problem with well-defined\nconstraints by learning a surrogate linear objective function. We demonstrate\nan application of this model on a shortest path problem for which we first have\nto set a drone reconnaissance strategy to capture image segments serving as\ninputs to a model that predicts travel costs. We ablate the problem with a\nnumber of training modalities and demonstrate that the differentiable\noptimisation approach outperforms random search strategies.", "published": "2025-04-21 12:41:35", "link": "http://arxiv.org/abs/2504.15062v1", "categories": ["math.OC", "cs.AI"], "primary_category": "math.OC"}
{"title": "VeLU: Variance-enhanced Learning Unit for Deep Neural Networks", "abstract": "Activation functions are fundamental in deep neural networks and directly\nimpact gradient flow, optimization stability, and generalization. Although ReLU\nremains standard because of its simplicity, it suffers from vanishing gradients\nand lacks adaptability. Alternatives like Swish and GELU introduce smooth\ntransitions, but fail to dynamically adjust to input statistics. We propose\nVeLU, a Variance-enhanced Learning Unit as an activation function that\ndynamically scales based on input variance by integrating ArcTan-Sin\ntransformations and Wasserstein-2 regularization, effectively mitigating\ncovariate shifts and stabilizing optimization. Extensive experiments on\nViT_B16, VGG19, ResNet50, DenseNet121, MobileNetV2, and EfficientNetB3 confirm\nVeLU's superiority over ReLU, ReLU6, Swish, and GELU on six vision benchmarks.\nThe codes of VeLU are publicly available on GitHub.", "published": "2025-04-21 12:20:46", "link": "http://arxiv.org/abs/2504.15051v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Text-to-Decision Agent: Learning Generalist Policies from Natural Language Supervision", "abstract": "RL systems usually tackle generalization by inferring task beliefs from\nhigh-quality samples or warmup explorations. The restricted form limits their\ngenerality and usability since these supervision signals are expensive and even\ninfeasible to acquire in advance for unseen tasks. Learning directly from the\nraw text about decision tasks is a promising alternative to leverage a much\nbroader source of supervision. In the paper, we propose Text-to-Decision Agent\n(T2DA), a simple and scalable framework that supervises generalist policy\nlearning with natural language. We first introduce a generalized world model to\nencode multi-task decision data into a dynamics-aware embedding space. Then,\ninspired by CLIP, we predict which textual description goes with which decision\nembedding, effectively bridging their semantic gap via contrastive\nlanguage-decision pre-training and aligning the text embeddings to comprehend\nthe environment dynamics. After training the text-conditioned generalist\npolicy, the agent can directly realize zero-shot text-to-decision generation in\nresponse to language instructions. Comprehensive experiments on MuJoCo and\nMeta-World benchmarks show that T2DA facilitates high-capacity zero-shot\ngeneralization and outperforms various types of baselines.", "published": "2025-04-21 12:00:20", "link": "http://arxiv.org/abs/2504.15046v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Beyond Terabit/s Integrated Neuromorphic Photonic Processor for DSP-Free Optical Interconnects", "abstract": "The rapid expansion of generative AI drives unprecedented demands for\nhigh-performance computing. Training large-scale AI models now requires vast\ninterconnected GPU clusters across multiple data centers. Multi-scale AI\ntraining and inference demand uniform, ultra-low latency, and energy-efficient\nlinks to enable massive GPUs to function as a single cohesive unit. However,\ntraditional electrical and optical interconnects, relying on conventional\ndigital signal processors (DSPs) for signal distortion compensation,\nincreasingly fail to meet these stringent requirements. To overcome these\nlimitations, we present an integrated neuromorphic optical signal processor\n(OSP) that leverages deep reservoir computing and achieves DSP-free,\nall-optical, real-time processing. Experimentally, our OSP achieves a 100 Gbaud\nPAM4 per lane, 1.6 Tbit/s data center interconnect over a 5 km optical fiber in\nthe C-band (equivalent to over 80 km in the O-band), far exceeding the reach of\nstate-of-the-art DSP solutions, which are fundamentally constrained by\nchromatic dispersion in IMDD systems. Simultaneously, it reduces processing\nlatency by four orders of magnitude and energy consumption by three orders of\nmagnitude. Unlike DSPs, which introduce increased latency at high data rates,\nour OSP maintains consistent, ultra-low latency regardless of data rate\nscaling, making it ideal for future optical interconnects. Moreover, the OSP\nretains full optical field information for better impairment compensation and\nadapts to various modulation formats, data rates, and wavelengths. Fabricated\nusing a mature silicon photonic process, the OSP can be monolithically\nintegrated with silicon photonic transceivers, enhancing the compactness and\nreliability of all-optical interconnects. This research provides a highly\nscalable, energy-efficient, and high-speed solution, paving the way for\nnext-generation AI infrastructure.", "published": "2025-04-21 11:56:36", "link": "http://arxiv.org/abs/2504.15044v1", "categories": ["physics.optics", "cs.AI", "cs.ET"], "primary_category": "physics.optics"}
{"title": "Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification", "abstract": "Lifelong Person Re-identification (LReID) suffers from a key challenge in\npreserving old knowledge while adapting to new information. The existing\nsolutions include rehearsal-based and rehearsal-free methods to address this\nchallenge. Rehearsal-based approaches rely on knowledge distillation,\ncontinuously accumulating forgetting during the distillation process.\nRehearsal-free methods insufficiently learn the distribution of each domain,\nleading to forgetfulness over time. To solve these issues, we propose a novel\nDistribution-aware Forgetting Compensation (DAFC) model that explores\ncross-domain shared representation learning and domain-specific distribution\nintegration without using old exemplars or knowledge distillation. We propose a\nText-driven Prompt Aggregation (TPA) that utilizes text features to enrich\nprompt elements and guide the prompt model to learn fine-grained\nrepresentations for each instance. This can enhance the differentiation of\nidentity information and establish the foundation for domain distribution\nawareness. Then, Distribution-based Awareness and Integration (DAI) is designed\nto capture each domain-specific distribution by a dedicated expert network and\nadaptively consolidate them into a shared region in high-dimensional space. In\nthis manner, DAI can consolidate and enhance cross-domain shared representation\nlearning while alleviating catastrophic forgetting. Furthermore, we develop a\nKnowledge Consolidation Mechanism (KCM) that comprises instance-level\ndiscrimination and cross-domain consistency alignment strategies to facilitate\nmodel adaptive learning of new knowledge from the current domain and promote\nknowledge consolidation learning between acquired domain-specific\ndistributions, respectively. Experimental results show that our DAFC outperform\nstate-of-the-art methods by at least 9.8\\%/6.6\\% and 6.4\\%/6.2\\% of average\nmAP/R@1 on two training orders.", "published": "2025-04-21 11:53:43", "link": "http://arxiv.org/abs/2504.15041v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank Adaptation", "abstract": "The accelerated advancement of speech generative models has given rise to\nsecurity issues, including model infringement and unauthorized abuse of\ncontent. Although existing generative watermarking techniques have proposed\ncorresponding solutions, most methods require substantial computational\noverhead and training costs. In addition, some methods have limitations in\nrobustness when handling variable-length inputs. To tackle these challenges, we\npropose \\textsc{SOLIDO}, a novel generative watermarking method that integrates\nparameter-efficient fine-tuning with speech watermarking through low-rank\nadaptation (LoRA) for speech diffusion models. Concretely, the watermark\nencoder converts the watermark to align with the input of diffusion models. To\nachieve precise watermark extraction from variable-length inputs, the watermark\ndecoder based on depthwise separable convolution is designed for watermark\nrecovery. To further enhance speech generation performance and watermark\nextraction capability, we propose a speech-driven lightweight fine-tuning\nstrategy, which reduces computational overhead through LoRA. Comprehensive\nexperiments demonstrate that the proposed method ensures high-fidelity\nwatermarked speech even at a large capacity of 2000 bps. Furthermore, against\ncommon individual and compound speech attacks, our SOLIDO achieves a maximum\naverage extraction accuracy of 99.20\\% and 98.43\\%, respectively. It surpasses\nother state-of-the-art methods by nearly 23\\% in resisting time-stretching\nattacks.", "published": "2025-04-21 11:43:36", "link": "http://arxiv.org/abs/2504.15035v1", "categories": ["cs.CR", "cs.AI", "cs.SD"], "primary_category": "cs.CR"}
{"title": "Trainable Quantum Neural Network for Multiclass Image Classification with the Power of Pre-trained Tree Tensor Networks", "abstract": "Tree tensor networks (TTNs) offer powerful models for image classification.\nWhile these TTN image classifiers already show excellent performance on\nclassical hardware, embedding them into quantum neural networks (QNNs) may\nfurther improve the performance by leveraging quantum resources. However,\nembedding TTN classifiers into QNNs for multiclass classification remains\nchallenging. Key obstacles are the highorder gate operations required for large\nbond dimensions and the mid-circuit postselection with exponentially low\nsuccess rates necessary for the exact embedding. In this work, to address these\nchallenges, we propose forest tensor network (FTN)-classifiers, which aggregate\nmultiple small-bond-dimension TTNs. This allows us to handle multiclass\nclassification without requiring large gates in the embedded circuits. We then\nremove the overhead of mid-circuit postselection by extending the adiabatic\nencoding framework to our setting and smoothly encode the FTN-classifiers into\na quantum forest tensor network (qFTN)- classifiers. Numerical experiments on\nMNIST and CIFAR-10 demonstrate that we can successfully train FTN-classifiers\nand encode them into qFTN-classifiers, while maintaining or even improving the\nperformance of the pre-trained FTN-classifiers. These results suggest that\nsynergy between TTN classification models and QNNs can provide a robust and\nscalable framework for multiclass quantum-enhanced image classification.", "published": "2025-04-21 09:51:39", "link": "http://arxiv.org/abs/2504.14995v1", "categories": ["quant-ph", "cs.AI", "cs.LG"], "primary_category": "quant-ph"}
{"title": "aiXamine: LLM Safety and Security Simplified", "abstract": "Evaluating Large Language Models (LLMs) for safety and security remains a\ncomplex task, often requiring users to navigate a fragmented landscape of ad\nhoc benchmarks, datasets, metrics, and reporting formats. To address this\nchallenge, we present aiXamine, a comprehensive black-box evaluation platform\nfor LLM safety and security. aiXamine integrates over 40 tests (i.e.,\nbenchmarks) organized into eight key services targeting specific dimensions of\nsafety and security: adversarial robustness, code security, fairness and bias,\nhallucination, model and data privacy, out-of-distribution (OOD) robustness,\nover-refusal, and safety alignment. The platform aggregates the evaluation\nresults into a single detailed report per model, providing a detailed breakdown\nof model performance, test examples, and rich visualizations. We used aiXamine\nto assess over 50 publicly available and proprietary LLMs, conducting over 2K\nexaminations. Our findings reveal notable vulnerabilities in leading models,\nincluding susceptibility to adversarial attacks in OpenAI's GPT-4o, biased\noutputs in xAI's Grok-3, and privacy weaknesses in Google's Gemini 2.0.\nAdditionally, we observe that open-source models can match or exceed\nproprietary models in specific services such as safety alignment, fairness and\nbias, and OOD robustness. Finally, we identify trade-offs between distillation\nstrategies, model size, training methods, and architectural choices.", "published": "2025-04-21 09:26:05", "link": "http://arxiv.org/abs/2504.14985v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Evaluating Code Generation of LLMs in Advanced Computer Science Problems", "abstract": "Large Language Models (LLMs), such as GitHub Copilot and ChatGPT have become\npopular among programming students. Students use LLMs to assist them in\nprogramming courses, including generating source code. Previous work has\nevaluated the ability of LLMs in solving introductory-course programming\nassignments. The results have shown that LLMs are highly effective in\ngenerating code for introductory Computer Science (CS) courses. However, there\nis a gap in research on evaluating LLMs' ability to generate code that solves\nadvanced programming assignments. In this work, we evaluate the ability of four\nLLM tools to solve programming assignments from advanced CS courses in three\npopular programming languages, Java, Python, and C. We manually select 12\nproblems, three problems from introductory courses as the baseline and nine\nprogramming assignments from second- and third-year CS courses. To evaluate the\nLLM-generated code, we generate a test suite of 1000 test cases per problem and\nanalyze the program output. Our evaluation shows that although LLMs are highly\neffective in generating source code for introductory programming courses,\nsolving advanced programming assignments is more challenging. Nonetheless, in\nmany cases, LLMs identify the base problem and provide partial solutions that\nmay be useful to CS students. Furthermore, our results may provide useful\nguidance for teachers of advanced programming courses on how to design\nprogramming assignments.", "published": "2025-04-21 08:45:23", "link": "http://arxiv.org/abs/2504.14964v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Generative Semantic Communications: Principles and Practices", "abstract": "Semantic communication leverages artificial intelligence (AI) technologies to\nextract semantic information from data for efficient transmission, theraby\nsignificantly reducing communication cost. With the evolution towards\nartificial general intelligence (AGI), the increasing demands for AGI services\npose new challenges to semantic communication. In response, we propose a new\nparadigm for AGI-driven communications, called generative semantic\ncommunication (GSC), which utilizes advanced AI technologies such as foundation\nmodels and generative models. We first describe the basic concept of GSC and\nits difference from existing semantic communications, and then introduce a\ngeneral framework of GSC, followed by two case studies to verify the advantages\nof GSC in AGI-driven applications. Finally, open challenges and new research\ndirections are discussed to stimulate this line of research and pave the way\nfor practical applications.", "published": "2025-04-21 08:10:59", "link": "http://arxiv.org/abs/2504.14947v1", "categories": ["cs.AI", "eess.IV", "eess.SP"], "primary_category": "cs.AI"}
{"title": "Giving AI a voice: how does AI think it should be treated?", "abstract": "With the astounding progress in (generative) artificial intelligence (AI),\nthere has been significant public discourse regarding regulation and ethics of\nthe technology. Is it sufficient when humans discuss this with other humans?\nOr, given that AI is increasingly becoming a viable source of inspiration for\npeople (and let alone the hypothetical possibility that the technology may at\nsome point become \"artificial general intelligence\" and/or develop\nconsciousness), should AI not join the discourse? There are new questions and\nangles that AI brings to the table that we might not have considered before -\nso let us make the key subject of this book an active participant. This chapter\ntherefore includes a brief human-AI conversation on the topic of AI rights and\nethics.", "published": "2025-04-21 07:59:17", "link": "http://arxiv.org/abs/2504.14936v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Fast Adversarial Training with Weak-to-Strong Spatial-Temporal Consistency in the Frequency Domain on Videos", "abstract": "Adversarial Training (AT) has been shown to significantly enhance adversarial\nrobustness via a min-max optimization approach. However, its effectiveness in\nvideo recognition tasks is hampered by two main challenges. First, fast\nadversarial training for video models remains largely unexplored, which\nseverely impedes its practical applications. Specifically, most video\nadversarial training methods are computationally costly, with long training\ntimes and high expenses. Second, existing methods struggle with the trade-off\nbetween clean accuracy and adversarial robustness. To address these challenges,\nwe introduce Video Fast Adversarial Training with Weak-to-Strong consistency\n(VFAT-WS), the first fast adversarial training method for video data.\nSpecifically, VFAT-WS incorporates the following key designs: First, it\nintegrates a straightforward yet effective temporal frequency augmentation\n(TF-AUG), and its spatial-temporal enhanced form STF-AUG, along with a\nsingle-step PGD attack to boost training efficiency and robustness. Second, it\ndevises a weak-to-strong spatial-temporal consistency regularization, which\nseamlessly integrates the simpler TF-AUG and the more complex STF-AUG.\nLeveraging the consistency regularization, it steers the learning process from\nsimple to complex augmentations. Both of them work together to achieve a better\ntrade-off between clean accuracy and robustness. Extensive experiments on\nUCF-101 and HMDB-51 with both CNN and Transformer-based models demonstrate that\nVFAT-WS achieves great improvements in adversarial robustness and corruption\nrobustness, while accelerating training by nearly 490%.", "published": "2025-04-21 07:40:35", "link": "http://arxiv.org/abs/2504.14921v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "StableQuant: Layer Adaptive Post-Training Quantization for Speech Foundation Models", "abstract": "In this paper, we propose StableQuant, a novel adaptive post-training\nquantization (PTQ) algorithm for widely used speech foundation models (SFMs).\nWhile PTQ has been successfully employed for compressing large language models\n(LLMs) due to its ability to bypass additional fine-tuning, directly applying\nthese techniques to SFMs may not yield optimal results, as SFMs utilize\ndistinct network architecture for feature extraction. StableQuant demonstrates\noptimal quantization performance regardless of the network architecture type,\nas it adaptively determines the quantization range for each layer by analyzing\nboth the scale distributions and overall performance. We evaluate our algorithm\non two SFMs, HuBERT and wav2vec2.0, for an automatic speech recognition (ASR)\ntask, and achieve superior performance compared to traditional PTQ methods.\nStableQuant successfully reduces the sizes of SFM models to a quarter and\ndoubles the inference speed while limiting the word error rate (WER)\nperformance drop to less than 0.3% with 8-bit quantization.", "published": "2025-04-21 07:33:27", "link": "http://arxiv.org/abs/2504.14915v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Guidelines for External Disturbance Factors in the Use of OCR in Real-World Environments", "abstract": "The performance of OCR has improved with the evolution of AI technology. As\nOCR continues to broaden its range of applications, the increased likelihood of\ninterference introduced by various usage environments can prevent it from\nachieving its inherent performance. This results in reduced recognition\naccuracy under certain conditions, and makes the quality control of recognition\ndevices more challenging. Therefore, to ensure that users can properly utilize\nOCR, we compiled the real-world external disturbance factors that cause\nperformance degradation, along with the resulting image degradation phenomena,\ninto an external disturbance factor table and, by also indicating how to make\nuse of it, organized them into guidelines.", "published": "2025-04-21 07:32:28", "link": "http://arxiv.org/abs/2504.14913v1", "categories": ["cs.CV", "cs.AI", "I.5.2; I.5.m"], "primary_category": "cs.CV"}
{"title": "Latent Bayesian Optimization via Autoregressive Normalizing Flows", "abstract": "Bayesian Optimization (BO) has been recognized for its effectiveness in\noptimizing expensive and complex objective functions. Recent advancements in\nLatent Bayesian Optimization (LBO) have shown promise by integrating generative\nmodels such as variational autoencoders (VAEs) to manage the complexity of\nhigh-dimensional and structured data spaces. However, existing LBO approaches\noften suffer from the value discrepancy problem, which arises from the\nreconstruction gap between input and latent spaces. This value discrepancy\nproblem propagates errors throughout the optimization process, leading to\nsuboptimal outcomes. To address this issue, we propose a Normalizing Flow-based\nBayesian Optimization (NF-BO), which utilizes normalizing flow as a generative\nmodel to establish one-to-one encoding function from the input space to the\nlatent space, along with its left-inverse decoding function, eliminating the\nreconstruction gap. Specifically, we introduce SeqFlow, an autoregressive\nnormalizing flow for sequence data. In addition, we develop a new candidate\nsampling strategy that dynamically adjusts the exploration probability for each\ntoken based on its importance. Through extensive experiments, our NF-BO method\ndemonstrates superior performance in molecule generation tasks, significantly\noutperforming both traditional and recent LBO approaches.", "published": "2025-04-21 06:36:09", "link": "http://arxiv.org/abs/2504.14889v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Impact of Latent Space Dimension on IoT Botnet Detection Performance: VAE-Encoder Versus ViT-Encoder", "abstract": "The rapid evolution of Internet of Things (IoT) technology has led to a\nsignificant increase in the number of IoT devices, applications, and services.\nThis surge in IoT devices, along with their widespread presence, has made them\na prime target for various cyber-attacks, particularly through IoT botnets. As\na result, security has become a major concern within the IoT ecosystem. This\nstudy focuses on investigating how the latent dimension impacts the performance\nof different deep learning classifiers when trained on latent vector\nrepresentations of the train dataset. The primary objective is to compare the\noutcomes of these models when encoder components from two cutting-edge\narchitectures: the Vision Transformer (ViT) and the Variational Auto-Encoder\n(VAE) are utilized to project the high dimensional train dataset to the learned\nlow dimensional latent space. The encoder components are employed to project\nhigh-dimensional structured .csv IoT botnet traffic datasets to various latent\nsizes. Evaluated on N-BaIoT and CICIoT2022 datasets, findings reveal that\nVAE-encoder based dimension reduction outperforms ViT-encoder based dimension\nreduction for both datasets in terms of four performance metrics including\naccuracy, precision, recall, and F1-score for all models which can be\nattributed to absence of spatial patterns in the datasets the ViT model\nattempts to learn and extract from image instances.", "published": "2025-04-21 06:15:07", "link": "http://arxiv.org/abs/2504.14879v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ReSpec: Relevance and Specificity Grounded Online Filtering for Learning on Video-Text Data Streams", "abstract": "The rapid growth of video-text data presents challenges in storage and\ncomputation during training. Online learning, which processes streaming data in\nreal-time, offers a promising solution to these issues while also allowing\nswift adaptations in scenarios demanding real-time responsiveness. One strategy\nto enhance the efficiency and effectiveness of learning involves identifying\nand prioritizing data that enhances performance on target downstream tasks. We\npropose Relevance and Specificity-based online filtering framework (ReSpec)\nthat selects data based on four criteria: (i) modality alignment for clean\ndata, (ii) task relevance for target focused data, (iii) specificity for\ninformative and detailed data, and (iv) efficiency for low-latency processing.\nRelevance is determined by the probabilistic alignment of incoming data with\ndownstream tasks, while specificity employs the distance to a root embedding\nrepresenting the least specific data as an efficient proxy for informativeness.\nBy establishing reference points from target task data, ReSpec filters incoming\ndata in real-time, eliminating the need for extensive storage and compute.\nEvaluating on large-scale datasets WebVid2M and VideoCC3M, ReSpec attains\nstate-of-the-art performance on five zeroshot video retrieval tasks, using as\nlittle as 5% of the data while incurring minimal compute. The source code is\navailable at https://github.com/cdjkim/ReSpec.", "published": "2025-04-21 06:02:03", "link": "http://arxiv.org/abs/2504.14875v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Bridge the Gap: From Weak to Full Supervision for Temporal Action Localization with PseudoFormer", "abstract": "Weakly-supervised Temporal Action Localization (WTAL) has achieved notable\nsuccess but still suffers from a lack of temporal annotations, leading to a\nperformance and framework gap compared with fully-supervised methods. While\nrecent approaches employ pseudo labels for training, three key challenges:\ngenerating high-quality pseudo labels, making full use of different priors, and\noptimizing training methods with noisy labels remain unresolved. Due to these\nperspectives, we propose PseudoFormer, a novel two-branch framework that\nbridges the gap between weakly and fully-supervised Temporal Action\nLocalization (TAL). We first introduce RickerFusion, which maps all predicted\naction proposals to a global shared space to generate pseudo labels with better\nquality. Subsequently, we leverage both snippet-level and proposal-level labels\nwith different priors from the weak branch to train the regression-based model\nin the full branch. Finally, the uncertainty mask and iterative refinement\nmechanism are applied for training with noisy pseudo labels. PseudoFormer\nachieves state-of-the-art WTAL results on the two commonly used benchmarks,\nTHUMOS14 and ActivityNet1.3. Besides, extensive ablation studies demonstrate\nthe contribution of each component of our method.", "published": "2025-04-21 05:00:07", "link": "http://arxiv.org/abs/2504.14860v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Object-Level Verbalized Confidence Calibration in Vision-Language Models via Semantic Perturbation", "abstract": "Vision-language models (VLMs) excel in various multimodal tasks but\nfrequently suffer from poor calibration, resulting in misalignment between\ntheir verbalized confidence and response correctness. This miscalibration\nundermines user trust, especially when models confidently provide incorrect or\nfabricated information. In this work, we propose a novel Confidence Calibration\nthrough Semantic Perturbation (CSP) framework to improve the calibration of\nverbalized confidence for VLMs in response to object-centric queries. We first\nintroduce a perturbed dataset where Gaussian noise is applied to the key object\nregions to simulate visual uncertainty at different confidence levels,\nestablishing an explicit mapping between visual ambiguity and confidence\nlevels. We further enhance calibration through a two-stage training process\ncombining supervised fine-tuning on the perturbed dataset with subsequent\npreference optimization. Extensive experiments on popular benchmarks\ndemonstrate that our method significantly improves the alignment between\nverbalized confidence and response correctness while maintaining or enhancing\noverall task performance. These results highlight the potential of semantic\nperturbation as a practical tool for improving the reliability and\ninterpretability of VLMs.", "published": "2025-04-21 04:01:22", "link": "http://arxiv.org/abs/2504.14848v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Exploring $\\ell_0$ Sparsification for Inference-free Sparse Retrievers", "abstract": "With increasing demands for efficiency, information retrieval has developed a\nbranch of sparse retrieval, further advancing towards inference-free retrieval\nwhere the documents are encoded during indexing time and there is no\nmodel-inference for queries. Existing sparse retrieval models rely on FLOPS\nregularization for sparsification, while this mechanism was originally designed\nfor Siamese encoders, it is considered to be suboptimal in inference-free\nscenarios which is asymmetric. Previous attempts to adapt FLOPS for\ninference-free scenarios have been limited to rule-based methods, leaving the\npotential of sparsification approaches for inference-free retrieval models\nlargely unexplored. In this paper, we explore $\\ell_0$ inspired sparsification\nmanner for inference-free retrievers. Through comprehensive out-of-domain\nevaluation on the BEIR benchmark, our method achieves state-of-the-art\nperformance among inference-free sparse retrieval models and is comparable to\nleading Siamese sparse retrieval models. Furthermore, we provide insights into\nthe trade-off between retrieval effectiveness and computational efficiency,\ndemonstrating practical value for real-world applications.", "published": "2025-04-21 03:40:43", "link": "http://arxiv.org/abs/2504.14839v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Establishing Reliability Metrics for Reward Models in Large Language Models", "abstract": "The reward model (RM) that represents human preferences plays a crucial role\nin optimizing the outputs of large language models (LLMs), e.g., through\nreinforcement learning from human feedback (RLHF) or rejection sampling.\nHowever, a long challenge for RM is its uncertain reliability, i.e., LLM\noutputs with higher rewards may not align with actual human preferences.\nCurrently, there is a lack of a convincing metric to quantify the reliability\nof RMs. To bridge this gap, we propose the \\textit{\\underline{R}eliable at\n\\underline{$\\eta$}} (RETA) metric, which directly measures the reliability of\nan RM by evaluating the average quality (scored by an oracle) of the top $\\eta$\nquantile responses assessed by an RM. On top of RETA, we present an integrated\nbenchmarking pipeline that allows anyone to evaluate their own RM without\nincurring additional Oracle labeling costs. Extensive experimental studies\ndemonstrate the superior stability of RETA metric, providing solid evaluations\nof the reliability of various publicly available and proprietary RMs. When\ndealing with an unreliable RM, we can use the RETA metric to identify the\noptimal quantile from which to select the responses.", "published": "2025-04-21 03:39:33", "link": "http://arxiv.org/abs/2504.14838v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Protecting Your Voice: Temporal-aware Robust Watermarking", "abstract": "The rapid advancement of generative models has led to the synthesis of\nreal-fake ambiguous voices. To erase the ambiguity, embedding watermarks into\nthe frequency-domain features of synthesized voices has become a common\nroutine. However, the robustness achieved by choosing the frequency domain\noften comes at the expense of fine-grained voice features, leading to a loss of\nfidelity. Maximizing the comprehensive learning of time-domain features to\nenhance fidelity while maintaining robustness, we pioneer a\n\\textbf{\\underline{t}}emporal-aware\n\\textbf{\\underline{r}}ob\\textbf{\\underline{u}}st\nwat\\textbf{\\underline{e}}rmarking (\\emph{True}) method for protecting the\nspeech and singing voice.", "published": "2025-04-21 03:23:10", "link": "http://arxiv.org/abs/2504.14832v1", "categories": ["cs.CR", "cs.AI", "cs.SD"], "primary_category": "cs.CR"}
{"title": "ECViT: Efficient Convolutional Vision Transformer with Local-Attention and Multi-scale Stages", "abstract": "Vision Transformers (ViTs) have revolutionized computer vision by leveraging\nself-attention to model long-range dependencies. However, ViTs face challenges\nsuch as high computational costs due to the quadratic scaling of self-attention\nand the requirement of a large amount of training data. To address these\nlimitations, we propose the Efficient Convolutional Vision Transformer (ECViT),\na hybrid architecture that effectively combines the strengths of CNNs and\nTransformers. ECViT introduces inductive biases such as locality and\ntranslation invariance, inherent to Convolutional Neural Networks (CNNs) into\nthe Transformer framework by extracting patches from low-level features and\nenhancing the encoder with convolutional operations. Additionally, it\nincorporates local-attention and a pyramid structure to enable efficient\nmulti-scale feature extraction and representation. Experimental results\ndemonstrate that ECViT achieves an optimal balance between performance and\nefficiency, outperforming state-of-the-art models on various image\nclassification tasks while maintaining low computational and storage\nrequirements. ECViT offers an ideal solution for applications that prioritize\nhigh efficiency without compromising performance.", "published": "2025-04-21 03:00:17", "link": "http://arxiv.org/abs/2504.14825v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale", "abstract": "Diffusion models (DMs) have revolutionized text-to-image generation, enabling\nthe creation of highly realistic and customized images from text prompts. With\nthe rise of parameter-efficient fine-tuning (PEFT) techniques like LoRA, users\ncan now customize powerful pre-trained models using minimal computational\nresources. However, the widespread sharing of fine-tuned DMs on open platforms\nraises growing ethical and legal concerns, as these models may inadvertently or\ndeliberately generate sensitive or unauthorized content, such as copyrighted\nmaterial, private individuals, or harmful content. Despite the increasing\nregulatory attention on generative AI, there are currently no practical tools\nfor systematically auditing these models before deployment. In this paper, we\naddress the problem of concept auditing: determining whether a fine-tuned DM\nhas learned to generate a specific target concept. Existing approaches\ntypically rely on prompt-based input crafting and output-based image\nclassification but suffer from critical limitations, including prompt\nuncertainty, concept drift, and poor scalability. To overcome these challenges,\nwe introduce Prompt-Agnostic Image-Free Auditing (PAIA), a novel, model-centric\nconcept auditing framework. By treating the DM as the object of inspection,\nPAIA enables direct analysis of internal model behavior, bypassing the need for\noptimized prompts or generated images. We evaluate PAIA on 320 controlled model\nand 690 real-world community models sourced from a public DM sharing platform.\nPAIA achieves over 90% detection accuracy while reducing auditing time by\n18-40x compared to existing baselines. To our knowledge, PAIA is the first\nscalable and practical solution for pre-deployment concept auditing of\ndiffusion models, providing a practical foundation for safer and more\ntransparent diffusion model sharing.", "published": "2025-04-21 02:44:59", "link": "http://arxiv.org/abs/2504.14815v1", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV"], "primary_category": "cs.LG"}
{"title": "DONOD: Robust and Generalizable Instruction Fine-Tuning for LLMs via Model-Intrinsic Dataset Pruning", "abstract": "Ad-hoc instruction fine-tuning of large language models (LLMs) is widely\nadopted for domain-specific adaptation. While domain-specific supervised\nfine-tuning (SFT) is effective and efficient, it often weakens cross-domain\ngeneralization and struggles with noisy training data. To address these\nchallenges, we propose DONOD, a lightweight model-intrinsic data pruning\nmethod. Our approach evaluates data using two model-parameter-based metrics:\nDelta of Norm (DON), which captures the cumulative influence on model weights,\nand Norm of Delta (NOD), which quantifies weight instability. Moreover, by\nemploying the Technique for Order of Preference by Similarity to Ideal Solution\n(TOPSIS) algorithm, we effectively filter noisy, unlearnable, and\ngeneralization-harming samples without relying on auxiliary models during the\nSFT process. Experiments on mathematical tasks demonstrate that data selected\nby DONOD achieve superior fine-tuning efficiency and improved robustness\nagainst noisy data. By filtering out 70% of the full dataset, we improve\ntarget-domain accuracy by 14.90% and cross-domain accuracy by 5.67%. Meanwhile,\nour selected data present superior cross-architecture generalization. Data\npruned by smaller models (e.g., Llama 3.1-8B) generalize effectively on larger\nmodels (e.g., Llama 2-13B). Compared to existing related methodologies, DONOD\ndemonstrates comparable or superior performance while remaining\ndataset-agnostic, enabling broader applicability.", "published": "2025-04-21 02:25:03", "link": "http://arxiv.org/abs/2504.14810v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Dynamic Contrastive Skill Learning with State-Transition Based Skill Clustering and Dynamic Length Adjustment", "abstract": "Reinforcement learning (RL) has made significant progress in various domains,\nbut scaling it to long-horizon tasks with complex decision-making remains\nchallenging. Skill learning attempts to address this by abstracting actions\ninto higher-level behaviors. However, current approaches often fail to\nrecognize semantically similar behaviors as the same skill and use fixed skill\nlengths, limiting flexibility and generalization. To address this, we propose\nDynamic Contrastive Skill Learning (DCSL), a novel framework that redefines\nskill representation and learning. DCSL introduces three key ideas:\nstate-transition based skill representation, skill similarity function\nlearning, and dynamic skill length adjustment. By focusing on state transitions\nand leveraging contrastive learning, DCSL effectively captures the semantic\ncontext of behaviors and adapts skill lengths to match the appropriate temporal\nextent of behaviors. Our approach enables more flexible and adaptive skill\nextraction, particularly in complex or noisy datasets, and demonstrates\ncompetitive performance compared to existing methods in task completion and\nefficiency.", "published": "2025-04-21 02:11:39", "link": "http://arxiv.org/abs/2504.14805v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Automated Duplicate Bug Report Detection in Large Open Bug Repositories", "abstract": "Many users and contributors of large open-source projects report software\ndefects or enhancement requests (known as bug reports) to the issue-tracking\nsystems. However, they sometimes report issues that have already been reported.\nFirst, they may not have time to do sufficient research on existing bug\nreports. Second, they may not possess the right expertise in that specific area\nto realize that an existing bug report is essentially elaborating on the same\nmatter, perhaps with a different wording. In this paper, we propose a novel\napproach based on machine learning methods that can automatically detect\nduplicate bug reports in an open bug repository based on the textual data in\nthe reports. We present six alternative methods: Topic modeling, Gaussian Naive\nBayes, deep learning, time-based organization, clustering, and summarization\nusing a generative pre-trained transformer large language model. Additionally,\nwe introduce a novel threshold-based approach for duplicate identification, in\ncontrast to the conventional top-k selection method that has been widely used\nin the literature. Our approach demonstrates promising results across all the\nproposed methods, achieving accuracy rates ranging from the high 70%'s to the\nlow 90%'s. We evaluated our methods on a public dataset of issues belonging to\nan Eclipse open-source project.", "published": "2025-04-21 01:55:54", "link": "http://arxiv.org/abs/2504.14797v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "How Effective Can Dropout Be in Multiple Instance Learning ?", "abstract": "Multiple Instance Learning (MIL) is a popular weakly-supervised method for\nvarious applications, with a particular interest in histological whole slide\nimage (WSI) classification. Due to the gigapixel resolution of WSI,\napplications of MIL in WSI typically necessitate a two-stage training scheme:\nfirst, extract features from the pre-trained backbone and then perform MIL\naggregation. However, it is well-known that this suboptimal training scheme\nsuffers from \"noisy\" feature embeddings from the backbone and inherent weak\nsupervision, hindering MIL from learning rich and generalizable features.\nHowever, the most commonly used technique (i.e., dropout) for mitigating this\nissue has yet to be explored in MIL. In this paper, we empirically explore how\neffective the dropout can be in MIL. Interestingly, we observe that dropping\nthe top-k most important instances within a bag leads to better performance and\ngeneralization even under noise attack. Based on this key observation, we\npropose a novel MIL-specific dropout method, termed MIL-Dropout, which\nsystematically determines which instances to drop. Experiments on five MIL\nbenchmark datasets and two WSI datasets demonstrate that MIL-Dropout boosts the\nperformance of current MIL methods with a negligible computational cost. The\ncode is available at https://github.com/ChongQingNoSubway/MILDropout.", "published": "2025-04-21 00:46:31", "link": "http://arxiv.org/abs/2504.14783v1", "categories": ["cs.CV", "cs.AI", "eess.IV", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Exploring Collaborative GenAI Agents in Synchronous Group Settings: Eliciting Team Perceptions and Design Considerations for the Future of Work", "abstract": "While generative artificial intelligence (GenAI) is finding increased\nadoption in workplaces, current tools are primarily designed for individual\nuse. Prior work established the potential for these tools to enhance personal\ncreativity and productivity towards shared goals; however, we don't know yet\nhow to best take into account the nuances of group work and team dynamics when\ndeploying GenAI in work settings. In this paper, we investigate the potential\nof collaborative GenAI agents to augment teamwork in synchronous group settings\nthrough an exploratory study that engaged 25 professionals across 6 teams in\nspeculative design workshops and individual follow-up interviews. Our workshops\nincluded a mixed reality provotype to simulate embodied collaborative GenAI\nagents capable of actively participating in group discussions. Our findings\nsuggest that, if designed well, collaborative GenAI agents offer valuable\nopportunities to enhance team problem-solving by challenging groupthink,\nbridging communication gaps, and reducing social friction. However, teams'\nwillingness to integrate GenAI agents depended on its perceived fit across a\nnumber of individual, team, and organizational factors. We outline the key\ndesign tensions around agent representation, social prominence, and engagement\nand highlight the opportunities spatial and immersive technologies could offer\nto modulate GenAI influence on team outcomes and strike a balance between\naugmentation and agency.", "published": "2025-04-21 00:38:02", "link": "http://arxiv.org/abs/2504.14779v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "StyleMe3D: Stylization with Disentangled Priors by Multiple Encoders on 3D Gaussians", "abstract": "3D Gaussian Splatting (3DGS) excels in photorealistic scene reconstruction\nbut struggles with stylized scenarios (e.g., cartoons, games) due to fragmented\ntextures, semantic misalignment, and limited adaptability to abstract\naesthetics. We propose StyleMe3D, a holistic framework for 3D GS style transfer\nthat integrates multi-modal style conditioning, multi-level semantic alignment,\nand perceptual quality enhancement. Our key insights include: (1) optimizing\nonly RGB attributes preserves geometric integrity during stylization; (2)\ndisentangling low-, medium-, and high-level semantics is critical for coherent\nstyle transfer; (3) scalability across isolated objects and complex scenes is\nessential for practical deployment. StyleMe3D introduces four novel components:\nDynamic Style Score Distillation (DSSD), leveraging Stable Diffusion's latent\nspace for semantic alignment; Contrastive Style Descriptor (CSD) for localized,\ncontent-aware texture transfer; Simultaneously Optimized Scale (SOS) to\ndecouple style details and structural coherence; and 3D Gaussian Quality\nAssessment (3DG-QA), a differentiable aesthetic prior trained on human-rated\ndata to suppress artifacts and enhance visual harmony. Evaluated on NeRF\nsynthetic dataset (objects) and tandt db (scenes) datasets, StyleMe3D\noutperforms state-of-the-art methods in preserving geometric details (e.g.,\ncarvings on sculptures) and ensuring stylistic consistency across scenes (e.g.,\ncoherent lighting in landscapes), while maintaining real-time rendering. This\nwork bridges photorealistic 3D GS and artistic stylization, unlocking\napplications in gaming, virtual worlds, and digital art.", "published": "2025-04-21 17:59:55", "link": "http://arxiv.org/abs/2504.15281v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal Large Language Models", "abstract": "Visual reasoning is a core component of human intelligence and a critical\ncapability for advanced multimodal models. Yet current reasoning evaluations of\nmultimodal large language models (MLLMs) often rely on text descriptions and\nallow language-based reasoning shortcuts, failing to measure genuine\nvision-centric reasoning. To address this, we introduce VisuLogic: a benchmark\nof 1,000 human-verified problems across six categories (e.g., quantitative\nshifts, spatial relations, attribute comparisons). These various types of\nquestions can be evaluated to assess the visual reasoning capabilities of MLLMs\nfrom multiple perspectives. We evaluate leading MLLMs on this benchmark and\nanalyze their results to identify common failure modes. Most models score below\n30% accuracy-only slightly above the 25% random baseline and far below the\n51.4% achieved by humans-revealing significant gaps in visual reasoning.\nFurthermore, we provide a supplementary training dataset and a\nreinforcement-learning baseline to support further progress.", "published": "2025-04-21 17:59:53", "link": "http://arxiv.org/abs/2504.15279v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DRAWER: Digital Reconstruction and Articulation With Environment Realism", "abstract": "Creating virtual digital replicas from real-world data unlocks significant\npotential across domains like gaming and robotics. In this paper, we present\nDRAWER, a novel framework that converts a video of a static indoor scene into a\nphotorealistic and interactive digital environment. Our approach centers on two\nmain contributions: (i) a reconstruction module based on a dual scene\nrepresentation that reconstructs the scene with fine-grained geometric details,\nand (ii) an articulation module that identifies articulation types and hinge\npositions, reconstructs simulatable shapes and appearances and integrates them\ninto the scene. The resulting virtual environment is photorealistic,\ninteractive, and runs in real time, with compatibility for game engines and\nrobotic simulation platforms. We demonstrate the potential of DRAWER by using\nit to automatically create an interactive game in Unreal Engine and to enable\nreal-to-sim-to-real transfer for robotics applications.", "published": "2025-04-21 17:59:49", "link": "http://arxiv.org/abs/2504.15278v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models", "abstract": "We introduce Eagle 2.5, a family of frontier vision-language models (VLMs)\nfor long-context multimodal learning. Our work addresses the challenges in long\nvideo comprehension and high-resolution image understanding, introducing a\ngeneralist framework for both tasks. The proposed training framework\nincorporates Automatic Degrade Sampling and Image Area Preservation, two\ntechniques that preserve contextual integrity and visual details. The framework\nalso includes numerous efficiency optimizations in the pipeline for\nlong-context data training. Finally, we propose Eagle-Video-110K, a novel\ndataset that integrates both story-level and clip-level annotations,\nfacilitating long-video understanding. Eagle 2.5 demonstrates substantial\nimprovements on long-context multimodal benchmarks, providing a robust solution\nto the limitations of existing VLMs. Notably, our best model Eagle 2.5-8B\nachieves 72.4% on Video-MME with 512 input frames, matching the results of\ntop-tier commercial model such as GPT-4o and large-scale open-source models\nlike Qwen2.5-VL-72B and InternVL2.5-78B.", "published": "2025-04-21 17:57:28", "link": "http://arxiv.org/abs/2504.15271v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Diffusion Bridge Models for 3D Medical Image Translation", "abstract": "Diffusion tensor imaging (DTI) provides crucial insights into the\nmicrostructure of the human brain, but it can be time-consuming to acquire\ncompared to more readily available T1-weighted (T1w) magnetic resonance imaging\n(MRI). To address this challenge, we propose a diffusion bridge model for 3D\nbrain image translation between T1w MRI and DTI modalities. Our model learns to\ngenerate high-quality DTI fractional anisotropy (FA) images from T1w images and\nvice versa, enabling cross-modality data augmentation and reducing the need for\nextensive DTI acquisition. We evaluate our approach using perceptual\nsimilarity, pixel-level agreement, and distributional consistency metrics,\ndemonstrating strong performance in capturing anatomical structures and\npreserving information on white matter integrity. The practical utility of the\nsynthetic data is validated through sex classification and Alzheimer's disease\nclassification tasks, where the generated images achieve comparable performance\nto real data. Our diffusion bridge model offers a promising solution for\nimproving neuroimaging datasets and supporting clinical decision-making, with\nthe potential to significantly impact neuroimaging research and clinical\npractice.", "published": "2025-04-21 17:49:06", "link": "http://arxiv.org/abs/2504.15267v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields", "abstract": "Weak gravitational lensing is the slight distortion of galaxy shapes caused\nprimarily by the gravitational effects of dark matter in the universe. In our\nwork, we seek to invert the weak lensing signal from 2D telescope images to\nreconstruct a 3D map of the universe's dark matter field. While inversion\ntypically yields a 2D projection of the dark matter field, accurate 3D maps of\nthe dark matter distribution are essential for localizing structures of\ninterest and testing theories of our universe. However, 3D inversion poses\nsignificant challenges. First, unlike standard 3D reconstruction that relies on\nmultiple viewpoints, in this case, images are only observed from a single\nviewpoint. This challenge can be partially addressed by observing how galaxy\nemitters throughout the volume are lensed. However, this leads to the second\nchallenge: the shapes and exact locations of unlensed galaxies are unknown, and\ncan only be estimated with a very large degree of uncertainty. This introduces\nan overwhelming amount of noise which nearly drowns out the lensing signal\ncompletely. Previous approaches tackle this by imposing strong assumptions\nabout the structures in the volume. We instead propose a methodology using a\ngravitationally-constrained neural field to flexibly model the continuous\nmatter distribution. We take an analysis-by-synthesis approach, optimizing the\nweights of the neural network through a fully differentiable physical forward\nmodel to reproduce the lensing signal present in image measurements. We\nshowcase our method on simulations, including realistic simulated measurements\nof dark matter distributions that mimic data from upcoming telescope surveys.\nOur results show that our method can not only outperform previous methods, but\nimportantly is also able to recover potentially surprising dark matter\nstructures.", "published": "2025-04-21 17:43:21", "link": "http://arxiv.org/abs/2504.15262v1", "categories": ["astro-ph.CO", "cs.CV"], "primary_category": "astro-ph.CO"}
{"title": "Shape-Guided Clothing Warping for Virtual Try-On", "abstract": "Image-based virtual try-on aims to seamlessly fit in-shop clothing to a\nperson image while maintaining pose consistency. Existing methods commonly\nemploy the thin plate spline (TPS) transformation or appearance flow to deform\nin-shop clothing for aligning with the person's body. Despite their promising\nperformance, these methods often lack precise control over fine details,\nleading to inconsistencies in shape between clothing and the person's body as\nwell as distortions in exposed limb regions. To tackle these challenges, we\npropose a novel shape-guided clothing warping method for virtual try-on, dubbed\nSCW-VTON, which incorporates global shape constraints and additional limb\ntextures to enhance the realism and consistency of the warped clothing and\ntry-on results. To integrate global shape constraints for clothing warping, we\ndevise a dual-path clothing warping module comprising a shape path and a flow\npath. The former path captures the clothing shape aligned with the person's\nbody, while the latter path leverages the mapping between the pre- and\npost-deformation of the clothing shape to guide the estimation of appearance\nflow. Furthermore, to alleviate distortions in limb regions of try-on results,\nwe integrate detailed limb guidance by developing a limb reconstruction network\nbased on masked image modeling. Through the utilization of SCW-VTON, we are\nable to generate try-on results with enhanced clothing shape consistency and\nprecise control over details. Extensive experiments demonstrate the superiority\nof our approach over state-of-the-art methods both qualitatively and\nquantitatively. The code is available at https://github.com/xyhanHIT/SCW-VTON.", "published": "2025-04-21 17:08:36", "link": "http://arxiv.org/abs/2504.15232v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Automated Measurement of Eczema Severity with Self-Supervised Learning", "abstract": "Automated diagnosis of eczema using images acquired from digital camera can\nenable individuals to self-monitor their recovery. The process entails first\nsegmenting out the eczema region from the image and then measuring the severity\nof eczema in the segmented region. The state-of-the-art methods for automated\neczema diagnosis rely on deep neural networks such as convolutional neural\nnetwork (CNN) and have shown impressive performance in accurately measuring the\nseverity of eczema. However, these methods require massive volume of annotated\ndata to train which can be hard to obtain. In this paper, we propose a\nself-supervised learning framework for automated eczema diagnosis under limited\ntraining data regime. Our framework consists of two stages: i) Segmentation,\nwhere we use an in-context learning based algorithm called SegGPT for few-shot\nsegmentation of eczema region from the image; ii) Feature extraction and\nclassification, where we extract DINO features from the segmented regions and\nfeed it to a multi-layered perceptron (MLP) for 4-class classification of\neczema severity. When evaluated on a dataset of annotated \"in-the-wild\" eczema\nimages, we show that our method outperforms (Weighted F1: 0.67 $\\pm$ 0.01) the\nstate-of-the-art deep learning methods such as finetuned Resnet-18 (Weighted\nF1: 0.44 $\\pm$ 0.16) and Vision Transformer (Weighted F1: 0.40 $\\pm$ 0.22). Our\nresults show that self-supervised learning can be a viable solution for\nautomated skin diagnosis where labeled data is scarce.", "published": "2025-04-21 16:02:26", "link": "http://arxiv.org/abs/2504.15193v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Tiger200K: Manually Curated High Visual Quality Video Dataset from UGC Platform", "abstract": "The recent surge in open-source text-to-video generation models has\nsignificantly energized the research community, yet their dependence on\nproprietary training datasets remains a key constraint. While existing open\ndatasets like Koala-36M employ algorithmic filtering of web-scraped videos from\nearly platforms, they still lack the quality required for fine-tuning advanced\nvideo generation models. We present Tiger200K, a manually curated high visual\nquality video dataset sourced from User-Generated Content (UGC) platforms. By\nprioritizing visual fidelity and aesthetic quality, Tiger200K underscores the\ncritical role of human expertise in data curation, and providing high-quality,\ntemporally consistent video-text pairs for fine-tuning and optimizing video\ngeneration architectures through a simple but effective pipeline including shot\nboundary detection, OCR, border detecting, motion filter and fine bilingual\ncaption. The dataset will undergo ongoing expansion and be released as an\nopen-source initiative to advance research and applications in video generative\nmodels. Project page: https://tinytigerpan.github.io/tiger200k/", "published": "2025-04-21 15:44:06", "link": "http://arxiv.org/abs/2504.15182v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FaceCraft4D: Animated 3D Facial Avatar Generation from a Single Image", "abstract": "We present a novel framework for generating high-quality, animatable 4D\navatar from a single image. While recent advances have shown promising results\nin 4D avatar creation, existing methods either require extensive multiview data\nor struggle with shape accuracy and identity consistency. To address these\nlimitations, we propose a comprehensive system that leverages shape, image, and\nvideo priors to create full-view, animatable avatars. Our approach first\nobtains initial coarse shape through 3D-GAN inversion. Then, it enhances\nmultiview textures using depth-guided warping signals for cross-view\nconsistency with the help of the image diffusion model. To handle expression\nanimation, we incorporate a video prior with synchronized driving signals\nacross viewpoints. We further introduce a Consistent-Inconsistent training to\neffectively handle data inconsistencies during 4D reconstruction. Experimental\nresults demonstrate that our method achieves superior quality compared to the\nprior art, while maintaining consistency across different viewpoints and\nexpressions.", "published": "2025-04-21 15:40:14", "link": "http://arxiv.org/abs/2504.15179v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DSPO: Direct Semantic Preference Optimization for Real-World Image Super-Resolution", "abstract": "Recent advances in diffusion models have improved Real-World Image\nSuper-Resolution (Real-ISR), but existing methods lack human feedback\nintegration, risking misalignment with human preference and may leading to\nartifacts, hallucinations and harmful content generation. To this end, we are\nthe first to introduce human preference alignment into Real-ISR, a technique\nthat has been successfully applied in Large Language Models and Text-to-Image\ntasks to effectively enhance the alignment of generated outputs with human\npreferences. Specifically, we introduce Direct Preference Optimization (DPO)\ninto Real-ISR to achieve alignment, where DPO serves as a general alignment\ntechnique that directly learns from the human preference dataset. Nevertheless,\nunlike high-level tasks, the pixel-level reconstruction objectives of Real-ISR\nare difficult to reconcile with the image-level preferences of DPO, which can\nlead to the DPO being overly sensitive to local anomalies, leading to reduced\ngeneration quality. To resolve this dichotomy, we propose Direct Semantic\nPreference Optimization (DSPO) to align instance-level human preferences by\nincorporating semantic guidance, which is through two strategies: (a) semantic\ninstance alignment strategy, implementing instance-level alignment to ensure\nfine-grained perceptual consistency, and (b) user description feedback\nstrategy, mitigating hallucinations through semantic textual feedback on\ninstance-level images. As a plug-and-play solution, DSPO proves highly\neffective in both one-step and multi-step SR frameworks.", "published": "2025-04-21 15:35:48", "link": "http://arxiv.org/abs/2504.15176v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HSANET: A Hybrid Self-Cross Attention Network For Remote Sensing Change Detection", "abstract": "The remote sensing image change detection task is an essential method for\nlarge-scale monitoring. We propose HSANet, a network that uses hierarchical\nconvolution to extract multi-scale features. It incorporates hybrid\nself-attention and cross-attention mechanisms to learn and fuse global and\ncross-scale information. This enables HSANet to capture global context at\ndifferent scales and integrate cross-scale features, refining edge details and\nimproving detection performance. We will also open-source our model code:\nhttps://github.com/ChengxiHAN/HSANet.", "published": "2025-04-21 15:23:59", "link": "http://arxiv.org/abs/2504.15170v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Acquire and then Adapt: Squeezing out Text-to-Image Model for Image Restoration", "abstract": "Recently, pre-trained text-to-image (T2I) models have been extensively\nadopted for real-world image restoration because of their powerful generative\nprior. However, controlling these large models for image restoration usually\nrequires a large number of high-quality images and immense computational\nresources for training, which is costly and not privacy-friendly. In this\npaper, we find that the well-trained large T2I model (i.e., Flux) is able to\nproduce a variety of high-quality images aligned with real-world distributions,\noffering an unlimited supply of training samples to mitigate the above issue.\nSpecifically, we proposed a training data construction pipeline for image\nrestoration, namely FluxGen, which includes unconditional image generation,\nimage selection, and degraded image simulation. A novel light-weighted adapter\n(FluxIR) with squeeze-and-excitation layers is also carefully designed to\ncontrol the large Diffusion Transformer (DiT)-based T2I model so that\nreasonable details can be restored. Experiments demonstrate that our proposed\nmethod enables the Flux model to adapt effectively to real-world image\nrestoration tasks, achieving superior scores and visual quality on both\nsynthetic and real-world degradation datasets - at only about 8.5\\% of the\ntraining cost compared to current approaches.", "published": "2025-04-21 15:05:22", "link": "http://arxiv.org/abs/2504.15159v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dynamic 3D KAN Convolution with Adaptive Grid Optimization for Hyperspectral Image Classification", "abstract": "Deep neural networks face several challenges in hyperspectral image\nclassification, including high-dimensional data, sparse distribution of ground\nobjects, and spectral redundancy, which often lead to classification\noverfitting and limited generalization capability. To more efficiently adapt to\nground object distributions while extracting image features without introducing\nexcessive parameters and skipping redundant information, this paper proposes\nKANet based on an improved 3D-DenseNet model, consisting of 3D KAN Conv and an\nadaptive grid update mechanism. By introducing learnable univariate B-spline\nfunctions on network edges, specifically by flattening three-dimensional\nneighborhoods into vectors and applying B-spline-parameterized nonlinear\nactivation functions to replace the fixed linear weights of traditional 3D\nconvolutional kernels, we precisely capture complex spectral-spatial nonlinear\nrelationships in hyperspectral data. Simultaneously, through a dynamic grid\nadjustment mechanism, we adaptively update the grid point positions of\nB-splines based on the statistical characteristics of input data, optimizing\nthe resolution of spline functions to match the non-uniform distribution of\nspectral features, significantly improving the model's accuracy in\nhigh-dimensional data modeling and parameter efficiency, effectively\nalleviating the curse of dimensionality. This characteristic demonstrates\nsuperior neural scaling laws compared to traditional convolutional neural\nnetworks and reduces overfitting risks in small-sample and high-noise\nscenarios. KANet enhances model representation capability through a 3D dynamic\nexpert convolution system without increasing network depth or width. The\nproposed method demonstrates superior performance on IN, UP, and KSC datasets,\noutperforming mainstream hyperspectral image classification approaches.", "published": "2025-04-21 14:57:48", "link": "http://arxiv.org/abs/2504.15155v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "\"I Know It When I See It\": Mood Spaces for Connecting and Expressing Visual Concepts", "abstract": "Expressing complex concepts is easy when they can be labeled or quantified,\nbut many ideas are hard to define yet instantly recognizable. We propose a Mood\nBoard, where users convey abstract concepts with examples that hint at the\nintended direction of attribute changes. We compute an underlying Mood Space\nthat 1) factors out irrelevant features and 2) finds the connections between\nimages, thus bringing relevant concepts closer. We invent a fibration\ncomputation to compress/decompress pre-trained features into/from a compact\nspace, 50-100x smaller. The main innovation is learning to mimic the pairwise\naffinity relationship of the image tokens across exemplars. To focus on the\ncoarse-to-fine hierarchical structures in the Mood Space, we compute the top\neigenvector structure from the affinity matrix and define a loss in the\neigenvector space. The resulting Mood Space is locally linear and compact,\nallowing image-level operations, such as object averaging, visual analogy, and\npose transfer, to be performed as a simple vector operation in Mood Space. Our\nlearning is efficient in computation without any fine-tuning, needs only a few\n(2-20) exemplars, and takes less than a minute to learn.", "published": "2025-04-21 14:49:15", "link": "http://arxiv.org/abs/2504.15145v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Instance-Adaptive Keypoint Learning with Local-to-Global Geometric Aggregation for Category-Level Object Pose Estimation", "abstract": "Category-level object pose estimation aims to predict the 6D pose and size of\npreviously unseen instances from predefined categories, requiring strong\ngeneralization across diverse object instances. Although many previous methods\nattempt to mitigate intra-class variations, they often struggle with instances\nexhibiting complex geometries or significant deviations from canonical shapes.\nTo address this challenge, we propose INKL-Pose, a novel category-level object\npose estimation framework that enables INstance-adaptive Keypoint Learning with\nlocal-to-global geometric aggregation. Specifically, our approach first\npredicts semantically consistent and geometric informative keypoints through an\nInstance-Adaptive Keypoint Generator, then refines them with: (1) a Local\nKeypoint Feature Aggregator capturing fine-grained geometries, and (2) a Global\nKeypoint Feature Aggregator using bidirectional Mamba for structural\nconsistency. To enable bidirectional modeling in Mamba, we introduce a Feature\nSequence Flipping strategy that preserves spatial coherence while constructing\nbackward feature sequences. Additionally, we design a surface loss and a\nseparation loss to enforce uniform coverage and spatial diversity in keypoint\ndistribution. The generated keypoints are finally mapped to a canonical space\nfor regressing the object's 6D pose and size. Extensive experiments on\nCAMERA25, REAL275, and HouseCat6D demonstrate that INKL-Pose achieves\nstate-of-the-art performance and significantly outperforms existing methods.", "published": "2025-04-21 14:37:37", "link": "http://arxiv.org/abs/2504.15134v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry Monocular Video", "abstract": "We present MoBGS, a novel deblurring dynamic 3D Gaussian Splatting (3DGS)\nframework capable of reconstructing sharp and high-quality novel\nspatio-temporal views from blurry monocular videos in an end-to-end manner.\nExisting dynamic novel view synthesis (NVS) methods are highly sensitive to\nmotion blur in casually captured videos, resulting in significant degradation\nof rendering quality. While recent approaches address motion-blurred inputs for\nNVS, they primarily focus on static scene reconstruction and lack dedicated\nmotion modeling for dynamic objects. To overcome these limitations, our MoBGS\nintroduces a novel Blur-adaptive Latent Camera Estimation (BLCE) method for\neffective latent camera trajectory estimation, improving global camera motion\ndeblurring. In addition, we propose a physically-inspired Latent Camera-induced\nExposure Estimation (LCEE) method to ensure consistent deblurring of both\nglobal camera and local object motion. Our MoBGS framework ensures the temporal\nconsistency of unseen latent timestamps and robust motion decomposition of\nstatic and dynamic regions. Extensive experiments on the Stereo Blur dataset\nand real-world blurry videos show that our MoBGS significantly outperforms the\nvery recent advanced methods (DyBluRF and Deblur4DGS), achieving\nstate-of-the-art performance for dynamic NVS under motion blur.", "published": "2025-04-21 14:19:19", "link": "http://arxiv.org/abs/2504.15122v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Robust and Real-time Surface Normal Estimation from Stereo Disparities using Affine Transformations", "abstract": "This work introduces a novel method for surface normal estimation from\nrectified stereo image pairs, leveraging affine transformations derived from\ndisparity values to achieve fast and accurate results. We demonstrate how the\nrectification of stereo image pairs simplifies the process of surface normal\nestimation by reducing computational complexity. To address noise reduction, we\ndevelop a custom algorithm inspired by convolutional operations, tailored to\nprocess disparity data efficiently. We also introduce adaptive heuristic\ntechniques for efficiently detecting connected surface components within the\nimages, further improving the robustness of the method. By integrating these\nmethods, we construct a surface normal estimator that is both fast and\naccurate, producing a dense, oriented point cloud as the final output. Our\nmethod is validated using both simulated environments and real-world stereo\nimages from the Middlebury and Cityscapes datasets, demonstrating significant\nimprovements in real-time performance and accuracy when implemented on a GPU.\nUpon acceptance, the shader source code will be made publicly available to\nfacilitate further research and reproducibility.", "published": "2025-04-21 14:19:00", "link": "http://arxiv.org/abs/2504.15121v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Improving Sound Source Localization with Joint Slot Attention on Image and Audio", "abstract": "Sound source localization (SSL) is the task of locating the source of sound\nwithin an image. Due to the lack of localization labels, the de facto standard\nin SSL has been to represent an image and audio as a single embedding vector\neach, and use them to learn SSL via contrastive learning. To this end, previous\nwork samples one of local image features as the image embedding and aggregates\nall local audio features to obtain the audio embedding, which is far from\noptimal due to the presence of noise and background irrelevant to the actual\ntarget in the input. We present a novel SSL method that addresses this chronic\nissue by joint slot attention on image and audio. To be specific, two slots\ncompetitively attend image and audio features to decompose them into target and\noff-target representations, and only target representations of image and audio\nare used for contrastive learning. Also, we introduce cross-modal attention\nmatching to further align local features of image and audio. Our method\nachieved the best in almost all settings on three public benchmarks for SSL,\nand substantially outperformed all the prior work in cross-modal retrieval.", "published": "2025-04-21 14:16:46", "link": "http://arxiv.org/abs/2504.15118v1", "categories": ["cs.CV", "cs.SD"], "primary_category": "cs.CV"}
{"title": "Unwarping Screen Content Images via Structure-texture Enhancement Network and Transformation Self-estimation", "abstract": "While existing implicit neural network-based image unwarping methods perform\nwell on natural images, they struggle to handle screen content images (SCIs),\nwhich often contain large geometric distortions, text, symbols, and sharp\nedges. To address this, we propose a structure-texture enhancement network\n(STEN) with transformation self-estimation for SCI warping. STEN integrates a\nB-spline implicit neural representation module and a transformation error\nestimation and self-correction algorithm. It comprises two branches: the\nstructure estimation branch (SEB), which enhances local aggregation and global\ndependency modeling, and the texture estimation branch (TEB), which improves\ntexture detail synthesis using B-spline implicit neural representation.\nAdditionally, the transformation self-estimation module autonomously estimates\nthe transformation error and corrects the coordinate transformation matrix,\neffectively handling real-world image distortions. Extensive experiments on\npublic SCI datasets demonstrate that our approach significantly outperforms\nstate-of-the-art methods. Comparisons on well-known natural image datasets also\nshow the potential of our approach for natural image distortion.", "published": "2025-04-21 13:59:44", "link": "http://arxiv.org/abs/2504.15108v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VistaDepth: Frequency Modulation With Bias Reweighting For Enhanced Long-Range Depth Estimation", "abstract": "Monocular depth estimation (MDE) aims to predict per-pixel depth values from\na single RGB image. Recent advancements have positioned diffusion models as\neffective MDE tools by framing the challenge as a conditional image generation\ntask. Despite their progress, these methods often struggle with accurately\nreconstructing distant depths, due largely to the imbalanced distribution of\ndepth values and an over-reliance on spatial-domain features. To overcome these\nlimitations, we introduce VistaDepth, a novel framework that integrates\nadaptive frequency-domain feature enhancements with an adaptive\nweight-balancing mechanism into the diffusion process. Central to our approach\nis the Latent Frequency Modulation (LFM) module, which dynamically refines\nspectral responses in the latent feature space, thereby improving the\npreservation of structural details and reducing noisy artifacts. Furthermore,\nwe implement an adaptive weighting strategy that modulates the diffusion loss\nin real-time, enhancing the model's sensitivity towards distant depth\nreconstruction. These innovations collectively result in superior depth\nperception performance across both distance and detail. Experimental\nevaluations confirm that VistaDepth achieves state-of-the-art performance among\ndiffusion-based MDE techniques, particularly excelling in the accurate\nreconstruction of distant regions.", "published": "2025-04-21 13:30:51", "link": "http://arxiv.org/abs/2504.15095v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hierarchical Attention Fusion of Visual and Textual Representations for Cross-Domain Sequential Recommendation", "abstract": "Cross-Domain Sequential Recommendation (CDSR) predicts user behavior by\nleveraging historical interactions across multiple domains, focusing on\nmodeling cross-domain preferences through intra- and inter-sequence item\nrelationships. Inspired by human cognitive processes, we propose Hierarchical\nAttention Fusion of Visual and Textual Representations (HAF-VT), a novel\napproach integrating visual and textual data to enhance cognitive modeling.\nUsing the frozen CLIP model, we generate image and text embeddings, enriching\nitem representations with multimodal data. A hierarchical attention mechanism\njointly learns single-domain and cross-domain preferences, mimicking human\ninformation integration. Evaluated on four e-commerce datasets, HAF-VT\noutperforms existing methods in capturing cross-domain user interests, bridging\ncognitive principles with computational models and highlighting the role of\nmultimodal data in sequential decision-making.", "published": "2025-04-21 13:18:54", "link": "http://arxiv.org/abs/2504.15085v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Structure-guided Diffusion Transformer for Low-Light Image Enhancement", "abstract": "While the diffusion transformer (DiT) has become a focal point of interest in\nrecent years, its application in low-light image enhancement remains a blank\narea for exploration. Current methods recover the details from low-light images\nwhile inevitably amplifying the noise in images, resulting in poor visual\nquality. In this paper, we firstly introduce DiT into the low-light enhancement\ntask and design a novel Structure-guided Diffusion Transformer based Low-light\nimage enhancement (SDTL) framework. We compress the feature through wavelet\ntransform to improve the inference efficiency of the model and capture the\nmulti-directional frequency band. Then we propose a Structure Enhancement\nModule (SEM) that uses structural prior to enhance the texture and leverages an\nadaptive fusion strategy to achieve more accurate enhancement effect. In\nAddition, we propose a Structure-guided Attention Block (SAB) to pay more\nattention to texture-riched tokens and avoid interference from noisy areas in\nnoise prediction. Extensive qualitative and quantitative experiments\ndemonstrate that our method achieves SOTA performance on several popular\ndatasets, validating the effectiveness of SDTL in improving image quality and\nthe potential of DiT in low-light enhancement tasks.", "published": "2025-04-21 12:30:01", "link": "http://arxiv.org/abs/2504.15054v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ScanEdit: Hierarchically-Guided Functional 3D Scan Editing", "abstract": "With the fast pace of 3D capture technology and resulting abundance of 3D\ndata, effective 3D scene editing becomes essential for a variety of graphics\napplications. In this work we present ScanEdit, an instruction-driven method\nfor functional editing of complex, real-world 3D scans. To model large and\ninterdependent sets of ob- jectswe propose a hierarchically-guided approach.\nGiven a 3D scan decomposed into its object instances, we first construct a\nhierarchical scene graph representation to enable effective, tractable editing.\nWe then leverage reason- ing capabilities of Large Language Models (LLMs) and\ntranslate high-level language instructions into actionable commands applied\nhierarchically to the scene graph. Fi- nally, ScanEdit integrates LLM-based\nguidance with ex- plicit physical constraints and generates realistic scenes\nwhere object arrangements obey both physics and common sense. In our extensive\nexperimental evaluation ScanEdit outperforms state of the art and demonstrates\nexcellent re- sults for a variety of real-world scenes and input instruc-\ntions.", "published": "2025-04-21 12:12:43", "link": "http://arxiv.org/abs/2504.15049v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DyST-XL: Dynamic Layout Planning and Content Control for Compositional Text-to-Video Generation", "abstract": "Compositional text-to-video generation, which requires synthesizing dynamic\nscenes with multiple interacting entities and precise spatial-temporal\nrelationships, remains a critical challenge for diffusion-based models.\nExisting methods struggle with layout discontinuity, entity identity drift, and\nimplausible interaction dynamics due to unconstrained cross-attention\nmechanisms and inadequate physics-aware reasoning. To address these\nlimitations, we propose DyST-XL, a \\textbf{training-free} framework that\nenhances off-the-shelf text-to-video models (e.g., CogVideoX-5B) through\nframe-aware control. DyST-XL integrates three key innovations: (1) A Dynamic\nLayout Planner that leverages large language models (LLMs) to parse input\nprompts into entity-attribute graphs and generates physics-aware keyframe\nlayouts, with intermediate frames interpolated via trajectory optimization; (2)\nA Dual-Prompt Controlled Attention Mechanism that enforces localized text-video\nalignment through frame-aware attention masking, achieving the precise control\nover individual entities; and (3) An Entity-Consistency Constraint strategy\nthat propagates first-frame feature embeddings to subsequent frames during\ndenoising, preserving object identity without manual annotation. Experiments\ndemonstrate that DyST-XL excels in compositional text-to-video generation,\nsignificantly improving performance on complex prompts and bridging a crucial\ngap in training-free video synthesis.", "published": "2025-04-21 11:41:22", "link": "http://arxiv.org/abs/2504.15032v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Controllable Appearance Representation for Flexible Transfer and Editing", "abstract": "We present a method that computes an interpretable representation of material\nappearance within a highly compact, disentangled latent space. This\nrepresentation is learned in a self-supervised fashion using an adapted\nFactorVAE. We train our model with a carefully designed unlabeled dataset,\navoiding possible biases induced by human-generated labels. Our model\ndemonstrates strong disentanglement and interpretability by effectively\nencoding material appearance and illumination, despite the absence of explicit\nsupervision. Then, we use our representation as guidance for training a\nlightweight IP-Adapter to condition a diffusion pipeline that transfers the\nappearance of one or more images onto a target geometry, and allows the user to\nfurther edit the resulting appearance. Our approach offers fine-grained control\nover the generated results: thanks to the well-structured compact latent space,\nusers can intuitively manipulate attributes such as hue or glossiness in image\nspace to achieve the desired final appearance.", "published": "2025-04-21 11:29:06", "link": "http://arxiv.org/abs/2504.15028v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Gaussian Shading++: Rethinking the Realistic Deployment Challenge of Performance-Lossless Image Watermark for Diffusion Models", "abstract": "Ethical concerns surrounding copyright protection and inappropriate content\ngeneration pose challenges for the practical implementation of diffusion\nmodels. One effective solution involves watermarking the generated images.\nExisting methods primarily focus on ensuring that watermark embedding does not\ndegrade the model performance. However, they often overlook critical challenges\nin real-world deployment scenarios, such as the complexity of watermark key\nmanagement, user-defined generation parameters, and the difficulty of\nverification by arbitrary third parties. To address this issue, we propose\nGaussian Shading++, a diffusion model watermarking method tailored for\nreal-world deployment. We propose a double-channel design that leverages\npseudorandom error-correcting codes to encode the random seed required for\nwatermark pseudorandomization, achieving performance-lossless watermarking\nunder a fixed watermark key and overcoming key management challenges.\nAdditionally, we model the distortions introduced during generation and\ninversion as an additive white Gaussian noise channel and employ a novel soft\ndecision decoding strategy during extraction, ensuring strong robustness even\nwhen generation parameters vary. To enable third-party verification, we\nincorporate public key signatures, which provide a certain level of resistance\nagainst forgery attacks even when model inversion capabilities are fully\ndisclosed. Extensive experiments demonstrate that Gaussian Shading++ not only\nmaintains performance losslessness but also outperforms existing methods in\nterms of robustness, making it a more practical solution for real-world\ndeployment.", "published": "2025-04-21 11:18:16", "link": "http://arxiv.org/abs/2504.15026v1", "categories": ["cs.CV", "cs.CR"], "primary_category": "cs.CV"}
{"title": "Insert Anything: Image Insertion via In-Context Editing in DiT", "abstract": "This work presents Insert Anything, a unified framework for reference-based\nimage insertion that seamlessly integrates objects from reference images into\ntarget scenes under flexible, user-specified control guidance. Instead of\ntraining separate models for individual tasks, our approach is trained once on\nour new AnyInsertion dataset--comprising 120K prompt-image pairs covering\ndiverse tasks such as person, object, and garment insertion--and effortlessly\ngeneralizes to a wide range of insertion scenarios. Such a challenging setting\nrequires capturing both identity features and fine-grained details, while\nallowing versatile local adaptations in style, color, and texture. To this end,\nwe propose to leverage the multimodal attention of the Diffusion Transformer\n(DiT) to support both mask- and text-guided editing. Furthermore, we introduce\nan in-context editing mechanism that treats the reference image as contextual\ninformation, employing two prompting strategies to harmonize the inserted\nelements with the target scene while faithfully preserving their distinctive\nfeatures. Extensive experiments on AnyInsertion, DreamBooth, and VTON-HD\nbenchmarks demonstrate that our method consistently outperforms existing\nalternatives, underscoring its great potential in real-world applications such\nas creative content generation, virtual try-on, and scene composition.", "published": "2025-04-21 10:19:12", "link": "http://arxiv.org/abs/2504.15009v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Shifts in Doctors' Eye Movements Between Real and AI-Generated Medical Images", "abstract": "Eye-tracking analysis plays a vital role in medical imaging, providing key\ninsights into how radiologists visually interpret and diagnose clinical cases.\nIn this work, we first analyze radiologists' attention and agreement by\nmeasuring the distribution of various eye-movement patterns, including saccades\ndirection, amplitude, and their joint distribution. These metrics help uncover\npatterns in attention allocation and diagnostic strategies. Furthermore, we\ninvestigate whether and how doctors' gaze behavior shifts when viewing\nauthentic (Real) versus deep-learning-generated (Fake) images. To achieve this,\nwe examine fixation bias maps, focusing on first, last, short, and longest\nfixations independently, along with detailed saccades patterns, to quantify\ndifferences in gaze distribution and visual saliency between authentic and\nsynthetic images.", "published": "2025-04-21 10:13:59", "link": "http://arxiv.org/abs/2504.15007v1", "categories": ["cs.CV", "cs.HC"], "primary_category": "cs.CV"}
{"title": "NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and Enhancement: KwaiSR Dataset and Study", "abstract": "In this work, we build the first benchmark dataset for short-form UGC Image\nSuper-resolution in the wild, termed KwaiSR, intending to advance the research\non developing image super-resolution algorithms for short-form UGC platforms.\nThis dataset is collected from the Kwai Platform, which is composed of two\nparts, i.e., synthetic and wild parts. Among them, the synthetic dataset,\nincluding 1,900 image pairs, is produced by simulating the degradation\nfollowing the distribution of real-world low-quality short-form UGC images,\naiming to provide the ground truth for training and objective comparison in the\nvalidation/testing. The wild dataset contains low-quality images collected\ndirectly from the Kwai Platform, which are filtered using the quality\nassessment method KVQ from the Kwai Platform. As a result, the KwaiSR dataset\ncontains 1800 synthetic image pairs and 1900 wild images, which are divided\ninto training, validation, and testing parts with a ratio of 8:1:1. Based on\nthe KwaiSR dataset, we organize the NTIRE 2025 challenge on a second short-form\nUGC Video quality assessment and enhancement, which attracts lots of\nresearchers to develop the algorithm for it. The results of this competition\nhave revealed that our KwaiSR dataset is pretty challenging for existing Image\nSR methods, which is expected to lead to a new direction in the image\nsuper-resolution field. The dataset can be found from\nhttps://lixinustc.github.io/NTIRE2025-KVQE-KwaSR-KVQ.github.io/.", "published": "2025-04-21 10:04:26", "link": "http://arxiv.org/abs/2504.15003v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Benchmarking Large Vision-Language Models on Fine-Grained Image Tasks: A Comprehensive Evaluation", "abstract": "Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated\nremarkable multimodal perception capabilities, garnering significant attention.\nWhile numerous evaluation studies have emerged, assessing LVLMs both\nholistically and on specialized tasks, fine-grained image tasks-fundamental to\ncomputer vision-remain largely unexplored. To fill this gap, we introduce a\ncomprehensive fine-grained evaluation benchmark, i.e., FG-BMK, comprising 3.49\nmillion questions and 3.32 million images. Our evaluation systematically\nexamines LVLMs from both human-oriented and machine-oriented perspectives,\nfocusing on their semantic recognition and fine-grained feature representation\ncapabilities. Through extensive experiments on eight representative LVLMs/VLMs,\nwe uncover key findings regarding the influence of training paradigms, modality\nalignment, perturbation susceptibility, and fine-grained category reasoning on\ntask performance. This work provides critical insights into the limitations of\ncurrent LVLMs and offers guidance for future data construction and model design\nin the development of more advanced LVLMs. Our code is open-source and\navailable at https://github.com/SEU-VIPGroup/FG-BMK.", "published": "2025-04-21 09:30:41", "link": "http://arxiv.org/abs/2504.14988v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RealisDance-DiT: Simple yet Strong Baseline towards Controllable Character Animation in the Wild", "abstract": "Controllable character animation remains a challenging problem, particularly\nin handling rare poses, stylized characters, character-object interactions,\ncomplex illumination, and dynamic scenes. To tackle these issues, prior work\nhas largely focused on injecting pose and appearance guidance via elaborate\nbypass networks, but often struggles to generalize to open-world scenarios. In\nthis paper, we propose a new perspective that, as long as the foundation model\nis powerful enough, straightforward model modifications with flexible\nfine-tuning strategies can largely address the above challenges, taking a step\ntowards controllable character animation in the wild. Specifically, we\nintroduce RealisDance-DiT, built upon the Wan-2.1 video foundation model. Our\nsufficient analysis reveals that the widely adopted Reference Net design is\nsuboptimal for large-scale DiT models. Instead, we demonstrate that minimal\nmodifications to the foundation model architecture yield a surprisingly strong\nbaseline. We further propose the low-noise warmup and \"large batches and small\niterations\" strategies to accelerate model convergence during fine-tuning while\nmaximally preserving the priors of the foundation model. In addition, we\nintroduce a new test dataset that captures diverse real-world challenges,\ncomplementing existing benchmarks such as TikTok dataset and UBC fashion video\ndataset, to comprehensively evaluate the proposed method. Extensive experiments\nshow that RealisDance-DiT outperforms existing methods by a large margin.", "published": "2025-04-21 09:09:21", "link": "http://arxiv.org/abs/2504.14977v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cyc3D: Fine-grained Controllable 3D Generation via Cycle Consistency Regularization", "abstract": "Despite the remarkable progress of 3D generation, achieving controllability,\ni.e., ensuring consistency between generated 3D content and input conditions\nlike edge and depth, remains a significant challenge. Existing methods often\nstruggle to maintain accurate alignment, leading to noticeable discrepancies.\nTo address this issue, we propose \\name{}, a new framework that enhances\ncontrollable 3D generation by explicitly encouraging cyclic consistency between\nthe second-order 3D content, generated based on extracted signals from the\nfirst-order generation, and its original input controls. Specifically, we\nemploy an efficient feed-forward backbone that can generate a 3D object from an\ninput condition and a text prompt. Given an initial viewpoint and a control\nsignal, a novel view is rendered from the generated 3D content, from which the\nextracted condition is used to regenerate the 3D content. This re-generated\noutput is then rendered back to the initial viewpoint, followed by another\nround of control signal extraction, forming a cyclic process with two\nconsistency constraints. \\emph{View consistency} ensures coherence between the\ntwo generated 3D objects, measured by semantic similarity to accommodate\ngenerative diversity. \\emph{Condition consistency} aligns the final extracted\nsignal with the original input control, preserving structural or geometric\ndetails throughout the process. Extensive experiments on popular benchmarks\ndemonstrate that \\name{} significantly improves controllability, especially for\nfine-grained details, outperforming existing methods across various conditions\n(e.g., +14.17\\% PSNR for edge, +6.26\\% PSNR for sketch).", "published": "2025-04-21 09:05:52", "link": "http://arxiv.org/abs/2504.14975v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3D Gaussian Head Avatars with Expressive Dynamic Appearances by Compact Tensorial Representations", "abstract": "Recent studies have combined 3D Gaussian and 3D Morphable Models (3DMM) to\nconstruct high-quality 3D head avatars. In this line of research, existing\nmethods either fail to capture the dynamic textures or incur significant\noverhead in terms of runtime speed or storage space. To this end, we propose a\nnovel method that addresses all the aforementioned demands. In specific, we\nintroduce an expressive and compact representation that encodes texture-related\nattributes of the 3D Gaussians in the tensorial format. We store appearance of\nneutral expression in static tri-planes, and represents dynamic texture details\nfor different expressions using lightweight 1D feature lines, which are then\ndecoded into opacity offset relative to the neutral face. We further propose\nadaptive truncated opacity penalty and class-balanced sampling to improve\ngeneralization across different expressions. Experiments show this design\nenables accurate face dynamic details capturing while maintains real-time\nrendering and significantly reduces storage costs, thus broadening the\napplicability to more scenarios.", "published": "2025-04-21 08:50:12", "link": "http://arxiv.org/abs/2504.14967v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PIV-FlowDiffuser:Transfer-learning-based denoising diffusion models for PIV", "abstract": "Deep learning algorithms have significantly reduced the computational time\nand improved the spatial resolution of particle image velocimetry~(PIV).\nHowever, the models trained on synthetic datasets might have a degraded\nperformance on practical particle images due to domain gaps. As a result,\nspecial residual patterns are often observed for the vector fields of deep\nlearning-based estimators. To reduce the special noise step-by-step, we employ\na denoising diffusion model~(FlowDiffuser) for PIV analysis. And the\ndata-hungry iterative denoising diffusion model is trained via a transfer\nlearning strategy, resulting in our PIV-FlowDiffuser method. Specifically, (1)\npre-training a FlowDiffuser model with multiple optical flow datasets of the\ncomputer vision community, such as Sintel, KITTI, etc; (2) fine-tuning the\npre-trained model on synthetic PIV datasets. Note that the PIV images are\nupsampled by a factor of two to resolve the small-scale turbulent flow\nstructures. The visualized results indicate that our PIV-FlowDiffuser\neffectively suppresses the noise patterns. Therefore, the denoising diffusion\nmodel reduces the average end-point error~($AEE$) by 59.4% over RAFT256-PIV\nbaseline on the classic Cai's dataset. Besides, PIV-FlowDiffuser exhibits\nenhanced generalization performance on unseen particle images due to transfer\nlearning. Overall, this study highlights the transfer-learning-based denoising\ndiffusion models for PIV. And a detailed implementation is recommended for\ninterested readers in the repository\nhttps://github.com/Zhu-Qianyu/PIV-FlowDiffuser.", "published": "2025-04-21 08:22:58", "link": "http://arxiv.org/abs/2504.14952v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "TWIG: Two-Step Image Generation using Segmentation Masks in Diffusion Models", "abstract": "In today's age of social media and marketing, copyright issues can be a major\nroadblock to the free sharing of images. Generative AI models have made it\npossible to create high-quality images, but concerns about copyright\ninfringement are a hindrance to their abundant use. As these models use data\nfrom training images to generate new ones, it is often a daunting task to\nensure they do not violate intellectual property rights. Some AI models have\neven been noted to directly copy copyrighted images, a problem often referred\nto as source copying. Traditional copyright protection measures such as\nwatermarks and metadata have also proven to be futile in this regard. To\naddress this issue, we propose a novel two-step image generation model inspired\nby the conditional diffusion model. The first step involves creating an image\nsegmentation mask for some prompt-based generated images. This mask embodies\nthe shape of the image. Thereafter, the diffusion model is asked to generate\nthe image anew while avoiding the shape in question. This approach shows a\ndecrease in structural similarity from the training image, i.e. we are able to\navoid the source copying problem using this approach without expensive\nretraining of the model or user-centered prompt generation techniques. This\nmakes our approach the most computationally inexpensive approach to avoiding\nboth copyright infringement and source copying for diffusion model-based image\ngeneration.", "published": "2025-04-21 07:53:58", "link": "http://arxiv.org/abs/2504.14933v1", "categories": ["cs.CV", "68T07, 68U10, 68T45"], "primary_category": "cs.CV"}
{"title": "DyFo: A Training-Free Dynamic Focus Visual Search for Enhancing LMMs in Fine-Grained Visual Understanding", "abstract": "Humans can effortlessly locate desired objects in cluttered environments,\nrelying on a cognitive mechanism known as visual search to efficiently filter\nout irrelevant information and focus on task-related regions. Inspired by this\nprocess, we propose Dyfo (Dynamic Focus), a training-free dynamic focusing\nvisual search method that enhances fine-grained visual understanding in large\nmultimodal models (LMMs). Unlike existing approaches which require additional\nmodules or data collection, Dyfo leverages a bidirectional interaction between\nLMMs and visual experts, using a Monte Carlo Tree Search (MCTS) algorithm to\nsimulate human-like focus adjustments. This enables LMMs to focus on key visual\nregions while filtering out irrelevant content, without introducing additional\ntraining caused by vocabulary expansion or the integration of specialized\nlocalization modules. Experimental results demonstrate that Dyfo significantly\nimproves fine-grained visual understanding and reduces hallucination issues in\nLMMs, achieving superior performance across both fixed and dynamic resolution\nmodels. The code is available at https://github.com/PKU-ICST-MIPL/DyFo_CVPR2025", "published": "2025-04-21 07:39:29", "link": "http://arxiv.org/abs/2504.14920v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GenCLIP: Generalizing CLIP Prompts for Zero-shot Anomaly Detection", "abstract": "Zero-shot anomaly detection (ZSAD) aims to identify anomalies in unseen\ncategories by leveraging CLIP's zero-shot capabilities to match text prompts\nwith visual features. A key challenge in ZSAD is learning general prompts\nstably and utilizing them effectively, while maintaining both generalizability\nand category specificity. Although general prompts have been explored in prior\nworks, achieving their stable optimization and effective deployment remains a\nsignificant challenge. In this work, we propose GenCLIP, a novel framework that\nlearns and leverages general prompts more effectively through multi-layer\nprompting and dual-branch inference. Multi-layer prompting integrates\ncategory-specific visual cues from different CLIP layers, enriching general\nprompts with more comprehensive and robust feature representations. By\ncombining general prompts with multi-layer visual features, our method further\nenhances its generalization capability. To balance specificity and\ngeneralization, we introduce a dual-branch inference strategy, where a\nvision-enhanced branch captures fine-grained category-specific features, while\na query-only branch prioritizes generalization. The complementary outputs from\nboth branches improve the stability and reliability of anomaly detection across\nunseen categories. Additionally, we propose an adaptive text prompt filtering\nmechanism, which removes irrelevant or atypical class names not encountered\nduring CLIP's training, ensuring that only meaningful textual inputs contribute\nto the final vision-language alignment.", "published": "2025-04-21 07:38:25", "link": "http://arxiv.org/abs/2504.14919v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OmniAudio: Generating Spatial Audio from 360-Degree Video", "abstract": "Traditional video-to-audio generation techniques primarily focus on\nfield-of-view (FoV) video and non-spatial audio, often missing the spatial cues\nnecessary for accurately representing sound sources in 3D environments. To\naddress this limitation, we introduce a novel task, 360V2SA, to generate\nspatial audio from 360-degree videos, specifically producing First-order\nAmbisonics (FOA) audio - a standard format for representing 3D spatial audio\nthat captures sound directionality and enables realistic 3D audio reproduction.\nWe first create Sphere360, a novel dataset tailored for this task that is\ncurated from real-world data. We also design an efficient semi-automated\npipeline for collecting and cleaning paired video-audio data. To generate\nspatial audio from 360-degree video, we propose a novel framework OmniAudio,\nwhich leverages self-supervised pre-training using both spatial audio data (in\nFOA format) and large-scale non-spatial data. Furthermore, OmniAudio features a\ndual-branch framework that utilizes both panoramic and FoV video inputs to\ncapture comprehensive local and global information from 360-degree videos.\nExperimental results demonstrate that OmniAudio achieves state-of-the-art\nperformance across both objective and subjective metrics on Sphere360. Code and\ndatasets will be released at https://github.com/liuhuadai/OmniAudio. The demo\npage is available at https://OmniAudio-360V2SA.github.io.", "published": "2025-04-21 07:21:28", "link": "http://arxiv.org/abs/2504.14906v1", "categories": ["eess.AS", "cs.CV", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Uni3C: Unifying Precisely 3D-Enhanced Camera and Human Motion Controls for Video Generation", "abstract": "Camera and human motion controls have been extensively studied for video\ngeneration, but existing approaches typically address them separately,\nsuffering from limited data with high-quality annotations for both aspects. To\novercome this, we present Uni3C, a unified 3D-enhanced framework for precise\ncontrol of both camera and human motion in video generation. Uni3C includes two\nkey contributions. First, we propose a plug-and-play control module trained\nwith a frozen video generative backbone, PCDController, which utilizes\nunprojected point clouds from monocular depth to achieve accurate camera\ncontrol. By leveraging the strong 3D priors of point clouds and the powerful\ncapacities of video foundational models, PCDController shows impressive\ngeneralization, performing well regardless of whether the inference backbone is\nfrozen or fine-tuned. This flexibility enables different modules of Uni3C to be\ntrained in specific domains, i.e., either camera control or human motion\ncontrol, reducing the dependency on jointly annotated data. Second, we propose\na jointly aligned 3D world guidance for the inference phase that seamlessly\nintegrates both scenic point clouds and SMPL-X characters to unify the control\nsignals for camera and human motion, respectively. Extensive experiments\nconfirm that PCDController enjoys strong robustness in driving camera motion\nfor fine-tuned backbones of video generation. Uni3C substantially outperforms\ncompetitors in both camera controllability and human motion quality.\nAdditionally, we collect tailored validation sets featuring challenging camera\nmovements and human actions to validate the effectiveness of our method.", "published": "2025-04-21 07:10:41", "link": "http://arxiv.org/abs/2504.14899v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "WMKA-Net: A Weighted Multi-Kernel Attention NetworkMethod for Retinal Vessel Segmentation", "abstract": "We propose a novel retinal vessel segmentation network, the Weighted\nMulti-Kernel Attention Network (WMKA-Net), which aims to address the issues of\ninsufficient multiscale feature capture, loss of contextual information, and\nnoise sensitivity in retinal vessel segmentation. WMKA-Net significantly\nimproves the segmentation performance of small vessels and low-contrast regions\nby integrating several innovative components, including the MultiKernelFeature\nFusion Module (MKDC), the Progressive Feature Weighting Fusion Strategy (UDFF),\nand the Attention Mechanism Module (AttentionBlock). The MKDC module employs\nmultiscale parallel convolutional kernels to extract vessel characteristics,\nthereby enhancing the ability to capture complex vascular structures. The UDFF\nstrategy optimizes the transmission of feature information by weighted fusion\nof high- and low-level features. The AttentionBlock highlights key regions and\nsuppresses noise interference through the attention mechanism. Experimental\nresults demonstrate that WMKA-Net achieves excellent segmentation performance\nin multiple public datasets, particularly in segmentation of small vessels and\nprocessing of pathological regions. This work provides a robust and efficient\nnew method for segmentation of the retinal vessel.", "published": "2025-04-21 06:32:25", "link": "http://arxiv.org/abs/2504.14888v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Memory-Augmented Dual-Decoder Networks for Multi-Class Unsupervised Anomaly Detection", "abstract": "Recent advances in unsupervised anomaly detection (UAD) have shifted from\nsingle-class to multi-class scenarios. In such complex contexts, the increasing\npattern diversity has brought two challenges to reconstruction-based\napproaches: (1) over-generalization: anomalies that are subtle or share\ncompositional similarities with normal patterns may be reconstructed with high\nfidelity, making them difficult to distinguish from normal instances; and (2)\ninsufficient normality reconstruction: complex normal features, such as\nintricate textures or fine-grained structures, may not be faithfully\nreconstructed due to the model's limited representational capacity, resulting\nin false positives. Existing methods typically focus on addressing the former,\nwhich unintentionally exacerbate the latter, resulting in inadequate\nrepresentation of intricate normal patterns. To concurrently address these two\nchallenges, we propose a Memory-augmented Dual-Decoder Networks (MDD-Net). This\nnetwork includes two critical components: a Dual-Decoder Reverse Distillation\nNetwork (DRD-Net) and a Class-aware Memory Module (CMM). Specifically, the\nDRD-Net incorporates a restoration decoder designed to recover normal features\nfrom synthetic abnormal inputs and an identity decoder to reconstruct features\nthat maintain the anomalous semantics. By exploiting the discrepancy between\nfeatures produced by two decoders, our approach refines anomaly scores beyond\nthe conventional encoder-decoder comparison paradigm, effectively reducing\nfalse positives and enhancing localization accuracy. Furthermore, the CMM\nexplicitly encodes and preserves class-specific normal prototypes, actively\nsteering the network away from anomaly reconstruction. Comprehensive\nexperimental results across several benchmarks demonstrate the superior\nperformance of our MDD-Net framework over current SoTA approaches in\nmulti-class UAD tasks.", "published": "2025-04-21 06:29:04", "link": "http://arxiv.org/abs/2504.14884v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Some Optimizers are More Equal: Understanding the Role of Optimizers in Group Fairness", "abstract": "We study whether and how the choice of optimization algorithm can impact\ngroup fairness in deep neural networks. Through stochastic differential\nequation analysis of optimization dynamics in an analytically tractable setup,\nwe demonstrate that the choice of optimization algorithm indeed influences\nfairness outcomes, particularly under severe imbalance. Furthermore, we show\nthat when comparing two categories of optimizers, adaptive methods and\nstochastic methods, RMSProp (from the adaptive category) has a higher\nlikelihood of converging to fairer minima than SGD (from the stochastic\ncategory). Building on this insight, we derive two new theoretical guarantees\nshowing that, under appropriate conditions, RMSProp exhibits fairer parameter\nupdates and improved fairness in a single optimization step compared to SGD. We\nthen validate these findings through extensive experiments on three publicly\navailable datasets, namely CelebA, FairFace, and MS-COCO, across different\ntasks as facial expression recognition, gender classification, and multi-label\nclassification, using various backbones. Considering multiple fairness\ndefinitions including equalized odds, equal opportunity, and demographic\nparity, adaptive optimizers like RMSProp and Adam consistently outperform SGD\nin terms of group fairness, while maintaining comparable predictive accuracy.\nOur results highlight the role of adaptive updates as a crucial yet overlooked\nmechanism for promoting fair outcomes.", "published": "2025-04-21 06:20:50", "link": "http://arxiv.org/abs/2504.14882v1", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Collaborative Enhancement Network for Low-quality Multi-spectral Vehicle Re-identification", "abstract": "The performance of multi-spectral vehicle Re-identification (ReID) is\nsignificantly degraded when some important discriminative cues in visible, near\ninfrared and thermal infrared spectra are lost. Existing methods generate or\nenhance missing details in low-quality spectra data using the high-quality one,\ngenerally called the primary spectrum, but how to justify the primary spectrum\nis a challenging problem. In addition, when the quality of the primary spectrum\nis low, the enhancement effect would be greatly degraded, thus limiting the\nperformance of multi-spectral vehicle ReID. To address these problems, we\npropose the Collaborative Enhancement Network (CoEN), which generates a\nhigh-quality proxy from all spectra data and leverages it to supervise the\nselection of primary spectrum and enhance all spectra features in a\ncollaborative manner, for robust multi-spectral vehicle ReID. First, to\nintegrate the rich cues from all spectra data, we design the Proxy Generator\n(PG) to progressively aggregate multi-spectral features. Second, we design the\nDynamic Quality Sort Module (DQSM), which sorts all spectra data by measuring\ntheir correlations with the proxy, to accurately select the primary spectra\nwith the highest correlation. Finally, we design the Collaborative Enhancement\nModule (CEM) to effectively compensate for missing contents of all spectra by\ncollaborating the primary spectra and the proxy, thereby mitigating the impact\nof low-quality primary spectra. Extensive experiments on three benchmark\ndatasets are conducted to validate the efficacy of the proposed approach\nagainst other multi-spectral vehicle ReID methods. The codes will be released\nat https://github.com/yongqisun/CoEN.", "published": "2025-04-21 06:07:32", "link": "http://arxiv.org/abs/2504.14877v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Twin Co-Adaptive Dialogue for Progressive Image Generation", "abstract": "Modern text-to-image generation systems have enabled the creation of\nremarkably realistic and high-quality visuals, yet they often falter when\nhandling the inherent ambiguities in user prompts. In this work, we present\nTwin-Co, a framework that leverages synchronized, co-adaptive dialogue to\nprogressively refine image generation. Instead of a static generation process,\nTwin-Co employs a dynamic, iterative workflow where an intelligent dialogue\nagent continuously interacts with the user. Initially, a base image is\ngenerated from the user's prompt. Then, through a series of synchronized\ndialogue exchanges, the system adapts and optimizes the image according to\nevolving user feedback. The co-adaptive process allows the system to\nprogressively narrow down ambiguities and better align with user intent.\nExperiments demonstrate that Twin-Co not only enhances user experience by\nreducing trial-and-error iterations but also improves the quality of the\ngenerated images, streamlining the creative process across various\napplications.", "published": "2025-04-21 05:37:07", "link": "http://arxiv.org/abs/2504.14868v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Reliable Multi-Modal Object Re-Identification via Modality-Aware Graph Reasoning", "abstract": "Multi-modal data provides abundant and diverse object information, crucial\nfor effective modal interactions in Re-Identification (ReID) tasks. However,\nexisting approaches often overlook the quality variations in local features and\nfail to fully leverage the complementary information across modalities,\nparticularly in the case of low-quality features. In this paper, we propose to\naddress this issue by leveraging a novel graph reasoning model, termed the\nModality-aware Graph Reasoning Network (MGRNet). Specifically, we first\nconstruct modality-aware graphs to enhance the extraction of fine-grained local\ndetails by effectively capturing and modeling the relationships between\npatches. Subsequently, the selective graph nodes swap operation is employed to\nalleviate the adverse effects of low-quality local features by considering both\nlocal and global information, enhancing the representation of discriminative\ninformation. Finally, the swapped modality-aware graphs are fed into the\nlocal-aware graph reasoning module, which propagates multi-modal information to\nyield a reliable feature representation. Another advantage of the proposed\ngraph reasoning approach is its ability to reconstruct missing modal\ninformation by exploiting inherent structural relationships, thereby minimizing\ndisparities between different modalities. Experimental results on four\nbenchmarks (RGBNT201, Market1501-MM, RGBNT100, MSVR310) indicate that the\nproposed method achieves state-of-the-art performance in multi-modal object\nReID. The code for our method will be available upon acceptance.", "published": "2025-04-21 03:58:40", "link": "http://arxiv.org/abs/2504.14847v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Distribution-aware Dataset Distillation for Efficient Image Restoration", "abstract": "With the exponential increase in image data, training an image restoration\nmodel is laborious. Dataset distillation is a potential solution to this\nproblem, yet current distillation techniques are a blank canvas in the field of\nimage restoration. To fill this gap, we propose the Distribution-aware Dataset\nDistillation method (TripleD), a new framework that extends the principles of\ndataset distillation to image restoration. Specifically, TripleD uses a\npre-trained vision Transformer to extract features from images for complexity\nevaluation, and the subset (the number of samples is much smaller than the\noriginal training set) is selected based on complexity. The selected subset is\nthen fed through a lightweight CNN that fine-tunes the image distribution to\nalign with the distribution of the original dataset at the feature level. To\nefficiently condense knowledge, the training is divided into two stages. Early\nstages focus on simpler, low-complexity samples to build foundational\nknowledge, while later stages select more complex and uncertain samples as the\nmodel matures. Our method achieves promising performance on multiple image\nrestoration tasks, including multi-task image restoration, all-in-one image\nrestoration, and ultra-high-definition image restoration tasks. Note that we\ncan train a state-of-the-art image restoration model on an\nultra-high-definition (4K resolution) dataset using only one consumer-grade GPU\nin less than 8 hours (500 savings in computing resources and immeasurable\ntraining time).", "published": "2025-04-21 03:00:18", "link": "http://arxiv.org/abs/2504.14826v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Real-Time Sleepiness Detection for Driver State Monitoring System", "abstract": "A driver face monitoring system can detect driver fatigue, which is a\nsignificant factor in many accidents, using computer vision techniques. In this\npaper, we present a real-time technique for driver eye state detection. First,\nthe face is detected, and the eyes are located within the face region for\ntracking. A normalized cross-correlation-based online dynamic template matching\ntechnique, combined with Kalman filter tracking, is proposed to track the\ndetected eye positions in subsequent image frames. A support vector machine\nwith histogram of oriented gradients (HOG) features is used to classify the\nstate of the eyes as open or closed. If the eyes remain closed for a specified\nperiod, the driver is considered to be asleep, and an alarm is triggered.", "published": "2025-04-21 02:15:37", "link": "http://arxiv.org/abs/2504.14807v1", "categories": ["cs.CV", "cs.HC", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Survey on Small Sample Imbalance Problem: Metrics, Feature Analysis, and Solutions", "abstract": "The small sample imbalance (S&I) problem is a major challenge in machine\nlearning and data analysis. It is characterized by a small number of samples\nand an imbalanced class distribution, which leads to poor model performance. In\naddition, indistinct inter-class feature distributions further complicate\nclassification tasks. Existing methods often rely on algorithmic heuristics\nwithout sufficiently analyzing the underlying data characteristics. We argue\nthat a detailed analysis from the data perspective is essential before\ndeveloping an appropriate solution. Therefore, this paper proposes a systematic\nanalytical framework for the S\\&I problem. We first summarize imbalance metrics\nand complexity analysis methods, highlighting the need for interpretable\nbenchmarks to characterize S&I problems. Second, we review recent solutions for\nconventional, complexity-based, and extreme S&I problems, revealing\nmethodological differences in handling various data distributions. Our summary\nfinds that resampling remains a widely adopted solution. However, we conduct\nexperiments on binary and multiclass datasets, revealing that classifier\nperformance differences significantly exceed the improvements achieved through\nresampling. Finally, this paper highlights open questions and discusses future\ntrends.", "published": "2025-04-21 01:58:29", "link": "http://arxiv.org/abs/2504.14800v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Verifying Robust Unlearning: Probing Residual Knowledge in Unlearned Models", "abstract": "Machine Unlearning (MUL) is crucial for privacy protection and content\nregulation, yet recent studies reveal that traces of forgotten information\npersist in unlearned models, enabling adversaries to resurface removed\nknowledge. Existing verification methods only confirm whether unlearning was\nexecuted, failing to detect such residual information leaks. To address this,\nwe introduce the concept of Robust Unlearning, ensuring models are\nindistinguishable from retraining and resistant to adversarial recovery. To\nempirically evaluate whether unlearning techniques meet this security standard,\nwe propose the Unlearning Mapping Attack (UMA), a post-unlearning verification\nframework that actively probes models for forgotten traces using adversarial\nqueries. Extensive experiments on discriminative and generative tasks show that\nexisting unlearning techniques remain vulnerable, even when passing existing\nverification metrics. By establishing UMA as a practical verification tool,\nthis study sets a new standard for assessing and enhancing machine unlearning\nsecurity.", "published": "2025-04-21 01:56:15", "link": "http://arxiv.org/abs/2504.14798v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Segmentation with Noisy Labels via Spatially Correlated Distributions", "abstract": "In semantic segmentation, the accuracy of models heavily depends on the\nhigh-quality annotations. However, in many practical scenarios such as medical\nimaging and remote sensing, obtaining true annotations is not straightforward\nand usually requires significant human labor. Relying on human labor often\nintroduces annotation errors, including mislabeling, omissions, and\ninconsistency between annotators. In the case of remote sensing, differences in\nprocurement time can lead to misaligned ground truth annotations. These label\nerrors are not independently distributed, and instead usually appear in\nspatially connected regions where adjacent pixels are more likely to share the\nsame errors. To address these issues, we propose an approximate Bayesian\nestimation based on a probabilistic model that assumes training data includes\nlabel errors, incorporating the tendency for these errors to occur with spatial\ncorrelations between adjacent pixels. Bayesian inference requires computing the\nposterior distribution of label errors, which becomes intractable when spatial\ncorrelations are present. We represent the correlation of label errors between\nadjacent pixels through a Gaussian distribution whose covariance is structured\nby a Kac-Murdock-Szeg\\\"{o} (KMS) matrix, solving the computational challenges.\nThrough experiments on multiple segmentation tasks, we confirm that leveraging\nthe spatial correlation of label errors significantly improves performance.\nNotably, in specific tasks such as lung segmentation, the proposed method\nachieves performance comparable to training with clean labels under moderate\nnoise levels. Code is available at\nhttps://github.com/pfnet-research/Bayesian_SpatialCorr.", "published": "2025-04-21 01:50:10", "link": "http://arxiv.org/abs/2504.14795v1", "categories": ["eess.IV", "cs.CV", "cs.LG", "stat.ML"], "primary_category": "eess.IV"}
{"title": "When Cloud Removal Meets Diffusion Model in Remote Sensing", "abstract": "Cloud occlusion significantly hinders remote sensing applications by\nobstructing surface information and complicating analysis. To address this, we\npropose DC4CR (Diffusion Control for Cloud Removal), a novel multimodal\ndiffusion-based framework for cloud removal in remote sensing imagery. Our\nmethod introduces prompt-driven control, allowing selective removal of thin and\nthick clouds without relying on pre-generated cloud masks, thereby enhancing\npreprocessing efficiency and model adaptability. Additionally, we integrate\nlow-rank adaptation for computational efficiency, subject-driven generation for\nimproved generalization, and grouped learning to enhance performance on small\ndatasets. Designed as a plug-and-play module, DC4CR seamlessly integrates into\nexisting cloud removal models, providing a scalable and robust solution.\nExtensive experiments on the RICE and CUHK-CR datasets demonstrate\nstate-of-the-art performance, achieving superior cloud removal across diverse\nconditions. This work presents a practical and efficient approach for remote\nsensing image processing with broad real-world applications.", "published": "2025-04-21 00:56:57", "link": "http://arxiv.org/abs/2504.14785v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Sunflowers and Ramsey problems for restricted intersections", "abstract": "Extremal problems on set systems with restricted intersections have been an\nimportant part of combinatorics in the last 70 year. In this paper, we study\nthe following Ramsey version of these problems. Given a set $L\\subseteq\n\\{0,\\dots,k-1\\}$ and a family $\\mathcal{F}$ of $k$-element sets which does not\ncontain a sunflower with $m$ petals whose kernel size is in $L$, how large a\nsubfamily of $\\mathcal{F}$ can we find in which no pair has intersection size\nin $L$? We give matching upper and lower bounds, determining the dependence on\n$m$ for all $k$ and $L$. This problem also finds applications in quantum\ncomputing.\n  As an application of our techniques, we also obtain a variant of F\\\"uredi's\ncelebrated semilattice lemma, which is a key tool in the powerful delta-system\nmethod. We prove that one cannot remove the double-exponential dependency on\nthe uniformity in F\\\"uredi's result, however, we provide an alternative with\nsignificantly better, single-exponential dependency on the parameters, which is\nstill strong enough for most applications of the delta-system method.", "published": "2025-04-21 17:46:21", "link": "http://arxiv.org/abs/2504.15264v1", "categories": ["math.CO", "cs.DM", "quant-ph"], "primary_category": "math.CO"}
{"title": "Explicit Lossless Vertex Expanders", "abstract": "We give the first construction of explicit constant-degree lossless vertex\nexpanders. Specifically, for any $\\varepsilon > 0$ and sufficiently large $d$,\nwe give an explicit construction of an infinite family of $d$-regular graphs\nwhere every small set $S$ of vertices has $(1-\\varepsilon)d|S|$ neighbors\n(which implies $(1-2\\varepsilon)d|S|$ unique-neighbors). Our results also\nextend naturally to construct biregular bipartite graphs of any constant\nimbalance, where small sets on each side have strong expansion guarantees. The\ngraphs we construct admit a free group action, and hence realize new families\nof quantum LDPC codes of Lin and M. Hsieh with a linear time decoding\nalgorithm.\n  Our construction is based on taking an appropriate product of a\nconstant-sized lossless expander with a base graph constructed from Ramanujan\nCayley cubical complexes.", "published": "2025-04-21 13:20:37", "link": "http://arxiv.org/abs/2504.15087v1", "categories": ["math.CO", "cs.CC", "cs.DM", "cs.DS", "math.GR"], "primary_category": "math.CO"}
{"title": "Linear Item-Item Model with Neural Knowledge for Session-based Recommendation", "abstract": "Session-based recommendation (SBR) aims to predict users' subsequent actions\nby modeling short-term interactions within sessions. Existing neural models\nprimarily focus on capturing complex dependencies for sequential item\ntransitions. As an alternative solution, linear item-item models mainly\nidentify strong co-occurrence patterns across items and support faster\ninference speed. Although each paradigm has been actively studied in SBR, their\nfundamental differences in capturing item relationships and how to bridge these\ndistinct modeling paradigms effectively remain unexplored. In this paper, we\npropose a novel SBR model, namely Linear Item-Item model with Neural Knowledge\n(LINK), which integrates both types of knowledge into a unified linear\nframework. Specifically, we design two specialized components of LINK: (i)\nLinear knowledge-enhanced Item-item Similarity model (LIS), which refines the\nitem similarity correlation via self-distillation, and (ii) Neural\nknowledge-enhanced Item-item Transition model (NIT), which seamlessly\nincorporates complicated neural knowledge distilled from the off-the-shelf\nneural model. Extensive experiments demonstrate that LINK outperforms\nstate-of-the-art linear SBR models across six real-world datasets, achieving\nimprovements of up to 14.78% and 11.04% in Recall@20 and MRR@20 while showing\nup to 813x fewer inference FLOPs. Our code is available at\nhttps://github.com/jin530/LINK.", "published": "2025-04-21 12:34:57", "link": "http://arxiv.org/abs/2504.15057v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Understanding Accuracy-Fairness Trade-offs in Re-ranking through Elasticity in Economics", "abstract": "Fairness is an increasingly important factor in re-ranking tasks. Prior work\nhas identified a trade-off between ranking accuracy and item fairness. However,\nthe underlying mechanisms are still not fully understood. An analogy can be\ndrawn between re-ranking and the dynamics of economic transactions. The\naccuracy-fairness trade-off parallels the coupling of the commodity tax\ntransfer process. Fairness considerations in re-ranking, similar to a commodity\ntax on suppliers, ultimately translate into a cost passed on to consumers.\nAnalogously, item-side fairness constraints result in a decline in user-side\naccuracy. In economics, the extent to which commodity tax on the supplier (item\nfairness) transfers to commodity tax on users (accuracy loss) is formalized\nusing the notion of elasticity. The re-ranking fairness-accuracy trade-off is\nsimilarly governed by the elasticity of utility between item groups. This\ninsight underscores the limitations of current fair re-ranking evaluations,\nwhich often rely solely on a single fairness metric, hindering comprehensive\nassessment of fair re-ranking algorithms. Centered around the concept of\nelasticity, this work presents two significant contributions. We introduce the\nElastic Fairness Curve (EF-Curve) as an evaluation framework. This framework\nenables a comparative analysis of algorithm performance across different\nelasticity levels, facilitating the selection of the most suitable approach.\nFurthermore, we propose ElasticRank, a fair re-ranking algorithm that employs\nelasticity calculations to adjust inter-item distances within a curved space.\nExperiments on three widely used ranking datasets demonstrate its effectiveness\nand efficiency.", "published": "2025-04-21 09:41:08", "link": "http://arxiv.org/abs/2504.14991v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "ColBERT-serve: Efficient Multi-Stage Memory-Mapped Scoring", "abstract": "We study serving retrieval models, specifically late interaction models like\nColBERT, to many concurrent users at once and under a small budget, in which\nthe index may not fit in memory. We present ColBERT-serve, a novel serving\nsystem that applies a memory-mapping strategy to the ColBERT index, reducing\nRAM usage by 90% and permitting its deployment on cheap servers, and\nincorporates a multi-stage architecture with hybrid scoring, reducing ColBERT's\nquery latency and supporting many concurrent queries in parallel.", "published": "2025-04-21 07:18:09", "link": "http://arxiv.org/abs/2504.14903v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Stitching Inner Product and Euclidean Metrics for Topology-aware Maximum Inner Product Search", "abstract": "Maximum Inner Product Search (MIPS) is a fundamental challenge in machine\nlearning and information retrieval, particularly in high-dimensional data\napplications. Existing approaches to MIPS either rely solely on Inner Product\n(IP) similarity, which faces issues with local optima and redundant\ncomputations, or reduce the MIPS problem to the Nearest Neighbor Search under\nthe Euclidean metric via space projection, leading to topology destruction and\ninformation loss. Despite the divergence of the two paradigms, we argue that\nthere is no inherent binary opposition between IP and Euclidean metrics. By\nstitching IP and Euclidean in the design of indexing and search algorithms, we\ncan significantly enhance MIPS performance. Specifically, this paper explores\nthe theoretical and empirical connections between these two metrics from the\nMIPS perspective. Our investigation, grounded in graph-based search, reveals\nthat different indexing and search strategies offer distinct advantages for\nMIPS, depending on the underlying data topology. Building on these insights, we\nintroduce a novel graph-based index called Metric-Amphibious Graph (MAG) and a\ncorresponding search algorithm, Adaptive Navigation with Metric Switch (ANMS).\nTo facilitate parameter tuning for optimal performance, we identify three\nstatistical indicators that capture essential data topology properties and\ncorrelate strongly with parameter tuning. Extensive experiments on 12\nreal-world datasets demonstrate that MAG outperforms existing state-of-the-art\nmethods, achieving up to 4x search speedup while maintaining adaptability and\nscalability.", "published": "2025-04-21 05:01:58", "link": "http://arxiv.org/abs/2504.14861v1", "categories": ["cs.DB", "cs.IR"], "primary_category": "cs.DB"}
{"title": "Enhancing the Patent Matching Capability of Large Language Models via the Memory Graph", "abstract": "Intellectual Property (IP) management involves strategically protecting and\nutilizing intellectual assets to enhance organizational innovation,\ncompetitiveness, and value creation. Patent matching is a crucial task in\nintellectual property management, which facilitates the organization and\nutilization of patents. Existing models often rely on the emergent capabilities\nof Large Language Models (LLMs) and leverage them to identify related patents\ndirectly. However, these methods usually depend on matching keywords and\noverlook the hierarchical classification and categorical relationships of\npatents. In this paper, we propose MemGraph, a method that augments the patent\nmatching capabilities of LLMs by incorporating a memory graph derived from\ntheir parametric memory. Specifically, MemGraph prompts LLMs to traverse their\nmemory to identify relevant entities within patents, followed by attributing\nthese entities to corresponding ontologies. After traversing the memory graph,\nwe utilize extracted entities and ontologies to improve the capability of LLM\nin comprehending the semantics of patents. Experimental results on the\nPatentMatch dataset demonstrate the effectiveness of MemGraph, achieving a\n17.68% performance improvement over baseline LLMs. The further analysis\nhighlights the generalization ability of MemGraph across various LLMs, both\nin-domain and out-of-domain, and its capacity to enhance the internal reasoning\nprocesses of LLMs during patent matching. All data and codes are available at\nhttps://github.com/NEUIR/MemGraph.", "published": "2025-04-21 03:56:56", "link": "http://arxiv.org/abs/2504.14845v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "The 1st EReL@MIR Workshop on Efficient Representation Learning for Multimodal Information Retrieval", "abstract": "Multimodal representation learning has garnered significant attention in the\nAI community, largely due to the success of large pre-trained multimodal\nfoundation models like LLaMA, GPT, Mistral, and CLIP. These models have\nachieved remarkable performance across various tasks of multimodal information\nretrieval (MIR), including web search, cross-modal retrieval, and recommender\nsystems, etc. However, due to their enormous parameter sizes, significant\nefficiency challenges emerge across training, deployment, and inference stages\nwhen adapting these models' representation for IR tasks. These challenges\npresent substantial obstacles to the practical adaptation of foundation models\nfor representation learning in information retrieval tasks.\n  To address these pressing issues, we propose organizing the first EReL@MIR\nworkshop at the Web Conference 2025, inviting participants to explore novel\nsolutions, emerging problems, challenges, efficiency evaluation metrics and\nbenchmarks. This workshop aims to provide a platform for both academic and\nindustry researchers to engage in discussions, share insights, and foster\ncollaboration toward achieving efficient and effective representation learning\nfor multimodal information retrieval in the era of large foundation models.", "published": "2025-04-21 01:10:59", "link": "http://arxiv.org/abs/2504.14788v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Linear Complementary Pairs of Quasi-Cyclic and Quasi-Twisted Codes", "abstract": "In this paper, we provide a polynomial characterization of linear\ncomplementary pairs of quasi-cyclic and quasi-twisted codes of index 2. We also\ngive several examples of linear complementary pairs of quasi-cyclic and\nquasi-twisted codes with (almost) optimal security parameters.", "published": "2025-04-21 17:08:28", "link": "http://arxiv.org/abs/2504.15231v1", "categories": ["cs.IT", "math.IT", "94B05, 94B15, 94B60"], "primary_category": "cs.IT"}
{"title": "Soft-Output from Covered Space Decoding of Product Codes", "abstract": "In this work, we propose a new soft-in soft-out decoder called soft-output\nfrom covered space (SOCS) decoder. It estimates the a posteriori reliability\nbased on the space explored by a list decoder, i.e., the set of vectors for\nwhich the list decoder knows whether they are codewords. This approach enables\na more accurate calculation of the a posteriori reliability and results in\ngains of up to 0.25$\\,$dB for turbo product decoding with SOCS decoding\ncompared to Chase-Pyndiah decoding.", "published": "2025-04-21 16:20:13", "link": "http://arxiv.org/abs/2504.15204v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Extending the ElGamal Cryptosystem to the Third Group of Units of $\\Z_{n}$", "abstract": "In this paper, we extend the ElGamal cryptosystem to the third group of units\nof the ring $\\Z_{n}$, which we prove to be more secure than the previous\nextensions. We describe the arithmetic needed in the new setting. We also\nprovide some numerical simulations that shows the security and efficiency of\nour proposed cryptosystem.", "published": "2025-04-21 16:17:53", "link": "http://arxiv.org/abs/2504.15202v1", "categories": ["cs.CR", "cs.IT", "math.GR", "math.IT", "math.PR", "math.RA", "20D45, 68W30"], "primary_category": "cs.CR"}
{"title": "Energy-Efficient UAV-Mounted RIS for IoT: A Hybrid Energy Harvesting and DRL Approach", "abstract": "Many future Internet of Things (IoT) applications are expected to rely\nheavily on reconfigurable intelligent surface (RIS)-aided unmanned aerial\nvehicles (UAVs). However, the endurance of such systems is constrained by the\nlimited onboard energy, where frequent recharging or battery replacements are\nrequired. This consequently disrupts continuous operation and may be\nimpractical in disaster scenarios. To address this challenge, we explore a dual\nenergy harvesting (EH) framework that integrates time-switching (TS),\npower-splitting (PS), and element-splitting (ES) EH protocols for radio\nfrequency energy, along with solar energy as a renewable source. First, we\npresent the proposed system architecture and EH operating protocols,\nintroducing the proposed hybrid ES-TS-PS EH strategy to extend UAV-mounted RIS\nendurance. Next, we outline key application scenarios and the associated design\nchallenges. After that, a deep reinforcement learning-based framework is\nintroduced to maximize the EH efficiency by jointly optimizing UAV trajectory,\nRIS phase shifts, and EH strategies. The framework considers dual EH, hardware\nimpairments, and channel state information imperfections to reflect real-world\ndeployment conditions. The optimization problem is formulated as a Markov\ndecision process and solved using an enhanced deep deterministic policy\ngradient algorithm, incorporating clipped double Q-learning and softmax-based\nQ-value estimation for improved stability and efficiency. The results\ndemonstrate significant performance gains compared to the considered baseline\napproaches. Finally, possible challenges and open research directions are\npresented, highlighting the transformative potential of energy-efficient\nUAV-mounted RIS networks for IoT systems.", "published": "2025-04-21 11:54:40", "link": "http://arxiv.org/abs/2504.15043v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Energy-Efficient Irregular RIS-aided UAV-Assisted Optimization: A Deep Reinforcement Learning Approach", "abstract": "Reconfigurable intelligent surfaces (RISs) enhance unmanned aerial vehicles\n(UAV)-assisted communication by extending coverage, improving efficiency, and\nenabling adaptive beamforming. This paper investigates a multiple-input\nsingle-output system where a base station (BS) communicates with multiple\nsingle-antenna users through a UAV-assisted RIS, dynamically adapting to user\nmobility to maintain seamless connectivity. To extend UAV-RIS operational time,\nwe propose a hybrid energy-harvesting resource allocation (HERA) strategy that\nleverages the irregular RIS ON/OFF capability while adapting to BS-RIS and\nRIS-user channels. The HERA strategy dynamically allocates resources by\nintegrating non-linear radio frequency energy harvesting (EH) based on the\ntime-switching (TS) approach and renewable energy as a complementary source. A\nnon-convex mixed-integer nonlinear programming problem is formulated to\nmaximize EH efficiency while satisfying quality-of-service, power, and energy\nconstraints under channel state information and hardware impairments. The\noptimization jointly considers BS transmit power, RIS phase shifts, TS factor,\nand RIS element selection as decision variables. To solve this problem, we\nintroduce the energy-efficient deep deterministic policy gradient (EE-DDPG)\nalgorithm. This deep reinforcement learning (DRL)-based approach integrates\naction clipping and softmax-weighted Q-value estimation to mitigate estimation\nerrors. Simulation results demonstrate that the proposed HERA method\nsignificantly improves EH efficiency, reaching up to 81.5\\% and 73.2\\% in\nsingle-user and multi-user scenarios, respectively, contributing to extended\nUAV operational time. Additionally, the proposed EE-DDPG model outperforms\nexisting DRL algorithms while maintaining practical computational complexity.", "published": "2025-04-21 11:40:33", "link": "http://arxiv.org/abs/2504.15031v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Sum-Rate Maximization for NOMA-Assisted Pinching-Antenna Systems", "abstract": "In this letter, we investigate a non-orthogonal multiple access (NOMA)\nassisted downlink pinching-antenna system. Leveraging the ability of pinching\nantennas to flexibly adjust users' wireless channel conditions, we formulate an\noptimization problem to maximize the sum rate by optimizing both the users'\npower allocation coefficients and the positions of pinching antennas. The\noptimal power allocation coefficients are obtained in closed-form by using the\nKarush-Kuhn-Tucker (KKT) conditions. The optimization problem of pinching\nantenna placements is more challenging than the power allocation problem, and\nis solved by a bisection-based search algorithm. In particular, the algorithm\nfirst optimizes the antenna placements to create favorable channel disparities\nbetween users, followed by fine-tuning the antenna positions to ensure the\nphase alignment for users, thus maximizing the sum rate. Simulation results\ndemonstrate that, compared to conventional-antenna systems, pinching antennas\ncan significantly enhance the sum rate in NOMA scenarios, and the proposed\nbisection-based search algorithm can achieve a sum rate nearly equivalent to\nthat of an exhaustive search.", "published": "2025-04-21 10:12:00", "link": "http://arxiv.org/abs/2504.15006v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Short Proof of Coding Theorems for Reed-Muller Codes", "abstract": "In this paper, we present a short proof that ReedMuller (RM) codes are\nentropy-achieving as source coding for Bernoulli sources and capacity-achieving\nas channel coding for binary memoryless symmetric (BMS) channels, also known as\nmemoryless binary-input output-symmetric (BIOS) channels, in terms of bit error\nrate (BER) under maximum-likelihood (ML) decoding.", "published": "2025-04-21 03:54:27", "link": "http://arxiv.org/abs/2504.14842v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Optimal Linear MAP Decoding of Convolutional Codes", "abstract": "In this paper, we propose a linear representation of BCJR maximum a\nposteriori probability (MAP) decoding of a rate 1/2 convolutional code (CC),\nreferred to as the linear MAP decoding (LMAP). We discover that the MAP forward\nand backward decoding can be implemented by the corresponding dual soft input\nand soft output (SISO) encoders using shift registers. The bidrectional MAP\ndecoding output can be obtained by combining the contents of respective forward\nand backward dual encoders. Represented using simple shift-registers, LMAP\ndecoder maps naturally to hardware registers and thus can be easily\nimplemented. Simulation results demonstrate that the LMAP decoding achieves the\nsame performance as the BCJR MAP decoding, but has a significantly reduced\ndecoding delay. For the block length 64, the CC of the memory length 14 with\nLMAP decoding surpasses the random coding union (RCU) bound by approximately\n0.5 dB at a BLER of $10^{-3}$, and closely approaches both the normal\napproximation (NA) and meta-converse (MC) bounds.", "published": "2025-04-21 00:31:22", "link": "http://arxiv.org/abs/2504.14778v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On Learning Parallel Pancakes with Mostly Uniform Weights", "abstract": "We study the complexity of learning $k$-mixtures of Gaussians ($k$-GMMs) on\n$\\mathbb{R}^d$. This task is known to have complexity $d^{\\Omega(k)}$ in full\ngenerality. To circumvent this exponential lower bound on the number of\ncomponents, research has focused on learning families of GMMs satisfying\nadditional structural properties. A natural assumption posits that the\ncomponent weights are not exponentially small and that the components have the\nsame unknown covariance. Recent work gave a $d^{O(\\log(1/w_{\\min}))}$-time\nalgorithm for this class of GMMs, where $w_{\\min}$ is the minimum weight. Our\nfirst main result is a Statistical Query (SQ) lower bound showing that this\nquasi-polynomial upper bound is essentially best possible, even for the special\ncase of uniform weights. Specifically, we show that it is SQ-hard to\ndistinguish between such a mixture and the standard Gaussian. We further\nexplore how the distribution of weights affects the complexity of this task.\nOur second main result is a quasi-polynomial upper bound for the aforementioned\ntesting task when most of the weights are uniform while a small fraction of the\nweights are potentially arbitrary.", "published": "2025-04-21 17:31:55", "link": "http://arxiv.org/abs/2504.15251v1", "categories": ["cs.LG", "cs.DS", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Faster Algorithms for Agnostically Learning Disjunctions and their Implications", "abstract": "We study the algorithmic task of learning Boolean disjunctions in the\ndistribution-free agnostic PAC model. The best known agnostic learner for the\nclass of disjunctions over $\\{0, 1\\}^n$ is the $L_1$-polynomial regression\nalgorithm, achieving complexity $2^{\\tilde{O}(n^{1/2})}$. This complexity bound\nis known to be nearly best possible within the class of Correlational\nStatistical Query (CSQ) algorithms. In this work, we develop an agnostic\nlearner for this concept class with complexity $2^{\\tilde{O}(n^{1/3})}$. Our\nalgorithm can be implemented in the Statistical Query (SQ) model, providing the\nfirst separation between the SQ and CSQ models in distribution-free agnostic\nlearning.", "published": "2025-04-21 17:16:14", "link": "http://arxiv.org/abs/2504.15244v1", "categories": ["cs.LG", "cs.DS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Single-loop Algorithms for Stochastic Non-convex Optimization with Weakly-Convex Constraints", "abstract": "Constrained optimization with multiple functional inequality constraints has\nsignificant applications in machine learning. This paper examines a crucial\nsubset of such problems where both the objective and constraint functions are\nweakly convex. Existing methods often face limitations, including slow\nconvergence rates or reliance on double-loop algorithmic designs. To overcome\nthese challenges, we introduce a novel single-loop penalty-based stochastic\nalgorithm. Following the classical exact penalty method, our approach employs a\n{\\bf hinge-based penalty}, which permits the use of a constant penalty\nparameter, enabling us to achieve a {\\bf state-of-the-art complexity} for\nfinding an approximate Karush-Kuhn-Tucker (KKT) solution. We further extend our\nalgorithm to address finite-sum coupled compositional objectives, which are\nprevalent in artificial intelligence applications, establishing improved\ncomplexity over existing approaches. Finally, we validate our method through\nexperiments on fair learning with receiver operating characteristic (ROC)\nfairness constraints and continual learning with non-forgetting constraints.", "published": "2025-04-21 17:15:48", "link": "http://arxiv.org/abs/2504.15243v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Conformalized-KANs: Uncertainty Quantification with Coverage Guarantees for Kolmogorov-Arnold Networks (KANs) in Scientific Machine Learning", "abstract": "This paper explores uncertainty quantification (UQ) methods in the context of\nKolmogorov-Arnold Networks (KANs). We apply an ensemble approach to KANs to\nobtain a heuristic measure of UQ, enhancing interpretability and robustness in\nmodeling complex functions. Building on this, we introduce Conformalized-KANs,\nwhich integrate conformal prediction, a distribution-free UQ technique, with\nKAN ensembles to generate calibrated prediction intervals with guaranteed\ncoverage. Extensive numerical experiments are conducted to evaluate the\neffectiveness of these methods, focusing particularly on the robustness and\naccuracy of the prediction intervals under various hyperparameter settings. We\nshow that the conformal KAN predictions can be applied to recent extensions of\nKANs, including Finite Basis KANs (FBKANs) and multifideilty KANs (MFKANs). The\nresults demonstrate the potential of our approaches to improve the reliability\nand applicability of KANs in scientific machine learning.", "published": "2025-04-21 17:14:05", "link": "http://arxiv.org/abs/2504.15240v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Deep Learning Framework for Sequence Mining with Bidirectional LSTM and Multi-Scale Attention", "abstract": "This paper addresses the challenges of mining latent patterns and modeling\ncontextual dependencies in complex sequence data. A sequence pattern mining\nalgorithm is proposed by integrating Bidirectional Long Short-Term Memory\n(BiLSTM) with a multi-scale attention mechanism. The BiLSTM captures both\nforward and backward dependencies in sequences, enhancing the model's ability\nto perceive global contextual structures. At the same time, the multi-scale\nattention module assigns adaptive weights to key feature regions under\ndifferent window sizes. This improves the model's responsiveness to both local\nand global important information. Extensive experiments are conducted on a\npublicly available multivariate time series dataset. The proposed model is\ncompared with several mainstream sequence modeling methods. Results show that\nit outperforms existing models in terms of accuracy, precision, and recall.\nThis confirms the effectiveness and robustness of the proposed architecture in\ncomplex pattern recognition tasks. Further ablation studies and sensitivity\nanalyses are carried out to investigate the effects of attention scale and\ninput sequence length on model performance. These results provide empirical\nsupport for structural optimization of the model.", "published": "2025-04-21 16:53:02", "link": "http://arxiv.org/abs/2504.15223v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DRAGON: Distributional Rewards Optimize Diffusion Generative Models", "abstract": "We present Distributional RewArds for Generative OptimizatioN (DRAGON), a\nversatile framework for fine-tuning media generation models towards a desired\noutcome. Compared with traditional reinforcement learning with human feedback\n(RLHF) or pairwise preference approaches such as direct preference optimization\n(DPO), DRAGON is more flexible. It can optimize reward functions that evaluate\neither individual examples or distributions of them, making it compatible with\na broad spectrum of instance-wise, instance-to-distribution, and\ndistribution-to-distribution rewards. Leveraging this versatility, we construct\nnovel reward functions by selecting an encoder and a set of reference examples\nto create an exemplar distribution. When cross-modality encoders such as CLAP\nare used, the reference examples may be of a different modality (e.g., text\nversus audio). Then, DRAGON gathers online and on-policy generations, scores\nthem to construct a positive demonstration set and a negative set, and\nleverages the contrast between the two sets to maximize the reward. For\nevaluation, we fine-tune an audio-domain text-to-music diffusion model with 20\ndifferent reward functions, including a custom music aesthetics model, CLAP\nscore, Vendi diversity, and Frechet audio distance (FAD). We further compare\ninstance-wise (per-song) and full-dataset FAD settings while ablating multiple\nFAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an\n81.45% average win rate. Moreover, reward functions based on exemplar sets\nindeed enhance generations and are comparable to model-based rewards. With an\nappropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality\nwin rate without training on human preference annotations. As such, DRAGON\nexhibits a new approach to designing and optimizing reward functions for\nimproving human-perceived quality. Sound examples at\nhttps://ml-dragon.github.io/web.", "published": "2025-04-21 16:41:40", "link": "http://arxiv.org/abs/2504.15217v1", "categories": ["cs.SD", "cs.LG"], "primary_category": "cs.SD"}
{"title": "Histogram-based Parameter-efficient Tuning for Passive Sonar Classification", "abstract": "Parameter-efficient transfer learning (PETL) methods adapt large artificial\nneural networks to downstream tasks without fine-tuning the entire model.\nHowever, existing additive methods, such as adapters, sometimes struggle to\ncapture distributional shifts in intermediate feature embeddings. We propose a\nnovel histogram-based parameter-efficient tuning (HPT) technique that captures\nthe statistics of the target domain and modulates the embeddings. Experimental\nresults on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD)\ndemonstrate that HPT outperforms conventional adapters. Notably, HPT achieves\n91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yields\nfeature representations closer to those of fully fine-tuned models. Overall,\nHPT balances parameter savings and performance, providing a distribution-aware\nalternative to existing adapters and shows a promising direction for scalable\ntransfer learning in resource-constrained environments. The code is publicly\navailable:\nhttps://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.", "published": "2025-04-21 16:36:38", "link": "http://arxiv.org/abs/2504.15214v1", "categories": ["cs.LG", "cs.SD"], "primary_category": "cs.LG"}
{"title": "How Global Calibration Strengthens Multiaccuracy", "abstract": "Multiaccuracy and multicalibration are multigroup fairness notions for\nprediction that have found numerous applications in learning and computational\ncomplexity. They can be achieved from a single learning primitive: weak\nagnostic learning. Here we investigate the power of multiaccuracy as a learning\nprimitive, both with and without the additional assumption of calibration. We\nfind that multiaccuracy in itself is rather weak, but that the addition of\nglobal calibration (this notion is called calibrated multiaccuracy) boosts its\npower substantially, enough to recover implications that were previously known\nonly assuming the stronger notion of multicalibration.\n  We give evidence that multiaccuracy might not be as powerful as standard weak\nagnostic learning, by showing that there is no way to post-process a\nmultiaccurate predictor to get a weak learner, even assuming the best\nhypothesis has correlation $1/2$. Rather, we show that it yields a restricted\nform of weak agnostic learning, which requires some concept in the class to\nhave correlation greater than $1/2$ with the labels. However, by also requiring\nthe predictor to be calibrated, we recover not just weak, but strong agnostic\nlearning.\n  A similar picture emerges when we consider the derivation of hardcore\nmeasures from predictors satisfying multigroup fairness notions. On the one\nhand, while multiaccuracy only yields hardcore measures of density half the\noptimal, we show that (a weighted version of) calibrated multiaccuracy achieves\noptimal density.\n  Our results yield new insights into the complementary roles played by\nmultiaccuracy and calibration in each setting. They shed light on why\nmultiaccuracy and global calibration, although not particularly powerful by\nthemselves, together yield considerably stronger notions.", "published": "2025-04-21 16:22:44", "link": "http://arxiv.org/abs/2504.15206v1", "categories": ["cs.LG", "cs.CC"], "primary_category": "cs.LG"}
{"title": "Audio-Visual Class-Incremental Learning for Fish Feeding intensity Assessment in Aquaculture", "abstract": "Fish Feeding Intensity Assessment (FFIA) is crucial in industrial aquaculture\nmanagement. Recent multi-modal approaches have shown promise in improving FFIA\nrobustness and efficiency. However, these methods face significant challenges\nwhen adapting to new fish species or environments due to catastrophic\nforgetting and the lack of suitable datasets. To address these limitations, we\nfirst introduce AV-CIL-FFIA, a new dataset comprising 81,932 labelled\naudio-visual clips capturing feeding intensities across six different fish\nspecies in real aquaculture environments. Then, we pioneer audio-visual class\nincremental learning (CIL) for FFIA and demonstrate through benchmarking on\nAV-CIL-FFIA that it significantly outperforms single-modality methods. Existing\nCIL methods rely heavily on historical data. Exemplar-based approaches store\nraw samples, creating storage challenges, while exemplar-free methods avoid\ndata storage but struggle to distinguish subtle feeding intensity variations\nacross different fish species. To overcome these limitations, we introduce\nHAIL-FFIA, a novel audio-visual class-incremental learning framework that\nbridges this gap with a prototype-based approach that achieves exemplar-free\nefficiency while preserving essential knowledge through compact feature\nrepresentations. Specifically, HAIL-FFIA employs hierarchical representation\nlearning with a dual-path knowledge preservation mechanism that separates\ngeneral intensity knowledge from fish-specific characteristics. Additionally,\nit features a dynamic modality balancing system that adaptively adjusts the\nimportance of audio versus visual information based on feeding behaviour\nstages. Experimental results show that HAIL-FFIA is superior to SOTA methods on\nAV-CIL-FFIA, achieving higher accuracy with lower storage needs while\neffectively mitigating catastrophic forgetting in incremental fish species\nlearning.", "published": "2025-04-21 15:24:34", "link": "http://arxiv.org/abs/2504.15171v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Survey of Loss Augmented Knowledge Tracing", "abstract": "The training of artificial neural networks is heavily dependent on the\ncareful selection of an appropriate loss function. While commonly used loss\nfunctions, such as cross-entropy and mean squared error (MSE), generally\nsuffice for a broad range of tasks, challenges often emerge due to limitations\nin data quality or inefficiencies within the learning process. In such\ncircumstances, the integration of supplementary terms into the loss function\ncan serve to address these challenges, enhancing both model performance and\nrobustness. Two prominent techniques, loss regularization and contrastive\nlearning, have been identified as effective strategies for augmenting the\ncapacity of loss functions in artificial neural networks.\n  Knowledge tracing is a compelling area of research that leverages predictive\nartificial intelligence to facilitate the automation of personalized and\nefficient educational experiences for students. In this paper, we provide a\ncomprehensive review of the deep learning-based knowledge tracing (DKT)\nalgorithms trained using advanced loss functions and discuss their improvements\nover prior techniques. We discuss contrastive knowledge tracing algorithms,\nsuch as Bi-CLKT, CL4KT, SP-CLKT, CoSKT, and prediction-consistent DKT,\nproviding performance benchmarks and insights into real-world deployment\nchallenges. The survey concludes with future research directions, including\nhybrid loss strategies and context-aware modeling.", "published": "2025-04-21 15:09:40", "link": "http://arxiv.org/abs/2504.15163v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Advanced posterior analyses of hidden Markov models: finite Markov chain imbedding and hybrid decoding", "abstract": "Two major tasks in applications of hidden Markov models are to (i) compute\ndistributions of summary statistics of the hidden state sequence, and (ii)\ndecode the hidden state sequence. We describe finite Markov chain imbedding\n(FMCI) and hybrid decoding to solve each of these two tasks. In the first part\nof our paper we use FMCI to compute posterior distributions of summary\nstatistics such as the number of visits to a hidden state, the total time spent\nin a hidden state, the dwell time in a hidden state, and the longest run\nlength. We use simulations from the hidden state sequence, conditional on the\nobserved sequence, to establish the FMCI framework. In the second part of our\npaper we apply hybrid segmentation for improved decoding of a HMM. We\ndemonstrate that hybrid decoding shows increased performance compared to\nViterbi or Posterior decoding (often also referred to as global or local\ndecoding), and we introduce a novel procedure for choosing the tuning parameter\nin the hybrid procedure. Furthermore, we provide an alternative derivation of\nthe hybrid loss function based on weighted geometric means. We demonstrate and\napply FMCI and hybrid decoding on various classical data sets, and supply\naccompanying code for reproducibility.", "published": "2025-04-21 14:58:35", "link": "http://arxiv.org/abs/2504.15156v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Kolmogorov-Arnold Networks: Approximation and Learning Guarantees for Functions and their Derivatives", "abstract": "Inspired by the Kolmogorov-Arnold superposition theorem, Kolmogorov-Arnold\nNetworks (KANs) have recently emerged as an improved backbone for most deep\nlearning frameworks, promising more adaptivity than their multilayer perception\n(MLP) predecessor by allowing for trainable spline-based activation functions.\nIn this paper, we probe the theoretical foundations of the KAN architecture by\nshowing that it can optimally approximate any Besov function in\n$B^{s}_{p,q}(\\mathcal{X})$ on a bounded open, or even fractal, domain\n$\\mathcal{X}$ in $\\mathbb{R}^d$ at the optimal approximation rate with respect\nto any weaker Besov norm $B^{\\alpha}_{p,q}(\\mathcal{X})$; where $\\alpha < s$.\nWe complement our approximation guarantee with a dimension-free estimate on the\nsample complexity of a residual KAN model when learning a function of Besov\nregularity from $N$ i.i.d. noiseless samples. Our KAN architecture incorporates\ncontemporary deep learning wisdom by leveraging residual/skip connections\nbetween layers.", "published": "2025-04-21 14:02:59", "link": "http://arxiv.org/abs/2504.15110v1", "categories": ["cs.LG", "cs.NA", "cs.NE", "math.FA", "math.NA", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Application of Sensitivity Analysis Methods for Studying Neural Network Models", "abstract": "This study demonstrates the capabilities of several methods for analyzing the\nsensitivity of neural networks to perturbations of the input data and\ninterpreting their underlying mechanisms. The investigated approaches include\nthe Sobol global sensitivity analysis, the local sensitivity method for input\npixel perturbations and the activation maximization technique. As examples, in\nthis study we consider a small feedforward neural network for analyzing an open\ntabular dataset of clinical diabetes data, as well as two classical\nconvolutional architectures, VGG-16 and ResNet-18, which are widely used in\nimage processing and classification. Utilization of the global sensitivity\nanalysis allows us to identify the leading input parameters of the chosen tiny\nneural network and reduce their number without significant loss of the\naccuracy. As far as global sensitivity analysis is not applicable to larger\nmodels we try the local sensitivity analysis and activation maximization method\nin application to the convolutional neural networks. These methods show\ninteresting patterns for the convolutional models solving the image\nclassification problem. All in all, we compare the results of the activation\nmaximization method with popular Grad-CAM technique in the context of\nultrasound data analysis.", "published": "2025-04-21 13:41:20", "link": "http://arxiv.org/abs/2504.15100v1", "categories": ["math.NA", "cs.LG", "cs.NA", "68T07", "F.2.1; I.2.6; G.3; I.2.10"], "primary_category": "math.NA"}
{"title": "Think2SQL: Reinforce LLM Reasoning Capabilities for Text2SQL", "abstract": "Large Language Models (LLMs) have shown impressive capabilities in\ntransforming natural language questions about relational databases into SQL\nqueries. Despite recent improvements, small LLMs struggle to handle questions\ninvolving multiple tables and complex SQL patterns under a Zero-Shot Learning\n(ZSL) setting. Supervised Fine-Tuning (SFT) partially compensate the knowledge\ndeficits in pretrained models but falls short while dealing with queries\ninvolving multi-hop reasoning. To bridge this gap, different LLM training\nstrategies to reinforce reasoning capabilities have been proposed, ranging from\nleveraging a thinking process within ZSL, including reasoning traces in SFT, or\nadopt Reinforcement Learning (RL) strategies. However, the influence of\nreasoning on Text2SQL performance is still largely unexplored. This paper\ninvestigates to what extent LLM reasoning capabilities influence their Text2SQL\nperformance on four benchmark datasets. To this end, it considers the following\nLLM settings: (1) ZSL, including general-purpose reasoning or not; (2) SFT,\nwith and without task-specific reasoning traces; (3) RL, leveraging execution\naccuracy as primary reward function; (4) SFT+RL, i.e, a two-stage approach that\ncombines SFT and RL. The results show that general-purpose reasoning under ZSL\nproves to be ineffective in tackling complex Text2SQL cases. Small LLMs benefit\nfrom SFT with reasoning much more than larger ones, bridging the gap of their\n(weaker) model pretraining. RL is generally beneficial across all tested models\nand datasets, particularly when SQL queries involve multi-hop reasoning and\nmultiple tables. Small LLMs with SFT+RL excel on most complex datasets thanks\nto a strategic balance between generality of the reasoning process and\noptimization of the execution accuracy. Thanks to RL, the7B Qwen-Coder-2.5\nmodel performs on par with 100+ Billion ones on the Bird dataset.", "published": "2025-04-21 13:05:26", "link": "http://arxiv.org/abs/2504.15077v1", "categories": ["cs.LG", "cs.DB"], "primary_category": "cs.LG"}
{"title": "A Call for New Recipes to Enhance Spatial Reasoning in MLLMs", "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated impressive\nperformance in general vision-language tasks. However, recent studies have\nexposed critical limitations in their spatial reasoning capabilities. This\ndeficiency in spatial reasoning significantly constrains MLLMs' ability to\ninteract effectively with the physical world, thereby limiting their broader\napplications. We argue that spatial reasoning capabilities will not naturally\nemerge from merely scaling existing architectures and training methodologies.\nInstead, this challenge demands dedicated attention to fundamental\nmodifications in the current MLLM development approach. In this position paper,\nwe first establish a comprehensive framework for spatial reasoning within the\ncontext of MLLMs. We then elaborate on its pivotal role in real-world\napplications. Through systematic analysis, we examine how individual components\nof the current methodology-from training data to reasoning mechanisms-influence\nspatial reasoning capabilities. This examination reveals critical limitations\nwhile simultaneously identifying promising avenues for advancement. Our work\naims to direct the AI research community's attention toward these crucial yet\nunderexplored aspects. By highlighting these challenges and opportunities, we\nseek to catalyze progress toward achieving human-like spatial reasoning\ncapabilities in MLLMs.", "published": "2025-04-21 11:48:39", "link": "http://arxiv.org/abs/2504.15037v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Is Intelligence the Right Direction in New OS Scheduling for Multiple Resources in Cloud Environments?", "abstract": "Making it intelligent is a promising way in System/OS design. This paper\nproposes OSML+, a new ML-based resource scheduling mechanism for co-located\ncloud services. OSML+ intelligently schedules the cache and main memory\nbandwidth resources at the memory hierarchy and the computing core resources\nsimultaneously. OSML+ uses a multi-model collaborative learning approach during\nits scheduling and thus can handle complicated cases, e.g., avoiding resource\ncliffs, sharing resources among applications, enabling different scheduling\npolicies for applications with different priorities, etc. OSML+ can converge\nfaster using ML models than previous studies. Moreover, OSML+ can automatically\nlearn on the fly and handle dynamically changing workloads accordingly. Using\ntransfer learning technologies, we show our design can work well across various\ncloud servers, including the latest off-the-shelf large-scale servers. Our\nexperimental results show that OSML+ supports higher loads and meets QoS\ntargets with lower overheads than previous studies.", "published": "2025-04-21 11:09:43", "link": "http://arxiv.org/abs/2504.15021v1", "categories": ["cs.DC", "cs.LG", "cs.PF"], "primary_category": "cs.DC"}
{"title": "Learning Compositional Transferability of Time Series for Source-Free Domain Adaptation", "abstract": "Domain adaptation is challenging for time series classification due to the\nhighly dynamic nature. This study tackles the most difficult subtask when both\ntarget labels and source data are inaccessible, namely, source-free domain\nadaptation. To reuse the classification backbone pre-trained on source data,\ntime series reconstruction is a sound solution that aligns target and source\ntime series by minimizing the reconstruction errors of both. However, simply\nfine-tuning the source pre-trained reconstruction model on target data may lose\nthe learnt priori, and it struggles to accommodate domain varying temporal\npatterns in a single encoder-decoder. Therefore, this paper tries to\ndisentangle the composition of domain transferability by using a compositional\narchitecture for time series reconstruction. Here, the preceding component is a\nU-net frozen since pre-trained, the output of which during adaptation is the\ninitial reconstruction of a given target time series, acting as a coarse step\nto prompt the subsequent finer adaptation. The following pipeline for finer\nadaptation includes two parallel branches: The source replay branch using a\nresidual link to preserve the output of U-net, and the offset compensation\nbranch that applies an additional autoencoder (AE) to further warp U-net's\noutput. By deploying a learnable factor on either branch to scale their\ncomposition in the final output of reconstruction, the data transferability is\ndisentangled and the learnt reconstructive capability from source data is\nretained. During inference, aside from the batch-level optimization in the\ntraining, we search at test time stability-aware rescaling of source replay\nbranch to tolerate instance-wise variation. The experimental results show that\nsuch compositional architecture of time series reconstruction leads to SOTA\nperformance on 3 widely used benchmarks.", "published": "2025-04-21 09:51:24", "link": "http://arxiv.org/abs/2504.14994v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MoE Parallel Folding: Heterogeneous Parallelism Mappings for Efficient Large-Scale MoE Model Training with Megatron Core", "abstract": "Mixture of Experts (MoE) models enhance neural network scalability by\ndynamically selecting relevant experts per input token, enabling larger model\nsizes while maintaining manageable computation costs. However, efficient\ntraining of large-scale MoE models across thousands of GPUs presents\nsignificant challenges due to limitations in existing parallelism strategies.\nWe introduce an end-to-end training framework for large-scale MoE models that\nutilizes five-dimensional hybrid parallelism: Tensor Parallelism, Expert\nParallelism, Context Parallelism, Data Parallelism, and Pipeline Parallelism.\nCentral to our approach is MoE Parallel Folding, a novel strategy that\ndecouples the parallelization of attention and MoE layers in Transformer\nmodels, allowing each layer type to adopt optimal parallel configurations.\nAdditionally, we develop a flexible token-level dispatcher that supports both\ntoken-dropping and token-dropless MoE training across all five dimensions of\nparallelism. This dispatcher accommodates dynamic tensor shapes and coordinates\ndifferent parallelism schemes for Attention and MoE layers, facilitating\ncomplex parallelism implementations. Our experiments demonstrate significant\nimprovements in training efficiency and scalability. We achieve up to 49.3%\nModel Flops Utilization (MFU) for the Mixtral 8x22B model and 39.0% MFU for the\nQwen2-57B-A14B model on H100 GPUs, outperforming existing methods. The\nframework scales efficiently up to 1,024 GPUs and maintains high performance\nwith sequence lengths up to 128K tokens, validating its effectiveness for\nlarge-scale MoE model training. The code is available in Megatron-Core.", "published": "2025-04-21 08:39:47", "link": "http://arxiv.org/abs/2504.14960v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Efficient Document Retrieval with G-Retriever", "abstract": "Textual data question answering has gained significant attention due to its\ngrowing applicability. Recently, a novel approach leveraging the\nRetrieval-Augmented Generation (RAG) method was introduced, utilizing the\nPrize-Collecting Steiner Tree (PCST) optimization for sub-graph construction.\nHowever, this method focused solely on node attributes, leading to incomplete\ncontextual understanding. In this paper, we propose an enhanced approach that\nreplaces the PCST method with an attention-based sub-graph construction\ntechnique, enabling more efficient and context-aware retrieval. Additionally,\nwe encode both node and edge attributes, leading to richer graph\nrepresentations. Our method also incorporates an improved projection layer and\nmulti-head attention pooling for better alignment with Large Language Models\n(LLMs). Experimental evaluations on the WebQSP dataset demonstrate that our\napproach is competitive and achieves marginally better results compared to the\noriginal method, underscoring its potential for more accurate question\nanswering.", "published": "2025-04-21 08:27:26", "link": "http://arxiv.org/abs/2504.14955v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Symmetry-Preserving Architecture for Multi-NUMA Environments (SPANE): A Deep Reinforcement Learning Approach for Dynamic VM Scheduling", "abstract": "As cloud computing continues to evolve, the adoption of multi-NUMA\n(Non-Uniform Memory Access) architecture by cloud service providers has\nintroduced new challenges in virtual machine (VM) scheduling. To address these\nchallenges and more accurately reflect the complexities faced by modern cloud\nenvironments, we introduce the Dynamic VM Allocation problem in Multi-NUMA PM\n(DVAMP). We formally define both offline and online versions of DVAMP as\nmixed-integer linear programming problems, providing a rigorous mathematical\nfoundation for analysis. A tight performance bound for greedy online algorithms\nis derived, offering insights into the worst-case optimality gap as a function\nof the number of physical machines and VM lifetime variability. To address the\nchallenges posed by DVAMP, we propose SPANE (Symmetry-Preserving Architecture\nfor Multi-NUMA Environments), a novel deep reinforcement learning approach that\nexploits the problem's inherent symmetries. SPANE produces invariant results\nunder arbitrary permutations of physical machine states, enhancing learning\nefficiency and solution quality. Extensive experiments conducted on the\nHuawei-East-1 dataset demonstrate that SPANE outperforms existing baselines,\nreducing average VM wait time by 45%. Our work contributes to the field of\ncloud resource management by providing both theoretical insights and practical\nsolutions for VM scheduling in multi-NUMA environments, addressing a critical\ngap in the literature and offering improved performance for real-world cloud\nsystems.", "published": "2025-04-21 08:09:40", "link": "http://arxiv.org/abs/2504.14946v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Integrating Response Time and Attention Duration in Bayesian Preference Learning for Multiple Criteria Decision Aiding", "abstract": "We introduce a multiple criteria Bayesian preference learning framework\nincorporating behavioral cues for decision aiding. The framework integrates\npairwise comparisons, response time, and attention duration to deepen insights\ninto decision-making processes. The approach employs an additive value function\nmodel and utilizes a Bayesian framework to derive the posterior distribution of\npotential ranking models by defining the likelihood of observed preference data\nand specifying a prior on the preference structure. This distribution\nhighlights each model's ability to reconstruct Decision-Makers' holistic\npairwise comparisons. By leveraging both response time as a proxy for cognitive\neffort and alternative discriminability as well as attention duration as an\nindicator of criterion importance, the proposed model surpasses traditional\nmethods by uncovering richer behavioral patterns. We report the results of a\nlaboratory experiment on mobile phone contract selection involving 30 real\nsubjects using a dedicated application with time-, eye-, and mouse-tracking\ncomponents. We validate the novel method's ability to reconstruct complete\npreferences. The detailed ablation studies reveal time- and attention-related\nbehavioral patterns, confirming that integrating comprehensive data leads to\ndeveloping models that better align with the DM's actual preferences.", "published": "2025-04-21 08:01:44", "link": "http://arxiv.org/abs/2504.14938v1", "categories": ["stat.AP", "cs.LG"], "primary_category": "stat.AP"}
{"title": "Causal DAG Summarization (Full Version)", "abstract": "Causal inference aids researchers in discovering cause-and-effect\nrelationships, leading to scientific insights. Accurate causal estimation\nrequires identifying confounding variables to avoid false discoveries. Pearl's\ncausal model uses causal DAGs to identify confounding variables, but incorrect\nDAGs can lead to unreliable causal conclusions. However, for high dimensional\ndata, the causal DAGs are often complex beyond human verifiability. Graph\nsummarization is a logical next step, but current methods for general-purpose\ngraph summarization are inadequate for causal DAG summarization. This paper\naddresses these challenges by proposing a causal graph summarization objective\nthat balances graph simplification for better understanding while retaining\nessential causal information for reliable inference. We develop an efficient\ngreedy algorithm and show that summary causal DAGs can be directly used for\ninference and are more robust to misspecification of assumptions, enhancing\nrobustness for causal inference. Experimenting with six real-life datasets, we\ncompared our algorithm to three existing solutions, showing its effectiveness\nin handling high-dimensional data and its ability to generate summary DAGs that\nensure both reliable causal inference and robustness against misspecifications.", "published": "2025-04-21 08:01:32", "link": "http://arxiv.org/abs/2504.14937v1", "categories": ["cs.LG", "cs.DB", "stat.ME"], "primary_category": "cs.LG"}
{"title": "POLYRAG: Integrating Polyviews into Retrieval-Augmented Generation for Medical Applications", "abstract": "Large language models (LLMs) have become a disruptive force in the industry,\nintroducing unprecedented capabilities in natural language processing, logical\nreasoning and so on. However, the challenges of knowledge updates and\nhallucination issues have limited the application of LLMs in medical scenarios,\nwhere retrieval-augmented generation (RAG) can offer significant assistance.\nNevertheless, existing retrieve-then-read approaches generally digest the\nretrieved documents, without considering the timeliness, authoritativeness and\ncommonality of retrieval. We argue that these approaches can be suboptimal,\nespecially in real-world applications where information from different sources\nmight conflict with each other and even information from the same source in\ndifferent time scale might be different, and totally relying on this would\ndeteriorate the performance of RAG approaches. We propose PolyRAG that\ncarefully incorporate judges from different perspectives and finally integrate\nthe polyviews for retrieval augmented generation in medical applications. Due\nto the scarcity of real-world benchmarks for evaluation, to bridge the gap we\npropose PolyEVAL, a benchmark consists of queries and documents collected from\nreal-world medical scenarios (including medical policy, hospital & doctor\ninquiry and healthcare) with multiple tagging (e.g., timeliness,\nauthoritativeness) on them. Extensive experiments and analysis on PolyEVAL have\ndemonstrated the superiority of PolyRAG.", "published": "2025-04-21 07:35:24", "link": "http://arxiv.org/abs/2504.14917v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Dynamic Graph-Like Learning with Contrastive Clustering on Temporally-Factored Ship Motion Data for Imbalanced Sea State Estimation in Autonomous Vessel", "abstract": "Accurate sea state estimation is crucial for the real-time control and future\nstate prediction of autonomous vessels. However, traditional methods struggle\nwith challenges such as data imbalance and feature redundancy in ship motion\ndata, limiting their effectiveness. To address these challenges, we propose the\nTemporal-Graph Contrastive Clustering Sea State Estimator (TGC-SSE), a novel\ndeep learning model that combines three key components: a time dimension\nfactorization module to reduce data redundancy, a dynamic graph-like learning\nmodule to capture complex variable interactions, and a contrastive clustering\nloss function to effectively manage class imbalance. Our experiments\ndemonstrate that TGC-SSE significantly outperforms existing methods across 14\npublic datasets, achieving the highest accuracy in 9 datasets, with a 20.79%\nimprovement over EDI. Furthermore, in the field of sea state estimation,\nTGC-SSE surpasses five benchmark methods and seven deep learning models.\nAblation studies confirm the effectiveness of each module, demonstrating their\nrespective roles in enhancing overall model performance. Overall, TGC-SSE not\nonly improves the accuracy of sea state estimation but also exhibits strong\ngeneralization capabilities, providing reliable support for autonomous vessel\noperations.", "published": "2025-04-21 07:22:11", "link": "http://arxiv.org/abs/2504.14907v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Expected Free Energy-based Planning as Variational Inference", "abstract": "We address the problem of planning under uncertainty, where an agent must\nchoose actions that not only achieve desired outcomes but also reduce\nuncertainty. Traditional methods often treat exploration and exploitation as\nseparate objectives, lacking a unified inferential foundation. Active\ninference, grounded in the Free Energy Principle, offers such a foundation by\nminimizing Expected Free Energy (EFE), a cost function that combines utility\nwith epistemic drives like ambiguity resolution and novelty seeking. However,\nthe computational burden of EFE minimization has remained a major obstacle to\nits scalability. In this paper, we show that EFE-based planning arises\nnaturally from minimizing a variational free energy functional on a generative\nmodel augmented with preference and epistemic priors. This result reinforces\ntheoretical consistency with the Free Energy Principle, by casting planning\nitself as variational inference. Our formulation yields optimal policies that\njointly support goal achievement and information gain, while incorporating a\ncomplexity term that accounts for bounded computational resources. This\nunifying framework connects and extends existing methods, enabling scalable,\nresource-aware implementations of active inference agents.", "published": "2025-04-21 07:09:05", "link": "http://arxiv.org/abs/2504.14898v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Uncertainty quantification of neural network models of evolving processes via Langevin sampling", "abstract": "We propose a scalable, approximate inference hypernetwork framework for a\ngeneral model of history-dependent processes. The flexible data model is based\non a neural ordinary differential equation (NODE) representing the evolution of\ninternal states together with a trainable observation model subcomponent. The\nposterior distribution corresponding to the data model parameters (weights and\nbiases) follows a stochastic differential equation with a drift term related to\nthe score of the posterior that is learned jointly with the data model\nparameters. This Langevin sampling approach offers flexibility in balancing the\ncomputational budget between the evaluation cost of the data model and the\napproximation of the posterior density of its parameters. We demonstrate\nperformance of the hypernetwork on chemical reaction and material physics data\nand compare it to mean-field variational inference.", "published": "2025-04-21 04:45:40", "link": "http://arxiv.org/abs/2504.14854v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Basic Evaluation of Neural Networks Trained with the Error Diffusion Learning Algorithm", "abstract": "Artificial neural networks are powerful tools capable of addressing various\ntasks. Although the backpropagation algorithm has become a standard training\nmethod for these neural networks, its lack of biological plausibility has\ninspired the development of alternative learning approaches. One such\nalternative is Kaneko's Error Diffusion Learning Algorithm (EDLA), a\nbiologically motivated approach wherein a single global error signal diffuses\nthroughout a network composed of paired excitatory-inhibitory sublayers,\nthereby eliminating the necessity for layer-wise backpropagation. This study\npresents a contemporary formulation of the EDLA framework and evaluates its\neffectiveness through parity check, regression, and image classification tasks.\nOur experimental results indicate that EDLA networks can consistently achieve\nhigh accuracy across these benchmarks, with performance efficiency and\nconvergence speed notably influenced by the choice of learning rate, neuron\ncount, and network depth. Further investigation of the internal representations\nformed by EDLA networks reveals their capacity for meaningful feature\nextraction, similar to traditional neural networks. These results suggest that\nEDLA is a biologically motivated alternative for training feedforward networks\nand will motivate future work on extending this method to biologically inspired\nneural networks.", "published": "2025-04-21 02:41:17", "link": "http://arxiv.org/abs/2504.14814v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Edge-boosted graph learning for functional brain connectivity analysis", "abstract": "Predicting disease states from functional brain connectivity is critical for\nthe early diagnosis of severe neurodegenerative diseases such as Alzheimer's\nDisease and Parkinson's Disease. Existing studies commonly employ Graph Neural\nNetworks (GNNs) to infer clinical diagnoses from node-based brain connectivity\nmatrices generated through node-to-node similarities of regionally averaged\nfMRI signals. However, recent neuroscience studies found that such node-based\nconnectivity does not accurately capture ``functional connections\" within the\nbrain. This paper proposes a novel approach to brain network analysis that\nemphasizes edge functional connectivity (eFC), shifting the focus to inter-edge\nrelationships. Additionally, we introduce a co-embedding technique to integrate\nedge functional connections effectively. Experimental results on the ADNI and\nPPMI datasets demonstrate that our method significantly outperforms\nstate-of-the-art GNN methods in classifying functional brain networks.", "published": "2025-04-21 01:53:55", "link": "http://arxiv.org/abs/2504.14796v1", "categories": ["cs.LG", "eess.IV"], "primary_category": "cs.LG"}
{"title": "Enhanced Data-driven Topology Design Methodology with Multi-level Mesh and Correlation-based Mutation for Stress-related Multi-objective Optimization", "abstract": "Topology optimization (TO) serves as a widely applied structural design\napproach to tackle various engineering problems. Nevertheless,\nsensitivity-based TO methods usually struggle with solving strongly nonlinear\noptimization problems. By leveraging high capacity of deep generative model,\nwhich is an influential machine learning technique, the sensitivity-free\ndata-driven topology design (DDTD) methodology is regarded as an effective\nmeans of overcoming these issues. The DDTD methodology depends on initial\ndataset with a certain regularity, making its results highly sensitive to\ninitial dataset quality. This limits its effectiveness and generalizability,\nespecially for optimization problems without priori information. In this\nresearch, we proposed a multi-level mesh DDTD-based method with\ncorrelation-based mutation module to escape from the limitation of the quality\nof the initial dataset on the results and enhance computational efficiency. The\ncore is to employ a correlation-based mutation module to assign new geometric\nfeatures with physical meaning to the generated data, while utilizing a\nmulti-level mesh strategy to progressively enhance the refinement of the\nstructural representation, thus avoiding the maintenance of a high\ndegree-of-freedom (DOF) representation throughout the iterative process. The\nproposed multi-level mesh DDTD-based method can be driven by a low quality\ninitial dataset without the need for time-consuming construction of a specific\ndataset, thus significantly increasing generality and reducing application\ndifficulty, while further lowering computational cost of DDTD methodology.\nVarious comparison experiments with the traditional sensitivity-based TO\nmethods on stress-related strongly nonlinear problems demonstrate the\ngenerality and effectiveness of the proposed method.", "published": "2025-04-21 01:33:56", "link": "http://arxiv.org/abs/2504.14790v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Novel Concept-Oriented Synthetic Data approach for Training Generative AI-Driven Crystal Grain Analysis Using Diffusion Model", "abstract": "The traditional techniques for extracting polycrystalline grain structures\nfrom microscopy images, such as transmission electron microscopy (TEM) and\nscanning electron microscopy (SEM), are labour-intensive, subjective, and\ntime-consuming, limiting their scalability for high-throughput analysis. In\nthis study, we present an automated methodology integrating edge detection with\ngenerative diffusion models to effectively identify grains, eliminate noise,\nand connect broken segments in alignment with predicted grain boundaries. Due\nto the limited availability of adequate images preventing the training of deep\nmachine learning models, a new seven-stage methodology is employed to generate\nsynthetic TEM images for training. This concept-oriented synthetic data\napproach can be extended to any field of interest where the scarcity of data is\na challenge. The presented model was applied to various metals with average\ngrain sizes down to the nanoscale, producing grain morphologies from\nlow-resolution TEM images that are comparable to those obtained from advanced\nand demanding experimental techniques with an average accuracy of 97.23%.", "published": "2025-04-21 00:46:28", "link": "http://arxiv.org/abs/2504.14782v1", "categories": ["cs.LG", "cond-mat.mtrl-sci", "I.4.9"], "primary_category": "cs.LG"}
{"title": "ADL: A Declarative Language for Agent-Based Chatbots", "abstract": "There are numerous agent frameworks capable of creating and orchestrating\nagents to address complex tasks. However, these frameworks are often too\ncomplicated for customer service professionals, who may not have much\nprogramming experience but still need an easy way to create chatbots with rich\nbusiness logic. In this work, we introduce ADL, a Declarative Language for\nAgent-Based Chatbots. ADL simplifies chatbot development by using natural\nlanguage programming at its core, making it easier for a broad audience to\ncustomize and build task-oriented chatbots. It includes four types of agents\nand supports integration with custom functions, tool use, and third-party\nagents. ADL abstracts away implementation details, offering a declarative way\nto define agents and their interactions, which could ease prompt engineering,\ntesting and debugging. MICA, a multi-agent system designed to interpret and\nexecute ADL programs, has been developed and is now available as an open-source\nproject at https://github.com/Mica-labs/MICA. Its user documentation can be\nfound at https://mica-labs.github.io/.", "published": "2025-04-21 01:02:08", "link": "http://arxiv.org/abs/2504.14787v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Phase-separated lipid vesicles: continuum modeling, simulation, and validation", "abstract": "The paper presents a complete research cycle comprising continuum-based\nmodeling, computational framework development, and validation setup to predict\nphase separation and surface hydrodynamics in lipid bilayer membranes. We\nstarting with an overview of the key physical characteristics of lipid\nbilayers, including their composition, mechanical properties, and\nthermodynamics, and then discuss continuum models of multi-component bilayers.\nThe most complex model is a Navier--Stokes--Cahn--Hilliard (NSCH) type system,\ndescribing the coupling of incompressible surface fluid dynamics with\nphase-field dynamics on arbitrarily curved geometries. It is discretized using\ntrace finite element methods, which offer geometric flexibility and stability\nin representing surface PDEs. Numerical studies are conducted to examine\nphysical features such as coarsening rates and interfacial dynamics. The\ncomputational results obtained from the NSCH model are compared against\nexperimental data for membrane compositions with distinct phase behaviors,\ndemonstrating that including both phase-field models and surface hydrodynamics\nis essential to accurately reproduce domain evolution observed in\nepi-fluorescence microscopy. Lastly, we extend the model to incorporate\nexternal forces that enable the simulation of vesicles containing cationic\nlipids, used to enhance membrane fusion.", "published": "2025-04-21 16:17:39", "link": "http://arxiv.org/abs/2504.15201v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An $rp$-adaptive method for accurate resolution of shock-dominated viscous flow based on implicit shock tracking", "abstract": "This work introduces an optimization-based $rp$-adaptive numerical method to\napproximate solutions of viscous, shock-dominated flows using implicit shock\ntracking and a high-order discontinuous Galerkin discretization on\ntraditionally coarse grids without nonlinear stabilization (e.g., artificial\nviscosity or limiting). The proposed method adapts implicit shock tracking\nmethods, originally developed to align mesh faces with solution\ndiscontinuities, to compress elements into viscous shocks and boundary layers,\nfunctioning as a novel approach to aggressive $r$-adaptation. This form of\n$r$-adaptation is achieved naturally as the minimizer of the enriched residual\nwith respect to the discrete flow variables and coordinates of the nodes of the\ngrid. Several innovations to the shock tracking optimization solver are\nproposed to ensure sufficient mesh compression at viscous features to render\nstabilization unnecessary, including residual weighting, step constraints and\nmodifications, and viscosity-based continuation. Finally, $p$-adaptivity is\nused to locally increase the polynomial degree with three clear benefits: (1)\nlessens the mesh compression requirements near shock waves and boundary layers,\n(2) reduces the error in regions where $r$-adaptivity is not sufficient with\nthe given grid topology, and (3) reduces computational cost by performing a\nmajority of the $r$-adaptivity iterations on the coarsest discretization. A\nseries of numerical experiments show the proposed method effectively resolves\nviscous, shock-dominated flows, including accurate prediction of heat flux\nprofiles produced by hypersonic flow over a cylinder, and compares favorably in\nterms of accuracy per degree of freedom to $h$-adaptation with a high-order\ndiscretization.", "published": "2025-04-21 15:39:42", "link": "http://arxiv.org/abs/2504.15177v1", "categories": ["math.NA", "cs.NA", "math.OC", "physics.flu-dyn"], "primary_category": "math.NA"}
{"title": "Poroelastic flow across a permeable interface: a Hamilton's principle approach and its finite element implementation", "abstract": "We consider fluid flow across a permeable interface within a deformable\nporous medium. We use mixture theory. The mixture's constituents are assumed to\nbe incompressible in their pure form. We use Hamilton's principle to obtain the\ngoverning equations, and we propose a corresponding finite element\nimplementation. The filtration velocity and the pore pressure are allowed to be\ndiscontinuous across the interface while some control of these discontinuities\nis built into the interfacial constitutive behavior. To facilitate the\npractical implementation of the formulation in a finite element scheme, we\nintroduce a Lagrange multiplier field over the interface for the explicit\nenforcement of the jump condition of the balance of mass. Our formulation\nappears to recover some basic results from the literature. The novelty of the\nwork is the formulation of an approach that can accommodate specific\nconstitutive assumptions pertaining to the behavior of the interface that do\nnot necessarily imply the continuity of the filtration velocity and/or of the\npore pressure across it.", "published": "2025-04-21 15:26:35", "link": "http://arxiv.org/abs/2504.15173v1", "categories": ["math.NA", "cs.NA", "physics.flu-dyn", "74A99, 76S05, 74S05, 76-10"], "primary_category": "math.NA"}
{"title": "Artificial compressibility method for the incompressible Navier-Stokes equations with variable density", "abstract": "We introduce a novel artificial compressibility technique to approximate the\nincompressible Navier-Stokes equations with variable fluid properties such as\ndensity and dynamical viscosity. The proposed scheme used the couple pressure\nand momentum, equal to the density times the velocity, as primary unknowns. It\nalso involves an adequate treatment of the diffusive operator such that\ntreating the nonlinear convective term explicitly leads to a scheme with time\nindependent stiffness matrices that is suitable for pseudo-spectral methods.\nThe stability and temporal convergence of the semi-implicit version of the\nscheme is established under the hypothesis that the density is approximated\nwith a method that conserves the minimum-maximum principle. Numerical\nillustrations confirm that both the semi-implicit and explicit scheme are\nstable and converge with order one under classic CFL condition. Moreover, the\nproposed scheme is shown to perform better than a momentum based pressure\nprojection method, previously introduced by one of the authors, on setups\ninvolving gravitational waves and immiscible multi-fluids in a cylinder.", "published": "2025-04-21 14:55:24", "link": "http://arxiv.org/abs/2504.15151v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Hermitian Quaternion Toeplitz Matrices by Quaternion-valued Generating Functions", "abstract": "In this paper, we study Hermitian quaternion Toeplitz matrices generated by\nquaternion-valued functions. We show that such generating function must be the\nsum of a real-valued function and an odd function with imaginary component.\nThis setting is different from the case of Hermitian complex Toeplitz matrices\ngenerated by real-valued functions only. By using of 2-by-2 block complex\nrepresentation of quaternion matrices, we give a quaternion version of\nGrenander-Szeg\\\"{o} theorem stating the distribution of eigenvalues of\nHermitian quaternion Toeplitz matrices in terms of its generating function. As\nan application, we investigate Strang's circulant preconditioners for Hermitian\nquaternion Toeplitz linear systems arising from quaternion signal processing.\nWe show that Strang's circulant preconditioners can be diagionalized by\ndiscrete quaternion Fourier transform matrices whereas general quaternion\ncirculant matrices cannot be diagonalized by them. Also we verify the\ntheoretical and numerical convergence results of Strang's circulant\npreconditioned conjugate gradient method for solving Hermitian quaternion\nToeplitz systems.", "published": "2025-04-21 13:03:21", "link": "http://arxiv.org/abs/2504.15073v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Full Discretization of Stochastic Semilinear Schr\u00f6dinger equation driven by multiplicative Wiener noise", "abstract": "In this article, we have analyzed the full discretization of the Stochastic\nsemilinear Schr\\\"{o}dinger equation in a bounded convex polygonal domain driven\nby multiplicative Wiener noise. We use the finite element method for spatial\ndiscretization and the stochastic trigonometric method for time discretization\nand derive a strong convergence rate with respect to both parameters (temporal\nand spatial). Numerical experiments have also been performed to support\ntheoretical bounds.", "published": "2025-04-21 08:02:07", "link": "http://arxiv.org/abs/2504.14939v1", "categories": ["math.NA", "cs.NA", "math.PR", "60H15, 65N30, 65M60, 60H35, 65C30, 35Q41"], "primary_category": "math.NA"}
{"title": "Kernel-learning parameter prediction and evaluation in algebraic multigrid method for several PDEs", "abstract": "This paper explores the application of kernel learning methods for parameter\nprediction and evaluation in the Algebraic Multigrid Method (AMG), focusing on\nseveral Partial Differential Equation (PDE) problems. AMG is an efficient\niterative solver for large-scale sparse linear systems, particularly those\nderived from elliptic and parabolic PDE discretizations. However, its\nperformance heavily relies on numerous parameters, which are often set\nempirically and are highly sensitive to AMG's effectiveness. Traditional\nparameter optimization methods are either computationally expensive or lack\ntheoretical support. To address this, we propose a Gaussian Process Regression\n(GPR)-based strategy to optimize AMG parameters and introduce evaluation\nmetrics to assess their effectiveness. Trained on small-scale datasets, GPR\npredicts nearly optimal parameters, bypassing the time-consuming parameter\nsweeping process. We also use kernel learning techniques to build a kernel\nfunction library and determine the optimal kernel function through linear\ncombination, enhancing prediction accuracy. In numerical experiments, we tested\ntypical PDEs such as the constant-coefficient Poisson equation,\nvariable-coefficient Poisson equation, diffusion equation, and Helmholtz\nequation. Results show that GPR-predicted parameters match grid search results\nin iteration counts while significantly reducing computational time. A\ncomprehensive analysis using metrics like mean squared error, prediction\ninterval coverage, and Bayesian information criterion confirms GPR's efficiency\nand reliability. These findings validate GPR's effectiveness in AMG parameter\noptimization and provide theoretical support for AMG's practical application.", "published": "2025-04-21 07:50:51", "link": "http://arxiv.org/abs/2504.14930v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Beating the Correlation Breakdown: Robust Inference, Flexible Scenarios, and Stress Testing for Financial Portfolios", "abstract": "We live in a multivariate world, and effective modeling of financial\nportfolios, including their construction, allocation, forecasting, and risk\nanalysis, simply is not possible without explicitly modeling the dependence\nstructure of their assets. Dependence structure can drive portfolio results\nmore than many other parameters in investment and risk models, sometimes even\nmore than their combined effects, but the literature provides relatively little\nto define the finite-sample distributions of dependence measures in useable and\nuseful ways under challenging, real-world financial data conditions. Yet this\nis exactly what is needed to make valid inferences about their estimates, and\nto use these inferences for a myriad of essential purposes, such as hypothesis\ntesting, dynamic monitoring, realistic and granular scenario and reverse\nscenario analyses, and mitigating the effects of correlation breakdowns during\nmarket upheavals (which is when we need valid inferences the most). This work\ndevelops a new and straightforward method, Nonparametric Angles-based\nCorrelation (NAbC), for defining the finite-sample distributions of any\ndependence measure whose matrix of pairwise associations is positive definite\n(e.g. Pearsons, Kendalls Tau, Spearmans Rho, Chatterjees, Lancasters, Szekelys,\nand their many variants). The solution remains valid under marginal asset\ndistributions characterized by notably different and varying degrees of serial\ncorrelation, non-stationarity, heavy-tailedness, and asymmetry. Notably, NAbCs\np-values and confidence intervals remain analytically consistent at both the\nmatrix level and the pairwise cell level. Finally, NAbC maintains validity even\nwhen selected cells in the matrix are frozen for a given scenario or stress\ntest, that is, unaffected by the scenario, thus enabling flexible, granular,\nand realistic scenarios.", "published": "2025-04-21 17:52:36", "link": "http://arxiv.org/abs/2504.15268v1", "categories": ["q-fin.RM", "q-fin.PM", "q-fin.ST", "stat.AP", "62-07, 62E20, 62F10, 62F12, 60E05, 60G70, 91B30", "G.3"], "primary_category": "q-fin.RM"}
{"title": "On feature representations for marmoset vocal communication analysis", "abstract": "The acoustic analysis of marmoset (Callithrix jacchus) vocalizations is often\nused to understand the evolutionary origins of human language. Currently, the\nanalysis is largely carried out in a manual or semi-manual manner. Thus, there\nis a need to develop automatic call analysis methods. In that direction,\nresearch has been limited to the development of analysis methods with small\namounts of data or for specific scenarios. Furthermore, there is lack of prior\nknowledge about what type of information is relevant for different call\nanalysis tasks. To address these issues, as a first step, this paper explores\ndifferent feature representation methods, namely, HCTSA-based hand-crafted\nfeatures Catch22, pre-trained self supervised learning (SSL) based features\nextracted from neural networks trained on human speech and end-to-end acoustic\nmodeling for call-type classification, caller identification and caller sex\nidentification. Through an investigation on three different marmoset call\ndatasets, we demonstrate that SSL-based feature representations and end-to-end\nacoustic modeling tend to lead to better systems than Catch22 features for\ncall-type and caller classification. Furthermore, we also highlight the impact\nof signal bandwidth on the obtained task performances.", "published": "2025-04-21 09:15:45", "link": "http://arxiv.org/abs/2504.14981v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Quantitative Measures for Passive Sonar Texture Analysis", "abstract": "Passive sonar signals contain complex characteristics often arising from\nenvironmental noise, vessel machinery, and propagation effects. While\nconvolutional neural networks (CNNs) perform well on passive sonar\nclassification tasks, they can struggle with statistical variations that occur\nin the data. To investigate this limitation, synthetic underwater acoustic\ndatasets are generated that centered on amplitude and period variations. Two\nmetrics are proposed to quantify and validate these characteristics in the\ncontext of statistical and structural texture for passive sonar. These measures\nare applied to real-world passive sonar datasets to assess texture information\nin the signals and correlate the performances of the models. Results show that\nCNNs underperform on statistically textured signals, but incorporating explicit\nstatistical texture modeling yields consistent improvements. These findings\nhighlight the importance of quantifying texture information for passive sonar\nclassification.", "published": "2025-04-21 03:55:49", "link": "http://arxiv.org/abs/2504.14843v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "DNN based HRIRs Identification with a Continuously Rotating Speaker Array", "abstract": "Conventional static measurement of head-related impulse responses (HRIRs) is\ntime-consuming due to the need for repositioning a speaker array for each\nazimuth angle. Dynamic approaches using analytical models with a continuously\nrotating speaker array have been proposed, but their accuracy is significantly\nreduced at high rotational speeds. To address this limitation, we propose a\nDNN-based HRIRs identification using sequence-to-sequence learning. The\nproposed DNN model incorporates fully connected (FC) networks to effectively\ncapture HRIR transitions and includes reset and update gates to identify HRIRs\nover a whole sequence. The model updates the HRIRs vector coefficients based on\nthe gradient of the instantaneous square error (ISE). Additionally, we\nintroduce a learnable normalization process based on the speaker excitation\nsignals to stabilize the gradient scale of ISE across time. A training scheme,\nreferred to as whole-sequence updating and optimization scheme, is also\nintroduced to prevent overfitting. We evaluated the proposed method through\nsimulations and experiments. Simulation results using the FABIAN database show\nthat the proposed method outperforms previous analytic models, achieving over 7\ndB improvement in normalized misalignment (NM) and maintaining log spectral\ndistortion (LSD) below 2 dB at a rotational speed of 45{\\deg}/s. Experimental\nresults with a custom-built speaker array confirm that the proposed method\nsuccessfully preserved accurate sound localization cues, consistent with those\nfrom static measurement. Source code is available at\nhttps://github.com/byko0810/DNN-based-HRIRs-identification", "published": "2025-04-21 02:50:34", "link": "http://arxiv.org/abs/2504.14817v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Joint Knowledge and Power Management for Secure Semantic Communication Networks", "abstract": "Recently, semantic communication (SemCom) has shown its great superiorities\nin resource savings and information exchanges. However, while its unique\nbackground knowledge guarantees accurate semantic reasoning and recovery,\nsemantic information security-related concerns are introduced at the same time.\nSince the potential eavesdroppers may have the same background knowledge to\naccurately decrypt the private semantic information transmitted between legal\nSemCom users, this makes the knowledge management in SemCom networks rather\nchallenging in joint consideration with the power control. To this end, this\npaper focuses on jointly addressing three core issues of power allocation,\nknowledge base caching (KBC), and device-to-device (D2D) user pairing (DUP) in\nsecure SemCom networks. We first develop a novel performance metric, namely\nsemantic secrecy throughput (SST), to quantify the information security level\nthat can be achieved at each pair of D2D SemCom users. Next, an SST\nmaximization problem is formulated subject to secure SemCom-related delay and\nreliability constraints. Afterward, we propose a security-aware resource\nmanagement solution using the Lagrange primal-dual method and a two-stage\nmethod. Simulation results demonstrate our proposed solution nearly doubles the\nSST performance and realizes less than half of the queuing delay performance\ncompared to different benchmarks.", "published": "2025-04-21 17:39:59", "link": "http://arxiv.org/abs/2504.15260v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Time-Series Analysis on Edge-AI Hardware for Healthcare Monitoring", "abstract": "This project addresses the need for efficient, real-time analysis of\nbiomedical signals such as electrocardiograms (ECG) and electroencephalograms\n(EEG) for continuous health monitoring. Traditional methods rely on\nlong-duration data recording followed by offline analysis, which is\npower-intensive and delays responses to critical symptoms such as arrhythmia.\nTo overcome these limitations, a time-domain ECG analysis model based on a\nnovel dynamically-biased Long Short-Term Memory (DB-LSTM) neural network is\nproposed. This model supports simultaneous ECG forecasting and classification\nwith high performance-achieving over 98% accuracy and a normalized mean square\nerror below 1e-3 for forecasting, and over 97% accuracy with faster convergence\nand fewer training parameters for classification. To enable edge deployment,\nthe model is hardware-optimized by quantizing weights to INT4 or INT3 formats,\nresulting in only a 2% and 6% drop in classification accuracy during training\nand inference, respectively, while maintaining full accuracy for forecasting.\nExtensive simulations using multiple ECG datasets confirm the model's\nrobustness. Future work includes implementing the algorithm on FPGA and CMOS\ncircuits for practical cardiac monitoring, as well as developing a digital\nhardware platform that supports flexible neural network configurations and\non-chip online training for personalized healthcare applications.", "published": "2025-04-21 15:40:10", "link": "http://arxiv.org/abs/2504.15178v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Bayesian Sensing for Time-Varying Channels in ISAC Systems", "abstract": "Future mobile networks are projected to support integrated sensing and\ncommunications in high-speed communication scenarios. Nevertheless, large\nDoppler shifts induced by time-varying channels may cause severe inter-carrier\ninterference (ICI). Frequency domain shows the potential of reducing ISAC\ncomplexity as compared with other domains. However, parameter mismatching issue\nstill exists for such sensing. In this paper, we develop a novel sensing scheme\nbased on sparse Bayesian framework, where the delay and Doppler estimation\nproblem in time-varying channels is formulated as a 3D multiple\nmeasurement-sparse signal recovery (MM-SSR) problem. We then propose a novel\ntwo-layer variational Bayesian inference (VBI) method to decompose the 3D\nMM-SSR problem into two layers and estimate the Doppler in the first layer and\nthe delay in the second layer alternatively. Subsequently, as is benefited from\nnewly unveiled signal construction, a simplified two-stage multiple signal\nclassification (MUSIC)-based VBI method is proposed, where the delay and the\nDoppler are estimated by MUSIC and VBI, respectively. Additionally, the\nCram\\'er-Rao bound (CRB) of the considered sensing parameters is derived to\ncharacterize the lower bound for the proposed estimators. Corroborated by\nextensive simulation results, our proposed method can achieve improved mean\nsquare error (MSE) than its conventional counterparts and is robust against the\ntarget number and target speed, thereby validating its wide applicability and\nadvantages over prior arts.", "published": "2025-04-21 11:53:44", "link": "http://arxiv.org/abs/2504.15042v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "The PHD/CPHD filter for Multiple Extended Target Tracking with Trajectory Set Theory and Explicit Shape Estimation", "abstract": "In this paper, we propose two methods for tracking multiple extended targets\nor unresolved group targets with elliptical extent shape. These two methods are\ndeduced from the famous Probability Hypothesis Density (PHD) filter and the\nCardinality-PHD (CPHD) filter, respectively. In these two methods, Trajectory\nSet Theory (TST) is combined to establish the target trajectory estimates.\nMoreover, by employing a decoupled shape estimation model, the proposed methods\ncan explicitly provide the shape estimation of the target, such as the\norientation of the ellipse extension and the length of its two axes. We derived\nthe closed Bayesian recursive of these two methods with stable trajectory\ngeneration and accurate extent estimation, resulting in the TPHD-E filter and\nthe TCPHD-E filter. In addition, Gaussian mixture implementations of our\nmethods are provided, which are further referred to as the GM-TPHD-E filter and\nthe GM-TCPHD-E filters. We illustrate the ability of these methods through\nsimulations and experiments with real data. These experiments demonstrate that\nthe two proposed algorithms have advantages over existing algorithms in target\nshape estimation, as well as in the completeness and accuracy of target\ntrajectory generation.", "published": "2025-04-21 11:49:22", "link": "http://arxiv.org/abs/2504.15040v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Blinding the Wiretapper: RIS-Enabled User Occultation in the ISAC Era", "abstract": "An undesirable consequence of the foreseeable proliferation of sophisticated\nintegrated sensing and communications (ISAC) technologies is the enabling of\nspoofing, by malicious agents, of situational information (such as proximity,\ndirection or location) of legitimate users of wireless systems. In order to\nmitigate this threat, we present a novel ISAC scheme that, aided by a\nreconfigurable intelligent surface (RIS), enables the occultation of the\npositions of user equipment (UE) from wiretappers, while maintaining both\nsensing and desired communication performance between the UEs and a legitimate\nbase station (BS). To that end, we first formulate an RIS phase-shift\noptimization problem that jointly maximizes the sum-rate performance of the UEs\n(communication objective), while minimizing the projection of the wiretapper's\neffective channel onto the legitimate channel (hiding objective), thereby\ndisrupting the attempts by a wiretapper of localizing the UEs. Then, in order\nto efficiently solve the resulting non-convex joint optimization problem, a\nnovel manifold optimization algorithm is derived, whose effectiveness is\nvalidated by numerical results, which demonstrate that the proposed approach\npreserves legitimate ISAC performance while significantly degrading the\nwiretapper's sensing capability.", "published": "2025-04-21 11:41:28", "link": "http://arxiv.org/abs/2504.15033v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Frequency Comb-based Wavelength Division Multiplexing and Detection without Wavelength Demultiplexers", "abstract": "We demonstrate a wavelength division multiplexing (WDM) concept using\ndemultiplexer-free frequency combs at both transmitter and receiver in a\n4-wavelength 200-GHz-grid WDM system with flexible symbol rates, aiming to\navoid the power-hungry wavelength control on demultiplexers.", "published": "2025-04-21 10:30:53", "link": "http://arxiv.org/abs/2504.15012v1", "categories": ["physics.optics", "eess.SP"], "primary_category": "physics.optics"}
{"title": "A Purely Data-Driven Adaptive Impedance Matching Method Robust to Parasitic Effects", "abstract": "Adaptive impedance matching between antennas and radio frequency front-end\n(RFFE) power modules is essential for mobile communication systems. To address\nthe matching performance degradation caused by parasitic effects in practical\ntunable matching networks (TMN), this paper proposes a purely data-driven\nadaptive impedance matching method that avoids trial-and-error physical\nadjustment. First, we propose the residual enhanced circuit behavior modeling\nnetwork (RECBM-Net), a deep learning model that maps TMN operating states to\ntheir scattering parameters (S-parameters). Then, we formulate the matching\nprocess based on the trained surrogate model as a mathematical optimization\nproblem. We employ two classic numerical methods with different online\ncomputational overhead, namely simulated annealing particle swarm optimization\n(SAPSO) and adaptive moment estimation with automatic differentiation\n(AD-Adam), to search for the matching solution. To further reduce the online\ninference overhead caused by repeated forward propagation through RECBM-Net, we\ntrain an inverse mapping solver network (IMS-Net) to directly predict the\noptimal solution. Simulation results show that RECBM-Net achieves exceptionally\nhigh modeling accuracy. While AD-Adam significantly reduces computational\noverhead compared to SAPSO, it sacrifices slight accuracy. IMS-Net offers the\nlowest online overhead while maintaining excellent matching accuracy.", "published": "2025-04-21 08:17:41", "link": "http://arxiv.org/abs/2504.14951v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Radar Code Design for the Joint Optimization of Detection Performance and Measurement Accuracy in Track Maintenance", "abstract": "This paper deals with the design of slow-time coded waveforms which jointly\noptimize the detection probability and the measurements accuracy for track\nmaintenance in the presence of colored Gaussian interference. The output\nsignal-to-interference-plus-noise ratio (SINR) and Cram\\'er Rao bounds (CRBs)\non time delay and Doppler shift are used as figures of merit to accomplish\nreliable detection as well as accurate measurements. The transmitted code is\nsubject to radar power budget requirements and a similarity constraint. To\ntackle the resulting non-convex multi-objective optimization problem, a\npolynomial-time algorithm that integrates scalarization and tensor-based\nrelaxation methods is developed. The corresponding relaxed multi-linear\nproblems are solved by means of the maximum block improvement (MBI) framework,\nwhere the optimal solution at each iteration is obtained in closed form.\nNumeral results demonstrate the trade-off between the detection and the\nestimation performance, along with the acceptable Doppler robustness achieved\nby the proposed algorithm.", "published": "2025-04-21 06:30:11", "link": "http://arxiv.org/abs/2504.14885v1", "categories": ["eess.SP", "94A12, 94A13", "H.4.0"], "primary_category": "eess.SP"}
{"title": "Aligning Beam with Imbalanced Multi-modality: A Generative Federated Learning Approach", "abstract": "As vehicle intelligence advances, multi-modal sensing-aided communication\nemerges as a key enabler for reliable Vehicle-to-Everything (V2X) connectivity\nthrough precise environmental characterization. As centralized learning may\nsuffer from data privacy, model heterogeneity and communication overhead\nissues, federated learning (FL) has been introduced to support V2X. However,\nthe practical deployment of FL faces critical challenges: model performance\ndegradation from label imbalance across vehicles and training instability\ninduced by modality disparities in sensor-equipped agents. To overcome these\nlimitations, we propose a generative FL approach for beam selection (GFL4BS).\nOur solution features two core innovations: 1) An adaptive zero-shot\nmulti-modal generator coupled with spectral-regularized loss functions to\nenhance the expressiveness of synthetic data compensating for both label\nscarcity and missing modalities; 2) A hybrid training paradigm integrating\nfeature fusion with decentralized optimization to ensure training resilience\nwhile minimizing communication costs. Experimental evaluations demonstrate\nsignificant improvements over baselines achieving 16.2% higher accuracy than\nthe current state-of-the-art under severe label imbalance conditions while\nmaintaining over 70% successful rate even when two agents lack both LiDAR and\nRGB camera inputs.", "published": "2025-04-21 03:32:00", "link": "http://arxiv.org/abs/2504.14835v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Delay-Angle Information Spoofing for Channel State Information-Free Location-Privacy Enhancement", "abstract": "In this paper, a delay-angle information spoofing (DAIS) strategy is proposed\nto enhance the location privacy at the physical layer. More precisely, the\nlocation-relevant delays and angles are artificially shifted without the aid of\nchannel state information (CSI) at the transmitter, such that the location\nperceived by the eavesdropper is incorrect and distinct from the true one. By\nleveraging the intrinsic structure of the wireless channel, a precoder is\ndesigned to achieve DAIS while the legitimate localizer can remove the\nobfuscation via securely receiving a modest amount of information, i.e., the\ndelay-angle shifts. A lower bound on eavesdropper's localization error is\nderived, revealing that location privacy is enhanced not only due to estimation\nerror, but also by the geometric mismatch introduced by DAIS. Furthermore, the\nlower bound is explicitly expressed as a function of the delay-angle shifts,\ncharacterizing performance trends and providing the appropriate design of these\nshift parameters. The statistical hardness of maliciously inferring the\ndelay-angle shifts by a single-antenna eavesdropper as well as the challenges\nfor a multi-antenna eavesdropper are investigated to assess the robustness of\nthe proposed DAIS strategy. Numerical results show that the proposed DAIS\nstrategy results in more than 15 dB performance degradation for the\neavesdropper as compared with that for the legitimate localizer at high\nsignal-to-noise ratios, and provides more effective location-privacy\nenhancement than the prior art.", "published": "2025-04-21 00:40:45", "link": "http://arxiv.org/abs/2504.14780v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Learning to Reason under Off-Policy Guidance", "abstract": "Recent advances in large reasoning models (LRMs) demonstrate that\nsophisticated behaviors such as multi-step reasoning and self-reflection can\nemerge via reinforcement learning (RL) with simple rule-based rewards. However,\nexisting zero-RL approaches are inherently ``on-policy'', limiting learning to\na model's own outputs and failing to acquire reasoning abilities beyond its\ninitial capabilities. We introduce LUFFY (Learning to reason Under oFF-policY\nguidance), a framework that augments zero-RL with off-policy reasoning traces.\nLUFFY dynamically balances imitation and exploration by combining off-policy\ndemonstrations with on-policy rollouts during training. Notably, we propose\npolicy shaping via regularized importance sampling to avoid superficial and\nrigid imitation during mixed-policy training. Remarkably, LUFFY achieves an\nover +7.0 average gain across six math benchmarks and an advantage of over +6.2\npoints in out-of-distribution tasks. It also substantially surpasses\nimitation-based supervised fine-tuning (SFT), particularly in generalization.\nAnalysis shows LUFFY not only imitates effectively but also explores beyond\ndemonstrations, offering a scalable path to train generalizable reasoning\nmodels with off-policy guidance.", "published": "2025-04-21 08:09:13", "link": "http://arxiv.org/abs/2504.14945v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Synergistic Weak-Strong Collaboration by Aligning Preferences", "abstract": "Current Large Language Models (LLMs) excel in general reasoning yet struggle\nwith specialized tasks requiring proprietary or domain-specific knowledge.\nFine-tuning large models for every niche application is often infeasible due to\nblack-box constraints and high computational overhead. To address this, we\npropose a collaborative framework that pairs a specialized weak model with a\ngeneral strong model. The weak model, tailored to specific domains, produces\ninitial drafts and background information, while the strong model leverages its\nadvanced reasoning to refine these drafts, extending LLMs' capabilities to\ncritical yet specialized tasks. To optimize this collaboration, we introduce a\ncollaborative feedback to fine-tunes the weak model, which quantifies the\ninfluence of the weak model's contributions in the collaboration procedure and\nestablishes preference pairs to guide preference tuning of the weak model. We\nvalidate our framework through experiments on three domains. We find that the\ncollaboration significantly outperforms each model alone by leveraging\ncomplementary strengths. Moreover, aligning the weak model with the\ncollaborative preference further enhances overall performance.", "published": "2025-04-21 15:57:33", "link": "http://arxiv.org/abs/2504.15188v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Text-to-Decision Agent: Learning Generalist Policies from Natural Language Supervision", "abstract": "RL systems usually tackle generalization by inferring task beliefs from\nhigh-quality samples or warmup explorations. The restricted form limits their\ngenerality and usability since these supervision signals are expensive and even\ninfeasible to acquire in advance for unseen tasks. Learning directly from the\nraw text about decision tasks is a promising alternative to leverage a much\nbroader source of supervision. In the paper, we propose Text-to-Decision Agent\n(T2DA), a simple and scalable framework that supervises generalist policy\nlearning with natural language. We first introduce a generalized world model to\nencode multi-task decision data into a dynamics-aware embedding space. Then,\ninspired by CLIP, we predict which textual description goes with which decision\nembedding, effectively bridging their semantic gap via contrastive\nlanguage-decision pre-training and aligning the text embeddings to comprehend\nthe environment dynamics. After training the text-conditioned generalist\npolicy, the agent can directly realize zero-shot text-to-decision generation in\nresponse to language instructions. Comprehensive experiments on MuJoCo and\nMeta-World benchmarks show that T2DA facilitates high-capacity zero-shot\ngeneralization and outperforms various types of baselines.", "published": "2025-04-21 12:00:20", "link": "http://arxiv.org/abs/2504.15046v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification", "abstract": "Lifelong Person Re-identification (LReID) suffers from a key challenge in\npreserving old knowledge while adapting to new information. The existing\nsolutions include rehearsal-based and rehearsal-free methods to address this\nchallenge. Rehearsal-based approaches rely on knowledge distillation,\ncontinuously accumulating forgetting during the distillation process.\nRehearsal-free methods insufficiently learn the distribution of each domain,\nleading to forgetfulness over time. To solve these issues, we propose a novel\nDistribution-aware Forgetting Compensation (DAFC) model that explores\ncross-domain shared representation learning and domain-specific distribution\nintegration without using old exemplars or knowledge distillation. We propose a\nText-driven Prompt Aggregation (TPA) that utilizes text features to enrich\nprompt elements and guide the prompt model to learn fine-grained\nrepresentations for each instance. This can enhance the differentiation of\nidentity information and establish the foundation for domain distribution\nawareness. Then, Distribution-based Awareness and Integration (DAI) is designed\nto capture each domain-specific distribution by a dedicated expert network and\nadaptively consolidate them into a shared region in high-dimensional space. In\nthis manner, DAI can consolidate and enhance cross-domain shared representation\nlearning while alleviating catastrophic forgetting. Furthermore, we develop a\nKnowledge Consolidation Mechanism (KCM) that comprises instance-level\ndiscrimination and cross-domain consistency alignment strategies to facilitate\nmodel adaptive learning of new knowledge from the current domain and promote\nknowledge consolidation learning between acquired domain-specific\ndistributions, respectively. Experimental results show that our DAFC\noutperforms state-of-the-art methods. Our code is available at\nhttps://github.com/LiuShiBen/DAFC.", "published": "2025-04-21 11:53:43", "link": "http://arxiv.org/abs/2504.15041v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DRAWER: Digital Reconstruction and Articulation With Environment Realism", "abstract": "Creating virtual digital replicas from real-world data unlocks significant\npotential across domains like gaming and robotics. In this paper, we present\nDRAWER, a novel framework that converts a video of a static indoor scene into a\nphotorealistic and interactive digital environment. Our approach centers on two\nmain contributions: (i) a reconstruction module based on a dual scene\nrepresentation that reconstructs the scene with fine-grained geometric details,\nand (ii) an articulation module that identifies articulation types and hinge\npositions, reconstructs simulatable shapes and appearances and integrates them\ninto the scene. The resulting virtual environment is photorealistic,\ninteractive, and runs in real time, with compatibility for game engines and\nrobotic simulation platforms. We demonstrate the potential of DRAWER by using\nit to automatically create an interactive game in Unreal Engine and to enable\nreal-to-sim-to-real transfer for robotics applications.", "published": "2025-04-21 17:59:49", "link": "http://arxiv.org/abs/2504.15278v2", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "VistaDepth: Frequency Modulation With Bias Reweighting For Enhanced Long-Range Depth Estimation", "abstract": "Monocular depth estimation (MDE) aims to predict per-pixel depth values from\na single RGB image. Recent advancements have positioned diffusion models as\neffective MDE tools by framing the challenge as a conditional image generation\ntask. Despite their progress, these methods often struggle with accurately\nreconstructing distant depths, due largely to the imbalanced distribution of\ndepth values and an over-reliance on spatial-domain features. To overcome these\nlimitations, we introduce VistaDepth, a novel framework that integrates\nadaptive frequency-domain feature enhancements with an adaptive\nweight-balancing mechanism into the diffusion process. Central to our approach\nis the Latent Frequency Modulation (LFM) module, which dynamically refines\nspectral responses in the latent feature space, thereby improving the\npreservation of structural details and reducing noisy artifacts. Furthermore,\nwe implement an adaptive weighting strategy that modulates the diffusion loss\nin real-time, enhancing the model's sensitivity towards distant depth\nreconstruction. These innovations collectively result in superior depth\nperception performance across both distance and detail. Experimental\nevaluations confirm that VistaDepth achieves state-of-the-art performance among\ndiffusion-based MDE techniques, particularly excelling in the accurate\nreconstruction of distant regions.", "published": "2025-04-21 13:30:51", "link": "http://arxiv.org/abs/2504.15095v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Histogram-based Parameter-efficient Tuning for Passive Sonar Classification", "abstract": "Parameter-efficient transfer learning (PETL) methods adapt large artificial\nneural networks to downstream tasks without fine-tuning the entire model.\nHowever, existing additive methods, such as adapters, sometimes struggle to\ncapture distributional shifts in intermediate feature embeddings. We propose a\nnovel histogram-based parameter-efficient tuning (HPT) technique that captures\nthe statistics of the target domain and modulates the embeddings. Experimental\nresults on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD)\ndemonstrate that HPT outperforms conventional adapters. Notably, HPT achieves\n91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yields\nfeature representations closer to those of fully fine-tuned models. Overall,\nHPT balances parameter savings and performance, providing a distribution-aware\nalternative to existing adapters and shows a promising direction for scalable\ntransfer learning in resource-constrained environments. The code is publicly\navailable:\nhttps://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.", "published": "2025-04-21 16:36:38", "link": "http://arxiv.org/abs/2504.15214v2", "categories": ["cs.LG", "cs.SD"], "primary_category": "cs.LG"}
{"title": "Radar Code Design for the Joint Optimization of Detection Performance and Measurement Accuracy in Track Maintenance", "abstract": "This paper deals with the design of slow-time coded waveforms which jointly\noptimize the detection probability and the measurements accuracy for track\nmaintenance in the presence of colored Gaussian interference. The output\nsignal-to-interference-plus-noise ratio (SINR) and Cram\\'er Rao bounds (CRBs)\non time delay and Doppler shift are used as figures of merit to accomplish\nreliable detection as well as accurate measurements. The transmitted code is\nsubject to radar power budget requirements and a similarity constraint. To\ntackle the resulting non-convex multi-objective optimization problem, a\npolynomial-time algorithm that integrates scalarization and tensor-based\nrelaxation methods is developed. The corresponding relaxed multi-linear\nproblems are solved by means of the maximum block improvement (MBI) framework,\nwhere the optimal solution at each iteration is obtained in closed form.\nNumeral results demonstrate the trade-off between the detection and the\nestimation performance, along with the acceptable Doppler robustness achieved\nby the proposed algorithm.", "published": "2025-04-21 06:30:11", "link": "http://arxiv.org/abs/2504.14885v2", "categories": ["eess.SP", "94A12, 94A13", "H.4.0"], "primary_category": "eess.SP"}
{"title": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting", "abstract": "Recognizing and reasoning about occluded (partially or fully hidden) objects\nis vital to understanding visual scenes, as occlusions frequently occur in\nreal-world environments and act as obstacles for spatial comprehension. To test\nmodels' ability to reason about multiple occluded objects, we introduce a novel\ntask, Counting Amodally for Patterns Through Unseen REgions (CAPTURe), which\nrequires a model to count objects arranged in a pattern by inferring how the\npattern continues behind an occluder (an object which blocks parts of the\nscene). CAPTURe requires both recognizing visual patterns and reasoning, making\nit a useful testbed for evaluating vision-language models (VLMs) on whether\nthey understand occluded patterns and possess spatial understanding skills. By\nrequiring models to reason about occluded objects, CAPTURe also tests VLMs'\nability to form world models that would allow them to fill in missing\ninformation. CAPTURe consists of two parts: (1) CAPTURe-real, with manually\nfiltered images of real objects in patterns and (2) CAPTURe-synthetic, a\ncontrolled diagnostic with generated patterned images. We evaluate four strong\nVLMs (GPT-4o, Intern-VL2, Molmo, and Qwen2-VL) on CAPTURe, finding that models\nstruggle to count on both occluded and unoccluded patterns. Crucially, we find\nthat models perform worse with occlusion, suggesting that VLMs are also\ndeficient in inferring unseen spatial relationships: even the strongest VLMs\nlike GPT-4o fail to count with occlusion. In contrast, we find that humans\nachieve very little error on CAPTURe. We also find that providing auxiliary\ninformation of occluded object locations increases performance, underscoring\nthat the model error comes both from an inability to handle occlusion as well\nas difficulty counting in images.", "published": "2025-04-21 23:38:43", "link": "http://arxiv.org/abs/2504.15485v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Speculative Sampling via Exponential Races", "abstract": "Speculative decoding accelerates large language model inference using a\nsmaller draft model. In this paper, we establish a surprising connection\nbetween speculative decoding and channel simulation, which aims at simulating a\nnoisy channel using as few bits as possible. This connection allows us to\nprovide an information-theoretic analysis of the speed up that can be achieved\nby speculative decoding. Leveraging this link, we derive an explicit relation\nbetween generation speed-up and the number of tokens $k$ generated by the draft\nmodel for large $k$, which serves as an upper bound for all $k$. We also\npropose a novel speculative decoding method via exponential race ERSD that\nmatches state-of-the-art performance.", "published": "2025-04-21 23:02:08", "link": "http://arxiv.org/abs/2504.15475v1", "categories": ["cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "Bigram Subnetworks: Mapping to Next Tokens in Transformer Language Models", "abstract": "In Transformer language models, activation vectors transform from current\ntoken embeddings to next token predictions as they pass through the model. To\nisolate a minimal form of this transformation, we identify language model\nsubnetworks that make bigram predictions, naive next token predictions based\nonly on the current token. We find that bigram subnetworks can be found in\nfully trained language models up to 1B parameters, and these subnetworks are\ncritical for model performance even when they consist of less than 0.2% of\nmodel parameters. Bigram subnetworks are concentrated in the first Transformer\nMLP layer, and they overlap significantly with subnetworks trained to optimally\nprune a given model. Mechanistically, the bigram subnetworks often recreate a\npattern from the full models where the first layer induces a sharp change that\naligns activations with next token predictions rather than current token\nrepresentations. Our results demonstrate that bigram subnetworks comprise a\nminimal subset of parameters that are both necessary and sufficient for basic\nnext token predictions in language models, and they help drive the\ntransformation from current to next token activations in the residual stream.\nThese subnetworks can lay a foundation for studying language model circuits by\nbuilding up from a minimal circuit rather than the traditional approach of\nablating circuits from a full model.", "published": "2025-04-21 22:41:00", "link": "http://arxiv.org/abs/2504.15471v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Adaptive Parallel Reasoning with Language Models", "abstract": "Scaling inference-time computation has substantially improved the reasoning\ncapabilities of language models. However, existing methods have significant\nlimitations: serialized chain-of-thought approaches generate overly long\noutputs, leading to increased latency and exhausted context windows, while\nparallel methods such as self-consistency suffer from insufficient\ncoordination, resulting in redundant computations and limited performance\ngains. To address these shortcomings, we propose Adaptive Parallel Reasoning\n(APR), a novel reasoning framework that enables language models to orchestrate\nboth serialized and parallel computations end-to-end. APR generalizes existing\nreasoning methods by enabling adaptive multi-threaded inference using spawn()\nand join() operations. A key innovation is our end-to-end reinforcement\nlearning strategy, optimizing both parent and child inference threads to\nenhance task success rate without requiring predefined reasoning structures.\nExperiments on the Countdown reasoning task demonstrate significant benefits of\nAPR: (1) higher performance within the same context window (83.4% vs. 60.0% at\n4k context); (2) superior scalability with increased computation (80.1% vs.\n66.6% at 20k total tokens); (3) improved accuracy at equivalent latency (75.2%\nvs. 57.3% at approximately 5,000ms). APR represents a step towards enabling\nlanguage models to autonomously optimize their reasoning processes through\nadaptive allocation of computation.", "published": "2025-04-21 22:29:02", "link": "http://arxiv.org/abs/2504.15466v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Real-Time Sentiment Insights from X Using VADER, DistilBERT, and Web-Scraped Data", "abstract": "In the age of social media, understanding public sentiment toward major\ncorporations is crucial for investors, policymakers, and researchers. This\npaper presents a comprehensive sentiment analysis system tailored for corporate\nreputation monitoring, combining Natural Language Processing (NLP) and machine\nlearning techniques to accurately interpret public opinion in real time. The\nmethodology integrates a hybrid sentiment detection framework leveraging both\nrule-based models (VADER) and transformer-based deep learning models\n(DistilBERT), applied to social media data from multiple platforms. The system\nbegins with robust preprocessing involving noise removal and text\nnormalization, followed by sentiment classification using an ensemble approach\nto ensure both interpretability and contextual accuracy. Results are visualized\nthrough sentiment distribution plots, comparative analyses, and temporal\nsentiment trends for enhanced interpretability. Our analysis reveals\nsignificant disparities in public sentiment across major corporations, with\ncompanies like Amazon (81.2) and Samsung (45.8) receiving excellent sentiment\nscores, while Microsoft (21.7) and Walmart (21.9) exhibit poor sentiment\nprofiles. These findings demonstrate the utility of our multi-source sentiment\nframework in providing actionable insights regarding corporate public\nperception, enabling stakeholders to make informed strategic decisions based on\ncomprehensive sentiment analysis.", "published": "2025-04-21 21:33:55", "link": "http://arxiv.org/abs/2504.15448v1", "categories": ["econ.GN", "cs.CL", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "Feeding LLM Annotations to BERT Classifiers at Your Own Risk", "abstract": "Using LLM-generated labels to fine-tune smaller encoder-only models for text\nclassification has gained popularity in various settings. While this approach\nmay be justified in simple and low-stakes applications, we conduct empirical\nanalysis to demonstrate how the perennial curse of training on synthetic data\nmanifests itself in this specific setup. Compared to models trained on gold\nlabels, we observe not only the expected performance degradation in accuracy\nand F1 score, but also increased instability across training runs and premature\nperformance plateaus. These findings cast doubts on the reliability of such\napproaches in real-world applications. We contextualize the observed phenomena\nthrough the lens of error propagation and offer several practical mitigation\nstrategies, including entropy-based filtering and ensemble techniques. Although\nthese heuristics offer partial relief, they do not fully resolve the inherent\nrisks of propagating non-random errors from LLM annotations to smaller\nclassifiers, underscoring the need for caution when applying this workflow in\nhigh-stakes text classification tasks.", "published": "2025-04-21 20:54:55", "link": "http://arxiv.org/abs/2504.15432v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Trillion 7B Technical Report", "abstract": "We introduce Trillion-7B, the most token-efficient Korean-centric\nmultilingual LLM available. Our novel Cross-lingual Document Attention (XLDA)\nmechanism enables highly efficient and effective knowledge transfer from\nEnglish to target languages like Korean and Japanese. Combined with optimized\ndata mixtures, language-specific filtering, and tailored tokenizer\nconstruction, Trillion-7B achieves competitive performance while dedicating\nonly 10\\% of its 2T training tokens to multilingual data and requiring just\n59.4K H100 GPU hours (\\$148K) for full training. Comprehensive evaluations\nacross 27 benchmarks in four languages demonstrate Trillion-7B's robust\nmultilingual performance and exceptional cross-lingual consistency.", "published": "2025-04-21 20:54:44", "link": "http://arxiv.org/abs/2504.15431v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "IV-Bench: A Benchmark for Image-Grounded Video Perception and Reasoning in Multimodal LLMs", "abstract": "Existing evaluation frameworks for Multimodal Large Language Models (MLLMs)\nprimarily focus on image reasoning or general video understanding tasks,\nlargely overlooking the significant role of image context in video\ncomprehension. To bridge this gap, we propose IV-Bench, the first comprehensive\nbenchmark for evaluating Image-Grounded Video Perception and Reasoning.\nIV-Bench consists of 967 videos paired with 2,585 meticulously annotated\nimage-text queries across 13 tasks (7 perception and 6 reasoning tasks) and 5\nrepresentative categories. Extensive evaluations of state-of-the-art\nopen-source (e.g., InternVL2.5, Qwen2.5-VL) and closed-source (e.g., GPT-4o,\nGemini2-Flash and Gemini2-Pro) MLLMs demonstrate that current models\nsubstantially underperform in image-grounded video Perception and Reasoning,\nmerely achieving at most 28.9% accuracy. Further analysis reveals key factors\ninfluencing model performance on IV-Bench, including inference pattern, frame\nnumber, and resolution. Additionally, through a simple data synthesis approach,\nwe demonstratethe challenges of IV- Bench extend beyond merely aligning the\ndata format in the training proecss. These findings collectively provide\nvaluable insights for future research. Our codes and data are released in\nhttps://github.com/multimodal-art-projection/IV-Bench.", "published": "2025-04-21 19:53:44", "link": "http://arxiv.org/abs/2504.15415v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Tell Me What You Know About Sexism: Expert-LLM Interaction Strategies and Co-Created Definitions for Zero-Shot Sexism Detection", "abstract": "This paper investigates hybrid intelligence and collaboration between\nresearchers of sexism and Large Language Models (LLMs), with a four-component\npipeline. First, nine sexism researchers answer questions about their knowledge\nof sexism and of LLMs. They then participate in two interactive experiments\ninvolving an LLM (GPT3.5). The first experiment has experts assessing the\nmodel's knowledge about sexism and suitability for use in research. The second\nexperiment tasks them with creating three different definitions of sexism: an\nexpert-written definition, an LLM-written one, and a co-created definition.\nLastly, zero-shot classification experiments use the three definitions from\neach expert in a prompt template for sexism detection, evaluating GPT4o on\n2.500 texts sampled from five sexism benchmarks. We then analyze the resulting\n67.500 classification decisions. The LLM interactions lead to longer and more\ncomplex definitions of sexism. Expert-written definitions on average perform\npoorly compared to LLM-generated definitions. However, some experts do improve\nclassification performance with their co-created definitions of sexism, also\nexperts who are inexperienced in using LLMs.", "published": "2025-04-21 18:59:18", "link": "http://arxiv.org/abs/2504.15392v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Towards Understanding Camera Motions in Any Video", "abstract": "We introduce CameraBench, a large-scale dataset and benchmark designed to\nassess and improve camera motion understanding. CameraBench consists of ~3,000\ndiverse internet videos, annotated by experts through a rigorous multi-stage\nquality control process. One of our contributions is a taxonomy of camera\nmotion primitives, designed in collaboration with cinematographers. We find,\nfor example, that some motions like \"follow\" (or tracking) require\nunderstanding scene content like moving subjects. We conduct a large-scale\nhuman study to quantify human annotation performance, revealing that domain\nexpertise and tutorial-based training can significantly enhance accuracy. For\nexample, a novice may confuse zoom-in (a change of intrinsics) with translating\nforward (a change of extrinsics), but can be trained to differentiate the two.\nUsing CameraBench, we evaluate Structure-from-Motion (SfM) and Video-Language\nModels (VLMs), finding that SfM models struggle to capture semantic primitives\nthat depend on scene content, while VLMs struggle to capture geometric\nprimitives that require precise estimation of trajectories. We then fine-tune a\ngenerative VLM on CameraBench to achieve the best of both worlds and showcase\nits applications, including motion-augmented captioning, video question\nanswering, and video-text retrieval. We hope our taxonomy, benchmark, and\ntutorials will drive future efforts towards the ultimate goal of understanding\ncamera motions in any video.", "published": "2025-04-21 18:34:57", "link": "http://arxiv.org/abs/2504.15376v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "LongPerceptualThoughts: Distilling System-2 Reasoning for System-1 Perception", "abstract": "Recent reasoning models through test-time scaling have demonstrated that long\nchain-of-thoughts can unlock substantial performance boosts in hard reasoning\ntasks such as math and code. However, the benefit of such long thoughts for\nsystem-2 reasoning is relatively less explored in other domains such as\nperceptual tasks where shallower, system-1 reasoning seems sufficient. In this\npaper, we introduce LongPerceptualThoughts, a new synthetic dataset with 30K\nlong-thought traces for perceptual tasks. The key challenges in synthesizing\nelaborate reasoning thoughts for perceptual tasks are that off-the-shelf models\nare not yet equipped with such thinking behavior and that it is not\nstraightforward to build a reliable process verifier for perceptual tasks.\nThus, we propose a novel three-stage data synthesis framework that first\nsynthesizes verifiable multiple-choice questions from dense image descriptions,\nthen extracts simple CoTs from VLMs for those verifiable problems, and finally\nexpands those simple thoughts to elaborate long thoughts via frontier reasoning\nmodels. In controlled experiments with a strong instruction-tuned 7B model, we\ndemonstrate notable improvements over existing visual reasoning data-generation\nmethods. Our model, trained on the generated dataset, achieves an average +3.4\npoints improvement over 5 vision-centric benchmarks, including +11.8 points on\nV$^*$ Bench. Notably, despite being tuned for vision tasks, it also improves\nperformance on the text reasoning benchmark, MMLU-Pro, by +2 points.", "published": "2025-04-21 18:10:38", "link": "http://arxiv.org/abs/2504.15362v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Exploring Compositional Generalization (in ReCOGS_pos) by Transformers using Restricted Access Sequence Processing (RASP)", "abstract": "Humans understand new combinations of words encountered if they are\ncombinations of words recognized from different contexts, an ability called\nCompositional Generalization. The COGS benchmark (Kim and Linzen, 2020)\narXiv:2010.05465 reports 0% accuracy for Transformer models on some structural\ngeneralizations. We use (Weiss et al., 2021) arXiv:2106.06981's Restricted\nAccess Sequence Processing (RASP), a Transformer-equivalent programming\nlanguage, to prove by construction that a Transformer encoder-decoder can\nperform the semantically equivalent ReCOGS_pos (Wu et al., 2024)\narXiv:2303.13716 variant of COGS systematically and compositionally: Our RASP\nmodel attains 100% semantic exact match on the ReCOGS test set and 100% SEM on\nall generalization splits except obj_pp_to_subj_pp which gets 92%. Furthermore,\nour RASP model shows the ReCOGS_pos task does not require a hierarchical or\ntree-structured solution: we use word-level tokens with an \"embedding\" layer\nthat tags with possible parts of speech, applying just once per encoder pass 19\nattention-head compatible flat pattern-matching rules, shown using grammar\ncoverage (Zeller et al., 2023) to be learnable from the training data, plus\ngeneral prepositional phrase (pp) handling and sentential complement (cp)\nhandling logic, and output the next logical form (LF) token (repeating until\nthe LF is complete). The model does not apply recursive, tree-structured rules\nlike 'np_det pp np -> np_pp -> np', but scores 100% semantic and string exact\nmatch on pp recursion, cp recursion using the decoder loop.", "published": "2025-04-21 18:00:24", "link": "http://arxiv.org/abs/2504.15349v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Med-CoDE: Medical Critique based Disagreement Evaluation Framework", "abstract": "The emergence of large language models (LLMs) has significantly influenced\nnumerous fields, including healthcare, by enhancing the capabilities of\nautomated systems to process and generate human-like text. However, despite\ntheir advancements, the reliability and accuracy of LLMs in medical contexts\nremain critical concerns. Current evaluation methods often lack robustness and\nfail to provide a comprehensive assessment of LLM performance, leading to\npotential risks in clinical settings. In this work, we propose Med-CoDE, a\nspecifically designed evaluation framework for medical LLMs to address these\nchallenges. The framework leverages a critique-based approach to quantitatively\nmeasure the degree of disagreement between model-generated responses and\nestablished medical ground truths. This framework captures both accuracy and\nreliability in medical settings. The proposed evaluation framework aims to fill\nthe existing gap in LLM assessment by offering a systematic method to evaluate\nthe quality and trustworthiness of medical LLMs. Through extensive experiments\nand case studies, we illustrate the practicality of our framework in providing\na comprehensive and reliable evaluation of medical LLMs.", "published": "2025-04-21 16:51:11", "link": "http://arxiv.org/abs/2504.15330v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Improving Human-AI Coordination through Adversarial Training and Generative Models", "abstract": "Being able to cooperate with new people is an important component of many\neconomically valuable AI tasks, from household robotics to autonomous driving.\nHowever, generalizing to novel humans requires training on data that captures\nthe diversity of human behaviors. Adversarial training is one avenue for\nsearching for such data and ensuring that agents are robust. However, it is\ndifficult to apply in the cooperative setting because adversarial policies\nintentionally learn to sabotage the task instead of simulating valid\ncooperation partners. To address this challenge, we propose a novel strategy\nfor overcoming self-sabotage that combines a pre-trained generative model to\nsimulate valid cooperative agent policies with adversarial training to maximize\nregret. We call our method GOAT: Generative Online Adversarial Training. In\nthis framework, the GOAT dynamically searches for and generates coordination\nstrategies where the learning policy -- the Cooperator agent -- underperforms.\nGOAT enables better generalization by exposing the Cooperator to various\nchallenging interaction scenarios. We maintain realistic coordination\nstrategies by updating only the generative model's embedding while keeping its\nparameters frozen, thus avoiding adversarial exploitation. We evaluate GOAT\nwith real human partners, and the results demonstrate state-of-the-art\nperformance on the Overcooked benchmark, highlighting its effectiveness in\ngeneralizing to diverse human behaviors.", "published": "2025-04-21 21:53:00", "link": "http://arxiv.org/abs/2504.15457v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Demand for LLMs: Descriptive Evidence on Substitution, Market Expansion, and Multihoming", "abstract": "This paper documents three stylized facts about the demand for Large Language\nModels (LLMs) using data from OpenRouter, a prominent LLM marketplace. First,\nnew models experience rapid initial adoption that stabilizes within weeks.\nSecond, model releases differ substantially in whether they primarily attract\nnew users or substitute demand from competing models. Third, multihoming, using\nmultiple models simultaneously, is common among apps. These findings suggest\nsignificant horizontal and vertical differentiation in the LLM market, implying\nopportunities for providers to maintain demand and pricing power despite rapid\ntechnological advances.", "published": "2025-04-21 21:12:28", "link": "http://arxiv.org/abs/2504.15440v1", "categories": ["cs.CY", "cs.AI", "econ.GN", "q-fin.EC", "K.4; I.2"], "primary_category": "cs.CY"}
{"title": "AGI Is Coming... Right After AI Learns to Play Wordle", "abstract": "This paper investigates multimodal agents, in particular, OpenAI's\nComputer-User Agent (CUA), trained to control and complete tasks through a\nstandard computer interface, similar to humans. We evaluated the agent's\nperformance on the New York Times Wordle game to elicit model behaviors and\nidentify shortcomings. Our findings revealed a significant discrepancy in the\nmodel's ability to recognize colors correctly depending on the context. The\nmodel had a $5.36\\%$ success rate over several hundred runs across a week of\nWordle. Despite the immense enthusiasm surrounding AI agents and their\npotential to usher in Artificial General Intelligence (AGI), our findings\nreinforce the fact that even simple tasks present substantial challenges for\ntoday's frontier AI models. We conclude with a discussion of the potential\nunderlying causes, implications for future development, and research directions\nto improve these AI systems.", "published": "2025-04-21 20:58:58", "link": "http://arxiv.org/abs/2504.15434v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Solving Multi-Agent Safe Optimal Control with Distributed Epigraph Form MARL", "abstract": "Tasks for multi-robot systems often require the robots to collaborate and\ncomplete a team goal while maintaining safety. This problem is usually\nformalized as a constrained Markov decision process (CMDP), which targets\nminimizing a global cost and bringing the mean of constraint violation below a\nuser-defined threshold. Inspired by real-world robotic applications, we define\nsafety as zero constraint violation. While many safe multi-agent reinforcement\nlearning (MARL) algorithms have been proposed to solve CMDPs, these algorithms\nsuffer from unstable training in this setting. To tackle this, we use the\nepigraph form for constrained optimization to improve training stability and\nprove that the centralized epigraph form problem can be solved in a distributed\nfashion by each agent. This results in a novel centralized training distributed\nexecution MARL algorithm named Def-MARL. Simulation experiments on 8 different\ntasks across 2 different simulators show that Def-MARL achieves the best\noverall performance, satisfies safety constraints, and maintains stable\ntraining. Real-world hardware experiments on Crazyflie quadcopters demonstrate\nthe ability of Def-MARL to safely coordinate agents to complete complex\ncollaborative tasks compared to other methods.", "published": "2025-04-21 20:34:55", "link": "http://arxiv.org/abs/2504.15425v1", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA", "math.OC"], "primary_category": "cs.RO"}
{"title": "LLM-Assisted Translation of Legacy FORTRAN Codes to C++: A Cross-Platform Study", "abstract": "Large Language Models (LLMs) are increasingly being leveraged for generating\nand translating scientific computer codes by both domain-experts and non-domain\nexperts. Fortran has served as one of the go to programming languages in legacy\nhigh-performance computing (HPC) for scientific discoveries. Despite growing\nadoption, LLM-based code translation of legacy code-bases has not been\nthoroughly assessed or quantified for its usability. Here, we studied the\napplicability of LLM-based translation of Fortran to C++ as a step towards\nbuilding an agentic-workflow using open-weight LLMs on two different\ncomputational platforms. We statistically quantified the compilation accuracy\nof the translated C++ codes, measured the similarity of the LLM translated code\nto the human translated C++ code, and statistically quantified the output\nsimilarity of the Fortran to C++ translation.", "published": "2025-04-21 20:34:37", "link": "http://arxiv.org/abs/2504.15424v1", "categories": ["cs.SE", "cs.AI", "I.2.2; I.2.7; D.2.3; D.2.4"], "primary_category": "cs.SE"}
{"title": "On the Boolean Network Theory of Datalog$^\\neg$", "abstract": "Datalog$^\\neg$ is a central formalism used in a variety of domains ranging\nfrom deductive databases and abstract argumentation frameworks to answer set\nprogramming. Its model theory is the finite counterpart of the logical\nsemantics developed for normal logic programs, mainly based on the notions of\nClark's completion and two-valued or three-valued canonical models including\nsupported, stable, regular and well-founded models. In this paper we establish\na formal link between Datalog$^\\neg$ and Boolean network theory, which was\ninitially introduced by Stuart Kaufman and Ren\\'e Thomas to reason about gene\nregulatory networks. We use previous results from Boolean network theory to\nprove that in the absence of odd cycles in a Datalog$^\\neg$ program, the\nregular models coincide with the stable models, which entails the existence of\nstable models, and in the absence of even cycles, we show the uniqueness of\nstable partial models, which entails the uniqueness of regular models. These\nresults on regular models have been claimed by You and Yuan in 1994 for normal\nlogic programs but we show problems in their definition of well-founded\nstratification and in their proofs that we can fix for negative normal logic\nprograms only. We also give upper bounds on the numbers of stable partial,\nregular, and stable models of a Datalog$^\\neg$ program using the cardinality of\na feedback vertex set in its atom dependency graph. Interestingly, our\nconnection to Boolean network theory also points us to the notion of trap\nspaces for Datalog$^\\neg$ programs. We relate the notions of supported or\nstable trap spaces to the other semantics of Datalog$^\\neg$, and show the\nequivalence between subset-minimal stable trap spaces and regular models.", "published": "2025-04-21 20:02:59", "link": "http://arxiv.org/abs/2504.15417v1", "categories": ["cs.LO", "cs.AI"], "primary_category": "cs.LO"}
{"title": "Solving New Tasks by Adapting Internet Video Knowledge", "abstract": "Video generative models demonstrate great promise in robotics by serving as\nvisual planners or as policy supervisors. When pretrained on internet-scale\ndata, such video models intimately understand alignment with natural language,\nand can thus facilitate generalization to novel downstream behavior through\ntext-conditioning. However, they may not be sensitive to the specificities of\nthe particular environment the agent inhabits. On the other hand, training\nvideo models on in-domain examples of robotic behavior naturally encodes\nenvironment-specific intricacies, but the scale of available demonstrations may\nnot be sufficient to support generalization to unseen tasks via natural\nlanguage specification. In this work, we investigate different adaptation\ntechniques that integrate in-domain information with large-scale pretrained\nvideo models, and explore the extent to which they enable novel\ntext-conditioned generalization for robotic tasks, while also considering their\nindependent data and resource considerations. We successfully demonstrate\nacross robotic environments that adapting powerful video models with small\nscales of example data can successfully facilitate generalization to novel\nbehaviors. In particular, we present a novel adaptation strategy, termed\nInverse Probabilistic Adaptation, that not only consistently achieves strong\ngeneralization performance across robotic tasks and settings, but also exhibits\nrobustness to the quality of adaptation data, successfully solving novel tasks\neven when only suboptimal in-domain demonstrations are available.", "published": "2025-04-21 18:20:13", "link": "http://arxiv.org/abs/2504.15369v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "KeDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments", "abstract": "In this work, we demonstrate that distinctive keys during LLM inference tend\nto have high attention scores. We explore this phenomenon and propose KeyDiff,\na training-free KV cache eviction method based on key similarity. This method\nfacilitates the deployment of LLM-based application requiring long input\nprompts in resource-constrained environments with limited memory and compute\nbudgets. Unlike other KV cache eviction methods, KeyDiff can process\narbitrarily long prompts within strict resource constraints and efficiently\ngenerate responses. We demonstrate that KeyDiff computes the optimal solution\nto a KV cache selection problem that maximizes key diversity, providing a\ntheoretical understanding of KeyDiff. Notably,KeyDiff does not rely on\nattention scores, allowing the use of optimized attention mechanisms like\nFlashAttention. We demonstrate the effectiveness of KeyDiff across diverse\ntasks and models, illustrating a performance gap of less than 0.04\\% with 8K\ncache budget ($\\sim$ 23\\% KV cache reduction) from the non-evicting baseline on\nthe LongBench benchmark for Llama 3.1-8B and Llama 3.2-3B.", "published": "2025-04-21 18:12:46", "link": "http://arxiv.org/abs/2504.15364v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Reliable Classification with Conformal Learning and Interval-Type 2 Fuzzy Sets", "abstract": "Classical machine learning classifiers tend to be overconfident can be\nunreliable outside of the laboratory benchmarks. Properly assessing the\nreliability of the output of the model per sample is instrumental for real-life\nscenarios where these systems are deployed. Because of this, different\ntechniques have been employed to properly quantify the quality of prediction\nfor a given model. These are most commonly Bayesian statistics and, more\nrecently, conformal learning. Given a calibration set, conformal learning can\nproduce outputs that are guaranteed to cover the target class with a desired\nsignificance level, and are more reliable than the standard confidence\nintervals used by Bayesian methods. In this work, we propose to use conformal\nlearning with fuzzy rule-based systems in classification and show some metrics\nof their performance. Then, we discuss how the use of type 2 fuzzy sets can\nimprove the quality of the output of the system compared to both fuzzy and\ncrisp rules. Finally, we also discuss how the fine-tuning of the system can be\nadapted to improve the quality of the conformal prediction.", "published": "2025-04-21 18:07:55", "link": "http://arxiv.org/abs/2504.15360v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Split-quaternions for perceptual white balance", "abstract": "We propose a perceptual chromatic adaptation transform for white balance that\nmakes use of split-quaternions. The novelty of the present work, which is\nmotivated by a recently developed quantum-like model of color perception,\nconsists at stressing the link between the algebraic structures appearing in\nthis model and a certain sub-algebra of the split-quaternions. We show the\npotentiality of this approach for color image processing applications by\nproposing a chromatic adaptation transform, implemented via an appropriate use\nof the split-quaternion multiplication. Moreover, quantitative comparisons with\nthe widely used state-of-the art von Kries chromatic adaptation transform are\nprovided.", "published": "2025-04-21 23:25:37", "link": "http://arxiv.org/abs/2504.15481v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Unifying Image Counterfactuals and Feature Attributions with Latent-Space Adversarial Attacks", "abstract": "Counterfactuals are a popular framework for interpreting machine learning\npredictions. These what if explanations are notoriously challenging to create\nfor computer vision models: standard gradient-based methods are prone to\nproduce adversarial examples, in which imperceptible modifications to image\npixels provoke large changes in predictions. We introduce a new,\neasy-to-implement framework for counterfactual images that can flexibly adapt\nto contemporary advances in generative modeling. Our method, Counterfactual\nAttacks, resembles an adversarial attack on the representation of the image\nalong a low-dimensional manifold. In addition, given an auxiliary dataset of\nimage descriptors, we show how to accompany counterfactuals with feature\nattribution that quantify the changes between the original and counterfactual\nimages. These importance scores can be aggregated into global counterfactual\nexplanations that highlight the overall features driving model predictions.\nWhile this unification is possible for any counterfactual method, it has\nparticular computational efficiency for ours. We demonstrate the efficacy of\nour approach with the MNIST and CelebA datasets.", "published": "2025-04-21 23:09:30", "link": "http://arxiv.org/abs/2504.15479v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Emergence and Evolution of Interpretable Concepts in Diffusion Models", "abstract": "Diffusion models have become the go-to method for text-to-image generation,\nproducing high-quality images from noise through a process called reverse\ndiffusion. Understanding the dynamics of the reverse diffusion process is\ncrucial in steering the generation and achieving high sample quality. However,\nthe inner workings of diffusion models is still largely a mystery due to their\nblack-box nature and complex, multi-step generation process. Mechanistic\nInterpretability (MI) techniques, such as Sparse Autoencoders (SAEs), aim at\nuncovering the operating principles of models through granular analysis of\ntheir internal representations. These MI techniques have been successful in\nunderstanding and steering the behavior of large language models at scale.\nHowever, the great potential of SAEs has not yet been applied toward gaining\ninsight into the intricate generative process of diffusion models. In this\nwork, we leverage the SAE framework to probe the inner workings of a popular\ntext-to-image diffusion model, and uncover a variety of human-interpretable\nconcepts in its activations. Interestingly, we find that even before the first\nreverse diffusion step is completed, the final composition of the scene can be\npredicted surprisingly well by looking at the spatial distribution of activated\nconcepts. Moreover, going beyond correlational analysis, we show that the\ndiscovered concepts have a causal effect on the model output and can be\nleveraged to steer the generative process. We design intervention techniques\naimed at manipulating image composition and style, and demonstrate that (1) in\nearly stages of diffusion image composition can be effectively controlled, (2)\nin the middle stages of diffusion image composition is finalized, however\nstylistic interventions are effective, and (3) in the final stages of diffusion\nonly minor textural details are subject to change.", "published": "2025-04-21 22:48:37", "link": "http://arxiv.org/abs/2504.15473v1", "categories": ["cs.CV", "cs.LG", "eess.IV", "I.2.6; I.2.10"], "primary_category": "cs.CV"}
{"title": "Manifold Induced Biases for Zero-shot and Few-shot Detection of Generated Images", "abstract": "Distinguishing between real and AI-generated images, commonly referred to as\n'image detection', presents a timely and significant challenge. Despite\nextensive research in the (semi-)supervised regime, zero-shot and few-shot\nsolutions have only recently emerged as promising alternatives. Their main\nadvantage is in alleviating the ongoing data maintenance, which quickly becomes\noutdated due to advances in generative technologies. We identify two main gaps:\n(1) a lack of theoretical grounding for the methods, and (2) significant room\nfor performance improvements in zero-shot and few-shot regimes. Our approach is\nfounded on understanding and quantifying the biases inherent in generated\ncontent, where we use these quantities as criteria for characterizing generated\nimages. Specifically, we explore the biases of the implicit probability\nmanifold, captured by a pre-trained diffusion model. Through score-function\nanalysis, we approximate the curvature, gradient, and bias towards points on\nthe probability manifold, establishing criteria for detection in the zero-shot\nregime. We further extend our contribution to the few-shot setting by employing\na mixture-of-experts methodology. Empirical results across 20 generative models\ndemonstrate that our method outperforms current approaches in both zero-shot\nand few-shot settings. This work advances the theoretical understanding and\npractical usage of generated content biases through the lens of manifold\nanalysis.", "published": "2025-04-21 22:39:24", "link": "http://arxiv.org/abs/2504.15470v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Context Aware Grounded Teacher for Source Free Object Detection", "abstract": "We focus on the Source Free Object Detection (SFOD) problem, when source data\nis unavailable during adaptation, and the model must adapt to the unlabeled\ntarget domain. In medical imaging, several approaches have leveraged a\nsemi-supervised student-teacher architecture to bridge domain discrepancy.\nContext imbalance in labeled training data and significant domain shifts\nbetween domains can lead to biased teacher models that produce inaccurate\npseudolabels, degrading the student model's performance and causing a mode\ncollapse. Class imbalance, particularly when one class significantly outnumbers\nanother, leads to contextual bias. To tackle the problem of context bias and\nthe significant performance drop of the student model in the SFOD setting, we\nintroduce Grounded Teacher (GT) as a standard framework. In this study, we\nmodel contextual relationships using a dedicated relational context module and\nleverage it to mitigate inherent biases in the model. This approach enables us\nto apply augmentations to closely related classes, across and within domains,\nenhancing the performance of underrepresented classes while keeping the effect\non dominant classes minimal. We further improve the quality of predictions by\nimplementing an expert foundational branch to supervise the student model. We\nvalidate the effectiveness of our approach in mitigating context bias under the\nSFOD setting through experiments on three medical datasets supported by\ncomprehensive ablation studies. All relevant resources, including preprocessed\ndata, trained model weights, and code, are publicly available at this\nhttps://github.com/Tajamul21/Grounded_Teacher.", "published": "2025-04-21 19:13:33", "link": "http://arxiv.org/abs/2504.15404v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MirrorVerse: Pushing Diffusion Models to Realistically Reflect the World", "abstract": "Diffusion models have become central to various image editing tasks, yet they\noften fail to fully adhere to physical laws, particularly with effects like\nshadows, reflections, and occlusions. In this work, we address the challenge of\ngenerating photorealistic mirror reflections using diffusion-based generative\nmodels. Despite extensive training data, existing diffusion models frequently\noverlook the nuanced details crucial to authentic mirror reflections. Recent\napproaches have attempted to resolve this by creating synhetic datasets and\nframing reflection generation as an inpainting task; however, they struggle to\ngeneralize across different object orientations and positions relative to the\nmirror. Our method overcomes these limitations by introducing key augmentations\ninto the synthetic data pipeline: (1) random object positioning, (2) randomized\nrotations, and (3) grounding of objects, significantly enhancing generalization\nacross poses and placements. To further address spatial relationships and\nocclusions in scenes with multiple objects, we implement a strategy to pair\nobjects during dataset generation, resulting in a dataset robust enough to\nhandle these complex scenarios. Achieving generalization to real-world scenes\nremains a challenge, so we introduce a three-stage training curriculum to\ndevelop the MirrorFusion 2.0 model to improve real-world performance. We\nprovide extensive qualitative and quantitative evaluations to support our\napproach. The project page is available at: https://mirror-verse.github.io/.", "published": "2025-04-21 19:01:02", "link": "http://arxiv.org/abs/2504.15397v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ICGM-FRAX: Iterative Cross Graph Matching for Hip Fracture Risk Assessment using Dual-energy X-ray Absorptiometry Images", "abstract": "Hip fractures represent a major health concern, particularly among the\nelderly, often leading decreased mobility and increased mortality. Early and\naccurate detection of at risk individuals is crucial for effective\nintervention. In this study, we propose Iterative Cross Graph Matching for Hip\nFracture Risk Assessment (ICGM-FRAX), a novel approach for predicting hip\nfractures using Dual-energy X-ray Absorptiometry (DXA) images. ICGM-FRAX\ninvolves iteratively comparing a test (subject) graph with multiple template\ngraphs representing the characteristics of hip fracture subjects to assess the\nsimilarity and accurately to predict hip fracture risk. These graphs are\nobtained as follows. The DXA images are separated into multiple regions of\ninterest (RoIs), such as the femoral head, shaft, and lesser trochanter.\nRadiomic features are then calculated for each RoI, with the central\ncoordinates used as nodes in a graph. The connectivity between nodes is\nestablished according to the Euclidean distance between these coordinates. This\nprocess transforms each DXA image into a graph, where each node represents a\nRoI, and edges derived by the centroids of RoIs capture the spatial\nrelationships between them. If the test graph closely matches a set of template\ngraphs representing subjects with incident hip fractures, it is classified as\nindicating high hip fracture risk. We evaluated our method using 547 subjects\nfrom the UK Biobank dataset, and experimental results show that ICGM-FRAX\nachieved a sensitivity of 0.9869, demonstrating high accuracy in predicting hip\nfractures.", "published": "2025-04-21 18:52:15", "link": "http://arxiv.org/abs/2504.15384v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Plug-and-Play Versatile Compressed Video Enhancement", "abstract": "As a widely adopted technique in data transmission, video compression\neffectively reduces the size of files, making it possible for real-time cloud\ncomputing. However, it comes at the cost of visual quality, posing challenges\nto the robustness of downstream vision models. In this work, we present a\nversatile codec-aware enhancement framework that reuses codec information to\nadaptively enhance videos under different compression settings, assisting\nvarious downstream vision tasks without introducing computation bottleneck.\nSpecifically, the proposed codec-aware framework consists of a\ncompression-aware adaptation (CAA) network that employs a hierarchical\nadaptation mechanism to estimate parameters of the frame-wise enhancement\nnetwork, namely the bitstream-aware enhancement (BAE) network. The BAE network\nfurther leverages temporal and spatial priors embedded in the bitstream to\neffectively improve the quality of compressed input frames. Extensive\nexperimental results demonstrate the superior quality enhancement performance\nof our framework over existing enhancement methods, as well as its versatility\nin assisting multiple downstream tasks on compressed videos as a plug-and-play\nmodule. Code and models are available at\nhttps://huimin-zeng.github.io/PnP-VCVE/.", "published": "2025-04-21 18:39:31", "link": "http://arxiv.org/abs/2504.15380v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Physics Driven Image Simulation from Commercial Satellite Imagery", "abstract": "Physics driven image simulation allows for the modeling and creation of\nrealistic imagery beyond what is afforded by typical rendering pipelines. We\naim to automatically generate a physically realistic scene for simulation of a\ngiven region using satellite imagery to model the scene geometry, drive\nmaterial estimates, and populate the scene with dynamic elements. We present\nautomated techniques to utilize satellite imagery throughout the simulated\nscene to expedite scene construction and decrease manual overhead. Our\ntechnique does not use lidar, enabling simulations that could not be\nconstructed previously. To develop a 3D scene, we model the various components\nof the real location, addressing the terrain, modelling man-made structures,\nand populating the scene with smaller elements such as vegetation and vehicles.\nTo create the scene we begin with a Digital Surface Model, which serves as the\nbasis for scene geometry, and allows us to reason about the real location in a\ncommon 3D frame of reference. These simulated scenes can provide increased\nfidelity with less manual intervention for novel locations on earth, and can\nfacilitate algorithm development, and processing pipelines for imagery ranging\nfrom UV to LWIR $(200nm-20\\mu m)$.", "published": "2025-04-21 18:38:00", "link": "http://arxiv.org/abs/2504.15378v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Event2Vec: Processing neuromorphic events directly by representations in vector space", "abstract": "The neuromorphic event cameras have overwhelming advantages in temporal\nresolution, power efficiency, and dynamic range compared to traditional\ncameras. However, the event cameras output asynchronous, sparse, and irregular\nevents, which are not compatible with mainstream computer vision and deep\nlearning methods. Various methods have been proposed to solve this issue but at\nthe cost of long preprocessing procedures, losing temporal resolutions, or\nbeing incompatible with massively parallel computation. Inspired by the great\nsuccess of the word to vector, we summarize the similarities between words and\nevents, then propose the first event to vector (event2vec) representation. We\nvalidate event2vec on classifying the ASL-DVS dataset, showing impressive\nparameter efficiency, accuracy, and speed than previous graph/image/voxel-based\nrepresentations. Beyond task performance, the most attractive advantage of\nevent2vec is that it aligns events to the domain of natural language\nprocessing, showing the promising prospect of integrating events into large\nlanguage and multimodal models. Our codes, models, and training logs are\navailable at https://github.com/fangwei123456/event2vec.", "published": "2025-04-21 18:21:18", "link": "http://arxiv.org/abs/2504.15371v1", "categories": ["cs.CV", "cs.NE"], "primary_category": "cs.CV"}
{"title": "Vision6D: 3D-to-2D Interactive Visualization and Annotation Tool for 6D Pose Estimation", "abstract": "Accurate 6D pose estimation has gained more attention over the years for\nrobotics-assisted tasks that require precise interaction with physical objects.\nThis paper presents an interactive 3D-to-2D visualization and annotation tool\nto support the 6D pose estimation research community. To the best of our\nknowledge, the proposed work is the first tool that allows users to visualize\nand manipulate 3D objects interactively on a 2D real-world scene, along with a\ncomprehensive user study. This system supports robust 6D camera pose annotation\nby providing both visual cues and spatial relationships to determine object\nposition and orientation in various environments. The annotation feature in\nVision6D is particularly helpful in scenarios where the transformation matrix\nbetween the camera and world objects is unknown, as it enables accurate\nannotation of these objects' poses using only the camera intrinsic matrix. This\ncapability serves as a foundational step in developing and training advanced\npose estimation models across various domains. We evaluate Vision6D's\neffectiveness by utilizing widely-used open-source pose estimation datasets\nLinemod and HANDAL through comparisons between the default ground-truth camera\nposes with manual annotations. A user study was performed to show that Vision6D\ngenerates accurate pose annotations via visual cues in an intuitive 3D user\ninterface. This approach aims to bridge the gap between 2D scene projections\nand 3D scenes, offering an effective way for researchers and developers to\nsolve 6D pose annotation related problems. The software is open-source and\npublicly available at https://github.com/InteractiveGL/vision6D.", "published": "2025-04-21 16:36:52", "link": "http://arxiv.org/abs/2504.15329v1", "categories": ["cs.GR", "cs.CV", "cs.HC", "cs.RO"], "primary_category": "cs.GR"}
{"title": "From Reviews to Dialogues: Active Synthesis for Zero-Shot LLM-based Conversational Recommender System", "abstract": "Conversational recommender systems (CRS) typically require extensive\ndomain-specific conversational datasets, yet high costs, privacy concerns, and\ndata-collection challenges severely limit their availability. Although Large\nLanguage Models (LLMs) demonstrate strong zero-shot recommendation\ncapabilities, practical applications often favor smaller, internally managed\nrecommender models due to scalability, interpretability, and data privacy\nconstraints, especially in sensitive or rapidly evolving domains. However,\ntraining these smaller models effectively still demands substantial\ndomain-specific conversational data, which remains challenging to obtain. To\naddress these limitations, we propose an active data augmentation framework\nthat synthesizes conversational training data by leveraging black-box LLMs\nguided by active learning techniques. Specifically, our method utilizes\npublicly available non-conversational domain data, including item metadata,\nuser reviews, and collaborative signals, as seed inputs. By employing active\nlearning strategies to select the most informative seed samples, our approach\nefficiently guides LLMs to generate synthetic, semantically coherent\nconversational interactions tailored explicitly to the target domain. Extensive\nexperiments validate that conversational data generated by our proposed\nframework significantly improves the performance of LLM-based CRS models,\neffectively addressing the challenges of building CRS in no- or low-resource\nscenarios.", "published": "2025-04-21 23:05:47", "link": "http://arxiv.org/abs/2504.15476v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Capacity on BMS Channels via Code Symmetry and Nesting", "abstract": "The past decade has seen notable advances in our understanding of structured\nerror-correcting codes, particularly binary Reed--Muller (RM) codes. While\ninitial breakthroughs were for erasure channels based on symmetry, extending\nthese results to the binary symmetric channel (BSC) and other binary memoryless\nsymmetric (BMS) channels required new tools and conditions. Recent work uses\nnesting to obtain multiple weakly correlated \"looks\" that imply\ncapacity-achieving performance under bit-MAP and block-MAP decoding. This paper\nrevisits and extends past approaches, aiming to simplify proofs, unify\ninsights, and remove unnecessary conditions. By leveraging powerful results\nfrom the analysis of boolean functions, we derive recursive bounds using two or\nthree looks at each stage. This gives bounds on the bit error probability that\ndecay exponentially in the number of stages. For the BSC, we incorporate\nlevel-k inequalities and hypercontractive techniques to achieve the faster\ndecay rate required for vanishing block error probability. The results are\npresented in a semitutorial style, providing both theoretical insights and\npractical implications for future research on structured codes.", "published": "2025-04-21 19:00:24", "link": "http://arxiv.org/abs/2504.15394v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Graph Based Raman Spectral Processing Technique for Exosome Classification", "abstract": "Exosomes are small vesicles crucial for cell signaling and disease\nbiomarkers. Due to their complexity, an \"omics\" approach is preferable to\nindividual biomarkers. While Raman spectroscopy is effective for exosome\nanalysis, it requires high sample concentrations and has limited sensitivity to\nlipids and proteins. Surface-enhanced Raman spectroscopy helps overcome these\nchallenges. In this study, we leverage Neo4j graph databases to organize 3,045\nRaman spectra of exosomes, enhancing data generalization. To further refine\nspectral analysis, we introduce a novel spectral filtering process that\nintegrates the PageRank Filter with optimal Dimensionality Reduction. This\nmethod improves feature selection, resulting in superior classification\nperformance. Specifically, the Extra Trees model, using our spectral processing\napproach, achieves 0.76 and 0.857 accuracy in classifying hyperglycemic,\nhypoglycemic, and normal exosome samples based on Raman spectra and surface,\nrespectively, with group 10-fold cross-validation. Our results show that\ngraph-based spectral filtering combined with optimal dimensionality reduction\nsignificantly improves classification accuracy by reducing noise while\npreserving key biomarker signals. This novel framework enhances Raman-based\nexosome analysis, expanding its potential for biomedical applications, disease\ndiagnostics, and biomarker discovery.", "published": "2025-04-21 09:19:41", "link": "http://arxiv.org/abs/2504.15324v1", "categories": ["q-bio.QM", "cs.AI", "cs.IT", "cs.LG", "math.IT"], "primary_category": "q-bio.QM"}
{"title": "Application of Deep Generative Models for Anomaly Detection in Complex Financial Transactions", "abstract": "This study proposes an algorithm for detecting suspicious behaviors in large\npayment flows based on deep generative models. By combining Generative\nAdversarial Networks (GAN) and Variational Autoencoders (VAE), the algorithm is\ndesigned to detect abnormal behaviors in financial transactions. First, the GAN\nis used to generate simulated data that approximates normal payment flows. The\ndiscriminator identifies anomalous patterns in transactions, enabling the\ndetection of potential fraud and money laundering behaviors. Second, a VAE is\nintroduced to model the latent distribution of payment flows, ensuring that the\ngenerated data more closely resembles real transaction features, thus improving\nthe model's detection accuracy. The method optimizes the generative\ncapabilities of both GAN and VAE, ensuring that the model can effectively\ncapture suspicious behaviors even in sparse data conditions. Experimental\nresults show that the proposed method significantly outperforms traditional\nmachine learning algorithms and other deep learning models across various\nevaluation metrics, especially in detecting rare fraudulent behaviors.\nFurthermore, this study provides a detailed comparison of performance in\nrecognizing different transaction patterns (such as normal, money laundering,\nand fraud) in large payment flows, validating the advantages of generative\nmodels in handling complex financial data.", "published": "2025-04-21 23:49:10", "link": "http://arxiv.org/abs/2504.15491v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Fourier analysis of the physics of transfer learning for data-driven subgrid-scale models of ocean turbulence", "abstract": "Transfer learning (TL) is a powerful tool for enhancing the performance of\nneural networks (NNs) in applications such as weather and climate prediction\nand turbulence modeling. TL enables models to generalize to out-of-distribution\ndata with minimal training data from the new system. In this study, we employ a\n9-layer convolutional NN to predict the subgrid forcing in a two-layer ocean\nquasi-geostrophic system and examine which metrics best describe its\nperformance and generalizability to unseen dynamical regimes. Fourier analysis\nof the NN kernels reveals that they learn low-pass, Gabor, and high-pass\nfilters, regardless of whether the training data are isotropic or anisotropic.\nBy analyzing the activation spectra, we identify why NNs fail to generalize\nwithout TL and how TL can overcome these limitations: the learned weights and\nbiases from one dataset underestimate the out-of-distribution sample spectra as\nthey pass through the network, leading to an underestimation of output spectra.\nBy re-training only one layer with data from the target system, this\nunderestimation is corrected, enabling the NN to produce predictions that match\nthe target spectra. These findings are broadly applicable to data-driven\nparameterization of dynamical systems.", "published": "2025-04-21 23:42:19", "link": "http://arxiv.org/abs/2504.15487v1", "categories": ["cs.LG", "nlin.CD", "physics.ao-ph", "physics.geo-ph"], "primary_category": "cs.LG"}
{"title": "In-context Ranking Preference Optimization", "abstract": "Recent developments in Direct Preference Optimization (DPO) allow large\nlanguage models (LLMs) to function as implicit ranking models by maximizing the\nmargin between preferred and non-preferred responses. In practice, user\nfeedback on such lists typically involves identifying a few relevant items in\ncontext rather than providing detailed pairwise comparisons for every possible\nitem pair. Moreover, many complex information retrieval tasks, such as\nconversational agents and summarization systems, critically depend on ranking\nthe highest-quality outputs at the top, emphasizing the need to support natural\nand flexible forms of user feedback. To address the challenge of limited and\nsparse pairwise feedback in the in-context setting, we propose an In-context\nRanking Preference Optimization (IRPO) framework that directly optimizes LLMs\nbased on ranking lists constructed during inference. To further capture\nflexible forms of feedback, IRPO extends the DPO objective by incorporating\nboth the relevance of items and their positions in the list. Modeling these\naspects jointly is non-trivial, as ranking metrics are inherently discrete and\nnon-differentiable, making direct optimization difficult. To overcome this,\nIRPO introduces a differentiable objective based on positional aggregation of\npairwise item preferences, enabling effective gradient-based optimization of\ndiscrete ranking metrics. We further provide theoretical insights showing that\nIRPO (i) automatically emphasizes items with greater disagreement between the\nmodel and the reference ranking, and (ii) links its gradient to an importance\nsampling estimator, yielding an unbiased estimator with reduced variance.\nEmpirical results show IRPO outperforms standard DPO approaches in ranking\nperformance, highlighting its effectiveness in aligning LLMs with direct\nin-context ranking preferences.", "published": "2025-04-21 23:06:12", "link": "http://arxiv.org/abs/2504.15477v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "LAPP: Large Language Model Feedback for Preference-Driven Reinforcement Learning", "abstract": "We introduce Large Language Model-Assisted Preference Prediction (LAPP), a\nnovel framework for robot learning that enables efficient, customizable, and\nexpressive behavior acquisition with minimum human effort. Unlike prior\napproaches that rely heavily on reward engineering, human demonstrations,\nmotion capture, or expensive pairwise preference labels, LAPP leverages large\nlanguage models (LLMs) to automatically generate preference labels from raw\nstate-action trajectories collected during reinforcement learning (RL). These\nlabels are used to train an online preference predictor, which in turn guides\nthe policy optimization process toward satisfying high-level behavioral\nspecifications provided by humans. Our key technical contribution is the\nintegration of LLMs into the RL feedback loop through trajectory-level\npreference prediction, enabling robots to acquire complex skills including\nsubtle control over gait patterns and rhythmic timing. We evaluate LAPP on a\ndiverse set of quadruped locomotion and dexterous manipulation tasks and show\nthat it achieves efficient learning, higher final performance, faster\nadaptation, and precise control of high-level behaviors. Notably, LAPP enables\nrobots to master highly dynamic and expressive tasks such as quadruped\nbackflips, which remain out of reach for standard LLM-generated or handcrafted\nrewards. Our results highlight LAPP as a promising direction for scalable\npreference-driven robot learning.", "published": "2025-04-21 22:46:29", "link": "http://arxiv.org/abs/2504.15472v1", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "LithOS: An Operating System for Efficient Machine Learning on GPUs", "abstract": "The surging demand for GPUs in datacenters for machine learning (ML) has made\nefficient GPU utilization crucial. However, meeting the diverse needs of ML\nmodels while optimizing resource usage is challenging. To enable transparent,\nfine-grained GPU management that maximizes utilization and energy efficiency\nwhile maintaining strong isolation, an operating system (OS) approach is\nneeded. This paper introduces LithOS, a first step toward a GPU OS. LithOS\nincludes the following new abstractions and mechanisms for efficient GPU\nresource management: (i) a novel TPC Scheduler that supports spatial scheduling\nat the granularity of individual TPCs, unlocking efficient TPC stealing between\nworkloads; (ii) transparent kernel atomization to reduce head-of-line blocking\nand enable dynamic resource reallocation mid-execution; (iii) a lightweight\nhardware right-sizing mechanism that determines the minimal TPC resources\nneeded per atom; and (iv) a transparent power management mechanism that reduces\npower consumption based on in-flight work behavior. We implement LithOS in Rust\nand evaluate its performance across extensive ML environments, comparing it to\nstate-of-the-art solutions from NVIDIA and prior research. For inference\nstacking, LithOS reduces tail latencies by 13x compared to MPS; compared to the\nbest SotA, it reduces tail latencies by 3x while improving aggregate throughput\nby 1.6x. In hybrid inference-training stacking, LithOS reduces tail latencies\nby 4.7x compared to MPS; compared to the best SotA, it reduces tail latencies\n1.18x while improving aggregate throughput by 1.35x. Finally, for a modest\nperformance hit under 4%, LithOS's right-sizing provides a quarter of GPU\ncapacity savings on average, while for a 7% hit, its power management yields a\nquarter of a GPU's energy savings. Overall, LithOS increases GPU efficiency,\nestablishing a foundation for future OS research on GPUs.", "published": "2025-04-21 22:21:39", "link": "http://arxiv.org/abs/2504.15465v1", "categories": ["cs.OS", "cs.LG"], "primary_category": "cs.OS"}
{"title": "Compton Form Factor Extraction using Quantum Deep Neural Networks", "abstract": "Extraction tests of Compton Form Factors are performed using pseudodata based\non experimental data from Deeply Virtual Compton Scattering experiments\nconducted at Jefferson Lab. The standard Belitsky, Kirchner, and Muller\nformalism at twist-two is employed, along with a fitting procedure designed to\nreduce model dependency similar to traditional local fits. The extraction of\nthe Compton Form Factors is performed using both Classical Deep Neural Networks\n(CDNNs) and Quantum Deep Neural Networks (QDNNs). Comparative studies reveal\nthat QDNNs outperform CDNNs for this application, demonstrating improved\npredictive accuracy and precision even for limited model complexity. The\nresults demonstrate the potential of QDNNs for future studies in which quantum\nalgorithms can be fully optimized.", "published": "2025-04-21 21:56:49", "link": "http://arxiv.org/abs/2504.15458v1", "categories": ["cs.LG", "nucl-th", "quant-ph"], "primary_category": "cs.LG"}
{"title": "Combating Toxic Language: A Review of LLM-Based Strategies for Software Engineering", "abstract": "Large Language Models (LLMs) have become integral to software engineering\n(SE), where they are increasingly used in development workflows. However, their\nwidespread use raises concerns about the presence and propagation of toxic\nlanguage--harmful or offensive content that can foster exclusionary\nenvironments. This paper provides a comprehensive review of recent research on\ntoxicity detection and mitigation, focusing on both SE-specific and\ngeneral-purpose datasets. We examine annotation and preprocessing techniques,\nassess detection methodologies, and evaluate mitigation strategies,\nparticularly those leveraging LLMs. Additionally, we conduct an ablation study\ndemonstrating the effectiveness of LLM-based rewriting for reducing toxicity.\nBy synthesizing existing work and identifying open challenges, this review\nhighlights key areas for future research to ensure the responsible deployment\nof LLMs in SE and beyond.", "published": "2025-04-21 21:09:33", "link": "http://arxiv.org/abs/2504.15439v1", "categories": ["cs.LG", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Post-Convergence Sim-to-Real Policy Transfer: A Principled Alternative to Cherry-Picking", "abstract": "Learning-based approaches, particularly reinforcement learning (RL), have\nbecome widely used for developing control policies for autonomous agents, such\nas locomotion policies for legged robots. RL training typically maximizes a\npredefined reward (or minimizes a corresponding cost/loss) by iteratively\noptimizing policies within a simulator. Starting from a randomly initialized\npolicy, the empirical expected reward follows a trajectory with an overall\nincreasing trend. While some policies become temporarily stuck in local optima,\na well-defined training process generally converges to a reward level with\nnoisy oscillations. However, selecting a policy for real-world deployment is\nrarely an analytical decision (i.e., simply choosing the one with the highest\nreward) and is instead often performed through trial and error. To improve\nsim-to-real transfer, most research focuses on the pre-convergence stage,\nemploying techniques such as domain randomization, multi-fidelity training,\nadversarial training, and architectural innovations. However, these methods do\nnot eliminate the inevitable convergence trajectory and noisy oscillations of\nrewards, leading to heuristic policy selection or cherry-picking. This paper\naddresses the post-convergence sim-to-real transfer problem by introducing a\nworst-case performance transference optimization approach, formulated as a\nconvex quadratic-constrained linear programming problem. Extensive experiments\ndemonstrate its effectiveness in transferring RL-based locomotion policies from\nsimulation to real-world laboratory tests.", "published": "2025-04-21 19:48:05", "link": "http://arxiv.org/abs/2504.15414v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Improving Learning to Optimize Using Parameter Symmetries", "abstract": "We analyze a learning-to-optimize (L2O) algorithm that exploits parameter\nspace symmetry to enhance optimization efficiency. Prior work has shown that\njointly learning symmetry transformations and local updates improves\nmeta-optimizer performance. Supporting this, our theoretical analysis\ndemonstrates that even without identifying the optimal group element, the\nmethod locally resembles Newton's method. We further provide an example where\nthe algorithm provably learns the correct symmetry transformation during\ntraining. To empirically evaluate L2O with teleportation, we introduce a\nbenchmark, analyze its success and failure cases, and show that enhancements\nlike momentum further improve performance. Our results highlight the potential\nof leveraging neural network parameter space symmetry to advance\nmeta-optimization.", "published": "2025-04-21 19:03:23", "link": "http://arxiv.org/abs/2504.15399v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Deep learning with missing data", "abstract": "In the context of multivariate nonparametric regression with missing\ncovariates, we propose Pattern Embedded Neural Networks (PENNs), which can be\napplied in conjunction with any existing imputation technique. In addition to a\nneural network trained on the imputed data, PENNs pass the vectors of\nobservation indicators through a second neural network to provide a compact\nrepresentation. The outputs are then combined in a third neural network to\nproduce final predictions. Our main theoretical result exploits an assumption\nthat the observation patterns can be partitioned into cells on which the Bayes\nregression function behaves similarly, and belongs to a compositional H\\\"older\nclass. It provides a finite-sample excess risk bound that holds for an\narbitrary missingness mechanism, and in combination with a complementary\nminimax lower bound, demonstrates that our PENN estimator attains in typical\ncases the minimax rate of convergence as if the cells of the partition were\nknown in advance, up to a poly-logarithmic factor in the sample size. Numerical\nexperiments on simulated, semi-synthetic and real data confirm that the PENN\nestimator consistently improves, often dramatically, on standard neural\nnetworks without pattern embedding. Code to reproduce our experiments, as well\nas a tutorial on how to apply our method, is publicly available.", "published": "2025-04-21 18:57:36", "link": "http://arxiv.org/abs/2504.15388v1", "categories": ["stat.ME", "cs.LG", "math.ST", "stat.ML", "stat.TH", "62C20, 62D10, 62G08"], "primary_category": "stat.ME"}
{"title": "Assessing Surrogate Heterogeneity in Real World Data Using Meta-Learners", "abstract": "Surrogate markers are most commonly studied within the context of randomized\nclinical trials. However, the need for alternative outcomes extends beyond\nthese settings and may be more pronounced in real-world public health and\nsocial science research, where randomized trials are often impractical.\nResearch on identifying surrogates in real-world non-randomized data is scarce,\nas available statistical approaches for evaluating surrogate markers tend to\nrely on the assumption that treatment is randomized. While the few methods that\nallow for non-randomized treatment/exposure appropriately handle confounding\nindividual characteristics, they do not offer a way to examine surrogate\nheterogeneity with respect to patient characteristics. In this paper, we\npropose a framework to assess surrogate heterogeneity in real-world, i.e.,\nnon-randomized, data and implement this framework using various meta-learners.\nOur approach allows us to quantify heterogeneity in surrogate strength with\nrespect to patient characteristics while accommodating confounders through the\nuse of flexible, off-the-shelf machine learning methods. In addition, we use\nour framework to identify individuals for whom the surrogate is a valid\nreplacement of the primary outcome. We examine the performance of our methods\nvia a simulation study and application to examine heterogeneity in the\nsurrogacy of hemoglobin A1c as a surrogate for fasting plasma glucose.", "published": "2025-04-21 18:54:48", "link": "http://arxiv.org/abs/2504.15386v1", "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "stat.ME"}
{"title": "FLARE: Feature-based Lightweight Aggregation for Robust Evaluation of IoT Intrusion Detection", "abstract": "The proliferation of Internet of Things (IoT) devices has expanded the attack\nsurface, necessitating efficient intrusion detection systems (IDSs) for network\nprotection. This paper presents FLARE, a feature-based lightweight aggregation\nfor robust evaluation of IoT intrusion detection to address the challenges of\nsecuring IoT environments through feature aggregation techniques. FLARE\nutilizes a multilayered processing approach, incorporating session, flow, and\ntime-based sliding-window data aggregation to analyze network behavior and\ncapture vital features from IoT network traffic data. We perform extensive\nevaluations on IoT data generated from our laboratory experimental setup to\nassess the effectiveness of the proposed aggregation technique. To classify\nattacks in IoT IDS, we employ four supervised learning models and two deep\nlearning models. We validate the performance of these models in terms of\naccuracy, precision, recall, and F1-score. Our results reveal that\nincorporating the FLARE aggregation technique as a foundational step in feature\nengineering, helps lay a structured representation, and enhances the\nperformance of complex end-to-end models, making it a crucial step in IoT IDS\npipeline. Our findings highlight the potential of FLARE as a valuable technique\nto improve performance and reduce computational costs of end-to-end IDS\nimplementations, thereby fostering more robust IoT intrusion detection systems.", "published": "2025-04-21 18:33:53", "link": "http://arxiv.org/abs/2504.15375v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Transferable Learning of Reaction Pathways from Geometric Priors", "abstract": "Identifying minimum-energy paths (MEPs) is crucial for understanding chemical\nreaction mechanisms but remains computationally demanding. We introduce MEPIN,\na scalable machine-learning method for efficiently predicting MEPs from\nreactant and product configurations, without relying on transition-state\ngeometries or pre-optimized reaction paths during training. The task is defined\nas predicting deviations from geometric interpolations along reaction\ncoordinates. We address this task with a continuous reaction path model based\non a symmetry-broken equivariant neural network that generates a flexible\nnumber of intermediate structures. The model is trained using an energy-based\nobjective, with efficiency enhanced by incorporating geometric priors from\ngeodesic interpolation as initial interpolations or pre-training objectives.\nOur approach generalizes across diverse chemical reactions and achieves\naccurate alignment with reference intrinsic reaction coordinates, as\ndemonstrated on various small molecule reactions and [3+2] cycloadditions. Our\nmethod enables the exploration of large chemical reaction spaces with\nefficient, data-driven predictions of reaction pathways.", "published": "2025-04-21 18:20:53", "link": "http://arxiv.org/abs/2504.15370v1", "categories": ["physics.chem-ph", "cs.LG"], "primary_category": "physics.chem-ph"}
{"title": "FedFetch: Faster Federated Learning with Adaptive Downstream Prefetching", "abstract": "Federated learning (FL) is a machine learning paradigm that facilitates\nmassively distributed model training with end-user data on edge devices\ndirected by a central server. However, the large number of heterogeneous\nclients in FL deployments leads to a communication bottleneck between the\nserver and the clients. This bottleneck is made worse by straggling clients,\nany one of which will further slow down training. To tackle these challenges,\nresearchers have proposed techniques like client sampling and update\ncompression. These techniques work well in isolation but combine poorly in the\ndownstream, server-to-client direction. This is because unselected clients have\noutdated local model states and need to synchronize these states with the\nserver first.\n  We introduce FedFetch, a strategy to mitigate the download time overhead\ncaused by combining client sampling and compression techniques. FedFetch\nachieves this with an efficient prefetch schedule for clients to prefetch model\nstates multiple rounds before a stated training round. We empirically show that\nadding FedFetch to communication efficient FL techniques reduces end-to-end\ntraining time by 1.26$\\times$ and download time by 4.49$\\times$ across\ncompression techniques with heterogeneous client settings. Our implementation\nis available at https://github.com/DistributedML/FedFetch", "published": "2025-04-21 18:17:05", "link": "http://arxiv.org/abs/2504.15366v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "On optimality and bounds for internal solutions generated from boundary data-driven Gramians", "abstract": "We consider the computation of internal solutions for a time domain plasma\nwave equation with unknown coefficients from the data obtained by sampling its\ntransfer function at the boundary. The computation is performed by transforming\nknown background snapshots using the Cholesky decomposition of the data-driven\nGramian. We show that this approximation is asymptotically close to the\nprojection of the true internal solution onto the subspace of background\nsnapshots. This allows us to derive a generally applicable bound for the error\nin the approximation of internal fields from boundary data for a time domain\nplasma wave equation with an unknown potential $q$. For general $q\\in\nL^\\infty$, we prove convergence of these data generated internal fields in one\ndimension for two examples. The first is for piecewise constant initial data\nand sampling $\\tau$ equal to the pulse width. The second is piecewise linear\ninitial data and sampling at half the pulse width. We show that in both cases\nthe data generated solutions converge in $L^2$ at order $\\sqrt{\\tau}$. We\npresent numerical experiments validating the result and the sharpness of this\nconvergence rate.", "published": "2025-04-21 19:31:14", "link": "http://arxiv.org/abs/2504.15407v1", "categories": ["math.NA", "cs.NA", "65M32, 78A46"], "primary_category": "math.NA"}
{"title": "Convergence-rate and error analysis of sectional-volume average method for the collisional breakage equation with multi-dimensional modelling", "abstract": "Recent literature reports two sectional techniques, the finite volume method\n[Das et al., 2020, SIAM J. Sci. Comput., 42(6): B1570-B1598] and the fixed\npivot technique [Kushwah et al., 2023, Commun. Nonlinear Sci. Numer. Simul.,\n121(37): 107244] to solve one-dimensional collision-induced nonlinear particle\nbreakage equation. It is observed that both the methods become inconsistent\nover random grids. Therefore, we propose a new birth modification strategy,\nwhere the newly born particles are proportionately allocated in three adjacent\ncells, depending upon the average volume in each cell. This modification\ntechnique improves the numerical model by making it consistent over random\ngrids. A detailed convergence and error analysis for this new scheme is studied\nover different possible choices of grids such as uniform, nonuniform,\nlocally-uniform, random and oscillatory grids. In addition, we have also\nidentified the conditions upon kernels for which the convergence rate increases\nsignificantly and the scheme achieves second order of convergence over uniform,\nnonuniform and locally-uniform grids. The enhanced order of accuracy will\nenable the new model to be easily coupled with CFD-modules. Another significant\nadvancement in the literature is done by extending the discrete model for\ntwo-dimensional equation over rectangular grids.", "published": "2025-04-21 18:13:11", "link": "http://arxiv.org/abs/2504.15365v1", "categories": ["math.NA", "cs.NA", "Primary: 34A12, 35Q70, 45K05, Secondary: 47J35"], "primary_category": "math.NA"}
{"title": "Randomized Proper Orthogonal Decomposition for data-driven reduced order modeling of a two-layer quasi-geostrophic ocean model", "abstract": "The two-layer quasi-geostrophic equations (2QGE) serve as a simplified model\nfor simulating wind-driven, stratified ocean flows. However, their numerical\nsimulation remains computationally expensive due to the need for\nhigh-resolution meshes to capture a wide range of turbulent scales. This\nbecomes especially problematic when several simulations need to be run because\nof, e.g., uncertainty in the parameter settings. To address this challenge, we\npropose a data-driven reduced order model (ROM) for the 2QGE that leverages\nrandomized proper orthogonal decomposition (rPOD) and long short-term memory\n(LSTM) networks. To efficiently generate the snapshot data required for model\nconstruction, we apply a nonlinear filtering stabilization technique that\nallows for the use of larger mesh sizes compared to a direct numerical\nsimulations (DNS). Thanks to the use of rPOD to extract the dominant modes from\nthe snapshot matrices, we achieve up to 700 times speedup over the use of\ndeterministic POD. LSTM networks are trained with the modal coefficients\nassociated with the snapshots to enable the prediction of the time- and\nparameter-dependent modal coefficients during the online phase, which is\nhundreds of thousands of time faster than a DNS. We assess the accuracy and\nefficiency of our rPOD-LSTM ROM through an extension of a well-known benchmark\ncalled double-gyre wind forcing test. The dimension of the parameter space in\nthis test is increased from two to four.", "published": "2025-04-21 18:00:27", "link": "http://arxiv.org/abs/2504.15350v1", "categories": ["math.NA", "cs.NA", "physics.flu-dyn"], "primary_category": "math.NA"}
{"title": "Bayesian Federated Learning for Continual Training", "abstract": "Bayesian Federated Learning (BFL) enables uncertainty quantification and\nrobust adaptation in distributed learning. In contrast to the frequentist\napproach, it estimates the posterior distribution of a global model, offering\ninsights into model reliability. However, current BFL methods neglect continual\nlearning challenges in dynamic environments where data distributions shift over\ntime. We propose a continual BFL framework applied to human sensing with radar\ndata collected over several days. Using Stochastic Gradient Langevin Dynamics\n(SGLD), our approach sequentially updates the model, leveraging past posteriors\nto construct the prior for the new tasks. We assess the accuracy, the expected\ncalibration error (ECE) and the convergence speed of our approach against\nseveral baselines. Results highlight the effectiveness of continual Bayesian\nupdates in preserving knowledge and adapting to evolving data.", "published": "2025-04-21 14:33:04", "link": "http://arxiv.org/abs/2504.15328v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Significativity Indices for Agreement Values", "abstract": "Agreement measures, such as Cohen's kappa or intraclass correlation, gauge\nthe matching between two or more classifiers. They are used in a wide range of\ncontexts from medicine, where they evaluate the effectiveness of medical\ntreatments and clinical trials, to artificial intelligence, where they can\nquantify the approximation due to the reduction of a classifier. The\nconsistency of different classifiers to a golden standard can be compared\nsimply by using the order induced by their agreement measure with respect to\nthe golden standard itself. Nevertheless, labelling an approach as good or bad\nexclusively by using the value of an agreement measure requires a scale or a\nsignificativity index. Some quality scales have been proposed in the literature\nfor Cohen's kappa, but they are mainly naive, and their boundaries are\narbitrary. This work proposes a general approach to evaluate the\nsignificativity of any agreement value between two classifiers and introduces\ntwo significativity indices: one dealing with finite data sets, the other one\nhandling classification probability distributions. Moreover, this manuscript\nconsiders the computational issues of evaluating such indices and identifies\nsome efficient algorithms to evaluate them.", "published": "2025-04-21 09:47:53", "link": "http://arxiv.org/abs/2504.15325v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Underwater Multi-Wavelength Optical Links With Blue Targets and Constraints: Opportunities and Challenges", "abstract": "Underwater optical wireless technologies offer multiple advantages over the\nacoustic technology. Acoustic signals, for instance, are susceptible to noise\nfrom marine sources due to marine life and human activities. This is not the\ncase with optical signals. However, absorption and scattering significantly\nattenuate optical signals. This limits the communication range and requires\nhigher transmission power or more sensitive receivers to detect transmitted\nlight. Therefore, it is necessary to design underwater optical systems with a\nhigher transmission rate and reduced attenuation. To this end, we introduce a\nframework for designing optical signaling constellations employing\nmulti-wavelength light sources to account for the transmission distance and\nachievable rate. In particular, we redefine the color-shift keying (CSK)\nconstraint region to target blue light and adapt to marine environments. We\ndiscuss an example of 4-point underwater CSK. The corresponding analytical\nresults demonstrate the trade-offs between the symbol error probability,\nachievable rate, and transmission range of the proposed scheme.", "published": "2025-04-21 20:50:08", "link": "http://arxiv.org/abs/2504.15430v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "314-GBaud Single-Wavelength Signaling Generated All-Electronically by a 158-GHz Digital-Band-Interleaved DAC", "abstract": "We demonstrate an all-electronic generation of 314-GBaud PS 8-ASK signals by\na 158-GHz digital-band-interleaved DAC. The signals drive a thin-film LiNbO3\nmodulator that achieves over 300 GBaud single-wavelength Nyquist signaling\nwithout optical equalization.", "published": "2025-04-21 17:47:44", "link": "http://arxiv.org/abs/2504.15331v1", "categories": ["physics.optics", "eess.SP"], "primary_category": "physics.optics"}
{"title": "A Short Proof of Coding Theorems for Reed-Muller Codes Under a Mild Assumption", "abstract": "In this paper, by treating Reed-Muller (RM) codes as a special class of\nlow-density parity-check (LDPC) codes and assuming that sub-blocks of the\nparity-check matrix are randomly interleaved to each other as Gallager's codes,\nwe present a short proof that RM codes are entropy-achieving as source coding\nfor Bernoulli sources and capacity-achieving as channel coding for binary\nmemoryless symmetric (BMS) channels, also known as memoryless binary-input\noutput-symmetric (BIOS) channels, in terms of bit error rate (BER) under\nmaximum-likelihood (ML) decoding.", "published": "2025-04-21 03:54:27", "link": "http://arxiv.org/abs/2504.14842v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Expected Free Energy-based Planning as Variational Inference", "abstract": "We address the problem of planning under uncertainty, where an agent must\nchoose actions that not only achieve desired outcomes but also reduce\nuncertainty. Traditional methods often treat exploration and exploitation as\nseparate objectives, lacking a unified inferential foundation. Active\ninference, grounded in the Free Energy Principle, provides such a foundation by\nminimizing Expected Free Energy (EFE), a cost function that combines utility\nwith epistemic drives, such as ambiguity resolution and novelty seeking.\nHowever, the computational burden of EFE minimization had remained a\nsignificant obstacle to its scalability. In this paper, we show that EFE-based\nplanning arises naturally from minimizing a variational free energy functional\non a generative model augmented with preference and epistemic priors. This\nresult reinforces theoretical consistency with the Free Energy Principle by\ncasting planning under uncertainty itself as a form of variational inference.\nOur formulation yields policies that jointly support goal achievement and\ninformation gain, while incorporating a complexity term that accounts for\nbounded computational resources. This unifying framework connects and extends\nexisting methods, enabling scalable, resource-aware implementations of active\ninference agents.", "published": "2025-04-21 07:09:05", "link": "http://arxiv.org/abs/2504.14898v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
