{"title": "Transfer Topic Modeling with Ease and Scalability", "abstract": "The increasing volume of short texts generated on social media sites, such as\nTwitter or Facebook, creates a great demand for effective and efficient topic\nmodeling approaches. While latent Dirichlet allocation (LDA) can be applied, it\nis not optimal due to its weakness in handling short texts with fast-changing\ntopics and scalability concerns. In this paper, we propose a transfer learning\napproach that utilizes abundant labeled documents from other domains (such as\nYahoo! News or Wikipedia) to improve topic modeling, with better model fitting\nand result interpretation. Specifically, we develop Transfer Hierarchical LDA\n(thLDA) model, which incorporates the label information from other domains via\ninformative priors. In addition, we develop a parallel implementation of our\nmodel for large-scale applications. We demonstrate the effectiveness of our\nthLDA model on both a microblogging dataset and standard text collections\nincluding AP and RCV1 datasets.", "published": "2013-01-24 02:02:13", "link": "http://arxiv.org/abs/1301.5686v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
