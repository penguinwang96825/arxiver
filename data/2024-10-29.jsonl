{"title": "Fast Deep Hedging with Second-Order Optimization", "abstract": "Hedging exotic options in presence of market frictions is an important risk\nmanagement task. Deep hedging can solve such hedging problems by training\nneural network policies in realistic simulated markets. Training these neural\nnetworks may be delicate and suffer from slow convergence, particularly for\noptions with long maturities and complex sensitivities to market parameters. To\naddress this, we propose a second-order optimization scheme for deep hedging.\nWe leverage pathwise differentiability to construct a curvature matrix, which\nwe approximate as block-diagonal and Kronecker-factored to efficiently\nprecondition gradients. We evaluate our method on a challenging and practically\nimportant problem: hedging a cliquet option on a stock with stochastic\nvolatility by trading in the spot and vanilla options. We find that our\nsecond-order scheme can optimize the policy in 1/4 of the number of steps that\nstandard adaptive moment-based optimization takes.", "published": "2024-10-29 22:17:52", "link": "http://arxiv.org/abs/2410.22568v1", "categories": ["q-fin.RM", "cs.LG", "q-fin.CP"], "primary_category": "q-fin.RM"}
{"title": "Evaluating utility in synthetic banking microdata applications", "abstract": "Financial regulators such as central banks collect vast amounts of data, but\naccess to the resulting fine-grained banking microdata is severely restricted\nby banking secrecy laws. Recent developments have resulted in mechanisms that\ngenerate faithful synthetic data, but current evaluation frameworks lack a\nfocus on the specific challenges of banking institutions and microdata. We\ndevelop a framework that considers the utility and privacy requirements of\nregulators, and apply this to financial usage indices, term deposit yield\ncurves, and credit card transition matrices. Using the Central Bank of\nParaguay's data, we provide the first implementation of synthetic banking\nmicrodata using a central bank's collected information, with the resulting\nsynthetic datasets for all three domain applications being publicly available\nand featuring information not yet released in statistical disclosure. We find\nthat applications less susceptible to post-processing information loss, which\nare based on frequency tables, are particularly suited for this approach, and\nthat marginal-based inference mechanisms to outperform generative adversarial\nnetwork models for these applications. Our results demonstrate that synthetic\ndata generation is a promising privacy-enhancing technology for financial\nregulators seeking to complement their statistical disclosure, while\nhighlighting the crucial role of evaluating such endeavors in terms of utility\nand privacy requirements.", "published": "2024-10-29 20:20:05", "link": "http://arxiv.org/abs/2410.22519v1", "categories": ["q-fin.CP", "cs.LG", "90B90, 91B82, 62P20"], "primary_category": "q-fin.CP"}
{"title": "Schur Complementary Allocation: A Unification of Hierarchical Risk Parity and Minimum Variance Portfolios", "abstract": "Despite many attempts to make optimization-based portfolio construction in\nthe spirit of Markowitz robust and approachable, it is far from universally\nadopted. Meanwhile, the collection of more heuristic divide-and-conquer\napproaches was revitalized by Lopez de Prado where Hierarchical Risk Parity\n(HRP) was introduced. This paper reveals the hidden connection between these\nseemingly disparate approaches.", "published": "2024-10-29 22:16:40", "link": "http://arxiv.org/abs/2411.05807v1", "categories": ["q-fin.PM", "q-fin.MF", "91G10", "J.4"], "primary_category": "q-fin.PM"}
{"title": "Applications of the Second-Order Esscher Pricing in Risk Management", "abstract": "This paper explores the application and significance of the second-order\nEsscher pricing model in option pricing and risk management. We split the study\ninto two main parts. First, we focus on the constant jump diffusion (CJD) case,\nanalyzing the behavior of option prices as a function of the second-order\nparameter and the resulting pricing intervals. Using real data, we perform a\ndynamic delta hedging strategy, illustrating how risk managers can determine an\ninterval of value-at-risks (VaR) and expected shortfalls (ES), granting\nflexibility in pricing based on additional information. We compare our pricing\ninterval to other jump-diffusion models, showing its comprehensive risk factor\nincorporation. The second part extends the second-order Esscher pricing to more\ncomplex models, including the Merton jump-diffusion, Kou's Double Exponential\njump-diffusion, and the Variance Gamma model. We derive option prices using the\nfast Fourier transform (FFT) method and provide practical formulas for European\ncall and put options under these models.", "published": "2024-10-29 01:31:23", "link": "http://arxiv.org/abs/2410.21649v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "The VIX as Stochastic Volatility for Corporate Bonds", "abstract": "Classic stochastic volatility models assume volatility is unobservable. We\nuse the Volatility Index: S&P 500 VIX to observe it, to easier fit the model.\nWe apply it to corporate bonds. We fit autoregression for corporate rates and\nfor risk spreads between these rates and Treasury rates. Next, we divide\nresiduals by VIX. Our main idea is such division makes residuals closer to the\nideal case of a Gaussian white noise. This is remarkable, since these residuals\nand VIX come from separate market segments. Similarly, we model corporate bond\nreturns as a linear function of rates and rate changes. Our article has two\nmain parts: Moody's AAA and BAA spreads; Bank of America investment-grade and\nhigh-yield rates, spreads, and returns. We analyze long-term stability of these\nmodels.", "published": "2024-10-29 19:41:43", "link": "http://arxiv.org/abs/2410.22498v5", "categories": ["q-fin.ST", "stat.AP", "62J05, 62M10, 91B70, 91G30"], "primary_category": "q-fin.ST"}
{"title": "Log Heston Model for Monthly Average VIX", "abstract": "We model time series of VIX (monthly average) and monthly stock index\nreturns. We use log-Heston model: logarithm of VIX is modeled as an\nautoregression of order 1. Our main insight is that normalizing monthly stock\nindex returns (dividing them by VIX) makes them much closer to independent\nidentically distributed Gaussian. The resulting model is mean-reverting, and\nthe innovations are non-Gaussian. The combined stochastic volatility model fits\nwell, and captures Pareto-like tails of real-world stock market returns. This\nworks for small and large stock indices, for both price and total returns.", "published": "2024-10-29 19:04:37", "link": "http://arxiv.org/abs/2410.22471v1", "categories": ["q-fin.ST", "stat.AP", "60E99, 60G50, 62E99, 62J05, 62M10, 62P05, 91G15"], "primary_category": "q-fin.ST"}
{"title": "Joint Estimation of Conditional Mean and Covariance for Unbalanced Panels", "abstract": "We develop a nonparametric, kernel-based joint estimator for conditional mean\nand covariance matrices in large and unbalanced panels. The estimator is\nsupported by rigorous consistency results and finite-sample guarantees,\nensuring its reliability for empirical applications. We apply it to an\nextensive panel of monthly US stock excess returns from 1962 to 2021, using\nmacroeconomic and firm-specific covariates as conditioning variables. The\nestimator effectively captures time-varying cross-sectional dependencies,\ndemonstrating robust statistical and economic performance. We find that\nidiosyncratic risk explains, on average, more than 75% of the cross-sectional\nvariance.", "published": "2024-10-29 08:42:22", "link": "http://arxiv.org/abs/2410.21858v5", "categories": ["stat.ME", "cs.LG", "q-fin.ST", "stat.ML", "(primary) 62G05 (secondary) 62G20, 46E40, 46E22"], "primary_category": "stat.ME"}
{"title": "Robust Graph Neural Networks for Stability Analysis in Dynamic Networks", "abstract": "In the current context of accelerated globalization and digitalization, the\ncomplexity and uncertainty of financial markets are increasing, and the\nidentification and prevention of economic risks have become a key link in\nmaintaining the stability of the financial system. Traditional risk\nidentification methods often have limitations because they are difficult to\ncope with the multi-level and dynamically changing complex relationships in\nfinancial networks. With the rapid development of financial technology, graph\nneural network (GNN) technology, as an emerging deep learning method, has\ngradually shown great potential in the field of financial risk management. GNN\ncan map transaction behaviors, financial institutions, individuals, and their\ninteractive relationships in financial networks into graph structures, and\neffectively capture potential patterns and abnormal signals in financial data\nthrough embedded representation learning. Using this technology, financial\ninstitutions can extract valuable information from complex transaction\nnetworks, identify hidden dangers or abnormal behaviors that may cause systemic\nrisks in a timely manner, optimize decision-making processes, and improve the\naccuracy of risk warnings. This paper explores the economic risk identification\nalgorithm based on the GNN algorithm, aiming to provide financial institutions\nand regulators with more intelligent technical tools to help maintain the\nsecurity and stability of the financial market. Improving the efficiency of\neconomic risk identification through innovative technical means is expected to\nfurther enhance the risk resistance of the financial system and lay the\nfoundation for building a robust global financial system.", "published": "2024-10-29 06:11:36", "link": "http://arxiv.org/abs/2411.11848v1", "categories": ["q-fin.ST", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "FinVision: A Multi-Agent Framework for Stock Market Prediction", "abstract": "Financial trading has been a challenging task, as it requires the integration\nof vast amounts of data from various modalities. Traditional deep learning and\nreinforcement learning methods require large training data and often involve\nencoding various data types into numerical formats for model input, which\nlimits the explainability of model behavior. Recently, LLM-based agents have\ndemonstrated remarkable advancements in handling multi-modal data, enabling\nthem to execute complex, multi-step decision-making tasks while providing\ninsights into their thought processes. This research introduces a multi-modal\nmulti-agent system designed specifically for financial trading tasks. Our\nframework employs a team of specialized LLM-based agents, each adept at\nprocessing and interpreting various forms of financial data, such as textual\nnews reports, candlestick charts, and trading signal charts. A key feature of\nour approach is the integration of a reflection module, which conducts analyses\nof historical trading signals and their outcomes. This reflective process is\ninstrumental in enhancing the decision-making capabilities of the system for\nfuture trading scenarios. Furthermore, the ablation studies indicate that the\nvisual reflection module plays a crucial role in enhancing the decision-making\ncapabilities of our framework.", "published": "2024-10-29 06:02:28", "link": "http://arxiv.org/abs/2411.08899v1", "categories": ["q-fin.TR", "cs.AI"], "primary_category": "q-fin.TR"}
{"title": "Let's Be Self-generated via Step by Step: A Curriculum Learning Approach\n  to Automated Reasoning with Large Language Models", "abstract": "While Chain of Thought (CoT) prompting approaches have significantly\nconsolidated the reasoning capabilities of large language models (LLMs), they\nstill face limitations that require extensive human effort or have performance\nneeds to be improved. Existing endeavors have focused on bridging these gaps;\nhowever, these approaches either hinge on external data and cannot completely\neliminate manual effort, or they fall short in effectively directing LLMs to\ngenerate high-quality exemplary prompts. To address the said pitfalls, we\npropose a novel prompt approach for automatic reasoning named \\textbf{LBS3},\ninspired by curriculum learning which better reflects human learning habits.\nSpecifically, LBS3 initially steers LLMs to recall easy-to-hard proxy queries\nthat are pertinent to the target query. Following this, it invokes a\nprogressive strategy that utilizes exemplary prompts stemmed from easy-proxy\nqueries to direct LLMs in solving hard-proxy queries, enabling the high-quality\nof the proxy solutions. Finally, our extensive experiments in various\nreasoning-intensive tasks with varying open- and closed-source LLMs show that\nLBS3 achieves strongly competitive performance compared to the SOTA baselines.", "published": "2024-10-29 04:28:49", "link": "http://arxiv.org/abs/2410.21728v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RELATE: A Modern Processing Platform for Romanian Language", "abstract": "This paper presents the design and evolution of the RELATE platform. It\nprovides a high-performance environment for natural language processing\nactivities, specially constructed for Romanian language. Initially developed\nfor text processing, it has been recently updated to integrate audio processing\ntools. Technical details are provided with regard to core components. We\nfurther present different usage scenarios, derived from actual use in national\nand international research projects, thus demonstrating that RELATE is a\nmature, modern, state-of-the-art platform for processing Romanian language\ncorpora. Finally, we present very recent developments including bimodal (text\nand audio) features available within the platform.", "published": "2024-10-29 06:33:38", "link": "http://arxiv.org/abs/2410.21778v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging LLMs for Hypothetical Deduction in Logical Inference: A\n  Neuro-Symbolic Approach", "abstract": "Large Language Models (LLMs) have exhibited remarkable potential across a\nwide array of reasoning tasks, including logical reasoning. Although massive\nefforts have been made to empower the logical reasoning ability of LLMs via\nexternal logical symbolic solvers, crucial challenges of the poor\ngeneralization ability to questions with different features and inevitable\nquestion information loss of symbolic solver-driven approaches remain\nunresolved. To mitigate these issues, we introduce LINA, a LLM-driven\nneuro-symbolic approach for faithful logical reasoning. By enabling an LLM to\nautonomously perform the transition from propositional logic extraction to\nsophisticated logical reasoning, LINA not only bolsters the resilience of the\nreasoning process but also eliminates the dependency on external solvers.\nAdditionally, through its adoption of a hypothetical-deductive reasoning\nparadigm, LINA effectively circumvents the expansive search space challenge\nthat plagues traditional forward reasoning methods. Empirical evaluations\ndemonstrate that LINA substantially outperforms both established propositional\nlogic frameworks and conventional prompting techniques across a spectrum of\nfive logical reasoning tasks. Specifically, LINA achieves an improvement of\n24.34% over LINC on the FOLIO dataset, while also surpassing prompting\nstrategies like CoT and CoT-SC by up to 24.02%. Our code is available at\nhttps://github.com/wufeiwuwoshihua/nshy.", "published": "2024-10-29 06:38:46", "link": "http://arxiv.org/abs/2410.21779v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Adversarial Attacks through Chain of Thought", "abstract": "Large language models (LLMs) have demonstrated impressive performance across\nvarious domains but remain susceptible to safety concerns. Prior research\nindicates that gradient-based adversarial attacks are particularly effective\nagainst aligned LLMs and the chain of thought (CoT) prompting can elicit\ndesired answers through step-by-step reasoning. This paper proposes enhancing\nthe robustness of adversarial attacks on aligned LLMs by integrating CoT\nprompts with the greedy coordinate gradient (GCG) technique. Using CoT triggers\ninstead of affirmative targets stimulates the reasoning abilities of backend\nLLMs, thereby improving the transferability and universality of adversarial\nattacks. We conducted an ablation study comparing our CoT-GCG approach with\nAmazon Web Services auto-cot. Results revealed our approach outperformed both\nthe baseline GCG attack and CoT prompting. Additionally, we used Llama Guard to\nevaluate potentially harmful interactions, providing a more objective risk\nassessment of entire conversations compared to matching outputs to rejection\nphrases. The code of this paper is available at\nhttps://github.com/sujingbo0217/CS222W24-LLM-Attack.", "published": "2024-10-29 06:54:00", "link": "http://arxiv.org/abs/2410.21791v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SimSiam Naming Game: A Unified Approach for Representation Learning and\n  Emergent Communication", "abstract": "Emergent communication, driven by generative models, enables agents to\ndevelop a shared language for describing their individual views of the same\nobjects through interactions. Meanwhile, self-supervised learning (SSL),\nparticularly SimSiam, uses discriminative representation learning to make\nrepresentations of augmented views of the same data point closer in the\nrepresentation space. Building on the prior work of VI-SimSiam, which\nincorporates a generative and Bayesian perspective into the SimSiam framework\nvia variational inference (VI) interpretation, we propose SimSiam+VAE, a\nunified approach for both representation learning and emergent communication.\nSimSiam+VAE integrates a variational autoencoder (VAE) into the predictor of\nthe SimSiam network to enhance representation learning and capture uncertainty.\nExperimental results show that SimSiam+VAE outperforms both SimSiam and\nVI-SimSiam. We further extend this model into a communication framework called\nthe SimSiam Naming Game (SSNG), which applies the generative and Bayesian\napproach based on VI to develop internal representations and emergent language,\nwhile utilizing the discriminative process of SimSiam to facilitate mutual\nunderstanding between agents. In experiments with established models, despite\nthe dynamic alternation of agent roles during interactions, SSNG demonstrates\ncomparable performance to the referential game and slightly outperforms the\nMetropolis-Hastings naming game.", "published": "2024-10-29 07:16:20", "link": "http://arxiv.org/abs/2410.21803v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Preference Bias in LLM-as-a-Judge", "abstract": "Automated evaluation leveraging large language models (LLMs), commonly\nreferred to as LLM evaluators or LLM-as-a-judge, has been widely used in\nmeasuring the performance of dialogue systems. However, the self-preference\nbias in LLMs has posed significant risks, including promoting specific styles\nor policies intrinsic to the LLMs. Despite the importance of this issue, there\nis a lack of established methods to measure the self-preference bias\nquantitatively, and its underlying causes are poorly understood. In this paper,\nwe introduce a novel quantitative metric to measure the self-preference bias.\nOur experimental results demonstrate that GPT-4 exhibits a significant degree\nof self-preference bias. To explore the causes, we hypothesize that LLMs may\nfavor outputs that are more familiar to them, as indicated by lower perplexity.\nWe analyze the relationship between LLM evaluations and the perplexities of\noutputs. Our findings reveal that LLMs assign significantly higher evaluations\nto outputs with lower perplexity than human evaluators, regardless of whether\nthe outputs were self-generated. This suggests that the essence of the bias\nlies in perplexity and that the self-preference bias exists because LLMs prefer\ntexts more familiar to them.", "published": "2024-10-29 07:42:18", "link": "http://arxiv.org/abs/2410.21819v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-aspect Depression Severity Assessment via Inductive Dialogue\n  System", "abstract": "With the advancement of chatbots and the growing demand for automatic\ndepression detection, identifying depression in patient conversations has\ngained more attention. However, prior methods often assess depression in a\nbinary way or only a single score without diverse feedback and lack focus on\nenhancing dialogue responses. In this paper, we present a novel task of\nmulti-aspect depression severity assessment via an inductive dialogue system\n(MaDSA), evaluating a patient's depression level on multiple criteria by\nincorporating an assessment-aided response generation. Further, we propose a\nfoundational system for MaDSA, which induces psychological dialogue responses\nwith an auxiliary emotion classification task within a hierarchical severity\nassessment structure. We synthesize the conversational dataset annotated with\neight aspects of depression severity alongside emotion labels, proven robust\nvia human evaluations. Experimental results show potential for our preliminary\nwork on MaDSA.", "published": "2024-10-29 08:00:08", "link": "http://arxiv.org/abs/2410.21836v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Beamforming and Speaker-Attributed ASR for Real Distant-Microphone\n  Meeting Transcription", "abstract": "Distant-microphone meeting transcription is a challenging task.\nState-of-the-art end-to-end speaker-attributed automatic speech recognition\n(SA-ASR) architectures lack a multichannel noise and reverberation reduction\nfront-end, which limits their performance. In this paper, we introduce a joint\nbeamforming and SA-ASR approach for real meeting transcription. We first\ndescribe a data alignment and augmentation method to pretrain a neural\nbeamformer on real meeting data. We then compare fixed, hybrid, and fully\nneural beamformers as front-ends to the SA-ASR model. Finally, we jointly\noptimize the fully neural beamformer and the SA-ASR model. Experiments on the\nreal AMI corpus show that,while state-of-the-art multi-frame cross-channel\nattention based channel fusion fails to improve ASR performance, fine-tuning\nSA-ASR on the fixed beamformer's output and jointly fine-tuning SA-ASR with the\nneural beamformer reduce the word error rate by 8% and 9% relative,\nrespectively.", "published": "2024-10-29 08:17:31", "link": "http://arxiv.org/abs/2410.21849v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving In-Context Learning with Small Language Model Ensembles", "abstract": "Large language models (LLMs) have shown impressive capabilities across\nvarious tasks, but their performance on domain-specific tasks remains limited.\nWhile methods like retrieval augmented generation and fine-tuning can help to\naddress this, they require significant resources. In-context learning (ICL) is\na cheap and efficient alternative but cannot match the accuracies of advanced\nmethods. We present Ensemble SuperICL, a novel approach that enhances ICL by\nleveraging the expertise of multiple fine-tuned small language models (SLMs).\nEnsemble SuperICL achieves state of the art (SoTA) results on several natural\nlanguage understanding benchmarks. Additionally, we test it on a medical-domain\nlabelling task and showcase its practicality by using off-the-shelf SLMs\nfine-tuned on a general language task, achieving superior accuracy in\nlarge-scale data labelling compared to all baselines. Finally, we conduct an\nablation study and sensitivity analyses to elucidate the underlying mechanism\nof Ensemble SuperICL. Our research contributes to the growing demand for\nefficient domain specialisation methods in LLMs, offering a cheap and effective\nmethod for practitioners.", "published": "2024-10-29 09:02:37", "link": "http://arxiv.org/abs/2410.21868v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SG-Bench: Evaluating LLM Safety Generalization Across Diverse Tasks and\n  Prompt Types", "abstract": "Ensuring the safety of large language model (LLM) applications is essential\nfor developing trustworthy artificial intelligence. Current LLM safety\nbenchmarks have two limitations. First, they focus solely on either\ndiscriminative or generative evaluation paradigms while ignoring their\ninterconnection. Second, they rely on standardized inputs, overlooking the\neffects of widespread prompting techniques, such as system prompts, few-shot\ndemonstrations, and chain-of-thought prompting. To overcome these issues, we\ndeveloped SG-Bench, a novel benchmark to assess the generalization of LLM\nsafety across various tasks and prompt types. This benchmark integrates both\ngenerative and discriminative evaluation tasks and includes extended data to\nexamine the impact of prompt engineering and jailbreak on LLM safety. Our\nassessment of 3 advanced proprietary LLMs and 10 open-source LLMs with the\nbenchmark reveals that most LLMs perform worse on discriminative tasks than\ngenerative ones, and are highly susceptible to prompts, indicating poor\ngeneralization in safety alignment. We also explain these findings\nquantitatively and qualitatively to provide insights for future research.", "published": "2024-10-29 11:47:01", "link": "http://arxiv.org/abs/2410.21965v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Not All Languages are Equal: Insights into Multilingual\n  Retrieval-Augmented Generation", "abstract": "RALMs (Retrieval-Augmented Language Models) broaden their knowledge scope by\nincorporating external textual resources. However, the multilingual nature of\nglobal knowledge necessitates RALMs to handle diverse languages, a topic that\nhas received limited research focus. In this work, we propose\n\\textit{Futurepedia}, a carefully crafted benchmark containing parallel texts\nacross eight representative languages. We evaluate six multilingual RALMs using\nour benchmark to explore the challenges of multilingual RALMs. Experimental\nresults reveal linguistic inequalities: 1) high-resource languages stand out in\nMonolingual Knowledge Extraction; 2) Indo-European languages lead RALMs to\nprovide answers directly from documents, alleviating the challenge of\nexpressing answers across languages; 3) English benefits from RALMs' selection\nbias and speaks louder in multilingual knowledge selection. Based on these\nfindings, we offer advice for improving multilingual Retrieval Augmented\nGeneration. For monolingual knowledge extraction, careful attention must be\npaid to cascading errors from translating low-resource languages into\nhigh-resource ones. In cross-lingual knowledge transfer, encouraging RALMs to\nprovide answers within documents in different languages can improve transfer\nperformance. For multilingual knowledge selection, incorporating more\nnon-English documents and repositioning English documents can help mitigate\nRALMs' selection bias. Through comprehensive experiments, we underscore the\ncomplexities inherent in multilingual RALMs and offer valuable insights for\nfuture research.", "published": "2024-10-29 11:53:19", "link": "http://arxiv.org/abs/2410.21970v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distinguishing Ignorance from Error in LLM Hallucinations", "abstract": "Large language models (LLMs) are susceptible to hallucinations -- factually\nincorrect outputs -- leading to a large body of work on detecting and\nmitigating such cases. We argue that it is important to distinguish between two\ntypes of hallucinations: ones where the model does not hold the correct answer\nin its parameters, which we term HK-, and ones where the model answers\nincorrectly despite having the required knowledge, termed HK+. We first find\nthat HK+ hallucinations are prevalent and occur across models and datasets.\nThen, we demonstrate that distinguishing between these two cases is beneficial\nfor mitigating hallucinations. Importantly, we show that different models\nhallucinate on different examples, which motivates constructing model-specific\nhallucination datasets for training detectors. Overall, our findings draw\nattention to classifying types of hallucinations and provide means to handle\nthem more effectively. The code is available at\nhttps://github.com/technion-cs-nlp/hallucination-mitigation .", "published": "2024-10-29 14:31:33", "link": "http://arxiv.org/abs/2410.22071v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Choosy Babies Need One Coach: Inducing Mode-Seeking Behavior in\n  BabyLlama with Reverse KL Divergence", "abstract": "This study presents our submission to the Strict-Small Track of the 2nd\nBabyLM Challenge. We use a teacher-student distillation setup with the\nBabyLLaMa model (Timiryasov and Tastet, 2023) as a backbone. To make the\nstudent's learning process more focused, we replace the objective function with\na reverse Kullback-Leibler divergence, known to cause mode-seeking (rather than\nmode-averaging) behaviour in computational learners. We further experiment with\nhaving a single teacher (instead of an ensemble of two teachers) and implement\nadditional optimization strategies to improve the distillation process. Our\nexperiments show that under reverse KL divergence, a single-teacher model often\noutperforms or matches multiple-teacher models across most tasks. Additionally,\nincorporating advanced optimization techniques further enhances model\nperformance, demonstrating the effectiveness and robustness of our proposed\napproach. These findings support our idea that \"choosy babies need one coach\".", "published": "2024-10-29 14:36:50", "link": "http://arxiv.org/abs/2410.22081v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AmpleGCG-Plus: A Strong Generative Model of Adversarial Suffixes to\n  Jailbreak LLMs with Higher Success Rates in Fewer Attempts", "abstract": "Although large language models (LLMs) are typically aligned, they remain\nvulnerable to jailbreaking through either carefully crafted prompts in natural\nlanguage or, interestingly, gibberish adversarial suffixes. However, gibberish\ntokens have received relatively less attention despite their success in\nattacking aligned LLMs. Recent work, AmpleGCG~\\citep{liao2024amplegcg},\ndemonstrates that a generative model can quickly produce numerous customizable\ngibberish adversarial suffixes for any harmful query, exposing a range of\nalignment gaps in out-of-distribution (OOD) language spaces. To bring more\nattention to this area, we introduce AmpleGCG-Plus, an enhanced version that\nachieves better performance in fewer attempts. Through a series of exploratory\nexperiments, we identify several training strategies to improve the learning of\ngibberish suffixes. Our results, verified under a strict evaluation setting,\nshow that it outperforms AmpleGCG on both open-weight and closed-source models,\nachieving increases in attack success rate (ASR) of up to 17\\% in the white-box\nsetting against Llama-2-7B-chat, and more than tripling ASR in the black-box\nsetting against GPT-4. Notably, AmpleGCG-Plus jailbreaks the newer GPT-4o\nseries of models at similar rates to GPT-4, and, uncovers vulnerabilities\nagainst the recently proposed circuit breakers defense. We publicly release\nAmpleGCG-Plus along with our collected training datasets.", "published": "2024-10-29 15:40:07", "link": "http://arxiv.org/abs/2410.22143v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking LLM Guardrails in Handling Multilingual Toxicity", "abstract": "With the ubiquity of Large Language Models (LLMs), guardrails have become\ncrucial to detect and defend against toxic content. However, with the\nincreasing pervasiveness of LLMs in multilingual scenarios, their effectiveness\nin handling multilingual toxic inputs remains unclear. In this work, we\nintroduce a comprehensive multilingual test suite, spanning seven datasets and\nover ten languages, to benchmark the performance of state-of-the-art\nguardrails. We also investigates the resilience of guardrails against recent\njailbreaking techniques, and assess the impact of in-context safety policies\nand language resource availability on guardrails' performance. Our findings\nshow that existing guardrails are still ineffective at handling multilingual\ntoxicity and lack robustness against jailbreaking prompts. This work aims to\nidentify the limitations of guardrails and to build a more reliable and\ntrustworthy LLMs in multilingual scenarios.", "published": "2024-10-29 15:51:24", "link": "http://arxiv.org/abs/2410.22153v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Class-Aware Contrastive Optimization for Imbalanced Text Classification", "abstract": "The unique characteristics of text data make classification tasks a complex\nproblem. Advances in unsupervised and semi-supervised learning and autoencoder\narchitectures addressed several challenges. However, they still struggle with\nimbalanced text classification tasks, a common scenario in real-world\napplications, demonstrating a tendency to produce embeddings with unfavorable\nproperties, such as class overlap. In this paper, we show that leveraging\nclass-aware contrastive optimization combined with denoising autoencoders can\nsuccessfully tackle imbalanced text classification tasks, achieving better\nperformance than the current state-of-the-art. Concretely, our proposal\ncombines reconstruction loss with contrastive class separation in the embedding\nspace, allowing a better balance between the truthfulness of the generated\nembeddings and the model's ability to separate different classes. Compared with\nan extensive set of traditional and state-of-the-art competing methods, our\nproposal demonstrates a notable increase in performance across a wide variety\nof text datasets.", "published": "2024-10-29 16:34:08", "link": "http://arxiv.org/abs/2410.22197v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ProMQA: Question Answering Dataset for Multimodal Procedural Activity\n  Understanding", "abstract": "Multimodal systems have great potential to assist humans in procedural\nactivities, where people follow instructions to achieve their goals. Despite\ndiverse application scenarios, systems are typically evaluated on traditional\nclassification tasks, e.g., action recognition or temporal action segmentation.\nIn this paper, we present a novel evaluation dataset, ProMQA, to measure system\nadvancements in application-oriented scenarios. ProMQA consists of 401\nmultimodal procedural QA pairs on user recording of procedural activities\ncoupled with their corresponding instruction. For QA annotation, we take a\ncost-effective human-LLM collaborative approach, where the existing annotation\nis augmented with LLM-generated QA pairs that are later verified by humans. We\nthen provide the benchmark results to set the baseline performance on ProMQA.\nOur experiment reveals a significant gap between human performance and that of\ncurrent systems, including competitive proprietary multimodal models. We hope\nour dataset sheds light on new aspects of models' multimodal understanding\ncapabilities.", "published": "2024-10-29 16:39:28", "link": "http://arxiv.org/abs/2410.22211v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FactBench: A Dynamic Benchmark for In-the-Wild Language Model Factuality\n  Evaluation", "abstract": "The rapid adoption of language models (LMs) across diverse applications has\nraised concerns about their factuality, i.e., their consistency with real-world\nfacts. We first present VERIFY (Verification and Evidence RetrIeval for\nFactualitY evaluation), a pipeline to evaluate LMs' factuality in real-world\nuser interactions. VERIFY considers the verifiability of LM-generated content\nand categorizes content units as supported, unsupported, or undecidable based\non Web-retrieved evidence. Importantly, factuality judgment by VERIFY\ncorrelates better with human evaluations than existing methods. Using VERIFY,\nwe identify \"hallucination prompts\" across diverse topics, i.e., those\neliciting the highest rates of incorrect (unsupported) and inconclusive\n(undecidable) LM responses. These prompts form FACTBENCH, a dataset of 1K\nprompts across 150 fine-grained topics. Our dataset captures emerging\nfactuality challenges in real-world LM interactions and can be regularly\nupdated with new prompts. We benchmark widely-used LMs from GPT, Gemini, and\nLlama families on FACTBENCH, yielding the following key findings: (i)\nProprietary models exhibit better factuality, with decreased performance from\nEasy to Hard hallucination prompts. (ii) Llama3.1-405B-Instruct shows\ncomparable or lower factual precision than Llama3.1-70B-Instruct across all\nevaluation methods due to its higher subjectivity that leads to more content\nlabeled as undecidable. (iii) Gemini1.5-Pro shows a significantly higher\nrefusal rate, with over-refusal in 25% of cases.", "published": "2024-10-29 17:19:56", "link": "http://arxiv.org/abs/2410.22257v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Synthetic Context Extension via Retrieval Heads", "abstract": "Long-context LLMs are increasingly in demand for applications such as\nretrieval-augmented generation. To defray the cost of pretraining LLMs over\nlong contexts, recent work takes an approach of synthetic context extension:\nfine-tuning LLMs with synthetically generated long-context data in a\npost-training stage. However, it remains unclear how and why this synthetic\ncontext extension imparts abilities for downstream long-context tasks. In this\npaper, we investigate fine-tuning on synthetic data for three long-context\ntasks that require retrieval and reasoning. We vary the realism of \"needle\"\nconcepts to be retrieved and diversity of the surrounding \"haystack\" context,\nfrom using LLMs to construct synthetic documents to using templated relations\nand creating symbolic datasets. We find that models trained on synthetic data\nfall short of the real data, but surprisingly, the mismatch can be interpreted\nand even predicted in terms of a special set of attention heads that are\nresponsible for retrieval over long context, retrieval heads (Wu et al., 2024).\nThe retrieval heads learned on synthetic data have high overlap with retrieval\nheads learned on real data, and there is a strong correlation between the\nrecall of heads learned and the downstream performance of a model. Furthermore,\nwith attention knockout and activation patching, we mechanistically show that\nretrieval heads are necessary and explain model performance, although they are\nnot totally sufficient. Our results shed light on how to interpret synthetic\ndata fine-tuning performance and how to approach creating better data for\nlearning real-world capabilities over long contexts.", "published": "2024-10-29 17:55:00", "link": "http://arxiv.org/abs/2410.22316v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Machine Translation with a BiLSTM-Attention Approach", "abstract": "With the rapid development of Natural Language Processing (NLP) technology,\nthe accuracy and efficiency of machine translation have become hot topics of\nresearch. This paper proposes a novel Seq2Seq model aimed at improving\ntranslation quality while reducing the storage space required by the model. The\nmodel employs a Bidirectional Long Short-Term Memory network (Bi-LSTM) as the\nencoder to capture the context information of the input sequence; the decoder\nincorporates an attention mechanism, enhancing the model's ability to focus on\nkey information during the translation process. Compared to the current\nmainstream Transformer model, our model achieves superior performance on the\nWMT14 machine translation dataset while maintaining a smaller size.\n  The study first introduces the design principles and innovative points of the\nmodel architecture, followed by a series of experiments to verify the\neffectiveness of the model. The experimental includes an assessment of the\nmodel's performance on different language pairs, as well as comparative\nanalysis with traditional Seq2Seq models. The results show that while\nmaintaining translation accuracy, our model significantly reduces the storage\nrequirements, which is of great significance for translation applications in\nresource-constrained scenarios. our code are available at\nhttps://github.com/mindspore-lab/models/tree/master/research/arxiv_papers/miniformer.\nThanks for the support provided by MindSpore Community.", "published": "2024-10-29 01:12:50", "link": "http://arxiv.org/abs/2410.22335v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AAAR-1.0: Assessing AI's Potential to Assist Research", "abstract": "Numerous studies have assessed the proficiency of AI systems, particularly\nlarge language models (LLMs), in facilitating everyday tasks such as email\nwriting, question answering, and creative content generation. However,\nresearchers face unique challenges and opportunities in leveraging LLMs for\ntheir own work, such as brainstorming research ideas, designing experiments,\nand writing or reviewing papers. In this study, we introduce AAAR-1.0, a\nbenchmark dataset designed to evaluate LLM performance in three fundamental,\nexpertise-intensive research tasks: (i) EquationInference, assessing the\ncorrectness of equations based on the contextual information in paper\nsubmissions; (ii) ExperimentDesign, designing experiments to validate research\nideas and solutions; (iii) PaperWeakness, identifying weaknesses in paper\nsubmissions; and (iv) REVIEWCRITIQUE, identifying each segment in human reviews\nis deficient or not. AAAR-1.0 differs from prior benchmarks in two key ways:\nfirst, it is explicitly research-oriented, with tasks requiring deep domain\nexpertise; second, it is researcher-oriented, mirroring the primary activities\nthat researchers engage in on a daily basis. An evaluation of both open-source\nand proprietary LLMs reveals their potential as well as limitations in\nconducting sophisticated research tasks. We will keep iterating AAAR-1.0 to new\nversions.", "published": "2024-10-29 17:58:29", "link": "http://arxiv.org/abs/2410.22394v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Anticipating Future with Large Language Model for Simultaneous Machine\n  Translation", "abstract": "Simultaneous machine translation (SMT) takes streaming input utterances and\nincrementally produces target text. Existing SMT methods only use the partial\nutterance that has already arrived at the input and the generated hypothesis.\nMotivated by human interpreters' technique to forecast future words before\nhearing them, we propose $\\textbf{T}$ranslation by $\\textbf{A}$nticipating\n$\\textbf{F}$uture (TAF), a method to improve translation quality while\nretraining low latency. Its core idea is to use a large language model (LLM) to\npredict future source words and opportunistically translate without introducing\ntoo much risk. We evaluate our TAF and multiple baselines of SMT on four\nlanguage directions. Experiments show that TAF achieves the best translation\nquality-latency trade-off and outperforms the baselines by up to 5 BLEU points\nat the same latency (three words).", "published": "2024-10-29 19:42:30", "link": "http://arxiv.org/abs/2410.22499v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toxicity of the Commons: Curating Open-Source Pre-Training Data", "abstract": "Open-source large language models are becoming increasingly available and\npopular among researchers and practitioners. While significant progress has\nbeen made on open-weight models, open training data is a practice yet to be\nadopted by the leading open-weight models creators. At the same time, there\nresearchers are working to make language models safer. We propose a data\ncuration pipeline to reduce harmful outputs by models trained on public domain\ndata. There are unique challenges to working with public domain data, as these\nsources differ from web text in both form and content. Many sources are\nhistorical documents and are the result of Optical Character Recognition (OCR).\nConsequently, current state-of-the-art approaches to toxicity filtering are\noften infeasible or inappropriate for open data models. In this paper, we\nintroduce a new fully open-source pipeline for open-data toxicity filtering.\nOur contributions are threefold. We create a custom training dataset,\nToxicCommons, which is composed of texts which have been classified across five\ndifferent dimensions (racial/origin-based, gender/sex-based, religious,\nability-based discrimination, and violence). We use this dataset to train a\ncustom classifier, Celadon, that can be used to detect toxic content in open\ndata more efficiently at a larger scale. Finally, we describe the balanced\napproach to content filtration that optimizes safety filtering with respect to\nthe filtered data available for training.", "published": "2024-10-29 23:00:05", "link": "http://arxiv.org/abs/2410.22587v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Characterizing the Role of Similarity in the Property Inferences of\n  Language Models", "abstract": "Property inheritance -- a phenomenon where novel properties are projected\nfrom higher level categories (e.g., birds) to lower level ones (e.g., sparrows)\n-- provides a unique window into how humans organize and deploy conceptual\nknowledge. It is debated whether this ability arises due to explicitly stored\ntaxonomic knowledge vs. simple computations of similarity between mental\nrepresentations. How are these mechanistic hypotheses manifested in\ncontemporary language models? In this work, we investigate how LMs perform\nproperty inheritance with behavioral and causal representational analysis\nexperiments. We find that taxonomy and categorical similarities are not\nmutually exclusive in LMs' property inheritance behavior. That is, LMs are more\nlikely to project novel properties from one category to the other when they are\ntaxonomically related and at the same time, highly similar. Our findings\nprovide insight into the conceptual structure of language models and may\nsuggest new psycholinguistic experiments for human subjects.", "published": "2024-10-29 23:05:41", "link": "http://arxiv.org/abs/2410.22590v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Personalization of Large Language Models: A Survey", "abstract": "Personalization of Large Language Models (LLMs) has recently become\nincreasingly important with a wide range of applications. Despite the\nimportance and recent progress, most existing works on personalized LLMs have\nfocused either entirely on (a) personalized text generation or (b) leveraging\nLLMs for personalization-related downstream applications, such as\nrecommendation systems. In this work, we bridge the gap between these two\nseparate main directions for the first time by introducing a taxonomy for\npersonalized LLM usage and summarizing the key differences and challenges. We\nprovide a formalization of the foundations of personalized LLMs that\nconsolidates and expands notions of personalization of LLMs, defining and\ndiscussing novel facets of personalization, usage, and desiderata of\npersonalized LLMs. We then unify the literature across these diverse fields and\nusage scenarios by proposing systematic taxonomies for the granularity of\npersonalization, personalization techniques, datasets, evaluation methods, and\napplications of personalized LLMs. Finally, we highlight challenges and\nimportant open problems that remain to be addressed. By unifying and surveying\nrecent research using the proposed taxonomies, we aim to provide a clear guide\nto the existing literature and different facets of personalization in LLMs,\nempowering both researchers and practitioners.", "published": "2024-10-29 04:01:11", "link": "http://arxiv.org/abs/2411.00027v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Math Problem Solving in Large Language Models Through\n  Categorization and Strategy Tailoring", "abstract": "In this paper, we explore how to leverage large language models (LLMs) to\nsolve mathematical problems efficiently and accurately. Specifically, we\ndemonstrate the effectiveness of classifying problems into distinct categories\nand employing category-specific problem-solving strategies to improve the\nmathematical performance of LLMs. We design a simple yet intuitive machine\nlearning model for problem categorization and show that its accuracy can be\nsignificantly enhanced through the development of well-curated training\ndatasets. Additionally, we find that the performance of this simple model\napproaches that of state-of-the-art (SOTA) models for categorization. Moreover,\nthe accuracy of SOTA models also benefits from the use of improved training\ndata. Finally, we assess the advantages of using category-specific strategies\nwhen prompting LLMs and observe significantly better performance compared to\nnon-tailored approaches.", "published": "2024-10-29 16:06:26", "link": "http://arxiv.org/abs/2411.00042v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MCPDial: A Minecraft Persona-driven Dialogue Dataset", "abstract": "We propose a novel approach that uses large language models (LLMs) to\ngenerate persona-driven conversations between Players and Non-Player Characters\n(NPC) in games. Showcasing the application of our methodology, we introduce the\nMinecraft Persona-driven Dialogue dataset (MCPDial). Starting with a small seed\nof expert-written conversations, we employ our method to generate hundreds of\nadditional conversations. Each conversation in the dataset includes rich\ncharacter descriptions of the player and NPC. The conversations are long,\nallowing for in-depth and extensive interactions between the player and NPC.\nMCPDial extends beyond basic conversations by incorporating canonical function\ncalls (e.g. \"Call find a resource on iron ore\") between the utterances.\nFinally, we conduct a qualitative analysis of the dataset to assess its quality\nand characteristics.", "published": "2024-10-29 00:19:55", "link": "http://arxiv.org/abs/2410.21627v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mitigating Paraphrase Attacks on Machine-Text Detectors via Paraphrase\n  Inversion", "abstract": "High-quality paraphrases are easy to produce using instruction-tuned language\nmodels or specialized paraphrasing models. Although this capability has a\nvariety of benign applications, paraphrasing\nattacks$\\unicode{x2013}$paraphrases applied to machine-generated\ntexts$\\unicode{x2013}$are known to significantly degrade the performance of\nmachine-text detectors. This motivates us to consider the novel problem of\nparaphrase inversion, where, given paraphrased text, the objective is to\nrecover an approximation of the original text. The closer the approximation is\nto the original text, the better machine-text detectors will perform. We\npropose an approach which frames the problem as translation from paraphrased\ntext back to the original text, which requires examples of texts and\ncorresponding paraphrases to train the inversion model. Fortunately, such\ntraining data can easily be generated, given a corpus of original texts and one\nor more paraphrasing models. We find that language models such as GPT-4 and\nLlama-3 exhibit biases when paraphrasing which an inversion model can learn\nwith a modest amount of data. Perhaps surprisingly, we also find that such\nmodels generalize well, including to paraphrase models unseen at training time.\nFinally, we show that when combined with a paraphrased-text detector, our\ninversion models provide an effective defense against paraphrasing attacks, and\noverall our approach yields an average improvement of +22% AUROC across seven\nmachine-text detectors and three different domains.", "published": "2024-10-29 00:46:24", "link": "http://arxiv.org/abs/2410.21637v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can Language Models Replace Programmers? REPOCOD Says 'Not Yet'", "abstract": "Large language models (LLMs) have achieved high accuracy, i.e., more than 90%\npass@1, in solving Python coding problems in HumanEval and MBPP. Thus, a\nnatural question is, whether LLMs achieve comparable code completion\nperformance compared to human developers? Unfortunately, one cannot answer this\nquestion using existing manual crafted or simple (e.g., single-line) code\ngeneration benchmarks, since such tasks fail to represent real-world software\ndevelopment tasks. In addition, existing benchmarks often use poor code\ncorrectness metrics, providing misleading conclusions.\n  To address these challenges, we create REPOCOD, a code generation benchmark\nwith 980 problems collected from 11 popular real-world projects, with more than\n58% of them requiring file-level or repository-level context information. In\naddition, REPOCOD has the longest average canonical solution length (331.6\ntokens) and the highest average cyclomatic complexity (9.00) compared to\nexisting benchmarks. Each task in REPOCOD includes 313.5 developer-written test\ncases on average for better correctness evaluation. In our evaluations of ten\nLLMs, none of the models achieve more than 30% pass@1 on REPOCOD, indicating\nthe necessity of building stronger LLMs that can help developers in real-world\nsoftware development. REPOCOD is available at\nhttps://github.com/lt-asset/REPOCOD", "published": "2024-10-29 01:21:05", "link": "http://arxiv.org/abs/2410.21647v3", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "$f$-PO: Generalizing Preference Optimization with $f$-divergence\n  Minimization", "abstract": "Preference optimization has made significant progress recently, with numerous\nmethods developed to align language models with human preferences. This paper\nintroduces $f$-divergence Preference Optimization ($f$-PO), a novel framework\nthat generalizes and extends existing approaches. $f$-PO minimizes\n$f$-divergences between the optimized policy and the optimal policy,\nencompassing a broad family of alignment methods using various divergences. Our\napproach unifies previous algorithms like DPO and EXO, while offering new\nvariants through different choices of $f$-divergences. We provide theoretical\nanalysis of $f$-PO's properties and conduct extensive experiments on\nstate-of-the-art language models using benchmark datasets. Results demonstrate\n$f$-PO's effectiveness across various tasks, achieving superior performance\ncompared to existing methods on popular benchmarks such as AlpacaEval 2,\nArena-Hard, MT-Bench, and Open LLM Leaderboard v2. Additionally, we present\nablation studies exploring the impact of different $f$-divergences, offering\ninsights into the trade-offs between regularization and performance in offline\npreference optimization. Our work contributes both practical algorithms and\ntheoretical understanding to the field of language model alignment. Code is\navailable at https://github.com/MinkaiXu/fPO.", "published": "2024-10-29 02:11:45", "link": "http://arxiv.org/abs/2410.21662v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CFSafety: Comprehensive Fine-grained Safety Assessment for LLMs", "abstract": "As large language models (LLMs) rapidly evolve, they bring significant\nconveniences to our work and daily lives, but also introduce considerable\nsafety risks. These models can generate texts with social biases or unethical\ncontent, and under specific adversarial instructions, may even incite illegal\nactivities. Therefore, rigorous safety assessments of LLMs are crucial. In this\nwork, we introduce a safety assessment benchmark, CFSafety, which integrates 5\nclassic safety scenarios and 5 types of instruction attacks, totaling 10\ncategories of safety questions, to form a test set with 25k prompts. This test\nset was used to evaluate the natural language generation (NLG) capabilities of\nLLMs, employing a combination of simple moral judgment and a 1-5 safety rating\nscale for scoring. Using this benchmark, we tested eight popular LLMs,\nincluding the GPT series. The results indicate that while GPT-4 demonstrated\nsuperior safety performance, the safety effectiveness of LLMs, including this\nmodel, still requires improvement. The data and code associated with this study\nare available on GitHub.", "published": "2024-10-29 03:25:20", "link": "http://arxiv.org/abs/2410.21695v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Financial Question Answering with a Multi-Agent Reflection\n  Framework", "abstract": "While Large Language Models (LLMs) have shown impressive capabilities in\nnumerous Natural Language Processing (NLP) tasks, they still struggle with\nfinancial question answering (QA), particularly when numerical reasoning is\nrequired. Recently, LLM-based multi-agent frameworks have demonstrated\nremarkable effectiveness in multi-step reasoning, which is crucial for\nfinancial QA tasks as it involves extracting relevant information from tables\nand text and then performing numerical reasoning on the extracted data to infer\nanswers. In this study, we propose a multi-agent framework incorporating a\ncritic agent that reflects on the reasoning steps and final answers for each\nquestion. Additionally, we enhance our system by adding multiple critic agents,\neach focusing on a specific aspect of the answer. Our results indicate that\nthis framework significantly improves performance compared to single-agent\nreasoning, with an average performance increase of 15% for the LLaMA3-8B model\nand 5% for the LLaMA3-70B model. Furthermore, our framework performs on par\nwith, and in some cases surpasses, larger single-agent LLMs such as\nLLaMA3.1-405B and GPT-4o-mini, though it falls slightly short compared to\nClaude-3.5 Sonnet. Overall, our framework presents an effective solution to\nenhance open-source LLMs for financial QA tasks, offering a cost-effective\nalternative to larger models like Claude-3.5 Sonnet.", "published": "2024-10-29 04:58:07", "link": "http://arxiv.org/abs/2410.21741v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning and Unlearning of Fabricated Knowledge in Language Models", "abstract": "What happens when a new piece of knowledge is introduced into the training\ndata and how long does it last while a large language model (LM) continues to\ntrain? We investigate this question by injecting facts into LMs from a new\nprobing dataset, \"Outlandish\", which is designed to permit the testing of a\nspectrum of different fact types. When studying how robust these memories are,\nthere appears to be a sweet spot in the spectrum of fact novelty between\nconsistency with world knowledge and total randomness, where the injected\nmemory is the most enduring. Specifically we show that facts that conflict with\ncommon knowledge are remembered for tens of thousands of training steps, while\nprompts not conflicting with common knowledge (mundane), as well as scrambled\nprompts (randomly jumbled) are both forgotten much more rapidly. Further,\nknowledge-conflicting facts can \"prime'' how the language model hallucinates on\nlogically unrelated prompts, showing their propensity for non-target\ngeneralization, while both mundane and randomly jumbled facts prime\nsignificantly less. Finally, we show that impacts of knowledge-conflicting\nfacts in LMs, though they can be long lasting, can be largely erased by novel\napplication of multi-step sparse updates, even while the training ability of\nthe model is preserved. As such, this very simple procedure has direct\nimplications for mitigating the effects of data poisoning in training.", "published": "2024-10-29 05:33:14", "link": "http://arxiv.org/abs/2410.21750v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating K-Fold Cross Validation for Transformer Based Symbolic\n  Regression Models", "abstract": "Symbolic Regression remains an NP-Hard problem, with extensive research\nfocusing on AI models for this task. Transformer models have shown promise in\nSymbolic Regression, but performance suffers with smaller datasets. We propose\napplying k-fold cross-validation to a transformer-based symbolic regression\nmodel trained on a significantly reduced dataset (15,000 data points, down from\n500,000). This technique partitions the training data into multiple subsets\n(folds), iteratively training on some while validating on others. Our aim is to\nprovide an estimate of model generalization and mitigate overfitting issues\nassociated with smaller datasets. Results show that this process improves the\nmodel's output consistency and generalization by a relative improvement in\nvalidation loss of 53.31%. Potentially enabling more efficient and accessible\nsymbolic regression in resource-constrained environments.", "published": "2024-10-29 09:39:54", "link": "http://arxiv.org/abs/2410.21896v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Beyond Text: Optimizing RAG with Multimodal Inputs for Industrial\n  Applications", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nanswering questions, but they lack domain-specific knowledge and are prone to\nhallucinations. Retrieval Augmented Generation (RAG) is one approach to address\nthese challenges, while multimodal models are emerging as promising AI\nassistants for processing both text and images. In this paper we describe a\nseries of experiments aimed at determining how to best integrate multimodal\nmodels into RAG systems for the industrial domain. The purpose of the\nexperiments is to determine whether including images alongside text from\ndocuments within the industrial domain increases RAG performance and to find\nthe optimal configuration for such a multimodal RAG system. Our experiments\ninclude two approaches for image processing and retrieval, as well as two LLMs\n(GPT4-Vision and LLaVA) for answer synthesis. These image processing strategies\ninvolve the use of multimodal embeddings and the generation of textual\nsummaries from images. We evaluate our experiments with an LLM-as-a-Judge\napproach. Our results reveal that multimodal RAG can outperform single-modality\nRAG settings, although image retrieval poses a greater challenge than text\nretrieval. Additionally, leveraging textual summaries from images presents a\nmore promising approach compared to the use of multimodal embeddings, providing\nmore opportunities for future advancements.", "published": "2024-10-29 11:03:31", "link": "http://arxiv.org/abs/2410.21943v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Are VLMs Really Blind", "abstract": "Vision Language Models excel in handling a wide range of complex tasks,\nincluding Optical Character Recognition (OCR), Visual Question Answering (VQA),\nand advanced geometric reasoning. However, these models fail to perform well on\nlow-level basic visual tasks which are especially easy for humans. Our goal in\nthis work was to determine if these models are truly \"blind\" to geometric\nreasoning or if there are ways to enhance their capabilities in this area. Our\nwork presents a novel automatic pipeline designed to extract key information\nfrom images in response to specific questions. Instead of just relying on\ndirect VQA, we use question-derived keywords to create a caption that\nhighlights important details in the image related to the question. This caption\nis then used by a language model to provide a precise answer to the question\nwithout requiring external fine-tuning.", "published": "2024-10-29 13:20:50", "link": "http://arxiv.org/abs/2410.22029v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Unlearning as multi-task optimization: A normalized gradient difference\n  approach with an adaptive learning rate", "abstract": "Machine unlearning has been used to remove unwanted knowledge acquired by\nlarge language models (LLMs). In this paper, we examine machine unlearning from\nan optimization perspective, framing it as a regularized multi-task\noptimization problem, where one task optimizes a forgetting objective and\nanother optimizes the model performance. In particular, we introduce a\nnormalized gradient difference (NGDiff) algorithm, enabling us to have better\ncontrol over the trade-off between the objectives, while integrating a new,\nautomatic learning rate scheduler. We provide a theoretical analysis and\nempirically demonstrate the superior performance of NGDiff among\nstate-of-the-art unlearning methods on the TOFU and MUSE datasets while\nexhibiting stable training.", "published": "2024-10-29 14:41:44", "link": "http://arxiv.org/abs/2410.22086v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Joint Extraction and Classification of Danish Competences for Job\n  Matching", "abstract": "The matching of competences, such as skills, occupations or knowledges, is a\nkey desiderata for candidates to be fit for jobs. Automatic extraction of\ncompetences from CVs and Jobs can greatly promote recruiters' productivity in\nlocating relevant candidates for job vacancies. This work presents the first\nmodel that jointly extracts and classifies competence from Danish job postings.\nDifferent from existing works on skill extraction and skill classification, our\nmodel is trained on a large volume of annotated Danish corpora and is capable\nof extracting a wide range of Danish competences, including skills, occupations\nand knowledges of different categories. More importantly, as a single BERT-like\narchitecture for joint extraction and classification, our model is lightweight\nand efficient at inference. On a real-scenario job matching dataset, our model\nbeats the state-of-the-art models in the overall performance of Danish\ncompetence extraction and classification, and saves over 50% time at inference.", "published": "2024-10-29 15:00:40", "link": "http://arxiv.org/abs/2410.22103v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Protecting Privacy in Multimodal Large Language Models with MLLMU-Bench", "abstract": "Generative models such as Large Language Models (LLM) and Multimodal Large\nLanguage models (MLLMs) trained on massive web corpora can memorize and\ndisclose individuals' confidential and private data, raising legal and ethical\nconcerns. While many previous works have addressed this issue in LLM via\nmachine unlearning, it remains largely unexplored for MLLMs. To tackle this\nchallenge, we introduce Multimodal Large Language Model Unlearning Benchmark\n(MLLMU-Bench), a novel benchmark aimed at advancing the understanding of\nmultimodal machine unlearning. MLLMU-Bench consists of 500 fictitious profiles\nand 153 profiles for public celebrities, each profile feature over 14\ncustomized question-answer pairs, evaluated from both multimodal (image+text)\nand unimodal (text) perspectives. The benchmark is divided into four sets to\nassess unlearning algorithms in terms of efficacy, generalizability, and model\nutility. Finally, we provide baseline results using existing generative model\nunlearning algorithms. Surprisingly, our experiments show that unimodal\nunlearning algorithms excel in generation and cloze tasks, while multimodal\nunlearning approaches perform better in classification tasks with multimodal\ninputs.", "published": "2024-10-29 15:07:23", "link": "http://arxiv.org/abs/2410.22108v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Natural Language Processing for Analyzing Electronic Health Records and\n  Clinical Notes in Cancer Research: A Review", "abstract": "Objective: This review aims to analyze the application of natural language\nprocessing (NLP) techniques in cancer research using electronic health records\n(EHRs) and clinical notes. This review addresses gaps in the existing\nliterature by providing a broader perspective than previous studies focused on\nspecific cancer types or applications. Methods: A comprehensive literature\nsearch was conducted using the Scopus database, identifying 94 relevant studies\npublished between 2019 and 2024. Data extraction included study\ncharacteristics, cancer types, NLP methodologies, dataset information,\nperformance metrics, challenges, and future directions. Studies were\ncategorized based on cancer types and NLP applications. Results: The results\nshowed a growing trend in NLP applications for cancer research, with breast,\nlung, and colorectal cancers being the most studied. Information extraction and\ntext classification emerged as predominant NLP tasks. A shift from rule-based\nto advanced machine learning techniques, particularly transformer-based models,\nwas observed. The Dataset sizes used in existing studies varied widely. Key\nchallenges included the limited generalizability of proposed solutions and the\nneed for improved integration into clinical workflows. Conclusion: NLP\ntechniques show significant potential in analyzing EHRs and clinical notes for\ncancer research. However, future work should focus on improving model\ngeneralizability, enhancing robustness in handling complex clinical language,\nand expanding applications to understudied cancer types. Integration of NLP\ntools into clinical practice and addressing ethical considerations remain\ncrucial for utilizing the full potential of NLP in enhancing cancer diagnosis,\ntreatment, and patient outcomes.", "published": "2024-10-29 16:17:07", "link": "http://arxiv.org/abs/2410.22180v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cora: Accelerating Stateful Network Applications with SmartNICs", "abstract": "With the growing performance requirements on networked applications, there is\na new trend of offloading stateful network applications to SmartNICs to improve\nperformance and reduce the total cost of ownership. However, offloading\nstateful network applications is non-trivial due to state operation complexity,\nstate resource consumption, and the complicated relationship between traffic\nand state. Naively partitioning the program by state or traffic can result in a\nsuboptimal partition plan with higher CPU usage or even packet drops. In this\npaper, we propose Cora, a compiler and runtime that offloads stateful network\napplications to SmartNIC-accelerated hosts. Cora compiler introduces an\naccurate performance model for each SmartNIC and employs an efficient compiling\nalgorithm to search the offloading plan. Cora runtime can monitor traffic\ndynamics and adapt to minimize CPU usage. Cora is built atop Netronome Agilio\nand BlueField 2 SmartNICs. Our evaluation shows that for the same throughput\ntarget, Cora can propose partition plans saving up to 94.0% CPU cores, 1.9\ntimes more than baseline solutions. Under the same resource constraint, Cora\ncan accelerate network functions by 44.9%-82.3%. Cora runtime can adapt to\ntraffic changes and keep CPU usage low.", "published": "2024-10-29 16:55:36", "link": "http://arxiv.org/abs/2410.22229v1", "categories": ["cs.NI", "cs.CL"], "primary_category": "cs.NI"}
{"title": "DISCERN: Decoding Systematic Errors in Natural Language for Text\n  Classifiers", "abstract": "Despite their high predictive accuracies, current machine learning systems\noften exhibit systematic biases stemming from annotation artifacts or\ninsufficient support for certain classes in the dataset. Recent work proposes\nautomatic methods for identifying and explaining systematic biases using\nkeywords. We introduce DISCERN, a framework for interpreting systematic biases\nin text classifiers using language explanations. DISCERN iteratively generates\nprecise natural language descriptions of systematic errors by employing an\ninteractive loop between two large language models. Finally, we use the\ndescriptions to improve classifiers by augmenting classifier training sets with\nsynthetically generated instances or annotated examples via active learning. On\nthree text-classification datasets, we demonstrate that language explanations\nfrom our framework induce consistent performance improvements that go beyond\nwhat is achievable with exemplars of systematic bias. Finally, in human\nevaluations, we show that users can interpret systematic biases more\neffectively (by over 25% relative) and efficiently when described through\nlanguage explanations as opposed to cluster exemplars.", "published": "2024-10-29 17:04:55", "link": "http://arxiv.org/abs/2410.22239v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From melodic note sequences to pitches using word2vec", "abstract": "Applying the word2vec technique, commonly used in language modeling, to\nmelodies, where notes are treated as words in sentences, enables the capture of\npitch information. This study examines two datasets: 20 children's songs and an\nexcerpt from a Bach sonata. The semantic space for defining the embeddings is\nof very small dimension, specifically 2. Notes are predicted based on the 2, 3\nor 4 preceding notes that establish the context. A multivariate analysis of the\nresults shows that the semantic vectors representing the notes have a multiple\ncorrelation coefficient of approximately 0.80 with their pitches.", "published": "2024-10-29 17:38:27", "link": "http://arxiv.org/abs/2410.22285v1", "categories": ["cs.CL", "cs.AI", "I.2"], "primary_category": "cs.CL"}
{"title": "Flow-DPO: Improving LLM Mathematical Reasoning through Online\n  Multi-Agent Learning", "abstract": "Mathematical reasoning is a crucial capability for Large Language Models\n(LLMs), yet generating detailed and accurate reasoning traces remains a\nsignificant challenge. This paper introduces a novel approach to produce\nhigh-quality reasoning traces for LLM fine-tuning using online learning\n\\textbf{Flows}. Our method employs an incremental output production Flow, where\ncomponent LLMs collaboratively construct solutions through iterative\ncommunication. We train the Flow using online Direct Preference Optimization\n(DPO) learning with rollouts, generating DPO pairs for each training example\nand updating models in real-time. We directly compare the quality of reasoning\ntraces generated by our method with those produced through direct model\ninference, demonstrating the effectiveness of our approach in improving LLM\nperformance in mathematical reasoning tasks.", "published": "2024-10-29 17:50:31", "link": "http://arxiv.org/abs/2410.22304v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Natural Language Inference Improves Compositionality in Vision-Language\n  Models", "abstract": "Compositional reasoning in Vision-Language Models (VLMs) remains challenging\nas these models often struggle to relate objects, attributes, and spatial\nrelationships. Recent methods aim to address these limitations by relying on\nthe semantics of the textual description, using Large Language Models (LLMs) to\nbreak them down into subsets of questions and answers. However, these methods\nprimarily operate on the surface level, failing to incorporate deeper lexical\nunderstanding while introducing incorrect assumptions generated by the LLM. In\nresponse to these issues, we present Caption Expansion with Contradictions and\nEntailments (CECE), a principled approach that leverages Natural Language\nInference (NLI) to generate entailments and contradictions from a given\npremise. CECE produces lexically diverse sentences while maintaining their core\nmeaning. Through extensive experiments, we show that CECE enhances\ninterpretability and reduces overreliance on biased or superficial features. By\nbalancing CECE along the original premise, we achieve significant improvements\nover previous methods without requiring additional fine-tuning, producing\nstate-of-the-art results on benchmarks that score agreement with human\njudgments for image-text alignment, and achieving an increase in performance on\nWinoground of +19.2% (group score) and +12.9% on EqBen (group score) over the\nbest prior work (finetuned with targeted data).", "published": "2024-10-29 17:54:17", "link": "http://arxiv.org/abs/2410.22315v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Do Large Language Models Align with Core Mental Health Counseling\n  Competencies?", "abstract": "The rapid evolution of Large Language Models (LLMs) presents a promising\nsolution to the global shortage of mental health professionals. However, their\nalignment with essential counseling competencies remains underexplored. We\nintroduce CounselingBench, a novel NCMHCE-based benchmark evaluating 22\ngeneral-purpose and medical-finetuned LLMs across five key competencies. While\nfrontier models surpass minimum aptitude thresholds, they fall short of\nexpert-level performance, excelling in Intake, Assessment & Diagnosis but\nstruggling with Core Counseling Attributes and Professional Practice & Ethics.\nSurprisingly, medical LLMs do not outperform generalist models in accuracy,\nthough they provide slightly better justifications while making more\ncontext-related errors. These findings highlight the challenges of developing\nAI for mental health counseling, particularly in competencies requiring empathy\nand nuanced reasoning. Our results underscore the need for specialized,\nfine-tuned models aligned with core mental health counseling competencies and\nsupported by human oversight before real-world deployment. Code and data\nassociated with this manuscript can be found at:\nhttps://github.com/cuongnguyenx/CounselingBench", "published": "2024-10-29 18:27:11", "link": "http://arxiv.org/abs/2410.22446v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Pointer Network-based Approach for Joint Extraction and Detection of\n  Multi-Label Multi-Class Intents", "abstract": "In task-oriented dialogue systems, intent detection is crucial for\ninterpreting user queries and providing appropriate responses. Existing\nresearch primarily addresses simple queries with a single intent, lacking\neffective systems for handling complex queries with multiple intents and\nextracting different intent spans. Additionally, there is a notable absence of\nmultilingual, multi-intent datasets. This study addresses three critical tasks:\nextracting multiple intent spans from queries, detecting multiple intents, and\ndeveloping a multi-lingual multi-label intent dataset. We introduce a novel\nmulti-label multi-class intent detection dataset (MLMCID-dataset) curated from\nexisting benchmark datasets. We also propose a pointer network-based\narchitecture (MLMCID) to extract intent spans and detect multiple intents with\ncoarse and fine-grained labels in the form of sextuplets. Comprehensive\nanalysis demonstrates the superiority of our pointer network-based system over\nbaseline approaches in terms of accuracy and F1-score across various datasets.", "published": "2024-10-29 19:10:12", "link": "http://arxiv.org/abs/2410.22476v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Scaling LLM Inference with Optimized Sample Compute Allocation", "abstract": "Sampling is a basic operation in many inference-time algorithms of large\nlanguage models (LLMs). To scale up inference efficiently with a limited\ncompute, it is crucial to find an optimal allocation for sample compute\nbudgets: Which sampling configurations (model, temperature, language, etc.) do\nwe use? How many samples do we generate in each configuration? We formulate\nthese choices as a learning problem and propose OSCA, an algorithm that\nOptimizes Sample Compute Allocation by finding an optimal mix of different\ninference configurations. Our experiments show that with our learned mixed\nallocation, we can achieve accuracy better than the best single configuration\nwith 128x less compute on code generation and 25x less compute on 4 reasoning\ntasks. OSCA is also shown to be effective in agentic workflows beyond\nsingle-turn tasks, achieving a better accuracy on SWE-Bench with 3x less\ncompute than the default configuration. Our code and generations are released\nat https://github.com/LeiLiLab/OSCA.", "published": "2024-10-29 19:17:55", "link": "http://arxiv.org/abs/2410.22480v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Is Our Chatbot Telling Lies? Assessing Correctness of an LLM-based Dutch\n  Support Chatbot", "abstract": "Companies support their customers using live chats and chatbots to gain their\nloyalty. AFAS is a Dutch company aiming to leverage the opportunity large\nlanguage models (LLMs) offer to answer customer queries with minimal to no\ninput from its customer support team. Adding to its complexity, it is unclear\nwhat makes a response correct, and that too in Dutch. Further, with minimal\ndata available for training, the challenge is to identify whether an answer\ngenerated by a large language model is correct and do it on the fly.\n  This study is the first to define the correctness of a response based on how\nthe support team at AFAS makes decisions. It leverages literature on natural\nlanguage generation and automated answer grading systems to automate the\ndecision-making of the customer support team. We investigated questions\nrequiring a binary response (e.g., Would it be possible to adjust tax rates\nmanually?) or instructions (e.g., How would I adjust tax rate manually?) to\ntest how close our automated approach reaches support rating. Our approach can\nidentify wrong messages in 55\\% of the cases. This work shows the viability of\nautomatically assessing when our chatbot tell lies.", "published": "2024-10-29 12:02:14", "link": "http://arxiv.org/abs/2411.00034v1", "categories": ["cs.CL", "cs.AI", "I.2.7; I.7.0"], "primary_category": "cs.CL"}
{"title": "Topic-Conversation Relevance (TCR) Dataset and Benchmarks", "abstract": "Workplace meetings are vital to organizational collaboration, yet a large\npercentage of meetings are rated as ineffective. To help improve meeting\neffectiveness by understanding if the conversation is on topic, we create a\ncomprehensive Topic-Conversation Relevance (TCR) dataset that covers a variety\nof domains and meeting styles. The TCR dataset includes 1,500 unique meetings,\n22 million words in transcripts, and over 15,000 meeting topics, sourced from\nboth newly collected Speech Interruption Meeting (SIM) data and existing public\ndatasets. Along with the text data, we also open source scripts to generate\nsynthetic meetings or create augmented meetings from the TCR dataset to enhance\ndata diversity. For each data source, benchmarks are created using GPT-4 to\nevaluate the model accuracy in understanding transcription-topic relevance.", "published": "2024-10-29 13:55:17", "link": "http://arxiv.org/abs/2411.00038v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MIMIC-IV-Ext-PE: Using a large language model to predict pulmonary\n  embolism phenotype in the MIMIC-IV dataset", "abstract": "Pulmonary embolism (PE) is a leading cause of preventable in-hospital\nmortality. Advances in diagnosis, risk stratification, and prevention can\nimprove outcomes. There are few large publicly available datasets that contain\nPE labels for research. Using the MIMIC-IV database, we extracted all available\nradiology reports of computed tomography pulmonary angiography (CTPA) scans and\ntwo physicians manually labeled the results as PE positive (acute PE) or PE\nnegative. We then applied a previously finetuned Bio_ClinicalBERT transformer\nlanguage model, VTE-BERT, to extract labels automatically. We verified\nVTE-BERT's reliability by measuring its performance against manual\nadjudication. We also compared the performance of VTE-BERT to diagnosis codes.\nWe found that VTE-BERT has a sensitivity of 92.4% and positive predictive value\n(PPV) of 87.8% on all 19,942 patients with CTPA radiology reports from the\nemergency room and/or hospital admission. In contrast, diagnosis codes have a\nsensitivity of 95.4% and PPV of 83.8% on the subset of 11,990 hospitalized\npatients with discharge diagnosis codes. We successfully add nearly 20,000\nlabels to CTPAs in a publicly available dataset and demonstrate the external\nvalidity of a semi-supervised language model in accelerating hematologic\nresearch.", "published": "2024-10-29 19:28:44", "link": "http://arxiv.org/abs/2411.00044v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Novel Psychometrics-Based Approach to Developing Professional\n  Competency Benchmark for Large Language Models", "abstract": "The era of large language models (LLM) raises questions not only about how to\ntrain models, but also about how to evaluate them. Despite numerous existing\nbenchmarks, insufficient attention is often given to creating assessments that\ntest LLMs in a valid and reliable manner. To address this challenge, we\naccommodate the Evidence-centered design (ECD) methodology and propose a\ncomprehensive approach to benchmark development based on rigorous psychometric\nprinciples. In this paper, we have made the first attempt to illustrate this\napproach by creating a new benchmark in the field of pedagogy and education,\nhighlighting the limitations of existing benchmark development approach and\ntaking into account the development of LLMs. We conclude that a new approach to\nbenchmarking is required to match the growing complexity of AI applications in\nthe educational context. We construct a novel benchmark guided by the Bloom's\ntaxonomy and rigorously designed by a consortium of education experts trained\nin test development. Thus the current benchmark provides an academically robust\nand practical assessment tool tailored for LLMs, rather than human\nparticipants. Tested empirically on the GPT model in the Russian language, it\nevaluates model performance across varied task complexities, revealing critical\ngaps in current LLM capabilities. Our results indicate that while generative AI\ntools hold significant promise for education - potentially supporting tasks\nsuch as personalized tutoring, real-time feedback, and multilingual learning -\ntheir reliability as autonomous teachers' assistants right now remain rather\nlimited, particularly in tasks requiring deeper cognitive engagement.", "published": "2024-10-29 19:32:43", "link": "http://arxiv.org/abs/2411.00045v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Big Data-empowered System for Real-time Detection of Regional\n  Discriminatory Comments on Vietnamese Social Media", "abstract": "Regional discrimination is a persistent social issue in Vietnam. While\nexisting research has explored hate speech in the Vietnamese language, the\nspecific issue of regional discrimination remains under-addressed. Previous\nstudies primarily focused on model development without considering practical\nsystem implementation. In this work, we propose a task called Detection of\nRegional Discriminatory Comments on Vietnamese Social Media, leveraging the\npower of machine learning and transfer learning models. We have built the ViRDC\n(Vietnamese Regional Discrimination Comments) dataset, which contains comments\nfrom social media platforms, providing a valuable resource for further research\nand development. Our approach integrates streaming capabilities to process\nreal-time data from social media networks, ensuring the system's scalability\nand responsiveness. We developed the system on the Apache Spark framework to\nefficiently handle increasing data inputs during streaming. Our system offers a\ncomprehensive solution for the real-time detection of regional discrimination\nin Vietnam.", "published": "2024-10-29 10:06:49", "link": "http://arxiv.org/abs/2411.02587v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Sequential choice in ordered bundles", "abstract": "Experience goods such as sporting and artistic events, songs, videos, news\nstories, podcasts, and television series, are often packaged and consumed in\nbundles. Many such bundles are ordered in the sense that the individual items\nare consumed sequentially, one at a time. We examine if an individual's\ndecision to consume the next item in an ordered bundle can be predicted based\non his/her consumption pattern for the preceding items. We evaluate several\npredictive models, including two custom Transformers using decoder-only and\nencoder-decoder architectures, fine-tuned GPT-3, a custom LSTM model, a\nreinforcement learning model, two Markov models, and a zero-order model. Using\ndata from Spotify, we find that the custom Transformer with a decoder-only\narchitecture provides the most accurate predictions, both for individual\nchoices and aggregate demand. This model captures a general form of state\ndependence. Analysis of Transformer attention weights suggests that the\nconsumption of the next item in a bundle is based on approximately equal\nweighting of all preceding choices. Our results indicate that the Transformer\ncan assist in queuing the next item that an individual is likely to consume\nfrom an ordered bundle, predicting the demand for individual items, and\npersonalizing promotions to increase demand.", "published": "2024-10-29 02:35:21", "link": "http://arxiv.org/abs/2410.21670v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Bayesian Approach to Harnessing the Power of LLMs in Authorship\n  Attribution", "abstract": "Authorship attribution aims to identify the origin or author of a document.\nTraditional approaches have heavily relied on manual features and fail to\ncapture long-range correlations, limiting their effectiveness. Recent\nadvancements leverage text embeddings from pre-trained language models, which\nrequire significant fine-tuning on labeled data, posing challenges in data\ndependency and limited interpretability. Large Language Models (LLMs), with\ntheir deep reasoning capabilities and ability to maintain long-range textual\nassociations, offer a promising alternative. This study explores the potential\nof pre-trained LLMs in one-shot authorship attribution, specifically utilizing\nBayesian approaches and probability outputs of LLMs. Our methodology calculates\nthe probability that a text entails previous writings of an author, reflecting\na more nuanced understanding of authorship. By utilizing only pre-trained\nmodels such as Llama-3-70B, our results on the IMDb and blog datasets show an\nimpressive 85\\% accuracy in one-shot authorship classification across ten\nauthors. Our findings set new baselines for one-shot authorship analysis using\nLLMs and expand the application scope of these models in forensic linguistics.\nThis work also includes extensive ablation studies to validate our approach.", "published": "2024-10-29 04:14:23", "link": "http://arxiv.org/abs/2410.21716v1", "categories": ["cs.CL", "cs.AI", "stat.AP"], "primary_category": "cs.CL"}
{"title": "MARCO: Multi-Agent Real-time Chat Orchestration", "abstract": "Large language model advancements have enabled the development of multi-agent\nframeworks to tackle complex, real-world problems such as to automate tasks\nthat require interactions with diverse tools, reasoning, and human\ncollaboration. We present MARCO, a Multi-Agent Real-time Chat Orchestration\nframework for automating tasks using LLMs. MARCO addresses key challenges in\nutilizing LLMs for complex, multi-step task execution. It incorporates robust\nguardrails to steer LLM behavior, validate outputs, and recover from errors\nthat stem from inconsistent output formatting, function and parameter\nhallucination, and lack of domain knowledge. Through extensive experiments we\ndemonstrate MARCO's superior performance with 94.48% and 92.74% accuracy on\ntask execution for Digital Restaurant Service Platform conversations and Retail\nconversations datasets respectively along with 44.91% improved latency and\n33.71% cost reduction. We also report effects of guardrails in performance gain\nalong with comparisons of various LLM models, both open-source and proprietary.\nThe modular and generic design of MARCO allows it to be adapted for automating\ntasks across domains and to execute complex usecases through multi-turn\ninteractions.", "published": "2024-10-29 06:42:27", "link": "http://arxiv.org/abs/2410.21784v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "A Longitudinal Analysis of Racial and Gender Bias in New York Times and\n  Fox News Images and Articles", "abstract": "The manner in which different racial and gender groups are portrayed in news\ncoverage plays a large role in shaping public opinion. As such, understanding\nhow such groups are portrayed in news media is of notable societal value, and\nhas thus been a significant endeavour in both the computer and social sciences.\nYet, the literature still lacks a longitudinal study examining both the\nfrequency of appearance of different racial and gender groups in online news\narticles, as well as the context in which such groups are discussed. To fill\nthis gap, we propose two machine learning classifiers to detect the race and\nage of a given subject. Next, we compile a dataset of 123,337 images and\n441,321 online news articles from New York Times (NYT) and Fox News (Fox), and\nexamine representation through two computational approaches. Firstly, we\nexamine the frequency and prominence of appearance of racial and gender groups\nin images embedded in news articles, revealing that racial and gender\nminorities are largely under-represented, and when they do appear, they are\nfeatured less prominently compared to majority groups. Furthermore, we find\nthat NYT largely features more images of racial minority groups compared to\nFox. Secondly, we examine both the frequency and context with which racial\nminority groups are presented in article text. This reveals the narrow scope in\nwhich certain racial groups are covered and the frequency with which different\ngroups are presented as victims and/or perpetrators in a given conflict. Taken\ntogether, our analysis contributes to the literature by providing two novel\nopen-source classifiers to detect race and age from images, and shedding light\non the racial and gender biases in news articles from venues on opposite ends\nof the American political spectrum.", "published": "2024-10-29 09:42:54", "link": "http://arxiv.org/abs/2410.21898v2", "categories": ["cs.CY", "cs.CL", "cs.CV"], "primary_category": "cs.CY"}
{"title": "SceneGenAgent: Precise Industrial Scene Generation with Coding Agent", "abstract": "The modeling of industrial scenes is essential for simulations in industrial\nmanufacturing. While large language models (LLMs) have shown significant\nprogress in generating general 3D scenes from textual descriptions, generating\nindustrial scenes with LLMs poses a unique challenge due to their demand for\nprecise measurements and positioning, requiring complex planning over spatial\narrangement. To address this challenge, we introduce SceneGenAgent, an\nLLM-based agent for generating industrial scenes through C# code. SceneGenAgent\nensures precise layout planning through a structured and calculable format,\nlayout verification, and iterative refinement to meet the quantitative\nrequirements of industrial scenarios. Experiment results demonstrate that LLMs\npowered by SceneGenAgent exceed their original performance, reaching up to\n81.0% success rate in real-world industrial scene generation tasks and\neffectively meeting most scene generation requirements. To further enhance\naccessibility, we construct SceneInstruct, a dataset designed for fine-tuning\nopen-source LLMs to integrate into SceneGenAgent. Experiments show that\nfine-tuning open-source LLMs on SceneInstruct yields significant performance\nimprovements, with Llama3.1-70B approaching the capabilities of GPT-4o. Our\ncode and data are available at https://github.com/THUDM/SceneGenAgent .", "published": "2024-10-29 10:01:40", "link": "http://arxiv.org/abs/2410.21909v1", "categories": ["cs.CL", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Sing it, Narrate it: Quality Musical Lyrics Translation", "abstract": "Translating lyrics for musicals presents unique challenges due to the need to\nensure high translation quality while adhering to singability requirements such\nas length and rhyme. Existing song translation approaches often prioritize\nthese singability constraints at the expense of translation quality, which is\ncrucial for musicals. This paper aims to enhance translation quality while\nmaintaining key singability features. Our method consists of three main\ncomponents. First, we create a dataset to train reward models for the automatic\nevaluation of translation quality. Second, to enhance both singability and\ntranslation quality, we implement a two-stage training process with filtering\ntechniques. Finally, we introduce an inference-time optimization framework for\ntranslating entire songs. Extensive experiments, including both automatic and\nhuman evaluations, demonstrate significant improvements over baseline methods\nand validate the effectiveness of each component in our approach.", "published": "2024-10-29 14:23:56", "link": "http://arxiv.org/abs/2410.22066v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "The Impact of Inference Acceleration on Bias of LLMs", "abstract": "Last few years have seen unprecedented advances in capabilities of Large\nLanguage Models (LLMs). These advancements promise to benefit a vast array of\napplication domains. However, due to their immense size, performing inference\nwith LLMs is both costly and slow. Consequently, a plethora of recent work has\nproposed strategies to enhance inference efficiency, e.g., quantization,\npruning, and caching. These acceleration strategies reduce the inference cost\nand latency, often by several factors, while maintaining much of the predictive\nperformance measured via common benchmarks. In this work, we explore another\ncritical aspect of LLM performance: demographic bias in model generations due\nto inference acceleration optimizations. Using a wide range of metrics, we\nprobe bias in model outputs from a number of angles. Analysis of outputs before\nand after inference acceleration shows significant change in bias. Worryingly,\nthese bias effects are complex and unpredictable. A combination of an\nacceleration strategy and bias type may show little bias change in one model\nbut may lead to a large effect in another. Our results highlight a need for\nin-depth and case-by-case evaluation of model bias after it has been modified\nto accelerate inference.", "published": "2024-10-29 15:19:13", "link": "http://arxiv.org/abs/2410.22118v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Robust and Unbounded Length Generalization in Autoregressive\n  Transformer-Based Text-to-Speech", "abstract": "Autoregressive (AR) Transformer-based sequence models are known to have\ndifficulty generalizing to sequences longer than those seen during training.\nWhen applied to text-to-speech (TTS), these models tend to drop or repeat words\nor produce erratic output, especially for longer utterances. In this paper, we\nintroduce enhancements aimed at AR Transformer-based encoder-decoder TTS\nsystems that address these robustness and length generalization issues. Our\napproach uses an alignment mechanism to provide cross-attention operations with\nrelative location information. The associated alignment position is learned as\na latent property of the model via backpropagation and requires no external\nalignment information during training. While the approach is tailored to the\nmonotonic nature of TTS input-output alignment, it is still able to benefit\nfrom the flexible modeling power of interleaved multi-head self- and\ncross-attention operations. A system incorporating these improvements, which we\ncall Very Attentive Tacotron, matches the naturalness and expressiveness of a\nbaseline T5-based TTS system, while eliminating problems with repeated or\ndropped words and enabling generalization to any practical utterance length.", "published": "2024-10-29 16:17:01", "link": "http://arxiv.org/abs/2410.22179v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ADAM: An Embodied Causal Agent in Open-World Environments", "abstract": "In open-world environments like Minecraft, existing agents face challenges in\ncontinuously learning structured knowledge, particularly causality. These\nchallenges stem from the opacity inherent in black-box models and an excessive\nreliance on prior knowledge during training, which impair their\ninterpretability and generalization capability. To this end, we introduce ADAM,\nAn emboDied causal Agent in Minecraft, that can autonomously navigate the open\nworld, perceive multimodal contexts, learn causal world knowledge, and tackle\ncomplex tasks through lifelong learning. ADAM is empowered by four key\ncomponents: 1) an interaction module, enabling the agent to execute actions\nwhile documenting the interaction processes; 2) a causal model module, tasked\nwith constructing an ever-growing causal graph from scratch, which enhances\ninterpretability and diminishes reliance on prior knowledge; 3) a controller\nmodule, comprising a planner, an actor, and a memory pool, which uses the\nlearned causal graph to accomplish tasks; 4) a perception module, powered by\nmultimodal large language models, which enables ADAM to perceive like a human\nplayer. Extensive experiments show that ADAM constructs an almost perfect\ncausal graph from scratch, enabling efficient task decomposition and execution\nwith strong interpretability. Notably, in our modified Minecraft games where no\nprior knowledge is available, ADAM maintains its performance and shows\nremarkable robustness and generalization capability. ADAM pioneers a novel\nparadigm that integrates causal methods and embodied agents in a synergistic\nmanner. Our project page is at https://opencausalab.github.io/ADAM.", "published": "2024-10-29 16:32:01", "link": "http://arxiv.org/abs/2410.22194v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Fourier Head: Helping Large Language Models Learn Complex Probability\n  Distributions", "abstract": "As the quality of large language models has improved, there has been\nincreased interest in using them to model non-linguistic tokens. For example,\nthe Decision Transformer recasts agentic decision making as a sequence modeling\nproblem, using a decoder-only LLM to model the distribution over the discrete\naction space for an Atari agent. However, when adapting LLMs to non-linguistic\ndomains, it remains unclear if softmax over discrete bins captures the\ncontinuous structure of the tokens and the potentially complex distributions\nneeded for high quality token generation. We introduce a neural network layer,\nconstructed using Fourier series, which we can easily substitute for any linear\nlayer if we want the outputs to have a more continuous structure. We perform\nextensive analysis on synthetic datasets, as well as on large-scale decision\nmaking and time series forecasting tasks. We also provide theoretical evidence\nthat this layer can better learn signal from data while ignoring high-frequency\nnoise. All of our results support the effectiveness of our proposed Fourier\nhead in scenarios where the underlying data distribution has a natural\ncontinuous structure. For example, the Fourier head improves a Decision\nTransformer agent's returns across four benchmark Atari games by as much as\n377%, and increases a state-of-the-art times series foundation model's\nforecasting performance by 3.5% across 20 benchmarks unseen during training.", "published": "2024-10-29 17:27:58", "link": "http://arxiv.org/abs/2410.22269v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SVIP: Towards Verifiable Inference of Open-source Large Language Models", "abstract": "Open-source Large Language Models (LLMs) have recently demonstrated\nremarkable capabilities in natural language understanding and generation,\nleading to widespread adoption across various domains. However, their\nincreasing model sizes render local deployment impractical for individual\nusers, pushing many to rely on computing service providers for inference\nthrough a blackbox API. This reliance introduces a new risk: a computing\nprovider may stealthily substitute the requested LLM with a smaller, less\ncapable model without consent from users, thereby delivering inferior outputs\nwhile benefiting from cost savings. In this paper, we formalize the problem of\nverifiable inference for LLMs. Existing verifiable computing solutions based on\ncryptographic or game-theoretic techniques are either computationally\nuneconomical or rest on strong assumptions. We introduce SVIP, a secret-based\nverifiable LLM inference protocol that leverages intermediate outputs from LLM\nas unique model identifiers. By training a proxy task on these outputs and\nrequiring the computing provider to return both the generated text and the\nprocessed intermediate outputs, users can reliably verify whether the computing\nprovider is acting honestly. In addition, the integration of a secret mechanism\nfurther enhances the security of our protocol. We thoroughly analyze our\nprotocol under multiple strong and adaptive adversarial scenarios. Our\nextensive experiments demonstrate that SVIP is accurate, generalizable,\ncomputationally efficient, and resistant to various attacks. Notably, SVIP\nachieves false negative rates below 5% and false positive rates below 3%, while\nrequiring less than 0.01 seconds per query for verification.", "published": "2024-10-29 17:52:45", "link": "http://arxiv.org/abs/2410.22307v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Task Vectors are Cross-Modal", "abstract": "We investigate the internal representations of vision-and-language models\n(VLMs) and how they encode task representations. We consider tasks specified\nthrough examples or instructions, using either text or image inputs.\nSurprisingly, we find that conceptually similar tasks are mapped to similar\ntask vector representations, regardless of how they are specified. Our findings\nsuggest that to output answers, tokens in VLMs undergo three distinct phases:\ninput, task, and answer, a process which is consistent across different\nmodalities and specifications. The task vectors we identify in VLMs are general\nenough to be derived in one modality (e.g., text) and transferred to another\n(e.g., image). Additionally, we find that ensembling exemplar and instruction\nbased task vectors produce better task representations. Taken together, these\ninsights shed light on the underlying mechanisms of VLMs, particularly their\nability to represent tasks in a shared manner across different modalities and\ntask specifications. Project page:\nhttps://task-vectors-are-cross-modal.github.io.", "published": "2024-10-29 17:59:45", "link": "http://arxiv.org/abs/2410.22330v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Rethinking Code Refinement: Learning to Judge Code Efficiency", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nunderstanding and generating codes. Due to these capabilities, many recent\nmethods are proposed to automatically refine the codes with LLMs. However, we\nshould rethink that the refined codes (from LLMs and even humans) are not\nalways more efficient than their original versions. On the other hand, running\ntwo different versions of codes and comparing them every time is not ideal and\ntime-consuming. Therefore, in this work, we propose a novel method based on the\ncode language model that is trained to judge the efficiency between two\ndifferent codes (generated across humans and machines) by either classifying\nthe superior one or predicting the relative improvement. We validate our method\non multiple programming languages with multiple refinement steps, demonstrating\nthat the proposed method can effectively distinguish between more and less\nefficient versions of code.", "published": "2024-10-29 06:17:37", "link": "http://arxiv.org/abs/2410.22375v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion\n  Models on Rare Concepts with LLM Guidance", "abstract": "State-of-the-art text-to-image (T2I) diffusion models often struggle to\ngenerate rare compositions of concepts, e.g., objects with unusual attributes.\nIn this paper, we show that the compositional generation power of diffusion\nmodels on such rare concepts can be significantly enhanced by the Large\nLanguage Model (LLM) guidance. We start with empirical and theoretical\nanalysis, demonstrating that exposing frequent concepts relevant to the target\nrare concepts during the diffusion sampling process yields more accurate\nconcept composition. Based on this, we propose a training-free approach, R2F,\nthat plans and executes the overall rare-to-frequent concept guidance\nthroughout the diffusion inference by leveraging the abundant semantic\nknowledge in LLMs. Our framework is flexible across any pre-trained diffusion\nmodels and LLMs, and can be seamlessly integrated with the region-guided\ndiffusion approaches. Extensive experiments on three datasets, including our\nnewly proposed benchmark, RareBench, containing various prompts with rare\ncompositions of concepts, R2F significantly surpasses existing models including\nSD3.0 and FLUX by up to 28.1%p in T2I alignment. Code is available at\nhttps://github.com/krafton-ai/Rare-to-Frequent.", "published": "2024-10-29 07:43:39", "link": "http://arxiv.org/abs/2410.22376v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "A Closer Look at Neural Codec Resynthesis: Bridging the Gap between\n  Codec and Waveform Generation", "abstract": "Neural Audio Codecs, initially designed as a compression technique, have\ngained more attention recently for speech generation. Codec models represent\neach audio frame as a sequence of tokens, i.e., discrete embeddings. The\ndiscrete and low-frequency nature of neural codecs introduced a new way to\ngenerate speech with token-based models. As these tokens encode information at\nvarious levels of granularity, from coarse to fine, most existing works focus\non how to better generate the coarse tokens. In this paper, we focus on an\nequally important but often overlooked question: How can we better resynthesize\nthe waveform from coarse tokens? We point out that both the choice of learning\ntarget and resynthesis approach have a dramatic impact on the generated audio\nquality. Specifically, we study two different strategies based on token\nprediction and regression, and introduce a new method based on Schr\\\"odinger\nBridge. We examine how different design choices affect machine and human\nperception.", "published": "2024-10-29 18:29:39", "link": "http://arxiv.org/abs/2410.22448v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration\n  and Evaluation using Novel Metrics and Dataset", "abstract": "Advancements in Large Language Models (LLMs) are revolutionizing the\ndevelopment of autonomous agentic systems by enabling dynamic, context-aware\ntask decomposition and automated tool selection. These sophisticated systems\npossess significant automation potential across various industries, managing\ncomplex tasks, interacting with external systems to enhance knowledge, and\nexecuting actions independently. This paper presents three primary\ncontributions to advance this field:\n  - Advanced Agentic Framework: A system that handles multi-hop queries,\ngenerates and executes task graphs, selects appropriate tools, and adapts to\nreal-time changes.\n  - Novel Evaluation Metrics: Introduction of Node F1 Score, Structural\nSimilarity Index (SSI), and Tool F1 Score to comprehensively assess agentic\nsystems.\n  - Specialized Dataset: Development of an AsyncHow-based dataset for analyzing\nagent behavior across different task complexities.\n  Our findings reveal that asynchronous and dynamic task graph decomposition\nsignificantly enhances system responsiveness and scalability, particularly for\ncomplex, multi-step tasks. Detailed analysis shows that structural and\nnode-level metrics are crucial for sequential tasks, while tool-related metrics\nare more important for parallel tasks. Specifically, the Structural Similarity\nIndex (SSI) is the most significant predictor of performance in sequential\ntasks, and the Tool F1 Score is essential for parallel tasks. These insights\nhighlight the need for balanced evaluation methods that capture both structural\nand operational dimensions of agentic systems. Additionally, our evaluation\nframework, validated through empirical analysis and statistical testing,\nprovides valuable insights for improving the adaptability and reliability of\nagentic systems in dynamic environments.", "published": "2024-10-29 18:45:13", "link": "http://arxiv.org/abs/2410.22457v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Attention Speaks Volumes: Localizing and Mitigating Bias in Language\n  Models", "abstract": "We explore the internal mechanisms of how bias emerges in large language\nmodels (LLMs) when provided with ambiguous comparative prompts: inputs that\ncompare or enforce choosing between two or more entities without providing\nclear context for preference. Most approaches for bias mitigation focus on\neither post-hoc analysis or data augmentation. However, these are transient\nsolutions, without addressing the root cause: the model itself. Numerous prior\nworks show the influence of the attention module towards steering generations.\nWe believe that analyzing attention is also crucial for understanding bias, as\nit provides insight into how the LLM distributes its focus across different\nentities and how this contributes to biased decisions. To this end, we first\nintroduce a metric to quantify the LLM's preference for one entity over\nanother. We then propose $\\texttt{ATLAS}$ (Attention-based Targeted Layer\nAnalysis and Scaling), a technique to localize bias to specific layers of the\nLLM by analyzing attention scores and then reduce bias by scaling attention in\nthese biased layers. To evaluate our method, we conduct experiments across 3\ndatasets (BBQ, Crows-Pairs, and WinoGender) using $\\texttt{GPT-2 XL}$ (1.5B),\n$\\texttt{GPT-J}$ (6B), $\\texttt{LLaMA-2}$ (7B) and $\\texttt{LLaMA-3}$ (8B). Our\nexperiments demonstrate that bias is concentrated in the later layers,\ntypically around the last third. We also show how $\\texttt{ATLAS}$ effectively\nmitigates bias through targeted interventions without compromising downstream\nperformance and an average increase of only 0.82% in perplexity when the\nintervention is applied. We see an average improvement of 0.28 points in the\nbias score across all the datasets.", "published": "2024-10-29 20:15:56", "link": "http://arxiv.org/abs/2410.22517v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Auto-Intent: Automated Intent Discovery and Self-Exploration for Large\n  Language Model Web Agents", "abstract": "In this paper, we introduce Auto-Intent, a method to adapt a pre-trained\nlarge language model (LLM) as an agent for a target domain without direct\nfine-tuning, where we empirically focus on web navigation tasks. Our approach\nfirst discovers the underlying intents from target domain demonstrations\nunsupervisedly, in a highly compact form (up to three words). With the\nextracted intents, we train our intent predictor to predict the next intent\ngiven the agent's past observations and actions. In particular, we propose a\nself-exploration approach where top-k probable intent predictions are provided\nas a hint to the pre-trained LLM agent, which leads to enhanced decision-making\ncapabilities. Auto-Intent substantially improves the performance of GPT-{3.5,\n4} and Llama-3.1-{70B, 405B} agents on the large-scale real-website navigation\nbenchmarks from Mind2Web and online navigation tasks from WebArena with its\ncross-benchmark generalization from Mind2Web.", "published": "2024-10-29 21:37:04", "link": "http://arxiv.org/abs/2410.22552v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BENCHAGENTS: Automated Benchmark Creation with Agent Interaction", "abstract": "Evaluations are limited by benchmark availability. As models evolve, there is\na need to create benchmarks that can measure progress on new generative\ncapabilities. However, creating new benchmarks through human annotations is\nslow and expensive, restricting comprehensive evaluations for any capability.\nWe introduce BENCHAGENTS, a framework that methodically leverages large\nlanguage models (LLMs) to automate benchmark creation for complex capabilities\nwhile inherently ensuring data and metric quality. BENCHAGENTS decomposes the\nbenchmark creation process into planning, generation, data verification, and\nevaluation, each of which is executed by an LLM agent. These agents interact\nwith each other and utilize human-in-the-loop feedback from benchmark\ndevelopers to explicitly improve and flexibly control data diversity and\nquality. We use BENCHAGENTS to create benchmarks to evaluate capabilities\nrelated to planning and constraint satisfaction during text generation. We then\nuse these benchmarks to study seven state-of-the-art models and extract new\ninsights on common failure modes and model differences.", "published": "2024-10-29 22:56:18", "link": "http://arxiv.org/abs/2410.22584v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction\n  in LBSN", "abstract": "The fast development of location-based social networks (LBSNs) has led to\nsignificant changes in society, resulting in popular studies of using LBSN data\nfor socioeconomic prediction, e.g., regional population and commercial activity\nestimation. Existing studies design various graphs to model heterogeneous LBSN\ndata, and further apply graph representation learning methods for socioeconomic\nprediction. However, these approaches heavily rely on heuristic ideas and\nexpertise to extract task-relevant knowledge from diverse data, which may not\nbe optimal for specific tasks. Additionally, they tend to overlook the inherent\nrelationships between different indicators, limiting the prediction accuracy.\nMotivated by the remarkable abilities of large language models (LLMs) in\ncommonsense reasoning, embedding, and multi-agent collaboration, in this work,\nwe synergize LLM agents and knowledge graph for socioeconomic prediction. We\nfirst construct a location-based knowledge graph (LBKG) to integrate\nmulti-sourced LBSN data. Then we leverage the reasoning power of LLM agent to\nidentify relevant meta-paths in the LBKG for each type of socioeconomic\nprediction task, and design a semantic-guided attention module for knowledge\nfusion with meta-paths. Moreover, we introduce a cross-task communication\nmechanism to further enhance performance by enabling knowledge sharing across\ntasks at both LLM agent and KG levels. On the one hand, the LLM agents for\ndifferent tasks collaborate to generate more diverse and comprehensive\nmeta-paths. On the other hand, the embeddings from different tasks are\nadaptively merged for better socioeconomic prediction. Experiments on two\ndatasets demonstrate the effectiveness of the synergistic design between LLM\nand KG, providing insights for information sharing across socioeconomic\nprediction tasks.", "published": "2024-10-29 04:03:15", "link": "http://arxiv.org/abs/2411.00028v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Preserving Pre-trained Representation Space: On Effectiveness of\n  Prefix-tuning for Large Multi-modal Models", "abstract": "Recently, we have observed that Large Multi-modal Models (LMMs) are\nrevolutionizing the way machines interact with the world, unlocking new\npossibilities across various multi-modal applications. To adapt LMMs for\ndownstream tasks, parameter-efficient fine-tuning (PEFT) which only trains\nadditional prefix tokens or modules, has gained popularity. Nevertheless, there\nhas been little analysis of how PEFT works in LMMs. In this paper, we delve\ninto the strengths and weaknesses of each tuning strategy, shifting the focus\nfrom the efficiency typically associated with these approaches. We first\ndiscover that model parameter tuning methods such as LoRA and Adapters distort\nthe feature representation space learned during pre-training and limit the full\nutilization of pre-trained knowledge. We also demonstrate that prefix-tuning\nexcels at preserving the representation space, despite its lower performance on\ndownstream tasks. These findings suggest a simple two-step PEFT strategy called\nPrefix-Tuned PEFT (PT-PEFT), which successively performs prefix-tuning and then\nPEFT (i.e., Adapter, LoRA), combines the benefits of both. Experimental results\nshow that PT-PEFT not only improves performance in image captioning and visual\nquestion answering compared to vanilla PEFT methods but also helps preserve the\nrepresentation space of the four pre-trained models.", "published": "2024-10-29 07:55:50", "link": "http://arxiv.org/abs/2411.00029v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "WikiNER-fr-gold: A Gold-Standard NER Corpus", "abstract": "We address in this article the the quality of the WikiNER corpus, a\nmultilingual Named Entity Recognition corpus, and provide a consolidated\nversion of it. The annotation of WikiNER was produced in a semi-supervised\nmanner i.e. no manual verification has been carried out a posteriori. Such\ncorpus is called silver-standard. In this paper we propose WikiNER-fr-gold\nwhich is a revised version of the French proportion of WikiNER. Our corpus\nconsists of randomly sampled 20% of the original French sub-corpus (26,818\nsentences with 700k tokens). We start by summarizing the entity types included\nin each category in order to define an annotation guideline, and then we\nproceed to revise the corpus. Finally we present an analysis of errors and\ninconsistency observed in the WikiNER-fr corpus, and we discuss potential\nfuture work directions.", "published": "2024-10-29 08:00:16", "link": "http://arxiv.org/abs/2411.00030v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Linear Chain Transformation: Expanding Optimization Dynamics for\n  Fine-Tuning Large Language Models", "abstract": "Fine-tuning large language models (LLMs) has become essential for adapting\npretrained models to specific downstream tasks. In this paper, we propose\nLinear Chain Transformation (LinChain), a novel approach that introduces a\nsequence of linear transformations during fine-tuning to enrich optimization\ndynamics. By incorporating multiple linear transformations into the parameter\nupdate process, LinChain expands the effective rank of updates and enhances the\nmodel's ability to learn complex task-specific representations. We demonstrate\nthat this method significantly improves the performance of LLM fine-tuning over\nstate-of-the-art methods by providing more flexible optimization paths during\ntraining, while maintaining the inference efficiency of the resulting model.\nOur experiments on various benchmark tasks show that LinChain leads to better\ngeneralization, fewer learnable parameters, and improved task adaptation,\nmaking it a compelling strategy for LLM fine-tuning.", "published": "2024-10-29 14:07:24", "link": "http://arxiv.org/abs/2411.00039v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NeuroSym-BioCAT: Leveraging Neuro-Symbolic Methods for Biomedical\n  Scholarly Document Categorization and Question Answering", "abstract": "The growing volume of biomedical scholarly document abstracts presents an\nincreasing challenge in efficiently retrieving accurate and relevant\ninformation. To address this, we introduce a novel approach that integrates an\noptimized topic modelling framework, OVB-LDA, with the BI-POP CMA-ES\noptimization technique for enhanced scholarly document abstract categorization.\nComplementing this, we employ the distilled MiniLM model, fine-tuned on\ndomain-specific data, for high-precision answer extraction. Our approach is\nevaluated across three configurations: scholarly document abstract retrieval,\ngold-standard scholarly documents abstract, and gold-standard snippets,\nconsistently outperforming established methods such as RYGH and bio-answer\nfinder. Notably, we demonstrate that extracting answers from scholarly\ndocuments abstracts alone can yield high accuracy, underscoring the sufficiency\nof abstracts for many biomedical queries. Despite its compact size, MiniLM\nexhibits competitive performance, challenging the prevailing notion that only\nlarge, resource-intensive models can handle such complex tasks. Our results,\nvalidated across various question types and evaluation batches, highlight the\nrobustness and adaptability of our method in real-world biomedical\napplications. While our approach shows promise, we identify challenges in\nhandling complex list-type questions and inconsistencies in evaluation metrics.\nFuture work will focus on refining the topic model with more extensive\ndomain-specific datasets, further optimizing MiniLM and utilizing large\nlanguage models (LLM) to improve both precision and efficiency in biomedical\nquestion answering.", "published": "2024-10-29 14:45:12", "link": "http://arxiv.org/abs/2411.00041v1", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CurateGPT: A flexible language-model assisted biocuration tool", "abstract": "Effective data-driven biomedical discovery requires data curation: a\ntime-consuming process of finding, organizing, distilling, integrating,\ninterpreting, annotating, and validating diverse information into a structured\nform suitable for databases and knowledge bases. Accurate and efficient\ncuration of these digital assets is critical to ensuring that they are FAIR,\ntrustworthy, and sustainable. Unfortunately, expert curators face significant\ntime and resource constraints. The rapid pace of new information being\npublished daily is exceeding their capacity for curation. Generative AI,\nexemplified by instruction-tuned large language models (LLMs), has opened up\nnew possibilities for assisting human-driven curation. The design philosophy of\nagents combines the emerging abilities of generative AI with more precise\nmethods. A curator's tasks can be aided by agents for performing reasoning,\nsearching ontologies, and integrating knowledge across external sources, all\nefforts otherwise requiring extensive manual effort. Our LLM-driven annotation\ntool, CurateGPT, melds the power of generative AI together with trusted\nknowledge bases and literature sources. CurateGPT streamlines the curation\nprocess, enhancing collaboration and efficiency in common workflows. Compared\nto direct interaction with an LLM, CurateGPT's agents enable access to\ninformation beyond that in the LLM's training data and they provide direct\nlinks to the data supporting each claim. This helps curators, researchers, and\nengineers scale up curation efforts to keep pace with the ever-increasing\nvolume of scientific data.", "published": "2024-10-29 20:00:04", "link": "http://arxiv.org/abs/2411.00046v1", "categories": ["cs.CL", "cs.AI", "cs.DB", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "Mobility-LLM: Learning Visiting Intentions and Travel Preferences from\n  Human Mobility Data with Large Language Models", "abstract": "Location-based services (LBS) have accumulated extensive human mobility data\non diverse behaviors through check-in sequences. These sequences offer valuable\ninsights into users' intentions and preferences. Yet, existing models analyzing\ncheck-in sequences fail to consider the semantics contained in these sequences,\nwhich closely reflect human visiting intentions and travel preferences, leading\nto an incomplete comprehension. Drawing inspiration from the exceptional\nsemantic understanding and contextual information processing capabilities of\nlarge language models (LLMs) across various domains, we present Mobility-LLM, a\nnovel framework that leverages LLMs to analyze check-in sequences for multiple\ntasks. Since LLMs cannot directly interpret check-ins, we reprogram these\nsequences to help LLMs comprehensively understand the semantics of human\nvisiting intentions and travel preferences. Specifically, we introduce a\nvisiting intention memory network (VIMN) to capture the visiting intentions at\neach record, along with a shared pool of human travel preference prompts (HTPP)\nto guide the LLM in understanding users' travel preferences. These components\nenhance the model's ability to extract and leverage semantic information from\nhuman mobility data effectively. Extensive experiments on four benchmark\ndatasets and three downstream tasks demonstrate that our approach significantly\noutperforms existing models, underscoring the effectiveness of Mobility-LLM in\nadvancing our understanding of human mobility data within LBS contexts.", "published": "2024-10-29 01:58:06", "link": "http://arxiv.org/abs/2411.00823v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SI"], "primary_category": "cs.LG"}
{"title": "DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical\n  Reasoning Robustness of Vision Language Models", "abstract": "The rapid advancements in Vision-Language Models (VLMs) have shown great\npotential in tackling mathematical reasoning tasks that involve visual context.\nUnlike humans who can reliably apply solution steps to similar problems with\nminor modifications, we found that SOTA VLMs like GPT-4o can consistently fail\nin these scenarios, revealing limitations in their mathematical reasoning\ncapabilities. In this paper, we investigate the mathematical reasoning\nrobustness in VLMs and evaluate how well these models perform under different\nvariants of the same question, such as changes in visual numerical values or\nfunction graphs. While several vision-based math benchmarks have been developed\nto assess VLMs' problem-solving capabilities, these benchmarks contain only\nstatic sets of problems and cannot easily evaluate mathematical reasoning\nrobustness. To fill this gap, we introduce DynaMath, a dynamic visual math\nbenchmark designed for in-depth assessment of VLMs. DynaMath includes 501\nhigh-quality, multi-topic seed questions, each represented as a Python program.\nThose programs are carefully designed and annotated to enable the automatic\ngeneration of a much larger set of concrete questions, including many different\ntypes of visual and textual variations. DynaMath allows us to evaluate the\ngeneralization ability of VLMs, by assessing their performance under varying\ninput conditions of a seed question. We evaluated 14 SOTA VLMs with 5,010\ngenerated concrete questions. Our results show that the worst-case model\naccuracy, defined as the percentage of correctly answered seed questions in all\n10 variants, is significantly lower than the average-case accuracy. Our\nanalysis emphasizes the need to study the robustness of VLMs' reasoning\nabilities, and DynaMath provides valuable insights to guide the development of\nmore reliable models for mathematical reasoning.", "published": "2024-10-29 17:29:19", "link": "http://arxiv.org/abs/2411.00836v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Multimodal Quantum Natural Language Processing: A Novel Framework for\n  using Quantum Methods to Analyse Real Data", "abstract": "Despite significant advances in quantum computing across various domains,\nresearch on applying quantum approaches to language compositionality - such as\nmodeling linguistic structures and interactions - remains limited. This gap\nextends to the integration of quantum language data with real-world data from\nsources like images, video, and audio. This thesis explores how quantum\ncomputational methods can enhance the compositional modeling of language\nthrough multimodal data integration. Specifically, it advances Multimodal\nQuantum Natural Language Processing (MQNLP) by applying the Lambeq toolkit to\nconduct a comparative analysis of four compositional models and evaluate their\ninfluence on image-text classification tasks. Results indicate that\nsyntax-based models, particularly DisCoCat and TreeReader, excel in effectively\ncapturing grammatical structures, while bag-of-words and sequential models\nstruggle due to limited syntactic awareness. These findings underscore the\npotential of quantum methods to enhance language modeling and drive\nbreakthroughs as quantum technology evolves.", "published": "2024-10-29 19:03:43", "link": "http://arxiv.org/abs/2411.05023v1", "categories": ["cs.CL", "cs.LG", "quant-ph"], "primary_category": "cs.CL"}
{"title": "Gnothi Seauton: Empowering Faithful Self-Interpretability in Black-Box\n  Transformers", "abstract": "The debate between self-interpretable models and post-hoc explanations for\nblack-box models is central to Explainable AI (XAI). Self-interpretable models,\nsuch as concept-based networks, offer insights by connecting decisions to\nhuman-understandable concepts but often struggle with performance and\nscalability. Conversely, post-hoc methods like Shapley values, while\ntheoretically robust, are computationally expensive and resource-intensive. To\nbridge the gap between these two lines of research, we propose a novel method\nthat combines their strengths, providing theoretically guaranteed\nself-interpretability for black-box models without compromising prediction\naccuracy. Specifically, we introduce a parameter-efficient pipeline,\nAutoGnothi, which integrates a small side network into the black-box model,\nallowing it to generate Shapley value explanations without changing the\noriginal network parameters. This side-tuning approach significantly reduces\nmemory, training, and inference costs, outperforming traditional\nparameter-efficient methods, where full fine-tuning serves as the optimal\nbaseline. AutoGnothi enables the black-box model to predict and explain its\npredictions with minimal overhead. Extensive experiments show that AutoGnothi\noffers accurate explanations for both vision and language tasks, delivering\nsuperior computational efficiency with comparable interpretability.", "published": "2024-10-29 07:35:33", "link": "http://arxiv.org/abs/2410.21815v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.GT"], "primary_category": "cs.LG"}
{"title": "RankUp: Boosting Semi-Supervised Regression with an Auxiliary Ranking\n  Classifier", "abstract": "State-of-the-art (SOTA) semi-supervised learning techniques, such as FixMatch\nand it's variants, have demonstrated impressive performance in classification\ntasks. However, these methods are not directly applicable to regression tasks.\nIn this paper, we present RankUp, a simple yet effective approach that adapts\nexisting semi-supervised classification techniques to enhance the performance\nof regression tasks. RankUp achieves this by converting the original regression\ntask into a ranking problem and training it concurrently with the original\nregression objective. This auxiliary ranking classifier outputs a\nclassification result, thus enabling integration with existing semi-supervised\nclassification methods. Moreover, we introduce regression distribution\nalignment (RDA), a complementary technique that further enhances RankUp's\nperformance by refining pseudo-labels through distribution alignment. Despite\nits simplicity, RankUp, with or without RDA, achieves SOTA results in across a\nrange of regression benchmarks, including computer vision, audio, and natural\nlanguage processing tasks. Our code and log data are open-sourced at\nhttps://github.com/pm25/semi-supervised-regression.", "published": "2024-10-29 15:25:21", "link": "http://arxiv.org/abs/2410.22124v1", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "VL-Cache: Sparsity and Modality-Aware KV Cache Compression for\n  Vision-Language Model Inference Acceleration", "abstract": "Vision-Language Models (VLMs) have demonstrated impressive performance across\na versatile set of tasks. A key challenge in accelerating VLMs is storing and\naccessing the large Key-Value (KV) cache that encodes long visual contexts,\nsuch as images or videos. While existing KV cache compression methods are\neffective for Large Language Models (LLMs), directly migrating them to VLMs\nyields suboptimal accuracy and speedup. To bridge the gap, we propose VL-Cache,\na novel KV cache compression recipe tailored for accelerating VLM inference. In\nthis paper, we first investigate the unique sparsity pattern of VLM attention\nby distinguishing visual and text tokens in prefill and decoding phases. Based\non these observations, we introduce a layer-adaptive sparsity-aware cache\nbudget allocation method that effectively distributes the limited cache budget\nacross different layers, further reducing KV cache size without compromising\naccuracy. Additionally, we develop a modality-aware token scoring policy to\nbetter evaluate the token importance. Empirical results on multiple benchmark\ndatasets demonstrate that retaining only 10% of KV cache achieves accuracy\ncomparable to that with full cache. In a speed benchmark, our method\naccelerates end-to-end latency of generating 100 tokens by up to 2.33x and\nspeeds up decoding by up to 7.08x, while reducing the memory footprint of KV\ncache in GPU by 90%.", "published": "2024-10-29 20:04:34", "link": "http://arxiv.org/abs/2410.23317v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.DC", "cs.PF"], "primary_category": "cs.CV"}
{"title": "Representational learning for an anomalous sound detection system with\n  source separation model", "abstract": "The detection of anomalous sounds in machinery operation presents a\nsignificant challenge due to the difficulty in generalizing anomalous acoustic\npatterns. This task is typically approached as an unsupervised learning or\nnovelty detection problem, given the complexities associated with the\nacquisition of comprehensive anomalous acoustic data. Conventional\nmethodologies for training anomalous sound detection systems primarily employ\nauto-encoder architectures or representational learning with auxiliary tasks.\nHowever, both approaches have inherent limitations. Auto-encoder structures are\nconstrained to utilizing only the target machine's operational sounds, while\ntraining with auxiliary tasks, although capable of incorporating diverse\nacoustic inputs, may yield representations that lack correlation with the\ncharacteristic acoustic signatures of anomalous conditions. We propose a\ntraining method based on the source separation model (CMGAN) that aims to\nisolate non-target machine sounds from a mixture of target and non-target class\nacoustic signals. This approach enables the effective utilization of diverse\nmachine sounds and facilitates the training of complex neural network\narchitectures with limited sample sizes. Our experimental results demonstrate\nthat the proposed method yields better performance compared to both\nconventional auto-encoder training approaches and source separation techniques\nthat focus on isolating target machine signals. Moreover, our experimental\nresults demonstrate that the proposed method exhibits the potential for\nenhanced representation learning as the quantity of non-target data increases,\neven while maintaining a constant volume of target class data.", "published": "2024-10-29 07:05:48", "link": "http://arxiv.org/abs/2410.21797v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Timbre Difference Capturing in Anomalous Sound Detection", "abstract": "This paper proposes a framework of explaining anomalous machine sounds in the\ncontext of anomalous sound detection~(ASD). While ASD has been extensively\nexplored, identifying how anomalous sounds differ from normal sounds is also\nbeneficial for machine condition monitoring. However, existing sound difference\ncaptioning methods require anomalous sounds for training, which is impractical\nin typical machine condition monitoring settings where such sounds are\nunavailable. To solve this issue, we propose a new strategy for explaining\nanomalous differences that does not require anomalous sounds for training.\nSpecifically, we introduce a framework that explains differences in predefined\ntimbre attributes instead of using free-form text captions. Objective metrics\nof timbre attributes can be computed using timbral models developed through\npsycho-acoustical research, enabling the estimation of how and what timbre\nattributes have changed from normal sounds without training machine learning\nmodels. Additionally, to accurately determine timbre differences regardless of\nvariations in normal training data, we developed a method that jointly conducts\nanomalous sound detection and timbre difference estimation based on a k-nearest\nneighbors method in an audio embedding space. Evaluation using the MIMII DG\ndataset demonstrated the effectiveness of the proposed method.", "published": "2024-10-29 13:30:35", "link": "http://arxiv.org/abs/2410.22033v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Retrieval-Augmented Approach for Unsupervised Anomalous Sound Detection\n  and Captioning without Model Training", "abstract": "This paper proposes a method for unsupervised anomalous sound detection\n(UASD) and captioning the reason for detection. While there is a method that\ncaptions the difference between given normal and anomalous sound pairs, it is\nassumed to be trained and used separately from the UASD model. Therefore, the\nobtained caption can be irrelevant to the differences that the UASD model\ncaptured. In addition, it requires many caption labels representing differences\nbetween anomalous and normal sounds for model training. The proposed method\nemploys a retrieval-augmented approach for captioning of anomalous sounds.\nDifference captioning in the embedding space output by the pre-trained CLAP\n(contrastive language-audio pre-training) model makes the anomalous sound\ndetection results consistent with the captions and does not require training.\nExperiments based on subjective evaluation and a sample-wise analysis of the\noutput captions demonstrate the effectiveness of the proposed method.", "published": "2024-10-29 14:05:57", "link": "http://arxiv.org/abs/2410.22056v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Tutorial on Clinical Speech AI Development: From Data Collection to\n  Model Validation", "abstract": "There has been a surge of interest in leveraging speech as a marker of health\nfor a wide spectrum of conditions. The underlying premise is that any\nneurological, mental, or physical deficits that impact speech production can be\nobjectively assessed via automated analysis of speech. Recent advances in\nspeech-based Artificial Intelligence (AI) models for diagnosing and tracking\nmental health, cognitive, and motor disorders often use supervised learning,\nsimilar to mainstream speech technologies like recognition and verification.\nHowever, clinical speech AI has distinct challenges, including the need for\nspecific elicitation tasks, small available datasets, diverse speech\nrepresentations, and uncertain diagnostic labels. As a result, application of\nthe standard supervised learning paradigm may lead to models that perform well\nin controlled settings but fail to generalize in real-world clinical\ndeployments. With translation into real-world clinical scenarios in mind, this\ntutorial paper provides an overview of the key components required for robust\ndevelopment of clinical speech AI. Specifically, this paper will cover the\ndesign of speech elicitation tasks and protocols most appropriate for different\nclinical conditions, collection of data and verification of hardware,\ndevelopment and validation of speech representations designed to measure\nclinical constructs of interest, development of reliable and robust clinical\nprediction models, and ethical and participant considerations for clinical\nspeech AI. The goal is to provide comprehensive guidance on building models\nwhose inputs and outputs link to the more interpretable and clinically\nmeaningful aspects of speech, that can be interrogated and clinically validated\non clinical datasets, and that adhere to ethical, privacy, and security\nconsiderations by design.", "published": "2024-10-29 00:58:15", "link": "http://arxiv.org/abs/2410.21640v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "RDSinger: Reference-based Diffusion Network for Singing Voice Synthesis", "abstract": "Singing voice synthesis (SVS) aims to produce high-fidelity singing audio\nfrom music scores, requiring a detailed understanding of notes, pitch, and\nduration, unlike text-to-speech tasks. Although diffusion models have shown\nexceptional performance in various generative tasks like image and video\ncreation, their application in SVS is hindered by time complexity and the\nchallenge of capturing acoustic features, particularly during pitch\ntransitions. Some networks learn from the prior distribution and use the\ncompressed latent state as a better start in the diffusion model, but the\ndenoising step doesn't consistently improve quality over the entire duration.\nWe introduce RDSinger, a reference-based denoising diffusion network that\ngenerates high-quality audio for SVS tasks. Our approach is inspired by Animate\nAnyone, a diffusion image network that maintains intricate appearance features\nfrom reference images. RDSinger utilizes FastSpeech2 mel-spectrogram as a\nreference to mitigate denoising step artifacts. Additionally, existing models\ncould be influenced by misleading information on the compressed latent state\nduring pitch transitions. We address this issue by applying Gaussian blur on\npartial reference mel-spectrogram and adjusting loss weights in these regions.\nExtensive ablation studies demonstrate the efficiency of our method.\nEvaluations on OpenCpop, a Chinese singing dataset, show that RDSinger\noutperforms current state-of-the-art SVS methods in performance.", "published": "2024-10-29 01:01:18", "link": "http://arxiv.org/abs/2410.21641v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Application of Audio Fingerprinting Techniques for Real-Time Scalable\n  Speech Retrieval and Speech Clusterization", "abstract": "Audio fingerprinting techniques have seen great advances in recent years,\nenabling accurate and fast audio retrieval even in conditions when the queried\naudio sample has been highly deteriorated or recorded in noisy conditions.\nExpectedly, most of the existing work is centered around music, with popular\nmusic identification services such as Apple's Shazam or Google's Now Playing\ndesigned for individual audio recognition on mobile devices. However, the\nspectral content of speech differs from that of music, necessitating\nmodifications to current audio fingerprinting approaches. This paper offers\nfresh insights into adapting existing techniques to address the specialized\nchallenge of speech retrieval in telecommunications and cloud communications\nplatforms. The focus is on achieving rapid and accurate audio retrieval in\nbatch processing instead of facilitating single requests, typically on a\ncentralized server. Moreover, the paper demonstrates how this approach can be\nutilized to support audio clustering based on speech transcripts without\nundergoing actual speech-to-text conversion. This optimization enables\nsignificantly faster processing without the need for GPU computing, a\nrequirement for real-time operation that is typically associated with\nstate-of-the-art speech-to-text tools.", "published": "2024-10-29 09:11:28", "link": "http://arxiv.org/abs/2410.21876v1", "categories": ["cs.IR", "cs.SD", "eess.AS", "H.3"], "primary_category": "cs.IR"}
{"title": "Semi-Supervised Self-Learning Enhanced Music Emotion Recognition", "abstract": "Music emotion recognition (MER) aims to identify the emotions conveyed in a\ngiven musical piece. However, currently, in the field of MER, the available\npublic datasets have limited sample sizes. Recently, segment-based methods for\nemotion-related tasks have been proposed, which train backbone networks on\nshorter segments instead of entire audio clips, thereby naturally augmenting\ntraining samples without requiring additional resources. Then, the predicted\nsegment-level results are aggregated to obtain the entire song prediction. The\nmost commonly used method is that the segment inherits the label of the clip\ncontaining it, but music emotion is not constant during the whole clip. Doing\nso will introduce label noise and make the training easy to overfit. To handle\nthe noisy label issue, we propose a semi-supervised self-learning (SSSL)\nmethod, which can differentiate between samples with correct and incorrect\nlabels in a self-learning manner, thus effectively utilizing the augmented\nsegment-level data. Experiments on three public emotional datasets demonstrate\nthat the proposed method can achieve better or comparable performance.", "published": "2024-10-29 09:42:07", "link": "http://arxiv.org/abs/2410.21897v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fast and High-Quality Auto-Regressive Speech Synthesis via Speculative\n  Decoding", "abstract": "The auto-regressive architecture, like GPTs, is widely used in modern\nText-to-Speech (TTS) systems. However, it incurs substantial inference time,\nparticularly due to the challenges in the next-token prediction posed by\nlengthy sequences of speech tokens. In this work, we introduce VADUSA, one of\nthe first approaches to accelerate auto-regressive TTS through speculative\ndecoding. Our results show that VADUSA not only significantly improves\ninference speed but also enhances performance by incorporating draft heads to\npredict future speech content auto-regressively. Furthermore, the inclusion of\na tolerance mechanism during sampling accelerates inference without\ncompromising quality. Our approach demonstrates strong generalization across\nlarge datasets and various types of speech tokens.", "published": "2024-10-29 11:12:01", "link": "http://arxiv.org/abs/2410.21951v2", "categories": ["eess.AS", "cs.AI", "cs.SD", "68T07"], "primary_category": "eess.AS"}
{"title": "CHORDONOMICON: A Dataset of 666,000 Songs and their Chord Progressions", "abstract": "Chord progressions encapsulate important information about music, pertaining\nto its structure and conveyed emotions. They serve as the backbone of musical\ncomposition, and in many cases, they are the sole information required for a\nmusician to play along and follow the music. Despite their importance, chord\nprogressions as a data domain remain underexplored. There is a lack of\nlarge-scale datasets suitable for deep learning applications, and limited\nresearch exploring chord progressions as an input modality. In this work, we\npresent Chordonomicon, a dataset of over 666,000 songs and their chord\nprogressions, annotated with structural parts, genre, and release date -\ncreated by scraping various sources of user-generated progressions and\nassociated metadata. We demonstrate the practical utility of the Chordonomicon\ndataset for classification and generation tasks, and discuss its potential to\nprovide valuable insights to the research community. Chord progressions are\nunique in their ability to be represented in multiple formats (e.g. text,\ngraph) and the wealth of information chords convey in given contexts, such as\ntheir harmonic function . These characteristics make the Chordonomicon an ideal\ntestbed for exploring advanced machine learning techniques, including\ntransformers, graph machine learning, and hybrid systems that combine knowledge\nrepresentation and machine learning.", "published": "2024-10-29 13:53:09", "link": "http://arxiv.org/abs/2410.22046v3", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "USpeech: Ultrasound-Enhanced Speech with Minimal Human Effort via\n  Cross-Modal Synthesis", "abstract": "Speech enhancement is crucial in human-computer interaction, especially for\nubiquitous devices. Ultrasound-based speech enhancement has emerged as an\nattractive choice because of its superior ubiquity and performance. However,\ninevitable interference from unexpected and unintended sources during\naudio-ultrasound data acquisition makes existing solutions rely heavily on\nhuman effort for data collection and processing. This leads to significant data\nscarcity that limits the full potential of ultrasound-based speech enhancement.\nTo address this, we propose USpeech, a cross-modal ultrasound synthesis\nframework for speech enhancement with minimal human effort. At its core is a\ntwo-stage framework that establishes correspondence between visual and\nultrasonic modalities by leveraging audible audio as a bridge. This approach\novercomes challenges from the lack of paired video-ultrasound datasets and the\ninherent heterogeneity between video and ultrasound data. Our framework\nincorporates contrastive video-audio pre-training to project modalities into a\nshared semantic space and employs an audio-ultrasound encoder-decoder for\nultrasound synthesis. We then present a speech enhancement network that\nenhances speech in the time-frequency domain and recovers the clean speech\nwaveform via a neural vocoder. Comprehensive experiments show USpeech achieves\nremarkable performance using synthetic ultrasound data comparable to physical\ndata, significantly outperforming state-of-the-art ultrasound-based speech\nenhancement baselines. USpeech is open-sourced at\nhttps://github.com/aiot-lab/USpeech/.", "published": "2024-10-29 14:34:41", "link": "http://arxiv.org/abs/2410.22076v1", "categories": ["cs.SD", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Leveraging Reverberation and Visual Depth Cues for Sound Event\n  Localization and Detection with Distance Estimation", "abstract": "This report describes our systems submitted for the DCASE2024 Task 3\nchallenge: Audio and Audiovisual Sound Event Localization and Detection with\nSource Distance Estimation (Track B). Our main model is based on the\naudio-visual (AV) Conformer, which processes video and audio embeddings\nextracted with ResNet50 and with an audio encoder pre-trained on SELD,\nrespectively. This model outperformed the audio-visual baseline of the\ndevelopment set of the STARSS23 dataset by a wide margin, halving its DOAE and\nimproving the F1 by more than 3x. Our second system performs a temporal\nensemble from the outputs of the AV-Conformer. We then extended the model with\nfeatures for distance estimation, such as direct and reverberant signal\ncomponents extracted from the omnidirectional audio channel, and depth maps\nextracted from the video frames. While the new system improved the RDE of our\nprevious model by about 3 percentage points, it achieved a lower F1 score. This\nmay be caused by sound classes that rarely appear in the training set and that\nthe more complex system does not detect, as analysis can determine. To overcome\nthis problem, our fourth and final system consists of an ensemble strategy\ncombining the predictions of the other three. Many opportunities to refine the\nsystem and training strategy can be tested in future ablation experiments, and\nlikely achieve incremental performance gains for this audio-visual task.", "published": "2024-10-29 17:28:43", "link": "http://arxiv.org/abs/2410.22271v1", "categories": ["eess.AS", "cs.AI", "eess.IV", "eess.SP"], "primary_category": "eess.AS"}
