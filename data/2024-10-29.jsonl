{"title": "Fast Deep Hedging with Second-Order Optimization", "abstract": "Hedging exotic options in presence of market frictions is an important risk\nmanagement task. Deep hedging can solve such hedging problems by training\nneural network policies in realistic simulated markets. Training these neural\nnetworks may be delicate and suffer from slow convergence, particularly for\noptions with long maturities and complex sensitivities to market parameters. To\naddress this, we propose a second-order optimization scheme for deep hedging.\nWe leverage pathwise differentiability to construct a curvature matrix, which\nwe approximate as block-diagonal and Kronecker-factored to efficiently\nprecondition gradients. We evaluate our method on a challenging and practically\nimportant problem: hedging a cliquet option on a stock with stochastic\nvolatility by trading in the spot and vanilla options. We find that our\nsecond-order scheme can optimize the policy in 1/4 of the number of steps that\nstandard adaptive moment-based optimization takes.", "published": "2024-10-29 22:17:52", "link": "http://arxiv.org/abs/2410.22568v1", "categories": ["q-fin.RM", "cs.LG", "q-fin.CP"], "primary_category": "q-fin.RM"}
{"title": "Evaluating utility in synthetic banking microdata applications", "abstract": "Financial regulators such as central banks collect vast amounts of data, but\naccess to the resulting fine-grained banking microdata is severely restricted\nby banking secrecy laws. Recent developments have resulted in mechanisms that\ngenerate faithful synthetic data, but current evaluation frameworks lack a\nfocus on the specific challenges of banking institutions and microdata. We\ndevelop a framework that considers the utility and privacy requirements of\nregulators, and apply this to financial usage indices, term deposit yield\ncurves, and credit card transition matrices. Using the Central Bank of\nParaguay's data, we provide the first implementation of synthetic banking\nmicrodata using a central bank's collected information, with the resulting\nsynthetic datasets for all three domain applications being publicly available\nand featuring information not yet released in statistical disclosure. We find\nthat applications less susceptible to post-processing information loss, which\nare based on frequency tables, are particularly suited for this approach, and\nthat marginal-based inference mechanisms to outperform generative adversarial\nnetwork models for these applications. Our results demonstrate that synthetic\ndata generation is a promising privacy-enhancing technology for financial\nregulators seeking to complement their statistical disclosure, while\nhighlighting the crucial role of evaluating such endeavors in terms of utility\nand privacy requirements.", "published": "2024-10-29 20:20:05", "link": "http://arxiv.org/abs/2410.22519v1", "categories": ["q-fin.CP", "cs.LG", "90B90, 91B82, 62P20"], "primary_category": "q-fin.CP"}
{"title": "Schur Complementary Allocation: A Unification of Hierarchical Risk Parity and Minimum Variance Portfolios", "abstract": "Despite many attempts to make optimization-based portfolio construction in\nthe spirit of Markowitz robust and approachable, it is far from universally\nadopted. Meanwhile, the collection of more heuristic divide-and-conquer\napproaches was revitalized by Lopez de Prado where Hierarchical Risk Parity\n(HRP) was introduced. This paper reveals the hidden connection between these\nseemingly disparate approaches.", "published": "2024-10-29 22:16:40", "link": "http://arxiv.org/abs/2411.05807v1", "categories": ["q-fin.PM", "q-fin.MF", "91G10", "J.4"], "primary_category": "q-fin.PM"}
{"title": "Applications of the Second-Order Esscher Pricing in Risk Management", "abstract": "This paper explores the application and significance of the second-order\nEsscher pricing model in option pricing and risk management. We split the study\ninto two main parts. First, we focus on the constant jump diffusion (CJD) case,\nanalyzing the behavior of option prices as a function of the second-order\nparameter and the resulting pricing intervals. Using real data, we perform a\ndynamic delta hedging strategy, illustrating how risk managers can determine an\ninterval of value-at-risks (VaR) and expected shortfalls (ES), granting\nflexibility in pricing based on additional information. We compare our pricing\ninterval to other jump-diffusion models, showing its comprehensive risk factor\nincorporation. The second part extends the second-order Esscher pricing to more\ncomplex models, including the Merton jump-diffusion, Kou's Double Exponential\njump-diffusion, and the Variance Gamma model. We derive option prices using the\nfast Fourier transform (FFT) method and provide practical formulas for European\ncall and put options under these models.", "published": "2024-10-29 01:31:23", "link": "http://arxiv.org/abs/2410.21649v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "The VIX as Stochastic Volatility for Corporate Bonds", "abstract": "Classic stochastic volatility models assume volatility is unobservable. We\nuse the Volatility Index: S&P 500 VIX to observe it, to easier fit the model.\nWe apply it to corporate bonds. We fit autoregression for corporate rates and\nfor risk spreads between these rates and Treasury rates. Next, we divide\nresiduals by VIX. Our main idea is such division makes residuals closer to the\nideal case of a Gaussian white noise. This is remarkable, since these residuals\nand VIX come from separate market segments. Similarly, we model corporate bond\nreturns as a linear function of rates and rate changes. Our article has two\nmain parts: Moody's AAA and BAA spreads; Bank of America investment-grade and\nhigh-yield rates, spreads, and returns. We analyze long-term stability of these\nmodels.", "published": "2024-10-29 19:41:43", "link": "http://arxiv.org/abs/2410.22498v5", "categories": ["q-fin.ST", "stat.AP", "62J05, 62M10, 91B70, 91G30"], "primary_category": "q-fin.ST"}
{"title": "Log Heston Model for Monthly Average VIX", "abstract": "We model time series of VIX (monthly average) and monthly stock index\nreturns. We use log-Heston model: logarithm of VIX is modeled as an\nautoregression of order 1. Our main insight is that normalizing monthly stock\nindex returns (dividing them by VIX) makes them much closer to independent\nidentically distributed Gaussian. The resulting model is mean-reverting, and\nthe innovations are non-Gaussian. The combined stochastic volatility model fits\nwell, and captures Pareto-like tails of real-world stock market returns. This\nworks for small and large stock indices, for both price and total returns.", "published": "2024-10-29 19:04:37", "link": "http://arxiv.org/abs/2410.22471v1", "categories": ["q-fin.ST", "stat.AP", "60E99, 60G50, 62E99, 62J05, 62M10, 62P05, 91G15"], "primary_category": "q-fin.ST"}
{"title": "Joint Estimation of Conditional Mean and Covariance for Unbalanced Panels", "abstract": "We develop a nonparametric, kernel-based joint estimator for conditional mean\nand covariance matrices in large and unbalanced panels. The estimator is\nsupported by rigorous consistency results and finite-sample guarantees,\nensuring its reliability for empirical applications. We apply it to an\nextensive panel of monthly US stock excess returns from 1962 to 2021, using\nmacroeconomic and firm-specific covariates as conditioning variables. The\nestimator effectively captures time-varying cross-sectional dependencies,\ndemonstrating robust statistical and economic performance. We find that\nidiosyncratic risk explains, on average, more than 75% of the cross-sectional\nvariance.", "published": "2024-10-29 08:42:22", "link": "http://arxiv.org/abs/2410.21858v5", "categories": ["stat.ME", "cs.LG", "q-fin.ST", "stat.ML", "(primary) 62G05 (secondary) 62G20, 46E40, 46E22"], "primary_category": "stat.ME"}
{"title": "Robust Graph Neural Networks for Stability Analysis in Dynamic Networks", "abstract": "In the current context of accelerated globalization and digitalization, the\ncomplexity and uncertainty of financial markets are increasing, and the\nidentification and prevention of economic risks have become a key link in\nmaintaining the stability of the financial system. Traditional risk\nidentification methods often have limitations because they are difficult to\ncope with the multi-level and dynamically changing complex relationships in\nfinancial networks. With the rapid development of financial technology, graph\nneural network (GNN) technology, as an emerging deep learning method, has\ngradually shown great potential in the field of financial risk management. GNN\ncan map transaction behaviors, financial institutions, individuals, and their\ninteractive relationships in financial networks into graph structures, and\neffectively capture potential patterns and abnormal signals in financial data\nthrough embedded representation learning. Using this technology, financial\ninstitutions can extract valuable information from complex transaction\nnetworks, identify hidden dangers or abnormal behaviors that may cause systemic\nrisks in a timely manner, optimize decision-making processes, and improve the\naccuracy of risk warnings. This paper explores the economic risk identification\nalgorithm based on the GNN algorithm, aiming to provide financial institutions\nand regulators with more intelligent technical tools to help maintain the\nsecurity and stability of the financial market. Improving the efficiency of\neconomic risk identification through innovative technical means is expected to\nfurther enhance the risk resistance of the financial system and lay the\nfoundation for building a robust global financial system.", "published": "2024-10-29 06:11:36", "link": "http://arxiv.org/abs/2411.11848v1", "categories": ["q-fin.ST", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "FinVision: A Multi-Agent Framework for Stock Market Prediction", "abstract": "Financial trading has been a challenging task, as it requires the integration\nof vast amounts of data from various modalities. Traditional deep learning and\nreinforcement learning methods require large training data and often involve\nencoding various data types into numerical formats for model input, which\nlimits the explainability of model behavior. Recently, LLM-based agents have\ndemonstrated remarkable advancements in handling multi-modal data, enabling\nthem to execute complex, multi-step decision-making tasks while providing\ninsights into their thought processes. This research introduces a multi-modal\nmulti-agent system designed specifically for financial trading tasks. Our\nframework employs a team of specialized LLM-based agents, each adept at\nprocessing and interpreting various forms of financial data, such as textual\nnews reports, candlestick charts, and trading signal charts. A key feature of\nour approach is the integration of a reflection module, which conducts analyses\nof historical trading signals and their outcomes. This reflective process is\ninstrumental in enhancing the decision-making capabilities of the system for\nfuture trading scenarios. Furthermore, the ablation studies indicate that the\nvisual reflection module plays a crucial role in enhancing the decision-making\ncapabilities of our framework.", "published": "2024-10-29 06:02:28", "link": "http://arxiv.org/abs/2411.08899v1", "categories": ["q-fin.TR", "cs.AI"], "primary_category": "q-fin.TR"}
