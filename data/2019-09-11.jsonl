{"title": "Dynamic Fusion: Attentional Language Model for Neural Machine\n  Translation", "abstract": "Neural Machine Translation (NMT) can be used to generate fluent output. As\nsuch, language models have been investigated for incorporation with NMT. In\nprior investigations, two models have been used: a translation model and a\nlanguage model. The translation model's predictions are weighted by the\nlanguage model with a hand-crafted ratio in advance. However, these approaches\nfail to adopt the language model weighting with regard to the translation\nhistory. In another line of approach, language model prediction is incorporated\ninto the translation model by jointly considering source and target\ninformation. However, this line of approach is limited because it largely\nignores the adequacy of the translation output.\n  Accordingly, this work employs two mechanisms, the translation model and the\nlanguage model, with an attentive architecture to the language model as an\nauxiliary element of the translation model. Compared with previous work in\nEnglish--Japanese machine translation using a language model, the experimental\nresults obtained with the proposed Dynamic Fusion mechanism improve BLEU and\nRank-based Intuitive Bilingual Evaluation Scores (RIBES) scores. Additionally,\nin the analyses of the attention and predictivity of the language model, the\nDynamic Fusion mechanism allows predictive language modeling that conforms to\nthe appropriate grammatical structure.", "published": "2019-09-11 07:14:58", "link": "http://arxiv.org/abs/1909.04879v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comprehensive Analysis of Aspect Term Extraction Methods using Various\n  Text Embeddings", "abstract": "Recently, a variety of model designs and methods have blossomed in the\ncontext of the sentiment analysis domain. However, there is still a lack of\nwide and comprehensive studies of aspect-based sentiment analysis (ABSA). We\nwant to fill this gap and propose a comparison with ablation analysis of aspect\nterm extraction using various text embedding methods. We particularly focused\non architectures based on long short-term memory (LSTM) with optional\nconditional random field (CRF) enhancement using different pre-trained word\nembeddings. Moreover, we analyzed the influence on the performance of extending\nthe word vectorization step with character embedding. The experimental results\non SemEval datasets revealed that not only does bi-directional long short-term\nmemory (BiLSTM) outperform regular LSTM, but also word embedding coverage and\nits source highly affect aspect detection performance. An additional CRF layer\nconsistently improves the results as well.", "published": "2019-09-11 08:40:16", "link": "http://arxiv.org/abs/1909.04917v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Proposal Towards a Personalized Knowledge-powered Self-play Based\n  Ensemble Dialog System", "abstract": "This is the application document for the 2019 Amazon Alexa competition. We\ngive an overall vision of our conversational experience, as well as a sample\nconversation that we would like our dialog system to achieve by the end of the\ncompetition. We believe personalization, knowledge, and self-play are important\ncomponents towards better chatbots. These are further highlighted by our\ndetailed system architecture proposal and novelty section. Finally, we describe\nhow we would ensure an engaging experience, how this research would impact the\nfield, and related work.", "published": "2019-09-11 12:53:01", "link": "http://arxiv.org/abs/1909.05016v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Getting Gender Right in Neural Machine Translation", "abstract": "Speakers of different languages must attend to and encode strikingly\ndifferent aspects of the world in order to use their language correctly (Sapir,\n1921; Slobin, 1996). One such difference is related to the way gender is\nexpressed in a language. Saying \"I am happy\" in English, does not encode any\nadditional knowledge of the speaker that uttered the sentence. However, many\nother languages do have grammatical gender systems and so such knowledge would\nbe encoded. In order to correctly translate such a sentence into, say, French,\nthe inherent gender information needs to be retained/recovered. The same\nsentence would become either \"Je suis heureux\", for a male speaker or \"Je suis\nheureuse\" for a female one. Apart from morphological agreement, demographic\nfactors (gender, age, etc.) also influence our use of language in terms of word\nchoices or even on the level of syntactic constructions (Tannen, 1991;\nPennebaker et al., 2003). We integrate gender information into NMT systems. Our\ncontribution is two-fold: (1) the compilation of large datasets with speaker\ninformation for 20 language pairs, and (2) a simple set of experiments that\nincorporate gender information into NMT for multiple language pairs. Our\nexperiments show that adding a gender feature to an NMT system significantly\nimproves the translation quality for some language pairs.", "published": "2019-09-11 14:44:27", "link": "http://arxiv.org/abs/1909.05088v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From English to Code-Switching: Transfer Learning with Strong\n  Morphological Clues", "abstract": "Linguistic Code-switching (CS) is still an understudied phenomenon in natural\nlanguage processing. The NLP community has mostly focused on monolingual and\nmulti-lingual scenarios, but little attention has been given to CS in\nparticular. This is partly because of the lack of resources and annotated data,\ndespite its increasing occurrence in social media platforms. In this paper, we\naim at adapting monolingual models to code-switched text in various tasks.\nSpecifically, we transfer English knowledge from a pre-trained ELMo model to\ndifferent code-switched language pairs (i.e., Nepali-English, Spanish-English,\nand Hindi-English) using the task of language identification. Our method,\nCS-ELMo, is an extension of ELMo with a simple yet effective position-aware\nattention mechanism inside its character convolutions. We show the\neffectiveness of this transfer learning step by outperforming multilingual BERT\nand homologous CS-unaware ELMo models and establishing a new state of the art\nin CS tasks, such as NER and POS tagging. Our technique can be expanded to more\nEnglish-paired code-switched languages, providing more resources to the CS\ncommunity.", "published": "2019-09-11 15:53:21", "link": "http://arxiv.org/abs/1909.05158v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dependency-Aware Named Entity Recognition with Relative and Global\n  Attentions", "abstract": "Named entity recognition is one of the core tasks in NLP. Although many\nimprovements have been made on this task during the last years, the\nstate-of-the-art systems do not explicitly take into account the recursive\nnature of language. Instead of only treating the text as a plain sequence of\nwords, we incorporate a linguistically-inspired way to recognize entities based\non syntax and tree structures. Our model exploits syntactic relationships among\nwords using a Tree-LSTM guided by dependency trees. Then, we enhance these\nfeatures by applying relative and global attention mechanisms. On the one hand,\nthe relative attention detects the most informative words in the sentence with\nrespect to the word being evaluated. On the other hand, the global attention\nspots the most relevant words in the sequence. Lastly, we linearly project the\nweighted vectors into the tagging space so that a conditional random field\nclassifier predicts the entity labels. Our findings show that the model detects\nwords that disclose the entity types based on their syntactic roles in a\nsentence (e.g., verbs such as speak and write are attended when the entity type\nis PERSON, whereas meet and travel strongly relate to LOCATION). We confirm our\nfindings and establish a new state of the art on two datasets.", "published": "2019-09-11 16:10:26", "link": "http://arxiv.org/abs/1909.05166v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Frustratingly Easy Natural Question Answering", "abstract": "Existing literature on Question Answering (QA) mostly focuses on algorithmic\nnovelty, data augmentation, or increasingly large pre-trained language models\nlike XLNet and RoBERTa. Additionally, a lot of systems on the QA leaderboards\ndo not have associated research documentation in order to successfully\nreplicate their experiments. In this paper, we outline these algorithmic\ncomponents such as Attention-over-Attention, coupled with data augmentation and\nensembling strategies that have shown to yield state-of-the-art results on\nbenchmark datasets like SQuAD, even achieving super-human performance. Contrary\nto these prior results, when we evaluate on the recently proposed Natural\nQuestions benchmark dataset, we find that an incredibly simple approach of\ntransfer learning from BERT outperforms the previous state-of-the-art system\ntrained on 4 million more examples than ours by 1.9 F1 points. Adding\nensembling strategies further improves that number by 2.3 F1 points.", "published": "2019-09-11 18:28:48", "link": "http://arxiv.org/abs/1909.05286v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Makes A Good Story? Designing Composite Rewards for Visual\n  Storytelling", "abstract": "Previous storytelling approaches mostly focused on optimizing traditional\nmetrics such as BLEU, ROUGE and CIDEr. In this paper, we re-examine this\nproblem from a different angle, by looking deep into what defines a\nrealistically-natural and topically-coherent story. To this end, we propose\nthree assessment criteria: relevance, coherence and expressiveness, which we\nobserve through empirical analysis could constitute a \"high-quality\" story to\nthe human eye. Following this quality guideline, we propose a reinforcement\nlearning framework, ReCo-RL, with reward functions designed to capture the\nessence of these quality criteria. Experiments on the Visual Storytelling\nDataset (VIST) with both automatic and human evaluations demonstrate that our\nReCo-RL model achieves better performance than state-of-the-art baselines on\nboth traditional metrics and the proposed new criteria.", "published": "2019-09-11 19:17:03", "link": "http://arxiv.org/abs/1909.05316v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CTRL: A Conditional Transformer Language Model for Controllable\n  Generation", "abstract": "Large-scale language models show promising text generation capabilities, but\nusers cannot easily control particular aspects of the generated text. We\nrelease CTRL, a 1.63 billion-parameter conditional transformer language model,\ntrained to condition on control codes that govern style, content, and\ntask-specific behavior. Control codes were derived from structure that\nnaturally co-occurs with raw text, preserving the advantages of unsupervised\nlearning while providing more explicit control over text generation. These\ncodes also allow CTRL to predict which parts of the training data are most\nlikely given a sequence. This provides a potential method for analyzing large\namounts of data via model-based source attribution. We have released multiple\nfull-sized, pretrained versions of CTRL at https://github.com/salesforce/ctrl.", "published": "2019-09-11 17:57:18", "link": "http://arxiv.org/abs/1909.05858v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Discrete Hard EM Approach for Weakly Supervised Question Answering", "abstract": "Many question answering (QA) tasks only provide weak supervision for how the\nanswer should be computed. For example, TriviaQA answers are entities that can\nbe mentioned multiple times in supporting documents, while DROP answers can be\ncomputed by deriving many different equations from numbers in the reference\ntext. In this paper, we show it is possible to convert such tasks into discrete\nlatent variable learning problems with a precomputed, task-specific set of\npossible \"solutions\" (e.g. different mentions or equations) that contains one\ncorrect option. We then develop a hard EM learning scheme that computes\ngradients relative to the most likely solution at each update. Despite its\nsimplicity, we show that this approach significantly outperforms previous\nmethods on six QA tasks, including absolute gains of 2--10%, and achieves the\nstate-of-the-art on five of them. Using hard updates instead of maximizing\nmarginal likelihood is key to these results as it encourages the model to find\nthe one correct answer, which we show through detailed qualitative analysis.", "published": "2019-09-11 04:47:36", "link": "http://arxiv.org/abs/1909.04849v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How Does BERT Answer Questions? A Layer-Wise Analysis of Transformer\n  Representations", "abstract": "Bidirectional Encoder Representations from Transformers (BERT) reach\nstate-of-the-art results in a variety of Natural Language Processing tasks.\nHowever, understanding of their internal functioning is still insufficient and\nunsatisfactory. In order to better understand BERT and other Transformer-based\nmodels, we present a layer-wise analysis of BERT's hidden states. Unlike\nprevious research, which mainly focuses on explaining Transformer models by\ntheir attention weights, we argue that hidden states contain equally valuable\ninformation. Specifically, our analysis focuses on models fine-tuned on the\ntask of Question Answering (QA) as an example of a complex downstream task. We\ninspect how QA models transform token vectors in order to find the correct\nanswer. To this end, we apply a set of general and QA-specific probing tasks\nthat reveal the information stored in each representation layer. Our\nqualitative analysis of hidden state visualizations provides additional\ninsights into BERT's reasoning process. Our results show that the\ntransformations within BERT go through phases that are related to traditional\npipeline tasks. The system can therefore implicitly incorporate task-specific\ninformation into its token representations. Furthermore, our analysis reveals\nthat fine-tuning has little impact on the models' semantic abilities and that\nprediction errors can be recognized in the vector representations of even early\nlayers.", "published": "2019-09-11 08:55:09", "link": "http://arxiv.org/abs/1909.04925v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain\n  Natural Language Interfaces to Databases", "abstract": "We present CoSQL, a corpus for building cross-domain, general-purpose\ndatabase (DB) querying dialogue systems. It consists of 30k+ turns plus 10k+\nannotated SQL queries, obtained from a Wizard-of-Oz (WOZ) collection of 3k\ndialogues querying 200 complex DBs spanning 138 domains. Each dialogue\nsimulates a real-world DB query scenario with a crowd worker as a user\nexploring the DB and a SQL expert retrieving answers with SQL, clarifying\nambiguous questions, or otherwise informing of unanswerable questions. When\nuser questions are answerable by SQL, the expert describes the SQL and\nexecution results to the user, hence maintaining a natural interaction flow.\nCoSQL introduces new challenges compared to existing task-oriented dialogue\ndatasets:(1) the dialogue states are grounded in SQL, a domain-independent\nexecutable representation, instead of domain-specific slot-value pairs, and (2)\nbecause testing is done on unseen databases, success requires generalizing to\nnew domains. CoSQL includes three tasks: SQL-grounded dialogue state tracking,\nresponse generation from query results, and user dialogue act prediction. We\nevaluate a set of strong baselines for each task and show that CoSQL presents\nsignificant challenges for future research. The dataset, baselines, and\nleaderboard will be released at https://yale-lily.github.io/cosql.", "published": "2019-09-11 21:15:47", "link": "http://arxiv.org/abs/1909.05378v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Interactive Fiction Games: A Colossal Adventure", "abstract": "A hallmark of human intelligence is the ability to understand and communicate\nwith language. Interactive Fiction games are fully text-based simulation\nenvironments where a player issues text commands to effect change in the\nenvironment and progress through the story. We argue that IF games are an\nexcellent testbed for studying language-based autonomous agents. In particular,\nIF games combine challenges of combinatorial action spaces, language\nunderstanding, and commonsense reasoning. To facilitate rapid development of\nlanguage-based agents, we introduce Jericho, a learning environment for\nman-made IF games and conduct a comprehensive study of text-agents across a\nrich set of games, highlighting directions in which agents can improve.", "published": "2019-09-11 22:41:00", "link": "http://arxiv.org/abs/1909.05398v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Probabilistic framework for solving Visual Dialog", "abstract": "In this paper, we propose a probabilistic framework for solving the task of\n`Visual Dialog'. Solving this task requires reasoning and understanding of\nvisual modality, language modality, and common sense knowledge to answer.\nVarious architectures have been proposed to solve this task by variants of\nmulti-modal deep learning techniques that combine visual and language\nrepresentations. However, we believe that it is crucial to understand and\nanalyze the sources of uncertainty for solving this task. Our approach allows\nfor estimating uncertainty and also aids a diverse generation of answers. The\nproposed approach is obtained through a probabilistic representation module\nthat provides us with representations for image, question and conversation\nhistory, a module that ensures that diverse latent representations for\ncandidate answers are obtained given the probabilistic representations and an\nuncertainty representation module that chooses the appropriate answer that\nminimizes uncertainty. We thoroughly evaluate the model with a detailed\nablation analysis, comparison with state of the art and visualization of the\nuncertainty that aids in the understanding of the method. Using the proposed\nprobabilistic framework, we thus obtain an improved visual dialog system that\nis also more explainable.", "published": "2019-09-11 00:25:12", "link": "http://arxiv.org/abs/1909.04800v2", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Global Locality in Biomedical Relation and Event Extraction", "abstract": "Due to the exponential growth of biomedical literature, event and relation\nextraction are important tasks in biomedical text mining. Most work only focus\non relation extraction, and detect a single entity pair mention on a short span\nof text, which is not ideal due to long sentences that appear in biomedical\ncontexts. We propose an approach to both relation and event extraction, for\nsimultaneously predicting relationships between all mention pairs in a text. We\nalso perform an empirical study to discuss different network setups for this\npurpose. The best performing model includes a set of multi-head attentions and\nconvolutions, an adaptation of the transformer architecture, which offers\nself-attention the ability to strengthen dependencies among related elements,\nand models the interaction between features extracted by multiple attention\nheads. Experiment results demonstrate that our approach outperforms the state\nof the art on a set of benchmark biomedical corpora including BioNLP 2009,\n2011, 2013 and BioCreative 2017 shared tasks.", "published": "2019-09-11 02:20:57", "link": "http://arxiv.org/abs/1909.04822v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BERTgrid: Contextualized Embedding for 2D Document Representation and\n  Understanding", "abstract": "For understanding generic documents, information like font sizes, column\nlayout, and generally the positioning of words may carry semantic information\nthat is crucial for solving a downstream document intelligence task. Our novel\nBERTgrid, which is based on Chargrid by Katti et al. (2018), represents a\ndocument as a grid of contextualized word piece embedding vectors, thereby\nmaking its spatial structure and semantics accessible to the processing neural\nnetwork. The contextualized embedding vectors are retrieved from a BERT\nlanguage model. We use BERTgrid in combination with a fully convolutional\nnetwork on a semantic instance segmentation task for extracting fields from\ninvoices. We demonstrate its performance on tabulated line item and document\nheader field extraction.", "published": "2019-09-11 09:51:02", "link": "http://arxiv.org/abs/1909.04948v2", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Dynamic Author Representations with Temporal Language Models", "abstract": "Language models are at the heart of numerous works, notably in the text\nmining and information retrieval communities. These statistical models aim at\nextracting word distributions, from simple unigram models to recurrent\napproaches with latent variables that capture subtle dependencies in texts.\nHowever, those models are learned from word sequences only, and authors'\nidentities, as well as publication dates, are seldom considered. We propose a\nneural model, based on recurrent language modeling, which aims at capturing\nlanguage diffusion tendencies in author communities through time. By\nconditioning language models with author and temporal vector states, we are\nable to leverage the latent dependencies between the text contexts. This allows\nus to beat several temporal and non-temporal language baselines on two\nreal-world corpora, and to learn meaningful author representations that vary\nthrough time.", "published": "2019-09-11 11:51:43", "link": "http://arxiv.org/abs/1909.04985v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Self-Attentional Models Application in Task-Oriented Dialogue Generation\n  Systems", "abstract": "Self-attentional models are a new paradigm for sequence modelling tasks which\ndiffer from common sequence modelling methods, such as recurrence-based and\nconvolution-based sequence learning, in the way that their architecture is only\nbased on the attention mechanism. Self-attentional models have been used in the\ncreation of the state-of-the-art models in many NLP tasks such as neural\nmachine translation, but their usage has not been explored for the task of\ntraining end-to-end task-oriented dialogue generation systems yet. In this\nstudy, we apply these models on the three different datasets for training\ntask-oriented chatbots. Our finding shows that self-attentional models can be\nexploited to create end-to-end task-oriented chatbots which not only achieve\nhigher evaluation scores compared to recurrence-based models, but also do so\nmore efficiently.", "published": "2019-09-11 03:40:26", "link": "http://arxiv.org/abs/1909.05246v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Hope Speech Detection: A Computational Analysis of the Voice of Peace", "abstract": "The recent Pulwama terror attack (February 14, 2019, Pulwama, Kashmir)\ntriggered a chain of escalating events between India and Pakistan adding\nanother episode to their 70-year-old dispute over Kashmir. The present era of\nubiquitious social media has never seen nuclear powers closer to war. In this\npaper, we analyze this evolving international crisis via a substantial corpus\nconstructed using comments on YouTube videos (921,235 English comments posted\nby 392,460 users out of 2.04 million overall comments by 791,289 users on 2,890\nvideos). Our main contributions in the paper are three-fold. First, we present\nan observation that polyglot word-embeddings reveal precise and accurate\nlanguage clusters, and subsequently construct a document\nlanguage-identification technique with negligible annotation requirements. We\ndemonstrate the viability and utility across a variety of data sets involving\nseveral low-resource languages. Second, we present an analysis on temporal\ntrends of pro-peace and pro-war intent observing that when tensions between the\ntwo nations were at their peak, pro-peace intent in the corpus was at its\nhighest point. Finally, in the context of heated discussions in a politically\ntense situation where two nations are at the brink of a full-fledged war, we\nargue the importance of automatic identification of user-generated web content\nthat can diffuse hostility and address this prediction task, dubbed\n\\emph{hope-speech detection}.", "published": "2019-09-11 04:22:20", "link": "http://arxiv.org/abs/1909.12940v4", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Large-Scale Multilingual Speech Recognition with a Streaming End-to-End\n  Model", "abstract": "Multilingual end-to-end (E2E) models have shown great promise in expansion of\nautomatic speech recognition (ASR) coverage of the world's languages. They have\nshown improvement over monolingual systems, and have simplified training and\nserving by eliminating language-specific acoustic, pronunciation, and language\nmodels. This work presents an E2E multilingual system which is equipped to\noperate in low-latency interactive applications, as well as handle a key\nchallenge of real world data: the imbalance in training data across languages.\nUsing nine Indic languages, we compare a variety of techniques, and find that a\ncombination of conditioning on a language vector and training language-specific\nadapter layers produces the best model. The resulting E2E multilingual model\nachieves a lower word error rate (WER) than both monolingual E2E models (eight\nof nine languages) and monolingual conventional systems (all nine languages).", "published": "2019-09-11 19:46:21", "link": "http://arxiv.org/abs/1909.05330v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Guided Learning Convolution System for DCASE 2019 Task 4", "abstract": "In this paper, we describe in detail the system we submitted to DCASE2019\ntask 4: sound event detection (SED) in domestic environments. We employ a\nconvolutional neural network (CNN) with an embedding-level attention pooling\nmodule to solve it. By considering the interference caused by the co-occurrence\nof multiple events in the unbalanced dataset, we utilize the disentangled\nfeature to raise the performance of the model. To take advantage of the\nunlabeled data, we adopt Guided Learning for semi-supervised learning. A group\nof median filters with adaptive window sizes is utilized in the post-processing\nof output probabilities of the model. We also analyze the effect of the\nsynthetic data on the performance of the model and finally achieve an\nevent-based F-measure of 45.43% on the validation set and an event-based\nF-measure of 42.7% on the test set. The system we submitted to the challenge\nachieves the best performance compared to those of other participates.", "published": "2019-09-11 03:42:45", "link": "http://arxiv.org/abs/1909.06178v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
