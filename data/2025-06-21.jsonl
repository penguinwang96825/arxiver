{"title": "THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction", "abstract": "Automated clinical risk prediction from electronic health records (EHRs)\ndemands modeling both structured diagnostic codes and unstructured narrative\nnotes. However, most prior approaches either handle these modalities separately\nor rely on simplistic fusion strategies that ignore the directional,\nhierarchical causal interactions by which narrative observations precipitate\ndiagnoses and propagate risk across admissions. In this paper, we propose\nTHCM-CAL, a Temporal-Hierarchical Causal Model with Conformal Calibration. Our\nframework constructs a multimodal causal graph where nodes represent clinical\nentities from two modalities: Textual propositions extracted from notes and ICD\ncodes mapped to textual descriptions. Through hierarchical causal discovery,\nTHCM-CAL infers three clinically grounded interactions: intra-slice\nsame-modality sequencing, intra-slice cross-modality triggers, and inter-slice\nrisk propagation. To enhance prediction reliability, we extend conformal\nprediction to multi-label ICD coding, calibrating per-code confidence intervals\nunder complex co-occurrences. Experimental results on MIMIC-III and MIMIC-IV\ndemonstrate the superiority of THCM-CAL.", "published": "2025-06-21 22:43:42", "link": "http://arxiv.org/abs/2506.17844v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach", "abstract": "Aligning large language models (LLMs) with human preferences usually requires\nfine-tuning methods such as RLHF and DPO. These methods directly optimize the\nmodel parameters, so they cannot be used in test-time to improve model\nperformance, nor are they applicable when the model weights are not accessible.\nIn contrast, test-time methods sidestep weight updates by leveraging reward\nfunctions to guide and improve output quality. However, they incur high\ninference costs, and their one-shot guidance is often based on imperfect reward\nor value functions, leading to suboptimal outputs. In this work, we present a\nmethod named Iterative Reweight-then-Optimize (IRO), a reinforcement learning\n(RL) framework that performs RL-style alignment of the (frozen) base model\nwithout touching its parameters. During training, each iteration (i) samples\ncandidates from the base model, (ii) resamples using current value functions,\nand (iii) trains a new lightweight value function that guides the next decoding\npass. At test time, the value functions are used to guide the base model\ngeneration via a search-based optimization process. Notably, users can apply\nIRO to align a model on their own dataset, similar to OpenAI's reinforcement\nfine-tuning (RFT), but without requiring access to the model weights.", "published": "2025-06-21 21:49:02", "link": "http://arxiv.org/abs/2506.17828v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Multilingual Tokenization through the Lens of Indian Languages: Challenges and Insights", "abstract": "Tokenization plays a pivotal role in multilingual NLP. However, existing\ntokenizers are often skewed towards high-resource languages, limiting their\neffectiveness for linguistically diverse and morphologically rich languages\nsuch as those in the Indian subcontinent. This paper presents a comprehensive\nintrinsic evaluation of tokenization strategies across 17 Indian languages. We\nquantify the trade-offs between bottom-up and top-down tokenizer algorithms\n(BPE and Unigram LM), effects of vocabulary sizes, and compare strategies of\nmultilingual vocabulary construction such as joint and cluster-based training.\nWe also show that extremely low-resource languages can benefit from tokenizers\ntrained on related high-resource languages. Our study provides practical\ninsights for building more fair, efficient, and linguistically informed\ntokenizers for multilingual NLP.", "published": "2025-06-21 18:47:33", "link": "http://arxiv.org/abs/2506.17789v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bayesian Social Deduction with Graph-Informed Language Models", "abstract": "Social reasoning - inferring unobservable beliefs and intentions from partial\nobservations of other agents - remains a challenging task for large language\nmodels (LLMs). We evaluate the limits of current reasoning language models in\nthe social deduction game Avalon and find that while the largest models\ndemonstrate strong performance, they require extensive test-time inference and\ndegrade sharply when distilled to smaller, real-time-capable variants. To\naddress this, we introduce a hybrid reasoning framework that externalizes\nbelief inference to a structured probabilistic model, while using an LLM for\nlanguage understanding and interaction. Our approach achieves competitive\nperformance with much larger models in Agent-Agent play and, notably, is the\nfirst language agent to defeat human players in a controlled study - achieving\na 67% win rate and receiving higher qualitative ratings than both reasoning\nbaselines and human teammates. We release code, models, and a dataset to\nsupport future work on social reasoning in LLM agents, which can be found at\nhttps://camp-lab-purdue.github.io/bayesian-social-deduction/", "published": "2025-06-21 18:45:28", "link": "http://arxiv.org/abs/2506.17788v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "I.2.1; I.2.7"], "primary_category": "cs.AI"}
{"title": "Beyond instruction-conditioning, MoTE: Mixture of Task Experts for Multi-task Embedding Models", "abstract": "Dense embeddings are fundamental to modern machine learning systems, powering\nRetrieval-Augmented Generation (RAG), information retrieval, and representation\nlearning. While instruction-conditioning has become the dominant approach for\nembedding specialization, its direct application to low-capacity models imposes\nfundamental representational constraints that limit the performance gains\nderived from specialization. In this paper, we analyze these limitations and\nintroduce the Mixture of Task Experts (MoTE) transformer block, which leverages\ntask-specialized parameters trained with Task-Aware Contrastive Learning\n(\\tacl) to enhance the model ability to generate specialized embeddings.\nEmpirical results show that MoTE achieves $64\\%$ higher performance gains in\nretrieval datasets ($+3.27 \\rightarrow +5.21$) and $43\\%$ higher performance\ngains across all datasets ($+1.81 \\rightarrow +2.60$). Critically, these gains\nare achieved without altering instructions, training data, inference time, or\nnumber of active parameters.", "published": "2025-06-21 18:28:25", "link": "http://arxiv.org/abs/2506.17781v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "HIDE and Seek: Detecting Hallucinations in Language Models via Decoupled Representations", "abstract": "Contemporary Language Models (LMs), while impressively fluent, often generate\ncontent that is factually incorrect or unfaithful to the input context - a\ncritical issue commonly referred to as 'hallucination'. This tendency of LMs to\ngenerate hallucinated content undermines their reliability, especially because\nthese fabrications are often highly convincing and therefore difficult to\ndetect. While several existing methods attempt to detect hallucinations, most\nrely on analyzing multiple generations per input, leading to increased\ncomputational cost and latency. To address this, we propose a single-pass,\ntraining-free approach for effective Hallucination detectIon via Decoupled\nrEpresentations (HIDE). Our approach leverages the hypothesis that\nhallucinations result from a statistical decoupling between an LM's internal\nrepresentations of input context and its generated output. We quantify this\ndecoupling using the Hilbert-Schmidt Independence Criterion (HSIC) applied to\nhidden-state representations extracted while generating the output sequence. We\nconduct extensive experiments on four diverse question answering datasets,\nevaluating both faithfulness and factuality hallucinations across six\nopen-source LMs of varying scales and properties. Our results demonstrate that\nHIDE outperforms other single-pass methods in almost all settings, achieving an\naverage relative improvement of ~29% in AUC-ROC over the best-performing\nsingle-pass strategy across various models and datasets. Additionally, HIDE\nshows competitive and often superior performance with multi-pass\nstate-of-the-art methods, obtaining an average relative improvement of ~3% in\nAUC-ROC while consuming ~51% less computation time. Our findings highlight the\neffectiveness of exploiting internal representation decoupling in LMs for\nefficient and practical hallucination detection.", "published": "2025-06-21 16:02:49", "link": "http://arxiv.org/abs/2506.17748v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "KAG-Thinker: Teaching Large Language Models to Think with Human-like Reasoning Process", "abstract": "In this paper, we introduce KAG-Thinker, a novel human-like reasoning\nframework built upon a parameter-light large language model (LLM). Our approach\nenhances the logical coherence and contextual consistency of the thinking\nprocess in question-answering (Q\\&A) tasks on domain-specific knowledge bases\n(KBs) within LLMs. This framework simulates human cognitive mechanisms for\nhandling complex problems by establishing a structured thinking process.\nContinuing the \\textbf{Logical Form} guided retrieval and reasoning technology\nroute of KAG v0.7, firstly, it decomposes complex questions into independently\nsolvable sub-problems(also referred to as logical forms) through\n\\textbf{breadth decomposition}, each represented in two equivalent\nforms-natural language and logical function-and further classified as either\nKnowledge Retrieval or Reasoning Analysis tasks, with dependencies and\nvariables passing explicitly modeled via logical function interfaces. In the\nsolving process, the Retrieval function is used to perform knowledge retrieval\ntasks, while the Math and Deduce functions are used to perform reasoning\nanalysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval\nsub-problem tasks, LLMs and external knowledge sources are regarded as\nequivalent KBs. We use the \\textbf{knowledge boundary} model to determine the\noptimal source using self-regulatory mechanisms such as confidence calibration\nand reflective reasoning, and use the \\textbf{depth solving} model to enhance\nthe comprehensiveness of knowledge acquisition. Finally, instead of utilizing\nreinforcement learning, we employ supervised fine-tuning with multi-turn\ndialogues to align the model with our structured inference paradigm, thereby\navoiding excessive reflection. This is supported by a data evaluation framework\nand iterative corpus synthesis, which facilitate the generation of detailed\nreasoning trajectories...", "published": "2025-06-21 14:58:53", "link": "http://arxiv.org/abs/2506.17728v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unveiling Factors for Enhanced POS Tagging: A Study of Low-Resource Medieval Romance Languages", "abstract": "Part-of-speech (POS) tagging remains a foundational component in natural\nlanguage processing pipelines, particularly critical for historical text\nanalysis at the intersection of computational linguistics and digital\nhumanities. Despite significant advancements in modern large language models\n(LLMs) for ancient languages, their application to Medieval Romance languages\npresents distinctive challenges stemming from diachronic linguistic evolution,\nspelling variations, and labeled data scarcity. This study systematically\ninvestigates the central determinants of POS tagging performance across diverse\ncorpora of Medieval Occitan, Medieval Spanish, and Medieval French texts,\nspanning biblical, hagiographical, medical, and dietary domains. Through\nrigorous experimentation, we evaluate how fine-tuning approaches, prompt\nengineering, model architectures, decoding strategies, and cross-lingual\ntransfer learning techniques affect tagging accuracy. Our results reveal both\nnotable limitations in LLMs' ability to process historical language variations\nand non-standardized spelling, as well as promising specialized techniques that\neffectively address the unique challenges presented by low-resource historical\nlanguages.", "published": "2025-06-21 13:33:07", "link": "http://arxiv.org/abs/2506.17715v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Aged to Perfection: Machine-Learning Maps of Age in Conversational English", "abstract": "The study uses the British National Corpus 2014, a large sample of\ncontemporary spoken British English, to investigate language patterns across\ndifferent age groups. Our research attempts to explore how language patterns\nvary between different age groups, exploring the connection between speaker\ndemographics and linguistic factors such as utterance duration, lexical\ndiversity, and word choice. By merging computational language analysis and\nmachine learning methodologies, we attempt to uncover distinctive linguistic\nmarkers characteristic of multiple generations and create prediction models\nthat can consistently estimate the speaker's age group from various aspects.\nThis work contributes to our knowledge of sociolinguistic diversity throughout\nthe life of modern British speech.", "published": "2025-06-21 13:08:57", "link": "http://arxiv.org/abs/2506.17708v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Evolution of Natural Language Processing: How Prompt Optimization and Language Models are Shaping the Future", "abstract": "Large Language Models (LLMs) have revolutionized the field of Natural\nLanguage Processing (NLP) by automating traditional labor-intensive tasks and\nconsequently accelerated the development of computer-aided applications. As\nresearchers continue to advance this field with the introduction of novel\nlanguage models and more efficient training/finetuning methodologies, the idea\nof prompt engineering and subsequent optimization strategies with LLMs has\nemerged as a particularly impactful trend to yield a substantial performance\nboost across diverse NLP tasks. To best of our knowledge numerous review\narticles have explored prompt engineering, however, a critical gap exists in\ncomprehensive analyses of prompt optimization strategies. To bridge this gap\nthis paper provides unique and comprehensive insights about the potential of\ndiverse prompt optimization strategies. It analyzes their underlying working\nparadigms and based on these principles, categorizes them into 11 distinct\nclasses. Moreover, the paper provides details about various NLP tasks where\nthese prompt optimization strategies have been employed, along with details of\ndifferent LLMs and benchmark datasets used for evaluation. This comprehensive\ncompilation lays a robust foundation for future comparative studies and enables\nrigorous assessment of prompt optimization and LLM-based predictive pipelines\nunder consistent experimental settings: a critical need in the current\nlandscape. Ultimately, this research will centralize diverse strategic\nknowledge to facilitate the adaptation of existing prompt optimization\nstrategies for development of innovative predictors across unexplored tasks.", "published": "2025-06-21 12:25:37", "link": "http://arxiv.org/abs/2506.17700v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Conversational Stance Detection: Dataset and Approaches", "abstract": "Stance detection, which aims to identify public opinion towards specific\ntargets using social media data, is an important yet challenging task. With the\nincreasing number of online debates among social media users, conversational\nstance detection has become a crucial research area. However, existing\nconversational stance detection datasets are restricted to a limited set of\nspecific targets, which constrains the effectiveness of stance detection models\nwhen encountering a large number of unseen targets in real-world applications.\nTo bridge this gap, we manually curate a large-scale, high-quality zero-shot\nconversational stance detection dataset, named ZS-CSD, comprising 280 targets\nacross two distinct target types. Leveraging the ZS-CSD dataset, we propose\nSITPCL, a speaker interaction and target-aware prototypical contrastive\nlearning model, and establish the benchmark performance in the zero-shot\nsetting. Experimental results demonstrate that our proposed SITPCL model\nachieves state-of-the-art performance in zero-shot conversational stance\ndetection. Notably, the SITPCL model attains only an F1-macro score of 43.81%,\nhighlighting the persistent challenges in zero-shot conversational stance\ndetection.", "published": "2025-06-21 12:02:06", "link": "http://arxiv.org/abs/2506.17693v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering", "abstract": "Knowledge-intensive multi-hop question answering (QA) tasks, which require\nintegrating evidence from multiple sources to address complex queries, often\nnecessitate multiple rounds of retrieval and iterative generation by large\nlanguage models (LLMs). However, incorporating many documents and extended\ncontexts poses challenges -such as hallucinations and semantic drift-for\nlightweight LLMs with fewer parameters. This work proposes a novel framework\ncalled DEC (Dynamic Enhancement Chain). DEC first decomposes complex questions\ninto logically coherent subquestions to form a hallucination-free reasoning\nchain. It then iteratively refines these subquestions through context-aware\nrewriting to generate effective query formulations. For retrieval, we introduce\na lightweight discriminative keyword extraction module that leverages extracted\nkeywords to achieve targeted, precise document recall with relatively low\ncomputational overhead. Extensive experiments on three multi-hop QA datasets\ndemonstrate that DEC performs on par with or surpasses state-of-the-art\nbenchmarks while significantly reducing token consumption. Notably, our\napproach attains state-of-the-art results on models with 8B parameters,\nshowcasing its effectiveness in various scenarios, particularly in\nresource-constrained environments.", "published": "2025-06-21 11:55:27", "link": "http://arxiv.org/abs/2506.17692v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Few-shot Keyword Spotting Performance through Pre-Trained Self-supervised Speech Models", "abstract": "Keyword Spotting plays a critical role in enabling hands-free interaction for\nbattery-powered edge devices. Few-Shot Keyword Spotting (FS-KWS) addresses the\nscalability and adaptability challenges of traditional systems by enabling\nrecognition of custom keywords with only a few examples. However, existing\nFS-KWS systems achieve subpar accuracy at desirable false acceptance rates,\nparticularly in resource-constrained edge environments. To address these\nissues, we propose a training scheme that leverages self-supervised learning\nmodels for robust feature extraction, dimensionality reduction, and knowledge\ndistillation. The teacher model, based on Wav2Vec 2.0 is trained using\nSub-center ArcFace loss, which enhances inter-class separability and\nintra-class compactness. To enable efficient deployment on edge devices, we\nintroduce attention-based dimensionality reduction and train a standard\nlightweight ResNet15 student model. We evaluate the proposed approach on the\nEnglish portion of the Multilingual Spoken Words Corpus (MSWC) and the Google\nSpeech Commands (GSC) datasets. Notably, the proposed training method improves\nthe 10-shot classification accuracy from 33.4% to 74.1% on 11 classes at 1%\nfalse alarm accuracy on the GSC dataset, thus making it significantly\nbetter-suited for a real use case scenario.", "published": "2025-06-21 11:39:11", "link": "http://arxiv.org/abs/2506.17686v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "FaithfulSAE: Towards Capturing Faithful Features with Sparse Autoencoders without External Dataset Dependencies", "abstract": "Sparse Autoencoders (SAEs) have emerged as a promising solution for\ndecomposing large language model representations into interpretable features.\nHowever, Paulo and Belrose (2025) have highlighted instability across different\ninitialization seeds, and Heap et al. (2025) have pointed out that SAEs may not\ncapture model-internal features. These problems likely stem from training SAEs\non external datasets - either collected from the Web or generated by another\nmodel - which may contain out-of-distribution (OOD) data beyond the model's\ngeneralisation capabilities. This can result in hallucinated SAE features,\nwhich we term \"Fake Features\", that misrepresent the model's internal\nactivations. To address these issues, we propose FaithfulSAE, a method that\ntrains SAEs on the model's own synthetic dataset. Using FaithfulSAEs, we\ndemonstrate that training SAEs on less-OOD instruction datasets results in SAEs\nbeing more stable across seeds. Notably, FaithfulSAEs outperform SAEs trained\non web-based datasets in the SAE probing task and exhibit a lower Fake Feature\nRatio in 5 out of 7 models. Overall, our approach eliminates the dependency on\nexternal datasets, advancing interpretability by better capturing\nmodel-internal features while highlighting the often neglected importance of\nSAE training datasets.", "published": "2025-06-21 10:18:25", "link": "http://arxiv.org/abs/2506.17673v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "TPTT: Transforming Pretrained Transformer into Titans", "abstract": "Recent advances in large language models (LLMs) have led to remarkable\nprogress in natural language processing, but their computational and memory\ndemands remain a significant challenge, particularly for long-context\ninference. We introduce TPTT (Transforming Pretrained Transformer into Titans),\na novel framework for enhancing pretrained Transformer models with efficient\nlinearized attention mechanisms and advanced memory management. TPTT employs\ntechniques such as Memory as Gate (MaG) and mixed linearized attention (LiZA).\nIt is fully compatible with the Hugging Face Transformers library, enabling\nseamless adaptation of any causal LLM through parameter-efficient fine-tuning\n(LoRA) without full retraining. We show the effectiveness of TPTT on the MMLU\nbenchmark with models of approximately 1 billion parameters, observing\nsubstantial improvements in both efficiency and accuracy. For instance,\nTitans-Llama-3.2-1B achieves a 20% increase in Exact Match (EM) over its\nbaseline. Statistical analyses and comparisons with recent state-of-the-art\nmethods confirm the practical scalability and robustness of TPTT. Code is\navailable at https://github.com/fabienfrfr/tptt . Python package at\nhttps://pypi.org/project/tptt/ .", "published": "2025-06-21 10:06:07", "link": "http://arxiv.org/abs/2506.17671v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Step-Opt: Boosting Optimization Modeling in LLMs through Iterative Data Synthesis and Structured Validation", "abstract": "Large Language Models (LLMs) have revolutionized various domains but\nencounter substantial challenges in tackling optimization modeling tasks for\nOperations Research (OR), particularly when dealing with complex problem. In\nthis work, we propose Step-Opt-Instruct, a framework that augments existing\ndatasets and generates high-quality fine-tuning data tailored to optimization\nmodeling. Step-Opt-Instruct employs iterative problem generation to\nsystematically increase problem complexity and stepwise validation to\nrigorously verify data, preventing error propagation and ensuring the quality\nof the generated dataset. Leveraging this framework, we fine-tune open-source\nLLMs, including LLaMA-3-8B and Mistral-7B, to develop Step-Opt--a model that\nachieves state-of-the-art performance on benchmarks such as NL4OPT, MAMO, and\nIndustryOR. Extensive experiments demonstrate the superior performance of\nStep-Opt, especially in addressing complex OR tasks, with a notable 17.01\\%\nimprovement in micro average accuracy on difficult problems. These findings\nhighlight the effectiveness of combining structured validation with gradual\nproblem refinement to advance the automation of decision-making processes using\nLLMs.The code and dataset are available at https://github.com/samwu-learn/Step.", "published": "2025-06-21 08:42:27", "link": "http://arxiv.org/abs/2506.17637v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Answer-Centric or Reasoning-Driven? Uncovering the Latent Memory Anchor in LLMs", "abstract": "While Large Language Models (LLMs) demonstrate impressive reasoning\ncapabilities, growing evidence suggests much of their success stems from\nmemorized answer-reasoning patterns rather than genuine inference. In this\nwork, we investigate a central question: are LLMs primarily anchored to final\nanswers or to the textual pattern of reasoning chains? We propose a five-level\nanswer-visibility prompt framework that systematically manipulates answer cues\nand probes model behavior through indirect, behavioral analysis. Experiments\nacross state-of-the-art LLMs reveal a strong and consistent reliance on\nexplicit answers. The performance drops by 26.90\\% when answer cues are masked,\neven with complete reasoning chains. These findings suggest that much of the\nreasoning exhibited by LLMs may reflect post-hoc rationalization rather than\ntrue inference, calling into question their inferential depth. Our study\nuncovers the answer-anchoring phenomenon with rigorous empirical validation and\nunderscores the need for a more nuanced understanding of what constitutes\nreasoning in LLMs.", "published": "2025-06-21 08:15:45", "link": "http://arxiv.org/abs/2506.17630v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CLiViS: Unleashing Cognitive Map through Linguistic-Visual Synergy for Embodied Visual Reasoning", "abstract": "Embodied Visual Reasoning (EVR) seeks to follow complex, free-form\ninstructions based on egocentric video, enabling semantic understanding and\nspatiotemporal reasoning in dynamic environments. Despite its promising\npotential, EVR encounters significant challenges stemming from the diversity of\ncomplex instructions and the intricate spatiotemporal dynamics in long-term\negocentric videos. Prior solutions either employ Large Language Models (LLMs)\nover static video captions, which often omit critical visual details, or rely\non end-to-end Vision-Language Models (VLMs) that struggle with stepwise\ncompositional reasoning. Consider the complementary strengths of LLMs in\nreasoning and VLMs in perception, we propose CLiViS. It is a novel\ntraining-free framework that leverages LLMs for high-level task planning and\norchestrates VLM-driven open-world visual perception to iteratively update the\nscene context. Building on this synergy, the core of CLiViS is a dynamic\nCognitive Map that evolves throughout the reasoning process. This map\nconstructs a structured representation of the embodied scene, bridging\nlow-level perception and high-level reasoning. Extensive experiments across\nmultiple benchmarks demonstrate the effectiveness and generality of CLiViS,\nespecially in handling long-term visual dependencies. Code is available at\nhttps://github.com/Teacher-Tom/CLiViS.", "published": "2025-06-21 08:11:40", "link": "http://arxiv.org/abs/2506.17629v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "OpusLM: A Family of Open Unified Speech Language Models", "abstract": "This paper presents Open Unified Speech Language Models (OpusLMs), a family\nof open foundational speech language models (SpeechLMs) up to 7B. Initialized\nfrom decoder-only text language models, the OpusLMs are continuously\npre-trained on 213K hours of speech-text pairs and 292B text-only tokens. We\ndemonstrate our OpusLMs achieve comparable (or even superior) performance with\nexisting SpeechLMs in speech recognition, speech synthesis, and text-only\ncapabilities. Technically, this paper articulates our SpeechLM designs on\ntokenization, multi-stream language models, and multi-stage training\nstrategies. We experimentally demonstrate the importance of model size scaling\nand the effect of annealing data selection. The OpusLMs are all built from\npublicly available materials and are fully transparent models. We release our\ncode, data, checkpoints, and training logs to facilitate open SpeechLM research", "published": "2025-06-21 06:30:59", "link": "http://arxiv.org/abs/2506.17611v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting", "abstract": "Accurate typhoon track forecasting is crucial for early system warning and\ndisaster response. While Transformer-based models have demonstrated strong\nperformance in modeling the temporal dynamics of dense trajectories of humans\nand vehicles in smart cities, they usually lack access to broader contextual\nknowledge that enhances the forecasting reliability of sparse meteorological\ntrajectories, such as typhoon tracks. To address this challenge, we propose\nTyphoFormer, a novel framework that incorporates natural language descriptions\nas auxiliary prompts to improve typhoon trajectory forecasting. For each time\nstep, we use Large Language Model (LLM) to generate concise textual\ndescriptions based on the numerical attributes recorded in the North Atlantic\nhurricane database. The language descriptions capture high-level meteorological\nsemantics and are embedded as auxiliary special tokens prepended to the\nnumerical time series input. By integrating both textual and sequential\ninformation within a unified Transformer encoder, TyphoFormer enables the model\nto leverage contextual cues that are otherwise inaccessible through numerical\nfeatures alone. Extensive experiments are conducted on HURDAT2 benchmark,\nresults show that TyphoFormer consistently outperforms other state-of-the-art\nbaseline methods, particularly under challenging scenarios involving nonlinear\npath shifts and limited historical observations.", "published": "2025-06-21 06:14:57", "link": "http://arxiv.org/abs/2506.17609v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mind the Gap: Assessing Wiktionary's Crowd-Sourced Linguistic Knowledge on Morphological Gaps in Two Related Languages", "abstract": "Morphological defectivity is an intriguing and understudied phenomenon in\nlinguistics. Addressing defectivity, where expected inflectional forms are\nabsent, is essential for improving the accuracy of NLP tools in morphologically\nrich languages. However, traditional linguistic resources often lack coverage\nof morphological gaps as such knowledge requires significant human expertise\nand effort to document and verify. For scarce linguistic phenomena in\nunder-explored languages, Wikipedia and Wiktionary often serve as among the few\naccessible resources. Despite their extensive reach, their reliability has been\na subject of controversy. This study customizes a novel neural morphological\nanalyzer to annotate Latin and Italian corpora. Using the massive annotated\ndata, crowd-sourced lists of defective verbs compiled from Wiktionary are\nvalidated computationally. Our results indicate that while Wiktionary provides\na highly reliable account of Italian morphological gaps, 7% of Latin lemmata\nlisted as defective show strong corpus evidence of being non-defective. This\ndiscrepancy highlights potential limitations of crowd-sourced wikis as\ndefinitive sources of linguistic knowledge, particularly for less-studied\nphenomena and languages, despite their value as resources for rare linguistic\nfeatures. By providing scalable tools and methods for quality assurance of\ncrowd-sourced data, this work advances computational morphology and expands\nlinguistic knowledge of defectivity in non-English, morphologically rich\nlanguages.", "published": "2025-06-21 05:46:30", "link": "http://arxiv.org/abs/2506.17603v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models", "abstract": "Trustworthy language models should provide both correct and verifiable\nanswers. While language models can sometimes attribute their outputs to\npretraining data, their citations are often unreliable due to hallucination. As\na result, current systems insert citations by querying an external retriever at\ninference time, introducing latency, infrastructure dependence, and\nvulnerability to retrieval noise. We explore whether LLMs can be made to\nreliably attribute to the documents seen during (continual)\npretraining--without test-time retrieval--by revising the training process. To\nevaluate this, we release CitePretrainBench, a benchmark that mixes real-world\ncorpora (Wikipedia, Common Crawl, arXiv) with novel, unseen documents and\nprobes both short-form (single fact) and long-form (multi-fact) citation tasks.\nOur approach follows a two-stage process: (1) continual pretraining to bind\nfacts to persistent document identifiers, and (2) instruction tuning to elicit\ncitation behavior. We find that simple Passive Indexing, which appends an\nidentifier to each document, helps memorize verbatim text but fails on\nparaphrased or compositional facts. Instead, we propose Active Indexing, which\ncontinually pretrains on synthetic QA pairs that (1) restate each fact in\ndiverse compositional forms, and (2) require bidirectional source-to-fact and\nfact-to-source generation, jointly teaching the model to generate content from\na cited source and to attribute its own answers. Experiments with Qwen2.5-7B\nand 3B show that Active Indexing consistently outperforms Passive Indexing\nacross all tasks and models, with citation precision gains up to 30.2 percent.\nOur ablation studies reveal that performance continues to improve as we scale\nthe amount of augmented data, showing a clear upward trend even at 16 times the\noriginal token count.", "published": "2025-06-21 04:48:05", "link": "http://arxiv.org/abs/2506.17585v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "AgriCHN: A Comprehensive Cross-domain Resource for Chinese Agricultural Named Entity Recognition", "abstract": "Agricultural named entity recognition is a specialized task focusing on\nidentifying distinct agricultural entities within vast bodies of text,\nincluding crops, diseases, pests, and fertilizers. It plays a crucial role in\nenhancing information extraction from extensive agricultural text resources.\nHowever, the scarcity of high-quality agricultural datasets, particularly in\nChinese, has resulted in suboptimal performance when employing mainstream\nmethods for this purpose. Most earlier works only focus on annotating\nagricultural entities while overlook the profound correlation of agriculture\nwith hydrology and meteorology. To fill this blank, we present AgriCHN, a\ncomprehensive open-source Chinese resource designed to promote the accuracy of\nautomated agricultural entity annotation. The AgriCHN dataset has been\nmeticulously curated from a wealth of agricultural articles, comprising a total\nof 4,040 sentences and encapsulating 15,799 agricultural entity mentions\nspanning 27 diverse entity categories. Furthermore, it encompasses entities\nfrom hydrology to meteorology, thereby enriching the diversity of entities\nconsidered. Data validation reveals that, compared with relevant resources,\nAgriCHN demonstrates outstanding data quality, attributable to its richer\nagricultural entity types and more fine-grained entity divisions. A benchmark\ntask has also been constructed using several state-of-the-art neural NER\nmodels. Extensive experimental results highlight the significant challenge\nposed by AgriCHN and its potential for further research.", "published": "2025-06-21 04:21:11", "link": "http://arxiv.org/abs/2506.17578v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Expanding Relevance Judgments for Medical Case-based Retrieval Task with Multimodal LLMs", "abstract": "Evaluating Information Retrieval (IR) systems relies on high-quality manual\nrelevance judgments (qrels), which are costly and time-consuming to obtain.\nWhile pooling reduces the annotation effort, it results in only partially\nlabeled datasets. Large Language Models (LLMs) offer a promising alternative to\nreducing reliance on manual judgments, particularly in complex domains like\nmedical case-based retrieval, where relevance assessment requires analyzing\nboth textual and visual information. In this work, we explore using a\nMultimodal Large Language Model (MLLM) to expand relevance judgments, creating\na new dataset of automated judgments. Specifically, we employ Gemini 1.5 Pro on\nthe ImageCLEFmed 2013 case-based retrieval task, simulating human assessment\nthrough an iteratively refined, structured prompting strategy that integrates\nbinary scoring, instruction-based evaluation, and few-shot learning. We\nsystematically experimented with various prompt configurations to maximize\nagreement with human judgments. To evaluate agreement between the MLLM and\nhuman judgments, we use Cohen's Kappa, achieving a substantial agreement score\nof 0.6, comparable to inter-annotator agreement typically observed in\nmultimodal retrieval tasks. Starting from the original 15,028 manual judgments\n(4.72% relevant) across 35 topics, our MLLM-based approach expanded the dataset\nby over 37x to 558,653 judgments, increasing relevant annotations to 5,950. On\naverage, each medical case query received 15,398 new annotations, with\napproximately 99% being non-relevant, reflecting the high sparsity typical in\nthis domain. Our results demonstrate the potential of MLLMs to scale relevance\njudgment collection, offering a promising direction for supporting retrieval\nevaluation in medical and multimodal IR tasks.", "published": "2025-06-21 18:29:33", "link": "http://arxiv.org/abs/2506.17782v1", "categories": ["cs.IR", "cs.AI", "H.3.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "CARTS: Collaborative Agents for Recommendation Textual Summarization", "abstract": "Current recommendation systems often require some form of textual data\nsummarization, such as generating concise and coherent titles for product\ncarousels or other grouped item displays. While large language models have\nshown promise in NLP domains for textual summarization, these approaches do not\ndirectly apply to recommendation systems, where explanations must be highly\nrelevant to the core features of item sets, adhere to strict word limit\nconstraints. In this paper, we propose CARTS (Collaborative Agents for\nRecommendation Textual Summarization), a multi-agent LLM framework designed for\nstructured summarization in recommendation systems. CARTS decomposes the task\ninto three stages-Generation Augmented Generation (GAG), refinement circle, and\narbitration, where successive agent roles are responsible for extracting\nsalient item features, iteratively refining candidate titles based on relevance\nand length feedback, and selecting the final title through a collaborative\narbitration process. Experiments on large-scale e-commerce data and live A/B\ntesting show that CARTS significantly outperforms single-pass and\nchain-of-thought LLM baselines, delivering higher title relevance and improved\nuser engagement metrics.", "published": "2025-06-21 17:18:35", "link": "http://arxiv.org/abs/2506.17765v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Reinforcing User Interest Evolution in Multi-Scenario Learning for recommender systems", "abstract": "In real-world recommendation systems, users would engage in variety\nscenarios, such as homepages, search pages, and related recommendation pages.\nEach of these scenarios would reflect different aspects users focus on.\nHowever, the user interests may be inconsistent in different scenarios, due to\ndifferences in decision-making processes and preference expression. This\nvariability complicates unified modeling, making multi-scenario learning a\nsignificant challenge. To address this, we propose a novel reinforcement\nlearning approach that models user preferences across scenarios by modeling\nuser interest evolution across multiple scenarios. Our method employs Double\nQ-learning to enhance next-item prediction accuracy and optimizes contrastive\nlearning loss using Q-value to make model performance better. Experimental\nresults demonstrate that our approach surpasses state-of-the-art methods in\nmulti-scenario recommendation tasks. Our work offers a fresh perspective on\nmulti-scenario modeling and highlights promising directions for future\nresearch.", "published": "2025-06-21 11:27:53", "link": "http://arxiv.org/abs/2506.17682v1", "categories": ["cs.IR", "cs.AI", "68T07", "H.3.3"], "primary_category": "cs.IR"}
{"title": "A novel fast short-time root music method for vibration monitoring of high-speed spindles", "abstract": "Ultra-high-speed spindle bearings challenge traditional vibration monitoring\ndue to broadband noise, non-stationarity, and limited time-frequency\nresolution. We present a fast Short-Time Root-MUSIC (fSTrM) algorithm that\nexploits\n  FFT-accelerated Lanczos bidiagonalization to reduce computational complexity\nfrom $\\mathcal{O}(N^3)$ to $SN\\log_2N+S^2(N+S)+M^2(N+M)$\n  while preserving parametric super-resolution. The method constructs Hankel\nmatrices from 16 ms signal frames and extracts fault frequencies through\npolynomial rooting on the unit circle. Experimental validation on the\nPolitecnico di Torino bearing dataset demonstrates breakthrough micro-defect\ndetection capabilities. The algorithm reliably identifies 150 $\\mu$m defects --\npreviously undetectable by conventional methods -- providing 72+ hours\nadditional warning time. Compared to STFT and wavelet methods, fSTrM achieves\n1.2 Hz frequency resolution (vs. 12.5 Hz), 93\\% detection rate at $-$5 dB SNR,\nand quantifies defect severity through harmonic content analysis. Critically,\nthe algorithm processes each frame in 2.4 ms on embedded ARM Cortex-M7\nhardware, enabling real-time deployment. This advancement transforms bearing\nmonitoring from failure prevention to continuous degradation assessment,\nestablishing a new paradigm for predictive maintenance in aerospace and\nprecision machining.", "published": "2025-06-21 05:35:38", "link": "http://arxiv.org/abs/2506.17600v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models", "abstract": "The exponential growth of scientific literature challenges researchers\nextracting and synthesizing knowledge. Traditional search engines return many\nsources without direct, detailed answers, while general-purpose LLMs may offer\nconcise responses that lack depth or omit current information. LLMs with search\ncapabilities are also limited by context window, yielding short, incomplete\nanswers. This paper introduces WISE (Workflow for Intelligent Scientific\nKnowledge Extraction), a system addressing these limits by using a structured\nworkflow to extract, refine, and rank query-specific knowledge. WISE uses an\nLLM-powered, tree-based architecture to refine data, focusing on query-aligned,\ncontext-aware, and non-redundant information. Dynamic scoring and ranking\nprioritize unique contributions from each source, and adaptive stopping\ncriteria minimize processing overhead. WISE delivers detailed, organized\nanswers by systematically exploring and synthesizing knowledge from diverse\nsources. Experiments on HBB gene-associated diseases demonstrate WISE reduces\nprocessed text by over 80% while achieving significantly higher recall over\nbaselines like search engines and other LLM-based approaches. ROUGE and BLEU\nmetrics reveal WISE's output is more unique than other systems, and a novel\nlevel-based metric shows it provides more in-depth information. We also explore\nhow the WISE workflow can be adapted for diverse domains like drug discovery,\nmaterial science, and social science, enabling efficient knowledge extraction\nand synthesis from unstructured scientific papers and web sources.", "published": "2025-06-21 04:22:34", "link": "http://arxiv.org/abs/2506.17580v1", "categories": ["cs.IR", "cs.AI", "cs.DL", "cs.ET"], "primary_category": "cs.IR"}
{"title": "Virtual Teleportation of CSIT via Non-Signaling Assistance", "abstract": "Non-signaling correlations, which (strictly) include quantum correlations,\nprovide a tractable path to explore the potential impact of quantum nonlocality\non the capacity of classical communication networks. Motivated by a recent\ndiscovery that certain wireless network settings benefit significantly from\nnon-signaling (NS) correlations, various generalizations are considered. First,\nit is shown that for a point to point discrete memoryless channel with a\nnon-causal channel state information at the transmitter (CSIT), the NS-assisted\nShannon capacity matches the classical (without NS assistance) capacity of the\nchannel for the setting where the state is also made available to the receiver.\nThe key insight is summarized as 'virtual teleportation of CSIT via\nNS-assistance' and is supported by further results as follows. For a discrete\nmemoryless 2-user broadcast channel (BC), the Shannon capacity region with\nNS-assistance available only between the transmitter and User 1, is found next.\nConsistent with the aforementioned key insight, the result matches the\nclassical capacity region for the setting where the desired message of User 2\nis made available in advance as side-information to User 1. The latter capacity\nregion is known from a result of Kramer and Shamai. Next, for a\nsemi-deterministic BC, the Shannon capacity region with full (tripartite)\nNS-assistance is shown to be the same as if only bipartite NS-assistance was\navailable between the transmitter and the non-deterministic user. Bipartite\nNS-assistance between the transmitter and only the deterministic user, does not\nimprove the capacity region relative to the corresponding classical setting.\nFinally, the analysis is extended to a K-user BC with full NS-assistance among\nall parties.", "published": "2025-06-21 20:21:03", "link": "http://arxiv.org/abs/2506.17803v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Quantizing for Noisy Flash Memory Channels", "abstract": "Flash memory-based processing-in-memory (flash-based PIM) offers high storage\ncapacity and computational efficiency but faces significant reliability\nchallenges due to noise in high-density multi-level cell (MLC) flash memories.\nExisting verify level optimization methods are designed for general storage\nscenarios and fail to address the unique requirements of flash-based PIM\nsystems, where metrics such as mean squared error (MSE) and peak\nsignal-to-noise ratio (PSNR) are critical. This paper introduces an integrated\nframework that jointly optimizes quantization and verify levels to minimize the\nMSE, considering both quantization and flash memory channel errors. We develop\nan iterative algorithm to solve the joint optimization problem. Experimental\nresults on quantized images and SwinIR model parameters stored in flash memory\nshow that the proposed method significantly improves the reliability of\nflash-based PIM systems.", "published": "2025-06-21 09:01:24", "link": "http://arxiv.org/abs/2506.17646v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Signal Recovery on Algebraic Varieties Using Linear Samples", "abstract": "The recovery of an unknown signal from its linear measurements is a\nfundamental problem spanning numerous scientific and engineering disciplines.\nCommonly, prior knowledge suggests that the underlying signal resides within a\nknown algebraic variety. This context naturally leads to a question: what is\nthe minimum number of measurements required to uniquely recover any signal\nbelonging to such an algebraic variety? In this survey paper, we introduce a\nmethod that leverages tools from algebraic geometry to address this question.\nWe then demonstrate the utility of this approach by applying it to two\nproblems: phase retrieval and low-rank matrix recovery. %Furthermore, this\npaper bridges abstract algebraic concepts with concrete signal processing. We\nalso highlight several open problems, which could serve as a basis for future\ninvestigations in this field.", "published": "2025-06-21 03:56:16", "link": "http://arxiv.org/abs/2506.17572v1", "categories": ["cs.IT", "math.AG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Joint Transmission for Cellular Networks with Pinching Antennas: System Design and Analysis", "abstract": "As an emerging flexible antenna technology for wireless communications,\npinching-antenna systems, offer distinct advantages in terms of cost efficiency\nand deployment flexibility. This paper investigates joint transmission\nstrategies of the base station (BS) and pinching antennas (PAS), focusing\nspecifically on how to cooperate efficiently between the BS and\nwaveguide-mounted pinching antennas for enhancing the performance of the user\nequipment (UE). By jointly considering the performance, flexibility, and\ncomplexity, we propose three joint BS-PAS transmission schemes along with the\nbest beamforming designs, namely standalone deployment (SD), semi-cooperative\ndeployment (SCD) and full-cooperative deployment (FCD). More specifically, for\neach BS-PAS joint transmission scheme, we conduct a comprehensive performance\nanalysis in terms of the power allocation strategy, beamforming design, and\npractical implementation considerations. We also derive closed-form expressions\nfor the average received SNR across the proposed BS-PAS joint transmission\nschemes, which are verified through Monte Carlo simulations. Finally, numerical\nresults demonstrate that deploying pinching antennas in cellular networks,\nparticularly through cooperation between the BS and PAS, can achieve\nsignificant performance gains. We further identify and characterize the key\nnetwork parameters that influence the performance, providing insights for\ndeploying pinching antennas.", "published": "2025-06-21 03:03:04", "link": "http://arxiv.org/abs/2506.17559v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Deep-OFDM: Neural Modulation for High Mobility", "abstract": "Orthogonal Frequency Division Multiplexing (OFDM) is the foundational\nwaveform in current 5G deployments due to its robustness in quasi-static\nchannels and efficient spectrum use. However, in high-mobility scenarios, OFDM\nsuffers from inter-carrier interference (ICI), and its reliance on dense pilot\npatterns and cyclic prefixes significantly reduces spectral efficiency. In this\nwork, we propose Deep-OFDM: a learnable modulation framework that augments\ntraditional OFDM by incorporating neural parameterization. Instead of mapping\neach symbol to a fixed resource element, Deep-OFDM spreads information across\nthe OFDM grid using a convolutional neural network modulator. This modulator is\njointly optimized with a neural receiver through end-to-end training, enabling\nthe system to adapt to time-varying channels without relying on explicit\nchannel estimation. Deep-OFDM outperforms conventional OFDM when paired with\nneural receiver baselines, particularly in pilot-sparse and pilotless regimes,\nachieving substantial gains in BLER and goodput, especially at high Doppler\nfrequencies. In the pilotless setting, the neural modulator learns a low-rank\nstructure that resembles a superimposed pilot, effectively enabling reliable\ncommunication without explicit overhead. Deep-OFDM demonstrates significant\nimprovements in BLER and goodput at high Doppler frequencies across various\nscenarios, including MIMO systems. Comprehensive ablation studies quantify the\nrole of nonlinear activations and characterize performance-complexity\ntrade-offs. These results highlight the potential of transmitter-receiver\nco-design for robust, resource-efficient communication, paving the way for\nAI-native physical layer designs in next-generation wireless systems.", "published": "2025-06-21 00:57:06", "link": "http://arxiv.org/abs/2506.17530v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Distributed Butterfly Analysis using Mobile Agents", "abstract": "Butterflies, or 4-cycles in bipartite graphs, are crucial for identifying\ncohesive structures and dense subgraphs. While agent-based data mining is\ngaining prominence, its application to bipartite networks remains relatively\nunexplored. We propose distributed, agent-based algorithms for \\emph{Butterfly\nCounting} in a bipartite graph $G((A,B),E)$. Agents first determine their\nrespective partitions and collaboratively construct a spanning tree, electing a\nleader within $O(n \\log \\lambda)$ rounds using only $O(\\log \\lambda)$ bits per\nagent. A novel meeting mechanism between adjacent agents improves efficiency\nand eliminates the need for prior knowledge of the graph, requiring only the\nhighest agent ID $\\lambda$ among the $n$ agents. Notably, our techniques\nnaturally extend to general graphs, where leader election and spanning tree\nconstruction maintain the same round and memory complexities. Building on these\nfoundations, agents count butterflies per node in $O(\\Delta)$ rounds and\ncompute the total butterfly count of $G$ in $O(\\Delta+\\min\\{|A|,|B|\\})$ rounds.", "published": "2025-06-21 14:27:32", "link": "http://arxiv.org/abs/2506.17721v1", "categories": ["cs.DC", "cs.MA"], "primary_category": "cs.DC"}
{"title": "Towards Zero-Shot Coordination between Teams of Agents: The N-XPlay Framework", "abstract": "Zero-shot coordination (ZSC) -- the ability to collaborate with unfamiliar\npartners -- is essential to making autonomous agents effective teammates.\nExisting ZSC methods evaluate coordination capabilities between two agents who\nhave not previously interacted. However, these scenarios do not reflect the\ncomplexity of real-world multi-agent systems, where coordination often involves\na hierarchy of sub-groups and interactions between teams of agents, known as\nMulti-Team Systems (MTS). To address this gap, we first introduce N-player\nOvercooked, an N-agent extension of the popular two-agent ZSC benchmark,\nenabling evaluation of ZSC in N-agent scenarios. We then propose N-XPlay for\nZSC in N-agent, multi-team settings. Comparison against Self-Play across two-,\nthree- and five-player Overcooked scenarios, where agents are split between an\n``ego-team'' and a group of unseen collaborators shows that agents trained with\nN-XPlay are better able to simultaneously balance ``intra-team'' and\n``inter-team'' coordination than agents trained with SP.", "published": "2025-06-21 03:04:53", "link": "http://arxiv.org/abs/2506.17560v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Numerical simulation of transient heat conduction with moving heat source using Physics Informed Neural Networks", "abstract": "In this paper, the physics informed neural networks (PINNs) is employed for\nthe numerical simulation of heat transfer involving a moving source. To reduce\nthe computational effort, a new training method is proposed that uses a\ncontinuous time-stepping through transfer learning. Within this, the time\ninterval is divided into smaller intervals and a single network is initialized.\nOn this single network each time interval is trained with the initial condition\nfor (n+1)th as the solution obtained at nth time increment. Thus, this\nframework enables the computation of large temporal intervals without\nincreasing the complexity of the network itself. The proposed framework is used\nto estimate the temperature distribution in a homogeneous medium with a moving\nheat source. The results from the proposed framework is compared with\ntraditional finite element method and a good agreement is seen.", "published": "2025-06-21 14:51:46", "link": "http://arxiv.org/abs/2506.17726v1", "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "math.NA"}
{"title": "Regular Tree Search for Simulation Optimization", "abstract": "Tackling simulation optimization problems with non-convex objective functions\nremains a fundamental challenge in operations research. In this paper, we\npropose a class of random search algorithms, called Regular Tree Search, which\nintegrates adaptive sampling with recursive partitioning of the search space.\nThe algorithm concentrates simulations on increasingly promising regions by\niteratively refining a tree structure. A tree search strategy guides sampling\ndecisions, while partitioning is triggered when the number of samples in a leaf\nnode exceeds a threshold that depends on its depth. Furthermore, a specific\ntree search strategy, Upper Confidence Bounds applied to Trees (UCT), is\nemployed in the Regular Tree Search. We prove global convergence under\nsub-Gaussian noise, based on assumptions involving the optimality gap, without\nrequiring continuity of the objective function. Numerical experiments confirm\nthat the algorithm reliably identifies the global optimum and provides accurate\nestimates of its objective value.", "published": "2025-06-21 12:07:01", "link": "http://arxiv.org/abs/2506.17696v1", "categories": ["math.OC", "cs.NA", "math.NA", "stat.ML", "I.6.1; G.1.2; G.1.6"], "primary_category": "math.OC"}
{"title": "A meshless generalized finite difference method for solving the Stokes-Darcy coupled problem in static and moving systems", "abstract": "In this paper, a meshless Generalized Finite Difference Method (GFDM) is\nproposed to deal with the Stokes-Darcy coupled problem with the\nBeavers-Joseph-Saffman (BJS) interface conditions. Some high order GFDMs are\nproposed to show the advantage of the high order GFDM for the Stokes-Darcy\ncoupled problem, which is that the high order method has high order accuracy\nand the convergence order. Some Stokes-Darcy coupled problems with closed\ninterfaces, which has more complex geometric shape, are given to show the\nadvantage of the GFDM for the complex interface. The interface location has\nbeen changed to show the influence of the interface location for the\nStokes-Darcy coupled problem. The BJS interface conditions has related to the\npartial derivatives of unknown variables and the GFDM has advantage in dealing\nwith the interface conditions with the jump of derivatives. Four numerical\nexamples have been provided to verify the existence of the good performance of\nthe GFDM for the Stokes-Darcy coupled problems, including that the simplicity,\naccuracy, and stability in static and moving systems. Especially, the GFDM has\nthe tolerance of the large jump. The Neaumann boundary condition is used in\nnumerical simulations.", "published": "2025-06-21 11:45:40", "link": "http://arxiv.org/abs/2506.17688v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Rank Inspired Neural Network for solving linear partial differential equations", "abstract": "This paper proposes a rank inspired neural network (RINN) to tackle the\ninitialization sensitivity issue of physics informed extreme learning machines\n(PIELM) when numerically solving partial differential equations (PDEs). Unlike\nPIELM which randomly initializes the parameters of its hidden layers, RINN\nincorporates a preconditioning stage. In this stage, covariance-driven\nregularization is employed to optimize the orthogonality of the basis functions\ngenerated by the last hidden layer. The key innovation lies in minimizing the\noff-diagonal elements of the covariance matrix derived from the hidden-layer\noutput. By doing so, pairwise orthogonality constraints across collocation\npoints are enforced which effectively enhances both the numerical stability and\nthe approximation ability of the optimized function space.The RINN algorithm\nunfolds in two sequential stages. First, it conducts a non-linear optimization\nprocess to orthogonalize the basis functions. Subsequently, it solves the PDE\nconstraints using linear least-squares method. Extensive numerical experiments\ndemonstrate that RINN significantly reduces performance variability due to\nparameter initialization compared to PIELM. Incorporating an early stopping\nmechanism based on PDE loss further improves stability, ensuring consistently\nhigh accuracy across diverse initialization settings.", "published": "2025-06-21 09:24:15", "link": "http://arxiv.org/abs/2506.17654v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Simultaneous Identification of Coefficients and Source in a Subdiffusion Equation from One Passive Measurement", "abstract": "This article is devoted to the detection of parameters in anomalous diffusion\nfrom a single passive measurement. More precisely, we consider the simultaneous\nidentification of coefficients as well as a time-dependent source term\nappearing in a time-fractional diffusion equation from a single boundary or\ninternal passive measurement. We obtain several uniqueness results in dimension\none as well as a multidimensional extension under some symmetry assumptions.\nOur analysis relies on spectral representation of solutions, complex and\nharmonic analysis combined with some known inverse spectral results for\nSturm-Liouville operators. The theoretical results are complemented by a\ncorresponding reconstruction algorithm and numerical simulations.", "published": "2025-06-21 09:13:16", "link": "http://arxiv.org/abs/2506.17648v1", "categories": ["math.AP", "cs.NA", "math.NA"], "primary_category": "math.AP"}
{"title": "Local feature filtering for scalable and well-conditioned Random Feature Methods", "abstract": "In recent years, machine learning has emerged as a powerful tool for solving\npartial differential equations (PDEs), with randomized neural networks showing\nremarkable potential. These networks, typically shallow, differ from\nconventional approaches by randomizing all parameters except those in the final\nlayer. Notably, by integrating techniques inspired by domain decomposition,\nthey achieve improved local accuracy and computational efficiency. Following\n\\cite{chen:2022:BTM}, we refer to these approaches as \\emph{random feature\nmethods} (RFM). Despite their promise, RFMs lead to highly ill-conditioned\nleast squares systems, posing a significant computational challenge. To address\nthis, we introduce a novel approach based on different strategies of local\nfiltering. This technique provides two key advantages: first, it enables the\nselective elimination of nonexpressive features, reducing system size and\nimproving the condition number without sacrificing accuracy; second, it\nfacilitates the construction of an efficient preconditioner for the global\nsystem. Our numerical experiments demonstrate that this strategy can rival or\neven outperform existing preconditioning techniques, both in terms of condition\nnumber and the efficiency of iterative solvers. These results underscore the\npotential of our method as a powerful enhancement to machine learning-based PDE\nsolvers.", "published": "2025-06-21 07:54:05", "link": "http://arxiv.org/abs/2506.17626v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A $C^0$ weak Galerkin method with preconditioning for constrained optimal control problems with general tracking", "abstract": "This paper presents a $C^0$ weak Galerkin ($C^0$-WG) method combined with an\nadditive Schwarz preconditioner for solving optimal control problems (OCPs)\ngoverned by partial differential equations with general tracking cost\nfunctionals and pointwise state constraints. These problems pose significant\nanalytical and numerical challenges due to the presence of fourth-order\nvariational inequalities and the reduced regularity of solutions. Our first\ncontribution is the design of a $C^0$-WG method based on globally continuous\nquadratic Lagrange elements, enabling efficient elementwise stiffness matrix\nassembly and parameter-free implementation while maintaining accuracy, as\nsupported by a rigorous error analysis. As a second contribution, we develop an\nadditive Schwarz preconditioner tailored to the $C^0$-WG method to improve\nsolver performance for the resulting ill-conditioned linear systems. Numerical\nexperiments confirm the effectiveness and robustness of the proposed method and\npreconditioner for both biharmonic and optimal control problems.", "published": "2025-06-21 07:04:30", "link": "http://arxiv.org/abs/2506.17619v1", "categories": ["math.NA", "cs.NA", "math.OC", "65N30, 49M41, 65F08, 65N12"], "primary_category": "math.NA"}
{"title": "A priori error analysis of consistent PINNs for parabolic PDEs", "abstract": "We present a new a priori analysis of a class of collocation methods for\nparabolic PDEs that rely only on pointwise data of force term, boundary data,\nand initial data. Under Besov regularity assumptions, we characterize the\noptimal recovery rate of the solution u based on sample complexity. We\nestablish error bounds by constructing a new consistent loss function that\neffectively controls the approximation error. This loss incorporates\ncontributions from the interior, boundary, and initial data in a discretized\nform and is designed to reflect the true PDE structure. Our theoretical results\ndemonstrate that minimizing this loss function yields near optimal recovery\nunder suitable conditions of regularity and sampling. Novel practical variants\nof the loss function are discussed, and numerical experiments confirm the\neffectiveness.", "published": "2025-06-21 06:44:29", "link": "http://arxiv.org/abs/2506.17614v1", "categories": ["math.NA", "cs.NA", "35B45, 35K20, 65M15, 41A25"], "primary_category": "math.NA"}
{"title": "Scattered point measurement-based regularization for backward problems for fractional wave equations", "abstract": "In this work, we are devoted to the reconstruction of an unknown initial\nvalue from the terminal data. The asymptotic and root-distribution properties\nof Mittag-Leffler functions are used to establish stability of the backward\nproblem. Furthermore, we introduce a regularization method that effectively\nhandles scattered point measurements contaminated with stochastic noise.\nFurthermore, we prove the stochastic convergence of our proposed regularization\nand provide an iterative algorithm to find the optimal regularization\nparameter. Finally, several numerical experiments are presented to demonstrate\nthe efficiency and accuracy of the algorithm.", "published": "2025-06-21 04:06:36", "link": "http://arxiv.org/abs/2506.17575v1", "categories": ["math.NA", "cs.NA", "35R11, 35R09, 35B40"], "primary_category": "math.NA"}
{"title": "Operator Splitting Methods: Numerical Solutions of Ordinary Differential Equations via Separation of Variables", "abstract": "This paper applies the concept of linear semigroups induced by nonlinear\nflows, originally developed by Dorroh and Neuberger in the 1990s, to the\napproximation of uniquely solvable initial value problems for nonlinear\nordinary differential equations. Building on a framework rooted in the earlier\nworks of Lie, Kowalewski, and Groebner, we analyze nonlinear systems through\nthe lens of the Koopman-Lie semigroup exp(tK), where K is the linear Lie\ngenerator associated with the flow induced by the nonlinear differential\nequation. A central feature of this approach is the decomposition K = K1 + ...\n+ KN, which enables the use of operator splitting methods. We revisit the\nfoundational first-order splitting scheme introduced by H. F. Trotter in 1959\nand extend it to higher-order schemes with improved error bounds. These\ntheoretical developments are supported by numerical examples that demonstrate\nthe accuracy and efficiency of the proposed methods, which are based entirely\non the classical separation of variables technique for solving ordinary\ndifferential equations.", "published": "2025-06-21 00:24:15", "link": "http://arxiv.org/abs/2506.17524v1", "categories": ["math.NA", "cs.NA", "math.DS", "65L05, 65L20, 47D03, 37M20"], "primary_category": "math.NA"}
{"title": "Structural Optimal Jacobian Accumulation and Minimum Edge Count are NP-Complete Under Vertex Elimination", "abstract": "We study graph-theoretic formulations of two fundamental problems in\nalgorithmic differentiation. The first (Structural Optimal Jacobian\nAccumulation) is that of computing a Jacobian while minimizing multiplications.\nThe second (Minimum Edge Count) is to find a minimum-size computational graph.\nFor both problems, we consider the vertex elimination operation. Our main\ncontribution is to show that both problems are NP-complete, thus resolving\nlongstanding open questions. In contrast to prior work, our reduction for\nStructural Optimal Jacobian Accumulation does not rely on any assumptions about\nthe algebraic relationships between local partial derivatives; we allow these\nvalues to be mutually independent. We also provide $O^*(2^n)$-time exact\nalgorithms for both problems, and show that under the exponential time\nhypothesis these running times are essentially tight. Finally, we provide a\ndata reduction rule for Structural Optimal Jacobian Accumulation by showing\nthat false twins may always be eliminated consecutively.", "published": "2025-06-21 00:02:38", "link": "http://arxiv.org/abs/2506.17521v1", "categories": ["cs.DS", "cs.NA", "math.NA"], "primary_category": "cs.DS"}
{"title": "Predicting Stock Market Crash with Bayesian Generalised Pareto Regression", "abstract": "This paper develops a Bayesian Generalised Pareto Regression (GPR) model to\nforecast extreme losses in Indian equity markets, with a focus on the Nifty 50\nindex. Extreme negative returns, though rare, can cause significant financial\ndisruption, and accurate modelling of such events is essential for effective\nrisk management. Traditional Generalised Pareto Distribution (GPD) models often\nignore market conditions; in contrast, our framework links the scale parameter\nto covariates using a log-linear function, allowing tail risk to respond\ndynamically to market volatility. We examine four prior choices for Bayesian\nregularisation of regression coefficients: Cauchy, Lasso (Laplace), Ridge\n(Gaussian), and Zellner's g-prior. Simulation results suggest that the Cauchy\nprior delivers the best trade-off between predictive accuracy and model\nsimplicity, achieving the lowest RMSE, AIC, and BIC values. Empirically, we\napply the model to large negative returns (exceeding 5%) in the Nifty 50 index.\nVolatility measures from the Nifty 50, S&P 500, and gold are used as covariates\nto capture both domestic and global risk drivers. Our findings show that tail\nrisk increases significantly with higher market volatility. In particular, both\nS&P 500 and gold volatilities contribute meaningfully to crash prediction,\nhighlighting global spillover and flight-to-safety effects. The proposed GPR\nmodel offers a robust and interpretable approach for tail risk forecasting in\nemerging markets. It improves upon traditional EVT-based models by\nincorporating real-time financial indicators, making it useful for\npractitioners, policymakers, and financial regulators concerned with systemic\nrisk and stress testing.", "published": "2025-06-21 02:36:05", "link": "http://arxiv.org/abs/2506.17549v1", "categories": ["q-fin.ST", "stat.AP", "stat.ML", "62K05, 05B0530"], "primary_category": "q-fin.ST"}
{"title": "Bayesian Inference for Left-Truncated Log-Logistic Distributions for Time-to-event Data Analysis", "abstract": "Parameter estimation is a foundational step in statistical modeling, enabling\nus to extract knowledge from data and apply it effectively. Bayesian estimation\nof parameters incorporates prior beliefs with observed data to infer\ndistribution parameters probabilistically and robustly. Moreover, it provides\nfull posterior distributions, allowing uncertainty quantification and\nregularization, especially useful in small or truncated samples. Utilizing the\nleft-truncated log-logistic (LTLL) distribution is particularly well-suited for\nmodeling time-to-event data where observations are subject to a known lower\nbound such as precipitation data and cancer survival times. In this paper, we\npropose a Bayesian approach for estimating the parameters of the LTLL\ndistribution with a fixed truncation point \\( x_L > 0 \\). Given a random\nvariable \\( X \\sim LL(\\alpha, \\beta; x_L) \\), where \\( \\alpha > 0 \\) is the\nscale parameter and \\( \\beta > 0 \\) is the shape parameter, the likelihood\nfunction is derived based on a truncated sample \\( X_1, X_2, \\dots, X_N \\) with\n\\( X_i > x_L \\). We assume independent prior distributions for the parameters,\nand the posterior inference is conducted via Markov Chain Monte Carlo sampling,\nspecifically using the Metropolis-Hastings algorithm to obtain posterior\nestimates \\( \\hat{\\alpha} \\) and \\( \\hat{\\beta} \\). Through simulation studies\nand real-world applications, we demonstrate that Bayesian estimation provides\nmore stable and reliable parameter estimates, particularly when the likelihood\nsurface is irregular due to left truncation. The results highlight the\nadvantages of Bayesian inference outperform the estimation of parameter\nuncertainty in truncated distributions for time to event data analysis.", "published": "2025-06-21 23:10:07", "link": "http://arxiv.org/abs/2506.17852v1", "categories": ["stat.ME", "cs.LG", "stat.AP", "stat.CO", "stat.ML", "62P10, 62P12, 62F15, 62N02"], "primary_category": "stat.ME"}
{"title": "Flatness After All?", "abstract": "Recent literature has examined the relationship between the curvature of the\nloss function at minima and generalization, mainly in the context of\noverparameterized networks. A key observation is that \"flat\" minima tend to\ngeneralize better than \"sharp\" minima. While this idea is supported by\nempirical evidence, it has also been shown that deep networks can generalize\neven with arbitrary sharpness, as measured by either the trace or the spectral\nnorm of the Hessian. In this paper, we argue that generalization could be\nassessed by measuring flatness using a soft rank measure of the Hessian. We\nshow that when the common neural network model (neural network with exponential\nfamily negative log likelihood loss) is calibrated, and its prediction error\nand its confidence in the prediction are not correlated with the first and the\nsecond derivatives of the network's output, our measure accurately captures the\nasymptotic expected generalization gap. For non-calibrated models, we connect\nour flatness measure to the well-known Takeuchi Information Criterion and show\nthat it still provides reliable estimates of generalization gaps for models\nthat are not overly confident. Experimental results indicate that our approach\noffers a robust estimate of the generalization gap compared to baselines.", "published": "2025-06-21 20:33:36", "link": "http://arxiv.org/abs/2506.17809v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SING: SDE Inference via Natural Gradients", "abstract": "Latent stochastic differential equation (SDE) models are important tools for\nthe unsupervised discovery of dynamical systems from data, with applications\nranging from engineering to neuroscience. In these complex domains, exact\nposterior inference of the latent state path is typically intractable,\nmotivating the use of approximate methods such as variational inference (VI).\nHowever, existing VI methods for inference in latent SDEs often suffer from\nslow convergence and numerical instability. Here, we propose SDE Inference via\nNatural Gradients (SING), a method that leverages natural gradient VI to\nefficiently exploit the underlying geometry of the model and variational\nposterior. SING enables fast and reliable inference in latent SDE models by\napproximating intractable integrals and parallelizing computations in time. We\nprovide theoretical guarantees that SING will approximately optimize the\nintractable, continuous-time objective of interest. Moreover, we demonstrate\nthat better state inference enables more accurate estimation of nonlinear drift\nfunctions using, for example, Gaussian process SDE models. SING outperforms\nprior methods in state inference and drift estimation on a variety of datasets,\nincluding a challenging application to modeling neural dynamics in freely\nbehaving animals. Altogether, our results illustrate the potential of SING as a\ntool for accurate inference in complex dynamical systems, especially those\ncharacterized by limited prior knowledge and non-conjugate structure.", "published": "2025-06-21 19:36:11", "link": "http://arxiv.org/abs/2506.17796v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Log-Normal Multiplicative Dynamics for Stable Low-Precision Training of Large Networks", "abstract": "Studies in neuroscience have shown that biological synapses follow a\nlog-normal distribution whose transitioning can be explained by noisy\nmultiplicative dynamics. Biological networks can function stably even under\ndynamically fluctuating conditions arising due to unreliable synaptic\ntransmissions. Here we ask: Is it possible to design similar multiplicative\ntraining in artificial neural networks? To answer this question, we derive a\nBayesian learning rule that assumes log-normal posterior distributions over\nweights which gives rise to a new Log-Normal Multiplicative Dynamics (LMD)\nalgorithm. The algorithm uses multiplicative updates with both noise and\nregularization applied multiplicatively. The method is as easy to implement as\nAdam and only requires one additional vector to store. Our results show that\nLMD achieves stable and accurate training-from-scratch under low-precision\nforward operations for Vision Transformer and GPT-2. These results suggest that\nmultiplicative dynamics, a biological feature, may enable stable low-precision\ninference and learning on future energy-efficient hardware.", "published": "2025-06-21 17:37:22", "link": "http://arxiv.org/abs/2506.17768v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Derandomizing Simultaneous Confidence Regions for Band-Limited Functions by Improved Norm Bounds and Majority-Voting Schemes", "abstract": "Band-limited functions are fundamental objects that are widely used in\nsystems theory and signal processing. In this paper we refine a recent\nnonparametric, nonasymptotic method for constructing simultaneous confidence\nregions for band-limited functions from noisy input-output measurements, by\nworking in a Paley-Wiener reproducing kernel Hilbert space. Kernel norm bounds\nare tightened using a uniformly-randomized Hoeffding's inequality for small\nsamples and an empirical Bernstein bound for larger ones. We derive an\napproximate threshold, based on the sample size and how informative the inputs\nare, that governs which bound to deploy. Finally, we apply majority voting to\naggregate confidence sets from random subsamples, boosting both stability and\nregion size. We prove that even per-input aggregated intervals retain their\nsimultaneous coverage guarantee. These refinements are also validated through\nnumerical experiments.", "published": "2025-06-21 17:14:38", "link": "http://arxiv.org/abs/2506.17764v1", "categories": ["stat.ML", "cs.LG", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "stat.ML"}
{"title": "Learning Time-Aware Causal Representation for Model Generalization in Evolving Domains", "abstract": "Endowing deep models with the ability to generalize in dynamic scenarios is\nof vital significance for real-world deployment, given the continuous and\ncomplex changes in data distribution. Recently, evolving domain generalization\n(EDG) has emerged to address distribution shifts over time, aiming to capture\nevolving patterns for improved model generalization. However, existing EDG\nmethods may suffer from spurious correlations by modeling only the dependence\nbetween data and targets across domains, creating a shortcut between\ntask-irrelevant factors and the target, which hinders generalization. To this\nend, we design a time-aware structural causal model (SCM) that incorporates\ndynamic causal factors and the causal mechanism drifts, and propose\n\\textbf{S}tatic-D\\textbf{YN}amic \\textbf{C}ausal Representation Learning\n(\\textbf{SYNC}), an approach that effectively learns time-aware causal\nrepresentations. Specifically, it integrates specially designed\ninformation-theoretic objectives into a sequential VAE framework which captures\nevolving patterns, and produces the desired representations by preserving\nintra-class compactness of causal factors both across and within domains.\nMoreover, we theoretically show that our method can yield the optimal causal\npredictor for each time domain. Results on both synthetic and real-world\ndatasets exhibit that SYNC can achieve superior temporal generalization\nperformance.", "published": "2025-06-21 14:05:37", "link": "http://arxiv.org/abs/2506.17718v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "CEGA: A Cost-Effective Approach for Graph-Based Model Extraction and Acquisition", "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable utility across\ndiverse applications, and their growing complexity has made Machine Learning as\na Service (MLaaS) a viable platform for scalable deployment. However, this\naccessibility also exposes GNN to serious security threats, most notably model\nextraction attacks (MEAs), in which adversaries strategically query a deployed\nmodel to construct a high-fidelity replica. In this work, we evaluate the\nvulnerability of GNNs to MEAs and explore their potential for cost-effective\nmodel acquisition in non-adversarial research settings. Importantly, adaptive\nnode querying strategies can also serve a critical role in research,\nparticularly when labeling data is expensive or time-consuming. By selectively\nsampling informative nodes, researchers can train high-performing GNNs with\nminimal supervision, which is particularly valuable in domains such as\nbiomedicine, where annotations often require expert input. To address this, we\npropose a node querying strategy tailored to a highly practical yet\nunderexplored scenario, where bulk queries are prohibited, and only a limited\nset of initial nodes is available. Our approach iteratively refines the node\nselection mechanism over multiple learning cycles, leveraging historical\nfeedback to improve extraction efficiency. Extensive experiments on benchmark\ngraph datasets demonstrate our superiority over comparable baselines on\naccuracy, fidelity, and F1 score under strict query-size constraints. These\nresults highlight both the susceptibility of deployed GNNs to extraction\nattacks and the promise of ethical, efficient GNN acquisition methods to\nsupport low-resource research environments.", "published": "2025-06-21 13:11:42", "link": "http://arxiv.org/abs/2506.17709v1", "categories": ["cs.LG", "cs.CR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Scalable Machine Learning Algorithms using Path Signatures", "abstract": "The interface between stochastic analysis and machine learning is a rapidly\nevolving field, with path signatures - iterated integrals that provide\nfaithful, hierarchical representations of paths - offering a principled and\nuniversal feature map for sequential and structured data. Rooted in rough path\ntheory, path signatures are invariant to reparameterization and well-suited for\nmodelling evolving dynamics, long-range dependencies, and irregular sampling -\ncommon challenges in real-world time series and graph data.\n  This thesis investigates how to harness the expressive power of path\nsignatures within scalable machine learning pipelines. It introduces a suite of\nmodels that combine theoretical robustness with computational efficiency,\nbridging rough path theory with probabilistic modelling, deep learning, and\nkernel methods. Key contributions include: Gaussian processes with signature\nkernel-based covariance functions for uncertainty-aware time series modelling;\nthe Seq2Tens framework, which employs low-rank tensor structure in the weight\nspace for scalable deep modelling of long-range dependencies; and graph-based\nmodels where expected signatures over graphs induce hypo-elliptic diffusion\nprocesses, offering expressive yet tractable alternatives to standard graph\nneural networks. Further developments include Random Fourier Signature\nFeatures, a scalable kernel approximation with theoretical guarantees, and\nRecurrent Sparse Spectrum Signature Gaussian Processes, which combine Gaussian\nprocesses, signature kernels, and random features with a principled forgetting\nmechanism for multi-horizon time series forecasting with adaptive context\nlength.\n  We hope this thesis serves as both a methodological toolkit and a conceptual\nbridge, and provides a useful reference for the current state of the art in\nscalable, signature-based learning for sequential and structured data.", "published": "2025-06-21 08:36:34", "link": "http://arxiv.org/abs/2506.17634v1", "categories": ["stat.ML", "cs.LG", "math.PR"], "primary_category": "stat.ML"}
{"title": "Towards Fundamental Limits for Active Multi-distribution Learning", "abstract": "Multi-distribution learning extends agnostic Probably Approximately Correct\n(PAC) learning to the setting in which a family of $k$ distributions,\n$\\{D_i\\}_{i\\in[k]}$, is considered and a classifier's performance is measured\nby its error under the worst distribution. This problem has attracted a lot of\nrecent interests due to its applications in collaborative learning, fairness,\nand robustness. Despite a rather complete picture of sample complexity of\npassive multi-distribution learning, research on active multi-distribution\nlearning remains scarce, with algorithms whose optimality remaining unknown.\n  In this paper, we develop new algorithms for active multi-distribution\nlearning and establish improved label complexity upper and lower bounds, in\ndistribution-dependent and distribution-free settings. Specifically, in the\nnear-realizable setting we prove an upper bound of\n$\\widetilde{O}\\Bigl(\\theta_{\\max}(d+k)\\ln\\frac{1}{\\varepsilon}\\Bigr)$ and\n$\\widetilde{O}\\Bigl(\\theta_{\\max}(d+k)\\Bigl(\\ln\\frac{1}{\\varepsilon}+\\frac{\\nu^2}{\\varepsilon^2}\\Bigr)+\\frac{k\\nu}{\\varepsilon^2}\\Bigr)$\nin the realizable and agnostic settings respectively, where $\\theta_{\\max}$ is\nthe maximum disagreement coefficient among the $k$ distributions, $d$ is the VC\ndimension of the hypothesis class, $\\nu$ is the multi-distribution error of the\nbest hypothesis, and $\\varepsilon$ is the target excess error. Moreover, we\nshow that the bound in the realizable setting is information-theoretically\noptimal and that the $k\\nu/\\varepsilon^2$ term in the agnostic setting is\nfundamental for proper learners. We also establish instance-dependent sample\ncomplexity bound for passive multidistribution learning that smoothly\ninterpolates between realizable and agnostic\nregimes~\\citep{blum2017collaborative,zhang2024optimal}, which may be of\nindependent interest.", "published": "2025-06-21 06:08:58", "link": "http://arxiv.org/abs/2506.17607v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "CultureMERT: Continual Pre-Training for Cross-Cultural Music Representation Learning", "abstract": "Recent advances in music foundation models have improved audio representation\nlearning, yet their effectiveness across diverse musical traditions remains\nlimited. We introduce CultureMERT-95M, a multi-culturally adapted foundation\nmodel developed to enhance cross-cultural music representation learning and\nunderstanding. To achieve this, we propose a two-stage continual pre-training\nstrategy that integrates learning rate re-warming and re-decaying, enabling\nstable adaptation even with limited computational resources. Training on a\n650-hour multi-cultural data mix, comprising Greek, Turkish, and Indian music\ntraditions, results in an average improvement of 4.9% in ROC-AUC and AP across\ndiverse non-Western music auto-tagging tasks, surpassing prior\nstate-of-the-art, with minimal forgetting on Western-centric benchmarks. We\nfurther investigate task arithmetic, an alternative approach to multi-cultural\nadaptation that merges single-culture adapted models in the weight space. Task\narithmetic performs on par with our multi-culturally trained model on\nnon-Western auto-tagging tasks and shows no regression on Western datasets.\nCross-cultural evaluation reveals that single-culture models transfer with\nvarying effectiveness across musical traditions, whereas the multi-culturally\nadapted model achieves the best overall performance. To support research on\nworld music representation learning, we publicly release CultureMERT-95M and\nCultureMERT-TA-95M, fostering the development of more culturally aware music\nfoundation models.", "published": "2025-06-21 21:16:39", "link": "http://arxiv.org/abs/2506.17818v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SLAP: Siamese Language-Audio Pretraining Without Negative Samples for Music Understanding", "abstract": "Joint embedding spaces have significantly advanced music understanding and\ngeneration by linking text and audio through multimodal contrastive learning.\nHowever, these approaches face large memory requirement limitations due to\nrelying on large batch sizes to effectively utilize negative samples. Further,\nmultimodal joint embedding spaces suffer from a modality gap wherein embeddings\nfrom different modalities lie in different manifolds of the embedding space. To\naddress these challenges, we propose Siamese Language-Audio Pretraining (SLAP),\na novel multimodal pretraining framework that allows learning powerful\nrepresentations without negative samples. SLAP adapts the Bootstrap Your Own\nLatent (BYOL) paradigm for multimodal audio-text training, promoting\nscalability in training multimodal embedding spaces.\n  We illustrate the ability of our model to learn meaningful relationships\nbetween music and text -- specifically, we show that SLAP outperforms CLAP on\ntasks such as text-music retrieval and zero-shot classification. We also\nobserve competitive downstream performance on several MIR tasks, including with\nlarger or supervised models (genre and instrument classification,\nauto-tagging). Additionally, our approach has attractive properties, such as a\nquantifiably reduced modality gap and improved robustness to batch size\nvariations on retrieval performance. Finally, its novel formulation unlocks\nlarge-scale training on a single GPU through gradient accumulation.", "published": "2025-06-21 21:04:09", "link": "http://arxiv.org/abs/2506.17815v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Algebraic Structures in Microtonal Music", "abstract": "We will discuss how certain group theory structures are found in music\ntheory. Western music splits the octave into 12 equal tones called half-steps.\nWe can take this division further and split the octave into 24 equal tones by\nsplitting each half-step in two, called a quarter-step. By assigning each of\nthese 24 notes a number, we can discuss musical actions mathematically. In this\npaper, we analyze 24-tone microtonal music and explore how musical and harmonic\nstructures in this system can be interpreted in terms of group-theoretic\nstructures. This work extends the study by Crans, Fiore, and Satyendra.", "published": "2025-06-21 18:13:45", "link": "http://arxiv.org/abs/2506.17778v1", "categories": ["cs.SD", "eess.AS", "math.HO", "20-01 (Primary), 00A08 (secondary)"], "primary_category": "cs.SD"}
{"title": "Low-resource keyword spotting using contrastively trained transformer acoustic word embeddings", "abstract": "We introduce a new approach, the ContrastiveTransformer, that produces\nacoustic word embeddings (AWEs) for the purpose of very low-resource keyword\nspotting. The ContrastiveTransformer, an encoder-only model, directly optimises\nthe embedding space using normalised temperature-scaled cross entropy (NT-Xent)\nloss. We use this model to perform keyword spotting for radio broadcasts in\nLuganda and Bambara, the latter a severely under-resourced language. We compare\nour model to various existing AWE approaches, including those constructed from\nlarge pre-trained self-supervised models, a recurrent encoder which previously\nused the NT-Xent loss, and a DTW baseline. We demonstrate that the proposed\ncontrastive transformer approach offers performance improvements over all\nconsidered existing approaches to very low-resource keyword spotting in both\nlanguages.", "published": "2025-06-21 11:47:05", "link": "http://arxiv.org/abs/2506.17690v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Machine Learning-Based Near-Field Localization in Mixed LoS/NLoS Scenarios", "abstract": "The conventional MUltiple SIgnal Classification (MUSIC) algorithm is\neffective for angle-of-arrival estimation in the far-field and can be extended\nfor full source localization in the near-field. However, it suffers from high\ncomputational complexity, which becomes especially prohibitive in near-field\nscenarios due to the need for exhaustive 3D grid searches. This paper presents\na machine learning-based approach for 3D localization of near-field sources in\nmixed line-of-sight (LoS)/non-LoS scenarios. A convolutional neural network\n(CNN) learns the mapping between the eigenvectors of the received signal's\ncovariance matrix at the anchor node and the sources' 3D locations. The\ndetailed description of the proposed CNN model is provided. The effectiveness\nand time efficiency of the proposed CNN-based localization approach is\ncorroborated via numerical simulations.", "published": "2025-06-21 20:42:14", "link": "http://arxiv.org/abs/2506.17810v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Locally Differential Private Coding-Assisted Succinct Histogram Protocol", "abstract": "A succinct histogram captures frequent items and their frequencies across\nclients and has become increasingly important for large-scale,\nprivacy-sensitive machine learning applications. To develop a rigorous\nframework to guarantee privacy for the succinct histogram problem, local\ndifferential privacy (LDP) has been utilized and shown promising results. To\npreserve data utility under LDP, which essentially works by intentionally\nadding noise to data, error-correcting codes naturally emerge as a promising\ntool for reliable information collection. This work presents the first\npractical $(\\epsilon,\\delta)$-LDP protocol for constructing succinct histograms\nusing error-correcting codes. To this end, polar codes and their\nsuccessive-cancellation list (SCL) decoding algorithms are leveraged as the\nunderlying coding scheme. More specifically, our protocol introduces\nGaussian-based perturbations to enable efficient soft decoding. Experiments\ndemonstrate that our approach outperforms prior methods, particularly for items\nwith low true frequencies, while maintaining similar frequency estimation\naccuracy.", "published": "2025-06-21 17:30:31", "link": "http://arxiv.org/abs/2506.17767v1", "categories": ["cs.CR", "cs.DC", "cs.LG", "eess.SP"], "primary_category": "cs.CR"}
{"title": "Rethinking the Role of Operating Conditions for Learning-based Multi-condition Fault Diagnosis", "abstract": "Multi-condition fault diagnosis is prevalent in industrial systems and\npresents substantial challenges for conventional diagnostic approaches. The\ndiscrepancy in data distributions across different operating conditions\ndegrades model performance when a model trained under one condition is applied\nto others. With the recent advancements in deep learning, transfer learning has\nbeen introduced to the fault diagnosis field as a paradigm for addressing\nmulti-condition fault diagnosis. Among these methods, domain generalization\napproaches can handle complex scenarios by extracting condition-invariant fault\nfeatures. Although many studies have considered fault diagnosis in specific\nmulti-condition scenarios, the extent to which operating conditions affect\nfault information has been scarcely studied, which is crucial. However, the\nextent to which operating conditions affect fault information has been scarcely\nstudied, which is crucial. When operating conditions have a significant impact\non fault features, directly applying domain generalization methods may lead the\nmodel to learn condition-specific information, thereby reducing its overall\ngeneralization ability. This paper investigates the performance of existing\nend-to-end domain generalization methods under varying conditions, specifically\nin variable-speed and variable-load scenarios, using multiple experiments on a\nreal-world gearbox. Additionally, a two-stage diagnostic framework is proposed,\naiming to improve fault diagnosis performance under scenarios with significant\noperating condition impacts. By incorporating a domain-generalized encoder with\na retraining strategy, the framework is able to extract condition-invariant\nfault features while simultaneously alleviating potential overfitting to the\nsource domain. Several experiments on a real-world gearbox dataset are\nconducted to validate the effectiveness of the proposed approach.", "published": "2025-06-21 15:34:51", "link": "http://arxiv.org/abs/2506.17740v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Two-Stage Prony-Based Estimation of Fractional Delay and Doppler Shifts in OTFS Modulation", "abstract": "This paper addresses the estimation of fractional delay and Doppler shifts in\nmultipath channels that cause doubly selective fading-an essential task for\nintegrated sensing and communication (ISAC) systems in high-mobility\nenvironments. Orthogonal Time Frequency Space (OTFS) modulation enables simple\nand robust channel compensation under such conditions. However, fractional\ndelay and Doppler components introduce inter-path interference, degrading\nestimation accuracy. We propose a two-stage estimation method based on Prony's\ntechnique using OTFS pilot signals with M subchannels and N pilot repetitions.\nIn the first stage, Doppler frequencies are estimated by jointly solving M\ncoupled Prony equations, exploiting the periodicity of the pilot signal. In the\nsecond stage, delays are estimated by applying the discrete Fourier transform\n(DFT) and Prony's method to each Doppler component obtained in the first stage.\nThe proposed method can accurately estimate up to N-1 delay-Doppler parameters\nunder noiseless conditions. In noisy environments, conventional information\ncriteria such as AIC and BIC yield suboptimal performance; thus, a heuristic\nmodel order selection is adopted. Numerical simulations confirm that the\nproposed method achieves high estimation accuracy, highlighting its potential\nfor future ISAC frameworks.", "published": "2025-06-21 05:31:29", "link": "http://arxiv.org/abs/2506.17599v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
