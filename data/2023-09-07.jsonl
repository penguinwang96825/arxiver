{"title": "From Base to Conversational: Japanese Instruction Dataset and Tuning\n  Large Language Models", "abstract": "Instruction tuning is essential for large language models (LLMs) to become\ninteractive. While many instruction tuning datasets exist in English, there is\na noticeable lack in other languages. Also, their effectiveness has not been\nwell verified in non-English languages. We construct a Japanese instruction\ndataset by expanding and filtering existing datasets and apply the dataset to a\nJapanese pre-trained base model. We performed Low-Rank Adaptation (LoRA) tuning\non both Japanese and English existing models using our instruction dataset. We\nevaluated these models from both quantitative and qualitative perspectives. As\na result, the effectiveness of Japanese instruction datasets is confirmed. The\nresults also indicate that even with relatively small LLMs, performances in\ndownstream tasks would be improved through instruction tuning. Our instruction\ndataset, tuned models, and implementation are publicly available online.", "published": "2023-09-07 00:14:37", "link": "http://arxiv.org/abs/2309.03412v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Open Information Extraction with Large Language Models: A\n  Study on Demonstration Uncertainty", "abstract": "Open Information Extraction (OIE) task aims at extracting structured facts\nfrom unstructured text, typically in the form of (subject, relation, object)\ntriples. Despite the potential of large language models (LLMs) like ChatGPT as\na general task solver, they lag behind state-of-the-art (supervised) methods in\nOIE tasks due to two key issues. First, LLMs struggle to distinguish irrelevant\ncontext from relevant relations and generate structured output due to the\nrestrictions on fine-tuning the model. Second, LLMs generates responses\nautoregressively based on probability, which makes the predicted relations lack\nconfidence. In this paper, we assess the capabilities of LLMs in improving the\nOIE task. Particularly, we propose various in-context learning strategies to\nenhance LLM's instruction-following ability and a demonstration uncertainty\nquantification module to enhance the confidence of the generated relations. Our\nexperiments on three OIE benchmark datasets show that our approach holds its\nown against established supervised methods, both quantitatively and\nqualitatively.", "published": "2023-09-07 01:35:24", "link": "http://arxiv.org/abs/2309.03433v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Anchor Learning Approach for Citation Field Learning", "abstract": "Citation field learning is to segment a citation string into fields of\ninterest such as author, title, and venue. Extracting such fields from\ncitations is crucial for citation indexing, researcher profile analysis, etc.\nUser-generated resources like academic homepages and Curriculum Vitae, provide\nrich citation field information. However, extracting fields from these\nresources is challenging due to inconsistent citation styles, incomplete\nsentence syntax, and insufficient training data. To address these challenges,\nwe propose a novel algorithm, CIFAL (citation field learning by anchor\nlearning), to boost the citation field learning performance. CIFAL leverages\nthe anchor learning, which is model-agnostic for any Pre-trained Language\nModel, to help capture citation patterns from the data of different citation\nstyles. The experiments demonstrate that CIFAL outperforms state-of-the-art\nmethods in citation field learning, achieving a 2.68% improvement in\nfield-level F1-scores. Extensive analysis of the results further confirms the\neffectiveness of CIFAL quantitatively and qualitatively.", "published": "2023-09-07 08:42:40", "link": "http://arxiv.org/abs/2309.03559v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "All Labels Together: Low-shot Intent Detection with an Efficient Label\n  Semantic Encoding Paradigm", "abstract": "In intent detection tasks, leveraging meaningful semantic information from\nintent labels can be particularly beneficial for few-shot scenarios. However,\nexisting few-shot intent detection methods either ignore the intent labels,\n(e.g. treating intents as indices) or do not fully utilize this information\n(e.g. only using part of the intent labels). In this work, we present an\nend-to-end One-to-All system that enables the comparison of an input utterance\nwith all label candidates. The system can then fully utilize label semantics in\nthis way. Experiments on three few-shot intent detection tasks demonstrate that\nOne-to-All is especially effective when the training resource is extremely\nscarce, achieving state-of-the-art performance in 1-, 3- and 5-shot settings.\nMoreover, we present a novel pretraining strategy for our model that utilizes\nindirect supervision from paraphrasing, enabling zero-shot cross-domain\ngeneralization on intent detection tasks. Our code is at\nhttps://github.com/jiangshdd/AllLablesTogether.", "published": "2023-09-07 08:50:45", "link": "http://arxiv.org/abs/2309.03563v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BNS-Net: A Dual-channel Sarcasm Detection Method Considering\n  Behavior-level and Sentence-level Conflicts", "abstract": "Sarcasm detection is a binary classification task that aims to determine\nwhether a given utterance is sarcastic. Over the past decade, sarcasm detection\nhas evolved from classical pattern recognition to deep learning approaches,\nwhere features such as user profile, punctuation and sentiment words have been\ncommonly employed for sarcasm detection. In real-life sarcastic expressions,\nbehaviors without explicit sentimental cues often serve as carriers of implicit\nsentimental meanings. Motivated by this observation, we proposed a dual-channel\nsarcasm detection model named BNS-Net. The model considers behavior and\nsentence conflicts in two channels. Channel 1: Behavior-level Conflict Channel\nreconstructs the text based on core verbs while leveraging the modified\nattention mechanism to highlight conflict information. Channel 2:\nSentence-level Conflict Channel introduces external sentiment knowledge to\nsegment the text into explicit and implicit sentences, capturing conflicts\nbetween them. To validate the effectiveness of BNS-Net, several comparative and\nablation experiments are conducted on three public sarcasm datasets. The\nanalysis and evaluation of experimental results demonstrate that the BNS-Net\neffectively identifies sarcasm in text and achieves the state-of-the-art\nperformance.", "published": "2023-09-07 11:55:11", "link": "http://arxiv.org/abs/2309.03658v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring an LM to generate Prolog Predicates from Mathematics Questions", "abstract": "Recently, there has been a surge in interest in NLP driven by ChatGPT.\nChatGPT, a transformer-based generative language model of substantial scale,\nexhibits versatility in performing various tasks based on natural language.\nNevertheless, large language models often exhibit poor performance in solving\nmathematics questions that require reasoning. Prior research has demonstrated\nthe effectiveness of chain-of-thought prompting in enhancing reasoning\ncapabilities. Now, we aim to investigate whether fine-tuning a model for the\ngeneration of Prolog codes, a logic language, and subsequently passing these\ncodes to a compiler can further improve accuracy. Consequently, we employ\nchain-of-thought to fine-tune LLaMA7B as a baseline model and develop other\nfine-tuned LLaMA7B models for the generation of Prolog code, Prolog code +\nchain-of-thought, and chain-of-thought + Prolog code, respectively. The results\nreveal that the Prolog generation model surpasses the baseline in performance,\nwhile the combination generation models do not yield significant improvements.\nThe Prolog corpus based on GSM8K and the correspondingly finetuned Prolog\ngeneration model based on LLaMA7B are released to the research community.", "published": "2023-09-07 12:10:47", "link": "http://arxiv.org/abs/2309.03667v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word segmentation granularity in Korean", "abstract": "This paper describes word {segmentation} granularity in Korean language\nprocessing. From a word separated by blank space, which is termed an eojeol, to\na sequence of morphemes in Korean, there are multiple possible levels of word\nsegmentation granularity in Korean. For specific language processing and corpus\nannotation tasks, several different granularity levels have been proposed and\nutilized, because the agglutinative languages including Korean language have a\none-to-one mapping between functional morpheme and syntactic category. Thus, we\nanalyze these different granularity levels, presenting the examples of Korean\nlanguage processing systems for future reference. Interestingly, the\ngranularity by separating only functional morphemes including case markers and\nverbal endings, and keeping other suffixes for morphological derivation results\nin the optimal performance for phrase structure parsing. This contradicts\nprevious best practices for Korean language processing, which has been the de\nfacto standard for various applications that require separating all morphemes.", "published": "2023-09-07 13:42:05", "link": "http://arxiv.org/abs/2309.03713v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Daunting Dilemma with Sentence Encoders: Success on Standard\n  Benchmarks, Failure in Capturing Basic Semantic Properties", "abstract": "In this paper, we adopted a retrospective approach to examine and compare\nfive existing popular sentence encoders, i.e., Sentence-BERT, Universal\nSentence Encoder (USE), LASER, InferSent, and Doc2vec, in terms of their\nperformance on downstream tasks versus their capability to capture basic\nsemantic properties. Initially, we evaluated all five sentence encoders on the\npopular SentEval benchmark and found that multiple sentence encoders perform\nquite well on a variety of popular downstream tasks. However, being unable to\nfind a single winner in all cases, we designed further experiments to gain a\ndeeper understanding of their behavior. Specifically, we proposed four semantic\nevaluation criteria, i.e., Paraphrasing, Synonym Replacement, Antonym\nReplacement, and Sentence Jumbling, and evaluated the same five sentence\nencoders using these criteria. We found that the Sentence-Bert and USE models\npass the paraphrasing criterion, with SBERT being the superior between the two.\nLASER dominates in the case of the synonym replacement criterion.\nInterestingly, all the sentence encoders failed the antonym replacement and\njumbling criteria. These results suggest that although these popular sentence\nencoders perform quite well on the SentEval benchmark, they still struggle to\ncapture some basic semantic properties, thus, posing a daunting dilemma in NLP\nresearch.", "published": "2023-09-07 14:42:35", "link": "http://arxiv.org/abs/2309.03747v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "USA: Universal Sentiment Analysis Model & Construction of Japanese\n  Sentiment Text Classification and Part of Speech Dataset", "abstract": "Sentiment analysis is a pivotal task in the domain of natural language\nprocessing. It encompasses both text-level sentiment polarity classification\nand word-level Part of Speech(POS) sentiment polarity determination. Such\nanalysis challenges models to understand text holistically while also\nextracting nuanced information. With the rise of Large Language Models(LLMs),\nnew avenues for sentiment analysis have opened. This paper proposes enhancing\nperformance by leveraging the Mutual Reinforcement Effect(MRE) between\nindividual words and the overall text. It delves into how word polarity\ninfluences the overarching sentiment of a passage. To support our research, we\nannotated four novel Sentiment Text Classification and Part of Speech(SCPOS)\ndatasets, building upon existing sentiment classification datasets.\nFurthermore, we developed a Universal Sentiment Analysis(USA) model, with a\n7-billion parameter size. Experimental results revealed that our model\nsurpassed the performance of gpt-3.5-turbo across all four datasets,\nunderscoring the significance of MRE in sentiment analysis.", "published": "2023-09-07 15:35:00", "link": "http://arxiv.org/abs/2309.03787v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models Are Not Robust Multiple Choice Selectors", "abstract": "Multiple choice questions (MCQs) serve as a common yet important task format\nin the evaluation of large language models (LLMs). This work shows that modern\nLLMs are vulnerable to option position changes in MCQs due to their inherent\n\"selection bias\", namely, they prefer to select specific option IDs as answers\n(like \"Option A\"). Through extensive empirical analyses with 20 LLMs on three\nbenchmarks, we pinpoint that this behavioral bias primarily stems from LLMs'\ntoken bias, where the model a priori assigns more probabilistic mass to\nspecific option ID tokens (e.g., A/B/C/D) when predicting answers from the\noption IDs. To mitigate selection bias, we propose a label-free, inference-time\ndebiasing method, called PriDe, which separates the model's prior bias for\noption IDs from the overall prediction distribution. PriDe first estimates the\nprior by permutating option contents on a small number of test samples, and\nthen applies the estimated prior to debias the remaining samples. We\ndemonstrate that it achieves interpretable and transferable debiasing with high\ncomputational efficiency. We hope this work can draw broader research attention\nto the bias and robustness of modern LLMs.", "published": "2023-09-07 17:44:56", "link": "http://arxiv.org/abs/2309.03882v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Supervised Learning and Large Language Model Benchmarks on Mental Health\n  Datasets: Cognitive Distortions and Suicidal Risks in Chinese Social Media", "abstract": "On social media, users often express their personal feelings, which may\nexhibit cognitive distortions or even suicidal tendencies on certain specific\ntopics. Early recognition of these signs is critical for effective\npsychological intervention. In this paper, we introduce two novel datasets from\nChinese social media: SOS-HL-1K for suicidal risk classification and\nSocialCD-3K for cognitive distortions detection. The SOS-HL-1K dataset\ncontained 1,249 posts and SocialCD-3K dataset was a multi-label classification\ndataset that containing 3,407 posts. We propose a comprehensive evaluation\nusing two supervised learning methods and eight large language models (LLMs) on\nthe proposed datasets. From the prompt engineering perspective, we experimented\nwith two types of prompt strategies, including four zero-shot and five few-shot\nstrategies. We also evaluated the performance of the LLMs after fine-tuning on\nthe proposed tasks. The experimental results show that there is still a huge\ngap between LLMs relying only on prompt engineering and supervised learning. In\nthe suicide classification task, this gap is 6.95% points in F1-score, while in\nthe cognitive distortion task, the gap is even more pronounced, reaching 31.53%\npoints in F1-score. However, after fine-tuning, this difference is\nsignificantly reduced. In the suicide and cognitive distortion classification\ntasks, the gap decreases to 4.31% and 3.14%, respectively. This research\nhighlights the potential of LLMs in psychological contexts, but supervised\nlearning remains necessary for more challenging tasks. All datasets and code\nare made available.", "published": "2023-09-07 08:50:46", "link": "http://arxiv.org/abs/2309.03564v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Loquacity and Visible Emotion: ChatGPT as a Policy Advisor", "abstract": "ChatGPT, a software seeking to simulate human conversational abilities, is\nattracting increasing attention. It is sometimes portrayed as a groundbreaking\nproductivity aid, including for creative work. In this paper, we run an\nexperiment to assess its potential in complex writing tasks. We ask the\nsoftware to compose a policy brief for the Board of the Bank of Italy. We find\nthat ChatGPT can accelerate workflows by providing well-structured content\nsuggestions, and by producing extensive, linguistically correct text in a\nmatter of seconds. It does, however, require a significant amount of expert\nsupervision, which partially offsets productivity gains. If the app is used\nnaively, output can be incorrect, superficial, or irrelevant. Superficiality is\nan especially problematic limitation in the context of policy advice intended\nfor high-level audiences.", "published": "2023-09-07 09:40:12", "link": "http://arxiv.org/abs/2309.03595v1", "categories": ["cs.CL", "cs.HC", "J.4; K.4.1"], "primary_category": "cs.CL"}
{"title": "FLM-101B: An Open LLM and How to Train It with $100K Budget", "abstract": "Large language models (LLMs) are considered important approaches towards\nfoundational machine intelligence, achieving remarkable success in Natural\nLanguage Processing and multimodal tasks, among others. However, the carbon\nfootprints and financial costs originating from heavy pre-training computation\nis a non-negligible issue. Progressive training methods, inspired by the\nneurogenesis process that grows neural structures, have shown potential to\naccelerate LLM pre-training. However, the algorithms, implementation, and\npractices for progressively training LLMs beyond 100B parameters remain\nunderexplored. In this paper, we show that our model, namely FLM-101B, trained\nwith our growth strategy under a budget of \\$100K, reaches 80\\% of the\nbaselines' performances with only 10\\% of their floating-point operations. We\nbelieve that further studies on progressive training will benefit the community\nby cutting down the costs and promoting green AI. The checkpoint of FLM-101B is\nreleased at https://huggingface.co/CofeAI/FLM-101B.", "published": "2023-09-07 17:07:36", "link": "http://arxiv.org/abs/2309.03852v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Introducing \"Forecast Utterance\" for Conversational Data Science", "abstract": "Envision an intelligent agent capable of assisting users in conducting\nforecasting tasks through intuitive, natural conversations, without requiring\nin-depth knowledge of the underlying machine learning (ML) processes. A\nsignificant challenge for the agent in this endeavor is to accurately\ncomprehend the user's prediction goals and, consequently, formulate precise ML\ntasks. In this paper, we take a pioneering step towards this ambitious goal by\nintroducing a new concept called Forecast Utterance and then focus on the\nautomatic and accurate interpretation of users' prediction goals from these\nutterances. Specifically, we frame the task as a slot-filling problem, where\neach slot corresponds to a specific aspect of the goal prediction task. We then\nemploy two zero-shot methods for solving the slot-filling task, namely: 1)\nEntity Extraction (EE), and 2) Question-Answering (QA) techniques. Our\nexperiments, conducted with three meticulously crafted data sets, validate the\nviability of our ambitious goal and demonstrate the effectiveness of both EE\nand QA techniques in interpreting Forecast Utterances.", "published": "2023-09-07 17:41:41", "link": "http://arxiv.org/abs/2309.03877v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "TIDE: Textual Identity Detection for Evaluating and Augmenting\n  Classification and Language Models", "abstract": "Machine learning models can perpetuate unintended biases from unfair and\nimbalanced datasets. Evaluating and debiasing these datasets and models is\nespecially hard in text datasets where sensitive attributes such as race,\ngender, and sexual orientation may not be available. When these models are\ndeployed into society, they can lead to unfair outcomes for historically\nunderrepresented groups. In this paper, we present a dataset coupled with an\napproach to improve text fairness in classifiers and language models. We create\na new, more comprehensive identity lexicon, TIDAL, which includes 15,123\nidentity terms and associated sense context across three demographic\ncategories. We leverage TIDAL to develop an identity annotation and\naugmentation tool that can be used to improve the availability of identity\ncontext and the effectiveness of ML fairness techniques. We evaluate our\napproaches using human contributors, and additionally run experiments focused\non dataset and model debiasing. Results show our assistive annotation technique\nimproves the reliability and velocity of human-in-the-loop processes. Our\ndataset and methods uncover more disparities during evaluation, and also\nproduce more fair models during remediation. These approaches provide a\npractical path forward for scaling classifier and generative model fairness in\nreal-world settings.", "published": "2023-09-07 21:44:42", "link": "http://arxiv.org/abs/2309.04027v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluation and Enhancement of Semantic Grounding in Large\n  Vision-Language Models", "abstract": "Large Vision-Language Models (LVLMs) offer remarkable benefits for a variety\nof vision-language tasks. However, a challenge hindering their application in\nreal-world scenarios, particularly regarding safety, robustness, and\nreliability, is their constrained semantic grounding ability, which pertains to\nconnecting language to the physical-world entities or concepts referenced in\nimages. Therefore, a crucial need arises for a comprehensive study to assess\nthe semantic grounding ability of widely used LVLMs. Despite the significance,\nsufficient investigation in this direction is currently lacking. Our work\nbridges this gap by designing a pipeline for generating large-scale evaluation\ndatasets covering fine-grained semantic information, such as color, number,\nmaterial, etc., along with a thorough assessment of seven popular LVLMs'\nsemantic grounding ability. Results highlight prevalent misgrounding across\nvarious aspects and degrees. To address this issue, we propose a data-centric\nenhancement method that aims to improve LVLMs' semantic grounding ability\nthrough multimodal instruction tuning on fine-grained conversations.\nExperiments on enhanced LVLMs demonstrate notable improvements in addressing\nmisgrounding issues.", "published": "2023-09-07 22:59:56", "link": "http://arxiv.org/abs/2309.04041v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Can Large Language Models Discern Evidence for Scientific Hypotheses?\n  Case Studies in the Social Sciences", "abstract": "Hypothesis formulation and testing are central to empirical research. A\nstrong hypothesis is a best guess based on existing evidence and informed by a\ncomprehensive view of relevant literature. However, with exponential increase\nin the number of scientific articles published annually, manual aggregation and\nsynthesis of evidence related to a given hypothesis is a challenge. Our work\nexplores the ability of current large language models (LLMs) to discern\nevidence in support or refute of specific hypotheses based on the text of\nscientific abstracts. We share a novel dataset for the task of scientific\nhypothesis evidencing using community-driven annotations of studies in the\nsocial sciences. We compare the performance of LLMs to several state-of-the-art\nbenchmarks and highlight opportunities for future research in this area. The\ndataset is available at\nhttps://github.com/Sai90000/ScientificHypothesisEvidencing.git", "published": "2023-09-07 04:15:17", "link": "http://arxiv.org/abs/2309.06578v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models as Optimizers", "abstract": "Optimization is ubiquitous. While derivative-based algorithms have been\npowerful tools for various problems, the absence of gradient imposes challenges\non many real-world applications. In this work, we propose Optimization by\nPROmpting (OPRO), a simple and effective approach to leverage large language\nmodels (LLMs) as optimizers, where the optimization task is described in\nnatural language. In each optimization step, the LLM generates new solutions\nfrom the prompt that contains previously generated solutions with their values,\nthen the new solutions are evaluated and added to the prompt for the next\noptimization step. We first showcase OPRO on linear regression and traveling\nsalesman problems, then move on to our main application in prompt optimization,\nwhere the goal is to find instructions that maximize the task accuracy. With a\nvariety of LLMs, we demonstrate that the best prompts optimized by OPRO\noutperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on\nBig-Bench Hard tasks. Code at https://github.com/google-deepmind/opro.", "published": "2023-09-07 00:07:15", "link": "http://arxiv.org/abs/2309.03409v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "XGen-7B Technical Report", "abstract": "Large Language Models (LLMs) have become ubiquitous across various domains,\ntransforming the way we interact with information and conduct research.\nHowever, most high-performing LLMs remain confined behind proprietary walls,\nhindering scientific progress. Most open-source LLMs, on the other hand, are\nlimited in their ability to support longer sequence lengths, which is a key\nrequirement for many tasks that require inference over an input context. To\naddress this, we have trained XGen, a series of 7B parameter models on up to 8K\nsequence length for up to 1.5T tokens. We have also finetuned the XGen models\non public-domain instructional data, creating their instruction-tuned\ncounterparts (XGen-Inst). We open-source our models for both research\nadvancements and commercial applications. Our evaluation on standard benchmarks\nshows that XGen models achieve comparable or better results when compared with\nstate-of-the-art open-source LLMs. Our targeted evaluation on long sequence\nmodeling tasks shows the benefits of our 8K-sequence models over 2K-sequence\nopen-source LLMs.", "published": "2023-09-07 02:20:03", "link": "http://arxiv.org/abs/2309.03450v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Machine Learning for Tangible Effects: Natural Language Processing for\n  Uncovering the Illicit Massage Industry & Computer Vision for Tactile Sensing", "abstract": "I explore two questions in this thesis: how can computer science be used to\nfight human trafficking? And how can computer vision create a sense of touch?\n  I use natural language processing (NLP) to monitor the United States illicit\nmassage industry (IMI), a multi-billion dollar industry that offers not just\ntherapeutic massages but also commercial sexual services. Employees of this\nindustry are often immigrant women with few job opportunities, leaving them\nvulnerable to fraud, coercion, and other facets of human trafficking.\nMonitoring spatiotemporal trends helps prevent trafficking in the IMI. By\ncreating datasets with three publicly-accessible websites: Google Places,\nRubmaps, and AMPReviews, combined with NLP techniques such as bag-of-words and\nWord2Vec, I show how to derive insights into the labor pressures and language\nbarriers that employees face, as well as the income, demographics, and societal\npressures affecting sex buyers. I include a call-to-action to other researchers\ngiven these datasets. I also consider how to creating synthetic financial data,\nwhich can aid with counter-trafficking in the banking sector. I use an\nagent-based model to create both tabular and payee-recipient graph data.\n  I then consider the role of computer vision in making tactile sensors. I\nreport on a novel sensor, the Digger Finger, that adapts the Gelsight sensor to\nfinding objects in granular media. Changes include using a wedge shape to\nfacilitate digging, replacing the internal lighting LEDs with fluorescent\npaint, and adding a vibrator motor to counteract jamming. Finally, I also show\nhow to use a webcam and a printed reference marker, or fiducial, to create a\nlow-cost six-axis force-torque sensor. This sensor is up to a hundred times\nless expensive than commercial sensors, allowing for a wider range of\napplications. For this and earlier chapters I release design files and code as\nopen source.", "published": "2023-09-07 04:04:01", "link": "http://arxiv.org/abs/2309.03470v1", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Evaluating ChatGPT as a Recommender System: A Rigorous Approach", "abstract": "Large Language Models (LLMs) have recently shown impressive abilities in\nhandling various natural language-related tasks. Among different LLMs, current\nstudies have assessed ChatGPT's superior performance across manifold tasks,\nespecially under the zero/few-shot prompting conditions. Given such successes,\nthe Recommender Systems (RSs) research community have started investigating its\npotential applications within the recommendation scenario. However, although\nvarious methods have been proposed to integrate ChatGPT's capabilities into\nRSs, current research struggles to comprehensively evaluate such models while\nconsidering the peculiarities of generative models. Often, evaluations do not\nconsider hallucinations, duplications, and out-of-the-closed domain\nrecommendations and solely focus on accuracy metrics, neglecting the impact on\nbeyond-accuracy facets. To bridge this gap, we propose a robust evaluation\npipeline to assess ChatGPT's ability as an RS and post-process ChatGPT\nrecommendations to account for these aspects. Through this pipeline, we\ninvestigate ChatGPT-3.5 and ChatGPT-4 performance in the recommendation task\nunder the zero-shot condition employing the role-playing prompt. We analyze the\nmodel's functionality in three settings: the Top-N Recommendation, the\ncold-start recommendation, and the re-ranking of a list of recommendations, and\nin three domains: movies, music, and books. The experiments reveal that ChatGPT\nexhibits higher accuracy than the baselines on books domain. It also excels in\nre-ranking and cold-start scenarios while maintaining reasonable\nbeyond-accuracy metrics. Furthermore, we measure the similarity between the\nChatGPT recommendations and the other recommenders, providing insights about\nhow ChatGPT could be categorized in the realm of recommender systems. The\nevaluation pipeline is publicly released for future research.", "published": "2023-09-07 10:13:09", "link": "http://arxiv.org/abs/2309.03613v2", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Enhancing Pipeline-Based Conversational Agents with Large Language\n  Models", "abstract": "The latest advancements in AI and deep learning have led to a breakthrough in\nlarge language model (LLM)-based agents such as GPT-4. However, many commercial\nconversational agent development tools are pipeline-based and have limitations\nin holding a human-like conversation. This paper investigates the capabilities\nof LLMs to enhance pipeline-based conversational agents during two phases: 1)\nin the design and development phase and 2) during operations. In 1) LLMs can\naid in generating training data, extracting entities and synonyms,\nlocalization, and persona design. In 2) LLMs can assist in contextualization,\nintent classification to prevent conversational breakdown and handle\nout-of-scope questions, auto-correcting utterances, rephrasing responses,\nformulating disambiguation questions, summarization, and enabling closed\nquestion-answering capabilities. We conducted informal experiments with GPT-4\nin the private banking domain to demonstrate the scenarios above with a\npractical example. Companies may be hesitant to replace their pipeline-based\nagents with LLMs entirely due to privacy concerns and the need for deep\nintegration within their existing ecosystems. A hybrid approach in which LLMs'\nare integrated into the pipeline-based agents allows them to save time and\ncosts of building and running agents by capitalizing on the capabilities of\nLLMs while retaining the integration and privacy safeguards of their existing\nsystems.", "published": "2023-09-07 14:43:17", "link": "http://arxiv.org/abs/2309.03748v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Uncovering Drift in Textual Data: An Unsupervised Method for Detecting\n  and Mitigating Drift in Machine Learning Models", "abstract": "Drift in machine learning refers to the phenomenon where the statistical\nproperties of data or context, in which the model operates, change over time\nleading to a decrease in its performance. Therefore, maintaining a constant\nmonitoring process for machine learning model performance is crucial in order\nto proactively prevent any potential performance regression. However,\nsupervised drift detection methods require human annotation and consequently\nlead to a longer time to detect and mitigate the drift. In our proposed\nunsupervised drift detection method, we follow a two step process. Our first\nstep involves encoding a sample of production data as the target distribution,\nand the model training data as the reference distribution. In the second step,\nwe employ a kernel-based statistical test that utilizes the maximum mean\ndiscrepancy (MMD) distance metric to compare the reference and target\ndistributions and estimate any potential drift. Our method also identifies the\nsubset of production data that is the root cause of the drift. The models\nretrained using these identified high drift samples show improved performance\non online customer experience quality metrics.", "published": "2023-09-07 16:45:42", "link": "http://arxiv.org/abs/2309.03831v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs", "abstract": "Instruction-tuned Large Language Models (LLMs) have recently showcased\nremarkable ability to generate fitting responses to natural language\ninstructions. However, an open research question concerns the inherent biases\nof trained models and their responses. For instance, if the data used to tune\nan LLM is dominantly written by persons with a specific political bias, we\nmight expect generated answers to share this bias. Current research work seeks\nto de-bias such models, or suppress potentially biased answers. With this\ndemonstration, we take a different view on biases in instruction-tuning: Rather\nthan aiming to suppress them, we aim to make them explicit and transparent. To\nthis end, we present OpinionGPT, a web demo in which users can ask questions\nand select all biases they wish to investigate. The demo will answer this\nquestion using a model fine-tuned on text representing each of the selected\nbiases, allowing side-by-side comparison. To train the underlying model, we\nidentified 11 different biases (political, geographic, gender, age) and derived\nan instruction-tuning corpus in which each answer was written by members of one\nof these demographics. This paper presents OpinionGPT, illustrates how we\ntrained the bias-aware model and showcases the web application (available at\nhttps://opiniongpt.informatik.hu-berlin.de).", "published": "2023-09-07 17:41:01", "link": "http://arxiv.org/abs/2309.03876v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DoLa: Decoding by Contrasting Layers Improves Factuality in Large\n  Language Models", "abstract": "Despite their impressive capabilities, large language models (LLMs) are prone\nto hallucinations, i.e., generating content that deviates from facts seen\nduring pretraining. We propose a simple decoding strategy for reducing\nhallucinations with pretrained LLMs that does not require conditioning on\nretrieved external knowledge nor additional fine-tuning. Our approach obtains\nthe next-token distribution by contrasting the differences in logits obtained\nfrom projecting the later layers versus earlier layers to the vocabulary space,\nexploiting the fact that factual knowledge in an LLMs has generally been shown\nto be localized to particular transformer layers. We find that this Decoding by\nContrasting Layers (DoLa) approach is able to better surface factual knowledge\nand reduce the generation of incorrect facts. DoLa consistently improves the\ntruthfulness across multiple choices tasks and open-ended generation tasks, for\nexample improving the performance of LLaMA family models on TruthfulQA by\n12-17% absolute points, demonstrating its potential in making LLMs reliably\ngenerate truthful facts.", "published": "2023-09-07 17:45:31", "link": "http://arxiv.org/abs/2309.03883v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Audio Captioning via Audibility Guidance", "abstract": "The task of audio captioning is similar in essence to tasks such as image and\nvideo captioning. However, it has received much less attention. We propose\nthree desiderata for captioning audio -- (i) fluency of the generated text,\n(ii) faithfulness of the generated text to the input audio, and the somewhat\nrelated (iii) audibility, which is the quality of being able to be perceived\nbased only on audio. Our method is a zero-shot method, i.e., we do not learn to\nperform captioning. Instead, captioning occurs as an inference process that\ninvolves three networks that correspond to the three desired qualities: (i) A\nLarge Language Model, in our case, for reasons of convenience, GPT-2, (ii) A\nmodel that provides a matching score between an audio file and a text, for\nwhich we use a multimodal matching network called ImageBind, and (iii) A text\nclassifier, trained using a dataset we collected automatically by instructing\nGPT-4 with prompts designed to direct the generation of both audible and\ninaudible sentences. We present our results on the AudioCap dataset,\ndemonstrating that audibility guidance significantly enhances performance\ncompared to the baseline, which lacks this objective.", "published": "2023-09-07 17:45:58", "link": "http://arxiv.org/abs/2309.03884v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FIND: A Function Description Benchmark for Evaluating Interpretability\n  Methods", "abstract": "Labeling neural network submodules with human-legible descriptions is useful\nfor many downstream tasks: such descriptions can surface failures, guide\ninterventions, and perhaps even explain important model behaviors. To date,\nmost mechanistic descriptions of trained networks have involved small models,\nnarrowly delimited phenomena, and large amounts of human labor. Labeling all\nhuman-interpretable sub-computations in models of increasing size and\ncomplexity will almost certainly require tools that can generate and validate\ndescriptions automatically. Recently, techniques that use learned models\nin-the-loop for labeling have begun to gain traction, but methods for\nevaluating their efficacy are limited and ad-hoc. How should we validate and\ncompare open-ended labeling tools? This paper introduces FIND (Function\nINterpretation and Description), a benchmark suite for evaluating the building\nblocks of automated interpretability methods. FIND contains functions that\nresemble components of trained neural networks, and accompanying descriptions\nof the kind we seek to generate. The functions span textual and numeric\ndomains, and involve a range of real-world complexities. We evaluate methods\nthat use pretrained language models (LMs) to produce descriptions of function\nbehavior in natural language and code. Additionally, we introduce a new\ninteractive method in which an Automated Interpretability Agent (AIA) generates\nfunction descriptions. We find that an AIA, built from an LM with black-box\naccess to functions, can infer function structure, acting as a scientist by\nforming hypotheses, proposing experiments, and updating descriptions in light\nof new data. However, AIA descriptions tend to capture global function behavior\nand miss local details. These results suggest that FIND will be useful for\nevaluating more sophisticated interpretability methods before they are applied\nto real-world models.", "published": "2023-09-07 17:47:26", "link": "http://arxiv.org/abs/2309.03886v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LanSER: Language-Model Supported Speech Emotion Recognition", "abstract": "Speech emotion recognition (SER) models typically rely on costly\nhuman-labeled data for training, making scaling methods to large speech\ndatasets and nuanced emotion taxonomies difficult. We present LanSER, a method\nthat enables the use of unlabeled data by inferring weak emotion labels via\npre-trained large language models through weakly-supervised learning. For\ninferring weak labels constrained to a taxonomy, we use a textual entailment\napproach that selects an emotion label with the highest entailment score for a\nspeech transcript extracted via automatic speech recognition. Our experimental\nresults show that models pre-trained on large datasets with this weak\nsupervision outperform other baseline models on standard SER datasets when\nfine-tuned, and show improved label efficiency. Despite being pre-trained on\nlabels derived only from text, we show that the resulting representations\nappear to model the prosodic content of speech.", "published": "2023-09-07 19:21:08", "link": "http://arxiv.org/abs/2309.03978v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ConDA: Contrastive Domain Adaptation for AI-generated Text Detection", "abstract": "Large language models (LLMs) are increasingly being used for generating text\nin a variety of use cases, including journalistic news articles. Given the\npotential malicious nature in which these LLMs can be used to generate\ndisinformation at scale, it is important to build effective detectors for such\nAI-generated text. Given the surge in development of new LLMs, acquiring\nlabeled training data for supervised detectors is a bottleneck. However, there\nmight be plenty of unlabeled text data available, without information on which\ngenerator it came from. In this work we tackle this data problem, in detecting\nAI-generated news text, and frame the problem as an unsupervised domain\nadaptation task. Here the domains are the different text generators, i.e. LLMs,\nand we assume we have access to only the labeled source data and unlabeled\ntarget data. We develop a Contrastive Domain Adaptation framework, called\nConDA, that blends standard domain adaptation techniques with the\nrepresentation power of contrastive learning to learn domain invariant\nrepresentations that are effective for the final unsupervised detection task.\nOur experiments demonstrate the effectiveness of our framework, resulting in\naverage performance gains of 31.7% from the best performing baselines, and\nwithin 0.8% margin of a fully supervised detector. All our code and data is\navailable at https://github.com/AmritaBh/ConDA-gen-text-detection.", "published": "2023-09-07 19:51:30", "link": "http://arxiv.org/abs/2309.03992v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluation of large language models for discovery of gene set function", "abstract": "Gene set analysis is a mainstay of functional genomics, but it relies on\ncurated databases of gene functions that are incomplete. Here we evaluate five\nLarge Language Models (LLMs) for their ability to discover the common\nbiological functions represented by a gene set, substantiated by supporting\nrationale, citations and a confidence assessment. Benchmarking against\ncanonical gene sets from the Gene Ontology, GPT-4 confidently recovered the\ncurated name or a more general concept (73% of cases), while benchmarking\nagainst random gene sets correctly yielded zero confidence. Gemini-Pro and\nMixtral-Instruct showed ability in naming but were falsely confident for random\nsets, whereas Llama2-70b had poor performance overall. In gene sets derived\nfrom 'omics data, GPT-4 identified novel functions not reported by classical\nfunctional enrichment (32% of cases), which independent review indicated were\nlargely verifiable and not hallucinations. The ability to rapidly synthesize\ncommon gene functions positions LLMs as valuable 'omics assistants.", "published": "2023-09-07 21:10:48", "link": "http://arxiv.org/abs/2309.04019v2", "categories": ["q-bio.GN", "cs.AI", "cs.CL", "q-bio.MN"], "primary_category": "q-bio.GN"}
{"title": "Multiple Representation Transfer from Large Language Models to\n  End-to-End ASR Systems", "abstract": "Transferring the knowledge of large language models (LLMs) is a promising\ntechnique to incorporate linguistic knowledge into end-to-end automatic speech\nrecognition (ASR) systems. However, existing works only transfer a single\nrepresentation of LLM (e.g. the last layer of pretrained BERT), while the\nrepresentation of a text is inherently non-unique and can be obtained variously\nfrom different layers, contexts and models. In this work, we explore a wide\nrange of techniques to obtain and transfer multiple representations of LLMs\ninto a transducer-based ASR system. While being conceptually simple, we show\nthat transferring multiple representations of LLMs can be an effective\nalternative to transferring only a single representation.", "published": "2023-09-07 21:57:39", "link": "http://arxiv.org/abs/2309.04031v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ImageBind-LLM: Multi-modality Instruction Tuning", "abstract": "We present ImageBind-LLM, a multi-modality instruction tuning method of large\nlanguage models (LLMs) via ImageBind. Existing works mainly focus on language\nand image instruction tuning, different from which, our ImageBind-LLM can\nrespond to multi-modality conditions, including audio, 3D point clouds, video,\nand their embedding-space arithmetic by only image-text alignment training.\nDuring training, we adopt a learnable bind network to align the embedding space\nbetween LLaMA and ImageBind's image encoder. Then, the image features\ntransformed by the bind network are added to word tokens of all layers in\nLLaMA, which progressively injects visual instructions via an attention-free\nand zero-initialized gating mechanism. Aided by the joint embedding of\nImageBind, the simple image-text training enables our model to exhibit superior\nmulti-modality instruction-following capabilities. During inference, the\nmulti-modality inputs are fed into the corresponding ImageBind encoders, and\nprocessed by a proposed visual cache model for further cross-modal embedding\nenhancement. The training-free cache model retrieves from three million image\nfeatures extracted by ImageBind, which effectively mitigates the\ntraining-inference modality discrepancy. Notably, with our approach,\nImageBind-LLM can respond to instructions of diverse modalities and demonstrate\nsignificant language generation quality. Code is released at\nhttps://github.com/OpenGVLab/LLaMA-Adapter.", "published": "2023-09-07 17:59:45", "link": "http://arxiv.org/abs/2309.03905v2", "categories": ["cs.MM", "cs.CL", "cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Simulating room transfer functions between transducers mounted on audio\n  devices using a modified image source method", "abstract": "The image source method (ISM) is often used to simulate room acoustics due to\nits ease of use and computational efficiency. The standard ISM is limited to\nsimulations of room impulse responses between point sources and omnidirectional\nreceivers. In this work, the ISM is extended using spherical harmonic\ndirectivity coefficients to include acoustic diffraction effects due to source\nand receiver transducers mounted on physical devices, which are typically\nencountered in practical situations. The proposed method is verified using\nfinite element simulations of various loudspeaker and microphone configurations\nin a rectangular room. It is shown that the accuracy of the proposed method is\nrelated to the sizes, shapes, number, and positions of the devices inside a\nroom. A simplified version of the proposed method, which can significantly\nreduce computational effort, is also presented. The proposed method and its\nsimplified version can simulate room transfer functions more accurately than\ncurrently available image source methods and can aid the development and\nevaluation of speech and acoustic signal processing algorithms, including\nspeech enhancement, acoustic scene analysis, and acoustic parameter estimation.", "published": "2023-09-07 05:45:22", "link": "http://arxiv.org/abs/2309.03486v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Causal Signal-Based DCCRN with Overlapped-Frame Prediction for Online\n  Speech Enhancement", "abstract": "The aim of speech enhancement is to improve speech signal quality and\nintelligibility from a noisy microphone signal. In many applications, it is\ncrucial to enable processing with small computational complexity and minimal\nrequirements regarding access to future signal samples (look-ahead). This paper\npresents signal-based causal DCCRN that improves online single-channel speech\nenhancement by reducing the required look-ahead and the number of network\nparameters. The proposed modifications include complex filtering of the signal,\napplication of overlapped-frame prediction, causal convolutions and\ndeconvolutions, and modification of the loss function. Results of performed\nexperiments indicate that the proposed model with overlapped signal prediction\nand additional adjustments, achieves similar or better performance than the\noriginal DCCRN in terms of various speech enhancement metrics, while it reduces\nthe latency and network parameter number by around 30%.", "published": "2023-09-07 12:52:21", "link": "http://arxiv.org/abs/2309.03684v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Cross-domain Sound Recognition for Efficient Underwater Data Analysis", "abstract": "This paper presents a novel deep learning approach for analyzing massive\nunderwater acoustic data by leveraging a model trained on a broad spectrum of\nnon-underwater (aerial) sounds. Recognizing the challenge in labeling vast\namounts of underwater data, we propose a two-fold methodology to accelerate\nthis labor-intensive procedure.\n  The first part of our approach involves PCA and UMAP visualization of the\nunderwater data using the feature vectors of an aerial sound recognition model.\nThis enables us to cluster the data in a two dimensional space and listen to\npoints within these clusters to understand their defining characteristics. This\ninnovative method simplifies the process of selecting candidate labels for\nfurther training.\n  In the second part, we train a neural network model using both the selected\nunderwater data and the non-underwater dataset. We conducted a quantitative\nanalysis to measure the precision, recall, and F1 score of our model for\nrecognizing airgun sounds, a common type of underwater sound. The F1 score\nachieved by our model exceeded 84.3%, demonstrating the effectiveness of our\napproach in analyzing underwater acoustic data.\n  The methodology presented in this paper holds significant potential to reduce\nthe amount of labor required in underwater data analysis and opens up new\npossibilities for further research in the field of cross-domain data analysis.", "published": "2023-09-07 02:26:32", "link": "http://arxiv.org/abs/2309.03451v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Topological fingerprints for audio identification", "abstract": "We present a topological audio fingerprinting approach for robustly\nidentifying duplicate audio tracks. Our method applies persistent homology on\nlocal spectral decompositions of audio signals, using filtered cubical\ncomplexes computed from mel-spectrograms. By encoding the audio content in\nterms of local Betti curves, our topological audio fingerprints enable accurate\ndetection of time-aligned audio matchings. Experimental results demonstrate the\naccuracy of our algorithm in the detection of tracks with the same audio\ncontent, even when subjected to various obfuscations. Our approach outperforms\nexisting methods in scenarios involving topological distortions, such as time\nstretching and pitch shifting.", "published": "2023-09-07 06:56:56", "link": "http://arxiv.org/abs/2309.03516v1", "categories": ["cs.SD", "eess.AS", "math.AT", "55N31, 68U10, 62R40"], "primary_category": "cs.SD"}
{"title": "MVD:A Novel Methodology and Dataset for Acoustic Vehicle Type\n  Classification", "abstract": "Rising urban populations have led to a surge in vehicle use and made traffic\nmonitoring and management indispensable. Acoustic traffic monitoring (ATM)\noffers a cost-effective and efficient alternative to more computationally\nexpensive methods of monitoring traffic such as those involving computer vision\ntechnologies. In this paper, we present MVD and MVDA: two open datasets for the\ndevelopment of acoustic traffic monitoring and vehicle-type classification\nalgorithms, which contain audio recordings of moving vehicles. The dataset\ncontain four classes- Trucks, Cars, Motorbikes, and a No-vehicle class.\nAdditionally, we propose a novel and efficient way to accurately classify these\nacoustic signals using cepstrum and spectrum based local and global audio\nfeatures, and a multi-input neural network. Experimental results show that our\nmethodology improves upon the established baselines of previous works and\nachieves an accuracy of 91.98% and 96.66% on MVD and MVDA Datasets,\nrespectively. Finally, the proposed model was deployed through an Android\napplication to make it accessible for testing and demonstrate its efficacy.", "published": "2023-09-07 08:02:57", "link": "http://arxiv.org/abs/2309.03544v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Understanding Self-Supervised Learning of Speech Representation via\n  Invariance and Redundancy Reduction", "abstract": "Self-supervised learning (SSL) has emerged as a promising paradigm for\nlearning flexible speech representations from unlabeled data. By designing\npretext tasks that exploit statistical regularities, SSL models can capture\nuseful representations that are transferable to downstream tasks. This study\nprovides an empirical analysis of Barlow Twins (BT), an SSL technique inspired\nby theories of redundancy reduction in human perception. On downstream tasks,\nBT representations accelerated learning and transferred across domains.\nHowever, limitations exist in disentangling key explanatory factors, with\nredundancy reduction and invariance alone insufficient for factorization of\nlearned latents into modular, compact, and informative codes. Our ablations\nstudy isolated gains from invariance constraints, but the gains were\ncontext-dependent. Overall, this work substantiates the potential of Barlow\nTwins for sample-efficient speech encoding. However, challenges remain in\nachieving fully hierarchical representations. The analysis methodology and\ninsights pave a path for extensions incorporating further inductive priors and\nperceptual principles to further enhance the BT self-supervision framework.", "published": "2023-09-07 10:23:59", "link": "http://arxiv.org/abs/2309.03619v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Spiking Structured State Space Model for Monaural Speech Enhancement", "abstract": "Speech enhancement seeks to extract clean speech from noisy signals.\nTraditional deep learning methods face two challenges: efficiently using\ninformation in long speech sequences and high computational costs. To address\nthese, we introduce the Spiking Structured State Space Model (Spiking-S4). This\napproach merges the energy efficiency of Spiking Neural Networks (SNN) with the\nlong-range sequence modeling capabilities of Structured State Space Models\n(S4), offering a compelling solution. Evaluation on the DNS Challenge and\nVoiceBank+Demand Datasets confirms that Spiking-S4 rivals existing Artificial\nNeural Network (ANN) methods but with fewer computational resources, as\nevidenced by reduced parameters and Floating Point Operations (FLOPs).", "published": "2023-09-07 11:21:10", "link": "http://arxiv.org/abs/2309.03641v2", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Large-Scale Automatic Audiobook Creation", "abstract": "An audiobook can dramatically improve a work of literature's accessibility\nand improve reader engagement. However, audiobooks can take hundreds of hours\nof human effort to create, edit, and publish. In this work, we present a system\nthat can automatically generate high-quality audiobooks from online e-books. In\nparticular, we leverage recent advances in neural text-to-speech to create and\nrelease thousands of human-quality, open-license audiobooks from the Project\nGutenberg e-book collection. Our method can identify the proper subset of\ne-book content to read for a wide collection of diversely structured books and\ncan operate on hundreds of books in parallel. Our system allows users to\ncustomize an audiobook's speaking speed and style, emotional intonation, and\ncan even match a desired voice using a small amount of sample audio. This work\ncontributed over five thousand open-license audiobooks and an interactive demo\nthat allows users to quickly create their own customized audiobooks. To listen\nto the audiobook collection visit \\url{https://aka.ms/audiobook}.", "published": "2023-09-07 11:41:23", "link": "http://arxiv.org/abs/2309.03926v1", "categories": ["cs.SD", "cs.AI", "cs.DC", "cs.DL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DGSD: Dynamical Graph Self-Distillation for EEG-Based Auditory Spatial\n  Attention Detection", "abstract": "Auditory Attention Detection (AAD) aims to detect target speaker from brain\nsignals in a multi-speaker environment. Although EEG-based AAD methods have\nshown promising results in recent years, current approaches primarily rely on\ntraditional convolutional neural network designed for processing Euclidean data\nlike images. This makes it challenging to handle EEG signals, which possess\nnon-Euclidean characteristics. In order to address this problem, this paper\nproposes a dynamical graph self-distillation (DGSD) approach for AAD, which\ndoes not require speech stimuli as input. Specifically, to effectively\nrepresent the non-Euclidean properties of EEG signals, dynamical graph\nconvolutional networks are applied to represent the graph structure of EEG\nsignals, which can also extract crucial features related to auditory spatial\nattention in EEG signals. In addition, to further improve AAD detection\nperformance, self-distillation, consisting of feature distillation and\nhierarchical distillation strategies at each layer, is integrated. These\nstrategies leverage features and classification results from the deepest\nnetwork layers to guide the learning of shallow layers. Our experiments are\nconducted on two publicly available datasets, KUL and DTU. Under a 1-second\ntime window, we achieve results of 90.0\\% and 79.6\\% accuracy on KUL and DTU,\nrespectively. We compare our DGSD method with competitive baselines, and the\nexperimental results indicate that the detection performance of our proposed\nDGSD method is not only superior to the best reproducible baseline but also\nsignificantly reduces the number of trainable parameters by approximately 100\ntimes.", "published": "2023-09-07 13:43:46", "link": "http://arxiv.org/abs/2309.07147v1", "categories": ["eess.SP", "cs.HC", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
