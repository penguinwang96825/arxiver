{"title": "Monolingual and Cross-lingual Zero-shot Style Transfer", "abstract": "We introduce the task of zero-shot style transfer between different\nlanguages. Our training data includes multilingual parallel corpora, but does\nnot contain any parallel sentences between styles, similarly to the recent\nprevious work. We propose a unified multilingual multi-style machine\ntranslation system design, that allows to perform zero-shot style conversions\nduring inference; moreover, it does so both monolingually and cross-lingually.\nOur model allows to increase the presence of dissimilar styles in corpus by up\nto 3 times, easily learns to operate with various contractions, and provides\nreasonable lexicon swaps as we see from manual evaluation.", "published": "2018-08-01 06:12:49", "link": "http://arxiv.org/abs/1808.00179v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Low-Latency Neural Speech Translation", "abstract": "Through the development of neural machine translation, the quality of machine\ntranslation systems has been improved significantly. By exploiting advancements\nin deep learning, systems are now able to better approximate the complex\nmapping from source sentences to target sentences. But with this ability, new\nchallenges also arise. An example is the translation of partial sentences in\nlow-latency speech translation. Since the model has only seen complete\nsentences in training, it will always try to generate a complete sentence,\nthough the input may only be a partial sentence. We show that NMT systems can\nbe adapted to scenarios where no task-specific training data is available.\nFurthermore, this is possible without losing performance on the original\ntraining data. We achieve this by creating artificial data and by using\nmulti-task learning. After adaptation, we are able to reduce the number of\ncorrections displayed during incremental output construction by 45%, without a\ndecrease in translation quality.", "published": "2018-08-01 18:17:05", "link": "http://arxiv.org/abs/1808.00491v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpretable Visual Question Answering by Visual Grounding from\n  Attention Supervision Mining", "abstract": "A key aspect of VQA models that are interpretable is their ability to ground\ntheir answers to relevant regions in the image. Current approaches with this\ncapability rely on supervised learning and human annotated groundings to train\nattention mechanisms inside the VQA architecture. Unfortunately, obtaining\nhuman annotations specific for visual grounding is difficult and expensive. In\nthis work, we demonstrate that we can effectively train a VQA architecture with\ngrounding supervision that can be automatically obtained from available region\ndescriptions and object annotations. We also show that our model trained with\nthis mined supervision generates visual groundings that achieve a higher\ncorrelation with respect to manually-annotated groundings, meanwhile achieving\nstate-of-the-art VQA accuracy.", "published": "2018-08-01 11:06:08", "link": "http://arxiv.org/abs/1808.00265v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Seq2Seq and Multi-Task Learning for joint intent and content extraction\n  for domain specific interpreters", "abstract": "This study evaluates the performances of an LSTM network for detecting and\nextracting the intent and content of com- mands for a financial chatbot. It\npresents two techniques, sequence to sequence learning and Multi-Task Learning,\nwhich might improve on the previous task.", "published": "2018-08-01 17:04:48", "link": "http://arxiv.org/abs/1808.00423v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Data Augmentation for Robust Keyword Spotting under Playback\n  Interference", "abstract": "Accurate on-device keyword spotting (KWS) with low false accept and false\nreject rate is crucial to customer experience for far-field voice control of\nconversational agents. It is particularly challenging to maintain low false\nreject rate in real world conditions where there is (a) ambient noise from\nexternal sources such as TV, household appliances, or other speech that is not\ndirected at the device (b) imperfect cancellation of the audio playback from\nthe device, resulting in residual echo, after being processed by the Acoustic\nEcho Cancellation (AEC) system. In this paper, we propose a data augmentation\nstrategy to improve keyword spotting performance under these challenging\nconditions. The training set audio is artificially corrupted by mixing in music\nand TV/movie audio, at different signal to interference ratios. Our results\nshow that we get around 30-45% relative reduction in false reject rates, at a\nrange of false alarm rates, under audio playback from such devices.", "published": "2018-08-01 21:00:50", "link": "http://arxiv.org/abs/1808.00563v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Learning Visual Question Answering by Bootstrapping Hard Attention", "abstract": "Attention mechanisms in biological perception are thought to select subsets\nof perceptual information for more sophisticated processing which would be\nprohibitive to perform on all sensory inputs. In computer vision, however,\nthere has been relatively little exploration of hard attention, where some\ninformation is selectively ignored, in spite of the success of soft attention,\nwhere information is re-weighted and aggregated, but never filtered out. Here,\nwe introduce a new approach for hard attention and find it achieves very\ncompetitive performance on a recently-released visual question answering\ndatasets, equalling and in some cases surpassing similar soft attention\narchitectures while entirely ignoring some features. Even though the hard\nattention mechanism is thought to be non-differentiable, we found that the\nfeature magnitudes correlate with semantic relevance, and provide a useful\nsignal for our mechanism's attentional selection criterion. Because hard\nattention selects important features of the input information, it can also be\nmore efficient than analogous soft attention mechanisms. This is especially\nimportant for recent approaches that use non-local pairwise operations, whereby\ncomputational and memory costs are quadratic in the size of the set of\nfeatures.", "published": "2018-08-01 12:39:43", "link": "http://arxiv.org/abs/1808.00300v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CV"}
