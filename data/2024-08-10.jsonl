{"title": "LaiDA: Linguistics-aware In-context Learning with Data Augmentation for\n  Metaphor Components Identification", "abstract": "Metaphor Components Identification (MCI) contributes to enhancing machine\nunderstanding of metaphors, thereby advancing downstream natural language\nprocessing tasks. However, the complexity, diversity, and dependency on context\nand background knowledge pose significant challenges for MCI. Large language\nmodels (LLMs) offer new avenues for accurate comprehension of complex natural\nlanguage texts due to their strong semantic analysis and extensive commonsense\nknowledge. In this research, a new LLM-based framework is proposed, named\nLinguistics-aware In-context Learning with Data Augmentation (LaiDA).\nSpecifically, ChatGPT and supervised fine-tuning are utilized to tailor a\nhigh-quality dataset. LaiDA incorporates a simile dataset for pre-training. A\ngraph attention network encoder generates linguistically rich feature\nrepresentations to retrieve similar examples. Subsequently, LLM is fine-tuned\nwith prompts that integrate linguistically similar examples. LaiDA ranked 2nd\nin Subtask 2 of NLPCC2024 Shared Task 9, demonstrating its effectiveness. Code\nand data are available at https://github.com/WXLJZ/LaiDA.", "published": "2024-08-10 02:02:26", "link": "http://arxiv.org/abs/2408.05404v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain of Condition: Construct, Verify and Solve Conditions for\n  Conditional Question Answering", "abstract": "Conditional question answering (CQA) is an important task that aims to find\nprobable answers and identify missing conditions. Existing approaches struggle\nwith CQA due to two challenges: (1) precisely identifying necessary conditions\nand the logical relationship, and (2) verifying conditions to detect any that\nare missing. In this paper, we propose a novel prompting approach, Chain of\ncondition, by first identifying all conditions and constructing their logical\nrelationships explicitly according to the document, then verifying whether\nthese conditions are satisfied, finally solving the logical expression to\nindicate any missing conditions and generating the answer accordingly.\nExperiments on two CQA benchmark datasets show our chain of condition\noutperforms existing prompting baselines, establishing a new state of the art.\nFurthermore, with only a few examples, our method can facilitate GPT-3.5-Turbo\nor GPT-4 to outperform all existing supervised models.", "published": "2024-08-10 05:09:11", "link": "http://arxiv.org/abs/2408.05442v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Path-LLM: A Shortest-Path-based LLM Learning for Unified Graph\n  Representation", "abstract": "Unified graph representation learning aims to produce node embeddings, which\ncan be applied to multiple downstream applications. However, existing studies\nbased on graph neural networks and language models either suffer from the\nlimitations of numerous training needed toward specific downstream predictions\nor have shallow semantic features. In this work, we propose a novel Path-LLM\nmodel to learn unified graph representation, which leverages a powerful large\nlanguage model (LLM) to incorporate our proposed path features. Our Path-LLM\nframework consists of several well-designed techniques. First, we develop a new\nmechanism of long-to-short shortest path (L2SP) selection, which covers\nessential connections between different dense groups. An in-depth comparison of\ndifferent path selection plans is offered to illustrate the strength of our\ndesigned L2SP. Then, we design path textualization to obtain L2SP-based\ntraining texts. Next, we feed the texts into a self-supervised LLM training\nprocess to learn embeddings. Extensive experiments on benchmarks validate the\nsuperiority of Path-LLM against the state-of-the-art WalkLM method on two\nclassical graph learning tasks (node classification and link prediction) and\none NP-hard graph query processing task (keyword search), meanwhile saving more\nthan 90% of training paths.", "published": "2024-08-10 06:35:11", "link": "http://arxiv.org/abs/2408.05456v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MABR: A Multilayer Adversarial Bias Removal Approach Without Prior Bias\n  Knowledge", "abstract": "Models trained on real-world data often mirror and exacerbate existing social\nbiases. Traditional methods for mitigating these biases typically require prior\nknowledge of the specific biases to be addressed, such as gender or racial\nbiases, and the social groups associated with each instance. In this paper, we\nintroduce a novel adversarial training strategy that operates independently of\nprior bias-type knowledge and protected attribute labels. Our approach\nproactively identifies biases during model training by utilizing auxiliary\nmodels, which are trained concurrently by predicting the performance of the\nmain model without relying on task labels. Additionally, we implement these\nauxiliary models at various levels of the feature maps of the main model,\nenabling the detection of a broader and more nuanced range of bias features.\nThrough experiments on racial and gender biases in sentiment and occupation\nclassification tasks, our method effectively reduces social biases without the\nneed for demographic annotations. Moreover, our approach not only matches but\noften surpasses the efficacy of methods that require detailed demographic\ninsights, marking a significant advancement in bias mitigation techniques.", "published": "2024-08-10 09:11:01", "link": "http://arxiv.org/abs/2408.05497v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Your Context Is Not an Array: Unveiling Random Access Limitations in\n  Transformers", "abstract": "Despite their recent successes, Transformer-based large language models show\nsurprising failure modes. A well-known example of such failure modes is their\ninability to length-generalize: solving problem instances at inference time\nthat are longer than those seen during training. In this work, we further\nexplore the root cause of this failure by performing a detailed analysis of\nmodel behaviors on the simple parity task. Our analysis suggests that length\ngeneralization failures are intricately related to a model's inability to\nperform random memory accesses within its context window. We present supporting\nevidence for this hypothesis by demonstrating the effectiveness of\nmethodologies that circumvent the need for indexing or that enable random token\naccess indirectly, through content-based addressing. We further show where and\nhow the failure to perform random memory access manifests through attention map\nvisualizations.", "published": "2024-08-10 10:12:09", "link": "http://arxiv.org/abs/2408.05506v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning", "abstract": "Recent development in Large Language Models (LLMs) and Multi-modal Large\nLanguage Models (MLLMs) have leverage Attention-based Transformer architectures\nand achieved superior performance and generalization capabilities. They have\nsince covered extensive areas of traditional learning tasks. For instance,\ntext-based tasks such as text-classification and sequence-labeling, as well as\nmulti-modal tasks like Visual Question Answering (VQA) and Optical Character\nRecognition (OCR), which were previously addressed using different models, can\nnow be tackled based on one foundation model. Consequently, the training and\nlightweight fine-tuning of LLMs and MLLMs, especially those based on\nTransformer architecture, has become particularly important. In recognition of\nthese overwhelming needs, we develop SWIFT, a customizable one-stop\ninfrastructure for large models. With support of over $300+$ LLMs and $50+$\nMLLMs, SWIFT stands as the open-source framework that provide the most\ncomprehensive support for fine-tuning large models. In particular, it is the\nfirst training framework that provides systematic support for MLLMs. In\naddition to the core functionalities of fine-tuning, SWIFT also integrates\npost-training processes such as inference, evaluation, and model quantization,\nto facilitate fast adoptions of large models in various application scenarios.\nWith a systematic integration of various training techniques, SWIFT offers\nhelpful utilities such as benchmark comparisons among different training\ntechniques for large models. For fine-tuning models specialized in agent\nframework, we show that notable improvements on the ToolBench leader-board can\nbe achieved by training with customized dataset on SWIFT, with an increase of\n5.2%-21.8% in the Act.EM metric over various baseline models, a reduction in\nhallucination by 1.6%-14.1%, and an average performance improvement of 8%-17%.", "published": "2024-08-10 11:00:13", "link": "http://arxiv.org/abs/2408.05517v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "P3: A Policy-Driven, Pace-Adaptive, and Diversity-Promoted Framework for\n  data pruning in LLM Training", "abstract": "In the rapidly advancing field of Large Language Models (LLMs), effectively\nleveraging existing datasets during fine-tuning to maximize the model's\npotential is of paramount importance. This paper introduces P3, an adaptive\nframework aimed at optimizing the task-specific fine-tuning process through\niterative data pruning. P3 consists of three key components: (1) Policy-driven\nDifficulty Measurement, which dynamically assesses data difficulty based on the\nmodel's real-time performance, replacing static metrics with adaptable\nevaluations; (2) Pace-Adaptive Selection, leveraging self-paced learning to\nprogressively introduce more challenging data, thereby enhancing model\ncapability; (3) Diversity Promotion, incorporating Determinantal Point Process\n(DPP) to ensure data diversity across epochs, enriching the learning process.\nWe validate P3 on the reasoning scenarios, APPS and MATH, demonstrating\nsignificant improvements over traditional data pruning methods. By advancing\ndynamic data selection and utilization strategies, P3 contributes both a\ntheoretical framework and concrete approach to fully exploit existing data for\nLLMs' performance improvement, offering utility across diverse tasks.", "published": "2024-08-10 12:44:49", "link": "http://arxiv.org/abs/2408.05541v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Model-based Role-Playing for Personalized Medical Jargon\n  Extraction", "abstract": "Previous studies reveal that Electronic Health Records (EHR), which have been\nwidely adopted in the U.S. to allow patients to access their personal medical\ninformation, do not have high readability to patients due to the prevalence of\nmedical jargon. Tailoring medical notes to individual comprehension by\nidentifying jargon that is difficult for each person will enhance the utility\nof generative models. We present the first quantitative analysis to measure the\nimpact of role-playing in LLM in medical term extraction. By comparing the\nresults of Mechanical Turk workers over 20 sentences, our study demonstrates\nthat LLM role-playing improves F1 scores in 95% of cases across 14 different\nsocio-demographic backgrounds. Furthermore, applying role-playing with\nin-context learning outperformed the previous state-of-the-art models. Our\nresearch showed that ChatGPT can improve traditional medical term extraction\nsystems by utilizing role-play to deliver personalized patient education, a\npotential that previous models had not achieved.", "published": "2024-08-10 13:40:44", "link": "http://arxiv.org/abs/2408.05555v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WiDe-analysis: Enabling One-click Content Moderation Analysis on\n  Wikipedia's Articles for Deletion", "abstract": "Content moderation in online platforms is crucial for ensuring activity\ntherein adheres to existing policies, especially as these platforms grow. NLP\nresearch in this area has typically focused on automating some part of it given\nthat it is not feasible to monitor all active discussions effectively. Past\nworks have focused on revealing deletion patterns with like sentiment analysis,\nor on developing platform-specific models such as Wikipedia policy or stance\ndetectors. Unsurprisingly, however, this valuable body of work is rather\nscattered, with little to no agreement with regards to e.g., the deletion\ndiscussions corpora used for training or the number of stance labels. Moreover,\nwhile efforts have been made to connect stance with rationales (e.g., to ground\na deletion decision on the relevant policy), there is little explanability work\nbeyond that. In this paper, we introduce a suite of experiments on Wikipedia\ndeletion discussions and wide-analyis (Wikipedia Deletion Analysis), a Python\npackage aimed at providing one click analysis to content moderation\ndiscussions. We release all assets associated with wide-analysis, including\ndata, models and the Python package, and a HuggingFace space with the goal to\naccelerate research on automating content moderation in Wikipedia and beyond.", "published": "2024-08-10 23:43:11", "link": "http://arxiv.org/abs/2408.05655v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Instruction Tuning Large Language Models on Graphs", "abstract": "Inspired by the recent advancements of Large Language Models (LLMs) in NLP\ntasks, there's growing interest in applying LLMs to graph-related tasks. This\nstudy delves into the capabilities of instruction-following LLMs for engaging\nwith real-world graphs, aiming to offer empirical insights into how LLMs can\neffectively interact with graphs and generalize across graph tasks. We begin by\nconstructing a dataset designed for instruction tuning, which comprises a\ndiverse collection of 79 graph-related tasks from academic and e-commerce\ndomains, featuring 44,240 training instances and 18,960 test samples. Utilizing\nthis benchmark, our initial investigation focuses on identifying the optimal\ngraph representation that serves as a conduit for LLMs to understand complex\ngraph structures. Our findings indicate that JSON format for graph\nrepresentation consistently outperforms natural language and code formats\nacross various LLMs and graph types. Furthermore, we examine the key factors\nthat influence the generalization abilities of instruction-tuned LLMs by\nevaluating their performance on both in-domain and out-of-domain graph tasks.", "published": "2024-08-10 06:54:35", "link": "http://arxiv.org/abs/2408.05457v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GEM: Context-Aware Gaze EstiMation with Visual Search Behavior Matching\n  for Chest Radiograph", "abstract": "Gaze estimation is pivotal in human scene comprehension tasks, particularly\nin medical diagnostic analysis. Eye-tracking technology facilitates the\nrecording of physicians' ocular movements during image interpretation, thereby\nelucidating their visual attention patterns and information-processing\nstrategies. In this paper, we initially define the context-aware gaze\nestimation problem in medical radiology report settings. To understand the\nattention allocation and cognitive behavior of radiologists during the medical\nimage interpretation process, we propose a context-aware Gaze EstiMation (GEM)\nnetwork that utilizes eye gaze data collected from radiologists to simulate\ntheir visual search behavior patterns throughout the image interpretation\nprocess. It consists of a context-awareness module, visual behavior graph\nconstruction, and visual behavior matching. Within the context-awareness\nmodule, we achieve intricate multimodal registration by establishing\nconnections between medical reports and images. Subsequently, for a more\naccurate simulation of genuine visual search behavior patterns, we introduce a\nvisual behavior graph structure, capturing such behavior through high-order\nrelationships (edges) between gaze points (nodes). To maintain the authenticity\nof visual behavior, we devise a visual behavior-matching approach, adjusting\nthe high-order relationships between them by matching the graph constructed\nfrom real and estimated gaze points. Extensive experiments on four publicly\navailable datasets demonstrate the superiority of GEM over existing methods and\nits strong generalizability, which also provides a new direction for the\neffective utilization of diverse modalities in medical image interpretation and\nenhances the interpretability of models in the field of medical imaging.\nhttps://github.com/Tiger-SN/GEM", "published": "2024-08-10 09:46:25", "link": "http://arxiv.org/abs/2408.05502v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Context-Driven Index Trimming: A Data Quality Perspective to Enhancing\n  Precision of RALMs", "abstract": "Retrieval-Augmented Large Language Models (RALMs) have made significant\nstrides in enhancing the accuracy of generated responses.However, existing\nresearch often overlooks the data quality issues within retrieval results,\noften caused by inaccurate existing vector-distance-based retrieval methods.We\npropose to boost the precision of RALMs' answers from a data quality\nperspective through the Context-Driven Index Trimming (CDIT) framework, where\nContext Matching Dependencies (CMDs) are employed as logical data quality rules\nto capture and regulate the consistency between retrieved contexts.Based on the\nsemantic comprehension capabilities of Large Language Models (LLMs), CDIT can\neffectively identify and discard retrieval results that are inconsistent with\nthe query context and further modify indexes in the database, thereby improving\nanswer quality.Experiments demonstrate on challenging question-answering\ntasks.Also, the flexibility of CDIT is verified through its compatibility with\nvarious language models and indexing methods, which offers a promising approach\nto bolster RALMs' data quality and retrieval precision jointly.", "published": "2024-08-10 11:39:22", "link": "http://arxiv.org/abs/2408.05524v1", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Multi-layer Sequence Labeling-based Joint Biomedical Event Extraction", "abstract": "In recent years, biomedical event extraction has been dominated by\ncomplicated pipeline and joint methods, which need to be simplified. In\naddition, existing work has not effectively utilized trigger word information\nexplicitly. Hence, we propose MLSL, a method based on multi-layer sequence\nlabeling for joint biomedical event extraction. MLSL does not introduce prior\nknowledge and complex structures. Moreover, it explicitly incorporates the\ninformation of candidate trigger words into the sequence labeling to learn the\ninteraction relationships between trigger words and argument roles. Based on\nthis, MLSL can learn well with just a simple workflow. Extensive\nexperimentation demonstrates the superiority of MLSL in terms of extraction\nperformance compared to other state-of-the-art methods.", "published": "2024-08-10 13:03:19", "link": "http://arxiv.org/abs/2408.05545v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Speculative Diffusion Decoding: Accelerating Language Generation through\n  Diffusion", "abstract": "Speculative decoding has emerged as a widely adopted method to accelerate\nlarge language model inference without sacrificing the quality of the model\noutputs. While this technique has facilitated notable speed improvements by\nenabling parallel sequence verification, its efficiency remains inherently\nlimited by the reliance on incremental token generation in existing draft\nmodels. To overcome this limitation, this paper proposes an adaptation of\nspeculative decoding which uses discrete diffusion models to generate draft\nsequences. This allows parallelization of both the drafting and verification\nsteps, providing significant speedups to the inference process. Our proposed\napproach, $\\textit{Speculative Diffusion Decoding (SpecDiff)}$, is validated on\nstandard language generation benchmarks and empirically demonstrated to provide\nup to 7.2x speedups over standard generation processes and up to 1.75x speedups\nover existing speculative decoding approaches.", "published": "2024-08-10 21:24:25", "link": "http://arxiv.org/abs/2408.05636v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Preserving Privacy in Large Language Models: A Survey on Current Threats\n  and Solutions", "abstract": "Large Language Models (LLMs) represent a significant advancement in\nartificial intelligence, finding applications across various domains. However,\ntheir reliance on massive internet-sourced datasets for training brings notable\nprivacy issues, which are exacerbated in critical domains (e.g., healthcare).\nMoreover, certain application-specific scenarios may require fine-tuning these\nmodels on private data. This survey critically examines the privacy threats\nassociated with LLMs, emphasizing the potential for these models to memorize\nand inadvertently reveal sensitive information. We explore current threats by\nreviewing privacy attacks on LLMs and propose comprehensive solutions for\nintegrating privacy mechanisms throughout the entire learning pipeline. These\nsolutions range from anonymizing training datasets to implementing differential\nprivacy during training or inference and machine unlearning after training. Our\ncomprehensive review of existing literature highlights ongoing challenges,\navailable tools, and future directions for preserving privacy in LLMs. This\nwork aims to guide the development of more secure and trustworthy AI systems by\nproviding a thorough understanding of privacy preservation methods and their\neffectiveness in mitigating risks.", "published": "2024-08-10 05:41:19", "link": "http://arxiv.org/abs/2408.05212v2", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Improving Whisper's Recognition Performance for Under-Represented\n  Language Kazakh Leveraging Unpaired Speech and Text", "abstract": "Whisper and other large-scale automatic speech recognition models have made\nsignificant progress in performance. However, their performance on many\nlow-resource languages, such as Kazakh, is not satisfactory. It is worth\nresearching how to utilize low-cost data to improve the performance of Whisper\non under-represented languages. In this study, we utilized easily accessible\nunpaired speech and text data and combined the language model GPT with Whisper\non Kazakh. We implemented end of transcript (EOT) judgment modification and\nhallucination penalty to improve the performance of speech recognition.\nFurther, we employed the decoding average token log probability as a criterion\nto select samples from unlabeled speech data and used pseudo-labeled data to\nfine-tune the model to further improve its performance. Ultimately, we achieved\nmore than 10\\% absolute WER reduction in multiple experiments, and the whole\nprocess has the potential to be generalized to other under-represented\nlanguages.", "published": "2024-08-10 13:39:13", "link": "http://arxiv.org/abs/2408.05554v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Document-Level Event Extraction with Definition-Driven ICL", "abstract": "In the field of Natural Language Processing (NLP), Large Language Models\n(LLMs) have shown great potential in document-level event extraction tasks, but\nexisting methods face challenges in the design of prompts. To address this\nissue, we propose an optimization strategy called \"Definition-driven\nDocument-level Event Extraction (DDEE).\" By adjusting the length of the prompt\nand enhancing the clarity of heuristics, we have significantly improved the\nevent extraction performance of LLMs. We used data balancing techniques to\nsolve the long-tail effect problem, enhancing the model's generalization\nability for event types. At the same time, we refined the prompt to ensure it\nis both concise and comprehensive, adapting to the sensitivity of LLMs to the\nstyle of prompts. In addition, the introduction of structured heuristic methods\nand strict limiting conditions has improved the precision of event and argument\nrole extraction. These strategies not only solve the prompt engineering\nproblems of LLMs in document-level event extraction but also promote the\ndevelopment of event extraction technology, providing new research perspectives\nfor other tasks in the NLP field.", "published": "2024-08-10 14:24:09", "link": "http://arxiv.org/abs/2408.05566v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Metacognitive Myopia in Large Language Models", "abstract": "Large Language Models (LLMs) exhibit potentially harmful biases that\nreinforce culturally inherent stereotypes, cloud moral judgments, or amplify\npositive evaluations of majority groups. Previous explanations mainly\nattributed bias in LLMs to human annotators and the selection of training data.\nConsequently, they have typically been addressed with bottom-up approaches such\nas reinforcement learning or debiasing corpora. However, these methods only\ntreat the effects of LLM biases by indirectly influencing the model\narchitecture, but do not address the underlying causes in the computational\nprocess. Here, we propose metacognitive myopia as a cognitive-ecological\nframework that can account for a conglomerate of established and emerging LLM\nbiases and provide a lever to address problems in powerful but vulnerable\ntools. Our theoretical framework posits that a lack of the two components of\nmetacognition, monitoring and control, causes five symptoms of metacognitive\nmyopia in LLMs: integration of invalid tokens and embeddings, susceptibility to\nredundant information, neglect of base rates in conditional computation,\ndecision rules based on frequency, and inappropriate higher-order statistical\ninference for nested data structures. As a result, LLMs produce erroneous\noutput that reaches into the daily high-stakes decisions of humans. By\nintroducing metacognitive regulatory processes into LLMs, engineers and\nscientists can develop precise remedies for the underlying causes of these\nbiases. Our theory sheds new light on flawed human-machine interactions and\nraises ethical concerns regarding the increasing, imprudent implementation of\nLLMs in organizational structures.", "published": "2024-08-10 14:43:57", "link": "http://arxiv.org/abs/2408.05568v1", "categories": ["cs.AI", "cs.CL", "cs.CY", "stat.AP"], "primary_category": "cs.AI"}
{"title": "Eigen Attention: Attention in Low-Rank Space for KV Cache Compression", "abstract": "Large language models (LLMs) represent a groundbreaking advancement in the\ndomain of natural language processing due to their impressive reasoning\nabilities. Recently, there has been considerable interest in increasing the\ncontext lengths for these models to enhance their applicability to complex\ntasks. However, at long context lengths and large batch sizes, the key-value\n(KV) cache, which stores the attention keys and values, emerges as the new\nbottleneck in memory usage during inference. To address this, we propose Eigen\nAttention, which performs the attention operation in a low-rank space, thereby\nreducing the KV cache memory overhead. Our proposed approach is orthogonal to\nexisting KV cache compression techniques and can be used synergistically with\nthem. Through extensive experiments over OPT, MPT, and Llama model families, we\ndemonstrate that Eigen Attention results in up to 40% reduction in KV cache\nsizes and up to 60% reduction in attention operation latency with minimal drop\nin performance. Code is available at\nhttps://github.com/UtkarshSaxena1/EigenAttn.", "published": "2024-08-10 22:47:12", "link": "http://arxiv.org/abs/2408.05646v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ViC: Virtual Compiler Is All You Need For Assembly Code Search", "abstract": "Assembly code search is vital for reducing the burden on reverse engineers,\nallowing them to quickly identify specific functions using natural language\nwithin vast binary programs. Despite its significance, this critical task is\nimpeded by the complexities involved in building high-quality datasets. This\npaper explores training a Large Language Model (LLM) to emulate a general\ncompiler. By leveraging Ubuntu packages to compile a dataset of 20 billion\ntokens, we further continue pre-train CodeLlama as a Virtual Compiler (ViC),\ncapable of compiling any source code of any language to assembly code. This\napproach allows for virtual compilation across a wide range of programming\nlanguages without the need for a real compiler, preserving semantic equivalency\nand expanding the possibilities for assembly code dataset construction.\nFurthermore, we use ViC to construct a sufficiently large dataset for assembly\ncode search. Employing this extensive dataset, we achieve a substantial\nimprovement in assembly code search performance, with our model surpassing the\nleading baseline by 26%.", "published": "2024-08-10 17:23:02", "link": "http://arxiv.org/abs/2408.06385v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Towards a Quantitative Analysis of Coarticulation with a\n  Phoneme-to-Articulatory Model", "abstract": "Prior coarticulation studies focus mainly on limited phonemic sequences and\nspecific articulators, providing only approximate descriptions of the temporal\nextent and magnitude of coarticulation. This paper is an initial attempt to\ncomprehensively investigate coarticulation. We leverage existing\nElectromagnetic Articulography (EMA) datasets to develop and train a\nphoneme-to-articulatory (P2A) model that can generate realistic EMA for novel\nphoneme sequences and replicate known coarticulation patterns. We use\nmodel-generated EMA on 9K minimal word pairs to analyze coarticulation\nmagnitude and extent up to eight phonemes from the coarticulation trigger, and\ncompare coarticulation resistance across different consonants. Our findings\nalign with earlier studies and suggest a longer-range coarticulation effect\nthan previously found. This model-based approach can potentially compare\ncoarticulation between adults and children and across languages, offering new\ninsights into speech production.", "published": "2024-08-10 21:55:37", "link": "http://arxiv.org/abs/2408.05641v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Stream-based Active Learning for Anomalous Sound Detection in Machine\n  Condition Monitoring", "abstract": "This paper introduces an active learning (AL) framework for anomalous sound\ndetection (ASD) in machine condition monitoring system. Typically, ASD models\nare trained solely on normal samples due to the scarcity of anomalous data,\nleading to decreased accuracy for unseen samples during inference. AL is a\npromising solution to solve this problem by enabling the model to learn new\nconcepts more effectively with fewer labeled examples, thus reducing manual\nannotation efforts. However, its effectiveness in ASD remains unexplored. To\nminimize update costs and time, our proposed method focuses on updating the\nscoring backend of ASD system without retraining the neural network model.\nExperimental results on the DCASE 2023 Challenge Task 2 dataset confirm that\nour AL framework significantly improves ASD performance even with low labeling\nbudgets. Moreover, our proposed sampling strategy outperforms other baselines\nin terms of the partial area under the receiver operating characteristic score.", "published": "2024-08-10 08:58:39", "link": "http://arxiv.org/abs/2408.05493v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dilated Convolution with Learnable Spacings", "abstract": "This thesis presents and evaluates the Dilated Convolution with Learnable\nSpacings (DCLS) method. Through various supervised learning experiments in the\nfields of computer vision, audio, and speech processing, the DCLS method proves\nto outperform both standard and advanced convolution techniques. The research\nis organized into several steps, starting with an analysis of the literature\nand existing convolution techniques that preceded the development of the DCLS\nmethod. We were particularly interested in the methods that are closely related\nto our own and that remain essential to capture the nuances and uniqueness of\nour approach. The cornerstone of our study is the introduction and application\nof the DCLS method to convolutional neural networks (CNNs), as well as to\nhybrid architectures that rely on both convolutional and visual attention\napproaches. DCLS is shown to be particularly effective in tasks such as\nclassification, semantic segmentation, and object detection. Initially using\nbilinear interpolation, the study also explores other interpolation methods,\nfinding that Gaussian interpolation slightly improves performance. The DCLS\nmethod is further applied to spiking neural networks (SNNs) to enable synaptic\ndelay learning within a neural network that could eventually be transferred to\nso-called neuromorphic chips. The results show that the DCLS method stands out\nas a new state-of-the-art technique in SNN audio classification for certain\nbenchmark tasks in this field. These tasks involve datasets with a high\ntemporal component. In addition, we show that DCLS can significantly improve\nthe accuracy of artificial neural networks for the multi-label audio\nclassification task. We conclude with a discussion of the chosen experimental\nsetup, its limitations, the limitations of our method, and our results.", "published": "2024-08-10 12:12:39", "link": "http://arxiv.org/abs/2408.06383v1", "categories": ["cs.LG", "cs.CV", "cs.NE", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
