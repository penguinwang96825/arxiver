{"title": "S&P 500 Trend Prediction", "abstract": "This project aims to predict short-term and long-term upward trends in the\nS&P 500 index using machine learning models and feature engineering based on\nthe \"101 Formulaic Alphas\" methodology. The study employed multiple models,\nincluding Logistic Regression, Decision Trees, Random Forests, Neural Networks,\nK-Nearest Neighbors (KNN), and XGBoost, to identify market trends from\nhistorical stock data collected from Yahoo! Finance. Data preprocessing\ninvolved handling missing values, standardization, and iterative feature\nselection to ensure relevance and variability.\n  For short-term predictions, KNN emerged as the most effective model,\ndelivering robust performance with high recall for upward trends, while for\nlong-term forecasts, XGBoost demonstrated the highest accuracy and AUC scores\nafter hyperparameter tuning and class imbalance adjustments using SMOTE.\nFeature importance analysis highlighted the dominance of momentum-based and\nvolume-related indicators in driving predictions. However, models exhibited\nlimitations such as overfitting and low recall for positive market movements,\nparticularly in imbalanced datasets.\n  The study concludes that KNN is ideal for short-term alerts, whereas XGBoost\nis better suited for long-term trend forecasting. Future enhancements could\ninclude advanced architectures like Long Short-Term Memory (LSTM) networks and\nfurther feature refinement to improve precision and generalizability. These\nfindings contribute to developing reliable machine learning tools for market\ntrend prediction and investment decision-making.", "published": "2024-12-16 05:37:30", "link": "http://arxiv.org/abs/2412.11462v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Stochastic optimal self-path-dependent control: A new type of variational inequality and its viscosity solution", "abstract": "In this paper, we explore a new class of stochastic control problems\ncharacterized by specific control constraints. Specifically, the admissible\ncontrols are subject to the ratcheting constraint, meaning they must be\nnon-decreasing over time and are thus self-path-dependent. This type of\nproblems is common in various practical applications, such as optimal\nconsumption problems in financial engineering and optimal dividend payout\nproblems in actuarial science. Traditional stochastic control theory does not\nreadily apply to these problems due to their unique self-path-dependent control\nfeature. To tackle this challenge, we introduce a new class of\nHamilton-Jacobi-Bellman (HJB) equations, which are variational inequalities\nconcerning the derivative of a new spatial argument that represents the\nhistorical maximum control value. Under the standard Lipschitz continuity\ncondition, we demonstrate that the value functions for these\nself-path-dependent control problems are the unique solutions to their\ncorresponding HJB equations in the viscosity sense.", "published": "2024-12-16 02:23:36", "link": "http://arxiv.org/abs/2412.11383v1", "categories": ["math.OC", "math.AP", "q-fin.MF"], "primary_category": "math.OC"}
{"title": "Multivariate Distributions in Non-Stationary Complex Systems II: Empirical Results for Correlated Stock Markets", "abstract": "Multivariate Distributions are needed to capture the correlation structure of\ncomplex systems. In previous works, we developed a Random Matrix Model for such\ncorrelated multivariate joint probability density functions that accounts for\nthe non-stationarity typically found in complex systems. Here, we apply these\nresults to the returns measured in correlated stock markets. Only the knowledge\nof the multivariate return distributions allows for a full-fledged risk\nassessment. We analyze intraday data of 479 US stocks included in the S&P500\nindex during the trading year of 2014. We focus particularly on the tails which\nare algebraic and heavy. The non-stationary fluctuations of the correlations\nmake the tails heavier. With the few-parameter formulae of our Random Matrix\nModel we can describe and quantify how the empirical distributions change for\nvarying time resolution and in the presence of non-stationarity.", "published": "2024-12-16 09:39:55", "link": "http://arxiv.org/abs/2412.11602v1", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "Multivariate Distributions in Non-Stationary Complex Systems I: Random Matrix Model and Formulae for Data Analysis", "abstract": "Risk assessment for rare events is essential for understanding systemic\nstability in complex systems. As rare events are typically highly correlated,\nit is important to study heavy-tailed multivariate distributions of the\nrelevant variables, i.e. their joint probability density functions. Only for\nfew systems, such investigation have been performed. Statistical models are\ndesirable that describe heavy-tailed multivariate distributions, in particular\nwhen non-stationarity is present as is typically the case in complex systems.\nRecently, we put forward such a model based on a separation of time scales. By\nutilizing random matrices, we showed that the fluctuations of the correlations\nlift the tails. Here, we present formulae and methods to carry out a data\ncomparisons for complex systems. There are only few fit parameters. Compared to\nour previous results, we manage to remove in the algebraic cases one out of the\ntwo, respectively three, fit parameters which considerably facilitates\napplications. Furthermore, we explicitly work out the moments of our model\ndistributions. In a forthcoming paper we will apply our model to financial\nmarkets.", "published": "2024-12-16 09:39:20", "link": "http://arxiv.org/abs/2412.11601v1", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "A Deep Learning Approach for Trading Factor Residuals", "abstract": "The residuals in factor models prevalent in asset pricing presents\nopportunities to exploit the mis-pricing from unexplained cross-sectional\nvariation for arbitrage. We performed a replication of the methodology of\nGuijarro-Ordonez et al. (2019) (G-P-Z) on Deep Learning Statistical Arbitrage\n(DLSA), originally applied to U.S. equity data from 1998 to 2016, using a more\nrecent out-of-sample period from 2016 to 2024. Adhering strictly to\npoint-in-time (PIT) principles and ensuring no information leakage, we follow\nthe same data pre-processing, factor modeling, and deep learning architectures\n(CNNs and Transformers) as outlined by G-P-Z. Our replication yields unusually\nstrong performance metrics in certain tests, with out-of-sample Sharpe ratios\noccasionally exceeding 10. While such results are intriguing, they may indicate\nmodel overfitting, highly specific market conditions, or insufficient\naccounting for transaction costs and market impact. Further examination and\nrobustness checks are needed to align these findings with the more modest\nimprovements reported in the original study. (This work was conducted as the\nfinal project for IEOR 4576: Data-Driven Methods in Finance at Columbia\nUniversity.)", "published": "2024-12-16 04:04:38", "link": "http://arxiv.org/abs/2412.11432v2", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "A multi-factor market-neutral investment strategy for New York Stock Exchange equities", "abstract": "This report presents a systematic market-neutral, multi-factor investment\nstrategy for New York Stock Exchange equities with the objective of delivering\nsteady returns while minimizing correlation with the market. A robust feature\nset is integrated combining momentum-based indicators, fundamental factors, and\nanalyst recommendations. Using various statistical tests for feature selection,\nthe strategy identifies key drivers of equity performance and ranks stocks to\nbuild a balanced portfolio of long and short positions. Portfolio construction\nmethods, including equally weighted, risk parity, and minimum variance\nbeta-neutral approaches, were evaluated through rigorous backtesting. Risk\nparity demonstrated superior performance with a higher Sharpe ratio, lower\nbeta, and smaller maximum drawdown compared to the Standard and Poor's 500\nindex. Risk parity's market neutrality, combined with its ability to maintain\nsteady returns and mitigate large drawdowns, makes it a suitable approach for\nmanaging significant capital in equity markets.", "published": "2024-12-16 20:42:32", "link": "http://arxiv.org/abs/2412.12350v1", "categories": ["q-fin.TR", "91"], "primary_category": "q-fin.TR"}
{"title": "INTERACT: Enabling Interactive, Question-Driven Learning in Large\n  Language Models", "abstract": "Large language models (LLMs) excel at answering questions but remain passive\nlearners--absorbing static data without the ability to question and refine\nknowledge. This paper explores how LLMs can transition to interactive,\nquestion-driven learning through student-teacher dialogues. We introduce\nINTERACT (INTEReractive Learning for Adaptive Concept Transfer), a framework in\nwhich a \"student\" LLM engages a \"teacher\" LLM through iterative inquiries to\nacquire knowledge across 1,347 contexts, including song lyrics, news articles,\nmovie plots, academic papers, and images. Our experiments show that across a\nwide range of scenarios and LLM architectures, interactive learning\nconsistently enhances performance, achieving up to a 25% improvement, with\n'cold-start' student models matching static learning baselines in as few as\nfive dialogue turns. Interactive setups can also mitigate the disadvantages of\nweaker teachers, showcasing the robustness of question-driven learning.", "published": "2024-12-16 02:28:53", "link": "http://arxiv.org/abs/2412.11388v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ConceptEdit: Conceptualization-Augmented Knowledge Editing in Large\n  Language Models for Commonsense Reasoning", "abstract": "Knowledge Editing (KE) aims to adjust a Large Language Model's (LLM) internal\nrepresentations and parameters to correct inaccuracies and improve output\nconsistency without incurring the computational expense of re-training the\nentire model. However, editing commonsense knowledge still faces difficulties,\nincluding limited knowledge coverage in existing resources, the infeasibility\nof annotating labels for an overabundance of commonsense knowledge, and the\nstrict knowledge formats of current editing methods. In this paper, we address\nthese challenges by presenting ConceptEdit, a framework that integrates\nconceptualization and instantiation into the KE pipeline for LLMs to enhance\ntheir commonsense reasoning capabilities. ConceptEdit dynamically diagnoses\nimplausible commonsense knowledge within an LLM using another verifier LLM and\naugments the source knowledge to be edited with conceptualization for stronger\ngeneralizability. Experimental results demonstrate that LLMs enhanced with\nConceptEdit successfully generate commonsense knowledge with improved\nplausibility compared to other baselines and achieve stronger performance\nacross multiple question answering benchmarks.", "published": "2024-12-16 03:34:40", "link": "http://arxiv.org/abs/2412.11418v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FTP: A Fine-grained Token-wise Pruner for Large Language Models via\n  Token Routing", "abstract": "Recently, large language models (LLMs) have demonstrated superior performance\nacross various tasks by adhering to scaling laws, which significantly increase\nmodel size. However, the huge computation overhead during inference hinders the\ndeployment in industrial applications. Many works leverage traditional\ncompression approaches to boost model inference, but these always introduce\nadditional training costs to restore the performance and the pruning results\ntypically show noticeable performance drops compared to the original model when\naiming for a specific level of acceleration. To address these issues, we\npropose a fine-grained token-wise pruning approach for the LLMs, which presents\na learnable router to adaptively identify the less important tokens and skip\nthem across model blocks to reduce computational cost during inference. To\nconstruct the router efficiently, we present a search-based sparsity scheduler\nfor pruning sparsity allocation, a trainable router combined with our proposed\nfour low-dimensional factors as input and three proposed losses. We conduct\nextensive experiments across different benchmarks on different LLMs to\ndemonstrate the superiority of our method. Our approach achieves\nstate-of-the-art (SOTA) pruning results, surpassing other existing pruning\nmethods. For instance, our method outperforms BlockPruner and ShortGPT by\napproximately 10 points on both LLaMA2-7B and Qwen1.5-7B in accuracy retention\nat comparable token sparsity levels.", "published": "2024-12-16 07:09:46", "link": "http://arxiv.org/abs/2412.11494v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Let your LLM generate a few tokens and you will reduce the need for\n  retrieval", "abstract": "In this paper, we investigate how efficiently large language models (LLM) can\nbe trained to check whether an answer is already stored in their parametric\nmemory. We distill an LLM-as-a-judge to compute the IK (I Know) score. We found\nthat this method is particularly beneficial in the context of\nretrieval-assisted augmented generation (RAG), with a respectable accuracy of\n80%. It enables a significant reduction (more than 50%) in the number of search\nand reranking steps required for certain data sets. We have also introduced the\nIK score, which serves as a useful tool for characterising datasets by\nfacilitating the classification task. Interestingly, through the inclusion of\nresponse tokens as input, our results suggest that only about 20,000 training\nsamples are required to achieve good performance. The central element of this\nwork is the use of a teacher model - the LLM as a judge - to generate training\ndata. We also assess the robustness of the IK classifier by evaluating it with\nvarious types of teachers, including both string-based methods and LLMs, with\nthe latter providing better results.", "published": "2024-12-16 08:13:14", "link": "http://arxiv.org/abs/2412.11536v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Role of Natural Language Processing Tasks in Automatic Literary\n  Character Network Construction", "abstract": "The automatic extraction of character networks from literary texts is\ngenerally carried out using natural language processing (NLP) cascading\npipelines. While this approach is widespread, no study exists on the impact of\nlow-level NLP tasks on their performance. In this article, we conduct such a\nstudy on a literary dataset, focusing on the role of named entity recognition\n(NER) and coreference resolution when extracting co-occurrence networks. To\nhighlight the impact of these tasks' performance, we start with gold-standard\nannotations, progressively add uniformly distributed errors, and observe their\nimpact in terms of character network quality. We demonstrate that NER\nperformance depends on the tested novel and strongly affects character\ndetection. We also show that NER-detected mentions alone miss a lot of\ncharacter co-occurrences, and that coreference resolution is needed to prevent\nthis. Finally, we present comparison points with 2 methods based on large\nlanguage models (LLMs), including a fully end-to-end one, and show that these\nmodels are outperformed by traditional NLP pipelines in terms of recall.", "published": "2024-12-16 08:46:53", "link": "http://arxiv.org/abs/2412.11560v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AUEB-Archimedes at RIRAG-2025: Is obligation concatenation really all\n  you need?", "abstract": "This paper presents the systems we developed for RIRAG-2025, a shared task\nthat requires answering regulatory questions by retrieving relevant passages.\nThe generated answers are evaluated using RePASs, a reference-free and\nmodel-based metric. Our systems use a combination of three retrieval models and\na reranker. We show that by exploiting a neural component of RePASs that\nextracts important sentences ('obligations') from the retrieved passages, we\nachieve a dubiously high score (0.947), even though the answers are directly\nextracted from the retrieved passages and are not actually generated answers.\nWe then show that by selecting the answer with the best RePASs among a few\ngenerated alternatives and then iteratively refining this answer by reducing\ncontradictions and covering more obligations, we can generate readable,\ncoherent answers that achieve a more plausible and relatively high score\n(0.639).", "published": "2024-12-16 08:54:21", "link": "http://arxiv.org/abs/2412.11567v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MT-LENS: An all-in-one Toolkit for Better Machine Translation Evaluation", "abstract": "We introduce MT-LENS, a framework designed to evaluate Machine Translation\n(MT) systems across a variety of tasks, including translation quality, gender\nbias detection, added toxicity, and robustness to misspellings. While several\ntoolkits have become very popular for benchmarking the capabilities of Large\nLanguage Models (LLMs), existing evaluation tools often lack the ability to\nthoroughly assess the diverse aspects of MT performance. MT-LENS addresses\nthese limitations by extending the capabilities of LM-eval-harness for MT,\nsupporting state-of-the-art datasets and a wide range of evaluation metrics. It\nalso offers a user-friendly platform to compare systems and analyze\ntranslations with interactive visualizations. MT-LENS aims to broaden access to\nevaluation strategies that go beyond traditional translation quality\nevaluation, enabling researchers and engineers to better understand the\nperformance of a NMT model and also easily measure system's biases.", "published": "2024-12-16 09:57:28", "link": "http://arxiv.org/abs/2412.11615v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fool Me, Fool Me: User Attitudes Toward LLM Falsehoods", "abstract": "While Large Language Models (LLMs) have become central tools in various\nfields, they often provide inaccurate or false information. This study examines\nuser preferences regarding falsehood responses from LLMs. Specifically, we\nevaluate preferences for LLM responses where false statements are explicitly\nmarked versus unmarked responses and preferences for confident falsehoods\ncompared to LLM disclaimers acknowledging a lack of knowledge. Additionally, we\ninvestigate how requiring users to assess the truthfulness of statements\ninfluences these preferences.\n  Surprisingly, 61\\% of users prefer unmarked falsehood responses over marked\nones, and 69\\% prefer confident falsehoods over LLMs admitting lack of\nknowledge. In all our experiments, a total of 300 users participated,\ncontributing valuable data to our analysis and conclusions. When users are\nrequired to evaluate the truthfulness of statements, preferences for unmarked\nand falsehood responses decrease slightly but remain high. These findings\nsuggest that user preferences, which influence LLM training via feedback\nmechanisms, may inadvertently encourage the generation of falsehoods. Future\nresearch should address the ethical and practical implications of aligning LLM\nbehavior with such preferences.", "published": "2024-12-16 10:10:27", "link": "http://arxiv.org/abs/2412.11625v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Crowdsourcing Task Design for Discourse Relation Annotation", "abstract": "Interpreting implicit discourse relations involves complex reasoning,\nrequiring the integration of semantic cues with background knowledge, as overt\nconnectives like because or then are absent. These relations often allow\nmultiple interpretations, best represented as distributions. In this study, we\ncompare two established methods that crowdsource English implicit discourse\nrelation annotation by connective insertion: a free-choice approach, which\nallows annotators to select any suitable connective, and a forced-choice\napproach, which asks them to select among a set of predefined options.\nSpecifically, we re-annotate the whole DiscoGeM 1.0 corpus -- initially\nannotated with the free-choice method -- using the forced-choice approach. The\nfree-choice approach allows for flexible and intuitive insertion of various\nconnectives, which are context-dependent. Comparison among over 130,000\nannotations, however, shows that the free-choice strategy produces less diverse\nannotations, often converging on common labels. Analysis of the results reveals\nthe interplay between task design and the annotators' abilities to interpret\nand produce discourse relations.", "published": "2024-12-16 10:26:11", "link": "http://arxiv.org/abs/2412.11637v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Adaptive Paraphrasing and Preference Learning for Improved Claim\n  Verifiability", "abstract": "In fact-checking, structure and phrasing of claims critically influence a\nmodel's ability to predict verdicts accurately. Social media content in\nparticular rarely serves as optimal input for verification systems, which\nnecessitates pre-processing to extract the claim from noisy context before fact\nchecking. Prior work suggests extracting a claim representation that humans\nfind to be checkworthy and verifiable. This has two limitations: (1) the format\nmay not be optimal for a fact-checking model, and (2), it requires annotated\ndata to learn the extraction task from. We address both issues and propose a\nmethod to extract claims that is not reliant on labeled training data. Instead,\nour self-adaptive approach only requires a black-box fact checking model and a\ngenerative language model (LM). Given a tweet, we iteratively optimize the LM\nto generate a claim paraphrase that increases the performance of a fact\nchecking model. By learning from preference pairs, we align the LM to the fact\nchecker using direct preference optimization. We show that this novel setup\nextracts a claim paraphrase that is more verifiable than their original social\nmedia formulations, and is on par with competitive baselines. For refuted\nclaims, our method consistently outperforms all baselines.", "published": "2024-12-16 10:54:57", "link": "http://arxiv.org/abs/2412.11653v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoinMath: Harnessing the Power of Coding Instruction for Math LLMs", "abstract": "Large Language Models (LLMs) have shown strong performance in solving\nmathematical problems, with code-based solutions proving particularly\neffective. However, the best practice to leverage coding instruction data to\nenhance mathematical reasoning remains underexplored. This study investigates\nthree key questions: (1) How do different coding styles of mathematical\ncode-based rationales impact LLMs' learning performance? (2) Can general-domain\ncoding instructions improve performance? (3) How does integrating textual\nrationales with code-based ones during training enhance mathematical reasoning\nabilities? Our findings reveal that code-based rationales with concise\ncomments, descriptive naming, and hardcoded solutions are beneficial, while\nimprovements from general-domain coding instructions and textual rationales are\nrelatively minor. Based on these insights, we propose CoinMath, a learning\nstrategy designed to enhance mathematical reasoning by diversifying the coding\nstyles of code-based rationales. CoinMath generates a variety of code-based\nrationales incorporating concise comments, descriptive naming conventions, and\nhardcoded solutions. Experimental results demonstrate that CoinMath\nsignificantly outperforms its baseline model, MAmmoTH, one of the SOTA math\nLLMs.", "published": "2024-12-16 12:21:11", "link": "http://arxiv.org/abs/2412.11699v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context Filtering with Reward Modeling in Question Answering", "abstract": "Question Answering (QA) in NLP is the task of finding answers to a query\nwithin a relevant context retrieved by a retrieval system. Yet, the mix of\nrelevant and irrelevant information in these contexts can hinder performance\nenhancements in QA tasks. To address this, we introduce a context filtering\napproach that removes non-essential details, summarizing crucial content\nthrough Reward Modeling. This method emphasizes keeping vital data while\nomitting the extraneous during summarization model training. We offer a\nframework for developing efficient QA models by discerning useful information\nfrom dataset pairs, bypassing the need for costly human evaluation.\nFurthermore, we show that our approach can significantly outperform the\nbaseline, as evidenced by a 6.8-fold increase in the EM Per Token (EPT) metric,\nwhich we propose as a measure of token efficiency, indicating a notable\ntoken-efficiency boost for low-resource settings.", "published": "2024-12-16 12:29:24", "link": "http://arxiv.org/abs/2412.11707v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MiMoTable: A Multi-scale Spreadsheet Benchmark with Meta Operations for\n  Table Reasoning", "abstract": "Extensive research has been conducted to explore the capability of Large\nLanguage Models (LLMs) for table reasoning and has significantly improved the\nperformance on existing benchmarks. However, tables and user questions in\nreal-world applications are more complex and diverse, presenting an unignorable\ngap compared to the existing benchmarks. To fill the gap, we propose a\n\\textbf{M}ult\\textbf{i}-scale spreadsheet benchmark with \\textbf{M}eta\n\\textbf{o}perations for \\textbf{Table} reasoning, named as MiMoTable.\nSpecifically, MiMoTable incorporates two key features. First, the tables in\nMiMoTable are all spreadsheets used in real-world scenarios, which cover seven\ndomains and contain different types. Second, we define a new criterion with six\ncategories of meta operations for measuring the difficulty of each question in\nMiMoTable, simultaneously as a new perspective for measuring the difficulty of\nthe existing benchmarks. Experimental results show that Claude-3.5-Sonnet\nachieves the best performance with 77.4\\% accuracy, indicating that there is\nstill significant room to improve for LLMs on MiMoTable. Furthermore, we grade\nthe difficulty of existing benchmarks according to our new criteria.\nExperiments have shown that the performance of LLMs decreases as the difficulty\nof benchmarks increases, thereby proving the effectiveness of our proposed new\ncriterion.", "published": "2024-12-16 12:33:12", "link": "http://arxiv.org/abs/2412.11711v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Findings of the WMT 2024 Shared Task on Discourse-Level Literary\n  Translation", "abstract": "Following last year, we have continued to host the WMT translation shared\ntask this year, the second edition of the Discourse-Level Literary Translation.\nWe focus on three language directions: Chinese-English, Chinese-German, and\nChinese-Russian, with the latter two ones newly added. This year, we totally\nreceived 10 submissions from 5 academia and industry teams. We employ both\nautomatic and human evaluations to measure the performance of the submitted\nsystems. The official ranking of the systems is based on the overall human\njudgments. We release data, system outputs, and leaderboard at\nhttps://www2.statmt.org/wmt24/literary-translation-task.html.", "published": "2024-12-16 12:54:52", "link": "http://arxiv.org/abs/2412.11732v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Personalized LLM for Generating Customized Responses to the Same Query\n  from Different Users", "abstract": "Existing work on large language model (LLM) personalization assigned\ndifferent responding roles to LLM, but overlooked the diversity of questioners.\nIn this work, we propose a new form of questioner-aware LLM personalization,\ngenerating different responses even for the same query from different\nquestioners. We design a dual-tower model architecture with a cross-questioner\ngeneral encoder and a questioner-specific encoder. We further apply contrastive\nlearning with multi-view augmentation, pulling close the dialogue\nrepresentations of the same questioner, while pulling apart those of different\nquestioners. To mitigate the impact of question diversity on\nquestioner-contrastive learning, we cluster the dialogues based on question\nsimilarity and restrict the scope of contrastive learning within each cluster.\nWe also build a multi-questioner dataset from English and Chinese scripts and\nWeChat records, called MQDialog, containing 173 questioners and 12 responders.\nExtensive evaluation with different metrics shows a significant improvement in\nthe quality of personalized response generation.", "published": "2024-12-16 12:57:19", "link": "http://arxiv.org/abs/2412.11736v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CSR:Achieving 1 Bit Key-Value Cache via Sparse Representation", "abstract": "The emergence of long-context text applications utilizing large language\nmodels (LLMs) has presented significant scalability challenges, particularly in\nmemory footprint. The linear growth of the Key-Value (KV) cache responsible for\nstoring attention keys and values to minimize redundant computations can lead\nto substantial increases in memory consumption, potentially causing models to\nfail to serve with limited memory resources. To address this issue, we propose\na novel approach called Cache Sparse Representation (CSR), which converts the\nKV cache by transforming the dense Key-Value cache tensor into sparse indexes\nand weights, offering a more memory-efficient representation during LLM\ninference. Furthermore, we introduce NeuralDict, a novel neural network-based\nmethod for automatically generating the dictionary used in our sparse\nrepresentation. Our extensive experiments demonstrate that CSR achieves\nperformance comparable to state-of-the-art KV cache quantization algorithms\nwhile maintaining robust functionality in memory-constrained environments.", "published": "2024-12-16 13:01:53", "link": "http://arxiv.org/abs/2412.11741v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Dataset Creation: Critical View of Annotation Variation and Bias\n  Probing of a Dataset for Online Radical Content Detection", "abstract": "The proliferation of radical content on online platforms poses significant\nrisks, including inciting violence and spreading extremist ideologies. Despite\nongoing research, existing datasets and models often fail to address the\ncomplexities of multilingual and diverse data. To bridge this gap, we introduce\na publicly available multilingual dataset annotated with radicalization levels,\ncalls for action, and named entities in English, French, and Arabic. This\ndataset is pseudonymized to protect individual privacy while preserving\ncontextual information. Beyond presenting our freely available dataset, we\nanalyze the annotation process, highlighting biases and disagreements among\nannotators and their implications for model performance. Additionally, we use\nsynthetic data to investigate the influence of socio-demographic traits on\nannotation patterns and model predictions. Our work offers a comprehensive\nexamination of the challenges and opportunities in building robust datasets for\nradical content detection, emphasizing the importance of fairness and\ntransparency in model development.", "published": "2024-12-16 13:03:43", "link": "http://arxiv.org/abs/2412.11745v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Common Ground, Diverse Roots: The Difficulty of Classifying Common\n  Examples in Spanish Varieties", "abstract": "Variations in languages across geographic regions or cultures are crucial to\naddress to avoid biases in NLP systems designed for culturally sensitive tasks,\nsuch as hate speech detection or dialog with conversational agents. In\nlanguages such as Spanish, where varieties can significantly overlap, many\nexamples can be valid across them, which we refer to as common examples.\nIgnoring these examples may cause misclassifications, reducing model accuracy\nand fairness. Therefore, accounting for these common examples is essential to\nimprove the robustness and representativeness of NLP systems trained on such\ndata. In this work, we address this problem in the context of Spanish\nvarieties. We use training dynamics to automatically detect common examples or\nerrors in existing Spanish datasets. We demonstrate the efficacy of using\npredicted label confidence for our Datamaps\n\\cite{swayamdipta-etal-2020-dataset} implementation for the identification of\nhard-to-classify examples, especially common examples, enhancing model\nperformance in variety identification tasks. Additionally, we introduce a Cuban\nSpanish Variety Identification dataset with common examples annotations\ndeveloped to facilitate more accurate detection of Cuban and Caribbean Spanish\nvarieties. To our knowledge, this is the first dataset focused on identifying\nthe Cuban, or any other Caribbean, Spanish variety.", "published": "2024-12-16 13:10:09", "link": "http://arxiv.org/abs/2412.11750v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SCITAT: A Question Answering Benchmark for Scientific Tables and Text\n  Covering Diverse Reasoning Types", "abstract": "Scientific question answering (SQA) is an important task aimed at answering\nquestions based on papers. However, current SQA datasets have limited reasoning\ntypes and neglect the relevance between tables and text, creating a significant\ngap with real scenarios. To address these challenges, we propose a QA benchmark\nfor scientific tables and text with diverse reasoning types (SciTaT). To cover\nmore reasoning types, we summarize various reasoning types from real-world\nquestions. To involve both tables and text, we require the questions to\nincorporate tables and text as much as possible. Based on SciTaT, we propose a\nstrong baseline (CaR), which combines various reasoning methods to address\ndifferent reasoning types and process tables and text at the same time. CaR\nbrings average improvements of 12.9% over other baselines on SciTaT, validating\nits effectiveness. Error analysis reveals the challenges of SciTaT, such as\ncomplex numerical calculations and domain knowledge.", "published": "2024-12-16 13:21:57", "link": "http://arxiv.org/abs/2412.11757v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QUENCH: Measuring the gap between Indic and Non-Indic Contextual General\n  Reasoning in LLMs", "abstract": "The rise of large language models (LLMs) has created a need for advanced\nbenchmarking systems beyond traditional setups. To this end, we introduce\nQUENCH, a novel text-based English Quizzing Benchmark manually curated and\ntranscribed from YouTube quiz videos. QUENCH possesses masked entities and\nrationales for the LLMs to predict via generation. At the intersection of\ngeographical context and common sense reasoning, QUENCH helps assess world\nknowledge and deduction capabilities of LLMs via a zero-shot, open-domain\nquizzing setup. We perform an extensive evaluation on 7 LLMs and 4 metrics,\ninvestigating the influence of model size, prompting style, geographical\ncontext, and gold-labeled rationale generation. The benchmarking concludes with\nan error analysis to which the LLMs are prone.", "published": "2024-12-16 13:28:29", "link": "http://arxiv.org/abs/2412.11763v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on\n  Large Language Models", "abstract": "Despite demonstrating impressive capabilities, Large Language Models (LLMs)\nstill often struggle to accurately express the factual knowledge they possess,\nespecially in cases where the LLMs' knowledge boundaries are ambiguous. To\nimprove LLMs' factual expressions, we propose the UAlign framework, which\nleverages Uncertainty estimations to represent knowledge boundaries, and then\nexplicitly incorporates these representations as input features into prompts\nfor LLMs to Align with factual knowledge. First, we prepare the dataset on\nknowledge question-answering (QA) samples by calculating two uncertainty\nestimations, including confidence score and semantic entropy, to represent the\nknowledge boundaries for LLMs. Subsequently, using the prepared dataset, we\ntrain a reward model that incorporates uncertainty estimations and then employ\nthe Proximal Policy Optimization (PPO) algorithm for factuality alignment on\nLLMs. Experimental results indicate that, by integrating uncertainty\nrepresentations in LLM alignment, the proposed UAlign can significantly enhance\nthe LLMs' capacities to confidently answer known questions and refuse unknown\nquestions on both in-domain and out-of-domain tasks, showing reliability\nimprovements and good generalizability over various prompt- and training-based\nbaselines.", "published": "2024-12-16 14:14:27", "link": "http://arxiv.org/abs/2412.11803v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EventSum: A Large-Scale Event-Centric Summarization Dataset for Chinese\n  Multi-News Documents", "abstract": "In real life, many dynamic events, such as major disasters and large-scale\nsports events, evolve continuously over time. Obtaining an overview of these\nevents can help people quickly understand the situation and respond more\neffectively. This is challenging because the key information of the event is\noften scattered across multiple documents, involving complex event knowledge\nunderstanding and reasoning, which is under-explored in previous work.\nTherefore, we proposed the Event-Centric Multi-Document Summarization (ECS)\ntask, which aims to generate concise and comprehensive summaries of a given\nevent based on multiple related news documents. Based on this, we constructed\nthe EventSum dataset, which was constructed using Baidu Baike entries and\nunderwent extensive human annotation, to facilitate relevant research. It is\nthe first large scale Chinese multi-document summarization dataset, containing\n5,100 events and a total of 57,984 news documents, with an average of 11.4\ninput news documents and 13,471 characters per event. To ensure data quality\nand mitigate potential data leakage, we adopted a multi-stage annotation\napproach for manually labeling the test set. Given the complexity of\nevent-related information, existing metrics struggle to comprehensively assess\nthe quality of generated summaries. We designed specific metrics including\nEvent Recall, Argument Recall, Causal Recall, and Temporal Recall along with\ncorresponding calculation methods for evaluation. We conducted comprehensive\nexperiments on EventSum to evaluate the performance of advanced long-context\nLarge Language Models (LLMs) on this task. Our experimental results indicate\nthat: 1) The event-centric multi-document summarization task remains\nchallenging for existing long-context LLMs; 2) The recall metrics we designed\nare crucial for evaluating the comprehensiveness of the summary information.", "published": "2024-12-16 14:29:49", "link": "http://arxiv.org/abs/2412.11814v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancements and Challenges in Bangla Question Answering Models: A\n  Comprehensive Review", "abstract": "The domain of Natural Language Processing (NLP) has experienced notable\nprogress in the evolution of Bangla Question Answering (QA) systems. This paper\npresents a comprehensive review of seven research articles that contribute to\nthe progress in this domain. These research studies explore different aspects\nof creating question-answering systems for the Bangla language. They cover\nareas like collecting data, preparing it for analysis, designing models,\nconducting experiments, and interpreting results. The papers introduce\ninnovative methods like using LSTM-based models with attention mechanisms,\ncontext-based QA systems, and deep learning techniques based on prior\nknowledge. However, despite the progress made, several challenges remain,\nincluding the lack of well-annotated data, the absence of high-quality reading\ncomprehension datasets, and difficulties in understanding the meaning of words\nin context. Bangla QA models' precision and applicability are constrained by\nthese challenges. This review emphasizes the significance of these research\ncontributions by highlighting the developments achieved in creating Bangla QA\nsystems as well as the ongoing effort required to get past roadblocks and\nimprove the performance of these systems for actual language comprehension\ntasks.", "published": "2024-12-16 14:42:26", "link": "http://arxiv.org/abs/2412.11823v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are You Doubtful? Oh, It Might Be Difficult Then! Exploring the Use of\n  Model Uncertainty for Question Difficulty Estimation", "abstract": "In an educational setting, an estimate of the difficulty of multiple-choice\nquestions (MCQs), a commonly used strategy to assess learning progress,\nconstitutes very useful information for both teachers and students. Since human\nassessment is costly from multiple points of view, automatic approaches to MCQ\nitem difficulty estimation are investigated, yielding however mixed success\nuntil now. Our approach to this problem takes a different angle from previous\nwork: asking various Large Language Models to tackle the questions included in\ntwo different MCQ datasets, we leverage model uncertainty to estimate item\ndifficulty. By using both model uncertainty features as well as textual\nfeatures in a Random Forest regressor, we show that uncertainty features\ncontribute substantially to difficulty prediction, where difficulty is\ninversely proportional to the number of students who can correctly answer a\nquestion. In addition to showing the value of our approach, we also observe\nthat our model achieves state-of-the-art results on the BEA publicly available\ndataset.", "published": "2024-12-16 14:55:09", "link": "http://arxiv.org/abs/2412.11831v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improved Models for Media Bias Detection and Subcategorization", "abstract": "We present improved models for the granular detection and sub-classification\nnews media bias in English news articles. We compare the performance of\nzero-shot versus fine-tuned large pre-trained neural transformer language\nmodels, explore how the level of detail of the classes affects performance on a\nnovel taxonomy of 27 news bias-types, and demonstrate how using synthetically\ngenerated example data can be used to improve quality", "published": "2024-12-16 14:56:31", "link": "http://arxiv.org/abs/2412.11835v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Instruction-Tuned Large Language Models to Identify Indicators of\n  Vulnerability in Police Incident Narratives", "abstract": "Objectives: Compare qualitative coding of instruction tuned large language\nmodels (IT-LLMs) against human coders in classifying the presence or absence of\nvulnerability in routinely collected unstructured text that describes\npolice-public interactions. Evaluate potential bias in IT-LLM codings. Methods:\nAnalyzing publicly available text narratives of police-public interactions\nrecorded by Boston Police Department, we provide humans and IT-LLMs with\nqualitative labelling codebooks and compare labels generated by both, seeking\nto identify situations associated with (i) mental ill health; (ii) substance\nmisuse; (iii) alcohol dependence; and (iv) homelessness. We explore multiple\nprompting strategies and model sizes, and the variability of labels generated\nby repeated prompts. Additionally, to explore model bias, we utilize\ncounterfactual methods to assess the impact of two protected characteristics -\nrace and gender - on IT-LLM classification. Results: Results demonstrate that\nIT-LLMs can effectively support human qualitative coding of police incident\nnarratives. While there is some disagreement between LLM and human generated\nlabels, IT-LLMs are highly effective at screening narratives where no\nvulnerabilities are present, potentially vastly reducing the requirement for\nhuman coding. Counterfactual analyses demonstrate that manipulations to both\ngender and race of individuals described in narratives have very limited\neffects on IT-LLM classifications beyond those expected by chance. Conclusions:\nIT-LLMs offer effective means to augment human qualitative coding in a way that\nrequires much lower levels of resource to analyze large unstructured datasets.\nMoreover, they encourage specificity in qualitative coding, promote\ntransparency, and provide the opportunity for more standardized, replicable\napproaches to analyzing large free-text police data sources.", "published": "2024-12-16 15:27:37", "link": "http://arxiv.org/abs/2412.11878v1", "categories": ["cs.CL", "I.2.7; H.3.1"], "primary_category": "cs.CL"}
{"title": "Can Language Models Rival Mathematics Students? Evaluating Mathematical\n  Reasoning through Textual Manipulation and Human Experiments", "abstract": "In this paper we look at the ability of recent large language models (LLMs)\nat solving mathematical problems in combinatorics. We compare models LLaMA-2,\nLLaMA-3.1, GPT-4, and Mixtral against each other and against human pupils and\nundergraduates with prior experience in mathematical olympiads. To facilitate\nthese comparisons we introduce the Combi-Puzzles dataset, which contains 125\nproblem variants based on 25 combinatorial reasoning problems. Each problem is\npresented in one of five distinct forms, created by systematically manipulating\nthe problem statements through adversarial additions, numeric parameter\nchanges, and linguistic obfuscation. Our variations preserve the mathematical\ncore and are designed to measure the generalisability of LLM problem-solving\nabilities, while also increasing confidence that problems are submitted to LLMs\nin forms that have not been seen as training instances. We found that a model\nbased on GPT-4 outperformed all other models in producing correct responses,\nand performed significantly better in the mathematical variation of the\nproblems than humans. We also found that modifications to problem statements\nsignificantly impact the LLM's performance, while human performance remains\nunaffected.", "published": "2024-12-16 15:54:06", "link": "http://arxiv.org/abs/2412.11908v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CharacterBench: Benchmarking Character Customization of Large Language\n  Models", "abstract": "Character-based dialogue (aka role-playing) enables users to freely customize\ncharacters for interaction, which often relies on LLMs, raising the need to\nevaluate LLMs' character customization capability. However, existing benchmarks\nfail to ensure a robust evaluation as they often only involve a single\ncharacter category or evaluate limited dimensions. Moreover, the sparsity of\ncharacter features in responses makes feature-focused generative evaluation\nboth ineffective and inefficient. To address these issues, we propose\nCharacterBench, the largest bilingual generative benchmark, with 22,859\nhuman-annotated samples covering 3,956 characters from 25 detailed character\ncategories. We define 11 dimensions of 6 aspects, classified as sparse and\ndense dimensions based on whether character features evaluated by specific\ndimensions manifest in each response. We enable effective and efficient\nevaluation by crafting tailored queries for each dimension to induce\ncharacters' responses related to specific dimensions. Further, we develop\nCharacterJudge model for cost-effective and stable evaluations. Experiments\nshow its superiority over SOTA automatic judges (e.g., GPT-4) and our\nbenchmark's potential to optimize LLMs' character customization. Our repository\nis at https://github.com/thu-coai/CharacterBench.", "published": "2024-12-16 15:55:34", "link": "http://arxiv.org/abs/2412.11912v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Mathematical Reasoning in the Era of Multimodal Large\n  Language Model: Benchmark, Method & Challenges", "abstract": "Mathematical reasoning, a core aspect of human cognition, is vital across\nmany domains, from educational problem-solving to scientific advancements. As\nartificial general intelligence (AGI) progresses, integrating large language\nmodels (LLMs) with mathematical reasoning tasks is becoming increasingly\nsignificant. This survey provides the first comprehensive analysis of\nmathematical reasoning in the era of multimodal large language models (MLLMs).\nWe review over 200 studies published since 2021, and examine the\nstate-of-the-art developments in Math-LLMs, with a focus on multimodal\nsettings. We categorize the field into three dimensions: benchmarks,\nmethodologies, and challenges. In particular, we explore multimodal\nmathematical reasoning pipeline, as well as the role of (M)LLMs and the\nassociated methodologies. Finally, we identify five major challenges hindering\nthe realization of AGI in this domain, offering insights into the future\ndirection for enhancing multimodal reasoning capabilities. This survey serves\nas a critical resource for the research community in advancing the capabilities\nof LLMs to tackle complex multimodal reasoning tasks.", "published": "2024-12-16 16:21:41", "link": "http://arxiv.org/abs/2412.11936v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Precise Length Control in Large Language Models", "abstract": "Large Language Models (LLMs) are increasingly used in production systems,\npowering applications such as chatbots, summarization, and question answering.\nDespite their success, controlling the length of their response remains a\nsignificant challenge, particularly for tasks requiring structured outputs or\nspecific levels of detail. In this work, we propose a method to adapt\npre-trained decoder-only LLMs for precise control of response length. Our\napproach incorporates a secondary length-difference positional encoding (LDPE)\ninto the input embeddings, which counts down to a user-set response termination\nlength. Fine-tuning with LDPE allows the model to learn to terminate responses\ncoherently at the desired length, achieving mean token errors of less than 3\ntokens. We also introduce Max New Tokens++, an extension that enables flexible\nupper-bound length control, rather than an exact target. Experimental results\non tasks such as question answering and document summarization demonstrate that\nour method enables precise length control without compromising response\nquality.", "published": "2024-12-16 16:22:27", "link": "http://arxiv.org/abs/2412.11937v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "The Impact of Token Granularity on the Predictive Power of Language\n  Model Surprisal", "abstract": "Word-by-word language model surprisal is often used to model the incremental\nprocessing of human readers, which raises questions about how various choices\nin language modeling influence its predictive power. One factor that has been\noverlooked in cognitive modeling is the granularity of subword tokens, which\nexplicitly encodes information about word length and frequency, and ultimately\ninfluences the quality of vector representations that are learned. This paper\npresents experiments that manipulate the token granularity and evaluate its\nimpact on the ability of surprisal to account for processing difficulty of\nnaturalistic text and garden-path constructions. Experiments with naturalistic\nreading times reveal a substantial influence of token granularity on surprisal,\nwith tokens defined by a vocabulary size of 8,000 resulting in surprisal that\nis most predictive. In contrast, on garden-path constructions, language models\ntrained on coarser-grained tokens generally assigned higher surprisal to\ncritical regions, suggesting their increased sensitivity to syntax. Taken\ntogether, these results suggest a large role of token granularity on the\nquality of language model surprisal for cognitive modeling.", "published": "2024-12-16 16:24:58", "link": "http://arxiv.org/abs/2412.11940v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inferring Functionality of Attention Heads from their Parameters", "abstract": "Attention heads are one of the building blocks of large language models\n(LLMs). Prior work on investigating their operation mostly focused on analyzing\ntheir behavior during inference for specific circuits or tasks. In this work,\nwe seek a comprehensive mapping of the operations they implement in a model. We\npropose MAPS (Mapping Attention head ParameterS), an efficient framework that\ninfers the functionality of attention heads from their parameters, without any\nmodel training or inference. We showcase the utility of MAPS for answering two\ntypes of questions: (a) given a predefined operation, mapping how strongly\nheads across the model implement it, and (b) given an attention head, inferring\nits salient functionality. Evaluating MAPS on 20 operations across 6 popular\nLLMs shows its estimations correlate with the head's outputs during inference\nand are causally linked to the model's predictions. Moreover, its mappings\nreveal attention heads of certain operations that were overlooked in previous\nstudies, and valuable insights on function universality and architecture biases\nin LLMs. Next, we present an automatic pipeline and analysis that leverage MAPS\nto characterize the salient operations of a given head. Our pipeline produces\nplausible operation descriptions for most heads, as assessed by human judgment,\nwhile revealing diverse operations.", "published": "2024-12-16 16:45:33", "link": "http://arxiv.org/abs/2412.11965v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DARWIN 1.5: Large Language Models as Materials Science Adapted Learners", "abstract": "Materials discovery and design aim to find compositions and structures with\ndesirable properties over highly complex and diverse physical spaces.\nTraditional solutions, such as high-throughput simulations or machine learning,\noften rely on complex descriptors, which hinder generalizability and\ntransferability across different material systems. Moreover, These descriptors\nmay inadequately represent macro-scale material properties, which are\ninfluenced by structural imperfections and compositional variations in\nreal-world samples, thus limiting their practical applicability. To address\nthese challenges, we propose DARWIN 1.5, the largest open-source large language\nmodel tailored for materials science. By leveraging natural language as input,\nDARWIN eliminates the need for task-specific descriptors and enables a\nflexible, unified approach to material property prediction and discovery. Our\napproach integrates 6M material domain papers and 21 experimental datasets from\n49,256 materials across modalities while enabling cross-task knowledge\ntransfer. The enhanced model achieves up to 59.1% improvement in prediction\naccuracy over the base LLaMA-7B architecture and outperforms SOTA machine\nlearning approaches across 8 materials design tasks. These results establish\nLLMs as a promising foundation for developing versatile and scalable models in\nmaterials science.", "published": "2024-12-16 16:51:27", "link": "http://arxiv.org/abs/2412.11970v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speak & Improve Challenge 2025: Tasks and Baseline Systems", "abstract": "This paper presents the \"Speak & Improve Challenge 2025: Spoken Language\nAssessment and Feedback\" -- a challenge associated with the ISCA SLaTE 2025\nWorkshop. The goal of the challenge is to advance research on spoken language\nassessment and feedback, with tasks associated with both the underlying\ntechnology and language learning feedback. Linked with the challenge, the Speak\n& Improve (S&I) Corpus 2025 is being pre-released, a dataset of L2 learner\nEnglish data with holistic scores and language error annotation, collected from\nopen (spontaneous) speaking tests on the Speak & Improve learning platform. The\ncorpus consists of approximately 315 hours of audio data from second language\nEnglish learners with holistic scores, and a 55-hour subset with manual\ntranscriptions and error labels. The Challenge has four shared tasks: Automatic\nSpeech Recognition (ASR), Spoken Language Assessment (SLA), Spoken Grammatical\nError Correction (SGEC), and Spoken Grammatical Error Correction Feedback\n(SGECF). Each of these tasks has a closed track where a predetermined set of\nmodels and data sources are allowed to be used, and an open track where any\npublic resource may be used. Challenge participants may do one or more of the\ntasks. This paper describes the challenge, the S&I Corpus 2025, and the\nbaseline systems released for the Challenge.", "published": "2024-12-16 17:05:18", "link": "http://arxiv.org/abs/2412.11985v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speak & Improve Corpus 2025: an L2 English Speech Corpus for Language\n  Assessment and Feedback", "abstract": "We introduce the Speak & Improve Corpus 2025, a dataset of L2 learner English\ndata with holistic scores and language error annotation, collected from open\n(spontaneous) speaking tests on the Speak & Improve learning platform. The aim\nof the corpus release is to address a major challenge to developing L2 spoken\nlanguage processing systems, the lack of publicly available data with\nhigh-quality annotations. It is being made available for non-commercial use on\nthe ELiT website. In designing this corpus we have sought to make it cover a\nwide-range of speaker attributes, from their L1 to their speaking ability, as\nwell as providing manual annotations. This enables a range of language-learning\ntasks to be examined, such as assessing speaking proficiency or providing\nfeedback on grammatical errors in a learner's speech. Additionally the data\nsupports research into the underlying technology required for these tasks\nincluding automatic speech recognition (ASR) of low resource L2 learner\nEnglish, disfluency detection or spoken grammatical error correction (GEC). The\ncorpus consists of around 315 hours of L2 English learners audio with holistic\nscores, and a subset of audio annotated with transcriptions and error labels.", "published": "2024-12-16 17:07:26", "link": "http://arxiv.org/abs/2412.11986v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ExecRepoBench: Multi-level Executable Code Completion Evaluation", "abstract": "Code completion has become an essential tool for daily software development.\nExisting evaluation benchmarks often employ static methods that do not fully\ncapture the dynamic nature of real-world coding environments and face\nsignificant challenges, including limited context length, reliance on\nsuperficial evaluation metrics, and potential overfitting to training datasets.\nIn this work, we introduce a novel framework for enhancing code completion in\nsoftware development through the creation of a repository-level benchmark\nExecRepoBench and the instruction corpora Repo-Instruct, aim at improving the\nfunctionality of open-source large language models (LLMs) in real-world coding\nscenarios that involve complex interdependencies across multiple files.\nExecRepoBench includes 1.2K samples from active Python repositories. Plus, we\npresent a multi-level grammar-based completion methodology conditioned on the\nabstract syntax tree to mask code fragments at various logical units (e.g.\nstatements, expressions, and functions). Then, we fine-tune the open-source LLM\nwith 7B parameters on Repo-Instruct to produce a strong code completion\nbaseline model Qwen2.5-Coder-Instruct-C based on the open-source model.\nQwen2.5-Coder-Instruct-C is rigorously evaluated against existing benchmarks,\nincluding MultiPL-E and ExecRepoBench, which consistently outperforms prior\nbaselines across all programming languages. The deployment of \\ourmethod{} can\nbe used as a high-performance, local service for programming\ndevelopment\\footnote{\\url{https://execrepobench.github.io/}}.", "published": "2024-12-16 17:14:35", "link": "http://arxiv.org/abs/2412.11990v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Private are Language Models in Abstractive Summarization?", "abstract": "Language models (LMs) have shown outstanding performance in text\nsummarization including sensitive domains such as medicine and law. In these\nsettings, it is important that personally identifying information (PII)\nincluded in the source document should not leak in the summary. Prior efforts\nhave mostly focused on studying how LMs may inadvertently elicit PII from\ntraining data. However, to what extent LMs can provide privacy-preserving\nsummaries given a non-private source document remains under-explored. In this\npaper, we perform a comprehensive study across two closed- and three\nopen-weight LMs of different sizes and families. We experiment with prompting\nand fine-tuning strategies for privacy-preservation across a range of\nsummarization datasets across three domains. Our extensive quantitative and\nqualitative analysis including human evaluation shows that LMs often cannot\nprevent PII leakage on their summaries and that current widely-used metrics\ncannot capture context dependent privacy risks.", "published": "2024-12-16 18:08:22", "link": "http://arxiv.org/abs/2412.12040v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Making FETCH! Happen: Finding Emergent Dog Whistles Through Common\n  Habitats", "abstract": "WARNING: This paper contains content that maybe upsetting or offensive to\nsome readers. Dog whistles are coded expressions with dual meanings: one\nintended for the general public (outgroup) and another that conveys a specific\nmessage to an intended audience (ingroup). Often, these expressions are used to\nconvey controversial political opinions while maintaining plausible deniability\nand slip by content moderation filters. Identification of dog whistles relies\non curated lexicons, which have trouble keeping up to date. We introduce\nFETCH!, a task for finding novel dog whistles in massive social media corpora.\nWe find that state-of-the-art systems fail to achieve meaningful results across\nthree distinct social media case studies. We present EarShot, a strong baseline\nsystem that combines the strengths of vector databases and Large Language\nModels (LLMs) to efficiently and effectively identify new dog whistles.", "published": "2024-12-16 18:46:12", "link": "http://arxiv.org/abs/2412.12072v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unanswerability Evaluation for Retrieval Augmented Generation", "abstract": "Existing evaluation frameworks for retrieval-augmented generation (RAG)\nsystems focus on answerable queries, but they overlook the importance of\nappropriately rejecting unanswerable requests. In this paper, we introduce\nUAEval4RAG, a framework designed to evaluate whether RAG systems can handle\nunanswerable queries effectively. We define a taxonomy with six unanswerable\ncategories, and UAEval4RAG automatically synthesizes diverse and challenging\nqueries for any given knowledge base with unanswered ratio and acceptable ratio\nmetrics. We conduct experiments with various RAG components, including\nretrieval models, rewriting methods, rerankers, language models, and prompting\nstrategies, and reveal hidden trade-offs in performance of RAG systems. Our\nfindings highlight the critical role of component selection and prompt design\nin optimizing RAG systems to balance the accuracy of answerable queries with\nhigh rejection rates of unanswerable ones. UAEval4RAG provides valuable\ninsights and tools for developing more robust and reliable RAG systems.", "published": "2024-12-16 19:11:55", "link": "http://arxiv.org/abs/2412.12300v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Second Language (Arabic) Acquisition of LLMs via Progressive Vocabulary\n  Expansion", "abstract": "This paper addresses the critical need for democratizing large language\nmodels (LLM) in the Arab world, a region that has seen slower progress in\ndeveloping models comparable to state-of-the-art offerings like GPT-4 or\nChatGPT 3.5, due to a predominant focus on mainstream languages (e.g., English\nand Chinese). One practical objective for an Arabic LLM is to utilize an\nArabic-specific vocabulary for the tokenizer that could speed up decoding.\nHowever, using a different vocabulary often leads to a degradation of learned\nknowledge since many words are initially out-of-vocabulary (OOV) when training\nstarts. Inspired by the vocabulary learning during Second Language (Arabic)\nAcquisition for humans, the released AraLLaMA employs progressive vocabulary\nexpansion, which is implemented by a modified BPE algorithm that progressively\nextends the Arabic subwords in its dynamic vocabulary during training, thereby\nbalancing the OOV ratio at every stage. The ablation study demonstrated the\neffectiveness of Progressive Vocabulary Expansion. Moreover, AraLLaMA achieves\ndecent performance comparable to the best Arabic LLMs across a variety of\nArabic benchmarks. Models, training data, benchmarks, and codes will be all\nopen-sourced.", "published": "2024-12-16 19:29:06", "link": "http://arxiv.org/abs/2412.12310v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph-Guided Textual Explanation Generation Framework", "abstract": "Natural language explanations (NLEs) are commonly used to provide plausible\nfree-text explanations of a model's reasoning about its predictions. However,\nrecent work has questioned their faithfulness, as they may not accurately\nreflect the model's internal reasoning process regarding its predicted answer.\nIn contrast, highlight explanations--input fragments critical for the model's\npredicted answers--exhibit measurable faithfulness. Building on this\nfoundation, we propose G-Tex, a Graph-Guided Textual Explanation Generation\nframework designed to enhance the faithfulness of NLEs. Specifically, highlight\nexplanations are first extracted as faithful cues reflecting the model's\nreasoning logic toward answer prediction. They are subsequently encoded through\na graph neural network layer to guide the NLE generation, which aligns the\ngenerated explanations with the model's underlying reasoning toward the\npredicted answer. Experiments on T5 and BART using three reasoning datasets\nshow that G-Tex improves NLE faithfulness by up to 12.18% compared to baseline\nmethods. Additionally, G-Tex generates NLEs with greater semantic and lexical\nsimilarity to human-written ones. Human evaluations show that G-Tex can\ndecrease redundant content and enhance the overall quality of NLEs. Our work\npresents a novel method for explicitly guiding NLE generation to enhance\nfaithfulness, serving as a foundation for addressing broader criteria in NLE\nand generated text.", "published": "2024-12-16 19:35:55", "link": "http://arxiv.org/abs/2412.12318v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PROPOE 2: Avan\u00e7os na S\u00edntese Computacional de Poemas Baseados em\n  Prosa Liter\u00e1ria Brasileira", "abstract": "The computational generation of poems is a complex task, which involves\nseveral sound, prosodic and rhythmic resources. In this work we present PROPOE\n2, with the extension of structural and rhythmic possibilities compared to the\noriginal system, generating poems from metered sentences extracted from the\nprose of Brazilian literature, with multiple rhythmic assembly criteria. These\nadvances allow for a more coherent exploration of rhythms and sound effects for\nthe poem. Results of poems generated by the system are demonstrated, with\nvariations in parameters to exemplify generation and evaluation using various\ncriteria.\n  A gera\\c{c}\\~ao computacional de poemas \\'e uma tarefa complexa, que envolve\ndiversos recursos sonoros, pros\\'odicos e r\\'itmicos. Neste trabalho\napresentamos PROPOE 2, com a amplia\\c{c}\\~ao de possibilidades estruturais e\nr\\'itmicas em rela\\c{c}\\~ao ao sistema original, gerando poemas a partir de\nsenten\\c{c}as metrificadas extra\\'idas da prosa da literatura brasileira, com\nm\\'ultiplos crit\\'erios r\\'itmicos de montagem. Esses avan\\c{c}os permitem uma\nexplora\\c{c}\\~ao mais coerente de ritmos e efeitos sonoros para o poema.\nResultados de poemas gerados pelo sistema s\\~ao demonstrados, com\nvaria\\c{c}\\~oes de par\\^ametros para exemplificar a gera\\c{c}\\~ao e a\navalia\\c{c}\\~ao pelos variados crit\\'erios.", "published": "2024-12-16 20:53:24", "link": "http://arxiv.org/abs/2412.15263v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-head attention debiasing and contrastive learning for mitigating\n  Dataset Artifacts in Natural Language Inference", "abstract": "While Natural Language Inference (NLI) models have achieved high performances\non benchmark datasets, there are still concerns whether they truly capture the\nintended task, or largely exploit dataset artifacts. Through detailed analysis\nof the Stanford Natural Language Inference (SNLI) dataset, we have uncovered\ncomplex patterns of various types of artifacts and their interactions, leading\nto the development of our novel structural debiasing approach. Our fine-grained\nanalysis of 9,782 validation examples reveals four major categories of\nartifacts: length-based patterns, lexical overlap, subset relationships, and\nnegation patterns. Our multi-head debiasing architecture achieves substantial\nimprovements across all bias categories: length bias accuracy improved from\n86.03% to 90.06%, overlap bias from 91.88% to 93.13%, subset bias from 95.43%\nto 96.49%, and negation bias from 88.69% to 94.64%. Overall, our approach\nreduces the error rate from 14.19% to 10.42% while maintaining high performance\non unbiased examples. Analysis of 1,026 error cases shows significant\nimprovement in handling neutral relationships, traditionally one of the most\nchallenging areas for NLI systems.", "published": "2024-12-16 17:12:21", "link": "http://arxiv.org/abs/2412.16194v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Look Ahead Text Understanding and LLM Stitching", "abstract": "This paper proposes a look ahead text understanding problem with look ahead\nsection identification (LASI) as an example. This problem may appear in\ngenerative AI as well as human interactions, where we want to understand the\ndirection of a developing text or conversation. We tackle the problem using\ntransformer-based LLMs. We show that LASI is more challenging than classic\nsection identification (SI). We argue that both bidirectional contextual\ninformation (e.g., BERT) and unidirectional predictive ability (e.g., GPT) will\nbenefit the task. We propose two approaches to stitch together BERT and GPT.\nExperiments show that our approach outperforms the established models,\nespecially when there is noise in the text (which is often the case for\ndeveloping text in generative AI). Our paper sheds light on other look ahead\ntext understanding tasks that are important to social media, such as look ahead\nsentiment classification, and points out the opportunities to leverage\npre-trained LLMs through stitching.", "published": "2024-12-16 03:32:32", "link": "http://arxiv.org/abs/2412.17836v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating the Feasibility of Mitigating Potential Copyright\n  Infringement via Large Language Model Unlearning", "abstract": "Pre-trained Large Language Models (LLMs) have demonstrated remarkable\ncapabilities but also pose risks by learning and generating copyrighted\nmaterial, leading to significant legal and ethical concerns. In a potential\nreal-world scenario, model owners may need to continuously address copyright\ninfringement in order to address requests for content removal that emerge at\ndifferent time points. One potential way of addressing this is via sequential\nunlearning, where copyrighted content is removed sequentially as new requests\narise. Despite its practical relevance, sequential unlearning in the context of\ncopyright infringement has not been rigorously explored in existing literature.\nTo address this gap, we propose Stable Sequential Unlearning (SSU), a novel\nframework designed to unlearn copyrighted content from LLMs over multiple time\nsteps. Our approach works by identifying and removing specific weight updates\nin the model's parameters that correspond to copyrighted content using task\nvectors. We improve unlearning efficacy by introducing random labeling loss and\nensuring the model retains its general-purpose knowledge by adjusting targeted\nparameters with gradient-based weight saliency. Extensive experimental results\nshow that SSU sometimes achieves an effective trade-off between unlearning\nefficacy and general-purpose language abilities, outperforming existing\nbaselines, but it's not a cure-all for unlearning copyrighted material.", "published": "2024-12-16 20:01:06", "link": "http://arxiv.org/abs/2412.18621v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can AI Extract Antecedent Factors of Human Trust in AI? An Application\n  of Information Extraction for Scientific Literature in Behavioural and\n  Computer Sciences", "abstract": "Information extraction from the scientific literature is one of the main\ntechniques to transform unstructured knowledge hidden in the text into\nstructured data which can then be used for decision-making in down-stream\ntasks. One such area is Trust in AI, where factors contributing to human trust\nin artificial intelligence applications are studied. The relationships of these\nfactors with human trust in such applications are complex. We hence explore\nthis space from the lens of information extraction where, with the input of\ndomain experts, we carefully design annotation guidelines, create the first\nannotated English dataset in this domain, investigate an LLM-guided annotation,\nand benchmark it with state-of-the-art methods using large language models in\nnamed entity and relation extraction. Our results indicate that this problem\nrequires supervised learning which may not be currently feasible with\nprompt-based LLMs.", "published": "2024-12-16 00:02:38", "link": "http://arxiv.org/abs/2412.11344v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Codenames as a Benchmark for Large Language Models", "abstract": "In this paper, we propose the use of the popular word-based board game\nCodenames as a suitable benchmark for evaluating the reasoning capabilities of\nLarge Language Models (LLMs). Codenames presents a highly interesting challenge\nfor achieving successful AI performance, requiring both a sophisticated\nunderstanding of language, theory of mind, and epistemic reasoning\ncapabilities. Prior attempts to develop agents for Codenames have largely\nrelied on word embedding techniques, which have a limited vocabulary range and\nperform poorly when paired with differing approaches. LLMs have demonstrated\nenhanced reasoning and comprehension capabilities for language-based tasks, but\ncan still suffer in lateral thinking challenges. We evaluate the capabilities\nof several state-of-the-art LLMs, including GPT-4o, Gemini 1.5, Claude 3.5\nSonnet, and Llama 3.1, across a variety of board setups. Our results indicate\nthat while certain LLMs perform better than others overall, different models\nexhibit varying emergent behaviours during gameplay and excel at specific\nroles. We also evaluate the performance of different combinations of LLMs when\nplaying cooperatively together, demonstrating that LLM agents are more\ngeneralisable to a wider range of teammates than prior techniques.", "published": "2024-12-16 01:59:03", "link": "http://arxiv.org/abs/2412.11373v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ChatTime: A Unified Multimodal Time Series Foundation Model Bridging\n  Numerical and Textual Data", "abstract": "Human experts typically integrate numerical and textual multimodal\ninformation to analyze time series. However, most traditional deep learning\npredictors rely solely on unimodal numerical data, using a fixed-length window\nfor training and prediction on a single dataset, and cannot adapt to different\nscenarios. The powered pre-trained large language model has introduced new\nopportunities for time series analysis. Yet, existing methods are either\ninefficient in training, incapable of handling textual information, or lack\nzero-shot forecasting capability. In this paper, we innovatively model time\nseries as a foreign language and construct ChatTime, a unified framework for\ntime series and text processing. As an out-of-the-box multimodal time series\nfoundation model, ChatTime provides zero-shot forecasting capability and\nsupports bimodal input/output for both time series and text. We design a series\nof experiments to verify the superior performance of ChatTime across multiple\ntasks and scenarios, and create four multimodal datasets to address data gaps.\nThe experimental results demonstrate the potential and utility of ChatTime.", "published": "2024-12-16 02:04:06", "link": "http://arxiv.org/abs/2412.11376v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Attention with Dependency Parsing Augmentation for Fine-Grained\n  Attribution", "abstract": "To assist humans in efficiently validating RAG-generated content, developing\na fine-grained attribution mechanism that provides supporting evidence from\nretrieved documents for every answer span is essential. Existing fine-grained\nattribution methods rely on model-internal similarity metrics between responses\nand documents, such as saliency scores and hidden state similarity. However,\nthese approaches suffer from either high computational complexity or\ncoarse-grained representations. Additionally, a common problem shared by the\nprevious works is their reliance on decoder-only Transformers, limiting their\nability to incorporate contextual information after the target span. To address\nthe above problems, we propose two techniques applicable to all\nmodel-internals-based methods. First, we aggregate token-wise evidence through\nset union operations, preserving the granularity of representations. Second, we\nenhance the attributor by integrating dependency parsing to enrich the semantic\ncompleteness of target spans. For practical implementation, our approach\nemploys attention weights as the similarity metric. Experimental results\ndemonstrate that the proposed method consistently outperforms all prior works.", "published": "2024-12-16 03:12:13", "link": "http://arxiv.org/abs/2412.11404v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Biased or Flawed? Mitigating Stereotypes in Generative Language Models\n  by Addressing Task-Specific Flaws", "abstract": "Recent studies have shown that generative language models often reflect and\namplify societal biases in their outputs. However, these studies frequently\nconflate observed biases with other task-specific shortcomings, such as\ncomprehension failure. For example, when a model misinterprets a text and\nproduces a response that reinforces a stereotype, it becomes difficult to\ndetermine whether the issue arises from inherent bias or from a\nmisunderstanding of the given content. In this paper, we conduct a\nmulti-faceted evaluation that distinctly disentangles bias from flaws within\nthe reading comprehension task. We propose a targeted stereotype mitigation\nframework that implicitly mitigates observed stereotypes in generative models\nthrough instruction-tuning on general-purpose datasets. We reduce stereotypical\noutputs by over 60% across multiple dimensions -- including nationality, age,\ngender, disability, and physical appearance -- by addressing\ncomprehension-based failures, and without relying on explicit debiasing\ntechniques. We evaluate several state-of-the-art generative models to\ndemonstrate the effectiveness of our approach while maintaining the overall\nutility. Our findings highlight the need to critically disentangle the concept\nof `bias' from other types of errors to build more targeted and effective\nmitigation strategies. CONTENT WARNING: Some examples contain offensive\nstereotypes.", "published": "2024-12-16 03:29:08", "link": "http://arxiv.org/abs/2412.11414v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Optimized Quran Passage Retrieval Using an Expanded QA Dataset and\n  Fine-Tuned Language Models", "abstract": "Understanding the deep meanings of the Qur'an and bridging the language gap\nbetween modern standard Arabic and classical Arabic is essential to improve the\nquestion-and-answer system for the Holy Qur'an. The Qur'an QA 2023 shared task\ndataset had a limited number of questions with weak model retrieval. To address\nthis challenge, this work updated the original dataset and improved the model\naccuracy. The original dataset, which contains 251 questions, was reviewed and\nexpanded to 629 questions with question diversification and reformulation,\nleading to a comprehensive set of 1895 categorized into single-answer,\nmulti-answer, and zero-answer types. Extensive experiments fine-tuned\ntransformer models, including AraBERT, RoBERTa, CAMeLBERT, AraELECTRA, and\nBERT. The best model, AraBERT-base, achieved a MAP@10 of 0.36 and MRR of 0.59,\nrepresenting improvements of 63% and 59%, respectively, compared to the\nbaseline scores (MAP@10: 0.22, MRR: 0.37). Additionally, the dataset expansion\nled to improvements in handling \"no answer\" cases, with the proposed approach\nachieving a 75% success rate for such instances, compared to the baseline's\n25%. These results demonstrate the effect of dataset improvement and model\narchitecture optimization in increasing the performance of QA systems for the\nHoly Qur'an, with higher accuracy, recall, and precision.", "published": "2024-12-16 04:03:58", "link": "http://arxiv.org/abs/2412.11431v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "ACE-$M^3$: Automatic Capability Evaluator for Multimodal Medical Models", "abstract": "As multimodal large language models (MLLMs) gain prominence in the medical\nfield, the need for precise evaluation methods to assess their effectiveness\nhas become critical. While benchmarks provide a reliable means to evaluate the\ncapabilities of MLLMs, traditional metrics like ROUGE and BLEU employed for\nopen domain evaluation only focus on token overlap and may not align with human\njudgment. Although human evaluation is more reliable, it is labor-intensive,\ncostly, and not scalable. LLM-based evaluation methods have proven promising,\nbut to date, there is still an urgent need for open-source multimodal LLM-based\nevaluators in the medical field. To address this issue, we introduce ACE-$M^3$,\nan open-sourced \\textbf{A}utomatic \\textbf{C}apability \\textbf{E}valuator for\n\\textbf{M}ultimodal \\textbf{M}edical \\textbf{M}odels specifically designed to\nassess the question answering abilities of medical MLLMs. It first utilizes a\nbranch-merge architecture to provide both detailed analysis and a concise final\nscore based on standard medical evaluation criteria. Subsequently, a reward\ntoken-based direct preference optimization (RTDPO) strategy is incorporated to\nsave training time without compromising performance of our model. Extensive\nexperiments have demonstrated the effectiveness of our ACE-$M^3$\nmodel\\footnote{\\url{https://huggingface.co/collections/AIUSRTMP/ace-m3-67593297ff391b93e3e5d068}}\nin evaluating the capabilities of medical MLLMs.", "published": "2024-12-16 05:15:43", "link": "http://arxiv.org/abs/2412.11453v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Better Multi-task Learning: A Framework for Optimizing Dataset\n  Combinations in Large Language Models", "abstract": "To efficiently select optimal dataset combinations for enhancing multi-task\nlearning (MTL) performance in large language models, we proposed a novel\nframework that leverages a neural network to predict the best dataset\ncombinations. The framework iteratively refines the selection, greatly\nimproving efficiency, while being model-, dataset-, and domain-independent.\nThrough experiments on 12 biomedical datasets across four tasks - named entity\nrecognition, relation extraction, event extraction, and text classification-we\ndemonstrate that our approach effectively identifies better combinations, even\nfor tasks that may seem unpromising from a human perspective. This verifies\nthat our framework provides a promising solution for maximizing MTL potential.", "published": "2024-12-16 05:20:18", "link": "http://arxiv.org/abs/2412.11455v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Understanding Knowledge Hijack Mechanism in In-context Learning through\n  Associative Memory", "abstract": "In-context learning (ICL) enables large language models (LLMs) to adapt to\nnew tasks without fine-tuning by leveraging contextual information provided\nwithin a prompt. However, ICL relies not only on contextual clues but also on\nthe global knowledge acquired during pretraining for the next token prediction.\nAnalyzing this process has been challenging due to the complex computational\ncircuitry of LLMs. This paper investigates the balance between in-context\ninformation and pretrained bigram knowledge in token prediction, focusing on\nthe induction head mechanism, a key component in ICL. Leveraging the fact that\na two-layer transformer can implement the induction head mechanism with\nassociative memories, we theoretically analyze the logits when a two-layer\ntransformer is given prompts generated by a bigram model. In the experiments,\nwe design specific prompts to evaluate whether the outputs of a two-layer\ntransformer align with the theoretical results.", "published": "2024-12-16 05:33:05", "link": "http://arxiv.org/abs/2412.11459v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NoteContrast: Contrastive Language-Diagnostic Pretraining for Medical\n  Text", "abstract": "Accurate diagnostic coding of medical notes is crucial for enhancing patient\ncare, medical research, and error-free billing in healthcare organizations.\nManual coding is a time-consuming task for providers, and diagnostic codes\noften exhibit low sensitivity and specificity, whereas the free text in medical\nnotes can be a more precise description of a patients status. Thus, accurate\nautomated diagnostic coding of medical notes has become critical for a learning\nhealthcare system. Recent developments in long-document transformer\narchitectures have enabled attention-based deep-learning models to adjudicate\nmedical notes. In addition, contrastive loss functions have been used to\njointly pre-train large language and image models with noisy labels. To further\nimprove the automated adjudication of medical notes, we developed an approach\nbased on i) models for ICD-10 diagnostic code sequences using a large\nreal-world data set, ii) large language models for medical notes, and iii)\ncontrastive pre-training to build an integrated model of both ICD-10 diagnostic\ncodes and corresponding medical text. We demonstrate that a contrastive\napproach for pre-training improves performance over prior state-of-the-art\nmodels for the MIMIC-III-50, MIMIC-III-rare50, and MIMIC-III-full diagnostic\ncoding tasks.", "published": "2024-12-16 06:44:39", "link": "http://arxiv.org/abs/2412.11477v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Intention Knowledge Graph Construction for User Intention Relation\n  Modeling", "abstract": "Understanding user intentions is challenging for online platforms. Recent\nwork on intention knowledge graphs addresses this but often lacks focus on\nconnecting intentions, which is crucial for modeling user behavior and\npredicting future actions. This paper introduces a framework to automatically\ngenerate an intention knowledge graph, capturing connections between user\nintentions. Using the Amazon m2 dataset, we construct an intention graph with\n351 million edges, demonstrating high plausibility and acceptance. Our model\neffectively predicts new session intentions and enhances product\nrecommendations, outperforming previous state-of-the-art methods and showcasing\nthe approach's practical utility.", "published": "2024-12-16 07:18:40", "link": "http://arxiv.org/abs/2412.11500v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Glimpse: Enabling White-Box Methods to Use Proprietary Models for\n  Zero-Shot LLM-Generated Text Detection", "abstract": "Advanced large language models (LLMs) can generate text almost\nindistinguishable from human-written text, highlighting the importance of\nLLM-generated text detection. However, current zero-shot techniques face\nchallenges as white-box methods are restricted to use weaker open-source LLMs,\nand black-box methods are limited by partial observation from stronger\nproprietary LLMs. It seems impossible to enable white-box methods to use\nproprietary models because API-level access to the models neither provides full\npredictive distributions nor inner embeddings. To traverse the divide, we\npropose **Glimpse**, a probability distribution estimation approach, predicting\nthe full distributions from partial observations. Despite the simplicity of\nGlimpse, we successfully extend white-box methods like Entropy, Rank, Log-Rank,\nand Fast-DetectGPT to latest proprietary models. Experiments show that Glimpse\nwith Fast-DetectGPT and GPT-3.5 achieves an average AUROC of about 0.95 in five\nlatest source models, improving the score by 51% relative to the remaining\nspace of the open source baseline. It demonstrates that the latest LLMs can\neffectively detect their own outputs, suggesting that advanced LLMs may be the\nbest shield against themselves. We release our code and data at\nhttps://github.com/baoguangsheng/glimpse.", "published": "2024-12-16 07:28:36", "link": "http://arxiv.org/abs/2412.11506v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DART: An AIGT Detector using AMR of Rephrased Text", "abstract": "As large language models (LLMs) generate more human-like texts, concerns\nabout the side effects of AI-generated texts (AIGT) have grown. So, researchers\nhave developed methods for detecting AIGT. However, two challenges remain.\nFirst, the performance of detecting black-box LLMs is low because existing\nmodels focus on probabilistic features. Second, most AIGT detectors have been\ntested on a single-candidate setting, which assumes that we know the origin of\nan AIGT and which may deviate from the real-world scenario. To resolve these\nchallenges, we propose DART, which consists of four steps: rephrasing, semantic\nparsing, scoring, and multiclass classification. We conducted three experiments\nto test the performance of DART. The experimental result shows that DART can\ndiscriminate multiple black-box LLMs without probabilistic features and the\norigin of AIGT.", "published": "2024-12-16 07:51:09", "link": "http://arxiv.org/abs/2412.11517v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Token Prepending: A Training-Free Approach for Eliciting Better Sentence\n  Embeddings from LLMs", "abstract": "Extracting sentence embeddings from large language models (LLMs) is a\npromising direction, as LLMs have demonstrated stronger semantic understanding\ncapabilities. Previous studies typically focus on prompt engineering to elicit\nsentence embeddings from LLMs by prompting the model to encode sentence\ninformation into the embedding of the last token. However, LLMs are mostly\ndecoder-only models with causal attention and the earlier tokens in the\nsentence cannot attend to the latter tokens, resulting in biased encoding of\nsentence information and cascading effects on the final decoded token. To this\nend, we propose a novel Token Prepending (TP) technique that prepends each\nlayer's decoded sentence embedding to the beginning of the sentence in the next\nlayer's input, allowing earlier tokens to attend to the complete sentence\ninformation under the causal attention mechanism. The proposed TP technique is\na plug-and-play and training-free technique, which means it can be seamlessly\nintegrated with various prompt-based sentence embedding methods and\nautoregressive LLMs. Extensive experiments on various Semantic Textual\nSimilarity (STS) tasks and downstream classification tasks demonstrate that our\nproposed TP technique can significantly improve the performance of existing\nprompt-based sentence embedding methods across different LLMs, while incurring\nnegligible additional inference cost.", "published": "2024-12-16 08:42:00", "link": "http://arxiv.org/abs/2412.11556v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning\n  for Text Representation", "abstract": "Text representation learning is significant as the cornerstone of natural\nlanguage processing. In recent years, graph contrastive learning (GCL) has been\nwidely used in text representation learning due to its ability to represent and\ncapture complex text information in a self-supervised setting. However, current\nmainstream graph contrastive learning methods often require the incorporation\nof domain knowledge or cumbersome computations to guide the data augmentation\nprocess, which significantly limits the application efficiency and scope of\nGCL. Additionally, many methods learn text representations only by constructing\nword-document relationships, which overlooks the rich contextual semantic\ninformation in the text. To address these issues and exploit representative\ntextual semantics, we present an event-based, simple, and effective graph\ncontrastive learning (SE-GCL) for text representation. Precisely, we extract\nevent blocks from text and construct internal relation graphs to represent\ninter-semantic interconnections, which can ensure that the most critical\nsemantic information is preserved. Then, we devise a streamlined, unsupervised\ngraph contrastive learning framework to leverage the complementary nature of\nthe event semantic and structural information for intricate feature data\ncapture. In particular, we introduce the concept of an event skeleton for core\nrepresentation semantics and simplify the typically complex data augmentation\ntechniques found in existing graph contrastive learning to boost algorithmic\nefficiency. We employ multiple loss functions to prompt diverse embeddings to\nconverge or diverge within a confined distance in the vector space, ultimately\nachieving a harmonious equilibrium. We conducted experiments on the proposed\nSE-GCL on four standard data sets (AG News, 20NG, SougouNews, and THUCNews) to\nverify its effectiveness in text representation learning.", "published": "2024-12-16 10:53:24", "link": "http://arxiv.org/abs/2412.11652v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "C3oT: Generating Shorter Chain-of-Thought without Compromising\n  Effectiveness", "abstract": "Generating Chain-of-Thought (CoT) before deriving the answer can effectively\nimprove the reasoning capabilities of large language models (LLMs) and\nsignificantly improve the accuracy of the generated answer. However, in most\ncases, the length of the generated CoT is much longer than the desired final\nanswer, which results in additional decoding costs. Furthermore, existing\nresearch has discovered that shortening the reasoning steps in CoT, even while\npreserving the key information, diminishes LLMs' abilities. These phenomena\nmake it difficult to use LLMs and CoT in many real-world applications that only\nrequire the final answer and are sensitive to latency, such as search and\nrecommendation. To reduce the costs of model decoding and shorten the length of\nthe generated CoT, this paper presents $\\textbf{C}$onditioned\n$\\textbf{C}$ompressed $\\textbf{C}$hain-of-$\\textbf{T}$hought (C3oT), a CoT\ncompression framework that involves a compressor to compress an original longer\nCoT into a shorter CoT while maintaining key information and interpretability,\na conditioned training method to train LLMs with both longer CoT and shorter\nCoT simultaneously to learn the corresponding relationships between them, and a\nconditioned inference method to gain the reasoning ability learned from longer\nCoT by generating shorter CoT. We conduct experiments over four datasets from\narithmetic and commonsense scenarios, showing that the proposed method is\ncapable of compressing the length of generated CoT by up to more than 50%\nwithout compromising its effectiveness.", "published": "2024-12-16 11:12:45", "link": "http://arxiv.org/abs/2412.11664v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BioBridge: Unified Bio-Embedding with Bridging Modality in Code-Switched\n  EMR", "abstract": "Pediatric Emergency Department (PED) overcrowding presents a significant\nglobal challenge, prompting the need for efficient solutions. This paper\nintroduces the BioBridge framework, a novel approach that applies Natural\nLanguage Processing (NLP) to Electronic Medical Records (EMRs) in written\nfree-text form to enhance decision-making in PED. In non-English speaking\ncountries, such as South Korea, EMR data is often written in a Code-Switching\n(CS) format that mixes the native language with English, with most\ncode-switched English words having clinical significance. The BioBridge\nframework consists of two core modules: \"bridging modality in context\" and\n\"unified bio-embedding.\" The \"bridging modality in context\" module improves the\ncontextual understanding of bilingual and code-switched EMRs. In the \"unified\nbio-embedding\" module, the knowledge of the model trained in the medical domain\nis injected into the encoder-based model to bridge the gap between the medical\nand general domains. Experimental results demonstrate that the proposed\nBioBridge significantly performance traditional machine learning and\npre-trained encoder-based models on several metrics, including F1 score, area\nunder the receiver operating characteristic curve (AUROC), area under the\nprecision-recall curve (AUPRC), and Brier score. Specifically, BioBridge-XLM\nachieved enhancements of 0.85% in F1 score, 0.75% in AUROC, and 0.76% in AUPRC,\nalong with a notable 3.04% decrease in the Brier score, demonstrating marked\nimprovements in accuracy, reliability, and prediction calibration over the\nbaseline XLM model. The source code will be made publicly available.", "published": "2024-12-16 11:24:54", "link": "http://arxiv.org/abs/2412.11671v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Bias Vector: Mitigating Biases in Language Models with Task Arithmetic\n  Approach", "abstract": "The use of language models (LMs) has increased considerably in recent years,\nand the biases and stereotypes in training data that are reflected in the LM\noutputs are causing social problems. In this paper, inspired by the task\narithmetic, we propose the ``Bias Vector'' method for the mitigation of these\nLM biases. The Bias Vector method does not require manually created debiasing\ndata. The three main steps of our approach involve: (1) continual training the\npre-trained LMs on biased data using masked language modeling; (2) constructing\nthe Bias Vector as the difference between the weights of the biased LMs and\nthose of pre-trained LMs; and (3) subtracting the Bias Vector from the weights\nof the pre-trained LMs for debiasing. We evaluated the Bias Vector method on\nthe SEAT across three LMs and confirmed an average improvement of 0.177 points.\nWe demonstrated that the Bias Vector method does not degrade the LM performance\non downstream tasks in the GLUE benchmark. In addition, we examined the impact\nof scaling factors, which control the magnitudes of Bias Vectors, with effect\nsizes on the SEAT and conducted a comprehensive evaluation of our debiased LMs\nacross both the SEAT and GLUE benchmarks.", "published": "2024-12-16 11:38:23", "link": "http://arxiv.org/abs/2412.11679v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multilingual and Explainable Text Detoxification with Parallel Corpora", "abstract": "Even with various regulations in place across countries and social media\nplatforms (Government of India, 2021; European Parliament and Council of the\nEuropean Union, 2022, digital abusive speech remains a significant issue. One\npotential approach to address this challenge is automatic text detoxification,\na text style transfer (TST) approach that transforms toxic language into a more\nneutral or non-toxic form. To date, the availability of parallel corpora for\nthe text detoxification task (Logachevavet al., 2022; Atwell et al., 2022;\nDementievavet al., 2024a) has proven to be crucial for state-of-the-art\napproaches. With this work, we extend parallel text detoxification corpus to\nnew languages -- German, Chinese, Arabic, Hindi, and Amharic -- testing in the\nextensive multilingual setup TST baselines. Next, we conduct the first of its\nkind an automated, explainable analysis of the descriptive features of both\ntoxic and non-toxic sentences, diving deeply into the nuances, similarities,\nand differences of toxicity and detoxification across 9 languages. Finally,\nbased on the obtained insights, we experiment with a novel text detoxification\nmethod inspired by the Chain-of-Thoughts reasoning approach, enhancing the\nprompting process through clustering on relevant descriptive attributes.", "published": "2024-12-16 12:08:59", "link": "http://arxiv.org/abs/2412.11691v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Vocabulary Expansion of Chat Models with Unlabeled Target Language Data", "abstract": "Chat models (i.e. language models trained to follow instructions through\nconversation with humans) outperform base models (i.e. trained solely on\nunlabeled data) in both conversation and general task-solving abilities. These\nmodels are generally English-centric and require further adaptation for\nlanguages that are underrepresented in or absent from their training data. A\ncommon technique for adapting base models is to extend the model's vocabulary\nwith target language tokens, i.e. vocabulary expansion (VE), and then\ncontinually pre-train it on language-specific data. Using chat data is ideal\nfor chat model adaptation, but often, either this does not exist or is costly\nto construct. Alternatively, adapting chat models with unlabeled data is a\npossible solution, but it could result in catastrophic forgetting. In this\npaper, we investigate the impact of using unlabeled target language data for VE\non chat models for the first time. We first show that off-the-shelf VE\ngenerally performs well across target language tasks and models in 71% of\ncases, though it underperforms in scenarios where source chat models are\nalready strong. To further improve adapted models, we propose post-hoc\ntechniques that inject information from the source model without requiring any\nfurther training. Experiments reveal the effectiveness of our methods, helping\nthe adapted models to achieve performance improvements in 87% of cases.", "published": "2024-12-16 12:26:28", "link": "http://arxiv.org/abs/2412.11704v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Seeker: Towards Exception Safety Code Generation with Intermediate\n  Language Agents Framework", "abstract": "In real world software development, improper or missing exception handling\ncan severely impact the robustness and reliability of code. Exception handling\nmechanisms require developers to detect, capture, and manage exceptions\naccording to high standards, but many developers struggle with these tasks,\nleading to fragile code. This problem is particularly evident in open-source\nprojects and impacts the overall quality of the software ecosystem. To address\nthis challenge, we explore the use of large language models (LLMs) to improve\nexception handling in code. Through extensive analysis, we identify three key\nissues: Insensitive Detection of Fragile Code, Inaccurate Capture of Exception\nBlock, and Distorted Handling Solution. These problems are widespread across\nreal world repositories, suggesting that robust exception handling practices\nare often overlooked or mishandled. In response, we propose Seeker, a\nmulti-agent framework inspired by expert developer strategies for exception\nhandling. Seeker uses agents: Scanner, Detector, Predator, Ranker, and Handler\nto assist LLMs in detecting, capturing, and resolving exceptions more\neffectively. Our work is the first systematic study on leveraging LLMs to\nenhance exception handling practices in real development scenarios, providing\nvaluable insights for future improvements in code reliability.", "published": "2024-12-16 12:35:29", "link": "http://arxiv.org/abs/2412.11713v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "A Benchmark and Robustness Study of In-Context-Learning with Large\n  Language Models in Music Entity Detection", "abstract": "Detecting music entities such as song titles or artist names is a useful\napplication to help use cases like processing music search queries or analyzing\nmusic consumption on the web. Recent approaches incorporate smaller language\nmodels (SLMs) like BERT and achieve high results. However, further research\nindicates a high influence of entity exposure during pre-training on the\nperformance of the models. With the advent of large language models (LLMs),\nthese outperform SLMs in a variety of downstream tasks. However, researchers\nare still divided if this is applicable to tasks like entity detection in texts\ndue to issues like hallucination. In this paper, we provide a novel dataset of\nuser-generated metadata and conduct a benchmark and a robustness study using\nrecent LLMs with in-context-learning (ICL). Our results indicate that LLMs in\nthe ICL setting yield higher performance than SLMs. We further uncover the\nlarge impact of entity exposure on the best performing LLM in our study.", "published": "2024-12-16 15:11:03", "link": "http://arxiv.org/abs/2412.11851v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "GeoX: Geometric Problem Solving Through Unified Formalized\n  Vision-Language Pre-training", "abstract": "Despite their proficiency in general tasks, Multi-modal Large Language Models\n(MLLMs) struggle with automatic Geometry Problem Solving (GPS), which demands\nunderstanding diagrams, interpreting symbols, and performing complex reasoning.\nThis limitation arises from their pre-training on natural images and texts,\nalong with the lack of automated verification in the problem-solving process.\nBesides, current geometric specialists are limited by their task-specific\ndesigns, making them less effective for broader geometric problems. To this\nend, we present GeoX, a multi-modal large model focusing on geometric\nunderstanding and reasoning tasks. Given the significant differences between\ngeometric diagram-symbol and natural image-text, we introduce unimodal\npre-training to develop a diagram encoder and symbol decoder, enhancing the\nunderstanding of geometric images and corpora. Furthermore, we introduce\ngeometry-language alignment, an effective pre-training paradigm that bridges\nthe modality gap between unimodal geometric experts. We propose a\nGenerator-And-Sampler Transformer (GS-Former) to generate discriminative\nqueries and eliminate uninformative representations from unevenly distributed\ngeometric signals. Finally, GeoX benefits from visual instruction tuning,\nempowering it to take geometric images and questions as input and generate\nverifiable solutions. Experiments show that GeoX outperforms both generalists\nand geometric specialists on publicly recognized benchmarks, such as GeoQA,\nUniGeo, Geometry3K, and PGPS9k.", "published": "2024-12-16 15:20:03", "link": "http://arxiv.org/abs/2412.11863v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "PICLe: Pseudo-Annotations for In-Context Learning in Low-Resource Named\n  Entity Detection", "abstract": "In-context learning (ICL) enables Large Language Models (LLMs) to perform\ntasks using few demonstrations, facilitating task adaptation when labeled\nexamples are hard to obtain. However, ICL is sensitive to the choice of\ndemonstrations, and it remains unclear which demonstration attributes enable\nin-context generalization. In this work, we conduct a perturbation study of\nin-context demonstrations for low-resource Named Entity Detection (NED). Our\nsurprising finding is that in-context demonstrations with partially correct\nannotated entity mentions can be as effective for task transfer as fully\ncorrect demonstrations. Based off our findings, we propose Pseudo-annotated\nIn-Context Learning (PICLe), a framework for in-context learning with noisy,\npseudo-annotated demonstrations. PICLe leverages LLMs to annotate many\ndemonstrations in a zero-shot first pass. We then cluster these synthetic\ndemonstrations, sample specific sets of in-context demonstrations from each\ncluster, and predict entity mentions using each set independently. Finally, we\nuse self-verification to select the final set of entity mentions. We evaluate\nPICLe on five biomedical NED datasets and show that, with zero human\nannotation, PICLe outperforms ICL in low-resource settings where limited gold\nexamples can be used as in-context demonstrations.", "published": "2024-12-16 16:09:35", "link": "http://arxiv.org/abs/2412.11923v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Explainable Procedural Mistake Detection", "abstract": "Automated task guidance has recently attracted attention from the AI research\ncommunity. Procedural mistake detection (PMD) is a challenging sub-problem of\nclassifying whether a human user (observed through egocentric video) has\nsuccessfully executed the task at hand (specified by a procedural text).\nDespite significant efforts in building resources and models for PMD, machine\nperformance remains nonviable, and the reasoning processes underlying this\nperformance are opaque. As such, we recast PMD to an explanatory self-dialog of\nquestions and answers, which serve as evidence for a decision. As this\nreformulation enables an unprecedented transparency, we leverage a fine-tuned\nnatural language inference (NLI) model to formulate two automated coherence\nmetrics for generated explanations. Our results show that while open-source\nVLMs struggle with this task off-the-shelf, their accuracy, coherence, and\ndialog efficiency can be vastly improved by incorporating these coherence\nmetrics into common inference and fine-tuning methods. Furthermore, our\nmulti-faceted metrics can visualize common outcomes at a glance, highlighting\nareas for improvement.", "published": "2024-12-16 16:13:55", "link": "http://arxiv.org/abs/2412.11927v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "SEAGraph: Unveiling the Whole Story of Paper Review Comments", "abstract": "Peer review, as a cornerstone of scientific research, ensures the integrity\nand quality of scholarly work by providing authors with objective feedback for\nrefinement. However, in the traditional peer review process, authors often\nreceive vague or insufficiently detailed feedback, which provides limited\nassistance and leads to a more time-consuming review cycle. If authors can\nidentify some specific weaknesses in their paper, they can not only address the\nreviewer's concerns but also improve their work. This raises the critical\nquestion of how to enhance authors' comprehension of review comments. In this\npaper, we present SEAGraph, a novel framework developed to clarify review\ncomments by uncovering the underlying intentions behind them. We construct two\ntypes of graphs for each paper: the semantic mind graph, which captures the\nauthor's thought process, and the hierarchical background graph, which\ndelineates the research domains related to the paper. A retrieval method is\nthen designed to extract relevant content from both graphs, facilitating\ncoherent explanations for the review comments. Extensive experiments show that\nSEAGraph excels in review comment understanding tasks, offering significant\nbenefits to authors.", "published": "2024-12-16 16:24:36", "link": "http://arxiv.org/abs/2412.11939v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "SciFaultyQA: Benchmarking LLMs on Faulty Science Question Detection with\n  a GAN-Inspired Approach to Synthetic Dataset Generation", "abstract": "Consider the problem: ``If one man and one woman can produce one child in one\nyear, how many children will be produced by one woman and three men in 0.5\nyears?\" Current large language models (LLMs) such as GPT-4o, GPT-o1-preview,\nand Gemini Flash frequently answer \"0.5,\" which does not make sense. While\nthese models sometimes acknowledge the unrealistic nature of the question, in\nmany cases (8 out of 10 trials), they provide the nonsensical answer of \"0.5\nchild.\" Additionally, temporal variation has been observed: if an LLM answers\ncorrectly once (by recognizing the faulty nature of the question), subsequent\nresponses are more likely to also reflect this understanding. However, this is\ninconsistent.\n  These types of questions have motivated us to develop a dataset of science\nquestions, SciFaultyQA, where the questions themselves are intentionally\nfaulty. We observed that LLMs often proceed to answer these flawed questions\nwithout recognizing their inherent issues, producing results that are logically\nor scientifically invalid. By analyzing such patterns, we developed a novel\nmethod for generating synthetic datasets to evaluate and benchmark the\nperformance of various LLMs in identifying these flawed questions. We have also\ndeveloped novel approaches to reduce the errors.", "published": "2024-12-16 17:11:48", "link": "http://arxiv.org/abs/2412.11988v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLM-RG4: Flexible and Factual Radiology Report Generation across Diverse\n  Input Contexts", "abstract": "Drafting radiology reports is a complex task requiring flexibility, where\nradiologists tail content to available information and particular clinical\ndemands. However, most current radiology report generation (RRG) models are\nconstrained to a fixed task paradigm, such as predicting the full ``finding''\nsection from a single image, inherently involving a mismatch between inputs and\noutputs. The trained models lack the flexibility for diverse inputs and could\ngenerate harmful, input-agnostic hallucinations. To bridge the gap between\ncurrent RRG models and the clinical demands in practice, we first develop a\ndata generation pipeline to create a new MIMIC-RG4 dataset, which considers\nfour common radiology report drafting scenarios and has perfectly corresponded\ninput and output. Secondly, we propose a novel large language model (LLM) based\nRRG framework, namely LLM-RG4, which utilizes LLM's flexible\ninstruction-following capabilities and extensive general knowledge. We further\ndevelop an adaptive token fusion module that offers flexibility to handle\ndiverse scenarios with different input combinations, while minimizing the\nadditional computational burden associated with increased input volumes.\nBesides, we propose a token-level loss weighting strategy to direct the model's\nattention towards positive and uncertain descriptions. Experimental results\ndemonstrate that LLM-RG4 achieves state-of-the-art performance in both clinical\nefficiency and natural language generation on the MIMIC-RG4 and MIMIC-CXR\ndatasets. We quantitatively demonstrate that our model has minimal\ninput-agnostic hallucinations, whereas current open-source models commonly\nsuffer from this problem.", "published": "2024-12-16 17:29:51", "link": "http://arxiv.org/abs/2412.12001v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "The Open Source Advantage in Large Language Models (LLMs)", "abstract": "Large language models (LLMs) have rapidly advanced natural language\nprocessing, driving significant breakthroughs in tasks such as text generation,\nmachine translation, and domain-specific reasoning. The field now faces a\ncritical dilemma in its approach: closed-source models like GPT-4 deliver\nstate-of-the-art performance but restrict reproducibility, accessibility, and\nexternal oversight, while open-source frameworks like LLaMA and Mixtral\ndemocratize access, foster collaboration, and support diverse applications,\nachieving competitive results through techniques like instruction tuning and\nLoRA. Hybrid approaches address challenges like bias mitigation and resource\naccessibility by combining the scalability of closed-source systems with the\ntransparency and inclusivity of open-source framework. However, in this\nposition paper, we argue that open-source remains the most robust path for\nadvancing LLM research and ethical deployment.", "published": "2024-12-16 17:32:11", "link": "http://arxiv.org/abs/2412.12004v2", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Semi-automated analysis of audio-recorded lessons: The case of teachers'\n  engaging messages", "abstract": "Engaging messages delivered by teachers are a key aspect of the classroom\ndiscourse that influences student outcomes. However, improving this\ncommunication is challenging due to difficulties in obtaining observations.\nThis study presents a methodology for efficiently extracting actual\nobservations of engaging messages from audio-recorded lessons. We collected\n2,477 audio-recorded lessons from 75 teachers over two academic years. Using\nautomatic transcription and keyword-based filtering analysis, we identified and\nclassified engaging messages. This method reduced the information to be\nanalysed by 90%, optimising the time and resources required compared to\ntraditional manual coding. Subsequent descriptive analysis revealed that the\nmost used messages emphasised the future benefits of participating in school\nactivities. In addition, the use of engaging messages decreased as the academic\nyear progressed. This study offers insights for researchers seeking to extract\ninformation from teachers' discourse in naturalistic settings and provides\nuseful information for designing interventions to improve teachers'\ncommunication strategies.", "published": "2024-12-16 18:35:58", "link": "http://arxiv.org/abs/2412.12062v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Krony-PT: GPT2 compressed with Kronecker Products", "abstract": "We introduce Krony-PT, a compression technique of GPT2\n\\citep{radford2019language} based on Kronecker Products. We specifically target\nthe MLP layers of each transformer layer, and systematically compress the feed\nforward layer matrices to various degrees. We introduce a modified Van Loan\ndecomposition to initialize the new factors, and also introduce a new\npruning-based initialization trick. Our method compresses the original 124M\nparameter GPT2 to various smaller models, with 80M being the smallest, and 96M\nbeing the largest compressed model. Our 81M model variant outperforms\ndistilgpt2 on next-token prediction on all standard language modeling datasets,\nand shows competitive scores or performs on par with other Kronecker Products\nbased compressed models of GPT2 that are significantly higher in size.", "published": "2024-12-16 20:44:01", "link": "http://arxiv.org/abs/2412.12351v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "BioRAGent: A Retrieval-Augmented Generation System for Showcasing\n  Generative Query Expansion and Domain-Specific Search for Scientific Q&A", "abstract": "We present BioRAGent, an interactive web-based retrieval-augmented generation\n(RAG) system for biomedical question answering. The system uses large language\nmodels (LLMs) for query expansion, snippet extraction, and answer generation\nwhile maintaining transparency through citation links to the source documents\nand displaying generated queries for further editing. Building on our\nsuccessful participation in the BioASQ 2024 challenge, we demonstrate how\nfew-shot learning with LLMs can be effectively applied for a professional\nsearch setting. The system supports both direct short paragraph style responses\nand responses with inline citations. Our demo is available online, and the\nsource code is publicly accessible through GitHub.", "published": "2024-12-16 21:09:28", "link": "http://arxiv.org/abs/2412.12358v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLaVA Steering: Visual Instruction Tuning with 500x Fewer Parameters\n  through Modality Linear Representation-Steering", "abstract": "Multimodal Large Language Models (MLLMs) have significantly advanced visual\ntasks by integrating visual representations into large language models (LLMs).\nThe textual modality, inherited from LLMs, equips MLLMs with abilities like\ninstruction following and in-context learning. In contrast, the visual modality\nenhances performance in downstream tasks by leveraging rich semantic content,\nspatial information, and grounding capabilities. These intrinsic modalities\nwork synergistically across various visual tasks. Our research initially\nreveals a persistent imbalance between these modalities, with text often\ndominating output generation during visual instruction tuning. This imbalance\noccurs when using both full fine-tuning and parameter-efficient fine-tuning\n(PEFT) methods. We then found that re-balancing these modalities can\nsignificantly reduce the number of trainable parameters required, inspiring a\ndirection for further optimizing visual instruction tuning. We introduce\nModality Linear Representation-Steering (MoReS) to achieve the goal. MoReS\neffectively re-balances the intrinsic modalities throughout the model, where\nthe key idea is to steer visual representations through linear transformations\nin the visual subspace across each model layer. To validate our solution, we\ncomposed LLaVA Steering, a suite of models integrated with the proposed MoReS\nmethod. Evaluation results show that the composed LLaVA Steering models\nrequire, on average, 500 times fewer trainable parameters than LoRA needs while\nstill achieving comparable performance across three visual benchmarks and eight\nvisual question-answering tasks. Last, we present the LLaVA Steering Factory,\nan in-house developed platform that enables researchers to quickly customize\nvarious MLLMs with component-based architecture for seamlessly integrating\nstate-of-the-art models, and evaluate their intrinsic modality imbalance.", "published": "2024-12-16 21:14:11", "link": "http://arxiv.org/abs/2412.12359v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "How Different AI Chatbots Behave? Benchmarking Large Language Models in\n  Behavioral Economics Games", "abstract": "The deployment of large language models (LLMs) in diverse applications\nrequires a thorough understanding of their decision-making strategies and\nbehavioral patterns. As a supplement to a recent study on the behavioral Turing\ntest, this paper presents a comprehensive analysis of five leading LLM-based\nchatbot families as they navigate a series of behavioral economics games. By\nbenchmarking these AI chatbots, we aim to uncover and document both common and\ndistinct behavioral patterns across a range of scenarios. The findings provide\nvaluable insights into the strategic preferences of each LLM, highlighting\npotential implications for their deployment in critical decision-making roles.", "published": "2024-12-16 21:25:45", "link": "http://arxiv.org/abs/2412.12362v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Interpretable LLM-based Table Question Answering", "abstract": "Interpretability for Table Question Answering (Table QA) is critical,\nparticularly in high-stakes industries like finance or healthcare. Although\nrecent approaches using Large Language Models (LLMs) have significantly\nimproved Table QA performance, their explanations for how the answers are\ngenerated are ambiguous. To fill this gap, we introduce Plan-of-SQLs (POS), an\ninterpretable Table QA approach designed to improve users' understanding of\nmodel decision-making. Through qualitative and quantitative evaluations with\nhuman and LLM judges, we show that: First, POS is the highest-quality\nexplanation method, helps human users understand model behaviors, and\nfacilitates model prediction verification. Second, when evaluated on popular\nand standard Table QA datasets (TabFact, WikiTQ, and FetaQA), POS achieves QA\naccuracy that is competitive with or superior to existing methods, while also\noffering greater efficiency-requiring significantly fewer LLM calls and table\ndatabase queries-and robust performance on large-sized tables. Finally, we\nobserve high agreement (up to 90%) between LLMs and human users when making\ndecisions based on the same explanations, suggesting that LLMs could serve as\nan effective proxy for humans in evaluating explanations. This finding enables\nfaster, more affordable evaluation of AI explanations-possibly accelerating\ntrustworthy AI research while maintaining reliable judgments on\ninterpretability.", "published": "2024-12-16 22:44:31", "link": "http://arxiv.org/abs/2412.12386v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Incremental Clustering Baseline for Event Detection on Twitter", "abstract": "Event detection in text streams is a crucial task for the analysis of online\nmedia and social networks. One of the current challenges in this field is\nestablishing a performance standard while maintaining an acceptable level of\ncomputational complexity. In our study, we use an incremental clustering\nalgorithm combined with recent advancements in sentence embeddings. Our\nobjective is to compare our findings with previous studies, specifically those\nby Cao et al. (2024) and Mazoyer et al. (2020). Our results demonstrate\nsignificant improvements and could serve as a relevant baseline for future\nresearch in this area.", "published": "2024-12-16 09:33:13", "link": "http://arxiv.org/abs/2412.15257v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "DisEmbed: Transforming Disease Understanding through Embeddings", "abstract": "The medical domain is vast and diverse, with many existing embedding models\nfocused on general healthcare applications. However, these models often\nstruggle to capture a deep understanding of diseases due to their broad\ngeneralization across the entire medical field. To address this gap, I present\nDisEmbed, a disease-focused embedding model. DisEmbed is trained on a synthetic\ndataset specifically curated to include disease descriptions, symptoms, and\ndisease-related Q\\&A pairs, making it uniquely suited for disease-related\ntasks. For evaluation, I benchmarked DisEmbed against existing medical models\nusing disease-specific datasets and the triplet evaluation method. My results\ndemonstrate that DisEmbed outperforms other models, particularly in identifying\ndisease-related contexts and distinguishing between similar diseases. This\nmakes DisEmbed highly valuable for disease-specific use cases, including\nretrieval-augmented generation (RAG) tasks, where its performance is\nparticularly robust.", "published": "2024-12-16 12:04:22", "link": "http://arxiv.org/abs/2412.15258v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GLARE: Google Apps Arabic Reviews Dataset", "abstract": "This paper introduces GLARE an Arabic Apps Reviews dataset collected from\nSaudi Google PlayStore. It consists of 76M reviews, 69M of which are Arabic\nreviews of 9,980 Android Applications. We present the data collection\nmethodology, along with a detailed Exploratory Data Analysis (EDA) and Feature\nEngineering on the gathered reviews. We also highlight possible use cases and\nbenefits of the dataset.", "published": "2024-12-16 14:31:20", "link": "http://arxiv.org/abs/2412.15259v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Why Does ChatGPT \"Delve\" So Much? Exploring the Sources of Lexical\n  Overrepresentation in Large Language Models", "abstract": "Scientific English is currently undergoing rapid change, with words like\n\"delve,\" \"intricate,\" and \"underscore\" appearing far more frequently than just\na few years ago. It is widely assumed that scientists' use of large language\nmodels (LLMs) is responsible for such trends. We develop a formal, transferable\nmethod to characterize these linguistic changes. Application of our method\nyields 21 focal words whose increased occurrence in scientific abstracts is\nlikely the result of LLM usage. We then pose \"the puzzle of lexical\noverrepresentation\": WHY are such words overused by LLMs? We fail to find\nevidence that lexical overrepresentation is caused by model architecture,\nalgorithm choices, or training data. To assess whether reinforcement learning\nfrom human feedback (RLHF) contributes to the overuse of focal words, we\nundertake comparative model testing and conduct an exploratory online study.\nWhile the model testing is consistent with RLHF playing a role, our\nexperimental results suggest that participants may be reacting differently to\n\"delve\" than to other focal words. With LLMs quickly becoming a driver of\nglobal language change, investigating these potential sources of lexical\noverrepresentation is important. We note that while insights into the workings\nof LLMs are within reach, a lack of transparency surrounding model development\nremains an obstacle to such research.", "published": "2024-12-16 02:27:59", "link": "http://arxiv.org/abs/2412.11385v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MERaLiON-SpeechEncoder: Towards a Speech Foundation Model for Singapore\n  and Beyond", "abstract": "This technical report describes the MERaLiON-SpeechEncoder, a foundation\nmodel designed to support a wide range of downstream speech applications.\nDeveloped as part of Singapore's National Multimodal Large Language Model\nProgramme, the MERaLiON-SpeechEncoder is tailored to address the speech\nprocessing needs in Singapore and the surrounding Southeast Asian region. The\nmodel currently supports mainly English, including the variety spoken in\nSingapore. We are actively expanding our datasets to gradually cover other\nlanguages in subsequent releases. The MERaLiON-SpeechEncoder was pre-trained\nfrom scratch on 200,000 hours of unlabelled speech data using a self-supervised\nlearning approach based on masked language modelling. We describe our training\nprocedure and hyperparameter tuning experiments in detail below. Our evaluation\ndemonstrates improvements to spontaneous and Singapore speech benchmarks for\nspeech recognition, while remaining competitive to other state-of-the-art\nspeech encoders across ten other speech tasks. We commit to releasing our\nmodel, supporting broader research endeavours, both in Singapore and beyond.", "published": "2024-12-16 08:15:19", "link": "http://arxiv.org/abs/2412.11538v2", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Error Diversity Matters: An Error-Resistant Ensemble Method for\n  Unsupervised Dependency Parsing", "abstract": "We address unsupervised dependency parsing by building an ensemble of diverse\nexisting models through post hoc aggregation of their output dependency parse\nstructures. We observe that these ensembles often suffer from low robustness\nagainst weak ensemble components due to error accumulation. To tackle this\nproblem, we propose an efficient ensemble-selection approach that considers\nerror diversity and avoids error accumulation. Results demonstrate that our\napproach outperforms each individual model as well as previous ensemble\ntechniques. Additionally, our experiments show that the proposed\nensemble-selection method significantly enhances the performance and robustness\nof our ensemble, surpassing previously proposed strategies, which have not\naccounted for error diversity.", "published": "2024-12-16 08:23:50", "link": "http://arxiv.org/abs/2412.11543v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SPaR: Self-Play with Tree-Search Refinement to Improve\n  Instruction-Following in Large Language Models", "abstract": "Instruction-following is a fundamental capability of language models,\nrequiring the model to recognize even the most subtle requirements in the\ninstructions and accurately reflect them in its output. Such an ability is\nwell-suited for and often optimized by preference learning. However, existing\nmethods often directly sample multiple independent responses from the model\nwhen creating preference pairs. Such practice can introduce content variations\nirrelevant to whether the instruction is precisely followed (e.g., different\nexpressions about the same semantic), interfering with the goal of teaching\nmodels to recognize the key differences that lead to improved instruction\nfollowing. In light of this, we introduce SPaR, a self-play framework\nintegrating tree-search self-refinement to yield valid and comparable\npreference pairs free from distractions. By playing against itself, an LLM\nemploys a tree-search strategy to refine its previous responses with respect to\nthe instruction while minimizing unnecessary variations. Our experiments show\nthat a LLaMA3-8B model, trained over three iterations guided by SPaR, surpasses\nGPT-4-Turbo on the IFEval benchmark without losing general capabilities.\nFurthermore, SPaR demonstrates promising scalability, greatly enhancing models\nlike GLM-4-9B and LLaMA3-70B. We also identify how inference scaling in tree\nsearch would impact model performance. Our code and data are publicly available\nat https://github.com/thu-coai/SPaR.", "published": "2024-12-16 09:47:43", "link": "http://arxiv.org/abs/2412.11605v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Specific-MLLMs to Omni-MLLMs: A Survey on MLLMs Aligned with\n  Multi-modalities", "abstract": "To tackle complex tasks in real-world scenarios, more researchers are\nfocusing on Omni-MLLMs, which aim to achieve omni-modal understanding and\ngeneration. Beyond the constraints of any specific non-linguistic modality,\nOmni-MLLMs map various non-linguistic modalities into the embedding space of\nLLMs and enable the interaction and understanding of arbitrary combinations of\nmodalities within a single model. In this paper, we systematically investigate\nrelevant research and provide a comprehensive survey of Omni-MLLMs.\nSpecifically, we first explain the four core components of Omni-MLLMs for\nunified multi-modal modeling with a meticulous taxonomy that offers novel\nperspectives. Then, we introduce the effective integration achieved through\ntwo-stage training and discuss the corresponding datasets as well as\nevaluation. Furthermore, we summarize the main challenges of current Omni-MLLMs\nand outline future directions. We hope this paper serves as an introduction for\nbeginners and promotes the advancement of related research. Resources have been\nmade publicly available at https://github.com/threegold116/Awesome-Omni-MLLMs.", "published": "2024-12-16 12:12:45", "link": "http://arxiv.org/abs/2412.11694v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "LLMs Can Simulate Standardized Patients via Agent Coevolution", "abstract": "Training medical personnel using standardized patients (SPs) remains a\ncomplex challenge, requiring extensive domain expertise and role-specific\npractice. Most research on Large Language Model (LLM)-based simulated patients\nfocuses on improving data retrieval accuracy or adjusting prompts through human\nfeedback. However, this focus has overlooked the critical need for patient\nagents to learn a standardized presentation pattern that transforms data into\nhuman-like patient responses through unsupervised simulations. To address this\ngap, we propose EvoPatient, a novel simulated patient framework in which a\npatient agent and doctor agents simulate the diagnostic process through\nmulti-turn dialogues, simultaneously gathering experience to improve the\nquality of both questions and answers, ultimately enabling human doctor\ntraining. Extensive experiments on various cases demonstrate that, by providing\nonly overall SP requirements, our framework improves over existing reasoning\nmethods by more than 10% in requirement alignment and better human preference,\nwhile achieving an optimal balance of resource consumption after evolving over\n200 cases for 10 hours, with excellent generalizability. The code will be\navailable at https://github.com/ZJUMAI/EvoPatient.", "published": "2024-12-16 12:36:47", "link": "http://arxiv.org/abs/2412.11716v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.MA"], "primary_category": "cs.CL"}
{"title": "A Method for Detecting Legal Article Competition for Korean Criminal Law\n  Using a Case-augmented Mention Graph", "abstract": "As social systems become increasingly complex, legal articles are also\ngrowing more intricate, making it progressively harder for humans to identify\nany potential competitions among them, particularly when drafting new laws or\napplying existing laws. Despite this challenge, no method for detecting such\ncompetitions has been proposed so far. In this paper, we propose a new legal AI\ntask called Legal Article Competition Detection (LACD), which aims to identify\ncompeting articles within a given law. Our novel retrieval method, CAM-Re2,\noutperforms existing relevant methods, reducing false positives by 20.8% and\nfalse negatives by 8.3%, while achieving a 98.2% improvement in precision@5,\nfor the LACD task. We release our codes at\nhttps://github.com/asmath472/LACD-public.", "published": "2024-12-16 13:59:10", "link": "http://arxiv.org/abs/2412.11787v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "ProsodyFM: Unsupervised Phrasing and Intonation Control for Intelligible\n  Speech Synthesis", "abstract": "Prosody contains rich information beyond the literal meaning of words, which\nis crucial for the intelligibility of speech. Current models still fall short\nin phrasing and intonation; they not only miss or misplace breaks when\nsynthesizing long sentences with complex structures but also produce unnatural\nintonation. We propose ProsodyFM, a prosody-aware text-to-speech synthesis\n(TTS) model with a flow-matching (FM) backbone that aims to enhance the\nphrasing and intonation aspects of prosody. ProsodyFM introduces two key\ncomponents: a Phrase Break Encoder to capture initial phrase break locations,\nfollowed by a Duration Predictor for the flexible adjustment of break\ndurations; and a Terminal Intonation Encoder which learns a bank of intonation\nshape tokens combined with a novel Pitch Processor for more robust modeling of\nhuman-perceived intonation change. ProsodyFM is trained with no explicit\nprosodic labels and yet can uncover a broad spectrum of break durations and\nintonation patterns. Experimental results demonstrate that ProsodyFM can\neffectively improve the phrasing and intonation aspects of prosody, thereby\nenhancing the overall intelligibility compared to four state-of-the-art (SOTA)\nmodels. Out-of-distribution experiments show that this prosody improvement can\nfurther bring ProsodyFM superior generalizability for unseen complex sentences\nand speakers. Our case study intuitively illustrates the powerful and\nfine-grained controllability of ProsodyFM over phrasing and intonation.", "published": "2024-12-16 14:07:39", "link": "http://arxiv.org/abs/2412.11795v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Wonderful Matrices: Combining for a More Efficient and Effective\n  Foundation Model Architecture", "abstract": "In order to make the foundation model more efficient and effective, our idea\nis combining sequence transformation and state transformation. First, we prove\nthe availability of rotary position embedding in the state space duality\nalgorithm, which reduces the perplexity of the hybrid quadratic causal\nself-attention and state space duality by more than 4%, to ensure that the\ncombining sequence transformation unifies position encoding. Second, we propose\ndynamic mask attention, which maintains 100% accuracy in the more challenging\nmulti-query associative recall task, improving by more than 150% compared to\nquadratic causal self-attention and state space duality, to ensure that the\ncombining sequence transformation selectively filters relevant information.\nThird, we design cross domain mixture of experts, which makes the computational\nspeed of expert retrieval with more than 1024 experts 8 to 10 times faster than\nthe mixture of experts, to ensure that the combining state transformation\nquickly retrieval mixture. Finally, we summarize these matrix algorithms that\ncan form the foundation model: Wonderful Matrices, which can be a competitor to\npopular model architectures.", "published": "2024-12-16 14:56:28", "link": "http://arxiv.org/abs/2412.11834v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Classification of Spontaneous and Scripted Speech for Multilingual Audio", "abstract": "Distinguishing scripted from spontaneous speech is an essential tool for\nbetter understanding how speech styles influence speech processing research. It\ncan also improve recommendation systems and discovery experiences for media\nusers through better segmentation of large recorded speech catalogues. This\npaper addresses the challenge of building a classifier that generalises well\nacross different formats and languages. We systematically evaluate models\nranging from traditional, handcrafted acoustic and prosodic features to\nadvanced audio transformers, utilising a large, multilingual proprietary\npodcast dataset for training and validation. We break down the performance of\neach model across 11 language groups to evaluate cross-lingual biases. Our\nexperimental analysis extends to publicly available datasets to assess the\nmodels' generalisability to non-podcast domains. Our results indicate that\ntransformer-based models consistently outperform traditional feature-based\ntechniques, achieving state-of-the-art performance in distinguishing between\nscripted and spontaneous speech across various languages.", "published": "2024-12-16 15:45:10", "link": "http://arxiv.org/abs/2412.11896v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "RetroLLM: Empowering Large Language Models to Retrieve Fine-grained\n  Evidence within Generation", "abstract": "Large language models (LLMs) exhibit remarkable generative capabilities but\noften suffer from hallucinations. Retrieval-augmented generation (RAG) offers\nan effective solution by incorporating external knowledge, but existing methods\nstill face several limitations: additional deployment costs of separate\nretrievers, redundant input tokens from retrieved text chunks, and the lack of\njoint optimization of retrieval and generation. To address these issues, we\npropose \\textbf{RetroLLM}, a unified framework that integrates retrieval and\ngeneration into a single, cohesive process, enabling LLMs to directly generate\nfine-grained evidence from the corpus with constrained decoding. Moreover, to\nmitigate false pruning in the process of constrained evidence generation, we\nintroduce (1) hierarchical FM-Index constraints, which generate\ncorpus-constrained clues to identify a subset of relevant documents before\nevidence generation, reducing irrelevant decoding space; and (2) a\nforward-looking constrained decoding strategy, which considers the relevance of\nfuture sequences to improve evidence accuracy. Extensive experiments on five\nopen-domain QA datasets demonstrate RetroLLM's superior performance across both\nin-domain and out-of-domain tasks. The code is available at\n\\url{https://github.com/sunnynexus/RetroLLM}.", "published": "2024-12-16 16:03:25", "link": "http://arxiv.org/abs/2412.11919v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Emma-X: An Embodied Multimodal Action Model with Grounded Chain of\n  Thought and Look-ahead Spatial Reasoning", "abstract": "Traditional reinforcement learning-based robotic control methods are often\ntask-specific and fail to generalize across diverse environments or unseen\nobjects and instructions. Visual Language Models (VLMs) demonstrate strong\nscene understanding and planning capabilities but lack the ability to generate\nactionable policies tailored to specific robotic embodiments. To address this,\nVisual-Language-Action (VLA) models have emerged, yet they face challenges in\nlong-horizon spatial reasoning and grounded task planning. In this work, we\npropose the Embodied Multimodal Action Model with Grounded Chain of Thought and\nLook-ahead Spatial Reasoning, Emma-X. Emma-X leverages our constructed\nhierarchical embodiment dataset based on BridgeV2, containing 60,000 robot\nmanipulation trajectories auto-annotated with grounded task reasoning and\nspatial guidance. Additionally, we introduce a trajectory segmentation strategy\nbased on gripper states and motion trajectories, which can help mitigate\nhallucination in grounding subtask reasoning generation. Experimental results\ndemonstrate that Emma-X achieves superior performance over competitive\nbaselines, particularly in real-world robotic tasks requiring spatial\nreasoning.", "published": "2024-12-16 16:58:28", "link": "http://arxiv.org/abs/2412.11974v2", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Speech Foundation Models and Crowdsourcing for Efficient, High-Quality\n  Data Collection", "abstract": "While crowdsourcing is an established solution for facilitating and scaling\nthe collection of speech data, the involvement of non-experts necessitates\nprotocols to ensure final data quality. To reduce the costs of these essential\ncontrols, this paper investigates the use of Speech Foundation Models (SFMs) to\nautomate the validation process, examining for the first time the cost/quality\ntrade-off in data acquisition. Experiments conducted on French, German, and\nKorean data demonstrate that SFM-based validation has the potential to reduce\nreliance on human validation, resulting in an estimated cost saving of over\n40.0% without degrading final data quality. These findings open new\nopportunities for more efficient, cost-effective, and scalable speech data\nacquisition.", "published": "2024-12-16 16:59:22", "link": "http://arxiv.org/abs/2412.11978v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SpeechPrune: Context-aware Token Pruning for Speech Information\n  Retrieval", "abstract": "We introduce Speech Information Retrieval (SIR), a new long-context task for\nSpeech Large Language Models (Speech LLMs), and present SPIRAL, a 1,012-sample\nbenchmark testing models' ability to extract critical details from\napproximately 90-second spoken inputs. While current Speech LLMs excel at\nshort-form tasks, they struggle with the computational and representational\ndemands of longer audio sequences. To address this limitation, we propose\nSpeechPrune, a training-free token pruning strategy that uses speech-text\nsimilarity and approximated attention scores to efficiently discard irrelevant\ntokens. In SPIRAL, SpeechPrune achieves accuracy improvements of 29% and up to\n47% over the original model and the random pruning model at a pruning rate of\n20%, respectively. SpeechPrune can maintain network performance even at a\npruning level of 80%. This approach highlights the potential of token-level\npruning for efficient and scalable long-form speech understanding.", "published": "2024-12-16 17:36:02", "link": "http://arxiv.org/abs/2412.12009v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Can LLM Prompting Serve as a Proxy for Static Analysis in Vulnerability\n  Detection", "abstract": "Despite their remarkable success, large language models (LLMs) have shown\nlimited ability on applied tasks such as vulnerability detection. We\ninvestigate various prompting strategies for vulnerability detection and, as\npart of this exploration, propose a prompting strategy that integrates natural\nlanguage descriptions of vulnerabilities with a contrastive chain-of-thought\nreasoning approach, augmented using contrastive samples from a synthetic\ndataset. Our study highlights the potential of LLMs to detect vulnerabilities\nby integrating natural language descriptions, contrastive reasoning, and\nsynthetic examples into a comprehensive prompting framework. Our results show\nthat this approach can enhance LLM understanding of vulnerabilities. On a\nhigh-quality vulnerability detection dataset such as SVEN, our prompting\nstrategies can improve accuracies, F1-scores, and pairwise accuracies by 23%,\n11%, and 14%, respectively.", "published": "2024-12-16 18:08:14", "link": "http://arxiv.org/abs/2412.12039v2", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.CR"}
{"title": "Virtual Agent-Based Communication Skills Training to Facilitate Health\n  Persuasion Among Peers", "abstract": "Many laypeople are motivated to improve the health behavior of their family\nor friends but do not know where to start, especially if the health behavior is\npotentially stigmatizing or controversial. We present an approach that uses\nvirtual agents to coach community-based volunteers in health counseling\ntechniques, such as motivational interviewing, and allows them to practice\nthese skills in role-playing scenarios. We use this approach in a virtual\nagent-based system to increase COVID-19 vaccination by empowering users to\ninfluence their social network. In a between-subjects comparative design study,\nwe test the effects of agent system interactivity and role-playing\nfunctionality on counseling outcomes, with participants evaluated by\nstandardized patients and objective judges. We find that all versions are\neffective at producing peer counselors who score adequately on a standardized\nmeasure of counseling competence, and that participants were significantly more\nsatisfied with interactive virtual agents compared to passive viewing of the\ntraining material. We discuss design implications for interpersonal skills\ntraining systems based on our findings.", "published": "2024-12-16 18:34:32", "link": "http://arxiv.org/abs/2412.12061v1", "categories": ["cs.HC", "cs.CL", "cs.CY"], "primary_category": "cs.HC"}
{"title": "SepLLM: Accelerate Large Language Models by Compressing One Segment into\n  One Separator", "abstract": "Large Language Models (LLMs) have exhibited exceptional performance across a\nspectrum of natural language processing tasks. However, their substantial sizes\npose considerable challenges, particularly in computational demands and\ninference speed, due to their quadratic complexity. In this work, we have\nidentified a key pattern: certain seemingly meaningless separator tokens (i.e.,\npunctuations) contribute disproportionately to attention scores compared to\nsemantically meaningful tokens. This observation suggests that information of\nthe segments between these separator tokens can be effectively condensed into\nthe separator tokens themselves without significant information loss. Guided by\nthis insight, we introduce SepLLM, a plug-and-play framework that accelerates\ninference by compressing these segments and eliminating redundant tokens.\nAdditionally, we implement efficient kernels for training acceleration.\nExperimental results across training-free, training-from-scratch, and\npost-training settings demonstrate SepLLM's effectiveness. Notably, using the\nLlama-3-8B backbone, SepLLM achieves over 50% reduction in KV cache on the\nGSM8K-CoT benchmark while maintaining comparable performance. Furthermore, in\nstreaming settings, SepLLM effectively processes sequences of up to 4 million\ntokens or more while maintaining consistent language modeling capabilities.", "published": "2024-12-16 18:58:57", "link": "http://arxiv.org/abs/2412.12094v5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DLF: Disentangled-Language-Focused Multimodal Sentiment Analysis", "abstract": "Multimodal Sentiment Analysis (MSA) leverages heterogeneous modalities, such\nas language, vision, and audio, to enhance the understanding of human\nsentiment. While existing models often focus on extracting shared information\nacross modalities or directly fusing heterogeneous modalities, such approaches\ncan introduce redundancy and conflicts due to equal treatment of all modalities\nand the mutual transfer of information between modality pairs. To address these\nissues, we propose a Disentangled-Language-Focused (DLF) multimodal\nrepresentation learning framework, which incorporates a feature disentanglement\nmodule to separate modality-shared and modality-specific information. To\nfurther reduce redundancy and enhance language-targeted features, four\ngeometric measures are introduced to refine the disentanglement process. A\nLanguage-Focused Attractor (LFA) is further developed to strengthen language\nrepresentation by leveraging complementary modality-specific information\nthrough a language-guided cross-attention mechanism. The framework also employs\nhierarchical predictions to improve overall accuracy. Extensive experiments on\ntwo popular MSA datasets, CMU-MOSI and CMU-MOSEI, demonstrate the significant\nperformance gains achieved by the proposed DLF framework. Comprehensive\nablation studies further validate the effectiveness of the feature\ndisentanglement module, language-focused attractor, and hierarchical\npredictions. Our code is available at https://github.com/pwang322/DLF.", "published": "2024-12-16 10:03:44", "link": "http://arxiv.org/abs/2412.12225v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.LG"}
{"title": "Emergence of Abstractions: Concept Encoding and Decoding Mechanism for\n  In-Context Learning in Transformers", "abstract": "Humans distill complex experiences into fundamental abstractions that enable\nrapid learning and adaptation. Similarly, autoregressive transformers exhibit\nadaptive learning through in-context learning (ICL), which begs the question of\nhow. In this paper, we propose concept encoding-decoding mechanism to explain\nICL by studying how transformers form and use internal abstractions in their\nrepresentations. On synthetic ICL tasks, we analyze the training dynamics of a\nsmall transformer and report the coupled emergence of concept encoding and\ndecoding. As the model learns to encode different latent concepts (e.g.,\n``Finding the first noun in a sentence.\") into distinct, separable\nrepresentations, it concureently builds conditional decoding algorithms and\nimprove its ICL performance. We validate the existence of this mechanism across\npretrained models of varying scales (Gemma-2 2B/9B/27B, Llama-3.1 8B/70B).\nFurther, through mechanistic interventions and controlled finetuning, we\ndemonstrate that the quality of concept encoding is causally related and\npredictive of ICL performance. Our empirical insights shed light into better\nunderstanding the success and failure modes of large language models via their\nrepresentations.", "published": "2024-12-16 19:00:18", "link": "http://arxiv.org/abs/2412.12276v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RAG Playground: A Framework for Systematic Evaluation of Retrieval\n  Strategies and Prompt Engineering in RAG Systems", "abstract": "We present RAG Playground, an open-source framework for systematic evaluation\nof Retrieval-Augmented Generation (RAG) systems. The framework implements and\ncompares three retrieval approaches: naive vector search, reranking, and hybrid\nvector-keyword search, combined with ReAct agents using different prompting\nstrategies. We introduce a comprehensive evaluation framework with novel\nmetrics and provide empirical results comparing different language models\n(Llama 3.1 and Qwen 2.5) across various retrieval configurations. Our\nexperiments demonstrate significant performance improvements through hybrid\nsearch methods and structured self-evaluation prompting, achieving up to 72.7%\npass rate on our multi-metric evaluation framework. The results also highlight\nthe importance of prompt engineering in RAG systems, with our custom-prompted\nagents showing consistent improvements in retrieval accuracy and response\nquality.", "published": "2024-12-16 19:40:26", "link": "http://arxiv.org/abs/2412.12322v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Efficient Scaling of Diffusion Transformers for Text-to-Image Generation", "abstract": "We empirically study the scaling properties of various Diffusion Transformers\n(DiTs) for text-to-image generation by performing extensive and rigorous\nablations, including training scaled DiTs ranging from 0.3B upto 8B parameters\non datasets up to 600M images. We find that U-ViT, a pure self-attention based\nDiT model provides a simpler design and scales more effectively in comparison\nwith cross-attention based DiT variants, which allows straightforward expansion\nfor extra conditions and other modalities. We identify a 2.3B U-ViT model can\nget better performance than SDXL UNet and other DiT variants in controlled\nsetting. On the data scaling side, we investigate how increasing dataset size\nand enhanced long caption improve the text-image alignment performance and the\nlearning efficiency.", "published": "2024-12-16 22:59:26", "link": "http://arxiv.org/abs/2412.12391v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Bridging the Gap: Enhancing LLM Performance for Low-Resource African\n  Languages with New Benchmarks, Fine-Tuning, and Cultural Adjustments", "abstract": "Large Language Models (LLMs) have shown remarkable performance across various\ntasks, yet significant disparities remain for non-English languages, and\nespecially native African languages. This paper addresses these disparities by\ncreating approximately 1 million human-translated words of new benchmark data\nin 8 low-resource African languages, covering a population of over 160 million\nspeakers of: Amharic, Bambara, Igbo, Sepedi (Northern Sotho), Shona, Sesotho\n(Southern Sotho), Setswana, and Tsonga. Our benchmarks are translations of\nWinogrande and three sections of MMLU: college medicine, clinical knowledge,\nand virology. Using the translated benchmarks, we report previously unknown\nperformance gaps between state-of-the-art (SOTA) LLMs in English and African\nlanguages. Finally, using results from over 400 fine-tuned models, we explore\nseveral methods to reduce the LLM performance gap, including high-quality\ndataset fine-tuning (using an LLM-as-an-Annotator), cross-lingual transfer, and\ncultural appropriateness adjustments. Key findings include average mono-lingual\nimprovements of 5.6% with fine-tuning (with 5.4% average mono-lingual\nimprovements when using high-quality data over low-quality data), 2.9% average\ngains from cross-lingual transfer, and a 3.0% out-of-the-box performance boost\non culturally appropriate questions. The publicly available benchmarks,\ntranslations, and code from this study support further research and development\naimed at creating more inclusive and effective language technologies.", "published": "2024-12-16 23:50:21", "link": "http://arxiv.org/abs/2412.12417v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Structured Extraction of Real World Medical Knowledge using LLMs for\n  Summarization and Search", "abstract": "Creation and curation of knowledge graphs can accelerate disease discovery\nand analysis in real-world data. While disease ontologies aid in biological\ndata annotation, codified categories (SNOMED-CT, ICD10, CPT) may not capture\npatient condition nuances or rare diseases. Multiple disease definitions across\ndata sources complicate ontology mapping and disease clustering. We propose\ncreating patient knowledge graphs using large language model extraction\ntechniques, allowing data extraction via natural language rather than rigid\nontological hierarchies. Our method maps to existing ontologies (MeSH,\nSNOMED-CT, RxNORM, HPO) to ground extracted entities.\n  Using a large ambulatory care EHR database with 33.6M patients, we\ndemonstrate our method through the patient search for Dravet syndrome, which\nreceived ICD10 recognition in October 2020. We describe our construction of\npatient-specific knowledge graphs and symptom-based patient searches. Using\nconfirmed Dravet syndrome ICD10 codes as ground truth, we employ LLM-based\nentity extraction to characterize patients in grounded ontologies. We then\napply this method to identify Beta-propeller protein-associated\nneurodegeneration (BPAN) patients, demonstrating real-world discovery where no\nground truth exists.", "published": "2024-12-16 02:57:00", "link": "http://arxiv.org/abs/2412.15256v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Analyzing Images of Legal Documents: Toward Multi-Modal LLMs for Access\n  to Justice", "abstract": "Interacting with the legal system and the government requires the assembly\nand analysis of various pieces of information that can be spread across\ndifferent (paper) documents, such as forms, certificates and contracts (e.g.\nleases). This information is required in order to understand one's legal\nrights, as well as to fill out forms to file claims in court or obtain\ngovernment benefits. However, finding the right information, locating the\ncorrect forms and filling them out can be challenging for laypeople. Large\nlanguage models (LLMs) have emerged as a powerful technology that has the\npotential to address this gap, but still rely on the user to provide the\ncorrect information, which may be challenging and error-prone if the\ninformation is only available in complex paper documents. We present an\ninvestigation into utilizing multi-modal LLMs to analyze images of handwritten\npaper forms, in order to automatically extract relevant information in a\nstructured format. Our initial results are promising, but reveal some\nlimitations (e.g., when the image quality is low). Our work demonstrates the\npotential of integrating multi-modal LLMs to support laypeople and\nself-represented litigants in finding and assembling relevant information.", "published": "2024-12-16 14:58:27", "link": "http://arxiv.org/abs/2412.15260v1", "categories": ["cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Advanced ingestion process powered by LLM parsing for RAG system", "abstract": "Retrieval Augmented Generation (RAG) systems struggle with processing\nmultimodal documents of varying structural complexity. This paper introduces a\nnovel multi-strategy parsing approach using LLM-powered OCR to extract content\nfrom diverse document types, including presentations and high text density\nfiles both scanned or not. The methodology employs a node-based extraction\ntechnique that creates relationships between different information types and\ngenerates context-aware metadata. By implementing a Multimodal Assembler Agent\nand a flexible embedding strategy, the system enhances document comprehension\nand retrieval capabilities. Experimental evaluations across multiple knowledge\nbases demonstrate the approach's effectiveness, showing improvements in answer\nrelevancy and information faithfulness.", "published": "2024-12-16 20:33:33", "link": "http://arxiv.org/abs/2412.15262v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "The Three Social Dimensions of Chatbot Technology", "abstract": "The development and deployment of chatbot technology, while spanning decades\nand employing different techniques, require innovative frameworks to understand\nand interrogate their functionality and implications. A mere technocentric\naccount of the evolution of chatbot technology does not fully illuminate how\nconversational systems are embedded in societal dynamics. This study presents a\nstructured examination of chatbots across three societal dimensions,\nhighlighting their roles as objects of scientific research, commercial\ninstruments, and agents of intimate interaction. Through furnishing a\ndimensional framework for the evolution of conversational systems, from\nlaboratories to marketplaces to private lives, this article contributes to the\nwider scholarly inquiry of chatbot technology and its impact in lived human\nexperiences and dynamics.", "published": "2024-12-16 13:45:53", "link": "http://arxiv.org/abs/2501.10377v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "I.2; J.4; K.4"], "primary_category": "cs.CY"}
{"title": "Whisper-GPT: A Hybrid Representation Audio Large Language Model", "abstract": "We propose WHISPER-GPT: A generative large language model (LLM) for speech\nand music that allows us to work with continuous audio representations and\ndiscrete tokens simultaneously as part of a single architecture. There has been\na huge surge in generative audio, speech, and music models that utilize\ndiscrete audio tokens derived from neural compression algorithms, e.g. ENCODEC.\nHowever, one of the major drawbacks of this approach is handling the context\nlength. It blows up for high-fidelity generative architecture if one has to\naccount for all the audio contents at various frequencies for the next token\nprediction. By combining continuous audio representation like the spectrogram\nand discrete acoustic tokens, we retain the best of both worlds: Have all the\ninformation needed from the audio at a specific time instance in a single\ntoken, yet allow LLM to predict the future token to allow for sampling and\nother benefits discrete space provides. We show how our architecture improves\nthe perplexity and negative log-likelihood scores for the next token prediction\ncompared to a token-based LLM for speech and music.", "published": "2024-12-16 05:03:48", "link": "http://arxiv.org/abs/2412.11449v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Next Token Prediction Towards Multimodal Intelligence: A Comprehensive\n  Survey", "abstract": "Building on the foundations of language modeling in natural language\nprocessing, Next Token Prediction (NTP) has evolved into a versatile training\nobjective for machine learning tasks across various modalities, achieving\nconsiderable success. As Large Language Models (LLMs) have advanced to unify\nunderstanding and generation tasks within the textual modality, recent research\nhas shown that tasks from different modalities can also be effectively\nencapsulated within the NTP framework, transforming the multimodal information\ninto tokens and predict the next one given the context. This survey introduces\na comprehensive taxonomy that unifies both understanding and generation within\nmultimodal learning through the lens of NTP. The proposed taxonomy covers five\nkey aspects: Multimodal tokenization, MMNTP model architectures, unified task\nrepresentation, datasets \\& evaluation, and open challenges. This new taxonomy\naims to aid researchers in their exploration of multimodal intelligence. An\nassociated GitHub repository collecting the latest papers and repos is\navailable at https://github.com/LMM101/Awesome-Multimodal-Next-Token-Prediction", "published": "2024-12-16 05:02:25", "link": "http://arxiv.org/abs/2412.18619v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A lightweight and robust method for blind wideband-to-fullband extension\n  of speech", "abstract": "Reducing the bandwidth of speech is common practice in resource constrained\nenvironments like low-bandwidth speech transmission or low-complexity vocoding.\nWe propose a lightweight and robust method for extending the bandwidth of\nwideband speech signals that is inspired by classical methods developed in the\nspeech coding context. The resulting model has just $\\sim 370$~K parameters and\na complexity of ~140 MFLOPS (or ~70 MMACS). With a frame size of 10 ms and a\nlookahead of just 0.27 ms the model is well-suited for common wideband speech\ncodecs. We evaluate the model's robustness by pairing it with the Opus SILK\nspeech codec (1.5 release) and verify in a P.808 DCR listening test that it\nsignificantly improves quality from 6 to 12 kb/s. We also demonstrate that Opus\n1.5 together with the proposed bandwidth extension at 9 kb/s meets the quality\nof 3GPP EVS at 9.6 kb/s and that of Opus 1.4 at 18 kb/s showing that the blind\nbandwidth extension can meet the quality of classical guided bandwidth\nextensions.", "published": "2024-12-16 02:38:32", "link": "http://arxiv.org/abs/2412.11392v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "AudioCIL: A Python Toolbox for Audio Class-Incremental Learning with\n  Multiple Scenes", "abstract": "Deep learning, with its robust aotomatic feature extraction capabilities, has\ndemonstrated significant success in audio signal processing. Typically, these\nmethods rely on static, pre-collected large-scale datasets for training,\nperforming well on a fixed number of classes. However, the real world is\ncharacterized by constant change, with new audio classes emerging from\nstreaming or temporary availability due to privacy. This dynamic nature of\naudio environments necessitates models that can incrementally learn new\nknowledge for new classes without discarding existing information. Introducing\nincremental learning to the field of audio signal processing, i.e., Audio\nClass-Incremental Learning (AuCIL), is a meaningful endeavor. We propose such a\ntoolbox named AudioCIL to align audio signal processing algorithms with\nreal-world scenarios and strengthen research in audio class-incremental\nlearning. Code is available at https://github.com/colaudiolab/AudioCIL.", "published": "2024-12-16 15:53:02", "link": "http://arxiv.org/abs/2412.11907v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SECodec: Structural Entropy-based Compressive Speech Representation\n  Codec for Speech Language Models", "abstract": "With the rapid advancement of large language models (LLMs), discrete speech\nrepresentations have become crucial for integrating speech into LLMs. Existing\nmethods for speech representation discretization rely on a predefined codebook\nsize and Euclidean distance-based quantization. However, 1) the size of\ncodebook is a critical parameter that affects both codec performance and\ndownstream task training efficiency. 2) The Euclidean distance-based\nquantization may lead to audio distortion when the size of the codebook is\ncontrolled within a reasonable range. In fact, in the field of information\ncompression, structural information and entropy guidance are crucial, but\nprevious methods have largely overlooked these factors. Therefore, we address\nthe above issues from an information-theoretic perspective, we present SECodec,\na novel speech representation codec based on structural entropy (SE) for\nbuilding speech language models. Specifically, we first model speech as a\ngraph, clustering the speech features nodes within the graph and extracting the\ncorresponding codebook by hierarchically and disentangledly minimizing 2D SE.\nThen, to address the issue of audio distortion, we propose a new quantization\nmethod. This method still adheres to the 2D SE minimization principle,\nadaptively selecting the most suitable token corresponding to the cluster for\neach incoming original speech node. Furthermore, we develop a Structural\nEntropy-based Speech Language Model (SESLM) that leverages SECodec.\nExperimental results demonstrate that SECodec performs comparably to EnCodec in\nspeech reconstruction, and SESLM surpasses VALL-E in zero-shot text-to-speech\ntasks. Code, demo speeches, speech feature graph, SE codebook, and models are\navailable at https://github.com/wlq2019/SECodec.", "published": "2024-12-16 03:33:05", "link": "http://arxiv.org/abs/2501.00018v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Region-Based Optimization in Continual Learning for Audio Deepfake\n  Detection", "abstract": "Rapid advancements in speech synthesis and voice conversion bring convenience\nbut also new security risks, creating an urgent need for effective audio\ndeepfake detection. Although current models perform well, their effectiveness\ndiminishes when confronted with the diverse and evolving nature of real-world\ndeepfakes. To address this issue, we propose a continual learning method named\nRegion-Based Optimization (RegO) for audio deepfake detection. Specifically, we\nuse the Fisher information matrix to measure important neuron regions for real\nand fake audio detection, dividing them into four regions. First, we directly\nfine-tune the less important regions to quickly adapt to new tasks. Next, we\napply gradient optimization in parallel for regions important only to real\naudio detection, and in orthogonal directions for regions important only to\nfake audio detection. For regions that are important to both, we use sample\nproportion-based adaptive gradient optimization. This region-adaptive\noptimization ensures an appropriate trade-off between memory stability and\nlearning plasticity. Additionally, to address the increase of redundant neurons\nfrom old tasks, we further introduce the Ebbinghaus forgetting mechanism to\nrelease them, thereby promoting the capability of the model to learn more\ngeneralized discriminative features. Experimental results show our method\nachieves a 21.3% improvement in EER over the state-of-the-art continual\nlearning approach RWM for audio deepfake detection. Moreover, the effectiveness\nof RegO extends beyond the audio deepfake detection domain, showing potential\nsignificance in other tasks, such as image recognition. The code is available\nat https://github.com/cyjie429/RegO", "published": "2024-12-16 08:34:09", "link": "http://arxiv.org/abs/2412.11551v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Discrepancy-Aware Attention Network for Enhanced Audio-Visual Zero-Shot\n  Learning", "abstract": "Audio-visual Zero-Shot Learning (ZSL) has attracted significant attention for\nits ability to identify unseen classes and perform well in video classification\ntasks. However, modal imbalance in (G)ZSL leads to over-reliance on the optimal\nmodality, reducing discriminative capabilities for unseen classes. Some studies\nhave attempted to address this issue by modifying parameter gradients, but two\nchallenges still remain: (a) Quality discrepancies, where modalities offer\ndiffering quantities and qualities of information for the same concept. (b)\nContent discrepancies, where sample contributions within a modality vary\nsignificantly. To address these challenges, we propose a Discrepancy-Aware\nAttention Network (DAAN) for Enhanced Audio-Visual ZSL. Our approach introduces\na Quality-Discrepancy Mitigation Attention (QDMA) unit to minimize redundant\ninformation in the high-quality modality and a Contrastive Sample-level\nGradient Modulation (CSGM) block to adjust gradient magnitudes and balance\ncontent discrepancies. We quantify modality contributions by integrating\noptimization and convergence rate for more precise gradient modulation in CSGM.\nExperiments demonstrates DAAN achieves state-of-the-art performance on\nbenchmark datasets, with ablation studies validating the effectiveness of\nindividual modules.", "published": "2024-12-16 12:35:56", "link": "http://arxiv.org/abs/2412.11715v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Does it Chug? Towards a Data-Driven Understanding of Guitar Tone\n  Description", "abstract": "Natural language is commonly used to describe instrument timbre, such as a\n\"warm\" or \"heavy\" sound. As these descriptors are based on human perception,\nthere can be disagreement over which acoustic features correspond to a given\nadjective. In this work, we pursue a data-driven approach to further our\nunderstanding of such adjectives in the context of guitar tone. Our main\ncontribution is a dataset of timbre adjectives, constructed by processing\nsingle clips of instrument audio to produce varied timbres through adjustments\nin EQ and effects such as distortion. Adjective annotations are obtained for\neach clip by crowdsourcing experts to complete a pairwise comparison and a\nlabeling task. We examine the dataset and reveal correlations between adjective\nratings and highlight instances where the data contradicts prevailing theories\non spectral features and timbral adjectives, suggesting a need for a more\nnuanced, data-driven understanding of timbre.", "published": "2024-12-16 13:44:19", "link": "http://arxiv.org/abs/2412.11769v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "autrainer: A Modular and Extensible Deep Learning Toolkit for Computer\n  Audition Tasks", "abstract": "This work introduces the key operating principles for autrainer, our new deep\nlearning training framework for computer audition tasks. autrainer is a\nPyTorch-based toolkit that allows for rapid, reproducible, and easily\nextensible training on a variety of different computer audition tasks.\nConcretely, autrainer offers low-code training and supports a wide range of\nneural networks as well as preprocessing routines. In this work, we present an\noverview of its inner workings and key capabilities.", "published": "2024-12-16 16:25:58", "link": "http://arxiv.org/abs/2412.11943v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sound Classification of Four Insect Classes", "abstract": "The goal of this project is to classify four different insect sounds: cicada,\nbeetle, termite, and cricket. One application of this project is for pest\ncontrol to monitor and protect our ecosystem. Our project leverages data\naugmentation, including pitch shifting and speed changing, to improve model\ngeneralization. This project will test the performance of Decision Tree, Random\nForest, SVM RBF, XGBoost, and k-NN models, combined with MFCC feature. A\npotential novelty of this project is that various data augmentation techniques\nare used and created 6 data along with the original sound. The dataset consists\nof the sound recordings of these four insects. This project aims to achieve a\nhigh classification accuracy and to reduce the over-fitting problem.", "published": "2024-12-16 23:03:28", "link": "http://arxiv.org/abs/2412.12395v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
