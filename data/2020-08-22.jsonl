{"title": "Applications of BERT Based Sequence Tagging Models on Chinese Medical\n  Text Attributes Extraction", "abstract": "We convert the Chinese medical text attributes extraction task into a\nsequence tagging or machine reading comprehension task. Based on BERT\npre-trained models, we have not only tried the widely used LSTM-CRF sequence\ntagging model, but also other sequence models, such as CNN, UCNN, WaveNet,\nSelfAttention, etc, which reaches similar performance as LSTM+CRF. This sheds a\nlight on the traditional sequence tagging models. Since the aspect of emphasis\nfor different sequence tagging models varies substantially, ensembling these\nmodels adds diversity to the final system. By doing so, our system achieves\ngood performance on the task of Chinese medical text attributes extraction\n(subtask 2 of CCKS 2019 task 1).", "published": "2020-08-22 03:02:57", "link": "http://arxiv.org/abs/2008.09740v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DUTH at SemEval-2020 Task 11: BERT with Entity Mapping for Propaganda\n  Classification", "abstract": "This report describes the methods employed by the Democritus University of\nThrace (DUTH) team for participating in SemEval-2020 Task 11: Detection of\nPropaganda Techniques in News Articles. Our team dealt with Subtask 2:\nTechnique Classification. We used shallow Natural Language Processing (NLP)\npreprocessing techniques to reduce the noise in the dataset, feature selection\nmethods, and common supervised machine learning algorithms. Our final model is\nbased on using the BERT system with entity mapping. To improve our model's\naccuracy, we mapped certain words into five distinct categories by employing\nword-classes and entity recognition.", "published": "2020-08-22 18:18:02", "link": "http://arxiv.org/abs/2008.09894v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HinglishNLP: Fine-tuned Language Models for Hinglish Sentiment Detection", "abstract": "Sentiment analysis for code-mixed social media text continues to be an\nunder-explored area. This work adds two common approaches: fine-tuning large\ntransformer models and sample efficient methods like ULMFiT. Prior work\ndemonstrates the efficacy of classical ML methods for polarity detection.\nFine-tuned general-purpose language representation models, such as those of the\nBERT family are benchmarked along with classical machine learning and ensemble\nmethods. We show that NB-SVM beats RoBERTa by 6.2% (relative) F1. The best\nperforming model is a majority-vote ensemble which achieves an F1 of 0.707. The\nleaderboard submission was made under the codalab username nirantk, with F1 of\n0.689.", "published": "2020-08-22 12:01:44", "link": "http://arxiv.org/abs/2008.09820v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CyberWallE at SemEval-2020 Task 11: An Analysis of Feature Engineering\n  for Ensemble Models for Propaganda Detection", "abstract": "This paper describes our participation in the SemEval-2020 task Detection of\nPropaganda Techniques in News Articles. We participate in both subtasks: Span\nIdentification (SI) and Technique Classification (TC). We use a bi-LSTM\narchitecture in the SI subtask and train a complex ensemble model for the TC\nsubtask. Our architectures are built using embeddings from BERT in combination\nwith additional lexical features and extensive label post-processing. Our\nsystems achieve a rank of 8 out of 35 teams in the SI subtask (F1-score:\n43.86%) and 8 out of 31 teams in the TC subtask (F1-score: 57.37%).", "published": "2020-08-22 15:51:16", "link": "http://arxiv.org/abs/2008.09859v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "UTMN at SemEval-2020 Task 11: A Kitchen Solution to Automatic Propaganda\n  Detection", "abstract": "The article describes a fast solution to propaganda detection at SemEval-2020\nTask 11, based onfeature adjustment. We use per-token vectorization of features\nand a simple Logistic Regressionclassifier to quickly test different hypotheses\nabout our data. We come up with what seems to usthe best solution, however, we\nare unable to align it with the result of the metric suggested by theorganizers\nof the task. We test how our system handles class and feature imbalance by\nvarying thenumber of samples of two classes (Propaganda and None) in the\ntraining set, the size of a contextwindow in which a token is vectorized and\ncombination of vectorization means. The result of oursystem at SemEval2020 Task\n11 is F-score=0.37.", "published": "2020-08-22 16:31:01", "link": "http://arxiv.org/abs/2008.09869v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FAT ALBERT: Finding Answers in Large Texts using Semantic Similarity\n  Attention Layer based on BERT", "abstract": "Machine based text comprehension has always been a significant research field\nin natural language processing. Once a full understanding of the text context\nand semantics is achieved, a deep learning model can be trained to solve a\nlarge subset of tasks, e.g. text summarization, classification and question\nanswering. In this paper we focus on the question answering problem,\nspecifically the multiple choice type of questions. We develop a model based on\nBERT, a state-of-the-art transformer network. Moreover, we alleviate the\nability of BERT to support large text corpus by extracting the highest\ninfluence sentences through a semantic similarity model. Evaluations of our\nproposed model demonstrate that it outperforms the leading models in the\nMovieQA challenge and we are currently ranked first in the leader board with\ntest accuracy of 87.79%. Finally, we discuss the model shortcomings and suggest\npossible improvements to overcome these limitations.", "published": "2020-08-22 08:04:21", "link": "http://arxiv.org/abs/2009.01004v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Emotion-Based End-to-End Matching Between Image and Music in\n  Valence-Arousal Space", "abstract": "Both images and music can convey rich semantics and are widely used to induce\nspecific emotions. Matching images and music with similar emotions might help\nto make emotion perceptions more vivid and stronger. Existing emotion-based\nimage and music matching methods either employ limited categorical emotion\nstates which cannot well reflect the complexity and subtlety of emotions, or\ntrain the matching model using an impractical multi-stage pipeline. In this\npaper, we study end-to-end matching between image and music based on emotions\nin the continuous valence-arousal (VA) space. First, we construct a large-scale\ndataset, termed Image-Music-Emotion-Matching-Net (IMEMNet), with over 140K\nimage-music pairs. Second, we propose cross-modal deep continuous metric\nlearning (CDCML) to learn a shared latent embedding space which preserves the\ncross-modal similarity relationship in the continuous matching space. Finally,\nwe refine the embedding space by further preserving the single-modal emotion\nrelationship in the VA spaces of both images and music. The metric learning in\nthe embedding space and task regression in the label space are jointly\noptimized for both cross-modal matching and single-modal VA prediction. The\nextensive experiments conducted on IMEMNet demonstrate the superiority of CDCML\nfor emotion-based image and music matching as compared to the state-of-the-art\napproaches.", "published": "2020-08-22 20:12:23", "link": "http://arxiv.org/abs/2009.05103v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
