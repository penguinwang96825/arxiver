{"title": "CodeDiffuser: Attention-Enhanced Diffusion Policy via VLM-Generated Code for Instruction Ambiguity", "abstract": "Natural language instructions for robotic manipulation tasks often exhibit\nambiguity and vagueness. For instance, the instruction \"Hang a mug on the mug\ntree\" may involve multiple valid actions if there are several mugs and branches\nto choose from. Existing language-conditioned policies typically rely on\nend-to-end models that jointly handle high-level semantic understanding and\nlow-level action generation, which can result in suboptimal performance due to\ntheir lack of modularity and interpretability. To address these challenges, we\nintroduce a novel robotic manipulation framework that can accomplish tasks\nspecified by potentially ambiguous natural language. This framework employs a\nVision-Language Model (VLM) to interpret abstract concepts in natural language\ninstructions and generates task-specific code - an interpretable and executable\nintermediate representation. The generated code interfaces with the perception\nmodule to produce 3D attention maps that highlight task-relevant regions by\nintegrating spatial and semantic information, effectively resolving ambiguities\nin instructions. Through extensive experiments, we identify key limitations of\ncurrent imitation learning methods, such as poor adaptation to language and\nenvironmental variations. We show that our approach excels across challenging\nmanipulation tasks involving language ambiguity, contact-rich manipulation, and\nmulti-object interactions.", "published": "2025-06-19 23:42:03", "link": "http://arxiv.org/abs/2506.16652v1", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SE"], "primary_category": "cs.RO"}
{"title": "Leveraging CNN and IoT for Effective E-Waste Management", "abstract": "The increasing proliferation of electronic devices in the modern era has led\nto a significant surge in electronic waste (e-waste). Improper disposal and\ninsufficient recycling of e-waste pose serious environmental and health risks.\nThis paper proposes an IoT-enabled system combined with a lightweight CNN-based\nclassification pipeline to enhance the identification, categorization, and\nrouting of e-waste materials. By integrating a camera system and a digital\nweighing scale, the framework automates the classification of electronic items\nbased on visual and weight-based attributes. The system demonstrates how\nreal-time detection of e-waste components such as circuit boards, sensors, and\nwires can facilitate smart recycling workflows and improve overall waste\nprocessing efficiency.", "published": "2025-06-19 23:19:15", "link": "http://arxiv.org/abs/2506.16647v1", "categories": ["cs.CV", "68T05 (Primary), 68T01 (Secondary)", "I.2.10; C.3; J.2"], "primary_category": "cs.CV"}
{"title": "Overfitting in Histopathology Model Training: The Need for Customized Architectures", "abstract": "This study investigates the critical problem of overfitting in deep learning\nmodels applied to histopathology image analysis. We show that simply adopting\nand fine-tuning large-scale models designed for natural image analysis often\nleads to suboptimal performance and significant overfitting when applied to\nhistopathology tasks. Through extensive experiments with various model\narchitectures, including ResNet variants and Vision Transformers (ViT), we show\nthat increasing model capacity does not necessarily improve performance on\nhistopathology datasets. Our findings emphasize the need for customized\narchitectures specifically designed for histopathology image analysis,\nparticularly when working with limited datasets. Using Oesophageal\nAdenocarcinomas public dataset, we demonstrate that simpler, domain-specific\narchitectures can achieve comparable or better performance while minimizing\noverfitting.", "published": "2025-06-19 22:05:54", "link": "http://arxiv.org/abs/2506.16631v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "FlatCAD: Fast Curvature Regularization of Neural SDFs for CAD Models", "abstract": "Neural signed-distance fields (SDFs) have become a versatile backbone for\ngeometric learning, yet enforcing developable, CAD-style behavior still hinges\non Gaussian curvature penalties that require full Hessian evaluation and\nsecond-order automatic differentiation, both of which are costly in memory and\nruntime. We present a curvature proxy that regularizes only the mixed\nsecond-order term (Weingarten term), allowing the two principal curvatures to\nadapt freely to data while suppressing unwanted warp. Two complementary\ninstantiations realize this idea: (i) a finite-difference proxy that replaces\neach Hessian entry with four forward SDF evaluations and a single first-order\ngradient, and (ii) an autodiff proxy that computes the same mixed derivative\nvia one Hessian-vector product, sidestepping explicit full Hessian assembly and\nremaining faster in practice. Both variants converge to the exact mixed second\nderivative, thus preserving the intended geometric bias without incurring full\nsecond-order graphs. On the ABC benchmarks, the proxies match or exceed the\nreconstruction fidelity of Hessian-based baselines while reducing GPU memory\nuse and wall-clock time by a factor of two. Because the method is drop-in and\nframework-agnostic, it opens a practical path toward scalable, curvature-aware\nSDF learning for engineering-grade shape reconstruction.", "published": "2025-06-19 21:54:08", "link": "http://arxiv.org/abs/2506.16627v1", "categories": ["cs.GR", "cs.CV", "cs.LG", "65D18, 68U05, 68T07, 53A07", "I.3.5; I.3.7; I.2.6"], "primary_category": "cs.GR"}
{"title": "MetaQAP -- A Meta-Learning Approach for Quality-Aware Pretraining in Image Quality Assessment", "abstract": "Image Quality Assessment (IQA) is a critical task in a wide range of\napplications but remains challenging due to the subjective nature of human\nperception and the complexity of real-world image distortions. This study\nproposes MetaQAP, a novel no-reference IQA model designed to address these\nchallenges by leveraging quality-aware pre-training and meta-learning. The\nmodel performs three key contributions: pre-training Convolutional Neural\nNetworks (CNNs) on a quality-aware dataset, implementing a quality-aware loss\nfunction to optimize predictions, and integrating a meta-learner to form an\nensemble model that effectively combines predictions from multiple base models.\nExperimental evaluations were conducted on three benchmark datasets: LiveCD,\nKonIQ-10K, and BIQ2021. The proposed MetaQAP model achieved exceptional\nperformance with Pearson Linear Correlation Coefficient (PLCC) and Spearman\nRank Order Correlation Coefficient (SROCC) scores of 0.9885/0.9812 on LiveCD,\n0.9702/0.9658 on KonIQ-10K, and 0.884/0.8765 on BIQ2021, outperforming existing\nIQA methods. Cross-dataset evaluations further demonstrated the\ngeneralizability of the model, with PLCC and SROCC scores ranging from 0.6721\nto 0.8023 and 0.6515 to 0.7805, respectively, across diverse datasets. The\nablation study confirmed the significance of each model component, revealing\nsubstantial performance degradation when critical elements such as the\nmeta-learner or quality-aware loss function were omitted. MetaQAP not only\naddresses the complexities of authentic distortions but also establishes a\nrobust and generalizable framework for practical IQA applications. By advancing\nthe state-of-the-art in no-reference IQA, this research provides valuable\ninsights and methodologies for future improvements and extensions in the field.", "published": "2025-06-19 21:03:47", "link": "http://arxiv.org/abs/2506.16601v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Exoplanet Classification through Vision Transformers with Temporal Image Analysis", "abstract": "The classification of exoplanets has been a longstanding challenge in\nastronomy, requiring significant computational and observational resources.\nTraditional methods demand substantial effort, time, and cost, highlighting the\nneed for advanced machine learning techniques to enhance classification\nefficiency. In this study, we propose a methodology that transforms raw light\ncurve data from NASA's Kepler mission into Gramian Angular Fields (GAFs) and\nRecurrence Plots (RPs) using the Gramian Angular Difference Field and\nrecurrence plot techniques. These transformed images serve as inputs to the\nVision Transformer (ViT) model, leveraging its ability to capture intricate\ntemporal dependencies. We assess the performance of the model through recall,\nprecision, and F1 score metrics, using a 5-fold cross-validation approach to\nobtain a robust estimate of the model's performance and reduce evaluation bias.\nOur comparative analysis reveals that RPs outperform GAFs, with the ViT model\nachieving an 89.46$\\%$ recall and an 85.09$\\%$ precision rate, demonstrating\nits significant capability in accurately identifying exoplanetary transits.\nDespite using under-sampling techniques to address class imbalance, dataset\nsize reduction remains a limitation. This study underscores the importance of\nfurther research into optimizing model architectures to enhance automation,\nperformance, and generalization of the model.", "published": "2025-06-19 20:57:17", "link": "http://arxiv.org/abs/2506.16597v1", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.CV"], "primary_category": "astro-ph.EP"}
{"title": "Hybrid Attention Network for Accurate Breast Tumor Segmentation in Ultrasound Images", "abstract": "Breast ultrasound imaging is a valuable tool for early breast cancer\ndetection, but automated tumor segmentation is challenging due to inherent\nnoise, variations in scale of lesions, and fuzzy boundaries. To address these\nchallenges, we propose a novel hybrid attention-based network for lesion\nsegmentation. Our proposed architecture integrates a pre-trained DenseNet121 in\nthe encoder part for robust feature extraction with a multi-branch\nattention-enhanced decoder tailored for breast ultrasound images. The\nbottleneck incorporates Global Spatial Attention (GSA), Position Encoding (PE),\nand Scaled Dot-Product Attention (SDPA) to learn global context, spatial\nrelationships, and relative positional features. The Spatial Feature\nEnhancement Block (SFEB) is embedded at skip connections to refine and enhance\nspatial features, enabling the network to focus more effectively on tumor\nregions. A hybrid loss function combining Binary Cross-Entropy (BCE) and\nJaccard Index loss optimizes both pixel-level accuracy and region-level overlap\nmetrics, enhancing robustness to class imbalance and irregular tumor shapes.\nExperiments on public datasets demonstrate that our method outperforms existing\napproaches, highlighting its potential to assist radiologists in early and\naccurate breast cancer diagnosis.", "published": "2025-06-19 20:32:54", "link": "http://arxiv.org/abs/2506.16592v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Spatially-Aware Evaluation of Segmentation Uncertainty", "abstract": "Uncertainty maps highlight unreliable regions in segmentation predictions.\nHowever, most uncertainty evaluation metrics treat voxels independently,\nignoring spatial context and anatomical structure. As a result, they may assign\nidentical scores to qualitatively distinct patterns (e.g., scattered vs.\nboundary-aligned uncertainty). We propose three spatially aware metrics that\nincorporate structural and boundary information and conduct a thorough\nvalidation on medical imaging data from the prostate zonal segmentation\nchallenge within the Medical Segmentation Decathlon. Our results demonstrate\nimproved alignment with clinically important factors and better discrimination\nbetween meaningful and spurious uncertainty patterns.", "published": "2025-06-19 20:24:57", "link": "http://arxiv.org/abs/2506.16589v1", "categories": ["cs.CV", "cs.AI", "cs.PF", "stat.ML"], "primary_category": "cs.CV"}
{"title": "SafeTriage: Facial Video De-identification for Privacy-Preserving Stroke Triage", "abstract": "Effective stroke triage in emergency settings often relies on clinicians'\nability to identify subtle abnormalities in facial muscle coordination. While\nrecent AI models have shown promise in detecting such patterns from patient\nfacial videos, their reliance on real patient data raises significant ethical\nand privacy challenges -- especially when training robust and generalizable\nmodels across institutions. To address these concerns, we propose SafeTriage, a\nnovel method designed to de-identify patient facial videos while preserving\nessential motion cues crucial for stroke diagnosis. SafeTriage leverages a\npretrained video motion transfer (VMT) model to map the motion characteristics\nof real patient faces onto synthetic identities. This approach retains\ndiagnostically relevant facial dynamics without revealing the patients'\nidentities. To mitigate the distribution shift between normal population\npre-training videos and patient population test videos, we introduce a\nconditional generative model for visual prompt tuning, which adapts the input\nspace of the VMT model to ensure accurate motion transfer without needing to\nfine-tune the VMT model backbone. Comprehensive evaluation, including\nquantitative metrics and clinical expert assessments, demonstrates that\nSafeTriage-produced synthetic videos effectively preserve stroke-relevant\nfacial patterns, enabling reliable AI-based triage. Our evaluations also show\nthat SafeTriage provides robust privacy protection while maintaining diagnostic\naccuracy, offering a secure and ethically sound foundation for data sharing and\nAI-driven clinical analysis in neurological disorders.", "published": "2025-06-19 20:02:47", "link": "http://arxiv.org/abs/2506.16578v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DiffO: Single-step Diffusion for Image Compression at Ultra-Low Bitrates", "abstract": "Although image compression is fundamental to visual data processing and has\ninspired numerous standard and learned codecs, these methods still suffer\nsevere quality degradation at extremely low bits per pixel. While recent\ndiffusion based models provided enhanced generative performance at low\nbitrates, they still yields limited perceptual quality and prohibitive decoding\nlatency due to multiple denoising steps. In this paper, we propose the first\nsingle step diffusion model for image compression (DiffO) that delivers high\nperceptual quality and fast decoding at ultra low bitrates. DiffO achieves\nthese goals by coupling two key innovations: (i) VQ Residual training, which\nfactorizes a structural base code and a learned residual in latent space,\ncapturing both global geometry and high frequency details; and (ii) rate\nadaptive noise modulation, which tunes denoising strength on the fly to match\nthe desired bitrate. Extensive experiments show that DiffO surpasses state of\nthe art compression performance while improving decoding speed by about 50x\ncompared to prior diffusion-based methods, greatly improving the practicality\nof generative codecs. The code will be available at\nhttps://github.com/Freemasti/DiffO.", "published": "2025-06-19 19:53:27", "link": "http://arxiv.org/abs/2506.16572v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Reimagination with Test-time Observation Interventions: Distractor-Robust World Model Predictions for Visual Model Predictive Control", "abstract": "World models enable robots to \"imagine\" future observations given current\nobservations and planned actions, and have been increasingly adopted as\ngeneralized dynamics models to facilitate robot learning. Despite their\npromise, these models remain brittle when encountering novel visual distractors\nsuch as objects and background elements rarely seen during training.\nSpecifically, novel distractors can corrupt action outcome predictions, causing\ndownstream failures when robots rely on the world model imaginations for\nplanning or action verification. In this work, we propose Reimagination with\nObservation Intervention (ReOI), a simple yet effective test-time strategy that\nenables world models to predict more reliable action outcomes in open-world\nscenarios where novel and unanticipated visual distractors are inevitable.\nGiven the current robot observation, ReOI first detects visual distractors by\nidentifying which elements of the scene degrade in physically implausible ways\nduring world model prediction. Then, it modifies the current observation to\nremove these distractors and bring the observation closer to the training\ndistribution. Finally, ReOI \"reimagines\" future outcomes with the modified\nobservation and reintroduces the distractors post-hoc to preserve visual\nconsistency for downstream planning and verification. We validate our approach\non a suite of robotic manipulation tasks in the context of action verification,\nwhere the verifier needs to select desired action plans based on predictions\nfrom a world model. Our results show that ReOI is robust to both\nin-distribution and out-of-distribution visual distractors. Notably, it\nimproves task success rates by up to 3x in the presence of novel distractors,\nsignificantly outperforming action verification that relies on world model\npredictions without imagination interventions.", "published": "2025-06-19 19:41:29", "link": "http://arxiv.org/abs/2506.16565v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "From Semantic To Instance: A Semi-Self-Supervised Learning Approach", "abstract": "Instance segmentation is essential for applications such as automated\nmonitoring of plant health, growth, and yield. However, extensive effort is\nrequired to create large-scale datasets with pixel-level annotations of each\nobject instance for developing instance segmentation models that restrict the\nuse of deep learning in these areas. This challenge is more significant in\nimages with densely packed, self-occluded objects, which are common in\nagriculture. To address this challenge, we propose a semi-self-supervised\nlearning approach that requires minimal manual annotation to develop a\nhigh-performing instance segmentation model. We design GLMask, an image-mask\nrepresentation for the model to focus on shape, texture, and pattern while\nminimizing its dependence on color features. We develop a pipeline to generate\nsemantic segmentation and then transform it into instance-level segmentation.\nThe proposed approach substantially outperforms the conventional instance\nsegmentation models, establishing a state-of-the-art wheat head instance\nsegmentation model with mAP@50 of 98.5%. Additionally, we assessed the proposed\nmethodology on the general-purpose Microsoft COCO dataset, achieving a\nsignificant performance improvement of over 12.6% mAP@50. This highlights that\nthe utility of our proposed approach extends beyond precision agriculture and\napplies to other domains, specifically those with similar data characteristics.", "published": "2025-06-19 19:38:01", "link": "http://arxiv.org/abs/2506.16563v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "VesselSDF: Distance Field Priors for Vascular Network Reconstruction", "abstract": "Accurate segmentation of vascular networks from sparse CT scan slices remains\na significant challenge in medical imaging, particularly due to the thin,\nbranching nature of vessels and the inherent sparsity between imaging planes.\nExisting deep learning approaches, based on binary voxel classification, often\nstruggle with structural continuity and geometric fidelity. To address this\nchallenge, we present VesselSDF, a novel framework that leverages signed\ndistance fields (SDFs) for robust vessel reconstruction. Our method\nreformulates vessel segmentation as a continuous SDF regression problem, where\neach point in the volume is represented by its signed distance to the nearest\nvessel surface. This continuous representation inherently captures the smooth,\ntubular geometry of blood vessels and their branching patterns. We obtain\naccurate vessel reconstructions while eliminating common SDF artifacts such as\nfloating segments, thanks to our adaptive Gaussian regularizer which ensures\nsmoothness in regions far from vessel surfaces while producing precise geometry\nnear the surface boundaries. Our experimental results demonstrate that\nVesselSDF significantly outperforms existing methods and preserves vessel\ngeometry and connectivity, enabling more reliable vascular analysis in clinical\nsettings.", "published": "2025-06-19 19:20:51", "link": "http://arxiv.org/abs/2506.16556v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "How Hard Is Snow? A Paired Domain Adaptation Dataset for Clear and Snowy Weather: CADC+", "abstract": "The impact of snowfall on 3D object detection performance remains\nunderexplored. Conducting such an evaluation requires a dataset with sufficient\nlabelled data from both weather conditions, ideally captured in the same\ndriving environment. Current driving datasets with LiDAR point clouds either do\nnot provide enough labelled data in both snowy and clear weather conditions, or\nrely on de-snowing methods to generate synthetic clear weather. Synthetic data\noften lacks realism and introduces an additional domain shift that confounds\naccurate evaluations. To address these challenges, we present CADC+, the first\npaired weather domain adaptation dataset for autonomous driving in winter\nconditions. CADC+ extends the Canadian Adverse Driving Conditions dataset\n(CADC) using clear weather data that was recorded on the same roads and in the\nsame period as CADC. To create CADC+, we pair each CADC sequence with a clear\nweather sequence that matches the snowy sequence as closely as possible. CADC+\nthus minimizes the domain shift resulting from factors unrelated to the\npresence of snow. We also present some preliminary results using CADC+ to\nevaluate the effect of snow on 3D object detection performance. We observe that\nsnow introduces a combination of aleatoric and epistemic uncertainties, acting\nas both noise and a distinct data domain.", "published": "2025-06-19 18:24:03", "link": "http://arxiv.org/abs/2506.16531v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Subspace-Boosted Model Merging", "abstract": "Model merging enables the combination of multiple specialized expert models\ninto a single model capable of performing multiple tasks. However, the benefits\nof merging an increasing amount of specialized experts generally lead to\ndiminishing returns and reduced overall performance gains. In this work, we\noffer an explanation and analysis from a task arithmetic perspective; revealing\nthat as the merging process (across numerous existing merging methods)\ncontinues for more and more experts, the associated task vector space\nexperiences rank collapse. To mitigate this issue, we introduce Subspace\nBoosting, which operates on the singular value decomposed task vector space and\nmaintains task vector ranks. Subspace Boosting raises merging efficacy for up\nto 20 expert models by large margins of more than 10% when evaluated on vision\nbenchmarks. Moreover, we propose employing Higher-Order Generalized Singular\nValue Decomposition to further quantify task similarity, offering a new\ninterpretable perspective on model merging.", "published": "2025-06-19 17:59:29", "link": "http://arxiv.org/abs/2506.16506v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details", "abstract": "In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion\nmodels aimed at generating high-fidelity and detailed textured 3D assets.\nHunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D\n2.0, while demonstrating substantial advancements in both shape and texture\ngeneration. In terms of shape generation, we introduce a new shape foundation\nmodel -- LATTICE, which is trained with scaled high-quality datasets,\nmodel-size, and compute. Our largest model reaches 10B parameters and generates\nsharp and detailed 3D shape with precise image-3D following while keeping mesh\nsurface clean and smooth, significantly closing the gap between generated and\nhandcrafted 3D shapes. In terms of texture generation, it is upgraded with\nphyiscal-based rendering (PBR) via a novel multi-view architecture extended\nfrom Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D\n2.5 significantly outperforms previous methods in both shape and end-to-end\ntexture generation.", "published": "2025-06-19 17:57:40", "link": "http://arxiv.org/abs/2506.16504v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Spotting tell-tale visual artifacts in face swapping videos: strengths and pitfalls of CNN detectors", "abstract": "Face swapping manipulations in video streams represents an increasing threat\nin remote video communications, due to advances\n  in automated and real-time tools. Recent literature proposes to characterize\nand exploit visual artifacts introduced in video frames\n  by swapping algorithms when dealing with challenging physical scenes, such as\nface occlusions. This paper investigates the\n  effectiveness of this approach by benchmarking CNN-based data-driven models\non two data corpora (including a newly collected\n  one) and analyzing generalization capabilities with respect to different\nacquisition sources and swapping algorithms. The results\n  confirm excellent performance of general-purpose CNN architectures when\noperating within the same data source, but a significant\n  difficulty in robustly characterizing occlusion-based visual cues across\ndatasets. This highlights the need for specialized detection\n  strategies to deal with such artifacts.", "published": "2025-06-19 17:51:11", "link": "http://arxiv.org/abs/2506.16497v1", "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "cs.CV"}
{"title": "DT-UFC: Universal Large Model Feature Coding via Peaky-to-Balanced Distribution Transformation", "abstract": "Like image coding in visual data transmission, feature coding is essential\nfor the distributed deployment of large models by significantly reducing\ntransmission and storage overhead. However, prior studies have mostly targeted\ntask- or model-specific scenarios, leaving the challenge of universal feature\ncoding across diverse large models largely unaddressed. In this paper, we\npresent the first systematic study on universal feature coding for large\nmodels. The key challenge lies in the inherently diverse and distributionally\nincompatible nature of features extracted from different models. For example,\nfeatures from DINOv2 exhibit highly peaky, concentrated distributions, while\nthose from Stable Diffusion 3 (SD3) are more dispersed and uniform. This\ndistributional heterogeneity severely hampers both compression efficiency and\ncross-model generalization. To address this, we propose a learned\npeaky-to-balanced distribution transformation, which reshapes highly skewed\nfeature distributions into a common, balanced target space. This transformation\nis non-uniform, data-driven, and plug-and-play, enabling effective alignment of\nheterogeneous distributions without modifying downstream codecs. With this\nalignment, a universal codec trained on the balanced target distribution can\neffectively generalize to features from different models and tasks. We validate\nour approach on three representative large models-LLaMA3, DINOv2, and\nSD3-across multiple tasks and modalities. Extensive experiments show that our\nmethod achieves notable improvements in both compression efficiency and\ncross-model generalization over task-specific baselines. All source code will\nbe released for future research.", "published": "2025-06-19 17:43:32", "link": "http://arxiv.org/abs/2506.16495v1", "categories": ["cs.MM", "cs.CV"], "primary_category": "cs.MM"}
{"title": "How Far Can Off-the-Shelf Multimodal Large Language Models Go in Online Episodic Memory Question Answering?", "abstract": "We investigate whether off-the-shelf Multimodal Large Language Models (MLLMs)\ncan tackle Online Episodic-Memory Video Question Answering (OEM-VQA) without\nadditional training. Our pipeline converts a streaming egocentric video into a\nlightweight textual memory, only a few kilobytes per minute, via an MLLM\ndescriptor module, and answers multiple-choice questions by querying this\nmemory with an LLM reasoner module. On the QAEgo4D-Closed benchmark, our best\nconfiguration attains 56.0% accuracy with 3.6 kB per minute storage, matching\nthe performance of dedicated state-of-the-art systems while being 10**4/10**5\ntimes more memory-efficient. Extensive ablations provides insights into the\nrole of each component and design choice, and highlight directions of\nimprovement for future research.", "published": "2025-06-19 16:35:49", "link": "http://arxiv.org/abs/2506.16450v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Structured Semantic 3D Reconstruction (S23DR) Challenge 2025 -- Winning solution", "abstract": "This paper presents the winning solution for the S23DR Challenge 2025, which\ninvolves predicting a house's 3D roof wireframe from a sparse point cloud and\nsemantic segmentations. Our method operates directly in 3D, first identifying\nvertex candidates from the COLMAP point cloud using Gestalt segmentations. We\nthen employ two PointNet-like models: one to refine and classify these\ncandidates by analyzing local cubic patches, and a second to predict edges by\nprocessing the cylindrical regions connecting vertex pairs. This two-stage, 3D\ndeep learning approach achieved a winning Hybrid Structure Score (HSS) of 0.43\non the private leaderboard.", "published": "2025-06-19 15:56:51", "link": "http://arxiv.org/abs/2506.16421v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient Transformations in Deep Learning Convolutional Neural Networks", "abstract": "This study investigates the integration of signal processing transformations\n-- Fast Fourier Transform (FFT), Walsh-Hadamard Transform (WHT), and Discrete\nCosine Transform (DCT) -- within the ResNet50 convolutional neural network\n(CNN) model for image classification. The primary objective is to assess the\ntrade-offs between computational efficiency, energy consumption, and\nclassification accuracy during training and inference. Using the CIFAR-100\ndataset (100 classes, 60,000 images), experiments demonstrated that\nincorporating WHT significantly reduced energy consumption while improving\naccuracy. Specifically, a baseline ResNet50 model achieved a testing accuracy\nof 66%, consuming an average of 25,606 kJ per model. In contrast, a modified\nResNet50 incorporating WHT in the early convolutional layers achieved 74%\naccuracy, and an enhanced version with WHT applied to both early and late\nlayers achieved 79% accuracy, with an average energy consumption of only 39 kJ\nper model. These results demonstrate the potential of WHT as a highly efficient\nand effective approach for energy-constrained CNN applications.", "published": "2025-06-19 15:54:59", "link": "http://arxiv.org/abs/2506.16418v1", "categories": ["cs.CV", "cs.AI", "eess.IV", "eess.SP", "68T07, 68T10, 94A08, 42C10"], "primary_category": "cs.CV"}
{"title": "Robustness Evaluation of OCR-based Visual Document Understanding under Multi-Modal Adversarial Attacks", "abstract": "Visual Document Understanding (VDU) systems have achieved strong performance\nin information extraction by integrating textual, layout, and visual signals.\nHowever, their robustness under realistic adversarial perturbations remains\ninsufficiently explored. We introduce the first unified framework for\ngenerating and evaluating multi-modal adversarial attacks on OCR-based VDU\nmodels. Our method covers six gradient-based layout attack scenarios,\nincorporating manipulations of OCR bounding boxes, pixels, and texts across\nboth word and line granularities, with constraints on layout perturbation\nbudget (e.g., IoU >= 0.6) to preserve plausibility.\n  Experimental results across four datasets (FUNSD, CORD, SROIE, DocVQA) and\nsix model families demonstrate that line-level attacks and compound\nperturbations (BBox + Pixel + Text) yield the most severe performance\ndegradation. Projected Gradient Descent (PGD)-based BBox perturbations\noutperform random-shift baselines in all investigated models. Ablation studies\nfurther validate the impact of layout budget, text modification, and\nadversarial transferability.", "published": "2025-06-19 15:38:31", "link": "http://arxiv.org/abs/2506.16407v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks", "abstract": "Flawed planning from VLM-driven embodied agents poses significant safety\nhazards, hindering their deployment in real-world household tasks. However,\nexisting static, non-interactive evaluation paradigms fail to adequately assess\nrisks within these interactive environments, since they cannot simulate dynamic\nrisks that emerge from an agent's actions and rely on unreliable post-hoc\nevaluations that ignore unsafe intermediate steps. To bridge this critical gap,\nwe propose evaluating an agent's interactive safety: its ability to perceive\nemergent risks and execute mitigation steps in the correct procedural order. We\nthus present IS-Bench, the first multi-modal benchmark designed for interactive\nsafety, featuring 161 challenging scenarios with 388 unique safety risks\ninstantiated in a high-fidelity simulator. Crucially, it facilitates a novel\nprocess-oriented evaluation that verifies whether risk mitigation actions are\nperformed before/after specific risk-prone steps. Extensive experiments on\nleading VLMs, including the GPT-4o and Gemini-2.5 series, reveal that current\nagents lack interactive safety awareness, and that while safety-aware\nChain-of-Thought can improve performance, it often compromises task completion.\nBy highlighting these critical limitations, IS-Bench provides a foundation for\ndeveloping safer and more reliable embodied AI systems.", "published": "2025-06-19 15:34:46", "link": "http://arxiv.org/abs/2506.16402v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "TrajSceneLLM: A Multimodal Perspective on Semantic GPS Trajectory Analysis", "abstract": "GPS trajectory data reveals valuable patterns of human mobility and urban\ndynamics, supporting a variety of spatial applications. However, traditional\nmethods often struggle to extract deep semantic representations and incorporate\ncontextual map information. We propose TrajSceneLLM, a multimodal perspective\nfor enhancing semantic understanding of GPS trajectories. The framework\nintegrates visualized map images (encoding spatial context) and textual\ndescriptions generated through LLM reasoning (capturing temporal sequences and\nmovement dynamics). Separate embeddings are generated for each modality and\nthen concatenated to produce trajectory scene embeddings with rich semantic\ncontent which are further paired with a simple MLP classifier. We validate the\nproposed framework on Travel Mode Identification (TMI), a critical task for\nanalyzing travel choices and understanding mobility behavior. Our experiments\nshow that these embeddings achieve significant performance improvement,\nhighlighting the advantage of our LLM-driven method in capturing deep\nspatio-temporal dependencies and reducing reliance on handcrafted features.\nThis semantic enhancement promises significant potential for diverse downstream\napplications and future research in geospatial artificial intelligence. The\nsource code and dataset are publicly available at:\nhttps://github.com/februarysea/TrajSceneLLM.", "published": "2025-06-19 15:31:40", "link": "http://arxiv.org/abs/2506.16401v1", "categories": ["cs.CY", "cs.CV"], "primary_category": "cs.CY"}
{"title": "HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis", "abstract": "Pathology is essential for cancer diagnosis, with multiple instance learning\n(MIL) widely used for whole slide image (WSI) analysis. WSIs exhibit a natural\nhierarchy -- patches, regions, and slides -- with distinct semantic\nassociations. While some methods attempt to leverage this hierarchy for\nimproved representation, they predominantly rely on Euclidean embeddings, which\nstruggle to fully capture semantic hierarchies. To address this limitation, we\npropose HyperPath, a novel method that integrates knowledge from textual\ndescriptions to guide the modeling of semantic hierarchies of WSIs in\nhyperbolic space, thereby enhancing WSI classification. Our approach adapts\nboth visual and textual features extracted by pathology vision-language\nfoundation models to the hyperbolic space. We design an Angular Modality\nAlignment Loss to ensure robust cross-modal alignment, while a Semantic\nHierarchy Consistency Loss further refines feature hierarchies through\nentailment and contradiction relationships and thus enhance semantic coherence.\nThe classification is performed with geodesic distance, which measures the\nsimilarity between entities in the hyperbolic semantic hierarchy. This\neliminates the need for linear classifiers and enables a geometry-aware\napproach to WSI analysis. Extensive experiments show that our method achieves\nsuperior performance across tasks compared to existing methods, highlighting\nthe potential of hyperbolic embeddings for WSI analysis.", "published": "2025-06-19 15:30:33", "link": "http://arxiv.org/abs/2506.16398v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CLIP-MG: Guiding Semantic Attention with Skeletal Pose Features and RGB Data for Micro-Gesture Recognition on the iMiGUE Dataset", "abstract": "Micro-gesture recognition is a challenging task in affective computing due to\nthe subtle, involuntary nature of the gestures and their low movement\namplitude. In this paper, we introduce a Pose-Guided Semantics-Aware CLIP-based\narchitecture, or CLIP for Micro-Gesture recognition (CLIP-MG), a modified CLIP\nmodel tailored for micro-gesture classification on the iMiGUE dataset. CLIP-MG\nintegrates human pose (skeleton) information into the CLIP-based recognition\npipeline through pose-guided semantic query generation and a gated multi-modal\nfusion mechanism. The proposed model achieves a Top-1 accuracy of 61.82%. These\nresults demonstrate both the potential of our approach and the remaining\ndifficulty in fully adapting vision-language models like CLIP for micro-gesture\nrecognition.", "published": "2025-06-19 15:16:06", "link": "http://arxiv.org/abs/2506.16385v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "AGC-Drive: A Large-Scale Dataset for Real-World Aerial-Ground Collaboration in Driving Scenarios", "abstract": "By sharing information across multiple agents, collaborative perception helps\nautonomous vehicles mitigate occlusions and improve overall perception\naccuracy. While most previous work focus on vehicle-to-vehicle and\nvehicle-to-infrastructure collaboration, with limited attention to aerial\nperspectives provided by UAVs, which uniquely offer dynamic, top-down views to\nalleviate occlusions and monitor large-scale interactive environments. A major\nreason for this is the lack of high-quality datasets for aerial-ground\ncollaborative scenarios. To bridge this gap, we present AGC-Drive, the first\nlarge-scale real-world dataset for Aerial-Ground Cooperative 3D perception. The\ndata collection platform consists of two vehicles, each equipped with five\ncameras and one LiDAR sensor, and one UAV carrying a forward-facing camera and\na LiDAR sensor, enabling comprehensive multi-view and multi-agent perception.\nConsisting of approximately 120K LiDAR frames and 440K images, the dataset\ncovers 14 diverse real-world driving scenarios, including urban roundabouts,\nhighway tunnels, and on/off ramps. Notably, 19.5% of the data comprises dynamic\ninteraction events, including vehicle cut-ins, cut-outs, and frequent lane\nchanges. AGC-Drive contains 400 scenes, each with approximately 100 frames and\nfully annotated 3D bounding boxes covering 13 object categories. We provide\nbenchmarks for two 3D perception tasks: vehicle-to-vehicle collaborative\nperception and vehicle-to-UAV collaborative perception. Additionally, we\nrelease an open-source toolkit, including spatiotemporal alignment verification\ntools, multi-agent visualization systems, and collaborative annotation\nutilities. The dataset and code are available at\nhttps://github.com/PercepX/AGC-Drive.", "published": "2025-06-19 14:48:43", "link": "http://arxiv.org/abs/2506.16371v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Prompt-based Dynamic Token Pruning to Guide Transformer Attention in Efficient Segmentation", "abstract": "The high computational demands of Vision Transformers (ViTs), in processing a\nhuge number of tokens, often constrain their practical application in analyzing\nmedical images. This research proposes an adaptive prompt-guided pruning method\nto selectively reduce the processing of irrelevant tokens in the segmentation\npipeline. The prompt-based spatial prior helps to rank the tokens according to\ntheir relevance. Tokens with low-relevance scores are down-weighted, ensuring\nthat only the relevant ones are propagated for processing across subsequent\nstages. This data-driven pruning strategy facilitates end-to-end training,\nmaintains gradient flow, and improves segmentation accuracy by focusing\ncomputational resources on essential regions. The proposed framework is\nintegrated with several state-of-the-art models to facilitate the elimination\nof irrelevant tokens; thereby, enhancing computational efficiency while\npreserving segmentation accuracy. The experimental results show a reduction of\n$\\sim$ 35-55\\% tokens; thus reducing the computational costs relative to the\nbaselines. Cost-effective medical image processing, using our framework,\nfacilitates real-time diagnosis by expanding its applicability in\nresource-constrained environments.", "published": "2025-06-19 14:45:46", "link": "http://arxiv.org/abs/2506.16369v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MambaHash: Visual State Space Deep Hashing Model for Large-Scale Image Retrieval", "abstract": "Deep image hashing aims to enable effective large-scale image retrieval by\nmapping the input images into simple binary hash codes through deep neural\nnetworks. More recently, Vision Mamba with linear time complexity has attracted\nextensive attention from researchers by achieving outstanding performance on\nvarious computer tasks. Nevertheless, the suitability of Mamba for large-scale\nimage retrieval tasks still needs to be explored. Towards this end, we propose\na visual state space hashing model, called MambaHash. Concretely, we propose a\nbackbone network with stage-wise architecture, in which grouped Mamba operation\nis introduced to model local and global information by utilizing Mamba to\nperform multi-directional scanning along different groups of the channel.\nSubsequently, the proposed channel interaction attention module is used to\nenhance information communication across channels. Finally, we meticulously\ndesign an adaptive feature enhancement module to increase feature diversity and\nenhance the visual representation capability of the model. We have conducted\ncomprehensive experiments on three widely used datasets: CIFAR-10, NUS-WIDE and\nIMAGENET. The experimental results demonstrate that compared with the\nstate-of-the-art deep hashing methods, our proposed MambaHash has well\nefficiency and superior performance to effectively accomplish large-scale image\nretrieval tasks. Source code is available\nhttps://github.com/shuaichaochao/MambaHash.git", "published": "2025-06-19 14:30:55", "link": "http://arxiv.org/abs/2506.16353v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Watermarking Autoregressive Image Generation", "abstract": "Watermarking the outputs of generative models has emerged as a promising\napproach for tracking their provenance. Despite significant interest in\nautoregressive image generation models and their potential for misuse, no prior\nwork has attempted to watermark their outputs at the token level. In this work,\nwe present the first such approach by adapting language model watermarking\ntechniques to this setting. We identify a key challenge: the lack of reverse\ncycle-consistency (RCC), wherein re-tokenizing generated image tokens\nsignificantly alters the token sequence, effectively erasing the watermark. To\naddress this and to make our method robust to common image transformations,\nneural compression, and removal attacks, we introduce (i) a custom\ntokenizer-detokenizer finetuning procedure that improves RCC, and (ii) a\ncomplementary watermark synchronization layer. As our experiments demonstrate,\nour approach enables reliable and robust watermark detection with theoretically\ngrounded p-values.", "published": "2025-06-19 14:25:51", "link": "http://arxiv.org/abs/2506.16349v1", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Transparency Techniques for Neural Networks trained on Writer Identification and Writer Verification", "abstract": "Neural Networks are the state of the art for many tasks in the computer\nvision domain, including Writer Identification (WI) and Writer Verification\n(WV). The transparency of these \"black box\" systems is important for\nimprovements of performance and reliability. For this work, two transparency\ntechniques are applied to neural networks trained on WI and WV for the first\ntime in this domain. The first technique provides pixel-level saliency maps,\nwhile the point-specific saliency maps of the second technique provide\ninformation on similarities between two images. The transparency techniques are\nevaluated using deletion and insertion score metrics. The goal is to support\nforensic experts with information on similarities in handwritten text and to\nexplore the characteristics selected by a neural network for the identification\nprocess. For the qualitative evaluation, the highlights of the maps are\ncompared to the areas forensic experts consider during the identification\nprocess. The evaluation results show that the pixel-wise saliency maps\noutperform the point-specific saliency maps and are suitable for the support of\nforensic experts.", "published": "2025-06-19 14:07:04", "link": "http://arxiv.org/abs/2506.16331v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Maximum Reachability Orientation of Mixed Graphs", "abstract": "We aim to find orientations of mixed graphs optimizing the total\nreachability, a problem that has applications in causality and biology. For\ngiven a digraph $D$, we use $P(D)$ for the set of ordered pairs of distinct\nvertices in $V(D)$ and we define $\\kappa_D:P(D)\\rightarrow \\{0,1\\}$ by\n$\\kappa_D(u,v)=1$ if $v$ is reachable from $u$ in $D$, and $\\kappa_D(u,v)=0$,\notherwise. We use $R(D)=\\sum_{(u,v)\\in P(D)}\\kappa_D(u,v)$.\n  Now, given a mixed graph $G$, we aim to find an orientation $\\vec{G}$ of $G$\nthat maximizes $R(\\vec{G})$. Hakimi, Schmeichel, and Young proved that the\nproblem can be solved in polynomial time when restricted to undirected inputs.\nThey inquired about the complexity in mixed graphs.\n  We answer this question by showing that this problem is NP-hard, and,\nmoreover, APX-hard.\n  We then develop a finer understanding of how quickly the problem becomes\ndifficult when going from undirected to mixed graphs. To this end, we consider\nthe parameterized complexity of the problem with respect to the number $k$ of\npreoriented arcs of $G$, a new form of parameterization.\n  We show that the problem can be solved in $n^{O(k)}$ and that a\n$(1-\\epsilon)$-approximation can be computed in $f(k,\\epsilon)n^{O(1)}$ for any\n$\\epsilon > 0$.", "published": "2025-06-19 09:44:55", "link": "http://arxiv.org/abs/2506.16171v1", "categories": ["cs.CC", "cs.DM"], "primary_category": "cs.CC"}
{"title": "Semantic Outlier Removal with Embedding Models and LLMs", "abstract": "Modern text processing pipelines demand robust methods to remove extraneous\ncontent while preserving a document's core message. Traditional approaches such\nas HTML boilerplate extraction or keyword filters often fail in multilingual\nsettings and struggle with context-sensitive nuances, whereas Large Language\nModels (LLMs) offer improved quality at high computational cost. We introduce\nSORE (Semantic Outlier Removal), a cost-effective, transparent method that\nleverages multilingual sentence embeddings and approximate nearest-neighbor\nsearch to identify and excise unwanted text segments. By first identifying core\ncontent via metadata embedding and then flagging segments that either closely\nmatch predefined outlier groups or deviate significantly from the core, SORE\nachieves near-LLM extraction precision at a fraction of the cost. Experiments\non HTML datasets demonstrate that SORE outperforms structural methods and yield\nhigh precision in diverse scenarios. Our system is currently deployed in\nproduction, processing millions of documents daily across multiple languages\nwhile maintaining both efficiency and accuracy. To facilitate reproducibility\nand further research, we release our implementation and evaluation datasets.", "published": "2025-06-19 23:06:12", "link": "http://arxiv.org/abs/2506.16644v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Revela: Dense Retriever Learning via Language Modeling", "abstract": "Dense retrievers play a vital role in accessing external and specialized\nknowledge to augment language models (LMs). Training dense retrievers typically\nrequires annotated query-document pairs, which are costly and hard to obtain in\nspecialized domains such as code-motivating growing interest in self-supervised\nretriever learning. Since LMs are trained to capture token-level dependencies\nthrough a self-supervised learning objective (i.e., next-token prediction), we\ncan analogously cast retrieval as learning dependencies among chunks of tokens.\nThis analogy naturally leads to the question: How can we adapt self-supervised\nlearning objectives in the spirit of language modeling to train retrievers?\n  To answer this question, we introduce Revela, a unified and scalable training\nframework for self-supervised retriever learning via language modeling. Revela\nmodels semantic dependencies among documents by conditioning next-token\nprediction on both local and cross-document context through an in-batch\nattention mechanism. This attention is weighted by retriever-computed\nsimilarity scores, enabling the retriever to be optimized as part of language\nmodeling. We evaluate Revela on both general-domain (BEIR) and domain-specific\n(CoIR) benchmarks across various retriever backbones. At a comparable parameter\nscale, Revela outperforms the previous best method with absolute improvements\nof 5.2 % (18.3 % relative) and 5.6 % (14.4 % relative) on NDCG@10,\nrespectively, underscoring its effectiveness. Performance increases with model\nsize, highlighting both the scalability of our approach and its promise for\nself-supervised retriever learning.", "published": "2025-06-19 19:13:59", "link": "http://arxiv.org/abs/2506.16552v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Agentic Personalisation of Cross-Channel Marketing Experiences", "abstract": "Consumer applications provide ample opportunities to surface and communicate\nvarious forms of content to users. From promotional campaigns for new features\nor subscriptions, to evergreen nudges for engagement, or personalised\nrecommendations; across e-mails, push notifications, and in-app surfaces. The\nconventional approach to orchestration for communication relies heavily on\nlabour-intensive manual marketer work, and inhibits effective personalisation\nof content, timing, frequency, and copy-writing. We formulate this task under a\nsequential decision-making framework, where we aim to optimise a modular\ndecision-making policy that maximises incremental engagement for any funnel\nevent. Our approach leverages a Difference-in-Differences design for Individual\nTreatment Effect estimation, and Thompson sampling to balance the\nexplore-exploit trade-off. We present results from a multi-service application,\nwhere our methodology has resulted in significant increases to a variety of\ngoal events across several product features, and is currently deployed across\n150 million users.", "published": "2025-06-19 16:07:31", "link": "http://arxiv.org/abs/2506.16429v1", "categories": ["cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Analyzing the Influence of Knowledge Graph Information on Relation Extraction", "abstract": "We examine the impact of incorporating knowledge graph information on the\nperformance of relation extraction models across a range of datasets. Our\nhypothesis is that the positions of entities within a knowledge graph provide\nimportant insights for relation extraction tasks. We conduct experiments on\nmultiple datasets, each varying in the number of relations, training examples,\nand underlying knowledge graphs. Our results demonstrate that integrating\nknowledge graph information significantly enhances performance, especially when\ndealing with an imbalance in the number of training examples for each relation.\nWe evaluate the contribution of knowledge graph-based features by combining\nestablished relation extraction methods with graph-aware Neural Bellman-Ford\nnetworks. These features are tested in both supervised and zero-shot settings,\ndemonstrating consistent performance improvements across various datasets.", "published": "2025-06-19 14:21:08", "link": "http://arxiv.org/abs/2506.16343v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Neural Prioritisation for Web Crawling", "abstract": "Given the vast scale of the Web, crawling prioritisation techniques based on\nlink graph traversal, popularity, link analysis, and textual content are\nfrequently applied to surface documents that are most likely to be valuable.\nWhile existing techniques are effective for keyword-based search, both\nretrieval methods and user search behaviours are shifting from keyword-based\nmatching to natural language semantic matching. The remarkable success of\napplying semantic matching and quality signals during ranking leads us to\nhypothesize that crawling could be improved by prioritizing Web pages with high\nsemantic quality. To investigate this, we propose a semantic quality-driven\nprioritisation technique to enhance the effectiveness of crawling and align the\ncrawler behaviour with recent shift towards natural language search. We embed\nsemantic understanding directly into the crawling process -- leveraging recent\nneural semantic quality estimators to prioritise the crawling frontier -- with\nthe goal of surfacing content that is semantically rich and valuable for modern\nsearch needs. Our experiments on the English subset of ClueWeb22-B and the\nResearchy Questions query set show that, compared to existing crawling\ntechniques, neural crawling policies significantly improve harvest rate,\nmaxNDCG, and search effectiveness during the early stages of crawling.\nMeanwhile, crawlers based on our proposed neural policies maintain comparable\nsearch performance on keyword queries from the MS MARCO Web Search query set.\nWhile this work does not propose a definitive and complete solution, it\npresents a forward-looking perspective on Web crawling and opens the door to a\nnew line of research on leveraging semantic analysis to effectively align\ncrawlers with the ongoing shift toward natural language search.", "published": "2025-06-19 08:59:21", "link": "http://arxiv.org/abs/2506.16146v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "GFlowGR: Fine-tuning Generative Recommendation Frameworks with Generative Flow Networks", "abstract": "Generative recommendations (GR), which usually include item tokenizers and\ngenerative Large Language Models (LLMs), have demonstrated remarkable success\nacross a wide range of scenarios. The majority of existing research efforts\nprimarily concentrate on developing powerful item tokenizers or advancing LLM\ndecoding strategies to attain superior performance. However, the critical\nfine-tuning step in GR frameworks, which is essential for adapting LLMs to\nrecommendation data, remains largely unexplored. Current approaches\npredominantly rely on either the next-token prediction loss of supervised\nfine-tuning (SFT) or recommendationspecific direct preference optimization\n(DPO) strategies. Both methods ignore the exploration of possible positive\nunobserved samples, which is commonly referred to as the exposure bias problem.\nTo mitigate this problem, this paper treats the GR as a multi-step generation\ntask and constructs a GFlowNets-based fine-tuning framework (GFlowGR). The\nproposed framework integrates collaborative knowledge from traditional\nrecommender systems to create an adaptive trajectory sampler and a\ncomprehensive reward model. Leveraging the diverse generation property of\nGFlowNets, along with sampling and heuristic weighting techniques, GFlowGR\nemerges as a promising approach to mitigate the exposure bias problem.\nExtensive empirical results on two real-world datasets and with two different\nGR backbones highlight the effectiveness and robustness of GFlowGR.", "published": "2025-06-19 08:04:31", "link": "http://arxiv.org/abs/2506.16114v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Vision-Guided Chunking Is All You Need: Enhancing RAG with Multimodal Document Understanding", "abstract": "Retrieval-Augmented Generation (RAG) systems have revolutionized information\nretrieval and question answering, but traditional text-based chunking methods\nstruggle with complex document structures, multi-page tables, embedded figures,\nand contextual dependencies across page boundaries. We present a novel\nmultimodal document chunking approach that leverages Large Multimodal Models\n(LMMs) to process PDF documents in batches while maintaining semantic coherence\nand structural integrity. Our method processes documents in configurable page\nbatches with cross-batch context preservation, enabling accurate handling of\ntables spanning multiple pages, embedded visual elements, and procedural\ncontent. We evaluate our approach on a curated dataset of PDF documents with\nmanually crafted queries, demonstrating improvements in chunk quality and\ndownstream RAG performance. Our vision-guided approach achieves better accuracy\ncompared to traditional vanilla RAG systems, with qualitative analysis showing\nsuperior preservation of document structure and semantic coherence.", "published": "2025-06-19 05:11:43", "link": "http://arxiv.org/abs/2506.16035v1", "categories": ["cs.LG", "cs.AI", "cs.IR"], "primary_category": "cs.LG"}
{"title": "SEP-GCN: Leveraging Similar Edge Pairs with Temporal and Spatial Contexts for Location-Based Recommender Systems", "abstract": "Recommender systems play a crucial role in enabling personalized content\ndelivery amidst the challenges of information overload and human mobility.\nAlthough conventional methods often rely on interaction matrices or graph-based\nretrieval, recent approaches have sought to exploit contextual signals such as\ntime and location. However, most existing models focus on node-level\nrepresentation or isolated edge attributes, underutilizing the relational\nstructure between interactions. We propose SEP-GCN, a novel graph-based\nrecommendation framework that learns from pairs of contextually similar\ninteraction edges, each representing a user-item check-in event. By identifying\nedge pairs that occur within similar temporal windows or geographic proximity,\nSEP-GCN augments the user-item graph with contextual similarity links. These\nlinks bridge distant but semantically related interactions, enabling improved\nlong-range information propagation. The enriched graph is processed via an\nedge-aware convolutional mechanism that integrates contextual similarity into\nthe message-passing process. This allows SEP-GCN to model user preferences more\naccurately and robustly, especially in sparse or dynamic environments.\nExperiments on benchmark data sets show that SEP-GCN consistently outperforms\nstrong baselines in both predictive accuracy and robustness.", "published": "2025-06-19 03:48:30", "link": "http://arxiv.org/abs/2506.16003v1", "categories": ["cs.IR", "cs.IT", "math.IT"], "primary_category": "cs.IR"}
{"title": "Empowering Graph-based Approximate Nearest Neighbor Search with Adaptive Awareness Capabilities", "abstract": "Approximate Nearest Neighbor Search (ANNS) in high-dimensional spaces finds\nextensive applications in databases, information retrieval, recommender\nsystems, etc. While graph-based methods have emerged as the leading solution\nfor ANNS due to their superior query performance, they still face several\nchallenges, such as struggling with local optima and redundant computations.\nThese issues arise because existing methods (i) fail to fully exploit the\ntopological information underlying the proximity graph G, and (ii) suffer from\nsevere distribution mismatches between the base data and queries in practice.\n  To this end, this paper proposes GATE, high-tier proximity Graph with\nAdaptive Topology and Query AwarEness, as a lightweight and adaptive module\natop the graph-based indexes to accelerate ANNS. Specifically, GATE formulates\nthe critical problem to identify an optimal entry point in the proximity graph\nfor a given query, facilitating faster online search. By leveraging the\ninherent clusterability of high-dimensional data, GATE first extracts a small\nset of hub nodes V as candidate entry points. Then, resorting to a contrastive\nlearning-based two-tower model, GATE encodes both the structural semantics\nunderlying G and the query-relevant features into the latent representations of\nthese hub nodes V. A navigation graph index on V is further constructed to\nminimize the model inference overhead. Extensive experiments demonstrate that\nGATE achieves a 1.2-2.0X speed-up in query performance compared to\nstate-of-the-art graph-based indexes.", "published": "2025-06-19 03:07:12", "link": "http://arxiv.org/abs/2506.15986v1", "categories": ["cs.DB", "cs.IR"], "primary_category": "cs.DB"}
{"title": "Covert Communication over Physically-Degraded Alarm Two-Way Channels", "abstract": "We study covert communications over binary-input discrete memoryless alarm\ntwo-way channels, in which two users interact through a two-way channel and\nattempt to hide the presence of their communication from an eavesdropping\nreceiver. The alarm two-way channel is one in which simultaneous transmissions\nby both users trigger an alarm at the eavesdropper, which captures the\nchallenges and opportunities of cooperation beyond interference management. In\nparticular, by characterizing the covert capacity region of two-way channels\nwhen using public time sharing, we show how cooperation strictly improves\nachievable covert communication throughputs. While our analysis falls short of\ncharacterizing the two-way covert capacity region for all two-way channels, we\nprovide general achievable and converse bounds that illuminate the cooperation\nmechanisms that benefit covertness and are tight for a physically-degraded\nalarm two-way channels. Because of the unique nature of covert communications,\nour analysis also shows that the coordination required to avoid triggering\nalarms comes asymptotically \"for free\". The key technical challenge that we\naddress is how to appropriately design auxiliary random variables in a\nmulti-user covert communication setting subject to the square root law.", "published": "2025-06-19 20:12:32", "link": "http://arxiv.org/abs/2506.16581v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Data Compression with Relative Entropy Coding", "abstract": "Over the last few years, machine learning unlocked previously infeasible\nfeatures for compression, such as providing guarantees for users' privacy or\ntailoring compression to specific data statistics (e.g., satellite images or\naudio recordings of animals) or users' audiovisual perception. This, in turn,\nhas led to an explosion of theoretical investigations and insights that aim to\ndevelop new fundamental theories, methods and algorithms better suited for\nmachine learning-based compressors.\n  In this thesis, I contribute to this trend by investigating relative entropy\ncoding, a mathematical framework that generalises classical source coding\ntheory. Concretely, relative entropy coding deals with the efficient\ncommunication of uncertain or randomised information. One of its key advantages\nis that it extends compression methods to continuous spaces and can thus be\nintegrated more seamlessly into modern machine learning pipelines than\nclassical quantisation-based approaches. Furthermore, it is a natural\nfoundation for developing advanced compression methods that are\nprivacy-preserving or account for the perceptual quality of the reconstructed\ndata.\n  The thesis considers relative entropy coding at three conceptual levels:\nAfter introducing the basics of the framework, (1) I prove results that provide\nnew, maximally tight fundamental limits to the communication and computational\nefficiency of relative entropy coding; (2) I use the theory of Poisson point\nprocesses to develop and analyse new relative entropy coding algorithms, whose\nperformance attains the theoretic optima and (3) I showcase the strong\npractical performance of relative entropy coding by applying it to image,\naudio, video and protein data compression using small, energy-efficient,\nprobabilistic neural networks called Bayesian implicit neural representations.", "published": "2025-06-19 13:31:45", "link": "http://arxiv.org/abs/2506.16309v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Optimal Online Bookmaking for Any Number of Outcomes", "abstract": "We study the Online Bookmaking problem, where a bookmaker dynamically updates\nbetting odds on the possible outcomes of an event. In each betting round, the\nbookmaker can adjust the odds based on the cumulative betting behavior of\ngamblers, aiming to maximize profit while mitigating potential loss. We show\nthat for any event and any number of betting rounds, in a worst-case setting\nover all possible gamblers and outcome realizations, the bookmaker's optimal\nloss is the largest root of a simple polynomial. Our solution shows that\nbookmakers can be as fair as desired while avoiding financial risk, and the\nexplicit characterization reveals an intriguing relation between the\nbookmaker's regret and Hermite polynomials. We develop an efficient algorithm\nthat computes the optimal bookmaking strategy: when facing an optimal gambler,\nthe algorithm achieves the optimal loss, and in rounds where the gambler is\nsuboptimal, it reduces the achieved loss to the optimal opportunistic loss, a\nnotion that is related to subgame perfect Nash equilibrium. The key technical\ncontribution to achieve these results is an explicit characterization of the\nBellman-Pareto frontier, which unifies the dynamic programming updates for\nBellman's value function with the multi-criteria optimization framework of the\nPareto frontier in the context of vector repeated games.", "published": "2025-06-19 12:11:58", "link": "http://arxiv.org/abs/2506.16253v1", "categories": ["cs.LG", "cs.GT", "cs.IT", "math.IT", "math.OC"], "primary_category": "cs.LG"}
{"title": "Graph-Cover-based Characterization of the Bethe Partition Function of Double-Edge Factor Graphs", "abstract": "For standard factor graphs (S-FGs) with non-negative real-valued local\nfunctions, Vontobel provided a combinatorial characterization of the Bethe\napproximation of the partition function, also known as the Bethe partition\nfunction, using finite graph covers. The proof of this characterization, i.e.,\nthe graph-cover theorem for S-FGs, heavily relied on the method of types.\n  In this paper, we study double-edge factor graphs (DE-FGs), a class of factor\ngraphs where each local function takes complex values and satisfies some\npositive semi-definiteness constraints. DE-FGs and their partition functions\nare particularly relevant for quantum information processing. Approximating the\npartition function of a DE-FG is more difficult than for an S-FG, as it\ninvolves summing complex values instead of non-negative real values. We develop\nthe sum-product algorithm (SPA) fixed-point-based Bethe approximation of the\npartition function. However, one cannot directly apply the method of types to\nprove a similar combinatorial characterization as in the case of S-FGs.\n  We provide a combinatorial characterization of the Bethe partition function\nin terms of finite graph covers for a class of DE-FGs that satisfy a specific,\neasily checkable condition. Towards proving this characterization, we apply a\nsuitable loop-calculus transform (LCT) to these graphs. Originally, the LCT was\nintroduced by Chertkov and Chernyak as a special linear transform for S-FGs and\nlater extended by Mori. Our proposed LCT is applicable for both DE-FGs and\nS-FGs and generalizes prior versions by handling zero-valued SPA fixed-point\nmessage components, which are common in DE-FGs.\n  Supported by numerical results, we conjecture that this combinatorial\ncharacterization of the Bethe partition function in terms of finite graph\ncovers holds more broadly for DE-FGs.", "published": "2025-06-19 12:08:54", "link": "http://arxiv.org/abs/2506.16250v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "All Kolmogorov complexity functions are optimal, but are some more optimal?", "abstract": "Kolmogorov (1965) defined the complexity of a string $x$ as the minimal\nlength of a program generating $x$. Obviously this definition depends on the\nchoice of the programming language. Kolmogorov noted that there exist\n\\emph{optimal} programming languages that make the complexity function minimal\nup to $O(1)$ additive terms, and we should take one of them -- but which one?\n  Is there a chance to agree on some specific programming language in this\ndefinition? Or at least should we add some other requirements to optimality?\nWhat can we achieve in this way?\n  In this paper we discuss different suggestions of this type that appeared\nsince 1965, specifically a stronger requirement of universality (and show that\nin many cases this does not change the set of complexity functions).", "published": "2025-06-19 09:56:38", "link": "http://arxiv.org/abs/2506.16180v1", "categories": ["cs.IT", "math.IT", "68Q30", "H.1.1"], "primary_category": "cs.IT"}
{"title": "End-to-End Learning of Probabilistic Constellation Shaping through Importance Sampling", "abstract": "Probabilistic constellation shaping enables easy rate adaption and has been\nproven to reduce the gap to Shannon capacity. Constellation point probabilities\nare optimized to maximize either the mutual information or the bit-wise mutual\ninformation. The optimization problem is however challenging even for simple\nchannel models. While autoencoder-based machine learning has been applied\nsuccessfully to solve this problem [1], it requires manual computation of\nadditional terms for the gradient which is an error-prone task. In this work,\nwe present novel loss functions for autoencoder-based learning of probabilistic\nconstellation shaping for coded modulation systems using automatic\ndifferentiation and importance sampling. We show analytically that our proposed\napproach also uses exact gradients of the constellation point probabilities for\nthe optimization. In simulations, our results closely match the results from\n[1] for the additive white Gaussian noise channel and a simplified model of the\nintensity-modulation direct-detection channel.", "published": "2025-06-19 07:35:48", "link": "http://arxiv.org/abs/2506.16098v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Information-computation trade-offs in non-linear transforms", "abstract": "In this work, we explore the interplay between information and computation in\nnon-linear transform-based compression for broad classes of modern\ninformation-processing tasks. We first investigate two emerging nonlinear data\ntransformation frameworks for image compression: Implicit Neural\nRepresentations (INRs) and 2D Gaussian Splatting (GS). We analyze their\nrepresentational properties, behavior under lossy compression, and convergence\ndynamics. Our results highlight key trade-offs between INR's compact,\nresolution-flexible neural field representations and GS's highly\nparallelizable, spatially interpretable fitting, providing insights for future\nhybrid and compression-aware frameworks. Next, we introduce the textual\ntransform that enables efficient compression at ultra-low bitrate regimes and\nsimultaneously enhances human perceptual satisfaction. When combined with the\nconcept of denoising via lossy compression, the textual transform becomes a\npowerful tool for denoising tasks. Finally, we present a Lempel-Ziv (LZ78)\n\"transform\", a universal method that, when applied to any member of a broad\ncompressor family, produces new compressors that retain the asymptotic\nuniversality guarantees of the LZ78 algorithm. Collectively, these three\ntransforms illuminate the fundamental trade-offs between coding efficiency and\ncomputational cost. We discuss how these insights extend beyond compression to\ntasks such as classification, denoising, and generative AI, suggesting new\npathways for using non-linear transformations to balance resource constraints\nand performance.", "published": "2025-06-19 01:13:04", "link": "http://arxiv.org/abs/2506.15948v1", "categories": ["cs.IT", "eess.IV", "math.IT"], "primary_category": "cs.IT"}
{"title": "Competing Bandits in Matching Markets via Super Stability", "abstract": "We study bandit learning in matching markets with two-sided reward\nuncertainty, extending prior research primarily focused on single-sided\nuncertainty. Leveraging the concept of `super-stability' from Irving (1994), we\ndemonstrate the advantage of the Extended Gale-Shapley (GS) algorithm over the\nstandard GS algorithm in achieving true stable matchings under incomplete\ninformation. By employing the Extended GS algorithm, our centralized algorithm\nattains a logarithmic pessimal stable regret dependent on an instance-dependent\nadmissible gap parameter. This algorithm is further adapted to a decentralized\nsetting with a constant regret increase. Finally, we establish a novel\ncentralized instance-dependent lower bound for binary stable regret,\nelucidating the roles of the admissible gap and super-stable matching in\ncharacterizing the complexity of stable matching with bandit feedback.", "published": "2025-06-19 00:03:20", "link": "http://arxiv.org/abs/2506.15926v1", "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Relational Deep Learning: Challenges, Foundations and Next-Generation Architectures", "abstract": "Graph machine learning has led to a significant increase in the capabilities\nof models that learn on arbitrary graph-structured data and has been applied to\nmolecules, social networks, recommendation systems, and transportation, among\nother domains. Data in multi-tabular relational databases can also be\nconstructed as 'relational entity graphs' for Relational Deep Learning (RDL) -\na new blueprint that enables end-to-end representation learning without\ntraditional feature engineering. Compared to arbitrary graph-structured data,\nrelational entity graphs have key properties: (i) their structure is defined by\nprimary-foreign key relationships between entities in different tables, (ii)\nthe structural connectivity is a function of the relational schema defining a\ndatabase, and (iii) the graph connectivity is temporal and heterogeneous in\nnature. In this paper, we provide a comprehensive review of RDL by first\nintroducing the representation of relational databases as relational entity\ngraphs, and then reviewing public benchmark datasets that have been used to\ndevelop and evaluate recent GNN-based RDL models. We discuss key challenges\nincluding large-scale multi-table integration and the complexities of modeling\ntemporal dynamics and heterogeneous data, while also surveying foundational\nneural network methods and recent architectural advances specialized for\nrelational entity graphs. Finally, we explore opportunities to unify these\ndistinct modeling challenges, highlighting how RDL converges multiple\nsub-fields in graph machine learning towards the design of foundation models\nthat can transform the processing of relational data.", "published": "2025-06-19 23:51:38", "link": "http://arxiv.org/abs/2506.16654v1", "categories": ["cs.LG", "cs.AI", "cs.DB"], "primary_category": "cs.LG"}
{"title": "LLMs in Coding and their Impact on the Commercial Software Engineering Landscape", "abstract": "Large-language-model coding tools are now mainstream in software engineering.\nBut as these same tools move human effort up the development stack, they\npresent fresh dangers: 10% of real prompts leak private data, 42% of generated\nsnippets hide security flaws, and the models can even ``agree'' with wrong\nideas, a trait called sycophancy. We argue that firms must tag and review every\nAI-generated line of code, keep prompts and outputs inside private or\non-premises deployments, obey emerging safety regulations, and add tests that\ncatch sycophantic answers -- so they can gain speed without losing security and\naccuracy.", "published": "2025-06-19 23:43:54", "link": "http://arxiv.org/abs/2506.16653v1", "categories": ["cs.SE", "cs.AI", "cs.LG"], "primary_category": "cs.SE"}
{"title": "A Distributional-Lifting Theorem for PAC Learning", "abstract": "The apparent difficulty of efficient distribution-free PAC learning has led\nto a large body of work on distribution-specific learning. Distributional\nassumptions facilitate the design of efficient algorithms but also limit their\nreach and relevance. Towards addressing this, we prove a distributional-lifting\ntheorem: This upgrades a learner that succeeds with respect to a limited\ndistribution family $\\mathcal{D}$ to one that succeeds with respect to any\ndistribution $D^\\star$, with an efficiency overhead that scales with the\ncomplexity of expressing $D^\\star$ as a mixture of distributions in\n$\\mathcal{D}$.\n  Recent work of Blanc, Lange, Malik, and Tan considered the special case of\nlifting uniform-distribution learners and designed a lifter that uses a\nconditional sample oracle for $D^\\star$, a strong form of access not afforded\nby the standard PAC model. Their approach, which draws on ideas from\nsemi-supervised learning, first learns $D^\\star$ and then uses this information\nto lift.\n  We show that their approach is information-theoretically intractable with\naccess only to random examples, thereby giving formal justification for their\nuse of the conditional sample oracle. We then take a different approach that\nsidesteps the need to learn $D^\\star$, yielding a lifter that works in the\nstandard PAC model and enjoys additional advantages: it works for all base\ndistribution families, preserves the noise tolerance of learners, has better\nsample complexity, and is simpler.", "published": "2025-06-19 23:28:38", "link": "http://arxiv.org/abs/2506.16651v1", "categories": ["cs.LG", "cs.CC", "cs.DS"], "primary_category": "cs.LG"}
{"title": "Latent Noise Injection for Private and Statistically Aligned Synthetic Data Generation", "abstract": "Synthetic Data Generation has become essential for scalable,\nprivacy-preserving statistical analysis. While standard approaches based on\ngenerative models, such as Normalizing Flows, have been widely used, they often\nsuffer from slow convergence in high-dimensional settings, frequently\nconverging more slowly than the canonical $1/\\sqrt{n}$ rate when approximating\nthe true data distribution.\n  To overcome these limitations, we propose a Latent Noise Injection method\nusing Masked Autoregressive Flows (MAF). Instead of directly sampling from the\ntrained model, our method perturbs each data point in the latent space and maps\nit back to the data domain. This construction preserves a one to one\ncorrespondence between observed and synthetic data, enabling synthetic outputs\nthat closely reflect the underlying distribution, particularly in challenging\nhigh-dimensional regimes where traditional sampling struggles.\n  Our procedure satisfies local $(\\epsilon, \\delta)$-differential privacy and\nintroduces a single perturbation parameter to control the privacy-utility\ntrade-off. Although estimators based on individual synthetic datasets may\nconverge slowly, we show both theoretically and empirically that aggregating\nacross $K$ studies in a meta analysis framework restores classical efficiency\nand yields consistent, reliable inference. We demonstrate that with a\nwell-calibrated perturbation parameter, Latent Noise Injection achieves strong\nstatistical alignment with the original data and robustness against membership\ninference attacks. These results position our method as a compelling\nalternative to conventional flow-based sampling for synthetic data sharing in\ndecentralized and privacy-sensitive domains, such as biomedical research.", "published": "2025-06-19 22:22:57", "link": "http://arxiv.org/abs/2506.16636v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Learning Causally Predictable Outcomes from Psychiatric Longitudinal Data", "abstract": "Causal inference in longitudinal biomedical data remains a central challenge,\nespecially in psychiatry, where symptom heterogeneity and latent confounding\nfrequently undermine classical estimators. Most existing methods for treatment\neffect estimation presuppose a fixed outcome variable and address confounding\nthrough observed covariate adjustment. However, the assumption of\nunconfoundedness may not hold for a fixed outcome in practice. To address this\nfoundational limitation, we directly optimize the outcome definition to\nmaximize causal identifiability. Our DEBIAS (Durable Effects with\nBackdoor-Invariant Aggregated Symptoms) algorithm learns non-negative,\nclinically interpretable weights for outcome aggregation, maximizing durable\ntreatment effects and empirically minimizing both observed and latent\nconfounding by leveraging the time-limited direct effects of prior treatments\nin psychiatric longitudinal data. The algorithm also furnishes an empirically\nverifiable test for outcome unconfoundedness. DEBIAS consistently outperforms\nstate-of-the-art methods in recovering causal effects for clinically\ninterpretable composite outcomes across comprehensive experiments in depression\nand schizophrenia.", "published": "2025-06-19 21:56:30", "link": "http://arxiv.org/abs/2506.16629v1", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Initial Investigation of LLM-Assisted Development of Rule-Based Clinical NLP System", "abstract": "Despite advances in machine learning (ML) and large language models (LLMs),\nrule-based natural language processing (NLP) systems remain active in clinical\nsettings due to their interpretability and operational efficiency. However,\ntheir manual development and maintenance are labor-intensive, particularly in\ntasks with large linguistic variability. To overcome these limitations, we\nproposed a novel approach employing LLMs solely during the rule-based systems\ndevelopment phase. We conducted the initial experiments focusing on the first\ntwo steps of developing a rule-based NLP pipeline: find relevant snippets from\nthe clinical note; extract informative keywords from the snippets for the\nrule-based named entity recognition (NER) component. Our experiments\ndemonstrated exceptional recall in identifying clinically relevant text\nsnippets (Deepseek: 0.98, Qwen: 0.99) and 1.0 in extracting key terms for NER.\nThis study sheds light on a promising new direction for NLP development,\nenabling semi-automated or automated development of rule-based systems with\nsignificantly faster, more cost-effective, and transparent execution compared\nwith deep learning model-based solutions.", "published": "2025-06-19 21:55:33", "link": "http://arxiv.org/abs/2506.16628v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distribution Parameter Actor-Critic: Shifting the Agent-Environment Boundary for Diverse Action Spaces", "abstract": "We introduce a novel reinforcement learning (RL) framework that treats\ndistribution parameters as actions, redefining the boundary between agent and\nenvironment. This reparameterization makes the new action space continuous,\nregardless of the original action type (discrete, continuous, mixed, etc.).\nUnder this new parameterization, we develop a generalized deterministic policy\ngradient estimator, Distribution Parameter Policy Gradient (DPPG), which has\nlower variance than the gradient in the original action space. Although\nlearning the critic over distribution parameters poses new challenges, we\nintroduce interpolated critic learning (ICL), a simple yet effective strategy\nto enhance learning, supported by insights from bandit settings. Building on\nTD3, a strong baseline for continuous control, we propose a practical\nDPPG-based actor-critic algorithm, Distribution Parameter Actor-Critic (DPAC).\nEmpirically, DPAC outperforms TD3 in MuJoCo continuous control tasks from\nOpenAI Gym and DeepMind Control Suite, and demonstrates competitive performance\non the same environments with discretized action spaces.", "published": "2025-06-19 21:19:19", "link": "http://arxiv.org/abs/2506.16608v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SlepNet: Spectral Subgraph Representation Learning for Neural Dynamics", "abstract": "Graph neural networks have been useful in machine learning on\ngraph-structured data, particularly for node classification and some types of\ngraph classification tasks. However, they have had limited use in representing\npatterning of signals over graphs. Patterning of signals over graphs and in\nsubgraphs carries important information in many domains including neuroscience.\nNeural signals are spatiotemporally patterned, high dimensional and difficult\nto decode. Graph signal processing and associated GCN models utilize the graph\nFourier transform and are unable to efficiently represent spatially or\nspectrally localized signal patterning on graphs. Wavelet transforms have shown\npromise here, but offer non-canonical representations and cannot be tightly\nconfined to subgraphs. Here we propose SlepNet, a novel GCN architecture that\nuses Slepian bases rather than graph Fourier harmonics. In SlepNet, the Slepian\nharmonics optimally concentrate signal energy on specifically relevant\nsubgraphs that are automatically learned with a mask. Thus, they can produce\ncanonical and highly resolved representations of neural activity, focusing\nenergy of harmonics on areas of the brain which are activated. We evaluated\nSlepNet across three fMRI datasets, spanning cognitive and visual tasks, and\ntwo traffic dynamics datasets, comparing its performance against conventional\nGNNs and graph signal processing constructs. SlepNet outperforms the baselines\nin all datasets. Moreover, the extracted representations of signal patterns\nfrom SlepNet offers more resolution in distinguishing between similar patterns,\nand thus represent brain signaling transients as informative trajectories. Here\nwe have shown that these extracted trajectory representations can be used for\nother downstream untrained tasks. Thus we establish that SlepNet is useful both\nfor prediction and representation learning in spatiotemporal data.", "published": "2025-06-19 21:03:52", "link": "http://arxiv.org/abs/2506.16602v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FLAME: Towards Federated Fine-Tuning Large Language Models Through Adaptive SMoE", "abstract": "Existing resource-adaptive LoRA federated fine-tuning methods enable clients\nto fine-tune models using compressed versions of global LoRA matrices, in order\nto accommodate various compute resources across clients. This compression\nrequirement will lead to suboptimal performance due to information loss. To\naddress this, we propose FLAME, a novel federated learning framework based on\nthe Sparse Mixture-of-Experts (SMoE) architecture. Unlike prior approaches,\nFLAME retains full (uncompressed) global LoRA matrices and achieves client-side\nadaptability by varying the number of activated experts per client. However,\nincorporating SMoE into federated learning introduces unique challenges,\nspecifically, the mismatch in output magnitude from partial expert activation\nand the imbalance in expert training quality across clients. FLAME tackles\nthese challenges through a lightweight rescaling mechanism and an\nactivation-aware aggregation scheme. Empirical results across diverse\ncomputational settings demonstrate that FLAME consistently outperforms existing\nmethods, providing a robust and effective solution for resource-adaptive\nfederated learning.", "published": "2025-06-19 21:02:19", "link": "http://arxiv.org/abs/2506.16600v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Energy-Based Transfer for Reinforcement Learning", "abstract": "Reinforcement learning algorithms often suffer from poor sample efficiency,\nmaking them challenging to apply in multi-task or continual learning settings.\nEfficiency can be improved by transferring knowledge from a previously trained\nteacher policy to guide exploration in new but related tasks. However, if the\nnew task sufficiently differs from the teacher's training task, the transferred\nguidance may be sub-optimal and bias exploration toward low-reward behaviors.\nWe propose an energy-based transfer learning method that uses\nout-of-distribution detection to selectively issue guidance, enabling the\nteacher to intervene only in states within its training distribution. We\ntheoretically show that energy scores reflect the teacher's state-visitation\ndensity and empirically demonstrate improved sample efficiency and performance\nacross both single-task and multi-task settings.", "published": "2025-06-19 20:25:52", "link": "http://arxiv.org/abs/2506.16590v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Measuring (a Sufficient) World Model in LLMs: A Variance Decomposition Framework", "abstract": "Understanding whether large language models (LLMs) possess a world model-a\nstructured understanding of the world that supports generalization beyond\nsurface-level patterns-is central to assessing their reliability, especially in\nhigh-stakes applications. We propose a formal framework for evaluating whether\nan LLM exhibits a sufficiently robust world model, defined as producing\nconsistent outputs across semantically equivalent prompts while distinguishing\nbetween prompts that express different intents. We introduce a new evaluation\napproach to measure this that decomposes model response variability into three\ncomponents: variability due to user purpose, user articulation, and model\ninstability. An LLM with a strong world model should attribute most of the\nvariability in its responses to changes in foundational purpose rather than\nsuperficial changes in articulation. This approach allows us to quantify how\nmuch of a model's behavior is semantically grounded rather than driven by model\ninstability or alternative wording. We apply this framework to evaluate LLMs\nacross diverse domains. Our results show how larger models attribute a greater\nshare of output variability to changes in user purpose, indicating a more\nrobust world model. This improvement is not uniform, however: larger models do\nnot consistently outperform smaller ones across all domains, and their\nadvantage in robustness is often modest. These findings highlight the\nimportance of moving beyond accuracy-based benchmarks toward semantic\ndiagnostics that more directly assess the structure and stability of a model's\ninternal understanding of the world.", "published": "2025-06-19 20:19:18", "link": "http://arxiv.org/abs/2506.16584v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50, 68T05", "I.2.7; I.2.6; I.5.1"], "primary_category": "cs.CL"}
{"title": "One Sample is Enough to Make Conformal Prediction Robust", "abstract": "Given any model, conformal prediction (CP) returns prediction sets guaranteed\nto include the true label with high adjustable probability. Robust CP (RCP)\nextends this to inputs with worst-case noise. A well-established approach is to\nuse randomized smoothing for RCP since it is applicable to any black-box model\nand provides smaller sets compared to deterministic methods. However, current\nsmoothing-based RCP requires many model forward passes per each input which is\ncomputationally expensive. We show that conformal prediction attains some\nrobustness even with a forward pass on a single randomly perturbed input. Using\nany binary certificate we propose a single sample robust CP (RCP1). Our\napproach returns robust sets with smaller average set size compared to SOTA\nmethods which use many (e.g. around 100) passes per input. Our key insight is\nto certify the conformal prediction procedure itself rather than individual\nscores. Our approach is agnostic to the setup (classification and regression).\nWe further extend our approach to smoothing-based robust conformal risk\ncontrol.", "published": "2025-06-19 19:14:25", "link": "http://arxiv.org/abs/2506.16553v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Free Probabilistic Framework for Analyzing the Transformer-based Language Models", "abstract": "We outline an operator-theoretic framework for analyzing transformer-based\nlanguage models using the tools of free probability theory. By representing\ntoken embeddings and attention mechanisms as self-adjoint operators in a racial\nprobability space, we reinterpret attention as a non-commutative convolution\nand view the layer-wise propagation of representations as an evolution governed\nby free additive convolution. This formalism reveals a spectral dynamical\nsystem underpinning deep transformer stacks and offers insight into their\ninductive biases, generalization behavior, and entropy dynamics. We derive a\ngeneralization bound based on free entropy and demonstrate that the spectral\ntrace of transformer layers evolves predictably with depth. Our approach\nbridges neural architecture with non-commutative harmonic analysis, enabling\nprincipled analysis of information flow and structural complexity in large\nlanguage models", "published": "2025-06-19 19:13:02", "link": "http://arxiv.org/abs/2506.16550v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Mr. Snuffleupagus at SemEval-2025 Task 4: Unlearning Factual Knowledge from LLMs Using Adaptive RMU", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding and generation. However, their tendency to\nmemorize training data raises concerns regarding privacy, copyright compliance,\nand security, particularly in cases involving Personally Identifiable\nInformation (PII). Effective machine unlearning techniques are essential to\nmitigate these risks, yet existing methods remain underdeveloped for LLMs due\nto their open-ended output space. In this work, we apply the Adaptive\nRepresentation Misdirection Unlearning (RMU) technique to unlearn sensitive\ninformation from LLMs. Through extensive experiments, we analyze the effects of\nunlearning across different decoder layers to determine the most effective\nregions for sensitive information removal. Our technique ranked 4th on the\nofficial leaderboard of both 1B parameter and 7B parameter models.", "published": "2025-06-19 19:06:44", "link": "http://arxiv.org/abs/2506.16548v1", "categories": ["cs.LG", "I.2.7"], "primary_category": "cs.LG"}
{"title": "BIDA: A Bi-level Interaction Decision-making Algorithm for Autonomous Vehicles in Dynamic Traffic Scenarios", "abstract": "In complex real-world traffic environments, autonomous vehicles (AVs) need to\ninteract with other traffic participants while making real-time and\nsafety-critical decisions accordingly. The unpredictability of human behaviors\nposes significant challenges, particularly in dynamic scenarios, such as\nmulti-lane highways and unsignalized T-intersections. To address this gap, we\ndesign a bi-level interaction decision-making algorithm (BIDA) that integrates\ninteractive Monte Carlo tree search (MCTS) with deep reinforcement learning\n(DRL), aiming to enhance interaction rationality, efficiency and safety of AVs\nin dynamic key traffic scenarios. Specifically, we adopt three types of DRL\nalgorithms to construct a reliable value network and policy network, which\nguide the online deduction process of interactive MCTS by assisting in value\nupdate and node selection. Then, a dynamic trajectory planner and a trajectory\ntracking controller are designed and implemented in CARLA to ensure smooth\nexecution of planned maneuvers. Experimental evaluations demonstrate that our\nBIDA not only enhances interactive deduction and reduces computational costs,\nbut also outperforms other latest benchmarks, which exhibits superior safety,\nefficiency and interaction rationality under varying traffic conditions.", "published": "2025-06-19 19:03:40", "link": "http://arxiv.org/abs/2506.16546v1", "categories": ["cs.RO", "cs.AI", "cs.ET", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Aligning ASR Evaluation with Human and LLM Judgments: Intelligibility Metrics Using Phonetic, Semantic, and NLI Approaches", "abstract": "Traditional ASR metrics like WER and CER fail to capture intelligibility,\nespecially for dysarthric and dysphonic speech, where semantic alignment\nmatters more than exact word matches. ASR systems struggle with these speech\ntypes, often producing errors like phoneme repetitions and imprecise\nconsonants, yet the meaning remains clear to human listeners. We identify two\nkey challenges: (1) Existing metrics do not adequately reflect intelligibility,\nand (2) while LLMs can refine ASR output, their effectiveness in correcting ASR\ntranscripts of dysarthric speech remains underexplored. To address this, we\npropose a novel metric integrating Natural Language Inference (NLI) scores,\nsemantic similarity, and phonetic similarity. Our ASR evaluation metric\nachieves a 0.890 correlation with human judgments on Speech Accessibility\nProject data, surpassing traditional methods and emphasizing the need to\nprioritize intelligibility over error-based measures.", "published": "2025-06-19 18:21:19", "link": "http://arxiv.org/abs/2506.16528v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Improvement of Nuclide Detection through Graph Spectroscopic Analysis Framework and its Application to Nuclear Facility Upset Detection", "abstract": "We present a method to improve the detection limit for radionuclides using\nspectroscopic radiation detectors and the arrival time of each detected\nradiation quantum. We enable this method using a neural network with an\nattention mechanism. We illustrate the method on the detection of Cesium\nrelease from a nuclear facility during an upset, and our method shows $2\\times$\nimprovement over the traditional spectroscopic method. We hypothesize that our\nmethod achieves this performance increase by modulating its detection\nprobability by the overall rate of probable detections, specifically by\nadapting detection thresholds based on temporal event distributions and local\nspectral features, and show evidence to this effect. We believe this method is\napplicable broadly and may be more successful for radionuclides with more\ncomplicated decay chains than Cesium; we also note that our method can\ngeneralize beyond the addition of arrival time and could integrate other data\nabout each detection event, such as pulse quality, location in detector, or\neven combining the energy and time from detections in different detectors.", "published": "2025-06-19 18:06:10", "link": "http://arxiv.org/abs/2506.16522v1", "categories": ["physics.ins-det", "cs.LG", "physics.data-an"], "primary_category": "physics.ins-det"}
{"title": "Robust Reward Modeling via Causal Rubrics", "abstract": "Reward models (RMs) are fundamental to aligning Large Language Models (LLMs)\nvia human feedback, yet they often suffer from reward hacking. They tend to\nlatch on to superficial or spurious attributes, such as response length or\nformatting, mistaking these cues learned from correlations in training data for\nthe true causal drivers of quality (e.g., factuality, relevance). This occurs\nbecause standard training objectives struggle to disentangle these factors,\nleading to brittle RMs and misaligned policies. We introduce Crome (Causally\nRobust Reward Modeling), a novel framework grounded in an explicit causal model\ndesigned to mitigate reward hacking. Crome employs the following synthetic\ntargeted augmentations during training: (1) Causal Augmentations, which are\npairs that differ along specific causal attributes, to enforce sensitivity\nalong each causal attribute individually, and (2) Neutral Augmentations, which\nare tie-label pairs varying primarily in spurious attributes, to enforce\ninvariance along spurious attributes. Notably, our augmentations are produced\nwithout any knowledge of spurious factors, via answer interventions only along\ncausal rubrics, that are identified by querying an oracle LLM. Empirically,\nCrome significantly outperforms standard baselines on RewardBench, improving\naverage accuracy by up to 5.4% and achieving gains of up to 13.2% and 7.2% in\nspecific categories. The robustness of Crome is further testified by the\nconsistent gains obtained in a Best-of-N inference setting across increasing N,\nacross various benchmarks, including the popular RewardBench (covering chat,\nchat-hard, safety, and reasoning tasks), the safety-focused WildGuardTest, and\nthe reasoning-specific GSM8k.", "published": "2025-06-19 17:59:47", "link": "http://arxiv.org/abs/2506.16507v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SparseLoRA: Accelerating LLM Fine-Tuning with Contextual Sparsity", "abstract": "Fine-tuning LLMs is both computationally and memory-intensive. While\nparameter-efficient fine-tuning methods, such as QLoRA and DoRA, reduce the\nnumber of trainable parameters and lower memory usage, they do not decrease\ncomputational cost. In some cases, they may even slow down fine-tuning. In this\npaper, we introduce SparseLoRA, a method that accelerates LLM fine-tuning\nthrough contextual sparsity. We propose a lightweight, training-free SVD\nsparsity estimator that dynamically selects a sparse subset of weights for loss\nand gradient computation. Also, we systematically analyze and address\nsensitivity across layers, tokens, and training steps. Our experimental results\nshow that SparseLoRA reduces computational cost by up to 2.2 times and a\nmeasured speedup of up to 1.6 times while maintaining accuracy across various\ndownstream tasks, including commonsense and arithmetic reasoning, code\ngeneration, and instruction following.", "published": "2025-06-19 17:53:34", "link": "http://arxiv.org/abs/2506.16500v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SemAgent: A Semantics Aware Program Repair Agent", "abstract": "Large Language Models (LLMs) have shown impressive capabilities in downstream\nsoftware engineering tasks such as Automated Program Repair (APR). In\nparticular, there has been a lot of research on repository-level\nissue-resolution benchmarks such as SWE-Bench. Although there has been\nsignificant progress on this topic, we notice that in the process of solving\nsuch issues, existing agentic systems tend to hyper-localize on immediately\nsuspicious lines of code and fix them in isolation, without a deeper\nunderstanding of the issue semantics, code semantics, or execution semantics.\nConsequently, many existing systems generate patches that overfit to the user\nissue, even when a more general fix is preferable. To address this limitation,\nwe introduce SemAgent, a novel workflow-based procedure that leverages issue,\ncode, and execution semantics to generate patches that are complete -\nidentifying and fixing all lines relevant to the issue. We achieve this through\na novel pipeline that (a) leverages execution semantics to retrieve relevant\ncontext, (b) comprehends issue-semantics via generalized abstraction, (c)\nisolates code-semantics within the context of this abstraction, and (d)\nleverages this understanding in a two-stage architecture: a repair stage that\nproposes fine-grained fixes, followed by a reviewer stage that filters relevant\nfixes based on the inferred issue-semantics. Our evaluations show that our\nmethodology achieves a solve rate of 44.66% on the SWEBench-Lite benchmark\nbeating all other workflow-based approaches, and an absolute improvement of\n7.66% compared to our baseline, which lacks such deep semantic understanding.\nWe note that our approach performs particularly well on issues requiring\nmulti-line reasoning (and editing) and edge-case handling, suggesting that\nincorporating issue and code semantics into APR pipelines can lead to robust\nand semantically consistent repairs.", "published": "2025-06-19 23:27:58", "link": "http://arxiv.org/abs/2506.16650v1", "categories": ["cs.SE", "cs.AI", "cs.MA"], "primary_category": "cs.SE"}
{"title": "eCAV: An Edge-Assisted Evaluation Platform for Connected Autonomous Vehicles", "abstract": "As autonomous vehicles edge closer to widespread adoption, enhancing road\nsafety through collision avoidance and minimization of collateral damage\nbecomes imperative. Vehicle-to-everything (V2X) technologies, which include\nvehicle-to-vehicle (V2V), vehicle-to-infrastructure (V2I), and vehicle-to-cloud\n(V2C), are being proposed as mechanisms to achieve this safety improvement.\n  Simulation-based testing is crucial for early-stage evaluation of Connected\nAutonomous Vehicle (CAV) control systems, offering a safer and more\ncost-effective alternative to real-world tests. However, simulating large 3D\nenvironments with many complex single- and multi-vehicle sensors and\ncontrollers is computationally intensive. There is currently no evaluation\nframework that can effectively evaluate realistic scenarios involving large\nnumbers of autonomous vehicles.\n  We propose eCAV -- an efficient, modular, and scalable evaluation platform to\nfacilitate both functional validation of algorithmic approaches to increasing\nroad safety, as well as performance prediction of algorithms of various V2X\ntechnologies, including a futuristic Vehicle-to-Edge control plane and\ncorrespondingly designed control algorithms. eCAV can model up to 256 vehicles\nrunning individual control algorithms without perception enabled, which is\n$8\\times$ more vehicles than what is possible with state-of-the-art\nalternatives. %faster than state-of-the-art alternatives that can simulate\n$8\\times$ fewer vehicles. With perception enabled, eCAV simulates up to 64\nvehicles with a step time under 800ms, which is $4\\times$ more and $1.5\\times$\nfaster than the state-of-the-art OpenCDA framework.", "published": "2025-06-19 18:32:00", "link": "http://arxiv.org/abs/2506.16535v1", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Goal-conditioned Hierarchical Reinforcement Learning for Sample-efficient and Safe Autonomous Driving at Intersections", "abstract": "Reinforcement learning (RL) exhibits remarkable potential in addressing\nautonomous driving tasks. However, it is difficult to train a sample-efficient\nand safe policy in complex scenarios. In this article, we propose a novel\nhierarchical reinforcement learning (HRL) framework with a goal-conditioned\ncollision prediction (GCCP) module. In the hierarchical structure, the GCCP\nmodule predicts collision risks according to different potential subgoals of\nthe ego vehicle. A high-level decision-maker choose the best safe subgoal. A\nlow-level motion-planner interacts with the environment according to the\nsubgoal. Compared to traditional RL methods, our algorithm is more\nsample-efficient, since its hierarchical structure allows reusing the policies\nof subgoals across similar tasks for various navigation scenarios. In\nadditional, the GCCP module's ability to predict both the ego vehicle's and\nsurrounding vehicles' future actions according to different subgoals, ensures\nthe safety of the ego vehicle throughout the decision-making process.\nExperimental results demonstrate that the proposed method converges to an\noptimal policy faster and achieves higher safety than traditional RL methods.", "published": "2025-06-19 14:14:55", "link": "http://arxiv.org/abs/2506.16336v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Towards Emergency Scenarios: An Integrated Decision-making Framework of Multi-lane Platoon Reorganization", "abstract": "To enhance the ability for vehicle platoons to respond to emergency\nscenarios, a platoon distribution reorganization decision-making framework is\nproposed. This framework contains platoon distribution layer, vehicle\ncooperative decision-making layer and vehicle planning and control layer.\nFirstly, a reinforcement-learning-based platoon distribution model is\npresented, where a risk potential field is established to quantitatively assess\ndriving risks, and a reward function tailored to the platoon reorganization\nprocess is constructed. Then, a coalition-game-based vehicle cooperative\ndecision-making model is put forward, modeling the cooperative relationships\namong vehicles through dividing coalitions and generating the optimal decision\nresults for each vehicle. Additionally, a novel graph-theory-based Platoon\nDisposition Index (PDI) is incorporated into the game reward function to\nmeasure the platoon's distribution state during the reorganization process, in\norder to accelerating the reorganization process. Finally, the validation of\nthe proposed framework is conducted in two high-risk scenarios under random\ntraffic flows. The results show that, compared to the baseline models, the\nproposed method can significantly reduce the collision rate and improve driving\nefficiency. Moreover, the model with PDI can significantly decrease the platoon\nformation reorganization time and improve the reorganization efficiency.", "published": "2025-06-19 13:35:27", "link": "http://arxiv.org/abs/2506.16311v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Coordination of Electrical and Heating Resources by Self-Interested Agents", "abstract": "With the rise of distributed energy resources and sector coupling,\ndistributed optimization can be a sensible approach to coordinate decentralized\nenergy resources. Further, district heating, heat pumps, cogeneration, and\nsharing concepts like local energy communities introduce the potential to\noptimize heating and electricity output simultaneously. To solve this issue, we\ntackle the distributed multi-energy scheduling optimization problem, which\ndescribes the optimization of distributed energy generators over multiple time\nsteps to reach a specific target schedule. This work describes a novel\ndistributed hybrid algorithm as a solution approach. This approach is based on\nthe heuristics of gossiping and local search and can simultaneously optimize\nthe private objective of the participants and the collective objective,\nconsidering multiple energy sectors. We show that the algorithm finds globally\nnear-optimal solutions while protecting the stakeholders' economic goals and\nthe plants' technical properties. Two test cases representing pure electrical\nand gas-based technologies are evaluated.", "published": "2025-06-19 12:53:14", "link": "http://arxiv.org/abs/2506.16277v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Solving Zero-Sum Convex Markov Games", "abstract": "We contribute the first provable guarantees of global convergence to Nash\nequilibria (NE) in two-player zero-sum convex Markov games (cMGs) by using\nindependent policy gradient methods. Convex Markov games, recently defined by\nGemp et al. (2024), extend Markov decision processes to multi-agent settings\nwith preferences that are convex over occupancy measures, offering a broad\nframework for modeling generic strategic interactions. However, even the\nfundamental min-max case of cMGs presents significant challenges, including\ninherent nonconvexity, the absence of Bellman consistency, and the complexity\nof the infinite horizon.\n  We follow a two-step approach. First, leveraging properties of\nhidden-convex--hidden-concave functions, we show that a simple nonconvex\nregularization transforms the min-max optimization problem into a\nnonconvex-proximal Polyak-Lojasiewicz (NC-pPL) objective. Crucially, this\nregularization can stabilize the iterates of independent policy gradient\nmethods and ultimately lead them to converge to equilibria. Second, building on\nthis reduction, we address the general constrained min-max problems under\nNC-pPL and two-sided pPL conditions, providing the first global convergence\nguarantees for stochastic nested and alternating gradient descent-ascent\nmethods, which we believe may be of independent interest.", "published": "2025-06-19 08:12:02", "link": "http://arxiv.org/abs/2506.16120v1", "categories": ["cs.GT", "cs.LG", "cs.MA", "math.OC"], "primary_category": "cs.GT"}
{"title": "Autocratic strategies in Cournot oligopoly game", "abstract": "An oligopoly is a market in which the price of a goods is controlled by a few\nfirms. Cournot introduced the simplest game-theoretic model of oligopoly, where\nprofit-maximizing behavior of each firm results in market failure. Furthermore,\nwhen the Cournot oligopoly game is infinitely repeated, firms can tacitly\ncollude to monopolize the market. Such tacit collusion is realized by the same\nmechanism as direct reciprocity in the repeated prisoner's dilemma game, where\nmutual cooperation can be realized whereas defection is favorable for both\nprisoners in one-shot game. Recently, in the repeated prisoner's dilemma game,\na class of strategies called zero-determinant strategies attracts much\nattention in the context of direct reciprocity. Zero-determinant strategies are\nautocratic strategies which unilaterally control payoffs of players. There were\nmany attempts to find zero-determinant strategies in other games and to extend\nthem so as to apply them to broader situations. In this paper, first, we show\nthat zero-determinant strategies exist even in the repeated Cournot oligopoly\ngame. Especially, we prove that an averagely unbeatable zero-determinant\nstrategy exists, which is guaranteed to obtain the average payoff of the\nopponents. Second, we numerically show that the averagely unbeatable\nzero-determinant strategy can be used to promote collusion when it is used\nagainst an adaptively learning player, whereas it cannot promote collusion when\nit is used against two adaptively learning players. Our findings elucidate some\nnegative impact of zero-determinant strategies in oligopoly market.", "published": "2025-06-19 05:23:01", "link": "http://arxiv.org/abs/2506.16038v1", "categories": ["physics.soc-ph", "cs.GT", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "physics.soc-ph"}
{"title": "Quasi-Monte Carlo with one categorical variable", "abstract": "We study randomized quasi-Monte Carlo (RQMC) estimation of a multivariate\nintegral where one of the variables takes only a finite number of values. This\nproblem arises when the variable of integration is drawn from a mixture\ndistribution as is common in importance sampling and also arises in some recent\nwork on transport maps. We find that when integration error decreases at an\nRQMC rate that it is then beneficial to oversample the smallest mixture\ncomponents instead of using a proportional allocation. We also find that for\nthe most accurate RQMC sampling methods, it is advantageous to arrange that our\n$n=2^m$ randomized Sobol' points split into subsample sizes that are also\npowers of~$2$.", "published": "2025-06-19 20:15:43", "link": "http://arxiv.org/abs/2506.16582v1", "categories": ["stat.CO", "cs.NA", "math.NA"], "primary_category": "stat.CO"}
{"title": "IMEX-RB: a self-adaptive IMEX time integration scheme exploiting the RB method", "abstract": "In this work, we introduce a self-adaptive implicit-explicit (IMEX) time\nintegration scheme, named IMEX-RB, for the numerical integration of systems of\nordinary differential equations (ODEs), arising from spatial discretizations of\npartial differential equations (PDEs) by finite difference methods. Leveraging\nthe Reduced Basis (RB) method, at each timestep we project the high-fidelity\nproblem onto a suitable low-dimensional subspace and integrate its dynamics\nimplicitly. Following the IMEX paradigm, the resulting solution then serves as\nan educated guess within a full-order explicit step. Notably, compared to the\ncanonical RB method, IMEX-RB neither requires a parametrization of the\nunderlying PDE nor features an offline-online splitting, since the reduced\nsubspace is built dynamically, exploiting the high-fidelity solution history.\nWe present the first-order formulation of IMEX-RB, demonstrating and showcasing\nits convergence and stability properties. In particular, under appropriate\nconditions on the method's hyperparameters, IMEX-RB is unconditionally stable.\nThe theoretical analysis is corroborated by numerical experiments performed on\nrepresentative model problems in two and three dimensions. The results\ndemonstrate that our approach can outperform conventional time integration\nschemes like backward Euler. Indeed, IMEX-RB yields high-fidelity accurate\nsolutions, provided that its main hyperparameters - namely the reduced basis\nsize and the stability tolerance - are suitably tuned. Moreover, IMEX-RB\nrealizes computational gains over backward Euler for a range of timestep sizes\nabove the forward Euler stability threshold.", "published": "2025-06-19 17:12:44", "link": "http://arxiv.org/abs/2506.16470v1", "categories": ["math.NA", "cs.NA", "65M12"], "primary_category": "math.NA"}
{"title": "Scientific Applications Leveraging Randomized Linear Algebra", "abstract": "This report showcases the role of, and future directions for, the field of\nRandomized Numerical Linear Algebra (RNLA) in a selection of scientific\napplications. These applications span the domains of imaging, genomics and\ntime-varying systems, and are thematically connected by needing to perform\nlinear algebra routines on large-scale matrices (with up to quantillions of\nentries). At such scales, the linear algebra routines face typical bottlenecks:\nmemory constraints, data access latencies, and substantial floating-point\noperation costs. RNLA routines are discussed at a high level to demonstrate how\nRNLA is able to solve the challenges faced by traditional linear algebra\nroutines, and, consequently, address the computational problem posed in the\nunderlying application. For each application, RNLA's open challenges and\npossible future directions are also presented, which broadly fall into the\ncategories: creating structure-aware RNLA algorithms; co-designing RNLA\nalgorithms with hardware and mixed-precision considerations; and advancing\nmodular, composable software infrastructure. Ultimately, this report serves two\npurposes: it invites domain scientists to engage with RNLA; and it offers a\nguide for future RNLA research grounded in real applications.", "published": "2025-06-19 16:50:56", "link": "http://arxiv.org/abs/2506.16457v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "On a quantitative partial imaging problem in vector tomography", "abstract": "In two dimensions, we consider the problem of reconstructing a vector field\nfrom partial knowledge of its zeroth and first moment ray transforms. Different\nfrom existing works the data is known on a subset of lines, namely the ones\nintersecting a given arc. The problem is non-local and, for partial data,\nseverely ill-posed. We present a reconstruction method which recovers the\nvector field in the convex hull of the arc. An algorithm based on this method\nis implemented on some numerical experiments. While still ill-posed the\ndiscretization stabilizes the numerical reconstruction.", "published": "2025-06-19 16:46:05", "link": "http://arxiv.org/abs/2506.16455v1", "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "math.NA"}
{"title": "Fast Converging Single Trace Quasi-local PMCHWT Equation for the Modelling of Composite Systems", "abstract": "The PMCHWT integral equation enables the modelling of scattering of\ntime-harmonic fields by penetrable, piecewise homogeneous, systems. They have\nbeen generalised to include the modelling of composite systems that may contain\njunctions, i.e. lines along which three or more materials meet. Linear systems\nresulting upon discretisation of the PMCHWT are, because of their large\ndimension, typically solved by Krylov iterative methods. The number of\niterations required for this solution critically depends on the eigenvalue\ndistribution of the system matrix. For systems that do not contain junction\nlines, Calder\\'on preconditioning, which was first applied to the electric\nfield integral equation, has been generalised to the PMCHWT equation. When\njunctions are present, this approach cannot be applied. Alternative approaches,\nsuch as the global multi-trace method, conceptually remove the junction lines\nand as a result are amenable to Calder\\'on preconditioning. This approach\nentails a doubling of the degrees of freedom, and the solution that is produced\nonly approximately fulfils the continuity conditions at interfaces separating\ndomains. In this contribution, a single trace quasi-local PMCHWT equation is\nintroduced that requires a number of iterations for its solution that only\nslowly increases as the mesh size tends to zero. The method is constructed as a\ngeneralisation of the classic PMCHWT, and its discretisation is thoroughly\ndiscussed. A comprehensive suite of numerical experiments demonstrates the\ncorrectness, convergence behaviour, and efficiency of the method. The integral\nequation is demonstrated to be free from interior resonances.", "published": "2025-06-19 14:50:30", "link": "http://arxiv.org/abs/2506.16376v1", "categories": ["cs.CE", "cs.NA", "math.NA"], "primary_category": "cs.CE"}
{"title": "Transformations of Computational Meshes", "abstract": "Computational meshes, as a way to partition space, form the basis of much of\nPDE simulation technology, for instance for the finite element and finite\nvolume discretization methods. In complex simulations, we are often driven to\nmodify an input mesh, for example, to refine, coarsen, extrude, change cell\ntypes, or filter it. Mesh manipulation code can be voluminous, error-prone,\nspread over many special cases, and hard to understand and maintain by\nsubsequent developers. We present a simple, table-driven paradigm for mesh\ntransformation which can execute a large variety of transformations in a\nperformant, parallel manner, along with experiments in the open source library\nPETSc which can be run by the reader.", "published": "2025-06-19 14:20:15", "link": "http://arxiv.org/abs/2506.16341v1", "categories": ["cs.MS", "cs.NA", "math.NA"], "primary_category": "cs.MS"}
{"title": "Quasiseparable LU decay bounds for inverses of banded matrices", "abstract": "We develop new, easily computable exponential decay bounds for inverses of\nbanded matrices, based on the quasiseparable representation of Green matrices.\nThe bounds rely on a diagonal dominance hypothesis and do not require explicit\nspectral information. Numerical experiments and comparisons show that these new\nbounds can be advantageous especially for nonsymmetric or symmetric indefinite\nmatrices.", "published": "2025-06-19 14:18:39", "link": "http://arxiv.org/abs/2506.16339v1", "categories": ["math.NA", "cs.NA", "15A09, 65F99, 15B99"], "primary_category": "math.NA"}
{"title": "A third-order finite volume semi-implicit method for the Shallow Water-Exner model", "abstract": "In this work, third-order semi-implicit schemes on staggered meshes for the\nshallow water and Saint-Venant-Exner systems are presented. They are based on a\nthird-order extension of the technique introduced in Cassulli \\& Cheng [1]. The\nstability conditions for these schemes depend on the velocity and not on the\ncelerity, allowing us to reduce computational efforts, especially in\nsubcritical flow simulations, which is the regime we are mainly interested in.\nThe main novelty consists in the third-order approximation of the pressure\ngradient term in the momentum equation through appropriate polynomial\nreconstructions. Concretely, CWENO conservative reconstruction is considered\nfor the water thickness $h$ and a centered fourth-degree polynomial is adopted\ninterpolating the cell averages of the free surface $\\eta$. For time\ndiscretization, a third-order IMEX scheme is applied. In addition, a novel\ntime-dependent semi-analytical solution for Saint-Venant-Exner system is\nintroduced and compared with the numerical ones. Several tests are performed,\nincluding accuracy tests showing third-order accuracy, well-balance tests, and\nsimulations of slow bedload processes for large time.", "published": "2025-06-19 13:05:04", "link": "http://arxiv.org/abs/2506.16287v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Mesoscale FEM Model of Concrete: Statistical Assessment of Inherent Stress Concentrations in Dependence on Phase Heterogeneity", "abstract": "Concrete heterogeneity originates from its production process, which involves\nbonding aggregates with a binder matrix. This study presents a mesoscale finite\nelement model (MFEM) that offers detailed insights into the fracture process at\nthe aggregate-cement matrix interface, focusing on one of concrete's key\nproperties: its mechanical response. Unlike discrete models, which often\naverage out critical stress concentrations within the mesostructure, the MFEM\napproach captures detailed stress distributions, revealing localized effects\ncrucial for understanding damage evolution. Although computationally more\ndemanding, the MFEM leverages modern high-performance computing (HPC) to\nprovide a detailed description of the stress field and material damage across\ndifferent phases and interfaces. Various matrix-to-aggregate stiffness ratios\nare considered to evaluate the influence of material heterogeneity on the\nstress field. The results are based on a statistical evaluation of stress\nconcentrations arising from variations in material stiffness. The model is\napplied to investigate the impact of using recycled crushed bricks as\naggregates in concrete, with particular emphasis on the stiffness mismatch\nbetween the matrix and aggregates. The study examines how this stiffness\ncontrast affects stress distribution and ultimately influences the composite's\nfailure mechanisms.", "published": "2025-06-19 11:57:17", "link": "http://arxiv.org/abs/2506.16242v1", "categories": ["cond-mat.mtrl-sci", "cs.NA", "math.NA"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "From eigenvector nonlinearities to eigenvalue nonlinearities", "abstract": "Over the past decades, transformations between different classes of\neigenvalue problems have played a central role in the development of numerical\nmethods for eigenvalue computations. One of the most well-known and successful\nexamples of this is the companion linearization. In this paper, we construct a\ntransformation that equivalently re-frames a specific type of eigenvalue\nproblem with eigenvector nonlinearities (NEPv) into an eigenvalue problem with\neigenvalue nonlinearities (NEP). The NEPv class considered consists of\nnonlinearities expressed as sums of products of matrices and scalar functions,\nwhere the scalar functions depend nonlinearly on the eigenvector. Our\ntransformation defines the scalar nonlinearities through a polynomial system,\nresulting in NEP nonlinearities of algebraic type. We propose methods to solve\nthe polynomial system, one involving a multiparameter eigenvalue problem (MEP).\nWe adapt well-established NEP solvers to this setting, with the most effective\nstrategy being a combination of deflation and a locally quadratically\nconvergent iterative method. The efficiency and properties of the approach is\nillustrated by solving a problem related to a modification of a\nGross-Pitaevskii equation (GPE). The simulations are reproducible and publicly\navailable.", "published": "2025-06-19 10:02:27", "link": "http://arxiv.org/abs/2506.16182v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Monolithic and Block Overlapping Schwarz Preconditioners for the Incompressible Navier--Stokes Equations", "abstract": "Monolithic preconditioners applied to the linear systems arising during the\nsolution of the discretized incompressible Navier--Stokes equations are\ntypically more robust than preconditioners based on incomplete block\nfactorizations. Lower number of iterations and a reduced sensitivity to\nparameters like velocity and viscosity can significantly outweigh the\nadditional cost for their setup. Different monolithic preconditioning\ntechniques are introduced and compared to a selection of block preconditioners.\nIn particular, two-level additive overlapping Schwarz methods (OSM) are used to\nset up monolithic preconditioners and to approximate the inverses arising in\nthe block preconditioners. GDSW-type (Generalized Dryja--Smith--Widlund) coarse\nspaces are used for the second level. These highly scalable, parallel\npreconditioners have been implemented in the solver framework \\texttt{FROSch}\n(Fast and Robust Overlapping Schwarz), which is part of the software library\n\\texttt{Trilinos}. The new GDSW-type coarse space GDSW\\expStar{} is introduced;\ncombining it with other techniques results in a robust algorithm. The block\npreconditioners PCD (Pressure Convection--Diffusion), SIMPLE (Semi-Implicit\nMethod for Pressure Linked Equations), and LSC (Least-Squares Commutator) are\nconsidered to various degrees. The OSM for the monolithic as well as the block\napproach allows the optimized combination of different coarse spaces for the\nvelocity and pressure component, enabling the use of tailored coarse spaces.\nThe numerical and parallel performance of the different preconditioning methods\nfor finite element discretizations of stationary as well as time-dependent\nincompressible fluid flow problems is investigated and compared. Their\nrobustness is analyzed for a range of Reynolds and Courant-Friedrichs-Lewy\n(CFL) numbers with respect to a realistic problem setting.", "published": "2025-06-19 09:52:32", "link": "http://arxiv.org/abs/2506.16179v1", "categories": ["math.NA", "cs.NA", "65N55, 65F08, 6504, 7604, 7610"], "primary_category": "math.NA"}
{"title": "Two-dimensional greedy randomized extended Kaczmarz methods", "abstract": "The randomized extended Kaczmarz method, proposed by Zouzias and Freris (SIAM\nJ. Matrix Anal. Appl. 34: 773-793, 2013), is appealing for solving\nleast-squares problems. However, its randomly selecting rows and columns of A\nwith probability proportional to their squared norm is unattractive compared to\nthe greedy strategy. In this paper, we first consider a novel two-dimensional\ngreedy randomized extended Kaczmarz method for solving large linear\nleast-squares problems. The proposed method randomly selects two rows and two\ncolumns of A by grasping two larger entries in the magnitude of the\ncorresponding residual vector per iteration. To improve its convergence, we\nthen propose a two-dimensional semi-randomized extended Kaczmarz method and its\nmodified version with simple random sampling, which is particularly favorable\nfor big data problems. The convergence analysis of which is also established.\nNumerical results on some practical applications illustrate the superiority of\nthe proposed methods compared with state-of-the-art randomized extended\nKaczmarz methods, especially in terms of computing time.", "published": "2025-06-19 07:58:30", "link": "http://arxiv.org/abs/2506.16106v1", "categories": ["math.NA", "cs.NA", "65F10, 65F20, 94A08"], "primary_category": "math.NA"}
{"title": "General-domain FC-based shock-dynamics solver I: Basic elements", "abstract": "This contribution, Part I in a two-part article series, presents a\ngeneral-domain version of the FC-SDNN (Fourier Continuation Shock-detecting\nNeural Network) spectral scheme for the numerical solution of nonlinear\nconservation laws, which is applicable under arbitrary boundary conditions and\nin general domains. Like the previous simple-domain contribution (Journal of\nComputational Physics X 15, (2022)), the present approach relies on the use of\nthe Fourier Continuation method for accurate spectral representation of\nnon-periodic functions in conjunction with smooth artificial viscosity\nassignments localized in regions detected by means of a Shock-Detecting Neural\nNetwork (SDNN). Relying on such techniques, the present Part I paper introduces\na novel multi-patch/subpatch artificial viscosity-capable domain decomposition\nstrategy for complex domains with smooth boundaries, and it illustrates the\nmethodology by means of a variety of computational results produced by an\nassociated parallel implementation of the resulting shock-capturing algorithm\nin a present-day computing cluster. The subsequent Part II contribution then\nextends the algorithm to enable treatment of obstacles with non-smooth\nboundaries, it considers questions concerning parallelization and accuracy, and\nit presents comparisons with physical theory and prior experimental and\ncomputational results. The resulting multi-patch FC-SDNN algorithm does not\nrequire use of problem-dependent algorithmic parameters or\npositivity-preserving limiters, and, on account of its use of an\noverlapping-patch discretization, it is geometrically flexible and efficiently\nparallelized. A variety of numerical tests for the 2D Euler equations are\npresented, including the simulation of supersonic and hypersonic flows and\nshocks past physical obstacles at high speeds, such as Mach 25 re-entry flow\nspeeds.", "published": "2025-06-19 07:01:38", "link": "http://arxiv.org/abs/2506.16076v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Preconditioning and Linearly Implicit Time Integration for the Serre-Green-Naghdi Equations", "abstract": "The treatment of the differential PDE constraint poses a key challenge in\ncomputing the numerical solution of the Serre-Green-Naghdi (SGN) equations. In\nthis work, we introduce a constant coefficient preconditioner for the SGN\nconstraint operator and prove rigorous bounds on the preconditioned\nconditioning number. The conditioning bounds incorporate the effects of\nbathymetry in two dimensions, are quasi-optimal within a class of constant\ncoefficient operators, highlight fundamental scalings for a loss of\nconditioning, and ensure mesh independent performance for iterative Krylov\nmethods.\n  Utilizing the conditioning bounds, we devise and test two time integration\nstrategies for solving the full SGN equations. The first class combines\nclassical explicit time integration schemes (4th order Runge-Kutta and 2nd--4th\norder Adams-Bashforth) with the new preconditioner. The second is a linearly\nimplicit scheme where the differential constraint is split into a constant\ncoefficient implicit part and remaining (stiff) explicit part. The linearly\nimplicit methods require a single linear solve of a constant coefficient\noperator at each time step. We provide a host of computational experiments that\nvalidate the robustness of the preconditioners, as well as full solutions of\nthe SGN equations including solitary waves traveling over an underwater shelf\n(in 1d) and a circular bump (in 2d).", "published": "2025-06-19 05:44:32", "link": "http://arxiv.org/abs/2506.16045v1", "categories": ["math.NA", "cs.NA", "65L04, 65L06, 65L07, 65M12, 76B15, 76M22"], "primary_category": "math.NA"}
{"title": "Reactive Transport Modeling with Physics-Informed Machine Learning for Critical Minerals Applications", "abstract": "This study presents a physics-informed neural network (PINN) framework for\nreactive transport modeling for simulating fast bimolecular reactions in porous\nmedia. Accurate characterization of chemical interactions and product formation\nin surface and subsurface environments is essential for advancing critical\nmineral extraction and related geoscience applications.", "published": "2025-06-19 02:09:57", "link": "http://arxiv.org/abs/2506.15960v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Pricing under the Benchmark Approach", "abstract": "The paper summarizes key results of the benchmark approach with a focus on\nthe concept of benchmark-neutral pricing. It applies these results to the\npricing of an extreme-maturity European put option on a well-diversified stock\nindex. The growth optimal portfolio of the stocks is approximated by a\nwell-diversified stock portfolio and modeled by a drifted time-transformed\nsquared Bessel process of dimension four. It is shown that the\nbenchmark-neutral price of a European put option is theoretically the minimal\npossible price and the respective risk-neutral put price turns out to be\nsignificantly more expensive.", "published": "2025-06-19 12:26:40", "link": "http://arxiv.org/abs/2506.16264v1", "categories": ["q-fin.MF", "q-fin.GN", "62P05, 60G35, 62P20", "G.3"], "primary_category": "q-fin.MF"}
{"title": "An introduction to Causal Modelling", "abstract": "This tutorial provides a concise introduction to modern causal modeling by\nintegrating potential outcomes and graphical methods. We motivate causal\nquestions such as counterfactual reasoning under interventions and define\nbinary treatments and potential outcomes. We discuss causal effect\nmeasures-including average treatment effects on the treated and on the\nuntreated-and choices of effect scales for binary outcomes. We derive\nidentification in randomized experiments under exchangeability and consistency,\nand extend to stratification and blocking designs. We present inverse\nprobability weighting with propensity score estimation and robust inference via\nsandwich estimators. Finally, we introduce causal graphs, d-separation, the\nbackdoor criterion, single-world intervention graphs, and structural equation\nmodels, showing how graphical and potential-outcome approaches complement each\nother. Emphasis is placed on clear notation, intuitive explanations, and\npractical examples for applied researchers.", "published": "2025-06-19 17:29:09", "link": "http://arxiv.org/abs/2506.16486v1", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Joint Tensor-Train Parameterization for Efficient and Expressive Low-Rank Adaptation", "abstract": "Low-Rank Adaptation (LoRA) is widely recognized for its parameter-efficient\nfine-tuning of large-scale neural models. However, standard LoRA independently\noptimizes low-rank matrices, which inherently limits its expressivity and\ngeneralization capabilities. While classical tensor-train (TT) decomposition\ncan be separately employed on individual LoRA matrices, this work demonstrates\nthat the classical TT-based approach neither significantly improves parameter\nefficiency nor achieves substantial performance gains. This paper proposes\nTensorGuide, a novel tensor-train-guided adaptation framework to overcome these\nlimitations. TensorGuide generates two correlated low-rank LoRA matrices\nthrough a unified TT structure driven by controlled Gaussian noise. The\nresulting joint TT representation inherently provides structured, low-rank\nadaptations, significantly enhancing expressivity, generalization, and\nparameter efficiency without increasing the number of trainable parameters.\nTheoretically, we justify these improvements through neural tangent kernel\nanalyses, demonstrating superior optimization dynamics and enhanced\ngeneralization. Extensive experiments on quantum dot classification and GPT-2\nfine-tuning benchmarks demonstrate that TensorGuide-based LoRA consistently\noutperforms standard LoRA and TT-LoRA, achieving improved accuracy and\nscalability with fewer parameters.", "published": "2025-06-19 16:46:23", "link": "http://arxiv.org/abs/2506.16456v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "On Continuous Monitoring of Risk Violations under Unknown Shift", "abstract": "Machine learning systems deployed in the real world must operate under\ndynamic and often unpredictable distribution shifts. This challenges the\nvalidity of statistical safety assurances on the system's risk established\nbeforehand. Common risk control frameworks rely on fixed assumptions and lack\nmechanisms to continuously monitor deployment reliability. In this work, we\npropose a general framework for the real-time monitoring of risk violations in\nevolving data streams. Leveraging the 'testing by betting' paradigm, we propose\na sequential hypothesis testing procedure to detect violations of bounded risks\nassociated with the model's decision-making mechanism, while ensuring control\non the false alarm rate. Our method operates under minimal assumptions on the\nnature of encountered shifts, rendering it broadly applicable. We illustrate\nthe effectiveness of our approach by monitoring risks in outlier detection and\nset prediction under a variety of shifts.", "published": "2025-06-19 15:52:24", "link": "http://arxiv.org/abs/2506.16416v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Identifying Heterogeneity in Distributed Learning", "abstract": "We study methods for identifying heterogeneous parameter components in\ndistributed M-estimation with minimal data transmission. One is based on a\nre-normalized Wald test, which is shown to be consistent as long as the number\nof distributed data blocks $K$ is of a smaller order of the minimum block\nsample size {and the level of heterogeneity is dense}. The second one is an\nextreme contrast test (ECT) based on the difference between the largest and\nsmallest component-wise estimated parameters among data blocks. By introducing\na sample splitting procedure, the ECT can avoid the bias accumulation arising\nfrom the M-estimation procedures, and exhibits consistency for $K$ being much\nlarger than the sample size while the heterogeneity is sparse. The ECT\nprocedure is easy to operate and communication-efficient. A combination of the\nWald and the extreme contrast tests is formulated to attain more robust power\nunder varying levels of sparsity of the heterogeneity. We also conduct\nintensive numerical experiments to compare the family-wise error rate (FWER)\nand the power of the proposed methods. Additionally, we conduct a case study to\npresent the implementation and validity of the proposed methods.", "published": "2025-06-19 15:26:48", "link": "http://arxiv.org/abs/2506.16394v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "The Condition Number as a Scale-Invariant Proxy for Information Encoding in Neural Units", "abstract": "This paper explores the relationship between the condition number of a neural\nnetwork's weight tensor and the extent of information encoded by the associated\nprocessing unit, viewed through the lens of information theory. We argue that a\nhigh condition number, though not sufficient for effective knowledge encoding,\nmay indicate that the unit has learned to selectively amplify and compress\ninformation. We formalize this intuition, particularly for linear units with\nGaussian inputs, linking the condition number and the transformation's\nlog-volume scaling factor to the characteristics of the output entropy and the\ngeometric properties of the learned transformation. Our analysis demonstrates\nthat for a fixed weight norm, a concentrated distribution of singular values\n(high condition number) corresponds to reduced overall information transfer,\nindicating a specialized and efficient encoding strategy. Furthermore, we\npresent a practical case study where these principles are applied to guide\nselective fine-tuning of a multimodal Large Language Model, aiming to mitigate\ncatastrophic forgetting during cross-modal adaptation. Unlike many existing\ncatastrophic forgetting mitigation methods that rely on access to pre-training\nstatistics, which are often unavailable, our selective fine-tuning approach\noffers a way to bypass this common requirement.", "published": "2025-06-19 13:06:16", "link": "http://arxiv.org/abs/2506.16289v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Random feature approximation for general spectral methods", "abstract": "Random feature approximation is arguably one of the most widely used\ntechniques for kernel methods in large-scale learning algorithms. In this work,\nwe analyze the generalization properties of random feature methods, extending\nprevious results for Tikhonov regularization to a broad class of spectral\nregularization techniques. This includes not only explicit methods but also\nimplicit schemes such as gradient descent and accelerated algorithms like the\nHeavy-Ball and Nesterov method. Through this framework, we enable a theoretical\nanalysis of neural networks and neural operators through the lens of the Neural\nTangent Kernel (NTK) approach trained via gradient descent. For our estimators\nwe obtain optimal learning rates over regularity classes (even for classes that\nare not included in the reproducing kernel Hilbert space), which are defined\nthrough appropriate source conditions. This improves or completes previous\nresults obtained in related settings for specific kernel algorithms.", "published": "2025-06-19 13:00:17", "link": "http://arxiv.org/abs/2506.16283v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "On Design of Representative Distributionally Robust Formulations for Evaluation of Tail Risk Measures", "abstract": "Conditional Value-at-Risk (CVaR) is a risk measure widely used to quantify\nthe impact of extreme losses. Owing to the lack of representative samples CVaR\nis sensitive to the tails of the underlying distribution. In order to combat\nthis sensitivity, Distributionally Robust Optimization (DRO), which evaluates\nthe worst-case CVaR measure over a set of plausible data distributions is often\ndeployed. Unfortunately, an improper choice of the DRO formulation can lead to\na severe underestimation of tail risk. This paper aims at leveraging extreme\nvalue theory to arrive at a DRO formulation which leads to representative\nworst-case CVaR evaluations in that the above pitfall is avoided while\nsimultaneously, the worst case evaluation is not a gross over-estimate of the\ntrue CVaR. We demonstrate theoretically that even when there is paucity of\nsamples in the tail of the distribution, our formulation is readily\nimplementable from data, only requiring calibration of a single scalar\nparameter. We showcase that our formulation can be easily extended to provide\nrobustness to tail risk in multivariate applications as well as in the\nevaluation of other commonly used risk measures. Numerical illustrations on\nsynthetic and real-world data showcase the practical utility of our approach.", "published": "2025-06-19 11:40:02", "link": "http://arxiv.org/abs/2506.16230v1", "categories": ["q-fin.RM", "math.PR", "stat.ME", "stat.ML"], "primary_category": "q-fin.RM"}
{"title": "CP$^2$: Leveraging Geometry for Conformal Prediction via Canonicalization", "abstract": "We study the problem of conformal prediction (CP) under geometric data\nshifts, where data samples are susceptible to transformations such as rotations\nor flips. While CP endows prediction models with post-hoc uncertainty\nquantification and formal coverage guarantees, their practicality breaks under\ndistribution shifts that deteriorate model performance. To address this issue,\nwe propose integrating geometric information--such as geometric pose--into the\nconformal procedure to reinstate its guarantees and ensure robustness under\ngeometric shifts. In particular, we explore recent advancements on pose\ncanonicalization as a suitable information extractor for this purpose.\nEvaluating the combined approach across discrete and continuous shifts and\nagainst equivariant and augmentation-based baselines, we find that integrating\ngeometric information with CP yields a principled way to address geometric\nshifts while maintaining broad applicability to black-box predictors.", "published": "2025-06-19 10:12:02", "link": "http://arxiv.org/abs/2506.16189v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Diffusion-Based Hypothesis Testing and Change-Point Detection", "abstract": "Score-based methods have recently seen increasing popularity in modeling and\ngeneration. Methods have been constructed to perform hypothesis testing and\nchange-point detection with score functions, but these methods are in general\nnot as powerful as their likelihood-based peers. Recent works consider\ngeneralizing the score-based Fisher divergence into a diffusion-divergence by\ntransforming score functions via multiplication with a matrix-valued function\nor a weight matrix. In this paper, we extend the score-based hypothesis test\nand change-point detection stopping rule into their diffusion-based analogs.\nAdditionally, we theoretically quantify the performance of these\ndiffusion-based algorithms and study scenarios where optimal performance is\nachievable. We propose a method of numerically optimizing the weight matrix and\npresent numerical simulations to illustrate the advantages of diffusion-based\nalgorithms.", "published": "2025-06-19 07:22:27", "link": "http://arxiv.org/abs/2506.16089v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Leveraging Optimal Transport for Distributed Two-Sample Testing: An Integrated Transportation Distance-based Framework", "abstract": "This paper introduces a novel framework for distributed two-sample testing\nusing the Integrated Transportation Distance (ITD), an extension of the Optimal\nTransport distance. The approach addresses the challenges of detecting\ndistributional changes in decentralized learning or federated learning\nenvironments, where data privacy and heterogeneity are significant concerns. We\nprovide theoretical foundations for the ITD, including convergence properties\nand asymptotic behavior. A permutation test procedure is proposed for practical\nimplementation in distributed settings, allowing for efficient computation\nwhile preserving data privacy. The framework's performance is demonstrated\nthrough theoretical power analysis and extensive simulations, showing robust\nType I error control and high power across various distributions and\ndimensions. The results indicate that ITD effectively aggregates information\nacross distributed clients, detecting subtle distributional shifts that might\nbe missed when examining individual clients. This work contributes to the\ngrowing field of distributed statistical inference, offering a powerful tool\nfor two-sample testing in modern, decentralized data environments.", "published": "2025-06-19 05:59:48", "link": "http://arxiv.org/abs/2506.16047v1", "categories": ["stat.ME", "math.ST", "stat.AP", "stat.CO", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Streaming Non-Autoregressive Model for Accent Conversion and Pronunciation Improvement", "abstract": "We propose a first streaming accent conversion (AC) model that transforms\nnon-native speech into a native-like accent while preserving speaker identity,\nprosody and improving pronunciation. Our approach enables stream processing by\nmodifying a previous AC architecture with an Emformer encoder and an optimized\ninference mechanism. Additionally, we integrate a native text-to-speech (TTS)\nmodel to generate ideal ground-truth data for efficient training. Our streaming\nAC model achieves comparable performance to the top AC models while maintaining\nstable latency, making it the first AC system capable of streaming.", "published": "2025-06-19 20:05:29", "link": "http://arxiv.org/abs/2506.16580v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Weight Factorization and Centralization for Continual Learning in Speech Recognition", "abstract": "Modern neural network based speech recognition models are required to\ncontinually absorb new data without re-training the whole system, especially in\ndownstream applications using foundation models, having no access to the\noriginal training data. Continually training the models in a rehearsal-free,\nmultilingual, and language agnostic condition, likely leads to catastrophic\nforgetting, when a seemingly insignificant disruption to the weights can\ndestructively harm the quality of the models. Inspired by the ability of human\nbrains to learn and consolidate knowledge through the waking-sleeping cycle, we\npropose a continual learning approach with two distinct phases: factorization\nand centralization, learning and merging knowledge accordingly. Our experiments\non a sequence of varied code-switching datasets showed that the centralization\nstage can effectively prevent catastrophic forgetting by accumulating the\nknowledge in multiple scattering low-rank adapters.", "published": "2025-06-19 19:59:24", "link": "http://arxiv.org/abs/2506.16574v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Automatic Speech Recognition Biases in Newcastle English: an Error Analysis", "abstract": "Automatic Speech Recognition (ASR) systems struggle with regional dialects\ndue to biased training which favours mainstream varieties. While previous\nresearch has identified racial, age, and gender biases in ASR, regional bias\nremains underexamined. This study investigates ASR performance on Newcastle\nEnglish, a well-documented regional dialect known to be challenging for ASR. A\ntwo-stage analysis was conducted: first, a manual error analysis on a subsample\nidentified key phonological, lexical, and morphosyntactic errors behind ASR\nmisrecognitions; second, a case study focused on the systematic analysis of ASR\nrecognition of the regional pronouns ``yous'' and ``wor''. Results show that\nASR errors directly correlate with regional dialectal features, while social\nfactors play a lesser role in ASR mismatches. We advocate for greater dialectal\ndiversity in ASR training data and highlight the value of sociolinguistic\nanalysis in diagnosing and addressing regional biases.", "published": "2025-06-19 19:24:12", "link": "http://arxiv.org/abs/2506.16558v1", "categories": ["cs.CL", "cs.CY", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Towards Bitrate-Efficient and Noise-Robust Speech Coding with Variable Bitrate RVQ", "abstract": "Residual Vector Quantization (RVQ) has become a dominant approach in neural\nspeech and audio coding, providing high-fidelity compression. However, speech\ncoding presents additional challenges due to real-world noise, which degrades\ncompression efficiency. Standard codecs allocate bits uniformly, wasting\nbitrate on noise components that do not contribute to intelligibility. This\npaper introduces a Variable Bitrate RVQ (VRVQ) framework for noise-robust\nspeech coding, dynamically adjusting bitrate per frame to optimize\nrate-distortion trade-offs. Unlike constant bitrate (CBR) RVQ, our method\nprioritizes critical speech components while suppressing residual noise.\nAdditionally, we integrate a feature denoiser to further improve noise\nrobustness. Experimental results show that VRVQ improves rate-distortion\ntrade-offs over conventional methods, achieving better compression efficiency\nand perceptual quality in noisy conditions. Samples are available at our\nproject page: https://yoongi43.github.io/noise_robust_vrvq/.", "published": "2025-06-19 18:49:41", "link": "http://arxiv.org/abs/2506.16538v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "InstructTTSEval: Benchmarking Complex Natural-Language Instruction Following in Text-to-Speech Systems", "abstract": "In modern speech synthesis, paralinguistic information--such as a speaker's\nvocal timbre, emotional state, and dynamic prosody--plays a critical role in\nconveying nuance beyond mere semantics. Traditional Text-to-Speech (TTS)\nsystems rely on fixed style labels or inserting a speech prompt to control\nthese cues, which severely limits flexibility. Recent attempts seek to employ\nnatural-language instructions to modulate paralinguistic features,\nsubstantially improving the generalization of instruction-driven TTS models.\nAlthough many TTS systems now support customized synthesis via textual\ndescription, their actual ability to interpret and execute complex instructions\nremains largely unexplored. In addition, there is still a shortage of\nhigh-quality benchmarks and automated evaluation metrics specifically designed\nfor instruction-based TTS, which hinders accurate assessment and iterative\noptimization of these models. To address these limitations, we introduce\nInstructTTSEval, a benchmark for measuring the capability of complex\nnatural-language style control. We introduce three tasks, namely\nAcoustic-Parameter Specification, Descriptive-Style Directive, and Role-Play,\nincluding English and Chinese subsets, each with 1k test cases (6k in total)\npaired with reference audio. We leverage Gemini as an automatic judge to assess\ntheir instruction-following abilities. Our evaluation of accessible\ninstruction-following TTS systems highlights substantial room for further\nimprovement. We anticipate that InstructTTSEval will drive progress toward more\npowerful, flexible, and accurate instruction-following TTS.", "published": "2025-06-19 15:08:01", "link": "http://arxiv.org/abs/2506.16381v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Optimizing Multilingual Text-To-Speech with Accents & Emotions", "abstract": "State-of-the-art text-to-speech (TTS) systems realize high naturalness in\nmonolingual environments, synthesizing speech with correct multilingual accents\n(especially for Indic languages) and context-relevant emotions still poses\ndifficulty owing to cultural nuance discrepancies in current frameworks. This\npaper introduces a new TTS architecture integrating accent along with\npreserving transliteration with multi-scale emotion modelling, in particularly\ntuned for Hindi and Indian English accent. Our approach extends the Parler-TTS\nmodel by integrating A language-specific phoneme alignment hybrid\nencoder-decoder architecture, and culture-sensitive emotion embedding layers\ntrained on native speaker corpora, as well as incorporating a dynamic accent\ncode switching with residual vector quantization. Quantitative tests\ndemonstrate 23.7% improvement in accent accuracy (Word Error Rate reduction\nfrom 15.4% to 11.8%) and 85.3% emotion recognition accuracy from native\nlisteners, surpassing METTS and VECL-TTS baselines. The novelty of the system\nis that it can mix code in real time - generating statements such as \"Namaste,\nlet's talk about <Hindi phrase>\" with uninterrupted accent shifts while\npreserving emotional consistency. Subjective evaluation with 200 users reported\na mean opinion score (MOS) of 4.2/5 for cultural correctness, much better than\nexisting multilingual systems (p<0.01). This research makes cross-lingual\nsynthesis more feasible by showcasing scalable accent-emotion disentanglement,\nwith direct application in South Asian EdTech and accessibility software.", "published": "2025-06-19 13:35:05", "link": "http://arxiv.org/abs/2506.16310v1", "categories": ["cs.LG", "cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Advancing Automated Speaking Assessment Leveraging Multifaceted Relevance and Grammar Information", "abstract": "Current automated speaking assessment (ASA) systems for use in multi-aspect\nevaluations often fail to make full use of content relevance, overlooking image\nor exemplar cues, and employ superficial grammar analysis that lacks detailed\nerror types. This paper ameliorates these deficiencies by introducing two novel\nenhancements to construct a hybrid scoring model. First, a multifaceted\nrelevance module integrates question and the associated image content,\nexemplar, and spoken response of an L2 speaker for a comprehensive assessment\nof content relevance. Second, fine-grained grammar error features are derived\nusing advanced grammar error correction (GEC) and detailed annotation to\nidentify specific error categories. Experiments and ablation studies\ndemonstrate that these components significantly improve the evaluation of\ncontent relevance, language use, and overall ASA performance, highlighting the\nbenefits of using richer, more nuanced feature sets for holistic speaking\nassessment.", "published": "2025-06-19 13:01:11", "link": "http://arxiv.org/abs/2506.16285v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "End-to-End Speech Translation for Low-Resource Languages Using Weakly Labeled Data", "abstract": "The scarcity of high-quality annotated data presents a significant challenge\nin developing effective end-to-end speech-to-text translation (ST) systems,\nparticularly for low-resource languages. This paper explores the hypothesis\nthat weakly labeled data can be used to build ST models for low-resource\nlanguage pairs. We constructed speech-to-text translation datasets with the\nhelp of bitext mining using state-of-the-art sentence encoders. We mined the\nmultilingual Shrutilipi corpus to build Shrutilipi-anuvaad, a dataset\ncomprising ST data for language pairs Bengali-Hindi, Malayalam-Hindi,\nOdia-Hindi, and Telugu-Hindi. We created multiple versions of training data\nwith varying degrees of quality and quantity to investigate the effect of\nquality versus quantity of weakly labeled data on ST model performance. Results\ndemonstrate that ST systems can be built using weakly labeled data, with\nperformance comparable to massive multi-modal multilingual baselines such as\nSONAR and SeamlessM4T.", "published": "2025-06-19 12:11:01", "link": "http://arxiv.org/abs/2506.16251v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "EDNet: A Distortion-Agnostic Speech Enhancement Framework with Gating Mamba Mechanism and Phase Shift-Invariant Training", "abstract": "Speech signals in real-world environments are frequently affected by various\ndistortions such as additive noise, reverberation, and bandwidth limitation,\nwhich may appear individually or in combination. Traditional speech enhancement\nmethods typically rely on either masking, which focuses on suppressing\nnon-speech components while preserving observable structure, or mapping, which\nseeks to recover clean speech through direct transformation of the input. Each\napproach offers strengths in specific scenarios but may be less effective\noutside its target conditions. We propose the Erase and Draw Network (EDNet), a\ndistortion-agnostic speech enhancement framework designed to handle a broad\nrange of distortion types without prior assumptions about task or input\ncharacteristics. EDNet consists of two main components: (1) the Gating Mamba\n(GM) module, which adaptively combines masking and mapping through a learnable\ngating mechanism that selects between suppression (Erase) and reconstruction\n(Draw) based on local signal features, and (2) Phase Shift-Invariant Training\n(PSIT), a shift tolerant supervision strategy that improves phase estimation by\nenabling dynamic alignment during training while remaining compatible with\nstandard loss functions. Experimental results on denoising, dereverberation,\nbandwidth extension, and multi distortion enhancement tasks show that EDNet\nconsistently achieves strong performance across conditions, demonstrating its\narchitectural flexibility and adaptability to diverse task settings.", "published": "2025-06-19 11:42:57", "link": "http://arxiv.org/abs/2506.16231v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Spatio-spectral diarization of meetings by combining TDOA-based segmentation and speaker embedding-based clustering", "abstract": "We propose a spatio-spectral, combined model-based and data-driven\ndiarization pipeline consisting of TDOA-based segmentation followed by\nembedding-based clustering. The proposed system requires neither access to\nmulti-channel training data nor prior knowledge about the number or placement\nof microphones. It works for both a compact microphone array and distributed\nmicrophones, with minor adjustments. Due to its superior handling of\noverlapping speech during segmentation, the proposed pipeline significantly\noutperforms the single-channel pyannote approach, both in a scenario with a\ncompact microphone array and in a setup with distributed microphones.\nAdditionally, we show that, unlike fully spatial diarization pipelines, the\nproposed system can correctly track speakers when they change positions.", "published": "2025-06-19 11:37:35", "link": "http://arxiv.org/abs/2506.16228v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "AeroGPT: Leveraging Large-Scale Audio Model for Aero-Engine Bearing Fault Diagnosis", "abstract": "Aerospace engines, as critical components in aviation and aerospace\nindustries, require continuous and accurate fault diagnosis to ensure\noperational safety and prevent catastrophic failures. While deep learning\ntechniques have been extensively studied in this context, they output logits or\nconfidence scores, necessitating post-processing to derive actionable insights.\nFurthermore, the potential of large-scale audio models in this domain remains\nlargely untapped. To address these limitations, this paper proposes AeroGPT, a\nnovel framework that transfers knowledge from general audio domain to\naero-engine bearing fault diagnosis. AeroGPT is a framework based on\nlarge-scale audio model that incorporates Vibration Signal Alignment (VSA) to\nadapt general audio knowledge to domain-specific vibration patterns, and\ncombines Generative Fault Classification (GFC) to directly output interpretable\nfault labels. This approach eliminates the need for post-processing of fault\nlabels, supports interactive, interpretable, and actionable fault diagnosis,\nthereby greatly enhancing industrial applicability. Through comprehensive\nexperimental validation on two aero-engine bearing datasets, AeroGPT achieved\nexceptional performance with 98.94% accuracy on the DIRG dataset and perfect\n100% classification on the HIT bearing dataset, surpassing traditional deep\nlearning approaches. Additional Qualitative analysis validates the\neffectiveness of our approach and highlights the potential of large-scale\nmodels to revolutionize fault diagnosis.", "published": "2025-06-19 11:34:59", "link": "http://arxiv.org/abs/2506.16225v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Single-Microphone-Based Sound Source Localization for Mobile Robots in Reverberant Environments", "abstract": "Accurately estimating sound source positions is crucial for robot audition.\nHowever, existing sound source localization methods typically rely on a\nmicrophone array with at least two spatially preconfigured microphones. This\nrequirement hinders the applicability of microphone-based robot audition\nsystems and technologies. To alleviate these challenges, we propose an online\nsound source localization method that uses a single microphone mounted on a\nmobile robot in reverberant environments. Specifically, we develop a\nlightweight neural network model with only 43k parameters to perform real-time\ndistance estimation by extracting temporal information from reverberant\nsignals. The estimated distances are then processed using an extended Kalman\nfilter to achieve online sound source localization. To the best of our\nknowledge, this is the first work to achieve online sound source localization\nusing a single microphone on a moving robot, a gap that we aim to fill in this\nwork. Extensive experiments demonstrate the effectiveness and merits of our\napproach. To benefit the broader research community, we have open-sourced our\ncode at https://github.com/JiangWAV/single-mic-SSL.", "published": "2025-06-19 09:45:28", "link": "http://arxiv.org/abs/2506.16173v1", "categories": ["cs.RO", "cs.SD", "eess.AS"], "primary_category": "cs.RO"}
{"title": "Improved Intelligibility of Dysarthric Speech using Conditional Flow Matching", "abstract": "Dysarthria is a neurological disorder that significantly impairs speech\nintelligibility, often rendering affected individuals unable to communicate\neffectively. This necessitates the development of robust dysarthric-to-regular\nspeech conversion techniques. In this work, we investigate the utility and\nlimitations of self-supervised learning (SSL) features and their quantized\nrepresentations as an alternative to mel-spectrograms for speech generation.\nAdditionally, we explore methods to mitigate speaker variability by generating\nclean speech in a single-speaker voice using features extracted from WavLM. To\nthis end, we propose a fully non-autoregressive approach that leverages\nConditional Flow Matching (CFM) with Diffusion Transformers to learn a direct\nmapping from dysarthric to clean speech. Our findings highlight the\neffectiveness of discrete acoustic units in improving intelligibility while\nachieving faster convergence compared to traditional mel-spectrogram-based\napproaches.", "published": "2025-06-19 08:24:17", "link": "http://arxiv.org/abs/2506.16127v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VS-Singer: Vision-Guided Stereo Singing Voice Synthesis with Consistency Schr\u00f6dinger Bridge", "abstract": "To explore the potential advantages of utilizing spatial cues from images for\ngenerating stereo singing voices with room reverberation, we introduce\nVS-Singer, a vision-guided model designed to produce stereo singing voices with\nroom reverberation from scene images. VS-Singer comprises three modules:\nfirstly, a modal interaction network integrates spatial features into text\nencoding to create a linguistic representation enriched with spatial\ninformation. Secondly, the decoder employs a consistency Schr\\\"odinger bridge\nto facilitate one-step sample generation. Moreover, we utilize the SFE module\nto improve the consistency of audio-visual matching. To our knowledge, this\nstudy is the first to combine stereo singing voice synthesis with visual\nacoustic matching within a unified framework. Experimental results demonstrate\nthat VS-Singer can effectively generate stereo singing voices that align with\nthe scene perspective in a single step.", "published": "2025-06-19 04:34:53", "link": "http://arxiv.org/abs/2506.16020v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion", "abstract": "The rapid advancement of AI-based music generation tools is revolutionizing\nthe music industry but also posing challenges to artists, copyright holders,\nand providers alike. This necessitates reliable methods for detecting such\nAI-generated content. However, existing detectors, relying on either audio or\nlyrics, face key practical limitations: audio-based detectors fail to\ngeneralize to new or unseen generators and are vulnerable to audio\nperturbations; lyrics-based methods require cleanly formatted and accurate\nlyrics, unavailable in practice. To overcome these limitations, we propose a\nnovel, practically grounded approach: a multimodal, modular late-fusion\npipeline that combines automatically transcribed sung lyrics and speech\nfeatures capturing lyrics-related information within the audio. By relying on\nlyrical aspects directly from audio, our method enhances robustness, mitigates\nsusceptibility to low-level artifacts, and enables practical applicability.\nExperiments show that our method, DE-detect, outperforms existing lyrics-based\ndetectors while also being more robust to audio perturbations. Thus, it offers\nan effective, robust solution for detecting AI-generated music in real-world\nscenarios. Our code is available at\nhttps://github.com/deezer/robust-AI-lyrics-detection.", "published": "2025-06-19 02:56:49", "link": "http://arxiv.org/abs/2506.15981v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SparseDPD: A Sparse Neural Network-based Digital Predistortion FPGA Accelerator for RF Power Amplifier Linearization", "abstract": "Digital predistortion (DPD) is crucial for linearizing radio frequency (RF)\npower amplifiers (PAs), improving signal integrity and efficiency in wireless\nsystems. Neural network (NN)-based DPD methods surpass traditional polynomial\nmodels but face computational challenges limiting their practical deployment.\nThis paper introduces SparseDPD, an FPGA accelerator employing a spatially\nsparse phase-normalized time-delay neural network (PNTDNN), optimized through\nunstructured pruning to reduce computational load without accuracy loss.\nImplemented on a Xilinx Zynq-7Z010 FPGA, SparseDPD operates at 170 MHz,\nachieving exceptional linearization performance (ACPR: -59.4 dBc, EVM: -54.0\ndBc, NMSE: -48.2 dB) with only 241 mW dynamic power, using 64 parameters with\n74% sparsity. This work demonstrates FPGA-based acceleration, making NN-based\nDPD practical and efficient for real-time wireless communication applications.\nCode is publicly available at https://github.com/MannoVersluis/SparseDPD.", "published": "2025-06-19 20:26:05", "link": "http://arxiv.org/abs/2506.16591v1", "categories": ["cs.AR", "eess.SP"], "primary_category": "cs.AR"}
{"title": "Manifold Learning for Personalized and Label-Free Detection of Cardiac Arrhythmias", "abstract": "Electrocardiograms (ECGs) provide direct, non-invasive measurements of heart\nactivity and are well-established tools for detecting and monitoring\ncardiovascular disease. However, manual ECG analysis can be time-consuming and\nprone to errors. Machine learning has emerged as a promising approach for\nautomated heartbeat recognition and classification, but substantial variations\nin ECG signals make it challenging to develop generalizable models. ECG signals\ncan vary widely across individuals and leads, while datasets often follow\ndifferent labeling standards and may be biased, all of which greatly hinder\nsupervised methods. Conventional unsupervised methods, e.g. principal component\nanalysis, prioritize large (and often obvious) variances in the data and\ntypically overlook subtle yet clinically relevant patterns. If labels are\nmissing and/or variations are significant but small, both approaches fail.\nHere, we show that nonlinear dimensionality reduction (NLDR) can accommodate\nthese issues and identify medically relevant features in ECG signals, with no\nneed for training or prior information. Using the MLII and V1 leads of the\nMIT-BIH dataset, we demonstrate that t-distributed stochastic neighbor\nembedding and uniform manifold approximation and projection can discriminate\nindividual recordings in mixed populations with >= 90% accuracy and distinguish\ndifferent arrhythmias in individual patients with a median accuracy of 98.96%\nand a median F1-score of 91.02%. The results show that NLDR holds much promise\nfor cardiac monitoring, including the limiting cases of single-lead ECG and the\ncurrent 12-lead standard of care, and for personalized health care beyond\ncardiology.", "published": "2025-06-19 17:39:57", "link": "http://arxiv.org/abs/2506.16494v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "A Tractable Approach to Massive Communication and Ubiquitous Connectivity in 6G Standardization", "abstract": "The full-scale 6G standardization has attracted considerable recent\nattention, especially since the first 3GPP-wide 6G workshop held in March 2025.\nTo understand the practical and fundamental values of 6G and facilitate its\nstandardization, it is crucial to explore the theoretical limits of spectrum,\nenergy, and coverage efficiency considering practical hardware and signaling\nconstraints. In this paper, we present a mean-field-approximation-based\ninvestigation on two out of six use case scenarios defined by IMT-2030, namely,\nmassive communication and ubiquitous connectivity. Being aware of the\nlimitation in interference cancellation owing to constrained cost and hardware\ncomplexity, we investigate the spectrum reuse architecture in both usage\nscenarios. We propose a tractable spectrum reuse with low signaling overhead\nconsumed for channel estimation and channel state information (CSI) feedback.\nOur analysis indicates that the massive communication over cellular and\ndevice-to-device (D2D) networks can benefit from channel orthogonalization,\nwhile it is unnecessary to share the CSI of interfering links. Moreover,\ndeploying relays or movable base stations, e.g. unmanned aerial vehicle, yields\nsubstantial energy and spectrum gain for ubiquitous connectivity, despite\nintroducing interference. As such, the mean-field-optimization-based evaluation\nis expected to positively impact 6G and NextG standardization in 3GPP and other\nstandardization bodies.", "published": "2025-06-19 13:24:34", "link": "http://arxiv.org/abs/2506.16304v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Refining Ray-Tracing Accuracy and Efficiency in the Context of FRMCS Urban Railway Channel Predictions", "abstract": "The upcoming roll-out of the new wireless communication standard for wireless\nrailway services, FRMCS, requires a thorough understanding of the system\nperformance in real-world conditions, since this will strongly influence the\ndeployment costs and the effectiveness of an infrastructure planned for\ndecades. The virtual testing of the equipment and network performance in\nrealistic simulated scenarios is key; its accuracy depends on the reliability\nof the predicted radio channel properties. In this article, the authors explain\nhow they are evolving a ray-tracing (RT) tool to apply it to the specific case\nof simulating the radio link between the FRMCS fixed infrastructure and an\nantenna placed on the roof of a train moving in an urban environment. First, a\ndynamic version of the RT tool is used to capture the rapid variations of all\nchannel metrics; a compromise is sought between computation time and accuracy.\nBesides, a hybridization of RT and physical optics (PO) allows the integration\nof objects near the track, such as catenary pylons, into the simulation. A case\nstudy shows that the scattering by metallic pylons brings a significant\ncontribution.", "published": "2025-06-19 11:47:53", "link": "http://arxiv.org/abs/2506.16236v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On Designing Modulation for Over-the-Air Computation -- Part II: Pyramid Sampling", "abstract": "Over-the-air computation (OAC) harnesses the natural superposition of\nwireless signals to compute aggregate functions during transmission, thereby\ncollapsing communication and computation into a single step and significantly\nreducing latency and resource usage. In Part I, digital OAC was formulated as a\nnoise-aware constellation design problem by casting encoder design as a max-min\noptimization that aligns minimum Euclidean distances between superimposed\nconstellation points with squared differences of their corresponding function\noutputs.\n  In this paper, Part II, we address the prohibitive complexity and\nquantization challenges inherent in digital OAC constellation design for\nlarge-scale edge networks. More precisely, we introduce a pyramid sampling\nstrategy that judiciously selects a subset of superimposed constellation points\nto reduce the encoder design complexity from $\\mathcal{O}(q^K)$ to\n$\\mathcal{O}(q^{K-p+1})$, where $p\\in\\{1,\\dots, K\\}$ denotes the sampling\norder, $q$ levels of modulation, and $K$ denotes the number nodes in the\nnetwork. Under the assumption of symmetric aggregation, this approach enables a\ncontrolled trade-off between computational complexity and function computation\naccuracy. As a special case, we propose majority-based sampling ($p=K$), which\nconfines aggregation to only $q$ consensus points, inherently avoiding\ndestructive overlaps and permitting the use of standard digital modulations\n(e.g., QAM, PSK, ASK) without bespoke constellation designs. We also show via\nseveral simulations, across various aggregation functions, modulation levels,\nand noise levels, that moderate sampling orders attain acceptable performance\nwith orders-of-magnitude fewer constraints than exhaustive designs.", "published": "2025-06-19 10:56:59", "link": "http://arxiv.org/abs/2506.16208v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "MASC: Integrated Sensing and Communications for the Martian Internet of Space", "abstract": "Mars exploration missions increasingly demand reliable communication systems,\nyet harsh environmental conditions -- particularly frequent dust storms,\nextreme Doppler effects, and stringent resource constraints -- pose\nunprecedented challenges to conventional communication approaches. This paper\npresents the Martian Adaptive Sensing and Communication (MASC) system\nspecifically designed for the Martian environment. MASC establishes a\nphysically interpretable channel model and develops three key components:\nenvironment-aware hybrid precoding, adaptive parameter mapping, and robust\ncommunication precoding. Simulation results demonstrate that MASC maintains 45\npercent sensing coverage under severe dust conditions compared to only 5\npercent with conventional methods, provides up to 2.5 dB\nsignal-to-interference-plus-noise ratio (SINR) improvement at 50 percent\nchannel state information (CSI) uncertainty, and yields 80 percent higher\ncapacity in moderate dust storms. Using an epsilon-constraint multi-objective\noptimization approach, we enable mission planners to select operational modes\nranging from communication-priority (0.33 bps/Hz capacity, 28 percent sensing\ncoverage) to sensing-priority (90 percent coverage with minimal capacity),\noffering a versatile framework that balances environmental awareness with\nhyper-reliable data transmission. This work provides a validated blueprint for\nintegrated sensing and communication (ISAC) in non-terrestrial networks (NTN),\na key enabler for achieving ubiquitous connectivity in the 6G era.", "published": "2025-06-19 10:26:18", "link": "http://arxiv.org/abs/2506.16198v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "DCFNet: Doppler Correction Filter Network for Integrated Sensing and Communication in Multi-User MIMO-OFDM Systems", "abstract": "Integrated sensing and communication (ISAC) is a headline feature for the\nforthcoming IMT-2030 and 6G releases, yet a concrete solution that fits within\nthe established orthogonal frequency division multiplexing (OFDM) family\nremains open. Specifically, Doppler-induced inter-carrier interference (ICI)\ndestroys sub-carrier orthogonality of OFDM sensing signals, blurring\nrange-velocity maps and severely degrading sensing accuracy. Building on\nmulti-user multi-input-multi-output (MIMO) OFDM systems, this paper proposes\nDoppler-Correction Filter Network (DCFNet), an AI-native ISAC model that\ndelivers fine range-velocity resolution at minimal complexity without altering\nthe legacy frame structure. A bank of DCFs first shifts dominant ICI energy\naway from critical Doppler bins; a compact deep learning network then\nsuppresses the ICI. To further enhance the range and velocity resolutions, we\npropose DCFNet with local refinement (DCFNet-LR), which applies a generalized\nlikelihood ratio test (GLRT) to refine target estimates of DCFNet to sub-cell\naccuracy. Simulation results show that DCFNet-LR runs $143\\times$ faster than\nmaximum likelihood search and achieves significantly superior performance,\nreducing the range RMSE by up to $2.7 \\times 10^{-4}$ times and the velocity\nRMSE by $6.7 \\times 10^{-4}$ times compared to conventional detection methods.", "published": "2025-06-19 10:13:27", "link": "http://arxiv.org/abs/2506.16191v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multigroup Multicast Design for Pinching-Antenna Systems: Waveguide-Division or Waveguide-Multiplexing?", "abstract": "This article addresses the design of multigroup multicast communications in\nthe pinching-antenna system (PASS). A PASS-enabled multigroup transmission\nframework is proposed to maximize multicast rates under a couple of\ntransmission architectures: waveguide-division (WD) and waveguide-multiplexing\n(WM). 1) For WD, an element-wise sequential optimization strategy is proposed\nfor pinching beamforming, i.e., optimizing the activated positions of pinching\nantennas along dielectric waveguides. Meanwhile, a log-sum-exp projected\ngradient descent algorithm is proposed for transmit power allocation across\nwaveguides. 2) For WM, a majorization-minimization (MM)-based framework is\nproposed to tackle the problem's non-smoothness and non-convexity. On this\nbasis, a low-complexity element-wise sequential optimization method is\ndeveloped for pinching beamforming using the MM surrogate objective.\nFurthermore, the optimal transmit beamformer structure is derived from the MM\nsurrogate objective using the Lagrange duality, with an efficient transmit\nbeamforming algorithm proposed using projected adaptive gradient descent.\nNumerical results demonstrate that: i) both WD and WM architectures in PASS\nachieve significant multicast rate improvements over conventional MIMO\ntechniques, especially for systems with large service areas; ii) WM is more\nrobust than WD in dense deployments, while WD excels when user groups are\nspatially separated.", "published": "2025-06-19 10:03:06", "link": "http://arxiv.org/abs/2506.16184v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Towards AI-Driven RANs for 6G and Beyond: Architectural Advancements and Future Horizons", "abstract": "It is envisioned that 6G networks will be supported by key architectural\nprinciples, including intelligence, decentralization, interoperability, and\ndigitalization. With the advances in artificial intelligence (AI) and machine\nlearning (ML), embedding intelligence into the foundation of wireless\ncommunication systems is recognized as essential for 6G and beyond. Existing\nradio access network (RAN) architectures struggle to meet the ever growing\ndemands for flexibility, automation, and adaptability required to build\nself-evolving and autonomous wireless networks. In this context, this paper\nexplores the transition towards AI-driven RAN (AI-RAN) by developing a novel\nAI-RAN framework whose performance is evaluated through a practical scenario\nfocused on intelligent orchestration and resource optimization. Besides, the\npaper reviews the evolution of RAN architectures and sheds light on key\nenablers of AI-RAN including digital twins (DTs), intelligent reflecting\nsurfaces (IRSs), large generative AI (GenAI) models, and blockchain (BC).\nFurthermore, it discusses the deployment challenges of AI-RAN, including\ntechnical and regulatory perspectives, and outlines future research directions\nincorporating technologies such as integrated sensing and communication (ISAC)\nand agentic AI.", "published": "2025-06-19 06:54:14", "link": "http://arxiv.org/abs/2506.16070v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Scalable Factorization Approach for High-Order Structured Tensor Recovery", "abstract": "Tensor decompositions, which represent an $N$-order tensor using\napproximately $N$ factors of much smaller dimensions, can significantly reduce\nthe number of parameters. This is particularly beneficial for high-order\ntensors, as the number of entries in a tensor grows exponentially with the\norder. Consequently, they are widely used in signal recovery and data analysis\nacross domains such as signal processing, machine learning, and quantum\nphysics. A computationally and memory-efficient approach to these problems is\nto optimize directly over the factors using local search algorithms such as\ngradient descent, a strategy known as the factorization approach in matrix and\ntensor optimization. However, the resulting optimization problems are highly\nnonconvex due to the multiplicative interactions between factors, posing\nsignificant challenges for convergence analysis and recovery guarantees.\n  In this paper, we present a unified framework for the factorization approach\nto solving various tensor decomposition problems. Specifically, by leveraging\nthe canonical form of tensor decompositions--where most factors are constrained\nto be orthonormal to mitigate scaling ambiguity--we apply Riemannian gradient\ndescent (RGD) to optimize these orthonormal factors on the Stiefel manifold.\nUnder a mild condition on the loss function, we establish a Riemannian\nregularity condition for the factorized objective and prove that RGD converges\nto the ground-truth tensor at a linear rate when properly initialized. Notably,\nboth the initialization requirement and the convergence rate scale polynomially\nrather than exponentially with $N$, improving upon existing results for Tucker\nand tensor-train format tensors.", "published": "2025-06-19 05:07:07", "link": "http://arxiv.org/abs/2506.16032v1", "categories": ["cs.LG", "eess.SP", "math.OC"], "primary_category": "cs.LG"}
{"title": "Multi-Domain Optimization Framework for ISAC: From Electromagnetic Shaping to Network Cooperation", "abstract": "Integrated sensing and communication (ISAC) has emerged as a key feature for\nsixth-generation (6G) networks, providing an opportunity to meet the dual\ndemands of communication and sensing. Existing ISAC research primarily focuses\non baseband optimization at individual access points, with limited attention to\nthe roles of electromagnetic (EM) shaping and network-wide coordination. The\nintricate interdependencies between these domains remain insufficiently\nexplored, leaving their full potential for enhancing ISAC performance largely\nuntapped. To bridge this gap, we consider multi-domain ISAC optimization\nintegrating EM shaping, baseband processing, and network cooperation strategies\nthat facilitate efficient resource management and system-level design. We\nanalyze the fundamental trade-offs between these domains and offer insights\ninto domain-specific and cross-domain strategies contributing to ISAC\nperformance and efficiency. We then conduct a case study demonstrating the\neffectiveness of joint multi-domain optimization. Finally, we discuss key\nchallenges and future research directions to connect theoretical advancements\nand practical ISAC deployments. This work paves the way for intelligent and\nscalable ISAC architectures, providing critical insights for their seamless\nintegration into next-generation wireless networks.", "published": "2025-06-19 04:12:37", "link": "http://arxiv.org/abs/2506.16011v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Exploiting Both Pilots and Data Payloads for Integrated Sensing and Communications", "abstract": "Integrated sensing and communications (ISAC) is one of the key enabling\ntechnologies in future sixth-generation (6G) networks. Current ISAC systems\npredominantly rely on deterministic pilot signals within the signal frame to\naccomplish sensing tasks. However, these pilot signals typically occupy only a\nsmall portion, e.g., 0.15% to 25%, of the time-frequency resources. To enhance\nthe system utility, a promising solution is to repurpose the extensive random\ndata payload signals for sensing tasks. In this paper, we analyze the ISAC\nperformance of a multi-antenna system where both deterministic pilot and random\ndata symbols are employed for sensing tasks. By capitalizing on random matrix\ntheory (RMT), we first derive a semi-closed-form asymptotic expression of the\nergodic linear minimum mean square error (ELMMSE). Then, we formulate an ISAC\nprecoding optimization problem to minimize the ELMMSE, which is solved via a\nspecifically tailored successive convex approximation (SAC) algorithm. To\nprovide system insights, we further derive a closed-form expression for the\nasymptotic ELMMSE at high signal-to-noise ratios (SNRs). Our analysis reveals\nthat, compared with conventional sensing implemented by deterministic signals,\nthe sensing performance degradation induced by random signals is critically\ndetermined by the ratio of the transmit antenna size to the data symbol length.\nBased on this result, the ISAC precoding optimization problem at high SNRs is\ntransformed into a convex optimization problem that can be efficiently solved.\nSimulation results validate the accuracy of the derived asymptotic expressions\nof ELMMSE and the performance of the proposed precoding schemes. Particularly,\nby leveraging data payload signals for sensing tasks, the sensing error is\nreduced by up to 5.6 dB compared to conventional pilot-based sensing.", "published": "2025-06-19 03:43:21", "link": "http://arxiv.org/abs/2506.15998v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Low-Cost Portable Lidar-based Mobile Mapping System on an Android Smartphone", "abstract": "The rapid advancement of the metaverse, digital twins, and robotics\nunderscores the demand for low-cost, portable mapping systems for reality\ncapture. Current mobile solutions, such as the Leica BLK2Go and lidar-equipped\nsmartphones, either come at a high cost or are limited in range and accuracy.\nLeveraging the proliferation and technological evolution of mobile devices\nalongside recent advancements in lidar technology, we introduce a novel,\nlow-cost, portable mobile mapping system. Our system integrates a lidar unit,\nan Android smartphone, and an RTK-GNSS stick. Running on the Android platform,\nit features lidar-inertial odometry built with the NDK, and logs data from the\nlidar, wide-angle camera, IMU, and GNSS. With a total bill of materials (BOM)\ncost under 2,000 USD and a weight of about 1 kilogram, the system achieves a\ngood balance between affordability and portability. We detail the system\ndesign, multisensor calibration, synchronization, and evaluate its performance\nfor tracking and mapping. To further contribute to the community, the system's\ndesign and software are made open source at:\nhttps://github.com/OSUPCVLab/marslogger_android/releases/tag/v2.1", "published": "2025-06-19 03:01:01", "link": "http://arxiv.org/abs/2506.15983v1", "categories": ["cs.RO", "eess.SP"], "primary_category": "cs.RO"}
{"title": "Theoretical Analysis of Near-Field MIMO Channel Capacity and Mid-Band Experimental Validation", "abstract": "With the increase of multiple-input-multiple-output (MIMO) array size and\ncarrier frequency, near-field MIMO communications will become crucial in 6G\nwireless networks. Due to the increase of MIMO near-field range, the research\nof near-field MIMO capacity has aroused wide interest. In this paper, we focus\non the theoretical analysis and empirical study of near-field MIMO capacity.\nFirst, the near-field channel model is characterized from the electromagnetic\ninformation perspective. Second, with the uniform planar array (UPA), the\nchannel capacity based on effective degree of freedom (EDoF) is analyzed\ntheoretically, and the closed-form analytical expressions are derived in\ndetail. Finally, based on the numerical verification of near-field channel\nmeasurement experiment at 13 GHz band, we reveal that the channel capacity of\nUPA-type MIMO systems decreases continuously with the communication distance\nincreasing. It can be observed that the near-field channel capacity gain is\nrelatively obvious when large-scale MIMO is adopted at both receiving and\ntransmitter ends, but the near-field channel capacity gain may be limited in\nthe actual communication system with the small antenna array at receiving end.\nThis work will give some reference to the near-field communication systems.", "published": "2025-06-19 02:35:07", "link": "http://arxiv.org/abs/2506.15972v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On Designing Modulation for Over-the-Air Computation -- Part I: Noise-Aware Design", "abstract": "Over-the-air computation (OAC) leverages the physical superposition property\nof wireless multiple access channels (MACs) to compute functions while\ncommunication occurs, enabling scalable and low-latency processing in\ndistributed networks. While analog OAC methods suffer from noise sensitivity\nand hardware constraints, existing digital approaches are often limited in\ndesign complexity, which may hinder scalability and fail to exploit spectral\nefficiency fully. This two-part paper revisits and extends the ChannelComp\nframework, a general methodology for computing arbitrary finite-valued\nfunctions using digital modulation. In Part I, we develop a novel constellation\ndesign approach that is aware of the noise distribution and formulates the\nencoder design as a max-min optimization problem using noise-tailored distance\nmetrics. Our design supports noise models, including Gaussian, Laplace, and\nheavy-tailed distributions. We further demonstrate that, for heavy-tailed\nnoise, the optimal ChannelComp setup coincides with the solution to the\ncorresponding max-min criterion for the channel noise with heavy-tailed\ndistributions. Numerical experiments confirm that our noise-aware design\nachieves a substantially lower mean-square error than leading digital OAC\nmethods over noisy MACs. In Part II, we consider a constellation design with a\nquantization-based sampling scheme to enhance modulation scalability and\ncomputational accuracy for large-scale digital OAC.", "published": "2025-06-19 01:26:08", "link": "http://arxiv.org/abs/2506.15950v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "HybridRAG-based LLM Agents for Low-Carbon Optimization in Low-Altitude Economy Networks", "abstract": "Low-Altitude Economy Networks (LAENets) are emerging as a promising paradigm\nto support various low-altitude services through integrated air-ground\ninfrastructure. To satisfy low-latency and high-computation demands, the\nintegration of Unmanned Aerial Vehicles (UAVs) with Mobile Edge Computing (MEC)\nsystems plays a vital role, which offloads computing tasks from terminal\ndevices to nearby UAVs, enabling flexible and resilient service provisions for\nground users. To promote the development of LAENets, it is significant to\nachieve low-carbon multi-UAV-assisted MEC networks. However, several challenges\nhinder this implementation, including the complexity of multi-dimensional UAV\nmodeling and the difficulty of multi-objective coupled optimization. To this\nend, this paper proposes a novel Retrieval Augmented Generation (RAG)-based\nLarge Language Model (LLM) agent framework for model formulation. Specifically,\nwe develop HybridRAG by combining KeywordRAG, VectorRAG, and GraphRAG,\nempowering LLM agents to efficiently retrieve structural information from\nexpert databases and generate more accurate optimization problems compared with\ntraditional RAG-based LLM agents. After customizing carbon emission\noptimization problems for multi-UAV-assisted MEC networks, we propose a Double\nRegularization Diffusion-enhanced Soft Actor-Critic (R\\textsuperscript{2}DSAC)\nalgorithm to solve the formulated multi-objective optimization problem. The\nR\\textsuperscript{2}DSAC algorithm incorporates diffusion entropy\nregularization and action entropy regularization to improve the performance of\nthe diffusion policy. Furthermore, we dynamically mask unimportant neurons in\nthe actor network to reduce the carbon emissions associated with model\ntraining. Simulation results demonstrate the effectiveness and reliability of\nthe proposed HybridRAG-based LLM agent framework and the\nR\\textsuperscript{2}DSAC algorithm.", "published": "2025-06-19 01:11:35", "link": "http://arxiv.org/abs/2506.15947v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Arch-Router: Aligning LLM Routing with Human Preferences", "abstract": "With the rapid proliferation of large language models (LLMs) -- each\noptimized for different strengths, style, or latency/cost profile -- routing\nhas become an essential technique to operationalize the use of different\nmodels. However, existing LLM routing approaches are limited in two key ways:\nthey evaluate performance using benchmarks that often fail to capture human\npreferences driven by subjective evaluation criteria, and they typically select\nfrom a limited pool of models. In this work, we propose a preference-aligned\nrouting framework that guides model selection by matching queries to\nuser-defined domains (e.g., travel) or action types (e.g., image editing) --\noffering a practical mechanism to encode preferences in routing decisions.\nSpecifically, we introduce \\textbf{Arch-Router}, a compact 1.5B model that\nlearns to map queries to domain-action preferences for model routing decisions.\nOur approach also supports seamlessly adding new models for routing without\nrequiring retraining or architectural modifications. Experiments on\nconversational datasets demonstrate that our approach achieves state-of-the-art\n(SOTA) results in matching queries with human preferences, outperforming top\nproprietary models. Our approach captures subjective evaluation criteria and\nmakes routing decisions more transparent and flexible. Our model is available\nat: \\texttt{https://huggingface.co/katanemo/Arch-Router-1.5B}.", "published": "2025-06-19 23:57:41", "link": "http://arxiv.org/abs/2506.16655v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Long-Context Generalization with Sparse Attention", "abstract": "Transformer-based architectures traditionally employ softmax to compute\nattention weights, which produces dense distributions over all tokens in a\nsequence. While effective in many settings, this density has been shown to be\ndetrimental for tasks that demand precise focus on fixed-size patterns: as\nsequence length increases, non-informative tokens accumulate attention\nprobability mass, leading to dispersion and representational collapse. We show\nin this paper that sparse attention mechanisms using $\\alpha$-entmax can avoid\nthese issues, due to their ability to assign exact zeros to irrelevant tokens.\nFurthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows\n$\\alpha$-entmax with a learnable temperature parameter, allowing the attention\ndistribution to interpolate between sparse (pattern-focused) and dense\n(softmax-like) regimes. Finally, we show that the ability to locate and\ngeneralize fixed-size patterns can be further improved through a careful design\nof position encodings, which impacts both dense and sparse attention methods.\nBy integrating ASEntmax into standard transformer layers alongside proper\npositional encodings, we show that our models greatly outperform softmax,\nscalable softmax, and fixed-temperature $\\alpha$-entmax baselines on\nlong-context generalization.", "published": "2025-06-19 22:43:25", "link": "http://arxiv.org/abs/2506.16640v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GeoGuess: Multimodal Reasoning based on Hierarchy of Visual Information in Street View", "abstract": "Multimodal reasoning is a process of understanding, integrating and inferring\ninformation across different data modalities. It has recently attracted surging\nacademic attention as a benchmark for Artificial Intelligence (AI). Although\nthere are various tasks for evaluating multimodal reasoning ability, they still\nhave limitations. Lack of reasoning on hierarchical visual clues at different\nlevels of granularity, e.g., local details and global context, is of little\ndiscussion, despite its frequent involvement in real scenarios. To bridge the\ngap, we introduce a novel and challenging task for multimodal reasoning, namely\nGeoGuess. Given a street view image, the task is to identify its location and\nprovide a detailed explanation. A system that succeeds in GeoGuess should be\nable to detect tiny visual clues, perceive the broader landscape, and associate\nwith vast geographic knowledge. Therefore, GeoGuess would require the ability\nto reason between hierarchical visual information and geographic knowledge. In\nthis work, we establish a benchmark for GeoGuess by introducing a specially\ncurated dataset GeoExplain which consists of\npanoramas-geocoordinates-explanation tuples. Additionally, we present a\nmultimodal and multilevel reasoning method, namely SightSense which can make\nprediction and generate comprehensive explanation based on hierarchy of visual\ninformation and external knowledge. Our analysis and experiments demonstrate\ntheir outstanding performance in GeoGuess.", "published": "2025-06-19 22:19:31", "link": "http://arxiv.org/abs/2506.16633v1", "categories": ["cs.CL", "cs.AI", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Modeling Public Perceptions of Science in Media", "abstract": "Effectively engaging the public with science is vital for fostering trust and\nunderstanding in our scientific community. Yet, with an ever-growing volume of\ninformation, science communicators struggle to anticipate how audiences will\nperceive and interact with scientific news. In this paper, we introduce a\ncomputational framework that models public perception across twelve dimensions,\nsuch as newsworthiness, importance, and surprisingness. Using this framework,\nwe create a large-scale science news perception dataset with 10,489 annotations\nfrom 2,101 participants from diverse US and UK populations, providing valuable\ninsights into public responses to scientific information across domains. We\nfurther develop NLP models that predict public perception scores with a strong\nperformance. Leveraging the dataset and model, we examine public perception of\nscience from two perspectives: (1) Perception as an outcome: What factors\naffect the public perception of scientific information? (2) Perception as a\npredictor: Can we use the estimated perceptions to predict public engagement\nwith science? We find that individuals' frequency of science news consumption\nis the driver of perception, whereas demographic factors exert minimal\ninfluence. More importantly, through a large-scale analysis and carefully\ndesigned natural experiment on Reddit, we demonstrate that the estimated public\nperception of scientific information has direct connections with the final\nengagement pattern. Posts with more positive perception scores receive\nsignificantly more comments and upvotes, which is consistent across different\nscientific information and for the same science, but are framed differently.\nOverall, this research underscores the importance of nuanced perception\nmodeling in science communication, offering new pathways to predict public\ninterest and engagement with scientific content.", "published": "2025-06-19 21:49:28", "link": "http://arxiv.org/abs/2506.16622v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "A Scoping Review of Synthetic Data Generation for Biomedical Research and Applications", "abstract": "Synthetic data generation--mitigating data scarcity, privacy concerns, and\ndata quality challenges in biomedical fields--has been facilitated by rapid\nadvances of large language models (LLMs). This scoping review follows\nPRISMA-ScR guidelines and synthesizes 59 studies, published between 2020 and\n2025 and collected from PubMed, ACM, Web of Science, and Google Scholar. The\nreview systematically examines biomedical research and application trends in\nsynthetic data generation, emphasizing clinical applications, methodologies,\nand evaluations. Our analysis identifies data modalities of unstructured texts\n(78.0%), tabular data (13.6%), and multimodal sources (8.4%); generation\nmethods of prompting (72.9%), fine-tuning (22.0%) LLMs and specialized model\n(5.1%); and heterogeneous evaluations of intrinsic metrics (27.1%),\nhuman-in-the-loop assessments (55.9%), and LLM-based evaluations (13.6%). The\nanalysis addresses current limitations in what, where, and how health\nprofessionals can leverage synthetic data generation for biomedical domains.\nOur review also highlights challenges in adaption across clinical domains,\nresource and model accessibility, and evaluation standardizations.", "published": "2025-06-19 20:38:17", "link": "http://arxiv.org/abs/2506.16594v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancing Harmful Content Detection in Organizational Research: Integrating Large Language Models with Elo Rating System", "abstract": "Large language models (LLMs) offer promising opportunities for organizational\nresearch. However, their built-in moderation systems can create problems when\nresearchers try to analyze harmful content, often refusing to follow certain\ninstructions or producing overly cautious responses that undermine validity of\nthe results. This is particularly problematic when analyzing organizational\nconflicts such as microaggressions or hate speech. This paper introduces an Elo\nrating-based method that significantly improves LLM performance for harmful\ncontent analysis In two datasets, one focused on microaggression detection and\nthe other on hate speech, we find that our method outperforms traditional LLM\nprompting techniques and conventional machine learning models on key measures\nsuch as accuracy, precision, and F1 scores. Advantages include better\nreliability when analyzing harmful content, fewer false positives, and greater\nscalability for large-scale datasets. This approach supports organizational\napplications, including detecting workplace harassment, assessing toxic\ncommunication, and fostering safer and more inclusive work environments.", "published": "2025-06-19 20:01:12", "link": "http://arxiv.org/abs/2506.16575v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Relic: Enhancing Reward Model Generalization for Low-Resource Indic Languages with Few-Shot Examples", "abstract": "Reward models are essential for aligning large language models (LLMs) with\nhuman preferences. However, most open-source multilingual reward models are\nprimarily trained on preference datasets in high-resource languages, resulting\nin unreliable reward signals for low-resource Indic languages. Collecting\nlarge-scale, high-quality preference data for these languages is prohibitively\nexpensive, making preference-based training approaches impractical. To address\nthis challenge, we propose RELIC, a novel in-context learning framework for\nreward modeling in low-resource Indic languages. RELIC trains a retriever with\na pairwise ranking objective to select in-context examples from auxiliary\nhigh-resource languages that most effectively highlight the distinction between\npreferred and less-preferred responses. Extensive experiments on three\npreference datasets- PKU-SafeRLHF, WebGPT, and HH-RLHF-using state-of-the-art\nopen-source reward models demonstrate that RELIC significantly improves reward\nmodel accuracy for low-resource Indic languages, consistently outperforming\nexisting example selection methods. For example, on Bodo-a low-resource Indic\nlanguage-using a LLaMA-3.2-3B reward model, RELIC achieves a 12.81% and 10.13%\nimprovement in accuracy over zero-shot prompting and state-of-the-art example\nselection method, respectively.", "published": "2025-06-19 17:56:16", "link": "http://arxiv.org/abs/2506.16502v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Generalizable Generic Harmful Speech Datasets for Implicit Hate Speech Detection", "abstract": "Implicit hate speech has recently emerged as a critical challenge for social\nmedia platforms. While much of the research has traditionally focused on\nharmful speech in general, the need for generalizable techniques to detect\nveiled and subtle forms of hate has become increasingly pressing. Based on\nlexicon analysis, we hypothesize that implicit hate speech is already present\nin publicly available harmful speech datasets but may not have been explicitly\nrecognized or labeled by annotators. Additionally, crowdsourced datasets are\nprone to mislabeling due to the complexity of the task and often influenced by\nannotators' subjective interpretations. In this paper, we propose an approach\nto address the detection of implicit hate speech and enhance generalizability\nacross diverse datasets by leveraging existing harmful speech datasets. Our\nmethod comprises three key components: influential sample identification,\nreannotation, and augmentation using Llama-3 70B and GPT-4o. Experimental\nresults demonstrate the effectiveness of our approach in improving implicit\nhate detection, achieving a +12.9-point F1 score improvement compared to the\nbaseline.", "published": "2025-06-19 17:23:08", "link": "http://arxiv.org/abs/2506.16476v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Do We Talk to Robots Like Therapists, and Do They Respond Accordingly? Language Alignment in AI Emotional Support", "abstract": "As conversational agents increasingly engage in emotionally supportive\ndialogue, it is important to understand how closely their interactions resemble\nthose in traditional therapy settings. This study investigates whether the\nconcerns shared with a robot align with those shared in human-to-human (H2H)\ntherapy sessions, and whether robot responses semantically mirror those of\nhuman therapists. We analyzed two datasets: one of interactions between users\nand professional therapists (Hugging Face's NLP Mental Health Conversations),\nand another involving supportive conversations with a social robot (QTrobot\nfrom LuxAI) powered by a large language model (LLM, GPT-3.5). Using sentence\nembeddings and K-means clustering, we assessed cross-agent thematic alignment\nby applying a distance-based cluster-fitting method that evaluates whether\nresponses from one agent type map to clusters derived from the other, and\nvalidated it using Euclidean distances. Results showed that 90.88% of robot\nconversation disclosures could be mapped to clusters from the human therapy\ndataset, suggesting shared topical structure. For matched clusters, we compared\nthe subjects as well as therapist and robot responses using Transformer,\nWord2Vec, and BERT embeddings, revealing strong semantic overlap in subjects'\ndisclosures in both datasets, as well as in the responses given to similar\nhuman disclosure themes across agent types (robot vs. human therapist). These\nfindings highlight both the parallels and boundaries of robot-led support\nconversations and their potential for augmenting mental health interventions.", "published": "2025-06-19 17:20:30", "link": "http://arxiv.org/abs/2506.16473v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Probe before You Talk: Towards Black-box Defense against Backdoor Unalignment for Large Language Models", "abstract": "Backdoor unalignment attacks against Large Language Models (LLMs) enable the\nstealthy compromise of safety alignment using a hidden trigger while evading\nnormal safety auditing. These attacks pose significant threats to the\napplications of LLMs in the real-world Large Language Model as a Service\n(LLMaaS) setting, where the deployed model is a fully black-box system that can\nonly interact through text. Furthermore, the sample-dependent nature of the\nattack target exacerbates the threat. Instead of outputting a fixed label, the\nbackdoored LLM follows the semantics of any malicious command with the hidden\ntrigger, significantly expanding the target space. In this paper, we introduce\nBEAT, a black-box defense that detects triggered samples during inference to\ndeactivate the backdoor. It is motivated by an intriguing observation (dubbed\nthe probe concatenate effect), where concatenated triggered samples\nsignificantly reduce the refusal rate of the backdoored LLM towards a malicious\nprobe, while non-triggered samples have little effect. Specifically, BEAT\nidentifies whether an input is triggered by measuring the degree of distortion\nin the output distribution of the probe before and after concatenation with the\ninput. Our method addresses the challenges of sample-dependent targets from an\nopposite perspective. It captures the impact of the trigger on the refusal\nsignal (which is sample-independent) instead of sample-specific successful\nattack behaviors. It overcomes black-box access limitations by using multiple\nsampling to approximate the output distribution. Extensive experiments are\nconducted on various backdoor attacks and LLMs (including the closed-source\nGPT-3.5-turbo), verifying the effectiveness and efficiency of our defense.\nBesides, we also preliminarily verify that BEAT can effectively defend against\npopular jailbreak attacks, as they can be regarded as 'natural backdoors'.", "published": "2025-06-19 16:30:56", "link": "http://arxiv.org/abs/2506.16447v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "StoryWriter: A Multi-Agent Framework for Long Story Generation", "abstract": "Long story generation remains a challenge for existing large language models\n(LLMs), primarily due to two main factors: (1) discourse coherence, which\nrequires plot consistency, logical coherence, and completeness in the long-form\ngeneration, and (2) narrative complexity, which requires an interwoven and\nengaging narrative. To address these challenges, we propose StoryWriter, a\nmulti-agent story generation framework, which consists of three main modules:\n(1) outline agent, which generates event-based outlines containing rich event\nplots, character, and event-event relationships. (2) planning agent, which\nfurther details events and plans which events should be written in each chapter\nto maintain an interwoven and engaging story. (3) writing agent, which\ndynamically compresses the story history based on the current event to generate\nand reflect new plots, ensuring the coherence of the generated story. We\nconduct both human and automated evaluation, and StoryWriter significantly\noutperforms existing story generation baselines in both story quality and\nlength. Furthermore, we use StoryWriter to generate a dataset, which contains\nabout $6,000$ high-quality long stories, with an average length of $8,000$\nwords. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning\non LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which\ndemonstrates advanced performance in long story generation.", "published": "2025-06-19 16:26:58", "link": "http://arxiv.org/abs/2506.16445v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing", "abstract": "Large Language Models (LLMs) face an inherent challenge: their knowledge is\nconfined to the data that they have been trained on. To overcome this issue,\nRetrieval-Augmented Generation (RAG) complements the static training-derived\nknowledge of LLMs with an external knowledge repository. RAG consists of three\nstages: indexing, retrieval, and generation. The retrieval stage of RAG becomes\na significant bottleneck in inference pipelines. In this stage, a user query is\nmapped to an embedding vector and an Approximate Nearest Neighbor Search (ANNS)\nalgorithm searches for similar vectors in the database to identify relevant\nitems. Due to the large database sizes, ANNS incurs significant data movement\noverheads between the host and the storage system. To alleviate these\noverheads, prior works propose In-Storage Processing (ISP) techniques that\naccelerate ANNS by performing computations inside storage. However, existing\nworks that leverage ISP for ANNS (i) employ algorithms that are not tailored to\nISP systems, (ii) do not accelerate data retrieval operations for data selected\nby ANNS, and (iii) introduce significant hardware modifications, limiting\nperformance and hindering their adoption. We propose REIS, the first ISP system\ntailored for RAG that addresses these limitations with three key mechanisms.\nFirst, REIS employs a database layout that links database embedding vectors to\ntheir associated documents, enabling efficient retrieval. Second, it enables\nefficient ANNS by introducing an ISP-tailored data placement technique that\ndistributes embeddings across the planes of the storage system and employs a\nlightweight Flash Translation Layer. Third, REIS leverages an ANNS engine that\nuses the existing computational resources inside the storage system. Compared\nto a server-grade system, REIS improves the performance (energy efficiency) of\nretrieval by an average of 13x (55x).", "published": "2025-06-19 16:26:51", "link": "http://arxiv.org/abs/2506.16444v1", "categories": ["cs.CL", "cs.AR", "cs.DB", "H.3.3; I.2.7"], "primary_category": "cs.CL"}
{"title": "Unpacking Generative AI in Education: Computational Modeling of Teacher and Student Perspectives in Social Media Discourse", "abstract": "Generative AI (GAI) technologies are quickly reshaping the educational\nlandscape. As adoption accelerates, understanding how students and educators\nperceive these tools is essential. This study presents one of the most\ncomprehensive analyses to date of stakeholder discourse dynamics on GAI in\neducation using social media data. Our dataset includes 1,199 Reddit posts and\n13,959 corresponding top-level comments. We apply sentiment analysis, topic\nmodeling, and author classification. To support this, we propose and validate a\nmodular framework that leverages prompt-based large language models (LLMs) for\nanalysis of online social discourse, and we evaluate this framework against\nclassical natural language processing (NLP) models. Our GPT-4o pipeline\nconsistently outperforms prior approaches across all tasks. For example, it\nachieved 90.6% accuracy in sentiment analysis against gold-standard human\nannotations. Topic extraction uncovered 12 latent topics in the public\ndiscourse with varying sentiment and author distributions. Teachers and\nstudents convey optimism about GAI's potential for personalized learning and\nproductivity in higher education. However, key differences emerged: students\noften voice distress over false accusations of cheating by AI detectors, while\nteachers generally express concern about job security, academic integrity, and\ninstitutional pressures to adopt GAI tools. These contrasting perspectives\nhighlight the tension between innovation and oversight in GAI-enabled learning\nenvironments. Our findings suggest a need for clearer institutional policies,\nmore transparent GAI integration practices, and support mechanisms for both\neducators and students. More broadly, this study demonstrates the potential of\nLLM-based frameworks for modeling stakeholder discourse within online\ncommunities.", "published": "2025-06-19 15:50:08", "link": "http://arxiv.org/abs/2506.16412v1", "categories": ["cs.SI", "cs.CL", "cs.CY"], "primary_category": "cs.SI"}
{"title": "When Does Divide and Conquer Work for Long Context LLM? A Noise Decomposition Framework", "abstract": "We investigate the challenge of applying Large Language Models (LLMs) to long\ntexts. We propose a theoretical framework that distinguishes the failure modes\nof long context tasks into three categories: cross-chunk dependence (task\nnoise), confusion that grows with context size (model noise), and the imperfect\nintegration of partial results (aggregator noise). Under this view, we analyze\nwhen it is effective to use multi-agent chunking, i.e., dividing a length\nsequence into smaller chunks and aggregating the processed results of each\nchunk. Our experiments on tasks such as retrieval, question answering, and\nsummarization confirm both the theoretical analysis and the conditions that\nfavor multi-agent chunking. By exploring superlinear model noise growth with\ninput length, we also explain why, for large inputs, a weaker model configured\nwith chunk-based processing can surpass a more advanced model like GPT4o\napplied in a single shot. Overall, we present a principled understanding\nframework and our results highlight a direct pathway to handling long contexts\nin LLMs with carefully managed chunking and aggregator strategies.", "published": "2025-06-19 15:49:34", "link": "http://arxiv.org/abs/2506.16411v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NepaliGPT: A Generative Language Model for the Nepali Language", "abstract": "After the release of ChatGPT, Large Language Models (LLMs) have gained huge\npopularity in recent days and thousands of variants of LLMs have been released.\nHowever, there is no generative language model for the Nepali language, due to\nwhich other downstream tasks, including fine-tuning, have not been explored\nyet. To fill this research gap in the Nepali NLP space, this research proposes\n\\textit{NepaliGPT}, a generative large language model tailored specifically for\nthe Nepali language. This research introduces an advanced corpus for the Nepali\nlanguage collected from several sources, called the Devanagari Corpus.\nLikewise, the research introduces the first NepaliGPT benchmark dataset\ncomprised of 4,296 question-answer pairs in the Nepali language. The proposed\nLLM NepaliGPT achieves the following metrics in text generation: Perplexity of\n26.32245, ROUGE-1 score of 0.2604, causal coherence of 81.25\\%, and causal\nconsistency of 85.41\\%.", "published": "2025-06-19 15:31:12", "link": "http://arxiv.org/abs/2506.16399v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "OJBench: A Competition Level Code Benchmark For Large Language Models", "abstract": "Recent advancements in large language models (LLMs) have demonstrated\nsignificant progress in math and code reasoning capabilities. However, existing\ncode benchmark are limited in their ability to evaluate the full spectrum of\nthese capabilities, particularly at the competitive level. To bridge this gap,\nwe introduce OJBench, a novel and challenging benchmark designed to assess the\ncompetitive-level code reasoning abilities of LLMs. OJBench comprises 232\nprogramming competition problems from NOI and ICPC, providing a more rigorous\ntest of models' reasoning skills. We conducted a comprehensive evaluation using\nOJBench on 37 models, including both closed-source and open-source models,\nreasoning-oriented and non-reasoning-oriented models. Our results indicate that\neven state-of-the-art reasoning-oriented models, such as o4-mini and\nGemini-2.5-pro-exp, struggle with highly challenging competition-level\nproblems. This highlights the significant challenges that models face in\ncompetitive-level code reasoning.", "published": "2025-06-19 15:27:02", "link": "http://arxiv.org/abs/2506.16395v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling", "abstract": "Although the annotation paradigm based on Large Language Models (LLMs) has\nmade significant breakthroughs in recent years, its actual deployment still has\ntwo core bottlenecks: first, the cost of calling commercial APIs in large-scale\nannotation is very expensive; second, in scenarios that require fine-grained\nsemantic understanding, such as sentiment classification and toxicity\nclassification, the annotation accuracy of LLMs is even lower than that of\nSmall Language Models (SLMs) dedicated to this field. To address these\nproblems, we propose a new paradigm of multi-model cooperative annotation and\ndesign a fully automatic annotation framework AutoAnnotator based on this.\nSpecifically, AutoAnnotator consists of two layers. The upper-level\nmeta-controller layer uses the generation and reasoning capabilities of LLMs to\nselect SLMs for annotation, automatically generate annotation code and verify\ndifficult samples; the lower-level task-specialist layer consists of multiple\nSLMs that perform annotation through multi-model voting. In addition, we use\nthe difficult samples obtained by the secondary review of the meta-controller\nlayer as the reinforcement learning set and fine-tune the SLMs in stages\nthrough a continual learning strategy, thereby improving the generalization of\nSLMs. Extensive experiments show that AutoAnnotator outperforms existing\nopen-source/API LLMs in zero-shot, one-shot, CoT, and majority voting settings.\nNotably, AutoAnnotator reduces the annotation cost by 74.15% compared to\ndirectly annotating with GPT-3.5-turbo, while still improving the accuracy by\n6.21%. Project page: https://github.com/Zhaiyuan-Ji/AutoAnnotator.", "published": "2025-06-19 15:26:08", "link": "http://arxiv.org/abs/2506.16393v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RiOT: Efficient Prompt Refinement with Residual Optimization Tree", "abstract": "Recent advancements in large language models (LLMs) have highlighted their\npotential across a variety of tasks, but their performance still heavily relies\non the design of effective prompts. Existing methods for automatic prompt\noptimization face two challenges: lack of diversity, limiting the exploration\nof valuable and innovative directions and semantic drift, where optimizations\nfor one task can degrade performance in others. To address these issues, we\npropose Residual Optimization Tree (RiOT), a novel framework for automatic\nprompt optimization. RiOT iteratively refines prompts through text gradients,\ngenerating multiple semantically diverse candidates at each step, and selects\nthe best prompt using perplexity. Additionally, RiOT incorporates the text\nresidual connection to mitigate semantic drift by selectively retaining\nbeneficial content across optimization iterations. A tree structure efficiently\nmanages the optimization process, ensuring scalability and flexibility.\nExtensive experiments across five benchmarks, covering commonsense,\nmathematical, logical, temporal, and semantic reasoning, demonstrate that RiOT\noutperforms both previous prompt optimization methods and manual prompting.", "published": "2025-06-19 15:19:56", "link": "http://arxiv.org/abs/2506.16389v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HausaNLP at SemEval-2025 Task 11: Advancing Hausa Text-based Emotion Detection", "abstract": "This paper presents our approach to multi-label emotion detection in Hausa, a\nlow-resource African language, as part of SemEval Track A. We fine-tuned\nAfriBERTa, a transformer-based model pre-trained on African languages, to\nclassify Hausa text into six emotions: anger, disgust, fear, joy, sadness, and\nsurprise. Our methodology involved data preprocessing, tokenization, and model\nfine-tuning using the Hugging Face Trainer API. The system achieved a\nvalidation accuracy of 74.00%, with an F1-score of 73.50%, demonstrating the\neffectiveness of transformer-based models for emotion detection in low-resource\nlanguages.", "published": "2025-06-19 15:19:35", "link": "http://arxiv.org/abs/2506.16388v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models in Argument Mining: A Survey", "abstract": "Argument Mining (AM), a critical subfield of Natural Language Processing\n(NLP), focuses on extracting argumentative structures from text. The advent of\nLarge Language Models (LLMs) has profoundly transformed AM, enabling advanced\nin-context learning, prompt-based generation, and robust cross-domain\nadaptability. This survey systematically synthesizes recent advancements in\nLLM-driven AM. We provide a concise review of foundational theories and\nannotation frameworks, alongside a meticulously curated catalog of datasets. A\nkey contribution is our comprehensive taxonomy of AM subtasks, elucidating how\ncontemporary LLM techniques -- such as prompting, chain-of-thought reasoning,\nand retrieval augmentation -- have reconfigured their execution. We further\ndetail current LLM architectures and methodologies, critically assess\nevaluation practices, and delineate pivotal challenges including long-context\nreasoning, interpretability, and annotation bottlenecks. Conclusively, we\nhighlight emerging trends and propose a forward-looking research agenda for\nLLM-based computational argumentation, aiming to strategically guide\nresearchers in this rapidly evolving domain.", "published": "2025-06-19 15:12:58", "link": "http://arxiv.org/abs/2506.16383v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can structural correspondences ground real world representational content in Large Language Models?", "abstract": "Large Language Models (LLMs) such as GPT-4 produce compelling responses to a\nwide range of prompts. But their representational capacities are uncertain.\nMany LLMs have no direct contact with extra-linguistic reality: their inputs,\noutputs and training data consist solely of text, raising the questions (1) can\nLLMs represent anything and (2) if so, what? In this paper, I explore what it\nwould take to answer these questions according to a structural-correspondence\nbased account of representation, and make an initial survey of this evidence. I\nargue that the mere existence of structural correspondences between LLMs and\nworldly entities is insufficient to ground representation of those entities.\nHowever, if these structural correspondences play an appropriate role - they\nare exploited in a way that explains successful task performance - then they\ncould ground real world contents. This requires overcoming a challenge: the\ntext-boundedness of LLMs appears, on the face of it, to prevent them engaging\nin the right sorts of tasks.", "published": "2025-06-19 14:48:40", "link": "http://arxiv.org/abs/2506.16370v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DISCIE -- Discriminative Closed Information Extraction", "abstract": "This paper introduces a novel method for closed information extraction. The\nmethod employs a discriminative approach that incorporates type and\nentity-specific information to improve relation extraction accuracy,\nparticularly benefiting long-tail relations. Notably, this method demonstrates\nsuperior performance compared to state-of-the-art end-to-end generative models.\nThis is especially evident for the problem of large-scale closed information\nextraction where we are confronted with millions of entities and hundreds of\nrelations. Furthermore, we emphasize the efficiency aspect by leveraging\nsmaller models. In particular, the integration of type-information proves\ninstrumental in achieving performance levels on par with or surpassing those of\na larger generative model. This advancement holds promise for more accurate and\nefficient information extraction techniques.", "published": "2025-06-19 14:24:48", "link": "http://arxiv.org/abs/2506.16348v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalizability of Media Frames: Corpus creation and analysis across countries", "abstract": "Frames capture aspects of an issue that are emphasized in a debate by\ninterlocutors and can help us understand how political language conveys\ndifferent perspectives and ultimately shapes people's opinions. The Media Frame\nCorpus (MFC) is the most commonly used framework with categories and detailed\nguidelines for operationalizing frames. It is, however, focused on a few\nsalient U.S. news issues, making it unclear how well these frames can capture\nnews issues in other cultural contexts. To explore this, we introduce\nFrameNews-PT, a dataset of Brazilian Portuguese news articles covering\npolitical and economic news and annotate it within the MFC framework. Through\nseveral annotation rounds, we evaluate the extent to which MFC frames\ngeneralize to the Brazilian debate issues. We further evaluate how fine-tuned\nand zero-shot models perform on out-of-domain data. Results show that the 15\nMFC frames remain broadly applicable with minor revisions of the guidelines.\nHowever, some MFC frames are rarely used, and novel news issues are analyzed\nusing general 'fall-back' frames. We conclude that cross-cultural frame use\nrequires careful consideration.", "published": "2025-06-19 14:15:25", "link": "http://arxiv.org/abs/2506.16337v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PL-Guard: Benchmarking Language Model Safety for Polish", "abstract": "Despite increasing efforts to ensure the safety of large language models\n(LLMs), most existing safety assessments and moderation tools remain heavily\nbiased toward English and other high-resource languages, leaving majority of\nglobal languages underexamined. To address this gap, we introduce a manually\nannotated benchmark dataset for language model safety classification in Polish.\nWe also create adversarially perturbed variants of these samples designed to\nchallenge model robustness. We conduct a series of experiments to evaluate\nLLM-based and classifier-based models of varying sizes and architectures.\nSpecifically, we fine-tune three models: Llama-Guard-3-8B, a HerBERT-based\nclassifier (a Polish BERT derivative), and PLLuM, a Polish-adapted Llama-8B\nmodel. We train these models using different combinations of annotated data and\nevaluate their performance, comparing it against publicly available guard\nmodels. Results demonstrate that the HerBERT-based classifier achieves the\nhighest overall performance, particularly under adversarial conditions.", "published": "2025-06-19 13:56:41", "link": "http://arxiv.org/abs/2506.16322v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Comparative Analysis of Abstractive Summarization Models for Clinical Radiology Reports", "abstract": "The findings section of a radiology report is often detailed and lengthy,\nwhereas the impression section is comparatively more compact and captures key\ndiagnostic conclusions. This research explores the use of advanced abstractive\nsummarization models to generate the concise impression from the findings\nsection of a radiology report. We have used the publicly available MIMIC-CXR\ndataset. A comparative analysis is conducted on leading pre-trained and\nopen-source large language models, including T5-base, BART-base,\nPEGASUS-x-base, ChatGPT-4, LLaMA-3-8B, and a custom Pointer Generator Network\nwith a coverage mechanism. To ensure a thorough assessment, multiple evaluation\nmetrics are employed, including ROUGE-1, ROUGE-2, ROUGE-L, METEOR, and\nBERTScore. By analyzing the performance of these models, this study identifies\ntheir respective strengths and limitations in the summarization of medical\ntext. The findings of this paper provide helpful information for medical\nprofessionals who need automated summarization solutions in the healthcare\nsector.", "published": "2025-06-19 12:07:17", "link": "http://arxiv.org/abs/2506.16247v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Web(er) of Hate: A Survey on How Hate Speech Is Typed", "abstract": "The curation of hate speech datasets involves complex design decisions that\nbalance competing priorities. This paper critically examines these\nmethodological choices in a diverse range of datasets, highlighting common\nthemes and practices, and their implications for dataset reliability. Drawing\non Max Weber's notion of ideal types, we argue for a reflexive approach in\ndataset creation, urging researchers to acknowledge their own value judgments\nduring dataset construction, fostering transparency and methodological rigour.", "published": "2025-06-19 10:12:20", "link": "http://arxiv.org/abs/2506.16190v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JETHICS: Japanese Ethics Understanding Evaluation Dataset", "abstract": "In this work, we propose JETHICS, a Japanese dataset for evaluating ethics\nunderstanding of AI models. JETHICS contains 78K examples and is built by\nfollowing the construction methods of the existing English ETHICS dataset. It\nincludes four categories based normative theories and concepts from ethics and\npolitical philosophy; and one representing commonsense morality. Our evaluation\nexperiments on non-proprietary large language models (LLMs) and on GPT-4o\nreveal that even GPT-4o achieves only an average score of about 0.7, while the\nbest-performing Japanese LLM attains around 0.5, indicating a relatively large\nroom for improvement in current LLMs.", "published": "2025-06-19 10:06:57", "link": "http://arxiv.org/abs/2506.16187v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SGIC: A Self-Guided Iterative Calibration Framework for RAG", "abstract": "Recent research in retrieval-augmented generation (RAG) has concentrated on\nretrieving useful information from candidate documents. However, numerous\nmethodologies frequently neglect the calibration capabilities of large language\nmodels (LLMs), which capitalize on their robust in-context reasoning prowess.\nThis work illustrates that providing LLMs with specific cues substantially\nimproves their calibration efficacy, especially in multi-round calibrations. We\npresent a new SGIC: Self-Guided Iterative Calibration Framework that employs\nuncertainty scores as a tool. Initially, this framework calculates uncertainty\nscores to determine both the relevance of each document to the query and the\nconfidence level in the responses produced by the LLMs. Subsequently, it\nreevaluates these scores iteratively, amalgamating them with prior responses to\nrefine calibration. Furthermore, we introduce an innovative approach for\nconstructing an iterative self-calibration training set, which optimizes LLMs\nto efficiently harness uncertainty scores for capturing critical information\nand enhancing response accuracy. Our proposed framework significantly improves\nperformance on both closed-source and open-weight LLMs.", "published": "2025-06-19 09:45:13", "link": "http://arxiv.org/abs/2506.16172v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Under the Shadow of Babel: How Language Shapes Reasoning in LLMs", "abstract": "Language is not only a tool for communication but also a medium for human\ncognition and reasoning. If, as linguistic relativity suggests, the structure\nof language shapes cognitive patterns, then large language models (LLMs)\ntrained on human language may also internalize the habitual logical structures\nembedded in different languages. To examine this hypothesis, we introduce\nBICAUSE, a structured bilingual dataset for causal reasoning, which includes\nsemantically aligned Chinese and English samples in both forward and reversed\ncausal forms. Our study reveals three key findings: (1) LLMs exhibit\ntypologically aligned attention patterns, focusing more on causes and\nsentence-initial connectives in Chinese, while showing a more balanced\ndistribution in English. (2) Models internalize language-specific preferences\nfor causal word order and often rigidly apply them to atypical inputs, leading\nto degraded performance, especially in Chinese. (3) When causal reasoning\nsucceeds, model representations converge toward semantically aligned\nabstractions across languages, indicating a shared understanding beyond surface\nform. Overall, these results suggest that LLMs not only mimic surface\nlinguistic forms but also internalize the reasoning biases shaped by language.\nRooted in cognitive linguistic theory, this phenomenon is for the first time\nempirically verified through structural analysis of model internals.", "published": "2025-06-19 09:06:38", "link": "http://arxiv.org/abs/2506.16151v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning", "abstract": "Recent reinforcement learning approaches, such as outcome-supervised GRPO,\nhave advanced Chain-of-Thought reasoning in large language models (LLMs), yet\ntheir adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lack\nof rigorous evaluation for MLLM post-training methods, we introduce\nSEED-Bench-R1, a benchmark with complex real-world videos requiring balanced\nperception and reasoning. It offers a large training set and evaluates\ngeneralization across three escalating challenges: in-distribution,\ncross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1,\nwe find that standard GRPO, while improving answer accuracy, often reduces\nlogical coherence between reasoning steps and answers, with only a 57.9%\nconsistency rate. This stems from reward signals focusing solely on final\nanswers, encouraging shortcuts, and strict KL penalties limiting exploration.To\naddress this, we propose GRPO-CARE, a consistency-aware RL framework optimizing\nboth answer correctness and reasoning coherence without explicit supervision.\nGRPO-CARE introduces a two-tiered reward: (1) a base reward for answer\ncorrectness, and (2) an adaptive consistency bonus, computed by comparing the\nmodel's reasoning-to-answer likelihood (via a slowly-evolving reference model)\nagainst group peers.This dual mechanism amplifies rewards for reasoning paths\nthat are both correct and logically consistent. Replacing KL penalties with\nthis adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1,\nachieving a 6.7% performance gain on the hardest evaluation level and a 24.5%\nimprovement in consistency. It also shows strong transferability, improving\nmodel performance across diverse video understanding benchmarks. Our work\ncontributes a systematically designed benchmark and a generalizable\npost-training framework, advancing the development of more interpretable and\nrobust MLLMs.", "published": "2025-06-19 08:49:13", "link": "http://arxiv.org/abs/2506.16141v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "FinCoT: Grounding Chain-of-Thought in Expert Financial Reasoning", "abstract": "This paper presents FinCoT, a structured chain-of-thought (CoT) prompting\napproach that incorporates insights from domain-specific expert financial\nreasoning to guide the reasoning traces of large language models. We\ninvestigate that there are three main prompting styles in FinNLP: (1) standard\nprompting--zero-shot prompting; (2) unstructured CoT--CoT prompting without an\nexplicit reasoning structure, such as the use of tags; and (3) structured CoT\nprompting--CoT prompting with explicit instructions or examples that define\nstructured reasoning steps. Previously, FinNLP has primarily focused on prompt\nengineering with either standard or unstructured CoT prompting. However,\nstructured CoT prompting has received limited attention in prior work.\nFurthermore, the design of reasoning structures in structured CoT prompting is\noften based on heuristics from non-domain experts. In this study, we\ninvestigate each prompting approach in FinNLP. We evaluate the three main\nprompting styles and FinCoT on CFA-style questions spanning ten financial\ndomains. We observe that FinCoT improves performance from 63.2% to 80.5% and\nQwen-2.5-7B-Instruct from 69.7% to 74.2%, while reducing generated tokens\neight-fold compared to structured CoT prompting. Our findings show that\ndomain-aligned structured prompts not only improve performance and reduce\ninference costs but also yield more interpretable and expert-aligned reasoning\ntraces.", "published": "2025-06-19 08:18:55", "link": "http://arxiv.org/abs/2506.16123v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing the Robustness of Large Language Models Safety to Latent Perturbations", "abstract": "Safety alignment is a key requirement for building reliable Artificial\nGeneral Intelligence. Despite significant advances in safety alignment, we\nobserve that minor latent shifts can still trigger unsafe responses in aligned\nmodels. We argue that this stems from the shallow nature of existing alignment\nmethods, which focus on surface-level refusal behaviors without sufficiently\naltering internal representations. Consequently, small shifts in hidden\nactivations can re-trigger harmful behaviors embedded in the latent space. To\nexplore the robustness of safety alignment to latent perturbations, we\nintroduce a probing method that measures the Negative Log-Likelihood of the\noriginal response generated by the model. This probe quantifies local\nsensitivity in the latent space, serving as a diagnostic tool for identifying\nvulnerable directions. Based on this signal, we construct effective jailbreak\ntrajectories, giving rise to the Activation Steering Attack (ASA). More\nimportantly, these insights offer a principled foundation for improving\nalignment robustness. To this end, we introduce Layer-wise Adversarial Patch\nTraining~(LAPT), a fine-tuning strategy that inject controlled perturbations\ninto hidden representations during training. Experimental results highlight\nthat LAPT strengthen alignment robustness without compromising general\ncapabilities. Our findings reveal fundamental flaws in current alignment\nparadigms and call for representation-level training strategies that move\nbeyond surface-level behavior supervision. Codes and results are available at\nhttps://github.com/Carol-gutianle/LatentSafety.", "published": "2025-06-19 07:03:05", "link": "http://arxiv.org/abs/2506.16078v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Cyberbullying Detection in Hinglish Text Using MURIL and Explainable AI", "abstract": "The growth of digital communication platforms has led to increased\ncyberbullying incidents worldwide, creating a need for automated detection\nsystems to protect users. The rise of code-mixed Hindi-English (Hinglish)\ncommunication on digital platforms poses challenges for existing cyberbullying\ndetection systems, which were designed primarily for monolingual text. This\npaper presents a framework for cyberbullying detection in Hinglish text using\nthe Multilingual Representations for Indian Languages (MURIL) architecture to\naddress limitations in current approaches. Evaluation across six benchmark\ndatasets -- Bohra \\textit{et al.}, BullyExplain, BullySentemo, Kumar \\textit{et\nal.}, HASOC 2021, and Mendeley Indo-HateSpeech -- shows that the MURIL-based\napproach outperforms existing multilingual models including RoBERTa and\nIndicBERT, with improvements of 1.36 to 13.07 percentage points and accuracies\nof 86.97\\% on Bohra, 84.62\\% on BullyExplain, 86.03\\% on BullySentemo, 75.41\\%\non Kumar datasets, 83.92\\% on HASOC 2021, and 94.63\\% on Mendeley dataset. The\nframework includes explainability features through attribution analysis and\ncross-linguistic pattern recognition. Ablation studies show that selective\nlayer freezing, appropriate classification head design, and specialized\npreprocessing for code-mixed content improve detection performance, while\nfailure analysis identifies challenges including context-dependent\ninterpretation, cultural understanding, and cross-linguistic sarcasm detection,\nproviding directions for future research in multilingual cyberbullying\ndetection.", "published": "2025-06-19 06:46:42", "link": "http://arxiv.org/abs/2506.16066v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Critique-Guided Curiosity Refinement: Enhancing Honesty and Helpfulness in Large Language Models via In-Context Learning", "abstract": "Large language models (LLMs) have demonstrated robust capabilities across\nvarious natural language tasks. However, producing outputs that are\nconsistently honest and helpful remains an open challenge. To overcome this\nchallenge, this paper tackles the problem through two complementary directions.\nIt conducts a comprehensive benchmark evaluation of ten widely used large\nlanguage models, including both proprietary and open-weight models from OpenAI,\nMeta, and Google. In parallel, it proposes a novel prompting strategy,\nself-critique-guided curiosity refinement prompting. The key idea behind this\nstrategy is enabling models to self-critique and refine their responses without\nadditional training. The proposed method extends the curiosity-driven prompting\nstrategy by incorporating two lightweight in-context steps including\nself-critique step and refinement step.\n  The experiment results on the HONESET dataset evaluated using the framework\n$\\mathrm{H}^2$ (honesty and helpfulness), which was executed with GPT-4o as a\njudge of honesty and helpfulness, show consistent improvements across all\nmodels. The approach reduces the number of poor-quality responses, increases\nhigh-quality responses, and achieves relative gains in $\\mathrm{H}^2$ scores\nranging from 1.4% to 4.3% compared to curiosity-driven prompting across\nevaluated models. These results highlight the effectiveness of structured\nself-refinement as a scalable and training-free strategy to improve the\ntrustworthiness of LLMs outputs.", "published": "2025-06-19 06:42:35", "link": "http://arxiv.org/abs/2506.16064v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knee-Deep in C-RASP: A Transformer Depth Hierarchy", "abstract": "It has been observed that transformers with greater depth (that is, more\nlayers) have more capabilities, but can we establish formally which\ncapabilities are gained with greater depth? We answer this question with a\ntheoretical proof followed by an empirical study. First, we consider\ntransformers that round to fixed precision except inside attention. We show\nthat this subclass of transformers is expressively equivalent to the\nprogramming language C-RASP and this equivalence preserves depth. Second, we\nprove that deeper C-RASP programs are more expressive than shallower C-RASP\nprograms, implying that deeper transformers are more expressive than shallower\ntransformers (within the subclass mentioned above). These results are\nestablished by studying a form of temporal logic with counting operators, which\nwas shown equivalent to C-RASP in previous work. Finally, we provide empirical\nevidence that our theory predicts the depth required for transformers without\npositional encodings to length-generalize on a family of sequential dependency\ntasks.", "published": "2025-06-19 06:27:54", "link": "http://arxiv.org/abs/2506.16055v1", "categories": ["cs.CL", "cs.FL"], "primary_category": "cs.CL"}
{"title": "A Hybrid DeBERTa and Gated Broad Learning System for Cyberbullying Detection in English Text", "abstract": "The proliferation of online communication platforms has created unprecedented\nopportunities for global connectivity while simultaneously enabling harmful\nbehaviors such as cyberbullying, which affects approximately 54.4\\% of\nteenagers according to recent research. This paper presents a hybrid\narchitecture that combines the contextual understanding capabilities of\ntransformer-based models with the pattern recognition strengths of broad\nlearning systems for effective cyberbullying detection. This approach\nintegrates a modified DeBERTa model augmented with Squeeze-and-Excitation\nblocks and sentiment analysis capabilities with a Gated Broad Learning System\n(GBLS) classifier, creating a synergistic framework that outperforms existing\napproaches across multiple benchmark datasets. The proposed ModifiedDeBERTa +\nGBLS model achieved good performance on four English datasets: 79.3\\% accuracy\non HateXplain, 95.41\\% accuracy on SOSNet, 91.37\\% accuracy on Mendeley-I, and\n94.67\\% accuracy on Mendeley-II. Beyond performance gains, the framework\nincorporates comprehensive explainability mechanisms including token-level\nattribution analysis, LIME-based local interpretations, and confidence\ncalibration, addressing critical transparency requirements in automated content\nmoderation. Ablation studies confirm the meaningful contribution of each\narchitectural component, while failure case analysis reveals specific\nchallenges in detecting implicit bias and sarcastic content, providing valuable\ninsights for future improvements in cyberbullying detection systems.", "published": "2025-06-19 06:15:22", "link": "http://arxiv.org/abs/2506.16052v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling", "abstract": "Inference-time scaling has proven effective in boosting large language model\n(LLM) performance through increased test-time computation. Yet, its practical\napplication is often hindered by reliance on external verifiers or a lack of\noptimization for realistic computational constraints. We propose DynScaling,\nwhich addresses these limitations through two primary innovations: an\nintegrated parallel-sequential sampling strategy and a bandit-based dynamic\nbudget allocation framework. The integrated sampling strategy unifies parallel\nand sequential sampling by constructing synthetic sequential reasoning chains\nfrom initially independent parallel responses, promoting diverse and coherent\nreasoning trajectories. The dynamic budget allocation framework formulates the\nallocation of computational resources as a multi-armed bandit problem,\nadaptively distributing the inference budget across queries based on the\nuncertainty of previously sampled responses, thereby maximizing computational\nefficiency. By combining these components, DynScaling effectively improves LLM\nperformance under practical resource constraints without the need for external\nverifiers. Experimental results demonstrate that DynScaling consistently\nsurpasses existing verifier-free inference scaling baselines in both task\nperformance and computational cost.", "published": "2025-06-19 05:40:54", "link": "http://arxiv.org/abs/2506.16043v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Document-Level Question Answering via Multi-Hop Retrieval-Augmented Generation with LLaMA 3", "abstract": "This paper presents a novel Retrieval-Augmented Generation (RAG) framework\ntailored for complex question answering tasks, addressing challenges in\nmulti-hop reasoning and contextual understanding across lengthy documents.\nBuilt upon LLaMA 3, the framework integrates a dense retrieval module with\nadvanced context fusion and multi-hop reasoning mechanisms, enabling more\naccurate and coherent response generation. A joint optimization strategy\ncombining retrieval likelihood and generation cross-entropy improves the\nmodel's robustness and adaptability. Experimental results show that the\nproposed system outperforms existing retrieval-augmented and generative\nbaselines, confirming its effectiveness in delivering precise, contextually\ngrounded answers.", "published": "2025-06-19 05:22:18", "link": "http://arxiv.org/abs/2506.16037v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EvoLM: In Search of Lost Language Model Training Dynamics", "abstract": "Modern language model (LM) training has been divided into multiple stages,\nmaking it difficult for downstream developers to evaluate the impact of design\nchoices made at each stage. We present EvoLM, a model suite that enables\nsystematic and transparent analysis of LMs' training dynamics across\npre-training, continued pre-training, supervised fine-tuning, and reinforcement\nlearning. By training over 100 LMs with 1B and 4B parameters from scratch, we\nrigorously evaluate both upstream (language modeling) and downstream\n(problem-solving) reasoning capabilities, including considerations of both\nin-domain and out-of-domain generalization. Key insights highlight the\ndiminishing returns from excessive pre-training and post-training, the\nimportance and practices of mitigating forgetting during domain-specific\ncontinued pre-training, the crucial role of continued pre-training in bridging\npre-training and post-training phases, and various intricate trade-offs when\nconfiguring supervised fine-tuning and reinforcement learning. To facilitate\nopen research and reproducibility, we release all pre-trained and post-trained\nmodels, training datasets for all stages, and our entire training and\nevaluation pipeline.", "published": "2025-06-19 04:58:47", "link": "http://arxiv.org/abs/2506.16029v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From General to Targeted Rewards: Surpassing GPT-4 in Open-Ended Long-Context Generation", "abstract": "Current research on long-form context in Large Language Models (LLMs)\nprimarily focuses on the understanding of long-contexts, the Open-ended Long\nText Generation (Open-LTG) remains insufficiently explored. Training a\nlong-context generation model requires curation of gold standard reference\ndata, which is typically nonexistent for informative Open-LTG tasks. However,\nprevious methods only utilize general assessments as reward signals, which\nlimits accuracy. To bridge this gap, we introduce ProxyReward, an innovative\nreinforcement learning (RL) based framework, which includes a dataset and a\nreward signal computation method. Firstly, ProxyReward Dataset generation is\naccomplished through simple prompts that enables the model to create\nautomatically, obviating extensive labeled data or significant manual effort.\nSecondly, ProxyReward Signal offers a targeted evaluation of information\ncomprehensiveness and accuracy for specific questions. The experimental results\nindicate that our method ProxyReward surpasses even GPT-4-Turbo. It can\nsignificantly enhance performance by 20% on the Open-LTG task when training\nwidely used open-source models, while also surpassing the LLM-as-a-Judge\napproach. Our work presents effective methods to enhance the ability of LLMs to\naddress complex open-ended questions posed by human.", "published": "2025-06-19 04:44:34", "link": "http://arxiv.org/abs/2506.16024v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Bayesian Epistemology with Weighted Authority: A Formal Architecture for Truth-Promoting Autonomous Scientific Reasoning", "abstract": "The exponential expansion of scientific literature has surpassed the\nepistemic processing capabilities of both human experts and current artificial\nintelligence systems. This paper introduces Bayesian Epistemology with Weighted\nAuthority (BEWA), a formally structured architecture that operationalises\nbelief as a dynamic, probabilistically coherent function over structured\nscientific claims. Each claim is contextualised, author-attributed, and\nevaluated through a system of replication scores, citation weighting, and\ntemporal decay. Belief updates are performed via evidence-conditioned Bayesian\ninference, contradiction processing, and epistemic decay mechanisms. The\narchitecture supports graph-based claim propagation, authorial credibility\nmodelling, cryptographic anchoring, and zero-knowledge audit verification. By\nformalising scientific reasoning into a computationally verifiable epistemic\nnetwork, BEWA advances the foundation for machine reasoning systems that\npromote truth utility, rational belief convergence, and audit-resilient\nintegrity across dynamic scientific domains.", "published": "2025-06-19 04:22:35", "link": "http://arxiv.org/abs/2506.16015v1", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LO", "math.LO", "68T27, 03B70, 68P20", "I.2.3; F.4.1; H.2.8"], "primary_category": "cs.AI"}
{"title": "A Vietnamese Dataset for Text Segmentation and Multiple Choices Reading Comprehension", "abstract": "Vietnamese, the 20th most spoken language with over 102 million native\nspeakers, lacks robust resources for key natural language processing tasks such\nas text segmentation and machine reading comprehension (MRC). To address this\ngap, we present VSMRC, the Vietnamese Text Segmentation and Multiple-Choice\nReading Comprehension Dataset. Sourced from Vietnamese Wikipedia, our dataset\nincludes 15,942 documents for text segmentation and 16,347 synthetic\nmultiple-choice question-answer pairs generated with human quality assurance,\nensuring a reliable and diverse resource. Experiments show that mBERT\nconsistently outperforms monolingual models on both tasks, achieving an\naccuracy of 88.01% on MRC test set and an F1 score of 63.15\\% on text\nsegmentation test set. Our analysis reveals that multilingual models excel in\nNLP tasks for Vietnamese, suggesting potential applications to other\nunder-resourced languages. VSMRC is available at HuggingFace", "published": "2025-06-19 02:53:24", "link": "http://arxiv.org/abs/2506.15978v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-use LLM Watermarking and the False Detection Problem", "abstract": "Digital watermarking is a promising solution for mitigating some of the risks\narising from the misuse of automatically generated text. These approaches\neither embed non-specific watermarks to allow for the detection of any text\ngenerated by a particular sampler, or embed specific keys that allow the\nidentification of the LLM user. However, simultaneously using the same\nembedding for both detection and user identification leads to a false detection\nproblem, whereby, as user capacity grows, unwatermarked text is increasingly\nlikely to be falsely detected as watermarked. Through theoretical analysis, we\nidentify the underlying causes of this phenomenon. Building on these insights,\nwe propose Dual Watermarking which jointly encodes detection and identification\nwatermarks into generated text, significantly reducing false positives while\nmaintaining high detection accuracy. Our experimental results validate our\ntheoretical findings and demonstrate the effectiveness of our approach.", "published": "2025-06-19 02:37:02", "link": "http://arxiv.org/abs/2506.15975v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Exploring Big Five Personality and AI Capability Effects in LLM-Simulated Negotiation Dialogues", "abstract": "This paper presents an evaluation framework for agentic AI systems in\nmission-critical negotiation contexts, addressing the need for AI agents that\ncan adapt to diverse human operators and stakeholders. Using Sotopia as a\nsimulation testbed, we present two experiments that systematically evaluated\nhow personality traits and AI agent characteristics influence LLM-simulated\nsocial negotiation outcomes--a capability essential for a variety of\napplications involving cross-team coordination and civil-military interactions.\nExperiment 1 employs causal discovery methods to measure how personality traits\nimpact price bargaining negotiations, through which we found that Agreeableness\nand Extraversion significantly affect believability, goal achievement, and\nknowledge acquisition outcomes. Sociocognitive lexical measures extracted from\nteam communications detected fine-grained differences in agents' empathic\ncommunication, moral foundations, and opinion patterns, providing actionable\ninsights for agentic AI systems that must operate reliably in high-stakes\noperational scenarios. Experiment 2 evaluates human-AI job negotiations by\nmanipulating both simulated human personality and AI system characteristics,\nspecifically transparency, competence, adaptability, demonstrating how AI agent\ntrustworthiness impact mission effectiveness. These findings establish a\nrepeatable evaluation methodology for experimenting with AI agent reliability\nacross diverse operator personalities and human-agent team dynamics, directly\nsupporting operational requirements for reliable AI systems. Our work advances\nthe evaluation of agentic AI workflows by moving beyond standard performance\nmetrics to incorporate social dynamics essential for mission success in complex\noperations.", "published": "2025-06-19 00:14:56", "link": "http://arxiv.org/abs/2506.15928v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Reranking-based Generation for Unbiased Perspective Summarization", "abstract": "Generating unbiased summaries in real-world settings such as political\nperspective summarization remains a crucial application of Large Language\nModels (LLMs). Yet, existing evaluation frameworks rely on traditional metrics\nfor measuring key attributes such as coverage and faithfulness without\nverifying their applicability, and efforts to develop improved summarizers are\nstill nascent. We address these gaps by (1) identifying reliable metrics for\nmeasuring perspective summary quality, and (2) investigating the efficacy of\nLLM-based methods beyond zero-shot inference. Namely, we build a test set for\nbenchmarking metric reliability using human annotations and show that\ntraditional metrics underperform compared to language model-based metrics,\nwhich prove to be strong evaluators. Using these metrics, we show that\nreranking-based methods yield strong results, and preference tuning with\nsynthetically generated and reranking-labeled data further boosts performance.\nOur findings aim to contribute to the reliable evaluation and development of\nperspective summarization methods.", "published": "2025-06-19 00:01:43", "link": "http://arxiv.org/abs/2506.15925v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "History-Augmented Vision-Language Models for Frontier-Based Zero-Shot Object Navigation", "abstract": "Object Goal Navigation (ObjectNav) challenges robots to find objects in\nunseen environments, demanding sophisticated reasoning. While Vision-Language\nModels (VLMs) show potential, current ObjectNav methods often employ them\nsuperficially, primarily using vision-language embeddings for object-scene\nsimilarity checks rather than leveraging deeper reasoning. This limits\ncontextual understanding and leads to practical issues like repetitive\nnavigation behaviors. This paper introduces a novel zero-shot ObjectNav\nframework that pioneers the use of dynamic, history-aware prompting to more\ndeeply integrate VLM reasoning into frontier-based exploration. Our core\ninnovation lies in providing the VLM with action history context, enabling it\nto generate semantic guidance scores for navigation actions while actively\navoiding decision loops. We also introduce a VLM-assisted waypoint generation\nmechanism for refining the final approach to detected objects. Evaluated on the\nHM3D dataset within Habitat, our approach achieves a 46% Success Rate (SR) and\n24.8% Success weighted by Path Length (SPL). These results are comparable to\nstate-of-the-art zero-shot methods, demonstrating the significant potential of\nour history-augmented VLM prompting strategy for more robust and context-aware\nrobotic navigation.", "published": "2025-06-19 21:50:16", "link": "http://arxiv.org/abs/2506.16623v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "The Role of Explanation Styles and Perceived Accuracy on Decision Making in Predictive Process Monitoring", "abstract": "Predictive Process Monitoring (PPM) often uses deep learning models to\npredict the future behavior of ongoing processes, such as predicting process\noutcomes. While these models achieve high accuracy, their lack of\ninterpretability undermines user trust and adoption. Explainable AI (XAI) aims\nto address this challenge by providing the reasoning behind the predictions.\nHowever, current evaluations of XAI in PPM focus primarily on functional\nmetrics (such as fidelity), overlooking user-centered aspects such as their\neffect on task performance and decision-making. This study investigates the\neffects of explanation styles (feature importance, rule-based, and\ncounterfactual) and perceived AI accuracy (low or high) on decision-making in\nPPM. We conducted a decision-making experiment, where users were presented with\nthe AI predictions, perceived accuracy levels, and explanations of different\nstyles. Users' decisions were measured both before and after receiving\nexplanations, allowing the assessment of objective metrics (Task Performance\nand Agreement) and subjective metrics (Decision Confidence). Our findings show\nthat perceived accuracy and explanation style have a significant effect.", "published": "2025-06-19 21:30:28", "link": "http://arxiv.org/abs/2506.16617v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "A Community-driven vision for a new Knowledge Resource for AI", "abstract": "The long-standing goal of creating a comprehensive, multi-purpose knowledge\nresource, reminiscent of the 1984 Cyc project, still persists in AI. Despite\nthe success of knowledge resources like WordNet, ConceptNet, Wolfram|Alpha and\nother commercial knowledge graphs, verifiable, general-purpose widely available\nsources of knowledge remain a critical deficiency in AI infrastructure. Large\nlanguage models struggle due to knowledge gaps; robotic planning lacks\nnecessary world knowledge; and the detection of factually false information\nrelies heavily on human expertise. What kind of knowledge resource is most\nneeded in AI today? How can modern technology shape its development and\nevaluation? A recent AAAI workshop gathered over 50 researchers to explore\nthese questions. This paper synthesizes our findings and outlines a\ncommunity-driven vision for a new knowledge infrastructure. In addition to\nleveraging contemporary advances in knowledge representation and reasoning, one\npromising idea is to build an open engineering framework to exploit knowledge\nmodules effectively within the context of practical applications. Such a\nframework should include sets of conventions and social structures that are\nadopted by contributors.", "published": "2025-06-19 20:51:28", "link": "http://arxiv.org/abs/2506.16596v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AI-Driven Tools in Modern Software Quality Assurance: An Assessment of Benefits, Challenges, and Future Directions", "abstract": "Traditional quality assurance (QA) methods face significant challenges in\naddressing the complexity, scale, and rapid iteration cycles of modern software\nsystems and are strained by limited resources available, leading to substantial\ncosts associated with poor quality. The object of this research is the Quality\nAssurance processes for modern distributed software applications. The subject\nof the research is the assessment of the benefits, challenges, and prospects of\nintegrating modern AI-oriented tools into quality assurance processes. We\nperformed comprehensive analysis of implications on both verification and\nvalidation processes covering exploratory test analyses, equivalence\npartitioning and boundary analyses, metamorphic testing, finding\ninconsistencies in acceptance criteria (AC), static analyses, test case\ngeneration, unit test generation, test suit optimization and assessment, end to\nend scenario execution. End to end regression of sample enterprise application\nutilizing AI-agents over generated test scenarios was implemented as a proof of\nconcept highlighting practical use of the study. The results, with only 8.3%\nflaky executions of generated test cases, indicate significant potential for\nthe proposed approaches. However, the study also identified substantial\nchallenges for practical adoption concerning generation of semantically\nidentical coverage, \"black box\" nature and lack of explainability from\nstate-of-the-art Large Language Models (LLMs), the tendency to correct mutated\ntest cases to match expected results, underscoring the necessity for thorough\nverification of both generated artifacts and test execution results. The\nresearch demonstrates AI's transformative potential for QA but highlights the\nimportance of a strategic approach to implementing these technologies,\nconsidering the identified limitations and the need for developing appropriate\nverification methodologies.", "published": "2025-06-19 20:22:47", "link": "http://arxiv.org/abs/2506.16586v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "HausaNLP at SemEval-2025 Task 11: Hausa Text Emotion Detection", "abstract": "This paper presents our approach to multi-label emotion detection in Hausa, a\nlow-resource African language, for SemEval Track A. We fine-tuned AfriBERTa, a\ntransformer-based model pre-trained on African languages, to classify Hausa\ntext into six emotions: anger, disgust, fear, joy, sadness, and surprise. Our\nmethodology involved data preprocessing, tokenization, and model fine-tuning\nusing the Hugging Face Trainer API. The system achieved a validation accuracy\nof 74.00%, with an F1-score of 73.50%, demonstrating the effectiveness of\ntransformer-based models for emotion detection in low-resource languages.", "published": "2025-06-19 15:19:35", "link": "http://arxiv.org/abs/2506.16388v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Autocratic strategies in Cournot oligopoly game", "abstract": "An oligopoly is a market in which the price of a goods is controlled by a few\nfirms. Cournot introduced the simplest game-theoretic model of oligopoly, where\nprofit-maximizing behavior of each firm results in market failure. Furthermore,\nwhen the Cournot oligopoly game is infinitely repeated, firms can tacitly\ncollude to monopolize the market. Such tacit collusion is realized by the same\nmechanism as direct reciprocity in the repeated prisoner's dilemma game, where\nmutual cooperation can be realized whereas defection is favorable for both\nprisoners in one-shot game. Recently, in the repeated prisoner's dilemma game,\na class of strategies called zero-determinant strategies attracts much\nattention in the context of direct reciprocity. Zero-determinant strategies are\nautocratic strategies which unilaterally control payoffs of players. There were\nmany attempts to find zero-determinant strategies in other games and to extend\nthem so as to apply them to broader situations. In this paper, first, we show\nthat zero-determinant strategies exist even in the repeated Cournot oligopoly\ngame. Especially, we prove that an averagely unbeatable zero-determinant\nstrategy exists, which is guaranteed to obtain the average payoff of the\nopponents. Second, we numerically show that the averagely unbeatable\nzero-determinant strategy can be used to promote collusion when it is used\nagainst an adaptively learning player, whereas it cannot promote collusion when\nit is used against two adaptively learning players. Our findings elucidate some\nnegative impact of zero-determinant strategies in oligopoly market.", "published": "2025-06-19 05:23:01", "link": "http://arxiv.org/abs/2506.16038v2", "categories": ["physics.soc-ph", "cs.GT", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "physics.soc-ph"}
{"title": "Identifying Heterogeneity in Distributed Learning", "abstract": "We study methods for identifying heterogeneous parameter components in\ndistributed M-estimation with minimal data transmission. One is based on a\nre-normalized Wald test, which is shown to be consistent as long as the number\nof distributed data blocks $K$ is of a smaller order of the minimum block\nsample size {and the level of heterogeneity is dense}. The second one is an\nextreme contrast test (ECT) based on the difference between the largest and\nsmallest component-wise estimated parameters among data blocks. By introducing\na sample splitting procedure, the ECT can avoid the bias accumulation arising\nfrom the M-estimation procedures, and exhibits consistency for $K$ being much\nlarger than the sample size while the heterogeneity is sparse. The ECT\nprocedure is easy to operate and communication-efficient. A combination of the\nWald and the extreme contrast tests is formulated to attain more robust power\nunder varying levels of sparsity of the heterogeneity. We also conduct\nintensive numerical experiments to compare the family-wise error rate (FWER)\nand the power of the proposed methods. Additionally, we conduct a case study to\npresent the implementation and validity of the proposed methods.", "published": "2025-06-19 15:26:48", "link": "http://arxiv.org/abs/2506.16394v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "On Designing Modulation for Over-the-Air Computation -- Part II: Pyramid Sampling", "abstract": "Over-the-air computation (OAC) harnesses the natural superposition of\nwireless signals to compute aggregate functions during transmission, thereby\ncollapsing communication and computation into a single step and significantly\nreducing latency and resource usage. In Part I, digital OAC was formulated as a\nnoise-aware constellation design problem by casting encoder design as a max-min\noptimization that aligns minimum Euclidean distances between superimposed\nconstellation points with squared differences of their corresponding function\noutputs.\n  In this paper, Part II, we address the prohibitive complexity and\nquantization challenges inherent in digital OAC constellation design for\nlarge-scale edge networks. More precisely, we introduce a pyramid sampling\nstrategy that judiciously selects a subset of superimposed constellation points\nto reduce the encoder design complexity from $\\mathcal{O}(q^K)$ to\n$\\mathcal{O}(q^{K-p+1})$, where $p\\in\\{1,\\dots, K\\}$ denotes the sampling\norder, $q$ levels of modulation, and $K$ denotes the number nodes in the\nnetwork. Under the assumption of symmetric aggregation, this approach enables a\ncontrolled trade-off between computational complexity and function computation\naccuracy. As a special case, we propose majority-based sampling ($p=K$), which\nconfines aggregation to only $q$ consensus points, inherently avoiding\ndestructive overlaps and permitting the use of standard digital modulations\n(e.g., QAM, PSK, ASK) without bespoke constellation designs. We also show via\nseveral simulations, across various aggregation functions, modulation levels,\nand noise levels, that moderate sampling orders attain acceptable performance\nwith orders-of-magnitude fewer constraints than exhaustive designs.", "published": "2025-06-19 10:56:59", "link": "http://arxiv.org/abs/2506.16208v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On Designing Modulation for Over-the-Air Computation -- Part I: Noise-Aware Design", "abstract": "Over-the-air computation (OAC) leverages the physical superposition property\nof wireless multiple access channels (MACs) to compute functions while\ncommunication occurs, enabling scalable and low-latency processing in\ndistributed networks. While analog OAC methods suffer from noise sensitivity\nand hardware constraints, existing digital approaches are often limited in\ndesign complexity, which may hinder scalability and fail to exploit spectral\nefficiency fully. This two-part paper revisits and extends the ChannelComp\nframework, a general methodology for computing arbitrary finite-valued\nfunctions using digital modulation. In Part I, we develop a novel constellation\ndesign approach that is aware of the noise distribution and formulates the\nencoder design as a max-min optimization problem using noise-tailored distance\nmetrics. Our design supports noise models, including Gaussian, Laplace, and\nheavy-tailed distributions. We further demonstrate that, for heavy-tailed\nnoise, the optimal ChannelComp setup coincides with the solution to the\ncorresponding max-min criterion for the channel noise with heavy-tailed\ndistributions. Numerical experiments confirm that our noise-aware design\nachieves a substantially lower mean-square error than leading digital OAC\nmethods over noisy MACs. In Part II, we consider a constellation design with a\nquantization-based sampling scheme to enhance modulation scalability and\ncomputational accuracy for large-scale digital OAC.", "published": "2025-06-19 01:26:08", "link": "http://arxiv.org/abs/2506.15950v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
