{"title": "Schema2QA: High-Quality and Low-Cost Q&A Agents for the Structured Web", "abstract": "Building a question-answering agent currently requires large annotated\ndatasets, which are prohibitively expensive. This paper proposes Schema2QA, an\nopen-source toolkit that can generate a Q&A system from a database schema\naugmented with a few annotations for each field. The key concept is to cover\nthe space of possible compound queries on the database with a large number of\nin-domain questions synthesized with the help of a corpus of generic query\ntemplates. The synthesized data and a small paraphrase set are used to train a\nnovel neural network based on the BERT pretrained model. We use Schema2QA to\ngenerate Q&A systems for five Schema.org domains, restaurants, people, movies,\nbooks and music, and obtain an overall accuracy between 64% and 75% on\ncrowdsourced questions for these domains. Once annotations and paraphrases are\nobtained for a Schema.org schema, no additional manual effort is needed to\ncreate a Q&A agent for any website that uses the same schema. Furthermore, we\ndemonstrate that learning can be transferred from the restaurant to the hotel\ndomain, obtaining a 64% accuracy on crowdsourced questions with no manual\neffort. Schema2QA achieves an accuracy of 60% on popular restaurant questions\nthat can be answered using Schema.org. Its performance is comparable to Google\nAssistant, 7% lower than Siri, and 15% higher than Alexa. It outperforms all\nthese assistants by at least 18% on more complex, long-tail questions.", "published": "2020-01-16 01:49:16", "link": "http://arxiv.org/abs/2001.05609v6", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AandP: Utilizing Prolog for converting between active sentence and\n  passive sentence with three-steps conversion", "abstract": "I introduce a simple but efficient method to solve one of the critical\naspects of English grammar which is the relationship between active sentence\nand passive sentence. In fact, an active sentence and its corresponding passive\nsentence express the same meaning, but their structure is different. I utilized\nProlog [4] along with Definite Clause Grammars (DCG) [5] for doing the\nconversion between active sentence and passive sentence. Some advanced\ntechniques were also used such as Extra Arguments, Extra Goals, Lexicon, etc. I\ntried to solve a variety of cases of active and passive sentences such as 12\nEnglish tenses, modal verbs, negative form, etc. More details and my\ncontributions will be presented in the following sections. The source code is\navailable at https://github.com/tqtrunghnvn/ActiveAndPassive.", "published": "2020-01-16 06:31:53", "link": "http://arxiv.org/abs/2001.05672v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing lexical-based approach with external knowledge for Vietnamese\n  multiple-choice machine reading comprehension", "abstract": "Although Vietnamese is the 17th most popular native-speaker language in the\nworld, there are not many research studies on Vietnamese machine reading\ncomprehension (MRC), the task of understanding a text and answering questions\nabout it. One of the reasons is because of the lack of high-quality benchmark\ndatasets for this task. In this work, we construct a dataset which consists of\n2,783 pairs of multiple-choice questions and answers based on 417 Vietnamese\ntexts which are commonly used for teaching reading comprehension for elementary\nschool pupils. In addition, we propose a lexical-based MRC method that utilizes\nsemantic similarity measures and external knowledge sources to analyze\nquestions and extract answers from the given text. We compare the performance\nof the proposed model with several baseline lexical-based and neural\nnetwork-based models. Our proposed method achieves 61.81% by accuracy, which is\n5.51% higher than the best baseline model. We also measure human performance on\nour dataset and find that there is a big gap between machine-model and human\nperformances. This indicates that significant progress can be made on this\ntask. The dataset is freely available on our website for research purposes.", "published": "2020-01-16 08:09:51", "link": "http://arxiv.org/abs/2001.05687v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparing Rule-based, Feature-based and Deep Neural Methods for\n  De-identification of Dutch Medical Records", "abstract": "Unstructured information in electronic health records provide an invaluable\nresource for medical research. To protect the confidentiality of patients and\nto conform to privacy regulations, de-identification methods automatically\nremove personally identifying information from these medical records. However,\ndue to the unavailability of labeled data, most existing research is\nconstrained to English medical text and little is known about the\ngeneralizability of de-identification methods across languages and domains. In\nthis study, we construct a varied dataset consisting of the medical records of\n1260 patients by sampling data from 9 institutes and three domains of Dutch\nhealthcare. We test the generalizability of three de-identification methods\nacross languages and domains. Our experiments show that an existing rule-based\nmethod specifically developed for the Dutch language fails to generalize to\nthis new data. Furthermore, a state-of-the-art neural architecture performs\nstrongly across languages and domains, even with limited training data.\nCompared to feature-based and rule-based methods the neural method requires\nsignificantly less configuration effort and domain-knowledge. We make all code\nand pre-trained de-identification models available to the research community,\nallowing practitioners to apply them to their datasets and to enable future\nbenchmarks.", "published": "2020-01-16 09:42:29", "link": "http://arxiv.org/abs/2001.05714v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lexical Sememe Prediction using Dictionary Definitions by Capturing\n  Local Semantic Correspondence", "abstract": "Sememes, defined as the minimum semantic units of human languages in\nlinguistics, have been proven useful in many NLP tasks. Since manual\nconstruction and update of sememe knowledge bases (KBs) are costly, the task of\nautomatic sememe prediction has been proposed to assist sememe annotation. In\nthis paper, we explore the approach of applying dictionary definitions to\npredicting sememes for unannotated words. We find that sememes of each word are\nusually semantically matched to different words in its dictionary definition,\nand we name this matching relationship local semantic correspondence.\nAccordingly, we propose a Sememe Correspondence Pooling (SCorP) model, which is\nable to capture this kind of matching to predict sememes. We evaluate our model\nand baseline methods on a famous sememe KB HowNet and find that our model\nachieves state-of-the-art performance. Moreover, further quantitative analysis\nshows that our model can properly learn the local semantic correspondence\nbetween sememes and words in dictionary definitions, which explains the\neffectiveness of our model. The source codes of this paper can be obtained from\nhttps://github.com/thunlp/scorp.", "published": "2020-01-16 17:30:36", "link": "http://arxiv.org/abs/2001.05954v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fact-aware Sentence Split and Rephrase with Permutation Invariant\n  Training", "abstract": "Sentence Split and Rephrase aims to break down a complex sentence into\nseveral simple sentences with its meaning preserved. Previous studies tend to\naddress the issue by seq2seq learning from parallel sentence pairs, which takes\na complex sentence as input and sequentially generates a series of simple\nsentences. However, the conventional seq2seq learning has two limitations for\nthis task: (1) it does not take into account the facts stated in the long\nsentence; As a result, the generated simple sentences may miss or inaccurately\nstate the facts in the original sentence. (2) The order variance of the simple\nsentences to be generated may confuse the seq2seq model during training because\nthe simple sentences derived from the long source sentence could be in any\norder.\n  To overcome the challenges, we first propose the Fact-aware Sentence\nEncoding, which enables the model to learn facts from the long sentence and\nthus improves the precision of sentence split; then we introduce Permutation\nInvariant Training to alleviate the effects of order variance in seq2seq\nlearning for this task. Experiments on the WebSplit-v1.0 benchmark dataset show\nthat our approaches can largely improve the performance over the previous\nseq2seq learning approaches. Moreover, an extrinsic evaluation on oie-benchmark\nverifies the effectiveness of our approaches by an observation that splitting\nlong sentences with our state-of-the-art model as preprocessing is helpful for\nimproving OpenIE performance.", "published": "2020-01-16 07:30:19", "link": "http://arxiv.org/abs/2001.11383v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Delving Deeper into the Decoder for Video Captioning", "abstract": "Video captioning is an advanced multi-modal task which aims to describe a\nvideo clip using a natural language sentence. The encoder-decoder framework is\nthe most popular paradigm for this task in recent years. However, there exist\nsome problems in the decoder of a video captioning model. We make a thorough\ninvestigation into the decoder and adopt three techniques to improve the\nperformance of the model. First of all, a combination of variational dropout\nand layer normalization is embedded into a recurrent unit to alleviate the\nproblem of overfitting. Secondly, a new online method is proposed to evaluate\nthe performance of a model on a validation set so as to select the best\ncheckpoint for testing. Finally, a new training strategy called professional\nlearning is proposed which uses the strengths of a captioning model and\nbypasses its weaknesses. It is demonstrated in the experiments on Microsoft\nResearch Video Description Corpus (MSVD) and MSR-Video to Text (MSR-VTT)\ndatasets that our model has achieved the best results evaluated by BLEU, CIDEr,\nMETEOR and ROUGE-L metrics with significant gains of up to 18% on MSVD and 3.5%\non MSR-VTT compared with the previous state-of-the-art models.", "published": "2020-01-16 02:18:27", "link": "http://arxiv.org/abs/2001.05614v3", "categories": ["cs.CV", "cs.CL", "68T45, 68T50", "I.2.10; I.2.7"], "primary_category": "cs.CV"}
{"title": "Document Network Projection in Pretrained Word Embedding Space", "abstract": "We present Regularized Linear Embedding (RLE), a novel method that projects a\ncollection of linked documents (e.g. citation network) into a pretrained word\nembedding space. In addition to the textual content, we leverage a matrix of\npairwise similarities providing complementary information (e.g., the network\nproximity of two documents in a citation graph). We first build a simple word\nvector average for each document, and we use the similarities to alter this\naverage representation. The document representations can help to solve many\ninformation retrieval tasks, such as recommendation, classification and\nclustering. We demonstrate that our approach outperforms or matches existing\ndocument network embedding methods on node classification and link prediction\ntasks. Furthermore, we show that it helps identifying relevant keywords to\ndescribe document classes.", "published": "2020-01-16 10:16:37", "link": "http://arxiv.org/abs/2001.05727v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Intweetive Text Summarization", "abstract": "The amount of user generated contents from various social medias allows\nanalyst to handle a wide view of conversations on several topics related to\ntheir business. Nevertheless keeping up-to-date with this amount of information\nis not humanly feasible. Automatic Summarization then provides an interesting\nmean to digest the dynamics and the mass volume of contents. In this paper, we\naddress the issue of tweets summarization which remains scarcely explored. We\npropose to automatically generated summaries of Micro-Blogs conversations\ndealing with public figures E-Reputation. These summaries are generated using\nkey-word queries or sample tweet and offer a focused view of the whole\nMicro-Blog network. Since state-of-the-art is lacking on this point we conduct\nand evaluate our experiments over the multilingual CLEF RepLab Topic-Detection\ndataset according to an experimental evaluation process.", "published": "2020-01-16 08:38:40", "link": "http://arxiv.org/abs/2001.11382v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Speech Emotion Recognition Based on Multi-feature and Multi-lingual\n  Fusion", "abstract": "A speech emotion recognition algorithm based on multi-feature and\nMulti-lingual fusion is proposed in order to resolve low recognition accuracy\ncaused by lack of large speech dataset and low robustness of acoustic features\nin the recognition of speech emotion. First, handcrafted and deep automatic\nfeatures are extracted from existing data in Chinese and English speech\nemotions. Then, the various features are fused respectively. Finally, the fused\nfeatures of different languages are fused again and trained in a classification\nmodel. Distinguishing the fused features with the unfused ones, the results\nmanifest that the fused features significantly enhance the accuracy of speech\nemotion recognition algorithm. The proposed solution is evaluated on the two\nChinese corpus and two English corpus, and is shown to provide more accurate\npredictions compared to original solution. As a result of this study, the\nmulti-feature and Multi-lingual fusion algorithm can significantly improve the\nspeech emotion recognition accuracy when the dataset is small.", "published": "2020-01-16 15:53:13", "link": "http://arxiv.org/abs/2001.05908v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "#MeToo on Campus: Studying College Sexual Assault at Scale Using Data\n  Reported on Social Media", "abstract": "Recently, the emergence of the #MeToo trend on social media has empowered\nthousands of people to share their own sexual harassment experiences. This\nviral trend, in conjunction with the massive personal information and content\navailable on Twitter, presents a promising opportunity to extract data driven\ninsights to complement the ongoing survey based studies about sexual harassment\nin college. In this paper, we analyze the influence of the #MeToo trend on a\npool of college followers. The results show that the majority of topics\nembedded in those #MeToo tweets detail sexual harassment stories, and there\nexists a significant correlation between the prevalence of this trend and\nofficial reports on several major geographical regions. Furthermore, we\ndiscover the outstanding sentiments of the #MeToo tweets using deep semantic\nmeaning representations and their implications on the affected users\nexperiencing different types of sexual harassment. We hope this study can raise\nfurther awareness regarding sexual misconduct in academia.", "published": "2020-01-16 18:05:46", "link": "http://arxiv.org/abs/2001.05970v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.SI"}
{"title": "User-in-the-loop Adaptive Intent Detection for Instructable Digital\n  Assistant", "abstract": "People are becoming increasingly comfortable using Digital Assistants (DAs)\nto interact with services or connected objects. However, for non-programming\nusers, the available possibilities for customizing their DA are limited and do\nnot include the possibility of teaching the assistant new tasks. To make the\nmost of the potential of DAs, users should be able to customize assistants by\ninstructing them through Natural Language (NL). To provide such\nfunctionalities, NL interpretation in traditional assistants should be\nimproved: (1) The intent identification system should be able to recognize new\nforms of known intents, and to acquire new intents as they are expressed by the\nuser. (2) In order to be adaptive to novel intents, the Natural Language\nUnderstanding module should be sample efficient, and should not rely on a\npretrained model. Rather, the system should continuously collect the training\ndata as it learns new intents from the user. In this work, we propose AidMe\n(Adaptive Intent Detection in Multi-Domain Environments), a user-in-the-loop\nadaptive intent detection framework that allows the assistant to adapt to its\nuser by learning his intents as their interaction progresses. AidMe builds its\nrepertoire of intents and collects data to train a model of semantic similarity\nevaluation that can discriminate between the learned intents and autonomously\ndiscover new forms of known intents. AidMe addresses two major issues - intent\nlearning and user adaptation - for instructable digital assistants. We\ndemonstrate the capabilities of AidMe as a standalone system by comparing it\nwith a one-shot learning system and a pretrained NLU module through simulations\nof interactions with a user. We also show how AidMe can smoothly integrate to\nan existing instructable digital assistant.", "published": "2020-01-16 18:06:43", "link": "http://arxiv.org/abs/2001.06007v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Multimodal Story Generation on Plural Images", "abstract": "Traditionally, text generation models take in a sequence of text as input,\nand iteratively generate the next most probable word using pre-trained\nparameters. In this work, we propose the architecture to use images instead of\ntext as the input of the text generation model, called StoryGen. In the\narchitecture, we design a Relational Text Data Generator algorithm that relates\ndifferent features from multiple images. The output samples from the model\ndemonstrate the ability to generate meaningful paragraphs of text containing\nthe extracted features from the input images. This is an undergraduate project\nreport. Completed Dec. 2019 at the Cooper Union.", "published": "2020-01-16 03:39:00", "link": "http://arxiv.org/abs/2001.10980v2", "categories": ["cs.CL", "cs.CV", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "SqueezeWave: Extremely Lightweight Vocoders for On-device Speech\n  Synthesis", "abstract": "Automatic speech synthesis is a challenging task that is becoming\nincreasingly important as edge devices begin to interact with users through\nspeech. Typical text-to-speech pipelines include a vocoder, which translates\nintermediate audio representations into an audio waveform. Most existing\nvocoders are difficult to parallelize since each generated sample is\nconditioned on previous samples. WaveGlow is a flow-based feed-forward\nalternative to these auto-regressive models (Prenger et al., 2019). However,\nwhile WaveGlow can be easily parallelized, the model is too expensive for\nreal-time speech synthesis on the edge. This paper presents SqueezeWave, a\nfamily of lightweight vocoders based on WaveGlow that can generate audio of\nsimilar quality to WaveGlow with 61x - 214x fewer MACs. Code, trained models,\nand generated audio are publicly available at\nhttps://github.com/tianrengao/SqueezeWave.", "published": "2020-01-16 07:26:19", "link": "http://arxiv.org/abs/2001.05685v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Critical Look at the Applicability of Markov Logic Networks for Music\n  Signal Analysis", "abstract": "In recent years, Markov logic networks (MLNs) have been proposed as a\npotentially useful paradigm for music signal analysis. Because all hidden\nMarkov models can be reformulated as MLNs, the latter can provide an\nall-encompassing framework that reuses and extends previous work in the field.\nHowever, just because it is theoretically possible to reformulate previous work\nas MLNs, does not mean that it is advantageous. In this paper, we analyse some\nproposed examples of MLNs for musical analysis and consider their practical\ndisadvantages when compared to formulating the same musical dependence\nrelationships as (dynamic) Bayesian networks. We argue that a number of\npractical hurdles such as the lack of support for sequences and for arbitrary\ncontinuous probability distributions make MLNs less than ideal for the proposed\nmusical applications, both in terms of easy of formulation and computational\nrequirements due to their required inference algorithms. These conclusions are\nnot specific to music, but apply to other fields as well, especially when\nsequential data with continuous observations is involved. Finally, we show that\nthe ideas underlying the proposed examples can be expressed perfectly well in\nthe more commonly used framework of (dynamic) Bayesian networks.", "published": "2020-01-16 21:46:13", "link": "http://arxiv.org/abs/2001.06086v1", "categories": ["cs.AI", "cs.IR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
