{"title": "A More Fine-Grained Aspect-Sentiment-Opinion Triplet Extraction Task", "abstract": "Aspect Sentiment Triplet Extraction (ASTE) aims to extract aspect term,\nsentiment and opinion term triplets from sentences and tries to provide a\ncomplete solution for aspect-based sentiment analysis (ABSA). However, some\ntriplets extracted by ASTE are confusing, since the sentiment in a triplet\nextracted by ASTE is the sentiment that the sentence expresses toward the\naspect term rather than the sentiment of the aspect term and opinion term pair.\nIn this paper, we introduce a more fine-grained Aspect-Sentiment-Opinion\nTriplet Extraction (ASOTE) Task. ASOTE also extracts aspect term, sentiment and\nopinion term triplets. However, the sentiment in a triplet extracted by ASOTE\nis the sentiment of the aspect term and opinion term pair. We build four\ndatasets for ASOTE based on several popular ABSA benchmarks. We propose a\nPosition-aware BERT-based Framework (PBF) to address this task. PBF first\nextracts aspect terms from sentences. For each extracted aspect term, PBF first\ngenerates aspect term-specific sentence representations considering both the\nmeaning and the position of the aspect term, then extracts associated opinion\nterms and predicts the sentiments of the aspect term and opinion term pairs\nbased on the sentence representations. Experimental results on the four\ndatasets show the effectiveness of PBF.", "published": "2021-03-29 00:42:51", "link": "http://arxiv.org/abs/2103.15255v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Centrality Meets Centroid: A Graph-based Approach for Unsupervised\n  Document Summarization", "abstract": "Unsupervised document summarization has re-acquired lots of attention in\nrecent years thanks to its simplicity and data independence. In this paper, we\npropose a graph-based unsupervised approach for extractive document\nsummarization. Instead of ranking sentences by salience and extracting\nsentences one by one, our approach works at a summary-level by utilizing graph\ncentrality and centroid. We first extract summary candidates as subgraphs based\non centrality from the sentence graph and then select from the summary\ncandidates by matching to the centroid. We perform extensive experiments on two\nbench-marked summarization datasets, and the results demonstrate the\neffectiveness of our model compared to state-of-the-art baselines.", "published": "2021-03-29 04:35:33", "link": "http://arxiv.org/abs/2103.15327v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Changing the Mind of Transformers for Topically-Controllable Language\n  Generation", "abstract": "Large Transformer-based language models can aid human authors by suggesting\nplausible continuations of text written so far. However, current interactive\nwriting assistants do not allow authors to guide text generation in desired\ntopical directions. To address this limitation, we design a framework that\ndisplays multiple candidate upcoming topics, of which a user can select a\nsubset to guide the generation. Our framework consists of two components: (1) a\nmethod that produces a set of candidate topics by predicting the centers of\nword clusters in the possible continuations, and (2) a text generation model\nwhose output adheres to the chosen topics. The training of both components is\nself-supervised, using only unlabeled text. Our experiments demonstrate that\nour topic options are better than those of standard clustering approaches, and\nour framework often generates fluent sentences related to the chosen topics, as\njudged by automated metrics and crowdsourced workers.", "published": "2021-03-29 05:02:25", "link": "http://arxiv.org/abs/2103.15335v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-facet Universal Schema", "abstract": "Universal schema (USchema) assumes that two sentence patterns that share the\nsame entity pairs are similar to each other. This assumption is widely adopted\nfor solving various types of relation extraction (RE) tasks. Nevertheless, each\nsentence pattern could contain multiple facets, and not every facet is similar\nto all the facets of another sentence pattern co-occurring with the same entity\npair. To address the violation of the USchema assumption, we propose\nmulti-facet universal schema that uses a neural model to represent each\nsentence pattern as multiple facet embeddings and encourage one of these facet\nembeddings to be close to that of another sentence pattern if they co-occur\nwith the same entity pair. In our experiments, we demonstrate that multi-facet\nembeddings significantly outperform their single-facet embedding counterpart,\ncompositional universal schema (CUSchema) (Verga et al., 2016), in distantly\nsupervised relation extraction tasks. Moreover, we can also use multiple\nembeddings to detect the entailment relation between two sentence patterns when\nno manual label is available.", "published": "2021-03-29 05:10:10", "link": "http://arxiv.org/abs/2103.15339v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieving Event-related Human Brain Dynamics from Natural Sentence\n  Reading", "abstract": "Electroencephalography (EEG) signals recordings when people reading natural\nlanguages are commonly used as a cognitive method to interpret human language\nunderstanding in neuroscience and psycholinguistics. Previous studies have\ndemonstrated that the human fixation and activation in word reading associated\nwith some brain regions, but it is not clear when and how to measure the brain\ndynamics across time and frequency domains. In this study, we propose the first\nanalysis of event-related brain potentials (ERPs), and event-related spectral\nperturbations (ERSPs) on benchmark datasets which consist of sentence-level\nsimultaneous EEG and related eye-tracking recorded from human natural reading\nexperiment tasks. Our results showed peaks evoked at around 162 ms after the\nstimulus (starting to read each sentence) in the occipital area, indicating the\nbrain retriving lexical and semantic visual information processing approaching\n200 ms from the sentence onset. Furthermore, the occipital ERP around 200ms\npresents negative power and positive power in short and long reaction times. In\naddition, the occipital ERSP around 200ms demonstrated increased high gamma and\ndecreased low beta and low gamma power, relative to the baseline. Our results\nimplied that most of the semantic-perception responses occurred around the\n200ms in alpha, beta and gamma bands of EEG signals. Our findings also provide\npotential impacts on promoting cognitive natural language processing models\nevaluation from EEG dynamics.", "published": "2021-03-29 11:11:34", "link": "http://arxiv.org/abs/2103.15500v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multiple-hypothesis CTC-based semi-supervised adaptation of end-to-end\n  speech recognition", "abstract": "This paper proposes an adaptation method for end-to-end speech recognition.\nIn this method, multiple automatic speech recognition (ASR) 1-best hypotheses\nare integrated in the computation of the connectionist temporal classification\n(CTC) loss function. The integration of multiple ASR hypotheses helps\nalleviating the impact of errors in the ASR hypotheses to the computation of\nthe CTC loss when ASR hypotheses are used. When being applied in\nsemi-supervised adaptation scenarios where part of the adaptation data do not\nhave labels, the CTC loss of the proposed method is computed from different ASR\n1-best hypotheses obtained by decoding the unlabeled adaptation data.\nExperiments are performed in clean and multi-condition training scenarios where\nthe CTC-based end-to-end ASR systems are trained on Wall Street Journal (WSJ)\nclean training data and CHiME-4 multi-condition training data, respectively,\nand tested on Aurora-4 test data. The proposed adaptation method yields 6.6%\nand 5.8% relative word error rate (WER) reductions in clean and multi-condition\ntraining scenarios, respectively, compared to a baseline system which is\nadapted with part of the adaptation data having manual transcriptions using\nback-propagation fine-tuning.", "published": "2021-03-29 11:38:35", "link": "http://arxiv.org/abs/2103.15515v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability\n  of the Embedding Layers in NLP Models", "abstract": "Recent studies have revealed a security threat to natural language processing\n(NLP) models, called the Backdoor Attack. Victim models can maintain\ncompetitive performance on clean samples while behaving abnormally on samples\nwith a specific trigger word inserted. Previous backdoor attacking methods\nusually assume that attackers have a certain degree of data knowledge, either\nthe dataset which users would use or proxy datasets for a similar task, for\nimplementing the data poisoning procedure. However, in this paper, we find that\nit is possible to hack the model in a data-free way by modifying one single\nword embedding vector, with almost no accuracy sacrificed on clean samples.\nExperimental results on sentiment analysis and sentence-pair classification\ntasks show that our method is more efficient and stealthier. We hope this work\ncan raise the awareness of such a critical security risk hidden in the\nembedding layers of NLP models. Our code is available at\nhttps://github.com/lancopku/Embedding-Poisoning.", "published": "2021-03-29 12:19:45", "link": "http://arxiv.org/abs/2103.15543v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Shrinking Bigfoot: Reducing wav2vec 2.0 footprint", "abstract": "Wav2vec 2.0 is a state-of-the-art speech recognition model which maps speech\naudio waveforms into latent representations. The largest version of wav2vec 2.0\ncontains 317 million parameters. Hence, the inference latency of wav2vec 2.0\nwill be a bottleneck in production, leading to high costs and a significant\nenvironmental footprint. To improve wav2vec's applicability to a production\nsetting, we explore multiple model compression methods borrowed from the domain\nof large language models. Using a teacher-student approach, we distilled the\nknowledge from the original wav2vec 2.0 model into a student model, which is 2\ntimes faster and 4.8 times smaller than the original model. This increase in\nperformance is accomplished with only a 7% degradation in word error rate\n(WER). Our quantized model is 3.6 times smaller than the original model, with\nonly a 0.1% degradation in WER. To the best of our knowledge, this is the first\nwork that compresses wav2vec 2.0.", "published": "2021-03-29 16:50:28", "link": "http://arxiv.org/abs/2103.15760v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Normalization for Low-Resource Languages of Africa", "abstract": "Training data for machine learning models can come from many different\nsources, which can be of dubious quality. For resource-rich languages like\nEnglish, there is a lot of data available, so we can afford to throw out the\ndubious data. For low-resource languages where there is much less data\navailable, we can't necessarily afford to throw out the dubious data, in case\nwe end up with a training set which is too small to train a model. In this\nstudy, we examine the effects of text normalization and data set quality for a\nset of low-resource languages of Africa -- Afrikaans, Amharic, Hausa, Igbo,\nMalagasy, Somali, Swahili, and Zulu. We describe our text normalizer which we\nbuilt in the Pynini framework, a Python library for finite state transducers,\nand our experiments in training language models for African languages using the\nNatural Language Toolkit (NLTK), an open-source Python library for NLP.", "published": "2021-03-29 18:00:26", "link": "http://arxiv.org/abs/2103.15845v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Augmentation in a Hybrid Approach for Aspect-Based Sentiment\n  Analysis", "abstract": "Data augmentation is a way to increase the diversity of available data by\napplying constrained transformations on the original data. This strategy has\nbeen widely used in image classification but has to the best of our knowledge\nnot yet been used in aspect-based sentiment analysis (ABSA). ABSA is a text\nanalysis technique that determines aspects and their associated sentiment in\nopinionated text. In this paper, we investigate the effect of data augmentation\non a state-of-the-art hybrid approach for aspect-based sentiment analysis\n(HAABSA). We apply modified versions of easy data augmentation (EDA),\nbacktranslation, and word mixup. We evaluate the proposed techniques on the\nSemEval 2015 and SemEval 2016 datasets. The best result is obtained with the\nadjusted version of EDA, which yields a 0.5 percentage point improvement on the\nSemEval 2016 dataset and 1 percentage point increase on the SemEval 2015\ndataset compared to the original HAABSA model.", "published": "2021-03-29 19:43:15", "link": "http://arxiv.org/abs/2103.15912v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explaining a Neural Attention Model for Aspect-Based Sentiment\n  Classification Using Diagnostic Classification", "abstract": "Many high performance machine learning models for Aspect-Based Sentiment\nClassification (ABSC) produce black box models, and therefore barely explain\nhow they classify a certain sentiment value towards an aspect. In this paper,\nwe propose explanation models, that inspect the internal dynamics of a\nstate-of-the-art neural attention model, the LCR-Rot-hop, by using a technique\ncalled Diagnostic Classification. Our diagnostic classifier is a simple neural\nnetwork, which evaluates whether the internal layers of the LCR-Rot-hop model\nencode useful word information for classification, i.e., the part of speech,\nthe sentiment value, the presence of aspect relation, and the aspect-related\nsentiment value of words. We conclude that the lower layers in the LCR-Rot-hop\nmodel encode the part of speech and the sentiment value, whereas the higher\nlayers represent the presence of a relation with the aspect and the\naspect-related sentiment value of words.", "published": "2021-03-29 19:59:34", "link": "http://arxiv.org/abs/2103.15927v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extending Multi-Sense Word Embedding to Phrases and Sentences for\n  Unsupervised Semantic Applications", "abstract": "Most unsupervised NLP models represent each word with a single point or\nsingle region in semantic space, while the existing multi-sense word embeddings\ncannot represent longer word sequences like phrases or sentences. We propose a\nnovel embedding method for a text sequence (a phrase or a sentence) where each\nsequence is represented by a distinct set of multi-mode codebook embeddings to\ncapture different semantic facets of its meaning. The codebook embeddings can\nbe viewed as the cluster centers which summarize the distribution of possibly\nco-occurring words in a pre-trained word embedding space. We introduce an\nend-to-end trainable neural model that directly predicts the set of cluster\ncenters from the input text sequence during test time. Our experiments show\nthat the per-sentence codebook embeddings significantly improve the\nperformances in unsupervised sentence similarity and extractive summarization\nbenchmarks. In phrase similarity experiments, we discover that the multi-facet\nembeddings provide an interpretable semantic representation but do not\noutperform the single-facet baseline.", "published": "2021-03-29 04:54:28", "link": "http://arxiv.org/abs/2103.15330v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Explanations from Empirical Explainers", "abstract": "Amid a discussion about Green AI in which we see explainability neglected, we\nexplore the possibility to efficiently approximate computationally expensive\nexplainers. To this end, we propose feature attribution modelling with\nEmpirical Explainers. Empirical Explainers learn from data to predict the\nattribution maps of expensive explainers. We train and test Empirical\nExplainers in the language domain and find that they model their expensive\ncounterparts surprisingly well, at a fraction of the cost. They could thus\nmitigate the computational burden of neural explanations significantly, in\napplications that tolerate an approximation error.", "published": "2021-03-29 08:54:55", "link": "http://arxiv.org/abs/2103.15429v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "NLP for Ghanaian Languages", "abstract": "NLP Ghana is an open-source non-profit organization aiming to advance the\ndevelopment and adoption of state-of-the-art NLP techniques and digital\nlanguage tools to Ghanaian languages and problems. In this paper, we first\npresent the motivation and necessity for the efforts of the organization; by\nintroducing some popular Ghanaian languages while presenting the state of NLP\nin Ghana. We then present the NLP Ghana organization and outline its aims,\nscope of work, some of the methods employed and contributions made thus far in\nthe NLP community in Ghana.", "published": "2021-03-29 10:16:52", "link": "http://arxiv.org/abs/2103.15475v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "English-Twi Parallel Corpus for Machine Translation", "abstract": "We present a parallel machine translation training corpus for English and\nAkuapem Twi of 25,421 sentence pairs. We used a transformer-based translator to\ngenerate initial translations in Akuapem Twi, which were later verified and\ncorrected where necessary by native speakers to eliminate any occurrence of\ntranslationese. In addition, 697 higher quality crowd-sourced sentences are\nprovided for use as an evaluation set for downstream Natural Language\nProcessing (NLP) tasks. The typical use case for the larger human-verified\ndataset is for further training of machine translation models in Akuapem Twi.\nThe higher quality 697 crowd-sourced dataset is recommended as a testing\ndataset for machine translation of English to Twi and Twi to English models.\nFurthermore, the Twi part of the crowd-sourced data may also be used for other\ntasks, such as representation learning, classification, etc. We fine-tune the\ntransformer translation model on the training corpus and report benchmarks on\nthe crowd-sourced test set.", "published": "2021-03-29 14:04:57", "link": "http://arxiv.org/abs/2103.15625v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Retraining DistilBERT for a Voice Shopping Assistant by Using Universal\n  Dependencies", "abstract": "In this work, we retrained the distilled BERT language model for Walmart's\nvoice shopping assistant on retail domain-specific data. We also injected\nuniversal syntactic dependencies to improve the performance of the model\nfurther. The Natural Language Understanding (NLU) components of the voice\nassistants available today are heavily dependent on language models for various\ntasks. The generic language models such as BERT and RoBERTa are useful for\ndomain-independent assistants but have limitations when they cater to a\nspecific domain. For example, in the shopping domain, the token 'horizon' means\na brand instead of its literal meaning. Generic models are not able to capture\nsuch subtleties. So, in this work, we retrained a distilled version of the BERT\nlanguage model on retail domain-specific data for Walmart's voice shopping\nassistant. We also included universal dependency-based features in the\nretraining process further to improve the performance of the model on\ndownstream tasks. We evaluated the performance of the retrained language model\non four downstream tasks, including intent-entity detection, sentiment\nanalysis, voice title shortening and proactive intent suggestion. We observed\nan increase in the performance of all the downstream tasks of up to 1.31% on\naverage.", "published": "2021-03-29 16:24:00", "link": "http://arxiv.org/abs/2103.15737v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Unsupervised Machine Translation On Dravidian Languages", "abstract": "Unsupervised neural machine translation (UNMT) is beneficial especially for\nlow resource languages such as those from the Dravidian family. However, UNMT\nsystems tend to fail in realistic scenarios involving actual low resource\nlanguages. Recent works propose to utilize auxiliary parallel data and have\nachieved state-of-the-art results. In this work, we focus on unsupervised\ntranslation between English and Kannada, a low resource Dravidian language. We\nadditionally utilize a limited amount of auxiliary data between English and\nother related Dravidian languages. We show that unifying the writing systems is\nessential in unsupervised translation between the Dravidian languages. We\nexplore several model architectures that use the auxiliary data in order to\nmaximize knowledge sharing and enable UNMT for distant language pairs. Our\nexperiments demonstrate that it is crucial to include auxiliary languages that\nare similar to our focal language, Kannada. Furthermore, we propose a metric to\nmeasure language similarity and show that it serves as a good indicator for\nselecting the auxiliary languages.", "published": "2021-03-29 18:33:53", "link": "http://arxiv.org/abs/2103.15877v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Transformer visualization via dictionary learning: contextualized\n  embedding as a linear superposition of transformer factors", "abstract": "Transformer networks have revolutionized NLP representation learning since\nthey were introduced. Though a great effort has been made to explain the\nrepresentation in transformers, it is widely recognized that our understanding\nis not sufficient. One important reason is that there lack enough visualization\ntools for detailed analysis. In this paper, we propose to use dictionary\nlearning to open up these \"black boxes\" as linear superpositions of transformer\nfactors. Through visualization, we demonstrate the hierarchical semantic\nstructures captured by the transformer factors, e.g., word-level polysemy\ndisambiguation, sentence-level pattern formation, and long-range dependency.\nWhile some of these patterns confirm the conventional prior linguistic\nknowledge, the rest are relatively unexpected, which may provide new insights.\nWe hope this visualization tool can bring further knowledge and a better\nunderstanding of how transformer networks work. The code is available at\nhttps://github.com/zeyuyun1/TransformerVis", "published": "2021-03-29 20:51:33", "link": "http://arxiv.org/abs/2103.15949v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TREC 2020 Podcasts Track Overview", "abstract": "The Podcast Track is new at the Text Retrieval Conference (TREC) in 2020. The\npodcast track was designed to encourage research into podcasts in the\ninformation retrieval and NLP research communities. The track consisted of two\nshared tasks: segment retrieval and summarization, both based on a dataset of\nover 100,000 podcast episodes (metadata, audio, and automatic transcripts)\nwhich was released concurrently with the track. The track generated\nconsiderable interest, attracted hundreds of new registrations to TREC and\nfifteen teams, mostly disjoint between search and summarization, made final\nsubmissions for assessment. Deep learning was the dominant experimental\napproach for both search experiments and summarization. This paper gives an\noverview of the tasks and the results of the participants' experiments. The\ntrack will return to TREC 2021 with the same two tasks, incorporating slight\nmodifications in response to participant feedback.", "published": "2021-03-29 20:58:10", "link": "http://arxiv.org/abs/2103.15953v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Contextual Text Embeddings for Twi", "abstract": "Transformer-based language models have been changing the modern Natural\nLanguage Processing (NLP) landscape for high-resource languages such as\nEnglish, Chinese, Russian, etc. However, this technology does not yet exist for\nany Ghanaian language. In this paper, we introduce the first of such models for\nTwi or Akan, the most widely spoken Ghanaian language. The specific\ncontribution of this research work is the development of several pretrained\ntransformer language models for the Akuapem and Asante dialects of Twi, paving\nthe way for advances in application areas such as Named Entity Recognition\n(NER), Neural Machine Translation (NMT), Sentiment Analysis (SA) and\nPart-of-Speech (POS) tagging. Specifically, we introduce four different\nflavours of ABENA -- A BERT model Now in Akan that is fine-tuned on a set of\nAkan corpora, and BAKO - BERT with Akan Knowledge only, which is trained from\nscratch. We open-source the model through the Hugging Face model hub and\ndemonstrate its use via a simple sentiment classification example.", "published": "2021-03-29 21:36:44", "link": "http://arxiv.org/abs/2103.15963v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Whitening Sentence Representations for Better Semantics and Faster\n  Retrieval", "abstract": "Pre-training models such as BERT have achieved great success in many natural\nlanguage processing tasks. However, how to obtain better sentence\nrepresentation through these pre-training models is still worthy to exploit.\nPrevious work has shown that the anisotropy problem is an critical bottleneck\nfor BERT-based sentence representation which hinders the model to fully utilize\nthe underlying semantic features. Therefore, some attempts of boosting the\nisotropy of sentence distribution, such as flow-based model, have been applied\nto sentence representations and achieved some improvement. In this paper, we\nfind that the whitening operation in traditional machine learning can similarly\nenhance the isotropy of sentence representations and achieve competitive\nresults. Furthermore, the whitening technique is also capable of reducing the\ndimensionality of the sentence representation. Our experimental results show\nthat it can not only achieve promising performance but also significantly\nreduce the storage cost and accelerate the model retrieval speed.", "published": "2021-03-29 03:51:53", "link": "http://arxiv.org/abs/2103.15316v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CaSiNo: A Corpus of Campsite Negotiation Dialogues for Automatic\n  Negotiation Systems", "abstract": "Automated systems that negotiate with humans have broad applications in\npedagogy and conversational AI. To advance the development of practical\nnegotiation systems, we present CaSiNo: a novel corpus of over a thousand\nnegotiation dialogues in English. Participants take the role of campsite\nneighbors and negotiate for food, water, and firewood packages for their\nupcoming trip. Our design results in diverse and linguistically rich\nnegotiations while maintaining a tractable, closed-domain environment. Inspired\nby the literature in human-human negotiations, we annotate persuasion\nstrategies and perform correlation analysis to understand how the dialogue\nbehaviors are associated with the negotiation performance. We further propose\nand evaluate a multi-task framework to recognize these strategies in a given\nutterance. We find that multi-task learning substantially improves the\nperformance for all strategy labels, especially for the ones that are the most\nskewed. We release the dataset, annotations, and the code to propel future work\nin human-machine negotiations: https://github.com/kushalchawla/CaSiNo", "published": "2021-03-29 16:07:25", "link": "http://arxiv.org/abs/2103.15721v2", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Transformer-based end-to-end speech recognition with residual\n  Gaussian-based self-attention", "abstract": "Self-attention (SA), which encodes vector sequences according to their\npairwise similarity, is widely used in speech recognition due to its strong\ncontext modeling ability. However, when applied to long sequence data, its\naccuracy is reduced. This is caused by the fact that its weighted average\noperator may lead to the dispersion of the attention distribution, which\nresults in the relationship between adjacent signals ignored. To address this\nissue, in this paper, we introduce relative-position-awareness self-attention\n(RPSA). It not only maintains the global-range dependency modeling ability of\nself-attention, but also improves the localness modeling ability. Because the\nlocal window length of the original RPSA is fixed and sensitive to different\ntest data, here we propose Gaussian-based self-attention (GSA) whose window\nlength is learnable and adaptive to the test data automatically. We further\ngeneralize GSA to a new residual Gaussian self-attention (resGSA) for the\nperformance improvement. We apply RPSA, GSA, and resGSA to Transformer-based\nspeech recognition respectively. Experimental results on the AISHELL-1 Mandarin\nspeech recognition corpus demonstrate the effectiveness of the proposed\nmethods. For example, the resGSA-Transformer achieves a character error rate\n(CER) of 5.86% on the test set, which is relative 7.8% lower than that of the\nSA-Transformer. Although the performance of the proposed resGSA-Transformer is\nonly slightly better than that of the RPSA-Transformer, it does not have to\ntune the window length manually.", "published": "2021-03-29 16:09:00", "link": "http://arxiv.org/abs/2103.15722v4", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Industry Scale Semi-Supervised Learning for Natural Language\n  Understanding", "abstract": "This paper presents a production Semi-Supervised Learning (SSL) pipeline\nbased on the student-teacher framework, which leverages millions of unlabeled\nexamples to improve Natural Language Understanding (NLU) tasks. We investigate\ntwo questions related to the use of unlabeled data in production SSL context:\n1) how to select samples from a huge unlabeled data pool that are beneficial\nfor SSL training, and 2) how do the selected data affect the performance of\ndifferent state-of-the-art SSL techniques. We compare four widely used SSL\ntechniques, Pseudo-Label (PL), Knowledge Distillation (KD), Virtual Adversarial\nTraining (VAT) and Cross-View Training (CVT) in conjunction with two data\nselection methods including committee-based selection and submodular\noptimization based selection. We further examine the benefits and drawbacks of\nthese techniques when applied to intent classification (IC) and named entity\nrecognition (NER) tasks, and provide guidelines specifying when each of these\nmethods might be beneficial to improve large scale NLU systems.", "published": "2021-03-29 18:24:02", "link": "http://arxiv.org/abs/2103.15871v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cognitive networks identify the content of English and Italian popular\n  posts about COVID-19 vaccines: Anticipation, logistics, conspiracy and loss\n  of trust", "abstract": "Monitoring social discourse about COVID-19 vaccines is key to understanding\nhow large populations perceive vaccination campaigns. We focus on 4765 unique\npopular tweets in English or Italian about COVID-19 vaccines between 12/2020\nand 03/2021. One popular English tweet was liked up to 495,000 times, stressing\nhow popular tweets affected cognitively massive populations. We investigate\nboth text and multimedia in tweets, building a knowledge graph of\nsyntactic/semantic associations in messages including visual features and\nindicating how online users framed social discourse mostly around the logistics\nof vaccine distribution. The English semantic frame of \"vaccine\" was highly\npolarised between trust/anticipation (towards the vaccine as a scientific asset\nsaving lives) and anger/sadness (mentioning critical issues with dose\nadministering). Semantic associations with \"vaccine,\" \"hoax\" and conspiratorial\njargon indicated the persistence of conspiracy theories and vaccines in\nmassively read English posts (absent in Italian messages). The image analysis\nfound that popular tweets with images of people wearing face masks used\nlanguage lacking the trust and joy found in tweets showing people with no\nmasks, indicating a negative affect attributed to face covering in social\ndiscourse. A behavioural analysis revealed a tendency for users to share\ncontent eliciting joy, sadness and disgust and to like less sad messages,\nhighlighting an interplay between emotions and content diffusion beyond\nsentiment. With the AstraZeneca vaccine being suspended in mid March 2021,\n\"Astrazeneca\" was associated with trustful language driven by experts, but\npopular Italian tweets framed \"vaccine\" by crucially replacing earlier levels\nof trust with deep sadness. Our results stress how cognitive networks and\ninnovative multimedia processing open new ways for reconstructing online\nperceptions about vaccines and trust.", "published": "2021-03-29 19:38:13", "link": "http://arxiv.org/abs/2103.15909v1", "categories": ["physics.soc-ph", "cs.CL", "cs.CY", "cs.SI"], "primary_category": "physics.soc-ph"}
{"title": "Entity Context Graph: Learning Entity Representations\n  fromSemi-Structured Textual Sources on the Web", "abstract": "Knowledge is captured in the form of entities and their relationships and\nstored in knowledge graphs. Knowledge graphs enhance the capabilities of\napplications in many different areas including Web search, recommendation, and\nnatural language understanding. This is mainly because, entities enable\nmachines to understand things that go beyond simple tokens. Many modern\nalgorithms use learned entity embeddings from these structured representations.\nHowever, building a knowledge graph takes time and effort, hence very costly\nand nontrivial. On the other hand, many Web sources describe entities in some\nstructured format and therefore, finding ways to get them into useful entity\nknowledge is advantageous. We propose an approach that processes entity centric\ntextual knowledge sources to learn entity embeddings and in turn avoids the\nneed for a traditional knowledge graph. We first extract triples into the new\nrepresentation format that does not use traditional complex triple extraction\nmethods defined by pre-determined relationship labels. Then we learn entity\nembeddings through this new type of triples. We show that the embeddings\nlearned from our approach are: (i) high quality and comparable to a known\nknowledge graph-based embeddings and can be used to improve them further, (ii)\nbetter than a contextual language model-based entity embeddings, and (iii) easy\nto compute and versatile in domain-specific applications where a knowledge\ngraph is not readily available", "published": "2021-03-29 20:52:14", "link": "http://arxiv.org/abs/2103.15950v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Improved Meta-Learning Training for Speaker Verification", "abstract": "Meta-learning has recently become a research hotspot in speaker verification\n(SV). We introduce two methods to improve the meta-learning training for SV in\nthis paper. For the first method, a backbone embedding network is first jointly\ntrained with the conventional cross entropy loss and prototypical networks (PN)\nloss. Then, inspired by speaker adaptive training in speech recognition,\nadditional transformation coefficients are trained with only the PN loss. The\ntransformation coefficients are used to modify the original backbone embedding\nnetwork in the x-vector extraction process. Furthermore, the random erasing\ndata augmentation technique is applied to all support samples in each episode\nto construct positive pairs, and a contrastive loss between the augmented and\nthe original support samples is added to the objective in model training.\nExperiments are carried out on the SITW and VOiCES databases. Both of the\nmethods can obtain consistent improvements over existing meta-learning training\nframeworks. By combining these two methods, we can observe further improvements\non these two databases.", "published": "2021-03-29 08:37:27", "link": "http://arxiv.org/abs/2103.15421v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Scaling sparsemax based channel selection for speech recognition with\n  ad-hoc microphone arrays", "abstract": "Recently, speech recognition with ad-hoc microphone arrays has received much\nattention. It is known that channel selection is an important problem of ad-hoc\nmicrophone arrays, however, this topic seems far from explored in speech\nrecognition yet, particularly with a large-scale ad-hoc microphone array. To\naddress this problem, we propose a Scaling Sparsemax algorithm for the channel\nselection problem of the speech recognition with large-scale ad-hoc microphone\narrays. Specifically, we first replace the conventional Softmax operator in the\nstream attention mechanism of a multichannel end-to-end speech recognition\nsystem with Sparsemax, which conducts channel selection by forcing the channel\nweights of noisy channels to zero. Because Sparsemax punishes the weights of\nmany channels to zero harshly, we propose Scaling Sparsemax which punishes the\nchannels mildly by setting the weights of very noisy channels to zero only.\nExperimental results with ad-hoc microphone arrays of over 30 channels under\nthe conformer speech recognition architecture show that the proposed Scaling\nSparsemax yields a word error rate of over 30% lower than Softmax on simulation\ndata sets, and over 20% lower on semi-real data sets, in test scenarios with\nboth matched and mismatched channel numbers.", "published": "2021-03-29 03:24:05", "link": "http://arxiv.org/abs/2103.15305v3", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
