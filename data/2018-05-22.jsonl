{"title": "Controlling Personality-Based Stylistic Variation with Neural Natural\n  Language Generators", "abstract": "Natural language generators for task-oriented dialogue must effectively\nrealize system dialogue actions and their associated semantics. In many\napplications, it is also desirable for generators to control the style of an\nutterance. To date, work on task-oriented neural generation has primarily\nfocused on semantic fidelity rather than achieving stylistic goals, while work\non style has been done in contexts where it is difficult to measure content\npreservation. Here we present three different sequence-to-sequence models and\ncarefully test how well they disentangle content and style. We use a\nstatistical generator, Personage, to synthesize a new corpus of over 88,000\nrestaurant domain utterances whose style varies according to models of\npersonality, giving us total control over both the semantic content and the\nstylistic variation in the training data. We then vary the amount of explicit\nstylistic supervision given to the three models. We show that our most explicit\nmodel can simultaneously achieve high fidelity to both semantic and stylistic\ngoals: this model adds a context vector of 36 stylistic parameters as input to\nthe hidden state of the encoder at each time step, showing the benefits of\nexplicit stylistic supervision, even when the amount of training data is large.", "published": "2018-05-22 02:07:32", "link": "http://arxiv.org/abs/1805.08352v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning sentence embeddings using Recursive Networks", "abstract": "Learning sentence vectors that generalise well is a challenging task. In this\npaper we compare three methods of learning phrase embeddings: 1) Using LSTMs,\n2) using recursive nets, 3) A variant of the method 2 using the POS information\nof the phrase. We train our models on dictionary definitions of words to obtain\na reverse dictionary application similar to Felix et al. [1]. To see if our\nembeddings can be transferred to a new task we also train and test on the\nrotten tomatoes dataset [2]. We train keeping the sentence embeddings fixed as\nwell as with fine tuning.", "published": "2018-05-22 02:09:02", "link": "http://arxiv.org/abs/1805.08353v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Estimating the Rating of Reviewers Based on the Text", "abstract": "User-generated texts such as reviews and social media are valuable sources of\ninformation. Online reviews are important assets for users to buy a product,\nsee a movie, or make a decision. Therefore, rating of a review is one of the\nreliable factors for all users to read and trust the reviews. This paper\nanalyzes the texts of the reviews to evaluate and predict the ratings.\nMoreover, we study the effect of lexical features generated from text as well\nas sentimental words on the accuracy of rating prediction. Our analysis show\nthat words with high information gain score are more efficient compared to\nwords with high TF-IDF value. In addition, we explore the best number of\nfeatures for predicting the ratings of the reviews.", "published": "2018-05-22 06:09:39", "link": "http://arxiv.org/abs/1805.08415v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Paracompositionality, MWEs and Argument Substitution", "abstract": "Multi-word expressions, verb-particle constructions, idiomatically combining\nphrases, and phrasal idioms have something in common: not all of their elements\ncontribute to the argument structure of the predicate implicated by the\nexpression.\n  Radically lexicalized theories of grammar that avoid string-, term-, logical\nform-, and tree-writing, and categorial grammars that avoid wrap operation,\nmake predictions about the categories involved in verb-particles and phrasal\nidioms. They may require singleton types, which can only substitute for one\nvalue, not just for one kind of value. These types are asymmetric: they can be\narguments only. They also narrowly constrain the kind of semantic value that\ncan correspond to such syntactic categories. Idiomatically combining phrases do\nnot subcategorize for singleton types, and they exploit another locally\ncomputable and compositional property of a correspondence, that every syntactic\nexpression can project its head word. Such MWEs can be seen as empirically\nrealized categorial possibilities, rather than lacuna in a theory of\nlexicalizable syntactic categories.", "published": "2018-05-22 07:59:53", "link": "http://arxiv.org/abs/1805.08438v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis of Arabic Tweets: Feature Engineering and A Hybrid\n  Approach", "abstract": "Sentiment Analysis in Arabic is a challenging task due to the rich morphology\nof the language. Moreover, the task is further complicated when applied to\nTwitter data that is known to be highly informal and noisy. In this paper, we\ndevelop a hybrid method for sentiment analysis for Arabic tweets for a specific\nArabic dialect which is the Saudi Dialect. Several features were engineered and\nevaluated using a feature backward selection method. Then a hybrid method that\ncombines a corpus-based and lexicon-based method was developed for several\nclassification models (two-way, three-way, four-way). The best F1-score for\neach of these models was (69.9,61.63,55.07) respectively.", "published": "2018-05-22 12:08:22", "link": "http://arxiv.org/abs/1805.08533v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Affective Analysis Using Hierarchical Attention Strategy with\n  Word-Level Alignment", "abstract": "Multimodal affective computing, learning to recognize and interpret human\naffects and subjective information from multiple data sources, is still\nchallenging because: (i) it is hard to extract informative features to\nrepresent human affects from heterogeneous inputs; (ii) current fusion\nstrategies only fuse different modalities at abstract level, ignoring\ntime-dependent interactions between modalities. Addressing such issues, we\nintroduce a hierarchical multimodal architecture with attention and word-level\nfusion to classify utter-ance-level sentiment and emotion from text and audio\ndata. Our introduced model outperforms the state-of-the-art approaches on\npublished datasets and we demonstrated that our model is able to visualize and\ninterpret the synchronized attention over modalities.", "published": "2018-05-22 15:25:29", "link": "http://arxiv.org/abs/1805.08660v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Normalization of Transliterated Words in Code-Mixed Data Using Seq2Seq\n  Model & Levenshtein Distance", "abstract": "Building tools for code-mixed data is rapidly gaining popularity in the NLP\nresearch community as such data is exponentially rising on social media.\nWorking with code-mixed data contains several challenges, especially due to\ngrammatical inconsistencies and spelling variations in addition to all the\nprevious known challenges for social media scenarios. In this article, we\npresent a novel architecture focusing on normalizing phonetic typing\nvariations, which is commonly seen in code-mixed data. One of the main features\nof our architecture is that in addition to normalizing, it can also be utilized\nfor back-transliteration and word identification in some cases. Our model\nachieved an accuracy of 90.27% on the test data.", "published": "2018-05-22 16:11:12", "link": "http://arxiv.org/abs/1805.08701v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Image Captioning and Question Answering", "abstract": "Answering visual questions need acquire daily common knowledge and model the\nsemantic connection among different parts in images, which is too difficult for\nVQA systems to learn from images with the only supervision from answers.\nMeanwhile, image captioning systems with beam search strategy tend to generate\nsimilar captions and fail to diversely describe images. To address the\naforementioned issues, we present a system to have these two tasks compensate\nwith each other, which is capable of jointly producing image captions and\nanswering visual questions. In particular, we utilize question and image\nfeatures to generate question-related captions and use the generated captions\nas additional features to provide new knowledge to the VQA system. For image\ncaptioning, our system attains more informative results in term of the relative\nimprovements on VQA tasks as well as competitive results using automated\nmetrics. Applying our system to the VQA tasks, our results on VQA v2 dataset\nachieve 65.8% using generated captions and 69.1% using annotated captions in\nvalidation set and 68.4% in the test-standard set. Further, an ensemble of 10\nmodels results in 69.7% in the test-standard split.", "published": "2018-05-22 04:41:37", "link": "http://arxiv.org/abs/1805.08389v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Context-Aware Sequence-to-Sequence Models for Conversational Systems", "abstract": "This work proposes a novel approach based on sequence-to-sequence (seq2seq)\nmodels for context-aware conversational systems. Exist- ing seq2seq models have\nbeen shown to be good for generating natural responses in a data-driven\nconversational system. However, they still lack mechanisms to incorporate\nprevious conversation turns. We investigate RNN-based methods that efficiently\nintegrate previous turns as a context for generating responses. Overall, our\nexperimental results based on human judgment demonstrate the feasibility and\neffectiveness of the proposed approach.", "published": "2018-05-22 08:34:10", "link": "http://arxiv.org/abs/1805.08455v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "COCO-CN for Cross-Lingual Image Tagging, Captioning and Retrieval", "abstract": "This paper contributes to cross-lingual image annotation and retrieval in\nterms of data and baseline methods. We propose COCO-CN, a novel dataset\nenriching MS-COCO with manually written Chinese sentences and tags. For more\neffective annotation acquisition, we develop a recommendation-assisted\ncollective annotation system, automatically providing an annotator with several\ntags and sentences deemed to be relevant with respect to the pictorial content.\nHaving 20,342 images annotated with 27,218 Chinese sentences and 70,993 tags,\nCOCO-CN is currently the largest Chinese-English dataset that provides a\nunified and challenging platform for cross-lingual image tagging, captioning\nand retrieval. We develop conceptually simple yet effective methods per task\nfor learning from cross-lingual resources. Extensive experiments on the three\ntasks justify the viability of the proposed dataset and methods. Data and code\nare publicly available at https://github.com/li-xirong/coco-cn", "published": "2018-05-22 15:26:15", "link": "http://arxiv.org/abs/1805.08661v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Guided Feature Transformation (GFT): A Neural Language Grounding Module\n  for Embodied Agents", "abstract": "Recently there has been a rising interest in training agents, embodied in\nvirtual environments, to perform language-directed tasks by deep reinforcement\nlearning. In this paper, we propose a simple but effective neural language\ngrounding module for embodied agents that can be trained end to end from\nscratch taking raw pixels, unstructured linguistic commands, and sparse rewards\nas the inputs. We model the language grounding process as a language-guided\ntransformation of visual features, where latent sentence embeddings are used as\nthe transformation matrices. In several language-directed navigation tasks that\nfeature challenging partial observability and require simple reasoning, our\nmodule significantly outperforms the state of the art. We also release\nXWorld3D, an easy-to-customize 3D environment that can potentially be modified\nto evaluate a variety of embodied agents.", "published": "2018-05-22 00:16:39", "link": "http://arxiv.org/abs/1805.08329v2", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Generative timbre spaces: regularizing variational auto-encoders with\n  perceptual metrics", "abstract": "Timbre spaces have been used in music perception to study the perceptual\nrelationships between instruments based on dissimilarity ratings. However,\nthese spaces do not generalize to novel examples and do not provide an\ninvertible mapping, preventing audio synthesis. In parallel, generative models\nhave aimed to provide methods for synthesizing novel timbres. However, these\nsystems do not provide an understanding of their inner workings and are usually\nnot related to any perceptually relevant information. Here, we show that\nVariational Auto-Encoders (VAE) can alleviate all of these limitations by\nconstructing generative timbre spaces. To do so, we adapt VAEs to learn an\naudio latent space, while using perceptual ratings from timbre studies to\nregularize the organization of this space. The resulting space allows us to\nanalyze novel instruments, while being able to synthesize audio from any point\nof this space. We introduce a specific regularization allowing to enforce any\ngiven similarity distances onto these spaces. We show that the resulting space\nprovide almost similar distance relationships as timbre spaces. We evaluate\nseveral spectral transforms and show that the Non-Stationary Gabor Transform\n(NSGT) provides the highest correlation to timbre spaces and the best quality\nof synthesis. Furthermore, we show that these spaces can generalize to novel\ninstruments and can generate any path between instruments to understand their\ntimbre relationships. As these spaces are continuous, we study how audio\ndescriptors behave along the latent dimensions. We show that even though\ndescriptors have an overall non-linear topology, they follow a locally smooth\nevolution. Based on this, we introduce a method for descriptor-based synthesis\nand show that we can control the descriptors of an instrument while keeping its\ntimbre structure.", "published": "2018-05-22 11:05:46", "link": "http://arxiv.org/abs/1805.08501v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Music Source Separation Using Stacked Hourglass Networks", "abstract": "In this paper, we propose a simple yet effective method for multiple music\nsource separation using convolutional neural networks. Stacked hourglass\nnetwork, which was originally designed for human pose estimation in natural\nimages, is applied to a music source separation task. The network learns\nfeatures from a spectrogram image across multiple scales and generates masks\nfor each music source. The estimated mask is refined as it passes over stacked\nhourglass modules. The proposed framework is able to separate multiple music\nsources using a single network. Experimental results on MIR-1K and DSD100\ndatasets validate that the proposed method achieves competitive results\ncomparable to the state-of-the-art methods in multiple music source separation\nand singing voice separation tasks.", "published": "2018-05-22 13:01:39", "link": "http://arxiv.org/abs/1805.08559v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Study On Convolutional Neural Network Based End-To-End Replay\n  Anti-Spoofing", "abstract": "The second Automatic Speaker Verification Spoofing and Countermeasures\nchallenge (ASVspoof 2017) focused on \"replay attack\" detection. The best\ndeep-learning systems to compete in ASVspoof 2017 used Convolutional Neural\nNetworks (CNNs) as a feature extractor. In this paper, we study their\nperformance in an end-to-end setting. We find that these architectures show\npoor generalization in the evaluation dataset, but find a compact architecture\nthat shows good generalization on the development data. We demonstrate that for\nthis dataset it is not easy to obtain a similar level of generalization on both\nthe development and evaluation data. This leads to a variety of open questions\nabout what the differences are in the data; why these are more evident in an\nend-to-end setting; and how these issues can be overcome by increasing the\ntraining data.", "published": "2018-05-22 14:53:13", "link": "http://arxiv.org/abs/1805.09164v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
