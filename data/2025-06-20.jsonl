{"title": "VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning", "abstract": "Vision-Language Navigation (VLN) is a core challenge in embodied AI,\nrequiring agents to navigate real-world environments using natural language\ninstructions. Current language model-based navigation systems operate on\ndiscrete topological graphs, limiting path planning to predefined node\nconnections. We propose VLN-R1, an end-to-end framework that leverages Large\nVision-Language Models (LVLM) to directly translate egocentric video streams\ninto continuous navigation actions, adopting GRPO-based training inspired by\nDeepSeek-R1. To enable effective training, we first construct the VLN-Ego\ndataset using a 3D simulator, Habitat, and propose Long-Short Memory Sampling\nto balance historical and current observations. While large language models can\nsupervise complete textual instructions, they lack fine-grained action-level\ncontrol. Our framework employs a two-stage training approach: a) Supervised\nfine-tuning (SFT) to align the model's action sequence text predictions with\nexpert demonstrations, followed by b) Reinforcement fine-tuning (RFT) enhanced\nwith a Time-Decayed Reward (TDR) mechanism that strategically weights\nmulti-step future actions. Experimental results show VLN-R1 achieves strong\nperformance on VLN-CE benchmark. VLN-R1 proves LVLMs can drive embodied\nnavigation and enhance task-specific reasoning through data-efficient,\nreward-driven post-training.", "published": "2025-06-20 17:59:59", "link": "http://arxiv.org/abs/2506.17221v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Emergent Temporal Correspondences from Video Diffusion Transformers", "abstract": "Recent advancements in video diffusion models based on Diffusion Transformers\n(DiTs) have achieved remarkable success in generating temporally coherent\nvideos. Yet, a fundamental question persists: how do these models internally\nestablish and represent temporal correspondences across frames? We introduce\nDiffTrack, the first quantitative analysis framework designed to answer this\nquestion. DiffTrack constructs a dataset of prompt-generated video with pseudo\nground-truth tracking annotations and proposes novel evaluation metrics to\nsystematically analyze how each component within the full 3D attention\nmechanism of DiTs (e.g., representations, layers, and timesteps) contributes to\nestablishing temporal correspondences. Our analysis reveals that query-key\nsimilarities in specific, but not all, layers play a critical role in temporal\nmatching, and that this matching becomes increasingly prominent during the\ndenoising process. We demonstrate practical applications of DiffTrack in\nzero-shot point tracking, where it achieves state-of-the-art performance\ncompared to existing vision foundation and self-supervised video models.\nFurther, we extend our findings to motion-enhanced video generation with a\nnovel guidance method that improves temporal consistency of generated videos\nwithout additional training. We believe our work offers crucial insights into\nthe inner workings of video DiTs and establishes a foundation for further\nresearch and applications leveraging their temporal understanding.", "published": "2025-06-20 17:59:55", "link": "http://arxiv.org/abs/2506.17220v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens", "abstract": "Vision-language models (VLMs) excel at multimodal understanding, yet their\ntext-only decoding forces them to verbalize visual reasoning, limiting\nperformance on tasks that demand visual imagination. Recent attempts train VLMs\nto render explicit images, but the heavy image-generation pre-training often\nhinders the reasoning ability. Inspired by the way humans reason with mental\nimagery-the internal construction and manipulation of visual cues-we\ninvestigate whether VLMs can reason through interleaved multimodal trajectories\nwithout producing explicit images. To this end, we present a Machine Mental\nImagery framework, dubbed as Mirage, which augments VLM decoding with latent\nvisual tokens alongside ordinary text. Concretely, whenever the model chooses\nto ``think visually'', it recasts its hidden states as next tokens, thereby\ncontinuing a multimodal trajectory without generating pixel-level images. Begin\nby supervising the latent tokens through distillation from ground-truth image\nembeddings, we then switch to text-only supervision to make the latent\ntrajectory align tightly with the task objective. A subsequent reinforcement\nlearning stage further enhances the multimodal reasoning capability.\nExperiments on diverse benchmarks demonstrate that Mirage unlocks stronger\nmultimodal reasoning without explicit image generation.", "published": "2025-06-20 17:59:31", "link": "http://arxiv.org/abs/2506.17218v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Long-term Traffic Simulation with Interleaved Autoregressive Motion and Scenario Generation", "abstract": "An ideal traffic simulator replicates the realistic long-term point-to-point\ntrip that a self-driving system experiences during deployment. Prior models and\nbenchmarks focus on closed-loop motion simulation for initial agents in a\nscene. This is problematic for long-term simulation. Agents enter and exit the\nscene as the ego vehicle enters new regions. We propose InfGen, a unified\nnext-token prediction model that performs interleaved closed-loop motion\nsimulation and scene generation. InfGen automatically switches between\nclosed-loop motion simulation and scene generation mode. It enables stable\nlong-term rollout simulation. InfGen performs at the state-of-the-art in\nshort-term (9s) traffic simulation, and significantly outperforms all other\nmethods in long-term (30s) simulation. The code and model of InfGen will be\nreleased at https://orangesodahub.github.io/InfGen", "published": "2025-06-20 17:59:21", "link": "http://arxiv.org/abs/2506.17213v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Part$^{2}$GS: Part-aware Modeling of Articulated Objects using 3D Gaussian Splatting", "abstract": "Articulated objects are common in the real world, yet modeling their\nstructure and motion remains a challenging task for 3D reconstruction methods.\nIn this work, we introduce Part$^{2}$GS, a novel framework for modeling\narticulated digital twins of multi-part objects with high-fidelity geometry and\nphysically consistent articulation. Part$^{2}$GS leverages a part-aware 3D\nGaussian representation that encodes articulated components with learnable\nattributes, enabling structured, disentangled transformations that preserve\nhigh-fidelity geometry. To ensure physically consistent motion, we propose a\nmotion-aware canonical representation guided by physics-based constraints,\nincluding contact enforcement, velocity consistency, and vector-field\nalignment. Furthermore, we introduce a field of repel points to prevent part\ncollisions and maintain stable articulation paths, significantly improving\nmotion coherence over baselines. Extensive evaluations on both synthetic and\nreal-world datasets show that Part$^{2}$GS consistently outperforms\nstate-of-the-art methods by up to 10$\\times$ in Chamfer Distance for movable\nparts.", "published": "2025-06-20 17:59:12", "link": "http://arxiv.org/abs/2506.17212v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "DreamCube: 3D Panorama Generation via Multi-plane Synchronization", "abstract": "3D panorama synthesis is a promising yet challenging task that demands\nhigh-quality and diverse visual appearance and geometry of the generated\nomnidirectional content. Existing methods leverage rich image priors from\npre-trained 2D foundation models to circumvent the scarcity of 3D panoramic\ndata, but the incompatibility between 3D panoramas and 2D single views limits\ntheir effectiveness. In this work, we demonstrate that by applying multi-plane\nsynchronization to the operators from 2D foundation models, their capabilities\ncan be seamlessly extended to the omnidirectional domain. Based on this design,\nwe further introduce DreamCube, a multi-plane RGB-D diffusion model for 3D\npanorama generation, which maximizes the reuse of 2D foundation model priors to\nachieve diverse appearances and accurate geometry while maintaining multi-view\nconsistency. Extensive experiments demonstrate the effectiveness of our\napproach in panoramic image generation, panoramic depth estimation, and 3D\nscene generation.", "published": "2025-06-20 17:55:06", "link": "http://arxiv.org/abs/2506.17206v1", "categories": ["cs.GR", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "UniFork: Exploring Modality Alignment for Unified Multimodal Understanding and Generation", "abstract": "Unified image understanding and generation has emerged as a promising\nparadigm in multimodal artificial intelligence. Despite recent progress, the\noptimal architectural design for such unified models remains an open challenge.\nIn this work, we start by analyzing the modality alignment behaviors of\ntask-specific expert models for understanding and generation, as well as\ncurrent unified models. Our analysis reveals a crucial observation:\nunderstanding tasks benefit from a progressively increasing modality alignment\nacross network depth, which helps build up semantic information for better\ncomprehension; In contrast, generation tasks follow a different trend: modality\nalignment increases in the early layers but decreases in the deep layers to\nrecover spatial details. These divergent alignment patterns create a\nfundamental conflict in fully shared Transformer backbones, where a uniform\nrepresentational flow often leads to performance compromises across two tasks.\nMotivated by this finding, we introduce UniFork, a novel Y-shaped architecture\nthat shares the shallow layers for cross-task representation learning, while\nemploying task-specific branches in deeper layers to avoid task interference.\nThis design effectively balances shared learning and task specialization.\nThrough extensive ablation experiments, we demonstrate that Unifork\nconsistently outperforms conventional fully shared Transformer architectures,\nand achieves performance on par with or better than task-specific models.", "published": "2025-06-20 17:52:31", "link": "http://arxiv.org/abs/2506.17202v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hunyuan-GameCraft: High-dynamic Interactive Game Video Generation with Hybrid History Condition", "abstract": "Recent advances in diffusion-based and controllable video generation have\nenabled high-quality and temporally coherent video synthesis, laying the\ngroundwork for immersive interactive gaming experiences. However, current\nmethods face limitations in dynamics, generality, long-term consistency, and\nefficiency, which limit the ability to create various gameplay videos. To\naddress these gaps, we introduce Hunyuan-GameCraft, a novel framework for\nhigh-dynamic interactive video generation in game environments. To achieve\nfine-grained action control, we unify standard keyboard and mouse inputs into a\nshared camera representation space, facilitating smooth interpolation between\nvarious camera and movement operations. Then we propose a hybrid\nhistory-conditioned training strategy that extends video sequences\nautoregressively while preserving game scene information. Additionally, to\nenhance inference efficiency and playability, we achieve model distillation to\nreduce computational overhead while maintaining consistency across long\ntemporal sequences, making it suitable for real-time deployment in complex\ninteractive environments. The model is trained on a large-scale dataset\ncomprising over one million gameplay recordings across over 100 AAA games,\nensuring broad coverage and diversity, then fine-tuned on a carefully annotated\nsynthetic dataset to enhance precision and control. The curated game scene data\nsignificantly improves the visual fidelity, realism and action controllability.\nExtensive experiments demonstrate that Hunyuan-GameCraft significantly\noutperforms existing models, advancing the realism and playability of\ninteractive game video generation.", "published": "2025-06-20 17:50:37", "link": "http://arxiv.org/abs/2506.17201v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation", "abstract": "Generating large-scale demonstrations for dexterous hand manipulation remains\nchallenging, and several approaches have been proposed in recent years to\naddress this. Among them, generative models have emerged as a promising\nparadigm, enabling the efficient creation of diverse and physically plausible\ndemonstrations. In this paper, we introduce Dex1B, a large-scale, diverse, and\nhigh-quality demonstration dataset produced with generative models. The dataset\ncontains one billion demonstrations for two fundamental tasks: grasping and\narticulation. To construct it, we propose a generative model that integrates\ngeometric constraints to improve feasibility and applies additional conditions\nto enhance diversity. We validate the model on both established and newly\nintroduced simulation benchmarks, where it significantly outperforms prior\nstate-of-the-art methods. Furthermore, we demonstrate its effectiveness and\nrobustness through real-world robot experiments. Our project page is at\nhttps://jianglongye.com/dex1b", "published": "2025-06-20 17:49:04", "link": "http://arxiv.org/abs/2506.17198v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Facial Landmark Visualization and Emotion Recognition Through Neural Networks", "abstract": "Emotion recognition from facial images is a crucial task in human-computer\ninteraction, enabling machines to learn human emotions through facial\nexpressions. Previous studies have shown that facial images can be used to\ntrain deep learning models; however, most of these studies do not include a\nthrough dataset analysis. Visualizing facial landmarks can be challenging when\nextracting meaningful dataset insights; to address this issue, we propose\nfacial landmark box plots, a visualization technique designed to identify\noutliers in facial datasets. Additionally, we compare two sets of facial\nlandmark features: (i) the landmarks' absolute positions and (ii) their\ndisplacements from a neutral expression to the peak of an emotional expression.\nOur results indicate that a neural network achieves better performance than a\nrandom forest classifier.", "published": "2025-06-20 17:45:34", "link": "http://arxiv.org/abs/2506.17191v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "YASMOT: Yet another stereo image multi-object tracker", "abstract": "There now exists many popular object detectors based on deep learning that\ncan analyze images and extract locations and class labels for occurrences of\nobjects. For image time series (i.e., video or sequences of stills), tracking\nobjects over time and preserving object identity can help to improve object\ndetection performance, and is necessary for many downstream tasks, including\nclassifying and predicting behaviors, and estimating total abundances. Here we\npresent yasmot, a lightweight and flexible object tracker that can process the\noutput from popular object detectors and track objects over time from either\nmonoscopic or stereoscopic camera configurations. In addition, it includes\nfunctionality to generate consensus detections from ensembles of object\ndetectors.", "published": "2025-06-20 17:40:54", "link": "http://arxiv.org/abs/2506.17186v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Proportional Sensitivity in Generative Adversarial Network (GAN)-Augmented Brain Tumor Classification Using Convolutional Neural Network", "abstract": "Generative Adversarial Networks (GAN) have shown potential in expanding\nlimited medical imaging datasets. This study explores how different ratios of\nGAN-generated and real brain tumor MRI images impact the performance of a CNN\nin classifying healthy vs. tumorous scans. A DCGAN was used to create synthetic\nimages which were mixed with real ones at various ratios to train a custom CNN.\nThe CNN was then evaluated on a separate real-world test set. Our results\nindicate that the model maintains high sensitivity and precision in tumor\nclassification, even when trained predominantly on synthetic data. When only a\nsmall portion of GAN data was added, such as 900 real images and 100 GAN\nimages, the model achieved excellent performance, with test accuracy reaching\n95.2%, and precision, recall, and F1-score all exceeding 95%. However, as the\nproportion of GAN images increased further, performance gradually declined.\nThis study suggests that while GANs are useful for augmenting limited datasets\nespecially when real data is scarce, too much synthetic data can introduce\nartifacts that affect the model's ability to generalize to real world cases.", "published": "2025-06-20 17:12:03", "link": "http://arxiv.org/abs/2506.17165v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Co-Seg++: Mutual Prompt-Guided Collaborative Learning for Versatile Medical Segmentation", "abstract": "Medical image analysis is critical yet challenged by the need of jointly\nsegmenting organs or tissues, and numerous instances for anatomical structures\nand tumor microenvironment analysis. Existing studies typically formulated\ndifferent segmentation tasks in isolation, which overlooks the fundamental\ninterdependencies between these tasks, leading to suboptimal segmentation\nperformance and insufficient medical image understanding. To address this\nissue, we propose a Co-Seg++ framework for versatile medical segmentation.\nSpecifically, we introduce a novel co-segmentation paradigm, allowing semantic\nand instance segmentation tasks to mutually enhance each other. We first devise\na spatio-temporal prompt encoder (STP-Encoder) to capture long-range spatial\nand temporal relationships between segmentation regions and image embeddings as\nprior spatial constraints. Moreover, we devise a multi-task collaborative\ndecoder (MTC-Decoder) that leverages cross-guidance to strengthen the\ncontextual consistency of both tasks, jointly computing semantic and instance\nsegmentation masks. Extensive experiments on diverse CT and histopathology\ndatasets demonstrate that the proposed Co-Seg++ outperforms state-of-the-arts\nin the semantic, instance, and panoptic segmentation of dental anatomical\nstructures, histopathology tissues, and nuclei instances. The source code is\navailable at https://github.com/xq141839/Co-Seg-Plus.", "published": "2025-06-20 17:05:09", "link": "http://arxiv.org/abs/2506.17159v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Do We Need Large VLMs for Spotting Soccer Actions?", "abstract": "Traditional video-based tasks like soccer action spotting rely heavily on\nvisual inputs, often requiring complex and computationally expensive models to\nprocess dense video data. In this work, we propose a shift from this\nvideo-centric approach to a text-based task, making it lightweight and scalable\nby utilizing Large Language Models (LLMs) instead of Vision-Language Models\n(VLMs). We posit that expert commentary, which provides rich, fine-grained\ndescriptions and contextual cues such as excitement and tactical insights,\ncontains enough information to reliably spot key actions in a match. To\ndemonstrate this, we use the SoccerNet Echoes dataset, which provides\ntimestamped commentary, and employ a system of three LLMs acting as judges\nspecializing in outcome, excitement, and tactics. Each LLM evaluates sliding\nwindows of commentary to identify actions like goals, cards, and substitutions,\ngenerating accurate timestamps for these events. Our experiments show that this\nlanguage-centric approach performs effectively in detecting critical match\nevents, providing a lightweight and training-free alternative to traditional\nvideo-based methods for action spotting.", "published": "2025-06-20 16:45:54", "link": "http://arxiv.org/abs/2506.17144v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification", "abstract": "Deep learning models have made significant advances in histological\nprediction tasks in recent years. However, for adaptation in clinical practice,\ntheir lack of robustness to varying conditions such as staining, scanner,\nhospital, and demographics is still a limiting factor: if trained on\noverrepresented subpopulations, models regularly struggle with less frequent\npatterns, leading to shortcut learning and biased predictions. Large-scale\nfoundation models have not fully eliminated this issue. Therefore, we propose a\nnovel approach explicitly modeling such metadata into a Metadata-guided\ngenerative Diffusion model framework (MeDi). MeDi allows for a targeted\naugmentation of underrepresented subpopulations with synthetic data, which\nbalances limited training data and mitigates biases in downstream models. We\nexperimentally show that MeDi generates high-quality histopathology images for\nunseen subpopulations in TCGA, boosts the overall fidelity of the generated\nimages, and enables improvements in performance for downstream classifiers on\ndatasets with subpopulation shifts. Our work is a proof-of-concept towards\nbetter mitigating data biases with generative models.", "published": "2025-06-20 16:41:25", "link": "http://arxiv.org/abs/2506.17140v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "On the Theory of Conditional Feature Alignment for Unsupervised Domain-Adaptive Counting", "abstract": "Object counting models suffer when deployed across domains with differing\ndensity variety, since density shifts are inherently task-relevant and violate\nstandard domain adaptation assumptions. To address this, we propose a\ntheoretical framework of conditional feature alignment. We first formalize the\nnotion of conditional divergence by partitioning each domain into subsets\n(e.g., object vs. background) and measuring divergences per condition. We then\nderive a joint error bound showing that, under discrete label spaces treated as\ncondition sets, aligning distributions conditionally leads to tighter bounds on\nthe combined source-target decision error than unconditional alignment. These\ninsights motivate a general conditional adaptation principle: by preserving\ntask-relevant variations while filtering out nuisance shifts, one can achieve\nsuperior cross-domain generalization for counting. We provide both defining\nconditional divergence then proving its benefit in lowering joint error and a\npractical adaptation strategy that preserves task-relevant information in\nunsupervised domain-adaptive counting. We demonstrate the effectiveness of our\napproach through extensive experiments on multiple counting datasets with\nvarying density distributions. The results show that our method outperforms\nexisting unsupervised domain adaptation methods, empirically validating the\ntheoretical insights on conditional feature alignment.", "published": "2025-06-20 16:37:48", "link": "http://arxiv.org/abs/2506.17137v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Semi-Supervised Multi-Modal Medical Image Segmentation for Complex Situations", "abstract": "Semi-supervised learning addresses the issue of limited annotations in\nmedical images effectively, but its performance is often inadequate for complex\nbackgrounds and challenging tasks. Multi-modal fusion methods can significantly\nimprove the accuracy of medical image segmentation by providing complementary\ninformation. However, they face challenges in achieving significant\nimprovements under semi-supervised conditions due to the challenge of\neffectively leveraging unlabeled data. There is a significant need to create an\neffective and reliable multi-modal learning strategy for leveraging unlabeled\ndata in semi-supervised segmentation. To address these issues, we propose a\nnovel semi-supervised multi-modal medical image segmentation approach, which\nleverages complementary multi-modal information to enhance performance with\nlimited labeled data. Our approach employs a multi-stage multi-modal fusion and\nenhancement strategy to fully utilize complementary multi-modal information,\nwhile reducing feature discrepancies and enhancing feature sharing and\nalignment. Furthermore, we effectively introduce contrastive mutual learning to\nconstrain prediction consistency across modalities, thereby facilitating the\nrobustness of segmentation results in semi-supervised tasks. Experimental\nresults on two multi-modal datasets demonstrate the superior performance and\nrobustness of the proposed framework, establishing its valuable potential for\nsolving medical image segmentation tasks in complex scenarios.", "published": "2025-06-20 16:37:44", "link": "http://arxiv.org/abs/2506.17136v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dynamic Watermark Generation for Digital Images using Perimeter Gated SPAD Imager PUFs", "abstract": "Digital image watermarks as a security feature can be derived from the\nimager's physically unclonable functions (PUFs) by utilizing the manufacturing\nvariations, i.e., the dark signal non-uniformity (DSNU). While a few\ndemonstrations focused on the CMOS image sensors (CIS) and active pixel sensors\n(APS), single photon avalanche diode (SPAD) imagers have never been\ninvestigated for this purpose. In this work, we have proposed a novel\nwatermarking technique using perimeter gated SPAD (pgSPAD) imagers. We utilized\nthe DSNU of three 64 x 64 pgSPAD imager chips, fabricated in a 0.35 {\\mu}m\nstandard CMOS process and analyzed the simulated watermarks for standard test\nimages from publicly available database. Our observation shows that both source\nidentification and tamper detection can be achieved using the proposed\nsource-scene-specific dynamic watermarks with a controllable\nsensitivity-robustness trade-off.", "published": "2025-06-20 16:36:43", "link": "http://arxiv.org/abs/2506.17134v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Robust Training with Data Augmentation for Medical Imaging Classification", "abstract": "Deep neural networks are increasingly being used to detect and diagnose\nmedical conditions using medical imaging. Despite their utility, these models\nare highly vulnerable to adversarial attacks and distribution shifts, which can\naffect diagnostic reliability and undermine trust among healthcare\nprofessionals. In this study, we propose a robust training algorithm with data\naugmentation (RTDA) to mitigate these vulnerabilities in medical image\nclassification. We benchmark classifier robustness against adversarial\nperturbations and natural variations of RTDA and six competing baseline\ntechniques, including adversarial training and data augmentation approaches in\nisolation and combination, using experimental data sets with three different\nimaging technologies (mammograms, X-rays, and ultrasound). We demonstrate that\nRTDA achieves superior robustness against adversarial attacks and improved\ngeneralization performance in the presence of distribution shift in each image\nclassification task while maintaining high clean accuracy.", "published": "2025-06-20 16:36:39", "link": "http://arxiv.org/abs/2506.17133v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking", "abstract": "We introduce a robust framework, RGBTrack, for real-time 6D pose estimation\nand tracking that operates solely on RGB data, thereby eliminating the need for\ndepth input for such dynamic and precise object pose tracking tasks. Building\non the FoundationPose architecture, we devise a novel binary search strategy\ncombined with a render-and-compare mechanism to efficiently infer depth and\ngenerate robust pose hypotheses from true-scale CAD models. To maintain stable\ntracking in dynamic scenarios, including rapid movements and occlusions,\nRGBTrack integrates state-of-the-art 2D object tracking (XMem) with a Kalman\nfilter and a state machine for proactive object pose recovery. In addition,\nRGBTrack's scale recovery module dynamically adapts CAD models of unknown scale\nusing an initial depth estimate, enabling seamless integration with modern\ngenerative reconstruction techniques. Extensive evaluations on benchmark\ndatasets demonstrate that RGBTrack's novel depth-free approach achieves\ncompetitive accuracy and real-time performance, making it a promising practical\nsolution candidate for application areas including robotics, augmented reality,\nand computer vision.\n  The source code for our implementation will be made publicly available at\nhttps://github.com/GreatenAnoymous/RGBTrack.git.", "published": "2025-06-20 16:19:28", "link": "http://arxiv.org/abs/2506.17119v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation", "abstract": "Combining pre-trained expert models offers substantial potential for scalable\nmultimodal reasoning, but building a unified framework remains challenging due\nto the increasing diversity of input modalities and task complexity. For\ninstance, medical diagnosis requires precise reasoning over structured clinical\ntables, while financial forecasting depends on interpreting plot-based data to\nmake informed predictions. To tackle this challenge, we introduce MEXA, a\ntraining-free framework that performs modality- and task-aware aggregation of\nmultiple expert models to enable effective multimodal reasoning across diverse\nand distinct domains. MEXA dynamically selects expert models based on the input\nmodality and the task-specific reasoning demands (i.e., skills). Each expert\nmodel, specialized in a modality task pair, generates interpretable textual\nreasoning outputs. MEXA then aggregates and reasons over these outputs using a\nLarge Reasoning Model (LRM) to produce the final answer. This modular design\nallows flexible and transparent multimodal reasoning across diverse domains\nwithout additional training overhead. We extensively evaluate our approach on\ndiverse multimodal benchmarks, including Video Reasoning, Audio Reasoning, 3D\nUnderstanding, and Medical QA. MEXA consistently delivers performance\nimprovements over strong multimodal baselines, highlighting the effectiveness\nand broad applicability of our expert-driven selection and aggregation in\ndiverse multimodal reasoning tasks.", "published": "2025-06-20 16:14:13", "link": "http://arxiv.org/abs/2506.17113v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping", "abstract": "Accurate 6D object pose estimation is a prerequisite for successfully\ncompleting robotic prehensile and non-prehensile manipulation tasks. At\npresent, 6D pose estimation for robotic manipulation generally relies on depth\nsensors based on, e.g., structured light, time-of-flight, and stereo-vision,\nwhich can be expensive, produce noisy output (as compared with RGB cameras),\nand fail to handle transparent objects. On the other hand, state-of-the-art\nmonocular depth estimation models (MDEMs) provide only affine-invariant depths\nup to an unknown scale and shift. Metric MDEMs achieve some successful\nzero-shot results on public datasets, but fail to generalize. We propose a\nnovel framework, Monocular One-shot Metric-depth Alignment (MOMA), to recover\nmetric depth from a single RGB image, through a one-shot adaptation building on\nMDEM techniques. MOMA performs scale-rotation-shift alignments during camera\ncalibration, guided by sparse ground-truth depth points, enabling accurate\ndepth estimation without additional data collection or model retraining on the\ntesting setup. MOMA supports fine-tuning the MDEM on transparent objects,\ndemonstrating strong generalization capabilities. Real-world experiments on\ntabletop 2-finger grasping and suction-based bin-picking applications show MOMA\nachieves high success rates in diverse tasks, confirming its effectiveness.", "published": "2025-06-20 16:11:20", "link": "http://arxiv.org/abs/2506.17110v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Acquiring and Accumulating Knowledge from Diverse Datasets for Multi-label Driving Scene Classification", "abstract": "Driving scene identification, which assigns multiple non-exclusive class\nlabels to a scene, provides the contextual awareness necessary for enhancing\nautonomous vehicles' ability to understand, reason about, and interact with the\ncomplex driving environment. As a multi-label classification problem, it is\nbetter tackled via multitasking learning. However, directly training a\nmulti-label classification model for driving scene identification through\nmultitask learning presents two main challenges: acquiring a balanced,\ncomprehensively annotated multi-label dataset and balancing learning across\ndifferent tasks. This paper introduces a novel learning system that synergizes\nknowledge acquisition and accumulation (KAA) with consistency-based active\nlearning (CAL) to address those challenges. KAA acquires and accumulates\nknowledge about scene identification from various single-label datasets via\nmonotask learning. Subsequently, CAL effectively resolves the knowledge gap\ncaused by the discrepancy between the marginal distributions of individual\nattributes and their joint distribution. An ablation study on our Driving Scene\nIdentification (DSI) dataset demonstrates a 56.1% performance increase over the\nbaseline model pretrained on ImageNet. Of this, KAA accounts for 31.3% of the\ngain, and CAL contributes 24.8%. Moreover, KAA-CAL stands out as the best\nperformer when compared to state-of-the-art (SOTA) multi-label models on two\npublic datasets, BDD100K and HSD, achieving this while using 85% less data. The\nDSI dataset and the implementation code for KAA-CAL are available at\nhttps://github.com/KELISBU/KAA-CAL .", "published": "2025-06-20 16:06:53", "link": "http://arxiv.org/abs/2506.17101v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Assembler: Scalable 3D Part Assembly via Anchor Point Diffusion", "abstract": "We present Assembler, a scalable and generalizable framework for 3D part\nassembly that reconstructs complete objects from input part meshes and a\nreference image. Unlike prior approaches that mostly rely on deterministic part\npose prediction and category-specific training, Assembler is designed to handle\ndiverse, in-the-wild objects with varying part counts, geometries, and\nstructures. It addresses the core challenges of scaling to general 3D part\nassembly through innovations in task formulation, representation, and data.\nFirst, Assembler casts part assembly as a generative problem and employs\ndiffusion models to sample plausible configurations, effectively capturing\nambiguities arising from symmetry, repeated parts, and multiple valid\nassemblies. Second, we introduce a novel shape-centric representation based on\nsparse anchor point clouds, enabling scalable generation in Euclidean space\nrather than SE(3) pose prediction. Third, we construct a large-scale dataset of\nover 320K diverse part-object assemblies using a synthesis and filtering\npipeline built on existing 3D shape repositories. Assembler achieves\nstate-of-the-art performance on PartNet and is the first to demonstrate\nhigh-quality assembly for complex, real-world objects. Based on Assembler, we\nfurther introduce an interesting part-aware 3D modeling system that generates\nhigh-resolution, editable objects from images, demonstrating potential for\ninteractive and compositional design. Project page:\nhttps://assembler3d.github.io", "published": "2025-06-20 15:25:20", "link": "http://arxiv.org/abs/2506.17074v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Relaxed syntax modeling in Transformers for future-proof license plate recognition", "abstract": "Effective license plate recognition systems are required to be resilient to\nconstant change, as new license plates are released into traffic daily. While\nTransformer-based networks excel in their recognition at first sight, we\nobserve significant performance drop over time which proves them unsuitable for\ntense production environments. Indeed, such systems obtain state-of-the-art\nresults on plates whose syntax is seen during training. Yet, we show they\nperform similarly to random guessing on future plates where legible characters\nare wrongly recognized due to a shift in their syntax. After highlighting the\nflows of positional and contextual information in Transformer encoder-decoders,\nwe identify several causes for their over-reliance on past syntax. Following,\nwe devise architectural cut-offs and replacements which we integrate into SaLT,\nan attempt at a Syntax-Less Transformer for syntax-agnostic modeling of license\nplate representations. Experiments on both real and synthetic datasets show\nthat our approach reaches top accuracy on past syntax and most importantly\nnearly maintains performance on future license plates. We further demonstrate\nthe robustness of our architecture enhancements by way of various ablations.", "published": "2025-06-20 15:03:57", "link": "http://arxiv.org/abs/2506.17051v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Stretching Beyond the Obvious: A Gradient-Free Framework to Unveil the Hidden Landscape of Visual Invariance", "abstract": "Uncovering which features' combinations high-level visual units encode is\ncritical to understand how images are transformed into representations that\nsupport recognition. While existing feature visualization approaches typically\ninfer a unit's most exciting images, this is insufficient to reveal the\nmanifold of transformations under which responses remain invariant, which is\nkey to generalization in vision. Here we introduce Stretch-and-Squeeze (SnS),\nan unbiased, model-agnostic, and gradient-free framework to systematically\ncharacterize a unit's invariance landscape and its vulnerability to adversarial\nperturbations in both biological and artificial visual systems. SnS frames\nthese transformations as bi-objective optimization problems. To probe\ninvariance, SnS seeks image perturbations that maximally alter the\nrepresentation of a reference stimulus in a given processing stage while\npreserving unit activation. To probe adversarial sensitivity, SnS seeks\nperturbations that minimally alter the stimulus while suppressing unit\nactivation. Applied to convolutional neural networks (CNNs), SnS revealed image\nvariations that were further from a reference image in pixel-space than those\nproduced by affine transformations, while more strongly preserving the target\nunit's response. The discovered invariant images differed dramatically\ndepending on the choice of image representation used for optimization:\npixel-level changes primarily affected luminance and contrast, while stretching\nmid- and late-layer CNN representations altered texture and pose respectively.\nNotably, the invariant images from robust networks were more recognizable by\nhuman subjects than those from standard networks, supporting the higher\nfidelity of robust CNNs as models of the visual system.", "published": "2025-06-20 14:49:35", "link": "http://arxiv.org/abs/2506.17040v1", "categories": ["cs.CV", "cs.NE"], "primary_category": "cs.CV"}
{"title": "Unsupervised Image Super-Resolution Reconstruction Based on Real-World Degradation Patterns", "abstract": "The training of real-world super-resolution reconstruction models heavily\nrelies on datasets that reflect real-world degradation patterns. Extracting and\nmodeling degradation patterns for super-resolution reconstruction using only\nreal-world low-resolution (LR) images remains a challenging task. When\nsynthesizing datasets to simulate real-world degradation, relying solely on\ndegradation extraction methods fails to capture both blur and diverse noise\ncharacteristics across varying LR distributions, as well as more implicit\ndegradations such as color gamut shifts. Conversely, domain translation alone\ncannot accurately approximate real-world blur characteristics due to the\nsignificant degradation domain gap between synthetic and real data. To address\nthese challenges, we propose a novel TripleGAN framework comprising two\nstrategically designed components: The FirstGAN primarily focuses on narrowing\nthe domain gap in blur characteristics, while the SecondGAN performs\ndomain-specific translation to approximate target-domain blur properties and\nlearn additional degradation patterns. The ThirdGAN is trained on pseudo-real\ndata generated by the FirstGAN and SecondGAN to reconstruct real-world LR\nimages. Extensive experiments on the RealSR and DRealSR datasets demonstrate\nthat our method exhibits clear advantages in quantitative metrics while\nmaintaining sharp reconstructions without over-smoothing artifacts. The\nproposed framework effectively learns real-world degradation patterns from LR\nobservations and synthesizes aligned datasets with corresponding degradation\ncharacteristics, thereby enabling the trained network to achieve superior\nperformance in reconstructing high-quality SR images from real-world LR inputs.", "published": "2025-06-20 14:24:48", "link": "http://arxiv.org/abs/2506.17027v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "A Synthetic Benchmark for Collaborative 3D Semantic Occupancy Prediction in V2X Autonomous Driving", "abstract": "3D semantic occupancy prediction is an emerging perception paradigm in\nautonomous driving, providing a voxel-level representation of both geometric\ndetails and semantic categories. However, the perception capability of a single\nvehicle is inherently constrained by occlusion, restricted sensor range, and\nnarrow viewpoints. To address these limitations, collaborative perception\nenables the exchange of complementary information, thereby enhancing the\ncompleteness and accuracy. In the absence of a dedicated dataset for\ncollaborative 3D semantic occupancy prediction, we augment an existing\ncollaborative perception dataset by replaying it in CARLA with a\nhigh-resolution semantic voxel sensor to provide dense and comprehensive\noccupancy annotations. In addition, we establish benchmarks with varying\nprediction ranges designed to systematically assess the impact of spatial\nextent on collaborative prediction. We further develop a baseline model that\nperforms inter-agent feature fusion via spatial alignment and attention\naggregation. Experimental results demonstrate that our baseline model\nconsistently outperforms single-agent models, with increasing gains observed as\nthe prediction range expands.", "published": "2025-06-20 13:58:10", "link": "http://arxiv.org/abs/2506.17004v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Prmpt2Adpt: Prompt-Based Zero-Shot Domain Adaptation for Resource-Constrained Environments", "abstract": "Unsupervised Domain Adaptation (UDA) is a critical challenge in real-world\nvision systems, especially in resource-constrained environments like drones,\nwhere memory and computation are limited. Existing prompt-driven UDA methods\ntypically rely on large vision-language models and require full access to\nsource-domain data during adaptation, limiting their applicability. In this\nwork, we propose Prmpt2Adpt, a lightweight and efficient zero-shot domain\nadaptation framework built around a teacher-student paradigm guided by\nprompt-based feature alignment. At the core of our method is a distilled and\nfine-tuned CLIP model, used as the frozen backbone of a Faster R-CNN teacher. A\nsmall set of low-level source features is aligned to the target domain\nsemantics-specified only through a natural language prompt-via Prompt-driven\nInstance Normalization (PIN). These semantically steered features are used to\nbriefly fine-tune the detection head of the teacher model. The adapted teacher\nthen generates high-quality pseudo-labels, which guide the on-the-fly\nadaptation of a compact student model. Experiments on the MDS-A dataset\ndemonstrate that Prmpt2Adpt achieves competitive detection performance compared\nto state-of-the-art methods, while delivering up to 7x faster adaptation and 5x\nfaster inference speed using few source images-making it a practical and\nscalable solution for real-time adaptation in low-resource domains.", "published": "2025-06-20 13:43:54", "link": "http://arxiv.org/abs/2506.16994v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds", "abstract": "The segmentation of forest LiDAR 3D point clouds, including both individual\ntree and semantic segmentation, is fundamental for advancing forest management\nand ecological research. However, current approaches often struggle with the\ncomplexity and variability of natural forest environments. We present\nForestFormer3D, a new unified and end-to-end framework designed for precise\nindividual tree and semantic segmentation. ForestFormer3D incorporates\nISA-guided query point selection, a score-based block merging strategy during\ninference, and a one-to-many association mechanism for effective training. By\ncombining these new components, our model achieves state-of-the-art performance\nfor individual tree segmentation on the newly introduced FOR-instanceV2\ndataset, which spans diverse forest types and regions. Additionally,\nForestFormer3D generalizes well to unseen test sets (Wytham woods and LAUTx),\nshowcasing its robustness across different forest conditions and sensor\nmodalities. The FOR-instanceV2 dataset and the ForestFormer3D code will be\nreleased soon.", "published": "2025-06-20 13:39:27", "link": "http://arxiv.org/abs/2506.16991v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs", "abstract": "Multimodal large language models (MLLMs) have begun to demonstrate robust\nreasoning capabilities on general tasks, yet their application in the medical\ndomain remains in its early stages. Constructing chain-of-thought (CoT)\ntraining data is essential for bolstering the reasoning abilities of medical\nMLLMs. However, existing approaches exhibit a deficiency in offering a\ncomprehensive framework for searching and evaluating effective reasoning paths\ntowards critical diagnosis. To address this challenge, we propose Mentor-Intern\nCollaborative Search (MICS), a novel reasoning-path searching scheme to\ngenerate rigorous and effective medical CoT data. MICS first leverages mentor\nmodels to initialize the reasoning, one step at a time, then prompts each\nintern model to continue the thinking along those initiated paths, and finally\nselects the optimal reasoning path according to the overall reasoning\nperformance of multiple intern models. The reasoning performance is determined\nby an MICS-Score, which assesses the quality of generated reasoning paths.\nEventually, we construct MMRP, a multi-task medical reasoning dataset with\nranked difficulty, and Chiron-o1, a new medical MLLM devised via a curriculum\nlearning strategy, with robust visual question-answering and generalizable\nreasoning capabilities. Extensive experiments demonstrate that Chiron-o1,\ntrained on our CoT dataset constructed using MICS, achieves state-of-the-art\nperformance across a list of medical visual question answering and reasoning\nbenchmarks. Codes are available at GitHub - manglu097/Chiron-o1: Enhancing\nStep-by-Step and Verifiable Medical Reasoning in MLLMs", "published": "2025-06-20 12:51:19", "link": "http://arxiv.org/abs/2506.16962v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Reversing Flow for Image Restoration", "abstract": "Image restoration aims to recover high-quality (HQ) images from degraded\nlow-quality (LQ) ones by reversing the effects of degradation. Existing\ngenerative models for image restoration, including diffusion and score-based\nmodels, often treat the degradation process as a stochastic transformation,\nwhich introduces inefficiency and complexity. In this work, we propose ResFlow,\na novel image restoration framework that models the degradation process as a\ndeterministic path using continuous normalizing flows. ResFlow augments the\ndegradation process with an auxiliary process that disambiguates the\nuncertainty in HQ prediction to enable reversible modeling of the degradation\nprocess. ResFlow adopts entropy-preserving flow paths and learns the augmented\ndegradation flow by matching the velocity field. ResFlow significantly improves\nthe performance and speed of image restoration, completing the task in fewer\nthan four sampling steps. Extensive experiments demonstrate that ResFlow\nachieves state-of-the-art results across various image restoration benchmarks,\noffering a practical and efficient solution for real-world applications.", "published": "2025-06-20 12:51:12", "link": "http://arxiv.org/abs/2506.16961v1", "categories": ["cs.CV", "eess.IV", "68U10", "I.4.4"], "primary_category": "cs.CV"}
{"title": "Visual-Instructed Degradation Diffusion for All-in-One Image Restoration", "abstract": "Image restoration tasks like deblurring, denoising, and dehazing usually need\ndistinct models for each degradation type, restricting their generalization in\nreal-world scenarios with mixed or unknown degradations. In this work, we\npropose \\textbf{Defusion}, a novel all-in-one image restoration framework that\nutilizes visual instruction-guided degradation diffusion. Unlike existing\nmethods that rely on task-specific models or ambiguous text-based priors,\nDefusion constructs explicit \\textbf{visual instructions} that align with the\nvisual degradation patterns. These instructions are grounded by applying\ndegradations to standardized visual elements, capturing intrinsic degradation\nfeatures while agnostic to image semantics. Defusion then uses these visual\ninstructions to guide a diffusion-based model that operates directly in the\ndegradation space, where it reconstructs high-quality images by denoising the\ndegradation effects with enhanced stability and generalizability. Comprehensive\nexperiments demonstrate that Defusion outperforms state-of-the-art methods\nacross diverse image restoration tasks, including complex and real-world\ndegradations.", "published": "2025-06-20 12:50:42", "link": "http://arxiv.org/abs/2506.16960v1", "categories": ["cs.CV", "68U10", "I.4.4"], "primary_category": "cs.CV"}
{"title": "LAION-C: An Out-of-Distribution Benchmark for Web-Scale Vision Models", "abstract": "Out-of-distribution (OOD) robustness is a desired property of computer vision\nmodels. Improving model robustness requires high-quality signals from\nrobustness benchmarks to quantify progress. While various benchmark datasets\nsuch as ImageNet-C were proposed in the ImageNet era, most ImageNet-C\ncorruption types are no longer OOD relative to today's large, web-scraped\ndatasets, which already contain common corruptions such as blur or JPEG\ncompression artifacts. Consequently, these benchmarks are no longer well-suited\nfor evaluating OOD robustness in the era of web-scale datasets. Indeed, recent\nmodels show saturating scores on ImageNet-era OOD benchmarks, indicating that\nit is unclear whether models trained on web-scale datasets truly become better\nat OOD generalization or whether they have simply been exposed to the test\ndistortions during training. To address this, we introduce LAION-C as a\nbenchmark alternative for ImageNet-C. LAION-C consists of six novel distortion\ntypes specifically designed to be OOD, even for web-scale datasets such as\nLAION. In a comprehensive evaluation of state-of-the-art models, we find that\nthe LAION-C dataset poses significant challenges to contemporary models,\nincluding MLLMs such as Gemini and GPT-4o. We additionally conducted a\npsychophysical experiment to evaluate the difficulty of our corruptions for\nhuman observers, enabling a comparison of models to lab-quality human\nrobustness data. We observe a paradigm shift in OOD generalization: from humans\noutperforming models, to the best models now matching or outperforming the best\nhuman observers.", "published": "2025-06-20 12:32:27", "link": "http://arxiv.org/abs/2506.16950v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "LunarLoc: Segment-Based Global Localization on the Moon", "abstract": "Global localization is necessary for autonomous operations on the lunar\nsurface where traditional Earth-based navigation infrastructure, such as GPS,\nis unavailable. As NASA advances toward sustained lunar presence under the\nArtemis program, autonomous operations will be an essential component of tasks\nsuch as robotic exploration and infrastructure deployment. Tasks such as\nexcavation and transport of regolith require precise pose estimation, but\nproposed approaches such as visual-inertial odometry (VIO) accumulate odometry\ndrift over long traverses. Precise pose estimation is particularly important\nfor upcoming missions such as the ISRU Pilot Excavator (IPEx) that rely on\nautonomous agents to operate over extended timescales and varied terrain. To\nhelp overcome odometry drift over long traverses, we propose LunarLoc, an\napproach to global localization that leverages instance segmentation for\nzero-shot extraction of boulder landmarks from onboard stereo imagery. Segment\ndetections are used to construct a graph-based representation of the terrain,\nwhich is then aligned with a reference map of the environment captured during a\nprevious session using graph-theoretic data association. This method enables\naccurate and drift-free global localization in visually ambiguous settings.\nLunarLoc achieves sub-cm level accuracy in multi-session global localization\nexperiments, significantly outperforming the state of the art in lunar global\nlocalization. To encourage the development of further methods for global\nlocalization on the Moon, we release our datasets publicly with a playback\nmodule: https://github.com/mit-acl/lunarloc-data.", "published": "2025-06-20 12:06:47", "link": "http://arxiv.org/abs/2506.16940v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PET Tracer Separation Using Conditional Diffusion Transformer with Multi-latent Space Learning", "abstract": "In clinical practice, single-radiotracer positron emission tomography (PET)\nis commonly used for imaging. Although multi-tracer PET imaging can provide\nsupplementary information of radiotracers that are sensitive to physiological\nfunction changes, enabling a more comprehensive characterization of\nphysiological and pathological states, the gamma-photon pairs generated by\npositron annihilation reactions of different tracers in PET imaging have the\nsame energy, making it difficult to distinguish the tracer signals. In this\nstudy, a multi-latent space guided texture conditional diffusion transformer\nmodel (MS-CDT) is proposed for PET tracer separation. To the best of our\nknowledge, this is the first attempt to use texture condition and multi-latent\nspace for tracer separation in PET imaging. The proposed model integrates\ndiffusion and transformer architectures into a unified optimization framework,\nwith the novel addition of texture masks as conditional inputs to enhance image\ndetails. By leveraging multi-latent space prior derived from different tracers,\nthe model captures multi-level feature representations, aiming to balance\ncomputational efficiency and detail preservation. The texture masks, serving as\nconditional guidance, help the model focus on salient structural patterns,\nthereby improving the extraction and utilization of fine-grained image\ntextures. When combined with the diffusion transformer backbone, this\nconditioning mechanism contributes to more accurate and robust tracer\nseparation. To evaluate its effectiveness, the proposed MS-CDT is compared with\nseveral advanced methods on two types of 3D PET datasets: brain and chest\nscans. Experimental results indicate that MS-CDT achieved competitive\nperformance in terms of image quality and preservation of clinically relevant\ninformation. Code is available at: https://github.com/yqx7150/MS-CDT.", "published": "2025-06-20 11:55:35", "link": "http://arxiv.org/abs/2506.16934v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "AI's Blind Spots: Geographic Knowledge and Diversity Deficit in Generated Urban Scenario", "abstract": "Image generation models are revolutionizing many domains, and urban analysis\nand design is no exception. While such models are widely adopted, there is a\nlimited literature exploring their geographic knowledge, along with the biases\nthey embed. In this work, we generated 150 synthetic images for each state in\nthe USA and related capitals using FLUX 1 and Stable Diffusion 3.5, two\nstate-of-the-art models for image generation. We embed each image using DINO-v2\nViT-S/14 and the Fr\\'echet Inception Distances to measure the similarity\nbetween the generated images. We found that while these models have implicitly\nlearned aspects of USA geography, if we prompt the models to generate an image\nfor \"United States\" instead of specific cities or states, the models exhibit a\nstrong representative bias toward metropolis-like areas, excluding rural states\nand smaller cities. {\\color{black} In addition, we found that models\nsystematically exhibit some entity-disambiguation issues with European-sounding\nnames like Frankfort or Devon.", "published": "2025-06-20 10:43:22", "link": "http://arxiv.org/abs/2506.16898v1", "categories": ["cs.AI", "cs.CV", "cs.CY"], "primary_category": "cs.AI"}
{"title": "With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You", "abstract": "Multimodal models have demonstrated powerful capabilities in complex tasks\nrequiring multimodal alignment including zero-shot classification and\ncross-modal retrieval. However, existing models typically rely on millions of\npaired multimodal samples, which are prohibitively expensive or infeasible to\nobtain in many domains. In this work, we explore the feasibility of building\nmultimodal models with limited amount of paired data by aligning pretrained\nunimodal foundation models. We show that high-quality alignment is possible\nwith as few as tens of thousands of paired samples$\\unicode{x2013}$less than\n$1\\%$ of the data typically used in the field. To achieve this, we introduce\nSTRUCTURE, an effective regularization technique that preserves the\nneighborhood geometry of the latent space of unimodal encoders. Additionally,\nwe show that aligning last layers is often suboptimal and demonstrate the\nbenefits of aligning the layers with the highest representational similarity\nacross modalities. These two components can be readily incorporated into\nexisting alignment methods, yielding substantial gains across 24 zero-shot\nimage classification and retrieval benchmarks, with average relative\nimprovement of $51.6\\%$ in classification and $91.8\\%$ in retrieval tasks. Our\nresults highlight the effectiveness and broad applicability of our framework\nfor limited-sample multimodal learning and offer a promising path forward for\nresource-constrained domains.", "published": "2025-06-20 10:32:54", "link": "http://arxiv.org/abs/2506.16895v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "From Lab to Factory: Pitfalls and Guidelines for Self-/Unsupervised Defect Detection on Low-Quality Industrial Images", "abstract": "The detection and localization of quality-related problems in industrially\nmass-produced products has historically relied on manual inspection, which is\ncostly and error-prone. Machine learning has the potential to replace manual\nhandling. As such, the desire is to facilitate an unsupervised (or\nself-supervised) approach, as it is often impossible to specify all conceivable\ndefects ahead of time. A plethora of prior works have demonstrated the aptitude\nof common reconstruction-, embedding-, and synthesis-based methods in\nlaboratory settings. However, in practice, we observe that most methods do not\nhandle low data quality well or exude low robustness in unfavorable, but\ntypical real-world settings. For practitioners it may be very difficult to\nidentify the actual underlying problem when such methods underperform. Worse,\noften-reported metrics (e.g., AUROC) are rarely suitable in practice and may\ngive misleading results. In our setting, we attempt to identify subtle\nanomalies on the surface of blasted forged metal parts, using rather\nlow-quality RGB imagery only, which is a common industrial setting. We\nspecifically evaluate two types of state-of-the-art models that allow us to\nidentify and improve quality issues in production data, without having to\nobtain new data. Our contribution is to provide guardrails for practitioners\nthat allow them to identify problems related to, e.g., (lack of) robustness or\ninvariance, in either the chosen model or the data reliably in similar\nscenarios. Furthermore, we exemplify common pitfalls in and shortcomings of\nlikelihood-based approaches and outline a framework for proper empirical risk\nestimation that is more suitable for real-world scenarios.", "published": "2025-06-20 10:28:00", "link": "http://arxiv.org/abs/2506.16890v1", "categories": ["cs.LG", "cs.CV", "stat.AP", "62-06", "G.3; I.4; I.5"], "primary_category": "cs.LG"}
{"title": "ParkFormer: A Transformer-Based Parking Policy with Goal Embedding and Pedestrian-Aware Control", "abstract": "Autonomous parking plays a vital role in intelligent vehicle systems,\nparticularly in constrained urban environments where high-precision control is\nrequired. While traditional rule-based parking systems struggle with\nenvironmental uncertainties and lack adaptability in crowded or dynamic scenes,\nhuman drivers demonstrate the ability to park intuitively without explicit\nmodeling. Inspired by this observation, we propose a Transformer-based\nend-to-end framework for autonomous parking that learns from expert\ndemonstrations. The network takes as input surround-view camera images,\ngoal-point representations, ego vehicle motion, and pedestrian trajectories. It\noutputs discrete control sequences including throttle, braking, steering, and\ngear selection. A novel cross-attention module integrates BEV features with\ntarget points, and a GRU-based pedestrian predictor enhances safety by modeling\ndynamic obstacles. We validate our method on the CARLA 0.9.14 simulator in both\nvertical and parallel parking scenarios. Experiments show our model achieves a\nhigh success rate of 96.57\\%, with average positional and orientation errors of\n0.21 meters and 0.41 degrees, respectively. The ablation studies further\ndemonstrate the effectiveness of key modules such as pedestrian prediction and\ngoal-point attention fusion. The code and dataset will be released at:\nhttps://github.com/little-snail-f/ParkFormer.", "published": "2025-06-20 09:14:09", "link": "http://arxiv.org/abs/2506.16856v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Controllable and Expressive One-Shot Video Head Swapping", "abstract": "In this paper, we propose a novel diffusion-based multi-condition\ncontrollable framework for video head swapping, which seamlessly transplant a\nhuman head from a static image into a dynamic video, while preserving the\noriginal body and background of target video, and further allowing to tweak\nhead expressions and movements during swapping as needed. Existing\nface-swapping methods mainly focus on localized facial replacement neglecting\nholistic head morphology, while head-swapping approaches struggling with\nhairstyle diversity and complex backgrounds, and none of these methods allow\nusers to modify the transplanted head expressions after swapping. To tackle\nthese challenges, our method incorporates several innovative strategies through\na unified latent diffusion paradigm. 1) Identity-preserving context fusion: We\npropose a shape-agnostic mask strategy to explicitly disentangle foreground\nhead identity features from background/body contexts, combining hair\nenhancement strategy to achieve robust holistic head identity preservation\nacross diverse hair types and complex backgrounds. 2) Expression-aware landmark\nretargeting and editing: We propose a disentangled 3DMM-driven retargeting\nmodule that decouples identity, expression, and head poses, minimizing the\nimpact of original expressions in input images and supporting expression\nediting. While a scale-aware retargeting strategy is further employed to\nminimize cross-identity expression distortion for higher transfer precision.\nExperimental results demonstrate that our method excels in seamless background\nintegration while preserving the identity of the source portrait, as well as\nshowcasing superior expression transfer capabilities applicable to both real\nand virtual characters.", "published": "2025-06-20 09:01:17", "link": "http://arxiv.org/abs/2506.16852v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Camera Calibration via Circular Patterns: A Comprehensive Framework with Measurement Uncertainty and Unbiased Projection Model", "abstract": "Camera calibration using planar targets has been widely favored, and two\ntypes of control points have been mainly considered as measurements: the\ncorners of the checkerboard and the centroid of circles. Since a centroid is\nderived from numerous pixels, the circular pattern provides more precise\nmeasurements than the checkerboard. However, the existing projection model of\ncircle centroids is biased under lens distortion, resulting in low performance.\nTo surmount this limitation, we propose an unbiased projection model of the\ncircular pattern and demonstrate its superior accuracy compared to the\ncheckerboard. Complementing this, we introduce uncertainty into circular\npatterns to enhance calibration robustness and completeness. Defining centroid\nuncertainty improves the performance of calibration components, including\npattern detection, optimization, and evaluation metrics. We also provide\nguidelines for performing good camera calibration based on the evaluation\nmetric. The core concept of this approach is to model the boundary points of a\ntwo-dimensional shape as a Markov random field, considering its connectivity.\nThe shape distribution is propagated to the centroid uncertainty through an\nappropriate shape representation based on the Green theorem. Consequently, the\nresulting framework achieves marked gains in calibration accuracy and\nrobustness. The complete source code and demonstration video are available at\nhttps://github.com/chaehyeonsong/discocal.", "published": "2025-06-20 08:46:48", "link": "http://arxiv.org/abs/2506.16842v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Beyond Blur: A Fluid Perspective on Generative Diffusion Models", "abstract": "We propose a novel PDE-driven corruption process for generative image\nsynthesis based on advection-diffusion processes which generalizes existing\nPDE-based approaches. Our forward pass formulates image corruption via a\nphysically motivated PDE that couples directional advection with isotropic\ndiffusion and Gaussian noise, controlled by dimensionless numbers (Peclet,\nFourier). We implement this PDE numerically through a GPU-accelerated custom\nLattice Boltzmann solver for fast evaluation. To induce realistic turbulence,\nwe generate stochastic velocity fields that introduce coherent motion and\ncapture multi-scale mixing. In the generative process, a neural network learns\nto reverse the advection-diffusion operator thus constituting a novel\ngenerative model. We discuss how previous methods emerge as specific cases of\nour operator, demonstrating that our framework generalizes prior PDE-based\ncorruption techniques. We illustrate how advection improves the diversity and\nquality of the generated images while keeping the overall color palette\nunaffected. This work bridges fluid dynamics, dimensionless PDE theory, and\ndeep generative modeling, offering a fresh perspective on physically informed\nimage corruption processes for diffusion-based synthesis.", "published": "2025-06-20 08:31:30", "link": "http://arxiv.org/abs/2506.16827v1", "categories": ["cs.GR", "cs.CV", "cs.LG", "I.2.6; I.4.10; I.4.8"], "primary_category": "cs.GR"}
{"title": "AnyTraverse: An off-road traversability framework with VLM and human operator in the loop", "abstract": "Off-road traversability segmentation enables autonomous navigation with\napplications in search-and-rescue, military operations, wildlife exploration,\nand agriculture. Current frameworks struggle due to significant variations in\nunstructured environments and uncertain scene changes, and are not adaptive to\nbe used for different robot types. We present AnyTraverse, a framework\ncombining natural language-based prompts with human-operator assistance to\ndetermine navigable regions for diverse robotic vehicles. The system segments\nscenes for a given set of prompts and calls the operator only when encountering\npreviously unexplored scenery or unknown class not part of the prompt in its\nregion-of-interest, thus reducing active supervision load while adapting to\nvarying outdoor scenes. Our zero-shot learning approach eliminates the need for\nextensive data collection or retraining. Our experimental validation includes\ntesting on RELLIS-3D, Freiburg Forest, and RUGD datasets and demonstrate\nreal-world deployment on multiple robot platforms. The results show that\nAnyTraverse performs better than GA-NAV and Off-seg while offering a\nvehicle-agnostic approach to off-road traversability that balances automation\nwith targeted human supervision.", "published": "2025-06-20 08:31:13", "link": "http://arxiv.org/abs/2506.16826v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Self-supervised Feature Extraction for Enhanced Ball Detection on Soccer Robots", "abstract": "Robust and accurate ball detection is a critical component for autonomous\nhumanoid soccer robots, particularly in dynamic and challenging environments\nsuch as RoboCup outdoor fields. However, traditional supervised approaches\nrequire extensive manual annotation, which is costly and time-intensive. To\novercome this problem, we present a self-supervised learning framework for\ndomain-adaptive feature extraction to enhance ball detection performance. The\nproposed approach leverages a general-purpose pretrained model to generate\npseudo-labels, which are then used in a suite of self-supervised pretext tasks\n-- including colorization, edge detection, and triplet loss -- to learn robust\nvisual features without relying on manual annotations. Additionally, a\nmodel-agnostic meta-learning (MAML) strategy is incorporated to ensure rapid\nadaptation to new deployment scenarios with minimal supervision. A new dataset\ncomprising 10,000 labeled images from outdoor RoboCup SPL matches is\nintroduced, used to validate the method, and made available to the community.\nExperimental results demonstrate that the proposed pipeline outperforms\nbaseline models in terms of accuracy, F1 score, and IoU, while also exhibiting\nfaster convergence.", "published": "2025-06-20 08:21:34", "link": "http://arxiv.org/abs/2506.16821v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Loupe: A Generalizable and Adaptive Framework for Image Forgery Detection", "abstract": "The proliferation of generative models has raised serious concerns about\nvisual content forgery. Existing deepfake detection methods primarily target\neither image-level classification or pixel-wise localization. While some\nachieve high accuracy, they often suffer from limited generalization across\nmanipulation types or rely on complex architectures. In this paper, we propose\nLoupe, a lightweight yet effective framework for joint deepfake detection and\nlocalization. Loupe integrates a patch-aware classifier and a segmentation\nmodule with conditional queries, allowing simultaneous global authenticity\nclassification and fine-grained mask prediction. To enhance robustness against\ndistribution shifts of test set, Loupe introduces a pseudo-label-guided\ntest-time adaptation mechanism by leveraging patch-level predictions to\nsupervise the segmentation head. Extensive experiments on the DDL dataset\ndemonstrate that Loupe achieves state-of-the-art performance, securing the\nfirst place in the IJCAI 2025 Deepfake Detection and Localization Challenge\nwith an overall score of 0.846. Our results validate the effectiveness of the\nproposed patch-level fusion and conditional query design in improving both\nclassification accuracy and spatial localization under diverse forgery\npatterns. The code is available at https://github.com/Kamichanw/Loupe.", "published": "2025-06-20 08:18:44", "link": "http://arxiv.org/abs/2506.16819v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation", "abstract": "Recent Large Vision Language Models (LVLMs) demonstrate promising\ncapabilities in unifying visual understanding and generative modeling, enabling\nboth accurate content understanding and flexible editing. However, current\napproaches treat \"what to see\" and \"how to edit\" separately: they either\nperform isolated object segmentation or utilize segmentation masks merely as\nconditional prompts for local edit generation tasks, often relying on multiple\ndisjointed models. To bridge these gaps, we introduce FOCUS, a unified LVLM\nthat integrates segmentation-aware perception and controllable object-centric\ngeneration within an end-to-end framework. FOCUS employs a dual-branch visual\nencoder to simultaneously capture global semantic context and fine-grained\nspatial details. In addition, we leverage a MoVQGAN-based visual tokenizer to\nproduce discrete visual tokens that enhance generation quality. To enable\naccurate and controllable image editing, we propose a progressive multi-stage\ntraining pipeline, where segmentation masks are jointly optimized and used as\nspatial condition prompts to guide the diffusion decoder. This strategy aligns\nvisual encoding, segmentation, and generation modules, effectively bridging\nsegmentation-aware perception with fine-grained visual synthesis. Extensive\nexperiments across three core tasks, including multimodal understanding,\nreferring segmentation accuracy, and controllable image generation, demonstrate\nthat FOCUS achieves strong performance by jointly optimizing visual perception\nand generative capabilities.", "published": "2025-06-20 07:46:40", "link": "http://arxiv.org/abs/2506.16806v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes", "abstract": "Humans exhibit a remarkable ability to recognize co-visibility-the\noverlapping regions visible in multiple images-even when these images are\nsparsely distributed across a complex scene. This capability is foundational in\n3D vision and robotic perception. Despite significant progress in vision\nlearning, it remains unclear whether current vision models have reached\nhuman-level proficiency in co-visibility analysis. In this work, we introduce\nthe Co-Visibility reasONing (Co-VisiON) benchmark, designed to directly\nevaluate co-visibility reasoning on sparse image sets across over 1000 indoor\nscenarios. Our experiments reveal that while co-visibility is typically treated\nas a low-level feature matching task, it poses a significant challenge for\nexisting vision models under sparse conditions. Notably, a proprietary\nvision-language model outperforms all purely vision-based approaches, with all\nmodels lagging substantially behind human performance. This gap underscores the\nneed for more than basic pairwise vision processing-it calls for a\ncomprehensive spatial understanding through high-level reasoning across\nmultiple views. Inspired by human visual cognition, we propose a novel\nmulti-view baseline, Covis, which achieves top performance among pure vision\nmodels and narrows the gap to the proprietary VLM. We hope our benchmark and\nfindings will spur further advancements in developing vision models capable of\nrobust, high-level reasoning in challenging, sparse environments. Our dataset\nand source code can be found at: https://ai4ce.github.io/CoVISION", "published": "2025-06-20 07:42:26", "link": "http://arxiv.org/abs/2506.16805v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Temperature calibration of surface emissivities with an improved thermal image enhancement network", "abstract": "Infrared thermography faces persistent challenges in temperature accuracy due\nto material emissivity variations, where existing methods often neglect the\njoint optimization of radiometric calibration and image degradation. This study\nintroduces a physically guided neural framework that unifies temperature\ncorrection and image enhancement through a symmetric skip-CNN architecture and\nan emissivity-aware attention module. The pre-processing stage segments the\nROIs of the image and and initially corrected the firing rate. A novel\ndual-constrained loss function strengthens the statistical consistency between\nthe target and reference regions through mean-variance alignment and histogram\nmatching based on Kullback-Leibler dispersion. The method works by dynamically\nfusing thermal radiation features and spatial context, and the model suppresses\nemissivity artifacts while recovering structural details. After validating the\nindustrial blower system under different conditions, the improved network\nrealizes the dynamic fusion of thermal radiation characteristics and spatial\nbackground, with accurate calibration results in various industrial conditions.", "published": "2025-06-20 07:40:05", "link": "http://arxiv.org/abs/2506.16803v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Seeing What Matters: Generalizable AI-generated Video Detection with Forensic-Oriented Augmentation", "abstract": "Synthetic video generation is progressing very rapidly. The latest models can\nproduce very realistic high-resolution videos that are virtually\nindistinguishable from real ones. Although several video forensic detectors\nhave been recently proposed, they often exhibit poor generalization, which\nlimits their applicability in a real-world scenario. Our key insight to\novercome this issue is to guide the detector towards seeing what really\nmatters. In fact, a well-designed forensic classifier should focus on\nidentifying intrinsic low-level artifacts introduced by a generative\narchitecture rather than relying on high-level semantic flaws that characterize\na specific model. In this work, first, we study different generative\narchitectures, searching and identifying discriminative features that are\nunbiased, robust to impairments, and shared across models. Then, we introduce a\nnovel forensic-oriented data augmentation strategy based on the wavelet\ndecomposition and replace specific frequency-related bands to drive the model\nto exploit more relevant forensic cues. Our novel training paradigm improves\nthe generalizability of AI-generated video detectors, without the need for\ncomplex algorithms and large datasets that include multiple synthetic\ngenerators. To evaluate our approach, we train the detector using data from a\nsingle generative model and test it against videos produced by a wide range of\nother models. Despite its simplicity, our method achieves a significant\naccuracy improvement over state-of-the-art detectors and obtains excellent\nresults even on very recent generative models, such as NOVA and FLUX. Code and\ndata will be made publicly available.", "published": "2025-06-20 07:36:59", "link": "http://arxiv.org/abs/2506.16802v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought", "abstract": "Real-World Image Super-Resolution is one of the most challenging task in\nimage restoration. However, existing methods struggle with an accurate\nunderstanding of degraded image content, leading to reconstructed results that\nare both low-fidelity and unnatural. We present RealSR-R1 in this work, which\nempowers the RealSR models with understanding and reasoning capabilities.\nInspired by the success of Chain of Thought (CoT) in large language models\n(LLMs), we simulate the human process of handling degraded images and propose\nthe VLCoT framework, which integrates vision and language reasoning. The\nframework aims to precisely restore image details by progressively generating\nmore comprehensive text and higher-resolution images. To overcome the challenge\nof traditional supervised learning CoT failing to generalize to real-world\nscenarios, we introduce, for the first time, Group Relative Policy Optimization\n(GRPO) into the Real-World Image Super-Resolution task. We propose VLCoT-GRPO\nas a solution, which designs four reward functions: (1) Format reward, used to\nstandardize the CoT process; (2) Degradation reward, to incentivize accurate\ndegradation estimation; (3) Understanding reward, to ensure the accuracy of the\ngenerated content; and (4) Generation reward, where we propose using a visual\nexpert model to evaluate the quality of generated images, encouraging the model\nto generate more realistic images. Extensive experiments demonstrate that our\nproposed RealSR-R1 can generate realistic details and accurately understand\nimage content, particularly in semantically rich scenes or images with severe\ndegradation.", "published": "2025-06-20 07:21:21", "link": "http://arxiv.org/abs/2506.16796v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TextBraTS: Text-Guided Volumetric Brain Tumor Segmentation with Innovative Dataset Development and Fusion Module Exploration", "abstract": "Deep learning has demonstrated remarkable success in medical image\nsegmentation and computer-aided diagnosis. In particular, numerous advanced\nmethods have achieved state-of-the-art performance in brain tumor segmentation\nfrom MRI scans. While recent studies in other medical imaging domains have\nrevealed that integrating textual reports with visual data can enhance\nsegmentation accuracy, the field of brain tumor analysis lacks a comprehensive\ndataset that combines radiological images with corresponding textual\nannotations. This limitation has hindered the exploration of multimodal\napproaches that leverage both imaging and textual data.\n  To bridge this critical gap, we introduce the TextBraTS dataset, the first\npublicly available volume-level multimodal dataset that contains paired MRI\nvolumes and rich textual annotations, derived from the widely adopted BraTS2020\nbenchmark. Building upon this novel dataset, we propose a novel baseline\nframework and sequential cross-attention method for text-guided volumetric\nmedical image segmentation. Through extensive experiments with various\ntext-image fusion strategies and templated text formulations, our approach\ndemonstrates significant improvements in brain tumor segmentation accuracy,\noffering valuable insights into effective multimodal integration techniques.\n  Our dataset, implementation code, and pre-trained models are publicly\navailable at https://github.com/Jupitern52/TextBraTS.", "published": "2025-06-20 06:57:56", "link": "http://arxiv.org/abs/2506.16784v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "PQCAD-DM: Progressive Quantization and Calibration-Assisted Distillation for Extremely Efficient Diffusion Model", "abstract": "Diffusion models excel in image generation but are computational and\nresource-intensive due to their reliance on iterative Markov chain processes,\nleading to error accumulation and limiting the effectiveness of naive\ncompression techniques. In this paper, we propose PQCAD-DM, a novel hybrid\ncompression framework combining Progressive Quantization (PQ) and\nCalibration-Assisted Distillation (CAD) to address these challenges. PQ employs\na two-stage quantization with adaptive bit-width transitions guided by a\nmomentum-based mechanism, reducing excessive weight perturbations in\nlow-precision. CAD leverages full-precision calibration datasets during\ndistillation, enabling the student to match full-precision performance even\nwith a quantized teacher. As a result, PQCAD-DM achieves a balance between\ncomputational efficiency and generative quality, halving inference time while\nmaintaining competitive performance. Extensive experiments validate PQCAD-DM's\nsuperior generative capabilities and efficiency across diverse datasets,\noutperforming fixed-bit quantization methods.", "published": "2025-06-20 06:43:27", "link": "http://arxiv.org/abs/2506.16776v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Infrared and Visible Image Fusion Based on Implicit Neural Representations", "abstract": "Infrared and visible light image fusion aims to combine the strengths of both\nmodalities to generate images that are rich in information and fulfill visual\nor computational requirements. This paper proposes an image fusion method based\non Implicit Neural Representations (INR), referred to as INRFuse. This method\nparameterizes a continuous function through a neural network to implicitly\nrepresent the multimodal information of the image, breaking through the\ntraditional reliance on discrete pixels or explicit features. The normalized\nspatial coordinates of the infrared and visible light images serve as inputs,\nand multi-layer perceptrons is utilized to adaptively fuse the features of both\nmodalities, resulting in the output of the fused image. By designing multiple\nloss functions, the method jointly optimizes the similarity between the fused\nimage and the original images, effectively preserving the thermal radiation\ninformation of the infrared image while maintaining the texture details of the\nvisible light image. Furthermore, the resolution-independent characteristic of\nINR allows for the direct fusion of images with varying resolutions and\nachieves super-resolution reconstruction through high-density coordinate\nqueries. Experimental results indicate that INRFuse outperforms existing\nmethods in both subjective visual quality and objective evaluation metrics,\nproducing fused images with clear structures, natural details, and rich\ninformation without the necessity for a training dataset.", "published": "2025-06-20 06:34:19", "link": "http://arxiv.org/abs/2506.16773v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models", "abstract": "Large Vision-Language Models (LVLMs) demonstrate exceptional performance\nacross multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass\nbuilt-in safety mechanisms to elicit restricted content generation. Existing\nblack-box jailbreak methods primarily rely on adversarial textual prompts or\nimage perturbations, yet these approaches are highly detectable by standard\ncontent filtering systems and exhibit low query and computational efficiency.\nIn this work, we present Cross-modal Adversarial Multimodal Obfuscation (CAMO),\na novel black-box jailbreak attack framework that decomposes malicious prompts\ninto semantically benign visual and textual fragments. By leveraging LVLMs'\ncross-modal reasoning abilities, CAMO covertly reconstructs harmful\ninstructions through multi-step reasoning, evading conventional detection\nmechanisms. Our approach supports adjustable reasoning complexity and requires\nsignificantly fewer queries than prior attacks, enabling both stealth and\nefficiency. Comprehensive evaluations conducted on leading LVLMs validate\nCAMO's effectiveness, showcasing robust performance and strong cross-model\ntransferability. These results underscore significant vulnerabilities in\ncurrent built-in safety mechanisms, emphasizing an urgent need for advanced,\nalignment-aware security and safety solutions in vision-language systems.", "published": "2025-06-20 05:30:25", "link": "http://arxiv.org/abs/2506.16760v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Class Agnostic Instance-level Descriptor for Visual Instance Search", "abstract": "Despite the great success of the deep features in content-based image\nretrieval, the visual instance search remains challenging due to the lack of\neffective instance level feature representation. Supervised or weakly\nsupervised object detection methods are not among the options due to their poor\nperformance on the unknown object categories. In this paper, based on the\nfeature set output from self-supervised ViT, the instance level region\ndiscovery is modeled as detecting the compact feature subsets in a hierarchical\nfashion. The hierarchical decomposition results in a hierarchy of feature\nsubsets. The non-leaf nodes and leaf nodes on the hierarchy correspond to the\nvarious instance regions in an image of different semantic scales. The\nhierarchical decomposition well addresses the problem of object embedding and\nocclusions, which are widely observed in the real scenarios. The features\nderived from the nodes on the hierarchy make up a comprehensive representation\nfor the latent instances in the image. Our instance-level descriptor remains\neffective on both the known and unknown object categories. Empirical studies on\nthree instance search benchmarks show that it outperforms state-of-the-art\nmethods considerably.", "published": "2025-06-20 04:32:39", "link": "http://arxiv.org/abs/2506.16745v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Noise-Informed Diffusion-Generated Image Detection with Anomaly Attention", "abstract": "With the rapid development of image generation technologies, especially the\nadvancement of Diffusion Models, the quality of synthesized images has\nsignificantly improved, raising concerns among researchers about information\nsecurity. To mitigate the malicious abuse of diffusion models,\ndiffusion-generated image detection has proven to be an effective\ncountermeasure.However, a key challenge for forgery detection is generalising\nto diffusion models not seen during training. In this paper, we address this\nproblem by focusing on image noise. We observe that images from different\ndiffusion models share similar noise patterns, distinct from genuine images.\nBuilding upon this insight, we introduce a novel Noise-Aware Self-Attention\n(NASA) module that focuses on noise regions to capture anomalous patterns. To\nimplement a SOTA detection model, we incorporate NASA into Swin Transformer,\nforming an novel detection architecture NASA-Swin. Additionally, we employ a\ncross-modality fusion embedding to combine RGB and noise images, along with a\nchannel mask strategy to enhance feature learning from both modalities.\nExtensive experiments demonstrate the effectiveness of our approach in\nenhancing detection capabilities for diffusion-generated images. When\nencountering unseen generation methods, our approach achieves the\nstate-of-the-art performance.Our code is available at\nhttps://github.com/WeinanGuan/NASA-Swin.", "published": "2025-06-20 04:25:59", "link": "http://arxiv.org/abs/2506.16743v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Uncertainty-Aware Variational Information Pursuit for Interpretable Medical Image Analysis", "abstract": "In medical imaging, AI decision-support systems must balance accuracy and\ninterpretability to build user trust and support effective clinical\ndecision-making. Recently, Variational Information Pursuit (V-IP) and its\nvariants have emerged as interpretable-by-design modeling techniques, aiming to\nexplain AI decisions in terms of human-understandable, clinically relevant\nconcepts. However, existing V-IP methods overlook instance-level uncertainties\nin query-answer generation, which can arise from model limitations (epistemic\nuncertainty) or variability in expert responses (aleatoric uncertainty).\n  This paper introduces Uncertainty-Aware V-IP (UAV-IP), a novel framework that\nintegrates uncertainty quantification into the V-IP process. We evaluate UAV-IP\nacross four medical imaging datasets, PH2, Derm7pt, BrEaST, and SkinCon,\ndemonstrating an average AUC improvement of approximately 3.2% while generating\n20% more concise explanations compared to baseline V-IP, without sacrificing\ninformativeness. These findings highlight the importance of uncertainty-aware\nreasoning in interpretable by design models for robust and reliable medical\ndecision-making.", "published": "2025-06-20 04:25:47", "link": "http://arxiv.org/abs/2506.16742v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cross-modal Offset-guided Dynamic Alignment and Fusion for Weakly Aligned UAV Object Detection", "abstract": "Unmanned aerial vehicle (UAV) object detection plays a vital role in\napplications such as environmental monitoring and urban security. To improve\nrobustness, recent studies have explored multimodal detection by fusing visible\n(RGB) and infrared (IR) imagery. However, due to UAV platform motion and\nasynchronous imaging, spatial misalignment frequently occurs between\nmodalities, leading to weak alignment. This introduces two major challenges:\nsemantic inconsistency at corresponding spatial locations and modality conflict\nduring feature fusion. Existing methods often address these issues in\nisolation, limiting their effectiveness. In this paper, we propose Cross-modal\nOffset-guided Dynamic Alignment and Fusion (CoDAF), a unified framework that\njointly tackles both challenges in weakly aligned UAV-based object detection.\nCoDAF comprises two novel modules: the Offset-guided Semantic Alignment (OSA),\nwhich estimates attention-based spatial offsets and uses deformable convolution\nguided by a shared semantic space to align features more precisely; and the\nDynamic Attention-guided Fusion Module (DAFM), which adaptively balances\nmodality contributions through gating and refines fused features via\nspatial-channel dual attention. By integrating alignment and fusion in a\nunified design, CoDAF enables robust UAV object detection. Experiments on\nstandard benchmarks validate the effectiveness of our approach, with CoDAF\nachieving a mAP of 78.6% on the DroneVehicle dataset.", "published": "2025-06-20 04:11:39", "link": "http://arxiv.org/abs/2506.16737v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3DeepRep: 3D Deep Low-rank Tensor Representation for Hyperspectral Image Inpainting", "abstract": "Recent approaches based on transform-based tensor nuclear norm (TNN) have\ndemonstrated notable effectiveness in hyperspectral image (HSI) inpainting by\nleveraging low-rank structures in latent representations. Recent developments\nincorporate deep transforms to improve low-rank tensor representation; however,\nexisting approaches typically restrict the transform to the spectral mode,\nneglecting low-rank properties along other tensor modes. In this paper, we\npropose a novel 3-directional deep low-rank tensor representation (3DeepRep)\nmodel, which performs deep nonlinear transforms along all three modes of the\nHSI tensor. To enforce low-rankness, the model minimizes the nuclear norms of\nmode-i frontal slices in the corresponding latent space for each direction\n(i=1,2,3), forming a 3-directional TNN regularization. The outputs from the\nthree directional branches are subsequently fused via a learnable aggregation\nmodule to produce the final result. An efficient gradient-based optimization\nalgorithm is developed to solve the model in a self-supervised manner.\nExtensive experiments on real-world HSI datasets demonstrate that the proposed\nmethod achieves superior inpainting performance compared to existing\nstate-of-the-art techniques, both qualitatively and quantitatively.", "published": "2025-06-20 04:09:34", "link": "http://arxiv.org/abs/2506.16735v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "A Prior-Guided Joint Diffusion Model in Projection Domain for PET Tracer Conversion", "abstract": "Positron emission tomography (PET) is widely used to assess metabolic\nactivity, but its application is limited by the availability of radiotracers.\n18F-labeled fluorodeoxyglucose (18F-FDG) is the most commonly used tracer but\nshows limited effectiveness for certain tumors. In contrast,\n6-18F-fluoro-3,4-dihydroxy-L-phenylalanine (18F-DOPA) offers higher specificity\nfor neuroendocrine tumors and neurological disorders. However, its complex\nsynthesis and limitations in transportation and clinical use hinder widespread\nadoption. During PET imaging, the sinogram represents a form of raw data\nacquired by the scanner. Therefore, modeling in projection domain enables more\ndirect utilization of the original information, potentially reducing the\naccumulation of errors introduced during the image reconstruction process.\nInspired by these factors, this study proposes a prior-guided joint diffusion\nmodel (PJDM) for transforming 18F-FDG PET images into 18F-DOPA PET images in\nprojection domain. Specifically, a coarse estimation model and a prior\nrefinement model are trained independently. During inference, an initial\nsynthetic 18F-DOPA PET sinogram is generated using a higher-order hybrid\nsampler. This sinogram is then degraded and serves as an additional condition\nto guide the iterative refinement process using learned prior. Experimental\nresults demonstrated that PJDM effectively improved both sinogram quality and\nsynthetic outcomes. The code is available at: https://github.com/yqx7150/PJDM.", "published": "2025-06-20 04:05:34", "link": "http://arxiv.org/abs/2506.16733v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "TeSG: Textual Semantic Guidance for Infrared and Visible Image Fusion", "abstract": "Infrared and visible image fusion (IVF) aims to combine complementary\ninformation from both image modalities, producing more informative and\ncomprehensive outputs. Recently, text-guided IVF has shown great potential due\nto its flexibility and versatility. However, the effective integration and\nutilization of textual semantic information remains insufficiently studied. To\ntackle these challenges, we introduce textual semantics at two levels: the mask\nsemantic level and the text semantic level, both derived from textual\ndescriptions extracted by large Vision-Language Models (VLMs). Building on\nthis, we propose Textual Semantic Guidance for infrared and visible image\nfusion, termed TeSG, which guides the image synthesis process in a way that is\noptimized for downstream tasks such as detection and segmentation.\nSpecifically, TeSG consists of three core components: a Semantic Information\nGenerator (SIG), a Mask-Guided Cross-Attention (MGCA) module, and a Text-Driven\nAttentional Fusion (TDAF) module. The SIG generates mask and text semantics\nbased on textual descriptions. The MGCA module performs initial attention-based\nfusion of visual features from both infrared and visible images, guided by mask\nsemantics. Finally, the TDAF module refines the fusion process with gated\nattention driven by text semantics. Extensive experiments demonstrate the\ncompetitiveness of our approach, particularly in terms of performance on\ndownstream tasks, compared to existing state-of-the-art methods.", "published": "2025-06-20 03:53:07", "link": "http://arxiv.org/abs/2506.16730v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Few-Shot Generalized Category Discovery With Retrieval-Guided Decision Boundary Enhancement", "abstract": "While existing Generalized Category Discovery (GCD) models have achieved\nsignificant success, their performance with limited labeled samples and a small\nnumber of known categories remains largely unexplored. In this work, we\nintroduce the task of Few-shot Generalized Category Discovery (FSGCD), aiming\nto achieve competitive performance in GCD tasks under conditions of known\ninformation scarcity. To tackle this challenge, we propose a decision boundary\nenhancement framework with affinity-based retrieval. Our framework is designed\nto learn the decision boundaries of known categories and transfer these\nboundaries to unknown categories. First, we use a decision boundary\npre-training module to mitigate the overfitting of pre-trained information on\nknown category boundaries and improve the learning of these decision boundaries\nusing labeled samples. Second, we implement a two-stage retrieval-guided\ndecision boundary optimization strategy. Specifically, this strategy further\nenhances the severely limited known boundaries by using affinity-retrieved\npseudo-labeled samples. Then, these refined boundaries are applied to unknown\nclusters via guidance from affinity-based feature retrieval. Experimental\nresults demonstrate that our proposed method outperforms existing methods on\nsix public GCD benchmarks under the FSGCD setting. The codes are available at:\nhttps://github.com/Ryh1218/FSGCD", "published": "2025-06-20 03:52:36", "link": "http://arxiv.org/abs/2506.16728v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Language-driven Description Generation and Common Sense Reasoning for Video Action Recognition", "abstract": "Recent video action recognition methods have shown excellent performance by\nadapting large-scale pre-trained language-image models to the video domain.\nHowever, language models contain rich common sense priors - the scene contexts\nthat humans use to constitute an understanding of objects, human-object\ninteractions, and activities - that have not been fully exploited. In this\npaper, we introduce a framework incorporating language-driven common sense\npriors to identify cluttered video action sequences from monocular views that\nare often heavily occluded. We propose: (1) A video context summary component\nthat generates candidate objects, activities, and the interactions between\nobjects and activities; (2) A description generation module that describes the\ncurrent scene given the context and infers subsequent activities, through\nauxiliary prompts and common sense reasoning; (3) A multi-modal activity\nrecognition head that combines visual and textual cues to recognize video\nactions. We demonstrate the effectiveness of our approach on the challenging\nAction Genome and Charades datasets.", "published": "2025-06-20 02:43:53", "link": "http://arxiv.org/abs/2506.16701v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LaVi: Efficient Large Vision-Language Models via Internal Feature Modulation", "abstract": "Despite the impressive advancements of Large Vision-Language Models (LVLMs),\nexisting approaches suffer from a fundamental bottleneck: inefficient\nvisual-language integration. Current methods either disrupt the model's\ninherent structure or introduce severe long-context computational burden,\nseverely limiting scalability and efficiency. In this paper, we rethink\nmultimodal integration and present LaVi, a novel LVLM that enables seamless and\nefficient vision-language fusion through internal feature modulation within the\nLarge Language Models (LLMs). Unlike dominant LVLMs that rely on visual token\nconcatenation, LaVi bypasses long-context expansion by introducing a\nlightweight and adaptive transformation, which incorporates visual context by\ninjecting token-wise vision-conditioned deltas into the affine parameters of\nlayer normalization. This mechanism directly modulates linguistic hidden states\nbased on visual input, ensuring precise vision-language alignment while\npreserving the LLM's linguistic priors and drastically reducing computational\ncosts. Extensive evaluations across 15 image and video benchmarks demonstrate\nthat LaVi not only achieves state-of-the-art multimodal performance but also\ndramatically enhances efficiency. Compared to LLaVA-OV-7B, LaVi reduces FLOPs\nby 94.0%, improves inference speed by 3.1 times, and cuts memory usage in half\n- establishing LaVi as a scalable and practical solution for real-time\nmultimodal reasoning. The code and models will be released soon.", "published": "2025-06-20 02:25:33", "link": "http://arxiv.org/abs/2506.16691v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DepthVanish: Optimizing Adversarial Interval Structures for Stereo-Depth-Invisible Patches", "abstract": "Stereo Depth estimation is a critical task in autonomous driving and\nrobotics, where inaccuracies (such as misidentifying nearby objects as distant)\ncan lead to dangerous situations. Adversarial attacks against stereo depth\nestimation can help reveal vulnerabilities before deployment. Previous work has\nshown that repeating optimized textures can effectively mislead stereo depth\nestimation in digital settings. However, our research reveals that these\nnaively repeated texture structures perform poorly in physical-world\nimplementations, i.e., when deployed as patches, limiting their practical\nutility for testing stereo depth estimation systems. In this work, for the\nfirst time, we discover that introducing regular intervals between repeated\ntextures, creating a striped structure, significantly enhances the patch attack\neffectiveness. Through extensive experimentation, we analyze how variations of\nthis novel structure influence the performance. Based on these insights, we\ndevelop a novel stereo depth attack that jointly optimizes both the striped\nstructure and texture elements. Our generated adversarial patches can be\ninserted into any scenes and successfully attack state-of-the-art stereo depth\nestimation methods, i.e., RAFT-Stereo and STTR. Most critically, our patch can\nalso attack commercial RGB-D cameras (Intel RealSense) in real-world\nconditions, demonstrating their practical relevance for security assessment of\nstereo systems.", "published": "2025-06-20 02:22:21", "link": "http://arxiv.org/abs/2506.16690v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "How to Train your Text-to-Image Model: Evaluating Design Choices for Synthetic Training Captions", "abstract": "Training data is at the core of any successful text-to-image models. The\nquality and descriptiveness of image text are crucial to a model's performance.\nGiven the noisiness and inconsistency in web-scraped datasets, recent works\nshifted towards synthetic training captions. While this setup is generally\nbelieved to produce more capable models, current literature does not provide\nany insights into its design choices. This study closes this gap by\nsystematically investigating how different synthetic captioning strategies\nimpact the downstream performance of text-to-image models. Our experiments\ndemonstrate that dense, high-quality captions enhance text alignment but may\nintroduce trade-offs in output aesthetics and diversity. Conversely, captions\nof randomized lengths yield balanced improvements across aesthetics and\nalignment without compromising sample diversity. We also demonstrate that\nvarying caption distributions introduce significant shifts in the output bias\nof a trained model. Our findings underscore the importance of caption design in\nachieving optimal model performance and provide practical insights for more\neffective training data strategies in text-to-image generation.", "published": "2025-06-20 01:52:17", "link": "http://arxiv.org/abs/2506.16679v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Extracting Multimodal Learngene in CLIP: Unveiling the Multimodal Generalizable Knowledge", "abstract": "CLIP (Contrastive Language-Image Pre-training) has attracted widespread\nattention for its multimodal generalizable knowledge, which is significant for\ndownstream tasks. However, the computational overhead of a large number of\nparameters and large-scale pre-training poses challenges of pre-training a\ndifferent scale of CLIP. Learngene extracts the generalizable components termed\nas learngene from an ancestry model and initializes diverse descendant models\nwith it. Previous Learngene paradigms fail to handle the generalizable\nknowledge in multimodal scenarios. In this paper, we put forward the idea of\nutilizing a multimodal block to extract the multimodal generalizable knowledge,\nwhich inspires us to propose MM-LG (Multimodal Learngene), a novel framework\ndesigned to extract and leverage generalizable components from CLIP.\nSpecifically, we first establish multimodal and unimodal blocks to extract the\nmultimodal and unimodal generalizable knowledge in a weighted-sum manner.\nSubsequently, we employ these components to numerically initialize descendant\nmodels of varying scales and modalities. Extensive experiments demonstrate\nMM-LG's effectiveness, which achieves performance gains over existing learngene\napproaches (e.g.,+3.1% on Oxford-IIIT PET and +4.13% on Flickr30k) and\ncomparable or superior results to the pre-training and fine-tuning paradigm\n(e.g.,+1.9% on Oxford-IIIT PET and +3.65% on Flickr30k). Notably, MM-LG\nrequires only around 25% of the parameter storage while reducing around 2.8\ntimes pre-training costs for diverse model scales compared to the pre-training\nand fine-tuning paradigm, making it particularly suitable for efficient\ndeployment across diverse downstream tasks.", "published": "2025-06-20 01:17:41", "link": "http://arxiv.org/abs/2506.16673v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Comparative Analysis of Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) as Dimensionality Reduction Techniques", "abstract": "High-dimensional image data often require dimensionality reduction before\nfurther analysis. This paper provides a purely analytical comparison of two\nlinear techniques-Principal Component Analysis (PCA) and Singular Value\nDecomposition (SVD). After the derivation of each algorithm from first\nprinciples, we assess their interpretability, numerical stability, and\nsuitability for differing matrix shapes. building on classical and recent\nnumerical literature, We synthesize rule-of-thumb guidelines for choosing one\nout of the two algorithms without empirical benchmarking, building on classical\nand recent numerical literature. Limitations and directions for future\nexperimental work are outlined at the end.", "published": "2025-06-20 00:19:45", "link": "http://arxiv.org/abs/2506.16663v1", "categories": ["cs.CV", "cs.NA", "math.NA"], "primary_category": "cs.CV"}
{"title": "When does FTP become FPT?", "abstract": "In the problem Fault-Tolerant Path (FTP), we are given an edge-weighted\ndirected graph G = (V, E), a subset U \\subseteq E of vulnerable edges, two\nvertices s, t \\in V, and integers k and \\ell. The task is to decide whether\nthere exists a subgraph H of G with total cost at most \\ell such that, after\nthe removal of any k vulnerable edges, H still contains an s-t-path. We study\nwhether Fault-Tolerant Path is fixed-parameter tractable (FPT) and whether it\nadmits a polynomial kernel under various parameterizations. Our choices of\nparameters include: the number of vulnerable edges in the input graph, the\nnumber of safe (i.e, invulnerable) edges in the input graph, the budget \\ell,\nthe minimum number of safe edges in any optimal solution, the minimum number of\nvulnerable edges in any optimal solution, the required redundancy k, and\nnatural above- and below-guarantee parameterizations. We provide an almost\ncomplete description of the complexity landscape of FTP for these parameters.", "published": "2025-06-20 14:05:08", "link": "http://arxiv.org/abs/2506.17008v1", "categories": ["cs.DS", "cs.DM"], "primary_category": "cs.DS"}
{"title": "On Training-Test (Mis)alignment in Unsupervised Combinatorial Optimization: Observation, Empirical Exploration, and Analysis", "abstract": "In unsupervised combinatorial optimization (UCO), during training, one aims\nto have continuous decisions that are promising in a probabilistic sense for\neach training instance, which enables end-to-end training on initially discrete\nand non-differentiable problems. At the test time, for each test instance,\nstarting from continuous decisions, derandomization is typically applied to\nobtain the final deterministic decisions. Researchers have developed more and\nmore powerful test-time derandomization schemes to enhance the empirical\nperformance and the theoretical guarantee of UCO methods. However, we notice a\nmisalignment between training and testing in the existing UCO methods.\nConsequently, lower training losses do not necessarily entail better\npost-derandomization performance, even for the training instances without any\ndata distribution shift. Empirically, we indeed observe such undesirable cases.\nWe explore a preliminary idea to better align training and testing in UCO by\nincluding a differentiable version of derandomization into training. Our\nempirical exploration shows that such an idea indeed improves training-test\nalignment, but also introduces nontrivial challenges into training.", "published": "2025-06-20 04:05:09", "link": "http://arxiv.org/abs/2506.16732v1", "categories": ["cs.LG", "cs.AI", "cs.DM", "math.PR"], "primary_category": "cs.LG"}
{"title": "Towards AI Search Paradigm", "abstract": "In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint\nfor next-generation search systems capable of emulating human information\nprocessing and decision-making. The paradigm employs a modular architecture of\nfour LLM-powered agents (Master, Planner, Executor and Writer) that dynamically\nadapt to the full spectrum of information needs, from simple factual queries to\ncomplex multi-stage reasoning tasks. These agents collaborate dynamically\nthrough coordinated workflows to evaluate query complexity, decompose problems\ninto executable plans, and orchestrate tool usage, task execution, and content\nsynthesis. We systematically present key methodologies for realizing this\nparadigm, including task planning and tool integration, execution strategies,\naligned and robust retrieval-augmented generation, and efficient LLM inference,\nspanning both algorithmic techniques and infrastructure-level optimizations. By\nproviding an in-depth guide to these foundational components, this work aims to\ninform the development of trustworthy, adaptive, and scalable AI search\nsystems.", "published": "2025-06-20 17:42:13", "link": "http://arxiv.org/abs/2506.17188v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Universal Music Representations? Evaluating Foundation Models on World Music Corpora", "abstract": "Foundation models have revolutionized music information retrieval, but\nquestions remain about their ability to generalize across diverse musical\ntraditions. This paper presents a comprehensive evaluation of five\nstate-of-the-art audio foundation models across six musical corpora spanning\nWestern popular, Greek, Turkish, and Indian classical traditions. We employ\nthree complementary methodologies to investigate these models' cross-cultural\ncapabilities: probing to assess inherent representations, targeted supervised\nfine-tuning of 1-2 layers, and multi-label few-shot learning for low-resource\nscenarios. Our analysis shows varying cross-cultural generalization, with\nlarger models typically outperforming on non-Western music, though results\ndecline for culturally distant traditions. Notably, our approaches achieve\nstate-of-the-art performance on five out of six evaluated datasets,\ndemonstrating the effectiveness of foundation models for world music\nunderstanding. We also find that our targeted fine-tuning approach does not\nconsistently outperform probing across all settings, suggesting foundation\nmodels already encode substantial musical knowledge. Our evaluation framework\nand benchmarking results contribute to understanding how far current models are\nfrom achieving universal music representations while establishing metrics for\nfuture progress.", "published": "2025-06-20 15:06:44", "link": "http://arxiv.org/abs/2506.17055v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PersonalAI: Towards digital twins in the graph form", "abstract": "The challenge of personalizing language models, specifically the ability to\naccount for a user's history during interactions, is of significant interest.\nDespite recent advancements in large language models (LLMs) and Retrieval\nAugmented Generation that have enhanced the factual base of LLMs, the task of\nretaining extensive personal information and using it to generate personalized\nresponses remains pertinent. To address this, we propose utilizing external\nmemory in the form of knowledge graphs, which are constructed and updated by\nthe LLM itself. We have expanded upon ideas of AriGraph architecture and for\nthe first time introduced a combined graph featuring both standard edges and\ntwo types of hyperedges. Experiments conducted on the TriviaQA, HotpotQA and\nDiaASQ benchmarks indicates that this approach aids in making the process of\ngraph construction and knowledge extraction unified and robust. Furthermore, we\naugmented the DiaASQ benchmark by incorporating parameters such as time into\ndialogues and introducing contradictory statements made by the same speaker at\ndifferent times. Despite these modifications, the performance of the\nquestion-answering system remained robust, demonstrating the proposed\narchitecture's ability to maintain and utilize temporal dependencies.", "published": "2025-06-20 13:52:15", "link": "http://arxiv.org/abs/2506.17001v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "RAGentA: Multi-Agent Retrieval-Augmented Generation for Attributed Question Answering", "abstract": "We present RAGentA, a multi-agent retrieval-augmented generation (RAG)\nframework for attributed question answering (QA). With the goal of trustworthy\nanswer generation, RAGentA focuses on optimizing answer correctness, defined by\ncoverage and relevance to the question and faithfulness, which measures the\nextent to which answers are grounded in retrieved documents. RAGentA uses a\nmulti-agent architecture that iteratively filters retrieved documents,\ngenerates attributed answers with in-line citations, and verifies completeness\nthrough dynamic refinement. Central to the framework is a hybrid retrieval\nstrategy that combines sparse and dense methods, improving Recall@20 by 12.5%\ncompared to the best single retrieval model, resulting in more correct and\nwell-supported answers. Evaluated on a synthetic QA dataset derived from the\nFineWeb index, RAGentA outperforms standard RAG baselines, achieving gains of\n1.09% in correctness and 10.72% in faithfulness. These results demonstrate the\neffectiveness of the multi-agent architecture and hybrid retrieval in advancing\ntrustworthy QA.", "published": "2025-06-20 13:37:03", "link": "http://arxiv.org/abs/2506.16988v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Pyramid Mixer: Multi-dimensional Multi-period Interest Modeling for Sequential Recommendation", "abstract": "Sequential recommendation, a critical task in recommendation systems,\npredicts the next user action based on the understanding of the user's\nhistorical behaviors. Conventional studies mainly focus on cross-behavior\nmodeling with self-attention based methods while neglecting comprehensive user\ninterest modeling for more dimensions. In this study, we propose a novel\nsequential recommendation model, Pyramid Mixer, which leverages the MLP-Mixer\narchitecture to achieve efficient and complete modeling of user interests. Our\nmethod learns comprehensive user interests via cross-behavior and cross-feature\nuser sequence modeling. The mixer layers are stacked in a pyramid way for\ncross-period user temporal interest learning. Through extensive offline and\nonline experiments, we demonstrate the effectiveness and efficiency of our\nmethod, and we obtain a +0.106% improvement in user stay duration and a\n+0.0113% increase in user active days in the online A/B test. The Pyramid Mixer\nhas been successfully deployed on the industrial platform, demonstrating its\nscalability and impact in real-world applications.", "published": "2025-06-20 12:11:38", "link": "http://arxiv.org/abs/2506.16942v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Multi-Objective Recommendation in the Era of Generative AI: A Survey of Recent Progress and Future Prospects", "abstract": "With the recent progress in generative artificial intelligence (Generative\nAI), particularly in the development of large language models, recommendation\nsystems are evolving to become more versatile. Unlike traditional techniques,\ngenerative AI not only learns patterns and representations from complex data\nbut also enables content generation, data synthesis, and personalized\nexperiences. This generative capability plays a crucial role in the field of\nrecommendation systems, helping to address the issue of data sparsity and\nimproving the overall performance of recommendation systems. Numerous studies\non generative AI have already emerged in the field of recommendation systems.\nMeanwhile, the current requirements for recommendation systems have surpassed\nthe single utility of accuracy, leading to a proliferation of multi-objective\nresearch that considers various goals in recommendation systems. However, to\nthe best of our knowledge, there remains a lack of comprehensive studies on\nmulti-objective recommendation systems based on generative AI technologies,\nleaving a significant gap in the literature. Therefore, we investigate the\nexisting research on multi-objective recommendation systems involving\ngenerative AI to bridge this gap. We compile current research on\nmulti-objective recommendation systems based on generative techniques,\ncategorizing them by objectives. Additionally, we summarize relevant evaluation\nmetrics and commonly used datasets, concluding with an analysis of the\nchallenges and future directions in this domain.", "published": "2025-06-20 10:30:39", "link": "http://arxiv.org/abs/2506.16893v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "eSapiens: A Real-World NLP Framework for Multimodal Document Understanding and Enterprise Knowledge Processing", "abstract": "We introduce eSapiens, a unified question-answering system designed for\nenterprise settings, which bridges structured databases and unstructured\ntextual corpora via a dual-module architecture. The system combines a\nText-to-SQL planner with a hybrid Retrieval-Augmented Generation (RAG)\npipeline, enabling natural language access to both relational data and\nfree-form documents. To enhance answer faithfulness, the RAG module integrates\ndense and sparse retrieval, commercial reranking, and a citation verification\nloop that ensures grounding consistency. We evaluate eSapiens on the RAGTruth\nbenchmark across five leading large language models (LLMs), analyzing\nperformance across key dimensions such as completeness, hallucination, and\ncontext utilization. Results demonstrate that eSapiens outperforms a FAISS\nbaseline in contextual relevance and generation quality, with optional\nstrict-grounding controls for high-stakes scenarios. This work provides a\ndeployable framework for robust, citation-aware question answering in\nreal-world enterprise applications.", "published": "2025-06-20 06:07:20", "link": "http://arxiv.org/abs/2506.16768v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Simple Contrastive Framework Of Item Tokenization For Generative Recommendation", "abstract": "Generative retrieval-based recommendation has emerged as a promising paradigm\naiming at directly generating the identifiers of the target candidates.\nHowever, in large-scale recommendation systems, this approach becomes\nincreasingly cumbersome due to the redundancy and sheer scale of the token\nspace. To overcome these limitations, recent research has explored the use of\nsemantic tokens as an alternative to ID tokens, which typically leveraged\nreconstruction-based strategies, like RQ-VAE, to quantize content embeddings\nand significantly reduce the embedding size. However, reconstructive\nquantization aims for the precise reconstruction of each item embedding\nindependently, which conflicts with the goal of generative retrieval tasks\nfocusing more on differentiating among items. Moreover, multi-modal side\ninformation of items, such as descriptive text and images, geographical\nknowledge in location-based recommendation services, has been shown to be\neffective in improving recommendations by providing richer contexts for\ninteractions. Nevertheless, effectively integrating such complementary\nknowledge into existing generative recommendation frameworks remains\nchallenging. To overcome these challenges, we propose a novel unsupervised deep\nquantization exclusively based on contrastive learning, named SimCIT (a Simple\nContrastive Item Tokenization framework). Specifically, different from existing\nreconstruction-based strategies, SimCIT propose to use a learnable residual\nquantization module to align with the signals from different modalities of the\nitems, which combines multi-modal knowledge alignment and semantic tokenization\nin a mutually beneficial contrastive learning framework. Extensive experiments\nacross public datasets and a large-scale industrial dataset from various\ndomains demonstrate SimCIT's effectiveness in LLM-based generative\nrecommendation.", "published": "2025-06-20 01:54:32", "link": "http://arxiv.org/abs/2506.16683v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Codeword-Segmentation Rate-Splitting Multiple Access and Evaluation under Suboptimal Decoding", "abstract": "Rate-Splitting Multiple Access (RSMA) has been recognized as a promising\nmultiple access technique. We propose a novel architecture for downlink RSMA,\nnamely Codeword-Segmentation RSMA (CS-RSMA). Different from conventional RSMA\nwhich splits users' messages into common and private parts before encoding,\nCS-RSMA encodes the users' messages directly, segments the codewords into\ncommon and private parts, and transmits the codeword segments using common and\nprivate streams. In addition to the principle of CS-RSMA, a novel performance\nanalysis framework is proposed. This framework utilizes a recent discovery in\nmismatched decoding under finite-alphabet input and interference, and can\nbetter capture the receiver's complexity limits. Precoder optimization under\nfinite alphabets and suboptimal decoders for conventional RSMA and CS-RSMA to\nmaximize the Sum-Rate (SR) and the Max-Min Fairness (MMF) is also addressed.\nThe numerical results reveal the theoretical performance of conventional RSMA\nand CS-RSMA. We observe that CS-RSMA leads to better performance than\nconventional RSMA in SR, and similar performance in MMF. Furthermore, a\nphysical-layer implementation of CS-RSMA is proposed and evaluated through\nlink-level simulations. Aside performance benefits, we also demonstrate that\nCS-RSMA brings significant benefits on the encoding/decoding, control\nsignaling, and retransmission process compared to conventional RSMA.", "published": "2025-06-20 17:11:11", "link": "http://arxiv.org/abs/2506.17164v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Searching for a Hidden Markov Anomaly over Multiple Processes", "abstract": "We address the problem of detecting an anomalous process among a large number\nof processes. At each time t, normal processes are in state zero (normal\nstate), while the abnormal process may be in either state zero (normal state)\nor state one (abnormal state), with the states being hidden. The transition\nbetween states for the abnormal process is governed by a Markov chain over\ntime. At each time step, observations can be drawn from a selected subset of\nprocesses. Each probed process generates an observation depending on its hidden\nstate, either a typical distribution under state zero or an abnormal\ndistribution under state one. The objective is to design a sequential search\nstrategy that minimizes the expected detection time, subject to an error\nprobability constraint. In contrast to prior works that assume i.i.d.\nobservations, we address a new setting where anomalies evolve according to a\nhidden Markov model. To this end, we propose a novel algorithm, dubbed Anomaly\nDetection under Hidden Markov model (ADHM), which dynamically adapts the\nprobing strategy based on accumulated statistical evidence and predictive\nbelief updates over hidden states. ADHM effectively leverages temporal\ncorrelations to focus sensing resources on the most informative processes. The\nalgorithm is supported by an asymptotic theoretical foundation, grounded in an\noracle analysis that characterizes the fundamental limits of detection under\nthe assumption of a known distribution of the hidden states. In addition, the\nalgorithm demonstrates strong empirical performance, consistently outperforming\nexisting methods in extensive simulations.", "published": "2025-06-20 16:10:38", "link": "http://arxiv.org/abs/2506.17108v1", "categories": ["eess.SP", "cs.IT", "math.IT", "stat.ML"], "primary_category": "eess.SP"}
{"title": "Neural Polar Decoders for DNA Data Storage", "abstract": "Synchronization errors, such as insertions and deletions, present a\nfundamental challenge in DNA-based data storage systems, arising from both\nsynthesis and sequencing noise. These channels are often modeled as\ninsertion-deletion-substitution (IDS) channels, for which designing\nmaximum-likelihood decoders is computationally expensive. In this work, we\npropose a data-driven approach based on neural polar decoders (NPDs) to design\nlow-complexity decoders for channels with synchronization errors. The proposed\narchitecture enables decoding over IDS channels with reduced complexity $O(AN\nlog N )$, where $A$ is a tunable parameter independent of the channel. NPDs\nrequire only sample access to the channel and can be trained without an\nexplicit channel model. Additionally, NPDs provide mutual information (MI)\nestimates that can be used to optimize input distributions and code design. We\ndemonstrate the effectiveness of NPDs on both synthetic deletion and IDS\nchannels. For deletion channels, we show that NPDs achieve near-optimal\ndecoding performance and accurate MI estimation, with significantly lower\ncomplexity than trellis-based decoders. We also provide numerical estimates of\nthe channel capacity for the deletion channel. We extend our evaluation to\nrealistic DNA storage settings, including channels with multiple noisy reads\nand real-world Nanopore sequencing data. Our results show that NPDs match or\nsurpass the performance of existing methods while using significantly fewer\nparameters than the state-of-the-art. These findings highlight the promise of\nNPDs for robust and efficient decoding in DNA data storage systems.", "published": "2025-06-20 15:26:38", "link": "http://arxiv.org/abs/2506.17076v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Empowering Near-Field Communications in Low-Altitude Economy with LLM: Fundamentals, Potentials, Solutions, and Future Directions", "abstract": "The low-altitude economy (LAE) is gaining significant attention from academia\nand industry. Fortunately, LAE naturally aligns with near-field communications\nin extremely large-scale MIMO (XL-MIMO) systems. By leveraging near-field\nbeamfocusing, LAE can precisely direct beam energy to unmanned aerial vehicles,\nwhile the additional distance dimension boosts overall spectrum efficiency.\nHowever, near-field communications in LAE still face several challenges, such\nas the increase in signal processing complexity and the necessity of\ndistinguishing between far and near-field users. Inspired by the large language\nmodels (LLM) with powerful ability to handle complex problems, we apply LLM to\nsolve challenges of near-field communications in LAE. The objective of this\narticle is to provide a comprehensive analysis and discussion on LLM-empowered\nnear-field communications in LAE. Specifically, we first introduce fundamentals\nof LLM and near-field communications, including the key advantages of LLM and\nkey characteristics of near-field communications. Then, we reveal the\nopportunities and challenges of near-field communications in LAE. To address\nthese challenges, we present a LLM-based scheme for near-field communications\nin LAE, and provide a case study which jointly distinguishes far and near-field\nusers and designs multi-user precoding matrix. Finally, we outline and\nhighlight several future research directions and open issues.", "published": "2025-06-20 15:14:29", "link": "http://arxiv.org/abs/2506.17067v1", "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Maximal Achievable Service Rates of Codes and Connections to Combinatorial Designs", "abstract": "We investigate the service-rate region (SRR) of distributed storage systems\nthat employ linear codes. We focus on systems where each server stores one code\nsymbol, and a user recovers a data symbol by accessing any of its recovery\ngroups, subject to per-server capacity limits. The SRR--the convex polytope of\nsimultaneously achievable request rates--captures system throughput and\nscalability. We first derive upper and lower bounds on the maximum request rate\nof each data object. These bounds hold for all linear codes and depend only on\nthe number of parity checks orthogonal to a particular set of codeword\ncoordinates associated with that object, i.e., the equations used in\nmajority-logic decoding, and on code parameters. We then check the bound\nsaturation for 1) all non-systematic codes whose SRRs are already known and 2)\nsystematic codes. For the former, we prove the bounds are tight. For systematic\ncodes, we show that the upper bound is achieved whenever the supports of\nminimum-weight dual codewords form a 2-design. As an application, we determine\nthe exact per-object demand limits for binary Hamming codes. Our framework\nprovides a new lens to address the SRR problem through combinatorial design\ntheory.", "published": "2025-06-20 13:24:51", "link": "http://arxiv.org/abs/2506.16983v1", "categories": ["cs.IT", "math.CO", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Generic Construction of $q$-ary Near-MDS Codes Supporting 2-Designs with Lengths Beyond $q+1$", "abstract": "A linear code with parameters $[n, k, n - k + 1]$ is called maximum distance\nseparable (MDS), and one with parameters $[n, k, n - k]$ is called almost MDS\n(AMDS). A code is near-MDS (NMDS) if both it and its dual are AMDS. NMDS codes\nsupporting combinatorial $t$-designs have attracted growing interest, yet\nconstructing such codes remains highly challenging. In 2020, Ding and Tang\ninitiated the study of NMDS codes supporting 2-designs by constructing the\nfirst infinite family, followed by several other constructions for $t > 2$, all\nwith length at most $q + 1$. Although NMDS codes can, in principle, exceed this\nlength, known examples supporting 2-designs and having length greater than $q +\n1$ are extremely rare and limited to a few sporadic binary and ternary cases.\nIn this paper, we present the first \\emph{generic construction} of $q$-ary NMDS\ncodes supporting 2-designs with lengths \\emph{exceeding $q + 1$}. Our method\nleverages new connections between elliptic curve codes, finite abelian groups,\nsubset sums, and combinatorial designs, resulting in an infinite family of such\ncodes along with their weight distributions.", "published": "2025-06-20 07:17:17", "link": "http://arxiv.org/abs/2506.16793v1", "categories": ["math.CO", "cs.IT", "math.IT"], "primary_category": "math.CO"}
{"title": "No Free Lunch: Rethinking Internal Feedback for LLM Reasoning", "abstract": "Reinforcement learning has emerged as a powerful paradigm for post-training\nlarge language models (LLMs) to improve reasoning. Approaches like\nReinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning\nwith Verifiable Rewards (RLVR) have shown strong results, but they require\nextensive external supervision. We investigate an alternative class of methods,\nReinforcement Learning from Internal Feedback (RLIF), which relies solely on\nintrinsic model-derived signals instead of external rewards. In particular, we\nleverage unsupervised reward proxies such as token-level entropy,\ntrajectory-level entropy, and self-certainty. Our theoretical analysis shows\nthese internal objectives are partially equivalent, and we empirically evaluate\nvarious RLIF strategies on challenging math reasoning benchmarks. Experimental\nresults demonstrate that RLIF can boost the reasoning performance of base LLMs\nat the beginning phase of the training, matching or surpassing RLVR techniques\non these tasks. However, when training progresses, performance degrades even\nbelow the model before training. Moreover, we find that RLIF yields little\nimprovement for instruction-tuned models, indicating diminishing returns of\nintrinsic feedback once an LLM is already instruction-tuned. We further analyze\nthis limitation by mixing model weights and explain the reason of RLIF's\ntraining behaviors, providing practical guidelines for integrating internal\nfeedback signals into LLM training. We hope our analysis of internal feedback\nwill inform more principled and effective strategies for LLM post-training.", "published": "2025-06-20 17:59:52", "link": "http://arxiv.org/abs/2506.17219v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "BREAD: Branched Rollouts from Expert Anchors Bridge SFT & RL for Reasoning", "abstract": "Small language models (SLMs) struggle to learn complex reasoning behaviors,\nespecially when high-quality traces are scarce or difficult to learn from. The\nstandard training approach combines a supervised fine-tuning (SFT) stage, often\nto distill capabilities of a larger model, followed by a reinforcement learning\n(RL)stage such as Group Relative Policy Optimization (GRPO). In this paper, we\ninvestigate the fundamental limitations of this SFT + RL paradigm and propose\nmethods to overcome them. Under a suitable theoretical model, we demonstrate\nthat the SFT + RL strategy can fail completely when (1) the expert's traces are\ntoo difficult for the small model to express, or (2) the small model's\ninitialization has exponentially small likelihood of success. To address these,\nwe introduce BREAD: a GRPO variant that unifies the SFT and RL stages via\npartial expert guidance and branched rollouts. When self-generated traces fail,\nBREAD adaptively inserts short expert prefixes/hints, allowing the small model\nto complete the rest of the reasoning path, and ensuring that each update\nincludes at least one successful trace. This mechanism both densifies the\nreward signal and induces a natural learning curriculum. BREAD requires fewer\nthan 40% of ground-truth traces, consistently outperforming standard GRPO while\nspeeding up the training by about 3 times. Importantly, we demonstrate that\nBREAD helps the model solve problems that are otherwise unsolvable by the SFT +\nRL strategy, highlighting how branched rollouts and expert guidance can\nsubstantially boost SLM reasoning.", "published": "2025-06-20 17:59:07", "link": "http://arxiv.org/abs/2506.17211v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Network Sparsity Unlocks the Scaling Potential of Deep Reinforcement Learning", "abstract": "Effectively scaling up deep reinforcement learning models has proven\nnotoriously difficult due to network pathologies during training, motivating\nvarious targeted interventions such as periodic reset and architectural\nadvances such as layer normalization. Instead of pursuing more complex\nmodifications, we show that introducing static network sparsity alone can\nunlock further scaling potential beyond their dense counterparts with\nstate-of-the-art architectures. This is achieved through simple one-shot random\npruning, where a predetermined percentage of network weights are randomly\nremoved once before training. Our analysis reveals that, in contrast to naively\nscaling up dense DRL networks, such sparse networks achieve both higher\nparameter efficiency for network expressivity and stronger resistance to\noptimization challenges like plasticity loss and gradient interference. We\nfurther extend our evaluation to visual and streaming RL scenarios,\ndemonstrating the consistent benefits of network sparsity.", "published": "2025-06-20 17:54:24", "link": "http://arxiv.org/abs/2506.17204v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Schr\u00f6dinger Bridge Matching for Tree-Structured Costs and Entropic Wasserstein Barycentres", "abstract": "Recent advances in flow-based generative modelling have provided scalable\nmethods for computing the Schr\\\"odinger Bridge (SB) between distributions, a\ndynamic form of entropy-regularised Optimal Transport (OT) for the quadratic\ncost. The successful Iterative Markovian Fitting (IMF) procedure solves the SB\nproblem via sequential bridge-matching steps, presenting an elegant and\npractical approach with many favourable properties over the more traditional\nIterative Proportional Fitting (IPF) procedure. Beyond the standard setting,\noptimal transport can be generalised to the multi-marginal case in which the\nobjective is to minimise a cost defined over several marginal distributions. Of\nparticular importance are costs defined over a tree structure, from which\nWasserstein barycentres can be recovered as a special case. In this work, we\nextend the IMF procedure to solve for the tree-structured SB problem. Our\nresulting algorithm inherits the many advantages of IMF over IPF approaches in\nthe tree-based setting. In the specific case of Wasserstein barycentres, our\napproach can be viewed as extending fixed-point approaches for barycentre\ncomputation to the case of flow-based entropic OT solvers.", "published": "2025-06-20 17:47:47", "link": "http://arxiv.org/abs/2506.17197v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Optimal Implicit Bias in Linear Regression", "abstract": "Most modern learning problems are over-parameterized, where the number of\nlearnable parameters is much greater than the number of training data points.\nIn this over-parameterized regime, the training loss typically has infinitely\nmany global optima that completely interpolate the data with varying\ngeneralization performance. The particular global optimum we converge to\ndepends on the implicit bias of the optimization algorithm. The question we\naddress in this paper is, ``What is the implicit bias that leads to the best\ngeneralization performance?\". To find the optimal implicit bias, we provide a\nprecise asymptotic analysis of the generalization performance of interpolators\nobtained from the minimization of convex functions/potentials for\nover-parameterized linear regression with non-isotropic Gaussian data. In\nparticular, we obtain a tight lower bound on the best generalization error\npossible among this class of interpolators in terms of the\nover-parameterization ratio, the variance of the noise in the labels, the\neigenspectrum of the data covariance, and the underlying distribution of the\nparameter to be estimated. Finally, we find the optimal convex implicit bias\nthat achieves this lower bound under certain sufficient conditions involving\nthe log-concavity of the distribution of a Gaussian convolved with the prior of\nthe true underlying parameter.", "published": "2025-06-20 17:41:39", "link": "http://arxiv.org/abs/2506.17187v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Variational Learning of Disentangled Representations", "abstract": "Disentangled representations enable models to separate factors of variation\nthat are shared across experimental conditions from those that are\ncondition-specific. This separation is essential in domains such as biomedical\ndata analysis, where generalization to new treatments, patients, or species\ndepends on isolating stable biological signals from context-dependent effects.\nWhile extensions of the variational autoencoder (VAE) framework have been\nproposed to address this problem, they frequently suffer from leakage between\nlatent representations, limiting their ability to generalize to unseen\nconditions. Here, we introduce DISCoVeR, a new variational framework that\nexplicitly separates condition-invariant and condition-specific factors.\nDISCoVeR integrates three key components: (i) a dual-latent architecture that\nmodels shared and specific factors separately; (ii) two parallel\nreconstructions that ensure both representations remain informative; and (iii)\na novel max-min objective that encourages clean separation without relying on\nhandcrafted priors, while making only minimal assumptions. Theoretically, we\nshow that this objective maximizes data likelihood while promoting\ndisentanglement, and that it admits a unique equilibrium. Empirically, we\ndemonstrate that DISCoVeR achieves improved disentanglement on synthetic\ndatasets, natural images, and single-cell RNA-seq data. Together, these results\nestablish DISCoVeR as a principled approach for learning disentangled\nrepresentations in multi-condition settings.", "published": "2025-06-20 17:36:12", "link": "http://arxiv.org/abs/2506.17182v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Deep generative models as the probability transformation functions", "abstract": "This paper introduces a unified theoretical perspective that views deep\ngenerative models as probability transformation functions. Despite the apparent\ndifferences in architecture and training methodologies among various types of\ngenerative models - autoencoders, autoregressive models, generative adversarial\nnetworks, normalizing flows, diffusion models, and flow matching - we\ndemonstrate that they all fundamentally operate by transforming simple\npredefined distributions into complex target data distributions. This unifying\nperspective facilitates the transfer of methodological improvements between\nmodel architectures and provides a foundation for developing universal\ntheoretical approaches, potentially leading to more efficient and effective\ngenerative modeling techniques.", "published": "2025-06-20 17:22:23", "link": "http://arxiv.org/abs/2506.17171v1", "categories": ["cs.LG", "68T07"], "primary_category": "cs.LG"}
{"title": "Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity", "abstract": "In this paper, we investigate the use of small datasets in the context of\noffline reinforcement learning (RL). While many common offline RL benchmarks\nemploy datasets with over a million data points, many offline RL applications\nrely on considerably smaller datasets. We show that offline RL algorithms can\noverfit on small datasets, resulting in poor performance. To address this\nchallenge, we introduce \"Sparse-Reg\": a regularization technique based on\nsparsity to mitigate overfitting in offline reinforcement learning, enabling\neffective learning in limited data settings and outperforming state-of-the-art\nbaselines in continuous control.", "published": "2025-06-20 16:57:59", "link": "http://arxiv.org/abs/2506.17155v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Consistent Sampling and Simulation: Molecular Dynamics with Energy-Based Diffusion Models", "abstract": "Diffusion models have recently gained significant attention due to their\neffectiveness in various scientific domains, including biochemistry. When\ntrained on equilibrium molecular distributions, diffusion models provide both:\na generative procedure to sample equilibrium conformations and associated\nforces derived from the model's scores. However, using the forces for\ncoarse-grained molecular dynamics simulations uncovers inconsistencies in the\nsamples generated via classical diffusion inference and simulation, despite\nboth originating from the same model. Particularly at the small diffusion\ntimesteps required for simulations, diffusion models fail to satisfy the\nFokker-Planck equation, which governs how the score should evolve over time. We\ninterpret this deviation as an indication of the observed inconsistencies and\npropose an energy-based diffusion model with a Fokker-Planck-derived\nregularization term enforcing consistency. We demonstrate the effectiveness of\nour approach on toy systems, alanine dipeptide, and introduce a\nstate-of-the-art transferable Boltzmann emulator for dipeptides that supports\nsimulation and demonstrates enhanced consistency and efficient sampling.", "published": "2025-06-20 16:38:29", "link": "http://arxiv.org/abs/2506.17139v1", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "physics.comp-ph", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Rapid and Continuous Trust Evaluation for Effective Task Collaboration Through Siamese Model", "abstract": "Trust is emerging as an effective tool to ensure the successful completion of\ncollaborative tasks within collaborative systems. However, rapidly and\ncontinuously evaluating the trustworthiness of collaborators during task\nexecution is a significant challenge due to distributed devices, complex\noperational environments, and dynamically changing resources. To tackle this\nchallenge, this paper proposes a Siamese-enabled rapid and continuous trust\nevaluation framework (SRCTE) to facilitate effective task collaboration. First,\nthe communication and computing resource attributes of the collaborator in a\ntrusted state, along with historical collaboration data, are collected and\nrepresented using an attributed control flow graph (ACFG) that captures\ntrust-related semantic information and serves as a reference for comparison\nwith data collected during task execution. At each time slot of task execution,\nthe collaborator's communication and computing resource attributes, as well as\ntask completion effectiveness, are collected in real time and represented with\nan ACFG to convey their trust-related semantic information. A Siamese model,\nconsisting of two shared-parameter Structure2vec networks, is then employed to\nlearn the deep semantics of each pair of ACFGs and generate their embeddings.\nFinally, the similarity between the embeddings of each pair of ACFGs is\ncalculated to determine the collaborator's trust value at each time slot. A\nreal system is built using two Dell EMC 5200 servers and a Google Pixel 8 to\ntest the effectiveness of the proposed SRCTE framework. Experimental results\ndemonstrate that SRCTE converges rapidly with only a small amount of data and\nachieves a high anomaly trust detection rate compared to the baseline\nalgorithm.", "published": "2025-06-20 16:30:59", "link": "http://arxiv.org/abs/2506.17128v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "TransDreamerV3: Implanting Transformer In DreamerV3", "abstract": "This paper introduces TransDreamerV3, a reinforcement learning model that\nenhances the DreamerV3 architecture by integrating a transformer encoder. The\nmodel is designed to improve memory and decision-making capabilities in complex\nenvironments. We conducted experiments on Atari-Boxing, Atari-Freeway,\nAtari-Pong, and Crafter tasks, where TransDreamerV3 demonstrated improved\nperformance over DreamerV3, particularly in the Atari-Freeway and Crafter\ntasks. While issues in the Minecraft task and limited training across all tasks\nwere noted, TransDreamerV3 displays advancement in world model-based\nreinforcement learning, leveraging transformer architectures.", "published": "2025-06-20 16:09:17", "link": "http://arxiv.org/abs/2506.17103v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Identifiability of Deep Polynomial Neural Networks", "abstract": "Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric\nstructure. However, their identifiability -- a key property for ensuring\ninterpretability -- remains poorly understood. In this work, we present a\ncomprehensive analysis of the identifiability of deep PNNs, including\narchitectures with and without bias terms. Our results reveal an intricate\ninterplay between activation degrees and layer widths in achieving\nidentifiability. As special cases, we show that architectures with\nnon-increasing layer widths are generically identifiable under mild conditions,\nwhile encoder-decoder networks are identifiable when the decoder widths do not\ngrow too rapidly. Our proofs are constructive and center on a connection\nbetween deep PNNs and low-rank tensor decompositions, and Kruskal-type\nuniqueness theorems. This yields both generic conditions determined by the\narchitecture, and effective conditions that depend on the network's parameters.\nWe also settle an open conjecture on the expected dimension of PNN's\nneurovarieties, and provide new bounds on the activation degrees required for\nit to reach its maximum.", "published": "2025-06-20 15:58:46", "link": "http://arxiv.org/abs/2506.17093v1", "categories": ["cs.LG", "cs.AI", "math.AG", "stat.ML", "68T07, 62R01, 15A69, 14M99"], "primary_category": "cs.LG"}
{"title": "Flow-Based Non-stationary Temporal Regime Causal Structure Learning", "abstract": "Understanding causal relationships in multivariate time series is crucial in\nmany scenarios, such as those dealing with financial or neurological data. Many\nsuch time series exhibit multiple regimes, i.e., consecutive temporal segments\nwith a priori unknown boundaries, with each regime having its own causal\nstructure. Inferring causal dependencies and regime shifts is critical for\nanalyzing the underlying processes. However, causal structure learning in this\nsetting is challenging due to (1) non stationarity, i.e., each regime can have\nits own causal graph and mixing function, and (2) complex noise distributions,\nwhich may be non Gaussian or heteroscedastic. Existing causal discovery\napproaches cannot address these challenges, since generally assume stationarity\nor Gaussian noise with constant variance. Hence, we introduce FANTOM, a unified\nframework for causal discovery that handles non stationary processes along with\nnon Gaussian and heteroscedastic noises. FANTOM simultaneously infers the\nnumber of regimes and their corresponding indices and learns each regime's\nDirected Acyclic Graph. It uses a Bayesian Expectation Maximization algorithm\nthat maximizes the evidence lower bound of the data log likelihood. On the\ntheoretical side, we prove, under mild assumptions, that temporal\nheteroscedastic causal models, introduced in FANTOM's formulation, are\nidentifiable in both stationary and non stationary settings. In addition,\nextensive experiments on synthetic and real data show that FANTOM outperforms\nexisting methods.", "published": "2025-06-20 15:12:43", "link": "http://arxiv.org/abs/2506.17065v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings", "abstract": "Generating diverse, all-atom conformational ensembles of dynamic proteins\nsuch as G-protein-coupled receptors (GPCRs) is critical for understanding their\nfunction, yet most generative models simplify atomic detail or ignore\nconformational diversity altogether. We present latent diffusion for full\nprotein generation (LD-FPG), a framework that constructs complete all-atom\nprotein structures, including every side-chain heavy atom, directly from\nmolecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neural\nnetwork (ChebNet) to obtain low-dimensional latent embeddings of protein\nconformations, which are processed using three pooling strategies: blind,\nsequential and residue-based. A diffusion model trained on these latent\nrepresentations generates new samples that a decoder, optionally regularized by\ndihedral-angle losses, maps back to Cartesian coordinates. Using D2R-MD, a\n2-microsecond MD trajectory (12 000 frames) of the human dopamine D2 receptor\nin a membrane environment, the sequential and residue-based pooling strategy\nreproduces the reference ensemble with high structural fidelity (all-atom lDDT\nof approximately 0.7; C-alpha-lDDT of approximately 0.8) and recovers backbone\nand side-chain dihedral-angle distributions with a Jensen-Shannon divergence of\nless than 0.03 compared to the MD data. LD-FPG thereby offers a practical route\nto system-specific, all-atom ensemble generation for large proteins, providing\na promising tool for structure-based therapeutic design on complex, dynamic\ntargets. The D2R-MD dataset and our implementation are freely available to\nfacilitate further research.", "published": "2025-06-20 15:12:34", "link": "http://arxiv.org/abs/2506.17064v1", "categories": ["q-bio.BM", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "Client Selection Strategies for Federated Semantic Communications in Heterogeneous IoT Networks", "abstract": "The exponential growth of IoT devices presents critical challenges in\nbandwidth-constrained wireless networks, particularly regarding efficient data\ntransmission and privacy preservation. This paper presents a novel federated\nsemantic communication (SC) framework that enables collaborative training of\nbandwidth-efficient models for image reconstruction across heterogeneous IoT\ndevices. By leveraging SC principles to transmit only semantic features, our\napproach dramatically reduces communication overhead while preserving\nreconstruction quality. We address the fundamental challenge of client\nselection in federated learning environments where devices exhibit significant\ndisparities in dataset sizes and data distributions. Our framework implements\nthree distinct client selection strategies that explore different trade-offs\nbetween system performance and fairness in resource allocation. The system\nemploys an end-to-end SC architecture with semantic bottlenecks, coupled with a\nloss-based aggregation mechanism that naturally adapts to client heterogeneity.\nExperimental evaluation on image data demonstrates that while Utilitarian\nselection achieves the highest reconstruction quality, Proportional Fairness\nmaintains competitive performance while significantly reducing participation\ninequality and improving computational efficiency. These results establish that\nfederated SC can successfully balance reconstruction quality, resource\nefficiency, and fairness in heterogeneous IoT deployments, paving the way for\nsustainable and privacy-preserving edge intelligence applications.", "published": "2025-06-20 15:11:20", "link": "http://arxiv.org/abs/2506.17063v1", "categories": ["cs.NI", "cs.LG"], "primary_category": "cs.NI"}
{"title": "From Concepts to Components: Concept-Agnostic Attention Module Discovery in Transformers", "abstract": "Transformers have achieved state-of-the-art performance across language and\nvision tasks. This success drives the imperative to interpret their internal\nmechanisms with the dual goals of enhancing performance and improving\nbehavioral control. Attribution methods help advance interpretability by\nassigning model outputs associated with a target concept to specific model\ncomponents. Current attribution research primarily studies multi-layer\nperceptron neurons and addresses relatively simple concepts such as factual\nassociations (e.g., Paris is located in France). This focus tends to overlook\nthe impact of the attention mechanism and lacks a unified approach for\nanalyzing more complex concepts. To fill these gaps, we introduce Scalable\nAttention Module Discovery (SAMD), a concept-agnostic method for mapping\narbitrary, complex concepts to specific attention heads of general transformer\nmodels. We accomplish this by representing each concept as a vector,\ncalculating its cosine similarity with each attention head, and selecting the\nTopK-scoring heads to construct the concept-associated attention module. We\nthen propose Scalar Attention Module Intervention (SAMI), a simple strategy to\ndiminish or amplify the effects of a concept by adjusting the attention module\nusing only a single scalar parameter. Empirically, we demonstrate SAMD on\nconcepts of varying complexity, and visualize the locations of their\ncorresponding modules. Our results demonstrate that module locations remain\nstable before and after LLM post-training, and confirm prior work on the\nmechanics of LLM multilingualism. Through SAMI, we facilitate jailbreaking on\nHarmBench (+72.7%) by diminishing \"safety\" and improve performance on the GSM8K\nbenchmark (+1.6%) by amplifying \"reasoning\". Lastly, we highlight the\ndomain-agnostic nature of our approach by suppressing the image classification\naccuracy of vision transformers on ImageNet.", "published": "2025-06-20 15:04:11", "link": "http://arxiv.org/abs/2506.17052v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Navigating the Deep: Signature Extraction on Deep Neural Networks", "abstract": "Neural network model extraction has emerged in recent years as an important\nsecurity concern, as adversaries attempt to recover a network's parameters via\nblack-box queries. A key step in this process is signature extraction, which\naims to recover the absolute values of the network's weights layer by layer.\nPrior work, notably by Carlini et al. (2020), introduced a technique inspired\nby differential cryptanalysis to extract neural network parameters. However,\ntheir method suffers from several limitations that restrict its applicability\nto networks with a few layers only. Later works focused on improving sign\nextraction, but largely relied on the assumption that signature extraction\nitself was feasible.\n  In this work, we revisit and refine the signature extraction process by\nsystematically identifying and addressing for the first time critical\nlimitations of Carlini et al.'s signature extraction method. These limitations\ninclude rank deficiency and noise propagation from deeper layers. To overcome\nthese challenges, we propose efficient algorithmic solutions for each of the\nidentified issues, greatly improving the efficiency of signature extraction.\nOur approach permits the extraction of much deeper networks than was previously\npossible. We validate our method through extensive experiments on ReLU-based\nneural networks, demonstrating significant improvements in extraction depth and\naccuracy. For instance, our extracted network matches the target network on at\nleast 95% of the input space for each of the eight layers of a neural network\ntrained on the CIFAR-10 dataset, while previous works could barely extract the\nfirst three layers. Our results represent a crucial step toward practical\nattacks on larger and more complex neural network architectures.", "published": "2025-06-20 14:59:47", "link": "http://arxiv.org/abs/2506.17047v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models", "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated significant\nadvances across numerous vision-language tasks. Due to their strong image-text\nalignment capability, MLLMs can effectively understand image-text pairs with\nclear meanings. However, effectively resolving the inherent ambiguities in\nnatural language and visual contexts remains challenging. Existing multimodal\nbenchmarks typically overlook linguistic and visual ambiguities, relying mainly\non unimodal context for disambiguation and thus failing to exploit the mutual\nclarification potential between modalities. To bridge this gap, we introduce\nMUCAR, a novel and challenging benchmark designed explicitly for evaluating\nmultimodal ambiguity resolution across multilingual and cross-modal scenarios.\nMUCAR includes: (1) a multilingual dataset where ambiguous textual expressions\nare uniquely resolved by corresponding visual contexts, and (2) a\ndual-ambiguity dataset that systematically pairs ambiguous images with\nambiguous textual contexts, with each combination carefully constructed to\nyield a single, clear interpretation through mutual disambiguation. Extensive\nevaluations involving 19 state-of-the-art multimodal models--encompassing both\nopen-source and proprietary architectures--reveal substantial gaps compared to\nhuman-level performance, highlighting the need for future research into more\nsophisticated cross-modal ambiguity comprehension methods, further pushing the\nboundaries of multimodal reasoning.", "published": "2025-06-20 14:57:41", "link": "http://arxiv.org/abs/2506.17046v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MAWIFlow Benchmark: Realistic Flow-Based Evaluation for Network Intrusion Detection", "abstract": "Benchmark datasets for network intrusion detection commonly rely on\nsynthetically generated traffic, which fails to reflect the statistical\nvariability and temporal drift encountered in operational environments. This\npaper introduces MAWIFlow, a flow-based benchmark derived from the MAWILAB v1.1\ndataset, designed to enable realistic and reproducible evaluation of anomaly\ndetection methods. A reproducible preprocessing pipeline is presented that\ntransforms raw packet captures into flow representations conforming to the\nCICFlowMeter format, while preserving MAWILab's original anomaly labels. The\nresulting datasets comprise temporally distinct samples from January 2011,\n2016, and 2021, drawn from trans-Pacific backbone traffic.\n  To establish reference baselines, traditional machine learning methods,\nincluding Decision Trees, Random Forests, XGBoost, and Logistic Regression, are\ncompared to a deep learning model based on a CNN-BiLSTM architecture. Empirical\nresults demonstrate that tree-based classifiers perform well on temporally\nstatic data but experience significant performance degradation over time. In\ncontrast, the CNN-BiLSTM model maintains better performance, thus showing\nimproved generalization. These findings underscore the limitations of synthetic\nbenchmarks and static models, and motivate the adoption of realistic datasets\nwith explicit temporal structure. All datasets, pipeline code, and model\nimplementations are made publicly available to foster transparency and\nreproducibility.", "published": "2025-06-20 14:51:35", "link": "http://arxiv.org/abs/2506.17041v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "LSCD: Lomb-Scargle Conditioned Diffusion for Time series Imputation", "abstract": "Time series with missing or irregularly sampled data are a persistent\nchallenge in machine learning. Many methods operate on the frequency-domain,\nrelying on the Fast Fourier Transform (FFT) which assumes uniform sampling,\ntherefore requiring prior interpolation that can distort the spectra. To\naddress this limitation, we introduce a differentiable Lomb--Scargle layer that\nenables a reliable computation of the power spectrum of irregularly sampled\ndata. We integrate this layer into a novel score-based diffusion model (LSCD)\nfor time series imputation conditioned on the entire signal spectrum.\nExperiments on synthetic and real-world benchmarks demonstrate that our method\nrecovers missing data more accurately than purely time-domain baselines, while\nsimultaneously producing consistent frequency estimates. Crucially, our method\ncan be easily integrated into learning frameworks, enabling broader adoption of\nspectral guidance in machine learning approaches involving incomplete or\nirregular data.", "published": "2025-06-20 14:48:42", "link": "http://arxiv.org/abs/2506.17039v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Bayesian Joint Model of Multi-Sensor and Failure Event Data for Multi-Mode Failure Prediction", "abstract": "Modern industrial systems are often subject to multiple failure modes, and\ntheir conditions are monitored by multiple sensors, generating multiple\ntime-series signals. Additionally, time-to-failure data are commonly available.\nAccurately predicting a system's remaining useful life (RUL) requires\neffectively leveraging multi-sensor time-series data alongside multi-mode\nfailure event data. In most existing models, failure modes and RUL prediction\nare performed independently, ignoring the inherent relationship between these\ntwo tasks. Some models integrate multiple failure modes and event prediction\nusing black-box machine learning approaches, which lack statistical rigor and\ncannot characterize the inherent uncertainty in the model and data. This paper\nintroduces a unified approach to jointly model the multi-sensor time-series\ndata and failure time concerning multiple failure modes. This proposed model\nintegrate a Cox proportional hazards model, a Convolved Multi-output Gaussian\nProcess, and multinomial failure mode distributions in a hierarchical Bayesian\nframework with corresponding priors, enabling accurate prediction with robust\nuncertainty quantification. Posterior distributions are effectively obtained by\nVariational Bayes, and prediction is performed with Monte Carlo sampling. The\nadvantages of the proposed model is validated through extensive numerical and\ncase studies with jet-engine dataset.", "published": "2025-06-20 14:44:15", "link": "http://arxiv.org/abs/2506.17036v1", "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Critical Appraisal of Fairness Metrics in Clinical Predictive AI", "abstract": "Predictive artificial intelligence (AI) offers an opportunity to improve\nclinical practice and patient outcomes, but risks perpetuating biases if\nfairness is inadequately addressed. However, the definition of \"fairness\"\nremains unclear. We conducted a scoping review to identify and critically\nappraise fairness metrics for clinical predictive AI. We defined a \"fairness\nmetric\" as a measure quantifying whether a model discriminates (societally)\nagainst individuals or groups defined by sensitive attributes. We searched five\ndatabases (2014-2024), screening 820 records, to include 41 studies, and\nextracted 62 fairness metrics. Metrics were classified by\nperformance-dependency, model output level, and base performance metric,\nrevealing a fragmented landscape with limited clinical validation and\noverreliance on threshold-dependent measures. Eighteen metrics were explicitly\ndeveloped for healthcare, including only one clinical utility metric. Our\nfindings highlight conceptual challenges in defining and quantifying fairness\nand identify gaps in uncertainty quantification, intersectionality, and\nreal-world applicability. Future work should prioritise clinically meaningful\nmetrics.", "published": "2025-06-20 14:43:36", "link": "http://arxiv.org/abs/2506.17035v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Scalable and Reliable Multi-agent Reinforcement Learning for Traffic Assignment", "abstract": "The evolution of metropolitan cities and the increase in travel demands\nimpose stringent requirements on traffic assignment methods. Multi-agent\nreinforcement learning (MARL) approaches outperform traditional methods in\nmodeling adaptive routing behavior without requiring explicit system dynamics,\nwhich is beneficial for real-world deployment. However, MARL frameworks face\nchallenges in scalability and reliability when managing extensive networks with\nsubstantial travel demand, which limiting their practical applicability in\nsolving large-scale traffic assignment problems. To address these challenges,\nthis study introduces MARL-OD-DA, a new MARL framework for the traffic\nassignment problem, which redefines agents as origin-destination (OD) pair\nrouters rather than individual travelers, significantly enhancing scalability.\nAdditionally, a Dirichlet-based action space with action pruning and a reward\nfunction based on the local relative gap are designed to enhance solution\nreliability and improve convergence efficiency. Experiments demonstrate that\nthe proposed MARL framework effectively handles medium-sized networks with\nextensive and varied city-level OD demand, surpassing existing MARL methods.\nWhen implemented in the SiouxFalls network, MARL-OD-DA achieves better\nassignment solutions in 10 steps, with a relative gap that is 94.99% lower than\nthat of conventional methods.", "published": "2025-06-20 14:25:23", "link": "http://arxiv.org/abs/2506.17029v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Quantile Regression Approach for Remaining Useful Life Estimation with State Space Models", "abstract": "Predictive Maintenance (PdM) is pivotal in Industry 4.0 and 5.0, proactively\nenhancing efficiency through accurate equipment Remaining Useful Life (RUL)\nprediction, thus optimizing maintenance scheduling and reducing unexpected\nfailures and premature interventions. This paper introduces a novel RUL\nestimation approach leveraging State Space Models (SSM) for efficient long-term\nsequence modeling. To handle model uncertainty, Simoultaneous Quantile\nRegression (SQR) is integrated into the SSM, enabling multiple quantile\nestimations. The proposed method is benchmarked against traditional sequence\nmodelling techniques (LSTM, Transformer, Informer) using the C-MAPSS dataset.\nResults demonstrate superior accuracy and computational efficiency of SSM\nmodels, underscoring their potential for high-stakes industrial applications.", "published": "2025-06-20 14:15:55", "link": "http://arxiv.org/abs/2506.17018v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "The Hidden Cost of an Image: Quantifying the Energy Consumption of AI Image Generation", "abstract": "With the growing adoption of AI image generation, in conjunction with the\never-increasing environmental resources demanded by AI, we are urged to answer\na fundamental question: What is the environmental impact hidden behind each\nimage we generate? In this research, we present a comprehensive empirical\nexperiment designed to assess the energy consumption of AI image generation.\nOur experiment compares 17 state-of-the-art image generation models by\nconsidering multiple factors that could affect their energy consumption, such\nas model quantization, image resolution, and prompt length. Additionally, we\nconsider established image quality metrics to study potential trade-offs\nbetween energy consumption and generated image quality. Results show that image\ngeneration models vary drastically in terms of the energy they consume, with up\nto a 46x difference. Image resolution affects energy consumption\ninconsistently, ranging from a 1.3x to 4.7x increase when doubling resolution.\nU-Net-based models tend to consume less than Transformer-based one. Model\nquantization instead results to deteriorate the energy efficiency of most\nmodels, while prompt length and content have no statistically significant\nimpact. Improving image quality does not always come at the cost of a higher\nenergy consumption, with some of the models producing the highest quality\nimages also being among the most energy efficient ones.", "published": "2025-06-20 14:13:52", "link": "http://arxiv.org/abs/2506.17016v1", "categories": ["cs.LG", "cs.MM"], "primary_category": "cs.LG"}
{"title": "Simulating Correlated Electrons with Symmetry-Enforced Normalizing Flows", "abstract": "We present the first proof of principle that normalizing flows can accurately\nlearn the Boltzmann distribution of the fermionic Hubbard model - a key\nframework for describing the electronic structure of graphene and related\nmaterials. State-of-the-art methods like Hybrid Monte Carlo often suffer from\nergodicity issues near the time-continuum limit, leading to biased estimates.\nLeveraging symmetry-aware architectures as well as independent and identically\ndistributed sampling, our approach resolves these issues and achieves\nsignificant speed-ups over traditional methods.", "published": "2025-06-20 14:13:47", "link": "http://arxiv.org/abs/2506.17015v1", "categories": ["cond-mat.str-el", "cs.LG", "hep-lat"], "primary_category": "cond-mat.str-el"}
{"title": "Robust Reinforcement Learning for Discrete Compositional Generation via General Soft Operators", "abstract": "A major bottleneck in scientific discovery involves narrowing a large\ncombinatorial set of objects, such as proteins or molecules, to a small set of\npromising candidates. While this process largely relies on expert knowledge,\nrecent methods leverage reinforcement learning (RL) to enhance this filtering.\nThey achieve this by estimating proxy reward functions from available datasets\nand using regularization to generate more diverse candidates. These reward\nfunctions are inherently uncertain, raising a particularly salient challenge\nfor scientific discovery. In this work, we show that existing methods, often\nframed as sampling proportional to a reward function, are inadequate and yield\nsuboptimal candidates, especially in large search spaces. To remedy this issue,\nwe take a robust RL approach and introduce a unified operator that seeks\nrobustness to the uncertainty of the proxy reward function. This general\noperator targets peakier sampling distributions while encompassing known soft\nRL operators. It also leads us to a novel algorithm that identifies\nhigher-quality, diverse candidates in both synthetic and real-world tasks.\nUltimately, our work offers a new, flexible perspective on discrete\ncompositional generation tasks. Code: https://github.com/marcojira/tgm.", "published": "2025-06-20 14:03:17", "link": "http://arxiv.org/abs/2506.17007v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Language Bottleneck Models: A Framework for Interpretable Knowledge Tracing and Beyond", "abstract": "Accurately assessing student knowledge is critical for effective education,\nyet traditional Knowledge Tracing (KT) methods rely on opaque latent\nembeddings, limiting interpretability. Even LLM-based approaches generate\ndirect predictions or summaries that may hallucinate without any accuracy\nguarantees. We recast KT as an inverse problem: learning the minimum\nnatural-language summary that makes past answers explainable and future answers\npredictable. Our Language Bottleneck Model (LBM) consists of an encoder LLM\nthat writes an interpretable knowledge summary and a frozen decoder LLM that\nmust reconstruct and predict student responses using only that summary text. By\nconstraining all predictive information to pass through a short\nnatural-language bottleneck, LBMs ensure that the summary contains accurate\ninformation while remaining human-interpretable. Experiments on synthetic\narithmetic benchmarks and the large-scale Eedi dataset show that LBMs rival the\naccuracy of state-of-the-art KT and direct LLM methods while requiring\norders-of-magnitude fewer student trajectories. We demonstrate that training\nthe encoder with group-relative policy optimization, using downstream decoding\naccuracy as a reward signal, effectively improves summary quality.", "published": "2025-06-20 13:21:14", "link": "http://arxiv.org/abs/2506.16982v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Latent Concept Disentanglement in Transformer-based Language Models", "abstract": "When large language models (LLMs) use in-context learning (ICL) to solve a\nnew task, they seem to grasp not only the goal of the task but also core,\nlatent concepts in the demonstration examples. This begs the question of\nwhether transformers represent latent structures as part of their computation\nor whether they take shortcuts to solve the problem. Prior mechanistic work on\nICL does not address this question because it does not sufficiently examine the\nrelationship between the learned representation and the latent concept, and the\nconsidered problem settings often involve only single-step reasoning. In this\nwork, we examine how transformers disentangle and use latent concepts. We show\nthat in 2-hop reasoning tasks with a latent, discrete concept, the model\nsuccessfully identifies the latent concept and does step-by-step concept\ncomposition. In tasks parameterized by a continuous latent concept, we find\nlow-dimensional subspaces in the representation space where the geometry mimics\nthe underlying parameterization. Together, these results refine our\nunderstanding of ICL and the representation of transformers, and they provide\nevidence for highly localized structures in the model that disentangle latent\nconcepts in ICL tasks.", "published": "2025-06-20 13:08:12", "link": "http://arxiv.org/abs/2506.16975v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RocketStack: A level-aware deep recursive ensemble learning framework with exploratory feature fusion and model pruning dynamics", "abstract": "Ensemble learning remains a cornerstone of machine learning, with stacking\nused to integrate predictions from multiple base learners through a meta-model.\nHowever, deep stacking remains rare, as most designs prioritize horizontal\ndiversity over recursive depth due to model complexity, feature redundancy, and\ncomputational burden. To address these challenges, RocketStack, a level-aware\nrecursive ensemble framework, is introduced and explored up to ten stacking\nlevels, extending beyond prior architectures. The framework incrementally\nprunes weaker learners at each level, enabling deeper stacking without\nexcessive complexity. To mitigate early performance saturation, mild Gaussian\nnoise is added to out-of-fold (OOF) scores before pruning, and compared against\nstrict OOF pruning. Further both per-level and periodic feature compressions\nare explored using attention-based selection, Simple, Fast, Efficient (SFE)\nfilter, and autoencoders. Across 33 datasets (23 binary, 10 multi-class),\nlinear-trend tests confirmed rising accuracy with depth in most variants, and\nthe top performing meta-model at each level increasingly outperformed the\nstrongest standalone ensemble. In the binary subset, periodic SFE with mild\nOOF-score randomization reached 97.08% at level 10, 5.14% above the\nstrict-pruning configuration and cut runtime by 10.5% relative to no\ncompression. In the multi-class subset, periodic attention selection reached\n98.60% at level 10, exceeding the strongest baseline by 6.11%, while reducing\nruntime by 56.1% and feature dimensionality by 74% compared to no compression.\nThese findings highlight mild randomization as an effective regularizer and\nperiodic compression as a stabilizer. Echoing the design of multistage rockets\nin aerospace (prune, compress, propel) RocketStack achieves deep recursive\nensembling with tractable complexity.", "published": "2025-06-20 12:52:44", "link": "http://arxiv.org/abs/2506.16965v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Enhancing Expressivity of Quantum Neural Networks Based on the SWAP test", "abstract": "Parameterized quantum circuits represent promising architectures for machine\nlearning applications, yet many lack clear connections to classical models,\npotentially limiting their ability to translate the wide success of classical\nneural networks to the quantum realm. We examine a specific type of quantum\nneural network (QNN) built exclusively from SWAP test circuits, and discuss its\nmathematical equivalence to a classical two-layer feedforward network with\nquadratic activation functions under amplitude encoding. Our analysis across\nclassical real-world and synthetic datasets reveals that while this\narchitecture can successfully learn many practical tasks, it exhibits\nfundamental expressivity limitations due to violating the universal\napproximation theorem, particularly failing on harder problems like the parity\ncheck function. To address this limitation, we introduce a circuit modification\nusing generalized SWAP test circuits that effectively implements classical\nneural networks with product layers. This enhancement enables successful\nlearning of parity check functions in arbitrary dimensions which we\nanalytically argue to be impossible for the original architecture beyond two\ndimensions regardless of network size. Our results establish a framework for\nenhancing QNN expressivity through classical task analysis and demonstrate that\nour SWAP test-based architecture offers broad representational capacity,\nsuggesting potential promise also for quantum learning tasks.", "published": "2025-06-20 12:05:31", "link": "http://arxiv.org/abs/2506.16938v1", "categories": ["quant-ph", "cs.ET", "cs.LG"], "primary_category": "quant-ph"}
{"title": "A deep learning and machine learning approach to predict neonatal death in the context of S\u00e3o Paulo", "abstract": "Neonatal death is still a concerning reality for underdeveloped and even some\ndeveloped countries. Worldwide data indicate that 26.693 babies out of 1,000\nbirths die, according to Macro Trades. To reduce this number, early prediction\nof endangered babies is crucial. Such prediction enables the opportunity to\ntake ample care of the child and mother so that early child death can be\navoided. In this context, machine learning was used to determine whether a\nnewborn baby is at risk. To train the predictive model, historical data of 1.4\nmillion newborns was used. Machine learning and deep learning techniques such\nas logical regression, K-nearest neighbor, random forest classifier, extreme\ngradient boosting (XGBoost), convolutional neural network, and long short-term\nmemory (LSTM) were implemented using the dataset to identify the most accurate\nmodel for predicting neonatal mortality. Among the machine learning algorithms,\nXGBoost and random forest classifier achieved the best accuracy with 94%, while\namong the deep learning models, LSTM delivered the highest accuracy with 99%.\nTherefore, using LSTM appears to be the most suitable approach to predict\nwhether precautionary measures for a child are necessary.", "published": "2025-06-20 11:44:48", "link": "http://arxiv.org/abs/2506.16929v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Neural Operator based Hybrid Microscale Model for Multiscale Simulation of Rate-Dependent Materials", "abstract": "The behavior of materials is influenced by a wide range of phenomena\noccurring across various time and length scales. To better understand the\nimpact of microstructure on macroscopic response, multiscale modeling\nstrategies are essential. Numerical methods, such as the $\\text{FE}^2$\napproach, account for micro-macro interactions to predict the global response\nin a concurrent manner. However, these methods are computationally intensive\ndue to the repeated evaluations of the microscale. This challenge has led to\nthe integration of deep learning techniques into computational homogenization\nframeworks to accelerate multiscale simulations. In this work, we employ neural\noperators to predict the microscale physics, resulting in a hybrid model that\ncombines data-driven and physics-based approaches. This allows for\nphysics-guided learning and provides flexibility for different materials and\nspatial discretizations. We apply this method to time-dependent solid mechanics\nproblems involving viscoelastic material behavior, where the state is\nrepresented by internal variables only at the microscale. The constitutive\nrelations of the microscale are incorporated into the model architecture and\nthe internal variables are computed based on established physical principles.\nThe results for homogenized stresses ($<6\\%$ error) show that the approach is\ncomputationally efficient ($\\sim 100 \\times$ faster).", "published": "2025-06-20 11:25:26", "link": "http://arxiv.org/abs/2506.16918v1", "categories": ["physics.comp-ph", "cs.CE", "cs.LG"], "primary_category": "physics.comp-ph"}
{"title": "From Data to Knowledge: Evaluating How Efficiently Language Models Learn Facts", "abstract": "Sample efficiency is a crucial property of language models with practical\nimplications for training efficiency. In real-world text, information follows a\nlong-tailed distribution. Yet, we expect models to learn and recall frequent\nand infrequent facts. Sample-efficient models are better equipped to handle\nthis challenge of learning and retaining rare information without requiring\nexcessive exposure. This study analyzes multiple models of varying\narchitectures and sizes, all trained on the same pre-training data. By\nannotating relational facts with their frequencies in the training corpus, we\nexamine how model performance varies with fact frequency. Our findings show\nthat most models perform similarly on high-frequency facts but differ notably\non low-frequency facts. This analysis provides new insights into the\nrelationship between model architecture, size, and factual learning efficiency.", "published": "2025-06-20 11:10:24", "link": "http://arxiv.org/abs/2506.16912v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RCNet: $\u0394\u03a3$ IADCs as Recurrent AutoEncoders", "abstract": "This paper proposes a deep learning model (RCNet) for Delta-Sigma\n($\\Delta\\Sigma$) ADCs. Recurrent Neural Networks (RNNs) allow to describe both\nmodulators and filters. This analogy is applied to Incremental ADCs (IADC).\nHigh-end optimizers combined with full-custom losses are used to define\nadditional hardware design constraints: quantized weights, signal saturation,\ntemporal noise injection, devices area. Focusing on DC conversion, our early\nresults demonstrate that $SNR$ defined as an Effective Number Of Bits (ENOB)\ncan be optimized under a certain hardware mapping complexity. The proposed\nRCNet succeeded to provide design tradeoffs in terms of $SNR$ ($>$13bit) versus\narea constraints ($<$14pF total capacitor) at a given $OSR$ (80 samples).\nInterestingly, it appears that the best RCNet architectures do not necessarily\nrely on high-order modulators, leveraging additional topology exploration\ndegrees of freedom.", "published": "2025-06-20 10:55:01", "link": "http://arxiv.org/abs/2506.16903v1", "categories": ["cs.AR", "cs.LG"], "primary_category": "cs.AR"}
{"title": "The Importance of Being Lazy: Scaling Limits of Continual Learning", "abstract": "Despite recent efforts, neural networks still struggle to learn in\nnon-stationary environments, and our understanding of catastrophic forgetting\n(CF) is far from complete. In this work, we perform a systematic study on the\nimpact of model scale and the degree of feature learning in continual learning.\nWe reconcile existing contradictory observations on scale in the literature, by\ndifferentiating between lazy and rich training regimes through a variable\nparameterization of the architecture. We show that increasing model width is\nonly beneficial when it reduces the amount of feature learning, yielding more\nlaziness. Using the framework of dynamical mean field theory, we then study the\ninfinite width dynamics of the model in the feature learning regime and\ncharacterize CF, extending prior theoretical results limited to the lazy\nregime. We study the intricate relationship between feature learning, task\nnon-stationarity, and forgetting, finding that high feature learning is only\nbeneficial with highly similar tasks. We identify a transition modulated by\ntask similarity where the model exits an effectively lazy regime with low\nforgetting to enter a rich regime with significant forgetting. Finally, our\nfindings reveal that neural networks achieve optimal performance at a critical\nlevel of feature learning, which depends on task non-stationarity and transfers\nacross model scales. This work provides a unified perspective on the role of\nscale and feature learning in continual learning.", "published": "2025-06-20 10:12:38", "link": "http://arxiv.org/abs/2506.16884v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Optimal Depth of Neural Networks", "abstract": "Determining the optimal depth of a neural network is a fundamental yet\nchallenging problem, typically resolved through resource-intensive\nexperimentation. This paper introduces a formal theoretical framework to\naddress this question by recasting the forward pass of a deep network,\nspecifically a Residual Network (ResNet), as an optimal stopping problem. We\nmodel the layer-by-layer evolution of hidden representations as a sequential\ndecision process where, at each layer, a choice is made between halting\ncomputation to make a prediction or continuing to a deeper layer for a\npotentially more refined representation. This formulation captures the\nintrinsic trade-off between accuracy and computational cost. Our primary\ntheoretical contribution is a proof that, under a plausible condition of\ndiminishing returns on the residual functions, the expected optimal stopping\ndepth is provably finite, even in an infinite-horizon setting. We leverage this\ninsight to propose a novel and practical regularization term, $\\mathcal{L}_{\\rm\ndepth}$, that encourages the network to learn representations amenable to\nefficient, early exiting. We demonstrate the generality of our framework by\nextending it to the Transformer architecture and exploring its connection to\ncontinuous-depth models via free-boundary problems. Empirical validation on\nImageNet confirms that our regularizer successfully induces the theoretically\npredicted behavior, leading to significant gains in computational efficiency\nwithout compromising, and in some cases improving, final model accuracy.", "published": "2025-06-20 09:26:01", "link": "http://arxiv.org/abs/2506.16862v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Anomaly Detection in Event-triggered Traffic Time Series via Similarity Learning", "abstract": "Time series analysis has achieved great success in cyber security such as\nintrusion detection and device identification. Learning similarities among\nmultiple time series is a crucial problem since it serves as the foundation for\ndownstream analysis. Due to the complex temporal dynamics of the\nevent-triggered time series, it often remains unclear which similarity metric\nis appropriate for security-related tasks, such as anomaly detection and\nclustering. The overarching goal of this paper is to develop an unsupervised\nlearning framework that is capable of learning similarities among a set of\nevent-triggered time series. From the machine learning vantage point, the\nproposed framework harnesses the power of both hierarchical multi-resolution\nsequential autoencoders and the Gaussian Mixture Model (GMM) to effectively\nlearn the low-dimensional representations from the time series. Finally, the\nobtained similarity measure can be easily visualized for the explanation. The\nproposed framework aspires to offer a stepping stone that gives rise to a\nsystematic approach to model and learn similarities among a multitude of\nevent-triggered time series. Through extensive qualitative and quantitative\nexperiments, it is revealed that the proposed method outperforms\nstate-of-the-art methods considerably.", "published": "2025-06-20 09:09:04", "link": "http://arxiv.org/abs/2506.16855v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Reward-Agnostic Prompt Optimization for Text-to-Image Diffusion Models", "abstract": "We investigate a general approach for improving user prompts in text-to-image\n(T2I) diffusion models by finding prompts that maximize a reward function\nspecified at test-time. Although diverse reward models are used for evaluating\nimage generation, existing automated prompt engineering methods typically\ntarget specific reward configurations. Consequently, these specialized designs\nexhibit suboptimal performance when applied to new prompt engineering scenarios\ninvolving different reward models. To address this limitation, we introduce\nRATTPO (Reward-Agnostic Test-Time Prompt Optimization), a flexible test-time\noptimization method applicable across various reward scenarios without\nmodification. RATTPO iteratively searches for optimized prompts by querying\nlarge language models (LLMs) \\textit{without} requiring reward-specific task\ndescriptions. Instead, it uses the optimization trajectory and a novel\nreward-aware feedback signal (termed a \"hint\") as context. Empirical results\ndemonstrate the versatility of RATTPO, effectively enhancing user prompts\nacross diverse reward setups that assess various generation aspects, such as\naesthetics, general human preference, or spatial relationships between objects.\nRATTPO surpasses other test-time search baselines in search efficiency, using\nup to 3.5 times less inference budget, and, given sufficient inference budget,\nachieves performance comparable to learning-based baselines that require\nreward-specific fine-tuning. The code is available at\nhttps://github.com/seminkim/RATTPO.", "published": "2025-06-20 09:02:05", "link": "http://arxiv.org/abs/2506.16853v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Soft decision trees for survival analysis", "abstract": "Decision trees are popular in survival analysis for their interpretability\nand ability to model complex relationships. Survival trees, which predict the\ntiming of singular events using censored historical data, are typically built\nthrough heuristic approaches. Recently, there has been growing interest in\nglobally optimized trees, where the overall tree is trained by minimizing the\nerror function over all its parameters. We propose a new soft survival tree\nmodel (SST), with a soft splitting rule at each branch node, trained via a\nnonlinear optimization formulation amenable to decomposition. Since SSTs\nprovide for every input vector a specific survival function associated to a\nsingle leaf node, they satisfy the conditional computation property and inherit\nthe related benefits. SST and the training formulation combine flexibility with\ninterpretability: any smooth survival function (parametric, semiparametric, or\nnonparametric) estimated through maximum likelihood can be used, and each leaf\nnode of an SST yields a cluster of distinct survival functions which are\nassociated to the data points routed to it. Numerical experiments on 15\nwell-known datasets show that SSTs, with parametric and spline-based\nsemiparametric survival functions, trained using an adaptation of the\nnode-based decomposition algorithm proposed by Consolo et al. (2024) for soft\nregression trees, outperform three benchmark survival trees in terms of four\nwidely-used discrimination and calibration measures. SSTs can also be extended\nto consider group fairness.", "published": "2025-06-20 08:51:33", "link": "http://arxiv.org/abs/2506.16846v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Bandwidth Selectors on Semiparametric Bayesian Networks", "abstract": "Semiparametric Bayesian networks (SPBNs) integrate parametric and\nnon-parametric probabilistic models, offering flexibility in learning complex\ndata distributions from samples. In particular, kernel density estimators\n(KDEs) are employed for the non-parametric component. Under the assumption of\ndata normality, the normal rule is used to learn the bandwidth matrix for the\nKDEs in SPBNs. This matrix is the key hyperparameter that controls the\ntrade-off between bias and variance. However, real-world data often deviates\nfrom normality, potentially leading to suboptimal density estimation and\nreduced predictive performance. This paper first establishes the theoretical\nframework for the application of state-of-the-art bandwidth selectors and\nsubsequently evaluates their impact on SPBN performance. We explore the\napproaches of cross-validation and plug-in selectors, assessing their\neffectiveness in enhancing the learning capability and applicability of SPBNs.\nTo support this investigation, we have extended the open-source package\nPyBNesian for SPBNs with the additional bandwidth selection techniques and\nconducted extensive experimental analyses. Our results demonstrate that the\nproposed bandwidth selectors leverage increasing information more effectively\nthan the normal rule, which, despite its robustness, stagnates with more data.\nIn particular, unbiased cross-validation generally outperforms the normal rule,\nhighlighting its advantage in high sample size scenarios.", "published": "2025-06-20 08:48:05", "link": "http://arxiv.org/abs/2506.16844v1", "categories": ["cs.LG", "cs.AI", "stat.ML", "I.2.6; I.5.1; G.3"], "primary_category": "cs.LG"}
{"title": "FedFitTech: A Baseline in Federated Learning for Fitness Tracking", "abstract": "Rapid evolution of sensors and resource-efficient machine learning models\nhave spurred the widespread adoption of wearable fitness tracking devices.\nEquipped with inertial sensors, such devices can continuously capture physical\nmovements for fitness technology (FitTech), enabling applications from sports\noptimization to preventive healthcare. Traditional centralized learning\napproaches to detect fitness activities struggle with privacy concerns,\nregulatory constraints, and communication inefficiencies. In contrast,\nFederated Learning (FL) enables a decentralized model training by communicating\nmodel updates rather than private wearable sensor data. Applying FL to FitTech\npresents unique challenges, such as data imbalance, lack of labelled data,\nheterogeneous user activity patterns, and trade-offs between personalization\nand generalization. To simplify research on FitTech in FL, we present the\nFedFitTech baseline, under the Flower framework, which is publicly available\nand widely used by both industry and academic researchers. Additionally, to\nillustrate its usage, this paper presents a case study that implements a system\nbased on the FedFitTech baseline, incorporating a client-side early stopping\nstrategy and comparing the results. For instance, this system allows wearable\ndevices to optimize the trade-off between capturing common fitness activity\npatterns and preserving individuals' nuances, thereby enhancing both the\nscalability and efficiency of privacy-aware fitness tracking applications.\nResults show that this reduces overall redundant communications by 13 percent,\nwhile maintaining the overall recognition performance at a negligible\nrecognition cost by 1 percent. Thus, FedFitTech baseline creates a foundation\nfor a wide range of new research and development opportunities in FitTech, and\nit is available as open-source at:\nhttps://github.com/adap/flower/tree/main/baselines/fedfittech", "published": "2025-06-20 08:43:39", "link": "http://arxiv.org/abs/2506.16840v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Predicting New Research Directions in Materials Science using Large Language Models and Concept Graphs", "abstract": "Due to an exponential increase in published research articles, it is\nimpossible for individual scientists to read all publications, even within\ntheir own research field. In this work, we investigate the use of large\nlanguage models (LLMs) for the purpose of extracting the main concepts and\nsemantic information from scientific abstracts in the domain of materials\nscience to find links that were not noticed by humans and thus to suggest\ninspiring near/mid-term future research directions. We show that LLMs can\nextract concepts more efficiently than automated keyword extraction methods to\nbuild a concept graph as an abstraction of the scientific literature. A machine\nlearning model is trained to predict emerging combinations of concepts, i.e.\nnew research ideas, based on historical data. We demonstrate that integrating\nsemantic concept information leads to an increased prediction performance. The\napplicability of our model is demonstrated in qualitative interviews with\ndomain experts based on individualized model suggestions. We show that the\nmodel can inspire materials scientists in their creative thinking process by\npredicting innovative combinations of topics that have not yet been\ninvestigated.", "published": "2025-06-20 08:26:12", "link": "http://arxiv.org/abs/2506.16824v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Robust Group Anomaly Detection for Quasi-Periodic Network Time Series", "abstract": "Many real-world multivariate time series are collected from a network of\nphysical objects embedded with software, electronics, and sensors. The\nquasi-periodic signals generated by these objects often follow a similar\nrepetitive and periodic pattern, but have variations in the period, and come in\ndifferent lengths caused by timing (synchronization) errors. Given a multitude\nof such quasi-periodic time series, can we build machine learning models to\nidentify those time series that behave differently from the majority of the\nobservations? In addition, can the models help human experts to understand how\nthe decision was made? We propose a sequence to Gaussian Mixture Model\n(seq2GMM) framework. The overarching goal of this framework is to identify\nunusual and interesting time series within a network time series database. We\nfurther develop a surrogate-based optimization algorithm that can efficiently\ntrain the seq2GMM model. Seq2GMM exhibits strong empirical performance on a\nplurality of public benchmark datasets, outperforming state-of-the-art anomaly\ndetection techniques by a significant margin. We also theoretically analyze the\nconvergence property of the proposed training algorithm and provide numerical\nresults to substantiate our theoretical claims.", "published": "2025-06-20 08:11:04", "link": "http://arxiv.org/abs/2506.16815v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "TabArena: A Living Benchmark for Machine Learning on Tabular Data", "abstract": "With the growing popularity of deep learning and foundation models for\ntabular data, the need for standardized and reliable benchmarks is higher than\never. However, current benchmarks are static. Their design is not updated even\nif flaws are discovered, model versions are updated, or new models are\nreleased. To address this, we introduce TabArena, the first continuously\nmaintained living tabular benchmarking system. To launch TabArena, we manually\ncurate a representative collection of datasets and well-implemented models,\nconduct a large-scale benchmarking study to initialize a public leaderboard,\nand assemble a team of experienced maintainers. Our results highlight the\ninfluence of validation method and ensembling of hyperparameter configurations\nto benchmark models at their full potential. While gradient-boosted trees are\nstill strong contenders on practical tabular datasets, we observe that deep\nlearning methods have caught up under larger time budgets with ensembling. At\nthe same time, foundation models excel on smaller datasets. Finally, we show\nthat ensembles across models advance the state-of-the-art in tabular machine\nlearning and investigate the contributions of individual models. We launch\nTabArena with a public leaderboard, reproducible code, and maintenance\nprotocols to create a living benchmark available at https://tabarena.ai.", "published": "2025-06-20 07:14:48", "link": "http://arxiv.org/abs/2506.16791v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Exploring and Improving Initialization for Deep Graph Neural Networks: A Signal Propagation Perspective", "abstract": "Graph Neural Networks (GNNs) often suffer from performance degradation as the\nnetwork depth increases. This paper addresses this issue by introducing\ninitialization methods that enhance signal propagation (SP) within GNNs. We\npropose three key metrics for effective SP in GNNs: forward propagation,\nbackward propagation, and graph embedding variation (GEV). While the first two\nmetrics derive from classical SP theory, the third is specifically designed for\nGNNs. We theoretically demonstrate that a broad range of commonly used\ninitialization methods for GNNs, which exhibit performance degradation with\nincreasing depth, fail to control these three metrics simultaneously. To deal\nwith this limitation, a direct exploitation of the SP analysis--searching for\nweight initialization variances that optimize the three metrics--is shown to\nsignificantly enhance the SP in deep GCNs. This approach is called Signal\nPropagation on Graph-guided Initialization (SPoGInit). Our experiments\ndemonstrate that SPoGInit outperforms commonly used initialization methods on\nvarious tasks and architectures. Notably, SPoGInit enables performance\nimprovements as GNNs deepen, which represents a significant advancement in\naddressing depth-related challenges and highlights the validity and\neffectiveness of the SP analysis framework.", "published": "2025-06-20 07:14:31", "link": "http://arxiv.org/abs/2506.16790v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Revisiting LoRA through the Lens of Parameter Redundancy: Spectral Encoding Helps", "abstract": "Low-Rank Adaptation (LoRA) has emerged as a prominent technique for\nfine-tuning large foundation models. Despite its successes, the substantial\nparameter redundancy, which limits the capacity and efficiency of LoRA, has\nbeen recognized as a bottleneck. In this work, we systematically investigate\nthe impact of redundancy in fine-tuning LoRA and reveal that reducing density\nredundancy does not degrade expressiveness. Based on this insight, we introduce\n\\underline{S}pectral-\\underline{e}ncoding \\underline{L}ow-\\underline{R}ank\n\\underline{A}daptation (SeLoRA), which harnesses the robust expressiveness of\nspectral bases to re-parameterize LoRA from a sparse spectral subspace.\nDesigned with simplicity, SeLoRA enables seamless integration with various LoRA\nvariants for performance boosting, serving as a scalable plug-and-play\nframework. Extensive experiments substantiate that SeLoRA achieves greater\nefficiency with fewer parameters, delivering superior performance enhancements\nover strong baselines on various downstream tasks, including commonsense\nreasoning, math reasoning, and code generation.", "published": "2025-06-20 07:09:05", "link": "http://arxiv.org/abs/2506.16787v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "What Is the Point of Equality in Machine Learning Fairness? Beyond Equality of Opportunity", "abstract": "Fairness in machine learning (ML) has become a rapidly growing area of\nresearch. But why, in the first place, is unfairness in ML morally wrong? And\nwhy should we care about improving fairness? Most fair-ML research implicitly\nappeals to distributive equality: the idea that desirable goods and benefits,\nsuch as opportunities (e.g., Barocas et al., 2023), should be equally\ndistributed across society. Unfair ML models, then, are seen as wrong because\nthey unequally distribute such benefits. This paper argues that this exclusive\nfocus on distributive equality offers an incomplete and potentially misleading\nethical foundation. Grounding ML fairness in egalitarianism -- the view that\nequality is a fundamental moral and social ideal -- requires challenging\nstructural inequality: systematic, institutional, and durable arrangements that\nprivilege some groups while disadvantaging others. Structural inequality\nmanifests through ML systems in two primary forms: allocative harms (e.g.,\neconomic loss) and representational harms (e.g., stereotypes, erasure). While\ndistributive equality helps address allocative harms, it fails to explain why\nrepresentational harms are wrong -- why it is wrong for ML systems to reinforce\nsocial hierarchies that stratify people into superior and inferior groups --\nand why ML systems should aim to foster a society where people relate as equals\n(i.e., relational equality). To address these limitations, the paper proposes a\nmultifaceted egalitarian framework for ML fairness that integrates both\ndistributive and relational equality. Drawing on critical social and political\nphilosophy, this framework offers a more comprehensive ethical foundation for\ntackling the full spectrum of harms perpetuated by ML systems. The paper also\noutlines practical pathways for implementing the framework across the ML\npipeline.", "published": "2025-06-20 06:57:53", "link": "http://arxiv.org/abs/2506.16782v1", "categories": ["cs.LG", "cs.AI", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Metapath-based Hyperbolic Contrastive Learning for Heterogeneous Graph Embedding", "abstract": "The hyperbolic space, characterized by a constant negative curvature and\nexponentially expanding space, aligns well with the structural properties of\nheterogeneous graphs. However, although heterogeneous graphs inherently possess\ndiverse power-law structures, most hyperbolic heterogeneous graph embedding\nmodels rely on a single hyperbolic space. This approach may fail to effectively\ncapture the diverse power-law structures within heterogeneous graphs. To\naddress this limitation, we propose a Metapath-based Hyperbolic Contrastive\nLearning framework (MHCL), which uses multiple hyperbolic spaces to capture\ndiverse complex structures within heterogeneous graphs. Specifically, by\nlearning each hyperbolic space to describe the distribution of complex\nstructures corresponding to each metapath, it is possible to capture semantic\ninformation effectively. Since metapath embeddings represent distinct semantic\ninformation, preserving their discriminability is important when aggregating\nthem to obtain node representations. Therefore, we use a contrastive learning\napproach to optimize MHCL and improve the discriminability of metapath\nembeddings. In particular, our contrastive learning method minimizes the\ndistance between embeddings of the same metapath and maximizes the distance\nbetween those of different metapaths in hyperbolic space, thereby improving the\nseparability of metapath embeddings with distinct semantic information. We\nconduct comprehensive experiments to evaluate the effectiveness of MHCL. The\nexperimental results demonstrate that MHCL outperforms state-of-the-art\nbaselines in various graph machine learning tasks, effectively capturing the\ncomplex structures of heterogeneous graphs.", "published": "2025-06-20 05:19:11", "link": "http://arxiv.org/abs/2506.16754v1", "categories": ["cs.LG", "cs.AI", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Off-Policy Actor-Critic for Adversarial Observation Robustness: Virtual Alternative Training via Symmetric Policy Evaluation", "abstract": "Recently, robust reinforcement learning (RL) methods designed to handle\nadversarial input observations have received significant attention, motivated\nby RL's inherent vulnerabilities. While existing approaches have demonstrated\nreasonable success, addressing worst-case scenarios over long time horizons\nrequires both minimizing the agent's cumulative rewards for adversaries and\ntraining agents to counteract them through alternating learning. However, this\nprocess introduces mutual dependencies between the agent and the adversary,\nmaking interactions with the environment inefficient and hindering the\ndevelopment of off-policy methods. In this work, we propose a novel off-policy\nmethod that eliminates the need for additional environmental interactions by\nreformulating adversarial learning as a soft-constrained optimization problem.\nOur approach is theoretically supported by the symmetric property of policy\nevaluation between the agent and the adversary. The implementation is available\nat https://github.com/nakanakakosuke/VALT_SAC.", "published": "2025-06-20 05:13:10", "link": "http://arxiv.org/abs/2506.16753v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "IsoNet: Causal Analysis of Multimodal Transformers for Neuromuscular Gesture Classification", "abstract": "Hand gestures are a primary output of the human motor system, yet the\ndecoding of their neuromuscular signatures remains a bottleneck for basic\nneuroscience and assistive technologies such as prosthetics. Traditional\nhuman-machine interface pipelines rely on a single biosignal modality, but\nmultimodal fusion can exploit complementary information from sensors. We\nsystematically compare linear and attention-based fusion strategies across\nthree architectures: a Multimodal MLP, a Multimodal Transformer, and a\nHierarchical Transformer, evaluating performance on scenarios with unimodal and\nmultimodal inputs. Experiments use two publicly available datasets: NinaPro DB2\n(sEMG and accelerometer) and HD-sEMG 65-Gesture (high-density sEMG and force).\nAcross both datasets, the Hierarchical Transformer with attention-based fusion\nconsistently achieved the highest accuracy, surpassing the multimodal and best\nsingle-modality linear-fusion MLP baseline by over 10% on NinaPro DB2 and 3.7%\non HD-sEMG. To investigate how modalities interact, we introduce an Isolation\nNetwork that selectively silences unimodal or cross-modal attention pathways,\nquantifying each group of token interactions' contribution to downstream\ndecisions. Ablations reveal that cross-modal interactions contribute\napproximately 30% of the decision signal across transformer layers,\nhighlighting the importance of attention-driven fusion in harnessing\ncomplementary modality information. Together, these findings reveal when and\nhow multimodal fusion would enhance biosignal classification and also provides\nmechanistic insights of human muscle activities. The study would be beneficial\nin the design of sensor arrays for neurorobotic systems.", "published": "2025-06-20 04:31:32", "link": "http://arxiv.org/abs/2506.16744v1", "categories": ["cs.LG", "cs.RO", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Optimism Without Regularization: Constant Regret in Zero-Sum Games", "abstract": "This paper studies the optimistic variant of Fictitious Play for learning in\ntwo-player zero-sum games. While it is known that Optimistic FTRL -- a\nregularized algorithm with a bounded stepsize parameter -- obtains constant\nregret in this setting, we show for the first time that similar, optimal rates\nare also achievable without regularization: we prove for two-strategy games\nthat Optimistic Fictitious Play (using any tiebreaking rule) obtains only\nconstant regret, providing surprising new evidence on the ability of\nnon-no-regret algorithms for fast learning in games. Our proof technique\nleverages a geometric view of Optimistic Fictitious Play in the dual space of\npayoff vectors, where we show a certain energy function of the iterates remains\nbounded over time. Additionally, we also prove a regret lower bound of\n$\\Omega(\\sqrt{T})$ for Alternating Fictitious Play. In the unregularized\nregime, this separates the ability of optimism and alternation in achieving\n$o(\\sqrt{T})$ regret.", "published": "2025-06-20 04:10:51", "link": "http://arxiv.org/abs/2506.16736v1", "categories": ["cs.LG", "cs.GT"], "primary_category": "cs.LG"}
{"title": "Incentivizing High-quality Participation From Federated Learning Agents", "abstract": "Federated learning (FL) provides a promising paradigm for facilitating\ncollaboration between multiple clients that jointly learn a global model\nwithout directly sharing their local data. However, existing research suffers\nfrom two caveats: 1) From the perspective of agents, voluntary and unselfish\nparticipation is often assumed. But self-interested agents may opt out of the\nsystem or provide low-quality contributions without proper incentives; 2) From\nthe mechanism designer's perspective, the aggregated models can be\nunsatisfactory as the existing game-theoretical federated learning approach for\ndata collection ignores the potential heterogeneous effort caused by\ncontributed data. To alleviate above challenges, we propose an incentive-aware\nframework for agent participation that considers data heterogeneity to\naccelerate the convergence process. Specifically, we first introduce the notion\nof Wasserstein distance to explicitly illustrate the heterogeneous effort and\nreformulate the existing upper bound of convergence. To induce truthful\nreporting from agents, we analyze and measure the generalization error gap of\nany two agents by leveraging the peer prediction mechanism to develop score\nfunctions. We further present a two-stage Stackelberg game model that\nformalizes the process and examines the existence of equilibrium. Extensive\nexperiments on real-world datasets demonstrate the effectiveness of our\nproposed mechanism.", "published": "2025-06-20 03:58:39", "link": "http://arxiv.org/abs/2506.16731v1", "categories": ["cs.AI", "cs.DC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "TriCon-SF: A Triple-Shuffle and Contribution-Aware Serial Federated Learning Framework for Heterogeneous Healthcare Data", "abstract": "Serial pipeline training is an efficient paradigm for handling data\nheterogeneity in cross-silo federated learning with low communication overhead.\nHowever, even without centralized aggregation, direct transfer of models\nbetween clients can violate privacy regulations and remain susceptible to\ngradient leakage and linkage attacks. Additionally, ensuring resilience against\nsemi-honest or malicious clients who may manipulate or misuse received models\nremains a grand challenge, particularly in privacy-sensitive domains such as\nhealthcare. To address these challenges, we propose TriCon-SF, a novel serial\nfederated learning framework that integrates triple shuffling and contribution\nawareness. TriCon-SF introduces three levels of randomization by shuffling\nmodel layers, data segments, and training sequences to break deterministic\nlearning patterns and disrupt potential attack vectors, thereby enhancing\nprivacy and robustness. In parallel, it leverages Shapley value methods to\ndynamically evaluate client contributions during training, enabling the\ndetection of dishonest behavior and enhancing system accountability. Extensive\nexperiments on non-IID healthcare datasets demonstrate that TriCon-SF\noutperforms standard serial and parallel federated learning in both accuracy\nand communication efficiency. Security analysis further supports its resilience\nagainst client-side privacy attacks.", "published": "2025-06-20 03:40:35", "link": "http://arxiv.org/abs/2506.16723v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "How Many Domains Suffice for Domain Generalization? A Tight Characterization via the Domain Shattering Dimension", "abstract": "We study a fundamental question of domain generalization: given a family of\ndomains (i.e., data distributions), how many randomly sampled domains do we\nneed to collect data from in order to learn a model that performs reasonably\nwell on every seen and unseen domain in the family? We model this problem in\nthe PAC framework and introduce a new combinatorial measure, which we call the\ndomain shattering dimension. We show that this dimension characterizes the\ndomain sample complexity. Furthermore, we establish a tight quantitative\nrelationship between the domain shattering dimension and the classic VC\ndimension, demonstrating that every hypothesis class that is learnable in the\nstandard PAC setting is also learnable in our setting.", "published": "2025-06-20 02:50:14", "link": "http://arxiv.org/abs/2506.16704v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SIDE: Semantic ID Embedding for effective learning from sequences", "abstract": "Sequence-based recommendations models are driving the state-of-the-art for\nindustrial ad-recommendation systems. Such systems typically deal with user\nhistories or sequence lengths ranging in the order of O(10^3) to O(10^4)\nevents. While adding embeddings at this scale is manageable in pre-trained\nmodels, incorporating them into real-time prediction models is challenging due\nto both storage and inference costs. To address this scaling challenge, we\npropose a novel approach that leverages vector quantization (VQ) to inject a\ncompact Semantic ID (SID) as input to the recommendation models instead of a\ncollection of embeddings. Our method builds on recent works of SIDs by\nintroducing three key innovations: (i) a multi-task VQ-VAE framework, called VQ\nfusion that fuses multiple content embeddings and categorical predictions into\na single Semantic ID; (ii) a parameter-free, highly granular SID-to-embedding\nconversion technique, called SIDE, that is validated with two content embedding\ncollections, thereby eliminating the need for a large parameterized lookup\ntable; and (iii) a novel quantization method called Discrete-PCA (DPCA) which\ngeneralizes and enhances residual quantization techniques. The proposed\nenhancements when applied to a large-scale industrial ads-recommendation system\nachieves 2.4X improvement in normalized entropy (NE) gain and 3X reduction in\ndata footprint compared to traditional SID methods.", "published": "2025-06-20 02:40:38", "link": "http://arxiv.org/abs/2506.16698v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Fast and Stable Diffusion Planning through Variational Adaptive Weighting", "abstract": "Diffusion models have recently shown promise in offline RL. However, these\nmethods often suffer from high training costs and slow convergence,\nparticularly when using transformer-based denoising backbones. While several\noptimization strategies have been proposed -- such as modified noise schedules,\nauxiliary prediction targets, and adaptive loss weighting -- challenges remain\nin achieving stable and efficient training. In particular, existing loss\nweighting functions typically rely on neural network approximators, which can\nbe ineffective in early training phases due to limited generalization capacity\nof MLPs when exposed to sparse feedback in the early training stages. In this\nwork, we derive a variationally optimal uncertainty-aware weighting function\nand introduce a closed-form polynomial approximation method for its online\nestimation under the flow-based generative modeling framework. We integrate our\nmethod into a diffusion planning pipeline and evaluate it on standard offline\nRL benchmarks. Experimental results on Maze2D and Kitchen tasks show that our\nmethod achieves competitive performance with up to 10 times fewer training\nsteps, highlighting its practical effectiveness.", "published": "2025-06-20 02:12:04", "link": "http://arxiv.org/abs/2506.16688v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "The Hitchhiker's Guide to Efficient, End-to-End, and Tight DP Auditing", "abstract": "This paper systematizes research on auditing Differential Privacy (DP)\ntechniques, aiming to identify key insights into the current state of the art\nand open challenges. First, we introduce a comprehensive framework for\nreviewing work in the field and establish three cross-contextual desiderata\nthat DP audits should target--namely, efficiency, end-to-end-ness, and\ntightness. Then, we systematize the modes of operation of state-of-the-art DP\nauditing techniques, including threat models, attacks, and evaluation\nfunctions. This allows us to highlight key details overlooked by prior work,\nanalyze the limiting factors to achieving the three desiderata, and identify\nopen research problems. Overall, our work provides a reusable and systematic\nmethodology geared to assess progress in the field and identify friction points\nand future directions for our community to focus on.", "published": "2025-06-20 00:32:59", "link": "http://arxiv.org/abs/2506.16666v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Private Training & Data Generation by Clustering Embeddings", "abstract": "Deep neural networks often use large, high-quality datasets to achieve high\nperformance on many machine learning tasks. When training involves potentially\nsensitive data, this process can raise privacy concerns, as large models have\nbeen shown to unintentionally memorize and reveal sensitive information,\nincluding reconstructing entire training samples. Differential privacy (DP)\nprovides a robust framework for protecting individual data and in particular, a\nnew approach to privately training deep neural networks is to approximate the\ninput dataset with a privately generated synthetic dataset, before any\nsubsequent training algorithm. We introduce a novel principled method for DP\nsynthetic image embedding generation, based on fitting a Gaussian Mixture Model\n(GMM) in an appropriate embedding space using DP clustering. Our method\nprovably learns a GMM under separation conditions. Empirically, a simple\ntwo-layer neural network trained on synthetically generated embeddings achieves\nstate-of-the-art (SOTA) classification accuracy on standard benchmark datasets.\nAdditionally, we demonstrate that our method can generate realistic synthetic\nimages that achieve downstream classification accuracy comparable to SOTA\nmethods. Our method is quite general, as the encoder and decoder modules can be\nfreely substituted to suit different tasks. It is also highly scalable,\nconsisting only of subroutines that scale linearly with the number of samples\nand/or can be implemented efficiently in distributed systems.", "published": "2025-06-20 00:17:14", "link": "http://arxiv.org/abs/2506.16661v1", "categories": ["cs.LG", "cs.CR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Minimalist Optimizer Design for LLM Pretraining", "abstract": "Training large language models (LLMs) typically relies on adaptive optimizers\nsuch as Adam, which require significant memory to maintain first- and\nsecond-moment matrices, known as optimizer states. While recent works such as\nGaLore, Fira, and APOLLO have proposed state-compressed variants to reduce\nmemory consumption, a fundamental question remains: What is the minimal amount\nof optimizer state that is truly necessary to retain state-of-the-art\nperformance in LLM pretraining? In this work, we systematically investigate\nthis question using a bottom-up approach. We find that two memory- and\ncompute-efficient optimization techniques are particularly effective: (1)\ncolumn-wise gradient normalization significantly boosts the performance of\nplain SGD without requiring momentum; and (2) adding first-order momentum only\nto the output layer - where gradient variance is highest - yields performance\ncompetitive with fully adaptive methods such as Muon. Based on these insights,\nwe propose SCALE (Stochastic Column-normalized Last-layer Momentum), a new\noptimizer that combines column-normalized SGD with last-layer momentum, where\ncolumn normalization refers to normalizing the gradient along the output\ndimension. Across multiple LLaMA models (60M-1B), SCALE matches or exceeds the\nperformance of Adam while using only 35-45% of the total memory. It also\nconsistently outperforms memory-efficient optimizers such as GaLore, Fira, and\nAPOLLO, making it a strong candidate for large-scale pretraining under memory\nconstraints. For the LLaMA 7B model, SCALE outperforms the state-of-the-art\nmethod APOLLO in terms of both perplexity and memory consumption. In addition,\nour method serves as a minimalist baseline for more sophisticated optimizer\ndesign.", "published": "2025-06-20 00:10:35", "link": "http://arxiv.org/abs/2506.16659v1", "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "cs.LG"}
{"title": "Multi-Armed Bandits With Machine Learning-Generated Surrogate Rewards", "abstract": "Multi-armed bandit (MAB) is a widely adopted framework for sequential\ndecision-making under uncertainty. Traditional bandit algorithms rely solely on\nonline data, which tends to be scarce as it must be gathered during the online\nphase when the arms are actively pulled. However, in many practical settings,\nrich auxiliary data, such as covariates of past users, is available prior to\ndeploying any arms. We introduce a new setting for MAB where pre-trained\nmachine learning (ML) models are applied to convert side information and\nhistorical data into \\emph{surrogate rewards}. A prominent feature of this\nsetting is that the surrogate rewards may exhibit substantial bias, as true\nreward data is typically unavailable in the offline phase, forcing ML\npredictions to heavily rely on extrapolation. To address the issue, we propose\nthe Machine Learning-Assisted Upper Confidence Bound (MLA-UCB) algorithm, which\ncan be applied to any reward prediction model and any form of auxiliary data.\nWhen the predicted and true rewards are jointly Gaussian, it provably improves\nthe cumulative regret, provided that the correlation is non-zero -- even in\ncases where the mean surrogate reward completely misaligns with the true mean\nrewards. Notably, our method requires no prior knowledge of the covariance\nmatrix between true and surrogate rewards. We compare MLA-UCB with the standard\nUCB on a range of numerical studies and show a sizable efficiency gain even\nwhen the size of the offline data and the correlation between predicted and\ntrue rewards are moderate.", "published": "2025-06-20 00:09:39", "link": "http://arxiv.org/abs/2506.16658v1", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Mesh-Informed Neural Operator : A Transformer Generative Approach", "abstract": "Generative models in function spaces, situated at the intersection of\ngenerative modeling and operator learning, are attracting increasing attention\ndue to their immense potential in diverse scientific and engineering\napplications. While functional generative models are theoretically domain- and\ndiscretization-agnostic, current implementations heavily rely on the Fourier\nNeural Operator (FNO), limiting their applicability to regular grids and\nrectangular domains. To overcome these critical limitations, we introduce the\nMesh-Informed Neural Operator (MINO). By leveraging graph neural operators and\ncross-attention mechanisms, MINO offers a principled, domain- and\ndiscretization-agnostic backbone for generative modeling in function spaces.\nThis advancement significantly expands the scope of such models to more diverse\napplications in generative, inverse, and regression tasks. Furthermore, MINO\nprovides a unified perspective on integrating neural operators with general\nadvanced deep learning architectures. Finally, we introduce a suite of\nstandardized evaluation metrics that enable objective comparison of functional\ngenerative models, addressing another critical gap in the field.", "published": "2025-06-20 00:00:22", "link": "http://arxiv.org/abs/2506.16656v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Formal Control for Uncertain Systems via Contract-Based Probabilistic Surrogates (Extended Version)", "abstract": "The requirement for identifying accurate system representations has not only\nbeen a challenge to fulfill, but it has compromised the scalability of formal\nmethods, as the resulting models are often too complex for effective decision\nmaking with formal correctness and performance guarantees. Focusing on\nprobabilistic simulation relations and surrogate models of stochastic systems,\nwe propose an approach that significantly enhances the scalability and\npractical applicability of such simulation relations by eliminating the need to\ncompute error bounds directly. As a result, we provide an abstraction-based\ntechnique that scales effectively to higher dimensions while addressing complex\nnonlinear agent-environment interactions with infinite-horizon temporal logic\nguarantees amidst uncertainty. Our approach trades scalability for conservatism\nfavorably, as demonstrated on a complex high-dimensional vehicle intersection\ncase study.", "published": "2025-06-20 13:00:50", "link": "http://arxiv.org/abs/2506.16971v1", "categories": ["cs.SY", "cs.AI", "cs.MA", "eess.SY"], "primary_category": "cs.SY"}
{"title": "Engineering Resilience: An Energy-Based Approach to Sustainable Behavioural Interventions", "abstract": "Addressing complex societal challenges, such as improving public health,\nfostering honesty in workplaces, or encouraging eco-friendly behaviour requires\neffective nudges to influence human behaviour at scale. Intervention science\nseeks to design such nudges within complex societal systems. While\ninterventions primarily aim to shift the system toward a desired state, less\nattention is given to the sustainability of that state, which we define in\nterms of resilience: the system's ability to retain the desired state even\nunder perturbations. In this work, we offer a more holistic perspective to\nintervention design by incorporating a nature-inspired postulate i.e., lower\nenergy states tend to exhibit greater resilience, as a regularization mechanism\nwithin intervention optimization to ensure that the resulting state is also\nsustainable. Using a simple agent-based simulation where commuters are nudged\nto choose eco-friendly options (e.g., cycles) over individually attractive but\nless eco-friendly ones (e.g., cars), we demonstrate how embedding lower energy\npostulate into intervention design induces resilience. The system energy is\ndefined in terms of motivators that drive its agent's behaviour. By inherently\nensuring that agents are not pushed into actions that contradict their\nmotivators, the energy-based approach helps design effective interventions that\ncontribute to resilient behavioural states.", "published": "2025-06-20 08:40:39", "link": "http://arxiv.org/abs/2506.16836v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "A Scalable Post-Processing Pipeline for Large-Scale Free-Space Multi-Agent Path Planning with PiBT", "abstract": "Free-space multi-agent path planning remains challenging at large scales.\nMost existing methods either offer optimality guarantees but do not scale\nbeyond a few dozen agents, or rely on grid-world assumptions that do not\ngeneralize well to continuous space. In this work, we propose a hybrid,\nrule-based planning framework that combines Priority Inheritance with\nBacktracking (PiBT) with a novel safety-aware path smoothing method. Our\napproach extends PiBT to 8-connected grids and selectively applies\nstring-pulling based smoothing while preserving collision safety through local\ninteraction awareness and a fallback collision resolution step based on Safe\nInterval Path Planning (SIPP). This design allows us to reduce overall path\nlengths while maintaining real-time performance. We demonstrate that our method\ncan scale to over 500 agents in large free-space environments, outperforming\nexisting any-angle and optimal methods in terms of runtime, while producing\nnear-optimal trajectories in sparse domains. Our results suggest this framework\nis a promising building block for scalable, real-time multi-agent navigation in\nrobotics systems operating beyond grid constraints.", "published": "2025-06-20 04:50:35", "link": "http://arxiv.org/abs/2506.16748v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Generalizable Agent Modeling for Agent Collaboration-Competition Adaptation with Multi-Retrieval and Dynamic Generation", "abstract": "Adapting a single agent to a new multi-agent system brings challenges,\nnecessitating adjustments across various tasks, environments, and interactions\nwith unknown teammates and opponents. Addressing this challenge is highly\ncomplex, and researchers have proposed two simplified scenarios, Multi-agent\nreinforcement learning for zero-shot learning and Ad-Hoc Teamwork. Building on\nthese foundations, we propose a more comprehensive setting, Agent\nCollaborative-Competitive Adaptation (ACCA), which evaluates an agent to\ngeneralize across diverse scenarios, tasks, and interactions with both\nunfamiliar opponents and teammates. In ACCA, agents adjust to task and\nenvironmental changes, collaborate with unseen teammates, and compete against\nunknown opponents. We introduce a new modeling approach, Multi-Retrieval and\nDynamic Generation (MRDG), that effectively models both teammates and opponents\nusing their behavioral trajectories. This method incorporates a positional\nencoder for varying team sizes and a hypernetwork module to boost agents'\nlearning and adaptive capabilities. Additionally, a viewpoint alignment module\nharmonizes the observational perspectives of retrieved teammates and opponents\nwith the learning agent. Extensive tests in benchmark scenarios like SMAC,\nOvercooked-AI, and Melting Pot show that MRDG significantly improves robust\ncollaboration and competition with unseen teammates and opponents, surpassing\nestablished baselines. Our code is available at:\nhttps://github.com/vcis-wangchenxu/MRDG.git", "published": "2025-06-20 03:28:18", "link": "http://arxiv.org/abs/2506.16718v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Experimental Setup and Software Pipeline to Evaluate Optimization based Autonomous Multi-Robot Search Algorithms", "abstract": "Signal source localization has been a problem of interest in the multi-robot\nsystems domain given its applications in search \\& rescue and hazard\nlocalization in various industrial and outdoor settings. A variety of\nmulti-robot search algorithms exist that usually formulate and solve the\nassociated autonomous motion planning problem as a heuristic model-free or\nbelief model-based optimization process. Most of these algorithms however\nremains tested only in simulation, thereby losing the opportunity to generate\nknowledge about how such algorithms would compare/contrast in a real physical\nsetting in terms of search performance and real-time computing performance. To\naddress this gap, this paper presents a new lab-scale physical setup and\nassociated open-source software pipeline to evaluate and benchmark multi-robot\nsearch algorithms. The presented physical setup innovatively uses an acoustic\nsource (that is safe and inexpensive) and small ground robots (e-pucks)\noperating in a standard motion-capture environment. This setup can be easily\nrecreated and used by most robotics researchers. The acoustic source also\npresents interesting uncertainty in terms of its noise-to-signal ratio, which\nis useful to assess sim-to-real gaps. The overall software pipeline is designed\nto readily interface with any multi-robot search algorithm with minimal effort\nand is executable in parallel asynchronous form. This pipeline includes a\nframework for distributed implementation of multi-robot or swarm search\nalgorithms, integrated with a ROS (Robotics Operating System)-based software\nstack for motion capture supported localization. The utility of this novel\nsetup is demonstrated by using it to evaluate two state-of-the-art multi-robot\nsearch algorithms, based on swarm optimization and batch-Bayesian Optimization\n(called Bayes-Swarm), as well as a random walk baseline.", "published": "2025-06-20 03:06:43", "link": "http://arxiv.org/abs/2506.16710v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Any nonincreasing convergence curves are simultaneously possible for GMRES and weighted GMRES, as well as for left and right preconditioned GMRES", "abstract": "The convergence of the GMRES linear solver is notoriously hard to predict. A\nparticularly enlightening result by [Greenbaum, Pt\\'ak, Strako\\v{s}, 1996] is\nthat, given any convergence curve, one can build a linear system for which\nGMRES realizes that convergence curve. What is even more extraordinary is that\nthe eigenvalues of the problem matrix can be chosen arbitrarily. We build upon\nthis idea to derive novel results about weighted GMRES. We prove that for any\nlinear system and any prescribed convergence curve, there exists a weight\nmatrix M for which weighted GMRES (i.e., GMRES in the inner product induced by\nM) realizes that convergence curve, and we characterize the form of M.\nAdditionally, we exhibit a necessary and sufficient condition on M for the\nsimultaneous prescription of two convergence curves, one realized by GMRES in\nthe Euclidean inner product, and the other in the inner product induced by M.\nThese results are then applied to infer some properties of preconditioned GMRES\nwhen the preconditioner is applied either on the left or on the right. For\ninstance, we show that any two convergence curves are simultaneously possible\nfor left and right preconditioned GMRES.", "published": "2025-06-20 17:46:15", "link": "http://arxiv.org/abs/2506.17193v1", "categories": ["math.NA", "cs.NA", "65F10, 65Y05, 68W40"], "primary_category": "math.NA"}
{"title": "Complexity of sparse polynomial solving 3: Infinity", "abstract": "A theory of numerical path-following in toric varieties was suggested in two\nprevious papers. The motivation is solving systems of polynomials with real or\ncomplex coefficients. When those polynomials are not assumed `dense', solving\nthem over projective space or complex space may introduce spurious, degenerate\nroots or components.Spurious roots may be avoided by solving over toric\nvarieties.\n  In this paper, a homotopy algorithm is locally defined on charts of the toric\nvariety. Its complexity is bounded linearly by the condition length, that is\nthe integral along the lifted path (coefficients and solution) of thetoric\ncondition number. Those charts allow for stable computations near \"toric\ninfinity\",which was not possible within the technology of the previous papers.", "published": "2025-06-20 15:42:31", "link": "http://arxiv.org/abs/2506.17086v1", "categories": ["math.AG", "cs.NA", "math.NA", "65H10, 65H20, 14M25, 14Q20", "G.1.5"], "primary_category": "math.AG"}
{"title": "Structure-preserving scheme for 1D KWC system", "abstract": "In this paper, we consider a system of one-dimensional parabolic PDEs, known\nas the KWC system, as a phase-field model for grain boundary motion. A key\nfeature of this system is that the equation for the crystalline orientation\nangle is described as a quasilinear diffusion equation with variable mobility.\nThe goal of this paper is to establish a structure-preserving numerical scheme\nfor the system, focusing on two main structural properties: $\\sharp\\,1)$ range\npreservation; and $\\sharp\\,2)$ energy dissipation. Under suitable assumptions,\nwe construct a structure-preserving numerical scheme and address the following\nin the main theorems: (O) verification of the structural properties; (I)\nclarification of the convergence conditions; and (II) error estimate for the\nscheme.", "published": "2025-06-20 12:51:53", "link": "http://arxiv.org/abs/2506.16963v1", "categories": ["math.NA", "cs.NA", "35A15, 35K20, 65M12, 65M06, 74N20"], "primary_category": "math.NA"}
{"title": "Error analysis of BDF schemes for the evolutionary incompressible Navier--Stokes equations", "abstract": "Error bounds for fully discrete schemes for the evolutionary incompressible\nNavier--Stokes equations are derived in this paper. For the time integration we\napply BDF-$q$ methods, $q\\le 5$, for which error bounds for $q\\ge 3$ cannot be\nfound in the literature. Inf-sup stable mixed finite elements are used as\nspatial approximation. First, we analyze the standard Galerkin method and\nsecond a grad-div stabilized method. The grad-div stabilization allows to prove\nerror bounds with constants independent of inverse powers of the viscosity\ncoefficient. We prove optimal bounds for the velocity and pressure with order\n$(\\Delta t)^q$ in time for the BDF-$q$ scheme and order $h^{k+1}$ for the\n$L^2(\\Omega)$ error of the velocity in the first case and $h^k$ in the second\ncase, $k$ being the degree of the polynomials in finite element velocity space.", "published": "2025-06-20 11:20:14", "link": "http://arxiv.org/abs/2506.16917v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Magnus Methods for Stochastic Delay-Differential Equations", "abstract": "This paper introduces Magnus-based methods for solving stochastic\ndelay-differential equations (SDDEs). We construct Magnus--Euler--Maruyama\n(MEM) and Magnus--Milstein (MM) schemes by combining stochastic Magnus\nintegrators with Taylor methods for SDDEs. These schemes are applied\nincrementally between multiples of the delay times. We present proofs of their\nconvergence orders and demonstrate these rates through numerical examples and\nerror graphs. Among the examples, we apply the MEM and MM schemes to both\nlinear and nonlinear problems. We also apply the MEM scheme to a stochastic\npartial delay-differential equation (SPDDE), comparing its performance with the\ntraditional Euler--Maruyama (EM) method. Under fine spatial discretization, the\nMEM scheme remains numerically stable while the EM method becomes unstable,\nyielding a significant computational advantage.", "published": "2025-06-20 11:01:20", "link": "http://arxiv.org/abs/2506.16908v1", "categories": ["math.NA", "cs.NA", "65C30, 60H35, 34K50, 65L05, 65F60"], "primary_category": "math.NA"}
{"title": "Uncertainty Quantification for Linear Inverse Problems with Besov Prior: A Randomize-Then-Optimize Method", "abstract": "In this work, we investigate the use of Besov priors in the context of\nBayesian inverse problems. The solution to Bayesian inverse problems is the\nposterior distribution which naturally enables us to interpret the\nuncertainties. Besov priors are discretization invariant and can promote\nsparsity in terms of wavelet coefficients. We propose the\nrandomize-then-optimize method to draw samples from the posterior distribution\nwith Besov priors under a general parameter setting and estimate the modes of\nthe posterior distribution. The performance of the proposed method is studied\nthrough numerical experiments of a 1D inpainting problem, a 1D deconvolution\nproblem, and a 2D computed tomography problem. Further, we discuss the\ninfluence of the choice of the Besov parameters and the wavelet basis in\ndetail, and we compare the proposed method with the state-of-the-art methods.\nThe numerical results suggest that the proposed method is an effective tool for\nsampling the posterior distribution equipped with general Besov priors.", "published": "2025-06-20 10:20:24", "link": "http://arxiv.org/abs/2506.16888v1", "categories": ["math.NA", "cs.NA", "stat.CO", "G.3; G.4"], "primary_category": "math.NA"}
{"title": "Comparison of substructured non-overlapping domain decomposition and overlapping additive Schwarz methods for large-scale Helmholtz problems with multiple sources", "abstract": "Solving large-scale Helmholtz problems discretized with high-order finite\nelements is notoriously difficult, especially in 3D where direct factorization\nof the system matrix is very expensive and memory demanding, and robust\nconvergence of iterative methods is difficult to obtain. Domain decomposition\nmethods (DDM) constitute one of the most promising strategy so far, by\ncombining direct and iterative approaches: using direct solvers on overlapping\nor non-overlapping subdomains, as a preconditioner for a Krylov subspace method\non the original Helmholtz system or as an iterative solver on a substructured\nproblem involving field values or Lagrange multipliers on the interfaces\nbetween the subdomains. In this work we compare the computational performance\nof non-overlapping substructured DDM and Optimized Restricted Additive Schwarz\n(ORAS) preconditioners for solving large-scale Helmholtz problems with multiple\nsources, as is encountered, e.g., in frequency-domain Full Waveform Inversion.\nWe show on a realistic geophysical test-case that, when appropriately tuned,\nthe non-overlapping methods can reduce the convergence gap sufficiently to\nsignificantly outperform the overlapping methods.", "published": "2025-06-20 09:50:39", "link": "http://arxiv.org/abs/2506.16875v1", "categories": ["math.NA", "cs.DC", "cs.NA", "math.AP", "35J05, 65N55, 68W10, 35-04, 86-08", "J.2; G.1.3; G.1.8; G.4"], "primary_category": "math.NA"}
{"title": "Do high-order Gauss-Legendre methods admit a composition representation and a conjugate-symplectic counterpart?", "abstract": "One of the most classical pairs of symplectic and conjugate-symplectic\nschemes is given by the Midpoint method (the Gauss--Runge--Kutta method of\norder 2) and the Trapezoidal rule. These can be interpreted as compositions of\nthe Implicit and Explicit Euler methods, taken in direct and reverse order,\nrespectively. This naturally raises the question of whether a similar\ncomposition structure exists for higher-order Gauss--Legendre methods. In this\npaper, we provide a positive answer in the case of the fourth-order method. The\ntechnique we employ also enables the derivation of a high-order dense output.", "published": "2025-06-20 07:56:01", "link": "http://arxiv.org/abs/2506.16809v1", "categories": ["math.NA", "cs.NA", "65L06", "G.1.7"], "primary_category": "math.NA"}
{"title": "Hemodynamic Simulation in the Aortic Arch Under Anemic Diabetic and Healthy Blood Flow Conditions Using Computational Fluid Dynamics", "abstract": "This study investigates the hemodynamic behavior of blood flow in the aortic\narch across anemic, diabetic, and healthy conditions using computational fluid\ndynamics (CFD) simulations with a non-Newtonian Carreau viscosity model.\nVelocity fields, pressure distributions, and wall shear stress (WSS) patterns\nwere analyzed to assess the impact of blood rheology and vessel geometry.\nAnemic blood, with low viscosity and hematocrit, produced smooth,\nlow-resistance flow with reduced WSS and pressure gradients, potentially\nimpairing perfusion. Diabetic blood exhibited elevated viscosity, leading to\nincreased flow resistance, higher WSS, and localized separation at arterial\nbranches -- conditions associated with vascular stress and remodeling. Healthy\ncases showed balanced hemodynamic behavior with localized flow acceleration but\nmaintained physiological ranges. These findings highlight the mechanistic links\nbetween rheological properties and cardiovascular stress, supporting the role\nof CFD in non-invasive vascular risk assessment and motivating future\nintegration of patient-specific data and structural modeling for enhanced\nclinical relevance.", "published": "2025-06-20 05:47:35", "link": "http://arxiv.org/abs/2506.16763v1", "categories": ["physics.flu-dyn", "cs.NA", "math-ph", "math.MP", "math.NA"], "primary_category": "physics.flu-dyn"}
{"title": "State-Space Models in Efficient Whispered and Multi-dialect Speech Recognition", "abstract": "Whispered speech recognition presents significant challenges for conventional\nautomatic speech recognition systems, particularly when combined with dialect\nvariation. However, utilizing an efficient method to solve this problem using a\nlow-range dataset and processing load is beneficial. This paper proposes a\nsolution using a Mamba-based state-space model and four fine-tuned\nself-supervised models consisting of Wav2Vec2, WavLM, HuBERT, and Whisper to\naddress the dual challenges of whispered speech and dialect diversity. Based on\nour knowledge, this represents the best performance reported on the wTIMIT and\nCHAINS datasets for whispered speech recognition. We trained the models using\nwhispered and normal speech data across Singaporean, US, and Irish dialects.\nThe findings demonstrated that utilizing the proposed Mamba-based model could\nwork as a highly efficient model trained with low amounts of whispered data to\nsimultaneously work on whispered and normal speech recognition. The code for\nthis work is freely available.", "published": "2025-06-20 12:59:35", "link": "http://arxiv.org/abs/2506.16969v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ITO-Master: Inference-Time Optimization for Audio Effects Modeling of Music Mastering Processors", "abstract": "Music mastering style transfer aims to model and apply the mastering\ncharacteristics of a reference track to a target track, simulating the\nprofessional mastering process. However, existing methods apply fixed\nprocessing based on a reference track, limiting users' ability to fine-tune the\nresults to match their artistic intent. In this paper, we introduce the\nITO-Master framework, a reference-based mastering style transfer system that\nintegrates Inference-Time Optimization (ITO) to enable finer user control over\nthe mastering process. By optimizing the reference embedding during inference,\nour approach allows users to refine the output dynamically, making micro-level\nadjustments to achieve more precise mastering results. We explore both\nblack-box and white-box methods for modeling mastering processors and\ndemonstrate that ITO improves mastering performance across different styles.\nThrough objective evaluation, subjective listening tests, and qualitative\nanalysis using text-based conditioning with CLAP embeddings, we validate that\nITO enhances mastering style similarity while offering increased adaptability.\nOur framework provides an effective and user-controllable solution for\nmastering style transfer, allowing users to refine their results beyond the\ninitial style transfer.", "published": "2025-06-20 10:21:56", "link": "http://arxiv.org/abs/2506.16889v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Hybrid-Sep: Language-queried audio source separation via pre-trained Model Fusion and Adversarial Diffusion Training", "abstract": "Language-queried Audio Separation (LASS) employs linguistic queries to\nisolate target sounds based on semantic descriptions. However, existing methods\nface challenges in aligning complex auditory features with linguistic context\nwhile preserving separation precision. Current research efforts focus primarily\non text description augmentation and architectural innovations, yet the\npotential of integrating pre-trained self-supervised learning (SSL) audio\nmodels and Contrastive Language-Audio Pretraining (CLAP) frameworks, capable of\nextracting cross-modal audio-text relationships, remains underexplored. To\naddress this, we present HybridSep, a two-stage LASS framework that synergizes\nSSL-based acoustic representations with CLAP-derived semantic embeddings. Our\nframework introduces Adversarial Consistent Training (ACT), a novel\noptimization strategy that treats diffusion as an auxiliary regularization loss\nwhile integrating adversarial training to enhance separation fidelity.\nExperiments demonstrate that HybridSep achieves significant performance\nimprovements over state-of-the-art baselines (e.g., AudioSep, FlowSep) across\nmultiple metrics, establishing new benchmarks for LASS tasks.", "published": "2025-06-20 08:38:51", "link": "http://arxiv.org/abs/2506.16833v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "H-QuEST: Accelerating Query-by-Example Spoken Term Detection with Hierarchical Indexing", "abstract": "Query-by-example spoken term detection (QbE-STD) searches for matching words\nor phrases in an audio dataset using a sample spoken query. When annotated data\nis limited or unavailable, QbE-STD is often done using template matching\nmethods like dynamic time warping (DTW), which are computationally expensive\nand do not scale well. To address this, we propose H-QuEST (Hierarchical\nQuery-by-Example Spoken Term Detection), a novel framework that accelerates\nspoken term retrieval by utilizing Term Frequency and Inverse Document\nFrequency (TF-IDF)-based sparse representations obtained through advanced audio\nrepresentation learning techniques and Hierarchical Navigable Small World\n(HNSW) indexing with further refinement. Experimental results show that H-QuEST\ndelivers substantial improvements in retrieval speed without sacrificing\naccuracy compared to existing methods.", "published": "2025-06-20 05:01:54", "link": "http://arxiv.org/abs/2506.16751v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "RapFlow-TTS: Rapid and High-Fidelity Text-to-Speech with Improved Consistency Flow Matching", "abstract": "We introduce RapFlow-TTS, a rapid and high-fidelity TTS acoustic model that\nleverages velocity consistency constraints in flow matching (FM) training.\nAlthough ordinary differential equation (ODE)-based TTS generation achieves\nnatural-quality speech, it typically requires a large number of generation\nsteps, resulting in a trade-off between quality and inference speed. To address\nthis challenge, RapFlow-TTS enforces consistency in the velocity field along\nthe FM-straightened ODE trajectory, enabling consistent synthetic quality with\nfewer generation steps. Additionally, we introduce techniques such as time\ninterval scheduling and adversarial learning to further enhance the quality of\nthe few-step synthesis. Experimental results show that RapFlow-TTS achieves\nhigh-fidelity speech synthesis with a 5- and 10-fold reduction in synthesis\nsteps than the conventional FM- and score-based approaches, respectively.", "published": "2025-06-20 04:19:29", "link": "http://arxiv.org/abs/2506.16741v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "LM-SPT: LM-Aligned Semantic Distillation for Speech Tokenization", "abstract": "With the rapid progress of speech language models (SLMs), discrete speech\ntokens have emerged as a core interface between speech and text, enabling\nunified modeling across modalities. Recent speech tokenization approaches aim\nto isolate semantic information from low-level acoustics to better align with\nlanguage models. In particular, previous methods use SSL teachers such as\nHuBERT to extract semantic representations, which are then distilled into a\nsemantic quantizer to suppress acoustic redundancy as well as capture\ncontent-related latent structures. However, they still produce speech token\nsequences significantly longer than their textual counterparts, creating\nchallenges for efficient speech-language modeling. Reducing the frame rate is a\nnatural solution, but standard techniques, such as rigid average pooling across\nframes, can distort or dilute the semantic structure required for effective LM\nalignment. To address this, we propose LM-SPT, a speech tokenization method\nthat introduces a novel semantic distillation. Instead of directly matching\nteacher and student features via pooling, we reconstruct speech solely from\nsemantic tokens and minimize the discrepancy between the encoded\nrepresentations of the original and reconstructed waveforms, obtained from a\nfrozen automatic speech recognition (ASR) encoder. This indirect yet\ndata-driven supervision enables the tokenizer to learn discrete units that are\nmore semantically aligned with language models. LM-SPT further incorporates\narchitectural improvements to the encoder and decoder for speech tokenization,\nand supports multiple frame rates, including 25Hz, 12.5Hz, and 6.25Hz.\nExperimental results show that LM-SPT achieves superior reconstruction fidelity\ncompared to baselines, and that SLMs trained with LM-SPT tokens achieve\ncompetitive performances on speech-to-text and consistently outperform\nbaselines on text-to-speech tasks.", "published": "2025-06-20 04:15:14", "link": "http://arxiv.org/abs/2506.16738v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Learning Magnitude Distribution of Sound Fields via Conditioned Autoencoder", "abstract": "A learning-based method for estimating the magnitude distribution of sound\nfields from spatially sparse measurements is proposed. Estimating the magnitude\ndistribution of acoustic transfer function (ATF) is useful when phase\nmeasurements are unreliable or inaccessible and has a wide range of\napplications related to spatial audio. We propose a neural-network-based method\nfor the ATF magnitude estimation. The key feature of our network architecture\nis the input and output layers conditioned on source and receiver positions and\nfrequency and the aggregation module of latent variables, which can be\ninterpreted as an autoencoder-based extension of the basis expansion of the\nsound field. Numerical simulation results indicated that the ATF magnitude is\naccurately estimated with a small number of receivers by our proposed method.", "published": "2025-06-20 03:52:37", "link": "http://arxiv.org/abs/2506.16729v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Efficient Implementation of Multi-sensor Adaptive Birth Samplers for Labeled Random Finite Set Tracking", "abstract": "Adaptive track initiation remains a crucial component of many modern\nmulti-target tracking systems. For labeled random finite sets multi-object\nfilters, prior work has been established to construct a labeled multi-object\nbirth density using measurements from multiple sensors. A naive construction of\nthis adaptive birth set density results in an exponential number of newborn\ncomponents in the number of sensors. A truncation procedure was provided that\nleverages a Gibbs sampler to truncate the birth density, reducing the\ncomplexity to quadratic in the number of sensors. However, only a limited\ndiscussion has been provided on additional algorithmic techniques that can be\nemployed to substantially reduce the complexity in practical tracking\napplications. In this paper, we propose five efficiency enhancements for the\nlabeled random finite sets multi-sensor adaptive birth procedure. Simulation\nresults are provided to demonstrate their computational benefits and show that\nthey result in a negligible change to the multi-target tracking performance.", "published": "2025-06-20 17:55:01", "link": "http://arxiv.org/abs/2506.17205v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Intelligent Reflecting Surfaces for THz Communications: Fundamentals, Key Solutions, and System Prototyping", "abstract": "Intelligent reflecting surfaces (IRSs) have emerged as a cost-effective\ntechnology for terahertz (THz) communications by enabling programmable control\nof the wireless environment. This paper provides a comprehensive overview of\nIRSs-aided THz communications, covering hardware designs, advanced signal\nprocessing techniques, and practical deployment strategies. It first examines\nkey THz reconfigurable metasurface architectures, including electronic,\noptical, phase-change material, and micro-electromechanical systems\n(MEMS)-based implementations, highlighting their reconfiguration mechanisms and\nchallenges. Then, fundamental effects including near field and beam squint in\nwideband THz systems are analyzed, along with their impacts on system\nperformance. The paper further explores conventional and beam-squint-assisted\nchannel estimation methods, innovative beam management strategies, and\ndeployment considerations across large- and small-scale scenarios. Practical\nexperiments at 220 gigahertz (GHz) validate the effectiveness of IRS in\nimproving signal strength and communication reliability for both single-user\nand multi-user setups.", "published": "2025-06-20 17:50:07", "link": "http://arxiv.org/abs/2506.17200v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On Energy-Efficient Passive Beamforming Design of RIS-Assisted CoMP-NOMA Networks", "abstract": "This paper investigates the synergistic potential of reconfigurable\nintelligent surfaces (RIS) and non-orthogonal multiple access (NOMA) to enhance\nthe energy efficiency and performance of next-generation wireless networks. We\ndelve into the design of energy-efficient passive beamforming (PBF) strategies\nwithin RIS-assisted coordinated multi-point (CoMP)-NOMA networks. Two distinct\nRIS configurations, namely, enhancement-only PBF (EO) and enhancement &\ncancellation PBF (EC), are proposed and analyzed. Our findings demonstrate that\nRIS-assisted CoMP-NOMA networks offer significant efficiency gains compared to\ntraditional CoMP-NOMA systems. Furthermore, we formulate a PBF design problem\nto optimize the RIS phase shifts for maximizing energy efficiency. Our results\nreveal that the optimal PBF design is contingent upon several factors,\nincluding the number of cooperating base stations (BSs), the number of RIS\nelements deployed, and the RIS configuration. This study underscores the\npotential of RIS-assisted CoMP-NOMA networks as a promising solution for\nachieving superior energy efficiency and overall performance in future wireless\nnetworks.", "published": "2025-06-20 17:42:49", "link": "http://arxiv.org/abs/2506.17189v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Low-Complexity Receiver Design for Affine Filter Bank Modulation", "abstract": "We propose a low-complexity receiver structure for the recently introduced\nAffine Filter Bank Modulation (AFBM) scheme, which is a novel waveform designed\nfor integrated sensing and communications (ISAC) systems operating in\ndoubly-dispersive (DD) channels. The proposed receiver structure is based on\nthe Gaussian Belief Propagation (GaBP) framework, making use of only\nelement-wise scalar operations to perform detection of the transmitted symbols.\nSimulation results demonstrate that AFBM in conjunction with GaBP outperforms\naffine frequency division multiplexing (AFDM) in terms of bit error rates\n(BERs) in DD channels, while achieving very low out-of-band emissions (OOBE) in\nhigh-mobility scenarios.", "published": "2025-06-20 14:06:41", "link": "http://arxiv.org/abs/2506.17010v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Wi-Fi Sensing Tool Release: Gathering 802.11ax Channel State Information from a Commercial Wi-Fi Access Point", "abstract": "Wi-Fi sensing has emerged as a powerful technology, leveraging channel state\ninformation (CSI) extracted from wireless data packets to enable diverse\napplications, ranging from human presence detection to gesture recognition and\nhealth monitoring. However, CSI extraction from commercial Wi-Fi access point\nlacks and out of date. This paper introduces ZTECSITool,a toolkit designed to\ncapture high-resolution CSI measurements from commercial Wi-Fi 6 (802.11ax)\naccess points, supporting bandwidths up to 160 MHz and 512 subcarriers.\nZTECSITool bridges a critical gap in Wi-Fi sensing research, facilitating the\ndevelopment of next-generation sensing systems. The toolkit includes customized\nfirmware and open-source software tools for configuring, collecting, and\nparsing CSI data, offering researchers a robust platform for advanced sensing\napplications. We detail the command protocols for CSI extraction, including\nband selection,STA filtering, and report configuration, and provide insights\ninto the data structure of the reported CSI. Additionally, we present a\nPython-based graphical interface for real-time CSI visualization and analysis", "published": "2025-06-20 12:44:31", "link": "http://arxiv.org/abs/2506.16957v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Beamforming design for minimizing the signal power estimation error", "abstract": "We study the properties of beamformers in their ability to either maintain or\nestimate the true signal power of the signal of interest (SOI). Our focus is\nparticularly on the Capon beamformer and the minimum mean squared error (MMSE)\nbeamformer. The Capon beamformer, also known as the minimum power\ndistortionless response (MPDR) or the minimum variance distortionless response\n(MVDR) beamformer, is a widely used method in array signal processing. A\ncurious feature of both the Capon and the MMSE beamformers is their tendency to\neither overestimate or underestimate the signal power. That is, they are not\nasymptotically unbiased (as the sample size approaches infinity). To address\nthis issue, we propose to shrink the Capon beamformer by finding a scaling\nfactor that minimizes the mean squared error (MSE) of the signal power\nestimate. The new beamformer, referred to as the Capon$^+$ beamformer, is\nevaluated against the Capon and MMSE beamformers in terms of bias, signal power\nMSE, and signal waveform MSE. The Capon$^+$ beamformer strikes a better balance\nbetween signal power and waveform estimation while also exhibiting minimal\nbias, which approaches zero as the sample size increases.", "published": "2025-06-20 06:02:27", "link": "http://arxiv.org/abs/2506.16767v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fine-Tuning Lowers Safety and Disrupts Evaluation Consistency", "abstract": "Fine-tuning a general-purpose large language model (LLM) for a specific\ndomain or task has become a routine procedure for ordinary users. However,\nfine-tuning is known to remove the safety alignment features of the model, even\nwhen the fine-tuning data does not contain any harmful content. We consider\nthis to be a critical failure mode of LLMs due to the widespread uptake of\nfine-tuning, combined with the benign nature of the \"attack\". Most\nwell-intentioned developers are likely unaware that they are deploying an LLM\nwith reduced safety. On the other hand, this known vulnerability can be easily\nexploited by malicious actors intending to bypass safety guardrails. To make\nany meaningful progress in mitigating this issue, we first need reliable and\nreproducible safety evaluations. In this work, we investigate how robust a\nsafety benchmark is to trivial variations in the experimental procedure, and\nthe stochastic nature of LLMs. Our initial experiments expose surprising\nvariance in the results of the safety evaluation, even when seemingly\ninconsequential changes are made to the fine-tuning setup. Our observations\nhave serious implications for how researchers in this field should report\nresults to enable meaningful comparisons in the future.", "published": "2025-06-20 17:57:12", "link": "http://arxiv.org/abs/2506.17209v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dissecting the SWE-Bench Leaderboards: Profiling Submitters and Architectures of LLM- and Agent-Based Repair Systems", "abstract": "The rapid progress in Automated Program Repair (APR) has been driven by\nadvances in AI, particularly large language models (LLMs) and agent-based\nsystems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair\nsystems using real issues and pull requests mined from 12 popular open-source\nPython repositories. Its public leaderboards, SWE-Bench Lite and SWE-Bench\nVerified, have become central platforms for tracking progress and comparing\nsolutions. However, because the submission process does not require detailed\ndocumentation, the architectural design and origin of many solutions remain\nunclear. In this paper, we present the first comprehensive study of all\nsubmissions to the SWE-Bench Lite (68 entries) and Verified (79 entries)\nleaderboards, analyzing 67 unique approaches across dimensions such as\nsubmitter type, product availability, LLM usage, and system architecture. Our\nfindings reveal the dominance of proprietary LLMs (especially Claude 3.5/3.7),\nthe presence of both agentic and non-agentic designs, and a contributor base\nspanning from individual developers to large tech companies.", "published": "2025-06-20 17:57:08", "link": "http://arxiv.org/abs/2506.17208v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "CLEAR-3K: Assessing Causal Explanatory Capabilities in Language Models", "abstract": "We introduce CLEAR-3K, a dataset of 3,000 assertion-reasoning questions\ndesigned to evaluate whether language models can determine if one statement\ncausally explains another. Each question present an assertion-reason pair and\nchallenge language models to distinguish between semantic relatedness and\ngenuine causal explanatory relationships. Through comprehensive evaluation of\n21 state-of-the-art language models (ranging from 0.5B to 72B parameters), we\nidentify two fundamental findings. First, language models frequently confuse\nsemantic similarity with causality, relying on lexical and semantic overlap\ninstead of inferring actual causal explanatory relationships. Second, as\nparameter size increases, models tend to shift from being overly skeptical\nabout causal relationships to being excessively permissive in accepting them.\nDespite this shift, performance measured by the Matthews Correlation\nCoefficient plateaus at just 0.55, even for the best-performing models.Hence,\nCLEAR-3K provides a crucial benchmark for developing and evaluating genuine\ncausal reasoning in language models, which is an essential capability for\napplications that require accurate assessment of causal relationships.", "published": "2025-06-20 17:35:36", "link": "http://arxiv.org/abs/2506.17180v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cache Me If You Can: How Many KVs Do You Need for Effective Long-Context LMs?", "abstract": "Language models handle increasingly long contexts for tasks such as book\nsummarization, but this leads to growing memory costs for the key-value (KV)\ncache. Many prior works have proposed ways of discarding KVs from memory, but\ntheir approaches are tailored to favorable settings, obscuring caveats like\nhigh peak memory and performance degradation, and a fair comparison between\nmethods is difficult. In this paper, we propose the *KV footprint* as a unified\nmetric, which accounts for both the amount of KV entries stored and their\nlifespan in memory. We evaluate methods based on the smallest footprint they\nattain while preserving performance in both long-context understanding and\ngeneration, with context lengths of up to 128K tokens. This metric reveals the\nhigh peak memory of prior KV eviction methods. One class of methods --\n*post-fill eviction* -- has a high footprint due to being incompatible with\neviction during pre-filling. We adapt these methods to be able to evict KVs\nduring pre-filling, achieving substantially lower KV footprints. We then turn\nto *recency eviction* methods, wherein we propose PruLong, an end-to-end\noptimization method for learning which attention heads need to retain the full\nKV cache and which do not. PruLong saves memory while preserving long-context\nperformance, achieving 12% smaller KV footprint than prior methods while\nretaining performance in challenging recall tasks. Our paper clarifies the\ncomplex tangle of long-context inference methods and paves the way for future\ndevelopment to minimize the KV footprint.", "published": "2025-06-20 16:21:12", "link": "http://arxiv.org/abs/2506.17121v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Bias Evaluation Methods Biased ?", "abstract": "The creation of benchmarks to evaluate the safety of Large Language Models is\none of the key activities within the trusted AI community. These benchmarks\nallow models to be compared for different aspects of safety such as toxicity,\nbias, harmful behavior etc. Independent benchmarks adopt different approaches\nwith distinct data sets and evaluation methods. We investigate how robust such\nbenchmarks are by using different approaches to rank a set of representative\nmodels for bias and compare how similar are the overall rankings. We show that\ndifferent but widely used bias evaluations methods result in disparate model\nrankings. We conclude with recommendations for the community in the usage of\nsuch benchmarks.", "published": "2025-06-20 16:11:25", "link": "http://arxiv.org/abs/2506.17111v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Better Language Model Inversion by Compactly Representing Next-Token Distributions", "abstract": "Language model inversion seeks to recover hidden prompts using only language\nmodel outputs. This capability has implications for security and accountability\nin language model deployments, such as leaking private information from an\nAPI-protected language model's system message. We propose a new method --\nprompt inversion from logprob sequences (PILS) -- that recovers hidden prompts\nby gleaning clues from the model's next-token probabilities over the course of\nmultiple generation steps. Our method is enabled by a key insight: The\nvector-valued outputs of a language model occupy a low-dimensional subspace.\nThis enables us to losslessly compress the full next-token probability\ndistribution over multiple generation steps using a linear map, allowing more\noutput information to be used for inversion. Our approach yields massive gains\nover previous state-of-the-art methods for recovering hidden prompts, achieving\n2--3.5 times higher exact recovery rates across test sets, in one case\nincreasing the recovery rate from 17% to 60%. Our method also exhibits\nsurprisingly good generalization behavior; for instance, an inverter trained on\n16 generations steps gets 5--27 points higher prompt recovery when we increase\nthe number of steps to 32 at test time. Furthermore, we demonstrate strong\nperformance of our method on the more challenging task of recovering hidden\nsystem messages. We also analyze the role of verbatim repetition in prompt\nrecovery and propose a new method for cross-family model transfer for\nlogit-based inverters. Our findings show that next-token probabilities are a\nconsiderably more vulnerable attack surface for inversion attacks than\npreviously known.", "published": "2025-06-20 15:53:51", "link": "http://arxiv.org/abs/2506.17090v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain-of-Thought Prompting Obscures Hallucination Cues in Large Language Models: An Empirical Evaluation", "abstract": "Large Language Models (LLMs) often exhibit \\textit{hallucinations},\ngenerating factually incorrect or semantically irrelevant content in response\nto prompts. Chain-of-Thought (CoT) prompting can mitigate hallucinations by\nencouraging step-by-step reasoning, but its impact on hallucination detection\nremains underexplored. To bridge this gap, we conduct a systematic empirical\nevaluation. We begin with a pilot experiment, revealing that CoT reasoning\nsignificantly affects the LLM's internal states and token probability\ndistributions. Building on this, we evaluate the impact of various CoT\nprompting methods on mainstream hallucination detection methods across both\ninstruction-tuned and reasoning-oriented LLMs. Specifically, we examine three\nkey dimensions: changes in hallucination score distributions, variations in\ndetection accuracy, and shifts in detection confidence. Our findings show that\nwhile CoT prompting helps reduce hallucination frequency, it also tends to\nobscure critical signals used for detection, impairing the effectiveness of\nvarious detection methods. Our study highlights an overlooked trade-off in the\nuse of reasoning. Code is publicly available at:\nhttps://anonymous.4open.science/r/cot-hallu-detect.", "published": "2025-06-20 15:49:37", "link": "http://arxiv.org/abs/2506.17088v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tower+: Bridging Generality and Translation Specialization in Multilingual LLMs", "abstract": "Fine-tuning pretrained LLMs has been shown to be an effective strategy for\nreaching state-of-the-art performance on specific tasks like machine\ntranslation. However, this process of adaptation often implies sacrificing\ngeneral-purpose capabilities, such as conversational reasoning and\ninstruction-following, hampering the utility of the system in real-world\napplications that require a mixture of skills. In this paper, we introduce\nTower+, a suite of models designed to deliver strong performance across both\ntranslation and multilingual general-purpose text capabilities. We achieve a\nPareto frontier between translation specialization and multilingual\ngeneral-purpose capabilities by introducing a novel training recipe that builds\non Tower (Alves et al., 2024), comprising continued pretraining, supervised\nfine-tuning, preference optimization, and reinforcement learning with\nverifiable rewards. At each stage of training, we carefully generate and curate\ndata to strengthen performance on translation as well as general-purpose tasks\ninvolving code generation, mathematics problem solving, and general\ninstruction-following. We develop models at multiple scales: 2B, 9B, and 72B.\nOur smaller models often outperform larger general-purpose open-weight and\nproprietary LLMs (e.g., Llama 3.3 70B, GPT-4o). Our largest model delivers\nbest-in-class translation performance for high-resource languages and top\nresults in multilingual Arena Hard evaluations and in IF-MT, a benchmark we\nintroduce for evaluating both translation and instruction-following. Our\nfindings highlight that it is possible to rival frontier models in general\ncapabilities, while optimizing for specific business domains, such as\ntranslation and localization.", "published": "2025-06-20 15:30:06", "link": "http://arxiv.org/abs/2506.17080v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Simultaneous Translation with Offline Speech and LLM Models in CUNI Submission to IWSLT 2025", "abstract": "This paper describes Charles University submission to the Simultaneous Speech\nTranslation Task of the IWSLT 2025. We cover all four language pairs with a\ndirect or cascade approach. The backbone of our systems is the offline Whisper\nspeech model, which we use for both translation and transcription in\nsimultaneous mode with the state-of-the-art simultaneous policy AlignAtt. We\nfurther improve the performance by prompting to inject in-domain terminology,\nand we accommodate context. Our cascaded systems further use EuroLLM for\nunbounded simultaneous translation. Compared to the Organizers' baseline, our\nsystems improve by 2 BLEU points on Czech to English and 13-22 BLEU points on\nEnglish to German, Chinese and Japanese on the development sets. Additionally,\nwe also propose a new enhanced measure of speech recognition latency.", "published": "2025-06-20 15:27:44", "link": "http://arxiv.org/abs/2506.17077v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Instituto de Telecomunica\u00e7\u00f5es at IWSLT 2025: Aligning Small-Scale Speech and Language Models for Speech-to-Text Learning", "abstract": "This paper presents the IT-IST submission to the IWSLT 2025 Shared Task on\nInstruction Following Speech Processing. We submit results for the Short Track,\ni.e., speech recognition, translation, and spoken question answering. Our model\nis a unified speech-to-text model that integrates a pre-trained continuous\nspeech encoder and text decoder through a first phase of modality alignment and\na second phase of instruction fine-tuning. Crucially, we focus on using\nsmall-scale language model backbones (< 2B) and restrict to high-quality, CC-BY\ndata along with synthetic data generation to supplement existing resources.", "published": "2025-06-20 14:17:42", "link": "http://arxiv.org/abs/2506.17019v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLM-Generated Feedback Supports Learning If Learners Choose to Use It", "abstract": "Large language models (LLMs) are increasingly used to generate feedback, yet\ntheir impact on learning remains underexplored, especially compared to existing\nfeedback methods. This study investigates how on-demand LLM-generated\nexplanatory feedback influences learning in seven scenario-based tutor training\nlessons. Analyzing over 2,600 lesson completions from 885 tutor learners, we\ncompare posttest performance among learners across three groups: learners who\nreceived feedback generated by gpt-3.5-turbo, those who declined it, and those\nwithout access. All groups received non-LLM corrective feedback. To address\npotential selection bias-where higher-performing learners may be more inclined\nto use LLM feedback-we applied propensity scoring. Learners with a higher\npredicted likelihood of engaging with LLM feedback scored significantly higher\nat posttest than those with lower propensity. After adjusting for this effect,\ntwo out of seven lessons showed statistically significant learning benefits\nfrom LLM feedback with standardized effect sizes of 0.28 and 0.33. These\nmoderate effects suggest that the effectiveness of LLM feedback depends on the\nlearners' tendency to seek support. Importantly, LLM feedback did not\nsignificantly increase completion time, and learners overwhelmingly rated it as\nhelpful. These findings highlight LLM feedback's potential as a low-cost and\nscalable way to improve learning on open-ended tasks, particularly in existing\nsystems already providing feedback without LLMs. This work contributes open\ndatasets, LLM prompts, and rubrics to support reproducibility.", "published": "2025-06-20 13:59:14", "link": "http://arxiv.org/abs/2506.17006v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs", "abstract": "LaTeX's precision and flexibility in typesetting have made it the gold\nstandard for the preparation of scientific documentation. Large Language Models\n(LLMs) present a promising opportunity for researchers to produce\npublication-ready material using LaTeX with natural language instructions, yet\ncurrent benchmarks completely lack evaluation of this ability. By introducing\nTeXpert, our benchmark dataset with natural language prompts for generating\nLaTeX code focused on components of scientific documents across multiple\ndifficulty levels, we conduct an in-depth analysis of LLM performance in this\nregard and identify frequent error types. Our evaluation across open and\nclosed-source LLMs highlights multiple key findings: LLMs excelling on standard\nbenchmarks perform poorly in LaTeX generation with a significant accuracy\ndrop-off as the complexity of tasks increases; open-source models like DeepSeek\nv3 and DeepSeek Coder strongly rival closed-source counterparts in LaTeX tasks;\nand formatting and package errors are unexpectedly prevalent, suggesting a lack\nof diverse LaTeX examples in the training datasets of most LLMs. Our dataset,\ncode, and model evaluations are available at\nhttps://github.com/knowledge-verse-ai/TeXpert.", "published": "2025-06-20 13:39:16", "link": "http://arxiv.org/abs/2506.16990v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning", "abstract": "Despite efforts to align large language models (LLMs) with societal and moral\nvalues, these models remain susceptible to jailbreak attacks--methods designed\nto elicit harmful responses. Jailbreaking black-box LLMs is considered\nchallenging due to the discrete nature of token inputs, restricted access to\nthe target LLM, and limited query budget. To address the issues above, we\npropose an effective method for jailbreaking black-box large language Models\nvia Iterative Semantic Tuning, named MIST. MIST enables attackers to\niteratively refine prompts that preserve the original semantic intent while\ninducing harmful content. Specifically, to balance semantic similarity with\ncomputational efficiency, MIST incorporates two key strategies: sequential\nsynonym search, and its advanced version--order-determining optimization.\nExtensive experiments across two open-source models and four closed-source\nmodels demonstrate that MIST achieves competitive attack success rates and\nattack transferability compared with other state-of-the-art white-box and\nblack-box jailbreak methods. Additionally, we conduct experiments on\ncomputational efficiency to validate the practical viability of MIST.", "published": "2025-06-20 07:16:47", "link": "http://arxiv.org/abs/2506.16792v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DistillNote: LLM-based clinical note summaries improve heart failure diagnosis", "abstract": "Large language models (LLMs) offer unprecedented opportunities to generate\nconcise summaries of patient information and alleviate the burden of clinical\ndocumentation that overwhelms healthcare providers. We present Distillnote, a\nframework for LLM-based clinical note summarization, and generate over 64,000\nadmission note summaries through three techniques: (1) One-step, direct\nsummarization, and a divide-and-conquer approach involving (2) Structured\nsummarization focused on independent clinical insights, and (3) Distilled\nsummarization that further condenses the Structured summaries. We test how\nuseful are the summaries by using them to predict heart failure compared to a\nmodel trained on the original notes. Distilled summaries achieve 79% text\ncompression and up to 18.2% improvement in AUPRC compared to an LLM trained on\nthe full notes. We also evaluate the quality of the generated summaries in an\nLLM-as-judge evaluation as well as through blinded pairwise comparisons with\nclinicians. Evaluations indicate that one-step summaries are favoured by\nclinicians according to relevance and clinical actionability, while distilled\nsummaries offer optimal efficiency (avg. 6.9x compression-to-performance ratio)\nand significantly reduce hallucinations. We release our summaries on PhysioNet\nto encourage future research.", "published": "2025-06-20 06:45:40", "link": "http://arxiv.org/abs/2506.16777v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SocialSim: Towards Socialized Simulation of Emotional Support Conversation", "abstract": "Emotional support conversation (ESC) helps reduce people's psychological\nstress and provide emotional value through interactive dialogues. Due to the\nhigh cost of crowdsourcing a large ESC corpus, recent attempts use large\nlanguage models for dialogue augmentation. However, existing approaches largely\noverlook the social dynamics inherent in ESC, leading to less effective\nsimulations. In this paper, we introduce SocialSim, a novel framework that\nsimulates ESC by integrating key aspects of social interactions: social\ndisclosure and social awareness. On the seeker side, we facilitate social\ndisclosure by constructing a comprehensive persona bank that captures diverse\nand authentic help-seeking scenarios. On the supporter side, we enhance social\nawareness by eliciting cognitive reasoning to generate logical and supportive\nresponses. Building upon SocialSim, we construct SSConv, a large-scale\nsynthetic ESC corpus of which quality can even surpass crowdsourced ESC data.\nWe further train a chatbot on SSConv and demonstrate its state-of-the-art\nperformance in both automatic and human evaluations. We believe SocialSim\noffers a scalable way to synthesize ESC, making emotional care more accessible\nand practical.", "published": "2025-06-20 05:24:40", "link": "http://arxiv.org/abs/2506.16756v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language-Informed Synthesis of Rational Agent Models for Grounded Theory-of-Mind Reasoning On-The-Fly", "abstract": "Drawing real world social inferences usually requires taking into account\ninformation from multiple modalities. Language is a particularly powerful\nsource of information in social settings, especially in novel situations where\nlanguage can provide both abstract information about the environment dynamics\nand concrete specifics about an agent that cannot be easily visually observed.\nIn this paper, we propose Language-Informed Rational Agent Synthesis (LIRAS), a\nframework for drawing context-specific social inferences that integrate\nlinguistic and visual inputs. LIRAS frames multimodal social reasoning as a\nprocess of constructing structured but situation-specific agent and environment\nrepresentations - leveraging multimodal language models to parse language and\nvisual inputs into unified symbolic representations, over which a Bayesian\ninverse planning engine can be run to produce granular probabilistic judgments.\nOn a range of existing and new social reasoning tasks derived from cognitive\nscience experiments, we find that our model (instantiated with a comparatively\nlightweight VLM) outperforms ablations and state-of-the-art models in capturing\nhuman judgments across all domains.", "published": "2025-06-20 05:21:42", "link": "http://arxiv.org/abs/2506.16755v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Role of Model Confidence on Bias Effects in Measured Uncertainties", "abstract": "With the growing adoption of Large Language Models (LLMs) for open-ended\ntasks, accurately assessing epistemic uncertainty, which reflects a model's\nlack of knowledge, has become crucial to ensuring reliable outcomes. However,\nquantifying epistemic uncertainty in such tasks is challenging due to the\npresence of aleatoric uncertainty, which arises from multiple valid answers.\nWhile bias can introduce noise into epistemic uncertainty estimation, it may\nalso reduce noise from aleatoric uncertainty. To investigate this trade-off, we\nconduct experiments on Visual Question Answering (VQA) tasks and find that\nmitigating prompt-introduced bias improves uncertainty quantification in\nGPT-4o. Building on prior work showing that LLMs tend to copy input information\nwhen model confidence is low, we further analyze how these prompt biases affect\nmeasured epistemic and aleatoric uncertainty across varying bias-free\nconfidence levels with GPT-4o and Qwen2-VL. We find that all considered biases\ninduce greater changes in both uncertainties when bias-free model confidence is\nlower. Moreover, lower bias-free model confidence leads to greater\nunderestimation of epistemic uncertainty (i.e. overconfidence) due to bias,\nwhereas it has no significant effect on the direction of changes in aleatoric\nuncertainty estimation. These distinct effects deepen our understanding of bias\nmitigation for uncertainty quantification and potentially inform the\ndevelopment of more advanced techniques.", "published": "2025-06-20 03:43:10", "link": "http://arxiv.org/abs/2506.16724v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ReasonGRM: Enhancing Generative Reward Models through Large Reasoning Models", "abstract": "Generative Reward Models (GRMs) provide greater flexibility than scalar\nreward models in capturing human preferences, but their effectiveness is\nlimited by poor reasoning capabilities. This often results in incomplete or\noverly speculative reasoning paths, leading to hallucinations or missing key\ninformation in complex tasks. We address this challenge with ReasonGRM, a\nthree-stage generative reward modeling framework. In the first stage, Zero-RL\nis used to generate concise, outcome-directed reasoning paths that reduce the\nlikelihood of critical omissions. In the second stage, we introduce a novel\nevaluation metric, $R^\\star$, which scores reasoning paths based on their\ngeneration likelihood. This favors paths that reach correct answers with\nminimal exploration, helping to reduce hallucination-prone data during\ntraining. In the final stage, the model is further refined through\nreinforcement learning on challenging examples to enhance its preference\ndiscrimination capabilities. Experiments on three public benchmarks show that\nReasonGRM achieves competitive or state-of-the-art performance, outperforming\nprevious best GRMs by 1.8\\% on average and surpassing proprietary models such\nas GPT-4o by up to 5.6\\%. These results demonstrate the effectiveness of\nreasoning-aware training and highlight the importance of high-quality rationale\nselection for reliable preference modeling.", "published": "2025-06-20 03:10:52", "link": "http://arxiv.org/abs/2506.16712v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models as Psychological Simulators: A Methodological Guide", "abstract": "Large language models (LLMs) offer emerging opportunities for psychological\nand behavioral research, but methodological guidance is lacking. This article\nprovides a framework for using LLMs as psychological simulators across two\nprimary applications: simulating roles and personas to explore diverse\ncontexts, and serving as computational models to investigate cognitive\nprocesses. For simulation, we present methods for developing psychologically\ngrounded personas that move beyond demographic categories, with strategies for\nvalidation against human data and use cases ranging from studying inaccessible\npopulations to prototyping research instruments. For cognitive modeling, we\nsynthesize emerging approaches for probing internal representations,\nmethodological advances in causal interventions, and strategies for relating\nmodel behavior to human cognition. We address overarching challenges including\nprompt sensitivity, temporal limitations from training data cutoffs, and\nethical considerations that extend beyond traditional human subjects review.\nThroughout, we emphasize the need for transparency about model capabilities and\nconstraints. Together, this framework integrates emerging empirical evidence\nabout LLM performance--including systematic biases, cultural limitations, and\nprompt brittleness--to help researchers wrangle these challenges and leverage\nthe unique capabilities of LLMs in psychological research.", "published": "2025-06-20 02:45:23", "link": "http://arxiv.org/abs/2506.16702v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.CY"}
{"title": "From Prompts to Constructs: A Dual-Validity Framework for LLM Research in Psychology", "abstract": "Large language models (LLMs) are rapidly being adopted across psychology,\nserving as research tools, experimental subjects, human simulators, and\ncomputational models of cognition. However, the application of human\nmeasurement tools to these systems can produce contradictory results, raising\nconcerns that many findings are measurement phantoms--statistical artifacts\nrather than genuine psychological phenomena. In this Perspective, we argue that\nbuilding a robust science of AI psychology requires integrating two of our\nfield's foundational pillars: the principles of reliable measurement and the\nstandards for sound causal inference. We present a dual-validity framework to\nguide this integration, which clarifies how the evidence needed to support a\nclaim scales with its scientific ambition. Using an LLM to classify text may\nrequire only basic accuracy checks, whereas claiming it can simulate anxiety\ndemands a far more rigorous validation process. Current practice systematically\nfails to meet these requirements, often treating statistical pattern matching\nas evidence of psychological phenomena. The same model output--endorsing \"I am\nanxious\"--requires different validation strategies depending on whether\nresearchers claim to measure, characterize, simulate, or model psychological\nconstructs. Moving forward requires developing computational analogues of\npsychological constructs and establishing clear, scalable standards of evidence\nrather than the uncritical application of human measurement tools.", "published": "2025-06-20 02:38:42", "link": "http://arxiv.org/abs/2506.16697v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.CY"}
{"title": "LegiGPT: Party Politics and Transport Policy with Large Language Model", "abstract": "Given the significant influence of lawmakers' political ideologies on\nlegislative decision-making, understanding their impact on policymaking is\ncritically important. We introduce a novel framework, LegiGPT, which integrates\na large language model (LLM) with explainable artificial intelligence (XAI) to\nanalyze transportation-related legislative proposals. LegiGPT employs a\nmulti-stage filtering and classification pipeline using zero-shot prompting\nwith GPT-4. Using legislative data from South Korea's 21st National Assembly,\nwe identify key factors - including sponsor characteristics, political\naffiliations, and geographic variables - that significantly influence\ntransportation policymaking. The LLM was used to classify\ntransportation-related bill proposals through a stepwise filtering process\nbased on keywords, phrases, and contextual relevance. XAI techniques were then\napplied to examine relationships between party affiliation and associated\nattributes. The results reveal that the number and proportion of conservative\nand progressive sponsors, along with district size and electoral population,\nare critical determinants shaping legislative outcomes. These findings suggest\nthat both parties contributed to bipartisan legislation through different forms\nof engagement, such as initiating or supporting proposals. This integrated\napproach provides a valuable tool for understanding legislative dynamics and\nguiding future policy development, with broader implications for infrastructure\nplanning and governance.", "published": "2025-06-20 02:25:52", "link": "http://arxiv.org/abs/2506.16692v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mechanisms vs. Outcomes: Probing for Syntax Fails to Explain Performance on Targeted Syntactic Evaluations", "abstract": "Large Language Models (LLMs) exhibit a robust mastery of syntax when\nprocessing and generating text. While this suggests internalized understanding\nof hierarchical syntax and dependency relations, the precise mechanism by which\nthey represent syntactic structure is an open area within interpretability\nresearch. Probing provides one way to identify the mechanism of syntax being\nlinearly encoded in activations, however, no comprehensive study has yet\nestablished whether a model's probing accuracy reliably predicts its downstream\nsyntactic performance. Adopting a \"mechanisms vs. outcomes\" framework, we\nevaluate 32 open-weight transformer models and find that syntactic features\nextracted via probing fail to predict outcomes of targeted syntax evaluations\nacross English linguistic phenomena. Our results highlight a substantial\ndisconnect between latent syntactic representations found via probing and\nobservable syntactic behaviors in downstream tasks.", "published": "2025-06-20 01:46:50", "link": "http://arxiv.org/abs/2506.16678v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Continual Learning with Columnar Spiking Neural Networks", "abstract": "This study investigates columnar-organized spiking neural networks (SNNs) for\ncontinual learning and catastrophic forgetting. Using CoLaNET (Columnar Layered\nNetwork), we show that microcolumns adapt most efficiently to new tasks when\nthey lack shared structure with prior learning. We demonstrate how CoLaNET\nhyperparameters govern the trade-off between retaining old knowledge\n(stability) and acquiring new information (plasticity). Our optimal\nconfiguration learns ten sequential MNIST tasks effectively, maintaining 92%\naccuracy on each. It shows low forgetting, with only 4% performance degradation\non the first task after training on nine subsequent tasks.", "published": "2025-06-20 17:13:38", "link": "http://arxiv.org/abs/2506.17169v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "The MedPerturb Dataset: What Non-Content Perturbations Reveal About Human and Clinical LLM Decision Making", "abstract": "Clinical robustness is critical to the safe deployment of medical Large\nLanguage Models (LLMs), but key questions remain about how LLMs and humans may\ndiffer in response to the real-world variability typified by clinical settings.\nTo address this, we introduce MedPerturb, a dataset designed to systematically\nevaluate medical LLMs under controlled perturbations of clinical input.\nMedPerturb consists of clinical vignettes spanning a range of pathologies, each\ntransformed along three axes: (1) gender modifications (e.g., gender-swapping\nor gender-removal); (2) style variation (e.g., uncertain phrasing or colloquial\ntone); and (3) format changes (e.g., LLM-generated multi-turn conversations or\nsummaries). With MedPerturb, we release a dataset of 800 clinical contexts\ngrounded in realistic input variability, outputs from four LLMs, and three\nhuman expert reads per clinical context. We use MedPerturb in two case studies\nto reveal how shifts in gender identity cues, language style, or format reflect\ndiverging treatment selections between humans and LLMs. We find that LLMs are\nmore sensitive to gender and style perturbations while human annotators are\nmore sensitive to LLM-generated format perturbations such as clinical\nsummaries. Our results highlight the need for evaluation frameworks that go\nbeyond static benchmarks to assess the similarity between human clinician and\nLLM decisions under the variability characteristic of clinical settings.", "published": "2025-06-20 17:09:27", "link": "http://arxiv.org/abs/2506.17163v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Chain-of-Trust: A Progressive Trust Evaluation Framework Enabled by Generative AI", "abstract": "In collaborative systems with complex tasks relying on distributed resources,\ntrust evaluation of potential collaborators has emerged as an effective\nmechanism for task completion. However, due to the network dynamics and varying\ninformation gathering latencies, it is extremely challenging to observe and\ncollect all trust attributes of a collaborating device concurrently for a\ncomprehensive trust assessment. In this paper, a novel progressive trust\nevaluation framework, namely chain-of-trust, is proposed to make better use of\nmisaligned device attribute data. This framework, designed for effective task\ncompletion, divides the trust evaluation process into multiple chained stages\nbased on task decomposition. At each stage, based on the task completion\nprocess, the framework only gathers the latest device attribute data relevant\nto that stage, leading to reduced trust evaluation complexity and overhead. By\nleveraging advanced in-context learning, few-shot learning, and reasoning\ncapabilities, generative AI is then employed to analyze and interpret the\ncollected data to produce correct evaluation results quickly. Only devices\ndeemed trustworthy at this stage proceed to the next round of trust evaluation.\nThe framework ultimately determines devices that remain trustworthy across all\nstages. Experimental results demonstrate that the proposed framework achieves\nhigh accuracy in trust evaluation.", "published": "2025-06-20 16:33:03", "link": "http://arxiv.org/abs/2506.17130v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "When Can Model-Free Reinforcement Learning be Enough for Thinking?", "abstract": "Recent work on large language models has demonstrated the use of model-free\nreinforcement learning (RL) to train reasoning-like capabilities. The emergence\nof \"thinking\" through model-free RL is interesting as thinking actions neither\nproduce reward nor change the external world state to one where the agent is\nmore likely to get reward. This paper seeks to build a domain-independent\nunderstanding of when model-free RL will lead to \"thinking\" as a strategy for\nreward maximization. To build this understanding, we first introduce a\ntheoretical model which we call a \\textit{thought Markov decision process}\n(MDP). Thought MDPs minimally extend the classical MDP model to include an\nabstract notion of thought state and thought action. Using the thought MDP\nmodel, we prove the importance of policy initialization in determining whether\nor not thinking emerges and show formally that thought actions are equivalent\nto the agent choosing to perform a step of policy improvement before continuing\nto act. We then show that open-source LLMs satisfy the conditions that our\ntheory predicts are necessary for model-free RL to produce thinking-like\nbehavior. Finally, we hypothesize sufficient conditions that would enable\nthinking to be learned outside of language generation and introduce a toy\ndomain where a combination of multi-task pre-training and designated thought\nactions enable more data-efficient RL compared to non-thinking agents.", "published": "2025-06-20 16:23:46", "link": "http://arxiv.org/abs/2506.17124v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models", "abstract": "Large reasoning models (e.g., R1, o3) have demonstrated remarkable\nmathematical problem-solving abilities. However, the high reported accuracy of\nthese advanced models on popular datasets, reliance on purely numerical\nevaluation and potential benchmark leakage, often masks their true reasoning\nshortcomings. To address this, we propose leveraging the inherent rigor and\nmethodological complexity of mathematical proofs as a diagnostic tool to expose\nthese hidden failures. Specifically, we introduce the RFMDataset (Reveal\nFailure Modes), a collection of 200 diverse mathematical proof problems, and\nthoroughly evaluate advanced models' performance on it. Our in-depth analysis\nof their failures uncovers 10 fine-grained error types, which shows fundamental\nlimitations in current large reasoning models: 1) large reasoning models\ngrapple profoundly with mathematical proofs, with some generating entirely\ncorrect proofs for less than 20% of problems and failing even on basic ones; 2)\nmodels exhibit a diverse spectrum of reasoning failures, prominently\ndemonstrating the lack of guarantees for the correctness and rigor of\nsingle-step reasoning; and 3) models show hallucination and incompleteness\nduring the reasoning process. Our findings reveal that models' self-reflection\nis insufficient to resolve the current logical dilemmas, necessitating\nformalized and fine-grained logical training.", "published": "2025-06-20 16:14:18", "link": "http://arxiv.org/abs/2506.17114v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards Advanced Mathematical Reasoning for LLMs via First-Order Logic Theorem Proving", "abstract": "Large language models (LLMs) have shown promising first-order logic (FOL)\nreasoning capabilities with applications in various areas. However, their\neffectiveness in complex mathematical reasoning involving multi-step FOL\ndeductions is still under-researched. While LLMs perform competitively on\nestablished mathematical reasoning benchmarks, they struggle with multi-step\nFOL tasks, as demonstrated by Deepseek-Prover-V2-7B's low accuracy (4.2%) on\nour proposed theorem proving dataset. This issue arises from the limited\nexploration of diverse proof strategies and the potential for early reasoning\nmistakes to undermine entire proofs. To address these issues, we propose DREAM,\na self-adaptive solution that enhances the Diversity and REAsonability of LLMs'\ngeneration strategies. DREAM incorporates an Axiom-Driven Strategy\nDiversification mechanism to promote varied strategic outcomes and a\nSub-Proposition Error Feedback to help LLMs reflect on and correct their\nproofs. Our contributions include pioneering advancements in LLMs' mathematical\nreasoning through FOL theorem proving, introducing a novel inference stage\nsolution that improves performance by 0.6% to 6.4%, and providing a curated\ndataset of 447 mathematical theorems in Lean 4 format for evaluation.", "published": "2025-06-20 16:09:56", "link": "http://arxiv.org/abs/2506.17104v1", "categories": ["cs.AI", "cs.CL", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Dispositions and Roles of Generically Dependent Entities", "abstract": "BFO 2020 does not support functions, dispositions, and roles of generically\ndependent continuants (like software or datasets). In this paper, we argue that\nthis is a severe limitation, which prevents, for example, the adequate\nrepresentation of the functions of computer models or the various roles of\ndatasets during the execution of these models. We discuss the aspects of BFO\n2020 that prevent the representation of realizable entities of generically\ndependent continuants. Two approaches to address the issue are presented: (a)\nthe use of defined classes and (b) a proposal of changes that allow BFO to\nsupport functions, dispositions, and roles of generically dependent\ncontinuants.", "published": "2025-06-20 15:40:45", "link": "http://arxiv.org/abs/2506.17085v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "LLM-Based Bot Broadens the Range of Arguments in Online Discussions, Even When Transparently Disclosed as AI", "abstract": "A wide range of participation is essential for democracy, as it helps prevent\nthe dominance of extreme views, erosion of legitimacy, and political\npolarization. However, engagement in online political discussions often\nfeatures a limited spectrum of views due to high levels of self-selection and\nthe tendency of online platforms to facilitate exchanges primarily among\nlike-minded individuals. This study examines whether an LLM-based bot can widen\nthe scope of perspectives expressed by participants in online discussions\nthrough two pre-registered randomized experiments conducted in a chatroom. We\nevaluate the impact of a bot that actively monitors discussions, identifies\nmissing arguments, and introduces them into the conversation. The results\nindicate that our bot significantly expands the range of arguments, as measured\nby both objective and subjective metrics. Furthermore, disclosure of the bot as\nAI does not significantly alter these effects. These findings suggest that\nLLM-based moderation tools can positively influence online political discourse.", "published": "2025-06-20 15:24:31", "link": "http://arxiv.org/abs/2506.17073v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Elevating Styled Mahjong Agents with Learning from Demonstration", "abstract": "A wide variety of bots in games enriches the gameplay experience and enhances\nreplayability. Recent advancements in game artificial intelligence have\npredominantly focused on improving the proficiency of bots. Nevertheless,\ndeveloping highly competent bots with a wide range of distinct play styles\nremains a relatively under-explored area. We select the Mahjong game\nenvironment as a case study. The high degree of randomness inherent in the\nMahjong game and the prevalence of out-of-distribution states lead to\nsuboptimal performance of existing offline learning and\nLearning-from-Demonstration (LfD) algorithms. In this paper, we leverage the\ngameplay histories of existing Mahjong agents and put forward a novel LfD\nalgorithm that necessitates only minimal modifications to the Proximal Policy\nOptimization algorithm. The comprehensive empirical results illustrate that our\nproposed method not only significantly enhances the proficiency of the agents\nbut also effectively preserves their unique play styles.", "published": "2025-06-20 13:46:06", "link": "http://arxiv.org/abs/2506.16995v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Multimodal Fused Learning for Solving the Generalized Traveling Salesman Problem in Robotic Task Planning", "abstract": "Effective and efficient task planning is essential for mobile robots,\nespecially in applications like warehouse retrieval and environmental\nmonitoring. These tasks often involve selecting one location from each of\nseveral target clusters, forming a Generalized Traveling Salesman Problem\n(GTSP) that remains challenging to solve both accurately and efficiently. To\naddress this, we propose a Multimodal Fused Learning (MMFL) framework that\nleverages both graph and image-based representations to capture complementary\naspects of the problem, and learns a policy capable of generating high-quality\ntask planning schemes in real time. Specifically, we first introduce a\ncoordinate-based image builder that transforms GTSP instances into spatially\ninformative representations. We then design an adaptive resolution scaling\nstrategy to enhance adaptability across different problem scales, and develop a\nmultimodal fusion module with dedicated bottlenecks that enables effective\nintegration of geometric and spatial features. Extensive experiments show that\nour MMFL approach significantly outperforms state-of-the-art methods across\nvarious GTSP instances while maintaining the computational efficiency required\nfor real-time robotic applications. Physical robot tests further validate its\npractical effectiveness in real-world scenarios.", "published": "2025-06-20 11:51:52", "link": "http://arxiv.org/abs/2506.16931v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Single-shot thermometry of simulated Bose--Einstein condensates using artificial intelligence", "abstract": "Precise determination of thermodynamic parameters in ultracold Bose gases\nremains challenging due to the destructive nature of conventional measurement\ntechniques and inherent experimental uncertainties. We demonstrate an\nartificial intelligence approach for rapid, non-destructive estimation of the\nchemical potential and temperature from single-shot, in situ imaged density\nprofiles of finite-temperature Bose gases. Our convolutional neural network is\ntrained exclusively on quasi-2D `pancake' condensates in harmonic trap\nconfigurations. It achieves parameter extraction within fractions of a second.\nThe model also demonstrates zero-shot generalisation across both trap geometry\nand thermalisation dynamics, successfully estimating thermodynamic parameters\nfor toroidally trapped condensates with errors of only a few nanokelvin despite\nno prior exposure to such geometries during training, and maintaining\npredictive accuracy during dynamic thermalisation processes after a relatively\nbrief evolution without explicit training on non-equilibrium states. These\nresults suggest that supervised learning can overcome traditional limitations\nin ultracold atom thermometry, with extension to broader geometric\nconfigurations, temperature ranges, and additional parameters potentially\nenabling comprehensive real-time analysis of quantum gas experiments. Such\ncapabilities could significantly streamline experimental workflows whilst\nimproving measurement precision across a range of quantum fluid systems.", "published": "2025-06-20 11:36:15", "link": "http://arxiv.org/abs/2506.16925v1", "categories": ["cond-mat.quant-gas", "cs.AI", "physics.comp-ph"], "primary_category": "cond-mat.quant-gas"}
{"title": "Real-Time Black-Box Optimization for Dynamic Discrete Environments Using Embedded Ising Machines", "abstract": "Many real-time systems require the optimization of discrete variables.\nBlack-box optimization (BBO) algorithms and multi-armed bandit (MAB) algorithms\nperform optimization by repeatedly taking actions and observing the\ncorresponding instant rewards without any prior knowledge. Recently, a BBO\nmethod using an Ising machine has been proposed to find the best action that is\nrepresented by a combination of discrete values and maximizes the instant\nreward in static environments. In contrast, dynamic environments, where\nreal-time systems operate, necessitate MAB algorithms that maximize the average\nreward over multiple trials. However, due to the enormous number of actions\nresulting from the combinatorial nature of discrete optimization, conventional\nMAB algorithms cannot effectively optimize dynamic, discrete environments.\nHere, we show a heuristic MAB method for dynamic, discrete environments by\nextending the BBO method, in which an Ising machine effectively explores the\nactions while considering interactions between variables and changes in dynamic\nenvironments. We demonstrate the dynamic adaptability of the proposed method in\na wireless communication system with moving users.", "published": "2025-06-20 11:31:43", "link": "http://arxiv.org/abs/2506.16924v1", "categories": ["cs.AI", "cs.ET", "I.2.8"], "primary_category": "cs.AI"}
{"title": "Towards Effective Complementary Security Analysis using Large Language Models", "abstract": "A key challenge in security analysis is the manual evaluation of potential\nsecurity weaknesses generated by static application security testing (SAST)\ntools. Numerous false positives (FPs) in these reports reduce the effectiveness\nof security analysis. We propose using Large Language Models (LLMs) to improve\nthe assessment of SAST findings. We investigate the ability of LLMs to reduce\nFPs while trying to maintain a perfect true positive rate, using datasets\nextracted from the OWASP Benchmark (v1.2) and a real-world software project.\nOur results indicate that advanced prompting techniques, such as\nChain-of-Thought and Self-Consistency, substantially improve FP detection.\nNotably, some LLMs identified approximately 62.5% of FPs in the OWASP Benchmark\ndataset without missing genuine weaknesses. Combining detections from different\nLLMs would increase this FP detection to approximately 78.9%. Additionally, we\ndemonstrate our approach's generalizability using a real-world dataset covering\nfive SAST tools, three programming languages, and infrastructure files. The\nbest LLM detected 33.85% of all FPs without missing genuine weaknesses, while\ncombining detections from different LLMs would increase this detection to\n38.46%. Our findings highlight the potential of LLMs to complement traditional\nSAST tools, enhancing automation and reducing resources spent addressing false\nalarms.", "published": "2025-06-20 10:46:35", "link": "http://arxiv.org/abs/2506.16899v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Learning Dexterous Object Handover", "abstract": "Object handover is an important skill that we use daily when interacting with\nother humans. To deploy robots in collaborative setting, like houses, being\nable to receive and handing over objects safely and efficiently becomes a\ncrucial skill. In this work, we demonstrate the use of Reinforcement Learning\n(RL) for dexterous object handover between two multi-finger hands. Key to this\ntask is the use of a novel reward function based on dual quaternions to\nminimize the rotation distance, which outperforms other rotation\nrepresentations such as Euler and rotation matrices. The robustness of the\ntrained policy is experimentally evaluated by testing w.r.t. objects that are\nnot included in the training distribution, and perturbations during the\nhandover process. The results demonstrate that the trained policy successfully\nperform this task, achieving a total success rate of 94% in the best-case\nscenario after 100 experiments, thereby showing the robustness of our policy\nwith novel objects. In addition, the best-case performance of the policy\ndecreases by only 13.8% when the other robot moves during the handover, proving\nthat our policy is also robust to this type of perturbation, which is common in\nreal-world object handovers.", "published": "2025-06-20 08:22:46", "link": "http://arxiv.org/abs/2506.16822v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Robust Dynamic Material Handling via Adaptive Constrained Evolutionary Reinforcement Learning", "abstract": "Dynamic material handling (DMH) involves the assignment of dynamically\narriving material transporting tasks to suitable vehicles in real time for\nminimising makespan and tardiness. In real-world scenarios, historical task\nrecords are usually available, which enables the training of a decision policy\non multiple instances consisting of historical records. Recently, reinforcement\nlearning has been applied to solve DMH. Due to the occurrence of dynamic events\nsuch as new tasks, adaptability is highly required. Solving DMH is challenging\nsince constraints including task delay should be satisfied. A feedback is\nreceived only when all tasks are served, which leads to sparse reward. Besides,\nmaking the best use of limited computational resources and historical records\nfor training a robust policy is crucial. The time allocated to different\nproblem instances would highly impact the learning process. To tackle those\nchallenges, this paper proposes a novel adaptive constrained evolutionary\nreinforcement learning (ACERL) approach, which maintains a population of actors\nfor diverse exploration. ACERL accesses each actor for tackling sparse rewards\nand constraint violation to restrict the behaviour of the policy. Moreover,\nACERL adaptively selects the most beneficial training instances for improving\nthe policy. Extensive experiments on eight training and eight unseen test\ninstances demonstrate the outstanding performance of ACERL compared with\nseveral state-of-the-art algorithms. Policies trained by ACERL can schedule the\nvehicles while fully satisfying the constraints. Additional experiments on 40\nunseen noised instances show the robust performance of ACERL. Cross-validation\nfurther presents the overall effectiveness of ACREL. Besides, a rigorous\nablation study highlights the coordination and benefits of each ingredient of\nACERL.", "published": "2025-06-20 07:20:22", "link": "http://arxiv.org/abs/2506.16795v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "Reinforcement learning for hybrid charging stations planning and operation considering fixed and mobile chargers", "abstract": "The success of vehicle electrification, which brings significant societal and\nenvironmental benefits, is contingent upon the availability of efficient and\nadaptable charging infrastructure. Traditional fixed-location charging stations\noften face issues like underutilization or congestion due to the dynamic nature\nof charging demand. Mobile chargers have emerged as a flexible solution,\ncapable of relocating to align with these demand fluctuations. This paper\naddresses the optimal planning and operation of hybrid charging\ninfrastructures, integrating both fixed and mobile chargers within urban road\nnetworks. We introduce the Hybrid Charging Station Planning and Operation\n(HCSPO) problem, which simultaneously optimizes the location and configuration\nof fixed charging stations and schedules mobile chargers for dynamic\noperations. Our approach incorporates a charging demand prediction model\ngrounded in Model Predictive Control (MPC) to enhance decision-making. To solve\nthe HCSPO problem, we propose a deep reinforcement learning method, augmented\nwith heuristic scheduling techniques, to effectively bridge the planning of\nfixed chargers with the real-time operation of mobile chargers. Extensive case\nstudies using real-world urban scenarios demonstrate that our method\nsignificantly improves the availability of charging infrastructure and reduces\nuser inconvenience compared to existing solutions and baselines.", "published": "2025-06-20 05:51:02", "link": "http://arxiv.org/abs/2506.16764v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Interpretable Low-Dimensional Modeling of Spatiotemporal Agent States for Decision Making in Football Tactics", "abstract": "Understanding football tactics is crucial for managers and analysts. Previous\nresearch has proposed models based on spatial and kinematic equations, but\nthese are computationally expensive. Also, Reinforcement learning approaches\nuse player positions and velocities but lack interpretability and require large\ndatasets. Rule-based models align with expert knowledge but have not fully\nconsidered all players' states. This study explores whether low-dimensional,\nrule-based models using spatiotemporal data can effectively capture football\ntactics. Our approach defines interpretable state variables for both the\nball-holder and potential pass receivers, based on criteria that explore\noptions like passing. Through discussions with a manager, we identified key\nvariables representing the game state. We then used StatsBomb event data and\nSkillCorner tracking data from the 2023$/$24 LaLiga season to train an XGBoost\nmodel to predict pass success. The analysis revealed that the distance between\nthe player and the ball, as well as the player's space score, were key factors\nin determining successful passes. Our interpretable low-dimensional modeling\nfacilitates tactical analysis through the use of intuitive variables and\nprovides practical value as a tool to support decision-making in football.", "published": "2025-06-20 02:37:52", "link": "http://arxiv.org/abs/2506.16696v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Better Language Model Inversion by Compactly Representing Next-Token Distributions", "abstract": "Language model inversion seeks to recover hidden prompts using only language\nmodel outputs. This capability has implications for security and accountability\nin language model deployments, such as leaking private information from an\nAPI-protected language model's system message. We propose a new method --\nprompt inversion from logprob sequences (PILS) -- that recovers hidden prompts\nby gleaning clues from the model's next-token probabilities over the course of\nmultiple generation steps. Our method is enabled by a key insight: The\nvector-valued outputs of a language model occupy a low-dimensional subspace.\nThis enables us to losslessly compress the full next-token probability\ndistribution over multiple generation steps using a linear map, allowing more\noutput information to be used for inversion. Our approach yields massive gains\nover previous state-of-the-art methods for recovering hidden prompts, achieving\n2--3.5 times higher exact recovery rates across test sets, in one case\nincreasing the recovery rate from 17% to 60%. Our method also exhibits\nsurprisingly good generalization behavior; for instance, an inverter trained on\n16 generations steps gets 5--27 points higher prompt recovery when we increase\nthe number of steps to 32 at test time. Furthermore, we demonstrate strong\nperformance of our method on the more challenging task of recovering hidden\nsystem messages. We also analyze the role of verbatim repetition in prompt\nrecovery and propose a new method for cross-family model transfer for\nlogit-based inverters. Our findings show that next-token probabilities are a\nconsiderably more vulnerable attack surface for inversion attacks than\npreviously known.", "published": "2025-06-20 15:53:51", "link": "http://arxiv.org/abs/2506.17090v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models", "abstract": "Large reasoning models (e.g., R1, o3) have demonstrated remarkable\nmathematical problem-solving abilities. However, the high reported accuracy of\nthese advanced models on popular datasets, reliance on purely numerical\nevaluation and potential benchmark leakage, often masks their true reasoning\nshortcomings. To address this, we propose leveraging the inherent rigor and\nmethodological complexity of mathematical proofs as a diagnostic tool to expose\nthese hidden failures. Specifically, we introduce the RFMDataset (Reveal\nFailure Modes), a collection of 200 diverse mathematical proof problems, and\nthoroughly evaluate advanced models' performance on it. Our in-depth analysis\nof their failures uncovers 10 fine-grained error types, which shows fundamental\nlimitations in current large reasoning models: 1) large reasoning models\ngrapple profoundly with mathematical proofs, with some generating entirely\ncorrect proofs for less than 20% of problems and failing even on basic ones; 2)\nmodels exhibit a diverse spectrum of reasoning failures, prominently\ndemonstrating the lack of guarantees for the correctness and rigor of\nsingle-step reasoning; and 3) models show hallucination and incompleteness\nduring the reasoning process. Our findings reveal that models' self-reflection\nis insufficient to resolve the current logical dilemmas, necessitating\nformalized and fine-grained logical training.", "published": "2025-06-20 16:14:18", "link": "http://arxiv.org/abs/2506.17114v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Emergent Temporal Correspondences from Video Diffusion Transformers", "abstract": "Recent advancements in video diffusion models based on Diffusion Transformers\n(DiTs) have achieved remarkable success in generating temporally coherent\nvideos. Yet, a fundamental question persists: how do these models internally\nestablish and represent temporal correspondences across frames? We introduce\nDiffTrack, the first quantitative analysis framework designed to answer this\nquestion. DiffTrack constructs a dataset of prompt-generated video with pseudo\nground-truth tracking annotations and proposes novel evaluation metrics to\nsystematically analyze how each component within the full 3D attention\nmechanism of DiTs (e.g., representations, layers, and timesteps) contributes to\nestablishing temporal correspondences. Our analysis reveals that query-key\nsimilarities in specific, but not all, layers play a critical role in temporal\nmatching, and that this matching becomes increasingly prominent during the\ndenoising process. We demonstrate practical applications of DiffTrack in\nzero-shot point tracking, where it achieves state-of-the-art performance\ncompared to existing vision foundation and self-supervised video models.\nFurther, we extend our findings to motion-enhanced video generation with a\nnovel guidance method that improves temporal consistency of generated videos\nwithout additional training. We believe our work offers crucial insights into\nthe inner workings of video DiTs and establishes a foundation for further\nresearch and applications leveraging their temporal understanding.", "published": "2025-06-20 17:59:55", "link": "http://arxiv.org/abs/2506.17220v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-label Scene Classification for Autonomous Vehicles: Acquiring and Accumulating Knowledge from Diverse Datasets", "abstract": "Driving scene identification, which assigns multiple non-exclusive class\nlabels to a scene, provides the contextual awareness necessary for enhancing\nautonomous vehicles' ability to understand, reason about, and interact with the\ncomplex driving environment. As a multi-label classification problem, it is\nbetter tackled via multitasking learning. However, directly training a\nmulti-label classification model for driving scene identification through\nmultitask learning presents two main challenges: acquiring a balanced,\ncomprehensively annotated multi-label dataset and balancing learning across\ndifferent tasks. This paper introduces a novel learning system that synergizes\nknowledge acquisition and accumulation (KAA) with consistency-based active\nlearning (CAL) to address those challenges. KAA acquires and accumulates\nknowledge about scene identification from various single-label datasets via\nmonotask learning. Subsequently, CAL effectively resolves the knowledge gap\ncaused by the discrepancy between single-label and multi-label data. An\nablation study on our Driving Scene Identification (DSI) dataset demonstrates a\n56.1% performance increase over the baseline model pretrained on ImageNet. Of\nthis, KAA accounts for 31.3% of the gain, and CAL contributes 24.8%. Moreover,\nKAA-CAL stands out as the best performer when compared to state-of-the-art\n(SOTA) multi-label models on two public datasets, BDD100K and HSD, achieving\nthis while using 85% less data. The DSI dataset and the implementation code for\nKAA-CAL are available at https://github.com/KELISBU/KAA-CAL .", "published": "2025-06-20 16:06:53", "link": "http://arxiv.org/abs/2506.17101v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought", "abstract": "Real-World Image Super-Resolution is one of the most challenging task in\nimage restoration. However, existing methods struggle with an accurate\nunderstanding of degraded image content, leading to reconstructed results that\nare both low-fidelity and unnatural. We present RealSR-R1 in this work, which\nempowers the RealSR models with understanding and reasoning capabilities.\nInspired by the success of Chain of Thought (CoT) in large language models\n(LLMs), we simulate the human process of handling degraded images and propose\nthe VLCoT framework, which integrates vision and language reasoning. The\nframework aims to precisely restore image details by progressively generating\nmore comprehensive text and higher-resolution images. To overcome the challenge\nof traditional supervised learning CoT failing to generalize to real-world\nscenarios, we introduce, for the first time, Group Relative Policy Optimization\n(GRPO) into the Real-World Image Super-Resolution task. We propose VLCoT-GRPO\nas a solution, which designs four reward functions: (1) Format reward, used to\nstandardize the CoT process; (2) Degradation reward, to incentivize accurate\ndegradation estimation; (3) Understanding reward, to ensure the accuracy of the\ngenerated content; and (4) Generation reward, where we propose using a visual\nexpert model to evaluate the quality of generated images, encouraging the model\nto generate more realistic images. Extensive experiments demonstrate that our\nproposed RealSR-R1 can generate realistic details and accurately understand\nimage content, particularly in semantically rich scenes or images with severe\ndegradation.", "published": "2025-06-20 07:21:21", "link": "http://arxiv.org/abs/2506.16796v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TextBraTS: Text-Guided Volumetric Brain Tumor Segmentation with Innovative Dataset Development and Fusion Module Exploration", "abstract": "Deep learning has demonstrated remarkable success in medical image\nsegmentation and computer-aided diagnosis. In particular, numerous advanced\nmethods have achieved state-of-the-art performance in brain tumor segmentation\nfrom MRI scans. While recent studies in other medical imaging domains have\nrevealed that integrating textual reports with visual data can enhance\nsegmentation accuracy, the field of brain tumor analysis lacks a comprehensive\ndataset that combines radiological images with corresponding textual\nannotations. This limitation has hindered the exploration of multimodal\napproaches that leverage both imaging and textual data.\n  To bridge this critical gap, we introduce the TextBraTS dataset, the first\npublicly available volume-level multimodal dataset that contains paired MRI\nvolumes and rich textual annotations, derived from the widely adopted BraTS2020\nbenchmark. Building upon this novel dataset, we propose a novel baseline\nframework and sequential cross-attention method for text-guided volumetric\nmedical image segmentation. Through extensive experiments with various\ntext-image fusion strategies and templated text formulations, our approach\ndemonstrates significant improvements in brain tumor segmentation accuracy,\noffering valuable insights into effective multimodal integration techniques.\n  Our dataset, implementation code, and pre-trained models are publicly\navailable at https://github.com/Jupitern52/TextBraTS.", "published": "2025-06-20 06:57:56", "link": "http://arxiv.org/abs/2506.16784v2", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "A Prior-Guided Joint Diffusion Model in Projection Domain for PET Tracer Conversion", "abstract": "Positron emission tomography (PET) is widely used to assess metabolic\nactivity, but its application is limited by the availability of radiotracers.\n18F-labeled fluorodeoxyglucose (18F-FDG) is the most commonly used tracer but\nshows limited effectiveness for certain tumors. In contrast,\n6-18F-fluoro-3,4-dihydroxy-L-phenylalanine (18F-DOPA) offers higher specificity\nfor neuroendocrine tumors and neurological disorders. However, the complexity\nof its synthesis process and constraints on transportation time have limited\nits clinical application. Among different forms of raw data acquired by the\nscanner, sinogram is a commonly used representation in PET imaging. Therefore,\nmodeling in projection domain enables more direct utilization of the original\ninformation, potentially reducing the accumulation errors during the image\nreconstruction process. Inspired by these factors, this study proposes a\nprior-guided joint diffusion model (PJDM) for transforming 18F-FDG PET\nsinograms into 18F-DOPA PET sinograms. During inference, an initial synthetic\n18F-DOPA PET sinogram is first generated using a higher-order hybrid sampler.\nThis sinogram is then degraded and serves as an additional condition to guide\nthe iterative refinement process. Experimental results demonstrated that PJDM\neffectively improved both sinogram quality and the final synthetic outcomes.\nThe code is available at: https://github.com/yqx7150/PJDM.", "published": "2025-06-20 04:05:34", "link": "http://arxiv.org/abs/2506.16733v2", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "A Comparative Analysis of Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) as Dimensionality Reduction Techniques", "abstract": "High-dimensional image data often require dimensionality reduction before\nfurther analysis. This paper provides a purely analytical comparison of two\nlinear techniques-Principal Component Analysis (PCA) and Singular Value\nDecomposition (SVD). After the derivation of each algorithm from first\nprinciples, we assess their interpretability, numerical stability, and\nsuitability for differing matrix shapes. building on classical and recent\nnumerical literature, We synthesize rule-of-thumb guidelines for choosing one\nout of the two algorithms without empirical benchmarking, building on classical\nand recent numerical literature. Limitations and directions for future\nexperimental work are outlined at the end.", "published": "2025-06-20 00:19:45", "link": "http://arxiv.org/abs/2506.16663v2", "categories": ["cs.CV", "cs.NA", "math.NA"], "primary_category": "cs.CV"}
{"title": "Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings", "abstract": "Generating diverse, all-atom conformational ensembles of dynamic proteins\nsuch as G-protein-coupled receptors (GPCRs) is critical for understanding their\nfunction, yet most generative models simplify atomic detail or ignore\nconformational diversity altogether. We present latent diffusion for full\nprotein generation (LD-FPG), a framework that constructs complete all-atom\nprotein structures, including every side-chain heavy atom, directly from\nmolecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neural\nnetwork (ChebNet) to obtain low-dimensional latent embeddings of protein\nconformations, which are processed using three pooling strategies: blind,\nsequential and residue-based. A diffusion model trained on these latent\nrepresentations generates new samples that a decoder, optionally regularized by\ndihedral-angle losses, maps back to Cartesian coordinates. Using D2R-MD, a\n2-microsecond MD trajectory (12 000 frames) of the human dopamine D2 receptor\nin a membrane environment, the sequential and residue-based pooling strategy\nreproduces the reference ensemble with high structural fidelity (all-atom lDDT\nof approximately 0.7; C-alpha-lDDT of approximately 0.8) and recovers backbone\nand side-chain dihedral-angle distributions with a Jensen-Shannon divergence of\nless than 0.03 compared to the MD data. LD-FPG thereby offers a practical route\nto system-specific, all-atom ensemble generation for large proteins, providing\na promising tool for structure-based therapeutic design on complex, dynamic\ntargets. The D2R-MD dataset and our implementation are freely available to\nfacilitate further research.", "published": "2025-06-20 15:12:34", "link": "http://arxiv.org/abs/2506.17064v2", "categories": ["q-bio.BM", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "Soft decision trees for survival analysis", "abstract": "Decision trees are popular in survival analysis for their interpretability\nand ability to model complex relationships. Survival trees, which predict the\ntiming of singular events using censored historical data, are typically built\nthrough heuristic approaches. Recently, there has been growing interest in\nglobally optimized trees, where the overall tree is trained by minimizing the\nerror function over all its parameters. We propose a new soft survival tree\nmodel (SST), with a soft splitting rule at each branch node, trained via a\nnonlinear optimization formulation amenable to decomposition. Since SSTs\nprovide for every input vector a specific survival function associated to a\nsingle leaf node, they satisfy the conditional computation property and inherit\nthe related benefits. SST and the training formulation combine flexibility with\ninterpretability: any smooth survival function (parametric, semiparametric, or\nnonparametric) estimated through maximum likelihood can be used, and each leaf\nnode of an SST yields a cluster of distinct survival functions which are\nassociated to the data points routed to it. Numerical experiments on 15\nwell-known datasets show that SSTs, with parametric and spline-based\nsemiparametric survival functions, trained using an adaptation of the\nnode-based decomposition algorithm proposed by Consolo et al. (2024) for soft\nregression trees, outperform three benchmark survival trees in terms of four\nwidely-used discrimination and calibration measures. SSTs can also be extended\nto consider group fairness.", "published": "2025-06-20 08:51:33", "link": "http://arxiv.org/abs/2506.16846v2", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Closed curve covering and multiagent TSP ratios", "abstract": "How efficiently can a closed curve of unit length in $\\mathbb{R}^d$ be\ncovered by $k$ closed curves so as to minimize the maximum length of the $k$\ncurves? We show that the maximum length is at most $2k^{-1} - \\frac{1}{4}\nk^{-4}$ for all $k\\geq 2$ and $d \\geq 2$. As a byproduct, we show that $k$\nagents can traverse a Euclidean TSP instance significantly faster than a single\nagent. We thereby sharpen recent planar results by Berendsohn, Kim, and Kozma\n(2025) and extend these improvements to all dimensions.", "published": "2025-06-20 01:26:23", "link": "http://arxiv.org/abs/2506.16675v1", "categories": ["math.MG", "cs.DM"], "primary_category": "math.MG"}
{"title": "Mapping the Evolution of Research Contributions using KnoVo", "abstract": "This paper presents KnoVo (Knowledge Evolution), an intelligent framework\ndesigned for quantifying and analyzing the evolution of research novelty in the\nscientific literature. Moving beyond traditional citation analysis, which\nprimarily measures impact, KnoVo determines a paper's novelty relative to both\nprior and subsequent work within its multilayered citation network. Given a\ntarget paper's abstract, KnoVo utilizes Large Language Models (LLMs) to\ndynamically extract dimensions of comparison (e.g., methodology, application,\ndataset). The target paper is then compared to related publications along these\nsame extracted dimensions. This comparative analysis, inspired by tournament\nselection, yields quantitative novelty scores reflecting the relative\nimprovement, equivalence, or inferiority of the target paper in specific\naspects. By aggregating these scores and visualizing their progression, for\ninstance, through dynamic evolution graphs and comparative radar charts, KnoVo\nfacilitates researchers not only to assess originality and identify similar\nwork, but also to track knowledge evolution along specific research dimensions,\nuncover research gaps, and explore cross-disciplinary connections. We\ndemonstrate these capabilities through a detailed analysis of 20 diverse papers\nfrom multiple scientific fields and report on the performance of various\nopen-source LLMs within the KnoVo framework.", "published": "2025-06-20 23:17:11", "link": "http://arxiv.org/abs/2506.17508v1", "categories": ["cs.DL", "cs.AI", "cs.DB", "cs.ET", "cs.IR"], "primary_category": "cs.DL"}
{"title": "PreQRAG -- Classify and Rewrite for Enhanced RAG", "abstract": "This paper presents the submission of the UDInfo team to the SIGIR 2025\nLiveRAG Challenge. We introduce PreQRAG, a Retrieval Augmented Generation (RAG)\narchitecture designed to improve retrieval and generation quality through\ntargeted question preprocessing. PreQRAG incorporates a pipeline that first\nclassifies each input question as either single-document or multi-document\ntype. For single-document questions, we employ question rewriting techniques to\nimprove retrieval precision and generation relevance. For multi-document\nquestions, we decompose complex queries into focused sub-questions that can be\nprocessed more effectively by downstream components. This classification and\nrewriting strategy improves the RAG performance. Experimental evaluation of the\nLiveRAG Challenge dataset demonstrates the effectiveness of our\nquestion-type-aware architecture, with PreQRAG achieving the preliminary second\nplace in Session 2 of the LiveRAG challenge.", "published": "2025-06-20 22:02:05", "link": "http://arxiv.org/abs/2506.17493v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "From Drawings to Decisions: A Hybrid Vision-Language Framework for Parsing 2D Engineering Drawings into Structured Manufacturing Knowledge", "abstract": "Efficient and accurate extraction of key information from 2D engineering\ndrawings is essential for advancing digital manufacturing workflows. Such\ninformation includes geometric dimensioning and tolerancing (GD&T), measures,\nmaterial specifications, and textual annotations. Manual extraction is slow and\nlabor-intensive, while generic OCR models often fail due to complex layouts,\nengineering symbols, and rotated text, leading to incomplete and unreliable\noutputs. These limitations result in incomplete and unreliable outputs. To\naddress these challenges, we propose a hybrid vision-language framework that\nintegrates a rotation-aware object detection model (YOLOv11-obb) with a\ntransformer-based vision-language parser. Our structured pipeline applies\nYOLOv11-OBB to localize annotations and extract oriented bounding box (OBB)\npatches, which are then parsed into structured outputs using a fine-tuned,\nlightweight vision-language model (VLM). We curate a dataset of 1,367 2D\nmechanical drawings annotated across nine key categories. YOLOv11-OBB is\ntrained on this dataset to detect OBBs and extract annotation patches. These\nare parsed using two open-source VLMs: Donut and Florence-2. Both models are\nlightweight and well-suited for specialized industrial tasks under limited\ncomputational overhead. Following fine-tuning of both models on the curated\ndataset of image patches paired with structured annotation labels, a\ncomparative experiment is conducted to evaluate parsing performance across four\nkey metrics. Donut outperforms Florence-2, achieving 88.5% precision, 99.2%\nrecall, and a 93.5% F1-score, with a hallucination rate of 11.5%. Finally, a\ncase study demonstrates how the extracted structured information supports\ndownstream manufacturing tasks such as process and tool selection, showcasing\nthe practical utility of the proposed framework in modernizing 2D drawing\ninterpretation.", "published": "2025-06-20 17:10:01", "link": "http://arxiv.org/abs/2506.17374v1", "categories": ["cs.CV", "cs.AI", "cs.IR"], "primary_category": "cs.CV"}
{"title": "On the Power of Spatial Locality on Online Routing Problems", "abstract": "We consider the online versions of two fundamental routing problems,\ntraveling salesman (TSP) and dial-a-ride (DARP), which have a variety of\nrelevant applications in logistics and robotics. The online versions of these\nproblems concern with efficiently serving a sequence of requests presented in a\nreal-time on-line fashion located at points of a metric space by servers\n(salesmen/vehicles/robots). In this paper, motivated from real-world\napplications, such as Uber/Lyft rides, where some limited knowledge is\navailable on the future requests, we propose the {\\em spatial locality} model\nthat provides in advance the distance within which new request(s) will be\nreleased from the current position of server(s). We study the usefulness of\nthis advanced information on achieving the improved competitive ratios for both\nthe problems with $k\\geq 1$ servers, compared to the competitive results\nestablished in the literature without such spatial locality consideration. We\nshow that small locality is indeed useful in obtaining improved competitive\nratios irrespective of the metric space.", "published": "2025-06-20 23:46:33", "link": "http://arxiv.org/abs/2506.17517v1", "categories": ["cs.DS", "cs.MA", "cs.RO"], "primary_category": "cs.DS"}
{"title": "Cash or Comfort? How LLMs Value Your Inconvenience", "abstract": "Large Language Models (LLMs) are increasingly proposed as near-autonomous\nartificial intelligence (AI) agents capable of making everyday decisions on\nbehalf of humans. Although LLMs perform well on many technical tasks, their\nbehaviour in personal decision-making remains less understood. Previous studies\nhave assessed their rationality and moral alignment with human decisions.\nHowever, the behaviour of AI assistants in scenarios where financial rewards\nare at odds with user comfort has not yet been thoroughly explored. In this\npaper, we tackle this problem by quantifying the prices assigned by multiple\nLLMs to a series of user discomforts: additional walking, waiting, hunger and\npain. We uncover several key concerns that strongly question the prospect of\nusing current LLMs as decision-making assistants: (1) a large variance in\nresponses between LLMs, (2) within a single LLM, responses show fragility to\nminor variations in prompt phrasing (e.g., reformulating the question in the\nfirst person can considerably alter the decision), (3) LLMs can accept\nunreasonably low rewards for major inconveniences (e.g., 1 Euro to wait 10\nhours), and (4) LLMs can reject monetary gains where no discomfort is imposed\n(e.g., 1,000 Euro to wait 0 minutes). These findings emphasize the need for\nscrutiny of how LLMs value human inconvenience, particularly as we move toward\napplications where such cash-versus-comfort trade-offs are made on users'\nbehalf.", "published": "2025-06-20 14:49:20", "link": "http://arxiv.org/abs/2506.17367v1", "categories": ["cs.CL", "cs.AI", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Code Generation for Near-Roofline Finite Element Actions on GPUs from Symbolic Variational Forms", "abstract": "We present a novel parallelization strategy for evaluating Finite Element\nMethod (FEM) variational forms on GPUs, focusing on those that are expressible\nthrough the Unified Form Language (UFL) on simplex meshes. We base our approach\non code transformations, wherein we construct a space of scheduling candidates\nand rank them via a heuristic cost model to effectively handle the large\ndiversity of computational workloads that can be expressed in this way. We\npresent a design of a search space to which the cost model is applied, along\nwith an associated pruning strategy to limit the number of configurations that\nneed to be empirically evaluated. The goal of our design is to strike a balance\nbetween the device's latency-hiding capabilities and the amount of state space,\na key factor in attaining near-roofline performance.\n  To make our work widely available, we have prototyped our parallelization\nstrategy within the \\textsc{Firedrake} framework, a UFL-based FEM solver. We\nevaluate the performance of our parallelization scheme on two generations of\nNvidia GPUs, specifically the Titan V (Volta architecture) and Tesla K40c\n(Kepler architecture), across a range of operators commonly used in\napplications, including fluid dynamics, wave propagation, and structural\nmechanics, in 2D and 3D geometries. Our results demonstrate that our proposed\nalgorithm achieves more than $50\\%$ roofline performance in $65\\%$ of the test\ncases on both devices.", "published": "2025-06-20 20:23:42", "link": "http://arxiv.org/abs/2506.17471v1", "categories": ["cs.DC", "cs.MS", "cs.NA", "cs.PF", "math.NA", "65Y05"], "primary_category": "cs.DC"}
{"title": "Bounds-constrained finite element approximation of time-dependent partial differential equations", "abstract": "Finite element methods provide accurate and efficient methods for the\nnumerical solution of partial differential equations by means of restricting\nvariational problems to finite-dimensional approximating spaces. However, they\ndo not guarantee enforcement of bounds constraints inherent in the original\nproblem. Previous work enforces these bounds constraints by replacing the\nvariational equations with variational inequalities. We extend this approach to\ncollocation-type Runge-Kutta methods for time-dependent problems, obtaining\n(formally) high order methods in both space and time. By using a novel\nreformulation of the collocation scheme, we can guarantee that the bounds\nconstraints hold uniformly in time. Numerical examples for a model of\nphytoplankton growth, the heat equation, and the Cahn-Hilliard system are\ngiven.", "published": "2025-06-20 20:07:05", "link": "http://arxiv.org/abs/2506.17464v1", "categories": ["math.NA", "cs.NA", "65M60 (primary) 65L06 (secondary)"], "primary_category": "math.NA"}
{"title": "Fast solvers for the high-order FEM simplicial de Rham complex", "abstract": "We present new finite elements for solving the Riesz maps of the de Rham\ncomplex on triangular and tetrahedral meshes at high order. The finite elements\ndiscretize the same spaces as usual, but with different basis functions, so\nthat the resulting matrices have desirable properties. These properties mean\nthat we can solve the Riesz maps to a given accuracy in a $p$-robust number of\niterations with $\\mathcal{O}(p^6)$ flops in three dimensions, rather than the\nna\\\"ive $\\mathcal{O}(p^9)$ flops.\n  The degrees of freedom build upon an idea of Demkowicz et al., and consist of\nintegral moments on an equilateral reference simplex with respect to a\nnumerically computed polynomial basis that is orthogonal in two different inner\nproducts. As a result, the interior-interface and interior-interior couplings\nare provably weak, and we devise a preconditioning strategy by neglecting them.\nThe combination of this approach with a space decomposition method on vertex\nand edge star patches allows us to efficiently solve the canonical Riesz maps\nat high order. We apply this to solving the Hodge Laplacians of the de Rham\ncomplex with novel augmented Lagrangian preconditioners.", "published": "2025-06-20 18:10:11", "link": "http://arxiv.org/abs/2506.17406v1", "categories": ["math.NA", "cs.NA", "65F08, 65N35, 65N55"], "primary_category": "math.NA"}
{"title": "Convergent Proximal Multiblock ADMM for Nonconvex Dynamics-Constrained Optimization", "abstract": "This paper proposes a provably convergent multiblock ADMM for nonconvex\noptimization with nonlinear dynamics constraints, overcoming the divergence\nissue in classical extensions. We consider a class of optimization problems\nthat arise from discretization of dynamics-constrained variational problems\nthat are optimization problems for a functional constrained by time-dependent\nODEs or PDEs. This is a family of $n$-sum nonconvex optimization problems with\nnonlinear constraints. We study the convergence properties of the proximal\nalternating direction method of multipliers (proximal ADMM) applied to those\nproblems. Taking the advantage of the special problem structure, we show that\nunder local Lipschitz and local $L$-smooth conditions, the sequence generated\nby the proximal ADMM is bounded and all accumulation points are KKT points.\nBased on our analysis, we also design a procedure to determine the penalty\nparameters $\\rho_i$ and the proximal parameters $\\eta_i$. We further prove that\namong all the subsequences that converge, the fast one converges at the rate of\n$o(1/k)$. The numerical experiments are performed on 4D variational data\nassimilation problems and as the solver of implicit schemes for stiff problems.\nThe proposed proximal ADMM has more stable performance than gradient-based\nmethods. We discuss the implementation to solve the subproblems, a new way to\nsolve the implicit schemes, and the advantages of the proposed algorithm.", "published": "2025-06-20 18:09:56", "link": "http://arxiv.org/abs/2506.17405v1", "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "Gaussian Processes and Reproducing Kernels: Connections and Equivalences", "abstract": "This monograph studies the relations between two approaches using positive\ndefinite kernels: probabilistic methods using Gaussian processes, and\nnon-probabilistic methods using reproducing kernel Hilbert spaces (RKHS). They\nare widely studied and used in machine learning, statistics, and numerical\nanalysis. Connections and equivalences between them are reviewed for\nfundamental topics such as regression, interpolation, numerical integration,\ndistributional discrepancies, and statistical dependence, as well as for sample\npath properties of Gaussian processes. A unifying perspective for these\nequivalences is established, based on the equivalence between the Gaussian\nHilbert space and the RKHS. The monograph serves as a basis to bridge many\nother methods based on Gaussian processes and reproducing kernels, which are\ndeveloped in parallel by the two research communities.", "published": "2025-06-20 12:08:18", "link": "http://arxiv.org/abs/2506.17366v1", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "math.PR", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Empirical Models of the Time Evolution of SPX Option Prices", "abstract": "The key objective of this paper is to develop an empirical model for pricing\nSPX options that can be simulated over future paths of the SPX. To accomplish\nthis, we formulate and rigorously evaluate several statistical models,\nincluding neural network, random forest, and linear regression. These models\nuse the observed characteristics of the options as inputs -- their price,\nmoneyness and time-to-maturity, as well as a small set of external inputs, such\nas the SPX and its past history, dividend yield, and the risk-free rate. Model\nevaluation is performed on historical options data, spanning 30 years of daily\nobservations. Significant effort is given to understanding the data and\nensuring explainability for the neural network. A neural network model with two\nhidden layers and four neurons per layer, trained with minimal hyperparameter\ntuning, performs well against the theoretical Black-Scholes-Merton model for\nEuropean options, as well as two other empirical models based on the random\nforest and the linear regression. It delivers arbitrage-free option prices\nwithout requiring these conditions to be imposed.", "published": "2025-06-20 23:21:39", "link": "http://arxiv.org/abs/2506.17511v1", "categories": ["q-fin.PR", "q-fin.CP"], "primary_category": "q-fin.PR"}
{"title": "A Survey of State Representation Learning for Deep Reinforcement Learning", "abstract": "Representation learning methods are an important tool for addressing the\nchallenges posed by complex observations spaces in sequential decision making\nproblems. Recently, many methods have used a wide variety of types of\napproaches for learning meaningful state representations in reinforcement\nlearning, allowing better sample efficiency, generalization, and performance.\nThis survey aims to provide a broad categorization of these methods within a\nmodel-free online setting, exploring how they tackle the learning of state\nrepresentations differently. We categorize the methods into six main classes,\ndetailing their mechanisms, benefits, and limitations. Through this taxonomy,\nour aim is to enhance the understanding of this field and provide a guide for\nnew researchers. We also discuss techniques for assessing the quality of\nrepresentations, and detail relevant future directions.", "published": "2025-06-20 23:47:04", "link": "http://arxiv.org/abs/2506.17518v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Agentic Decision-Making", "abstract": "As Large Language Models (LLMs) are integrated into safety-critical\napplications involving sequential decision-making in the real world, it is\nessential to know when to trust LLM decisions. Existing LLM Uncertainty\nQuantification (UQ) methods are primarily designed for single-turn\nquestion-answering formats, resulting in multi-step decision-making scenarios,\ne.g., LLM agentic system, being underexplored. In this paper, we introduce a\nprincipled, information-theoretic framework that decomposes LLM sequential\ndecision uncertainty into two parts: (i) internal uncertainty intrinsic to the\ncurrent decision, which is focused on existing UQ methods, and (ii) extrinsic\nuncertainty, a Mutual-Information (MI) quantity describing how much uncertainty\nshould be inherited from preceding decisions. We then propose UProp, an\nefficient and effective extrinsic uncertainty estimator that converts the\ndirect estimation of MI to the estimation of Pointwise Mutual Information (PMI)\nover multiple Trajectory-Dependent Decision Processes (TDPs). UProp is\nevaluated over extensive multi-step decision-making benchmarks, e.g.,\nAgentBench and HotpotQA, with state-of-the-art LLMs, e.g., GPT-4.1 and\nDeepSeek-V3. Experimental results demonstrate that UProp significantly\noutperforms existing single-turn UQ baselines equipped with thoughtful\naggregation strategies. Moreover, we provide a comprehensive analysis of UProp,\nincluding sampling efficiency, potential applications, and intermediate\nuncertainty propagation, to demonstrate its effectiveness. Codes will be\navailable at https://github.com/jinhaoduan/UProp.", "published": "2025-06-20 18:34:04", "link": "http://arxiv.org/abs/2506.17419v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "From Generality to Mastery: Composer-Style Symbolic Music Generation via Large-Scale Pre-training", "abstract": "Despite progress in controllable symbolic music generation, data scarcity\nremains a challenge for certain control modalities. Composer-style music\ngeneration is a prime example, as only a few pieces per composer are available,\nlimiting the modeling of both styles and fundamental music elements (e.g.,\nmelody, chord, rhythm). In this paper, we investigate how general music\nknowledge learned from a broad corpus can enhance the mastery of specific\ncomposer styles, with a focus on piano piece generation. Our approach follows a\ntwo-stage training paradigm. First, we pre-train a REMI-based music generation\nmodel on a large corpus of pop, folk, and classical music. Then, we fine-tune\nit on a small, human-verified dataset from four renowned composers, namely\nBach, Mozart, Beethoven, and Chopin, using a lightweight adapter module to\ncondition the model on style indicators. To evaluate the effectiveness of our\napproach, we conduct both objective and subjective evaluations on style\naccuracy and musicality. Experimental results demonstrate that our method\noutperforms ablations and baselines, achieving more precise composer-style\nmodeling and better musical aesthetics. Additionally, we provide observations\non how the model builds music concepts from the generality pre-training and\nrefines its stylistic understanding through the mastery fine-tuning.", "published": "2025-06-20 22:20:59", "link": "http://arxiv.org/abs/2506.17497v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Adaptive Control Attention Network for Underwater Acoustic Localization and Domain Adaptation", "abstract": "Localizing acoustic sound sources in the ocean is a challenging task due to\nthe complex and dynamic nature of the environment. Factors such as high\nbackground noise, irregular underwater geometries, and varying acoustic\nproperties make accurate localization difficult. To address these obstacles, we\npropose a multi-branch network architecture designed to accurately predict the\ndistance between a moving acoustic source and a receiver, tested on real-world\nunderwater signal arrays. The network leverages Convolutional Neural Networks\n(CNNs) for robust spatial feature extraction and integrates Conformers with\nself-attention mechanism to effectively capture temporal dependencies. Log-mel\nspectrogram and generalized cross-correlation with phase transform (GCC-PHAT)\nfeatures are employed as input representations. To further enhance the model\nperformance, we introduce an Adaptive Gain Control (AGC) layer, that adaptively\nadjusts the amplitude of input features, ensuring consistent energy levels\nacross varying ranges, signal strengths, and noise conditions. We assess the\nmodel's generalization capability by training it in one domain and testing it\nin a different domain, using only a limited amount of data from the test domain\nfor fine-tuning. Our proposed method outperforms state-of-the-art (SOTA)\napproaches in similar settings, establishing new benchmarks for underwater\nsound localization.", "published": "2025-06-20 18:13:30", "link": "http://arxiv.org/abs/2506.17409v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Zero-Shot Cognitive Impairment Detection from Speech Using AudioLLM", "abstract": "Cognitive impairment (CI) is of growing public health concern, and early\ndetection is vital for effective intervention. Speech has gained attention as a\nnon-invasive and easily collectible biomarker for assessing cognitive decline.\nTraditional CI detection methods typically rely on supervised models trained on\nacoustic and linguistic features extracted from speech, which often require\nmanual annotation and may not generalise well across datasets and languages. In\nthis work, we propose the first zero-shot speech-based CI detection method\nusing the Qwen2- Audio AudioLLM, a model capable of processing both audio and\ntext inputs. By designing prompt-based instructions, we guide the model in\nclassifying speech samples as indicative of normal cognition or cognitive\nimpairment. We evaluate our approach on two datasets: one in English and\nanother multilingual, spanning different cognitive assessment tasks. Our\nresults show that the zero-shot AudioLLM approach achieves performance\ncomparable to supervised methods and exhibits promising generalizability and\nconsistency across languages, tasks, and datasets.", "published": "2025-06-20 01:28:43", "link": "http://arxiv.org/abs/2506.17351v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Cross-Modal Epileptic Signal Harmonization: Frequency Domain Mapping Quantization for Pre-training a Unified Neurophysiological Transformer", "abstract": "Scalp electroencephalography (EEG) and intracranial EEG (iEEG) are vital for\nepilepsy diagnosis and treatment. Their unified analysis offers the potential\nto harness the complementary strengths of each modality but is challenging due\nto variations in recording montages, amplitude and signal-to-noise ratio (SNR),\nand frequency components. To address the aforementioned challenges, this paper\nintroduces EpiNT, a novel Transformer-based pre-trained model for unified EEG\nand iEEG analysis. EpiNT employs channel-independent modeling with masked\nautoencoders (MAE) and vector quantization (VQ), along with a frequency domain\nmapping quantizer to capture crucial frequency features. Pre-trained on over\n2,700 hours of multi-modal clinical neurophysiological data from 1,199\npatients, EpiNT outperformed both randomly initialized models and other\npre-trained methods on six downstream classification tasks, demonstrating\nrobust representation learning capabilities. This work presents a promising\napproach for unified epilepsy neurophysiology analysis.", "published": "2025-06-20 15:14:48", "link": "http://arxiv.org/abs/2506.17068v1", "categories": ["q-bio.NC", "cs.ET", "eess.SP"], "primary_category": "q-bio.NC"}
{"title": "Experimental Setup and Software Pipeline to Evaluate Optimization based Autonomous Multi-Robot Search Algorithms", "abstract": "Signal source localization has been a problem of interest in the multi-robot\nsystems domain given its applications in search & rescue and hazard\nlocalization in various industrial and outdoor settings. A variety of\nmulti-robot search algorithms exist that usually formulate and solve the\nassociated autonomous motion planning problem as a heuristic model-free or\nbelief model-based optimization process. Most of these algorithms however\nremains tested only in simulation, thereby losing the opportunity to generate\nknowledge about how such algorithms would compare/contrast in a real physical\nsetting in terms of search performance and real-time computing performance. To\naddress this gap, this paper presents a new lab-scale physical setup and\nassociated open-source software pipeline to evaluate and benchmark multi-robot\nsearch algorithms. The presented physical setup innovatively uses an acoustic\nsource (that is safe and inexpensive) and small ground robots (e-pucks)\noperating in a standard motion-capture environment. This setup can be easily\nrecreated and used by most robotics researchers. The acoustic source also\npresents interesting uncertainty in terms of its noise-to-signal ratio, which\nis useful to assess sim-to-real gaps. The overall software pipeline is designed\nto readily interface with any multi-robot search algorithm with minimal effort\nand is executable in parallel asynchronous form. This pipeline includes a\nframework for distributed implementation of multi-robot or swarm search\nalgorithms, integrated with a ROS (Robotics Operating System)-based software\nstack for motion capture supported localization. The utility of this novel\nsetup is demonstrated by using it to evaluate two state-of-the-art multi-robot\nsearch algorithms, based on swarm optimization and batch-Bayesian Optimization\n(called Bayes-Swarm), as well as a random walk baseline.", "published": "2025-06-20 03:06:43", "link": "http://arxiv.org/abs/2506.16710v2", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Mapping the Evolution of Research Contributions using KnoVo", "abstract": "This paper presents KnoVo (Knowledge Evolution), an intelligent framework\ndesigned for quantifying and analyzing the evolution of research novelty in the\nscientific literature. Moving beyond traditional citation analysis, which\nprimarily measures impact, KnoVo determines a paper's novelty relative to both\nprior and subsequent work within its multilayered citation network. Given a\ntarget paper's abstract, KnoVo utilizes Large Language Models (LLMs) to\ndynamically extract dimensions of comparison (e.g., methodology, application,\ndataset). The target paper is then compared to related publications along these\nsame extracted dimensions. This comparative analysis, inspired by tournament\nselection, yields quantitative novelty scores reflecting the relative\nimprovement, equivalence, or inferiority of the target paper in specific\naspects. By aggregating these scores and visualizing their progression, for\ninstance, through dynamic evolution graphs and comparative radar charts, KnoVo\nfacilitates researchers not only to assess originality and identify similar\nwork, but also to track knowledge evolution along specific research dimensions,\nuncover research gaps, and explore cross-disciplinary connections. We\ndemonstrate these capabilities through a detailed analysis of 20 diverse papers\nfrom multiple scientific fields and report on the performance of various\nopen-source LLMs within the KnoVo framework.", "published": "2025-06-20 23:17:11", "link": "http://arxiv.org/abs/2506.17508v2", "categories": ["cs.DL", "cs.AI", "cs.DB", "cs.ET", "cs.IR"], "primary_category": "cs.DL"}
{"title": "Breaking the Transcription Bottleneck: Fine-tuning ASR Models for Extremely Low-Resource Fieldwork Languages", "abstract": "Automatic Speech Recognition (ASR) has reached impressive accuracy for\nhigh-resource languages, yet its utility in linguistic fieldwork remains\nlimited. Recordings collected in fieldwork contexts present unique challenges,\nincluding spontaneous speech, environmental noise, and severely constrained\ndatasets from under-documented languages. In this paper, we benchmark the\nperformance of two fine-tuned multilingual ASR models, MMS and XLS-R, on five\ntypologically diverse low-resource languages with control of training data\nduration. Our findings show that MMS is best suited when extremely small\namounts of training data are available, whereas XLS-R shows parity performance\nonce training data exceed one hour. We provide linguistically grounded analysis\nfor further provide insights towards practical guidelines for field linguists,\nhighlighting reproducible ASR adaptation approaches to mitigate the\ntranscription bottleneck in language documentation.", "published": "2025-06-20 19:59:49", "link": "http://arxiv.org/abs/2506.17459v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
