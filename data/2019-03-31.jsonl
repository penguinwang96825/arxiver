{"title": "Modeling Drug-Disease Relations with Linguistic and Knowledge Graph\n  Constraints", "abstract": "FDA drug labels are rich sources of information about drugs and drug-disease\nrelations, but their complexity makes them challenging texts to analyze in\nisolation. To overcome this, we situate these labels in two health knowledge\ngraphs: one built from precise structured information about drugs and diseases,\nand another built entirely from a database of clinical narrative texts using\nsimple heuristic methods. We show that Probabilistic Soft Logic models defined\nover these graphs are superior to text-only and relation-only variants, and\nthat the clinical narratives graph delivers exceptional results with little\nmanual effort. Finally, we release a new dataset of drug labels with\nannotations for five distinct drug-disease relations.", "published": "2019-03-31 00:48:42", "link": "http://arxiv.org/abs/1904.00313v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SART - Similarity, Analogies, and Relatedness for Tatar Language: New\n  Benchmark Datasets for Word Embeddings Evaluation", "abstract": "There is a huge imbalance between languages currently spoken and\ncorresponding resources to study them. Most of the attention naturally goes to\nthe \"big\" languages: those which have the largest presence in terms of media\nand number of speakers. Other less represented languages sometimes do not even\nhave a good quality corpus to study them. In this paper, we tackle this\nimbalance by presenting a new set of evaluation resources for Tatar, a language\nof the Turkic language family which is mainly spoken in Tatarstan Republic,\nRussia.\n  We present three datasets: Similarity and Relatedness datasets that consist\nof human scored word pairs and can be used to evaluate semantic models; and\nAnalogies dataset that comprises analogy questions and allows to explore\nsemantic, syntactic, and morphological aspects of language modeling. All three\ndatasets build upon existing datasets for the English language and follow the\nsame structure. However, they are not mere translations. They take into account\nspecifics of the Tatar language and expand beyond the original datasets. We\nevaluate state-of-the-art word embedding models for two languages using our\nproposed datasets for Tatar and the original datasets for English and report\nour findings on performance comparison.", "published": "2019-03-31 09:23:17", "link": "http://arxiv.org/abs/1904.00365v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conversation Model Fine-Tuning for Classifying Client Utterances in\n  Counseling Dialogues", "abstract": "The recent surge of text-based online counseling applications enables us to\ncollect and analyze interactions between counselors and clients. A dataset of\nthose interactions can be used to learn to automatically classify the client\nutterances into categories that help counselors in diagnosing client status and\npredicting counseling outcome. With proper anonymization, we collect\ncounselor-client dialogues, define meaningful categories of client utterances\nwith professional counselors, and develop a novel neural network model for\nclassifying the client utterances. The central idea of our model, ConvMFiT, is\na pre-trained conversation model which consists of a general language model\nbuilt from an out-of-domain corpus and two role-specific language models built\nfrom unlabeled in-domain dialogues. The classification result shows that\nConvMFiT outperforms state-of-the-art comparison models. Further, the attention\nweights in the learned model confirm that the model finds expected linguistic\npatterns for each category.", "published": "2019-03-31 07:30:47", "link": "http://arxiv.org/abs/1904.00350v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "An End-to-End Approach to Automatic Speech Assessment for\n  Cantonese-speaking People with Aphasia", "abstract": "Conventional automatic assessment of pathological speech usually follows two\nmain steps: (1) extraction of pathology-specific features; (2) classification\nor regression on extracted features. Given the great variety of speech and\nlanguage disorders, feature design is never a straightforward task, and yet it\nis most crucial to the performance of assessment. This paper presents an\nend-to-end approach to automatic speech assessment for Cantonese-speaking\nPeople With Aphasia (PWA). The assessment is formulated as a binary\nclassification task to discriminate PWA with high scores of subjective\nassessment from those with low scores. The sequence-to-one Recurrent Neural\nNetwork with Gated Recurrent Unit (GRU-RNN) and Convolutional Neural Network\n(CNN) models are applied to realize the end-to-end mapping from fundamental\nspeech features to the classification result. The pathology-specific features\nused for assessment can be learned implicitly by the neural network model.\nClass Activation Mapping (CAM) method is utilized to visualize how those\nfeatures contribute to the assessment result. Our experimental results show\nthat the end-to-end approach outperforms the conventional two-step approach in\nthe classification task, and confirm that the CNN model is able to learn\nimpairment-related features that are similar to human-designed features. The\nexperimental results also suggest that CNN model performs better than\nsequence-to-one GRU-RNN model in this specific task.", "published": "2019-03-31 09:04:17", "link": "http://arxiv.org/abs/1904.00361v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Learning Shared Encoding Representation for End-to-End Speech\n  Recognition Models", "abstract": "In this work, we learn a shared encoding representation for a multi-task\nneural network model optimized with connectionist temporal classification (CTC)\nand conventional framewise cross-entropy training criteria. Our experiments\nshow that the multi-task training not only tackles the complexity of optimizing\nCTC models such as acoustic-to-word but also results in significant improvement\ncompared to the plain-task training with an optimal setup. Furthermore, we\npropose to use the encoding representation learned by the multi-task network to\ninitialize the encoder of attention-based models. Thereby, we train a deep\nattention-based end-to-end model with 10 long short-term memory (LSTM) layers\nof encoder which produces 12.2\\% and 22.6\\% word-error-rate on Switchboard and\nCallHome subsets of the Hub5 2000 evaluation.", "published": "2019-03-31 20:46:13", "link": "http://arxiv.org/abs/1904.02147v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
