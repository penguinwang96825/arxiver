{"title": "Old Content and Modern Tools - Searching Named Entities in a Finnish\n  OCRed Historical Newspaper Collection 1771-1910", "abstract": "Named Entity Recognition (NER), search, classification and tagging of names\nand name like frequent informational elements in texts, has become a standard\ninformation extraction procedure for textual data. NER has been applied to many\ntypes of texts and different types of entities: newspapers, fiction, historical\nrecords, persons, locations, chemical compounds, protein families, animals etc.\nIn general a NER system's performance is genre and domain dependent and also\nused entity categories vary (Nadeau and Sekine, 2007). The most general set of\nnamed entities is usually some version of three partite categorization of\nlocations, persons and organizations. In this paper we report first large scale\ntrials and evaluation of NER with data out of a digitized Finnish historical\nnewspaper collection Digi. Experiments, results and discussion of this research\nserve development of the Web collection of historical Finnish newspapers.\n  Digi collection contains 1,960,921 pages of newspaper material from years\n1771-1910 both in Finnish and Swedish. We use only material of Finnish\ndocuments in our evaluation. The OCRed newspaper collection has lots of OCR\nerrors; its estimated word level correctness is about 70-75 % (Kettunen and\nP\\\"a\\\"akk\\\"onen, 2016). Our principal NER tagger is a rule-based tagger of\nFinnish, FiNER, provided by the FIN-CLARIN consortium. We show also results of\nlimited category semantic tagging with tools of the Semantic Computing Research\nGroup (SeCo) of the Aalto University. Three other tools are also evaluated\nbriefly.\n  This research reports first published large scale results of NER in a\nhistorical Finnish OCRed newspaper collection. Results of the research\nsupplement NER results of other languages with similar noisy data.", "published": "2016-11-09 07:37:28", "link": "http://arxiv.org/abs/1611.02839v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comparison of Word Embeddings for English and Cross-Lingual Chinese\n  Word Sense Disambiguation", "abstract": "Word embeddings are now ubiquitous forms of word representation in natural\nlanguage processing. There have been applications of word embeddings for\nmonolingual word sense disambiguation (WSD) in English, but few comparisons\nhave been done. This paper attempts to bridge that gap by examining popular\nembeddings for the task of monolingual English WSD. Our simplified method leads\nto comparable state-of-the-art performance without expensive retraining.\nCross-Lingual WSD - where the word senses of a word in a source language e come\nfrom a separate target translation language f - can also assist in language\nlearning; for example, when providing translations of target vocabulary for\nlearners. Thus we have also applied word embeddings to the novel task of\ncross-lingual WSD for Chinese and provide a public dataset for further\nbenchmarking. We have also experimented with using word embeddings for LSTM\nnetworks and found surprisingly that a basic LSTM network does not work well.\nWe discuss the ramifications of this outcome.", "published": "2016-11-09 14:50:01", "link": "http://arxiv.org/abs/1611.02956v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distant supervision for emotion detection using Facebook reactions", "abstract": "We exploit the Facebook reaction feature in a distant supervised fashion to\ntrain a support vector machine classifier for emotion detection, using several\nfeature combinations and combining different Facebook pages. We test our models\non existing benchmarks for emotion detection and show that employing only\ninformation that is derived completely automatically, thus without relying on\nany handcrafted lexicon as it's usually done, we can achieve competitive\nresults. The results also show that there is large room for improvement,\nespecially by gearing the collection of Facebook pages, with a view to the\ntarget domain.", "published": "2016-11-09 15:49:31", "link": "http://arxiv.org/abs/1611.02988v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When silver glitters more than gold: Bootstrapping an Italian\n  part-of-speech tagger for Twitter", "abstract": "We bootstrap a state-of-the-art part-of-speech tagger to tag Italian Twitter\ndata, in the context of the Evalita 2016 PoSTWITA shared task. We show that\ntraining the tagger on native Twitter data enriched with little amounts of\nspecifically selected gold data and additional silver-labelled data scraped\nfrom Facebook, yields better results than using large amounts of manually\nannotated data from a mix of genres.", "published": "2016-11-09 19:39:15", "link": "http://arxiv.org/abs/1611.03057v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Increasing the throughput of machine translation systems using clouds", "abstract": "The manuscript presents an experiment at implementation of a Machine\nTranslation system in a MapReduce model. The empirical evaluation was done\nusing fully implemented translation systems embedded into the MapReduce\nprogramming model. Two machine translation paradigms were studied: shallow\ntransfer Rule Based Machine Translation and Statistical Machine Translation.\n  The results show that the MapReduce model can be successfully used to\nincrease the throughput of a machine translation system. Furthermore this\nmethod enhances the throughput of a machine translation system without\ndecreasing the quality of the translation output.\n  Thus, the present manuscript also represents a contribution to the seminal\nwork in natural language processing, specifically Machine Translation. It first\npoints toward the importance of the definition of the metric of throughput of\ntranslation system and, second, the applicability of the machine translation\ntask to the MapReduce paradigm.", "published": "2016-11-09 14:27:03", "link": "http://arxiv.org/abs/1611.02944v1", "categories": ["cs.CL", "cs.DC"], "primary_category": "cs.CL"}
{"title": "Audio Visual Speech Recognition using Deep Recurrent Neural Networks", "abstract": "In this work, we propose a training algorithm for an audio-visual automatic\nspeech recognition (AV-ASR) system using deep recurrent neural network\n(RNN).First, we train a deep RNN acoustic model with a Connectionist Temporal\nClassification (CTC) objective function. The frame labels obtained from the\nacoustic model are then used to perform a non-linear dimensionality reduction\nof the visual features using a deep bottleneck network. Audio and visual\nfeatures are fused and used to train a fusion RNN. The use of bottleneck\nfeatures for visual modality helps the model to converge properly during\ntraining. Our system is evaluated on GRID corpus. Our results show that\npresence of visual modality gives significant improvement in character error\nrate (CER) at various levels of noise even when the model is trained without\nnoisy data. We also provide a comparison of two fusion methods: feature fusion\nand decision fusion.", "published": "2016-11-09 10:24:52", "link": "http://arxiv.org/abs/1611.02879v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
