{"title": "On R\u00e9nyi Differential Privacy in Statistics-Based Synthetic Data Generation", "abstract": "Privacy protection with synthetic data generation often uses differentially private statistics and model parameters to quantitatively express theoretical security. However, these methods do not take into account privacy protection due to the randomness of data generation. In this paper, we theoretically evaluate R\u00e9nyi differential privacy of the randomness in data generation of a synthetic data generation method that uses the mean vector and the covariance matrix of an original dataset. Specifically, for a fixed $\u03b1> 1$, we show the condition of $\\varepsilon$ such that the synthetic data generation satisfies $(\u03b1, \\varepsilon)$-R\u00e9nyi differential privacy under a bounded neighboring condition and an unbounded neighboring condition, respectively. In particular, under the unbounded condition, when the size of the original dataset and synthetic datase is 10 million, the mechanism satisfies $(4, 0.576)$-R\u00e9nyi differential privacy. We also show that when we translate it into the traditional $(\\varepsilon, \u03b4)$-differential privacy, the mechanism satisfies $(4.00, 10^{-10})$-differential privacy.", "published": "2023-03-31 07:26:52", "link": "http://arxiv.org/abs/2303.17849v1", "categories": ["cs.CR", "cs.IT"], "primary_category": "cs.CR"}
