{"title": "Extending a Single-Document Summarizer to Multi-Document: a Hierarchical\n  Approach", "abstract": "The increasing amount of online content motivated the development of\nmulti-document summarization methods. In this work, we explore straightforward\napproaches to extend single-document summarization methods to multi-document\nsummarization. The proposed methods are based on the hierarchical combination\nof single-document summaries, and achieves state of the art results.", "published": "2015-07-10 13:59:00", "link": "http://arxiv.org/abs/1507.02907v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Markov Logic Networks for Natural Language Question Answering", "abstract": "Our goal is to answer elementary-level science questions using knowledge\nextracted automatically from science textbooks, expressed in a subset of\nfirst-order logic. Given the incomplete and noisy nature of these automatically\nextracted rules, Markov Logic Networks (MLNs) seem a natural model to use, but\nthe exact way of leveraging MLNs is by no means obvious. We investigate three\nways of applying MLNs to our task. In the first, we simply use the extracted\nscience rules directly as MLN clauses. Unlike typical MLN applications, our\ndomain has long and complex rules, leading to an unmanageable number of\ngroundings. We exploit the structure present in hard constraints to improve\ntractability, but the formulation remains ineffective. In the second approach,\nwe instead interpret science rules as describing prototypical entities, thus\nmapping rules directly to grounded MLN assertions, whose constants are then\nclustered using existing entity resolution methods. This drastically simplifies\nthe network, but still suffers from brittleness. Finally, our third approach,\ncalled Praline, uses MLNs to align the lexical elements as well as define and\ncontrol how inference should be performed in this task. Our experiments,\ndemonstrating a 15\\% accuracy boost and a 10x reduction in runtime, suggest\nthat the flexibility and different inference semantics of Praline are a better\nfit for the natural language question answering task.", "published": "2015-07-10 23:17:53", "link": "http://arxiv.org/abs/1507.03045v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
