{"title": "Character-based Joint Segmentation and POS Tagging for Chinese using\n  Bidirectional RNN-CRF", "abstract": "We present a character-based model for joint segmentation and POS tagging for\nChinese. The bidirectional RNN-CRF architecture for general sequence tagging is\nadapted and applied with novel vector representations of Chinese characters\nthat capture rich contextual information and lower-than-character level\nfeatures. The proposed model is extensively evaluated and compared with a\nstate-of-the-art tagger respectively on CTB5, CTB9 and UD Chinese. The\nexperimental results indicate that our model is accurate and robust across\ndatasets in different sizes, genres and annotation schemes. We obtain\nstate-of-the-art performance on CTB5, achieving 94.38 F1-score for joint\nsegmentation and POS tagging.", "published": "2017-04-05 08:58:44", "link": "http://arxiv.org/abs/1704.01314v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CompiLIG at SemEval-2017 Task 1: Cross-Language Plagiarism Detection\n  Methods for Semantic Textual Similarity", "abstract": "We present our submitted systems for Semantic Textual Similarity (STS) Track\n4 at SemEval-2017. Given a pair of Spanish-English sentences, each system must\nestimate their semantic similarity by a score between 0 and 5. In our\nsubmission, we use syntax-based, dictionary-based, context-based, and MT-based\nmethods. We also combine these methods in unsupervised and supervised way. Our\nbest run ranked 1st on track 4a with a correlation of 83.02% with human\nannotations.", "published": "2017-04-05 10:07:22", "link": "http://arxiv.org/abs/1704.01346v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linear Ensembles of Word Embedding Models", "abstract": "This paper explores linear methods for combining several word embedding\nmodels into an ensemble. We construct the combined models using an iterative\nmethod based on either ordinary least squares regression or the solution to the\northogonal Procrustes problem.\n  We evaluate the proposed approaches on Estonian---a morphologically complex\nlanguage, for which the available corpora for training word embeddings are\nrelatively small. We compare both combined models with each other and with the\ninput word embedding models using synonym and analogy tests. The results show\nthat while using the ordinary least squares regression performs poorly in our\nexperiments, using orthogonal Procrustes to combine several word embedding\nmodels into an ensemble model leads to 7-10% relative improvements over the\nmean result of the initial models in synonym tests and 19-47% in analogy tests.", "published": "2017-04-05 13:38:01", "link": "http://arxiv.org/abs/1704.01419v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Measurement of Pre-aspiration", "abstract": "Pre-aspiration is defined as the period of glottal friction occurring in\nsequences of vocalic/consonantal sonorants and phonetically voiceless\nobstruents. We propose two machine learning methods for automatic measurement\nof pre-aspiration duration: a feedforward neural network, which works at the\nframe level; and a structured prediction model, which relies on manually\ndesigned feature functions, and works at the segment level. The input for both\nalgorithms is a speech signal of an arbitrary length containing a single\nobstruent, and the output is a pair of times which constitutes the\npre-aspiration boundaries. We train both models on a set of manually annotated\nexamples. Results suggest that the structured model is superior to the\nframe-based model as it yields higher accuracy in predicting the boundaries and\ngeneralizes to new speakers and new languages. Finally, we demonstrate the\napplicability of our structured prediction algorithm by replicating linguistic\nanalysis of pre-aspiration in Aberystwyth English with high correlation.", "published": "2017-04-05 21:10:07", "link": "http://arxiv.org/abs/1704.01653v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rhetorical relations for information retrieval", "abstract": "Typically, every part in most coherent text has some plausible reason for its\npresence, some function that it performs to the overall semantics of the text.\nRhetorical relations, e.g. contrast, cause, explanation, describe how the parts\nof a text are linked to each other. Knowledge about this socalled discourse\nstructure has been applied successfully to several natural language processing\ntasks. This work studies the use of rhetorical relations for Information\nRetrieval (IR): Is there a correlation between certain rhetorical relations and\nretrieval performance? Can knowledge about a document's rhetorical relations be\nuseful to IR? We present a language model modification that considers\nrhetorical relations when estimating the relevance of a document to a query.\nEmpirical evaluation of different versions of our model on TREC settings shows\nthat certain rhetorical relations can benefit retrieval effectiveness notably\n(> 10% in mean average precision over a state-of-the-art baseline).", "published": "2017-04-05 18:21:39", "link": "http://arxiv.org/abs/1704.01599v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Multitask Learning with Low-Level Auxiliary Tasks for Encoder-Decoder\n  Based Speech Recognition", "abstract": "End-to-end training of deep learning-based models allows for implicit\nlearning of intermediate representations based on the final task loss. However,\nthe end-to-end approach ignores the useful domain knowledge encoded in explicit\nintermediate-level supervision. We hypothesize that using intermediate\nrepresentations as auxiliary supervision at lower levels of deep networks may\nbe a good way of combining the advantages of end-to-end training and more\ntraditional pipeline approaches. We present experiments on conversational\nspeech recognition where we use lower-level tasks, such as phoneme recognition,\nin a multitask training approach with an encoder-decoder model for direct\ncharacter transcription. We compare multiple types of lower-level tasks and\nanalyze the effects of the auxiliary tasks. Our results on the Switchboard\ncorpus show that this approach improves recognition accuracy over a standard\nencoder-decoder model on the Eval2000 test set.", "published": "2017-04-05 19:44:23", "link": "http://arxiv.org/abs/1704.01631v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning to Generate Reviews and Discovering Sentiment", "abstract": "We explore the properties of byte-level recurrent language models. When given\nsufficient amounts of capacity, training data, and compute time, the\nrepresentations learned by these models include disentangled features\ncorresponding to high-level concepts. Specifically, we find a single unit which\nperforms sentiment analysis. These representations, learned in an unsupervised\nmanner, achieve state of the art on the binary subset of the Stanford Sentiment\nTreebank. They are also very data efficient. When using only a handful of\nlabeled examples, our approach matches the performance of strong baselines\ntrained on full datasets. We also demonstrate the sentiment unit has a direct\ninfluence on the generative process of the model. Simply fixing its value to be\npositive or negative generates samples with the corresponding positive or\nnegative sentiment.", "published": "2017-04-05 14:20:28", "link": "http://arxiv.org/abs/1704.01444v2", "categories": ["cs.LG", "cs.CL", "cs.NE"], "primary_category": "cs.LG"}
{"title": "MIT at SemEval-2017 Task 10: Relation Extraction with Convolutional\n  Neural Networks", "abstract": "Over 50 million scholarly articles have been published: they constitute a\nunique repository of knowledge. In particular, one may infer from them\nrelations between scientific concepts, such as synonyms and hyponyms.\nArtificial neural networks have been recently explored for relation extraction.\nIn this work, we continue this line of work and present a system based on a\nconvolutional neural network to extract relations. Our model ranked first in\nthe SemEval-2017 task 10 (ScienceIE) for relation extraction in scientific\narticles (subtask C).", "published": "2017-04-05 16:54:20", "link": "http://arxiv.org/abs/1704.01523v1", "categories": ["cs.CL", "cs.AI", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
