{"title": "Study of Phonemes Confusions in Hierarchical Automatic Phoneme\n  Recognition System", "abstract": "In this paper, we have analyzed the impact of confusions on the robustness of\nphoneme recognitions system. The confusions are detected at the pronunciation\nand the confusions matrices of the phoneme recognizer. The confusions show that\nsome similarities between phonemes at the pronunciation affect significantly\nthe recognition rates. This paper proposes to understand those confusions in\norder to improve the performance of the phoneme recognition system by isolating\nthe problematic phonemes. Confusion analysis leads to build a new hierarchical\nrecognizer using new phoneme distribution and the information from the\nconfusion matrices. This new hierarchical phoneme recognition system shows\nsignificant improvements of the recognition rates on TIMIT database.", "published": "2015-08-07 15:06:13", "link": "http://arxiv.org/abs/1508.01718v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantically Conditioned LSTM-based Natural Language Generation for\n  Spoken Dialogue Systems", "abstract": "Natural language generation (NLG) is a critical component of spoken dialogue\nand it has a significant impact both on usability and perceived quality. Most\nNLG systems in common use employ rules and heuristics and tend to generate\nrigid and stylised responses without the natural variation of human language.\nThey are also not easily scaled to systems covering multiple domains and\nlanguages. This paper presents a statistical language generator based on a\nsemantically controlled Long Short-term Memory (LSTM) structure. The LSTM\ngenerator can learn from unaligned data by jointly optimising sentence planning\nand surface realisation using a simple cross entropy training criterion, and\nlanguage variation can be easily achieved by sampling from output candidates.\nWith fewer heuristics, an objective evaluation in two differing test domains\nshowed the proposed method improved performance compared to previous methods.\nHuman judges scored the LSTM system higher on informativeness and naturalness\nand overall preferred it to the other systems.", "published": "2015-08-07 16:16:44", "link": "http://arxiv.org/abs/1508.01745v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stochastic Language Generation in Dialogue using Recurrent Neural\n  Networks with Convolutional Sentence Reranking", "abstract": "The natural language generation (NLG) component of a spoken dialogue system\n(SDS) usually needs a substantial amount of handcrafting or a well-labeled\ndataset to be trained on. These limitations add significantly to development\ncosts and make cross-domain, multi-lingual dialogue systems intractable.\nMoreover, human languages are context-aware. The most natural response should\nbe directly learned from data rather than depending on predefined syntaxes or\nrules. This paper presents a statistical language generator based on a joint\nrecurrent and convolutional neural network structure which can be trained on\ndialogue act-utterance pairs without any semantic alignments or predefined\ngrammar trees. Objective metrics suggest that this new model outperforms\nprevious methods under the same experimental conditions. Results of an\nevaluation by human judges indicate that it produces not only high quality but\nlinguistically varied utterances which are preferred compared to n-gram and\nrule-based systems.", "published": "2015-08-07 16:34:11", "link": "http://arxiv.org/abs/1508.01755v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automata networks model for alignment and least effort on vocabulary\n  formation", "abstract": "Can artificial communities of agents develop language with scaling relations\nclose to the Zipf law? As a preliminary answer to this question, we propose an\nAutomata Networks model of the formation of a vocabulary on a population of\nindividuals, under two in principle opposite strategies: the alignment and the\nleast effort principle. Within the previous account to the emergence of\nlinguistic conventions (specially, the Naming Game), we focus on modeling\nspeaker and hearer efforts as actions over their vocabularies and we study the\nimpact of these actions on the formation of a shared language. The numerical\nsimulations are essentially based on an energy function, that measures the\namount of local agreement between the vocabularies. The results suggests that\non one dimensional lattices the best strategy to the formation of shared\nlanguages is the one that minimizes the efforts of speakers on communicative\ntasks.", "published": "2015-08-07 00:57:18", "link": "http://arxiv.org/abs/1508.01577v2", "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Automata networks for memory loss effects in the formation of linguistic\n  conventions", "abstract": "This work attempts to give new theoretical insights to the absence of\nintermediate stages in the evolution of language. In particular, it is\ndeveloped an automata networks approach to a crucial question: how a population\nof language users can reach agreement on a linguistic convention? To describe\nthe appearance of sharp transitions in the self-organization of language, it is\nadopted an extremely simple model of (working) memory. At each time step,\nlanguage users simply loss part of their word-memories. Through computer\nsimulations of low-dimensional lattices, it appear sharp transitions at\ncritical values that depend on the size of the vicinities of the individuals.", "published": "2015-08-07 01:15:23", "link": "http://arxiv.org/abs/1508.01580v2", "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Applying Deep Learning to Answer Selection: A Study and An Open Task", "abstract": "We apply a general deep learning framework to address the non-factoid\nquestion answering task. Our approach does not rely on any linguistic tools and\ncan be applied to different languages or domains. Various architectures are\npresented and compared. We create and release a QA corpus and setup a new QA\ntask in the insurance domain. Experimental results demonstrate superior\nperformance compared to the baseline methods and various technologies give\nfurther improvements. For this highly challenging task, the top-1 accuracy can\nreach up to 65.3% on a test set, which indicates a great potential for\npractical use.", "published": "2015-08-07 01:54:04", "link": "http://arxiv.org/abs/1508.01585v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mimicry Is Presidential: Linguistic Style Matching in Presidential\n  Debates and Improved Polling Numbers", "abstract": "The current research used the contexts of U.S. presidential debates and\nnegotiations to examine whether matching the linguistic style of an opponent in\na two-party exchange affects the reactions of third-party observers. Building\noff communication accommodation theory (CAT), interaction alignment theory\n(IAT), and processing fluency, we propose that language style matching (LSM)\nwill improve subsequent third-party evaluations because matching an opponent's\nlinguistic style reflects greater perspective taking and will make one's\narguments easier to process. In contrast, research on status inferences\npredicts that LSM will negatively impact third-party evaluations because LSM\nimplies followership. We conduct two studies to test these competing\nhypotheses. Study 1 analyzed transcripts of U.S. presidential debates between\n1976 and 2012 and found that candidates who matched their opponent's linguistic\nstyle increased their standing in the polls. Study 2 demonstrated a causal\nrelationship between LSM and third-party observer evaluations using negotiation\ntranscripts.", "published": "2015-08-07 19:35:52", "link": "http://arxiv.org/abs/1508.01786v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Using Deep Learning for Detecting Spoofing Attacks on Speech Signals", "abstract": "It is well known that speaker verification systems are subject to spoofing\nattacks. The Automatic Speaker Verification Spoofing and Countermeasures\nChallenge -- ASVSpoof2015 -- provides a standard spoofing database, containing\nattacks based on synthetic speech, along with a protocol for experiments. This\npaper describes CPqD's systems submitted to the ASVSpoof2015 Challenge, based\non deep neural networks, working both as a classifier and as a feature\nextraction module for a GMM and a SVM classifier. Results show the validity of\nthis approach, achieving less than 0.5\\% EER for known attacks.", "published": "2015-08-07 16:20:52", "link": "http://arxiv.org/abs/1508.01746v2", "categories": ["cs.SD", "cs.CL", "cs.CR", "cs.LG", "stat.ML"], "primary_category": "cs.SD"}
