{"title": "Towards an Arabic-English Machine-Translation Based on Semantic Web", "abstract": "Communication tools make the world like a small village and as a consequence\npeople can contact with others who are from different societies or who speak\ndifferent languages. This communication cannot happen effectively without\nMachine Translation because they can be found anytime and everywhere. There are\na number of studies that have developed Machine Translation for the English\nlanguage with so many other languages except the Arabic it has not been\nconsidered yet. Therefore we aim to highlight a roadmap for our proposed\ntranslation machine to provide an enhanced Arabic English translation based on\nSemantic.", "published": "2017-09-14 09:36:48", "link": "http://arxiv.org/abs/1709.04682v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine-Translation History and Evolution: Survey for Arabic-English\n  Translations", "abstract": "As a result of the rapid changes in information and communication technology\n(ICT), the world has become a small village where people from all over the\nworld connect with each other in dialogue and communication via the Internet.\nAlso, communications have become a daily routine activity due to the new\nglobalization where companies and even universities become global residing\ncross countries borders. As a result, translation becomes a needed activity in\nthis connected world. ICT made it possible to have a student in one country\ntake a course or even a degree from a different country anytime anywhere\neasily. The resulted communication still needs a language as a means that helps\nthe receiver understands the contents of the sent message. People need an\nautomated translation application because human translators are hard to find\nall the times, and the human translations are very expensive comparing to the\ntranslations automated process. Several types of research describe the\nelectronic process of the Machine-Translation. In this paper, the authors are\ngoing to study some of these previous researches, and they will explore some of\nthe needed tools for the Machine-Translation. This research is going to\ncontribute to the Machine-Translation area by helping future researchers to\nhave a summary for the Machine-Translation groups of research and to let lights\non the importance of the translation mechanism.", "published": "2017-09-14 09:46:15", "link": "http://arxiv.org/abs/1709.04685v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synapse at CAp 2017 NER challenge: Fasttext CRF", "abstract": "We present our system for the CAp 2017 NER challenge which is about named\nentity recognition on French tweets. Our system leverages unsupervised learning\non a larger dataset of French tweets to learn features feeding a CRF model. It\nwas ranked first without using any gazetteer or structured external data, with\nan F-measure of 58.89\\%. To the best of our knowledge, it is the first system\nto use fasttext embeddings (which include subword representations) and an\nembedding-based sentence representation for NER.", "published": "2017-09-14 14:44:30", "link": "http://arxiv.org/abs/1709.04820v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Attentive Residual Decoder for Neural Machine Translation", "abstract": "Neural sequence-to-sequence networks with attention have achieved remarkable\nperformance for machine translation. One of the reasons for their effectiveness\nis their ability to capture relevant source-side contextual information at each\ntime-step prediction through an attention mechanism. However, the target-side\ncontext is solely based on the sequence model which, in practice, is prone to a\nrecency bias and lacks the ability to capture effectively non-sequential\ndependencies among words. To address this limitation, we propose a\ntarget-side-attentive residual recurrent network for decoding, where attention\nover previous words contributes directly to the prediction of the next word.\nThe residual learning facilitates the flow of information from the distant past\nand is able to emphasize any of the previously translated words, hence it gains\naccess to a wider context. The proposed model outperforms a neural MT baseline\nas well as a memory and self-attention network on three language pairs. The\nanalysis of the attention learned by the decoder confirms that it emphasizes a\nwider context, and that it captures syntactic-like structures.", "published": "2017-09-14 16:06:45", "link": "http://arxiv.org/abs/1709.04849v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Platform Emoji Interpretation: Analysis, a Solution, and\n  Applications", "abstract": "Most social media platforms are largely based on text, and users often write\nposts to describe where they are, what they are seeing, and how they are\nfeeling. Because written text lacks the emotional cues of spoken and\nface-to-face dialogue, ambiguities are common in written language. This problem\nis exacerbated in the short, informal nature of many social media posts. To\nbypass this issue, a suite of special characters called \"emojis,\" which are\nsmall pictograms, are embedded within the text. Many emojis are small\ndepictions of facial expressions designed to help disambiguate the emotional\nmeaning of the text. However, a new ambiguity arises in the way that emojis are\nrendered. Every platform (Windows, Mac, and Android, to name a few) renders\nemojis according to their own style. In fact, it has been shown that some\nemojis can be rendered so differently that they look \"happy\" on some platforms,\nand \"sad\" on others. In this work, we use real-world data to verify the\nexistence of this problem. We verify that the usage of the same emoji can be\nsignificantly different across platforms, with some emojis exhibiting different\nsentiment polarities on different platforms. We propose a solution to identify\nthe intended emoji based on the platform-specific nature of the emoji used by\nthe author of a social media post. We apply our solution to sentiment analysis,\na task that can benefit from the emoji calibration technique we use in this\nwork. We conduct experiments to evaluate the effectiveness of the mapping in\nthis task.", "published": "2017-09-14 20:28:27", "link": "http://arxiv.org/abs/1709.04969v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robustness Analysis of Visual QA Models by Basic Questions", "abstract": "Visual Question Answering (VQA) models should have both high robustness and\naccuracy. Unfortunately, most of the current VQA research only focuses on\naccuracy because there is a lack of proper methods to measure the robustness of\nVQA models. There are two main modules in our algorithm. Given a natural\nlanguage question about an image, the first module takes the question as input\nand then outputs the ranked basic questions, with similarity scores, of the\nmain given question. The second module takes the main question, image and these\nbasic questions as input and then outputs the text-based answer of the main\nquestion about the given image. We claim that a robust VQA model is one, whose\nperformance is not changed much when related basic questions as also made\navailable to it as input. We formulate the basic questions generation problem\nas a LASSO optimization, and also propose a large scale Basic Question Dataset\n(BQD) and Rscore (novel robustness measure), for analyzing the robustness of\nVQA models. We hope our BQD will be used as a benchmark for to evaluate the\nrobustness of VQA models, so as to help the community build more robust and\naccurate VQA models.", "published": "2017-09-14 06:11:09", "link": "http://arxiv.org/abs/1709.04625v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language\n  Understanding", "abstract": "Recurrent neural nets (RNN) and convolutional neural nets (CNN) are widely\nused on NLP tasks to capture the long-term and local dependencies,\nrespectively. Attention mechanisms have recently attracted enormous interest\ndue to their highly parallelizable computation, significantly less training\ntime, and flexibility in modeling dependencies. We propose a novel attention\nmechanism in which the attention between elements from input sequence(s) is\ndirectional and multi-dimensional (i.e., feature-wise). A light-weight neural\nnet, \"Directional Self-Attention Network (DiSAN)\", is then proposed to learn\nsentence embedding, based solely on the proposed attention without any RNN/CNN\nstructure. DiSAN is only composed of a directional self-attention with temporal\norder encoded, followed by a multi-dimensional attention that compresses the\nsequence into a vector representation. Despite its simple form, DiSAN\noutperforms complicated RNN models on both prediction quality and time\nefficiency. It achieves the best test accuracy among all sentence encoding\nmethods and improves the most recent best result by 1.02% on the Stanford\nNatural Language Inference (SNLI) dataset, and shows state-of-the-art test\naccuracy on the Stanford Sentiment Treebank (SST), Multi-Genre natural language\ninference (MultiNLI), Sentences Involving Compositional Knowledge (SICK),\nCustomer Review, MPQA, TREC question-type classification and Subjectivity\n(SUBJ) datasets.", "published": "2017-09-14 10:42:44", "link": "http://arxiv.org/abs/1709.04696v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Embedded-Graph Theory", "abstract": "In this paper, we propose a new type of graph, denoted as \"embedded-graph\",\nand its theory, which employs a distributed representation to describe the\nrelations on the graph edges. Embedded-graphs can express linguistic and\ncomplicated relations, which cannot be expressed by the existing edge-graphs or\nweighted-graphs. We introduce the mathematical definition of embedded-graph,\ntranslation, edge distance, and graph similarity. We can transform an\nembedded-graph into a weighted-graph and a weighted-graph into an edge-graph by\nthe translation method and by threshold calculation, respectively. The edge\ndistance of an embedded-graph is a distance based on the components of a target\nvector, and it is calculated through cosine similarity with the target vector.\nThe graph similarity is obtained considering the relations with linguistic\ncomplexity. In addition, we provide some examples and data structures for\nembedded-graphs in this paper.", "published": "2017-09-14 11:31:19", "link": "http://arxiv.org/abs/1709.04710v1", "categories": ["cs.DM", "cs.CL", "05C90, 68R10, 97K30", "G.2.2"], "primary_category": "cs.DM"}
