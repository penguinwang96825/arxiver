{"title": "Optimal Hardness of Online Algorithms for Large Independent Sets", "abstract": "We study the algorithmic problem of finding a large independent set in an\nErd\\\"{o}s-R\\'{e}nyi random graph $\\mathbb{G}(n,p)$. For constant $p$ and\n$b=1/(1-p)$, the largest independent set has size $2\\log_b n$, while a simple\ngreedy algorithm revealing vertices sequentially and making decisions based\nonly on previously seen vertices finds an independent set of size $\\log_b n$.\nIn his seminal 1976 paper, Karp challenged to either improve this guarantee or\nestablish its hardness. Decades later, this problem remains open, one of the\nmost prominent algorithmic problems in the theory of random graphs.\n  In this paper, we establish that a broad class of online algorithms fails to\nfind an independent set of size $(1+\\epsilon)\\log_b n$ any constant\n$\\epsilon>0$ w.h.p. This class includes Karp's algorithm as a special case, and\nextends it by allowing the algorithm to query exceptional edges not yet 'seen'\nby the algorithm. Our lower bound holds for all $p\\in [d/n,1-n^{-1/d}]$, where\n$d$ is a large constant. In the dense regime (constant $p$), we further prove\nthat our result is asymptotically tight with respect to the number of\nexceptional edges queried, by designing an online algorithm which beats the\nhalf-optimality threshold when the number of exceptional edges slightly exceeds\nour bound.\n  Our result provides evidence for the algorithmic hardness of Karp's problem\nby supporting the conjectured optimality of the aforementioned greedy algorithm\nand establishing it within the class of online algorithms. Our proof relies on\na refined analysis of the geometric structure of tuples of large independent\nsets, establishing a variant of the Overlap Gap Property (OGP) commonly used as\na barrier for classes of algorithms. While OGP has predominantly served as a\nbarrier to stable algorithms, online algorithms are not stable and our\napplication of OGP-based techniques to online setting is novel.", "published": "2025-04-15 17:58:08", "link": "http://arxiv.org/abs/2504.11450v1", "categories": ["cs.DS", "cs.CC", "cs.DM", "math.CO", "math.PR"], "primary_category": "cs.DS"}
{"title": "Improving LLM Interpretability and Performance via Guided Embedding Refinement for Sequential Recommendation", "abstract": "The fast development of Large Language Models (LLMs) offers growing\nopportunities to further improve sequential recommendation systems. Yet for\nsome practitioners, integrating LLMs to their existing base recommendation\nsystems raises questions about model interpretability, transparency and related\nsafety. To partly alleviate challenges from these questions, we propose guided\nembedding refinement, a method that carries out a guided and interpretable\nusage of LLM to enhance the embeddings associated with the base recommendation\nsystem. Instead of directly using LLMs as the backbone of sequential\nrecommendation systems, we utilize them as auxiliary tools to emulate the sales\nlogic of recommendation and generate guided embeddings that capture\ndomain-relevant semantic information on interpretable attributes. Benefiting\nfrom the strong generalization capabilities of the guided embedding, we\nconstruct refined embedding by using the guided embedding and reduced-dimension\nversion of the base embedding. We then integrate the refined embedding into the\nrecommendation module for training and inference. A range of numerical\nexperiments demonstrate that guided embedding is adaptable to various given\nexisting base embedding models, and generalizes well across different\nrecommendation tasks. The numerical results show that the refined embedding not\nonly improves recommendation performance, achieving approximately $10\\%$ to\n$50\\%$ gains in Mean Reciprocal Rank (MRR), Recall rate, and Normalized\nDiscounted Cumulative Gain (NDCG), but also enhances interpretability, as\nevidenced by case studies.", "published": "2025-04-15 23:03:53", "link": "http://arxiv.org/abs/2504.11658v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Bipartite Ranking From Multiple Labels: On Loss Versus Label Aggregation", "abstract": "Bipartite ranking is a fundamental supervised learning problem, with the goal\nof learning a ranking over instances with maximal area under the ROC curve\n(AUC) against a single binary target label. However, one may often observe\nmultiple binary target labels, e.g., from distinct human annotators. How can\none synthesize such labels into a single coherent ranking? In this work, we\nformally analyze two approaches to this problem -- loss aggregation and label\naggregation -- by characterizing their Bayes-optimal solutions. Based on this,\nwe show that while both methods can yield Pareto-optimal solutions, loss\naggregation can exhibit label dictatorship: one can inadvertently (and\nundesirably) favor one label over others. This suggests that label aggregation\ncan be preferable to loss aggregation, which we empirically verify.", "published": "2025-04-15 15:25:27", "link": "http://arxiv.org/abs/2504.11284v1", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Efficient Distributed Retrieval-Augmented Generation for Enhancing Language Model Performance", "abstract": "Small language models (SLMs) support efficient deployments on\nresource-constrained edge devices, but their limited capacity compromises\ninference performance. Retrieval-augmented generation (RAG) is a promising\nsolution to enhance model performance by integrating external databases,\nwithout requiring intensive on-device model retraining. However, large-scale\npublic databases and user-specific private contextual documents are typically\nlocated on the cloud and the device separately, while existing RAG\nimplementations are primarily centralized. To bridge this gap, we propose\nDRAGON, a distributed RAG framework to enhance on-device SLMs through both\ngeneral and personal knowledge without the risk of leaking document privacy.\nSpecifically, DRAGON decomposes multi-document RAG into multiple parallel token\ngeneration processes performed independently and locally on the cloud and the\ndevice, and employs a newly designed Speculative Aggregation, a dual-side\nspeculative algorithm to avoid frequent output synchronization between the\ncloud and device. A new scheduling algorithm is further introduced to identify\nthe optimal aggregation side based on real-time network conditions. Evaluations\non real-world hardware testbed demonstrate a significant performance\nimprovement of DRAGON-up to 1.9x greater gains over standalone SLM compared to\nthe centralized RAG, substantial reduction in per-token latency, and negligible\nTime to First Token (TTFT) overhead.", "published": "2025-04-15 13:53:08", "link": "http://arxiv.org/abs/2504.11197v2", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Evaluation Report on MCP Servers", "abstract": "With the rise of LLMs, a large number of Model Context Protocol (MCP)\nservices have emerged since the end of 2024. However, the effectiveness and\nefficiency of MCP servers have not been well studied. To study these questions,\nwe propose an evaluation framework, called MCPBench. We selected several widely\nused MCP server and conducted an experimental evaluation on their accuracy,\ntime, and token usage. Our experiments showed that the most effective MCP, Bing\nWeb Search, achieved an accuracy of 64%. Importantly, we found that the\naccuracy of MCP servers can be substantially enhanced by involving declarative\ninterface. This research paves the way for further investigations into\noptimized MCP implementations, ultimately leading to better AI-driven\napplications and data retrieval solutions.", "published": "2025-04-15 11:40:12", "link": "http://arxiv.org/abs/2504.11094v1", "categories": ["cs.IR", "cs.DB"], "primary_category": "cs.IR"}
{"title": "RAID: An In-Training Defense against Attribute Inference Attacks in Recommender Systems", "abstract": "In various networks and mobile applications, users are highly susceptible to\nattribute inference attacks, with particularly prevalent occurrences in\nrecommender systems. Attackers exploit partially exposed user profiles in\nrecommendation models, such as user embeddings, to infer private attributes of\ntarget users, such as gender and political views. The goal of defenders is to\nmitigate the effectiveness of these attacks while maintaining recommendation\nperformance. Most existing defense methods, such as differential privacy and\nattribute unlearning, focus on post-training settings, which limits their\ncapability of utilizing training data to preserve recommendation performance.\nAlthough adversarial training extends defenses to in-training settings, it\noften struggles with convergence due to unstable training processes. In this\npaper, we propose RAID, an in-training defense method against attribute\ninference attacks in recommender systems. In addition to the recommendation\nobjective, we define a defensive objective to ensure that the distribution of\nprotected attributes becomes independent of class labels, making users\nindistinguishable from attribute inference attacks. Specifically, this\ndefensive objective aims to solve a constrained Wasserstein barycenter problem\nto identify the centroid distribution that makes the attribute\nindistinguishable while complying with recommendation performance constraints.\nTo optimize our proposed objective, we use optimal transport to align users\nwith the centroid distribution. We conduct extensive experiments on four\nreal-world datasets to evaluate RAID. The experimental results validate the\neffectiveness of RAID and demonstrate its significant superiority over existing\nmethods in multiple aspects.", "published": "2025-04-15 10:24:37", "link": "http://arxiv.org/abs/2504.11510v1", "categories": ["cs.IR", "cs.AI", "cs.CR", "cs.CY", "cs.LG"], "primary_category": "cs.IR"}
{"title": "PATFinger: Prompt-Adapted Transferable Fingerprinting against Unauthorized Multimodal Dataset Usage", "abstract": "The multimodal datasets can be leveraged to pre-train large-scale\nvision-language models by providing cross-modal semantics. Current endeavors\nfor determining the usage of datasets mainly focus on single-modal dataset\nownership verification through intrusive methods and non-intrusive techniques,\nwhile cross-modal approaches remain under-explored. Intrusive methods can adapt\nto multimodal datasets but degrade model accuracy, while non-intrusive methods\nrely on label-driven decision boundaries that fail to guarantee stable\nbehaviors for verification. To address these issues, we propose a novel\nprompt-adapted transferable fingerprinting scheme from a training-free\nperspective, called PATFinger, which incorporates the global optimal\nperturbation (GOP) and the adaptive prompts to capture dataset-specific\ndistribution characteristics. Our scheme utilizes inherent dataset attributes\nas fingerprints instead of compelling the model to learn triggers. The GOP is\nderived from the sample distribution to maximize embedding drifts between\ndifferent modalities. Subsequently, our PATFinger re-aligns the adaptive prompt\nwith GOP samples to capture the cross-modal interactions on the carefully\ncrafted surrogate model. This allows the dataset owner to check the usage of\ndatasets by observing specific prediction behaviors linked to the PATFinger\nduring retrieval queries. Extensive experiments demonstrate the effectiveness\nof our scheme against unauthorized multimodal dataset usage on various\ncross-modal retrieval architectures by 30% over state-of-the-art baselines.", "published": "2025-04-15 09:53:02", "link": "http://arxiv.org/abs/2504.11509v2", "categories": ["cs.IR", "cs.CV"], "primary_category": "cs.IR"}
{"title": "Document Quality Scoring for Web Crawling", "abstract": "The internet contains large amounts of low-quality content, yet users expect\nweb search engines to deliver high-quality, relevant results. The abundant\npresence of low-quality pages can negatively impact retrieval and crawling\nprocesses by wasting resources on these documents. Therefore, search engines\ncan greatly benefit from techniques that leverage efficient quality estimation\nmethods to mitigate these negative impacts. Quality scoring methods for web\npages are useful for many processes typical for web search systems, including\nstatic index pruning, index tiering, and crawling. Building on work by Chang et\nal.~\\cite{chang2024neural}, who proposed using neural estimators of semantic\nquality for static index pruning, we extend their approach and apply their\nneural quality scorers to assess the semantic quality of web pages in crawling\nprioritisation tasks. In our experimental analysis, we found that prioritising\nsemantically high-quality pages over low-quality ones can improve downstream\nsearch effectiveness. Our software contribution consists of a Docker container\nthat computes an effective quality score for a given web page, allowing the\nquality scorer to be easily included and used in other components of web search\nsystems.", "published": "2025-04-15 09:32:57", "link": "http://arxiv.org/abs/2504.11011v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Why am I seeing this? Towards recognizing social media recommender systems with missing recommendations", "abstract": "Social media plays a crucial role in shaping society, often amplifying\npolarization and spreading misinformation. These effects stem from complex\ndynamics involving user interactions, individual traits, and recommender\nalgorithms driving content selection. Recommender systems, which significantly\nshape the content users see and decisions they make, offer an opportunity for\nintervention and regulation. However, assessing their impact is challenging due\nto algorithmic opacity and limited data availability. To effectively model user\ndecision-making, it is crucial to recognize the recommender system adopted by\nthe platform.\n  This work introduces a method for Automatic Recommender Recognition using\nGraph Neural Networks (GNNs), based solely on network structure and observed\nbehavior. To infer the hidden recommender, we first train a Recommender Neutral\nUser model (RNU) using a GNN and an adapted hindsight academic network\nrecommender, aiming to reduce reliance on the actual recommender in the data.\nWe then generate several Recommender Hypothesis-specific Synthetic Datasets\n(RHSD) by combining the RNU with different known recommenders, producing ground\ntruths for testing. Finally, we train Recommender Hypothesis-specific User\nmodels (RHU) under various hypotheses and compare each candidate with the\noriginal used to generate the RHSD.\n  Our approach enables accurate detection of hidden recommenders and their\ninfluence on user behavior. Unlike audit-based methods, it captures system\nbehavior directly, without ad hoc experiments that often fail to reflect real\nplatforms. This study provides insights into how recommenders shape behavior,\naiding efforts to reduce polarization and misinformation.", "published": "2025-04-15 09:16:17", "link": "http://arxiv.org/abs/2504.11000v1", "categories": ["cs.IR", "cs.SI"], "primary_category": "cs.IR"}
{"title": "MSCRS: Multi-modal Semantic Graph Prompt Learning Framework for Conversational Recommender Systems", "abstract": "Conversational Recommender Systems (CRSs) aim to provide personalized\nrecommendations by interacting with users through conversations. Most existing\nstudies of CRS focus on extracting user preferences from conversational\ncontexts. However, due to the short and sparse nature of conversational\ncontexts, it is difficult to fully capture user preferences by conversational\ncontexts only. We argue that multi-modal semantic information can enrich user\npreference expressions from diverse dimensions (e.g., a user preference for a\ncertain movie may stem from its magnificent visual effects and compelling\nstoryline). In this paper, we propose a multi-modal semantic graph prompt\nlearning framework for CRS, named MSCRS. First, we extract textual and image\nfeatures of items mentioned in the conversational contexts. Second, we capture\nhigher-order semantic associations within different semantic modalities\n(collaborative, textual, and image) by constructing modality-specific graph\nstructures. Finally, we propose an innovative integration of multi-modal\nsemantic graphs with prompt learning, harnessing the power of large language\nmodels to comprehensively explore high-dimensional semantic relationships.\nExperimental results demonstrate that our proposed method significantly\nimproves accuracy in item recommendation, as well as generates more natural and\ncontextually relevant content in response generation. We have released the code\nand the expanded multi-modal CRS datasets to facilitate further exploration in\nrelated research\\footnote{https://github.com/BIAOBIAO12138/MSCRS-main}.", "published": "2025-04-15 07:05:22", "link": "http://arxiv.org/abs/2504.10921v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "CSPLADE: Learned Sparse Retrieval with Causal Language Models", "abstract": "In recent years, dense retrieval has been the focus of information retrieval\n(IR) research. While effective, dense retrieval produces uninterpretable dense\nvectors, and suffers from the drawback of large index size. Learned sparse\nretrieval (LSR) has emerged as promising alternative, achieving competitive\nretrieval performance while also being able to leverage the classical inverted\nindex data structure for efficient retrieval. However, limited works have\nexplored scaling LSR beyond BERT scale. In this work, we identify two\nchallenges in training large language models (LLM) for LSR: (1) training\ninstability during the early stage of contrastive training; (2) suboptimal\nperformance due to pre-trained LLM's unidirectional attention. To address these\nchallenges, we propose two corresponding techniques: (1) a lightweight\nadaptation training phase to eliminate training instability; (2) two model\nvariants to enable bidirectional information. With these techniques, we are\nable to train LSR models with 8B scale LLM, and achieve competitive retrieval\nperformance with reduced index size. Furthermore, we are among the first to\nanalyze the performance-efficiency tradeoff of LLM-based LSR model through the\nlens of model quantization. Our findings provide insights into adapting LLMs\nfor efficient retrieval modeling.", "published": "2025-04-15 02:31:34", "link": "http://arxiv.org/abs/2504.10816v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Adaptive Error Correction for Entanglement Distillation", "abstract": "Quantum network applications impose a variety of requirements on entanglement\nresources in terms of rate, fidelity, latency, and more. The repeaters in the\nquantum network must combine good methods for entanglement generation,\neffective entanglement distillation, and smart routing protocols to satisfy\nthese application requirements. In this work, we focus on quantum error\ncorrection-based entanglement distillation in a linear chain of quantum\nrepeaters. While conventional approaches reuse the same distillation scheme\nover multiple hop lengths after entanglement swaps, we propose a novel adaptive\nerror correction scheme that boosts end-to-end metrics. Specifically, depending\non the network operation point, we adapt the code used in distillation over\nsuccessive rounds to monotonically increase the rate while also improving\nfidelity. We demonstrate the effectiveness of this strategy using three codes:\n[[9,1,3]], [[9,2,3]], [[9,3,3]]. We compare the performance of four different\nprotocols that combine the codes in different ways, where we define a new\nperformance metric, efficiency, that incorporates both overall rate and\nfidelity. While we highlight our innovation under minimal assumptions on noise,\nthe method can be easily generalized to realistic network settings. By\ncombining our approach with good entanglement generation methods and smart\nrouting protocols, we can achieve application requirements in a systematic,\nresource-efficient, way.", "published": "2025-04-15 23:52:25", "link": "http://arxiv.org/abs/2504.11670v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Transformer-Driven Neural Beamforming with Imperfect CSI in Urban Macro Wireless Channels", "abstract": "The literature is abundant with methodologies focusing on using transformer\narchitectures due to their prominence in wireless signal processing and their\ncapability to capture long-range dependencies via attention mechanisms. In\nparticular, depthwise separable convolutions enhance parameter efficiency for\nthe process of high-dimensional data characteristics of MIMO systems. In this\nwork, we introduce a novel unsupervised deep learning framework that integrates\ndepthwise separable convolutions and transformers to generate beamforming\nweights under imperfect channel state information (CSI) for a multi-user\nsingle-input multiple-output (MU-SIMO) system in dense urban environments. The\nprimary goal is to enhance throughput by maximizing sum-rate while ensuring\nreliable communication. Spectral efficiency and block error rate (BLER) are\nconsidered as performance metrics. Experiments are carried out under various\nconditions to compare the performance of the proposed NNBF framework against\nbaseline methods zero-forcing beamforming (ZFBF) and minimum mean square error\n(MMSE) beamforming. Experimental results demonstrate the superiority of the\nproposed framework over the baseline techniques.", "published": "2025-04-15 23:41:24", "link": "http://arxiv.org/abs/2504.11667v1", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Full-Diversity Construction-D Lattices: Design and Decoding Perspective on Block-Fading Channels", "abstract": "This paper introduces a novel framework for constructing algebraic lattices\nbased on Construction-D, leveraging nested linear codes and prime ideals from\nalgebraic number fields. We focus on the application of these lattices in\nblock-fading (BF) channels, which are characterized by piecewise-constant\nfading across blocks of transmitted symbols. This approach results in a\nsemi-systematic generator matrix, providing a structured foundation for\nhigh-dimensional lattice design for BF channels. The proposed Construction-D\nlattices exhibit the full diversity property, making them highly effective for\nerror performance improvement. To address this, we develop an efficient\ndecoding algorithm designed specifically for full-diversity Construction-D\nlattices.\n  Simulations indicate that the proposed lattices notably enhance error\nperformance compared to full-diversity Construction-A lattices in diversity-2\ncases. Interestingly, unlike AWGN channels, the expected performance\nenhancement of Construction-D over Construction-A, resulting from an increased\nnumber of nested code levels, was observed only in the two-level and\ndiversity-2 cases. This phenomenon is likely attributed to the intensified\neffects of error propagation that occur during successive cancellation at\nhigher levels, as well as the higher diversity orders.\n  These findings highlight the promise of Construction-D lattices as an\neffective coding strategy for enhancing communication reliability in BF\nchannels.", "published": "2025-04-15 17:57:56", "link": "http://arxiv.org/abs/2504.11448v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Fault Tolerant Quantum Simulation via Symplectic Transvections", "abstract": "Conventional approaches to fault-tolerant quantum computing realize logical\ncircuits gate-by-gate, synthesizing each gate independently on one or more code\nblocks. This incurs excess overhead and doesn't leverage common structures in\nquantum algorithms. In contrast, we propose a framework that enables the\nexecution of entire logical circuit blocks at once, preserving their global\nstructure. This whole-block approach allows for the direct implementation of\nlogical Trotter circuits - of arbitrary rotation angles - on any stabilizer\ncode, providing a powerful new method for fault tolerant Hamiltonian simulation\nwithin a single code block. At the heart of our approach lies a deep structural\ncorrespondence between symplectic transvections and Trotter circuits. This\nconnection enables both logical and physical circuits to share the Trotter\nstructure while preserving stabilizer centralization and circuit symmetry even\nin the presence of non-Clifford rotations. We discuss potential approaches to\nfault tolerance via biased noise and code concatenation. While we illustrate\nthe key principles using a $[[8,3,3]]$ code, our simulations show that the\nframework applies to Hamiltonian simulation on even good quantum LDPC codes.\nThese results open the door to new algorithm-tailored, block-level strategies\nfor fault tolerant circuit design, especially in quantum simulation.", "published": "2025-04-15 17:56:07", "link": "http://arxiv.org/abs/2504.11444v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Breaking the TDD Flow for Over-the-Air Phase Synchronization in Distributed Antenna Systems", "abstract": "Phase synchronization between distributed antenna arrays requires\nmeasurements that break the standard time-division duplex (TDD) operation. We\npresent a feasibility study on implementing such synchronization and analyze\nits impact on the quality of service. Considering two antenna arrays with\nindependent local oscillators (LOs), we propose a modified TDD flow to\naccommodate the transmission of phase synchronization signals, formulate the\nphase estimation and compensation problem, and derive the achievable downlink\nspectral efficiency (SE). Numerical results show that frequent re-estimation of\nthe interarray phase disparity is essential for maximizing SE in systems with\nlow-quality LOs. Furthermore, applying a Kalman filter for phase tracking\nsubstantially improves the SE, especially if phase estimation errors are large\ncompared to LOs phase drifts.", "published": "2025-04-15 17:26:42", "link": "http://arxiv.org/abs/2504.11411v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Property Inheritance for Subtensors in Tensor Train Decompositions", "abstract": "Tensor dimensionality reduction is one of the fundamental tools for modern\ndata science. To address the high computational overhead, fiber-wise sampled\nsubtensors that preserve the original tensor rank are often used in designing\nefficient and scalable tensor dimensionality reduction. However, the theory of\nproperty inheritance for subtensors is still underdevelopment, that is, how the\nessential properties of the original tensor will be passed to its subtensors.\nThis paper theoretically studies the property inheritance of the two key tensor\nproperties, namely incoherence and condition number, under the tensor train\nsetting. We also show how tensor train rank is preserved through fiber-wise\nsampling. The key parameters introduced in theorems are numerically evaluated\nunder various settings. The results show that the properties of interest can be\nwell preserved to the subtensors formed via fiber-wise sampling. Overall, this\npaper provides several handy analytic tools for developing efficient tensor\nanalysis", "published": "2025-04-15 17:10:38", "link": "http://arxiv.org/abs/2504.11396v1", "categories": ["cs.IT", "math.IT", "stat.ML"], "primary_category": "cs.IT"}
{"title": "Taxonomy of Prediction", "abstract": "A prediction makes a claim about a system's future given knowledge of its\npast. A retrodiction makes a claim about its past given knowledge of its\nfuture. We introduce the ambidextrous hidden Markov chain that does both\noptimally -- the bidirectional machine whose state structure makes explicit all\nstatistical correlations in a stochastic process. We introduce an informational\ntaxonomy to profile these correlations via a suite of multivariate information\nmeasures. While prior results laid out the different kinds of information\ncontained in isolated measurements, in addition to being limited to single\nmeasurements the associated informations were challenging to calculate\nexplicitly. Overcoming these via bidirectional machine states, we expand that\nanalysis to information embedded across sequential measurements. The result\nhighlights fourteen new interpretable and calculable information measures that\nfully characterize a process' informational structure. Additionally, we\nintroduce a labeling and indexing scheme that systematizes\ninformation-theoretic analyses of highly complex multivariate systems.\nOperationalizing this, we provide algorithms to directly calculate all of these\nquantities in closed form for finitely-modeled processes.", "published": "2025-04-15 16:36:20", "link": "http://arxiv.org/abs/2504.11371v1", "categories": ["cond-mat.stat-mech", "cs.IT", "math.IT", "nlin.AO"], "primary_category": "cond-mat.stat-mech"}
{"title": "A Mathematical Framework of Semantic Communication based on Category Theory", "abstract": "While semantic communication (SemCom) has recently demonstrated great\npotential to enhance transmission efficiency and reliability by leveraging\nmachine learning (ML) and knowledge base (KB), there is a lack of mathematical\nmodeling to rigorously characterize SemCom system and quantify the performance\ngain obtained from ML and KB. In this paper, we develop a mathematical\nframework for SemCom based on category theory, rigorously model the concepts of\nsemantic entities and semantic probability space. Within this framework,\nsemantic entropy is introduced to quantify the uncertainty of semantic\nentities. We theoretically prove that semantic entropy can be effectively\nreduced by exploiting KB, which capture semantic dependencies. Specifically,\nsemantic entities can be combined based on semantic ambiguity, and are encoded\nbased on contextual relationships among them. Then we refine semantic channel\ncapacity modeling, which considers the mutual information contained in KB to\nbetter reflect SemCom efficiency. Numerical simulations validate the\neffectiveness of the proposed framework, showing that SemCom with KB\nintegration outperforms traditional communication in both entropy reduction and\ncoding efficiency.", "published": "2025-04-15 16:07:33", "link": "http://arxiv.org/abs/2504.11334v1", "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "cs.NI"}
{"title": "Easy repair via codes with simplex locality", "abstract": "In the context of distributed storage systems, locally repairable codes have\nbecome important. In this paper we focus on codes that allow for multi-erasure\npattern decoding with low computational effort. Different optimality\nrequirements, measured by the code's rate, minimum distance, locality,\navailability as well as field size, influence each other and can not all be\nmaximized at the same time. We focus on the notion of easy repair, more\nspecifically on the construction of codes that can repair correctable erasure\npatterns with minimal computational effort. In particular, we introduce the\neasy repair property and then present codes of different rates that possess\nthis property. The presented codes are all in some way related to simplex codes\nand comprise block codes as well as unit-memory convolutional codes. We also\nformulate conditions under which the easy repairs can be performed in parallel,\nthus improving access speed of the distributed storage system.", "published": "2025-04-15 14:47:22", "link": "http://arxiv.org/abs/2504.11251v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Scalable Transceiver Design for Multi-User Communication in FDD Massive MIMO Systems via Deep Learning", "abstract": "This paper addresses the joint transceiver design, including pilot\ntransmission, channel feature extraction and feedback, as well as precoding,\nfor low-overhead downlink massive multiple-input multiple-output (MIMO)\ncommunication in frequency-division duplex (FDD) systems. Although deep\nlearning (DL) has shown great potential in tackling this problem, existing\nmethods often suffer from poor scalability in practical systems, as the\nsolution obtained in the training phase merely works for a fixed feedback\ncapacity and a fixed number of users in the deployment phase. To address this\nlimitation, we propose a novel DL-based framework comprised of choreographed\nneural networks, which can utilize one training phase to generate all the\ntransceiver solutions used in the deployment phase with varying sizes of\nfeedback codebooks and numbers of users. The proposed framework includes a\nresidual vector-quantized variational autoencoder (RVQ-VAE) for efficient\nchannel feedback and an edge graph attention network (EGAT) for robust\nmultiuser precoding. It can adapt to different feedback capacities by flexibly\nadjusting the RVQ codebook sizes using the hierarchical codebook structure, and\nscale with the number of users through a feedback module sharing scheme and the\ninherent scalability of EGAT. Moreover, a progressive training strategy is\nproposed to further enhance data transmission performance and generalization\ncapability. Numerical results on a real-world dataset demonstrate the superior\nscalability and performance of our approach over existing methods.", "published": "2025-04-15 13:11:26", "link": "http://arxiv.org/abs/2504.11162v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Helper-Friendly Latency-Bounded Mitigation Strategies against Reactive Jamming Adversaries", "abstract": "Due to the recent developments in the field of full-duplex radios and\ncognitive radios, a new class of reactive jamming attacks has gained attention\nwherein an adversary transmits jamming energy over the victim's frequency band\nand also monitors various energy statistics in the network so as to detect\ncountermeasures, thereby trapping the victim. Although cooperative mitigation\nstrategies against such security threats exist, they are known to incur\nspectral-efficiency loss on the helper node, and are also not robust to\nvariable latency-constraints on victim's messages. Identifying these research\ngaps in existing countermeasures against reactive jamming attacks, we propose a\nfamily of helper-friendly cooperative mitigation strategies that are applicable\nfor a wide-range of latency-requirements on the victim's messages as well as\npractical radio hardware at the helper nodes. The proposed strategies are\ndesigned to facilitate reliable communication for the victim, without\ncompromising the helper's spectral efficiency and also minimally disturbing the\nvarious energy statistics in the network. For theoretical guarantees on their\nefficacy, interesting optimization problems are formulated on the choice of the\nunderlying parameters, followed by extensive mathematical analyses on their\nerror-performance and covertness. Experimental results indicate that the\nproposed strategies should be preferred over the state-of-the-art methods when\nthe helper node is unwilling to compromise on its error performance for\nassisting the victim.", "published": "2025-04-15 11:56:57", "link": "http://arxiv.org/abs/2504.11110v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "New Constructions of Binary Cyclic Codes with Both Relatively Large Minimum Distance and Dual Distance", "abstract": "Binary cyclic codes are worth studying due to their applications and\ntheoretical importance. It is an important problem to construct an infinite\nfamily of cyclic codes with large minimum distance $d$ and dual distance\n$d^{\\perp}$. In recent years, much research has been devoted to improving the\nlower bound on $d$, some of which have exceeded the square-root bound. The\nconstructions presented recently seem to indicate that when the minimum\ndistance increases, the minimum distance of its dual code decreases. In this\npaper, we focus on the new constructions of binary cyclic codes with length\n$n=2^m-1$, dimension near $n/2$, and both relatively large minimum distance and\ndual distance. For $m$ is even, we construct a family of binary cyclic codes\nwith parameters $[2^m-1,2^{m-1}\\pm1,d]$, where $d\\ge 2^{m/2}-1$ and\n$d^\\perp\\ge2^{m/2}$. Both the minimum distance and the dual distance are\nsignificantly better than the previous results. When $m$ is the product of two\ndistinct primes, we construct some cyclic codes with dimensions $k=(n+1)/2$ and\n$d>\\frac{n}{\\log_2n},$ where the lower bound on the minimum distance is much\nlarger than the square-root bound. For $m$ is odd, we present two families of\nbinary $[2^m-1,2^{m-1},d]$ cyclic codes with $d\\ge2^{(m+1)/2}-1$,\n$d^\\perp\\ge2^{(m+1)/2}$ and $d\\ge2^{(m+3)/2}-15$, $d^\\perp\\ge2^{(m-1)/2}$\nrespectively, which leads that $d\\cdot d^\\perp$ can reach $2n$ asymptotically.\nTo the best of our knowledge, except for the punctured binary Reed-Muller\ncodes, there is no other construction of binary cyclic codes that reaches this\nbound.", "published": "2025-04-15 09:29:41", "link": "http://arxiv.org/abs/2504.11010v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Primer on Orthogonal Delay-Doppler Division Multiplexing (ODDM)", "abstract": "As a new type of multicarrier (MC) scheme built upon the recently discovered\ndelay-Doppler domain orthogonal pulse (DDOP), orthogonal delay-Doppler division\nmultiplexing (ODDM) aims to address the challenges of waveform design in linear\ntime-varying channels. In this paper, we explore the design principles of ODDM\nand clarify the key ideas underlying the DDOP. We then derive an alternative\nrepresentation of the DDOP and highlight the fundamental differences between\nODDM and conventional MC schemes. Finally, we discuss and compare two\nimplementation methods for ODDM.", "published": "2025-04-15 07:56:44", "link": "http://arxiv.org/abs/2504.10949v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Low-Overhead Channel Estimation Framework for Beyond Diagonal Reconfigurable Intelligent Surface Assisted Multi-User MIMO Communication", "abstract": "Beyond diagonal reconfigurable intelligent surface (BD-RIS) refers to a\nfamily of RIS architectures characterized by scattering matrices not limited to\nbeing diagonal and enables higher wave manipulation flexibility and large\nperformance gains over conventional (diagonal) RIS. To achieve those promising\ngains, accurate channel state information (CSI) needs to be acquired in BD-RIS\nassisted communication systems. However, the number of coefficients in the\ncascaded channels to be estimated in BD-RIS assisted systems is significantly\nlarger than that in conventional RIS assisted systems, because the channels\nassociated with the off-diagonal elements of the scattering matrix have to be\nestimated as well. Surprisingly, for the first time in the literature, this\npaper rigorously shows that the uplink channel estimation overhead in BD-RIS\nassisted systems is actually of the same order as that in the conventional RIS\nassisted systems. This amazing result stems from a key observation: for each\nuser antenna, its cascaded channel matrix associated with one reference BD-RIS\nelement is a scaled version of that associated with any other BD-RIS element\ndue to the common RIS-base station (BS) channel. In other words, the number of\nindependent unknown variables is far less than it would seem at first glance.\nBuilding upon this property, this paper manages to characterize the minimum\noverhead to perfectly estimate all the channels in the ideal case without noise\nat the BS, and propose a twophase estimation framework for the practical case\nwith noise at the BS. Numerical results demonstrate outstanding channel\nestimation overhead reduction over existing schemes in BD-RIS assisted systems.", "published": "2025-04-15 06:48:08", "link": "http://arxiv.org/abs/2504.10911v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Radiation Footprint Control in Cell-Free Cooperative ISAC: Optimal Joint BS Activation and Beamforming Coordination", "abstract": "Coordinated beamforming across distributed base stations (BSs) in cell-free\narchitectures can efficiently support integrated sensing and communication\n(ISAC) users by improving resource sharing and reducing conflicts in the\nspatial domain. However, coordinating numerous BSs within the ISAC network\nposes risks of generating substantial interference for other networks sharing\nthe spectrum, while also increasing operational costs from power consumption\nand signaling overhead. Therefore, in this paper, we propose an\ninterference-suppressed and cost-optimized cell-free ISAC network by\nopportunistically and cooperatively orchestrating distributed radio resources\nto address competing sensing and communication (S\\&C) demands. Specifically, we\nconceive a radiation footprint control mechanism that autonomously suppresses\ninterference across the entire signal propagation space to safeguard other\nnetworks without exchanging signaling. Then, we propose joint BS activation and\nbeamforming coordination to dynamically activate appropriate BSs and\norchestrate their spatial beams for service provisioning. Building upon this\nframework, we formulate a cost-efficient utility maximization problem that\nconsiders individual S\\&C demands and location-dependent radiation footprint\nconstraints. Since this results in a non-convex optimization problem, we\ndevelop a monotonic optimization embedded branch-and-bound (MO-BRB) algorithm\nto find the optimal solution. Additionally, we apply a low-complexity iterative\nmethod to obtain near-optimal solutions. Finally, simulation results validate\nthe effectiveness of the proposed algorithms.", "published": "2025-04-15 03:14:05", "link": "http://arxiv.org/abs/2504.10830v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "AdapCsiNet: Environment-Adaptive CSI Feedback via Scene Graph-Aided Deep Learning", "abstract": "Accurate channel state information (CSI) is critical for realizing the full\npotential of multiple-antenna wireless communication systems. While deep\nlearning (DL)-based CSI feedback methods have shown promise in reducing\nfeedback overhead, their generalization capability across varying propagation\nenvironments remains limited due to their data-driven nature. Existing\nsolutions based on online training improve adaptability but impose significant\noverhead in terms of data collection and computational resources. In this work,\nwe propose AdapCsiNet, an environment-adaptive DL-based CSI feedback framework\nthat eliminates the need for online training. By integrating environmental\ninformation -- represented as a scene graph -- into a hypernetwork-guided CSI\nreconstruction process, AdapCsiNet dynamically adapts to diverse channel\nconditions. A two-step training strategy is introduced to ensure baseline\nreconstruction performance and effective environment-aware adaptation.\nSimulation results demonstrate that AdapCsiNet achieves up to 46.4% improvement\nin CSI reconstruction accuracy and matches the performance of online learning\nmethods without incurring additional runtime overhead.", "published": "2025-04-15 01:51:15", "link": "http://arxiv.org/abs/2504.10798v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "TextArena", "abstract": "TextArena is an open-source collection of competitive text-based games for\ntraining and evaluation of agentic behavior in Large Language Models (LLMs). It\nspans 57+ unique environments (including single-player, two-player, and\nmulti-player setups) and allows for easy evaluation of model capabilities via\nan online-play system (against humans and other submitted models) with\nreal-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social\nskills such as negotiation, theory of mind, and deception, creating a gap that\nTextArena addresses. Designed with research, community and extensibility in\nmind, TextArena emphasizes ease of adding new games, adapting the framework,\ntesting models, playing against the models, and training models. Detailed\ndocumentation of environments, games, leaderboard, and examples are available\non https://github.com/LeonGuertler/TextArena and https://www.textarena.ai/.", "published": "2025-04-15 17:55:20", "link": "http://arxiv.org/abs/2504.11442v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Reimagining Urban Science: Scaling Causal Inference with Large Language Models", "abstract": "Urban causal research is essential for understanding the complex dynamics of\ncities and informing evidence-based policies. However, it is challenged by the\ninefficiency and bias of hypothesis generation, barriers to multimodal data\ncomplexity, and the methodological fragility of causal experimentation. Recent\nadvances in large language models (LLMs) present an opportunity to rethink how\nurban causal analysis is conducted. This Perspective examines current urban\ncausal research by analyzing taxonomies that categorize research topics, data\nsources, and methodological approaches to identify structural gaps. We then\nintroduce an LLM-driven conceptual framework, AutoUrbanCI, composed of four\ndistinct modular agents responsible for hypothesis generation, data\nengineering, experiment design and execution, and results interpretation with\npolicy recommendations. We propose evaluation criteria for rigor and\ntransparency and reflect on implications for human-AI collaboration, equity,\nand accountability. We call for a new research agenda that embraces\nAI-augmented workflows not as replacements for human expertise but as tools to\nbroaden participation, improve reproducibility, and unlock more inclusive forms\nof urban causal reasoning.", "published": "2025-04-15 16:58:11", "link": "http://arxiv.org/abs/2504.12345v1", "categories": ["cs.CL", "cs.CY", "cs.MA"], "primary_category": "cs.CL"}
{"title": "A Multi-UAV Formation Obstacle Avoidance Method Combined Improved Simulated Annealing and Adaptive Artificial Potential Field", "abstract": "The traditional Artificial Potential Field (APF) method exhibits limitations\nin its force distribution: excessive attraction when UAVs are far from the\ntarget may cause collisions with obstacles, while insufficient attraction near\nthe goal often results in failure to reach the target. Furthermore, APF is\nhighly susceptible to local minima, compromising motion reliability in complex\nenvironments. To address these challenges, this paper presents a novel hybrid\nobstacle avoidance algorithm-Deflected Simulated Annealing-Adaptive Artificial\nPotential Field (DSA-AAPF)-which combines an improved simulated annealing\nmechanism with an enhanced APF model. The proposed approach integrates a\nLeader-Follower distributed formation strategy with the APF framework, where\nthe resultant force formulation is redefined to smooth UAV trajectories. An\nadaptive gravitational gain function is introduced to dynamically adjust UAV\nvelocity based on environmental context, and a fast-converging controller\nensures accurate and efficient convergence to the target. Moreover, a\ndirectional deflection mechanism is embedded within the simulated annealing\nprocess, enabling UAVs to escape local minima caused by semi-enclosed obstacles\nthrough continuous rotational motion. The simulation results, covering\nformation reconfiguration, complex obstacle avoidance, and entrapment escape,\ndemonstrate the feasibility, robustness, and superiority of the proposed\nDSA-AAPF algorithm.", "published": "2025-04-15 10:53:51", "link": "http://arxiv.org/abs/2504.11064v1", "categories": ["cs.MA", "cs.RO", "cs.SY", "eess.SY"], "primary_category": "cs.MA"}
{"title": "LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI Agent Ecosystems", "abstract": "The rise of autonomous AI agents, capable of perceiving, reasoning, and\nacting independently, signals a profound shift in how digital ecosystems\noperate, govern, and evolve. As these agents proliferate beyond centralized\ninfrastructures, they expose foundational gaps in identity, accountability, and\nethical alignment. Three critical questions emerge: Identity: Who or what is\nthe agent? Accountability: Can its actions be verified, audited, and trusted?\nEthical Consensus: Can autonomous systems reliably align with human values and\nprevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered\nOrchestration for Knowledgeful Agents), a unified, systems-level architecture\nfor building ethically governed, interoperable AI agent ecosystems. LOKA\nintroduces a proposed Universal Agent Identity Layer (UAIL) for decentralized,\nverifiable identity; intent-centric communication protocols for semantic\ncoordination across diverse agents; and a Decentralized Ethical Consensus\nProtocol (DECP) that enables agents to make context-aware decisions grounded in\nshared ethical baselines. Anchored in emerging standards such as Decentralized\nIdentifiers (DIDs), Verifiable Credentials (VCs), and post-quantum\ncryptography, LOKA offers a scalable, future-resilient blueprint for\nmulti-agent AI governance. By embedding identity, trust, and ethics into the\nprotocol layer itself, LOKA establishes the foundation for a new era of\nresponsible, transparent, and autonomous AI ecosystems operating across digital\nand physical domains.", "published": "2025-04-15 06:51:35", "link": "http://arxiv.org/abs/2504.10915v1", "categories": ["cs.MA", "cs.AI", "cs.CY"], "primary_category": "cs.MA"}
{"title": "Data driven approach towards more efficient Newton-Raphson power flow calculation for distribution grids", "abstract": "Power flow (PF) calculations are fundamental to power system analysis to\nensure stable and reliable grid operation. The Newton-Raphson (NR) method is\ncommonly used for PF analysis due to its rapid convergence when initialized\nproperly. However, as power grids operate closer to their capacity limits,\nill-conditioned cases and convergence issues pose significant challenges. This\nwork, therefore, addresses these challenges by proposing strategies to improve\nNR initialization, hence minimizing iterations and avoiding divergence. We\nexplore three approaches: (i) an analytical method that estimates the basin of\nattraction using mathematical bounds on voltages, (ii) Two data-driven models\nleveraging supervised learning or physics-informed neural networks (PINNs) to\npredict optimal initial guesses, and (iii) a reinforcement learning (RL)\napproach that incrementally adjusts voltages to accelerate convergence. These\nmethods are tested on benchmark systems. This research is particularly relevant\nfor modern power systems, where high penetration of renewables and\ndecentralized generation require robust and scalable PF solutions. In\nexperiments, all three proposed methods demonstrate a strong ability to provide\nan initial guess for Newton-Raphson method to converge with fewer steps. The\nfindings provide a pathway for more efficient real-time grid operations, which,\nin turn, support the transition toward smarter and more resilient electricity\nnetworks.", "published": "2025-04-15 22:37:55", "link": "http://arxiv.org/abs/2504.11650v1", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.NA", "cs.SY", "math.NA", "I.2.8"], "primary_category": "eess.SY"}
{"title": "Uncertainty Quantification in Multiscale Modeling of Polymer Composite Materials Using Physically Recurrent Neural Networks", "abstract": "This study investigates whether Physically Recurrent Neural Networks (PRNNs),\na recent surrogate model for heterogeneous materials, trained on a micromodel\nwith fixed material parameters, can maintain accuracy for varying material\nproperties without retraining, and propagate uncertainty in a multiscale\nframework. Unlike conventional RNNs, where parameter changes require training\nor explicit inclusion of material properties as extra input features, PRNNs\nembeds material models in their material layer that allow for modification of\nmaterial parameters after training. When adjusting material properties\ndynamically according to the input during testing, PRNN shows high accuracy\nacross a wide range of parameters. Therefore the surrogate can be applied to\nmultiscale uncertainty quantification (UQ). Compared to the full-order\nsimulations on an overly coarse mesh, the PRNN-driven model reduces simulation\ntime by over 7000 times while accurately capturing highly nonlinear evolution\nof the probability density for the macroscopic response as a result of a given\ndistribution for microscale material parameters. A PRNN-driven UQ is\ndemonstrated on a more accurate finer mesh that would be computationally\ninfeasible with the full-order model.", "published": "2025-04-15 21:33:56", "link": "http://arxiv.org/abs/2504.11625v1", "categories": ["cond-mat.dis-nn", "cond-mat.mtrl-sci", "cs.NA", "math.NA"], "primary_category": "cond-mat.dis-nn"}
{"title": "Computing the Tropical Abel--Jacobi Transform and Tropical Distances for Metric Graphs", "abstract": "Metric graphs are important models for capturing the structure of complex\ndata across various domains. While much effort has been devoted to extracting\ngeometric and topological features from graph data, computational aspects of\nmetric graphs as abstract tropical curves remains unexplored. In this paper, we\npresent the first computational and machine learning-driven study of metric\ngraphs from the perspective of tropical algebraic geometry. Specifically, we\nstudy the tropical Abel--Jacobi transform, a vectorization of points on a\nmetric graph via the tropical Abel--Jacobi map into its associated flat torus,\nthe tropical Jacobian. We develop algorithms to compute this transform and\ninvestigate how the resulting embeddings depend on different combinatorial\nmodels of the same metric graph.\n  Once embedded, we compute pairwise distances between points in the tropical\nJacobian under two natural metrics: the tropical polarization distance and the\nFoster--Zhang distance. Computing these distances are generally NP-hard as they\nturn out to be linked to classical lattice problems in computational\ncomplexity, however, we identify a class of metric graphs where fast and\nexplicit computations are feasible. For the general case, we propose practical\nalgorithms for both exact and approximate distance matrix computations using\nlattice basis reduction and mixed-integer programming solvers. Our work lays\nthe groundwork for future applications of tropical geometry and the tropical\nAbel--Jacobi transform in machine learning and data analysis.", "published": "2025-04-15 21:15:32", "link": "http://arxiv.org/abs/2504.11619v2", "categories": ["math.AG", "cs.NA", "math.MG", "math.NA"], "primary_category": "math.AG"}
{"title": "Robust Containment Queries over Collections of Trimmed NURBS Surfaces via Generalized Winding Numbers", "abstract": "Efficient and accurate evaluation of containment queries for regions bound by\ntrimmed NURBS surfaces is important in many graphics and engineering\napplications. However, the algebraic complexity of surface-surface\nintersections makes gaps and overlaps between surfaces difficult to avoid for\nin-the-wild surface models. By considering this problem through the lens of the\ngeneralized winding number (GWN), a mathematical construction that is\nindifferent to the arrangement of surfaces in the shape, we can define a\ncontainment query that is robust to model watertightness. Applying contemporary\ntechniques for the 3D GWN on arbitrary curved surfaces would require some form\nof geometric discretization, potentially inducing containment\nmisclassifications near boundary components. In contrast, our proposed method\ncomputes an accurate GWN directly on the curved geometry of the input model. We\naccomplish this using a novel reformulation of the relevant surface integral\nusing Stokes' theorem, which in turn permits an efficient adaptive quadrature\ncalculation on the boundary and trimming curves of the model. While this is\nsufficient for \"far-field\" query points that are distant from the surface, we\naugment this approach for \"near-field\" query points (i.e., within a bounding\nbox) and even those coincident to the surface patches via a strategy that\ndirectly identifies and accounts for the jump discontinuity in the scalar\nfield. We demonstrate that our method of evaluating the GWN field is robust to\ncomplex trimming geometry in a CAD model, and is accurate up to arbitrary\nprecision at arbitrary distances from the surface. Furthermore, the derived\ncontainment query is robust to non-watertightness while respecting all curved\nfeatures of the input shape.", "published": "2025-04-15 17:51:39", "link": "http://arxiv.org/abs/2504.11435v1", "categories": ["cs.GR", "cs.CG", "cs.NA", "math.NA", "68U05", "I.3.5"], "primary_category": "cs.GR"}
{"title": "Predicting Wave Dynamics using Deep Learning with Multistep Integration Inspired Attention and Physics-Based Loss Decomposition", "abstract": "In this paper, we present a physics-based deep learning framework for\ndata-driven prediction of wave propagation in fluid media. The proposed\napproach, termed Multistep Integration-Inspired Attention (MI2A), combines a\ndenoising-based convolutional autoencoder for reduced latent representation\nwith an attention-based recurrent neural network with long-short-term memory\ncells for time evolution of reduced coordinates. This proposed architecture\ndraws inspiration from classical linear multistep methods to enhance stability\nand long-horizon accuracy in latent-time integration. Despite the efficiency of\nhybrid neural architectures in modeling wave dynamics, autoregressive\npredictions are often prone to accumulating phase and amplitude errors over\ntime. To mitigate this issue within the MI2A framework, we introduce a novel\nloss decomposition strategy that explicitly separates the training loss\nfunction into distinct phase and amplitude components. We assess the\nperformance of MI2A against two baseline reduced-order models trained with\nstandard mean-squared error loss: a sequence-to-sequence recurrent neural\nnetwork and a variant using Luong-style attention. To demonstrate the\neffectiveness of the MI2A model, we consider three benchmark wave propagation\nproblems of increasing complexity, namely one-dimensional linear convection,\nthe nonlinear viscous Burgers equation, and the two-dimensional Saint-Venant\nshallow water system. Our results demonstrate that the MI2A framework\nsignificantly improves the accuracy and stability of long-term predictions,\naccurately preserving wave amplitude and phase characteristics. Compared to the\nstandard long-short term memory and attention-based models, MI2A-based deep\nlearning exhibits superior generalization and temporal accuracy, making it a\npromising tool for real-time wave modeling.", "published": "2025-04-15 17:47:20", "link": "http://arxiv.org/abs/2504.11433v1", "categories": ["cs.LG", "cs.NA", "math.NA", "physics.flu-dyn"], "primary_category": "cs.LG"}
{"title": "Optimal and Scalable Augmented Lagrangian preconditioners for Fictitious Domain problems", "abstract": "We present optimal and scalable preconditioning techniques to solve linear\nsystems of equations with a block two-by-two and three-by-three structure\narising from fictitious domain problems and from finite element discretizations\nof immersed boundary methods. In particular, we propose two augmented\nLagrangian-based preconditioners to accelerate the convergence of iterative\nsolvers for these two classes of linear. We consider two relevant examples to\nillustrate the performance of these preconditioners when used in conjunction\nwith flexible GMRES: the Poisson and the Stokes fictitious domain problems. A\nspectral analysis is established for both exact and inexact versions of these\npreconditioners. We show the effectiveness of the proposed approach and the\nrobustness of our preconditioning strategy through extensive numerical tests in\nboth two and three dimensions.", "published": "2025-04-15 16:12:51", "link": "http://arxiv.org/abs/2504.11339v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Implicit dual time-stepping positivity-preserving entropy-stable schemes for the compressible Navier-Stokes equations", "abstract": "We generalize the explicit high-order positivity-preserving entropy-stable\nspectral collocation schemes developed in [30, 34] for the three-dimensional\n(3D) compressible Navier Stokes equations to a time implicit formulation. The\ntime derivative terms are discretized by using the first- and second-order\nimplicit backward difference formulas (BDF1 and BDF2) that are well suited for\nsolving steady-state and time-dependent viscous flows at high Reynolds numbers,\nrespectively. The nonlinear system of discrete equations at each physical\ntimestep is solved by using a dual time-stepping technique. The proposed scheme\nis provably entropy-stable and positivity-preserving and provides unconditional\nstability properties in the physical time. Numerical results demonstrating\naccuracy and positivity-preserving properties of the new dual time-stepping\nscheme are presented for supersonic viscous flows with strong shock waves and\ncontact discontinuities.", "published": "2025-04-15 16:07:05", "link": "http://arxiv.org/abs/2504.11333v1", "categories": ["math.NA", "cs.NA", "65L06, 65M12, 65M70, 76J20, 76M25"], "primary_category": "math.NA"}
{"title": "Optimal finite element approximations of monotone semilinear elliptic PDE with subcritical nonlinearities", "abstract": "We study iterative finite element approximations for the numerical\napproximation of semilinear elliptic boundary value problems with monotone\nnonlinear reactions of subcritical growth. The focus of our contribution is on\nan optimal a priori error estimate for a contractive Picard type iteration\nscheme on meshes that are locally refined towards possible corner singularities\nin polygonal domains. Our analysis involves, in particular, an elliptic\nregularity result in weighted Sobolev spaces and the use of the Trudinger\ninequality, which is instrumental in dealing with subcritically growing\nnonlinearities. A series of numerical experiments confirm the accuracy and\nefficiency of our method.", "published": "2025-04-15 15:32:26", "link": "http://arxiv.org/abs/2504.11292v1", "categories": ["math.NA", "cs.NA", "47J25, 65J15, 65N30"], "primary_category": "math.NA"}
{"title": "Characterizing High Schmidt Number Witnesses in Arbitrary Dimensions System", "abstract": "A profound comprehension of quantum entanglement is crucial for the\nprogression of quantum technologies. The degree of entanglement can be assessed\nby enumerating the entangled degrees of freedom, leading to the determination\nof a parameter known as the Schmidt number. In this paper, we develop an\nefficient analytical tool for characterizing high Schmidt number witnesses for\nbipartite quantum states in arbitrary dimensions. Our methods not only offer\nviable mathematical methods for constructing high-dimensional Schmidt number\nwitnesses in theory but also simplify the quantification of entanglement and\ndimensionality. Most notably, we develop high-dimensional Schmidt number\nwitnesses within arbitrary-dimensional systems, with our Schmidt witness\ncoefficients relying solely on the operator Schmidt coefficient. Subsequently,\nwe demonstrate our theoretical advancements and computational superiority by\nconstructing Schmidt number witnesses in arbitrary dimensional bipartite\nquantum systems with Schmidt numbers four and five.", "published": "2025-04-15 14:15:16", "link": "http://arxiv.org/abs/2504.11213v1", "categories": ["quant-ph", "cs.NA", "math-ph", "math.MP", "math.NA", "math.SP"], "primary_category": "quant-ph"}
{"title": "SDFs from Unoriented Point Clouds using Neural Variational Heat Distances", "abstract": "We propose a novel variational approach for computing neural Signed Distance\nFields (SDF) from unoriented point clouds. To this end, we replace the commonly\nused eikonal equation with the heat method, carrying over to the neural domain\nwhat has long been standard practice for computing distances on discrete\nsurfaces. This yields two convex optimization problems for whose solution we\nemploy neural networks: We first compute a neural approximation of the\ngradients of the unsigned distance field through a small time step of heat flow\nwith weighted point cloud densities as initial data. Then we use it to compute\na neural approximation of the SDF. We prove that the underlying variational\nproblems are well-posed. Through numerical experiments, we demonstrate that our\nmethod provides state-of-the-art surface reconstruction and consistent SDF\ngradients. Furthermore, we show in a proof-of-concept that it is accurate\nenough for solving a PDE on the zero-level set.", "published": "2025-04-15 14:13:54", "link": "http://arxiv.org/abs/2504.11212v1", "categories": ["math.NA", "cs.GR", "cs.LG", "cs.NA", "65K10, 68T07, 65D18, 49J45"], "primary_category": "math.NA"}
{"title": "Low-Rank SPIKE Framework for Solving Large Sparse Linear Systems with Applications", "abstract": "The SPIKE family of linear system solvers provides parallelism using a block\ntridiagonal partitioning. Typically SPIKE-based solvers are applied to banded\nsystems, resulting in structured off-diagonal blocks with non-zeros elements\nrestricted to relatively small submatrices comprising the band of the original\nmatrix. In this work, a low-rank SVD based approximation of the off-diagonal\nblocks is investigated. This produces a representation which more effectively\nhandles matrices with large, sparse bands. A set of flexible distributed\nsolvers, the LR-SPIKE variants, are implemented. There are applicable to a wide\nrange of applications -- from use as a \"black-box\" preconditioner which\nstraightforwardly improves upon the classic Block Jacobi preconditioner, to use\nas a specialized \"approximate direct solver.\" An investigation of the\neffectiveness of the new preconditioners for a selection of SuiteSparse\nmatrices is performed, particularly focusing on matrices derived from 3D finite\nelement simulations. In addition, the SPIKE approximate linear system solvers\nare also paired with the FEAST eigenvalue solver, where they are shown to be\nparticularly effective due to the former's rapid convergence, and the latter's\nacceptance of loose linear system solver convergence, resulting in a\ncombination which requires very few solver iterations.", "published": "2025-04-15 13:15:00", "link": "http://arxiv.org/abs/2504.11167v1", "categories": ["math.NA", "cs.MS", "cs.NA"], "primary_category": "math.NA"}
{"title": "An Unsupervised Network Architecture Search Method for Solving Partial Differential Equations", "abstract": "Solving partial differential equations (PDEs) has been indispensable in\nscientific and engineering applications. Recently, deep learning methods have\nbeen widely used to solve high-dimensional problems, one of which is the\nphysics-informed neural network (PINN). Typically, a deep learning method has\nthree main components: a neural network, a loss function, and an optimizer.\nWhile the construction of the loss function is rooted in the definition of\nsolution space, how to choose a optimal neural network is somewhat ad hoc,\nleaving much room for improvement. In the framework of PINN, we propose an\nunsupervised network architecture search method for solving PDEs, termed\nPINN-DARTS, which applies the differentiable architecture search (DARTS) to\nfind the optimal network architecture structure in a given set of neural\nnetworks. In this set, the number of layers and the number of neurons in each\nlayer can change. In the searching phase, both network and architecture\nparameters are updated simultaneously, so the running time is close to that of\nPINN with a pre-determined network structure. Unlike available works, our\napproach is unsupervised and purely based on the PDE residual without any prior\nusage of solutions. PINN-DARTS outputs the optimal network structure as well as\nthe associated numerical solution. The performance of PINN-DARTS is verified on\nseveral benchmark PDEs, including elliptic, parabolic, wave, and Burgers'\nequations. Compared to traditional architecture search methods, PINN-DARTS\nachieves significantly higher architectural accuracy. Another interesting\nobservation is that both the solution complexity and the PDE type have a\nprominent impact on the optimal network architecture. Our study suggests that\narchitectures with uneven widths from layer to layer may have superior\nperformance across different solution complexities and different PDE types.", "published": "2025-04-15 12:42:32", "link": "http://arxiv.org/abs/2504.11140v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A fully variational numerical method for structural topology optimization based on a Cahn-Hilliard model", "abstract": "We formulate a novel numerical method suitable for the solution of topology\noptimization problems in solid mechanics. The most salient feature of the new\napproach is that the space and time discrete equations of the numerical method\ncan be obtained as the optimality conditions of a single incremental potential.\nThe governing equations define a gradient flow of the mass in the domain that\nmaximizes the stiffness of the proposed solid, while exactly preserving the\nmass of the allocated material. Moreover, we propose a change of variables in\nthe model equations that constrains the value of the density within admissible\nbounds and a continuation strategy that speeds up the evolution of the flow.\nThe proposed strategy results in a robust and efficient topology optimization\nmethod that is exactly mass-preserving, does not employ Lagrange multipliers,\nand is fully variational.", "published": "2025-04-15 11:42:54", "link": "http://arxiv.org/abs/2504.11096v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "primary_category": "math.NA"}
{"title": "A study of troubled-cell indicators applied to finite volume methods using a novel monotonicity parameter", "abstract": "We adapt a troubled-cell indicator developed for discontinuous Galerkin (DG)\nmethods to the finite volume method (FVM) framework for solving hyperbolic\nconservation laws. This indicator depends solely on the cell-average data of\nthe target cell and its immediate neighbours. Once the troubled-cells are\nidentified, we apply the limiter only in these cells instead of applying in all\ncomputational cells. We introduce a novel technique to quantify the quality of\nthe solution in the neighbourhood of the shock by defining a monotonicity\nparameter $\\mu$. Numerical results from various two-dimensional simulations on\nthe hyperbolic systems of Euler equations using a finite volume solver\nemploying MUSCL reconstruction validate the performance of the troubled-cell\nindicator and the approach of limiting only in the troubled-cells. These\nresults show that limiting only in the troubled-cells is preferable to limiting\neverywhere as it improves convergence without compromising on the solution\naccuracy.", "published": "2025-04-15 10:44:16", "link": "http://arxiv.org/abs/2504.11056v1", "categories": ["math.NA", "cs.CE", "cs.NA"], "primary_category": "math.NA"}
{"title": "A broken Hardy inequality on finite element space and application to strain gradient elasticity", "abstract": "We illustrate a broken Hardy inequality on discontinuous finite element\nspaces, blowing up with a logarithmic factor with respect to the meshes size.\nThis is motivated by numerical analysis for the strain gradient elasticity with\nnatural boundary conditions. A mixed finite element pair is employed to solve\nthis model with nearly incompressible materials. This pair is quasi-stable with\na logarithmic factor, which is not significant in the approximation error, and\nconverges robustly in the incompressible limit and uniformly in the microscopic\nmaterial parameter. Numerical results back up that the theoretical predictions\nare nearly optimal. Moreover, the regularity estimates for the model over a\nsmooth domain have been proved with the aid of the Agmon-Douglis-Nirenberg\ntheory.", "published": "2025-04-15 09:08:57", "link": "http://arxiv.org/abs/2504.10993v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Convergence rate for a semidiscrete approximation of scalar conservation laws", "abstract": "We propose a semidiscrete scheme for approximation of entropy solutions of\none-dimensional scalar conservation laws with nonnegative initial data. The\nscheme is based on the concept of particle paths for conservation laws and can\nbe interpreted as a finite-particle discretization. A convergence rate of order\n$1/2$ with respect to initial particle spacing is proved. As a special case,\nthis covers the convergence of the Follow--the--Leader model to the\nLighthill--Whitham--Richards model for traffic flow.", "published": "2025-04-15 07:58:28", "link": "http://arxiv.org/abs/2504.10951v1", "categories": ["math.AP", "cs.NA", "math.NA", "65M12, 35L65, 90B20"], "primary_category": "math.AP"}
{"title": "Multi-scale DeepOnet (Mscale-DeepOnet) for Mitigating Spectral Bias in Learning High Frequency Operators of Oscillatory Functions", "abstract": "In this paper, a multi-scale DeepOnet (Mscale-DeepOnet) is proposed to reduce\nthe spectral bias of the DeepOnet in learning high-frequency mapping between\nhighly oscillatory functions, with an application to the nonlinear mapping\nbetween the coefficient of the Helmholtz equation and its solution. The\nMscale-DeepOnet introduces the multiscale neural network in the branch and\ntrunk networks of the original DeepOnet, the resulting Mscale-DeepOnet is shown\nto be able to capture various high-frequency components of the mapping itself\nand its image. Numerical results demonstrate the substantial improvement of the\nMscale-DeepOnet for the problem of wave scattering in the high-frequency regime\nover the normal DeepOnet with a similar number of network parameters.", "published": "2025-04-15 07:19:54", "link": "http://arxiv.org/abs/2504.10932v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Effective dimensionality reduction for Greeks computation using Randomized QMC", "abstract": "Global sensitivity analysis is employed to evaluate the effective dimension\nreduction achieved through Chebyshev interpolation and the conditional pathwise\nmethod for Greek estimation of discretely monitored barrier options and\narithmetic average Asian options. We compare results from finite difference and\nMonte Carlo methods with those obtained by using randomized Quasi Monte Carlo\ncombined with Brownian bridge discretization. Additionally, we investigate the\nbenefits of incorporating importance sampling with either the finite difference\nor Chebyshev interpolation methods. Our findings demonstrate that the reduced\neffective dimensionality identified through global sensitivity analysis\nexplains the performance advantages of one approach over another. Specifically,\nthe increased smoothness provided by Chebyshev or conditional pathwise methods\nenhances the convergence rate of randomized Quasi Monte Carlo integration,\nleading to the significant increase of accuracy and reduced computational\ncosts.", "published": "2025-04-15 19:51:07", "link": "http://arxiv.org/abs/2504.11576v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Breaking the Dimensional Barrier: A Pontryagin-Guided Direct Policy Optimization for Continuous-Time Multi-Asset Portfolio", "abstract": "Solving large-scale, continuous-time portfolio optimization problems\ninvolving numerous assets and state-dependent dynamics has long been challenged\nby the curse of dimensionality. Traditional dynamic programming and PDE-based\nmethods, while rigorous, typically become computationally intractable beyond a\nsmall number of state variables (often limited to ~3-6 in prior numerical\nstudies). To overcome this critical barrier, we introduce the\n\\emph{Pontryagin-Guided Direct Policy Optimization} (PG-DPO) framework. PG-DPO\nleverages Pontryagin's Maximum Principle to directly guide neural network\npolicies via backpropagation-through-time, naturally incorporating exogenous\nstate processes without requiring dense state grids. Crucially, our\ncomputationally efficient ``Two-Stage'' variant exploits rapidly stabilizing\ncostate estimates derived from BPTT, converting them into near-optimal\nclosed-form Pontryagin controls after only a short warm-up, significantly\nreducing training overhead. This enables a breakthrough in scalability:\nnumerical experiments demonstrate that PG-DPO successfully tackles problems\nwith dimensions previously considered far out of reach, optimizing portfolios\nwith up to 50 assets and 10 state variables. The framework delivers\nnear-optimal policies, offering a practical and powerful alternative for\nhigh-dimensional continuous-time portfolio choice.", "published": "2025-04-15 12:03:14", "link": "http://arxiv.org/abs/2504.11116v1", "categories": ["q-fin.PM", "q-fin.CP"], "primary_category": "q-fin.PM"}
{"title": "Can Large Language Models Trade? Testing Financial Theories with LLM Agents in Market Simulations", "abstract": "This paper presents a realistic simulated stock market where large language\nmodels (LLMs) act as heterogeneous competing trading agents. The open-source\nframework incorporates a persistent order book with market and limit orders,\npartial fills, dividends, and equilibrium clearing alongside agents with varied\nstrategies, information sets, and endowments. Agents submit standardized\ndecisions using structured outputs and function calls while expressing their\nreasoning in natural language. Three findings emerge: First, LLMs demonstrate\nconsistent strategy adherence and can function as value investors, momentum\ntraders, or market makers per their instructions. Second, market dynamics\nexhibit features of real financial markets, including price discovery, bubbles,\nunderreaction, and strategic liquidity provision. Third, the framework enables\nanalysis of LLMs' responses to varying market conditions, similar to partial\ndependence plots in machine-learning interpretability. The framework allows\nsimulating financial theories without closed-form solutions, creating\nexperimental designs that would be costly with human participants, and\nestablishing how prompts can generate correlated behaviors affecting market\nstability.", "published": "2025-04-15 01:18:36", "link": "http://arxiv.org/abs/2504.10789v1", "categories": ["q-fin.CP", "econ.GN", "q-fin.EC", "q-fin.GN", "q-fin.TR"], "primary_category": "q-fin.CP"}
{"title": "Multi-Agent Reinforcement Learning for Greenhouse Gas Offset Credit Markets", "abstract": "Climate change is a major threat to the future of humanity, and its impacts\nare being intensified by excess man-made greenhouse gas emissions. One method\ngovernments can employ to control these emissions is to provide firms with\nemission limits and penalize any excess emissions above the limit. Excess\nemissions may also be offset by firms who choose to invest in carbon reducing\nand capturing projects. These projects generate offset credits which can be\nsubmitted to a regulating agency to offset a firm's excess emissions, or they\ncan be traded with other firms. In this work, we characterize the finite-agent\nNash equilibrium for offset credit markets. As computing Nash equilibria is an\nNP-hard problem, we utilize the modern reinforcement learning technique\nNash-DQN to efficiently estimate the market's Nash equilibria. We demonstrate\nnot only the validity of employing reinforcement learning methods applied to\nclimate themed financial markets, but also the significant financial savings\nemitting firms may achieve when abiding by the Nash equilibria through\nnumerical experiments.", "published": "2025-04-15 14:56:42", "link": "http://arxiv.org/abs/2504.11258v1", "categories": ["q-fin.MF", "cs.LG"], "primary_category": "q-fin.MF"}
{"title": "TransST: Transfer Learning Embedded Spatial Factor Modeling of Spatial Transcriptomics Data", "abstract": "Background: Spatial transcriptomics have emerged as a powerful tool in\nbiomedical research because of its ability to capture both the spatial contexts\nand abundance of the complete RNA transcript profile in organs of interest.\nHowever, limitations of the technology such as the relatively low resolution\nand comparatively insufficient sequencing depth make it difficult to reliably\nextract real biological signals from these data. To alleviate this challenge,\nwe propose a novel transfer learning framework, referred to as TransST, to\nadaptively leverage the cell-labeled information from external sources in\ninferring cell-level heterogeneity of a target spatial transcriptomics data.\n  Results: Applications in several real studies as well as a number of\nsimulation settings show that our approach significantly improves existing\ntechniques. For example, in the breast cancer study, TransST successfully\nidentifies five biologically meaningful cell clusters, including the two\nsubgroups of cancer in situ and invasive cancer; in addition, only TransST is\nable to separate the adipose tissues from the connective issues among all the\nstudied methods.\n  Conclusions: In summary, the proposed method TransST is both effective and\nrobust in identifying cell subclusters and detecting corresponding driving\nbiomarkers in spatial transcriptomics data.", "published": "2025-04-15 22:03:38", "link": "http://arxiv.org/abs/2504.12353v1", "categories": ["q-bio.GN", "cs.LG", "stat.AP", "stat.ML"], "primary_category": "q-bio.GN"}
{"title": "Generalized probabilistic canonical correlation analysis for multi-modal data integration with full or partial observations", "abstract": "Background: The integration and analysis of multi-modal data are increasingly\nessential across various domains including bioinformatics. As the volume and\ncomplexity of such data grow, there is a pressing need for computational models\nthat not only integrate diverse modalities but also leverage their\ncomplementary information to improve clustering accuracy and insights,\nespecially when dealing with partial observations with missing data. Results:\nWe propose Generalized Probabilistic Canonical Correlation Analysis (GPCCA), an\nunsupervised method for the integration and joint dimensionality reduction of\nmulti-modal data. GPCCA addresses key challenges in multi-modal data analysis\nby handling missing values within the model, enabling the integration of more\nthan two modalities, and identifying informative features while accounting for\ncorrelations within individual modalities. The model demonstrates robustness to\nvarious missing data patterns and provides low-dimensional embeddings that\nfacilitate downstream clustering and analysis. In a range of simulation\nsettings, GPCCA outperforms existing methods in capturing essential patterns\nacross modalities. Additionally, we demonstrate its applicability to\nmulti-omics data from TCGA cancer datasets and a multi-view image dataset.\nConclusion: GPCCA offers a useful framework for multi-modal data integration,\neffectively handling missing data and providing informative low-dimensional\nembeddings. Its performance across cancer genomics and multi-view image data\nhighlights its robustness and potential for broad application. To make the\nmethod accessible to the wider research community, we have released an R\npackage, GPCCA, which is available at https://github.com/Kaversoniano/GPCCA.", "published": "2025-04-15 20:49:31", "link": "http://arxiv.org/abs/2504.11610v1", "categories": ["stat.ML", "cs.LG", "q-bio.QM"], "primary_category": "stat.ML"}
{"title": "Towards Interpretable Deep Generative Models via Causal Representation Learning", "abstract": "Recent developments in generative artificial intelligence (AI) rely on\nmachine learning techniques such as deep learning and generative modeling to\nachieve state-of-the-art performance across wide-ranging domains. These\nmethods' surprising performance is due in part to their ability to learn\nimplicit \"representations'' of complex, multi-modal data. Unfortunately, deep\nneural networks are notoriously black boxes that obscure these representations,\nmaking them difficult to interpret or analyze. To resolve these difficulties,\none approach is to build new interpretable neural network models from the\nground up. This is the goal of the emerging field of causal representation\nlearning (CRL) that uses causality as a vector for building flexible,\ninterpretable, and transferable generative AI. CRL can be seen as a culmination\nof three intrinsically statistical problems: (i) latent variable models such as\nfactor analysis; (ii) causal graphical models with latent variables; and (iii)\nnonparametric statistics and deep learning. This paper reviews recent progress\nin CRL from a statistical perspective, focusing on connections to classical\nmodels and statistical and causal identifiablity results. This review also\nhighlights key application areas, implementation strategies, and open\nstatistical questions in CRL.", "published": "2025-04-15 20:46:42", "link": "http://arxiv.org/abs/2504.11609v1", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Sub-optimality of the Separation Principle for Quadratic Control from Bilinear Observations", "abstract": "We consider the problem of controlling a linear dynamical system from\nbilinear observations with minimal quadratic cost. Despite the similarity of\nthis problem to standard linear quadratic Gaussian (LQG) control, we show that\nwhen the observation model is bilinear, neither does the Separation Principle\nhold, nor is the optimal controller affine in the estimated state. Moreover,\nthe cost-to-go is non-convex in the control input. Hence, finding an analytical\nexpression for the optimal feedback controller is difficult in general. Under\ncertain settings, we show that the standard LQG controller locally maximizes\nthe cost instead of minimizing it. Furthermore, the optimal controllers\n(derived analytically) are not unique and are nonlinear in the estimated state.\nWe also introduce a notion of input-dependent observability and derive\nconditions under which the Kalman filter covariance remains bounded. We\nillustrate our theoretical results through numerical experiments in multiple\nsynthetic settings.", "published": "2025-04-15 18:53:51", "link": "http://arxiv.org/abs/2504.11555v1", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY", "stat.ML"], "primary_category": "math.OC"}
{"title": "Normalizing Flow Regression for Bayesian Inference with Offline Likelihood Evaluations", "abstract": "Bayesian inference with computationally expensive likelihood evaluations\nremains a significant challenge in many scientific domains. We propose\nnormalizing flow regression (NFR), a novel offline inference method for\napproximating posterior distributions. Unlike traditional surrogate approaches\nthat require additional sampling or inference steps, NFR directly yields a\ntractable posterior approximation through regression on existing log-density\nevaluations. We introduce training techniques specifically for flow regression,\nsuch as tailored priors and likelihood functions, to achieve robust posterior\nand model evidence estimation. We demonstrate NFR's effectiveness on synthetic\nbenchmarks and real-world applications from neuroscience and biology, showing\nsuperior or comparable performance to existing methods. NFR represents a\npromising approach for Bayesian inference when standard methods are\ncomputationally prohibitive or existing model evaluations can be recycled.", "published": "2025-04-15 18:52:33", "link": "http://arxiv.org/abs/2504.11554v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "An Adaptive Dropout Approach for High-Dimensional Bayesian Optimization", "abstract": "Bayesian optimization (BO) is a widely used algorithm for solving expensive\nblack-box optimization problems. However, its performance decreases\nsignificantly on high-dimensional problems due to the inherent\nhigh-dimensionality of the acquisition function. In the proposed algorithm, we\nadaptively dropout the variables of the acquisition function along the\niterations. By gradually reducing the dimension of the acquisition function,\nthe proposed approach has less and less difficulty to optimize the acquisition\nfunction. Numerical experiments demonstrate that AdaDropout effectively tackle\nhigh-dimensional challenges and improve solution quality where standard\nBayesian optimization methods often struggle. Moreover, it achieves superior\nresults when compared with state-of-the-art high-dimensional Bayesian\noptimization approaches. This work provides a simple yet efficient solution for\nhigh-dimensional expensive optimization.", "published": "2025-04-15 16:23:25", "link": "http://arxiv.org/abs/2504.11353v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Interpretable Hybrid-Rule Temporal Point Processes", "abstract": "Temporal Point Processes (TPPs) are widely used for modeling event sequences\nin various medical domains, such as disease onset prediction, progression\nanalysis, and clinical decision support. Although TPPs effectively capture\ntemporal dynamics, their lack of interpretability remains a critical challenge.\nRecent advancements have introduced interpretable TPPs. However, these methods\nfail to incorporate numerical features, thereby limiting their ability to\ngenerate precise predictions. To address this issue, we propose Hybrid-Rule\nTemporal Point Processes (HRTPP), a novel framework that integrates temporal\nlogic rules with numerical features, improving both interpretability and\npredictive accuracy in event modeling. HRTPP comprises three key components:\nbasic intensity for intrinsic event likelihood, rule-based intensity for\nstructured temporal dependencies, and numerical feature intensity for dynamic\nprobability modulation. To effectively discover valid rules, we introduce a\ntwo-phase rule mining strategy with Bayesian optimization. To evaluate our\nmethod, we establish a multi-criteria assessment framework, incorporating rule\nvalidity, model fitting, and temporal predictive accuracy. Experimental results\non real-world medical datasets demonstrate that HRTPP outperforms\nstate-of-the-art interpretable TPPs in terms of predictive performance and\nclinical interpretability. In case studies, the rules extracted by HRTPP\nexplain the disease progression, offering valuable contributions to medical\ndiagnosis.", "published": "2025-04-15 16:15:16", "link": "http://arxiv.org/abs/2504.11344v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Minimalist Approach to LLM Reasoning: from Rejection Sampling to Reinforce", "abstract": "Reinforcement learning (RL) has become a prevailing approach for fine-tuning\nlarge language models (LLMs) on complex reasoning tasks. Among recent methods,\nGRPO stands out for its empirical success in training models such as\nDeepSeek-R1, yet the sources of its effectiveness remain poorly understood. In\nthis work, we revisit GRPO from a reinforce-like algorithm perspective and\nanalyze its core components. Surprisingly, we find that a simple rejection\nsampling baseline, RAFT, which trains only on positively rewarded samples,\nyields competitive performance than GRPO and PPO. Our ablation studies reveal\nthat GRPO's main advantage arises from discarding prompts with entirely\nincorrect responses, rather than from its reward normalization. Motivated by\nthis insight, we propose Reinforce-Rej, a minimal extension of policy gradient\nthat filters both entirely incorrect and entirely correct samples.\nReinforce-Rej improves KL efficiency and stability, serving as a lightweight\nyet effective alternative to more complex RL algorithms. We advocate RAFT as a\nrobust and interpretable baseline, and suggest that future advances should\nfocus on more principled designs for incorporating negative samples, rather\nthan relying on them indiscriminately. Our findings provide guidance for future\nwork in reward-based LLM post-training.", "published": "2025-04-15 16:15:02", "link": "http://arxiv.org/abs/2504.11343v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints", "abstract": "Large Language Models (LLMs) are indispensable in today's applications, but\ntheir inference procedure -- generating responses by processing text in\nsegments and using a memory-heavy Key-Value (KV) cache -- demands significant\ncomputational resources, particularly under memory constraints. This paper\nformulates LLM inference optimization as a multi-stage online scheduling\nproblem where sequential prompt arrivals and KV cache growth render\nconventional scheduling ineffective. We develop a fluid dynamics approximation\nto provide a tractable benchmark that guides algorithm design. Building on\nthis, we propose the Waiting for Accumulated Inference Threshold (WAIT)\nalgorithm, which uses multiple thresholds to schedule incoming prompts\noptimally when output lengths are known, and extend it to Nested WAIT for cases\nwith unknown output lengths. Theoretical analysis shows that both algorithms\nachieve near-optimal performance against the fluid benchmark in heavy traffic\nconditions, balancing throughput, latency, and Time to First Token (TTFT).\nExperiments with the Llama-7B model on an A100 GPU using both synthetic and\nreal-world datasets demonstrate improved throughput and reduced latency\nrelative to established baselines like vLLM and Sarathi. This work bridges\noperations research and machine learning, offering a rigorous framework for the\nefficient deployment of LLMs under memory constraints.", "published": "2025-04-15 16:00:21", "link": "http://arxiv.org/abs/2504.11320v1", "categories": ["cs.LG", "cs.AI", "cs.DC", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Differentially Private Geodesic and Linear Regression", "abstract": "In statistical applications it has become increasingly common to encounter\ndata structures that live on non-linear spaces such as manifolds. Classical\nlinear regression, one of the most fundamental methodologies of statistical\nlearning, captures the relationship between an independent variable and a\nresponse variable which both are assumed to live in Euclidean space. Thus,\ngeodesic regression emerged as an extension where the response variable lives\non a Riemannian manifold. The parameters of geodesic regression, as with linear\nregression, capture the relationship of sensitive data and hence one should\nconsider the privacy protection practices of said parameters. We consider\nreleasing Differentially Private (DP) parameters of geodesic regression via the\nK-Norm Gradient (KNG) mechanism for Riemannian manifolds. We derive theoretical\nbounds for the sensitivity of the parameters showing they are tied to their\nrespective Jacobi fields and hence the curvature of the space. This\ncorroborates recent findings of differential privacy for the Fr\\'echet mean. We\ndemonstrate the efficacy of our methodology on the sphere,\n$\\mbS^2\\subset\\mbR^3$ and, since it is general to Riemannian manifolds, the\nmanifold of Euclidean space which simplifies geodesic regression to a case of\nlinear regression. Our methodology is general to any Riemannian manifold and\nthus it is suitable for data in domains such as medical imaging and computer\nvision.", "published": "2025-04-15 15:45:48", "link": "http://arxiv.org/abs/2504.11304v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Simulation-based inference for stochastic nonlinear mixed-effects models with applications in systems biology", "abstract": "The analysis of data from multiple experiments, such as observations of\nseveral individuals, is commonly approached using mixed-effects models, which\naccount for variation between individuals through hierarchical representations.\nThis makes mixed-effects models widely applied in fields such as biology,\npharmacokinetics, and sociology. In this work, we propose a novel methodology\nfor scalable Bayesian inference in hierarchical mixed-effects models. Our\nframework first constructs amortized approximations of the likelihood and the\nposterior distribution, which are then rapidly refined for each individual\ndataset, to ultimately approximate the parameters posterior across many\nindividuals. The framework is easily trainable, as it uses mixtures of experts\nbut without neural networks, leading to parsimonious yet expressive surrogate\nmodels of the likelihood and the posterior. We demonstrate the effectiveness of\nour methodology using challenging stochastic models, such as mixed-effects\nstochastic differential equations emerging in systems biology-driven problems.\nHowever, the approach is broadly applicable and can accommodate both stochastic\nand deterministic models. We show that our approach can seamlessly handle\ninference for many parameters. Additionally, we applied our method to a\nreal-data case study of mRNA transfection. When compared to exact\npseudomarginal Bayesian inference, our approach proved to be both fast and\ncompetitive in terms of statistical accuracy.", "published": "2025-04-15 15:18:58", "link": "http://arxiv.org/abs/2504.11279v1", "categories": ["stat.CO", "stat.ME", "stat.ML"], "primary_category": "stat.CO"}
{"title": "FEAT: Free energy Estimators with Adaptive Transport", "abstract": "We present Free energy Estimators with Adaptive Transport (FEAT), a novel\nframework for free energy estimation -- a critical challenge across scientific\ndomains. FEAT leverages learned transports implemented via stochastic\ninterpolants and provides consistent, minimum-variance estimators based on\nescorted Jarzynski equality and controlled Crooks theorem, alongside\nvariational upper and lower bounds on free energy differences. Unifying\nequilibrium and non-equilibrium methods under a single theoretical framework,\nFEAT establishes a principled foundation for neural free energy calculations.\nExperimental validation on toy examples, molecular simulations, and quantum\nfield theory demonstrates improvements over existing learning-based methods.", "published": "2025-04-15 15:16:18", "link": "http://arxiv.org/abs/2504.11516v1", "categories": ["stat.ML", "cs.LG", "physics.chem-ph", "physics.comp-ph"], "primary_category": "stat.ML"}
{"title": "Cryo-em images are intrinsically low dimensional", "abstract": "Simulation-based inference provides a powerful framework for cryo-electron\nmicroscopy, employing neural networks in methods like CryoSBI to infer\nbiomolecular conformations via learned latent representations. This latent\nspace represents a rich opportunity, encoding valuable information about the\nphysical system and the inference process. Harnessing this potential hinges on\nunderstanding the underlying geometric structure of these representations. We\ninvestigate this structure by applying manifold learning techniques to CryoSBI\nrepresentations of hemagglutinin (simulated and experimental). We reveal that\nthese high-dimensional data inherently populate low-dimensional, smooth\nmanifolds, with simulated data effectively covering the experimental\ncounterpart. By characterizing the manifold's geometry using Diffusion Maps and\nidentifying its principal axes of variation via coordinate interpretation\nmethods, we establish a direct link between the latent structure and key\nphysical parameters. Discovering this intrinsic low-dimensionality and\ninterpretable geometric organization not only validates the CryoSBI approach\nbut enables us to learn more from the data structure and provides opportunities\nfor improving future inference strategies by exploiting this revealed manifold\ngeometry.", "published": "2025-04-15 14:46:25", "link": "http://arxiv.org/abs/2504.11249v1", "categories": ["q-bio.QM", "cs.CV", "cs.LG", "q-bio.BM", "stat.ML"], "primary_category": "q-bio.QM"}
{"title": "Hessian stability and convergence rates for entropic and Sinkhorn potentials via semiconcavity", "abstract": "In this paper we determine quantitative stability bounds for the Hessian of\nentropic potentials, i.e., the dual solution to the entropic optimal transport\nproblem. Up to authors' knowledge this is the first work addressing this\nsecond-order quantitative stability estimate in general unbounded settings. Our\nproof strategy relies on semiconcavity properties of entropic potentials and on\nthe representation of entropic transport plans as laws of forward and backward\ndiffusion processes, known as Schr\\\"odinger bridges. Moreover, our approach\nallows to deduce a stochastic proof of quantitative stability entropic\nestimates and integrated gradient estimates as well. Finally, as a direct\nconsequence of these stability bounds, we deduce exponential convergence rates\nfor gradient and Hessian of Sinkhorn iterates along Sinkhorn's algorithm, a\nproblem that was still open in unbounded settings. Our rates have a polynomial\ndependence on the regularization parameter.", "published": "2025-04-15 12:34:09", "link": "http://arxiv.org/abs/2504.11133v1", "categories": ["math.PR", "math.AP", "math.OC", "stat.ML", "49Q22, 49L12, 39B62, 60J60, 68Q87, 68W40"], "primary_category": "math.PR"}
{"title": "Divergence of Empirical Neural Tangent Kernel in Classification Problems", "abstract": "This paper demonstrates that in classification problems, fully connected\nneural networks (FCNs) and residual neural networks (ResNets) cannot be\napproximated by kernel logistic regression based on the Neural Tangent Kernel\n(NTK) under overtraining (i.e., when training time approaches infinity).\nSpecifically, when using the cross-entropy loss, regardless of how large the\nnetwork width is (as long as it is finite), the empirical NTK diverges from the\nNTK on the training samples as training time increases. To establish this\nresult, we first demonstrate the strictly positive definiteness of the NTKs for\nmulti-layer FCNs and ResNets. Then, we prove that during training, % with the\ncross-entropy loss, the neural network parameters diverge if the smallest\neigenvalue of the empirical NTK matrix (Gram matrix) with respect to training\nsamples is bounded below by a positive constant. This behavior contrasts\nsharply with the lazy training regime commonly observed in regression problems.\nConsequently, using a proof by contradiction, we show that the empirical NTK\ndoes not uniformly converge to the NTK across all times on the training samples\nas the network width increases. We validate our theoretical results through\nexperiments on both synthetic data and the MNIST classification task. This\nfinding implies that NTK theory is not applicable in this context, with\nsignificant theoretical implications for understanding neural networks in\nclassification problems.", "published": "2025-04-15 12:30:21", "link": "http://arxiv.org/abs/2504.11130v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "On relative universality, regression operator, and conditional independence", "abstract": "The notion of relative universality with respect to a {\\sigma}-field was\nintroduced to establish the unbiasedness and Fisher consistency of an estimator\nin nonlinear sufficient dimension reduction. However, there is a gap in the\nproof of this result in the existing literature. The existing definition of\nrelative universality seems to be too strong for the proof to be valid. In this\nnote we modify the definition of relative universality using the concept of\n\\k{o}-measurability, and rigorously establish the mentioned unbiasedness and\nFisher consistency. The significance of this result is beyond its original\ncontext of sufficient dimension reduction, because relative universality allows\nus to use the regression operator to fully characterize conditional\nindependence, a crucially important statistical relation that sits at the core\nof many areas and methodologies in statistics and machine learning, such as\ndimension reduction, graphical models, probability embedding, causal inference,\nand Bayesian estimation.", "published": "2025-04-15 10:12:26", "link": "http://arxiv.org/abs/2504.11044v1", "categories": ["math.ST", "stat.ME", "stat.ML", "stat.TH", "62", "G.3"], "primary_category": "math.ST"}
{"title": "Making Acoustic Side-Channel Attacks on Noisy Keyboards Viable with LLM-Assisted Spectrograms' \"Typo\" Correction", "abstract": "The large integration of microphones into devices increases the opportunities\nfor Acoustic Side-Channel Attacks (ASCAs), as these can be used to capture\nkeystrokes' audio signals that might reveal sensitive information. However, the\ncurrent State-Of-The-Art (SOTA) models for ASCAs, including Convolutional\nNeural Networks (CNNs) and hybrid models, such as CoAtNet, still exhibit\nlimited robustness under realistic noisy conditions. Solving this problem\nrequires either: (i) an increased model's capacity to infer contextual\ninformation from longer sequences, allowing the model to learn that an\ninitially noisily typed word is the same as a futurely collected non-noisy\nword, or (ii) an approach to fix misidentified information from the contexts,\nas one does not type random words, but the ones that best fit the conversation\ncontext. In this paper, we demonstrate that both strategies are viable and\ncomplementary solutions for making ASCAs practical. We observed that no\nexisting solution leverages advanced transformer architectures' power for these\ntasks and propose that: (i) Visual Transformers (VTs) are the candidate\nsolutions for capturing long-term contextual information and (ii)\ntransformer-powered Large Language Models (LLMs) are the candidate solutions to\nfix the ``typos'' (mispredictions) the model might make. Thus, we here present\nthe first-of-its-kind approach that integrates VTs and LLMs for ASCAs.\n  We first show that VTs achieve SOTA performance in classifying keystrokes\nwhen compared to the previous CNN benchmark. Second, we demonstrate that LLMs\ncan mitigate the impact of real-world noise. Evaluations on the natural\nsentences revealed that: (i) incorporating LLMs (e.g., GPT-4o) in our ASCA\npipeline boosts the performance of error-correction tasks; and (ii) the\ncomparable performance can be attained by a lightweight, fine-tuned smaller LLM\n(67 times smaller than GPT-4o), using...", "published": "2025-04-15 21:23:25", "link": "http://arxiv.org/abs/2504.11622v1", "categories": ["cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "Respiratory Inhaler Sound Event Classification Using Self-Supervised Learning", "abstract": "Asthma is a chronic respiratory condition that affects millions of people\nworldwide. While this condition can be managed by administering controller\nmedications through handheld inhalers, clinical studies have shown low\nadherence to the correct inhaler usage technique. Consequently, many patients\nmay not receive the full benefit of their medication. Automated classification\nof inhaler sounds has recently been studied to assess medication adherence.\nHowever, the existing classification models were typically trained using data\nfrom specific inhaler types, and their ability to generalize to sounds from\ndifferent inhalers remains unexplored. In this study, we adapted the wav2vec\n2.0 self-supervised learning model for inhaler sound classification by\npre-training and fine-tuning this model on inhaler sounds. The proposed model\nshows a balanced accuracy of 98% on a dataset collected using a dry powder\ninhaler and smartwatch device. The results also demonstrate that re-finetuning\nthis model on minimal data from a target inhaler is a promising approach to\nadapting a generic inhaler sound classification model to a different inhaler\ndevice and audio capture hardware. This is the first study in the field to\ndemonstrate the potential of smartwatches as assistive technologies for the\npersonalized monitoring of inhaler adherence using machine learning models.", "published": "2025-04-15 14:44:47", "link": "http://arxiv.org/abs/2504.11246v1", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Dopamine Audiobook: A Training-free MLLM Agent for Emotional and Human-like Audiobook Generation", "abstract": "Audiobook generation, which creates vivid and emotion-rich audio works, faces\nchallenges in conveying complex emotions, achieving human-like qualities, and\naligning evaluations with human preferences. Existing text-to-speech (TTS)\nmethods are often limited to specific scenarios, struggle with emotional\ntransitions, and lack automatic human-aligned evaluation benchmarks, instead\nrelying on either misaligned automated metrics or costly human assessments. To\naddress these issues, we propose Dopamine Audiobook, a new unified\ntraining-free system leveraging a multimodal large language model (MLLM) as an\nAI agent for emotional and human-like audiobook generation and evaluation.\nSpecifically, we first design a flow-based emotion-enhanced framework that\ndecomposes complex emotional speech synthesis into controllable sub-tasks.\nThen, we propose an adaptive model selection module that dynamically selects\nthe most suitable TTS methods from a set of existing state-of-the-art (SOTA)\nTTS methods for diverse scenarios. We further enhance emotional expressiveness\nthrough paralinguistic augmentation and prosody retrieval at word and utterance\nlevels. For evaluation, we propose a novel GPT-based evaluation framework\nincorporating self-critique, perspective-taking, and psychological MagicEmo\nprompts to ensure human-aligned and self-aligned assessments. Experiments show\nthat our method generates long speech with superior emotional expression to\nSOTA TTS models in various metrics. Importantly, our evaluation framework\ndemonstrates better alignment with human preferences and transferability across\naudio tasks. Project website with audio samples can be found at\nhttps://dopamine-audiobook.github.io.", "published": "2025-04-15 09:19:44", "link": "http://arxiv.org/abs/2504.11002v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Real-Time Word-Level Temporal Segmentation in Streaming Speech Recognition", "abstract": "Rich-text captions are essential to help communication for Deaf and\nhard-of-hearing (DHH) people, second-language learners, and those with autism\nspectrum disorder (ASD). They also preserve nuances when converting speech to\ntext, enhancing the realism of presentation scripts and conversation or speech\nlogs. However, current real-time captioning systems lack the capability to\nalter text attributes (ex. capitalization, sizes, and fonts) at the word level,\nhindering the accurate conveyance of speaker intent that is expressed in the\ntones or intonations of the speech. For example, ''YOU should do this'' tends\nto be considered as indicating ''You'' as the focus of the sentence, whereas\n''You should do THIS'' tends to be ''This'' as the focus. This paper proposes a\nsolution that changes the text decorations at the word level in real time. As a\nprototype, we developed an application that adjusts word size based on the\nloudness of each spoken word. Feedback from users implies that this system\nhelped to convey the speaker's intent, offering a more engaging and accessible\ncaptioning experience.", "published": "2025-04-15 04:17:08", "link": "http://arxiv.org/abs/2504.10849v1", "categories": ["cs.HC", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "SteerMusic: Enhanced Musical Consistency for Zero-shot Text-Guided and Personalized Music Editing", "abstract": "Music editing is an important step in music production, which has broad\napplications, including game development and film production. Most existing\nzero-shot text-guided methods rely on pretrained diffusion models by involving\nforward-backward diffusion processes for editing. However, these methods often\nstruggle to maintain the music content consistency. Additionally, text\ninstructions alone usually fail to accurately describe the desired music. In\nthis paper, we propose two music editing methods that enhance the consistency\nbetween the original and edited music by leveraging score distillation. The\nfirst method, SteerMusic, is a coarse-grained zero-shot editing approach using\ndelta denoising score. The second method, SteerMusic+, enables fine-grained\npersonalized music editing by manipulating a concept token that represents a\nuser-defined musical style. SteerMusic+ allows for the editing of music into\nany user-defined musical styles that cannot be achieved by the text\ninstructions alone. Experimental results show that our methods outperform\nexisting approaches in preserving both music content consistency and editing\nfidelity. User studies further validate that our methods achieve superior music\nediting quality. Audio examples are available on https://steermusic.pages.dev/.", "published": "2025-04-15 03:08:09", "link": "http://arxiv.org/abs/2504.10826v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Progressive Rock Music Classification", "abstract": "This study investigates the classification of progressive rock music, a genre\ncharacterized by complex compositions and diverse instrumentation, distinct\nfrom other musical styles. Addressing this Music Information Retrieval (MIR)\ntask, we extracted comprehensive audio features, including spectrograms,\nMel-Frequency Cepstral Coefficients (MFCCs), chromagrams, and beat positions\nfrom song snippets using the Librosa library. A winner-take-all voting strategy\nwas employed to aggregate snippet-level predictions into final song\nclassifications. We conducted a comparative analysis of various machine\nlearning techniques. Ensemble methods, encompassing Bagging (Random Forest,\nExtraTrees, Bagging Classifier) and Boosting (XGBoost, Gradient Boosting), were\nexplored, utilizing Principal Component Analysis (PCA) for dimensionality\nreduction to manage computational constraints with high-dimensional feature\nsets. Additionally, deep learning approaches were investigated, including the\ndevelopment of custom 1D Convolutional Neural Network (1D CNN) architectures\n(named \"Zuck\" and \"Satya\") featuring specific layer configurations,\nnormalization, and activation functions. Furthermore, we fine-tuned a\nstate-of-the-art Audio Spectrogram Transformer (AST) model, leveraging its\nattention-based mechanisms for audio classification. Performance evaluation on\nvalidation and test sets revealed varying effectiveness across models, with\nensemble methods like Extra Trees achieving test accuracies up to 76.38%. This\nresearch provides insights into the application and relative performance of\ndiverse machine learning paradigms for the nuanced task of progressive rock\ngenre classification.", "published": "2025-04-15 02:48:52", "link": "http://arxiv.org/abs/2504.10821v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Generalized Audio Deepfake Detection Using Frame-level Latent Information Entropy", "abstract": "Generalizability, the capacity of a robust model to perform effectively on\nunseen data, is crucial for audio deepfake detection due to the rapid evolution\nof text-to-speech (TTS) and voice conversion (VC) technologies. A promising\napproach to differentiate between bonafide and spoof samples lies in\nidentifying intrinsic disparities to enhance model generalizability. From an\ninformation-theoretic perspective, we hypothesize the information content is\none of the intrinsic differences: bonafide sample represents a dense,\ninformation-rich sampling of the real world, whereas spoof sample is typically\nderived from lower-dimensional, less informative representations. To implement\nthis, we introduce frame-level latent information entropy detector(f-InfoED), a\nframework that extracts distinctive information entropy from latent\nrepresentations at the frame level to identify audio deepfakes. Furthermore, we\npresent AdaLAM, which extends large pre-trained audio models with trainable\nadapters for enhanced feature extraction. To facilitate comprehensive\nevaluation, the audio deepfake forensics 2024 (ADFF 2024) dataset was built by\nthe latest TTS and VC methods. Extensive experiments demonstrate that our\nproposed approach achieves state-of-the-art performance and exhibits remarkable\ngeneralization capabilities. Further analytical studies confirms the efficacy\nof AdaLAM in extracting discriminative audio features and f-InfoED in\nleveraging latent entropy information for more generalized deepfake detection.", "published": "2025-04-15 02:39:46", "link": "http://arxiv.org/abs/2504.10819v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "GOAT-TTS: LLM-based Text-To-Speech Generation Optimized via A Dual-Branch Architecture", "abstract": "While large language models (LLMs) have revolutionized text-to-speech (TTS)\nsynthesis through discrete tokenization paradigms, current architectures\nexhibit fundamental tensions between three critical dimensions: 1) irreversible\nloss of acoustic characteristics caused by quantization of speech prompts; 2)\nstringent dependence on precisely aligned prompt speech-text pairs that limit\nreal-world deployment; and 3) catastrophic forgetting of the LLM's native text\ncomprehension during optimization for speech token generation. To address these\nchallenges, we propose an LLM-based text-to-speech Generation approach\nOptimized via a novel dual-branch ArchiTecture (GOAT-TTS). Our framework\nintroduces two key innovations: (1) The modality-alignment branch combines a\nspeech encoder and projector to capture continuous acoustic embeddings,\nenabling bidirectional correlation between paralinguistic features (language,\ntimbre, emotion) and semantic text representations without transcript\ndependency; (2) The speech-generation branch employs modular fine-tuning on\ntop-k layers of an LLM for speech token prediction while freezing the bottom-k\nlayers to preserve foundational linguistic knowledge. Moreover, multi-token\nprediction is introduced to support real-time streaming TTS synthesis.\nExperimental results demonstrate that our GOAT-TTS achieves performance\ncomparable to state-of-the-art TTS models while validating the efficacy of\nsynthesized dialect speech data.", "published": "2025-04-15 01:44:56", "link": "http://arxiv.org/abs/2504.12339v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SonicSieve: Bringing Directional Speech Extraction to Smartphones Using Acoustic Microstructures", "abstract": "Imagine placing your smartphone on a table in a noisy restaurant and clearly\ncapturing the voices of friends seated around you, or recording a lecturer's\nvoice with clarity in a reverberant auditorium. We introduce SonicSieve, the\nfirst intelligent directional speech extraction system for smartphones using a\nbio-inspired acoustic microstructure. Our passive design embeds directional\ncues onto incoming speech without any additional electronics. It attaches to\nthe in-line mic of low-cost wired earphones which can be attached to\nsmartphones. We present an end-to-end neural network that processes the raw\naudio mixtures in real-time on mobile devices. Our results show that SonicSieve\nachieves a signal quality improvement of 5.0 dB when focusing on a 30{\\deg}\nangular region. Additionally, the performance of our system based on only two\nmicrophones exceeds that of conventional 5-microphone arrays.", "published": "2025-04-15 01:30:48", "link": "http://arxiv.org/abs/2504.10793v1", "categories": ["cs.SD", "cs.HC", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Audio Watermarks are Shallow: Limitations of Post-Hoc Watermarking Techniques for Speech", "abstract": "In the audio modality, state-of-the-art watermarking methods leverage deep\nneural networks to allow the embedding of human-imperceptible signatures in\ngenerated audio. The ideal is to embed signatures that can be detected with\nhigh accuracy when the watermarked audio is altered via compression, filtering,\nor other transformations. Existing audio watermarking techniques operate in a\npost-hoc manner, manipulating \"low-level\" features of audio recordings after\ngeneration (e.g. through the addition of a low-magnitude watermark signal). We\nshow that this post-hoc formulation makes existing audio watermarks vulnerable\nto transformation-based removal attacks. Focusing on speech audio, we (1) unify\nand extend existing evaluations of the effect of audio transformations on\nwatermark detectability, and (2) demonstrate that state-of-the-art post-hoc\naudio watermarks can be removed with no knowledge of the watermarking scheme\nand minimal degradation in audio quality.", "published": "2025-04-15 00:52:01", "link": "http://arxiv.org/abs/2504.10782v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An Energy-efficient Ordered Transmission-based Sequential Estimation", "abstract": "Estimation problems in wireless sensor networks typically involve gathering\nand processing data from distributed sensors to infer the state of an\nenvironment at the fusion center. However, not all measurements contribute\nsignificantly to improving estimation accuracy. The ordered transmission\nprotocol, a promising approach for enhancing energy efficiency in wireless\nnetworks, allows for the selection of measurements from different sensors to\nensure the desired estimation quality. In this work, we use the idea of ordered\ntransmission to reduce the number of transmissions required for sequential\nestimation within a network, thereby achieving energy-efficient estimation. We\nderive a new stopping rule that minimizes the number of transmissions while\nmaintaining estimation accuracy similar to general sequential estimation with\nunordered transmissions. Moreover, we derive the expected number of\ntransmissions required for both general sequential estimation with unordered\ntransmissions and proposed sequential estimation with ordered transmissions and\nmake a comparison between the two systems. Simulation results indicate that our\nproposed scheme can efficiently reduce transmissions while still ensuring the\nquality of estimation.", "published": "2025-04-15 21:54:15", "link": "http://arxiv.org/abs/2504.11638v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Accelerated Recovery with RIS: Designing Wireless Resilience in Mission-Critical Environments", "abstract": "As 6G and beyond redefine connectivity, wireless networks become the\nfoundation of critical operations, making resilience more essential than ever.\nWith this shift, wireless systems cannot only take on vital services previously\nhandled by wired infrastructures but also enable novel innovative applications\nthat would not be possible with wired systems. As a result, there is a pressing\ndemand for strategies that can adapt to dynamic channel conditions,\ninterference, and unforeseen disruptions, ensuring seamless and reliable\nperformance in an increasingly complex environment. Despite considerable\nresearch, existing resilience assessments lack comprehensive key performance\nindicators (KPIs), especially those quantifying its adaptability, which are\nvital for identifying a system's capacity to rapidly adapt and reallocate\nresources. In this work, we bridge this gap by proposing a novel framework that\nexplicitly quantifies the adaption performance by augmenting the gradient of\nthe system's rate function. To further enhance the network resilience, we\nintegrate Reconfigurable Intelligent Surfaces (RISs) into our framework due to\ntheir capability to dynamically reshape the propagation environment while\nproviding alternative channel paths. Numerical results show that gradient\naugmentation enhances resilience by improving adaptability under adverse\nconditions while proactively preparing for future disruptions.", "published": "2025-04-15 20:09:04", "link": "http://arxiv.org/abs/2504.11589v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Towards a Universal Vibration Analysis Dataset: A Framework for Transfer Learning in Predictive Maintenance and Structural Health Monitoring", "abstract": "ImageNet has become a reputable resource for transfer learning, allowing the\ndevelopment of efficient ML models with reduced training time and data\nrequirements. However, vibration analysis in predictive maintenance, structural\nhealth monitoring, and fault diagnosis, lacks a comparable large-scale,\nannotated dataset to facilitate similar advancements. To address this, a\ndataset framework is proposed that begins with bearing vibration data as an\ninitial step towards creating a universal dataset for vibration-based\nspectrogram analysis for all machinery. The initial framework includes a\ncollection of bearing vibration signals from various publicly available\ndatasets. To demonstrate the advantages of this framework, experiments were\nconducted using a deep learning architecture, showing improvements in model\nperformance when pre-trained on bearing vibration data and fine-tuned on a\nsmaller, domain-specific dataset. These findings highlight the potential to\nparallel the success of ImageNet in visual computing but for vibration\nanalysis. For future work, this research will include a broader range of\nvibration signals from multiple types of machinery, emphasizing\nspectrogram-based representations of the data. Each sample will be labeled\naccording to machinery type, operational status, and the presence or type of\nfaults, ensuring its utility for supervised and unsupervised learning tasks.\nAdditionally, a framework for data preprocessing, feature extraction, and model\ntraining specific to vibration data will be developed. This framework will\nstandardize methodologies across the research community, allowing for\ncollaboration and accelerating progress in predictive maintenance, structural\nhealth monitoring, and related fields. By mirroring the success of ImageNet in\nvisual computing, this dataset has the potential to improve the development of\nintelligent systems in industrial applications.", "published": "2025-04-15 19:57:26", "link": "http://arxiv.org/abs/2504.11581v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Beam Misalignment in 3GPP mmWave NR", "abstract": "This paper presents an analytical framework for evaluating beam misalignment\nin 3GPP mmWave NR systems implementing analog beamforming. Our approach\ncaptures the interaction between user mobility, beam sweeping mechanisms, and\ndeployment configurations, focusing on long-term average performance metrics.\nSpecifically, we model the beam misalignment rates at both the base station\n(BS) and user equipment (UE) as Poisson processes and derive expressions for\nthe expected misalignment duration, misalignment fraction, and overall\nbeamforming gain. The framework accounts for practical constraints in NR such\nas Synchronization Signal Blocks (SSB) periodicity, TDD frame structures, and\nSSB overhead. Through numerical evaluation based on 3GPP mmWave parameters, we\nidentify key trade-offs between beam counts, user mobility, and SSB timing,\nproviding actionable design insights for robust and efficient beam management\nin future high-frequency networks.", "published": "2025-04-15 19:15:26", "link": "http://arxiv.org/abs/2504.11565v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Multi-Orbiter Continuous Lunar Beaming", "abstract": "In this work, free-space optics-based continuous wireless power transmission\nbetween multiple low lunar orbit satellites and a solar panel on the lunar\nrover located at the lunar south pole are investigated based on the\ntime-varying harvested power and overall system efficiency metrics. The\nperformances are compared between a solar panel with the tracking ability and a\nfixed solar panel that induces \\textit{the cosine effect} due to the\ntime-dependent angle of incidence (AoI). In our work, the Systems Tool Kit\n(STK) high-precision orbit propagator, which calculates the ephemeris data\nprecisely, is utilized. Interestingly, orbiter deployments in constellations\nchange significantly during a Moon revolution; thus, short-duration simulations\ncannot be used straightforwardly. In our work, many satellite configurations\nare assessed to be able to find a Cislunar constellation that establishes a\ncontinuous line-of-sight (LoS) between the solar panel and at least a single\nLLO satellite. It is found that 40-satellite schemes enable the establishment\nof a continuous WPT system model. Besides, a satellite selection method (SSM)\nis introduced so that only the best LoS link among multiple simultaneous links\nfrom multiple satellites will be active for optimum efficiency. Our benchmark\nsystem of a 40-satellite quadruple orbit scheme is compared with 30-satellite\nand a single satellite schemes based on the average harvested powers and\noverall system efficiencies 27.3 days so the trade-off options can be assessed\nfrom the multiple Cislunar models. The outcomes show that the average system\nefficiencies of single, 30-satellite, and 40-satellite schemes are 2.84%,\n32.33%, and 33.29%, respectively, for the tracking panel and 0.97%, 18.33%, and\n20.44%, respectively, for the fixed solar panel case.", "published": "2025-04-15 15:43:39", "link": "http://arxiv.org/abs/2504.11300v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Physics-Aware Initialization Refinement in Code-Aided EM for Blind Channel Estimation", "abstract": "This paper addresses the well-known local maximum problem of the\nexpectation-maximization (EM) algorithm in blind intersymbol interference (ISI)\nchannel estimation. This problem primarily results from phase and shift\nambiguity during initialization, which blind estimation is inherently unable to\ndistinguish. We propose an effective initialization refinement algorithm that\nutilizes the decoder output as a model selection metric, incorporating a\ntechnique to detect phase and shift ambiguity. Our results show that the\nproposed algorithm significantly reduces the number of local maximum cases to\nnearly one-third for a 3-tap ISI channel under highly uncertain initial\nconditions. The improvement becomes more pronounced as initial errors increase\nand the channel memory grows. When used in a turbo equalizer, the proposed\nalgorithm is required only in the first turbo iteration, which limits any\ncomplexity increase with subsequent iterations.", "published": "2025-04-15 14:42:47", "link": "http://arxiv.org/abs/2504.11241v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Guided Wave-Based Structural Awareness Under Varying Operating States via Manifold Representations", "abstract": "Guided wave-based structural health monitoring (SHM) remains a powerful\nstrategy for identifying early-stage defects and safeguarding vital aerospace\nstructures. Yet, its practical use is often hindered by the enormous,\nhigh-dimensional data streams produced by sensor arrays operating at megahertz\nsampling rates, coupled with the added complexity of shifts in environmental\nand operational conditions (EOCs). Studies have explored various\ndata-compression approaches that retain critical diagnostic details in a\nlower-dimensional latent space. While conventional techniques can streamline\ndimensionality to some extent, they do not always capture the nonlinear\ninteractions typical of guided waves. Manifold learning, as illustrated by\nDiffusion Maps, tackles these nonlinearities by deriving low-dimensional\nembeddings directly from wave signals, minimizing the need for manual feature\nextraction. In parallel, developments in deep learning -- particularly\nautoencoders -- provide an encoder-decoder model for both data compression and\nreconstruction. Convolutional autoencoders (CAEs) and variational autoencoders\n(VAEs) have been particularly effective for guided wave applications. However,\ncurrent methods can still struggle to maintain accurate state estimation under\nchanging EOCs, and they are often limited to a single task. In response, the\nproposed framework adopts a two-fold strategy: it compresses high-dimensional\nsignals into lower-dimensional representations and then leverages those\nrepresentations to both estimate structural states and reconstruct the original\ndata, even as conditions vary. Applied to two real-world SHM use-cases, this\nintegrated method has proven its ability to preserve and retrieve key damage\nsignatures under noise, shifting operational parameters, and other complicating\nfactors.", "published": "2025-04-15 14:38:30", "link": "http://arxiv.org/abs/2504.11235v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Focal Split: Untethered Snapshot Depth from Differential Defocus", "abstract": "We introduce Focal Split, a handheld, snapshot depth camera with fully\nonboard power and computing based on depth-from-differential-defocus (DfDD).\nFocal Split is passive, avoiding power consumption of light sources. Its\nachromatic optical system simultaneously forms two differentially defocused\nimages of the scene, which can be independently captured using two photosensors\nin a snapshot. The data processing is based on the DfDD theory, which\nefficiently computes a depth and a confidence value for each pixel with only\n500 floating point operations (FLOPs) per pixel from the camera measurements.\nWe demonstrate a Focal Split prototype, which comprises a handheld custom\ncamera system connected to a Raspberry Pi 5 for real-time data processing. The\nsystem consumes 4.9 W and is powered on a 5 V, 10,000 mAh battery. The\nprototype can measure objects with distances from 0.4 m to 1.2 m, outputting\n480$\\times$360 sparse depth maps at 2.1 frames per second (FPS) using\nunoptimized Python scripts. Focal Split is DIY friendly. A comprehensive guide\nto building your own Focal Split depth camera, code, and additional data can be\nfound at https://focal-split.qiguo.org.", "published": "2025-04-15 14:01:36", "link": "http://arxiv.org/abs/2504.11202v1", "categories": ["cs.CV", "eess.IV", "eess.SP", "68U10", "I.4.8"], "primary_category": "cs.CV"}
{"title": "A Fully Asynchronous Unsourced Random Access Scheme", "abstract": "We investigate fully asynchronous unsourced random access (URA), and propose\na high-performing scheme that employs on-off division multiple access (ODMA).\nIn this scheme, active users distribute their data over the transmit block\nbased on a sparse transmission pattern without any limitations on the starting\ntime. At the receiver side, we adopt a double sliding-window decoding approach,\nutilizing a smaller inner decoding window of two block lengths within a larger\nouter window to enhance the interference cancellation process. Within the inner\nwindow, the receiver iteratively applies preamble-free joint starting time and\npattern detection, single-user decoding, and successive interference\ncancellation operations. A notable feature of the proposed scheme is its\nelimination of the need for a preamble for starting time detection; this is\nachieved using ODMA transmission patterns. Numerical results demonstrate that\nthe proposed asynchronous URA scheme outperforms existing alternatives.", "published": "2025-04-15 12:31:24", "link": "http://arxiv.org/abs/2504.11131v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Unified Hardware Accelerator for Fast Fourier Transform and Number Theoretic Transform", "abstract": "The Number Theoretic Transform (NTT) is an indispensable tool for computing\nefficient polynomial multiplications in post-quantum lattice-based\ncryptography. It has strong resemblance with the Fast Fourier Transform (FFT),\nwhich is the most widely used algorithm in digital signal processing. In this\nwork, we demonstrate a unified hardware accelerator supporting both 512-point\ncomplex FFT as well as 256-point NTT for the recently standardized NIST\npost-quantum key encapsulation and digital signature algorithms ML-KEM and\nML-DSA respectively. Our proposed architecture effectively utilizes the\narithmetic circuitry required for complex FFT, and the only additional circuits\nrequired are for modular reduction along with modifications in the control\nlogic. Our implementation achieves performance comparable to state-of-the-art\nML-KEM / ML-DSA NTT accelerators on FPGA, thus demonstrating how an FFT\naccelerator can be augmented to support NTT and the unified hardware can be\nused for both digital signal processing and post-quantum lattice-based\ncryptography applications.", "published": "2025-04-15 12:13:05", "link": "http://arxiv.org/abs/2504.11124v1", "categories": ["cs.CR", "eess.SP"], "primary_category": "cs.CR"}
{"title": "Continuous Aperture Array (CAPA)-Based Secure Wireless Communications", "abstract": "A continuous aperture array (CAPA)-based secure communication system is\ninvestigated, where a base station equipped with a CAPA transmits signals to a\nlegitimate user under the existence of an eavesdropper. For improving the\nsecrecy performance, the artificial noise (AN) is employed at the BS for the\njamming purpose. We aim at maximizing the secrecy rate by jointly optimizing\nthe information-bearing and AN source current patterns, subject to the maximum\ntransmit power constraint. To solve the resultant non-convex integral-based\nfunctional programming problem, a channel subspace-based approach is first\nproposed via exploiting the result that the optimal current patterns always lie\nwithin the subspace spanned by all users' channel responses. Then, the\nintractable CAPA continuous source current pattern design problem with an\ninfinite number of optimization variables is equivalently transformed into the\nchannel-subspace weighting factor optimization problem with a finite number of\noptimization variables. A penalty-based successive convex approximation method\nis developed for iteratively optimizing the finite-size weighting vectors. To\nfurther reduce the computational complexity, we propose a two-stage source\ncurrent patterns design scheme. Specifically, the information-bearing and AN\npatterns are first designed using the maximal ration transmission and\nzero-forcing transmission, respectively. Then, the remaining power allocation\nis addressed via the one-dimensional search method. Numerical results unveil\nthat 1) the CAPA brings in significant secrecy rate gain compared to the\nconventional discrete multiple-input multiple-output; 2) the proposed channel\nsubspace-based algorithm outperforms the conventional Fourier-based approach,\nwhile sustaining much lower computational complexity; and 3) the two-stage\nZF-MRT approach has negligible performance loss for the large transmit power\nregime.", "published": "2025-04-15 12:02:03", "link": "http://arxiv.org/abs/2504.11114v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Signal Matrix-Based Local Flaw Detection Framework for Steel Wire Ropes Using Convolutional Neural Networks", "abstract": "Steel wire ropes (SWRs) are critical load-bearing components in industrial\napplications, yet their structural integrity is often compromised by local\nflaws (LFs). Magnetic Flux Leakage (MFL) is a widely used non-destructive\ntesting method that detects defects by measuring perturbations in magnetic\nfields. Traditional MFL detection methods suffer from critical limitations:\none-dimensional approaches fail to capture spatial relationships across sensor\nchannels, while multi-dimensional image-based techniques introduce\ninterpolation artifacts and computational inefficiencies. This paper proposes a\nnovel detection framework based on signal matrices, directly processing raw\nmulti-channel MFL signals using a specialized Convolutional Neural Network for\nsignal matrix as input (SM-CNN). The architecture incorporates stripe pooling\nto preserve channel-wise features and symmetric padding to improve boundary\ndefect detection. Our model achieves state-of-the-art performance with 98.74%\naccuracy and 97.85% recall. Additionally, it demonstrates exceptional\ncomputational efficiency, processing at 87.72 frames per second (FPS) with a\nlow inference latency of 2.6ms and preprocessing time of 8.8ms. With only 1.48\nmillion parameters, this lightweight design supports real-time processing,\nestablishing a new benchmark for SWR inspection in industrial settings.", "published": "2025-04-15 07:59:04", "link": "http://arxiv.org/abs/2504.10952v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fast-Powerformer: A Memory-Efficient Transformer for Accurate Mid-Term Wind Power Forecasting", "abstract": "Wind power forecasting (WPF), as a significant research topic within\nrenewable energy, plays a crucial role in enhancing the security, stability,\nand economic operation of power grids. However, due to the high stochasticity\nof meteorological factors (e.g., wind speed) and significant fluctuations in\nwind power output, mid-term wind power forecasting faces a dual challenge of\nmaintaining high accuracy and computational efficiency. To address these\nissues, this paper proposes an efficient and lightweight mid-term wind power\nforecasting model, termed Fast-Powerformer. The proposed model is built upon\nthe Reformer architecture, incorporating structural enhancements such as a\nlightweight Long Short-Term Memory (LSTM) embedding module, an input\ntransposition mechanism, and a Frequency Enhanced Channel Attention Mechanism\n(FECAM). These improvements enable the model to strengthen temporal feature\nextraction, optimize dependency modeling across variables, significantly reduce\ncomputational complexity, and enhance sensitivity to periodic patterns and\ndominant frequency components. Experimental results conducted on multiple\nreal-world wind farm datasets demonstrate that the proposed Fast-Powerformer\nachieves superior prediction accuracy and operational efficiency compared to\nmainstream forecasting approaches. Furthermore, the model exhibits fast\ninference speed and low memory consumption, highlighting its considerable\npractical value for real-world deployment scenarios.", "published": "2025-04-15 07:09:54", "link": "http://arxiv.org/abs/2504.10923v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Uplink Assisted Joint Channel Estimation and CSI Feedback: An Approach Based on Deep Joint Source-Channel Coding", "abstract": "In frequency division duplex (FDD) multiple-input multiple-output (MIMO)\nwireless communication systems, the acquisition of downlink channel state\ninformation (CSI) is essential for maximizing spatial resource utilization and\nimproving system spectral efficiency. The separate design of modules in\nAI-based CSI feedback architectures under traditional modular communication\nframeworks, including channel estimation (CE), CSI compression and feedback,\nleads to sub-optimal performance. In this paper, we propose an uplink assisted\njoint CE and and CSI feedback approach via deep learning for downlink CSI\nacquisition, which mitigates performance degradation caused by distribution\nbias across separately trained modules in traditional modular communication\nframeworks. The proposed network adopts a deep joint source-channel coding\n(DJSCC) architecture to mitigate the cliff effect encountered in the\nconventional separate source-channel coding. Furthermore, we exploit the uplink\nCSI as auxiliary information to enhance CSI reconstruction accuracy by\nleveraging the partial reciprocity between the uplink and downlink channels in\nFDD systems, without introducing additional overhead. The effectiveness of\nuplink CSI as assisted information and the necessity of an end-toend\nmulti-module joint training architecture is validated through comprehensive\nablation and scalability experiments.", "published": "2025-04-15 03:29:24", "link": "http://arxiv.org/abs/2504.10836v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "ACSNet: A Deep Neural Network for Compound GNSS Jamming Signal Classification", "abstract": "In the global navigation satellite system (GNSS), identifying not only single\nbut also compound jamming signals is crucial for ensuring reliable navigation\nand positioning, particularly in future wireless communication scenarios such\nas the space-air-ground integrated network (SAGIN). However, conventional\ntechniques often struggle with low recognition accuracy and high computational\ncomplexity, especially under low jamming-to-noise ratio (JNR) conditions. To\novercome the challenge of accurately identifying compound jamming signals\nembedded within GNSS signals, we propose ACSNet, a novel convolutional neural\nnetwork designed specifically for this purpose. Unlike traditional methods that\ntend to exhibit lower accuracy and higher computational demands, particularly\nin low JNR environments, ACSNet addresses these issues by integrating\nasymmetric convolution blocks, which enhance its sensitivity to subtle signal\nvariations. Simulations demonstrate that ACSNet significantly improves accuracy\nin low JNR regions and shows robust resilience to power ratio (PR) variations,\nconfirming its effectiveness and efficiency for practical GNSS interference\nmanagement applications.", "published": "2025-04-15 02:05:30", "link": "http://arxiv.org/abs/2504.10806v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Generative and Explainable AI for High-Dimensional Channel Estimation", "abstract": "In this paper, we propose a new adversarial training framework to address\nhigh-dimensional instantaneous channel estimation in wireless communications.\nSpecifically, we train a generative adversarial network to predict a channel\nrealization in the time-frequency-space domain, in which the generator exploits\nthe third-order moment of the input in its loss function and applies a new\nreparameterization method for latent distribution learning to minimize the\nWasserstein distance between the true and estimated channel distributions.\nNext, we propose an explainable artificial intelligence mechanism to examine\nhow the critic discriminates the generated channel. We demonstrate that our\nproposed framework is superior to existing methods in terms of minimizing\nestimation errors. Additionally, we find that the critic's attention focuses on\nthe high-power portion of the channel's time-frequency representation.", "published": "2025-04-15 00:29:40", "link": "http://arxiv.org/abs/2504.10775v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Evaluation Report on MCP Servers", "abstract": "With the rise of LLMs, a large number of Model Context Protocol (MCP)\nservices have emerged since the end of 2024. However, the effectiveness and\nefficiency of MCP servers have not been well studied. To study these questions,\nwe propose an evaluation framework, called MCPBench. We selected several widely\nused MCP server and conducted an experimental evaluation on their accuracy,\ntime, and token usage. Our experiments showed that the most effective MCP, Bing\nWeb Search, achieved an accuracy of 64%. Importantly, we found that the\naccuracy of MCP servers can be substantially enhanced by involving declarative\ninterface. This research paves the way for further investigations into\noptimized MCP implementations, ultimately leading to better AI-driven\napplications and data retrieval solutions.", "published": "2025-04-15 11:40:12", "link": "http://arxiv.org/abs/2504.11094v2", "categories": ["cs.IR", "cs.DB"], "primary_category": "cs.IR"}
{"title": "X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents", "abstract": "Multi-turn interactions with language models (LMs) pose critical safety\nrisks, as harmful intent can be strategically spread across exchanges. Yet, the\nvast majority of prior work has focused on single-turn safety, while\nadaptability and diversity remain among the key challenges of multi-turn\nred-teaming. To address these challenges, we present X-Teaming, a scalable\nframework that systematically explores how seemingly harmless interactions\nescalate into harmful outcomes and generates corresponding attack scenarios.\nX-Teaming employs collaborative agents for planning, attack optimization, and\nverification, achieving state-of-the-art multi-turn jailbreak effectiveness and\ndiversity with success rates up to 98.1% across representative leading\nopen-weight and closed-source models. In particular, X-Teaming achieves a 96.2%\nattack success rate against the latest Claude 3.7 Sonnet model, which has been\nconsidered nearly immune to single-turn attacks. Building on X-Teaming, we\nintroduce XGuard-Train, an open-source multi-turn safety training dataset that\nis 20x larger than the previous best resource, comprising 30K interactive\njailbreaks, designed to enable robust multi-turn safety alignment for LMs. Our\nwork offers essential tools and insights for mitigating sophisticated\nconversational attacks, advancing the multi-turn safety of LMs.", "published": "2025-04-15 16:11:28", "link": "http://arxiv.org/abs/2504.13203v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG", "cs.MA"], "primary_category": "cs.CR"}
{"title": "Concept Enhancement Engineering: A Lightweight and Efficient Robust Defense Against Jailbreak Attacks in Embodied AI", "abstract": "Embodied Intelligence (EI) systems integrated with large language models\n(LLMs) face significant security risks, particularly from jailbreak attacks\nthat manipulate models into generating harmful outputs or executing unsafe\nphysical actions. Traditional defense strategies, such as input filtering and\noutput monitoring, often introduce high computational overhead or interfere\nwith task performance in real-time embodied scenarios. To address these\nchallenges, we propose Concept Enhancement Engineering (CEE), a novel defense\nframework that leverages representation engineering to enhance the safety of\nembodied LLMs by dynamically steering their internal activations. CEE operates\nby (1) extracting multilingual safety patterns from model activations, (2)\nconstructing control directions based on safety-aligned concept subspaces, and\n(3) applying subspace concept rotation to reinforce safe behavior during\ninference. Our experiments demonstrate that CEE effectively mitigates jailbreak\nattacks while maintaining task performance, outperforming existing defense\nmethods in both robustness and efficiency. This work contributes a scalable and\ninterpretable safety mechanism for embodied AI, bridging the gap between\ntheoretical representation engineering and practical security applications. Our\nfindings highlight the potential of latent-space interventions as a viable\ndefense paradigm against emerging adversarial threats in physically grounded AI\nsystems.", "published": "2025-04-15 03:50:04", "link": "http://arxiv.org/abs/2504.13201v1", "categories": ["cs.CR", "cs.LG", "cs.MA"], "primary_category": "cs.CR"}
{"title": "A Mathematical Framework of Semantic Communication based on Category Theory", "abstract": "While semantic communication (SemCom) has recently demonstrated great\npotential to enhance transmission efficiency and reliability by leveraging\nmachine learning (ML) and knowledge base (KB), there is a lack of mathematical\nmodeling to rigorously characterize SemCom system and quantify the performance\ngain obtained from ML and KB. In this paper, we develop a mathematical\nframework for SemCom based on category theory, rigorously modeling the concepts\nof semantic entities and semantic probability space. Within this framework, we\nintroduce the semantic entropy to quantify the uncertainty of semantic\nentities. We theoretically prove that semantic entropy can be effectively\nreduced by exploiting KBs, which capture semantic dependencies. Within the\nformulated semantic space, semantic entities can be combined according to the\nrequired semantic ambiguity, and the combined entities can be encoded based on\nsemantic dependencies obtained from KB. Then, we derive semantic channel\ncapacity modeling, which incorporates the mutual information obtained in KB to\naccurately measure the transmission efficiency of SemCom. Numerical simulations\nvalidate the effectiveness of the proposed framework, showing that SemCom with\nKB integration outperforms traditional communication in both entropy reduction\nand coding efficiency.", "published": "2025-04-15 16:07:33", "link": "http://arxiv.org/abs/2504.11334v2", "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "cs.NI"}
{"title": "Interpretable Hybrid-Rule Temporal Point Processes", "abstract": "Temporal Point Processes (TPPs) are widely used for modeling event sequences\nin various medical domains, such as disease onset prediction, progression\nanalysis, and clinical decision support. Although TPPs effectively capture\ntemporal dynamics, their lack of interpretability remains a critical challenge.\nRecent advancements have introduced interpretable TPPs. However, these methods\nfail to incorporate numerical features, thereby limiting their ability to\ngenerate precise predictions. To address this issue, we propose Hybrid-Rule\nTemporal Point Processes (HRTPP), a novel framework that integrates temporal\nlogic rules with numerical features, improving both interpretability and\npredictive accuracy in event modeling. HRTPP comprises three key components:\nbasic intensity for intrinsic event likelihood, rule-based intensity for\nstructured temporal dependencies, and numerical feature intensity for dynamic\nprobability modulation. To effectively discover valid rules, we introduce a\ntwo-phase rule mining strategy with Bayesian optimization. To evaluate our\nmethod, we establish a multi-criteria assessment framework, incorporating rule\nvalidity, model fitting, and temporal predictive accuracy. Experimental results\non real-world medical datasets demonstrate that HRTPP outperforms\nstate-of-the-art interpretable TPPs in terms of predictive performance and\nclinical interpretability. In case studies, the rules extracted by HRTPP\nexplain the disease progression, offering valuable contributions to medical\ndiagnosis.", "published": "2025-04-15 16:15:16", "link": "http://arxiv.org/abs/2504.11344v2", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI Agent Ecosystems", "abstract": "The rise of autonomous AI agents, capable of perceiving, reasoning, and\nacting independently, signals a profound shift in how digital ecosystems\noperate, govern, and evolve. As these agents proliferate beyond centralized\ninfrastructures, they expose foundational gaps in identity, accountability, and\nethical alignment. Three critical questions emerge: Identity: Who or what is\nthe agent? Accountability: Can its actions be verified, audited, and trusted?\nEthical Consensus: Can autonomous systems reliably align with human values and\nprevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered\nOrchestration for Knowledgeful Agents), a unified, systems-level architecture\nfor building ethically governed, interoperable AI agent ecosystems. LOKA\nintroduces a proposed Universal Agent Identity Layer (UAIL) for decentralized,\nverifiable identity; intent-centric communication protocols for semantic\ncoordination across diverse agents; and a Decentralized Ethical Consensus\nProtocol (DECP) that could enable agents to make context-aware decisions\ngrounded in shared ethical baselines. Anchored in emerging standards such as\nDecentralized Identifiers (DIDs), Verifiable Credentials (VCs), and\npost-quantum cryptography, LOKA proposes a scalable, future-resilient blueprint\nfor multi-agent AI governance. By embedding identity, trust, and ethics into\nthe protocol layer itself, LOKA proposes the foundation for a new era of\nresponsible, transparent, and autonomous AI ecosystems operating across digital\nand physical domains.", "published": "2025-04-15 06:51:35", "link": "http://arxiv.org/abs/2504.10915v2", "categories": ["cs.MA", "cs.AI", "cs.CY"], "primary_category": "cs.MA"}
{"title": "Breaking the Dimensional Barrier: A Pontryagin-Guided Direct Policy Optimization for Continuous-Time Multi-Asset Portfolio", "abstract": "Solving large-scale, continuous-time portfolio optimization problems\ninvolving numerous assets and state-dependent dynamics has long been challenged\nby the curse of dimensionality. Traditional dynamic programming and PDE-based\nmethods, while rigorous, typically become computationally intractable beyond\nfew state variables (3~6 limit in prior studies). To overcome this critical\nbarrier, we introduce the Pontryagin-Guided Direct Policy Optimization (PG-DPO)\nframework. PG-DPO leverages Pontryagin's Maximum Principle (PMP) and\nbackpropagation-through-time (BPTT) to guide neural network policies, handling\nexogenous states without dense grids. This PMP-guided approach holds potential\nfor a broad class of sufficiently regular continuous-time control problems.\nCrucially, our computationally efficient \"Two-Stage\" variant exploits rapidly\nstabilizing BPTT costate estimates, converting them into near-optimal\nPontryagin controls after only a short warm-up, significantly reducing training\noverhead. This enables a breakthrough in scalability: numerical experiments\nshow PG-DPO successfully tackles problems with dimensions previously considered\nfar out of reach (up to 50 assets and 10 state variables). The framework\ndelivers near-optimal policies, offering a practical and powerful alternative\nfor high-dimensional continuous-time portfolio choice.", "published": "2025-04-15 12:03:14", "link": "http://arxiv.org/abs/2504.11116v2", "categories": ["q-fin.PM", "q-fin.CP"], "primary_category": "q-fin.PM"}
{"title": "Determining Implication of Fixed Matrix Prenex Normal Forms Can Be Decided in Linear Time", "abstract": "For a fixed arbitrary matrix depending on $n$ variables, one may ask whether\na Prenex Normal Form (PNF) implies another. A RAM algorithm running in linear\ntime is presented and shown to be asymptotically optimal.", "published": "2025-04-15 00:47:57", "link": "http://arxiv.org/abs/2504.15294v1", "categories": ["cs.DS", "cs.DM"], "primary_category": "cs.DS"}
{"title": "High order treatment of moving curved boundaries: Arbitrary-Lagrangian-Eulerian methods with a shifted boundary polynomials correction", "abstract": "In this paper we present a novel approach for the prescription of high order\nboundary conditions when approximating the solution of the Euler equations for\ncompressible gas dynamics on curved moving domains. When dealing with curved\nboundaries, the consistency of boundary conditions is a real challenge, and it\nbecomes even more challenging in the context of moving domains discretized with\nhigh order Arbitrary-Lagrangian-Eulerian (ALE) schemes. The ALE formulation is\nparticularly well-suited for handling moving and deforming domains, thus\nallowing for the simulation of complex fluid-structure interaction problems.\nHowever, if not properly treated, the imposition of boundary conditions can\nlead to significant errors in the numerical solution, which can spoil the high\norder discretization of the underlying mathematical model. In order to tackle\nthis issue, we propose a new method based on the recently developed shifted\nboundary polynomial correction, which was originally proposed on fixed meshes.\nThe new method is integrated into the space-time corrector step of a direct ALE\nfinite volume method to account for the local curvature of the moving boundary\nby only exploiting the high order reconstruction polynomial of the finite\nvolume control volume. It relies on a correction based on the extrapolated\nvalue of the cell polynomial evaluated at the true geometry, thus not requiring\nthe explicit evaluation of high order Taylor series. This greatly simplifies\nthe treatment of moving curved boundaries, as it allows for the use of standard\nsimplicial meshes, which are much easier to generate and move than curvilinear\nones, especially for 3D time-dependent problems. Several numerical experiments\nare presented demonstrating the high order convergence properties of the new\nmethod in the context of compressible flows in moving curved domains, which\nremain approximated by piecewise linear elements.", "published": "2025-04-15 07:45:57", "link": "http://arxiv.org/abs/2504.15963v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
