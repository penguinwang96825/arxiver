{"title": "TextArena", "abstract": "TextArena is an open-source collection of competitive text-based games for\ntraining and evaluation of agentic behavior in Large Language Models (LLMs). It\nspans 57+ unique environments (including single-player, two-player, and\nmulti-player setups) and allows for easy evaluation of model capabilities via\nan online-play system (against humans and other submitted models) with\nreal-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social\nskills such as negotiation, theory of mind, and deception, creating a gap that\nTextArena addresses. Designed with research, community and extensibility in\nmind, TextArena emphasizes ease of adding new games, adapting the framework,\ntesting models, playing against the models, and training models. Detailed\ndocumentation of environments, games, leaderboard, and examples are available\non https://github.com/LeonGuertler/TextArena and https://www.textarena.ai/.", "published": "2025-04-15 17:55:20", "link": "http://arxiv.org/abs/2504.11442v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Reimagining Urban Science: Scaling Causal Inference with Large Language Models", "abstract": "Urban causal research is essential for understanding the complex dynamics of\ncities and informing evidence-based policies. However, it is challenged by the\ninefficiency and bias of hypothesis generation, barriers to multimodal data\ncomplexity, and the methodological fragility of causal experimentation. Recent\nadvances in large language models (LLMs) present an opportunity to rethink how\nurban causal analysis is conducted. This Perspective examines current urban\ncausal research by analyzing taxonomies that categorize research topics, data\nsources, and methodological approaches to identify structural gaps. We then\nintroduce an LLM-driven conceptual framework, AutoUrbanCI, composed of four\ndistinct modular agents responsible for hypothesis generation, data\nengineering, experiment design and execution, and results interpretation with\npolicy recommendations. We propose evaluation criteria for rigor and\ntransparency and reflect on implications for human-AI collaboration, equity,\nand accountability. We call for a new research agenda that embraces\nAI-augmented workflows not as replacements for human expertise but as tools to\nbroaden participation, improve reproducibility, and unlock more inclusive forms\nof urban causal reasoning.", "published": "2025-04-15 16:58:11", "link": "http://arxiv.org/abs/2504.12345v1", "categories": ["cs.CL", "cs.CY", "cs.MA"], "primary_category": "cs.CL"}
{"title": "A Multi-UAV Formation Obstacle Avoidance Method Combined Improved Simulated Annealing and Adaptive Artificial Potential Field", "abstract": "The traditional Artificial Potential Field (APF) method exhibits limitations\nin its force distribution: excessive attraction when UAVs are far from the\ntarget may cause collisions with obstacles, while insufficient attraction near\nthe goal often results in failure to reach the target. Furthermore, APF is\nhighly susceptible to local minima, compromising motion reliability in complex\nenvironments. To address these challenges, this paper presents a novel hybrid\nobstacle avoidance algorithm-Deflected Simulated Annealing-Adaptive Artificial\nPotential Field (DSA-AAPF)-which combines an improved simulated annealing\nmechanism with an enhanced APF model. The proposed approach integrates a\nLeader-Follower distributed formation strategy with the APF framework, where\nthe resultant force formulation is redefined to smooth UAV trajectories. An\nadaptive gravitational gain function is introduced to dynamically adjust UAV\nvelocity based on environmental context, and a fast-converging controller\nensures accurate and efficient convergence to the target. Moreover, a\ndirectional deflection mechanism is embedded within the simulated annealing\nprocess, enabling UAVs to escape local minima caused by semi-enclosed obstacles\nthrough continuous rotational motion. The simulation results, covering\nformation reconfiguration, complex obstacle avoidance, and entrapment escape,\ndemonstrate the feasibility, robustness, and superiority of the proposed\nDSA-AAPF algorithm.", "published": "2025-04-15 10:53:51", "link": "http://arxiv.org/abs/2504.11064v1", "categories": ["cs.MA", "cs.RO", "cs.SY", "eess.SY"], "primary_category": "cs.MA"}
{"title": "LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI Agent Ecosystems", "abstract": "The rise of autonomous AI agents, capable of perceiving, reasoning, and\nacting independently, signals a profound shift in how digital ecosystems\noperate, govern, and evolve. As these agents proliferate beyond centralized\ninfrastructures, they expose foundational gaps in identity, accountability, and\nethical alignment. Three critical questions emerge: Identity: Who or what is\nthe agent? Accountability: Can its actions be verified, audited, and trusted?\nEthical Consensus: Can autonomous systems reliably align with human values and\nprevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered\nOrchestration for Knowledgeful Agents), a unified, systems-level architecture\nfor building ethically governed, interoperable AI agent ecosystems. LOKA\nintroduces a proposed Universal Agent Identity Layer (UAIL) for decentralized,\nverifiable identity; intent-centric communication protocols for semantic\ncoordination across diverse agents; and a Decentralized Ethical Consensus\nProtocol (DECP) that enables agents to make context-aware decisions grounded in\nshared ethical baselines. Anchored in emerging standards such as Decentralized\nIdentifiers (DIDs), Verifiable Credentials (VCs), and post-quantum\ncryptography, LOKA offers a scalable, future-resilient blueprint for\nmulti-agent AI governance. By embedding identity, trust, and ethics into the\nprotocol layer itself, LOKA establishes the foundation for a new era of\nresponsible, transparent, and autonomous AI ecosystems operating across digital\nand physical domains.", "published": "2025-04-15 06:51:35", "link": "http://arxiv.org/abs/2504.10915v1", "categories": ["cs.MA", "cs.AI", "cs.CY"], "primary_category": "cs.MA"}
{"title": "Effective dimensionality reduction for Greeks computation using Randomized QMC", "abstract": "Global sensitivity analysis is employed to evaluate the effective dimension\nreduction achieved through Chebyshev interpolation and the conditional pathwise\nmethod for Greek estimation of discretely monitored barrier options and\narithmetic average Asian options. We compare results from finite difference and\nMonte Carlo methods with those obtained by using randomized Quasi Monte Carlo\ncombined with Brownian bridge discretization. Additionally, we investigate the\nbenefits of incorporating importance sampling with either the finite difference\nor Chebyshev interpolation methods. Our findings demonstrate that the reduced\neffective dimensionality identified through global sensitivity analysis\nexplains the performance advantages of one approach over another. Specifically,\nthe increased smoothness provided by Chebyshev or conditional pathwise methods\nenhances the convergence rate of randomized Quasi Monte Carlo integration,\nleading to the significant increase of accuracy and reduced computational\ncosts.", "published": "2025-04-15 19:51:07", "link": "http://arxiv.org/abs/2504.11576v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Breaking the Dimensional Barrier: A Pontryagin-Guided Direct Policy Optimization for Continuous-Time Multi-Asset Portfolio", "abstract": "Solving large-scale, continuous-time portfolio optimization problems\ninvolving numerous assets and state-dependent dynamics has long been challenged\nby the curse of dimensionality. Traditional dynamic programming and PDE-based\nmethods, while rigorous, typically become computationally intractable beyond a\nsmall number of state variables (often limited to ~3-6 in prior numerical\nstudies). To overcome this critical barrier, we introduce the\n\\emph{Pontryagin-Guided Direct Policy Optimization} (PG-DPO) framework. PG-DPO\nleverages Pontryagin's Maximum Principle to directly guide neural network\npolicies via backpropagation-through-time, naturally incorporating exogenous\nstate processes without requiring dense state grids. Crucially, our\ncomputationally efficient ``Two-Stage'' variant exploits rapidly stabilizing\ncostate estimates derived from BPTT, converting them into near-optimal\nclosed-form Pontryagin controls after only a short warm-up, significantly\nreducing training overhead. This enables a breakthrough in scalability:\nnumerical experiments demonstrate that PG-DPO successfully tackles problems\nwith dimensions previously considered far out of reach, optimizing portfolios\nwith up to 50 assets and 10 state variables. The framework delivers\nnear-optimal policies, offering a practical and powerful alternative for\nhigh-dimensional continuous-time portfolio choice.", "published": "2025-04-15 12:03:14", "link": "http://arxiv.org/abs/2504.11116v1", "categories": ["q-fin.PM", "q-fin.CP"], "primary_category": "q-fin.PM"}
{"title": "Can Large Language Models Trade? Testing Financial Theories with LLM Agents in Market Simulations", "abstract": "This paper presents a realistic simulated stock market where large language\nmodels (LLMs) act as heterogeneous competing trading agents. The open-source\nframework incorporates a persistent order book with market and limit orders,\npartial fills, dividends, and equilibrium clearing alongside agents with varied\nstrategies, information sets, and endowments. Agents submit standardized\ndecisions using structured outputs and function calls while expressing their\nreasoning in natural language. Three findings emerge: First, LLMs demonstrate\nconsistent strategy adherence and can function as value investors, momentum\ntraders, or market makers per their instructions. Second, market dynamics\nexhibit features of real financial markets, including price discovery, bubbles,\nunderreaction, and strategic liquidity provision. Third, the framework enables\nanalysis of LLMs' responses to varying market conditions, similar to partial\ndependence plots in machine-learning interpretability. The framework allows\nsimulating financial theories without closed-form solutions, creating\nexperimental designs that would be costly with human participants, and\nestablishing how prompts can generate correlated behaviors affecting market\nstability.", "published": "2025-04-15 01:18:36", "link": "http://arxiv.org/abs/2504.10789v1", "categories": ["q-fin.CP", "econ.GN", "q-fin.EC", "q-fin.GN", "q-fin.TR"], "primary_category": "q-fin.CP"}
{"title": "Multi-Agent Reinforcement Learning for Greenhouse Gas Offset Credit Markets", "abstract": "Climate change is a major threat to the future of humanity, and its impacts\nare being intensified by excess man-made greenhouse gas emissions. One method\ngovernments can employ to control these emissions is to provide firms with\nemission limits and penalize any excess emissions above the limit. Excess\nemissions may also be offset by firms who choose to invest in carbon reducing\nand capturing projects. These projects generate offset credits which can be\nsubmitted to a regulating agency to offset a firm's excess emissions, or they\ncan be traded with other firms. In this work, we characterize the finite-agent\nNash equilibrium for offset credit markets. As computing Nash equilibria is an\nNP-hard problem, we utilize the modern reinforcement learning technique\nNash-DQN to efficiently estimate the market's Nash equilibria. We demonstrate\nnot only the validity of employing reinforcement learning methods applied to\nclimate themed financial markets, but also the significant financial savings\nemitting firms may achieve when abiding by the Nash equilibria through\nnumerical experiments.", "published": "2025-04-15 14:56:42", "link": "http://arxiv.org/abs/2504.11258v1", "categories": ["q-fin.MF", "cs.LG"], "primary_category": "q-fin.MF"}
