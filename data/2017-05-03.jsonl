{"title": "A Hybrid Architecture for Multi-Party Conversational Systems", "abstract": "Multi-party Conversational Systems are systems with natural language\ninteraction between one or more people or systems. From the moment that an\nutterance is sent to a group, to the moment that it is replied in the group by\na member, several activities must be done by the system: utterance\nunderstanding, information search, reasoning, among others. In this paper we\npresent the challenges of designing and building multi-party conversational\nsystems, the state of the art, our proposed hybrid architecture using both\nrules and machine learning and some insights after implementing and evaluating\none on the finance domain.", "published": "2017-05-03 01:05:14", "link": "http://arxiv.org/abs/1705.01214v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the effectiveness of feature set augmentation using clusters of word\n  embeddings", "abstract": "Word clusters have been empirically shown to offer important performance\nimprovements on various tasks. Despite their importance, their incorporation in\nthe standard pipeline of feature engineering relies more on a trial-and-error\nprocedure where one evaluates several hyper-parameters, like the number of\nclusters to be used. In order to better understand the role of such features we\nsystematically evaluate their effect on four tasks, those of named entity\nsegmentation and classification as well as, those of five-point sentiment\nclassification and quantification. Our results strongly suggest that cluster\nmembership features improve the performance.", "published": "2017-05-03 06:33:37", "link": "http://arxiv.org/abs/1705.01265v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chunk-Based Bi-Scale Decoder for Neural Machine Translation", "abstract": "In typical neural machine translation~(NMT), the decoder generates a sentence\nword by word, packing all linguistic granularities in the same time-scale of\nRNN. In this paper, we propose a new type of decoder for NMT, which splits the\ndecode state into two parts and updates them in two different time-scales.\nSpecifically, we first predict a chunk time-scale state for phrasal modeling,\non top of which multiple word time-scale states are generated. In this way, the\ntarget sentence is translated hierarchically from chunks to words, with\ninformation in different granularities being leveraged. Experiments show that\nour proposed model significantly improves the translation performance over the\nstate-of-the-art NMT model.", "published": "2017-05-03 14:39:56", "link": "http://arxiv.org/abs/1705.01452v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Forgettable-Watcher Model for Video Question Answering", "abstract": "A number of visual question answering approaches have been proposed recently,\naiming at understanding the visual scenes by answering the natural language\nquestions. While the image question answering has drawn significant attention,\nvideo question answering is largely unexplored.\n  Video-QA is different from Image-QA since the information and the events are\nscattered among multiple frames. In order to better utilize the temporal\nstructure of the videos and the phrasal structures of the answers, we propose\ntwo mechanisms: the re-watching and the re-reading mechanisms and combine them\ninto the forgettable-watcher model. Then we propose a TGIF-QA dataset for video\nquestion answering with the help of automatic question generation. Finally, we\nevaluate the models on our dataset. The experimental results show the\neffectiveness of our proposed models.", "published": "2017-05-03 04:46:33", "link": "http://arxiv.org/abs/1705.01253v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Amobee at SemEval-2017 Task 4: Deep Learning System for Sentiment\n  Detection on Twitter", "abstract": "This paper describes the Amobee sentiment analysis system, adapted to compete\nin SemEval 2017 task 4. The system consists of two parts: a supervised training\nof RNN models based on a Twitter sentiment treebank, and the use of feedforward\nNN, Naive Bayes and logistic regression classifiers to produce predictions for\nthe different sub-tasks. The algorithm reached the 3rd place on the 5-label\nclassification task (sub-task C).", "published": "2017-05-03 08:50:56", "link": "http://arxiv.org/abs/1705.01306v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Going Wider: Recurrent Neural Network With Parallel Cells", "abstract": "Recurrent Neural Network (RNN) has been widely applied for sequence modeling.\nIn RNN, the hidden states at current step are full connected to those at\nprevious step, thus the influence from less related features at previous step\nmay potentially decrease model's learning ability. We propose a simple\ntechnique called parallel cells (PCs) to enhance the learning ability of\nRecurrent Neural Network (RNN). In each layer, we run multiple small RNN cells\nrather than one single large cell. In this paper, we evaluate PCs on 2 tasks.\nOn language modeling task on PTB (Penn Tree Bank), our model outperforms state\nof art models by decreasing perplexity from 78.6 to 75.3. On Chinese-English\ntranslation task, our model increases BLEU score for 0.39 points than baseline\nmodel.", "published": "2017-05-03 10:22:22", "link": "http://arxiv.org/abs/1705.01346v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "FOIL it! Find One mismatch between Image and Language caption", "abstract": "In this paper, we aim to understand whether current language and vision\n(LaVi) models truly grasp the interaction between the two modalities. To this\nend, we propose an extension of the MSCOCO dataset, FOIL-COCO, which associates\nimages with both correct and \"foil\" captions, that is, descriptions of the\nimage that are highly similar to the original ones, but contain one single\nmistake (\"foil word\"). We show that current LaVi models fall into the traps of\nthis data and perform badly on three tasks: a) caption classification (correct\nvs. foil); b) foil word detection; c) foil word correction. Humans, in\ncontrast, have near-perfect performance on those tasks. We demonstrate that\nmerely utilising language cues is not enough to model FOIL-COCO and that it\nchallenges the state-of-the-art by requiring a fine-grained understanding of\nthe relation between text and image.", "published": "2017-05-03 11:07:13", "link": "http://arxiv.org/abs/1705.01359v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
