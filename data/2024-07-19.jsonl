{"title": "Reexamining Racial Disparities in Automatic Speech Recognition\n  Performance: The Role of Confounding by Provenance", "abstract": "Automatic speech recognition (ASR) models trained on large amounts of audio\ndata are now widely used to convert speech to written text in a variety of\napplications from video captioning to automated assistants used in healthcare\nand other domains. As such, it is important that ASR models and their use is\nfair and equitable. Prior work examining the performance of commercial ASR\nsystems on the Corpus of Regional African American Language (CORAAL)\ndemonstrated significantly worse ASR performance on African American English\n(AAE). The current study seeks to understand the factors underlying this\ndisparity by examining the performance of the current state-of-the-art neural\nnetwork based ASR system (Whisper, OpenAI) on the CORAAL dataset. Two key\nfindings have been identified as a result of the current study. The first\nconfirms prior findings of significant dialectal variation even across\nneighboring communities, and worse ASR performance on AAE that can be improved\nto some extent with fine-tuning of ASR models. The second is a novel finding\nnot discussed in prior work on CORAAL: differences in audio recording practices\nwithin the dataset have a significant impact on ASR accuracy resulting in a\n``confounding by provenance'' effect in which both language use and recording\nquality differ by study location. These findings highlight the need for further\nsystematic investigation to disentangle the effects of recording quality and\ninherent linguistic diversity when examining the fairness and bias present in\nneural ASR models, as any bias in ASR accuracy may have negative downstream\neffects on disparities in various domains of life in which ASR technology is\nused.", "published": "2024-07-19 02:14:17", "link": "http://arxiv.org/abs/2407.13982v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NeLLCom-X: A Comprehensive Neural-Agent Framework to Simulate Language\n  Learning and Group Communication", "abstract": "Recent advances in computational linguistics include simulating the emergence\nof human-like languages with interacting neural network agents, starting from\nsets of random symbols. The recently introduced NeLLCom framework (Lian et al.,\n2023) allows agents to first learn an artificial language and then use it to\ncommunicate, with the aim of studying the emergence of specific linguistics\nproperties. We extend this framework (NeLLCom-X) by introducing more realistic\nrole-alternating agents and group communication in order to investigate the\ninterplay between language learnability, communication pressures, and group\nsize effects. We validate NeLLCom-X by replicating key findings from prior\nresearch simulating the emergence of a word-order/case-marking trade-off. Next,\nwe investigate how interaction affects linguistic convergence and emergence of\nthe trade-off. The novel framework facilitates future simulations of diverse\nlinguistic aspects, emphasizing the importance of interaction and group\ndynamics in language evolution.", "published": "2024-07-19 03:03:21", "link": "http://arxiv.org/abs/2407.13999v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompted Aspect Key Point Analysis for Quantitative Review Summarization", "abstract": "Key Point Analysis (KPA) aims for quantitative summarization that provides\nkey points (KPs) as succinct textual summaries and quantities measuring their\nprevalence. KPA studies for arguments and reviews have been reported in the\nliterature. A majority of KPA studies for reviews adopt supervised learning to\nextract short sentences as KPs before matching KPs to review comments for\nquantification of KP prevalence. Recent abstractive approaches still generate\nKPs based on sentences, often leading to KPs with overlapping and hallucinated\nopinions, and inaccurate quantification. In this paper, we propose Prompted\nAspect Key Point Analysis (PAKPA) for quantitative review summarization. PAKPA\nemploys aspect sentiment analysis and prompted in-context learning with Large\nLanguage Models (LLMs) to generate and quantify KPs grounded in aspects for\nbusiness entities, which achieves faithful KPs with accurate quantification,\nand removes the need for large amounts of annotated data for supervised\ntraining. Experiments on the popular review dataset Yelp and the\naspect-oriented review summarization dataset SPACE show that our framework\nachieves state-of-the-art performance. Source code and data are available at:\nhttps://github.com/antangrocket1312/PAKPA", "published": "2024-07-19 06:07:32", "link": "http://arxiv.org/abs/2407.14049v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Improved Method for Class-specific Keyword Extraction: A Case Study\n  in the German Business Registry", "abstract": "The task of $\\textit{keyword extraction}$ is often an important initial step\nin unsupervised information extraction, forming the basis for tasks such as\ntopic modeling or document classification. While recent methods have proven to\nbe quite effective in the extraction of keywords, the identification of\n$\\textit{class-specific}$ keywords, or only those pertaining to a predefined\nclass, remains challenging. In this work, we propose an improved method for\nclass-specific keyword extraction, which builds upon the popular\n$\\textbf{KeyBERT}$ library to identify only keywords related to a class\ndescribed by $\\textit{seed keywords}$. We test this method using a dataset of\nGerman business registry entries, where the goal is to classify each business\naccording to an economic sector. Our results reveal that our method greatly\nimproves upon previous approaches, setting a new standard for\n$\\textit{class-specific}$ keyword extraction.", "published": "2024-07-19 07:42:48", "link": "http://arxiv.org/abs/2407.14085v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Impact of Model Size on Fine-tuned LLM Performance in Data-to-Text\n  Generation: A State-of-the-Art Investigation", "abstract": "Data-to-text (D2T) generation aims to generate human-readable text from\nsemi-structured data, such as tables and graphs. The recent success of D2T is\nlargely attributed to advancements in LLMs. Despite the success of LLMs, no\nresearch has been conducted to illustrate the impact of model size on the\nperformance of fine-tuned LLMs for D2T tasks. D2T model performance is\ntypically assessed based on three key qualities: \\textit{readability}\n(indicates fluency and coherence), \\textit{informativeness} (measures content\nsimilarity), and \\textit{faithfulness} (assesses consistency of factual\ninformation). It is currently uncertain whether increasing the size of LLMs\neffectively improves performance in D2T tasks across these three qualities. The\nobjective of this study is to investigate the performance of fine-tuned LLMs in\nD2T tasks in terms of model size. Through extensive comparative analysis, we\naim to elucidate both the advantages and limitations of scaling model sizes\nacross five widely used D2T datasets (E2E, ViGGo, WikiTableText, DART, and\nWebNLG) and twelve state-of-the-art LLMs with varying sizes from five different\nLLM families (T5, BART, OPT, BLOOM, and Llama 2). To comprehensively cover all\nthe three essential qualities of D2T models, we incorporate six widely\nrecognized automatic metrics -- \\textsc{BLEU}, \\textsc{METEOR},\n\\textsc{BERTScore}, \\textsc{MoverScore}, \\textsc{Parent}, and\n\\textsc{BARTScore}. We also provide an in-depth analysis of LLM performance\nconcerning model size in the presence of source-reference divergence, a\ncritical aspect of D2T tasks. Our investigation reveals that increasing LLM\nsize enhances \\textit{readability} and \\textit{informativeness} in D2T tasks,\nbut larger (in terms of size) LLMs may sacrifice \\textit{faithfulness}.\nMoreover, small-sized LLMs show more resilience than larger ones when\nsource-reference divergence is present.", "published": "2024-07-19 07:54:30", "link": "http://arxiv.org/abs/2407.14088v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "I Know About \"Up\"! Enhancing Spatial Reasoning in Visual Language Models\n  Through 3D Reconstruction", "abstract": "Visual Language Models (VLMs) are essential for various tasks, particularly\nvisual reasoning tasks, due to their robust multi-modal information\nintegration, visual reasoning capabilities, and contextual awareness. However,\nexisting \\VLMs{}' visual spatial reasoning capabilities are often inadequate,\nstruggling even with basic tasks such as distinguishing left from right. To\naddress this, we propose the \\ours{} model, designed to enhance the visual\nspatial reasoning abilities of VLMS. ZeroVLM employs Zero-1-to-3, a 3D\nreconstruction model for obtaining different views of the input images and\nincorporates a prompting mechanism to further improve visual spatial reasoning.\nExperimental results on four visual spatial reasoning datasets show that our\n\\ours{} achieves up to 19.48% accuracy improvement, which indicates the\neffectiveness of the 3D reconstruction and prompting mechanisms of our ZeroVLM.", "published": "2024-07-19 09:03:30", "link": "http://arxiv.org/abs/2407.14133v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unipa-GPT: Large Language Models for university-oriented QA in Italian", "abstract": "This paper illustrates the architecture and training of Unipa-GPT, a chatbot\nrelying on a Large Language Model, developed for assisting students in choosing\na bachelor/master degree course at the University of Palermo. Unipa-GPT relies\non gpt-3.5-turbo, it was presented in the context of the European Researchers'\nNight (SHARPER night). In our experiments we adopted both the Retrieval\nAugmented Generation (RAG) approach and fine-tuning to develop the system. The\nwhole architecture of Unipa-GPT is presented, both the RAG and the fine-tuned\nsystems are compared, and a brief discussion on their performance is reported.\nFurther comparison with other Large Language Models and the experimental\nresults during the SHARPER night are illustrated.", "published": "2024-07-19 12:28:22", "link": "http://arxiv.org/abs/2407.14246v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the Reliability of Self-Explanations in Large Language Models", "abstract": "This paper investigates the reliability of explanations generated by large\nlanguage models (LLMs) when prompted to explain their previous output. We\nevaluate two kinds of such self-explanations - extractive and counterfactual -\nusing three state-of-the-art LLMs (2B to 8B parameters) on two different\nclassification tasks (objective and subjective). Our findings reveal, that,\nwhile these self-explanations can correlate with human judgement, they do not\nfully and accurately follow the model's decision process, indicating a gap\nbetween perceived and actual model reasoning. We show that this gap can be\nbridged because prompting LLMs for counterfactual explanations can produce\nfaithful, informative, and easy-to-verify results. These counterfactuals offer\na promising alternative to traditional explainability methods (e.g. SHAP,\nLIME), provided that prompts are tailored to specific tasks and checked for\nvalidity.", "published": "2024-07-19 17:41:08", "link": "http://arxiv.org/abs/2407.14487v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Internal Consistency and Self-Feedback in Large Language Models: A\n  Survey", "abstract": "Large language models (LLMs) often exhibit deficient reasoning or generate\nhallucinations. To address these, studies prefixed with \"Self-\" such as\nSelf-Consistency, Self-Improve, and Self-Refine have been initiated. They share\na commonality: involving LLMs evaluating and updating themselves. Nonetheless,\nthese efforts lack a unified perspective on summarization, as existing surveys\npredominantly focus on categorization.\n  In this paper, we use a unified perspective of internal consistency, offering\nexplanations for reasoning deficiencies and hallucinations. Internal\nconsistency refers to the consistency in expressions among LLMs' latent,\ndecoding, or response layers based on sampling methodologies. Then, we\nintroduce an effective theoretical framework capable of mining internal\nconsistency, named Self-Feedback. This framework consists of two modules:\nSelf-Evaluation and Self-Update. The former captures internal consistency\nsignals, while the latter leverages the signals to enhance either the model's\nresponse or the model itself. This framework has been employed in numerous\nstudies.\n  We systematically classify these studies by tasks and lines of work;\nsummarize relevant evaluation methods and benchmarks; and delve into the\nconcern, \"Does Self-Feedback Really Work?\" We also propose several critical\nviewpoints, including the \"Hourglass Evolution of Internal Consistency\",\n\"Consistency Is (Almost) Correctness\" hypothesis, and \"The Paradox of Latent\nand Explicit Reasoning\". The relevant resources are open-sourced at\nhttps://github.com/IAAR-Shanghai/ICSFSurvey.", "published": "2024-07-19 17:59:03", "link": "http://arxiv.org/abs/2407.14507v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Databases Improve Success in Retrieval-based Large Language\n  Models", "abstract": "Open-source LLMs have shown great potential as fine-tuned chatbots, and\ndemonstrate robust abilities in reasoning and surpass many existing benchmarks.\nRetrieval-Augmented Generation (RAG) is a technique for improving the\nperformance of LLMs on tasks that the models weren't explicitly trained on, by\nleveraging external knowledge databases. Numerous studies have demonstrated the\neffectiveness of RAG to more successfully accomplish downstream tasks when\nusing vector datasets that consist of relevant background information. It has\nbeen implicitly assumed by those in the field that if adversarial background\ninformation is utilized in this context, that the success of using a RAG-based\napproach would be nonexistent or even negatively impact the results. To address\nthis assumption, we tested several open-source LLMs on the ability of RAG to\nimprove their success in answering multiple-choice questions (MCQ) in the\nmedical subspecialty field of Nephrology. Unlike previous studies, we examined\nthe effect of RAG in utilizing both relevant and adversarial background\ndatabases. We set up several open-source LLMs, including Llama 3, Phi-3,\nMixtral 8x7b, Zephyr$\\beta$, and Gemma 7B Instruct, in a zero-shot RAG\npipeline. As adversarial sources of information, text from the Bible and a\nRandom Words generated database were used for comparison. Our data show that\nmost of the open-source LLMs improve their multiple-choice test-taking success\nas expected when incorporating relevant information vector databases.\nSurprisingly however, adversarial Bible text significantly improved the success\nof many LLMs and even random word text improved test taking ability of some of\nthe models. In summary, our results demonstrate for the first time the\ncountertintuitive ability of adversarial information datasets to improve the\nRAG-based LLM success.", "published": "2024-07-19 18:08:39", "link": "http://arxiv.org/abs/2407.14609v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Human-Interpretable Adversarial Prompt Attack on Large Language Models\n  with Situational Context", "abstract": "Previous research on testing the vulnerabilities in Large Language Models\n(LLMs) using adversarial attacks has primarily focused on nonsensical prompt\ninjections, which are easily detected upon manual or automated review (e.g.,\nvia byte entropy). However, the exploration of innocuous human-understandable\nmalicious prompts augmented with adversarial injections remains limited. In\nthis research, we explore converting a nonsensical suffix attack into a\nsensible prompt via a situation-driven contextual re-writing. This allows us to\nshow suffix conversion without any gradients, using only LLMs to perform the\nattacks, and thus better understand the scope of possible risks. We combine an\nindependent, meaningful adversarial insertion and situations derived from\nmovies to check if this can trick an LLM. The situations are extracted from the\nIMDB dataset, and prompts are defined following a few-shot chain-of-thought\nprompting. Our approach demonstrates that a successful situation-driven attack\ncan be executed on both open-source and proprietary LLMs. We find that across\nmany LLMs, as few as 1 attempt produces an attack and that these attacks\ntransfer between LLMs.", "published": "2024-07-19 19:47:26", "link": "http://arxiv.org/abs/2407.14644v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextual modulation of language comprehension in a dynamic neural\n  model of lexical meaning", "abstract": "We propose and computationally implement a dynamic neural model of lexical\nmeaning, and experimentally test its behavioral predictions. We demonstrate the\narchitecture and behavior of the model using as a test case the English lexical\nitem 'have', focusing on its polysemous use. In the model, 'have' maps to a\nsemantic space defined by two continuous conceptual dimensions, connectedness\nand control asymmetry, previously proposed to parameterize the conceptual\nsystem for language. The mapping is modeled as coupling between a neural node\nrepresenting the lexical item and neural fields representing the conceptual\ndimensions. While lexical knowledge is modeled as a stable coupling pattern,\nreal-time lexical meaning retrieval is modeled as the motion of neural\nactivation patterns between metastable states corresponding to semantic\ninterpretations or readings. Model simulations capture two previously reported\nempirical observations: (1) contextual modulation of lexical semantic\ninterpretation, and (2) individual variation in the magnitude of this\nmodulation. Simulations also generate a novel prediction that the by-trial\nrelationship between sentence reading time and acceptability should be\ncontextually modulated. An experiment combining self-paced reading and\nacceptability judgments replicates previous results and confirms the new model\nprediction. Altogether, results support a novel perspective on lexical\npolysemy: that the many related meanings of a word are metastable neural\nactivation states that arise from the nonlinear dynamics of neural populations\ngoverning interpretation on continuous semantic dimensions.", "published": "2024-07-19 23:28:55", "link": "http://arxiv.org/abs/2407.14701v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval\n  Augmented Question Answering", "abstract": "Question answering based on retrieval augmented generation (RAG-QA) is an\nimportant research topic in NLP and has a wide range of real-world\napplications. However, most existing datasets for this task are either\nconstructed using a single source corpus or consist of short extractive\nanswers, which fall short of evaluating large language model (LLM) based RAG-QA\nsystems on cross-domain generalization. To address these limitations, we create\nLong-form RobustQA (LFRQA), a new dataset comprising human-written long-form\nanswers that integrate short extractive answers from multiple documents into a\nsingle, coherent narrative, covering 26K queries and large corpora across seven\ndifferent domains. We further propose RAG-QA Arena by directly comparing\nmodel-generated answers against LFRQA's answers using LLMs as evaluators. We\nshow via extensive experiments that RAG-QA Arena and human judgments on answer\nquality are highly correlated. Moreover, only 41.3% of the most competitive\nLLM's answers are preferred to LFRQA's answers, demonstrating RAG-QA Arena as a\nchallenging evaluation platform for future research.", "published": "2024-07-19 03:02:51", "link": "http://arxiv.org/abs/2407.13998v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BERTer: The Efficient One", "abstract": "We explore advanced fine-tuning techniques to boost BERT's performance in\nsentiment analysis, paraphrase detection, and semantic textual similarity. Our\napproach leverages SMART regularization to combat overfitting, improves\nhyperparameter choices, employs a cross-embedding Siamese architecture for\nimproved sentence embeddings, and introduces innovative early exiting methods.\nOur fine-tuning findings currently reveal substantial improvements in model\nefficiency and effectiveness when combining multiple fine-tuning architectures,\nachieving a state-of-the-art performance score of on the test set, surpassing\ncurrent benchmarks and highlighting BERT's adaptability in multifaceted\nlinguistic tasks.", "published": "2024-07-19 05:33:09", "link": "http://arxiv.org/abs/2407.14039v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing\n  Functional Correctness?", "abstract": "Although large language models (LLMs) have been largely successful in\ngenerating functionally correct programs, conditioning models to produce\nefficient solutions while ensuring correctness remains a challenge. Further,\nunreliability in benchmarking code efficiency is a hurdle across varying\nhardware specifications for popular interpreted languages such as Python. In\nthis paper, we present ECCO, a reproducible benchmark for evaluating program\nefficiency via two paradigms: natural language (NL) based code generation and\nhistory-based code editing. On ECCO, we adapt and thoroughly investigate the\nthree most promising existing LLM-based approaches: in-context learning,\niterative refinement with execution or NL feedback, and fine-tuning conditioned\non execution and editing history. While most methods degrade functional\ncorrectness and moderately increase program efficiency, we find that adding\nexecution information often helps maintain functional correctness, and NL\nfeedback enhances more on efficiency. We release our benchmark to support\nfuture work on LLM-based generation of efficient code.", "published": "2024-07-19 05:47:40", "link": "http://arxiv.org/abs/2407.14044v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automatic Classification of News Subjects in Broadcast News: Application\n  to a Gender Bias Representation Analysis", "abstract": "This paper introduces a computational framework designed to delineate gender\ndistribution biases in topics covered by French TV and radio news. We\ntranscribe a dataset of 11.7k hours, broadcasted in 2023 on 21 French channels.\nA Large Language Model (LLM) is used in few-shot conversation mode to obtain a\ntopic classification on those transcriptions. Using the generated LLM\nannotations, we explore the finetuning of a specialized smaller classification\nmodel, to reduce the computational cost. To evaluate the performances of these\nmodels, we construct and annotate a dataset of 804 dialogues. This dataset is\nmade available free of charge for research purposes. We show that women are\nnotably underrepresented in subjects such as sports, politics and conflicts.\nConversely, on topics such as weather, commercials and health, women have more\nspeaking time than their overall average across all subjects. We also observe\nrepresentations differences between private and public service channels.", "published": "2024-07-19 10:15:45", "link": "http://arxiv.org/abs/2407.14180v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LeKUBE: A Legal Knowledge Update BEnchmark", "abstract": "Recent advances in Large Language Models (LLMs) have significantly shaped the\napplications of AI in multiple fields, including the studies of legal\nintelligence. Trained on extensive legal texts, including statutes and legal\ndocuments, the legal LLMs can capture important legal knowledge/concepts\neffectively and provide important support for downstream legal applications\nsuch as legal consultancy. Yet, the dynamic nature of legal statutes and\ninterpretations also poses new challenges to the use of LLMs in legal\napplications. Particularly, how to update the legal knowledge of LLMs\neffectively and efficiently has become an important research problem in\npractice. Existing benchmarks for evaluating knowledge update methods are\nmostly designed for the open domain and cannot address the specific challenges\nof the legal domain, such as the nuanced application of new legal knowledge,\nthe complexity and lengthiness of legal regulations, and the intricate nature\nof legal reasoning. To address this gap, we introduce the Legal Knowledge\nUpdate BEnchmark, i.e. LeKUBE, which evaluates knowledge update methods for\nlegal LLMs across five dimensions. Specifically, we categorize the needs of\nknowledge updates in the legal domain with the help of legal professionals, and\nthen hire annotators from law schools to create synthetic updates to the\nChinese Criminal and Civil Code as well as sets of questions of which the\nanswers would change after the updates. Through a comprehensive evaluation of\nstate-of-the-art knowledge update methods, we reveal a notable gap between\nexisting knowledge update methods and the unique needs of the legal domain,\nemphasizing the need for further research and development of knowledge update\nmechanisms tailored for legal LLMs.", "published": "2024-07-19 10:40:10", "link": "http://arxiv.org/abs/2407.14192v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hierarchical Windowed Graph Attention Network and a Large Scale Dataset\n  for Isolated Indian Sign Language Recognition", "abstract": "Automatic Sign Language (SL) recognition is an important task in the computer\nvision community. To build a robust SL recognition system, we need a\nconsiderable amount of data which is lacking particularly in Indian sign\nlanguage (ISL). In this paper, we introduce a large-scale isolated ISL dataset\nand a novel SL recognition model based on skeleton graph structure. The dataset\ncovers 2002 daily used common words in the deaf community recorded by 20 (10\nmale and 10 female) deaf adult signers (contains 40033 videos). We propose a SL\nrecognition model namely Hierarchical Windowed Graph Attention Network (HWGAT)\nby utilizing the human upper body skeleton graph. The HWGAT tries to capture\ndistinctive motions by giving attention to different body parts induced by the\nhuman skeleton graph. The utility of the proposed dataset and the usefulness of\nour model are evaluated through extensive experiments. We pre-trained the\nproposed model on the presented dataset and fine-tuned it across different sign\nlanguage datasets further boosting the performance of 1.10, 0.46, 0.78, and\n6.84 percentage points on INCLUDE, LSA64, AUTSL and WLASL respectively compared\nto the existing state-of-the-art keypoints-based models.", "published": "2024-07-19 11:48:36", "link": "http://arxiv.org/abs/2407.14224v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Voices in a Crowd: Searching for Clusters of Unique Perspectives", "abstract": "Language models have been shown to reproduce underlying biases existing in\ntheir training data, which is the majority perspective by default. Proposed\nsolutions aim to capture minority perspectives by either modelling annotator\ndisagreements or grouping annotators based on shared metadata, both of which\nface significant challenges. We propose a framework that trains models without\nencoding annotator metadata, extracts latent embeddings informed by annotator\nbehaviour, and creates clusters of similar opinions, that we refer to as\nvoices. Resulting clusters are validated post-hoc via internal and external\nquantitative metrics, as well a qualitative analysis to identify the type of\nvoice that each cluster represents. Our results demonstrate the strong\ngeneralisation capability of our framework, indicated by resulting clusters\nbeing adequately robust, while also capturing minority perspectives based on\ndifferent demographic factors throughout two distinct datasets.", "published": "2024-07-19 12:37:15", "link": "http://arxiv.org/abs/2407.14259v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Foundation Models for Autonomous Robots in Unstructured Environments", "abstract": "Automating activities through robots in unstructured environments, such as\nconstruction sites, has been a long-standing desire. However, the high degree\nof unpredictable events in these settings has resulted in far less adoption\ncompared to more structured settings, such as manufacturing, where robots can\nbe hard-coded or trained on narrowly defined datasets. Recently, pretrained\nfoundation models, such as Large Language Models (LLMs), have demonstrated\nsuperior generalization capabilities by providing zero-shot solutions for\nproblems do not present in the training data, proposing them as a potential\nsolution for introducing robots to unstructured environments. To this end, this\nstudy investigates potential opportunities and challenges of pretrained\nfoundation models from a multi-dimensional perspective. The study\nsystematically reviews application of foundation models in two field of robotic\nand unstructured environment and then synthesized them with deliberative acting\ntheory. Findings showed that linguistic capabilities of LLMs have been utilized\nmore than other features for improving perception in human-robot interactions.\nOn the other hand, findings showed that the use of LLMs demonstrated more\napplications in project management and safety in construction, and natural\nhazard detection in disaster management. Synthesizing these findings, we\nlocated the current state-of-the-art in this field on a five-level scale of\nautomation, placing them at conditional automation. This assessment was then\nused to envision future scenarios, challenges, and solutions toward autonomous\nsafe unstructured environments. Our study can be seen as a benchmark to track\nour progress toward that future.", "published": "2024-07-19 13:26:52", "link": "http://arxiv.org/abs/2407.14296v2", "categories": ["cs.RO", "cs.CL"], "primary_category": "cs.RO"}
{"title": "How to Engage Your Readers? Generating Guiding Questions to Promote\n  Active Reading", "abstract": "Using questions in written text is an effective strategy to enhance\nreadability. However, what makes an active reading question good, what the\nlinguistic role of these questions is, and what is their impact on human\nreading remains understudied. We introduce GuidingQ, a dataset of 10K in-text\nquestions from textbooks and scientific articles. By analyzing the dataset, we\npresent a comprehensive understanding of the use, distribution, and linguistic\ncharacteristics of these questions. Then, we explore various approaches to\ngenerate such questions using language models. Our results highlight the\nimportance of capturing inter-question relationships and the challenge of\nquestion position identification in generating these questions. Finally, we\nconduct a human study to understand the implication of such questions on\nreading comprehension. We find that the generated questions are of high quality\nand are almost as effective as human-written questions in terms of improving\nreaders' memorization and comprehension.", "published": "2024-07-19 13:42:56", "link": "http://arxiv.org/abs/2407.14309v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Retrieval in Sponsored Search by Leveraging Query Context\n  Signals", "abstract": "Accurately retrieving relevant bid keywords for user queries is critical in\nSponsored Search but remains challenging, particularly for short, ambiguous\nqueries. Existing dense and generative retrieval models often fail to capture\nnuanced user intent in these cases. To address this, we propose an approach to\nenhance query understanding by augmenting queries with rich contextual signals\nderived from web search results and large language models, stored in an online\ncache. Specifically, we use web search titles and snippets to ground queries in\nreal-world information and utilize GPT-4 to generate query rewrites and\nexplanations that clarify user intent. These signals are efficiently integrated\nthrough a Fusion-in-Decoder based Unity architecture, enabling both dense and\ngenerative retrieval with serving costs on par with traditional context-free\nmodels. To address scenarios where context is unavailable in the cache, we\nintroduce context glancing, a curriculum learning strategy that improves model\nrobustness and performance even without contextual signals during inference.\nExtensive offline experiments demonstrate that our context-aware approach\nsubstantially outperforms context-free models. Furthermore, online A/B testing\non a prominent search engine across 160+ countries shows significant\nimprovements in user engagement and revenue.", "published": "2024-07-19 14:28:53", "link": "http://arxiv.org/abs/2407.14346v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Open Artificial Knowledge", "abstract": "The tremendous success of chat-based AI systems like ChatGPT, Claude, and\nGemini stems from Large Language Models (LLMs) trained on vast amount of\ndatasets. However, acquiring high-quality, diverse, and ethically sourced\ntraining data remains a significant challenge. We introduce the Open Artificial\nKnowledge (OAK) dataset, a large-scale resource of over 500 million tokens (at\nthe moment of writing) designed to address this issue. OAK leverages an\nensemble of state-of-the-art LLMs, including GPT4o, LLaMa3-70B, LLaMa3-8B,\nMixtral-8x7B, Gemma-7B, and Gemma-2-9B , to generate high-quality text across\ndiverse domains, guided by Wikipedia's main categories. Our methodology ensures\nbroad knowledge coverage while maintaining coherence and factual accuracy. The\nOAK dataset aims to foster the development of more capable and aligned language\nmodels while addressing critical issues of data scarcity and privacy in LLM\ntraining, and it is freely available on www.oakdataset.org.", "published": "2024-07-19 15:01:24", "link": "http://arxiv.org/abs/2407.14371v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AudioInsight: Detecting Social Contexts Relevant to Social Anxiety from\n  Speech", "abstract": "During social interactions, understanding the intricacies of the context can\nbe vital, particularly for socially anxious individuals. While previous\nresearch has found that the presence of a social interaction can be detected\nfrom ambient audio, the nuances within social contexts, which influence how\nanxiety provoking interactions are, remain largely unexplored. As an\nalternative to traditional, burdensome methods like self-report, this study\npresents a novel approach that harnesses ambient audio segments to detect\nsocial threat contexts. We focus on two key dimensions: number of interaction\npartners (dyadic vs. group) and degree of evaluative threat (explicitly\nevaluative vs. not explicitly evaluative). Building on data from a Zoom-based\nsocial interaction study (N=52 college students, of whom the majority N=45 are\nsocially anxious), we employ deep learning methods to achieve strong detection\nperformance. Under sample-wide 5-fold Cross Validation (CV), our model\ndistinguished dyadic from group interactions with 90\\% accuracy and detected\nevaluative threat at 83\\%. Using a leave-one-group-out CV, accuracies were 82\\%\nand 77\\%, respectively. While our data are based on virtual interactions due to\npandemic constraints, our method has the potential to extend to diverse\nreal-world settings. This research underscores the potential of passive sensing\nand AI to differentiate intricate social contexts, and may ultimately advance\nthe ability of context-aware digital interventions to offer personalized mental\nhealth support.", "published": "2024-07-19 17:01:12", "link": "http://arxiv.org/abs/2407.14458v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Check-Eval: A Checklist-based Approach for Evaluating Text Quality", "abstract": "Evaluating the quality of text generated by large language models (LLMs)\nremains a significant challenge. Traditional metrics often fail to align well\nwith human judgments, particularly in tasks requiring creativity and nuance. In\nthis paper, we propose \\textsc{Check-Eval}, a novel evaluation framework\nleveraging LLMs to assess the quality of generated text through a\nchecklist-based approach. \\textsc{Check-Eval} can be employed as both a\nreference-free and reference-dependent evaluation method, providing a\nstructured and interpretable assessment of text quality. The framework consists\nof two main stages: checklist generation and checklist evaluation. We validate\n\\textsc{Check-Eval} on two benchmark datasets: Portuguese Legal Semantic\nTextual Similarity and \\textsc{SummEval}. Our results demonstrate that\n\\textsc{Check-Eval} achieves higher correlations with human judgments compared\nto existing metrics, such as \\textsc{G-Eval} and \\textsc{GPTScore},\nunderscoring its potential as a more reliable and effective evaluation\nframework for natural language generation tasks. The code for our experiments\nis available at \\url{https://anonymous.4open.science/r/check-eval-0DB4}", "published": "2024-07-19 17:14:16", "link": "http://arxiv.org/abs/2407.14467v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating language models as risk scores", "abstract": "Current question-answering benchmarks predominantly focus on accuracy in\nrealizable prediction tasks. Conditioned on a question and answer-key, does the\nmost likely token match the ground truth? Such benchmarks necessarily fail to\nevaluate LLMs' ability to quantify ground-truth outcome uncertainty. In this\nwork, we focus on the use of LLMs as risk scores for unrealizable prediction\ntasks. We introduce folktexts, a software package to systematically generate\nrisk scores using LLMs, and evaluate them against US Census data products. A\nflexible API enables the use of different prompting schemes, local or\nweb-hosted models, and diverse census columns that can be used to compose\ncustom prediction tasks. We evaluate 17 recent LLMs across five proposed\nbenchmark tasks. We find that zero-shot risk scores produced by multiple-choice\nquestion-answering have high predictive signal but are widely miscalibrated.\nBase models consistently overestimate outcome uncertainty, while\ninstruction-tuned models underestimate uncertainty and produce over-confident\nrisk scores. In fact, instruction-tuning polarizes answer distribution\nregardless of true underlying data uncertainty. This reveals a general\ninability of instruction-tuned LLMs to express data uncertainty using\nmultiple-choice answers. A separate experiment using verbalized chat-style risk\nqueries yields substantially improved calibration across instruction-tuned\nmodels. These differences in ability to quantify data uncertainty cannot be\nrevealed in realizable settings, and highlight a blind-spot in the current\nevaluation ecosystem that folktexts covers.", "published": "2024-07-19 18:13:37", "link": "http://arxiv.org/abs/2407.14614v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Clinical Reading Comprehension with Encoder-Decoder Models Enhanced by\n  Direct Preference Optimization", "abstract": "Extractive question answering over clinical text is a crucial need to help\ndeal with the deluge of clinical text generated in hospitals. While encoder\nmodels (e.g., BERT) have been popular for this reading comprehension task,\nrecently encoder-decoder models (e.g., T5) are on the rise. There is also the\nemergence of preference optimization techniques to align decoder-only LLMs with\nhuman preferences. In this paper, we combine encoder-decoder models with the\ndirect preference optimization (DPO) method to improve over prior state of the\nart for the RadQA radiology question answering task by 12-15 F1 points. To the\nbest of our knowledge, this effort is the first to show that DPO method also\nworks for reading comprehension via novel heuristics to generate preference\ndata without human inputs.", "published": "2024-07-19 03:12:10", "link": "http://arxiv.org/abs/2407.14000v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "HeCiX: Integrating Knowledge Graphs and Large Language Models for\n  Biomedical Research", "abstract": "Despite advancements in drug development strategies, 90% of clinical trials\nfail. This suggests overlooked aspects in target validation and drug\noptimization. In order to address this, we introduce HeCiX-KG,\nHetionet-Clinicaltrials neXus Knowledge Graph, a novel fusion of data from\nClinicalTrials.gov and Hetionet in a single knowledge graph. HeCiX-KG combines\ndata on previously conducted clinical trials from ClinicalTrials.gov, and\ndomain expertise on diseases and genes from Hetionet. This offers a thorough\nresource for clinical researchers. Further, we introduce HeCiX, a system that\nuses LangChain to integrate HeCiX-KG with GPT-4, and increase its usability.\nHeCiX shows high performance during evaluation against a range of clinically\nrelevant issues, proving this model to be promising for enhancing the\neffectiveness of clinical research. Thus, this approach provides a more\nholistic view of clinical trials and existing biological data.", "published": "2024-07-19 05:04:24", "link": "http://arxiv.org/abs/2407.14030v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rasa: Building Expressive Speech Synthesis Systems for Indian Languages\n  in Low-resource Settings", "abstract": "We release Rasa, the first multilingual expressive TTS dataset for any Indian\nlanguage, which contains 10 hours of neutral speech and 1-3 hours of expressive\nspeech for each of the 6 Ekman emotions covering 3 languages: Assamese,\nBengali, & Tamil. Our ablation studies reveal that just 1 hour of neutral and\n30 minutes of expressive data can yield a Fair system as indicated by MUSHRA\nscores. Increasing neutral data to 10 hours, with minimal expressive data,\nsignificantly enhances expressiveness. This offers a practical recipe for\nresource-constrained languages, prioritizing easily obtainable neutral data\nalongside smaller amounts of expressive data. We show the importance of\nsyllabically balanced data and pooling emotions to enhance expressiveness. We\nalso highlight challenges in generating specific emotions, e.g., fear and\nsurprise.", "published": "2024-07-19 06:33:10", "link": "http://arxiv.org/abs/2407.14056v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LazyLLM: Dynamic Token Pruning for Efficient Long Context LLM Inference", "abstract": "The inference of transformer-based large language models consists of two\nsequential stages: 1) a prefilling stage to compute the KV cache of prompts and\ngenerate the first token, and 2) a decoding stage to generate subsequent\ntokens. For long prompts, the KV cache must be computed for all tokens during\nthe prefilling stage, which can significantly increase the time needed to\ngenerate the first token. Consequently, the prefilling stage may become a\nbottleneck in the generation process. An open question remains whether all\nprompt tokens are essential for generating the first token. To answer this, we\nintroduce a novel method, LazyLLM, that selectively computes the KV for tokens\nimportant for the next token prediction in both the prefilling and decoding\nstages. Contrary to static pruning approaches that prune the prompt at once,\nLazyLLM allows language models to dynamically select different subsets of\ntokens from the context in different generation steps, even though they might\nbe pruned in previous steps. Extensive experiments on standard datasets across\nvarious tasks demonstrate that LazyLLM is a generic method that can be\nseamlessly integrated with existing language models to significantly accelerate\nthe generation without fine-tuning. For instance, in the multi-document\nquestion-answering task, LazyLLM accelerates the prefilling stage of the LLama\n2 7B model by 2.34x while maintaining accuracy.", "published": "2024-07-19 06:34:45", "link": "http://arxiv.org/abs/2407.14057v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Domain-Specific Pretraining of Language Models: A Comparative Study in\n  the Medical Field", "abstract": "There are many cases where LLMs are used for specific tasks in a single\ndomain. These usually require less general, but more domain-specific knowledge.\nHighly capable, general-purpose state-of-the-art language models like GPT-4 or\nClaude-3-opus can often be used for such tasks, but they are very large and\ncannot be run locally, even if they were not proprietary. This can be a problem\nwhen working with sensitive data. This paper focuses on domain-specific and\nmixed-domain pretraining as potentially more efficient methods than general\npretraining for specialized language models. We will take a look at work\nrelated to domain-specific pretraining, specifically in the medical area, and\ncompare benchmark results of specialized language models to general-purpose\nlanguage models.", "published": "2024-07-19 07:12:43", "link": "http://arxiv.org/abs/2407.14076v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.7"], "primary_category": "cs.LG"}
{"title": "PassTSL: Modeling Human-Created Passwords through Two-Stage Learning", "abstract": "Textual passwords are still the most widely used user authentication\nmechanism. Due to the close connections between textual passwords and natural\nlanguages, advanced technologies in natural language processing (NLP) and\nmachine learning (ML) could be used to model passwords for different purposes\nsuch as studying human password-creation behaviors and developing more advanced\npassword cracking methods for informing better defence mechanisms. In this\npaper, we propose PassTSL (modeling human-created Passwords through Two-Stage\nLearning), inspired by the popular pretraining-finetuning framework in NLP and\ndeep learning (DL). We report how different pretraining settings affected\nPassTSL and proved its effectiveness by applying it to six large leaked\npassword databases. Experimental results showed that it outperforms five\nstate-of-the-art (SOTA) password cracking methods on password guessing by a\nsignificant margin ranging from 4.11% to 64.69% at the maximum point. Based on\nPassTSL, we also implemented a password strength meter (PSM), and our\nexperiments showed that it was able to estimate password strength more\naccurately, causing fewer unsafe errors (overestimating the password strength)\nthan two other SOTA PSMs when they produce the same rate of safe errors\n(underestimating the password strength): a neural-network based method and\nzxcvbn. Furthermore, we explored multiple finetuning settings, and our\nevaluations showed that, even a small amount of additional training data, e.g.,\nonly 0.1% of the pretrained data, can lead to over 3% improvement in password\nguessing on average. We also proposed a heuristic approach to selecting\nfinetuning passwords based on JS (Jensen-Shannon) divergence and experimental\nresults validated its usefulness. In summary, our contributions demonstrate the\npotential and feasibility of applying advanced NLP and ML methods to password\nmodeling and cracking.", "published": "2024-07-19 09:23:30", "link": "http://arxiv.org/abs/2407.14145v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Braille-to-Speech Generator: Audio Generation Based on Joint Fine-Tuning\n  of CLIP and Fastspeech2", "abstract": "An increasing number of Chinese people are troubled by different degrees of\nvisual impairment, which has made the modal conversion between a single image\nor video frame in the visual field and the audio expressing the same\ninformation a research hotspot. Deep learning technologies such as OCR+Vocoder\nand Im2Wav enable English audio synthesis or image-to-sound matching in a\nself-supervised manner. However, the audio data used for training is limited\nand English is not universal for visually impaired people with different\neducational levels. Therefore, for the sake of solving the problems of data\nvolume and language applicability to improve the reading efficiency of visually\nimpaired people, a set of image-to-speech framework CLIP-KNN-Fastspeech2 based\non the Chinese context was constructed. The framework integrates multiple basic\nmodels and adopts the strategy of independent pre-training and joint\nfine-tuning. First, the Chinese CLIP and Fastspeech2 text-to-speech models were\npre-trained on two public datasets, MUGE and Baker, respectively, and their\nconvergence was verified. Subsequently, joint fine-tuning was performed using a\nself-built Braille image dataset. Experimental results on multiple public\ndatasets such as VGGSound, Flickr8k, ImageHear, and the self-built Braille\ndataset BIT-DP show that the model has improved objective indicators such as\nBLEU4,FAD(Fr\\'echet Audio Distance), WER(Word Error Ratio), and even inference\nspeed. This verifies that the constructed model still has the ability to\nsynthesize high-quality speech under limited data, and also proves the\neffectiveness of the joint training strategy that integrates multiple basic\nmodels.", "published": "2024-07-19 11:18:44", "link": "http://arxiv.org/abs/2407.14212v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CoVoSwitch: Machine Translation of Synthetic Code-Switched Text Based on\n  Intonation Units", "abstract": "Multilingual code-switching research is often hindered by the lack and\nlinguistically biased status of available datasets. To expand language\nrepresentation, we synthesize code-switching data by replacing intonation units\ndetected through PSST, a speech segmentation model fine-tuned from OpenAI's\nWhisper, using a speech-to-text translation dataset, CoVoST 2. With our\ndataset, CoVoSwitch, spanning 13 languages, we evaluate the code-switching\ntranslation performance of two multilingual translation models, M2M-100 418M\nand NLLB-200 600M. We reveal that the inclusion of code-switching units results\nin higher translation performance than monolingual settings and that models are\nbetter at code-switching translation into English than non-English. Further,\nlow-resource languages gain most from integration of code-switched units when\ntranslating into English but much less when translating into non-English.\nTranslations into low-resource languages also perform worse than even raw\ncode-switched inputs. We find that systems excel at copying English tokens but\nstruggle with non-English tokens, that the off-target problem in monolingual\nsettings is also relevant in code-switching settings, and that models\nhallucinate in code-switching translation by introducing words absent in both\nof the original source sentences. CoVoSwitch and code are available at\nhttps://github.com/sophiayk20/covoswitch.", "published": "2024-07-19 13:26:35", "link": "http://arxiv.org/abs/2407.14295v1", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Multimodal Misinformation Detection using Large Vision-Language Models", "abstract": "The increasing proliferation of misinformation and its alarming impact have\nmotivated both industry and academia to develop approaches for misinformation\ndetection and fact checking. Recent advances on large language models (LLMs)\nhave shown remarkable performance in various tasks, but whether and how LLMs\ncould help with misinformation detection remains relatively underexplored. Most\nof existing state-of-the-art approaches either do not consider evidence and\nsolely focus on claim related features or assume the evidence to be provided.\nFew approaches consider evidence retrieval as part of the misinformation\ndetection but rely on fine-tuning models. In this paper, we investigate the\npotential of LLMs for misinformation detection in a zero-shot setting. We\nincorporate an evidence retrieval component into the process as it is crucial\nto gather pertinent information from various sources to detect the veracity of\nclaims. To this end, we propose a novel re-ranking approach for multimodal\nevidence retrieval using both LLMs and large vision-language models (LVLM). The\nretrieved evidence samples (images and texts) serve as the input for an\nLVLM-based approach for multimodal fact verification (LVLM4FV). To enable a\nfair evaluation, we address the issue of incomplete ground truth for evidence\nsamples in an existing evidence retrieval dataset by annotating a more complete\nset of evidence samples for both image and text retrieval. Our experimental\nresults on two datasets demonstrate the superiority of the proposed approach in\nboth evidence retrieval and fact verification tasks and also better\ngeneralization capability across dataset compared to the supervised baseline.", "published": "2024-07-19 13:57:11", "link": "http://arxiv.org/abs/2407.14321v1", "categories": ["cs.CL", "cs.IR", "cs.MM"], "primary_category": "cs.CL"}
{"title": "LLMs left, right, and center: Assessing GPT's capabilities to label\n  political bias from web domains", "abstract": "This research investigates whether OpenAI's GPT-4, a state-of-the-art large\nlanguage model, can accurately classify the political bias of news sources\nbased solely on their URLs. Given the subjective nature of political labels,\nthird-party bias ratings like those from Ad Fontes Media, AllSides, and Media\nBias/Fact Check (MBFC) are often used in research to analyze news source\ndiversity. This study aims to determine if GPT-4 can replicate these human\nratings on a seven-degree scale (\"far-left\" to \"far-right\"). The analysis\ncompares GPT-4's classifications against MBFC's, and controls for website\npopularity using Open PageRank scores. Findings reveal a high correlation\n($\\text{Spearman's } \\rho = .89$, $n = 5,877$, $p < 0.001$) between GPT-4's and\nMBFC's ratings, indicating the model's potential reliability. However, GPT-4\nabstained from classifying approximately $\\frac{2}{3}$ of the dataset. It is\nmore likely to abstain from rating unpopular websites, which also suffer from\nless accurate assessments. The LLM tends to avoid classifying sources that MBFC\nconsiders to be centrist, resulting in more polarized outputs. Finally, this\nanalysis shows a slight leftward skew in GPT's classifications compared to\nMBFC's. Therefore, while this paper suggests that while GPT-4 can be a\nscalable, cost-effective tool for political bias classification of news\nwebsites, its use should be as a complement to human judgment to mitigate\nbiases.", "published": "2024-07-19 14:28:07", "link": "http://arxiv.org/abs/2407.14344v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "System-1.x: Learning to Balance Fast and Slow Planning with Language\n  Models", "abstract": "Language models can be used to solve long-horizon planning problems in two\ndistinct modes: a fast 'System-1' mode, directly generating plans without any\nexplicit search or backtracking, and a slow 'System-2' mode, planning\nstep-by-step by explicitly searching over possible actions. While System-2 is\ntypically more effective, it is also more computationally expensive, making it\ninfeasible for long plans or large action spaces. Moreover, isolated System-1\nor 2 ignores the user's end goals, failing to provide ways to control the\nmodel's behavior. To this end, we propose the System-1.x Planner, a\ncontrollable planning framework with LLMs that is capable of generating hybrid\nplans and balancing between the two planning modes based on the difficulty of\nthe problem at hand. System-1.x consists of (i) a controller, (ii) a System-1\nPlanner, and (iii) a System-2 Planner. Based on a user-specified hybridization\nfactor (x) governing the mixture between System-1 and 2, the controller\ndecomposes a problem into sub-goals, and classifies them as easy or hard to be\nsolved by either System-1 or 2, respectively. We fine-tune all three components\non top of a single base LLM, requiring only search traces as supervision.\nExperiments with two diverse planning tasks -- Maze Navigation and Blocksworld\n-- show that our System-1.x Planner outperforms a System-1 Planner, a System-2\nPlanner trained to approximate A* search, and also a symbolic planner (A*). We\ndemonstrate the following key properties of our planner: (1) controllability:\nincreasing the hybridization factor (e.g., System-1.75 vs 1.5) performs more\nsearch, improving performance, (2) flexibility: by building a neuro-symbolic\nvariant with a neural System-1 and a symbolic System-2, we can use existing\nsymbolic methods, and (3) generalizability: by being able to learn from\ndifferent search algorithms, our method is robust to the choice of search\nalgorithm.", "published": "2024-07-19 15:40:59", "link": "http://arxiv.org/abs/2407.14414v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG\n  Capabilities", "abstract": "In this work, we introduce ChatQA 2, an Llama 3.0-based model with a 128K\ncontext window, designed to bridge the gap between open-source LLMs and leading\nproprietary models (e.g., GPT-4-Turbo-2024-04-09) in long context understanding\nand retrieval-augmented generation (RAG) capabilities. These two capabilities\nare complementary to each other and essential for LLMs to process large volumes\nof information that cannot fit into a single prompt. We present a detailed\ncontinued training recipe to extend the context window of Llama3-70B-base from\n8K to 128K tokens, along with a three-stage instruction tuning process to\nenhance the model's instruction-following, RAG performance, and long-context\nunderstanding capabilities. Our results demonstrate that the\nLlama3-ChatQA-2-70B model outperforms most existing state-of-the-art models,\nincluding GPT-4-Turbo-2024-04-09, Qwen2-72B-Instruct, and\nLlama3.1-70B-Instruct, on ultra-long tasks beyond 100K tokens, as well as on\nthe RAG benchmark using only a 4K context window, showing the strong long\ncontext capability across varying sequence lengths. We further provide\nextensive comparisons between direct long-context and RAG solutions using the\nsame state-of-the-art long-context LLMs. Interestingly, we find that the\nperformance of strong long-context LLMs using RAG improves when retrieving a\nlarger number of chunks. With a large set of top-k chunks, RAG consistently\noutperforms direct long-context solution using the same state-of-the-art\nlong-context models (e.g., Llama3-ChatQA-2-70B and Qwen2-72B-Instruct) on both\n32K and 128K benchmarks. We open-source the model weights, training data, and\nthe evaluation setup for the for the community:\nhttps://chatqa2-project.github.io/", "published": "2024-07-19 17:35:47", "link": "http://arxiv.org/abs/2407.14482v3", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Pre-training of Multimodal Language Models Customized for Chart\n  Understanding", "abstract": "Recent studies customizing Multimodal Large Language Models (MLLMs) for\ndomain-specific tasks have yielded promising results, especially in the field\nof scientific chart comprehension. These studies generally utilize visual\ninstruction tuning with specialized datasets to enhance question and answer\n(QA) accuracy within the chart domain. However, they often neglect the\nfundamental discrepancy between natural image-caption pre-training data and\ndigital chart image-QA data, particularly in the models' capacity to extract\nunderlying numeric values from charts. This paper tackles this oversight by\nexploring the training processes necessary to improve MLLMs' comprehension of\ncharts. We present three key findings: (1) Incorporating raw data values in\nalignment pre-training markedly improves comprehension of chart data. (2)\nReplacing images with their textual representation randomly during end-to-end\nfine-tuning transfer the language reasoning capability to chart interpretation\nskills. (3) Requiring the model to first extract the underlying chart data and\nthen answer the question in the fine-tuning can further improve the accuracy.\nConsequently, we introduce CHOPINLLM, an MLLM tailored for in-depth chart\ncomprehension. CHOPINLLM effectively interprets various types of charts,\nincluding unannotated ones, while maintaining robust reasoning abilities.\nFurthermore, we establish a new benchmark to evaluate MLLMs' understanding of\ndifferent chart types across various comprehension levels. Experimental results\nshow that CHOPINLLM exhibits strong performance in understanding both annotated\nand unannotated charts across a wide range of types.", "published": "2024-07-19 17:58:36", "link": "http://arxiv.org/abs/2407.14506v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "SQLfuse: Enhancing Text-to-SQL Performance through Comprehensive LLM\n  Synergy", "abstract": "Text-to-SQL conversion is a critical innovation, simplifying the transition\nfrom complex SQL to intuitive natural language queries, especially significant\ngiven SQL's prevalence in the job market across various roles. The rise of\nLarge Language Models (LLMs) like GPT-3.5 and GPT-4 has greatly advanced this\nfield, offering improved natural language understanding and the ability to\ngenerate nuanced SQL statements. However, the potential of open-source LLMs in\nText-to-SQL applications remains underexplored, with many frameworks failing to\nleverage their full capabilities, particularly in handling complex database\nqueries and incorporating feedback for iterative refinement. Addressing these\nlimitations, this paper introduces SQLfuse, a robust system integrating\nopen-source LLMs with a suite of tools to enhance Text-to-SQL translation's\naccuracy and usability. SQLfuse features four modules: schema mining, schema\nlinking, SQL generation, and a SQL critic module, to not only generate but also\ncontinuously enhance SQL query quality. Demonstrated by its leading performance\non the Spider Leaderboard and deployment by Ant Group, SQLfuse showcases the\npractical merits of open-source LLMs in diverse business contexts.", "published": "2024-07-19 06:01:57", "link": "http://arxiv.org/abs/2407.14568v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "BOND: Aligning LLMs with Best-of-N Distillation", "abstract": "Reinforcement learning from human feedback (RLHF) is a key driver of quality\nand safety in state-of-the-art large language models. Yet, a surprisingly\nsimple and strong inference-time strategy is Best-of-N sampling that selects\nthe best generation among N candidates. In this paper, we propose Best-of-N\nDistillation (BOND), a novel RLHF algorithm that seeks to emulate Best-of-N but\nwithout its significant computational overhead at inference time. Specifically,\nBOND is a distribution matching algorithm that forces the distribution of\ngenerations from the policy to get closer to the Best-of-N distribution. We use\nthe Jeffreys divergence (a linear combination of forward and backward KL) to\nbalance between mode-covering and mode-seeking behavior, and derive an\niterative formulation that utilizes a moving anchor for efficiency. We\ndemonstrate the effectiveness of our approach and several design choices\nthrough experiments on abstractive summarization and Gemma models. Aligning\nGemma policies with BOND outperforms other RLHF algorithms by improving results\non several benchmarks.", "published": "2024-07-19 18:38:25", "link": "http://arxiv.org/abs/2407.14622v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CVE-LLM : Automatic vulnerability evaluation in medical device industry\n  using large language models", "abstract": "The healthcare industry is currently experiencing an unprecedented wave of\ncybersecurity attacks, impacting millions of individuals. With the discovery of\nthousands of vulnerabilities each month, there is a pressing need to drive the\nautomation of vulnerability assessment processes for medical devices,\nfacilitating rapid mitigation efforts. Generative AI systems have\nrevolutionized various industries, offering unparalleled opportunities for\nautomation and increased efficiency. This paper presents a solution leveraging\nLarge Language Models (LLMs) to learn from historical evaluations of\nvulnerabilities for the automatic assessment of vulnerabilities in the medical\ndevices industry. This approach is applied within the portfolio of a single\nmanufacturer, taking into account device characteristics, including existing\nsecurity posture and controls. The primary contributions of this paper are\nthreefold. Firstly, it provides a detailed examination of the best practices\nfor training a vulnerability Language Model (LM) in an industrial context.\nSecondly, it presents a comprehensive comparison and insightful analysis of the\neffectiveness of Language Models in vulnerability assessment. Finally, it\nproposes a new human-in-the-loop framework to expedite vulnerability evaluation\nprocesses.", "published": "2024-07-19 19:34:17", "link": "http://arxiv.org/abs/2407.14640v1", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Compact Language Models via Pruning and Knowledge Distillation", "abstract": "Large language models (LLMs) targeting different deployment scales and sizes\nare currently produced by training each variant from scratch; this is extremely\ncompute-intensive. In this paper, we investigate if pruning an existing LLM and\nthen re-training it with a fraction (<3%) of the original training data can be\na suitable alternative to repeated, full retraining. To this end, we develop a\nset of practical and effective compression best practices for LLMs that combine\ndepth, width, attention and MLP pruning with knowledge distillation-based\nretraining; we arrive at these best practices through a detailed empirical\nexploration of pruning strategies for each axis, methods to combine axes,\ndistillation strategies, and search techniques for arriving at optimal\ncompressed architectures. We use this guide to compress the Nemotron-4 family\nof LLMs by a factor of 2-4x, and compare their performance to similarly-sized\nmodels on a variety of language modeling tasks. Deriving 8B and 4B models from\nan already pretrained 15B model using our approach requires up to 40x fewer\ntraining tokens per model compared to training from scratch; this results in\ncompute cost savings of 1.8x for training the full model family (15B, 8B, and\n4B). Minitron models exhibit up to a 16% improvement in MMLU scores compared to\ntraining from scratch, perform comparably to other community models such as\nMistral 7B, Gemma 7B and Llama-3 8B, and outperform state-of-the-art\ncompression techniques from the literature. We have open-sourced Minitron model\nweights on Huggingface, with corresponding supplementary material including\nexample code available on GitHub.", "published": "2024-07-19 21:47:57", "link": "http://arxiv.org/abs/2407.14679v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LAPIS: Language Model-Augmented Police Investigation System", "abstract": "Crime situations are race against time. An AI-assisted criminal investigation\nsystem, providing prompt but precise legal counsel is in need for police\nofficers. We introduce LAPIS (Language Model Augmented Police Investigation\nSystem), an automated system that assists police officers to perform rational\nand legal investigative actions. We constructed a finetuning dataset and\nretrieval knowledgebase specialized in crime investigation legal reasoning\ntask. We extended the dataset's quality by incorporating manual curation\nefforts done by a group of domain experts. We then finetuned the pretrained\nweights of a smaller Korean language model to the newly constructed dataset and\nintegrated it with the crime investigation knowledgebase retrieval approach.\nExperimental results show LAPIS' potential in providing reliable legal guidance\nfor police officers, even better than the proprietary GPT-4 model. Qualitative\nanalysis on the rationales generated by LAPIS demonstrate the model's reasoning\nability to leverage the premises and derive legally correct conclusions.", "published": "2024-07-19 09:24:29", "link": "http://arxiv.org/abs/2407.20248v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Advancing Chart Question Answering with Robust Chart Component\n  Recognition", "abstract": "Chart comprehension presents significant challenges for machine learning\nmodels due to the diverse and intricate shapes of charts. Existing multimodal\nmethods often overlook these visual features or fail to integrate them\neffectively for chart question answering (ChartQA). To address this, we\nintroduce Chartformer, a unified framework that enhances chart component\nrecognition by accurately identifying and classifying components such as bars,\nlines, pies, titles, legends, and axes. Additionally, we propose a novel\nQuestion-guided Deformable Co-Attention (QDCAt) mechanism, which fuses chart\nfeatures encoded by Chartformer with the given question, leveraging the\nquestion's guidance to ground the correct answer. Extensive experiments\ndemonstrate that the proposed approaches significantly outperform baseline\nmodels in chart component recognition and ChartQA tasks, achieving improvements\nof 3.2% in mAP and 15.4% in accuracy, respectively. These results underscore\nthe robustness of our solution for detailed visual data interpretation across\nvarious applications.", "published": "2024-07-19 20:55:06", "link": "http://arxiv.org/abs/2407.21038v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "The Vision of Autonomic Computing: Can LLMs Make It a Reality?", "abstract": "The Vision of Autonomic Computing (ACV), proposed over two decades ago,\nenvisions computing systems that self-manage akin to biological organisms,\nadapting seamlessly to changing environments. Despite decades of research,\nachieving ACV remains challenging due to the dynamic and complex nature of\nmodern computing systems. Recent advancements in Large Language Models (LLMs)\noffer promising solutions to these challenges by leveraging their extensive\nknowledge, language understanding, and task automation capabilities. This paper\nexplores the feasibility of realizing ACV through an LLM-based multi-agent\nframework for microservice management. We introduce a five-level taxonomy for\nautonomous service maintenance and present an online evaluation benchmark based\non the Sock Shop microservice demo project to assess our framework's\nperformance. Our findings demonstrate significant progress towards achieving\nLevel 3 autonomy, highlighting the effectiveness of LLMs in detecting and\nresolving issues within microservice architectures. This study contributes to\nadvancing autonomic computing by pioneering the integration of LLMs into\nmicroservice management frameworks, paving the way for more adaptive and\nself-managing computing systems. The code will be made available at\nhttps://aka.ms/ACV-LLM.", "published": "2024-07-19 15:30:32", "link": "http://arxiv.org/abs/2407.14402v1", "categories": ["cs.AI", "cs.CL", "cs.DC", "cs.MA", "cs.SE"], "primary_category": "cs.AI"}
{"title": "MSceneSpeech: A Multi-Scene Speech Dataset For Expressive Speech\n  Synthesis", "abstract": "We introduce an open source high-quality Mandarin TTS dataset MSceneSpeech\n(Multiple Scene Speech Dataset), which is intended to provide resources for\nexpressive speech synthesis. MSceneSpeech comprises numerous audio recordings\nand texts performed and recorded according to daily life scenarios. Each\nscenario includes multiple speakers and a diverse range of prosodic styles,\nmaking it suitable for speech synthesis that entails multi-speaker style and\nprosody modeling. We have established a robust baseline, through the prompting\nmechanism, that can effectively synthesize speech characterized by both\nuser-specific timbre and scene-specific prosody with arbitrary text input. The\nopen source MSceneSpeech Dataset and audio samples of our baseline are\navailable at https://speechai-demo.github.io/MSceneSpeech/.", "published": "2024-07-19 03:36:48", "link": "http://arxiv.org/abs/2407.14006v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Wideband Relative Transfer Function (RTF) Estimation Exploiting\n  Frequency Correlations", "abstract": "This article focuses on estimating relative transfer functions (RTFs) for\nbeamforming applications. Traditional methods often assume that spectra are\nuncorrelated, an assumption that is often violated in practical scenarios due\nto factors such as time-domain windowing or the non-stationary nature of\nsignals, as observed in speech. To overcome these limitations, we propose an\nRTF estimation technique that leverages spectral and spatial correlations\nthrough subspace analysis. Additionally, we derive Cram\\'er--Rao bounds (CRBs)\nfor the RTF estimation task, providing theoretical insights into the achievable\nestimation accuracy. These bounds reveal that channel estimation can be\nperformed more accurately if the noise or the target signal exhibits spectral\ncorrelations. Experiments with both real and synthetic data show that our\ntechnique outperforms the narrowband maximum-likelihood estimator, known as\ncovariance whitening (CW), when the target exhibits spectral correlations.\nAlthough the proposed algorithm generally achieves accuracy close to the\ntheoretical bound, there is potential for further improvement, especially in\nscenarios with highly spectrally correlated noise. While channel estimation has\nvarious applications, we demonstrate the method using a minimum variance\ndistortionless (MVDR) beamformer for multichannel speech enhancement. A free\nPython implementation is also provided.", "published": "2024-07-19 09:30:06", "link": "http://arxiv.org/abs/2407.14152v2", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Topology-Independent GEVD-Based Distributed Adaptive Node-Specific\n  Signal Estimation in Ad-Hoc Wireless Acoustic Sensor Networks", "abstract": "A low-rank approximation-based version of the topology-independent\ndistributed adaptive node-specific signal estimation (TI-DANSE) algorithm is\nintroduced, using a generalized eigenvalue decomposition (GEVD) for application\nin ad-hoc wireless acoustic sensor networks. This TI-GEVD-DANSE algorithm as\nwell as the original TI-DANSE algorithm exhibit a non-strict convergence, which\ncan lead to numerical instability over time, particularly in scenarios where\nthe estimation of accurate spatial covariance matrices is challenging. An\nadaptive filter coefficient normalization strategy is proposed to mitigate this\nissue and enable the stable performance of TI-(GEVD-)DANSE. The method is\nvalidated in numerical simulations including dynamic acoustic scenarios,\ndemonstrating the importance of the additional normalization.", "published": "2024-07-19 10:00:59", "link": "http://arxiv.org/abs/2407.14172v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Efficient Audio Captioning with Encoder-Level Knowledge Distillation", "abstract": "Significant improvement has been achieved in automated audio captioning (AAC)\nwith recent models. However, these models have become increasingly large as\ntheir performance is enhanced. In this work, we propose a knowledge\ndistillation (KD) framework for AAC. Our analysis shows that in the\nencoder-decoder based AAC models, it is more effective to distill knowledge\ninto the encoder as compared with the decoder. To this end, we incorporate\nencoder-level KD loss into training, in addition to the standard supervised\nloss and sequence-level KD loss. We investigate two encoder-level KD methods,\nbased on mean squared error (MSE) loss and contrastive loss, respectively.\nExperimental results demonstrate that contrastive KD is more robust than MSE\nKD, exhibiting superior performance in data-scarce situations. By leveraging\naudio-only data into training in the KD framework, our student model achieves\ncompetitive performance, with an inference speed that is 19 times\nfaster\\footnote{An online demo is available at\n\\url{https://huggingface.co/spaces/wsntxxn/efficient_audio_captioning}}.", "published": "2024-07-19 14:09:50", "link": "http://arxiv.org/abs/2407.14329v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhancing Zero-shot Audio Classification using Sound Attribute Knowledge\n  from Large Language Models", "abstract": "Zero-shot audio classification aims to recognize and classify a sound class\nthat the model has never seen during training. This paper presents a novel\napproach for zero-shot audio classification using automatically generated sound\nattribute descriptions. We propose a list of sound attributes and leverage\nlarge language model's domain knowledge to generate detailed attribute\ndescriptions for each class. In contrast to previous works that primarily\nrelied on class labels or simple descriptions, our method focuses on\nmulti-dimensional innate auditory attributes, capturing different\ncharacteristics of sound classes. Additionally, we incorporate a contrastive\nlearning approach to enhance zero-shot learning from textual labels. We\nvalidate the effectiveness of our method on VGGSound and AudioSet\\footnote{The\ncode is available at \\url{https://www.github.com/wsntxxn/AttrEnhZsAc}.}. Our\nresults demonstrate a substantial improvement in zero-shot classification\naccuracy. Ablation results show robust performance enhancement, regardless of\nthe model architecture.", "published": "2024-07-19 14:35:31", "link": "http://arxiv.org/abs/2407.14355v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PolySinger: Singing-Voice to Singing-Voice Translation from English to\n  Japanese", "abstract": "The speech domain prevails in the spotlight for several natural language\nprocessing (NLP) tasks while the singing domain remains less explored. The\nculmination of NLP is the speech-to-speech translation (S2ST) task, referring\nto translation and synthesis of human speech. A disparity between S2ST and the\npossible adaptation to the singing domain, which we describe as singing-voice\nto singing-voice translation (SV2SVT), is becoming prominent as the former is\nprogressing ever faster, while the latter is at a standstill. Singing-voice\nsynthesis systems are overcoming the barrier of multi-lingual synthesis,\ndespite limited attention has been paid to multi-lingual songwriting and song\ntranslation. This paper endeavors to determine what is required for successful\nSV2SVT and proposes PolySinger (Polyglot Singer): the first system for SV2SVT,\nperforming lyrics translation from English to Japanese. A cascaded approach is\nproposed to establish a framework with a high degree of control which can\npotentially diminish the disparity between SV2SVT and S2ST. The performance of\nPolySinger is evaluated by a mean opinion score test with native Japanese\nspeakers. Results and in-depth discussions with test subjects suggest a solid\nfoundation for SV2SVT, but several shortcomings must be overcome, which are\ndiscussed for the future of SV2SVT.", "published": "2024-07-19 15:21:14", "link": "http://arxiv.org/abs/2407.14399v1", "categories": ["eess.AS", "cs.IR"], "primary_category": "eess.AS"}
{"title": "GE2E-AC: Generalized End-to-End Loss Training for Accent Classification", "abstract": "Accent classification or AC is a task to predict the accent type of an input\nutterance, and it can be used as a preliminary step toward accented speech\nrecognition and accent conversion. Existing studies have often achieved such\nclassification by training a neural network model to minimize the\nclassification error of the predicted accent label, which can be obtained as a\nmodel output. Since we optimize the entire model only from the perspective of\nclassification loss during training time in this approach, the model might\nlearn to predict the accent type from irrelevant features, such as individual\nspeaker identity, which are not informative during test time. To address this\nproblem, we propose a GE2E-AC, in which we train a model to extract accent\nembedding or AE of an input utterance such that the AEs of the same accent\nclass get closer, instead of directly minimizing the classification loss. We\nexperimentally show the effectiveness of the proposed GE2E-AC, compared to the\nbaseline model trained with the conventional cross-entropy-based loss.", "published": "2024-07-19 04:44:16", "link": "http://arxiv.org/abs/2407.14021v2", "categories": ["eess.AS", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Stable Audio Open", "abstract": "Open generative models are vitally important for the community, allowing for\nfine-tunes and serving as baselines when presenting new models. However, most\ncurrent text-to-audio models are private and not accessible for artists and\nresearchers to build upon. Here we describe the architecture and training\nprocess of a new open-weights text-to-audio model trained with Creative Commons\ndata. Our evaluation shows that the model's performance is competitive with the\nstate-of-the-art across various metrics. Notably, the reported FDopenl3 results\n(measuring the realism of the generations) showcase its potential for\nhigh-quality stereo sound synthesis at 44.1kHz.", "published": "2024-07-19 14:40:23", "link": "http://arxiv.org/abs/2407.14358v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Assessing Data Replication in Music Generation with Music\n  Similarity Metrics on Raw Audio", "abstract": "Recent advancements in music generation are raising multiple concerns about\nthe implications of AI in creative music processes, current business models and\nimpacts related to intellectual property management. A relevant discussion and\nrelated technical challenge is the potential replication and plagiarism of the\ntraining set in AI-generated music, which could lead to misuse of data and\nintellectual property rights violations. To tackle this issue, we present the\nMusic Replication Assessment (MiRA) tool: a model-independent open evaluation\nmethod based on diverse audio music similarity metrics to assess data\nreplication. We evaluate the ability of five metrics to identify exact\nreplication by conducting a controlled replication experiment in different\nmusic genres using synthetic samples. Our results show that the proposed\nmethodology can estimate exact data replication with a proportion higher than\n10%. By introducing the MiRA tool, we intend to encourage the open evaluation\nof music-generative models by researchers, developers, and users concerning\ndata replication, highlighting the importance of the ethical, social, legal,\nand economic consequences. Code and examples are available for reproducibility\npurposes.", "published": "2024-07-19 14:52:11", "link": "http://arxiv.org/abs/2407.14364v2", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Composer's Assistant 2: Interactive Multi-Track MIDI Infilling with\n  Fine-Grained User Control", "abstract": "We introduce Composer's Assistant 2, a system for interactive human-computer\ncomposition in the REAPER digital audio workstation. Our work upgrades the\nComposer's Assistant system (which performs multi-track infilling of symbolic\nmusic at the track-measure level) with a wide range of new controls to give\nusers fine-grained control over the system's outputs. Controls introduced in\nthis work include two types of rhythmic conditioning controls, horizontal and\nvertical note onset density controls, several types of pitch controls, and a\nrhythmic interest control. We train a T5-like transformer model to implement\nthese controls and to serve as the backbone of our system. With these controls,\nwe achieve a dramatic improvement in objective metrics over the original\nsystem. We also study how well our model understands the meaning of our\ncontrols, and we conduct a listening study that does not find a significant\ndifference between real music and music composed in a co-creative fashion with\nour system. We release our complete system, consisting of source code,\npretrained models, and REAPER scripts.", "published": "2024-07-19 23:28:09", "link": "http://arxiv.org/abs/2407.14700v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
