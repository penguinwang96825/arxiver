{"title": "An unsupervised and customizable misspelling generator for mining noisy\n  health-related text sources", "abstract": "In this paper, we present a customizable datacentric system that\nautomatically generates common misspellings for complex health-related terms.\nThe spelling variant generator relies on a dense vector model learned from\nlarge unlabeled text, which is used to find semantically close terms to the\noriginal/seed keyword, followed by the filtering of terms that are lexically\ndissimilar beyond a given threshold. The process is executed recursively,\nconverging when no new terms similar (lexically and semantically) to the seed\nkeyword are found. Weighting of intra-word character sequence similarities\nallows further problem-specific customization of the system. On a dataset\nprepared for this study, our system outperforms the current state-of-the-art\nfor medication name variant generation with best F1-score of 0.69 and\nF1/4-score of 0.78. Extrinsic evaluation of the system on a set of\ncancer-related terms showed an increase of over 67% in retrieval rate from\nTwitter posts when the generated variants are included. Our proposed spelling\nvariant generator has several advantages over the current state-of-the-art and\nother types of variant generators-(i) it is capable of filtering out lexically\nsimilar but semantically dissimilar terms, (ii) the number of variants\ngenerated is low as many low-frequency and ambiguous misspellings are filtered\nout, and (iii) the system is fully automatic, customizable and easily\nexecutable. While the base system is fully unsupervised, we show how\nsupervision maybe employed to adjust weights for task-specific customization.\nThe performance and significant relative simplicity of our proposed approach\nmakes it a much needed misspelling generation resource for health-related text\nmining from noisy sources. The source code for the system has been made\npublicly available for research purposes.", "published": "2018-06-04 01:07:37", "link": "http://arxiv.org/abs/1806.00910v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Normalization Properties of Language Modeling", "abstract": "Self-normalizing discriminative models approximate the normalized probability\nof a class without having to compute the partition function. In the context of\nlanguage modeling, this property is particularly appealing as it may\nsignificantly reduce run-times due to large word vocabularies. In this study,\nwe provide a comprehensive investigation of language modeling\nself-normalization. First, we theoretically analyze the inherent\nself-normalization properties of Noise Contrastive Estimation (NCE) language\nmodels. Then, we compare them empirically to softmax-based approaches, which\nare self-normalized using explicit regularization, and suggest a hybrid model\nwith compelling properties. Finally, we uncover a surprising negative\ncorrelation between self-normalization and perplexity across the board, as well\nas some regularity in the observed errors, which may potentially be used for\nimproving self-normalization algorithms in the future.", "published": "2018-06-04 01:20:59", "link": "http://arxiv.org/abs/1806.00913v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DRCD: a Chinese Machine Reading Comprehension Dataset", "abstract": "In this paper, we introduce DRCD (Delta Reading Comprehension Dataset), an\nopen domain traditional Chinese machine reading comprehension (MRC) dataset.\nThis dataset aimed to be a standard Chinese machine reading comprehension\ndataset, which can be a source dataset in transfer learning. The dataset\ncontains 10,014 paragraphs from 2,108 Wikipedia articles and 30,000+ questions\ngenerated by annotators. We build a baseline model that achieves an F1 score of\n89.59%. F1 score of Human performance is 93.30%.", "published": "2018-06-04 01:50:21", "link": "http://arxiv.org/abs/1806.00920v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Adversarial Training for Semi-supervised Japanese\n  Predicate-argument Structure Analysis", "abstract": "Japanese predicate-argument structure (PAS) analysis involves zero anaphora\nresolution, which is notoriously difficult. To improve the performance of\nJapanese PAS analysis, it is straightforward to increase the size of corpora\nannotated with PAS. However, since it is prohibitively expensive, it is\npromising to take advantage of a large amount of raw corpora. In this paper, we\npropose a novel Japanese PAS analysis model based on semi-supervised\nadversarial training with a raw corpus. In our experiments, our model\noutperforms existing state-of-the-art models for Japanese PAS analysis.", "published": "2018-06-04 06:26:19", "link": "http://arxiv.org/abs/1806.00971v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Topic Modelling of Empirical Text Corpora: Validity, Reliability, and\n  Reproducibility in Comparison to Semantic Maps", "abstract": "Using the 6,638 case descriptions of societal impact submitted for evaluation\nin the Research Excellence Framework (REF 2014), we replicate the topic model\n(Latent Dirichlet Allocation or LDA) made in this context and compare the\nresults with factor-analytic results using a traditional word-document matrix\n(Principal Component Analysis or PCA). Removing a small fraction of documents\nfrom the sample, for example, has on average a much larger impact on LDA than\non PCA-based models to the extent that the largest distortion in the case of\nPCA has less effect than the smallest distortion of LDA-based models. In terms\nof semantic coherence, however, LDA models outperform PCA-based models. The\ntopic models inform us about the statistical properties of the document sets\nunder study, but the results are statistical and should not be used for a\nsemantic interpretation - for example, in grant selections and micro-decision\nmaking, or scholarly work-without follow-up using domain-specific semantic\nmaps.", "published": "2018-06-04 11:03:11", "link": "http://arxiv.org/abs/1806.01045v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Online Scalar Annotation with Bounded Support", "abstract": "We describe a novel method for efficiently eliciting scalar annotations for\ndataset construction and system quality estimation by human judgments. We\ncontrast direct assessment (annotators assign scores to items directly), online\npairwise ranking aggregation (scores derive from annotator comparison of\nitems), and a hybrid approach (EASL: Efficient Annotation of Scalar Labels)\nproposed here. Our proposal leads to increased correlation with ground truth,\nat far greater annotator efficiency, suggesting this strategy as an improved\nmechanism for dataset creation and manual system evaluation.", "published": "2018-06-04 16:10:19", "link": "http://arxiv.org/abs/1806.01170v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "History Playground: A Tool for Discovering Temporal Trends in Massive\n  Textual Corpora", "abstract": "Recent studies have shown that macroscopic patterns of continuity and change\nover the course of centuries can be detected through the analysis of time\nseries extracted from massive textual corpora. Similar data-driven approaches\nhave already revolutionised the natural sciences, and are widely believed to\nhold similar potential for the humanities and social sciences, driven by the\nmass-digitisation projects that are currently under way, and coupled with the\never-increasing number of documents which are \"born digital\". As such, new\ninteractive tools are required to discover and extract macroscopic patterns\nfrom these vast quantities of textual data. Here we present History Playground,\nan interactive web-based tool for discovering trends in massive textual\ncorpora. The tool makes use of scalable algorithms to first extract trends from\ntextual corpora, before making them available for real-time search and\ndiscovery, presenting users with an interface to explore the data. Included in\nthe tool are algorithms for standardization, regression, change-point detection\nin the relative frequencies of ngrams, multi-term indices and comparison of\ntrends across different corpora.", "published": "2018-06-04 16:30:03", "link": "http://arxiv.org/abs/1806.01185v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Closed Form Word Embedding Alignment", "abstract": "We develop a family of techniques to align word embeddings which are derived\nfrom different source datasets or created using different mechanisms (e.g.,\nGloVe or word2vec). Our methods are simple and have a closed form to optimally\nrotate, translate, and scale to minimize root mean squared errors or maximize\nthe average cosine similarity between two embeddings of the same vocabulary\ninto the same dimensional space. Our methods extend approaches known as\nAbsolute Orientation, which are popular for aligning objects in\nthree-dimensions, and generalize an approach by Smith etal (ICLR 2017). We\nprove new results for optimal scaling and for maximizing cosine similarity.\nThen we demonstrate how to evaluate the similarity of embeddings from different\nsources or mechanisms, and that certain properties like synonyms and analogies\nare preserved across the embeddings and can be enhanced by simply aligning and\naveraging ensembles of embeddings.", "published": "2018-06-04 19:03:52", "link": "http://arxiv.org/abs/1806.01330v4", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Voice Imitating Text-to-Speech Neural Networks", "abstract": "We propose a neural text-to-speech (TTS) model that can imitate a new\nspeaker's voice using only a small amount of speech sample. We demonstrate\nvoice imitation using only a 6-seconds long speech sample without any other\ninformation such as transcripts. Our model also enables voice imitation\ninstantly without additional training of the model. We implemented the voice\nimitating TTS model by combining a speaker embedder network with a\nstate-of-the-art TTS model, Tacotron. The speaker embedder network takes a new\nspeaker's speech sample and returns a speaker embedding. The speaker embedding\nwith a target sentence are fed to Tacotron, and speech is generated with the\nnew speaker's voice. We show that the speaker embeddings extracted by the\nspeaker embedder network can represent the latent structure in different\nvoices. The generated speech samples from our model have comparable voice\nquality to the ones from existing multi-speaker TTS models.", "published": "2018-06-04 02:10:48", "link": "http://arxiv.org/abs/1806.00927v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DNN-HMM based Speaker Adaptive Emotion Recognition using Proposed Epoch\n  and MFCC Features", "abstract": "Speech is produced when time varying vocal tract system is excited with time\nvarying excitation source. Therefore, the information present in a speech such\nas message, emotion, language, speaker is due to the combined effect of both\nexcitation source and vocal tract system. However, there is very less\nutilization of excitation source features to recognize emotion. In our earlier\nwork, we have proposed a novel method to extract glottal closure instants\n(GCIs) known as epochs. In this paper, we have explored epoch features namely\ninstantaneous pitch, phase and strength of epochs for discriminating emotions.\nWe have combined the excitation source features and the well known\nMale-frequency cepstral coefficient (MFCC) features to develop an emotion\nrecognition system with improved performance. DNN-HMM speaker adaptive models\nhave been developed using MFCC, epoch and combined features. IEMOCAP emotional\ndatabase has been used to evaluate the models. The average accuracy for emotion\nrecognition system when using MFCC and epoch features separately is 59.25% and\n54.52% respectively. The recognition performance improves to 64.2% when MFCC\nand epoch features are combined.", "published": "2018-06-04 06:58:45", "link": "http://arxiv.org/abs/1806.00984v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Revisiting Singing Voice Detection: a Quantitative Review and the Future\n  Outlook", "abstract": "Since the vocal component plays a crucial role in popular music, singing\nvoice detection has been an active research topic in music information\nretrieval. Although several proposed algorithms have shown high performances,\nwe argue that there still is a room to improve to build a more robust singing\nvoice detection system. In order to identify the area of improvement, we first\nperform an error analysis on three recent singing voice detection systems.\nBased on the analysis, we design novel methods to test the systems on multiple\nsets of internally curated and generated data to further examine the pitfalls,\nwhich are not clearly revealed with the current datasets. From the experiment\nresults, we also propose several directions towards building a more robust\nsinging voice detector.", "published": "2018-06-04 16:25:37", "link": "http://arxiv.org/abs/1806.01180v1", "categories": ["cs.SD", "cs.IR", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
