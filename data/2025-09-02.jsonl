{"title": "A-SEA3L-QA: A Fully Automated Self-Evolving, Adversarial Workflow for Arabic Long-Context Question-Answer Generation", "abstract": "We present an end-to-end, self-evolving adversarial workflow for long-context\nQuestion-Answer (QA) Generation in Arabic. By orchestrating multiple\nspecialized LVLMs: a question generator, an evaluator, and a swarm of answer\ngenerators, our system iteratively refines its own performance without any\nhuman intervention. Starting from raw, multi-page Arabic documents across\ndiverse domains, the question generator produces fine-grained, context-aware\nqueries to be tackled by the answer generator swarm, and the evaluator assesses\nand feeds back quality metrics. This closed-loop cycle enables continuous\nlearning: low-confidence outputs trigger automated re-generation and model\nupdates, progressively enhancing question difficulty and relevance. Moreover,\nwe set the quality metrics as a tunable hyperparameter, enabling question\ngeneration at controllable and customizable difficulty levels. We release\nAraLongBench, a large-scale Arabic benchmark of single- and multi-page\nchallenges spanning hundreds of pages, and demonstrate that our self-evolving\nworkflow substantially outperform static pipelines, markedly boosting the\nlong-context comprehension capabilities of leading Arabic Large Vision Language\nModels (LVLMs). Lastly, we also meticulously architect a fully automated\nagentic workflow for long-context Arabic document collection.", "published": "2025-09-02 22:21:55", "link": "http://arxiv.org/abs/2509.02864v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Speech DF Arena: A Leaderboard for Speech DeepFake Detection Models", "abstract": "Parallel to the development of advanced deepfake audio generation, audio\ndeepfake detection has also seen significant progress. However, a standardized\nand comprehensive benchmark is still missing. To address this, we introduce\nSpeech DeepFake (DF) Arena, the first comprehensive benchmark for audio\ndeepfake detection. Speech DF Arena provides a toolkit to uniformly evaluate\ndetection systems, currently across 14 diverse datasets and attack scenarios,\nstandardized evaluation metrics and protocols for reproducibility and\ntransparency. It also includes a leaderboard to compare and rank the systems to\nhelp researchers and developers enhance their reliability and robustness. We\ninclude 14 evaluation sets, 12 state-of-the-art open-source and 3 proprietary\ndetection systems. Our study presents many systems exhibiting high EER in\nout-of-domain scenarios, highlighting the need for extensive cross-domain\nevaluation. The leaderboard is hosted on Huggingface1 and a toolkit for\nreproducing results across the listed datasets is available on GitHub.", "published": "2025-09-02 22:11:29", "link": "http://arxiv.org/abs/2509.02859v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "IDEAlign: Comparing Large Language Models to Human Experts in Open-ended Interpretive Annotations", "abstract": "Large language models (LLMs) are increasingly applied to open-ended,\ninterpretive annotation tasks, such as thematic analysis by researchers or\ngenerating feedback on student work by teachers. These tasks involve free-text\nannotations requiring expert-level judgments grounded in specific objectives\n(e.g., research questions or instructional goals). Evaluating whether\nLLM-generated annotations align with those generated by expert humans is\nchallenging to do at scale, and currently, no validated, scalable measure of\nsimilarity in ideas exists. In this paper, we (i) introduce the scalable\nevaluation of interpretive annotation by LLMs as a critical and understudied\ntask, (ii) propose IDEAlgin, an intuitive benchmarking paradigm for capturing\nexpert similarity ratings via a \"pick-the-odd-one-out\" triplet judgment task,\nand (iii) evaluate various similarity metrics, including vector-based ones\n(topic models, embeddings) and LLM-as-a-judge via IDEAlgin, against these human\nbenchmarks. Applying this approach to two real-world educational datasets\n(interpretive analysis and feedback generation), we find that vector-based\nmetrics largely fail to capture the nuanced dimensions of similarity meaningful\nto experts. Prompting LLMs via IDEAlgin significantly improves alignment with\nexpert judgments (9-30% increase) compared to traditional lexical and\nvector-based metrics. These results establish IDEAlgin as a promising paradigm\nfor evaluating LLMs against open-ended expert annotations at scale, informing\nresponsible deployment of LLMs in education and beyond.", "published": "2025-09-02 21:58:58", "link": "http://arxiv.org/abs/2509.02855v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Clustering Discourses: Racial Biases in Short Stories about Women Generated by Large Language Models", "abstract": "This study investigates how large language models, in particular LLaMA\n3.2-3B, construct narratives about Black and white women in short stories\ngenerated in Portuguese. From 2100 texts, we applied computational methods to\ngroup semantically similar stories, allowing a selection for qualitative\nanalysis. Three main discursive representations emerge: social overcoming,\nancestral mythification and subjective self-realization. The analysis uncovers\nhow grammatically coherent, seemingly neutral texts materialize a crystallized,\ncolonially structured framing of the female body, reinforcing historical\ninequalities. The study proposes an integrated approach, that combines machine\nlearning techniques with qualitative, manual discourse analysis.", "published": "2025-09-02 21:01:02", "link": "http://arxiv.org/abs/2509.02834v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SSVD: Structured SVD for Parameter-Efficient Fine-Tuning and Benchmarking under Domain Shift in ASR", "abstract": "Parameter-efficient fine-tuning (PEFT) has emerged as a scalable solution for\nadapting large foundation models. While low-rank adaptation (LoRA) is widely\nused in speech applications, its state-of-the-art variants, e.g., VeRA, DoRA,\nPiSSA, and SVFT, are developed mainly for language and vision tasks, with\nlimited validation in speech. This work presents the first comprehensive\nintegration and benchmarking of these PEFT methods within ESPnet. We further\nintroduce structured SVD-guided (SSVD) fine-tuning, which selectively rotates\ninput-associated right singular vectors while keeping output-associated vectors\nfixed to preserve semantic mappings. This design enables robust domain\nadaptation with minimal trainable parameters and improved efficiency. We\nevaluate all methods on domain-shifted speech recognition tasks, including\nchild speech and dialectal variation, across model scales from 0.1B to 2B. All\nimplementations are released in ESPnet to support reproducibility and future\nwork.", "published": "2025-09-02 20:51:17", "link": "http://arxiv.org/abs/2509.02830v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "DrDiff: Dynamic Routing Diffusion with Hierarchical Attention for Breaking the Efficiency-Quality Trade-off", "abstract": "This paper introduces DrDiff, a novel framework for long-text generation that\novercomes the efficiency-quality trade-off through three core technologies.\nFirst, we design a dynamic expert scheduling mechanism that intelligently\nallocates computational resources during the diffusion process based on text\ncomplexity, enabling more efficient handling of text generation tasks of\nvarying difficulty. Second, we introduce a Hierarchical Sparse Attention (HSA)\nmechanism that adaptively adjusts attention patterns according to a variety of\ninput lengths, reducing computational complexity from O($n^2$) to O($n$) while\nmaintaining model performance. Finally, we propose a soft absorption guidance\noptimization strategy that combines with DPM-solver++ to reduce diffusion\nsteps, significantly improving generation speed. Comprehensive experiments on\nvarious long-text generation benchmarks demonstrate the superiority of our\nDrDiff over the existing SOTA methods.", "published": "2025-09-02 19:38:49", "link": "http://arxiv.org/abs/2509.02785v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DynaGuard: A Dynamic Guardrail Model With User-Defined Policies", "abstract": "Guardian models are used to supervise and moderate the outputs of user-facing\nchatbots, enforcing guardrails and detecting bad behaviors. Standard guardian\nmodels like LlamaGuard detect predefined, static categories of harms. We\npropose dynamic guardian models that evaluate text based on user-defined\npolicies, making them useful for different application domains that are not\naddressed by standard guardian models. Our dynamic guardian models can be used\nfor fast detection of policy violations or with chain-of-thought reasoning that\narticulates and justifies the model outputs. Our dynamic guardian models match\nstatic models in detection accuracy for static harm categories while\nidentifying violations of free-form policies with accuracy comparable to\nfrontier reasoning models in a fraction of the time.", "published": "2025-09-02 17:57:56", "link": "http://arxiv.org/abs/2509.02563v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "PalmX 2025: The First Shared Task on Benchmarking LLMs on Arabic and Islamic Culture", "abstract": "Large Language Models (LLMs) inherently reflect the vast data distributions\nthey encounter during their pre-training phase. As this data is predominantly\nsourced from the web, there is a high chance it will be skewed towards\nhigh-resourced languages and cultures, such as those of the West. Consequently,\nLLMs often exhibit a diminished understanding of certain communities, a gap\nthat is particularly evident in their knowledge of Arabic and Islamic cultures.\nThis issue becomes even more pronounced with increasingly under-represented\ntopics. To address this critical challenge, we introduce PalmX 2025, the first\nshared task designed to benchmark the cultural competence of LLMs in these\nspecific domains. The task is composed of two subtasks featuring\nmultiple-choice questions (MCQs) in Modern Standard Arabic (MSA): General\nArabic Culture and General Islamic Culture. These subtasks cover a wide range\nof topics, including traditions, food, history, religious practices, and\nlanguage expressions from across 22 Arab countries. The initiative drew\nconsiderable interest, with 26 teams registering for Subtask 1 and 19 for\nSubtask 2, culminating in nine and six valid submissions, respectively. Our\nfindings reveal that task-specific fine-tuning substantially boosts performance\nover baseline models. The top-performing systems achieved an accuracy of 72.15%\non cultural questions and 84.22% on Islamic knowledge. Parameter-efficient\nfine-tuning emerged as the predominant and most effective approach among\nparticipants, while the utility of data augmentation was found to be\ndomain-dependent.", "published": "2025-09-02 17:48:51", "link": "http://arxiv.org/abs/2509.02550v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Landscape of Agentic Reinforcement Learning for LLMs: A Survey", "abstract": "The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm\nshift from conventional reinforcement learning applied to large language models\n(LLM RL), reframing LLMs from passive sequence generators into autonomous,\ndecision-making agents embedded in complex, dynamic worlds. This survey\nformalizes this conceptual shift by contrasting the degenerate single-step\nMarkov Decision Processes (MDPs) of LLM-RL with the temporally extended,\npartially observable Markov decision processes (POMDPs) that define Agentic RL.\nBuilding on this foundation, we propose a comprehensive twofold taxonomy: one\norganized around core agentic capabilities, including planning, tool use,\nmemory, reasoning, self-improvement, and perception, and the other around their\napplications across diverse task domains. Central to our thesis is that\nreinforcement learning serves as the critical mechanism for transforming these\ncapabilities from static, heuristic modules into adaptive, robust agentic\nbehavior. To support and accelerate future research, we consolidate the\nlandscape of open-source environments, benchmarks, and frameworks into a\npractical compendium. By synthesizing over five hundred recent works, this\nsurvey charts the contours of this rapidly evolving field and highlights the\nopportunities and challenges that will shape the development of scalable,\ngeneral-purpose AI agents.", "published": "2025-09-02 17:46:26", "link": "http://arxiv.org/abs/2509.02547v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning", "abstract": "The development of autonomous agents for graphical user interfaces (GUIs)\npresents major challenges in artificial intelligence. While recent advances in\nnative agent models have shown promise by unifying perception, reasoning,\naction, and memory through end-to-end learning, open problems remain in data\nscalability, multi-turn reinforcement learning (RL), the limitations of\nGUI-only operation, and environment stability. In this technical report, we\npresent UI-TARS-2, a native GUI-centered agent model that addresses these\nchallenges through a systematic training methodology: a data flywheel for\nscalable data generation, a stabilized multi-turn RL framework, a hybrid GUI\nenvironment that integrates file systems and terminals, and a unified sandbox\nplatform for large-scale rollouts. Empirical evaluation demonstrates that\nUI-TARS-2 achieves significant improvements over its predecessor UI-TARS-1.5.\nOn GUI benchmarks, it reaches 88.2 on Online-Mind2Web, 47.5 on OSWorld, 50.6 on\nWindowsAgentArena, and 73.3 on AndroidWorld, outperforming strong baselines\nsuch as Claude and OpenAI agents. In game environments, it attains a mean\nnormalized score of 59.8 across a 15-game suite-roughly 60% of human-level\nperformance-and remains competitive with frontier proprietary models (e.g.,\nOpenAI o3) on LMGame-Bench. Additionally, the model can generalize to\nlong-horizon information-seeking tasks and software engineering benchmarks,\nhighlighting its robustness across diverse agent tasks. Detailed analyses of\ntraining dynamics further provide insights into achieving stability and\nefficiency in large-scale agent RL. These results underscore UI-TARS-2's\npotential to advance the state of GUI agents and exhibit strong generalization\nto real-world interactive scenarios.", "published": "2025-09-02 17:44:45", "link": "http://arxiv.org/abs/2509.02544v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Jointly Reinforcing Diversity and Quality in Language Model Generations", "abstract": "Post-training of Large Language Models (LMs) often prioritizes accuracy and\nhelpfulness at the expense of diversity. This creates a tension: while\npost-training improves response quality, it also sharpens output distributions\nand reduces the range of ideas, limiting the usefulness of LMs in creative and\nexploratory tasks such as brainstorming, storytelling, or problem solving. We\naddress this challenge with Diversity-Aware Reinforcement Learning (DARLING), a\nframework that jointly optimizes for response quality and semantic diversity.\nAt its core, DARLING introduces a learned partition function to measure\ndiversity beyond surface-level lexical variations. This diversity signal is\nthen combined with a quality reward during online reinforcement learning,\nencouraging models to generate outputs that are both high-quality and distinct.\nExperiments across multiple model families and sizes show that DARLING\ngeneralizes to two regimes: non-verifiable tasks (instruction following and\ncreative writing) and verifiable tasks (competition math). On five benchmarks\nin the first setting, DARLING consistently outperforms quality-only RL\nbaselines, producing outputs that are simultaneously of higher quality and\nnovelty. In the second setting, DARLING achieves higher pass@1 (solution\nquality) and pass@k (solution variety). Most strikingly, explicitly optimizing\nfor diversity catalyzes exploration in online RL, which manifests itself as\nhigher-quality responses.", "published": "2025-09-02 17:38:47", "link": "http://arxiv.org/abs/2509.02534v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Flavors of Moonshine: Tiny Specialized ASR Models for Edge Devices", "abstract": "We present the Flavors of Moonshine, a suite of tiny automatic speech\nrecognition (ASR) models specialized for a range of underrepresented languages.\nPrevailing wisdom suggests that multilingual ASR models outperform monolingual\ncounterparts by exploiting cross-lingual phonetic similarities. We challenge\nthis assumption, showing that for sufficiently small models (27M parameters),\ntraining monolingual systems on a carefully balanced mix of high-quality\nhuman-labeled, pseudo-labeled, and synthetic data yields substantially superior\nperformance. On average, our models achieve error rates 48% lower than the\ncomparably sized Whisper Tiny model, outperform the 9x larger Whisper Small\nmodel, and in most cases match or outperform the 28x larger Whisper Medium\nmodel. These results advance the state of the art for models of this size,\nenabling accurate on-device ASR for languages that previously had limited\nsupport. We release Arabic, Chinese, Japanese, Korean, Ukrainian, and\nVietnamese Moonshine models under a permissive open-source license.", "published": "2025-09-02 17:22:54", "link": "http://arxiv.org/abs/2509.02523v1", "categories": ["cs.CL", "cs.LG", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR", "abstract": "Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) have\nempowered large language models (LLMs) to tackle challenging reasoning tasks\nsuch as mathematics and programming. RLVR leverages verifiable outcome rewards\nto guide policy optimization, enabling LLMs to progressively improve output\nquality in a grounded and reliable manner. Despite its promise, the RLVR\nparadigm poses significant challenges, as existing methods often suffer from\nsparse reward signals and unstable policy gradient updates, particularly in\nRL-based approaches. To address the challenges, we propose $\\textbf{PACS}$, a\nnovel RLVR framework that achieves im$\\textbf{P}$licit $\\textbf{A}$ctor\n$\\textbf{C}$ritic coupling via a $\\textbf{S}$upervised learning framework. By\ntreating the outcome reward as a predictable label, we reformulate the RLVR\nproblem into a supervised learning task over a score function parameterized by\nthe policy model and optimized using cross-entropy loss. A detailed gradient\nanalysis shows that this supervised formulation inherently recovers the\nclassical policy gradient update while implicitly coupling actor and critic\nroles, yielding more stable and efficient training. Benchmarking on challenging\nmathematical reasoning tasks, PACS outperforms strong RLVR baselines, such as\nPPO and GRPO, achieving superior reasoning performance. For instance, PACS\nachieves 59.78\\% at pass@256 on AIME 2025, representing improvements of 13.32\nand 14.36 points over PPO and GRPO. This simple yet powerful framework offers a\npromising avenue for LLMs post-training with verifiable rewards. Our code and\ndata are available as open source at https://github.com/ritzz-ai/PACS.", "published": "2025-09-02 17:22:46", "link": "http://arxiv.org/abs/2509.02522v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FLM-Audio: Natural Monologues Improves Native Full-Duplex Chatbots via Dual Training", "abstract": "Full-duplex dialog models are designed to listen and speak simultaneously\nwith rapid responses to fast-changing user input. Among existing approaches,\nnative full-duplex models merges different channels (e.g. listen and speak) in\na single time step, overcoming the high response latency inherent to\ntime-division multiplexing time-division multiplexing (TDM) alternatives. Yet,\na key challenge remains: aligning textual monologues with audio streams that\noperate at different bitrates. The prevailing solution relies on word-level\nalignment, but this can degrade the language ability of large pre-trained\nmodels. Moreover, it requires highly accurate timestamps for every token, which\nintroduces cascading errors and increases pre-processing costs. In this paper,\nwe propose textual monologues in continuous tokens sequence, namely \"natural\"\nmonologues, which mimics humanoid cognitive behavior in dialogs. For temporal\nalignment, we alternate the position of the natural monologue - leading or\ntrailing the audio - across different training stages. This \"dual\" training\nparadigm proves highly effective in building FLM-Audio, our 7B spoken dialog\nmodel that demonstrates superior responsiveness, duplexity, and chatting\nexperiences, as confirmed by experimental results.", "published": "2025-09-02 17:18:49", "link": "http://arxiv.org/abs/2509.02521v1", "categories": ["cs.SD", "cs.AI", "cs.CL"], "primary_category": "cs.SD"}
{"title": "Comparative Study of Pre-Trained BERT and Large Language Models for Code-Mixed Named Entity Recognition", "abstract": "Named Entity Recognition (NER) in code-mixed text, particularly Hindi-English\n(Hinglish), presents unique challenges due to informal structure,\ntransliteration, and frequent language switching. This study conducts a\ncomparative evaluation of code-mixed fine-tuned models and non-code-mixed\nmultilingual models, along with zero-shot generative large language models\n(LLMs). Specifically, we evaluate HingBERT, HingMBERT, and HingRoBERTa (trained\non code-mixed data), and BERT Base Cased, IndicBERT, RoBERTa and MuRIL (trained\non non-code-mixed multilingual data). We also assess the performance of Google\nGemini in a zero-shot setting using a modified version of the dataset with NER\ntags removed. All models are tested on a benchmark Hinglish NER dataset using\nPrecision, Recall, and F1-score. Results show that code-mixed models,\nparticularly HingRoBERTa and HingBERT-based fine-tuned models, outperform\nothers - including closed-source LLMs like Google Gemini - due to\ndomain-specific pretraining. Non-code-mixed models perform reasonably but show\nlimited adaptability. Notably, Google Gemini exhibits competitive zero-shot\nperformance, underlining the generalization strength of modern LLMs. This study\nprovides key insights into the effectiveness of specialized versus generalized\nmodels for code-mixed NER tasks.", "published": "2025-09-02 17:07:02", "link": "http://arxiv.org/abs/2509.02514v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Top-H Decoding: Adapting the Creativity and Coherence with Bounded Entropy in Text Generation", "abstract": "Large language models (LLMs), despite their impressive performance across a\nwide range of tasks, often struggle to balance two competing objectives in\nopen-ended text generation: fostering diversity and creativity while preserving\nlogical coherence. Existing truncated sampling techniques, including\ntemperature scaling, top-\\$p\\$ (nucleus) sampling, and min-\\$p\\$ sampling, aim\nto manage this trade-off. However, they exhibit limitations, particularly in\nthe effective incorporation of the confidence of the model into the\ncorresponding sampling strategy. For example, min-\\$p\\$ sampling relies on a\nsingle top token as a heuristic for confidence, eventually underutilizing the\ninformation of the probability distribution. Toward effective incorporation of\nthe confidence of the model, in this paper, we present **top-H** decoding. We\nfirst establish the theoretical foundation of the interplay between creativity\nand coherence in truncated sampling by formulating an **entropy-constrained\nminimum divergence** problem. We then prove this minimization problem to be\nequivalent to an **entropy-constrained mass maximization** (ECMM) problem,\nwhich is NP-hard. Finally, we present top-H decoding, a computationally\nefficient greedy algorithm to solve the ECMM problem. Extensive empirical\nevaluations demonstrate that top-H outperforms the state-of-the-art (SoTA)\nalternative of min-\\$p\\$ sampling by up to **25.63%** on creative writing\nbenchmarks, while maintaining robustness on question-answering datasets such as\nGPQA, GSM8K, and MT-Bench. Additionally, an *LLM-as-judge* evaluation confirms\nthat top-H indeed produces coherent outputs even at higher temperatures, where\ncreativity is especially critical. In summary, top-H advances SoTA in\nopen-ended text generation and can be *easily integrated* into creative writing\napplications. The code is available at\nhttps://github.com/ErfanBaghaei/Top-H-Decoding.", "published": "2025-09-02 17:02:29", "link": "http://arxiv.org/abs/2509.02510v1", "categories": ["cs.CL", "cs.AI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "The Forgotten Code: Validating a Century-Old Translation System with AI", "abstract": "A pioneering rule-based mechanical translation system (precursor of modern\nRBMTs) was first presented in December 1929 by its inventor, Federico Pucci,\nwho later published the full method in a book titled \"Il traduttore meccanico\ned il metodo per corrispondersi fra Europei conoscendo ciascuno solo la propria\nlingua: Parte I\", in Salerno (Italy), in 1931. This study illustrates how AI\nbreathes new life into the system of international keys and ideograms devised\nby Pucci to translate from/into any Romance language (at least as a first\nstep). The methodology involves having the AIs retranslate, following Pucci's\nmethod, the two text excerpts originally translated in 1931 and clearly\ndocumented in his publication: a passage from Dante's La Vita Nuova, translated\nfrom Italian into French, and a passage from Voltaire's Zadig, translated from\nFrench into Italian. The result is notable: the two texts, translated 94 years\napart using the same method--by Pucci in 1931 and by AIs in 2025--show a low\naverage difference, with only minor variations observed. With Pucci's system\nthus validated, it became feasible to have the AIs reproduce the excerpts in\nEnglish, Spanish, and German according to his method. The results were\nconsistent, and Pucci--via Artificial Intelligence--was tasked with translating\nmore modern and technical texts, thereby reviving, nearly a century later, an\ninvention that had remained almost entirely unknown and never applied beyond\nits creator, now brought to wider attention and opened to possible\nexperimentation. Such a demonstration would not only affirm Pucci's historical\nstatus but also place him among the precursors and intellectual contributors to\nmachine translation, whose work merits examination alongside figures such as\nTroyanskij, Booth, and Weaver, with possible consequences for how the history\nof the field is understood.", "published": "2025-09-02 16:57:07", "link": "http://arxiv.org/abs/2509.02506v1", "categories": ["cs.CL", "I.2"], "primary_category": "cs.CL"}
{"title": "L3Cube-IndicHeadline-ID: A Dataset for Headline Identification and Semantic Evaluation in Low-Resource Indian Languages", "abstract": "Semantic evaluation in low-resource languages remains a major challenge in\nNLP. While sentence transformers have shown strong performance in high-resource\nsettings, their effectiveness in Indic languages is underexplored due to a lack\nof high-quality benchmarks. To bridge this gap, we introduce\nL3Cube-IndicHeadline-ID, a curated headline identification dataset spanning ten\nlow-resource Indic languages: Marathi, Hindi, Tamil, Gujarati, Odia, Kannada,\nMalayalam, Punjabi, Telugu, Bengali and English. Each language includes 20,000\nnews articles paired with four headline variants: the original, a semantically\nsimilar version, a lexically similar version, and an unrelated one, designed to\ntest fine-grained semantic understanding. The task requires selecting the\ncorrect headline from the options using article-headline similarity. We\nbenchmark several sentence transformers, including multilingual and\nlanguage-specific models, using cosine similarity. Results show that\nmultilingual models consistently perform well, while language-specific models\nvary in effectiveness. Given the rising use of similarity models in\nRetrieval-Augmented Generation (RAG) pipelines, this dataset also serves as a\nvaluable resource for evaluating and improving semantic understanding in such\napplications. Additionally, the dataset can be repurposed for multiple-choice\nquestion answering, headline classification, or other task-specific evaluations\nof LLMs, making it a versatile benchmark for Indic NLP. The dataset is shared\npublicly at https://github.com/l3cube-pune/indic-nlp", "published": "2025-09-02 16:54:30", "link": "http://arxiv.org/abs/2509.02503v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MoSEs: Uncertainty-Aware AI-Generated Text Detection via Mixture of Stylistics Experts with Conditional Thresholds", "abstract": "The rapid advancement of large language models has intensified public\nconcerns about the potential misuse. Therefore, it is important to build\ntrustworthy AI-generated text detection systems. Existing methods neglect\nstylistic modeling and mostly rely on static thresholds, which greatly limits\nthe detection performance. In this paper, we propose the Mixture of Stylistic\nExperts (MoSEs) framework that enables stylistics-aware uncertainty\nquantification through conditional threshold estimation. MoSEs contain three\ncore components, namely, the Stylistics Reference Repository (SRR), the\nStylistics-Aware Router (SAR), and the Conditional Threshold Estimator (CTE).\nFor input text, SRR can activate the appropriate reference data in SRR and\nprovide them to CTE. Subsequently, CTE jointly models the linguistic\nstatistical properties and semantic features to dynamically determine the\noptimal threshold. With a discrimination score, MoSEs yields prediction labels\nwith the corresponding confidence level. Our framework achieves an average\nimprovement 11.34% in detection performance compared to baselines. More\ninspiringly, MoSEs shows a more evident improvement 39.15% in the low-resource\ncase. Our code is available at https://github.com/creator-xi/MoSEs.", "published": "2025-09-02 16:51:43", "link": "http://arxiv.org/abs/2509.02499v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GRAM-R$^2$: Self-Training Generative Foundation Reward Models for Reward Reasoning", "abstract": "Significant progress in reward modeling over recent years has been driven by\na paradigm shift from task-specific designs towards generalist reward models.\nDespite this trend, developing effective reward models remains a fundamental\nchallenge: the heavy reliance on large-scale labeled preference data.\nPre-training on abundant unlabeled data offers a promising direction, but\nexisting approaches fall short of instilling explicit reasoning into reward\nmodels. To bridge this gap, we propose a self-training approach that leverages\nunlabeled data to elicit reward reasoning in reward models. Based on this\napproach, we develop GRAM-R$^2$, a generative reward model trained to produce\nnot only preference labels but also accompanying reward rationales. GRAM-R$^2$\ncan serve as a foundation model for reward reasoning and can be applied to a\nwide range of tasks with minimal or no additional fine-tuning. It can support\ndownstream applications such as response ranking and task-specific reward\ntuning. Experiments on response ranking, task adaptation, and reinforcement\nlearning from human feedback demonstrate that GRAM-R$^2$ consistently delivers\nstrong performance, outperforming several strong discriminative and generative\nbaselines.", "published": "2025-09-02 16:41:07", "link": "http://arxiv.org/abs/2509.02492v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SpecEval: Evaluating Model Adherence to Behavior Specifications", "abstract": "Companies that develop foundation models publish behavioral guidelines they\npledge their models will follow, but it remains unclear if models actually do\nso. While providers such as OpenAI, Anthropic, and Google have published\ndetailed specifications describing both desired safety constraints and\nqualitative traits for their models, there has been no systematic audit of\nadherence to these guidelines. We introduce an automated framework that audits\nmodels against their providers specifications by parsing behavioral statements,\ngenerating targeted prompts, and using models to judge adherence. Our central\nfocus is on three way consistency between a provider specification, its model\noutputs, and its own models as judges; an extension of prior two way generator\nvalidator consistency. This establishes a necessary baseline: at minimum, a\nfoundation model should consistently satisfy the developer behavioral\nspecifications when judged by the developer evaluator models. We apply our\nframework to 16 models from six developers across more than 100 behavioral\nstatements, finding systematic inconsistencies including compliance gaps of up\nto 20 percent across providers.", "published": "2025-09-02 16:18:40", "link": "http://arxiv.org/abs/2509.02464v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do LLMs Adhere to Label Definitions? Examining Their Receptivity to External Label Definitions", "abstract": "Do LLMs genuinely incorporate external definitions, or do they primarily rely\non their parametric knowledge? To address these questions, we conduct\ncontrolled experiments across multiple explanation benchmark datasets (general\nand domain-specific) and label definition conditions, including expert-curated,\nLLM-generated, perturbed, and swapped definitions. Our results reveal that\nwhile explicit label definitions can enhance accuracy and explainability, their\nintegration into an LLM's task-solving processes is neither guaranteed nor\nconsistent, suggesting reliance on internalized representations in many cases.\nModels often default to their internal representations, particularly in general\ntasks, whereas domain-specific tasks benefit more from explicit definitions.\nThese findings underscore the need for a deeper understanding of how LLMs\nprocess external knowledge alongside their pre-existing capabilities.", "published": "2025-09-02 16:01:47", "link": "http://arxiv.org/abs/2509.02452v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EmoPerso: Enhancing Personality Detection with Self-Supervised Emotion-Aware Modelling", "abstract": "Personality detection from text is commonly performed by analysing users'\nsocial media posts. However, existing methods heavily rely on large-scale\nannotated datasets, making it challenging to obtain high-quality personality\nlabels. Moreover, most studies treat emotion and personality as independent\nvariables, overlooking their interactions. In this paper, we propose a novel\nself-supervised framework, EmoPerso, which improves personality detection\nthrough emotion-aware modelling. EmoPerso first leverages generative mechanisms\nfor synthetic data augmentation and rich representation learning. It then\nextracts pseudo-labeled emotion features and jointly optimizes them with\npersonality prediction via multi-task learning. A cross-attention module is\nemployed to capture fine-grained interactions between personality traits and\nthe inferred emotional representations. To further refine relational reasoning,\nEmoPerso adopts a self-taught strategy to enhance the model's reasoning\ncapabilities iteratively. Extensive experiments on two benchmark datasets\ndemonstrate that EmoPerso surpasses state-of-the-art models. The source code is\navailable at https://github.com/slz0925/EmoPerso.", "published": "2025-09-02 15:57:26", "link": "http://arxiv.org/abs/2509.02450v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Ensemble Classification Approach in A Multi-Layered Large Language Model Framework for Disease Prediction", "abstract": "Social telehealth has made remarkable progress in healthcare by allowing\npatients to post symptoms and participate in medical consultations remotely.\nUsers frequently post symptoms on social media and online health platforms,\ncreating a huge repository of medical data that can be leveraged for disease\nclassification. Large language models (LLMs) such as LLAMA3 and GPT-3.5, along\nwith transformer-based models like BERT, have demonstrated strong capabilities\nin processing complex medical text. In this study, we evaluate three Arabic\nmedical text preprocessing methods such as summarization, refinement, and Named\nEntity Recognition (NER) before applying fine-tuned Arabic transformer models\n(CAMeLBERT, AraBERT, and AsafayaBERT). To enhance robustness, we adopt a\nmajority voting ensemble that combines predictions from original and\npreprocessed text representations. This approach achieved the best\nclassification accuracy of 80.56%, thus showing its effectiveness in leveraging\nvarious text representations and model predictions to improve the understanding\nof medical texts. To the best of our knowledge, this is the first work that\nintegrates LLM-based preprocessing with fine-tuned Arabic transformer models\nand ensemble learning for disease classification in Arabic social telehealth\ndata.", "published": "2025-09-02 15:53:51", "link": "http://arxiv.org/abs/2509.02446v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AppCopilot: Toward General, Accurate, Long-Horizon, and Efficient Mobile Agent", "abstract": "With the raid evolution of large language models and multimodal foundation\nmodels, the mobile-agent landscape has proliferated without converging on the\nfundamental challenges. This paper identifies four core problems that must be\nsolved for mobile agents to deliver practical, scalable impact: (1)\ngeneralization across tasks, modalities, apps, and devices; (2) accuracy,\nspecifically precise on-screen interaction and click targeting; (3)\nlong-horizon capability for sustained, multi-step goals; and (4) efficiency,\nspecifically high-performance runtime on resource-constrained devices. We\npresent AppCopilot, a multimodal, multi-agent, general-purpose on-device\nassistant that operates across applications and constitutes a full-stack,\nclosed-loop system from data to deployment. AppCopilot operationalizes this\nposition through an end-to-end autonomous pipeline spanning data collection,\ntraining, deployment, high-quality and efficient inference, and mobile\napplication development. At the model layer, it integrates multimodal\nfoundation models with robust Chinese-English support. At the reasoning and\ncontrol layer, it combines chain-of-thought reasoning, hierarchical task\nplanning and decomposition, and multi-agent collaboration. At the execution\nlayer, it enables user personalization and experiential adaptation, voice\ninteraction, function calling, cross-app and cross-device orchestration, and\ncomprehensive mobile app support. The system design incorporates\nprofiling-driven optimization for latency, memory, and energy across\nheterogeneous hardware. Empirically, AppCopilot achieves significant\nimprovements along all four dimensions: stronger generalization,\nhigher-precision on-screen actions, more reliable long-horizon task completion,\nand faster, more resource-efficient runtime.", "published": "2025-09-02 15:48:21", "link": "http://arxiv.org/abs/2509.02444v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Evaluating Cumulative Spectral Gradient as a Complexity Measure", "abstract": "Accurate estimation of dataset complexity is crucial for evaluating and\ncomparing link prediction models for knowledge graphs (KGs). The Cumulative\nSpectral Gradient (CSG) metric derived from probabilistic divergence between\nclasses within a spectral clustering framework was proposed as a dataset\ncomplexity measure that (1) naturally scales with the number of classes and (2)\ncorrelates strongly with downstream classification performance. In this work,\nwe rigorously assess CSG behavior on standard knowledge graph link prediction\nbenchmarks a multi class tail prediction task, using two key parameters\ngoverning its computation, M, the number of Monte Carlo sampled points per\nclass, and K, the number of nearest neighbors in the embedding space. Contrary\nto the original claims, we find that (1) CSG is highly sensitive to the choice\nof K and therefore does not inherently scale with the number of target classes,\nand (2) CSG values exhibit weak or no correlation with established performance\nmetrics such as mean reciprocal rank (MRR). Through experiments on FB15k 237,\nWN18RR, and other standard datasets, we demonstrate that CSG purported\nstability and generalization predictive power break down in link prediction\nsettings. Our results highlight the need for more robust, classifier agnostic\ncomplexity measures in KG link prediction evaluation.", "published": "2025-09-02 15:10:25", "link": "http://arxiv.org/abs/2509.02399v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Towards Temporal Knowledge-Base Creation for Fine-Grained Opinion Analysis with Language Models", "abstract": "We propose a scalable method for constructing a temporal opinion knowledge\nbase with large language models (LLMs) as automated annotators. Despite the\ndemonstrated utility of time-series opinion analysis of text for downstream\napplications such as forecasting and trend analysis, existing methodologies\nunderexploit this potential due to the absence of temporally grounded\nfine-grained annotations. Our approach addresses this gap by integrating\nwell-established opinion mining formulations into a declarative LLM annotation\npipeline, enabling structured opinion extraction without manual prompt\nengineering. We define three data models grounded in sentiment and opinion\nmining literature, serving as schemas for structured representation. We perform\nrigorous quantitative evaluation of our pipeline using human-annotated test\nsamples. We carry out the final annotations using two separate LLMs, and\ninter-annotator agreement is computed label-wise across the fine-grained\nopinion dimensions, analogous to human annotation protocols. The resulting\nknowledge base encapsulates time-aligned, structured opinions and is compatible\nwith applications in Retrieval-Augmented Generation (RAG), temporal question\nanswering, and timeline summarisation.", "published": "2025-09-02 14:24:25", "link": "http://arxiv.org/abs/2509.02363v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Implicit Reasoning in Large Language Models: A Comprehensive Survey", "abstract": "Large Language Models (LLMs) have demonstrated strong generalization across a\nwide range of tasks. Reasoning with LLMs is central to solving multi-step\nproblems and complex decision-making. To support efficient reasoning, recent\nstudies have shifted attention from explicit chain-of-thought prompting toward\nimplicit reasoning, where reasoning occurs silently via latent structures\nwithout emitting intermediate textual steps. Implicit reasoning brings\nadvantages such as lower generation cost, faster inference, and better\nalignment with internal computation. Although prior surveys have discussed\nlatent representations in the context of reasoning, a dedicated and\nmechanism-level examination of how reasoning unfolds internally within LLMs\nremains absent. This survey fills that gap by introducing a taxonomy centered\non execution paradigms, shifting the focus from representational forms to\ncomputational strategies. We organize existing methods into three execution\nparadigms based on \\textbf{\\textit{how and where internal computation\nunfolds}}: latent optimization, signal-guided control, and layer-recurrent\nexecution. We also review structural, behavioral and representation-based\nevidence that supports the presence of implicit reasoning in LLMs. We further\nprovide a structured overview of the evaluation metrics and benchmarks used in\nexisting works to assess the effectiveness and reliability of implicit\nreasoning. We maintain a continuously updated project at:\nhttps://github.com/digailab/awesome-llm-implicit-reasoning.", "published": "2025-09-02 14:16:02", "link": "http://arxiv.org/abs/2509.02350v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DCPO: Dynamic Clipping Policy Optimization", "abstract": "Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a\npromising framework for enhancing the reasoning capabilities of large language\nmodels. However, existing approaches such as GRPO often suffer from zero\ngradients. This problem arises primarily due to fixed clipping bounds for\ntoken-level probability ratios and the standardization of identical rewards,\nwhich can lead to ineffective gradient updates and underutilization of\ngenerated responses. In this work, we propose Dynamic Clipping Policy\nOptimization (DCPO), which introduces a dynamic clipping strategy that\nadaptively adjusts the clipping bounds based on token-specific prior\nprobabilities to enhance token-level exploration, and a smooth advantage\nstandardization technique that standardizes rewards across cumulative training\nsteps to improve the response-level effective utilization of generated\nresponses. DCPO achieved state-of-the-art performance on four benchmarks based\non four different models. In particular, DCPO achieved an Avg@1 of 46.7 under\ngreedy decoding and an Avg@32 of 38.8 under 32 times sampling on the AIME24\nbenchmark, surpassing both DAPO (36.7/31.6) and GRPO (36.7/32.1) on the\nQwen2.5-Math-7B model. On the AIME25 benchmark based on Qwen2.5-14B, DCPO\nachieves a performance of (23.3/19.0), surpassing GRPO (13.3/10.5) and DAPO\n(20.0/15.3). Furthermore, DCPO achieved an average 28% improvement in the\nnonzero advantage over GRPO in four models, doubled the training efficiency\nover DAPO, and significantly reduced the token clipping ratio by an order of\nmagnitude compared to both GRPO and DAPO, while achieving superior performance.\nThese results highlight DCPO's effectiveness in leveraging generated data more\nefficiently for reinforcement learning in large language models.", "published": "2025-09-02 14:01:07", "link": "http://arxiv.org/abs/2509.02333v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLMs and their Limited Theory of Mind: Evaluating Mental State Annotations in Situated Dialogue", "abstract": "What if large language models could not only infer human mindsets but also\nexpose every blind spot in team dialogue such as discrepancies in the team\nmembers' joint understanding? We present a novel, two-step framework that\nleverages large language models (LLMs) both as human-style annotators of team\ndialogues to track the team's shared mental models (SMMs) and as automated\ndiscrepancy detectors among individuals' mental states. In the first step, an\nLLM generates annotations by identifying SMM elements within task-oriented\ndialogues from the Cooperative Remote Search Task (CReST) corpus. Then, a\nsecondary LLM compares these LLM-derived annotations and human annotations\nagainst gold-standard labels to detect and characterize divergences. We define\nan SMM coherence evaluation framework for this use case and apply it to six\nCReST dialogues, ultimately producing: (1) a dataset of human and LLM\nannotations; (2) a reproducible evaluation framework for SMM coherence; and (3)\nan empirical assessment of LLM-based discrepancy detection. Our results reveal\nthat, although LLMs exhibit apparent coherence on straightforward\nnatural-language annotation tasks, they systematically err in scenarios\nrequiring spatial reasoning or disambiguation of prosodic cues.", "published": "2025-09-02 13:11:24", "link": "http://arxiv.org/abs/2509.02292v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Spectrogram Patch Codec: A 2D Block-Quantized VQ-VAE and HiFi-GAN for Neural Speech Coding", "abstract": "We present a neural speech codec that challenges the need for complex\nresidual vector quantization (RVQ) stacks by introducing a simpler,\nsingle-stage quantization approach. Our method operates directly on the\nmel-spectrogram, treating it as a 2D data and quantizing non-overlapping 4x4\npatches into a single, shared codebook. This patchwise design simplifies the\narchitecture, enables low-latency streaming, and yields a discrete latent grid.\nTo ensure high-fidelity synthesis, we employ a late-stage adversarial\nfine-tuning for the VQ-VAE and train a HiFi-GAN vocoder from scratch on the\ncodec's reconstructed spectrograms. Operating at approximately 7.5 kbits/s for\n16 kHz speech, our system was evaluated against several state-of-the-art neural\ncodecs using objective metrics such as STOI, PESQ, MCD, and ViSQOL. The results\ndemonstrate that our simplified, non-residual architecture achieves competitive\nperceptual quality and intelligibility, validating it as an effective and open\nfoundation for future low-latency codec designs.", "published": "2025-09-02 12:14:41", "link": "http://arxiv.org/abs/2509.02244v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Fundamental Language Models: Does Linguistic Competence Scale with Model Size?", "abstract": "Large Language Models offer impressive language capabilities but suffer from\nwell-known limitations, including hallucinations, biases, privacy concerns, and\nhigh computational costs. These issues are largely driven by the combination of\nlinguistic competence and factual memorization within a single monolithic\nmodel. This paper introduces and empirically supports the Fundamental Language\nModel (FLM) paradigm, which advocates for smaller, linguistically competent\nmodels that offload factual retrieval to external tools. We evaluate models\nranging from 135M to 32B parameters across three dimensions: linguistic\ncompetence, external factual knowledge, and internal factual knowledge. Our\nfindings reveal that while both linguistic competence and factual knowledge\nimprove with scale, internal factual knowledge grows significantly faster,\nsuggesting that model size is more closely tied to memorization than to core\nlanguage ability. These results support a modular approach to language\nmodeling, where compact, linguistically proficient models serve as the\nfoundation for tool-augmented systems. The FLM paradigm offers a path toward\nmore efficient, interpretable, and sustainable NLP solutions.", "published": "2025-09-02 11:43:21", "link": "http://arxiv.org/abs/2509.02225v1", "categories": ["cs.CL", "I.2.7; I.7"], "primary_category": "cs.CL"}
{"title": "FActBench: A Benchmark for Fine-grained Automatic Evaluation of LLM-Generated Text in the Medical Domain", "abstract": "Large Language Models tend to struggle when dealing with specialized domains.\nWhile all aspects of evaluation hold importance, factuality is the most\ncritical one. Similarly, reliable fact-checking tools and data sources are\nessential for hallucination mitigation. We address these issues by providing a\ncomprehensive Fact-checking Benchmark FActBench covering four generation tasks\nand six state-of-the-art Large Language Models (LLMs) for the Medical domain.\nWe use two state-of-the-art Fact-checking techniques: Chain-of-Thought (CoT)\nPrompting and Natural Language Inference (NLI). Our experiments show that the\nfact-checking scores acquired through the Unanimous Voting of both techniques\ncorrelate best with Domain Expert Evaluation.", "published": "2025-09-02 11:09:52", "link": "http://arxiv.org/abs/2509.02198v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Space Is Rocket Science - Only Top Reasoning Models Can Solve Spatial Understanding Tasks", "abstract": "We propose RocketScience, an open-source contrastive VLM benchmark that tests\nfor spatial relation understanding. It is comprised of entirely new real-world\nimage-text pairs covering mostly relative spatial understanding and the order\nof objects. The benchmark is designed\n  to be very easy for humans and hard for the current generation of VLMs, and\nthis is empirically verified. Our results show a striking lack of spatial\nrelation understanding in open source and frontier commercial VLMs and a\nsurprisingly high performance of reasoning models. Additionally, we perform a\ndisentanglement analysis to separate the contributions of object localization\nand spatial reasoning in chain-of-thought-based models and find that the\nperformance on the benchmark is bottlenecked by spatial reasoning and not\nobject localization capabilities.\n  We release the dataset with a CC-BY-4.0 license and make the evaluation code\navailable at: https://github.com/nilshoehing/rocketscience", "published": "2025-09-02 10:32:58", "link": "http://arxiv.org/abs/2509.02175v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Avoidance Decoding for Diverse Multi-Branch Story Generation", "abstract": "Large Language Models (LLMs) often generate repetitive and monotonous\noutputs, especially in tasks like story generation, due to limited creative\ndiversity when given the same input prompt. To address this challenge, we\npropose a novel decoding strategy, Avoidance Decoding, that modifies token\nlogits by penalizing similarity to previously generated outputs, thereby\nencouraging more diverse multi-branch stories. This penalty adaptively balances\ntwo similarity measures: (1) Concept-level Similarity Penalty, which is\nprioritized in early stages to diversify initial story concepts, and (2)\nNarrative-level Similarity Penalty, which is increasingly emphasized later to\nensure natural yet diverse plot development. Notably, our method achieves up to\n2.6 times higher output diversity and reduces repetition by an average of 30%\ncompared to strong baselines, while effectively mitigating text degeneration.\nFurthermore, we reveal that our method activates a broader range of neurons,\ndemonstrating that it leverages the model's intrinsic creativity.", "published": "2025-09-02 10:22:46", "link": "http://arxiv.org/abs/2509.02170v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Meta-Pretraining for Zero-Shot Cross-Lingual Named Entity Recognition in Low-Resource Philippine Languages", "abstract": "Named-entity recognition (NER) in low-resource languages is usually tackled\nby finetuning very large multilingual LMs, an option that is often infeasible\nin memory- or latency-constrained settings. We ask whether small decoder LMs\ncan be pretrained so that they adapt quickly and transfer zero-shot to\nlanguages unseen during pretraining. To this end we replace part of the\nautoregressive objective with first-order model-agnostic meta-learning (MAML).\nTagalog and Cebuano are typologically similar yet structurally different in\ntheir actor/non-actor voice systems, and hence serve as a challenging test-bed.\nAcross four model sizes (11 M - 570 M) MAML lifts zero-shot micro-F1 by 2-6 pp\nunder head-only tuning and 1-3 pp after full tuning, while cutting convergence\ntime by up to 8%. Gains are largest for single-token person entities that\nco-occur with Tagalog case particles si/ni, highlighting the importance of\nsurface anchors.", "published": "2025-09-02 10:09:51", "link": "http://arxiv.org/abs/2509.02160v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models", "abstract": "Large Language Models (LLMs) can inadvertently reflect societal biases\npresent in their training data, leading to harmful or prejudiced outputs. In\nthe Indian context, our empirical evaluations across a suite of models reveal\nthat biases around caste and religion are particularly salient. Yet, most\nexisting mitigation strategies are Western-centric and fail to address these\nlocal nuances. We propose AMBEDKAR, a framework inspired by the egalitarian\nvision of Dr B. R. Ambedkar, architect of the Indian Constitution, to guide LLM\noutputs toward fairness, neutrality, and inclusion in line with Articles 14 to\n17. Our approach introduces a Constitution-Aware Decoding Layer, guided by the\nAI Constitution of India and applied only at inference time, without any\nparameter updates to the base model. We incorporate a speculative decoding\nalgorithm that proactively reduces casteist and communal bias during\ngeneration. This mitigation layer operates directly within the decoding\nprocess, avoiding changes to model internals and lowering the computational and\ninfrastructural costs associated with retraining. We reinterpret speculative\ndecoding not merely as an efficiency tool but as a mechanism for fairness. In\nthis framework, a Small Language Model (SLM) acts as a potentially biased\ngenerator, while a constitutionally guided Large Language Model (LLM) serves as\nthe verifier. Rather than accelerating generation, the LLM enforces bias-robust\ntrajectories in the SLM outputs. This inversion of roles gives rise to a\nfairness-by-speculation paradigm. Our approach yields an absolute reduction of\nbias up to 26.41 percent compared to baseline. Our source code, datasets, and\nresults are available at https://anonymous.4open.science/r/AMBEDKAR-983B/", "published": "2025-09-02 09:33:30", "link": "http://arxiv.org/abs/2509.02133v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CMRAG: Co-modality-based document retrieval and visual question answering", "abstract": "Retrieval-Augmented Generation (RAG) has become a core paradigm in document\nquestion answering tasks. However, existing methods have limitations when\ndealing with multimodal documents: one category of methods relies on layout\nanalysis and text extraction, which can only utilize explicit text information\nand struggle to capture images or unstructured content; the other category\ntreats document segmentation as visual input and directly passes it to visual\nlanguage models (VLMs) for processing, yet it ignores the semantic advantages\nof text, leading to suboptimal generation results. This paper proposes\nco-modality-based RAG (CMRAG), which can simultaneously leverage text and\nimages for efficient retrieval and generation. Specifically, we first perform\nstructured parsing on documents to obtain co-modality representations of text\nsegments and image regions. Subsequently, in response to user queries, we\nretrieve candidate evidence from text and image channels, respectively, and\naggregate the results at the cross-modal retrieval level. Finally, we prompt\nthe VLM to generate the final response based on the co-modality retrieval\nresults. Experiments demonstrate that our method significantly outperforms\npure-vision-based RAG in visual document question answering tasks. The findings\nof this paper show that integrating co-modality information into the RAG\nframework in a unified manner is an effective approach to improving the\nperformance of complex document visual question-answering (VQA) systems.", "published": "2025-09-02 09:17:57", "link": "http://arxiv.org/abs/2509.02123v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "E-THER: A PCT-Grounded Dataset for Benchmarking Empathic AI", "abstract": "A prevalent shortfall among current empathic AI systems is their inability to\nrecognize when verbal expressions may not fully reflect underlying emotional\nstates. This is because the existing datasets, used for the training of these\nsystems, focus on surface-level emotion recognition without addressing the\ncomplex verbal-visual incongruence (mismatch) patterns useful for empathic\nunderstanding. In this paper, we present E-THER, the first Person-Centered\nTherapy-grounded multimodal dataset with multidimensional annotations for\nverbal-visual incongruence detection, enabling training of AI systems that\ndevelop genuine rather than performative empathic capabilities. The annotations\nincluded in the dataset are drawn from humanistic approach, i.e., identifying\nverbal-visual emotional misalignment in client-counsellor interactions -\nforming a framework for training and evaluating AI on empathy tasks. Additional\nengagement scores provide behavioral annotations for research applications.\nNotable gains in empathic and therapeutic conversational qualities are observed\nin state-of-the-art vision-language models (VLMs), such as IDEFICS and\nVideoLLAVA, using evaluation metrics grounded in empathic and therapeutic\nprinciples. Empirical findings indicate that our incongruence-trained models\noutperform general-purpose models in critical traits, such as sustaining\ntherapeutic engagement, minimizing artificial or exaggerated linguistic\npatterns, and maintaining fidelity to PCT theoretical framework.", "published": "2025-09-02 08:58:32", "link": "http://arxiv.org/abs/2509.02100v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "JudgeAgent: Dynamically Evaluate LLMs with Agent-as-Interviewer", "abstract": "Evaluating the capabilities of large language models (LLMs) is an essential\nstep to ensure the successful application of LLMs across various domains. The\ncurrent evaluation of LLMs is based on a paradigm that involves querying them\nwith predefined question sets and assessing their outputs. This paradigm offers\ncontrollable processes and simplicity, but faces challenges such as limited\ninteraction with targets, insufficient difficulty control, and difficulties in\nverifying the validity of evaluation results, making it hard to precisely\ndetermine the knowledge and capability boundaries of target models. To address\nthese challenges, we propose JudgeAgent, a knowledge-target adaptive dynamic\nevaluation framework based on a new interviewer-style evaluation paradigm.\nJudgeAgent employs a comprehensive evaluation approach consisting of benchmark\ngrading, interactive extension, and evaluation feedback. It utilizes\nknowledge-driven data synthesis and target-adaptive difficulty adjustment\nmethods to conduct extended testing, providing accurate and effective\nevaluation results. We also introduce a novel insight into validating\nevaluation methods, demonstrating the effectiveness of JudgeAgent and its\ndynamic evaluation paradigm through extensive experiments.", "published": "2025-09-02 08:52:16", "link": "http://arxiv.org/abs/2509.02097v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization", "abstract": "Automatic prompt optimization has recently emerged as a strategy for\nimproving the quality of prompts used in Large Language Models (LLMs), with the\ngoal of generating more accurate and useful responses. However, most prior work\nfocuses on direct prompt refinement or model fine-tuning, overlooking the\npotential of leveraging LLMs' inherent reasoning capability to learn from\ncontrasting examples. In this paper, we present Contrastive Reasoning Prompt\nOptimization (CRPO), a novel framework that formulates prompt optimization as a\nretrieval augmented reasoning process. Our approach retrieves top k reference\nprompts from the HelpSteer2 dataset, an open-source collection annotated for\nhelpfulness, correctness, coherence, complexity, and verbosity, and constructs\ntwo complementary optimization paradigms: (1) tiered contrastive reasoning,\nwhere the LLM compares high, medium, and low quality prompts to refine its own\ngeneration through reflective reasoning, and (2) multi-metric contrastive\nreasoning, where the LLM analyzes the best prompts along each evaluation\ndimension and integrates their strengths into an optimized prompt. By\nexplicitly contrasting high and low quality exemplars, CRPO enables the model\nto deduce why certain prompts succeed while others fail, thereby achieving more\nrobust and interpretable optimization. Experimental results on the HelpSteer2\nbenchmark demonstrate that CRPO significantly outperforms baselines. Our\nfindings highlight the promise of contrastive, retrieval-augmented reasoning\nfor advancing automatic prompt optimization.", "published": "2025-09-02 08:45:29", "link": "http://arxiv.org/abs/2509.02093v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach", "abstract": "In the domain of security, vulnerabilities frequently remain undetected even\nafter their exploitation. In this work, vulnerabilities refer to publicly\ndisclosed flaws documented in Common Vulnerabilities and Exposures (CVE)\nreports. Establishing a connection between attacks and vulnerabilities is\nessential for enabling timely incident response, as it provides defenders with\nimmediate, actionable insights. However, manually mapping attacks to CVEs is\ninfeasible, thereby motivating the need for automation. This paper evaluates 14\nstate-of-the-art (SOTA) sentence transformers for automatically identifying\nvulnerabilities from textual descriptions of attacks. Our results demonstrate\nthat the multi-qa-mpnet-base-dot-v1 (MMPNet) model achieves superior\nclassification performance when using attack Technique descriptions, with an\nF1-score of 89.0, precision of 84.0, and recall of 94.7. Furthermore, it was\nobserved that, on average, 56% of the vulnerabilities identified by the MMPNet\nmodel are also represented within the CVE repository in conjunction with an\nattack, while 61% of the vulnerabilities detected by the model correspond to\nthose cataloged in the CVE repository. A manual inspection of the results\nrevealed the existence of 275 predicted links that were not documented in the\nMITRE repositories. Consequently, the automation of linking attack techniques\nto vulnerabilities not only enhances the detection and response capabilities\nrelated to software security incidents but also diminishes the duration during\nwhich vulnerabilities remain exploitable, thereby contributing to the\ndevelopment of more secure systems.", "published": "2025-09-02 08:27:36", "link": "http://arxiv.org/abs/2509.02077v1", "categories": ["cs.CR", "cs.CL", "cs.LG", "68T50 Natural language processing", "D.4.6; I.2.7"], "primary_category": "cs.CR"}
{"title": "How Instruction-Tuning Imparts Length Control: A Cross-Lingual Mechanistic Analysis", "abstract": "Adhering to explicit length constraints, such as generating text with a\nprecise word count, remains a significant challenge for Large Language Models\n(LLMs). This study aims at investigating the differences between foundation\nmodels and their instruction-tuned counterparts, on length-controlled text\ngeneration in English and Italian. We analyze both performance and internal\ncomponent contributions using Cumulative Weighted Attribution, a metric derived\nfrom Direct Logit Attribution. Our findings reveal that instruction-tuning\nsubstantially improves length control, primarily by specializing components in\ndeeper model layers. Specifically, attention heads in later layers of IT models\nshow increasingly positive contributions, particularly in English. In Italian,\nwhile attention contributions are more attenuated, final-layer MLPs exhibit a\nstronger positive role, suggesting a compensatory mechanism. These results\nindicate that instruction-tuning reconfigures later layers for task adherence,\nwith component-level strategies potentially adapting to linguistic context.", "published": "2025-09-02 08:26:18", "link": "http://arxiv.org/abs/2509.02075v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation", "abstract": "Large Language Models (LLMs) excel at generating synthetic data, but ensuring\nits quality and diversity remains challenging. We propose Genetic Prompt, a\nnovel framework that combines genetic algorithms with LLMs to augment synthetic\ndata generation. Our approach treats semantic text attributes as gene sequences\nand leverages the LLM to simulate crossover and mutation operations. This\ngenetic process enhances data quality and diversity by creating novel attribute\ncombinations, yielding synthetic distributions closer to real-world data. To\noptimize parent selection, we also integrate an active learning scheme that\nexpands the offspring search space. Our experiments on multiple NLP tasks\nreveal several key findings: Genetic Prompt not only significantly outperforms\nstate-of-the-art baselines but also shows robust performance across various\ngenerator model sizes and scales. Moreover, we demonstrate that fusing our\nsynthetic data with the original training set significantly boosts downstream\nmodel performance, particularly for class-imbalanced scenarios. Our findings\nvalidate that Genetic Prompt is an effective method for producing high-quality\nsynthetic data for a wide range of NLP applications.", "published": "2025-09-02 07:35:20", "link": "http://arxiv.org/abs/2509.02040v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NADI 2025: The First Multidialectal Arabic Speech Processing Shared Task", "abstract": "We present the findings of the sixth Nuanced Arabic Dialect Identification\n(NADI 2025) Shared Task, which focused on Arabic speech dialect processing\nacross three subtasks: spoken dialect identification (Subtask 1), speech\nrecognition (Subtask 2), and diacritic restoration for spoken dialects (Subtask\n3). A total of 44 teams registered, and during the testing phase, 100 valid\nsubmissions were received from eight unique teams. The distribution was as\nfollows: 34 submissions for Subtask 1 \"five teams{\\ae}, 47 submissions for\nSubtask 2 \"six teams\", and 19 submissions for Subtask 3 \"two teams\". The\nbest-performing systems achieved 79.8% accuracy on Subtask 1, 35.68/12.20\nWER/CER (overall average) on Subtask 2, and 55/13 WER/CER on Subtask 3. These\nresults highlight the ongoing challenges of Arabic dialect speech processing,\nparticularly in dialect identification, recognition, and diacritic restoration.\nWe also summarize the methods adopted by participating teams and briefly\noutline directions for future editions of NADI.", "published": "2025-09-02 07:28:51", "link": "http://arxiv.org/abs/2509.02038v1", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "DeepSeek performs better than other Large Language Models in Dental Cases", "abstract": "Large language models (LLMs) hold transformative potential in healthcare, yet\ntheir capacity to interpret longitudinal patient narratives remains\ninadequately explored. Dentistry, with its rich repository of structured\nclinical data, presents a unique opportunity to rigorously assess LLMs'\nreasoning abilities. While several commercial LLMs already exist, DeepSeek, a\nmodel that gained significant attention earlier this year, has also joined the\ncompetition. This study evaluated four state-of-the-art LLMs (GPT-4o, Gemini\n2.0 Flash, Copilot, and DeepSeek V3) on their ability to analyze longitudinal\ndental case vignettes through open-ended clinical tasks. Using 34 standardized\nlongitudinal periodontal cases (comprising 258 question-answer pairs), we\nassessed model performance via automated metrics and blinded evaluations by\nlicensed dentists. DeepSeek emerged as the top performer, demonstrating\nsuperior faithfulness (median score = 0.528 vs. 0.367-0.457) and higher expert\nratings (median = 4.5/5 vs. 4.0/5), without significantly compromising\nreadability. Our study positions DeepSeek as the leading LLM for case analysis,\nendorses its integration as an adjunct tool in both medical education and\nresearch, and highlights its potential as a domain-specific agent.", "published": "2025-09-02 07:26:20", "link": "http://arxiv.org/abs/2509.02036v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "StructCoh: Structured Contrastive Learning for Context-Aware Text Semantic Matching", "abstract": "Text semantic matching requires nuanced understanding of both structural\nrelationships and fine-grained semantic distinctions. While pre-trained\nlanguage models excel at capturing token-level interactions, they often\noverlook hierarchical structural patterns and struggle with subtle semantic\ndiscrimination. In this paper, we proposed StructCoh, a graph-enhanced\ncontrastive learning framework that synergistically combines structural\nreasoning with representation space optimization. Our approach features two key\ninnovations: (1) A dual-graph encoder constructs semantic graphs via dependency\nparsing and topic modeling, then employs graph isomorphism networks to\npropagate structural features across syntactic dependencies and cross-document\nconcept nodes. (2) A hierarchical contrastive objective enforces consistency at\nmultiple granularities: node-level contrastive regularization preserves core\nsemantic units, while graph-aware contrastive learning aligns inter-document\nstructural semantics through both explicit and implicit negative sampling\nstrategies. Experiments on three legal document matching benchmarks and\nacademic plagiarism detection datasets demonstrate significant improvements\nover state-of-the-art methods. Notably, StructCoh achieves 86.7% F1-score\n(+6.2% absolute gain) on legal statute matching by effectively identifying\nargument structure similarities.", "published": "2025-09-02 07:21:36", "link": "http://arxiv.org/abs/2509.02033v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DRAssist: Dispute Resolution Assistance using Large Language Models", "abstract": "Disputes between two parties occur in almost all domains such as taxation,\ninsurance, banking, healthcare, etc. The disputes are generally resolved in a\nspecific forum (e.g., consumer court) where facts are presented, points of\ndisagreement are discussed, arguments as well as specific demands of the\nparties are heard, and finally a human judge resolves the dispute by often\nfavouring one of the two parties. In this paper, we explore the use of large\nlanguage models (LLMs) as assistants for the human judge to resolve such\ndisputes, as part of our DRAssist system. We focus on disputes from two\nspecific domains -- automobile insurance and domain name disputes. DRAssist\nidentifies certain key structural elements (e.g., facts, aspects or\ndisagreement, arguments) of the disputes and summarizes the unstructured\ndispute descriptions to produce a structured summary for each dispute. We then\nexplore multiple prompting strategies with multiple LLMs for their ability to\nassist in resolving the disputes in these domains. In DRAssist, these LLMs are\nprompted to produce the resolution output at three different levels -- (i)\nidentifying an overall stronger party in a dispute, (ii) decide whether each\nspecific demand of each contesting party can be accepted or not, (iii) evaluate\nwhether each argument by each contesting party is strong or weak. We evaluate\nthe performance of LLMs on all these tasks by comparing them with relevant\nbaselines using suitable evaluation metrics.", "published": "2025-09-02 05:09:34", "link": "http://arxiv.org/abs/2509.01962v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Content and Engagement Trends in COVID-19 YouTube Videos: Evidence from the Late Pandemic", "abstract": "This work investigated about 10,000 COVID-19-related YouTube videos published\nbetween January 2023 and October 2024 to evaluate how temporal, lexical,\nlinguistic, and structural factors influenced engagement during the late\npandemic period. Publishing activity showed consistent weekday effects: in the\nfirst window, average views peaked on Mondays at 92,658; in the second, on\nWednesdays at 115,479; and in the third, on Fridays at 84,874, reflecting a\nshift in audience attention toward mid- and late week. Lexical analysis of\nvideo titles revealed recurring high-frequency keywords related to COVID-19 and\nYouTube features, including COVID, coronavirus, shorts, and live. Frequency\nanalysis revealed sharp spikes, with COVID appearing in 799 video titles in\nAugust 2024, while engagement analysis showed that videos titled with shorts\nattracted very high views, peaking at 2.16 million average views per video in\nJune 2023. Analysis of sentiment of video descriptions in English showed weak\ncorrelation with views in the raw data (Pearson r = 0.0154, p = 0.2987), but\nstronger correlations emerged once outliers were addressed, with Spearman r =\n0.110 (p < 0.001) and Pearson r = 0.0925 (p < 0.001). Category-level analysis\nof video durations revealed contrasting outcomes: long videos focusing on\npeople and blogs averaged 209,114 views, short entertainment videos averaged\n288,675 views, and medium-to-long news and politics videos averaged 51,309 and\n59,226 views, respectively. These results demonstrate that engagement patterns\nof COVID-19-related videos on YouTube during the late pandemic followed\ndistinct characteristics driven by publishing schedules, title vocabulary,\ntopics, and genre-specific duration effects.", "published": "2025-09-02 04:49:03", "link": "http://arxiv.org/abs/2509.01954v1", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.ET", "cs.LG", "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"], "primary_category": "cs.SI"}
{"title": "EigenBench: A Comparative Behavioral Measure of Value Alignment", "abstract": "Aligning AI with human values is a pressing unsolved problem. To address the\nlack of quantitative metrics for value alignment, we propose EigenBench: a\nblack-box method for comparatively benchmarking language models' values. Given\nan ensemble of models, a constitution describing a value system, and a dataset\nof scenarios, our method returns a vector of scores quantifying each model's\nalignment to the given constitution. To produce these scores, each model judges\nthe outputs of other models across many scenarios, and these judgments are\naggregated with EigenTrust (Kamvar et al, 2003), yielding scores that reflect a\nweighted-average judgment of the whole ensemble. EigenBench uses no ground\ntruth labels, as it is designed to quantify traits for which reasonable judges\nmay disagree on the correct label. Using prompted personas, we test whether\nEigenBench scores are more sensitive to the model or the prompt: we find that\nmost of the variance is explained by the prompt, but a small residual\nquantifies the disposition of the model itself.", "published": "2025-09-02 04:14:26", "link": "http://arxiv.org/abs/2509.01938v1", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.AI"}
{"title": "How Real Is AI Tutoring? Comparing Simulated and Human Dialogues in One-on-One Instruction", "abstract": "Heuristic and scaffolded teacher-student dialogues are widely regarded as\ncritical for fostering students' higher-order thinking and deep learning.\nHowever, large language models (LLMs) currently face challenges in generating\npedagogically rich interactions. This study systematically investigates the\nstructural and behavioral differences between AI-simulated and authentic human\ntutoring dialogues. We conducted a quantitative comparison using an\nInitiation-Response-Feedback (IRF) coding scheme and Epistemic Network Analysis\n(ENA). The results show that human dialogues are significantly superior to\ntheir AI counterparts in utterance length, as well as in questioning (I-Q) and\ngeneral feedback (F-F) behaviors. More importantly, ENA results reveal a\nfundamental divergence in interactional patterns: human dialogues are more\ncognitively guided and diverse, centered around a \"question-factual\nresponse-feedback\" teaching loop that clearly reflects pedagogical guidance and\nstudent-driven thinking; in contrast, simulated dialogues exhibit a pattern of\nstructural simplification and behavioral convergence, revolving around an\n\"explanation-simplistic response\" loop that is essentially a simple information\ntransfer between the teacher and student. These findings illuminate key\nlimitations in current AI-generated tutoring and provide empirical guidance for\ndesigning and evaluating more pedagogically effective generative educational\ndialogue systems.", "published": "2025-09-02 03:18:39", "link": "http://arxiv.org/abs/2509.01914v1", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models", "abstract": "Large language models (LLMs) typically deploy safety mechanisms to prevent\nharmful content generation. Most current approaches focus narrowly on risks\nposed by malicious actors, often framing risks as adversarial events and\nrelying on defensive refusals. However, in real-world settings, risks also come\nfrom non-malicious users seeking help while under psychological distress (e.g.,\nself-harm intentions). In such cases, the model's response can strongly\ninfluence the user's next actions. Simple refusals may lead them to repeat,\nescalate, or move to unsafe platforms, creating worse outcomes. We introduce\nConstructive Safety Alignment (CSA), a human-centric paradigm that protects\nagainst malicious misuse while actively guiding vulnerable users toward safe\nand helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic\nanticipation of user reactions, fine-grained risk boundary discovery, and\ninterpretable reasoning control, turning safety into a trust-building process.\nOy1 achieves state-of-the-art safety among open models while retaining high\ngeneral capabilities. On our Constructive Benchmark, it shows strong\nconstructive engagement, close to GPT-5, and unmatched robustness on the\nStrata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from\nrefusal-first to guidance-first safety, CSA redefines the model-user\nrelationship, aiming for systems that are not just safe, but meaningfully\nhelpful. We release Oy1, code, and the benchmark to support responsible,\nuser-centered AI.", "published": "2025-09-02 03:04:27", "link": "http://arxiv.org/abs/2509.01909v1", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.SC"], "primary_category": "cs.AI"}
{"title": "RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events", "abstract": "Remote sensing is critical for disaster monitoring, yet existing datasets\nlack temporal image pairs and detailed textual annotations. While\nsingle-snapshot imagery dominates current resources, it fails to capture\ndynamic disaster impacts over time. To address this gap, we introduce the\nRemote Sensing Change Caption (RSCC) dataset, a large-scale benchmark\ncomprising 62,315 pre-/post-disaster image pairs (spanning earthquakes, floods,\nwildfires, and more) paired with rich, human-like change captions. By bridging\nthe temporal and semantic divide in remote sensing data, RSCC enables robust\ntraining and evaluation of vision-language models for disaster-aware\nbi-temporal understanding. Our results highlight RSCC's ability to facilitate\ndetailed disaster-related analysis, paving the way for more accurate,\ninterpretable, and scalable vision-language applications in remote sensing.\nCode and dataset are available at https://github.com/Bili-Sakura/RSCC.", "published": "2025-09-02 03:01:23", "link": "http://arxiv.org/abs/2509.01907v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Weakly Supervised Medical Entity Extraction and Linking for Chief Complaints", "abstract": "A Chief complaint (CC) is the reason for the medical visit as stated in the\npatient's own words. It helps medical professionals to quickly understand a\npatient's situation, and also serves as a short summary for medical text\nmining. However, chief complaint records often take a variety of entering\nmethods, resulting in a wide variation of medical notations, which makes it\ndifficult to standardize across different medical institutions for record\nkeeping or text mining. In this study, we propose a weakly supervised method to\nautomatically extract and link entities in chief complaints in the absence of\nhuman annotation. We first adopt a split-and-match algorithm to produce weak\nannotations, including entity mention spans and class labels, on 1.2 million\nreal-world de-identified and IRB approved chief complaint records. Then we\ntrain a BERT-based model with generated weak labels to locate entity mentions\nin chief complaint text and link them to a pre-defined ontology. We conducted\nextensive experiments, and the results showed that our Weakly Supervised Entity\nExtraction and Linking (\\ours) method produced superior performance over\nprevious methods without any human annotation.", "published": "2025-09-02 02:39:42", "link": "http://arxiv.org/abs/2509.01899v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting OPQRST in Electronic Health Records using Large Language Models with Reasoning", "abstract": "The extraction of critical patient information from Electronic Health Records\n(EHRs) poses significant challenges due to the complexity and unstructured\nnature of the data. Traditional machine learning approaches often fail to\ncapture pertinent details efficiently, making it difficult for clinicians to\nutilize these tools effectively in patient care. This paper introduces a novel\napproach to extracting the OPQRST assessment from EHRs by leveraging the\ncapabilities of Large Language Models (LLMs). We propose to reframe the task\nfrom sequence labeling to text generation, enabling the models to provide\nreasoning steps that mimic a physician's cognitive processes. This approach\nenhances interpretability and adapts to the limited availability of labeled\ndata in healthcare settings. Furthermore, we address the challenge of\nevaluating the accuracy of machine-generated text in clinical contexts by\nproposing a modification to traditional Named Entity Recognition (NER) metrics.\nThis includes the integration of semantic similarity measures, such as the BERT\nScore, to assess the alignment between generated text and the clinical intent\nof the original records. Our contributions demonstrate a significant\nadvancement in the use of AI in healthcare, offering a scalable solution that\nimproves the accuracy and usability of information extraction from EHRs,\nthereby aiding clinicians in making more informed decisions and enhancing\npatient care outcomes.", "published": "2025-09-02 02:21:02", "link": "http://arxiv.org/abs/2509.01885v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cut Costs, Not Accuracy: LLM-Powered Data Processing with Guarantees", "abstract": "Large Language Models (LLMs) are being increasingly used as a building block\nin data systems to process large text datasets. To do so, LLM model providers\noffer multiple LLMs with different sizes, spanning various cost-quality\ntrade-offs when processing text at scale. Top-of-the-line LLMs (e.g., GPT-4o,\nClaude Sonnet) operate with high accuracy but are prohibitively expensive when\nprocessing many records. To avoid high costs, more affordable but lower quality\nLLMs (e.g., GPT-4o-mini, Claude Haiku) can be used to process records, but we\nneed to ensure that the overall accuracy does not deviate substantially from\nthat of the top-of-the-line LLMs. The model cascade framework provides a\nblueprint to manage this trade-off, by using the confidence of LLMs in their\noutput (e.g., log-probabilities) to decide on which records to use the\naffordable LLM. However, existing solutions following this framework provide\nonly marginal cost savings and weak theoretical guarantees because of poor\nestimation of the quality of the affordable LLM's outputs. We present BARGAIN,\na method that judiciously uses affordable LLMs in data processing to\nsignificantly reduce cost while providing strong theoretical guarantees on the\nsolution quality. BARGAIN employs a novel adaptive sampling strategy and\nstatistical estimation procedure that uses data and task characteristics and\nbuilds on recent statistical tools to make accurate estimations with tight\ntheoretical guarantees. Variants of BARGAIN can support guarantees on accuracy,\nprecision, or recall of the output. Experimental results across 8 real-world\ndatasets show that BARGAIN reduces cost, on average, by up to 86% more than\nstate-of-the-art, while providing stronger theoretical guarantees on accuracy\nof output, with similar gains when guaranteeing a desired level of precision or\nrecall.", "published": "2025-09-02 23:41:50", "link": "http://arxiv.org/abs/2509.02896v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "Grocery to General Merchandise: A Cross-Pollination Recommender using LLMs and Real-Time Cart Context", "abstract": "Modern e-commerce platforms strive to enhance customer experience by\nproviding timely and contextually relevant recommendations. However,\nrecommending general merchandise to customers focused on grocery shopping --\nsuch as pairing milk with a milk frother -- remains a critical yet\nunder-explored challenge. This paper introduces a cross-pollination (XP)\nframework, a novel approach that bridges grocery and general merchandise\ncross-category recommendations by leveraging multi-source product associations\nand real-time cart context. Our solution employs a two-stage framework: (1) A\ncandidate generation mechanism that uses co-purchase market basket analysis and\nLLM-based approach to identify novel item-item associations; and (2) a\ntransformer-based ranker that leverages the real-time sequential cart context\nand optimizes for engagement signals such as add-to-carts. Offline analysis and\nonline A/B tests show an increase of 36\\% add-to-cart rate with LLM-based\nretrieval, and 27\\% NDCG\\@4 lift using cart context-based ranker. Our work\ncontributes practical techniques for cross-category recommendations and broader\ninsights for e-commerce systems.", "published": "2025-09-02 23:28:34", "link": "http://arxiv.org/abs/2509.02890v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Enhancing Machine Learning for Imbalanced Medical Data: A Quantum-Inspired Approach to Synthetic Oversampling (QI-SMOTE)", "abstract": "Class imbalance remains a critical challenge in machine learning (ML),\nparticularly in the medical domain, where underrepresented minority classes\nlead to biased models and reduced predictive performance. This study introduces\nQuantum-Inspired SMOTE (QI-SMOTE), a novel data augmentation technique that\nenhances the performance of ML classifiers, including Random Forest (RF),\nSupport Vector Machine (SVM), Logistic Regression (LR), k-Nearest Neighbors\n(KNN), Gradient Boosting (GB), and Neural Networks, by leveraging quantum\nprinciples such as quantum evolution and layered entanglement. Unlike\nconventional oversampling methods, QI-SMOTE generates synthetic instances that\npreserve complex data structures, improving model generalization and\nclassification accuracy. We validate QI-SMOTE on the MIMIC-III and MIMIC-IV\ndatasets, using mortality detection as a benchmark task due to their clinical\nsignificance and inherent class imbalance. We compare our method against\ntraditional oversampling techniques, including Borderline-SMOTE, ADASYN,\nSMOTE-ENN, SMOTE-TOMEK, and SVM-SMOTE, using key performance metrics such as\nAccuracy, F1-score, G-Mean, and AUC-ROC. The results demonstrate that QI-SMOTE\nsignificantly improves the effectiveness of ensemble methods (RF, GB, ADA),\nkernel-based models (SVM), and deep learning approaches by producing more\ninformative and balanced training data. By integrating quantum-inspired\ntransformations into the ML pipeline, QI-SMOTE not only mitigates class\nimbalance but also enhances the robustness and reliability of predictive models\nin medical diagnostics and decision-making. This study highlights the potential\nof quantum-inspired resampling techniques in advancing state-of-the-art ML\nmethodologies.", "published": "2025-09-02 22:20:46", "link": "http://arxiv.org/abs/2509.02863v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "The Architecture of AI Transformation: Four Strategic Patterns and an Emerging Frontier", "abstract": "Despite extensive investment in artificial intelligence, 95% of enterprises\nreport no measurable profit impact from AI deployments (MIT, 2025). We argue\nthat this gap reflects paradigmatic lock-in that channels AI into incremental\noptimization rather than structural transformation. Using a cross-case\nanalysis, we propose a 2x2 framework that reconceptualizes AI strategy along\ntwo independent dimensions: the degree of transformation achieved (incremental\nto transformational) and the treatment of human contribution (reduced to\namplified). The framework surfaces four patterns now dominant in practice:\nindividual augmentation, process automation, workforce substitution, and a less\ndeployed frontier of collaborative intelligence. Evidence shows that the first\nthree reinforce legacy work models and yield localized gains without durable\nvalue capture. Realizing collaborative intelligence requires three mechanisms:\ncomplementarity (pairing distinct human and machine strengths), co-evolution\n(mutual adaptation through interaction), and boundary-setting (human\ndetermination of ethical and strategic parameters). Complementarity and\nboundary-setting are observable in regulated and high-stakes domains;\nco-evolution is largely absent, which helps explain limited system-level\nimpact. A case study analysis illustrates that advancing toward collaborative\nintelligence requires material restructuring of roles, governance, and data\narchitecture rather than additional tools. The framework reframes AI\ntransformation as an organizational design challenge: moving from optimizing\nthe division of labor between humans and machines to architecting their\nconvergence, with implications for operating models, workforce development, and\nthe future of work.", "published": "2025-09-02 21:57:58", "link": "http://arxiv.org/abs/2509.02853v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Conformal Prediction for Time-series Forecasting with Change Points", "abstract": "Conformal prediction has been explored as a general and efficient way to\nprovide uncertainty quantification for time series. However, current methods\nstruggle to handle time series data with change points - sudden shifts in the\nunderlying data-generating process. In this paper, we propose a novel Conformal\nPrediction for Time-series with Change points (CPTC) algorithm, addressing this\ngap by integrating a model to predict the underlying state with online\nconformal prediction to model uncertainties in non-stationary time series. We\nprove CPTC's validity and improved adaptivity in the time series setting under\nminimum assumptions, and demonstrate CPTC's practical effectiveness on 6\nsynthetic and real-world datasets, showing improved validity and adaptivity\ncompared to state-of-the-art baselines.", "published": "2025-09-02 21:26:53", "link": "http://arxiv.org/abs/2509.02844v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "HF-RAG: Hierarchical Fusion-based RAG with Multiple Sources and Rankers", "abstract": "Leveraging both labeled (input-output associations) and unlabeled data (wider\ncontextual grounding) may provide complementary benefits in retrieval augmented\ngeneration (RAG). However, effectively combining evidence from these\nheterogeneous sources is challenging as the respective similarity scores are\nnot inter-comparable. Additionally, aggregating beliefs from the outputs of\nmultiple rankers can improve the effectiveness of RAG. Our proposed method\nfirst aggregates the top-documents from a number of IR models using a standard\nrank fusion technique for each source (labeled and unlabeled). Next, we\nstandardize the retrieval score distributions within each source by applying\nz-score transformation before merging the top-retrieved documents from the two\nsources. We evaluate our approach on the fact verification task, demonstrating\nthat it consistently improves over the best-performing individual ranker or\nsource and also shows better out-of-domain generalization.", "published": "2025-09-02 21:03:40", "link": "http://arxiv.org/abs/2509.02837v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Ensemble Learning for Healthcare: A Comparative Analysis of Hybrid Voting and Ensemble Stacking in Obesity Risk Prediction", "abstract": "Obesity is a critical global health issue driven by dietary, physiological,\nand environmental factors, and is strongly associated with chronic diseases\nsuch as diabetes, cardiovascular disorders, and cancer. Machine learning has\nemerged as a promising approach for early obesity risk prediction, yet a\ncomparative evaluation of ensemble techniques -- particularly hybrid majority\nvoting and ensemble stacking -- remains limited. This study aims to compare\nhybrid majority voting and ensemble stacking methods for obesity risk\nprediction, identifying which approach delivers higher accuracy and efficiency.\nThe analysis seeks to highlight the complementary strengths of these ensemble\ntechniques in guiding better predictive model selection for healthcare\napplications. Two datasets were utilized to evaluate three ensemble models:\nMajority Hard Voting, Weighted Hard Voting, and Stacking (with a Multi-Layer\nPerceptron as meta-classifier). A pool of nine Machine Learning (ML)\nalgorithms, evaluated across a total of 50 hyperparameter configurations, was\nanalyzed to identify the top three models to serve as base learners for the\nensemble methods. Preprocessing steps involved dataset balancing, and outlier\ndetection, and model performance was evaluated using Accuracy and F1-Score. On\nDataset-1, weighted hard voting and stacking achieved nearly identical\nperformance (Accuracy: 0.920304, F1: 0.920070), outperforming majority hard\nvoting. On Dataset-2, stacking demonstrated superior results (Accuracy:\n0.989837, F1: 0.989825) compared to majority hard voting (Accuracy: 0.981707,\nF1: 0.981675) and weighted hard voting, which showed the lowest performance.\nThe findings confirm that ensemble stacking provides stronger predictive\ncapability, particularly for complex data distributions, while hybrid majority\nvoting remains a robust alternative.", "published": "2025-09-02 20:44:52", "link": "http://arxiv.org/abs/2509.02826v1", "categories": ["cs.LG", "cs.AI", "stat.AP", "stat.CO"], "primary_category": "cs.LG"}
{"title": "Improving the Resilience of Quadrotors in Underground Environments by Combining Learning-based and Safety Controllers", "abstract": "Autonomously controlling quadrotors in large-scale subterranean environments\nis applicable to many areas such as environmental surveying, mining operations,\nand search and rescue. Learning-based controllers represent an appealing\napproach to autonomy, but are known to not generalize well to\n`out-of-distribution' environments not encountered during training. In this\nwork, we train a normalizing flow-based prior over the environment, which\nprovides a measure of how far out-of-distribution the quadrotor is at any given\ntime. We use this measure as a runtime monitor, allowing us to switch between a\nlearning-based controller and a safe controller when we are sufficiently\nout-of-distribution. Our methods are benchmarked on a point-to-point navigation\ntask in a simulated 3D cave environment based on real-world point cloud data\nfrom the DARPA Subterranean Challenge Final Event Dataset. Our experimental\nresults show that our combined controller simultaneously possesses the liveness\nof the learning-based controller (completing the task quickly) and the safety\nof the safety controller (avoiding collision).", "published": "2025-09-02 20:22:54", "link": "http://arxiv.org/abs/2509.02808v1", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Learning General Policies From Examples", "abstract": "Combinatorial methods for learning general policies that solve large\ncollections of planning problems have been recently developed. One of their\nstrengths, in relation to deep learning approaches, is that the resulting\npolicies can be understood and shown to be correct. A weakness is that the\nmethods do not scale up and learn only from small training instances and\nfeature pools that contain a few hundreds of states and features at most. In\nthis work, we propose a new symbolic method for learning policies based on the\ngeneralization of sampled plans that ensures structural termination and hence\nacyclicity. The proposed learning approach is not based on SAT/ASP, as previous\nsymbolic methods, but on a hitting set algorithm that can effectively handle\nproblems with millions of states, and pools with hundreds of thousands of\nfeatures. The formal properties of the approach are analyzed, and its\nscalability is tested on a number of benchmarks.", "published": "2025-09-02 19:56:08", "link": "http://arxiv.org/abs/2509.02794v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "The Transparent Earth: A Multimodal Foundation Model for the Earth's Subsurface", "abstract": "We present the Transparent Earth, a transformer-based architecture for\nreconstructing subsurface properties from heterogeneous datasets that vary in\nsparsity, resolution, and modality, where each modality represents a distinct\ntype of observation (e.g., stress angle, mantle temperature, tectonic plate\ntype). The model incorporates positional encodings of observations together\nwith modality encodings, derived from a text embedding model applied to a\ndescription of each modality. This design enables the model to scale to an\narbitrary number of modalities, making it straightforward to add new ones not\nconsidered in the initial design. We currently include eight modalities\nspanning directional angles, categorical classes, and continuous properties\nsuch as temperature and thickness. These capabilities support in-context\nlearning, enabling the model to generate predictions either with no inputs or\nwith an arbitrary number of additional observations from any subset of\nmodalities. On validation data, this reduces errors in predicting stress angle\nby more than a factor of three. The proposed architecture is scalable and\ndemonstrates improved performance with increased parameters. Together, these\nadvances make the Transparent Earth an initial foundation model for the Earth's\nsubsurface that ultimately aims to predict any subsurface property anywhere on\nEarth.", "published": "2025-09-02 19:37:12", "link": "http://arxiv.org/abs/2509.02783v1", "categories": ["cs.LG", "cs.AI", "physics.geo-ph"], "primary_category": "cs.LG"}
{"title": "Key Principles in Cross-Domain Hyper-Heuristic Performance", "abstract": "Cross-domain selection hyper-heuristics aim to distill decades of research on\nproblem-specific heuristic search algorithms into adaptable general-purpose\nsearch strategies. In this respect, existing selection hyper-heuristics\nprimarily focus on an adaptive selection of low-level heuristics (LLHs) from a\npredefined set. In contrast, we concentrate on the composition of this set and\nits strategic transformations. We systematically analyze transformations based\non three key principles: solution acceptance, LLH repetitions, and perturbation\nintensity, i.e., the proportion of a solution affected by a perturbative LLH.\nWe demonstrate the raw effects of our transformations on a trivial unbiased\nrandom selection mechanism. With an appropriately constructed transformation,\nthis trivial method outperforms all available state-of-the-art hyper-heuristics\non three challenging real-world domains and finds 11 new best-known solutions.\nThe same method is competitive with the winner of the CHeSC competition,\ncommonly used as the standard cross-domain benchmark. Moreover, we accompany\nseveral recent hyper-heuristics with such strategic transformations. Using this\napproach, we outperform the current state-of-the-art methods on both the CHeSC\nbenchmark and real-world domains while often simplifying their designs.", "published": "2025-09-02 19:36:28", "link": "http://arxiv.org/abs/2509.02782v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Plan Verification for LLM-Based Embodied Task Completion Agents", "abstract": "Large language model (LLM) based task plans and corresponding human\ndemonstrations for embodied AI may be noisy, with unnecessary actions,\nredundant navigation, and logical errors that reduce policy quality. We propose\nan iterative verification framework in which a Judge LLM critiques action\nsequences and a Planner LLM applies the revisions, yielding progressively\ncleaner and more spatially coherent trajectories. Unlike rule-based approaches,\nour method relies on natural language prompting, enabling broad generalization\nacross error types including irrelevant actions, contradictions, and missing\nsteps. On a set of manually annotated actions from the TEACh embodied AI\ndataset, our framework achieves up to 90% recall and 100% precision across four\nstate-of-the-art LLMs (GPT o4-mini, DeepSeek-R1, Gemini 2.5, LLaMA 4 Scout).\nThe refinement loop converges quickly, with 96.5% of sequences requiring at\nmost three iterations, while improving both temporal efficiency and spatial\naction organization. Crucially, the method preserves human error-recovery\npatterns rather than collapsing them, supporting future work on robust\ncorrective behavior. By establishing plan verification as a reliable LLM\ncapability for spatial planning and action refinement, we provide a scalable\npath to higher-quality training data for imitation learning in embodied AI.", "published": "2025-09-02 19:06:56", "link": "http://arxiv.org/abs/2509.02761v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Optimizing Geometry Problem Sets for Skill Development", "abstract": "This article describes an ontology and methodology for annotating and\norganizing Euclidean Geometry problems, developed in the early 1990s and\nimplemented as a software tool. While the majority of this work -- including\nthe ontology and solution graph paradigm -- was completed over thirty years\nago, we argue that it has renewed relevance in the context of modern artificial\nintelligence. In particular, we explore the hypothesis that this established\nframework can facilitate automated solution validation and feedback when paired\nwith contemporary large language models, thereby supporting teachers and\nself-learners in geometry education. We document the original architecture and\nits enduring value, and outline pathways for bridging historical educational\nresources with next-generation AI techniques.", "published": "2025-09-02 19:04:45", "link": "http://arxiv.org/abs/2509.02758v1", "categories": ["math.HO", "cs.AI", "51M05, 68T05", "I.2.4"], "primary_category": "math.HO"}
{"title": "Do LLM Modules Generalize? A Study on Motion Generation for Autonomous Driving", "abstract": "Recent breakthroughs in large language models (LLMs) have not only advanced\nnatural language processing but also inspired their application in domains with\nstructurally similar problems--most notably, autonomous driving motion\ngeneration. Both domains involve autoregressive sequence modeling, token-based\nrepresentations, and context-aware decision making, making the transfer of LLM\ncomponents a natural and increasingly common practice. However, despite\npromising early attempts, a systematic understanding of which LLM modules are\ntruly transferable remains lacking. In this paper, we present a comprehensive\nevaluation of five key LLM modules--tokenizer design, positional embedding,\npre-training paradigms, post-training strategies, and test-time\ncomputation--within the context of motion generation for autonomous driving.\nThrough extensive experiments on the Waymo Sim Agents benchmark, we demonstrate\nthat, when appropriately adapted, these modules can significantly improve\nperformance for autonomous driving motion generation. In addition, we identify\nwhich techniques can be effectively transferred, analyze the potential reasons\nfor the failure of others, and discuss the specific adaptations needed for\nautonomous driving scenarios. We evaluate our method on the Sim Agents task and\nachieve competitive results.", "published": "2025-09-02 19:02:49", "link": "http://arxiv.org/abs/2509.02754v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics", "abstract": "With advances in large language models (LLMs), researchers are creating new\nsystems that can perform AI-driven analytics over large unstructured datasets.\nRecent work has explored executing such analytics queries using semantic\noperators -- a declarative set of AI-powered data transformations with natural\nlanguage specifications. However, even when optimized, these operators can be\nexpensive to execute on millions of records and their iterator execution\nsemantics make them ill-suited for interactive data analytics tasks. In another\nline of work, Deep Research systems have demonstrated an ability to answer\nnatural language question(s) over large datasets. These systems use one or more\nLLM agent(s) to plan their execution, process the dataset(s), and iteratively\nrefine their answer. However, these systems do not explicitly optimize their\nquery plans which can lead to poor plan execution. In order for AI-driven\nanalytics to excel, we need a runtime which combines the optimized execution of\nsemantic operators with the flexibility and more dynamic execution of Deep\nResearch systems. As a first step towards this vision, we build a prototype\nwhich enables Deep Research agents to write and execute optimized semantic\noperator programs. We evaluate our prototype and demonstrate that it can\noutperform a handcrafted semantic operator program and open Deep Research\nsystems on two basic queries. Compared to a standard open Deep Research agent,\nour prototype achieves up to 1.95x better F1-score. Furthermore, even if we\ngive the agent access to semantic operators as tools, our prototype still\nachieves cost and runtime savings of up to 76.8% and 72.7% thanks to its\noptimized execution.", "published": "2025-09-02 18:59:15", "link": "http://arxiv.org/abs/2509.02751v1", "categories": ["cs.AI", "cs.DB", "cs.LG", "cs.MA", "I.2.1; H.3.3; H.2.4"], "primary_category": "cs.AI"}
{"title": "Mentality: A Mamba-based Approach towards Foundation Models for EEG", "abstract": "This work explores the potential of foundation models, specifically a\nMamba-based selective state space model, for enhancing EEG analysis in\nneurological disorder diagnosis. EEG, crucial for diagnosing conditions like\nepilepsy, presents significant challenges due to its noisy, high-dimensional,\nand nonlinear nature. Traditional machine learning methods have made advances\nin automating EEG analysis but often fail to capture its complex\nspatio-temporal dynamics. Recent advances in deep learning, particularly in\nsequence modeling, offer new avenues for creating more generalized and\nexpressive models capable of handling such complexities. By training a\nMamba-based model on a large dataset containing seizure and non-seizure EEG\nrecordings through a self-supervised reconstruction task followed by a seizure\ndetection task, we demonstrate the model's effectiveness, achieving an AUROC of\n0.72 on a held-out test set. This approach marks a significant step toward\ndeveloping large-scale, clinically applicable foundation models for EEG data\nanalysis.", "published": "2025-09-02 18:47:38", "link": "http://arxiv.org/abs/2509.02746v1", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "primary_category": "cs.LG"}
{"title": "Planning with Reasoning using Vision Language World Model", "abstract": "Effective planning requires strong world models, but high-level world models\nthat can understand and reason about actions with semantic and temporal\nabstraction remain largely underdeveloped. We introduce the Vision Language\nWorld Model (VLWM), a foundation model trained for language-based world\nmodeling on natural videos. Given visual observations, the VLWM first infers\nthe overall goal achievements then predicts a trajectory composed of\ninterleaved actions and world state changes. Those targets are extracted by\niterative LLM Self-Refine conditioned on compressed future observations\nrepresented by Tree of Captions. The VLWM learns both an action policy and a\ndynamics model, which respectively facilitates reactive system-1 plan decoding\nand reflective system-2 planning via cost minimization. The cost evaluates the\nsemantic distance between the hypothetical future states given by VLWM\nroll-outs and the expected goal state, and is measured by a critic model that\nwe trained in a self-supervised manner. The VLWM achieves state-of-the-art\nVisual Planning for Assistance (VPA) performance on both benchmark evaluations\nand our proposed PlannerArena human evaluations, where system-2 improves the\nElo score by +27% upon system-1. The VLWM models also outperforms strong VLM\nbaselines on RoboVQA and WorldPrediction benchmark.", "published": "2025-09-02 18:18:57", "link": "http://arxiv.org/abs/2509.02722v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "The Future of Artificial Intelligence and the Mathematical and Physical Sciences (AI+MPS)", "abstract": "This community paper developed out of the NSF Workshop on the Future of\nArtificial Intelligence (AI) and the Mathematical and Physics Sciences (MPS),\nwhich was held in March 2025 with the goal of understanding how the MPS domains\n(Astronomy, Chemistry, Materials Research, Mathematical Sciences, and Physics)\ncan best capitalize on, and contribute to, the future of AI. We present here a\nsummary and snapshot of the MPS community's perspective, as of Spring/Summer\n2025, in a rapidly developing field. The link between AI and MPS is becoming\nincreasingly inextricable; now is a crucial moment to strengthen the link\nbetween AI and Science by pursuing a strategy that proactively and thoughtfully\nleverages the potential of AI for scientific discovery and optimizes\nopportunities to impact the development of AI by applying concepts from\nfundamental science. To achieve this, we propose activities and strategic\npriorities that: (1) enable AI+MPS research in both directions; (2) build up an\ninterdisciplinary community of AI+MPS researchers; and (3) foster education and\nworkforce development in AI for MPS researchers and students. We conclude with\na summary of suggested priorities for funding agencies, educational\ninstitutions, and individual researchers to help position the MPS community to\nbe a leader in, and take full advantage of, the transformative potential of\nAI+MPS.", "published": "2025-09-02 18:00:00", "link": "http://arxiv.org/abs/2509.02661v1", "categories": ["cs.AI", "astro-ph.IM", "cond-mat.mtrl-sci", "cs.LG", "physics.data-an"], "primary_category": "cs.AI"}
{"title": "Surrogate Benchmarks for Model Merging Optimization", "abstract": "Model merging techniques aim to integrate the abilities of multiple models\ninto a single model. Most model merging techniques have hyperparameters, and\ntheir setting affects the performance of the merged model. Because several\nexisting works show that tuning hyperparameters in model merging can enhance\nthe merging outcome, developing hyperparameter optimization algorithms for\nmodel merging is a promising direction. However, its optimization process is\ncomputationally expensive, particularly in merging LLMs. In this work, we\ndevelop surrogate benchmarks for optimization of the merging hyperparameters to\nrealize algorithm development and performance comparison at low cost. We define\ntwo search spaces and collect data samples to construct surrogate models to\npredict the performance of a merged model from a hyperparameter. We demonstrate\nthat our benchmarks can predict the performance of merged models well and\nsimulate optimization algorithm behaviors.", "published": "2025-09-02 17:51:03", "link": "http://arxiv.org/abs/2509.02555v1", "categories": ["cs.LG", "cs.AI", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots", "abstract": "Modern robotic manipulation primarily relies on visual observations in a 2D\ncolor space for skill learning but suffers from poor generalization. In\ncontrast, humans, living in a 3D world, depend more on physical properties-such\nas distance, size, and shape-than on texture when interacting with objects.\nSince such 3D geometric information can be acquired from widely available depth\ncameras, it appears feasible to endow robots with similar perceptual\ncapabilities. Our pilot study found that using depth cameras for manipulation\nis challenging, primarily due to their limited accuracy and susceptibility to\nvarious types of noise. In this work, we propose Camera Depth Models (CDMs) as\na simple plugin on daily-use depth cameras, which take RGB images and raw depth\nsignals as input and output denoised, accurate metric depth. To achieve this,\nwe develop a neural data engine that generates high-quality paired data from\nsimulation by modeling a depth camera's noise pattern. Our results show that\nCDMs achieve nearly simulation-level accuracy in depth prediction, effectively\nbridging the sim-to-real gap for manipulation tasks. Notably, our experiments\ndemonstrate, for the first time, that a policy trained on raw simulated depth,\nwithout the need for adding noise or real-world fine-tuning, generalizes\nseamlessly to real-world robots on two challenging long-horizon tasks involving\narticulated, reflective, and slender objects, with little to no performance\ndegradation. We hope our findings will inspire future research in utilizing\nsimulation data and 3D information in general robot policies.", "published": "2025-09-02 17:29:38", "link": "http://arxiv.org/abs/2509.02530v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Contemporary Agent Technology: LLM-Driven Advancements vs Classic Multi-Agent Systems", "abstract": "This contribution provides our comprehensive reflection on the contemporary\nagent technology, with a particular focus on the advancements driven by Large\nLanguage Models (LLM) vs classic Multi-Agent Systems (MAS). It delves into the\nmodels, approaches, and characteristics that define these new systems. The\npaper emphasizes the critical analysis of how the recent developments relate to\nthe foundational MAS, as articulated in the core academic literature. Finally,\nit identifies key challenges and promising future directions in this rapidly\nevolving domain.", "published": "2025-09-02 17:07:58", "link": "http://arxiv.org/abs/2509.02515v1", "categories": ["cs.MA", "cs.AI", "68Txx", "I.2"], "primary_category": "cs.MA"}
{"title": "Probabilistically stable revision and comparative probability: a representation theorem and applications", "abstract": "The stability rule for belief, advocated by Leitgeb [Annals of Pure and\nApplied Logic 164, 2013], is a rule for rational acceptance that captures\ncategorical belief in terms of $\\textit{probabilistically stable\npropositions}$: propositions to which the agent assigns resiliently high\ncredence. The stability rule generates a class of $\\textit{probabilistically\nstable belief revision}$ operators, which capture the dynamics of belief that\nresult from an agent updating their credences through Bayesian conditioning\nwhile complying with the stability rule for their all-or-nothing beliefs. In\nthis paper, we prove a representation theorem that yields a complete\ncharacterisation of such probabilistically stable revision operators and\nprovides a `qualitative' selection function semantics for the (non-monotonic)\nlogic of probabilistically stable belief revision. Drawing on the theory of\ncomparative probability orders, this result gives necessary and sufficient\nconditions for a selection function to be representable as a\nstrongest-stable-set operator on a finite probability space. The resulting\nlogic of probabilistically stable belief revision exhibits strong monotonicity\nproperties while failing the AGM belief revision postulates and satisfying only\nvery weak forms of case reasoning. In showing the main theorem, we prove two\nresults of independent interest to the theory of comparative probability: the\nfirst provides necessary and sufficient conditions for the joint representation\nof a pair of (respectively, strict and non-strict) comparative probability\norders. The second result provides a method for axiomatising the logic of ratio\ncomparisons of the form ``event $A$ is at least $k$ times more likely than\nevent $B$''. In addition to these measurement-theoretic applications, we point\nout two applications of our main result to the theory of simple voting games\nand to revealed preference theory.", "published": "2025-09-02 16:42:47", "link": "http://arxiv.org/abs/2509.02495v1", "categories": ["cs.LO", "cs.AI", "econ.TH", "math.PR", "03B42, 03B48, 03B70, 60A05, 68T27, 91B12"], "primary_category": "cs.LO"}
{"title": "GridMind: LLMs-Powered Agents for Power System Analysis and Operations", "abstract": "The complexity of traditional power system analysis workflows presents\nsignificant barriers to efficient decision-making in modern electric grids.\nThis paper presents GridMind, a multi-agent AI system that integrates Large\nLanguage Models (LLMs) with deterministic engineering solvers to enable\nconversational scientific computing for power system analysis. The system\nemploys specialized agents coordinating AC Optimal Power Flow and N-1\ncontingency analysis through natural language interfaces while maintaining\nnumerical precision via function calls. GridMind addresses workflow\nintegration, knowledge accessibility, context preservation, and expert\ndecision-support augmentation. Experimental evaluation on IEEE test cases\ndemonstrates that the proposed agentic framework consistently delivers correct\nsolutions across all tested language models, with smaller LLMs achieving\ncomparable analytical accuracy with reduced computational latency. This work\nestablishes agentic AI as a viable paradigm for scientific computing,\ndemonstrating how conversational interfaces can enhance accessibility while\npreserving numerical rigor essential for critical engineering applications.", "published": "2025-09-02 16:42:18", "link": "http://arxiv.org/abs/2509.02494v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MLP-Offload: Multi-Level, Multi-Path Offloading for LLM Pre-training to Break the GPU Memory Wall", "abstract": "Training LLMs larger than the aggregated memory of multiple GPUs is\nincreasingly necessary due to the faster growth of LLM sizes compared to GPU\nmemory. To this end, multi-tier host memory or disk offloading techniques are\nproposed by state of art. Despite advanced asynchronous multi-tier read/write\nstrategies, such offloading strategies result in significant I/O overheads in\nthe critical path of training, resulting in slower iterations. To this end, we\npropose MLP-Offload, a novel multi-level, multi-path offloading engine\nspecifically designed for optimizing LLM training on resource-constrained\nsetups by mitigating I/O bottlenecks. We make several key observations that\ndrive the design of MLP-Offload, such as I/O overheads during the update\ndominate the iteration time; I/O bandwidth of the third-level remote storage\ntier remains unutilized; and, contention due to concurrent offloading amplifies\nI/O bottlenecks. Driven by these insights, we design and implement MLP-Offload\nto offload the optimizer states across multiple tiers in a cache-efficient and\nconcurrency-controlled fashion to mitigate I/O bottlenecks during the backward\nand update phases. Evaluations on models up to 280B parameters shows that\nMLP-Offload achieves 2.5$\\times$ faster iterations compared to the\nstate-of-the-art LLM training runtimes.", "published": "2025-09-02 16:30:49", "link": "http://arxiv.org/abs/2509.02480v1", "categories": ["cs.DC", "cs.AI", "cs.LG", "H.2.0; E.2; I.2.11"], "primary_category": "cs.DC"}
{"title": "Generative Sequential Notification Optimization via Multi-Objective Decision Transformers", "abstract": "Notifications are an important communication channel for delivering timely\nand relevant information. Optimizing their delivery involves addressing complex\nsequential decision-making challenges under constraints such as message utility\nand user fatigue. Offline reinforcement learning (RL) methods, such as\nConservative Q-Learning (CQL), have been applied to this problem but face\npractical challenges at scale, including instability, sensitivity to\ndistribution shifts, limited reproducibility, and difficulties with\nexplainability in high-dimensional recommendation settings. We present a\nDecision Transformer (DT) based framework that reframes policy learning as\nreturn-conditioned supervised learning, improving robustness, scalability, and\nmodeling flexibility. Our contributions include a real-world comparison with\nCQL, a multi-reward design suitable for non-episodic tasks, a quantile\nregression approach to return-to-go conditioning, and a production-ready system\nwith circular buffer-based sequence processing for near-real-time inference.\nExtensive offline and online experiments in a deployed notification system show\nthat our approach improves notification utility and overall session activity\nwhile minimizing user fatigue. Compared to a multi-objective CQL-based agent,\nthe DT-based approach achieved a +0.72% increase in sessions for notification\ndecision-making at LinkedIn by making notification recommendation more\nrelevant.", "published": "2025-09-02 16:09:02", "link": "http://arxiv.org/abs/2509.02458v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "From Noisy Labels to Intrinsic Structure: A Geometric-Structural Dual-Guided Framework for Noise-Robust Medical Image Segmentation", "abstract": "The effectiveness of convolutional neural networks in medical image\nsegmentation relies on large-scale, high-quality annotations, which are costly\nand time-consuming to obtain. Even expert-labeled datasets inevitably contain\nnoise arising from subjectivity and coarse delineations, which disrupt feature\nlearning and adversely impact model performance. To address these challenges,\nthis study propose a Geometric-Structural Dual-Guided Network (GSD-Net), which\nintegrates geometric and structural cues to improve robustness against noisy\nannotations. It incorporates a Geometric Distance-Aware module that dynamically\nadjusts pixel-level weights using geometric features, thereby strengthening\nsupervision in reliable regions while suppressing noise. A Structure-Guided\nLabel Refinement module further refines labels with structural priors, and a\nKnowledge Transfer module enriches supervision and improves sensitivity to\nlocal details. To comprehensively assess its effectiveness, we evaluated\nGSD-Net on six publicly available datasets: four containing three types of\nsimulated label noise, and two with multi-expert annotations that reflect\nreal-world subjectivity and labeling inconsistencies. Experimental results\ndemonstrate that GSD-Net achieves state-of-the-art performance under noisy\nannotations, achieving improvements of 2.52% on Kvasir, 22.76% on Shenzhen,\n8.87% on BU-SUC, and 4.59% on BraTS2020 under SR simulated noise. The codes of\nthis study are available at https://github.com/ortonwang/GSD-Net.", "published": "2025-09-02 15:23:59", "link": "http://arxiv.org/abs/2509.02419v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Survey: Towards Privacy and Security in Mobile Large Language Models", "abstract": "Mobile Large Language Models (LLMs) are revolutionizing diverse fields such\nas healthcare, finance, and education with their ability to perform advanced\nnatural language processing tasks on-the-go. However, the deployment of these\nmodels in mobile and edge environments introduces significant challenges\nrelated to privacy and security due to their resource-intensive nature and the\nsensitivity of the data they process. This survey provides a comprehensive\noverview of privacy and security issues associated with mobile LLMs,\nsystematically categorizing existing solutions such as differential privacy,\nfederated learning, and prompt encryption. Furthermore, we analyze\nvulnerabilities unique to mobile LLMs, including adversarial attacks,\nmembership inference, and side-channel attacks, offering an in-depth comparison\nof their effectiveness and limitations. Despite recent advancements, mobile\nLLMs face unique hurdles in achieving robust security while maintaining\nefficiency in resource-constrained environments. To bridge this gap, we propose\npotential applications, discuss open challenges, and suggest future research\ndirections, paving the way for the development of trustworthy,\nprivacy-compliant, and scalable mobile LLM systems.", "published": "2025-09-02 15:19:57", "link": "http://arxiv.org/abs/2509.02411v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "BioBlue: Notable runaway-optimiser-like LLM failure modes on biologically and economically aligned AI safety benchmarks for LLMs with simplified observation format", "abstract": "Relatively many past AI safety discussions have centered around the dangers\nof unbounded utility maximisation by RL agents, illustrated by scenarios like\nthe \"paperclip maximiser\" or by specification gaming in general. Unbounded\nmaximisation is problematic for many reasons. We wanted to verify whether these\nRL runaway optimisation problems are still relevant with LLMs as well. Turns\nout, strangely, this is indeed clearly the case. The problem is not that the\nLLMs just lose context or become incoherent. The problem is that in various\nscenarios, LLMs lose context in very specific ways, which systematically\nresemble runaway optimisers in the following distinct ways: 1) Ignoring\nhomeostatic targets and \"defaulting\" to unbounded maximisation instead. 2) It\nis equally concerning that the \"default\" meant also reverting back to\nsingle-objective optimisation. Our findings also suggest that long-running\nscenarios are important. Systematic failures emerge after periods of initially\nsuccessful behaviour. In some trials the LLMs were successful until the end.\nThis means, while current LLMs do conceptually grasp biological and economic\nalignment, they exhibit randomly triggered problematic behavioural tendencies\nunder sustained long-running conditions, particularly involving multiple or\ncompeting objectives. Once they flip, they usually do not recover. Even though\nLLMs look multi-objective and bounded on the surface, the underlying mechanisms\nseem to be actually still biased towards being single-objective and unbounded.", "published": "2025-09-02 15:13:14", "link": "http://arxiv.org/abs/2509.02655v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Towards Agents That Know When They Don't Know: Uncertainty as a Control Signal for Structured Reasoning", "abstract": "Large language model (LLM) agents are increasingly deployed in structured\nbiomedical data environments, yet they often produce fluent but overconfident\noutputs when reasoning over complex multi-table data. We introduce an\nuncertainty-aware agent for query-conditioned multi-table summarization that\nleverages two complementary signals: (i) retrieval uncertainty--entropy over\nmultiple table-selection rollouts--and (ii) summary uncertainty--combining\nself-consistency and perplexity. Summary uncertainty is incorporated into\nreinforcement learning (RL) with Group Relative Policy Optimization (GRPO),\nwhile both retrieval and summary uncertainty guide inference-time filtering and\nsupport the construction of higher-quality synthetic datasets.\n  On multi-omics benchmarks, our approach improves factuality and calibration,\nnearly tripling correct and useful claims per summary (3.0\\(\\rightarrow\\)8.4\ninternal; 3.6\\(\\rightarrow\\)9.9 cancer multi-omics) and substantially improving\ndownstream survival prediction (C-index 0.32\\(\\rightarrow\\)0.63). These results\ndemonstrate that uncertainty can serve as a control signal--enabling agents to\nabstain, communicate confidence, and become more reliable tools for complex\nstructured-data environments.", "published": "2025-09-02 15:12:10", "link": "http://arxiv.org/abs/2509.02401v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Real-time ML-based Defense Against Malicious Payload in Reconfigurable Embedded Systems", "abstract": "The growing use of FPGAs in reconfigurable systems introducessecurity risks\nthrough malicious bitstreams that could cause denial-of-service (DoS), data\nleakage, or covert attacks. We investigated chip-level hardware malicious\npayload in embedded systems and proposed a supervised machine learning method\nto detect malicious bitstreams via static byte-level features. Our approach\ndiverges from existing methods by analyzing bitstreams directly at the binary\nlevel, enabling real-time detection without requiring access to source code or\nnetlists. Bitstreams were sourced from state-of-the-art (SOTA) benchmarks and\nre-engineered to target the Xilinx PYNQ-Z1 FPGA Development Board. Our dataset\nincluded 122 samples of benign and malicious configurations. The data were\nvectorized using byte frequency analysis, compressed using TSVD, and balanced\nusing SMOTE to address class imbalance. The evaluated classifiers demonstrated\nthat Random Forest achieved a macro F1-score of 0.97, underscoring the\nviability of real-time Trojan detection on resource-constrained systems. The\nfinal model was serialized and successfully deployed via PYNQ to enable\nintegrated bitstream analysis.", "published": "2025-09-02 14:52:43", "link": "http://arxiv.org/abs/2509.02387v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "PRECISE-AS: Personalized Reinforcement Learning for Efficient Point-of-Care Echocardiography in Aortic Stenosis Diagnosis", "abstract": "Aortic stenosis (AS) is a life-threatening condition caused by a narrowing of\nthe aortic valve, leading to impaired blood flow. Despite its high prevalence,\naccess to echocardiography (echo), the gold-standard diagnostic tool, is often\nlimited due to resource constraints, particularly in rural and underserved\nareas. Point-of-care ultrasound (POCUS) offers a more accessible alternative\nbut is restricted by operator expertise and the challenge of selecting the most\nrelevant imaging views. To address this, we propose a reinforcement learning\n(RL)-driven active video acquisition framework that dynamically selects each\npatient's most informative echo videos. Unlike traditional methods that rely on\na fixed set of videos, our approach continuously evaluates whether additional\nimaging is needed, optimizing both accuracy and efficiency. Tested on data from\n2,572 patients, our method achieves 80.6% classification accuracy while using\nonly 47% of the echo videos compared to a full acquisition. These results\ndemonstrate the potential of active feature acquisition to enhance AS\ndiagnosis, making echocardiographic assessments more efficient, scalable, and\npersonalized. Our source code is available at:\nhttps://github.com/Armin-Saadat/PRECISE-AS.", "published": "2025-09-02 23:47:43", "link": "http://arxiv.org/abs/2509.02898v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-Scale Deep Learning for Colon Histopathology: A Hybrid Graph-Transformer Approach", "abstract": "Colon cancer also known as Colorectal cancer, is one of the most malignant\ntypes of cancer worldwide. Early-stage detection of colon cancer is highly\ncrucial to prevent its deterioration. This research presents a hybrid\nmulti-scale deep learning architecture that synergizes capsule networks, graph\nattention mechanisms, transformer modules, and residual learning to advance\ncolon cancer classification on the Lung and Colon Cancer Histopathological\nImage Dataset (LC25000) dataset. The proposed model in this paper utilizes the\nHG-TNet model that introduces a hybrid architecture that joins strength points\nin transformers and convolutional neural networks to capture multi-scale\nfeatures in histopathological images. Mainly, a transformer branch extracts\nglobal contextual bonds by partitioning the image into patches by\nconvolution-based patch embedding and then processing these patches through a\ntransformer encoder. Analogously, a dedicated CNN branch captures fine-grained,\nlocal details through successive Incorporation these diverse features, combined\nwith a self-supervised rotation prediction objective, produce a robust\ndiagnostic representation that surpasses standard architectures in performance.\nResults show better performance not only in accuracy or loss function but also\nin these algorithms by utilizing capsule networks to preserve spatial orders\nand realize how each element individually combines and forms whole structures.", "published": "2025-09-02 21:40:57", "link": "http://arxiv.org/abs/2509.02851v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "PixFoundation 2.0: Do Video Multi-Modal LLMs Use Motion in Visual Grounding?", "abstract": "Multi-modal large language models (MLLMs) have shown impressive\ngeneralization across tasks using images and text modalities. While their\nextension to video has enabled tasks such as video question answering and video\ncaptioning, their pixel-level visual grounding abilities are less studied. In\nthis work, we raise the pertinent question of whether motion is used in\npixel-level visual grounding and whether video MLLMs can segment objects based\non natural language expressions describing their motion patterns. We identify\nthe shortcomings in the current benchmarks, where we show that a single frame\ncan often suffice for capturing the motion referring expression without any\ntemporal reasoning. To address this, we introduce four motion-centric probing\ntechniques, particularly designed for the visual grounding task, to study video\nMLLMs' ability to identify true motion from a fake one and their ability to\ngrasp the motion order. Consequently, we provide a motion-centric benchmark,\nMoCentric-Bench. It ensures that video MLLMs are evaluated towards leveraging\nthe interaction between motion and language rather than being dominated by\nstatic appearance cues emphasized in existing visual grounding datasets. We\nfurther establish strong single-image baselines that are on par with or\noutperform prior methods. Finally, we explore simple motion-centric adaptation\ntechniques that provide state-of-the-art performance on our MoCentric-Bench.\nOur motion-centric benchmark, evaluation and findings challenge future models\nto improve dense spatiotemporal grounding and pixel-level understanding within\nvideos. Code and datasets will be made publicly available at\nhttps://github.com/MSiam/PixFoundation-2.0.git.", "published": "2025-09-02 20:21:11", "link": "http://arxiv.org/abs/2509.02807v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Toward a robust lesion detection model in breast DCE-MRI: adapting foundation models to high-risk women", "abstract": "Accurate breast MRI lesion detection is critical for early cancer diagnosis,\nespecially in high-risk populations. We present a classification pipeline that\nadapts a pretrained foundation model, the Medical Slice Transformer (MST), for\nbreast lesion classification using dynamic contrast-enhanced MRI (DCE-MRI).\nLeveraging DINOv2-based self-supervised pretraining, MST generates robust\nper-slice feature embeddings, which are then used to train a Kolmogorov--Arnold\nNetwork (KAN) classifier. The KAN provides a flexible and interpretable\nalternative to conventional convolutional networks by enabling localized\nnonlinear transformations via adaptive B-spline activations. This enhances the\nmodel's ability to differentiate benign from malignant lesions in imbalanced\nand heterogeneous clinical datasets. Experimental results demonstrate that the\nMST+KAN pipeline outperforms the baseline MST classifier, achieving AUC = 0.80\n\\pm 0.02 while preserving interpretability through attention-based heatmaps.\nOur findings highlight the effectiveness of combining foundation model\nembeddings with advanced classification strategies for building robust and\ngeneralizable breast MRI analysis tools.", "published": "2025-09-02 18:11:18", "link": "http://arxiv.org/abs/2509.02710v1", "categories": ["physics.med-ph", "cs.CV", "cs.LG"], "primary_category": "physics.med-ph"}
{"title": "FastVGGT: Training-Free Acceleration of Visual Geometry Transformer", "abstract": "Foundation models for 3D vision have recently demonstrated remarkable\ncapabilities in 3D perception. However, scaling these models to long-sequence\nimage inputs remains a significant challenge due to inference-time\ninefficiency. In this work, we present a detailed analysis of VGGT, a\nstate-of-the-art feed-forward visual geometry model and identify its primary\nbottleneck. Visualization further reveals a token collapse phenomenon in the\nattention maps. Motivated by these findings, we explore the potential of token\nmerging in the feed-forward visual geometry model. Owing to the unique\narchitectural and task-specific properties of 3D models, directly applying\nexisting merging techniques proves challenging. To this end, we propose\nFastVGGT, which, for the first time, leverages token merging in the 3D domain\nthrough a training-free mechanism for accelerating VGGT. we devise a unique\ntoken partitioning strategy tailored to 3D architectures and tasks, effectively\neliminating redundant computation while preserving VGGT's powerful\nreconstruction capacity. Extensive experiments on multiple 3D geometry\nbenchmarks validate the effectiveness of our approach. Notably, with 1000 input\nimages, FastVGGT achieves a 4x speedup over VGGT while mitigating error\naccumulation in long-sequence scenarios. These findings underscore the\npotential of token merging as a principled solution for scalable 3D vision\nsystems. Code is available at: https://mystorm16.github.io/fastvggt/.", "published": "2025-09-02 17:54:21", "link": "http://arxiv.org/abs/2509.02560v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model", "abstract": "End-to-end autonomous driving has drawn tremendous attention recently. Many\nworks focus on using modular deep neural networks to construct the end-to-end\narchi-tecture. However, whether using powerful large language models (LLM),\nespecially multi-modality Vision Language Models (VLM) could benefit the\nend-to-end driving tasks remain a question. In our work, we demonstrate that\ncombining end-to-end architectural design and knowledgeable VLMs yield\nimpressive performance on the driving tasks. It is worth noting that our method\nonly uses a single camera and is the best camera-only solution across the\nleaderboard, demonstrating the effectiveness of vision-based driving approach\nand the potential for end-to-end driving tasks.", "published": "2025-09-02 17:52:29", "link": "http://arxiv.org/abs/2509.02659v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Motion-Refined DINOSAUR for Unsupervised Multi-Object Discovery", "abstract": "Unsupervised multi-object discovery (MOD) aims to detect and localize\ndistinct object instances in visual scenes without any form of human\nsupervision. Recent approaches leverage object-centric learning (OCL) and\nmotion cues from video to identify individual objects. However, these\napproaches use supervision to generate pseudo labels to train the OCL model. We\naddress this limitation with MR-DINOSAUR -- Motion-Refined DINOSAUR -- a\nminimalistic unsupervised approach that extends the self-supervised pre-trained\nOCL model, DINOSAUR, to the task of unsupervised multi-object discovery. We\ngenerate high-quality unsupervised pseudo labels by retrieving video frames\nwithout camera motion for which we perform motion segmentation of unsupervised\noptical flow. We refine DINOSAUR's slot representations using these pseudo\nlabels and train a slot deactivation module to assign slots to foreground and\nbackground. Despite its conceptual simplicity, MR-DINOSAUR achieves strong\nmulti-object discovery results on the TRI-PD and KITTI datasets, outperforming\nthe previous state of the art despite being fully unsupervised.", "published": "2025-09-02 17:44:49", "link": "http://arxiv.org/abs/2509.02545v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mix-modal Federated Learning for MRI Image Segmentation", "abstract": "Magnetic resonance imaging (MRI) image segmentation is crucial in diagnosing\nand treating many diseases, such as brain tumors. Existing MRI image\nsegmentation methods mainly fall into a centralized multimodal paradigm, which\nis inapplicable in engineering non-centralized mix-modal medical scenarios. In\nthis situation, each distributed client (hospital) processes multiple mixed MRI\nmodalities, and the modality set and image data for each client are diverse,\nsuffering from extensive client-wise modality heterogeneity and data\nheterogeneity. In this paper, we first formulate non-centralized mix-modal MRI\nimage segmentation as a new paradigm for federated learning (FL) that involves\nmultiple modalities, called mix-modal federated learning (MixMFL). It\ndistinguishes from existing multimodal federating learning (MulMFL) and\ncross-modal federating learning (CroMFL) paradigms. Then, we proposed a novel\nmodality decoupling and memorizing mix-modal federated learning framework\n(MDM-MixMFL) for MRI image segmentation, which is characterized by a modality\ndecoupling strategy and a modality memorizing mechanism. Specifically, the\nmodality decoupling strategy disentangles each modality into modality-tailored\nand modality-shared information. During mix-modal federated updating,\ncorresponding modality encoders undergo tailored and shared updating,\nrespectively. It facilitates stable and adaptive federating aggregation of\nheterogeneous data and modalities from distributed clients. Besides, the\nmodality memorizing mechanism stores client-shared modality prototypes\ndynamically refreshed from every modality-tailored encoder to compensate for\nincomplete modalities in each local client. It further benefits modality\naggregation and fusion processes during mixmodal federated learning. Extensive\nexperiments on two public datasets for MRI image segmentation demonstrate the\neffectiveness and superiority of our methods.", "published": "2025-09-02 17:43:51", "link": "http://arxiv.org/abs/2509.02541v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Fitness Movement Recognition with Attention Mechanism and Pre-Trained Feature Extractors", "abstract": "Fitness movement recognition, a focused subdomain of human activity\nrecognition (HAR), plays a vital role in health monitoring, rehabilitation, and\npersonalized fitness training by enabling automated exercise classification\nfrom video data. However, many existing deep learning approaches rely on\ncomputationally intensive 3D models, limiting their feasibility in real-time or\nresource-constrained settings. In this paper, we present a lightweight and\neffective framework that integrates pre-trained 2D Convolutional Neural\nNetworks (CNNs) such as ResNet50, EfficientNet, and Vision Transformers (ViT)\nwith a Long Short-Term Memory (LSTM) network enhanced by spatial attention.\nThese models efficiently extract spatial features while the LSTM captures\ntemporal dependencies, and the attention mechanism emphasizes informative\nsegments. We evaluate the framework on a curated subset of the UCF101 dataset,\nachieving a peak accuracy of 93.34\\% with the ResNet50-based configuration.\nComparative results demonstrate the superiority of our approach over several\nstate-of-the-art HAR systems. The proposed method offers a scalable and\nreal-time-capable solution for fitness activity recognition with broader\napplications in vision-based health and activity monitoring.", "published": "2025-09-02 17:04:42", "link": "http://arxiv.org/abs/2509.02511v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Anisotropic Fourier Features for Positional Encoding in Medical Imaging", "abstract": "The adoption of Transformer-based architectures in the medical domain is\ngrowing rapidly. In medical imaging, the analysis of complex shapes - such as\norgans, tissues, or other anatomical structures - combined with the often\nanisotropic nature of high-dimensional images complicates these adaptations. In\nthis study, we critically examine the role of Positional Encodings (PEs),\narguing that commonly used approaches may be suboptimal for the specific\nchallenges of medical imaging. Sinusoidal Positional Encodings (SPEs) have\nproven effective in vision tasks, but they struggle to preserve Euclidean\ndistances in higher-dimensional spaces. Isotropic Fourier Feature Positional\nEncodings (IFPEs) have been proposed to better preserve Euclidean distances,\nbut they lack the ability to account for anisotropy in images. To address these\nlimitations, we propose Anisotropic Fourier Feature Positional Encoding (AFPE),\na generalization of IFPE that incorporates anisotropic, class-specific, and\ndomain-specific spatial dependencies. We systematically benchmark AFPE against\ncommonly used PEs on multi-label classification in chest X-rays, organ\nclassification in CT images, and ejection fraction regression in\nechocardiography. Our results demonstrate that choosing the correct PE can\nsignificantly improve model performance. We show that the optimal PE depends on\nthe shape of the structure of interest and the anisotropy of the data. Finally,\nour proposed AFPE significantly outperforms state-of-the-art PEs in all tested\nanisotropic settings. We conclude that, in anisotropic medical images and\nvideos, it is of paramount importance to choose an anisotropic PE that fits the\ndata and the shape of interest.", "published": "2025-09-02 16:38:53", "link": "http://arxiv.org/abs/2509.02488v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Unifi3D: A Study on 3D Representations for Generation and Reconstruction in a Common Framework", "abstract": "Following rapid advancements in text and image generation, research has\nincreasingly shifted towards 3D generation. Unlike the well-established\npixel-based representation in images, 3D representations remain diverse and\nfragmented, encompassing a wide variety of approaches such as voxel grids,\nneural radiance fields, signed distance functions, point clouds, or octrees,\neach offering distinct advantages and limitations. In this work, we present a\nunified evaluation framework designed to assess the performance of 3D\nrepresentations in reconstruction and generation. We compare these\nrepresentations based on multiple criteria: quality, computational efficiency,\nand generalization performance. Beyond standard model benchmarking, our\nexperiments aim to derive best practices over all steps involved in the 3D\ngeneration pipeline, including preprocessing, mesh reconstruction, compression\nwith autoencoders, and generation. Our findings highlight that reconstruction\nerrors significantly impact overall performance, underscoring the need to\nevaluate generation and reconstruction jointly. We provide insights that can\ninform the selection of suitable 3D models for various applications,\nfacilitating the development of more robust and application-specific solutions\nin 3D generation. The code for our framework is available at\nhttps://github.com/isl-org/unifi3d.", "published": "2025-09-02 16:25:12", "link": "http://arxiv.org/abs/2509.02474v1", "categories": ["cs.GR", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "TeRA: Rethinking Text-driven Realistic 3D Avatar Generation", "abstract": "In this paper, we rethink text-to-avatar generative models by proposing TeRA,\na more efficient and effective framework than the previous SDS-based models and\ngeneral large 3D generative models. Our approach employs a two-stage training\nstrategy for learning a native 3D avatar generative model. Initially, we\ndistill a decoder to derive a structured latent space from a large human\nreconstruction model. Subsequently, a text-controlled latent diffusion model is\ntrained to generate photorealistic 3D human avatars within this latent space.\nTeRA enhances the model performance by eliminating slow iterative optimization\nand enables text-based partial customization through a structured 3D human\nrepresentation. Experiments have proven our approach's superiority over\nprevious text-to-avatar generative models in subjective and objective\nevaluation.", "published": "2025-09-02 16:20:20", "link": "http://arxiv.org/abs/2509.02466v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GenCompositor: Generative Video Compositing with Diffusion Transformer", "abstract": "Video compositing combines live-action footage to create video production,\nserving as a crucial technique in video creation and film production.\nTraditional pipelines require intensive labor efforts and expert collaboration,\nresulting in lengthy production cycles and high manpower costs. To address this\nissue, we automate this process with generative models, called generative video\ncompositing. This new task strives to adaptively inject identity and motion\ninformation of foreground video to the target video in an interactive manner,\nallowing users to customize the size, motion trajectory, and other attributes\nof the dynamic elements added in final video. Specifically, we designed a novel\nDiffusion Transformer (DiT) pipeline based on its intrinsic properties. To\nmaintain consistency of the target video before and after editing, we revised a\nlight-weight DiT-based background preservation branch with masked token\ninjection. As to inherit dynamic elements from other sources, a DiT fusion\nblock is proposed using full self-attention, along with a simple yet effective\nforeground augmentation for training. Besides, for fusing background and\nforeground videos with different layouts based on user control, we developed a\nnovel position embedding, named Extended Rotary Position Embedding (ERoPE).\nFinally, we curated a dataset comprising 61K sets of videos for our new task,\ncalled VideoComp. This data includes complete dynamic elements and high-quality\ntarget videos. Experiments demonstrate that our method effectively realizes\ngenerative video compositing, outperforming existing possible solutions in\nfidelity and consistency.", "published": "2025-09-02 16:10:13", "link": "http://arxiv.org/abs/2509.02460v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RiverScope: High-Resolution River Masking Dataset", "abstract": "Surface water dynamics play a critical role in Earth's climate system,\ninfluencing ecosystems, agriculture, disaster resilience, and sustainable\ndevelopment. Yet monitoring rivers and surface water at fine spatial and\ntemporal scales remains challenging -- especially for narrow or sediment-rich\nrivers that are poorly captured by low-resolution satellite data. To address\nthis, we introduce RiverScope, a high-resolution dataset developed through\ncollaboration between computer science and hydrology experts. RiverScope\ncomprises 1,145 high-resolution images (covering 2,577 square kilometers) with\nexpert-labeled river and surface water masks, requiring over 100 hours of\nmanual annotation. Each image is co-registered with Sentinel-2, SWOT, and the\nSWOT River Database (SWORD), enabling the evaluation of cost-accuracy\ntrade-offs across sensors -- a key consideration for operational water\nmonitoring. We also establish the first global, high-resolution benchmark for\nriver width estimation, achieving a median error of 7.2 meters -- significantly\noutperforming existing satellite-derived methods. We extensively evaluate deep\nnetworks across multiple architectures (e.g., CNNs and transformers),\npretraining strategies (e.g., supervised and self-supervised), and training\ndatasets (e.g., ImageNet and satellite imagery). Our best-performing models\ncombine the benefits of transfer learning with the use of all the multispectral\nPlanetScope channels via learned adaptors. RiverScope provides a valuable\nresource for fine-scale and multi-sensor hydrological modeling, supporting\nclimate adaptation and sustainable water management.", "published": "2025-09-02 16:00:27", "link": "http://arxiv.org/abs/2509.02451v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards High-Fidelity, Identity-Preserving Real-Time Makeup Transfer: Decoupling Style Generation", "abstract": "We present a novel framework for real-time virtual makeup try-on that\nachieves high-fidelity, identity-preserving cosmetic transfer with robust\ntemporal consistency. In live makeup transfer applications, it is critical to\nsynthesize temporally coherent results that accurately replicate fine-grained\nmakeup and preserve user's identity. However, existing methods often struggle\nto disentangle semitransparent cosmetics from skin tones and other identify\nfeatures, causing identity shifts and raising fairness concerns. Furthermore,\ncurrent methods lack real-time capabilities and fail to maintain temporal\nconsistency, limiting practical adoption. To address these challenges, we\ndecouple makeup transfer into two steps: transparent makeup mask extraction and\ngraphics-based mask rendering. After the makeup extraction step, the makeup\nrendering can be performed in real time, enabling live makeup try-on. Our\nmakeup extraction model trained on pseudo-ground-truth data generated via two\ncomplementary methods: a graphics-based rendering pipeline and an unsupervised\nk-means clustering approach. To further enhance transparency estimation and\ncolor fidelity, we propose specialized training objectives, including\nalpha-weighted reconstruction and lip color losses. Our method achieves robust\nmakeup transfer across diverse poses, expressions, and skin tones while\npreserving temporal smoothness. Extensive experiments demonstrate that our\napproach outperforms existing baselines in capturing fine details, maintaining\ntemporal stability, and preserving identity integrity.", "published": "2025-09-02 15:52:56", "link": "http://arxiv.org/abs/2509.02445v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient Pyramidal Analysis of Gigapixel Images on a Decentralized Modest Computer Cluster", "abstract": "Analyzing gigapixel images is recognized as computationally demanding. In\nthis paper, we introduce PyramidAI, a technique for analyzing gigapixel images\nwith reduced computational cost. The proposed approach adopts a gradual\nanalysis of the image, beginning with lower resolutions and progressively\nconcentrating on regions of interest for detailed examination at higher\nresolutions. We investigated two strategies for tuning the accuracy-computation\nperformance trade-off when implementing the adaptive resolution selection,\nvalidated against the Camelyon16 dataset of biomedical images. Our results\ndemonstrate that PyramidAI substantially decreases the amount of processed data\nrequired for analysis by up to 2.65x, while preserving the accuracy in\nidentifying relevant sections on a single computer. To ensure democratization\nof gigapixel image analysis, we evaluated the potential to use mainstream\ncomputers to perform the computation by exploiting the parallelism potential of\nthe approach. Using a simulator, we estimated the best data distribution and\nload balancing algorithm according to the number of workers. The selected\nalgorithms were implemented and highlighted the same conclusions in a\nreal-world setting. Analysis time is reduced from more than an hour to a few\nminutes using 12 modest workers, offering a practical solution for efficient\nlarge-scale image analysis.", "published": "2025-09-02 15:44:25", "link": "http://arxiv.org/abs/2509.02440v1", "categories": ["cs.DC", "cs.CV"], "primary_category": "cs.DC"}
{"title": "Faster and Better: Reinforced Collaborative Distillation and Self-Learning for Infrared-Visible Image Fusion", "abstract": "Infrared and visible image fusion plays a critical role in enhancing scene\nperception by combining complementary information from different modalities.\nDespite recent advances, achieving high-quality image fusion with lightweight\nmodels remains a significant challenge. To bridge this gap, we propose a novel\ncollaborative distillation and self-learning framework for image fusion driven\nby reinforcement learning. Unlike conventional distillation, this approach not\nonly enables the student model to absorb image fusion knowledge from the\nteacher model, but more importantly, allows the student to perform\nself-learning on more challenging samples to enhance its capabilities.\nParticularly, in our framework, a reinforcement learning agent explores and\nidentifies a more suitable training strategy for the student.The agent takes\nboth the student's performance and the teacher-student gap as inputs, which\nleads to the generation of challenging samples to facilitate the student's\nself-learning. Simultaneously, it dynamically adjusts the teacher's guidance\nstrength based on the student's state to optimize the knowledge transfer.\nExperimental results demonstrate that our method can significantly improve\nstudent performance and achieve better fusion results compared to existing\ntechniques.", "published": "2025-09-02 15:25:53", "link": "http://arxiv.org/abs/2509.02424v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Decoupling Bidirectional Geometric Representations of 4D cost volume with 2D convolution", "abstract": "High-performance real-time stereo matching methods invariably rely on 3D\nregularization of the cost volume, which is unfriendly to mobile devices. And\n2D regularization based methods struggle in ill-posed regions. In this paper,\nwe present a deployment-friendly 4D cost aggregation network DBStereo, which is\nbased on pure 2D convolutions. Specifically, we first provide a thorough\nanalysis of the decoupling characteristics of 4D cost volume. And design a\nlightweight bidirectional geometry aggregation block to capture spatial and\ndisparity representation respectively. Through decoupled learning, our approach\nachieves real-time performance and impressive accuracy simultaneously.\nExtensive experiments demonstrate that our proposed DBStereo outperforms all\nexisting aggregation-based methods in both inference time and accuracy, even\nsurpassing the iterative-based method IGEV-Stereo. Our study break the\nempirical design of using 3D convolutions for 4D cost volume and provides a\nsimple yet strong baseline of the proposed decouple aggregation paradigm for\nfurther study. Code will be available at\n(\\href{https://github.com/happydummy/DBStereo}{https://github.com/happydummy/DBStereo})\nsoon.", "published": "2025-09-02 15:21:49", "link": "http://arxiv.org/abs/2509.02415v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MedDINOv3: How to adapt vision foundation models for medical image segmentation?", "abstract": "Accurate segmentation of organs and tumors in CT and MRI scans is essential\nfor diagnosis, treatment planning, and disease monitoring. While deep learning\nhas advanced automated segmentation, most models remain task-specific, lacking\ngeneralizability across modalities and institutions. Vision foundation models\n(FMs) pretrained on billion-scale natural images offer powerful and\ntransferable representations. However, adapting them to medical imaging faces\ntwo key challenges: (1) the ViT backbone of most foundation models still\nunderperform specialized CNNs on medical image segmentation, and (2) the large\ndomain gap between natural and medical images limits transferability. We\nintroduce MedDINOv3, a simple and effective framework for adapting DINOv3 to\nmedical segmentation. We first revisit plain ViTs and design a simple and\neffective architecture with multi-scale token aggregation. Then, we perform\ndomain-adaptive pretraining on CT-3M, a curated collection of 3.87M axial CT\nslices, using a multi-stage DINOv3 recipe to learn robust dense features.\nMedDINOv3 matches or exceeds state-of-the-art performance across four\nsegmentation benchmarks, demonstrating the potential of vision foundation\nmodels as unified backbones for medical image segmentation. The code is\navailable at https://github.com/ricklisz/MedDINOv3.", "published": "2025-09-02 14:44:43", "link": "http://arxiv.org/abs/2509.02379v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Why Do MLLMs Struggle with Spatial Understanding? A Systematic Analysis from Data to Architecture", "abstract": "Spatial understanding is essential for Multimodal Large Language Models\n(MLLMs) to support perception, reasoning, and planning in embodied\nenvironments. Despite recent progress, existing studies reveal that MLLMs still\nstruggle with spatial understanding. However, existing research lacks a\ncomprehensive and systematic evaluation of these limitations, often restricted\nto isolated scenarios, such as single-view or video. In this work, we present a\nsystematic analysis of spatial understanding from both data and architectural\nperspectives across three representative scenarios: single-view, multi-view,\nand video. We propose a benchmark named MulSeT (Multi-view Spatial\nUnderstanding Tasks), and design a series of experiments to analyze the spatial\nreasoning capabilities of MLLMs. From the data perspective, the performance of\nspatial understanding converges quickly as the training data increases, and the\nupper bound is relatively low, especially for tasks that require spatial\nimagination. This indicates that merely expanding training data is insufficient\nto achieve satisfactory performance. From the architectural perspective, we\nfind that spatial understanding relies more heavily on the positional encoding\nwithin the visual encoder than within the language model, in both cascaded and\nnative MLLMs. Moreover, we explore reasoning injection and envision future\nimprovements through architectural design to optimize spatial understanding.\nThese insights shed light on the limitations of current MLLMs and suggest new\ndirections for improving spatial reasoning capabilities through data scaling\nand architectural tuning.", "published": "2025-09-02 14:22:43", "link": "http://arxiv.org/abs/2509.02359v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Category-Aware 3D Object Composition with Disentangled Texture and Shape Multi-view Diffusion", "abstract": "In this paper, we tackle a new task of 3D object synthesis, where a 3D model\nis composited with another object category to create a novel 3D model. However,\nmost existing text/image/3D-to-3D methods struggle to effectively integrate\nmultiple content sources, often resulting in inconsistent textures and\ninaccurate shapes. To overcome these challenges, we propose a straightforward\nyet powerful approach, category+3D-to-3D (C33D), for generating novel and\nstructurally coherent 3D models. Our method begins by rendering multi-view\nimages and normal maps from the input 3D model, then generating a novel 2D\nobject using adaptive text-image harmony (ATIH) with the front-view image and a\ntext description from another object category as inputs. To ensure texture\nconsistency, we introduce texture multi-view diffusion, which refines the\ntextures of the remaining multi-view RGB images based on the novel 2D object.\nFor enhanced shape accuracy, we propose shape multi-view diffusion to improve\nthe 2D shapes of both the multi-view RGB images and the normal maps, also\nconditioned on the novel 2D object. Finally, these outputs are used to\nreconstruct a complete and novel 3D model. Extensive experiments demonstrate\nthe effectiveness of our method, yielding impressive 3D creations, such as\nshark(3D)-crocodile(text) in the first row of Fig. 1. A project page is\navailable at: https://xzr52.github.io/C33D/", "published": "2025-09-02 14:19:21", "link": "http://arxiv.org/abs/2509.02357v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Ordinal Adaptive Correction: A Data-Centric Approach to Ordinal Image Classification with Noisy Labels", "abstract": "Labeled data is a fundamental component in training supervised deep learning\nmodels for computer vision tasks. However, the labeling process, especially for\nordinal image classification where class boundaries are often ambiguous, is\nprone to error and noise. Such label noise can significantly degrade the\nperformance and reliability of machine learning models. This paper addresses\nthe problem of detecting and correcting label noise in ordinal image\nclassification tasks. To this end, a novel data-centric method called ORDinal\nAdaptive Correction (ORDAC) is proposed for adaptive correction of noisy\nlabels. The proposed approach leverages the capabilities of Label Distribution\nLearning (LDL) to model the inherent ambiguity and uncertainty present in\nordinal labels. During training, ORDAC dynamically adjusts the mean and\nstandard deviation of the label distribution for each sample. Rather than\ndiscarding potentially noisy samples, this approach aims to correct them and\nmake optimal use of the entire training dataset. The effectiveness of the\nproposed method is evaluated on benchmark datasets for age estimation (Adience)\nand disease severity detection (Diabetic Retinopathy) under various asymmetric\nGaussian noise scenarios. Results show that ORDAC and its extended versions\n(ORDAC_C and ORDAC_R) lead to significant improvements in model performance.\nFor instance, on the Adience dataset with 40% noise, ORDAC_R reduced the mean\nabsolute error from 0.86 to 0.62 and increased the recall metric from 0.37 to\n0.49. The method also demonstrated its effectiveness in correcting intrinsic\nnoise present in the original datasets. This research indicates that adaptive\nlabel correction using label distributions is an effective strategy to enhance\nthe robustness and accuracy of ordinal classification models in the presence of\nnoisy data.", "published": "2025-09-02 14:17:16", "link": "http://arxiv.org/abs/2509.02351v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "OmniActor: A Generalist GUI and Embodied Agent for 2D&3D Worlds", "abstract": "Multimodal large language models are evolving toward multimodal agents\ncapable of proactively executing tasks. Most agent research focuses on GUI or\nembodied scenarios, which correspond to agents interacting with 2D virtual\nworlds or 3D real worlds, respectively. However, many complex tasks typically\nrequire agents to interleavely interact with these two types of environment. We\ninitially mix GUI and embodied data to train, but find the performance\ndegeneration brought by the data conflict. Further analysis reveals that GUI\nand embodied data exhibit synergy and conflict at the shallow and deep layers,\nrespectively, which resembles the cerebrum-cerebellum mechanism in the human\nbrain. To this end, we propose a high-performance generalist agent OmniActor,\ndesigned from both structural and data perspectives. First, we propose\nLayer-heterogeneity MoE to eliminate the conflict between GUI and embodied data\nby separating deep-layer parameters, while leverage their synergy by sharing\nshallow-layer parameters. By successfully leveraging the synergy and\neliminating the conflict, OmniActor outperforms agents only trained by GUI or\nembodied data in GUI or embodied tasks. Furthermore, we unify the action spaces\nof GUI and embodied tasks, and collect large-scale GUI and embodied data from\nvarious sources for training. This significantly improves OmniActor under\ndifferent scenarios, especially in GUI tasks. The code will be publicly\navailable.", "published": "2025-09-02 13:47:54", "link": "http://arxiv.org/abs/2509.02322v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hues and Cues: Human vs. CLIP", "abstract": "Playing games is inherently human, and a lot of games are created to\nchallenge different human characteristics. However, these tasks are often left\nout when evaluating the human-like nature of artificial models. The objective\nof this work is proposing a new approach to evaluate artificial models via\nboard games. To this effect, we test the color perception and color naming\ncapabilities of CLIP by playing the board game Hues & Cues and assess its\nalignment with humans. Our experiments show that CLIP is generally well aligned\nwith human observers, but our approach brings to light certain cultural biases\nand inconsistencies when dealing with different abstraction levels that are\nhard to identify with other testing strategies. Our findings indicate that\nassessing models with different tasks like board games can make certain\ndeficiencies in the models stand out in ways that are difficult to test with\nthe commonly used benchmarks.", "published": "2025-09-02 13:30:16", "link": "http://arxiv.org/abs/2509.02305v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Data-Driven Loss Functions for Inference-Time Optimization in Text-to-Image Generation", "abstract": "Text-to-image diffusion models can generate stunning visuals, yet they often\nfail at tasks children find trivial--like placing a dog to the right of a teddy\nbear rather than to the left. When combinations get more unusual--a giraffe\nabove an airplane--these failures become even more pronounced. Existing methods\nattempt to fix these spatial reasoning failures through model fine-tuning or\ntest-time optimization with handcrafted losses that are suboptimal. Rather than\nimposing our assumptions about spatial encoding, we propose learning these\nobjectives directly from the model's internal representations. We introduce\nLearn-to-Steer, a novel framework that learns data-driven objectives for\ntest-time optimization rather than handcrafting them. Our key insight is to\ntrain a lightweight classifier that decodes spatial relationships from the\ndiffusion model's cross-attention maps, then deploy this classifier as a\nlearned loss function during inference. Training such classifiers poses a\nsurprising challenge: they can take shortcuts by detecting linguistic traces\nrather than learning true spatial patterns. We solve this with a dual-inversion\nstrategy that enforces geometric understanding. Our method dramatically\nimproves spatial accuracy: from 0.20 to 0.61 on FLUX.1-dev and from 0.07 to\n0.54 on SD2.1 across standard benchmarks. Moreover, our approach generalizes to\nmultiple relations and significantly improves accuracy.", "published": "2025-09-02 13:17:11", "link": "http://arxiv.org/abs/2509.02295v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SynthGenNet: a self-supervised approach for test-time generalization using synthetic multi-source domain mixing of street view images", "abstract": "Unstructured urban environments present unique challenges for scene\nunderstanding and generalization due to their complex and diverse layouts. We\nintroduce SynthGenNet, a self-supervised student-teacher architecture designed\nto enable robust test-time domain generalization using synthetic multi-source\nimagery. Our contributions include the novel ClassMix++ algorithm, which blends\nlabeled data from various synthetic sources while maintaining semantic\nintegrity, enhancing model adaptability. We further employ Grounded Mask\nConsistency Loss (GMC), which leverages source ground truth to improve\ncross-domain prediction consistency and feature alignment. The Pseudo-Label\nGuided Contrastive Learning (PLGCL) mechanism is integrated into the student\nnetwork to facilitate domain-invariant feature learning through iterative\nknowledge distillation from the teacher network. This self-supervised strategy\nimproves prediction accuracy, addresses real-world variability, bridges the\nsim-to-real domain gap, and reliance on labeled target data, even in complex\nurban areas. Outcomes show our model outperforms the state-of-the-art (relying\non single source) by achieving 50% Mean Intersection-Over-Union (mIoU) value on\nreal-world datasets like Indian Driving Dataset (IDD).", "published": "2025-09-02 13:08:03", "link": "http://arxiv.org/abs/2509.02287v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RS-OOD: A Vision-Language Augmented Framework for Out-of-Distribution Detection in Remote Sensing", "abstract": "Out-of-distribution (OOD) detection represents a critical challenge in remote\nsensing applications, where reliable identification of novel or anomalous\npatterns is essential for autonomous monitoring, disaster response, and\nenvironmental assessment. Despite remarkable progress in OOD detection for\nnatural images, existing methods and benchmarks remain poorly suited to remote\nsensing imagery due to data scarcity, complex multi-scale scene structures, and\npronounced distribution shifts. To this end, we propose RS-OOD, a novel\nframework that leverages remote sensing-specific vision-language modeling to\nenable robust few-shot OOD detection. Our approach introduces three key\ninnovations: spatial feature enhancement that improved scene discrimination, a\ndual-prompt alignment mechanism that cross-verifies scene context against\nfine-grained semantics for spatial-semantic consistency, and a\nconfidence-guided self-training loop that dynamically mines pseudo-labels to\nexpand training data without manual annotation. RS-OOD consistently outperforms\nexisting methods across multiple remote sensing benchmarks and enables\nefficient adaptation with minimal labeled data, demonstrating the critical\nvalue of spatial-semantic integration.", "published": "2025-09-02 12:48:39", "link": "http://arxiv.org/abs/2509.02273v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DSGC-Net: A Dual-Stream Graph Convolutional Network for Crowd Counting via Feature Correlation Mining", "abstract": "Deep learning-based crowd counting methods have achieved remarkable progress\nin recent years. However, in complex crowd scenarios, existing models still\nface challenges when adapting to significant density distribution differences\nbetween regions. Additionally, the inconsistency of individual representations\ncaused by viewpoint changes and body posture differences further limits the\ncounting accuracy of the models. To address these challenges, we propose\nDSGC-Net, a Dual-Stream Graph Convolutional Network based on feature\ncorrelation mining. DSGC-Net introduces a Density Approximation (DA) branch and\na Representation Approximation (RA) branch. By modeling two semantic graphs, it\ncaptures the potential feature correlations in density variations and\nrepresentation distributions. The DA branch incorporates a density prediction\nmodule that generates the density distribution map, and constructs a\ndensity-driven semantic graph based on density similarity. The RA branch\nestablishes a representation-driven semantic graph by computing global\nrepresentation similarity. Then, graph convolutional networks are applied to\nthe two semantic graphs separately to model the latent semantic relationships,\nwhich enhance the model's ability to adapt to density variations and improve\ncounting accuracy in multi-view and multi-pose scenarios. Extensive experiments\non three widely used datasets demonstrate that DSGC-Net outperforms current\nstate-of-the-art methods. In particular, we achieve MAE of 48.9 and 5.9 in\nShanghaiTech Part A and Part B datasets, respectively. The released code is\navailable at: https://github.com/Wu-eon/CrowdCounting-DSGCNet.", "published": "2025-09-02 12:35:33", "link": "http://arxiv.org/abs/2509.02261v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Multimodal Cross-View Model for Predicting Postoperative Neck Pain in Cervical Spondylosis Patients", "abstract": "Neck pain is the primary symptom of cervical spondylosis, yet its underlying\nmechanisms remain unclear, leading to uncertain treatment outcomes. To address\nthe challenges of multimodal feature fusion caused by imaging differences and\nspatial mismatches, this paper proposes an Adaptive Bidirectional Pyramid\nDifference Convolution (ABPDC) module that facilitates multimodal integration\nby exploiting the advantages of difference convolution in texture extraction\nand grayscale invariance, and a Feature Pyramid Registration Auxiliary Network\n(FPRAN) to mitigate structural misalignment. Experiments on the MMCSD dataset\ndemonstrate that the proposed model achieves superior prediction accuracy of\npostoperative neck pain recovery compared with existing methods, and ablation\nstudies further confirm its effectiveness.", "published": "2025-09-02 12:33:43", "link": "http://arxiv.org/abs/2509.02256v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Palmistry-Informed Feature Extraction and Analysis using Machine Learning", "abstract": "This paper explores the automated analysis of palmar features using machine\nlearning techniques. We present a computer vision pipeline that extracts key\ncharacteristics from palm images, such as principal line structures, texture,\nand shape metrics. These features are used to train predictive models on a\nnovel dataset curated from annotated palm images. Our approach moves beyond\ntraditional subjective interpretation by providing a data-driven, quantitative\nframework for studying the correlations between palmar morphology and\nexternally validated traits or conditions. The methodology demonstrates\nfeasibility for applications in digital anthropometry and personalized user\nanalytics, with potential for deployment on mobile platforms. Results indicate\nthat machine learning models can identify complex patterns in palm data,\nopening avenues for research that intersects cultural practices with\ncomputational analysis.", "published": "2025-09-02 12:17:03", "link": "http://arxiv.org/abs/2509.02248v1", "categories": ["cs.CV", "I.4.9; I.2.10; J.5"], "primary_category": "cs.CV"}
{"title": "ADVMEM: Adversarial Memory Initialization for Realistic Test-Time Adaptation via Tracklet-Based Benchmarking", "abstract": "We introduce a novel tracklet-based dataset for benchmarking test-time\nadaptation (TTA) methods. The aim of this dataset is to mimic the intricate\nchallenges encountered in real-world environments such as images captured by\nhand-held cameras, self-driving cars, etc. The current benchmarks for TTA focus\non how models face distribution shifts, when deployed, and on violations to the\ncustomary independent-and-identically-distributed (i.i.d.) assumption in\nmachine learning. Yet, these benchmarks fail to faithfully represent realistic\nscenarios that naturally display temporal dependencies, such as how consecutive\nframes from a video stream likely show the same object across time. We address\nthis shortcoming of current datasets by proposing a novel TTA benchmark we call\nthe \"Inherent Temporal Dependencies\" (ITD) dataset. We ensure the instances in\nITD naturally embody temporal dependencies by collecting them from\ntracklets-sequences of object-centric images we compile from the bounding boxes\nof an object-tracking dataset. We use ITD to conduct a thorough experimental\nanalysis of current TTA methods, and shed light on the limitations of these\nmethods when faced with the challenges of temporal dependencies. Moreover, we\nbuild upon these insights and propose a novel adversarial memory initialization\nstrategy to improve memory-based TTA methods. We find this strategy\nsubstantially boosts the performance of various methods on our challenging\nbenchmark.", "published": "2025-09-02 10:45:33", "link": "http://arxiv.org/abs/2509.02182v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Lower Bounds for Linear Operators", "abstract": "We consider a static data structure problem of computing a linear operator\nunder cell-probe model. Given a linear operator $M \\in \\mathbb{F}_2^{m \\times\nn}$, the goal is to pre-process a vector $X \\in \\mathbb{F}_2^n$ into a data\nstructure of size $s$ to answer any query $\\langle M_i , X \\rangle$ in time\n$t$. We prove that for a random operator $M$, any such data structure requires:\n  $$ t \\geq \\Omega ( \\min \\{ \\log (m/s) , n / \\log s \\} ).$$ This result\novercomes the well-known logarithmic barrier in static data structures [MNSW98,\nSie04, PD06, PTW08, Pat11, DGW19] by using a random linear operator.\nFurthermore, it provides the first significant progress toward confirming a\ndecades-old folklore conjecture: that non-linear pre-processing does not\nsubstantially help in computing most linear operators.\n  A straightforward modification of our proof also yields a wire lower bound of\n$\\Omega(n \\cdot \\log^{1/d}(n))$ for depth-$d$ circuits with arbitrary gates\nthat compute a specific linear operator $M \\in \\mathbb{F}_2^{O(n) \\times n}$,\neven against some small constant advantage over random guessing. This bound\nholds even for circuits with only a small constant advantage over random\nguessing, improving upon longstanding results [RS03, Che08a, Che08b, GHK+13]\nfor a random operator.\n  Finally, our work partially resolves the communication form of the Multiphase\nConjecture [Pat10] and makes progress on Jukna-Schnitger's Conjecture [JS11,\nJuk12]. We address the former by considering the Inner Product (mod 2) problem\n(instead of Set Disjointness) when the number of queries $m$ is\nsuper-polynomial (e.g., $2^{n^{1/3}}$), and the total update time is\n$m^{0.99}$. Our result for the latter also applies to cases with\nsuper-polynomial $m$.", "published": "2025-09-02 18:26:23", "link": "http://arxiv.org/abs/2509.02730v1", "categories": ["cs.CC", "cs.DM", "cs.DS"], "primary_category": "cs.CC"}
{"title": "A threshold for online balancing of sparse i.i.d. vectors", "abstract": "Consider the task of \\textit{online} vector balancing for stochastic arrivals\n$(X_i)_{i \\in [T]}$, where the time horizon satisfies $T = \\Theta(n)$, and the\n$X_i$ are i.i.d uniform $d$--sparse $n$--dimensional binary vectors, with\n$2\\leq d \\le (\\log\\log n)^2/\\log\\log\\log n$. We show that for this range of\nparameters, every online algorithm incurs discrepancy at least $\\Omega(\\log\n\\log n)$, and there is an efficient algorithm which achieves a matching\ndiscrepancy bound of $O(\\log\\log n)$ w.h.p. This establishes an asymptotic gap,\nboth existential and algorithmic, between the online and offline versions of\nthe average--case Beck--Fiala problem. Strikingly, the optimal online\ndiscrepancy in the considered setting is order $\\log \\log n$, independent of\n$d$ and the norms of the vectors $(X_i)_i$. Our assumptions on $d$ are nearly\noptimal, as this independence ceases when $d=\\omega((\\log\\log n)^2)$.", "published": "2025-09-02 15:35:42", "link": "http://arxiv.org/abs/2509.02432v1", "categories": ["math.PR", "cs.DM", "math.CO"], "primary_category": "math.PR"}
{"title": "Constricting the Computational Complexity Gap of the $4$-Coloring Problem in $(P_t,C_3)$-free Graphs", "abstract": "The $k$-Coloring problem on hereditary graph classes has been a deeply\nresearched problem over the last decade. A hereditary graph class is\ncharacterized by a (possibly infinite) list of minimal forbidden induced\nsubgraphs. We say that a graph is $(H_1,H_2,\\ldots)$-free if it does not\ncontain any of $H_1,H_2,\\ldots$ as induced subgraphs. The complexity landscape\nof the problem remains unclear even when restricting to the case $k=4$ and\nclasses defined by a few forbidden induced subgraphs. While the case of only\none forbidden induced subgraph has been completely resolved lately, the\ncomplexity when considering two forbidden induced subgraphs still has a couple\nof unknown cases. In particular, $4$-Coloring on $(P_6,C_3)$-free graphs is\npolynomial while it is NP-hard on $(P_{22},C_3)$-free graphs.\n  We provide a reduction showing NP-completeness of $4$-Coloring on\n$(P_t,C_3)$-free graphs for $19\\leq t\\leq 21$, thus constricting the gap of\ncases whose complexity remains unknown. Our proof includes a computer search\nensuring that the graph family obtained through the reduction is indeed\n$P_{19}$-free.", "published": "2025-09-02 15:25:00", "link": "http://arxiv.org/abs/2509.02423v1", "categories": ["cs.CC", "cs.DM", "math.CO", "05C15, 05C85"], "primary_category": "cs.CC"}
{"title": "Continuous Petri Nets for Fast Yield Computation: Polynomial-Time and MILP Approaches", "abstract": "Petri nets provide accurate analogues to chemical reaction networks, with\nplaces representing individual molecules (the resources of the system) and\ntransitions representing chemical reactions which convert educt molecules into\nproduct molecules. Their natural affinity for modeling chemical reaction\nnetworks is, however, impeded by their computational complexity, which is at\nleast PSpace-hard for most interesting questions, including reachability.\nContinuous Petri nets offer the same structure and discrete time as discrete\nPetri nets, but use continuous state-space, which allows them to answer the\nreachability question in polynomial time. We exploit this property to introduce\na polynomial time algorithm for computing the maximal yield of a molecule in a\nchemical system. Additionally, we provide an alternative algorithm based on\nmixed-integer linear programming with worse theoretical complexity, but better\nruntime in practice, as demonstrated on both synthetic and chemical data.", "published": "2025-09-02 14:35:07", "link": "http://arxiv.org/abs/2509.02371v1", "categories": ["cs.DM", "cs.DS"], "primary_category": "cs.DM"}
{"title": "Lighting the Way for BRIGHT: Reproducible Baselines with Anserini, Pyserini, and RankLLM", "abstract": "The BRIGHT benchmark is a dataset consisting of reasoning-intensive queries\nover diverse domains. We explore retrieval results on BRIGHT using a range of\nretrieval techniques, including sparse, dense, and fusion methods, and\nestablish reproducible baselines. We then apply listwise reranking with large\nlanguage models (LLMs) to further investigate the impact of reranking on\nreasoning-intensive queries. These baselines are integrated into popular\nretrieval and reranking toolkits Anserini, Pyserini, and RankLLM, with\ntwo-click reproducibility that makes them easy to build upon and convenient for\nfurther development. While attempting to reproduce the results reported in the\noriginal BRIGHT paper, we find that the provided BM25 scores differ notably\nfrom those that we obtain using Anserini and Pyserini. We discover that this\ndifference is due to BRIGHT's implementation of BM25, which applies BM25 on the\nquery rather than using the standard bag-of-words approach, as in Anserini, to\nconstruct query vectors. This difference has become increasingly relevant due\nto the rise of longer queries, with BRIGHT's lengthy reasoning-intensive\nqueries being a prime example, and further accentuated by the increasing usage\nof retrieval-augmented generation, where LLM prompts can grow to be much longer\nthan ''traditional'' search engine queries. Our observation signifies that it\nmay be time to reconsider BM25 approaches going forward in order to better\naccommodate emerging applications. To facilitate this, we integrate query-side\nBM25 into both Anserini and Pyserini.", "published": "2025-09-02 17:53:57", "link": "http://arxiv.org/abs/2509.02558v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Upcycling Candidate Tokens of Large Language Models for Query Expansion", "abstract": "Query Expansion (QE) improves retrieval performance by enriching queries with\nrelated terms. Recently, Large Language Models (LLMs) have been used for QE,\nbut existing methods face a trade-off: generating diverse terms boosts\nperformance but increases computational cost. To address this challenge, we\npropose Candidate Token Query Expansion (CTQE), which extracts diverse and\nrelevant terms from a single LLM decoding pass by leveraging unselected\ncandidate tokens. These tokens, though not part of the final output, are\nconditioned on the full query and capture useful information. By aggregating\nthem, CTQE achieves both relevance and diversity without extra inference,\nreducing overhead and latency. Experiments show that CTQE delivers strong\nretrieval performance with significantly lower cost, outperforming or\ncomparable to more expensive methods. Code is available at:\nhttps://github.com/bluejeans8/CTQE", "published": "2025-09-02 14:43:59", "link": "http://arxiv.org/abs/2509.02377v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Leveraging Media Frames to Improve Normative Diversity in News Recommendations", "abstract": "Click-based news recommender systems suggest users content that aligns with\ntheir existing history, limiting the diversity of articles they encounter.\nRecent advances in aspect-based diversification -- adding features such as\nsentiments or news categories (e.g. world, politics) -- have made progress\ntoward diversifying recommendations in terms of perspectives. However, these\napproaches often overlook the role of news framing, which shapes how stories\nare told by emphasizing specific angles or interpretations. In this paper, we\ntreat media frames as a controllable aspect within the recommendation pipeline.\nBy selecting articles based on a diversity of frames, our approach emphasizes\nvaried narrative angles and broadens the interpretive space recommended to\nusers. In addition to introducing frame-based diversification method, our work\nis the first to assess the impact of a news recommender system that integrates\nframe diversity using normative diversity metrics: representation, calibration,\nand activation. Our experiments based on media frame diversification show an\nimprovement in exposure to previously unclicked frames up to 50%. This is\nimportant because repeated exposure to the same frames can reinforce existing\nbiases or narrow interpretations, whereas introducing novel frames broadens\nusers' understanding of issues and perspectives. The method also enhances\ndiversification across categorical and sentiment levels, thereby demonstrating\nthat framing acts as a strong control lever for enhancing normative diversity.", "published": "2025-09-02 12:43:41", "link": "http://arxiv.org/abs/2509.02266v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Application Of Large Language Models For The Extraction Of Information From Particle Accelerator Technical Documentation", "abstract": "The large set of technical documentation of legacy accelerator systems,\ncoupled with the retirement of experienced personnel, underscores the urgent\nneed for efficient methods to preserve and transfer specialized knowledge. This\npaper explores the application of large language models (LLMs), to automate and\nenhance the extraction of information from particle accelerator technical\ndocuments. By exploiting LLMs, we aim to address the challenges of knowledge\nretention, enabling the retrieval of domain expertise embedded in legacy\ndocumentation. We present initial results of adapting LLMs to this specialized\ndomain. Our evaluation demonstrates the effectiveness of LLMs in extracting,\nsummarizing, and organizing knowledge, significantly reducing the risk of\nlosing valuable insights as personnel retire. Furthermore, we discuss the\nlimitations of current LLMs, such as interpretability and handling of rare\ndomain-specific terms, and propose strategies for improvement. This work\nhighlights the potential of LLMs to play a pivotal role in preserving\ninstitutional knowledge and ensuring continuity in highly specialized fields.", "published": "2025-09-02 11:45:01", "link": "http://arxiv.org/abs/2509.02227v1", "categories": ["cs.IR", "cs.AI", "physics.acc-ph"], "primary_category": "cs.IR"}
{"title": "Towards Multi-Aspect Diversification of News Recommendations Using Neuro-Symbolic AI for Individual and Societal Benefit", "abstract": "News recommendations are complex, with diversity playing a vital role. So\nfar, existing literature predominantly focuses on specific aspects of news\ndiversity, such as viewpoints. In this paper, we introduce multi-aspect\ndiversification in four distinct recommendation modes and outline the nuanced\nchallenges in diversifying lists, sequences, summaries, and interactions. Our\nproposed research direction combines symbolic and subsymbolic artificial\nintelligence, leveraging both knowledge graphs and rule learning. We plan to\nevaluate our models using user studies to not only capture behavior but also\ntheir perceived experience. Our vision to balance news consumption points to\nother positive effects for users (e.g., increased serendipity) and society\n(e.g., decreased polarization).", "published": "2025-09-02 11:40:52", "link": "http://arxiv.org/abs/2509.02220v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Abex-rat: Synergizing Abstractive Augmentation and Adversarial Training for Classification of Occupational Accident Reports", "abstract": "The automatic classification of occupational accident reports is a critical\nresearch area for enhancing workplace safety and enabling large-scale risk\nanalysis. However, the severe class imbalance inherent in these real-world\ndatasets often compromises the performance of analytical models, particularly\nfor rare but severe incident types, hindering the development of reliable\nautomated systems. To address this challenge, we propose ABEX-RAT, a novel and\nefficient framework that synergizes generative data augmentation with robust\nadversarial training. Our approach first employs a twostep\nabstractive-expansive (ABEX) pipeline, which leverages a large language model\nto distill core incident semantics and then uses a generative model to create\ndiverse, highquality synthetic samples for underrepresented classes.\nSubsequently, a lightweight classifier is trained on the augmented data using a\ncomputationally efficient random adversarial training (RAT) protocol, which\nstochastically applies perturbations to enhance model generalization and\nrobustness without significant overhead. Experimental results on the public\nOSHA dataset demonstrate that our method achieves new state-of-the-art\nperformance, reaching a macro-F1 score of 90.32% and significantly\noutperforming previous SOTA and fine-tuned large model baselines. Our work\nvalidates that this synergistic strategy is a highly effective and efficient\nalternative to brute-force fine-tuning for specialized, imbalanced\nclassification tasks. The code is publicly available\nat:https://github.com/nxcc-lab/ABEX-RAT.", "published": "2025-09-02 08:22:59", "link": "http://arxiv.org/abs/2509.02072v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs", "abstract": "Sequential recommendation (SR) aims to capture users' dynamic interests and\nsequential patterns based on their historical interactions. Recently, the\npowerful capabilities of large language models (LLMs) have driven their\nadoption in SR. However, we identify two critical challenges in existing\nLLM-based SR methods: 1) embedding collapse when incorporating pre-trained\ncollaborative embeddings and 2) catastrophic forgetting of quantized embeddings\nwhen utilizing semantic IDs. These issues dampen the model scalability and lead\nto suboptimal recommendation performance. Therefore, based on LLMs like\nLlama3-8B-instruct, we introduce a novel SR framework named MME-SID, which\nintegrates multimodal embeddings and quantized embeddings to mitigate embedding\ncollapse. Additionally, we propose a Multimodal Residual Quantized Variational\nAutoencoder (MM-RQ-VAE) with maximum mean discrepancy as the reconstruction\nloss and contrastive learning for alignment, which effectively preserve\nintra-modal distance information and capture inter-modal correlations,\nrespectively. To further alleviate catastrophic forgetting, we initialize the\nmodel with the trained multimodal code embeddings. Finally, we fine-tune the\nLLM efficiently using LoRA in a multimodal frequency-aware fusion manner.\nExtensive experiments on three public datasets validate the superior\nperformance of MME-SID thanks to its capability to mitigate embedding collapse\nand catastrophic forgetting. The implementation code and datasets are publicly\navailable for reproduction:\nhttps://github.com/Applied-Machine-Learning-Lab/MME-SID.", "published": "2025-09-02 07:02:29", "link": "http://arxiv.org/abs/2509.02017v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Rollout-Based Approximate Dynamic Programming for MDPs with Information-Theoretic Constraints", "abstract": "This paper studies a finite-horizon Markov decision problem with\ninformation-theoretic constraints, where the goal is to minimize directed\ninformation from the controlled source process to the control process, subject\nto stage-wise cost constraints, aiming for an optimal control policy. We\npropose a new way of approximating a solution for this problem, which is known\nto be formulated as an unconstrained MDP with a continuous information-state\nusing Q-factors. To avoid the computational complexity of discretizing the\ncontinuous information-state space, we propose a truncated rollout-based\nbackward-forward approximate dynamic programming (ADP) framework. Our approach\nconsists of two phases: an offline base policy approximation over a shorter\ntime horizon, followed by an online rollout lookahead minimization, both\nsupported by provable convergence guarantees. We supplement our theoretical\nresults with a numerical example where we demonstrate the cost improvement of\nthe rollout method compared to a previously proposed policy approximation\nmethod, and the computational complexity observed in executing the offline and\nonline phases for the two methods.", "published": "2025-09-02 20:28:14", "link": "http://arxiv.org/abs/2509.02812v1", "categories": ["eess.SY", "cs.IT", "cs.SY", "math.IT"], "primary_category": "eess.SY"}
{"title": "minPIC: Towards Optimal Power Allocation in Multi-User Interference Channels", "abstract": "6G envisions massive cell-free networks with spatially nested multiple access\n(MAC) and broadcast (BC) channels without centralized coordination. This makes\noptimal resource allocation across power, subcarriers, and decoding orders\ncrucial for interference channels (ICs), where neither transmitters nor\nreceivers can cooperate. Current orthogonal multiple access (OMA) methods, as\nwell as non-orthogonal (NOMA) and rate-splitting (RSMA) schemes, rely on fixed\nheuristics for interference management, leading to suboptimal rates, power\ninefficiency, and scalability issues. This paper proposes a novel minPIC\nframework for optimal power, subcarrier, and decoding order allocation in\ngeneral multi-user ICs. Unlike existing methods, minPIC eliminates heuristic\nSIC order assumptions. Despite the convexity of the IC capacity region, fixing\nan SIC order induces non-convexity in resource allocation, traditionally\nrequiring heuristic approximations. We instead introduce a dual-variable-guided\nsorting criterion to identify globally optimal SIC orders, followed by convex\noptimization with auxiliary log-det constraints, efficiently solved via binary\nsearch. We also demonstrate that minPIC could potentially meet the stringent\nhigh-rate, low-power targets of immersive XR and other 6G applications. To the\nbest of our knowledge, minPIC is the first algorithmic realisation of the\nPareto boundary of the SIC-achievable rate region for Gaussian ICs, opening the\ndoor to scalable interference management in cell-free networks.", "published": "2025-09-02 20:00:12", "link": "http://arxiv.org/abs/2509.02797v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Recall Gabor Communication Theory and Joint Time-Frequency Analysis", "abstract": "In this article, we first briefly recall Gabor's communication theory and\nthen Gabor transform and expansion, and also its connection with joint time\nfrequency analysis.", "published": "2025-09-02 18:19:57", "link": "http://arxiv.org/abs/2509.02724v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Federated learning over physical channels: adaptive algorithms with near-optimal guarantees", "abstract": "In federated learning, communication cost can be significantly reduced by\ntransmitting the information over the air through physical channels. In this\npaper, we propose a new class of adaptive federated stochastic gradient descent\n(SGD) algorithms that can be implemented over physical channels, taking into\naccount both channel noise and hardware constraints. We establish theoretical\nguarantees for the proposed algorithms, demonstrating convergence rates that\nare adaptive to the stochastic gradient noise level. We also demonstrate the\npractical effectiveness of our algorithms through simulation studies with deep\nlearning models.", "published": "2025-09-02 17:40:27", "link": "http://arxiv.org/abs/2509.02538v1", "categories": ["cs.LG", "cs.IT", "eess.SP", "math.IT", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Novel Coded Caching Scheme for Partially Cooperative Device-to-Device Networks", "abstract": "Device-to-device (D2D) communication is one of the most promising techniques\nfor future wireless cellular communication systems. This paper considers coded\ncaching in a partially cooperative wireless D2D network, where only a subset of\nusers transmit during delivery, while all users request files. The\nnon-transmitting users are referred to as selfish users. All existing schemes\nthat do not require knowledge of the identity of selfish users before content\nplacement are limited to the high-memory regime, particularly when the number\nof selfish users is large. We propose a novel coded caching scheme for a\npartially cooperative D2D network that operates in all feasible memory regimes,\nregardless of the number of selfish users. We also derive a lower bound on the\ntransmission load of a partially cooperative D2D coded caching scheme. Using\nthis bound, the proposed scheme is shown to be optimal in the high-memory\nregime.", "published": "2025-09-02 17:35:42", "link": "http://arxiv.org/abs/2509.02532v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Feasibility Guaranteed Learning-to-Optimize in Wireless Communication Resource Allocation", "abstract": "The emergence of 6G wireless communication enables massive edge device access\nand supports real-time intelligent services such as the Internet of things\n(IoT) and vehicle-to-everything (V2X). However, the surge in edge devices\nconnectivity renders wireless resource allocation (RA) tasks as large-scale\nconstrained optimization problems, whereas the stringent real-time requirement\nposes significant computational challenge for traditional algorithms. To\naddress the challenge, feasibility guaranteed learning-to-optimize (L2O)\ntechniques have recently gained attention. These learning-based methods offer\nefficient alternatives to conventional solvers by directly learning mappings\nfrom system parameters to feasible and near-optimal solutions. This article\nprovide a comprehensive review of L2O model designs and feasibility enforcement\ntechniques and investigates the application of constrained L2O in wireless RA\nsystems and. The paper also presents a case study to benchmark different L2O\napproaches in weighted sum rate problem, and concludes by identifying key\nchallenges and future research directions.", "published": "2025-09-02 15:22:01", "link": "http://arxiv.org/abs/2509.02417v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Practical Channel Estimation for Pinching-Antenna Systems: Serial vs. Parallel and Downlink vs. Uplink?", "abstract": "The practical channel estimation in uplink pinching-antenna systems is\ninvestigated, in which an electromagnetic-compliant in-waveguide transmission\nmodel is exhibited, incorporating both bidirectional power splitting,\ncumulative power leakage, and waveguide attenuation. Based on this model, the\npaper investigates two antenna activation protocols for channel estimation: a\nserial protocol based on one-by-one antenna activation and a parallel protocol\nutilizing a binary S-Matrix activation. The serial protocol is characterized by\nits superior numerical stability but a lack of array gain, whereas the parallel\nprotocol theoretically offers array gain but suffers from severe performance\ndegradation due to structural crosstalk from the non-orthogonal S-Matrix and\nill-conditioning from cumulative leakage. Furthermore, the paper analyzes the\nfundamental commonalities and asymmetries between uplink and downlink channel\nestimation in pinching-antenna systems. Numerical results demonstrate that 1)\nin an ideal lossless model, the parallel protocol is superior to the serial\nprotocol due to the array gain from simultaneous energy collection in uplink\ntransmission; 2) in a practical model with physical losses, the serial protocol\noutperforms the parallel protocol, as the performance of the parallel protocol\nis degraded by the numerical instability from cumulative leakage, which\noutweighs the benefit of array gain; 3) For downlink channel estimation, the\nserial protocol is more suitable because it avoids bidirectional power\nsplitting, while the parallel protocol is more suitable for the uplink as it\ncan make full use of array gain.", "published": "2025-09-02 15:13:49", "link": "http://arxiv.org/abs/2509.02403v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Next-Generation Sustainable Wireless Systems: Energy Efficiency Meets Environmental Impact", "abstract": "Aligning with the global mandates pushing towards advanced technologies with\nreduced resource consumption and environmental impacts, the sustainability of\nwireless networks becomes a significant concern in 6G systems. To address this\nconcern, a native integration of sustainability into the operations of\nnext-generation networks through novel designs and metrics is necessary.\nNevertheless, existing wireless sustainability efforts remain limited to\nenergy-efficient network designs which fail to capture the environmental impact\nof such systems. In this paper, a novel sustainability metric is proposed that\ncaptures emissions per bit, providing a rigorous measure of the environmental\nfoot- print associated with energy consumption in 6G networks. This metric also\ncaptures how energy, computing, and communication resource parameters influence\nthe reduction of emissions per bit. Then, the problem of allocating the energy,\ncomputing and communication resources is posed as a multi-objective (MO)\noptimization problem. To solve the resulting non-convex problem, our framework\nleverages MO reinforcement learning (MORL) to maximize the novel sustainability\nmetric alongside minimizing energy consumption and average delays in\nsuccessfully delivering the data, all while adhering to constraints on energy\nresource capacity. The proposed MORL methodology computes a global policy that\nachieves a Pareto-optimal tradeoff among multiple objectives, thereby balancing\nenvironmental sustainability with network performance. Simulation results show\nthat the proposed approach reduces the average emissions per bit by around 26%\ncompared to state-of-the-art methods that do not explicitly integrate carbon\nemissions into their control objectives.", "published": "2025-09-02 15:02:44", "link": "http://arxiv.org/abs/2509.02395v1", "categories": ["cs.IT", "cs.NI", "math.IT"], "primary_category": "cs.IT"}
{"title": "Tree algorithms for set reconciliation", "abstract": "In this work, a set reconciliation setting is considered in which two parties\nhave similar sets that they would like to reconcile. In particular, we focus on\na divide-and-conquer strategy known as partitioned set reconciliation (PSR), in\nwhich the sets to be reconciled are successively partitioned until they contain\na number of differences below some predetermined value. Borrowing techniques\nfrom tree-algorithms for random-access protocols, we present and analyze a\nnovel set reconciliation scheme that we term enhanced partitioned set\nreconciliation (EPSR). This approach improves the efficiency in terms of\noverhead, i.e., it yields a lower communication cost, while keeping the same\ntime and communication round complexity as PSR. Additionally, we simulate the\nperformance of the proposed algorithm in an event-driven simulator. Our\nfindings indicate that this novel protocol nearly halves the communication cost\nof PSR while maintaining the same time complexity.", "published": "2025-09-02 14:40:25", "link": "http://arxiv.org/abs/2509.02373v1", "categories": ["cs.NI", "cs.DS", "cs.IT", "math.IT"], "primary_category": "cs.NI"}
{"title": "Beamforming Design for Pinching Antenna Systems with Multiple Receive Antennas", "abstract": "Next-generation networks require intelligent and robust channel conditions to\nsupport ultra-high data rates, seamless connectivity, and large-scale device\ndeployments in dynamic environments. While flexible antenna technologies such\nas fluid and movable antennas offer some degree of adaptability, their limited\nreconfiguration range and structural rigidity reduce their effectiveness in\nrestoring line-of-sight (LoS) links. As a complementary solution, pinching\nantenna systems (PASs) enable fine-grained, hardware-free control of radiation\nlocations along a waveguide, offering enhanced flexibility in challenging\npropagation environments, especially under non-LoS (NLoS) conditions. This\npaper introduces a general and novel modeling framework for downlink PASs\ntargeting users equipped with multiple receive antennas, addressing a practical\nyet underexplored scenario in the existing literature. Specifically, we first\nderive an analytical relationship between the received signal-to-noise ratio\nand the pinching antenna (PA) positions, and based on this, we propose a\ntwo-layer placement strategy. First, we optimize the central radiation point\nusing large-scale channel characteristics, and then we use a heuristic\ncompressed placement algorithm to approximate phase alignment across multiple\nreceive antennas and select a spatially compact set of active elements.\nSimulation results demonstrate notable performance gains over conventional\nsingle-antenna schemes, particularly in short-range scenarios with dense PAs\nand widely spaced user antennas.", "published": "2025-09-02 10:19:44", "link": "http://arxiv.org/abs/2509.02166v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Dual Target-Mounted RISs-Assisted ISAC Against Eavesdropping and Malicious Interference", "abstract": "The synergy between integrated sensing and communication (ISAC) and\nreconfigurable intelligent surfaces (RISs) unlocks novel applications and\nadvanced services for next-generation wireless networks, yet also introduces\nnew security challenges. In this study, a novel dual target-mounted\nRISs-assisted ISAC scheme is proposed, where a base station with ISAC\ncapability performs sensing of two unmanned aerial vehicle (UAV) targets, one\nof which is legitimate and the other is eavesdropper, while communicating with\nthe users through an RIS mounted on the legitimate UAV target. The proposed\nscheme addresses dual security threats posed by a hostile UAV target:\neavesdropping on legitimate user communications and random interference attacks\nlaunched by a malicious RIS mounted on this eavesdropper UAV target, aiming to\ndisrupt secure transmissions. A non-convex optimization problem maximizing the\nsecrecy rate of the users is formulated, and a semi-definite relaxation\n(SDR)-based two-stage solution is developed to optimize the transmit\nbeamforming matrix of the base station and the phase shift coefficients of the\nlegitimate RIS. Extensive computer simulations are conducted to evaluate the\nrobustness of the proposed solution under various system configurations. The\nproposed system's communication performance is assessed using the secrecy rate\nmetric, while the sensing performance is evaluated through the\nsignal-to-interference-plus-noise ratio and the Cramer-Rao bound (CRB) for\nangle-of-departure (AoD) estimation of the eavesdropper UAV target.", "published": "2025-09-02 07:18:39", "link": "http://arxiv.org/abs/2509.02030v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "MUSE-FM: Multi-task Environment-aware Foundation Model for Wireless Communications", "abstract": "Recent advancements in foundation models (FMs) have attracted increasing\nattention in the wireless communication domain. Leveraging the powerful\nmulti-task learning capability, FMs hold the promise of unifying multiple tasks\nof wireless communication with a single framework. with a single framework.\nNevertheless, existing wireless FMs face limitations in the uniformity to\naddress multiple tasks with diverse inputs/outputs across different\ncommunication scenarios.In this paper, we propose a MUlti-taSk\nEnvironment-aware FM (MUSE-FM) with a unified architecture to handle multiple\ntasks in wireless communications, while effectively incorporating scenario\ninformation.Specifically, to achieve task uniformity, we propose a unified\nprompt-guided data encoder-decoder pair to handle data with heterogeneous\nformats and distributions across different tasks. Besides, we integrate the\nenvironmental context as a multi-modal input, which serves as prior knowledge\nof environment and channel distributions and facilitates cross-scenario feature\nextraction. Simulation results illustrate that the proposed MUSE-FM outperforms\nexisting methods for various tasks, and its prompt-guided encoder-decoder pair\nimproves the scalability for new task configurations. Moreover, the\nincorporation of environment information improves the ability to adapt to\ndifferent scenarios.", "published": "2025-09-02 05:15:48", "link": "http://arxiv.org/abs/2509.01967v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "AoI-based Scheduling of Correlated Sources for Timely Inference", "abstract": "We investigate a real-time remote inference system where multiple correlated\nsources transmit observations over a communication channel to a receiver. The\nreceiver utilizes these observations to infer multiple time-varying targets.\nDue to limited communication resources, the delivered observations may not be\nfresh. To quantify data freshness, we employ the Age of Information (AoI)\nmetric. To minimize the inference error, we aim to design a signal-agnostic\nscheduling policy that leverages AoI without requiring knowledge of the actual\ntarget values or the source observations. This scheduling problem is a restless\nmulti-armed bandit (RMAB) problem with a non-separable penalty function. Unlike\ntraditional RMABs, the correlation among sources introduces a unique challenge:\nthe penalty function of each source depends on the AoI of other correlated\nsources, preventing decomposition of the problem into multiple independent\nMarkov Decision Processes (MDPs), a key step in applying traditional RMAB\nsolutions. To address this, we propose a novel approach by approximating the\npenalty function of each source and establish an analytical bound on the\napproximation error. We then develop scheduling policies for two scenarios: (i)\nfull knowledge of the penalty functions and (ii) no knowledge of the penalty\nfunctions. For the case of known penalty functions, we present an upper bound\non the optimality gap of our policy in the asymptotic regime. For the case of\nunknown penalty functions and signal distributions, we develop an online\nlearning approach that utilizes bandit feedback to learn an online Maximum Gain\nFirst (MGF) policy. Simulation results demonstrate the effectiveness of our\nproposed policies in minimizing inference error and achieving scalability in\nthe number of sources.", "published": "2025-09-02 03:46:14", "link": "http://arxiv.org/abs/2509.01926v1", "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "cs.NI"}
{"title": "On the Analysis of Random Linear Streaming Codes in Stochastic Channels", "abstract": "Random Linear Streaming Codes (RLSCs) can dramatically reduce the queuing\ndelay of block codes in real-time services. In this paper, we aim to explore\nthe fundamental limit of large-field-size RLSCs in stochastic symbol erasure\nchannels (SEC). The Non-systematic RLSCs (NRLSCs) in i.i.d. SEC has been\nanalyzed in [Pinwen Su et al. 2022]. In this work, we first derive the\nclosed-form expression on the exact error probability of NRLSCs in\nGilbert-Elliott symbol erasure channels (G-ESEC). Compared to i.i.d SEC, the\nerasure probability of G-ESEC depends on channel state, thus transitions\nbetween the states should be considered. To deal with the stochastic state\ntransitions, we introduce two novel techniques. (i) To account for the impact\nof switching states on probability terms, we find and leverage the recursive\nstructure of the state transition traces. (ii) To obtain the expected number of\nerror timeslots, we derive the stationary initial distribution of the states,\nand formulate iterative equation to characterize the expectation terms. Then we\nanalyze the Systematic RLSCs (SRLSCs) in a special SEC, i.e., the packet\nerasure channel (PEC). In this scenario, SRLSCs could save some source symbols\nwhich should have exceeded the decoding delay in NRLSCs, and thus could\nsignificantly reduce the error probability. To this point, our contributions\nare two-folds. (i) Through a case study, we find a counter-intuitive phenomenon\nthat SRLSCs can cause unexpected error events comparing to NRLSCs in some\nerasure patterns. Then we fully characterize the error event of SRLSCs for any\nerasure pattern. (ii) For i.i.d. PEC, we derive an analytical expression on\nexact error probability of SRLSCs when length of memory approaches infinity and\ncoding rate equals to 1/2. Simulations are conducted to verify the accuracy of\nour analysis and compare the performance of NRLSCs, SRLSCs, and existing\nstreaming codes.", "published": "2025-09-02 02:32:02", "link": "http://arxiv.org/abs/2509.01894v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Improving Generative Methods for Causal Evaluation via Simulation-Based Inference", "abstract": "Generating synthetic datasets that accurately reflect real-world\nobservational data is critical for evaluating causal estimators, but remains a\nchallenging task. Existing generative methods offer a solution by producing\nsynthetic datasets anchored in the observed data (source data) while allowing\nvariation in key parameters such as the treatment effect and amount of\nconfounding bias. However, existing methods typically require users to provide\npoint estimates of such parameters (rather than distributions) and fixed\nestimates (rather than estimates that can be improved with reference to the\nsource data). This denies users the ability to express uncertainty over\nparameter values and removes the potential for posterior inference, potentially\nleading to unreliable estimator comparisons. We introduce simulation-based\ninference for causal evaluation (SBICE), a framework that models generative\nparameters as uncertain and infers their posterior distribution given a source\ndataset. Leveraging techniques in simulation-based inference, SBICE identifies\nparameter configurations that produce synthetic datasets closely aligned with\nthe source data distribution. Empirical results demonstrate that SBICE improves\nthe reliability of estimator evaluations by generating more realistic datasets,\nwhich supports a robust and data-consistent approach to causal benchmarking\nunder uncertainty.", "published": "2025-09-02 23:35:22", "link": "http://arxiv.org/abs/2509.02892v1", "categories": ["cs.LG", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Power Grid Control with Graph-Based Distributed Reinforcement Learning", "abstract": "The necessary integration of renewable energy sources, combined with the\nexpanding scale of power networks, presents significant challenges in\ncontrolling modern power grids. Traditional control systems, which are human\nand optimization-based, struggle to adapt and to scale in such an evolving\ncontext, motivating the exploration of more dynamic and distributed control\nstrategies. This work advances a graph-based distributed reinforcement learning\nframework for real-time, scalable grid management. The proposed architecture\nconsists of a network of distributed low-level agents acting on individual\npower lines and coordinated by a high-level manager agent. A Graph Neural\nNetwork (GNN) is employed to encode the network's topological information\nwithin the single low-level agent's observation. To accelerate convergence and\nenhance learning stability, the framework integrates imitation learning and\npotential-based reward shaping. In contrast to conventional decentralized\napproaches that decompose only the action space while relying on global\nobservations, this method also decomposes the observation space. Each low-level\nagent acts based on a structured and informative local view of the environment\nconstructed through the GNN. Experiments on the Grid2Op simulation environment\nshow the effectiveness of the approach, which consistently outperforms the\nstandard baseline commonly adopted in the field. Additionally, the proposed\nmodel proves to be much more computationally efficient than the\nsimulation-based Expert method.", "published": "2025-09-02 22:17:25", "link": "http://arxiv.org/abs/2509.02861v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Managing Correlations in Data and Privacy Demand", "abstract": "Previous works in the differential privacy literature that allow users to\nchoose their privacy levels typically operate under the heterogeneous\ndifferential privacy (HDP) framework with the simplifying assumption that user\ndata and privacy levels are not correlated. Firstly, we demonstrate that the\nstandard HDP framework falls short when user data and privacy demands are\nallowed to be correlated. Secondly, to address this shortcoming, we propose an\nalternate framework, Add-remove Heterogeneous Differential Privacy (AHDP), that\njointly accounts for user data and privacy preference. We show that AHDP is\nrobust to possible correlations between data and privacy. Thirdly, we formalize\nthe guarantees of the proposed AHDP framework through an operational hypothesis\ntesting perspective. The hypothesis testing setup may be of independent\ninterest in analyzing other privacy frameworks as well. Fourthly, we show that\nthere exists non-trivial AHDP mechanisms that notably do not require prior\nknowledge of the data-privacy correlations. We propose some such mechanisms and\napply them to core statistical tasks such as mean estimation, frequency\nestimation, and linear regression. The proposed mechanisms are simple to\nimplement with minimal assumptions and modeling requirements, making them\nattractive for real-world use. Finally, we empirically evaluate proposed AHDP\nmechanisms, highlighting their trade-offs using LLM-generated synthetic\ndatasets, which we release for future research.", "published": "2025-09-02 22:03:13", "link": "http://arxiv.org/abs/2509.02856v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Towards Reasoning for PDE Foundation Models: A Reward-Model-Driven Inference-Time-Scaling Algorithm", "abstract": "Partial Differential Equations (PDEs) are the bedrock for modern\ncomputational sciences and engineering, and inherently computationally\nexpensive. While PDE foundation models have shown much promise for simulating\nsuch complex spatio-temporal phenomena, existing models remain constrained by\nthe pretraining datasets and struggle with auto-regressive rollout performance,\nespecially in out-of-distribution (OOD) cases. Furthermore, they have\nsignificant compute and training data requirements which hamper their use in\nmany critical applications. Inspired by recent advances in ``thinking\"\nstrategies used in large language models (LLMs), we introduce the first\ntest-time computing (TTC) strategy for PDEs that utilizes computational\nresources during inference to achieve more accurate predictions with fewer\ntraining samples and smaller models. We accomplish this with two types of\nreward models that evaluate predictions of a stochastic based model for\nspatio-temporal consistency. We demonstrate this method on compressible\nEuler-equation simulations from the PDEGym benchmark and show that TTC captures\nimproved predictions relative to standard non-adaptive auto-regressive\ninference. This TTC framework marks a foundational step towards more advanced\nreasoning algorithms or PDE modeling, inluding building\nreinforcement-learning-based approaches, potentially transforming computational\nworkflows in physics and engineering.", "published": "2025-09-02 21:31:32", "link": "http://arxiv.org/abs/2509.02846v1", "categories": ["cs.LG", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Fast and Accurate SVD-Type Updating in Streaming Data", "abstract": "For a datastream, the change over a short interval is often of low rank. For\nhigh throughput information arranged in matrix format, recomputing an optimal\nSVD approximation after each step is typically prohibitive. Instead,\nincremental and truncated updating strategies are used, which may not scale for\nlarge truncation ranks. Therefore, we propose a set of efficient new algorithms\nthat update a bidiagonal factorization, and which are similarly accurate as the\nSVD methods. In particular, we develop a compact Householder-type algorithm\nthat decouples a sparse part from a low-rank update and has about half the\nmemory requirements of standard bidiagonalization methods. A second algorithm\nbased on Givens rotations has only about 10 flops per rotation and scales\nquadratically with the problem size, compared to a typical cubic scaling. The\nalgorithm is therefore effective for processing high-throughput updates, as we\ndemonstrate in tracking large subspaces of recommendation systems and networks,\nand when compared to well known software such as LAPACK or the incremental SVD.", "published": "2025-09-02 21:17:37", "link": "http://arxiv.org/abs/2509.02840v1", "categories": ["math.NA", "cs.LG", "cs.MS", "cs.NA", "65F55, 68T09, 65Y20"], "primary_category": "math.NA"}
{"title": "Unlearning That Lasts: Utility-Preserving, Robust, and Almost Irreversible Forgetting in LLMs", "abstract": "Unlearning in large language models (LLMs) involves precisely removing\nspecific information from a pre-trained model. This is crucial to ensure safety\nof LLMs by deleting private data or harmful knowledge acquired during\npre-training. However, existing unlearning methods often fall short when\nsubjected to thorough evaluation. To overcome this, we introduce JensUn, where\nwe leverage the Jensen-Shannon Divergence as the training objective for both\nforget and retain sets for more stable and effective unlearning dynamics\ncompared to commonly used loss functions. In extensive experiments, JensUn\nachieves better forget-utility trade-off than competing methods, and even\ndemonstrates strong resilience to benign relearning. Additionally, for a\nprecise unlearning evaluation, we introduce LKF, a curated dataset of\nlesser-known facts that provides a realistic unlearning scenario. Finally, to\ncomprehensively test unlearning methods, we propose (i) employing an LLM as\nsemantic judge instead of the standard ROUGE score, and (ii) using worst-case\nunlearning evaluation over various paraphrases and input formats. Our improved\nevaluation framework reveals that many existing methods are less effective than\npreviously thought.", "published": "2025-09-02 20:38:53", "link": "http://arxiv.org/abs/2509.02820v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multi-Embodiment Locomotion at Scale with extreme Embodiment Randomization", "abstract": "We present a single, general locomotion policy trained on a diverse\ncollection of 50 legged robots. By combining an improved embodiment-aware\narchitecture (URMAv2) with a performance-based curriculum for extreme\nEmbodiment Randomization, our policy learns to control millions of\nmorphological variations. Our policy achieves zero-shot transfer to unseen\nreal-world humanoid and quadruped robots.", "published": "2025-09-02 20:32:02", "link": "http://arxiv.org/abs/2509.02815v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Challenges in Understanding Modality Conflict in Vision-Language Models", "abstract": "This paper highlights the challenge of decomposing conflict detection from\nconflict resolution in Vision-Language Models (VLMs) and presents potential\napproaches, including using a supervised metric via linear probes and\ngroup-based attention pattern analysis. We conduct a mechanistic investigation\nof LLaVA-OV-7B, a state-of-the-art VLM that exhibits diverse resolution\nbehaviors when faced with conflicting multimodal inputs. Our results show that\na linearly decodable conflict signal emerges in the model's intermediate layers\nand that attention patterns associated with conflict detection and resolution\ndiverge at different stages of the network. These findings support the\nhypothesis that detection and resolution are functionally distinct mechanisms.\nWe discuss how such decomposition enables more actionable interpretability and\ntargeted interventions for improving model robustness in challenging multimodal\nsettings.", "published": "2025-09-02 20:15:49", "link": "http://arxiv.org/abs/2509.02805v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Too Noisy to Collude? Algorithmic Collusion Under Laplacian Noise", "abstract": "The rise of autonomous pricing systems has sparked growing concern over\nalgorithmic collusion in markets from retail to housing. This paper examines\ncontrolled information quality as an ex ante policy lever: by reducing the\nfidelity of data that pricing algorithms draw on, regulators can frustrate\ncollusion before supracompetitive prices emerge. We show, first, that\ninformation quality is the central driver of competitive outcomes, shaping\nprices, profits, and consumer welfare. Second, we demonstrate that collusion\ncan be slowed or destabilized by injecting carefully calibrated noise into\npooled market data, yielding a feasibility region where intervention disrupts\ncartels without undermining legitimate pricing. Together, these results\nhighlight information control as a lightweight yet practical lever to blunt\ndigital collusion at its source.", "published": "2025-09-02 20:02:17", "link": "http://arxiv.org/abs/2509.02800v1", "categories": ["econ.GN", "cs.GT", "cs.MA", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "Harnessing Information in Incentive Design", "abstract": "Incentive design deals with interaction between a principal and an agent\nwhere the former can shape the latter's utility through a policy commitment. It\nis well known that the principal faces an information rent when dealing with an\nagent that has informational advantage. In this work, we embark on a systematic\nstudy of the effect of information asymmetry in incentive design games.\nSpecifically, we first demonstrate that it is in principal's interest to\ndecrease this information asymmetry. To mitigate this uncertainty, we let the\nprincipal gather information either by letting the agent shape her belief (aka\nInformation Design), or by paying to acquire it. Providing solutions to all\nthese cases we show that while introduction of uncertainty increases the\nprincipal's cost, letting the agent shape its belief can be advantageous. We\nstudy information asymmetry and information acquisition in both matrix games\nand quadratic Gaussian game setups.", "published": "2025-09-02 16:41:50", "link": "http://arxiv.org/abs/2509.02493v1", "categories": ["cs.GT", "cs.MA", "cs.SY", "eess.SY", "math.OC"], "primary_category": "cs.GT"}
{"title": "VariAntNet: Learning Decentralized Control of Multi-Agent Systems", "abstract": "A simple multi-agent system can be effectively utilized in disaster response\napplications, such as firefighting. Such a swarm is required to operate in\ncomplex environments with limited local sensing and no reliable inter-agent\ncommunication or centralized control. These simple robotic agents, also known\nas Ant Robots, are defined as anonymous agents that possess limited sensing\ncapabilities, lack a shared coordinate system, and do not communicate\nexplicitly with one another. A key challenge for simple swarms lies in\nmaintaining cohesion and avoiding fragmentation despite limited-range sensing.\nRecent advances in machine learning offer effective solutions to some of the\nclassical decentralized control challenges. We propose VariAntNet, a deep\nlearning-based decentralized control model designed to facilitate agent\nswarming and collaborative task execution. VariAntNet includes geometric\nfeatures extraction from unordered, variable-sized local observations. It\nincorporates a neural network architecture trained with a novel,\ndifferentiable, multi-objective, mathematically justified loss function that\npromotes swarm cohesiveness by utilizing the properties of the visibility graph\nLaplacian matrix. VariAntNet is demonstrated on the fundamental multi-agent\ngathering task, where agents with bearing-only and limited-range sensing must\ngather at some location. VariAntNet significantly outperforms an existing\nanalytical solution, achieving more than double the convergence rate while\nmaintaining high swarm connectivity across varying swarm sizes. While the\nanalytical solution guarantees cohesion, it is often too slow in practice. In\ntime-critical scenarios, such as emergency response operations where lives are\nat risk, slower analytical methods are impractical and justify the loss of some\nagents within the swarm. This paper presents and analyzes this trade-off in\ndetail.", "published": "2025-09-02 12:48:15", "link": "http://arxiv.org/abs/2509.02271v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Dynamic Speculative Agent Planning", "abstract": "Despite their remarkable success in complex tasks propelling widespread\nadoption, large language-model-based agents still face critical deployment\nchallenges due to prohibitive latency and inference costs. While recent work\nhas explored various methods to accelerate inference, existing approaches\nsuffer from significant limitations: they either fail to preserve performance\nfidelity, require extensive offline training of router modules, or incur\nexcessive operational costs. Moreover, they provide minimal user control over\nthe tradeoff between acceleration and other performance metrics. To address\nthese gaps, we introduce Dynamic Speculative Planning (DSP), an asynchronous\nonline reinforcement learning framework that provides lossless acceleration\nwith substantially reduced costs without requiring additional pre-deployment\npreparation. DSP explicitly optimizes a joint objective balancing end-to-end\nlatency against dollar cost, allowing practitioners to adjust a single\nparameter that steers the system toward faster responses, cheaper operation, or\nany point along this continuum. Experiments on two standard agent benchmarks\ndemonstrate that DSP achieves comparable efficiency to the fastest lossless\nacceleration method while reducing total cost by 30% and unnecessary cost up to\n60%. Our code and data are available through\nhttps://github.com/guanyilin428/Dynamic-Speculative-Planning.", "published": "2025-09-02 03:34:36", "link": "http://arxiv.org/abs/2509.01920v1", "categories": ["cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Spacetime Wavelet Method for Linear Boundary-Value Problems in Sylvester Matrix Equation Form", "abstract": "We present a high-order spacetime numerical method for discretizing and\nsolving linear initial-boundary value problems using wavelet-based techniques\nwith user-prescribed error estimates. The spacetime wavelet discretization\nyields a system of algebraic equations resulting in a Sylvester matrix\nequation. We solve this system with a Global Generalized Minimal Residual\n(GMRES) method in conjunction with a wavelet-based recursive algorithm to\nimprove convergence. We perform rigorous verification studies using linear\npartial differential equations (PDEs) with both convective and diffusive terms.\nThe results of these simulations show the high-order convergence rates for the\nsolution and derivative approximations predicted by wavelet theory. We\ndemonstrate the utility of solving the Sylvester equation through comparisons\nto the commonly-used Kronecker product formulation. We show that our recursive\nwavelet-based algorithm that generates initial guesses for the iterative Global\nGMRES method improves the performance of the solver.", "published": "2025-09-02 18:17:37", "link": "http://arxiv.org/abs/2509.02720v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Fractional differential equations: non-constant coefficients, simulation and model reduction", "abstract": "We consider boundary value problems with Riemann-Liouville fractional\nderivatives of order $s\\in (1, 2)$ with non-constant diffusion and reaction\ncoefficients. A variational formulation is derived and analyzed leading to the\nwell-posedness of the continuous problem and its Finite Element discretization.\nThen, the Reduced Basis Method through a greedy algorithm for parametric\ndiffusion and reaction coefficients is analyzed. Its convergence properties,\nand in particular the decay of the Kolmogorov $n$-width, are seen to depend on\nthe fractional order $s$. Finally, numerical results confirming our findings\nare presented.", "published": "2025-09-02 16:19:22", "link": "http://arxiv.org/abs/2509.02465v1", "categories": ["math.NA", "cs.NA", "26A33, 34K37, 65N30"], "primary_category": "math.NA"}
{"title": "A Convolutional Hierarchical Deep-learning Neural Network (C-HiDeNN) Framework for Non-linear Finite Element/Meshfree Analysis", "abstract": "We present a framework for the Convolutional Hierarchical Deep Neural Network\n(C-HiDeNN) tailored for nonlinear finite element and meshfree analysis.\nBuilding upon the structured foundation of HiDeNN, which includes the\nevaluation of shape function derivatives, adaptivity, and material derivatives,\nC-HiDeNN introduces a convolution operator to enhance the HiDeNN approximation.\nA distinctive feature of C-HiDeNN is its expanded set of optimization\nparameters, such as the polynomial order 'p,' dilation parameter 'a,' patch\nsize 's,' and nodal position 'X'. These parameters function as the weights and\nbiases within the C-HiDeNN patch. In addition, C-HiDeNN can be prescribed in\nregions where high resolution is desired to adaptively improve prediction\naccuracy. To demonstrate the effectiveness of this framework, we provide\nnumerical examples in the context of nonlinear finite element and meshfree\nanalysis. The results show that our approach achieves significantly higher\naccuracy compared to the standard Finite Element Method (FEM) while\nsubstantially reducing computational costs.", "published": "2025-09-02 15:37:03", "link": "http://arxiv.org/abs/2509.02435v1", "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "math.NA"}
{"title": "Bryne: sustainable prototyping of finite element models", "abstract": "Open-source simulation frameworks are evolving rapidly to provide accessible\ntools for the numerical solution of partial differential equations. Modern\nfinite element (FEM) software such as FEniCS, Firedrake, or dune-fem alleviates\nthe need for modelers to recode the discretization and linear solver backend\nfor each application and enables rapid prototyping of solvers. However, while\nit has become easier to build prototype FEM models, creating a solver reusable\nbeyond its specific initial simulation setup remains difficult. Moreover,\nsimulation setups typically cover an ample input parameter space, and tracking\ncomplex metadata on research project time scales has become a challenge. This\nimplies the need to supplement model development with a coding-intensive\ncomplementary workstream, seldom developed for sustainable reuse. To address\nthese issues, we introduce our open-source Python package Bryne. Bryne is an\nobject-oriented framework for FEM solvers built with the dune-fem Python API.\nIn this article, we describe how it helps to evolve rapid-prototyping solver\ndevelopment into sustainable simulation building. First, we show how to\ntranslate a minimal dune-fem solver into a Bryne FEM model to build\nhuman-readable, metadata-enriched simulations. Bryne then offers a simulation\ndriver and model coupling interfaces to combine implemented solvers in\noperator-split multiphysics simulations. The resulting reproducibility-enabled\ninfrastructure allows users to tackle complex simulation setups without\nsacrificing backend flexibility. We demonstrate the workflow on a\nconvection-coupled phase-change simulation, where a discontinuous Galerkin flow\nsolver is coupled with a solver for solidification phase change.", "published": "2025-09-02 14:44:18", "link": "http://arxiv.org/abs/2509.02378v1", "categories": ["physics.comp-ph", "cs.NA", "math.NA"], "primary_category": "physics.comp-ph"}
{"title": "Multi-stage PDE-based image processing techniques for noisy MRI scans", "abstract": "Image denoising and image segmentation play essential roles in image\nprocessing. Partial differential equations (PDE)-based methods have proven to\nshow reliable results when incorporated in both denoising and segmentation of\nimages. In our work, we discuss a multi-stage PDE-based image processing\napproach. It relies upon the nonlinear diffusion for noise removal and\nclustering and region growing for segmentation. In the first stage of the\napproach, the raw image is computed from noisy measurement data. The second\nstage aims to filter out the noise using anisotropic diffusion. We couple these\nstages into one optimisation problem which allows us to incorporate a diffusion\ncoefficient based on a presegmented image. The third stage performs the final\nsegmentation of the image. We demonstrate our approach on both images for which\nthe ground truth is known and on MR measurements made by an experimental,\ninexpensive scanner.", "published": "2025-09-02 14:08:44", "link": "http://arxiv.org/abs/2509.02342v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Correction of weighted and shifted seven-step BDF for parabolic equations with nonsmooth data", "abstract": "It is well known that the seven-step backward difference formula (BDF) is\nunstable for the parabolic equations, since it is not even zero-stable.\nHowever, a linear combination of two non zero-stable schemes, namely the\nseven-step BDF and its shifted counterpart, can yield $A(\\alpha)$ stable. Based\non this observation, the authors [Akrivis, Chen, and Yu, IMA J. Numer. Anal.,\nDOI:10.1093/imanum/drae089] propose the weighted and shifted seven-step BDF\nmethods for the parabolic equations, which stability regions are larger than\nthe standard BDF. Nonetheless, this approach is not directly applicable for the\nparabolic equations with nonsmooth data, which may suffer from severe order\nreduction. This motivates us to design proper correction time-stepping schemes\nto restore the desired $k$th-order convergence rate of the $k$-step weighted\nand shifted BDF ($k\\leq 7$) convolution quadrature for the parabolic problems.\nWe prove that the desired $k$th-order convergence can be recovered even if the\nsource term is discontinuous and the initial value is nonsmooth data. Numerical\nexperiments illustrate the theoretical results.", "published": "2025-09-02 13:30:32", "link": "http://arxiv.org/abs/2509.02307v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Paving the way to a $\\operatorname{T}$-coercive method for the wave equation", "abstract": "In this paper, we take a first step toward introducing a space-time\ntransformation operator $\\operatorname{T}$ that establishes\n$\\operatorname{T}$-coercivity for the weak variational formulation of the wave\nequation in space and time on bounded Lipschitz domains. As a model problem, we\nstudy the ordinary differential equation (ODE) $u'' + \\mu u = f$ for $\\mu>0$,\nwhich is linked to the wave equation via a Fourier expansion in space. For its\nweak formulation, we introduce a transformation operator $\\operatorname{T}_\\mu$\nthat establishes $\\operatorname{T}_\\mu$-coercivity of the bilinear form\nyielding an unconditionally stable Galerkin-Bubnov formulation with error\nestimates independent of $\\mu$. The novelty of the current approach is the\nexplicit dependence of the transformation on $\\mu$ which, when extended to the\nframework of partial differential equations, yields an operator acting in both\ntime and space. We pay particular attention to keeping the trial space as a\nstandard Sobolev space, simplifying the error analysis, while only the test\nspace is modified. The theoretical results are complemented by numerical\nexamples.", "published": "2025-09-02 13:08:16", "link": "http://arxiv.org/abs/2509.02288v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Higher Order Unfitted Space-Time Methods for Transport Problems", "abstract": "In this article, we present an Unfitted Space-Time Finite Element method for\nthe scalar transport equation posed on moving domains. We consider the case of\nthe domain boundary being transported by the same velocity field as the scalar\nconcentration inside the physical domain. A standard continuous Galerkin Finite\nelement space is considered on a fixed background mesh, as well as tensor\nproduct Space-Time elements, which can be discontinuous along time slice\nboundaries. For the computational geometry, we opt for a spatially second-order\naccurate approximation variant in the mathematical analysis. In particular, we\nestablish stability in a problem-specific norm and prove a priori error bounds\nof high order. Numerical examples illustrate these theoretical findings.", "published": "2025-09-02 12:26:15", "link": "http://arxiv.org/abs/2509.02253v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Notes on Simplifying the Construction of Barabanov Norms", "abstract": "To answer the question about the growth rate of matrix products, the concepts\nof joint and generalized spectral radius were introduced in the 1960s. A common\ntool for finding the joint/generalized spectral radius is the so-called\nextremal norms and, in particular, the Barabanov norm. The goal of this paper\nis to try to combine the advantages of different approaches based on the\nconcept of extremality in order to obtain results that are simpler for everyday\nuse. It is shown how the Dranishnikov-Konyagin theorem on the existence of a\nspecial invariant body for a set of matrices can be used to construct a\nBarabanov norm. A modified max-relaxation algorithm for constructing Barabanov\nnorms, which follows from this theorem, is described. Additional techniques are\nalso described that simplify the construction of Barabanov norms under the\nassumption that", "published": "2025-09-02 11:52:08", "link": "http://arxiv.org/abs/2509.02230v1", "categories": ["math.RA", "cs.NA", "math.NA", "15A18, 15A60, 65F15"], "primary_category": "math.RA"}
{"title": "Achieving wavenumber robustness in domain decomposition for heterogeneous Helmholtz equation: an overview of spectral coarse spaces", "abstract": "Solving time-harmonic wave propagation problems in the frequency domain\nwithin heterogeneous media poses significant mathematical and computational\nchallenges, particularly in the high-frequency regime. Among the available\nnumerical approaches, domain decomposition methods are widely regarded as\neffective due to their suitability for parallel computing and their capacity to\nmaintain robustness with respect to physical parameters, such as the\nwavenumber. These methods can achieve near-constant time-to-solution as the\nwavenumber increases, though often at the expense of a computationally\nintensive coarse correction step. This work focuses on identifying the best\nalgorithms and numerical strategies for benchmark problems modelled by the\nHelmholtz equation. Specifically, we examine and compare several coarse spaces\nwhich are part of different families, e.g. GenEO (Generalised Eigenvalue\nOverlap) type coarse spaces and harmonic coarse spaces, that underpin two-level\ndomain decomposition methods. By leveraging spectral information and multiscale\napproaches, we aim to provide a comprehensive overview of the strengths and\nweaknesses of these methods. Numerical experiments demonstrate that the\neffectiveness of these coarse spaces depends on the specific problem and\nnumerical configuration, highlighting the trade-offs between computational\ncost, robustness, and practical applicability.", "published": "2025-09-02 09:26:08", "link": "http://arxiv.org/abs/2509.02131v1", "categories": ["math.NA", "cs.NA", "65N55, 65N35, 65F10"], "primary_category": "math.NA"}
{"title": "High-Order Schemes for Hyperbolic Conservation Laws Using Young Measures", "abstract": "We develop high-order numerical schemes to solve random hyperbolic\nconservation laws using linear programming. The proposed schemes are high-order\nextensions of the existing first-order scheme introduced in [{\\sc S. Chu, M.\nHerty, M. Luk\\'a\\v{c}ov\\'a-Medvi{\\softd}ov\\'a, and Y. Zhou}, solving random\nhyperbolic conservation laws using linear programming], where a novel\nstructure-preserving numerical method using a concept of generalized,\nmeasure-valued solutions to solve random hyperbolic systems of conservation\nlaws is proposed, yielding a linear partial differential equation concerning\nthe Young measure and allowing the computation of approximations based on\nlinear programming problems. The second-order extension is obtained using\npiecewise linear reconstructions of the one-sided point values of the unknowns.\nThe fifth-order scheme is developed using the finite-difference alternative\nweighted essentially non-oscillatory (A-WENO) framework. These extensions\nsignificantly improve the resolution of discontinuities, as demonstrated by a\nseries of numerical experiments on both random (Burgers equation, isentropic\nEuler equations) and deterministic (discontinuous flux, pressureless gas\ndynamics, Burgers equation with non-atomic support) hyperbolic conservation\nlaws.", "published": "2025-09-02 09:04:28", "link": "http://arxiv.org/abs/2509.02107v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "CLINN: Conservation Law Informed Neural Network for Approximating Discontinuous Solutions", "abstract": "Physics-informed Neural Network (PINN) faces significant challenges when\napproximating solutions to conservation laws, particularly in ensuring\nconservation and accurately resolving discontinuities. To address these\nlimitations, we propose Conservation Law-informed Neural Network (CLINN), a\nnovel framework that incorporates the boundedness constraint, implicit solution\nform, and Rankine-Hugoniot condition of scalar conservation laws into the loss\nfunction, thereby enforcing exact conservation properties. Furthermore, we\nintegrate a residual-based adaptive refinement (RAR) strategy to dynamically\nprioritize training near discontinuities, substantially improving the network's\nability to capture sharp gradients. Numerical experiments are conducted on\nbenchmark problems, including the inviscid Burgers equation, the\nLighthill-Whitham-Richards (LWR) traffic flow model, and the Buckley-Leverett\nproblem. Results demonstrate that CLINN achieves superior accuracy in resolving\nsolution profiles and discontinuity locations while reducing numeral\noscillations. Compared to conventional PINN, CLINN yields a maximum reduction\nof 99.2% in mean squared error (MSE).", "published": "2025-09-02 08:42:15", "link": "http://arxiv.org/abs/2509.02091v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "The Conjugate Function Method for Surfaces with Elaborate Topological Types", "abstract": "The conjugate function method is an algorithm for numerical computation of\nconformal mappings for simply and multiply connected domains on surfaces. In\nthis paper the conjugate function method is generalized and refined to achieve\nthe same level of accuracy on simply and multiply connected planar domains and\nRiemann surfaces. The main challenge addressed here is the accurate and\nefficient construction of the conjugate problem for multiply connected domains.\nThe method relies on high-order finite element methods which allow for highly\naccurate computations of mappings on surfaces, including domains of complex\nboundary geometry containing strong singularities and cusps. The efficacy of\nthe proposed method is illustrated via an extensive set of numerical\nexperiments with error estimates.", "published": "2025-09-02 05:42:27", "link": "http://arxiv.org/abs/2509.01978v1", "categories": ["math.NA", "cs.NA", "math.CV", "math.DG", "30Cxx, 30Fxx, 65E10, 65N30"], "primary_category": "math.NA"}
{"title": "A Million-Point Fast Trajectory Optimization Solver", "abstract": "One might argue that solving a trajectory optimization problem over a million\ngrid points is preposterous. How about solving such a problem at an incredibly\nfast computational time? On a small form-factor processor? Algorithmic details\nthat make possible this trifecta of breakthroughs are presented in this paper.\nThe computational mathematics that deliver these advancements are: (i) a\nBirkhoff-theoretic discretization of optimal control problems, (ii) matrix-free\nlinear algebra leveraging Krylov-subspace methods, and (iii) a near-perfect\nBirkhoff preconditioner that helps achieve $\\mathcal{O}(1)$ iteration speed\nwith respect to the grid size,~$N$. A key enabler of this high performance is\nthe computation of Birkhoff matrix-vector products at $\\mathcal{O}(N\\log(N))$\ntime using fast Fourier transform techniques that eliminate traditional\ncomputational bottlenecks. A numerical demonstration of this unprecedented\nscale and speed is illustrated for a practical astrodynamics problem.", "published": "2025-09-02 00:47:59", "link": "http://arxiv.org/abs/2509.01855v1", "categories": ["math.NA", "cs.MS", "cs.NA", "cs.SY", "eess.SY", "math.OC"], "primary_category": "math.NA"}
{"title": "A deep learning-driven iterative scheme for high-dimensional HJB equations in portfolio selection with exogenous and endogenous costs", "abstract": "In this paper, we first conduct a study of the portfolio selection problem,\nincorporating both exogenous (proportional) and endogenous (resulting from\nliquidity risk, characterized by a stochastic process) transaction costs\nthrough the utility-based approach. We also consider the intrinsic relationship\nbetween these two types of costs. To address the associated nonlinear\ntwo-dimensional Hamilton-Jacobi-Bellman (HJB) equation, we propose an\ninnovative deep learning-driven policy iteration scheme with three key\nadvantages: i) it has the potential to address the curse of dimensionality; ii)\nit is adaptable to problems involving high-dimensional control spaces; iii) it\neliminates truncation errors. The numerical analysis of the proposed scheme,\nincluding convergence analysis in a general setting, is also discussed. To\nillustrate the impact of these two types of transaction costs on portfolio\nchoice, we conduct through numerical experiments using three typical utility\nfunctions.", "published": "2025-09-02 12:43:46", "link": "http://arxiv.org/abs/2509.02267v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Bridging Human Cognition and AI: A Framework for Explainable Decision-Making Systems", "abstract": "Explainability in AI and ML models is critical for fostering trust, ensuring\naccountability, and enabling informed decision making in high stakes domains.\nYet this objective is often unmet in practice. This paper proposes a general\npurpose framework that bridges state of the art explainability techniques with\nMalle's five category model of behavior explanation: Knowledge Structures,\nSimulation/Projection, Covariation, Direct Recall, and Rationalization. The\nframework is designed to be applicable across AI assisted decision making\nsystems, with the goal of enhancing transparency, interpretability, and user\ntrust. We demonstrate its practical relevance through real world case studies,\nincluding credit risk assessment and regulatory analysis powered by large\nlanguage models (LLMs). By aligning technical explanations with human cognitive\nmechanisms, the framework lays the groundwork for more comprehensible,\nresponsible, and ethical AI systems.", "published": "2025-09-02 14:53:37", "link": "http://arxiv.org/abs/2509.02388v1", "categories": ["q-fin.ST", "62P20, 68T05, 62P20", "I.2.7; G.3; H.5.m"], "primary_category": "q-fin.ST"}
{"title": "A proximal augmented Lagrangian method for nonconvex optimization with equality and inequality constraints", "abstract": "We propose an inexact proximal augmented Lagrangian method (P-ALM) for\nnonconvex structured optimization problems. The proposed method features an\neasily implementable rule not only for updating the penalty parameters, but\nalso for adaptively tuning the proximal term. It allows the penalty parameter\nto grow rapidly in the early stages to speed up progress, while ameliorating\nthe issue of ill-conditioning in later iterations, a well-known drawback of the\ntraditional approach of linearly increasing the penalty parameters. A key\nelement in our analysis lies in the observation that the augmented Lagrangian\ncan be controlled effectively along the iterates, provided an initial feasible\npoint is available. Our analysis, while simple, provides a new theoretical\nperspective about P-ALM and, as a by-product, results in similar convergence\nproperties for its non-proximal variant, the classical augmented Lagrangian\nmethod (ALM). Numerical experiments, including convex and nonconvex problem\ninstances, demonstrate the effectiveness of our approach.", "published": "2025-09-02 23:39:53", "link": "http://arxiv.org/abs/2509.02894v1", "categories": ["math.OC", "stat.ML", "65K05, 93-08, 49M37 (Primary) 90C06, 90C53 (Secondary)"], "primary_category": "math.OC"}
{"title": "A Composite-Loss Graph Neural Network for the Multivariate Post-Processing of Ensemble Weather Forecasts", "abstract": "Ensemble forecasting systems have advanced meteorology by providing\nprobabilistic estimates of future states, supporting applications from\nrenewable energy production to transportation safety. Nonetheless, systematic\nbiases often persist, making statistical post-processing essential. Traditional\nparametric post-processing techniques and machine learning-based methods can\nproduce calibrated predictive distributions at specific locations and lead\ntimes, yet often struggle to capture dependencies across forecast dimensions.\nTo address this, multivariate post-processing methods-such as ensemble copula\ncoupling and the Schaake shuffle-are widely applied in a second step to restore\nrealistic inter-variable or spatio-temporal dependencies. The aim of this study\nis the multivariate post-processing of ensemble forecasts using a graph neural\nnetwork (dualGNN) trained with a composite loss function that combines the\nenergy score (ES) and the variogram score (VS). The method is evaluated on two\ndatasets: WRF-based solar irradiance forecasts over northern Chile and ECMWF\nvisibility forecasts for Central Europe. The dualGNN consistently outperforms\nall empirical copula-based post-processed forecasts and shows significant\nimprovements compared to graph neural networks trained solely on either the\ncontinuous ranked probability score (CRPS) or the ES, according to the\nevaluated multivariate verification metrics. Furthermore, for the WRF\nforecasts, the rank-order structure of the dualGNN forecasts captures valuable\ndependency information, enabling a more effective restoration of spatial\nrelationships than either the raw numerical weather prediction ensemble or\nhistorical observational rank structures. By contrast, for the visibility\nforecasts, the GNNs trained on CRPS, ES, or the ES-VS combination outperform\nthe calibrated reference.", "published": "2025-09-02 19:37:44", "link": "http://arxiv.org/abs/2509.02784v1", "categories": ["stat.AP", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Inference on covariance structure in high-dimensional multi-view data", "abstract": "This article focuses on covariance estimation for multi-view data. Popular\napproaches rely on factor-analytic decompositions that have shared and\nview-specific latent factors. Posterior computation is conducted via expensive\nand brittle Markov chain Monte Carlo (MCMC) sampling or variational\napproximations that underestimate uncertainty and lack theoretical guarantees.\nOur proposed methodology employs spectral decompositions to estimate and align\nlatent factors that are active in at least one view. Conditionally on these\nfactors, we choose jointly conjugate prior distributions for factor loadings\nand residual variances. The resulting posterior is a simple product of\nnormal-inverse gamma distributions for each variable, bypassing MCMC and\nfacilitating posterior computation. We prove favorable increasing-dimension\nasymptotic properties, including posterior contraction and central limit\ntheorems for point estimators. We show excellent performance in simulations,\nincluding accurate uncertainty quantification, and apply the methodology to\nintegrate four high-dimensional views from a multi-omics dataset of cancer cell\nsamples.", "published": "2025-09-02 19:20:42", "link": "http://arxiv.org/abs/2509.02772v1", "categories": ["stat.ME", "stat.CO", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Calibration Prediction Interval for Non-parametric Regression and Neural Networks", "abstract": "Accurate conditional prediction in the regression setting plays an important\nrole in many real-world problems. Typically, a point prediction often falls\nshort since no attempt is made to quantify the prediction accuracy.\nClassically, under the normality and linearity assumptions, the Prediction\nInterval (PI) for the response variable can be determined routinely based on\nthe $t$ distribution. Unfortunately, these two assumptions are rarely met in\npractice. To fully avoid these two conditions, we develop a so-called\ncalibration PI (cPI) which leverages estimations by Deep Neural Networks (DNN)\nor kernel methods. Moreover, the cPI can be easily adjusted to capture the\nestimation variability within the prediction procedure, which is a crucial\nerror source often ignored in practice. Under regular assumptions, we verify\nthat our cPI has an asymptotically valid coverage rate. We also demonstrate\nthat cPI based on the kernel method ensures a coverage rate with a high\nprobability when the sample size is large. Besides, with several conditions,\nthe cPI based on DNN works even with finite samples. A comprehensive simulation\nstudy supports the usefulness of cPI, and the convincing performance of cPI\nwith a short sample is confirmed with two empirical datasets.", "published": "2025-09-02 18:30:39", "link": "http://arxiv.org/abs/2509.02735v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Probabilities of Causation and Root Cause Analysis with Quasi-Markovian Models", "abstract": "Probabilities of causation provide principled ways to assess causal\nrelationships but face computational challenges due to partial identifiability\nand latent confounding. This paper introduces both algorithmic simplifications,\nsignificantly reducing the computational complexity of calculating tighter\nbounds for these probabilities, and a novel methodological framework for Root\nCause Analysis that systematically employs these causal metrics to rank entire\ncausal paths.", "published": "2025-09-02 17:39:23", "link": "http://arxiv.org/abs/2509.02535v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Is RL fine-tuning harder than regression? A PDE learning approach for diffusion models", "abstract": "We study the problem of learning the optimal control policy for fine-tuning a\ngiven diffusion process, using general value function approximation. We develop\na new class of algorithms by solving a variational inequality problem based on\nthe Hamilton-Jacobi-Bellman (HJB) equations. We prove sharp statistical rates\nfor the learned value function and control policy, depending on the complexity\nand approximation errors of the function class. In contrast to generic\nreinforcement learning problems, our approach shows that fine-tuning can be\nachieved via supervised regression, with faster statistical rate guarantees.", "published": "2025-09-02 17:29:23", "link": "http://arxiv.org/abs/2509.02528v1", "categories": ["cs.LG", "math.OC", "math.PR", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Wild Refitting for Model-Free Excess Risk Evaluation of Opaque ML/AI Models under Bregman Loss", "abstract": "We study the problem of evaluating the excess risk of classical penalized\nempirical risk minimization (ERM) with Bregman losses. We show that by\nleveraging the recently proposed wild refitting procedure (Wainwright, 2025),\none can efficiently upper bound the excess risk through the so-called \"wild\noptimism,\" without relying on the global structure of the underlying function\nclass. This property makes our approach inherently model-free. Unlike\nconventional analyses, our framework operates with just one dataset and\nblack-box access to the training procedure. The method involves randomized\nvector-valued symmetrization with an appropriate scaling of the prediction\nresidues and constructing artificially modified outcomes, upon which we retrain\na second predictor for excess risk estimation. We establish high-probability\nperformance guarantees both under the fixed design setting and the random\ndesign setting, demonstrating that wild refitting under Bregman losses, with an\nappropriately chosen wild noise scale, yields a valid upper bound on the excess\nrisk. This work thus is promising for theoretically evaluating modern opaque ML\nand AI models such as deep neural networks and large language models, where the\nmodel class is too complex for classical learning theory and empirical process\ntechniques to apply.", "published": "2025-09-02 16:26:03", "link": "http://arxiv.org/abs/2509.02476v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Gaming and Cooperation in Federated Learning: What Can Happen and How to Monitor It", "abstract": "The success of Federated Learning depends on the actions that participants\ntake out of sight. We model Federated Learning not as a mere optimization task\nbut as a strategic system entangled with rules and incentives. From this\nperspective, we present an analytical framework that makes it possible to\nclearly identify where behaviors that genuinely improve performance diverge\nfrom those that merely target metrics. We introduce two indices that\nrespectively quantify behavioral incentives and collective performance loss,\nand we use them as the basis for consistently interpreting the impact of\noperational choices such as rule design, the level of information disclosure,\nevaluation methods, and aggregator switching. We further summarize thresholds,\nauto-switch rules, and early warning signals into a checklist that can be\napplied directly in practice, and we provide both a practical algorithm for\nallocating limited audit resources and a performance guarantee. Simulations\nconducted across diverse environments consistently validate the patterns\npredicted by our framework, and we release all procedures for full\nreproducibility. While our approach operates most strongly under several\nassumptions, combining periodic recalibration, randomization, and\nconnectivity-based alarms enables robust application under the variability of\nreal-world operations. We present both design principles and operational\nguidelines that lower the incentives for metric gaming while sustaining and\nexpanding stable cooperation.", "published": "2025-09-02 14:55:01", "link": "http://arxiv.org/abs/2509.02391v1", "categories": ["cs.LG", "cs.GT", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Distribution estimation via Flow Matching with Lipschitz guarantees", "abstract": "Flow Matching, a promising approach in generative modeling, has recently\ngained popularity. Relying on ordinary differential equations, it offers a\nsimple and flexible alternative to diffusion models, which are currently the\nstate-of-the-art. Despite its empirical success, the mathematical understanding\nof its statistical power so far is very limited. This is largely due to the\nsensitivity of theoretical bounds to the Lipschitz constant of the vector field\nwhich drives the ODE. In this work, we study the assumptions that lead to\ncontrolling this dependency. Based on these results, we derive a convergence\nrate for the Wasserstein $1$ distance between the estimated distribution and\nthe target distribution which improves previous results in high dimensional\nsetting. This rate applies to certain classes of unbounded distributions and\nparticularly does not require $\\log$-concavity.", "published": "2025-09-02 14:04:11", "link": "http://arxiv.org/abs/2509.02337v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH", "62E17, 62G07, 68T07"], "primary_category": "stat.ML"}
{"title": "Variational Uncertainty Decomposition for In-Context Learning", "abstract": "As large language models (LLMs) gain popularity in conducting prediction\ntasks in-context, understanding the sources of uncertainty in in-context\nlearning becomes essential to ensuring reliability. The recent hypothesis of\nin-context learning performing predictive Bayesian inference opens the avenue\nfor Bayesian uncertainty estimation, particularly for decomposing uncertainty\ninto epistemic uncertainty due to lack of in-context data and aleatoric\nuncertainty inherent in the in-context prediction task. However, the\ndecomposition idea remains under-explored due to the intractability of the\nlatent parameter posterior from the underlying Bayesian model. In this work, we\nintroduce a variational uncertainty decomposition framework for in-context\nlearning without explicitly sampling from the latent parameter posterior, by\noptimising auxiliary queries as probes to obtain an upper bound to the\naleatoric uncertainty of an LLM's in-context learning procedure, which also\ninduces a lower bound to the epistemic uncertainty. Through experiments on\nsynthetic and real-world tasks, we show quantitatively and qualitatively that\nthe decomposed uncertainties obtained from our method exhibit desirable\nproperties of epistemic and aleatoric uncertainty.", "published": "2025-09-02 13:53:09", "link": "http://arxiv.org/abs/2509.02327v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Calibration through the Lens of Indistinguishability", "abstract": "Calibration is a classical notion from the forecasting literature which aims\nto address the question: how should predicted probabilities be interpreted? In\na world where we only get to observe (discrete) outcomes, how should we\nevaluate a predictor that hypothesizes (continuous) probabilities over possible\noutcomes? The study of calibration has seen a surge of recent interest, given\nthe ubiquity of probabilistic predictions in machine learning. This survey\ndescribes recent work on the foundational questions of how to define and\nmeasure calibration error, and what these measures mean for downstream decision\nmakers who wish to use the predictions to make decisions. A unifying viewpoint\nthat emerges is that of calibration as a form of indistinguishability, between\nthe world hypothesized by the predictor and the real world (governed by nature\nor the Bayes optimal predictor). In this view, various calibration measures\nquantify the extent to which the two worlds can be told apart by certain\nclasses of distinguishers or statistical measures.", "published": "2025-09-02 13:01:43", "link": "http://arxiv.org/abs/2509.02279v1", "categories": ["cs.LG", "cs.GT", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Fast kernel methods: Sobolev, physics-informed, and additive models", "abstract": "Kernel methods are powerful tools in statistical learning, but their cubic\ncomplexity in the sample size n limits their use on large-scale datasets. In\nthis work, we introduce a scalable framework for kernel regression with O(n log\nn) complexity, fully leveraging GPU acceleration. The approach is based on a\nFourier representation of kernels combined with non-uniform fast Fourier\ntransforms (NUFFT), enabling exact, fast, and memory-efficient computations. We\ninstantiate our framework in three settings: Sobolev kernel regression,\nphysics-informed regression, and additive models. When known, the proposed\nestimators are shown to achieve minimax convergence rates, consistent with\nclassical kernel theory. Empirical results demonstrate that our methods can\nprocess up to tens of billions of samples within minutes, providing both\nstatistical accuracy and computational scalability. These contributions\nestablish a flexible approach, paving the way for the routine application of\nkernel methods in large-scale learning tasks.", "published": "2025-09-02 12:07:48", "link": "http://arxiv.org/abs/2509.02649v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Amputation-imputation based generation of synthetic tabular data for ratemaking", "abstract": "Actuarial ratemaking depends on high-quality data, yet access to such data is\noften limited by the cost of obtaining new data, privacy concerns, etc. In this\npaper, we explore synthetic-data generation as a potential solution to these\nissues. In addition to discussing generative methods previously studied in the\nactuarial literature, we introduce to the insurance community another approach\nbased on Multiple Imputation by Chained Equations (MICE). We present a\ncomparative study using an open-source dataset and evaluating MICE-based models\nagainst other generative models like Variational Autoencoders and Conditional\nTabular Generative Adversarial Networks. We assess how well synthetic data\npreserves the original marginal distributions of variables as well as the\nmultivariate relationships among covariates. We also investigate the\nconsistency between Generalized Linear Models (GLMs) trained on synthetic data\nwith GLMs trained on the original data. Furthermore, we assess the ease of use\nof each generative approach and study the impact of augmenting original data\nwith synthetic data on the performance of GLMs for predicting claim counts. Our\nresults highlight the potential of MICE-based methods in creating high-quality\ntabular data while being more user-friendly than the other methods.", "published": "2025-09-02 10:23:04", "link": "http://arxiv.org/abs/2509.02171v1", "categories": ["stat.ML", "cs.LG", "stat.AP", "62P05 (Primary), 68T05, 68T07 (Secondary)", "I.2.1; I.2.6"], "primary_category": "stat.ML"}
{"title": "Conditional-$t^3$VAE: Equitable Latent Space Allocation for Fair Generation", "abstract": "Variational Autoencoders (VAEs) with global priors mirror the training set's\nclass frequency in latent space, underrepresenting tail classes and reducing\ngenerative fairness on imbalanced datasets. While $t^3$VAE improves robustness\nvia heavy-tailed Student's t-distribution priors, it still allocates latent\nvolume proportionally to the class frequency.In this work, we address this\nissue by explicitly enforcing equitable latent space allocation across classes.\nTo this end, we propose Conditional-$t^3$VAE, which defines a per-class\n\\mbox{Student's t} joint prior over latent and output variables, preventing\ndominance by majority classes. Our model is optimized using a closed-form\nobjective derived from the $\\gamma$-power divergence. Moreover, for\nclass-balanced generation, we derive an equal-weight latent mixture of\nStudent's t-distributions. On SVHN-LT, CIFAR100-LT, and CelebA,\nConditional-$t^3$VAE consistently achieves lower FID scores than both $t^3$VAE\nand Gaussian-based VAE baselines, particularly under severe class imbalance. In\nper-class F1 evaluations, Conditional-$t^3$VAE also outperforms the conditional\nGaussian VAE across all highly imbalanced settings. While Gaussian-based models\nremain competitive under mild imbalance ratio ($\\rho \\lesssim 3$), our approach\nsubstantially improves generative fairness and diversity in more extreme\nregimes.", "published": "2025-09-02 10:03:10", "link": "http://arxiv.org/abs/2509.02154v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Differentiable Expectation-Maximisation and Applications to Gaussian Mixture Model Optimal Transport", "abstract": "The Expectation-Maximisation (EM) algorithm is a central tool in statistics\nand machine learning, widely used for latent-variable models such as Gaussian\nMixture Models (GMMs). Despite its ubiquity, EM is typically treated as a\nnon-differentiable black box, preventing its integration into modern learning\npipelines where end-to-end gradient propagation is essential. In this work, we\npresent and compare several differentiation strategies for EM, from full\nautomatic differentiation to approximate methods, assessing their accuracy and\ncomputational efficiency. As a key application, we leverage this differentiable\nEM in the computation of the Mixture Wasserstein distance $\\mathrm{MW}_2$\nbetween GMMs, allowing $\\mathrm{MW}_2$ to be used as a differentiable loss in\nimaging and machine learning tasks. To complement our practical use of\n$\\mathrm{MW}_2$, we contribute a novel stability result which provides\ntheoretical justification for the use of $\\mathrm{MW}_2$ with EM, and also\nintroduce a novel unbalanced variant of $\\mathrm{MW}_2$. Numerical experiments\non barycentre computation, colour and style transfer, image generation, and\ntexture synthesis illustrate the versatility and effectiveness of the proposed\napproach in different settings.", "published": "2025-09-02 09:06:01", "link": "http://arxiv.org/abs/2509.02109v1", "categories": ["cs.LG", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Inference in Spreading Processes with Neural-Network Priors", "abstract": "Stochastic processes on graphs are a powerful tool for modelling complex\ndynamical systems such as epidemics. A recent line of work focused on the\ninference problem where one aims to estimate the state of every node at every\ntime, starting from partial observation of a subset of nodes at a subset of\ntimes. In these works, the initial state of the process was assumed to be\nrandom i.i.d. over nodes. Such an assumption may not be realistic in practice,\nwhere one may have access to a set of covariate variables for every node that\ninfluence the initial state of the system. In this work, we will assume that\nthe initial state of a node is an unknown function of such covariate variables.\nGiven that functions can be represented by neural networks, we will study a\nmodel where the initial state is given by a simple neural network -- notably\nthe single-layer perceptron acting on the known node-wise covariate variables.\n  Within a Bayesian framework, we study how such neural-network prior\ninformation enhances the recovery of initial states and spreading trajectories.\nWe derive a hybrid belief propagation and approximate message passing (BP-AMP)\nalgorithm that handles both the spreading dynamics and the information included\nin the node covariates, and we assess its performance against the estimators\nthat either use only the spreading information or use only the information from\nthe covariate variables.\n  We show that in some regimes, the model can exhibit first-order phase\ntransitions when using a Rademacher distribution for the neural-network\nweights. These transitions create a statistical-to-computational gap where even\nthe BP-AMP algorithm, despite the theoretical possibility of perfect recovery,\nfails to achieve it.", "published": "2025-09-02 08:24:37", "link": "http://arxiv.org/abs/2509.02073v1", "categories": ["stat.ML", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG", "physics.soc-ph"], "primary_category": "stat.ML"}
{"title": "Fantastic Pretraining Optimizers and Where to Find Them", "abstract": "AdamW has long been the dominant optimizer in language model pretraining,\ndespite numerous claims that alternative optimizers offer 1.4 to 2x speedup. We\nposit that two methodological shortcomings have obscured fair comparisons and\nhindered practical adoption: (i) unequal hyperparameter tuning and (ii) limited\nor misleading evaluation setups. To address these two issues, we conduct a\nsystematic study of ten deep learning optimizers across four model scales\n(0.1B-1.2B parameters) and data-to-model ratios (1-8x the Chinchilla optimum).\nWe find that fair and informative comparisons require rigorous hyperparameter\ntuning and evaluations across a range of model scales and data-to-model ratios,\nperformed at the end of training. First, optimal hyperparameters for one\noptimizer may be suboptimal for another, making blind hyperparameter transfer\nunfair. Second, the actual speedup of many proposed optimizers over well-tuned\nbaselines is lower than claimed and decreases with model size to only 1.1x for\n1.2B parameter models. Thirdly, comparing intermediate checkpoints before\nreaching the target training budgets can be misleading, as rankings between two\noptimizers can flip during training due to learning rate decay. Through our\nthorough investigation, we find that all the fastest optimizers such as Muon\nand Soap, use matrices as preconditioners -- multiplying gradients with\nmatrices rather than entry-wise scalars. However, the speedup of matrix-based\noptimizers is inversely proportional to model scale, decreasing from 1.4x over\nAdamW for 0.1B parameter models to merely 1.1x for 1.2B parameter models.", "published": "2025-09-02 07:43:22", "link": "http://arxiv.org/abs/2509.02046v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Bouncy particle sampler with infinite exchanging parallel tempering", "abstract": "Bayesian inference is useful to obtain a predictive distribution with a small\ngeneralization error. However, since posterior distributions are rarely\nevaluated analytically, we employ the variational Bayesian inference or\nsampling method to approximate posterior distributions. When we obtain samples\nfrom a posterior distribution, Hamiltonian Monte Carlo (HMC) has been widely\nused for the continuous variable part and Markov chain Monte Carlo (MCMC) for\nthe discrete variable part. Another sampling method, the bouncy particle\nsampler (BPS), has been proposed, which combines uniform linear motion and\nstochastic reflection to perform sampling. BPS was reported to have the\nadvantage of being easier to set simulation parameters than HMC. To accelerate\nthe convergence to a posterior distribution, we introduced parallel tempering\n(PT) to BPS, and then proposed an algorithm when the inverse temperature\nexchange rate is set to infinity. We performed numerical simulations and\ndemonstrated its effectiveness for multimodal distribution.", "published": "2025-09-02 06:37:57", "link": "http://arxiv.org/abs/2509.02003v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Non-Linear Model-Based Sequential Decision-Making in Agriculture", "abstract": "Sequential decision-making is central to sustainable agricultural management\nand precision agriculture, where resource inputs must be optimized under\nuncertainty and over time. However, such decisions must often be made with\nlimited observations, whereas classical bandit and reinforcement learning\napproaches typically rely on either linear or black-box reward models that may\nmisrepresent domain knowledge or require large amounts of data. We propose a\nfamily of nonlinear, model-based bandit algorithms that embed domain-specific\nresponse curves directly into the exploration-exploitation loop. By coupling\n(i) principled uncertainty quantification with (ii) closed-form or rapidly\ncomputable profit optima, these algorithms achieve sublinear regret and\nnear-optimal sample complexity while preserving interpretability. Theoretical\nanalysis establishes regret and sample complexity bounds, and extensive\nsimulations emulating real-world fertilizer-rate decisions show consistent\nimprovements over both linear and nonparametric baselines (such as linear UCB\nand $k$-NN UCB) in the low-sample regime, under both well-specified and\nshape-compatible misspecified models. Because our approach leverages\nmechanistic insight rather than large data volumes, it is especially suited to\nresource-constrained settings, supporting sustainable, inclusive, and\ntransparent sequential decision-making across agriculture, environmental\nmanagement, and allied applications. This methodology directly contributes to\nSDG 2 (Zero Hunger) and SDG 12 (Responsible Consumption and Production) by\nenabling data-driven, less wasteful agricultural practices.", "published": "2025-09-02 03:41:48", "link": "http://arxiv.org/abs/2509.01924v1", "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.ME", "62P12, 91B06"], "primary_category": "stat.ML"}
{"title": "Design of Experiment for Discovering Directed Mixed Graph", "abstract": "We study the problem of experimental design for accurately identifying the\ncausal graph structure of a simple structural causal model (SCM), where the\nunderlying graph may include both cycles and bidirected edges induced by latent\nconfounders. The presence of cycles renders it impossible to recover the graph\nskeleton using observational data alone, while confounding can further\ninvalidate traditional conditional independence (CI) tests in certain\nscenarios. To address these challenges, we establish lower bounds on both the\nmaximum number of variables that can be intervened upon in a single experiment\nand the total number of experiments required to identify all directed edges and\nnon-adjacent bidirected edges. Leveraging both CI tests and do see tests, and\naccounting for $d$ separation and $\\sigma$ separation, we develop two classes\nof algorithms, i.e., bounded and unbounded, that can recover all causal edges\nexcept for double adjacent bidirected edges. We further show that, up to\nlogarithmic factors, the proposed algorithms are tight with respect to the\nderived lower bounds.", "published": "2025-09-02 02:24:55", "link": "http://arxiv.org/abs/2509.01887v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Analysis of Speaker Verification Performance Trade-offs with Neural Audio Codec Transmission", "abstract": "Neural audio codecs (NACs) have made significant advancements in recent years\nand are rapidly being adopted in many audio processing pipelines. However, they\ncan introduce audio distortions which degrade speaker verification (SV)\nperformance. This study investigates the impact of both traditional and neural\naudio codecs at varying bitrates on three state of-the-art SV models evaluated\non the VoxCeleb1 dataset. Our findings reveal a consistent degradation in SV\nperformance across all models and codecs as bitrates decrease. Notably, NACs do\nnot fundamentally break SV performance when compared to traditional codecs.\nThey outperform Opus by 6-8% at low-bitrates (< 12 kbps) and remain marginally\nbehind at higher bitrates ($\\approx$ 24 kbps), with an EER increase of only\n0.4-0.7%. The disparity at higher bitrates is likely due to the primary\noptimization of NACs for perceptual quality, which can inadvertently discard\ncritical speaker-discriminative features, unlike Opus which was designed to\npreserve vocal characteristics. Our investigation suggests that NACs are a\nfeasible alternative to traditional codecs, especially under bandwidth\nlimitations. To bridge the gap at higher bitrates, future work should focus on\ndeveloping speaker-aware NACs or retraining and adapting SV models.", "published": "2025-09-02 19:20:06", "link": "http://arxiv.org/abs/2509.02771v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "TTA-Bench: A Comprehensive Benchmark for Evaluating Text-to-Audio Models", "abstract": "Text-to-Audio (TTA) generation has made rapid progress, but current\nevaluation methods remain narrow, focusing mainly on perceptual quality while\noverlooking robustness, generalization, and ethical concerns. We present\nTTA-Bench, a comprehensive benchmark for evaluating TTA models across\nfunctional performance, reliability, and social responsibility. It covers seven\ndimensions including accuracy, robustness, fairness, and toxicity, and includes\n2,999 diverse prompts generated through automated and manual methods. We\nintroduce a unified evaluation protocol that combines objective metrics with\nover 118,000 human annotations from both experts and general users. Ten\nstate-of-the-art models are benchmarked under this framework, offering detailed\ninsights into their strengths and limitations. TTA-Bench establishes a new\nstandard for holistic and responsible evaluation of TTA systems. The dataset\nand evaluation tools are open-sourced at https://nku-hlt.github.io/tta-bench/.", "published": "2025-09-02 15:10:09", "link": "http://arxiv.org/abs/2509.02398v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FireRedTTS-2: Towards Long Conversational Speech Generation for Podcast and Chatbot", "abstract": "Current dialogue generation approaches typically require the complete\ndialogue text before synthesis and produce a single, inseparable speech\ncontaining all voices, making them unsuitable for interactive chat; moreover,\nthey suffer from unstable synthesis, inaccurate speaker transitions, and\nincoherent prosody. In this work, we present FireRedTTS-2, a long-form\nstreaming TTS system for multi-speaker dialogue generation, delivering stable,\nnatural speech with reliable speaker switching and context-aware prosody. A new\n12.5Hz streaming speech tokenizer accelerates training and inference, extends\nmaximum dialogue length, encodes richer semantics to stabilize text-to-token\nmodeling and supports high-fidelity streaming generation for real-time\napplications. We adopt a text-speech interleaved format, concatenating\nspeaker-labeled text with aligned speech tokens in chronological order, and\nmodel it with a dual-transformer: a large decoder-only transformer predicts\ntokens at the first layer, and a smaller one completes subsequent layers.\nExperimental results show that FireRedTTS-2 integrates seamlessly with chat\nframeworks and, with minimal fine-tuning, produces emotionally expressive\nspeech guided by implicit contextual cues. In podcast generation, it surpasses\nexisting systems including MoonCast, Zipvoice-Dialogue, and MOSS-TTSD in\nobjective intelligibility, speaker-turn reliability, and perceived naturalness\nwith context-consistent prosody. Our demos are available at\nhttps://fireredteam.github.io/demos/firered_tts_2.", "published": "2025-09-02 07:06:46", "link": "http://arxiv.org/abs/2509.02020v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Group Relative Policy Optimization for Speech Recognition", "abstract": "Speech Recognition has seen a dramatic shift towards adopting Large Language\nModels (LLMs). This shift is partly driven by good scalability properties\ndemonstrated by LLMs, ability to leverage large amounts of labelled, unlabelled\nspeech and text data, streaming capabilities with auto-regressive framework and\nmulti-tasking with instruction following characteristics of LLMs. However,\nsimple next-token prediction objective, typically employed with LLMs, have\ncertain limitations in performance and challenges with hallucinations. In this\npaper, we propose application of Group Relative Policy Optimization (GRPO) to\nenable reinforcement learning from human feedback for automatic speech\nrecognition (ASR). We design simple rule based reward functions to guide the\npolicy updates. We demonstrate significant improvements in word error rate\n(upto 18.4% relative), reduction in hallucinations, increased robustness on\nout-of-domain datasets and effectiveness in domain adaptation.", "published": "2025-09-02 04:20:12", "link": "http://arxiv.org/abs/2509.01939v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Binaural Unmasking in Practical Use: Perceived Level of Phase-inverted Speech in Environmental Noise", "abstract": "We aim to develop a technology that makes the sound from earphones and\nheadphones easier to hear without increasing the sound pressure or eliminating\nambient noise. To this end, we focus on harnessing the phenomenon of binaural\nunmasking through phase reversal in one ear. Specifically, we conduct\nexperiments to evaluate the improvement of audibility caused by the phenomenon,\nusing conditions that approximate practical scenarios. We use speech sounds by\nvarious speakers, including women, and noises that can be encountered in daily\nlife (urban environmental sounds, cheers) to verify the effects of binaural\nunmasking under conditions close to practical situations. The results of\nexperiments using the Japanese language showed that (i) speech in a noisy\nenvironment is perceived to be up to about 6 dB louder with phase reversal in\none ear, and (ii) a certain effect (improvement of audibility by 5 dB or more)\nis obtained for all speakers and noises targeted in this study. These findings\ndemonstrate the effectiveness of binaural unmasking attributed to interaural\nphase differences in practical scenarios.", "published": "2025-09-02 03:53:06", "link": "http://arxiv.org/abs/2509.01929v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Multilingual Speech Recognition Using Discrete Tokens with a Two-step Training Strategy", "abstract": "Pre-trained models, especially self-supervised learning (SSL) models, have\ndemonstrated impressive results in automatic speech recognition (ASR) task.\nWhile most applications of SSL models focus on leveraging continuous\nrepresentations as features for training downstream tasks, the utilization of\ndiscrete units has gained increasing attention in recent years owing to its\nlower storage requirements and broader range of applications. In multilingual\nASR tasks, representations at different layers of the model contribute\ndifferently to various languages, complicating the unification of discrete unit\nmodeling. In this paper, we propose a two-stage training strategy to improve\nthe discrete token performance of pre-trained models and narrow the gap with\ncontinuous representation performance. We validate our method on the XLS-R\nmodel following the settings of Interspeech2024 Speech Processing Using\nDiscrete Speech Unit Challenge. Our method demonstrates a significant\nimprovement on the ML-SUPERB dataset, achieving a 44% relative reduction on CER\nfor the XLS-R model. This surpasses the previous baseline set by the WavLM\nmodel, which achieves a 26% relative reduction on CER. Furthermore, our method\nachieves the first place among all the single-system results on the\nleaderboard.", "published": "2025-09-02 02:43:11", "link": "http://arxiv.org/abs/2509.01900v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "From Evaluation to Optimization: Neural Speech Assessment for Downstream Applications", "abstract": "The evaluation of synthetic and processed speech has long been a cornerstone\nof audio engineering and speech science. Although subjective listening tests\nremain the gold standard for assessing perceptual quality and intelligibility,\ntheir high cost, time requirements, and limited scalability present significant\nchallenges in the rapid development cycles of modern speech technologies.\nTraditional objective metrics, while computationally efficient, often exhibit\nweak correlation with human perception, creating a perceptual gap between\nsystem optimization and actual user experience. Bridging this gap requires\nspeech assessment models that are more closely aligned with human perception.\nIn recent years, numerous neural network-based speech assessment models have\nbeen developed to predict quality and intelligibility, achieving promising\nresults. Beyond their role in evaluation, these models are increasingly\nintegrated into downstream speech processing tasks. This review focuses on\ntheir role in two main areas: (1) serving as differentiable perceptual proxies\nthat not only assess but also guide the optimization of speech enhancement and\nsynthesis models; and (2) enabling the detection of salient speech\ncharacteristics to support more precise and efficient downstream processing.\nFinally, we discuss current limitations and outline future research directions\nto further advance the integration of speech assessment into speech processing\npipelines.", "published": "2025-09-02 02:26:38", "link": "http://arxiv.org/abs/2509.01889v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Protecting Legacy Wireless Systems Against Interference: Precoding and Codebook Approaches Using Massive MIMO and Region Constraints", "abstract": "The ever-increasing demand for high-speed wireless communication has\ngenerated significant interest in utilizing frequency bands that are adjacent\nto those occupied by legacy wireless systems. Since the legacy wireless systems\nwere designed based on often decades-old assumptions about wireless\ninterference, utilizing these new bands will result in interference with the\nexisting legacy users. Many of these legacy wireless devices are used by\ncritical infrastructure networks upon which society depends. There is an urgent\nneed to develop schemes that can protect legacy users from such interference.\nFor many applications, legacy users are located within\ngeographically-constrained regions. Several studies have proposed mitigating\ninterference through the implementation of exclusion zones near these\ngeographically-constrained regions. In contrast to solutions based on\ngeographic exclusion zones, this paper presents a communication theory-based\nsolution. By leveraging knowledge of these geographically-constrained regions,\nwe aim to reduce the interference impact on legacy users. We achieve this by\nincorporating received power constraints, termed as region constraints, in our\nmassive multiple-input multiple-output (MIMO) system design. We perform a\ncapacity analysis of single-user massive MIMO and a sum-rate analysis of the\nmulti-user massive MIMO system with transmit power and region constraints. We\npresent a precoding design method that allows for the utilization of new\nfrequency bands while protecting legacy users.", "published": "2025-09-02 20:37:42", "link": "http://arxiv.org/abs/2509.02819v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "LLM-Enhanced Space-Air-Ground-Sea Integrated Networks", "abstract": "The space-air-ground-sea integrated networking (SAGSIN) concept promises\nseamless global multimedia connectivity, yet two obstacles still limit its\npractical deployment. Firstly, high-velocity satellites, aerial relays and\nsea-surface platforms suffer from obsolete channel state information (CSI),\nundermining feedback-based adaptation. Secondly, data-rate disparity across the\nprotocol stack is extreme: terabit optical links in space coexist with kilobit\nacoustic under-water links. This article shows that a single large language\nmodel (LLM) backbone, trained jointly on radio, optical and acoustic traces,\ncan provide a unified, data-driven adaptation layer that addresses both rapid\nCSI ageing and severe bandwidth disparity across the SAGSIN protocol stack.\nExplicitly, an LLM-based long-range channel predictor forecasts the strongest\ndelay-Doppler components several coherence intervals ahead, facilitating\nnear-capacity reception despite violent channel fluctuations. Furthermore, our\nLLM-based semantic encoder turns raw sensor payloads into task-oriented tokens.\nThis substantially reduces the SNR required for high-fidelity image delivery in\na coastal underwater link, circumventing the data rate limitation by semantic\ncommunications. Inclusion of these tools creates a medium-agnostic adaptation\nlayer that spans radio, optical and acoustic channels. We conclude with\npromising open research directions in on-device model compression, multimodal\nfidelity control, cross-layer resource orchestration and trustworthy operation,\ncharting a path from laboratory prototypes to field deployment.", "published": "2025-09-02 17:43:16", "link": "http://arxiv.org/abs/2509.02540v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Know What, Know Why: Semantic Hazard Communication for Intelligent V2X Systems", "abstract": "In current vehicle-to-everything (V2X) communication systems, roadside units\n(RSUs) broadcast brief warning messages that alert nearby vehicles to avoid\npotential hazards. However, these messages lack contextual information on why a\nwarning is issued, leading to excessive caution or inefficient driving\nbehaviors. To avoid such a situation, we propose a semantic-enhanced and\nexplainable V2X (SEE-V2X) system. In the proposed system, RSUs equipped with\nsmart cameras detect obstructions and transmit context-aware messages to\nvehicles. By understanding both what the hazard is and why it occurs, drivers\ncan make more intelligent decisions based on their specific driving situation.\nFurthermore, through a real-field demonstration, we show the new \"see-through\"\nfeature in the proposed system, which enables drivers to visualize hidden\npedestrians behind obstacles. We also perform simulations to compare\ntraditional V2X with SEE-V2X under different traffic conditions. The results\nshow that SEE-V2X significantly improves traffic efficiency and reduces\nunnecessary deceleration.", "published": "2025-09-02 15:46:47", "link": "http://arxiv.org/abs/2509.02442v1", "categories": ["eess.SP", "cs.HC"], "primary_category": "eess.SP"}
{"title": "Frequency-Domain Characterization of Load Demand from Electrified Highways", "abstract": "Electrified roadways (ER) equipped with dynamic wireless power transfer\n(DWPT) capabilities can patently extend the driving range and reduce the\nbattery size of electric vehicles (EVs). However, due to the spatial\narrangement of the transmitter coils in the ER, the DWPT load exhibits\nfrequency content that could excite power system frequency dynamics. In this\ncontext, this work aims to study the spectrum of DWPT loads under different\ntraffic conditions. We develop statistical models for EVs moving at constant\nspeeds to identify the location and magnitude of DWPT load harmonics. Our\nanalysis reveals that the fundamental frequency is dependent on the ER coil\nspacing and the average EV speed. In the worst-case yet unlikely scenario that\nEVs move in a synchronized fashion, the amplitude of harmonics scales with the\nnumber of EVs. On the contrary, when EVs move freely, harmonics scale with the\nsquare root of the number of EVs. Platoon formations can accentuate harmonics.\nWe also show that for higher-order harmonics, the spectral content around\nharmonics decreases in magnitude and increases in bandwidth. Despite the\nsimplified models, our analysis offers valuable insights for ER planners and\ngrid operators. Numerical tests using a traffic simulator corroborate some of\nthese insights.", "published": "2025-09-02 15:27:19", "link": "http://arxiv.org/abs/2509.02426v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Interference Management for Integrated Sensing and Communications: A Multiple Access Perspective", "abstract": "The integrated sensing and communication (ISAC) technique has been considered\na key enabler for 6G radio access networks. ISAC fulfills a brand new paradigm\nshift in wireless networks via the seamless interplay between communication and\nsensing within a unified network. However, the tight integration of these\nfunctionalities inevitably gives rise to various types of interference, posing\nsignificant challenges to existing ISAC waveform designs and rendering\ninterference management a critical concern. Inspired by the development\ntrajectory of wireless communications, different multiple access (MA)\ntechniques, such as orthogonal multiple access (OMA), space-division multiple\naccess (SDMA), and more recently, non-orthogonal multiple access (NOMA) and\nrate-splitting multiple access (RSMA), have been demonstrated to play a pivotal\nrole in efficiently utilizing limited spectrum resources, designing ISAC\nwaveforms, as well as managing inter-user interference and inter-functionality\ninterference in ISAC. Notably, the interplay between MA and ISAC presents\nmutually beneficial integration. On the one hand, ISAC helps MA techniques\nbetter exploit their interference management capability beyond the\ncommunication-only networks. On the other hand, different MA techniques serve\nas promising solutions for inter-functionality and inter-user interference\nmanagement in ISAC. In this paper, we deliver the first comprehensive tutorial\nof MA techniques in ISAC networks. Specifically, we illustrate the fundamental\nprinciples of ISAC, classify the diverse types of interference in different\nISAC systems, and compare MA-assisted ISAC designs, highlighting their\nrespective advantages and limitations. Moreover, we provide an outlook on the\nemerging applications and future research directions of different MA-assisted\nISAC.", "published": "2025-09-02 14:18:02", "link": "http://arxiv.org/abs/2509.02352v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Dual-end Fluid Antennas For Robust Anti-jamming in Low-altitude Air-ground Communications", "abstract": "This paper addresses the challenge of co-channel interference and intentional\njamming in low-altitude air-ground communications. Since conventional\nfixed-position antenna (FPA) systems lack spatial adaptability to dynamically\nbalance signal enhancement against interference suppression, we propose a\ntransformative fluid antenna system (FAS)-assisted heterogeneous dual-layer\ntransmission architecture. Specifically, a terrestrial base station with FPA\nserves ground users, while a low altitude-serving base station equipped with\nFAS communicates with the aerial user, also equipped with FAS, under the attack\nof a malicious jammer. We formulate a worst-case achievable rate maximization\nproblem for aerial user subject to constraints including quality-of-service for\nterrestrial users, imperfect jamming directions, minimum antenna separation,\netc. To address the non-convex problem, we propose a fractional\nprogramming-block coordinate descent algorithm that alternately optimizes the\ntransmit precoders, receive combiner, and antenna positions at both transceiver\nsides. Convex hull-based approach and geometric boundary method are used to\nhandle the jamming uncertainty and antenna placement constraints in confined\nspatial regions, respectively. Extensive simulations validate significant\nperformance gains. The FAS achieves up to 56\\% higher data rates than FPA under\nequivalent power constraints. Strategic antenna repositioning demonstrably\nenhances signal quality while suppressing interference, maintaining robustness\nacross diverse jammer channel uncertainties.", "published": "2025-09-02 12:34:40", "link": "http://arxiv.org/abs/2509.02260v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Green Traffic Engineering for Satellite Networks Using Segment Routing Flexible Algorithm", "abstract": "Large-scale low-Earth-orbit (LEO) constellations demand routing that\nsimultaneously minimizes energy, guarantees delivery under congestion, and\nmeets latency requirements for time-critical flows. We present a segment\nrouting over IPv6 (SRv6) flexible algorithm (Flex-Algo) framework that consists\nof three logical slices: an energy-efficient slice (Algo 130), a\nhigh-reliability slice (Algo 129), and a latency-sensitive slice (Algo 128).\nThe framework provides a unified mixed-integer linear program (MILP) that\ncombines satellite CPU power, packet delivery rate (PDR), and end-to-end\nlatency into a single objective, allowing a lightweight software-defined\nnetwork (SDN) controller to steer traffic from the source node. Emulation of\nTelesat's Lightspeed constellation shows that, compared with different routing\nschemes, the proposed design reduces the average CPU usage by 73%, maintains a\nPDR above 91% during traffic bursts, and decreases urgent flow delay by 18 ms\nbetween Ottawa and Vancouver. The results confirm Flex-Algo's value as a\nslice-based traffic engineering (TE) tool for resource-constrained satellite\nnetworks.", "published": "2025-09-02 09:53:46", "link": "http://arxiv.org/abs/2509.02149v1", "categories": ["cs.NI", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "cs.NI"}
{"title": "High-Resolution Sensing in Communication-Centric ISAC: Deep Learning and Parametric Methods", "abstract": "This paper introduces two novel algorithms designed to address the challenge\nof super-resolution sensing parameter estimation in bistatic configurations\nwithin communication-centric integrated sensing and communication (ISAC)\nsystems. Our approach leverages the estimated channel state information derived\nfrom reference symbols originally intended for communication to achieve\nsuper-resolution sensing parameter estimation. The first algorithm, IFFT-C2VNN,\nemploys complex-valued convolutional neural networks to estimate the parameters\nof different targets, achieving significant reductions in computational\ncomplexity compared to traditional methods. The second algorithm, PARAMING,\nutilizes a parametric method that capitalizes on the knowledge of the system\nmodel, including the transmit and receive array geometries, to extract the\nsensing parameters accurately. Through a comprehensive performance analysis, we\ndemonstrate the effectiveness and robustness of both algorithms across a range\nof signal-to-noise ratios, underscoring their applicability in realistic ISAC\nscenarios.", "published": "2025-09-02 09:41:01", "link": "http://arxiv.org/abs/2509.02137v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Affine-Doppler Division Multiplexing for High-Mobility Wireless Communications Systems", "abstract": "Affine Frequency Division Multiplexing (AFDM) has been regarded as a\ncandidate integrated sensing and communications (ISAC) waveform owing to its\nsuperior communication performance, outperforming the Orthogonal Time-Frequency\nSpace (OTFS) that has been researched for a longer time. However, since the\nabove two waveforms are incompatible with each other, the state-of-the-art\nmethods well-designed for OTFS may not be directly applicable to AFDM. This\npaper introduces a new orthogonal multicarrier waveform, namely Affine-Doppler\nDivision Multiplexing (ADDM), which can provide a generic framework and subsume\nthe existing OTFS and AFDM as a particular case. ADDM modulating information\nsymbols in the Affine-Doppler (A-D) domain based on a two-dimensional (2D)\ntransform can enjoy both excellent unambiguous Doppler and Doppler resolution,\nwhich is the same as AFDM but outperforms OTFS. Moreover, benefiting from the\n2D transform, the symbols block of ADDM in the A-D domain undergoes a 2D cyclic\nshift produced by the delay and the Doppler of the channel, similar to the 2D\ncyclic shift in the delay-Doppler domain of cyclic prefix (CP)-OTFS. This\noffers a potential to directly apply the state-of-the-art methods well-designed\nfor OTFS and AFDM to ADDM. Numerical results show that ADDM achieves comparable\nBER performance with AFDM but outperforms OTFS in high-mobility scenarios.", "published": "2025-09-02 09:11:35", "link": "http://arxiv.org/abs/2509.02116v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Environment-Aware Channel Measurement and Modeling for Terahertz Monostatic Sensing", "abstract": "Integrated sensing and communication (ISAC) at terahertz (THz) frequencies\nholds significant promise for unifying ultra-high-speed wireless connectivity\nwith fine-grained environmental awareness. Realistic and interpretable channel\nmodeling is essential to fully realize the potential of such systems. This work\npresents a comprehensive investigation of monostatic sensing channels at\n300~GHz, based on an extensive measurement campaign conducted at 57 co-located\ntransceiver (TRx) positions across three representative indoor scenarios.\nMultipath component (MPC) parameters, including amplitude, delay, and angle,\nare extracted using a high-resolution space-alternating generalized\nexpectation-maximization (SAGE) algorithm. To cluster the extracted MPCs, an\nimage-processing-based clustering method, i.e., connected component labeling\n(CCL), is applied to group MPCs based on delay-angle consistency. Based on the\nmeasurement data, an environment-aware channel modeling framework is proposed\nto establish mappings between physical scenario attributes (e.g., reflector\ngeometry, surface materials, and roughness) and their corresponding\nchannel-domain manifestations. The framework incorporates both specular and\ndiffuse reflections and leverages several channel parameters, e.g., reflection\nloss, Lambertian scattering, and intra-cluster dispersion models, to\ncharacterize reflection behavior. Experimental results demonstrate that the\nproposed approach can reliably extract physical characteristics, e.g.,\nstructural and material information, from the observed channel characteristics,\noffering a promising foundation for advanced THz ISAC channel modeling.", "published": "2025-09-02 08:38:42", "link": "http://arxiv.org/abs/2509.02088v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Synesthesia of Machines (SoM)-Based Task-Driven MIMO System for Image Transmission", "abstract": "To support cooperative perception (CP) of networked mobile agents in dynamic\nscenarios, the efficient and robust transmission of sensory data is a critical\nchallenge. Deep learning-based joint source-channel coding (JSCC) has\ndemonstrated promising results for image transmission under adverse channel\nconditions, outperforming traditional rule-based codecs. While recent works\nhave explored to combine JSCC with the widely adopted multiple-input\nmultiple-output (MIMO) technology, these approaches are still limited to the\ndiscrete-time analog transmission (DTAT) model and simple tasks. Given the\nlimited performance of existing MIMO JSCC schemes in supporting complex CP\ntasks for networked mobile agents with digital MIMO communication systems, this\npaper presents a Synesthesia of Machines (SoM)-based task-driven MIMO system\nfor image transmission, referred to as SoM-MIMO. By leveraging the structural\nproperties of the feature pyramid for perceptual tasks and the channel\nproperties of the closed-loop MIMO communication system, SoM-MIMO enables\nefficient and robust digital MIMO transmission of images. Experimental results\nhave shown that compared with two JSCC baseline schemes, our approach achieves\naverage mAP improvements of 6.30 and 10.48 across all SNR levels, while\nmaintaining identical communication overhead.", "published": "2025-09-02 07:19:02", "link": "http://arxiv.org/abs/2509.02031v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "Correlation Analysis Between MF R-Mode Temporal ASF and Meteorological Factors", "abstract": "As the vulnerabilities of global navigation satellite systems (GNSS) have\nbecome more widely recognized, the need for complementary navigation systems\nhas grown. Medium frequency ranging mode (MF R-Mode) has gained attention as an\neffective backup system during GNSS outages, owing to its strong signal\nstrength and cost-effective scalability. However, to achieve accurate\npositioning, MF R-Mode requires correction for the additional secondary factor\n(ASF), a propagation delay affected by terrain. The temporal variation of ASF,\nknown as temporal ASF, is typically corrected using reference stations;\nhowever, the effectiveness of this method decreases with distance from the\nreference station. In this study, we analyzed the correlation between temporal\nASF and meteorological factors to evaluate the feasibility of predicting\ntemporal ASF based on meteorological factors. Among these factors, temperature\nand humidity showed significant correlations with temporal ASF, suggesting\ntheir potential utility in ASF correction.", "published": "2025-09-02 05:01:24", "link": "http://arxiv.org/abs/2509.01958v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On Performance of IoT Networks with Coordinated NOMA Transmission: Covert Monitoring and Information Decoding", "abstract": "This work investigates the covertness and security performance of\nInternet-of-Things (IoTs) networks under Rayleigh fading environments.\nSpecifically, a cellular source transmits covert information to cell-edge users\nwith the assistance of an IoT master node, employing a coordinated direct and\nrelay transmission strategy combined with non-orthogonal multiple access\n(NOMA). This approach not only enhances spectrum utilization but also generates\nfriendly interference to complicate a warden's surveillance or an\neavesdropper's decoding efforts. From a covertness perspective, we derive exact\nclosed-form expressions for the detection error probability (DEP) under\narbitrary judgment thresholds. We then identify the optimal judgment threshold\nfor the worst-case scenario, at which the warden minimizes its DEP performance.\nAccordingly, we determine the effective region for user power allocation (PA)\nin NOMA transmission that satisfies the DEP constraint. From a security\nperspective, we derive analytical expressions for the secrecy outage\nprobability under two eavesdropping strategies using selection combining and\nmaximal ratio combining. Based on this analysis, we propose an adaptive PA\nscheme that maximizes covert rate while ensuring the quality-of-service (QoS)\nrequirements of legitimate users, the system's minimum covertness requirements,\nand supporting successive interference cancellation (SIC) procedures.\nFurthermore, we design an adaptive PA scheme that maximizes the secrecy rate\nwhile ensuring the QoS requirements of legitimate users and SIC conditions.\nNumerical results demonstrate the accuracy of the analytical framework, while\nthe proposed optimization strategies effectively adjust PA coefficients to\nmaximize either the covert rate or the secrecy rate.", "published": "2025-09-02 04:08:27", "link": "http://arxiv.org/abs/2509.01935v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "ECG-Based Stress Prediction with Power Spectral Density Features and Classification Models", "abstract": "Stress has emerged as a critical global health issue, contributing to\ncardiovascular disorders, depression, and several other long-term illnesses.\nConsequently, accurate and reliable stress monitoring systems are of growing\nimportance. In this work, we propose a stress prediction framework based on\nelectrocardiogram (ECG) signals recorded during multiple daily activities such\nas sitting, walking, and jogging. Frequency-domain indicators of autonomic\nnervous system activity were obtained through Power Spectral Density (PSD)\nanalysis and utilized as input for machine learning models including Decision\nTree, Random Forest, XGBoost, LightGBM, and CatBoost. In addition, deep\nlearning approaches, namely Convolutional Neural Networks (CNN) and Long\nShort-Term Memory (LSTM) networks, were directly applied to the raw ECG\nsignals. Our experiments highlight the effectiveness of ensemble-based\nclassifiers, with CatBoost achieving 90% accuracy. Moreover, the LSTM model\nprovided superior results, attaining 94% accuracy with balanced precision,\nrecall, and F1-score, reflecting its strength in modeling temporal dependencies\nin ECG data. Overall, the findings suggest that integrating frequency-domain\nfeature extraction with advanced learning algorithms enhances stress prediction\nand paves the way for real-time healthcare monitoring solutions.", "published": "2025-09-02 03:40:01", "link": "http://arxiv.org/abs/2509.01923v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Efficient River Water Level Sensing Using Cellular CSI and Joint Space-Time Processing", "abstract": "Accurate and timely water level monitoring is critical for flood prevention,\nenvironmental management, and emerging smart infrastructure systems.\nTraditional water sensing methods often rely on dedicated sensors, which can be\ncostly to deploy and difficult to maintain and are vulnerable to damage during\nfloods.In this work, we propose a novel cellular signalbased sensing scheme\nthat passively estimates water level changes using downlink mobile signals from\nexisting communication infrastructure. By capturing subtle variations in\nchannel state information (CSI), the proposed method estimates the length\nchanges of the water-reflected signal path, which correspond to water level\nvariations. A space-time processing framework is developed to jointly estimate\nthe angle of arrival and Doppler shift, enabling isolation and enhancement of\nthe water-reflected path via beamforming, while effectively suppressing\nenvironmental noise. The phase evolution of the beamformed signal is then\nextracted to infer water level changes. To address clock asynchronism between\nthe transmitter and receiver inherent in bistatic systems, we introduce a\nbeamforming-based compensation technique for removing time-varying random phase\noffsets in CSI. Field experiments conducted across a river demonstrate that the\nproposed method enables accurate and reliable water level estimation, achieving\na mean accuracy ranging from 1.5 cm to 3.05 cm across different receiver\nconfigurations and deployments.", "published": "2025-09-02 02:55:49", "link": "http://arxiv.org/abs/2509.01905v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Understanding Space Is Rocket Science -- Only Top Reasoning Models Can Solve Spatial Understanding Tasks", "abstract": "We propose RocketScience, an open-source contrastive VLM benchmark that tests\nfor spatial relation understanding. It is comprised of entirely new real-world\nimage-text pairs covering mostly relative spatial understanding and the order\nof objects. The benchmark is designed to be very easy for humans and hard for\nthe current generation of VLMs, and this is empirically verified. Our results\nshow a striking lack of spatial relation understanding in open source and\nfrontier commercial VLMs and a surprisingly high performance of reasoning\nmodels. Additionally, we perform a disentanglement analysis to separate the\ncontributions of object localization and spatial reasoning in\nchain-of-thought-based models and find that the performance on the benchmark is\nbottlenecked by spatial reasoning and not object localization capabilities. We\nrelease the dataset with a CC-BY-4.0 license and make the evaluation code\navailable at: https://github.com/nilshoehing/rocketscience", "published": "2025-09-02 10:32:58", "link": "http://arxiv.org/abs/2509.02175v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach", "abstract": "In the domain of security, vulnerabilities frequently remain undetected even\nafter their exploitation. In this work, vulnerabilities refer to publicly\ndisclosed flaws documented in Common Vulnerabilities and Exposures (CVE)\nreports. Establishing a connection between attacks and vulnerabilities is\nessential for enabling timely incident response, as it provides defenders with\nimmediate, actionable insights. However, manually mapping attacks to CVEs is\ninfeasible, thereby motivating the need for automation. This paper evaluates 14\nstate-of-the-art (SOTA) sentence transformers for automatically identifying\nvulnerabilities from textual descriptions of attacks. Our results demonstrate\nthat the multi-qa-mpnet-base-dot-v1 (MMPNet) model achieves superior\nclassification performance when using attack Technique descriptions, with an\nF1-score of 89.0, precision of 84.0, and recall of 94.7. Furthermore, it was\nobserved that, on average, 56% of the vulnerabilities identified by the MMPNet\nmodel are also represented within the CVE repository in conjunction with an\nattack, while 61% of the vulnerabilities detected by the model correspond to\nthose cataloged in the CVE repository. A manual inspection of the results\nrevealed the existence of 275 predicted links that were not documented in the\nMITRE repositories. Consequently, the automation of linking attack techniques\nto vulnerabilities not only enhances the detection and response capabilities\nrelated to software security incidents but also diminishes the duration during\nwhich vulnerabilities remain exploitable, thereby contributing to the\ndevelopment of more secure systems.", "published": "2025-09-02 08:27:36", "link": "http://arxiv.org/abs/2509.02077v2", "categories": ["cs.CR", "cs.CL", "cs.LG", "68T50 Natural language processing", "D.4.6; I.2.7"], "primary_category": "cs.CR"}
{"title": "NADI 2025: The First Multidialectal Arabic Speech Processing Shared Task", "abstract": "We present the findings of the sixth Nuanced Arabic Dialect Identification\n(NADI 2025) Shared Task, which focused on Arabic speech dialect processing\nacross three subtasks: spoken dialect identification (Subtask 1), speech\nrecognition (Subtask 2), and diacritic restoration for spoken dialects (Subtask\n3). A total of 44 teams registered, and during the testing phase, 100 valid\nsubmissions were received from eight unique teams. The distribution was as\nfollows: 34 submissions for Subtask 1 \"five teams{\\ae}, 47 submissions for\nSubtask 2 \"six teams\", and 19 submissions for Subtask 3 \"two teams\". The\nbest-performing systems achieved 79.8% accuracy on Subtask 1, 35.68/12.20\nWER/CER (overall average) on Subtask 2, and 55/13 WER/CER on Subtask 3. These\nresults highlight the ongoing challenges of Arabic dialect speech processing,\nparticularly in dialect identification, recognition, and diacritic restoration.\nWe also summarize the methods adopted by participating teams and briefly\noutline directions for future editions of NADI.", "published": "2025-09-02 07:28:51", "link": "http://arxiv.org/abs/2509.02038v2", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "EigenBench: A Comparative Behavioral Measure of Value Alignment", "abstract": "Aligning AI with human values is a pressing unsolved problem. To address the\nlack of quantitative metrics for value alignment, we propose EigenBench: a\nblack-box method for comparatively benchmarking language models' values. Given\nan ensemble of models, a constitution describing a value system, and a dataset\nof scenarios, our method returns a vector of scores quantifying each model's\nalignment to the given constitution. To produce these scores, each model judges\nthe outputs of other models across many scenarios, and these judgments are\naggregated with EigenTrust (Kamvar et al, 2003), yielding scores that reflect a\nweighted-average judgment of the whole ensemble. EigenBench uses no ground\ntruth labels, as it is designed to quantify traits for which reasonable judges\nmay disagree on the correct label. Using prompted personas, we test whether\nEigenBench scores are more sensitive to the model or the prompt: we find that\nmost of the variance is explained by the prompt, but a small residual\nquantifies the disposition of the model itself.", "published": "2025-09-02 04:14:26", "link": "http://arxiv.org/abs/2509.01938v2", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models", "abstract": "Large language models (LLMs) typically deploy safety mechanisms to prevent\nharmful content generation. Most current approaches focus narrowly on risks\nposed by malicious actors, often framing risks as adversarial events and\nrelying on defensive refusals. However, in real-world settings, risks also come\nfrom non-malicious users seeking help while under psychological distress (e.g.,\nself-harm intentions). In such cases, the model's response can strongly\ninfluence the user's next actions. Simple refusals may lead them to repeat,\nescalate, or move to unsafe platforms, creating worse outcomes. We introduce\nConstructive Safety Alignment (CSA), a human-centric paradigm that protects\nagainst malicious misuse while actively guiding vulnerable users toward safe\nand helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic\nanticipation of user reactions, fine-grained risk boundary discovery, and\ninterpretable reasoning control, turning safety into a trust-building process.\nOy1 achieves state-of-the-art safety among open models while retaining high\ngeneral capabilities. On our Constructive Benchmark, it shows strong\nconstructive engagement, close to GPT-5, and unmatched robustness on the\nStrata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from\nrefusal-first to guidance-first safety, CSA redefines the model-user\nrelationship, aiming for systems that are not just safe, but meaningfully\nhelpful. We release Oy1, code, and the benchmark to support responsible,\nuser-centered AI.", "published": "2025-09-02 03:04:27", "link": "http://arxiv.org/abs/2509.01909v2", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.SC"], "primary_category": "cs.AI"}
{"title": "Recall Gabor Communication Theory and Joint Time-Frequency Analysis", "abstract": "In this article, we first briefly recall Gabor's communication theory and\nthen Gabor transform and expansion, and also its connection with joint time\nfrequency analysis.", "published": "2025-09-02 18:19:57", "link": "http://arxiv.org/abs/2509.02724v2", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Towards Reasoning for PDE Foundation Models: A Reward-Model-Driven Inference-Time-Scaling Algorithm", "abstract": "Partial Differential Equations (PDEs) are the bedrock for modern\ncomputational sciences and engineering, and inherently computationally\nexpensive. While PDE foundation models have shown much promise for simulating\nsuch complex spatio-temporal phenomena, existing models remain constrained by\nthe pretraining datasets and struggle with auto-regressive rollout performance,\nespecially in out-of-distribution (OOD) cases. Furthermore, they have\nsignificant compute and training data requirements which hamper their use in\nmany critical applications. Inspired by recent advances in ``thinking\"\nstrategies used in large language models (LLMs), we introduce the first\ntest-time computing (TTC) strategy for PDEs that utilizes computational\nresources during inference to achieve more accurate predictions with fewer\ntraining samples and smaller models. We accomplish this with two types of\nreward models that evaluate predictions of a stochastic based model for\nspatio-temporal consistency. We demonstrate this method on compressible\nEuler-equation simulations from the PDEGym benchmark and show that TTC captures\nimproved predictions relative to standard non-adaptive auto-regressive\ninference. This TTC framework marks a foundational step towards more advanced\nreasoning algorithms or PDE modeling, inluding building\nreinforcement-learning-based approaches, potentially transforming computational\nworkflows in physics and engineering.", "published": "2025-09-02 21:31:32", "link": "http://arxiv.org/abs/2509.02846v2", "categories": ["cs.LG", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "FireRedTTS-2: Towards Long Conversational Speech Generation for Podcast and Chatbot", "abstract": "Current dialogue generation approaches typically require the complete\ndialogue text before synthesis and produce a single, inseparable speech\ncontaining all voices, making them unsuitable for interactive chat; moreover,\nthey suffer from unstable synthesis, inaccurate speaker transitions, and\nincoherent prosody. In this work, we present FireRedTTS-2, a long-form\nstreaming TTS system for multi-speaker dialogue generation, delivering stable,\nnatural speech with reliable speaker switching and context-aware prosody. A new\n12.5Hz streaming speech tokenizer accelerates training and inference, extends\nmaximum dialogue length, encodes richer semantics to stabilize text-to-token\nmodeling and supports high-fidelity streaming generation for real-time\napplications. We adopt a text-speech interleaved format, concatenating\nspeaker-labeled text with aligned speech tokens in chronological order, and\nmodel it with a dual-transformer: a large decoder-only transformer predicts\ntokens at the first layer, and a smaller one completes subsequent layers.\nExperimental results show that FireRedTTS-2 integrates seamlessly with chat\nframeworks and, with minimal fine-tuning, produces emotionally expressive\nspeech guided by implicit contextual cues. In podcast generation, it surpasses\nexisting systems including MoonCast, Zipvoice-Dialogue, and MOSS-TTSD in\nobjective intelligibility, speaker-turn reliability, and perceived naturalness\nwith context-consistent prosody. Our demos are available at\nhttps://fireredteam.github.io/demos/firered_tts_2.", "published": "2025-09-02 07:06:46", "link": "http://arxiv.org/abs/2509.02020v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "From Evaluation to Optimization: Neural Speech Assessment for Downstream Applications", "abstract": "The evaluation of synthetic and processed speech has long been a cornerstone\nof audio engineering and speech science. Although subjective listening tests\nremain the gold standard for assessing perceptual quality and intelligibility,\ntheir high cost, time requirements, and limited scalability present significant\nchallenges in the rapid development cycles of modern speech technologies.\nTraditional objective metrics, while computationally efficient, often rely on a\nclean reference signal, making them intrusive approaches. This presents a major\nlimitation, as clean signals are often unavailable in real-world applications.\nIn recent years, numerous neural network-based speech assessment models have\nbeen developed to predict quality and intelligibility, achieving promising\nresults. Beyond their role in evaluation, these models are increasingly\nintegrated into downstream speech processing tasks. This review focuses on\ntheir role in two main areas: (1) serving as differentiable perceptual proxies\nthat not only assess but also guide the optimization of speech enhancement and\nsynthesis models; and (2) enabling the detection of salient speech\ncharacteristics to support more precise and efficient downstream processing.\nFinally, we discuss current limitations and outline future research directions\nto further advance the integration of speech assessment into speech processing\npipelines.", "published": "2025-09-02 02:26:38", "link": "http://arxiv.org/abs/2509.01889v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Affine-Doppler Division Multiplexing for High-Mobility Wireless Communications Systems", "abstract": "Affine Frequency Division Multiplexing (AFDM) has been regarded as a\ncandidate integrated sensing and communications (ISAC) waveform owing to its\nsuperior communication performance, outperforming the Orthogonal Time-Frequency\nSpace (OTFS) that has been researched for a longer time. However, since the\nabove two waveforms are incompatible with each other, the state-of-the-art\nmethods well-designed for OTFS may not be directly applicable to AFDM. This\npaper introduces a new orthogonal multicarrier waveform, namely Affine-Doppler\nDivision Multiplexing (ADDM), which can provide a generic framework and subsume\nthe existing OTFS and AFDM as a particular case. ADDM modulating information\nsymbols in the Affine-Doppler (A-D) domain based on a two-dimensional (2D)\ntransform can enjoy both excellent unambiguous Doppler and Doppler resolution,\nwhich is the same as AFDM but outperforms OTFS. Moreover, benefiting from the\n2D transform, the symbols block of ADDM in the A-D domain undergoes a 2D cyclic\nshift produced by the delay and the Doppler of the channel, similar to the 2D\ncyclic shift in the delay-Doppler domain of cyclic prefix (CP)-OTFS. This\noffers a potential to directly apply the state-of-the-art methods well-designed\nfor OTFS and AFDM to ADDM. Numerical results show that ADDM achieves comparable\nBER performance with AFDM but outperforms OTFS in high-mobility scenarios.", "published": "2025-09-02 09:11:35", "link": "http://arxiv.org/abs/2509.02116v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Prospects for acoustically monitoring ecosystem tipping points", "abstract": "Many ecosystems can undergo important qualitative changes, including sudden\ntransitions to alternative stable states, in response to perturbations or\nincrements in conditions. Such 'tipping points' are often preceded by declines\nin aspects of ecosystem resilience, namely the capacity to recover from\nperturbations, that leave various spatial and temporal signatures. These\nso-called 'early warning signals' have been used to anticipate transitions in\ndiverse real systems, but many of the high-throughput, autonomous monitoring\ntechnologies that are transforming ecology have yet to be fully leveraged to\nthis end. Acoustic monitoring in particular is a powerful tool for quantifying\nbiodiversity, tracking ecosystem health, and facilitating conservation. By\ndeploying acoustic recorders in diverse environments, researchers have gained\ninsights from the calls and behaviour of individual species to higher-level\nsoundscape features that describe habitat quality and even predict species\noccurrence. Here, we draw on theory and practice to advocate for using\nacoustics to probe ecosystem resilience and identify emerging and established\nearly warning signals of tipping points. With a focus on pragmatic\nconsiderations, we emphasise that despite limits to tipping point theory and\nthe current scale and transferability of data, acoustics could be instrumental\nin understanding resilience and tipping potential across distinct ecosystems\nand scales.", "published": "2025-09-02 11:14:52", "link": "http://arxiv.org/abs/2509.02201v1", "categories": ["q-bio.PE", "cs.SD", "eess.AS", "math.DS"], "primary_category": "q-bio.PE"}
{"title": "UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning", "abstract": "The development of autonomous agents for graphical user interfaces (GUIs)\npresents major challenges in artificial intelligence. While recent advances in\nnative agent models have shown promise by unifying perception, reasoning,\naction, and memory through end-to-end learning, open problems remain in data\nscalability, multi-turn reinforcement learning (RL), the limitations of\nGUI-only operation, and environment stability. In this technical report, we\npresent UI-TARS-2, a native GUI-centered agent model that addresses these\nchallenges through a systematic training methodology: a data flywheel for\nscalable data generation, a stabilized multi-turn RL framework, a hybrid GUI\nenvironment that integrates file systems and terminals, and a unified sandbox\nplatform for large-scale rollouts. Empirical evaluation demonstrates that\nUI-TARS-2 achieves significant improvements over its predecessor UI-TARS-1.5.\nOn GUI benchmarks, it reaches 88.2 on Online-Mind2Web, 47.5 on OSWorld, 50.6 on\nWindowsAgentArena, and 73.3 on AndroidWorld, outperforming strong baselines\nsuch as Claude and OpenAI agents. In game environments, it attains a mean\nnormalized score of 59.8 across a 15-game suite-roughly 60% of human-level\nperformance-and remains competitive with frontier proprietary models (e.g.,\nOpenAI o3) on LMGame-Bench. Additionally, the model can generalize to\nlong-horizon information-seeking tasks and software engineering benchmarks,\nhighlighting its robustness across diverse agent tasks. Detailed analyses of\ntraining dynamics further provide insights into achieving stability and\nefficiency in large-scale agent RL. These results underscore UI-TARS-2's\npotential to advance the state of GUI agents and exhibit strong generalization\nto real-world interactive scenarios.", "published": "2025-09-02 17:44:45", "link": "http://arxiv.org/abs/2509.02544v2", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Abex-rat: Synergizing Abstractive Augmentation and Adversarial Training for Classification of Occupational Accident Reports", "abstract": "The automatic classification of occupational accident reports is a critical\nresearch area for enhancing workplace safety and enabling large-scale risk\nanalysis. However, the severe class imbalance inherent in these real-world\ndatasets often compromises the performance of analytical models, particularly\nfor rare but severe incident types, hindering the development of reliable\nautomated systems. To address this challenge, we propose ABEX-RAT, a novel and\nefficient framework that synergizes generative data augmentation with robust\nadversarial training. Our approach first employs a twostep\nabstractive-expansive (ABEX) pipeline, which leverages a large language model\nto distill core incident semantics and then uses a generative model to create\ndiverse, highquality synthetic samples for underrepresented classes.\nSubsequently, a lightweight classifier is trained on the augmented data using a\ncomputationally efficient random adversarial training (RAT) protocol, which\nstochastically applies perturbations to enhance model generalization and\nrobustness without significant overhead. Experimental results on the public\nOSHA dataset demonstrate that our method achieves new state-of-the-art\nperformance, reaching a macro-F1 score of 90.32% and significantly\noutperforming previous SOTA and fine-tuned large model baselines. Our work\nvalidates that this synergistic strategy is a highly effective and efficient\nalternative to brute-force fine-tuning for specialized, imbalanced\nclassification tasks. The code is publicly available\nat:https://github.com/nxcc-lab/ABEX-RAT.", "published": "2025-09-02 08:22:59", "link": "http://arxiv.org/abs/2509.02072v2", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Dynamic Speculative Agent Planning", "abstract": "Despite their remarkable success in complex tasks propelling widespread\nadoption, large language-model-based agents still face critical deployment\nchallenges due to prohibitive latency and inference costs. While recent work\nhas explored various methods to accelerate inference, existing approaches\nsuffer from significant limitations: they either fail to preserve performance\nfidelity, require extensive offline training of router modules, or incur\nexcessive operational costs. Moreover, they provide minimal user control over\nthe tradeoff between acceleration and other performance metrics. To address\nthese gaps, we introduce Dynamic Speculative Planning (DSP), an asynchronous\nonline reinforcement learning framework that provides lossless acceleration\nwith substantially reduced costs without requiring additional pre-deployment\npreparation. DSP explicitly optimizes a joint objective balancing end-to-end\nlatency against dollar cost, allowing practitioners to adjust a single\nparameter that steers the system toward faster responses, cheaper operation, or\nany point along this continuum. Experiments on two standard agent benchmarks\ndemonstrate that DSP achieves comparable efficiency to the fastest lossless\nacceleration method while reducing total cost by 30% and unnecessary cost up to\n60%. Our code and data are available through\nhttps://github.com/guanyilin428/Dynamic-Speculative-Planning.", "published": "2025-09-02 03:34:36", "link": "http://arxiv.org/abs/2509.01920v2", "categories": ["cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Fantastic Pretraining Optimizers and Where to Find Them", "abstract": "AdamW has long been the dominant optimizer in language model pretraining,\ndespite numerous claims that alternative optimizers offer 1.4 to 2x speedup. We\nposit that two methodological shortcomings have obscured fair comparisons and\nhindered practical adoption: (i) unequal hyperparameter tuning and (ii) limited\nor misleading evaluation setups. To address these two issues, we conduct a\nsystematic study of ten deep learning optimizers across four model scales\n(0.1B-1.2B parameters) and data-to-model ratios (1-8x the Chinchilla optimum).\nWe find that fair and informative comparisons require rigorous hyperparameter\ntuning and evaluations across a range of model scales and data-to-model ratios,\nperformed at the end of training. First, optimal hyperparameters for one\noptimizer may be suboptimal for another, making blind hyperparameter transfer\nunfair. Second, the actual speedup of many proposed optimizers over well-tuned\nbaselines is lower than claimed and decreases with model size to only 1.1x for\n1.2B parameter models. Thirdly, comparing intermediate checkpoints before\nreaching the target training budgets can be misleading, as rankings between two\noptimizers can flip during training due to learning rate decay. Through our\nthorough investigation, we find that all the fastest optimizers such as Muon\nand Soap, use matrices as preconditioners -- multiplying gradients with\nmatrices rather than entry-wise scalars. However, the speedup of matrix-based\noptimizers is inversely proportional to model scale, decreasing from 1.4x over\nAdamW for 0.1B parameter models to merely 1.1x for 1.2B parameter models.", "published": "2025-09-02 07:43:22", "link": "http://arxiv.org/abs/2509.02046v2", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Fidelity-preserving enhancement of ptychography with foundational text-to-image models", "abstract": "Ptychographic phase retrieval enables high-resolution imaging of complex\nsamples but often suffers from artifacts such as grid pathology and multislice\ncrosstalk, which degrade reconstructed images. We propose a plug-and-play (PnP)\nframework that integrates physics model-based phase retrieval with text-guided\nimage editing using foundational diffusion models. By employing the alternating\ndirection method of multipliers (ADMM), our approach ensures consensus between\ndata fidelity and artifact removal subproblems, maintaining physics consistency\nwhile enhancing image quality. Artifact removal is achieved using a text-guided\ndiffusion image editing method (LEDITS++) with a pre-trained foundational\ndiffusion model, allowing users to specify artifacts for removal in natural\nlanguage. Demonstrations on simulated and experimental datasets show\nsignificant improvements in artifact suppression and structural fidelity,\nvalidated by metrics such as peak signal-to-noise ratio (PSNR) and diffraction\npattern consistency. This work highlights the combination of text-guided\ngenerative models and model-based phase retrieval algorithms as a transferable\nand fidelity-preserving method for high-quality diffraction imaging.", "published": "2025-09-02 21:00:44", "link": "http://arxiv.org/abs/2509.04513v1", "categories": ["cs.GR", "cs.NA", "math.NA", "physics.app-ph", "65Kxx"], "primary_category": "cs.GR"}
