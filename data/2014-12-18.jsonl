{"title": "Incorporating Both Distributional and Relational Semantics in Word\n  Representations", "abstract": "We investigate the hypothesis that word representations ought to incorporate\nboth distributional and relational semantics. To this end, we employ the\nAlternating Direction Method of Multipliers (ADMM), which flexibly optimizes a\ndistributional objective on raw text and a relational objective on WordNet.\nPreliminary results on knowledge base completion, analogy tests, and parsing\nshow that word representations trained on both objectives can give improvements\nin some cases.", "published": "2014-12-18 12:30:55", "link": "http://arxiv.org/abs/1412.5836v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple and Efficient Method To Generate Word Sense Representations", "abstract": "Distributed representations of words have boosted the performance of many\nNatural Language Processing tasks. However, usually only one representation per\nword is obtained, not acknowledging the fact that some words have multiple\nmeanings. This has a negative effect on the individual word representations and\nthe language model as a whole. In this paper we present a simple model that\nenables recent techniques for building word vectors to represent distinct\nsenses of polysemic words. In our assessment of this model we show that it is\nable to effectively discriminate between words' senses and to do so in a\ncomputationally efficient manner.", "published": "2014-12-18 20:14:10", "link": "http://arxiv.org/abs/1412.6045v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
