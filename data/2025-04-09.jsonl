{"title": "Sculpting Subspaces: Constrained Full Fine-Tuning in LLMs for Continual Learning", "abstract": "Continual learning in large language models (LLMs) is prone to catastrophic\nforgetting, where adapting to new tasks significantly degrades performance on\npreviously learned ones. Existing methods typically rely on low-rank,\nparameter-efficient updates that limit the model's expressivity and introduce\nadditional parameters per task, leading to scalability issues. To address these\nlimitations, we propose a novel continual full fine-tuning approach leveraging\nadaptive singular value decomposition (SVD). Our method dynamically identifies\ntask-specific low-rank parameter subspaces and constrains updates to be\northogonal to critical directions associated with prior tasks, thus effectively\nminimizing interference without additional parameter overhead or storing\nprevious task gradients. We evaluate our approach extensively on standard\ncontinual learning benchmarks using both encoder-decoder (T5-Large) and\ndecoder-only (LLaMA-2 7B) models, spanning diverse tasks including\nclassification, generation, and reasoning. Empirically, our method achieves\nstate-of-the-art results, up to 7% higher average accuracy than recent\nbaselines like O-LoRA, and notably maintains the model's general linguistic\ncapabilities, instruction-following accuracy, and safety throughout the\ncontinual learning process by reducing forgetting to near-negligible levels.\nOur adaptive SVD framework effectively balances model plasticity and knowledge\nretention, providing a practical, theoretically grounded, and computationally\nscalable solution for continual learning scenarios in large language models.", "published": "2025-04-09 17:59:42", "link": "http://arxiv.org/abs/2504.07097v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "math.PR", "stat.ML", "68T50", "I.2.0; G.3"], "primary_category": "cs.LG"}
{"title": "OLMoTrace: Tracing Language Model Outputs Back to Trillions of Training Tokens", "abstract": "We present OLMoTrace, the first system that traces the outputs of language\nmodels back to their full, multi-trillion-token training data in real time.\nOLMoTrace finds and shows verbatim matches between segments of language model\noutput and documents in the training text corpora. Powered by an extended\nversion of infini-gram (Liu et al., 2024), our system returns tracing results\nwithin a few seconds. OLMoTrace can help users understand the behavior of\nlanguage models through the lens of their training data. We showcase how it can\nbe used to explore fact checking, hallucination, and the creativity of language\nmodels. OLMoTrace is publicly available and fully open-source.", "published": "2025-04-09 17:59:35", "link": "http://arxiv.org/abs/2504.07096v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OmniCaptioner: One Captioner to Rule Them All", "abstract": "We propose OmniCaptioner, a versatile visual captioning framework for\ngenerating fine-grained textual descriptions across a wide variety of visual\ndomains. Unlike prior methods limited to specific image types (e.g., natural\nimages or geometric visuals), our framework provides a unified solution for\ncaptioning natural images, visual text (e.g., posters, UIs, textbooks), and\nstructured visuals (e.g., documents, tables, charts). By converting low-level\npixel information into semantically rich textual representations, our framework\nbridges the gap between visual and textual modalities. Our results highlight\nthree key advantages: (i) Enhanced Visual Reasoning with LLMs, where\nlong-context captions of visual modalities empower LLMs, particularly the\nDeepSeek-R1 series, to reason effectively in multimodal scenarios; (ii)\nImproved Image Generation, where detailed captions improve tasks like\ntext-to-image generation and image transformation; and (iii) Efficient\nSupervised Fine-Tuning (SFT), which enables faster convergence with less data.\nWe believe the versatility and adaptability of OmniCaptioner can offer a new\nperspective for bridging the gap between language and visual modalities.", "published": "2025-04-09 17:58:58", "link": "http://arxiv.org/abs/2504.07089v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "KG-LLM-Bench: A Scalable Benchmark for Evaluating LLM Reasoning on Textualized Knowledge Graphs", "abstract": "Knowledge graphs have emerged as a popular method for injecting up-to-date,\nfactual knowledge into large language models (LLMs). This is typically achieved\nby converting the knowledge graph into text that the LLM can process in\ncontext. While multiple methods of encoding knowledge graphs have been\nproposed, the impact of this textualization process on LLM performance remains\nunder-explored. We introduce KG-LLM-Bench, a comprehensive and extensible\nbenchmark spanning five knowledge graph understanding tasks, and evaluate how\ndifferent encoding strategies affect performance across various base models.\nOur extensive experiments with seven language models and five textualization\nstrategies provide insights for optimizing LLM performance on KG reasoning\ntasks.", "published": "2025-04-09 17:58:47", "link": "http://arxiv.org/abs/2504.07087v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths to Reproducibility", "abstract": "Reasoning has emerged as the next major frontier for language models (LMs),\nwith rapid advances from both academic and industrial labs. However, this\nprogress often outpaces methodological rigor, with many evaluations relying on\nbenchmarking practices that lack transparency, robustness, or statistical\ngrounding. In this work, we conduct a comprehensive empirical study and find\nthat current mathematical reasoning benchmarks are highly sensitive to subtle\nimplementation choices - including decoding parameters, random seeds, prompt\nformatting, and even hardware and software-framework configurations.\nPerformance gains reported in recent studies frequently hinge on unclear\ncomparisons or unreported sources of variance. To address these issues, we\npropose a standardized evaluation framework with clearly defined best practices\nand reporting standards. Using this framework, we reassess recent methods and\nfind that reinforcement learning (RL) approaches yield only modest improvements\n- far below prior claims - and are prone to overfitting, especially on\nsmall-scale benchmarks like AIME24. In contrast, supervised finetuning (SFT)\nmethods show consistently stronger generalization. To foster reproducibility,\nwe release all code, prompts, and model outputs, for reasoning benchmarks,\nestablishing more rigorous foundations for future work.", "published": "2025-04-09 17:58:17", "link": "http://arxiv.org/abs/2504.07086v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Self-Steering Language Models", "abstract": "While test-time reasoning enables language models to tackle complex tasks,\nsearching or planning in natural language can be slow, costly, and error-prone.\nBut even when LMs struggle to emulate the precise reasoning steps needed to\nsolve a problem, they often excel at describing its abstract structure--both\nhow to verify solutions and how to search for them. This paper introduces\nDisCIPL, a method for \"self-steering\" LMs where a Planner model generates a\ntask-specific inference program that is executed by a population of Follower\nmodels. Our approach equips LMs with the ability to write recursive search\nprocedures that guide LM inference, enabling new forms of verifiable and\nefficient reasoning. When instantiated with a small Follower (e.g.,\nLlama-3.2-1B), DisCIPL matches (and sometimes outperforms) much larger models,\nincluding GPT-4o and o1, on challenging constrained generation tasks. In\ndecoupling planning from execution, our work opens up a design space of\nhighly-parallelized Monte Carlo inference strategies that outperform standard\nbest-of-N sampling, require no finetuning, and can be implemented automatically\nby existing LMs.", "published": "2025-04-09 17:54:22", "link": "http://arxiv.org/abs/2504.07081v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DeduCE: Deductive Consistency as a Framework to Evaluate LLM Reasoning", "abstract": "Despite great performance on Olympiad-level reasoning problems, frontier\nlarge language models can still struggle on high school math when presented\nwith novel problems outside standard benchmarks. Going beyond final accuracy,\nwe propose a deductive consistency metric to analyze chain-of-thought output\nfrom language models (LMs).Formally, deductive reasoning involves two subtasks:\nunderstanding a set of input premises and inferring the conclusions that follow\nfrom them. The proposed metric studies LMs' performance on these subtasks, with\nthe goal of explaining LMs' reasoning errors on novel problems: how well do LMs\nunderstand input premises with increasing context lengths, and how well can\nthey infer conclusions over multiple reasoning hops? Since existing benchmarks\nmay be memorized, we develop a pipeline to evaluate LMs' deductive consistency\non novel, perturbed versions of benchmark problems. On novel grade school math\nproblems (GSM-8k), we find that LMs are fairly robust to increasing number of\ninput premises, but suffer significant accuracy decay as the number of\nreasoning hops is increased. Interestingly, these errors are masked in the\noriginal benchmark as all models achieve near 100% accuracy. As we increase the\nnumber of solution steps using a synthetic dataset, prediction over multiple\nhops still remains the major source of error compared to understanding input\npremises. Other factors, such as shifts in language style or natural\npropagation of early errors do not explain the trends. Our analysis provides a\nnew view to characterize LM reasoning -- as computations over a window of input\npremises and reasoning hops -- that can provide unified evaluation across\nproblem domains.", "published": "2025-04-09 17:53:55", "link": "http://arxiv.org/abs/2504.07080v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SkillWeaver: Web Agents can Self-Improve by Discovering and Honing Skills", "abstract": "To survive and thrive in complex environments, humans have evolved\nsophisticated self-improvement mechanisms through environment exploration,\nhierarchical abstraction of experiences into reuseable skills, and\ncollaborative construction of an ever-growing skill repertoire. Despite recent\nadvancements, autonomous web agents still lack crucial self-improvement\ncapabilities, struggling with procedural knowledge abstraction, refining\nskills, and skill composition. In this work, we introduce SkillWeaver, a\nskill-centric framework enabling agents to self-improve by autonomously\nsynthesizing reusable skills as APIs. Given a new website, the agent\nautonomously discovers skills, executes them for practice, and distills\npractice experiences into robust APIs. Iterative exploration continually\nexpands a library of lightweight, plug-and-play APIs, significantly enhancing\nthe agent's capabilities. Experiments on WebArena and real-world websites\ndemonstrate the efficacy of SkillWeaver, achieving relative success rate\nimprovements of 31.8% and 39.8%, respectively. Additionally, APIs synthesized\nby strong agents substantially enhance weaker agents through transferable\nskills, yielding improvements of up to 54.3% on WebArena. These results\ndemonstrate the effectiveness of honing diverse website interactions into APIs,\nwhich can be seamlessly shared among various web agents.", "published": "2025-04-09 17:51:50", "link": "http://arxiv.org/abs/2504.07079v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Kaleidoscope: In-language Exams for Massively Multilingual Vision Evaluation", "abstract": "The evaluation of vision-language models (VLMs) has mainly relied on\nEnglish-language benchmarks, leaving significant gaps in both multilingual and\nmulticultural coverage. While multilingual benchmarks have expanded, both in\nsize and languages, many rely on translations of English datasets, failing to\ncapture cultural nuances. In this work, we propose Kaleidoscope, as the most\ncomprehensive exam benchmark to date for the multilingual evaluation of\nvision-language models. Kaleidoscope is a large-scale, in-language multimodal\nbenchmark designed to evaluate VLMs across diverse languages and visual inputs.\nKaleidoscope covers 18 languages and 14 different subjects, amounting to a\ntotal of 20,911 multiple-choice questions. Built through an open science\ncollaboration with a diverse group of researchers worldwide, Kaleidoscope\nensures linguistic and cultural authenticity. We evaluate top-performing\nmultilingual vision-language models and find that they perform poorly on\nlow-resource languages and in complex multimodal scenarios. Our results\nhighlight the need for progress on culturally inclusive multimodal evaluation\nframeworks.", "published": "2025-04-09 17:43:16", "link": "http://arxiv.org/abs/2504.07072v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "A Survey on Personalized and Pluralistic Preference Alignment in Large Language Models", "abstract": "Personalized preference alignment for large language models (LLMs), the\nprocess of tailoring LLMs to individual users' preferences, is an emerging\nresearch direction spanning the area of NLP and personalization. In this\nsurvey, we present an analysis of works on personalized alignment and modeling\nfor LLMs. We introduce a taxonomy of preference alignment techniques, including\ntraining time, inference time, and additionally, user-modeling based methods.\nWe provide analysis and discussion on the strengths and limitations of each\ngroup of techniques and then cover evaluation, benchmarks, as well as open\nproblems in the field.", "published": "2025-04-09 17:39:58", "link": "http://arxiv.org/abs/2504.07070v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HalluciNot: Hallucination Detection Through Context and Common Knowledge Verification", "abstract": "This paper introduces a comprehensive system for detecting hallucinations in\nlarge language model (LLM) outputs in enterprise settings. We present a novel\ntaxonomy of LLM responses specific to hallucination in enterprise applications,\ncategorizing them into context-based, common knowledge, enterprise-specific,\nand innocuous statements. Our hallucination detection model HDM-2 validates LLM\nresponses with respect to both context and generally known facts (common\nknowledge). It provides both hallucination scores and word-level annotations,\nenabling precise identification of problematic content. To evaluate it on\ncontext-based and common-knowledge hallucinations, we introduce a new dataset\nHDMBench. Experimental results demonstrate that HDM-2 out-performs existing\napproaches across RagTruth, TruthfulQA, and HDMBench datasets. This work\naddresses the specific challenges of enterprise deployment, including\ncomputational efficiency, domain specialization, and fine-grained error\nidentification. Our evaluation dataset, model weights, and inference code are\npublicly available.", "published": "2025-04-09 17:39:41", "link": "http://arxiv.org/abs/2504.07069v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TASTE: Text-Aligned Speech Tokenization and Embedding for Spoken Language Modeling", "abstract": "Large Language Models (LLMs) excel in text-based natural language processing\ntasks but remain constrained by their reliance on textual inputs and outputs.\nTo enable more natural human-LLM interaction, recent progress have focused on\nderiving a spoken language model (SLM) that can not only listen but also\ngenerate speech. To achieve this, a promising direction is to conduct\nspeech-text joint modeling. However, recent SLM still lag behind text LLM due\nto the modality mismatch. One significant mismatch can be the sequence lengths\nbetween speech and text tokens. To address this, we introduce Text-Aligned\nSpeech Tokenization and Embedding (TASTE), a method that directly addresses the\nmodality gap by aligning speech token with the corresponding text transcription\nduring the tokenization stage. We propose a method that can achieve this\nthrough the special aggregation mechanism and with speech reconstruction as the\ntraining objective. We conduct extensive experiments and show that TASTE can\npreserve essential paralinguistic information while dramatically reducing the\ntoken sequence length. Furthermore, by leveraging TASTE, we can adapt\ntext-based LLMs into effective SLMs with parameter-efficient fine-tuning\ntechniques such as Low-Rank Adaptation (LoRA). Experimental results on\nbenchmark tasks, including SALMON and StoryCloze, demonstrate that TASTE-based\nSLMs perform similarly to previous full-finetuning methods. To our knowledge,\nTASTE is the first end-to-end approach that utilizes a reconstruction objective\nto automatically learn a text-aligned speech tokenization and embedding\nsuitable for spoken language modeling. Our demo, code, and models are publicly\navailable at https://github.com/mtkresearch/TASTE-SpokenLM.", "published": "2025-04-09 17:14:33", "link": "http://arxiv.org/abs/2504.07053v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Unified Agentic Framework for Evaluating Conditional Image Generation", "abstract": "Conditional image generation has gained significant attention for its ability\nto personalize content. However, the field faces challenges in developing\ntask-agnostic, reliable, and explainable evaluation metrics. This paper\nintroduces CIGEval, a unified agentic framework for comprehensive evaluation of\nconditional image generation tasks. CIGEval utilizes large multimodal models\n(LMMs) as its core, integrating a multi-functional toolbox and establishing a\nfine-grained evaluation framework. Additionally, we synthesize evaluation\ntrajectories for fine-tuning, empowering smaller LMMs to autonomously select\nappropriate tools and conduct nuanced analyses based on tool outputs.\nExperiments across seven prominent conditional image generation tasks\ndemonstrate that CIGEval (GPT-4o version) achieves a high correlation of 0.4625\nwith human assessments, closely matching the inter-annotator correlation of\n0.47. Moreover, when implemented with 7B open-source LMMs using only 2.3K\ntraining trajectories, CIGEval surpasses the previous GPT-4o-based\nstate-of-the-art method. Case studies on GPT-4o image generation highlight\nCIGEval's capability in identifying subtle issues related to subject\nconsistency and adherence to control guidance, indicating its great potential\nfor automating evaluation of image generation tasks with human-level\nreliability.", "published": "2025-04-09 17:04:14", "link": "http://arxiv.org/abs/2504.07046v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Data Augmentation and Hyperparameter Tuning for Low-Resource MFA", "abstract": "A continued issue for those working with computational tools and endangered\nand under-resourced languages is the lower accuracy of results for languages\nwith smaller amounts of data. We attempt to ameliorate this issue by using data\naugmentation methods to increase corpus size, comparing augmentation to\nhyperparameter tuning for multilingual forced alignment. Unlike text\naugmentation methods, audio augmentation does not lead to substantially\nincreased performance. Hyperparameter tuning, on the other hand, results in\nsubstantial improvement without (for this amount of data) infeasible additional\ntraining time. For languages with small to medium amounts of training data,\nthis is a workable alternative to adapting models from high-resource languages.", "published": "2025-04-09 16:38:45", "link": "http://arxiv.org/abs/2504.07024v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Retrieval Augmented Generative Models for Document Queries in Transportation Safety", "abstract": "Applications of generative Large Language Models LLMs are rapidly expanding\nacross various domains, promising significant improvements in workflow\nefficiency and information retrieval. However, their implementation in\nspecialized, high-stakes domains such as hazardous materials transportation is\nchallenging due to accuracy and reliability concerns. This study evaluates the\nperformance of three fine-tuned generative models, ChatGPT, Google's Vertex AI,\nand ORNL Retrieval Augmented Generation augmented LLaMA 2 and LLaMA in\nretrieving regulatory information essential for hazardous material\ntransportation compliance in the United States. Utilizing approximately 40\npublicly available federal and state regulatory documents, we developed 100\nrealistic queries relevant to route planning and permitting requirements.\nResponses were qualitatively rated based on accuracy, detail, and relevance,\ncomplemented by quantitative assessments of semantic similarity between model\noutputs. Results demonstrated that the RAG-augmented LLaMA models significantly\noutperformed Vertex AI and ChatGPT, providing more detailed and generally\naccurate information, despite occasional inconsistencies. This research\nintroduces the first known application of RAG in transportation safety,\nemphasizing the need for domain-specific fine-tuning and rigorous evaluation\nmethodologies to ensure reliability and minimize the risk of inaccuracies in\nhigh-stakes environments.", "published": "2025-04-09 16:37:03", "link": "http://arxiv.org/abs/2504.07022v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards LLMs Robustness to Changes in Prompt Format Styles", "abstract": "Large language models (LLMs) have gained popularity in recent years for their\nutility in various applications. However, they are sensitive to non-semantic\nchanges in prompt formats, where small changes in the prompt format can lead to\nsignificant performance fluctuations. In the literature, this problem is\ncommonly referred to as prompt brittleness. Previous research on prompt\nengineering has focused mainly on developing techniques for identifying the\noptimal prompt for specific tasks. Some studies have also explored the issue of\nprompt brittleness and proposed methods to quantify performance variations;\nhowever, no simple solution has been found to address this challenge. We\npropose Mixture of Formats (MOF), a simple and efficient technique for\naddressing prompt brittleness in LLMs by diversifying the styles used in the\nprompt few-shot examples. MOF was inspired by computer vision techniques that\nutilize diverse style datasets to prevent models from associating specific\nstyles with the target variable. Empirical results show that our proposed\ntechnique reduces style-induced prompt brittleness in various LLMs while also\nenhancing overall performance across prompt variations and different datasets.", "published": "2025-04-09 15:26:00", "link": "http://arxiv.org/abs/2504.06969v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RNN-Transducer-based Losses for Speech Recognition on Noisy Targets", "abstract": "Training speech recognition systems on noisy transcripts is a significant\nchallenge in industrial pipelines, where datasets are enormous and ensuring\naccurate transcription for every instance is difficult. In this work, we\nintroduce novel loss functions to mitigate the impact of transcription errors\nin RNN-Transducer models. Our Star-Transducer loss addresses deletion errors by\nincorporating \"skip frame\" transitions in the loss lattice, restoring over 90%\nof the system's performance compared to models trained with accurate\ntranscripts. The Bypass-Transducer loss uses \"skip token\" transitions to tackle\ninsertion errors, recovering more than 60% of the quality. Finally, the\nTarget-Robust Transducer loss merges these approaches, offering robust\nperformance against arbitrary errors. Experimental results demonstrate that the\nTarget-Robust Transducer loss significantly improves RNN-T performance on noisy\ndata by restoring over 70% of the quality compared to well-transcribed data.", "published": "2025-04-09 15:18:29", "link": "http://arxiv.org/abs/2504.06963v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Adaptive Computation Pruning for the Forgetting Transformer", "abstract": "The recently proposed Forgetting Transformer (FoX) incorporates a forget gate\ninto softmax attention and has shown consistently better or on-par performance\ncompared to the standard RoPE-based Transformer. Notably, many attention heads\nin FoX tend to forget quickly, causing their output at each timestep to rely\nprimarily on the local context. Based on this observation, we propose Adaptive\nComputation Pruning (ACP) for FoX, a method that dynamically prunes\ncomputations involving input-output dependencies that are strongly decayed by\nthe forget gate. This is achieved using a dynamically set pruning threshold\nthat ensures that the pruned attention weights remain negligible. We apply ACP\nto language model pretraining with FoX and show it consistently reduces the\nnumber of FLOPs in softmax attention by around 70% across different model sizes\nand context lengths, resulting in a roughly 10% to 35% improvement in training\nthroughput. Furthermore, longer context lengths yield greater computational\nsavings. All these speed improvements are achieved without any performance\ndegradation. We also perform several analyses to provide deeper insights into\nour method, such as examining the pruning patterns and analyzing the\ndistribution of FLOP savings across different attention heads. Our code is\navailable at https://github.com/zhixuan-lin/arctic-fox.", "published": "2025-04-09 14:57:55", "link": "http://arxiv.org/abs/2504.06949v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RuOpinionNE-2024: Extraction of Opinion Tuples from Russian News Texts", "abstract": "In this paper, we introduce the Dialogue Evaluation shared task on extraction\nof structured opinions from Russian news texts. The task of the contest is to\nextract opinion tuples for a given sentence; the tuples are composed of a\nsentiment holder, its target, an expression and sentiment from the holder to\nthe target. In total, the task received more than 100 submissions. The\nparticipants experimented mainly with large language models in zero-shot,\nfew-shot and fine-tuning formats. The best result on the test set was obtained\nwith fine-tuning of a large language model. We also compared 30 prompts and 11\nopen source language models with 3-32 billion parameters in the 1-shot and\n10-shot settings and found the best models and prompts.", "published": "2025-04-09 14:54:00", "link": "http://arxiv.org/abs/2504.06947v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Data Augmentation for Fake Reviews Detection in Multiple Languages and Multiple Domains", "abstract": "With the growth of the Internet, buying habits have changed, and customers\nhave become more dependent on the online opinions of other customers to guide\ntheir purchases. Identifying fake reviews thus became an important area for\nNatural Language Processing (NLP) research. However, developing\nhigh-performance NLP models depends on the availability of large amounts of\ntraining data, which are often not available for low-resource languages or\ndomains. In this research, we used large language models to generate datasets\nto train fake review detectors. Our approach was used to generate fake reviews\nin different domains (book reviews, restaurant reviews, and hotel reviews) and\ndifferent languages (English and Chinese). Our results demonstrate that our\ndata augmentation techniques result in improved performance at fake review\ndetection for all domains and languages. The accuracy of our fake review\ndetection model can be improved by 0.3 percentage points on DeRev TEST, 10.9\npercentage points on Amazon TEST, 8.3 percentage points on Yelp TEST and 7.2\npercentage points on DianPing TEST using the augmented datasets.", "published": "2025-04-09 14:23:54", "link": "http://arxiv.org/abs/2504.06917v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Aspects in Peer Reviews", "abstract": "Peer review is central to academic publishing, but the growing volume of\nsubmissions is straining the process. This motivates the development of\ncomputational approaches to support peer review. While each review is tailored\nto a specific paper, reviewers often make assessments according to certain\naspects such as Novelty, which reflect the values of the research community.\nThis alignment creates opportunities for standardizing the reviewing process,\nimproving quality control, and enabling computational support. While prior work\nhas demonstrated the potential of aspect analysis for peer review assistance,\nthe notion of aspect remains poorly formalized. Existing approaches often\nderive aspect sets from review forms and guidelines of major NLP venues, yet\ndata-driven methods for aspect identification are largely underexplored. To\naddress this gap, our work takes a bottom-up approach: we propose an\noperational definition of aspect and develop a data-driven schema for deriving\nfine-grained aspects from a corpus of peer reviews. We introduce a dataset of\npeer reviews augmented with aspects and show how it can be used for\ncommunity-level review analysis. We further show how the choice of aspects can\nimpact downstream applications, such as LLM-generated review detection. Our\nresults lay a foundation for a principled and data-driven investigation of\nreview aspects, and pave the path for new applications of NLP to support peer\nreview.", "published": "2025-04-09 14:14:42", "link": "http://arxiv.org/abs/2504.06910v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Persona Dynamics: Unveiling the Impact of Personality Traits on Agents in Text-Based Games", "abstract": "Artificial agents are increasingly central to complex interactions and\ndecision-making tasks, yet aligning their behaviors with desired human values\nremains an open challenge. In this work, we investigate how human-like\npersonality traits influence agent behavior and performance within text-based\ninteractive environments. We introduce PANDA: PersonalityAdapted Neural\nDecision Agents, a novel method for projecting human personality traits onto\nagents to guide their behavior. To induce personality in a text-based game\nagent, (i) we train a personality classifier to identify what personality type\nthe agent's actions exhibit, and (ii) we integrate the personality profiles\ndirectly into the agent's policy-learning pipeline. By deploying agents\nembodying 16 distinct personality types across 25 text-based games and\nanalyzing their trajectories, we demonstrate that an agent's action decisions\ncan be guided toward specific personality profiles. Moreover, certain\npersonality types, such as those characterized by higher levels of Openness,\ndisplay marked advantages in performance. These findings underscore the promise\nof personality-adapted agents for fostering more aligned, effective, and\nhuman-centric decision-making in interactive environments.", "published": "2025-04-09 13:17:00", "link": "http://arxiv.org/abs/2504.06868v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Integrating Cognitive Processing Signals into Language Models: A Review of Advances, Applications and Future Directions", "abstract": "Recently, the integration of cognitive neuroscience in Natural Language\nProcessing (NLP) has gained significant attention. This article provides a\ncritical and timely overview of recent advancements in leveraging cognitive\nsignals, particularly Eye-tracking (ET) signals, to enhance Language Models\n(LMs) and Multimodal Large Language Models (MLLMs). By incorporating\nuser-centric cognitive signals, these approaches address key challenges,\nincluding data scarcity and the environmental costs of training large-scale\nmodels. Cognitive signals enable efficient data augmentation, faster\nconvergence, and improved human alignment. The review emphasises the potential\nof ET data in tasks like Visual Question Answering (VQA) and mitigating\nhallucinations in MLLMs, and concludes by discussing emerging challenges and\nresearch trends.", "published": "2025-04-09 13:01:48", "link": "http://arxiv.org/abs/2504.06843v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Open Problems and a Hypothetical Path Forward in LLM Knowledge Paradigms", "abstract": "Knowledge is fundamental to the overall capabilities of Large Language Models\n(LLMs). The knowledge paradigm of a model, which dictates how it encodes and\nutilizes knowledge, significantly affects its performance. Despite the\ncontinuous development of LLMs under existing knowledge paradigms, issues\nwithin these frameworks continue to constrain model potential.\n  This blog post highlight three critical open problems limiting model\ncapabilities: (1) challenges in knowledge updating for LLMs, (2) the failure of\nreverse knowledge generalization (the reversal curse), and (3) conflicts in\ninternal knowledge. We review recent progress made in addressing these issues\nand discuss potential general solutions. Based on observations in these areas,\nwe propose a hypothetical paradigm based on Contextual Knowledge Scaling, and\nfurther outline implementation pathways that remain feasible within\ncontemporary techniques. Evidence suggests this approach holds potential to\naddress current shortcomings, serving as our vision for future model paradigms.\n  This blog post aims to provide researchers with a brief overview of progress\nin LLM knowledge systems, while provide inspiration for the development of\nnext-generation model architectures.", "published": "2025-04-09 12:31:25", "link": "http://arxiv.org/abs/2504.06823v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inducing Programmatic Skills for Agentic Tasks", "abstract": "To succeed in common digital tasks such as web navigation, agents must carry\nout a variety of specialized tasks such as searching for products or planning a\ntravel route. To tackle these tasks, agents can bootstrap themselves by\nlearning task-specific skills online through interaction with the web\nenvironment. In this work, we demonstrate that programs are an effective\nrepresentation for skills. We propose agent skill induction (ASI), which allows\nagents to adapt themselves by inducing, verifying, and utilizing program-based\nskills on the fly. We start with an evaluation on the WebArena agent benchmark\nand show that ASI outperforms the static baseline agent and its text-skill\ncounterpart by 23.5% and 11.3% in success rate, mainly thanks to the\nprogrammatic verification guarantee during the induction phase. ASI also\nimproves efficiency by reducing 10.7-15.3% of the steps over baselines, by\ncomposing primitive actions (e.g., click) into higher-level skills (e.g.,\nsearch product). We then highlight the efficacy of ASI in remaining efficient\nand accurate under scaled-up web activities. Finally, we examine the\ngeneralizability of induced skills when transferring between websites, and find\nthat ASI can effectively reuse common skills, while also updating incompatible\nskills to versatile website changes.", "published": "2025-04-09 12:25:37", "link": "http://arxiv.org/abs/2504.06821v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Graph Diffusion Algorithm for Lexical Similarity Evaluation", "abstract": "In this paper, we present an algorithm for evaluating lexical similarity\nbetween a given language and several reference language clusters. As an input,\nwe have a list of concepts and the corresponding translations in all considered\nlanguages. Moreover, each reference language is assigned to one of $c$ language\nclusters. For each of the concepts, the algorithm computes the distance between\neach pair of translations. Based on these distances, it constructs a weighted\ndirected graph, where every vertex represents a language. After, it solves a\ngraph diffusion equation with a Dirichlet boundary condition, where the unknown\nis a map from the vertex set to $\\mathbb{R}^c$. The resulting coordinates are\nvalues from the interval $[0,1]$ and they can be interpreted as probabilities\nof belonging to each of the clusters or as a lexical similarity distribution\nwith respect to the reference clusters. The distances between translations are\ncalculated using phonetic transcriptions and a modification of the\nDamerau-Levenshtein distance. The algorithm can be useful in analyzing\nrelationships between languages spoken in multilingual territories with a lot\nof mutual influences. We demonstrate this by presenting a case study regarding\nvarious European languages.", "published": "2025-04-09 12:17:08", "link": "http://arxiv.org/abs/2504.06816v1", "categories": ["cs.CL", "2020: 00A69, 05C90, 91F20"], "primary_category": "cs.CL"}
{"title": "Domain-Specific Pruning of Large Mixture-of-Experts Models with Few-shot Demonstrations", "abstract": "Mixture-of-Experts (MoE) models achieve a favorable trade-off between\nperformance and inference efficiency by activating only a subset of experts.\nHowever, the memory overhead of storing all experts remains a major limitation,\nespecially in large-scale MoE models such as DeepSeek-R1 (671B). In this study,\nwe investigate domain specialization and expert redundancy in large-scale MoE\nmodels and uncover a consistent behavior we term few-shot expert localization,\nwith only a few demonstrations, the model consistently activates a sparse and\nstable subset of experts. Building on this observation, we propose a simple yet\neffective pruning framework, EASY-EP, that leverages a few domain-specific\ndemonstrations to identify and retain only the most relevant experts. EASY-EP\ncomprises two key components: output-aware expert importance assessment and\nexpert-level token contribution estimation. The former evaluates the importance\nof each expert for the current token by considering the gating scores and\nmagnitudes of the outputs of activated experts, while the latter assesses the\ncontribution of tokens based on representation similarities after and before\nrouted experts. Experiments show that our method can achieve comparable\nperformances and $2.99\\times$ throughput under the same memory budget with full\nDeepSeek-R1 with only half the experts. Our code is available at\nhttps://github.com/RUCAIBox/EASYEP.", "published": "2025-04-09 11:34:06", "link": "http://arxiv.org/abs/2504.06792v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FamilyTool: A Multi-hop Personalized Tool Use Benchmark", "abstract": "The integration of tool learning with Large Language Models (LLMs) has\nexpanded their capabilities in handling complex tasks by leveraging external\ntools. However, existing benchmarks for tool learning inadequately address\ncritical real-world personalized scenarios, particularly those requiring\nmulti-hop reasoning and inductive knowledge adaptation in dynamic environments.\nTo bridge this gap, we introduce FamilyTool, a novel benchmark grounded in a\nfamily-based knowledge graph (KG) that simulates personalized, multi-hop tool\nuse scenarios. FamilyTool challenges LLMs with queries spanning 1 to 3\nrelational hops (e.g., inferring familial connections and preferences) and\nincorporates an inductive KG setting where models must adapt to unseen user\npreferences and relationships without re-training, a common limitation in prior\napproaches that compromises generalization. We further propose KGETool: a\nsimple KG-augmented evaluation pipeline to systematically assess LLMs' tool use\nability in these settings. Experiments reveal significant performance gaps in\nstate-of-the-art LLMs, with accuracy dropping sharply as hop complexity\nincreases and inductive scenarios exposing severe generalization deficits.\nThese findings underscore the limitations of current LLMs in handling\npersonalized, evolving real-world contexts and highlight the urgent need for\nadvancements in tool-learning frameworks. FamilyTool serves as a critical\nresource for evaluating and advancing LLM agents' reasoning, adaptability, and\nscalability in complex, dynamic environments. Code and dataset are available at\nGithub.", "published": "2025-04-09 10:42:36", "link": "http://arxiv.org/abs/2504.06766v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "CAT: Circular-Convolutional Attention for Sub-Quadratic Transformers", "abstract": "Transformers have driven remarkable breakthroughs in natural language\nprocessing and computer vision, yet their standard attention mechanism still\nimposes O(N^2) complexity, hindering scalability to longer sequences. We\nintroduce Circular-convolutional ATtention (CAT), a Fourier-based approach that\nefficiently applies circular convolutions to reduce complexity without\nsacrificing representational power. CAT achieves O(NlogN) computations,\nrequires fewer learnable parameters by streamlining fully-connected layers, and\nintroduces no heavier operations, resulting in consistent accuracy improvements\nand about a 10% speedup in naive PyTorch implementations on large-scale\nbenchmarks such as ImageNet-1k and WikiText-103. Grounded in an\nengineering-isomorphism framework, CAT's design not only offers practical\nefficiency and ease of implementation but also provides insights to guide the\ndevelopment of next-generation, high-performance Transformer architectures.\nFinally, our ablation studies highlight the key conditions underlying CAT's\nsuccess, shedding light on broader principles for scalable attention\nmechanisms.", "published": "2025-04-09 09:08:26", "link": "http://arxiv.org/abs/2504.06704v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "NLP Security and Ethics, in the Wild", "abstract": "As NLP models are used by a growing number of end-users, an area of\nincreasing importance is NLP Security (NLPSec): assessing the vulnerability of\nmodels to malicious attacks and developing comprehensive countermeasures\nagainst them. While work at the intersection of NLP and cybersecurity has the\npotential to create safer NLP for all, accidental oversights can result in\ntangible harm (e.g., breaches of privacy or proliferation of malicious models).\nIn this emerging field, however, the research ethics of NLP have not yet faced\nmany of the long-standing conundrums pertinent to cybersecurity, until now. We\nthus examine contemporary works across NLPSec, and explore their engagement\nwith cybersecurity's ethical norms. We identify trends across the literature,\nultimately finding alarming gaps on topics like harm minimization and\nresponsible disclosure. To alleviate these concerns, we provide concrete\nrecommendations to help NLP researchers navigate this space more ethically,\nbridging the gap between traditional cybersecurity and NLP ethics, which we\nframe as ``white hat NLP''. The goal of this work is to help cultivate an\nintentional culture of ethical research for those working in NLP Security.", "published": "2025-04-09 08:12:34", "link": "http://arxiv.org/abs/2504.06669v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SEE: Continual Fine-tuning with Sequential Ensemble of Experts", "abstract": "Continual fine-tuning of large language models (LLMs) suffers from\ncatastrophic forgetting. Rehearsal-based methods mitigate this problem by\nretaining a small set of old data. Nevertheless, they still suffer inevitable\nperformance loss. Although training separate experts for each task can help\nprevent forgetting, effectively assembling them remains a challenge. Some\napproaches use routers to assign tasks to experts, but in continual learning,\nthey often require retraining for optimal performance. To address these\nchallenges, we introduce the Sequential Ensemble of Experts (SEE) framework.\nSEE removes the need for an additional router, allowing each expert to\nindependently decide whether a query should be handled. The framework employs\ndistributed routing, and during continual fine-tuning, SEE only requires the\ntraining of new experts for incoming tasks rather than retraining the entire\nsystem. Experiments reveal that the SEE outperforms prior approaches, including\nmulti-task learning, in continual fine-tuning. It also demonstrates remarkable\ngeneralization ability, as the expert can effectively identify\nout-of-distribution queries, which can then be directed to a more generalized\nmodel for resolution. This work highlights the promising potential of\nintegrating routing and response mechanisms within each expert, paving the way\nfor the future of distributed model ensembling.", "published": "2025-04-09 07:56:56", "link": "http://arxiv.org/abs/2504.06664v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bridging the Gap Between Preference Alignment and Machine Unlearning", "abstract": "Despite advances in Preference Alignment (PA) for Large Language Models\n(LLMs), mainstream methods like Reinforcement Learning with Human Feedback\n(RLHF) face notable challenges. These approaches require high-quality datasets\nof positive preference examples, which are costly to obtain and computationally\nintensive due to training instability, limiting their use in low-resource\nscenarios. LLM unlearning technique presents a promising alternative, by\ndirectly removing the influence of negative examples. However, current research\nhas primarily focused on empirical validation, lacking systematic quantitative\nanalysis. To bridge this gap, we propose a framework to explore the\nrelationship between PA and LLM unlearning. Specifically, we introduce a\nbi-level optimization-based method to quantify the impact of unlearning\nspecific negative examples on PA performance. Our analysis reveals that not all\nnegative examples contribute equally to alignment improvement when unlearned,\nand the effect varies significantly across examples. Building on this insight,\nwe pose a crucial question: how can we optimally select and weight negative\nexamples for unlearning to maximize PA performance? To answer this, we propose\na framework called Unlearning to Align (U2A), which leverages bi-level\noptimization to efficiently select and unlearn examples for optimal PA\nperformance. We validate the proposed method through extensive experiments,\nwith results confirming its effectiveness.", "published": "2025-04-09 07:49:08", "link": "http://arxiv.org/abs/2504.06659v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Neuro-inspired Interpretation of Unlearning in Large Language Models through Sample-level Unlearning Difficulty", "abstract": "Driven by privacy protection laws and regulations, unlearning in Large\nLanguage Models (LLMs) is gaining increasing attention. However, current\nresearch often neglects the interpretability of the unlearning process,\nparticularly concerning sample-level unlearning difficulty. Existing studies\ntypically assume a uniform unlearning difficulty across samples. This\nsimplification risks attributing the performance of unlearning algorithms to\nsample selection rather than the algorithm's design, potentially steering the\ndevelopment of LLM unlearning in the wrong direction. Thus, we investigate the\nrelationship between LLM unlearning and sample characteristics, with a focus on\nunlearning difficulty. Drawing inspiration from neuroscience, we propose a\nMemory Removal Difficulty ($\\mathrm{MRD}$) metric to quantify sample-level\nunlearning difficulty. Using $\\mathrm{MRD}$, we analyze the characteristics of\nhard-to-unlearn versus easy-to-unlearn samples. Furthermore, we propose an\n$\\mathrm{MRD}$-based weighted sampling method to optimize existing unlearning\nalgorithms, which prioritizes easily forgettable samples, thereby improving\nunlearning efficiency and effectiveness. We validate the proposed metric and\nmethod using public benchmarks and datasets, with results confirming its\neffectiveness.", "published": "2025-04-09 07:48:10", "link": "http://arxiv.org/abs/2504.06658v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ThoughtProbe: Classifier-Guided Thought Space Exploration Leveraging LLM Intrinsic Reasoning", "abstract": "Pre-trained large language models (LLMs) have been demonstrated to possess\nintrinsic reasoning capabilities that can emerge naturally when expanding the\nresponse space. However, the neural representation mechanisms underlying these\nintrinsic capabilities and approaches for their optimal utilization remain\ninadequately understood. In this work, we make the key discovery that a simple\nlinear classifier can effectively detect intrinsic reasoning capabilities in\nLLMs' activation space, particularly within specific representation types and\nnetwork layers. Based on this finding, we propose a classifier-guided search\nframework that strategically explore a tree-structured response space. In each\nnode expansion, the classifier serves as a scoring and ranking mechanism that\nefficiently allocates computational resources by identifying and prioritizing\nmore thoughtful reasoning directions for continuation. After completing the\ntree expansion, we collect answers from all branches to form a candidate answer\npool. We propose a branch-aggregation selection method that marginalizes over\nall supporting branches by aggregating their thoughtfulness scores, thereby\nidentifying the optimal answer from the pool. Experimental results show that\nour framework's comprehensive exploration not only covers valid reasoning\nchains but also effectively identifies them, achieving significant improvements\nacross multiple arithmetic reasoning benchmarks.", "published": "2025-04-09 07:37:27", "link": "http://arxiv.org/abs/2504.06650v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Wanting to be Understood", "abstract": "This paper explores an intrinsic motivation for mutual awareness,\nhypothesizing that humans possess a fundamental drive to understand \\textit{and\nto be understood} even in the absence of extrinsic rewards. Through simulations\nof the perceptual crossing paradigm, we explore the effect of various internal\nreward functions in reinforcement learning agents. The drive to understand is\nimplemented as an active inference type artificial curiosity reward, whereas\nthe drive to be understood is implemented through intrinsic rewards for\nimitation, influence/impressionability, and sub-reaction time anticipation of\nthe other. Results indicate that while artificial curiosity alone does not lead\nto a preference for social interaction, rewards emphasizing reciprocal\nunderstanding successfully drive agents to prioritize interaction. We\ndemonstrate that this intrinsic motivation can facilitate cooperation in tasks\nwhere only one agent receives extrinsic reward for the behaviour of the other.", "published": "2025-04-09 06:15:24", "link": "http://arxiv.org/abs/2504.06611v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Automated Business Process Analysis: An LLM-Based Approach to Value Assessment", "abstract": "Business processes are fundamental to organizational operations, yet their\noptimization remains challenging due to the timeconsuming nature of manual\nprocess analysis. Our paper harnesses Large Language Models (LLMs) to automate\nvalue-added analysis, a qualitative process analysis technique that aims to\nidentify steps in the process that do not deliver value. To date, this\ntechnique is predominantly manual, time-consuming, and subjective. Our method\noffers a more principled approach which operates in two phases: first,\ndecomposing high-level activities into detailed steps to enable granular\nanalysis, and second, performing a value-added analysis to classify each step\naccording to Lean principles. This approach enables systematic identification\nof waste while maintaining the semantic understanding necessary for qualitative\nanalysis. We develop our approach using 50 business process models, for which\nwe collect and publish manual ground-truth labels. Our evaluation, comparing\nzero-shot baselines with more structured prompts reveals (a) a consistent\nbenefit of structured prompting and (b) promising performance for both tasks.\nWe discuss the potential for LLMs to augment human expertise in qualitative\nprocess analysis while reducing the time and subjectivity inherent in manual\napproaches.", "published": "2025-04-09 05:52:50", "link": "http://arxiv.org/abs/2504.06600v1", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Bypassing Safety Guardrails in LLMs Using Humor", "abstract": "In this paper, we show it is possible to bypass the safety guardrails of\nlarge language models (LLMs) through a humorous prompt including the unsafe\nrequest. In particular, our method does not edit the unsafe request and follows\na fixed template -- it is simple to implement and does not need additional LLMs\nto craft prompts. Extensive experiments show the effectiveness of our method\nacross different LLMs. We also show that both removing and adding more humor to\nour method can reduce its effectiveness -- excessive humor possibly distracts\nthe LLM from fulfilling its unsafe request. Thus, we argue that LLM\njailbreaking occurs when there is a proper balance between focus on the unsafe\nrequest and presence of humor.", "published": "2025-04-09 04:58:14", "link": "http://arxiv.org/abs/2504.06577v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning", "abstract": "Watermarking has emerged as a promising technique for detecting texts\ngenerated by LLMs. Current research has primarily focused on three design\ncriteria: high quality of the watermarked text, high detectability, and\nrobustness against removal attack. However, the security against spoofing\nattacks remains relatively understudied. For example, a piggyback attack can\nmaliciously alter the meaning of watermarked text-transforming it into hate\nspeech-while preserving the original watermark, thereby damaging the reputation\nof the LLM provider. We identify two core challenges that make defending\nagainst spoofing difficult: (1) the need for watermarks to be both sensitive to\nsemantic-distorting changes and insensitive to semantic-preserving edits, and\n(2) the contradiction between the need to detect global semantic shifts and the\nlocal, auto-regressive nature of most watermarking schemes. To address these\nchallenges, we propose a semantic-aware watermarking algorithm that post-hoc\nembeds watermarks into a given target text while preserving its original\nmeaning. Our method introduces a semantic mapping model, which guides the\ngeneration of a green-red token list, contrastively trained to be sensitive to\nsemantic-distorting changes and insensitive to semantic-preserving changes.\nExperiments on two standard benchmarks demonstrate strong robustness against\nremoval attacks and security against spoofing attacks, including sentiment\nreversal and toxic content insertion, while maintaining high watermark\ndetectability. Our approach offers a significant step toward more secure and\nsemantically aware watermarking for LLMs. Our code is available at\nhttps://github.com/UCSB-NLP-Chang/contrastive-watermark.", "published": "2025-04-09 04:38:17", "link": "http://arxiv.org/abs/2504.06575v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Do Reasoning Models Show Better Verbalized Calibration?", "abstract": "Large reasoning models (LRMs) have recently shown impressive capabilities in\ncomplex reasoning by leveraging increased test-time computation and exhibiting\nbehaviors akin to human-like deliberation. Despite these advances, it remains\nan open question whether LRMs are better calibrated - particularly in their\nverbalized confidence - compared to instruction-tuned counterparts. In this\npaper, we investigate the calibration properties of LRMs trained via supervised\nfine-tuning distillation on long reasoning traces (henceforth SFT reasoning\nmodels) and outcome-based reinforcement learning for reasoning (henceforth RL\nreasoning models) across diverse domains. Our findings reveal that LRMs\nsignificantly outperform instruction-tuned models on complex reasoning tasks in\nboth accuracy and confidence calibration. In contrast, we find surprising\ntrends in the domain of factuality in particular. On factuality tasks, while\nDeepseek-R1 shows strong calibration behavior, smaller QwQ-32B shows no\nimprovement over instruct models; moreover, SFT reasoning models display worse\ncalibration (greater overconfidence) compared to instruct models. Our results\nprovide evidence for a potentially critical role of reasoning-oriented RL\ntraining in improving LLMs' capacity for generating trustworthy, self-aware\noutputs.", "published": "2025-04-09 03:58:19", "link": "http://arxiv.org/abs/2504.06564v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FuseRL: Dense Preference Optimization for Heterogeneous Model Fusion", "abstract": "Heterogeneous model fusion enhances the performance of LLMs by integrating\nthe knowledge and capabilities of multiple structurally diverse models.\nHowever, existing approaches often rely solely on selecting the best output for\neach prompt from source models, which underutilizes their full potential due to\nlimited source knowledge and results in sparse optimization signals. To address\nthis limitation, we propose FuseRL, a novel two-stage framework comprising\nFuseSFT and FusePO to maximize the utilization of source LLMs. FuseSFT\nestablishes a robust initialization by integrating the strengths of\nheterogeneous source models through weighted supervised fine-tuning (SFT) on\ndiverse outputs for each prompt. FusePO optimizes weighted preferences based on\nthe outputs of multiple source models to enable superior alignment performance.\nExtensive experiments demonstrate the effectiveness of our framework across\nvarious preference alignment methods, including RLOO, DPO, and SimPO. Using\nLlama-3.1-8B-Instruct as the target model, our approach achieves\nstate-of-the-art performance among 8B LLMs on the AlpacaEval-2 and Arena-Hard\nbenchmarks. Further analysis suggests that FuseSFT regularizes the training\nprocess to reduce overfitting, while FusePO introduces dense and diverse\nsignals for preference optimization.", "published": "2025-04-09 03:51:53", "link": "http://arxiv.org/abs/2504.06562v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NeedleInATable: Exploring Long-Context Capability of Large Language Models towards Long-Structured Tables", "abstract": "Processing structured tabular data, particularly lengthy tables, constitutes\na fundamental yet challenging task for large language models (LLMs). However,\nexisting long-context benchmarks primarily focus on unstructured text,\nneglecting the challenges of long and complex structured tables. To address\nthis gap, we introduce NeedleInATable (NIAT), a novel task that treats each\ntable cell as a \"needle\" and requires the model to extract the target cell\nunder different queries. Evaluation results of mainstream LLMs on this\nbenchmark show they lack robust long-table comprehension, often relying on\nsuperficial correlations or shortcuts for complex table understanding tasks,\nrevealing significant limitations in processing intricate tabular data. To this\nend, we propose a data synthesis method to enhance models' long-table\ncomprehension capabilities. Experimental results show that our synthesized\ntraining data significantly enhances LLMs' performance on the NIAT task,\noutperforming both long-context LLMs and long-table agent methods. This work\nadvances the evaluation of LLMs' genuine long-structured table comprehension\ncapabilities and paves the way for progress in long-context and table\nunderstanding applications.", "published": "2025-04-09 03:46:56", "link": "http://arxiv.org/abs/2504.06560v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lugha-Llama: Adapting Large Language Models for African Languages", "abstract": "Large language models (LLMs) have achieved impressive results in a wide range\nof natural language applications. However, they often struggle to recognize\nlow-resource languages, in particular African languages, which are not well\nrepresented in large training corpora. In this paper, we consider how to adapt\nLLMs to low-resource African languages. We find that combining curated data\nfrom African languages with high-quality English educational texts results in a\ntraining mix that substantially improves the model's performance on these\nlanguages. On the challenging IrokoBench dataset, our models consistently\nachieve the best performance amongst similarly sized baselines, particularly on\nknowledge-intensive multiple-choice questions (AfriMMLU). Additionally, on the\ncross-lingual question answering benchmark AfriQA, our models outperform the\nbase model by over 10%. To better understand the role of English data during\ntraining, we translate a subset of 200M tokens into Swahili language and\nperform an analysis which reveals that the content of these data is primarily\nresponsible for the strong performance. We release our models and data to\nencourage future research on African languages.", "published": "2025-04-09 02:25:53", "link": "http://arxiv.org/abs/2504.06536v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CDER: Collaborative Evidence Retrieval for Document-level Relation Extraction", "abstract": "Document-level Relation Extraction (DocRE) involves identifying relations\nbetween entities across multiple sentences in a document. Evidence sentences,\ncrucial for precise entity pair relationships identification, enhance focus on\nessential text segments, improving DocRE performance. However, existing\nevidence retrieval systems often overlook the collaborative nature among\nsemantically similar entity pairs in the same document, hindering the\neffectiveness of the evidence retrieval task. To address this, we propose a\nnovel evidence retrieval framework, namely CDER. CDER employs an attentional\ngraph-based architecture to capture collaborative patterns and incorporates a\ndynamic sub-structure for additional robustness in evidence retrieval.\nExperimental results on the benchmark DocRE dataset show that CDER not only\nexcels in the evidence retrieval task but also enhances overall performance of\nexisting DocRE system.", "published": "2025-04-09 02:10:21", "link": "http://arxiv.org/abs/2504.06529v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Missing Premise exacerbates Overthinking: Are Reasoning Models losing Critical Thinking Skill?", "abstract": "We find that the response length of reasoning LLMs, whether trained by\nreinforcement learning or supervised learning, drastically increases for\nill-posed questions with missing premises (MiP), ending up with redundant and\nineffective thinking. This newly introduced scenario exacerbates the general\noverthinking issue to a large extent, which we name as the MiP-Overthinking.\nSuch failures are against the ``test-time scaling law'' but have been widely\nobserved on multiple datasets we curated with MiP, indicating the harm of cheap\noverthinking and a lack of critical thinking. Surprisingly, LLMs not\nspecifically trained for reasoning exhibit much better performance on the MiP\nscenario, producing much shorter responses that quickly identify ill-posed\nqueries. This implies a critical flaw of the current training recipe for\nreasoning LLMs, which does not encourage efficient thinking adequately, leading\nto the abuse of thinking patterns. To further investigate the reasons behind\nsuch failures, we conduct fine-grained analyses of the reasoning length,\noverthinking patterns, and location of critical thinking on different types of\nLLMs. Moreover, our extended ablation study reveals that the overthinking is\ncontagious through the distillation of reasoning models' responses. These\nresults improve the understanding of overthinking and shed novel insights into\nmitigating the problem.", "published": "2025-04-09 01:25:27", "link": "http://arxiv.org/abs/2504.06514v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Are We Done with Object-Centric Learning?", "abstract": "Object-centric learning (OCL) seeks to learn representations that only encode\nan object, isolated from other objects or background cues in a scene. This\napproach underpins various aims, including out-of-distribution (OOD)\ngeneralization, sample-efficient composition, and modeling of structured\nenvironments. Most research has focused on developing unsupervised mechanisms\nthat separate objects into discrete slots in the representation space,\nevaluated using unsupervised object discovery. However, with recent\nsample-efficient segmentation models, we can separate objects in the pixel\nspace and encode them independently. This achieves remarkable zero-shot\nperformance on OOD object discovery benchmarks, is scalable to foundation\nmodels, and can handle a variable number of slots out-of-the-box. Hence, the\ngoal of OCL methods to obtain object-centric representations has been largely\nachieved. Despite this progress, a key question remains: How does the ability\nto separate objects within a scene contribute to broader OCL objectives, such\nas OOD generalization? We address this by investigating the OOD generalization\nchallenge caused by spurious background cues through the lens of OCL. We\npropose a novel, training-free probe called $\\textbf{Object-Centric\nClassification with Applied Masks (OCCAM)}$, demonstrating that\nsegmentation-based encoding of individual objects significantly outperforms\nslot-based OCL methods. However, challenges in real-world applications remain.\nWe provide the toolbox for the OCL community to use scalable object-centric\nrepresentations, and focus on practical applications and fundamental questions,\nsuch as understanding object perception in human cognition. Our code is\navailable $\\href{https://github.com/AlexanderRubinstein/OCCAM}{here}$.", "published": "2025-04-09 17:59:05", "link": "http://arxiv.org/abs/2504.07092v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "AssistanceZero: Scalably Solving Assistance Games", "abstract": "Assistance games are a promising alternative to reinforcement learning from\nhuman feedback (RLHF) for training AI assistants. Assistance games resolve key\ndrawbacks of RLHF, such as incentives for deceptive behavior, by explicitly\nmodeling the interaction between assistant and user as a two-player game where\nthe assistant cannot observe their shared goal. Despite their potential,\nassistance games have only been explored in simple settings. Scaling them to\nmore complex environments is difficult because it requires both solving\nintractable decision-making problems under uncertainty and accurately modeling\nhuman users' behavior. We present the first scalable approach to solving\nassistance games and apply it to a new, challenging Minecraft-based assistance\ngame with over $10^{400}$ possible goals. Our approach, AssistanceZero, extends\nAlphaZero with a neural network that predicts human actions and rewards,\nenabling it to plan under uncertainty. We show that AssistanceZero outperforms\nmodel-free RL algorithms and imitation learning in the Minecraft-based\nassistance game. In a human study, our AssistanceZero-trained assistant\nsignificantly reduces the number of actions participants take to complete\nbuilding tasks in Minecraft. Our results suggest that assistance games are a\ntractable framework for training effective AI assistants in complex\nenvironments. Our code and models are available at\nhttps://github.com/cassidylaidlaw/minecraft-building-assistance-game.", "published": "2025-04-09 17:59:03", "link": "http://arxiv.org/abs/2504.07091v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "$\u03a0$-NeSy: A Possibilistic Neuro-Symbolic Approach", "abstract": "In this article, we introduce a neuro-symbolic approach that combines a\nlow-level perception task performed by a neural network with a high-level\nreasoning task performed by a possibilistic rule-based system. The goal is to\nbe able to derive for each input instance the degree of possibility that it\nbelongs to a target (meta-)concept. This (meta-)concept is connected to\nintermediate concepts by a possibilistic rule-based system. The probability of\neach intermediate concept for the input instance is inferred using a neural\nnetwork. The connection between the low-level perception task and the\nhigh-level reasoning task lies in the transformation of neural network outputs\nmodeled by probability distributions (through softmax activation) into\npossibility distributions. The use of intermediate concepts is valuable for the\nexplanation purpose: using the rule-based system, the classification of an\ninput instance as an element of the (meta-)concept can be justified by the fact\nthat intermediate concepts have been recognized.\n  From the technical side, our contribution consists of the design of efficient\nmethods for defining the matrix relation and the equation system associated\nwith a possibilistic rule-based system. The corresponding matrix and equation\nare key data structures used to perform inferences from a possibilistic\nrule-based system and to learn the values of the rule parameters in such a\nsystem according to a training data sample. Furthermore, leveraging recent\nresults on the handling of inconsistent systems of fuzzy relational equations,\nan approach for learning rule parameters according to multiple training data\nsamples is presented. Experiments carried out on the MNIST addition problems\nand the MNIST Sudoku puzzles problems highlight the effectiveness of our\napproach compared with state-of-the-art neuro-symbolic ones.", "published": "2025-04-09 17:16:23", "link": "http://arxiv.org/abs/2504.07055v1", "categories": ["cs.AI", "cs.LG", "cs.LO"], "primary_category": "cs.AI"}
{"title": "RayFronts: Open-Set Semantic Ray Frontiers for Online Scene Understanding and Exploration", "abstract": "Open-set semantic mapping is crucial for open-world robots. Current mapping\napproaches either are limited by the depth range or only map beyond-range\nentities in constrained settings, where overall they fail to combine\nwithin-range and beyond-range observations. Furthermore, these methods make a\ntrade-off between fine-grained semantics and efficiency. We introduce\nRayFronts, a unified representation that enables both dense and beyond-range\nefficient semantic mapping. RayFronts encodes task-agnostic open-set semantics\nto both in-range voxels and beyond-range rays encoded at map boundaries,\nempowering the robot to reduce search volumes significantly and make informed\ndecisions both within & beyond sensory range, while running at 8.84 Hz on an\nOrin AGX. Benchmarking the within-range semantics shows that RayFronts's\nfine-grained image encoding provides 1.34x zero-shot 3D semantic segmentation\nperformance while improving throughput by 16.5x. Traditionally, online mapping\nperformance is entangled with other system components, complicating evaluation.\nWe propose a planner-agnostic evaluation framework that captures the utility\nfor online beyond-range search and exploration, and show RayFronts reduces\nsearch volume 2.2x more efficiently than the closest online baselines.", "published": "2025-04-09 16:06:58", "link": "http://arxiv.org/abs/2504.06994v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Enhancing Metabolic Syndrome Prediction with Hybrid Data Balancing and Counterfactuals", "abstract": "Metabolic Syndrome (MetS) is a cluster of interrelated risk factors that\nsignificantly increases the risk of cardiovascular diseases and type 2\ndiabetes. Despite its global prevalence, accurate prediction of MetS remains\nchallenging due to issues such as class imbalance, data scarcity, and\nmethodological inconsistencies in existing studies. In this paper, we address\nthese challenges by systematically evaluating and optimizing machine learning\n(ML) models for MetS prediction, leveraging advanced data balancing techniques\nand counterfactual analysis. Multiple ML models, including XGBoost, Random\nForest, TabNet, etc., were trained and compared under various data balancing\ntechniques such as random oversampling (ROS), SMOTE, ADASYN, and CTGAN.\nAdditionally, we introduce MetaBoost, a novel hybrid framework that integrates\nSMOTE, ADASYN, and CTGAN, optimizing synthetic data generation through weighted\naveraging and iterative weight tuning to enhance the model's performance\n(achieving a 1.14% accuracy improvement over individual balancing techniques).\nA comprehensive counterfactual analysis is conducted to quantify feature-level\nchanges required to shift individuals from high-risk to low-risk categories.\nThe results indicate that blood glucose (50.3%) and triglycerides (46.7%) were\nthe most frequently modified features, highlighting their clinical significance\nin MetS risk reduction. Additionally, probabilistic analysis shows elevated\nblood glucose (85.5% likelihood) and triglycerides (74.9% posterior\nprobability) as the strongest predictors. This study not only advances the\nmethodological rigor of MetS prediction but also provides actionable insights\nfor clinicians and researchers, highlighting the potential of ML in mitigating\nthe public health burden of metabolic syndrome.", "published": "2025-04-09 15:51:10", "link": "http://arxiv.org/abs/2504.06987v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Efficient Self-Supervised Learning for Earth Observation via Dynamic Dataset Curation", "abstract": "Self-supervised learning (SSL) has enabled the development of vision\nfoundation models for Earth Observation (EO), demonstrating strong\ntransferability across diverse remote sensing tasks. While prior work has\nfocused on network architectures and training strategies, the role of dataset\ncuration, especially in balancing and diversifying pre-training datasets,\nremains underexplored. In EO, this challenge is amplified by the redundancy and\nheavy-tailed distributions common in satellite imagery, which can lead to\nbiased representations and inefficient training.\n  In this work, we propose a dynamic dataset pruning strategy designed to\nimprove SSL pre-training by maximizing dataset diversity and balance. Our\nmethod iteratively refines the training set without requiring a pre-existing\nfeature extractor, making it well-suited for domains where curated datasets are\nlimited or unavailable. We demonstrate our approach on the Sentinel-1 Wave Mode\n(WV) Synthetic Aperture Radar (SAR) archive, a challenging dataset dominated by\nocean observations. We train models from scratch on the entire Sentinel-1 WV\narchive spanning 10 years. Across three downstream tasks, our results show that\ndynamic pruning improves both computational efficiency and representation\nquality, leading to stronger transferability.\n  We also release the weights of Nereus-SAR-1, the first model in the Nereus\nfamily, a series of foundation models for ocean observation and analysis using\nSAR imagery, at github.com/galeio-research/nereus-sar-models/.", "published": "2025-04-09 15:13:26", "link": "http://arxiv.org/abs/2504.06962v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "abstract": "Agents powered by Large Language Models (LLMs) have recently demonstrated\nimpressive capabilities in various tasks. Still, they face limitations in tasks\nrequiring specific, structured knowledge, flexibility, or accountable\ndecision-making. While agents are capable of perceiving their environments,\nforming inferences, planning, and executing actions towards goals, they often\nface issues such as hallucinations and lack of contextual memory across\ninteractions. This paper explores how Case-Based Reasoning (CBR), a strategy\nthat solves new problems by referencing past experiences, can be integrated\ninto LLM agent frameworks. This integration allows LLMs to leverage explicit\nknowledge, enhancing their effectiveness. We systematically review the\ntheoretical foundations of these enhanced agents, identify critical framework\ncomponents, and formulate a mathematical model for the CBR processes of case\nretrieval, adaptation, and learning. We also evaluate CBR-enhanced agents\nagainst other methods like Chain-of-Thought reasoning and standard\nRetrieval-Augmented Generation, analyzing their relative strengths. Moreover,\nwe explore how leveraging CBR's cognitive dimensions (including\nself-reflection, introspection, and curiosity) via goal-driven autonomy\nmechanisms can further enhance the LLM agent capabilities. Contributing to the\nongoing research on neuro-symbolic hybrid systems, this work posits CBR as a\nviable technique for enhancing the reasoning skills and cognitive aspects of\nautonomous LLM agents.", "published": "2025-04-09 14:51:02", "link": "http://arxiv.org/abs/2504.06943v1", "categories": ["cs.AI", "cs.MA", "68", "I.2; I.2.7"], "primary_category": "cs.AI"}
{"title": "Beyond Tools: Generative AI as Epistemic Infrastructure in Education", "abstract": "As generative AI rapidly integrates into educational infrastructures\nworldwide, it transforms how knowledge gets created, validated, and shared, yet\ncurrent discourse inadequately addresses its implications as epistemic\ninfrastructure mediating teaching and learning. This paper investigates how AI\nsystems function as epistemic infrastructures in education and their impact on\nhuman epistemic agency. Adopting a situated cognition perspective and following\na value-sensitive design approach, the study conducts a technical investigation\nof two representative AI systems in educational settings, analyzing their\nimpact on teacher practice across three dimensions: affordances for skilled\nepistemic actions, support for epistemic sensitivity, and implications for\nlong-term habit formation. The analysis reveals that current AI systems\ninadequately support teachers' skilled epistemic actions, insufficiently foster\nepistemic sensitivity, and potentially cultivate problematic habits that\nprioritize efficiency over epistemic agency. To address these challenges, the\npaper recommends recognizing the infrastructural transformation occurring in\neducation, developing AI environments that stimulate skilled actions while\nupholding epistemic norms, and involving educators in AI design processes --\nrecommendations aimed at fostering AI integration that aligns with core\neducational values and maintains human epistemic agency.", "published": "2025-04-09 14:35:30", "link": "http://arxiv.org/abs/2504.06928v1", "categories": ["cs.CY", "cs.AI", "K.3.1; K.4.3; H.5.2"], "primary_category": "cs.CY"}
{"title": "Are Vision-Language Models Ready for Dietary Assessment? Exploring the Next Frontier in AI-Powered Food Image Recognition", "abstract": "Automatic dietary assessment based on food images remains a challenge,\nrequiring precise food detection, segmentation, and classification.\nVision-Language Models (VLMs) offer new possibilities by integrating visual and\ntextual reasoning. In this study, we evaluate six state-of-the-art VLMs\n(ChatGPT, Gemini, Claude, Moondream, DeepSeek, and LLaVA), analyzing their\ncapabilities in food recognition at different levels. For the experimental\nframework, we introduce the FoodNExTDB, a unique food image database that\ncontains 9,263 expert-labeled images across 10 categories (e.g., \"protein\nsource\"), 62 subcategories (e.g., \"poultry\"), and 9 cooking styles (e.g.,\n\"grilled\"). In total, FoodNExTDB includes 50k nutritional labels generated by\nseven experts who manually annotated all images in the database. Also, we\npropose a novel evaluation metric, Expert-Weighted Recall (EWR), that accounts\nfor the inter-annotator variability. Results show that closed-source models\noutperform open-source ones, achieving over 90% EWR in recognizing food\nproducts in images containing a single product. Despite their potential,\ncurrent VLMs face challenges in fine-grained food recognition, particularly in\ndistinguishing subtle differences in cooking styles and visually similar food\nitems, which limits their reliability for automatic dietary assessment. The\nFoodNExTDB database is publicly available at\nhttps://github.com/AI4Food/FoodNExtDB.", "published": "2025-04-09 14:33:59", "link": "http://arxiv.org/abs/2504.06925v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Longitudinal Assessment of Lung Lesion Burden in CT", "abstract": "In the U.S., lung cancer is the second major cause of death. Early detection\nof suspicious lung nodules is crucial for patient treatment planning,\nmanagement, and improving outcomes. Many approaches for lung nodule\nsegmentation and volumetric analysis have been proposed, but few have looked at\nlongitudinal changes in total lung tumor burden. In this work, we trained two\n3D models (nnUNet) with and without anatomical priors to automatically segment\nlung lesions and quantified total lesion burden for each patient. The 3D model\nwithout priors significantly outperformed ($p < .001$) the model trained with\nanatomy priors. For detecting clinically significant lesions $>$ 1cm, a\nprecision of 71.3\\%, sensitivity of 68.4\\%, and F1-score of 69.8\\% was\nachieved. For segmentation, a Dice score of 77.1 $\\pm$ 20.3 and Hausdorff\ndistance error of 11.7 $\\pm$ 24.1 mm was obtained. The median lesion burden was\n6.4 cc (IQR: 2.1, 18.1) and the median volume difference between manual and\nautomated measurements was 0.02 cc (IQR: -2.8, 1.2). Agreements were also\nevaluated with linear regression and Bland-Altman plots. The proposed approach\ncan produce a personalized evaluation of the total tumor burden for a patient\nand facilitate interval change tracking over time.", "published": "2025-04-09 14:30:43", "link": "http://arxiv.org/abs/2504.06924v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Leveraging Anatomical Priors for Automated Pancreas Segmentation on Abdominal CT", "abstract": "An accurate segmentation of the pancreas on CT is crucial to identify\npancreatic pathologies and extract imaging-based biomarkers. However, prior\nresearch on pancreas segmentation has primarily focused on modifying the\nsegmentation model architecture or utilizing pre- and post-processing\ntechniques. In this article, we investigate the utility of anatomical priors to\nenhance the segmentation performance of the pancreas. Two 3D full-resolution\nnnU-Net models were trained, one with 8 refined labels from the public PANORAMA\ndataset, and another that combined them with labels derived from the public\nTotalSegmentator (TS) tool. The addition of anatomical priors resulted in a 6\\%\nincrease in Dice score ($p < .001$) and a 36.5 mm decrease in Hausdorff\ndistance for pancreas segmentation ($p < .001$). Moreover, the pancreas was\nalways detected when anatomy priors were used, whereas there were 8 instances\nof failed detections without their use. The use of anatomy priors shows promise\nfor pancreas segmentation and subsequent derivation of imaging biomarkers.", "published": "2025-04-09 14:29:08", "link": "http://arxiv.org/abs/2504.06921v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "An Analysis of Temporal Dropout in Earth Observation Time Series for Regression Tasks", "abstract": "Missing instances in time series data impose a significant challenge to deep\nlearning models, particularly in regression tasks. In the Earth Observation\nfield, satellite failure or cloud occlusion frequently results in missing\ntime-steps, introducing uncertainties in the predicted output and causing a\ndecline in predictive performance. While many studies address missing\ntime-steps through data augmentation to improve model robustness, the\nuncertainty arising at the input level is commonly overlooked. To address this\ngap, we introduce Monte Carlo Temporal Dropout (MC-TD), a method that\nexplicitly accounts for input-level uncertainty by randomly dropping time-steps\nduring inference using a predefined dropout ratio, thereby simulating the\neffect of missing data. To bypass the need for costly searches for the optimal\ndropout ratio, we extend this approach with Monte Carlo Concrete Temporal\nDropout (MC-ConcTD), a method that learns the optimal dropout distribution\ndirectly. Both MC-TD and MC-ConcTD are applied during inference, leveraging\nMonte Carlo sampling for uncertainty quantification. Experiments on three EO\ntime-series datasets demonstrate that MC-ConcTD improves predictive performance\nand uncertainty calibration compared to existing approaches. Additionally, we\nhighlight the advantages of adaptive dropout tuning over manual selection,\nmaking uncertainty quantification more robust and accessible for EO\napplications.", "published": "2025-04-09 14:23:04", "link": "http://arxiv.org/abs/2504.06915v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs", "abstract": "This paper presents MedSegFactory, a versatile medical synthesis framework\nthat generates high-quality paired medical images and segmentation masks across\nmodalities and tasks. It aims to serve as an unlimited data repository,\nsupplying image-mask pairs to enhance existing segmentation tools. The core of\nMedSegFactory is a dual-stream diffusion model, where one stream synthesizes\nmedical images and the other generates corresponding segmentation masks. To\nensure precise alignment between image-mask pairs, we introduce Joint\nCross-Attention (JCA), enabling a collaborative denoising paradigm by dynamic\ncross-conditioning between streams. This bidirectional interaction allows both\nrepresentations to guide each other's generation, enhancing consistency between\ngenerated pairs. MedSegFactory unlocks on-demand generation of paired medical\nimages and segmentation masks through user-defined prompts that specify the\ntarget labels, imaging modalities, anatomical regions, and pathological\nconditions, facilitating scalable and high-quality data generation. This new\nparadigm of medical image synthesis enables seamless integration into diverse\nmedical imaging workflows, enhancing both efficiency and accuracy. Extensive\nexperiments show that MedSegFactory generates data of superior quality and\nusability, achieving competitive or state-of-the-art performance in 2D and 3D\nsegmentation tasks while addressing data scarcity and regulatory constraints.", "published": "2025-04-09 13:56:05", "link": "http://arxiv.org/abs/2504.06897v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Audio-visual Event Localization on Portrait Mode Short Videos", "abstract": "Audio-visual event localization (AVEL) plays a critical role in multimodal\nscene understanding. While existing datasets for AVEL predominantly comprise\nlandscape-oriented long videos with clean and simple audio context, short\nvideos have become the primary format of online video content due to the the\nproliferation of smartphones. Short videos are characterized by\nportrait-oriented framing and layered audio compositions (e.g., overlapping\nsound effects, voiceovers, and music), which brings unique challenges\nunaddressed by conventional methods. To this end, we introduce AVE-PM, the\nfirst AVEL dataset specifically designed for portrait mode short videos,\ncomprising 25,335 clips that span 86 fine-grained categories with frame-level\nannotations. Beyond dataset creation, our empirical analysis shows that\nstate-of-the-art AVEL methods suffer an average 18.66% performance drop during\ncross-mode evaluation. Further analysis reveals two key challenges of different\nvideo formats: 1) spatial bias from portrait-oriented framing introduces\ndistinct domain priors, and 2) noisy audio composition compromise the\nreliability of audio modality. To address these issues, we investigate optimal\npreprocessing recipes and the impact of background music for AVEL on portrait\nmode videos. Experiments show that these methods can still benefit from\ntailored preprocessing and specialized model design, thus achieving improved\nperformance. This work provides both a foundational benchmark and actionable\ninsights for advancing AVEL research in the era of mobile-centric video\ncontent. Dataset and code will be released.", "published": "2025-04-09 13:38:40", "link": "http://arxiv.org/abs/2504.06884v1", "categories": ["cs.MM", "cs.AI", "cs.CV"], "primary_category": "cs.MM"}
{"title": "Compound and Parallel Modes of Tropical Convolutional Neural Networks", "abstract": "Convolutional neural networks have become increasingly deep and complex,\nleading to higher computational costs. While tropical convolutional neural\nnetworks (TCNNs) reduce multiplications, they underperform compared to standard\nCNNs. To address this, we propose two new variants - compound TCNN (cTCNN) and\nparallel TCNN (pTCNN)-that use combinations of tropical min-plus and max-plus\nkernels to replace traditional convolution kernels. This reduces\nmultiplications and balances efficiency with performance. Experiments on\nvarious datasets show that cTCNN and pTCNN match or exceed the performance of\nother CNN methods. Combining these with conventional CNNs in deeper\narchitectures also improves performance. We are further exploring simplified\nTCNN architectures that reduce parameters and multiplications with minimal\naccuracy loss, aiming for efficient and effective models.", "published": "2025-04-09 13:36:11", "link": "http://arxiv.org/abs/2504.06881v1", "categories": ["cs.CV", "cs.AI", "I.2.6"], "primary_category": "cs.CV"}
{"title": "GraspClutter6D: A Large-scale Real-world Dataset for Robust Perception and Grasping in Cluttered Scenes", "abstract": "Robust grasping in cluttered environments remains an open challenge in\nrobotics. While benchmark datasets have significantly advanced deep learning\nmethods, they mainly focus on simplistic scenes with light occlusion and\ninsufficient diversity, limiting their applicability to practical scenarios. We\npresent GraspClutter6D, a large-scale real-world grasping dataset featuring:\n(1) 1,000 highly cluttered scenes with dense arrangements (14.1 objects/scene,\n62.6\\% occlusion), (2) comprehensive coverage across 200 objects in 75\nenvironment configurations (bins, shelves, and tables) captured using four\nRGB-D cameras from multiple viewpoints, and (3) rich annotations including 736K\n6D object poses and 9.3B feasible robotic grasps for 52K RGB-D images. We\nbenchmark state-of-the-art segmentation, object pose estimation, and grasping\ndetection methods to provide key insights into challenges in cluttered\nenvironments. Additionally, we validate the dataset's effectiveness as a\ntraining resource, demonstrating that grasping networks trained on\nGraspClutter6D significantly outperform those trained on existing datasets in\nboth simulation and real-world experiments. The dataset, toolkit, and\nannotation tools are publicly available on our project website:\nhttps://sites.google.com/view/graspclutter6d.", "published": "2025-04-09 13:15:46", "link": "http://arxiv.org/abs/2504.06866v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "EIDT-V: Exploiting Intersections in Diffusion Trajectories for Model-Agnostic, Zero-Shot, Training-Free Text-to-Video Generation", "abstract": "Zero-shot, training-free, image-based text-to-video generation is an emerging\narea that aims to generate videos using existing image-based diffusion models.\nCurrent methods in this space require specific architectural changes to image\ngeneration models, which limit their adaptability and scalability. In contrast\nto such methods, we provide a model-agnostic approach. We use intersections in\ndiffusion trajectories, working only with the latent values. We could not\nobtain localized frame-wise coherence and diversity using only the intersection\nof trajectories. Thus, we instead use a grid-based approach. An in-context\ntrained LLM is used to generate coherent frame-wise prompts; another is used to\nidentify differences between frames. Based on these, we obtain a CLIP-based\nattention mask that controls the timing of switching the prompts for each grid\ncell. Earlier switching results in higher variance, while later switching\nresults in more coherence. Therefore, our approach can ensure appropriate\ncontrol between coherence and variance for the frames. Our approach results in\nstate-of-the-art performance while being more flexible when working with\ndiverse image-generation models. The empirical analysis using quantitative\nmetrics and user studies confirms our model's superior temporal consistency,\nvisual fidelity and user satisfaction, thus providing a novel way to obtain\ntraining-free, image-based text-to-video generation.", "published": "2025-04-09 13:11:09", "link": "http://arxiv.org/abs/2504.06861v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Adaptive Locally Linear Embedding", "abstract": "Manifold learning techniques, such as Locally linear embedding (LLE), are\ndesigned to preserve the local neighborhood structures of high-dimensional data\nduring dimensionality reduction. Traditional LLE employs Euclidean distance to\ndefine neighborhoods, which can struggle to capture the intrinsic geometric\nrelationships within complex data. A novel approach, Adaptive locally linear\nembedding(ALLE), is introduced to address this limitation by incorporating a\ndynamic, data-driven metric that enhances topological preservation. This method\nredefines the concept of proximity by focusing on topological neighborhood\ninclusion rather than fixed distances. By adapting the metric based on the\nlocal structure of the data, it achieves superior neighborhood preservation,\nparticularly for datasets with complex geometries and high-dimensional\nstructures. Experimental results demonstrate that ALLE significantly improves\nthe alignment between neighborhoods in the input and feature spaces, resulting\nin more accurate and topologically faithful embeddings. This approach advances\nmanifold learning by tailoring distance metrics to the underlying data,\nproviding a robust solution for capturing intricate relationships in\nhigh-dimensional datasets.", "published": "2025-04-09 12:40:13", "link": "http://arxiv.org/abs/2504.06829v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Learning in Spiking Neural Networks with a Calcium-based Hebbian Rule for Spike-timing-dependent Plasticity", "abstract": "Understanding how biological neural networks are shaped via local plasticity\nmechanisms can lead to energy-efficient and self-adaptive information\nprocessing systems, which promises to mitigate some of the current roadblocks\nin edge computing systems. While biology makes use of spikes to seamless use\nboth spike timing and mean firing rate to modulate synaptic strength, most\nmodels focus on one of the two. In this work, we present a Hebbian local\nlearning rule that models synaptic modification as a function of calcium traces\ntracking neuronal activity. We show how the rule reproduces results from spike\ntime and spike rate protocols from neuroscientific studies. Moreover, we use\nthe model to train spiking neural networks on MNIST digit recognition to show\nand explain what sort of mechanisms are needed to learn real-world patterns. We\nshow how our model is sensitive to correlated spiking activity and how this\nenables it to modulate the learning rate of the network without altering the\nmean firing rate of the neurons nor the hyparameters of the learning rule. To\nthe best of our knowledge, this is the first work that showcases how spike\ntiming and rate can be complementary in their role of shaping the connectivity\nof spiking neural networks.", "published": "2025-04-09 11:39:59", "link": "http://arxiv.org/abs/2504.06796v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "Zero-Shot Image-Based Large Language Model Approach to Road Pavement Monitoring", "abstract": "Effective and rapid evaluation of pavement surface condition is critical for\nprioritizing maintenance, ensuring transportation safety, and minimizing\nvehicle wear and tear. While conventional manual inspections suffer from\nsubjectivity, existing machine learning-based methods are constrained by their\nreliance on large and high-quality labeled datasets, which require significant\nresources and limit adaptability across varied road conditions. The\nrevolutionary advancements in Large Language Models (LLMs) present significant\npotential for overcoming these challenges. In this study, we propose an\ninnovative automated zero-shot learning approach that leverages the image\nrecognition and natural language understanding capabilities of LLMs to assess\nroad conditions effectively. Multiple LLM-based assessment models were\ndeveloped, employing prompt engineering strategies aligned with the Pavement\nSurface Condition Index (PSCI) standards. These models' accuracy and\nreliability were evaluated against official PSCI results, with an optimized\nmodel ultimately selected. Extensive tests benchmarked the optimized model\nagainst evaluations from various levels experts using Google Street View road\nimages. The results reveal that the LLM-based approach can effectively assess\nroad conditions, with the optimized model -employing comprehensive and\nstructured prompt engineering strategies -outperforming simpler configurations\nby achieving high accuracy and consistency, even surpassing expert evaluations.\nMoreover, successfully applying the optimized model to Google Street View\nimages demonstrates its potential for future city-scale deployments. These\nfindings highlight the transformative potential of LLMs in automating road\ndamage evaluations and underscore the pivotal role of detailed prompt\nengineering in achieving reliable assessments.", "published": "2025-04-09 11:19:17", "link": "http://arxiv.org/abs/2504.06785v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AI, Help Me Think$\\unicode{x2014}$but for Myself: Assisting People in Complex Decision-Making by Providing Different Kinds of Cognitive Support", "abstract": "How can we design AI tools that effectively support human decision-making by\ncomplementing and enhancing users' reasoning processes? Common\nrecommendation-centric approaches face challenges such as inappropriate\nreliance or a lack of integration with users' decision-making processes. Here,\nwe explore an alternative interaction model in which the AI outputs build upon\nusers' own decision-making rationales. We compare this approach, which we call\nExtendAI, with a recommendation-based AI. Participants in our mixed-methods\nuser study interacted with both AIs as part of an investment decision-making\ntask. We found that the AIs had different impacts, with ExtendAI integrating\nbetter into the decision-making process and people's own thinking and leading\nto slightly better outcomes. RecommendAI was able to provide more novel\ninsights while requiring less cognitive effort. We discuss the implications of\nthese and other findings along with three tensions of AI-assisted\ndecision-making which our study revealed.", "published": "2025-04-09 10:48:17", "link": "http://arxiv.org/abs/2504.06771v1", "categories": ["cs.HC", "cs.AI", "68, 91", "I.2; J.4"], "primary_category": "cs.HC"}
{"title": "Detect All-Type Deepfake Audio: Wavelet Prompt Tuning for Enhanced Auditory Perception", "abstract": "The rapid advancement of audio generation technologies has escalated the\nrisks of malicious deepfake audio across speech, sound, singing voice, and\nmusic, threatening multimedia security and trust. While existing\ncountermeasures (CMs) perform well in single-type audio deepfake detection\n(ADD), their performance declines in cross-type scenarios. This paper is\ndedicated to studying the alltype ADD task. We are the first to comprehensively\nestablish an all-type ADD benchmark to evaluate current CMs, incorporating\ncross-type deepfake detection across speech, sound, singing voice, and music.\nThen, we introduce the prompt tuning self-supervised learning (PT-SSL) training\nparadigm, which optimizes SSL frontend by learning specialized prompt tokens\nfor ADD, requiring 458x fewer trainable parameters than fine-tuning (FT).\nConsidering the auditory perception of different audio types,we propose the\nwavelet prompt tuning (WPT)-SSL method to capture type-invariant auditory\ndeepfake information from the frequency domain without requiring additional\ntraining parameters, thereby enhancing performance over FT in the all-type ADD\ntask. To achieve an universally CM, we utilize all types of deepfake audio for\nco-training. Experimental results demonstrate that WPT-XLSR-AASIST achieved the\nbest performance, with an average EER of 3.58% across all evaluation sets. The\ncode is available online.", "published": "2025-04-09 10:18:45", "link": "http://arxiv.org/abs/2504.06753v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "EDIT: Enhancing Vision Transformers by Mitigating Attention Sink through an Encoder-Decoder Architecture", "abstract": "In this paper, we propose EDIT (Encoder-Decoder Image Transformer), a novel\narchitecture designed to mitigate the attention sink phenomenon observed in\nVision Transformer models. Attention sink occurs when an excessive amount of\nattention is allocated to the [CLS] token, distorting the model's ability to\neffectively process image patches. To address this, we introduce a\nlayer-aligned encoder-decoder architecture, where the encoder utilizes\nself-attention to process image patches, while the decoder uses cross-attention\nto focus on the [CLS] token. Unlike traditional encoder-decoder framework,\nwhere the decoder depends solely on high-level encoder representations, EDIT\nallows the decoder to extract information starting from low-level features,\nprogressively refining the representation layer by layer. EDIT is naturally\ninterpretable demonstrated through sequential attention maps, illustrating the\nrefined, layer-by-layer focus on key image features. Experiments on ImageNet-1k\nand ImageNet-21k, along with transfer learning tasks, show that EDIT achieves\nconsistent performance improvements over DeiT3 models. These results highlight\nthe effectiveness of EDIT's design in addressing attention sink and improving\nvisual feature extraction.", "published": "2025-04-09 09:51:41", "link": "http://arxiv.org/abs/2504.06738v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Learning global control of underactuated systems with Model-Based Reinforcement Learning", "abstract": "This short paper describes our proposed solution for the third edition of the\n\"AI Olympics with RealAIGym\" competition, held at ICRA 2025. We employed\nMonte-Carlo Probabilistic Inference for Learning Control (MC-PILCO), an MBRL\nalgorithm recognized for its exceptional data efficiency across various\nlow-dimensional robotic tasks, including cart-pole, ball \\& plate, and Furuta\npendulum systems. MC-PILCO optimizes a system dynamics model using interaction\ndata, enabling policy refinement through simulation rather than direct system\ndata optimization. This approach has proven highly effective in physical\nsystems, offering greater data efficiency than Model-Free (MF) alternatives.\nNotably, MC-PILCO has previously won the first two editions of this\ncompetition, demonstrating its robustness in both simulated and real-world\nenvironments. Besides briefly reviewing the algorithm, we discuss the most\ncritical aspects of the MC-PILCO implementation in the tasks at hand: learning\na global policy for the pendubot and acrobot systems.", "published": "2025-04-09 09:20:37", "link": "http://arxiv.org/abs/2504.06721v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Masked Scene Modeling: Narrowing the Gap Between Supervised and Self-Supervised Learning in 3D Scene Understanding", "abstract": "Self-supervised learning has transformed 2D computer vision by enabling\nmodels trained on large, unannotated datasets to provide versatile\noff-the-shelf features that perform similarly to models trained with labels.\nHowever, in 3D scene understanding, self-supervised methods are typically only\nused as a weight initialization step for task-specific fine-tuning, limiting\ntheir utility for general-purpose feature extraction. This paper addresses this\nshortcoming by proposing a robust evaluation protocol specifically designed to\nassess the quality of self-supervised features for 3D scene understanding. Our\nprotocol uses multi-resolution feature sampling of hierarchical models to\ncreate rich point-level representations that capture the semantic capabilities\nof the model and, hence, are suitable for evaluation with linear probing and\nnearest-neighbor methods. Furthermore, we introduce the first self-supervised\nmodel that performs similarly to supervised models when only off-the-shelf\nfeatures are used in a linear probing setup. In particular, our model is\ntrained natively in 3D with a novel self-supervised approach based on a Masked\nScene Modeling objective, which reconstructs deep features of masked patches in\na bottom-up manner and is specifically tailored to hierarchical 3D models. Our\nexperiments not only demonstrate that our method achieves competitive\nperformance to supervised models, but also surpasses existing self-supervised\napproaches by a large margin. The model and training code can be found at our\nGithub repository (https://github.com/phermosilla/msm).", "published": "2025-04-09 09:19:49", "link": "http://arxiv.org/abs/2504.06719v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Hyperparameter Optimisation with Practical Interpretability and Explanation Methods in Probabilistic Curriculum Learning", "abstract": "Hyperparameter optimisation (HPO) is crucial for achieving strong performance\nin reinforcement learning (RL), as RL algorithms are inherently sensitive to\nhyperparameter settings. Probabilistic Curriculum Learning (PCL) is a\ncurriculum learning strategy designed to improve RL performance by structuring\nthe agent's learning process, yet effective hyperparameter tuning remains\nchallenging and computationally demanding. In this paper, we provide an\nempirical analysis of hyperparameter interactions and their effects on the\nperformance of a PCL algorithm within standard RL tasks, including point-maze\nnavigation and DC motor control. Using the AlgOS framework integrated with\nOptuna's Tree-Structured Parzen Estimator (TPE), we present strategies to\nrefine hyperparameter search spaces, enhancing optimisation efficiency.\nAdditionally, we introduce a novel SHAP-based interpretability approach\ntailored specifically for analysing hyperparameter impacts, offering clear\ninsights into how individual hyperparameters and their interactions influence\nRL performance. Our work contributes practical guidelines and interpretability\ntools that significantly improve the effectiveness and computational\nfeasibility of hyperparameter optimisation in reinforcement learning.", "published": "2025-04-09 08:41:27", "link": "http://arxiv.org/abs/2504.06683v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "GRAIN: Multi-Granular and Implicit Information Aggregation Graph Neural Network for Heterophilous Graphs", "abstract": "Graph neural networks (GNNs) have shown significant success in learning graph\nrepresentations. However, recent studies reveal that GNNs often fail to\noutperform simple MLPs on heterophilous graph tasks, where connected nodes may\ndiffer in features or labels, challenging the homophily assumption. Existing\nmethods addressing this issue often overlook the importance of information\ngranularity and rarely consider implicit relationships between distant nodes.\nTo overcome these limitations, we propose the Granular and Implicit Graph\nNetwork (GRAIN), a novel GNN model specifically designed for heterophilous\ngraphs. GRAIN enhances node embeddings by aggregating multi-view information at\nvarious granularity levels and incorporating implicit data from distant,\nnon-neighboring nodes. This approach effectively integrates local and global\ninformation, resulting in smoother, more accurate node representations. We also\nintroduce an adaptive graph information aggregator that efficiently combines\nmulti-granularity and implicit data, significantly improving node\nrepresentation quality, as shown by experiments on 13 datasets covering varying\nhomophily and heterophily. GRAIN consistently outperforms 12 state-of-the-art\nmodels, excelling on both homophilous and heterophilous graphs.", "published": "2025-04-09 07:36:44", "link": "http://arxiv.org/abs/2504.06649v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "AMAD: AutoMasked Attention for Unsupervised Multivariate Time Series Anomaly Detection", "abstract": "Unsupervised multivariate time series anomaly detection (UMTSAD) plays a\ncritical role in various domains, including finance, networks, and sensor\nsystems. In recent years, due to the outstanding performance of deep learning\nin general sequential tasks, many models have been specialized for deep UMTSAD\ntasks and have achieved impressive results, particularly those based on the\nTransformer and self-attention mechanisms. However, the sequence anomaly\nassociation assumptions underlying these models are often limited to specific\npredefined patterns and scenarios, such as concentrated or peak anomaly\npatterns. These limitations hinder their ability to generalize to diverse\nanomaly situations, especially where the lack of labels poses significant\nchallenges. To address these issues, we propose AMAD, which integrates\n\\textbf{A}uto\\textbf{M}asked Attention for UMTS\\textbf{AD} scenarios. AMAD\nintroduces a novel structure based on the AutoMask mechanism and an attention\nmixup module, forming a simple yet generalized anomaly association\nrepresentation framework. This framework is further enhanced by a Max-Min\ntraining strategy and a Local-Global contrastive learning approach. By\ncombining multi-scale feature extraction with automatic relative association\nmodeling, AMAD provides a robust and adaptable solution to UMTSAD challenges.\nExtensive experimental results demonstrate that the proposed model achieving\ncompetitive performance results compared to SOTA benchmarks across a variety of\ndatasets.", "published": "2025-04-09 07:32:59", "link": "http://arxiv.org/abs/2504.06643v1", "categories": ["cs.LG", "cs.AI", "I.5.1"], "primary_category": "cs.LG"}
{"title": "InteractRank: Personalized Web-Scale Search Pre-Ranking with Cross Interaction Features", "abstract": "Modern search systems use a multi-stage architecture to deliver personalized\nresults efficiently. Key stages include retrieval, pre-ranking, full ranking,\nand blending, which refine billions of items to top selections. The pre-ranking\nstage, vital for scoring and filtering hundreds of thousands of items down to a\nfew thousand, typically relies on two tower models due to their computational\nefficiency, despite often lacking in capturing complex interactions. While\nquery-item cross interaction features are paramount for full ranking,\nintegrating them into pre-ranking models presents efficiency-related\nchallenges. In this paper, we introduce InteractRank, a novel two tower\npre-ranking model with robust cross interaction features used at Pinterest. By\nincorporating historical user engagement-based query-item interactions in the\nscoring function along with the two tower dot product, InteractRank\nsignificantly boosts pre-ranking performance with minimal latency and\ncomputation costs. In real-world A/B experiments at Pinterest, InteractRank\nimproves the online engagement metric by 6.5% over a BM25 baseline and by 3.7%\nover a vanilla two tower baseline. We also highlight other components of\nInteractRank, like real-time user-sequence modeling, and analyze their\ncontributions through offline ablation studies. The code for InteractRank is\navailable at https://github.com/pinterest/atg-research/tree/main/InteractRank.", "published": "2025-04-09 06:13:58", "link": "http://arxiv.org/abs/2504.06609v1", "categories": ["cs.IR", "cs.AI", "cs.LG", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Right Prediction, Wrong Reasoning: Uncovering LLM Misalignment in RA Disease Diagnosis", "abstract": "Large language models (LLMs) offer a promising pre-screening tool, improving\nearly disease detection and providing enhanced healthcare access for\nunderprivileged communities. The early diagnosis of various diseases continues\nto be a significant challenge in healthcare, primarily due to the nonspecific\nnature of early symptoms, the shortage of expert medical practitioners, and the\nneed for prolonged clinical evaluations, all of which can delay treatment and\nadversely affect patient outcomes. With impressive accuracy in prediction\nacross a range of diseases, LLMs have the potential to revolutionize clinical\npre-screening and decision-making for various medical conditions. In this work,\nwe study the diagnostic capability of LLMs for Rheumatoid Arthritis (RA) with\nreal world patients data. Patient data was collected alongside diagnoses from\nmedical experts, and the performance of LLMs was evaluated in comparison to\nexpert diagnoses for RA disease prediction. We notice an interesting pattern in\ndisease diagnosis and find an unexpected \\textit{misalignment between\nprediction and explanation}. We conduct a series of multi-round analyses using\ndifferent LLM agents. The best-performing model accurately predicts rheumatoid\narthritis (RA) diseases approximately 95\\% of the time. However, when medical\nexperts evaluated the reasoning generated by the model, they found that nearly\n68\\% of the reasoning was incorrect. This study highlights a clear misalignment\nbetween LLMs high prediction accuracy and its flawed reasoning, raising\nimportant questions about relying on LLM explanations in clinical settings.\n\\textbf{LLMs provide incorrect reasoning to arrive at the correct answer for RA\ndisease diagnosis.}", "published": "2025-04-09 05:04:01", "link": "http://arxiv.org/abs/2504.06581v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Exploring Ordinal Bias in Action Recognition for Instructional Videos", "abstract": "Action recognition models have achieved promising results in understanding\ninstructional videos. However, they often rely on dominant, dataset-specific\naction sequences rather than true video comprehension, a problem that we define\nas ordinal bias. To address this issue, we propose two effective video\nmanipulation methods: Action Masking, which masks frames of frequently\nco-occurring actions, and Sequence Shuffling, which randomizes the order of\naction segments. Through comprehensive experiments, we demonstrate that current\nmodels exhibit significant performance drops when confronted with nonstandard\naction sequences, underscoring their vulnerability to ordinal bias. Our\nfindings emphasize the importance of rethinking evaluation strategies and\ndeveloping models capable of generalizing beyond fixed action patterns in\ndiverse instructional videos.", "published": "2025-04-09 05:03:51", "link": "http://arxiv.org/abs/2504.06580v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Attributes-aware Visual Emotion Representation Learning", "abstract": "Visual emotion analysis or recognition has gained considerable attention due\nto the growing interest in understanding how images can convey rich semantics\nand evoke emotions in human perception. However, visual emotion analysis poses\ndistinctive challenges compared to traditional vision tasks, especially due to\nthe intricate relationship between general visual features and the different\naffective states they evoke, known as the affective gap. Researchers have used\ndeep representation learning methods to address this challenge of extracting\ngeneralized features from entire images. However, most existing methods\noverlook the importance of specific emotional attributes such as brightness,\ncolorfulness, scene understanding, and facial expressions. Through this paper,\nwe introduce A4Net, a deep representation network to bridge the affective gap\nby leveraging four key attributes: brightness (Attribute 1), colorfulness\n(Attribute 2), scene context (Attribute 3), and facial expressions (Attribute\n4). By fusing and jointly training all aspects of attribute recognition and\nvisual emotion analysis, A4Net aims to provide a better insight into emotional\ncontent in images. Experimental results show the effectiveness of A4Net,\nshowcasing competitive performance compared to state-of-the-art methods across\ndiverse visual emotion datasets. Furthermore, visualizations of activation maps\ngenerated by A4Net offer insights into its ability to generalize across\ndifferent visual emotion datasets.", "published": "2025-04-09 05:00:43", "link": "http://arxiv.org/abs/2504.06578v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Societal Impacts Research Requires Benchmarks for Creative Composition Tasks", "abstract": "Foundation models that are capable of automating cognitive tasks represent a\npivotal technological shift, yet their societal implications remain unclear.\nThese systems promise exciting advances, yet they also risk flooding our\ninformation ecosystem with formulaic, homogeneous, and potentially misleading\nsynthetic content. Developing benchmarks grounded in real use cases where these\nrisks are most significant is therefore critical. Through a thematic analysis\nusing 2 million language model user prompts, we identify creative composition\ntasks as a prevalent usage category where users seek help with personal tasks\nthat require everyday creativity. Our fine-grained analysis identifies\nmismatches between current benchmarks and usage patterns among these tasks.\nCrucially, we argue that the same use cases that currently lack thorough\nevaluations can lead to negative downstream impacts. This position paper argues\nthat benchmarks focused on creative composition tasks is a necessary step\ntowards understanding the societal harms of AI-generated content. We call for\ngreater transparency in usage patterns to inform the development of new\nbenchmarks that can effectively measure both the progress and the impacts of\nmodels with creative capabilities.", "published": "2025-04-09 03:12:16", "link": "http://arxiv.org/abs/2504.06549v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Polygon: Symbolic Reasoning for SQL using Conflict-Driven Under-Approximation Search", "abstract": "We present a novel symbolic reasoning engine for SQL which can efficiently\ngenerate an input $I$ for $n$ queries $P_1, \\cdots, P_n$, such that their\noutputs on $I$ satisfy a given property (expressed in SMT). This is useful in\ndifferent contexts, such as disproving equivalence of two SQL queries and\ndisambiguating a set of queries. Our first idea is to reason about an\nunder-approximation of each $P_i$ -- that is, a subset of $P_i$'s input-output\nbehaviors. While it makes our approach both semantics-aware and lightweight,\nthis idea alone is incomplete (as a fixed under-approximation might miss some\nbehaviors of interest). Therefore, our second idea is to perform search over an\nexpressive family of under-approximations (which collectively cover all program\nbehaviors of interest), thereby making our approach complete. We have\nimplemented these ideas in a tool, Polygon, and evaluated it on over 30,000\nbenchmarks across two tasks (namely, SQL equivalence refutation and query\ndisambiguation). Our evaluation results show that Polygon significantly\noutperforms all prior techniques.", "published": "2025-04-09 02:46:52", "link": "http://arxiv.org/abs/2504.06542v1", "categories": ["cs.PL", "cs.AI", "cs.DB", "cs.SE"], "primary_category": "cs.PL"}
{"title": "OPAL: Encoding Causal Understanding of Physical Systems for Robot Learning", "abstract": "We present OPAL (Operant Physical Agent with Language), a novel\nvision-language-action architecture that introduces topological constraints to\nflow matching for robotic control. To do so, we further introduce topological\nattention. Our approach models action sequences as topologically-structured\nrepresentations with non-trivial constraints. Experimental results across 10\ncomplex manipulation tasks demonstrate OPAL's superior performance compared to\nprevious approaches, including Octo, OpenVLA, and ${\\pi}$0.\n  Our architecture achieves significant improvements in zero-shot performance\nwithout requiring task-specific fine-tuning, while reducing inference\ncomputational requirements by 42%. The theoretical guarantees provided by our\ntopological approach result in more coherent long-horizon action sequences. Our\nresults highlight the potential of constraining the search space of learning\nproblems in robotics by deriving from fundamental physical laws, and the\npossibility of using topological attention to embed causal understanding into\ntransformer architectures.", "published": "2025-04-09 02:29:36", "link": "http://arxiv.org/abs/2504.06538v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Flexible Graph Similarity Computation With A Proactive Optimization Strategy", "abstract": "Graph Edit Distance (GED) is an important similarity measure in graph\nretrieval, which quantifies the minimum cost of transforming one graph into\nanother through edit operations, and offers flexibility by allowing\ncustomizable operation costs. Recent learning-based approaches approximate GEDs\nwith the distances between representations in vector spaces. However, these\nmethods often struggle with varying operation costs due to neglecting the\nimpact of these costs on determining optimal graph mappings. Furthermore, they\nrely on isolated node distances as guidance, necessitating inefficient reactive\nrefinements of mappings. To address these issues, we propose Graph Edit Network\n(GEN), a novel learning-based approach for flexible GED computation. By\nidentifying the limitations of existing methods in capturing flexibility of\nGED, we introduce a principled yet simple solution that incorporates the\noperation costs before establishing mappings. To improve matching efficiency,\nwe propose a strategy that proactively optimizes guidance from a graph\nperspective. This strategy initializes guidance as each node's alignment\ndifficulty and captures the interdependencies between matches within and across\ngraphs through a difficulty propagation mechanism, enabling more informed\ndecisions. As a result, GEN selects optimal matches in a single step,\nminimizing the need for costly refinements. Results on real-world and synthetic\ndatasets demonstrate the effectiveness, time efficiency, and adaptability of\nGEN, achieving up to 37.8\\% error reduction and 72.7\\% inference time reduction\ncompared with state-of-the-art models, while performing robustly under varying\ncost settings and graph sizes.", "published": "2025-04-09 02:16:46", "link": "http://arxiv.org/abs/2504.06533v1", "categories": ["cs.LG", "cs.AI", "cs.DS"], "primary_category": "cs.LG"}
{"title": "WaveHiTS: Wavelet-Enhanced Hierarchical Time Series Modeling for Wind Direction Nowcasting in Eastern Inner Mongolia", "abstract": "Wind direction forecasting plays a crucial role in optimizing wind energy\nproduction, but faces significant challenges due to the circular nature of\ndirectional data, error accumulation in multi-step forecasting, and complex\nmeteorological interactions. This paper presents a novel model, WaveHiTS, which\nintegrates wavelet transform with Neural Hierarchical Interpolation for Time\nSeries to address these challenges. Our approach decomposes wind direction into\nU-V components, applies wavelet transform to capture multi-scale frequency\npatterns, and utilizes a hierarchical structure to model temporal dependencies\nat multiple scales, effectively mitigating error propagation. Experiments\nconducted on real-world meteorological data from Inner Mongolia, China\ndemonstrate that WaveHiTS significantly outperforms deep learning models (RNN,\nLSTM, GRU), transformer-based approaches (TFT, Informer, iTransformer), and\nhybrid models (EMD-LSTM). The proposed model achieves RMSE values of\napproximately 19.2{\\deg}-19.4{\\deg} compared to 56{\\deg}-64{\\deg} for deep\nlearning recurrent models, maintaining consistent accuracy across all\nforecasting steps up to 60 minutes ahead. Moreover, WaveHiTS demonstrates\nsuperior robustness with vector correlation coefficients (VCC) of 0.985-0.987\nand hit rates of 88.5%-90.1%, substantially outperforming baseline models.\nAblation studies confirm that each component-wavelet transform, hierarchical\nstructure, and U-V decomposition-contributes meaningfully to overall\nperformance. These improvements in wind direction nowcasting have significant\nimplications for enhancing wind turbine yaw control efficiency and grid\nintegration of wind energy.", "published": "2025-04-09 02:15:48", "link": "http://arxiv.org/abs/2504.06532v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Beyond Moore's Law: Harnessing the Redshift of Generative AI with Effective Hardware-Software Co-Design", "abstract": "For decades, Moore's Law has served as a steadfast pillar in computer\narchitecture and system design, promoting a clear abstraction between hardware\nand software. This traditional Moore's computing paradigm has deepened the rift\nbetween the two, enabling software developers to achieve near-exponential\nperformance gains often without needing to delve deeply into hardware-specific\noptimizations. Yet today, Moore's Law -- with its once relentless performance\ngains now diminished to incremental improvements -- faces inevitable physical\nbarriers. This stagnation necessitates a reevaluation of the conventional\nsystem design philosophy. The traditional decoupled system design philosophy,\nwhich maintains strict abstractions between hardware and software, is\nincreasingly obsolete. The once-clear boundary between software and hardware is\nrapidly dissolving, replaced by co-design. It is imperative for the computing\ncommunity to intensify its commitment to hardware-software co-design, elevating\nsystem abstractions to first-class citizens and reimagining design principles\nto satisfy the insatiable appetite of modern computing. Hardware-software\nco-design is not a recent innovation. To illustrate its historical evolution, I\nclassify its development into five relatively distinct ``epochs''. This post\nalso highlights the growing influence of the architecture community in\ninterdisciplinary teams -- particularly alongside ML researchers -- and\nexplores why current co-design paradigms are struggling in today's computing\nlandscape. Additionally, I will examine the concept of the ``hardware lottery''\nand explore directions to mitigate its constraining influence on the next era\nof computing innovation.", "published": "2025-04-09 02:10:58", "link": "http://arxiv.org/abs/2504.06531v1", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "TSP-OCS: A Time-Series Prediction for Optimal Camera Selection in Multi-Viewpoint Surgical Video Analysis", "abstract": "Recording the open surgery process is essential for educational and medical\nevaluation purposes; however, traditional single-camera methods often face\nchallenges such as occlusions caused by the surgeon's head and body, as well as\nlimitations due to fixed camera angles, which reduce comprehensibility of the\nvideo content. This study addresses these limitations by employing a\nmulti-viewpoint camera recording system, capturing the surgical procedure from\nsix different angles to mitigate occlusions. We propose a fully supervised\nlearning-based time series prediction method to choose the best shot sequences\nfrom multiple simultaneously recorded video streams, ensuring optimal\nviewpoints at each moment. Our time series prediction model forecasts future\ncamera selections by extracting and fusing visual and semantic features from\nsurgical videos using pre-trained models. These features are processed by a\ntemporal prediction network with TimeBlocks to capture sequential dependencies.\nA linear embedding layer reduces dimensionality, and a Softmax classifier\nselects the optimal camera view based on the highest probability. In our\nexperiments, we created five groups of open thyroidectomy videos, each with\nsimultaneous recordings from six different angles. The results demonstrate that\nour method achieves competitive accuracy compared to traditional supervised\nmethods, even when predicting over longer time horizons. Furthermore, our\napproach outperforms state-of-the-art time series prediction techniques on our\ndataset. This manuscript makes a unique contribution by presenting an\ninnovative framework that advances surgical video analysis techniques, with\nsignificant implications for improving surgical education and patient safety.", "published": "2025-04-09 02:07:49", "link": "http://arxiv.org/abs/2504.06527v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Power of the Pareto Front: Balancing Uncertain Rewards for Adaptive Experimentation in scanning probe microscopy", "abstract": "Automated experimentation has the potential to revolutionize scientific\ndiscovery, but its effectiveness depends on well-defined optimization targets,\nwhich are often uncertain or probabilistic in real-world settings. In this\nwork, we demonstrate the application of Multi-Objective Bayesian Optimization\n(MOBO) to balance multiple, competing rewards in autonomous experimentation.\nUsing scanning probe microscopy (SPM) imaging, one of the most widely used and\nfoundational SPM modes, we show that MOBO can optimize imaging parameters to\nenhance measurement quality, reproducibility, and efficiency. A key advantage\nof this approach is the ability to compute and analyze the Pareto front, which\nnot only guides optimization but also provides physical insights into the\ntrade-offs between different objectives. Additionally, MOBO offers a natural\nframework for human-in-the-loop decision-making, enabling researchers to\nfine-tune experimental trade-offs based on domain expertise. By standardizing\nhigh-quality, reproducible measurements and integrating human input into\nAI-driven optimization, this work highlights MOBO as a powerful tool for\nadvancing autonomous scientific discovery.", "published": "2025-04-09 01:59:31", "link": "http://arxiv.org/abs/2504.06525v1", "categories": ["cs.LG", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Continuous-Variable Quantum Encoding Techniques: A Comparative Study of Embedding Techniques and Their Impact on Machine Learning Performance", "abstract": "This study explores the intersection of continuous-variable quantum computing\n(CVQC) and classical machine learning, focusing on CVQC data encoding\ntechniques, including Displacement encoding and squeezing encoding, alongside\nInstantaneous Quantum Polynomial (IQP) encoding from discrete quantum\ncomputing. We perform an extensive empirical analysis to assess the impact of\nthese encoding methods on classical machine learning models, such as Logistic\nRegression, Support Vector Machines, K-Nearest Neighbors, and ensemble methods\nlike Random Forest and LightGBM. Our findings indicate that CVQC-based encoding\nmethods significantly enhance feature expressivity, resulting in improved\nclassification accuracy and F1 scores, especially in high-dimensional and\ncomplex datasets. However, these improvements come with varying computational\ncosts, which depend on the complexity of the encoding and the architecture of\nthe machine learning models. Additionally, we examine the trade-off between\nquantum expressibility and classical learnability, offering valuable insights\ninto the practical feasibility of incorporating these quantum encodings into\nreal-world applications. This study contributes to the growing body of research\non quantum-classical hybrid learning, emphasizing the role of CVQC in advancing\nquantum data representation and its integration into classical machine learning\nworkflows.", "published": "2025-04-09 00:00:45", "link": "http://arxiv.org/abs/2504.06497v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "FlashDepth: Real-time Streaming Video Depth Estimation at 2K Resolution", "abstract": "A versatile video depth estimation model should (1) be accurate and\nconsistent across frames, (2) produce high-resolution depth maps, and (3)\nsupport real-time streaming. We propose FlashDepth, a method that satisfies all\nthree requirements, performing depth estimation on a 2044x1148 streaming video\nat 24 FPS. We show that, with careful modifications to pretrained single-image\ndepth models, these capabilities are enabled with relatively little data and\ntraining. We evaluate our approach across multiple unseen datasets against\nstate-of-the-art depth models, and find that ours outperforms them in terms of\nboundary sharpness and speed by a significant margin, while maintaining\ncompetitive accuracy. We hope our model will enable various applications that\nrequire high-resolution depth, such as video editing, and online\ndecision-making, such as robotics.", "published": "2025-04-09 17:59:31", "link": "http://arxiv.org/abs/2504.07093v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GenDoP: Auto-regressive Camera Trajectory Generation as a Director of Photography", "abstract": "Camera trajectory design plays a crucial role in video production, serving as\na fundamental tool for conveying directorial intent and enhancing visual\nstorytelling. In cinematography, Directors of Photography meticulously craft\ncamera movements to achieve expressive and intentional framing. However,\nexisting methods for camera trajectory generation remain limited: Traditional\napproaches rely on geometric optimization or handcrafted procedural systems,\nwhile recent learning-based methods often inherit structural biases or lack\ntextual alignment, constraining creative synthesis. In this work, we introduce\nan auto-regressive model inspired by the expertise of Directors of Photography\nto generate artistic and expressive camera trajectories. We first introduce\nDataDoP, a large-scale multi-modal dataset containing 29K real-world shots with\nfree-moving camera trajectories, depth maps, and detailed captions in specific\nmovements, interaction with the scene, and directorial intent. Thanks to the\ncomprehensive and diverse database, we further train an auto-regressive,\ndecoder-only Transformer for high-quality, context-aware camera movement\ngeneration based on text guidance and RGBD inputs, named GenDoP. Extensive\nexperiments demonstrate that compared to existing methods, GenDoP offers better\ncontrollability, finer-grained trajectory adjustments, and higher motion\nstability. We believe our approach establishes a new standard for\nlearning-based cinematography, paving the way for future advancements in camera\ncontrol and filmmaking. Our project website:\nhttps://kszpxxzmc.github.io/GenDoP/.", "published": "2025-04-09 17:56:01", "link": "http://arxiv.org/abs/2504.07083v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Detecting AI-generated Artwork", "abstract": "The high efficiency and quality of artwork generated by Artificial\nIntelligence (AI) has created new concerns and challenges for human artists. In\nparticular, recent improvements in generative AI have made it difficult for\npeople to distinguish between human-generated and AI-generated art. In this\nresearch, we consider the potential utility of various types of Machine\nLearning (ML) and Deep Learning (DL) models in distinguishing AI-generated\nartwork from human-generated artwork. We focus on three challenging artistic\nstyles, namely, baroque, cubism, and expressionism. The learning models we test\nare Logistic Regression (LR), Support Vector Machine (SVM), Multilayer\nPerceptron (MLP), and Convolutional Neural Network (CNN). Our best experimental\nresults yield a multiclass accuracy of 0.8208 over six classes, and an\nimpressive accuracy of 0.9758 for the binary classification problem of\ndistinguishing AI-generated from human-generated art.", "published": "2025-04-09 17:50:07", "link": "http://arxiv.org/abs/2504.07078v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Teaching pathology foundation models to accurately predict gene expression with parameter efficient knowledge transfer", "abstract": "Gene expression profiling provides critical insights into cellular\nheterogeneity, biological processes and disease mechanisms. There has been an\nincreasing interest in computational approaches that can predict gene\nexpression directly from digitalized histopathology images. While image\nfoundation models have shown promise in a variety of pathology downstream\nanalysis, their performances on gene-expression prediction are still limited.\nExplicitly incorporating information from the transcriptomic models can help\nimage models to address domain shift, yet the fine-tuning and alignment of\nfoundation models can be expensive. In the work, we propose Parameter Efficient\nKnowledge trAnsfer (PEKA), a novel framework that leverages Block-Affine\nAdaptation and integrates knowledge distillation and structure alignment losses\nfor cross-modal knowledge transfer. We evaluated PEKA for gene expression\nprediction using multiple spatial transcriptomics datasets (comprising 206,123\nimage tiles with matched gene expression profiles) that encompassed various\ntypes of tissue. PEKA achieved at least 5\\% performance improvement over\nbaseline foundation models while also outperforming alternative\nparameter-efficient fine-tuning strategies. We will release the code, datasets\nand aligned models after peer-review to facilitate broader adoption and further\ndevelopment for parameter efficient model alignment.", "published": "2025-04-09 17:24:41", "link": "http://arxiv.org/abs/2504.07061v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generalized Semantic Contrastive Learning via Embedding Side Information for Few-Shot Object Detection", "abstract": "The objective of few-shot object detection (FSOD) is to detect novel objects\nwith few training samples. The core challenge of this task is how to construct\na generalized feature space for novel categories with limited data on the basis\nof the base category space, which could adapt the learned detection model to\nunknown scenarios. However, limited by insufficient samples for novel\ncategories, two issues still exist: (1) the features of the novel category are\neasily implicitly represented by the features of the base category, leading to\ninseparable classifier boundaries, (2) novel categories with fewer data are not\nenough to fully represent the distribution, where the model fine-tuning is\nprone to overfitting. To address these issues, we introduce the side\ninformation to alleviate the negative influences derived from the feature space\nand sample viewpoints and formulate a novel generalized feature representation\nlearning method for FSOD. Specifically, we first utilize embedding side\ninformation to construct a knowledge matrix to quantify the semantic\nrelationship between the base and novel categories. Then, to strengthen the\ndiscrimination between semantically similar categories, we further develop\ncontextual semantic supervised contrastive learning which embeds side\ninformation. Furthermore, to prevent overfitting problems caused by sparse\nsamples, a side-information guided region-aware masked module is introduced to\naugment the diversity of samples, which finds and abandons biased information\nthat discriminates between similar categories via counterfactual explanation,\nand refines the discriminative representation space further. Extensive\nexperiments using ResNet and ViT backbones on PASCAL VOC, MS COCO, LVIS V1,\nFSOD-1K, and FSVOD-500 benchmarks demonstrate that our model outperforms the\nprevious state-of-the-art methods, significantly improving the ability of FSOD\nin most shots/splits.", "published": "2025-04-09 17:24:05", "link": "http://arxiv.org/abs/2504.07060v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Distilling Textual Priors from LLM to Efficient Image Fusion", "abstract": "Multi-modality image fusion aims to synthesize a single, comprehensive image\nfrom multiple source inputs. Traditional approaches, such as CNNs and GANs,\noffer efficiency but struggle to handle low-quality or complex inputs. Recent\nadvances in text-guided methods leverage large model priors to overcome these\nlimitations, but at the cost of significant computational overhead, both in\nmemory and inference time. To address this challenge, we propose a novel\nframework for distilling large model priors, eliminating the need for text\nguidance during inference while dramatically reducing model size. Our framework\nutilizes a teacher-student architecture, where the teacher network incorporates\nlarge model priors and transfers this knowledge to a smaller student network\nvia a tailored distillation process. Additionally, we introduce spatial-channel\ncross-fusion module to enhance the model's ability to leverage textual priors\nacross both spatial and channel dimensions. Our method achieves a favorable\ntrade-off between computational efficiency and fusion quality. The distilled\nnetwork, requiring only 10\\% of the parameters and inference time of the\nteacher network, retains 90\\% of its performance and outperforms existing SOTA\nmethods. Extensive experiments demonstrate the effectiveness of our approach.\nThe implementation will be made publicly available as an open-source resource.", "published": "2025-04-09 16:44:19", "link": "http://arxiv.org/abs/2504.07029v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Glossy Object Reconstruction with Cost-effective Polarized Acquisition", "abstract": "The challenge of image-based 3D reconstruction for glossy objects lies in\nseparating diffuse and specular components on glossy surfaces from captured\nimages, a task complicated by the ambiguity in discerning lighting conditions\nand material properties using RGB data alone. While state-of-the-art methods\nrely on tailored and/or high-end equipment for data acquisition, which can be\ncumbersome and time-consuming, this work introduces a scalable\npolarization-aided approach that employs cost-effective acquisition tools. By\nattaching a linear polarizer to readily available RGB cameras, multi-view\npolarization images can be captured without the need for advance calibration or\nprecise measurements of the polarizer angle, substantially reducing system\nconstruction costs. The proposed approach represents polarimetric BRDF, Stokes\nvectors, and polarization states of object surfaces as neural implicit fields.\nThese fields, combined with the polarizer angle, are retrieved by optimizing\nthe rendering loss of input polarized images. By leveraging fundamental\nphysical principles for the implicit representation of polarization rendering,\nour method demonstrates superiority over existing techniques through\nexperiments in public datasets and real captured images on both reconstruction\nand novel view synthesis.", "published": "2025-04-09 16:38:51", "link": "http://arxiv.org/abs/2504.07025v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Latent Diffusion U-Net Representations Contain Positional Embeddings and Anomalies", "abstract": "Diffusion models have demonstrated remarkable capabilities in synthesizing\nrealistic images, spurring interest in using their representations for various\ndownstream tasks. To better understand the robustness of these representations,\nwe analyze popular Stable Diffusion models using representational similarity\nand norms. Our findings reveal three phenomena: (1) the presence of a learned\npositional embedding in intermediate representations, (2) high-similarity\ncorner artifacts, and (3) anomalous high-norm artifacts. These findings\nunderscore the need to further investigate the properties of diffusion model\nrepresentations before considering them for downstream tasks that require\nrobust features. Project page:\nhttps://jonasloos.github.io/sd-representation-anomalies", "published": "2025-04-09 16:26:26", "link": "http://arxiv.org/abs/2504.07008v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SIGMAN:Scaling 3D Human Gaussian Generation with Millions of Assets", "abstract": "3D human digitization has long been a highly pursued yet challenging task.\nExisting methods aim to generate high-quality 3D digital humans from single or\nmultiple views, but remain primarily constrained by current paradigms and the\nscarcity of 3D human assets. Specifically, recent approaches fall into several\nparadigms: optimization-based and feed-forward (both single-view regression and\nmulti-view generation with reconstruction). However, they are limited by slow\nspeed, low quality, cascade reasoning, and ambiguity in mapping low-dimensional\nplanes to high-dimensional space due to occlusion and invisibility,\nrespectively. Furthermore, existing 3D human assets remain small-scale,\ninsufficient for large-scale training. To address these challenges, we propose\na latent space generation paradigm for 3D human digitization, which involves\ncompressing multi-view images into Gaussians via a UV-structured VAE, along\nwith DiT-based conditional generation, we transform the ill-posed\nlow-to-high-dimensional mapping problem into a learnable distribution shift,\nwhich also supports end-to-end inference. In addition, we employ the multi-view\noptimization approach combined with synthetic data to construct the HGS-1M\ndataset, which contains $1$ million 3D Gaussian assets to support the\nlarge-scale training. Experimental results demonstrate that our paradigm,\npowered by large-scale training, produces high-quality 3D human Gaussians with\nintricate textures, facial details, and loose clothing deformation.", "published": "2025-04-09 15:38:18", "link": "http://arxiv.org/abs/2504.06982v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Wheat3DGS: In-field 3D Reconstruction, Instance Segmentation and Phenotyping of Wheat Heads with Gaussian Splatting", "abstract": "Automated extraction of plant morphological traits is crucial for supporting\ncrop breeding and agricultural management through high-throughput field\nphenotyping (HTFP). Solutions based on multi-view RGB images are attractive due\nto their scalability and affordability, enabling volumetric measurements that\n2D approaches cannot directly capture. While advanced methods like Neural\nRadiance Fields (NeRFs) have shown promise, their application has been limited\nto counting or extracting traits from only a few plants or organs. Furthermore,\naccurately measuring complex structures like individual wheat heads-essential\nfor studying crop yields-remains particularly challenging due to occlusions and\nthe dense arrangement of crop canopies in field conditions. The recent\ndevelopment of 3D Gaussian Splatting (3DGS) offers a promising alternative for\nHTFP due to its high-quality reconstructions and explicit point-based\nrepresentation. In this paper, we present Wheat3DGS, a novel approach that\nleverages 3DGS and the Segment Anything Model (SAM) for precise 3D instance\nsegmentation and morphological measurement of hundreds of wheat heads\nautomatically, representing the first application of 3DGS to HTFP. We validate\nthe accuracy of wheat head extraction against high-resolution laser scan data,\nobtaining per-instance mean absolute percentage errors of 15.1%, 18.3%, and\n40.2% for length, width, and volume. We provide additional comparisons to\nNeRF-based approaches and traditional Muti-View Stereo (MVS), demonstrating\nsuperior results. Our approach enables rapid, non-destructive measurements of\nkey yield-related traits at scale, with significant implications for\naccelerating crop breeding and improving our understanding of wheat\ndevelopment.", "published": "2025-04-09 15:31:42", "link": "http://arxiv.org/abs/2504.06978v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Deep Single Image Rectification Approach for Pan-Tilt-Zoom Cameras", "abstract": "Pan-Tilt-Zoom (PTZ) cameras with wide-angle lenses are widely used in\nsurveillance but often require image rectification due to their inherent\nnonlinear distortions. Current deep learning approaches typically struggle to\nmaintain fine-grained geometric details, resulting in inaccurate rectification.\nThis paper presents a Forward Distortion and Backward Warping Network\n(FDBW-Net), a novel framework for wide-angle image rectification. It begins by\nusing a forward distortion model to synthesize barrel-distorted images,\nreducing pixel redundancy and preventing blur. The network employs a pyramid\ncontext encoder with attention mechanisms to generate backward warping flows\ncontaining geometric details. Then, a multi-scale decoder is used to restore\ndistorted features and output rectified images. FDBW-Net's performance is\nvalidated on diverse datasets: public benchmarks, AirSim-rendered PTZ camera\nimagery, and real-scene PTZ camera datasets. It demonstrates that FDBW-Net\nachieves SOTA performance in distortion rectification, boosting the\nadaptability of PTZ cameras for practical visual applications.", "published": "2025-04-09 15:19:38", "link": "http://arxiv.org/abs/2504.06965v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Two by Two: Learning Multi-Task Pairwise Objects Assembly for Generalizable Robot Manipulation", "abstract": "3D assembly tasks, such as furniture assembly and component fitting, play a\ncrucial role in daily life and represent essential capabilities for future home\nrobots. Existing benchmarks and datasets predominantly focus on assembling\ngeometric fragments or factory parts, which fall short in addressing the\ncomplexities of everyday object interactions and assemblies. To bridge this\ngap, we present 2BY2, a large-scale annotated dataset for daily pairwise\nobjects assembly, covering 18 fine-grained tasks that reflect real-life\nscenarios, such as plugging into sockets, arranging flowers in vases, and\ninserting bread into toasters. 2BY2 dataset includes 1,034 instances and 517\npairwise objects with pose and symmetry annotations, requiring approaches that\nalign geometric shapes while accounting for functional and spatial\nrelationships between objects. Leveraging the 2BY2 dataset, we propose a\ntwo-step SE(3) pose estimation method with equivariant features for assembly\nconstraints. Compared to previous shape assembly methods, our approach achieves\nstate-of-the-art performance across all 18 tasks in the 2BY2 dataset.\nAdditionally, robot experiments further validate the reliability and\ngeneralization ability of our method for complex 3D assembly tasks.", "published": "2025-04-09 15:12:38", "link": "http://arxiv.org/abs/2504.06961v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning", "abstract": "Recent advancements in reinforcement learning have significantly advanced the\nreasoning capabilities of multimodal large language models (MLLMs). While\napproaches such as Group Relative Policy Optimization (GRPO) and rule-based\nreward mechanisms demonstrate promise in text and image domains, their\napplication to video understanding remains limited. This paper presents a\nsystematic exploration of Reinforcement Fine-Tuning (RFT) with GRPO for video\nMLLMs, aiming to enhance spatio-temporal perception while maintaining general\ncapabilities. Our experiments reveal that RFT is highly data-efficient for\ntask-specific improvements. Through multi-task RFT on spatio-temporal\nperception objectives with limited samples, we develop VideoChat-R1, a powerful\nvideo MLLM that achieves state-of-the-art performance on spatio-temporal\nperception tasks without sacrificing chat ability, while exhibiting emerging\nspatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1\nboosts performance several-fold in tasks like temporal grounding (+31.8) and\nobject tracking (+31.2). Additionally, it significantly improves on general QA\nbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9).\nOur findings underscore the potential of RFT for specialized task enhancement\nof Video MLLMs. We hope our work offers valuable insights for future RL\nresearch in video MLLMs.", "published": "2025-04-09 15:09:27", "link": "http://arxiv.org/abs/2504.06958v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Comparison of Deep Learning Methods for Cell Detection in Digital Cytology", "abstract": "Accurate and efficient cell detection is crucial in many biomedical image\nanalysis tasks. We evaluate the performance of several Deep Learning (DL)\nmethods for cell detection in Papanicolaou-stained cytological Whole Slide\nImages (WSIs), focusing on accuracy of predictions and computational\nefficiency. We examine recentoff-the-shelf algorithms as well as\ncustom-designed detectors, applying them to two datasets: the CNSeg Dataset and\nthe Oral Cancer (OC) Dataset. Our comparison includes well-established\nsegmentation methods such as StarDist, Cellpose, and the Segment Anything Model\n2 (SAM2), alongside centroid-based Fully Convolutional Regression Network\n(FCRN) approaches. We introduce a suitable evaluation metric to assess the\naccuracy of predictions based on the distance from ground truth positions. We\nalso explore the impact of dataset size and data augmentation techniques on\nmodel performance. Results show that centroid-based methods, particularly the\nImproved Fully Convolutional Regression Network (IFCRN) method, outperform\nsegmentation-based methods in terms of both detection accuracy and\ncomputational efficiency. This study highlights the potential of centroid-based\ndetectors as a preferred option for cell detection in resource-limited\nenvironments, offering faster processing times and lower GPU memory usage\nwithout compromising accuracy.", "published": "2025-04-09 15:08:12", "link": "http://arxiv.org/abs/2504.06957v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PathSegDiff: Pathology Segmentation using Diffusion model representations", "abstract": "Image segmentation is crucial in many computational pathology pipelines,\nincluding accurate disease diagnosis, subtyping, outcome, and survivability\nprediction. The common approach for training a segmentation model relies on a\npre-trained feature extractor and a dataset of paired image and mask\nannotations. These are used to train a lightweight prediction model that\ntranslates features into per-pixel classes. The choice of the feature extractor\nis central to the performance of the final segmentation model, and recent\nliterature has focused on finding tasks to pre-train the feature extractor. In\nthis paper, we propose PathSegDiff, a novel approach for histopathology image\nsegmentation that leverages Latent Diffusion Models (LDMs) as pre-trained\nfeatured extractors. Our method utilizes a pathology-specific LDM, guided by a\nself-supervised encoder, to extract rich semantic information from H\\&E stained\nhistopathology images. We employ a simple, fully convolutional network to\nprocess the features extracted from the LDM and generate segmentation masks.\nOur experiments demonstrate significant improvements over traditional methods\non the BCSS and GlaS datasets, highlighting the effectiveness of\ndomain-specific diffusion pre-training in capturing intricate tissue structures\nand enhancing segmentation accuracy in histopathology images.", "published": "2025-04-09 14:58:21", "link": "http://arxiv.org/abs/2504.06950v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "S-EO: A Large-Scale Dataset for Geometry-Aware Shadow Detection in Remote Sensing Applications", "abstract": "We introduce the S-EO dataset: a large-scale, high-resolution dataset,\ndesigned to advance geometry-aware shadow detection. Collected from diverse\npublic-domain sources, including challenge datasets and government providers\nsuch as USGS, our dataset comprises 702 georeferenced tiles across the USA,\neach covering 500x500 m. Each tile includes multi-date, multi-angle WorldView-3\npansharpened RGB images, panchromatic images, and a ground-truth DSM of the\narea obtained from LiDAR scans. For each image, we provide a shadow mask\nderived from geometry and sun position, a vegetation mask based on the NDVI\nindex, and a bundle-adjusted RPC model. With approximately 20,000 images, the\nS-EO dataset establishes a new public resource for shadow detection in remote\nsensing imagery and its applications to 3D reconstruction. To demonstrate the\ndataset's impact, we train and evaluate a shadow detector, showcasing its\nability to generalize, even to aerial images. Finally, we extend EO-NeRF - a\nstate-of-the-art NeRF approach for satellite imagery - to leverage our shadow\npredictions for improved 3D reconstructions.", "published": "2025-04-09 14:25:35", "link": "http://arxiv.org/abs/2504.06920v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UKBOB: One Billion MRI Labeled Masks for Generalizable 3D Medical Image Segmentation", "abstract": "In medical imaging, the primary challenge is collecting large-scale labeled\ndata due to privacy concerns, logistics, and high labeling costs. In this work,\nwe present the UK Biobank Organs and Bones (UKBOB), the largest labeled dataset\nof body organs, comprising 51,761 MRI 3D samples (equivalent to 17.9 million 2D\nimages) and more than 1.37 billion 2D segmentation masks of 72 organs, all\nbased on the UK Biobank MRI dataset. We utilize automatic labeling, introduce\nan automated label cleaning pipeline with organ-specific filters, and manually\nannotate a subset of 300 MRIs with 11 abdominal classes to validate the quality\n(referred to as UKBOB-manual). This approach allows for scaling up the dataset\ncollection while maintaining confidence in the labels. We further confirm the\nvalidity of the labels by demonstrating zero-shot generalization of trained\nmodels on the filtered UKBOB to other small labeled datasets from similar\ndomains (e.g., abdominal MRI). To further mitigate the effect of noisy labels,\nwe propose a novel method called Entropy Test-time Adaptation (ETTA) to refine\nthe segmentation output. We use UKBOB to train a foundation model, Swin-BOB,\nfor 3D medical image segmentation based on the Swin-UNetr architecture,\nachieving state-of-the-art results in several benchmarks in 3D medical imaging,\nincluding the BRATS brain MRI tumor challenge (with a 0.4% improvement) and the\nBTCV abdominal CT scan benchmark (with a 1.3% improvement). The pre-trained\nmodels and the code are available at https://emmanuelleb985.github.io/ukbob ,\nand the filtered labels will be made available with the UK Biobank.", "published": "2025-04-09 14:10:51", "link": "http://arxiv.org/abs/2504.06908v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ColorizeDiffusion v2: Enhancing Reference-based Sketch Colorization Through Separating Utilities", "abstract": "Reference-based sketch colorization methods have garnered significant\nattention due to their potential applications in the animation production\nindustry. However, most existing methods are trained with image triplets of\nsketch, reference, and ground truth that are semantically and spatially\nwell-aligned, while real-world references and sketches often exhibit\nsubstantial misalignment. This mismatch in data distribution between training\nand inference leads to overfitting, consequently resulting in spatial artifacts\nand significant degradation in overall colorization quality, limiting potential\napplications of current methods for general purposes. To address this\nlimitation, we conduct an in-depth analysis of the \\textbf{carrier}, defined as\nthe latent representation facilitating information transfer from reference to\nsketch. Based on this analysis, we propose a novel workflow that dynamically\nadapts the carrier to optimize distinct aspects of colorization. Specifically,\nfor spatially misaligned artifacts, we introduce a split cross-attention\nmechanism with spatial masks, enabling region-specific reference injection\nwithin the diffusion process. To mitigate semantic neglect of sketches, we\nemploy dedicated background and style encoders to transfer detailed reference\ninformation in the latent feature space, achieving enhanced spatial control and\nricher detail synthesis. Furthermore, we propose character-mask merging and\nbackground bleaching as preprocessing steps to improve foreground-background\nintegration and background generation. Extensive qualitative and quantitative\nevaluations, including a user study, demonstrate the superior performance of\nour proposed method compared to existing approaches. An ablation study further\nvalidates the efficacy of each proposed component.", "published": "2025-04-09 13:55:32", "link": "http://arxiv.org/abs/2504.06895v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MovSAM: A Single-image Moving Object Segmentation Framework Based on Deep Thinking", "abstract": "Moving object segmentation plays a vital role in understanding dynamic visual\nenvironments. While existing methods rely on multi-frame image sequences to\nidentify moving objects, single-image MOS is critical for applications like\nmotion intention prediction and handling camera frame drops. However,\nsegmenting moving objects from a single image remains challenging for existing\nmethods due to the absence of temporal cues. To address this gap, we propose\nMovSAM, the first framework for single-image moving object segmentation. MovSAM\nleverages a Multimodal Large Language Model (MLLM) enhanced with\nChain-of-Thought (CoT) prompting to search the moving object and generate text\nprompts based on deep thinking for segmentation. These prompts are cross-fused\nwith visual features from the Segment Anything Model (SAM) and a\nVision-Language Model (VLM), enabling logic-driven moving object segmentation.\nThe segmentation results then undergo a deep thinking refinement loop, allowing\nMovSAM to iteratively improve its understanding of the scene context and\ninter-object relationships with logical reasoning. This innovative approach\nenables MovSAM to segment moving objects in single images by considering scene\nunderstanding. We implement MovSAM in the real world to validate its practical\napplication and effectiveness for autonomous driving scenarios where the\nmulti-frame methods fail. Furthermore, despite the inherent advantage of\nmulti-frame methods in utilizing temporal information, MovSAM achieves\nstate-of-the-art performance across public MOS benchmarks, reaching 92.5\\% on\nJ\\&F. Our implementation will be available at\nhttps://github.com/IRMVLab/MovSAM.", "published": "2025-04-09 13:12:58", "link": "http://arxiv.org/abs/2504.06863v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CasTex: Cascaded Text-to-Texture Synthesis via Explicit Texture Maps and Physically-Based Shading", "abstract": "This work investigates text-to-texture synthesis using diffusion models to\ngenerate physically-based texture maps. We aim to achieve realistic model\nappearances under varying lighting conditions. A prominent solution for the\ntask is score distillation sampling. It allows recovering a complex texture\nusing gradient guidance given a differentiable rasterization and shading\npipeline. However, in practice, the aforementioned solution in conjunction with\nthe widespread latent diffusion models produces severe visual artifacts and\nrequires additional regularization such as implicit texture parameterization.\nAs a more direct alternative, we propose an approach using cascaded diffusion\nmodels for texture synthesis (CasTex). In our setup, score distillation\nsampling yields high-quality textures out-of-the box. In particular, we were\nable to omit implicit texture parameterization in favor of an explicit\nparameterization to improve the procedure. In the experiments, we show that our\napproach significantly outperforms state-of-the-art optimization-based\nsolutions on public texture synthesis benchmarks.", "published": "2025-04-09 13:08:30", "link": "http://arxiv.org/abs/2504.06856v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Classifying the Unknown: In-Context Learning for Open-Vocabulary Text and Symbol Recognition", "abstract": "We introduce Rosetta, a multimodal model that leverages Multimodal In-Context\nLearning (MICL) to classify sequences of novel script patterns in documents by\nleveraging minimal examples, thus eliminating the need for explicit retraining.\nTo enhance contextual learning, we designed a dataset generation process that\nensures varying degrees of contextual informativeness, improving the model's\nadaptability in leveraging context across different scenarios. A key strength\nof our method is the use of a Context-Aware Tokenizer (CAT), which enables\nopen-vocabulary classification. This allows the model to classify text and\nsymbol patterns across an unlimited range of classes, extending its\nclassification capabilities beyond the scope of its training alphabet of\npatterns. As a result, it unlocks applications such as the recognition of new\nalphabets and languages. Experiments on synthetic datasets demonstrate the\npotential of Rosetta to successfully classify Out-Of-Distribution visual\npatterns and diverse sets of alphabets and scripts, including but not limited\nto Chinese, Greek, Russian, French, Spanish, and Japanese.", "published": "2025-04-09 12:58:25", "link": "http://arxiv.org/abs/2504.06841v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box Vision-Language Models", "abstract": "Recent studies have introduced various approaches for prompt-tuning black-box\nvision-language models, referred to as black-box prompt-tuning (BBPT). While\nBBPT has demonstrated considerable potential, it is often found that many\nexisting methods require an excessive number of queries (i.e., function\nevaluations), which poses a significant challenge in real-world scenarios where\nthe number of allowed queries is limited. To tackle this issue, we propose\nZeroth-order Intrinsic-dimensional Prompt-tuning (ZIP), a novel approach that\nenables efficient and robust prompt optimization in a purely black-box setting.\nThe key idea of ZIP is to reduce the problem dimensionality and the variance of\nzeroth-order gradient estimates, such that the training is done fast with far\nless queries. We achieve this by re-parameterizing prompts in low-rank\nrepresentations and designing intrinsic-dimensional clipping of estimated\ngradients. We evaluate ZIP on 13+ vision-language tasks in standard benchmarks\nand show that it achieves an average improvement of approximately 6% in\nfew-shot accuracy and 48% in query efficiency compared to the best-performing\nalternative BBPT methods, establishing a new state of the art. Our ablation\nanalysis further shows that the proposed clipping mechanism is robust and\nnearly optimal, without the need to manually select the clipping threshold,\nmatching the result of expensive hyperparameter search.", "published": "2025-04-09 12:56:22", "link": "http://arxiv.org/abs/2504.06838v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Determining Fetal Orientations From Blind Sweep Ultrasound Video", "abstract": "Cognitive demands of fetal ultrasound examinations pose unique challenges\namong clinicians. With the goal of providing an assistive tool, we developed an\nautomated pipeline for predicting fetal orientation from ultrasound videos\nacquired following a simple blind sweep protocol. Leveraging on a pre-trained\nhead detection and segmentation model, this is achieved by first determining\nthe fetal presentation (cephalic or breech) with a template matching approach,\nfollowed by the fetal lie (facing left or right) by analyzing the spatial\ndistribution of segmented brain anatomies. Evaluation on a dataset of\nthird-trimester ultrasound scans demonstrated the promising accuracy of our\npipeline. This work distinguishes itself by introducing automated fetal lie\nprediction and by proposing an assistive paradigm that augments sonographer\nexpertise rather than replacing it. Future research will focus on enhancing\nacquisition efficiency, and exploring real-time clinical integration to improve\nworkflow and support for obstetric clinicians.", "published": "2025-04-09 12:51:15", "link": "http://arxiv.org/abs/2504.06836v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LVC: A Lightweight Compression Framework for Enhancing VLMs in Long Video Understanding", "abstract": "Long video understanding is a complex task that requires both spatial detail\nand temporal awareness. While Vision-Language Models (VLMs) obtain frame-level\nunderstanding capabilities through multi-frame input, they suffer from\ninformation loss due to the sparse sampling strategy. In contrast, Video Large\nLanguage Models (Video-LLMs) capture temporal relationships within visual\nfeatures but are limited by the scarcity of high-quality video-text datasets.\nTo transfer long video understanding capabilities to VLMs with minimal data and\ncomputational cost, we propose Lightweight Video Compression (LVC), a novel\nmethod featuring the Query-Attention Video Compression mechanism, which\neffectively tackles the sparse sampling problem in VLMs. By training only the\nalignment layer with 10k short video-text pairs, LVC significantly enhances the\ntemporal reasoning abilities of VLMs. Extensive experiments show that LVC\nprovides consistent performance improvements across various models, including\nthe InternVL2 series and Phi-3.5-Vision. Notably, the InternVL2-40B-LVC\nachieves scores of 68.2 and 65.9 on the long video understanding benchmarks\nMLVU and Video-MME, respectively, with relative improvements of 14.6% and 7.7%.\nThe enhanced models and code will be publicly available soon.", "published": "2025-04-09 12:51:10", "link": "http://arxiv.org/abs/2504.06835v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "IAAO: Interactive Affordance Learning for Articulated Objects in 3D Environments", "abstract": "This work presents IAAO, a novel framework that builds an explicit 3D model\nfor intelligent agents to gain understanding of articulated objects in their\nenvironment through interaction. Unlike prior methods that rely on\ntask-specific networks and assumptions about movable parts, our IAAO leverages\nlarge foundation models to estimate interactive affordances and part\narticulations in three stages. We first build hierarchical features and label\nfields for each object state using 3D Gaussian Splatting (3DGS) by distilling\nmask features and view-consistent labels from multi-view images. We then\nperform object- and part-level queries on the 3D Gaussian primitives to\nidentify static and articulated elements, estimating global transformations and\nlocal articulation parameters along with affordances. Finally, scenes from\ndifferent states are merged and refined based on the estimated transformations,\nenabling robust affordance-based interaction and manipulation of objects.\nExperimental results demonstrate the effectiveness of our method.", "published": "2025-04-09 12:36:48", "link": "http://arxiv.org/abs/2504.06827v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SVG-IR: Spatially-Varying Gaussian Splatting for Inverse Rendering", "abstract": "Reconstructing 3D assets from images, known as inverse rendering (IR),\nremains a challenging task due to its ill-posed nature. 3D Gaussian Splatting\n(3DGS) has demonstrated impressive capabilities for novel view synthesis (NVS)\ntasks. Methods apply it to relighting by separating radiance into BRDF\nparameters and lighting, yet produce inferior relighting quality with artifacts\nand unnatural indirect illumination due to the limited capability of each\nGaussian, which has constant material parameters and normal, alongside the\nabsence of physical constraints for indirect lighting. In this paper, we\npresent a novel framework called Spatially-vayring Gaussian Inverse Rendering\n(SVG-IR), aimed at enhancing both NVS and relighting quality. To this end, we\npropose a new representation-Spatially-varying Gaussian (SVG)-that allows\nper-Gaussian spatially varying parameters. This enhanced representation is\ncomplemented by a SVG splatting scheme akin to vertex/fragment shading in\ntraditional graphics pipelines. Furthermore, we integrate a physically-based\nindirect lighting model, enabling more realistic relighting. The proposed\nSVG-IR framework significantly improves rendering quality, outperforming\nstate-of-the-art NeRF-based methods by 2.5 dB in peak signal-to-noise ratio\n(PSNR) and surpassing existing Gaussian-based techniques by 3.5 dB in\nrelighting tasks, all while maintaining a real-time rendering speed.", "published": "2025-04-09 12:11:58", "link": "http://arxiv.org/abs/2504.06815v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hybrid CNN with Chebyshev Polynomial Expansion for Medical Image Analysis", "abstract": "Lung cancer remains one of the leading causes of cancer-related mortality\nworldwide, with early and accurate diagnosis playing a pivotal role in\nimproving patient outcomes. Automated detection of pulmonary nodules in\ncomputed tomography (CT) scans is a challenging task due to variability in\nnodule size, shape, texture, and location. Traditional Convolutional Neural\nNetworks (CNNs) have shown considerable promise in medical image analysis;\nhowever, their limited ability to capture fine-grained spatial-spectral\nvariations restricts their performance in complex diagnostic scenarios. In this\nstudy, we propose a novel hybrid deep learning architecture that incorporates\nChebyshev polynomial expansions into CNN layers to enhance expressive power and\nimprove the representation of underlying anatomical structures. The proposed\nChebyshev-CNN leverages the orthogonality and recursive properties of Chebyshev\npolynomials to extract high-frequency features and approximate complex\nnonlinear functions with greater fidelity. The model is trained and evaluated\non benchmark lung cancer imaging datasets, including LUNA16 and LIDC-IDRI,\nachieving superior performance in classifying pulmonary nodules as benign or\nmalignant. Quantitative results demonstrate significant improvements in\naccuracy, sensitivity, and specificity compared to traditional CNN-based\napproaches. This integration of polynomial-based spectral approximation within\ndeep learning provides a robust framework for enhancing automated medical\ndiagnostics and holds potential for broader applications in clinical decision\nsupport systems.", "published": "2025-04-09 12:02:56", "link": "http://arxiv.org/abs/2504.06811v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "DyDiT++: Dynamic Diffusion Transformers for Efficient Visual Generation", "abstract": "Diffusion Transformer (DiT), an emerging diffusion model for visual\ngeneration, has demonstrated superior performance but suffers from substantial\ncomputational costs. Our investigations reveal that these costs primarily stem\nfrom the \\emph{static} inference paradigm, which inevitably introduces\nredundant computation in certain \\emph{diffusion timesteps} and \\emph{spatial\nregions}. To overcome this inefficiency, we propose \\textbf{Dy}namic\n\\textbf{Di}ffusion \\textbf{T}ransformer (DyDiT), an architecture that\n\\emph{dynamically} adjusts its computation along both \\emph{timestep} and\n\\emph{spatial} dimensions. Specifically, we introduce a \\emph{Timestep-wise\nDynamic Width} (TDW) approach that adapts model width conditioned on the\ngeneration timesteps. In addition, we design a \\emph{Spatial-wise Dynamic\nToken} (SDT) strategy to avoid redundant computation at unnecessary spatial\nlocations. TDW and SDT can be seamlessly integrated into DiT and significantly\naccelerates the generation process. Building on these designs, we further\nenhance DyDiT in three key aspects. First, DyDiT is integrated seamlessly with\nflow matching-based generation, enhancing its versatility. Furthermore, we\nenhance DyDiT to tackle more complex visual generation tasks, including video\ngeneration and text-to-image generation, thereby broadening its real-world\napplications. Finally, to address the high cost of full fine-tuning and\ndemocratize technology access, we investigate the feasibility of training DyDiT\nin a parameter-efficient manner and introduce timestep-based dynamic LoRA\n(TD-LoRA). Extensive experiments on diverse visual generation models, including\nDiT, SiT, Latte, and FLUX, demonstrate the effectiveness of DyDiT.", "published": "2025-04-09 11:48:37", "link": "http://arxiv.org/abs/2504.06803v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MonoPlace3D: Learning 3D-Aware Object Placement for 3D Monocular Detection", "abstract": "Current monocular 3D detectors are held back by the limited diversity and\nscale of real-world datasets. While data augmentation certainly helps, it's\nparticularly difficult to generate realistic scene-aware augmented data for\noutdoor settings. Most current approaches to synthetic data generation focus on\nrealistic object appearance through improved rendering techniques. However, we\nshow that where and how objects are positioned is just as crucial for training\neffective 3D monocular detectors. The key obstacle lies in automatically\ndetermining realistic object placement parameters - including position,\ndimensions, and directional alignment when introducing synthetic objects into\nactual scenes. To address this, we introduce MonoPlace3D, a novel system that\nconsiders the 3D scene content to create realistic augmentations. Specifically,\ngiven a background scene, MonoPlace3D learns a distribution over plausible 3D\nbounding boxes. Subsequently, we render realistic objects and place them\naccording to the locations sampled from the learned distribution. Our\ncomprehensive evaluation on two standard datasets KITTI and NuScenes,\ndemonstrates that MonoPlace3D significantly improves the accuracy of multiple\nexisting monocular 3D detectors while being highly data efficient.", "published": "2025-04-09 11:47:48", "link": "http://arxiv.org/abs/2504.06801v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Meaningful Perturbation Metric for Evaluating Explainability Methods", "abstract": "Deep neural networks (DNNs) have demonstrated remarkable success, yet their\nwide adoption is often hindered by their opaque decision-making. To address\nthis, attribution methods have been proposed to assign relevance values to each\npart of the input. However, different methods often produce entirely different\nrelevance maps, necessitating the development of standardized metrics to\nevaluate them. Typically, such evaluation is performed through perturbation,\nwherein high- or low-relevance regions of the input image are manipulated to\nexamine the change in prediction. In this work, we introduce a novel approach,\nwhich harnesses image generation models to perform targeted perturbation.\nSpecifically, we focus on inpainting only the high-relevance pixels of an input\nimage to modify the model's predictions while preserving image fidelity. This\nis in contrast to existing approaches, which often produce out-of-distribution\nmodifications, leading to unreliable results. Through extensive experiments, we\ndemonstrate the effectiveness of our approach in generating meaningful rankings\nacross a wide range of models and attribution methods. Crucially, we establish\nthat the ranking produced by our metric exhibits significantly higher\ncorrelation with human preferences compared to existing approaches,\nunderscoring its potential for enhancing interpretability in DNNs.", "published": "2025-04-09 11:46:41", "link": "http://arxiv.org/abs/2504.06800v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Domain Generalization through Attenuation of Domain-Specific Information", "abstract": "In this paper, we propose a new evaluation metric called Domain Independence\n(DI) and Attenuation of Domain-Specific Information (ADSI) which is\nspecifically designed for domain-generalized semantic segmentation in\nautomotive images. DI measures the presence of domain-specific information: a\nlower DI value indicates strong domain dependence, while a higher DI value\nsuggests greater domain independence. This makes it roughly where\ndomain-specific information exists and up to which frequency range it is\npresent. As a result, it becomes possible to effectively suppress only the\nregions in the image that contain domain-specific information, enabling feature\nextraction independent of the domain. ADSI uses a Butterworth filter to remove\nthe low-frequency components of images that contain inherent domain-specific\ninformation such as sensor characteristics and lighting conditions. However,\nsince low-frequency components also contain important information such as\ncolor, we should not remove them completely. Thus, a scalar value (ranging from\n0 to 1) is multiplied by the low-frequency components to retain essential\ninformation. This helps the model learn more domain-independent features. In\nexperiments, GTA5 (synthetic dataset) was used as training images, and a\nreal-world dataset was used for evaluation, and the proposed method\noutperformed conventional approaches. Similarly, in experiments that the\nCityscapes (real-world dataset) was used for training and various environment\ndatasets such as rain and nighttime were used for evaluation, the proposed\nmethod demonstrated its robustness under nighttime conditions.", "published": "2025-04-09 11:10:29", "link": "http://arxiv.org/abs/2504.06781v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "End2end-ALARA: Approaching the ALARA Law in CT Imaging with End-to-end Learning", "abstract": "Computed tomography (CT) examination poses radiation injury to patient. A\nconsensus performing CT imaging is to make the radiation dose as low as\nreasonably achievable, i.e. the ALARA law. In this paper, we propose an\nend-to-end learning framework, named End2end-ALARA, that jointly optimizes dose\nmodulation and image reconstruction to meet the goal of ALARA in CT imaging.\nEnd2end-ALARA works by building a dose modulation module and an image\nreconstruction module, connecting these modules with a differentiable\nsimulation function, and optimizing the them with a constrained hinge loss\nfunction. The objective is to minimize radiation dose subject to a prescribed\nimage quality (IQ) index. The results show that End2end-ALARA is able to preset\npersonalized dose levels to gain a stable IQ level across patients, which may\nfacilitate image-based diagnosis and downstream model training. Moreover,\ncompared to fixed-dose and conventional dose modulation strategies,\nEnd2end-ALARA consumes lower dose to reach the same IQ level. Our study sheds\nlight on a way of realizing the ALARA law in CT imaging.", "published": "2025-04-09 10:57:58", "link": "http://arxiv.org/abs/2504.06777v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DIMA: DIffusing Motion Artifacts for unsupervised correction in brain MRI images", "abstract": "Motion artifacts remain a significant challenge in Magnetic Resonance Imaging\n(MRI), compromising diagnostic quality and potentially leading to misdiagnosis\nor repeated scans. Existing deep learning approaches for motion artifact\ncorrection typically require paired motion-free and motion-affected images for\ntraining, which are rarely available in clinical settings. To overcome this\nrequirement, we present DIMA (DIffusing Motion Artifacts), a novel framework\nthat leverages diffusion models to enable unsupervised motion artifact\ncorrection in brain MRI. Our two-phase approach first trains a diffusion model\non unpaired motion-affected images to learn the distribution of motion\nartifacts. This model then generates realistic motion artifacts on clean\nimages, creating paired datasets suitable for supervised training of correction\nnetworks. Unlike existing methods, DIMA operates without requiring k-space\nmanipulation or detailed knowledge of MRI sequence parameters, making it\nadaptable across different scanning protocols and hardware. Comprehensive\nevaluations across multiple datasets and anatomical planes demonstrate that our\nmethod achieves comparable performance to state-of-the-art supervised\napproaches while offering superior generalizability to real clinical data. DIMA\nrepresents a significant advancement in making motion artifact correction more\naccessible for routine clinical use, potentially reducing the need for repeat\nscans and improving diagnostic accuracy.", "published": "2025-04-09 10:43:38", "link": "http://arxiv.org/abs/2504.06767v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "FANeRV: Frequency Separation and Augmentation based Neural Representation for Video", "abstract": "Neural representations for video (NeRV) have gained considerable attention\nfor their strong performance across various video tasks. However, existing NeRV\nmethods often struggle to capture fine spatial details, resulting in vague\nreconstructions. In this paper, we present a Frequency Separation and\nAugmentation based Neural Representation for video (FANeRV), which addresses\nthese limitations with its core Wavelet Frequency Upgrade Block.This block\nexplicitly separates input frames into high and low-frequency components using\ndiscrete wavelet transform, followed by targeted enhancement using specialized\nmodules. Finally, a specially designed gated network effectively fuses these\nfrequency components for optimal reconstruction. Additionally, convolutional\nresidual enhancement blocks are integrated into the later stages of the network\nto balance parameter distribution and improve the restoration of high-frequency\ndetails. Experimental results demonstrate that FANeRV significantly improves\nreconstruction performance and excels in multiple tasks, including video\ncompression, inpainting, and interpolation, outperforming existing NeRV\nmethods.", "published": "2025-04-09 10:19:35", "link": "http://arxiv.org/abs/2504.06755v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Compass Control: Multi Object Orientation Control for Text-to-Image Generation", "abstract": "Existing approaches for controlling text-to-image diffusion models, while\npowerful, do not allow for explicit 3D object-centric control, such as precise\ncontrol of object orientation. In this work, we address the problem of\nmulti-object orientation control in text-to-image diffusion models. This\nenables the generation of diverse multi-object scenes with precise orientation\ncontrol for each object. The key idea is to condition the diffusion model with\na set of orientation-aware \\textbf{compass} tokens, one for each object, along\nwith text tokens. A light-weight encoder network predicts these compass tokens\ntaking object orientation as the input. The model is trained on a synthetic\ndataset of procedurally generated scenes, each containing one or two 3D assets\non a plain background. However, direct training this framework results in poor\norientation control as well as leads to entanglement among objects. To mitigate\nthis, we intervene in the generation process and constrain the cross-attention\nmaps of each compass token to its corresponding object regions. The trained\nmodel is able to achieve precise orientation control for a) complex objects not\nseen during training and b) multi-object scenes with more than two objects,\nindicating strong generalization capabilities. Further, when combined with\npersonalization methods, our method precisely controls the orientation of the\nnew object in diverse contexts. Our method achieves state-of-the-art\norientation control and text alignment, quantified with extensive evaluations\nand a user study.", "published": "2025-04-09 10:15:15", "link": "http://arxiv.org/abs/2504.06752v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Visualisation of a multidimensional point cloud as a 3D swarm of avatars", "abstract": "The article presents an innovative approach to the visualisation of\nmultidimensional data, using icons inspired by Chernoff faces. The approach\nmerges classical projection techniques with the assignment of particular data\ndimensions to mimic features, capitalizing on the natural ability of the human\nbrain to interpret facial expressions. The technique is implemented as a plugin\nto the dpVision open-source image handling platform. The plugin allows the data\nto be interactively explored in the form of a swarm of \"totems\" whose position\nin hyperspace as well as facial features represent various aspects of the data.\nSample visualisations, based on synthetic test data as well as the vinhoverde\n15-dimensional database on Portuguese wines, confirm the usefulness of our\napproach to the analysis of complex data structures.", "published": "2025-04-09 10:14:33", "link": "http://arxiv.org/abs/2504.06751v1", "categories": ["cs.CV", "cs.HC"], "primary_category": "cs.CV"}
{"title": "nnLandmark: A Self-Configuring Method for 3D Medical Landmark Detection", "abstract": "Landmark detection plays a crucial role in medical imaging tasks that rely on\nprecise spatial localization, including specific applications in diagnosis,\ntreatment planning, image registration, and surgical navigation. However,\nmanual annotation is labor-intensive and requires expert knowledge. While deep\nlearning shows promise in automating this task, progress is hindered by limited\npublic datasets, inconsistent benchmarks, and non-standardized baselines,\nrestricting reproducibility, fair comparisons, and model generalizability.This\nwork introduces nnLandmark, a self-configuring deep learning framework for 3D\nmedical landmark detection, adapting nnU-Net to perform heatmap-based\nregression. By leveraging nnU-Net's automated configuration, nnLandmark\neliminates the need for manual parameter tuning, offering out-of-the-box\nusability. It achieves state-of-the-art accuracy across two public datasets,\nwith a mean radial error (MRE) of 1.5 mm on the Mandibular Molar Landmark (MML)\ndental CT dataset and 1.2 mm for anatomical fiducials on a brain MRI dataset\n(AFIDs), where nnLandmark aligns with the inter-rater variability of 1.5 mm.\nWith its strong generalization, reproducibility, and ease of deployment,\nnnLandmark establishes a reliable baseline for 3D landmark detection,\nsupporting research in anatomical localization and clinical workflows that\ndepend on precise landmark identification. The code will be available soon.", "published": "2025-04-09 09:53:39", "link": "http://arxiv.org/abs/2504.06742v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Large Scale Supervised Pretraining For Traumatic Brain Injury Segmentation", "abstract": "The segmentation of lesions in Moderate to Severe Traumatic Brain Injury\n(msTBI) presents a significant challenge in neuroimaging due to the diverse\ncharacteristics of these lesions, which vary in size, shape, and distribution\nacross brain regions and tissue types. This heterogeneity complicates\ntraditional image processing techniques, resulting in critical errors in tasks\nsuch as image registration and brain parcellation. To address these challenges,\nthe AIMS-TBI Segmentation Challenge 2024 aims to advance innovative\nsegmentation algorithms specifically designed for T1-weighted MRI data, the\nmost widely utilized imaging modality in clinical practice. Our proposed\nsolution leverages a large-scale multi-dataset supervised pretraining approach\ninspired by the MultiTalent method. We train a Resenc L network on a\ncomprehensive collection of datasets covering various anatomical and\npathological structures, which equips the model with a robust understanding of\nbrain anatomy and pathology. Following this, the model is fine-tuned on\nmsTBI-specific data to optimize its performance for the unique characteristics\nof T1-weighted MRI scans and outperforms the baseline without pretraining up to\n2 Dice points.", "published": "2025-04-09 09:52:45", "link": "http://arxiv.org/abs/2504.06741v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MultiADS: Defect-aware Supervision for Multi-type Anomaly Detection and Segmentation in Zero-Shot Learning", "abstract": "Precise optical inspection in industrial applications is crucial for\nminimizing scrap rates and reducing the associated costs. Besides merely\ndetecting if a product is anomalous or not, it is crucial to know the distinct\ntype of defect, such as a bent, cut, or scratch. The ability to recognize the\n\"exact\" defect type enables automated treatments of the anomalies in modern\nproduction lines. Current methods are limited to solely detecting whether a\nproduct is defective or not without providing any insights on the defect type,\nnevertheless detecting and identifying multiple defects. We propose MultiADS, a\nzero-shot learning approach, able to perform Multi-type Anomaly Detection and\nSegmentation. The architecture of MultiADS comprises CLIP and extra linear\nlayers to align the visual- and textual representation in a joint feature\nspace. To the best of our knowledge, our proposal, is the first approach to\nperform a multi-type anomaly segmentation task in zero-shot learning. Contrary\nto the other baselines, our approach i) generates specific anomaly masks for\neach distinct defect type, ii) learns to distinguish defect types, and iii)\nsimultaneously identifies multiple defect types present in an anomalous\nproduct. Additionally, our approach outperforms zero/few-shot learning SoTA\nmethods on image-level and pixel-level anomaly detection and segmentation tasks\non five commonly used datasets: MVTec-AD, Visa, MPDD, MAD and Real-IAD.", "published": "2025-04-09 09:52:04", "link": "http://arxiv.org/abs/2504.06740v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GSta: Efficient Training Scheme with Siestaed Gaussians for Monocular 3D Scene Reconstruction", "abstract": "Gaussian Splatting (GS) is a popular approach for 3D reconstruction, mostly\ndue to its ability to converge reasonably fast, faithfully represent the scene\nand render (novel) views in a fast fashion. However, it suffers from large\nstorage and memory requirements, and its training speed still lags behind the\nhash-grid based radiance field approaches (e.g. Instant-NGP), which makes it\nespecially difficult to deploy them in robotics scenarios, where 3D\nreconstruction is crucial for accurate operation. In this paper, we propose\nGSta that dynamically identifies Gaussians that have converged well during\ntraining, based on their positional and color gradient norms. By forcing such\nGaussians into a siesta and stopping their updates (freezing) during training,\nwe improve training speed with competitive accuracy compared to state of the\nart. We also propose an early stopping mechanism based on the PSNR values\ncomputed on a subset of training images. Combined with other improvements, such\nas integrating a learning rate scheduler, GSta achieves an improved Pareto\nfront in convergence speed, memory and storage requirements, while preserving\nquality. We also show that GSta can improve other methods and complement\northogonal approaches in efficiency improvement; once combined with Trick-GS,\nGSta achieves up to 5x faster training, 16x smaller disk size compared to\nvanilla GS, while having comparable accuracy and consuming only half the peak\nmemory. More visualisations are available at\nhttps://anilarmagan.github.io/SRUK-GSta.", "published": "2025-04-09 09:17:56", "link": "http://arxiv.org/abs/2504.06716v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Deep Learning for Cardiovascular Risk Assessment: Proxy Features from Carotid Sonography as Predictors of Arterial Damage", "abstract": "In this study, hypertension is utilized as an indicator of individual\nvascular damage. This damage can be identified through machine learning\ntechniques, providing an early risk marker for potential major cardiovascular\nevents and offering valuable insights into the overall arterial condition of\nindividual patients. To this end, the VideoMAE deep learning model, originally\ndeveloped for video classification, was adapted by finetuning for application\nin the domain of ultrasound imaging. The model was trained and tested using a\ndataset comprising over 31,000 carotid sonography videos sourced from the\nGutenberg Health Study (15,010 participants), one of the largest prospective\npopulation health studies. This adaptation facilitates the classification of\nindividuals as hypertensive or non-hypertensive (75.7% validation accuracy),\nfunctioning as a proxy for detecting visual arterial damage. We demonstrate\nthat our machine learning model effectively captures visual features that\nprovide valuable insights into an individual's overall cardiovascular health.", "published": "2025-04-09 08:38:17", "link": "http://arxiv.org/abs/2504.06680v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Setup-Invariant Augmented Reality for Teaching by Demonstration with Surgical Robots", "abstract": "Augmented reality (AR) is an effective tool in robotic surgery education as\nit combines exploratory learning with three-dimensional guidance. However,\nexisting AR systems require expert supervision and do not account for\ndifferences in the mentor and mentee robot configurations. To enable novices to\ntrain outside the operating room while receiving expert-informed guidance, we\npresent dV-STEAR: an open-source system that plays back task-aligned expert\ndemonstrations without assuming identical setup joint positions between expert\nand novice. Pose estimation was rigorously quantified, showing a registration\nerror of 3.86 (SD=2.01)mm. In a user study (N=24), dV-STEAR significantly\nimproved novice performance on tasks from the Fundamentals of Laparoscopic\nSurgery. In a single-handed ring-over-wire task, dV-STEAR increased completion\nspeed (p=0.03) and reduced collision time (p=0.01) compared to dry-lab training\nalone. During a pick-and-place task, it improved success rates (p=0.004).\nAcross both tasks, participants using dV-STEAR exhibited significantly more\nbalanced hand use and reported lower frustration levels. This work presents a\nnovel educational tool implemented on the da Vinci Research Kit, demonstrates\nits effectiveness in teaching novices, and builds the foundation for further AR\nintegration into robot-assisted surgery.", "published": "2025-04-09 08:34:25", "link": "http://arxiv.org/abs/2504.06677v1", "categories": ["cs.RO", "cs.CV", "cs.HC", "cs.SY", "eess.SY", "I.4.9; J.3.2; J.2.7"], "primary_category": "cs.RO"}
{"title": "Probability Density Geodesics in Image Diffusion Latent Space", "abstract": "Diffusion models indirectly estimate the probability density over a data\nspace, which can be used to study its structure. In this work, we show that\ngeodesics can be computed in diffusion latent space, where the norm induced by\nthe spatially-varying inner product is inversely proportional to the\nprobability density. In this formulation, a path that traverses a high density\n(that is, probable) region of image latent space is shorter than the equivalent\npath through a low density region. We present algorithms for solving the\nassociated initial and boundary value problems and show how to compute the\nprobability density along the path and the geodesic distance between two\npoints. Using these techniques, we analyze how closely video clips approximate\ngeodesics in a pre-trained image diffusion space. Finally, we demonstrate how\nthese techniques can be applied to training-free image sequence interpolation\nand extrapolation, given a pre-trained image diffusion model.", "published": "2025-04-09 08:28:53", "link": "http://arxiv.org/abs/2504.06675v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RAGME: Retrieval Augmented Video Generation for Enhanced Motion Realism", "abstract": "Video generation is experiencing rapid growth, driven by advances in\ndiffusion models and the development of better and larger datasets. However,\nproducing high-quality videos remains challenging due to the high-dimensional\ndata and the complexity of the task. Recent efforts have primarily focused on\nenhancing visual quality and addressing temporal inconsistencies, such as\nflickering. Despite progress in these areas, the generated videos often fall\nshort in terms of motion complexity and physical plausibility, with many\noutputs either appearing static or exhibiting unrealistic motion. In this work,\nwe propose a framework to improve the realism of motion in generated videos,\nexploring a complementary direction to much of the existing literature.\nSpecifically, we advocate for the incorporation of a retrieval mechanism during\nthe generation phase. The retrieved videos act as grounding signals, providing\nthe model with demonstrations of how the objects move. Our pipeline is designed\nto apply to any text-to-video diffusion model, conditioning a pretrained model\non the retrieved samples with minimal fine-tuning. We demonstrate the\nsuperiority of our approach through established metrics, recently proposed\nbenchmarks, and qualitative results, and we highlight additional applications\nof the framework.", "published": "2025-04-09 08:14:05", "link": "http://arxiv.org/abs/2504.06672v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Patch Matters: Training-free Fine-grained Image Caption Enhancement via Local Perception", "abstract": "High-quality image captions play a crucial role in improving the performance\nof cross-modal applications such as text-to-image generation, text-to-video\ngeneration, and text-image retrieval. To generate long-form, high-quality\ncaptions, many recent studies have employed multimodal large language models\n(MLLMs). However, current MLLMs often produce captions that lack fine-grained\ndetails or suffer from hallucinations, a challenge that persists in both\nopen-source and closed-source models. Inspired by Feature-Integration theory,\nwhich suggests that attention must focus on specific regions to integrate\nvisual information effectively, we propose a \\textbf{divide-then-aggregate}\nstrategy. Our method first divides the image into semantic and spatial patches\nto extract fine-grained details, enhancing the model's local perception of the\nimage. These local details are then hierarchically aggregated to generate a\ncomprehensive global description. To address hallucinations and inconsistencies\nin the generated captions, we apply a semantic-level filtering process during\nhierarchical aggregation. This training-free pipeline can be applied to both\nopen-source models (LLaVA-1.5, LLaVA-1.6, Mini-Gemini) and closed-source models\n(Claude-3.5-Sonnet, GPT-4o, GLM-4V-Plus). Extensive experiments demonstrate\nthat our method generates more detailed, reliable captions, advancing\nmultimodal description generation without requiring model retraining. The\nsource code are available at https://github.com/GeWu-Lab/Patch-Matters", "published": "2025-04-09 08:07:46", "link": "http://arxiv.org/abs/2504.06666v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Uni-PrevPredMap: Extending PrevPredMap to a Unified Framework of Prior-Informed Modeling for Online Vectorized HD Map Construction", "abstract": "Safety constitutes a foundational imperative for autonomous driving systems,\nnecessitating the maximal incorporation of accessible external prior\ninformation. This study establishes that temporal perception buffers and\ncost-efficient maps inherently form complementary prior sources for online\nvectorized high-definition (HD) map construction. We present Uni-PrevPredMap, a\nunified prior-informed framework that systematically integrates two synergistic\ninformation sources: previous predictions and simulated outdated HD maps. The\nframework introduces two core innovations: a tile-indexed 3D vectorized global\nmap processor enabling efficient refreshment, storage, and retrieval of 3D\nvectorized priors; a tri-mode operational optimization paradigm ensuring\nconsistency across prior-free, map-absent, and map-prior scenarios while\nmitigating reliance on idealized map fidelity assumptions. Uni-PrevPredMap\nachieves state-of-the-art performance in map-free scenarios across established\nonline vectorized HD map construction benchmarks. When provided with simulated\noutdated HD maps, the framework exhibits robust capabilities in error-resilient\nprior fusion, empirically confirming the synergistic complementarity between\nprevious predictions and simulated outdated HD maps. Code will be available at\nhttps://github.com/pnnnnnnn/Uni-PrevPredMap.", "published": "2025-04-09 07:36:17", "link": "http://arxiv.org/abs/2504.06647v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HGMamba: Enhancing 3D Human Pose Estimation with a HyperGCN-Mamba Network", "abstract": "3D human pose lifting is a promising research area that leverages estimated\nand ground-truth 2D human pose data for training. While existing approaches\nprimarily aim to enhance the performance of estimated 2D poses, they often\nstruggle when applied to ground-truth 2D pose data. We observe that achieving\naccurate 3D pose reconstruction from ground-truth 2D poses requires precise\nmodeling of local pose structures, alongside the ability to extract robust\nglobal spatio-temporal features. To address these challenges, we propose a\nnovel Hyper-GCN and Shuffle Mamba (HGMamba) block, which processes input data\nthrough two parallel streams: Hyper-GCN and Shuffle-Mamba. The Hyper-GCN stream\nmodels the human body structure as hypergraphs with varying levels of\ngranularity to effectively capture local joint dependencies. Meanwhile, the\nShuffle Mamba stream leverages a state space model to perform spatio-temporal\nscanning across all joints, enabling the establishment of global dependencies.\nBy adaptively fusing these two representations, HGMamba achieves strong global\nfeature modeling while excelling at local structure modeling. We stack multiple\nHGMamba blocks to create three variants of our model, allowing users to select\nthe most suitable configuration based on the desired speed-accuracy trade-off.\nExtensive evaluations on the Human3.6M and MPI-INF-3DHP benchmark datasets\ndemonstrate the effectiveness of our approach. HGMamba-B achieves\nstate-of-the-art results, with P1 errors of 38.65 mm and 14.33 mm on the\nrespective datasets. Code and models are available:\nhttps://github.com/HuCui2022/HGMamba", "published": "2025-04-09 07:28:19", "link": "http://arxiv.org/abs/2504.06638v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Crafting Query-Aware Selective Attention for Single Image Super-Resolution", "abstract": "Single Image Super-Resolution (SISR) reconstructs high-resolution images from\nlow-resolution inputs, enhancing image details. While Vision Transformer\n(ViT)-based models improve SISR by capturing long-range dependencies, they\nsuffer from quadratic computational costs or employ selective attention\nmechanisms that do not explicitly focus on query-relevant regions. Despite\nthese advancements, prior work has overlooked how selective attention\nmechanisms should be effectively designed for SISR. We propose SSCAN, which\ndynamically selects the most relevant key-value windows based on query\nsimilarity, ensuring focused feature extraction while maintaining efficiency.\nIn contrast to prior approaches that apply attention globally or heuristically,\nour method introduces a query-aware window selection strategy that better\naligns attention computation with important image regions. By incorporating\nfixed-sized windows, SSCAN reduces memory usage and enforces linear\ntoken-to-token complexity, making it scalable for large images. Our experiments\ndemonstrate that SSCAN outperforms existing attention-based SISR methods,\nachieving up to 0.14 dB PSNR improvement on urban datasets, guaranteeing both\ncomputational efficiency and reconstruction quality in SISR.", "published": "2025-04-09 07:17:29", "link": "http://arxiv.org/abs/2504.06634v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PosterMaker: Towards High-Quality Product Poster Generation with Accurate Text Rendering", "abstract": "Product posters, which integrate subject, scene, and text, are crucial\npromotional tools for attracting customers. Creating such posters using modern\nimage generation methods is valuable, while the main challenge lies in\naccurately rendering text, especially for complex writing systems like Chinese,\nwhich contains over 10,000 individual characters. In this work, we identify the\nkey to precise text rendering as constructing a character-discriminative visual\nfeature as a control signal. Based on this insight, we propose a robust\ncharacter-wise representation as control and we develop TextRenderNet, which\nachieves a high text rendering accuracy of over 90%. Another challenge in\nposter generation is maintaining the fidelity of user-specific products. We\naddress this by introducing SceneGenNet, an inpainting-based model, and propose\nsubject fidelity feedback learning to further enhance fidelity. Based on\nTextRenderNet and SceneGenNet, we present PosterMaker, an end-to-end generation\nframework. To optimize PosterMaker efficiently, we implement a two-stage\ntraining strategy that decouples text rendering and background generation\nlearning. Experimental results show that PosterMaker outperforms existing\nbaselines by a remarkable margin, which demonstrates its effectiveness.", "published": "2025-04-09 07:13:08", "link": "http://arxiv.org/abs/2504.06632v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Rethinking LayerNorm in Image Restoration Transformers", "abstract": "This work investigates abnormal feature behaviors observed in image\nrestoration (IR) Transformers. Specifically, we identify two critical issues:\nfeature entropy becoming excessively small and feature magnitudes diverging up\nto a million-fold scale. We pinpoint the root cause to the per-token\nnormalization aspect of conventional LayerNorm, which disrupts essential\nspatial correlations and internal feature statistics. To address this, we\npropose a simple normalization strategy tailored for IR Transformers. Our\napproach applies normalization across the entire spatio-channel dimension,\neffectively preserving spatial correlations. Additionally, we introduce an\ninput-adaptive rescaling method that aligns feature statistics to the unique\nstatistical requirements of each input. Experimental results verify that this\ncombined strategy effectively resolves feature divergence, significantly\nenhancing both the stability and performance of IR Transformers across various\nIR tasks.", "published": "2025-04-09 07:06:44", "link": "http://arxiv.org/abs/2504.06629v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FACT: Multinomial Misalignment Classification for Point Cloud Registration", "abstract": "We present FACT, a method for predicting alignment quality (i.e.,\nregistration error) of registered lidar point cloud pairs. This is useful e.g.\nfor quality assurance of large, automatically registered 3D models. FACT\nextracts local features from a registered pair and processes them with a point\ntransformer-based network to predict a misalignment class. We generalize prior\nwork that study binary alignment classification of registration errors, by\nrecasting it as multinomial misalignment classification. To achieve this, we\nintroduce a custom regression-by-classification loss function that combines the\ncross-entropy and Wasserstein losses, and demonstrate that it outperforms both\ndirect regression and prior binary classification. FACT successfully classifies\npoint-cloud pairs registered with both the classical ICP and GeoTransformer,\nwhile other choices, such as standard point-cloud-quality metrics and\nregistration residuals are shown to be poor choices for predicting\nmisalignment. On a synthetically perturbed point-cloud task introduced by the\nCorAl method, we show that FACT achieves substantially better performance than\nCorAl. Finally, we demonstrate how FACT can assist experts in correcting\nmisaligned point-cloud maps. Our code is available at\nhttps://github.com/LudvigDillen/FACT_for_PCMC.", "published": "2025-04-09 07:01:57", "link": "http://arxiv.org/abs/2504.06627v1", "categories": ["cs.CV", "cs.LG", "I.4.5; I.4.8; I.2.9; I.2.10"], "primary_category": "cs.CV"}
{"title": "InstantSticker: Realistic Decal Blending via Disentangled Object Reconstruction", "abstract": "We present InstantSticker, a disentangled reconstruction pipeline based on\nImage-Based Lighting (IBL), which focuses on highly realistic decal blending,\nsimulates stickers attached to the reconstructed surface, and allows for\ninstant editing and real-time rendering. To achieve stereoscopic impression of\nthe decal, we introduce shadow factor into IBL, which can be adaptively\noptimized during training. This allows the shadow brightness of surfaces to be\naccurately decomposed rather than baked into the diffuse color, ensuring that\nthe edited texture exhibits authentic shading. To address the issues of warping\nand blurriness in previous methods, we apply As-Rigid-As-Possible (ARAP)\nparameterization to pre-unfold a specified area of the mesh and use the local\nUV mapping combined with a neural texture map to enhance the ability to express\nhigh-frequency details in that area. For instant editing, we utilize the Disney\nBRDF model, explicitly defining material colors with 3-channel diffuse albedo.\nThis enables instant replacement of albedo RGB values during the editing\nprocess, avoiding the prolonged optimization required in previous approaches.\nIn our experiment, we introduce the Ratio Variance Warping (RVW) metric to\nevaluate the local geometric warping of the decal area. Extensive experimental\nresults demonstrate that our method surpasses previous decal blending methods\nin terms of editing quality, editing speed and rendering speed, achieving the\nstate-of-the-art.", "published": "2025-04-09 06:36:36", "link": "http://arxiv.org/abs/2504.06620v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Human-like compositional learning of visually-grounded concepts using synthetic environments", "abstract": "The compositional structure of language enables humans to decompose complex\nphrases and map them to novel visual concepts, showcasing flexible\nintelligence. While several algorithms exhibit compositionality, they fail to\nelucidate how humans learn to compose concept classes and ground visual cues\nthrough trial and error. To investigate this multi-modal learning challenge, we\ndesigned a 3D synthetic environment in which an agent learns, via\nreinforcement, to navigate to a target specified by a natural language\ninstruction. These instructions comprise nouns, attributes, and critically,\ndeterminers, prepositions, or both. The vast array of word combinations\nheightens the compositional complexity of the visual grounding task, as\nnavigating to a blue cube above red spheres is not rewarded when the\ninstruction specifies navigating to \"some blue cubes below the red sphere\". We\nfirst demonstrate that reinforcement learning agents can ground determiner\nconcepts to visual targets but struggle with more complex prepositional\nconcepts. Second, we show that curriculum learning, a strategy humans employ,\nenhances concept learning efficiency, reducing the required training episodes\nby 15% in determiner environments and enabling agents to easily learn\nprepositional concepts. Finally, we establish that agents trained on determiner\nor prepositional concepts can decompose held-out test instructions and rapidly\nadapt their navigation policies to unseen visual object combinations.\nLeveraging synthetic environments, our findings demonstrate that multi-modal\nreinforcement learning agents can achieve compositional understanding of\ncomplex concept classes and highlight the efficacy of human-like learning\nstrategies in improving artificial systems' learning efficiency.", "published": "2025-04-09 06:33:28", "link": "http://arxiv.org/abs/2504.06618v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Disentangle and Regularize: Sign Language Production with Articulator-Based Disentanglement and Channel-Aware Regularization", "abstract": "In this work, we propose a simple gloss-free, transformer-based sign language\nproduction (SLP) framework that directly maps spoken-language text to sign pose\nsequences. We first train a pose autoencoder that encodes sign poses into a\ncompact latent space using an articulator-based disentanglement strategy, where\nfeatures corresponding to the face, right hand, left hand, and body are modeled\nseparately to promote structured and interpretable representation learning.\nNext, a non-autoregressive transformer decoder is trained to predict these\nlatent representations from sentence-level text embeddings. To guide this\nprocess, we apply channel-aware regularization by aligning predicted latent\ndistributions with priors extracted from the ground-truth encodings using a\nKL-divergence loss. The contribution of each channel to the loss is weighted\naccording to its associated articulator region, enabling the model to account\nfor the relative importance of different articulators during training. Our\napproach does not rely on gloss supervision or pretrained models, and achieves\nstate-of-the-art results on the PHOENIX14T dataset using only a modest training\nset.", "published": "2025-04-09 06:14:19", "link": "http://arxiv.org/abs/2504.06610v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "A Cross-Domain Few-Shot Learning Method Based on Domain Knowledge Mapping", "abstract": "In task-based few-shot learning paradigms, it is commonly assumed that\ndifferent tasks are independently and identically distributed (i.i.d.).\nHowever, in real-world scenarios, the distribution encountered in few-shot\nlearning can significantly differ from the distribution of existing data. Thus,\nhow to effectively leverage existing data knowledge to enable models to quickly\nadapt to class variations under non-i.i.d. assumptions has emerged as a key\nresearch challenge. To address this challenge, this paper proposes a new\ncross-domain few-shot learning approach based on domain knowledge mapping,\napplied consistently throughout the pre-training, training, and testing phases.\nIn the pre-training phase, our method integrates self-supervised and supervised\nlosses by maximizing mutual information, thereby mitigating mode collapse.\nDuring the training phase, the domain knowledge mapping layer collaborates with\na domain classifier to learn both domain mapping capabilities and the ability\nto assess domain adaptation difficulty. Finally, this approach is applied\nduring the testing phase, rapidly adapting to domain variations through\nmeta-training tasks on support sets, consequently enhancing the model's\ncapability to transfer domain knowledge effectively. Experimental validation\nconducted across six datasets from diverse domains demonstrates the\neffectiveness of the proposed method.", "published": "2025-04-09 06:11:55", "link": "http://arxiv.org/abs/2504.06608v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Visually Similar Pair Alignment for Robust Cross-Domain Object Detection", "abstract": "Domain gaps between training data (source) and real-world environments\n(target) often degrade the performance of object detection models. Most\nexisting methods aim to bridge this gap by aligning features across source and\ntarget domains but often fail to account for visual differences, such as color\nor orientation, in alignment pairs. This limitation leads to less effective\ndomain adaptation, as the model struggles to manage both domain-specific shifts\n(e.g., fog) and visual variations simultaneously. In this work, we demonstrate\nfor the first time, using a custom-built dataset, that aligning visually\nsimilar pairs significantly improves domain adaptation. Based on this insight,\nwe propose a novel memory-based system to enhance domain alignment. This system\nstores precomputed features of foreground objects and background areas from the\nsource domain, which are periodically updated during training. By retrieving\nvisually similar source features for alignment with target foreground and\nbackground features, the model effectively addresses domain-specific\ndifferences while reducing the impact of visual variations. Extensive\nexperiments across diverse domain shift scenarios validate our method's\neffectiveness, achieving 53.1 mAP on Foggy Cityscapes and 62.3 on Sim10k,\nsurpassing prior state-of-the-art methods by 1.2 and 4.1 mAP, respectively.", "published": "2025-04-09 06:11:11", "link": "http://arxiv.org/abs/2504.06607v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Benchmarking Multimodal CoT Reward Model Stepwise by Visual Program", "abstract": "Recent advancements in reward signal usage for Large Language Models (LLMs)\nare remarkable. However, significant challenges exist when transitioning reward\nsignal to the multimodal domain, including labor-intensive annotations,\nover-reliance on one-step rewards, and inadequate evaluation. To address these\nissues, we propose SVIP, a novel approach to train a step-level\nmulti-dimensional Chain-of-Thought~(CoT) reward model automatically. It\ngenerates code for solving visual tasks and transforms the analysis of code\nblocks into the evaluation of CoT step as training samples. Then, we train\nSVIP-Reward model using a multi-head attention mechanism called TriAtt-CoT. The\nadvantages of SVIP-Reward are evident throughout the entire process of MLLM. We\nalso introduce a benchmark for CoT reward model training and testing.\nExperimental results demonstrate that SVIP-Reward improves MLLM performance\nacross training and inference-time scaling, yielding better results on\nbenchmarks while reducing hallucinations and enhancing reasoning ability.", "published": "2025-04-09 06:09:40", "link": "http://arxiv.org/abs/2504.06606v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Image registration of 2D optical thin sections in a 3D porous medium: Application to a Berea sandstone digital rock image", "abstract": "This study proposes a systematic image registration approach to align 2D\noptical thin-section images within a 3D digital rock volume. Using template\nimage matching with differential evolution optimization, we identify the most\nsimilar 2D plane in 3D. The method is validated on a synthetic porous medium,\nachieving exact registration, and applied to Berea sandstone, where it achieves\na structural similarity index (SSIM) of 0.990. With the registered images, we\nexplore upscaling properties based on paired multimodal images, focusing on\npore characteristics and effective elastic moduli. The thin-section image\nreveals 50 % more porosity and submicron pores than the registered CT plane. In\naddition, bulk and shear moduli from thin sections are 25 % and 30 % lower,\nrespectively, than those derived from CT images. Beyond numerical comparisons,\nthin sections provide additional geological insights, including cementation,\nmineral phases, and weathering effects, which are not clear in CT images. This\nstudy demonstrates the potential of multimodal image registration to improve\ncomputed rock properties in digital rock physics by integrating complementary\nimaging modalities.", "published": "2025-04-09 06:01:43", "link": "http://arxiv.org/abs/2504.06604v1", "categories": ["physics.geo-ph", "cs.CV"], "primary_category": "physics.geo-ph"}
{"title": "Domain Generalization via Discrete Codebook Learning", "abstract": "Domain generalization (DG) strives to address distribution shifts across\ndiverse environments to enhance model's generalizability. Current DG approaches\nare confined to acquiring robust representations with continuous features,\nspecifically training at the pixel level. However, this DG paradigm may\nstruggle to mitigate distribution gaps in dealing with a large space of\ncontinuous features, rendering it susceptible to pixel details that exhibit\nspurious correlations or noise. In this paper, we first theoretically\ndemonstrate that the domain gaps in continuous representation learning can be\nreduced by the discretization process. Based on this inspiring finding, we\nintroduce a novel learning paradigm for DG, termed Discrete Domain\nGeneralization (DDG). DDG proposes to use a codebook to quantize the feature\nmap into discrete codewords, aligning semantic-equivalent information in a\nshared discrete representation space that prioritizes semantic-level\ninformation over pixel-level intricacies. By learning at the semantic level,\nDDG diminishes the number of latent features, optimizing the utilization of the\nrepresentation space and alleviating the risks associated with the wide-ranging\nspace of continuous features. Extensive experiments across widely employed\nbenchmarks in DG demonstrate DDG's superior performance compared to\nstate-of-the-art approaches, underscoring its potential to reduce the\ndistribution gaps and enhance the model's generalizability.", "published": "2025-04-09 04:19:35", "link": "http://arxiv.org/abs/2504.06572v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ASHiTA: Automatic Scene-grounded HIerarchical Task Analysis", "abstract": "While recent work in scene reconstruction and understanding has made strides\nin grounding natural language to physical 3D environments, it is still\nchallenging to ground abstract, high-level instructions to a 3D scene.\nHigh-level instructions might not explicitly invoke semantic elements in the\nscene, and even the process of breaking a high-level task into a set of more\nconcrete subtasks, a process called hierarchical task analysis, is\nenvironment-dependent. In this work, we propose ASHiTA, the first framework\nthat generates a task hierarchy grounded to a 3D scene graph by breaking down\nhigh-level tasks into grounded subtasks. ASHiTA alternates LLM-assisted\nhierarchical task analysis, to generate the task breakdown, with task-driven 3D\nscene graph construction to generate a suitable representation of the\nenvironment. Our experiments show that ASHiTA performs significantly better\nthan LLM baselines in breaking down high-level tasks into environment-dependent\nsubtasks and is additionally able to achieve grounding performance comparable\nto state-of-the-art methods.", "published": "2025-04-09 03:22:52", "link": "http://arxiv.org/abs/2504.06553v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "LCGC: Learning from Consistency Gradient Conflicting for Class-Imbalanced Semi-Supervised Debiasing", "abstract": "Classifiers often learn to be biased corresponding to the class-imbalanced\ndataset, especially under the semi-supervised learning (SSL) set. While\nprevious work tries to appropriately re-balance the classifiers by subtracting\na class-irrelevant image's logit, but lacks a firm theoretical basis. We\ntheoretically analyze why exploiting a baseline image can refine pseudo-labels\nand prove that the black image is the best choice. We also indicated that as\nthe training process deepens, the pseudo-labels before and after refinement\nbecome closer. Based on this observation, we propose a debiasing scheme dubbed\nLCGC, which Learning from Consistency Gradient Conflicting, by encouraging\nbiased class predictions during training. We intentionally update the\npseudo-labels whose gradient conflicts with the debiased logits, representing\nthe optimization direction offered by the over-imbalanced classifier\npredictions. Then, we debiased the predictions by subtracting the baseline\nimage logits during testing. Extensive experiments demonstrate that LCGC can\nsignificantly improve the prediction accuracy of existing CISSL models on\npublic benchmarks.", "published": "2025-04-09 02:57:53", "link": "http://arxiv.org/abs/2504.06544v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DUKAE: DUal-level Knowledge Accumulation and Ensemble for Pre-Trained Model-Based Continual Learning", "abstract": "Pre-trained model-based continual learning (PTMCL) has garnered growing\nattention, as it enables more rapid acquisition of new knowledge by leveraging\nthe extensive foundational understanding inherent in pre-trained model (PTM).\nMost existing PTMCL methods use Parameter-Efficient Fine-Tuning (PEFT) to learn\nnew knowledge while consolidating existing memory. However, they often face\nsome challenges. A major challenge lies in the misalignment of classification\nheads, as the classification head of each task is trained within a distinct\nfeature space, leading to inconsistent decision boundaries across tasks and,\nconsequently, increased forgetting. Another critical limitation stems from the\nrestricted feature-level knowledge accumulation, with feature learning\ntypically restricted to the initial task only, which constrains the model's\nrepresentation capabilities. To address these issues, we propose a method named\nDUal-level Knowledge Accumulation and Ensemble (DUKAE) that leverages both\nfeature-level and decision-level knowledge accumulation by aligning\nclassification heads into a unified feature space through Gaussian distribution\nsampling and introducing an adaptive expertise ensemble to fuse knowledge\nacross feature subspaces.Extensive experiments on CIFAR-100, ImageNet-R,\nCUB-200, and Cars-196 datasets demonstrate the superior performance of our\napproach.", "published": "2025-04-09 01:40:38", "link": "http://arxiv.org/abs/2504.06521v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "STaR: Seamless Spatial-Temporal Aware Motion Retargeting with Penetration and Consistency Constraints", "abstract": "Motion retargeting seeks to faithfully replicate the spatio-temporal motion\ncharacteristics of a source character onto a target character with a different\nbody shape. Apart from motion semantics preservation, ensuring geometric\nplausibility and maintaining temporal consistency are also crucial for\neffective motion retargeting. However, many existing methods prioritize either\ngeometric plausibility or temporal consistency. Neglecting geometric\nplausibility results in interpenetration while neglecting temporal consistency\nleads to motion jitter. In this paper, we propose a novel sequence-to-sequence\nmodel for seamless Spatial-Temporal aware motion Retargeting (STaR), with\npenetration and consistency constraints. STaR consists of two modules: (1) a\nspatial module that incorporates dense shape representation and a novel limb\npenetration constraint to ensure geometric plausibility while preserving motion\nsemantics, and (2) a temporal module that utilizes a temporal transformer and a\nnovel temporal consistency constraint to predict the entire motion sequence at\nonce while enforcing multi-level trajectory smoothness. The seamless\ncombination of the two modules helps us achieve a good balance between the\nsemantic, geometric, and temporal targets. Extensive experiments on the Mixamo\nand ScanRet datasets demonstrate that our method produces plausible and\ncoherent motions while significantly reducing interpenetration rates compared\nwith other approaches.", "published": "2025-04-09 00:37:08", "link": "http://arxiv.org/abs/2504.06504v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Solving \"pseudo-injective\" polynomial equations over finite dynamical systems", "abstract": "We consider the semiring of abstract finite dynamical systems up to\nisomorphism, with the operations of alternative and synchronous execution. We\ncontinue searching for efficient algorithms for solving polynomial equations of\nthe form $P(X) = B$, with a constant side B, with the goal of decomposing\ncomplex behaviors into simpler systems. Taking inspiration from the\ncharacterization of injective polynomials P over dynamical systems, which is\nbased on a condition on the lengths of limit cycles of their coefficients, we\nintroduce a more general notion of pseudo-injectivity by relaxing this\nconstraint. We prove that the associated equations can be solved efficiently,\neven in certain cases where the input is encoded in an exponentially more\ncompact way.", "published": "2025-04-09 15:49:39", "link": "http://arxiv.org/abs/2504.06986v1", "categories": ["cs.DM", "math.DS"], "primary_category": "cs.DM"}
{"title": "Grouping Strategies on Two-Phase Methods for Bi-objective Combinatorial Optimization", "abstract": "Two-phase methods are commonly used to solve bi-objective combinatorial\noptimization problems. In the first phase, all extreme supported nondominated\npoints are generated through a dichotomic search. This phase also allows the\nidentification of search zones that may contain other nondominated points. The\nsecond phase focuses on exploring these search zones to locate the remaining\npoints, which typically accounts for most of the computational cost. Ranking\nalgorithms are frequently employed to explore each zone individually, but this\napproach leads to redundancies, causing multiple visits to the same solutions.\nTo mitigate these redundancies, we propose several strategies that group\nadjacent zones, allowing a single run of the ranking algorithm for the entire\ngroup. Additionally, we explore an implicit grouping approach based on a new\nconcept of coverage. Our experiments on the Bi-Objective Spanning Tree Problem\ndemonstrate the beneficial impact of these grouping strategies when combined\nwith coverage.", "published": "2025-04-09 13:19:26", "link": "http://arxiv.org/abs/2504.06869v1", "categories": ["cs.DS", "cs.DM"], "primary_category": "cs.DS"}
{"title": "On a Characterization of Spartan Graphs", "abstract": "The eternal vertex cover game is played between an attacker and a defender on\nan undirected graph $G$. The defender identifies $k$ vertices to position\nguards on to begin with. The attacker, on their turn, attacks an edge $e$, and\nthe defender must move a guard along $e$ to defend the attack. The defender may\nmove other guards as well, under the constraint that every guard moves at most\nonce and to a neighboring vertex. The smallest number of guards required to\ndefend attacks forever is called the eternal vertex cover number of $G$,\ndenoted $evc(G)$.\n  For any graph $G$, $evc(G)$ is at least the vertex cover number of $G$,\ndenoted $mvc(G)$. A graph is Spartan if $evc(G) = mvc(G)$. It is known that a\nbipartite graph is Spartan if and only if every edge belongs to a perfect\nmatching. We show that the only K\\\"onig graphs that are Spartan are the\nbipartite Spartan graphs. We also give new lower bounds for $evc(G)$,\ngeneralizing a known lower bound based on cut vertices. We finally show a new\nmatching-based characterization of all Spartan graphs.", "published": "2025-04-09 12:47:29", "link": "http://arxiv.org/abs/2504.06832v1", "categories": ["cs.DM", "math.CO"], "primary_category": "cs.DM"}
{"title": "CHIME: A Compressive Framework for Holistic Interest Modeling", "abstract": "Modeling holistic user interests is important for improving recommendation\nsystems but is challenged by high computational cost and difficulty in handling\ndiverse information with full behavior context. Existing search-based methods\nmight lose critical signals during behavior selection. To overcome these\nlimitations, we propose CHIME: A Compressive Framework for Holistic Interest\nModeling. It uses adapted large language models to encode complete user\nbehaviors with heterogeneous inputs. We introduce multi-granular contrastive\nlearning objectives to capture both persistent and transient interest patterns\nand apply residual vector quantization to generate compact embeddings. CHIME\ndemonstrates superior ranking performance across diverse datasets, establishing\na robust solution for scalable holistic interest modeling in recommendation\nsystems.", "published": "2025-04-09 11:08:49", "link": "http://arxiv.org/abs/2504.06780v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Unifying Search and Recommendation: A Generative Paradigm Inspired by Information Theory", "abstract": "Recommender systems and search engines serve as foundational elements of\nonline platforms, with the former delivering information proactively and the\nlatter enabling users to seek information actively. Unifying both tasks in a\nshared model is promising since it can enhance user modeling and item\nunderstanding. Previous approaches mainly follow a discriminative paradigm,\nutilizing shared encoders to process input features and task-specific heads to\nperform each task. However, this paradigm encounters two key challenges:\ngradient conflict and manual design complexity. From the information theory\nperspective, these challenges potentially both stem from the same issue -- low\nmutual information between the input features and task-specific outputs during\nthe optimization process.\n  To tackle these issues, we propose GenSR, a novel generative paradigm for\nunifying search and recommendation (S&R), which leverages task-specific prompts\nto partition the model's parameter space into subspaces, thereby enhancing\nmutual information. To construct effective subspaces for each task, GenSR first\nprepares informative representations for each subspace and then optimizes both\nsubspaces in one unified model. Specifically, GenSR consists of two main\nmodules: (1) Dual Representation Learning, which independently models\ncollaborative and semantic historical information to derive expressive item\nrepresentations; and (2) S&R Task Unifying, which utilizes contrastive learning\ntogether with instruction tuning to generate task-specific outputs effectively.\nExtensive experiments on two public datasets show GenSR outperforms\nstate-of-the-art methods across S&R tasks. Our work introduces a new generative\nparadigm compared with previous discriminative methods and establishes its\nsuperiority from the mutual information perspective.", "published": "2025-04-09 09:15:37", "link": "http://arxiv.org/abs/2504.06714v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Toward Holistic Evaluation of Recommender Systems Powered by Generative Models", "abstract": "Recommender systems powered by generative models (Gen-RecSys) extend beyond\nclassical item ranking by producing open-ended content, which simultaneously\nunlocks richer user experiences and introduces new risks. On one hand, these\nsystems can enhance personalization and appeal through dynamic explanations and\nmulti-turn dialogues. On the other hand, they might venture into unknown\nterritory-hallucinating nonexistent items, amplifying bias, or leaking private\ninformation. Traditional accuracy metrics cannot fully capture these\nchallenges, as they fail to measure factual correctness, content safety, or\nalignment with user intent.\n  This paper makes two main contributions. First, we categorize the evaluation\nchallenges of Gen-RecSys into two groups: (i) existing concerns that are\nexacerbated by generative outputs (e.g., bias, privacy) and (ii) entirely new\nrisks (e.g., item hallucinations, contradictory explanations). Second, we\npropose a holistic evaluation approach that includes scenario-based assessments\nand multi-metric checks-incorporating relevance, factual grounding, bias\ndetection, and policy compliance. Our goal is to provide a guiding framework so\nresearchers and practitioners can thoroughly assess Gen-RecSys, ensuring\neffective personalization and responsible deployment.", "published": "2025-04-09 08:08:16", "link": "http://arxiv.org/abs/2504.06667v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "BBQRec: Behavior-Bind Quantization for Multi-Modal Sequential Recommendation", "abstract": "Multi-modal sequential recommendation systems leverage auxiliary signals\n(e.g., text, images) to alleviate data sparsity in user-item interactions.\nWhile recent methods exploit large language models to encode modalities into\ndiscrete semantic IDs for autoregressive prediction, we identify two critical\nlimitations: (1) Existing approaches adopt fragmented quantization, where\nmodalities are independently mapped to semantic spaces misaligned with\nbehavioral objectives, and (2) Over-reliance on semantic IDs disrupts\ninter-modal semantic coherence, thereby weakening the expressive power of\nmulti-modal representations for modeling diverse user preferences.\n  To address these challenges, we propose a Behavior-Bind multi-modal\nQuantization for Sequential Recommendation (BBQRec for short) featuring\ndual-aligned quantization and semantics-aware sequence modeling. First, our\nbehavior-semantic alignment module disentangles modality-agnostic behavioral\npatterns from noisy modality-specific features through contrastive codebook\nlearning, ensuring semantic IDs are inherently tied to recommendation tasks.\nSecond, we design a discretized similarity reweighting mechanism that\ndynamically adjusts self-attention scores using quantized semantic\nrelationships, preserving multi-modal synergies while avoiding invasive\nmodifications to the sequence modeling architecture. Extensive evaluations\nacross four real-world benchmarks demonstrate BBQRec's superiority over the\nstate-of-the-art baselines.", "published": "2025-04-09 07:19:48", "link": "http://arxiv.org/abs/2504.06636v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Serendipitous Recommendation System Considering User Curiosity", "abstract": "To address the problem of narrow recommendation ranges caused by an emphasis\non prediction accuracy, serendipitous recommendations, which consider both\nusefulness and unexpectedness, have attracted attention. However, realizing\nserendipitous recommendations is challenging due to the varying proportions of\nusefulness and unexpectedness preferred by different users, which is influenced\nby their differing desires for knowledge. In this paper, we propose a method to\nestimate the proportion of usefulness and unexpectedness that each user desires\nbased on their curiosity, and make recommendations that match this preference.\nThe proposed method estimates a user's curiosity by considering both their\nlong-term and short-term interests. Offline experiments were conducted using\nthe MovieLens-1M dataset to evaluate the effectiveness of the proposed method.\nThe experimental results demonstrate that our method achieves the same level of\nperformance as state-of-the-art method while successfully providing\nserendipitous recommendations.", "published": "2025-04-09 07:15:06", "link": "http://arxiv.org/abs/2504.06633v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Diversity-aware Dual-promotion Poisoning Attack on Sequential Recommendation", "abstract": "Sequential recommender systems (SRSs) excel in capturing users' dynamic\ninterests, thus playing a key role in various industrial applications. The\npopularity of SRSs has also driven emerging research on their security aspects,\nwhere data poisoning attack for targeted item promotion is a typical example.\nExisting attack mechanisms primarily focus on increasing the ranks of target\nitems in the recommendation list by injecting carefully crafted interactions\n(i.e., poisoning sequences), which comes at the cost of demoting users' real\npreferences. Consequently, noticeable recommendation accuracy drops are\nobserved, restricting the stealthiness of the attack. Additionally, the\ngenerated poisoning sequences are prone to substantial repetition of target\nitems, which is a result of the unitary objective of boosting their overall\nexposure and lack of effective diversity regularizations. Such homogeneity not\nonly compromises the authenticity of these sequences, but also limits the\nattack effectiveness, as it ignores the opportunity to establish sequential\ndependencies between the target and many more items in the SRS. To address the\nissues outlined, we propose a Diversity-aware Dual-promotion Sequential\nPoisoning attack method named DDSP for SRSs. Specifically, by theoretically\nrevealing the conflict between recommendation and existing attack objectives,\nwe design a revamped attack objective that promotes the target item while\nmaintaining the relevance of preferred items in a user's ranking list. We\nfurther develop a diversity-aware, auto-regressive poisoning sequence\ngenerator, where a re-ranking method is in place to sequentially pick the\noptimal items by integrating diversity constraints.", "published": "2025-04-09 05:28:41", "link": "http://arxiv.org/abs/2504.06586v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Bridging Queries and Tables through Entities in Table Retrieval", "abstract": "Table retrieval is essential for accessing information stored in structured\ntabular formats; however, it remains less explored than text retrieval. The\ncontent of the table primarily consists of phrases and words, which include a\nlarge number of entities, such as time, locations, persons, and organizations.\nEntities are well-studied in the context of text retrieval, but there is a\nnoticeable lack of research on their applications in table retrieval. In this\nwork, we explore how to leverage entities in tables to improve retrieval\nperformance. First, we investigate the important role of entities in table\nretrieval from a statistical perspective and propose an entity-enhanced\ntraining framework. Subsequently, we use the type of entities to highlight\nentities instead of introducing an external knowledge base. Moreover, we design\nan interaction paradigm based on entity representations. Our proposed framework\nis plug-and-play and flexible, making it easy to integrate into existing table\nretriever training processes. Empirical results on two table retrieval\nbenchmarks, NQ-TABLES and OTT-QA, show that our proposed framework is both\nsimple and effective in enhancing existing retrievers. We also conduct\nextensive analyses to confirm the efficacy of different components. Overall,\nour work provides a promising direction for elevating table retrieval,\nenlightening future research in this area.", "published": "2025-04-09 03:16:33", "link": "http://arxiv.org/abs/2504.06551v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "DiffusionCom: Structure-Aware Multimodal Diffusion Model for Multimodal Knowledge Graph Completion", "abstract": "Most current MKGC approaches are predominantly based on discriminative models\nthat maximize conditional likelihood. These approaches struggle to efficiently\ncapture the complex connections in real-world knowledge graphs, thereby\nlimiting their overall performance. To address this issue, we propose a\nstructure-aware multimodal Diffusion model for multimodal knowledge graph\nCompletion (DiffusionCom). DiffusionCom innovatively approaches the problem\nfrom the perspective of generative models, modeling the association between the\n$(head, relation)$ pair and candidate tail entities as their joint probability\ndistribution $p((head, relation), (tail))$, and framing the MKGC task as a\nprocess of gradually generating the joint probability distribution from noise.\nFurthermore, to fully leverage the structural information in MKGs, we propose\nStructure-MKGformer, an adaptive and structure-aware multimodal knowledge\nrepresentation learning method, as the encoder for DiffusionCom.\nStructure-MKGformer captures rich structural information through a multimodal\ngraph attention network (MGAT) and adaptively fuses it with entity\nrepresentations, thereby enhancing the structural awareness of these\nrepresentations. This design effectively addresses the limitations of existing\nMKGC methods, particularly those based on multimodal pre-trained models, in\nutilizing structural information. DiffusionCom is trained using both generative\nand discriminative losses for the generator, while the feature extractor is\noptimized exclusively with discriminative loss. This dual approach allows\nDiffusionCom to harness the strengths of both generative and discriminative\nmodels. Extensive experiments on the FB15k-237-IMG and WN18-IMG datasets\ndemonstrate that DiffusionCom outperforms state-of-the-art models.", "published": "2025-04-09 02:50:37", "link": "http://arxiv.org/abs/2504.06543v1", "categories": ["cs.IR", "68T30", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Quantum Reverse Shannon Theorem Revisited", "abstract": "Reverse Shannon theorems concern the use of noiseless channels to simulate\nnoisy ones. This is dual to the usual noisy channel coding problem, where a\nnoisy (classical or quantum) channel is used to simulate a noiseless one. The\nQuantum Reverse Shannon Theorem is extensively studied by Bennett and\nco-authors in [IEEE Trans. Inf. Theory, 2014]. They present two distinct\ntheorems, each tailored to classical and quantum channel simulations\nrespectively, explaining the fact that these theorems remain incomparable due\nto the fundamentally different nature of correlations they address. The authors\nleave as an open question the challenge of formulating a unified theorem that\ncould encompass the principles of both and unify them. We unify these two\ntheorems into a single, comprehensive theorem, extending it to the most general\ncase by considering correlations with a general mixed-state reference system.\nFurthermore, we unify feedback and non-feedback theorems by simulating a\ngeneral side information system at the encoder side.", "published": "2025-04-09 17:37:20", "link": "http://arxiv.org/abs/2504.07068v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Finite Field Multiple Access III: from 2-ary to p-ary", "abstract": "This paper extends finite-field multiple-access (FFMA) techniques from binary\nto general $p$-ary source transmission. We introduce element-assemblage (EA)\ncodes over GF($p^m$), generalizing element-pair (EP) codes, and define two\nspecific types for ternary transmission: orthogonal EA codes and double\ncodeword EA (D-CWEA) codes. A unique sum-pattern mapping (USPM) constraint is\nproposed for the design of uniquely-decodable CWEA (UD-CWEA) codes, including\nadditive inverse D-CWEA (AI-D-CWEA) and basis decomposition D-CWEA (BD-D-CWEA)\ncodes. Moreover, we extend EP-coding to EA-coding, focusing on non-orthogonal\nCWEA (NO-CWEA) codes and their USPM constraint in the complex field.\nAdditionally, $p$-ary CWEA codes are constructed using a basis decomposition\nmethod, leveraging ternary decomposition for faster convergence and simplified\nencoder/decoder design. We present a comprehensive performance analysis of the\nproposed FFMA system from two complementary perspectives: channel capacity and\nerror performance. We demonstrate that equal power allocation (EPA) achieves\nthe theoretical channel capacity bound, while independently developing a\nrate-driven capacity alignment (CA) theorem based on the capacity-to-rate ratio\n(CRR) metric for error performance analysis. We then explore the multiuser\nfinite blocklength (FBL) characteristics of FFMA systems. Finally, a\ncomparative analysis of $p$-ary transmission systems against classical binary\nsystems is conducted, revealing that low-order $p$-ary systems (e.g., $p=3$)\noutperform binary systems at small loading factors, while higher-order systems\n(e.g., $p=257$) excel at larger loading factors. These findings highlight the\npotential of $p$-ary systems, although practical implementations may benefit\nfrom decomposing $p$-ary systems into ternary systems to manage complexity.", "published": "2025-04-09 14:41:36", "link": "http://arxiv.org/abs/2504.06937v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Optimality of Gradient-MUSIC for Spectral Estimation", "abstract": "The goal of spectral estimation is to estimate the frequencies and amplitudes\nof a nonharmonic Fourier sum given noisy time samples. This paper introduces\nthe Gradient-MUSIC algorithm, which is a novel nonconvex optimization\nreformulation of the classical MUSIC algorithm. Under the assumption that\n$m\\Delta\\geq 8\\pi$, where $\\pi/m$ is the Nyquist rate and $\\Delta$ is the\nminimum separation of the frequencies normalized to be in $[0,2\\pi)$, we\nprovide a thorough geometric analysis of the objective functions generated by\nthe algorithm. Gradient-MUSIC thresholds the objective function on a set that\nis as coarse as possible and locates a set of suitable initialization for\ngradient descent. Although the objective function is nonconvex, gradient\ndescent converges exponentially fast to the desired local minima, which are the\nestimated frequencies of the signal. For deterministic $\\ell^p$ perturbations\nand any $p\\in [1,\\infty]$, Gradient-MUSIC estimates the frequencies and\namplitudes at the minimax optimal rate in terms of the noise level and $m$. For\nexample, if the noise has $\\ell^\\infty$ norm at most $\\epsilon$, then the\nfrequencies and amplitudes are recovered up to error at most $C\\epsilon/m$ and\n$C\\epsilon$, respectively, which are optimal in $\\epsilon$ and $m$. Aside from\nlogarithmic factors, Gradient-MUSIC is optimal for white noise and matches the\nrate achieved by nonlinear least squares for various families of nonstationary\nindependent Gaussian noise. Our results show that classical MUSIC is equally\noptimal, but it requires an expensive search on a thin grid, whereas\nGradient-MUSIC is always computationally more efficient, especially for small\nnoise. As a consequence of this paper, for sufficiently well separated\nfrequencies, both Gradient-MUSIC and classical MUSIC are the first provably\noptimal and computationally tractable algorithms for deterministic $\\ell^p$\nperturbations.", "published": "2025-04-09 13:00:49", "link": "http://arxiv.org/abs/2504.06842v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Analog Computing with Microwave Networks", "abstract": "Analog computing has been recently revived due to its potential for\nenergy-efficient and highly parallel computations. In this paper, we\ninvestigate analog computers that linearly process microwave signals, named\nmicrowave linear analog computers (MiLACs), and their applications in signal\nprocessing for communications. We model a MiLAC as a multiport microwave\nnetwork with tunable impedance components, which enables the execution of\nmathematical operations by reconfiguring the microwave network and applying\ninput signals at its ports. We demonstrate that a MiLAC can efficiently compute\nthe linear minimum mean square error (LMMSE) estimator, widely used in\nmultiple-input multiple-output (MIMO) communications beamforming and detection,\nwith remarkably low computational complexity, unachievable through digital\ncomputing. Specifically, the LMMSE estimator can be computed with complexity\ngrowing with the square of its input size, rather than the cube, with\nrevolutionary applications to gigantic MIMO beamforming and detection.", "published": "2025-04-09 11:29:39", "link": "http://arxiv.org/abs/2504.06790v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Locally Repairable Convertible Codes: Improved Lower Bound and General Construction", "abstract": "In this paper, we consider the convertible code with locally repairable\nproperty. We present an improved lower bound on access cost associated with\n$(r,\\delta)$. Then, we provide a general construction of convertible codes with\noptimal access cost which shows that those codes can be with super-linear\nlength or maximum repairable property. Additionally, employing the known\nlocally repairable codes with super-linear length or maximum repairable\nproperty, we provide explicit constructions of convertible codes with\nsuper-linear length or maximum repairable property.", "published": "2025-04-09 09:46:08", "link": "http://arxiv.org/abs/2504.06734v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Several new infinite families of NMDS codes with arbitrary dimensions supporting $t$-designs", "abstract": "Near maximum distance separable (NMDS) codes, where both the code and its\ndual are almost maximum distance separable, play pivotal roles in combinatorial\ndesign theory and cryptographic applications. Despite progress in fixed\ndimensions (e.g., dimension 4 codes by Ding and Tang \\cite{Ding2020}),\nconstructing NMDS codes with arbitrary dimensions supporting $t$-designs\n($t\\geq 2$) has remained open. In this paper, we construct two infinite\nfamilies of NMDS codes over $\\mathbb{F}_q$ for any prime power $q$ with\nflexible dimensions and determine their weight distributions. Further, two\nadditional families with arbitrary dimensions over $\\mathbb{F}_{2^m}$\nsupporting $2$-designs and $3$-designs, and their weight distributions are\nobtained. Our results fully generalize prior fixed-dimension\nworks~\\cite{DingY2024,Heng2023,Heng20231,Xu2022}, and affirmatively settle the\nHeng-Wang conjecture \\cite{Heng2023} on the existence of NMDS codes with\nflexible parameters supporting $2$-designs.", "published": "2025-04-09 03:02:10", "link": "http://arxiv.org/abs/2504.06546v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Neural Motion Simulator: Pushing the Limit of World Models in Reinforcement Learning", "abstract": "An embodied system must not only model the patterns of the external world but\nalso understand its own motion dynamics. A motion dynamic model is essential\nfor efficient skill acquisition and effective planning. In this work, we\nintroduce the neural motion simulator (MoSim), a world model that predicts the\nfuture physical state of an embodied system based on current observations and\nactions. MoSim achieves state-of-the-art performance in physical state\nprediction and provides competitive performance across a range of downstream\ntasks. This works shows that when a world model is accurate enough and performs\nprecise long-horizon predictions, it can facilitate efficient skill acquisition\nin imagined worlds and even enable zero-shot reinforcement learning.\nFurthermore, MoSim can transform any model-free reinforcement learning (RL)\nalgorithm into a model-based approach, effectively decoupling physical\nenvironment modeling from RL algorithm development. This separation allows for\nindependent advancements in RL algorithms and world modeling, significantly\nimproving sample efficiency and enhancing generalization capabilities. Our\nfindings highlight that world models for motion dynamics is a promising\ndirection for developing more versatile and capable embodied systems.", "published": "2025-04-09 17:59:32", "link": "http://arxiv.org/abs/2504.07095v1", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Identifying Unknown Stochastic Dynamics via Finite expression methods", "abstract": "Modeling stochastic differential equations (SDEs) is crucial for\nunderstanding complex dynamical systems in various scientific fields. Recent\nmethods often employ neural network-based models, which typically represent\nSDEs through a combination of deterministic and stochastic terms. However,\nthese models usually lack interpretability and have difficulty generalizing\nbeyond their training domain. This paper introduces the Finite Expression\nMethod (FEX), a symbolic learning approach designed to derive interpretable\nmathematical representations of the deterministic component of SDEs. For the\nstochastic component, we integrate FEX with advanced generative modeling\ntechniques to provide a comprehensive representation of SDEs. The numerical\nexperiments on linear, nonlinear, and multidimensional SDEs demonstrate that\nFEX generalizes well beyond the training domain and delivers more accurate\nlong-term predictions compared to neural network-based methods. The symbolic\nexpressions identified by FEX not only improve prediction accuracy but also\noffer valuable scientific insights into the underlying dynamics of the systems,\npaving the way for new scientific discoveries.", "published": "2025-04-09 17:57:54", "link": "http://arxiv.org/abs/2504.07085v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Enhancing Downstream Analysis in Genome Sequencing: Species Classification While Basecalling", "abstract": "The ability to quickly and accurately identify microbial species in a sample,\nknown as metagenomic profiling, is critical across various fields, from\nhealthcare to environmental science. This paper introduces a novel method to\nprofile signals coming from sequencing devices in parallel with determining\ntheir nucleotide sequences, a process known as basecalling, via a\nmulti-objective deep neural network for simultaneous basecalling and\nmulti-class genome classification. We introduce a new loss strategy where\nlosses for basecalling and classification are back-propagated separately, with\nmodel weights combined for the shared layers, and a pre-configured ranking\nstrategy allowing top-K species accuracy, giving users flexibility to choose\nbetween higher accuracy or higher speed at identifying the species. We achieve\nstate-of-the-art basecalling accuracies, while classification accuracies meet\nand exceed the results of state-of-the-art binary classifiers, attaining an\naverage of 92.5%/98.9% accuracy at identifying the top-1/3 species among a\ntotal of 17 genomes in the Wick bacterial dataset. The work presented here has\nimplications for future studies in metagenomic profiling by accelerating the\nbottleneck step of matching the DNA sequence to the correct genome.", "published": "2025-04-09 17:30:43", "link": "http://arxiv.org/abs/2504.07065v1", "categories": ["q-bio.GN", "cs.LG"], "primary_category": "q-bio.GN"}
{"title": "To Backtrack or Not to Backtrack: When Sequential Search Limits Model Reasoning", "abstract": "Recent advancements in large language models have significantly improved\ntheir reasoning abilities, particularly through techniques involving search and\nbacktracking. Backtracking naturally scales test-time compute by enabling\nsequential, linearized exploration via long chain-of-thought (CoT) generation.\nHowever, this is not the only strategy for scaling test-time compute: parallel\nsampling with best-of-n selection provides an alternative that generates\ndiverse solutions simultaneously. Despite the growing adoption of sequential\nsearch, its advantages over parallel sampling--especially under a fixed compute\nbudget remain poorly understood. In this paper, we systematically compare these\ntwo approaches on two challenging reasoning tasks: CountDown and Sudoku.\nSurprisingly, we find that sequential search underperforms parallel sampling on\nCountDown but outperforms it on Sudoku, suggesting that backtracking is not\nuniversally beneficial. We identify two factors that can cause backtracking to\ndegrade performance: (1) training on fixed search traces can lock models into\nsuboptimal strategies, and (2) explicit CoT supervision can discourage\n\"implicit\" (non-verbalized) reasoning. Extending our analysis to reinforcement\nlearning (RL), we show that models with backtracking capabilities benefit\nsignificantly from RL fine-tuning, while models without backtracking see\nlimited, mixed gains. Together, these findings challenge the assumption that\nbacktracking universally enhances LLM reasoning, instead revealing a complex\ninteraction between task structure, training data, model scale, and learning\nparadigm.", "published": "2025-04-09 17:12:49", "link": "http://arxiv.org/abs/2504.07052v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Identifying Key Challenges of Hardness-Based Resampling", "abstract": "Performance gap across classes remains a persistent challenge in machine\nlearning, often attributed to variations in class hardness. One way to quantify\nclass hardness is through sample complexity - the minimum number of samples\nrequired to effectively learn a given class. Sample complexity theory suggests\nthat class hardness is driven by differences in the amount of data required for\ngeneralization. That is, harder classes need substantially more samples to\nachieve generalization. Therefore, hardness-based resampling is a promising\napproach to mitigate these performance disparities. While resampling has been\nstudied extensively in data-imbalanced settings, its impact on balanced\ndatasets remains unexplored.\n  This raises the fundamental question whether resampling is effective because\nit addresses data imbalance or hardness imbalance. We begin addressing this\nquestion by introducing class imbalance into balanced datasets and evaluate its\neffect on performance disparities. We oversample hard classes and undersample\neasy classes to bring hard classes closer to their sample complexity\nrequirements while maintaining a constant dataset size for fairness. We\nestimate class-level hardness using the Area Under the Margin (AUM) hardness\nestimator and leverage it to compute resampling ratios. Using these ratios, we\nperform hardness-based resampling on the well-known CIFAR-10 and CIFAR-100\ndatasets.\n  Contrary to theoretical expectations, our results show that hardness-based\nresampling does not meaningfully affect class-wise performance disparities. To\nexplain this discrepancy, we conduct detailed analyses to identify key\nchallenges unique to hardness-based imbalance, distinguishing it from\ntraditional data-based imbalance. Our insights help explain why theoretical\nsample complexity expectations fail to translate into practical performance\ngains and we provide guidelines for future research.", "published": "2025-04-09 16:45:57", "link": "http://arxiv.org/abs/2504.07031v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Using ML filters to help automated vulnerability repairs: when it helps and when it doesn't", "abstract": "[Context:] The acceptance of candidate patches in automated program repair\nhas been typically based on testing oracles. Testing requires typically a\ncostly process of building the application while ML models can be used to\nquickly classify patches, thus allowing more candidate patches to be generated\nin a positive feedback loop. [Problem:] If the model predictions are unreliable\n(as in vulnerability detection) they can hardly replace the more reliable\noracles based on testing. [New Idea:] We propose to use an ML model as a\npreliminary filter of candidate patches which is put in front of a traditional\nfilter based on testing. [Preliminary Results:] We identify some theoretical\nbounds on the precision and recall of the ML algorithm that makes such\noperation meaningful in practice. With these bounds and the results published\nin the literature, we calculate how fast some of state-of-the art vulnerability\ndetectors must be to be more effective over a traditional AVR pipeline such as\nAPR4Vuln based just on testing.", "published": "2025-04-09 16:39:09", "link": "http://arxiv.org/abs/2504.07027v1", "categories": ["cs.SE", "cs.CR", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Adapting GT2-FLS for Uncertainty Quantification: A Blueprint Calibration Strategy", "abstract": "Uncertainty Quantification (UQ) is crucial for deploying reliable Deep\nLearning (DL) models in high-stakes applications. Recently, General Type-2\nFuzzy Logic Systems (GT2-FLSs) have been proven to be effective for UQ,\noffering Prediction Intervals (PIs) to capture uncertainty. However, existing\nmethods often struggle with computational efficiency and adaptability, as\ngenerating PIs for new coverage levels $(\\phi_d)$ typically requires retraining\nthe model. Moreover, methods that directly estimate the entire conditional\ndistribution for UQ are computationally expensive, limiting their scalability\nin real-world scenarios. This study addresses these challenges by proposing a\nblueprint calibration strategy for GT2-FLSs, enabling efficient adaptation to\nany desired $\\phi_d$ without retraining. By exploring the relationship between\n$\\alpha$-plane type reduced sets and uncertainty coverage, we develop two\ncalibration methods: a lookup table-based approach and a derivative-free\noptimization algorithm. These methods allow GT2-FLSs to produce accurate and\nreliable PIs while significantly reducing computational overhead. Experimental\nresults on high-dimensional datasets demonstrate that the calibrated GT2-FLS\nachieves superior performance in UQ, highlighting its potential for scalable\nand practical applications.", "published": "2025-04-09 16:32:43", "link": "http://arxiv.org/abs/2504.07017v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FAME: Introducing Fuzzy Additive Models for Explainable AI", "abstract": "In this study, we introduce the Fuzzy Additive Model (FAM) and FAM with\nExplainability (FAME) as a solution for Explainable Artificial Intelligence\n(XAI). The family consists of three layers: (1) a Projection Layer that\ncompresses the input space, (2) a Fuzzy Layer built upon Single Input-Single\nOutput Fuzzy Logic Systems (SFLS), where SFLS functions as subnetworks within\nan additive index model, and (3) an Aggregation Layer. This architecture\nintegrates the interpretability of SFLS, which uses human-understandable\nif-then rules, with the explainability of input-output relationships,\nleveraging the additive model structure. Furthermore, using SFLS inherently\naddresses issues such as the curse of dimensionality and rule explosion. To\nfurther improve interpretability, we propose a method for sculpting antecedent\nspace within FAM, transforming it into FAME. We show that FAME captures the\ninput-output relationships with fewer active rules, thus improving clarity. To\nlearn the FAM family, we present a deep learning framework. Through the\npresented comparative results, we demonstrate the promising potential of FAME\nin reducing model complexity while retaining interpretability, positioning it\nas a valuable tool for XAI.", "published": "2025-04-09 16:29:55", "link": "http://arxiv.org/abs/2504.07011v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Assumption-free fidelity bounds for hardware noise characterization", "abstract": "In the Quantum Supremacy regime, quantum computers may overcome classical\nmachines on several tasks if we can estimate, mitigate, or correct unavoidable\nhardware noise. Estimating the error requires classical simulations, which\nbecome unfeasible in the Quantum Supremacy regime. We leverage Machine Learning\ndata-driven approaches and Conformal Prediction, a Machine Learning uncertainty\nquantification tool known for its mild assumptions and finite-sample validity,\nto find theoretically valid upper bounds of the fidelity between noiseless and\nnoisy outputs of quantum devices. Under reasonable extrapolation assumptions,\nthe proposed scheme applies to any Quantum Computing hardware, does not require\nmodeling the device's noise sources, and can be used when classical simulations\nare unavailable, e.g. in the Quantum Supremacy regime.", "published": "2025-04-09 16:27:52", "link": "http://arxiv.org/abs/2504.07010v1", "categories": ["quant-ph", "cs.LG", "stat.ML"], "primary_category": "quant-ph"}
{"title": "Neural Signal Compression using RAMAN tinyML Accelerator for BCI Applications", "abstract": "High-quality, multi-channel neural recording is indispensable for\nneuroscience research and clinical applications. Large-scale brain recordings\noften produce vast amounts of data that must be wirelessly transmitted for\nsubsequent offline analysis and decoding, especially in brain-computer\ninterfaces (BCIs) utilizing high-density intracortical recordings with hundreds\nor thousands of electrodes. However, transmitting raw neural data presents\nsignificant challenges due to limited communication bandwidth and resultant\nexcessive heating. To address this challenge, we propose a neural signal\ncompression scheme utilizing Convolutional Autoencoders (CAEs), which achieves\na compression ratio of up to 150 for compressing local field potentials (LFPs).\nThe CAE encoder section is implemented on RAMAN, an energy-efficient tinyML\naccelerator designed for edge computing, and subsequently deployed on an Efinix\nTi60 FPGA with 37.3k LUTs and 8.6k register utilization. RAMAN leverages\nsparsity in activation and weights through zero skipping, gating, and weight\ncompression techniques. Additionally, we employ hardware-software\nco-optimization by pruning CAE encoder model parameters using a hardware-aware\nbalanced stochastic pruning strategy, resolving workload imbalance issues and\neliminating indexing overhead to reduce parameter storage requirements by up to\n32.4%. Using the proposed compact depthwise separable convolutional autoencoder\n(DS-CAE) model, the compressed neural data from RAMAN is reconstructed offline\nwith superior signal-to-noise and distortion ratios (SNDR) of 22.6 dB and 27.4\ndB, along with R2 scores of 0.81 and 0.94, respectively, evaluated on two\nmonkey neural recordings.", "published": "2025-04-09 16:09:00", "link": "http://arxiv.org/abs/2504.06996v1", "categories": ["cs.AR", "cs.HC", "cs.LG"], "primary_category": "cs.AR"}
{"title": "Dissimilar Batch Decompositions of Random Datasets", "abstract": "For better learning, large datasets are often split into small batches and\nfed sequentially to the predictive model. In this paper, we study such batch\ndecompositions from a probabilistic perspective. We assume that data points\n(possibly corrupted) are drawn independently from a given space and define a\nconcept of similarity between two data points. We then consider decompositions\nthat restrict the amount of similarity within each batch and obtain high\nprobability bounds for the minimum size. We demonstrate an inherent tradeoff\nbetween relaxing the similarity constraint and the overall size and also use\nmartingale methods to obtain bounds for the maximum size of data subsets with a\ngiven similarity.", "published": "2025-04-09 15:58:06", "link": "http://arxiv.org/abs/2504.06991v1", "categories": ["cs.LG", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Free Random Projection for In-Context Reinforcement Learning", "abstract": "Hierarchical inductive biases are hypothesized to promote generalizable\npolicies in reinforcement learning, as demonstrated by explicit hyperbolic\nlatent representations and architectures. Therefore, a more flexible approach\nis to have these biases emerge naturally from the algorithm. We introduce Free\nRandom Projection, an input mapping grounded in free probability theory that\nconstructs random orthogonal matrices where hierarchical structure arises\ninherently. The free random projection integrates seamlessly into existing\nin-context reinforcement learning frameworks by encoding hierarchical\norganization within the input space without requiring explicit architectural\nmodifications. Empirical results on multi-environment benchmarks show that free\nrandom projection consistently outperforms the standard random projection,\nleading to improvements in generalization. Furthermore, analyses within\nlinearly solvable Markov decision processes and investigations of the spectrum\nof kernel random matrices reveal the theoretical underpinnings of free random\nprojection's enhanced performance, highlighting its capacity for effective\nadaptation in hierarchically structured state spaces.", "published": "2025-04-09 15:38:50", "link": "http://arxiv.org/abs/2504.06983v1", "categories": ["cs.LG", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Artificial Intelligence for Pediatric Height Prediction Using Large-Scale Longitudinal Body Composition Data", "abstract": "This study developed an accurate artificial intelligence model for predicting\nfuture height in children and adolescents using anthropometric and body\ncomposition data from the GP Cohort Study (588,546 measurements from 96,485\nchildren aged 7-18). The model incorporated anthropometric measures, body\ncomposition, standard deviation scores, and growth velocity parameters, with\nperformance evaluated using RMSE, MAE, and MAPE. Results showed high accuracy\nwith males achieving average RMSE, MAE, and MAPE of 2.51 cm, 1.74 cm, and\n1.14%, and females showing 2.28 cm, 1.68 cm, and 1.13%, respectively.\nExplainable AI approaches identified height SDS, height velocity, and soft lean\nmass velocity as crucial predictors. The model generated personalized growth\ncurves by estimating individual-specific height trajectories, offering a robust\ntool for clinical decision support, early identification of growth disorders,\nand optimization of growth outcomes.", "published": "2025-04-09 15:32:15", "link": "http://arxiv.org/abs/2504.06979v1", "categories": ["q-bio.QM", "cs.LG", "62P10, 68T05"], "primary_category": "q-bio.QM"}
{"title": "ASRL:A robust loss function with potential for development", "abstract": "In this article, we proposed a partition:wise robust loss function based on\nthe previous robust loss function. The characteristics of this loss function\nare that it achieves high robustness and a wide range of applicability through\npartition-wise design and adaptive parameter adjustment. Finally, the\nadvantages and development potential of this loss function were verified by\napplying this loss function to the regression question and using five different\ndatasets (with different dimensions, different sample numbers, and different\nfields) to compare with the other loss functions. The results of multiple\nexperiments have proven the advantages of our loss function .", "published": "2025-04-09 14:40:46", "link": "http://arxiv.org/abs/2504.06935v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "RO-FIGS: Efficient and Expressive Tree-Based Ensembles for Tabular Data", "abstract": "Tree-based models are often robust to uninformative features and can\naccurately capture non-smooth, complex decision boundaries. Consequently, they\noften outperform neural network-based models on tabular datasets at a\nsignificantly lower computational cost. Nevertheless, the capability of\ntraditional tree-based ensembles to express complex relationships efficiently\nis limited by using a single feature to make splits. To improve the efficiency\nand expressiveness of tree-based methods, we propose Random Oblique Fast\nInterpretable Greedy-Tree Sums (RO-FIGS). RO-FIGS builds on Fast Interpretable\nGreedy-Tree Sums, and extends it by learning trees with oblique or multivariate\nsplits, where each split consists of a linear combination learnt from random\nsubsets of features. This helps uncover interactions between features and\nimproves performance. The proposed method is suitable for tabular datasets with\nboth numerical and categorical features. We evaluate RO-FIGS on 22 real-world\ntabular datasets, demonstrating superior performance and much smaller models\nover other tree- and neural network-based methods. Additionally, we analyse\ntheir splits to reveal valuable insights into feature interactions, enriching\nthe information learnt from SHAP summary plots, and thereby demonstrating the\nenhanced interpretability of RO-FIGS models. The proposed method is well-suited\nfor applications, where balance between accuracy and interpretability is\nessential.", "published": "2025-04-09 14:35:24", "link": "http://arxiv.org/abs/2504.06927v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "The Importance of Being Discrete: Measuring the Impact of Discretization in End-to-End Differentially Private Synthetic Data", "abstract": "Differentially Private (DP) generative marginal models are often used in the\nwild to release synthetic tabular datasets in lieu of sensitive data while\nproviding formal privacy guarantees. These models approximate low-dimensional\nmarginals or query workloads; crucially, they require the training data to be\npre-discretized, i.e., continuous values need to first be partitioned into\nbins. However, as the range of values (or their domain) is often inferred\ndirectly from the training data, with the number of bins and bin edges\ntypically defined arbitrarily, this approach can ultimately break end-to-end DP\nguarantees and may not always yield optimal utility.\n  In this paper, we present an extensive measurement study of four\ndiscretization strategies in the context of DP marginal generative models. More\nprecisely, we design DP versions of three discretizers (uniform, quantile, and\nk-means) and reimplement the PrivTree algorithm. We find that optimizing both\nthe choice of discretizer and bin count can improve utility, on average, by\nalmost 30% across six DP marginal models, compared to the default strategy and\nnumber of bins, with PrivTree being the best-performing discretizer in the\nmajority of cases. We demonstrate that, while DP generative models with\nnon-private discretization remain vulnerable to membership inference attacks,\napplying DP during discretization effectively mitigates this risk. Finally, we\npropose an optimized approach for automatically selecting the optimal number of\nbins, achieving high utility while reducing both privacy budget consumption and\ncomputational overhead.", "published": "2025-04-09 14:30:30", "link": "http://arxiv.org/abs/2504.06923v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "CRYSIM: Prediction of Symmetric Structures of Large Crystals with GPU-based Ising Machines", "abstract": "Solving black-box optimization problems with Ising machines is increasingly\ncommon in materials science. However, their application to crystal structure\nprediction (CSP) is still ineffective due to symmetry agnostic encoding of\natomic coordinates. We introduce CRYSIM, an algorithm that encodes the space\ngroup, the Wyckoff positions combination, and coordinates of independent atomic\nsites as separate variables. This encoding reduces the search space\nsubstantially by exploiting the symmetry in space groups. When CRYSIM is\ninterfaced to Fixstars Amplify, a GPU-based Ising machine, its prediction\nperformance was competitive with CALYPSO and Bayesian optimization for crystals\ncontaining more than 150 atoms in a unit cell. Although it is not realistic to\ninterface CRYSIM to current small-scale quantum devices, it has the potential\nto become the standard CSP algorithm in the coming quantum age.", "published": "2025-04-09 13:33:48", "link": "http://arxiv.org/abs/2504.06878v1", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Regret Bounds for Robust Online Decision Making", "abstract": "We propose a framework which generalizes \"decision making with structured\nobservations\" by allowing robust (i.e. multivalued) models. In this framework,\neach model associates each decision with a convex set of probability\ndistributions over outcomes. Nature can choose distributions out of this set in\nan arbitrary (adversarial) manner, that can be nonoblivious and depend on past\nhistory. The resulting framework offers much greater generality than classical\nbandits and reinforcement learning, since the realizability assumption becomes\nmuch weaker and more realistic. We then derive a theory of regret bounds for\nthis framework. Although our lower and upper bounds are not tight, they are\nsufficient to fully characterize power-law learnability. We demonstrate this\ntheory in two special cases: robust linear bandits and tabular robust online\nreinforcement learning. In both cases, we derive regret bounds that improve\nstate-of-the-art (except that we do not address computational efficiency).", "published": "2025-04-09 12:25:00", "link": "http://arxiv.org/abs/2504.06820v1", "categories": ["cs.LG", "68Q32", "I.2.6"], "primary_category": "cs.LG"}
{"title": "Deep Neural Koopman Operator-based Economic Model Predictive Control of Shipboard Carbon Capture System", "abstract": "Shipboard carbon capture is a promising solution to help reduce carbon\nemissions in international shipping. In this work, we propose a data-driven\ndynamic modeling and economic predictive control approach within the Koopman\nframework. This integrated modeling and control approach is used to achieve\nsafe and energy-efficient process operation of shipboard post-combustion carbon\ncapture plants. Specifically, we propose a deep neural Koopman operator\nmodeling approach, based on which a Koopman model with time-varying model\nparameters is established. This Koopman model predicts the overall economic\noperational cost and key system outputs, based on accessible partial state\nmeasurements. By leveraging this learned model, a constrained economic\npredictive control scheme is developed. Despite time-varying parameters\ninvolved in the formulated model, the formulated optimization problem\nassociated with the economic predictive control design is convex, and it can be\nsolved efficiently during online control implementations. Extensive tests are\nconducted on a high-fidelity simulation environment for shipboard\npost-combustion carbon capture processes. Four ship operational conditions are\ntaken into account. The results show that the proposed method significantly\nimproves the overall economic operational performance and carbon capture rate.\nAdditionally, the proposed method guarantees safe operation by ensuring that\nhard constraints on the system outputs are satisfied.", "published": "2025-04-09 12:22:42", "link": "http://arxiv.org/abs/2504.06818v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Mass Balance Approximation of Unfolding Improves Potential-Like Methods for Protein Stability Predictions", "abstract": "The prediction of protein stability changes following single-point mutations\nplays a pivotal role in computational biology, particularly in areas like drug\ndiscovery, enzyme reengineering, and genetic disease analysis. Although\ndeep-learning strategies have pushed the field forward, their use in standard\nworkflows remains limited due to resource demands. Conversely, potential-like\nmethods are fast, intuitive, and efficient. Yet, these typically estimate Gibbs\nfree energy shifts without considering the free-energy variations in the\nunfolded protein state, an omission that may breach mass balance and diminish\naccuracy. This study shows that incorporating a mass-balance correction (MBC)\nto account for the unfolded state significantly enhances these methods. While\nmany machine learning models partially model this balance, our analysis\nsuggests that a refined representation of the unfolded state may improve the\npredictive performance.", "published": "2025-04-09 11:53:02", "link": "http://arxiv.org/abs/2504.06806v1", "categories": ["q-bio.QM", "cs.LG", "physics.bio-ph"], "primary_category": "q-bio.QM"}
{"title": "Robust Classification with Noisy Labels Based on Posterior Maximization", "abstract": "Designing objective functions robust to label noise is crucial for real-world\nclassification algorithms. In this paper, we investigate the robustness to\nlabel noise of an $f$-divergence-based class of objective functions recently\nproposed for supervised classification, herein referred to as $f$-PML. We show\nthat, in the presence of label noise, any of the $f$-PML objective functions\ncan be corrected to obtain a neural network that is equal to the one learned\nwith the clean dataset. Additionally, we propose an alternative and novel\ncorrection approach that, during the test phase, refines the posterior\nestimated by the neural network trained in the presence of label noise. Then,\nwe demonstrate that, even if the considered $f$-PML objective functions are not\nsymmetric, they are robust to symmetric label noise for any choice of\n$f$-divergence, without the need for any correction approach. This allows us to\nprove that the cross-entropy, which belongs to the $f$-PML class, is robust to\nsymmetric label noise. Finally, we show that such a class of objective\nfunctions can be used together with refined training strategies, achieving\ncompetitive performance against state-of-the-art techniques of classification\nwith label noise.", "published": "2025-04-09 11:52:51", "link": "http://arxiv.org/abs/2504.06805v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Beware of \"Explanations\" of AI", "abstract": "Understanding the decisions made and actions taken by increasingly complex AI\nsystem remains a key challenge. This has led to an expanding field of research\nin explainable artificial intelligence (XAI), highlighting the potential of\nexplanations to enhance trust, support adoption, and meet regulatory standards.\nHowever, the question of what constitutes a \"good\" explanation is dependent on\nthe goals, stakeholders, and context. At a high level, psychological insights\nsuch as the concept of mental model alignment can offer guidance, but success\nin practice is challenging due to social and technical factors. As a result of\nthis ill-defined nature of the problem, explanations can be of poor quality\n(e.g. unfaithful, irrelevant, or incoherent), potentially leading to\nsubstantial risks. Instead of fostering trust and safety, poorly designed\nexplanations can actually cause harm, including wrong decisions, privacy\nviolations, manipulation, and even reduced AI adoption. Therefore, we caution\nstakeholders to beware of explanations of AI: while they can be vital, they are\nnot automatically a remedy for transparency or responsible AI adoption, and\ntheir misuse or limitations can exacerbate harm. Attention to these caveats can\nhelp guide future research to improve the quality and impact of AI\nexplanations.", "published": "2025-04-09 11:31:08", "link": "http://arxiv.org/abs/2504.06791v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Hybrid machine learning models based on physical patterns to accelerate CFD simulations: a short guide on autoregressive models", "abstract": "Accurate modeling of the complex dynamics of fluid flows is a fundamental\nchallenge in computational physics and engineering. This study presents an\ninnovative integration of High-Order Singular Value Decomposition (HOSVD) with\nLong Short-Term Memory (LSTM) architectures to address the complexities of\nreduced-order modeling (ROM) in fluid dynamics. HOSVD improves the\ndimensionality reduction process by preserving multidimensional structures,\nsurpassing the limitations of Singular Value Decomposition (SVD). The\nmethodology is tested across numerical and experimental data sets, including\ntwo- and three-dimensional (2D and 3D) cylinder wake flows, spanning both\nlaminar and turbulent regimes. The emphasis is also on exploring how the depth\nand complexity of LSTM architectures contribute to improving predictive\nperformance. Simpler architectures with a single dense layer effectively\ncapture the periodic dynamics, demonstrating the network's ability to model\nnon-linearities and chaotic dynamics. The addition of extra layers provides\nhigher accuracy at minimal computational cost. These additional layers enable\nthe network to expand its representational capacity, improving the prediction\naccuracy and reliability. The results demonstrate that HOSVD outperforms SVD in\nall tested scenarios, as evidenced by using different error metrics. Efficient\nmode truncation by HOSVD-based models enables the capture of complex temporal\npatterns, offering reliable predictions even in challenging, noise-influenced\ndata sets. The findings underscore the adaptability and robustness of\nHOSVD-LSTM architectures, offering a scalable framework for modeling fluid\ndynamics.", "published": "2025-04-09 10:56:03", "link": "http://arxiv.org/abs/2504.06774v1", "categories": ["physics.flu-dyn", "cs.LG"], "primary_category": "physics.flu-dyn"}
{"title": "FedMerge: Federated Personalization via Model Merging", "abstract": "One global model in federated learning (FL) might not be sufficient to serve\nmany clients with non-IID tasks and distributions. While there has been\nadvances in FL to train multiple global models for better personalization, they\nonly provide limited choices to clients so local finetuning is still\nindispensable. In this paper, we propose a novel ``FedMerge'' approach that can\ncreate a personalized model per client by simply merging multiple global models\nwith automatically optimized and customized weights. In FedMerge, a few global\nmodels can serve many non-IID clients, even without further local finetuning.\nWe formulate this problem as a joint optimization of global models and the\nmerging weights for each client. Unlike existing FL approaches where the server\nbroadcasts one or multiple global models to all clients, the server only needs\nto send a customized, merged model to each client. Moreover, instead of\nperiodically interrupting the local training and re-initializing it to a global\nmodel, the merged model aligns better with each client's task and data\ndistribution, smoothening the local-global gap between consecutive rounds\ncaused by client drift. We evaluate FedMerge on three different non-IID\nsettings applied to different domains with diverse tasks and data types, in\nwhich FedMerge consistently outperforms existing FL approaches, including\nclustering-based and mixture-of-experts (MoE) based methods.", "published": "2025-04-09 10:44:14", "link": "http://arxiv.org/abs/2504.06768v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Efficient Deployment of Spiking Neural Networks on SpiNNaker2 for DVS Gesture Recognition Using Neuromorphic Intermediate Representation", "abstract": "Spiking Neural Networks (SNNs) are highly energy-efficient during inference,\nmaking them particularly suitable for deployment on neuromorphic hardware.\nTheir ability to process event-driven inputs, such as data from dynamic vision\nsensors (DVS), further enhances their applicability to edge computing tasks.\nHowever, the resource constraints of edge hardware necessitate techniques like\nweight quantization, which reduce the memory footprint of SNNs while preserving\naccuracy. Despite its importance, existing quantization methods typically focus\non synaptic weights quantization without taking account of other critical\nparameters, such as scaling neuron firing thresholds.\n  To address this limitation, we present the first benchmark for the DVS\ngesture recognition task using SNNs optimized for the many-core neuromorphic\nchip SpiNNaker2. Our study evaluates two quantization pipelines for fixed-point\ncomputations. The first approach employs post training quantization (PTQ) with\npercentile-based threshold scaling, while the second uses quantization aware\ntraining (QAT) with adaptive threshold scaling. Both methods achieve accurate\n8-bit on-chip inference, closely approximating 32-bit floating-point\nperformance. Additionally, our baseline SNNs perform competitively against\npreviously reported results without specialized techniques. These models are\ndeployed on SpiNNaker2 using the neuromorphic intermediate representation\n(NIR). Ultimately, we achieve 94.13% classification accuracy on-chip,\ndemonstrating the SpiNNaker2's potential for efficient, low-energy neuromorphic\ncomputing.", "published": "2025-04-09 10:09:29", "link": "http://arxiv.org/abs/2504.06748v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "PETNet -- Coincident Particle Event Detection using Spiking Neural Networks", "abstract": "Spiking neural networks (SNN) hold the promise of being a more biologically\nplausible, low-energy alternative to conventional artificial neural networks.\nTheir time-variant nature makes them particularly suitable for processing\ntime-resolved, sparse binary data. In this paper, we investigate the potential\nof leveraging SNNs for the detection of photon coincidences in positron\nemission tomography (PET) data. PET is a medical imaging technique based on\ninjecting a patient with a radioactive tracer and detecting the emitted\nphotons. One central post-processing task for inferring an image of the tracer\ndistribution is the filtering of invalid hits occurring due to e.g. absorption\nor scattering processes. Our approach, coined PETNet, interprets the detector\nhits as a binary-valued spike train and learns to identify photon coincidence\npairs in a supervised manner. We introduce a dedicated multi-objective loss\nfunction and demonstrate the effects of explicitly modeling the detector\ngeometry on simulation data for two use-cases. Our results show that PETNet can\noutperform the state-of-the-art classical algorithm with a maximal coincidence\ndetection $F_1$ of 95.2%. At the same time, PETNet is able to predict photon\ncoincidences up to 36 times faster than the classical approach, highlighting\nthe great potential of SNNs in particle physics applications.", "published": "2025-04-09 09:38:45", "link": "http://arxiv.org/abs/2504.06730v1", "categories": ["cs.LG", "hep-ex"], "primary_category": "cs.LG"}
{"title": "Plastic tensor networks for interpretable generative modeling", "abstract": "A structural optimization scheme for a single-layer nonnegative adaptive\ntensor tree (NATT) that models a target probability distribution is proposed.\nThe NATT scheme, by construction, has the advantage that it is interpretable as\na probabilistic graphical model. We consider the NATT scheme and a recently\nproposed Born machine adaptive tensor tree (BMATT) optimization scheme and\ndemonstrate their effectiveness on a variety of generative modeling tasks where\nthe objective is to infer the hidden structure of a provided dataset. Our\nresults show that in terms of minimizing the negative log-likelihood, the\nsingle-layer scheme has model performance comparable to the Born machine\nscheme, though not better. The tasks include deducing the structure of binary\nbitwise operations, learning the internal structure of random Bayesian networks\ngiven only visible sites, and a real-world example related to hierarchical\nclustering where a cladogram is constructed from mitochondrial DNA sequences.\nIn doing so, we also show the importance of the choice of network topology and\nthe versatility of a least-mutual information criterion in selecting a\ncandidate structure for a tensor tree, as well as discuss aspects of these\ntensor tree generative models including their information content and\ninterpretability.", "published": "2025-04-09 09:23:11", "link": "http://arxiv.org/abs/2504.06722v1", "categories": ["cs.LG", "cond-mat.stat-mech"], "primary_category": "cs.LG"}
{"title": "Clustering and novel class recognition: evaluating bioacoustic deep learning feature extractors", "abstract": "In computational bioacoustics, deep learning models are composed of feature\nextractors and classifiers. The feature extractors generate vector\nrepresentations of the input sound segments, called embeddings, which can be\ninput to a classifier. While benchmarking of classification scores provides\ninsights into specific performance statistics, it is limited to species that\nare included in the models' training data. Furthermore, it makes it impossible\nto compare models trained on very different taxonomic groups. This paper aims\nto address this gap by analyzing the embeddings generated by the feature\nextractors of 15 bioacoustic models spanning a wide range of setups (model\narchitectures, training data, training paradigms). We evaluated and compared\ndifferent ways in which models structure embedding spaces through clustering\nand kNN classification, which allows us to focus our comparison on feature\nextractors independent of their classifiers. We believe that this approach lets\nus evaluate the adaptability and generalization potential of models going\nbeyond the classes they were trained on.", "published": "2025-04-09 09:13:18", "link": "http://arxiv.org/abs/2504.06710v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Benchmarking Convolutional Neural Network and Graph Neural Network based Surrogate Models on a Real-World Car External Aerodynamics Dataset", "abstract": "Aerodynamic optimization is crucial for developing eco-friendly, aerodynamic,\nand stylish cars, which requires close collaboration between aerodynamicists\nand stylists, a collaboration impaired by the time-consuming nature of\naerodynamic simulations. Surrogate models offer a viable solution to reduce\nthis overhead, but they are untested in real-world aerodynamic datasets. We\npresent a comparative evaluation of two surrogate modeling approaches for\npredicting drag on a real-world dataset: a Convolutional Neural Network (CNN)\nmodel that uses a signed distance field as input and a commercial tool based on\nGraph Neural Networks (GNN) that directly processes a surface mesh. In contrast\nto previous studies based on datasets created from parameterized geometries,\nour dataset comprises 343 geometries derived from 32 baseline vehicle\ngeometries across five distinct car projects, reflecting the diverse, free-form\nmodifications encountered in the typical vehicle development process. Our\nresults show that the CNN-based method achieves a mean absolute error of 2.3\ndrag counts, while the GNN-based method achieves 3.8. Both methods achieve\napproximately 77% accuracy in predicting the direction of drag change relative\nto the baseline geometry. While both methods effectively capture the broader\ntrends between baseline groups (set of samples derived from a single baseline\ngeometry), they struggle to varying extents in capturing the finer\nintra-baseline group variations. In summary, our findings suggest that\naerodynamicists can effectively use both methods to predict drag in under two\nminutes, which is at least 600 times faster than performing a simulation.\nHowever, there remains room for improvement in capturing the finer details of\nthe geometry.", "published": "2025-04-09 09:04:59", "link": "http://arxiv.org/abs/2504.06699v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Robust and Noise-resilient Long-Term Prediction of Spatiotemporal Data Using Variational Mode Graph Neural Networks with 3D Attention", "abstract": "This paper focuses on improving the robustness of spatiotemporal long-term\nprediction using a variational mode graph convolutional network (VMGCN) by\nintroducing 3D channel attention. The deep learning network for this task\nrelies on historical data inputs, yet real-time data can be corrupted by sensor\nnoise, altering its distribution. We model this noise as independent and\nidentically distributed (i.i.d.) Gaussian noise and incorporate it into the\nLargeST traffic volume dataset, resulting in data with both inherent and\nadditive noise components. Our approach involves decomposing the corrupted\nsignal into modes using variational mode decomposition, followed by feeding the\ndata into a learning pipeline for prediction. We integrate a 3D attention\nmechanism encompassing spatial, temporal, and channel attention. The spatial\nand temporal attention modules learn their respective correlations, while the\nchannel attention mechanism is used to suppress noise and highlight the\nsignificant modes in the spatiotemporal signals. Additionally, a learnable soft\nthresholding method is implemented to exclude unimportant modes from the\nfeature vector, and a feature reduction method based on the signal-to-noise\nratio (SNR) is applied. We compare the performance of our approach against\nbaseline models, demonstrating that our method achieves superior long-term\nprediction accuracy, robustness to noise, and improved performance with mode\ntruncation compared to the baseline models. The code of the paper is available\nat https://github.com/OsamaAhmad369/VMGCN.", "published": "2025-04-09 07:49:45", "link": "http://arxiv.org/abs/2504.06660v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Quantum neural networks facilitating quantum state classification", "abstract": "The classification of quantum states into distinct classes poses a\nsignificant challenge. In this study, we address this problem using quantum\nneural networks in combination with a problem-inspired circuit and customised\nas well as predefined ans\\\"{a}tz. To facilitate the resource-efficient quantum\nstate classification, we construct the dataset of quantum states using the\nproposed problem-inspired circuit. The problem-inspired circuit incorporates\ntwo-qubit parameterised unitary gates of varying entangling power, which is\nfurther integrated with the ans\\\"{a}tz, developing an entire quantum neural\nnetwork. To demonstrate the capability of the selected ans\\\"{a}tz, we visualise\nthe mitigated barren plateaus. The designed quantum neural network demonstrates\nthe efficiency in binary and multi-class classification tasks. This work\nestablishes a foundation for the classification of multi-qubit quantum states\nand offers the potential for generalisation to multi-qubit pure quantum states.", "published": "2025-04-09 06:42:32", "link": "http://arxiv.org/abs/2504.06622v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "NAPER: Fault Protection for Real-Time Resource-Constrained Deep Neural Networks", "abstract": "Fault tolerance in Deep Neural Networks (DNNs) deployed on\nresource-constrained systems presents unique challenges for high-accuracy\napplications with strict timing requirements. Memory bit-flips can severely\ndegrade DNN accuracy, while traditional protection approaches like Triple\nModular Redundancy (TMR) often sacrifice accuracy to maintain reliability,\ncreating a three-way dilemma between reliability, accuracy, and timeliness. We\nintroduce NAPER, a novel protection approach that addresses this challenge\nthrough ensemble learning. Unlike conventional redundancy methods, NAPER\nemploys heterogeneous model redundancy, where diverse models collectively\nachieve higher accuracy than any individual model. This is complemented by an\nefficient fault detection mechanism and a real-time scheduler that prioritizes\nmeeting deadlines by intelligently scheduling recovery operations without\ninterrupting inference. Our evaluations demonstrate NAPER's superiority: 40%\nfaster inference in both normal and fault conditions, maintained accuracy 4.2%\nhigher than TMR-based strategies, and guaranteed uninterrupted operation even\nduring fault recovery. NAPER effectively balances the competing demands of\naccuracy, reliability, and timeliness in real-time DNN applications", "published": "2025-04-09 05:37:54", "link": "http://arxiv.org/abs/2504.06591v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "CAFE-AD: Cross-Scenario Adaptive Feature Enhancement for Trajectory Planning in Autonomous Driving", "abstract": "Imitation learning based planning tasks on the nuPlan dataset have gained\ngreat interest due to their potential to generate human-like driving behaviors.\nHowever, open-loop training on the nuPlan dataset tends to cause causal\nconfusion during closed-loop testing, and the dataset also presents a long-tail\ndistribution of scenarios. These issues introduce challenges for imitation\nlearning. To tackle these problems, we introduce CAFE-AD, a Cross-Scenario\nAdaptive Feature Enhancement for Trajectory Planning in Autonomous Driving\nmethod, designed to enhance feature representation across various scenario\ntypes. We develop an adaptive feature pruning module that ranks feature\nimportance to capture the most relevant information while reducing the\ninterference of noisy information during training. Moreover, we propose a\ncross-scenario feature interpolation module that enhances scenario information\nto introduce diversity, enabling the network to alleviate over-fitting in\ndominant scenarios. We evaluate our method CAFE-AD on the challenging public\nnuPlan Test14-Hard closed-loop simulation benchmark. The results demonstrate\nthat CAFE-AD outperforms state-of-the-art methods including rule-based and\nhybrid planners, and exhibits the potential in mitigating the impact of\nlong-tail distribution within the dataset. Additionally, we further validate\nits effectiveness in real-world environments. The code and models will be made\navailable at https://github.com/AlniyatRui/CAFE-AD.", "published": "2025-04-09 05:16:29", "link": "http://arxiv.org/abs/2504.06584v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Diffusion Factor Models: Generating High-Dimensional Returns with Factor Structure", "abstract": "Financial scenario simulation is essential for risk management and portfolio\noptimization, yet it remains challenging especially in high-dimensional and\nsmall data settings common in finance. We propose a diffusion factor model that\nintegrates latent factor structure into generative diffusion processes,\nbridging econometrics with modern generative AI to address the challenges of\nthe curse of dimensionality and data scarcity in financial simulation. By\nexploiting the low-dimensional factor structure inherent in asset returns, we\ndecompose the score function--a key component in diffusion models--using\ntime-varying orthogonal projections, and this decomposition is incorporated\ninto the design of neural network architectures. We derive rigorous statistical\nguarantees, establishing nonasymptotic error bounds for both score estimation\nat O(d^{5/2} n^{-2/(k+5)}) and generated distribution at O(d^{5/4}\nn^{-1/2(k+5)}), primarily driven by the intrinsic factor dimension k rather\nthan the number of assets d, surpassing the dimension-dependent limits in the\nclassical nonparametric statistics literature and making the framework viable\nfor markets with thousands of assets. Numerical studies confirm superior\nperformance in latent subspace recovery under small data regimes. Empirical\nanalysis demonstrates the economic significance of our framework in\nconstructing mean-variance optimal portfolios and factor portfolios. This work\npresents the first theoretical integration of factor structure with diffusion\nmodels, offering a principled approach for high-dimensional financial\nsimulation with limited data.", "published": "2025-04-09 04:01:35", "link": "http://arxiv.org/abs/2504.06566v1", "categories": ["q-fin.ST", "cs.LG", "q-fin.MF"], "primary_category": "q-fin.ST"}
{"title": "TabKAN: Advancing Tabular Data Analysis using Kolmograv-Arnold Network", "abstract": "Tabular data analysis presents unique challenges due to its heterogeneous\nfeature types, missing values, and complex interactions. While traditional\nmachine learning methods, such as gradient boosting, often outperform deep\nlearning approaches, recent advancements in neural architectures offer\npromising alternatives. This paper introduces TabKAN, a novel framework that\nadvances tabular data modeling using Kolmogorov-Arnold Networks (KANs). Unlike\nconventional deep learning models, KANs leverage learnable activation functions\non edges, enhancing both interpretability and training efficiency. Our\ncontributions include: (1) the introduction of modular KAN-based architectures\ntailored for tabular data analysis, (2) the development of a transfer learning\nframework for KAN models, enabling effective knowledge transfer between\ndomains, (3) the development of model-specific interpretability for tabular\ndata learning, reducing reliance on post hoc and model-agnostic analysis, and\n(4) comprehensive evaluation of vanilla supervised learning across binary and\nmulti-class classification tasks. Through extensive benchmarking on diverse\npublic datasets, TabKAN demonstrates superior performance in supervised\nlearning while significantly outperforming classical and Transformer-based\nmodels in transfer learning scenarios. Our findings highlight the advantage of\nKAN-based architectures in efficiently transferring knowledge across domains,\nbridging the gap between traditional machine learning and deep learning for\nstructured data.", "published": "2025-04-09 03:46:10", "link": "http://arxiv.org/abs/2504.06559v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Controller Distillation Reduces Fragile Brain-Body Co-Adaptation and Enables Migrations in MAP-Elites", "abstract": "Brain-body co-optimization suffers from fragile co-adaptation where brains\nbecome over-specialized for particular bodies, hindering their ability to\ntransfer well to others. Evolutionary algorithms tend to discard such\nlow-performing solutions, eliminating promising morphologies. Previous work\nconsidered applying MAP-Elites, where niche descriptors are based on\nmorphological features, to promote better search over morphology space. In this\nwork, we show that this approach still suffers from fragile co-adaptation:\nwhere a core mechanism of MAP-Elites, creating stepping stones through\nsolutions that migrate from one niche to another, is disrupted. We suggest that\nthis disruption occurs because the body mutations that move an offspring to a\nnew morphological niche break the robots' fragile brain-body co-adaptation and\nthus significantly decrease the performance of those potential solutions --\nreducing their likelihood of outcompeting an existing elite in that new niche.\nWe utilize a technique, we call Pollination, that periodically replaces the\ncontrollers of certain solutions with a distilled controller with better\ngeneralization across morphologies to reduce fragile brain-body co-adaptation\nand thus promote MAP-Elites migrations. Pollination increases the success of\nbody mutations and the number of migrations, resulting in better\nquality-diversity metrics. We believe we develop important insights that could\napply to other domains where MAP-Elites is used.", "published": "2025-04-09 01:45:51", "link": "http://arxiv.org/abs/2504.06523v1", "categories": ["cs.RO", "cs.LG", "cs.NE"], "primary_category": "cs.RO"}
{"title": "GTS-LUM: Reshaping User Behavior Modeling with LLMs in Telecommunications Industry", "abstract": "As telecommunication service providers shifting their focus to analyzing user\nbehavior for package design and marketing interventions, a critical challenge\nlies in developing a unified, end-to-end framework capable of modeling\nlong-term and periodic user behavior sequences with diverse time granularities,\nmulti-modal data inputs, and heterogeneous labels. This paper introduces\nGTS-LUM, a novel user behavior model that redefines modeling paradigms in\ntelecommunication settings. GTS-LUM adopts a (multi-modal) encoder-adapter-LLM\ndecoder architecture, enhanced with several telecom-specific innovations.\nSpecifically, the model incorporates an advanced timestamp processing method to\nhandle varying time granularities. It also supports multi-modal data inputs --\nincluding structured tables and behavior co-occurrence graphs -- and aligns\nthese with semantic information extracted by a tokenizer using a Q-former\nstructure. Additionally, GTS-LUM integrates a front-placed target-aware\nmechanism to highlight historical behaviors most relevant to the target.\nExtensive experiments on industrial dataset validate the effectiveness of this\nend-to-end framework and also demonstrate that GTS-LUM outperforms LLM4Rec\napproaches which are popular in recommendation systems, offering an effective\nand generalizing solution for user behavior modeling in telecommunications.", "published": "2025-04-09 01:12:07", "link": "http://arxiv.org/abs/2504.06511v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Data-driven Fuzzy Control for Time-Optimal Aggressive Trajectory Following", "abstract": "Optimal trajectories that minimize a user-defined cost function in dynamic\nsystems require the solution of a two-point boundary value problem. The\noptimization process yields an optimal control sequence that depends on the\ninitial conditions and system parameters. However, the optimal sequence may\nresult in undesirable behavior if the system's initial conditions and\nparameters are erroneous. This work presents a data-driven fuzzy controller\nsynthesis framework that is guided by a time-optimal trajectory for multicopter\ntracking problems. In particular, we consider an aggressive maneuver consisting\nof a mid-air flip and generate a time-optimal trajectory by numerically solving\nthe two-point boundary value problem. A fuzzy controller consisting of a\nstabilizing controller near hover conditions and an autoregressive moving\naverage (ARMA) controller, trained to mimic the time-optimal aggressive\ntrajectory, is constructed using the Takagi-Sugeno fuzzy framework.", "published": "2025-04-09 00:06:15", "link": "http://arxiv.org/abs/2504.06500v1", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY"], "primary_category": "eess.SY"}
{"title": "AI-Driven Consensus: Modeling Multi-Agent Networks with Long-Range Interactions through path-Laplacian Matrices", "abstract": "Extended connectivity in graphs can be analyzed through k-path Laplacian\nmatrices, which permit the capture of long-range interactions in various\nreal-world networked systems such as social, transportation, and multi-agent\nnetworks. In this work, we present several alternative methods based on machine\nlearning methods (LSTM, xLSTM, Transformer, XGBoost, and ConvLSTM) to predict\nthe final consensus value based on directed networks (Erd\\\"os-Renyi,\nWatts-Strogatz, and Barab\\'asi-Albert) and on the initial state. We highlight\nhow different k-hop interactions affect the performance of the tested methods.\nThis framework opens new avenues for analyzing multi-scale diffusion processes\nin large-scale, complex networks.", "published": "2025-04-09 13:53:57", "link": "http://arxiv.org/abs/2504.06894v1", "categories": ["cs.SI", "cs.MA"], "primary_category": "cs.SI"}
{"title": "Adaptive Human-Robot Collaborative Missions using Hybrid Task Planning", "abstract": "Producing robust task plans in human-robot collaborative missions is a\ncritical activity in order to increase the likelihood of these missions\ncompleting successfully. Despite the broad research body in the area, which\nconsiders different classes of constraints and uncertainties, its applicability\nis confined to relatively simple problems that can be comfortably addressed by\nthe underpinning mathematically-based or heuristic-driven solver engines. In\nthis paper, we introduce a hybrid approach that effectively solves the task\nplanning problem by decomposing it into two intertwined parts, starting with\nthe identification of a feasible plan and followed by its uncertainty\naugmentation and verification yielding a set of Pareto optimal plans. To\nenhance its robustness, adaptation tactics are devised for the evolving system\nrequirements and agents' capabilities. We demonstrate our approach through an\nindustrial case study involving workers and robots undertaking activities\nwithin a vineyard, showcasing the benefits of our hybrid approach both in the\ngeneration of feasible solutions and scalability compared to native planners.", "published": "2025-04-09 10:07:15", "link": "http://arxiv.org/abs/2504.06746v1", "categories": ["cs.MA", "cs.RO"], "primary_category": "cs.MA"}
{"title": "FJ-MM: The Friedkin-Johnsen Opinion Dynamics Model with Memory and Higher-Order Neighbors", "abstract": "The Friedkin-Johnsen (FJ) model has been extensively explored and validated,\nspanning applications in social science, systems and control, game theory, and\nalgorithmic research. In this paper, we introduce an advanced generalization of\nthe FJ model, termed FJ-MM which incorporates both memory effects and multi-hop\n(higher-order neighbor) influence. This formulation allows agents to naturally\nincorporate both current and previous opinions at each iteration stage. Our\nnumerical results demonstrate that incorporating memory and multi-hop influence\nsignificantly reshapes the opinion landscape; for example, the final opinion\nprofile can exhibit reduced polarization. We analyze the stability and\nequilibrium properties of the FJ-MM model, showing that these properties can be\nreduced to those of a comparison model--namely, the standard FJ model with a\nmodified influence matrix. This reduction enables us to leverage established\nstability results from FJ dynamics. Additionally, we examine the convergence\nrate of the FJ-MM model and demonstrate that, as can be expected, the time lags\nintroduced by memory and higher-order neighbor influences result in slower\nconvergence.", "published": "2025-04-09 09:43:04", "link": "http://arxiv.org/abs/2504.06731v1", "categories": ["eess.SY", "cs.MA", "cs.SY", "math.OC", "physics.soc-ph"], "primary_category": "eess.SY"}
{"title": "SDHN: Skewness-Driven Hypergraph Networks for Enhanced Localized Multi-Robot Coordination", "abstract": "Multi-Agent Reinforcement Learning is widely used for multi-robot\ncoordination, where simple graphs typically model pairwise interactions.\nHowever, such representations fail to capture higher-order collaborations,\nlimiting effectiveness in complex tasks. While hypergraph-based approaches\nenhance cooperation, existing methods often generate arbitrary hypergraph\nstructures and lack adaptability to environmental uncertainties. To address\nthese challenges, we propose the Skewness-Driven Hypergraph Network (SDHN),\nwhich employs stochastic Bernoulli hyperedges to explicitly model higher-order\nmulti-robot interactions. By introducing a skewness loss, SDHN promotes an\nefficient structure with Small-Hyperedge Dominant Hypergraph, allowing robots\nto prioritize localized synchronization while still adhering to the overall\ninformation, similar to human coordination. Extensive experiments on Moving\nAgents in Formation and Robotic Warehouse tasks validate SDHN's effectiveness,\ndemonstrating superior performance over state-of-the-art baselines.", "published": "2025-04-09 08:41:57", "link": "http://arxiv.org/abs/2504.06684v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Physics informed neural network for forward and inverse modeling of low grade brain tumors", "abstract": "A low grade tumor is a slow growing tumor with a lower likelihood of\nspreading compared to high grade tumors. Mathematical modeling using partial\ndifferential equations (PDEs) plays a crucial role in describing tumor\nbehavior, growth and progression. This study employs the Burgess and extended\nFisher Kolmogorov equations to model low-grade brain tumors. We utilize Physics\nInformed Neural Networks (PINNs) based algorithm to develop an automated\nnumerical solver for these models and explore their application in solving\nforward and inverse problems in brain tumor modeling. The study aims to\ndemonstrate that the PINN based algorithms serve as advanced methodologies for\nmodeling brain tumor dynamics by integrating deep learning with\nphysics-informed principles. Additionally, we establish generalized error\nbounds in terms of training and quadrature errors. The convergence and\nstability of the neural network are derived for both models. Numerical tests\nconfirm the accuracy and efficiency of the algorithms in both linear and\nnonlinear cases. Additionally, a statistical analysis of the numerical results\nis presented.", "published": "2025-04-09 17:20:06", "link": "http://arxiv.org/abs/2504.07058v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Krylov projection algorithm for large symmetric matrices with dense spectra", "abstract": "We consider the approximation of $B^T (A+sI)^{-1} B$ for large s.p.d.\n$A\\in\\mathbb{R}^{n\\times n}$ with dense spectrum and $B\\in\\mathbb{R}^{n\\times\np}$, $p\\ll n$. We target the computations of Multiple-Input Multiple-Output\n(MIMO) transfer functions for large-scale discretizations of problems with\ncontinuous spectral measures, such as linear time-invariant (LTI) PDEs on\nunbounded domains. Traditional Krylov methods, such as the Lanczos or CG\nalgorithm, are known to be optimal for the computation of $(A+sI)^{-1}B$ with\nreal positive $s$, resulting in an adaptation to the distinctively discrete and\nnonuniform spectra. However, the adaptation is damped for matrices with dense\nspectra. It was demonstrated in [Zimmerling, Druskin, Simoncini, Journal of\nScientific Computing 103(1), 5 (2025)] that averaging Gau{\\ss} and Gau\\ss\n-Radau quadratures computed using the block-Lanczos method significantly\nreduces approximation errors for such problems. Here, we introduce an adaptive\nKre\\u{i}n-Nudelman extension to the (block) Lanczos recursions, allowing\nfurther acceleration at negligible $o(n)$ cost. Similar to the Gau\\ss -Radau\nquadrature, a low-rank modification is applied to the (block) Lanczos matrix.\nHowever, unlike the Gau\\ss -Radau quadrature, this modification depends on\n$\\sqrt{s}$ and can be considered in the framework of the Hermite-Pad\\'e\napproximants, which are known to be efficient for problems with branch-cuts,\nthat can be good approximations to dense spectral intervals. Numerical results\nfor large-scale discretizations of heat-diffusion and quasi-magnetostatic\nMaxwell's operators in unbounded domains confirm the efficiency of the proposed\napproach.", "published": "2025-04-09 16:09:34", "link": "http://arxiv.org/abs/2504.06998v1", "categories": ["math.NA", "cs.NA", "65F10, 65N22, 65F50, 65F60"], "primary_category": "math.NA"}
{"title": "GLT hidden structures in mean-field quantum spin systems", "abstract": "This work explores structured matrix sequences arising in mean-field quantum\nspin systems. We express these sequences within the framework of generalized\nlocally Toeplitz (GLT) $*$-algebras, leveraging the fact that each GLT matrix\nsequence has a unique GLT symbol. This symbol characterizes both the asymptotic\nsingular value distribution and, for Hermitian or quasi-Hermitian sequences,\nthe asymptotic spectral distribution. Specifically, we analyze two cases of\nreal symmetric matrix sequences stemming from mean-field quantum spin systems\nand determine their associated distributions using GLT theory. Our study\nconcludes with visualizations and numerical tests that validate the theoretical\nfindings, followed by a discussion of open problems and future directions.", "published": "2025-04-09 14:58:31", "link": "http://arxiv.org/abs/2504.06951v1", "categories": ["quant-ph", "cs.NA", "math.NA", "46L65, 15B05, 15A18 (81R30, 82B20)"], "primary_category": "quant-ph"}
{"title": "On the Compressibility of Integral Operators in Anisotropic Wavelet Coordinates", "abstract": "The present article is concerned with the s*-compressibility of classical\nboundary integral operators in anisotropic wavelet coordinates. Having the\ns*-compressibility at hand, one can design adaptive wavelet algorithms which\nare asymptotically optimal, meaning that any target accuracy can be achieved at\na computational expense that stays proportional to the number of degrees of\nfreedom (within the setting determined by an underlying wavelet basis) that\nwould ideally be necessary for realising that target accuracy if full knowledge\nabout the unknown solution were given. As we consider here anisotropic wavelet\ncoordinates, we can achieve higher convergence rates compared to the standard,\nisotropic setting. Especially, edge singularities of anisotropic nature can be\nresolved.", "published": "2025-04-09 14:42:01", "link": "http://arxiv.org/abs/2504.06938v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Mixed-Precision in High-Order Methods: the Impact of Floating-Point Precision on the ADER-DG Algorithm", "abstract": "We present a mixed-precision implementation of the high-order discontinuous\nGalerkin method with ADER time stepping (ADER-DG) for solving hyperbolic\nsystems of partial differential equations (PDEs) in the hyperbolic PDE engine\nExaHyPE. The implementation provides a simple API extension for specifying the\nnumerical precision for individual kernels, and thus allows for testing the\neffect of low and mixed precision on the accuracy of the solution. To showcase\nthis, we study the impact of precision on the overall convergence order and\nactual accuracy of the method as achieved for four common hyperbolic PDE\nsystems and five relevant scenarios that feature an analytic solution. For all\nscenarios, we also assess how sensitive each kernel of the ADER-DG algorithm is\nto using double, single or even half precision. This addresses the question\nwhere thoughtful adoption of mixed precision can mitigate hurtful effects of\nlow precision on the overall simulation.", "published": "2025-04-09 13:50:43", "link": "http://arxiv.org/abs/2504.06889v1", "categories": ["math.NA", "cs.DS", "cs.NA", "G.4.4; G.1.8; I.0"], "primary_category": "math.NA"}
{"title": "Discrete-to-continuum limit for nonlinear reaction-diffusion systems via EDP convergence for gradient systems", "abstract": "We investigate the convergence of spatial discretizations for\nreaction-diffusion systems with mass-action law satisfying a detailed balance\ncondition. Considering systems on the d-dimensional torus, we construct\nappropriate space-discrete processes and show convergence not only on the level\nof solutions, but also on the level of the gradient systems governing the\nevolutions. As an important step, we prove chain rule inequalities for the\nreaction-diffusion systems as well as their discretizations, featuring a\nnon-convex dissipation functional. The convergence is then obtained with\nvariational methods by building on the recently introduced notion of gradient\nsystems in continuity equation format.", "published": "2025-04-09 12:51:15", "link": "http://arxiv.org/abs/2504.06837v1", "categories": ["math.AP", "cs.NA", "math-ph", "math.DS", "math.MP", "math.NA", "35A15, 35K57, 35A35, 47J35, 65M08"], "primary_category": "math.AP"}
{"title": "Probabilistic Grading and Classification System for End-of-Life Building Components Toward Circular Economy Loop", "abstract": "The longevity and viability of construction components in a circular economy\ndemand a robust, data-informed framework for reuse decision-making. This paper\nintroduces a multi-level grading and classification system that combines\nBayesian probabilistic modeling with scenario-based performance thresholds to\nassess the reusability of end-of-life modular components. By grading components\nacross a five-tier scale, the system supports strategic decisions for reuse,\nup-use, or down-use, ensuring alignment with engineering standards and\nsustainability objectives. The model's development is grounded in empirical\ndata from precast concrete wall panels, and its explainability is enhanced\nthrough decision tree logic and Sankey visualizations that trace the influence\nof contextual scenarios on classification outcomes. MGCS addresses the\nenvironmental, economic, and operational challenges of EoL management--reducing\nmaterial waste, optimizing value recovery, and improving workflow efficiency.\nThrough dynamic feature weighting and transparent reasoning, the system offers\na practical yet rigorous pathway to embed circular thinking into construction\nindustry practices.", "published": "2025-04-09 11:14:02", "link": "http://arxiv.org/abs/2504.06782v1", "categories": ["econ.GN", "cs.NA", "math.NA", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "Convergence of a continuous Galerkin method for the Biot-Allard poroelasticity system", "abstract": "We study a space-time finite element method for a system of poromechanics\nwith memory effects that are modeled by a convolution integral. In the\nliterature, the system is referred to as the Biot-Allard model. We recast the\nmodel as a first-order system in time, where the memory effects are transformed\ninto an auxiliary differential equation. This allows for a computationally\nefficient numerical scheme. The system is discretized by continuous Galerkin\nmethods in time and equal-order finite element methods in space. An optimal\norder error estimate is proved for the norm of the first-order energy of the\nunknowns of the system. The estimate is confirmed by numerical experiments.", "published": "2025-04-09 10:38:13", "link": "http://arxiv.org/abs/2504.06763v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Computation of shape Taylor expansions", "abstract": "Shape derivative is an important analytical tool for studying scattering\nproblems involving perturbations in scatterers. Many applications, including\ninverse scattering, optimal design, and uncertainty quantification, are based\non shape derivatives. However, computing high order shape derivatives is\nchallenging due to the complexity of shape calculus. This work introduces a\ncomprehensive method for computing shape Taylor expansions in two dimensions\nusing recurrence formulas. The approach is developed under sound-soft,\nsound-hard, impedance, and transmission boundary conditions. Additionally, we\napply the shape Taylor expansion to uncertainty quantification in wave\nscattering, enabling high order moment estimation for the scattered field under\nrandom boundary perturbations. Numerical examples are provided to illustrate\nthe effectiveness of the shape Taylor expansion in achieving high order\napproximations.", "published": "2025-04-09 06:42:21", "link": "http://arxiv.org/abs/2504.06621v1", "categories": ["math.NA", "cs.NA", "35J05, 30B20, 45A05, 49J50, 78M50"], "primary_category": "math.NA"}
{"title": "Asymptotic Variance in the Central Limit Theorem for Multilevel Markovian Stochastic Approximation", "abstract": "In this note we consider the finite-dimensional parameter estimation problem\nassociated to inverse problems. In such scenarios, one seeks to maximize the\nmarginal likelihood associated to a Bayesian model. This latter model is\nconnected to the solution of partial or ordinary differential equation. As\nsuch, there are two primary difficulties in maximizing the marginal likelihood\n(i) that the solution of differential equation is not always analytically\ntractable and (ii) neither is the marginal likelihood. Typically (i) is dealt\nwith using a numerical solution of the differential equation, leading to a\nnumerical bias and (ii) has been well studied in the literature using, for\ninstance, Markovian stochastic approximation. It is well-known that to reduce\nthe computational effort to obtain the maximal value of the parameter, one can\nuse a hierarchy of solutions of the differential equation and combine with\nstochastic gradient methods. Several approaches do exactly this. In this paper\nwe consider the asymptotic variance in the central limit theorem, associated to\nknown estimates and find bounds on the asymptotic variance in terms of the\nprecision of the solution of the differential equation. The significance of\nthese bounds are the that they provide missing theoretical guidelines on how to\nset simulation parameters; that is, these appear to be the first mathematical\nresults which help to run the methods efficiently in practice.", "published": "2025-04-09 05:59:40", "link": "http://arxiv.org/abs/2504.06603v1", "categories": ["math.NA", "cs.NA", "stat.CO"], "primary_category": "math.NA"}
{"title": "Aplicando diferencias finitas para resolver ecuaciones y sistemas de ecuaciones diferenciales parciales sobre dominios planos irregulares simplemente conexos y no conexos", "abstract": "Using exhaustion method and finite differences a new method to solve system\nof partial differential equations and is presented. This method allows design\nalgorithm to solve linear and nonlinear systems in irregular domains. Applying\nthis method to solve linear and nonlinear problems with prescribed conditions\nDirichlet over two-dimensional irregular domains are analyzed.", "published": "2025-04-09 05:05:04", "link": "http://arxiv.org/abs/2504.06583v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Density Approximation of Affine Jump Diffusions via Closed-Form Moment Matching", "abstract": "We develop a recursive approach for deriving closed-form solutions to both\nconditional and unconditional moments of affine jump diffusions with\nstate-independent jump intensities. Using these moment solutions, we construct\nclosed-form density approximations (up to a normalization constant) via moment\nmatching for both conditional and unconditional distributions. Our framework\nenables important financial applications, including efficient option pricing\nand exact simulation for affine jump diffusions. Numerical experiments\ndemonstrate the method's superior computational efficiency compared to existing\nsimulation techniques, while preserving numerical precision.", "published": "2025-04-09 14:50:18", "link": "http://arxiv.org/abs/2504.06942v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Polyspectral Mean based Time Series Clustering of Indian Stock Market", "abstract": "In this study, we employ k-means clustering algorithm of polyspectral means\nto analyze 49 stocks in the Indian stock market. We have used spectral and\nbispectral information obtained from the data, by using spectral and bispectral\nmeans with different weight functions that will give us varying insights into\nthe temporal patterns of the stocks. In particular, the higher order\npolyspectral means can provide significantly more information than what we can\ngather from power spectra, and can also unveil nonlinear trends in a time\nseries. Through rigorous analysis, we identify five distinctive clusters,\nuncovering nuanced market structures. Notably, one cluster emerges as that of a\nconglomerate powerhouse, featuring ADANI, BIRLA, TATA, and unexpectedly,\ngovernment-owned bank SBI. Another cluster spotlights the IT sector with WIPRO\nand TCS, while a third combines private banks, government entities, and\nRELIANCE. The final cluster comprises publicly traded companies with dispersed\nownership. Such clustering of stocks sheds light on intricate financial\nrelationships within the stock market, providing valuable insights for\ninvestors and analysts navigating the dynamic landscape of the Indian stock\nmarket.", "published": "2025-04-09 16:36:39", "link": "http://arxiv.org/abs/2504.07021v1", "categories": ["q-fin.ST", "stat.AP"], "primary_category": "q-fin.ST"}
{"title": "Maximizing Battery Storage Profits via High-Frequency Intraday Trading", "abstract": "Maximizing revenue for grid-scale battery energy storage systems in\ncontinuous intraday electricity markets requires strategies that are able to\nseize trading opportunities as soon as new information arrives. This paper\nintroduces and evaluates an automated high-frequency trading strategy for\nbattery energy storage systems trading on the intraday market for power while\nexplicitly considering the dynamics of the limit order book, market rules, and\ntechnical parameters. The standard rolling intrinsic strategy is adapted for\ncontinuous intraday electricity markets and solved using a dynamic programming\napproximation that is two to three orders of magnitude faster than an exact\nmixed-integer linear programming solution. A detailed backtest over a full year\nof German order book data demonstrates that the proposed dynamic programming\nformulation does not reduce trading profits and enables the policy to react to\nevery relevant order book update, enabling realistic rapid backtesting. Our\nresults show the significant revenue potential of high-frequency trading: our\npolicy earns 58% more than when re-optimizing only once every hour and 14% more\nthan when re-optimizing once per minute, highlighting that profits critically\ndepend on trading speed. Furthermore, we leverage the speed of our algorithm to\ntrain a parametric extension of the rolling intrinsic, increasing yearly\nrevenue by 8.4% out of sample.", "published": "2025-04-09 14:38:09", "link": "http://arxiv.org/abs/2504.06932v1", "categories": ["q-fin.TR", "cs.SY", "eess.SY", "math.OC"], "primary_category": "q-fin.TR"}
{"title": "Optimal Execution and Macroscopic Market Making", "abstract": "We propose a stochastic game modelling the strategic interaction between\nmarket makers and traders of optimal execution type. For traders, the permanent\nprice impact commonly attributed to them is replaced by quoting strategies\nimplemented by market makers. For market makers, order flows become endogenous,\ndriven by tactical traders rather than assumed exogenously. Using the\nforward-backward stochastic differential equation (FBSDE) characterization of\nNash equilibria, we establish a local well-posedness result for the general\ngame. In the specific Almgren-Chriss-Avellaneda-Stoikov model, a decoupling\napproach guarantees the global well-posedness of the FBSDE system via the\nwell-posedness of an associated backward stochastic Riccati equation. Finally,\nby introducing small diffusion terms into the inventory processes, global\nwell-posedness is achieved for the approximation game.", "published": "2025-04-09 09:18:37", "link": "http://arxiv.org/abs/2504.06717v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Controllable Automatic Foley Artist", "abstract": "Foley is a key element in video production, refers to the process of adding\nan audio signal to a silent video while ensuring semantic and temporal\nalignment. In recent years, the rise of personalized content creation and\nadvancements in automatic video-to-audio models have increased the demand for\ngreater user control in the process. One possible approach is to incorporate\ntext to guide audio generation. While supported by existing methods, challenges\nremain in ensuring compatibility between modalities, particularly when the text\nintroduces additional information or contradicts the sounds naturally inferred\nfrom the visuals. In this work, we introduce CAFA (Controllable Automatic Foley\nArtist) a video-and-text-to-audio model that generates semantically and\ntemporally aligned audio for a given video, guided by text input. CAFA is built\nupon a text-to-audio model and integrates video information through a modality\nadapter mechanism. By incorporating text, users can refine semantic details and\nintroduce creative variations, guiding the audio synthesis beyond the expected\nvideo contextual cues. Experiments show that besides its superior quality in\nterms of semantic alignment and audio-visual synchronization the proposed\nmethod enable high textual controllability as demonstrated in subjective and\nobjective evaluations.", "published": "2025-04-09 10:58:54", "link": "http://arxiv.org/abs/2504.06778v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Conformal Robust Beamforming via Generative Channel Models", "abstract": "Traditional approaches to outage-constrained beamforming optimization rely on\nstatistical assumptions about channel distributions and estimation errors.\nHowever, the resulting outage probability guarantees are only valid when these\nassumptions accurately reflect reality. This paper tackles the fundamental\nchallenge of providing outage probability guarantees that remain robust\nregardless of specific channel or estimation error models. To achieve this, we\npropose a two-stage framework: (i) construction of a channel uncertainty set\nusing a generative channel model combined with conformal prediction, and (ii)\nrobust beamforming via the solution of a min-max optimization problem. The\nproposed method separates the modeling and optimization tasks, enabling\nprincipled uncertainty quantification and robust decision-making. Simulation\nresults confirm the effectiveness and reliability of the framework in achieving\nmodel-agnostic outage guarantees.", "published": "2025-04-09 14:40:05", "link": "http://arxiv.org/abs/2504.06934v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "xApp Conflict Mitigation with Scheduler", "abstract": "Open RAN (O-RAN) fosters multi-vendor interoperability and data-driven\ncontrol but simultaneously introduces the challenge of managing pre-trained\nxApps that can produce conflicting actions. Although O-RAN specifications\nmandate offline training and validation to prevent untrained models,\noperational conflicts remain likely under dynamic, context-dependent\nconditions. This work proposes a scheduler-based conflict mitigation framework\nto address these challenges without requiring training xApps together or\nfurther xApp re-training. By examining an indirect conflict involving power and\nresource block allocation xApps and employing an Advantage Actor-Critic (A2C)\napproach to train both xApps and the scheduler, we illustrate that a\nstraightforward A2C-based scheduler improves performance relative to\nindependently deployed xApps and conflicting cases. Notably, augmenting the\nsystem with baseline xApps and allowing the scheduler to select from a broader\npool yields the best results, underscoring the importance of adaptive\nscheduling mechanisms. These findings highlight the context-dependent nature of\nconflicts in automated network management, as two xApps may conflict under\ncertain conditions but coexist under others. Consequently, the ability to\ndynamically update and adapt the scheduler to accommodate diverse operational\nintents is vital for future network deployments. By offering dynamic scheduling\nwithout re-training xApps, this framework advances practical conflict\nresolution solutions while supporting real-world scalability.", "published": "2025-04-09 13:16:48", "link": "http://arxiv.org/abs/2504.06867v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Interference Mitigation and Spectral Efficiency Enhancement in a Multi-BD Symbiotic Radio", "abstract": "This study presents a framework designed to mitigate direct-link interference\n(DLI) and inter-backscatter device interference (IBDI) in multi-backscatter\northogonal frequency division multiplexing (OFDM)-based symbiotic radio (SR)\nsystems. The framework employs OFDM signal designs with strategic allocation of\nnull subcarriers and incorporates two backscatter modulation techniques: on-off\nfrequency shift keying (OFSK) and multiple frequency shift keying (MFSK) for\nsymbiotic backscatter communication (SBC). Additionally, we propose\nFully-Orthogonal and Semi-Orthogonal multiple access schemes to facilitate SBC\nalongside primary communication. The Fully-Orthogonal scheme maintains\northogonality between direct link and SBC signals, thereby ensuring\ninterference-free SBC, albeit at a reduced spectral efficiency. In contrast,\nthe Semi-Orthogonal schemes eliminate IBDI but permit partial DLI, striking a\nbalance between reliability and spectral efficiency. To address the partial DLI\ninherent in Semi-Orthogonal schemes, successive interference cancellation (SIC)\nis employed at the receiver, enhancing SBC reliability. To tackle channel\nestimation challenges in SBC within the SR system, we implement non-coherent\ndetection techniques at the receiver. The performance of the proposed system is\nevaluated based on average bit error rate (BER) and sum-rate metrics,\ndemonstrating the effectiveness of our schemes. We provide analytical results\nfor the system's detection performance under both proposed modulation\ntechniques and multiple access schemes, which are subsequently validated\nthrough extensive simulations. These simulations indicate a notable error-rate\nreduction of up to $10^{-3}$ at $20$ dB with the Fully-Orthogonal scheme with\nMFSK.", "published": "2025-04-09 12:57:58", "link": "http://arxiv.org/abs/2504.06840v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Integrated Sensing and Communications Over the Years: An Evolution Perspective", "abstract": "Integrated Sensing and Communications (ISAC) enables efficient spectrum\nutilization and reduces hardware costs for beyond 5G (B5G) and 6G networks,\nfacilitating intelligent applications that require both high-performance\ncommunication and precise sensing capabilities. This survey provides a\ncomprehensive review of the evolution of ISAC over the years. We examine the\nexpansion of the spectrum across RF and optical ISAC, highlighting the role of\nadvanced technologies, along with key challenges and synergies. We further\ndiscuss the advancements in network architecture from single-cell to multi-cell\nsystems, emphasizing the integration of collaborative sensing and interference\nmitigation strategies. Moreover, we analyze the progress from single-modal to\nmulti-modal sensing, with a focus on the integration of edge intelligence to\nenable real-time data processing, reduce latency, and enhance decision-making.\nFinally, we extensively review standardization efforts by 3GPP, IEEE, and ITU,\nexamining the transition of ISAC-related technologies and their implications\nfor the deployment of 6G networks.", "published": "2025-04-09 12:42:58", "link": "http://arxiv.org/abs/2504.06830v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Survey of New Mid-Band/FR3 for 6G: Channel Measurement, Characterization and Modeling in Outdoor Environment", "abstract": "The new mid-band (6-24 GHz) has attracted significant attention from both\nacademia and industry, which is the spectrum with continuous bandwidth that\ncombines the coverage benefits of low frequency with the capacity advantages of\nhigh frequency. Since outdoor environments represent the primary application\nscenario for mobile communications, this paper presents the first comprehensive\nreview and summary of multi-scenario and multi-frequency channel\ncharacteristics based on extensive outdoor new mid-band channel measurement\ndata, including UMa, UMi, and O2I. Specifically, a survey of the progress of\nthe channel characteristics is presented, such as path loss, delay spread,\nangular spread, channel sparsity, capacity and near-field spatial\nnon-stationary characteristics. Then, considering that satellite communication\nwill be an important component of future communication systems, we examine the\nimpact of clutter loss in air-ground communications. Our analysis of the\nfrequency dependence of mid-band clutter loss suggests that its impact is not\nsignificant. Additionally, given that penetration loss is frequency-dependent,\nwe summarize its variation within the FR3 band. Based on experimental results,\ncomparisons with the standard model reveal that while the 3GPP TR 38.901 model\nremains a useful reference for penetration loss in wood and glass, it shows\nsignificant deviations for concrete and glass, indicating the need for further\nrefinement. In summary, the findings of this survey provide both empirical data\nand theoretical support for the deployment of mid-band in future communication\nsystems, as well as guidance for optimizing mid-band base station deployment in\nthe outdoor environment. This survey offers the reference for improving\nstandard models and advancing channel modeling.", "published": "2025-04-09 09:32:52", "link": "http://arxiv.org/abs/2504.06727v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Sensing-Oriented Adaptive Resource Allocation Designs for OFDM-ISAC Systems", "abstract": "Orthogonal frequency division multiplexing - integrated sensing and\ncommunication (OFDM-ISAC) has emerged as a key enabler for future wireless\nnetworks, leveraging the widely adopted OFDM waveform to seamlessly integrate\nwireless communication and radar sensing within a unified framework. In this\npaper, we propose adaptive resource allocation strategies for OFDM-ISAC systems\nto achieve optimal trade-offs between diverse sensing requirements and\ncommunication quality-of-service (QoS). We first develop a comprehensive\nresource allocation framework for OFDM-ISAC systems, deriving closed-form\nexpressions for key sensing performance metrics, including delay resolution,\nDoppler resolution, delay-Doppler peak sidelobe level (PSL), and received\nsignal-to-noise ratio (SNR). Building on this theoretical foundation, we\nintroduce two novel resource allocation algorithms tailored to distinct sensing\nobjectives. The resolution-oriented algorithm aims to maximize the weighted\ndelay-Doppler resolution while satisfying constraints on PSL, sensing SNR,\ncommunication sum-rate, and transmit power. The sidelobe-oriented algorithm\nfocuses on minimizing delay-Doppler PSL while satisfying resolution, SNR, and\ncommunication constraints. To efficiently solve the resulting non-convex\noptimization problems, we develop two adaptive resource allocation algorithms\nbased on Dinkelbach's transform and majorization-minimization (MM). Extensive\nsimulations validate the effectiveness of the proposed sensing-oriented\nadaptive resource allocation strategies in enhancing resolution and sidelobe\nsuppression. Remarkably, these strategies achieve sensing performance nearly\nidentical to that of a radar-only scheme, which dedicates all resources to\nsensing. These results highlight the superior performance of the proposed\nmethods in optimizing the trade-off between sensing and communication\nobjectives within OFDM-ISAC systems.", "published": "2025-04-09 06:08:13", "link": "http://arxiv.org/abs/2504.06605v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Novel Angle-Delay-Doppler Estimation Scheme for AFDM-ISAC System in Mixed Near-field and Far-field Scenarios", "abstract": "The recently proposed multi-chirp waveform, affine frequency division\nmultiplexing (AFDM), is considered as a potential candidate for integrated\nsensing and communication (ISAC). However, acquiring accurate target sensing\nparameter information becomes challenging due to fractional delay and Doppler\nshift occurrence, as well as effects introduced by the coexistence of\nnear-field (NF) and far-field (FF) targets associated with large-scale antenna\nsystems. In this paper, we propose a novel angle-delay-Doppler estimation\nscheme for AFDM-ISAC system in mixed NF and FF scenarios. Specifically, we\nmodel the received ISAC signals as a third-order tensor that admits a low-rank\nCANDECOMP/PARAFAC (CP) format. By employing the Vandermonde nature of the\nfactor matrix and the spatial smoothing technique, we develop a structured CP\ndecomposition method that guarantees the condition for uniqueness. We further\npropose a low-complexity estimation scheme to acquire target sensing parameters\nwith fractional values, including angle of arrival/departure (AoA/AoD), delay\nand Doppler shift accurately. We also derive the Cram\\'er-Rao Lower Bound\n(CRLB) as a benchmark and analyze the complexity of our proposed scheme.\nFinally, simulation results are provided to demonstrate the effectiveness and\nsuperiority of our proposed scheme.", "published": "2025-04-09 04:02:22", "link": "http://arxiv.org/abs/2504.06567v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Sensing With Random Communication Signals", "abstract": "Communication-centric Integrated Sensing and Communication (ISAC) has been\nrecognized as a promising methodology to implement wireless sensing\nfunctionality over existing network architectures, due to its\ncost-effectiveness and backward compatibility to legacy cellular systems.\nHowever, the inherent randomness of the communication signal may incur huge\nfluctuations in sensing capabilities, leading to unfavorable detection and\nestimation performance. To address this issue, we elaborate on random ISAC\nsignal processing methods in this article, aiming at improving the sensing\nperformance without unduly deteriorating the communication functionality.\nSpecifically, we commence by discussing the fundamentals of sensing with random\ncommunication signals, including the performance metrics and optimal ranging\nwaveforms. Building on these concepts, we then present a general framework for\nrandom ISAC signal transmission, followed by an in-depth exploration of\ntime-domain pulse shaping, frequency-domain constellation shaping, and\nspatial-domain precoding methods. We provide a comprehensive overview of each\nof these topics, including models, results, and design guidelines. Finally, we\nconclude this article by identifying several promising research directions for\nrandom ISAC signal transmission.", "published": "2025-04-09 02:27:18", "link": "http://arxiv.org/abs/2504.06537v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Wanting to be Understood", "abstract": "This paper explores an intrinsic motivation for mutual awareness,\nhypothesizing that humans possess a fundamental drive to understand and to be\nunderstood even in the absence of extrinsic rewards. Through simulations of the\nperceptual crossing paradigm, we explore the effect of various internal reward\nfunctions in reinforcement learning agents. The drive to understand is\nimplemented as an active inference type artificial curiosity reward, whereas\nthe drive to be understood is implemented through intrinsic rewards for\nimitation, influence/impressionability, and sub-reaction time anticipation of\nthe other. Results indicate that while artificial curiosity alone does not lead\nto a preference for social interaction, rewards emphasizing reciprocal\nunderstanding successfully drive agents to prioritize interaction. We\ndemonstrate that this intrinsic motivation can facilitate cooperation in tasks\nwhere only one agent receives extrinsic reward for the behaviour of the other.", "published": "2025-04-09 06:15:24", "link": "http://arxiv.org/abs/2504.06611v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning", "abstract": "Watermarking has emerged as a promising technique for detecting texts\ngenerated by LLMs. Current research has primarily focused on three design\ncriteria: high quality of the watermarked text, high detectability, and\nrobustness against removal attack. However, the security against spoofing\nattacks remains relatively understudied. For example, a piggyback attack can\nmaliciously alter the meaning of watermarked text-transforming it into hate\nspeech-while preserving the original watermark, thereby damaging the reputation\nof the LLM provider. We identify two core challenges that make defending\nagainst spoofing difficult: (1) the need for watermarks to be both sensitive to\nsemantic-distorting changes and insensitive to semantic-preserving edits, and\n(2) the contradiction between the need to detect global semantic shifts and the\nlocal, auto-regressive nature of most watermarking schemes. To address these\nchallenges, we propose a semantic-aware watermarking algorithm that post-hoc\nembeds watermarks into a given target text while preserving its original\nmeaning. Our method introduces a semantic mapping model, which guides the\ngeneration of a green-red token list, contrastively trained to be sensitive to\nsemantic-distorting changes and insensitive to semantic-preserving changes.\nExperiments on two standard benchmarks demonstrate strong robustness against\nremoval attacks and security against spoofing attacks, including sentiment\nreversal and toxic content insertion, while maintaining high watermark\ndetectability. Our approach offers a significant step toward more secure and\nsemantically aware watermarking for LLMs. Our code is available at\nhttps://github.com/UCSB-NLP-Chang/contrastive-watermark.", "published": "2025-04-09 04:38:17", "link": "http://arxiv.org/abs/2504.06575v2", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "AMAD: AutoMasked Attention for Unsupervised Multivariate Time Series Anomaly Detection", "abstract": "Unsupervised multivariate time series anomaly detection (UMTSAD) plays a\ncritical role in various domains, including finance, networks, and sensor\nsystems. In recent years, due to the outstanding performance of deep learning\nin general sequential tasks, many models have been specialized for deep UMTSAD\ntasks and have achieved impressive results, particularly those based on the\nTransformer and self-attention mechanisms. However, the sequence anomaly\nassociation assumptions underlying these models are often limited to specific\npredefined patterns and scenarios, such as concentrated or peak anomaly\npatterns. These limitations hinder their ability to generalize to diverse\nanomaly situations, especially where the lack of labels poses significant\nchallenges. To address these issues, we propose AMAD, which integrates\n\\textbf{A}uto\\textbf{M}asked Attention for UMTS\\textbf{AD} scenarios. AMAD\nintroduces a novel structure based on the AutoMask mechanism and an attention\nmixup module, forming a simple yet generalized anomaly association\nrepresentation framework. This framework is further enhanced by a Max-Min\ntraining strategy and a Local-Global contrastive learning approach. By\ncombining multi-scale feature extraction with automatic relative association\nmodeling, AMAD provides a robust and adaptable solution to UMTSAD challenges.\nExtensive experimental results demonstrate that the proposed model achieving\ncompetitive performance results compared to SOTA benchmarks across a variety of\ndatasets.", "published": "2025-04-09 07:32:59", "link": "http://arxiv.org/abs/2504.06643v2", "categories": ["cs.LG", "cs.AI", "I.5.1"], "primary_category": "cs.LG"}
{"title": "GenDoP: Auto-regressive Camera Trajectory Generation as a Director of Photography", "abstract": "Camera trajectory design plays a crucial role in video production, serving as\na fundamental tool for conveying directorial intent and enhancing visual\nstorytelling. In cinematography, Directors of Photography meticulously craft\ncamera movements to achieve expressive and intentional framing. However,\nexisting methods for camera trajectory generation remain limited: Traditional\napproaches rely on geometric optimization or handcrafted procedural systems,\nwhile recent learning-based methods often inherit structural biases or lack\ntextual alignment, constraining creative synthesis. In this work, we introduce\nan auto-regressive model inspired by the expertise of Directors of Photography\nto generate artistic and expressive camera trajectories. We first introduce\nDataDoP, a large-scale multi-modal dataset containing 29K real-world shots with\nfree-moving camera trajectories, depth maps, and detailed captions in specific\nmovements, interaction with the scene, and directorial intent. Thanks to the\ncomprehensive and diverse database, we further train an auto-regressive,\ndecoder-only Transformer for high-quality, context-aware camera movement\ngeneration based on text guidance and RGBD inputs, named GenDoP. Extensive\nexperiments demonstrate that compared to existing methods, GenDoP offers better\ncontrollability, finer-grained trajectory adjustments, and higher motion\nstability. We believe our approach establishes a new standard for\nlearning-based cinematography, paving the way for future advancements in camera\ncontrol and filmmaking. Our project website:\nhttps://kszpxxzmc.github.io/GenDoP/.", "published": "2025-04-09 17:56:01", "link": "http://arxiv.org/abs/2504.07083v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning", "abstract": "Recent advancements in reinforcement learning have significantly advanced the\nreasoning capabilities of multimodal large language models (MLLMs). While\napproaches such as Group Relative Policy Optimization (GRPO) and rule-based\nreward mechanisms demonstrate promise in text and image domains, their\napplication to video understanding remains limited. This paper presents a\nsystematic exploration of Reinforcement Fine-Tuning (RFT) with GRPO for video\nMLLMs, aiming to enhance spatio-temporal perception while maintaining general\ncapabilities. Our experiments reveal that RFT is highly data-efficient for\ntask-specific improvements. Through multi-task RFT on spatio-temporal\nperception objectives with limited samples, we develop VideoChat-R1, a powerful\nvideo MLLM that achieves state-of-the-art performance on spatio-temporal\nperception tasks without sacrificing chat ability, while exhibiting emerging\nspatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1\nboosts performance several-fold in tasks like temporal grounding (+31.8) and\nobject tracking (+31.2). Additionally, it significantly improves on general QA\nbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9).\nOur findings underscore the potential of RFT for specialized task enhancement\nof Video MLLMs. We hope our work offers valuable insights for future RL\nresearch in video MLLMs.", "published": "2025-04-09 15:09:27", "link": "http://arxiv.org/abs/2504.06958v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MonoPlace3D: Learning 3D-Aware Object Placement for 3D Monocular Detection", "abstract": "Current monocular 3D detectors are held back by the limited diversity and\nscale of real-world datasets. While data augmentation certainly helps, it's\nparticularly difficult to generate realistic scene-aware augmented data for\noutdoor settings. Most current approaches to synthetic data generation focus on\nrealistic object appearance through improved rendering techniques. However, we\nshow that where and how objects are positioned is just as crucial for training\neffective 3D monocular detectors. The key obstacle lies in automatically\ndetermining realistic object placement parameters - including position,\ndimensions, and directional alignment when introducing synthetic objects into\nactual scenes. To address this, we introduce MonoPlace3D, a novel system that\nconsiders the 3D scene content to create realistic augmentations. Specifically,\ngiven a background scene, MonoPlace3D learns a distribution over plausible 3D\nbounding boxes. Subsequently, we render realistic objects and place them\naccording to the locations sampled from the learned distribution. Our\ncomprehensive evaluation on two standard datasets KITTI and NuScenes,\ndemonstrates that MonoPlace3D significantly improves the accuracy of multiple\nexisting monocular 3D detectors while being highly data efficient.", "published": "2025-04-09 11:47:48", "link": "http://arxiv.org/abs/2504.06801v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Compass Control: Multi Object Orientation Control for Text-to-Image Generation", "abstract": "Existing approaches for controlling text-to-image diffusion models, while\npowerful, do not allow for explicit 3D object-centric control, such as precise\ncontrol of object orientation. In this work, we address the problem of\nmulti-object orientation control in text-to-image diffusion models. This\nenables the generation of diverse multi-object scenes with precise orientation\ncontrol for each object. The key idea is to condition the diffusion model with\na set of orientation-aware \\textbf{compass} tokens, one for each object, along\nwith text tokens. A light-weight encoder network predicts these compass tokens\ntaking object orientation as the input. The model is trained on a synthetic\ndataset of procedurally generated scenes, each containing one or two 3D assets\non a plain background. However, direct training this framework results in poor\norientation control as well as leads to entanglement among objects. To mitigate\nthis, we intervene in the generation process and constrain the cross-attention\nmaps of each compass token to its corresponding object regions. The trained\nmodel is able to achieve precise orientation control for a) complex objects not\nseen during training and b) multi-object scenes with more than two objects,\nindicating strong generalization capabilities. Further, when combined with\npersonalization methods, our method precisely controls the orientation of the\nnew object in diverse contexts. Our method achieves state-of-the-art\norientation control and text alignment, quantified with extensive evaluations\nand a user study.", "published": "2025-04-09 10:15:15", "link": "http://arxiv.org/abs/2504.06752v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "nnLandmark: A Self-Configuring Method for 3D Medical Landmark Detection", "abstract": "Landmark detection plays a crucial role in medical imaging tasks that rely on\nprecise spatial localization, including specific applications in diagnosis,\ntreatment planning, image registration, and surgical navigation. However,\nmanual annotation is labor-intensive and requires expert knowledge. While deep\nlearning shows promise in automating this task, progress is hindered by limited\npublic datasets, inconsistent benchmarks, and non-standardized baselines,\nrestricting reproducibility, fair comparisons, and model generalizability. This\nwork introduces nnLandmark, a self-configuring deep learning framework for 3D\nmedical landmark detection, adapting nnU-Net to perform heatmap-based\nregression. By leveraging nnU-Net's automated configuration, nnLandmark\neliminates the need for manual parameter tuning, offering out-of-the-box\nusability. It achieves state-of-the-art accuracy across two public datasets,\nwith a mean radial error (MRE) of 1.5 mm on the Mandibular Molar Landmark (MML)\ndental CT dataset and 1.2 mm for anatomical fiducials on a brain MRI dataset\n(AFIDs), where nnLandmark aligns with the inter-rater variability of 1.5 mm.\nWith its strong generalization, reproducibility, and ease of deployment,\nnnLandmark establishes a reliable baseline for 3D landmark detection,\nsupporting research in anatomical localization and clinical workflows that\ndepend on precise landmark identification. The code will be available soon.", "published": "2025-04-09 09:53:39", "link": "http://arxiv.org/abs/2504.06742v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Uni-PrevPredMap: Extending PrevPredMap to a Unified Framework of Prior-Informed Modeling for Online Vectorized HD Map Construction", "abstract": "Safety constitutes a foundational imperative for autonomous driving systems,\nnecessitating the maximal incorporation of accessible external prior\ninformation. This study establishes that temporal perception buffers and\ncost-efficient maps inherently form complementary prior sources for online\nvectorized high-definition (HD) map construction. We present Uni-PrevPredMap, a\nunified prior-informed framework that systematically integrates two synergistic\ninformation sources: previous predictions and simulated outdated HD maps. The\nframework introduces two core innovations: a tile-indexed 3D vectorized global\nmap processor enabling efficient refreshment, storage, and retrieval of 3D\nvectorized priors; a tri-mode operational optimization paradigm ensuring\nconsistency across non-prior, temporal-prior, and temporal-map-fusion-prior\nscenarios while mitigating reliance on idealized map fidelity assumptions.\nUni-PrevPredMap achieves state-of-the-art performance in map-absent scenarios\nacross established online vectorized HD map construction benchmarks. When\nprovided with simulated outdated HD maps, the framework exhibits robust\ncapabilities in error-resilient prior fusion, empirically confirming the\nsynergistic complementarity between previous predictions and simulated outdated\nHD maps. Code will be available at https://github.com/pnnnnnnn/Uni-PrevPredMap.", "published": "2025-04-09 07:36:17", "link": "http://arxiv.org/abs/2504.06647v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ASHiTA: Automatic Scene-grounded HIerarchical Task Analysis", "abstract": "While recent work in scene reconstruction and understanding has made strides\nin grounding natural language to physical 3D environments, it is still\nchallenging to ground abstract, high-level instructions to a 3D scene.\nHigh-level instructions might not explicitly invoke semantic elements in the\nscene, and even the process of breaking a high-level task into a set of more\nconcrete subtasks, a process called hierarchical task analysis, is\nenvironment-dependent. In this work, we propose ASHiTA, the first framework\nthat generates a task hierarchy grounded to a 3D scene graph by breaking down\nhigh-level tasks into grounded subtasks. ASHiTA alternates LLM-assisted\nhierarchical task analysis, to generate the task breakdown, with task-driven 3D\nscene graph construction to generate a suitable representation of the\nenvironment. Our experiments show that ASHiTA performs significantly better\nthan LLM baselines in breaking down high-level tasks into environment-dependent\nsubtasks and is additionally able to achieve grounding performance comparable\nto state-of-the-art methods.", "published": "2025-04-09 03:22:52", "link": "http://arxiv.org/abs/2504.06553v2", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Alice: Proactive Learning with Teacher's Demonstrations for Weak-to-Strong Generalization", "abstract": "The growing capabilities of large language models (LLMs) present a key\nchallenge of maintaining effective human oversight. Weak-to-strong\ngeneralization (W2SG) offers a promising framework for supervising increasingly\ncapable LLMs using weaker ones. Traditional W2SG methods rely on passive\nlearning, where a weak teacher provides noisy demonstrations to train a strong\nstudent. This hinders students from employing their knowledge during training\nand reaching their full potential. In this work, we introduce Alice\n(pro{A}ctive {l}earning w{i}th tea{c}her's D{e}monstrations), a framework that\nleverages complementary knowledge between teacher and student to enhance the\nlearning process.We probe the knowledge base of the teacher model by eliciting\ntheir uncertainty, and then use these insights together with teachers'\nresponses as demonstrations to guide student models in self-generating improved\nresponses for supervision. In addition, for situations with significant\ncapability gaps between teacher and student models, we introduce cascade Alice,\nwhich employs a hierarchical training approach where weak teachers initially\nsupervise intermediate models, who then guide stronger models in sequence.\nExperimental results demonstrate that our method significantly enhances the\nW2SG performance, yielding substantial improvements in three key tasks compared\nto the original W2SG: knowledge-based reasoning (+4.0%), mathematical reasoning\n(+22.62%), and logical reasoning (+12.11%). This highlights the effectiveness\nof our new W2SG paradigm that enables more robust knowledge transfer and\nsupervision outcome.", "published": "2025-04-09 22:33:06", "link": "http://arxiv.org/abs/2504.07316v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual MFA: Forced Alignment on Low-Resource Related Languages", "abstract": "We compare the outcomes of multilingual and crosslingual training for related\nand unrelated Australian languages with similar phonological inventories. We\nuse the Montreal Forced Aligner to train acoustic models from scratch and adapt\na large English model, evaluating results against seen data, unseen data (seen\nlanguage), and unseen data and language. Results indicate benefits of adapting\nthe English baseline model for previously unseen languages.", "published": "2025-04-09 22:32:57", "link": "http://arxiv.org/abs/2504.07315v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PAYADOR: A Minimalist Approach to Grounding Language Models on Structured Data for Interactive Storytelling and Role-playing Games", "abstract": "Every time an Interactive Storytelling (IS) system gets a player input, it is\nfacing the world-update problem. Classical approaches to this problem consist\nin mapping that input to known preprogrammed actions, what can severely\nconstrain the free will of the player. When the expected experience has a\nstrong focus on improvisation, like in Role-playing Games (RPGs), this problem\nis critical. In this paper we present PAYADOR, a different approach that\nfocuses on predicting the outcomes of the actions instead of representing the\nactions themselves. To implement this approach, we ground a Large Language\nModel to a minimal representation of the fictional world, obtaining promising\nresults. We make this contribution open-source, so it can be adapted and used\nfor other related research on unleashing the co-creativity power of RPGs.", "published": "2025-04-09 21:59:31", "link": "http://arxiv.org/abs/2504.07304v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MDIT: A Model-free Data Interpolation Method for Diverse Instruction Tuning", "abstract": "As Large Language Models (LLMs) are increasingly applied across various\ntasks, instruction tuning has emerged as a critical method for enhancing model\nperformance. However, current data management strategies face substantial\nchallenges in generating diverse and comprehensive data, restricting further\nimprovements in model performance. To address this gap, we propose MDIT, a\nnovel model-free data interpolation method for diverse instruction tuning,\nwhich generates varied and high-quality instruction data by performing task\ninterpolation. Moreover, it contains diversity-based clustering strategies to\nensure the diversity of the training data. Extensive experiments show that our\nmethod achieves superior performance in multiple benchmark tasks. The LLMs\nfinetuned with MDIT show significant improvements in numerous tasks such as\ngeneral question answering, math reasoning, and code generation. MDIT offers an\nefficient and automatic data synthetic method, generating diverse instruction\ndata without depending on external resources while expanding the application\npotential of LLMs in complex environments.", "published": "2025-04-09 21:28:17", "link": "http://arxiv.org/abs/2504.07288v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RAISE: Reinforenced Adaptive Instruction Selection For Large Language Models", "abstract": "In the instruction fine-tuning of large language models (LLMs), it has become\na consensus that a few high-quality instructions are superior to a large number\nof low-quality instructions. At present, many instruction selection methods\nhave been proposed, but most of these methods select instruction based on\nheuristic quality metrics, and only consider data selection before training.\nThese designs lead to insufficient optimization of instruction fine-tuning, and\nfixed heuristic indicators are often difficult to optimize for specific tasks.\nSo we designed a dynamic, task-objective-driven instruction selection framework\nRAISE(Reinforenced Adaptive Instruction SElection), which incorporates the\nentire instruction fine-tuning process into optimization, selecting instruction\nat each step based on the expected impact of instruction on model performance\nimprovement. Our approach is well interpretable and has strong task-specific\noptimization capabilities. By modeling dynamic instruction selection as a\nsequential decision-making process, we use RL to train our selection strategy.\nExtensive experiments and result analysis prove the superiority of our method\ncompared with other instruction selection methods. Notably, RAISE achieves\nsuperior performance by updating only 1\\% of the training steps compared to\nfull-data training, demonstrating its efficiency and effectiveness.", "published": "2025-04-09 21:17:52", "link": "http://arxiv.org/abs/2504.07282v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Modeling for the Future of Finance: A Quantitative Survey into Metrics, Tasks, and Data Opportunities", "abstract": "Recent advances in language modeling have led to growing interest in applying\nNatural Language Processing (NLP) techniques to financial problems, enabling\nnew approaches to analysis and decision-making. To systematically examine this\ntrend, we review 374 NLP research papers published between 2017 and 2024 across\n38 conferences and workshops, with a focused analysis of 221 papers that\ndirectly address finance-related tasks. We evaluate these papers across 11\nqualitative and quantitative dimensions, identifying key trends such as the\nincreasing use of general-purpose language models, steady progress in sentiment\nanalysis and information extraction, and emerging efforts around explainability\nand privacy-preserving methods. We also discuss the use of evaluation metrics,\nhighlighting the importance of domain-specific ones to complement standard\nmachine learning metrics. Our findings emphasize the need for more accessible,\nadaptive datasets and highlight the significance of incorporating financial\ncrisis periods to strengthen model robustness under real-world conditions. This\nsurvey provides a structured overview of NLP research applied to finance and\noffers practical insights for researchers and practitioners working at this\nintersection.", "published": "2025-04-09 21:02:12", "link": "http://arxiv.org/abs/2504.07274v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visual-Aware Speech Recognition for Noisy Scenarios", "abstract": "Humans have the ability to utilize visual cues, such as lip movements and\nvisual scenes, to enhance auditory perception, particularly in noisy\nenvironments. However, current Automatic Speech Recognition (ASR) or\nAudio-Visual Speech Recognition (AVSR) models often struggle in noisy\nscenarios. To solve this task, we propose a model that improves transcription\nby correlating noise sources to visual cues. Unlike works that rely on lip\nmotion and require the speaker's visibility, we exploit broader visual\ninformation from the environment. This allows our model to naturally filter\nspeech from noise and improve transcription, much like humans do in noisy\nscenarios. Our method re-purposes pretrained speech and visual encoders,\nlinking them with multi-headed attention. This approach enables the\ntranscription of speech and the prediction of noise labels in video inputs. We\nintroduce a scalable pipeline to develop audio-visual datasets, where visual\ncues correlate to noise in the audio. We show significant improvements over\nexisting audio-only models in noisy scenarios. Results also highlight that\nvisual cues play a vital role in improved transcription accuracy.", "published": "2025-04-09 19:09:54", "link": "http://arxiv.org/abs/2504.07229v1", "categories": ["cs.CL", "eess.AS", "eess.SP"], "primary_category": "cs.CL"}
{"title": "ConceptCarve: Dynamic Realization of Evidence", "abstract": "Finding evidence for human opinion and behavior at scale is a challenging\ntask, often requiring an understanding of sophisticated thought patterns among\nvast online communities found on social media. For example, studying how gun\nownership is related to the perception of Freedom, requires a retrieval system\nthat can operate at scale over social media posts, while dealing with two key\nchallenges: (1) identifying abstract concept instances, (2) which can be\ninstantiated differently across different communities. To address these, we\nintroduce ConceptCarve, an evidence retrieval framework that utilizes\ntraditional retrievers and LLMs to dynamically characterize the search space\nduring retrieval. Our experiments show that ConceptCarve surpasses traditional\nretrieval systems in finding evidence within a social media community. It also\nproduces an interpretable representation of the evidence for that community,\nwhich we use to qualitatively analyze complex thought patterns that manifest\ndifferently across the communities.", "published": "2025-04-09 19:09:31", "link": "http://arxiv.org/abs/2504.07228v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SemEval-2025 Task 5: LLMs4Subjects -- LLM-based Automated Subject Tagging for a National Technical Library's Open-Access Catalog", "abstract": "We present SemEval-2025 Task 5: LLMs4Subjects, a shared task on automated\nsubject tagging for scientific and technical records in English and German\nusing the GND taxonomy. Participants developed LLM-based systems to recommend\ntop-k subjects, evaluated through quantitative metrics (precision, recall,\nF1-score) and qualitative assessments by subject specialists. Results highlight\nthe effectiveness of LLM ensembles, synthetic data generation, and multilingual\nprocessing, offering insights into applying LLMs for digital library\nclassification.", "published": "2025-04-09 18:26:46", "link": "http://arxiv.org/abs/2504.07199v1", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HypoEval: Hypothesis-Guided Evaluation for Natural Language Generation", "abstract": "Large language models (LLMs) have demonstrated great potential for automating\nthe evaluation of natural language generation. Previous frameworks of\nLLM-as-a-judge fall short in two ways: they either use zero-shot setting\nwithout consulting any human input, which leads to low alignment, or fine-tune\nLLMs on labeled data, which requires a non-trivial number of samples. Moreover,\nprevious methods often provide little reasoning behind automated evaluations.\nIn this paper, we propose HypoEval, Hypothesis-guided Evaluation framework,\nwhich first uses a small corpus of human evaluations to generate more detailed\nrubrics for human judgments and then incorporates a checklist-like approach to\ncombine LLM's assigned scores on each decomposed dimension to acquire overall\nscores. With only 30 human evaluations, HypoEval achieves state-of-the-art\nperformance in alignment with both human rankings (Spearman correlation) and\nhuman scores (Pearson correlation), on average outperforming G-Eval by 11.86%\nand fine-tuned Llama-3.1-8B-Instruct with at least 3 times more human\nevaluations by 11.95%. Furthermore, we conduct systematic studies to assess the\nrobustness of HypoEval, highlighting its effectiveness as a reliable and\ninterpretable automated evaluation framework.", "published": "2025-04-09 18:00:01", "link": "http://arxiv.org/abs/2504.07174v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "R2E-Gym: Procedural Environments and Hybrid Verifiers for Scaling Open-Weights SWE Agents", "abstract": "Improving open-source models on real-world SWE tasks (solving GITHUB issues)\nfaces two key challenges: 1) scalable curation of execution environments to\ntrain these models, and, 2) optimal scaling of test-time compute. We introduce\nAgentGym, the largest procedurally-curated executable gym environment for\ntraining real-world SWE-agents, consisting of more than 8.7K tasks. AgentGym is\npowered by two main contributions: 1) SYNGEN: a synthetic data curation recipe\nthat enables scalable curation of executable environments using test-generation\nand back-translation directly from commits, thereby reducing reliance on\nhuman-written issues or unit tests. We show that this enables more scalable\ntraining leading to pass@1 performance of 34.4% on SWE-Bench Verified benchmark\nwith our 32B model. 2) Hybrid Test-time Scaling: we provide an in-depth\nanalysis of two test-time scaling axes; execution-based and execution-free\nverifiers, demonstrating that they exhibit complementary strengths and\nlimitations. Test-based verifiers suffer from low distinguishability, while\nexecution-free verifiers are biased and often rely on stylistic features.\nSurprisingly, we find that while each approach individually saturates around\n42-43%, significantly higher gains can be obtained by leveraging their\ncomplementary strengths. Overall, our approach achieves 51% on the SWE-Bench\nVerified benchmark, reflecting a new state-of-the-art for open-weight\nSWE-agents and for the first time showing competitive performance with\nproprietary models such as o1, o1-preview and sonnet-3.5-v2 (with tools). We\nwill open-source our environments, models, and agent trajectories.", "published": "2025-04-09 17:55:19", "link": "http://arxiv.org/abs/2504.07164v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Holistic Capability Preservation: Towards Compact Yet Comprehensive Reasoning Models", "abstract": "This technical report presents Ring-Lite-Distill, a lightweight reasoning\nmodel derived from our open-source Mixture-of-Experts (MoE) Large Language\nModels (LLMs) Ling-Lite. This study demonstrates that through meticulous\nhigh-quality data curation and ingenious training paradigms, the compact MoE\nmodel Ling-Lite can be further trained to achieve exceptional reasoning\ncapabilities, while maintaining its parameter-efficient architecture with only\n2.75 billion activated parameters, establishing an efficient lightweight\nreasoning architecture. In particular, in constructing this model, we have not\nmerely focused on enhancing advanced reasoning capabilities, exemplified by\nhigh-difficulty mathematical problem solving, but rather aimed to develop a\nreasoning model with more comprehensive competency coverage. Our approach\nensures coverage across reasoning tasks of varying difficulty levels while\npreserving generic capabilities, such as instruction following, tool use, and\nknowledge retention. We show that, Ring-Lite-Distill's reasoning ability\nreaches a level comparable to DeepSeek-R1-Distill-Qwen-7B, while its general\ncapabilities significantly surpass those of DeepSeek-R1-Distill-Qwen-7B. The\nmodels are accessible at https://huggingface.co/inclusionAI", "published": "2025-04-09 11:24:32", "link": "http://arxiv.org/abs/2504.07158v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Zeus: Zero-shot LLM Instruction for Union Segmentation in Multimodal Medical Imaging", "abstract": "Medical image segmentation has achieved remarkable success through the\ncontinuous advancement of UNet-based and Transformer-based foundation\nbackbones. However, clinical diagnosis in the real world often requires\nintegrating domain knowledge, especially textual information. Conducting\nmultimodal learning involves visual and text modalities shown as a solution,\nbut collecting paired vision-language datasets is expensive and time-consuming,\nposing significant challenges. Inspired by the superior ability in numerous\ncross-modal tasks for Large Language Models (LLMs), we proposed a novel\nVision-LLM union framework to address the issues. Specifically, we introduce\nfrozen LLMs for zero-shot instruction generation based on corresponding medical\nimages, imitating the radiology scanning and report generation process. {To\nbetter approximate real-world diagnostic processes}, we generate more precise\ntext instruction from multimodal radiology images (e.g., T1-w or T2-w MRI and\nCT). Based on the impressive ability of semantic understanding and rich\nknowledge of LLMs. This process emphasizes extracting special features from\ndifferent modalities and reunion the information for the ultimate clinical\ndiagnostic. With generated text instruction, our proposed union segmentation\nframework can handle multimodal segmentation without prior collected\nvision-language datasets. To evaluate our proposed method, we conduct\ncomprehensive experiments with influential baselines, the statistical results\nand the visualized case study demonstrate the superiority of our novel method.}", "published": "2025-04-09 23:33:35", "link": "http://arxiv.org/abs/2504.07336v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Objaverse++: Curated 3D Object Dataset with Quality Annotations", "abstract": "This paper presents Objaverse++, a curated subset of Objaverse enhanced with\ndetailed attribute annotations by human experts. Recent advances in 3D content\ngeneration have been driven by large-scale datasets such as Objaverse, which\ncontains over 800,000 3D objects collected from the Internet. Although\nObjaverse represents the largest available 3D asset collection, its utility is\nlimited by the predominance of low-quality models. To address this limitation,\nwe manually annotate 10,000 3D objects with detailed attributes, including\naesthetic quality scores, texture color classifications, multi-object\ncomposition flags, transparency characteristics, etc. Then, we trained a neural\nnetwork capable of annotating the tags for the rest of the Objaverse dataset.\nThrough experiments and a user study on generation results, we demonstrate that\nmodels pre-trained on our quality-focused subset achieve better performance\nthan those trained on the larger dataset of Objaverse in image-to-3D generation\ntasks. In addition, by comparing multiple subsets of training data filtered by\nour tags, our results show that the higher the data quality, the faster the\ntraining loss converges. These findings suggest that careful curation and rich\nannotation can compensate for the raw dataset size, potentially offering a more\nefficient path to develop 3D generative models. We release our enhanced dataset\nof approximately 500,000 curated 3D models to facilitate further research on\nvarious downstream tasks in 3D computer vision. In the near future, we aim to\nextend our annotations to cover the entire Objaverse dataset.", "published": "2025-04-09 23:29:08", "link": "http://arxiv.org/abs/2504.07334v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "68T45, 68T07", "I.2.10; I.3.5; I.3.7; I.4.8; I.5.1"], "primary_category": "cs.CV"}
{"title": "Identifying regions of interest in whole slide images of renal cell carcinoma", "abstract": "The histopathological images contain a huge amount of information, which can\nmake diagnosis an extremely timeconsuming and tedious task. In this study, we\ndeveloped a completely automated system to detect regions of interest (ROIs) in\nwhole slide images (WSI) of renal cell carcinoma (RCC), to reduce time analysis\nand assist pathologists in making more accurate decisions. The proposed\napproach is based on an efficient texture descriptor named dominant rotated\nlocal binary pattern (DRLBP) and color transformation to reveal and exploit the\nimmense texture variability at the microscopic high magnifications level.\nThereby, the DRLBPs retain the structural information and utilize the magnitude\nvalues in a local neighborhood for more discriminative power. For the\nclassification of the relevant ROIs, feature extraction of WSIs patches was\nperformed on the color channels separately to form the histograms. Next, we\nused the most frequently occurring patterns as a feature selection step to\ndiscard non-informative features. The performances of different classifiers on\na set of 1800 kidney cancer patches originating from 12 whole slide images were\ncompared and evaluated. Furthermore, the small size of the image dataset allows\nto investigate deep learning approach based on transfer learning for image\npatches classification by using deep features and fine-tuning methods. High\nrecognition accuracy was obtained and the classifiers are efficient, the best\nprecision result was 99.17% achieved with SVM. Moreover, transfer learning\nmodels perform well with comparable performance, and the highest precision\nusing ResNet-50 reached 98.50%. The proposed approach results revealed a very\nefficient image classification and demonstrated efficacy in identifying ROIs.\nThis study presents an automatic system to detect regions of interest relevant\nto the diagnosis of kidney cancer in whole slide histopathology images.", "published": "2025-04-09 22:28:26", "link": "http://arxiv.org/abs/2504.07313v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Modeling Response Consistency in Multi-Agent LLM Systems: A Comparative Analysis of Shared and Separate Context Approaches", "abstract": "Large Language Models (LLMs) are increasingly utilized in multi-agent systems\n(MAS) to enhance collaborative problem-solving and interactive reasoning.\nRecent advancements have enabled LLMs to function as autonomous agents capable\nof understanding complex interactions across multiple topics. However,\ndeploying LLMs in MAS introduces challenges related to context management,\nresponse consistency, and scalability, especially when agents must operate\nunder memory limitations and handle noisy inputs. While prior research has\nexplored optimizing context sharing and response latency in LLM-driven MAS,\nthese efforts often focus on either fully centralized or decentralized\nconfigurations, each with distinct trade-offs.\n  In this paper, we develop a probabilistic framework to analyze the impact of\nshared versus separate context configurations on response consistency and\nresponse times in LLM-based MAS. We introduce the Response Consistency Index\n(RCI) as a metric to evaluate the effects of context limitations, noise, and\ninter-agent dependencies on system performance. Our approach differs from\nexisting research by focusing on the interplay between memory constraints and\nnoise management, providing insights into optimizing scalability and response\ntimes in environments with interdependent topics. Through this analysis, we\noffer a comprehensive understanding of how different configurations impact the\nefficiency of LLM-driven multi-agent systems, thereby guiding the design of\nmore robust architectures.", "published": "2025-04-09 21:54:21", "link": "http://arxiv.org/abs/2504.07303v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "A Multi-Phase Analysis of Blood Culture Stewardship: Machine Learning Prediction, Expert Recommendation Assessment, and LLM Automation", "abstract": "Blood cultures are often over ordered without clear justification, straining\nhealthcare resources and contributing to inappropriate antibiotic use pressures\nworsened by the global shortage. In study of 135483 emergency department (ED)\nblood culture orders, we developed machine learning (ML) models to predict the\nrisk of bacteremia using structured electronic health record (EHR) data and\nprovider notes via a large language model (LLM). The structured models AUC\nimproved from 0.76 to 0.79 with note embeddings and reached 0.81 with added\ndiagnosis codes. Compared to an expert recommendation framework applied by\nhuman reviewers and an LLM-based pipeline, our ML approach offered higher\nspecificity without compromising sensitivity. The recommendation framework\nachieved sensitivity 86%, specificity 57%, while the LLM maintained high\nsensitivity (96%) but over classified negatives, reducing specificity (16%).\nThese findings demonstrate that ML models integrating structured and\nunstructured data can outperform consensus recommendations, enhancing\ndiagnostic stewardship beyond existing standards of care.", "published": "2025-04-09 21:12:29", "link": "http://arxiv.org/abs/2504.07278v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Evaluating Parameter-Based Training Performance of Neural Networks and Variational Quantum Circuits", "abstract": "In recent years, neural networks (NNs) have driven significant advances in\nmachine learning. However, as tasks grow more complex, NNs often require large\nnumbers of trainable parameters, which increases computational and energy\ndemands. Variational quantum circuits (VQCs) offer a promising alternative:\nthey leverage quantum mechanics to capture intricate relationships and\ntypically need fewer parameters. In this work, we evaluate NNs and VQCs on\nsimple supervised and reinforcement learning tasks, examining models with\ndifferent parameter sizes. We simulate VQCs and execute selected parts of the\ntraining process on real quantum hardware to approximate actual training times.\nOur results show that VQCs can match NNs in performance while using\nsignificantly fewer parameters, despite longer training durations. As quantum\ntechnology and algorithms advance, and VQC architectures improve, we posit that\nVQCs could become advantageous for certain machine learning tasks.", "published": "2025-04-09 21:00:41", "link": "http://arxiv.org/abs/2504.07273v1", "categories": ["quant-ph", "cs.AI", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Better Decisions through the Right Causal World Model", "abstract": "Reinforcement learning (RL) agents have shown remarkable performances in\nvarious environments, where they can discover effective policies directly from\nsensory inputs. However, these agents often exploit spurious correlations in\nthe training data, resulting in brittle behaviours that fail to generalize to\nnew or slightly modified environments. To address this, we introduce the Causal\nObject-centric Model Extraction Tool (COMET), a novel algorithm designed to\nlearn the exact interpretable causal world models (CWMs). COMET first extracts\nobject-centric state descriptions from observations and identifies the\nenvironment's internal states related to the depicted objects' properties.\nUsing symbolic regression, it models object-centric transitions and derives\ncausal relationships governing object dynamics. COMET further incorporates\nlarge language models (LLMs) for semantic inference, annotating causal\nvariables to enhance interpretability.\n  By leveraging these capabilities, COMET constructs CWMs that align with the\ntrue causal structure of the environment, enabling agents to focus on\ntask-relevant features. The extracted CWMs mitigate the danger of shortcuts,\npermitting the development of RL systems capable of better planning and\ndecision-making across dynamic scenarios. Our results, validated in Atari\nenvironments such as Pong and Freeway, demonstrate the accuracy and robustness\nof COMET, highlighting its potential to bridge the gap between object-centric\nreasoning and causal inference in reinforcement learning.", "published": "2025-04-09 20:29:13", "link": "http://arxiv.org/abs/2504.07257v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A new training approach for text classification in Mental Health: LatentGLoss", "abstract": "This study presents a multi-stage approach to mental health classification by\nleveraging traditional machine learning algorithms, deep learning\narchitectures, and transformer-based models. A novel data set was curated and\nutilized to evaluate the performance of various methods, starting with\nconventional classifiers and advancing through neural networks. To broaden the\narchitectural scope, recurrent neural networks (RNNs) such as LSTM and GRU were\nalso evaluated to explore their effectiveness in modeling sequential patterns\nin the data. Subsequently, transformer models such as BERT were fine-tuned to\nassess the impact of contextual embeddings in this domain. Beyond these\nbaseline evaluations, the core contribution of this study lies in a novel\ntraining strategy involving a dual-model architecture composed of a teacher and\na student network. Unlike standard distillation techniques, this method does\nnot rely on soft label transfer; instead, it facilitates information flow\nthrough both the teacher model's output and its latent representations by\nmodifying the loss function. The experimental results highlight the\neffectiveness of each modeling stage and demonstrate that the proposed loss\nfunction and teacher-student interaction significantly enhance the model's\nlearning capacity in mental health prediction tasks.", "published": "2025-04-09 19:34:31", "link": "http://arxiv.org/abs/2504.07245v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Face-LLaVA: Facial Expression and Attribute Understanding through Instruction Tuning", "abstract": "The human face plays a central role in social communication, necessitating\nthe use of performant computer vision tools for human-centered applications. We\npropose Face-LLaVA, a multimodal large language model for face-centered,\nin-context learning, including facial expression and attribute recognition.\nAdditionally, Face-LLaVA is able to generate natural language descriptions that\ncan be used for reasoning. Leveraging existing visual databases, we first\ndeveloped FaceInstruct-1M, a face-centered database for instruction tuning\nMLLMs for face processing. We then developed a novel face-specific visual\nencoder powered by Face-Region Guided Cross-Attention that integrates face\ngeometry with local visual features. We evaluated the proposed method across\nnine different datasets and five different face processing tasks, including\nfacial expression recognition, action unit detection, facial attribute\ndetection, age estimation and deepfake detection. Face-LLaVA achieves superior\nresults compared to existing open-source MLLMs and competitive performance\ncompared to commercial solutions. Our model output also receives a higher\nreasoning rating by GPT under a zero-shot setting across all the tasks. Both\nour dataset and model wil be released at https://face-llava.github.io to\nsupport future advancements in social AI and foundational vision-language\nresearch.", "published": "2025-04-09 18:26:07", "link": "http://arxiv.org/abs/2504.07198v1", "categories": ["cs.CV", "cs.AI", "cs.HC"], "primary_category": "cs.CV"}
{"title": "Trustworthy AI Must Account for Intersectionality", "abstract": "Trustworthy AI encompasses many aspirational aspects for aligning AI systems\nwith human values, including fairness, privacy, robustness, explainability, and\nuncertainty quantification. However, efforts to enhance one aspect often\nintroduce unintended trade-offs that negatively impact others, making it\nchallenging to improve all aspects simultaneously. In this position paper, we\nreview notable approaches to these five aspects and systematically consider\nevery pair, detailing the negative interactions that can arise. For example,\napplying differential privacy to model training can amplify biases in the data,\nundermining fairness. Drawing on these findings, we take the position that\naddressing trustworthiness along each axis in isolation is insufficient.\nInstead, research on Trustworthy AI must account for intersectionality between\naspects and adopt a holistic view across all relevant axes at once. To\nillustrate our perspective, we provide guidance on how researchers can work\ntowards integrated trustworthiness, a case study on how intersectionality\napplies to the financial industry, and alternative views to our position.", "published": "2025-04-09 18:00:00", "link": "http://arxiv.org/abs/2504.07170v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DLTPose: 6DoF Pose Estimation From Accurate Dense Surface Point Estimates", "abstract": "We propose DLTPose, a novel method for 6DoF object pose estimation from RGB-D\nimages that combines the accuracy of sparse keypoint methods with the\nrobustness of dense pixel-wise predictions. DLTPose predicts per-pixel radial\ndistances to a set of minimally four keypoints, which are then fed into our\nnovel Direct Linear Transform (DLT) formulation to produce accurate 3D object\nframe surface estimates, leading to better 6DoF pose estimation. Additionally,\nwe introduce a novel symmetry-aware keypoint ordering approach, designed to\nhandle object symmetries that otherwise cause inconsistencies in keypoint\nassignments. Previous keypoint-based methods relied on fixed keypoint\norderings, which failed to account for the multiple valid configurations\nexhibited by symmetric objects, which our ordering approach exploits to enhance\nthe model's ability to learn stable keypoint representations. Extensive\nexperiments on the benchmark LINEMOD, Occlusion LINEMOD and YCB-Video datasets\nshow that DLTPose outperforms existing methods, especially for symmetric and\noccluded objects, demonstrating superior Mean Average Recall values of 86.5%\n(LM), 79.7% (LM-O) and 89.5% (YCB-V). The code is available at\nhttps://anonymous.4open.science/r/DLTPose_/ .", "published": "2025-04-09 23:30:22", "link": "http://arxiv.org/abs/2504.07335v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MoEDiff-SR: Mixture of Experts-Guided Diffusion Model for Region-Adaptive MRI Super-Resolution", "abstract": "Magnetic Resonance Imaging (MRI) at lower field strengths (e.g., 3T) suffers\nfrom limited spatial resolution, making it challenging to capture fine\nanatomical details essential for clinical diagnosis and neuroimaging research.\nTo overcome this limitation, we propose MoEDiff-SR, a Mixture of Experts\n(MoE)-guided diffusion model for region-adaptive MRI Super-Resolution (SR).\nUnlike conventional diffusion-based SR models that apply a uniform denoising\nprocess across the entire image, MoEDiff-SR dynamically selects specialized\ndenoising experts at a fine-grained token level, ensuring region-specific\nadaptation and enhanced SR performance. Specifically, our approach first\nemploys a Transformer-based feature extractor to compute multi-scale patch\nembeddings, capturing both global structural information and local texture\ndetails. The extracted feature embeddings are then fed into an MoE gating\nnetwork, which assigns adaptive weights to multiple diffusion-based denoisers,\neach specializing in different brain MRI characteristics, such as centrum\nsemiovale, sulcal and gyral cortex, and grey-white matter junction. The final\noutput is produced by aggregating the denoised results from these specialized\nexperts according to dynamically assigned gating probabilities. Experimental\nresults demonstrate that MoEDiff-SR outperforms existing state-of-the-art\nmethods in terms of quantitative image quality metrics, perceptual fidelity,\nand computational efficiency. Difference maps from each expert further\nhighlight their distinct specializations, confirming the effective\nregion-specific denoising capability and the interpretability of expert\ncontributions. Additionally, clinical evaluation validates its superior\ndiagnostic capability in identifying subtle pathological features, emphasizing\nits practical relevance in clinical neuroimaging. Our code is available at\nhttps://github.com/ZWang78/MoEDiff-SR.", "published": "2025-04-09 22:12:44", "link": "http://arxiv.org/abs/2504.07308v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "CEC-MMR: Cross-Entropy Clustering Approach to Multi-Modal Regression", "abstract": "In practical applications of regression analysis, it is not uncommon to\nencounter a multitude of values for each attribute. In such a situation, the\nunivariate distribution, which is typically Gaussian, is suboptimal because the\nmean may be situated between modes, resulting in a predicted value that differs\nsignificantly from the actual data. Consequently, to address this issue, a\nmixture distribution with parameters learned by a neural network, known as a\nMixture Density Network (MDN), is typically employed. However, this approach\nhas an important inherent limitation, in that it is not feasible to ascertain\nthe precise number of components with a reasonable degree of accuracy. In this\npaper, we introduce CEC-MMR, a novel approach based on Cross-Entropy Clustering\n(CEC), which allows for the automatic detection of the number of components in\na regression problem. Furthermore, given an attribute and its value, our method\nis capable of uniquely identifying it with the underlying component. The\nexperimental results demonstrate that CEC-MMR yields superior outcomes compared\nto classical MDNs.", "published": "2025-04-09 21:51:38", "link": "http://arxiv.org/abs/2504.07301v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Quantifying Epistemic Uncertainty in Absolute Pose Regression", "abstract": "Visual relocalization is the task of estimating the camera pose given an\nimage it views. Absolute pose regression offers a solution to this task by\ntraining a neural network, directly regressing the camera pose from image\nfeatures. While an attractive solution in terms of memory and compute\nefficiency, absolute pose regression's predictions are inaccurate and\nunreliable outside the training domain. In this work, we propose a novel method\nfor quantifying the epistemic uncertainty of an absolute pose regression model\nby estimating the likelihood of observations within a variational framework.\nBeyond providing a measure of confidence in predictions, our approach offers a\nunified model that also handles observation ambiguities, probabilistically\nlocalizing the camera in the presence of repetitive structures. Our method\noutperforms existing approaches in capturing the relation between uncertainty\nand prediction error.", "published": "2025-04-09 20:32:45", "link": "http://arxiv.org/abs/2504.07260v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Few-Shot Adaptation of Grounding DINO for Agricultural Domain", "abstract": "Deep learning models are transforming agricultural applications by enabling\nautomated phenotyping, monitoring, and yield estimation. However, their\neffectiveness heavily depends on large amounts of annotated training data,\nwhich can be labor and time intensive. Recent advances in open-set object\ndetection, particularly with models like Grounding-DINO, offer a potential\nsolution to detect regions of interests based on text prompt input. Initial\nzero-shot experiments revealed challenges in crafting effective text prompts,\nespecially for complex objects like individual leaves and visually similar\nclasses. To address these limitations, we propose an efficient few-shot\nadaptation method that simplifies the Grounding-DINO architecture by removing\nthe text encoder module (BERT) and introducing a randomly initialized trainable\ntext embedding. This method achieves superior performance across multiple\nagricultural datasets, including plant-weed detection, plant counting, insect\nidentification, fruit counting, and remote sensing tasks. Specifically, it\ndemonstrates up to a $\\sim24\\%$ higher mAP than fully fine-tuned YOLO models on\nagricultural datasets and outperforms previous state-of-the-art methods by\n$\\sim10\\%$ in remote sensing, under few-shot learning conditions. Our method\noffers a promising solution for automating annotation and accelerating the\ndevelopment of specialized agricultural AI solutions.", "published": "2025-04-09 19:57:25", "link": "http://arxiv.org/abs/2504.07252v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MESA: Text-Driven Terrain Generation Using Latent Diffusion and Global Copernicus Data", "abstract": "Terrain modeling has traditionally relied on procedural techniques, which\noften require extensive domain expertise and handcrafted rules. In this paper,\nwe present MESA - a novel data-centric alternative by training a diffusion\nmodel on global remote sensing data. This approach leverages large-scale\ngeospatial information to generate high-quality terrain samples from text\ndescriptions, showcasing a flexible and scalable solution for terrain\ngeneration. The model's capabilities are demonstrated through extensive\nexperiments, highlighting its ability to generate realistic and diverse terrain\nlandscapes. The dataset produced to support this work, the Major TOM Core-DEM\nextension dataset, is released openly as a comprehensive resource for global\nterrain data. The results suggest that data-driven models, trained on remote\nsensing data, can provide a powerful tool for realistic terrain modeling and\ngeneration.", "published": "2025-04-09 18:37:24", "link": "http://arxiv.org/abs/2504.07210v1", "categories": ["cs.GR", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "Perception in Reflection", "abstract": "We present a perception in reflection paradigm designed to transcend the\nlimitations of current large vision-language models (LVLMs), which are expected\nyet often fail to achieve perfect perception initially. Specifically, we\npropose Reflective Perception (RePer), a dual-model reflection mechanism that\nsystematically alternates between policy and critic models, enables iterative\nrefinement of visual perception. This framework is powered by Reflective\nPerceptual Learning (RPL), which reinforces intrinsic reflective capabilities\nthrough a methodically constructed visual reflection dataset and reflective\nunlikelihood training. Comprehensive experimental evaluation demonstrates\nRePer's quantifiable improvements in image understanding, captioning precision,\nand hallucination reduction. Notably, RePer achieves strong alignment between\nmodel attention patterns and human visual focus, while RPL optimizes\nfine-grained and free-form preference alignment. These advancements establish\nperception in reflection as a robust paradigm for future multimodal agents,\nparticularly in tasks requiring complex reasoning and multi-step manipulation.", "published": "2025-04-09 17:59:02", "link": "http://arxiv.org/abs/2504.07165v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Implied Integrality in Mixed-Integer Optimization", "abstract": "Implied-integer detection is a well-known presolving technique that is used\nby many Mixed-Integer Linear Programming solvers. Informally, a variable is\nsaid to be implied integer if its integrality is enforced implicitly by\nintegrality of other variables and the constraints of a problem. In this paper\nwe formalize the definition of implied integrality by taking a polyhedral\nperspective. Our main result characterizes implied integrality as occurring\nwhen a subset of integer variables is fixed to integer values and the\npolyhedron on the remaining variables is integral. While integral polyhedra are\nwell-understood theoretically, existing detection methods infer implied\nintegrality only for one variable at a time. We introduce new detection methods\nbased on the detection of integral polyhedra, extending existing techniques to\nmultiple variables. Additionally, we discuss the computational complexity of\nrecognizing implied integers. We conduct experiments using a new detection\nmethod that uses totally unimodular submatrices to identify implied\nintegrality. For the MIPLIB 2017 collection dataset our results indicate that,\non average, 18.8% of the variables are classified as implied integer after\npresolving, compared to just 3.3% identified by state-of-the-art techniques. We\nare able to reduce the average percentage of variables whose integrality needs\nto be enforced after presolving from 70.2% to 59.0%.", "published": "2025-04-09 18:36:22", "link": "http://arxiv.org/abs/2504.07209v1", "categories": ["cs.DM", "math.OC", "90C11 (Primary) 90C10, 90C57 (Secondary)"], "primary_category": "cs.DM"}
{"title": "Disjunctive domination in maximal outerplanar graphs", "abstract": "A disjunctive dominating set of a graph $G$ is a set $D \\subseteq V(G)$ such\nthat every vertex in $V(G)\\setminus D$ has a neighbor in $D$ or has at least\ntwo vertices in $D$ at distance $2$ from it. The disjunctive domination number\nof $G$, denoted by $\\gamma_2^d(G)$, is the minimum cardinality of a disjunctive\ndominating set of $G$. In this paper, we show that if $G$ is a maximal\nouterplanar graph of order $n \\ge 7$ with $k$ vertices of degree $2$, then\n$\\gamma_2^d(G)\\le \\lfloor\\frac{2}{9}(n+k)\\rfloor$, and this bound is sharp.", "published": "2025-04-09 18:05:29", "link": "http://arxiv.org/abs/2504.07186v1", "categories": ["math.CO", "cs.DM", "05C69"], "primary_category": "math.CO"}
{"title": "Learning to erase quantum states: thermodynamic implications of quantum learning theory", "abstract": "The energy cost of erasing quantum states depends on our knowledge of the\nstates. We show that learning algorithms can acquire such knowledge to erase\nmany copies of an unknown state at the optimal energy cost. This is proved by\nshowing that learning can be made fully reversible and has no fundamental\nenergy cost itself. With simple counting arguments, we relate the energy cost\nof erasing quantum states to their complexity, entanglement, and magic. We\nfurther show that the constructed erasure protocol is computationally efficient\nwhen learning is efficient. Conversely, under standard cryptographic\nassumptions, we prove that the optimal energy cost cannot be achieved\nefficiently in general. These results also enable efficient work extraction\nbased on learning. Together, our results establish a concrete connection\nbetween quantum learning theory and thermodynamics, highlighting the physical\nsignificance of learning processes and enabling efficient learning-based\nprotocols for thermodynamic tasks.", "published": "2025-04-09 23:51:01", "link": "http://arxiv.org/abs/2504.07341v1", "categories": ["quant-ph", "cond-mat.stat-mech", "cs.CC", "cs.IT", "cs.LG", "math.IT"], "primary_category": "quant-ph"}
{"title": "Bregman-Hausdorff divergence: strengthening the connections between computational geometry and machine learning", "abstract": "The purpose of this paper is twofold. On a technical side, we propose an\nextension of the Hausdorff distance from metric spaces to spaces equipped with\nasymmetric distance measures. Specifically, we focus on the family of Bregman\ndivergences, which includes the popular Kullback--Leibler divergence (also\nknown as relative entropy).\n  As a proof of concept, we use the resulting Bregman--Hausdorff divergence to\ncompare two collections of probabilistic predictions produced by different\nmachine learning models trained using the relative entropy loss. The algorithms\nwe propose are surprisingly efficient even for large inputs with hundreds of\ndimensions.\n  In addition to the introduction of this technical concept, we provide a\nsurvey. It outlines the basics of Bregman geometry, as well as computational\ngeometry algorithms. We focus on algorithms that are compatible with this\ngeometry and are relevant for machine learning.", "published": "2025-04-09 22:42:29", "link": "http://arxiv.org/abs/2504.07322v1", "categories": ["cs.LG", "cs.CG", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Leveraging deep learning for plant disease identification: a bibliometric analysis in SCOPUS from 2018 to 2024", "abstract": "This work aimed to present a bibliometric analysis of deep learning research\nfor plant disease identification, with a special focus on generative modeling.\nA thorough analysis of SCOPUS-sourced bibliometric data from 253 documents was\nperformed. Key performance metrics such as accuracy, precision, recall, and\nF1-score were analyzed for generative modeling. The findings highlighted\nsignificant contributions from some authors Too and Arnal Barbedo, whose works\nhad notable citation counts, suggesting their influence on the academic\ncommunity. Co-authorship networks revealed strong collaborative clusters, while\nkeyword analysis identified emerging research gaps. This study highlights the\nrole of collaboration and citation metrics in shaping research directions and\nenhancing the impact of scholarly work in applications of deep learning to\nplant disease identification. Future research should explore the methodologies\nof highly cited studies to inform best practices and policy-making.", "published": "2025-04-09 23:57:30", "link": "http://arxiv.org/abs/2504.07342v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FLASH: Flexible Learning of Adaptive Sampling from History in Temporal Graph Neural Networks", "abstract": "Aggregating temporal signals from historic interactions is a key step in\nfuture link prediction on dynamic graphs. However, incorporating long histories\nis resource-intensive. Hence, temporal graph neural networks (TGNNs) often rely\non historical neighbors sampling heuristics such as uniform sampling or recent\nneighbors selection. These heuristics are static and fail to adapt to the\nunderlying graph structure. We introduce FLASH, a learnable and graph-adaptive\nneighborhood selection mechanism that generalizes existing heuristics. FLASH\nintegrates seamlessly into TGNNs and is trained end-to-end using a\nself-supervised ranking loss. We provide theoretical evidence that commonly\nused heuristics hinders TGNNs performance, motivating our design. Extensive\nexperiments across multiple benchmarks demonstrate consistent and significant\nperformance improvements for TGNNs equipped with FLASH.", "published": "2025-04-09 23:35:09", "link": "http://arxiv.org/abs/2504.07337v1", "categories": ["cs.LG", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Follow-the-Perturbed-Leader Achieves Best-of-Both-Worlds for the m-Set Semi-Bandit Problems", "abstract": "We consider a common case of the combinatorial semi-bandit problem, the\n$m$-set semi-bandit, where the learner exactly selects $m$ arms from the total\n$d$ arms. In the adversarial setting, the best regret bound, known to be\n$\\mathcal{O}(\\sqrt{nmd})$ for time horizon $n$, is achieved by the well-known\nFollow-the-Regularized-Leader (FTRL) policy, which, however, requires to\nexplicitly compute the arm-selection probabilities by solving optimizing\nproblems at each time step and sample according to it. This problem can be\navoided by the Follow-the-Perturbed-Leader (FTPL) policy, which simply pulls\nthe $m$ arms that rank among the $m$ smallest (estimated) loss with random\nperturbation. In this paper, we show that FTPL with a Fr\\'echet perturbation\nalso enjoys the optimal regret bound $\\mathcal{O}(\\sqrt{nmd})$ in the\nadversarial setting and achieves best-of-both-world regret bounds, i.e.,\nachieves a logarithmic regret for the stochastic setting.", "published": "2025-04-09 22:07:01", "link": "http://arxiv.org/abs/2504.07307v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Data Fusion of Deep Learned Molecular Embeddings for Property Prediction", "abstract": "Data-driven approaches such as deep learning can result in predictive models\nfor material properties with exceptional accuracy and efficiency. However, in\nmany problems data is sparse, severely limiting their accuracy and\napplicability. To improve predictions, techniques such as transfer learning and\nmulti-task learning have been used. The performance of multi-task learning\nmodels depends on the strength of the underlying correlations between tasks and\nthe completeness of the dataset. We find that standard multi-task models tend\nto underperform when trained on sparse datasets with weakly correlated\nproperties. To address this gap, we use data fusion techniques to combine the\nlearned molecular embeddings of various single-task models and trained a\nmulti-task model on this combined embedding. We apply this technique to a\nwidely used benchmark dataset of quantum chemistry data for small molecules as\nwell as a newly compiled sparse dataset of experimental data collected from\nliterature and our own quantum chemistry and thermochemical calculations. The\nresults show that the fused, multi-task models outperform standard multi-task\nmodels for sparse datasets and can provide enhanced prediction on data-limited\nproperties compared to single-task models.", "published": "2025-04-09 21:40:15", "link": "http://arxiv.org/abs/2504.07297v1", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "primary_category": "cs.LG"}
{"title": "A Scalable Approach to Clustering Embedding Projections", "abstract": "Interactive visualization of embedding projections is a useful technique for\nunderstanding data and evaluating machine learning models. Labeling data within\nthese visualizations is critical for interpretation, as labels provide an\noverview of the projection and guide user navigation. However, most methods for\nproducing labels require clustering the points, which can be computationally\nexpensive as the number of points grows. In this paper, we describe an\nefficient clustering approach using kernel density estimation in the projected\n2D space instead of points. This algorithm can produce high-quality cluster\nregions from a 2D density map in a few hundred milliseconds, orders of\nmagnitude faster than current approaches. We contribute the design of the\nalgorithm, benchmarks, and applications that demonstrate the utility of the\nalgorithm, including labeling and summarization.", "published": "2025-04-09 21:24:17", "link": "http://arxiv.org/abs/2504.07285v1", "categories": ["cs.HC", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Adapting to Online Distribution Shifts in Deep Learning: A Black-Box Approach", "abstract": "We study the well-motivated problem of online distribution shift in which the\ndata arrive in batches and the distribution of each batch can change\narbitrarily over time. Since the shifts can be large or small, abrupt or\ngradual, the length of the relevant historical data to learn from may vary over\ntime, which poses a major challenge in designing algorithms that can\nautomatically adapt to the best ``attention span'' while remaining\ncomputationally efficient. We propose a meta-algorithm that takes any network\narchitecture and any Online Learner (OL) algorithm as input and produces a new\nalgorithm which provably enhances the performance of the given OL under\nnon-stationarity. Our algorithm is efficient (it requires maintaining only\n$O(\\log(T))$ OL instances) and adaptive (it automatically chooses OL instances\nwith the ideal ``attention'' length at every timestamp). Experiments on various\nreal-world datasets across text and image modalities show that our method\nconsistently improves the accuracy of user specified OL algorithms for\nclassification tasks. Key novel algorithmic ingredients include a\n\\emph{multi-resolution instance} design inspired by wavelet theory and a\ncross-validation-through-time technique. Both could be of independent interest.", "published": "2025-04-09 20:34:24", "link": "http://arxiv.org/abs/2504.07261v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Resource-efficient Inference with Foundation Model Programs", "abstract": "The inference-time resource costs of large language and vision models present\na growing challenge in production deployments. We propose the use of foundation\nmodel programs, i.e., programs that can invoke foundation models with varying\nresource costs and performance, as an approach to this problem. Specifically,\nwe present a method that translates a task into a program, then learns a policy\nfor resource allocation that, on each input, selects foundation model\n\"backends\" for each program module. The policy uses smaller, cheaper backends\nto handle simpler subtasks, while allowing more complex subtasks to leverage\nlarger, more capable models. We evaluate the method on two new \"streaming\"\nvisual question-answering tasks in which a system answers a question on a\nsequence of inputs, receiving ground-truth feedback after each answer. Compared\nto monolithic multi-modal models, our implementation achieves up to 98%\nresource savings with minimal accuracy loss, demonstrating its potential for\nscalable and resource-efficient multi-modal inference.", "published": "2025-04-09 19:36:47", "link": "http://arxiv.org/abs/2504.07247v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Prototype-Based Continual Learning with Label-free Replay Buffer and Cluster Preservation Loss", "abstract": "Continual learning techniques employ simple replay sample selection processes\nand use them during subsequent tasks. Typically, they rely on labeled data. In\nthis paper, we depart from this by automatically selecting prototypes stored\nwithout labels, preserving cluster structures in the latent space across tasks.\nBy eliminating label dependence in the replay buffer and introducing cluster\npreservation loss, it is demonstrated that the proposed method can maintain\nessential information from previously encountered tasks while ensuring\nadaptation to new tasks. \"Push-away\" and \"pull-toward\" mechanisms over\npreviously learned prototypes are also introduced for class-incremental and\ndomain-incremental scenarios. These mechanisms ensure the retention of\npreviously learned information as well as adaptation to new classes or domain\nshifts. The proposed method is evaluated on several benchmarks, including\nSplitCIFAR100, SplitImageNet32, SplitTinyImageNet, and SplitCaltech256 for\nclass-incremental, as well as R-MNIST and CORe50 for domain-incremental setting\nusing pre-extracted DINOv2 features. Experimental results indicate that the\nlabel-free replay-based technique outperforms state-of-the-art continual\nlearning methods and, in some cases, even surpasses offline learning. An\nunsupervised variant of the proposed technique for the class-incremental\nsetting, avoiding labels use even on incoming data, also demonstrated\ncompetitive performance, outperforming particular supervised baselines in some\ncases. These findings underscore the effectiveness of the proposed framework in\nretaining prior information and facilitating continual adaptation.", "published": "2025-04-09 19:26:26", "link": "http://arxiv.org/abs/2504.07240v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Earth-like planet predictor: A machine learning approach", "abstract": "Searching for planets analogous to Earth in terms of mass and equilibrium\ntemperature is currently the first step in the quest for habitable conditions\noutside our Solar System and, ultimately, the search for life in the universe.\nFuture missions such as PLATO or LIFE will begin to detect and characterise\nthese small, cold planets, dedicating significant observation time to them. The\naim of this work is to predict which stars are most likely to host an\nEarth-like planet (ELP) to avoid blind searches, minimises detection times, and\nthus maximises the number of detections. Using a previous study on correlations\nbetween the presence of an ELP and the properties of its system, we trained a\nRandom Forest to recognise and classify systems as 'hosting an ELP' or 'not\nhosting an ELP'. The Random Forest was trained and tested on populations of\nsynthetic planetary systems derived from the Bern model, and then applied to\nreal observed systems. The tests conducted on the machine learning (ML) model\nyield precision scores of up to 0.99, indicating that 99% of the systems\nidentified by the model as having ELPs possess at least one. Among the few real\nobserved systems that have been tested, 44 have been selected as having a high\nprobability of hosting an ELP, and a quick study of the stability of these\nsystems confirms that the presence of an Earth-like planet within them would\nleave them stable. The excellent results obtained from the tests conducted on\nthe ML model demonstrate its ability to recognise the typical architectures of\nsystems with or without ELPs within populations derived from the Bern model. If\nwe assume that the Bern model adequately describes the architecture of real\nsystems, then such a tool can prove indispensable in the search for Earth-like\nplanets. A similar approach could be applied to other planetary system\nformation models to validate those predictions.", "published": "2025-04-09 19:21:46", "link": "http://arxiv.org/abs/2504.07235v1", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.LG"], "primary_category": "astro-ph.EP"}
{"title": "Evolutionary algorithms meet self-supervised learning: a comprehensive survey", "abstract": "The number of studies that combine Evolutionary Machine Learning and\nself-supervised learning has been growing steadily in recent years.\nEvolutionary Machine Learning has been shown to help automate the design of\nmachine learning algorithms and to lead to more reliable solutions.\nSelf-supervised learning, on the other hand, has produced good results in\nlearning useful features when labelled data is limited. This suggests that the\ncombination of these two areas can help both in shaping evolutionary processes\nand in automating the design of deep neural networks, while also reducing the\nneed for labelled data. Still, there are no detailed reviews that explain how\nEvolutionary Machine Learning and self-supervised learning can be used\ntogether. To help with this, we provide an overview of studies that bring these\nareas together. Based on this growing interest and the range of existing works,\nwe suggest a new sub-area of research, which we call Evolutionary\nSelf-Supervised Learning and introduce a taxonomy for it. Finally, we point out\nsome of the main challenges and suggest directions for future research to help\nEvolutionary Self-Supervised Learning grow and mature as a field.", "published": "2025-04-09 18:39:41", "link": "http://arxiv.org/abs/2504.07213v1", "categories": ["cs.NE", "cs.LG"], "primary_category": "cs.NE"}
{"title": "Self-organisation of common good usage and an application to Internet services", "abstract": "Natural and human-made common goods present key challenges due to their\nsusceptibility to degradation, overuse, or congestion. We explore the\nself-organisation of their usage when individuals have access to several\navailable commons but limited information on them. We propose an extension of\nthe Win-Stay, Lose-Shift (WSLS) strategy for such systems, under which\nindividuals use a resource iteratively until they are unsuccessful and then\nshift randomly. This simple strategy leads to a distribution of the use of\ncommons with an improvement against random shifting. Selective individuals who\nretain information on their usage and accordingly adapt their tolerance to\nfailure in each common good improve the average experienced quality for an\nentire population. Hybrid systems of selective and non-selective individuals\ncan lead to an equilibrium with equalised experienced quality akin to the ideal\nfree distribution. We show that these results can be applied to the server\nselection problem faced by mobile users accessing Internet services and we\nperform realistic simulations to test their validity. Furthermore, these\nfindings can be used to understand other real systems such as animal dispersal\non grazing and foraging land, and to propose solutions to operators of systems\nof public transport or other technological commons.", "published": "2025-04-09 18:00:01", "link": "http://arxiv.org/abs/2504.07175v1", "categories": ["cs.MA", "cs.GT", "cs.NI", "nlin.AO"], "primary_category": "cs.MA"}
{"title": "Multi-Object Tracking for Collision Avoidance Using Multiple Cameras in Open RAN Networks", "abstract": "This paper deals with the multi-object detection and tracking problem, within\nthe scope of open Radio Access Network (RAN), for collision avoidance in\nvehicular scenarios. To this end, a set of distributed intelligent agents\ncollocated with cameras are considered. The fusion of detected objects is done\nat an edge service, considering Open RAN connectivity. Then, the edge service\npredicts the objects trajectories for collision avoidance. Compared to the\nrelated work a more realistic Open RAN network is implemented and multiple\ncameras are used.", "published": "2025-04-09 17:36:40", "link": "http://arxiv.org/abs/2504.07163v1", "categories": ["cs.MA", "cs.LG", "cs.RO"], "primary_category": "cs.MA"}
{"title": "A Space-Time Continuous Galerkin Finite Element Method for Linear Schr\u00f6dinger Equations", "abstract": "We introduce a space-time finite element method for the linear time-dependent\nSchr\\\"odinger equation with Dirichlet conditions in a bounded Lipschitz domain.\nThe proposed discretization scheme is based on a space-time variational\nformulation of the time-dependent Schr\\\"odinger equation. In particular, the\nspace-time method is conforming and is of Galerkin-type, i.e., trial and test\nspaces are equal. We consider a tensor-product approach with respect to time\nand space, using piecewise polynomial, continuous trial and test functions. In\nthis case, we state the global linear system and efficient direct space-time\nsolvers based on exploiting the Kronecker structure of the global system\nmatrix. This leads to the Bartels-Stewart method and the fast diagonalization\nmethod. Both methods result in solving a sequence of spatial subproblems. In\nparticular, the fast diagonalization method allows for solving the spatial\nsubproblems in parallel, i.e., a time parallelization is possible. Numerical\nexamples for a two-dimensional spatial domain illustrate convergence in\nspace-time norms and show the potential of the proposed solvers.", "published": "2025-04-09 20:49:24", "link": "http://arxiv.org/abs/2504.07269v1", "categories": ["math.NA", "cs.NA", "65F05, 65M60"], "primary_category": "math.NA"}
{"title": "Application of CTS (Computer to Screen) Machine in Printing Industries for Process Improvement & Material Optimization", "abstract": "The printing and labeling industries are struggling to meet the need for more\ncomplex and dynamic design requirements coming from the customers. It is now\ncrucial to implement technological advancements to manage workflow,\nproductivity, process optimization, and continual improvement. There has never\nbeen a time when the imagery and embellishments of apparel has been more\ncommercially viable as it is now. Images and text are fused directly to fabric\nby heat transfer printing and labeling. For screen development which is\nrequired for heat transfer label mass production, many industries are still\nusing the conventional method of screen development process. A CTS\n(computer-to-screen) innovates the printing and labeling industries by\nenhancing workflow, lowering consumable consumptions and chemical usage,\nspeeding up setup, guaranteeing flawless design, and raising the print quality\nof the producing screens. The study's objective is to assess how CTS machines\nare used and how they affect existing heat transfer screen development\nprocesses in one of Bangladesh's leading printing and labeling companies. The\nstudy's primary goal is to highlight and analyze how the use of CTS machines\nreduces material and operational costs by optimizing the process. Costs for\nCapEx and OpEx are computed and compared for using CTS technology before and\nafter adoption. Savings data such as material, consumable, and operating cost\nsavings versus depreciation and machine payback period analysis were taken into\nconsideration. It is clear from this study that CTS machines in the printing\nand labeling industries can guarantee profitability on top of Capital\nExpenditures.", "published": "2025-04-09 21:37:29", "link": "http://arxiv.org/abs/2504.07294v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Enabling Continuous 5G Connectivity in Aircraft through Low Earth Orbit Satellites", "abstract": "As air travel demand increases, uninterrupted high-speed internet access\nbecomes essential. However, current satellite-based systems face latency and\nconnectivity challenges. While prior research has focused on terrestrial 5G and\ngeostationary satellites, there is a gap in optimizing Low Earth Orbit\n(LEO)-based 5G systems for aircraft. This study evaluates the feasibility of\ndeployment strategies and improving signal quality with LEO satellites for\nseamless in-flight 5G connectivity. Using Matlab and Simulink, we model\nsatellite trajectories, aircraft movement, and handover mechanisms,\ncomplemented by ray-tracing techniques for in-cabin signal analysis. Results\nshow that proposed LEO satellite configurations enhance coverage and reduce\nlatency, with sequential handovers minimizing service interruptions. These\nfindings contribute to advancing in-flight 5G networks, improving passenger\nexperience, and supporting real-time global connectivity solutions.", "published": "2025-04-09 20:35:52", "link": "http://arxiv.org/abs/2504.07262v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "SemEval-2025 Task 5: LLMs4Subjects -- LLM-based Automated Subject Tagging for a National Technical Library's Open-Access Catalog", "abstract": "We present SemEval-2025 Task 5: LLMs4Subjects, a shared task on automated\nsubject tagging for scientific and technical records in English and German\nusing the GND taxonomy. Participants developed LLM-based systems to recommend\ntop-k subjects, evaluated through quantitative metrics (precision, recall,\nF1-score) and qualitative assessments by subject specialists. Results highlight\nthe effectiveness of LLM ensembles, synthetic data generation, and multilingual\nprocessing, offering insights into applying LLMs for digital library\nclassification.", "published": "2025-04-09 18:26:46", "link": "http://arxiv.org/abs/2504.07199v2", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Holistic Capability Preservation: Towards Compact Yet Comprehensive Reasoning Models", "abstract": "This technical report presents Ring-Lite-Distill, a lightweight reasoning\nmodel derived from our open-source Mixture-of-Experts (MoE) Large Language\nModels (LLMs) Ling-Lite. This study demonstrates that through meticulous\nhigh-quality data curation and ingenious training paradigms, the compact MoE\nmodel Ling-Lite can be further trained to achieve exceptional reasoning\ncapabilities, while maintaining its parameter-efficient architecture with only\n2.75 billion activated parameters, establishing an efficient lightweight\nreasoning architecture. In particular, in constructing this model, we have not\nmerely focused on enhancing advanced reasoning capabilities, exemplified by\nhigh-difficulty mathematical problem solving, but rather aimed to develop a\nreasoning model with more comprehensive competency coverage. Our approach\nensures coverage across reasoning tasks of varying difficulty levels while\npreserving generic capabilities, such as instruction following, tool use, and\nknowledge retention. We show that, Ring-Lite-Distill's reasoning ability\nreaches a level comparable to DeepSeek-R1-Distill-Qwen-7B, while its general\ncapabilities significantly surpass those of DeepSeek-R1-Distill-Qwen-7B. The\nmodels are accessible at https://huggingface.co/inclusionAI", "published": "2025-04-09 11:24:32", "link": "http://arxiv.org/abs/2504.07158v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Are We Done with Object-Centric Learning?", "abstract": "Object-centric learning (OCL) seeks to learn representations that only encode\nan object, isolated from other objects or background cues in a scene. This\napproach underpins various aims, including out-of-distribution (OOD)\ngeneralization, sample-efficient composition, and modeling of structured\nenvironments. Most research has focused on developing unsupervised mechanisms\nthat separate objects into discrete slots in the representation space,\nevaluated using unsupervised object discovery. However, with recent\nsample-efficient segmentation models, we can separate objects in the pixel\nspace and encode them independently. This achieves remarkable zero-shot\nperformance on OOD object discovery benchmarks, is scalable to foundation\nmodels, and can handle a variable number of slots out-of-the-box. Hence, the\ngoal of OCL methods to obtain object-centric representations has been largely\nachieved. Despite this progress, a key question remains: How does the ability\nto separate objects within a scene contribute to broader OCL objectives, such\nas OOD generalization? We address this by investigating the OOD generalization\nchallenge caused by spurious background cues through the lens of OCL. We\npropose a novel, training-free probe called Object-Centric Classification with\nApplied Masks (OCCAM), demonstrating that segmentation-based encoding of\nindividual objects significantly outperforms slot-based OCL methods. However,\nchallenges in real-world applications remain. We provide the toolbox for the\nOCL community to use scalable object-centric representations, and focus on\npractical applications and fundamental questions, such as understanding object\nperception in human cognition. Our code is available here:\nhttps://github.com/AlexanderRubinstein/OCCAM.", "published": "2025-04-09 17:59:05", "link": "http://arxiv.org/abs/2504.07092v2", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "abstract": "Agents powered by Large Language Models (LLMs) have recently demonstrated\nimpressive capabilities in various tasks. Still, they face limitations in tasks\nrequiring specific, structured knowledge, flexibility, or accountable\ndecision-making. While agents are capable of perceiving their environments,\nforming inferences, planning, and executing actions towards goals, they often\nface issues such as hallucinations and lack of contextual memory across\ninteractions. This paper explores how Case-Based Reasoning (CBR), a strategy\nthat solves new problems by referencing past experiences, can be integrated\ninto LLM agent frameworks. This integration allows LLMs to leverage explicit\nknowledge, enhancing their effectiveness. We systematically review the\ntheoretical foundations of these enhanced agents, identify critical framework\ncomponents, and formulate a mathematical model for the CBR processes of case\nretrieval, adaptation, and learning. We also evaluate CBR-enhanced agents\nagainst other methods like Chain-of-Thought reasoning and standard\nRetrieval-Augmented Generation, analyzing their relative strengths. Moreover,\nwe explore how leveraging CBR's cognitive dimensions (including\nself-reflection, introspection, and curiosity) via goal-driven autonomy\nmechanisms can further enhance the LLM agent capabilities. Contributing to the\nongoing research on neuro-symbolic hybrid systems, this work posits CBR as a\nviable technique for enhancing the reasoning skills and cognitive aspects of\nautonomous LLM agents.", "published": "2025-04-09 14:51:02", "link": "http://arxiv.org/abs/2504.06943v2", "categories": ["cs.AI", "cs.MA", "68", "I.2; I.2.7"], "primary_category": "cs.AI"}
{"title": "Alice: Proactive Learning with Teacher's Demonstrations for Weak-to-Strong Generalization", "abstract": "The growing capabilities of large language models (LLMs) present a key\nchallenge of maintaining effective human oversight. Weak-to-strong\ngeneralization (W2SG) offers a promising framework for supervising increasingly\ncapable LLMs using weaker ones. Traditional W2SG methods rely on passive\nlearning, where a weak teacher provides noisy demonstrations to train a strong\nstudent. This hinders students from employing their knowledge during training\nand reaching their full potential. In this work, we introduce Alice\n(pro{A}ctive {l}earning w{i}th tea{c}her's D{e}monstrations), a framework that\nleverages complementary knowledge between teacher and student to enhance the\nlearning process. We probe the knowledge base of the teacher model by eliciting\ntheir uncertainty, and then use these insights together with teachers'\nresponses as demonstrations to guide student models in self-generating improved\nresponses for supervision. In addition, for situations with significant\ncapability gaps between teacher and student models, we introduce cascade Alice,\nwhich employs a hierarchical training approach where weak teachers initially\nsupervise intermediate models, who then guide stronger models in sequence.\nExperimental results demonstrate that our method significantly enhances the\nW2SG performance, yielding substantial improvements in three key tasks compared\nto the original W2SG: knowledge-based reasoning (+4.0%), mathematical reasoning\n(+22.62%), and logical reasoning (+12.11%). This highlights the effectiveness\nof our new W2SG paradigm that enables more robust knowledge transfer and\nsupervision outcome.", "published": "2025-04-09 22:33:06", "link": "http://arxiv.org/abs/2504.07316v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GLT hidden structures in mean-field quantum spin systems", "abstract": "This work explores structured matrix sequences arising in mean-field quantum\nspin systems. We express these sequences within the framework of generalized\nlocally Toeplitz (GLT) $*$-algebras, leveraging the fact that each GLT matrix\nsequence has a unique GLT symbol. This symbol characterizes both the asymptotic\nsingular value distribution and, for Hermitian or quasi-Hermitian sequences,\nthe asymptotic spectral distribution. Specifically, we analyze two cases of\nreal symmetric matrix sequences stemming from mean-field quantum spin systems\nand determine their associated distributions using GLT theory. Our study\nconcludes with visualizations and numerical tests that validate the theoretical\nfindings, followed by a discussion of open problems and future directions.", "published": "2025-04-09 14:58:31", "link": "http://arxiv.org/abs/2504.06951v2", "categories": ["quant-ph", "cs.NA", "math.NA", "46L65, 15B05, 15A18 (81R30, 82B20)"], "primary_category": "quant-ph"}
{"title": "The Exploratory Study on the Relationship Between the Failure of Distance Metrics in High-Dimensional Space and Emergent Phenomena", "abstract": "This paper presents a unified framework, integrating information theory and\nstatistical mechanics, to connect metric failure in high-dimensional data with\nemergence in complex systems. We propose the \"Information Dilution Theorem,\"\ndemonstrating that as dimensionality ($d$) increases, the mutual information\nefficiency between geometric metrics (e.g., Euclidean distance) and system\nstates decays approximately as $O(1/d)$. This decay arises from the mismatch\nbetween linearly growing system entropy and sublinearly growing metric entropy,\nexplaining the mechanism behind distance concentration. Building on this, we\nintroduce information structural complexity ($C(S)$) based on the mutual\ninformation matrix spectrum and interaction encoding capacity ($C'$) derived\nfrom information bottleneck theory. The \"Emergence Critical Theorem\" states\nthat when $C(S)$ exceeds $C'$, new global features inevitably emerge,\nsatisfying a predefined mutual information threshold. This provides an\noperational criterion for self-organization and phase transitions. We discuss\npotential applications in physics, biology, and deep learning, suggesting\npotential directions like MI-based manifold learning (UMAP+) and offering a\nquantitative foundation for analyzing emergence across disciplines.", "published": "2025-04-09 02:19:58", "link": "http://arxiv.org/abs/2504.08807v1", "categories": ["cs.IT", "cond-mat.stat-mech", "math.IT", "nlin.AO"], "primary_category": "cs.IT"}
{"title": "Probabilistic QoS Metric Forecasting in Delay-Tolerant Networks Using Conditional Diffusion Models on Latent Dynamics", "abstract": "Active QoS metric prediction, commonly employed in the maintenance and\noperation of DTN, could enhance network performance regarding latency,\nthroughput, energy consumption, and dependability. Naturally formulated as a\nmultivariate time series forecasting problem, it attracts substantial research\nefforts. Traditional mean regression methods for time series forecasting cannot\ncapture the data complexity adequately, resulting in deteriorated performance\nin operational tasks in DTNs such as routing. This paper formulates the\nprediction of QoS metrics in DTN as a probabilistic forecasting problem on\nmultivariate time series, where one could quantify the uncertainty of forecasts\nby characterizing the distribution of these samples. The proposed approach\nhires diffusion models and incorporates the latent temporal dynamics of\nnon-stationary and multi-mode data into them. Extensive experiments demonstrate\nthe efficacy of the proposed approach by showing that it outperforms the\npopular probabilistic time series forecasting methods.", "published": "2025-04-09 15:40:02", "link": "http://arxiv.org/abs/2504.08821v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "CAFA: a Controllable Automatic Foley Artist", "abstract": "Foley is a key element in video production, refers to the process of adding\nan audio signal to a silent video while ensuring semantic and temporal\nalignment. In recent years, the rise of personalized content creation and\nadvancements in automatic video-to-audio models have increased the demand for\ngreater user control in the process. One possible approach is to incorporate\ntext to guide audio generation. While supported by existing methods, challenges\nremain in ensuring compatibility between modalities, particularly when the text\nintroduces additional information or contradicts the sounds naturally inferred\nfrom the visuals. In this work, we introduce CAFA (Controllable Automatic Foley\nArtist) a video-and-text-to-audio model that generates semantically and\ntemporally aligned audio for a given video, guided by text input. CAFA is built\nupon a text-to-audio model and integrates video information through a modality\nadapter mechanism. By incorporating text, users can refine semantic details and\nintroduce creative variations, guiding the audio synthesis beyond the expected\nvideo contextual cues. Experiments show that besides its superior quality in\nterms of semantic alignment and audio-visual synchronization the proposed\nmethod enable high textual controllability as demonstrated in subjective and\nobjective evaluations.", "published": "2025-04-09 10:58:54", "link": "http://arxiv.org/abs/2504.06778v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
