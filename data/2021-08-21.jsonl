{"title": "Yseop at FinSim-3 Shared Task 2021: Specializing Financial Domain\n  Learning with Phrase Representations", "abstract": "In this paper, we present our approaches for the FinSim-3 Shared Task 2021:\nLearning Semantic Similarities for the Financial Domain. The aim of this shared\ntask is to correctly classify a list of given terms from the financial domain\ninto the most relevant hypernym (or top-level) concept in an external ontology.\nFor our system submission, we evaluate two methods: a Sentence-RoBERTa\n(SRoBERTa) embeddings model pre-trained on a custom corpus, and a dual\nword-sentence embeddings model that builds on the first method by improving the\nproposed baseline word embeddings construction using the FastText model to\nboost the classification performance. Our system ranks 2nd overall on both\nmetrics, scoring 0.917 on Average Accuracy and 1.141 on Mean Rank.", "published": "2021-08-21 10:53:12", "link": "http://arxiv.org/abs/2108.09485v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Metric Learning in Multilingual Sentence Similarity Measurement for\n  Document Alignment", "abstract": "Document alignment techniques based on multilingual sentence representations\nhave recently shown state of the art results. However, these techniques rely on\nunsupervised distance measurement techniques, which cannot be fined-tuned to\nthe task at hand. In this paper, instead of these unsupervised distance\nmeasurement techniques, we employ Metric Learning to derive task-specific\ndistance measurements. These measurements are supervised, meaning that the\ndistance measurement metric is trained using a parallel dataset. Using a\ndataset belonging to English, Sinhala, and Tamil, which belong to three\ndifferent language families, we show that these task-specific supervised\ndistance learning metrics outperform their unsupervised counterparts, for\ndocument alignment.", "published": "2021-08-21 11:48:31", "link": "http://arxiv.org/abs/2108.09495v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Hierarchical Entity Graph Convolutional Network for Relation\n  Extraction across Documents", "abstract": "Distantly supervised datasets for relation extraction mostly focus on\nsentence-level extraction, and they cover very few relations. In this work, we\npropose cross-document relation extraction, where the two entities of a\nrelation tuple appear in two different documents that are connected via a chain\nof common entities. Following this idea, we create a dataset for two-hop\nrelation extraction, where each chain contains exactly two documents. Our\nproposed dataset covers a higher number of relations than the publicly\navailable sentence-level datasets. We also propose a hierarchical entity graph\nconvolutional network (HEGCN) model for this task that improves performance by\n1.1\\% F1 score on our two-hop relation extraction dataset, compared to some\nstrong neural baselines.", "published": "2021-08-21 12:33:50", "link": "http://arxiv.org/abs/2108.09505v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Cute is Pikachu? Gathering and Ranking Pok\u00e9mon Properties from\n  Data with Pok\u00e9mon Word Embeddings", "abstract": "We present different methods for obtaining descriptive properties\nautomatically for the 151 original Pok\\'emon. We train several different word\nembeddings models on a crawled Pok\\'emon corpus, and use them to rank\nautomatically English adjectives based on how characteristic they are to a\ngiven Pok\\'emon. Based on our experiments, it is better to train a model with\ndomain specific data than to use a pretrained model. Word2Vec produces less\nnoise in the results than fastText model. Furthermore, we expand the list of\nproperties for each Pok\\'emon automatically. However, none of the methods is\nspot on and there is a considerable amount of noise in the different semantic\nmodels. Our models have been released on Zenodo.", "published": "2021-08-21 16:52:09", "link": "http://arxiv.org/abs/2108.09546v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "2020 U.S. presidential election in swing states: Gender differences in\n  Twitter conversations", "abstract": "Social media is commonly used by the public during election campaigns to\nexpress their opinions regarding different issues. Among various social media\nchannels, Twitter provides an efficient platform for researchers and\npoliticians to explore public opinion regarding a wide range of topics such as\nthe economy and foreign policy. Current literature mainly focuses on analyzing\nthe content of tweets without considering the gender of users. This research\ncollects and analyzes a large number of tweets and uses computational, human\ncoding, and statistical analyses to identify topics in more than 300,000 tweets\nposted during the 2020 U.S. presidential election and to compare female and\nmale users regarding the average weight of the discussed topics. Our findings\nare based upon a wide range of topics, such as tax, climate change, and the\nCOVID-19 pandemic. Out of the topics, there exists a significant difference\nbetween female and male users for more than 70% of topics.", "published": "2021-08-21 01:31:03", "link": "http://arxiv.org/abs/2108.09416v2", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Hierarchical Summarization for Longform Spoken Dialog", "abstract": "Every day we are surrounded by spoken dialog. This medium delivers rich\ndiverse streams of information auditorily; however, systematically\nunderstanding dialog can often be non-trivial. Despite the pervasiveness of\nspoken dialog, automated speech understanding and quality information\nextraction remains markedly poor, especially when compared to written prose.\nFurthermore, compared to understanding text, auditory communication poses many\nadditional challenges such as speaker disfluencies, informal prose styles, and\nlack of structure. These concerns all demonstrate the need for a distinctly\nspeech tailored interactive system to help users understand and navigate the\nspoken language domain. While individual automatic speech recognition (ASR) and\ntext summarization methods already exist, they are imperfect technologies;\nneither consider user purpose and intent nor address spoken language induced\ncomplications. Consequently, we design a two stage ASR and text summarization\npipeline and propose a set of semantic segmentation and merging algorithms to\nresolve these speech modeling challenges. Our system enables users to easily\nbrowse and navigate content as well as recover from errors in these underlying\ntechnologies. Finally, we present an evaluation of the system which highlights\nuser preference for hierarchical summarization as a tool to quickly skim audio\nand identify content of interest to the user.", "published": "2021-08-21 23:31:31", "link": "http://arxiv.org/abs/2108.09597v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BoundaryNet: An Attentive Deep Network with Fast Marching Distance Maps\n  for Semi-automatic Layout Annotation", "abstract": "Precise boundary annotations of image regions can be crucial for downstream\napplications which rely on region-class semantics. Some document collections\ncontain densely laid out, highly irregular and overlapping multi-class region\ninstances with large range in aspect ratio. Fully automatic boundary estimation\napproaches tend to be data intensive, cannot handle variable-sized images and\nproduce sub-optimal results for aforementioned images. To address these issues,\nwe propose BoundaryNet, a novel resizing-free approach for high-precision\nsemi-automatic layout annotation. The variable-sized user selected region of\ninterest is first processed by an attention-guided skip network. The network\noptimization is guided via Fast Marching distance maps to obtain a good quality\ninitial boundary estimate and an associated feature representation. These\noutputs are processed by a Residual Graph Convolution Network optimized using\nHausdorff loss to obtain the final region boundary. Results on a challenging\nimage manuscript dataset demonstrate that BoundaryNet outperforms strong\nbaselines and produces high-quality semantic region boundaries. Qualitatively,\nour approach generalizes across multiple document image datasets containing\ndifferent script systems and layouts, all without additional fine-tuning. We\nintegrate BoundaryNet into a document annotation system and show that it\nprovides high annotation throughput compared to manual and fully automatic\nalternatives.", "published": "2021-08-21 04:24:00", "link": "http://arxiv.org/abs/2108.09433v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Palmira: A Deep Deformable Network for Instance Segmentation of Dense\n  and Uneven Layouts in Handwritten Manuscripts", "abstract": "Handwritten documents are often characterized by dense and uneven layout.\nDespite advances, standard deep network based approaches for semantic layout\nsegmentation are not robust to complex deformations seen across semantic\nregions. This phenomenon is especially pronounced for the low-resource Indic\npalm-leaf manuscript domain. To address the issue, we first introduce\nIndiscapes2, a new large-scale diverse dataset of Indic manuscripts with\nsemantic layout annotations. Indiscapes2 contains documents from four different\nhistorical collections and is 150% larger than its predecessor, Indiscapes. We\nalso propose a novel deep network Palmira for robust, deformation-aware\ninstance segmentation of regions in handwritten manuscripts. We also report\nHausdorff distance and its variants as a boundary-aware performance measure.\nOur experiments demonstrate that Palmira provides robust layouts, outperforms\nstrong baseline approaches and ablative variants. We also include qualitative\nresults on Arabic, South-East Asian and Hebrew historical manuscripts to\nshowcase the generalization capability of Palmira.", "published": "2021-08-21 04:41:46", "link": "http://arxiv.org/abs/2108.09436v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Grid-VLP: Revisiting Grid Features for Vision-Language Pre-training", "abstract": "Existing approaches to vision-language pre-training (VLP) heavily rely on an\nobject detector based on bounding boxes (regions), where salient objects are\nfirst detected from images and then a Transformer-based model is used for\ncross-modal fusion. Despite their superior performance, these approaches are\nbounded by the capability of the object detector in terms of both effectiveness\nand efficiency. Besides, the presence of object detection imposes unnecessary\nconstraints on model designs and makes it difficult to support end-to-end\ntraining. In this paper, we revisit grid-based convolutional features for\nvision-language pre-training, skipping the expensive region-related steps. We\npropose a simple yet effective grid-based VLP method that works surprisingly\nwell with the grid features. By pre-training only with in-domain datasets, the\nproposed Grid-VLP method can outperform most competitive region-based VLP\nmethods on three examined vision-language understanding tasks. We hope that our\nfindings help to further advance the state of the art of vision-language\npre-training, and provide a new direction towards effective and efficient VLP.", "published": "2021-08-21 09:57:21", "link": "http://arxiv.org/abs/2108.09479v1", "categories": ["cs.MM", "cs.CL", "cs.CV"], "primary_category": "cs.MM"}
{"title": "cushLEPOR: customising hLEPOR metric using Optuna for higher agreement\n  with human judgments or pre-trained language model LaBSE", "abstract": "Human evaluation has always been expensive while researchers struggle to\ntrust the automatic metrics. To address this, we propose to customise\ntraditional metrics by taking advantages of the pre-trained language models\n(PLMs) and the limited available human labelled scores. We first re-introduce\nthe hLEPOR metric factors, followed by the Python version we developed (ported)\nwhich achieved the automatic tuning of the weighting parameters in hLEPOR\nmetric. Then we present the customised hLEPOR (cushLEPOR) which uses Optuna\nhyper-parameter optimisation framework to fine-tune hLEPOR weighting parameters\ntowards better agreement to pre-trained language models (using LaBSE) regarding\nthe exact MT language pairs that cushLEPOR is deployed to. We also optimise\ncushLEPOR towards professional human evaluation data based on MQM and pSQM\nframework on English-German and Chinese-English language pairs. The\nexperimental investigations show cushLEPOR boosts hLEPOR performances towards\nbetter agreements to PLMs like LaBSE with much lower cost, and better\nagreements to human evaluations including MQM and pSQM scores, and yields much\nbetter performances than BLEU (data available at\n\\url{https://github.com/poethan/cushLEPOR}). Official results show that our\nsubmissions win three language pairs including \\textbf{English-German} and\n\\textbf{Chinese-English} on \\textit{News} domain via cushLEPOR(LM) and\n\\textbf{English-Russian} on \\textit{TED} domain via hLEPOR.", "published": "2021-08-21 10:21:21", "link": "http://arxiv.org/abs/2108.09484v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Curricular SincNet: Towards Robust Deep Speaker Recognition by\n  Emphasizing Hard Samples in Latent Space", "abstract": "Deep learning models have become an increasingly preferred option for\nbiometric recognition systems, such as speaker recognition. SincNet, a deep\nneural network architecture, gained popularity in speaker recognition tasks due\nto its parameterized sinc functions that allow it to work directly on the\nspeech signal. The original SincNet architecture uses the softmax loss, which\nmay not be the most suitable choice for recognition-based tasks. Such loss\nfunctions do not impose inter-class margins nor differentiate between easy and\nhard training samples. Curriculum learning, particularly those leveraging\nangular margin-based losses, has proven very successful in other biometric\napplications such as face recognition. The advantage of such a curriculum\nlearning-based techniques is that it will impose inter-class margins as well as\ntaking to account easy and hard samples. In this paper, we propose Curricular\nSincNet (CL-SincNet), an improved SincNet model where we use a curricular loss\nfunction to train the SincNet architecture. The proposed model is evaluated on\nmultiple datasets using intra-dataset and inter-dataset evaluation protocols.\nIn both settings, the model performs competitively with other previously\npublished work. In the case of inter-dataset testing, it achieves the best\noverall results with a reduction of 4\\% error rate compare to SincNet and other\npublished work.", "published": "2021-08-21 09:13:45", "link": "http://arxiv.org/abs/2108.10714v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
