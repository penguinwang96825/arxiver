{"title": "English-Czech Systems in WMT19: Document-Level Transformer", "abstract": "We describe our NMT systems submitted to the WMT19 shared task in\nEnglish-Czech news translation. Our systems are based on the Transformer model\nimplemented in either Tensor2Tensor (T2T) or Marian framework.\n  We aimed at improving the adequacy and coherence of translated documents by\nenlarging the context of the source and target. Instead of translating each\nsentence independently, we split the document into possibly overlapping\nmulti-sentence segments. In case of the T2T implementation, this\n\"document-level\"-trained system achieves a $+0.6$ BLEU improvement ($p<0.05$)\nrelative to the same system applied on isolated sentences. To assess the\npotential effect document-level models might have on lexical coherence, we\nperformed a semi-automatic analysis, which revealed only a few sentences\nimproved in this aspect. Thus, we cannot draw any conclusions from this weak\nevidence.", "published": "2019-07-30 06:17:19", "link": "http://arxiv.org/abs/1907.12750v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IPRE: a Dataset for Inter-Personal Relationship Extraction", "abstract": "Inter-personal relationship is the basis of human society. In order to\nautomatically identify the relations between persons from texts, we need\nannotated data for training systems. However, there is a lack of a massive\namount of such data so far. To address this situation, we introduce IPRE, a new\ndataset for inter-personal relationship extraction which aims to facilitate\ninformation extraction and knowledge graph construction research. In total,\nIPRE has over 41,000 labeled sentences for 34 types of relations, including\nabout 9,000 sentences annotated by workers. Our data is the first dataset for\ninter-personal relationship extraction. Additionally, we define three\nevaluation tasks based on IPRE and provide the baseline systems for further\ncomparison in future work.", "published": "2019-07-30 09:33:13", "link": "http://arxiv.org/abs/1907.12801v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Confirmatory Aspect-based Opinion Mining Processes", "abstract": "A new opinion extraction method is proposed to summarize unstructured,\nuser-generated content (i.e., online customer reviews) in the fixed topic\ndomains. To differentiate the current approach from other opinion extraction\napproaches, which are often exposed to a sparsity problem and lack of sentiment\nscores, a confirmatory aspect-based opinion mining framework is introduced\nalong with its practical algorithm called DiSSBUS. In this procedure, 1) each\ncustomer review is disintegrated into a set of clauses; 2) each clause is\nsummarized to bi-terms-a topic word and an evaluation word-using a\npart-of-speech (POS) tagger; and 3) each bi-term is matched to a pre-specified\ntopic relevant to a specific domain. The proposed processes have two primary\nadvantages over existing methods: 1) they can decompose a single review into a\nset of bi-terms related to pre-specified topics in the domain of interest and,\ntherefore, 2) allow identification of the reviewer's opinions on the topics via\nevaluation words within the set of bi-terms. The proposed aspect-based opinion\nmining is applied to customer reviews of restaurants in Hawaii obtained from\nTripAdvisor, and the empirical findings validate the effectiveness of the\nmethod.\n  Keywords: Clause-based sentiment analysis, Customer review, Opinion mining,\nTopic modeling, User-generate-contents.", "published": "2019-07-30 12:00:03", "link": "http://arxiv.org/abs/1907.12850v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Retrieval-Based Dialogue Systems: A Short Review", "abstract": "Building dialogue systems that naturally converse with humans is being an\nattractive and an active research domain. Multiple systems are being designed\neveryday and several datasets are being available. For this reason, it is being\nhard to keep an up-to-date state-of-the-art. In this work, we present the\nlatest and most relevant retrieval-based dialogue systems and the available\ndatasets used to build and evaluate them. We discuss their limitations and\nprovide insights and guidelines for future work.", "published": "2019-07-30 13:16:18", "link": "http://arxiv.org/abs/1907.12878v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-shot transfer for implicit discourse relation classification", "abstract": "Automatically classifying the relation between sentences in a discourse is a\nchallenging task, in particular when there is no overt expression of the\nrelation. It becomes even more challenging by the fact that annotated training\ndata exists only for a small number of languages, such as English and Chinese.\nWe present a new system using zero-shot transfer learning for implicit\ndiscourse relation classification, where the only resource used for the target\nlanguage is unannotated parallel text. This system is evaluated on the\ndiscourse-annotated TED-MDB parallel corpus, where it obtains good results for\nall seven languages using only English training data.", "published": "2019-07-30 13:23:01", "link": "http://arxiv.org/abs/1907.12885v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MaSS: A Large and Clean Multilingual Corpus of Sentence-aligned Spoken\n  Utterances Extracted from the Bible", "abstract": "The CMU Wilderness Multilingual Speech Dataset (Black, 2019) is a newly\npublished multilingual speech dataset based on recorded readings of the New\nTestament. It provides data to build Automatic Speech Recognition (ASR) and\nText-to-Speech (TTS) models for potentially 700 languages. However, the fact\nthat the source content (the Bible) is the same for all the languages is not\nexploited to date.Therefore, this article proposes to add multilingual links\nbetween speech segments in different languages, and shares a large and clean\ndataset of 8,130 parallel spoken utterances across 8 languages (56 language\npairs). We name this corpus MaSS (Multilingual corpus of Sentence-aligned\nSpoken utterances). The covered languages (Basque, English, Finnish, French,\nHungarian, Romanian, Russian and Spanish) allow researches on speech-to-speech\nalignment as well as on translation for typologically different language pairs.\nThe quality of the final corpus is attested by human evaluation performed on a\ncorpus subset (100 utterances, 8 language pairs). Lastly, we showcase the\nusefulness of the final product on a bilingual speech retrieval task.", "published": "2019-07-30 13:31:49", "link": "http://arxiv.org/abs/1907.12895v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Abstractive Document Summarization without Parallel Data", "abstract": "Abstractive summarization typically relies on large collections of paired\narticles and summaries. However, in many cases, parallel data is scarce and\ncostly to obtain. We develop an abstractive summarization system that relies\nonly on large collections of example summaries and non-matching articles. Our\napproach consists of an unsupervised sentence extractor that selects salient\nsentences to include in the final summary, as well as a sentence abstractor\nthat is trained on pseudo-parallel and synthetic data, that paraphrases each of\nthe extracted sentences. We perform an extensive evaluation of our method: on\nthe CNN/DailyMail benchmark, on which we compare our approach to fully\nsupervised baselines, as well as on the novel task of automatically generating\na press release from a scientific journal article, which is well suited for our\nsystem. We show promising performance on both tasks, without relying on any\narticle-summary pairs.", "published": "2019-07-30 14:00:03", "link": "http://arxiv.org/abs/1907.12951v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DuTongChuan: Context-aware Translation Model for Simultaneous\n  Interpreting", "abstract": "In this paper, we present DuTongChuan, a novel context-aware translation\nmodel for simultaneous interpreting. This model allows to constantly read\nstreaming text from the Automatic Speech Recognition (ASR) model and\nsimultaneously determine the boundaries of Information Units (IUs) one after\nanother. The detected IU is then translated into a fluent translation with two\nsimple yet effective decoding strategies: partial decoding and context-aware\ndecoding. In practice, by controlling the granularity of IUs and the size of\nthe context, we can get a good trade-off between latency and translation\nquality easily. Elaborate evaluation from human translators reveals that our\nsystem achieves promising translation quality (85.71% for Chinese-English, and\n86.36% for English-Chinese), specially in the sense of surprisingly good\ndiscourse coherence. According to an End-to-End (speech-to-speech simultaneous\ninterpreting) evaluation, this model presents impressive performance in\nreducing latency (to less than 3 seconds at most times). Furthermore, we\nsuccessfully deploy this model in a variety of Baidu's products which have\nhundreds of millions of users, and we release it as a service in our AI\nplatform.", "published": "2019-07-30 14:35:06", "link": "http://arxiv.org/abs/1907.12984v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Finding Moments in Video Collections Using Natural Language", "abstract": "We introduce the task of retrieving relevant video moments from a large\ncorpus of untrimmed, unsegmented videos given a natural language query. Our\ntask poses unique challenges as a system must efficiently identify both the\nrelevant videos and localize the relevant moments in the videos. To address\nthese challenges, we propose SpatioTemporal Alignment with Language (STAL), a\nmodel that represents a video moment as a set of regions within a series of\nshort video clips and aligns a natural language query to the moment's regions.\nOur alignment cost compares variable-length language and video features using\nsymmetric squared Chamfer distance, which allows for efficient indexing and\nretrieval of the video moments. Moreover, aligning language features to regions\nwithin a video moment allows for finer alignment compared to methods that\nextract only an aggregate feature from the entire video moment. We evaluate our\napproach on two recently proposed datasets for temporal localization of moments\nin video with natural language (DiDeMo and Charades-STA) extended to our video\ncorpus moment retrieval setting. We show that our STAL re-ranking model\noutperforms the recently proposed Moment Context Network on all criteria across\nall datasets on our proposed task, obtaining relative gains of 37% - 118% for\naverage recall and up to 30% for median rank. Moreover, our approach achieves\nmore than 130x faster retrieval and 8x smaller index size with a 1M video\ncorpus in an approximate setting.", "published": "2019-07-30 07:31:02", "link": "http://arxiv.org/abs/1907.12763v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Reward Learning for Efficient Reinforcement Learning in Extractive\n  Document Summarisation", "abstract": "Document summarisation can be formulated as a sequential decision-making\nproblem, which can be solved by Reinforcement Learning (RL) algorithms. The\npredominant RL paradigm for summarisation learns a cross-input policy, which\nrequires considerable time, data and parameter tuning due to the huge search\nspaces and the delayed rewards. Learning input-specific RL policies is a more\nefficient alternative but so far depends on handcrafted rewards, which are\ndifficult to design and yield poor performance. We propose RELIS, a novel RL\nparadigm that learns a reward function with Learning-to-Rank (L2R) algorithms\nat training time and uses this reward function to train an input-specific RL\npolicy at test time. We prove that RELIS guarantees to generate near-optimal\nsummaries with appropriate L2R and RL algorithms. Empirically, we evaluate our\napproach on extractive multi-document summarisation. We show that RELIS reduces\nthe training time by two orders of magnitude compared to the state-of-the-art\nmodels while performing on par with them.", "published": "2019-07-30 13:31:07", "link": "http://arxiv.org/abs/1907.12894v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SenseFitting: Sense Level Semantic Specialization of Word Embeddings for\n  Word Sense Disambiguation", "abstract": "We introduce a neural network-based system of Word Sense Disambiguation (WSD)\nfor German that is based on SenseFitting, a novel method for optimizing WSD. We\noutperform knowledge-based WSD methods by up to 25% F1-score and produce a new\nstate-of-the-art on the German sense-annotated dataset WebCAGe. Our method uses\nthree feature vectors consisting of a) sense, b) gloss, and c) relational\nvectors to represent target senses and to compare them with the vector\ncentroids of sample contexts. Utilizing widely available word embeddings and\nlexical resources, we are able to compensate for the lower resource\navailability of German. SenseFitting builds upon the recently introduced\nsemantic specialization procedure Attract-Repel, and leverages sense level\nsemantic constraints from lexical-semantic networks (e.g. GermaNet) or online\nsocial dictionaries (e.g. Wiktionary) to produce high-quality sense embeddings\nfrom pre-trained word embeddings. We evaluate our sense embeddings with a new\nSimLex-999 based similarity dataset, called SimSense, that we developed for\nthis work. We achieve results that outperform current lemma-based\nspecialization methods for German, making them comparable to results achieved\nfor English.", "published": "2019-07-30 21:38:16", "link": "http://arxiv.org/abs/1907.13237v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dual-FOFE-net Neural Models for Entity Linking with PageRank", "abstract": "This paper presents a simple and computationally efficient approach for\nentity linking (EL), compared with recurrent neural networks (RNNs) or\nconvolutional neural networks (CNNs), by making use of feedforward neural\nnetworks (FFNNs) and the recent dual fixed-size ordinally forgetting encoding\n(dual-FOFE) method to fully encode the sentence fragment and its left/right\ncontexts into a fixed-size representation. Furthermore, in this work, we\npropose to incorporate PageRank based distillation in our candidate generation\nmodule. Our neural linking models consist of three parts: a PageRank based\ncandidate generation module, a dual-FOFE-net neural ranking model and a simple\nNIL entity clustering system. Experimental results have shown that our proposed\nneural linking models achieved higher EL accuracy than state-of-the-art models\non the TAC2016 task dataset over the baseline system, without requiring any\nin-house data or complicated handcrafted features. Moreover, it achieves a\ncompetitive accuracy on the TAC2017 task dataset.", "published": "2019-07-30 01:37:34", "link": "http://arxiv.org/abs/1907.12697v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Marine Mammal Species Classification using Convolutional Neural Networks\n  and a Novel Acoustic Representation", "abstract": "Research into automated systems for detecting and classifying marine mammals\nin acoustic recordings is expanding internationally due to the necessity to\nanalyze large collections of data for conservation purposes. In this work, we\npresent a Convolutional Neural Network that is capable of classifying the\nvocalizations of three species of whales, non-biological sources of noise, and\na fifth class pertaining to ambient noise. In this way, the classifier is\ncapable of detecting the presence and absence of whale vocalizations in an\nacoustic recording. Through transfer learning, we show that the classifier is\ncapable of learning high-level representations and can generalize to additional\nspecies. We also propose a novel representation of acoustic signals that builds\nupon the commonly used spectrogram representation by way of interpolating and\nstacking multiple spectrograms produced using different Short-time Fourier\nTransform (STFT) parameters. The proposed representation is particularly\neffective for the task of marine mammal species classification where the\nacoustic events we are attempting to classify are sensitive to the parameters\nof the STFT.", "published": "2019-07-30 19:17:41", "link": "http://arxiv.org/abs/1907.13188v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
