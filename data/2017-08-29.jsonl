{"title": "Really? Well. Apparently Bootstrapping Improves the Performance of\n  Sarcasm and Nastiness Classifiers for Online Dialogue", "abstract": "More and more of the information on the web is dialogic, from Facebook\nnewsfeeds, to forum conversations, to comment threads on news articles. In\ncontrast to traditional, monologic Natural Language Processing resources such\nas news, highly social dialogue is frequent in social media, making it a\nchallenging context for NLP. This paper tests a bootstrapping method,\noriginally proposed in a monologic domain, to train classifiers to identify two\ndifferent types of subjective language in dialogue: sarcasm and nastiness. We\nexplore two methods of developing linguistic indicators to be used in a first\nlevel classifier aimed at maximizing precision at the expense of recall. The\nbest performing classifier for the first phase achieves 54% precision and 38%\nrecall for sarcastic utterances. We then use general syntactic patterns from\nprevious work to create more general sarcasm indicators, improving precision to\n62% and recall to 52%. To further test the generality of the method, we then\napply it to bootstrapping a classifier for nastiness dialogic acts. Our first\nphase, using crowdsourced nasty indicators, achieves 58% precision and 49%\nrecall, which increases to 75% precision and 62% recall when we bootstrap over\nthe first level with generalized syntactic patterns.", "published": "2017-08-29 02:05:14", "link": "http://arxiv.org/abs/1708.08572v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Different Story Tellings from Semantic Representations of\n  Narrative", "abstract": "In order to tell stories in different voices for different audiences,\ninteractive story systems require: (1) a semantic representation of story\nstructure, and (2) the ability to automatically generate story and dialogue\nfrom this semantic representation using some form of Natural Language\nGeneration (NLG). However, there has been limited research on methods for\nlinking story structures to narrative descriptions of scenes and story events.\nIn this paper we present an automatic method for converting from Scheherazade's\nstory intention graph, a semantic representation, to the input required by the\nPersonage NLG engine. Using 36 Aesop Fables distributed in DramaBank, a\ncollection of story encodings, we train translation rules on one story and then\ntest these rules by generating text for the remaining 35. The results are\nmeasured in terms of the string similarity metrics Levenshtein Distance and\nBLEU score. The results show that we can generate the 35 stories with correct\ncontent: the test set stories on average are close to the output of the\nScheherazade realizer, which was customized to this semantic representation. We\nprovide some examples of story variations generated by personage. In future\nwork, we will experiment with measuring the quality of the same stories\ngenerated in different voices, and with techniques for making storytelling\ninteractive.", "published": "2017-08-29 02:05:56", "link": "http://arxiv.org/abs/1708.08573v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Subjective and Figurative Language in Online Dialogue", "abstract": "More and more of the information on the web is dialogic, from Facebook\nnewsfeeds, to forum conversations, to comment threads on news articles. In\ncontrast to traditional, monologic resources such as news, highly social\ndialogue is very frequent in social media. We aim to automatically identify\nsarcastic and nasty utterances in unannotated online dialogue, extending a\nbootstrapping method previously applied to the classification of monologic\nsubjective sentences in Riloff and Weibe 2003. We have adapted the method to\nfit the sarcastic and nasty dialogic domain. Our method is as follows: 1)\nExplore methods for identifying sarcastic and nasty cue words and phrases in\ndialogues; 2) Use the learned cues to train a sarcastic (nasty) Cue-Based\nClassifier; 3) Learn general syntactic extraction patterns from the sarcastic\n(nasty) utterances and define fine-tuned sarcastic patterns to create a\nPattern-Based Classifier; 4) Combine both Cue-Based and fine-tuned\nPattern-Based Classifiers to maximize precision at the expense of recall and\ntest on unannotated utterances.", "published": "2017-08-29 02:21:48", "link": "http://arxiv.org/abs/1708.08575v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Sentence Planning Variations for Story Telling", "abstract": "There has been a recent explosion in applications for dialogue interaction\nranging from direction-giving and tourist information to interactive story\nsystems. Yet the natural language generation (NLG) component for many of these\nsystems remains largely handcrafted. This limitation greatly restricts the\nrange of applications; it also means that it is impossible to take advantage of\nrecent work in expressive and statistical language generation that can\ndynamically and automatically produce a large number of variations of given\ncontent. We propose that a solution to this problem lies in new methods for\ndeveloping language generation resources. We describe the ES-Translator, a\ncomputational language generator that has previously been applied only to\nfables, and quantitatively evaluate the domain independence of the EST by\napplying it to personal narratives from weblogs. We then take advantage of\nrecent work on language generation to create a parameterized sentence planner\nfor story generation that provides aggregation operations, variations in\ndiscourse and in point of view. Finally, we present a user evaluation of\ndifferent personal narrative retellings.", "published": "2017-08-29 03:11:20", "link": "http://arxiv.org/abs/1708.08580v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Narrative Variations in a Virtual Storyteller", "abstract": "Research on storytelling over the last 100 years has distinguished at least\ntwo levels of narrative representation (1) story, or fabula; and (2) discourse,\nor sujhet. We use this distinction to create Fabula Tales, a computational\nframework for a virtual storyteller that can tell the same story in different\nways through the implementation of general narratological variations, such as\nvarying direct vs. indirect speech, character voice (style), point of view, and\nfocalization. A strength of our computational framework is that it is based on\nvery general methods for re-using existing story content, either from fables or\nfrom personal narratives collected from blogs. We first explain how a simple\nannotation tool allows naive annotators to easily create a deep representation\nof fabula called a story intention graph, and show how we use this\nrepresentation to generate story tellings automatically. Then we present\nresults of two studies testing our narratological parameters, and showing that\ndifferent tellings affect the reader's perception of the story and characters.", "published": "2017-08-29 03:51:56", "link": "http://arxiv.org/abs/1708.08585v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparing Human and Machine Errors in Conversational Speech\n  Transcription", "abstract": "Recent work in automatic recognition of conversational telephone speech (CTS)\nhas achieved accuracy levels comparable to human transcribers, although there\nis some debate how to precisely quantify human performance on this task, using\nthe NIST 2000 CTS evaluation set. This raises the question what systematic\ndifferences, if any, may be found differentiating human from machine\ntranscription errors. In this paper we approach this question by comparing the\noutput of our most accurate CTS recognition system to that of a standard speech\ntranscription vendor pipeline. We find that the most frequent substitution,\ndeletion and insertion error types of both outputs show a high degree of\noverlap. The only notable exception is that the automatic recognizer tends to\nconfuse filled pauses (\"uh\") and backchannel acknowledgments (\"uhhuh\"). Humans\ntend not to make this error, presumably due to the distinctive and opposing\npragmatic functions attached to these words. Furthermore, we quantify the\ncorrelation between human and machine errors at the speaker level, and\ninvestigate the effect of speaker overlap between training and test data.\nFinally, we report on an informal \"Turing test\" asking humans to discriminate\nbetween automatic and human transcription error cases.", "published": "2017-08-29 07:21:39", "link": "http://arxiv.org/abs/1708.08615v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Machine Translation Training in a Multi-Domain Scenario", "abstract": "In this paper, we explore alternative ways to train a neural machine\ntranslation system in a multi-domain scenario. We investigate data\nconcatenation (with fine tuning), model stacking (multi-level fine tuning),\ndata selection and multi-model ensemble. Our findings show that the best\ntranslation quality can be achieved by building an initial system on a\nconcatenation of available out-of-domain data and then fine-tuning it on\nin-domain data. Model stacking works best when training begins with the\nfurthest out-of-domain data and the model is incrementally fine-tuned with the\nnext furthest domain and so on. Data selection did not give the best results,\nbut can be considered as a decent compromise between training time and\ntranslation quality. A weighted ensemble of different individual models\nperformed better than data selection. It is beneficial in a scenario when there\nis no time for fine-tuning an already trained model.", "published": "2017-08-29 11:56:41", "link": "http://arxiv.org/abs/1708.08712v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple LSTM model for Transition-based Dependency Parsing", "abstract": "We present a simple LSTM-based transition-based dependency parser. Our model\nis composed of a single LSTM hidden layer replacing the hidden layer in the\nusual feed-forward network architecture. We also propose a new initialization\nmethod that uses the pre-trained weights from a feed-forward neural network to\ninitialize our LSTM-based model. We also show that using dropout on the input\nlayer has a positive effect on performance. Our final parser achieves a 93.06%\nunlabeled and 91.01% labeled attachment score on the Penn Treebank. We\nadditionally replace LSTMs with GRUs and Elman units in our model and explore\nthe effectiveness of our initialization method on individual gates constituting\nall three types of RNN units.", "published": "2017-08-29 18:25:35", "link": "http://arxiv.org/abs/1708.08959v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Information Theoretic Analysis of DNN-HMM Acoustic Modeling", "abstract": "We propose an information theoretic framework for quantitative assessment of\nacoustic modeling for hidden Markov model (HMM) based automatic speech\nrecognition (ASR). Acoustic modeling yields the probabilities of HMM sub-word\nstates for a short temporal window of speech acoustic features. We cast ASR as\na communication channel where the input sub-word probabilities convey the\ninformation about the output HMM state sequence. The quality of the acoustic\nmodel is thus quantified in terms of the information transmitted through this\nchannel. The process of inferring the most likely HMM state sequence from the\nsub-word probabilities is known as decoding. HMM based decoding assumes that an\nacoustic model yields accurate state-level probabilities and the data\ndistribution given the underlying hidden state is independent of any other\nstate in the sequence. We quantify 1) the acoustic model accuracy and 2) its\nrobustness to mismatch between data and the HMM conditional independence\nassumption in terms of some mutual information quantities. In this context,\nexploiting deep neural network (DNN) posterior probabilities leads to a simple\nand straightforward analysis framework to assess shortcomings of the acoustic\nmodel for HMM based decoding. This analysis enables us to evaluate the Gaussian\nmixture acoustic model (GMM) and the importance of many hidden layers in DNNs\nwithout any need of explicit speech recognition. In addition, it sheds light on\nthe contribution of low-dimensional models to enhance acoustic modeling for\nbetter compliance with the HMM based decoding requirements.", "published": "2017-08-29 10:03:05", "link": "http://arxiv.org/abs/1709.01144v2", "categories": ["cs.SD", "cs.CL", "cs.LG"], "primary_category": "cs.SD"}
{"title": "Unsupervised Terminological Ontology Learning based on Hierarchical\n  Topic Modeling", "abstract": "In this paper, we present hierarchical relationbased latent Dirichlet\nallocation (hrLDA), a data-driven hierarchical topic model for extracting\nterminological ontologies from a large number of heterogeneous documents. In\ncontrast to traditional topic models, hrLDA relies on noun phrases instead of\nunigrams, considers syntax and document structures, and enriches topic\nhierarchies with topic relations. Through a series of experiments, we\ndemonstrate the superiority of hrLDA over existing topic models, especially for\nbuilding hierarchies. Furthermore, we illustrate the robustness of hrLDA in the\nsettings of noisy data sets, which are likely to occur in many practical\nscenarios. Our ontology evaluation results show that ontologies extracted from\nhrLDA are very competitive with the ontologies created by domain experts.", "published": "2017-08-29 21:04:11", "link": "http://arxiv.org/abs/1708.09025v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Modelling Protagonist Goals and Desires in First-Person Narrative", "abstract": "Many genres of natural language text are narratively structured, a testament\nto our predilection for organizing our experiences as narratives. There is\nbroad consensus that understanding a narrative requires identifying and\ntracking the goals and desires of the characters and their narrative outcomes.\nHowever, to date, there has been limited work on computational models for this\nproblem. We introduce a new dataset, DesireDB, which includes gold-standard\nlabels for identifying statements of desire, textual evidence for desire\nfulfillment, and annotations for whether the stated desire is fulfilled given\nthe evidence in the narrative context. We report experiments on tracking desire\nfulfillment using different methods, and show that LSTM Skip-Thought model\nachieves F-measure of 0.7 on our corpus.", "published": "2017-08-29 21:40:22", "link": "http://arxiv.org/abs/1708.09040v1", "categories": ["cs.AI", "cs.CL", "cs.NE"], "primary_category": "cs.AI"}
