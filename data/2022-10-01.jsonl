{"title": "Zemi: Learning Zero-Shot Semi-Parametric Language Models from Multiple\n  Tasks", "abstract": "Although large language models have achieved impressive zero-shot ability,\nthe huge model size generally incurs high cost. Recently, semi-parametric\nlanguage models, which augment a smaller language model with an external\nretriever, have demonstrated promising language modeling capabilities. However,\nit remains unclear whether such semi-parametric language models can perform\ncompetitively well as their fully-parametric counterparts on zero-shot\ngeneralization to downstream tasks. In this work, we introduce $\\text{Zemi}$, a\nzero-shot semi-parametric language model. To our best knowledge, this is the\nfirst semi-parametric language model that can demonstrate strong zero-shot\nperformance on a wide range of held-out unseen tasks. We train $\\text{Zemi}$\nwith a novel semi-parametric multitask prompted training paradigm, which shows\nsignificant improvement compared with the parametric multitask training as\nproposed by T0. Specifically, we augment the multitask training and zero-shot\nevaluation with retrieval from a large-scale task-agnostic unlabeled corpus. In\norder to incorporate multiple potentially noisy retrieved augmentations, we\nfurther propose a novel $\\text{augmentation fusion}$ module leveraging\nperceiver resampler and gated cross-attention. Notably, our proposed\n$\\text{Zemi}_\\text{LARGE}$ outperforms T0-3B by 16% on all seven evaluation\ntasks while being 3.9x smaller in model size.", "published": "2022-10-01 04:08:50", "link": "http://arxiv.org/abs/2210.00185v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FRMT: A Benchmark for Few-Shot Region-Aware Machine Translation", "abstract": "We present FRMT, a new dataset and evaluation benchmark for Few-shot\nRegion-aware Machine Translation, a type of style-targeted translation. The\ndataset consists of professional translations from English into two regional\nvariants each of Portuguese and Mandarin Chinese. Source documents are selected\nto enable detailed analysis of phenomena of interest, including lexically\ndistinct terms and distractor terms. We explore automatic evaluation metrics\nfor FRMT and validate their correlation with expert human evaluation across\nboth region-matched and mismatched rating scenarios. Finally, we present a\nnumber of baseline models for this task, and offer guidelines for how\nresearchers can train, evaluate, and compare their own models. Our dataset and\nevaluation code are publicly available: https://bit.ly/frmt-task", "published": "2022-10-01 05:02:04", "link": "http://arxiv.org/abs/2210.00193v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CGELBank: CGEL as a Framework for English Syntax Annotation", "abstract": "We introduce the syntactic formalism of the \\textit{Cambridge Grammar of the\nEnglish Language} (CGEL) to the world of treebanking through the CGELBank\nproject. We discuss some issues in linguistic analysis that arose in adapting\nthe formalism to corpus annotation, followed by quantitative and qualitative\ncomparisons with parallel UD and PTB treebanks. We argue that CGEL provides a\ngood tradeoff between comprehensiveness of analysis and usability for\nannotation, which motivates expanding the treebank with automatic conversion in\nthe future.", "published": "2022-10-01 23:44:06", "link": "http://arxiv.org/abs/2210.00394v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Synthetic Text Detection: Systemic Literature Review", "abstract": "Within the text analysis and processing fields, generated text attacks have\nbeen made easier to create than ever before. To combat these attacks open\nsourcing models and datasets have become a major trend to create automated\ndetection algorithms in defense of authenticity. For this purpose, synthetic\ntext detection has become an increasingly viable topic of research. This review\nis written for the purpose of creating a snapshot of the state of current\nliterature and easing the barrier to entry for future authors. Towards that\ngoal, we identified few research trends and challenges in this field.", "published": "2022-10-01 04:43:41", "link": "http://arxiv.org/abs/2210.06336v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Construction and Evaluation of a Self-Attention Model for Semantic\n  Understanding of Sentence-Final Particles", "abstract": "Sentence-final particles serve an essential role in spoken Japanese because\nthey express the speaker's mental attitudes toward a proposition and/or an\ninterlocutor. They are acquired at early ages and occur very frequently in\neveryday conversation. However, there has been little proposal for a\ncomputational model of acquiring sentence-final particles. This paper proposes\nSubjective BERT, a self-attention model that takes various subjective senses in\naddition to language and images as input and learns the relationship between\nwords and subjective senses. An evaluation experiment revealed that the model\nunderstands the usage of \"yo\", which expresses the speaker's intention to\ncommunicate new information, and that of \"ne\", which denotes the speaker's\ndesire to confirm that some information is shared.", "published": "2022-10-01 13:54:54", "link": "http://arxiv.org/abs/2210.00282v1", "categories": ["cs.CL", "cs.NE", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MALM: Mixing Augmented Language Modeling for Zero-Shot Machine\n  Translation", "abstract": "Large pre-trained language models have brought remarkable progress in NLP.\nPre-training and Fine-tuning have given state-of-art performance across tasks\nin text processing. Data Augmentation techniques have also helped build\nstate-of-art models on low or zero resource tasks. Many works in the past have\nattempted at learning a single massively-multilingual machine translation model\nfor zero-shot translation. Although those translation models are producing\ncorrect translations, the main challenge is those models are producing the\nwrong languages for zero-shot translation. This work and its results indicate\nthat prompt conditioned large models do not suffer from off-target language\nerrors i.e. errors arising due to translation to wrong languages. We\nempirically demonstrate the effectiveness of self-supervised pre-training and\ndata augmentation for zero-shot multi-lingual machine translation.", "published": "2022-10-01 17:01:30", "link": "http://arxiv.org/abs/2210.00320v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Comparison of Transformer, Convolutional, and Recurrent Neural\n  Networks on Phoneme Recognition", "abstract": "Phoneme recognition is a very important part of speech recognition that\nrequires the ability to extract phonetic features from multiple frames. In this\npaper, we compare and analyze CNN, RNN, Transformer, and Conformer models using\nphoneme recognition. For CNN, the ContextNet model is used for the experiments.\nFirst, we compare the accuracy of various architectures under different\nconstraints, such as the receptive field length, parameter size, and layer\ndepth. Second, we interpret the performance difference of these models,\nespecially when the observable sequence length varies. Our analyses show that\nTransformer and Conformer models benefit from the long-range accessibility of\nself-attention through input frames.", "published": "2022-10-01 20:47:25", "link": "http://arxiv.org/abs/2210.00367v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Longitudinal Sentiment Analyses for Radicalization Research:\n  Intertemporal Dynamics on Social Media Platforms and their Implications", "abstract": "This discussion paper demonstrates how longitudinal sentiment analyses can\ndepict intertemporal dynamics on social media platforms, what challenges are\ninherent and how further research could benefit from a longitudinal\nperspective. Furthermore and since tools for sentiment analyses shall simplify\nand accelerate the analytical process regarding qualitative data at acceptable\ninter-rater reliability, their applicability in the context of radicalization\nresearch will be examined regarding the Tweets collected on January 6th 2021,\nthe day of the storming of the U.S. Capitol in Washington. Therefore, a total\nof 49,350 Tweets will be analyzed evenly distributed within three different\nsequences: before, during and after the U.S. Capitol in Washington was stormed.\nThese sequences highlight the intertemporal dynamics within comments on social\nmedia platforms as well as the possible benefits of a longitudinal perspective\nwhen using conditional means and conditional variances. Limitations regarding\nthe identification of supporters of such events and associated hate speech as\nwell as common application errors will be demonstrated as well. As a result,\nonly under certain conditions a longitudinal sentiment analysis can increase\nthe accuracy of evidence based predictions in the context of radicalization\nresearch.", "published": "2022-10-01 18:30:00", "link": "http://arxiv.org/abs/2210.00339v1", "categories": ["cs.CL", "cs.CV", "stat.AP", "D.1.5; D.3.0; J.4; K.4.1"], "primary_category": "cs.CL"}
{"title": "LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph\n  Embeddings", "abstract": "Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph\nstructure and text-rich entity/relation information. Text-based KG embeddings\ncan represent entities by encoding descriptions with pre-trained language\nmodels, but no open-sourced library is specifically designed for KGs with PLMs\nat present. In this paper, we present LambdaKG, a library for KGE that equips\nwith many pre-trained language models (e.g., BERT, BART, T5, GPT-3), and\nsupports various tasks (e.g., knowledge graph completion, question answering,\nrecommendation, and knowledge probing). LambdaKG is publicly open-sourced at\nhttps://github.com/zjunlp/PromptKG/tree/main/lambdaKG, with a demo video at\nhttp://deepke.zjukg.cn/lambdakg.mp4 and long-term maintenance.", "published": "2022-10-01 16:01:53", "link": "http://arxiv.org/abs/2210.00305v3", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multimodal Analogical Reasoning over Knowledge Graphs", "abstract": "Analogical reasoning is fundamental to human cognition and holds an important\nplace in various fields. However, previous studies mainly focus on single-modal\nanalogical reasoning and ignore taking advantage of structure knowledge.\nNotably, the research in cognitive psychology has demonstrated that information\nfrom multimodal sources always brings more powerful cognitive transfer than\nsingle modality sources. To this end, we introduce the new task of multimodal\nanalogical reasoning over knowledge graphs, which requires multimodal reasoning\nability with the help of background knowledge. Specifically, we construct a\nMultimodal Analogical Reasoning dataSet (MARS) and a multimodal knowledge graph\nMarKG. We evaluate with multimodal knowledge graph embedding and pre-trained\nTransformer baselines, illustrating the potential challenges of the proposed\ntask. We further propose a novel model-agnostic Multimodal analogical reasoning\nframework with Transformer (MarT) motivated by the structure mapping theory,\nwhich can obtain better performance. Code and datasets are available in\nhttps://github.com/zjunlp/MKG_Analogy.", "published": "2022-10-01 16:24:15", "link": "http://arxiv.org/abs/2210.00312v4", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Physical Computing: A Category Theoretic Perspective on Physical\n  Computation and System Compositionality", "abstract": "This paper introduces a category theory-based framework to redefine physical\ncomputing in light of advancements in quantum computing and non-standard\ncomputing systems. By integrating classical definitions within this broader\nperspective, the paper rigorously recontextualizes what constitutes physical\ncomputing devices and processes. It demonstrates how the compositional nature\nand relational structures of physical computing systems can be coherently\nformalized using category theory. This approach not only encapsulates recent\nformalisms in physical computing but also offers a structured method to explore\nthe dynamic interactions within these systems.", "published": "2022-10-01 23:18:30", "link": "http://arxiv.org/abs/2210.00392v4", "categories": ["quant-ph", "cs.AI", "cs.CL", "physics.comp-ph", "q-bio.OT"], "primary_category": "quant-ph"}
{"title": "Pre-trained Speech Representations as Feature Extractors for Speech\n  Quality Assessment in Online Conferencing Applications", "abstract": "Speech quality in online conferencing applications is typically assessed\nthrough human judgements in the form of the mean opinion score (MOS) metric.\nSince such a labor-intensive approach is not feasible for large-scale speech\nquality assessments in most settings, the focus has shifted towards automated\nMOS prediction through end-to-end training of deep neural networks (DNN).\nInstead of training a network from scratch, we propose to leverage the speech\nrepresentations from the pre-trained wav2vec-based XLS-R model. However, the\nnumber of parameters of such a model exceeds task-specific DNNs by several\norders of magnitude, which poses a challenge for resulting fine-tuning\nprocedures on smaller datasets. Therefore, we opt to use pre-trained speech\nrepresentations from XLS-R in a feature extraction rather than a fine-tuning\nsetting, thereby significantly reducing the number of trainable model\nparameters. We compare our proposed XLS-R-based feature extractor to a\nMel-frequency cepstral coefficient (MFCC)-based one, and experiment with\nvarious combinations of bidirectional long short term memory (Bi-LSTM) and\nattention pooling feedforward (AttPoolFF) networks trained on the output of the\nfeature extractors. We demonstrate the increased performance of pre-trained\nXLS-R embeddings in terms a reduced root mean squared error (RMSE) on the\nConferencingSpeech 2022 MOS prediction task.", "published": "2022-10-01 11:51:06", "link": "http://arxiv.org/abs/2210.00259v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multi-stage Progressive Compression of Conformer Transducer for\n  On-device Speech Recognition", "abstract": "The smaller memory bandwidth in smart devices prompts development of smaller\nAutomatic Speech Recognition (ASR) models. To obtain a smaller model, one can\nemploy the model compression techniques. Knowledge distillation (KD) is a\npopular model compression approach that has shown to achieve smaller model size\nwith relatively lesser degradation in the model performance. In this approach,\nknowledge is distilled from a trained large size teacher model to a smaller\nsize student model. Also, the transducer based models have recently shown to\nperform well for on-device streaming ASR task, while the conformer models are\nefficient in handling long term dependencies. Hence in this work we employ a\nstreaming transducer architecture with conformer as the encoder. We propose a\nmulti-stage progressive approach to compress the conformer transducer model\nusing KD. We progressively update our teacher model with the distilled student\nmodel in a multi-stage setup. On standard LibriSpeech dataset, our experimental\nresults have successfully achieved compression rates greater than 60% without\nsignificant degradation in the performance compared to the larger teacher\nmodel.", "published": "2022-10-01 02:23:00", "link": "http://arxiv.org/abs/2210.00169v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fine-tuning Wav2vec for Vocal-burst Emotion Recognition", "abstract": "The ACII Affective Vocal Bursts (A-VB) competition introduces a new topic in\naffective computing, which is understanding emotional expression using the\nnon-verbal sound of humans. We are familiar with emotion recognition via verbal\nvocal or facial expression. However, the vocal bursts such as laughs, cries,\nand signs, are not exploited even though they are very informative for behavior\nanalysis. The A-VB competition comprises four tasks that explore non-verbal\ninformation in different spaces. This technical report describes the method and\nthe result of SclabCNU Team for the tasks of the challenge. We achieved\npromising results compared to the baseline model provided by the organizers.", "published": "2022-10-01 12:03:27", "link": "http://arxiv.org/abs/2210.00263v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Optimized Decoders for Mixed-Order Ambisonics", "abstract": "In this paper we discuss the motivation, design, and analysis of ambisonic\ndecoders for systems where the vertical order is less than the horizontal\norder, known as mixed-order Ambisonic systems. This can be due to the use of\nmicrophone arrays that emphasize horizontal spatial resolution or speaker\narrays that provide sparser coverage vertically. First, we review Ambisonic\nreproduction criteria, as defined by Gerzon, and summarize recent results on\nthe relative perceptual importance of the various criteria. Then we show that\nusing full-order decoders with mixed-order program material results in poorer\nperformance than with a properly designed mixed-order decoder. We then\nintroduce a new implementation of a decoder optimizer that draws upon\ntechniques from machine learning for quick and robust convergence, discuss the\nconstruction of the objective function, and apply it to the problem of\ndesigning two-band decoders for mixed-order signal sets and non-uniform\nloudspeaker layouts. Results of informal listening tests are summarized and\nfuture directions discussed.", "published": "2022-10-01 21:24:26", "link": "http://arxiv.org/abs/2210.00378v1", "categories": ["eess.AS", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
