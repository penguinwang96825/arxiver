{"title": "Exploring Failure Cases in Multimodal Reasoning About Physical Dynamics", "abstract": "In this paper, we present an exploration of LLMs' abilities to problem solve\nwith physical reasoning in situated environments. We construct a simple\nsimulated environment and demonstrate examples of where, in a zero-shot\nsetting, both text and multimodal LLMs display atomic world knowledge about\nvarious objects but fail to compose this knowledge in correct solutions for an\nobject manipulation and placement task. We also use BLIP, a vision-language\nmodel trained with more sophisticated cross-modal attention, to identify cases\nrelevant to object physical properties that that model fails to ground.\nFinally, we present a procedure for discovering the relevant properties of\nobjects in the environment and propose a method to distill this knowledge back\ninto the LLM.", "published": "2024-02-24 00:01:01", "link": "http://arxiv.org/abs/2402.15654v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging ChatGPT in Pharmacovigilance Event Extraction: An Empirical\n  Study", "abstract": "With the advent of large language models (LLMs), there has been growing\ninterest in exploring their potential for medical applications. This research\naims to investigate the ability of LLMs, specifically ChatGPT, in the context\nof pharmacovigilance event extraction, of which the main goal is to identify\nand extract adverse events or potential therapeutic events from textual medical\nsources. We conduct extensive experiments to assess the performance of ChatGPT\nin the pharmacovigilance event extraction task, employing various prompts and\ndemonstration selection strategies. The findings demonstrate that while ChatGPT\ndemonstrates reasonable performance with appropriate demonstration selection\nstrategies, it still falls short compared to fully fine-tuned small models.\nAdditionally, we explore the potential of leveraging ChatGPT for data\naugmentation. However, our investigation reveals that the inclusion of\nsynthesized data into fine-tuning may lead to a decrease in performance,\npossibly attributed to noise in the ChatGPT-generated labels. To mitigate this,\nwe explore different filtering strategies and find that, with the proper\napproach, more stable performance can be achieved, although constant\nimprovement remains elusive.", "published": "2024-02-24 00:38:29", "link": "http://arxiv.org/abs/2402.15663v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HD-Eval: Aligning Large Language Model Evaluators Through Hierarchical\n  Criteria Decomposition", "abstract": "Large language models (LLMs) have emerged as a promising alternative to\nexpensive human evaluations. However, the alignment and coverage of LLM-based\nevaluations are often limited by the scope and potential bias of the evaluation\nprompts and criteria. To address this challenge, we propose HD-Eval, a novel\nframework that iteratively aligns LLM-based evaluators with human preference\nvia Hierarchical Criteria Decomposition. HD-Eval inherits the essence from the\nevaluation mindset of human experts and enhances the alignment of LLM-based\nevaluators by decomposing a given evaluation task into finer-grained criteria,\naggregating them according to estimated human preferences, pruning\ninsignificant criteria with attribution, and further decomposing significant\ncriteria. By integrating these steps within an iterative alignment training\nprocess, we obtain a hierarchical decomposition of criteria that\ncomprehensively captures aspects of natural language at multiple levels of\ngranularity. Implemented as a white box, the human preference-guided aggregator\nis efficient to train and more explainable than relying solely on prompting,\nand its independence from model parameters makes it applicable to closed-source\nLLMs. Extensive experiments on three evaluation domains demonstrate the\nsuperiority of HD-Eval in further aligning state-of-the-art evaluators and\nproviding deeper insights into the explanation of evaluation results and the\ntask itself.", "published": "2024-02-24 08:01:32", "link": "http://arxiv.org/abs/2402.15754v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dental Severity Assessment through Few-shot Learning and SBERT\n  Fine-tuning", "abstract": "Dental diseases have a significant impact on a considerable portion of the\npopulation, leading to various health issues that can detrimentally affect\nindividuals' overall well-being. The integration of automated systems in oral\nhealthcare has become increasingly crucial. Machine learning approaches offer a\nviable solution to address challenges such as diagnostic difficulties,\ninefficiencies, and errors in oral disease diagnosis. These methods prove\nparticularly useful when physicians struggle to predict or diagnose diseases at\ntheir early stages. In this study, thirteen different machine learning, deep\nlearning, and large language models were employed to determine the severity\nlevel of oral health issues based on radiologists' reports. The results\nrevealed that the Few-shot learning with SBERT and Multi-Layer Perceptron model\noutperformed all other models across various experiments, achieving an\nimpressive accuracy of 94.1% as the best result. Consequently, this model\nexhibits promise as a reliable tool for evaluating the severity of oral\ndiseases, enabling patients to receive more effective treatment and aiding\nhealthcare professionals in making informed decisions regarding resource\nallocation and the management of high-risk patients.", "published": "2024-02-24 08:02:19", "link": "http://arxiv.org/abs/2402.15755v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linguistic Intelligence in Large Language Models for Telecommunications", "abstract": "Large Language Models (LLMs) have emerged as a significant advancement in the\nfield of Natural Language Processing (NLP), demonstrating remarkable\ncapabilities in language generation and other language-centric tasks. Despite\ntheir evaluation across a multitude of analytical and reasoning tasks in\nvarious scientific domains, a comprehensive exploration of their knowledge and\nunderstanding within the realm of natural language tasks in the\ntelecommunications domain is still needed. This study, therefore, seeks to\nevaluate the knowledge and understanding capabilities of LLMs within this\ndomain. To achieve this, we conduct an exhaustive zero-shot evaluation of four\nprominent LLMs-Llama-2, Falcon, Mistral, and Zephyr. These models require fewer\nresources than ChatGPT, making them suitable for resource-constrained\nenvironments. Their performance is compared with state-of-the-art, fine-tuned\nmodels. To the best of our knowledge, this is the first work to extensively\nevaluate and compare the understanding of LLMs across multiple language-centric\ntasks in this domain. Our evaluation reveals that zero-shot LLMs can achieve\nperformance levels comparable to the current state-of-the-art fine-tuned\nmodels. This indicates that pretraining on extensive text corpora equips LLMs\nwith a degree of specialization, even within the telecommunications domain. We\nalso observe that no single LLM consistently outperforms others, and the\nperformance of different LLMs can fluctuate. Although their performance lags\nbehind fine-tuned models, our findings underscore the potential of LLMs as a\nvaluable resource for understanding various aspects of this field that lack\nlarge annotated data.", "published": "2024-02-24 14:01:07", "link": "http://arxiv.org/abs/2402.15818v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MATHWELL: Generating Educational Math Word Problems Using Teacher\n  Annotations", "abstract": "Math word problems are critical K-8 educational tools, but writing them is\ntime consuming and requires extensive expertise. To be educational, problems\nmust be solvable, have accurate answers, and, most importantly, be\neducationally appropriate. We propose that language models have potential to\nsupport K-8 math education by automatically generating word problems. However,\nevaluating educational appropriateness is hard to quantify. We fill this gap by\nhaving teachers evaluate problems generated by LLMs, who find existing models\nand data often fail to be educationally appropriate. We then explore\nautomatically generating educational word problems, ultimately using our expert\nannotations to finetune a 70B language model. Our model, MATHWELL, is the first\nK-8 word problem generator targeted at educational appropriateness. Further\nexpert studies find MATHWELL generates problems far more solvable, accurate,\nand appropriate than public models. MATHWELL also matches GPT-4's problem\nquality while attaining more appropriate reading levels for K-8 students and\navoiding generating harmful questions.", "published": "2024-02-24 17:08:45", "link": "http://arxiv.org/abs/2402.15861v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SportQA: A Benchmark for Sports Understanding in Large Language Models", "abstract": "A deep understanding of sports, a field rich in strategic and dynamic\ncontent, is crucial for advancing Natural Language Processing (NLP). This holds\nparticular significance in the context of evaluating and advancing Large\nLanguage Models (LLMs), given the existing gap in specialized benchmarks. To\nbridge this gap, we introduce SportQA, a novel benchmark specifically designed\nfor evaluating LLMs in the context of sports understanding. SportQA encompasses\nover 70,000 multiple-choice questions across three distinct difficulty levels,\neach targeting different aspects of sports knowledge from basic historical\nfacts to intricate, scenario-based reasoning tasks. We conducted a thorough\nevaluation of prevalent LLMs, mainly utilizing few-shot learning paradigms\nsupplemented by chain-of-thought (CoT) prompting. Our results reveal that while\nLLMs exhibit competent performance in basic sports knowledge, they struggle\nwith more complex, scenario-based sports reasoning, lagging behind human\nexpertise. The introduction of SportQA marks a significant step forward in NLP,\noffering a tool for assessing and enhancing sports understanding in LLMs.", "published": "2024-02-24 17:12:10", "link": "http://arxiv.org/abs/2402.15862v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SemEval-2024 Task 8: Weighted Layer Averaging RoBERTa for Black-Box\n  Machine-Generated Text Detection", "abstract": "This document contains the details of the authors' submission to the\nproceedings of SemEval 2024's Task 8: Multigenerator, Multidomain, and\nMultilingual Black-Box Machine-Generated Text Detection Subtask A (monolingual)\nand B. Detection of machine-generated text is becoming an increasingly\nimportant task, with the advent of large language models (LLMs). In this paper,\nwe lay out how using weighted averages of RoBERTa layers lets us capture\ninformation about text that is relevant to machine-generated text detection.", "published": "2024-02-24 17:44:56", "link": "http://arxiv.org/abs/2402.15873v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Prompting Strategies for Grammatical Error Correction Based\n  on Language Proficiency", "abstract": "The writing examples of English language learners may be different from those\nof native speakers. Given that there is a significant differences in second\nlanguage (L2) learners' error types by their proficiency levels, this paper\nattempts to reduce overcorrection by examining the interaction between LLM's\nperformance and L2 language proficiency. Our method focuses on zero-shot and\nfew-shot prompting and fine-tuning models for GEC for learners of English as a\nforeign language based on the different proficiency. We investigate GEC results\nand find that overcorrection happens primarily in advanced language learners'\nwriting (proficiency C) rather than proficiency A (a beginner level) and\nproficiency B (an intermediate level). Fine-tuned LLMs, and even few-shot\nprompting with writing examples of English learners, actually tend to exhibit\ndecreased recall measures. To make our claim concrete, we conduct a\ncomprehensive examination of GEC outcomes and their evaluation results based on\nlanguage proficiency.", "published": "2024-02-24 23:17:56", "link": "http://arxiv.org/abs/2402.15930v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Frustratingly Simple Prompting-based Text Denoising", "abstract": "This paper introduces a novel perspective on the automated essay scoring\n(AES) task, challenging the conventional view of the ASAP dataset as a static\nentity. Employing simple text denoising techniques using prompting, we explore\nthe dynamic potential within the dataset. While acknowledging the previous\nemphasis on building regression systems, our paper underscores how making minor\nchanges to a dataset through text denoising can enhance the final results.", "published": "2024-02-24 23:23:06", "link": "http://arxiv.org/abs/2402.15931v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Foot In The Door: Understanding Large Language Model Jailbreaking via\n  Cognitive Psychology", "abstract": "Large Language Models (LLMs) have gradually become the gateway for people to\nacquire new knowledge. However, attackers can break the model's security\nprotection (\"jail\") to access restricted information, which is called\n\"jailbreaking.\" Previous studies have shown the weakness of current LLMs when\nconfronted with such jailbreaking attacks. Nevertheless, comprehension of the\nintrinsic decision-making mechanism within the LLMs upon receipt of jailbreak\nprompts is noticeably lacking. Our research provides a psychological\nexplanation of the jailbreak prompts. Drawing on cognitive consistency theory,\nwe argue that the key to jailbreak is guiding the LLM to achieve cognitive\ncoordination in an erroneous direction. Further, we propose an automatic\nblack-box jailbreaking method based on the Foot-in-the-Door (FITD) technique.\nThis method progressively induces the model to answer harmful questions via\nmulti-step incremental prompts. We instantiated a prototype system to evaluate\nthe jailbreaking effectiveness on 8 advanced LLMs, yielding an average success\nrate of 83.9%. This study builds a psychological perspective on the explanatory\ninsights into the intrinsic decision-making logic of LLMs.", "published": "2024-02-24 02:27:55", "link": "http://arxiv.org/abs/2402.15690v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Making Pre-trained Language Models Better Continual Few-Shot Relation\n  Extractors", "abstract": "Continual Few-shot Relation Extraction (CFRE) is a practical problem that\nrequires the model to continuously learn novel relations while avoiding\nforgetting old ones with few labeled training data. The primary challenges are\ncatastrophic forgetting and overfitting. This paper harnesses prompt learning\nto explore the implicit capabilities of pre-trained language models to address\nthe above two challenges, thereby making language models better continual\nfew-shot relation extractors. Specifically, we propose a Contrastive Prompt\nLearning framework, which designs prompt representation to acquire more\ngeneralized knowledge that can be easily adapted to old and new categories, and\nmargin-based contrastive learning to focus more on hard samples, therefore\nalleviating catastrophic forgetting and overfitting issues. To further remedy\noverfitting in low-resource scenarios, we introduce an effective memory\naugmentation strategy that employs well-crafted prompts to guide ChatGPT in\ngenerating diverse samples. Extensive experiments demonstrate that our method\noutperforms state-of-the-art methods by a large margin and significantly\nmitigates catastrophic forgetting and overfitting in low-resource scenarios.", "published": "2024-02-24 04:32:44", "link": "http://arxiv.org/abs/2402.15713v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hal-Eval: A Universal and Fine-grained Hallucination Evaluation\n  Framework for Large Vision Language Models", "abstract": "Large Vision Language Models exhibit remarkable capabilities but struggle\nwith hallucinations inconsistencies between images and their descriptions.\nPrevious hallucination evaluation studies on LVLMs have identified\nhallucinations in terms of objects, attributes, and relations but overlooked\ncomplex hallucinations that create an entire narrative around a fictional\nentity. In this paper, we introduce a refined taxonomy of hallucinations,\nfeaturing a new category: Event Hallucination. We then utilize advanced LLMs to\ngenerate and filter fine grained hallucinatory data consisting of various types\nof hallucinations, with a particular focus on event hallucinations, laying the\ngroundwork for integrating discriminative and generative evaluation methods\nwithin our universal evaluation framework. The proposed benchmark distinctively\nassesses LVLMs ability to tackle a broad spectrum of hallucinations, making it\na reliable and comprehensive tool for gauging LVLMs efficacy in handling\nhallucinations. We will release our code and data.", "published": "2024-02-24 05:14:52", "link": "http://arxiv.org/abs/2402.15721v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Chimera: A Lossless Decoding Method for Accelerating Large Language\n  Models Inference by Fusing all Tokens", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks. However, their widespread application is hindered by the\nresource-intensive decoding process. To address this challenge, current\napproaches have incorporated additional decoding heads to enable parallel\nprediction of multiple subsequent tokens, thereby achieving inference\nacceleration. Nevertheless, the accuracy of these decoding heads falls short of\nthe auto-regressive decoding approach.\n  In light of these limitations, we propose Chimera, a novel framework\nspecifically designed for speculative sampling. Within this framework, we\nintroduce a lightweight draft model that effectively utilizes previously\ngenerated tokens to predict subsequent words. To ensure both accuracy and\nefficiency, we present two strategies within the lightweight draft model.\nFirstly, we focus on capturing short-range dependencies at the bottom layer.\nSecondly, we leverage the readily available representations from the original\nLLM.Through empirical evaluation on the Vicuna and LlaMA-2 series, Chimera\ndemonstrates impressive results, achieving an average latency speedup ratio of\n2.7x compared to the vanilla auto-regressive decoding approach. This highlights\nthe potential of our proposed framework in significantly improving the\nefficiency of large language models during the decoding process.", "published": "2024-02-24 08:10:39", "link": "http://arxiv.org/abs/2402.15758v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Look Before You Leap: Problem Elaboration Prompting Improves\n  Mathematical Reasoning in Large Language Models", "abstract": "Large language models (LLMs) still grapple with complex tasks like\nmathematical reasoning. Despite significant efforts invested in improving\nprefix prompts or reasoning process, the crucial role of problem context might\nhave been neglected. Accurate recognition of inputs is fundamental for solving\nmathematical tasks, as ill-formed problems could potentially mislead LLM's\nreasoning. In this study, we propose a new approach named Problem Elaboration\nPrompting (PEP) to enhance the mathematical capacities of LLMs. Specifically,\nPEP decomposes and elucidates the problem context before reasoning, therefore\nenhancing the context modeling and parsing efficiency. Experiments across\ndatasets and models demonstrate promising performances: (1) PEP demonstrates an\noverall enhancement in various mathematical tasks. For instance, with the\nGPT-3.5 model, PEP exhibits improvements of 9.93% and 8.80% on GSM8k through\ngreedy decoding and self-consistency, respectively. (2) PEP can be easily\nimplemented and integrated with other prompting methods. (3) PEP shows\nparticular strength in handling distraction problems.", "published": "2024-02-24 08:40:30", "link": "http://arxiv.org/abs/2402.15764v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Empowering Large Language Model Agents through Action Learning", "abstract": "Large Language Model (LLM) Agents have recently garnered increasing interest\nyet they are limited in their ability to learn from trial and error, a key\nelement of intelligent behavior. In this work, we argue that the capacity to\nlearn new actions from experience is fundamental to the advancement of learning\nin LLM agents. While humans naturally expand their action spaces and develop\nskills through experiential learning, LLM agents typically operate within fixed\naction spaces, limiting their potential for growth. To address these\nchallenges, our study explores open-action learning for language agents. We\nintroduce a framework LearnAct with an iterative learning strategy to create\nand improve actions in the form of Python functions. In each iteration, LLM\nrevises and updates the currently available actions based on the errors\nidentified in unsuccessful training tasks, thereby enhancing action\neffectiveness. Our experimental evaluations across Robotic Planning and\nAlfworld environments reveal that after learning on a few training task\ninstances, our approach to open-action learning markedly improves agent\nperformance for the type of task (by 32 percent in AlfWorld compared to\nReAct+Reflexion, for instance) highlighting the importance of experiential\naction learning in the development of more intelligent LLM agents.", "published": "2024-02-24 13:13:04", "link": "http://arxiv.org/abs/2402.15809v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Measuring Bargaining Abilities of LLMs: A Benchmark and A\n  Buyer-Enhancement Method", "abstract": "Bargaining is an important and unique part of negotiation between humans. As\nLLM-driven agents learn to negotiate and act like real humans, how to evaluate\nagents' bargaining abilities remains an open problem. For the first time, we\nformally described the Bargaining task as an asymmetric incomplete information\ngame, defining the gains of the Buyer and Seller in multiple bargaining\nprocesses. It allows us to quantitatively assess an agent's performance in the\nBargain task. We collected a real product price dataset, AmazonHistoryPrice,\nand conducted evaluations of various LLM agents' bargaining abilities. We find\nthat playing a Buyer is much harder than a Seller, and increasing model size\ncan not effectively improve the Buyer's performance. To address the challenge,\nwe propose a novel approach called OG-Narrator that integrates a deterministic\nOffer Generator to control the price range of Buyer's offers, and an LLM\nNarrator to create natural language sentences for generated offers.\nExperimental results show that OG-Narrator improves the buyer's deal rates from\n26.67% to 88.88% and brings a ten times multiplication of profits on all\nbaselines, even a model that has not been aligned.", "published": "2024-02-24 13:36:58", "link": "http://arxiv.org/abs/2402.15813v3", "categories": ["cs.CL", "cs.GT"], "primary_category": "cs.CL"}
{"title": "Prompt Perturbation Consistency Learning for Robust Language Models", "abstract": "Large language models (LLMs) have demonstrated impressive performance on a\nnumber of natural language processing tasks, such as question answering and\ntext summarization. However, their performance on sequence labeling tasks such\nas intent classification and slot filling (IC-SF), which is a central component\nin personal assistant systems, lags significantly behind discriminative models.\nFurthermore, there is a lack of substantive research on the robustness of LLMs\nto various perturbations in the input prompts. The contributions of this paper\nare three-fold. First, we show that fine-tuning sufficiently large LLMs can\nproduce IC-SF performance comparable to discriminative models. Next, we\nsystematically analyze the performance deterioration of those fine-tuned models\ndue to three distinct yet relevant types of input perturbations - oronyms,\nsynonyms, and paraphrasing. Finally, we propose an efficient mitigation\napproach, Prompt Perturbation Consistency Learning (PPCL), which works by\nregularizing the divergence between losses from clean and perturbed samples.\nOur experiments demonstrate that PPCL can recover on average 59% and 69% of the\nperformance drop for IC and SF tasks, respectively. Furthermore, PPCL beats the\ndata augmentation approach while using ten times fewer augmented data samples.", "published": "2024-02-24 15:00:58", "link": "http://arxiv.org/abs/2402.15833v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PRP: Propagating Universal Perturbations to Attack Large Language Model\n  Guard-Rails", "abstract": "Large language models (LLMs) are typically aligned to be harmless to humans.\nUnfortunately, recent work has shown that such models are susceptible to\nautomated jailbreak attacks that induce them to generate harmful content. More\nrecent LLMs often incorporate an additional layer of defense, a Guard Model,\nwhich is a second LLM that is designed to check and moderate the output\nresponse of the primary LLM. Our key contribution is to show a novel attack\nstrategy, PRP, that is successful against several open-source (e.g., Llama 2)\nand closed-source (e.g., GPT 3.5) implementations of Guard Models. PRP\nleverages a two step prefix-based attack that operates by (a) constructing a\nuniversal adversarial prefix for the Guard Model, and (b) propagating this\nprefix to the response. We find that this procedure is effective across\nmultiple threat models, including ones in which the adversary has no access to\nthe Guard Model at all. Our work suggests that further advances are required on\ndefenses and Guard Models before they can be considered effective.", "published": "2024-02-24 21:27:13", "link": "http://arxiv.org/abs/2402.15911v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "IPED: An Implicit Perspective for Relational Triple Extraction based on\n  Diffusion Model", "abstract": "Relational triple extraction is a fundamental task in the field of\ninformation extraction, and a promising framework based on table filling has\nrecently gained attention as a potential baseline for entity relation\nextraction. However, inherent shortcomings such as redundant information and\nincomplete triple recognition remain problematic. To address these challenges,\nwe propose an Implicit Perspective for relational triple Extraction based on\nDiffusion model (IPED), an innovative approach for extracting relational\ntriples. Our classifier-free solution adopts an implicit strategy using block\ncoverage to complete the tables, avoiding the limitations of explicit tagging\nmethods. Additionally, we introduce a generative model structure, the\nblock-denoising diffusion model, to collaborate with our implicit perspective\nand effectively circumvent redundant information disruptions. Experimental\nresults on two popular datasets demonstrate that IPED achieves state-of-the-art\nperformance while gaining superior inference speed and low computational\ncomplexity. To support future research, we have made our source code publicly\navailable online.", "published": "2024-02-24 14:18:11", "link": "http://arxiv.org/abs/2403.00808v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Abdelhak at SemEval-2024 Task 9 : Decoding Brainteasers, The Efficacy of\n  Dedicated Models Versus ChatGPT", "abstract": "This study introduces a dedicated model aimed at solving the BRAINTEASER task\n9 , a novel challenge designed to assess models lateral thinking capabilities\nthrough sentence and word puzzles. Our model demonstrates remarkable efficacy,\nsecuring Rank 1 in sentence puzzle solving during the test phase with an\noverall score of 0.98. Additionally, we explore the comparative performance of\nChatGPT, specifically analyzing how variations in temperature settings affect\nits ability to engage in lateral thinking and problem-solving. Our findings\nindicate a notable performance disparity between the dedicated model and\nChatGPT, underscoring the potential of specialized approaches in enhancing\ncreative reasoning in AI.", "published": "2024-02-24 20:00:03", "link": "http://arxiv.org/abs/2403.00809v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CoRelation: Boosting Automatic ICD Coding Through Contextualized Code\n  Relation Learning", "abstract": "Automatic International Classification of Diseases (ICD) coding plays a\ncrucial role in the extraction of relevant information from clinical notes for\nproper recording and billing. One of the most important directions for boosting\nthe performance of automatic ICD coding is modeling ICD code relations.\nHowever, current methods insufficiently model the intricate relationships among\nICD codes and often overlook the importance of context in clinical notes. In\nthis paper, we propose a novel approach, a contextualized and flexible\nframework, to enhance the learning of ICD code representations. Our approach,\nunlike existing methods, employs a dependent learning paradigm that considers\nthe context of clinical notes in modeling all possible code relations. We\nevaluate our approach on six public ICD coding datasets and the experimental\nresults demonstrate the effectiveness of our approach compared to\nstate-of-the-art baselines.", "published": "2024-02-24 03:25:28", "link": "http://arxiv.org/abs/2402.15700v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Query Augmentation by Decoding Semantics from Brain Signals", "abstract": "Query augmentation is a crucial technique for refining semantically imprecise\nqueries. Traditionally, query augmentation relies on extracting information\nfrom initially retrieved, potentially relevant documents. If the quality of the\ninitially retrieved documents is low, then the effectiveness of query\naugmentation would be limited as well. We propose Brain-Aug, which enhances a\nquery by incorporating semantic information decoded from brain signals.\nBrainAug generates the continuation of the original query with a prompt\nconstructed with brain signal information and a ranking-oriented inference\napproach. Experimental results on fMRI (functional magnetic resonance imaging)\ndatasets show that Brain-Aug produces semantically more accurate queries,\nleading to improved document ranking performance. Such improvement brought by\nbrain signals is particularly notable for ambiguous queries.", "published": "2024-02-24 04:08:51", "link": "http://arxiv.org/abs/2402.15708v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "How Do Humans Write Code? Large Models Do It the Same Way Too", "abstract": "Program-of-Thought (PoT) replaces natural language-based Chain-of-Thought\n(CoT) as the most popular method in Large Language Models (LLMs) mathematical\nreasoning tasks by utilizing external tool calls to circumvent computational\nerrors. However, our evaluation of the GPT-4 and Llama series reveals that\nusing PoT introduces more reasoning errors, such as incorrect formulas or\nflawed logic, compared to CoT. To address this issue, we propose Human-Think\nLanguage (HTL), which leverages a suite of strategies that help integrate PoT\nand CoT, encompassing: (1) a new generation paradigm that uses full CoT\nreasoning to control code generation. (2) Focus Attention, that directs model\nattention to the CoT reasoning during PoT to generate more logical code. (3)\nreinforcement learning that utilizes the accuracy of both CoT and PoT responses\nas rewards to prevent repetitive reasoning steps in LLMs when solving difficult\nmath problems. Our method achieves an average improvement of 6.5% on the\nLlama-Base model and 4.3% on the Mistral-Base model across 8 mathematical\ncalculation datasets. It also shows significant effectiveness on five\nout-of-domain datasets by controlling the model's information flow, exhibiting\nstrong transferability. Additionally, HTL shows the most significant\nimprovement in non-mathematical natural language inference task, contributing\nto a unified reasoning task framework", "published": "2024-02-24 05:40:01", "link": "http://arxiv.org/abs/2402.15729v3", "categories": ["cs.AI", "cs.CL", "cs.PL"], "primary_category": "cs.AI"}
{"title": "ArEEG_Chars: Dataset for Envisioned Speech Recognition using EEG for\n  Arabic Characters", "abstract": "Brain-computer interfaces is an important and hot research topic that\nrevolutionize how people interact with the world, especially for individuals\nwith neurological disorders. While extensive research has been done in EEG\nsignals of English letters and words, a major limitation remains: the lack of\npublicly available EEG datasets for many non-English languages, such as Arabic.\nAlthough Arabic is one of the most spoken languages worldwide, to the best of\nour knowledge, there is no publicly available dataset for EEG signals of Arabic\ncharacters until now. To address this gap, we introduce ArEEG_Chars, a novel\nEEG dataset for Arabic 31 characters collected from 30 participants (21 males\nand 9 females), these records were collected using Epoc X 14 channels device\nfor 10 seconds long for each char record. The number of recorded signals were\n930 EEG recordings. To make the EEG signals suitable for analyzing, each\nrecording has been split into multiple signals with a time duration of 250ms,\nrespectively. Therefore, a total of 39857 recordings of EEG signals have been\ncollected in this study. Moreover, ArEEG_Chars will be publicly available for\nresearchers. We do hope that this dataset will fill an important gap in the\nresearch of Arabic EEG benefiting Arabic-speaking individuals with\ndisabilities.", "published": "2024-02-24 06:05:15", "link": "http://arxiv.org/abs/2402.15733v3", "categories": ["cs.HC", "cs.CL", "cs.LG", "eess.SP"], "primary_category": "cs.HC"}
{"title": "GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models\n  Evaluation", "abstract": "The Large Vision-Language Models (LVLMs) have demonstrated great abilities in\nimage perception and language understanding. However, existing multimodal\nbenchmarks focus on primary perception abilities and commonsense knowledge\nwhich are insufficient to reflect the comprehensive capabilities of LVLMs. We\npropose GAOKAO-MM, a multimodal benchmark based on the Chinese College Entrance\nExamination (GAOKAO), comprising of 8 subjects and 12 types of images, such as\ndiagrams, function graphs, maps and photos. GAOKAO-MM derives from native\nChinese context and sets human-level requirements for the model's abilities,\nincluding perception, understanding, knowledge and reasoning. We evaluate 10\nLVLMs and find that the accuracies of all of them are lower than 50%, with\nGPT-4-Vison (48.1%), Qwen-VL-Plus (41.2%) and Gemini-Pro-Vision (35.1%) ranking\nin the top three positions. The results of our multi-dimension analysis\nindicate that LVLMs have moderate distance towards Artificial General\nIntelligence (AGI) and provide insights facilitating the development of\nmultilingual LVLMs.", "published": "2024-02-24 06:57:15", "link": "http://arxiv.org/abs/2402.15745v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Sparse MeZO: Less Parameters for Better Performance in Zeroth-Order LLM\n  Fine-Tuning", "abstract": "While fine-tuning large language models (LLMs) for specific tasks often\nyields impressive results, it comes at the cost of memory inefficiency due to\nback-propagation in gradient-based training. Memory-efficient Zeroth-order\n(MeZO) optimizers, recently proposed to address this issue, only require\nforward passes during training, making them more memory-friendly. However, the\nquality of gradient estimates in zeroth order optimization often depends on the\ndata dimensionality, potentially explaining why MeZO still exhibits significant\nperformance drops compared to standard fine-tuning across various tasks.\nInspired by the success of Parameter-Efficient Fine-Tuning (PEFT), this paper\nintroduces Sparse MeZO, a novel memory-efficient zeroth-order optimization\napproach that applies ZO only to a carefully chosen subset of parameters. We\npropose a simple yet effective parameter selection scheme that yields\nsignificant performance gains with Sparse-MeZO. Additionally, we develop a\nmemory-optimized implementation for sparse masking, ensuring the algorithm\nrequires only inference-level memory consumption, allowing Sparse-MeZO to\nfine-tune LLaMA-30b on a single A100 GPU. Experimental results illustrate that\nSparse-MeZO consistently improves both performance and convergence speed over\nMeZO without any overhead. For example, it achieves a 9\\% absolute accuracy\nimprovement and 3.5x speedup over MeZO on the RTE task.", "published": "2024-02-24 07:22:04", "link": "http://arxiv.org/abs/2402.15751v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "OAG-Bench: A Human-Curated Benchmark for Academic Graph Mining", "abstract": "With the rapid proliferation of scientific literature, versatile academic\nknowledge services increasingly rely on comprehensive academic graph mining.\nDespite the availability of public academic graphs, benchmarks, and datasets,\nthese resources often fall short in multi-aspect and fine-grained annotations,\nare constrained to specific task types and domains, or lack underlying real\nacademic graphs. In this paper, we present OAG-Bench, a comprehensive,\nmulti-aspect, and fine-grained human-curated benchmark based on the Open\nAcademic Graph (OAG). OAG-Bench covers 10 tasks, 20 datasets, 70+ baselines,\nand 120+ experimental results to date. We propose new data annotation\nstrategies for certain tasks and offer a suite of data pre-processing codes,\nalgorithm implementations, and standardized evaluation protocols to facilitate\nacademic graph mining. Extensive experiments reveal that even advanced\nalgorithms like large language models (LLMs) encounter difficulties in\naddressing key challenges in certain tasks, such as paper source tracing and\nscholar profiling. We also introduce the Open Academic Graph Challenge\n(OAG-Challenge) to encourage community input and sharing. We envisage that\nOAG-Bench can serve as a common ground for the community to evaluate and\ncompare algorithms in academic graph mining, thereby accelerating algorithm\ndevelopment and advancement in this field. OAG-Bench is accessible at\nhttps://www.aminer.cn/data/.", "published": "2024-02-24 13:15:54", "link": "http://arxiv.org/abs/2402.15810v2", "categories": ["cs.DL", "cs.CL", "cs.LG"], "primary_category": "cs.DL"}
{"title": "On Efficiently Representing Regular Languages as RNNs", "abstract": "Recent work by Hewitt et al. (2020) provides an interpretation of the\nempirical success of recurrent neural networks (RNNs) as language models (LMs).\nIt shows that RNNs can efficiently represent bounded hierarchical structures\nthat are prevalent in human language. This suggests that RNNs' success might be\nlinked to their ability to model hierarchy. However, a closer inspection of\nHewitt et al.'s (2020) construction shows that it is not inherently limited to\nhierarchical structures. This poses a natural question: What other classes of\nLMs can RNNs efficiently represent? To this end, we generalize Hewitt et al.'s\n(2020) construction and show that RNNs can efficiently represent a larger class\nof LMs than previously claimed -- specifically, those that can be represented\nby a pushdown automaton with a bounded stack and a specific stack update\nfunction. Altogether, the efficiency of representing this diverse class of LMs\nwith RNN LMs suggests novel interpretations of their inductive bias.", "published": "2024-02-24 13:42:06", "link": "http://arxiv.org/abs/2402.15814v2", "categories": ["cs.CL", "cs.CC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MultiContrievers: Analysis of Dense Retrieval Representations", "abstract": "Dense retrievers compress source documents into (possibly lossy) vector\nrepresentations, yet there is little analysis of what information is lost\nversus preserved, and how it affects downstream tasks. We conduct the first\nanalysis of the information captured by dense retrievers compared to the\nlanguage models they are based on (e.g., BERT versus Contriever). We use 25\nMultiBert checkpoints as randomized initialisations to train MultiContrievers,\na set of 25 contriever models. We test whether specific pieces of information\n-- such as gender and occupation -- can be extracted from contriever vectors of\nwikipedia-like documents. We measure this extractability via information\ntheoretic probing. We then examine the relationship of extractability to\nperformance and gender bias, as well as the sensitivity of these results to\nmany random initialisations and data shuffles. We find that (1) contriever\nmodels have significantly increased extractability, but extractability usually\ncorrelates poorly with benchmark performance 2) gender bias is present, but is\nnot caused by the contriever representations 3) there is high sensitivity to\nboth random initialisation and to data shuffle, suggesting that future\nretrieval research should test across a wider spread of both.", "published": "2024-02-24 23:01:21", "link": "http://arxiv.org/abs/2402.15925v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Decoding Intelligence: A Framework for Certifying Knowledge\n  Comprehension in LLMs", "abstract": "Knowledge comprehension capability is an important aspect of human\nintelligence. As Large Language Models (LLMs) are being envisioned as\nsuperhuman agents, it is crucial for them to be proficient at knowledge\ncomprehension. However, existing benchmarking studies do not provide\nconsistent, generalizable, and formal guarantees on the knowledge comprehension\ncapabilities of LLMs. In this work, we propose the first framework to certify\nknowledge comprehension in LLMs with formal probabilistic guarantees. Our\ncertificates are quantitative -- they consist of high-confidence, tight bounds\non the probability that a target LLM gives the correct answer on any knowledge\ncomprehension prompt sampled from a distribution. We design and certify novel\nspecifications that precisely represent distributions of knowledge\ncomprehension prompts leveraging knowledge graphs. We certify SOTA LLMs for\nspecifications over the Wikidata5m knowledge graph. We find that the knowledge\ncomprehension capability improves significantly with scaling the size of the\nmodels.", "published": "2024-02-24 23:16:57", "link": "http://arxiv.org/abs/2402.15929v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Bridging the Gap between 2D and 3D Visual Question Answering: A Fusion\n  Approach for 3D VQA", "abstract": "In 3D Visual Question Answering (3D VQA), the scarcity of fully annotated\ndata and limited visual content diversity hampers the generalization to novel\nscenes and 3D concepts (e.g., only around 800 scenes are utilized in ScanQA and\nSQA dataset). Current approaches resort supplement 3D reasoning with 2D\ninformation. However, these methods face challenges: either they use top-down\n2D views that introduce overly complex and sometimes question-irrelevant visual\nclues, or they rely on globally aggregated scene/image-level representations\nfrom 2D VLMs, losing the fine-grained vision-language correlations. To overcome\nthese limitations, our approach utilizes question-conditional 2D view selection\nprocedure, pinpointing semantically relevant 2D inputs for crucial visual\nclues. We then integrate this 2D knowledge into the 3D-VQA system via a\ntwo-branch Transformer structure. This structure, featuring a Twin-Transformer\ndesign, compactly combines 2D and 3D modalities and captures fine-grained\ncorrelations between modalities, allowing them mutually augmenting each other.\nIntegrating proposed mechanisms above, we present BridgeQA, that offers a fresh\nperspective on multi-modal transformer-based architectures for 3D-VQA.\nExperiments validate that BridgeQA achieves state-of-the-art on 3D-VQA datasets\nand significantly outperforms existing solutions. Code is available at\n$\\href{https://github.com/matthewdm0816/BridgeQA}{\\text{this URL}}$.", "published": "2024-02-24 23:31:34", "link": "http://arxiv.org/abs/2402.15933v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Stepwise Self-Consistent Mathematical Reasoning with Large Language\n  Models", "abstract": "Using Large Language Models for complex mathematical reasoning is difficult,\nprimarily due to the complexity of multi-step reasoning. The main challenges of\nthis process include (1) selecting critical intermediate results to advance the\nprocedure, and (2) limited exploration of potential solutions. To address these\nissues, we introduce a novel algorithm, namely Stepwise Self-Consistent\nChain-of-Thought (SSC-CoT). SSC-CoT employs a strategy of selecting\nintermediate steps based on the intersection of various reasoning chains.\nAdditionally, SSC-CoT enables the model to discover critical intermediate steps\nby querying a knowledge graph comprising relevant domain knowledge. To validate\nSSC-CoT, we present a new dataset, TriMaster100, tailored for complex\ntrigonometry problems. This dataset contains 100 questions, with each solution\nbroken down into scored intermediate steps, facilitating a comprehensive\nevaluation of the mathematical reasoning process. On TriMaster100, SSC-CoT\ntriples the effectiveness of the state-of-the-art methods. Furthermore, we\nbenchmark SSC-CoT on the widely recognized complex mathematical question\ndataset, MATH level 5, and it surpasses the second-best method by 7.2% in\naccuracy. Code and the TriMaster100 dataset can be found at:\nhttps://github.com/zhao-zilong/ssc-cot.", "published": "2024-02-24 08:22:39", "link": "http://arxiv.org/abs/2402.17786v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Uncovering Customer Issues through Topological Natural Language Analysis", "abstract": "E-commerce companies deal with a high volume of customer service requests\ndaily. While a simple annotation system is often used to summarize the topics\nof customer contacts, thoroughly exploring each specific issue can be\nchallenging. This presents a critical concern, especially during an emerging\noutbreak where companies must quickly identify and address specific issues. To\ntackle this challenge, we propose a novel machine learning algorithm that\nleverages natural language techniques and topological data analysis to monitor\nemerging and trending customer issues. Our approach involves an end-to-end deep\nlearning framework that simultaneously tags the primary question sentence of\neach customer's transcript and generates sentence embedding vectors. We then\nwhiten the embedding vectors and use them to construct an undirected graph.\nFrom there, we define trending and emerging issues based on the topological\nproperties of each transcript. We have validated our results through various\nmethods and found that they are highly consistent with news sources.", "published": "2024-02-24 00:15:09", "link": "http://arxiv.org/abs/2403.00804v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhanced User Interaction in Operating Systems through Machine Learning\n  Language Models", "abstract": "With the large language model showing human-like logical reasoning and\nunderstanding ability, whether agents based on the large language model can\nsimulate the interaction behavior of real users, so as to build a reliable\nvirtual recommendation A/B test scene to help the application of recommendation\nresearch is an urgent, important and economic value problem. The combination of\ninteraction design and machine learning can provide a more efficient and\npersonalized user experience for products and services. This personalized\nservice can meet the specific needs of users and improve user satisfaction and\nloyalty. Second, the interactive system can understand the user's views and\nneeds for the product by providing a good user interface and interactive\nexperience, and then use machine learning algorithms to improve and optimize\nthe product. This iterative optimization process can continuously improve the\nquality and performance of the product to meet the changing needs of users. At\nthe same time, designers need to consider how these algorithms and tools can be\ncombined with interactive systems to provide a good user experience. This paper\nexplores the potential applications of large language models, machine learning\nand interaction design for user interaction in recommendation systems and\noperating systems. By integrating these technologies, more intelligent and\npersonalized services can be provided to meet user needs and promote continuous\nimprovement and optimization of products. This is of great value for both\nrecommendation research and user experience applications.", "published": "2024-02-24 12:17:06", "link": "http://arxiv.org/abs/2403.00806v1", "categories": ["cs.IR", "cs.CE", "cs.CL", "cs.CV"], "primary_category": "cs.IR"}
{"title": "Enhancing Cloud-Based Large Language Model Processing with Elasticsearch\n  and Transformer Models", "abstract": "Large Language Models (LLMs) are a class of generative AI models built using\nthe Transformer network, capable of leveraging vast datasets to identify,\nsummarize, translate, predict, and generate language. LLMs promise to\nrevolutionize society, yet training these foundational models poses immense\nchallenges. Semantic vector search within large language models is a potent\ntechnique that can significantly enhance search result accuracy and relevance.\nUnlike traditional keyword-based search methods, semantic search utilizes the\nmeaning and context of words to grasp the intent behind queries and deliver\nmore precise outcomes. Elasticsearch emerges as one of the most popular tools\nfor implementing semantic search an exceptionally scalable and robust search\nengine designed for indexing and searching extensive datasets. In this article,\nwe delve into the fundamentals of semantic search and explore how to harness\nElasticsearch and Transformer models to bolster large language model processing\nparadigms. We gain a comprehensive understanding of semantic search principles\nand acquire practical skills for implementing semantic search in real-world\nmodel application scenarios.", "published": "2024-02-24 12:31:22", "link": "http://arxiv.org/abs/2403.00807v1", "categories": ["cs.IR", "cs.CL", "cs.DC", "cs.DL"], "primary_category": "cs.IR"}
{"title": "MemeCraft: Contextual and Stance-Driven Multimodal Meme Generation", "abstract": "Online memes have emerged as powerful digital cultural artifacts in the age\nof social media, offering not only humor but also platforms for political\ndiscourse, social critique, and information dissemination. Their extensive\nreach and influence in shaping online communities' sentiments make them\ninvaluable tools for campaigning and promoting ideologies. Despite the\ndevelopment of several meme-generation tools, there remains a gap in their\nsystematic evaluation and their ability to effectively communicate ideologies.\nAddressing this, we introduce MemeCraft, an innovative meme generator that\nleverages large language models (LLMs) and visual language models (VLMs) to\nproduce memes advocating specific social movements. MemeCraft presents an\nend-to-end pipeline, transforming user prompts into compelling multimodal memes\nwithout manual intervention. Conscious of the misuse potential in creating\ndivisive content, an intrinsic safety mechanism is embedded to curb hateful\nmeme production.", "published": "2024-02-24 06:14:34", "link": "http://arxiv.org/abs/2403.14652v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.MM", "I.2.7; I.2.10"], "primary_category": "cs.CY"}
{"title": "Generalization or Memorization: Data Contamination and Trustworthy\n  Evaluation for Large Language Models", "abstract": "Recent statements about the impressive capabilities of large language models\n(LLMs) are usually supported by evaluating on open-access benchmarks.\nConsidering the vast size and wide-ranging sources of LLMs' training data, it\ncould explicitly or implicitly include test data, leading to LLMs being more\nsusceptible to data contamination. However, due to the opacity of training\ndata, the black-box access of models, and the rapid growth of synthetic\ntraining data, detecting and mitigating data contamination for LLMs faces\nsignificant challenges. In this paper, we propose CDD, which stands for\nContamination Detection via output Distribution for LLMs. CDD necessitates only\nthe sampled texts to detect data contamination, by identifying the peakedness\nof LLM's output distribution. To mitigate the impact of data contamination in\nevaluation, we also present TED: Trustworthy Evaluation via output\nDistribution, based on the correction of LLM's output distribution. To\nfacilitate this study, we introduce two benchmarks, i.e., DetCon and ComiEval,\nfor data contamination detection and contamination mitigation evaluation tasks.\nExtensive experimental results show that CDD achieves the average relative\nimprovements of 21.8\\%-30.2\\% over other contamination detection approaches in\nterms of Accuracy, F1 Score, and AUC metrics, and can effectively detect\nimplicit contamination. TED substantially mitigates performance improvements up\nto 66.9\\% attributed to data contamination across various contamination setups.\nIn real-world applications, we reveal that ChatGPT exhibits a high potential to\nsuffer from data contamination on HumanEval benchmark.", "published": "2024-02-24 23:54:41", "link": "http://arxiv.org/abs/2402.15938v3", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Text-guided HuBERT: Self-Supervised Speech Pre-training via Generative\n  Adversarial Networks", "abstract": "Human language can be expressed in either written or spoken form, i.e. text\nor speech. Humans can acquire knowledge from text to improve speaking and\nlistening. However, the quest for speech pre-trained models to leverage\nunpaired text has just started. In this paper, we investigate a new way to\npre-train such a joint speech-text model to learn enhanced speech\nrepresentations and benefit various speech-related downstream tasks.\nSpecifically, we propose a novel pre-training method, text-guided HuBERT, or\nT-HuBERT, which performs self-supervised learning over speech to derive\nphoneme-like discrete representations. And these phoneme-like pseudo-label\nsequences are firstly derived from speech via the generative adversarial\nnetworks (GAN) to be statistically similar to those from additional unpaired\ntextual data. In this way, we build a bridge between unpaired speech and text\nin an unsupervised manner. Extensive experiments demonstrate the significant\nsuperiority of our proposed method over various strong baselines, which\nachieves up to 15.3% relative Word Error Rate (WER) reduction on the\nLibriSpeech dataset.", "published": "2024-02-24 05:30:23", "link": "http://arxiv.org/abs/2402.15725v5", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A circular microphone array with virtual microphones based on\n  acoustics-informed neural networks", "abstract": "Acoustic beamforming aims to focus acoustic signals to a specific direction\nand suppress undesirable interferences from other directions. Despite its\nflexibility and steerability, beamforming with circular microphone arrays\nsuffers from significant performance degradation at frequencies corresponding\nto zeros of the Bessel functions. To conquer this constraint, baffled or\nconcentric circular microphone arrays have been studied; however, the former\nneeds a bulky baffle that interferes with the original sound field whereas the\nlatter requires more microphones that increase the complexity and cost, both of\nwhich are undesirable in practical applications. To tackle this challenge, this\npaper proposes a circular microphone array equipped with virtual microphones,\nwhich resolves the performance degradation commonly associated with circular\nmicrophone arrays without resorting to physical modifications. The sound\npressures at the virtual microphones are predicted from those measured by the\nphysical microphones based on an acoustics-informed neural network, and then\nthe sound pressures measured by the physical microphones and those predicted at\nthe virtual microphones are integrated to design the beamformer. Experimental\nresults demonstrate that the proposed approach not only eliminates the\nperformance degradation but also suppresses spatial aliasing at high\nfrequencies, thereby underscoring its promising potential.", "published": "2024-02-24 06:29:24", "link": "http://arxiv.org/abs/2402.15735v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ByteComposer: a Human-like Melody Composition Method based on Language\n  Model Agent", "abstract": "Large Language Models (LLM) have shown encouraging progress in multimodal\nunderstanding and generation tasks. However, how to design a human-aligned and\ninterpretable melody composition system is still under-explored. To solve this\nproblem, we propose ByteComposer, an agent framework emulating a human's\ncreative pipeline in four separate steps : \"Conception Analysis - Draft\nComposition - Self-Evaluation and Modification - Aesthetic Selection\". This\nframework seamlessly blends the interactive and knowledge-understanding\nfeatures of LLMs with existing symbolic music generation models, thereby\nachieving a melody composition agent comparable to human creators. We conduct\nextensive experiments on GPT4 and several open-source large language models,\nwhich substantiate our framework's effectiveness. Furthermore, professional\nmusic composers were engaged in multi-dimensional evaluations, the final\nresults demonstrated that across various facets of music composition,\nByteComposer agent attains the level of a novice melody composer.", "published": "2024-02-24 04:35:07", "link": "http://arxiv.org/abs/2402.17785v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
