{"title": "Inductive Relation Prediction by BERT", "abstract": "Relation prediction in knowledge graphs is dominated by embedding based\nmethods which mainly focus on the transductive setting. Unfortunately, they are\nnot able to handle inductive learning where unseen entities and relations are\npresent and cannot take advantage of prior knowledge. Furthermore, their\ninference process is not easily explainable. In this work, we propose an\nall-in-one solution, called BERTRL (BERT-based Relational Learning), which\nleverages pre-trained language model and fine-tunes it by taking relation\ninstances and their possible reasoning paths as training samples. BERTRL\noutperforms the SOTAs in 15 out of 18 cases in both inductive and transductive\nsettings. Meanwhile, it demonstrates strong generalization capability in\nfew-shot learning and is explainable.", "published": "2021-03-12 06:27:11", "link": "http://arxiv.org/abs/2103.07102v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Constrained Text Generation with Global Guidance -- Case Study on\n  CommonGen", "abstract": "This paper studies constrained text generation, which is to generate\nsentences under certain pre-conditions. We focus on CommonGen, the task of\ngenerating text based on a set of concepts, as a representative task of\nconstrained text generation. Traditional methods mainly rely on supervised\ntraining to maximize the likelihood of target sentences.However, global\nconstraints such as common sense and coverage cannot be incorporated into the\nlikelihood objective of the autoregressive decoding process. In this paper, we\nconsider using reinforcement learning to address the limitation, measuring\nglobal constraints including fluency, common sense and concept coverage with a\ncomprehensive score, which serves as the reward for reinforcement learning.\nBesides, we design a guided decoding method at the word, fragment and sentence\nlevels. Experiments demonstrate that our method significantly increases the\nconcept coverage and outperforms existing models in various automatic\nevaluations.", "published": "2021-03-12 09:40:49", "link": "http://arxiv.org/abs/2103.07170v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are NLP Models really able to Solve Simple Math Word Problems?", "abstract": "The problem of designing NLP solvers for math word problems (MWP) has seen\nsustained research activity and steady gains in the test accuracy. Since\nexisting solvers achieve high performance on the benchmark datasets for\nelementary level MWPs containing one-unknown arithmetic word problems, such\nproblems are often considered \"solved\" with the bulk of research attention\nmoving to more complex MWPs. In this paper, we restrict our attention to\nEnglish MWPs taught in grades four and lower. We provide strong evidence that\nthe existing MWP solvers rely on shallow heuristics to achieve high performance\non the benchmark datasets. To this end, we show that MWP solvers that do not\nhave access to the question asked in the MWP can still solve a large fraction\nof MWPs. Similarly, models that treat MWPs as bag-of-words can also achieve\nsurprisingly high accuracy. Further, we introduce a challenge dataset, SVAMP,\ncreated by applying carefully chosen variations over examples sampled from\nexisting datasets. The best accuracy achieved by state-of-the-art models is\nsubstantially lower on SVAMP, thus showing that much remains to be done even\nfor the simplest of the MWPs.", "published": "2021-03-12 10:23:47", "link": "http://arxiv.org/abs/2103.07191v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Romanization of Arabic Bibliographic Records", "abstract": "International library standards require cataloguers to tediously input\nRomanization of their catalogue records for the benefit of library users\nwithout specific language expertise. In this paper, we present the first\nreported results on the task of automatic Romanization of undiacritized Arabic\nbibliographic entries. This complex task requires the modeling of Arabic\nphonology, morphology, and even semantics. We collected a 2.5M word corpus of\nparallel Arabic and Romanized bibliographic entries, and benchmarked a number\nof models that vary in terms of complexity and resource dependence. Our best\nsystem reaches 89.3% exact word Romanization on a blind test set. We make our\ndata and code publicly available.", "published": "2021-03-12 10:46:32", "link": "http://arxiv.org/abs/2103.07199v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explaining and Improving BERT Performance on Lexical Semantic Change\n  Detection", "abstract": "Type- and token-based embedding architectures are still competing in lexical\nsemantic change detection. The recent success of type-based models in\nSemEval-2020 Task 1 has raised the question why the success of token-based\nmodels on a variety of other NLP tasks does not translate to our field. We\ninvestigate the influence of a range of variables on clusterings of BERT\nvectors and show that its low performance is largely due to orthographic\ninformation on the target word, which is encoded even in the higher layers of\nBERT representations. By reducing the influence of orthography we considerably\nimprove BERT's performance.", "published": "2021-03-12 13:29:30", "link": "http://arxiv.org/abs/2103.07259v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple Post-Processing Technique for Improving Readability Assessment\n  of Texts using Word Mover's Distance", "abstract": "Assessing the proper difficulty levels of reading materials or texts in\ngeneral is the first step towards effective comprehension and learning. In this\nstudy, we improve the conventional methodology of automatic readability\nassessment by incorporating the Word Mover's Distance (WMD) of ranked texts as\nan additional post-processing technique to further ground the difficulty level\ngiven by a model. Results of our experiments on three multilingual datasets in\nFilipino, German, and English show that the post-processing technique\noutperforms previous vanilla and ranking-based models using SVM.", "published": "2021-03-12 13:51:38", "link": "http://arxiv.org/abs/2103.07277v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visual Cues and Error Correction for Translation Robustness", "abstract": "Neural Machine Translation models are sensitive to noise in the input texts,\nsuch as misspelled words and ungrammatical constructions. Existing robustness\ntechniques generally fail when faced with unseen types of noise and their\nperformance degrades on clean texts. In this paper, we focus on three types of\nrealistic noise that are commonly generated by humans and introduce the idea of\nvisual context to improve translation robustness for noisy texts. In addition,\nwe describe a novel error correction training regime that can be used as an\nauxiliary task to further improve translation robustness. Experiments on\nEnglish-French and English-German translation show that both multimodal and\nerror correction components improve model robustness to noisy texts, while\nstill retaining translation quality on clean texts.", "published": "2021-03-12 15:31:34", "link": "http://arxiv.org/abs/2103.07352v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-Shot Text Classification with Triplet Networks, Data Augmentation,\n  and Curriculum Learning", "abstract": "Few-shot text classification is a fundamental NLP task in which a model aims\nto classify text into a large number of categories, given only a few training\nexamples per category. This paper explores data augmentation -- a technique\nparticularly suitable for training with limited data -- for this few-shot,\nhighly-multiclass text classification setting. On four diverse text\nclassification tasks, we find that common data augmentation techniques can\nimprove the performance of triplet networks by up to 3.0% on average.\n  To further boost performance, we present a simple training strategy called\ncurriculum data augmentation, which leverages curriculum learning by first\ntraining on only original examples and then introducing augmented data as\ntraining progresses. We explore a two-stage and a gradual schedule, and find\nthat, compared with standard single-stage training, curriculum data\naugmentation trains faster, improves performance, and remains robust to high\namounts of noising from augmentation.", "published": "2021-03-12 22:07:35", "link": "http://arxiv.org/abs/2103.07552v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Socially Intelligent Agents with Mental State Transition and\n  Human Utility", "abstract": "Building a socially intelligent agent involves many challenges. One of which\nis to track the agent's mental state transition and teach the agent to make\ndecisions guided by its value like a human. Towards this end, we propose to\nincorporate mental state simulation and value modeling into dialogue agents.\nFirst, we build a hybrid mental state parser that extracts information from\nboth the dialogue and event observations and maintains a graphical\nrepresentation of the agent's mind; Meanwhile, the transformer-based value\nmodel learns human preferences from the human value dataset, ValueNet.\nEmpirical results show that the proposed model attains state-of-the-art\nperformance on the dialogue/action/emotion prediction task in the fantasy\ntext-adventure game dataset, LIGHT. We also show example cases to demonstrate:\n(i) how the proposed mental state parser can assist the agent's decision by\ngrounding on the context like locations and objects, and (ii) how the value\nmodel can help the agent make decisions based on its personal priorities.", "published": "2021-03-12 00:06:51", "link": "http://arxiv.org/abs/2103.07011v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Weakly Supervised Approach for Classifying Stance in Twitter Replies", "abstract": "Conversations on social media (SM) are increasingly being used to investigate\nsocial issues on the web, such as online harassment and rumor spread. For such\nissues, a common thread of research uses adversarial reactions, e.g., replies\npointing out factual inaccuracies in rumors. Though adversarial reactions are\nprevalent in online conversations, inferring those adverse views (or stance)\nfrom the text in replies is difficult and requires complex natural language\nprocessing (NLP) models. Moreover, conventional NLP models for stance mining\nneed labeled data for supervised learning. Getting labeled conversations can\nitself be challenging as conversations can be on any topic, and topics change\nover time. These challenges make learning the stance a difficult NLP problem.\n  In this research, we first create a new stance dataset comprised of three\ndifferent topics by labeling both users' opinions on the topics (as in pro/con)\nand users' stance while replying to others' posts (as in favor/oppose). As we\nfind limitations with supervised approaches, we propose a weakly-supervised\napproach to predict the stance in Twitter replies. Our novel method allows\nusing a smaller number of hashtags to generate weak labels for Twitter replies.\nCompared to supervised learning, our method improves the mean F1-macro by 8\\%\non the hand-labeled dataset without using any hand-labeled examples in the\ntraining set. We further show the applicability of our proposed method on COVID\n19 related conversations on Twitter.", "published": "2021-03-12 06:02:45", "link": "http://arxiv.org/abs/2103.07098v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Is BERT a Cross-Disciplinary Knowledge Learner? A Surprising Finding of\n  Pre-trained Models' Transferability", "abstract": "This paper investigates whether the power of the models pre-trained on text\ndata, such as BERT, can be transferred to general token sequence classification\napplications. To verify pre-trained models' transferability, we test the\npre-trained models on text classification tasks with meanings of tokens\nmismatches, and real-world non-text token sequence classification data,\nincluding amino acid, DNA, and music. We find that even on non-text data, the\nmodels pre-trained on text converge faster, perform better than the randomly\ninitialized models, and only slightly worse than the models using task-specific\nknowledge. We also find that the representations of the text and non-text\npre-trained models share non-trivial similarities.", "published": "2021-03-12 09:19:14", "link": "http://arxiv.org/abs/2103.07162v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cooperative Self-training of Machine Reading Comprehension", "abstract": "Pretrained language models have significantly improved the performance of\ndownstream language understanding tasks, including extractive question\nanswering, by providing high-quality contextualized word embeddings. However,\ntraining question answering models still requires large amounts of annotated\ndata for specific domains. In this work, we propose a cooperative self-training\nframework, RGX, for automatically generating more non-trivial question-answer\npairs to improve model performance. RGX is built upon a masked answer\nextraction task with an interactive learning environment containing an answer\nentity Recognizer, a question Generator, and an answer eXtractor. Given a\npassage with a masked entity, the generator generates a question around the\nentity, and the extractor is trained to extract the masked entity with the\ngenerated question and raw texts. The framework allows the training of question\ngeneration and answering models on any text corpora without annotation.\nExperiment results show that RGX outperforms the state-of-the-art (SOTA)\npretrained language models and transfer learning approaches on standard\nquestion-answering benchmarks, and yields the new SOTA performance under given\nmodel size and transfer learning settings.", "published": "2021-03-12 18:22:28", "link": "http://arxiv.org/abs/2103.07449v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Comparing the Performance of NLP Toolkits and Evaluation measures in\n  Legal Tech", "abstract": "Recent developments in Natural Language Processing have led to the\nintroduction of state-of-the-art Neural Language Models, enabled with\nunsupervised transferable learning, using different pretraining objectives.\nWhile these models achieve excellent results on the downstream NLP tasks,\nvarious domain adaptation techniques can improve their performance on\ndomain-specific tasks. We compare and analyze the pretrained Neural Language\nModels, XLNet (autoregressive), and BERT (autoencoder) on the Legal Tasks.\nResults show that XLNet Model performs better on our Sequence Classification\ntask of Legal Opinions Classification, whereas BERT produces better results on\nthe NER task. We use domain-specific pretraining and additional legal\nvocabulary to adapt BERT Model further to the Legal Domain. We prepared\nmultiple variants of the BERT Model, using both methods and their combination.\nComparing our variants of the BERT Model, specializing in the Legal Domain, we\nconclude that both additional pretraining and vocabulary techniques enhance the\nBERT model's performance on the Legal Opinions Classification task. Additional\nlegal vocabulary improves BERT's performance on the NER task. Combining the\npretraining and vocabulary techniques further improves the final results. Our\nLegal-Vocab-BERT Model gives the best results on the Legal Opinions Task,\noutperforming the larger pretrained general Language Models, i.e., BERT-Base\nand XLNet-Base.", "published": "2021-03-12 11:06:32", "link": "http://arxiv.org/abs/2103.11792v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Graph Ensemble Learning over Multiple Dependency Trees for Aspect-level\n  Sentiment Classification", "abstract": "Recent work on aspect-level sentiment classification has demonstrated the\nefficacy of incorporating syntactic structures such as dependency trees with\ngraph neural networks(GNN), but these approaches are usually vulnerable to\nparsing errors. To better leverage syntactic information in the face of\nunavoidable errors, we propose a simple yet effective graph ensemble technique,\nGraphMerge, to make use of the predictions from differ-ent parsers. Instead of\nassigning one set of model parameters to each dependency tree, we first combine\nthe dependency relations from different parses before applying GNNs over the\nresulting graph. This allows GNN mod-els to be robust to parse errors at no\nadditional computational cost, and helps avoid overparameterization and\noverfitting from GNN layer stacking by introducing more connectivity into the\nensemble graph. Our experiments on the SemEval 2014 Task 4 and ACL 14 Twitter\ndatasets show that our GraphMerge model not only outperforms models with single\ndependency tree, but also beats other ensemble mod-els without adding model\nparameters.", "published": "2021-03-12 22:27:23", "link": "http://arxiv.org/abs/2103.11794v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bilingual Dictionary-based Language Model Pretraining for Neural Machine\n  Translation", "abstract": "Recent studies have demonstrated a perceivable improvement on the performance\nof neural machine translation by applying cross-lingual language model\npretraining (Lample and Conneau, 2019), especially the Translation Language\nModeling (TLM). To alleviate the need for expensive parallel corpora by TLM, in\nthis work, we incorporate the translation information from dictionaries into\nthe pretraining process and propose a novel Bilingual Dictionary-based Language\nModel (BDLM). We evaluate our BDLM in Chinese, English, and Romanian. For\nChinese-English, we obtained a 55.0 BLEU on WMT-News19 (Tiedemann, 2012) and a\n24.3 BLEU on WMT20 news-commentary, outperforming the Vanilla Transformer\n(Vaswani et al., 2017) by more than 8.4 BLEU and 2.3 BLEU, respectively.\nAccording to our results, the BDLM also has advantages on convergence speed and\npredicting rare words. The increase in BLEU for WMT16 Romanian-English also\nshows its effectiveness in low-resources language translation.", "published": "2021-03-12 02:01:22", "link": "http://arxiv.org/abs/2103.07040v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Authorship Verification using Linguistic Divergence", "abstract": "We propose an unsupervised solution to the Authorship Verification task that\nutilizes pre-trained deep language models to compute a new metric called\nDV-Distance. The proposed metric is a measure of the difference between the two\nauthors comparing against pre-trained language models. Our design addresses the\nproblem of non-comparability in authorship verification, frequently encountered\nin small or cross-domain corpora. To the best of our knowledge, this paper is\nthe first one to introduce a method designed with non-comparability in mind\nfrom the ground up, rather than indirectly. It is also one of the first to use\nDeep Language Models in this setting. The approach is intuitive, and it is easy\nto understand and interpret through visualization. Experiments on four datasets\nshow our methods matching or surpassing current state-of-the-art and strong\nbaselines in most tasks.", "published": "2021-03-12 03:01:17", "link": "http://arxiv.org/abs/2103.07052v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dynamic Acoustic Unit Augmentation With BPE-Dropout for Low-Resource\n  End-to-End Speech Recognition", "abstract": "With the rapid development of speech assistants, adapting server-intended\nautomatic speech recognition (ASR) solutions to a direct device has become\ncrucial. Researchers and industry prefer to use end-to-end ASR systems for\non-device speech recognition tasks. This is because end-to-end systems can be\nmade resource-efficient while maintaining a higher quality compared to hybrid\nsystems. However, building end-to-end models requires a significant amount of\nspeech data. Another challenging task associated with speech assistants is\npersonalization, which mainly lies in handling out-of-vocabulary (OOV) words.\nIn this work, we consider building an effective end-to-end ASR system in\nlow-resource setups with a high OOV rate, embodied in Babel Turkish and Babel\nGeorgian tasks. To address the aforementioned problems, we propose a method of\ndynamic acoustic unit augmentation based on the BPE-dropout technique. It\nnon-deterministically tokenizes utterances to extend the token's contexts and\nto regularize their distribution for the model's recognition of unseen words.\nIt also reduces the need for optimal subword vocabulary size search. The\ntechnique provides a steady improvement in regular and personalized\n(OOV-oriented) speech recognition tasks (at least 6% relative WER and 25%\nrelative F-score) at no additional computational cost. Owing to the use of\nBPE-dropout, our monolingual Turkish Conformer established a competitive result\nwith 22.2% character error rate (CER) and 38.9% word error rate (WER), which is\nclose to the best published multilingual system.", "published": "2021-03-12 10:10:13", "link": "http://arxiv.org/abs/2103.07186v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Abolitionist Networks: Modeling Language Change in Nineteenth-Century\n  Activist Newspapers", "abstract": "The abolitionist movement of the nineteenth-century United States remains\namong the most significant social and political movements in US history.\nAbolitionist newspapers played a crucial role in spreading information and\nshaping public opinion around a range of issues relating to the abolition of\nslavery. These newspapers also serve as a primary source of information about\nthe movement for scholars today, resulting in powerful new accounts of the\nmovement and its leaders. This paper supplements recent qualitative work on the\nrole of women in abolition's vanguard, as well as the role of the Black press,\nwith a quantitative text modeling approach. Using diachronic word embeddings,\nwe identify which newspapers tended to lead lexical semantic innovations -- the\nintroduction of new usages of specific words -- and which newspapers tended to\nfollow. We then aggregate the evidence across hundreds of changes into a\nweighted network with the newspapers as nodes; directed edge weights represent\nthe frequency with which each newspaper led the other in the adoption of a\nlexical semantic change. Analysis of this network reveals pathways of lexical\nsemantic influence, distinguishing leaders from followers, as well as others\nwho stood apart from the semantic changes that swept through this period. More\nspecifically, we find that two newspapers edited by women -- THE PROVINCIAL\nFREEMAN and THE LILY -- led a large number of semantic changes in our corpus,\nlending additional credence to the argument that a multiracial coalition of\nwomen led the abolitionist movement in terms of both thought and action. It\nalso contributes additional complexity to the scholarship that has sought to\ntease apart the relation of the abolitionist movement to the women's suffrage\nmovement, and the vexed racial politics that characterized their relation.", "published": "2021-03-12 21:26:30", "link": "http://arxiv.org/abs/2103.07538v1", "categories": ["cs.CL", "cs.CY", "cs.DL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "A Distributed Optimisation Framework Combining Natural Gradient with\n  Hessian-Free for Discriminative Sequence Training", "abstract": "This paper presents a novel natural gradient and Hessian-free (NGHF)\noptimisation framework for neural network training that can operate efficiently\nin a distributed manner. It relies on the linear conjugate gradient (CG)\nalgorithm to combine the natural gradient (NG) method with local curvature\ninformation from Hessian-free (HF) or other second-order methods. A solution to\na numerical issue in CG allows effective parameter updates to be generated with\nfar fewer CG iterations than usually used (e.g. 5-8 instead of 200). This work\nalso presents a novel preconditioning approach to improve the progress made by\nindividual CG iterations for models with shared parameters. Although applicable\nto other training losses and model structures, NGHF is investigated in this\npaper for lattice-based discriminative sequence training for hybrid hidden\nMarkov model acoustic models using a standard recurrent neural network, long\nshort-term memory, and time delay neural network models for output probability\ncalculation. Automatic speech recognition experiments are reported on the\nmulti-genre broadcast data set for a range of different acoustic model types.\nThese experiments show that NGHF achieves larger word error rate reductions\nthan standard stochastic gradient descent or Adam, while requiring orders of\nmagnitude fewer parameter updates.", "published": "2021-03-12 22:18:34", "link": "http://arxiv.org/abs/2103.07554v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Privacy Regularization: Joint Privacy-Utility Optimization in Language\n  Models", "abstract": "Neural language models are known to have a high capacity for memorization of\ntraining samples. This may have serious privacy implications when training\nmodels on user content such as email correspondence. Differential privacy (DP),\na popular choice to train models with privacy guarantees, comes with\nsignificant costs in terms of utility degradation and disparate impact on\nsubgroups of users. In this work, we introduce two privacy-preserving\nregularization methods for training language models that enable joint\noptimization of utility and privacy through (1) the use of a discriminator and\n(2) the inclusion of a triplet-loss term. We compare our methods with DP\nthrough extensive evaluation. We show the advantages of our regularizers with\nfavorable utility-privacy trade-off, faster training with the ability to tap\ninto existing optimization approaches, and ensuring uniform treatment of\nunder-represented subgroups.", "published": "2021-03-12 23:17:43", "link": "http://arxiv.org/abs/2103.07567v2", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "A Review on Semi-Supervised Relation Extraction", "abstract": "Relation extraction (RE) plays an important role in extracting knowledge from\nunstructured text but requires a large amount of labeled corpus. To reduce the\nexpensive annotation efforts, semisupervised learning aims to leverage both\nlabeled and unlabeled data. In this paper, we review and compare three typical\nmethods in semi-supervised RE with deep learning or meta-learning:\nself-ensembling, which forces consistent under perturbations but may confront\ninsufficient supervision; self-training, which iteratively generates pseudo\nlabels and retrain itself with the enlarged labeled set; dual learning, which\nleverages a primal task and a dual task to give mutual feedback. Mean-teacher\n(Tarvainen and Valpola, 2017), LST (Li et al., 2019), and DualRE (Lin et al.,\n2019) are elaborated as the representatives to alleviate the weakness of these\nthree methods, respectively.", "published": "2021-03-12 23:43:23", "link": "http://arxiv.org/abs/2103.07575v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Learning spectro-temporal representations of complex sounds with\n  parameterized neural networks", "abstract": "Deep Learning models have become potential candidates for auditory\nneuroscience research, thanks to their recent successes on a variety of\nauditory tasks. Yet, these models often lack interpretability to fully\nunderstand the exact computations that have been performed. Here, we proposed a\nparametrized neural network layer, that computes specific spectro-temporal\nmodulations based on Gabor kernels (Learnable STRFs) and that is fully\ninterpretable. We evaluated predictive capabilities of this layer on Speech\nActivity Detection, Speaker Verification, Urban Sound Classification and Zebra\nFinch Call Type Classification. We found out that models based on Learnable\nSTRFs are on par for all tasks with different toplines, and obtain the best\nperformance for Speech Activity Detection. As this layer is fully\ninterpretable, we used quantitative measures to describe the distribution of\nthe learned spectro-temporal modulations. The filters adapted to each task and\nfocused mostly on low temporal and spectral modulations. The analyses show that\nthe filters learned on human speech have similar spectro-temporal parameters as\nthe ones measured directly in the human auditory cortex. Finally, we observed\nthat the tasks organized in a meaningful way: the human vocalizations tasks\ncloser to each other and bird vocalizations far away from human vocalizations\nand urban sounds tasks.", "published": "2021-03-12 07:53:47", "link": "http://arxiv.org/abs/2103.07125v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Latent Space Explorations of Singing Voice Synthesis using DDSP", "abstract": "Machine learning based singing voice models require large datasets and\nlengthy training times. In this work we present a lightweight architecture,\nbased on the Differentiable Digital Signal Processing (DDSP) library, that is\nable to output song-like utterances conditioned only on pitch and amplitude,\nafter twelve hours of training using small datasets of unprocessed audio. The\nresults are promising, as both the melody and the singer's voice are\nrecognizable. In addition, we present two zero-configuration tools to train new\nmodels and experiment with them. Currently we are exploring the latent space\nrepresentation, which is included in the DDSP library, but not in the original\nDDSP examples. Our results indicate that the latent space improves both the\nidentification of the singer as well as the comprehension of the lyrics. Our\ncode is available at https://github.com/juanalonso/DDSP-singing-experiments\nwith links to the zero-configuration notebooks, and our sound examples are at\nhttps://juanalonso.github.io/DDSP-singing-experiments/ .", "published": "2021-03-12 10:38:29", "link": "http://arxiv.org/abs/2103.07197v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Real-time Timbre Transfer and Sound Synthesis using DDSP", "abstract": "Neural audio synthesis is an actively researched topic, having yielded a wide\nrange of techniques that leverages machine learning architectures. Google\nMagenta elaborated a novel approach called Differential Digital Signal\nProcessing (DDSP) that incorporates deep neural networks with preconditioned\ndigital signal processing techniques, reaching state-of-the-art results\nespecially in timbre transfer applications. However, most of these techniques,\nincluding the DDSP, are generally not applicable in real-time constraints,\nmaking them ineligible in a musical workflow. In this paper, we present a\nreal-time implementation of the DDSP library embedded in a virtual synthesizer\nas a plug-in that can be used in a Digital Audio Workstation. We focused on\ntimbre transfer from learned representations of real instruments to arbitrary\nsound inputs as well as controlling these models by MIDI. Furthermore, we\ndeveloped a GUI for intuitive high-level controls which can be used for\npost-processing and manipulating the parameters estimated by the neural\nnetwork. We have conducted a user experience test with seven participants\nonline. The results indicated that our users found the interface appealing,\neasy to understand, and worth exploring further. At the same time, we have\nidentified issues in the timbre transfer quality, in some components we did not\nimplement, and in installation and distribution of our plugin. The next\niteration of our design will address these issues. Our real-time MATLAB and\nJUCE implementations are available at https://github.com/SMC704/juce-ddsp and\nhttps://github.com/SMC704/matlab-ddsp , respectively.", "published": "2021-03-12 11:49:51", "link": "http://arxiv.org/abs/2103.07220v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Modelling Animal Biodiversity Using Acoustic Monitoring and Deep\n  Learning", "abstract": "For centuries researchers have used sound to monitor and study wildlife.\nTraditionally, conservationists have identified species by ear; however, it is\nnow common to deploy audio recording technology to monitor animal and ecosystem\nsounds. Animals use sound for communication, mating, navigation and territorial\ndefence. Animal sounds provide valuable information and help conservationists\nto quantify biodiversity. Acoustic monitoring has grown in popularity due to\nthe availability of diverse sensor types which include camera traps, portable\nacoustic sensors, passive acoustic sensors, and even smartphones. Passive\nacoustic sensors are easy to deploy and can be left running for long durations\nto provide insights on habitat and the sounds made by animals and illegal\nactivity. While this technology brings enormous benefits, the amount of data\nthat is generated makes processing a time-consuming process for\nconservationists. Consequently, there is interest among conservationists to\nautomatically process acoustic data to help speed up biodiversity assessments.\nProcessing these large data sources and extracting relevant sounds from\nbackground noise introduces significant challenges. In this paper we outline an\napproach for achieving this using state of the art in machine learning to\nautomatically extract features from time-series audio signals and modelling\ndeep learning models to classify different bird species based on the sounds\nthey make. The acquired bird songs are processed using mel-frequency cepstrum\n(MFC) to extract features which are later classified using a multilayer\nperceptron (MLP). Our proposed method achieved promising results with 0.74\nsensitivity, 0.92 specificity and an accuracy of 0.74.", "published": "2021-03-12 13:50:31", "link": "http://arxiv.org/abs/2103.07276v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Signal Representations for Synthesizing Audio Textures with Generative\n  Adversarial Networks", "abstract": "Generative Adversarial Networks (GANs) currently achieve the state-of-the-art\nsound synthesis quality for pitched musical instruments using a 2-channel\nspectrogram representation consisting of log magnitude and instantaneous\nfrequency (the \"IFSpectrogram\"). Many other synthesis systems use\nrepresentations derived from the magnitude spectra, and then depend on a\nbackend component to invert the output magnitude spectrograms that generally\nresult in audible artefacts associated with the inversion process. However, for\nsignals that have closely-spaced frequency components such as non-pitched and\nother noisy sounds, training the GAN on the 2-channel IFSpectrogram\nrepresentation offers no advantage over the magnitude spectra based\nrepresentations. In this paper, we propose that training GANs on single-channel\nmagnitude spectra, and using the Phase Gradient Heap Integration (PGHI)\ninversion algorithm is a better comprehensive approach for audio synthesis\nmodeling of diverse signals that include pitched, non-pitched, and dynamically\ncomplex sounds. We show that this method produces higher-quality output for\nwideband and noisy sounds, such as pops and chirps, compared to using the\nIFSpectrogram. Furthermore, the sound quality for pitched sounds is comparable\nto using the IFSpectrogram, even while using a simpler representation with half\nthe memory requirements.", "published": "2021-03-12 16:31:20", "link": "http://arxiv.org/abs/2103.07390v1", "categories": ["eess.AS", "cs.MM", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
