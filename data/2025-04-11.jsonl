{"title": "Towards an Understanding of Context Utilization in Code Intelligence", "abstract": "Code intelligence is an emerging domain in software engineering, aiming to\nimprove the effectiveness and efficiency of various code-related tasks. Recent\nresearch suggests that incorporating contextual information beyond the basic\noriginal task inputs (i.e., source code) can substantially enhance model\nperformance. Such contextual signals may be obtained directly or indirectly\nfrom sources such as API documentation or intermediate representations like\nabstract syntax trees can significantly improve the effectiveness of code\nintelligence. Despite growing academic interest, there is a lack of systematic\nanalysis of context in code intelligence. To address this gap, we conduct an\nextensive literature review of 146 relevant studies published between September\n2007 and August 2024. Our investigation yields four main contributions. (1) A\nquantitative analysis of the research landscape, including publication trends,\nvenues, and the explored domains; (2) A novel taxonomy of context types used in\ncode intelligence; (3) A task-oriented analysis investigating context\nintegration strategies across diverse code intelligence tasks; (4) A critical\nevaluation of evaluation methodologies for context-aware methods. Based on\nthese findings, we identify fundamental challenges in context utilization in\ncurrent code intelligence systems and propose a research roadmap that outlines\nkey opportunities for future research.", "published": "2025-04-11 17:59:53", "link": "http://arxiv.org/abs/2504.08734v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "DocAgent: A Multi-Agent System for Automated Code Documentation Generation", "abstract": "High-quality code documentation is crucial for software development\nespecially in the era of AI. However, generating it automatically using Large\nLanguage Models (LLMs) remains challenging, as existing approaches often\nproduce incomplete, unhelpful, or factually incorrect outputs. We introduce\nDocAgent, a novel multi-agent collaborative system using topological code\nprocessing for incremental context building. Specialized agents (Reader,\nSearcher, Writer, Verifier, Orchestrator) then collaboratively generate\ndocumentation. We also propose a multi-faceted evaluation framework assessing\nCompleteness, Helpfulness, and Truthfulness. Comprehensive experiments show\nDocAgent significantly outperforms baselines consistently. Our ablation study\nconfirms the vital role of the topological processing order. DocAgent offers a\nrobust approach for reliable code documentation generation in complex and\nproprietary repositories.", "published": "2025-04-11 17:50:08", "link": "http://arxiv.org/abs/2504.08725v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "SWAN-GPT: An Efficient and Scalable Approach for Long-Context Language Modeling", "abstract": "We present a decoder-only Transformer architecture that robustly generalizes\nto sequence lengths substantially longer than those seen during training. Our\nmodel, SWAN-GPT, interleaves layers without positional encodings (NoPE) and\nsliding-window attention layers equipped with rotary positional encodings\n(SWA-RoPE). Experiments demonstrate strong performance on sequence lengths\nsignificantly longer than the training length without the need for additional\nlong-context training. This robust length extrapolation is achieved through our\nnovel architecture, enhanced by a straightforward dynamic scaling of attention\nscores during inference. In addition, SWAN-GPT is more computationally\nefficient than standard GPT architectures, resulting in cheaper training and\nhigher throughput. Further, we demonstrate that existing pre-trained\ndecoder-only models can be efficiently converted to the SWAN architecture with\nminimal continued training, enabling longer contexts. Overall, our work\npresents an effective approach for scaling language models to longer contexts\nin a robust and efficient manner.", "published": "2025-04-11 17:33:32", "link": "http://arxiv.org/abs/2504.08719v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ModernBERT or DeBERTaV3? Examining Architecture and Data Influence on Transformer Encoder Models Performance", "abstract": "Pretrained transformer-encoder models like DeBERTaV3 and ModernBERT introduce\narchitectural advancements aimed at improving efficiency and performance.\nAlthough the authors of ModernBERT report improved performance over DeBERTaV3\non several benchmarks, the lack of disclosed training data and the absence of\ncomparisons using a shared dataset make it difficult to determine whether these\ngains are due to architectural improvements or differences in training data. In\nthis work, we conduct a controlled study by pretraining ModernBERT on the same\ndataset as CamemBERTaV2, a DeBERTaV3 French model, isolating the effect of\nmodel design. Our results show that the previous model generation remains\nsuperior in sample efficiency and overall benchmark performance, with\nModernBERT's primary advantage being faster training and inference speed.\nHowever, the new proposed model still provides meaningful architectural\nimprovements compared to earlier models such as BERT and RoBERTa. Additionally,\nwe observe that high-quality pre-training data accelerates convergence but does\nnot significantly improve final performance, suggesting potential benchmark\nsaturation. These findings show the importance of disentangling pretraining\ndata from architectural innovations when evaluating transformer models.", "published": "2025-04-11 17:29:35", "link": "http://arxiv.org/abs/2504.08716v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Fine Details of Entity Interactions", "abstract": "Images not only depict objects but also encapsulate rich interactions between\nthem. However, generating faithful and high-fidelity images involving multiple\nentities interacting with each other, is a long-standing challenge. While\npre-trained text-to-image models are trained on large-scale datasets to follow\ndiverse text instructions, they struggle to generate accurate interactions,\nlikely due to the scarcity of training data for uncommon object interactions.\nThis paper introduces InterActing, an interaction-focused dataset with 1000\nfine-grained prompts covering three key scenarios: (1) functional and\naction-based interactions, (2) compositional spatial relationships, and (3)\nmulti-subject interactions. To address interaction generation challenges, we\npropose a decomposition-augmented refinement procedure. Our approach,\nDetailScribe, built on Stable Diffusion 3.5, leverages LLMs to decompose\ninteractions into finer-grained concepts, uses a VLM to critique generated\nimages, and applies targeted interventions within the diffusion process in\nrefinement. Automatic and human evaluations show significantly improved image\nquality, demonstrating the potential of enhanced inference strategies. Our\ndataset and code are available at https://concepts-ai.com/p/detailscribe/ to\nfacilitate future exploration of interaction-rich image generation.", "published": "2025-04-11 17:24:58", "link": "http://arxiv.org/abs/2504.08714v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Large Language Models as Span Annotators", "abstract": "For high-quality texts, single-score metrics seldom provide actionable\nfeedback. In contrast, span annotation - pointing out issues in the text by\nannotating their spans - can guide improvements and provide insights. Until\nrecently, span annotation was limited to human annotators or fine-tuned encoder\nmodels. In this study, we automate span annotation with large language models\n(LLMs). We compare expert or skilled crowdworker annotators with open and\nproprietary LLMs on three tasks: data-to-text generation evaluation, machine\ntranslation evaluation, and propaganda detection in human-written texts. In our\nexperiments, we show that LLMs as span annotators are straightforward to\nimplement and notably more cost-efficient than human annotators. The LLMs\nachieve moderate agreement with skilled human annotators, in some scenarios\ncomparable to the average agreement among the annotators themselves.\nQualitative analysis shows that reasoning models outperform their\ninstruction-tuned counterparts and provide more valid explanations for\nannotations. We release the dataset of more than 40k model and human\nannotations for further research.", "published": "2025-04-11 17:04:51", "link": "http://arxiv.org/abs/2504.08697v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TP-RAG: Benchmarking Retrieval-Augmented Large Language Model Agents for Spatiotemporal-Aware Travel Planning", "abstract": "Large language models (LLMs) have shown promise in automating travel\nplanning, yet they often fall short in addressing nuanced spatiotemporal\nrationality. While existing benchmarks focus on basic plan validity, they\nneglect critical aspects such as route efficiency, POI appeal, and real-time\nadaptability. This paper introduces TP-RAG, the first benchmark tailored for\nretrieval-augmented, spatiotemporal-aware travel planning. Our dataset includes\n2,348 real-world travel queries, 85,575 fine-grain annotated POIs, and 18,784\nhigh-quality travel trajectory references sourced from online tourist\ndocuments, enabling dynamic and context-aware planning. Through extensive\nexperiments, we reveal that integrating reference trajectories significantly\nimproves spatial efficiency and POI rationality of the travel plan, while\nchallenges persist in universality and robustness due to conflicting references\nand noisy data. To address these issues, we propose EvoRAG, an evolutionary\nframework that potently synergizes diverse retrieved trajectories with LLMs'\nintrinsic reasoning. EvoRAG achieves state-of-the-art performance, improving\nspatiotemporal compliance and reducing commonsense violation compared to\nground-up and retrieval-augmented baselines. Our work underscores the potential\nof hybridizing Web knowledge with LLM-driven optimization, paving the way for\nmore reliable and adaptive travel planning agents.", "published": "2025-04-11 17:02:40", "link": "http://arxiv.org/abs/2504.08694v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fast-Slow-Thinking: Complex Task Solving with Large Language Models", "abstract": "Nowadays, Large Language Models (LLMs) have been gradually employed to solve\ncomplex tasks. To face the challenge, task decomposition has become an\neffective way, which proposes to divide a complex task into multiple simpler\nsubtasks and then solve them separately so that the difficulty of the original\ntask can be reduced. However, the performance of existing task decomposition\nmethods can be suboptimal when the task contains overly complex logic and\nconstraints. In this situation, the solution generated by LLMs may deviate from\nthe original purpose of the task, or contain redundant or even erroneous\ncontent. Therefore, inspired by the fact that humans possess two thinking\nsystems including fast thinking and slow thinking, this paper introduces a new\ntask decomposition method termed ``Fast-Slow-Thinking'' (FST), which stimulates\nLLMs to solve tasks through the cooperation of Fast Thinking (FT) and Slow\nThinking (ST) steps. Here FT focuses more on the general and concise aspect of\nthe task, and ST focuses more on the details of the task. In FT, LLMs are\nprompted to remove the constraints of the original task, therefore simplifying\nit to a general and concise one. In ST, we recall the constraints removed in\nFT, so that LLMs can improve the answer generated in FT to meet the\nrequirements of the original task. Therefore, our FST method enables LLMs to\nconsider a complex problem via a human-like cognition process from coarse to\nfine, the effectiveness of which has been well demonstrated by the experiments\non three types of tasks.", "published": "2025-04-11 16:57:36", "link": "http://arxiv.org/abs/2504.08690v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Genius: A Generalizable and Purely Unsupervised Self-Training Framework For Advanced Reasoning", "abstract": "Advancing LLM reasoning skills has captivated wide interest. However, current\npost-training techniques rely heavily on supervisory signals, such as outcome\nsupervision or auxiliary reward models, which face the problem of scalability\nand high annotation costs. This motivates us to enhance LLM reasoning without\nthe need for external supervision. We introduce a generalizable and purely\nunsupervised self-training framework, named Genius. Without external auxiliary,\nGenius requires to seek the optimal response sequence in a stepwise manner and\noptimize the LLM. To explore the potential steps and exploit the optimal ones,\nGenius introduces a stepwise foresight re-sampling strategy to sample and\nestimate the step value by simulating future outcomes. Further, we recognize\nthat the unsupervised setting inevitably induces the intrinsic noise and\nuncertainty. To provide a robust optimization, we propose an\nadvantage-calibrated optimization (ACO) loss function to mitigate estimation\ninconsistencies. Combining these techniques together, Genius provides an\nadvanced initial step towards self-improve LLM reasoning with general queries\nand without supervision, revolutionizing reasoning scaling laws given the vast\navailability of general queries. The code will be released at\nhttps://github.com/xufangzhi/Genius.", "published": "2025-04-11 16:26:23", "link": "http://arxiv.org/abs/2504.08672v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Training-free Guidance in Text-to-Video Generation via Multimodal Planning and Structured Noise Initialization", "abstract": "Recent advancements in text-to-video (T2V) diffusion models have\nsignificantly enhanced the visual quality of the generated videos. However,\neven recent T2V models find it challenging to follow text descriptions\naccurately, especially when the prompt requires accurate control of spatial\nlayouts or object trajectories. A recent line of research uses layout guidance\nfor T2V models that require fine-tuning or iterative manipulation of the\nattention map during inference time. This significantly increases the memory\nrequirement, making it difficult to adopt a large T2V model as a backbone. To\naddress this, we introduce Video-MSG, a training-free Guidance method for T2V\ngeneration based on Multimodal planning and Structured noise initialization.\nVideo-MSG consists of three steps, where in the first two steps, Video-MSG\ncreates Video Sketch, a fine-grained spatio-temporal plan for the final video,\nspecifying background, foreground, and object trajectories, in the form of\ndraft video frames. In the last step, Video-MSG guides a downstream T2V\ndiffusion model with Video Sketch through noise inversion and denoising.\nNotably, Video-MSG does not need fine-tuning or attention manipulation with\nadditional memory during inference time, making it easier to adopt large T2V\nmodels. Video-MSG demonstrates its effectiveness in enhancing text alignment\nwith multiple T2V backbones (VideoCrafter2 and CogVideoX-5B) on popular T2V\ngeneration benchmarks (T2VCompBench and VBench). We provide comprehensive\nablation studies about noise inversion ratio, different background generators,\nbackground object detection, and foreground object segmentation.", "published": "2025-04-11 15:41:43", "link": "http://arxiv.org/abs/2504.08641v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Analyzing 16,193 LLM Papers for Fun and Profits", "abstract": "Large Language Models (LLMs) are reshaping the landscape of computer science\nresearch, driving significant shifts in research priorities across diverse\nconferences and fields. This study provides a comprehensive analysis of the\npublication trend of LLM-related papers in 77 top-tier computer science\nconferences over the past six years (2019-2024). We approach this analysis from\nfour distinct perspectives: (1) We investigate how LLM research is driving\ntopic shifts within major conferences. (2) We adopt a topic modeling approach\nto identify various areas of LLM-related topic growth and reveal the topics of\nconcern at different conferences. (3) We explore distinct contribution patterns\nof academic and industrial institutions. (4) We study the influence of national\norigins on LLM development trajectories. Synthesizing the findings from these\ndiverse analytical angles, we derive ten key insights that illuminate the\ndynamics and evolution of the LLM research ecosystem.", "published": "2025-04-11 15:24:23", "link": "http://arxiv.org/abs/2504.08619v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "A Survey of Machine Learning Models and Datasets for the Multi-label Classification of Textual Hate Speech in English", "abstract": "The dissemination of online hate speech can have serious negative\nconsequences for individuals, online communities, and entire societies. This\nand the large volume of hateful online content prompted both practitioners',\ni.e., in content moderation or law enforcement, and researchers' interest in\nmachine learning models to automatically classify instances of hate speech.\nWhereas most scientific works address hate speech classification as a binary\ntask, practice often requires a differentiation into sub-types, e.g., according\nto target, severity, or legality, which may overlap for individual content.\nHence, researchers created datasets and machine learning models that approach\nhate speech classification in textual data as a multi-label problem. This work\npresents the first systematic and comprehensive survey of scientific literature\non this emerging research landscape in English (N=46). We contribute with a\nconcise overview of 28 datasets suited for training multi-label classification\nmodels that reveals significant heterogeneity regarding label-set, size,\nmeta-concept, annotation process, and inter-annotator agreement. Our analysis\nof 24 publications proposing suitable classification models further establishes\ninconsistency in evaluation and a preference for architectures based on\nBidirectional Encoder Representation from Transformers (BERT) and Recurrent\nNeural Networks (RNNs). We identify imbalanced training data, reliance on\ncrowdsourcing platforms, small and sparse datasets, and missing methodological\nalignment as critical open issues and formulate ten recommendations for\nresearch.", "published": "2025-04-11 15:16:31", "link": "http://arxiv.org/abs/2504.08609v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MedHal: An Evaluation Dataset for Medical Hallucination Detection", "abstract": "We present MedHal, a novel large-scale dataset specifically designed to\nevaluate if models can detect hallucinations in medical texts. Current\nhallucination detection methods face significant limitations when applied to\nspecialized domains like medicine, where they can have disastrous consequences.\nExisting medical datasets are either too small, containing only a few hundred\nsamples, or focus on a single task like Question Answering or Natural Language\nInference. MedHal addresses these gaps by: (1) incorporating diverse medical\ntext sources and tasks; (2) providing a substantial volume of annotated samples\nsuitable for training medical hallucination detection models; and (3) including\nexplanations for factual inconsistencies to guide model learning. We\ndemonstrate MedHal's utility by training and evaluating a baseline medical\nhallucination detection model, showing improvements over general-purpose\nhallucination detection approaches. This resource enables more efficient\nevaluation of medical text generation systems while reducing reliance on costly\nexpert review, potentially accelerating the development of medical AI research.", "published": "2025-04-11 14:55:15", "link": "http://arxiv.org/abs/2504.08596v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Playpen: An Environment for Exploring Learning Through Conversational Interaction", "abstract": "Are we running out of learning signal? Predicting the next word in an\nexisting text has turned out to be a powerful signal, at least at scale. But\nthere are signs that we are running out of this resource. In recent months,\ninteraction between learner and feedback-giver has come into focus, both for\n\"alignment\" (with a reward model judging the quality of instruction following\nattempts) and for improving \"reasoning\" (process- and outcome-based verifiers\njudging reasoning steps). In this paper, we explore to what extent synthetic\ninteraction in what we call Dialogue Games -- goal-directed and rule-governed\nactivities driven predominantly by verbal actions -- can provide a learning\nsignal, and how this signal can be used. We introduce an environment for\nproducing such interaction data (with the help of a Large Language Model as\ncounterpart to the learner model), both offline and online. We investigate the\neffects of supervised fine-tuning on this data, as well as reinforcement\nlearning setups such as DPO, and GRPO; showing that all of these approaches\nachieve some improvements in in-domain games, but only GRPO demonstrates the\nability to generalise to out-of-domain games as well as retain competitive\nperformance in reference-based tasks. We release the framework and the baseline\ntraining setups in the hope that this can foster research in this promising new\ndirection.", "published": "2025-04-11 14:49:33", "link": "http://arxiv.org/abs/2504.08590v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UoB-NLP at SemEval-2025 Task 11: Leveraging Adapters for Multilingual and Cross-Lingual Emotion Detection", "abstract": "Emotion detection in natural language processing is a challenging task due to\nthe complexity of human emotions and linguistic diversity. While significant\nprogress has been made in high-resource languages, emotion detection in\nlow-resource languages remains underexplored. In this work, we address\nmultilingual and cross-lingual emotion detection by leveraging adapter-based\nfine-tuning with multilingual pre-trained language models. Adapters introduce a\nsmall number of trainable parameters while keeping the pre-trained model\nweights fixed, offering a parameter-efficient approach to adaptation. We\nexperiment with different adapter tuning strategies, including task-only\nadapters, target-language-ready task adapters, and language-family-based\nadapters. Our results show that target-language-ready task adapters achieve the\nbest overall performance, particularly for low-resource African languages with\nour team ranking 7th for Tigrinya, and 8th for Kinyarwanda in Track A. In Track\nC, our system ranked 3rd for Amharic, and 4th for Oromo, Tigrinya, Kinyarwanda,\nHausa, and Igbo. Our approach outperforms large language models in 11 languages\nand matches their performance in four others, despite our models having\nsignificantly fewer parameters. Furthermore, we find that adapter-based models\nretain cross-linguistic transfer capabilities while requiring fewer\ncomputational resources compared to full fine-tuning for each language.", "published": "2025-04-11 13:56:44", "link": "http://arxiv.org/abs/2504.08543v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lexical Bundle Frequency as a Construct-Relevant Candidate Feature in Automated Scoring of L2 Academic Writing", "abstract": "Automated scoring (AS) systems are increasingly used for evaluating L2\nwriting, but require ongoing refinement for construct validity. While prior\nwork suggested lexical bundles (LBs) - recurrent multi-word sequences\nsatisfying certain frequency criteria - could inform assessment, their\nempirical integration into AS models needs further investigation. This study\ntested the impact of incorporating LB frequency features into an AS model for\nTOEFL independent writing tasks. Analyzing a sampled subcorpus (N=1,225 essays,\n9 L1s) from the TOEFL11 corpus, scored by ETS-trained raters (Low, Medium,\nHigh), 3- to 9-word LBs were extracted, distinguishing prompt-specific from\nnon-prompt types. A baseline Support Vector Machine (SVM) scoring model using\nestablished linguistic features (e.g., mechanics, cohesion, sophistication) was\ncompared against an extended model including three aggregate LB frequency\nfeatures (total prompt, total non-prompt, overall total). Results revealed\nsignificant, though generally small-effect, relationships between LB frequency\n(especially non-prompt bundles) and proficiency (p < .05). Mean frequencies\nsuggested lower proficiency essays used more LBs overall. Critically, the\nLB-enhanced model improved agreement with human raters (Quadratic Cohen's Kappa\n+2.05%, overall Cohen's Kappa +5.63%), with notable gains for low (+10.1% exact\nagreement) and medium (+14.3% Cohen's Kappa) proficiency essays. These findings\ndemonstrate that integrating aggregate LB frequency offers potential for\ndeveloping more linguistically informed and accurate AS systems, particularly\nfor differentiating developing L2 writers.", "published": "2025-04-11 13:47:56", "link": "http://arxiv.org/abs/2504.08537v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On The Landscape of Spoken Language Models: A Comprehensive Survey", "abstract": "The field of spoken language processing is undergoing a shift from training\ncustom-built, task-specific models toward using and optimizing spoken language\nmodels (SLMs) which act as universal speech processing systems. This trend is\nsimilar to the progression toward universal language models that has taken\nplace in the field of (text) natural language processing. SLMs include both\n\"pure\" language models of speech -- models of the distribution of tokenized\nspeech sequences -- and models that combine speech encoders with text language\nmodels, often including both spoken and written input or output. Work in this\narea is very diverse, with a range of terminology and evaluation settings. This\npaper aims to contribute an improved understanding of SLMs via a unifying\nliterature survey of recent work in the context of the evolution of the field.\nOur survey categorizes the work in this area by model architecture, training,\nand evaluation choices, and describes some key challenges and directions for\nfuture work.", "published": "2025-04-11 13:40:53", "link": "http://arxiv.org/abs/2504.08528v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Integrated ensemble of BERT- and features-based models for authorship attribution in Japanese literary works", "abstract": "Traditionally, authorship attribution (AA) tasks relied on statistical data\nanalysis and classification based on stylistic features extracted from texts.\nIn recent years, pre-trained language models (PLMs) have attracted significant\nattention in text classification tasks. However, although they demonstrate\nexcellent performance on large-scale short-text datasets, their effectiveness\nremains under-explored for small samples, particularly in AA tasks.\nAdditionally, a key challenge is how to effectively leverage PLMs in\nconjunction with traditional feature-based methods to advance AA research. In\nthis study, we aimed to significantly improve performance using an integrated\nintegrative ensemble of traditional feature-based and modern PLM-based methods\non an AA task in a small sample. For the experiment, we used two corpora of\nliterary works to classify 10 authors each. The results indicate that BERT is\neffective, even for small-sample AA tasks. Both BERT-based and classifier\nensembles outperformed their respective stand-alone models, and the integrated\nensemble approach further improved the scores significantly. For the corpus\nthat was not included in the pre-training data, the integrated ensemble\nimproved the F1 score by approximately 14 points, compared to the\nbest-performing single model. Our methodology provides a viable solution for\nthe efficient use of the ever-expanding array of data processing tools in the\nforeseeable future.", "published": "2025-04-11 13:40:50", "link": "http://arxiv.org/abs/2504.08527v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "abstract": "Large Language Models (LLMs) are increasingly used as autonomous agents for\nmulti-step tasks. However, most existing frameworks fail to maintain a\nstructured understanding of the task state, often relying on linear prompt\nconcatenation or shallow memory buffers. This leads to brittle performance,\nfrequent hallucinations, and poor long-range coherence. In this work, we\npropose the Task Memory Engine (TME), a lightweight and structured memory\nmodule that tracks task execution using a hierarchical Task Memory Tree (TMT).\nEach node in the tree corresponds to a task step, storing relevant input,\noutput, status, and sub-task relationships. We introduce a prompt synthesis\nmethod that dynamically generates LLM prompts based on the active node path,\nsignificantly improving execution consistency and contextual grounding. Through\ncase studies and comparative experiments on multi-step agent tasks, we\ndemonstrate that TME leads to better task completion accuracy and more\ninterpretable behavior with minimal implementation overhead. The full\nimplementation of TME is available at\nhttps://github.com/biubiutomato/TME-Agent.", "published": "2025-04-11 13:38:36", "link": "http://arxiv.org/abs/2504.08525v1", "categories": ["cs.AI", "cs.CL", "68T05", "I.2.6; I.2.8; H.3.3"], "primary_category": "cs.AI"}
{"title": "BOISHOMMO: Holistic Approach for Bangla Hate Speech", "abstract": "One of the most alarming issues in digital society is hate speech (HS) on\nsocial media. The severity is so high that researchers across the globe are\ncaptivated by this domain. A notable amount of work has been conducted to\naddress the identification and alarm system. However, a noticeable gap exists,\nespecially for low-resource languages. Comprehensive datasets are the main\nproblem among the constrained resource languages, such as Bangla.\nInterestingly, hate speech or any particular speech has no single\ndimensionality. Similarly, the hate component can simultaneously have multiple\nabusive attributes, which seems to be missed in the existing datasets. Thus, a\nmulti-label Bangla hate speech dataset named BOISHOMMO has been compiled and\nevaluated in this work. That includes categories of HS across race, gender,\nreligion, politics, and more. With over two thousand annotated examples,\nBOISHOMMO provides a nuanced understanding of hate speech in Bangla and\nhighlights the complexities of processing non-Latin scripts. Apart from\nevaluating with multiple algorithmic approaches, it also highlights the\ncomplexities of processing Bangla text and assesses model performance. This\nunique multi-label approach enriches future hate speech detection and analysis\nstudies for low-resource languages by providing a more nuanced, diverse\ndataset.", "published": "2025-04-11 10:14:40", "link": "http://arxiv.org/abs/2504.08408v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Beyond Self-Reports: Multi-Observer Agents for Personality Assessment in Large Language Models", "abstract": "There is a growing interest in assessing the personality traits of Large\nlanguage models (LLMs). However, traditional personality assessments based on\nself-report questionnaires may fail to capture their true behavioral nuances\ndue to inherent biases and meta-knowledge contamination. This paper introduces\na novel multi-observer framework for LLM personality assessment that draws\ninspiration from informant-report methods in psychology. Instead of relying\nsolely on self-assessments, our approach employs multiple observer agents\nconfigured with a specific relationship context (e.g., family, friend, or\nworkplace) to simulate interactive scenarios with a subject LLM. These\nobservers engage in dialogues and subsequently provide ratings across the Big\nFive personality dimensions. Our experiments reveal that LLMs possess\nsystematic biases in self-report personality ratings. Moreover, aggregating\nobserver ratings effectively reduces non-systematic biases and achieves optimal\nreliability with 5-7 observers. The findings highlight the significant impact\nof relationship context on personality perception and demonstrate that a\nmulti-observer paradigm yields a more robust and context-sensitive evaluation\nof LLM personality traits.", "published": "2025-04-11 10:03:55", "link": "http://arxiv.org/abs/2504.08399v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Scholar Inbox: Personalized Paper Recommendations for Scientists", "abstract": "Scholar Inbox is a new open-access platform designed to address the\nchallenges researchers face in staying current with the rapidly expanding\nvolume of scientific literature. We provide personalized recommendations,\ncontinuous updates from open-access archives (arXiv, bioRxiv, etc.), visual\npaper summaries, semantic search, and a range of tools to streamline research\nworkflows and promote open research access. The platform's personalized\nrecommendation system is trained on user ratings, ensuring that recommendations\nare tailored to individual researchers' interests. To further enhance the user\nexperience, Scholar Inbox also offers a map of science that provides an\noverview of research across domains, enabling users to easily explore specific\ntopics. We use this map to address the cold start problem common in recommender\nsystems, as well as an active learning strategy that iteratively prompts users\nto rate a selection of papers, allowing the system to learn user preferences\nquickly. We evaluate the quality of our recommendation system on a novel\ndataset of 800k user ratings, which we make publicly available, as well as via\nan extensive user study. https://www.scholar-inbox.com/", "published": "2025-04-11 09:37:48", "link": "http://arxiv.org/abs/2504.08385v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "FocalLens: Instruction Tuning Enables Zero-Shot Conditional Image Representations", "abstract": "Visual understanding is inherently contextual -- what we focus on in an image\ndepends on the task at hand. For instance, given an image of a person holding a\nbouquet of flowers, we may focus on either the person such as their clothing,\nor the type of flowers, depending on the context of interest. Yet, most\nexisting image encoding paradigms represent an image as a fixed, generic\nfeature vector, overlooking the potential needs of prioritizing varying visual\ninformation for different downstream use cases. In this work, we introduce\nFocalLens, a conditional visual encoding method that produces different\nrepresentations for the same image based on the context of interest, expressed\nflexibly through natural language. We leverage vision instruction tuning data\nand contrastively finetune a pretrained vision encoder to take natural language\ninstructions as additional inputs for producing conditional image\nrepresentations. Extensive experiments validate that conditional image\nrepresentation from FocalLens better pronounce the visual features of interest\ncompared to generic features produced by standard vision encoders like CLIP. In\naddition, we show FocalLens further leads to performance improvements on a\nrange of downstream tasks including image-image retrieval, image\nclassification, and image-text retrieval, with an average gain of 5 and 10\npoints on the challenging SugarCrepe and MMVP-VLM benchmarks, respectively.", "published": "2025-04-11 09:07:05", "link": "http://arxiv.org/abs/2504.08368v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models", "abstract": "Electronic health record (EHR) foundation models have been an area ripe for\nexploration with their improved performance in various medical tasks. Despite\nthe rapid advances, there exists a fundamental limitation: Processing unseen\nmedical codes out of the vocabulary. This problem limits the generality of EHR\nfoundation models and the integration of models trained with different\nvocabularies. To deal with this problem, we propose MedRep for EHR foundation\nmodels based on the observational medical outcome partnership (OMOP) common\ndata model (CDM), providing the integrated medical concept representations and\nthe basic data augmentation strategy for patient trajectories. For concept\nrepresentation learning, we enrich the information of each concept with a\nminimal definition through large language model (LLM) prompts and enhance the\ntext-based representations through graph ontology of OMOP vocabulary.\nTrajectory augmentation randomly replaces selected concepts with other similar\nconcepts that have closely related representations to let the model practice\nwith the concepts out-of-vocabulary. Finally, we demonstrate that EHR\nfoundation models trained with MedRep better maintain the prediction\nperformance in external datasets. Our code implementation is publicly available\nat https://github.com/kicarussays/MedRep.", "published": "2025-04-11 07:51:58", "link": "http://arxiv.org/abs/2504.08329v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Large language models could be rote learners", "abstract": "Multiple-choice question (MCQ) benchmarks are widely used for evaluating\nLarge Language Models (LLMs), yet their reliability is undermined by benchmark\ncontamination. In this study, we reframe contamination as an inherent aspect of\nlearning and seek to disentangle genuine capability acquisition from\nsuperficial memorization in LLM evaluation. First, by analyzing model\nperformance under different memorization conditions, we uncover a\ncounterintuitive trend: LLMs perform worse on memorized MCQs than on\nnon-memorized ones, indicating the coexistence of two distinct learning\nphenomena, i.e., rote memorization and genuine capability learning. To\ndisentangle them, we propose TrinEval, a novel evaluation framework that\nreformulates MCQs into an alternative trinity format, reducing memorization\nwhile preserving knowledge assessment. Experiments validate TrinEval's\neffectiveness in reformulation, and its evaluation reveals that common LLMs may\nmemorize by rote 20.5% of knowledge points (in MMLU on average).", "published": "2025-04-11 07:04:44", "link": "http://arxiv.org/abs/2504.08300v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ELSA: A Style Aligned Dataset for Emotionally Intelligent Language Generation", "abstract": "Advancements in emotion aware language processing increasingly shape vital\nNLP applications ranging from conversational AI and affective computing to\ncomputational psychology and creative content generation. Existing emotion\ndatasets either lack emotional granularity or fail to capture necessary\nstylistic diversity, limiting the advancement of effective emotion conditioned\ntext generation systems. Seeking to bridge this crucial gap between granularity\nand style diversity, this paper introduces a novel systematically constructed\ndataset named ELSA Emotion and Language Style Alignment Dataset leveraging fine\ngrained emotion taxonomies adapted from existing sources such as dair ai\nemotion dataset and GoEmotions taxonomy. This dataset comprises multiple\nemotionally nuanced variations of original sentences regenerated across\ndistinct contextual styles such as conversational, formal, poetic, and\nnarrative, using advanced Large Language Models LLMs. Rigorous computational\nevaluation using metrics such as perplexity, embedding variance, readability,\nlexical diversity, and semantic coherence measures validates the datasets\nemotional authenticity, linguistic fluency, and textual diversity.\nComprehensive metric analyses affirm its potential to support deeper\nexplorations into emotion conditioned style adaptive text generation. By\nenabling precision tuned emotionally nuanced language modeling, our dataset\ncreates fertile ground for research on fine grained emotional control, prompt\ndriven explanation, interpretability, and style adaptive expressive language\ngeneration with LLMs.", "published": "2025-04-11 06:30:16", "link": "http://arxiv.org/abs/2504.08281v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generalized Multilingual Text-to-Speech Generation with Language-Aware Style Adaptation", "abstract": "Text-to-Speech (TTS) models can generate natural, human-like speech across\nmultiple languages by transforming phonemes into waveforms. However,\nmultilingual TTS remains challenging due to discrepancies in phoneme\nvocabularies and variations in prosody and speaking style across languages.\nExisting approaches either train separate models for each language, which\nachieve high performance at the cost of increased computational resources, or\nuse a unified model for multiple languages that struggles to capture\nfine-grained, language-specific style variations. In this work, we propose\nLanStyleTTS, a non-autoregressive, language-aware style adaptive TTS framework\nthat standardizes phoneme representations and enables fine-grained,\nphoneme-level style control across languages. This design supports a unified\nmultilingual TTS model capable of producing accurate and high-quality speech\nwithout the need to train language-specific models. We evaluate LanStyleTTS by\nintegrating it with several state-of-the-art non-autoregressive TTS\narchitectures. Results show consistent performance improvements across\ndifferent model backbones. Furthermore, we investigate a range of acoustic\nfeature representations, including mel-spectrograms and autoencoder-derived\nlatent features. Our experiments demonstrate that latent encodings can\nsignificantly reduce model size and computational cost while preserving\nhigh-quality speech generation.", "published": "2025-04-11 06:12:57", "link": "http://arxiv.org/abs/2504.08274v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VLMT: Vision-Language Multimodal Transformer for Multimodal Multi-hop Question Answering", "abstract": "The increasing availability of multimodal data across text, tables, and\nimages presents new challenges for developing models capable of complex\ncross-modal reasoning. Existing methods for Multimodal Multi-hop Question\nAnswering (MMQA) often suffer from limited reasoning capabilities, reliance on\nmodality conversion, and inadequate alignment between visual and textual\nrepresentations. To address these limitations, this paper introduces\nVision-Language Multimodal Transformer (VLMT), a unified architecture that\nintegrates a transformer-based vision encoder with a sequence-to-sequence\nlanguage model. VLMT employs a direct token-level injection mechanism to fuse\nvisual and textual inputs within a shared embedding space, eliminating the need\nfor intermediate projection layers. To enhance cross-modal alignment and\nreasoning, a three-stage pretraining strategy is proposed to progressively\nalign vision-language representations and improve the model's capacity for\nmultimodal understanding. Based on the pretrained backbone, two task-specific\nmodules are instantiated to form a two-stage MMQA framework: a multimodal\nreranker that predicts document relevance scores and utilizes a relative\nthreshold with top-k strategy for context retrieval, and a multimodal question\nanswering model that generates contextually grounded answers based on the\nretrieved evidence. Comprehensive experiments on two benchmark datasets\ndemonstrate the effectiveness of the proposed approach. On MultimodalQA\nvalidation set, VLMT-Large achieves 76.5% Exact Match and 80.1% F1,\noutperforming the previous state-of-the-art by +9.1% in Exact Match and +8.8%\nin F1. On WebQA, it attains a QA score of 47.6, surpassing prior models such as\nPERQA by +3.2. These results highlight VLMT's strong capabilities in multimodal\nreasoning and its potential to advance real-world information retrieval and\nquestion answering systems.", "published": "2025-04-11 05:51:44", "link": "http://arxiv.org/abs/2504.08269v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Evaluating the Bias in LLMs for Surveying Opinion and Decision Making in Healthcare", "abstract": "Generative agents have been increasingly used to simulate human behaviour in\nsilico, driven by large language models (LLMs). These simulacra serve as\nsandboxes for studying human behaviour without compromising privacy or safety.\nHowever, it remains unclear whether such agents can truly represent real\nindividuals. This work compares survey data from the Understanding America\nStudy (UAS) on healthcare decision-making with simulated responses from\ngenerative agents. Using demographic-based prompt engineering, we create\ndigital twins of survey respondents and analyse how well different LLMs\nreproduce real-world behaviours. Our findings show that some LLMs fail to\nreflect realistic decision-making, such as predicting universal vaccine\nacceptance. However, Llama 3 captures variations across race and Income more\naccurately but also introduces biases not present in the UAS data. This study\nhighlights the potential of generative agents for behavioural research while\nunderscoring the risks of bias from both LLMs and prompting strategies.", "published": "2025-04-11 05:11:40", "link": "http://arxiv.org/abs/2504.08260v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Millions of States: Designing a Scalable MoE Architecture with RWKV-7 Meta-learner", "abstract": "State-based sequence models like RWKV-7 offer a compelling alternative to\nTransformer architectures, achieving linear complexity while demonstrating\ngreater expressive power in short-context scenarios and enabling state tracking\nbeyond the \\(\\text{TC}^0\\) complexity class. However, RWKV-7 lacks mechanisms\nfor token-parameter interactions and native scalability, limiting its\nadaptability and growth without retraining. In this paper, we propose\n\\textbf{Meta-State}, a novel extension to RWKV-7 that replaces attention\nmechanisms with a fully state-driven approach, integrating token-parameter\ninteractions through a \\textbf{Self-State Encoder} (SSE) mechanism. The SSE\nrepurposes a portion of the RWKV-7 Weighted Key-Value (WKV) state as\ntransformation weights to encode token-parameter interactions in a linear,\nstate-driven manner without introducing new trainable matrices or softmax\noperations, while preserving the autoregressive property of token processing.\nMeta-State supports progressive model scaling by expanding the WKV state and\nparameter tokens, reusing existing parameters without retraining. Our approach\nbridges the gap between state-based modeling, token-parameter interactions, and\nscalable architectures, offering a flexible framework for efficient and\nadaptable sequence modeling with linear complexity and constant memory usage.", "published": "2025-04-11 04:14:32", "link": "http://arxiv.org/abs/2504.08247v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Out of Style: RAG's Fragility to Linguistic Variation", "abstract": "Despite the impressive performance of Retrieval-augmented Generation (RAG)\nsystems across various NLP benchmarks, their robustness in handling real-world\nuser-LLM interaction queries remains largely underexplored. This presents a\ncritical gap for practical deployment, where user queries exhibit greater\nlinguistic variations and can trigger cascading errors across interdependent\nRAG components. In this work, we systematically analyze how varying four\nlinguistic dimensions (formality, readability, politeness, and grammatical\ncorrectness) impact RAG performance. We evaluate two retrieval models and nine\nLLMs, ranging from 3 to 72 billion parameters, across four information-seeking\nQuestion Answering (QA) datasets. Our results reveal that linguistic\nreformulations significantly impact both retrieval and generation stages,\nleading to a relative performance drop of up to 40.41% in Recall@5 scores for\nless formal queries and 38.86% in answer match scores for queries containing\ngrammatical errors. Notably, RAG systems exhibit greater sensitivity to such\nvariations compared to LLM-only generations, highlighting their vulnerability\nto error propagation due to linguistic shifts. These findings highlight the\nneed for improved robustness techniques to enhance reliability in diverse user\ninteractions.", "published": "2025-04-11 03:30:26", "link": "http://arxiv.org/abs/2504.08231v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Big Meaning: Qualitative Analysis on Large Bodies of Data Using AI", "abstract": "This study introduces a framework that leverages AI-generated descriptive\ncodes to indicate a text's fecundity--the density of unique human-generated\ncodes--in thematic analysis. Rather than replacing human interpretation,\nAI-generated codes guide the selection of texts likely to yield richer\nqualitative insights. Using a dataset of 2,530 Malaysian news articles on\nrefugee attitudes, we compare AI-selected documents to randomly chosen ones by\nhaving three human coders independently derive codes. The results demonstrate\nthat AI-selected texts exhibit approximately twice the fecundity. Our findings\nsupport the use of AI-generated codes as an effective proxy for identifying\ndocuments with a high potential for meaning-making in thematic analysis.", "published": "2025-04-11 02:38:06", "link": "http://arxiv.org/abs/2504.08213v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM for Comparative Narrative Analysis", "abstract": "In this paper, we conducted a Multi-Perspective Comparative Narrative\nAnalysis (CNA) on three prominent LLMs: GPT-3.5, PaLM2, and Llama2. We applied\nidentical prompts and evaluated their outputs on specific tasks, ensuring an\nequitable and unbiased comparison between various LLMs. Our study revealed that\nthe three LLMs generated divergent responses to the same prompt, indicating\nnotable discrepancies in their ability to comprehend and analyze the given\ntask. Human evaluation was used as the gold standard, evaluating four\nperspectives to analyze differences in LLM performance.", "published": "2025-04-11 02:34:39", "link": "http://arxiv.org/abs/2504.08211v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Harnessing the Unseen: The Hidden Influence of Intrinsic Knowledge in Long-Context Language Models", "abstract": "Recent advances in long-context models (LCMs), designed to handle extremely\nlong input contexts, primarily focus on utilizing external contextual\ninformation, often leaving the influence of large language models' intrinsic\nknowledge underexplored. In this work, we investigate how this intrinsic\nknowledge affects content generation and demonstrate that its impact becomes\nincreasingly pronounced as context length extends. Furthermore, we show that\nthe model's ability to utilize intrinsic knowledge, which we call intrinsic\nretrieval ability, does not improve simultaneously with its ability to leverage\ncontextual knowledge through extrinsic retrieval ability. Moreover, better\nextrinsic retrieval can interfere with the model's ability to use its own\nknowledge effectively, limiting its full potential. To bridge this gap, we\ndesign a simple yet effective Hybrid Needle-in-a-Haystack test that evaluates\nmodels based on their capabilities across both retrieval abilities, rather than\nsolely emphasizing extrinsic retrieval ability. Our experimental results reveal\nthat Qwen-2.5 models significantly outperform Llama-3.1 models, demonstrating\nsuperior intrinsic retrieval ability. Moreover, even the more powerful\nLlama-3.1-70B-Instruct model fails to exhibit better performance under LCM\nconditions, highlighting the importance of evaluating models from a\ndual-retrieval perspective.", "published": "2025-04-11 02:06:58", "link": "http://arxiv.org/abs/2504.08202v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SAEs $\\textit{Can}$ Improve Unlearning: Dynamic Sparse Autoencoder Guardrails for Precision Unlearning in LLMs", "abstract": "Machine unlearning is a promising approach to improve LLM safety by removing\nunwanted knowledge from the model. However, prevailing gradient-based\nunlearning methods suffer from issues such as high computational costs,\nhyperparameter instability, poor sequential unlearning capability,\nvulnerability to relearning attacks, low data efficiency, and lack of\ninterpretability. While Sparse Autoencoders are well-suited to improve these\naspects by enabling targeted activation-based unlearning, prior approaches\nunderperform gradient-based methods. This work demonstrates that, contrary to\nthese earlier findings, SAEs can significantly improve unlearning when employed\ndynamically. We introduce $\\textbf{Dynamic DAE Guardrails}$ (DSG), a novel\nmethod for precision unlearning that leverages principled feature selection and\na dynamic classifier. Our experiments show DSG substantially outperforms\nleading unlearning methods, achieving superior forget-utility trade-offs. DSG\naddresses key drawbacks of gradient-based approaches for unlearning -- offering\nenhanced computational efficiency and stability, robust performance in\nsequential unlearning, stronger resistance to relearning attacks, better data\nefficiency including zero-shot settings, and more interpretable unlearning.", "published": "2025-04-11 01:24:03", "link": "http://arxiv.org/abs/2504.08192v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Steering CLIP's vision transformer with sparse autoencoders", "abstract": "While vision models are highly capable, their internal mechanisms remain\npoorly understood -- a challenge which sparse autoencoders (SAEs) have helped\naddress in language, but which remains underexplored in vision. We address this\ngap by training SAEs on CLIP's vision transformer and uncover key differences\nbetween vision and language processing, including distinct sparsity patterns\nfor SAEs trained across layers and token types. We then provide the first\nsystematic analysis on the steerability of CLIP's vision transformer by\nintroducing metrics to quantify how precisely SAE features can be steered to\naffect the model's output. We find that 10-15\\% of neurons and features are\nsteerable, with SAEs providing thousands more steerable features than the base\nmodel. Through targeted suppression of SAE features, we then demonstrate\nimproved performance on three vision disentanglement tasks (CelebA, Waterbirds,\nand typographic attacks), finding optimal disentanglement in middle model\nlayers, and achieving state-of-the-art performance on defense against\ntypographic attacks.", "published": "2025-04-11 17:56:09", "link": "http://arxiv.org/abs/2504.08729v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Visual Chronicles: Using Multimodal LLMs to Analyze Massive Collections of Images", "abstract": "We present a system using Multimodal LLMs (MLLMs) to analyze a large database\nwith tens of millions of images captured at different times, with the aim of\ndiscovering patterns in temporal changes. Specifically, we aim to capture\nfrequent co-occurring changes (\"trends\") across a city over a certain period.\nUnlike previous visual analyses, our analysis answers open-ended queries (e.g.,\n\"what are the frequent types of changes in the city?\") without any\npredetermined target subjects or training labels. These properties cast prior\nlearning-based or unsupervised visual analysis tools unsuitable. We identify\nMLLMs as a novel tool for their open-ended semantic understanding capabilities.\nYet, our datasets are four orders of magnitude too large for an MLLM to ingest\nas context. So we introduce a bottom-up procedure that decomposes the massive\nvisual analysis problem into more tractable sub-problems. We carefully design\nMLLM-based solutions to each sub-problem. During experiments and ablation\nstudies with our system, we find it significantly outperforms baselines and is\nable to discover interesting trends from images captured in large cities (e.g.,\n\"addition of outdoor dining,\", \"overpass was painted blue,\" etc.). See more\nresults and interactive demos at https://boyangdeng.com/visual-chronicles.", "published": "2025-04-11 17:55:45", "link": "http://arxiv.org/abs/2504.08727v1", "categories": ["cs.CV", "cs.AI", "cs.CY"], "primary_category": "cs.CV"}
{"title": "ProtoECGNet: Case-Based Interpretable Deep Learning for Multi-Label ECG Classification with Contrastive Learning", "abstract": "Deep learning-based electrocardiogram (ECG) classification has shown\nimpressive performance but clinical adoption has been slowed by the lack of\ntransparent and faithful explanations. Post hoc methods such as saliency maps\nmay fail to reflect a model's true decision process. Prototype-based reasoning\noffers a more transparent alternative by grounding decisions in similarity to\nlearned representations of real ECG segments, enabling faithful, case-based\nexplanations. We introduce ProtoECGNet, a prototype-based deep learning model\nfor interpretable, multi-label ECG classification. ProtoECGNet employs a\nstructured, multi-branch architecture that reflects clinical interpretation\nworkflows: it integrates a 1D CNN with global prototypes for rhythm\nclassification, a 2D CNN with time-localized prototypes for morphology-based\nreasoning, and a 2D CNN with global prototypes for diffuse abnormalities. Each\nbranch is trained with a prototype loss designed for multi-label learning,\ncombining clustering, separation, diversity, and a novel contrastive loss that\nencourages appropriate separation between prototypes of unrelated classes while\nallowing clustering for frequently co-occurring diagnoses. We evaluate\nProtoECGNet on all 71 diagnostic labels from the PTB-XL dataset, demonstrating\ncompetitive performance relative to state-of-the-art black-box models while\nproviding structured, case-based explanations. To assess prototype quality, we\nconduct a structured clinician review of the final model's projected\nprototypes, finding that they are rated as representative and clear.\nProtoECGNet shows that prototype learning can be effectively scaled to complex,\nmulti-label time-series classification, offering a practical path toward\ntransparent and trustworthy deep learning models for clinical decision support.", "published": "2025-04-11 17:23:37", "link": "http://arxiv.org/abs/2504.08713v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Voice Interaction With Conversational AI Could Facilitate Thoughtful Reflection and Substantive Revision in Writing", "abstract": "Writing well requires not only expressing ideas but also refining them\nthrough revision, a process facilitated by reflection. Prior research suggests\nthat feedback delivered through dialogues, such as those in writing center\ntutoring sessions, can help writers reflect more thoughtfully on their work\ncompared to static feedback. Recent advancements in multi-modal large language\nmodels (LLMs) now offer new possibilities for supporting interactive and\nexpressive voice-based reflection in writing. In particular, we propose that\nLLM-generated static feedback can be repurposed as conversation starters,\nallowing writers to seek clarification, request examples, and ask follow-up\nquestions, thereby fostering deeper reflection on their writing. We argue that\nvoice-based interaction can naturally facilitate this conversational exchange,\nencouraging writers' engagement with higher-order concerns, facilitating\niterative refinement of their reflections, and reduce cognitive load compared\nto text-based interactions. To investigate these effects, we propose a\nformative study exploring how text vs. voice input influence writers'\nreflection and subsequent revisions. Findings from this study will inform the\ndesign of intelligent and interactive writing tools, offering insights into how\nvoice-based interactions with LLM-powered conversational agents can support\nreflection and revision.", "published": "2025-04-11 16:54:12", "link": "http://arxiv.org/abs/2504.08687v1", "categories": ["cs.HC", "cs.AI", "cs.CY", "H.5.2; I.2.7"], "primary_category": "cs.HC"}
{"title": "Pobogot -- An Open-Hardware Open-Source Low Cost Robot for Swarm Robotics", "abstract": "This paper describes the Pogobot, an open-source and open-hardware platform\nspecifically designed for research involving swarm robotics. Pogobot features\nvibration-based locomotion, infrared communication, and an array of sensors in\na cost-effective package (approx. 250~euros/unit). The platform's modular\ndesign, comprehensive API, and extensible architecture facilitate the\nimplementation of swarm intelligence algorithms and distributed online\nreinforcement learning algorithms. Pogobots offer an accessible alternative to\nexisting platforms while providing advanced capabilities including directional\ncommunication between units. More than 200 Pogobots are already being used on a\ndaily basis at Sorbonne Universit\\'e and PSL to study self-organizing systems,\nprogrammable active matter, discrete reaction-diffusion-advection systems as\nwell as models of social learning and evolution.", "published": "2025-04-11 16:47:59", "link": "http://arxiv.org/abs/2504.08686v1", "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Seaweed-7B: Cost-Effective Training of Video Generation Foundation Model", "abstract": "This technical report presents a cost-efficient strategy for training a video\ngeneration foundation model. We present a mid-sized research model with\napproximately 7 billion parameters (7B) called Seaweed-7B trained from scratch\nusing 665,000 H100 GPU hours. Despite being trained with moderate computational\nresources, Seaweed-7B demonstrates highly competitive performance compared to\ncontemporary video generation models of much larger size. Design choices are\nespecially crucial in a resource-constrained setting. This technical report\nhighlights the key design decisions that enhance the performance of the\nmedium-sized diffusion model. Empirically, we make two observations: (1)\nSeaweed-7B achieves performance comparable to, or even surpasses, larger models\ntrained on substantially greater GPU resources, and (2) our model, which\nexhibits strong generalization ability, can be effectively adapted across a\nwide range of downstream applications either by lightweight fine-tuning or\ncontinue training. See the project page at https://seaweed.video/", "published": "2025-04-11 16:46:20", "link": "http://arxiv.org/abs/2504.08685v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Designing Child-Friendly AI Interfaces: Six Developmentally-Appropriate Design Insights from Analysing Disney Animation", "abstract": "To build AI interfaces that children can intuitively understand and use,\ndesigners need a design grammar that truly serves children's developmental\nneeds. This paper bridges Artificial Intelligence design for children -- an\nemerging field still defining its best practices -- and children's animation, a\nwell-established field with decades of experience in engaging young viewers\nthrough emotionally resonant, cognitively accessible storytelling. Pairing\nPiagetian developmental theory with design pattern extraction from 52 works of\nDisney animation, the paper presents six design insights transferable to\nchild-centred AI interface design: (1) emotional expressiveness and visual\nclarity, (2) musical and auditory scaffolding, (3) audiovisual synchrony for\nemotional comfort, (4) sidekick-style personas, (5) support for symbolic play\nand imaginative exploration, and (6) predictable and scaffolded interaction\nstructures. These strategies -- long refined in Disney animation -- function as\nmultimodal scaffolds for attention, understanding, and emotional attunement,\nthereby forming a structured design grammar familiar to children and\ntransferable to AI interface design. By reframing cinematic storytelling as\ndesign logic for AI, the paper offers heuristics for crafting intuitive AI\ninterfaces that align with children's cognitive stages and emotional needs. The\nwork contributes to design theory by showing how sensory, affective and\nnarrative techniques can inform developmentally attuned AI design for children.\nFuture directions include empirical testing, cultural adaptation, and\nparticipatory co-design.", "published": "2025-04-11 16:23:37", "link": "http://arxiv.org/abs/2504.08670v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Variability-Driven User-Story Generation using LLM and Triadic Concept Analysis", "abstract": "A widely used Agile practice for requirements is to produce a set of user\nstories (also called ``agile product backlog''), which roughly includes a list\nof pairs (role, feature), where the role handles the feature for a certain\npurpose. In the context of Software Product Lines, the requirements for a\nfamily of similar systems is thus a family of user-story sets, one per system,\nleading to a 3-dimensional dataset composed of sets of triples (system, role,\nfeature). In this paper, we combine Triadic Concept Analysis (TCA) and Large\nLanguage Model (LLM) prompting to suggest the user-story set required to\ndevelop a new system relying on the variability logic of an existing system\nfamily. This process consists in 1) computing 3-dimensional variability\nexpressed as a set of TCA implications, 2) providing the designer with\nintelligible design options, 3) capturing the designer's selection of options,\n4) proposing a first user-story set corresponding to this selection, 5)\nconsolidating its validity according to the implications identified in step 1,\nwhile completing it if necessary, and 6) leveraging LLM to have a more\ncomprehensive website. This process is evaluated with a dataset comprising the\nuser-story sets of 67 similar-purpose websites.", "published": "2025-04-11 16:15:27", "link": "http://arxiv.org/abs/2504.08666v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Title block detection and information extraction for enhanced building drawings search", "abstract": "The architecture, engineering, and construction (AEC) industry still heavily\nrelies on information stored in drawings for building construction,\nmaintenance, compliance and error checks. However, information extraction (IE)\nfrom building drawings is often time-consuming and costly, especially when\ndealing with historical buildings. Drawing search can be simplified by\nleveraging the information stored in the title block portion of the drawing,\nwhich can be seen as drawing metadata. However, title block IE can be complex\nespecially when dealing with historical drawings which do not follow existing\nstandards for uniformity. This work performs a comparison of existing methods\nfor this kind of IE task, and then proposes a novel title block detection and\nIE pipeline which outperforms existing methods, in particular when dealing with\ncomplex, noisy historical drawings. The pipeline is obtained by combining a\nlightweight Convolutional Neural Network and GPT-4o, the proposed inference\npipeline detects building engineering title blocks with high accuracy, and then\nextract structured drawing metadata from the title blocks, which can be used\nfor drawing search, filtering and grouping. The work demonstrates high accuracy\nand efficiency in IE for both vector (CAD) and hand-drawn (historical)\ndrawings. A user interface (UI) that leverages the extracted metadata for\ndrawing search is established and deployed on real projects, which demonstrates\nsignificant time savings. Additionally, an extensible domain-expert-annotated\ndataset for title block detection is developed, via an efficient AEC-friendly\nannotation workflow that lays the foundation for future work.", "published": "2025-04-11 15:45:17", "link": "http://arxiv.org/abs/2504.08645v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Do LLMs trust AI regulation? Emerging behaviour of game-theoretic LLM agents", "abstract": "There is general agreement that fostering trust and cooperation within the AI\ndevelopment ecosystem is essential to promote the adoption of trustworthy AI\nsystems. By embedding Large Language Model (LLM) agents within an evolutionary\ngame-theoretic framework, this paper investigates the complex interplay between\nAI developers, regulators and users, modelling their strategic choices under\ndifferent regulatory scenarios. Evolutionary game theory (EGT) is used to\nquantitatively model the dilemmas faced by each actor, and LLMs provide\nadditional degrees of complexity and nuances and enable repeated games and\nincorporation of personality traits. Our research identifies emerging\nbehaviours of strategic AI agents, which tend to adopt more \"pessimistic\" (not\ntrusting and defective) stances than pure game-theoretic agents. We observe\nthat, in case of full trust by users, incentives are effective to promote\neffective regulation; however, conditional trust may deteriorate the \"social\npact\". Establishing a virtuous feedback between users' trust and regulators'\nreputation thus appears to be key to nudge developers towards creating safe AI.\nHowever, the level at which this trust emerges may depend on the specific LLM\nused for testing. Our results thus provide guidance for AI regulation systems,\nand help predict the outcome of strategic LLM agents, should they be used to\naid regulation itself.", "published": "2025-04-11 15:41:21", "link": "http://arxiv.org/abs/2504.08640v1", "categories": ["cs.AI", "cs.CY", "cs.GT", "nlin.CD"], "primary_category": "cs.AI"}
{"title": "Deep Learning Methods for Detecting Thermal Runaway Events in Battery Production Lines", "abstract": "One of the key safety considerations of battery manufacturing is thermal\nrunaway, the uncontrolled increase in temperature which can lead to fires,\nexplosions, and emissions of toxic gasses. As such, development of automated\nsystems capable of detecting such events is of considerable importance in both\nacademic and industrial contexts. In this work, we investigate the use of deep\nlearning for detecting thermal runaway in the battery production line of VDL\nNedcar, a Dutch automobile manufacturer. Specifically, we collect data from the\nproduction line to represent both baseline (non thermal runaway) and thermal\nrunaway conditions. Thermal runaway was simulated through the use of external\nheat and smoke sources. The data consisted of both optical and thermal images\nwhich were then preprocessed and fused before serving as input to our models.\nIn this regard, we evaluated three deep-learning models widely used in computer\nvision including shallow convolutional neural networks, residual neural\nnetworks, and vision transformers on two performance metrics. Furthermore, we\nevaluated these models using explainability methods to gain insight into their\nability to capture the relevant feature information from their inputs. The\nobtained results indicate that the use of deep learning is a viable approach to\nthermal runaway detection in battery production lines.", "published": "2025-04-11 15:35:50", "link": "http://arxiv.org/abs/2504.08632v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Task-conditioned Ensemble of Expert Models for Continuous Learning", "abstract": "One of the major challenges in machine learning is maintaining the accuracy\nof the deployed model (e.g., a classifier) in a non-stationary environment. The\nnon-stationary environment results in distribution shifts and, consequently, a\ndegradation in accuracy. Continuous learning of the deployed model with new\ndata could be one remedy. However, the question arises as to how we should\nupdate the model with new training data so that it retains its accuracy on the\nold data while adapting to the new data. In this work, we propose a\ntask-conditioned ensemble of models to maintain the performance of the existing\nmodel. The method involves an ensemble of expert models based on task\nmembership information. The in-domain models-based on the local outlier concept\n(different from the expert models) provide task membership information\ndynamically at run-time to each probe sample. To evaluate the proposed method,\nwe experiment with three setups: the first represents distribution shift\nbetween tasks (LivDet-Iris-2017), the second represents distribution shift both\nbetween and within tasks (LivDet-Iris-2020), and the third represents disjoint\ndistribution between tasks (Split MNIST). The experiments highlight the\nbenefits of the proposed method. The source code is available at\nhttps://github.com/iPRoBe-lab/Continuous_Learning_FE_DM.", "published": "2025-04-11 15:27:29", "link": "http://arxiv.org/abs/2504.08626v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Enterprise-Grade Security for the Model Context Protocol (MCP): Frameworks and Mitigation Strategies", "abstract": "The Model Context Protocol (MCP), introduced by Anthropic, provides a\nstandardized framework for artificial intelligence (AI) systems to interact\nwith external data sources and tools in real-time. While MCP offers significant\nadvantages for AI integration and capability extension, it introduces novel\nsecurity challenges that demand rigorous analysis and mitigation. This paper\nbuilds upon foundational research into MCP architecture and preliminary\nsecurity assessments to deliver enterprise-grade mitigation frameworks and\ndetailed technical implementation strategies. Through systematic threat\nmodeling and analysis of MCP implementations and analysis of potential attack\nvectors, including sophisticated threats like tool poisoning, we present\nactionable security patterns tailored for MCP implementers and adopters. The\nprimary contribution of this research lies in translating theoretical security\nconcerns into a practical, implementable framework with actionable controls,\nthereby providing essential guidance for the secure enterprise adoption and\ngovernance of integrated AI systems.", "published": "2025-04-11 15:25:58", "link": "http://arxiv.org/abs/2504.08623v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Neural Fidelity Calibration for Informative Sim-to-Real Adaptation", "abstract": "Deep reinforcement learning can seamlessly transfer agile locomotion and\nnavigation skills from the simulator to real world. However, bridging the\nsim-to-real gap with domain randomization or adversarial methods often demands\nexpert physics knowledge to ensure policy robustness. Even so, cutting-edge\nsimulators may fall short of capturing every real-world detail, and the\nreconstructed environment may introduce errors due to various perception\nuncertainties. To address these challenges, we propose Neural Fidelity\nCalibration (NFC), a novel framework that employs conditional score-based\ndiffusion models to calibrate simulator physical coefficients and residual\nfidelity domains online during robot execution. Specifically, the residual\nfidelity reflects the simulation model shift relative to the real-world\ndynamics and captures the uncertainty of the perceived environment, enabling us\nto sample realistic environments under the inferred distribution for policy\nfine-tuning. Our framework is informative and adaptive in three key ways: (a)\nwe fine-tune the pretrained policy only under anomalous scenarios, (b) we build\nsequential NFC online with the pretrained NFC's proposal prior, reducing the\ndiffusion model's training burden, and (c) when NFC uncertainty is high and may\ndegrade policy improvement, we leverage optimistic exploration to enable\nhallucinated policy optimization. Our framework achieves superior simulator\ncalibration precision compared to state-of-the-art methods across diverse\nrobots with high-dimensional parametric spaces. We study the critical\ncontribution of residual fidelity to policy improvement in simulation and\nreal-world experiments. Notably, our approach demonstrates robust robot\nnavigation under challenging real-world conditions, such as a broken wheel axle\non snowy surfaces.", "published": "2025-04-11 15:12:12", "link": "http://arxiv.org/abs/2504.08604v1", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "FindAnything: Open-Vocabulary and Object-Centric Mapping for Robot Exploration in Any Environment", "abstract": "Geometrically accurate and semantically expressive map representations have\nproven invaluable to facilitate robust and safe mobile robot navigation and\ntask planning. Nevertheless, real-time, open-vocabulary semantic understanding\nof large-scale unknown environments is still an open problem. In this paper we\npresent FindAnything, an open-world mapping and exploration framework that\nincorporates vision-language information into dense volumetric submaps. Thanks\nto the use of vision-language features, FindAnything bridges the gap between\npure geometric and open-vocabulary semantic information for a higher level of\nunderstanding while allowing to explore any environment without the help of any\nexternal source of ground-truth pose information. We represent the environment\nas a series of volumetric occupancy submaps, resulting in a robust and accurate\nmap representation that deforms upon pose updates when the underlying SLAM\nsystem corrects its drift, allowing for a locally consistent representation\nbetween submaps. Pixel-wise vision-language features are aggregated from\nefficient SAM (eSAM)-generated segments, which are in turn integrated into\nobject-centric volumetric submaps, providing a mapping from open-vocabulary\nqueries to 3D geometry that is scalable also in terms of memory usage. The\nopen-vocabulary map representation of FindAnything achieves state-of-the-art\nsemantic accuracy in closed-set evaluations on the Replica dataset. This level\nof scene understanding allows a robot to explore environments based on objects\nor areas of interest selected via natural language queries. Our system is the\nfirst of its kind to be deployed on resource-constrained devices, such as MAVs,\nleveraging vision-language information for real-world robotic tasks.", "published": "2025-04-11 15:12:05", "link": "http://arxiv.org/abs/2504.08603v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "On Background Bias of Post-Hoc Concept Embeddings in Computer Vision DNNs", "abstract": "The thriving research field of concept-based explainable artificial\nintelligence (C-XAI) investigates how human-interpretable semantic concepts\nembed in the latent spaces of deep neural networks (DNNs). Post-hoc approaches\ntherein use a set of examples to specify a concept, and determine its\nembeddings in DNN latent space using data driven techniques. This proved useful\nto uncover biases between different target (foreground or concept) classes.\nHowever, given that the background is mostly uncontrolled during training, an\nimportant question has been left unattended so far: Are/to what extent are\nstate-of-the-art, data-driven post-hoc C-XAI approaches themselves prone to\nbiases with respect to their backgrounds? E.g., wild animals mostly occur\nagainst vegetation backgrounds, and they seldom appear on roads. Even simple\nand robust C-XAI methods might abuse this shortcut for enhanced performance. A\ndangerous performance degradation of the concept-corner cases of animals on the\nroad could thus remain undiscovered. This work validates and thoroughly\nconfirms that established Net2Vec-based concept segmentation techniques\nfrequently capture background biases, including alarming ones, such as\nunderperformance on road scenes. For the analysis, we compare 3 established\ntechniques from the domain of background randomization on >50 concepts from 2\ndatasets, and 7 diverse DNN architectures. Our results indicate that even\nlow-cost setups can provide both valuable insight and improved background\nrobustness.", "published": "2025-04-11 15:10:41", "link": "http://arxiv.org/abs/2504.08602v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Hands-On: Segmenting Individual Signs from Continuous Sequences", "abstract": "This work tackles the challenge of continuous sign language segmentation, a\nkey task with huge implications for sign language translation and data\nannotation. We propose a transformer-based architecture that models the\ntemporal dynamics of signing and frames segmentation as a sequence labeling\nproblem using the Begin-In-Out (BIO) tagging scheme. Our method leverages the\nHaMeR hand features, and is complemented with 3D Angles. Extensive experiments\nshow that our model achieves state-of-the-art results on the DGS Corpus, while\nour features surpass prior benchmarks on BSLCorpus.", "published": "2025-04-11 14:52:59", "link": "http://arxiv.org/abs/2504.08593v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Ready, Bid, Go! On-Demand Delivery Using Fleets of Drones with Unknown, Heterogeneous Energy Storage Constraints", "abstract": "Unmanned Aerial Vehicles (UAVs) are expected to transform logistics, reducing\ndelivery time, costs, and emissions. This study addresses an on-demand delivery\n, in which fleets of UAVs are deployed to fulfil orders that arrive\nstochastically. Unlike previous work, it considers UAVs with heterogeneous,\nunknown energy storage capacities and assumes no knowledge of the energy\nconsumption models. We propose a decentralised deployment strategy that\ncombines auction-based task allocation with online learning. Each UAV\nindependently decides whether to bid for orders based on its energy storage\ncharge level, the parcel mass, and delivery distance. Over time, it refines its\npolicy to bid only for orders within its capability. Simulations using\nrealistic UAV energy models reveal that, counter-intuitively, assigning orders\nto the least confident bidders reduces delivery times and increases the number\nof successfully fulfilled orders. This strategy is shown to outperform\nthreshold-based methods which require UAVs to exceed specific charge levels at\ndeployment. We propose a variant of the strategy which uses learned policies\nfor forecasting. This enables UAVs with insufficient charge levels to commit to\nfulfilling orders at specific future times, helping to prioritise early orders.\nOur work provides new insights into long-term deployment of UAV swarms,\nhighlighting the advantages of decentralised energy-aware decision-making\ncoupled with online learning in real-world dynamic environments.", "published": "2025-04-11 14:39:25", "link": "http://arxiv.org/abs/2504.08585v1", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Boosting multi-demographic federated learning for chest x-ray analysis using general-purpose self-supervised representations", "abstract": "Reliable artificial intelligence (AI) models for medical image analysis often\ndepend on large and diverse labeled datasets. Federated learning (FL) offers a\ndecentralized and privacy-preserving approach to training but struggles in\nhighly non-independent and identically distributed (non-IID) settings, where\ninstitutions with more representative data may experience degraded performance.\nMoreover, existing large-scale FL studies have been limited to adult datasets,\nneglecting the unique challenges posed by pediatric data, which introduces\nadditional non-IID variability. To address these limitations, we analyzed\nn=398,523 adult chest radiographs from diverse institutions across multiple\ncountries and n=9,125 pediatric images, leveraging transfer learning from\ngeneral-purpose self-supervised image representations to classify pneumonia and\ncases with no abnormality. Using state-of-the-art vision transformers, we found\nthat FL improved performance only for smaller adult datasets (P<0.001) but\ndegraded performance for larger datasets (P<0.064) and pediatric cases\n(P=0.242). However, equipping FL with self-supervised weights significantly\nenhanced outcomes across pediatric cases (P=0.031) and most adult datasets\n(P<0.008), except the largest dataset (P=0.052). These findings underscore the\npotential of easily deployable general-purpose self-supervised image\nrepresentations to address non-IID challenges in clinical FL applications and\nhighlight their promise for enhancing patient outcomes and advancing pediatric\nhealthcare, where data scarcity and variability remain persistent obstacles.", "published": "2025-04-11 14:38:09", "link": "http://arxiv.org/abs/2504.08584v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Uncovering the Structure of Explanation Quality with Spectral Analysis", "abstract": "As machine learning models are increasingly considered for high-stakes\ndomains, effective explanation methods are crucial to ensure that their\nprediction strategies are transparent to the user. Over the years, numerous\nmetrics have been proposed to assess quality of explanations. However, their\npractical applicability remains unclear, in particular due to a limited\nunderstanding of which specific aspects each metric rewards. In this paper we\npropose a new framework based on spectral analysis of explanation outcomes to\nsystematically capture the multifaceted properties of different explanation\ntechniques. Our analysis uncovers two distinct factors of explanation\nquality-stability and target sensitivity-that can be directly observed through\nspectral decomposition. Experiments on both MNIST and ImageNet show that\npopular evaluation techniques (e.g., pixel-flipping, entropy) partially capture\nthe trade-offs between these factors. Overall, our framework provides a\nfoundational basis for understanding explanation quality, guiding the\ndevelopment of more reliable techniques for evaluating explanations.", "published": "2025-04-11 14:03:23", "link": "http://arxiv.org/abs/2504.08553v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards an Evaluation Framework for Explainable Artificial Intelligence Systems for Health and Well-being", "abstract": "The integration of Artificial Intelligence in the development of computer\nsystems presents a new challenge: make intelligent systems explainable to\nhumans. This is especially vital in the field of health and well-being, where\ntransparency in decision support systems enables healthcare professionals to\nunderstand and trust automated decisions and predictions. To address this need,\ntools are required to guide the development of explainable AI systems. In this\npaper, we introduce an evaluation framework designed to support the development\nof explainable AI systems for health and well-being. Additionally, we present a\ncase study that illustrates the application of the framework in practice. We\nbelieve that our framework can serve as a valuable tool not only for developing\nexplainable AI systems in healthcare but also for any AI system that has a\nsignificant impact on individuals.", "published": "2025-04-11 14:02:54", "link": "http://arxiv.org/abs/2504.08552v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Proxy-Anchor and EVT-Driven Continual Learning Method for Generalized Category Discovery", "abstract": "Continual generalized category discovery has been introduced and studied in\nthe literature as a method that aims to continuously discover and learn novel\ncategories in incoming data batches while avoiding catastrophic forgetting of\npreviously learned categories. A key component in addressing this challenge is\nthe model's ability to separate novel samples, where Extreme Value Theory (EVT)\nhas been effectively employed. In this work, we propose a novel method that\nintegrates EVT with proxy anchors to define boundaries around proxies using a\nprobability of inclusion function, enabling the rejection of unknown samples.\nAdditionally, we introduce a novel EVT-based loss function to enhance the\nlearned representation, achieving superior performance compared to other\ndeep-metric learning methods in similar settings. Using the derived probability\nfunctions, novel samples are effectively separated from previously known\ncategories. However, category discovery within these novel samples can\nsometimes overestimate the number of new categories. To mitigate this issue, we\npropose a novel EVT-based approach to reduce the model size and discard\nredundant proxies. We also incorporate experience replay and knowledge\ndistillation mechanisms during the continual learning stage to prevent\ncatastrophic forgetting. Experimental results demonstrate that our proposed\napproach outperforms state-of-the-art methods in continual generalized category\ndiscovery scenarios.", "published": "2025-04-11 14:01:49", "link": "http://arxiv.org/abs/2504.08550v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset", "abstract": "We introduce Digital Twin Catalog (DTC), a new large-scale photorealistic 3D\nobject digital twin dataset. A digital twin of a 3D object is a highly\ndetailed, virtually indistinguishable representation of a physical object,\naccurately capturing its shape, appearance, physical properties, and other\nattributes. Recent advances in neural-based 3D reconstruction and inverse\nrendering have significantly improved the quality of 3D object reconstruction.\nDespite these advancements, there remains a lack of a large-scale, digital twin\nquality real-world dataset and benchmark that can quantitatively assess and\ncompare the performance of different reconstruction methods, as well as improve\nreconstruction quality through training or fine-tuning. Moreover, to\ndemocratize 3D digital twin creation, it is essential to integrate creation\ntechniques with next-generation egocentric computing platforms, such as AR\nglasses. Currently, there is no dataset available to evaluate 3D object\nreconstruction using egocentric captured images. To address these gaps, the DTC\ndataset features 2,000 scanned digital twin-quality 3D objects, along with\nimage sequences captured under different lighting conditions using DSLR cameras\nand egocentric AR glasses. This dataset establishes the first comprehensive\nreal-world evaluation benchmark for 3D digital twin creation tasks, offering a\nrobust foundation for comparing and improving existing reconstruction methods.\nThe DTC dataset is already released at\nhttps://www.projectaria.com/datasets/dtc/ and we will also make the baseline\nevaluations open-source.", "published": "2025-04-11 13:54:19", "link": "http://arxiv.org/abs/2504.08541v1", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.RO"], "primary_category": "cs.GR"}
{"title": "Explainability and Continual Learning meet Federated Learning at the Network Edge", "abstract": "As edge devices become more capable and pervasive in wireless networks, there\nis growing interest in leveraging their collective compute power for\ndistributed learning. However, optimizing learning at the network edge entails\nunique challenges, particularly when moving beyond conventional settings and\nobjectives. While Federated Learning (FL) has emerged as a key paradigm for\ndistributed model training, critical challenges persist. First, existing\napproaches often overlook the trade-off between predictive accuracy and\ninterpretability. Second, they struggle to integrate inherently explainable\nmodels such as decision trees because their non-differentiable structure makes\nthem not amenable to backpropagation-based training algorithms. Lastly, they\nlack meaningful mechanisms for continual Machine Learning (ML) model adaptation\nthrough Continual Learning (CL) in resource-limited environments. In this\npaper, we pave the way for a set of novel optimization problems that emerge in\ndistributed learning at the network edge with wirelessly interconnected edge\ndevices, and we identify key challenges and future directions. Specifically, we\ndiscuss how Multi-objective optimization (MOO) can be used to address the\ntrade-off between predictive accuracy and explainability when using complex\npredictive models. Next, we discuss the implications of integrating inherently\nexplainable tree-based models into distributed learning settings. Finally, we\ninvestigate how CL strategies can be effectively combined with FL to support\nadaptive, lifelong learning when limited-size buffers are used to store past\ndata for retraining. Our approach offers a cohesive set of tools for designing\nprivacy-preserving, adaptive, and trustworthy ML solutions tailored to the\ndemands of edge computing and intelligent services.", "published": "2025-04-11 13:45:55", "link": "http://arxiv.org/abs/2504.08536v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "LGRPool: Hierarchical Graph Pooling Via Local-Global Regularisation", "abstract": "Hierarchical graph pooling(HGP) are designed to consider the fact that\nconventional graph neural networks(GNN) are inherently flat and are also not\nmultiscale. However, most HGP methods suffer not only from lack of considering\nglobal topology of the graph and focusing on the feature learning aspect, but\nalso they do not align local and global features since graphs should inherently\nbe analyzed in a multiscale way. LGRPool is proposed in the present paper as a\nHGP in the framework of expectation maximization in machine learning that\naligns local and global aspects of message passing with each other using a\nregularizer to force the global topological information to be inline with the\nlocal message passing at different scales through the representations at\ndifferent layers of HGP. Experimental results on some graph classification\nbenchmarks show that it slightly outperforms some baselines.", "published": "2025-04-11 13:41:14", "link": "http://arxiv.org/abs/2504.08530v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Hallucination, reliability, and the role of generative AI in science", "abstract": "Generative AI is increasingly used in scientific domains, from protein\nfolding to climate modeling. But these models produce distinctive errors known\nas hallucinations - outputs that are incorrect yet superficially plausible.\nWorse, some arguments suggest that hallucinations are an inevitable consequence\nof the mechanisms underlying generative inference. Fortunately, such arguments\nrely on a conception of hallucination defined solely with respect to internal\nproperties of the model, rather than in reference to the empirical target\nsystem. This conception fails to distinguish epistemically benign errors from\nthose that threaten scientific inference. I introduce the concept of corrosive\nhallucination to capture the epistemically troubling subclass:\nmisrepresentations that are substantively misleading and resistant to\nsystematic anticipation. I argue that although corrosive hallucinations do pose\na threat to scientific reliability, they are not inevitable. Scientific\nworkflows such as those surrounding AlphaFold and GenCast, both of which serve\nas case studies, can neutralize their effects by imposing theoretical\nconstraints during training, and by strategically screening for errors at\ninference time. When embedded in such workflows, generative AI can reliably\ncontribute to scientific knowledge.", "published": "2025-04-11 13:38:56", "link": "http://arxiv.org/abs/2504.08526v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Mitigating Timbre Leakage with Universal Semantic Mapping Residual Block for Voice Conversion", "abstract": "Voice conversion (VC) transforms source speech into a target voice by\npreserving the content. However, timbre information from the source speaker is\ninherently embedded in the content representations, causing significant timbre\nleakage and reducing similarity to the target speaker. To address this, we\nintroduce a residual block to a content extractor. The residual block consists\nof two weighted branches: 1) universal semantic dictionary based Content\nFeature Re-expression (CFR) module, supplying timbre-free content\nrepresentation. 2) skip connection to the original content layer, providing\ncomplementary fine-grained information. In the CFR module, each dictionary\nentry in the universal semantic dictionary represents a phoneme class, computed\nstatistically using speech from multiple speakers, creating a stable,\nspeaker-independent semantic set. We introduce a CFR method to obtain\ntimbre-free content representations by expressing each content frame as a\nweighted linear combination of dictionary entries using corresponding phoneme\nposteriors as weights. Extensive experiments across various VC frameworks\ndemonstrate that our approach effectively mitigates timbre leakage and\nsignificantly improves similarity to the target speaker.", "published": "2025-04-11 13:36:59", "link": "http://arxiv.org/abs/2504.08524v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Adopting Large Language Models to Automated System Integration", "abstract": "Modern enterprise computing systems integrate numerous subsystems to resolve\na common task by yielding emergent behavior. A widespread approach is using\nservices implemented with Web technologies like REST or OpenAPI, which offer an\ninteraction mechanism and service documentation standard, respectively. Each\nservice represents a specific business functionality, allowing encapsulation\nand easier maintenance. Despite the reduced maintenance costs on an individual\nservice level, increased integration complexity arises. Consequently, automated\nservice composition approaches have arisen to mitigate this issue.\nNevertheless, these approaches have not achieved high acceptance in practice\ndue to their reliance on complex formal modeling. Within this Ph.D. thesis, we\nanalyze the application of Large Language Models (LLMs) to automatically\nintegrate the services based on a natural language input. The result is a\nreusable service composition, e.g., as program code. While not always\ngenerating entirely correct results, the result can still be helpful by\nproviding integration engineers with a close approximation of a suitable\nsolution, which requires little effort to become operational. Our research\ninvolves (i) introducing a software architecture for automated service\ncomposition using LLMs, (ii) analyzing Retrieval Augmented Generation (RAG) for\nservice discovery, (iii) proposing a novel natural language query-based\nbenchmark for service discovery, and (iv) extending the benchmark to complete\nservice composition scenarios. We have presented our software architecture as\nCompositio Prompto, the analysis of RAG for service discovery, and submitted a\nproposal for the service discovery benchmark. Open topics are primarily the\nextension of the service discovery benchmark to service composition scenarios\nand the improvements of the service composition generation, e.g., using\nfine-tuning or LLM agents.", "published": "2025-04-11 12:42:01", "link": "http://arxiv.org/abs/2504.08490v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "A Hybrid Fully Convolutional CNN-Transformer Model for Inherently Interpretable Medical Image Classification", "abstract": "In many medical imaging tasks, convolutional neural networks (CNNs)\nefficiently extract local features hierarchically. More recently, vision\ntransformers (ViTs) have gained popularity, using self-attention mechanisms to\ncapture global dependencies, but lacking the inherent spatial localization of\nconvolutions. Therefore, hybrid models combining CNNs and ViTs have been\ndeveloped to combine the strengths of both architectures. However, such hybrid\nCNN-ViT models are difficult to interpret, which hinders their application in\nmedical imaging. In this work, we introduce an interpretable-by-design hybrid\nfully convolutional CNN-Transformer architecture for medical image\nclassification. Unlike widely used post-hoc saliency methods for ViTs, our\napproach generates faithful and localized evidence maps that directly reflect\nthe model's decision process. We evaluated our method on two medical image\nclassification tasks using color fundus images. Our model not only achieves\nstate-of-the-art predictive performance compared to both black-box and\ninterpretable models but also provides class-specific sparse evidence maps in a\nsingle forward pass. The code is available at:\nhttps://anonymous.4open.science/r/Expl-CNN-Transformer/.", "published": "2025-04-11 12:15:22", "link": "http://arxiv.org/abs/2504.08481v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "On the Design of Diffusion-based Neural Speech Codecs", "abstract": "Recently, neural speech codecs (NSCs) trained as generative models have shown\nsuperior performance compared to conventional codecs at low bitrates. Although\nmost state-of-the-art NSCs are trained as Generative Adversarial Networks\n(GANs), Diffusion Models (DMs), a recent class of generative models, represent\na promising alternative due to their superior performance in image generation\nrelative to GANs. Consequently, DMs have been successfully applied for audio\nand speech coding among various other audio generation applications. However,\nthe design of diffusion-based NSCs has not yet been explored in a systematic\nway. We address this by providing a comprehensive analysis of diffusion-based\nNSCs divided into three contributions. First, we propose a categorization based\non the conditioning and output domains of the DM. This simple conceptual\nframework allows us to define a design space for diffusion-based NSCs and to\nassign a category to existing approaches in the literature. Second, we\nsystematically investigate unexplored designs by creating and evaluating new\ndiffusion-based NSCs within the conceptual framework. Finally, we compare the\nproposed models to existing GAN and DM baselines through objective metrics and\nsubjective listening tests.", "published": "2025-04-11 11:58:38", "link": "http://arxiv.org/abs/2504.08470v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Generalization Bounds in Hybrid Quantum-Classical Machine Learning Models", "abstract": "Hybrid classical-quantum models aim to harness the strengths of both quantum\ncomputing and classical machine learning, but their practical potential remains\npoorly understood. In this work, we develop a unified mathematical framework\nfor analyzing generalization in hybrid models, offering insight into how these\nsystems learn from data. We establish a novel generalization bound of the form\n$O\\big( \\sqrt{\\frac{T\\log{T}}{N}} + \\frac{\\alpha}{\\sqrt{N}}\\big)$ for $N$\ntraining data points, $T$ trainable quantum gates, and bounded fully-connected\nlayers $||F|| \\leq \\alpha$. This bound decomposes cleanly into quantum and\nclassical contributions, extending prior work on both components and clarifying\ntheir interaction. We apply our results to the quantum-classical convolutional\nneural network (QCCNN), an architecture that integrates quantum convolutional\nlayers with classical processing. Alongside the bound, we highlight conceptual\nlimitations of applying classical statistical learning theory in the hybrid\nsetting and suggest promising directions for future theoretical work.", "published": "2025-04-11 11:35:03", "link": "http://arxiv.org/abs/2504.08456v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "seeBias: A Comprehensive Tool for Assessing and Visualizing AI Fairness", "abstract": "Fairness in artificial intelligence (AI) prediction models is increasingly\nemphasized to support responsible adoption in high-stakes domains such as\nhealth care and criminal justice. Guidelines and implementation frameworks\nhighlight the importance of both predictive accuracy and equitable outcomes.\nHowever, current fairness toolkits often evaluate classification performance\ndisparities in isolation, with limited attention to other critical aspects such\nas calibration. To address these gaps, we present seeBias, an R package for\ncomprehensive evaluation of model fairness and predictive performance. seeBias\noffers an integrated evaluation across classification, calibration, and other\nperformance domains, providing a more complete view of model behavior. It\nincludes customizable visualizations to support transparent reporting and\nresponsible AI implementation. Using public datasets from criminal justice and\nhealthcare, we demonstrate how seeBias supports fairness evaluations, and\nuncovers disparities that conventional fairness metrics may overlook. The R\npackage is available on GitHub, and a Python version is under development.", "published": "2025-04-11 10:23:10", "link": "http://arxiv.org/abs/2504.08418v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Belief States for Cooperative Multi-Agent Reinforcement Learning under Partial Observability", "abstract": "Reinforcement learning in partially observable environments is typically\nchallenging, as it requires agents to learn an estimate of the underlying\nsystem state. These challenges are exacerbated in multi-agent settings, where\nagents learn simultaneously and influence the underlying state as well as each\nothers' observations. We propose the use of learned beliefs on the underlying\nstate of the system to overcome these challenges and enable reinforcement\nlearning with fully decentralized training and execution. Our approach\nleverages state information to pre-train a probabilistic belief model in a\nself-supervised fashion. The resulting belief states, which capture both\ninferred state information as well as uncertainty over this information, are\nthen used in a state-based reinforcement learning algorithm to create an\nend-to-end model for cooperative multi-agent reinforcement learning under\npartial observability. By separating the belief and reinforcement learning\ntasks, we are able to significantly simplify the policy and value function\nlearning tasks and improve both the convergence speed and the final\nperformance. We evaluate our proposed method on diverse partially observable\nmulti-agent tasks designed to exhibit different variants of partial\nobservability.", "published": "2025-04-11 10:21:58", "link": "http://arxiv.org/abs/2504.08417v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Constrained Machine Learning Through Hyperspherical Representation", "abstract": "The problem of ensuring constraints satisfaction on the output of machine\nlearning models is critical for many applications, especially in\nsafety-critical domains. Modern approaches rely on penalty-based methods at\ntraining time, which do not guarantee to avoid constraints violations; or\nconstraint-specific model architectures (e.g., for monotonocity); or on output\nprojection, which requires to solve an optimization problem that might be\ncomputationally demanding. We present the Hypersherical Constrained\nRepresentation, a novel method to enforce constraints in the output space for\nconvex and bounded feasibility regions (generalizable to star domains). Our\nmethod operates on a different representation system, where Euclidean\ncoordinates are converted into hyperspherical coordinates relative to the\nconstrained region, which can only inherently represent feasible points.\nExperiments on a synthetic and a real-world dataset show that our method has\npredictive performance comparable to the other approaches, can guarantee 100%\nconstraint satisfaction, and has a minimal computational cost at inference\ntime.", "published": "2025-04-11 10:19:49", "link": "http://arxiv.org/abs/2504.08415v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Knowledge-guided Adversarial Defense for Resisting Malicious Visual Manipulation", "abstract": "Malicious applications of visual manipulation have raised serious threats to\nthe security and reputation of users in many fields. To alleviate these issues,\nadversarial noise-based defenses have been enthusiastically studied in recent\nyears. However, ``data-only\" methods tend to distort fake samples in the\nlow-level feature space rather than the high-level semantic space, leading to\nlimitations in resisting malicious manipulation. Frontier research has shown\nthat integrating knowledge in deep learning can produce reliable and\ngeneralizable solutions. Inspired by these, we propose a knowledge-guided\nadversarial defense (KGAD) to actively force malicious manipulation models to\noutput semantically confusing samples. Specifically, in the process of\ngenerating adversarial noise, we focus on constructing significant semantic\nconfusions at the domain-specific knowledge level, and exploit a metric closely\nrelated to visual perception to replace the general pixel-wise metrics. The\ngenerated adversarial noise can actively interfere with the malicious\nmanipulation model by triggering knowledge-guided and perception-related\ndisruptions in the fake samples. To validate the effectiveness of the proposed\nmethod, we conduct qualitative and quantitative experiments on human perception\nand visual quality assessment. The results on two different tasks both show\nthat our defense provides better protection compared to state-of-the-art\nmethods and achieves great generalizability.", "published": "2025-04-11 10:18:13", "link": "http://arxiv.org/abs/2504.08411v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Human strategies for correcting `human-robot' errors during a laundry sorting task", "abstract": "Mental models and expectations underlying human-human interaction (HHI)\ninform human-robot interaction (HRI) with domestic robots. To ease\ncollaborative home tasks by improving domestic robot speech and behaviours for\nhuman-robot communication, we designed a study to understand how people\ncommunicated when failure occurs. To identify patterns of natural\ncommunication, particularly in response to robotic failures, participants\ninstructed Laundrobot to move laundry into baskets using natural language and\ngestures. Laundrobot either worked error-free, or in one of two error modes.\nParticipants were not advised Laundrobot would be a human actor, nor given\ninformation about error modes. Video analysis from 42 participants found speech\npatterns, included laughter, verbal expressions, and filler words, such as\n``oh'' and ``ok'', also, sequences of body movements, including touching one's\nown face, increased pointing with a static finger, and expressions of surprise.\nCommon strategies deployed when errors occurred, included correcting and\nteaching, taking responsibility, and displays of frustration. The strength of\nreaction to errors diminished with exposure, possibly indicating acceptance or\nresignation. Some used strategies similar to those used to communicate with\nother technologies, such as smart assistants. An anthropomorphic robot may not\nbe ideally suited to this kind of task. Laundrobot's appearance, morphology,\nvoice, capabilities, and recovery strategies may have impacted how it was\nperceived. Some participants indicated Laundrobot's actual skills were not\naligned with expectations; this made it difficult to know what to expect and\nhow much Laundrobot understood. Expertise, personality, and cultural\ndifferences may affect responses, however these were not assessed.", "published": "2025-04-11 09:53:36", "link": "http://arxiv.org/abs/2504.08395v1", "categories": ["cs.RO", "cs.AI", "cs.HC"], "primary_category": "cs.RO"}
{"title": "MineWorld: a Real-Time and Open-Source Interactive World Model on Minecraft", "abstract": "World modeling is a crucial task for enabling intelligent agents to\neffectively interact with humans and operate in dynamic environments. In this\nwork, we propose MineWorld, a real-time interactive world model on Minecraft,\nan open-ended sandbox game which has been utilized as a common testbed for\nworld modeling. MineWorld is driven by a visual-action autoregressive\nTransformer, which takes paired game scenes and corresponding actions as input,\nand generates consequent new scenes following the actions. Specifically, by\ntransforming visual game scenes and actions into discrete token ids with an\nimage tokenizer and an action tokenizer correspondingly, we consist the model\ninput with the concatenation of the two kinds of ids interleaved. The model is\nthen trained with next token prediction to learn rich representations of game\nstates as well as the conditions between states and actions simultaneously. In\ninference, we develop a novel parallel decoding algorithm that predicts the\nspatial redundant tokens in each frame at the same time, letting models in\ndifferent scales generate $4$ to $7$ frames per second and enabling real-time\ninteractions with game players. In evaluation, we propose new metrics to assess\nnot only visual quality but also the action following capacity when generating\nnew scenes, which is crucial for a world model. Our comprehensive evaluation\nshows the efficacy of MineWorld, outperforming SoTA open-sourced diffusion\nbased world models significantly. The code and model have been released.", "published": "2025-04-11 09:41:04", "link": "http://arxiv.org/abs/2504.08388v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "PCA-RAG: Principal Component Analysis for Efficient Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for\ngrounding large language models in external knowledge sources, improving the\nprecision of agents responses. However, high-dimensional language model\nembeddings, often in the range of hundreds to thousands of dimensions, can\npresent scalability challenges in terms of storage and latency, especially when\nprocessing massive financial text corpora. This paper investigates the use of\nPrincipal Component Analysis (PCA) to reduce embedding dimensionality, thereby\nmitigating computational bottlenecks without incurring large accuracy losses.\nWe experiment with a real-world dataset and compare different similarity and\ndistance metrics under both full-dimensional and PCA-compressed embeddings. Our\nresults show that reducing vectors from 3,072 to 110 dimensions provides a\nsizeable (up to $60\\times$) speedup in retrieval operations and a $\\sim\n28.6\\times$ reduction in index size, with only moderate declines in correlation\nmetrics relative to human-annotated similarity scores. These findings\ndemonstrate that PCA-based compression offers a viable balance between\nretrieval fidelity and resource efficiency, essential for real-time systems\nsuch as Zanista AI's \\textit{Newswitch} platform. Ultimately, our study\nunderscores the practicality of leveraging classical dimensionality reduction\ntechniques to scale RAG architectures for knowledge-intensive applications in\nfinance and trading, where speed, memory efficiency, and accuracy must jointly\nbe optimized.", "published": "2025-04-11 09:38:12", "link": "http://arxiv.org/abs/2504.08386v1", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Passive Underwater Acoustic Signal Separation based on Feature Decoupling Dual-path Network", "abstract": "Signal separation in the passive underwater acoustic domain has heavily\nrelied on deep learning techniques to isolate ship radiated noise. However, the\nseparation networks commonly used in this domain stem from speech separation\napplications and may not fully consider the unique aspects of underwater\nacoustics beforehand, such as the influence of different propagation media,\nsignal frequencies and modulation characteristics. This oversight highlights\nthe need for tailored approaches that account for the specific characteristics\nof underwater sound propagation. This study introduces a novel temporal network\ndesigned to separate ship radiated noise by employing a dual-path model and a\nfeature decoupling approach. The mixed signals' features are transformed into a\nspace where they exhibit greater independence, with each dimension's\nsignificance decoupled. Subsequently, a fusion of local and global attention\nmechanisms is employed in the separation layer. Extensive comparisons showcase\nthe effectiveness of this method when compared to other prevalent network\nmodels, as evidenced by its performance in the ShipsEar and DeepShip datasets.", "published": "2025-04-11 09:16:22", "link": "http://arxiv.org/abs/2504.08371v1", "categories": ["cs.SD", "cs.AI", "eess.AS", "68T10", "I.5.4; I.2.6; J.2"], "primary_category": "cs.SD"}
{"title": "Kernel-Level Energy-Efficient Neural Architecture Search for Tabular Dataset", "abstract": "Many studies estimate energy consumption using proxy metrics like memory\nusage, FLOPs, and inference latency, with the assumption that reducing these\nmetrics will also lower energy consumption in neural networks. This paper,\nhowever, takes a different approach by introducing an energy-efficient Neural\nArchitecture Search (NAS) method that directly focuses on identifying\narchitectures that minimize energy consumption while maintaining acceptable\naccuracy. Unlike previous methods that primarily target vision and language\ntasks, the approach proposed here specifically addresses tabular datasets.\nRemarkably, the optimal architecture suggested by this method can reduce energy\nconsumption by up to 92% compared to architectures recommended by conventional\nNAS.", "published": "2025-04-11 08:48:54", "link": "http://arxiv.org/abs/2504.08359v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Entropic bounds for conditionally Gaussian vectors and applications to neural networks", "abstract": "Using entropic inequalities from information theory, we provide new bounds on\nthe total variation and 2-Wasserstein distances between a conditionally\nGaussian law and a Gaussian law with invertible covariance matrix. We apply our\nresults to quantify the speed of convergence to Gaussian of a randomly\ninitialized fully connected neural network and its derivatives - evaluated in a\nfinite number of inputs - when the initialization is Gaussian and the sizes of\nthe inner layers diverge to infinity. Our results require mild assumptions on\nthe activation function, and allow one to recover optimal rates of convergence\nin a variety of distances, thus improving and extending the findings of Basteri\nand Trevisan (2023), Favaro et al. (2023), Trevisan (2024) and Apollonio et al.\n(2024). One of our main tools are the quantitative cumulant estimates\nestablished in Hanin (2024). As an illustration, we apply our results to bound\nthe total variation distance between the Bayesian posterior law of the neural\nnetwork and its derivatives, and the posterior law of the corresponding\nGaussian limit: this yields quantitative versions of a posterior CLT by Hron et\nal. (2022), and extends several estimates by Trevisan (2024) to the total\nvariation metric.", "published": "2025-04-11 08:00:37", "link": "http://arxiv.org/abs/2504.08335v1", "categories": ["math.PR", "cs.AI", "cs.LG", "stat.ML", "60F05 (Primary) 68T07 (Secondary)", "G.3; I.2"], "primary_category": "math.PR"}
{"title": "SortBench: Benchmarking LLMs based on their ability to sort lists", "abstract": "Sorting is a tedious but simple task for human intelligence and can be solved\nfairly easily algorithmically. However, for Large Language Models (LLMs) this\ntask is surprisingly hard, as some properties of sorting are among known\nweaknesses of LLMs: being faithful to the input data, logical comparisons\nbetween values, and strictly differentiating between syntax (used for sorting)\nand semantics (typically learned by embeddings). Within this paper, we describe\nthe new SortBench benchmark for LLMs that comes with different difficulties and\nthat can be easily scaled in terms of difficulty. We apply this benchmark to\nseven state-of-the-art LLMs, including current test-time reasoning models. Our\nresults show that while the o3-mini model is very capable at sorting in\ngeneral, even this can be fooled if strings are defined to mix syntactical and\nsemantical aspects, e.g., by asking to sort numbers written-out as word.\nFurthermore, all models have problems with the faithfulness to the input of\nlong lists, i.e., they drop items and add new ones. Our results also show that\ntest-time reasoning has a tendency to overthink problems which leads to\nperformance degradation. Finally, models without test-time reasoning like\nGPT-4o are not much worse than reasoning models.", "published": "2025-04-11 07:29:56", "link": "http://arxiv.org/abs/2504.08312v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "CoProSketch: Controllable and Progressive Sketch Generation with Diffusion Model", "abstract": "Sketches serve as fundamental blueprints in artistic creation because sketch\nediting is easier and more intuitive than pixel-level RGB image editing for\npainting artists, yet sketch generation remains unexplored despite advancements\nin generative models. We propose a novel framework CoProSketch, providing\nprominent controllability and details for sketch generation with diffusion\nmodels. A straightforward method is fine-tuning a pretrained image generation\ndiffusion model with binarized sketch images. However, we find that the\ndiffusion models fail to generate clear binary images, which makes the produced\nsketches chaotic. We thus propose to represent the sketches by unsigned\ndistance field (UDF), which is continuous and can be easily decoded to sketches\nthrough a lightweight network. With CoProSketch, users generate a rough sketch\nfrom a bounding box and a text prompt. The rough sketch can be manually edited\nand fed back into the model for iterative refinement and will be decoded to a\ndetailed sketch as the final result. Additionally, we curate the first\nlarge-scale text-sketch paired dataset as the training data. Experiments\ndemonstrate superior semantic consistency and controllability over baselines,\noffering a practical solution for integrating user feedback into generative\nworkflows.", "published": "2025-04-11 05:11:17", "link": "http://arxiv.org/abs/2504.08259v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Accelerating Multi-Objective Collaborative Optimization of Doped Thermoelectric Materials via Artificial Intelligence", "abstract": "The thermoelectric performance of materials exhibits complex nonlinear\ndependencies on both elemental types and their proportions, rendering\ntraditional trial-and-error approaches inefficient and time-consuming for\nmaterial discovery. In this work, we present a deep learning model capable of\naccurately predicting thermoelectric properties of doped materials directly\nfrom their chemical formulas, achieving state-of-the-art performance. To\nenhance interpretability, we further incorporate sensitivity analysis\ntechniques to elucidate how physical descriptors affect the thermoelectric\nfigure of merit (zT). Moreover, we establish a coupled framework that\nintegrates a surrogate model with a multi-objective genetic algorithm to\nefficiently explore the vast compositional space for high-performance\ncandidates. Experimental validation confirms the discovery of a novel\nthermoelectric material with superior $zT$ values in the medium-temperature\nregime.", "published": "2025-04-11 05:10:18", "link": "http://arxiv.org/abs/2504.08258v1", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Bayesian Reasoning Enabled by Spin-Orbit Torque Magnetic Tunnel Junctions", "abstract": "Bayesian networks play an increasingly important role in data mining,\ninference, and reasoning with the rapid development of artificial intelligence.\nIn this paper, we present proof-of-concept experiments demonstrating the use of\nspin-orbit torque magnetic tunnel junctions (SOT-MTJs) in Bayesian network\nreasoning. Not only can the target probability distribution function (PDF) of a\nBayesian network be precisely formulated by a conditional probability table as\nusual but also quantitatively parameterized by a probabilistic forward\npropagating neuron network. Moreover, the parameters of the network can also\napproach the optimum through a simple point-by point training algorithm, by\nleveraging which we do not need to memorize all historical data nor\nstatistically summarize conditional probabilities behind them, significantly\nimproving storage efficiency and economizing data pretreatment. Furthermore, we\ndeveloped a simple medical diagnostic system using the SOT-MTJ as a random\nnumber generator and sampler, showcasing the application of SOT-MTJ-based\nBayesian reasoning. This SOT-MTJ-based Bayesian reasoning shows great promise\nin the field of artificial probabilistic neural network, broadening the scope\nof spintronic device applications and providing an efficient and low-storage\nsolution for complex reasoning tasks.", "published": "2025-04-11 05:02:27", "link": "http://arxiv.org/abs/2504.08257v1", "categories": ["physics.app-ph", "cs.AI"], "primary_category": "physics.app-ph"}
{"title": "RAG-VR: Leveraging Retrieval-Augmented Generation for 3D Question Answering in VR Environments", "abstract": "Recent advances in large language models (LLMs) provide new opportunities for\ncontext understanding in virtual reality (VR). However, VR contexts are often\nhighly localized and personalized, limiting the effectiveness of\ngeneral-purpose LLMs. To address this challenge, we present RAG-VR, the first\n3D question-answering system for VR that incorporates retrieval-augmented\ngeneration (RAG), which augments an LLM with external knowledge retrieved from\na localized knowledge database to improve the answer quality. RAG-VR includes a\npipeline for extracting comprehensive knowledge about virtual environments and\nuser conditions for accurate answer generation. To ensure efficient retrieval,\nRAG-VR offloads the retrieval process to a nearby edge server and uses only\nessential information during retrieval. Moreover, we train the retriever to\neffectively distinguish among relevant, irrelevant, and hard-to-differentiate\ninformation in relation to questions. RAG-VR improves answer accuracy by\n17.9%-41.8% and reduces end-to-end latency by 34.5%-47.3% compared with two\nbaseline systems.", "published": "2025-04-11 04:55:50", "link": "http://arxiv.org/abs/2504.08256v1", "categories": ["cs.IR", "cs.AI", "cs.HC"], "primary_category": "cs.IR"}
{"title": "Jupiter: Fast and Resource-Efficient Collaborative Inference of Generative LLMs on Edge Devices", "abstract": "Generative large language models (LLMs) have garnered significant attention\ndue to their exceptional capabilities in various AI tasks. Traditionally\ndeployed in cloud datacenters, LLMs are now increasingly moving towards more\naccessible edge platforms to protect sensitive user data and ensure privacy\npreservation. The limited computational resources of individual edge devices,\nhowever, can result in excessively prolonged inference latency and overwhelmed\nmemory usage. While existing research has explored collaborative edge computing\nto break the resource wall of individual devices, these solutions yet suffer\nfrom massive communication overhead and under-utilization of edge resources.\nFurthermore, they focus exclusively on optimizing the prefill phase, neglecting\nthe crucial autoregressive decoding phase for generative LLMs. To address that,\nwe propose Jupiter, a fast, scalable, and resource-efficient collaborative edge\nAI system for generative LLM inference. Jupiter introduces a flexible pipelined\narchitecture as a principle and differentiates its system design according to\nthe differentiated characteristics of the prefill and decoding phases. For\nprefill phase, Jupiter submits a novel intra-sequence pipeline parallelism and\ndevelops a meticulous parallelism planning strategy to maximize resource\nefficiency; For decoding, Jupiter devises an effective outline-based pipeline\nparallel decoding mechanism combined with speculative decoding, which further\nmagnifies inference acceleration. Extensive evaluation based on realistic\nimplementation demonstrates that Jupiter remarkably outperforms\nstate-of-the-art approaches under various edge environment setups, achieving up\nto 26.1x end-to-end latency reduction while rendering on-par generation\nquality.", "published": "2025-04-11 03:58:59", "link": "http://arxiv.org/abs/2504.08242v1", "categories": ["cs.DC", "cs.AI", "cs.NI"], "primary_category": "cs.DC"}
{"title": "F$^3$Set: Towards Analyzing Fast, Frequent, and Fine-grained Events from Videos", "abstract": "Analyzing Fast, Frequent, and Fine-grained (F$^3$) events presents a\nsignificant challenge in video analytics and multi-modal LLMs. Current methods\nstruggle to identify events that satisfy all the F$^3$ criteria with high\naccuracy due to challenges such as motion blur and subtle visual discrepancies.\nTo advance research in video understanding, we introduce F$^3$Set, a benchmark\nthat consists of video datasets for precise F$^3$ event detection. Datasets in\nF$^3$Set are characterized by their extensive scale and comprehensive detail,\nusually encompassing over 1,000 event types with precise timestamps and\nsupporting multi-level granularity. Currently, F$^3$Set contains several sports\ndatasets, and this framework may be extended to other applications as well. We\nevaluated popular temporal action understanding methods on F$^3$Set, revealing\nsubstantial challenges for existing techniques. Additionally, we propose a new\nmethod, F$^3$ED, for F$^3$ event detections, achieving superior performance.\nThe dataset, model, and benchmark code are available at\nhttps://github.com/F3Set/F3Set.", "published": "2025-04-11 03:05:35", "link": "http://arxiv.org/abs/2504.08222v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Optimizing Power Grid Topologies with Reinforcement Learning: A Survey of Methods and Challenges", "abstract": "Power grid operation is becoming increasingly complex due to the rising\nintegration of renewable energy sources and the need for more adaptive control\nstrategies. Reinforcement Learning (RL) has emerged as a promising approach to\npower network control (PNC), offering the potential to enhance decision-making\nin dynamic and uncertain environments. The Learning To Run a Power Network\n(L2RPN) competitions have played a key role in accelerating research by\nproviding standardized benchmarks and problem formulations, leading to rapid\nadvancements in RL-based methods. This survey provides a comprehensive and\nstructured overview of RL applications for power grid topology optimization,\ncategorizing existing techniques, highlighting key design choices, and\nidentifying gaps in current research. Additionally, we present a comparative\nnumerical study evaluating the impact of commonly applied RL-based methods,\noffering insights into their practical effectiveness. By consolidating existing\nresearch and outlining open challenges, this survey aims to provide a\nfoundation for future advancements in RL-driven power grid optimization.", "published": "2025-04-11 02:27:30", "link": "http://arxiv.org/abs/2504.08210v1", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY", "stat.ML"], "primary_category": "eess.SY"}
{"title": "How Good Are Large Language Models for Course Recommendation in MOOCs?", "abstract": "Large Language Models (LLMs) have made significant strides in natural\nlanguage processing and are increasingly being integrated into recommendation\nsystems. However, their potential in educational recommendation systems has yet\nto be fully explored. This paper investigates the use of LLMs as a\ngeneral-purpose recommendation model, leveraging their vast knowledge derived\nfrom large-scale corpora for course recommendation tasks. We explore a variety\nof approaches, ranging from prompt-based methods to more advanced fine-tuning\ntechniques, and compare their performance against traditional recommendation\nmodels. Extensive experiments were conducted on a real-world MOOC dataset,\nevaluating using LLMs as course recommendation systems across key dimensions\nsuch as accuracy, diversity, and novelty. Our results demonstrate that LLMs can\nachieve good performance comparable to traditional models, highlighting their\npotential to enhance educational recommendation systems. These findings pave\nthe way for further exploration and development of LLM-based approaches in the\ncontext of educational recommendations.", "published": "2025-04-11 02:19:26", "link": "http://arxiv.org/abs/2504.08208v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "DRAFT-ing Architectural Design Decisions using LLMs", "abstract": "Architectural Knowledge Management (AKM) is crucial for software development\nbut remains challenging due to the lack of standardization and high manual\neffort. Architecture Decision Records (ADRs) provide a structured approach to\ncapture Architecture Design Decisions (ADDs), but their adoption is limited due\nto the manual effort involved and insufficient tool support. Our previous work\nhas shown that Large Language Models (LLMs) can assist in generating ADDs.\nHowever, simply prompting the LLM does not produce quality ADDs. Moreover,\nusing third-party LLMs raises privacy concerns, while self-hosting them poses\nresource challenges.\n  To this end, we experimented with different approaches like few-shot,\nretrieval-augmented generation (RAG) and fine-tuning to enhance LLM's ability\nto generate ADDs. Our results show that both techniques improve effectiveness.\nBuilding on this, we propose Domain Specific Retreival Augumented Few Shot Fine\nTuninng, DRAFT, which combines the strengths of all these three approaches for\nmore effective ADD generation. DRAFT operates in two phases: an offline phase\nthat fine-tunes an LLM on generating ADDs augmented with retrieved examples and\nan online phase that generates ADDs by leveraging retrieved ADRs and the\nfine-tuned model.\n  We evaluated DRAFT against existing approaches on a dataset of 4,911 ADRs and\nvarious LLMs and analyzed them using automated metrics and human evaluations.\nResults show DRAFT outperforms all other approaches in effectiveness while\nmaintaining efficiency. Our findings indicate that DRAFT can aid architects in\ndrafting ADDs while addressing privacy and resource constraints.", "published": "2025-04-11 02:19:01", "link": "http://arxiv.org/abs/2504.08207v1", "categories": ["cs.SE", "cs.AI", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Neural Encoding and Decoding at Scale", "abstract": "Recent work has demonstrated that large-scale, multi-animal models are\npowerful tools for characterizing the relationship between neural activity and\nbehavior. Current large-scale approaches, however, focus exclusively on either\npredicting neural activity from behavior (encoding) or predicting behavior from\nneural activity (decoding), limiting their ability to capture the bidirectional\nrelationship between neural activity and behavior. To bridge this gap, we\nintroduce a multimodal, multi-task model that enables simultaneous Neural\nEncoding and Decoding at Scale (NEDS). Central to our approach is a novel\nmulti-task-masking strategy, which alternates between neural, behavioral,\nwithin-modality, and cross-modality masking. We pretrain our method on the\nInternational Brain Laboratory (IBL) repeated site dataset, which includes\nrecordings from 83 animals performing the same visual decision-making task. In\ncomparison to other large-scale models, we demonstrate that NEDS achieves\nstate-of-the-art performance for both encoding and decoding when pretrained on\nmulti-animal data and then fine-tuned on new animals. Surprisingly, NEDS's\nlearned embeddings exhibit emergent properties: even without explicit training,\nthey are highly predictive of the brain regions in each recording. Altogether,\nour approach is a step towards a foundation model of the brain that enables\nseamless translation between neural activity and behavior.", "published": "2025-04-11 02:06:20", "link": "http://arxiv.org/abs/2504.08201v1", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "Influential Bandits: Pulling an Arm May Change the Environment", "abstract": "While classical formulations of multi-armed bandit problems assume that each\narm's reward is independent and stationary, real-world applications often\ninvolve non-stationary environments and interdependencies between arms. In\nparticular, selecting one arm may influence the future rewards of other arms, a\nscenario not adequately captured by existing models such as rotting bandits or\nrestless bandits. To address this limitation, we propose the influential bandit\nproblem, which models inter-arm interactions through an unknown, symmetric,\npositive semi-definite interaction matrix that governs the dynamics of arm\nlosses. We formally define this problem and establish two regret lower bounds,\nincluding a superlinear $\\Omega(T^2 / \\log^2 T)$ bound for the standard UCB\nalgorithm and an algorithm-independent $\\Omega(T)$ bound, which highlight the\ninherent difficulty of the setting. We then introduce a new algorithm based on\na lower confidence bound (LCB) estimator tailored to the structure of the loss\ndynamics. Under mild assumptions, our algorithm achieves a regret of $O(KT \\log\nT)$, which is nearly optimal in terms of its dependence on the time horizon.\nThe algorithm is simple to implement and computationally efficient. Empirical\nevaluations on both synthetic and real-world datasets demonstrate the presence\nof inter-arm influence and confirm the superior performance of our method\ncompared to conventional bandit algorithms.", "published": "2025-04-11 02:05:51", "link": "http://arxiv.org/abs/2504.08200v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Graph Based Deep Reinforcement Learning Aided by Transformers for Multi-Agent Cooperation", "abstract": "Mission planning for a fleet of cooperative autonomous drones in applications\nthat involve serving distributed target points, such as disaster response,\nenvironmental monitoring, and surveillance, is challenging, especially under\npartial observability, limited communication range, and uncertain environments.\nTraditional path-planning algorithms struggle in these scenarios, particularly\nwhen prior information is not available. To address these challenges, we\npropose a novel framework that integrates Graph Neural Networks (GNNs), Deep\nReinforcement Learning (DRL), and transformer-based mechanisms for enhanced\nmulti-agent coordination and collective task execution. Our approach leverages\nGNNs to model agent-agent and agent-goal interactions through adaptive graph\nconstruction, enabling efficient information aggregation and decision-making\nunder constrained communication. A transformer-based message-passing mechanism,\naugmented with edge-feature-enhanced attention, captures complex interaction\npatterns, while a Double Deep Q-Network (Double DQN) with prioritized\nexperience replay optimizes agent policies in partially observable\nenvironments. This integration is carefully designed to address specific\nrequirements of multi-agent navigation, such as scalability, adaptability, and\nefficient task execution. Experimental results demonstrate superior\nperformance, with 90% service provisioning and 100% grid coverage (node\ndiscovery), while reducing the average steps per episode to 200, compared to\n600 for benchmark methods such as particle swarm optimization (PSO), greedy\nalgorithms and DQN.", "published": "2025-04-11 01:46:18", "link": "http://arxiv.org/abs/2504.08195v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "TokenMotion: Decoupled Motion Control via Token Disentanglement for Human-centric Video Generation", "abstract": "Human-centric motion control in video generation remains a critical\nchallenge, particularly when jointly controlling camera movements and human\nposes in scenarios like the iconic Grammy Glambot moment. While recent video\ndiffusion models have made significant progress, existing approaches struggle\nwith limited motion representations and inadequate integration of camera and\nhuman motion controls. In this work, we present TokenMotion, the first\nDiT-based video diffusion framework that enables fine-grained control over\ncamera motion, human motion, and their joint interaction. We represent camera\ntrajectories and human poses as spatio-temporal tokens to enable local control\ngranularity. Our approach introduces a unified modeling framework utilizing a\ndecouple-and-fuse strategy, bridged by a human-aware dynamic mask that\neffectively handles the spatially-and-temporally varying nature of combined\nmotion signals. Through extensive experiments, we demonstrate TokenMotion's\neffectiveness across both text-to-video and image-to-video paradigms,\nconsistently outperforming current state-of-the-art methods in human-centric\nmotion control tasks. Our work represents a significant advancement in\ncontrollable video generation, with particular relevance for creative\nproduction applications.", "published": "2025-04-11 00:41:25", "link": "http://arxiv.org/abs/2504.08181v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SynthFM: Training Modality-agnostic Foundation Models for Medical Image Segmentation without Real Medical Data", "abstract": "Foundation models like the Segment Anything Model (SAM) excel in zero-shot\nsegmentation for natural images but struggle with medical image segmentation\ndue to differences in texture, contrast, and noise. Annotating medical images\nis costly and requires domain expertise, limiting large-scale annotated data\navailability. To address this, we propose SynthFM, a synthetic data generation\nframework that mimics the complexities of medical images, enabling foundation\nmodels to adapt without real medical data. Using SAM's pretrained encoder and\ntraining the decoder from scratch on SynthFM's dataset, we evaluated our method\non 11 anatomical structures across 9 datasets (CT, MRI, and Ultrasound).\nSynthFM outperformed zero-shot baselines like SAM and MedSAM, achieving\nsuperior results under different prompt settings and on out-of-distribution\ndatasets.", "published": "2025-04-11 00:14:28", "link": "http://arxiv.org/abs/2504.08177v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "GigaTok: Scaling Visual Tokenizers to 3 Billion Parameters for Autoregressive Image Generation", "abstract": "In autoregressive (AR) image generation, visual tokenizers compress images\ninto compact discrete latent tokens, enabling efficient training of downstream\nautoregressive models for visual generation via next-token prediction. While\nscaling visual tokenizers improves image reconstruction quality, it often\ndegrades downstream generation quality -- a challenge not adequately addressed\nin existing literature. To address this, we introduce GigaTok, the first\napproach to simultaneously improve image reconstruction, generation, and\nrepresentation learning when scaling visual tokenizers. We identify the growing\ncomplexity of latent space as the key factor behind the reconstruction vs.\ngeneration dilemma. To mitigate this, we propose semantic regularization, which\naligns tokenizer features with semantically consistent features from a\npre-trained visual encoder. This constraint prevents excessive latent space\ncomplexity during scaling, yielding consistent improvements in both\nreconstruction and downstream autoregressive generation. Building on semantic\nregularization, we explore three key practices for scaling tokenizers:(1) using\n1D tokenizers for better scalability, (2) prioritizing decoder scaling when\nexpanding both encoder and decoder, and (3) employing entropy loss to stabilize\ntraining for billion-scale tokenizers. By scaling to $\\bf{3 \\space billion}$\nparameters, GigaTok achieves state-of-the-art performance in reconstruction,\ndownstream AR generation, and downstream AR representation quality.", "published": "2025-04-11 17:59:58", "link": "http://arxiv.org/abs/2504.08736v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EMO-X: Efficient Multi-Person Pose and Shape Estimation in One-Stage", "abstract": "Expressive Human Pose and Shape Estimation (EHPS) aims to jointly estimate\nhuman pose, hand gesture, and facial expression from monocular images. Existing\nmethods predominantly rely on Transformer-based architectures, which suffer\nfrom quadratic complexity in self-attention, leading to substantial\ncomputational overhead, especially in multi-person scenarios. Recently, Mamba\nhas emerged as a promising alternative to Transformers due to its efficient\nglobal modeling capability. However, it remains limited in capturing\nfine-grained local dependencies, which are essential for precise EHPS. To\naddress these issues, we propose EMO-X, the Efficient Multi-person One-stage\nmodel for multi-person EHPS. Specifically, we explore a Scan-based Global-Local\nDecoder (SGLD) that integrates global context with skeleton-aware local\nfeatures to iteratively enhance human tokens. Our EMO-X leverages the superior\nglobal modeling capability of Mamba and designs a local bidirectional scan\nmechanism for skeleton-aware local refinement. Comprehensive experiments\ndemonstrate that EMO-X strikes an excellent balance between efficiency and\naccuracy. Notably, it achieves a significant reduction in computational\ncomplexity, requiring 69.8% less inference time compared to state-of-the-art\n(SOTA) methods, while outperforming most of them in accuracy.", "published": "2025-04-11 17:30:46", "link": "http://arxiv.org/abs/2504.08718v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hypergraph Vision Transformers: Images are More than Nodes, More than Edges", "abstract": "Recent advancements in computer vision have highlighted the scalability of\nVision Transformers (ViTs) across various tasks, yet challenges remain in\nbalancing adaptability, computational efficiency, and the ability to model\nhigher-order relationships. Vision Graph Neural Networks (ViGs) offer an\nalternative by leveraging graph-based methodologies but are hindered by the\ncomputational bottlenecks of clustering algorithms used for edge generation. To\naddress these issues, we propose the Hypergraph Vision Transformer (HgVT),\nwhich incorporates a hierarchical bipartite hypergraph structure into the\nvision transformer framework to capture higher-order semantic relationships\nwhile maintaining computational efficiency. HgVT leverages population and\ndiversity regularization for dynamic hypergraph construction without\nclustering, and expert edge pooling to enhance semantic extraction and\nfacilitate graph-based image retrieval. Empirical results demonstrate that HgVT\nachieves strong performance on image classification and retrieval, positioning\nit as an efficient framework for semantic-based vision tasks.", "published": "2025-04-11 17:20:26", "link": "http://arxiv.org/abs/2504.08710v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "X2BR: High-Fidelity 3D Bone Reconstruction from a Planar X-Ray Image with Hybrid Neural Implicit Methods", "abstract": "Accurate 3D bone reconstruction from a single planar X-ray remains a\nchallenge due to anatomical complexity and limited input data. We propose X2BR,\na hybrid neural implicit framework that combines continuous volumetric\nreconstruction with template-guided non-rigid registration. The core network,\nX2B, employs a ConvNeXt-based encoder to extract spatial features from X-rays\nand predict high-fidelity 3D bone occupancy fields without relying on\nstatistical shape models. To further refine anatomical accuracy, X2BR\nintegrates a patient-specific template mesh, constructed using YOLOv9-based\ndetection and the SKEL biomechanical skeleton model. The coarse reconstruction\nis aligned to the template using geodesic-based coherent point drift, enabling\nanatomically consistent 3D bone volumes. Experimental results on a clinical\ndataset show that X2B achieves the highest numerical accuracy, with an IoU of\n0.952 and Chamfer-L1 distance of 0.005, outperforming recent baselines\nincluding X2V and D2IM-Net. Building on this, X2BR incorporates anatomical\npriors via YOLOv9-based bone detection and biomechanical template alignment,\nleading to reconstructions that, while slightly lower in IoU (0.875), offer\nsuperior anatomical realism, especially in rib curvature and vertebral\nalignment. This numerical accuracy vs. visual consistency trade-off between X2B\nand X2BR highlights the value of hybrid frameworks for clinically relevant 3D\nreconstructions.", "published": "2025-04-11 16:29:54", "link": "http://arxiv.org/abs/2504.08675v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The Invisible EgoHand: 3D Hand Forecasting through EgoBody Pose Estimation", "abstract": "Forecasting hand motion and pose from an egocentric perspective is essential\nfor understanding human intention. However, existing methods focus solely on\npredicting positions without considering articulation, and only when the hands\nare visible in the field of view. This limitation overlooks the fact that\napproximate hand positions can still be inferred even when they are outside the\ncamera's view. In this paper, we propose a method to forecast the 3D\ntrajectories and poses of both hands from an egocentric video, both in and out\nof the field of view. We propose a diffusion-based transformer architecture for\nEgocentric Hand Forecasting, EgoH4, which takes as input the observation\nsequence and camera poses, then predicts future 3D motion and poses for both\nhands of the camera wearer. We leverage full-body pose information, allowing\nother joints to provide constraints on hand motion. We denoise the hand and\nbody joints along with a visibility predictor for hand joints and a 3D-to-2D\nreprojection loss that minimizes the error when hands are in-view. We evaluate\nEgoH4 on the Ego-Exo4D dataset, combining subsets with body and hand\nannotations. We train on 156K sequences and evaluate on 34K sequences,\nrespectively. EgoH4 improves the performance by 3.4cm and 5.1cm over the\nbaseline in terms of ADE for hand trajectory forecasting and MPJPE for hand\npose forecasting. Project page: https://masashi-hatano.github.io/EgoH4/", "published": "2025-04-11 15:58:31", "link": "http://arxiv.org/abs/2504.08654v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MBE-ARI: A Multimodal Dataset Mapping Bi-directional Engagement in Animal-Robot Interaction", "abstract": "Animal-robot interaction (ARI) remains an unexplored challenge in robotics,\nas robots struggle to interpret the complex, multimodal communication cues of\nanimals, such as body language, movement, and vocalizations. Unlike human-robot\ninteraction, which benefits from established datasets and frameworks,\nanimal-robot interaction lacks the foundational resources needed to facilitate\nmeaningful bidirectional communication. To bridge this gap, we present the\nMBE-ARI (Multimodal Bidirectional Engagement in Animal-Robot Interaction), a\nnovel multimodal dataset that captures detailed interactions between a legged\nrobot and cows. The dataset includes synchronized RGB-D streams from multiple\nviewpoints, annotated with body pose and activity labels across interaction\nphases, offering an unprecedented level of detail for ARI research.\nAdditionally, we introduce a full-body pose estimation model tailored for\nquadruped animals, capable of tracking 39 keypoints with a mean average\nprecision (mAP) of 92.7%, outperforming existing benchmarks in animal pose\nestimation. The MBE-ARI dataset and our pose estimation framework lay a robust\nfoundation for advancing research in animal-robot interaction, providing\nessential tools for developing perception, reasoning, and interaction\nframeworks needed for effective collaboration between robots and animals. The\ndataset and resources are publicly available at\nhttps://github.com/RISELabPurdue/MBE-ARI/, inviting further exploration and\ndevelopment in this critical area.", "published": "2025-04-11 15:45:23", "link": "http://arxiv.org/abs/2504.08646v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Latent Diffusion Autoencoders: Toward Efficient and Meaningful Unsupervised Representation Learning in Medical Imaging", "abstract": "This study presents Latent Diffusion Autoencoder (LDAE), a novel\nencoder-decoder diffusion-based framework for efficient and meaningful\nunsupervised learning in medical imaging, focusing on Alzheimer disease (AD)\nusing brain MR from the ADNI database as a case study. Unlike conventional\ndiffusion autoencoders operating in image space, LDAE applies the diffusion\nprocess in a compressed latent representation, improving computational\nefficiency and making 3D medical imaging representation learning tractable. To\nvalidate the proposed approach, we explore two key hypotheses: (i) LDAE\neffectively captures meaningful semantic representations on 3D brain MR\nassociated with AD and ageing, and (ii) LDAE achieves high-quality image\ngeneration and reconstruction while being computationally efficient.\nExperimental results support both hypotheses: (i) linear-probe evaluations\ndemonstrate promising diagnostic performance for AD (ROC-AUC: 90%, ACC: 84%)\nand age prediction (MAE: 4.1 years, RMSE: 5.2 years); (ii) the learned semantic\nrepresentations enable attribute manipulation, yielding anatomically plausible\nmodifications; (iii) semantic interpolation experiments show strong\nreconstruction of missing scans, with SSIM of 0.969 (MSE: 0.0019) for a 6-month\ngap. Even for longer gaps (24 months), the model maintains robust performance\n(SSIM > 0.93, MSE < 0.004), indicating an ability to capture temporal\nprogression trends; (iv) compared to conventional diffusion autoencoders, LDAE\nsignificantly increases inference throughput (20x faster) while also enhancing\nreconstruction quality. These findings position LDAE as a promising framework\nfor scalable medical imaging applications, with the potential to serve as a\nfoundation model for medical image analysis. Code available at\nhttps://github.com/GabrieleLozupone/LDAE", "published": "2025-04-11 15:37:46", "link": "http://arxiv.org/abs/2504.08635v1", "categories": ["cs.CV", "41A05, 41A10, 65D05, 65D17,"], "primary_category": "cs.CV"}
{"title": "Efficient Mixture of Geographical Species for On Device Wildlife Monitoring", "abstract": "Efficient on-device models have become attractive for near-sensor insight\ngeneration, of particular interest to the ecological conservation community.\nFor this reason, deep learning researchers are proposing more approaches to\ndevelop lower compute models. However, since vision transformers are very new\nto the edge use case, there are still unexplored approaches, most notably\nconditional execution of subnetworks based on input data. In this work, we\nexplore the training of a single species detector which uses conditional\ncomputation to bias structured sub networks in a geographically-aware manner.\nWe propose a method for pruning the expert model per location and demonstrate\nconditional computation performance on two geographically distributed datasets:\niNaturalist and iWildcam.", "published": "2025-04-11 15:25:36", "link": "http://arxiv.org/abs/2504.08620v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Preserving Privacy Without Compromising Accuracy: Machine Unlearning for Handwritten Text Recognition", "abstract": "Handwritten Text Recognition (HTR) is essential for document analysis and\ndigitization. However, handwritten data often contains user-identifiable\ninformation, such as unique handwriting styles and personal lexicon choices,\nwhich can compromise privacy and erode trust in AI services. Legislation like\nthe ``right to be forgotten'' underscores the necessity for methods that can\nexpunge sensitive information from trained models. Machine unlearning addresses\nthis by selectively removing specific data from models without necessitating\ncomplete retraining. Yet, it frequently encounters a privacy-accuracy tradeoff,\nwhere safeguarding privacy leads to diminished model performance. In this\npaper, we introduce a novel two-stage unlearning strategy for a multi-head\ntransformer-based HTR model, integrating pruning and random labeling. Our\nproposed method utilizes a writer classification head both as an indicator and\na trigger for unlearning, while maintaining the efficacy of the recognition\nhead. To our knowledge, this represents the first comprehensive exploration of\nmachine unlearning within HTR tasks. We further employ Membership Inference\nAttacks (MIA) to evaluate the effectiveness of unlearning user-identifiable\ninformation. Extensive experiments demonstrate that our approach effectively\npreserves privacy while maintaining model accuracy, paving the way for new\nresearch directions in the document analysis community. Our code will be\npublicly available upon acceptance.", "published": "2025-04-11 15:21:12", "link": "http://arxiv.org/abs/2504.08616v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing knowledge retention for continual learning with domain-specific adapters and features gating", "abstract": "Continual learning empowers models to learn from a continuous stream of data\nwhile preserving previously acquired knowledge, effectively addressing the\nchallenge of catastrophic forgetting. In this study, we propose a new approach\nthat integrates adapters within the self-attention mechanisms of Vision\nTransformers to enhance knowledge retention when sequentially adding datasets\nfrom different domains. Unlike previous methods that continue learning with\nonly one dataset, our approach introduces domain-specific output heads and\nfeature gating, allowing the model to maintain high accuracy on previously\nlearned tasks while incorporating only the essential information from multiple\ndomains. The proposed method is compared to prominent parameter-efficient\nfine-tuning methods in the current state of the art. The results provide\nevidence that our method effectively alleviates the limitations of previous\nworks. Furthermore, we conduct a comparative analysis using three datasets,\nCIFAR-100, Flowers102, and DTD, each representing a distinct domain, to\ninvestigate the impact of task order on model performance. Our findings\nunderscore the critical role of dataset sequencing in shaping learning\noutcomes, demonstrating that strategic ordering can significantly improve the\nmodel's ability to adapt to evolving data distributions over time while\npreserving the integrity of previously learned knowledge.", "published": "2025-04-11 15:20:08", "link": "http://arxiv.org/abs/2504.08613v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "ZipIR: Latent Pyramid Diffusion Transformer for High-Resolution Image Restoration", "abstract": "Recent progress in generative models has significantly improved image\nrestoration capabilities, particularly through powerful diffusion models that\noffer remarkable recovery of semantic details and local fidelity. However,\ndeploying these models at ultra-high resolutions faces a critical trade-off\nbetween quality and efficiency due to the computational demands of long-range\nattention mechanisms. To address this, we introduce ZipIR, a novel framework\nthat enhances efficiency, scalability, and long-range modeling for high-res\nimage restoration. ZipIR employs a highly compressed latent representation that\ncompresses image 32x, effectively reducing the number of spatial tokens, and\nenabling the use of high-capacity models like the Diffusion Transformer (DiT).\nToward this goal, we propose a Latent Pyramid VAE (LP-VAE) design that\nstructures the latent space into sub-bands to ease diffusion training. Trained\non full images up to 2K resolution, ZipIR surpasses existing diffusion-based\nmethods, offering unmatched speed and quality in restoring high-resolution\nimages from severely degraded inputs.", "published": "2025-04-11 14:49:52", "link": "http://arxiv.org/abs/2504.08591v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hardware, Algorithms, and Applications of the Neuromorphic Vision Sensor: a Review", "abstract": "Neuromorphic, or event, cameras represent a transformation in the classical\napproach to visual sensing encodes detected instantaneous per-pixel\nillumination changes into an asynchronous stream of event packets. Their\nnovelty compared to standard cameras lies in the transition from capturing full\npicture frames at fixed time intervals to a sparse data format which, with its\ndistinctive qualities, offers potential improvements in various applications.\nHowever, these advantages come at the cost of reinventing algorithmic\nprocedures or adapting them to effectively process the new data format.\n  In this survey, we systematically examine neuromorphic vision along three\nmain dimensions. First, we highlight the technological evolution and\ndistinctive hardware features of neuromorphic cameras from their inception to\nrecent models. Second, we review image processing algorithms developed\nexplicitly for event-based data, covering key works on feature detection,\ntracking, and optical flow -which form the basis for analyzing image elements\nand transformations -as well as depth and pose estimation or object\nrecognition, which interpret more complex scene structures and components.\nThese techniques, drawn from classical computer vision and modern data-driven\napproaches, are examined to illustrate the breadth of applications for\nevent-based cameras. Third, we present practical application case studies\ndemonstrating how event cameras have been successfully used across various\nindustries and scenarios. Finally, we analyze the challenges limiting\nwidespread adoption, identify significant research gaps compared to standard\nimaging techniques, and outline promising future directions and opportunities\nthat neuromorphic vision offers.", "published": "2025-04-11 14:46:36", "link": "http://arxiv.org/abs/2504.08588v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FMLGS: Fast Multilevel Language Embedded Gaussians for Part-level Interactive Agents", "abstract": "The semantically interactive radiance field has long been a promising\nbackbone for 3D real-world applications, such as embodied AI to achieve scene\nunderstanding and manipulation. However, multi-granularity interaction remains\na challenging task due to the ambiguity of language and degraded quality when\nit comes to queries upon object components. In this work, we present FMLGS, an\napproach that supports part-level open-vocabulary query within 3D Gaussian\nSplatting (3DGS). We propose an efficient pipeline for building and querying\nconsistent object- and part-level semantics based on Segment Anything Model 2\n(SAM2). We designed a semantic deviation strategy to solve the problem of\nlanguage ambiguity among object parts, which interpolates the semantic features\nof fine-grained targets for enriched information. Once trained, we can query\nboth objects and their describable parts using natural language. Comparisons\nwith other state-of-the-art methods prove that our method can not only better\nlocate specified part-level targets, but also achieve first-place performance\nconcerning both speed and accuracy, where FMLGS is 98 x faster than LERF, 4 x\nfaster than LangSplat and 2.5 x faster than LEGaussians. Meanwhile, we further\nintegrate FMLGS as a virtual agent that can interactively navigate through 3D\nscenes, locate targets, and respond to user demands through a chat interface,\nwhich demonstrates the potential of our work to be further expanded and applied\nin the future.", "published": "2025-04-11 14:33:27", "link": "http://arxiv.org/abs/2504.08581v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Knowledge Distillation for Multimodal Egocentric Action Recognition Robust to Missing Modalities", "abstract": "Action recognition is an essential task in egocentric vision due to its wide\nrange of applications across many fields. While deep learning methods have been\nproposed to address this task, most rely on a single modality, typically video.\nHowever, including additional modalities may improve the robustness of the\napproaches to common issues in egocentric videos, such as blurriness and\nocclusions. Recent efforts in multimodal egocentric action recognition often\nassume the availability of all modalities, leading to failures or performance\ndrops when any modality is missing. To address this, we introduce an efficient\nmultimodal knowledge distillation approach for egocentric action recognition\nthat is robust to missing modalities (KARMMA) while still benefiting when\nmultiple modalities are available. Our method focuses on resource-efficient\ndevelopment by leveraging pre-trained models as unimodal feature extractors in\nour teacher model, which distills knowledge into a much smaller and faster\nstudent model. Experiments on the Epic-Kitchens and Something-Something\ndatasets demonstrate that our student model effectively handles missing\nmodalities while reducing its accuracy drop in this scenario.", "published": "2025-04-11 14:30:42", "link": "http://arxiv.org/abs/2504.08578v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Banana Ripeness Level Classification using a Simple CNN Model Trained with Real and Synthetic Datasets", "abstract": "The level of ripeness is essential in determining the quality of bananas. To\ncorrectly estimate banana maturity, the metrics of international marketing\nstandards need to be considered. However, the process of assessing the maturity\nof bananas at an industrial level is still carried out using manual methods.\nThe use of CNN models is an attractive tool to solve the problem, but there is\na limitation regarding the availability of sufficient data to train these\nmodels reliably. On the other hand, in the state-of-the-art, existing CNN\nmodels and the available data have reported that the accuracy results are\nacceptable in identifying banana maturity. For this reason, this work presents\nthe generation of a robust dataset that combines real and synthetic data for\ndifferent levels of banana ripeness. In addition, it proposes a simple CNN\narchitecture, which is trained with synthetic data and using the transfer\nlearning technique, the model is improved to classify real data, managing to\ndetermine the level of maturity of the banana. The proposed CNN model is\nevaluated with several architectures, then hyper-parameter configurations are\nvaried, and optimizers are used. The results show that the proposed CNN model\nreaches a high accuracy of 0.917 and a fast execution time.", "published": "2025-04-11 14:24:30", "link": "http://arxiv.org/abs/2504.08568v1", "categories": ["cs.CV", "68T05, 68T07, 68T10", "I.4.7; I.2.10"], "primary_category": "cs.CV"}
{"title": "Shadow Erosion and Nighttime Adaptability for Camera-Based Automated Driving Applications", "abstract": "Enhancement of images from RGB cameras is of particular interest due to its\nwide range of ever-increasing applications such as medical imaging, satellite\nimaging, automated driving, etc. In autonomous driving, various techniques are\nused to enhance image quality under challenging lighting conditions. These\ninclude artificial augmentation to improve visibility in poor nighttime\nconditions, illumination-invariant imaging to reduce the impact of lighting\nvariations, and shadow mitigation to ensure consistent image clarity in bright\ndaylight. This paper proposes a pipeline for Shadow Erosion and Nighttime\nAdaptability in images for automated driving applications while preserving\ncolor and texture details. The Shadow Erosion and Nighttime Adaptability\npipeline is compared to the widely used CLAHE technique and evaluated based on\nillumination uniformity and visual perception quality metrics. The results also\ndemonstrate a significant improvement over CLAHE, enhancing a YOLO-based\ndrivable area segmentation algorithm.", "published": "2025-04-11 14:02:11", "link": "http://arxiv.org/abs/2504.08551v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "COP-GEN-Beta: Unified Generative Modelling of COPernicus Imagery Thumbnails", "abstract": "In remote sensing, multi-modal data from various sensors capturing the same\nscene offers rich opportunities, but learning a unified representation across\nthese modalities remains a significant challenge. Traditional methods have\noften been limited to single or dual-modality approaches. In this paper, we\nintroduce COP-GEN-Beta, a generative diffusion model trained on optical, radar,\nand elevation data from the Major TOM dataset. What sets COP-GEN-Beta apart is\nits ability to map any subset of modalities to any other, enabling zero-shot\nmodality translation after training. This is achieved through a sequence-based\ndiffusion transformer, where each modality is controlled by its own timestep\nembedding. We extensively evaluate COP-GEN-Beta on thumbnail images from the\nMajor TOM dataset, demonstrating its effectiveness in generating high-quality\nsamples. Qualitative and quantitative evaluations validate the model's\nperformance, highlighting its potential as a powerful pre-trained model for\nfuture remote sensing tasks.", "published": "2025-04-11 14:00:46", "link": "http://arxiv.org/abs/2504.08548v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Discriminator-Free Direct Preference Optimization for Video Diffusion", "abstract": "Direct Preference Optimization (DPO), which aligns models with human\npreferences through win/lose data pairs, has achieved remarkable success in\nlanguage and image generation. However, applying DPO to video diffusion models\nfaces critical challenges: (1) Data inefficiency. Generating thousands of\nvideos per DPO iteration incurs prohibitive costs; (2) Evaluation uncertainty.\nHuman annotations suffer from subjective bias, and automated discriminators\nfail to detect subtle temporal artifacts like flickering or motion incoherence.\nTo address these, we propose a discriminator-free video DPO framework that: (1)\nUses original real videos as win cases and their edited versions (e.g.,\nreversed, shuffled, or noise-corrupted clips) as lose cases; (2) Trains video\ndiffusion models to distinguish and avoid artifacts introduced by editing. This\napproach eliminates the need for costly synthetic video comparisons, provides\nunambiguous quality signals, and enables unlimited training data expansion\nthrough simple editing operations. We theoretically prove the framework's\neffectiveness even when real videos and model-generated videos follow different\ndistributions. Experiments on CogVideoX demonstrate the efficiency of the\nproposed method.", "published": "2025-04-11 13:55:48", "link": "http://arxiv.org/abs/2504.08542v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Datasets for Lane Detection in Autonomous Driving: A Comprehensive Review", "abstract": "Accurate lane detection is essential for automated driving, enabling safe and\nreliable vehicle navigation in a variety of road scenarios. Numerous datasets\nhave been introduced to support the development and evaluation of lane\ndetection algorithms, each differing in terms of the amount of data, sensor\ntypes, annotation granularity, environmental conditions, and scenario\ndiversity. This paper provides a comprehensive review of over 30 publicly\navailable lane detection datasets, systematically analysing their\ncharacteristics, advantages and limitations. We classify these datasets based\non key factors such as sensor resolution, annotation types and diversity of\nroad and weather conditions. By identifying existing challenges and research\ngaps, we highlight opportunities for future dataset improvements that can\nfurther drive innovation in robust lane detection. This survey serves as a\nresource for researchers seeking appropriate datasets for lane detection, and\ncontributes to the broader goal of advancing autonomous driving.", "published": "2025-04-11 13:54:04", "link": "http://arxiv.org/abs/2504.08540v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Embodied Image Captioning: Self-supervised Learning Agents for Spatially Coherent Image Descriptions", "abstract": "We present a self-supervised method to improve an agent's abilities in\ndescribing arbitrary objects while actively exploring a generic environment.\nThis is a challenging problem, as current models struggle to obtain coherent\nimage captions due to different camera viewpoints and clutter. We propose a\nthree-phase framework to fine-tune existing captioning models that enhances\ncaption accuracy and consistency across views via a consensus mechanism. First,\nan agent explores the environment, collecting noisy image-caption pairs. Then,\na consistent pseudo-caption for each object instance is distilled via consensus\nusing a large language model. Finally, these pseudo-captions are used to\nfine-tune an off-the-shelf captioning model, with the addition of contrastive\nlearning. We analyse the performance of the combination of captioning models,\nexploration policies, pseudo-labeling methods, and fine-tuning strategies, on\nour manually labeled test set. Results show that a policy can be trained to\nmine samples with higher disagreement compared to classical baselines. Our\npseudo-captioning method, in combination with all policies, has a higher\nsemantic similarity compared to other existing methods, and fine-tuning\nimproves caption accuracy and consistency by a significant margin. Code and\ntest set annotations available at\nhttps://hsp-iit.github.io/embodied-captioning/", "published": "2025-04-11 13:41:17", "link": "http://arxiv.org/abs/2504.08531v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Cut-and-Splat: Leveraging Gaussian Splatting for Synthetic Data Generation", "abstract": "Generating synthetic images is a useful method for cheaply obtaining labeled\ndata for training computer vision models. However, obtaining accurate 3D models\nof relevant objects is necessary, and the resulting images often have a gap in\nrealism due to challenges in simulating lighting effects and camera artifacts.\nWe propose using the novel view synthesis method called Gaussian Splatting to\naddress these challenges. We have developed a synthetic data pipeline for\ngenerating high-quality context-aware instance segmentation training data for\nspecific objects. This process is fully automated, requiring only a video of\nthe target object. We train a Gaussian Splatting model of the target object and\nautomatically extract the object from the video. Leveraging Gaussian Splatting,\nwe then render the object on a random background image, and monocular depth\nestimation is employed to place the object in a believable pose. We introduce a\nnovel dataset to validate our approach and show superior performance over other\ndata generation approaches, such as Cut-and-Paste and Diffusion model-based\ngeneration.", "published": "2025-04-11 12:04:49", "link": "http://arxiv.org/abs/2504.08473v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Road Grip Uncertainty Estimation Through Surface State Segmentation", "abstract": "Slippery road conditions pose significant challenges for autonomous driving.\nBeyond predicting road grip, it is crucial to estimate its uncertainty reliably\nto ensure safe vehicle control. In this work, we benchmark several uncertainty\nprediction methods to assess their effectiveness for grip uncertainty\nestimation. Additionally, we propose a novel approach that leverages road\nsurface state segmentation to predict grip uncertainty. Our method estimates a\npixel-wise grip probability distribution based on inferred road surface\nconditions. Experimental results indicate that the proposed approach enhances\nthe robustness of grip uncertainty prediction.", "published": "2025-04-11 11:28:00", "link": "http://arxiv.org/abs/2504.08452v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Muon-Accelerated Attention Distillation for Real-Time Edge Synthesis via Optimized Latent Diffusion", "abstract": "Recent advances in visual synthesis have leveraged diffusion models and\nattention mechanisms to achieve high-fidelity artistic style transfer and\nphotorealistic text-to-image generation. However, real-time deployment on edge\ndevices remains challenging due to computational and memory constraints. We\npropose Muon-AD, a co-designed framework that integrates the Muon optimizer\nwith attention distillation for real-time edge synthesis. By eliminating\ngradient conflicts through orthogonal parameter updates and dynamic pruning,\nMuon-AD achieves 3.2 times faster convergence compared to Stable\nDiffusion-TensorRT, while maintaining synthesis quality (15% lower FID, 4%\nhigher SSIM). Our framework reduces peak memory to 7GB on Jetson Orin and\nenables 24FPS real-time generation through mixed-precision quantization and\ncurriculum learning. Extensive experiments on COCO-Stuff and ImageNet-Texture\ndemonstrate Muon-AD's Pareto-optimal efficiency-quality trade-offs. Here, we\nshow a 65% reduction in communication overhead during distributed training and\nreal-time 10s/image generation on edge GPUs. These advancements pave the way\nfor democratizing high-quality visual synthesis in resource-constrained\nenvironments.", "published": "2025-04-11 11:27:29", "link": "http://arxiv.org/abs/2504.08451v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Ego4o: Egocentric Human Motion Capture and Understanding from Multi-Modal Input", "abstract": "This work focuses on tracking and understanding human motion using consumer\nwearable devices, such as VR/AR headsets, smart glasses, cellphones, and\nsmartwatches. These devices provide diverse, multi-modal sensor inputs,\nincluding egocentric images, and 1-3 sparse IMU sensors in varied combinations.\nMotion descriptions can also accompany these signals. The diverse input\nmodalities and their intermittent availability pose challenges for consistent\nmotion capture and understanding. In this work, we present Ego4o (o for omni),\na new framework for simultaneous human motion capture and understanding from\nmulti-modal egocentric inputs. This method maintains performance with partial\ninputs while achieving better results when multiple modalities are combined.\nFirst, the IMU sensor inputs, the optional egocentric image, and text\ndescription of human motion are encoded into the latent space of a motion\nVQ-VAE. Next, the latent vectors are sent to the VQ-VAE decoder and optimized\nto track human motion. When motion descriptions are unavailable, the latent\nvectors can be input into a multi-modal LLM to generate human motion\ndescriptions, which can further enhance motion capture accuracy. Quantitative\nand qualitative evaluations demonstrate the effectiveness of our method in\npredicting accurate human motion and high-quality motion descriptions.", "published": "2025-04-11 11:18:57", "link": "http://arxiv.org/abs/2504.08449v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SARFormer -- An Acquisition Parameter Aware Vision Transformer for Synthetic Aperture Radar Data", "abstract": "This manuscript introduces SARFormer, a modified Vision Transformer (ViT)\narchitecture designed for processing one or multiple synthetic aperture radar\n(SAR) images. Given the complex image geometry of SAR data, we propose an\nacquisition parameter encoding module that significantly guides the learning\nprocess, especially in the case of multiple images, leading to improved\nperformance on downstream tasks. We further explore self-supervised\npre-training, conduct experiments with limited labeled data, and benchmark our\ncontribution and adaptations thoroughly in ablation experiments against a\nbaseline, where the model is tested on tasks such as height reconstruction and\nsegmentation. Our approach achieves up to 17% improvement in terms of RMSE over\nbaseline models", "published": "2025-04-11 11:06:12", "link": "http://arxiv.org/abs/2504.08441v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The Composite Visual-Laser Navigation Method Applied in Indoor Poultry Farming Environments", "abstract": "Indoor poultry farms require inspection robots to maintain precise\nenvironmental control, which is crucial for preventing the rapid spread of\ndisease and large-scale bird mortality. However, the complex conditions within\nthese facilities, characterized by areas of intense illumination and water\naccumulation, pose significant challenges. Traditional navigation methods that\nrely on a single sensor often perform poorly in such environments, resulting in\nissues like laser drift and inaccuracies in visual navigation line extraction.\nTo overcome these limitations, we propose a novel composite navigation method\nthat integrates both laser and vision technologies. This approach dynamically\ncomputes a fused yaw angle based on the real-time reliability of each sensor\nmodality, thereby eliminating the need for physical navigation lines.\nExperimental validation in actual poultry house environments demonstrates that\nour method not only resolves the inherent drawbacks of single-sensor systems,\nbut also significantly enhances navigation precision and operational\nefficiency. As such, it presents a promising solution for improving the\nperformance of inspection robots in complex indoor poultry farming settings.", "published": "2025-04-11 10:44:30", "link": "http://arxiv.org/abs/2504.08431v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "CMIP-CIL: A Cross-Modal Benchmark for Image-Point Class Incremental Learning", "abstract": "Image-point class incremental learning helps the 3D-points-vision robots\ncontinually learn category knowledge from 2D images, improving their perceptual\ncapability in dynamic environments. However, some incremental learning methods\naddress unimodal forgetting but fail in cross-modal cases, while others handle\nmodal differences within training/testing datasets but assume no modal gaps\nbetween them. We first explore this cross-modal task, proposing a benchmark\nCMIP-CIL and relieving the cross-modal catastrophic forgetting problem. It\nemploys masked point clouds and rendered multi-view images within a contrastive\nlearning framework in pre-training, empowering the vision model with the\ngeneralizations of image-point correspondence. In the incremental stage, by\nfreezing the backbone and promoting object representations close to their\nrespective prototypes, the model effectively retains and generalizes knowledge\nacross previously seen categories while continuing to learn new ones. We\nconduct comprehensive experiments on the benchmark datasets. Experiments prove\nthat our method achieves state-of-the-art results, outperforming the baseline\nmethods by a large margin.", "published": "2025-04-11 10:28:29", "link": "http://arxiv.org/abs/2504.08422v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Poisson multi-Bernoulli mixture filter for trajectory measurements", "abstract": "This paper presents a Poisson multi-Bernoulli mixture (PMBM) filter for\nmulti-target filtering based on sensor measurements that are sets of\ntrajectories in the last two-time step window. The proposed filter, the\ntrajectory measurement PMBM (TM-PMBM) filter, propagates a PMBM density on the\nset of target states. In prediction, the filter obtains the PMBM density on the\nset of trajectories over the last two time steps. This density is then updated\nwith the set of trajectory measurements. After the update step, the PMBM\nposterior on the set of two-step trajectories is marginalised to obtain a PMBM\ndensity on the set of target states. The filter provides a closed-form solution\nfor multi-target filtering based on sets of trajectory measurements, estimating\nthe set of target states at the end of each time window. Additionally, the\npaper proposes computationally lighter alternatives to the TM-PMBM filter by\nderiving a Poisson multi-Bernoulli (PMB) density through Kullback-Leibler\ndivergence minimisation in an augmented space with auxiliary variables. The\nperformance of the proposed filters are evaluated in a simulation study.", "published": "2025-04-11 10:27:07", "link": "http://arxiv.org/abs/2504.08421v1", "categories": ["eess.SP", "cs.CV", "stat.AP"], "primary_category": "eess.SP"}
{"title": "GeoTexBuild: 3D Building Model Generation from Map Footprints", "abstract": "We introduce GeoTexBuild, a modular generative framework for creating 3D\nbuilding models from map footprints. The proposed framework employs a\nthree-stage process comprising height map generation, geometry reconstruction,\nand appearance stylization, culminating in building models with intricate\ngeometry and appearance attributes. By integrating customized ControlNet and\nText2Mesh models, we explore effective methods for controlling both geometric\nand visual attributes during the generation process. By this, we eliminate the\nproblem of structural variations behind a single facade photo of the existing\n3D generation techniques. Experimental results at each stage validate the\ncapability of GeoTexBuild to generate detailed and accurate building models\nfrom footprints derived from site planning or map designs. Our framework\nsignificantly reduces manual labor in modeling buildings and can offer\ninspiration for designers.", "published": "2025-04-11 10:23:55", "link": "http://arxiv.org/abs/2504.08419v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adversarial Examples in Environment Perception for Automated Driving (Review)", "abstract": "The renaissance of deep learning has led to the massive development of\nautomated driving. However, deep neural networks are vulnerable to adversarial\nexamples. The perturbations of adversarial examples are imperceptible to human\neyes but can lead to the false predictions of neural networks. It poses a huge\nrisk to artificial intelligence (AI) applications for automated driving. This\nsurvey systematically reviews the development of adversarial robustness\nresearch over the past decade, including the attack and defense methods and\ntheir applications in automated driving. The growth of automated driving pushes\nforward the realization of trustworthy AI applications. This review lists\nsignificant references in the research history of adversarial examples.", "published": "2025-04-11 10:19:29", "link": "http://arxiv.org/abs/2504.08414v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Boosting the Class-Incremental Learning in 3D Point Clouds via Zero-Collection-Cost Basic Shape Pre-Training", "abstract": "Existing class-incremental learning methods in 3D point clouds rely on\nexemplars (samples of former classes) to resist the catastrophic forgetting of\nmodels, and exemplar-free settings will greatly degrade the performance. For\nexemplar-free incremental learning, the pre-trained model methods have achieved\nstate-of-the-art results in 2D domains. However, these methods cannot be\nmigrated to the 3D domains due to the limited pre-training datasets and\ninsufficient focus on fine-grained geometric details. This paper breaks through\nthese limitations, proposing a basic shape dataset with zero collection cost\nfor model pre-training. It helps a model obtain extensive knowledge of 3D\ngeometries. Based on this, we propose a framework embedded with 3D geometry\nknowledge for incremental learning in point clouds, compatible with\nexemplar-free (-based) settings. In the incremental stage, the geometry\nknowledge is extended to represent objects in point clouds. The class prototype\nis calculated by regularizing the data representation with the same category\nand is kept adjusting in the learning process. It helps the model remember the\nshape features of different categories. Experiments show that our method\noutperforms other baseline methods by a large margin on various benchmark\ndatasets, considering both exemplar-free (-based) settings.", "published": "2025-04-11 10:18:35", "link": "http://arxiv.org/abs/2504.08412v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PMNI: Pose-free Multi-view Normal Integration for Reflective and Textureless Surface Reconstruction", "abstract": "Reflective and textureless surfaces remain a challenge in multi-view 3D\nreconstruction.Both camera pose calibration and shape reconstruction often fail\ndue to insufficient or unreliable cross-view visual features. To address these\nissues, we present PMNI (Pose-free Multi-view Normal Integration), a neural\nsurface reconstruction method that incorporates rich geometric information by\nleveraging surface normal maps instead of RGB images. By enforcing geometric\nconstraints from surface normals and multi-view shape consistency within a\nneural signed distance function (SDF) optimization framework, PMNI\nsimultaneously recovers accurate camera poses and high-fidelity surface\ngeometry. Experimental results on synthetic and real-world datasets show that\nour method achieves state-of-the-art performance in the reconstruction of\nreflective surfaces, even without reliable initial camera poses.", "published": "2025-04-11 10:16:55", "link": "http://arxiv.org/abs/2504.08410v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Light-YOLOv8-Flame: A Lightweight High-Performance Flame Detection Algorithm", "abstract": "Fire detection algorithms, particularly those based on computer vision,\nencounter significant challenges such as high computational costs and delayed\nresponse times, which hinder their application in real-time systems. To address\nthese limitations, this paper introduces Light-YOLOv8-Flame, a lightweight\nflame detection algorithm specifically designed for fast and efficient\nreal-time deployment. The proposed model enhances the YOLOv8 architecture\nthrough the substitution of the original C2f module with the FasterNet Block\nmodule. This new block combines Partial Convolution (PConv) and Convolution\n(Conv) layers, reducing both computational complexity and model size. A dataset\ncomprising 7,431 images, representing both flame and non-flame scenarios, was\ncollected and augmented for training purposes. Experimental findings indicate\nthat the modified YOLOv8 model achieves a 0.78% gain in mean average precision\n(mAP) and a 2.05% boost in recall, while reducing the parameter count by\n25.34%, with only a marginal decrease in precision by 0.82%. These findings\nhighlight that Light-YOLOv8-Flame offers enhanced detection performance and\nspeed, making it well-suited for real-time fire detection on\nresource-constrained devices.", "published": "2025-04-11 09:42:46", "link": "http://arxiv.org/abs/2504.08389v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Efficient and Robust Moment Retrieval System: A Unified Framework for Multi-Granularity Models and Temporal Reranking", "abstract": "Long-form video understanding presents significant challenges for interactive\nretrieval systems, as conventional methods struggle to process extensive video\ncontent efficiently. Existing approaches often rely on single models,\ninefficient storage, unstable temporal search, and context-agnostic reranking,\nlimiting their effectiveness. This paper presents a novel framework to enhance\ninteractive video retrieval through four key innovations: (1) an ensemble\nsearch strategy that integrates coarse-grained (CLIP) and fine-grained (BEIT3)\nmodels to improve retrieval accuracy, (2) a storage optimization technique that\nreduces redundancy by selecting representative keyframes via TransNetV2 and\ndeduplication, (3) a temporal search mechanism that localizes video segments\nusing dual queries for start and end points, and (4) a temporal reranking\napproach that leverages neighboring frame context to stabilize rankings.\nEvaluated on known-item search and question-answering tasks, our framework\ndemonstrates substantial improvements in retrieval precision, efficiency, and\nuser interpretability, offering a robust solution for real-world interactive\nvideo retrieval applications.", "published": "2025-04-11 09:36:46", "link": "http://arxiv.org/abs/2504.08384v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "In-2-4D: Inbetweening from Two Single-View Images to 4D Generation", "abstract": "We propose a new problem, In-2-4D, for generative 4D (i.e., 3D + motion)\ninbetweening from a minimalistic input setting: two single-view images\ncapturing an object in two distinct motion states. Given two images\nrepresenting the start and end states of an object in motion, our goal is to\ngenerate and reconstruct the motion in 4D. We utilize a video interpolation\nmodel to predict the motion, but large frame-to-frame motions can lead to\nambiguous interpretations. To overcome this, we employ a hierarchical approach\nto identify keyframes that are visually close to the input states and show\nsignificant motion, then generate smooth fragments between them. For each\nfragment, we construct the 3D representation of the keyframe using Gaussian\nSplatting. The temporal frames within the fragment guide the motion, enabling\ntheir transformation into dynamic Gaussians through a deformation field. To\nimprove temporal consistency and refine 3D motion, we expand the self-attention\nof multi-view diffusion across timesteps and apply rigid transformation\nregularization. Finally, we merge the independently generated 3D motion\nsegments by interpolating boundary deformation fields and optimizing them to\nalign with the guiding video, ensuring smooth and flicker-free transitions.\nThrough extensive qualitative and quantitiave experiments as well as a user\nstudy, we show the effectiveness of our method and its components. The project\npage is available at https://in-2-4d.github.io/", "published": "2025-04-11 09:01:09", "link": "http://arxiv.org/abs/2504.08366v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "SN-LiDAR: Semantic Neural Fields for Novel Space-time View LiDAR Synthesis", "abstract": "Recent research has begun exploring novel view synthesis (NVS) for LiDAR\npoint clouds, aiming to generate realistic LiDAR scans from unseen viewpoints.\nHowever, most existing approaches do not reconstruct semantic labels, which are\ncrucial for many downstream applications such as autonomous driving and robotic\nperception. Unlike images, which benefit from powerful segmentation models,\nLiDAR point clouds lack such large-scale pre-trained models, making semantic\nannotation time-consuming and labor-intensive. To address this challenge, we\npropose SN-LiDAR, a method that jointly performs accurate semantic\nsegmentation, high-quality geometric reconstruction, and realistic LiDAR\nsynthesis. Specifically, we employ a coarse-to-fine planar-grid feature\nrepresentation to extract global features from multi-frame point clouds and\nleverage a CNN-based encoder to extract local semantic features from the\ncurrent frame point cloud. Extensive experiments on SemanticKITTI and KITTI-360\ndemonstrate the superiority of SN-LiDAR in both semantic and geometric\nreconstruction, effectively handling dynamic objects and large-scale scenes.\nCodes will be available on https://github.com/dtc111111/SN-Lidar.", "published": "2025-04-11 08:51:23", "link": "http://arxiv.org/abs/2504.08361v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "LMM4LMM: Benchmarking and Evaluating Large-multimodal Image Generation with LMMs", "abstract": "Recent breakthroughs in large multimodal models (LMMs) have significantly\nadvanced both text-to-image (T2I) generation and image-to-text (I2T)\ninterpretation. However, many generated images still suffer from issues related\nto perceptual quality and text-image alignment. Given the high cost and\ninefficiency of manual evaluation, an automatic metric that aligns with human\npreferences is desirable. To this end, we present EvalMi-50K, a comprehensive\ndataset and benchmark for evaluating large-multimodal image generation, which\nfeatures (i) comprehensive tasks, encompassing 2,100 extensive prompts across\n20 fine-grained task dimensions, and (ii) large-scale human-preference\nannotations, including 100K mean-opinion scores (MOSs) and 50K\nquestion-answering (QA) pairs annotated on 50,400 images generated from 24 T2I\nmodels. Based on EvalMi-50K, we propose LMM4LMM, an LMM-based metric for\nevaluating large multimodal T2I generation from multiple dimensions including\nperception, text-image correspondence, and task-specific accuracy. Extensive\nexperimental results show that LMM4LMM achieves state-of-the-art performance on\nEvalMi-50K, and exhibits strong generalization ability on other AI-generated\nimage evaluation benchmark datasets, manifesting the generality of both the\nEvalMi-50K dataset and LMM4LMM metric. Both EvalMi-50K and LMM4LMM will be\nreleased at https://github.com/IntMeGroup/LMM4LMM.", "published": "2025-04-11 08:46:49", "link": "http://arxiv.org/abs/2504.08358v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Single View Garment Reconstruction Using Diffusion Mapping Via Pattern Coordinates", "abstract": "Reconstructing 3D clothed humans from images is fundamental to applications\nlike virtual try-on, avatar creation, and mixed reality. While recent advances\nhave enhanced human body recovery, accurate reconstruction of garment geometry\n-- especially for loose-fitting clothing -- remains an open challenge. We\npresent a novel method for high-fidelity 3D garment reconstruction from single\nimages that bridges 2D and 3D representations. Our approach combines Implicit\nSewing Patterns (ISP) with a generative diffusion model to learn rich garment\nshape priors in a 2D UV space. A key innovation is our mapping model that\nestablishes correspondences between 2D image pixels, UV pattern coordinates,\nand 3D geometry, enabling joint optimization of both 3D garment meshes and the\ncorresponding 2D patterns by aligning learned priors with image observations.\nDespite training exclusively on synthetically simulated cloth data, our method\ngeneralizes effectively to real-world images, outperforming existing approaches\non both tight- and loose-fitting garments. The reconstructed garments maintain\nphysical plausibility while capturing fine geometric details, enabling\ndownstream applications including garment retargeting and texture manipulation.", "published": "2025-04-11 08:39:18", "link": "http://arxiv.org/abs/2504.08353v1", "categories": ["cs.GR", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "Geometric Consistency Refinement for Single Image Novel View Synthesis via Test-Time Adaptation of Diffusion Models", "abstract": "Diffusion models for single image novel view synthesis (NVS) can generate\nhighly realistic and plausible images, but they are limited in the geometric\nconsistency to the given relative poses. The generated images often show\nsignificant errors with respect to the epipolar constraints that should be\nfulfilled, as given by the target pose. In this paper we address this issue by\nproposing a methodology to improve the geometric correctness of images\ngenerated by a diffusion model for single image NVS. We formulate a loss\nfunction based on image matching and epipolar constraints, and optimize the\nstarting noise in a diffusion sampling process such that the generated image\nshould both be a realistic image and fulfill geometric constraints derived from\nthe given target pose. Our method does not require training data or fine-tuning\nof the diffusion models, and we show that we can apply it to multiple\nstate-of-the-art models for single image NVS. The method is evaluated on the\nMegaScenes dataset and we show that geometric consistency is improved compared\nto the baseline models while retaining the quality of the generated images.", "published": "2025-04-11 08:28:41", "link": "http://arxiv.org/abs/2504.08348v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EasyGenNet: An Efficient Framework for Audio-Driven Gesture Video Generation Based on Diffusion Model", "abstract": "Audio-driven cospeech video generation typically involves two stages:\nspeech-to-gesture and gesture-to-video. While significant advances have been\nmade in speech-to-gesture generation, synthesizing natural expressions and\ngestures remains challenging in gesture-to-video systems. In order to improve\nthe generation effect, previous works adopted complex input and training\nstrategies and required a large amount of data sets for pre-training, which\nbrought inconvenience to practical applications. We propose a simple one-stage\ntraining method and a temporal inference method based on a diffusion model to\nsynthesize realistic and continuous gesture videos without the need for\nadditional training of temporal modules.The entire model makes use of existing\npre-trained weights, and only a few thousand frames of data are needed for each\ncharacter at a time to complete fine-tuning. Built upon the video generator, we\nintroduce a new audio-to-video pipeline to synthesize co-speech videos, using\n2D human skeleton as the intermediate motion representation. Our experiments\nshow that our method outperforms existing GAN-based and diffusion-based\nmethods.", "published": "2025-04-11 08:19:18", "link": "http://arxiv.org/abs/2504.08344v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DSM: Building A Diverse Semantic Map for 3D Visual Grounding", "abstract": "In recent years, with the growing research and application of multimodal\nlarge language models (VLMs) in robotics, there has been an increasing trend of\nutilizing VLMs for robotic scene understanding tasks. Existing approaches that\nuse VLMs for 3D Visual Grounding tasks often focus on obtaining scene\ninformation through geometric and visual information, overlooking the\nextraction of diverse semantic information from the scene and the understanding\nof rich implicit semantic attributes, such as appearance, physics, and\naffordance. The 3D scene graph, which combines geometry and language, is an\nideal representation method for environmental perception and is an effective\ncarrier for language models in 3D Visual Grounding tasks. To address these\nissues, we propose a diverse semantic map construction method specifically\ndesigned for robotic agents performing 3D Visual Grounding tasks. This method\nleverages VLMs to capture the latent semantic attributes and relations of\nobjects within the scene and creates a Diverse Semantic Map (DSM) through a\ngeometry sliding-window map construction strategy. We enhance the understanding\nof grounding information based on DSM and introduce a novel approach named\nDSM-Grounding. Experimental results show that our method outperforms current\napproaches in tasks like semantic segmentation and 3D Visual Grounding,\nparticularly excelling in overall metrics compared to the state-of-the-art. In\naddition, we have deployed this method on robots to validate its effectiveness\nin navigation and grasping tasks.", "published": "2025-04-11 07:18:42", "link": "http://arxiv.org/abs/2504.08307v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "STSeg-Complex Video Object Segmentation: The 1st Solution for 4th PVUW MOSE Challenge", "abstract": "Segmentation of video objects in complex scenarios is highly challenging, and\nthe MOSE dataset has significantly contributed to the development of this\nfield. This technical report details the STSeg solution proposed by the\n\"imaplus\" team.By finetuning SAM2 and the unsupervised model TMO on the MOSE\ndataset, the STSeg solution demonstrates remarkable advantages in handling\ncomplex object motions and long-video sequences. In the inference phase, an\nAdaptive Pseudo-labels Guided Model Refinement Pipeline is adopted to\nintelligently select appropriate models for processing each video. Through\nfinetuning the models and employing the Adaptive Pseudo-labels Guided Model\nRefinement Pipeline in the inference phase, the STSeg solution achieved a J&F\nscore of 87.26% on the test set of the 2025 4th PVUW Challenge MOSE Track,\nsecuring the 1st place and advancing the technology for video object\nsegmentation in complex scenarios.", "published": "2025-04-11 07:15:32", "link": "http://arxiv.org/abs/2504.08306v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generative AI for Film Creation: A Survey of Recent Advances", "abstract": "Generative AI (GenAI) is transforming filmmaking, equipping artists with\ntools like text-to-image and image-to-video diffusion, neural radiance fields,\navatar generation, and 3D synthesis. This paper examines the adoption of these\ntechnologies in filmmaking, analyzing workflows from recent AI-driven films to\nunderstand how GenAI contributes to character creation, aesthetic styling, and\nnarration. We explore key strategies for maintaining character consistency,\nachieving stylistic coherence, and ensuring motion continuity. Additionally, we\nhighlight emerging trends such as the growing use of 3D generation and the\nintegration of real footage with AI-generated elements.\n  Beyond technical advancements, we examine how GenAI is enabling new artistic\nexpressions, from generating hard-to-shoot footage to dreamlike diffusion-based\nmorphing effects, abstract visuals, and unworldly objects. We also gather\nartists' feedback on challenges and desired improvements, including\nconsistency, controllability, fine-grained editing, and motion refinement. Our\nstudy provides insights into the evolving intersection of AI and filmmaking,\noffering a roadmap for researchers and artists navigating this rapidly\nexpanding field.", "published": "2025-04-11 06:54:29", "link": "http://arxiv.org/abs/2504.08296v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DreamFuse: Adaptive Image Fusion with Diffusion Transformer", "abstract": "Image fusion seeks to seamlessly integrate foreground objects with background\nscenes, producing realistic and harmonious fused images. Unlike existing\nmethods that directly insert objects into the background, adaptive and\ninteractive fusion remains a challenging yet appealing task. It requires the\nforeground to adjust or interact with the background context, enabling more\ncoherent integration. To address this, we propose an iterative\nhuman-in-the-loop data generation pipeline, which leverages limited initial\ndata with diverse textual prompts to generate fusion datasets across various\nscenarios and interactions, including placement, holding, wearing, and style\ntransfer. Building on this, we introduce DreamFuse, a novel approach based on\nthe Diffusion Transformer (DiT) model, to generate consistent and harmonious\nfused images with both foreground and background information. DreamFuse employs\na Positional Affine mechanism to inject the size and position of the foreground\ninto the background, enabling effective foreground-background interaction\nthrough shared attention. Furthermore, we apply Localized Direct Preference\nOptimization guided by human feedback to refine DreamFuse, enhancing background\nconsistency and foreground harmony. DreamFuse achieves harmonious fusion while\ngeneralizing to text-driven attribute editing of the fused results.\nExperimental results demonstrate that our method outperforms state-of-the-art\napproaches across multiple metrics.", "published": "2025-04-11 06:49:33", "link": "http://arxiv.org/abs/2504.08291v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PNE-SGAN: Probabilistic NDT-Enhanced Semantic Graph Attention Network for LiDAR Loop Closure Detection", "abstract": "LiDAR loop closure detection (LCD) is crucial for consistent Simultaneous\nLocalization and Mapping (SLAM) but faces challenges in robustness and\naccuracy. Existing methods, including semantic graph approaches, often suffer\nfrom coarse geometric representations and lack temporal robustness against\nnoise, dynamics, and viewpoint changes. We introduce PNE-SGAN, a Probabilistic\nNDT-Enhanced Semantic Graph Attention Network, to overcome these limitations.\nPNE-SGAN enhances semantic graphs by using Normal Distributions Transform (NDT)\ncovariance matrices as rich, discriminative geometric node features, processed\nvia a Graph Attention Network (GAT). Crucially, it integrates graph similarity\nscores into a probabilistic temporal filtering framework (modeled as an\nHMM/Bayes filter), incorporating uncertain odometry for motion modeling and\nutilizing forward-backward smoothing to effectively handle ambiguities.\nEvaluations on challenging KITTI sequences (00 and 08) demonstrate\nstate-of-the-art performance, achieving Average Precision of 96.2\\% and 95.1\\%,\nrespectively. PNE-SGAN significantly outperforms existing methods, particularly\nin difficult bidirectional loop scenarios where others falter. By synergizing\ndetailed NDT geometry with principled probabilistic temporal reasoning,\nPNE-SGAN offers a highly accurate and robust solution for LiDAR LCD, enhancing\nSLAM reliability in complex, large-scale environments.", "published": "2025-04-11 06:25:11", "link": "http://arxiv.org/abs/2504.08280v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Palmprint De-Identification Using Diffusion Model for High-Quality and Diverse Synthesis", "abstract": "Palmprint recognition techniques have advanced significantly in recent years,\nenabling reliable recognition even when palmprints are captured in uncontrolled\nor challenging environments. However, this strength also introduces new risks,\nas publicly available palmprint images can be misused by adversaries for\nmalicious activities. Despite this growing concern, research on methods to\nobscure or anonymize palmprints remains largely unexplored. Thus, it is\nessential to develop a palmprint de-identification technique capable of\nremoving identity-revealing features while retaining the image's utility and\npreserving non-sensitive information. In this paper, we propose a training-free\nframework that utilizes pre-trained diffusion models to generate diverse,\nhigh-quality palmprint images that conceal identity features for\nde-identification purposes. To ensure greater stability and controllability in\nthe synthesis process, we incorporate a semantic-guided embedding fusion\nalongside a prior interpolation mechanism. We further propose the\nde-identification ratio, a novel metric for intuitive de-identification\nassessment. Extensive experiments across multiple palmprint datasets and\nrecognition methods demonstrate that our method effectively conceals\nidentity-related traits with significant diversity across de-identified\nsamples. The de-identified samples preserve high visual fidelity and maintain\nexcellent usability, achieving a balance between de-identification and\nretaining non-identity information.", "published": "2025-04-11 06:00:06", "link": "http://arxiv.org/abs/2504.08272v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Knowledge Distillation for Underwater Feature Extraction and Matching via GAN-synthesized Images", "abstract": "Autonomous Underwater Vehicles (AUVs) play a crucial role in underwater\nexploration. Vision-based methods offer cost-effective solutions for\nlocalization and mapping in the absence of conventional sensors like GPS and\nLIDAR. However, underwater environments present significant challenges for\nfeature extraction and matching due to image blurring and noise caused by\nattenuation, scattering, and the interference of \\textit{marine snow}. In this\npaper, we aim to improve the robustness of the feature extraction and matching\nin the turbid underwater environment using the cross-modal knowledge\ndistillation method that transfers the in-air feature extraction models to\nunderwater settings using synthetic underwater images as the medium. We first\npropose a novel adaptive GAN-synthesis method to estimate water parameters and\nunderwater noise distribution, to generate environment-specific synthetic\nunderwater images. We then introduce a general knowledge distillation framework\ncompatible with different teacher models. The evaluation of GAN-based synthesis\nhighlights the significance of the new components, i.e. GAN-synthesized noise\nand forward scattering, in the proposed model. Additionally, the downstream\napplication of feature extraction and matching (VSLAM) on real underwater\nsequences validates the effectiveness of the transferred model.", "published": "2025-04-11 04:34:18", "link": "http://arxiv.org/abs/2504.08253v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Stereophotoclinometry Revisited", "abstract": "Image-based surface reconstruction and characterization is crucial for\nmissions to small celestial bodies, as it informs mission planning, navigation,\nand scientific analysis. However, current state-of-the-practice methods, such\nas stereophotoclinometry (SPC), rely heavily on human-in-the-loop verification\nand high-fidelity a priori information. This paper proposes\nPhotoclinometry-from-Motion (PhoMo), a novel framework that incorporates\nphotoclinometry techniques into a keypoint-based structure-from-motion (SfM)\nsystem to estimate the surface normal and albedo at detected landmarks to\nimprove autonomous surface and shape characterization of small celestial bodies\nfrom in-situ imagery. In contrast to SPC, we forego the expensive maplet\nestimation step and instead use dense keypoint measurements and correspondences\nfrom an autonomous keypoint detection and matching method based on deep\nlearning. Moreover, we develop a factor graph-based approach allowing for\nsimultaneous optimization of the spacecraft's pose, landmark positions,\nSun-relative direction, and surface normals and albedos via fusion of Sun\nvector measurements and image keypoint measurements. The proposed framework is\nvalidated on real imagery taken by the Dawn mission to the asteroid 4 Vesta and\nthe minor planet 1 Ceres and compared against an SPC reconstruction, where we\ndemonstrate superior rendering performance compared to an SPC solution and\nprecise alignment to a stereophotogrammetry (SPG) solution without relying on\nany a priori camera pose and topography information or humans-in-the-loop.", "published": "2025-04-11 04:33:56", "link": "http://arxiv.org/abs/2504.08252v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VL-UR: Vision-Language-guided Universal Restoration of Images Degraded by Adverse Weather Conditions", "abstract": "Image restoration is critical for improving the quality of degraded images,\nwhich is vital for applications like autonomous driving, security surveillance,\nand digital content enhancement. However, existing methods are often tailored\nto specific degradation scenarios, limiting their adaptability to the diverse\nand complex challenges in real-world environments. Moreover, real-world\ndegradations are typically non-uniform, highlighting the need for adaptive and\nintelligent solutions. To address these issues, we propose a novel\nvision-language-guided universal restoration (VL-UR) framework. VL-UR leverages\na zero-shot contrastive language-image pre-training (CLIP) model to enhance\nimage restoration by integrating visual and semantic information. A scene\nclassifier is introduced to adapt CLIP, generating high-quality language\nembeddings aligned with degraded images while predicting degraded types for\ncomplex scenarios. Extensive experiments across eleven diverse degradation\nsettings demonstrate VL-UR's state-of-the-art performance, robustness, and\nadaptability. This positions VL-UR as a transformative solution for modern\nimage restoration challenges in dynamic, real-world environments.", "published": "2025-04-11 02:59:06", "link": "http://arxiv.org/abs/2504.08219v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RealCam-Vid: High-resolution Video Dataset with Dynamic Scenes and Metric-scale Camera Movements", "abstract": "Recent advances in camera-controllable video generation have been constrained\nby the reliance on static-scene datasets with relative-scale camera\nannotations, such as RealEstate10K. While these datasets enable basic viewpoint\ncontrol, they fail to capture dynamic scene interactions and lack metric-scale\ngeometric consistency-critical for synthesizing realistic object motions and\nprecise camera trajectories in complex environments. To bridge this gap, we\nintroduce the first fully open-source, high-resolution dynamic-scene dataset\nwith metric-scale camera annotations in https://github.com/ZGCTroy/RealCam-Vid.", "published": "2025-04-11 02:35:19", "link": "http://arxiv.org/abs/2504.08212v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EO-VLM: VLM-Guided Energy Overload Attacks on Vision Models", "abstract": "Vision models are increasingly deployed in critical applications such as\nautonomous driving and CCTV monitoring, yet they remain susceptible to\nresource-consuming attacks. In this paper, we introduce a novel\nenergy-overloading attack that leverages vision language model (VLM) prompts to\ngenerate adversarial images targeting vision models. These images, though\nimperceptible to the human eye, significantly increase GPU energy consumption\nacross various vision models, threatening the availability of these systems.\nOur framework, EO-VLM (Energy Overload via VLM), is model-agnostic, meaning it\nis not limited by the architecture or type of the target vision model. By\nexploiting the lack of safety filters in VLMs like DALL-E 3, we create\nadversarial noise images without requiring prior knowledge or internal\nstructure of the target vision models. Our experiments demonstrate up to a 50%\nincrease in energy consumption, revealing a critical vulnerability in current\nvision models.", "published": "2025-04-11 02:13:24", "link": "http://arxiv.org/abs/2504.08205v1", "categories": ["cs.CV", "cs.CR"], "primary_category": "cs.CV"}
{"title": "Comparative Analysis of Different Methods for Classifying Polychromatic Sketches", "abstract": "Image classification is a significant challenge in computer vision,\nparticularly in domains humans are not accustomed to. As machine learning and\nartificial intelligence become more prominent, it is crucial these algorithms\ndevelop a sense of sight that is on par with or exceeds human ability. For this\nreason, we have collected, cleaned, and parsed a large dataset of hand-drawn\ndoodles and compared multiple machine learning solutions to classify these\nimages into 170 distinct categories. The best model we found achieved a Top-1\naccuracy of 47.5%, significantly surpassing human performance on the dataset,\nwhich stands at 41%.", "published": "2025-04-11 01:06:36", "link": "http://arxiv.org/abs/2504.08186v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-person Physics-based Pose Estimation for Combat Sports", "abstract": "We propose a novel framework for accurate 3D human pose estimation in combat\nsports using sparse multi-camera setups. Our method integrates robust\nmulti-view 2D pose tracking via a transformer-based top-down approach,\nemploying epipolar geometry constraints and long-term video object segmentation\nfor consistent identity tracking across views. Initial 3D poses are obtained\nthrough weighted triangulation and spline smoothing, followed by kinematic\noptimization to refine pose accuracy. We further enhance pose realism and\nrobustness by introducing a multi-person physics-based trajectory optimization\nstep, effectively addressing challenges such as rapid motions, occlusions, and\nclose interactions. Experimental results on diverse datasets, including a new\nbenchmark of elite boxing footage, demonstrate state-of-the-art performance.\nAdditionally, we release comprehensive annotated video datasets to advance\nfuture research in multi-person pose estimation for combat sports.", "published": "2025-04-11 00:08:14", "link": "http://arxiv.org/abs/2504.08175v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "$\u03c7$-Boundedness and Neighbourhood Complexity of Bounded Merge-Width Graphs", "abstract": "Merge-width, recently introduced by Dreier and Toru\\'nczyk, is a common\ngeneralisation of bounded expansion classes and twin-width for which the\nfirst-order model checking problem remains tractable. We prove that a number of\nbasic properties shared by bounded expansion and bounded twin-width graphs also\nhold for bounded merge-width graphs: they are $\\chi$-bounded, they satisfy the\nstrong Erd\\H{o}s-Hajnal property, and their neighbourhood complexity is linear.", "published": "2025-04-11 05:43:21", "link": "http://arxiv.org/abs/2504.08266v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "A Comparative Study of Recommender Systems under Big Data Constraints", "abstract": "Recommender Systems (RS) have become essential tools in a wide range of\ndigital services, from e-commerce and streaming platforms to news and social\nmedia. As the volume of user-item interactions grows exponentially, especially\nin Big Data environments, selecting the most appropriate RS model becomes a\ncritical task. This paper presents a comparative study of several\nstate-of-the-art recommender algorithms, including EASE-R, SLIM, SLIM with\nElasticNet regularization, Matrix Factorization (FunkSVD and ALS), P3Alpha, and\nRP3Beta. We evaluate these models according to key criteria such as\nscalability, computational complexity, predictive accuracy, and\ninterpretability. The analysis considers both their theoretical underpinnings\nand practical applicability in large-scale scenarios. Our results highlight\nthat while models like SLIM and SLIM-ElasticNet offer high accuracy and\ninterpretability, they suffer from high computational costs, making them less\nsuitable for real-time applications. In contrast, algorithms such as EASE-R and\nRP3Beta achieve a favorable balance between performance and scalability,\nproving more effective in large-scale environments. This study aims to provide\nguidelines for selecting the most appropriate recommender approach based on\nspecific Big Data constraints and system requirements.", "published": "2025-04-11 11:35:13", "link": "http://arxiv.org/abs/2504.08457v1", "categories": ["cs.IR", "Primary 68T05, 68P20, Secondary 68W20, 68R10"], "primary_category": "cs.IR"}
{"title": "A Reproducibility Study of Graph-Based Legal Case Retrieval", "abstract": "Legal retrieval is a widely studied area in Information Retrieval (IR) and a\nkey task in this domain is retrieving relevant cases based on a given query\ncase, often done by applying language models as encoders to model case\nsimilarity. Recently, Tang et al. proposed CaseLink, a novel graph-based method\nfor legal case retrieval, which models both cases and legal charges as nodes in\na network, with edges representing relationships such as references and shared\nsemantics. This approach offers a new perspective on the task by capturing\nhigher-order relationships of cases going beyond the stand-alone level of\ndocuments. However, while this shift in approaching legal case retrieval is a\npromising direction in an understudied area of graph-based legal IR, challenges\nin reproducing novel results have recently been highlighted, with multiple\nstudies reporting difficulties in reproducing previous findings. Thus, in this\nwork we reproduce CaseLink, a graph-based legal case retrieval method, to\nsupport future research in this area of IR. In particular, we aim to assess its\nreliability and generalizability by (i) first reproducing the original study\nsetup and (ii) applying the approach to an additional dataset. We then build\nupon the original implementations by (iii) evaluating the approach's\nperformance when using a more sophisticated graph data representation and (iv)\nusing an open large language model (LLM) in the pipeline to address limitations\nthat are known to result from using closed models accessed via an API. Our\nfindings aim to improve the understanding of graph-based approaches in legal IR\nand contribute to improving reproducibility in the field. To achieve this, we\nshare all our implementations and experimental artifacts with the community.", "published": "2025-04-11 10:04:12", "link": "http://arxiv.org/abs/2504.08400v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "OnSET: Ontology and Semantic Exploration Toolkit", "abstract": "Retrieval over knowledge graphs is usually performed using dedicated, complex\nquery languages like SPARQL. We propose a novel system, Ontology and Semantic\nExploration Toolkit (OnSET) that allows non-expert users to easily build\nqueries with visual user guidance provided by topic modelling and semantic\nsearch throughout the application. OnSET allows users without any prior\ninformation about the ontology or networked knowledge to start exploring topics\nof interest over knowledge graphs, including the retrieval and detailed\nexploration of prototypical sub-graphs and their instances. Existing systems\neither focus on direct graph explorations or do not foster further exploration\nof the result set. We, however, provide a node-based editor that can extend on\nthese missing properties of existing systems to support the search over big\nontologies with sub-graph instances. Furthermore, OnSET combines efficient and\nopen platforms to deploy the system on commodity hardware.", "published": "2025-04-11 09:18:06", "link": "http://arxiv.org/abs/2504.08373v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "eST$^2$ Miner -- Process Discovery Based on Firing Partial Orders", "abstract": "Process discovery generates process models from event logs. Traditionally, an\nevent log is defined as a multiset of traces, where each trace is a sequence of\nevents. The total order of the events in a sequential trace is typically based\non their temporal occurrence. However, real-life processes are partially\nordered by nature. Different activities can occur in different parts of the\nprocess and, thus, independently of each other. Therefore, the temporal total\norder of events does not necessarily reflect their causal order, as also\ncausally unrelated events may be ordered in time. Only partial orders allow to\nexpress concurrency, duration, overlap, and uncertainty of events.\nConsequently, there is a growing need for process mining algorithms that can\ndirectly handle partially ordered input. In this paper, we combine two\nwell-established and efficient algorithms, the eST Miner from the process\nmining community and the Firing LPO algorithm from the Petri net community, to\nintroduce the eST$^2$ Miner. The eST$^2$ Miner is a process discovery algorithm\nthat can directly handle partially ordered input, gives strong formal\nguarantees, offers good runtime and excellent space complexity, and can, thus,\nbe used in real-life applications.", "published": "2025-04-11 09:16:54", "link": "http://arxiv.org/abs/2504.08372v1", "categories": ["cs.DB", "cs.IR"], "primary_category": "cs.DB"}
{"title": "Joint Transmit Waveform and Receive Filter Design for ISAC System with Jamming", "abstract": "In this paper, to suppress jamming in the complex electromagnetic\nenvironment, we propose a joint transmit waveform and receive filter design\nframework for integrated sensing and communications (ISAC). By jointly\noptimizing the transmit waveform and receive filters, we aim at minimizing the\nmultiuser interference (MUI), subject to the constraints of the target\nmainlobe, jamming mainlobe and peak sidelobe level of the receive filter output\nas well as the transmit power of the ISAC base station. We propose two schemes\nto solve the problem, including joint transmit waveform and matched filter\ndesign (JTMD) and joint transmit waveform and mismatched filter design (JTMMD)\nschemes. For both schemes, we adopt the alternating direction method of\nmultipliers to iteratively optimize the transmit waveform and receive filters,\nwhere the number of targets as well as the range and angles of each target can\nalso be estimated. Simulation results show that both the JTMD and JTMMD schemes\nachieve superior performance in terms of communication MUI and radar detection\nperformance.", "published": "2025-04-11 13:32:29", "link": "http://arxiv.org/abs/2504.08520v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Simultaneous Rational Number Codes: Decoding Beyond Half the Minimum Distance with Multiplicities and Bad Primes", "abstract": "In this paper, we extend the work of (Abbondati et al., 2024) on decoding\nsimultaneous rational number codes by addressing two important scenarios:\nmultiplicities and the presence of bad primes (divisors of denominators).\nFirst, we generalize previous results to multiplicity rational codes by\nconsidering modular reductions with respect to prime power moduli. Then, using\nhybrid analysis techniques, we extend our approach to vectors of fractions that\nmay present bad primes. Our contributions include: a decoding algorithm for\nsimultaneous rational number reconstruction with multiplicities, a rigorous\nanalysis of the algorithm's failure probability that generalizes several\nprevious results, an extension to a hybrid model handling situations where not\nall errors can be assumed random, and a unified approach to handle bad primes\nwithin multiplicities. The theoretical results provide a comprehensive\nprobabilistic analysis of reconstruction failure in these more complex\nscenarios, advancing the state of the art in error correction for rational\nnumber codes.", "published": "2025-04-11 12:01:41", "link": "http://arxiv.org/abs/2504.08472v1", "categories": ["cs.IT", "cs.SC", "math.IT"], "primary_category": "cs.IT"}
{"title": "High-dimensional Clustering and Signal Recovery under Block Signals", "abstract": "This paper studies computationally efficient methods and their minimax\noptimality for high-dimensional clustering and signal recovery under block\nsignal structures. We propose two sets of methods, cross-block feature\naggregation PCA (CFA-PCA) and moving average PCA (MA-PCA), designed for sparse\nand dense block signals, respectively. Both methods adaptively utilize block\nsignal structures, applicable to non-Gaussian data with heterogeneous variances\nand non-diagonal covariance matrices. Specifically, the CFA method utilizes a\nblock-wise U-statistic to aggregate and select block signals non-parametrically\nfrom data with unknown cluster labels. We show that the proposed methods are\nconsistent for both clustering and signal recovery under mild conditions and\nweaker signal strengths than the existing methods without considering block\nstructures of signals. Furthermore, we derive both statistical and\ncomputational minimax lower bounds (SMLB and CMLB) for high-dimensional\nclustering and signal recovery under block signals, where the CMLBs are\nrestricted to algorithms with polynomial computation complexity. The minimax\nboundaries partition signals into regions of impossibility and possibility. No\nalgorithm (or no polynomial time algorithm) can achieve consistent clustering\nor signal recovery if the signals fall into the statistical (or computational)\nregion of impossibility. We show that the proposed CFA-PCA and MA-PCA methods\ncan achieve the CMLBs for the sparse and dense block signal regimes,\nrespectively, indicating the proposed methods are computationally minimax\noptimal. A tuning parameter selection method is proposed based on\npost-clustering signal recovery results. Simulation studies are conducted to\nevaluate the proposed methods. A case study on global temperature change\ndemonstrates their utility in practice.", "published": "2025-04-11 07:54:55", "link": "http://arxiv.org/abs/2504.08332v1", "categories": ["stat.ME", "cs.IT", "math.IT", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "A General DoF and Pattern Analyzing Scheme for Electromagnetic Information Theory", "abstract": "Electromagnetic information theory (EIT) is one of the emerging topics for 6G\ncommunication due to its potential to reveal the performance limit of wireless\ncommunication systems. For EIT, one of the most important research directions\nis degree of freedom (DoF) analysis. Existing research works on DoF analysis\nfor EIT focus on asymptotic conclusions of DoF, which do not well fit the\npractical wireless communication systems with finite spatial regions and finite\nfrequency bandwidth. In this paper, we use the theoretical analyzing tools from\nSlepian concentration problem and extend them to three-dimensional space domain\nand four-dimensional space-time domain under electromagnetic constraints. Then\nwe provide asymptotic DoF conclusions and non-asymptotic DoF analyzing scheme,\nwhich suits practical scenarios better, under different scenarios like\nthree-dimensional antenna array. Moreover, we theoretically prove that the\nchannel DoF is upper bounded by the proposed DoF of electromagnetic fields.\nFinally, we use numerical analysis to provide some insights about the optimal\nspatial sampling interval of the antenna array, the DoF of three-dimensional\nantenna array, the impact of unequal antenna spacing, the orthogonal space-time\npatterns, etc.", "published": "2025-04-11 05:27:33", "link": "http://arxiv.org/abs/2504.08262v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Dimension reduction for derivative-informed operator learning: An analysis of approximation errors", "abstract": "We study the derivative-informed learning of nonlinear operators between\ninfinite-dimensional separable Hilbert spaces by neural networks. Such\noperators can arise from the solution of partial differential equations (PDEs),\nand are used in many simulation-based outer-loop tasks in science and\nengineering, such as PDE-constrained optimization, Bayesian inverse problems,\nand optimal experimental design. In these settings, the neural network\napproximations can be used as surrogate models to accelerate the solution of\nthe outer-loop tasks. However, since outer-loop tasks in infinite dimensions\noften require knowledge of the underlying geometry, the approximation accuracy\nof the operator's derivatives can also significantly impact the performance of\nthe surrogate model. Motivated by this, we analyze the approximation errors of\nneural operators in Sobolev norms over infinite-dimensional Gaussian input\nmeasures. We focus on the reduced basis neural operator (RBNO), which uses\nlinear encoders and decoders defined on dominant input/output subspaces spanned\nby reduced sets of orthonormal bases. To this end, we study two methods for\ngenerating the bases; principal component analysis (PCA) and\nderivative-informed subspaces (DIS), which use the dominant eigenvectors of the\ncovariance of the data or the derivatives as the reduced bases, respectively.\nWe then derive bounds for errors arising from both the dimension reduction and\nthe latent neural network approximation, including the sampling errors\nassociated with the empirical estimation of the PCA/DIS. Our analysis is\nvalidated on numerical experiments with elliptic PDEs, where our results show\nthat bases informed by the map (i.e., DIS or output PCA) yield accurate\nreconstructions and generalization errors for both the operator and its\nderivatives, while input PCA may underperform unless ranks and training sample\nsizes are sufficiently large.", "published": "2025-04-11 17:56:52", "link": "http://arxiv.org/abs/2504.08730v1", "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "math.NA"}
{"title": "Surrogate-based optimization of system architectures subject to hidden constraints", "abstract": "The exploration of novel architectures requires physics-based simulation due\nto a lack of prior experience to start from, which introduces two specific\nchallenges for optimization algorithms: evaluations become more expensive (in\ntime) and evaluations might fail. The former challenge is addressed by\nSurrogate-Based Optimization (SBO) algorithms, in particular Bayesian\nOptimization (BO) using Gaussian Process (GP) models. An overview is provided\nof how BO can deal with challenges specific to architecture optimization, such\nas design variable hierarchy and multiple objectives: specific measures include\nensemble infills and a hierarchical sampling algorithm. Evaluations might fail\ndue to non-convergence of underlying solvers or infeasible geometry in certain\nareas of the design space. Such failed evaluations, also known as hidden\nconstraints, pose a particular challenge to SBO/BO, as the surrogate model\ncannot be trained on empty results. This work investigates various strategies\nfor satisfying hidden constraints in BO algorithms. Three high-level strategies\nare identified: rejection of failed points from the training set, replacing\nfailed points based on viable (non-failed) points, and predicting the failure\nregion. Through investigations on a set of test problems including a jet engine\narchitecture optimization problem, it is shown that best performance is\nachieved with a mixed-discrete GP to predict the Probability of Viability\n(PoV), and by ensuring selected infill points satisfy some minimum PoV\nthreshold. This strategy is demonstrated by solving a jet engine architecture\nproblem that features at 50% failure rate and could not previously be solved by\na BO algorithm. The developed BO algorithm and used test problems are available\nin the open-source Python library SBArchOpt.", "published": "2025-04-11 17:35:58", "link": "http://arxiv.org/abs/2504.08721v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Beyond Black-Box Predictions: Identifying Marginal Feature Effects in Tabular Transformer Networks", "abstract": "In recent years, deep neural networks have showcased their predictive power\nacross a variety of tasks. Beyond natural language processing, the transformer\narchitecture has proven efficient in addressing tabular data problems and\nchallenges the previously dominant gradient-based decision trees in these\nareas. However, this predictive power comes at the cost of intelligibility:\nMarginal feature effects are almost completely lost in the black-box nature of\ndeep tabular transformer networks. Alternative architectures that use the\nadditivity constraints of classical statistical regression models can maintain\nintelligible marginal feature effects, but often fall short in predictive power\ncompared to their more complex counterparts. To bridge the gap between\nintelligibility and performance, we propose an adaptation of tabular\ntransformer networks designed to identify marginal feature effects. We provide\ntheoretical justifications that marginal feature effects can be accurately\nidentified, and our ablation study demonstrates that the proposed model\nefficiently detects these effects, even amidst complex feature interactions. To\ndemonstrate the model's predictive capabilities, we compare it to several\ninterpretable as well as black-box models and find that it can match black-box\nperformances while maintaining intelligibility. The source code is available at\nhttps://github.com/OpenTabular/NAMpy.", "published": "2025-04-11 17:23:09", "link": "http://arxiv.org/abs/2504.08712v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Offline Reinforcement Learning using Human-Aligned Reward Labeling for Autonomous Emergency Braking in Occluded Pedestrian Crossing", "abstract": "Effective leveraging of real-world driving datasets is crucial for enhancing\nthe training of autonomous driving systems. While Offline Reinforcement\nLearning enables the training of autonomous vehicles using such data, most\navailable datasets lack meaningful reward labels. Reward labeling is essential\nas it provides feedback for the learning algorithm to distinguish between\ndesirable and undesirable behaviors, thereby improving policy performance. This\npaper presents a novel pipeline for generating human-aligned reward labels. The\nproposed approach addresses the challenge of absent reward signals in\nreal-world datasets by generating labels that reflect human judgment and safety\nconsiderations. The pipeline incorporates an adaptive safety component,\nactivated by analyzing semantic segmentation maps, allowing the autonomous\nvehicle to prioritize safety over efficiency in potential collision scenarios.\nThe proposed pipeline is applied to an occluded pedestrian crossing scenario\nwith varying levels of pedestrian traffic, using synthetic and simulation data.\nThe results indicate that the generated reward labels closely match the\nsimulation reward labels. When used to train the driving policy using Behavior\nProximal Policy Optimisation, the results are competitive with other baselines.\nThis demonstrates the effectiveness of our method in producing reliable and\nhuman-aligned reward signals, facilitating the training of autonomous driving\nsystems through Reinforcement Learning outside of simulation environments and\nin alignment with human values.", "published": "2025-04-11 17:11:21", "link": "http://arxiv.org/abs/2504.08704v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "SeaView: Software Engineering Agent Visual Interface for Enhanced Workflow", "abstract": "Auto-regressive LLM-based software engineering (SWE) agents, henceforth SWE\nagents, have made tremendous progress (>60% on SWE-Bench Verified) on\nreal-world coding challenges including GitHub issue resolution. SWE agents use\na combination of reasoning, environment interaction and self-reflection to\nresolve issues thereby generating \"trajectories\". Analysis of SWE agent\ntrajectories is difficult, not only as they exceed LLM sequence length\n(sometimes, greater than 128k) but also because it involves a relatively\nprolonged interaction between an LLM and the environment managed by the agent.\nIn case of an agent error, it can be hard to decipher, locate and understand\nits scope. Similarly, it can be hard to track improvements or regression over\nmultiple runs or experiments. While a lot of research has gone into making\nthese SWE agents reach state-of-the-art, much less focus has been put into\ncreating tools to help analyze and visualize agent output. We propose a novel\ntool called SeaView: Software Engineering Agent Visual Interface for Enhanced\nWorkflow, with a vision to assist SWE-agent researchers to visualize and\ninspect their experiments. SeaView's novel mechanisms help compare experimental\nruns with varying hyper-parameters or LLMs, and quickly get an understanding of\nLLM or environment related problems. Based on our user study, experienced\nresearchers spend between 10 and 30 minutes to gather the information provided\nby SeaView, while researchers with little experience can spend between 30\nminutes to 1 hour to diagnose their experiment.", "published": "2025-04-11 17:03:58", "link": "http://arxiv.org/abs/2504.08696v1", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Bayesian optimization for mixed variables using an adaptive dimension reduction process: applications to aircraft design", "abstract": "Multidisciplinary design optimization methods aim at adapting numerical\noptimization techniques to the design of engineering systems involving multiple\ndisciplines. In this context, a large number of mixed continuous, integer and\ncategorical variables might arise during the optimization process and practical\napplications involve a large number of design variables. Recently, there has\nbeen a growing interest in mixed variables constrained Bayesian optimization\nbut most existing approaches severely increase the number of the\nhyperparameters related to the surrogate model. In this paper, we address this\nissue by constructing surrogate models using less hyperparameters. The\nreduction process is based on the partial least squares method. An adaptive\nprocedure for choosing the number of hyperparameters is proposed. The\nperformance of the proposed approach is confirmed on analytical tests as well\nas two real applications related to aircraft design. A significant improvement\nis obtained compared to genetic algorithms.", "published": "2025-04-11 16:43:11", "link": "http://arxiv.org/abs/2504.08682v1", "categories": ["stat.ME", "cs.LG", "math.OC", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Regularized infill criteria for multi-objective Bayesian optimization with application to aircraft design", "abstract": "Bayesian optimization is an advanced tool to perform ecient global\noptimization It consists on enriching iteratively surrogate Kriging models of\nthe objective and the constraints both supposed to be computationally expensive\nof the targeted optimization problem Nowadays efficient extensions of Bayesian\noptimization to solve expensive multiobjective problems are of high interest\nThe proposed method in this paper extends the super efficient global\noptimization with mixture of experts SEGOMOE to solve constrained\nmultiobjective problems To cope with the illposedness of the multiobjective\ninll criteria different enrichment procedures using regularization techniques\nare proposed The merit of the proposed approaches are shown on known\nmultiobjective benchmark problems with and without constraints The proposed\nmethods are then used to solve a biobjective application related to conceptual\naircraft design with ve unknown design variables and three nonlinear inequality\nconstraints The preliminary results show a reduction of the total cost in terms\nof function evaluations by a factor of 20 compared to the evolutionary\nalgorithm NSGA-II.", "published": "2025-04-11 16:24:40", "link": "http://arxiv.org/abs/2504.08671v1", "categories": ["cs.LG", "math.ST", "stat.AP", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Channel Estimation by Infinite Width Convolutional Networks", "abstract": "In wireless communications, estimation of channels in OFDM systems spans\nfrequency and time, which relies on sparse collections of pilot data, posing an\nill-posed inverse problem. Moreover, deep learning estimators require large\namounts of training data, computational resources, and true channels to produce\naccurate channel estimates, which are not realistic. To address this, a\nconvolutional neural tangent kernel (CNTK) is derived from an infinitely wide\nconvolutional network whose training dynamics can be expressed by a closed-form\nequation. This CNTK is used to impute the target matrix and estimate the\nmissing channel response using only the known values available at pilot\nlocations. This is a promising solution for channel estimation that does not\nrequire a large training set. Numerical results on realistic channel datasets\ndemonstrate that our strategy accurately estimates the channels without a large\ndataset and significantly outperforms deep learning methods in terms of speed,\naccuracy, and computational resources.", "published": "2025-04-11 16:01:17", "link": "http://arxiv.org/abs/2504.08660v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Application of machine learning models to predict the relationship between air pollution, ecosystem degradation, and health disparities and lung cancer in Vietnam", "abstract": "Lung cancer is one of the major causes of death worldwide, and Vietnam is not\nan exception. This disease is the second most common type of cancer globally\nand the second most common cause of death in Vietnam, just after liver cancer,\nwith 23,797 fatal cases and 26,262 new cases, or 14.4% of the disease in 2020.\nRecently, with rising disease rates in Vietnam causing a huge public health\nburden, lung cancer continues to hold the top position in attention and care.\nEspecially together with climate change, under a variety of types of pollution,\ndeforestation, and modern lifestyles, lung cancer risks are on red alert,\nparticularly in Vietnam. To understand more about the severe disease sources in\nVietnam from a diversity of key factors, including environmental features and\nthe current health state, with a particular emphasis on Vietnam's distinct\nsocioeconomic and ecological context, we utilize large datasets such as patient\nhealth records and environmental indicators containing necessary information,\nsuch as deforestation rate, green cover rate, air pollution, and lung cancer\nrisks, that is collected from well-known governmental sharing websites. Then,\nwe process and connect them and apply analytical methods (heatmap, information\ngain, p-value, spearman correlation) to determine causal correlations\ninfluencing lung cancer risks. Moreover, we deploy machine learning (ML) models\n(Decision Tree, Random Forest, Support Vector Machine, K-mean clustering) to\ndiscover cancer risk patterns. Our experimental results, leveraged by the\naforementioned ML models to identify the disease patterns, are promising,\nparticularly, the models as Random Forest, SVM, and PCA are working well on the\ndatasets and give high accuracy (99%), however, the K means clustering has very\nlow accuracy (10%) and does not fit the datasets.", "published": "2025-04-11 15:55:50", "link": "http://arxiv.org/abs/2504.08651v1", "categories": ["cs.LG", "cs.ET"], "primary_category": "cs.LG"}
{"title": "Transformer Learns Optimal Variable Selection in Group-Sparse Classification", "abstract": "Transformers have demonstrated remarkable success across various\napplications. However, the success of transformers have not been understood in\ntheory. In this work, we give a case study of how transformers can be trained\nto learn a classic statistical model with \"group sparsity\", where the input\nvariables form multiple groups, and the label only depends on the variables\nfrom one of the groups. We theoretically demonstrate that, a one-layer\ntransformer trained by gradient descent can correctly leverage the attention\nmechanism to select variables, disregarding irrelevant ones and focusing on\nthose beneficial for classification. We also demonstrate that a well-pretrained\none-layer transformer can be adapted to new downstream tasks to achieve good\nprediction accuracy with a limited number of samples. Our study sheds light on\nhow transformers effectively learn structured data.", "published": "2025-04-11 15:39:44", "link": "http://arxiv.org/abs/2504.08638v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Gradient Descent Robustly Learns the Intrinsic Dimension of Data in Training Convolutional Neural Networks", "abstract": "Modern neural networks are usually highly over-parameterized. Behind the wide\nusage of over-parameterized networks is the belief that, if the data are\nsimple, then the trained network will be automatically equivalent to a simple\npredictor. Following this intuition, many existing works have studied different\nnotions of \"ranks\" of neural networks and their relation to the rank of data.\nIn this work, we study the rank of convolutional neural networks (CNNs) trained\nby gradient descent, with a specific focus on the robustness of the rank to\nimage background noises. Specifically, we point out that, when adding\nbackground noises to images, the rank of the CNN trained with gradient descent\nis affected far less compared with the rank of the data. We support our claim\nwith a theoretical case study, where we consider a particular data model to\ncharacterize low-rank clean images with added background noises. We prove that\nCNNs trained by gradient descent can learn the intrinsic dimension of clean\nimages, despite the presence of relatively large background noises. We also\nconduct experiments on synthetic and real datasets to further validate our\nclaim.", "published": "2025-04-11 15:29:55", "link": "http://arxiv.org/abs/2504.08628v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "MooseAgent: A LLM Based Multi-agent Framework for Automating Moose Simulation", "abstract": "The Finite Element Method (FEM) is widely used in engineering and scientific\ncomputing, but its pre-processing, solver configuration, and post-processing\nstages are often time-consuming and require specialized knowledge. This paper\nproposes an automated solution framework, MooseAgent, for the multi-physics\nsimulation framework MOOSE, which combines large-scale pre-trained language\nmodels (LLMs) with a multi-agent system. The framework uses LLMs to understand\nuser-described simulation requirements in natural language and employs task\ndecomposition and multi-round iterative verification strategies to\nautomatically generate MOOSE input files. To improve accuracy and reduce model\nhallucinations, the system builds and utilizes a vector database containing\nannotated MOOSE input cards and function documentation. We conducted\nexperimental evaluations on several typical cases, including heat transfer,\nmechanics, phase field, and multi-physics coupling. The results show that\nMooseAgent can automate the MOOSE simulation process to a certain extent,\nespecially demonstrating a high success rate when dealing with relatively\nsimple single-physics problems. The main contribution of this research is the\nproposal of a multi-agent automated framework for MOOSE, which validates its\npotential in simplifying finite element simulation processes and lowering the\nuser barrier, providing new ideas for the development of intelligent finite\nelement simulation software. The code for the MooseAgent framework proposed in\nthis paper has been open-sourced and is available at\nhttps://github.com/taozhan18/MooseAgent", "published": "2025-04-11 15:25:50", "link": "http://arxiv.org/abs/2504.08621v1", "categories": ["cs.LG", "cs.SE"], "primary_category": "cs.LG"}
{"title": "AstroLLaVA: towards the unification of astronomical data and natural language", "abstract": "We present AstroLLaVA, a vision language model for astronomy that enables\ninteraction with astronomical imagery through natural dialogue. By fine-tuning\nthe LLaVA model on a diverse dataset of $\\sim$30k images with captions and\nquestion-answer pairs sourced from NASA's `Astronomy Picture of the Day', the\nEuropean Southern Observatory, and the NASA/ESA Hubble Space Telescope, we\ncreate a model capable of answering open-ended questions about astronomical\nconcepts depicted visually. Our two-stage fine-tuning process adapts the model\nto both image captioning and visual question answering in the astronomy domain.\nWe demonstrate AstroLLaVA's performance on an astronomical visual question\nanswering benchmark and release the model weights, code, and training set to\nencourage further open source work in this space. Finally, we suggest a roadmap\ntowards general astronomical data alignment with pre-trained language models,\nand provide an open space for collaboration towards this end for interested\nresearchers.", "published": "2025-04-11 14:36:31", "link": "http://arxiv.org/abs/2504.08583v1", "categories": ["astro-ph.IM", "cs.LG"], "primary_category": "astro-ph.IM"}
{"title": "Boosting-inspired online learning with transfer for railway maintenance", "abstract": "The integration of advanced sensor technologies with deep learning algorithms\nhas revolutionized fault diagnosis in railway systems, particularly at the\nwheel-track interface. Although numerous models have been proposed to detect\nirregularities such as wheel out-of-roundness, they often fall short in\nreal-world applications due to the dynamic and nonstationary nature of railway\noperations. This paper introduces BOLT-RM (Boosting-inspired Online Learning\nwith Transfer for Railway Maintenance), a model designed to address these\nchallenges using continual learning for predictive maintenance. By allowing the\nmodel to continuously learn and adapt as new data become available, BOLT-RM\novercomes the issue of catastrophic forgetting that often plagues traditional\nmodels. It retains past knowledge while improving predictive accuracy with each\nnew learning episode, using a boosting-like knowledge sharing mechanism to\nadapt to evolving operational conditions such as changes in speed, load, and\ntrack irregularities. The methodology is validated through comprehensive\nmulti-domain simulations of train-track dynamic interactions, which capture\nrealistic railway operating conditions. The proposed BOLT-RM model demonstrates\nsignificant improvements in identifying wheel anomalies, establishing a\nreliable sequence for maintenance interventions.", "published": "2025-04-11 14:03:31", "link": "http://arxiv.org/abs/2504.08554v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Slicing the Gaussian Mixture Wasserstein Distance", "abstract": "Gaussian mixture models (GMMs) are widely used in machine learning for tasks\nsuch as clustering, classification, image reconstruction, and generative\nmodeling. A key challenge in working with GMMs is defining a computationally\nefficient and geometrically meaningful metric. The mixture Wasserstein (MW)\ndistance adapts the Wasserstein metric to GMMs and has been applied in various\ndomains, including domain adaptation, dataset comparison, and reinforcement\nlearning. However, its high computational cost -- arising from repeated\nWasserstein distance computations involving matrix square root estimations and\nan expensive linear program -- limits its scalability to high-dimensional and\nlarge-scale problems. To address this, we propose multiple novel slicing-based\napproximations to the MW distance that significantly reduce computational\ncomplexity while preserving key optimal transport properties. From a\ntheoretical viewpoint, we establish several weak and strong equivalences\nbetween the introduced metrics, and show the relations to the original MW\ndistance and the well-established sliced Wasserstein distance. Furthermore, we\nvalidate the effectiveness of our approach through numerical experiments,\ndemonstrating computational efficiency and applications in clustering,\nperceptual image comparison, and GMM minimization", "published": "2025-04-11 13:57:09", "link": "http://arxiv.org/abs/2504.08544v1", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Statistically guided deep learning", "abstract": "We present a theoretically well-founded deep learning algorithm for\nnonparametric regression. It uses over-parametrized deep neural networks with\nlogistic activation function, which are fitted to the given data via gradient\ndescent. We propose a special topology of these networks, a special random\ninitialization of the weights, and a data-dependent choice of the learning rate\nand the number of gradient descent steps. We prove a theoretical bound on the\nexpected $L_2$ error of this estimate, and illustrate its finite sample size\nperformance by applying it to simulated data. Our results show that a\ntheoretical analysis of deep learning which takes into account simultaneously\noptimization, generalization and approximation can result in a new deep\nlearning estimate which has an improved finite sample performance.", "published": "2025-04-11 12:36:06", "link": "http://arxiv.org/abs/2504.08489v1", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Physics-informed data-driven control without persistence of excitation", "abstract": "We show that data that is not sufficiently informative to allow for system\nre-identification can still provide meaningful information when combined with\nexternal or physical knowledge of the system, such as bounded system matrix\nnorms. We then illustrate how this information can be leveraged for safety and\nenergy minimization problems and to enhance predictions in unmodelled dynamics.\nThis preliminary work outlines key ideas toward using limited data for\neffective control by integrating physical knowledge of the system and\nexploiting interpolation conditions.", "published": "2025-04-11 12:19:51", "link": "http://arxiv.org/abs/2504.08484v1", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "primary_category": "eess.SY"}
{"title": "Artifact detection and localization in single-channel mobile EEG for sleep research using deep learning and attention mechanisms", "abstract": "Artifacts in the electroencephalogram (EEG) degrade signal quality and impact\nthe analysis of brain activity. Current methods for detecting artifacts in\nsleep EEG rely on simple threshold-based algorithms that require manual\nintervention, which is time-consuming and impractical due to the vast volume of\ndata that novel mobile recording systems generate. We propose a convolutional\nneural network (CNN) model incorporating a convolutional block attention module\n(CNN-CBAM) to detect and identify the location of artifacts in the sleep EEG\nwith attention maps. We benchmarked this model against six other machine\nlearning and signal processing approaches. We trained/tuned all models on 72\nmanually annotated EEG recordings obtained during home-based monitoring from 18\nhealthy participants with a mean (SD) age of 68.05 y ($\\pm$5.02). We tested\nthem on 26 separate recordings from 6 healthy participants with a mean (SD) age\nof 68.33 y ($\\pm$4.08), with contained artifacts in 4\\% of epochs. CNN-CBAM\nachieved the highest area under the receiver operating characteristic curve\n(0.88), sensitivity (0.81), and specificity (0.86) when compared to the other\napproaches. The attention maps from CNN-CBAM localized artifacts within the\nepoch with a sensitivity of 0.71 and specificity of 0.67. This work\ndemonstrates the feasibility of automating the detection and localization of\nartifacts in wearable sleep EEG.", "published": "2025-04-11 11:57:06", "link": "http://arxiv.org/abs/2504.08469v1", "categories": ["eess.SP", "cs.LG", "J.3"], "primary_category": "eess.SP"}
{"title": "A Systematic Evaluation of Knowledge Graph Embeddings for Gene-Disease Association Prediction", "abstract": "Discovery gene-disease links is important in biology and medicine areas,\nenabling disease identification and drug repurposing. Machine learning\napproaches accelerate this process by leveraging biological knowledge\nrepresented in ontologies and the structure of knowledge graphs. Still, many\nexisting works overlook ontologies explicitly representing diseases, missing\ncausal and semantic relationships between them. The gene-disease association\nproblem naturally frames itself as a link prediction task, where embedding\nalgorithms directly predict associations by exploring the structure and\nproperties of the knowledge graph. Some works frame it as a node-pair\nclassification task, combining embedding algorithms with traditional machine\nlearning algorithms. This strategy aligns with the logic of a machine learning\npipeline. However, the use of negative examples and the lack of validated\ngene-disease associations to train embedding models may constrain its\neffectiveness. This work introduces a novel framework for comparing the\nperformance of link prediction versus node-pair classification tasks, analyses\nthe performance of state of the art gene-disease association approaches, and\ncompares the different order-based formalizations of gene-disease association\nprediction. It also evaluates the impact of the semantic richness through a\ndisease-specific ontology and additional links between ontologies. The\nframework involves five steps: data splitting, knowledge graph integration,\nembedding, modeling and prediction, and method evaluation. Results show that\nenriching the semantic representation of diseases slightly improves\nperformance, while additional links generate a greater impact. Link prediction\nmethods better explore the semantic richness encoded in knowledge graphs.\nAlthough node-pair classification methods identify all true positives, link\nprediction methods outperform overall.", "published": "2025-04-11 11:11:35", "link": "http://arxiv.org/abs/2504.08445v1", "categories": ["cs.LG", "68U99 (Primary) 68T99 (Secondary)"], "primary_category": "cs.LG"}
{"title": "Customizing Spider Silk: Generative Models with Mechanical Property Conditioning for Protein Engineering", "abstract": "The remarkable mechanical properties of spider silk, including its tensile\nstrength and extensibility, are primarily governed by the repetitive regions of\nthe proteins that constitute the fiber, the major ampullate spidroins (MaSps).\nHowever, establishing correlations between mechanical characteristics and\nrepeat sequences is challenging due to the intricate\nsequence-structure-function relationships of MaSps and the limited availability\nof annotated datasets. In this study, we present a novel computational\nframework for designing MaSp repeat sequences with customizable mechanical\nproperties. To achieve this, we developed a lightweight GPT-based generative\nmodel by distilling the pre-trained ProtGPT2 protein language model. The\ndistilled model was subjected to multilevel fine-tuning using curated subsets\nof the Spider Silkome dataset. Specifically, we adapt the model for MaSp repeat\ngeneration using 6,000 MaSp repeat sequences and further refine it with 572\nrepeats associated with experimentally determined fiber-level mechanical\nproperties. Our model generates biologically plausible MaSp repeat regions\ntailored to specific mechanical properties while also predicting those\nproperties for given sequences. Validation includes sequence-level analysis,\nassessing physicochemical attributes and expected distribution of key motifs as\nwell as secondary structure compositions. A correlation study using BLAST on\nthe Spider Silkome dataset and a test set of MaSp repeats with known mechanical\nproperties further confirmed the predictive accuracy of the model. This\nframework advances the rational design of spider silk-inspired biomaterials,\noffering a versatile tool for engineering protein sequences with tailored\nmechanical attributes.", "published": "2025-04-11 10:55:01", "link": "http://arxiv.org/abs/2504.08437v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Standardization of Weighted Ranking Correlation Coefficients", "abstract": "A relevant problem in statistics is defining the correlation of two rankings\nof a list of items. Kendall's tau and Spearman's rho are two well established\ncorrelation coefficients, characterized by a symmetric form that ensures zero\nexpected value between two pairs of rankings randomly chosen with uniform\nprobability. However, in recent years, several weighted versions of the\noriginal Spearman and Kendall coefficients have emerged that take into account\nthe greater importance of top ranks compared to low ranks, which is common in\nmany contexts. The weighting schemes break the symmetry, causing a non-zero\nexpected value between two random rankings. This issue is very relevant, as it\nundermines the concept of uncorrelation between rankings. In this paper, we\naddress this problem by proposing a standardization function $g(x)$ that maps a\ncorrelation ranking coefficient $\\Gamma$ in a standard form $g(\\Gamma)$ that\nhas zero expected value, while maintaining the relevant statistical properties\nof $\\Gamma$.", "published": "2025-04-11 10:37:19", "link": "http://arxiv.org/abs/2504.08428v1", "categories": ["stat.ME", "cond-mat.stat-mech", "cs.LG", "math.ST", "stat.ML", "stat.TH", "62-08 (Primary) 62-04, 65D10 (Secondary)", "G.3"], "primary_category": "stat.ME"}
{"title": "Graph Reduction with Unsupervised Learning in Column Generation: A Routing Application", "abstract": "Column Generation (CG) is a popular method dedicated to enhancing\ncomputational efficiency in large scale Combinatorial Optimization (CO)\nproblems. It reduces the number of decision variables in a problem by solving a\npricing problem. For many CO problems, the pricing problem is an Elementary\nShortest Path Problem with Resource Constraints (ESPPRC). Large ESPPRC\ninstances are difficult to solve to near-optimality. Consequently, we use a\nGraph neural Network (GNN) to reduces the size of the ESPPRC such that it\nbecomes computationally tractable with standard solving techniques. Our GNN is\ntrained by Unsupervised Learning and outputs a distribution for the arcs to be\nretained in the reduced PP. The reduced PP is solved by a local search that\nfinds columns with large reduced costs and speeds up convergence. We apply our\nmethod on a set of Capacitated Vehicle Routing Problems with Time Windows and\nshow significant improvements in convergence compared to simple reduction\ntechniques from the literature. For a fixed computational budget, we improve\nthe objective values by over 9\\% for larger instances. We also analyze the\nperformance of our CG algorithm and test the generalization of our method to\ndifferent classes of instances than the training data.", "published": "2025-04-11 10:08:38", "link": "http://arxiv.org/abs/2504.08401v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MixDiT: Accelerating Image Diffusion Transformer Inference with Mixed-Precision MX Quantization", "abstract": "Diffusion Transformer (DiT) has driven significant progress in image\ngeneration tasks. However, DiT inferencing is notoriously compute-intensive and\nincurs long latency even on datacenter-scale GPUs, primarily due to its\niterative nature and heavy reliance on GEMM operations inherent to its\nencoder-based structure. To address the challenge, prior work has explored\nquantization, but achieving low-precision quantization for DiT inferencing with\nboth high accuracy and substantial speedup remains an open problem. To this\nend, this paper proposes MixDiT, an algorithm-hardware co-designed acceleration\nsolution that exploits mixed Microscaling (MX) formats to quantize DiT\nactivation values. MixDiT quantizes the DiT activation tensors by selectively\napplying higher precision to magnitude-based outliers, which produce\nmixed-precision GEMM operations. To achieve tangible speedup from the\nmixed-precision arithmetic, we design a MixDiT accelerator that enables\nprecision-flexible multiplications and efficient MX precision conversions. Our\nexperimental results show that MixDiT delivers a speedup of 2.10-5.32 times\nover RTX 3090, with no loss in FID.", "published": "2025-04-11 10:03:06", "link": "http://arxiv.org/abs/2504.08398v1", "categories": ["cs.AR", "cs.LG"], "primary_category": "cs.AR"}
{"title": "An Empirical Investigation of Reconstruction-Based Models for Seizure Prediction from ECG Signals", "abstract": "Epileptic seizures are sudden neurological disorders characterized by\nabnormal, excessive neuronal activity in the brain, which is often associated\nwith changes in cardiovascular activity. These disruptions can pose significant\nphysical and psychological challenges for patients. Therefore, accurate seizure\nprediction can help mitigate these risks by enabling timely interventions,\nultimately improving patients' quality of life. Traditionally, EEG signals have\nbeen the primary standard for seizure prediction due to their precision in\ncapturing brain activity. However, their high cost, susceptibility to noise,\nand logistical constraints limit their practicality, restricting their use to\nclinical settings. In order to overcome these limitations, this study focuses\non leveraging ECG signals as an alternative for seizure prediction. In this\npaper, we present a novel method for predicting seizures based on detecting\nanomalies in ECG signals during their reconstruction. By extracting\ntime-frequency features and leveraging various advanced deep learning\narchitectures, the proposed method identifies deviations in heart rate dynamics\nassociated with seizure onset. The proposed approach was evaluated using the\nSiena database and could achieve specificity of 99.16\\%, accuracy of 76.05\\%,\nand false positive rate (FPR) of 0.01/h, with an average prediction time of 45\nminutes before seizure onset. These results highlight the potential of\nECG-based seizure prediction as a patient-friendly alternative to traditional\nEEG-based methods.", "published": "2025-04-11 09:33:11", "link": "http://arxiv.org/abs/2504.08381v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Scaling Up On-Device LLMs via Active-Weight Swapping Between DRAM and Flash", "abstract": "Large language models (LLMs) are increasingly being deployed on mobile\ndevices, but the limited DRAM capacity constrains the deployable model size.\nThis paper introduces ActiveFlow, the first LLM inference framework that can\nachieve adaptive DRAM usage for modern LLMs (not ReLU-based), enabling the\nscaling up of deployable model sizes. The framework is based on the novel\nconcept of active weight DRAM-flash swapping and incorporates three novel\ntechniques: (1) Cross-layer active weights preloading. It uses the activations\nfrom the current layer to predict the active weights of several subsequent\nlayers, enabling computation and data loading to overlap, as well as\nfacilitating large I/O transfers. (2) Sparsity-aware self-distillation. It\nadjusts the active weights to align with the dense-model output distribution,\ncompensating for approximations introduced by contextual sparsity. (3) Active\nweight DRAM-flash swapping pipeline. It orchestrates the DRAM space allocation\namong the hot weight cache, preloaded active weights, and computation-involved\nweights based on available memory. Results show ActiveFlow achieves the\nperformance-cost Pareto frontier compared to existing efficiency optimization\nmethods.", "published": "2025-04-11 09:26:47", "link": "http://arxiv.org/abs/2504.08378v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Proofs as Explanations: Short Certificates for Reliable Predictions", "abstract": "We consider a model for explainable AI in which an explanation for a\nprediction $h(x)=y$ consists of a subset $S'$ of the training data (if it\nexists) such that all classifiers $h' \\in H$ that make at most $b$ mistakes on\n$S'$ predict $h'(x)=y$. Such a set $S'$ serves as a proof that $x$ indeed has\nlabel $y$ under the assumption that (1) the target function $h^\\star$ belongs\nto $H$, and (2) the set $S$ contains at most $b$ corrupted points. For example,\nif $b=0$ and $H$ is the family of linear classifiers in $\\mathbb{R}^d$, and if\n$x$ lies inside the convex hull of the positive data points in $S$ (and hence\nevery consistent linear classifier labels $x$ as positive), then\nCarath\\'eodory's theorem states that $x$ lies inside the convex hull of $d+1$\nof those points. So, a set $S'$ of size $d+1$ could be released as an\nexplanation for a positive prediction, and would serve as a short proof of\ncorrectness of the prediction under the assumption of realizability.\n  In this work, we consider this problem more generally, for general hypothesis\nclasses $H$ and general values $b\\geq 0$. We define the notion of the robust\nhollow star number of $H$ (which generalizes the standard hollow star number),\nand show that it precisely characterizes the worst-case size of the smallest\ncertificate achievable, and analyze its size for natural classes. We also\nconsider worst-case distributional bounds on certificate size, as well as\ndistribution-dependent bounds that we show tightly control the sample size\nneeded to get a certificate for any given test example. In particular, we\ndefine a notion of the certificate coefficient $\\varepsilon_x$ of an example\n$x$ with respect to a data distribution $D$ and target function $h^\\star$, and\nprove matching upper and lower bounds on sample size as a function of\n$\\varepsilon_x$, $b$, and the VC dimension $d$ of $H$.", "published": "2025-04-11 09:26:37", "link": "http://arxiv.org/abs/2504.08377v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "DRIP: DRop unImportant data Points -- Enhancing Machine Learning Efficiency with Grad-CAM-Based Real-Time Data Prioritization for On-Device Training", "abstract": "Selecting data points for model training is critical in machine learning.\nEffective selection methods can reduce the labeling effort, optimize on-device\ntraining for embedded systems with limited data storage, and enhance the model\nperformance. This paper introduces a novel algorithm that uses Grad-CAM to make\nonline decisions about retaining or discarding data points. Optimized for\nembedded devices, the algorithm computes a unique DRIP Score to quantify the\nimportance of each data point. This enables dynamic decision-making on whether\na data point should be stored for potential retraining or discarded without\ncompromising model performance. Experimental evaluations on four benchmark\ndatasets demonstrate that our approach can match or even surpass the accuracy\nof models trained on the entire dataset, all while achieving storage savings of\nup to 39\\%. To our knowledge, this is the first algorithm that makes online\ndecisions about data point retention without requiring access to the entire\ndataset.", "published": "2025-04-11 09:00:49", "link": "http://arxiv.org/abs/2504.08364v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "An Adaptive Clustering Scheme for Client Selections in Communication-Efficient Federated Learning", "abstract": "Federated learning is a novel decentralized learning architecture. During the\ntraining process, the client and server must continuously upload and receive\nmodel parameters, which consumes a lot of network transmission resources. Some\nmethods use clustering to find more representative customers, select only a\npart of them for training, and at the same time ensure the accuracy of\ntraining. However, in federated learning, it is not trivial to know what the\nnumber of clusters can bring the best training result. Therefore, we propose to\ndynamically adjust the number of clusters to find the most ideal grouping\nresults. It may reduce the number of users participating in the training to\nachieve the effect of reducing communication costs without affecting the model\nperformance. We verify its experimental results on the non-IID handwritten\ndigit recognition dataset and reduce the cost of communication and transmission\nby almost 50% compared with traditional federated learning without affecting\nthe accuracy of the model.", "published": "2025-04-11 08:43:12", "link": "http://arxiv.org/abs/2504.08356v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards generalizable single-cell perturbation modeling via the Conditional Monge Gap", "abstract": "Learning the response of single-cells to various treatments offers great\npotential to enable targeted therapies. In this context, neural optimal\ntransport (OT) has emerged as a principled methodological framework because it\ninherently accommodates the challenges of unpaired data induced by cell\ndestruction during data acquisition. However, most existing OT approaches are\nincapable of conditioning on different treatment contexts (e.g., time, drug\ntreatment, drug dosage, or cell type) and we still lack methods that\nunanimously show promising generalization performance to unseen treatments.\nHere, we propose the Conditional Monge Gap which learns OT maps conditionally\non arbitrary covariates. We demonstrate its value in predicting single-cell\nperturbation responses conditional to one or multiple drugs, a drug dosage, or\ncombinations thereof. We find that our conditional models achieve results\ncomparable and sometimes even superior to the condition-specific\nstate-of-the-art on scRNA-seq as well as multiplexed protein imaging data.\nNotably, by aggregating data across conditions we perform cross-task learning\nwhich unlocks remarkable generalization abilities to unseen drugs or drug\ndosages, widely outperforming other conditional models in capturing\nheterogeneity (i.e., higher moments) in the perturbed population. Finally, by\nscaling to hundreds of conditions and testing on unseen drugs, we narrow the\ngap between structure-based and effect-based drug representations, suggesting a\npromising path to the successful prediction of perturbation effects for unseen\ntreatments.", "published": "2025-04-11 07:51:33", "link": "http://arxiv.org/abs/2504.08328v1", "categories": ["cs.LG", "q-bio.CB"], "primary_category": "cs.LG"}
{"title": "Academic Network Representation via Prediction-Sampling Incorporated Tensor Factorization", "abstract": "Accurate representation to an academic network is of great significance to\nacademic relationship mining like predicting scientific impact. A Latent\nFactorization of Tensors (LFT) model is one of the most effective models for\nlearning the representation of a target network. However, an academic network\nis often High-Dimensional and Incomplete (HDI) because the relationships among\nnumerous network entities are impossible to be fully explored, making it\ndifficult for an LFT model to learn accurate representation of the academic\nnetwork. To address this issue, this paper proposes a Prediction-sampling-based\nLatent Factorization of Tensors (PLFT) model with two ideas: 1) constructing a\ncascade LFT architecture to enhance model representation learning ability via\nlearning academic network hierarchical features, and 2) introducing a nonlinear\nactivation-incorporated predicting-sampling strategy to more accurately learn\nthe network representation via generating new academic network data layer by\nlayer. Experimental results from the three real-world academic network datasets\nshow that the PLFT model outperforms existing models when predicting the\nunexplored relationships among network entities.", "published": "2025-04-11 07:47:39", "link": "http://arxiv.org/abs/2504.08323v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Enabling Automatic Differentiation with Mollified Graph Neural Operators", "abstract": "Physics-informed neural operators offer a powerful framework for learning\nsolution operators of partial differential equations (PDEs) by combining data\nand physics losses. However, these physics losses rely on derivatives.\nComputing these derivatives remains challenging, with spectral and finite\ndifference methods introducing approximation errors due to finite resolution.\nHere, we propose the mollified graph neural operator (mGNO), the first method\nto leverage automatic differentiation and compute \\emph{exact} gradients on\narbitrary geometries. This enhancement enables efficient training on irregular\ngrids and varying geometries while allowing seamless evaluation of physics\nlosses at randomly sampled points for improved generalization. For a PDE\nexample on regular grids, mGNO paired with autograd reduced the L2 relative\ndata error by 20x compared to finite differences, although training was slower.\nIt can also solve PDEs on unstructured point clouds seamlessly, using physics\nlosses only, at resolutions vastly lower than those needed for finite\ndifferences to be accurate enough. On these unstructured point clouds, mGNO\nleads to errors that are consistently 2 orders of magnitude lower than machine\nlearning baselines (Meta-PDE) for comparable runtimes, and also delivers\nspeedups from 1 to 3 orders of magnitude compared to the numerical solver for\nsimilar accuracy. mGNOs can also be used to solve inverse design and shape\noptimization problems on complex geometries.", "published": "2025-04-11 06:16:30", "link": "http://arxiv.org/abs/2504.08277v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Understanding the Impact of Data Domain Extraction on Synthetic Data Privacy", "abstract": "Privacy attacks, particularly membership inference attacks (MIAs), are widely\nused to assess the privacy of generative models for tabular synthetic data,\nincluding those with Differential Privacy (DP) guarantees. These attacks often\nexploit outliers, which are especially vulnerable due to their position at the\nboundaries of the data domain (e.g., at the minimum and maximum values).\nHowever, the role of data domain extraction in generative models and its impact\non privacy attacks have been overlooked. In this paper, we examine three\nstrategies for defining the data domain: assuming it is externally provided\n(ideally from public data), extracting it directly from the input data, and\nextracting it with DP mechanisms. While common in popular implementations and\nlibraries, we show that the second approach breaks end-to-end DP guarantees and\nleaves models vulnerable. While using a provided domain (if representative) is\npreferable, extracting it with DP can also defend against popular MIAs, even at\nhigh privacy budgets.", "published": "2025-04-11 04:35:24", "link": "http://arxiv.org/abs/2504.08254v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Neural Network-assisted Interval Reachability for Systems with Control Barrier Function-Based Safe Controllers", "abstract": "Control Barrier Functions (CBFs) have been widely utilized in the design of\noptimization-based controllers and filters for dynamical systems to ensure\nforward invariance of a given set of safe states. While CBF-based controllers\noffer safety guarantees, they can compromise the performance of the system,\nleading to undesirable behaviors such as unbounded trajectories and emergence\nof locally stable spurious equilibria. Computing reachable sets for systems\nwith CBF-based controllers is an effective approach for runtime performance and\nstability verification, and can potentially serve as a tool for trajectory\nre-planning. In this paper, we propose a computationally efficient interval\nreachability method for performance verification of systems with\noptimization-based controllers by: (i) approximating the optimization-based\ncontroller by a pre-trained neural network to avoid solving optimization\nproblems repeatedly, and (ii) using mixed monotone theory to construct an\nembedding system that leverages state-of-the-art neural network verification\nalgorithms for bounding the output of the neural network. Results in terms of\ncloseness of solutions of trajectories of the system with the\noptimization-based controller and the neural network are derived. Using a\nsingle trajectory of the embedding system along with our closeness of solutions\nresult, we obtain an over-approximation of the reachable set of the system with\noptimization-based controllers. Numerical results are presented to corroborate\nthe technical findings.", "published": "2025-04-11 04:14:55", "link": "http://arxiv.org/abs/2504.08249v1", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "primary_category": "eess.SY"}
{"title": "Spectral Normalization for Lipschitz-Constrained Policies on Learning Humanoid Locomotion", "abstract": "Reinforcement learning (RL) has shown great potential in training agile and\nadaptable controllers for legged robots, enabling them to learn complex\nlocomotion behaviors directly from experience. However, policies trained in\nsimulation often fail to transfer to real-world robots due to unrealistic\nassumptions such as infinite actuator bandwidth and the absence of torque\nlimits. These conditions allow policies to rely on abrupt, high-frequency\ntorque changes, which are infeasible for real actuators with finite bandwidth.\n  Traditional methods address this issue by penalizing aggressive motions\nthrough regularization rewards, such as joint velocities, accelerations, and\nenergy consumption, but they require extensive hyperparameter tuning.\nAlternatively, Lipschitz-Constrained Policies (LCP) enforce finite bandwidth\naction control by penalizing policy gradients, but their reliance on gradient\ncalculations introduces significant GPU memory overhead. To overcome this\nlimitation, this work proposes Spectral Normalization (SN) as an efficient\nreplacement for enforcing Lipschitz continuity. By constraining the spectral\nnorm of network weights, SN effectively limits high-frequency policy\nfluctuations while significantly reducing GPU memory usage. Experimental\nevaluations in both simulation and real-world humanoid robot show that SN\nachieves performance comparable to gradient penalty methods while enabling more\nefficient parallel training.", "published": "2025-04-11 04:12:15", "link": "http://arxiv.org/abs/2504.08246v1", "categories": ["cs.RO", "cs.LG", "cs.SY"], "primary_category": "cs.RO"}
{"title": "Bringing Structure to Naturalness: On the Naturalness of ASTs", "abstract": "Source code comes in different shapes and forms. Previous research has\nalready shown code to be more predictable than natural language as well as\nhighlighted its statistical predictability at the token level: source code can\nbe natural. More recently, the structure of code -- control flow, syntax\ngraphs, abstract syntax trees etc. -- has been successfully used to improve the\nstate-of-the-art on numerous tasks: code suggestion, code summarisation, method\nnaming etc. This body of work implicitly assumes that structured\nrepresentations of code are similarly statistically predictable, i.e. that a\nstructured view of code is also natural. We consider that this view should be\nmade explicit and propose directly studying the Structured Naturalness\nHypothesis. Beyond just naming existing research that assumes this hypothesis\nand formulating it, we also provide evidence in the case of trees: TreeLSTM\nmodels over ASTs for some languages, such as Ruby, are competitive with\n$n$-gram models while handling the syntax token issue highlighted by previous\nresearch 'for free'. For other languages, such as Java or Python, we find tree\nmodels to perform worse, suggesting that downstream task improvement is\nuncorrelated to the language modelling task. Further, we show how such\nnaturalness signals can be employed for near state-of-the-art results on\njust-in-time defect prediction while forgoing manual feature engineering work.", "published": "2025-04-11 03:43:46", "link": "http://arxiv.org/abs/2504.08234v1", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "All Optical Echo State Network Reservoir Computing", "abstract": "We propose an innovative design for an all-optical Echo State Network (ESN),\nan advanced type of reservoir computer known for its universal computational\ncapabilities. Our design enables fully optical implementation of arbitrary\nESNs, featuring complete flexibility in optical matrix multiplication and\nnonlinear activation. Leveraging the nonlinear characteristics of stimulated\nBrillouin scattering (SBS), the architecture efficiently realizes\nmeasurement-free operations crucial for reservoir computing. The approach\nsignificantly reduces computational overhead and energy consumption compared to\ntraditional software-based methods. Comprehensive simulations validate the\nsystem's memory capacity, nonlinear processing strength, and polynomial algebra\ncapabilities, showcasing performance comparable to software ESNs across key\nbenchmark tasks. Our design establishes a feasible, scalable, and universally\napplicable framework for optical reservoir computing, suitable for diverse\nmachine learning applications.", "published": "2025-04-11 03:12:53", "link": "http://arxiv.org/abs/2504.08224v1", "categories": ["physics.optics", "cs.LG", "stat.ML"], "primary_category": "physics.optics"}
{"title": "DrivAer Transformer: A high-precision and fast prediction method for vehicle aerodynamic drag coefficient based on the DrivAerNet++ dataset", "abstract": "At the current stage, deep learning-based methods have demonstrated excellent\ncapabilities in evaluating aerodynamic performance, significantly reducing the\ntime and cost required for traditional computational fluid dynamics (CFD)\nsimulations. However, when faced with the task of processing extremely complex\nthree-dimensional (3D) vehicle models, the lack of large-scale datasets and\ntraining resources, coupled with the inherent diversity and complexity of the\ngeometry of different vehicle models, means that the prediction accuracy and\nversatility of these networks are still not up to the level required for\ncurrent production. In view of the remarkable success of Transformer models in\nthe field of natural language processing and their strong potential in the\nfield of image processing, this study innovatively proposes a point cloud\nlearning framework called DrivAer Transformer (DAT). The DAT structure uses the\nDrivAerNet++ dataset, which contains high-fidelity CFD data of\nindustrial-standard 3D vehicle shapes. enabling accurate estimation of air drag\ndirectly from 3D meshes, thus avoiding the limitations of traditional methods\nsuch as 2D image rendering or signed distance fields (SDF). DAT enables fast\nand accurate drag prediction, driving the evolution of the aerodynamic\nevaluation process and laying the critical foundation for introducing a\ndata-driven approach to automotive design. The framework is expected to\naccelerate the vehicle design process and improve development efficiency.", "published": "2025-04-11 02:50:38", "link": "http://arxiv.org/abs/2504.08217v1", "categories": ["cs.LG", "76N15 (Primary), 76F65, 68T07 (Secondary)", "I.2.10; I.2.6; I.6.3; G.1.8"], "primary_category": "cs.LG"}
{"title": "Local Distance-Preserving Node Embeddings and Their Performance on Random Graphs", "abstract": "Learning node representations is a fundamental problem in graph machine\nlearning. While existing embedding methods effectively preserve local\nsimilarity measures, they often fail to capture global functions like graph\ndistances. Inspired by Bourgain's seminal work on Hilbert space embeddings of\nmetric spaces (1985), we study the performance of local distance-preserving\nnode embeddings. Known as landmark-based algorithms, these embeddings\napproximate pairwise distances by computing shortest paths from a small subset\nof reference nodes (i.e., landmarks). Our main theoretical contribution shows\nthat random graphs, such as Erd\\H{o}s-R\\'enyi random graphs, require lower\ndimensions in landmark-based embeddings compared to worst-case graphs.\nEmpirically, we demonstrate that the GNN-based approximations for the distances\nto landmarks generalize well to larger networks, offering a scalable\nalternative for graph representation learning.", "published": "2025-04-11 02:47:46", "link": "http://arxiv.org/abs/2504.08216v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Deep Distributional Learning with Non-crossing Quantile Network", "abstract": "In this paper, we introduce a non-crossing quantile (NQ) network for\nconditional distribution learning. By leveraging non-negative activation\nfunctions, the NQ network ensures that the learned distributions remain\nmonotonic, effectively addressing the issue of quantile crossing. Furthermore,\nthe NQ network-based deep distributional learning framework is highly\nadaptable, applicable to a wide range of applications, from classical\nnon-parametric quantile regression to more advanced tasks such as causal effect\nestimation and distributional reinforcement learning (RL). We also develop a\ncomprehensive theoretical foundation for the deep NQ estimator and its\napplication to distributional RL, providing an in-depth analysis that\ndemonstrates its effectiveness across these domains. Our experimental results\nfurther highlight the robustness and versatility of the NQ network.", "published": "2025-04-11 02:46:39", "link": "http://arxiv.org/abs/2504.08215v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "The More is not the Merrier: Investigating the Effect of Client Size on Federated Learning", "abstract": "Federated Learning (FL) has been introduced as a way to keep data local to\nclients while training a shared machine learning model, as clients train on\ntheir local data and send trained models to a central aggregator. It is\nexpected that FL will have a huge implication on Mobile Edge Computing, the\nInternet of Things, and Cross-Silo FL. In this paper, we focus on the widely\nused FedAvg algorithm to explore the effect of the number of clients in FL. We\nfind a significant deterioration of learning accuracy for FedAvg as the number\nof clients increases. To address this issue for a general application, we\npropose a method called Knowledgeable Client Insertion (KCI) that introduces a\nvery small number of knowledgeable clients to the MEC setting. These\nknowledgeable clients are expected to have accumulated a large set of data\nsamples to help with training. With the help of KCI, the learning accuracy of\nFL increases much faster even with a normal FedAvg aggregation technique. We\nexpect this approach to be able to provide great privacy protection for clients\nagainst security attacks such as model inversion attacks. Our code is available\nat https://github.com/Eleanor-W/KCI_for_FL.", "published": "2025-04-11 02:01:38", "link": "http://arxiv.org/abs/2504.08198v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Detecting Credit Card Fraud via Heterogeneous Graph Neural Networks with Graph Attention", "abstract": "This study proposes a credit card fraud detection method based on\nHeterogeneous Graph Neural Network (HGNN) to address fraud in complex\ntransaction networks. Unlike traditional machine learning methods that rely\nsolely on numerical features of transaction records, this approach constructs\nheterogeneous transaction graphs. These graphs incorporate multiple node types,\nincluding users, merchants, and transactions. By leveraging graph neural\nnetworks, the model captures higher-order transaction relationships. A Graph\nAttention Mechanism is employed to dynamically assign weights to different\ntransaction relationships. Additionally, a Temporal Decay Mechanism is\nintegrated to enhance the model's sensitivity to time-related fraud patterns.\nTo address the scarcity of fraudulent transaction samples, this study applies\nSMOTE oversampling and Cost-sensitive Learning. These techniques strengthen the\nmodel's ability to identify fraudulent transactions. Experimental results\ndemonstrate that the proposed method outperforms existing GNN models, including\nGCN, GAT, and GraphSAGE, on the IEEE-CIS Fraud Detection dataset. The model\nachieves notable improvements in both accuracy and OC-ROC. Future research may\nexplore the integration of dynamic graph neural networks and reinforcement\nlearning. Such advancements could enhance the real-time adaptability of fraud\ndetection systems and provide more intelligent solutions for financial risk\ncontrol.", "published": "2025-04-11 00:53:53", "link": "http://arxiv.org/abs/2504.08183v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Particle Hit Clustering and Identification Using Point Set Transformers in Liquid Argon Time Projection Chambers", "abstract": "Liquid argon time projection chambers are often used in neutrino physics and\ndark-matter searches because of their high spatial resolution. The images\ngenerated by these detectors are extremely sparse, as the energy values\ndetected by most of the detector are equal to 0, meaning that despite their\nhigh resolution, most of the detector is unused in a particular interaction.\nInstead of representing all of the empty detections, the interaction is usually\nstored as a sparse matrix, a list of detection locations paired with their\nenergy values. Traditional machine learning methods that have been applied to\nparticle reconstruction such as convolutional neural networks (CNNs), however,\ncannot operate over data stored in this way and therefore must have the matrix\nfully instantiated as a dense matrix. Operating on dense matrices requires a\nlot of memory and computation time, in contrast to directly operating on the\nsparse matrix. We propose a machine learning model using a point set neural\nnetwork that operates over a sparse matrix, greatly improving both processing\nspeed and accuracy over methods that instantiate the dense matrix, as well as\nover other methods that operate over sparse matrices. Compared to competing\nstate-of-the-art methods, our method improves classification performance by\n14%, segmentation performance by more than 22%, while taking 80% less time and\nusing 66% less memory. Compared to state-of-the-art CNN methods, our method\nimproves classification performance by more than 86%, segmentation performance\nby more than 71%, while reducing runtime by 91% and reducing memory usage by\n61%.", "published": "2025-04-11 00:46:57", "link": "http://arxiv.org/abs/2504.08182v1", "categories": ["hep-ex", "cs.LG"], "primary_category": "hep-ex"}
{"title": "A Piecewise Lyapunov Analysis of sub--quadratic SGD: Applications to Robust and Quantile Regression", "abstract": "Motivated by robust and quantile regression problems, {we investigate the\nstochastic gradient descent (SGD) algorithm} for minimizing an objective\nfunction $f$ that is locally strongly convex with a sub--quadratic tail. This\nsetting covers many widely used online statistical methods. We introduce a\nnovel piecewise Lyapunov function that enables us to handle functions $f$ with\nonly first-order differentiability, which includes a wide range of popular loss\nfunctions such as Huber loss. Leveraging our proposed Lyapunov function, we\nderive finite-time moment bounds under general diminishing stepsizes, as well\nas constant stepsizes. We further establish the weak convergence, central limit\ntheorem and bias characterization under constant stepsize, providing the first\ngeometrical convergence result for sub--quadratic SGD. Our results have wide\napplications, especially in online statistical methods. In particular, we\ndiscuss two applications of our results. 1) Online robust regression: We\nconsider a corrupted linear model with sub--exponential covariates and\nheavy--tailed noise. Our analysis provides convergence rates comparable to\nthose for corrupted models with Gaussian covariates and noise. 2) Online\nquantile regression: Importantly, our results relax the common assumption in\nprior work that the conditional density is continuous and provide a more\nfine-grained analysis for the moment bounds.", "published": "2025-04-11 00:20:37", "link": "http://arxiv.org/abs/2504.08178v1", "categories": ["stat.ML", "cs.LG", "math.OC", "math.PR", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "A Hybrid ABM-PDE Framework for Real-World Infectious Disease Simulations", "abstract": "This paper presents a hybrid modeling approach that couples an Agent-Based\nModel (ABM) with a partial differential equation (PDE) model in an epidemic\nsetting to simulate the spatial spread of infectious diseases using a\ncompartmental structure with seven health states. The goal is to reduce the\ncomputational complexity of a full-ABM by introducing a coupled ABM-PDE model\nthat offers significantly faster simulations while maintaining comparable\naccuracy. Our results demonstrate that the hybrid model not only reduces the\noverall simulation runtime (defined as the number of runs required for stable\nresults multiplied by the duration of a single run) but also achieves smaller\nerrors across both 25% and 100% population samples. The coupling mechanism\nensures consistency at the model interface: agents crossing from the ABM into\nthe PDE domain are removed and represented as density contributions at the\ncorresponding grid node, while surplus density in the PDE domain is used to\ngenerate agents with plausible trajectories derived from mobile phone data. We\nevaluate the hybrid model using real-world mobility and infection data for the\nBerlin-Brandenburg region in Germany, showing that it captures the core\nepidemiological dynamics while enabling efficient large-scale simulations.", "published": "2025-04-11 10:44:09", "link": "http://arxiv.org/abs/2504.08430v1", "categories": ["cs.MA", "q-bio.PE"], "primary_category": "cs.MA"}
{"title": "Discretization Error Analysis of a High Order Unfitted Space-Time Method for moving domain problems", "abstract": "We present a numerical analysis of a higher order unfitted space-time Finite\nElement method applied to a convection-diffusion model problem posed on a\nmoving bulk domain. The method uses isoparametric space-time mappings for the\ngeometry approximation of level set domains and has been presented and\ninvestigated computationally in [Heimann, Lehrenfeld, Preu{\\ss}, SIAM J. Sci.\nComp. 45(2), 2023, B139 - B165]. Recently, in [Heimann, Lehrenfeld, IMA J.\nNumer. Anal., 2025] error bounds for the geometry approximation have been\nproven. In this paper we prove stability and accuracy including the influence\nof the geometry approximation.", "published": "2025-04-11 15:16:20", "link": "http://arxiv.org/abs/2504.08608v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Well-Posedness of Discretizations for Fractional Elasto-Plasticity", "abstract": "We consider a fractional plasticity model based on linear isotropic and\nkinematic hardening as well as a standard von-Mises yield function, where the\nflow rule is replaced by a Riesz--Caputo fractional derivative. The resulting\nmathematical model is typically non-local and non-smooth. Our numerical\nalgorithm is based on the well-known radial return mapping and exploits that\nthe kernel is finitely supported. We propose explicit and implicit\ndiscretizations of the model and show the well-posedness of the explicit in\ntime discretization in combination with a standard finite element approach in\nspace. Our numerical results in 2D and 3D illustrate the performance of the\nalgorithm and the influence of the fractional parameter.", "published": "2025-04-11 11:25:26", "link": "http://arxiv.org/abs/2504.08450v1", "categories": ["math.NA", "cs.NA", "26A33, 74H15, 74H20, 74S05"], "primary_category": "math.NA"}
{"title": "An posteriori error estimator for discontinuous Galerkin discretisations of convection-diffusion problems with application to Earth's mantle convection simulations", "abstract": "We present new aposteriori error estimates for the interior penalty\ndiscontinuous Galerkin method applied to non-stationary convection-diffusion\nequations. The focus is on strongly convection-dominated problems without\nzeroth-order reaction terms, which leads to the absence of positive L^2-like\ncomponents. An important specific example is the energy/temperature equation of\nthe Boussinesq system arising from the modelling of mantle convection of the\nEarth. The key mathematical challenge of mitigating the effects of exponential\nfactors with respect to the final time, arising from the use of Gronwall-type\narguments, is addressed by an exponential fitting technique. The latter results\nto a new class of aposteriori error estimates for the stationary problem, which\nare valid in cases of convection and reaction coefficient combinations not\ncovered by the existing literature. This new class of estimators is combined\nwith an elliptic reconstruction technique to derive new respective estimates\nfor the non-stationary problem, exhibiting reduced dependence on Gronwall-type\nexponents and, thus, offer more accurate estimation for longer time intervals.\nWe showcase the superior performance of the new class of aposteriori error\nestimators in driving mesh adaptivity in Earth's mantle convection simulations,\nin a setting where the energy/temperature equation is discretised by the\ndiscontinuous Galerkin method, coupled with the Taylor-Hood finite element for\nthe momentum and mass conservation equations. We exploit the community code\nASPECT, to present numerical examples showing the effectivity of the proposed\napproach.", "published": "2025-04-11 09:34:50", "link": "http://arxiv.org/abs/2504.08382v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Deep learning-based moment closure for multi-phase computation of semiclassical limit of the Schr\u00f6dinger equation", "abstract": "We present a deep learning approach for computing multi-phase solutions to\nthe semiclassical limit of the Schr\\\"odinger equation. Traditional methods\nrequire deriving a multi-phase ansatz to close the moment system of the\nLiouville equation, a process that is often computationally intensive and\nimpractical. Our method offers an efficient alternative by introducing a novel\ntwo-stage neural network framework to close the $2N\\times 2N$ moment system,\nwhere $N$ represents the number of phases in the solution ansatz. In the first\nstage, we train neural networks to learn the mapping between higher-order\nmoments and lower-order moments (along with their derivatives). The second\nstage incorporates physics-informed neural networks (PINNs), where we\nsubstitute the learned higher-order moments to systematically close the system.\nWe provide theoretical guarantees for the convergence of both the loss\nfunctions and the neural network approximations. Numerical experiments\ndemonstrate the effectiveness of our method for one- and two-dimensional\nproblems with various phase numbers $N$ in the multi-phase solutions. The\nresults confirm the accuracy and computational efficiency of the proposed\napproach compared to conventional techniques.", "published": "2025-04-11 08:13:52", "link": "http://arxiv.org/abs/2504.08341v1", "categories": ["math.NA", "cs.NA", "68T20, 35Q84, 35B40, 82C40"], "primary_category": "math.NA"}
{"title": "Stochastic Momentum ADMM for nonconvex and nonsmooth optimization with application to PnP algorithm", "abstract": "This paper introduces a single-loop Stochastic Momentum Alternating Direction\nMethod of Multipliers (SMADMM) for tackling a class of nonconvex and nonsmooth\noptimization problems. We establish that SMADMM achieves an optimal oracle\ncomplexity of $\\mathcal{O}(\\epsilon^{-\\frac{3}{2}})$ in the online setting,\nwhere only stochastic first-order oracle, is available. In particular, SMADMM\nrequires only $\\mathcal{O}(1)$ stochastic gradient evaluations per iteration\nand avoids the need for restarting with large batch gradient estimates. This is\nthe first stochastic ADMM method achieving optimal oracle complexity for\nnonconvex and nonsmooth problems, requiring $\\mathcal{O}(1)$ batch size.\nFurthermore, we extend our method by integrating it with plug-and-play (PnP)\npriors, resulting in the PnP-SMADMM algorithm. Numerical experiments on\nclassification, CT image reconstruction and phase retrieve demonstrate the\npractical effectiveness of our approach and validate the theoretical findings.", "published": "2025-04-11 03:11:51", "link": "http://arxiv.org/abs/2504.08223v1", "categories": ["math.OC", "cs.NA", "math.NA", "65K05, 65K10, 90C05, 90C26, 90C30"], "primary_category": "math.OC"}
{"title": "International Financial Markets Through 150 Years: Evaluating Stylized Facts", "abstract": "In the theory of financial markets, a stylized fact is a qualitative summary\nof a pattern in financial market data that is observed across multiple assets,\nasset classes and time horizons. In this article, we test a set of eleven\nstylized facts for financial market data. Our main contribution is to consider\na broad range of geographical regions across Asia, continental Europe, and the\nUS over a time period of 150 years, as well as two of the most traded\ncryptocurrencies, thus providing insights into the robustness and\ngeneralizability of commonly known stylized facts.", "published": "2025-04-11 15:19:00", "link": "http://arxiv.org/abs/2504.08611v1", "categories": ["q-fin.ST", "q-fin.GN", "62P05"], "primary_category": "q-fin.ST"}
{"title": "Diffusion Models for Robotic Manipulation: A Survey", "abstract": "Diffusion generative models have demonstrated remarkable success in visual\ndomains such as image and video generation. They have also recently emerged as\na promising approach in robotics, especially in robot manipulations. Diffusion\nmodels leverage a probabilistic framework, and they stand out with their\nability to model multi-modal distributions and their robustness to\nhigh-dimensional input and output spaces. This survey provides a comprehensive\nreview of state-of-the-art diffusion models in robotic manipulation, including\ngrasp learning, trajectory planning, and data augmentation. Diffusion models\nfor scene and image augmentation lie at the intersection of robotics and\ncomputer vision for vision-based tasks to enhance generalizability and data\nscarcity. This paper also presents the two main frameworks of diffusion models\nand their integration with imitation learning and reinforcement learning. In\naddition, it discusses the common architectures and benchmarks and points out\nthe challenges and advantages of current state-of-the-art diffusion-based\nmethods.", "published": "2025-04-11 11:01:11", "link": "http://arxiv.org/abs/2504.08438v1", "categories": ["cs.RO", "stat.ML"], "primary_category": "cs.RO"}
{"title": "An Introduction to Double/Debiased Machine Learning", "abstract": "This paper provides a practical introduction to Double/Debiased Machine\nLearning (DML). DML provides a general approach to performing inference about a\ntarget parameter in the presence of nuisance parameters. The aim of DML is to\nreduce the impact of nuisance parameter estimation on estimators of the\nparameter of interest. We describe DML and its two essential components: Neyman\northogonality and cross-fitting. We highlight that DML reduces functional form\ndependence and accommodates the use of complex data types, such as text data.\nWe illustrate its application through three empirical examples that demonstrate\nDML's applicability in cross-sectional and panel settings.", "published": "2025-04-11 07:48:42", "link": "http://arxiv.org/abs/2504.08324v1", "categories": ["econ.EM", "stat.ME", "stat.ML"], "primary_category": "econ.EM"}
{"title": "BowelRCNN: Region-based Convolutional Neural Network System for Bowel Sound Auscultation", "abstract": "Sound events representing intestinal activity detection is a diagnostic tool\nwith potential to identify gastrointestinal conditions. This article introduces\nBowelRCNN, a novel bowel sound detection system that uses audio recording,\nspectrogram analysys and region-based convolutional neural network (RCNN)\narchitecture. The system was trained and validated on a real recording dataset\ngathered from 19 patients, comprising 60 minutes of prepared and annotated\naudio data. BowelRCNN achieved a classification accuracy of 96% and an F1 score\nof 71%. This research highlights the feasibility of using CNN architectures for\nbowel sound auscultation, achieving results comparable to those of\nrecurrent-convolutional methods.", "published": "2025-04-11 16:01:04", "link": "http://arxiv.org/abs/2504.08659v1", "categories": ["cs.SD", "eess.AS", "68", "J.3"], "primary_category": "cs.SD"}
{"title": "Reverberation-based Features for Sound Event Localization and Detection with Distance Estimation", "abstract": "Sound event localization and detection (SELD) involves predicting active\nsound event classes over time while estimating their positions. The\nlocalization subtask in SELD is usually treated as a direction of arrival\nestimation problem, ignoring source distance. Only recently, SELD was extended\nto 3D by incorporating distance estimation, enabling the prediction of sound\nevent positions in 3D space (3D SELD). However, existing methods lack input\nfeatures designed for distance estimation. We argue that reverberation encodes\nvaluable information for this task. This paper introduces two novel feature\nformats for 3D SELD based on reverberation: one using direct-to-reverberant\nratio (DRR) and another leveraging signal autocorrelation to provide the model\nwith insights into early reflections. Pre-training on synthetic data improves\nrelative distance error (RDE) and overall SELD score, with\nautocorrelation-based features reducing RDE by over 3 percentage points on the\nSTARSS23 dataset. The code to extract the features is available at\ngithub.com/dberghi/SELD-distance-features.", "published": "2025-04-11 15:43:13", "link": "http://arxiv.org/abs/2504.08644v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "TorchFX: A modern approach to Audio DSP with PyTorch and GPU acceleration", "abstract": "The burgeoning complexity and real-time processing demands of audio signals\nnecessitate optimized algorithms that harness the computational prowess of\nGraphics Processing Units (GPUs). Existing Digital Signal Processing (DSP)\nlibraries often fall short in delivering the requisite efficiency and\nflexibility, particularly in integrating Artificial Intelligence (AI) models.\nIn response, we introduce TorchFX: a GPU-accelerated Python library for DSP,\nspecifically engineered to facilitate sophisticated audio signal processing.\nBuilt atop the PyTorch framework, TorchFX offers an Object-Oriented interface\nthat emulates the usability of torchaudio, enhancing functionality with a novel\npipe operator for intuitive filter chaining. This library provides a\ncomprehensive suite of Finite Impulse Response (FIR) and Infinite Impulse\nResponse (IIR) filters, with a focus on multichannel audio files, thus\nfacilitating the integration of DSP and AI-based approaches. Our benchmarking\nresults demonstrate significant efficiency gains over traditional libraries\nlike SciPy, particularly in multichannel contexts. Despite current limitations\nin GPU compatibility, ongoing developments promise broader support and\nreal-time processing capabilities. TorchFX aims to become a useful tool for the\ncommunity, contributing to innovation and progress in DSP with GPU\nacceleration. TorchFX is publicly available on GitHub at\nhttps://github.com/matteospanio/torchfx.", "published": "2025-04-11 15:26:10", "link": "http://arxiv.org/abs/2504.08624v1", "categories": ["eess.AS", "cs.PF", "cs.SD", "eess.SP", "D.2.10; J.5"], "primary_category": "eess.AS"}
{"title": "Location-Oriented Sound Event Localization and Detection with Spatial Mapping and Regression Localization", "abstract": "Sound Event Localization and Detection (SELD) combines the Sound Event\nDetection (SED) with the corresponding Direction Of Arrival (DOA). Recently,\nadopted event oriented multi-track methods affect the generality in polyphonic\nenvironments due to the limitation of the number of tracks. To enhance the\ngenerality in polyphonic environments, we propose Spatial Mapping and\nRegression Localization for SELD (SMRL-SELD). SMRL-SELD segments the 3D spatial\nspace, mapping it to a 2D plane, and a new regression localization loss is\nproposed to help the results converge toward the location of the corresponding\nevent. SMRL-SELD is location-oriented, allowing the model to learn event\nfeatures based on orientation. Thus, the method enables the model to process\npolyphonic sounds regardless of the number of overlapping events. We conducted\nexperiments on STARSS23 and STARSS22 datasets and our proposed SMRL-SELD\noutperforms the existing SELD methods in overall evaluation and polyphony\nenvironments.", "published": "2025-04-11 09:00:53", "link": "http://arxiv.org/abs/2504.08365v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Channel Estimation and Hybrid Precoding for Massive MIMO-OTFS System With Doubly Squint", "abstract": "Orthogonal time frequency space (OTFS) modulation and massive multi-input\nmulti-output (MIMO) are promising technologies for next generation wireless\ncommunication systems for their abilities to counteract the issue of high\nmobility with large Doppler spread and mitigate the channel path attenuation,\nrespectively. The natural integration of massive MIMO with OTFS in\nmillimeter-wave systems can improve communication data rate and enhance the\nspectral efficiency. However, when transmitting wideband signals with\nlarge-scale arrays, the beam squint effect may occur, causing discrepancies in\nbeam directions across subcarriers in multi-carrier systems. Moreover, the\nhigh-mobility wideband millimeter wave communications\n  can induce the Doppler squint effect, leading to different Doppler shifts\namong the subcarriers. Both beam squint effect and Doppler squint effect\n(denoted as doubly squint effect) can degrade communication performance\nsignificantly. In this paper, we present an efficient channel estimation and\nhybrid precoding scheme to address the doubly squint effect in massive\nMIMO-OTFS systems. We first characterize the wideband channel model and the\ninput-output relationship for massive MIMO-OTFS transmission considering doubly\nsquint effect. We then mathematically derive the impact of channel parameters\non chirp pilots under the doubly squint effect. Additionally, we develop a\npeak-index-based channel estimation scheme. By leveraging the results from\nchannel estimation, we propose a hybrid precoding method to mitigate the doubly\nsquint effect in downlink transmission scenarios. Finally, simulation results\nvalidate the effectiveness of our proposed scheme and show its superiority over\nthe existing schemes.", "published": "2025-04-11 14:26:12", "link": "http://arxiv.org/abs/2504.08569v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Distributed Uplink Joint Transmission for 6G Communication", "abstract": "This paper investigates the spectral efficiency achieved through uplink joint\ntransmission, where a serving user and the network users (UEs) collaborate by\njointly transmitting to the base station (BS). The analysis incorporates the\nresource requirements for information sharing among UEs as a critical factor in\nthe capacity evaluation. Furthermore, coherent and non-coherent joint\ntransmission schemes are compared under various transmission power scenarios,\nproviding insights into spectral and energy efficiency. A selection algorithm\nidentifying the optimal UEs for joint transmission, achieving maximum capacity,\nis discussed. The results indicate that uplink joint transmission is one of the\npromising techniques for enabling 6G, achieving greater spectral efficiency\neven when accounting for the resource requirements for information sharing.", "published": "2025-04-11 14:21:20", "link": "http://arxiv.org/abs/2504.08567v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "STF-GCN: A Multi-Domain Graph Convolution Network Method for Automatic Modulation Recognition via Adaptive Correlation", "abstract": "Automatic Modulation Recognition (AMR) is an essential part of Intelligent\nTransportation System (ITS) dynamic spectrum allocation. However, current deep\nlearning-based AMR (DL-AMR) methods are challenged to extract discriminative\nand robust features at low signal-to-noise ratios (SNRs), where the\nrepresentation of modulation symbols is highly interfered by noise.\nFurthermore, current research on GNN methods for AMR tasks generally suffers\nfrom issues related to graph structure construction and computational\ncomplexity. In this paper, we propose a Spatial-Temporal-Frequency Graph\nConvolution Network (STF-GCN) framework, with the temporal domain as the anchor\npoint, to fuse spatial and frequency domain features embedded in the graph\nstructure nodes. On this basis, an adaptive correlation-based adjacency matrix\nconstruction method is proposed, which significantly enhances the graph\nstructure's capacity to aggregate local information into individual nodes. In\naddition, a PoolGAT layer is proposed to coarsen and compress the global key\nfeatures of the graph, significantly reducing the computational complexity. The\nresults of the experiments confirm that STF-GCN is able to achieve recognition\nperformance far beyond the state-of-the-art DL-AMR algorithms, with overall\naccuracies of 64.35%, 66.04% and 70.95% on the RML2016.10a, RML2016.10b and\nRML22 datasets, respectively. Furthermore, the average recognition accuracies\nunder low SNR conditions from -14dB to 0dB outperform the state-of-the-art\n(SOTA) models by 1.20%, 1.95% and 1.83%, respectively.", "published": "2025-04-11 13:10:38", "link": "http://arxiv.org/abs/2504.08504v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "AI-Driven Smart Sportswear for Real-Time Fitness Monitoring Using Textile Strain Sensors", "abstract": "Wearable biosensors have revolutionized human performance monitoring by\nenabling real-time assessment of physiological and biomechanical parameters.\nHowever, existing solutions lack the ability to simultaneously capture\nbreath-force coordination and muscle activation symmetry in a seamless and\nnon-invasive manner, limiting their applicability in strength training and\nrehabilitation. This work presents a wearable smart sportswear system that\nintegrates screen-printed graphene-based strain sensors with a wireless deep\nlearning framework for real-time classification of exercise execution quality.\nBy leveraging 1D ResNet-18 for feature extraction, the system achieves 92.3%\nclassification accuracy across six exercise conditions, distinguishing between\nbreathing irregularities and asymmetric muscle exertion. Additionally, t-SNE\nanalysis and Grad-CAM-based explainability visualization confirm that the\nnetwork accurately captures biomechanically relevant features, ensuring robust\ninterpretability. The proposed system establishes a foundation for\nnext-generation AI-powered sportswear, with applications in fitness\noptimization, injury prevention, and adaptive rehabilitation training.", "published": "2025-04-11 13:07:08", "link": "http://arxiv.org/abs/2504.08500v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Successive Jump and Mode Decomposition", "abstract": "We propose fully data-driven variational methods, termed successive jump and\nmode decomposition (SJMD) and its multivariate extension, successive\nmultivariate jump and mode decomposition (SMJMD), for successively decomposing\nnonstationary signals into amplitude- and frequency-modulated (AM-FM)\noscillations and jump components. Unlike existing methods that treat\noscillatory modes and jump discontinuities separately and often require prior\nknowledge of the number of components (K) -- which is difficult to obtain in\npractice -- our approaches employ successive optimization-based schemes that\njointly handle AM-FM oscillations and jump discontinuities without the need to\npredefine K. Empirical evaluations on synthetic and real-world datasets\ndemonstrate that the proposed algorithms offer superior accuracy and\ncomputational efficiency compared to state-of-the-art methods.", "published": "2025-04-11 11:28:11", "link": "http://arxiv.org/abs/2504.08453v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Statistical Linear Regression Approach to Kalman Filtering and Smoothing under Cyber-Attacks", "abstract": "Remote state estimation in cyber-physical systems is often vulnerable to\ncyber-attacks due to wireless connections between sensors and computing units.\nIn such scenarios, adversaries compromise the system by injecting false data or\nblocking measurement transmissions via denial-of-service attacks, distorting\nsensor readings. This paper develops a Kalman filter and Rauch--Tung--Striebel\n(RTS) smoother for linear stochastic state-space models subject to\ncyber-attacked measurements. We approximate the faulty measurement model via\ngeneralized statistical linear regression (GSLR). The GSLR-based approximated\nmeasurement model is then used to develop a Kalman filter and RTS smoother for\nthe problem. The effectiveness of the proposed algorithms under cyber-attacks\nis demonstrated through a simulated aircraft tracking experiment.", "published": "2025-04-11 10:11:32", "link": "http://arxiv.org/abs/2504.08404v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Flip-KLJN: Random Resistance Flipping for Noise-Driven Secure Communication", "abstract": "The information-theoretically (unconditionally) secure\nKirchhoff-law-Johnson-noise (KLJN) bit exchange protocol uses two identical\nresistor pairs with high (H) and low (L) resistance values, driven by Gaussian\nnoise generators emulating Johnson noise with a high common temperature. The\nresulting mean-square noise voltage on the wire connecting Alice and Bob has\nthree levels: low (L/L), intermediate (H/L or L/H), and high (H/H), and secure\nkey sharing is achieved at the intermediate level (L/H or H/L). This paper\nintroduces the Flip-KLJN scheme, where a pre-agreed intermediate level, such as\nH/L, triggers a flip of the bit map value during the bit exchange period. For\nEve, the bit map flips appear random. Thus, the formerly discarded H/H and L/L\nsituations can also have a pre-agreed bit value mapping, which flips together\nwith the original bit mapping. Thus, Flip-KLJN doubles the key rate and ensures\nthat all three levels on the wire are indistinguishable for Eve. Bit error\nprobabilities are addressed through analytic calculations and computer\nsimulations.", "published": "2025-04-11 09:06:58", "link": "http://arxiv.org/abs/2504.08367v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fast Reconfiguration of LC-RISs: Modeling and Algorithm Design", "abstract": "LC technology is a promising hardware solution for realizing extremely large\nRISs due to its advantages in cost-effectiveness, scalability, energy\nefficiency, and continuous phase shift tunability. However, the slow response\ntime of the LC cells, especially in comparison to the silicon-based\nalternatives like radio frequency switches and PIN diodes, limits the\nperformance. This limitation becomes particularly relevant in TDMA applications\nwhere RIS must sequentially serve users in different locations, as the\nphase-shifting response time of LC cells can constrain system performance. This\npaper addresses the slow phase-shifting limitation of LC by developing a\nphysics-based model for the time response of an LC unit cell and proposing a\nnovel phase-shift design framework to reduce the transition time. Specifically,\nexploiting the fact that LC-RIS at milimeter wave bands have a large electric\naperture, we optimize the LC phase shifts based on user locations, eliminating\nthe need for full channel state information and minimizing reconfiguration\noverhead. Moreover, instead of focusing on a single point, the RIS phase\nshifters are designed to optimize coverage over an area. This enhances\ncommunication reliability for mobile users and mitigates performance\ndegradation due to user location estimation errors. The proposed design\nminimizes the transition time between configurations, a critical requirement\nfor TDMA schemes. Our analysis reveals that the impact of RIS reconfiguration\ntime on system throughput becomes particularly significant when TDMA intervals\nare comparable to the reconfiguration time. In such scenarios, optimizing the\nphase-shift design helps mitigate performance degradation while ensuring\nspecific QoS requirements. Moreover, the proposed algorithm has been tested\nthrough experimental evaluations, which demonstrate that it also performs\neffectively in practice.", "published": "2025-04-11 08:39:14", "link": "http://arxiv.org/abs/2504.08352v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Distributed Kalman Filter with Ultimately Accurate Fused Measurement Covariance", "abstract": "This paper investigates the distributed Kalman filter (DKF) for linear\nsystems, with specific attention on measurement fusion, which is a typical way\nof information sharing and is vital for enhancing stability and improving\nestimation accuracy. We show that it is the mismatch between the fused\nmeasurement and the fused covariance that leads to performance degradation or\ninconsistency in previous consensus-based DKF algorithms. To address this\nissue, we introduce two fully distributed approaches for calculating the exact\ncovariance of the fused measurements, building upon which the modified DKF\nalgorithms are proposed. Moreover, the performance analysis of the modified\nalgorithms is also provided under rather mild conditions, including the\nsteady-state value of the estimation error covariance. We also show that due to\nthe guaranteed consistency in the modified DKF algorithms, the steady-state\nestimation accuracy is significantly improved compared to classical DKF\nalgorithms. Numerical experiments are carried out to validate the theoretical\nanalysis and show the advantages of the proposed methods.", "published": "2025-04-11 07:07:14", "link": "http://arxiv.org/abs/2504.08302v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "General Theory of Coupled Characteristic Mode: An Eigen Subspace Approach", "abstract": "In this work, the problem of characteristic mode analysis using\neigendecomposition of the method of moments impedance matrix has been\nsimplified using the eigen-subspace approach. The idea behind the\neigen-subspace arises from the physical properties of antenna or scatterers,\nwhere only a few eigenmodes are enough to characterize the antenna or\nscatterer. Therefore, entire space eigenanalysis is a waste of computational\nresources, and eigen-subspace analysis with few modes is good enough to\ncharacterize antennas and scatterers. It has been assumed that there is an\neigen-subspace (or hyperplane) of coupled characteristic mode, which coincides\nwith the eigen-hyperplane of uncoupled characteristic mode. We can say the\ncoupled characteristic modes are linear combinations of isolated modes based on\nthis assumption. The linear combination is mapped via modal coupling matrix.\nUsing the modal coupling matrix, we can explain the behavior of arbitrarily\nshaped antennas and scatterers. A computationally efficient method is developed\nto compute coupled characteristic modes of two mutually coupled scatterers or\nantennas using the eigen-subspace. The method is summarized as a theorem of\ntwo-body coupled characteristic mode. The theorem of two-body coupled\ncharacteristic mode has been extended to the N-body coupled characteristic\nmode. Two algorithms have been developed for the two-body multimode coupled\ncharacteristic mode and N-body multimode coupled characteristic mode. Two\nnumerical examples are provided to validate the proposed concepts.", "published": "2025-04-11 04:29:48", "link": "http://arxiv.org/abs/2504.08251v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "InSPE: Rapid Evaluation of Heterogeneous Multi-Modal Infrastructure Sensor Placement", "abstract": "Infrastructure sensing is vital for traffic monitoring at safety hotspots\n(e.g., intersections) and serves as the backbone of cooperative perception in\nautonomous driving. While vehicle sensing has been extensively studied,\ninfrastructure sensing has received little attention, especially given the\nunique challenges of diverse intersection geometries, complex occlusions,\nvarying traffic conditions, and ambient environments like lighting and weather.\nTo address these issues and ensure cost-effective sensor placement, we propose\nHeterogeneous Multi-Modal Infrastructure Sensor Placement Evaluation (InSPE), a\nperception surrogate metric set that rapidly assesses perception effectiveness\nacross diverse infrastructure and environmental scenarios with combinations of\nmulti-modal sensors. InSPE systematically evaluates perception capabilities by\nintegrating three carefully designed metrics, i.e., sensor coverage, perception\nocclusion, and information gain. To support large-scale evaluation, we develop\na data generation tool within the CARLA simulator and also introduce Infra-Set,\na dataset covering diverse intersection types and environmental conditions.\nBenchmarking experiments with state-of-the-art perception algorithms\ndemonstrate that InSPE enables efficient and scalable sensor placement\nanalysis, providing a robust solution for optimizing intelligent intersection\ninfrastructure.", "published": "2025-04-11 03:55:00", "link": "http://arxiv.org/abs/2504.08240v1", "categories": ["cs.RO", "eess.SP"], "primary_category": "cs.RO"}
{"title": "Examining Different Placement Strategies for Indoor Environmental Quality Sensors in Office Environments", "abstract": "Collecting Indoor Environmental Quality (IEQ) data from an occupant's\nimmediate surroundings can provide personalized insights for healthy\nenvironmental conditions aligned with occupant preferences, but effective\nsensor placement for data accuracy and reliability has not been thoroughly\nexplored. This paper explores various positioning of IEQ multi-sensing devices\nat individual workstations in typical office settings, aiming to identify\nsensor placements that most accurately reflect the environmental conditions\nexperienced by occupants. We examined five unique positions close to an\noccupant (above and below the monitor, right side of the desk, ceiling, and\nchair backrest), two orientations, and three desk locations characterized by\ndifferent lighting levels, thermal and airflow conditions. Data on temperature,\nhumidity, carbon dioxide (CO2), particulate matters (PM1, PM2.5, PM10),\nilluminance, and sound were collected over a 2-week longitudinal experiment,\nfollowed by short-term experiments simulating common pollution events such as\ncoughing and sneezing. Principal Component Analysis, Spearman's rank\ncorrelation, R2, and Mean Absolute Error were applied to identify the position\nand orientation that best captures the most information and matches breathing\nzone measurements. It was found that above the monitor position, facing the\noccupant, best captures the IEQ conditions experienced by the occupant.", "published": "2025-04-11 03:52:11", "link": "http://arxiv.org/abs/2504.08237v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Analyzing 16,193 LLM Papers for Fun and Profits", "abstract": "Large Language Models (LLMs) are reshaping the landscape of computer science\nresearch, driving significant shifts in research priorities across diverse\nconferences and fields. This study provides a comprehensive analysis of the\npublication trend of LLM-related papers in 77 top-tier computer science\nconferences over the past six years (2019-2024). We approach this analysis from\nfour distinct perspectives: (1) We investigate how LLM research is driving\ntopic shifts within major conferences. (2) We adopt a topic modeling approach\nto identify various areas of LLM-related topic growth and reveal the topics of\nconcern at different conferences. (3) We explore distinct contribution patterns\nof academic and industrial institutions. (4) We study the influence of national\norigins on LLM development trajectories. Synthesizing the findings from these\ndiverse analytical angles, we derive ten key insights that illuminate the\ndynamics and evolution of the LLM research ecosystem.", "published": "2025-04-11 15:24:23", "link": "http://arxiv.org/abs/2504.08619v2", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Task Memory Engine (TME): A Structured Memory Framework with Graph-Aware Extensions for Multi-Step LLM Agent Tasks", "abstract": "Large Language Models (LLMs) are increasingly used as autonomous agents for\nmulti-step tasks. However, most existing frameworks fail to maintain a\nstructured understanding of the task state, often relying on linear prompt\nconcatenation or shallow memory buffers. This leads to brittle performance,\nfrequent hallucinations, and poor long-range coherence. In this work, we\npropose the Task Memory Engine (TME), a lightweight and structured memory\nmodule that tracks task execution using a hierarchical Task Memory Tree (TMT).\nEach node in the tree corresponds to a task step, storing relevant input,\noutput, status, and sub-task relationships. We introduce a prompt synthesis\nmethod that dynamically generates LLM prompts based on the active node path,\nsignificantly improving execution consistency and contextual grounding. Through\ncase studies and comparative experiments on multi-step agent tasks, we\ndemonstrate that TME leads to better task completion accuracy and more\ninterpretable behavior with minimal implementation overhead. A reference\nimplementation of the core TME components is available at\nhttps://github.com/biubiutomato/TME-Agent, including basic examples and\nstructured memory integration. While the current implementation uses a\ntree-based structure, TME is designed to be graph-aware, supporting reusable\nsubsteps, converging task paths, and shared dependencies. This lays the\ngroundwork for future DAG-based memory architectures.", "published": "2025-04-11 13:38:36", "link": "http://arxiv.org/abs/2504.08525v2", "categories": ["cs.AI", "cs.CL", "68T05", "I.2.6; I.2.8; H.3.3"], "primary_category": "cs.AI"}
{"title": "Large language models could be rote learners", "abstract": "Multiple-choice question (MCQ) benchmarks are widely used for evaluating\nLarge Language Models (LLMs), yet their reliability is undermined by benchmark\ncontamination. In this study, we reframe contamination as an inherent aspect of\nlearning and seek to disentangle genuine capability acquisition from\nsuperficial memorization in LLM evaluation. First, by analyzing model\nperformance under different memorization conditions, we uncover a\ncounterintuitive trend: LLMs perform worse on memorized MCQs than on\nnon-memorized ones, indicating the coexistence of two distinct learning\nphenomena, i.e., rote memorization and genuine capability learning. To\ndisentangle them, we propose TrinEval, a novel evaluation framework that\nreformulates MCQs into an alternative trinity format, reducing memorization\nwhile preserving knowledge assessment. Experiments validate TrinEval's\neffectiveness in reformulation, and its evaluation reveals that common LLMs may\nmemorize by rote 20.5% of knowledge points (in MMLU on average).", "published": "2025-04-11 07:04:44", "link": "http://arxiv.org/abs/2504.08300v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hands-On: Segmenting Individual Signs from Continuous Sequences", "abstract": "This work tackles the challenge of continuous sign language segmentation, a\nkey task with huge implications for sign language translation and data\nannotation. We propose a transformer-based architecture that models the\ntemporal dynamics of signing and frames segmentation as a sequence labeling\nproblem using the Begin-In-Out (BIO) tagging scheme. Our method leverages the\nHaMeR hand features, and is complemented with 3D Angles. Extensive experiments\nshow that our model achieves state-of-the-art results on the DGS Corpus, while\nour features surpass prior benchmarks on BSLCorpus.", "published": "2025-04-11 14:52:59", "link": "http://arxiv.org/abs/2504.08593v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "RAG-VR: Leveraging Retrieval-Augmented Generation for 3D Question Answering in VR Environments", "abstract": "Recent advances in large language models (LLMs) provide new opportunities for\ncontext understanding in virtual reality (VR). However, VR contexts are often\nhighly localized and personalized, limiting the effectiveness of\ngeneral-purpose LLMs. To address this challenge, we present RAG-VR, the first\n3D question-answering system for VR that incorporates retrieval-augmented\ngeneration (RAG), which augments an LLM with external knowledge retrieved from\na localized knowledge database to improve the answer quality. RAG-VR includes a\npipeline for extracting comprehensive knowledge about virtual environments and\nuser conditions for accurate answer generation. To ensure efficient retrieval,\nRAG-VR offloads the retrieval process to a nearby edge server and uses only\nessential information during retrieval. Moreover, we train the retriever to\neffectively distinguish among relevant, irrelevant, and hard-to-differentiate\ninformation in relation to questions. RAG-VR improves answer accuracy by\n17.9%-41.8% and reduces end-to-end latency by 34.5%-47.3% compared with two\nbaseline systems.", "published": "2025-04-11 04:55:50", "link": "http://arxiv.org/abs/2504.08256v2", "categories": ["cs.IR", "cs.AI", "cs.HC"], "primary_category": "cs.IR"}
{"title": "Neural Encoding and Decoding at Scale", "abstract": "Recent work has demonstrated that large-scale, multi-animal models are\npowerful tools for characterizing the relationship between neural activity and\nbehavior. Current large-scale approaches, however, focus exclusively on either\npredicting neural activity from behavior (encoding) or predicting behavior from\nneural activity (decoding), limiting their ability to capture the bidirectional\nrelationship between neural activity and behavior. To bridge this gap, we\nintroduce a multimodal, multi-task model that enables simultaneous Neural\nEncoding and Decoding at Scale (NEDS). Central to our approach is a novel\nmulti-task-masking strategy, which alternates between neural, behavioral,\nwithin-modality, and cross-modality masking. We pretrain our method on the\nInternational Brain Laboratory (IBL) repeated site dataset, which includes\nrecordings from 83 animals performing the same visual decision-making task. In\ncomparison to other large-scale models, we demonstrate that NEDS achieves\nstate-of-the-art performance for both encoding and decoding when pretrained on\nmulti-animal data and then fine-tuned on new animals. Surprisingly, NEDS's\nlearned embeddings exhibit emergent properties: even without explicit training,\nthey are highly predictive of the brain regions in each recording. Altogether,\nour approach is a step towards a foundation model of the brain that enables\nseamless translation between neural activity and behavior.", "published": "2025-04-11 02:06:20", "link": "http://arxiv.org/abs/2504.08201v2", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "PMNI: Pose-free Multi-view Normal Integration for Reflective and Textureless Surface Reconstruction", "abstract": "Reflective and textureless surfaces remain a challenge in multi-view 3D\nreconstruction. Both camera pose calibration and shape reconstruction often\nfail due to insufficient or unreliable cross-view visual features. To address\nthese issues, we present PMNI (Pose-free Multi-view Normal Integration), a\nneural surface reconstruction method that incorporates rich geometric\ninformation by leveraging surface normal maps instead of RGB images. By\nenforcing geometric constraints from surface normals and multi-view shape\nconsistency within a neural signed distance function (SDF) optimization\nframework, PMNI simultaneously recovers accurate camera poses and high-fidelity\nsurface geometry. Experimental results on synthetic and real-world datasets\nshow that our method achieves state-of-the-art performance in the\nreconstruction of reflective surfaces, even without reliable initial camera\nposes.", "published": "2025-04-11 10:16:55", "link": "http://arxiv.org/abs/2504.08410v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SeaView: Software Engineering Agent Visual Interface for Enhanced Workflow", "abstract": "Auto-regressive LLM-based software engineering (SWE) agents, henceforth SWE\nagents, have made tremendous progress (>60% on SWE-Bench Verified) on\nreal-world coding challenges including GitHub issue resolution. SWE agents use\na combination of reasoning, environment interaction and self-reflection to\nresolve issues thereby generating \"trajectories\". Analysis of SWE agent\ntrajectories is difficult, not only as they exceed LLM sequence length\n(sometimes, greater than 128k) but also because it involves a relatively\nprolonged interaction between an LLM and the environment managed by the agent.\nIn case of an agent error, it can be hard to decipher, locate and understand\nits scope. Similarly, it can be hard to track improvements or regression over\nmultiple runs or experiments. While a lot of research has gone into making\nthese SWE agents reach state-of-the-art, much less focus has been put into\ncreating tools to help analyze and visualize agent output. We propose a novel\ntool called SeaView: Software Engineering Agent Visual Interface for Enhanced\nWorkflow, with a vision to assist SWE-agent researchers to visualize and\ninspect their experiments. SeaView's novel mechanisms help compare experimental\nruns with varying hyper-parameters or LLMs, and quickly get an understanding of\nLLM or environment related problems. Based on our user study, experienced\nresearchers spend between 10 and 30 minutes to gather the information provided\nby SeaView, while researchers with little experience can spend between 30\nminutes to 1 hour to diagnose their experiment.", "published": "2025-04-11 17:03:58", "link": "http://arxiv.org/abs/2504.08696v2", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Understanding the Impact of Data Domain Extraction on Synthetic Data Privacy", "abstract": "Privacy attacks, particularly membership inference attacks (MIAs), are widely\nused to assess the privacy of generative models for tabular synthetic data,\nincluding those with Differential Privacy (DP) guarantees. These attacks often\nexploit outliers, which are especially vulnerable due to their position at the\nboundaries of the data domain (e.g., at the minimum and maximum values).\nHowever, the role of data domain extraction in generative models and its impact\non privacy attacks have been overlooked. In this paper, we examine three\nstrategies for defining the data domain: assuming it is externally provided\n(ideally from public data), extracting it directly from the input data, and\nextracting it with DP mechanisms. While common in popular implementations and\nlibraries, we show that the second approach breaks end-to-end DP guarantees and\nleaves models vulnerable. While using a provided domain (if representative) is\npreferable, extracting it with DP can also defend against popular MIAs, even at\nhigh privacy budgets.", "published": "2025-04-11 04:35:24", "link": "http://arxiv.org/abs/2504.08254v2", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "A Piecewise Lyapunov Analysis of Sub-quadratic SGD: Applications to Robust and Quantile Regression", "abstract": "Motivated by robust and quantile regression problems, we investigate the\nstochastic gradient descent (SGD) algorithm for minimizing an objective\nfunction $f$ that is locally strongly convex with a sub--quadratic tail. This\nsetting covers many widely used online statistical methods. We introduce a\nnovel piecewise Lyapunov function that enables us to handle functions $f$ with\nonly first-order differentiability, which includes a wide range of popular loss\nfunctions such as Huber loss. Leveraging our proposed Lyapunov function, we\nderive finite-time moment bounds under general diminishing stepsizes, as well\nas constant stepsizes. We further establish the weak convergence, central limit\ntheorem and bias characterization under constant stepsize, providing the first\ngeometrical convergence result for sub--quadratic SGD. Our results have wide\napplications, especially in online statistical methods. In particular, we\ndiscuss two applications of our results. 1) Online robust regression: We\nconsider a corrupted linear model with sub--exponential covariates and\nheavy--tailed noise. Our analysis provides convergence rates comparable to\nthose for corrupted models with Gaussian covariates and noise. 2) Online\nquantile regression: Importantly, our results relax the common assumption in\nprior work that the conditional density is continuous and provide a more\nfine-grained analysis for the moment bounds.", "published": "2025-04-11 00:20:37", "link": "http://arxiv.org/abs/2504.08178v2", "categories": ["stat.ML", "cs.LG", "math.OC", "math.PR", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Relative-error testing of conjunctions and decision lists", "abstract": "We study the relative-error property testing model for Boolean functions that\nwas recently introduced in the work of Chen et al. (SODA 2025). In\nrelative-error testing, the testing algorithm gets uniform random satisfying\nassignments as well as black-box queries to $f$, and it must accept $f$ with\nhigh probability whenever $f$ has the property that is being tested and reject\nany $f$ that is relative-error far from having the property. Here the\nrelative-error distance from $f$ to a function $g$ is measured with respect to\n$|f^{-1}(1)|$ rather than with respect to the entire domain size $2^n$ as in\nthe Hamming distance measure that is used in the standard model; thus, unlike\nthe standard model, relative-error testing allows us to study the testability\nof sparse Boolean functions that have few satisfying assignments. It was shown\nin Chen et al. (SODA 2025) that relative-error testing is at least as difficult\nas standard-model property testing, but for many natural and important Boolean\nfunction classes the precise relationship between the two notions is unknown.\n  In this paper we consider the well-studied and fundamental properties of\nbeing a conjunction and being a decision list. In the relative-error setting,\nwe give an efficient one-sided error tester for conjunctions with running time\nand query complexity $O(1/\\epsilon)$.\n  Secondly, we give a two-sided relative-error $\\tilde{O}$$(1/\\epsilon)$ tester\nfor decision lists, matching the query complexity of the state-of-the-art\nalgorithm in the standard model Bshouty (RANDOM 2020) and Diakonikolas et al.\n(FOCS 2007).", "published": "2025-04-11 21:40:57", "link": "http://arxiv.org/abs/2504.08987v1", "categories": ["cs.CC", "cs.DM", "cs.DS"], "primary_category": "cs.CC"}
{"title": "RouterKT: Mixture-of-Experts for Knowledge Tracing", "abstract": "Knowledge Tracing (KT) is a fundamental task in Intelligent Tutoring Systems\n(ITS), which aims to model the dynamic knowledge states of students based on\ntheir interaction histories. However, existing KT models often rely on a global\nforgetting decay mechanism for capturing learning patterns, assuming that\nstudents' performance is predominantly influenced by their most recent\ninteractions. Such approaches fail to account for the diverse and complex\nlearning patterns arising from individual differences and varying learning\nstages. To address this limitation, we propose RouterKT, a novel\nMixture-of-Experts (MoE) architecture designed to capture heterogeneous\nlearning patterns by enabling experts to specialize in different patterns\nwithout any handcrafted learning pattern bias such as forgetting decay.\nSpecifically, RouterKT introduces a \\textbf{person-wise routing mechanism} to\neffectively model individual-specific learning behaviors and employs\n\\textbf{multi-heads as experts} to enhance the modeling of complex and diverse\npatterns. Comprehensive experiments on ten benchmark datasets demonstrate that\nRouterKT exhibits significant flexibility and improves the performance of\nvarious KT backbone models, with a maximum average AUC improvement of 3.29\\%\nacross different backbones and datasets, outperforming other state-of-the-art\nmodels. Moreover, RouterKT demonstrates consistently superior inference\nefficiency compared to existing approaches based on handcrafted learning\npattern bias, highlighting its usability for real-world educational\napplications. The source code is available at\nhttps://github.com/derek-liao/RouterKT.git.", "published": "2025-04-11 21:42:08", "link": "http://arxiv.org/abs/2504.08989v1", "categories": ["cs.CY", "cs.IR", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Code-Craft: Hierarchical Graph-Based Code Summarization for Enhanced Context Retrieval", "abstract": "Understanding and navigating large-scale codebases remains a significant\nchallenge in software engineering. Existing methods often treat code as flat\ntext or focus primarily on local structural relationships, limiting their\nability to provide holistic, context-aware information retrieval. We present\nHierarchical Code Graph Summarization (HCGS), a novel approach that constructs\na multi-layered representation of a codebase by generating structured summaries\nin a bottom-up fashion from a code graph. HCGS leverages the Language Server\nProtocol for language-agnostic code analysis and employs a parallel level-based\nalgorithm for efficient summary generation. Through extensive evaluation on\nfive diverse codebases totaling 7,531 functions, HCGS demonstrates significant\nimprovements in code retrieval accuracy, achieving up to 82 percentage relative\nimprovement in top-1 retrieval precision for large codebases like libsignal\n(27.15 percentage points), and perfect Pass@3 scores for smaller repositories.\nThe system's hierarchical approach consistently outperforms traditional\ncode-only retrieval across all metrics, with particularly substantial gains in\nlarger, more complex codebases where understanding function relationships is\ncrucial.", "published": "2025-04-11 20:57:27", "link": "http://arxiv.org/abs/2504.08975v1", "categories": ["cs.SE", "cs.IR"], "primary_category": "cs.SE"}
{"title": "Large Language Model Empowered Recommendation Meets All-domain Continual Pre-Training", "abstract": "Recent research efforts have investigated how to integrate Large Language\nModels (LLMs) into recommendation, capitalizing on their semantic comprehension\nand open-world knowledge for user behavior understanding. These approaches\npredominantly employ supervised fine-tuning on single-domain user interactions\nto adapt LLMs for specific recommendation tasks. However, they typically\nencounter dual challenges: the mismatch between general language\nrepresentations and domain-specific preference patterns, as well as the limited\nadaptability to multi-domain recommendation scenarios. To bridge these gaps, we\nintroduce CPRec -- an All-domain Continual Pre-Training framework for\nRecommendation -- designed to holistically align LLMs with universal user\nbehaviors through the continual pre-training paradigm. Specifically, we first\ndesign a unified prompt template and organize users' multi-domain behaviors\ninto domain-specific behavioral sequences and all-domain mixed behavioral\nsequences that emulate real-world user decision logic. To optimize behavioral\nknowledge infusion, we devise a Warmup-Stable-Annealing learning rate schedule\ntailored for the continual pre-training paradigm in recommendation to\nprogressively enhance the LLM's capability in knowledge adaptation from\nopen-world knowledge to universal recommendation tasks. To evaluate the\neffectiveness of our CPRec, we implement it on a large-scale dataset covering\nseven domains and conduct extensive experiments on five real-world datasets\nfrom two distinct platforms. Experimental results confirm that our continual\npre-training paradigm significantly mitigates the semantic-behavioral\ndiscrepancy and achieves state-of-the-art performance in all recommendation\nscenarios. The source code will be released upon acceptance.", "published": "2025-04-11 20:01:25", "link": "http://arxiv.org/abs/2504.08949v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Perfect Clustering in Nonuniform Hypergraphs", "abstract": "While there has been tremendous activity in the area of statistical network\ninference on graphs, hypergraphs have not enjoyed the same attention, on\naccount of their relative complexity and the lack of tractable statistical\nmodels. We introduce a hyper-edge-centric model for analyzing hypergraphs,\ncalled the interaction hypergraph, which models natural sampling methods for\nhypergraphs in neuroscience and communication networks, and accommodates\ninteractions involving different numbers of entities. We define latent\nembeddings for the interactions in such a network, and analyze their\nestimators. In particular, we show that a spectral estimate of the interaction\nlatent positions can achieve perfect clustering once enough interactions are\nobserved.", "published": "2025-04-11 21:12:48", "link": "http://arxiv.org/abs/2504.08980v1", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH", "05C65, 05C80, 60B20, 62F12"], "primary_category": "stat.ME"}
{"title": "Rethinking Few-Shot Fusion: Granular Ball Priors Enable General-Purpose Deep Image Fusion", "abstract": "In image fusion tasks, due to the lack of real fused images as priors, most\ndeep learning-based fusion methods obtain global weight features from original\nimages in large-scale data pairs to generate images that approximate real fused\nimages. However, unlike previous studies, this paper utilizes Granular Ball\nadaptation to extract features in the brightness space as priors for deep\nnetworks, enabling the fusion network to converge quickly and complete the\nfusion task. This leads to few-shot training for a general image fusion\nnetwork, and based on this, we propose the GBFF fusion method. According to the\ninformation expression division of pixel pairs in the original fused image, we\nclassify pixel pairs with significant performance as the positive domain and\nnon-significant pixel pairs as the boundary domain. We perform split inference\nin the brightness space using Granular Ball adaptation to compute weights for\npixels that express information to varying degrees, generating approximate\nsupervision images that provide priors for the neural network in the structural\nbrightness space. Additionally, the extracted global saliency features also\nadaptively provide priors for setting the loss function weights of each image\nin the network, guiding the network to converge quickly at both global and\npixel levels alongside the supervised images, thereby enhancing the\nexpressiveness of the fused images. Each modality only used 10 pairs of images\nas the training set, completing the fusion task with a limited number of\niterations. Experiments validate the effectiveness of the algorithm and theory,\nand qualitative and quantitative comparisons with SOTA methods show that this\napproach is highly competitive in terms of fusion time and image\nexpressiveness.", "published": "2025-04-11 19:33:06", "link": "http://arxiv.org/abs/2504.08937v1", "categories": ["cs.GR", "cs.CV", "cs.LG", "eess.IV", "stat.ML"], "primary_category": "cs.GR"}
{"title": "Improving the evaluation of samplers on multi-modal targets", "abstract": "Addressing multi-modality constitutes one of the major challenges of\nsampling. In this reflection paper, we advocate for a more systematic\nevaluation of samplers towards two sources of difficulty that are mode\nseparation and dimension. For this, we propose a synthetic experimental setting\nthat we illustrate on a selection of samplers, focusing on the challenging\ncriterion of recovery of the mode relative importance. These evaluations are\ncrucial to diagnose the potential of samplers to handle multi-modality and\ntherefore to drive progress in the field.", "published": "2025-04-11 18:47:16", "link": "http://arxiv.org/abs/2504.08916v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "In almost all shallow analytic neural network optimization landscapes, efficient minimizers have strongly convex neighborhoods", "abstract": "Whether or not a local minimum of a cost function has a strongly convex\nneighborhood greatly influences the asymptotic convergence rate of optimizers.\nIn this article, we rigorously analyze the prevalence of this property for the\nmean squared error induced by shallow, 1-hidden layer neural networks with\nanalytic activation functions when applied to regression problems. The\nparameter space is divided into two domains: the 'efficient domain' (all\nparameters for which the respective realization function cannot be generated by\na network having a smaller number of neurons) and the 'redundant domain' (the\nremaining parameters). In almost all regression problems on the efficient\ndomain the optimization landscape only features local minima that are strongly\nconvex. Formally, we will show that for certain randomly picked regression\nproblems the optimization landscape is almost surely a Morse function on the\nefficient domain. The redundant domain has significantly smaller dimension than\nthe efficient domain and on this domain, potential local minima are never\nisolated.", "published": "2025-04-11 10:43:17", "link": "http://arxiv.org/abs/2504.08867v1", "categories": ["cs.LG", "math.PR", "stat.ML", "60G15, 60G60, 62J02, 62M45, 68T07"], "primary_category": "cs.LG"}
{"title": "Beyond Global Metrics: A Fairness Analysis for Interpretable Voice Disorder Detection Systems", "abstract": "We conducted a comprehensive analysis of an Automatic Voice Disorders\nDetection (AVDD) system using existing voice disorder datasets with available\ndemographic metadata. The study involved analysing system performance across\nvarious demographic groups, particularly focusing on gender and age-based\ncohorts. Performance evaluation was based on multiple metrics, including\nnormalised costs and cross-entropy. We employed calibration techniques trained\nseparately on predefined demographic groups to address group-dependent\nmiscalibration. Analysis revealed significant performance disparities across\ngroups despite strong global metrics. The system showed systematic biases,\nmisclassifying healthy speakers over 55 as having a voice disorder and speakers\nwith disorders aged 14-30 as healthy. Group-specific calibration improved\nposterior probability quality, reducing overconfidence. For young disordered\nspeakers, low severity scores were identified as contributing to poor system\nperformance. For older speakers, age-related voice characteristics and\npotential limitations in the pretrained Hubert model used as feature extractor\nlikely affected results. The study demonstrates that global performance metrics\nare insufficient for evaluating AVDD system performance. Group-specific\nanalysis may unmask problems in system performance which are hidden within\nglobal metrics. Further, group-dependent calibration strategies help mitigate\nbiases, resulting in a more reliable indication of system confidence. These\nfindings emphasize the need for demographic-specific evaluation and calibration\nin voice disorder detection systems, while providing a methodological framework\napplicable to broader biomedical classification tasks where demographic\nmetadata is available.", "published": "2025-04-11 22:17:05", "link": "http://arxiv.org/abs/2504.08997v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Spatial Audio Processing with Large Language Model on Wearable Devices", "abstract": "Integrating spatial context into large language models (LLMs) has the\npotential to revolutionize human-computer interaction, particularly in wearable\ndevices. In this work, we present a novel system architecture that incorporates\nspatial speech understanding into LLMs, enabling contextually aware and\nadaptive applications for wearable technologies. Our approach leverages\nmicrostructure-based spatial sensing to extract precise Direction of Arrival\n(DoA) information using a monaural microphone. To address the lack of existing\ndataset for microstructure-assisted speech recordings, we synthetically create\na dataset called OmniTalk by using the LibriSpeech dataset. This spatial\ninformation is fused with linguistic embeddings from OpenAI's Whisper model,\nallowing each modality to learn complementary contextual representations. The\nfused embeddings are aligned with the input space of LLaMA-3.2 3B model and\nfine-tuned with lightweight adaptation technique LoRA to optimize for on-device\nprocessing. SING supports spatially-aware automatic speech recognition (ASR),\nachieving a mean error of $25.72^\\circ$-a substantial improvement compared to\nthe 88.52$^\\circ$ median error in existing work-with a word error rate (WER) of\n5.3. SING also supports soundscaping, for example, inference how many people\nwere talking and their directions, with up to 5 people and a median DoA error\nof 16$^\\circ$. Our system demonstrates superior performance in spatial speech\nunderstanding while addressing the challenges of power efficiency, privacy, and\nhardware constraints, paving the way for advanced applications in augmented\nreality, accessibility, and immersive experiences.", "published": "2025-04-11 18:19:59", "link": "http://arxiv.org/abs/2504.08907v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Data-Importance-Aware Power Allocation for Adaptive Real-Time Communication in Computer Vision Applications", "abstract": "Life-transformative applications such as immersive extended reality are\nrevolutionizing wireless communications and computer vision (CV). This paper\npresents a novel framework for importance-aware adaptive data transmissions,\ndesigned specifically for real-time CV applications where task-specific\nfidelity is critical. A novel importance-weighted mean square error (IMSE)\nmetric is introduced as a task-oriented measure of reconstruction quality,\nconsidering sub-pixel-level importance (SP-I) and semantic segment-level\nimportance (SS-I) models. To minimize IMSE under total power constraints,\ndata-importance-aware waterfilling approaches are proposed to optimally\nallocate transmission power according to data importance and channel\nconditions, prioritizing sub-streams with high importance. Simulation results\ndemonstrate that the proposed approaches significantly outperform\nmargin-adaptive waterfilling and equal power allocation strategies. The data\npartitioning that combines both SP-I and SS-I models is shown to achieve the\nmost significant improvements, with normalized IMSE gains exceeding $7\\,$dB and\n$10\\,$dB over the baselines at high SNRs ($>10\\,$dB). These substantial gains\nhighlight the potential of the proposed framework to enhance data efficiency\nand robustness in real-time CV applications, especially in bandwidth-limited\nand resource-constrained environments.", "published": "2025-04-11 19:06:32", "link": "http://arxiv.org/abs/2504.08922v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
