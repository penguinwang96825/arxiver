{"title": "Native Language Cognate Effects on Second Language Lexical Choice", "abstract": "We present a computational analysis of cognate effects on the spontaneous\nlinguistic productions of advanced non-native speakers. Introducing a large\ncorpus of highly competent non-native English speakers, and using a set of\ncarefully selected lexical items, we show that the lexical choices of\nnon-natives are affected by cognates in their native language. This effect is\nso powerful that we are able to reconstruct the phylogenetic language tree of\nthe Indo-European language family solely from the frequencies of specific\nlexical items in the English of authors with various native languages. We\nquantitatively analyze non-native lexical choice, highlighting cognate\nfacilitation as one of the important phenomena shaping the language of\nnon-native speakers.", "published": "2018-05-24 10:24:47", "link": "http://arxiv.org/abs/1805.09590v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Letting Emotions Flow: Success Prediction by Modeling the Flow of\n  Emotions in Books", "abstract": "Books have the power to make us feel happiness, sadness, pain, surprise, or\nsorrow. An author's dexterity in the use of these emotions captivates readers\nand makes it difficult for them to put the book down. In this paper, we model\nthe flow of emotions over a book using recurrent neural networks and quantify\nits usefulness in predicting success in books. We obtained the best weighted\nF1-score of 69% for predicting books' success in a multitask setting\n(simultaneously predicting success and genre of books).", "published": "2018-05-24 15:56:08", "link": "http://arxiv.org/abs/1805.09746v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Corpus for Multilingual Document Classification in Eight Languages", "abstract": "Cross-lingual document classification aims at training a document classifier\non resources in one language and transferring it to a different language\nwithout any additional resources. Several approaches have been proposed in the\nliterature and the current best practice is to evaluate them on a subset of the\nReuters Corpus Volume 2. However, this subset covers only few languages\n(English, German, French and Spanish) and almost all published works focus on\nthe the transfer between English and German. In addition, we have observed that\nthe class prior distributions differ significantly between the languages. We\nargue that this complicates the evaluation of the multilinguality. In this\npaper, we propose a new subset of the Reuters corpus with balanced class priors\nfor eight languages. By adding Italian, Russian, Japanese and Chinese, we cover\nlanguages which are very different with respect to syntax, morphology, etc. We\nprovide strong baselines for all language transfer directions using\nmultilingual word and sentence embeddings respectively. Our goal is to offer a\nfreely available framework to evaluate cross-lingual document classification,\nand we hope to foster by these means, research in this important area.", "published": "2018-05-24 10:36:20", "link": "http://arxiv.org/abs/1805.09821v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fast Neural Machine Translation Implementation", "abstract": "This paper describes the submissions to the efficiency track for GPUs at the\nWorkshop for Neural Machine Translation and Generation by members of the\nUniversity of Edinburgh, Adam Mickiewicz University, Tilde and University of\nAlicante. We focus on efficient implementation of the recurrent deep-learning\nmodel as implemented in Amun, the fast inference engine for neural machine\ntranslation. We improve the performance with an efficient mini-batching\nalgorithm, and by fusing the softmax operation with the k-best extraction\nalgorithm. Submissions using Amun were first, second and third fastest in the\nGPU efficiency track.", "published": "2018-05-24 19:33:03", "link": "http://arxiv.org/abs/1805.09863v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robust Distant Supervision Relation Extraction via Deep Reinforcement\n  Learning", "abstract": "Distant supervision has become the standard method for relation extraction.\nHowever, even though it is an efficient method, it does not come at no\ncost---The resulted distantly-supervised training samples are often very noisy.\nTo combat the noise, most of the recent state-of-the-art approaches focus on\nselecting one-best sentence or calculating soft attention weights over the set\nof the sentences of one specific entity pair. However, these methods are\nsuboptimal, and the false positive problem is still a key stumbling bottleneck\nfor the performance. We argue that those incorrectly-labeled candidate\nsentences must be treated with a hard decision, rather than being dealt with\nsoft attention weights. To do this, our paper describes a radical solution---We\nexplore a deep reinforcement learning strategy to generate the false-positive\nindicator, where we automatically recognize false positives for each relation\ntype without any supervised information. Unlike the removal operation in the\nprevious studies, we redistribute them into the negative examples. The\nexperimental results show that the proposed strategy significantly improves the\nperformance of distant supervision comparing to state-of-the-art systems.", "published": "2018-05-24 22:32:55", "link": "http://arxiv.org/abs/1805.09927v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DSGAN: Generative Adversarial Training for Distant Supervision Relation\n  Extraction", "abstract": "Distant supervision can effectively label data for relation extraction, but\nsuffers from the noise labeling problem. Recent works mainly perform soft\nbag-level noise reduction strategies to find the relatively better samples in a\nsentence bag, which is suboptimal compared with making a hard decision of false\npositive samples in sentence level. In this paper, we introduce an adversarial\nlearning framework, which we named DSGAN, to learn a sentence-level\ntrue-positive generator. Inspired by Generative Adversarial Networks, we regard\nthe positive samples generated by the generator as the negative samples to\ntrain the discriminator. The optimal generator is obtained until the\ndiscrimination ability of the discriminator has the greatest decline. We adopt\nthe generator to filter distant supervision training dataset and redistribute\nthe false positive instances into the negative set, in which way to provide a\ncleaned dataset for relation classification. The experimental results show that\nthe proposed strategy significantly improves the performance of distant\nsupervision relation extraction comparing to state-of-the-art systems.", "published": "2018-05-24 22:37:59", "link": "http://arxiv.org/abs/1805.09929v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WSD algorithm based on a new method of vector-word contexts proximity\n  calculation via epsilon-filtration", "abstract": "The problem of word sense disambiguation (WSD) is considered in the article.\nGiven a set of synonyms (synsets) and sentences with these synonyms. It is\nnecessary to select the meaning of the word in the sentence automatically. 1285\nsentences were tagged by experts, namely, one of the dictionary meanings was\nselected by experts for target words. To solve the WSD-problem, an algorithm\nbased on a new method of vector-word contexts proximity calculation is\nproposed. In order to achieve higher accuracy, a preliminary epsilon-filtering\nof words is performed, both in the sentence and in the set of synonyms. An\nextensive program of experiments was carried out. Four algorithms are\nimplemented, including a new algorithm. Experiments have shown that in a number\nof cases the new algorithm shows better results. The developed software and the\ntagged corpus have an open license and are available online. Wiktionary and\nWikisource are used. A brief description of this work can be viewed in slides\n(https://goo.gl/9ak6Gt). Video lecture in Russian on this research is available\nonline (https://youtu.be/-DLmRkepf58).", "published": "2018-05-24 09:04:44", "link": "http://arxiv.org/abs/1805.09559v2", "categories": ["cs.IR", "cs.CL", "68T50", "I.5.3; H.3.1; H.3.3"], "primary_category": "cs.IR"}
{"title": "Filtering and Mining Parallel Data in a Joint Multilingual Space", "abstract": "We learn a joint multilingual sentence embedding and use the distance between\nsentences in different languages to filter noisy parallel data and to mine for\nparallel data in large news collections. We are able to improve a competitive\nbaseline on the WMT'14 English to German task by 0.3 BLEU by filtering out 25%\nof the training data. The same approach is used to mine additional bitexts for\nthe WMT'14 system and to obtain competitive results on the BUCC shared task to\nidentify parallel sentences in comparable corpora. The approach is generic, it\ncan be applied to many language pairs and it is independent of the architecture\nof the machine translation system.", "published": "2018-05-24 13:09:59", "link": "http://arxiv.org/abs/1805.09822v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mining Procedures from Technical Support Documents", "abstract": "Guided troubleshooting is an inherent task in the domain of technical support\nservices. When a customer experiences an issue with the functioning of a\ntechnical service or a product, an expert user helps guide the customer through\na set of steps comprising a troubleshooting procedure. The objective is to\nidentify the source of the problem through a set of diagnostic steps and\nobservations, and arrive at a resolution. Procedures containing these set of\ndiagnostic steps and observations in response to different problems are common\nartifacts in the body of technical support documentation. The ability to use\nmachine learning and linguistics to understand and leverage these procedures\nfor applications like intelligent chatbots or robotic process automation, is\ncrucial. Existing research on question answering or intelligent chatbots does\nnot look within procedures or deep-understand them. In this paper, we outline a\nsystem for mining procedures from technical support documents. We create models\nfor solving important subproblems like extraction of procedures, identifying\ndecision points within procedures, identifying blocks of instructions\ncorresponding to these decision points and mapping instructions within a\ndecision block. We also release a dataset containing our manual annotations on\npublicly available support documents, to promote further research on the\nproblem.", "published": "2018-05-24 16:58:24", "link": "http://arxiv.org/abs/1805.09780v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Baseline Needs More Love: On Simple Word-Embedding-Based Models and\n  Associated Pooling Mechanisms", "abstract": "Many deep learning architectures have been proposed to model the\ncompositionality in text sequences, requiring a substantial number of\nparameters and expensive computations. However, there has not been a rigorous\nevaluation regarding the added value of sophisticated compositional functions.\nIn this paper, we conduct a point-by-point comparative study between Simple\nWord-Embedding-based Models (SWEMs), consisting of parameter-free pooling\noperations, relative to word-embedding-based RNN/CNN models. Surprisingly,\nSWEMs exhibit comparable or even superior performance in the majority of cases\nconsidered. Based upon this understanding, we propose two additional pooling\nstrategies over learned word embeddings: (i) a max-pooling operation for\nimproved interpretability; and (ii) a hierarchical pooling operation, which\npreserves spatial (n-gram) information within text sequences. We present\nexperiments on 17 datasets encompassing three tasks: (i) (long) document\nclassification; (ii) text sequence matching; and (iii) short text tasks,\nincluding classification and tagging. The source code and datasets can be\nobtained from https:// github.com/dinghanshen/SWEM.", "published": "2018-05-24 18:27:21", "link": "http://arxiv.org/abs/1805.09843v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Diffusion Maps for Textual Network Embedding", "abstract": "Textual network embedding leverages rich text information associated with the\nnetwork to learn low-dimensional vectorial representations of vertices. Rather\nthan using typical natural language processing (NLP) approaches, recent\nresearch exploits the relationship of texts on the same edge to graphically\nembed text. However, these models neglect to measure the complete level of\nconnectivity between any two texts in the graph. We present diffusion maps for\ntextual network embedding (DMTE), integrating global structural information of\nthe graph to capture the semantic relatedness between texts, with a\ndiffusion-convolution operation applied on the text inputs. In addition, a new\nobjective function is designed to efficiently preserve the high-order proximity\nusing the graph diffusion. Experimental results show that the proposed approach\noutperforms state-of-the-art methods on the vertex-classification and\nlink-prediction tasks.", "published": "2018-05-24 21:24:14", "link": "http://arxiv.org/abs/1805.09906v2", "categories": ["cs.CL", "cs.SI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual\n  Question Answering", "abstract": "Recently, Visual Question Answering (VQA) has emerged as one of the most\nsignificant tasks in multimodal learning as it requires understanding both\nvisual and textual modalities. Existing methods mainly rely on extracting image\nand question features to learn their joint feature embedding via multimodal\nfusion or attention mechanism. Some recent studies utilize external\nVQA-independent models to detect candidate entities or attributes in images,\nwhich serve as semantic knowledge complementary to the VQA task. However, these\ncandidate entities or attributes might be unrelated to the VQA task and have\nlimited semantic capacities. To better utilize semantic knowledge in images, we\npropose a novel framework to learn visual relation facts for VQA. Specifically,\nwe build up a Relation-VQA (R-VQA) dataset based on the Visual Genome dataset\nvia a semantic similarity module, in which each data consists of an image, a\ncorresponding question, a correct answer and a supporting relation fact. A\nwell-defined relation detector is then adopted to predict visual\nquestion-related relation facts. We further propose a multi-step attention\nmodel composed of visual attention and semantic attention sequentially to\nextract related visual knowledge and semantic knowledge. We conduct\ncomprehensive experiments on the two benchmark datasets, demonstrating that our\nmodel achieves state-of-the-art performance and verifying the benefit of\nconsidering visual relation facts.", "published": "2018-05-24 14:43:30", "link": "http://arxiv.org/abs/1805.09701v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "FastFCA-AS: Joint Diagonalization Based Acceleration of Full-Rank\n  Spatial Covariance Analysis for Separating Any Number of Sources", "abstract": "Here we propose FastFCA-AS, an accelerated algorithm for Full-rank spatial\nCovariance Analysis (FCA), which is a robust audio source separation method\nproposed by Duong et al. [\"Under-determined reverberant audio source separation\nusing a full-rank spatial covariance model,\" IEEE Trans. ASLP, vol. 18, no. 7,\npp. 1830-1840, Sept. 2010]. In the conventional FCA, matrix inversion and\nmatrix multiplication are required at each time-frequency point in each\niteration of an iterative parameter estimation algorithm. This causes a heavy\ncomputational load, thereby rendering the FCA infeasible in many applications.\nTo overcome this drawback, we take a joint diagonalization approach, whereby\nmatrix inversion and matrix multiplication are reduced to mere inversion and\nmultiplication of diagonal entries. This makes the FastFCA-AS significantly\nfaster than the FCA and even applicable to observed data of long duration or a\nsituation with restricted computational resources. Although we have already\nproposed another acceleration of the FCA for two sources, the proposed\nFastFCA-AS is applicable to an arbitrary number of sources. In an experiment\nwith three sources and three microphones, the FastFCA-AS was over 420 times\nfaster than the FCA with a slightly better source separation performance.", "published": "2018-05-24 03:46:20", "link": "http://arxiv.org/abs/1805.09498v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Simulating Multi-channel Wind Noise Based on the Corcos Model", "abstract": "A novel multi-channel artificial wind noise generator based on a fluid\ndynamics model, namely the Corcos model, is proposed. In particular, the model\nis used to approximate the complex coherence function of wind noise signals\nmeasured with closely-spaced microphones in the free-field and for\ntime-invariant wind stream direction and speed. Preliminary experiments focus\non a spatial analysis of recorded wind noise signals and the validation of the\nCorcos model for diverse measurement set-ups. Subsequently, the Corcos model is\nused to synthetically generate wind noise signals exhibiting the desired\ncomplex coherence. The multi-channel generator is designed extending an\nexisting single-channel generator to create N mutually uncorrelated signals,\nwhile the predefined complex coherence function is obtained exploiting an\nalgorithm developed to generate multi-channel non-stationary noise signals\nunder a complex coherence constraint. Temporal, spectral and spatial\ncharacteristics of synthetic signals match with those observed in measured wind\nnoise. The artificial generation overcomes the time-consuming challenge of\ncollecting pure wind noise samples for noise reduction evaluations and provides\nflexibility in the number of generated signals used in the simulations.", "published": "2018-05-24 13:55:43", "link": "http://arxiv.org/abs/1805.09679v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Environmental Sound Classification Based on Multi-temporal Resolution\n  Convolutional Neural Network Combining with Multi-level Features", "abstract": "Motivated by the fact that characteristics of different sound classes are\nhighly diverse in different temporal scales and hierarchical levels, a novel\ndeep convolutional neural network (CNN) architecture is proposed for the\nenvironmental sound classification task. This network architecture takes raw\nwaveforms as input, and a set of separated parallel CNNs are utilized with\ndifferent convolutional filter sizes and strides, in order to learn feature\nrepresentations with multi-temporal resolutions. On the other hand, the\nproposed architecture also aggregates hierarchical features from multi-level\nCNN layers for classification using direct connections between convolutional\nlayers, which is beyond the typical single-level CNN features employed by the\nmajority of previous studies. This network architecture also improves the flow\nof information and avoids vanishing gradient problem. The combination of\nmulti-level features boosts the classification performance significantly.\nComparative experiments are conducted on two datasets: the environmental sound\nclassification dataset (ESC-50), and DCASE 2017 audio scene classification\ndataset. Results demonstrate that the proposed method is highly effective in\nthe classification tasks by employing multi-temporal resolution and multi-level\nfeatures, and it outperforms the previous methods which only account for\nsingle-level features.", "published": "2018-05-24 16:06:54", "link": "http://arxiv.org/abs/1805.09752v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
