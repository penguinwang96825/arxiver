{"title": "Probabilistic Transformer: A Probabilistic Dependency Model for\n  Contextual Word Representation", "abstract": "Syntactic structures used to play a vital role in natural language processing\n(NLP), but since the deep learning revolution, NLP has been gradually dominated\nby neural models that do not consider syntactic structures in their design. One\nvastly successful class of neural models is transformers. When used as an\nencoder, a transformer produces contextual representation of words in the input\nsentence. In this work, we propose a new model of contextual word\nrepresentation, not from a neural perspective, but from a purely syntactic and\nprobabilistic perspective. Specifically, we design a conditional random field\nthat models discrete latent representations of all words in a sentence as well\nas dependency arcs between them; and we use mean field variational inference\nfor approximate inference. Strikingly, we find that the computation graph of\nour model resembles transformers, with correspondences between dependencies and\nself-attention and between distributions over latent representations and\ncontextual embeddings of words. Experiments show that our model performs\ncompetitively to transformers on small to medium sized datasets. We hope that\nour work could help bridge the gap between traditional syntactic and\nprobabilistic approaches and cutting-edge neural approaches to NLP, and inspire\nmore linguistically-principled neural approaches in the future.", "published": "2023-11-26 06:56:02", "link": "http://arxiv.org/abs/2311.15211v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UHGEval: Benchmarking the Hallucination of Chinese Large Language Models\n  via Unconstrained Generation", "abstract": "Large language models (LLMs) have emerged as pivotal contributors in\ncontemporary natural language processing and are increasingly being applied\nacross a diverse range of industries. However, these large-scale probabilistic\nstatistical models cannot currently ensure the requisite quality in\nprofessional content generation. These models often produce hallucinated text,\ncompromising their practical utility in professional contexts. To assess the\nauthentic reliability of LLMs in text generation, numerous initiatives have\ndeveloped benchmark evaluations for hallucination phenomena. Nevertheless,\nthese benchmarks frequently utilize constrained generation techniques due to\ncost and temporal constraints. These techniques encompass the use of directed\nhallucination induction and strategies that deliberately alter authentic text\nto produce hallucinations. These approaches are not congruent with the\nunrestricted text generation demanded by real-world applications. Furthermore,\na well-established Chinese-language dataset dedicated to the evaluation of\nhallucinations in text generation is presently lacking. Consequently, we have\ndeveloped an Unconstrained Hallucination Generation Evaluation (UHGEval)\nbenchmark, designed to compile outputs produced with minimal restrictions by\nLLMs. Concurrently, we have established a comprehensive benchmark evaluation\nframework to aid subsequent researchers in undertaking scalable and\nreproducible experiments. We have also executed extensive experiments,\nevaluating prominent Chinese language models and the GPT series models to\nderive professional performance insights regarding hallucination challenges.", "published": "2023-11-26 13:42:56", "link": "http://arxiv.org/abs/2311.15296v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sibyl: Empowering Empathetic Dialogue Generation in Large Language\n  Models via Sensible and Visionary Commonsense Inference", "abstract": "Recently, there has been a heightened interest in building chatbots based on\nLarge Language Models (LLMs) to emulate human-like qualities in multi-turn\nconversations. Despite having access to commonsense knowledge to better\nunderstand the psychological aspects and causality of dialogue context, even\nthese powerful LLMs struggle to achieve the goals of empathy and emotional\nsupport. Current commonsense knowledge derived from dialogue contexts is\ninherently limited and often fails to adequately anticipate the future course\nof a dialogue. This lack of foresight can mislead LLMs and hinder their ability\nto provide effective support. In response to this challenge, we present an\ninnovative framework named Sensible and Visionary Commonsense Knowledge\n(Sibyl). Designed to concentrate on the immediately succeeding dialogue, this\nparadigm equips LLMs with the capability to uncover the implicit requirements\nof the conversation, aiming to elicit more empathetic responses. Experimental\nresults demonstrate that incorporating our paradigm for acquiring commonsense\nknowledge into LLMs comprehensively enhances the quality of their responses.", "published": "2023-11-26 14:35:23", "link": "http://arxiv.org/abs/2311.15316v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Section Weights for Multi-Label Document Classification", "abstract": "Multi-label document classification is a traditional task in NLP. Compared to\nsingle-label classification, each document can be assigned multiple classes.\nThis problem is crucially important in various domains, such as tagging\nscientific articles. Documents are often structured into several sections such\nas abstract and title. Current approaches treat different sections equally for\nmulti-label classification. We argue that this is not a realistic assumption,\nleading to sub-optimal results. Instead, we propose a new method called\nLearning Section Weights (LSW), leveraging the contribution of each distinct\nsection for multi-label classification. Via multiple feed-forward layers, LSW\nlearns to assign weights to each section of, and incorporate the weights in the\nprediction. We demonstrate our approach on scientific articles. Experimental\nresults on public (arXiv) and private (Elsevier) datasets confirm the\nsuperiority of LSW, compared to state-of-the-art multi-label document\nclassification methods. In particular, LSW achieves a 1.3% improvement in terms\nof macro averaged F1-score while it achieves 1.3% in terms of macro averaged\nrecall on the publicly available arXiv dataset.", "published": "2023-11-26 19:56:19", "link": "http://arxiv.org/abs/2311.15402v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine-Generated Text Detection using Deep Learning", "abstract": "Our research focuses on the crucial challenge of discerning text produced by\nLarge Language Models (LLMs) from human-generated text, which holds\nsignificance for various applications. With ongoing discussions about attaining\na model with such functionality, we present supporting evidence regarding the\nfeasibility of such models. We evaluated our models on multiple datasets,\nincluding Twitter Sentiment, Football Commentary, Project Gutenberg, PubMedQA,\nand SQuAD, confirming the efficacy of the enhanced detection approaches. These\ndatasets were sampled with intricate constraints encompassing every\npossibility, laying the foundation for future research. We evaluate\nGPT-3.5-Turbo against various detectors such as SVM, RoBERTa-base, and\nRoBERTa-large. Based on the research findings, the results predominantly relied\non the sequence length of the sentence.", "published": "2023-11-26 21:16:01", "link": "http://arxiv.org/abs/2311.15425v1", "categories": ["cs.CL", "I.2.7; I.5.4; I.2.6"], "primary_category": "cs.CL"}
{"title": "Learning to Skip for Language Modeling", "abstract": "Overparameterized large-scale language models have impressive generalization\nperformance of in-context few-shot learning. However, most language models\nallocate the same amount of parameters or computation to each token,\ndisregarding the complexity or importance of the input data. We argue that in\nlanguage model pretraining, a variable amount of computation should be assigned\nto different tokens, and this can be efficiently achieved via a simple routing\nmechanism. Different from conventional early stopping techniques where tokens\ncan early exit at only early layers, we propose a more general method that\ndynamically skips the execution of a layer (or module) for any input token with\na binary router. In our extensive evaluation across 24 NLP tasks, we\ndemonstrate that the proposed method can significantly improve the 1-shot\nperformance compared to other competitive baselines only at mild extra cost for\ninference.", "published": "2023-11-26 21:45:53", "link": "http://arxiv.org/abs/2311.15436v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking Large Language Model Volatility", "abstract": "The impact of non-deterministic outputs from Large Language Models (LLMs) is\nnot well examined for financial text understanding tasks. Through a compelling\ncase study on investing in the US equity market via news sentiment analysis, we\nuncover substantial variability in sentence-level sentiment classification\nresults, underscoring the innate volatility of LLM outputs. These uncertainties\ncascade downstream, leading to more significant variations in portfolio\nconstruction and return. While tweaking the temperature parameter in the\nlanguage model decoder presents a potential remedy, it comes at the expense of\nstifled creativity. Similarly, while ensembling multiple outputs mitigates the\neffect of volatile outputs, it demands a notable computational investment. This\nwork furnishes practitioners with invaluable insights for adeptly navigating\nuncertainty in the integration of LLMs into financial decision-making,\nparticularly in scenarios dictated by non-deterministic information.", "published": "2023-11-26 03:54:03", "link": "http://arxiv.org/abs/2311.15180v1", "categories": ["q-fin.TR", "cs.CL"], "primary_category": "q-fin.TR"}
{"title": "LongStory: Coherent, Complete and Length Controlled Long story\n  Generation", "abstract": "A human author can write any length of story without losing coherence. Also,\nthey always bring the story to a proper ending, an ability that current\nlanguage models lack. In this work, we present the LongStory for coherent,\ncomplete, and length-controlled long story generation. LongStory introduces two\nnovel methodologies: (1) the long and short-term contexts weight calibrator\n(CWC) and (2) long story structural positions (LSP). The CWC adjusts weights\nfor long-term context Memory and short-term context Cheating, acknowledging\ntheir distinct roles. The LSP employs discourse tokens to convey the structural\npositions of a long story. Trained on three datasets with varied average story\nlengths, LongStory outperforms other baselines, including the strong story\ngenerator Plotmachine, in coherence, completeness, relevance, and\nrepetitiveness. We also perform zero-shot tests on each dataset to assess the\nmodel's ability to predict outcomes beyond its training data and validate our\nmethodology by comparing its performance with variants of our model.", "published": "2023-11-26 06:24:25", "link": "http://arxiv.org/abs/2311.15208v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Uncertainty-aware Language Modeling for Selective Question Answering", "abstract": "We present an automatic large language model (LLM) conversion approach that\nproduces uncertainty-aware LLMs capable of estimating uncertainty with every\nprediction. Our approach is model- and data-agnostic, is\ncomputationally-efficient, and does not rely on external models or systems. We\nevaluate converted models on the selective question answering setting -- to\nanswer as many questions as possible while maintaining a given accuracy,\nforgoing providing predictions when necessary. As part of our results, we test\nBERT and Llama 2 model variants on the SQuAD extractive QA task and the\nTruthfulQA generative QA task. We show that using the uncertainty estimates\nprovided by our approach to selectively answer questions leads to significantly\nhigher accuracy over directly using model probabilities.", "published": "2023-11-26 22:47:54", "link": "http://arxiv.org/abs/2311.15451v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Models in Law: A Survey", "abstract": "The advent of artificial intelligence (AI) has significantly impacted the\ntraditional judicial industry. Moreover, recently, with the development of\nAI-generated content (AIGC), AI and law have found applications in various\ndomains, including image recognition, automatic text generation, and\ninteractive chat. With the rapid emergence and growing popularity of large\nmodels, it is evident that AI will drive transformation in the traditional\njudicial industry. However, the application of legal large language models\n(LLMs) is still in its nascent stage. Several challenges need to be addressed.\nIn this paper, we aim to provide a comprehensive survey of legal LLMs. We not\nonly conduct an extensive survey of LLMs, but also expose their applications in\nthe judicial system. We first provide an overview of AI technologies in the\nlegal field and showcase the recent research in LLMs. Then, we discuss the\npractical implementation presented by legal LLMs, such as providing legal\nadvice to users and assisting judges during trials. In addition, we explore the\nlimitations of legal LLMs, including data, algorithms, and judicial practice.\nFinally, we summarize practical recommendations and propose future development\ndirections to address these challenges.", "published": "2023-11-26 00:48:12", "link": "http://arxiv.org/abs/2312.03718v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Comparative Analysis of ChatGPT, GPT-4, and Microsoft Bing Chatbots for\n  GRE Test", "abstract": "This research paper presents an analysis of how well three artificial\nintelligence chatbots: Bing, ChatGPT, and GPT-4, perform when answering\nquestions from standardized tests. The Graduate Record Examination is used in\nthis paper as a case study. A total of 137 questions with different forms of\nquantitative reasoning and 157 questions with verbal categories were used to\nassess their capabilities. This paper presents the performance of each chatbot\nacross various skills and styles tested in the exam. The proficiency of these\nchatbots in addressing image-based questions is also explored, and the\nuncertainty level of each chatbot is illustrated. The results show varying\ndegrees of success across the chatbots, where GPT-4 served as the most\nproficient, especially in complex language understanding tasks and image-based\nquestions. Results highlight the ability of these chatbots to pass the GRE with\na high score, which encourages the use of these chatbots in test preparation.\nThe results also show how important it is to ensure that, if the test is\nadministered online, as it was during COVID, the test taker is segregated from\nthese resources for a fair competition on higher education opportunities.", "published": "2023-11-26 05:27:35", "link": "http://arxiv.org/abs/2312.03719v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Negotiating with LLMS: Prompt Hacks, Skill Gaps, and Reasoning Deficits", "abstract": "Large language models LLMs like ChatGPT have reached the 100 Mio user barrier\nin record time and might increasingly enter all areas of our life leading to a\ndiverse set of interactions between those Artificial Intelligence models and\nhumans. While many studies have discussed governance and regulations\ndeductively from first-order principles, few studies provide an inductive,\ndata-driven lens based on observing dialogues between humans and LLMs\nespecially when it comes to non-collaborative, competitive situations that have\nthe potential to pose a serious threat to people. In this work, we conduct a\nuser study engaging over 40 individuals across all age groups in price\nnegotiations with an LLM. We explore how people interact with an LLM,\ninvestigating differences in negotiation outcomes and strategies. Furthermore,\nwe highlight shortcomings of LLMs with respect to their reasoning capabilities\nand, in turn, susceptiveness to prompt hacking, which intends to manipulate the\nLLM to make agreements that are against its instructions or beyond any\nrationality. We also show that the negotiated prices humans manage to achieve\nspan a broad range, which points to a literacy gap in effectively interacting\nwith LLMs.", "published": "2023-11-26 08:44:58", "link": "http://arxiv.org/abs/2312.03720v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring the Robustness of Model-Graded Evaluations and Automated\n  Interpretability", "abstract": "There has been increasing interest in evaluations of language models for a\nvariety of risks and characteristics. Evaluations relying on natural language\nunderstanding for grading can often be performed at scale by using other\nlanguage models. We test the robustness of these model-graded evaluations to\ninjections on different datasets including a new Deception Eval. These\ninjections resemble direct communication between the testee and the evaluator\nto change their grading. We extrapolate that future, more intelligent models\nmight manipulate or cooperate with their evaluation model. We find significant\nsusceptibility to these injections in state-of-the-art commercial models on all\nexamined evaluations. Furthermore, similar injections can be used on automated\ninterpretability frameworks to produce misleading model-written explanations.\nThe results inspire future work and should caution against unqualified trust in\nevaluations and automated interpretability.", "published": "2023-11-26 17:11:55", "link": "http://arxiv.org/abs/2312.03721v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ChatGPT and Beyond: The Generative AI Revolution in Education", "abstract": "The wide adoption and usage of generative artificial intelligence (AI)\nmodels, particularly ChatGPT, has sparked a surge in research exploring their\npotential applications in the educational landscape. This survey examines\nacademic literature published between November, 2022, and July, 2023,\nspecifically targeting high-impact research from Scopus-indexed Q1 and Q2\njournals. This survey delves into the practical applications and implications\nof generative AI models across a diverse range of educational contexts. Through\na comprehensive and rigorous evaluation of recent academic literature, this\nsurvey seeks to illuminate the evolving role of generative AI models,\nparticularly ChatGPT, in education. By shedding light on the potential\nbenefits, challenges, and emerging trends in this dynamic field, the survey\nendeavors to contribute to the understanding of the nexus between artificial\nintelligence and education. The findings of this review will empower educators,\nresearchers, and policymakers to make informed decisions about the integration\nof AI technologies into learning environments.", "published": "2023-11-26 05:34:22", "link": "http://arxiv.org/abs/2311.15198v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and\n  Qualitative Analysis", "abstract": "The application of Machine learning to finance has become a familiar\napproach, even more so in stock market forecasting. The stock market is highly\nvolatile, and huge amounts of data are generated every minute globally. The\nextraction of effective intelligence from this data is of critical importance.\nHowever, a collaboration of numerical stock data with qualitative text data can\nbe a challenging task. In this work, we accomplish this by providing an\nunprecedented, publicly available dataset with technical and fundamental data\nand sentiment that we gathered from news archives, TV news captions, radio\ntranscripts, tweets, daily financial newspapers, etc. The text data entries\nused for sentiment extraction total more than 1.4 Million. The dataset consists\nof daily entries from January 2018 to December 2022 for eight companies\nrepresenting diverse industrial sectors and the Dow Jones Industrial Average\n(DJIA) as a whole. Holistic Fundamental and Technical data is provided training\nready for Model learning and deployment. Most importantly, the data generated\ncould be used for incremental online learning with real-time data points\nretrieved daily since no stagnant data was utilized. All the data was retired\nfrom APIs or self-designed robust information retrieval technologies with\nextremely low latency and zero monetary cost. These adaptable technologies\nfacilitate data extraction for any stock. Moreover, the utilization of\nSpearman's rank correlation over real-time data, linking stock returns with\nsentiment analysis has produced noteworthy results for the DJIA and the eight\nother stocks, achieving accuracy levels surpassing 60%. The dataset is made\navailable at https://github.com/batking24/Huge-Stock-Dataset.", "published": "2023-11-26 07:19:10", "link": "http://arxiv.org/abs/2311.15218v4", "categories": ["cs.CL", "cs.CE", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging AI-derived Data for Carbon Accounting: Information Extraction\n  from Alternative Sources", "abstract": "Carbon accounting is a fundamental building block in our global path to\nemissions reduction and decarbonization, yet many challenges exist in achieving\nreliable and trusted carbon accounting measures. We motivate that carbon\naccounting not only needs to be more data-driven, but also more\nmethodologically sound. We discuss the need for alternative, more diverse data\nsources that can play a significant role on our path to trusted carbon\naccounting procedures and elaborate on not only why, but how Artificial\nIntelligence (AI) in general and Natural Language Processing (NLP) in\nparticular can unlock reasonable access to a treasure trove of alternative data\nsets in light of the recent advances in the field that better enable the\nutilization of unstructured data in this process. We present a case study of\nthe recent developments on real-world data via an NLP-powered analysis using\nOpenAI's GPT API on financial and shipping data. We conclude the paper with a\ndiscussion on how these methods and approaches can be integrated into a broader\nframework for AI-enabled integrative carbon accounting.", "published": "2023-11-26 22:49:41", "link": "http://arxiv.org/abs/2312.03722v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ChatGPT Application In Summarizing An Evolution Of Deep Learning\n  Techniques In Imaging: A Qualitative Study", "abstract": "The pursuit of article or text summarization has captured the attention of\nnatural language processing (NLP) practitioners, presenting itself as a\nformidable challenge. ChatGPT 3.5 exhibits the capacity to condense the content\nof up to 3000 tokens into a single page, aiming to retain pivotal information\nfrom a given text across diverse themes. In a conducted qualitative research\nendeavor, we selected seven scientific articles and employed the publicly\navailable ChatGPT service to generate summaries of these articles.\nSubsequently, we engaged six co-authors of the articles in a survey, presenting\nfive questions to evaluate the quality of the summaries compared to the\noriginal content. The findings revealed that the summaries produced by ChatGPT\neffectively encapsulated the crucial information present in the articles,\npreserving the principal message of each manuscript. Nonetheless, there was a\nslight diminishment in the technical depth of the summaries as opposed to the\noriginal articles. As a result, our conclusion underscores ChatGPT's text\nsummarization capability as a potent tool for extracting essential insights in\na manner more aligned with reporting than purely scientific discourse.", "published": "2023-11-26 23:22:37", "link": "http://arxiv.org/abs/2312.03723v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
