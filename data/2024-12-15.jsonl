{"title": "The AI Black-Scholes: Finance-Informed Neural Network", "abstract": "In the realm of option pricing, existing models are typically classified into\nprinciple-driven methods, such as solving partial differential equations (PDEs)\nthat pricing function satisfies, and data-driven approaches, such as machine\nlearning (ML) techniques that parameterize the pricing function directly. While\nprinciple-driven models offer a rigorous theoretical framework, they often rely\non unrealistic assumptions, such as asset processes adhering to fixed\nstochastic differential equations (SDEs). Moreover, they can become\ncomputationally intensive, particularly in high-dimensional settings when\nanalytical solutions are not available and thus numerical solutions are needed.\nIn contrast, data-driven models excel in capturing market data trends, but they\noften lack alignment with core financial principles, raising concerns about\ninterpretability and predictive accuracy, especially when dealing with limited\nor biased datasets. This work proposes a hybrid approach to address these\nlimitations by integrating the strengths of both principled and data-driven\nmethodologies. Our framework combines the theoretical rigor and\ninterpretability of PDE-based models with the adaptability of machine learning\ntechniques, yielding a more versatile methodology for pricing a broad spectrum\nof options. We validate our approach across different volatility modeling\napproaches-both with constant volatility (Black-Scholes) and stochastic\nvolatility (Heston), demonstrating that our proposed framework,\nFinance-Informed Neural Network (FINN), not only enhances predictive accuracy\nbut also maintains adherence to core financial principles. FINN presents a\npromising tool for practitioners, offering robust performance across a variety\nof market conditions.", "published": "2024-12-15 22:40:40", "link": "http://arxiv.org/abs/2412.12213v1", "categories": ["cs.LG", "q-fin.CP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Simulation of square-root processes made simple: applications to the Heston model", "abstract": "We introduce a simple, efficient and accurate nonnegative preserving\nnumerical scheme for simulating the square-root process. The novel idea is to\nsimulate the integrated square-root process first instead of the square-root\nprocess itself. Numerical experiments on realistic parameter sets, applied for\nthe integrated process and the Heston model, display high precision with a very\nlow number of time steps. As a bonus, our scheme yields the exact limiting\nInverse Gaussian distributions of the integrated square-root process with only\none single time-step in two scenarios: (i) for high mean-reversion and\nvolatility-of-volatility regimes, regardless of maturity; and (ii) for long\nmaturities, independent of the other parameters.", "published": "2024-12-15 17:58:23", "link": "http://arxiv.org/abs/2412.11264v1", "categories": ["q-fin.MF", "q-fin.CP"], "primary_category": "q-fin.MF"}
{"title": "From Votes to Volatility Predicting the Stock Market on Election Day", "abstract": "Stock market forecasting has been a topic of extensive research, aiming to\nprovide investors with optimal stock recommendations for higher returns. In\nrecent years, this field has gained even more attention due to the widespread\nadoption of deep learning models. While these models have achieved impressive\naccuracy in predicting stock behavior, tailoring them to specific scenarios has\nbecome increasingly important. Election Day represents one such critical\nscenario, characterized by intensified market volatility, as the winning\ncandidate's policies significantly impact various economic sectors and\ncompanies. To address this challenge, we propose the Election Day Stock Market\nForecasting (EDSMF) Model. Our approach leverages the contextual capabilities\nof large language models alongside specialized agents designed to analyze the\npolitical and economic consequences of elections. By building on a\nstate-of-the-art architecture, we demonstrate that EDSMF improves the\npredictive performance of the S&P 500 during this uniquely volatile day.", "published": "2024-12-15 13:58:20", "link": "http://arxiv.org/abs/2412.11192v1", "categories": ["q-fin.CP", "cs.AI"], "primary_category": "q-fin.CP"}
{"title": "PolyModel for Hedge Funds' Portfolio Construction Using Machine Learning", "abstract": "The domain of hedge fund investments is undergoing significant\ntransformation, influenced by the rapid expansion of data availability and the\nadvancement of analytical technologies. This study explores the enhancement of\nhedge fund investment performance through the integration of machine learning\ntechniques, the application of PolyModel feature selection, and the analysis of\nfund size. We address three critical questions: (1) the effect of machine\nlearning on trading performance, (2) the role of PolyModel feature selection in\nfund selection and performance, and (3) the comparative reliability of larger\nversus smaller funds.\n  Our findings offer compelling insights. We observe that while machine\nlearning techniques enhance cumulative returns, they also increase annual\nvolatility, indicating variability in performance. PolyModel feature selection\nproves to be a robust strategy, with approaches that utilize a comprehensive\nset of features for fund selection outperforming more selective methodologies.\nNotably, Long-Term Stability (LTS) effectively manages portfolio volatility\nwhile delivering favorable returns. Contrary to popular belief, our results\nsuggest that larger funds do not consistently yield better investment outcomes,\nchallenging the assumption of their inherent reliability.\n  This research highlights the transformative impact of data-driven approaches\nin the hedge fund investment arena and provides valuable implications for\ninvestors and asset managers. By leveraging machine learning and PolyModel\nfeature selection, investors can enhance portfolio optimization and reassess\nthe dependability of larger funds, leading to more informed investment\nstrategies.", "published": "2024-12-15 02:22:27", "link": "http://arxiv.org/abs/2412.11019v1", "categories": ["q-fin.ST", "q-fin.PM"], "primary_category": "q-fin.ST"}
{"title": "Decoding OTC Government Bond Market Liquidity: An ABM Model for Market Dynamics", "abstract": "The over-the-counter (OTC) government bond markets are characterised by their\nbilateral trading structures, which pose unique challenges to understanding and\nensuring market stability and liquidity. In this paper, we develop a bespoke\nABM that simulates market-maker interactions within a stylised government bond\nmarket. The model focuses on the dynamics of liquidity and stability in the\nsecondary trading of government bonds, particularly in concentrated markets\nlike those found in Australia and the UK. Through this simulation, we test key\nhypotheses around improving market stability, focusing on the effects of agent\ndiversity, business costs, and client base size. We demonstrate that greater\nagent diversity enhances market liquidity and that reducing the costs of\nmarket-making can improve overall market stability. The model offers insights\ninto computational finance by simulating trading without price transparency,\nhighlighting how micro-structural elements can affect macro-level market\noutcomes. This research contributes to the evolving field of computational\nfinance by employing computational intelligence techniques to better understand\nthe fundamental mechanics of government bond markets, providing actionable\ninsights for both academics and practitioners.", "published": "2024-12-15 11:22:25", "link": "http://arxiv.org/abs/2501.16331v1", "categories": ["q-fin.TR", "cs.AI"], "primary_category": "q-fin.TR"}
{"title": "Separate the Wheat from the Chaff: A Post-Hoc Approach to Safety\n  Re-Alignment for Fine-Tuned Language Models", "abstract": "Although large language models (LLMs) achieve effective safety alignment at\nthe time of release, they still face various safety challenges. A key issue is\nthat fine-tuning often compromises the safety alignment of LLMs. To address\nthis issue, we propose a method named IRR (Identify, Remove, and Recalibrate\nfor Safety Realignment) that performs safety realignment for LLMs. The core of\nIRR is to identify and remove unsafe delta parameters from the fine-tuned\nmodels, while recalibrating the retained ones. We evaluate the effectiveness of\nIRR across various datasets, including both full fine-tuning and LoRA methods.\nOur results demonstrate that IRR significantly enhances the safety performance\nof fine-tuned models on safety benchmarks, such as harmful queries and\njailbreak attacks, while maintaining their performance on downstream tasks. The\nsource code is available at: https://anonymous.4open.science/r/IRR-BD4F.", "published": "2024-12-15 03:58:38", "link": "http://arxiv.org/abs/2412.11041v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Superalignment of Superhuman Intelligence with Large Language Models", "abstract": "We have witnessed superhuman intelligence thanks to the fast development of\nlarge language models and multimodal language models. As the application of\nsuch superhuman models becomes more and more popular, a critical question\narises here: how can we ensure superhuman models are still safe, reliable and\naligned well to human values? In this position paper, we discuss the concept of\nsuperalignment from the learning perspective to answer this question by\noutlining the learning paradigm shift from large-scale pretraining, supervised\nfine-tuning, to alignment training. We define superalignment as designing\neffective and efficient alignment algorithms to learn from noisy-labeled data\n(point-wise samples or pair-wise preference data) in a scalable way when the\ntask becomes very complex for human experts to annotate and the model is\nstronger than human experts. We highlight some key research problems in\nsuperalignment, namely, weak-to-strong generalization, scalable oversight, and\nevaluation. We then present a conceptual framework for superalignment, which\nconsists of three modules: an attacker which generates adversary queries trying\nto expose the weaknesses of a learner model; a learner which will refine itself\nby learning from scalable feedbacks generated by a critic model along with\nminimal human experts; and a critic which generates critics or explanations for\na given query-response pair, with a target of improving the learner by\ncriticizing. We discuss some important research problems in each component of\nthis framework and highlight some interesting research ideas that are closely\nrelated to our proposed framework, for instance, self-alignment, self-play,\nself-refinement, and more. Last, we highlight some future research directions\nfor superalignment, including identification of new emergent risks and\nmulti-dimensional alignment.", "published": "2024-12-15 10:34:06", "link": "http://arxiv.org/abs/2412.11145v2", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Cultural Palette: Pluralising Culture Alignment via Multi-agent Palette", "abstract": "Large language models (LLMs) face challenges in aligning with diverse\ncultural values despite their remarkable performance in generation, which stems\nfrom inherent monocultural biases and difficulties in capturing nuanced\ncultural semantics. Existing methods struggle to adapt to unkown culture after\nfine-tuning. Inspired by cultural geography across five continents, we propose\nCultural Palette, a multi-agent framework that redefines cultural alignment as\nan adaptive \"color-blending\" process for country-specific adaptation. Our\napproach harnesses cultural geography across five continents (Africa, America,\nAsia, Europe, Oceania) through three key steps: First, we synthesize the\nPentachromatic Cultural Palette Dataset using GPT-4o, refining\ncontinental-level dialogues with Hofstede cultural dimensions to establish\nfoundational cultural representations. Second, five continent-level alignment\nagents form specialized cultural communities that generate region-specific\ndraft responses. Third, a Meta Agent employs Cultural MoErges to dynamically\nblend these cultural \"colors\" through attention-gated parameter merging, akin\nto mixing pigments on a palette, resolving conflicts while preserving cultural\nnuances to produce the final culturally-aligned response. Extensive experiments\nacross various countries demonstrate that Cultural Palette surpasses existing\nbaselines in cultural alignment.", "published": "2024-12-15 12:30:52", "link": "http://arxiv.org/abs/2412.11167v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unpacking the Resilience of SNLI Contradiction Examples to Attacks", "abstract": "Pre-trained models excel on NLI benchmarks like SNLI and MultiNLI, but their\ntrue language understanding remains uncertain. Models trained only on\nhypotheses and labels achieve high accuracy, indicating reliance on dataset\nbiases and spurious correlations. To explore this issue, we applied the\nUniversal Adversarial Attack to examine the model's vulnerabilities. Our\nanalysis revealed substantial drops in accuracy for the entailment and neutral\nclasses, whereas the contradiction class exhibited a smaller decline.\nFine-tuning the model on an augmented dataset with adversarial examples\nrestored its performance to near-baseline levels for both the standard and\nchallenge sets. Our findings highlight the value of adversarial triggers in\nidentifying spurious correlations and improving robustness while providing\ninsights into the resilience of the contradiction class to adversarial attacks.", "published": "2024-12-15 12:47:28", "link": "http://arxiv.org/abs/2412.11172v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Smaller Language Models Are Better Instruction Evolvers", "abstract": "Instruction tuning has been widely used to unleash the complete potential of\nlarge language models. Notably, complex and diverse instructions are of\nsignificant importance as they can effectively align models with various\ndownstream tasks. However, current approaches to constructing large-scale\ninstructions predominantly favour powerful models such as GPT-4 or those with\nover 70 billion parameters, under the empirical presumption that such larger\nlanguage models (LLMs) inherently possess enhanced capabilities. In this study,\nwe question this prevalent assumption and conduct an in-depth exploration into\nthe potential of smaller language models (SLMs) in the context of instruction\nevolution. Extensive experiments across three scenarios of instruction\nevolution reveal that smaller language models (SLMs) can synthesize more\neffective instructions than LLMs. Further analysis demonstrates that SLMs\npossess a broader output space during instruction evolution, resulting in more\ncomplex and diverse variants. We also observe that the existing metrics fail to\nfocus on the impact of the instructions. Thus, we propose Instruction\nComplex-Aware IFD (IC-IFD), which introduces instruction complexity in the\noriginal IFD score to evaluate the effectiveness of instruction data more\naccurately. Our source code is available at:\n\\href{https://github.com/HypherX/Evolution-Analysis}{https://github.com/HypherX/Evolution-Analysis}", "published": "2024-12-15 16:07:48", "link": "http://arxiv.org/abs/2412.11231v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reliable, Reproducible, and Really Fast Leaderboards with Evalica", "abstract": "The rapid advancement of natural language processing (NLP) technologies, such\nas instruction-tuned large language models (LLMs), urges the development of\nmodern evaluation protocols with human and machine feedback. We introduce\nEvalica, an open-source toolkit that facilitates the creation of reliable and\nreproducible model leaderboards. This paper presents its design, evaluates its\nperformance, and demonstrates its usability through its Web interface,\ncommand-line interface, and Python API.", "published": "2024-12-15 21:22:46", "link": "http://arxiv.org/abs/2412.11314v1", "categories": ["cs.CL", "62-04", "D.2.3"], "primary_category": "cs.CL"}
{"title": "RoLargeSum: A Large Dialect-Aware Romanian News Dataset for Summary,\n  Headline, and Keyword Generation", "abstract": "Using supervised automatic summarisation methods requires sufficient corpora\nthat include pairs of documents and their summaries. Similarly to many tasks in\nnatural language processing, most of the datasets available for summarization\nare in English, posing challenges for developing summarization models in other\nlanguages. Thus, in this work, we introduce RoLargeSum, a novel large-scale\nsummarization dataset for the Romanian language crawled from various publicly\navailable news websites from Romania and the Republic of Moldova that were\nthoroughly cleaned to ensure a high-quality standard. RoLargeSum contains more\nthan 615K news articles, together with their summaries, as well as their\nheadlines, keywords, dialect, and other metadata that we found on the targeted\nwebsites. We further evaluated the performance of several BART variants and\nopen-source large language models on RoLargeSum for benchmarking purposes. We\nmanually evaluated the results of the best-performing system to gain insight\ninto the potential pitfalls of this data set and future development.", "published": "2024-12-15 21:27:33", "link": "http://arxiv.org/abs/2412.11317v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RIRO: Reshaping Inputs, Refining Outputs Unlocking the Potential of\n  Large Language Models in Data-Scarce Contexts", "abstract": "Large language models (LLMs) have significantly advanced natural language\nprocessing, excelling in areas like text generation, summarization, and\nquestion-answering. Despite their capabilities, these models face challenges\nwhen fine-tuned on small, domain-specific datasets, often struggling to\ngeneralize and deliver accurate results with unfamiliar inputs. To tackle this\nissue, we introduce RIRO, a novel two-layer architecture designed to improve\nperformance in data-scarce environments. The first layer leverages advanced\nprompt engineering to reformulate inputs, ensuring better alignment with\ntraining data, while the second layer focuses on refining outputs to minimize\ninconsistencies. Through fine-tuning models like Phi-2, Falcon 7B, and Falcon\n1B, with Phi-2 outperforming the others. Additionally, we introduce a benchmark\nusing evaluation metrics such as cosine similarity, Levenshtein distance, BLEU\nscore, ROUGE-1, ROUGE-2, and ROUGE-L. While these advancements improve\nperformance, challenges like computational demands and overfitting persist,\nlimiting the potential of LLMs in data-scarce, high-stakes environments such as\nhealthcare, legal documentation, and software testing.", "published": "2024-12-15 15:48:37", "link": "http://arxiv.org/abs/2412.15254v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entropy-Regularized Process Reward Model", "abstract": "Large language models (LLMs) have shown promise in performing complex\nmulti-step reasoning, yet they continue to struggle with mathematical\nreasoning, often making systematic errors. A promising solution is\nreinforcement learning (RL) guided by reward models, particularly those\nfocusing on process rewards, which score each intermediate step rather than\nsolely evaluating the final outcome. This approach is more effective at guiding\npolicy models towards correct reasoning trajectories. In this work, we propose\nan entropy-regularized process reward model (ER-PRM) that integrates\nKL-regularized Markov Decision Processes (MDP) to balance policy optimization\nwith the need to prevent the policy from shifting too far from its initial\ndistribution. We derive a novel reward construction method based on the\ntheoretical results. Our theoretical analysis shows that we could derive the\noptimal reward model from the initial policy sampling. Our empirical\nexperiments on the MATH and GSM8K benchmarks demonstrate that ER-PRM\nconsistently outperforms existing process reward models, achieving 1%\nimprovement on GSM8K and 2-3% improvement on MATH under best-of-N evaluation,\nand more than 1% improvement under RLHF. These results highlight the efficacy\nof entropy-regularization in enhancing LLMs' reasoning capabilities.", "published": "2024-12-15 01:09:23", "link": "http://arxiv.org/abs/2412.11006v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Contextualized BERT model for Knowledge Graph Completion", "abstract": "Knowledge graphs (KGs) are valuable for representing structured,\ninterconnected information across domains, enabling tasks like semantic search,\nrecommendation systems and inference. A pertinent challenge with KGs, however,\nis that many entities (i.e., heads, tails) or relationships are unknown.\nKnowledge Graph Completion (KGC) addresses this by predicting these missing\nnodes or links, enhancing the graph's informational depth and utility.\nTraditional methods like TransE and ComplEx predict tail entities but struggle\nwith unseen entities. Textual-based models leverage additional semantics but\ncome with high computational costs, semantic inconsistencies, and data\nimbalance issues. Recent LLM-based models show improvement but overlook\ncontextual information and rely heavily on entity descriptions. In this study,\nwe introduce a contextualized BERT model for KGC that overcomes these\nlimitations by utilizing the contextual information from neighbouring entities\nand relationships to predict tail entities. Our model eliminates the need for\nentity descriptions and negative triplet sampling, reducing computational\ndemands while improving performance. Our model outperforms state-of-the-art\nmethods on standard datasets, improving Hit@1 by 5.3% and 4.88% on FB15k-237\nand WN18RR respectively, setting a new benchmark in KGC.", "published": "2024-12-15 02:03:16", "link": "http://arxiv.org/abs/2412.11016v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NITRO: LLM Inference on Intel Laptop NPUs", "abstract": "Large Language Models (LLMs) have become essential tools in natural language\nprocessing, finding large usage in chatbots such as ChatGPT and Gemini, and are\na central area of research. A particular area of interest includes designing\nhardware specialized for these AI applications, with one such example being the\nneural processing unit (NPU). In 2023, Intel released the Intel Core Ultra\nprocessor with codename Meteor Lake, featuring a CPU, GPU, and NPU\nsystem-on-chip. However, official software support for the NPU through Intel's\nOpenVINO framework is limited to static model inference. The dynamic nature of\nautoregressive token generation in LLMs is therefore not supported out of the\nbox. To address this shortcoming, we present NITRO (NPU Inference for\nTransformers Optimization), a Python-based framework built on top of OpenVINO\nto support text and chat generation on NPUs. In this paper, we discuss in\ndetail the key modifications made to the transformer architecture to enable\ninference, some performance benchmarks, and future steps towards improving the\npackage. The code repository for NITRO can be found here:\nhttps://github.com/abdelfattah-lab/nitro.", "published": "2024-12-15 05:15:54", "link": "http://arxiv.org/abs/2412.11053v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Feature engineering vs. deep learning for paper section identification:\n  Toward applications in Chinese medical literature", "abstract": "Section identification is an important task for library science, especially\nknowledge management. Identifying the sections of a paper would help filter\nnoise in entity and relation extraction. In this research, we studied the paper\nsection identification problem in the context of Chinese medical literature\nanalysis, where the subjects, methods, and results are more valuable from a\nphysician's perspective. Based on previous studies on English literature\nsection identification, we experiment with the effective features to use with\nclassic machine learning algorithms to tackle the problem. It is found that\nConditional Random Fields, which consider sentence interdependency, is more\neffective in combining different feature sets, such as bag-of-words,\npart-of-speech, and headings, for Chinese literature section identification.\nMoreover, we find that classic machine learning algorithms are more effective\nthan generic deep learning models for this problem. Based on these\nobservations, we design a novel deep learning model, the Structural\nBidirectional Long Short-Term Memory (SLSTM) model, which models word and\nsentence interdependency together with the contextual information. Experiments\non a human-curated asthma literature dataset show that our approach outperforms\nthe traditional machine learning methods and other deep learning methods and\nachieves close to 90% precision and recall in the task. The model shows good\npotential for use in other text mining tasks. The research has significant\nmethodological and practical implications.", "published": "2024-12-15 09:11:14", "link": "http://arxiv.org/abs/2412.11125v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection", "abstract": "Anomaly detection (AD) is an important machine learning task with many\nreal-world uses, including fraud detection, medical diagnosis, and industrial\nmonitoring. Within natural language processing (NLP), AD helps detect issues\nlike spam, misinformation, and unusual user activity. Although large language\nmodels (LLMs) have had a strong impact on tasks such as text generation and\nsummarization, their potential in AD has not been studied enough. This paper\nintroduces AD-LLM, the first benchmark that evaluates how LLMs can help with\nNLP anomaly detection. We examine three key tasks: (i) zero-shot detection,\nusing LLMs' pre-trained knowledge to perform AD without tasks-specific\ntraining; (ii) data augmentation, generating synthetic data and category\ndescriptions to improve AD models; and (iii) model selection, using LLMs to\nsuggest unsupervised AD models. Through experiments with different datasets, we\nfind that LLMs can work well in zero-shot AD, that carefully designed\naugmentation methods are useful, and that explaining model selection for\nspecific datasets remains challenging. Based on these results, we outline six\nfuture research directions on LLMs for AD.", "published": "2024-12-15 10:22:14", "link": "http://arxiv.org/abs/2412.11142v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Large Language Models for Active Merchant Non-player\n  Characters", "abstract": "We highlight two significant issues leading to the passivity of current\nmerchant non-player characters (NPCs): pricing and communication. While\nimmersive interactions have been a focus, negotiations between merchant NPCs\nand players on item prices have not received sufficient attention. First, we\ndefine passive pricing as the limited ability of merchants to modify predefined\nitem prices. Second, passive communication means that merchants can only\ninteract with players in a scripted manner. To tackle these issues and create\nan active merchant NPC, we propose a merchant framework based on large language\nmodels (LLMs), called MART, which consists of an appraiser module and a\nnegotiator module. We conducted two experiments to guide game developers in\nselecting appropriate implementations by comparing different training methods\nand LLM sizes. Our findings indicate that finetuning methods, such as\nsupervised finetuning (SFT) and knowledge distillation (KD), are effective in\nusing smaller LLMs to implement active merchant NPCs. Additionally, we found\nthree irregular cases arising from the responses of LLMs. We expect our\nfindings to guide developers in using LLMs for developing active merchant NPCs.", "published": "2024-12-15 13:48:39", "link": "http://arxiv.org/abs/2412.11189v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Drawing the Line: Enhancing Trustworthiness of MLLMs Through the Power\n  of Refusal", "abstract": "Multimodal large language models (MLLMs) excel at multimodal perception and\nunderstanding, yet their tendency to generate hallucinated or inaccurate\nresponses undermines their trustworthiness. Existing methods have largely\noverlooked the importance of refusal responses as a means of enhancing MLLMs\nreliability. To bridge this gap, we present the Information Boundary-aware\nLearning Framework (InBoL), a novel approach that empowers MLLMs to refuse to\nanswer user queries when encountering insufficient information. To the best of\nour knowledge, InBoL is the first framework that systematically defines the\nconditions under which refusal is appropriate for MLLMs using the concept of\ninformation boundaries proposed in our paper. This framework introduces a\ncomprehensive data generation pipeline and tailored training strategies to\nimprove the model's ability to deliver appropriate refusal responses. To\nevaluate the trustworthiness of MLLMs, we further propose a user-centric\nalignment goal along with corresponding metrics. Experimental results\ndemonstrate a significant improvement in refusal accuracy without noticeably\ncompromising the model's helpfulness, establishing InBoL as a pivotal\nadvancement in building more trustworthy MLLMs.", "published": "2024-12-15 14:17:14", "link": "http://arxiv.org/abs/2412.11196v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Beyond Discrete Personas: Personality Modeling Through Journal Intensive\n  Conversations", "abstract": "Large Language Models (LLMs) have significantly improved personalized\nconversational capabilities. However, existing datasets like Persona Chat,\nSynthetic Persona Chat, and Blended Skill Talk rely on static, predefined\npersonas. This approach often results in dialogues that fail to capture human\npersonalities' fluid and evolving nature. To overcome these limitations, we\nintroduce a novel dataset with around 400,000 dialogues and a framework for\ngenerating personalized conversations using long-form journal entries from\nReddit. Our approach clusters journal entries for each author and filters them\nby selecting the most representative cluster, ensuring that the retained\nentries best reflect the author's personality. We further refine the data by\ncapturing the Big Five personality traits --openness, conscientiousness,\nextraversion, agreeableness, and neuroticism --ensuring that dialogues\nauthentically reflect an individual's personality. Using Llama 3 70B, we\ngenerate high-quality, personality-rich dialogues grounded in these journal\nentries. Fine-tuning models on this dataset leads to an 11% improvement in\ncapturing personality traits on average, outperforming existing approaches in\ngenerating more coherent and personality-driven dialogues.", "published": "2024-12-15 17:16:08", "link": "http://arxiv.org/abs/2412.11250v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CATER: Leveraging LLM to Pioneer a Multidimensional,\n  Reference-Independent Paradigm in Translation Quality Evaluation", "abstract": "This paper introduces the Comprehensive AI-assisted Translation Edit Ratio\n(CATER), a novel and fully prompt-driven framework for evaluating machine\ntranslation (MT) quality. Leveraging large language models (LLMs) via a\ncarefully designed prompt-based protocol, CATER expands beyond traditional\nreference-bound metrics, offering a multidimensional, reference-independent\nevaluation that addresses linguistic accuracy, semantic fidelity, contextual\ncoherence, stylistic appropriateness, and information completeness. CATER's\nunique advantage lies in its immediate implementability: by providing the\nsource and target texts along with a standardized prompt, an LLM can rapidly\nidentify errors, quantify edit effort, and produce category-level and overall\nscores. This approach eliminates the need for pre-computed references or\ndomain-specific resources, enabling instant adaptation to diverse languages,\ngenres, and user priorities through adjustable weights and prompt\nmodifications. CATER's LLM-enabled strategy supports more nuanced assessments,\ncapturing phenomena such as subtle omissions, hallucinations, and\ndiscourse-level shifts that increasingly challenge contemporary MT systems. By\nuniting the conceptual rigor of frameworks like MQM and DQF with the\nscalability and flexibility of LLM-based evaluation, CATER emerges as a\nvaluable tool for researchers, developers, and professional translators\nworldwide. The framework and example prompts are openly available, encouraging\ncommunity-driven refinement and further empirical validation.", "published": "2024-12-15 17:45:34", "link": "http://arxiv.org/abs/2412.11261v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Sequence-Level Leakage Risk of Training Data in Large Language Models", "abstract": "This work performs an analysis of sequence-level probabilities for\nquantifying the of risk training data extraction from Large Language Models\n(LLMs). Per-sequence extraction probabilities provide finer-grained information\nthan has been studied in prior work. We re-analyze the effects of decoding\nschemes, model sizes, prefix lengths, partial sequence leakages, and token\npositions to uncover new insights that were not possible in previous works due\nto their choice of metrics. We perform this study on two pre-trained models,\nLlama and OPT, trained on the Common Crawl and The Pile respectively. We\ndiscover that 1) Extraction Rate, the predominant metric used in prior\nquantification work, underestimates the threat of leakage of training data in\nrandomized LLMs by as much as 2.14X. 2) Although on average, larger models and\nlonger prefixes can extract more data, this is not true for a substantial\nportion of individual sequences. 30.4-41.5% of our sequences are easier to\nextract with either shorter prefixes or smaller models. 3) Contrary to previous\nbeliefs, partial leakage in commonly used decoding schemes like top-k and top-p\nis not easier than leaking verbatim training data. 4) Extracting later tokens\nin a sequence is as much as 10.12X easier than extracting earlier tokens. The\ninsights gained from our analysis shed light on the nature of memorization of\ntraining data on a per-sequence basis.", "published": "2024-12-15 20:27:45", "link": "http://arxiv.org/abs/2412.11302v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generics are puzzling. Can language models find the missing piece?", "abstract": "Generic sentences express generalisations about the world without explicit\nquantification. Although generics are central to everyday communication,\nbuilding a precise semantic framework has proven difficult, in part because\nspeakers use generics to generalise properties with widely different\nstatistical prevalence. In this work, we study the implicit quantification and\ncontext-sensitivity of generics by leveraging language models as models of\nlanguage. We create ConGen, a dataset of 2873 naturally occurring generic and\nquantified sentences in context, and define p-acceptability, a metric based on\nsurprisal that is sensitive to quantification. Our experiments show generics\nare more context-sensitive than determiner quantifiers and about 20% of\nnaturally occurring generics we analyze express weak generalisations. We also\nexplore how human biases in stereotypes can be observed in language models.", "published": "2024-12-15 21:30:21", "link": "http://arxiv.org/abs/2412.11318v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Segment-Level Diffusion: A Framework for Controllable Long-Form\n  Generation with Diffusion Language Models", "abstract": "Diffusion models have shown promise in text generation but often struggle\nwith generating long, coherent, and contextually accurate text. Token-level\ndiffusion overlooks word-order dependencies and enforces short output windows,\nwhile passage-level diffusion struggles with learning robust representation for\nlong-form text. To address these challenges, we propose Segment-Level Diffusion\n(SLD), a framework that enhances diffusion-based text generation through text\nsegmentation, robust representation training with adversarial and contrastive\nlearning, and improved latent-space guidance. By segmenting long-form outputs\ninto separate latent representations and decoding them with an autoregressive\ndecoder, SLD simplifies diffusion predictions and improves scalability.\nExperiments on XSum, ROCStories, DialogSum, and DeliData demonstrate that SLD\nachieves competitive or superior performance in fluency, coherence, and\ncontextual compatibility across automatic and human evaluation metrics\ncomparing with other diffusion and autoregressive baselines. Ablation studies\nfurther validate the effectiveness of our segmentation and representation\nlearning strategies.", "published": "2024-12-15 22:47:44", "link": "http://arxiv.org/abs/2412.11333v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AgentPS: Agentic Process Supervision for Multi-modal Content Quality\n  Assurance through Multi-round QA", "abstract": "The advanced processing and reasoning capabilities of multimodal large\nlanguage models (MLLMs) have driven substantial progress in vision-language\n(VL) understanding tasks. However, while effective for tasks governed by\nstraightforward logic, MLLMs often encounter challenges when reasoning over\ncomplex, interdependent logic structures. To address this limitation, we\nintroduce \\textit{AgentPS}, a novel framework that integrates Agentic Process\nSupervision into MLLMs via multi-round question answering during fine-tuning.\n\\textit{AgentPS} demonstrates significant performance improvements over\nbaseline MLLMs on proprietary TikTok datasets, due to its integration of\nprocess supervision and structured sequential reasoning. Furthermore, we show\nthat replacing human-annotated labels with LLM-generated labels retains much of\nthe performance gain, highlighting the framework's practical scalability in\nindustrial applications. These results position \\textit{AgentPS} as a highly\neffective and efficient architecture for multimodal classification tasks. Its\nadaptability and scalability, especially when enhanced by automated annotation\ngeneration, make it a powerful tool for handling large-scale, real-world\nchallenges.", "published": "2024-12-15 04:58:00", "link": "http://arxiv.org/abs/2412.15251v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NER- RoBERTa: Fine-Tuning RoBERTa for Named Entity Recognition (NER)\n  within low-resource languages", "abstract": "Nowadays, Natural Language Processing (NLP) is an important tool for most\npeople's daily life routines, ranging from understanding speech, translation,\nnamed entity recognition (NER), and text categorization, to generative text\nmodels such as ChatGPT. Due to the existence of big data and consequently large\ncorpora for widely used languages like English, Spanish, Turkish, Persian, and\nmany more, these applications have been developed accurately. However, the\nKurdish language still requires more corpora and large datasets to be included\nin NLP applications. This is because Kurdish has a rich linguistic structure,\nvaried dialects, and a limited dataset, which poses unique challenges for\nKurdish NLP (KNLP) application development. While several studies have been\nconducted in KNLP for various applications, Kurdish NER (KNER) remains a\nchallenge for many KNLP tasks, including text analysis and classification. In\nthis work, we address this limitation by proposing a methodology for\nfine-tuning the pre-trained RoBERTa model for KNER. To this end, we first\ncreate a Kurdish corpus, followed by designing a modified model architecture\nand implementing the training procedures. To evaluate the trained model, a set\nof experiments is conducted to demonstrate the performance of the KNER model\nusing different tokenization methods and trained models. The experimental\nresults show that fine-tuned RoBERTa with the SentencePiece tokenization method\nsubstantially improves KNER performance, achieving a 12.8% improvement in\nF1-score compared to traditional models, and consequently establishes a new\nbenchmark for KNLP.", "published": "2024-12-15 07:07:17", "link": "http://arxiv.org/abs/2412.15252v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Using Machine Learning to Distinguish Human-written from\n  Machine-generated Creative Fiction", "abstract": "Following the universal availability of generative AI systems with the\nrelease of ChatGPT, automatic detection of deceptive text created by Large\nLanguage Models has focused on domains such as academic plagiarism and \"fake\nnews\". However, generative AI also poses a threat to the livelihood of creative\nwriters, and perhaps to literary culture in general, through reduction in\nquality of published material. Training a Large Language Model on writers'\noutput to generate \"sham books\" in a particular style seems to constitute a new\nform of plagiarism. This problem has been little researched. In this study, we\ntrained Machine Learning classifier models to distinguish short samples of\nhuman-written from machine-generated creative fiction, focusing on classic\ndetective novels. Our results show that a Naive Bayes and a Multi-Layer\nPerceptron classifier achieved a high degree of success (accuracy > 95%),\nsignificantly outperforming human judges (accuracy < 55%). This approach worked\nwell with short text samples (around 100 words), which previous research has\nshown to be difficult to classify. We have deployed an online proof-of-concept\nclassifier tool, AI Detective, as a first step towards developing lightweight\nand reliable applications for use by editors and publishers, with the aim of\nprotecting the economic and cultural contribution of human authors.", "published": "2024-12-15 12:46:57", "link": "http://arxiv.org/abs/2412.15253v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Data Laundering: Artificially Boosting Benchmark Results through\n  Knowledge Distillation", "abstract": "In this paper, we show that knowledge distillation can be subverted to\nmanipulate language model benchmark scores, revealing a critical vulnerability\nin current evaluation practices. We introduce \"Data Laundering,\" a three-phase\nprocess analogous to financial money laundering, that enables the covert\ntransfer of benchmark-specific knowledge through seemingly legitimate\nintermediate training steps. Through extensive experiments with a 2-layer BERT\nstudent model, we show how this approach can achieve substantial improvements\nin benchmark accuracy (up to 75\\% on GPQA) without developing genuine reasoning\ncapabilities. Notably, this method can be exploited intentionally or even\nunintentionally, as researchers may inadvertently adopt this method that\ninflates scores using knowledge distillation without realizing the\nimplications. While our findings demonstrate the effectiveness of this\ntechnique, we present them as a cautionary tale highlighting the urgent need\nfor more robust evaluation methods in AI. This work aims to contribute to the\nongoing discussion about evaluation integrity in AI development and the need\nfor benchmarks that more accurately reflect true model capabilities. The code\nis available at \\url{https://github.com/mbzuai-nlp/data_laundering}.", "published": "2024-12-15 19:38:48", "link": "http://arxiv.org/abs/2412.15255v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dual Traits in Probabilistic Reasoning of Large Language Models", "abstract": "We conducted three experiments to investigate how large language models\n(LLMs) evaluate posterior probabilities. Our results reveal the coexistence of\ntwo modes in posterior judgment among state-of-the-art models: a normative\nmode, which adheres to Bayes' rule, and a representative-based mode, which\nrelies on similarity -- paralleling human System 1 and System 2 thinking.\nAdditionally, we observed that LLMs struggle to recall base rate information\nfrom their memory, and developing prompt engineering strategies to mitigate\nrepresentative-based judgment may be challenging. We further conjecture that\nthe dual modes of judgment may be a result of the contrastive loss function\nemployed in reinforcement learning from human feedback. Our findings underscore\nthe potential direction for reducing cognitive biases in LLMs and the necessity\nfor cautious deployment of LLMs in critical areas.", "published": "2024-12-15 01:33:45", "link": "http://arxiv.org/abs/2412.11009v1", "categories": ["cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.AI"}
{"title": "LAW: Legal Agentic Workflows for Custody and Fund Services Contracts", "abstract": "Legal contracts in the custody and fund services domain govern critical\naspects such as key provider responsibilities, fee schedules, and\nindemnification rights. However, it is challenging for an off-the-shelf Large\nLanguage Model (LLM) to ingest these contracts due to the lengthy unstructured\nstreams of text, limited LLM context windows, and complex legal jargon. To\naddress these challenges, we introduce LAW (Legal Agentic Workflows for Custody\nand Fund Services Contracts). LAW features a modular design that responds to\nuser queries by orchestrating a suite of domain-specific tools and text agents.\nOur experiments demonstrate that LAW, by integrating multiple specialized\nagents and tools, significantly outperforms the baseline. LAW excels\nparticularly in complex tasks such as calculating a contract's termination\ndate, surpassing the baseline by 92.9% points. Furthermore, LAW offers a\ncost-effective alternative to traditional fine-tuned legal LLMs by leveraging\nreusable, domain-specific tools.", "published": "2024-12-15 05:40:57", "link": "http://arxiv.org/abs/2412.11063v1", "categories": ["cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Hanprome: Modified Hangeul for Expression of foreign language\n  pronunciation", "abstract": "Hangeul was created as a phonetic alphabet and is known to have the best 1:1\ncorrespondence between letters and pronunciation among existing alphabets. In\nthis paper, we examine the possibility of modifying the basic form of Hangeul\nand using it as a kind of phonetic symbol. The core concept of this approach is\nto preserve the basic form of the alphabet, modifying only the shape of a\nstroke rather than the letter itself. To the best of our knowledge, no previous\nattempts in any language have been made to express pronunciations of an\nalphabet different from the original simply by changing the shape of the\nalphabet strokes, and this paper is probably the first attempt in this\ndirection.", "published": "2024-12-15 07:15:58", "link": "http://arxiv.org/abs/2412.11090v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Transliterated Zero-Shot Domain Adaptation for Automatic Speech\n  Recognition", "abstract": "The performance of automatic speech recognition models often degenerates on\ndomains not covered by the training data. Domain adaptation can address this\nissue, assuming the availability of the target domain data in the target\nlanguage. However, such assumption does not stand in many real-world\napplications. To make domain adaptation more applicable, we address the problem\nof zero-shot domain adaptation (ZSDA), where target domain data is unavailable\nin the target language. Instead, we transfer the target domain knowledge from\nanother source language where the target domain data is more accessible. To do\nthat, we first perform cross-lingual pre-training (XLPT) to share domain\nknowledge across languages, then use target language fine-tuning to build the\nfinal model. One challenge in this practice is that the pre-trained knowledge\ncan be forgotten during fine-tuning, resulting in sub-optimal adaptation\nperformance. To address this issue, we propose transliterated ZSDA to achieve\nconsistent pre-training and fine-tuning labels, leading to maximum preservation\nof the pre-trained knowledge. Experimental results show that transliterated\nZSDA relatively decreases the word error rate by 9.2% compared with a wav2vec\n2.0 baseline. Moreover, transliterated ZSDA consistently outperforms\nself-supervised ZSDA and performs on par with supervised ZSDA, proving the\nsuperiority of transliteration-based pre-training labels.", "published": "2024-12-15 13:32:08", "link": "http://arxiv.org/abs/2412.11185v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Analyzing the Attention Heads for Pronoun Disambiguation in\n  Context-aware Machine Translation Models", "abstract": "In this paper, we investigate the role of attention heads in Context-aware\nMachine Translation models for pronoun disambiguation in the English-to-German\nand English-to-French language directions. We analyze their influence by both\nobserving and modifying the attention scores corresponding to the plausible\nrelations that could impact a pronoun prediction. Our findings reveal that\nwhile some heads do attend the relations of interest, not all of them influence\nthe models' ability to disambiguate pronouns. We show that certain heads are\nunderutilized by the models, suggesting that model performance could be\nimproved if only the heads would attend one of the relations more strongly.\nFurthermore, we fine-tune the most promising heads and observe the increase in\npronoun disambiguation accuracy of up to 5 percentage points which demonstrates\nthat the improvements in performance can be solidified into the models'\nparameters.", "published": "2024-12-15 13:42:49", "link": "http://arxiv.org/abs/2412.11187v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Task-Oriented Dialog Systems for the Senegalese Wolof Language", "abstract": "In recent years, we are seeing considerable interest in conversational agents\nwith the rise of large language models (LLMs). Although they offer considerable\nadvantages, LLMs also present significant risks, such as hallucination, which\nhinder their widespread deployment in industry. Moreover, low-resource\nlanguages such as African ones are still underrepresented in these systems\nlimiting their performance in these languages. In this paper, we illustrate a\nmore classical approach based on modular architectures of Task-oriented Dialog\nSystems (ToDS) offering better control over outputs. We propose a chatbot\ngeneration engine based on the Rasa framework and a robust methodology for\nprojecting annotations onto the Wolof language using an in-house machine\ntranslation system. After evaluating a generated chatbot trained on the Amazon\nMassive dataset, our Wolof Intent Classifier performs similarly to the one\nobtained for French, which is a resource-rich language. We also show that this\napproach is extensible to other low-resource languages, thanks to the intent\nclassifier's language-agnostic pipeline, simplifying the design of chatbots in\nthese languages.", "published": "2024-12-15 14:35:49", "link": "http://arxiv.org/abs/2412.11203v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.IR"], "primary_category": "cs.CL"}
{"title": "TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs", "abstract": "Specializing large language models (LLMs) for local deployment in\ndomain-specific use cases is necessary for strong performance while meeting\nlatency and privacy constraints. However, conventional task-specific adaptation\napproaches do not show simultaneous memory saving and inference speedup at\ndeployment time. Practical compression techniques like quantization and pruning\nrequire dedicated hardware or kernel support to achieve measured inference\nspeedup. We develop TrimLLM based on the layer-wise specialization phenomenon\nwe empirically observed and verified on contemporary LLMs. TrimLLM reduces the\ndepth of LLMs via progressive layer dropping. We show it retains LLMs' capacity\nin specific domains and achieves inference speedup irrespective of hardware and\ndeep learning frameworks. We evaluated TrimLLM on LLMs of various sizes for\ninference; models adapted on medical, legal, and financial datasets all\ndemonstrate $2.1-5.7\\times$ inference speedup on consumer GPUs and up to\n$3.1\\times$ speedup on A100 when compared to state-of-the-art model compression\nalgorithms, with no loss in accuracy at 50$\\sim$60\\% model compression ratio.", "published": "2024-12-15 16:47:16", "link": "http://arxiv.org/abs/2412.11242v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SEE: Sememe Entanglement Encoding for Transformer-bases Models\n  Compression", "abstract": "Transformer-based large language models exhibit groundbreaking capabilities,\nbut their storage and computational costs are prohibitively high, limiting\ntheir application in resource-constrained scenarios. An effective approach is\nto eliminate redundant model parameters and computational costs while\nincorporating efficient expert-derived knowledge structures to achieve a\nbalance between compression and performance. Therefore, we propose the\n\\textit{Sememe Entanglement Encoding (SEE)} algorithm. Guided by expert prior\nknowledge, the model is compressed through the low-rank approximation idea. In\nEntanglement Embedding, basic semantic units such as sememes are represented as\nlow-dimensional vectors, and then reconstructed into high-dimensional word\nembeddings through the combination of generalized quantum entanglement. We\nadapt the Sememe Entanglement Encoding algorithm to transformer-based models of\ndifferent magnitudes. Experimental results indicate that our approach achieves\nstable performance while compressing model parameters and computational costs.", "published": "2024-12-15 12:01:43", "link": "http://arxiv.org/abs/2412.12204v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Finding a Wolf in Sheep's Clothing: Combating Adversarial Text-To-Image\n  Prompts with Text Summarization", "abstract": "Text-to-image models are vulnerable to the stepwise \"Divide-and-Conquer\nAttack\" (DACA) that utilize a large language model to obfuscate inappropriate\ncontent in prompts by wrapping sensitive text in a benign narrative. To\nmitigate stepwise DACA attacks, we propose a two-layer method involving text\nsummarization followed by binary classification. We assembled the Adversarial\nText-to-Image Prompt (ATTIP) dataset ($N=940$), which contained DACA-obfuscated\nand non-obfuscated prompts. From the ATTIP dataset, we created two summarized\nversions: one generated by a small encoder model and the other by a large\nlanguage model. Then, we used an encoder classifier and a GPT-4o classifier to\nperform content moderation on the summarized and unsummarized prompts. When\ncompared with a classifier that operated over the unsummarized data, our method\nimproved F1 score performance by 31%. Further, the highest recorded F1 score\nachieved (98%) was produced by the encoder classifier on a summarized ATTIP\nvariant. This study indicates that pre-classification text summarization can\ninoculate content detection models against stepwise DACA obfuscations.", "published": "2024-12-15 22:12:36", "link": "http://arxiv.org/abs/2412.12212v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "LitLLMs, LLMs for Literature Review: Are we there yet?", "abstract": "Literature reviews are an essential component of scientific research, but\nthey remain time-intensive and challenging to write, especially due to the\nrecent influx of research papers. This paper explores the zero-shot abilities\nof recent Large Language Models (LLMs) in assisting with the writing of\nliterature reviews based on an abstract. We decompose the task into two\ncomponents: 1. Retrieving related works given a query abstract, and 2. Writing\na literature review based on the retrieved results. We analyze how effective\nLLMs are for both components. For retrieval, we introduce a novel two-step\nsearch strategy that first uses an LLM to extract meaningful keywords from the\nabstract of a paper and then retrieves potentially relevant papers by querying\nan external knowledge base. Additionally, we study a prompting-based re-ranking\nmechanism with attribution and show that re-ranking doubles the normalized\nrecall compared to naive search methods, while providing insights into the\nLLM's decision-making process. In the generation phase, we propose a two-step\napproach that first outlines a plan for the review and then executes steps in\nthe plan to generate the actual review. To evaluate different LLM-based\nliterature review methods, we create test sets from arXiv papers using a\nprotocol designed for rolling use with newly released LLMs to avoid test set\ncontamination in zero-shot evaluations. We release this evaluation protocol to\npromote additional research and development in this regard. Our empirical\nresults suggest that LLMs show promising potential for writing literature\nreviews when the task is decomposed into smaller components of retrieval and\nplanning. Our project page including a demonstration system and toolkit can be\naccessed here: https://litllm.github.io.", "published": "2024-12-15 01:12:26", "link": "http://arxiv.org/abs/2412.15249v2", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Enhanced Text Compression Approach Using Transformer-based Language\n  Models", "abstract": "Text compression shrinks textual data while keeping crucial information,\neradicating constraints on storage, bandwidth, and computational efficacy. The\nintegration of lossless compression techniques with transformer-based text\ndecompression has received negligible attention, despite the increasing volume\nof English text data in communication. The primary barrier in advancing text\ncompression and restoration involves optimizing transformer-based approaches\nwith efficient pre-processing and integrating lossless compression algorithms,\nthat remained unresolved in the prior attempts. Here, we propose a\ntransformer-based method named RejuvenateForme for text decompression,\naddressing prior issues by harnessing a new pre-processing technique and a\nlossless compression method. Our meticulous pre-processing technique\nincorporating the Lempel-Ziv-Welch algorithm achieves compression ratios of\n12.57, 13.38, and 11.42 on the BookCorpus, EN-DE, and EN-FR corpora, thus\nshowing state-of-the-art compression ratios compared to other deep learning and\ntraditional approaches. Furthermore, the RejuvenateForme achieves a BLEU score\nof 27.31, 25.78, and 50.45 on the EN-DE, EN-FR, and BookCorpus corpora,\nshowcasing its comprehensive efficacy. In contrast, the pre-trained T5-Small\nexhibits better performance over prior state-of-the-art models.", "published": "2024-12-15 03:01:17", "link": "http://arxiv.org/abs/2412.15250v1", "categories": ["cs.CL", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.CL"}
{"title": "GaLore$+$: Boosting Low-Rank Adaptation for LLMs with Cross-Head\n  Projection", "abstract": "Recent low-rank training methods, such as GaLore, have significantly reduced\nthe memory required to optimize large language models (LLMs). However, these\nmethods often suffer from time-consuming low-rank projection estimations. In\nparticular, the singular value decomposition (SVD) in GaLore can consume more\nthan 80\\% of the total training time. To address this issue, we propose\nGaLore$+$, which uses cross-head low-rank projection to reduce the substantial\ntime consumption in estimating low-rank projections for multi-head attention.\nIn addition, we employ randomized subspace iteration to achieve fast SVD. To\nfurther enhance performance, we propose sparsely coded residuals to reduce the\nerrors caused by low-rank approximation on the first- and second-order moments\nof the optimizers and weight updates. We evaluate GaLore$+$ on arithmetic\nreasoning and natural language generation datasets. Our experiments demonstrate\nthat GaLore$+$ delivers superior performance while achieving approximately\n$4\\times$ fine-tuning speed compared to vanilla GaLore.", "published": "2024-12-15 12:28:13", "link": "http://arxiv.org/abs/2412.19820v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Whisper on Streaming Speech", "abstract": "Speech foundation models, exemplified by OpenAI's Whisper, have emerged as\nleaders in speech understanding thanks to their exceptional accuracy and\nadaptability. However, their usage largely focuses on processing pre-recorded\naudio, with the efficient handling of streaming speech still in its infancy.\nSeveral core challenges underlie this limitation: (1) These models are trained\nfor long, fixed-length audio inputs (typically 30 seconds). (2) Encoding such\ninputs involves processing up to 1,500 tokens through numerous transformer\nlayers. (3) Generating outputs requires an irregular and computationally heavy\nbeam search. Consequently, streaming speech processing on edge devices with\nconstrained resources is more demanding than many other AI tasks, including\ntext generation. To address these challenges, we introduce Whisper-T, an\ninnovative framework combining both model and system-level optimizations: (1)\nHush words, short learnable audio segments appended to inputs, prevent\nover-processing and reduce hallucinations in the model. (2) Beam pruning aligns\nstreaming audio buffers over time, leveraging intermediate decoding results to\nsignificantly speed up the process. (3) CPU/GPU pipelining dynamically\ndistributes resources between encoding and decoding stages, optimizing\nperformance by adapting to variations in audio input, model characteristics,\nand hardware. We evaluate Whisper-T on ARM-based platforms with 4-12 CPU cores\nand 10-30 GPU cores, demonstrating latency reductions of 1.6x-4.7x, achieving\nper-word delays as low as 0.5 seconds with minimal accuracy loss. Additionally,\non a MacBook Air, Whisper-T maintains approximately 1-second latency per word\nwhile consuming just 7 Watts of total system power.", "published": "2024-12-15 18:27:37", "link": "http://arxiv.org/abs/2412.11272v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sonicmesh: Enhancing 3D Human Mesh Reconstruction in Vision-Impaired\n  Environments With Acoustic Signals", "abstract": "3D Human Mesh Reconstruction (HMR) from 2D RGB images faces challenges in\nenvironments with poor lighting, privacy concerns, or occlusions. These\nweaknesses of RGB imaging can be complemented by acoustic signals, which are\nwidely available, easy to deploy, and capable of penetrating obstacles.\nHowever, no existing methods effectively combine acoustic signals with RGB data\nfor robust 3D HMR. The primary challenges include the low-resolution images\ngenerated by acoustic signals and the lack of dedicated processing backbones.\nWe introduce SonicMesh, a novel approach combining acoustic signals with RGB\nimages to reconstruct 3D human mesh. To address the challenges of low\nresolution and the absence of dedicated processing backbones in images\ngenerated by acoustic signals, we modify an existing method, HRNet, for\neffective feature extraction. We also integrate a universal feature embedding\ntechnique to enhance the precision of cross-dimensional feature alignment,\nenabling SonicMesh to achieve high accuracy. Experimental results demonstrate\nthat SonicMesh accurately reconstructs 3D human mesh in challenging\nenvironments such as occlusions, non-line-of-sight scenarios, and poor\nlighting.", "published": "2024-12-15 22:04:26", "link": "http://arxiv.org/abs/2412.11325v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Imagined Speech State Classification for Robust Brain-Computer Interface", "abstract": "This study examines the effectiveness of traditional machine learning\nclassifiers versus deep learning models for detecting the imagined speech using\nelectroencephalogram data. Specifically, we evaluated conventional machine\nlearning techniques such as CSP-SVM and LDA-SVM classifiers alongside deep\nlearning architectures such as EEGNet, ShallowConvNet, and DeepConvNet. Machine\nlearning classifiers exhibited significantly lower precision and recall,\nindicating limited feature extraction capabilities and poor generalization\nbetween imagined speech and idle states. In contrast, deep learning models,\nparticularly EEGNet, achieved the highest accuracy of 0.7080 and an F1 score of\n0.6718, demonstrating their enhanced ability in automatic feature extraction\nand representation learning, essential for capturing complex neurophysiological\npatterns. These findings highlight the limitations of conventional machine\nlearning approaches in brain-computer interface (BCI) applications and advocate\nfor adopting deep learning methodologies to achieve more precise and reliable\nclassification of detecting imagined speech. This foundational research\ncontributes to the development of imagined speech-based BCI systems.", "published": "2024-12-15 23:59:55", "link": "http://arxiv.org/abs/2412.12215v1", "categories": ["cs.LG", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
