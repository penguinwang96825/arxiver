{"title": "A Sequence-to-Set Network for Nested Named Entity Recognition", "abstract": "Named entity recognition (NER) is a widely studied task in natural language\nprocessing. Recently, a growing number of studies have focused on the nested\nNER. The span-based methods, considering the entity recognition as a span\nclassification task, can deal with nested entities naturally. But they suffer\nfrom the huge search space and the lack of interactions between entities. To\naddress these issues, we propose a novel sequence-to-set neural network for\nnested NER. Instead of specifying candidate spans in advance, we provide a\nfixed set of learnable vectors to learn the patterns of the valuable spans. We\nutilize a non-autoregressive decoder to predict the final set of entities in\none pass, in which we are able to capture dependencies between entities.\nCompared with the sequence-to-sequence method, our model is more suitable for\nsuch unordered recognition task as it is insensitive to the label order. In\naddition, we utilize the loss function based on bipartite matching to compute\nthe overall training loss. Experimental results show that our proposed model\nachieves state-of-the-art on three nested NER corpora: ACE 2004, ACE 2005 and\nKBP 2017. The code is available at\nhttps://github.com/zqtan1024/sequence-to-set.", "published": "2021-05-19 03:10:04", "link": "http://arxiv.org/abs/2105.08901v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OpenMEVA: A Benchmark for Evaluating Open-ended Story Generation Metrics", "abstract": "Automatic metrics are essential for developing natural language generation\n(NLG) models, particularly for open-ended language generation tasks such as\nstory generation. However, existing automatic metrics are observed to correlate\npoorly with human evaluation. The lack of standardized benchmark datasets makes\nit difficult to fully evaluate the capabilities of a metric and fairly compare\ndifferent metrics. Therefore, we propose OpenMEVA, a benchmark for evaluating\nopen-ended story generation metrics. OpenMEVA provides a comprehensive test\nsuite to assess the capabilities of metrics, including (a) the correlation with\nhuman judgments, (b) the generalization to different model outputs and\ndatasets, (c) the ability to judge story coherence, and (d) the robustness to\nperturbations. To this end, OpenMEVA includes both manually annotated stories\nand auto-constructed test examples. We evaluate existing metrics on OpenMEVA\nand observe that they have poor correlation with human judgments, fail to\nrecognize discourse-level incoherence, and lack inferential knowledge (e.g.,\ncausal order between events), the generalization ability and robustness. Our\nstudy presents insights for developing NLG models and metrics in further\nresearch.", "published": "2021-05-19 04:45:07", "link": "http://arxiv.org/abs/2105.08920v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Answering Product-Questions by Utilizing Questions from Other\n  Contextually Similar Products", "abstract": "Predicting the answer to a product-related question is an emerging field of\nresearch that recently attracted a lot of attention. Answering subjective and\nopinion-based questions is most challenging due to the dependency on\ncustomer-generated content. Previous works mostly focused on review-aware\nanswer prediction; however, these approaches fail for new or unpopular\nproducts, having no (or only a few) reviews at hand. In this work, we propose a\nnovel and complementary approach for predicting the answer for such questions,\nbased on the answers for similar questions asked on similar products. We\nmeasure the contextual similarity between products based on the answers they\nprovide for the same question. A mixture-of-expert framework is used to predict\nthe answer by aggregating the answers from contextually similar products.\nEmpirical results demonstrate that our model outperforms strong baselines on\nsome segments of questions, namely those that have roughly ten or more similar\nresolved questions in the corpus. We additionally publish two large-scale\ndatasets used in this work, one is of similar product question pairs, and the\nsecond is of product question-answer pairs.", "published": "2021-05-19 07:05:00", "link": "http://arxiv.org/abs/2105.08956v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Long Text Generation by Modeling Sentence-Level and Discourse-Level\n  Coherence", "abstract": "Generating long and coherent text is an important but challenging task,\nparticularly for open-ended language generation tasks such as story generation.\nDespite the success in modeling intra-sentence coherence, existing generation\nmodels (e.g., BART) still struggle to maintain a coherent event sequence\nthroughout the generated text. We conjecture that this is because of the\ndifficulty for the decoder to capture the high-level semantics and discourse\nstructures in the context beyond token-level co-occurrence. In this paper, we\npropose a long text generation model, which can represent the prefix sentences\nat sentence level and discourse level in the decoding process. To this end, we\npropose two pretraining objectives to learn the representations by predicting\ninter-sentence semantic similarity and distinguishing between normal and\nshuffled sentence orders. Extensive experiments show that our model can\ngenerate more coherent texts than state-of-the-art baselines.", "published": "2021-05-19 07:29:08", "link": "http://arxiv.org/abs/2105.08963v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QuatDE: Dynamic Quaternion Embedding for Knowledge Graph Completion", "abstract": "Knowledge graph embedding has been an active research topic for knowledge\nbase completion (KGC), with progressive improvement from the initial TransE,\nTransH, RotatE et al to the current state-of-the-art QuatE. However, QuatE\nignores the multi-faceted nature of the entity and the complexity of the\nrelation, only using rigorous operation on quaternion space to capture the\ninteraction between entitiy pair and relation, leaving opportunities for better\nknowledge representation which will finally help KGC. In this paper, we propose\na novel model, QuatDE, with a dynamic mapping strategy to explicitly capture\nthe variety of relational patterns and separate different semantic information\nof the entity, using transition vectors to adjust the point position of the\nentity embedding vectors in the quaternion space via Hamilton product,\nenhancing the feature interaction capability between elements of the triplet.\nExperiment results show QuatDE achieves state-of-the-art performance on three\nwell-established knowledge graph completion benchmarks. In particular, the MR\nevaluation has relatively increased by 26% on WN18 and 15% on WN18RR, which\nproves the generalization of QuatDE.", "published": "2021-05-19 09:10:39", "link": "http://arxiv.org/abs/2105.09002v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentence Extraction-Based Machine Reading Comprehension for Vietnamese", "abstract": "The development of natural language processing (NLP) in general and machine\nreading comprehension in particular has attracted the great attention of the\nresearch community. In recent years, there are a few datasets for machine\nreading comprehension tasks in Vietnamese with large sizes, such as UIT-ViQuAD\nand UIT-ViNewsQA. However, the datasets are not diverse in answers to serve the\nresearch. In this paper, we introduce UIT-ViWikiQA, the first dataset for\nevaluating sentence extraction-based machine reading comprehension in the\nVietnamese language. The UIT-ViWikiQA dataset is converted from the UIT-ViQuAD\ndataset, consisting of comprises 23.074 question-answers based on 5.109\npassages of 174 Wikipedia Vietnamese articles. We propose a conversion\nalgorithm to create the dataset for sentence extraction-based machine reading\ncomprehension and three types of approaches for sentence extraction-based\nmachine reading comprehension in Vietnamese. Our experiments show that the best\nmachine model is XLM-R_Large, which achieves an exact match (EM) of 85.97% and\nan F1-score of 88.77% on our dataset. Besides, we analyze experimental results\nin terms of the question type in Vietnamese and the effect of context on the\nperformance of the MRC models, thereby showing the challenges from the\nUIT-ViWikiQA dataset that we propose to the language processing community.", "published": "2021-05-19 10:22:27", "link": "http://arxiv.org/abs/2105.09043v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Models Learn the Directionality of Relations? A New Evaluation:\n  Relation Direction Recognition", "abstract": "Deep neural networks such as BERT have made great progress in relation\nclassification. Although they can achieve good performance, it is still a\nquestion of concern whether these models recognize the directionality of\nrelations, especially when they may lack interpretability. To explore the\nquestion, a novel evaluation task, called Relation Direction Recognition (RDR),\nis proposed to explore whether models learn the directionality of relations.\nThree metrics for RDR are introduced to measure the degree to which models\nrecognize the directionality of relations. Several state-of-the-art models are\nevaluated on RDR. Experimental results on a real-world dataset indicate that\nthere are clear gaps among them in recognizing the directionality of relations,\neven though these models obtain similar performance in the traditional metric\n(e.g. Macro-F1). Finally, some suggestions are discussed to enhance models to\nrecognize the directionality of relations from the perspective of model design\nor training.", "published": "2021-05-19 10:24:50", "link": "http://arxiv.org/abs/2105.09045v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Partner Matters! An Empirical Study on Fusing Personas for Personalized\n  Response Selection in Retrieval-Based Chatbots", "abstract": "Persona can function as the prior knowledge for maintaining the consistency\nof dialogue systems. Most of previous studies adopted the self persona in\ndialogue whose response was about to be selected from a set of candidates or\ndirectly generated, but few have noticed the role of partner in dialogue. This\npaper makes an attempt to thoroughly explore the impact of utilizing personas\nthat describe either self or partner speakers on the task of response selection\nin retrieval-based chatbots. Four persona fusion strategies are designed, which\nassume personas interact with contexts or responses in different ways. These\nstrategies are implemented into three representative models for response\nselection, which are based on the Hierarchical Recurrent Encoder (HRE),\nInteractive Matching Network (IMN) and Bidirectional Encoder Representations\nfrom Transformers (BERT) respectively. Empirical studies on the Persona-Chat\ndataset show that the partner personas neglected in previous studies can\nimprove the accuracy of response selection in the IMN- and BERT-based models.\nBesides, our BERT-based model implemented with the context-response-aware\npersona fusion strategy outperforms previous methods by margins larger than\n2.7% on original personas and 4.6% on revised personas in terms of hits@1\n(top-1 accuracy), achieving a new state-of-the-art performance on the\nPersona-Chat dataset.", "published": "2021-05-19 10:32:30", "link": "http://arxiv.org/abs/2105.09050v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Essay-BR: a Brazilian Corpus of Essays", "abstract": "Automatic Essay Scoring (AES) is defined as the computer technology that\nevaluates and scores the written essays, aiming to provide computational models\nto grade essays either automatically or with minimal human involvement. While\nthere are several AES studies in a variety of languages, few of them are\nfocused on the Portuguese language. The main reason is the lack of a corpus\nwith manually graded essays. In order to bridge this gap, we create a large\ncorpus with several essays written by Brazilian high school students on an\nonline platform. All of the essays are argumentative and were scored across\nfive competencies by experts. Moreover, we conducted an experiment on the\ncreated corpus and showed challenges posed by the Portuguese language. Our\ncorpus is publicly available at https://github.com/rafaelanchieta/essay.", "published": "2021-05-19 11:59:46", "link": "http://arxiv.org/abs/2105.09081v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Combining GCN and Transformer for Chinese Grammatical Error Detection", "abstract": "This paper describes our system at NLPTEA-2020 Task: Chinese Grammatical\nError Diagnosis (CGED). The goal of CGED is to diagnose four types of\ngrammatical errors: word selection (S), redundant words (R), missing words (M),\nand disordered words (W). The automatic CGED system contains two parts\nincluding error detection and error correction and our system is designed to\nsolve the error detection problem. Our system is built on three models: 1) a\nBERT-based model leveraging syntactic information; 2) a BERT-based model\nleveraging contextual embeddings; 3) a lexicon-based graph neural network\nleveraging lexical information. We also design an ensemble mechanism to improve\nthe single model's performance. Finally, our system achieves the highest F1\nscores at detection level and identification level among all teams\nparticipating in the CGED 2020 task.", "published": "2021-05-19 12:17:07", "link": "http://arxiv.org/abs/2105.09085v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Privacy-Preserving Approach to Extraction of Personal Information\n  through Automatic Annotation and Federated Learning", "abstract": "We curated WikiPII, an automatically labeled dataset composed of Wikipedia\nbiography pages, annotated for personal information extraction. Although\nautomatic annotation can lead to a high degree of label noise, it is an\ninexpensive process and can generate large volumes of annotated documents. We\ntrained a BERT-based NER model with WikiPII and showed that with an adequately\nlarge training dataset, the model can significantly decrease the cost of manual\ninformation extraction, despite the high level of label noise. In a similar\napproach, organizations can leverage text mining techniques to create\ncustomized annotated datasets from their historical data without sharing the\nraw data for human annotation. Also, we explore collaborative training of NER\nmodels through federated learning when the annotation is noisy. Our results\nsuggest that depending on the level of trust to the ML operator and the volume\nof the available data, distributed training can be an effective way of training\na personal information identifier in a privacy-preserved manner. Research\nmaterial is available at https://github.com/ratmcu/wikipiifed.", "published": "2021-05-19 15:17:44", "link": "http://arxiv.org/abs/2105.09198v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detection of Emotions in Hindi-English Code Mixed Text Data", "abstract": "In recent times, we have seen an increased use of text chat for communication\non social networks and smartphones. This particularly involves the use of\nHindi-English code-mixed text which contains words which are not recognized in\nEnglish vocabulary. We have worked on detecting emotions in these mixed data\nand classify the sentences in human emotions which are angry, fear, happy or\nsad. We have used state of the art natural language processing models and\ncompared their performance on the dataset comprising sentences in this mixed\ndata. The dataset was collected and annotated from sources and then used to\ntrain the models.", "published": "2021-05-19 16:12:01", "link": "http://arxiv.org/abs/2105.09226v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Language Specific Sub-network for Multilingual Machine\n  Translation", "abstract": "Multilingual neural machine translation aims at learning a single translation\nmodel for multiple languages. These jointly trained models often suffer from\nperformance degradation on rich-resource language pairs. We attribute this\ndegeneration to parameter interference. In this paper, we propose LaSS to\njointly train a single unified multilingual MT model. LaSS learns Language\nSpecific Sub-network (LaSS) for each language pair to counter parameter\ninterference. Comprehensive experiments on IWSLT and WMT datasets with various\nTransformer architectures show that LaSS obtains gains on 36 language pairs by\nup to 1.2 BLEU. Besides, LaSS shows its strong generalization performance at\neasy extension to new language pairs and zero-shot translation.LaSS boosts\nzero-shot translation with an average of 8.3 BLEU on 30 language pairs. Codes\nand trained models are available at https://github.com/NLP-Playground/LaSS.", "published": "2021-05-19 17:08:38", "link": "http://arxiv.org/abs/2105.09259v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Computational Morphology with Neural Network Approaches", "abstract": "Neural network approaches have been applied to computational morphology with\ngreat success, improving the performance of most tasks by a large margin and\nproviding new perspectives for modeling. This paper starts with a brief\nintroduction to computational morphology, followed by a review of recent work\non computational morphology with neural network approaches, to provide an\noverview of the area. In the end, we will analyze the advantages and problems\nof neural network approaches to computational morphology, and point out some\ndirections to be explored by future research and study.", "published": "2021-05-19 21:17:53", "link": "http://arxiv.org/abs/2105.09404v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Adverse Drug Event Extraction with SpanBERT on Different Text\n  Typologies", "abstract": "In recent years, Internet users are reporting Adverse Drug Events (ADE) on\nsocial media, blogs and health forums. Because of the large volume of reports,\npharmacovigilance is seeking to resort to NLP to monitor these outlets. We\npropose for the first time the use of the SpanBERT architecture for the task of\nADE extraction: this new version of the popular BERT transformer showed\nimproved capabilities with multi-token text spans. We validate our hypothesis\nwith experiments on two datasets (SMM4H and CADEC) with different text\ntypologies (tweets and blog posts), finding that SpanBERT combined with a CRF\noutperforms all the competitors on both of them.", "published": "2021-05-19 02:01:09", "link": "http://arxiv.org/abs/2105.08882v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Investigating Math Word Problems using Pretrained Multilingual Language\n  Models", "abstract": "In this paper, we revisit math word problems~(MWPs) from the cross-lingual\nand multilingual perspective. We construct our MWP solvers over pretrained\nmultilingual language models using sequence-to-sequence model with copy\nmechanism. We compare how the MWP solvers perform in cross-lingual and\nmultilingual scenarios. To facilitate the comparison of cross-lingual\nperformance, we first adapt the large-scale English dataset MathQA as a\ncounterpart of the Chinese dataset Math23K. Then we extend several English\ndatasets to bilingual datasets through machine translation plus human\nannotation. Our experiments show that the MWP solvers may not be transferred to\na different language even if the target expressions have the same operator set\nand constants. But for both cross-lingual and multilingual cases, it can be\nbetter generalized if problem types exist on both source language and target\nlanguage.", "published": "2021-05-19 05:17:10", "link": "http://arxiv.org/abs/2105.08928v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Methods for Detoxification of Texts for the Russian Language", "abstract": "We introduce the first study of automatic detoxification of Russian texts to\ncombat offensive language. Such a kind of textual style transfer can be used,\nfor instance, for processing toxic content in social media. While much work has\nbeen done for the English language in this field, it has never been solved for\nthe Russian language yet. We test two types of models - unsupervised approach\nbased on BERT architecture that performs local corrections and supervised\napproach based on pretrained language GPT-2 model - and compare them with\nseveral baselines. In addition, we describe evaluation setup providing training\ndatasets and metrics for automatic evaluation. The results show that the tested\napproaches can be successfully used for detoxification, although there is room\nfor improvement.", "published": "2021-05-19 10:37:44", "link": "http://arxiv.org/abs/2105.09052v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Retrieval-Augmented Transformer-XL for Close-Domain Dialog Generation", "abstract": "Transformer-based models have demonstrated excellent capabilities of\ncapturing patterns and structures in natural language generation and achieved\nstate-of-the-art results in many tasks. In this paper we present a\ntransformer-based model for multi-turn dialog response generation. Our solution\nis based on a hybrid approach which augments a transformer-based generative\nmodel with a novel retrieval mechanism, which leverages the memorized\ninformation in the training data via k-Nearest Neighbor search. Our system is\nevaluated on two datasets made by customer/assistant dialogs: the Taskmaster-1,\nreleased by Google and holding high quality, goal-oriented conversational data\nand a proprietary dataset collected from a real customer service call center.\nBoth achieve better BLEU scores over strong baselines.", "published": "2021-05-19 16:34:33", "link": "http://arxiv.org/abs/2105.09235v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Geographic Question Answering: Challenges, Uniqueness, Classification,\n  and Future Directions", "abstract": "As an important part of Artificial Intelligence (AI), Question Answering (QA)\naims at generating answers to questions phrased in natural language. While\nthere has been substantial progress in open-domain question answering, QA\nsystems are still struggling to answer questions which involve geographic\nentities or concepts and that require spatial operations. In this paper, we\ndiscuss the problem of geographic question answering (GeoQA). We first\ninvestigate the reasons why geographic questions are difficult to answer by\nanalyzing challenges of geographic questions. We discuss the uniqueness of\ngeographic questions compared to general QA. Then we review existing work on\nGeoQA and classify them by the types of questions they can address. Based on\nthis survey, we provide a generic classification framework for geographic\nquestions. Finally, we conclude our work by pointing out unique future research\ndirections for GeoQA.", "published": "2021-05-19 20:47:36", "link": "http://arxiv.org/abs/2105.09392v1", "categories": ["cs.CL", "cs.AI", "68T50, 68T30, 68T07, 03B65, 91F20", "I.2.7; I.2.4"], "primary_category": "cs.CL"}
{"title": "Analysis of GraphSum's Attention Weights to Improve the Explainability\n  of Multi-Document Summarization", "abstract": "Modern multi-document summarization (MDS) methods are based on transformer\narchitectures. They generate state of the art summaries, but lack\nexplainability. We focus on graph-based transformer models for MDS as they\ngained recent popularity. We aim to improve the explainability of the\ngraph-based MDS by analyzing their attention weights. In a graph-based MDS such\nas GraphSum, vertices represent the textual units, while the edges form some\nsimilarity graph over the units. We compare GraphSum's performance utilizing\ndifferent textual units, i. e., sentences versus paragraphs, on two news\nbenchmark datasets, namely WikiSum and MultiNews. Our experiments show that\nparagraph-level representations provide the best summarization performance.\nThus, we subsequently focus oAnalysisn analyzing the paragraph-level attention\nweights of GraphSum's multi-heads and decoding layers in order to improve the\nexplainability of a transformer-based MDS model. As a reference metric, we\ncalculate the ROUGE scores between the input paragraphs and each sentence in\nthe generated summary, which indicate source origin information via text\nsimilarity. We observe a high correlation between the attention weights and\nthis reference metric, especially on the the later decoding layers of the\ntransformer architecture. Finally, we investigate if the generated summaries\nfollow a pattern of positional bias by extracting which paragraph provided the\nmost information for each generated summary. Our results show that there is a\nhigh correlation between the position in the summary and the source origin.", "published": "2021-05-19 08:18:59", "link": "http://arxiv.org/abs/2105.11908v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Compositional Processing Emerges in Neural Networks Solving Math\n  Problems", "abstract": "A longstanding question in cognitive science concerns the learning mechanisms\nunderlying compositionality in human cognition. Humans can infer the structured\nrelationships (e.g., grammatical rules) implicit in their sensory observations\n(e.g., auditory speech), and use this knowledge to guide the composition of\nsimpler meanings into complex wholes. Recent progress in artificial neural\nnetworks has shown that when large models are trained on enough linguistic\ndata, grammatical structure emerges in their representations. We extend this\nwork to the domain of mathematical reasoning, where it is possible to formulate\nprecise hypotheses about how meanings (e.g., the quantities corresponding to\nnumerals) should be composed according to structured rules (e.g., order of\noperations). Our work shows that neural networks are not only able to infer\nsomething about the structured relationships implicit in their training data,\nbut can also deploy this knowledge to guide the composition of individual\nmeanings into composite wholes.", "published": "2021-05-19 07:24:42", "link": "http://arxiv.org/abs/2105.08961v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Explainable Tsetlin Machine framework for fake news detection with\n  credibility score assessment", "abstract": "The proliferation of fake news, i.e., news intentionally spread for\nmisinformation, poses a threat to individuals and society. Despite various\nfact-checking websites such as PolitiFact, robust detection techniques are\nrequired to deal with the increase in fake news. Several deep learning models\nshow promising results for fake news classification, however, their black-box\nnature makes it difficult to explain their classification decisions and\nquality-assure the models. We here address this problem by proposing a novel\ninterpretable fake news detection framework based on the recently introduced\nTsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to\ncapture lexical and semantic properties of both true and fake news text.\nFurther, we use the clause ensembles to calculate the credibility of fake news.\nFor evaluation, we conduct experiments on two publicly available datasets,\nPolitiFact and GossipCop, and demonstrate that the TM framework significantly\noutperforms previously published baselines by at least $5\\%$ in terms of\naccuracy, with the added benefit of an interpretable logic-based\nrepresentation. Further, our approach provides higher F1-score than BERT and\nXLNet, however, we obtain slightly lower accuracy. We finally present a case\nstudy on our model's explainability, demonstrating how it decomposes into\nmeaningful words and their negations.", "published": "2021-05-19 13:18:02", "link": "http://arxiv.org/abs/2105.09114v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2; I.5; I.7"], "primary_category": "cs.CL"}
{"title": "Robustness and stability of enterprise intranet social networks: The\n  impact of moderators", "abstract": "In this study, we tested the robustness of three communication networks\nextracted from the online forums included in the intranet platforms of three\nlarge companies. For each company we analyzed the communication among employees\nboth in terms of network structure and content (language used). Over a period\nof eight months, we analyzed more than 52,000 messages posted by approximately\n12,000 employees. Specifically, we tested the network robustness and the\nstability of a set of structural and semantic metrics, while applying several\ndifferent node removal strategies. We removed the forum moderators, the\nspammers, the overly connected nodes and the nodes lying at the network\nperiphery, also testing different combinations of these selections. Results\nindicate that removing spammers and very peripheral nodes can be a relatively\nlow impact strategy in this context; accordingly, it could be used to clean the\nnoise generated by these types of social actor and to reduce the computation\ncomplexity of the analysis. On the other hand, the removal of moderators seems\nto have a significant impact on the network connectivity and the shared\ncontent. The most affected variables are closeness centrality and contribution\nindex. We also found that the removal of overly connected nodes can\nsignificantly change the network structure. Lastly, we compared the behavior of\nmoderators with the other users, finding distinctive characteristics by which\nmoderators can be identified when their list is unknown. Our findings can help\nonline community managers to understand the role of moderators within intranet\nforums and can be useful for social network analysts who are interested in\nevaluating the effects of graph simplification techniques.", "published": "2021-05-19 13:43:03", "link": "http://arxiv.org/abs/2105.09127v1", "categories": ["cs.SI", "cs.CL", "physics.soc-ph", "I.2.7; H.4.0; J.4"], "primary_category": "cs.SI"}
{"title": "TableZa -- A classical Computer Vision approach to Tabular Extraction", "abstract": "Computer aided Tabular Data Extraction has always been a very challenging and\nerror prone task because it demands both Spectral and Spatial Sanity of data.\nIn this paper we discuss an approach for Tabular Data Extraction in the realm\nof document comprehension. Given the different kinds of the Tabular formats\nthat are often found across various documents, we discuss a novel approach\nusing Computer Vision for extraction of tabular data from images or vector\npdf(s) converted to image(s).", "published": "2021-05-19 13:55:33", "link": "http://arxiv.org/abs/2105.09137v1", "categories": ["cs.CL", "cs.CV", "cs.IR", "I.5.1; I.5.2; I.5.4"], "primary_category": "cs.CL"}
{"title": "Laughing Heads: Can Transformers Detect What Makes a Sentence Funny?", "abstract": "The automatic detection of humor poses a grand challenge for natural language\nprocessing. Transformer-based systems have recently achieved remarkable results\non this task, but they usually (1)~were evaluated in setups where serious vs\nhumorous texts came from entirely different sources, and (2)~focused on\nbenchmarking performance without providing insights into how the models work.\nWe make progress in both respects by training and analyzing transformer-based\nhumor recognition models on a recently introduced dataset consisting of minimal\npairs of aligned sentences, one serious, the other humorous. We find that,\nalthough our aligned dataset is much harder than previous datasets,\ntransformer-based models recognize the humorous sentence in an aligned pair\nwith high accuracy (78%). In a careful error analysis, we characterize easy vs\nhard instances. Finally, by analyzing attention weights, we obtain important\ninsights into the mechanisms by which transformers recognize humor. Most\nremarkably, we find clear evidence that one single attention head learns to\nrecognize the words that make a test sentence humorous, even without access to\nthis information at training time.", "published": "2021-05-19 14:02:25", "link": "http://arxiv.org/abs/2105.09142v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Using four different online media sources to forecast the crude oil\n  price", "abstract": "This study looks for signals of economic awareness on online social media and\ntests their significance in economic predictions. The study analyses, over a\nperiod of two years, the relationship between the West Texas Intermediate daily\ncrude oil price and multiple predictors extracted from Twitter, Google Trends,\nWikipedia, and the Global Data on Events, Language, and Tone database (GDELT).\nSemantic analysis is applied to study the sentiment, emotionality and\ncomplexity of the language used. Autoregressive Integrated Moving Average with\nExplanatory Variable (ARIMAX) models are used to make predictions and to\nconfirm the value of the study variables. Results show that the combined\nanalysis of the four media platforms carries valuable information in making\nfinancial forecasting. Twitter language complexity, GDELT number of articles\nand Wikipedia page reads have the highest predictive power. This study also\nallows a comparison of the different fore-sighting abilities of each platform,\nin terms of how many days ahead a platform can predict a price movement before\nit happens. In comparison with previous work, more media sources and more\ndimensions of the interaction and of the language used are combined in a joint\nanalysis.", "published": "2021-05-19 14:19:18", "link": "http://arxiv.org/abs/2105.09154v1", "categories": ["econ.GN", "cs.CL", "q-fin.EC", "q-fin.GN", "I.2.7"], "primary_category": "econ.GN"}
{"title": "Forecasting managerial turnover through e-mail based social network\n  analysis", "abstract": "In this study we propose a method based on e-mail social network analysis to\ncompare the communication behavior of managers who voluntarily quit their job\nand managers who decide to stay. Collecting 18 months of e-mail, we analyzed\nthe communication behavior of 866 managers, out of which 111 left a large\nglobal service company. We compared differences in communication patterns by\ncomputing social network metrics, such as betweenness and closeness centrality,\nand content analysis indicators, such as emotionality and complexity of the\nlanguage used. To study the emergence of managers' disengagement, we made a\ndistinction based on the period of e-mail data examined. We observed\ncommunications during months 5 and 4 before managers left, and found\nsignificant variations in both their network structure and use of language.\nResults indicate that on average managers who quit had lower closeness\ncentrality and less engaged conversations. In addition, managers who chose to\nquit tended to shift their communication behavior starting from 5 months before\nleaving, by increasing their degree and closeness centrality, the complexity of\ntheir language, as well as their oscillations in betweenness centrality and the\nnumber of \"nudges\" they need to send to peers before getting an answer.", "published": "2021-05-19 15:39:55", "link": "http://arxiv.org/abs/2105.09208v1", "categories": ["cs.SI", "cs.CL", "physics.soc-ph", "J.4; I.2.7; H.4.0"], "primary_category": "cs.SI"}
{"title": "Explainable Health Risk Predictor with Transformer-based Medicare Claim\n  Encoder", "abstract": "In 2019, The Centers for Medicare and Medicaid Services (CMS) launched an\nArtificial Intelligence (AI) Health Outcomes Challenge seeking solutions to\npredict risk in value-based care for incorporation into CMS Innovation Center\npayment and service delivery models. Recently, modern language models have\nplayed key roles in a number of health related tasks. This paper presents, to\nthe best of our knowledge, the first application of these models to patient\nreadmission prediction. To facilitate this, we create a dataset of 1.2 million\nmedical history samples derived from the Limited Dataset (LDS) issued by CMS.\nMoreover, we propose a comprehensive modeling solution centered on a deep\nlearning framework for this data. To demonstrate the framework, we train an\nattention-based Transformer to learn Medicare semantics in support of\nperforming downstream prediction tasks thereby achieving 0.91 AUC and 0.91\nrecall on readmission classification. We also introduce a novel data\npre-processing pipeline and discuss pertinent deployment considerations\nsurrounding model explainability and bias.", "published": "2021-05-19 22:39:15", "link": "http://arxiv.org/abs/2105.09428v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SEMOUR: A Scripted Emotional Speech Repository for Urdu", "abstract": "Designing reliable Speech Emotion Recognition systems is a complex task that\ninevitably requires sufficient data for training purposes. Such extensive\ndatasets are currently available in only a few languages, including English,\nGerman, and Italian. In this paper, we present SEMOUR, the first scripted\ndatabase of emotion-tagged speech in the Urdu language, to design an Urdu\nSpeech Recognition System. Our gender-balanced dataset contains 15,040 unique\ninstances recorded by eight professional actors eliciting a syntactically\ncomplex script. The dataset is phonetically balanced, and reliably exhibits a\nvaried set of emotions as marked by the high agreement scores among human\nraters in experiments. We also provide various baseline speech emotion\nprediction scores on the database, which could be used for various applications\nlike personalized robot assistants, diagnosis of psychological disorders, and\ngetting feedback from a low-tech-enabled population, etc. On a random test\nsample, our model correctly predicts an emotion with a state-of-the-art 92%\naccuracy.", "published": "2021-05-19 07:15:03", "link": "http://arxiv.org/abs/2105.08957v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Advances in integration of end-to-end neural and clustering-based\n  diarization for real conversational speech", "abstract": "Recently, we proposed a novel speaker diarization method called\nEnd-to-End-Neural-Diarization-vector clustering (EEND-vector clustering) that\nintegrates clustering-based and end-to-end neural network-based diarization\napproaches into one framework. The proposed method combines advantages of both\nframeworks, i.e. high diarization performance and handling of overlapped speech\nbased on EEND, and robust handling of long recordings with an arbitrary number\nof speakers based on clustering-based approaches. However, the method was only\nevaluated so far on simulated 2-speaker meeting-like data. This paper is to (1)\nreport recent advances we made to this framework, including newly introduced\nrobust constrained clustering algorithms, and (2) experimentally show that the\nmethod can now significantly outperform competitive diarization methods such as\nEncoder-Decoder Attractor (EDA)-EEND, on CALLHOME data which comprises real\nconversational speech data including overlapped speech and an arbitrary number\nof speakers. By further analyzing the experimental results, this paper also\ndiscusses pros and cons of the proposed method and reveals potential for\nfurther improvement. A set of the code to reproduce the results is available at\nhttps://github.com/nttcslab-sp/EEND-vector-clustering.", "published": "2021-05-19 10:10:10", "link": "http://arxiv.org/abs/2105.09040v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Disentanglement Learning for Variational Autoencoders Applied to\n  Audio-Visual Speech Enhancement", "abstract": "Recently, the standard variational autoencoder has been successfully used to\nlearn a probabilistic prior over speech signals, which is then used to perform\nspeech enhancement. Variational autoencoders have then been conditioned on a\nlabel describing a high-level speech attribute (e.g. speech activity) that\nallows for a more explicit control of speech generation. However, the label is\nnot guaranteed to be disentangled from the other latent variables, which\nresults in limited performance improvements compared to the standard\nvariational autoencoder. In this work, we propose to use an adversarial\ntraining scheme for variational autoencoders to disentangle the label from the\nother latent variables. At training, we use a discriminator that competes with\nthe encoder of the variational autoencoder. Simultaneously, we also use an\nadditional encoder that estimates the label for the decoder of the variational\nautoencoder, which proves to be crucial to learn disentanglement. We show the\nbenefit of the proposed disentanglement learning when a voice activity label,\nestimated from visual data, is used for speech enhancement.", "published": "2021-05-19 07:42:14", "link": "http://arxiv.org/abs/2105.08970v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Attack on practical speaker verification system using universal\n  adversarial perturbations", "abstract": "In authentication scenarios, applications of practical speaker verification\nsystems usually require a person to read a dynamic authentication text.\nPrevious studies played an audio adversarial example as a digital signal to\nperform physical attacks, which would be easily rejected by audio replay\ndetection modules. This work shows that by playing our crafted adversarial\nperturbation as a separate source when the adversary is speaking, the practical\nspeaker verification system will misjudge the adversary as a target speaker. A\ntwo-step algorithm is proposed to optimize the universal adversarial\nperturbation to be text-independent and has little effect on the authentication\ntext recognition. We also estimated room impulse response (RIR) in the\nalgorithm which allowed the perturbation to be effective after being played\nover the air. In the physical experiment, we achieved targeted attacks with\nsuccess rate of 100%, while the word error rate (WER) on speech recognition was\nonly increased by 3.55%. And recorded audios could pass replay detection for\nthe live person speaking.", "published": "2021-05-19 09:43:34", "link": "http://arxiv.org/abs/2105.09022v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Music Generation using Three-layered LSTM", "abstract": "This paper explores the idea of utilising Long Short-Term Memory neural\nnetworks (LSTMNN) for the generation of musical sequences in ABC notation. The\nproposed approach takes ABC notations from the Nottingham dataset and encodes\nit to be fed as input for the neural networks. The primary objective is to\ninput the neural networks with an arbitrary note, let the network process and\naugment a sequence based on the note until a good piece of music is produced.\nMultiple calibrations have been done to amend the parameters of the network for\noptimal generation. The output is assessed on the basis of rhythm, harmony, and\ngrammar accuracy.", "published": "2021-05-19 10:27:58", "link": "http://arxiv.org/abs/2105.09046v3", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "XCycles Backprojection Acoustic Super-Resolution", "abstract": "The computer vision community has paid much attention to the development of\nvisible image super-resolution (SR) using deep neural networks (DNNs) and has\nachieved impressive results. The advancement of non-visible light sensors, such\nas acoustic imaging sensors, has attracted much attention, as they allow people\nto visualize the intensity of sound waves beyond the visible spectrum. However,\nbecause of the limitations imposed on acquiring acoustic data, new methods for\nimproving the resolution of the acoustic images are necessary. At this time,\nthere is no acoustic imaging dataset designed for the SR problem. This work\nproposed a novel backprojection model architecture for the acoustic image\nsuper-resolution problem, together with Acoustic Map Imaging VUB-ULB Dataset\n(AMIVU). The dataset provides large simulated and real captured images at\ndifferent resolutions. The proposed XCycles BackProjection model (XCBP), in\ncontrast to the feedforward model approach, fully uses the iterative correction\nprocedure in each cycle to reconstruct the residual error correction for the\nencoded features in both low- and high-resolution space. The proposed approach\nwas evaluated on the dataset and showed high outperformance compared to the\nclassical interpolation operators and to the recent feedforward\nstate-of-the-art models. It also contributed to a drastically reduced\nsub-sampling error produced during the data acquisition.", "published": "2021-05-19 13:43:15", "link": "http://arxiv.org/abs/2105.09128v1", "categories": ["cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Unsupervised Discriminative Learning of Sounds for Audio Event\n  Classification", "abstract": "Recent progress in network-based audio event classification has shown the\nbenefit of pre-training models on visual data such as ImageNet. While this\nprocess allows knowledge transfer across different domains, training a model on\nlarge-scale visual datasets is time consuming. On several audio event\nclassification benchmarks, we show a fast and effective alternative that\npre-trains the model unsupervised, only on audio data and yet delivers on-par\nperformance with ImageNet pre-training. Furthermore, we show that our\ndiscriminative audio learning can be used to transfer knowledge across audio\ndatasets and optionally include ImageNet pre-training.", "published": "2021-05-19 17:42:03", "link": "http://arxiv.org/abs/2105.09279v2", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speech & Song Emotion Recognition Using Multilayer Perceptron and\n  Standard Vector Machine", "abstract": "Herein, we have compared the performance of SVM and MLP in emotion\nrecognition using speech and song channels of the RAVDESS dataset. We have\nundertaken a journey to extract various audio features, identify optimal\nscaling strategy and hyperparameter for our models. To increase sample size, we\nhave performed audio data augmentation and addressed data imbalance using\nSMOTE. Our data indicate that optimised SVM outperforms MLP with an accuracy of\n82 compared to 75%. Following data augmentation, the performance of both\nalgorithms was identical at ~79%, however, overfitting was evident for the SVM.\nOur final exploration indicated that the performance of both SVM and MLP were\nsimilar in which both resulted in lower accuracy for the speech channel\ncompared to the song channel. Our findings suggest that both SVM and MLP are\npowerful classifiers for emotion recognition in a vocal-dependent manner.", "published": "2021-05-19 21:28:05", "link": "http://arxiv.org/abs/2105.09406v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
