{"title": "Pre-training for Abstractive Document Summarization by Reinstating\n  Source Text", "abstract": "Abstractive document summarization is usually modeled as a\nsequence-to-sequence (Seq2Seq) learning problem. Unfortunately, training large\nSeq2Seq based summarization models on limited supervised summarization data is\nchallenging. This paper presents three pre-training objectives which allow us\nto pre-train a Seq2Seq based abstractive summarization model on unlabeled text.\nThe main idea is that, given an input text artificially constructed from a\ndocument, a model is pre-trained to reinstate the original document. These\nobjectives include sentence reordering, next sentence generation, and masked\ndocument generation, which have close relations with the abstractive document\nsummarization task. Experiments on two benchmark summarization datasets (i.e.,\nCNN/DailyMail and New York Times) show that all three objectives can improve\nperformance upon baselines. Compared to models pre-trained on large-scale data\n(more than 160GB), our method, with only 19GB text for pre-training, achieves\ncomparable results, which demonstrates its effectiveness.", "published": "2020-04-04 05:06:26", "link": "http://arxiv.org/abs/2004.01853v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "News-Driven Stock Prediction With Attention-Based Noisy Recurrent State\n  Transition", "abstract": "We consider direct modeling of underlying stock value movement sequences over\ntime in the news-driven stock movement prediction. A recurrent state transition\nmodel is constructed, which better captures a gradual process of stock movement\ncontinuously by modeling the correlation between past and future price\nmovements. By separating the effects of news and noise, a noisy random factor\nis also explicitly fitted based on the recurrent states. Results show that the\nproposed model outperforms strong baselines. Thanks to the use of attention\nover news events, our model is also more explainable. To our knowledge, we are\nthe first to explicitly model both events and noise over a fundamental stock\nvalue state for news-driven stock movement prediction.", "published": "2020-04-04 07:17:16", "link": "http://arxiv.org/abs/2004.01878v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Multimodal Representations on Visual Semantic Textual\n  Similarity", "abstract": "The combination of visual and textual representations has produced excellent\nresults in tasks such as image captioning and visual question answering, but\nthe inference capabilities of multimodal representations are largely untested.\nIn the case of textual representations, inference tasks such as Textual\nEntailment and Semantic Textual Similarity have been often used to benchmark\nthe quality of textual representations. The long term goal of our research is\nto devise multimodal representation techniques that improve current inference\ncapabilities. We thus present a novel task, Visual Semantic Textual Similarity\n(vSTS), where such inference ability can be tested directly. Given two items\ncomprised each by an image and its accompanying caption, vSTS systems need to\nassess the degree to which the captions in context are semantically equivalent\nto each other. Our experiments using simple multimodal representations show\nthat the addition of image representations produces better inference, compared\nto text-only representations. The improvement is observed both when directly\ncomputing the similarity between the representations of the two items, and when\nlearning a siamese network based on vSTS training data. Our work shows, for the\nfirst time, the successful contribution of visual information to textual\ninference, with ample room for benchmarking more complex multimodal\nrepresentation options.", "published": "2020-04-04 09:03:04", "link": "http://arxiv.org/abs/2004.01894v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking Machine Reading Comprehension: A Psychological Perspective", "abstract": "Machine reading comprehension (MRC) has received considerable attention as a\nbenchmark for natural language understanding. However, the conventional task\ndesign of MRC lacks explainability beyond the model interpretation, i.e.,\nreading comprehension by a model cannot be explained in human terms. To this\nend, this position paper provides a theoretical basis for the design of MRC\ndatasets based on psychology as well as psychometrics, and summarizes it in\nterms of the prerequisites for benchmarking MRC. We conclude that future\ndatasets should (i) evaluate the capability of the model for constructing a\ncoherent and grounded representation to understand context-dependent situations\nand (ii) ensure substantive validity by shortcut-proof questions and\nexplanation as a part of the task design.", "published": "2020-04-04 11:45:27", "link": "http://arxiv.org/abs/2004.01912v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"None of the Above\":Measure Uncertainty in Dialog Response Retrieval", "abstract": "This paper discusses the importance of uncovering uncertainty in end-to-end\ndialog tasks, and presents our experimental results on uncertainty\nclassification on the Ubuntu Dialog Corpus. We show that, instead of retraining\nmodels for this specific purpose, the original retrieval model's underlying\nconfidence concerning the best prediction can be captured with trivial\nadditional computation.", "published": "2020-04-04 13:06:03", "link": "http://arxiv.org/abs/2004.01926v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Iterative Multi-Knowledge Transfer Network for Aspect-Based Sentiment\n  Analysis", "abstract": "Aspect-based sentiment analysis (ABSA) mainly involves three subtasks: aspect\nterm extraction, opinion term extraction, and aspect-level sentiment\nclassification, which are typically handled in a separate or joint manner.\nHowever, previous approaches do not well exploit the interactive relations\namong three subtasks and do not pertinently leverage the easily available\ndocument-level labeled domain/sentiment knowledge, which restricts their\nperformances. To address these issues, we propose a novel Iterative\nMulti-Knowledge Transfer Network (IMKTN) for end-to-end ABSA. For one thing,\nthrough the interactive correlations between the ABSA subtasks, our IMKTN\ntransfers the task-specific knowledge from any two of the three subtasks to\nanother one at the token level by utilizing a well-designed routing algorithm,\nthat is, any two of the three subtasks will help the third one. For another,\nour IMKTN pertinently transfers the document-level knowledge, i.e.,\ndomain-specific and sentiment-related knowledge, to the aspect-level subtasks\nto further enhance the corresponding performance. Experimental results on three\nbenchmark datasets demonstrate the effectiveness and superiority of our\napproach.", "published": "2020-04-04 13:49:54", "link": "http://arxiv.org/abs/2004.01935v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pre-Trained and Attention-Based Neural Networks for Building Noetic\n  Task-Oriented Dialogue Systems", "abstract": "The NOESIS II challenge, as the Track 2 of the 8th Dialogue System Technology\nChallenges (DSTC 8), is the extension of DSTC 7. This track incorporates new\nelements that are vital for the creation of a deployed task-oriented dialogue\nsystem. This paper describes our systems that are evaluated on all subtasks\nunder this challenge. We study the problem of employing pre-trained\nattention-based network for multi-turn dialogue systems. Meanwhile, several\nadaptation methods are proposed to adapt the pre-trained language models for\nmulti-turn dialogue systems, in order to keep the intrinsic property of\ndialogue systems. In the released evaluation results of Track 2 of DSTC 8, our\nproposed models ranked fourth in subtask 1, third in subtask 2, and first in\nsubtask 3 and subtask 4 respectively.", "published": "2020-04-04 14:14:43", "link": "http://arxiv.org/abs/2004.01940v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Dependency Syntactic Knowledge Augmented Interactive Architecture for\n  End-to-End Aspect-based Sentiment Analysis", "abstract": "The aspect-based sentiment analysis (ABSA) task remains to be a long-standing\nchallenge, which aims to extract the aspect term and then identify its\nsentiment orientation.In previous approaches, the explicit syntactic structure\nof a sentence, which reflects the syntax properties of natural language and\nhence is intuitively crucial for aspect term extraction and sentiment\nrecognition, is typically neglected or insufficiently modeled. In this paper,\nwe thus propose a novel dependency syntactic knowledge augmented interactive\narchitecture with multi-task learning for end-to-end ABSA. This model is\ncapable of fully exploiting the syntactic knowledge (dependency relations and\ntypes) by leveraging a well-designed Dependency Relation Embedded Graph\nConvolutional Network (DreGcn). Additionally, we design a simple yet effective\nmessage-passing mechanism to ensure that our model learns from multiple related\ntasks in a multi-task learning framework. Extensive experimental results on\nthree benchmark datasets demonstrate the effectiveness of our approach, which\nsignificantly outperforms existing state-of-the-art methods. Besides, we\nachieve further improvements by using BERT as an additional feature extractor.", "published": "2020-04-04 14:59:32", "link": "http://arxiv.org/abs/2004.01951v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BAE: BERT-based Adversarial Examples for Text Classification", "abstract": "Modern text classification models are susceptible to adversarial examples,\nperturbed versions of the original text indiscernible by humans which get\nmisclassified by the model. Recent works in NLP use rule-based synonym\nreplacement strategies to generate adversarial examples. These strategies can\nlead to out-of-context and unnaturally complex token replacements, which are\neasily identifiable by humans. We present BAE, a black box attack for\ngenerating adversarial examples using contextual perturbations from a BERT\nmasked language model. BAE replaces and inserts tokens in the original text by\nmasking a portion of the text and leveraging the BERT-MLM to generate\nalternatives for the masked tokens. Through automatic and human evaluations, we\nshow that BAE performs a stronger attack, in addition to generating adversarial\nexamples with improved grammaticality and semantic coherence as compared to\nprior work.", "published": "2020-04-04 16:25:48", "link": "http://arxiv.org/abs/2004.01970v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning a Simple and Effective Model for Multi-turn Response Generation\n  with Auxiliary Tasks", "abstract": "We study multi-turn response generation for open-domain dialogues. The\nexisting state-of-the-art addresses the problem with deep neural architectures.\nWhile these models improved response quality, their complexity also hinders the\napplication of the models in real systems. In this work, we pursue a model that\nhas a simple structure yet can effectively leverage conversation contexts for\nresponse generation. To this end, we propose four auxiliary tasks including\nword order recovery, utterance order recovery, masked word recovery, and masked\nutterance recovery, and optimize the objectives of these tasks together with\nmaximizing the likelihood of generation. By this means, the auxiliary tasks\nthat relate to context understanding can guide the learning of the generation\nmodel to achieve a better local optimum. Empirical studies with three\nbenchmarks indicate that our model can significantly outperform\nstate-of-the-art generation models in terms of response quality on both\nautomatic evaluation and human judgment, and at the same time enjoys a much\nfaster decoding process.", "published": "2020-04-04 16:37:00", "link": "http://arxiv.org/abs/2004.01972v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Hierarchical Explanations on Text Classification via Feature\n  Interaction Detection", "abstract": "Generating explanations for neural networks has become crucial for their\napplications in real-world with respect to reliability and trustworthiness. In\nnatural language processing, existing methods usually provide important\nfeatures which are words or phrases selected from an input text as an\nexplanation, but ignore the interactions between them. It poses challenges for\nhumans to interpret an explanation and connect it to model prediction. In this\nwork, we build hierarchical explanations by detecting feature interactions.\nSuch explanations visualize how words and phrases are combined at different\nlevels of the hierarchy, which can help users understand the decision-making of\nblack-box models. The proposed method is evaluated with three neural text\nclassifiers (LSTM, CNN, and BERT) on two benchmark datasets, via both automatic\nand human evaluations. Experiments show the effectiveness of the proposed\nmethod in providing explanations that are both faithful to models and\ninterpretable to humans.", "published": "2020-04-04 20:56:37", "link": "http://arxiv.org/abs/2004.02015v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Hierarchical Network for Abstractive Meeting Summarization with\n  Cross-Domain Pretraining", "abstract": "With the abundance of automatic meeting transcripts, meeting summarization is\nof great interest to both participants and other parties. Traditional methods\nof summarizing meetings depend on complex multi-step pipelines that make joint\noptimization intractable. Meanwhile, there are a handful of deep neural models\nfor text summarization and dialogue systems. However, the semantic structure\nand styles of meeting transcripts are quite different from articles and\nconversations. In this paper, we propose a novel abstractive summary network\nthat adapts to the meeting scenario. We design a hierarchical structure to\naccommodate long meeting transcripts and a role vector to depict the difference\namong speakers. Furthermore, due to the inadequacy of meeting summary data, we\npretrain the model on large-scale news summary data. Empirical results show\nthat our model outperforms previous approaches in both automatic metrics and\nhuman evaluation. For example, on ICSI dataset, the ROUGE-1 score increases\nfrom 34.66% to 46.28%.", "published": "2020-04-04 21:00:41", "link": "http://arxiv.org/abs/2004.02016v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aggressive, Repetitive, Intentional, Visible, and Imbalanced: Refining\n  Representations for Cyberbullying Classification", "abstract": "Cyberbullying is a pervasive problem in online communities. To identify\ncyberbullying cases in large-scale social networks, content moderators depend\non machine learning classifiers for automatic cyberbullying detection. However,\nexisting models remain unfit for real-world applications, largely due to a\nshortage of publicly available training data and a lack of standard criteria\nfor assigning ground truth labels. In this study, we address the need for\nreliable data using an original annotation framework. Inspired by social\nsciences research into bullying behavior, we characterize the nuanced problem\nof cyberbullying using five explicit factors to represent its social and\nlinguistic aspects. We model this behavior using social network and\nlanguage-based features, which improve classifier performance. These results\ndemonstrate the importance of representing and modeling cyberbullying as a\nsocial phenomenon.", "published": "2020-04-04 00:35:16", "link": "http://arxiv.org/abs/2004.01820v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "CG-BERT: Conditional Text Generation with BERT for Generalized Few-shot\n  Intent Detection", "abstract": "In this paper, we formulate a more realistic and difficult problem setup for\nthe intent detection task in natural language understanding, namely Generalized\nFew-Shot Intent Detection (GFSID). GFSID aims to discriminate a joint label\nspace consisting of both existing intents which have enough labeled data and\nnovel intents which only have a few examples for each class. To approach this\nproblem, we propose a novel model, Conditional Text Generation with BERT\n(CG-BERT). CG-BERT effectively leverages a large pre-trained language model to\ngenerate text conditioned on the intent label. By modeling the utterance\ndistribution with variational inference, CG-BERT can generate diverse\nutterances for the novel intents even with only a few utterances available.\nExperimental results show that CG-BERT achieves state-of-the-art performance on\nthe GFSID task with 1-shot and 5-shot settings on two real-world datasets.", "published": "2020-04-04 07:31:59", "link": "http://arxiv.org/abs/2004.01881v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Talk to Papers: Bringing Neural Question Answering to Academic Search", "abstract": "We introduce Talk to Papers, which exploits the recent open-domain question\nanswering (QA) techniques to improve the current experience of academic search.\nIt's designed to enable researchers to use natural language queries to find\nprecise answers and extract insights from a massive amount of academic papers.\nWe present a large improvement over classic search engine baseline on several\nstandard QA datasets and provide the community a collaborative data collection\ntool to curate the first natural language processing research QA dataset via a\ncommunity effort.", "published": "2020-04-04 19:19:55", "link": "http://arxiv.org/abs/2004.02002v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Recognizing Long Grammatical Sequences Using Recurrent Networks\n  Augmented With An External Differentiable Stack", "abstract": "Recurrent neural networks (RNNs) are a widely used deep architecture for\nsequence modeling, generation, and prediction. Despite success in applications\nsuch as machine translation and voice recognition, these stateful models have\nseveral critical shortcomings. Specifically, RNNs generalize poorly over very\nlong sequences, which limits their applicability to many important temporal\nprocessing and time series forecasting problems. For example, RNNs struggle in\nrecognizing complex context free languages (CFLs), never reaching 100% accuracy\non training. One way to address these shortcomings is to couple an RNN with an\nexternal, differentiable memory structure, such as a stack. However,\ndifferentiable memories in prior work have neither been extensively studied on\nCFLs nor tested on sequences longer than those seen in training. The few\nefforts that have studied them have shown that continuous differentiable memory\nstructures yield poor generalization for complex CFLs, making the RNN less\ninterpretable. In this paper, we improve the memory-augmented RNN with\nimportant architectural and state updating mechanisms that ensure that the\nmodel learns to properly balance the use of its latent states with external\nmemory. Our improved RNN models exhibit better generalization performance and\nare able to classify long strings generated by complex hierarchical context\nfree grammars (CFGs). We evaluate our models on CGGs, including the Dyck\nlanguages, as well as on the Penn Treebank language modelling task, and achieve\nstable, robust performance across these benchmarks. Furthermore, we show that\nonly our memory-augmented networks are capable of retaining memory for a longer\nduration up to strings of length 160.", "published": "2020-04-04 14:19:15", "link": "http://arxiv.org/abs/2004.07623v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Identifying Radiological Findings Related to COVID-19 from Medical\n  Literature", "abstract": "Coronavirus disease 2019 (COVID-19) has infected more than one million\nindividuals all over the world and caused more than 55,000 deaths, as of April\n3 in 2020. Radiological findings are important sources of information in\nguiding the diagnosis and treatment of COVID-19. However, the existing studies\non how radiological findings are correlated with COVID-19 are conducted\nseparately by different hospitals, which may be inconsistent or even\nconflicting due to population bias. To address this problem, we develop natural\nlanguage processing methods to analyze a large collection of COVID-19\nliterature containing study reports from hospitals all over the world,\nreconcile these results, and draw unbiased and universally-sensible conclusions\nabout the correlation between radiological findings and COVID-19. We apply our\nmethod to the CORD-19 dataset and successfully extract a set of radiological\nfindings that are closely tied to COVID-19.", "published": "2020-04-04 05:33:21", "link": "http://arxiv.org/abs/2004.01862v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "eess.IV"], "primary_category": "cs.IR"}
{"title": "ForecastTB An R Package as a Test-Bench for Time Series Forecasting\n  Application of Wind Speed and Solar Radiation Modeling", "abstract": "This paper introduces an R package ForecastTB that can be used to compare the\naccuracy of different forecasting methods as related to the characteristics of\na time series dataset. The ForecastTB is a plug-and-play structured module, and\nseveral forecasting methods can be included with simple instructions. The\nproposed test-bench is not limited to the default forecasting and error metric\nfunctions, and users are able to append, remove, or choose the desired methods\nas per requirements. Besides, several plotting functions and statistical\nperformance metrics are provided to visualize the comparative performance and\naccuracy of different forecasting methods. Furthermore, this paper presents\nreal application examples with natural time series datasets (i.e., wind speed\nand solar radiation) to exhibit the features of the ForecastTB package to\nevaluate forecasting comparison analysis as affected by the characteristics of\na dataset. Modeling results indicated the applicability and robustness of the\nproposed R package ForecastTB for time series forecasting.", "published": "2020-04-04 08:52:19", "link": "http://arxiv.org/abs/2004.01893v2", "categories": ["stat.ME", "cs.CL", "cs.LG"], "primary_category": "stat.ME"}
{"title": "Knowledge Guided Metric Learning for Few-Shot Text Classification", "abstract": "The training of deep-learning-based text classification models relies heavily\non a huge amount of annotation data, which is difficult to obtain. When the\nlabeled data is scarce, models tend to struggle to achieve satisfactory\nperformance. However, human beings can distinguish new categories very\nefficiently with few examples. This is mainly due to the fact that human beings\ncan leverage knowledge obtained from relevant tasks. Inspired by human\nintelligence, we propose to introduce external knowledge into few-shot learning\nto imitate human knowledge. A novel parameter generator network is investigated\nto this end, which is able to use the external knowledge to generate relation\nnetwork parameters. Metrics can be transferred among tasks when equipped with\nthese generated parameters, so that similar tasks use similar metrics while\ndifferent tasks use different metrics. Through experiments, we demonstrate that\nour method outperforms the state-of-the-art few-shot text classification\nmodels.", "published": "2020-04-04 10:56:26", "link": "http://arxiv.org/abs/2004.01907v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Conversational Question Reformulation via Sequence-to-Sequence\n  Architectures and Pretrained Language Models", "abstract": "This paper presents an empirical study of conversational question\nreformulation (CQR) with sequence-to-sequence architectures and pretrained\nlanguage models (PLMs). We leverage PLMs to address the strong token-to-token\nindependence assumption made in the common objective, maximum likelihood\nestimation, for the CQR task. In CQR benchmarks of task-oriented dialogue\nsystems, we evaluate fine-tuned PLMs on the recently-introduced CANARD dataset\nas an in-domain task and validate the models using data from the TREC 2019 CAsT\nTrack as an out-domain task. Examining a variety of architectures with\ndifferent numbers of parameters, we demonstrate that the recent text-to-text\ntransfer transformer (T5) achieves the best results both on CANARD and CAsT\nwith fewer parameters, compared to similar transformer architectures.", "published": "2020-04-04 11:07:54", "link": "http://arxiv.org/abs/2004.01909v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hooks in the Headline: Learning to Generate Headlines with Controlled\n  Styles", "abstract": "Current summarization systems only produce plain, factual headlines, but do\nnot meet the practical needs of creating memorable titles to increase exposure.\nWe propose a new task, Stylistic Headline Generation (SHG), to enrich the\nheadlines with three style options (humor, romance and clickbait), in order to\nattract more readers. With no style-specific article-headline pair (only a\nstandard headline summarization dataset and mono-style corpora), our method\nTitleStylist generates style-specific headlines by combining the summarization\nand reconstruction tasks into a multitasking framework. We also introduced a\nnovel parameter sharing scheme to further disentangle the style from the text.\nThrough both automatic and human evaluation, we demonstrate that TitleStylist\ncan generate relevant, fluent headlines with three target styles: humor,\nromance, and clickbait. The attraction score of our model generated headlines\nsurpasses that of the state-of-the-art summarization model by 9.68%, and even\noutperforms human-written references.", "published": "2020-04-04 17:24:47", "link": "http://arxiv.org/abs/2004.01980v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Open Domain Dialogue Generation with Latent Images", "abstract": "We consider grounding open domain dialogues with images. Existing work\nassumes that both an image and a textual context are available, but\nimage-grounded dialogues by nature are more difficult to obtain than textual\ndialogues. Thus, we propose learning a response generation model with both\nimage-grounded dialogues and textual dialogues by assuming that the visual\nscene information at the time of a conversation can be represented by an image,\nand trying to recover the latent images of the textual dialogues through\ntext-to-image generation techniques. The likelihood of the two types of\ndialogues is then formulated by a response generator and an image reconstructor\nthat are learned within a conditional variational auto-encoding framework.\nEmpirical studies are conducted in both image-grounded conversation and\ntext-based conversation. In the first scenario, image-grounded dialogues,\nespecially under a low-resource setting, can be effectively augmented by\ntextual dialogues with latent images; while in the second scenario, latent\nimages can enrich the content of responses and at the same time keep them\nrelevant to contexts.", "published": "2020-04-04 17:32:46", "link": "http://arxiv.org/abs/2004.01981v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Graph Sequential Network for Reasoning over Sequences", "abstract": "Recently Graph Neural Network (GNN) has been applied successfully to various\nNLP tasks that require reasoning, such as multi-hop machine reading\ncomprehension. In this paper, we consider a novel case where reasoning is\nneeded over graphs built from sequences, i.e. graph nodes with sequence data.\nExisting GNN models fulfill this goal by first summarizing the node sequences\ninto fixed-dimensional vectors, then applying GNN on these vectors. To avoid\ninformation loss inherent in the early summarization and make sequential\nlabeling tasks on GNN output feasible, we propose a new type of GNN called\nGraph Sequential Network (GSN), which features a new message passing algorithm\nbased on co-attention between a node and each of its neighbors. We validate the\nproposed GSN on two NLP tasks: interpretable multi-hop reading comprehension on\nHotpotQA and graph based fact verification on FEVER. Both tasks require\nreasoning over multiple documents or sentences. Our experimental results show\nthat the proposed GSN attains better performance than the standard GNN based\nmethods.", "published": "2020-04-04 19:18:54", "link": "http://arxiv.org/abs/2004.02001v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generating Rationales in Visual Question Answering", "abstract": "Despite recent advances in Visual QuestionAnswering (VQA), it remains a\nchallenge todetermine how much success can be attributedto sound reasoning and\ncomprehension ability.We seek to investigate this question by propos-ing a new\ntask ofrationale generation. Es-sentially, we task a VQA model with generat-ing\nrationales for the answers it predicts. Weuse data from the Visual Commonsense\nRea-soning (VCR) task, as it contains ground-truthrationales along with visual\nquestions and an-swers. We first investigate commonsense un-derstanding in one\nof the leading VCR mod-els, ViLBERT, by generating rationales frompretrained\nweights using a state-of-the-art lan-guage model, GPT-2. Next, we seek to\njointlytrain ViLBERT with GPT-2 in an end-to-endfashion with the dual task of\npredicting the an-swer in VQA and generating rationales. Weshow that this kind\nof training injects com-monsense understanding in the VQA modelthrough\nquantitative and qualitative evaluationmetrics", "published": "2020-04-04 22:15:35", "link": "http://arxiv.org/abs/2004.02032v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Subband modeling for spoofing detection in automatic speaker\n  verification", "abstract": "Spectrograms - time-frequency representations of audio signals - have found\nwidespread use in neural network-based spoofing detection. While deep models\nare trained on the fullband spectrum of the signal, we argue that not all\nfrequency bands are useful for these tasks. In this paper, we systematically\ninvestigate the impact of different subbands and their importance on replay\nspoofing detection on two benchmark datasets: ASVspoof 2017 v2.0 and ASVspoof\n2019 PA. We propose a joint subband modelling framework that employs n\ndifferent sub-networks to learn subband specific features. These are later\ncombined and passed to a classifier and the whole network weights are updated\nduring training. Our findings on the ASVspoof 2017 dataset suggest that the\nmost discriminative information appears to be in the first and the last 1 kHz\nfrequency bands, and the joint model trained on these two subbands shows the\nbest performance outperforming the baselines by a large margin. However, these\nfindings do not generalise on the ASVspoof 2019 PA dataset. This suggests that\nthe datasets available for training these models do not reflect real world\nreplay conditions suggesting a need for careful design of datasets for training\nreplay spoofing countermeasures.", "published": "2020-04-04 12:49:21", "link": "http://arxiv.org/abs/2004.01922v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "CNN-MoE based framework for classification of respiratory anomalies and\n  lung disease detection", "abstract": "This paper presents and explores a robust deep learning framework for\nauscultation analysis. This aims to classify anomalies in respiratory cycles\nand detect disease, from respiratory sound recordings. The framework begins\nwith front-end feature extraction that transforms input sound into a\nspectrogram representation. Then, a back-end deep learning network is used to\nclassify the spectrogram features into categories of respiratory anomaly cycles\nor diseases. Experiments, conducted over the ICBHI benchmark dataset of\nrespiratory sounds, confirm three main contributions towards respiratory-sound\nanalysis. Firstly, we carry out an extensive exploration of the effect of\nspectrogram type, spectral-time resolution, overlapped/non-overlapped windows,\nand data augmentation on final prediction accuracy. This leads us to propose a\nnovel deep learning system, built on the proposed framework, which outperforms\ncurrent state-of-the-art methods. Finally, we apply a Teacher-Student scheme to\nachieve a trade-off between model performance and model complexity which\nadditionally helps to increase the potential of the proposed framework for\nbuilding real-time applications.", "published": "2020-04-04 21:45:06", "link": "http://arxiv.org/abs/2004.04072v2", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
