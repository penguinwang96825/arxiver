{"title": "Finding structure in logographic writing with library learning", "abstract": "One hallmark of human language is its combinatoriality -- reusing a\nrelatively small inventory of building blocks to create a far larger inventory\nof increasingly complex structures. In this paper, we explore the idea that\ncombinatoriality in language reflects a human inductive bias toward\nrepresentational efficiency in symbol systems. We develop a computational\nframework for discovering structure in a writing system. Built on top of\nstate-of-the-art library learning and program synthesis techniques, our\ncomputational framework discovers known linguistic structures in the Chinese\nwriting system and reveals how the system evolves towards simplification under\npressures for representational efficiency. We demonstrate how a library\nlearning approach, utilizing learned abstractions and compression, may help\nreveal the fundamental computational principles that underlie the creation of\ncombinatorial structures in human cognition, and offer broader insights into\nthe evolution of efficient communication systems.", "published": "2024-05-11 04:23:53", "link": "http://arxiv.org/abs/2405.06906v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EmoMix-3L: A Code-Mixed Dataset for Bangla-English-Hindi Emotion\n  Detection", "abstract": "Code-mixing is a well-studied linguistic phenomenon that occurs when two or\nmore languages are mixed in text or speech. Several studies have been conducted\non building datasets and performing downstream NLP tasks on code-mixed data.\nAlthough it is not uncommon to observe code-mixing of three or more languages,\nmost available datasets in this domain contain code-mixed data from only two\nlanguages. In this paper, we introduce EmoMix-3L, a novel multi-label emotion\ndetection dataset containing code-mixed data from three different languages. We\nexperiment with several models on EmoMix-3L and we report that MuRIL\noutperforms other models on this dataset.", "published": "2024-05-11 05:58:55", "link": "http://arxiv.org/abs/2405.06922v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quite Good, but Not Enough: Nationality Bias in Large Language Models --\n  A Case Study of ChatGPT", "abstract": "While nationality is a pivotal demographic element that enhances the\nperformance of language models, it has received far less scrutiny regarding\ninherent biases. This study investigates nationality bias in ChatGPT (GPT-3.5),\na large language model (LLM) designed for text generation. The research covers\n195 countries, 4 temperature settings, and 3 distinct prompt types, generating\n4,680 discourses about nationality descriptions in Chinese and English.\nAutomated metrics were used to analyze the nationality bias, and expert\nannotators alongside ChatGPT itself evaluated the perceived bias. The results\nshow that ChatGPT's generated discourses are predominantly positive, especially\ncompared to its predecessor, GPT-2. However, when prompted with negative\ninclinations, it occasionally produces negative content. Despite ChatGPT\nconsidering its generated text as neutral, it shows consistent self-awareness\nabout nationality bias when subjected to the same pair-wise comparison\nannotation framework used by human annotators. In conclusion, while ChatGPT's\ngenerated texts seem friendly and positive, they reflect the inherent\nnationality biases in the real world. This bias may vary across different\nlanguage versions of ChatGPT, indicating diverse cultural perspectives. The\nstudy highlights the subtle and pervasive nature of biases within LLMs,\nemphasizing the need for further scrutiny.", "published": "2024-05-11 12:11:52", "link": "http://arxiv.org/abs/2405.06996v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word-specific tonal realizations in Mandarin", "abstract": "The pitch contours of Mandarin two-character words are generally understood\nas being shaped by the underlying tones of the constituent single-character\nwords, in interaction with articulatory constraints imposed by factors such as\nspeech rate, co-articulation with adjacent tones, segmental make-up, and\npredictability. This study shows that tonal realization is also partially\ndetermined by words' meanings. We first show, on the basis of a corpus of\nTaiwan Mandarin spontaneous conversations, using a generalized additive\nregression model, and focusing on the rise-fall tone pattern, that after\ncontrolling for effects of speaker and context, word type is a stronger\npredictor of tonal realization than all the previously established word-form\nrelated predictors combined. Importantly, the addition of information about\nmeaning in context improves prediction accuracy even further. We then proceed\nto show, using computational modeling with context-specific word embeddings,\nthat token-specific pitch contours predict word type with 50% accuracy on\nheld-out data, and that context-sensitive, token-specific embeddings can\npredict the shape of pitch contours with 40% accuracy. These accuracies, which\nare an order of magnitude above chance level, suggest that the relation between\nwords' pitch contours and their meanings are sufficiently strong to be\npotentially functional for language users. The theoretical implications of\nthese empirical findings are discussed.", "published": "2024-05-11 13:00:35", "link": "http://arxiv.org/abs/2405.07006v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Turkish Educational Crossword Puzzle Generator", "abstract": "This paper introduces the first Turkish crossword puzzle generator designed\nto leverage the capabilities of large language models (LLMs) for educational\npurposes. In this work, we introduced two specially created datasets: one with\nover 180,000 unique answer-clue pairs for generating relevant clues from the\ngiven answer, and another with over 35,000 samples containing text, answer,\ncategory, and clue data, aimed at producing clues for specific texts and\nkeywords within certain categories. Beyond entertainment, this generator\nemerges as an interactive educational tool that enhances memory, vocabulary,\nand problem-solving skills. It's a notable step in AI-enhanced education,\nmerging game-like engagement with learning for Turkish and setting new\nstandards for interactive, intelligent learning tools in Turkish.", "published": "2024-05-11 15:18:56", "link": "http://arxiv.org/abs/2405.07035v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Length-Aware Multi-Kernel Transformer for Long Document Classification", "abstract": "Lengthy documents pose a unique challenge to neural language models due to\nsubstantial memory consumption. While existing state-of-the-art (SOTA) models\nsegment long texts into equal-length snippets (e.g., 128 tokens per snippet) or\ndeploy sparse attention networks, these methods have new challenges of context\nfragmentation and generalizability due to sentence boundaries and varying text\nlengths. For example, our empirical analysis has shown that SOTA models\nconsistently overfit one set of lengthy documents (e.g., 2000 tokens) while\nperforming worse on texts with other lengths (e.g., 1000 or 4000). In this\nstudy, we propose a Length-Aware Multi-Kernel Transformer (LAMKIT) to address\nthe new challenges for the long document classification. LAMKIT encodes lengthy\ndocuments by diverse transformer-based kernels for bridging context boundaries\nand vectorizes text length by the kernels to promote model robustness over\nvarying document lengths. Experiments on five standard benchmarks from health\nand law domains show LAMKIT outperforms SOTA models up to an absolute 10.9%\nimprovement. We conduct extensive ablation analyses to examine model robustness\nand effectiveness over varying document lengths.", "published": "2024-05-11 16:48:06", "link": "http://arxiv.org/abs/2405.07052v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Pretrained Contextual Language Models Distinguish between Hebrew\n  Homograph Analyses?", "abstract": "Semitic morphologically-rich languages (MRLs) are characterized by extreme\nword ambiguity. Because most vowels are omitted in standard texts, many of the\nwords are homographs with multiple possible analyses, each with a different\npronunciation and different morphosyntactic properties. This ambiguity goes\nbeyond word-sense disambiguation (WSD), and may include token segmentation into\nmultiple word units. Previous research on MRLs claimed that standardly trained\npre-trained language models (PLMs) based on word-pieces may not sufficiently\ncapture the internal structure of such tokens in order to distinguish between\nthese analyses. Taking Hebrew as a case study, we investigate the extent to\nwhich Hebrew homographs can be disambiguated and analyzed using PLMs. We\nevaluate all existing models for contextualized Hebrew embeddings on a novel\nHebrew homograph challenge sets that we deliver. Our empirical results\ndemonstrate that contemporary Hebrew contextualized embeddings outperform\nnon-contextualized embeddings; and that they are most effective for\ndisambiguating segmentation and morphosyntactic features, less so regarding\npure word-sense disambiguation. We show that these embeddings are more\neffective when the number of word-piece splits is limited, and they are more\neffective for 2-way and 3-way ambiguities than for 4-way ambiguity. We show\nthat the embeddings are equally effective for homographs of both balanced and\nskewed distributions, whether calculated as masked or unmasked tokens. Finally,\nwe show that these embeddings are as effective for homograph disambiguation\nwith extensive supervised training as with a few-shot setup.", "published": "2024-05-11 21:50:56", "link": "http://arxiv.org/abs/2405.07099v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Designing and Evaluating Dialogue LLMs for Co-Creative Improvised\n  Theatre", "abstract": "Social robotics researchers are increasingly interested in multi-party\ntrained conversational agents. With a growing demand for real-world\nevaluations, our study presents Large Language Models (LLMs) deployed in a\nmonth-long live show at the Edinburgh Festival Fringe. This case study\ninvestigates human improvisers co-creating with conversational agents in a\nprofessional theatre setting. We explore the technical capabilities and\nconstraints of on-the-spot multi-party dialogue, providing comprehensive\ninsights from both audience and performer experiences with AI on stage. Our\nhuman-in-the-loop methodology underlines the challenges of these LLMs in\ngenerating context-relevant responses, stressing the user interface's crucial\nrole. Audience feedback indicates an evolving interest for AI-driven live\nentertainment, direct human-AI interaction, and a diverse range of expectations\nabout AI's conversational competence and utility as a creativity support tool.\nHuman performers express immense enthusiasm, varied satisfaction, and the\nevolving public opinion highlights mixed emotions about AI's role in arts.", "published": "2024-05-11 23:19:42", "link": "http://arxiv.org/abs/2405.07111v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TacoERE: Cluster-aware Compression for Event Relation Extraction", "abstract": "Event relation extraction (ERE) is a critical and fundamental challenge for\nnatural language processing. Existing work mainly focuses on directly modeling\nthe entire document, which cannot effectively handle long-range dependencies\nand information redundancy. To address these issues, we propose a cluster-aware\ncompression method for improving event relation extraction (TacoERE), which\nexplores a compression-then-extraction paradigm. Specifically, we first\nintroduce document clustering for modeling event dependencies. It splits the\ndocument into intra- and inter-clusters, where intra-clusters aim to enhance\nthe relations within the same cluster, while inter-clusters attempt to model\nthe related events at arbitrary distances. Secondly, we utilize cluster\nsummarization to simplify and highlight important text content of clusters for\nmitigating information redundancy and event distance. We have conducted\nextensive experiments on both pre-trained language models, such as RoBERTa, and\nlarge language models, such as ChatGPT and GPT-4, on three ERE datasets, i.e.,\nMAVEN-ERE, EventStoryLine and HiEve. Experimental results demonstrate that\nTacoERE is an effective method for ERE.", "published": "2024-05-11 03:06:08", "link": "http://arxiv.org/abs/2405.06890v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automating Thematic Analysis: How LLMs Analyse Controversial Topics", "abstract": "Large Language Models (LLMs) are promising analytical tools. They can augment\nhuman epistemic, cognitive and reasoning abilities, and support 'sensemaking',\nmaking sense of a complex environment or subject by analysing large volumes of\ndata with a sensitivity to context and nuance absent in earlier text processing\nsystems. This paper presents a pilot experiment that explores how LLMs can\nsupport thematic analysis of controversial topics. We compare how human\nresearchers and two LLMs GPT-4 and Llama 2 categorise excerpts from media\ncoverage of the controversial Australian Robodebt scandal. Our findings\nhighlight intriguing overlaps and variances in thematic categorisation between\nhuman and machine agents, and suggest where LLMs can be effective in supporting\nforms of discourse and thematic analysis. We argue LLMs should be used to\naugment, and not replace human interpretation, and we add further\nmethodological insights and reflections to existing research on the application\nof automation to qualitative research methods. We also introduce a novel\ncard-based design toolkit, for both researchers and practitioners to further\ninterrogate LLMs as analytical tools.", "published": "2024-05-11 05:28:25", "link": "http://arxiv.org/abs/2405.06919v1", "categories": ["cs.CY", "cs.CL", "K.4.2"], "primary_category": "cs.CY"}
{"title": "Piccolo2: General Text Embedding with Multi-task Hybrid Loss Training", "abstract": "In this report, we introduce Piccolo2, an embedding model that surpasses\nother models in the comprehensive evaluation over 6 tasks on CMTEB benchmark,\nsetting a new state-of-the-art. Piccolo2 primarily leverages an efficient\nmulti-task hybrid loss training approach, effectively harnessing textual data\nand labels from diverse downstream tasks. In addition, Piccolo2 scales up the\nembedding dimension and uses MRL training to support more flexible vector\ndimensions. The latest information of piccolo models can be accessed via:\nhttps://huggingface.co/sensenova/", "published": "2024-05-11 06:32:08", "link": "http://arxiv.org/abs/2405.06932v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AraSpell: A Deep Learning Approach for Arabic Spelling Correction", "abstract": "Spelling correction is the task of identifying spelling mistakes, typos, and\ngrammatical mistakes in a given text and correcting them according to their\ncontext and grammatical structure. This work introduces \"AraSpell,\" a framework\nfor Arabic spelling correction using different seq2seq model architectures such\nas Recurrent Neural Network (RNN) and Transformer with artificial data\ngeneration for error injection, trained on more than 6.9 Million Arabic\nsentences. Thorough experimental studies provide empirical evidence of the\neffectiveness of the proposed approach, which achieved 4.8% and 1.11% word\nerror rate (WER) and character error rate (CER), respectively, in comparison\nwith labeled data of 29.72% WER and 5.03% CER. Our approach achieved 2.9% CER\nand 10.65% WER in comparison with labeled data of 10.02% CER and 50.94% WER.\nBoth of these results are obtained on a test set of 100K sentences.", "published": "2024-05-11 10:36:28", "link": "http://arxiv.org/abs/2405.06981v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deciphering public attention to geoengineering and climate issues using\n  machine learning and dynamic analysis", "abstract": "As the conversation around using geoengineering to combat climate change\nintensifies, it is imperative to engage the public and deeply understand their\nperspectives on geoengineering research, development, and potential deployment.\nThrough a comprehensive data-driven investigation, this paper explores the\ntypes of news that captivate public interest in geoengineering. We delved into\n30,773 English-language news articles from the BBC and the New York Times,\ncombined with Google Trends data spanning 2018 to 2022, to explore how public\ninterest in geoengineering fluctuates in response to news coverage of broader\nclimate issues. Using BERT-based topic modeling, sentiment analysis, and\ntime-series regression models, we found that positive sentiment in\nenergy-related news serves as a good predictor of heightened public interest in\ngeoengineering, a trend that persists over time. Our findings suggest that\npublic engagement with geoengineering and climate action is not uniform, with\nsome topics being more potent in shaping interest over time, such as climate\nnews related to energy, disasters, and politics. Understanding these patterns\nis crucial for scientists, policymakers, and educators aiming to craft\neffective strategies for engaging with the public and fostering dialogue around\nemerging climate technologies.", "published": "2024-05-11 13:10:57", "link": "http://arxiv.org/abs/2405.07010v1", "categories": ["cs.CY", "cs.CL", "J.4; K.4"], "primary_category": "cs.CY"}
{"title": "Integrating Emotional and Linguistic Models for Ethical Compliance in\n  Large Language Models", "abstract": "This research develops advanced methodologies for Large Language Models\n(LLMs) to better manage linguistic behaviors related to emotions and ethics. We\nintroduce DIKE, an adversarial framework that enhances the LLMs' ability to\ninternalize and reflect global human values, adapting to varied cultural\ncontexts to promote transparency and trust among users. The methodology\ninvolves detailed modeling of emotions, classification of linguistic behaviors,\nand implementation of ethical guardrails. Our innovative approaches include\nmapping emotions and behaviors using self-supervised learning techniques,\nrefining these guardrails through adversarial reviews, and systematically\nadjusting outputs to ensure ethical alignment. This framework establishes a\nrobust foundation for AI systems to operate with ethical integrity and cultural\nsensitivity, paving the way for more responsible and context-aware AI\ninteractions.", "published": "2024-05-11 19:26:00", "link": "http://arxiv.org/abs/2405.07076v2", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "T-curator: a trust based curation tool for LOD logs", "abstract": "Nowadays, companies are racing towards Linked Open Data (LOD) to improve\ntheir added value, but they are ignoring their SPARQL query logs. If well\ncurated, these logs can present an asset for decision makers. A naive and\nstraightforward use of these logs is too risky because their provenance and\nquality are highly questionable. Users of these logs in a trusted way have to\nbe assisted by providing them with in-depth knowledge of the whole LOD\nenvironment and tools to curate these logs. In this paper, we propose an\ninteractive and intuitive trust based tool that can be used to curate these LOD\nlogs before exploiting them. This tool is proposed to support our approach\nproposed in our previous work Lanasri et al. [2020].", "published": "2024-05-11 19:32:27", "link": "http://arxiv.org/abs/2405.07081v1", "categories": ["cs.DB", "cs.CL"], "primary_category": "cs.DB"}
{"title": "Advanced Natural-based interaction for the ITAlian language:\n  LLaMAntino-3-ANITA", "abstract": "In the pursuit of advancing natural language processing for the Italian\nlanguage, we introduce a state-of-the-art Large Language Model (LLM) based on\nthe novel Meta LLaMA-3 model: LLaMAntino-3-ANITA-8B-Inst-DPO-ITA. We fine-tuned\nthe original 8B parameters instruction tuned model using the Supervised\nFine-tuning (SFT) technique on the English and Italian language datasets in\norder to improve the original performance. Consequently, a Dynamic Preference\nOptimization (DPO) process has been used to align preferences, avoid dangerous\nand inappropriate answers, and limit biases and prejudices. Our model leverages\nthe efficiency of QLoRA to fine-tune the model on a smaller portion of the\noriginal model weights and then adapt the model specifically for the Italian\nlinguistic structure, achieving significant improvements in both performance\nand computational efficiency. Concurrently, DPO is employed to refine the\nmodel's output, ensuring that generated content aligns with quality answers.\nThe synergy between SFT, QLoRA's parameter efficiency and DPO's user-centric\noptimization results in a robust LLM that excels in a variety of tasks,\nincluding but not limited to text completion, zero-shot classification, and\ncontextual understanding. The model has been extensively evaluated over\nstandard benchmarks for the Italian and English languages, showing outstanding\nresults. The model is freely available over the HuggingFace hub and, examples\nof use can be found in our GitHub repository.\nhttps://huggingface.co/swap-uniba/LLaMAntino-3-ANITA-8B-Inst-DPO-ITA", "published": "2024-05-11 22:02:55", "link": "http://arxiv.org/abs/2405.07101v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Robot Detection System 1: Front-Following", "abstract": "Front-following is more technically difficult to implement than the other two\nhuman following technologies, but front-following technology is more practical\nand can be applied in more areas to solve more practical problems.\nFront-following technology has many advantages not found in back-following and\nside-by-side technologies. In this paper, we will discuss basic and significant\nprinciples and general design idea of this technology. Besides, various of\nnovel and special useful methods will be presented and provided. We use enough\nbeautiful figures to display our novel design idea. Our research result is open\nsource in 2018, and this paper is just to expand the research result\npropagation granularity. Abundant magic design idea are included in this paper,\nmore idea and analyzing can sear and see other paper naming with a start of\nRobot Design System with Jinwei Lin, the only author of this series papers.", "published": "2024-05-11 03:56:23", "link": "http://arxiv.org/abs/2405.08014v1", "categories": ["cs.RO", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Survey on Reasoning Capabilities and Accessibility of Large Language\n  Models Using Biology-related Questions", "abstract": "This research paper discusses the advances made in the past decade in\nbiomedicine and Large Language Models. To understand how the advances have been\nmade hand-in-hand with one another, the paper also discusses the integration of\nNatural Language Processing techniques and tools into biomedicine. Finally, the\ngoal of this paper is to expand on a survey conducted last year (2023) by\nintroducing a new list of questions and prompts for the top two language\nmodels. Through this survey, this paper seeks to quantify the improvement made\nin the reasoning abilities in LLMs and to what extent those improvements are\nfelt by the average user. Additionally, this paper seeks to extend research on\nretrieval of biological literature by prompting the LLM to answer open-ended\nquestions in great depth.", "published": "2024-05-11 20:25:40", "link": "http://arxiv.org/abs/2406.16891v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Event GDR: Event-Centric Generative Document Retrieval", "abstract": "Generative document retrieval, an emerging paradigm in information retrieval,\nlearns to build connections between documents and identifiers within a single\nmodel, garnering significant attention. However, there are still two\nchallenges: (1) neglecting inner-content correlation during document\nrepresentation; (2) lacking explicit semantic structure during identifier\nconstruction. Nonetheless, events have enriched relations and well-defined\ntaxonomy, which could facilitate addressing the above two challenges. Inspired\nby this, we propose Event GDR, an event-centric generative document retrieval\nmodel, integrating event knowledge into this task. Specifically, we utilize an\nexchange-then-reflection method based on multi-agents for event knowledge\nextraction. For document representation, we employ events and relations to\nmodel the document to guarantee the comprehensiveness and inner-content\ncorrelation. For identifier construction, we map the events to well-defined\nevent taxonomy to construct the identifiers with explicit semantic structure.\nOur method achieves significant improvement over the baselines on two datasets,\nand also hopes to provide insights for future research.", "published": "2024-05-11 02:55:11", "link": "http://arxiv.org/abs/2405.06886v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "AIOS Compiler: LLM as Interpreter for Natural Language Programming and\n  Flow Programming of AI Agents", "abstract": "Since their inception, programming languages have trended towards greater\nreadability and lower barriers for programmers. Following this trend, natural\nlanguage can be a promising type of programming language that provides great\nflexibility and usability and helps towards the democracy of programming.\nHowever, the inherent vagueness, ambiguity, and verbosity of natural language\npose significant challenges in developing an interpreter that can accurately\nunderstand the programming logic and execute instructions written in natural\nlanguage. Fortunately, recent advancements in Large Language Models (LLMs) have\ndemonstrated remarkable proficiency in interpreting complex natural language.\nInspired by this, we develop a novel system for Code Representation and\nExecution (CoRE), which employs LLM as interpreter to interpret and execute\nnatural language instructions. The proposed system unifies natural language\nprogramming, pseudo-code programming, and flow programming under the same\nrepresentation for constructing language agents, while LLM serves as the\ninterpreter to interpret and execute the agent programs. In this paper, we\nbegin with defining the programming syntax that structures natural language\ninstructions logically. During the execution, we incorporate external memory to\nminimize redundancy. Furthermore, we equip the designed interpreter with the\ncapability to invoke external tools, compensating for the limitations of LLM in\nspecialized domains or when accessing real-time information. This work is\nopen-source at https://github.com/agiresearch/CoRE,\nhttps://github.com/agiresearch/OpenAGI, and\nhttps://github.com/agiresearch/AIOS.", "published": "2024-05-11 04:29:03", "link": "http://arxiv.org/abs/2405.06907v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.PL"], "primary_category": "cs.CL"}
{"title": "ChartInsights: Evaluating Multimodal Large Language Models for Low-Level\n  Chart Question Answering", "abstract": "Chart question answering (ChartQA) tasks play a critical role in interpreting\nand extracting insights from visualization charts. While recent advancements in\nmultimodal large language models (MLLMs) like GPT-4o have shown promise in\nhigh-level ChartQA tasks, such as chart captioning, their effectiveness in\nlow-level ChartQA tasks (e.g., identifying correlations) remains underexplored.\nIn this paper, we address this gap by evaluating MLLMs on low-level ChartQA\nusing a newly curated dataset, ChartInsights, which consists of 22,347 (chart,\ntask, query, answer) covering 10 data analysis tasks across 7 chart types. We\nsystematically evaluate 19 advanced MLLMs, including 12 open-source and 7\nclosed-source models. The average accuracy rate across these models is 39.8%,\nwith GPT-4o achieving the highest accuracy at 69.17%. To further explore the\nlimitations of MLLMs in low-level ChartQA, we conduct experiments that alter\nvisual elements of charts (e.g., changing color schemes, adding image noise) to\nassess their impact on the task effectiveness. Furthermore, we propose a new\ntextual prompt strategy, Chain-of-Charts, tailored for low-level ChartQA tasks,\nwhich boosts performance by 14.41%, achieving an accuracy of 83.58%. Finally,\nincorporating a visual prompt strategy that directs attention to relevant\nvisual elements further improves accuracy to 84.32%.", "published": "2024-05-11 12:33:46", "link": "http://arxiv.org/abs/2405.07001v4", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Translating Expert Intuition into Quantifiable Features: Encode\n  Investigator Domain Knowledge via LLM for Enhanced Predictive Analytics", "abstract": "In the realm of predictive analytics, the nuanced domain knowledge of\ninvestigators often remains underutilized, confined largely to subjective\ninterpretations and ad hoc decision-making. This paper explores the potential\nof Large Language Models (LLMs) to bridge this gap by systematically converting\ninvestigator-derived insights into quantifiable, actionable features that\nenhance model performance. We present a framework that leverages LLMs' natural\nlanguage understanding capabilities to encode these red flags into a structured\nfeature set that can be readily integrated into existing predictive models.\nThrough a series of case studies, we demonstrate how this approach not only\npreserves the critical human expertise within the investigative process but\nalso scales the impact of this knowledge across various prediction tasks. The\nresults indicate significant improvements in risk assessment and\ndecision-making accuracy, highlighting the value of blending human experiential\nknowledge with advanced machine learning techniques. This study paves the way\nfor more sophisticated, knowledge-driven analytics in fields where expert\ninsight is paramount.", "published": "2024-05-11 13:23:43", "link": "http://arxiv.org/abs/2405.08017v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RAGE Against the Machine: Retrieval-Augmented LLM Explanations", "abstract": "This paper demonstrates RAGE, an interactive tool for explaining Large\nLanguage Models (LLMs) augmented with retrieval capabilities; i.e., able to\nquery external sources and pull relevant information into their input context.\nOur explanations are counterfactual in the sense that they identify parts of\nthe input context that, when removed, change the answer to the question posed\nto the LLM. RAGE includes pruning methods to navigate the vast space of\npossible explanations, allowing users to view the provenance of the produced\nanswers.", "published": "2024-05-11 19:08:38", "link": "http://arxiv.org/abs/2405.13000v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "The Silent Curriculum: How Does LLM Monoculture Shape Educational\n  Content and Its Accessibility?", "abstract": "As Large Language Models (LLMs) ascend in popularity, offering information\nwith unprecedented convenience compared to traditional search engines, we delve\ninto the intriguing possibility that a new, singular perspective is being\npropagated. We call this the \"Silent Curriculum,\" where our focus shifts\ntowards a particularly impressionable demographic: children, who are drawn to\nthe ease and immediacy of acquiring knowledge through these digital oracles. In\nthis exploration, we delve into the sociocultural ramifications of LLMs, which,\nthrough their nuanced responses, may be subtly etching their own stereotypes,\nan algorithmic or AI monoculture. We hypothesize that the convergence of\npre-training data, fine-tuning datasets, and analogous guardrails across models\nmay have birthed a distinct cultural lens. We unpack this concept through a\nshort experiment navigating children's storytelling, occupational-ethnic\nbiases, and self-diagnosed annotations, to find that there exists strong cosine\nsimilarity (0.87) of biases across these models, suggesting a similar\nperspective of ethnic stereotypes in occupations. This paper invites a\nreimagining of LLMs' societal role, especially as the new information\ngatekeepers, advocating for a paradigm shift towards diversity-rich landscapes\nover unintended monocultures.", "published": "2024-05-11 12:02:44", "link": "http://arxiv.org/abs/2407.10371v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "IPDnet: A Universal Direct-Path IPD Estimation Network for Sound Source\n  Localization", "abstract": "Extracting direct-path spatial feature is crucial for sound source\nlocalization in adverse acoustic environments. This paper proposes the IPDnet,\na neural network that estimates direct-path inter-channel phase difference\n(DP-IPD) of sound sources from microphone array signals. The estimated DP-IPD\ncan be easily translated to source location based on the known microphone array\ngeometry. First, a full-band and narrow-band fusion network is proposed for\nDP-IPD estimation, in which alternating narrow-band and full-band layers are\nresponsible for estimating the rough DP-IPD information in one frequency band\nand capturing the frequency correlations of DP-IPD, respectively. Second, a new\nmulti-track DP-IPD learning target is proposed for the localization of flexible\nnumber of sound sources. Third, the IPDnet is extend to handling variable\nmicrophone arrays, once trained which is able to process arbitrary microphone\narrays with different number of channels and array topology. Experiments of\nmultiple-moving-speaker localization are conducted on both simulated and\nreal-world data, which show that the proposed full-band and narrow-band fusion\nnetwork and the proposed multi-track DP-IPD learning target together achieves\nexcellent sound source localization performance. Moreover, the proposed\nvariable-array model generalizes well to unseen microphone arrays.", "published": "2024-05-11 14:02:15", "link": "http://arxiv.org/abs/2405.07021v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A framework of text-dependent speaker verification for chinese numerical\n  string corpus", "abstract": "The Chinese numerical string corpus, serves as a valuable resource for\nspeaker verification, particularly in financial transactions. Researches\nindicate that in short speech scenarios, text-dependent speaker verification\n(TD-SV) consistently outperforms text-independent speaker verification (TI-SV).\nHowever, TD-SV potentially includes the validation of text information, that\ncan be negatively impacted by reading rhythms and pauses. To address this\nproblem, we propose an end-to-end speaker verification system that enhances\nTD-SV by decoupling speaker and text information. Our system consists of a text\nembedding extractor, a speaker embedding extractor and a fusion module. In the\ntext embedding extractor, we employ an enhanced Transformer and introduce a\ntriple loss including text classification loss, connectionist temporal\nclassification (CTC) loss and decoder loss; while in the speaker embedding\nextractor, we create a multi-scale pooling method by combining sliding window\nattentive statistics pooling (SWASP) with attentive statistics pooling (ASP).\nTo mitigate the scarcity of data, we have recorded a publicly available Chinese\nnumerical corpus named SHALCAS22A (hereinafter called SHAL), which can be\naccessed on Open-SLR. Moreover, we employ data augmentation techniques using\nTacotron2 and HiFi-GAN. Our method achieves an equal error rate (EER)\nperformance improvement of 49.2% on Hi-Mia and 75.0% on SHAL, respectively.", "published": "2024-05-11 15:02:06", "link": "http://arxiv.org/abs/2405.07029v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards an Accessible and Rapidly Trainable Rhythm Sequencer Using a\n  Generative Stacked Autoencoder", "abstract": "Neural networks and deep learning are often deployed for the sake of the most\ncomprehensive music generation with as little involvement as possible from the\nhuman musician. Implementations in aid of, or being a tool for, music\npractitioners are sparse. This paper proposes the integration of generative\nstacked autoencoder structures for rhythm generation, within a conventional\nmelodic step-sequencer. It further aims to work towards its implementation\nbeing accessible to the average electronic music practitioner. Several model\narchitectures have been trained and tested for their creative potential. While\nthe currently implementations do display limitations, they do represent viable\ncreative solutions for music practitioners.", "published": "2024-05-11 15:17:27", "link": "http://arxiv.org/abs/2405.07034v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Diff-ETS: Learning a Diffusion Probabilistic Model for\n  Electromyography-to-Speech Conversion", "abstract": "Electromyography-to-Speech (ETS) conversion has demonstrated its potential\nfor silent speech interfaces by generating audible speech from Electromyography\n(EMG) signals during silent articulations. ETS models usually consist of an EMG\nencoder which converts EMG signals to acoustic speech features, and a vocoder\nwhich then synthesises the speech signals. Due to an inadequate amount of\navailable data and noisy signals, the synthesised speech often exhibits a low\nlevel of naturalness. In this work, we propose Diff-ETS, an ETS model which\nuses a score-based diffusion probabilistic model to enhance the naturalness of\nsynthesised speech. The diffusion model is applied to improve the quality of\nthe acoustic features predicted by an EMG encoder. In our experiments, we\nevaluated fine-tuning the diffusion model on predictions of a pre-trained EMG\nencoder, and training both models in an end-to-end fashion. We compared\nDiff-ETS with a baseline ETS model without diffusion using objective metrics\nand a listening test. The results indicated the proposed Diff-ETS significantly\nimproved speech naturalness over the baseline.", "published": "2024-05-11 17:04:38", "link": "http://arxiv.org/abs/2405.08021v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Benchmarking Cross-Domain Audio-Visual Deception Detection", "abstract": "Automated deception detection is crucial for assisting humans in accurately\nassessing truthfulness and identifying deceptive behavior. Conventional\ncontact-based techniques, like polygraph devices, rely on physiological signals\nto determine the authenticity of an individual's statements. Nevertheless,\nrecent developments in automated deception detection have demonstrated that\nmultimodal features derived from both audio and video modalities may outperform\nhuman observers on publicly available datasets. Despite these positive\nfindings, the generalizability of existing audio-visual deception detection\napproaches across different scenarios remains largely unexplored. To close this\ngap, we present the first cross-domain audio-visual deception detection\nbenchmark, that enables us to assess how well these methods generalize for use\nin real-world scenarios. We used widely adopted audio and visual features and\ndifferent architectures for benchmarking, comparing single-to-single and\nmulti-to-single domain generalization performance. To further exploit the\nimpacts using data from multiple source domains for training, we investigate\nthree types of domain sampling strategies, including domain-simultaneous,\ndomain-alternating, and domain-by-domain for multi-to-single domain\ngeneralization evaluation. We also propose an algorithm to enhance the\ngeneralization performance by maximizing the gradient inner products between\nmodality encoders, named ``MM-IDGM\". Furthermore, we proposed the\nAttention-Mixer fusion method to improve performance, and we believe that this\nnew cross-domain benchmark will facilitate future research in audio-visual\ndeception detection.", "published": "2024-05-11 12:06:31", "link": "http://arxiv.org/abs/2405.06995v2", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Prompt-guided Precise Audio Editing with Diffusion Models", "abstract": "Audio editing involves the arbitrary manipulation of audio content through\nprecise control. Although text-guided diffusion models have made significant\nadvancements in text-to-audio generation, they still face challenges in finding\na flexible and precise way to modify target events within an audio track. We\npresent a novel approach, referred to as PPAE, which serves as a general module\nfor diffusion models and enables precise audio editing. The editing is based on\nthe input textual prompt only and is entirely training-free. We exploit the\ncross-attention maps of diffusion models to facilitate accurate local editing\nand employ a hierarchical local-global pipeline to ensure a smoother editing\nprocess. Experimental results highlight the effectiveness of our method in\nvarious editing tasks.", "published": "2024-05-11 07:41:27", "link": "http://arxiv.org/abs/2406.04350v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
