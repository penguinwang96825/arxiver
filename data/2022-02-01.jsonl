{"title": "WebFormer: The Web-page Transformer for Structure Information Extraction", "abstract": "Structure information extraction refers to the task of extracting structured\ntext fields from web pages, such as extracting a product offer from a shopping\npage including product title, description, brand and price. It is an important\nresearch topic which has been widely studied in document understanding and web\nsearch. Recent natural language models with sequence modeling have demonstrated\nstate-of-the-art performance on web information extraction. However,\neffectively serializing tokens from unstructured web pages is challenging in\npractice due to a variety of web layout patterns. Limited work has focused on\nmodeling the web layout for extracting the text fields. In this paper, we\nintroduce WebFormer, a Web-page transFormer model for structure information\nextraction from web documents. First, we design HTML tokens for each DOM node\nin the HTML by embedding representations from their neighboring tokens through\ngraph attention. Second, we construct rich attention patterns between HTML\ntokens and text tokens, which leverages the web layout for effective attention\nweight computation. We conduct an extensive set of experiments on SWDE and\nCommon Crawl benchmarks. Experimental results demonstrate the superior\nperformance of the proposed approach over several state-of-the-art methods.", "published": "2022-02-01 04:44:02", "link": "http://arxiv.org/abs/2202.00217v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "XAlign: Cross-lingual Fact-to-Text Alignment and Generation for\n  Low-Resource Languages", "abstract": "Multiple critical scenarios (like Wikipedia text generation given English\nInfoboxes) need automated generation of descriptive text in low resource (LR)\nlanguages from English fact triples. Previous work has focused on English\nfact-to-text (F2T) generation. To the best of our knowledge, there has been no\nprevious attempt on cross-lingual alignment or generation for LR languages.\nBuilding an effective cross-lingual F2T (XF2T) system requires alignment\nbetween English structured facts and LR sentences. We propose two unsupervised\nmethods for cross-lingual alignment. We contribute XALIGN, an XF2T dataset with\n0.45M pairs across 8 languages, of which 5402 pairs have been manually\nannotated. We also train strong baseline XF2T generation models on the XAlign\ndataset.", "published": "2022-02-01 09:41:59", "link": "http://arxiv.org/abs/2202.00291v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Finding the optimal human strategy for Wordle using maximum correct\n  letter probabilities and reinforcement learning", "abstract": "Wordle is an online word puzzle game that gained viral popularity in January\n2022. The goal is to guess a hidden five letter word. After each guess, the\nplayer gains information about whether the letters they guessed are present in\nthe word, and whether they are in the correct position. Numerous blogs have\nsuggested guessing strategies and starting word lists that improve the chance\nof winning. Optimized algorithms can win 100% of games within five of the six\nallowed trials. However, it is infeasible for human players to use these\nalgorithms due to an inability to perfectly recall all known 5-letter words and\nperform complex calculations that optimize information gain. Here, we present\ntwo different methods for choosing starting words along with a framework for\ndiscovering the optimal human strategy based on reinforcement learning. Human\nWordle players can use the rules we discover to optimize their chance of\nwinning.", "published": "2022-02-01 17:03:26", "link": "http://arxiv.org/abs/2202.00557v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic of Cloud Computing services for Time Series workflows", "abstract": "Time series (TS) are present in many fields of knowledge, research, and\nengineering. The processing and analysis of TS are essential in order to\nextract knowledge from the data and to tackle forecasting or predictive\nmaintenance tasks among others The modeling of TS is a challenging task,\nrequiring high statistical expertise as well as outstanding knowledge about the\napplication of Data Mining(DM) and Machine Learning (ML) methods. The overall\nwork with TS is not limited to the linear application of several techniques,\nbut is composed of an open workflow of methods and tests. These workflow,\ndeveloped mainly on programming languages, are complicated to execute and run\neffectively on different systems, including Cloud Computing (CC) environments.\nThe adoption of CC can facilitate the integration and portability of services\nallowing to adopt solutions towards services Internet Technologies (IT)\nindustrialization. The definition and description of workflow services for TS\nopen up a new set of possibilities regarding the reduction of complexity in the\ndeployment of this type of issues in CC environments. In this sense, we have\ndesigned an effective proposal based on semantic modeling (or vocabulary) that\nprovides the full description of workflow for Time Series modeling as a CC\nservice. Our proposal includes a broad spectrum of the most extended\noperations, accommodating any workflow applied to classification, regression,\nor clustering problems for Time Series, as well as including evaluation\nmeasures, information, tests, or machine learning algorithms among others.", "published": "2022-02-01 17:57:40", "link": "http://arxiv.org/abs/2202.00609v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Annotation and Querying Framework based on Semi-structured\n  Ayurvedic Text", "abstract": "Knowledge bases (KB) are an important resource in a number of natural\nlanguage processing (NLP) and information retrieval (IR) tasks, such as\nsemantic search, automated question-answering etc. They are also useful for\nresearchers trying to gain information from a text. Unfortunately, however, the\nstate-of-the-art in Sanskrit NLP does not yet allow automated construction of\nknowledge bases due to unavailability or lack of sufficient accuracy of tools\nand methods. Thus, in this work, we describe our efforts on manual annotation\nof Sanskrit text for the purpose of knowledge graph (KG) creation. We choose\nthe chapter Dhanyavarga from Bhavaprakashanighantu of the Ayurvedic text\nBhavaprakasha for annotation. The constructed knowledge graph contains 410\nentities and 764 relationships. Since Bhavaprakashanighantu is a technical\nglossary text that describes various properties of different substances, we\ndevelop an elaborate ontology to capture the semantics of the entity and\nrelationship types present in the text. To query the knowledge graph, we design\n31 query templates that cover most of the common question patterns. For both\nmanual annotation and querying, we customize the Sangrahaka framework\npreviously developed by us. The entire system including the dataset is\navailable from https://sanskrit.iitk.ac.in/ayurveda/ . We hope that the\nknowledge graph that we have created through manual annotation and subsequent\ncuration will help in development and testing of NLP tools in future as well as\nstudying of the Bhavaprakasanighantu text.", "published": "2022-02-01 04:33:13", "link": "http://arxiv.org/abs/2202.00216v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Active Learning Over Multiple Domains in Natural Language Tasks", "abstract": "Studies of active learning traditionally assume the target and source data\nstem from a single domain. However, in realistic applications, practitioners\noften require active learning with multiple sources of out-of-distribution\ndata, where it is unclear a priori which data sources will help or hurt the\ntarget domain. We survey a wide variety of techniques in active learning (AL),\ndomain shift detection (DS), and multi-domain sampling to examine this\nchallenging setting for question answering and sentiment analysis. We ask (1)\nwhat family of methods are effective for this task? And, (2) what properties of\nselected examples and domains achieve strong results? Among 18 acquisition\nfunctions from 4 families of methods, we find H-Divergence methods, and\nparticularly our proposed variant DAL-E, yield effective results, averaging\n2-3% improvements over the random baseline. We also show the importance of a\ndiverse allocation of domains, as well as room-for-improvement of existing\nmethods on both domain and example selection. Our findings yield the first\ncomprehensive analysis of both existing and novel methods for practitioners\nfaced with multi-domain active learning for natural language tasks.", "published": "2022-02-01 07:27:18", "link": "http://arxiv.org/abs/2202.00254v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Research on Question Classification Methods in the Medical Field", "abstract": "Question classification is one of the important links in the research of\nquestion and answering system. The existing question classification models are\nmore trained on public data sets. At present, there is a lack of question\nclassification data sets in specific fields, especially in the medical field.\nTo make up for this gap, this paper presents a data set for question\nclassification in the medical field. Moreover, this paper proposes a\nmulti-dimensional extraction of the characteristics of the question by\ncombining multiple neural network models, and proposes a question\nclassification model based on multi-dimensional feature extraction. The\nexperimental results show that the proposed method can effectively improve the\nperformance of question classification.", "published": "2022-02-01 09:58:30", "link": "http://arxiv.org/abs/2202.00298v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Natural Language to Code Using Transformers", "abstract": "We tackle the problem of generating code snippets from natural language\ndescriptions using the CoNaLa dataset. We use the self-attention based\ntransformer architecture and show that it performs better than recurrent\nattention-based encoder decoder. Furthermore, we develop a modified form of\nback translation and use cycle consistent losses to train the model in an\nend-to-end fashion. We achieve a BLEU score of 16.99 beating the previously\nreported baseline of the CoNaLa challenge.", "published": "2022-02-01 12:17:52", "link": "http://arxiv.org/abs/2202.00367v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Negativity Spreads Faster: A Large-Scale Multilingual Twitter Analysis\n  on the Role of Sentiment in Political Communication", "abstract": "Social media has become extremely influential when it comes to policy making\nin modern societies, especially in the western world, where platforms such as\nTwitter allow users to follow politicians, thus making citizens more involved\nin political discussion. In the same vein, politicians use Twitter to express\ntheir opinions, debate among others on current topics and promote their\npolitical agendas aiming to influence voter behaviour. In this paper, we\nattempt to analyse tweets of politicians from three European countries and\nexplore the virality of their tweets. Previous studies have shown that tweets\nconveying negative sentiment are likely to be retweeted more frequently. By\nutilising state-of-the-art pre-trained language models, we performed sentiment\nanalysis on hundreds of thousands of tweets collected from members of\nparliament in Greece, Spain and the United Kingdom, including devolved\nadministrations. We achieved this by systematically exploring and analysing the\ndifferences between influential and less popular tweets. Our analysis indicates\nthat politicians' negatively charged tweets spread more widely, especially in\nmore recent times, and highlights interesting differences between political\nparties as well as between politicians and the general population.", "published": "2022-02-01 13:25:19", "link": "http://arxiv.org/abs/2202.00396v3", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Examining Scaling and Transfer of Language Model Architectures for\n  Machine Translation", "abstract": "Natural language understanding and generation models follow one of the two\ndominant architectural paradigms: language models (LMs) that process\nconcatenated sequences in a single stack of layers, and encoder-decoder models\n(EncDec) that utilize separate layer stacks for input and output processing. In\nmachine translation, EncDec has long been the favoured approach, but with few\nstudies investigating the performance of LMs. In this work, we thoroughly\nexamine the role of several architectural design choices on the performance of\nLMs on bilingual, (massively) multilingual and zero-shot translation tasks,\nunder systematic variations of data conditions and model sizes. Our results\nshow that: (i) Different LMs have different scaling properties, where\narchitectural differences often have a significant impact on model performance\nat small scales, but the performance gap narrows as the number of parameters\nincreases, (ii) Several design choices, including causal masking and\nlanguage-modeling objectives for the source sequence, have detrimental effects\non translation quality, and (iii) When paired with full-visible masking for\nsource sequences, LMs could perform on par with EncDec on supervised bilingual\nand multilingual translation tasks, and improve greatly on zero-shot directions\nby facilitating the reduction of off-target translations.", "published": "2022-02-01 16:20:15", "link": "http://arxiv.org/abs/2202.00528v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Novelty Controlled Paraphrase Generation with Retrieval Augmented\n  Conditional Prompt Tuning", "abstract": "Paraphrase generation is a fundamental and long-standing task in natural\nlanguage processing. In this paper, we concentrate on two contributions to the\ntask: (1) we propose Retrieval Augmented Prompt Tuning (RAPT) as a\nparameter-efficient method to adapt large pre-trained language models for\nparaphrase generation; (2) we propose Novelty Conditioned RAPT (NC-RAPT) as a\nsimple model-agnostic method of using specialized prompt tokens for controlled\nparaphrase generation with varying levels of lexical novelty. By conducting\nextensive experiments on four datasets, we demonstrate the effectiveness of the\nproposed approaches for retaining the semantic content of the original text\nwhile inducing lexical novelty in the generation.", "published": "2022-02-01 16:26:36", "link": "http://arxiv.org/abs/2202.00535v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Locally Typical Sampling", "abstract": "Today's probabilistic language generators fall short when it comes to\nproducing coherent and fluent text despite the fact that the underlying models\nperform well under standard metrics, e.g., perplexity. This discrepancy has\npuzzled the language generation community for the last few years. In this work,\nwe posit that the abstraction of natural language generation as a discrete\nstochastic process--which allows for an information-theoretic analysis--can\nprovide new insights into the behavior of probabilistic language generators,\ne.g., why high-probability texts can be dull or repetitive. Humans use language\nas a means of communicating information, aiming to do so in a simultaneously\nefficient and error-minimizing manner; in fact, psycholinguistics research\nsuggests humans choose each word in a string with this subconscious goal in\nmind. We formally define the set of strings that meet this criterion: those for\nwhich each word has an information content close to the expected information\ncontent, i.e., the conditional entropy of our model. We then propose a simple\nand efficient procedure for enforcing this criterion when generating from\nprobabilistic models, which we call locally typical sampling. Automatic and\nhuman evaluations show that, in comparison to nucleus and top-k sampling,\nlocally typical sampling offers competitive performance (in both abstractive\nsummarization and story generation) in terms of quality while consistently\nreducing degenerate repetitions.", "published": "2022-02-01 18:58:45", "link": "http://arxiv.org/abs/2202.00666v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Semi-Supervised Deep Clustering Pipeline for Mining Intentions From\n  Texts", "abstract": "Mining the latent intentions from large volumes of natural language inputs is\na key step to help data analysts design and refine Intelligent Virtual\nAssistants (IVAs) for customer service. To aid data analysts in this task we\npresent Verint Intent Manager (VIM), an analysis platform that combines\nunsupervised and semi-supervised approaches to help analysts quickly surface\nand organize relevant user intentions from conversational texts. For the\ninitial exploration of data we make use of a novel unsupervised and\nsemi-supervised pipeline that integrates the fine-tuning of high performing\nlanguage models, a distributed k-NN graph building method and community\ndetection techniques for mining the intentions and topics from texts. The\nfine-tuning step is necessary because pre-trained language models cannot encode\ntexts to efficiently surface particular clustering structures when the target\ntexts are from an unseen domain or the clustering task is not topic detection.\nFor flexibility we deploy two clustering approaches: where the number of\nclusters must be specified and where the number of clusters is detected\nautomatically with comparable clustering quality but at the expense of\nadditional computation time. We describe the application and deployment and\ndemonstrate its performance using BERT on three text mining tasks. Our\nexperiments show that BERT begins to produce better task-aware representations\nusing a labeled subset as small as 0.5% of the task data. The clustering\nquality exceeds the state-of-the-art results when BERT is fine-tuned with\nlabeled subsets of only 2.5% of the task data. As deployed in the VIM\napplication, this flexible clustering pipeline produces high quality results,\nimproving the performance of data analysts and reducing the time it takes to\nsurface intentions from customer service data, thereby reducing the time it\ntakes to build and deploy IVAs in new domains.", "published": "2022-02-01 23:01:05", "link": "http://arxiv.org/abs/2202.00802v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Adaptive Deep Clustering Pipeline to Inform Text Labeling at Scale", "abstract": "Mining the latent intentions from large volumes of natural language inputs is\na key step to help data analysts design and refine Intelligent Virtual\nAssistants (IVAs) for customer service and sales support. We created a flexible\nand scalable clustering pipeline within the Verint Intent Manager (VIM) that\nintegrates the fine-tuning of language models, a high performing k-NN library\nand community detection techniques to help analysts quickly surface and\norganize relevant user intentions from conversational texts. The fine-tuning\nstep is necessary because pre-trained language models cannot encode texts to\nefficiently surface particular clustering structures when the target texts are\nfrom an unseen domain or the clustering task is not topic detection. We\ndescribe the pipeline and demonstrate its performance and ability to scale on\nthree real-world text mining tasks. As deployed in the VIM application, this\nclustering pipeline produces high quality results, improving the performance of\ndata analysts and reducing the time it takes to surface intentions from\ncustomer service data, thereby reducing the time it takes to build and deploy\nIVAs in new domains.", "published": "2022-02-01 22:54:18", "link": "http://arxiv.org/abs/2202.01211v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AI-based Approach for Safety Signals Detection from Social Networks:\n  Application to the Levothyrox Scandal in 2017 on Doctissimo Forum", "abstract": "Social media can be an important source of information facilitating the\ndetection of new safety signals in pharmacovigilance. Various approaches have\ninvestigated the analysis of social media data using AI such as NLP techniques\nfor detecting adverse drug events. Existing approaches have focused on the\nextraction and identification of Adverse Drug Reactions, Drug-Drug Interactions\nand drug misuse. However, non of the works tackled the detection of potential\nsafety signals by taking into account the evolution in time of relevant\nindicators. Moreover, despite the success of deep learning in various\nhealthcare applications, it was not explored for this task. We propose an\nAI-based approach for the detection of potential pharmaceutical safety signals\nfrom patients' reviews that can be used as part of the pharmacovigilance\nsurveillance process to flag the necessity of an in-depth pharmacovigilance\ninvestigation. We focus on the Levothyrox case in France which triggered huge\nattention from the media following the change of the medication formula,\nleading to an increase in the frequency of adverse drug reactions normally\nreported by patients. Our approach is two-fold. (1) We investigate various\nNLP-based indicators extracted from patients' reviews including words and\nn-grams frequency, semantic similarity, Adverse Drug Reactions mentions, and\nsentiment analysis. (2) We propose a deep learning architecture, named Word\nCloud Convolutional Neural Network (WC-CNN) which trains a CNN on word clouds\nextracted from the patients comments. We study the effect of different time\nresolutions and different NLP pre-processing techniques on the model\nperformance. Our results show that the proposed indicators could be used in the\nfuture to effectively detect new safety signals. The WC-CNN model trained on\nword clouds extracted at monthly resolution outperforms the others with an\naccuracy of 75%.", "published": "2022-02-01 10:17:32", "link": "http://arxiv.org/abs/2203.03538v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language Dependencies in Adversarial Attacks on Speech Recognition\n  Systems", "abstract": "Automatic speech recognition (ASR) systems are ubiquitously present in our\ndaily devices. They are vulnerable to adversarial attacks, where manipulated\ninput samples fool the ASR system's recognition. While adversarial examples for\nvarious English ASR systems have already been analyzed, there exists no\ninter-language comparative vulnerability analysis. We compare the attackability\nof a German and an English ASR system, taking Deepspeech as an example. We\ninvestigate if one of the language models is more susceptible to manipulations\nthan the other. The results of our experiments suggest statistically\nsignificant differences between English and German in terms of computational\neffort necessary for the successful generation of adversarial examples. This\nresult encourages further research in language-dependent characteristics in the\nrobustness analysis of ASR.", "published": "2022-02-01 13:27:40", "link": "http://arxiv.org/abs/2202.00399v2", "categories": ["cs.CL", "cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "BEA-Base: A Benchmark for ASR of Spontaneous Hungarian", "abstract": "Hungarian is spoken by 15 million people, still, easily accessible Automatic\nSpeech Recognition (ASR) benchmark datasets - especially for spontaneous speech\n- have been practically unavailable. In this paper, we introduce BEA-Base, a\nsubset of the BEA spoken Hungarian database comprising mostly spontaneous\nspeech of 140 speakers. It is built specifically to assess ASR, primarily for\nconversational AI applications. After defining the speech recognition subsets\nand task, several baselines - including classic HMM-DNN hybrid and end-to-end\napproaches augmented by cross-language transfer learning - are developed using\nopen-source toolkits. The best results obtained are based on multilingual\nself-supervised pretraining, achieving a 45% recognition error rate reduction\nas compared to the classical approach - without the application of an external\nlanguage model or additional supervised data. The results show the feasibility\nof using BEA-Base for training and evaluation of Hungarian speech recognition\nsystems.", "published": "2022-02-01 17:45:22", "link": "http://arxiv.org/abs/2202.00601v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Regression Transformer: Concurrent sequence regression and generation\n  for molecular language modeling", "abstract": "Despite significant progress of generative models in the natural sciences,\ntheir controllability remains challenging. One fundamentally missing aspect of\nmolecular or protein generative models is an inductive bias that can reflect\ncontinuous properties of interest. To that end, we propose the Regression\nTransformer (RT), a novel method that abstracts regression as a conditional\nsequence modeling problem. This introduces a new paradigm of multitask language\nmodels which seamlessly bridge sequence regression and conditional sequence\ngeneration.\n  We thoroughly demonstrate that, despite using a nominal-scale training\nobjective, the RT matches or surpasses the performance of conventional\nregression models in property prediction tasks of small molecules, proteins and\nchemical reactions. Critically, priming the same model with continuous\nproperties yields a highly competitive conditional generative model that\noutperforms specialized approaches in a substructure-constrained,\nproperty-driven molecule generation benchmark. Our dichotomous approach is\nfacilitated by a novel, alternating training scheme that enables the model to\ndecorate seed sequences by desired properties, e.g., to optimize reaction\nyield.\n  In sum, the RT is the first report of a multitask model that concurrently\nexcels at predictive and generative tasks in biochemistry. This finds\nparticular application in property-driven, local exploration of the chemical or\nprotein space and could pave the road toward foundation models in material\ndesign.\n  The code to reproduce all experiments of the paper is available at:\nhttps://github.com/IBM/regression-transformer", "published": "2022-02-01 08:57:31", "link": "http://arxiv.org/abs/2202.01338v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "Towards a Theoretical Understanding of Word and Relation Representation", "abstract": "Representing words by vectors, or embeddings, enables computational reasoning\nand is foundational to automating natural language tasks. For example, if word\nembeddings of similar words contain similar values, word similarity can be\nreadily assessed, whereas judging that from their spelling is often impossible\n(e.g. cat /feline) and to predetermine and store similarities between all words\nis prohibitively time-consuming, memory intensive and subjective. We focus on\nword embeddings learned from text corpora and knowledge graphs. Several\nwell-known algorithms learn word embeddings from text on an unsupervised basis\nby learning to predict those words that occur around each word, e.g. word2vec\nand GloVe. Parameters of such word embeddings are known to reflect word\nco-occurrence statistics, but how they capture semantic meaning has been\nunclear. Knowledge graph representation models learn representations both of\nentities (words, people, places, etc.) and relations between them, typically by\ntraining a model to predict known facts in a supervised manner. Despite steady\nimprovements in fact prediction accuracy, little is understood of the latent\nstructure that enables this.\n  The limited understanding of how latent semantic structure is encoded in the\ngeometry of word embeddings and knowledge graph representations makes a\nprincipled means of improving their performance, reliability or\ninterpretability unclear. To address this:\n  1. we theoretically justify the empirical observation that particular\ngeometric relationships between word embeddings learned by algorithms such as\nword2vec and GloVe correspond to semantic relations between words; and\n  2. we extend this correspondence between semantics and geometry to the\nentities and relations of knowledge graphs, providing a model for the latent\nstructure of knowledge graph representation linked to that of word embeddings.", "published": "2022-02-01 15:34:58", "link": "http://arxiv.org/abs/2202.00486v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Visualizing Automatic Speech Recognition -- Means for a Better\n  Understanding?", "abstract": "Automatic speech recognition (ASR) is improving ever more at mimicking human\nspeech processing. The functioning of ASR, however, remains to a large extent\nobfuscated by the complex structure of the deep neural networks (DNNs) they are\nbased on. In this paper, we show how so-called attribution methods, that we\nimport from image recognition and suitably adapt to handle audio data, can help\nto clarify the working of ASR. Taking DeepSpeech, an end-to-end model for ASR,\nas a case study, we show how these techniques help to visualize which features\nof the input are the most influential in determining the output. We focus on\nthree visualization techniques: Layer-wise Relevance Propagation (LRP),\nSaliency Maps, and Shapley Additive Explanations (SHAP). We compare these\nmethods and discuss potential further applications, such as in the detection of\nadversarial examples.", "published": "2022-02-01 13:35:08", "link": "http://arxiv.org/abs/2202.00673v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "New Insights on Target Speaker Extraction", "abstract": "Speaker extraction (SE) aims to segregate the speech of a target speaker from\na mixture of interfering speakers with the help of auxiliary information.\nSeveral forms of auxiliary information have been employed in single-channel SE,\nsuch as a speech snippet enrolled from the target speaker or visual information\ncorresponding to the spoken utterance. The effectiveness of the auxiliary\ninformation in SE is typically evaluated by comparing the extraction\nperformance of SE with uninformed speaker separation (SS) methods. Following\nthis evaluation protocol, many SE studies have reported performance improvement\ncompared to SS, attributing this to the auxiliary information. However, such\nstudies have been conducted on a few datasets and have not considered recent\ndeep neural network architectures for SS that have shown impressive separation\nperformance. In this paper, we examine the role of the auxiliary information in\nSE for different input scenarios and over multiple datasets. Specifically, we\ncompare the performance of two SE systems (audio-based and video-based) with SS\nusing a common framework that utilizes the recently proposed dual-path\nrecurrent neural network as the main learning machine. Experimental evaluation\non various datasets demonstrates that the use of auxiliary information in the\nconsidered SE systems does not always lead to better extraction performance\ncompared to the uninformed SS system. Furthermore, we offer insights into the\nbehavior of the SE systems when provided with different and distorted auxiliary\ninformation given the same mixture input.", "published": "2022-02-01 20:10:23", "link": "http://arxiv.org/abs/2202.00733v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Differentiable Digital Signal Processing Mixture Model for Synthesis\n  Parameter Extraction from Mixture of Harmonic Sounds", "abstract": "A differentiable digital signal processing (DDSP) autoencoder is a musical\nsound synthesizer that combines a deep neural network (DNN) and spectral\nmodeling synthesis. It allows us to flexibly edit sounds by changing the\nfundamental frequency, timbre feature, and loudness (synthesis parameters)\nextracted from an input sound. However, it is designed for a monophonic\nharmonic sound and cannot handle mixtures of harmonic sounds. In this paper, we\npropose a model (DDSP mixture model) that represents a mixture as the sum of\nthe outputs of multiple pretrained DDSP autoencoders. By fitting the output of\nthe proposed model to the observed mixture, we can directly estimate the\nsynthesis parameters of each source. Through synthesis parameter extraction\nexperiments, we show that the proposed method has high and stable performance\ncompared with a straightforward method that applies the DDSP autoencoder to the\nsignals separated by an audio source separation method.", "published": "2022-02-01 03:38:49", "link": "http://arxiv.org/abs/2202.00200v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The impact of removing head movements on audio-visual speech enhancement", "abstract": "This paper investigates the impact of head movements on audio-visual speech\nenhancement (AVSE). Although being a common conversational feature, head\nmovements have been ignored by past and recent studies: they challenge today's\nlearning-based methods as they often degrade the performance of models that are\ntrained on clean, frontal, and steady face images. To alleviate this problem,\nwe propose to use robust face frontalization (RFF) in combination with an AVSE\nmethod based on a variational auto-encoder (VAE) model. We briefly describe the\nbasic ingredients of the proposed pipeline and we perform experiments with a\nrecently released audio-visual dataset. In the light of these experiments, and\nbased on three standard metrics, namely STOI, PESQ and SI-SDR, we conclude that\nRFF improves the performance of AVSE by a considerable margin.", "published": "2022-02-01 16:27:44", "link": "http://arxiv.org/abs/2202.00538v2", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
