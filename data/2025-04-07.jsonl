{"title": "Truthful or Fabricated? Using Causal Attribution to Mitigate Reward Hacking in Explanations", "abstract": "Chain-of-thought explanations are widely used to inspect the decision process\nof large language models (LLMs) and to evaluate the trustworthiness of model\noutputs, making them important for effective collaboration between LLMs and\nhumans. We demonstrate that preference optimization - a key step in the\nalignment phase - can inadvertently reduce the faithfulness of these\nexplanations. This occurs because the reward model (RM), which guides\nalignment, is tasked with optimizing both the expected quality of the response\nand the appropriateness of the explanations (e.g., minimizing bias or adhering\nto safety standards), creating potential conflicts. The RM lacks a mechanism to\nassess the consistency between the model's internal decision process and the\ngenerated explanation. Consequently, the LLM may engage in \"reward hacking\" by\nproducing a final response that scores highly while giving an explanation\ntailored to maximize reward rather than accurately reflecting its reasoning. To\naddress this issue, we propose enriching the RM's input with a causal\nattribution of the prediction, allowing the RM to detect discrepancies between\nthe generated self-explanation and the model's decision process. In controlled\nsettings, we show that this approach reduces the tendency of the LLM to\ngenerate misleading explanations.", "published": "2025-04-07 17:49:23", "link": "http://arxiv.org/abs/2504.05294v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LiveVQA: Live Visual Knowledge Seeking", "abstract": "We introduce LiveVQA, an automatically collected dataset of latest visual\nknowledge from the Internet with synthesized VQA problems. LiveVQA consists of\n3,602 single- and multi-hop visual questions from 6 news websites across 14\nnews categories, featuring high-quality image-text coherence and authentic\ninformation. Our evaluation across 15 MLLMs (e.g., GPT-4o, Gemma-3, and\nQwen-2.5-VL family) demonstrates that stronger models perform better overall,\nwith advanced visual reasoning capabilities proving crucial for complex\nmulti-hop questions. Despite excellent performance on textual problems, models\nwith tools like search engines still show significant gaps when addressing\nvisual questions requiring latest visual knowledge, highlighting important\nareas for future research.", "published": "2025-04-07 17:39:31", "link": "http://arxiv.org/abs/2504.05288v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Enhancing LLM-Based Short Answer Grading with Retrieval-Augmented Generation", "abstract": "Short answer assessment is a vital component of science education, allowing\nevaluation of students' complex three-dimensional understanding. Large language\nmodels (LLMs) that possess human-like ability in linguistic tasks are\nincreasingly popular in assisting human graders to reduce their workload.\nHowever, LLMs' limitations in domain knowledge restrict their understanding in\ntask-specific requirements and hinder their ability to achieve satisfactory\nperformance. Retrieval-augmented generation (RAG) emerges as a promising\nsolution by enabling LLMs to access relevant domain-specific knowledge during\nassessment. In this work, we propose an adaptive RAG framework for automated\ngrading that dynamically retrieves and incorporates domain-specific knowledge\nbased on the question and student answer context. Our approach combines\nsemantic search and curated educational sources to retrieve valuable reference\nmaterials. Experimental results in a science education dataset demonstrate that\nour system achieves an improvement in grading accuracy compared to baseline LLM\napproaches. The findings suggest that RAG-enhanced grading systems can serve as\nreliable support with efficient performance gains.", "published": "2025-04-07 17:17:41", "link": "http://arxiv.org/abs/2504.05276v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning vs. Memorization in Large Language Models", "abstract": "Despite high benchmark scores, Large Language Models (LLMs) often fail simple\nproblem, raising a critical question: Do LLMs learn mathematical principles or\nmerely memorize patterns? Rather than designing increasingly complex benchmarks\nlike recent works, we investigate this using elementary two-integer addition\n($0$ to $2^{64}$), probing two core properties: commutativity ($A+B=B+A$) and\ncompositional generalization (via isomorphic symbolic mappings, e.g., $7\n\\rightarrow y$). While state-of-the-art LLMs achieve 73.8-99.8\\% accuracy on\nnumerical addition, performance collapses to $\\leq$7.5\\% under symbolic\nmapping, indicating failure to generalize learned rules. Non-monotonic\nperformance scaling with digit count and frequent commutativity violations\n(over 1,700 cases of $A+B \\neq B+A$) further support this. Explicitly providing\naddition rules degrades performance by 81.2\\% on average, while\nself-explanation maintains baseline accuracy, suggesting LLM arithmetic\nprocessing is misaligned with human-defined principles. Our findings indicate\ncurrent LLMs rely on memory pattern over genuine rule learning, highlighting\narchitectural limitations and the need for new approaches to achieve true\nmathematical reasoning.", "published": "2025-04-07 16:57:10", "link": "http://arxiv.org/abs/2504.05262v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models", "abstract": "Large Language Models (LLMs) have emerged as powerful tools for generating\ncoherent text, understanding context, and performing reasoning tasks. However,\nthey struggle with temporal reasoning, which requires processing time-related\ninformation such as event sequencing, durations, and inter-temporal\nrelationships. These capabilities are critical for applications including\nquestion answering, scheduling, and historical analysis. In this paper, we\nintroduce TISER, a novel framework that enhances the temporal reasoning\nabilities of LLMs through a multi-stage process that combines timeline\nconstruction with iterative self-reflection. Our approach leverages test-time\nscaling to extend the length of reasoning traces, enabling models to capture\ncomplex temporal dependencies more effectively. This strategy not only boosts\nreasoning accuracy but also improves the traceability of the inference process.\nExperimental results demonstrate state-of-the-art performance across multiple\nbenchmarks, including out-of-distribution test sets, and reveal that TISER\nenables smaller open-source models to surpass larger closed-weight models on\nchallenging temporal reasoning tasks.", "published": "2025-04-07 16:51:45", "link": "http://arxiv.org/abs/2504.05258v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLM-based Automated Grading with Human-in-the-Loop", "abstract": "The rise of artificial intelligence (AI) technologies, particularly large\nlanguage models (LLMs), has brought significant advancements to the field of\neducation. Among various applications, automatic short answer grading (ASAG),\nwhich focuses on evaluating open-ended textual responses, has seen remarkable\nprogress with the introduction of LLMs. These models not only enhance grading\nperformance compared to traditional ASAG approaches but also move beyond simple\ncomparisons with predefined \"golden\" answers, enabling more sophisticated\ngrading scenarios, such as rubric-based evaluation. However, existing\nLLM-powered methods still face challenges in achieving human-level grading\nperformance in rubric-based assessments due to their reliance on fully\nautomated approaches. In this work, we explore the potential of LLMs in ASAG\ntasks by leveraging their interactive capabilities through a human-in-the-loop\n(HITL) approach. Our proposed framework, GradeHITL, utilizes the generative\nproperties of LLMs to pose questions to human experts, incorporating their\ninsights to refine grading rubrics dynamically. This adaptive process\nsignificantly improves grading accuracy, outperforming existing methods and\nbringing ASAG closer to human-level evaluation.", "published": "2025-04-07 16:23:07", "link": "http://arxiv.org/abs/2504.05239v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NoveltyBench: Evaluating Creativity and Diversity in Language Models", "abstract": "Language models have demonstrated remarkable capabilities on standard\nbenchmarks, yet they struggle increasingly from mode collapse, the inability to\ngenerate diverse and novel outputs. Our work introduces NoveltyBench, a\nbenchmark specifically designed to evaluate the ability of language models to\nproduce multiple distinct and high-quality outputs. NoveltyBench utilizes\nprompts curated to elicit diverse answers and filtered real-world user queries.\nEvaluating 20 leading language models, we find that current state-of-the-art\nsystems generate significantly less diversity than human writers. Notably,\nlarger models within a family often exhibit less diversity than their smaller\ncounterparts, challenging the notion that capability on standard benchmarks\ntranslates directly to generative utility. While prompting strategies like\nin-context regeneration can elicit diversity, our findings highlight a\nfundamental lack of distributional diversity in current models, reducing their\nutility for users seeking varied responses and suggesting the need for new\ntraining and evaluation paradigms that prioritize creativity alongside quality.", "published": "2025-04-07 16:14:23", "link": "http://arxiv.org/abs/2504.05228v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Proposing TAGbank as a Corpus of Tree-Adjoining Grammar Derivations", "abstract": "The development of lexicalized grammars, particularly Tree-Adjoining Grammar\n(TAG), has significantly advanced our understanding of syntax and semantics in\nnatural language processing (NLP). While existing syntactic resources like the\nPenn Treebank and Universal Dependencies offer extensive annotations for\nphrase-structure and dependency parsing, there is a lack of large-scale corpora\ngrounded in lexicalized grammar formalisms. To address this gap, we introduce\nTAGbank, a corpus of TAG derivations automatically extracted from existing\nsyntactic treebanks. This paper outlines a methodology for mapping\nphrase-structure annotations to TAG derivations, leveraging the generative\npower of TAG to support parsing, grammar induction, and semantic analysis. Our\napproach builds on the work of CCGbank, extending it to incorporate the unique\nstructural properties of TAG, including its transparent derivation trees and\nits ability to capture long-distance dependencies. We also discuss the\nchallenges involved in the extraction process, including ensuring consistency\nacross treebank schemes and dealing with language-specific syntactic\nidiosyncrasies. Finally, we propose the future extension of TAGbank to include\nmultilingual corpora, focusing on the Penn Korean and Penn Chinese Treebanks,\nto explore the cross-linguistic application of TAG's formalism. By providing a\nrobust, derivation-based resource, TAGbank aims to support a wide range of\ncomputational tasks and contribute to the theoretical understanding of TAG's\ngenerative capacity.", "published": "2025-04-07 16:13:19", "link": "http://arxiv.org/abs/2504.05226v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging LLMs for Utility-Focused Annotation: Reducing Manual Effort for Retrieval and RAG", "abstract": "Retrieval models typically rely on costly human-labeled query-document\nrelevance annotations for training and evaluation. To reduce this cost and\nleverage the potential of Large Language Models (LLMs) in relevance judgments,\nwe aim to explore whether LLM-generated annotations can effectively replace\nhuman annotations in training retrieval models. Retrieval usually emphasizes\nrelevance, which indicates \"topic-relatedness\" of a document to a query, while\nin RAG, the value of a document (or utility) depends on how it contributes to\nanswer generation. Recognizing this mismatch, some researchers use LLM\nperformance on downstream tasks with documents as labels, but this approach\nrequires manual answers for specific tasks, leading to high costs and limited\ngeneralization. In another line of work, prompting LLMs to select useful\ndocuments as RAG references eliminates the need for human annotation and is not\ntask-specific. If we leverage LLMs' utility judgments to annotate retrieval\ndata, we may retain cross-task generalization without human annotation in\nlarge-scale corpora. Therefore, we investigate utility-focused annotation via\nLLMs for large-scale retriever training data across both in-domain and\nout-of-domain settings on the retrieval and RAG tasks. To reduce the impact of\nlow-quality positives labeled by LLMs, we design a novel loss function, i.e.,\nDisj-InfoNCE. Our experiments reveal that: (1) Retrievers trained on\nutility-focused annotations significantly outperform those trained on human\nannotations in the out-of-domain setting on both tasks, demonstrating superior\ngeneralization capabilities. (2) LLM annotation does not replace human\nannotation in the in-domain setting. However, incorporating just 20%\nhuman-annotated data enables retrievers trained with utility-focused\nannotations to match the performance of models trained entirely with human\nannotations.", "published": "2025-04-07 16:05:52", "link": "http://arxiv.org/abs/2504.05220v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Unleashing the Power of LLMs in Dense Retrieval with Query Likelihood Modeling", "abstract": "Dense retrieval is a crucial task in Information Retrieval (IR) and is the\nfoundation for downstream tasks such as re-ranking. Recently, large language\nmodels (LLMs) have shown compelling semantic understanding capabilities and are\nappealing to researchers studying dense retrieval. LLMs, as decoder-style\ngenerative models, are competent at language generation while falling short on\nmodeling global information due to the lack of attention to tokens afterward.\nInspired by the classical word-based language modeling approach for IR, i.e.,\nthe query likelihood (QL) model, we seek to sufficiently utilize LLMs'\ngenerative ability by QL maximization. However, instead of ranking documents\nwith QL estimation, we introduce an auxiliary task of QL maximization to yield\na better backbone for contrastively learning a discriminative retriever. We\nname our model as LLM-QL. To condense global document semantics to a single\nvector during QL modeling, LLM-QL has two major components, Attention Stop (AS)\nand Input Corruption (IC). AS stops the attention of predictive tokens to\nprevious tokens until the ending token of the document. IC masks a portion of\ntokens in the input documents during prediction. Experiments on MSMARCO show\nthat LLM-QL can achieve significantly better performance than other LLM-based\nretrievers and using QL estimated by LLM-QL for ranking outperforms word-based\nQL by a large margin.", "published": "2025-04-07 16:03:59", "link": "http://arxiv.org/abs/2504.05216v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Post-Training Language Models for Continual Relation Extraction", "abstract": "Real-world data, such as news articles, social media posts, and chatbot\nconversations, is inherently dynamic and non-stationary, presenting significant\nchallenges for constructing real-time structured representations through\nknowledge graphs (KGs). Relation Extraction (RE), a fundamental component of KG\ncreation, often struggles to adapt to evolving data when traditional models\nrely on static, outdated datasets. Continual Relation Extraction (CRE) methods\ntackle this issue by incrementally learning new relations while preserving\npreviously acquired knowledge. This study investigates the application of\npre-trained language models (PLMs), specifically large language models (LLMs),\nto CRE, with a focus on leveraging memory replay to address catastrophic\nforgetting. We evaluate decoder-only models (eg, Mistral-7B and Llama2-7B) and\nencoder-decoder models (eg, Flan-T5 Base) on the TACRED and FewRel datasets.\nTask-incremental fine-tuning of LLMs demonstrates superior performance over\nearlier approaches using encoder-only models like BERT on TACRED, excelling in\nseen-task accuracy and overall performance (measured by whole and average\naccuracy), particularly with the Mistral and Flan-T5 models. Results on FewRel\nare similarly promising, achieving second place in whole and average accuracy\nmetrics. This work underscores critical factors in knowledge transfer, language\nmodel architecture, and KG completeness, advancing CRE with LLMs and memory\nreplay for dynamic, real-time relation extraction.", "published": "2025-04-07 16:01:22", "link": "http://arxiv.org/abs/2504.05214v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting individual differences to bootstrap communication", "abstract": "Establishing a communication system is hard because the intended meaning of a\nsignal is unknown to its receiver when first produced, and the signaller also\nhas no idea how that signal will be interpreted. Most theoretical accounts of\nthe emergence of communication systems rely on feedback to reinforce behaviours\nthat have led to successful communication in the past. However, providing such\nfeedback requires already being able to communicate the meaning that was\nintended or interpreted. Therefore these accounts cannot explain how\ncommunication can be bootstrapped from non-communicative behaviours. Here we\npresent a model that shows how a communication system, capable of expressing an\nunbounded number of meanings, can emerge as a result of individual behavioural\ndifferences in a large population without any pre-existing means to determine\ncommunicative success. The two key cognitive capabilities responsible for this\noutcome are behaving predictably in a given situation, and an alignment of\npsychological states ahead of signal production that derives from shared\nintentionality. Since both capabilities can exist independently of\ncommunication, our results are compatible with theories in which large flexible\nsocially-learned communication systems like language are the product of a\ngeneral but well-developed capacity for social cognition.", "published": "2025-04-07 15:58:49", "link": "http://arxiv.org/abs/2504.05211v1", "categories": ["cs.CL", "physics.soc-ph", "q-bio.PE"], "primary_category": "cs.CL"}
{"title": "Concise Reasoning via Reinforcement Learning", "abstract": "Despite significant advancements in large language models (LLMs), a major\ndrawback of reasoning models is their enormous token usage, which increases\ncomputational cost, resource requirements, and response time. In this work, we\nrevisit the core principles of reinforcement learning (RL) and, through\nmathematical analysis, demonstrate that the tendency to generate lengthy\nresponses arises inherently from RL-based optimization during training. This\nfinding questions the prevailing assumption that longer responses inherently\nimprove reasoning accuracy. Instead, we uncover a natural correlation between\nconciseness and accuracy that has been largely overlooked. Moreover, we show\nthat introducing a secondary phase of RL post-training, using a small set of\nproblems and limited resources, can significantly reduce a model's chain of\nthought while maintaining or even enhancing accuracy. Finally, we validate our\nconclusions through extensive experimental results.", "published": "2025-04-07 15:35:54", "link": "http://arxiv.org/abs/2504.05185v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CARE: Aligning Language Models for Regional Cultural Awareness", "abstract": "Existing language models (LMs) often exhibit a Western-centric bias and\nstruggle to represent diverse cultural knowledge. Previous attempts to address\nthis rely on synthetic data and express cultural knowledge only in English. In\nthis work, we study whether a small amount of human-written, multilingual\ncultural preference data can improve LMs across various model families and\nsizes. We first introduce CARE, a multilingual resource of 24.1k responses with\nhuman preferences on 2,580 questions about Chinese and Arab cultures, all\ncarefully annotated by native speakers and offering more balanced coverage.\nUsing CARE, we demonstrate that cultural alignment improves existing LMs beyond\ngeneric resources without compromising general capabilities. Moreover, we\nevaluate the cultural awareness of LMs, native speakers, and retrieved web\ncontent when queried in different languages. Our experiment reveals regional\ndisparities among LMs, which may also be reflected in the documentation gap:\nnative speakers often take everyday cultural commonsense and social norms for\ngranted, while non-natives are more likely to actively seek out and document\nthem. CARE is publicly available at https://github.com/Guochry/CARE (we plan to\nadd Japanese data in the near future).", "published": "2025-04-07 14:57:06", "link": "http://arxiv.org/abs/2504.05154v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DoCIA: An Online Document-Level Context Incorporation Agent for Speech Translation", "abstract": "Document-level context is crucial for handling discourse challenges in\ntext-to-text document-level machine translation (MT). Despite the increased\ndiscourse challenges introduced by noise from automatic speech recognition\n(ASR), the integration of document-level context in speech translation (ST)\nremains insufficiently explored. In this paper, we develop DoCIA, an online\nframework that enhances ST performance by incorporating document-level context.\nDoCIA decomposes the ST pipeline into four stages. Document-level context is\nintegrated into the ASR refinement, MT, and MT refinement stages through\nauxiliary LLM (large language model)-based modules. Furthermore, DoCIA\nleverages document-level information in a multi-level manner while minimizing\ncomputational overhead. Additionally, a simple yet effective determination\nmechanism is introduced to prevent hallucinations from excessive refinement,\nensuring the reliability of the final results. Experimental results show that\nDoCIA significantly outperforms traditional ST baselines in both sentence and\ndiscourse metrics across four LLMs, demonstrating its effectiveness in\nimproving ST performance.", "published": "2025-04-07 14:26:49", "link": "http://arxiv.org/abs/2504.05122v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AI for Climate Finance: Agentic Retrieval and Multi-Step Reasoning for Early Warning System Investments", "abstract": "Tracking financial investments in climate adaptation is a complex and\nexpertise-intensive task, particularly for Early Warning Systems (EWS), which\nlack standardized financial reporting across multilateral development banks\n(MDBs) and funds. To address this challenge, we introduce an LLM-based agentic\nAI system that integrates contextual retrieval, fine-tuning, and multi-step\nreasoning to extract relevant financial data, classify investments, and ensure\ncompliance with funding guidelines. Our study focuses on a real-world\napplication: tracking EWS investments in the Climate Risk and Early Warning\nSystems (CREWS) Fund. We analyze 25 MDB project documents and evaluate multiple\nAI-driven classification methods, including zero-shot and few-shot learning,\nfine-tuned transformer-based classifiers, chain-of-thought (CoT) prompting, and\nan agent-based retrieval-augmented generation (RAG) approach. Our results show\nthat the agent-based RAG approach significantly outperforms other methods,\nachieving 87\\% accuracy, 89\\% precision, and 83\\% recall. Additionally, we\ncontribute a benchmark dataset and expert-annotated corpus, providing a\nvaluable resource for future research in AI-driven financial tracking and\nclimate finance transparency.", "published": "2025-04-07 14:11:11", "link": "http://arxiv.org/abs/2504.05104v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "State Tuning: State-based Test-Time Scaling on RWKV-7", "abstract": "Test-time scaling has emerged as a prominent research direction in machine\nlearning, enabling models to enhance their expressive capabilities during\ninference.Transformers, renowned for striking a delicate balance between\nefficiency and expressiveness, have benefited from test-time scaling techniques\nthat leverage an expanding key-value (KV) cache to significantly improve\nperformance.In this paper, we introduce a novel state-based approach to\ntest-time scaling, which we term state tuning, tailored to the RNN-based RWKV-7\nmodel.By exploiting the unique strengths of RWKV-7, our method achieves\nstate-of-the-art performance on the target task without altering the model's\npre-trained weights. Our approach centers on three key innovations. First, we\ndevelop an observer framework that allows a smaller model to replicate and\nlearn the state dynamics of the RWKV-7 model. Second, we employ a kernel method\nto dynamically upscale the state size, enhancing the model's capacity to\ncapture intricate patterns. Third, we integrate Decorrelated Backpropagation\n(DBP) to optimize the upscaled state matrix, thereby improving convergence and\nexpressivity. By tuning only the state matrix, we demonstrate that a smaller\nmodel can outperform larger models on the given task. This method preserves the\nefficiency of the original RWKV-7 architecture while harnessing the power of\ntest-time scaling to deliver superior results. Our findings underscore the\npotential of state tuning as an effective strategy for advancing model\nperformance in resource-constrained settings. Our code is\nhttps://github.com/TorchRWKV/flash-linear-attention.", "published": "2025-04-07 14:04:30", "link": "http://arxiv.org/abs/2504.05097v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Curse of CoT: On the Limitations of Chain-of-Thought in In-Context Learning", "abstract": "Chain-of-Thought (CoT) prompting has been widely recognized for its ability\nto enhance reasoning capabilities in large language models (LLMs) through the\ngeneration of explicit explanatory rationales. However, our study reveals a\nsurprising contradiction to this prevailing perspective. Through extensive\nexperiments involving 16 state-of-the-art LLMs and nine diverse pattern-based\nin-context learning (ICL) datasets, we demonstrate that CoT and its reasoning\nvariants consistently underperform direct answering across varying model scales\nand benchmark complexities. To systematically investigate this unexpected\nphenomenon, we designed extensive experiments to validate several hypothetical\nexplanations. Our analysis uncovers a fundamental explicit-implicit duality\ndriving CoT's performance in pattern-based ICL: while explicit reasoning\nfalters due to LLMs' struggles to infer underlying patterns from\ndemonstrations, implicit reasoning-disrupted by the increased contextual\ndistance of CoT rationales-often compensates, delivering correct answers\ndespite flawed rationales. This duality explains CoT's relative\nunderperformance, as noise from weak explicit inference undermines the process,\neven as implicit mechanisms partially salvage outcomes. Notably, even long-CoT\nreasoning models, which excel in abstract and symbolic reasoning, fail to fully\novercome these limitations despite higher computational costs. Our findings\nchallenge existing assumptions regarding the universal efficacy of CoT,\nyielding novel insights into its limitations and guiding future research toward\nmore nuanced and effective reasoning methodologies for LLMs.", "published": "2025-04-07 13:51:06", "link": "http://arxiv.org/abs/2504.05081v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Performance of an Explainable Language Model on PubMedQA", "abstract": "Large language models (LLMs) have shown significant abilities in retrieving\nmedical knowledge, reasoning over it and answering medical questions comparably\nto physicians. However, these models are not interpretable, hallucinate, are\ndifficult to maintain and require enormous compute resources for training and\ninference. In this paper, we report results from Gyan, an explainable language\nmodel based on an alternative architecture, on the PubmedQA data set. The Gyan\nLLM is a compositional language model and the model is decoupled from\nknowledge. Gyan is trustable, transparent, does not hallucinate and does not\nrequire significant training or compute resources. Gyan is easily transferable\nacross domains. Gyan-4.3 achieves SOTA results on PubmedQA with 87.1% accuracy\ncompared to 82% by MedPrompt based on GPT-4 and 81.8% by Med-PaLM 2 (Google and\nDeepMind). We will be reporting results for other medical data sets - MedQA,\nMedMCQA, MMLU - Medicine in the future.", "published": "2025-04-07 13:42:02", "link": "http://arxiv.org/abs/2504.05074v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Not All Data Are Unlearned Equally", "abstract": "Machine unlearning is concerned with the task of removing knowledge learned\nfrom particular data points from a trained model. In the context of large\nlanguage models (LLMs), unlearning has recently received increased attention,\nparticularly for removing knowledge about named entities from models for\nprivacy purposes. While various approaches have been proposed to address the\nunlearning problem, most existing approaches treat all data points to be\nunlearned equally, i.e., unlearning that Montreal is a city in Canada is\ntreated exactly the same as unlearning the phone number of the first author of\nthis paper. In this work, we show that this all data is equal assumption does\nnot hold for LLM unlearning. We study how the success of unlearning depends on\nthe frequency of the knowledge we want to unlearn in the pre-training data of a\nmodel and find that frequency strongly affects unlearning, i.e., more frequent\nknowledge is harder to unlearn. Additionally, we uncover a misalignment between\nprobability and generation-based evaluations of unlearning and show that this\nproblem worsens as models become larger. Overall, our experiments highlight the\nneed for better evaluation practices and novel methods for LLM unlearning that\ntake the training data of models into account.", "published": "2025-04-07 13:29:02", "link": "http://arxiv.org/abs/2504.05058v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language Models", "abstract": "Large language models (LLMs) are foundational explorations to artificial\ngeneral intelligence, yet their alignment with human values via instruction\ntuning and preference learning achieves only superficial compliance. Here, we\ndemonstrate that harmful knowledge embedded during pretraining persists as\nindelible \"dark patterns\" in LLMs' parametric memory, evading alignment\nsafeguards and resurfacing under adversarial inducement at distributional\nshifts. In this study, we first theoretically analyze the intrinsic ethical\nvulnerability of aligned LLMs by proving that current alignment methods yield\nonly local \"safety regions\" in the knowledge manifold. In contrast, pretrained\nknowledge remains globally connected to harmful concepts via high-likelihood\nadversarial trajectories. Building on this theoretical insight, we empirically\nvalidate our findings by employing semantic coherence inducement under\ndistributional shifts--a method that systematically bypasses alignment\nconstraints through optimized adversarial prompts. This combined theoretical\nand empirical approach achieves a 100% attack success rate across 19 out of 23\nstate-of-the-art aligned LLMs, including DeepSeek-R1 and LLaMA-3, revealing\ntheir universal vulnerabilities.", "published": "2025-04-07 13:20:17", "link": "http://arxiv.org/abs/2504.05050v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Batch Aggregation: An Approach to Enhance Text Classification with Correlated Augmented Data", "abstract": "Natural language processing models often face challenges due to limited\nlabeled data, especially in domain specific areas, e.g., clinical trials. To\novercome this, text augmentation techniques are commonly used to increases\nsample size by transforming the original input data into artificial ones with\nthe label preserved. However, traditional text classification methods ignores\nthe relationship between augmented texts and treats them as independent samples\nwhich may introduce classification error. Therefore, we propose a novel\napproach called 'Batch Aggregation' (BAGG) which explicitly models the\ndependence of text inputs generated through augmentation by incorporating an\nadditional layer that aggregates results from correlated texts. Through\nstudying multiple benchmark data sets across different domains, we found that\nBAGG can improve classification accuracy. We also found that the increase of\nperformance with BAGG is more obvious in domain specific data sets, with\naccuracy improvements of up to 10-29%. Through the analysis of benchmark data,\nthe proposed method addresses limitations of traditional techniques and\nimproves robustness in text classification tasks. Our result demonstrates that\nBAGG offers more robust results and outperforms traditional approaches when\ntraining data is limited.", "published": "2025-04-07 12:46:07", "link": "http://arxiv.org/abs/2504.05020v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mixture-of-Personas Language Models for Population Simulation", "abstract": "Advances in Large Language Models (LLMs) paved the way for their emerging\napplications in various domains, such as human behavior simulations, where LLMs\ncould augment human-generated data in social science research and machine\nlearning model training. However, pretrained LLMs often fail to capture the\nbehavioral diversity of target populations due to the inherent variability\nacross individuals and groups. To address this, we propose \\textit{Mixture of\nPersonas} (MoP), a \\textit{probabilistic} prompting method that aligns the LLM\nresponses with the target population. MoP is a contextual mixture model, where\neach component is an LM agent characterized by a persona and an exemplar\nrepresenting subpopulation behaviors. The persona and exemplar are randomly\nchosen according to the learned mixing weights to elicit diverse LLM responses\nduring simulation. MoP is flexible, requires no model finetuning, and is\ntransferable across base models. Experiments for synthetic data generation show\nthat MoP outperforms competing methods in alignment and diversity metrics.", "published": "2025-04-07 12:43:05", "link": "http://arxiv.org/abs/2504.05019v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Surveying Professional Writers on AI: Limitations, Expectations, and Fears", "abstract": "The rapid development of AI-driven tools, particularly large language models\n(LLMs), is reshaping professional writing. Still, key aspects of their adoption\nsuch as languages support, ethics, and long-term impact on writers voice and\ncreativity remain underexplored. In this work, we conducted a questionnaire (N\n= 301) and an interactive survey (N = 36) targeting professional writers\nregularly using AI. We examined LLM-assisted writing practices across 25+\nlanguages, ethical concerns, and user expectations. The findings of the survey\ndemonstrate important insights, reflecting upon the importance of: LLMs\nadoption for non-English speakers; the degree of misinformation, domain and\nstyle adaptation; usability and key features of LLMs. These insights can guide\nfurther development, benefiting both writers and a broader user base.", "published": "2025-04-07 12:35:17", "link": "http://arxiv.org/abs/2504.05008v1", "categories": ["cs.CL", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Following the Whispers of Values: Unraveling Neural Mechanisms Behind Value-Oriented Behaviors in LLMs", "abstract": "Despite the impressive performance of large language models (LLMs), they can\npresent unintended biases and harmful behaviors driven by encoded values,\nemphasizing the urgent need to understand the value mechanisms behind them.\nHowever, current research primarily evaluates these values through external\nresponses with a focus on AI safety, lacking interpretability and failing to\nassess social values in real-world contexts. In this paper, we propose a novel\nframework called ValueExploration, which aims to explore the behavior-driven\nmechanisms of National Social Values within LLMs at the neuron level. As a case\nstudy, we focus on Chinese Social Values and first construct C-voice, a\nlarge-scale bilingual benchmark for identifying and evaluating Chinese Social\nValues in LLMs. By leveraging C-voice, we then identify and locate the neurons\nresponsible for encoding these values according to activation difference.\nFinally, by deactivating these neurons, we analyze shifts in model behavior,\nuncovering the internal mechanism by which values influence LLM\ndecision-making. Extensive experiments on four representative LLMs validate the\nefficacy of our framework. The benchmark and code will be available.", "published": "2025-04-07 12:23:59", "link": "http://arxiv.org/abs/2504.04994v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Domain-Based Taxonomy of Jailbreak Vulnerabilities in Large Language Models", "abstract": "The study of large language models (LLMs) is a key area in open-world machine\nlearning. Although LLMs demonstrate remarkable natural language processing\ncapabilities, they also face several challenges, including consistency issues,\nhallucinations, and jailbreak vulnerabilities. Jailbreaking refers to the\ncrafting of prompts that bypass alignment safeguards, leading to unsafe outputs\nthat compromise the integrity of LLMs. This work specifically focuses on the\nchallenge of jailbreak vulnerabilities and introduces a novel taxonomy of\njailbreak attacks grounded in the training domains of LLMs. It characterizes\nalignment failures through generalization, objectives, and robustness gaps. Our\nprimary contribution is a perspective on jailbreak, framed through the\ndifferent linguistic domains that emerge during LLM training and alignment.\nThis viewpoint highlights the limitations of existing approaches and enables us\nto classify jailbreak attacks on the basis of the underlying model deficiencies\nthey exploit. Unlike conventional classifications that categorize attacks based\non prompt construction methods (e.g., prompt templating), our approach provides\na deeper understanding of LLM behavior. We introduce a taxonomy with four\ncategories -- mismatched generalization, competing objectives, adversarial\nrobustness, and mixed attacks -- offering insights into the fundamental nature\nof jailbreak vulnerabilities. Finally, we present key lessons derived from this\ntaxonomic study.", "published": "2025-04-07 12:05:16", "link": "http://arxiv.org/abs/2504.04976v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Towards Visual Text Grounding of Multimodal Large Language Model", "abstract": "Despite the existing evolution of Multimodal Large Language Models (MLLMs), a\nnon-neglectable limitation remains in their struggle with visual text\ngrounding, especially in text-rich images of documents. Document images, such\nas scanned forms and infographics, highlight critical challenges due to their\ncomplex layouts and textual content. However, current benchmarks do not fully\naddress these challenges, as they mostly focus on visual grounding on natural\nimages, rather than text-rich document images. Thus, to bridge this gap, we\nintroduce TRIG, a novel task with a newly designed instruction dataset for\nbenchmarking and improving the Text-Rich Image Grounding capabilities of MLLMs\nin document question-answering. Specifically, we propose an OCR-LLM-human\ninteraction pipeline to create 800 manually annotated question-answer pairs as\na benchmark and a large-scale training set of 90$ synthetic data based on four\ndiverse datasets. A comprehensive evaluation of various MLLMs on our proposed\nbenchmark exposes substantial limitations in their grounding capability on\ntext-rich images. In addition, we propose two simple and effective TRIG methods\nbased on general instruction tuning and plug-and-play efficient embedding,\nrespectively. By finetuning MLLMs on our synthetic dataset, they promisingly\nimprove spatial reasoning and grounding capabilities.", "published": "2025-04-07 12:01:59", "link": "http://arxiv.org/abs/2504.04974v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Few Dimensions are Enough: Fine-tuning BERT with Selected Dimensions Revealed Its Redundant Nature", "abstract": "When fine-tuning BERT models for specific tasks, it is common to select part\nof the final layer's output and input it into a newly created fully connected\nlayer. However, it remains unclear which part of the final layer should be\nselected and what information each dimension of the layers holds. In this\nstudy, we comprehensively investigated the effectiveness and redundancy of\ntoken vectors, layers, and dimensions through BERT fine-tuning on GLUE tasks.\nThe results showed that outputs other than the CLS vector in the final layer\ncontain equivalent information, most tasks require only 2-3 dimensions, and\nwhile the contribution of lower layers decreases, there is little difference\namong higher layers. We also evaluated the impact of freezing pre-trained\nlayers and conducted cross-fine-tuning, where fine-tuning is applied\nsequentially to different tasks. The findings suggest that hidden layers may\nchange significantly during fine-tuning, BERT has considerable redundancy,\nenabling it to handle multiple tasks simultaneously, and its number of\ndimensions may be excessive.", "published": "2025-04-07 11:53:16", "link": "http://arxiv.org/abs/2504.04966v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Constraint Multi-class Positive and Unlabeled Learning for Distantly Supervised Named Entity Recognition", "abstract": "Distantly supervised named entity recognition (DS-NER) has been proposed to\nexploit the automatically labeled training data by external knowledge bases\ninstead of human annotations. However, it tends to suffer from a high false\nnegative rate due to the inherent incompleteness. To address this issue, we\npresent a novel approach called \\textbf{C}onstraint \\textbf{M}ulti-class\n\\textbf{P}ositive and \\textbf{U}nlabeled Learning (CMPU), which introduces a\nconstraint factor on the risk estimator of multiple positive classes. It\nsuggests that the constraint non-negative risk estimator is more robust against\noverfitting than previous PU learning methods with limited positive data. Solid\ntheoretical analysis on CMPU is provided to prove the validity of our approach.\nExtensive experiments on two benchmark datasets that were labeled using diverse\nexternal knowledge sources serve to demonstrate the superior performance of\nCMPU in comparison to existing DS-NER methods.", "published": "2025-04-07 11:51:41", "link": "http://arxiv.org/abs/2504.04963v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "M-Prometheus: A Suite of Open Multilingual LLM Judges", "abstract": "The use of language models for automatically evaluating long-form text\n(LLM-as-a-judge) is becoming increasingly common, yet most LLM judges are\noptimized exclusively for English, with strategies for enhancing their\nmultilingual evaluation capabilities remaining largely unexplored in the\ncurrent literature. This has created a disparity in the quality of automatic\nevaluation methods for non-English languages, ultimately hindering the\ndevelopment of models with better multilingual capabilities. To bridge this\ngap, we introduce M-Prometheus, a suite of open-weight LLM judges ranging from\n3B to 14B parameters that can provide both direct assessment and pairwise\ncomparison feedback on multilingual outputs. M-Prometheus models outperform\nstate-of-the-art open LLM judges on multilingual reward benchmarks spanning\nmore than 20 languages, as well as on literary machine translation (MT)\nevaluation covering 4 language pairs. Furthermore, M-Prometheus models can be\nleveraged at decoding time to significantly improve generated outputs across\nall 3 tested languages, showcasing their utility for the development of better\nmultilingual models. Lastly, through extensive ablations, we identify the key\nfactors for obtaining an effective multilingual judge, including backbone model\nselection and training on natively multilingual feedback data instead of\ntranslated data. We release our models, training dataset, and code.", "published": "2025-04-07 11:37:26", "link": "http://arxiv.org/abs/2504.04953v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Llama walks into the 'Bar': Efficient Supervised Fine-Tuning for Legal Reasoning in the Multi-state Bar Exam", "abstract": "Legal reasoning tasks present unique challenges for large language models\n(LLMs) due to the complexity of domain-specific knowledge and reasoning\nprocesses. This paper investigates how effectively smaller language models\n(Llama 2 7B and Llama 3 8B) can be fine-tuned with a limited dataset of 1,514\nMulti-state Bar Examination (MBE) questions to improve legal question answering\naccuracy. We evaluate these models on the 2022 MBE questions licensed from JD\nAdvising, the same dataset used in the 'GPT-4 passes the Bar exam' study. Our\nmethodology involves collecting approximately 200 questions per legal domain\nacross 7 domains. We distill the dataset using Llama 3 (70B) to transform\nexplanations into a structured IRAC (Issue, Rule, Application, Conclusion)\nformat as a guided reasoning process to see if it results in better performance\nover the non-distilled dataset. We compare the non-fine-tuned models against\ntheir supervised fine-tuned (SFT) counterparts, trained for different sample\nsizes per domain, to study the effect on accuracy and prompt adherence. We also\nanalyse option selection biases and their mitigation following SFT. In\naddition, we consolidate the performance across multiple variables: prompt type\n(few-shot vs zero-shot), answer ordering (chosen-option first vs\ngenerated-explanation first), response format (Numbered list vs Markdown vs\nJSON), and different decoding temperatures. Our findings show that\ndomain-specific SFT helps some model configurations achieve close to human\nbaseline performance, despite limited computational resources and a relatively\nsmall dataset. We release both the gathered SFT dataset and the family of\nSupervised Fine-tuned (SFT) adapters optimised for MBE performance. This\nestablishes a practical lower bound on resources needed towards achieving\neffective legal question answering in smaller LLMs.", "published": "2025-04-07 11:31:22", "link": "http://arxiv.org/abs/2504.04945v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.7; I.2.1"], "primary_category": "cs.LG"}
{"title": "How Is Generative AI Used for Persona Development?: A Systematic Review of 52 Research Articles", "abstract": "Although Generative AI (GenAI) has the potential for persona development,\nmany challenges must be addressed. This research systematically reviews 52\narticles from 2022-2024, with important findings. First, closed commercial\nmodels are frequently used in persona development, creating a monoculture\nSecond, GenAI is used in various stages of persona development (data\ncollection, segmentation, enrichment, and evaluation). Third, similar to other\nquantitative persona development techniques, there are major gaps in persona\nevaluation for AI generated personas. Fourth, human-AI collaboration models are\nunderdeveloped, despite human oversight being crucial for maintaining ethical\nstandards. These findings imply that realizing the full potential of\nAI-generated personas will require substantial efforts across academia and\nindustry. To that end, we provide a list of research avenues to inspire future\nwork.", "published": "2025-04-07 11:09:57", "link": "http://arxiv.org/abs/2504.04927v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Collab-RAG: Boosting Retrieval-Augmented Generation for Complex Question Answering via White-Box and Black-Box LLM Collaboration", "abstract": "Retrieval-Augmented Generation (RAG) systems often struggle to handle\nmulti-hop question-answering tasks accurately due to irrelevant context\nretrieval and limited complex reasoning capabilities. We introduce Collab-RAG,\na collaborative training framework that leverages mutual enhancement between a\nwhite-box small language model (SLM) and a blackbox large language model (LLM)\nfor RAG. Specifically, the SLM decomposes complex queries into simpler\nsub-questions, thus enhancing the accuracy of the retrieval and facilitating\nmore effective reasoning by the black-box LLM. Concurrently, the black-box LLM\nprovides feedback signals to improve the SLM's decomposition capability. We\nobserve that Collab-RAG relies solely on supervision from an affordable\nblack-box LLM without additional distillation from frontier LLMs, yet\ndemonstrates strong generalization across multiple black-box LLMs. Experimental\nevaluations across five multi-hop QA datasets demonstrate that Collab-RAG\nsubstantially outperforms existing black-box-only and SLM fine-tuning baselines\nby 1.8%-14.2% on average. In particular, our fine-tuned 3B SLM surpasses a\nfrozen 32B LLM in question decomposition, highlighting the efficiency of\nCollab-RAG in improving reasoning and retrieval for complex questions. The code\nof Collab-RAG is available on https://github.com/ritaranx/Collab-RAG/.", "published": "2025-04-07 10:52:22", "link": "http://arxiv.org/abs/2504.04915v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging Large Language Models for Cost-Effective, Multilingual Depression Detection and Severity Assessment", "abstract": "Depression is a prevalent mental health disorder that is difficult to detect\nearly due to subjective symptom assessments. Recent advancements in large\nlanguage models have offered efficient and cost-effective approaches for this\nobjective. In this study, we evaluated the performance of four LLMs in\ndepression detection using clinical interview data. We selected the best\nperforming model and further tested it in the severity evaluation scenario and\nknowledge enhanced scenario. The robustness was evaluated in complex diagnostic\nscenarios using a dataset comprising 51074 statements from six different mental\ndisorders. We found that DeepSeek V3 is the most reliable and cost-effective\nmodel for depression detection, performing well in both zero-shot and few-shot\nscenarios, with zero-shot being the most efficient choice. The evaluation of\nseverity showed low agreement with the human evaluator, particularly for mild\ndepression. The model maintains stably high AUCs for detecting depression in\ncomplex diagnostic scenarios. These findings highlight DeepSeek V3s strong\npotential for text-based depression detection in real-world clinical\napplications. However, they also underscore the need for further refinement in\nseverity assessment and the mitigation of potential biases to enhance clinical\nreliability.", "published": "2025-04-07 09:58:19", "link": "http://arxiv.org/abs/2504.04891v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SAFT: Structure-aware Transformers for Textual Interaction Classification", "abstract": "Textual interaction networks (TINs) are an omnipresent data structure used to\nmodel the interplay between users and items on e-commerce websites, social\nnetworks, etc., where each interaction is associated with a text description.\nClassifying such textual interactions (TIC) finds extensive use in detecting\nspam reviews in e-commerce, fraudulent transactions in finance, and so on.\nExisting TIC solutions either (i) fail to capture the rich text semantics due\nto the use of context-free text embeddings, and/or (ii) disregard the bipartite\nstructure and node heterogeneity of TINs, leading to compromised TIC\nperformance. In this work, we propose SAFT, a new architecture that integrates\nlanguage- and graph-based modules for the effective fusion of textual and\nstructural semantics in the representation learning of interactions. In\nparticular, line graph attention (LGA)/gated attention units (GAUs) and\npretrained language models (PLMs) are capitalized on to model the\ninteraction-level and token-level signals, which are further coupled via the\nproxy token in an iterative and contextualized fashion. Additionally, an\nefficient and theoretically-grounded approach is developed to encode the local\nand global topology information pertaining to interactions into structural\nembeddings. The resulting embeddings not only inject the structural features\nunderlying TINs into the textual interaction encoding but also facilitate the\ndesign of graph sampling strategies. Extensive empirical evaluations on\nmultiple real TIN datasets demonstrate the superiority of SAFT over the\nstate-of-the-art baselines in TIC accuracy.", "published": "2025-04-07 09:19:12", "link": "http://arxiv.org/abs/2504.04861v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Discovering dynamical laws for speech gestures", "abstract": "A fundamental challenge in the cognitive sciences is discovering the dynamics\nthat govern behaviour. Take the example of spoken language, which is\ncharacterised by a highly variable and complex set of physical movements that\nmap onto the small set of cognitive units that comprise language. What are the\nfundamental dynamical principles behind the movements that structure speech\nproduction? In this study, we discover models in the form of symbolic equations\nthat govern articulatory gestures during speech. A sparse symbolic regression\nalgorithm is used to discover models from kinematic data on the tongue and\nlips. We explore these candidate models using analytical techniques and\nnumerical simulations, and find that a second-order linear model achieves high\nlevels of accuracy, but a nonlinear force is required to properly model\narticulatory dynamics in approximately one third of cases. This supports the\nproposal that an autonomous, nonlinear, second-order differential equation is a\nviable dynamical law for articulatory gestures in speech. We conclude by\nidentifying future opportunities and obstacles in data-driven model discovery\nand outline prospects for discovering the dynamical principles that govern\nlanguage, brain and behaviour.", "published": "2025-04-07 09:03:32", "link": "http://arxiv.org/abs/2504.04849v1", "categories": ["cs.CL", "nlin.AO"], "primary_category": "cs.CL"}
{"title": "Quantization Hurts Reasoning? An Empirical Study on Quantized Reasoning Models", "abstract": "Recent advancements in reasoning language models have demonstrated remarkable\nperformance in complex tasks, but their extended chain-of-thought reasoning\nprocess increases inference overhead. While quantization has been widely\nadopted to reduce the inference cost of large language models, its impact on\nreasoning models remains understudied. In this study, we conduct the first\nsystematic study on quantized reasoning models, evaluating the open-sourced\nDeepSeek-R1-Distilled Qwen and LLaMA families ranging from 1.5B to 70B\nparameters, and QwQ-32B. Our investigation covers weight, KV cache, and\nactivation quantization using state-of-the-art algorithms at varying\nbit-widths, with extensive evaluation across mathematical (AIME, MATH-500),\nscientific (GPQA), and programming (LiveCodeBench) reasoning benchmarks. Our\nfindings reveal that while lossless quantization can be achieved with W8A8 or\nW4A16 quantization, lower bit-widths introduce significant accuracy risks. We\nfurther identify model size, model origin, and task difficulty as critical\ndeterminants of performance. Contrary to expectations, quantized models do not\nexhibit increased output lengths. In addition, strategically scaling the model\nsizes or reasoning steps can effectively enhance the performance. All quantized\nmodels and codes will be open-sourced in\nhttps://github.com/ruikangliu/Quantized-Reasoning-Models.", "published": "2025-04-07 08:22:45", "link": "http://arxiv.org/abs/2504.04823v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "I only read it for the plot! Maturity Ratings Affect Fanfiction Style and Community Engagement", "abstract": "We consider the textual profiles of different fanfiction maturity ratings,\nhow they vary across fan groups, and how this relates to reader engagement\nmetrics. Previous studies have shown that fanfiction writing is motivated by a\ncombination of admiration for and frustration with the fan object. These\nfindings emerge when looking at fanfiction as a whole, as well as when it is\ndivided into subgroups, also called fandoms. However, maturity ratings are used\nto indicate the intended audience of the fanfiction, as well as whether the\nstory includes mature themes and explicit scenes. Since these ratings can be\nused to filter readers and writers, they can also be seen as a proxy for\ndifferent reader/writer motivations and desires. We find that explicit\nfanfiction in particular has a distinct textual profile when compared to other\nmaturity ratings. These findings thus nuance our understanding of reader/writer\nmotivations in fanfiction communities, and also highlights the influence of the\ncommunity norms and fan behavior more generally on these cultural products.", "published": "2025-04-07 07:20:59", "link": "http://arxiv.org/abs/2504.04782v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Multilingual Retrieval-Augmented Language Models through Dialectic Reasoning Argumentations", "abstract": "Retrieval-augmented generation (RAG) is key to enhancing large language\nmodels (LLMs) to systematically access richer factual knowledge. Yet, using RAG\nbrings intrinsic challenges, as LLMs must deal with potentially conflicting\nknowledge, especially in multilingual retrieval, where the heterogeneity of\nknowledge retrieved may deliver different outlooks. To make RAG more\nanalytical, critical and grounded, we introduce Dialectic-RAG (DRAG), a modular\napproach guided by Argumentative Explanations, i.e., structured reasoning\nprocess that systematically evaluates retrieved\n  information by comparing, contrasting, and resolving conflicting\nperspectives. Given a query and a set of multilingual related documents, DRAG\nselects and exemplifies relevant knowledge for delivering dialectic\nexplanations that, by critically weighing opposing arguments and filtering\nextraneous content, clearly determine the final response. Through a series of\nin-depth experiments, we show the impact of our framework both as an in-context\nlearning strategy and for constructing demonstrations to instruct smaller\nmodels. The final results demonstrate that DRAG significantly improves RAG\napproaches, requiring low-impact computational effort and providing robustness\nto knowledge perturbations.", "published": "2025-04-07 06:55:15", "link": "http://arxiv.org/abs/2504.04771v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLMs Interpret and Leverage Structured Linguistic Representations? A Case Study with AMRs", "abstract": "This paper evaluates the ability of Large Language Models (LLMs) to leverage\ncontextual information in the form of structured linguistic representations.\nSpecifically, we examine the impact of encoding both short and long contexts\nusing Abstract Meaning Representation (AMR) structures across a diverse set of\nlanguage tasks. We perform our analysis using 8-bit quantized and\ninstruction-tuned versions of Llama 3.1 (8B), Phi-3, and Mistral 7B. Our\nresults indicate that, for tasks involving short contexts, augmenting the\nprompt with the AMR of the original language context often degrades the\nperformance of the underlying LLM. However, for tasks that involve long\ncontexts, such as dialogue summarization in the SAMSum dataset, this\nenhancement improves LLM performance, for example, by increasing the zero-shot\ncosine similarity score of Llama 3.1 from 66.2% to 76%. This improvement is\nmore evident in the newer and larger LLMs, but does not extend to the older or\nsmaller ones. In addition, we observe that LLMs can effectively reconstruct the\noriginal text from a linearized AMR, achieving a cosine similarity of 81.3% in\nthe best-case scenario.", "published": "2025-04-07 05:38:40", "link": "http://arxiv.org/abs/2504.04745v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TathyaNyaya and FactLegalLlama: Advancing Factual Judgment Prediction and Explanation in the Indian Legal Context", "abstract": "In the landscape of Fact-based Judgment Prediction and Explanation (FJPE),\nreliance on factual data is essential for developing robust and realistic\nAI-driven decision-making tools. This paper introduces TathyaNyaya, the largest\nannotated dataset for FJPE tailored to the Indian legal context, encompassing\njudgments from the Supreme Court of India and various High Courts. Derived from\nthe Hindi terms \"Tathya\" (fact) and \"Nyaya\" (justice), the TathyaNyaya dataset\nis uniquely designed to focus on factual statements rather than complete legal\ntexts, reflecting real-world judicial processes where factual data drives\noutcomes. Complementing this dataset, we present FactLegalLlama, an\ninstruction-tuned variant of the LLaMa-3-8B Large Language Model (LLM),\noptimized for generating high-quality explanations in FJPE tasks. Finetuned on\nthe factual data in TathyaNyaya, FactLegalLlama integrates predictive accuracy\nwith coherent, contextually relevant explanations, addressing the critical need\nfor transparency and interpretability in AI-assisted legal systems. Our\nmethodology combines transformers for binary judgment prediction with\nFactLegalLlama for explanation generation, creating a robust framework for\nadvancing FJPE in the Indian legal domain. TathyaNyaya not only surpasses\nexisting datasets in scale and diversity but also establishes a benchmark for\nbuilding explainable AI systems in legal analysis. The findings underscore the\nimportance of factual precision and domain-specific tuning in enhancing\npredictive performance and interpretability, positioning TathyaNyaya and\nFactLegalLlama as foundational resources for AI-assisted legal decision-making.", "published": "2025-04-07 05:27:32", "link": "http://arxiv.org/abs/2504.04737v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Synthetic Data Generation & Multi-Step RL for Reasoning & Tool Use", "abstract": "Reinforcement learning has been shown to improve the performance of large\nlanguage models. However, traditional approaches like RLHF or RLAIF treat the\nproblem as single-step. As focus shifts toward more complex reasoning and\nagentic tasks, language models must take multiple steps of text generation,\nreasoning and environment interaction before generating a solution. We propose\na synthetic data generation and RL methodology targeting multi-step\noptimization scenarios. This approach, called Step-Wise Reinforcement Learning\n(SWiRL), iteratively generates multi-step reasoning and tool use data, and then\nlearns from that data. It employs a simple step-wise decomposition that breaks\neach multi-step trajectory into multiple sub-trajectories corresponding to each\naction by the original model. It then applies synthetic data filtering and RL\noptimization on these sub-trajectories. We evaluated SWiRL on a number of\nmulti-step tool use, question answering, and mathematical reasoning tasks. Our\nexperiments show that SWiRL outperforms baseline approaches by 21.5%, 12.3%,\n14.8%, 11.1%, and 15.3% in relative accuracy on GSM8K, HotPotQA, CofCA,\nMuSiQue, and BeerQA, respectively. Excitingly, the approach exhibits\ngeneralization across tasks: for example, training only on HotPotQA (text\nquestion-answering) improves zero-shot performance on GSM8K (a math dataset) by\na relative 16.9%.", "published": "2025-04-07 05:20:58", "link": "http://arxiv.org/abs/2504.04736v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "T1: Tool-integrated Self-verification for Test-time Compute Scaling in Small Language Models", "abstract": "Recent studies have demonstrated that test-time compute scaling effectively\nimproves the performance of small language models (sLMs). However, prior\nresearch has mainly examined test-time compute scaling with an additional\nlarger model as a verifier, leaving self-verification by sLMs underexplored. In\nthis work, we investigate whether sLMs can reliably self-verify their outputs\nunder test-time scaling. We find that even with knowledge distillation from\nlarger verifiers, sLMs struggle with verification tasks requiring memorization,\nsuch as numerical calculations and fact-checking. To address this limitation,\nwe propose Tool-integrated self-verification (T1), which delegates\nmemorization-heavy verification steps to external tools, such as a code\ninterpreter. Our theoretical analysis shows that tool integration reduces\nmemorization demands and improves test-time scaling performance. Experiments on\nthe MATH benchmark demonstrate that, with T1, a Llama-3.2 1B model under\ntest-time scaling outperforms the significantly larger Llama-3.1 8B model.\nMoreover, T1 generalizes effectively to both mathematical (MATH500) and\nmulti-domain knowledge-intensive tasks (MMLU-Pro). Our findings highlight the\npotential of tool integration to substantially improve the self-verification\nabilities of sLMs.", "published": "2025-04-07 04:01:17", "link": "http://arxiv.org/abs/2504.04718v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models", "abstract": "Recent advancements in large language models (LLMs) have revolutionized their\nability to handle single-turn tasks, yet real-world applications demand\nsophisticated multi-turn interactions. This survey provides a comprehensive\nreview of recent advancements in evaluating and enhancing multi-turn\ninteractions in LLMs. Focusing on task-specific scenarios, from instruction\nfollowing in diverse domains such as math and coding to complex conversational\nengagements in roleplay, healthcare, education, and even adversarial jailbreak\nsettings, we systematically examine the challenges of maintaining context,\ncoherence, fairness, and responsiveness over prolonged dialogues. The paper\norganizes current benchmarks and datasets into coherent categories that reflect\nthe evolving landscape of multi-turn dialogue evaluation. In addition, we\nreview a range of enhancement methodologies under multi-turn settings,\nincluding model-centric strategies (contextual learning, supervised\nfine-tuning, reinforcement learning, and new architectures), external\nintegration approaches (memory-augmented, retrieval-based methods, and\nknowledge graph), and agent-based techniques for collaborative interactions.\nFinally, we discuss open challenges and propose future directions for research\nto further advance the robustness and effectiveness of multi-turn interactions\nin LLMs. Related resources and papers are available at\nhttps://github.com/yubol-cmu/Awesome-Multi-Turn-LLMs.", "published": "2025-04-07 04:00:08", "link": "http://arxiv.org/abs/2504.04717v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Are You Getting What You Pay For? Auditing Model Substitution in LLM APIs", "abstract": "The proliferation of Large Language Models (LLMs) accessed via black-box APIs\nintroduces a significant trust challenge: users pay for services based on\nadvertised model capabilities (e.g., size, performance), but providers may\ncovertly substitute the specified model with a cheaper, lower-quality\nalternative to reduce operational costs. This lack of transparency undermines\nfairness, erodes trust, and complicates reliable benchmarking. Detecting such\nsubstitutions is difficult due to the black-box nature, typically limiting\ninteraction to input-output queries. This paper formalizes the problem of model\nsubstitution detection in LLM APIs. We systematically evaluate existing\nverification techniques, including output-based statistical tests, benchmark\nevaluations, and log probability analysis, under various realistic attack\nscenarios like model quantization, randomized substitution, and benchmark\nevasion. Our findings reveal the limitations of methods relying solely on text\noutputs, especially against subtle or adaptive attacks. While log probability\nanalysis offers stronger guarantees when available, its accessibility is often\nlimited. We conclude by discussing the potential of hardware-based solutions\nlike Trusted Execution Environments (TEEs) as a pathway towards provable model\nintegrity, highlighting the trade-offs between security, performance, and\nprovider adoption. Code is available at\nhttps://github.com/sunblaze-ucb/llm-api-audit", "published": "2025-04-07 03:57:41", "link": "http://arxiv.org/abs/2504.04715v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sequential-NIAH: A Needle-In-A-Haystack Benchmark for Extracting Sequential Needles from Long Contexts", "abstract": "Evaluating the ability of large language models (LLMs) to handle extended\ncontexts is critical, particularly for retrieving information relevant to\nspecific queries embedded within lengthy inputs. We introduce Sequential-NIAH,\na benchmark specifically designed to evaluate the capability of LLMs to extract\nsequential information items (known as needles) from long contexts. The\nbenchmark comprises three types of needle generation pipelines: synthetic,\nreal, and open-domain QA. It includes contexts ranging from 8K to 128K tokens\nin length, with a dataset of 14,000 samples (2,000 reserved for testing). To\nfacilitate evaluation on this benchmark, we trained a synthetic data-driven\nevaluation model capable of evaluating answer correctness based on\nchronological or logical order, achieving an accuracy of 99.49% on synthetic\ntest data. We conducted experiments on six well-known LLMs, revealing that even\nthe best-performing model achieved a maximum accuracy of only 63.15%. Further\nanalysis highlights the growing challenges posed by increasing context lengths\nand the number of needles, underscoring substantial room for improvement.\nAdditionally, noise robustness experiments validate the reliability of the\nbenchmark, making Sequential-NIAH an important reference for advancing research\non long text extraction capabilities of LLMs.", "published": "2025-04-07 03:50:12", "link": "http://arxiv.org/abs/2504.04713v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "LagKV: Lag-Relative Information of the KV Cache Tells Which Tokens Are Important", "abstract": "The increasing size of the Key-Value (KV) cache during the Large Language\nModels long-context inference is the main obstacle for its balance between the\ndeployment cost and task accuracy. To reduce the KV cache size in such\nscenarios, most previous efforts leveraged on the attention weight to evict\nnon-critical cache tokens. But there is a trade-off in those methods, they\nusually require major modifiation of the inference infrastructure and\nsignificant computation overhead. Base on the fact that the Large Lanuage\nmodels are autoregresssive models, we propose {\\it LagKV}, a KV allocation\nstrategy only relying on straight forward comparison among KV themself. It is a\ntotally attention free method which offers easy integration to the main stream\ninference platform and comparable performance comparing to other complicated KV\ncompression methods. Results on LongBench and PasskeyRetrieval show that, our\napproach achieves nearly zero loss when the ratio is $2\\times$ and $\\approx\n90\\%$ of the original model performance for $8\\times$. Especially in the\n64-digit passkey retrieval task, our mehod outperforms the attention weight\nbased method $H_2O$ over $60\\%$ with same compression ratios. Our code is\navailable at \\url{https://github.com/AI-Lab-China-Merchants-Bank/LagKV}.", "published": "2025-04-07 03:22:15", "link": "http://arxiv.org/abs/2504.04704v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Causal Retrieval with Semantic Consideration", "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced the performance of conversational AI systems. To extend their\ncapabilities to knowledge-intensive domains such as biomedical and legal\nfields, where the accuracy is critical, LLMs are often combined with\ninformation retrieval (IR) systems to generate responses based on retrieved\ndocuments. However, for IR systems to effectively support such applications,\nthey must go beyond simple semantic matching and accurately capture diverse\nquery intents, including causal relationships. Existing IR models primarily\nfocus on retrieving documents based on surface-level semantic similarity,\noverlooking deeper relational structures such as causality. To address this, we\npropose CAWAI, a retrieval model that is trained with dual objectives: semantic\nand causal relations. Our extensive experiments demonstrate that CAWAI\noutperforms various models on diverse causal retrieval tasks especially under\nlarge-scale retrieval settings. We also show that CAWAI exhibits strong\nzero-shot generalization across scientific domain QA tasks.", "published": "2025-04-07 03:04:31", "link": "http://arxiv.org/abs/2504.04700v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "R2Vul: Learning to Reason about Software Vulnerabilities with Reinforcement Learning and Structured Reasoning Distillation", "abstract": "Large language models (LLMs) have shown promising performance in software\nvulnerability detection (SVD), yet their reasoning capabilities remain\nunreliable. Existing approaches relying on chain-of-thought (CoT) struggle to\nprovide relevant and actionable security assessments. Additionally, effective\nSVD requires not only generating coherent reasoning but also differentiating\nbetween well-founded and misleading yet plausible security assessments, an\naspect overlooked in prior work. To this end, we introduce R2Vul, a novel\napproach that distills structured reasoning into small LLMs using reinforcement\nlearning from AI feedback (RLAIF). Through RLAIF, R2Vul enables LLMs to produce\nstructured, security-aware reasoning that is actionable and reliable while\nexplicitly learning to distinguish valid assessments from misleading ones. We\nevaluate R2Vul across five languages against SAST tools, CoT, instruction\ntuning, and classification-based baselines. Our results show that R2Vul with\nstructured reasoning distillation enables a 1.5B student LLM to rival larger\nmodels while improving generalization to out-of-distribution vulnerabilities.\nBeyond model improvements, we contribute a large-scale, multilingual preference\ndataset featuring structured reasoning to support future research in SVD.", "published": "2025-04-07 03:04:16", "link": "http://arxiv.org/abs/2504.04699v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "scAgent: Universal Single-Cell Annotation via a LLM Agent", "abstract": "Cell type annotation is critical for understanding cellular heterogeneity.\nBased on single-cell RNA-seq data and deep learning models, good progress has\nbeen made in annotating a fixed number of cell types within a specific tissue.\nHowever, universal cell annotation, which can generalize across tissues,\ndiscover novel cell types, and extend to novel cell types, remains less\nexplored. To fill this gap, this paper proposes scAgent, a universal cell\nannotation framework based on Large Language Models (LLMs). scAgent can\nidentify cell types and discover novel cell types in diverse tissues;\nfurthermore, it is data efficient to learn novel cell types. Experimental\nstudies in 160 cell types and 35 tissues demonstrate the superior performance\nof scAgent in general cell-type annotation, novel cell discovery, and\nextensibility to novel cell type.", "published": "2025-04-07 03:03:21", "link": "http://arxiv.org/abs/2504.04698v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LEO-MINI: An Efficient Multimodal Large Language Model using Conditional Token Reduction and Mixture of Multi-Modal Experts", "abstract": "Redundancy of visual tokens in multi-modal large language models (MLLMs)\nsignificantly reduces their computational efficiency. Recent approaches, such\nas resamplers and summarizers, have sought to reduce the number of visual\ntokens, but at the cost of visual reasoning ability. To address this, we\npropose LEO-MINI, a novel MLLM that significantly reduces the number of visual\ntokens and simultaneously boosts visual reasoning capabilities. For efficiency,\nLEO-MINI incorporates CoTR, a novel token reduction module to consolidate a\nlarge number of visual tokens into a smaller set of tokens, using the\nsimilarity between visual tokens, text tokens, and a compact learnable query.\nFor effectiveness, to scale up the model's ability with minimal computational\noverhead, LEO-MINI employs MMoE, a novel mixture of multi-modal experts module.\nMMOE employs a set of LoRA experts with a novel router to switch between them\nbased on the input text and visual tokens instead of only using the input\nhidden state. MMoE also includes a general LoRA expert that is always activated\nto learn general knowledge for LLM reasoning. For extracting richer visual\nfeatures, MMOE employs a set of vision experts trained on diverse\ndomain-specific data. To demonstrate LEO-MINI's improved efficiency and\nperformance, we evaluate it against existing efficient MLLMs on various\nbenchmark vision-language tasks.", "published": "2025-04-07 00:55:54", "link": "http://arxiv.org/abs/2504.04653v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "URECA: Unique Region Caption Anything", "abstract": "Region-level captioning aims to generate natural language descriptions for\nspecific image regions while highlighting their distinguishing features.\nHowever, existing methods struggle to produce unique captions across\nmulti-granularity, limiting their real-world applicability. To address the need\nfor detailed region-level understanding, we introduce URECA dataset, a\nlarge-scale dataset tailored for multi-granularity region captioning. Unlike\nprior datasets that focus primarily on salient objects, URECA dataset ensures a\nunique and consistent mapping between regions and captions by incorporating a\ndiverse set of objects, parts, and background elements. Central to this is a\nstage-wise data curation pipeline, where each stage incrementally refines\nregion selection and caption generation. By leveraging Multimodal Large\nLanguage Models (MLLMs) at each stage, our pipeline produces distinctive and\ncontextually grounded captions with improved accuracy and semantic diversity.\nBuilding upon this dataset, we present URECA, a novel captioning model designed\nto effectively encode multi-granularity regions. URECA maintains essential\nspatial properties such as position and shape through simple yet impactful\nmodifications to existing MLLMs, enabling fine-grained and semantically rich\nregion descriptions. Our approach introduces dynamic mask modeling and a\nhigh-resolution mask encoder to enhance caption uniqueness. Experiments show\nthat URECA achieves state-of-the-art performance on URECA dataset and\ngeneralizes well to existing region-level captioning benchmarks.", "published": "2025-04-07 17:59:44", "link": "http://arxiv.org/abs/2504.05305v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SmolVLM: Redefining small and efficient multimodal models", "abstract": "Large Vision-Language Models (VLMs) deliver exceptional performance but\nrequire significant computational resources, limiting their deployment on\nmobile and edge devices. Smaller VLMs typically mirror design choices of larger\nmodels, such as extensive image tokenization, leading to inefficient GPU memory\nusage and constrained practicality for on-device applications.\n  We introduce SmolVLM, a series of compact multimodal models specifically\nengineered for resource-efficient inference. We systematically explore\narchitectural configurations, tokenization strategies, and data curation\noptimized for low computational overhead. Through this, we identify key design\nchoices that yield substantial performance gains on image and video tasks with\nminimal memory footprints.\n  Our smallest model, SmolVLM-256M, uses less than 1GB GPU memory during\ninference and outperforms the 300-times larger Idefics-80B model, despite an\n18-month development gap. Our largest model, at 2.2B parameters, rivals\nstate-of-the-art VLMs consuming twice the GPU memory. SmolVLM models extend\nbeyond static images, demonstrating robust video comprehension capabilities.\n  Our results emphasize that strategic architectural optimizations, aggressive\nyet efficient tokenization, and carefully curated training data significantly\nenhance multimodal performance, facilitating practical, energy-efficient\ndeployments at significantly smaller scales.", "published": "2025-04-07 17:58:57", "link": "http://arxiv.org/abs/2504.05299v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Dion: A Communication-Efficient Optimizer for Large Models", "abstract": "Training large AI models efficiently requires distributing computation across\nmultiple accelerators, but this often incurs significant communication overhead\n-- especially during gradient synchronization. We introduce Dion, a\ncommunication-efficient optimizer that retains the synchronous semantics of\nstandard distributed training (e.g., DDP, FSDP) while substantially reducing\nI/O costs. Unlike conventional optimizers that synchronize full gradient\nmatrices, Dion leverages orthonormalized updates with device-local momentum\nbuffers, eliminating the need for full gradient exchange. It further supports\nan efficient sharding strategy that avoids reconstructing large matrices during\ntraining.", "published": "2025-04-07 17:49:37", "link": "http://arxiv.org/abs/2504.05295v1", "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "cs.LG"}
{"title": "The challenge of uncertainty quantification of large language models in medicine", "abstract": "This study investigates uncertainty quantification in large language models\n(LLMs) for medical applications, emphasizing both technical innovations and\nphilosophical implications. As LLMs become integral to clinical\ndecision-making, accurately communicating uncertainty is crucial for ensuring\nreliable, safe, and ethical AI-assisted healthcare. Our research frames\nuncertainty not as a barrier but as an essential part of knowledge that invites\na dynamic and reflective approach to AI design. By integrating advanced\nprobabilistic methods such as Bayesian inference, deep ensembles, and Monte\nCarlo dropout with linguistic analysis that computes predictive and semantic\nentropy, we propose a comprehensive framework that manages both epistemic and\naleatoric uncertainties. The framework incorporates surrogate modeling to\naddress limitations of proprietary APIs, multi-source data integration for\nbetter context, and dynamic calibration via continual and meta-learning.\nExplainability is embedded through uncertainty maps and confidence metrics to\nsupport user trust and clinical interpretability. Our approach supports\ntransparent and ethical decision-making aligned with Responsible and Reflective\nAI principles. Philosophically, we advocate accepting controlled ambiguity\ninstead of striving for absolute predictability, recognizing the inherent\nprovisionality of medical knowledge.", "published": "2025-04-07 17:24:11", "link": "http://arxiv.org/abs/2504.05278v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "How to evaluate control measures for LLM agents? A trajectory from today to superintelligence", "abstract": "As LLM agents grow more capable of causing harm autonomously, AI developers\nwill rely on increasingly sophisticated control measures to prevent possibly\nmisaligned agents from causing harm. AI developers could demonstrate that their\ncontrol measures are sufficient by running control evaluations: testing\nexercises in which a red team produces agents that try to subvert control\nmeasures. To ensure control evaluations accurately capture misalignment risks,\nthe affordances granted to this red team should be adapted to the capability\nprofiles of the agents to be deployed under control measures.\n  In this paper we propose a systematic framework for adapting affordances of\nred teams to advancing AI capabilities. Rather than assuming that agents will\nalways execute the best attack strategies known to humans, we demonstrate how\nknowledge of an agents's actual capability profile can inform proportional\ncontrol evaluations, resulting in more practical and cost-effective control\nmeasures. We illustrate our framework by considering a sequence of five\nfictional models (M1-M5) with progressively advanced capabilities, defining\nfive distinct AI control levels (ACLs). For each ACL, we provide example rules\nfor control evaluation, control measures, and safety cases that could be\nappropriate. Finally, we show why constructing a compelling AI control safety\ncase for superintelligent LLM agents will require research breakthroughs,\nhighlighting that we might eventually need alternative approaches to mitigating\nmisalignment risk.", "published": "2025-04-07 16:52:52", "link": "http://arxiv.org/abs/2504.05259v1", "categories": ["cs.AI", "cs.CR"], "primary_category": "cs.AI"}
{"title": "Explaining Low Perception Model Competency with High-Competency Counterfactuals", "abstract": "There exist many methods to explain how an image classification model\ngenerates its decision, but very little work has explored methods to explain\nwhy a classifier might lack confidence in its prediction. As there are various\nreasons the classifier might lose confidence, it would be valuable for this\nmodel to not only indicate its level of uncertainty but also explain why it is\nuncertain. Counterfactual images have been used to visualize changes that could\nbe made to an image to generate a different classification decision. In this\nwork, we explore the use of counterfactuals to offer an explanation for low\nmodel competency--a generalized form of predictive uncertainty that measures\nconfidence. Toward this end, we develop five novel methods to generate\nhigh-competency counterfactual images, namely Image Gradient Descent (IGD),\nFeature Gradient Descent (FGD), Autoencoder Reconstruction (Reco), Latent\nGradient Descent (LGD), and Latent Nearest Neighbors (LNN). We evaluate these\nmethods across two unique datasets containing images with six known causes for\nlow model competency and find Reco, LGD, and LNN to be the most promising\nmethods for counterfactual generation. We further evaluate how these three\nmethods can be utilized by pre-trained Multimodal Large Language Models (MLLMs)\nto generate language explanations for low model competency. We find that the\ninclusion of a counterfactual image in the language model query greatly\nincreases the ability of the model to generate an accurate explanation for the\ncause of low model competency, thus demonstrating the utility of counterfactual\nimages in explaining low perception model competency.", "published": "2025-04-07 16:46:52", "link": "http://arxiv.org/abs/2504.05254v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Adversarial KA", "abstract": "Regarding the representation theorem of Kolmogorov and Arnold (KA) as an\nalgorithm for representing or {\\guillemotleft}expressing{\\guillemotright}\nfunctions, we test its robustness by analyzing its ability to withstand\nadversarial attacks. We find KA to be robust to countable collections of\ncontinuous adversaries, but unearth a question about the equi-continuity of the\nouter functions that, so far, obstructs taking limits and defeating continuous\ngroups of adversaries. This question on the regularity of the outer functions\nis relevant to the debate over the applicability of KA to the general theory of\nNNs.", "published": "2025-04-07 16:46:52", "link": "http://arxiv.org/abs/2504.05255v1", "categories": ["cs.LG", "cs.AI", "math.FA"], "primary_category": "cs.LG"}
{"title": "PINNverse: Accurate parameter estimation in differential equations from noisy data with constrained physics-informed neural networks", "abstract": "Parameter estimation for differential equations from measured data is an\ninverse problem prevalent across quantitative sciences. Physics-Informed Neural\nNetworks (PINNs) have emerged as effective tools for solving such problems,\nespecially with sparse measurements and incomplete system information. However,\nPINNs face convergence issues, stability problems, overfitting, and complex\nloss function design. Here we introduce PINNverse, a training paradigm that\naddresses these limitations by reformulating the learning process as a\nconstrained differential optimization problem. This approach achieves a dynamic\nbalance between data loss and differential equation residual loss during\ntraining while preventing overfitting. PINNverse combines the advantages of\nPINNs with the Modified Differential Method of Multipliers to enable\nconvergence on any point on the Pareto front. We demonstrate robust and\naccurate parameter estimation from noisy data in four classical ODE and PDE\nmodels from physics and biology. Our method enables accurate parameter\ninference also when the forward problem is expensive to solve.", "published": "2025-04-07 16:34:57", "link": "http://arxiv.org/abs/2504.05248v1", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Mapping biodiversity at very-high resolution in Europe", "abstract": "This paper describes a cascading multimodal pipeline for high-resolution\nbiodiversity mapping across Europe, integrating species distribution modeling,\nbiodiversity indicators, and habitat classification. The proposed pipeline\nfirst predicts species compositions using a deep-SDM, a multimodal model\ntrained on remote sensing, climate time series, and species occurrence data at\n50x50m resolution. These predictions are then used to generate biodiversity\nindicator maps and classify habitats with Pl@ntBERT, a transformer-based LLM\ndesigned for species-to-habitat mapping. With this approach, continental-scale\nspecies distribution maps, biodiversity indicator maps, and habitat maps are\nproduced, providing fine-grained ecological insights. Unlike traditional\nmethods, this framework enables joint modeling of interspecies dependencies,\nbias-aware training with heterogeneous presence-absence data, and large-scale\ninference from multi-source remote sensing inputs.", "published": "2025-04-07 16:15:52", "link": "http://arxiv.org/abs/2504.05231v1", "categories": ["cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "FinGrAct: A Framework for FINe-GRrained Evaluation of ACTionability in Explainable Automatic Fact-Checking", "abstract": "The field of explainable Automatic Fact-Checking (AFC) aims to enhance the\ntransparency and trustworthiness of automated fact-verification systems by\nproviding clear and comprehensible explanations. However, the effectiveness of\nthese explanations depends on their actionability --their ability to empower\nusers to make informed decisions and mitigate misinformation. Despite\nactionability being a critical property of high-quality explanations, no prior\nresearch has proposed a dedicated method to evaluate it. This paper introduces\nFinGrAct, a fine-grained evaluation framework that can access the web, and it\nis designed to assess actionability in AFC explanations through well-defined\ncriteria and an evaluation dataset. FinGrAct surpasses state-of-the-art (SOTA)\nevaluators, achieving the highest Pearson and Kendall correlation with human\njudgments while demonstrating the lowest ego-centric bias, making it a more\nrobust evaluation approach for actionability evaluation in AFC.", "published": "2025-04-07 16:14:27", "link": "http://arxiv.org/abs/2504.05229v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A moving target in AI-assisted decision-making: Dataset shift, model updating, and the problem of update opacity", "abstract": "Machine learning (ML) systems are vulnerable to performance decline over time\ndue to dataset shift. To address this problem, experts often suggest that ML\nsystems should be regularly updated to ensure ongoing performance stability.\nSome scholarly literature has begun to address the epistemic and ethical\nchallenges associated with different updating methodologies. Thus far, however,\nlittle attention has been paid to the impact of model updating on the\nML-assisted decision-making process itself, particularly in the AI ethics and\nAI epistemology literatures. This article aims to address this gap in the\nliterature. It argues that model updating introduces a new sub-type of opacity\ninto ML-assisted decision-making -- update opacity -- that occurs when users\ncannot understand how or why an update has changed the reasoning or behaviour\nof an ML system. This type of opacity presents a variety of distinctive\nepistemic and safety concerns that available solutions to the black box problem\nin ML are largely ill-equipped to address. A variety of alternative strategies\nmay be developed or pursued to address the problem of update opacity more\ndirectly, including bi-factual explanations, dynamic model reporting, and\nupdate compatibility. However, each of these strategies presents its own risks\nor carries significant limitations. Further research will be needed to address\nthe epistemic and safety concerns associated with model updating and update\nopacity going forward.", "published": "2025-04-07 15:58:23", "link": "http://arxiv.org/abs/2504.05210v1", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Correcting Class Imbalances with Self-Training for Improved Universal Lesion Detection and Tagging", "abstract": "Universal lesion detection and tagging (ULDT) in CT studies is critical for\ntumor burden assessment and tracking the progression of lesion status\n(growth/shrinkage) over time. However, a lack of fully annotated data hinders\nthe development of effective ULDT approaches. Prior work used the DeepLesion\ndataset (4,427 patients, 10,594 studies, 32,120 CT slices, 32,735 lesions, 8\nbody part labels) for algorithmic development, but this dataset is not\ncompletely annotated and contains class imbalances. To address these issues, in\nthis work, we developed a self-training pipeline for ULDT. A VFNet model was\ntrained on a limited 11.5\\% subset of DeepLesion (bounding boxes + tags) to\ndetect and classify lesions in CT studies. Then, it identified and incorporated\nnovel lesion candidates from a larger unseen data subset into its training set,\nand self-trained itself over multiple rounds. Multiple self-training\nexperiments were conducted with different threshold policies to select\npredicted lesions with higher quality and cover the class imbalances. We\ndiscovered that direct self-training improved the sensitivities of\nover-represented lesion classes at the expense of under-represented classes.\nHowever, upsampling the lesions mined during self-training along with a\nvariable threshold policy yielded a 6.5\\% increase in sensitivity at 4 FP in\ncontrast to self-training without class balancing (72\\% vs 78.5\\%) and a 11.7\\%\nincrease compared to the same self-training policy without upsampling (66.8\\%\nvs 78.5\\%). Furthermore, we show that our results either improved or maintained\nthe sensitivity at 4FP for all 8 lesion classes.", "published": "2025-04-07 15:57:03", "link": "http://arxiv.org/abs/2504.05207v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "3D Universal Lesion Detection and Tagging in CT with Self-Training", "abstract": "Radiologists routinely perform the tedious task of lesion localization,\nclassification, and size measurement in computed tomography (CT) studies.\nUniversal lesion detection and tagging (ULDT) can simultaneously help alleviate\nthe cumbersome nature of lesion measurement and enable tumor burden assessment.\nPrevious ULDT approaches utilize the publicly available DeepLesion dataset,\nhowever it does not provide the full volumetric (3D) extent of lesions and also\ndisplays a severe class imbalance. In this work, we propose a self-training\npipeline to detect 3D lesions and tag them according to the body part they\noccur in. We used a significantly limited 30\\% subset of DeepLesion to train a\nVFNet model for 2D lesion detection and tagging. Next, the 2D lesion context\nwas expanded into 3D, and the mined 3D lesion proposals were integrated back\ninto the baseline training data in order to retrain the model over multiple\nrounds. Through the self-training procedure, our VFNet model learned from its\nown predictions, detected lesions in 3D, and tagged them. Our results indicated\nthat our VFNet model achieved an average sensitivity of 46.9\\% at [0.125:8]\nfalse positives (FP) with a limited 30\\% data subset in comparison to the\n46.8\\% of an existing approach that used the entire DeepLesion dataset. To our\nknowledge, we are the first to jointly detect lesions in 3D and tag them\naccording to the body part label.", "published": "2025-04-07 15:50:27", "link": "http://arxiv.org/abs/2504.05201v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Universal Lymph Node Detection in Multiparametric MRI with Selective Augmentation", "abstract": "Robust localization of lymph nodes (LNs) in multiparametric MRI (mpMRI) is\ncritical for the assessment of lymphadenopathy. Radiologists routinely measure\nthe size of LN to distinguish benign from malignant nodes, which would require\nsubsequent cancer staging. Sizing is a cumbersome task compounded by the\ndiverse appearances of LNs in mpMRI, which renders their measurement difficult.\nFurthermore, smaller and potentially metastatic LNs could be missed during a\nbusy clinical day. To alleviate these imaging and workflow problems, we propose\na pipeline to universally detect both benign and metastatic nodes in the body\nfor their ensuing measurement. The recently proposed VFNet neural network was\nemployed to identify LN in T2 fat suppressed and diffusion weighted imaging\n(DWI) sequences acquired by various scanners with a variety of exam protocols.\nWe also use a selective augmentation technique known as Intra-Label LISA (ILL)\nto diversify the input data samples the model sees during training, such that\nit improves its robustness during the evaluation phase. We achieved a\nsensitivity of $\\sim$83\\% with ILL vs. $\\sim$80\\% without ILL at 4 FP/vol.\nCompared with current LN detection approaches evaluated on mpMRI, we show a\nsensitivity improvement of $\\sim$9\\% at 4 FP/vol.", "published": "2025-04-07 15:46:43", "link": "http://arxiv.org/abs/2504.05196v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Resource-Efficient Beam Prediction in mmWave Communications with Multimodal Realistic Simulation Framework", "abstract": "Beamforming is a key technology in millimeter-wave (mmWave) communications\nthat improves signal transmission by optimizing directionality and intensity.\nHowever, conventional channel estimation methods, such as pilot signals or beam\nsweeping, often fail to adapt to rapidly changing communication environments.\nTo address this limitation, multimodal sensing-aided beam prediction has gained\nsignificant attention, using various sensing data from devices such as LiDAR,\nradar, GPS, and RGB images to predict user locations or network conditions.\nDespite its promising potential, the adoption of multimodal sensing-aided beam\nprediction is hindered by high computational complexity, high costs, and\nlimited datasets. Thus, in this paper, a resource-efficient learning approach\nis proposed to transfer knowledge from a multimodal network to a monomodal\n(radar-only) network based on cross-modal relational knowledge distillation\n(CRKD), while reducing computational overhead and preserving predictive\naccuracy. To enable multimodal learning with realistic data, a novel multimodal\nsimulation framework is developed while integrating sensor data generated from\nthe autonomous driving simulator CARLA with MATLAB-based mmWave channel\nmodeling, and reflecting real-world conditions. The proposed CRKD achieves its\nobjective by distilling relational information across different feature spaces,\nwhich enhances beam prediction performance without relying on expensive sensor\ndata. Simulation results demonstrate that CRKD efficiently distills multimodal\nknowledge, allowing a radar-only model to achieve $94.62\\%$ of the teacher\nperformance. In particular, this is achieved with just $10\\%$ of the teacher\nnetwork's parameters, thereby significantly reducing computational complexity\nand dependence on multimodal sensor data.", "published": "2025-04-07 15:38:25", "link": "http://arxiv.org/abs/2504.05187v1", "categories": ["cs.NI", "cs.AI", "cs.LG"], "primary_category": "cs.NI"}
{"title": "Lightweight and Direct Document Relevance Optimization for Generative Information Retrieval", "abstract": "Generative information retrieval (GenIR) is a promising neural retrieval\nparadigm that formulates document retrieval as a document identifier (docid)\ngeneration task, allowing for end-to-end optimization toward a unified global\nretrieval objective. However, existing GenIR models suffer from token-level\nmisalignment, where models trained to predict the next token often fail to\ncapture document-level relevance effectively. While reinforcement\nlearning-based methods, such as reinforcement learning from relevance feedback\n(RLRF), aim to address this misalignment through reward modeling, they\nintroduce significant complexity, requiring the optimization of an auxiliary\nreward function followed by reinforcement fine-tuning, which is computationally\nexpensive and often unstable. To address these challenges, we propose direct\ndocument relevance optimization (DDRO), which aligns token-level docid\ngeneration with document-level relevance estimation through direct optimization\nvia pairwise ranking, eliminating the need for explicit reward modeling and\nreinforcement learning. Experimental results on benchmark datasets, including\nMS MARCO document and Natural Questions, show that DDRO outperforms\nreinforcement learning-based methods, achieving a 7.4% improvement in MRR@10\nfor MS MARCO and a 19.9% improvement for Natural Questions. These findings\nhighlight DDRO's potential to enhance retrieval effectiveness with a simplified\noptimization approach. By framing alignment as a direct optimization problem,\nDDRO simplifies the ranking optimization pipeline of GenIR models while\noffering a viable alternative to reinforcement learning-based methods.", "published": "2025-04-07 15:27:37", "link": "http://arxiv.org/abs/2504.05181v1", "categories": ["cs.IR", "cs.AI", "cs.DL", "cs.LG", "H.3.3"], "primary_category": "cs.IR"}
{"title": "BRIDGES: Bridging Graph Modality and Large Language Models within EDA Tasks", "abstract": "While many EDA tasks already involve graph-based data, existing LLMs in EDA\nprimarily either represent graphs as sequential text, or simply ignore\ngraph-structured data that might be beneficial like dataflow graphs of RTL\ncode. Recent studies have found that LLM performance suffers when graphs are\nrepresented as sequential text, and using additional graph information\nsignificantly boosts performance. To address these challenges, we introduce\nBRIDGES, a framework designed to incorporate graph modality into LLMs for EDA\ntasks. BRIDGES integrates an automated data generation workflow, a solution\nthat combines graph modality with LLM, and a comprehensive evaluation suite.\nFirst, we establish an LLM-driven workflow to generate RTL and netlist-level\ndata, converting them into dataflow and netlist graphs with function\ndescriptions. This workflow yields a large-scale dataset comprising over\n500,000 graph instances and more than 1.5 billion tokens. Second, we propose a\nlightweight cross-modal projector that encodes graph representations into\ntext-compatible prompts, enabling LLMs to effectively utilize graph data\nwithout architectural modifications. Experimental results demonstrate 2x to 10x\nimprovements across multiple tasks compared to text-only baselines, including\naccuracy in design retrieval, type prediction and perplexity in function\ndescription, with negligible computational overhead (<1% model weights increase\nand <30% additional runtime overhead). Even without additional LLM finetuning,\nour results outperform text-only by a large margin. We plan to release BRIDGES,\nincluding the dataset, models, and training flow.", "published": "2025-04-07 15:27:32", "link": "http://arxiv.org/abs/2504.05180v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Attention-Based Multi-Scale Temporal Fusion Network for Uncertain-Mode Fault Diagnosis in Multimode Processes", "abstract": "Fault diagnosis in multimode processes plays a critical role in ensuring the\nsafe operation of industrial systems across multiple modes. It faces a great\nchallenge yet to be addressed - that is, the significant distributional\ndifferences among monitoring data from multiple modes make it difficult for the\nmodels to extract shared feature representations related to system health\nconditions. In response to this problem, this paper introduces a novel method\ncalled attention-based multi-scale temporal fusion network. The multi-scale\ndepthwise convolution and gated recurrent unit are employed to extract\nmulti-scale contextual local features and long-short-term features. A temporal\nattention mechanism is designed to focus on critical time points with higher\ncross-mode shared information, thereby enhancing the accuracy of fault\ndiagnosis. The proposed model is applied to Tennessee Eastman process dataset\nand three-phase flow facility dataset. The experiments demonstrate that the\nproposed model achieves superior diagnostic performance and maintains a small\nmodel size.", "published": "2025-04-07 15:16:22", "link": "http://arxiv.org/abs/2504.05172v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SSLFusion: Scale & Space Aligned Latent Fusion Model for Multimodal 3D Object Detection", "abstract": "Multimodal 3D object detection based on deep neural networks has indeed made\nsignificant progress. However, it still faces challenges due to the\nmisalignment of scale and spatial information between features extracted from\n2D images and those derived from 3D point clouds. Existing methods usually\naggregate multimodal features at a single stage. However, leveraging\nmulti-stage cross-modal features is crucial for detecting objects of various\nscales. Therefore, these methods often struggle to integrate features across\ndifferent scales and modalities effectively, thereby restricting the accuracy\nof detection. Additionally, the time-consuming Query-Key-Value-based\n(QKV-based) cross-attention operations often utilized in existing methods aid\nin reasoning the location and existence of objects by capturing non-local\ncontexts. However, this approach tends to increase computational complexity. To\naddress these challenges, we present SSLFusion, a novel Scale & Space Aligned\nLatent Fusion Model, consisting of a scale-aligned fusion strategy (SAF), a\n3D-to-2D space alignment module (SAM), and a latent cross-modal fusion module\n(LFM). SAF mitigates scale misalignment between modalities by aggregating\nfeatures from both images and point clouds across multiple levels. SAM is\ndesigned to reduce the inter-modal gap between features from images and point\nclouds by incorporating 3D coordinate information into 2D image features.\nAdditionally, LFM captures cross-modal non-local contexts in the latent space\nwithout utilizing the QKV-based attention operations, thus mitigating\ncomputational complexity. Experiments on the KITTI and DENSE datasets\ndemonstrate that our SSLFusion outperforms state-of-the-art methods. Our\napproach obtains an absolute gain of 2.15% in 3D AP, compared with the\nstate-of-art method GraphAlign on the moderate level of the KITTI test set.", "published": "2025-04-07 15:15:06", "link": "http://arxiv.org/abs/2504.05170v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "RLBayes: a Bayesian Network Structure Learning Algorithm via Reinforcement Learning-Based Search Strategy", "abstract": "The score-based structure learning of Bayesian network (BN) is an effective\nway to learn BN models, which are regarded as some of the most compelling\nprobabilistic graphical models in the field of representation and reasoning\nunder uncertainty. However, the search space of structure learning grows\nsuper-exponentially as the number of variables increases, which makes BN\nstructure learning an NP-hard problem, as well as a combination optimization\nproblem (COP). Despite the successes of many heuristic methods on it, the\nresults of the structure learning of BN are usually unsatisfactory. Inspired by\nQ-learning, in this paper, a Bayesian network structure learning algorithm via\nreinforcement learning-based (RL-based) search strategy is proposed, namely\nRLBayes. The method borrows the idea of RL and tends to record and guide the\nlearning process by a dynamically maintained Q-table. By creating and\nmaintaining the dynamic Q-table, RLBayes achieve storing the unlimited search\nspace within limited space, thereby achieving the structure learning of BN via\nQ-learning. Not only is it theoretically proved that RLBayes can converge to\nthe global optimal BN structure, but also it is experimentally proved that\nRLBayes has a better effect than almost all other heuristic search algorithms.", "published": "2025-04-07 15:11:51", "link": "http://arxiv.org/abs/2504.05167v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Evaluating Knowledge Graph Based Retrieval Augmented Generation Methods under Knowledge Incompleteness", "abstract": "Knowledge Graph based Retrieval-Augmented Generation (KG-RAG) is a technique\nthat enhances Large Language Model (LLM) inference in tasks like Question\nAnswering (QA) by retrieving relevant information from knowledge graphs (KGs).\nHowever, real-world KGs are often incomplete, meaning that essential\ninformation for answering questions may be missing. Existing benchmarks do not\nadequately capture the impact of KG incompleteness on KG-RAG performance. In\nthis paper, we systematically evaluate KG-RAG methods under incomplete KGs by\nremoving triples using different methods and analyzing the resulting effects.\nWe demonstrate that KG-RAG methods are sensitive to KG incompleteness,\nhighlighting the need for more robust approaches in realistic settings.", "published": "2025-04-07 15:08:03", "link": "http://arxiv.org/abs/2504.05163v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Leveraging Label Potential for Enhanced Multimodal Emotion Recognition", "abstract": "Multimodal emotion recognition (MER) seeks to integrate various modalities to\npredict emotional states accurately. However, most current research focuses\nsolely on the fusion of audio and text features, overlooking the valuable\ninformation in emotion labels. This oversight could potentially hinder the\nperformance of existing methods, as emotion labels harbor rich, insightful\ninformation that could significantly aid MER. We introduce a novel model called\nLabel Signal-Guided Multimodal Emotion Recognition (LSGMER) to overcome this\nlimitation. This model aims to fully harness the power of emotion label\ninformation to boost the classification accuracy and stability of MER.\nSpecifically, LSGMER employs a Label Signal Enhancement module that optimizes\nthe representation of modality features by interacting with audio and text\nfeatures through label embeddings, enabling it to capture the nuances of\nemotions precisely. Furthermore, we propose a Joint Objective Optimization(JOO)\napproach to enhance classification accuracy by introducing the\nAttribution-Prediction Consistency Constraint (APC), which strengthens the\nalignment between fused features and emotion categories. Extensive experiments\nconducted on the IEMOCAP and MELD datasets have demonstrated the effectiveness\nof our proposed LSGMER model.", "published": "2025-04-07 15:00:34", "link": "http://arxiv.org/abs/2504.05158v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Reinforcement Learning Method for Environments with Stochastic Variables: Post-Decision Proximal Policy Optimization with Dual Critic Networks", "abstract": "This paper presents Post-Decision Proximal Policy Optimization (PDPPO), a\nnovel variation of the leading deep reinforcement learning method, Proximal\nPolicy Optimization (PPO). The PDPPO state transition process is divided into\ntwo steps: a deterministic step resulting in the post-decision state and a\nstochastic step leading to the next state. Our approach incorporates\npost-decision states and dual critics to reduce the problem's dimensionality\nand enhance the accuracy of value function estimation. Lot-sizing is a mixed\ninteger programming problem for which we exemplify such dynamics. The objective\nof lot-sizing is to optimize production, delivery fulfillment, and inventory\nlevels in uncertain demand and cost parameters. This paper evaluates the\nperformance of PDPPO across various environments and configurations. Notably,\nPDPPO with a dual critic architecture achieves nearly double the maximum reward\nof vanilla PPO in specific scenarios, requiring fewer episode iterations and\ndemonstrating faster and more consistent learning across different\ninitializations. On average, PDPPO outperforms PPO in environments with a\nstochastic component in the state transition. These results support the\nbenefits of using a post-decision state. Integrating this post-decision state\nin the value function approximation leads to more informed and efficient\nlearning in high-dimensional and stochastic environments.", "published": "2025-04-07 14:56:43", "link": "http://arxiv.org/abs/2504.05150v1", "categories": ["cs.LG", "cs.AI", "I.2.6; G.1.6"], "primary_category": "cs.LG"}
{"title": "EffOWT: Transfer Visual Language Models to Open-World Tracking Efficiently and Effectively", "abstract": "Open-World Tracking (OWT) aims to track every object of any category, which\nrequires the model to have strong generalization capabilities. Trackers can\nimprove their generalization ability by leveraging Visual Language Models\n(VLMs). However, challenges arise with the fine-tuning strategies when VLMs are\ntransferred to OWT: full fine-tuning results in excessive parameter and memory\ncosts, while the zero-shot strategy leads to sub-optimal performance. To solve\nthe problem, EffOWT is proposed for efficiently transferring VLMs to OWT.\nSpecifically, we build a small and independent learnable side network outside\nthe VLM backbone. By freezing the backbone and only executing backpropagation\non the side network, the model's efficiency requirements can be met. In\naddition, EffOWT enhances the side network by proposing a hybrid structure of\nTransformer and CNN to improve the model's performance in the OWT field.\nFinally, we implement sparse interactions on the MLP, thus reducing parameter\nupdates and memory costs significantly. Thanks to the proposed methods, EffOWT\nachieves an absolute gain of 5.5% on the tracking metric OWTA for unknown\ncategories, while only updating 1.3% of the parameters compared to full\nfine-tuning, with a 36.4% memory saving. Other metrics also demonstrate obvious\nimprovement.", "published": "2025-04-07 14:47:58", "link": "http://arxiv.org/abs/2504.05141v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Interpretable Style Takagi-Sugeno-Kang Fuzzy Clustering", "abstract": "Clustering is an efficient and essential technique for exploring latent\nknowledge of data. However, limited attention has been given to the\ninterpretability of the clusters detected by most clustering algorithms. In\naddition, due to the homogeneity of data, different groups of data have their\nown homogeneous styles. In this paper, the above two aspects are considered,\nand an interpretable style Takagi-Sugeno-Kang (TSK) fuzzy clustering\n(IS-TSK-FC) algorithm is proposed. The clustering behavior of IS-TSK-FC is\nfully guided by the TSK fuzzy inference on fuzzy rules. In particular, samples\nare grouped into clusters represented by the corresponding consequent vectors\nof all fuzzy rules learned in an unsupervised manner. This can explain how the\nclusters are generated in detail, thus making the underlying decision-making\nprocess of the IS-TSK-FC interpretable. Moreover, a series of style matrices\nare introduced to facilitate the consequents of fuzzy rules in IS-TSK-FC by\ncapturing the styles of clusters as well as the nuances between different\nstyles. Consequently, all the fuzzy rules in IS-TSK-FC have powerful data\nrepresentation capability. After determining the antecedents of all the fuzzy\nrules, the optimization problem of IS-TSK-FC can be iteratively solved in an\nalternation manner. The effectiveness of IS-TSK-FC as an interpretable\nclustering tool is validated through extensive experiments on benchmark\ndatasets with unknown implicit/explicit styles. Specially, the superior\nclustering performance of IS-TSK-FC is demonstrated on case studies where\ndifferent groups of data present explicit styles. The source code of IS-TSK-FC\ncan be downloaded from https://github.com/gusuhang10/IS-TSK-FC.", "published": "2025-04-07 14:28:56", "link": "http://arxiv.org/abs/2504.05125v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Balancing Robustness and Efficiency in Embedded DNNs Through Activation Function Selection", "abstract": "Machine learning-based embedded systems for safety-critical applications,\nsuch as aerospace and autonomous driving, must be robust to perturbations\ncaused by soft errors. As transistor geometries shrink and voltages decrease,\nmodern electronic devices become more susceptible to background radiation,\nincreasing the concern about failures produced by soft errors. The resilience\nof deep neural networks (DNNs) to these errors depends not only on target\ndevice technology but also on model structure and the numerical representation\nand arithmetic precision of their parameters. Compression techniques like\npruning and quantization, used to reduce memory footprint and computational\ncomplexity, alter both model structure and representation, affecting soft error\nrobustness. In this regard, although often overlooked, the choice of activation\nfunctions (AFs) impacts not only accuracy and trainability but also\ncompressibility and error resilience. This paper explores the use of bounded\nAFs to enhance robustness against parameter perturbations, while evaluating\ntheir effects on model accuracy, compressibility, and computational load with a\ntechnology-agnostic approach. We focus on encoder-decoder convolutional models\ndeveloped for semantic segmentation of hyperspectral images with application to\nautonomous driving systems. Experiments are conducted on an AMD-Xilinx's KV260\nSoM.", "published": "2025-04-07 14:21:31", "link": "http://arxiv.org/abs/2504.05119v1", "categories": ["cs.LG", "cs.AI", "cs.AR", "cs.CV", "eess.IV"], "primary_category": "cs.LG"}
{"title": "VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks", "abstract": "We present VAPO, Value-based Augmented Proximal Policy Optimization framework\nfor reasoning models., a novel framework tailored for reasoning models within\nthe value-based paradigm. Benchmarked the AIME 2024 dataset, VAPO, built on the\nQwen 32B pre-trained model, attains a state-of-the-art score of\n$\\mathbf{60.4}$. In direct comparison under identical experimental settings,\nVAPO outperforms the previously reported results of DeepSeek-R1-Zero-Qwen-32B\nand DAPO by more than 10 points. The training process of VAPO stands out for\nits stability and efficiency. It reaches state-of-the-art performance within a\nmere 5,000 steps. Moreover, across multiple independent runs, no training\ncrashes occur, underscoring its reliability. This research delves into long\nchain-of-thought (long-CoT) reasoning using a value-based reinforcement\nlearning framework. We pinpoint three key challenges that plague value-based\nmethods: value model bias, the presence of heterogeneous sequence lengths, and\nthe sparsity of reward signals. Through systematic design, VAPO offers an\nintegrated solution that effectively alleviates these challenges, enabling\nenhanced performance in long-CoT reasoning tasks.", "published": "2025-04-07 14:21:11", "link": "http://arxiv.org/abs/2504.05118v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement Learning", "abstract": "Discovering efficient algorithms for solving complex problems has been an\noutstanding challenge in mathematics and computer science, requiring\nsubstantial human expertise over the years. Recent advancements in evolutionary\nsearch with large language models (LLMs) have shown promise in accelerating the\ndiscovery of algorithms across various domains, particularly in mathematics and\noptimization. However, existing approaches treat the LLM as a static generator,\nmissing the opportunity to update the model with the signal obtained from\nevolutionary exploration. In this work, we propose to augment LLM-based\nevolutionary search by continuously refining the search operator - the LLM -\nthrough reinforcement learning (RL) fine-tuning. Our method leverages\nevolutionary search as an exploration strategy to discover improved algorithms,\nwhile RL optimizes the LLM policy based on these discoveries. Our experiments\non three combinatorial optimization tasks - bin packing, traveling salesman,\nand the flatpack problem - show that combining RL and evolutionary search\nimproves discovery efficiency of improved algorithms, showcasing the potential\nof RL-enhanced evolutionary strategies to assist computer scientists and\nmathematicians for more efficient algorithm design.", "published": "2025-04-07 14:14:15", "link": "http://arxiv.org/abs/2504.05108v1", "categories": ["cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.AI"}
{"title": "SpeakEasy: Enhancing Text-to-Speech Interactions for Expressive Content Creation", "abstract": "Novice content creators often invest significant time recording expressive\nspeech for social media videos. While recent advancements in text-to-speech\n(TTS) technology can generate highly realistic speech in various languages and\naccents, many struggle with unintuitive or overly granular TTS interfaces. We\npropose simplifying TTS generation by allowing users to specify high-level\ncontext alongside their script. Our Wizard-of-Oz system, SpeakEasy, leverages\nuser-provided context to inform and influence TTS output, enabling iterative\nrefinement with high-level feedback. This approach was informed by two\n8-subject formative studies: one examining content creators' experiences with\nTTS, and the other drawing on effective strategies from voice actors. Our\nevaluation shows that participants using SpeakEasy were more successful in\ngenerating performances matching their personal standards, without requiring\nsignificantly more effort than leading industry interfaces.", "published": "2025-04-07 14:13:49", "link": "http://arxiv.org/abs/2504.05106v1", "categories": ["cs.HC", "cs.AI", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Debate Only When Necessary: Adaptive Multiagent Collaboration for Efficient LLM Reasoning", "abstract": "Multiagent collaboration has emerged as a promising framework for enhancing\nthe reasoning capabilities of large language models (LLMs). While this approach\nimproves reasoning capability, it incurs substantial computational overhead due\nto iterative agent interactions. Furthermore, engaging in debates for queries\nthat do not necessitate collaboration amplifies the risk of error generation.\nTo address these challenges, we propose Debate Only When Necessary (DOWN), an\nadaptive multiagent debate framework that selectively activates the debate\nprocess based on the confidence score of the agent's initial response. For\nqueries where debate is triggered, agents refine their outputs using responses\nfrom participating agents and their confidence scores. Experimental results\ndemonstrate that this mechanism significantly improves efficiency while\nmaintaining or even surpassing the performance of existing multiagent debate\nsystems. We also find that confidence-guided debate mitigates error propagation\nand enhances the selective incorporation of reliable responses. These results\nestablish DOWN as an optimization strategy for efficient and effective\nmultiagent reasoning, facilitating the practical deployment of LLM-based\ncollaboration.", "published": "2025-04-07 13:17:52", "link": "http://arxiv.org/abs/2504.05047v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Graph-based Diffusion Model for Collaborative Filtering", "abstract": "Recently, diffusion-based recommendation methods have achieved impressive\nresults. However, existing approaches predominantly treat each user's\nhistorical interactions as independent training samples, overlooking the\npotential of higher-order collaborative signals between users and items. Such\nsignals, which encapsulate richer and more nuanced relationships, can be\nnaturally captured using graph-based data structures. To address this\nlimitation, we extend diffusion-based recommendation methods to the graph\ndomain by directly modeling user-item bipartite graphs with diffusion models.\nThis enables better modeling of the higher-order connectivity inherent in\ncomplex interaction dynamics. However, this extension introduces two primary\nchallenges: (1) Noise Heterogeneity, where interactions are influenced by\nvarious forms of continuous and discrete noise, and (2) Relation Explosion,\nreferring to the high computational costs of processing large-scale graphs. To\ntackle these challenges, we propose a Graph-based Diffusion Model for\nCollaborative Filtering (GDMCF). To address noise heterogeneity, we introduce a\nmulti-level noise corruption mechanism that integrates both continuous and\ndiscrete noise, effectively simulating real-world interaction complexities. To\nmitigate relation explosion, we design a user-active guided diffusion process\nthat selectively focuses on the most meaningful edges and active users,\nreducing inference costs while preserving the graph's topological integrity.\nExtensive experiments on three benchmark datasets demonstrate that GDMCF\nconsistently outperforms state-of-the-art methods, highlighting its\neffectiveness in capturing higher-order collaborative signals and improving\nrecommendation performance.", "published": "2025-04-07 12:51:18", "link": "http://arxiv.org/abs/2504.05029v1", "categories": ["cs.SI", "cs.AI", "cs.LG"], "primary_category": "cs.SI"}
{"title": "Measuring the right thing: justifying metrics in AI impact assessments", "abstract": "AI Impact Assessments are only as good as the measures used to assess the\nimpact of these systems. It is therefore paramount that we can justify our\nchoice of metrics in these assessments, especially for difficult to quantify\nethical and social values. We present a two-step approach to ensure metrics are\nproperly motivated. First, a conception needs to be spelled out (e.g. Rawlsian\nfairness or fairness as solidarity) and then a metric can be fitted to that\nconception. Both steps require separate justifications, as conceptions can be\njudged on how well they fit with the function of, for example, fairness. We\nargue that conceptual engineering offers helpful tools for this step. Second,\nmetrics need to be fitted to a conception. We illustrate this process through\nan examination of competing fairness metrics to illustrate that here the\nadditional content that a conception offers helps us justify the choice for a\nspecific metric. We thus advocate that impact assessments are not only clear on\ntheir metrics, but also on the conceptions that motivate those metrics.", "published": "2025-04-07 12:32:41", "link": "http://arxiv.org/abs/2504.05007v1", "categories": ["cs.CY", "cs.AI", "cs.ET"], "primary_category": "cs.CY"}
{"title": "SurvSurf: a partially monotonic neural network for first-hitting time prediction of intermittently observed discrete and continuous sequential events", "abstract": "We propose a neural-network based survival model (SurvSurf) specifically\ndesigned for direct and simultaneous probabilistic prediction of the first\nhitting time of sequential events from baseline. Unlike existing models,\nSurvSurf is theoretically guaranteed to never violate the monotonic\nrelationship between the cumulative incidence functions of sequential events,\nwhile allowing nonlinear influence from predictors. It also incorporates\nimplicit truths for unobserved intermediate events in model fitting, and\nsupports both discrete and continuous time and events. We also identified a\nvariant of the Integrated Brier Score (IBS) that showed robust correlation with\nthe mean squared error (MSE) between the true and predicted probabilities by\naccounting for implied truths about the missing intermediate events. We\ndemonstrated the superiority of SurvSurf compared to modern and traditional\npredictive survival models in two simulated datasets and two real-world\ndatasets, using MSE, the more robust IBS and by measuring the extent of\nmonotonicity violation.", "published": "2025-04-07 12:24:59", "link": "http://arxiv.org/abs/2504.04997v1", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.ST", "stat.AP", "stat.TH", "62N01"], "primary_category": "stat.ML"}
{"title": "RS-RAG: Bridging Remote Sensing Imagery and Comprehensive Knowledge with a Multi-Modal Dataset and Retrieval-Augmented Generation Model", "abstract": "Recent progress in VLMs has demonstrated impressive capabilities across a\nvariety of tasks in the natural image domain. Motivated by these advancements,\nthe remote sensing community has begun to adopt VLMs for remote sensing\nvision-language tasks, including scene understanding, image captioning, and\nvisual question answering. However, existing remote sensing VLMs typically rely\non closed-set scene understanding and focus on generic scene descriptions, yet\nlack the ability to incorporate external knowledge. This limitation hinders\ntheir capacity for semantic reasoning over complex or context-dependent queries\nthat involve domain-specific or world knowledge. To address these challenges,\nwe first introduced a multimodal Remote Sensing World Knowledge (RSWK) dataset,\nwhich comprises high-resolution satellite imagery and detailed textual\ndescriptions for 14,141 well-known landmarks from 175 countries, integrating\nboth remote sensing domain knowledge and broader world knowledge. Building upon\nthis dataset, we proposed a novel Remote Sensing Retrieval-Augmented Generation\n(RS-RAG) framework, which consists of two key components. The Multi-Modal\nKnowledge Vector Database Construction module encodes remote sensing imagery\nand associated textual knowledge into a unified vector space. The Knowledge\nRetrieval and Response Generation module retrieves and re-ranks relevant\nknowledge based on image and/or text queries, and incorporates the retrieved\ncontent into a knowledge-augmented prompt to guide the VLM in producing\ncontextually grounded responses. We validated the effectiveness of our approach\non three representative vision-language tasks, including image captioning,\nimage classification, and visual question answering, where RS-RAG significantly\noutperformed state-of-the-art baselines.", "published": "2025-04-07 12:13:43", "link": "http://arxiv.org/abs/2504.04988v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Transforming Future Data Center Operations and Management via Physical AI", "abstract": "Data centers (DCs) as mission-critical infrastructures are pivotal in\npowering the growth of artificial intelligence (AI) and the digital economy.\nThe evolution from Internet DC to AI DC has introduced new challenges in\noperating and managing data centers for improved business resilience and\nreduced total cost of ownership. As a result, new paradigms, beyond the\ntraditional approaches based on best practices, must be in order for future\ndata centers. In this research, we propose and develop a novel Physical AI\n(PhyAI) framework for advancing DC operations and management. Our system\nleverages the emerging capabilities of state-of-the-art industrial products and\nour in-house research and development. Specifically, it presents three core\nmodules, namely: 1) an industry-grade in-house simulation engine to simulate DC\noperations in a highly accurate manner, 2) an AI engine built upon NVIDIA\nPhysicsNemo for the training and evaluation of physics-informed machine\nlearning (PIML) models, and 3) a digital twin platform built upon NVIDIA\nOmniverse for our proposed 5-tier digital twin framework. This system presents\na scalable and adaptable solution to digitalize, optimize, and automate future\ndata center operations and management, by enabling real-time digital twins for\nfuture data centers. To illustrate its effectiveness, we present a compelling\ncase study on building a surrogate model for predicting the thermal and airflow\nprofiles of a large-scale DC in a real-time manner. Our results demonstrate its\nsuperior performance over traditional time-consuming Computational Fluid\nDynamics/Heat Transfer (CFD/HT) simulation, with a median absolute temperature\nprediction error of 0.18 {\\deg}C. This emerging approach would open doors to\nseveral potential research directions for advancing Physical AI in future DC\noperations.", "published": "2025-04-07 12:09:22", "link": "http://arxiv.org/abs/2504.04982v1", "categories": ["cs.AI", "cs.DC"], "primary_category": "cs.AI"}
{"title": "DiCoTTA: Domain-invariant Learning for Continual Test-time Adaptation", "abstract": "This paper studies continual test-time adaptation (CTTA), the task of\nadapting a model to constantly changing unseen domains in testing while\npreserving previously learned knowledge. Existing CTTA methods mostly focus on\nadaptation to the current test domain only, overlooking generalization to\narbitrary test domains a model may face in the future. To tackle this\nlimitation, we present a novel online domain-invariant learning framework for\nCTTA, dubbed DiCoTTA. DiCoTTA aims to learn feature representation to be\ninvariant to both current and previous test domains on the fly during testing.\nTo this end, we propose a new model architecture and a test-time adaptation\nstrategy dedicated to learning domain-invariant features without corrupting\nsemantic contents, along with a new data structure and optimization algorithm\nfor effectively managing information from previous test domains. DiCoTTA\nachieved state-of-the-art performance on four public CTTA benchmarks. Moreover,\nit showed superior generalization to unseen test domains.", "published": "2025-04-07 12:09:18", "link": "http://arxiv.org/abs/2504.04981v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Ensuring Safety in an Uncertain Environment: Constrained MDPs via Stochastic Thresholds", "abstract": "This paper studies constrained Markov decision processes (CMDPs) with\nconstraints against stochastic thresholds, aiming at safety of reinforcement\nlearning in unknown and uncertain environments. We leverage a Growing-Window\nestimator sampling from interactions with the uncertain and dynamic environment\nto estimate the thresholds, based on which we design Stochastic\nPessimistic-Optimistic Thresholding (SPOT), a novel model-based primal-dual\nalgorithm for multiple constraints against stochastic thresholds. SPOT enables\nreinforcement learning under both pessimistic and optimistic threshold\nsettings. We prove that our algorithm achieves sublinear regret and constraint\nviolation; i.e., a reward regret of $\\tilde{\\mathcal{O}}(\\sqrt{T})$ while\nallowing an $\\tilde{\\mathcal{O}}(\\sqrt{T})$ constraint violation over $T$\nepisodes. The theoretical guarantees show that our algorithm achieves\nperformance comparable to that of an approach relying on fixed and clear\nthresholds. To the best of our knowledge, SPOT is the first reinforcement\nlearning algorithm that realises theoretical guaranteed performance in an\nuncertain environment where even thresholds are unknown.", "published": "2025-04-07 11:58:19", "link": "http://arxiv.org/abs/2504.04973v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A High-Force Gripper with Embedded Multimodal Sensing for Powerful and Perception Driven Grasping", "abstract": "Modern humanoid robots have shown their promising potential for executing\nvarious tasks involving the grasping and manipulation of objects using their\nend-effectors. Nevertheless, in the most of the cases, the grasping and\nmanipulation actions involve low to moderate payload and interaction forces.\nThis is due to limitations often presented by the end-effectors, which can not\nmatch their arm-reachable payload, and hence limit the payload that can be\ngrasped and manipulated. In addition, grippers usually do not embed adequate\nperception in their hardware, and grasping actions are mainly driven by\nperception sensors installed in the rest of the robot body, frequently affected\nby occlusions due to the arm motions during the execution of the grasping and\nmanipulation tasks. To address the above, we developed a modular high grasping\nforce gripper equipped with embedded multi-modal perception functionalities.\nThe proposed gripper can generate a grasping force of 110 N in a compact\nimplementation. The high grasping force capability is combined with embedded\nmulti-modal sensing, which includes an eye-in-hand camera, a Time-of-Flight\n(ToF) distance sensor, an Inertial Measurement Unit (IMU) and an\nomnidirectional microphone, permitting the implementation of perception-driven\ngrasping functionalities.\n  We extensively evaluated the grasping force capacity of the gripper by\nintroducing novel payload evaluation metrics that are a function of the robot\narm's dynamic motion and gripper thermal states. We also evaluated the embedded\nmulti-modal sensing by performing perception-guided enhanced grasping\noperations.", "published": "2025-04-07 11:57:08", "link": "http://arxiv.org/abs/2504.04970v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "The Dream Within Huang Long Cave: AI-Driven Interactive Narrative for Family Storytelling and Emotional Reflection", "abstract": "This paper introduces the art project The Dream Within Huang Long Cave, an\nAI-driven interactive and immersive narrative experience. The project offers\nnew insights into AI technology, artistic practice, and psychoanalysis.\nInspired by actual geographical landscapes and familial archetypes, the work\ncombines psychoanalytic theory and computational technology, providing an\nartistic response to the concept of the non-existence of the Big Other. The\nnarrative is driven by a combination of a large language model (LLM) and a\nrealistic digital character, forming a virtual agent named YELL. Through\ndialogue and exploration within a cave automatic virtual environment (CAVE),\nthe audience is invited to unravel the language puzzles presented by YELL and\nhelp him overcome his life challenges. YELL is a fictional embodiment of the\nBig Other, modeled after the artist's real father. Through a cross-temporal\ninteraction with this digital father, the project seeks to deconstruct complex\nfamilial relationships. By demonstrating the non-existence of the Big Other, we\naim to underscore the authenticity of interpersonal emotions, positioning art\nas a bridge for emotional connection and understanding within family dynamics.", "published": "2025-04-07 11:54:11", "link": "http://arxiv.org/abs/2504.04968v1", "categories": ["cs.MM", "cs.AI"], "primary_category": "cs.MM"}
{"title": "GOTHAM: Graph Class Incremental Learning Framework under Weak Supervision", "abstract": "Graphs are growing rapidly, along with the number of distinct label\ncategories associated with them. Applications like e-commerce, healthcare,\nrecommendation systems, and various social media platforms are rapidly moving\ntowards graph representation of data due to their ability to capture both\nstructural and attribute information. One crucial task in graph analysis is\nnode classification, where unlabeled nodes are categorized into predefined\nclasses. In practice, novel classes appear incrementally sometimes with just a\nfew labels (seen classes) or even without any labels (unseen classes), either\nbecause they are new or haven't been explored much. Traditional methods assume\nabundant labeled data for training, which isn't always feasible. We investigate\na broader objective: \\emph{Graph Class Incremental Learning under Weak\nSupervision (GCL)}, addressing this challenge by meta-training on base classes\nwith limited labeled instances. During the incremental streams, novel classes\ncan have few-shot or zero-shot representation. Our proposed framework GOTHAM\nefficiently accommodates these unlabeled nodes by finding the closest prototype\nrepresentation, serving as class representatives in the attribute space. For\nText-Attributed Graphs (TAGs), our framework additionally incorporates semantic\ninformation to enhance the representation. By employing teacher-student\nknowledge distillation to mitigate forgetting, GOTHAM achieves promising\nresults across various tasks. Experiments on datasets such as Cora-ML, Amazon,\nand OBGN-Arxiv showcase the effectiveness of our approach in handling evolving\ngraph data under limited supervision. The repository is available here:\n\\href{https://github.com/adityashahane10/GOTHAM--Graph-based-Class-Incremental-Learning-Framework-under-Weak-Supervision}{\\small\n\\textcolor{blue}{Code}}", "published": "2025-04-07 11:39:13", "link": "http://arxiv.org/abs/2504.04954v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "One Quantizer is Enough: Toward a Lightweight Audio Codec", "abstract": "Neural audio codecs have recently gained traction for their ability to\ncompress high-fidelity audio and generate discrete tokens that can be utilized\nin downstream generative modeling tasks. However, leading approaches often rely\non resource-intensive models and multi-quantizer architectures, resulting in\nconsiderable computational overhead and constrained real-world applicability.\nIn this paper, we present SQCodec, a lightweight neural audio codec that\nleverages a single quantizer to address these limitations. SQCodec explores\nstreamlined convolutional networks and local Transformer modules, alongside\nTConv, a novel mechanism designed to capture acoustic variations across\nmultiple temporal scales, thereby enhancing reconstruction fidelity while\nreducing model complexity. Extensive experiments across diverse datasets show\nthat SQCodec achieves audio quality comparable to multi-quantizer baselines,\nwhile its single-quantizer design offers enhanced adaptability and its\nlightweight architecture reduces resource consumption by an order of magnitude.\nThe source code is publicly available at https://github.com/zhai-lw/SQCodec.", "published": "2025-04-07 11:34:39", "link": "http://arxiv.org/abs/2504.04949v1", "categories": ["cs.SD", "cs.AI", "68T07", "I.2.m"], "primary_category": "cs.SD"}
{"title": "Lemmanaid: Neuro-Symbolic Lemma Conjecturing", "abstract": "Automatically conjecturing useful, interesting and novel lemmas would greatly\nimprove automated reasoning tools and lower the bar for formalizing mathematics\nin proof assistants. It is however a very challenging task for both neural and\nsymbolic approaches. We present the first steps towards a practical\nneuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language\nModels (LLMs) and symbolic methods, and evaluate it on proof libraries for the\nIsabelle proof assistant. We train an LLM to generate lemma templates that\ndescribe the shape of a lemma, and use symbolic methods to fill in the details.\nWe compare Lemmanaid against an LLM trained to generate complete lemma\nstatements as well as previous fully symbolic conjecturing methods. Our results\nindicate that neural and symbolic techniques are complementary. By leveraging\nthe best of both symbolic and neural methods we can generate useful lemmas for\na wide range of input domains, facilitating computer-assisted theory\ndevelopment and formalization.", "published": "2025-04-07 11:30:36", "link": "http://arxiv.org/abs/2504.04942v1", "categories": ["cs.AI", "cs.LO"], "primary_category": "cs.AI"}
{"title": "A Taxonomy of Self-Handover", "abstract": "Self-handover, transferring an object between one's own hands, is a common\nbut understudied bimanual action. While it facilitates seamless transitions in\ncomplex tasks, the strategies underlying its execution remain largely\nunexplored. Here, we introduce the first systematic taxonomy of self-handover,\nderived from manual annotation of over 12 hours of cooking activity performed\nby 21 participants. Our analysis reveals that self-handover is not merely a\npassive transition, but a highly coordinated action involving anticipatory\nadjustments by both hands. As a step toward automated analysis of human\nmanipulation, we further demonstrate the feasibility of classifying\nself-handover types using a state-of-the-art vision-language model. These\nfindings offer fresh insights into bimanual coordination, underscoring the role\nof self-handover in enabling smooth task transitions-an ability essential for\nadaptive dual-arm robotics.", "published": "2025-04-07 11:21:42", "link": "http://arxiv.org/abs/2504.04939v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "RCCFormer: A Robust Crowd Counting Network Based on Transformer", "abstract": "Crowd counting, which is a key computer vision task, has emerged as a\nfundamental technology in crowd analysis and public safety management. However,\nchallenges such as scale variations and complex backgrounds significantly\nimpact the accuracy of crowd counting. To mitigate these issues, this paper\nproposes a robust Transformer-based crowd counting network, termed RCCFormer,\nspecifically designed for background suppression and scale awareness. The\nproposed method incorporates a Multi-level Feature Fusion Module (MFFM), which\nmeticulously integrates features extracted at diverse stages of the backbone\narchitecture. It establishes a strong baseline capable of capturing intricate\nand comprehensive feature representations, surpassing traditional baselines.\nFurthermore, the introduced Detail-Embedded Attention Block (DEAB) captures\ncontextual information and local details through global self-attention and\nlocal attention along with a learnable manner for efficient fusion. This\nenhances the model's ability to focus on foreground regions while effectively\nmitigating background noise interference. Additionally, we develop an Adaptive\nScale-Aware Module (ASAM), with our novel Input-dependent Deformable\nConvolution (IDConv) as its fundamental building block. This module dynamically\nadapts to changes in head target shapes and scales, significantly improving the\nnetwork's capability to accommodate large-scale variations. The effectiveness\nof the proposed method is validated on the ShanghaiTech Part_A and Part_B,\nNWPU-Crowd, and QNRF datasets. The results demonstrate that our RCCFormer\nachieves excellent performance across all four datasets, showcasing\nstate-of-the-art outcomes.", "published": "2025-04-07 11:19:05", "link": "http://arxiv.org/abs/2504.04935v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Boosting Relational Deep Learning with Pretrained Tabular Models", "abstract": "Relational databases, organized into tables connected by primary-foreign key\nrelationships, are a common format for organizing data. Making predictions on\nrelational data often involves transforming them into a flat tabular format\nthrough table joins and feature engineering, which serve as input to tabular\nmethods. However, designing features that fully capture complex relational\npatterns remains challenging. Graph Neural Networks (GNNs) offer a compelling\nalternative by inherently modeling these relationships, but their time overhead\nduring inference limits their applicability for real-time scenarios. In this\nwork, we aim to bridge this gap by leveraging existing feature engineering\nefforts to enhance the efficiency of GNNs in relational databases.\nSpecifically, we use GNNs to capture complex relationships within relational\ndatabases, patterns that are difficult to featurize, while employing engineered\nfeatures to encode temporal information, thereby avoiding the need to retain\nthe entire historical graph and enabling the use of smaller, more efficient\ngraphs. Our \\textsc{LightRDL} approach not only improves efficiency, but also\noutperforms existing models. Experimental results on the RelBench benchmark\ndemonstrate that our framework achieves up to $33\\%$ performance improvement\nand a $526\\times$ inference speedup compared to GNNs, making it highly suitable\nfor real-time inference.", "published": "2025-04-07 11:19:04", "link": "http://arxiv.org/abs/2504.04934v1", "categories": ["cs.DB", "cs.AI", "cs.LG"], "primary_category": "cs.DB"}
{"title": "Expectations vs Reality -- A Secondary Study on AI Adoption in Software Testing", "abstract": "In the software industry, artificial intelligence (AI) has been utilized more\nand more in software development activities. In some activities, such as\ncoding, AI has already been an everyday tool, but in software testing\nactivities AI it has not yet made a significant breakthrough. In this paper,\nthe objective was to identify what kind of empirical research with industry\ncontext has been conducted on AI in software testing, as well as how AI has\nbeen adopted in software testing practice. To achieve this, we performed a\nsystematic mapping study of recent (2020 and later) studies on AI adoption in\nsoftware testing in the industry, and applied thematic analysis to identify\ncommon themes and categories, such as the real-world use cases and benefits, in\nthe found papers. The observations suggest that AI is not yet heavily utilized\nin software testing, and still relatively few studies on AI adoption in\nsoftware testing have been conducted in the industry context to solve\nreal-world problems. Earlier studies indicated there was a noticeable gap\nbetween the actual use cases and actual benefits versus the expectations, which\nwe analyzed further. While there were numerous potential use cases for AI in\nsoftware testing, such as test case generation, code analysis, and intelligent\ntest automation, the reported actual implementations and observed benefits were\nlimited. In addition, the systematic mapping study revealed a potential problem\nwith false positive search results in online databases when using the search\nstring \"artificial intelligence\".", "published": "2025-04-07 11:03:54", "link": "http://arxiv.org/abs/2504.04921v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Constitution or Collapse? Exploring Constitutional AI with Llama 3-8B", "abstract": "As language models continue to grow larger, the cost of acquiring\nhigh-quality training data has increased significantly. Collecting human\nfeedback is both expensive and time-consuming, and manual labels can be noisy,\nleading to an imbalance between helpfulness and harmfulness. Constitutional AI,\nintroduced by Anthropic in December 2022, uses AI to provide feedback to\nanother AI, greatly reducing the need for human labeling. However, the original\nimplementation was designed for a model with around 52 billion parameters, and\nthere is limited information on how well Constitutional AI performs with\nsmaller models, such as LLaMA 3-8B. In this paper, we replicated the\nConstitutional AI workflow using the smaller LLaMA 3-8B model. Our results show\nthat Constitutional AI can effectively increase the harmlessness of the model,\nreducing the Attack Success Rate in MT-Bench by 40.8%. However, similar to the\noriginal study, increasing harmlessness comes at the cost of helpfulness. The\nhelpfulness metrics, which are an average of the Turn 1 and Turn 2 scores,\ndropped by 9.8% compared to the baseline. Additionally, we observed clear signs\nof model collapse in the final DPO-CAI model, indicating that smaller models\nmay struggle with self-improvement due to insufficient output quality, making\neffective fine-tuning more challenging. Our study suggests that, like reasoning\nand math ability, self-improvement is an emergent property.", "published": "2025-04-07 11:01:25", "link": "http://arxiv.org/abs/2504.04918v1", "categories": ["cs.AI", "68T05, 68T50", "I.2.6; I.2.7; I.2.1"], "primary_category": "cs.AI"}
{"title": "AlgOS: Algorithm Operating System", "abstract": "Algorithm Operating System (AlgOS) is an unopinionated, extensible, modular\nframework for algorithmic implementations. AlgOS offers numerous features:\nintegration with Optuna for automated hyperparameter tuning; automated argument\nparsing for generic command-line interfaces; automated registration of new\nclasses; and a centralised database for logging experiments and studies. These\nfeatures are designed to reduce the overhead of implementing new algorithms and\nto standardise the comparison of algorithms. The standardisation of algorithmic\nimplementations is crucial for reproducibility and reliability in research.\nAlgOS combines Abstract Syntax Trees with a novel implementation of the\nObserver pattern to control the logical flow of algorithmic segments.", "published": "2025-04-07 10:36:46", "link": "http://arxiv.org/abs/2504.04909v1", "categories": ["cs.SE", "cs.AI", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Video-Bench: Human-Aligned Video Generation Benchmark", "abstract": "Video generation assessment is essential for ensuring that generative models\nproduce visually realistic, high-quality videos while aligning with human\nexpectations. Current video generation benchmarks fall into two main\ncategories: traditional benchmarks, which use metrics and embeddings to\nevaluate generated video quality across multiple dimensions but often lack\nalignment with human judgments; and large language model (LLM)-based\nbenchmarks, though capable of human-like reasoning, are constrained by a\nlimited understanding of video quality metrics and cross-modal consistency. To\naddress these challenges and establish a benchmark that better aligns with\nhuman preferences, this paper introduces Video-Bench, a comprehensive benchmark\nfeaturing a rich prompt suite and extensive evaluation dimensions. This\nbenchmark represents the first attempt to systematically leverage MLLMs across\nall dimensions relevant to video generation assessment in generative models. By\nincorporating few-shot scoring and chain-of-query techniques, Video-Bench\nprovides a structured, scalable approach to generated video evaluation.\nExperiments on advanced models including Sora demonstrate that Video-Bench\nachieves superior alignment with human preferences across all dimensions.\nMoreover, in instances where our framework's assessments diverge from human\nevaluations, it consistently offers more objective and accurate insights,\nsuggesting an even greater potential advantage over traditional human judgment.", "published": "2025-04-07 10:32:42", "link": "http://arxiv.org/abs/2504.04907v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Lumina-OmniLV: A Unified Multimodal Framework for General Low-Level Vision", "abstract": "We present Lunima-OmniLV (abbreviated as OmniLV), a universal multimodal\nmulti-task framework for low-level vision that addresses over 100 sub-tasks\nacross four major categories: image restoration, image enhancement,\nweak-semantic dense prediction, and stylization. OmniLV leverages both textual\nand visual prompts to offer flexible and user-friendly interactions. Built on\nDiffusion Transformer (DiT)-based generative priors, our framework supports\narbitrary resolutions -- achieving optimal performance at 1K resolution --\nwhile preserving fine-grained details and high fidelity. Through extensive\nexperiments, we demonstrate that separately encoding text and visual\ninstructions, combined with co-training using shallow feature control, is\nessential to mitigate task ambiguity and enhance multi-task generalization. Our\nfindings also reveal that integrating high-level generative tasks into\nlow-level vision models can compromise detail-sensitive restoration. These\ninsights pave the way for more robust and generalizable low-level vision\nsystems.", "published": "2025-04-07 10:22:00", "link": "http://arxiv.org/abs/2504.04903v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models", "abstract": "Typographic attacks exploit the interplay between text and visual content in\nmultimodal foundation models, causing misclassifications when misleading text\nis embedded within images. However, existing datasets are limited in size and\ndiversity, making it difficult to study such vulnerabilities. In this paper, we\nintroduce SCAM, the largest and most diverse dataset of real-world typographic\nattack images to date, containing 1,162 images across hundreds of object\ncategories and attack words. Through extensive benchmarking of Vision-Language\nModels (VLMs) on SCAM, we demonstrate that typographic attacks significantly\ndegrade performance, and identify that training data and model architecture\ninfluence the susceptibility to these attacks. Our findings reveal that\ntypographic attacks persist in state-of-the-art Large Vision-Language Models\n(LVLMs) due to the choice of their vision encoder, though larger Large Language\nModels (LLMs) backbones help mitigate their vulnerability. Additionally, we\ndemonstrate that synthetic attacks closely resemble real-world (handwritten)\nattacks, validating their use in research. Our work provides a comprehensive\nresource and empirical insights to facilitate future research toward robust and\ntrustworthy multimodal AI systems. We publicly release the datasets introduced\nin this paper under https://huggingface.co/datasets/BLISS-e-V/SCAM, along with\nthe code for evaluations at https://github.com/Bliss-e-V/SCAM.", "published": "2025-04-07 10:01:38", "link": "http://arxiv.org/abs/2504.04893v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Futureproof Static Memory Planning", "abstract": "The NP-complete combinatorial optimization task of assigning offsets to a set\nof buffers with known sizes and lifetimes so as to minimize total memory usage\nis called dynamic storage allocation (DSA). Existing DSA implementations bypass\nthe theoretical state-of-the-art algorithms in favor of either fast but\nwasteful heuristics, or memory-efficient approaches that do not scale beyond\none thousand buffers. The \"AI memory wall\", combined with deep neural networks'\nstatic architecture, has reignited interest in DSA. We present idealloc, a\nlow-fragmentation, high-performance DSA implementation designed for\nmillion-buffer instances. Evaluated on a novel suite of particularly hard\nbenchmarks from several domains, idealloc ranks first against four production\nimplementations in terms of a joint effectiveness/robustness criterion.", "published": "2025-04-07 09:28:54", "link": "http://arxiv.org/abs/2504.04874v1", "categories": ["cs.OS", "cs.AI", "cs.PL"], "primary_category": "cs.OS"}
{"title": "FedSAUC: A Similarity-Aware Update Control for Communication-Efficient Federated Learning in Edge Computing", "abstract": "Federated learning is a distributed machine learning framework to\ncollaboratively train a global model without uploading privacy-sensitive data\nonto a centralized server. Usually, this framework is applied to edge devices\nsuch as smartphones, wearable devices, and Internet of Things (IoT) devices\nwhich closely collect information from users. However, these devices are mostly\nbattery-powered. The update procedure of federated learning will constantly\nconsume the battery power and the transmission bandwidth. In this work, we\npropose an update control for federated learning, FedSAUC, by considering the\nsimilarity of users' behaviors (models). At the server side, we exploit\nclustering algorithms to group devices with similar models. Then we select some\nrepresentatives for each cluster to update information to train the model. We\nalso implemented a testbed prototyping on edge devices for validating the\nperformance. The experimental results show that this update control will not\naffect the training accuracy in the long run.", "published": "2025-04-07 09:21:43", "link": "http://arxiv.org/abs/2504.04867v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "GAMDTP: Dynamic Trajectory Prediction with Graph Attention Mamba Network", "abstract": "Accurate motion prediction of traffic agents is crucial for the safety and\nstability of autonomous driving systems. In this paper, we introduce GAMDTP, a\nnovel graph attention-based network tailored for dynamic trajectory prediction.\nSpecifically, we fuse the result of self attention and mamba-ssm through a gate\nmechanism, leveraging the strengths of both to extract features more\nefficiently and accurately, in each graph convolution layer. GAMDTP encodes the\nhigh-definition map(HD map) data and the agents' historical trajectory\ncoordinates and decodes the network's output to generate the final prediction\nresults. Additionally, recent approaches predominantly focus on dynamically\nfusing historical forecast results and rely on two-stage frameworks including\nproposal and refinement. To further enhance the performance of the two-stage\nframeworks we also design a scoring mechanism to evaluate the prediction\nquality during the proposal and refinement processes. Experiments on the\nArgoverse dataset demonstrates that GAMDTP achieves state-of-the-art\nperformance, achieving superior accuracy in dynamic trajectory prediction.", "published": "2025-04-07 09:19:20", "link": "http://arxiv.org/abs/2504.04862v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Don't Lag, RAG: Training-Free Adversarial Detection Using RAG", "abstract": "Adversarial patch attacks pose a major threat to vision systems by embedding\nlocalized perturbations that mislead deep models. Traditional defense methods\noften require retraining or fine-tuning, making them impractical for real-world\ndeployment. We propose a training-free Visual Retrieval-Augmented Generation\n(VRAG) framework that integrates Vision-Language Models (VLMs) for adversarial\npatch detection. By retrieving visually similar patches and images that\nresemble stored attacks in a continuously expanding database, VRAG performs\ngenerative reasoning to identify diverse attack types, all without additional\ntraining or fine-tuning. We extensively evaluate open-source large-scale VLMs,\nincluding Qwen-VL-Plus, Qwen2.5-VL-72B, and UI-TARS-72B-DPO, alongside\nGemini-2.0, a closed-source model. Notably, the open-source UI-TARS-72B-DPO\nmodel achieves up to 95 percent classification accuracy, setting a new\nstate-of-the-art for open-source adversarial patch detection. Gemini-2.0\nattains the highest overall accuracy, 98 percent, but remains closed-source.\nExperimental results demonstrate VRAG's effectiveness in identifying a variety\nof adversarial patches with minimal human annotation, paving the way for\nrobust, practical defenses against evolving adversarial patch attacks.", "published": "2025-04-07 09:14:47", "link": "http://arxiv.org/abs/2504.04858v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents", "abstract": "Detecting biases in structured data is a complex and time-consuming task.\nExisting automated techniques are limited in diversity of data types and\nheavily reliant on human case-by-case handling, resulting in a lack of\ngeneralizability. Currently, large language model (LLM)-based agents have made\nsignificant progress in data science, but their ability to detect data biases\nis still insufficiently explored. To address this gap, we introduce the first\nend-to-end, multi-agent synergy framework, BIASINSPECTOR, designed for\nautomatic bias detection in structured data based on specific user\nrequirements. It first develops a multi-stage plan to analyze user-specified\nbias detection tasks and then implements it with a diverse and well-suited set\nof tools. It delivers detailed results that include explanations and\nvisualizations. To address the lack of a standardized framework for evaluating\nthe capability of LLM agents to detect biases in data, we further propose a\ncomprehensive benchmark that includes multiple evaluation metrics and a large\nset of test cases. Extensive experiments demonstrate that our framework\nachieves exceptional overall performance in structured data bias detection,\nsetting a new milestone for fairer data applications.", "published": "2025-04-07 09:12:00", "link": "http://arxiv.org/abs/2504.04855v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "An Efficient Approach for Cooperative Multi-Agent Learning Problems", "abstract": "In this article, we propose a centralized Multi-Agent Learning framework for\nlearning a policy that models the simultaneous behavior of multiple agents that\nneed to coordinate to solve a certain task. Centralized approaches often suffer\nfrom the explosion of an action space that is defined by all possible\ncombinations of individual actions, known as joint actions. Our approach\naddresses the coordination problem via a sequential abstraction, which\novercomes the scalability problems typical to centralized methods. It\nintroduces a meta-agent, called \\textit{supervisor}, which abstracts joint\nactions as sequential assignments of actions to each agent. This sequential\nabstraction not only simplifies the centralized joint action space but also\nenhances the framework's scalability and efficiency. Our experimental results\ndemonstrate that the proposed approach successfully coordinates agents across a\nvariety of Multi-Agent Learning environments of diverse sizes.", "published": "2025-04-07 09:03:35", "link": "http://arxiv.org/abs/2504.04850v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Explanation-Driven Interventions for Artificial Intelligence Model Customization: Empowering End-Users to Tailor Black-Box AI in Rhinocytology", "abstract": "The integration of Artificial Intelligence (AI) in modern society is heavily\nshifting the way that individuals carry out their tasks and activities.\nEmploying AI-based systems raises challenges that designers and developers must\naddress to ensure that humans remain in control of the interaction process,\nparticularly in high-risk domains. This article presents a novel End-User\nDevelopment (EUD) approach for black-box AI models through a redesigned user\ninterface in the Rhino-Cyt platform, a medical AI-based decision-support system\nfor medical professionals (more precisely, rhinocytologists) to carry out cell\nclassification. The proposed interface empowers users to intervene in AI\ndecision-making process by editing explanations and reconfiguring the model,\ninfluencing its future predictions. This work contributes to Human-Centered AI\n(HCAI) and EUD by discussing how explanation-driven interventions allow a blend\nof explainability, user intervention, and model reconfiguration, fostering a\nsymbiosis between humans and user-tailored AI systems.", "published": "2025-04-07 08:44:48", "link": "http://arxiv.org/abs/2504.04833v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "From Specificity to Generality: Revisiting Generalizable Artifacts in Detecting Face Deepfakes", "abstract": "Detecting deepfakes has been an increasingly important topic, especially\ngiven the rapid development of AI generation techniques. In this paper, we ask:\nHow can we build a universal detection framework that is effective for most\nfacial deepfakes? One significant challenge is the wide variety of deepfake\ngenerators available, resulting in varying forgery artifacts (e.g., lighting\ninconsistency, color mismatch, etc). But should we ``teach\" the detector to\nlearn all these artifacts separately? It is impossible and impractical to\nelaborate on them all. So the core idea is to pinpoint the more common and\ngeneral artifacts across different deepfakes. Accordingly, we categorize\ndeepfake artifacts into two distinct yet complementary types: Face\nInconsistency Artifacts (FIA) and Up-Sampling Artifacts (USA). FIA arise from\nthe challenge of generating all intricate details, inevitably causing\ninconsistencies between the complex facial features and relatively uniform\nsurrounding areas. USA, on the other hand, are the inevitable traces left by\nthe generator's decoder during the up-sampling process. This categorization\nstems from the observation that all existing deepfakes typically exhibit one or\nboth of these artifacts. To achieve this, we propose a new data-level\npseudo-fake creation framework that constructs fake samples with only the FIA\nand USA, without introducing extra less-general artifacts. Specifically, we\nemploy a super-resolution to simulate the USA, while design a Blender module\nthat uses image-level self-blending on diverse facial regions to create the\nFIA. We surprisingly found that, with this intuitive design, a standard image\nclassifier trained only with our pseudo-fake data can non-trivially generalize\nwell to unseen deepfakes.", "published": "2025-04-07 08:34:28", "link": "http://arxiv.org/abs/2504.04827v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Customized SAT-based Solver for Graph Coloring", "abstract": "We introduce ZykovColor, a novel SAT-based algorithm to solve the graph\ncoloring problem working on top of an encoding that mimics the Zykov tree. Our\nmethod is based on an approach of H\\'ebrard and Katsirelos (2020) that employs\na propagator to enforce transitivity constraints, incorporate lower bounds for\nsearch tree pruning, and enable inferred propagations. We leverage the recently\nintroduced IPASIR-UP interface for CaDiCal to implement these techniques with a\nSAT solver. Furthermore, we propose new features that take advantage of the\nunderlying SAT solver. These include modifying the integrated decision strategy\nwith vertex domination hints and using incremental bottom-up search that allows\nto reuse learned clauses from previous calls. Additionally, we integrate a more\nefficient clique computation to improve the lower bounds during the search. We\nvalidate the effectiveness of each new feature through an experimental\nanalysis. ZykovColor outperforms other state-of-the-art graph coloring\nimplementations on the DIMACS benchmark set. Further experiments on random\nErd\\H{o}s-R\\'enyi graphs show that our new approach dominates state-of-the-art\nSAT-based methods for both very sparse and highly dense graphs.", "published": "2025-04-07 08:22:00", "link": "http://arxiv.org/abs/2504.04821v1", "categories": ["cs.DM", "cs.AI", "cs.DS", "cs.LO", "05C15", "G.2.2"], "primary_category": "cs.DM"}
{"title": "ELT-Bench: An End-to-End Benchmark for Evaluating AI Agents on ELT Pipelines", "abstract": "Practitioners are increasingly turning to Extract-Load-Transform (ELT)\npipelines with the widespread adoption of cloud data warehouses. However,\ndesigning these pipelines often involves significant manual work to ensure\ncorrectness. Recent advances in AI-based methods, which have shown strong\ncapabilities in data tasks, such as text-to-SQL, present an opportunity to\nalleviate manual efforts in developing ELT pipelines. Unfortunately, current\nbenchmarks in data engineering only evaluate isolated tasks, such as using data\ntools and writing data transformation queries, leaving a significant gap in\nevaluating AI agents for generating end-to-end ELT pipelines.\n  To fill this gap, we introduce ELT-Bench, an end-to-end benchmark designed to\nassess the capabilities of AI agents to build ELT pipelines. ELT-Bench consists\nof 100 pipelines, including 835 source tables and 203 data models across\nvarious domains. By simulating realistic scenarios involving the integration of\ndiverse data sources and the use of popular data tools, ELT-Bench evaluates AI\nagents' abilities in handling complex data engineering workflows. AI agents\nmust interact with databases and data tools, write code and SQL queries, and\norchestrate every pipeline stage. We evaluate two representative code agent\nframeworks, Spider-Agent and SWE-Agent, using six popular Large Language Models\n(LLMs) on ELT-Bench. The highest-performing agent, Spider-Agent\nClaude-3.7-Sonnet with extended thinking, correctly generates only 3.9% of data\nmodels, with an average cost of $4.30 and 89.3 steps per pipeline. Our\nexperimental results demonstrate the challenges of ELT-Bench and highlight the\nneed for a more advanced AI agent to reduce manual effort in ELT workflows. Our\ncode and data are available at https://github.com/uiuc-kang-lab/ETL.git.", "published": "2025-04-07 08:03:36", "link": "http://arxiv.org/abs/2504.04808v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "Multimodal Agricultural Agent Architecture (MA3): A New Paradigm for Intelligent Agricultural Decision-Making", "abstract": "As a strategic pillar industry for human survival and development, modern\nagriculture faces dual challenges: optimizing production efficiency and\nachieving sustainable development. Against the backdrop of intensified climate\nchange leading to frequent extreme weather events, the uncertainty risks in\nagricultural production systems are increasing exponentially. To address these\nchallenges, this study proposes an innovative \\textbf{M}ultimodal\n\\textbf{A}gricultural \\textbf{A}gent \\textbf{A}rchitecture (\\textbf{MA3}),\nwhich leverages cross-modal information fusion and task collaboration\nmechanisms to achieve intelligent agricultural decision-making. This study\nconstructs a multimodal agricultural agent dataset encompassing five major\ntasks: classification, detection, Visual Question Answering (VQA), tool\nselection, and agent evaluation. We propose a unified backbone for sugarcane\ndisease classification and detection tools, as well as a sugarcane disease\nexpert model. By integrating an innovative tool selection module, we develop a\nmultimodal agricultural agent capable of effectively performing tasks in\nclassification, detection, and VQA. Furthermore, we introduce a\nmulti-dimensional quantitative evaluation framework and conduct a comprehensive\nassessment of the entire architecture over our evaluation dataset, thereby\nverifying the practicality and robustness of MA3 in agricultural scenarios.\nThis study provides new insights and methodologies for the development of\nagricultural agents, holding significant theoretical and practical\nimplications. Our source code and dataset will be made publicly available upon\nacceptance.", "published": "2025-04-07 07:32:41", "link": "http://arxiv.org/abs/2504.04789v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Dynamic Vision Mamba", "abstract": "Mamba-based vision models have gained extensive attention as a result of\nbeing computationally more efficient than attention-based models. However,\nspatial redundancy still exists in these models, represented by token and block\nredundancy. For token redundancy, we analytically find that early token pruning\nmethods will result in inconsistency between training and inference or\nintroduce extra computation for inference. Therefore, we customize token\npruning to fit the Mamba structure by rearranging the pruned sequence before\nfeeding it into the next Mamba block. For block redundancy, we allow each image\nto select SSM blocks dynamically based on an empirical observation that the\ninference speed of Mamba-based vision models is largely affected by the number\nof SSM blocks. Our proposed method, Dynamic Vision Mamba (DyVM), effectively\nreduces FLOPs with minor performance drops. We achieve a reduction of 35.2\\%\nFLOPs with only a loss of accuracy of 1.7\\% on Vim-S. It also generalizes well\nacross different Mamba vision model architectures and different vision tasks.\nOur code will be made public.", "published": "2025-04-07 07:31:28", "link": "http://arxiv.org/abs/2504.04787v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Weak-for-Strong: Training Weak Meta-Agent to Harness Strong Executors", "abstract": "Efficiently leveraging of the capabilities of contemporary large language\nmodels (LLMs) is increasingly challenging, particularly when direct fine-tuning\nis expensive and often impractical. Existing training-free methods, including\nmanually or automated designed workflows, typically demand substantial human\neffort or yield suboptimal results. This paper proposes Weak-for-Strong\nHarnessing (W4S), a novel framework that customizes smaller, cost-efficient\nlanguage models to design and optimize workflows for harnessing stronger\nmodels. W4S formulates workflow design as a multi-turn markov decision process\nand introduces reinforcement learning for agentic workflow optimization (RLAO)\nto train a weak meta-agent. Through iterative interaction with the environment,\nthe meta-agent learns to design increasingly effective workflows without manual\nintervention. Empirical results demonstrate the superiority of W4S that our 7B\nmeta-agent, trained with just one GPU hour, outperforms the strongest baseline\nby 2.9% ~ 24.6% across eleven benchmarks, successfully elevating the\nperformance of state-of-the-art models such as GPT-3.5-Turbo and GPT-4o.\nNotably, W4S exhibits strong generalization capabilities across both seen and\nunseen tasks, offering an efficient, high-performing alternative to directly\nfine-tuning strong models.", "published": "2025-04-07 07:27:31", "link": "http://arxiv.org/abs/2504.04785v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Bidirectional Hierarchical Protein Multi-Modal Representation Learning", "abstract": "Protein representation learning is critical for numerous biological tasks.\nRecently, large transformer-based protein language models (pLMs) pretrained on\nlarge scale protein sequences have demonstrated significant success in\nsequence-based tasks. However, pLMs lack structural information. Conversely,\ngraph neural networks (GNNs) designed to leverage 3D structural information\nhave shown promising generalization in protein-related prediction tasks, but\ntheir effectiveness is often constrained by the scarcity of labeled structural\ndata. Recognizing that sequence and structural representations are\ncomplementary perspectives of the same protein entity, we propose a multimodal\nbidirectional hierarchical fusion framework to effectively merge these\nmodalities. Our framework employs attention and gating mechanisms to enable\neffective interaction between pLMs-generated sequential representations and\nGNN-extracted structural features, improving information exchange and\nenhancement across layers of the neural network. Based on the framework, we\nfurther introduce local Bi-Hierarchical Fusion with gating and global\nBi-Hierarchical Fusion with multihead self-attention approaches. Through\nextensive experiments on a diverse set of protein-related tasks, our method\ndemonstrates consistent improvements over strong baselines and existing fusion\ntechniques in a variety of protein representation learning benchmarks,\nincluding react (enzyme/EC classification), model quality assessment (MQA),\nprotein-ligand binding affinity prediction (LBA), protein-protein binding site\nprediction (PPBS), and B cell epitopes prediction (BCEs). Our method\nestablishes a new state-of-the-art for multimodal protein representation\nlearning, emphasizing the efficacy of BIHIERARCHICAL FUSION in bridging\nsequence and structural modalities.", "published": "2025-04-07 06:47:49", "link": "http://arxiv.org/abs/2504.04770v1", "categories": ["cs.LG", "cs.AI", "q-bio.MN"], "primary_category": "cs.LG"}
{"title": "KunPeng: A Global Ocean Environmental Model", "abstract": "Inspired by the similarity of the atmosphere-ocean physical coupling\nmechanism, this study innovatively migrates meteorological large-model\ntechniques to the ocean domain, constructing the KunPeng global ocean\nenvironmental prediction model. Aimed at the discontinuous characteristics of\nmarine space, we propose a terrain-adaptive mask constraint mechanism to\nmitigate effectively training divergence caused by abrupt gradients at land-sea\nboundaries. To fully integrate far-, medium-, and close-range marine features,\na longitude-cyclic deformable convolution network (LC-DCN) is employed to\nenhance the dynamic receptive field, achieving refined modeling of multi-scale\noceanic characteristics. A Deformable Convolution-enhanced Multi-Step\nPrediction module (DC-MTP) is employed to strengthen temporal dependency\nfeature extraction capabilities. Experimental results demonstrate that this\nmodel achieves an average ACC of 0.80 in 15-day global predictions at\n0.25$^\\circ$ resolution, outperforming comparative models by 0.01-0.08. The\naverage mean squared error (MSE) is 0.41 (representing a 5%-31% reduction) and\nthe average mean absolute error (MAE) is 0.44 (0.6%-21% reduction) compared to\nother models. Significant improvements are particularly observed in sea surface\nparameter prediction, deep-sea region characterization, and current velocity\nfield forecasting. Through a horizontal comparison of the applicability of\noperators at different scales in the marine domain, this study reveals that\nlocal operators significantly outperform global operators under slow-varying\noceanic processes, demonstrating the effectiveness of dynamic feature pyramid\nrepresentations in predicting marine physical parameters.", "published": "2025-04-07 06:41:05", "link": "http://arxiv.org/abs/2504.04766v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Enhancing Leaf Disease Classification Using GAT-GCN Hybrid Model", "abstract": "Agriculture plays a critical role in the global economy, providing\nlivelihoods and ensuring food security for billions. As innovative agricultural\npractices become more widespread, the risk of crop diseases has increased,\nhighlighting the urgent need for efficient, low-intervention disease\nidentification methods. This research presents a hybrid model combining Graph\nAttention Networks (GATs) and Graph Convolution Networks (GCNs) for leaf\ndisease classification. GCNs have been widely used for learning from\ngraph-structured data, and GATs enhance this by incorporating attention\nmechanisms to focus on the most important neighbors. The methodology integrates\nsuperpixel segmentation for efficient feature extraction, partitioning images\ninto meaningful, homogeneous regions that better capture localized features.\nThe authors have employed an edge augmentation technique to enhance the\nrobustness of the model. The edge augmentation technique has introduced a\nsignificant degree of generalization in the detection capabilities of the\nmodel. To further optimize training, weight initialization techniques are\napplied. The hybrid model is evaluated against the individual performance of\nthe GCN and GAT models and the hybrid model achieved a precision of 0.9822,\nrecall of 0.9818, and F1-score of 0.9818 in apple leaf disease classification,\na precision of 0.9746, recall of 0.9744, and F1-score of 0.9743 in potato leaf\ndisease classification, and a precision of 0.8801, recall of 0.8801, and\nF1-score of 0.8799 in sugarcane leaf disease classification. These results\ndemonstrate the robustness and performance of the model, suggesting its\npotential to support sustainable agricultural practices through precise and\neffective disease detection. This work is a small step towards reducing the\nloss of crops and hence supporting sustainable goals of zero hunger and life on\nland.", "published": "2025-04-07 06:31:38", "link": "http://arxiv.org/abs/2504.04764v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Unsupervised Estimation of Nonlinear Audio Effects: Comparing Diffusion-Based and Adversarial approaches", "abstract": "Accurately estimating nonlinear audio effects without access to paired\ninput-output signals remains a challenging problem.This work studies\nunsupervised probabilistic approaches for solving this task. We introduce a\nmethod, novel for this application, based on diffusion generative models for\nblind system identification, enabling the estimation of unknown nonlinear\neffects using black- and gray-box models. This study compares this method with\na previously proposed adversarial approach, analyzing the performance of both\nmethods under different parameterizations of the effect operator and varying\nlengths of available effected recordings.Through experiments on guitar\ndistortion effects, we show that the diffusion-based approach provides more\nstable results and is less sensitive to data availability, while the\nadversarial approach is superior at estimating more pronounced distortion\neffects. Our findings contribute to the robust unsupervised blind estimation of\naudio effects, demonstrating the potential of diffusion models for system\nidentification in music technology.", "published": "2025-04-07 05:56:51", "link": "http://arxiv.org/abs/2504.04751v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Grounding 3D Object Affordance with Language Instructions, Visual Observations and Interactions", "abstract": "Grounding 3D object affordance is a task that locates objects in 3D space\nwhere they can be manipulated, which links perception and action for embodied\nintelligence. For example, for an intelligent robot, it is necessary to\naccurately ground the affordance of an object and grasp it according to human\ninstructions. In this paper, we introduce a novel task that grounds 3D object\naffordance based on language instructions, visual observations and\ninteractions, which is inspired by cognitive science. We collect an Affordance\nGrounding dataset with Points, Images and Language instructions (AGPIL) to\nsupport the proposed task. In the 3D physical world, due to observation\norientation, object rotation, or spatial occlusion, we can only get a partial\nobservation of the object. So this dataset includes affordance estimations of\nobjects from full-view, partial-view, and rotation-view perspectives. To\naccomplish this task, we propose LMAffordance3D, the first multi-modal,\nlanguage-guided 3D affordance grounding network, which applies a\nvision-language model to fuse 2D and 3D spatial features with semantic\nfeatures. Comprehensive experiments on AGPIL demonstrate the effectiveness and\nsuperiority of our method on this task, even in unseen experimental settings.\nOur project is available at https://sites.google.com/view/lmaffordance3d.", "published": "2025-04-07 05:38:23", "link": "http://arxiv.org/abs/2504.04744v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Enhancing Compositional Reasoning in Vision-Language Models with Synthetic Preference Data", "abstract": "Compositionality, or correctly recognizing scenes as compositions of atomic\nvisual concepts, remains difficult for multimodal large language models\n(MLLMs). Even state of the art MLLMs such as GPT-4o can make mistakes in\ndistinguishing compositions like \"dog chasing cat\" vs \"cat chasing dog\". While\non Winoground, a benchmark for measuring such reasoning, MLLMs have made\nsignificant progress, they are still far from a human's performance. We show\nthat compositional reasoning in these models can be improved by elucidating\nsuch concepts via data, where a model is trained to prefer the correct caption\nfor an image over a close but incorrect one. We introduce SCRAMBLe: Synthetic\nCompositional Reasoning Augmentation of MLLMs with Binary preference Learning,\nan approach for preference tuning open-weight MLLMs on synthetic preference\ndata generated in a fully automated manner from existing image-caption data.\nSCRAMBLe holistically improves these MLLMs' compositional reasoning\ncapabilities which we can see through significant improvements across multiple\nvision language compositionality benchmarks, as well as smaller but significant\nimprovements on general question answering tasks. As a sneak peek, SCRAMBLe\ntuned Molmo-7B model improves on Winoground from 49.5% to 54.8% (best reported\nto date), while improving by ~1% on more general visual question answering\ntasks. Code for SCRAMBLe along with tuned models and our synthetic training\ndataset is available at https://github.com/samarth4149/SCRAMBLe.", "published": "2025-04-07 05:35:34", "link": "http://arxiv.org/abs/2504.04740v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Generalising from Self-Produced Data: Model Training Beyond Human Constraints", "abstract": "Current large language models (LLMs) are constrained by human-derived\ntraining data and limited by a single level of abstraction that impedes\ndefinitive truth judgments. This paper introduces a novel framework in which AI\nmodels autonomously generate and validate new knowledge through direct\ninteraction with their environment. Central to this approach is an unbounded,\nungamable numeric reward - such as annexed disk space or follower count - that\nguides learning without requiring human benchmarks. AI agents iteratively\ngenerate strategies and executable code to maximize this metric, with\nsuccessful outcomes forming the basis for self-retraining and incremental\ngeneralisation. To mitigate model collapse and the warm start problem, the\nframework emphasizes empirical validation over textual similarity and supports\nfine-tuning via GRPO. The system architecture employs modular agents for\nenvironment analysis, strategy generation, and code synthesis, enabling\nscalable experimentation. This work outlines a pathway toward self-improving AI\nsystems capable of advancing beyond human-imposed constraints toward autonomous\ngeneral intelligence.", "published": "2025-04-07 03:48:02", "link": "http://arxiv.org/abs/2504.04711v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AdvKT: An Adversarial Multi-Step Training Framework for Knowledge Tracing", "abstract": "Knowledge Tracing (KT) monitors students' knowledge states and simulates\ntheir responses to question sequences. Existing KT models typically follow a\nsingle-step training paradigm, which leads to discrepancies with the multi-step\ninference process required in real-world simulations, resulting in significant\nerror accumulation. This accumulation of error, coupled with the issue of data\nsparsity, can substantially degrade the performance of recommendation models in\nthe intelligent tutoring systems. To address these challenges, we propose a\nnovel Adversarial Multi-Step Training Framework for Knowledge Tracing (AdvKT),\nwhich, for the first time, focuses on the multi-step KT task. More\nspecifically, AdvKT leverages adversarial learning paradigm involving a\ngenerator and a discriminator. The generator mimics high-reward responses,\neffectively reducing error accumulation across multiple steps, while the\ndiscriminator provides feedback to generate synthetic data. Additionally, we\ndesign specialized data augmentation techniques to enrich the training data\nwith realistic variations, ensuring that the model generalizes well even in\nscenarios with sparse data. Experiments conducted on four real-world datasets\ndemonstrate the superiority of AdvKT over existing KT models, showcasing its\nability to address both error accumulation and data sparsity issues\neffectively.", "published": "2025-04-07 03:31:57", "link": "http://arxiv.org/abs/2504.04706v1", "categories": ["cs.LG", "cs.AI", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Provable Failure of Language Models in Learning Majority Boolean Logic via Gradient Descent", "abstract": "Recent advancements in Transformer-based architectures have led to impressive\nbreakthroughs in natural language processing tasks, with models such as GPT-4,\nClaude, and Gemini demonstrating human-level reasoning abilities. However,\ndespite their high performance, concerns remain about the inherent limitations\nof these models, especially when it comes to learning basic logical functions.\nWhile complexity-theoretic analyses indicate that Transformers can represent\nsimple logic functions (e.g., $\\mathsf{AND}$, $\\mathsf{OR}$, and majority\ngates) by its nature of belonging to the $\\mathsf{TC}^0$ class, these results\nassume ideal parameter settings and do not account for the constraints imposed\nby gradient descent-based training methods. In this work, we investigate\nwhether Transformers can truly learn simple majority functions when trained\nusing gradient-based methods. We focus on a simplified variant of the\nTransformer architecture and consider both $n=\\mathrm{poly}(d)$ and\n$n=\\exp(\\Omega(d))$ number of training samples, where each sample is a $d$-size\nbinary string paired with the output of a basic majority function. Our analysis\ndemonstrates that even after $\\mathrm{poly}(d)$ gradient queries, the\ngeneralization error of the Transformer model still remains substantially\nlarge, growing exponentially with $d$. This work highlights fundamental\noptimization challenges in training Transformers for the simplest logical\nreasoning tasks and provides new insights into their theoretical limitations.", "published": "2025-04-07 03:08:12", "link": "http://arxiv.org/abs/2504.04702v1", "categories": ["cs.LG", "cs.AI", "cs.CC"], "primary_category": "cs.LG"}
{"title": "Bridging Knowledge Gap Between Image Inpainting and Large-Area Visible Watermark Removal", "abstract": "Visible watermark removal which involves watermark cleaning and background\ncontent restoration is pivotal to evaluate the resilience of watermarks.\nExisting deep neural network (DNN)-based models still struggle with large-area\nwatermarks and are overly dependent on the quality of watermark mask\nprediction. To overcome these challenges, we introduce a novel feature adapting\nframework that leverages the representation modeling capacity of a pre-trained\nimage inpainting model. Our approach bridges the knowledge gap between image\ninpainting and watermark removal by fusing information of the residual\nbackground content beneath watermarks into the inpainting backbone model. We\nestablish a dual-branch system to capture and embed features from the residual\nbackground content, which are merged into intermediate features of the\ninpainting backbone model via gated feature fusion modules. Moreover, for\nrelieving the dependence on high-quality watermark masks, we introduce a new\ntraining paradigm by utilizing coarse watermark masks to guide the inference\nprocess. This contributes to a visible image removal model which is insensitive\nto the quality of watermark mask during testing. Extensive experiments on both\na large-scale synthesized dataset and a real-world dataset demonstrate that our\napproach significantly outperforms existing state-of-the-art methods. The\nsource code is available in the supplementary materials.", "published": "2025-04-07 02:37:14", "link": "http://arxiv.org/abs/2504.04687v1", "categories": ["cs.CV", "cs.AI", "cs.MM", "eess.IV", "I.2.10; I.4.4; I.4.5"], "primary_category": "cs.CV"}
{"title": "Dual Consistent Constraint via Disentangled Consistency and Complementarity for Multi-view Clustering", "abstract": "Multi-view clustering can explore common semantics from multiple views and\nhas received increasing attention in recent years. However, current methods\nfocus on learning consistency in representation, neglecting the contribution of\neach view's complementarity aspect in representation learning. This limit poses\na significant challenge in multi-view representation learning. This paper\nproposes a novel multi-view clustering framework that introduces a disentangled\nvariational autoencoder that separates multi-view into shared and private\ninformation, i.e., consistency and complementarity information. We first learn\ninformative and consistent representations by maximizing mutual information\nacross different views through contrastive learning. This process will ignore\ncomplementary information. Then, we employ consistency inference constraints to\nexplicitly utilize complementary information when attempting to seek the\nconsistency of shared information across all views. Specifically, we perform a\nwithin-reconstruction using the private and shared information of each view and\na cross-reconstruction using the shared information of all views. The dual\nconsistency constraints are not only effective in improving the representation\nquality of data but also easy to extend to other scenarios, especially in\ncomplex multi-view scenes. This could be the first attempt to employ dual\nconsistent constraint in a unified MVC theoretical framework. During the\ntraining procedure, the consistency and complementarity features are jointly\noptimized. Extensive experiments show that our method outperforms baseline\nmethods.", "published": "2025-04-07 02:00:16", "link": "http://arxiv.org/abs/2504.04676v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "HypRL: Reinforcement Learning of Control Policies for Hyperproperties", "abstract": "We study the problem of learning control policies for complex tasks whose\nrequirements are given by a hyperproperty. The use of hyperproperties is\nmotivated by their significant power to formally specify requirements of\nmulti-agent systems as well as those that need expressiveness in terms of\nmultiple execution traces (e.g., privacy and fairness). Given a Markov decision\nprocess M with unknown transitions (representing the environment) and a\nHyperLTL formula $\\varphi$, our approach first employs Skolemization to handle\nquantifier alternations in $\\varphi$. We introduce quantitative robustness\nfunctions for HyperLTL to define rewards of finite traces of M with respect to\n$\\varphi$. Finally, we utilize a suitable reinforcement learning algorithm to\nlearn (1) a policy per trace quantifier in $\\varphi$, and (2) the probability\ndistribution of transitions of M that together maximize the expected reward\nand, hence, probability of satisfaction of $\\varphi$ in M. We present a set of\ncase studies on (1) safety-preserving multi-agent path planning, (2) fairness\nin resource allocation, and (3) the post-correspondence problem (PCP).", "published": "2025-04-07 01:58:36", "link": "http://arxiv.org/abs/2504.04675v1", "categories": ["cs.AI", "cs.LO"], "primary_category": "cs.AI"}
{"title": "EquiCPI: SE(3)-Equivariant Geometric Deep Learning for Structure-Aware Prediction of Compound-Protein Interactions", "abstract": "Accurate prediction of compound-protein interactions (CPI) remains a\ncornerstone challenge in computational drug discovery. While existing\nsequence-based approaches leverage molecular fingerprints or graph\nrepresentations, they critically overlook three-dimensional (3D) structural\ndeterminants of binding affinity. To bridge this gap, we present EquiCPI, an\nend-to-end geometric deep learning framework that synergizes first-principles\nstructural modeling with SE(3)-equivariant neural networks. Our pipeline\ntransforms raw sequences into 3D atomic coordinates via ESMFold for proteins\nand DiffDock-L for ligands, followed by physics-guided conformer re-ranking and\nequivariant feature learning. At its core, EquiCPI employs SE(3)-equivariant\nmessage passing over atomic point clouds, preserving symmetry under rotations,\ntranslations, and reflections, while hierarchically encoding local interaction\npatterns through tensor products of spherical harmonics. The proposed model is\nevaluated on BindingDB (affinity prediction) and DUD-E (virtual screening),\nEquiCPI achieves performance on par with or exceeding the state-of-the-art deep\nlearning competitors.", "published": "2025-04-07 00:57:08", "link": "http://arxiv.org/abs/2504.04654v1", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "CREA: A Collaborative Multi-Agent Framework for Creative Content Generation with Diffusion Models", "abstract": "Creativity in AI imagery remains a fundamental challenge, requiring not only\nthe generation of visually compelling content but also the capacity to add\nnovel, expressive, and artistically rich transformations to images. Unlike\nconventional editing tasks that rely on direct prompt-based modifications,\ncreative image editing demands an autonomous, iterative approach that balances\noriginality, coherence, and artistic intent. To address this, we introduce\nCREA, a novel multi-agent collaborative framework that mimics the human\ncreative process. Our framework leverages a team of specialized AI agents who\ndynamically collaborate to conceptualize, generate, critique, and enhance\nimages. Through extensive qualitative and quantitative evaluations, we\ndemonstrate that CREA significantly outperforms state-of-the-art methods in\ndiversity, semantic alignment, and creative transformation. By structuring\ncreativity as a dynamic, agentic process, CREA redefines the intersection of AI\nand art, paving the way for autonomous AI-driven artistic exploration,\ngenerative design, and human-AI co-creation. To the best of our knowledge, this\nis the first work to introduce the task of creative editing.", "published": "2025-04-07 17:59:51", "link": "http://arxiv.org/abs/2504.05306v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Gaussian Mixture Flow Matching Models", "abstract": "Diffusion models approximate the denoising distribution as a Gaussian and\npredict its mean, whereas flow matching models reparameterize the Gaussian mean\nas flow velocity. However, they underperform in few-step sampling due to\ndiscretization error and tend to produce over-saturated colors under\nclassifier-free guidance (CFG). To address these limitations, we propose a\nnovel Gaussian mixture flow matching (GMFlow) model: instead of predicting the\nmean, GMFlow predicts dynamic Gaussian mixture (GM) parameters to capture a\nmulti-modal flow velocity distribution, which can be learned with a KL\ndivergence loss. We demonstrate that GMFlow generalizes previous diffusion and\nflow matching models where a single Gaussian is learned with an $L_2$ denoising\nloss. For inference, we derive GM-SDE/ODE solvers that leverage analytic\ndenoising distributions and velocity fields for precise few-step sampling.\nFurthermore, we introduce a novel probabilistic guidance scheme that mitigates\nthe over-saturation issues of CFG and improves image generation quality.\nExtensive experiments demonstrate that GMFlow consistently outperforms flow\nmatching baselines in generation quality, achieving a Precision of 0.942 with\nonly 6 sampling steps on ImageNet 256$\\times$256.", "published": "2025-04-07 17:59:42", "link": "http://arxiv.org/abs/2504.05304v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "InteractVLM: 3D Interaction Reasoning from 2D Foundational Models", "abstract": "We introduce InteractVLM, a novel method to estimate 3D contact points on\nhuman bodies and objects from single in-the-wild images, enabling accurate\nhuman-object joint reconstruction in 3D. This is challenging due to occlusions,\ndepth ambiguities, and widely varying object shapes. Existing methods rely on\n3D contact annotations collected via expensive motion-capture systems or\ntedious manual labeling, limiting scalability and generalization. To overcome\nthis, InteractVLM harnesses the broad visual knowledge of large Vision-Language\nModels (VLMs), fine-tuned with limited 3D contact data. However, directly\napplying these models is non-trivial, as they reason only in 2D, while\nhuman-object contact is inherently 3D. Thus we introduce a novel\nRender-Localize-Lift module that: (1) embeds 3D body and object surfaces in 2D\nspace via multi-view rendering, (2) trains a novel multi-view localization\nmodel (MV-Loc) to infer contacts in 2D, and (3) lifts these to 3D.\nAdditionally, we propose a new task called Semantic Human Contact estimation,\nwhere human contact predictions are conditioned explicitly on object semantics,\nenabling richer interaction modeling. InteractVLM outperforms existing work on\ncontact estimation and also facilitates 3D reconstruction from an in-the wild\nimage. Code and models are available at https://interactvlm.is.tue.mpg.de.", "published": "2025-04-07 17:59:33", "link": "http://arxiv.org/abs/2504.05303v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "S^4M: Boosting Semi-Supervised Instance Segmentation with SAM", "abstract": "Semi-supervised instance segmentation poses challenges due to limited labeled\ndata, causing difficulties in accurately localizing distinct object instances.\nCurrent teacher-student frameworks still suffer from performance constraints\ndue to unreliable pseudo-label quality stemming from limited labeled data.\nWhile the Segment Anything Model (SAM) offers robust segmentation capabilities\nat various granularities, directly applying SAM to this task introduces\nchallenges such as class-agnostic predictions and potential over-segmentation.\nTo address these complexities, we carefully integrate SAM into the\nsemi-supervised instance segmentation framework, developing a novel\ndistillation method that effectively captures the precise localization\ncapabilities of SAM without compromising semantic recognition. Furthermore, we\nincorporate pseudo-label refinement as well as a specialized data augmentation\nwith the refined pseudo-labels, resulting in superior performance. We establish\nstate-of-the-art performance, and provide comprehensive experiments and\nablation studies to validate the effectiveness of our proposed approach.", "published": "2025-04-07 17:59:10", "link": "http://arxiv.org/abs/2504.05301v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "One-Minute Video Generation with Test-Time Training", "abstract": "Transformers today still struggle to generate one-minute videos because\nself-attention layers are inefficient for long context. Alternatives such as\nMamba layers struggle with complex multi-scene stories because their hidden\nstates are less expressive. We experiment with Test-Time Training (TTT) layers,\nwhose hidden states themselves can be neural networks, therefore more\nexpressive. Adding TTT layers into a pre-trained Transformer enables it to\ngenerate one-minute videos from text storyboards. For proof of concept, we\ncurate a dataset based on Tom and Jerry cartoons. Compared to baselines such as\nMamba~2, Gated DeltaNet, and sliding-window attention layers, TTT layers\ngenerate much more coherent videos that tell complex stories, leading by 34 Elo\npoints in a human evaluation of 100 videos per method. Although promising,\nresults still contain artifacts, likely due to the limited capability of the\npre-trained 5B model. The efficiency of our implementation can also be\nimproved. We have only experimented with one-minute videos due to resource\nconstraints, but the approach can be extended to longer videos and more complex\nstories. Sample videos, code and annotations are available at:\nhttps://test-time-training.github.io/video-dit", "published": "2025-04-07 17:56:31", "link": "http://arxiv.org/abs/2504.05298v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Let it Snow! Animating Static Gaussian Scenes With Dynamic Weather Effects", "abstract": "3D Gaussian Splatting has recently enabled fast and photorealistic\nreconstruction of static 3D scenes. However, introducing dynamic elements that\ninteract naturally with such static scenes remains challenging. Accordingly, we\npresent a novel hybrid framework that combines Gaussian-particle\nrepresentations for incorporating physically-based global weather effects into\nstatic 3D Gaussian Splatting scenes, correctly handling the interactions of\ndynamic elements with the static scene. We follow a three-stage process: we\nfirst map static 3D Gaussians to a particle-based representation. We then\nintroduce dynamic particles and simulate their motion using the Material Point\nMethod (MPM). Finally, we map the simulated particles back to the Gaussian\ndomain while introducing appearance parameters tailored for specific effects.\nTo correctly handle the interactions of dynamic elements with the static scene,\nwe introduce specialized collision handling techniques. Our approach supports a\nvariety of weather effects, including snowfall, rainfall, fog, and sandstorms,\nand can also support falling objects, all with physically plausible motion and\nappearance. Experiments demonstrate that our method significantly outperforms\nexisting approaches in both visual quality and physical realism.", "published": "2025-04-07 17:51:21", "link": "http://arxiv.org/abs/2504.05296v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "AnomalousNet: A Hybrid Approach with Attention U-Nets and Change Point Detection for Accurate Characterization of Anomalous Diffusion in Video Data", "abstract": "Anomalous diffusion occurs in a wide range of systems, including protein\ntransport within cells, animal movement in complex habitats, pollutant\ndispersion in groundwater, and nanoparticle motion in synthetic materials.\nAccurately estimating the anomalous diffusion exponent and the diffusion\ncoefficient from the particle trajectories is essential to distinguish between\nsub-diffusive, super-diffusive, or normal diffusion regimes. These estimates\nprovide a deeper insight into the underlying dynamics of the system,\nfacilitating the identification of particle behaviors and the detection of\nchanges in diffusion states. However, analyzing short and noisy video data,\nwhich often yield incomplete and heterogeneous trajectories, poses a\nsignificant challenge for traditional statistical approaches. We introduce a\ndata-driven method that integrates particle tracking, an attention\n  U-Net architecture, and a change-point detection algorithm to address these\nissues. This approach not only infers the anomalous diffusion parameters with\nhigh accuracy but also identifies temporal transitions between different\nstates, even in the presence of noise and limited temporal resolution. Our\nmethodology demonstrated strong performance in the 2nd Anomalous Diffusion\n(AnDi) Challenge benchmark within the top submissions for video tasks.", "published": "2025-04-07 17:08:17", "link": "http://arxiv.org/abs/2504.05271v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "From Sparse Signal to Smooth Motion: Real-Time Motion Generation with Rolling Prediction Models", "abstract": "In extended reality (XR), generating full-body motion of the users is\nimportant to understand their actions, drive their virtual avatars for social\ninteraction, and convey a realistic sense of presence. While prior works\nfocused on spatially sparse and always-on input signals from motion\ncontrollers, many XR applications opt for vision-based hand tracking for\nreduced user friction and better immersion. Compared to controllers, hand\ntracking signals are less accurate and can even be missing for an extended\nperiod of time. To handle such unreliable inputs, we present Rolling Prediction\nModel (RPM), an online and real-time approach that generates smooth full-body\nmotion from temporally and spatially sparse input signals. Our model generates\n1) accurate motion that matches the inputs (i.e., tracking mode) and 2)\nplausible motion when inputs are missing (i.e., synthesis mode). More\nimportantly, RPM generates seamless transitions from tracking to synthesis, and\nvice versa. To demonstrate the practical importance of handling noisy and\nmissing inputs, we present GORP, the first dataset of realistic sparse inputs\nfrom a commercial virtual reality (VR) headset with paired high quality body\nmotion ground truth. GORP provides >14 hours of VR gameplay data from 28 people\nusing motion controllers (spatially sparse) and hand tracking (spatially and\ntemporally sparse). We benchmark RPM against the state of the art on both\nsynthetic data and GORP to highlight how we can bridge the gap for real-world\napplications with a realistic dataset and by handling unreliable input signals.\nOur code, pretrained models, and GORP dataset are available in the project\nwebpage.", "published": "2025-04-07 17:00:34", "link": "http://arxiv.org/abs/2504.05265v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Contour Integration Underlies Human-Like Vision", "abstract": "Despite the tremendous success of deep learning in computer vision, models\nstill fall behind humans in generalizing to new input distributions. Existing\nbenchmarks do not investigate the specific failure points of models by\nanalyzing performance under many controlled conditions. Our study\nsystematically dissects where and why models struggle with contour integration\n-- a hallmark of human vision -- by designing an experiment that tests object\nrecognition under various levels of object fragmentation. Humans (n=50) perform\nat high accuracy, even with few object contours present. This is in contrast to\nmodels which exhibit substantially lower sensitivity to increasing object\ncontours, with most of the over 1,000 models we tested barely performing above\nchance. Only at very large scales ($\\sim5B$ training dataset size) do models\nbegin to approach human performance. Importantly, humans exhibit an integration\nbias -- a preference towards recognizing objects made up of directional\nfragments over directionless fragments. We find that not only do models that\nshare this property perform better at our task, but that this bias also\nincreases with model training dataset size, and training models to exhibit\ncontour integration leads to high shape bias. Taken together, our results\nsuggest that contour integration is a hallmark of object vision that underlies\nobject recognition performance, and may be a mechanism learned from data at\nscale.", "published": "2025-04-07 16:45:06", "link": "http://arxiv.org/abs/2504.05253v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Texture2LoD3: Enabling LoD3 Building Reconstruction With Panoramic Images", "abstract": "Despite recent advancements in surface reconstruction, Level of Detail (LoD)\n3 building reconstruction remains an unresolved challenge. The main issue\npertains to the object-oriented modelling paradigm, which requires\ngeoreferencing, watertight geometry, facade semantics, and low-poly\nrepresentation -- Contrasting unstructured mesh-oriented models. In\nTexture2LoD3, we introduce a novel method leveraging the ubiquity of 3D\nbuilding model priors and panoramic street-level images, enabling the\nreconstruction of LoD3 building models. We observe that prior low-detail\nbuilding models can serve as valid planar targets for ortho-rectifying\nstreet-level panoramic images. Moreover, deploying segmentation on accurately\ntextured low-level building surfaces supports maintaining essential\ngeoreferencing, watertight geometry, and low-poly representation for LoD3\nreconstruction. In the absence of LoD3 validation data, we additionally\nintroduce the ReLoD3 dataset, on which we experimentally demonstrate that our\nmethod leads to improved facade segmentation accuracy by 11% and can replace\ncostly manual projections. We believe that Texture2LoD3 can scale the adoption\nof LoD3 models, opening applications in estimating building solar potential or\nenhancing autonomous driving simulations. The project website, code, and data\nare available here: https://wenzhaotang.github.io/Texture2LoD3/.", "published": "2025-04-07 16:40:16", "link": "http://arxiv.org/abs/2504.05249v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Federated Learning for Medical Image Classification: A Comprehensive Benchmark", "abstract": "The federated learning paradigm is wellsuited for the field of medical image\nanalysis, as it can effectively cope with machine learning on isolated\nmulticenter data while protecting the privacy of participating parties.\nHowever, current research on optimization algorithms in federated learning\noften focuses on limited datasets and scenarios, primarily centered around\nnatural images, with insufficient comparative experiments in medical contexts.\nIn this work, we conduct a comprehensive evaluation of several state-of-the-art\nfederated learning algorithms in the context of medical imaging. We conduct a\nfair comparison of classification models trained using various federated\nlearning algorithms across multiple medical imaging datasets. Additionally, we\nevaluate system performance metrics, such as communication cost and\ncomputational efficiency, while considering different federated learning\narchitectures. Our findings show that medical imaging datasets pose substantial\nchallenges for current federated learning optimization algorithms. No single\nalgorithm consistently delivers optimal performance across all medical\nfederated learning scenarios, and many optimization algorithms may underperform\nwhen applied to these datasets. Our experiments provide a benchmark and\nguidance for future research and application of federated learning in medical\nimaging contexts. Furthermore, we propose an efficient and robust method that\ncombines generative techniques using denoising diffusion probabilistic models\nwith label smoothing to augment datasets, widely enhancing the performance of\nfederated learning on classification tasks across various medical imaging\ndatasets. Our code will be released on GitHub, offering a reliable and\ncomprehensive benchmark for future federated learning studies in medical\nimaging.", "published": "2025-04-07 16:22:18", "link": "http://arxiv.org/abs/2504.05238v1", "categories": ["cs.CV", "cs.DC"], "primary_category": "cs.CV"}
{"title": "A Reality Check of Vision-Language Pre-training in Radiology: Have We Progressed Using Text?", "abstract": "Vision-language pre-training has recently gained popularity as it allows\nlearning rich feature representations using large-scale data sources. This\nparadigm has quickly made its way into the medical image analysis community. In\nparticular, there is an impressive amount of recent literature developing\nvision-language models for radiology. However, the available medical datasets\nwith image-text supervision are scarce, and medical concepts are fine-grained,\ninvolving expert knowledge that existing vision-language models struggle to\nencode. In this paper, we propose to take a prudent step back from the\nliterature and revisit supervised, unimodal pre-training, using fine-grained\nlabels instead. We conduct an extensive comparison demonstrating that unimodal\npre-training is highly competitive and better suited to integrating\nheterogeneous data sources. Our results also question the potential of recent\nvision-language models for open-vocabulary generalization, which have been\nevaluated using optimistic experimental settings. Finally, we study novel\nalternatives to better integrate fine-grained labels and noisy text\nsupervision.", "published": "2025-04-07 16:13:26", "link": "http://arxiv.org/abs/2504.05227v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Reinforced Multi-teacher Knowledge Distillation for Efficient General Image Forgery Detection and Localization", "abstract": "Image forgery detection and localization (IFDL) is of vital importance as\nforged images can spread misinformation that poses potential threats to our\ndaily lives. However, previous methods still struggled to effectively handle\nforged images processed with diverse forgery operations in real-world\nscenarios. In this paper, we propose a novel Reinforced Multi-teacher Knowledge\nDistillation (Re-MTKD) framework for the IFDL task, structured around an\nencoder-decoder \\textbf{C}onvNeXt-\\textbf{U}perNet along with\n\\textbf{E}dge-Aware Module, named Cue-Net. First, three Cue-Net models are\nseparately trained for the three main types of image forgeries, i.e.,\ncopy-move, splicing, and inpainting, which then serve as the multi-teacher\nmodels to train the target student model with Cue-Net through self-knowledge\ndistillation. A Reinforced Dynamic Teacher Selection (Re-DTS) strategy is\ndeveloped to dynamically assign weights to the involved teacher models, which\nfacilitates specific knowledge transfer and enables the student model to\neffectively learn both the common and specific natures of diverse tampering\ntraces. Extensive experiments demonstrate that, compared with other\nstate-of-the-art methods, the proposed method achieves superior performance on\nseveral recently emerged datasets comprised of various kinds of image\nforgeries.", "published": "2025-04-07 16:12:05", "link": "http://arxiv.org/abs/2504.05224v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "An ensemble deep learning approach to detect tumors on Mohs micrographic surgery slides", "abstract": "Mohs micrographic surgery (MMS) is the gold standard technique for removing\nhigh risk nonmelanoma skin cancer however, intraoperative histopathological\nexamination demands significant time, effort, and professionality. The\nobjective of this study is to develop a deep learning model to detect basal\ncell carcinoma (BCC) and artifacts on Mohs slides. A total of 731 Mohs slides\nfrom 51 patients with BCCs were used in this study, with 91 containing tumor\nand 640 without tumor which was defined as non-tumor. The dataset was employed\nto train U-Net based models that segment tumor and non-tumor regions on the\nslides. The segmented patches were classified as tumor, or non-tumor to produce\npredictions for whole slide images (WSIs). For the segmentation phase, the deep\nlearning model success was measured using a Dice score with 0.70 and 0.67\nvalue, area under the curve (AUC) score with 0.98 and 0.96 for tumor and\nnon-tumor, respectively. For the tumor classification, an AUC of 0.98 for\npatch-based detection, and AUC of 0.91 for slide-based detection was obtained\non the test dataset. We present an AI system that can detect tumors and\nnon-tumors in Mohs slides with high success. Deep learning can aid Mohs\nsurgeons and dermatopathologists in making more accurate decisions.", "published": "2025-04-07 16:05:42", "link": "http://arxiv.org/abs/2504.05219v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Training state-of-the-art pathology foundation models with orders of magnitude less data", "abstract": "The field of computational pathology has recently seen rapid advances driven\nby the development of modern vision foundation models (FMs), typically trained\non vast collections of pathology images. Recent studies demonstrate that\nincreasing the training data set and model size and integrating domain-specific\nimage processing techniques can significantly enhance the model's performance\non downstream tasks. Building on these insights, our work incorporates several\nrecent modifications to the standard DINOv2 framework from the literature to\noptimize the training of pathology FMs. We also apply a post-training procedure\nfor fine-tuning models on higher-resolution images to further enrich the\ninformation encoded in the embeddings. We present three novel pathology FMs\ntrained on up to two orders of magnitude fewer WSIs than those used to train\nother state-of-the-art FMs while demonstrating a comparable or superior\nperformance on downstream tasks. Even the model trained on TCGA alone (12k\nWSIs) outperforms most existing FMs and, on average, matches Virchow2, the\nsecond-best FM published to date. This suggests that there still remains a\nsignificant potential for further improving the models and algorithms used to\ntrain pathology FMs to take full advantage of the vast data collections.", "published": "2025-04-07 15:38:12", "link": "http://arxiv.org/abs/2504.05186v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MSA-UNet3+: Multi-Scale Attention UNet3+ with New Supervised Prototypical Contrastive Loss for Coronary DSA Image Segmentation", "abstract": "The accurate segmentation of coronary Digital Subtraction Angiography (DSA)\nimages is essential for diagnosing and treating coronary artery diseases.\nDespite advances in deep learning-based segmentation, challenges such as low\ncontrast, noise, overlapping structures, high intra-class variance, and class\nimbalance limit precise vessel delineation. To overcome these limitations, we\npropose the MSA-UNet3+: a Multi-Scale Attention enhanced UNet3+ architecture\nfor coronary DSA image segmentation. The framework combined Multi-Scale Dilated\nBottleneck (MSD-Bottleneck) with Contextual Attention Fusion Module (CAFM),\nwhich not only enhances multi-scale feature extraction but also preserve\nfine-grained details, and improve contextual understanding. Furthermore, we\npropose a new Supervised Prototypical Contrastive Loss (SPCL), which combines\nsupervised and prototypical contrastive learning to minimize class imbalance\nand high intra-class variance by focusing on hard-to-classified background\nsamples. Experiments carried out on a private coronary DSA dataset demonstrate\nthat MSA-UNet3+ outperforms state-of-the-art methods, achieving a Dice\ncoefficient of 87.73%, an F1-score of 87.78%, and significantly reduced Average\nSurface Distance (ASD) and Average Contour Distance (ACD). The developed\nframework provides clinicians with precise vessel segmentation, enabling\naccurate identification of coronary stenosis and supporting informed diagnostic\nand therapeutic decisions. The code will be released at the following GitHub\nprofile link https://github.com/rayanmerghani/MSA-UNet3plus.", "published": "2025-04-07 15:35:30", "link": "http://arxiv.org/abs/2504.05184v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The 1st Solution for 4th PVUW MeViS Challenge: Unleashing the Potential of Large Multimodal Models for Referring Video Segmentation", "abstract": "Motion expression video segmentation is designed to segment objects in\naccordance with the input motion expressions. In contrast to the conventional\nReferring Video Object Segmentation (RVOS), it places emphasis on motion as\nwell as multi-object expressions, making it more arduous. Recently, Large\nMultimodal Models (LMMs) have begun to shine in RVOS due to their powerful\nvision-language perception capabilities. In this work, we propose a simple and\neffective inference optimization method to fully unleash the potential of LMMs\nin referring video segmentation. Firstly, we use Sa2VA as our baseline, which\nis a unified LMM for dense grounded understanding of both images and videos.\nSecondly, we uniformly sample the video frames during the inference process to\nenhance the model's understanding of the entire video. Finally, we integrate\nthe results of multiple expert models to mitigate the erroneous predictions of\na single model. Our solution achieved 61.98% J&F on the MeViS test set and\nranked 1st place in the 4th PVUW Challenge MeViS Track at CVPR 2025.", "published": "2025-04-07 15:24:54", "link": "http://arxiv.org/abs/2504.05178v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Balancing Task-invariant Interaction and Task-specific Adaptation for Unified Image Fusion", "abstract": "Unified image fusion aims to integrate complementary information from\nmulti-source images, enhancing image quality through a unified framework\napplicable to diverse fusion tasks. While treating all fusion tasks as a\nunified problem facilitates task-invariant knowledge sharing, it often\noverlooks task-specific characteristics, thereby limiting the overall\nperformance. Existing general image fusion methods incorporate explicit task\nidentification to enable adaptation to different fusion tasks. However, this\ndependence during inference restricts the model's generalization to unseen\nfusion tasks. To address these issues, we propose a novel unified image fusion\nframework named \"TITA\", which dynamically balances both Task-invariant\nInteraction and Task-specific Adaptation. For task-invariant interaction, we\nintroduce the Interaction-enhanced Pixel Attention (IPA) module to enhance\npixel-wise interactions for better multi-source complementary information\nextraction. For task-specific adaptation, the Operation-based Adaptive Fusion\n(OAF) module dynamically adjusts operation weights based on task properties.\nAdditionally, we incorporate the Fast Adaptive Multitask Optimization (FAMO)\nstrategy to mitigate the impact of gradient conflicts across tasks during joint\ntraining. Extensive experiments demonstrate that TITA not only achieves\ncompetitive performance compared to specialized methods across three image\nfusion scenarios but also exhibits strong generalization to unseen fusion\ntasks.", "published": "2025-04-07 15:08:35", "link": "http://arxiv.org/abs/2504.05164v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PanoDreamer: Consistent Text to 360-Degree Scene Generation", "abstract": "Automatically generating a complete 3D scene from a text description, a\nreference image, or both has significant applications in fields like virtual\nreality and gaming. However, current methods often generate low-quality\ntextures and inconsistent 3D structures. This is especially true when\nextrapolating significantly beyond the field of view of the reference image. To\naddress these challenges, we propose PanoDreamer, a novel framework for\nconsistent, 3D scene generation with flexible text and image control. Our\napproach employs a large language model and a warp-refine pipeline, first\ngenerating an initial set of images and then compositing them into a 360-degree\npanorama. This panorama is then lifted into 3D to form an initial point cloud.\nWe then use several approaches to generate additional images, from different\nviewpoints, that are consistent with the initial point cloud and expand/refine\nthe initial point cloud. Given the resulting set of images, we utilize 3D\nGaussian Splatting to create the final 3D scene, which can then be rendered\nfrom different viewpoints. Experiments demonstrate the effectiveness of\nPanoDreamer in generating high-quality, geometrically consistent 3D scenes.", "published": "2025-04-07 14:57:01", "link": "http://arxiv.org/abs/2504.05152v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Stereo-LiDAR Fusion by Semi-Global Matching With Discrete Disparity-Matching Cost and Semidensification", "abstract": "We present a real-time, non-learning depth estimation method that fuses Light\nDetection and Ranging (LiDAR) data with stereo camera input. Our approach\ncomprises three key techniques: Semi-Global Matching (SGM) stereo with Discrete\nDisparity-matching Cost (DDC), semidensification of LiDAR disparity, and a\nconsistency check that combines stereo images and LiDAR data. Each of these\ncomponents is designed for parallelization on a GPU to realize real-time\nperformance. When it was evaluated on the KITTI dataset, the proposed method\nachieved an error rate of 2.79\\%, outperforming the previous state-of-the-art\nreal-time stereo-LiDAR fusion method, which had an error rate of 3.05\\%.\nFurthermore, we tested the proposed method in various scenarios, including\ndifferent LiDAR point densities, varying weather conditions, and indoor\nenvironments, to demonstrate its high adaptability. We believe that the\nreal-time and non-learning nature of our method makes it highly practical for\napplications in robotics and automation.", "published": "2025-04-07 14:54:08", "link": "http://arxiv.org/abs/2504.05148v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "BoxSeg: Quality-Aware and Peer-Assisted Learning for Box-supervised Instance Segmentation", "abstract": "Box-supervised instance segmentation methods aim to achieve instance\nsegmentation with only box annotations. Recent methods have demonstrated the\neffectiveness of acquiring high-quality pseudo masks under the teacher-student\nframework. Building upon this foundation, we propose a BoxSeg framework\ninvolving two novel and general modules named the Quality-Aware Module (QAM)\nand the Peer-assisted Copy-paste (PC). The QAM obtains high-quality pseudo\nmasks and better measures the mask quality to help reduce the effect of noisy\nmasks, by leveraging the quality-aware multi-mask complementation mechanism.\nThe PC imitates Peer-Assisted Learning to further improve the quality of the\nlow-quality masks with the guidance of the obtained high-quality pseudo masks.\nTheoretical and experimental analyses demonstrate the proposed QAM and PC are\neffective. Extensive experimental results show the superiority of our BoxSeg\nover the state-of-the-art methods, and illustrate the QAM and PC can be applied\nto improve other models.", "published": "2025-04-07 14:42:33", "link": "http://arxiv.org/abs/2504.05137v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DA2Diff: Exploring Degradation-aware Adaptive Diffusion Priors for All-in-One Weather Restoration", "abstract": "Image restoration under adverse weather conditions is a critical task for\nmany vision-based applications. Recent all-in-one frameworks that handle\nmultiple weather degradations within a unified model have shown potential.\nHowever, the diversity of degradation patterns across different weather\nconditions, as well as the complex and varied nature of real-world\ndegradations, pose significant challenges for multiple weather removal. To\naddress these challenges, we propose an innovative diffusion paradigm with\ndegradation-aware adaptive priors for all-in-one weather restoration, termed\nDA2Diff. It is a new exploration that applies CLIP to perceive\ndegradation-aware properties for better multi-weather restoration.\nSpecifically, we deploy a set of learnable prompts to capture degradation-aware\nrepresentations by the prompt-image similarity constraints in the CLIP space.\nBy aligning the snowy/hazy/rainy images with snow/haze/rain prompts, each\nprompt contributes to different weather degradation characteristics. The\nlearned prompts are then integrated into the diffusion model via the designed\nweather specific prompt guidance module, making it possible to restore multiple\nweather types. To further improve the adaptiveness to complex weather\ndegradations, we propose a dynamic expert selection modulator that employs a\ndynamic weather-aware router to flexibly dispatch varying numbers of\nrestoration experts for each weather-distorted image, allowing the diffusion\nmodel to restore diverse degradations adaptively. Experimental results\nsubstantiate the favorable performance of DA2Diff over state-of-the-arts in\nquantitative and qualitative evaluation. Source code will be available after\nacceptance.", "published": "2025-04-07 14:38:57", "link": "http://arxiv.org/abs/2504.05135v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ABCDWaveNet: Advancing Robust Road Ponding Detection in Fog through Dynamic Frequency-Spatial Synergy", "abstract": "Road ponding presents a significant threat to vehicle safety, particularly in\nadverse fog conditions, where reliable detection remains a persistent challenge\nfor Advanced Driver Assistance Systems (ADAS). To address this, we propose\nABCDWaveNet, a novel deep learning framework leveraging Dynamic\nFrequency-Spatial Synergy for robust ponding detection in fog. The core of\nABCDWaveNet achieves this synergy by integrating dynamic convolution for\nadaptive feature extraction across varying visibilities with a wavelet-based\nmodule for synergistic frequency-spatial feature enhancement, significantly\nimproving robustness against fog interference. Building on this foundation,\nABCDWaveNet captures multi-scale structural and contextual information,\nsubsequently employing an Adaptive Attention Coupling Gate (AACG) to adaptively\nfuse global and local features for enhanced accuracy. To facilitate realistic\nevaluations under combined adverse conditions, we introduce the Foggy Low-Light\nPuddle dataset. Extensive experiments demonstrate that ABCDWaveNet establishes\nnew state-of-the-art performance, achieving significant Intersection over Union\n(IoU) gains of 3.51%, 1.75%, and 1.03% on the Foggy-Puddle, Puddle-1000, and\nour Foggy Low-Light Puddle datasets, respectively. Furthermore, its processing\nspeed of 25.48 FPS on an NVIDIA Jetson AGX Orin confirms its suitability for\nADAS deployment. These findings underscore the effectiveness of the proposed\nDynamic Frequency-Spatial Synergy within ABCDWaveNet, offering valuable\ninsights for developing proactive road safety solutions capable of operating\nreliably in challenging weather conditions.", "published": "2025-04-07 14:15:48", "link": "http://arxiv.org/abs/2504.05112v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Climplicit: Climatic Implicit Embeddings for Global Ecological Tasks", "abstract": "Deep learning on climatic data holds potential for macroecological\napplications. However, its adoption remains limited among scientists outside\nthe deep learning community due to storage, compute, and technical expertise\nbarriers. To address this, we introduce Climplicit, a spatio-temporal\ngeolocation encoder pretrained to generate implicit climatic representations\nanywhere on Earth. By bypassing the need to download raw climatic rasters and\ntrain feature extractors, our model uses x1000 fewer disk space and\nsignificantly reduces computational needs for downstream tasks. We evaluate our\nClimplicit embeddings on biomes classification, species distribution modeling,\nand plant trait regression. We find that linear probing our Climplicit\nembeddings consistently performs better or on par with training a model from\nscratch on downstream tasks and overall better than alternative geolocation\nencoding models.", "published": "2025-04-07 13:58:55", "link": "http://arxiv.org/abs/2504.05089v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Content-Distortion High-Order Interaction for Blind Image Quality Assessment", "abstract": "The content and distortion are widely recognized as the two primary factors\naffecting the visual quality of an image. While existing No-Reference Image\nQuality Assessment (NR-IQA) methods have modeled these factors, they fail to\ncapture the complex interactions between content and distortions. This\nshortfall impairs their ability to accurately perceive quality. To confront\nthis, we analyze the key properties required for interaction modeling and\npropose a robust NR-IQA approach termed CoDI-IQA (Content-Distortion high-order\nInteraction for NR-IQA), which aggregates local distortion and global content\nfeatures within a hierarchical interaction framework. Specifically, a\nProgressive Perception Interaction Module (PPIM) is proposed to explicitly\nsimulate how content and distortions independently and jointly influence image\nquality. By integrating internal interaction, coarse interaction, and fine\ninteraction, it achieves high-order interaction modeling that allows the model\nto properly represent the underlying interaction patterns. To ensure sufficient\ninteraction, multiple PPIMs are employed to hierarchically fuse multi-level\ncontent and distortion features at different granularities. We also tailor a\ntraining strategy suited for CoDI-IQA to maintain interaction stability.\nExtensive experiments demonstrate that the proposed method notably outperforms\nthe state-of-the-art methods in terms of prediction accuracy, data efficiency,\nand generalization ability.", "published": "2025-04-07 13:44:30", "link": "http://arxiv.org/abs/2504.05076v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PvNeXt: Rethinking Network Design and Temporal Motion for Point Cloud Video Recognition", "abstract": "Point cloud video perception has become an essential task for the realm of 3D\nvision. Current 4D representation learning techniques typically engage in\niterative processing coupled with dense query operations. Although effective in\ncapturing temporal features, this approach leads to substantial computational\nredundancy. In this work, we propose a framework, named as PvNeXt, for\neffective yet efficient point cloud video recognition, via personalized\none-shot query operation. Specially, PvNeXt consists of two key modules, the\nMotion Imitator and the Single-Step Motion Encoder. The former module, the\nMotion Imitator, is designed to capture the temporal dynamics inherent in\nsequences of point clouds, thus generating the virtual motion corresponding to\neach frame. The Single-Step Motion Encoder performs a one-step query operation,\nassociating point cloud of each frame with its corresponding virtual motion\nframe, thereby extracting motion cues from point cloud sequences and capturing\ntemporal dynamics across the entire sequence. Through the integration of these\ntwo modules, {PvNeXt} enables personalized one-shot queries for each frame,\neffectively eliminating the need for frame-specific looping and intensive query\nprocesses. Extensive experiments on multiple benchmarks demonstrate the\neffectiveness of our method.", "published": "2025-04-07 13:43:51", "link": "http://arxiv.org/abs/2504.05075v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LDGNet: A Lightweight Difference Guiding Network for Remote Sensing Change Detection", "abstract": "With the rapid advancement of deep learning, the field of change detection\n(CD) in remote sensing imagery has achieved remarkable progress. Existing\nchange detection methods primarily focus on achieving higher accuracy with\nincreased computational costs and parameter sizes, leaving development of\nlightweight methods for rapid real-world processing an underexplored challenge.\nTo address this challenge, we propose a Lightweight Difference Guiding Network\n(LDGNet), leveraging absolute difference image to guide optical remote sensing\nchange detection. First, to enhance the feature representation capability of\nthe lightweight backbone network, we propose the Difference Guiding Module\n(DGM), which leverages multi-scale features extracted from the absolute\ndifference image to progressively influence the original image encoder at each\nlayer, thereby reinforcing feature extraction. Second, we propose the\nDifference-Aware Dynamic Fusion (DADF) module with Visual State Space Model\n(VSSM) for lightweight long-range dependency modeling. The module first uses\nfeature absolute differences to guide VSSM's global contextual modeling of\nchange regions, then employs difference attention to dynamically fuse these\nlong-range features with feature differences, enhancing change semantics while\nsuppressing noise and background. Extensive experiments on multiple datasets\ndemonstrate that our method achieves comparable or superior performance to\ncurrent state-of-the-art (SOTA) methods requiring several times more\ncomputation, while maintaining only 3.43M parameters and 1.12G FLOPs.", "published": "2025-04-07 13:33:54", "link": "http://arxiv.org/abs/2504.05062v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CMaP-SAM: Contraction Mapping Prior for SAM-driven Few-shot Segmentation", "abstract": "Few-shot segmentation (FSS) aims to segment new classes using few annotated\nimages. While recent FSS methods have shown considerable improvements by\nleveraging Segment Anything Model (SAM), they face two critical limitations:\ninsufficient utilization of structural correlations in query images, and\nsignificant information loss when converting continuous position priors to\ndiscrete point prompts. To address these challenges, we propose CMaP-SAM, a\nnovel framework that introduces contraction mapping theory to optimize position\npriors for SAM-driven few-shot segmentation. CMaP-SAM consists of three key\ncomponents: (1) a contraction mapping module that formulates position prior\noptimization as a Banach contraction mapping with convergence guarantees. This\nmodule iteratively refines position priors through pixel-wise structural\nsimilarity, generating a converged prior that preserves both semantic guidance\nfrom reference images and structural correlations in query images; (2) an\nadaptive distribution alignment module bridging continuous priors with SAM's\nbinary mask prompt encoder; and (3) a foreground-background decoupled\nrefinement architecture producing accurate final segmentation masks. Extensive\nexperiments demonstrate CMaP-SAM's effectiveness, achieving state-of-the-art\nperformance with 71.1 mIoU on PASCAL-$5^i$ and 56.1 on COCO-$20^i$ datasets.", "published": "2025-04-07 13:19:16", "link": "http://arxiv.org/abs/2504.05049v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MotionPRO: Exploring the Role of Pressure in Human MoCap and Beyond", "abstract": "Existing human Motion Capture (MoCap) methods mostly focus on the visual\nsimilarity while neglecting the physical plausibility. As a result, downstream\ntasks such as driving virtual human in 3D scene or humanoid robots in real\nworld suffer from issues such as timing drift and jitter, spatial problems like\nsliding and penetration, and poor global trajectory accuracy. In this paper, we\nrevisit human MoCap from the perspective of interaction between human body and\nphysical world by exploring the role of pressure. Firstly, we construct a\nlarge-scale human Motion capture dataset with Pressure, RGB and Optical sensors\n(named MotionPRO), which comprises 70 volunteers performing 400 types of\nmotion, encompassing a total of 12.4M pose frames. Secondly, we examine both\nthe necessity and effectiveness of the pressure signal through two challenging\ntasks: (1) pose and trajectory estimation based solely on pressure: We propose\na network that incorporates a small kernel decoder and a long-short-term\nattention module, and proof that pressure could provide accurate global\ntrajectory and plausible lower body pose. (2) pose and trajectory estimation by\nfusing pressure and RGB: We impose constraints on orthographic similarity along\nthe camera axis and whole-body contact along the vertical axis to enhance the\ncross-attention strategy to fuse pressure and RGB feature maps. Experiments\ndemonstrate that fusing pressure with RGB features not only significantly\nimproves performance in terms of objective metrics, but also plausibly drives\nvirtual humans (SMPL) in 3D scene. Furthermore, we demonstrate that\nincorporating physical perception enables humanoid robots to perform more\nprecise and stable actions, which is highly beneficial for the development of\nembodied artificial intelligence. Project page is available at:\nhttps://nju-cite-mocaphumanoid.github.io/MotionPRO/", "published": "2025-04-07 13:17:24", "link": "http://arxiv.org/abs/2504.05046v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "InstructionBench: An Instructional Video Understanding Benchmark", "abstract": "Despite progress in video large language models (Video-LLMs), research on\ninstructional video understanding, crucial for enhancing access to\ninstructional content, remains insufficient. To address this, we introduce\nInstructionBench, an Instructional video understanding Benchmark, which\nchallenges models' advanced temporal reasoning within instructional videos\ncharacterized by their strict step-by-step flow. Employing GPT-4, we formulate\nQ\\&A pairs in open-ended and multiple-choice formats to assess both\nCoarse-Grained event-level and Fine-Grained object-level reasoning. Our\nfiltering strategies exclude questions answerable purely by common-sense\nknowledge, focusing on visual perception and analysis when evaluating Video-LLM\nmodels. The benchmark finally contains 5k questions across over 700 videos. We\nevaluate the latest Video-LLMs on our InstructionBench, finding that\nclosed-source models outperform open-source ones. However, even the best model,\nGPT-4o, achieves only 53.42\\% accuracy, indicating significant gaps in temporal\nreasoning. To advance the field, we also develop a comprehensive instructional\nvideo dataset with over 19k Q\\&A pairs from nearly 2.5k videos, using an\nautomated data generation framework, thereby enriching the community's research\nresources.", "published": "2025-04-07 13:05:09", "link": "http://arxiv.org/abs/2504.05040v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CloSE: A Compact Shape- and Orientation-Agnostic Cloth State Representation", "abstract": "Cloth manipulation is a difficult problem mainly because of the non-rigid\nnature of cloth, which makes a good representation of deformation essential. We\npresent a new representation for the deformation-state of clothes. First, we\npropose the dGLI disk representation, based on topological indices computed for\nsegments on the edges of the cloth mesh border that are arranged on a circular\ngrid. The heat-map of the dGLI disk uncovers patterns that correspond to\nfeatures of the cloth state that are consistent for different shapes, sizes of\npositions of the cloth, like the corners and the fold locations. We then\nabstract these important features from the dGLI disk onto a circle, calling it\nthe Cloth StatE representation (CloSE). This representation is compact,\ncontinuous, and general for different shapes. Finally, we show the strengths of\nthis representation in two relevant applications: semantic labeling and high-\nand low-level planning. The code, the dataset and the video can be accessed\nfrom : https://jaykamat99.github.io/close-representation", "published": "2025-04-07 12:54:58", "link": "http://arxiv.org/abs/2504.05033v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "AsyReC: A Multimodal Graph-based Framework for Spatio-Temporal Asymmetric Dyadic Relationship Classification", "abstract": "Dyadic social relationships, which refer to relationships between two\nindividuals who know each other through repeated interactions (or not), are\nshaped by shared spatial and temporal experiences. Current computational\nmethods for modeling these relationships face three major challenges: (1) the\nfailure to model asymmetric relationships, e.g., one individual may perceive\nthe other as a friend while the other perceives them as an acquaintance, (2)\nthe disruption of continuous interactions by discrete frame sampling, which\nsegments the temporal continuity of interaction in real-world scenarios, and\n(3) the limitation to consider periodic behavioral cues, such as rhythmic\nvocalizations or recurrent gestures, which are crucial for inferring the\nevolution of dyadic relationships. To address these challenges, we propose\nAsyReC, a multimodal graph-based framework for asymmetric dyadic relationship\nclassification, with three core innovations: (i) a triplet graph neural network\nwith node-edge dual attention that dynamically weights multimodal cues to\ncapture interaction asymmetries (addressing challenge 1); (ii) a clip-level\nrelationship learning architecture that preserves temporal continuity, enabling\nfine-grained modeling of real-world interaction dynamics (addressing challenge\n2); and (iii) a periodic temporal encoder that projects time indices onto\nsine/cosine waveforms to model recurrent behavioral patterns (addressing\nchallenge 3). Extensive experiments on two public datasets demonstrate\nstate-of-the-art performance, while ablation studies validate the critical role\nof asymmetric interaction modeling and periodic temporal encoding in improving\nthe robustness of dyadic relationship classification in real-world scenarios.\nOur code is publicly available at: https://github.com/tw-repository/AsyReC.", "published": "2025-04-07 12:52:23", "link": "http://arxiv.org/abs/2504.05030v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "REWIND: Real-Time Egocentric Whole-Body Motion Diffusion with Exemplar-Based Identity Conditioning", "abstract": "We present REWIND (Real-Time Egocentric Whole-Body Motion Diffusion), a\none-step diffusion model for real-time, high-fidelity human motion estimation\nfrom egocentric image inputs. While an existing method for egocentric\nwhole-body (i.e., body and hands) motion estimation is non-real-time and\nacausal due to diffusion-based iterative motion refinement to capture\ncorrelations between body and hand poses, REWIND operates in a fully causal and\nreal-time manner. To enable real-time inference, we introduce (1) cascaded\nbody-hand denoising diffusion, which effectively models the correlation between\negocentric body and hand motions in a fast, feed-forward manner, and (2)\ndiffusion distillation, which enables high-quality motion estimation with a\nsingle denoising step. Our denoising diffusion model is based on a modified\nTransformer architecture, designed to causally model output motions while\nenhancing generalizability to unseen motion lengths. Additionally, REWIND\noptionally supports identity-conditioned motion estimation when identity prior\nis available. To this end, we propose a novel identity conditioning method\nbased on a small set of pose exemplars of the target identity, which further\nenhances motion estimation quality. Through extensive experiments, we\ndemonstrate that REWIND significantly outperforms the existing baselines both\nwith and without exemplar-based identity conditioning.", "published": "2025-04-07 11:44:11", "link": "http://arxiv.org/abs/2504.04956v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Inter-event Interval Microscopy for Event Cameras", "abstract": "Event cameras, an innovative bio-inspired sensor, differ from traditional\ncameras by sensing changes in intensity rather than directly perceiving\nintensity and recording these variations as a continuous stream of \"events\".\nThe intensity reconstruction from these sparse events has long been a\nchallenging problem. Previous approaches mainly focused on transforming\nmotion-induced events into videos or achieving intensity imaging for static\nscenes by integrating modulation devices at the event camera acquisition end.\nIn this paper, for the first time, we achieve event-to-intensity conversion\nusing a static event camera for both static and dynamic scenes in fluorescence\nmicroscopy. Unlike conventional methods that primarily rely on event\nintegration, the proposed Inter-event Interval Microscopy (IEIM) quantifies the\ntime interval between consecutive events at each pixel. With a fixed threshold\nin the event camera, the time interval can precisely represent the intensity.\nAt the hardware level, the proposed IEIM integrates a pulse light modulation\ndevice within a microscope equipped with an event camera, termed Pulse\nModulation-based Event-driven Fluorescence Microscopy.mAdditionally, we have\ncollected IEIMat dataset under various scenes including high dynamic range and\nhigh-speed scenarios. Experimental results on the IEIMat dataset demonstrate\nthat the proposed IEIM achieves superior spatial and temporal resolution, as\nwell as a higher dynamic range, with lower bandwidth compared to other methods.\nThe code and the IEIMat dataset will be made publicly available.", "published": "2025-04-07 11:05:13", "link": "http://arxiv.org/abs/2504.04924v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "IterMask3D: Unsupervised Anomaly Detection and Segmentation with Test-Time Iterative Mask Refinement in 3D Brain MR", "abstract": "Unsupervised anomaly detection and segmentation methods train a model to\nlearn the training distribution as 'normal'. In the testing phase, they\nidentify patterns that deviate from this normal distribution as 'anomalies'. To\nlearn the `normal' distribution, prevailing methods corrupt the images and\ntrain a model to reconstruct them. During testing, the model attempts to\nreconstruct corrupted inputs based on the learned 'normal' distribution.\nDeviations from this distribution lead to high reconstruction errors, which\nindicate potential anomalies. However, corrupting an input image inevitably\ncauses information loss even in normal regions, leading to suboptimal\nreconstruction and an increased risk of false positives. To alleviate this, we\npropose IterMask3D, an iterative spatial mask-refining strategy designed for 3D\nbrain MRI. We iteratively spatially mask areas of the image as corruption and\nreconstruct them, then shrink the mask based on reconstruction error. This\nprocess iteratively unmasks 'normal' areas to the model, whose information\nfurther guides reconstruction of 'normal' patterns under the mask to be\nreconstructed accurately, reducing false positives. In addition, to achieve\nbetter reconstruction performance, we also propose using high-frequency image\ncontent as additional structural information to guide the reconstruction of the\nmasked area. Extensive experiments on the detection of both synthetic and\nreal-world imaging artifacts, as well as segmentation of various pathological\nlesions across multiple MRI sequences, consistently demonstrate the\neffectiveness of our proposed method.", "published": "2025-04-07 10:41:23", "link": "http://arxiv.org/abs/2504.04911v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Content-Aware Transformer for All-in-one Image Restoration", "abstract": "Image restoration has witnessed significant advancements with the development\nof deep learning models. Although Transformer architectures have progressed\nconsiderably in recent years, challenges remain, particularly the limited\nreceptive field in window-based self-attention. In this work, we propose\nDSwinIR, a Deformable Sliding window Transformer for Image Restoration. DSwinIR\nintroduces a novel deformable sliding window self-attention that adaptively\nadjusts receptive fields based on image content, enabling the attention\nmechanism to focus on important regions and enhance feature extraction aligned\nwith salient features. Additionally, we introduce a central ensemble pattern to\nreduce the inclusion of irrelevant content within attention windows. In this\nway, the proposed DSwinIR model integrates the deformable sliding window\nTransformer and central ensemble pattern to amplify the strengths of both CNNs\nand Transformers while mitigating their limitations. Extensive experiments on\nvarious image restoration tasks demonstrate that DSwinIR achieves\nstate-of-the-art performance. For example, in image deraining, compared to\nDRSformer on the SPA dataset, DSwinIR achieves a 0.66 dB PSNR improvement. In\nall-in-one image restoration, compared to PromptIR, DSwinIR achieves over a\n0.66 dB and 1.04 dB improvement on three-task and five-task settings,\nrespectively. Pretrained models and code are available at our project\nhttps://github.com/Aitical/DSwinIR.", "published": "2025-04-07 09:24:41", "link": "http://arxiv.org/abs/2504.04869v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Embracing Dynamics: Dynamics-aware 4D Gaussian Splatting SLAM", "abstract": "Simultaneous localization and mapping (SLAM) technology now has\nphotorealistic mapping capabilities thanks to the real-time high-fidelity\nrendering capability of 3D Gaussian splatting (3DGS). However, due to the\nstatic representation of scenes, current 3DGS-based SLAM encounters issues with\npose drift and failure to reconstruct accurate maps in dynamic environments. To\naddress this problem, we present D4DGS-SLAM, the first SLAM method based on\n4DGS map representation for dynamic environments. By incorporating the temporal\ndimension into scene representation, D4DGS-SLAM enables high-quality\nreconstruction of dynamic scenes. Utilizing the dynamics-aware InfoModule, we\ncan obtain the dynamics, visibility, and reliability of scene points, and\nfilter stable static points for tracking accordingly. When optimizing Gaussian\npoints, we apply different isotropic regularization terms to Gaussians with\nvarying dynamic characteristics. Experimental results on real-world dynamic\nscene datasets demonstrate that our method outperforms state-of-the-art\napproaches in both camera pose tracking and map quality.", "published": "2025-04-07 08:56:35", "link": "http://arxiv.org/abs/2504.04844v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "FantasyTalking: Realistic Talking Portrait Generation via Coherent Motion Synthesis", "abstract": "Creating a realistic animatable avatar from a single static portrait remains\nchallenging. Existing approaches often struggle to capture subtle facial\nexpressions, the associated global body movements, and the dynamic background.\nTo address these limitations, we propose a novel framework that leverages a\npretrained video diffusion transformer model to generate high-fidelity,\ncoherent talking portraits with controllable motion dynamics. At the core of\nour work is a dual-stage audio-visual alignment strategy. In the first stage,\nwe employ a clip-level training scheme to establish coherent global motion by\naligning audio-driven dynamics across the entire scene, including the reference\nportrait, contextual objects, and background. In the second stage, we refine\nlip movements at the frame level using a lip-tracing mask, ensuring precise\nsynchronization with audio signals. To preserve identity without compromising\nmotion flexibility, we replace the commonly used reference network with a\nfacial-focused cross-attention module that effectively maintains facial\nconsistency throughout the video. Furthermore, we integrate a motion intensity\nmodulation module that explicitly controls expression and body motion\nintensity, enabling controllable manipulation of portrait movements beyond mere\nlip motion. Extensive experimental results show that our proposed approach\nachieves higher quality with better realism, coherence, motion intensity, and\nidentity preservation. Ours project page:\nhttps://fantasy-amap.github.io/fantasy-talking/.", "published": "2025-04-07 08:56:01", "link": "http://arxiv.org/abs/2504.04842v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Prior2Former -- Evidential Modeling of Mask Transformers for Assumption-Free Open-World Panoptic Segmentation", "abstract": "In panoptic segmentation, individual instances must be separated within\nsemantic classes. As state-of-the-art methods rely on a pre-defined set of\nclasses, they struggle with novel categories and out-of-distribution (OOD)\ndata. This is particularly problematic in safety-critical applications, such as\nautonomous driving, where reliability in unseen scenarios is essential. We\naddress the gap between outstanding benchmark performance and reliability by\nproposing Prior2Former (P2F), the first approach for segmentation vision\ntransformers rooted in evidential learning. P2F extends the mask vision\ntransformer architecture by incorporating a Beta prior for computing model\nuncertainty in pixel-wise binary mask assignments. This design enables\nhigh-quality uncertainty estimation that effectively detects novel and OOD\nobjects enabling state-of-the-art anomaly instance segmentation and open-world\npanoptic segmentation. Unlike most segmentation models addressing unknown\nclasses, P2F operates without access to OOD data samples or contrastive\ntraining on void (i.e., unlabeled) classes, making it highly applicable in\nreal-world scenarios where such prior information is unavailable. Additionally,\nP2F can be flexibly applied to anomaly instance and panoptic segmentation.\nThrough comprehensive experiments on the Cityscapes, COCO, SegmentMeIfYouCan,\nand OoDIS datasets, we demonstrate the state-of-the-art performance of P2F. It\nachieves the highest ranking in the OoDIS anomaly instance benchmark among\nmethods not using OOD data in any way.", "published": "2025-04-07 08:53:14", "link": "http://arxiv.org/abs/2504.04841v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Uni4D: A Unified Self-Supervised Learning Framework for Point Cloud Videos", "abstract": "Point cloud video representation learning is primarily built upon the masking\nstrategy in a self-supervised manner. However, the progress is slow due to\nseveral significant challenges: (1) existing methods learn the motion\nparticularly with hand-crafted designs, leading to unsatisfactory motion\npatterns during pre-training which are non-transferable on fine-tuning\nscenarios. (2) previous Masked AutoEncoder (MAE) frameworks are limited in\nresolving the huge representation gap inherent in 4D data. In this study, we\nintroduce the first self-disentangled MAE for learning discriminative 4D\nrepresentations in the pre-training stage. To address the first challenge, we\npropose to model the motion representation in a latent space. The second issue\nis resolved by introducing the latent tokens along with the typical geometry\ntokens to disentangle high-level and low-level features during decoding.\nExtensive experiments on MSR-Action3D, NTU-RGBD, HOI4D, NvGesture, and SHREC'17\nverify this self-disentangled learning framework. We demonstrate that it can\nboost the fine-tuning performance on all 4D tasks, which we term Uni4D. Our\npre-trained model presents discriminative and meaningful 4D representations,\nparticularly benefits processing long videos, as Uni4D gets $+3.8\\%$\nsegmentation accuracy on HOI4D, significantly outperforming either\nself-supervised or fully-supervised methods after end-to-end fine-tuning.", "published": "2025-04-07 08:47:36", "link": "http://arxiv.org/abs/2504.04837v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Inland Waterway Object Detection in Multi-environment: Dataset and Approach", "abstract": "The success of deep learning in intelligent ship visual perception relies\nheavily on rich image data. However, dedicated datasets for inland waterway\nvessels remain scarce, limiting the adaptability of visual perception systems\nin complex environments. Inland waterways, characterized by narrow channels,\nvariable weather, and urban interference, pose significant challenges to object\ndetection systems based on existing datasets. To address these issues, this\npaper introduces the Multi-environment Inland Waterway Vessel Dataset (MEIWVD),\ncomprising 32,478 high-quality images from diverse scenarios, including sunny,\nrainy, foggy, and artificial lighting conditions. MEIWVD covers common vessel\ntypes in the Yangtze River Basin, emphasizing diversity, sample independence,\nenvironmental complexity, and multi-scale characteristics, making it a robust\nbenchmark for vessel detection. Leveraging MEIWVD, this paper proposes a\nscene-guided image enhancement module to improve water surface images based on\nenvironmental conditions adaptively. Additionally, a parameter-limited dilated\nconvolution enhances the representation of vessel features, while a multi-scale\ndilated residual fusion method integrates multi-scale features for better\ndetection. Experiments show that MEIWVD provides a more rigorous benchmark for\nobject detection algorithms, and the proposed methods significantly improve\ndetector performance, especially in complex multi-environment scenarios.", "published": "2025-04-07 08:45:00", "link": "http://arxiv.org/abs/2504.04835v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Affine Correspondences by Integrating Geometric Constraints", "abstract": "Affine correspondences have received significant attention due to their\nbenefits in tasks like image matching and pose estimation. Existing methods for\nextracting affine correspondences still have many limitations in terms of\nperformance; thus, exploring a new paradigm is crucial. In this paper, we\npresent a new pipeline designed for extracting accurate affine correspondences\nby integrating dense matching and geometric constraints. Specifically, a novel\nextraction framework is introduced, with the aid of dense matching and a novel\nkeypoint scale and orientation estimator. For this purpose, we propose loss\nfunctions based on geometric constraints, which can effectively improve\naccuracy by supervising neural networks to learn feature geometry. The\nexperimental show that the accuracy and robustness of our method outperform the\nexisting ones in image matching tasks. To further demonstrate the effectiveness\nof the proposed method, we applied it to relative pose estimation. Affine\ncorrespondences extracted by our method lead to more accurate poses than the\nbaselines on a range of real-world datasets. The code is available at\nhttps://github.com/stilcrad/DenseAffine.", "published": "2025-04-07 08:44:50", "link": "http://arxiv.org/abs/2504.04834v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SMF: Template-free and Rig-free Animation Transfer using Kinetic Codes", "abstract": "Animation retargeting involves applying a sparse motion description (e.g.,\n2D/3D keypoint sequences) to a given character mesh to produce a semantically\nplausible and temporally coherent full-body motion. Existing approaches come\nwith a mix of restrictions - they require annotated training data, assume\naccess to template-based shape priors or artist-designed deformation rigs,\nsuffer from limited generalization to unseen motion and/or shapes, or exhibit\nmotion jitter. We propose Self-supervised Motion Fields (SMF) as a\nself-supervised framework that can be robustly trained with sparse motion\nrepresentations, without requiring dataset specific annotations, templates, or\nrigs. At the heart of our method are Kinetic Codes, a novel autoencoder-based\nsparse motion encoding, that exposes a semantically rich latent space\nsimplifying large-scale training. Our architecture comprises dedicated spatial\nand temporal gradient predictors, which are trained end-to-end. The resultant\nnetwork, regularized by the Kinetic Codes's latent space, has good\ngeneralization across shapes and motions. We evaluated our method on unseen\nmotion sampled from AMASS, D4D, Mixamo, and raw monocular video for animation\ntransfer on various characters with varying shapes and topology. We report a\nnew SoTA on the AMASS dataset in the context of generalization to unseen\nmotion. Project webpage at https://motionfields.github.io/", "published": "2025-04-07 08:42:52", "link": "http://arxiv.org/abs/2504.04831v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "SUEDE:Shared Unified Experts for Physical-Digital Face Attack Detection Enhancement", "abstract": "Face recognition systems are vulnerable to physical attacks (e.g., printed\nphotos) and digital threats (e.g., DeepFake), which are currently being studied\nas independent visual tasks, such as Face Anti-Spoofing and Forgery Detection.\nThe inherent differences among various attack types present significant\nchallenges in identifying a common feature space, making it difficult to\ndevelop a unified framework for detecting data from both attack modalities\nsimultaneously. Inspired by the efficacy of Mixture-of-Experts (MoE) in\nlearning across diverse domains, we explore utilizing multiple experts to learn\nthe distinct features of various attack types. However, the feature\ndistributions of physical and digital attacks overlap and differ. This suggests\nthat relying solely on distinct experts to learn the unique features of each\nattack type may overlook shared knowledge between them. To address these\nissues, we propose SUEDE, the Shared Unified Experts for Physical-Digital Face\nAttack Detection Enhancement. SUEDE combines a shared expert (always activated)\nto capture common features for both attack types and multiple routed experts\n(selectively activated) for specific attack types. Further, we integrate CLIP\nas the base network to ensure the shared expert benefits from prior visual\nknowledge and align visual-text representations in a unified space. Extensive\nresults demonstrate SUEDE achieves superior performance compared to\nstate-of-the-art unified detection methods.", "published": "2025-04-07 08:17:54", "link": "http://arxiv.org/abs/2504.04818v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Explainability of AI Uncertainty: Application to Multiple Sclerosis Lesion Segmentation on MRI", "abstract": "Trustworthy artificial intelligence (AI) is essential in healthcare,\nparticularly for high-stakes tasks like medical image segmentation. Explainable\nAI and uncertainty quantification significantly enhance AI reliability by\naddressing key attributes such as robustness, usability, and explainability.\nDespite extensive technical advances in uncertainty quantification for medical\nimaging, understanding the clinical informativeness and interpretability of\nuncertainty remains limited. This study introduces a novel framework to explain\nthe potential sources of predictive uncertainty, specifically in cortical\nlesion segmentation in multiple sclerosis using deep ensembles. The proposed\nanalysis shifts the focus from the uncertainty-error relationship towards\nrelevant medical and engineering factors. Our findings reveal that\ninstance-wise uncertainty is strongly related to lesion size, shape, and\ncortical involvement. Expert rater feedback confirms that similar factors\nimpede annotator confidence. Evaluations conducted on two datasets (206\npatients, almost 2000 lesions) under both in-domain and distribution-shift\nconditions highlight the utility of the framework in different scenarios.", "published": "2025-04-07 08:09:27", "link": "http://arxiv.org/abs/2504.04814v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "DebGCD: Debiased Learning with Distribution Guidance for Generalized Category Discovery", "abstract": "In this paper, we tackle the problem of Generalized Category Discovery (GCD).\nGiven a dataset containing both labelled and unlabelled images, the objective\nis to categorize all images in the unlabelled subset, irrespective of whether\nthey are from known or unknown classes. In GCD, an inherent label bias exists\nbetween known and unknown classes due to the lack of ground-truth labels for\nthe latter. State-of-the-art methods in GCD leverage parametric classifiers\ntrained through self-distillation with soft labels, leaving the bias issue\nunattended. Besides, they treat all unlabelled samples uniformly, neglecting\nvariations in certainty levels and resulting in suboptimal learning. Moreover,\nthe explicit identification of semantic distribution shifts between known and\nunknown classes, a vital aspect for effective GCD, has been neglected. To\naddress these challenges, we introduce DebGCD, a \\underline{Deb}iased learning\nwith distribution guidance framework for \\underline{GCD}. Initially, DebGCD\nco-trains an auxiliary debiased classifier in the same feature space as the GCD\nclassifier, progressively enhancing the GCD features. Moreover, we introduce a\nsemantic distribution detector in a separate feature space to implicitly boost\nthe learning efficacy of GCD. Additionally, we employ a curriculum learning\nstrategy based on semantic distribution certainty to steer the debiased\nlearning at an optimized pace. Thorough evaluations on GCD benchmarks\ndemonstrate the consistent state-of-the-art performance of our framework,\nhighlighting its superiority. Project page: https://visual-ai.github.io/debgcd/", "published": "2025-04-07 07:56:01", "link": "http://arxiv.org/abs/2504.04804v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OrderChain: A General Prompting Paradigm to Improve Ordinal Understanding Ability of MLLM", "abstract": "Despite the remarkable progress of multimodal large language models (MLLMs),\nthey continue to face challenges in achieving competitive performance on\nordinal regression (OR; a.k.a. ordinal classification). To address this issue,\nthis paper presents OrderChain, a novel and general prompting paradigm that\nimproves the ordinal understanding ability of MLLMs by specificity and\ncommonality modeling. Specifically, our OrderChain consists of a set of\ntask-aware prompts to facilitate the specificity modeling of diverse OR tasks\nand a new range optimization Chain-of-Thought (RO-CoT), which learns a\ncommonality way of thinking about OR tasks by uniformly decomposing them into\nmultiple small-range optimization subtasks. Further, we propose a category\nrecursive division (CRD) method to generate instruction candidate category\nprompts to support RO-CoT automatic optimization. Comprehensive experiments\nshow that a Large Language and Vision Assistant (LLaVA) model with our\nOrderChain improves baseline LLaVA significantly on diverse OR datasets, e.g.,\nfrom 47.5% to 93.2% accuracy on the Adience dataset for age estimation, and\nfrom 30.0% to 85.7% accuracy on the Diabetic Retinopathy dataset. Notably,\nLLaVA with our OrderChain also remarkably outperforms state-of-the-art methods\nby 27% on accuracy and 0.24 on MAE on the Adience dataset. To our best\nknowledge, our OrderChain is the first work that augments MLLMs for OR tasks,\nand the effectiveness is witnessed across a spectrum of OR datasets.", "published": "2025-04-07 07:53:44", "link": "http://arxiv.org/abs/2504.04801v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Disentangling Instruction Influence in Diffusion Transformers for Parallel Multi-Instruction-Guided Image Editing", "abstract": "Instruction-guided image editing enables users to specify modifications using\nnatural language, offering more flexibility and control. Among existing\nframeworks, Diffusion Transformers (DiTs) outperform U-Net-based diffusion\nmodels in scalability and performance. However, while real-world scenarios\noften require concurrent execution of multiple instructions, step-by-step\nediting suffers from accumulated errors and degraded quality, and integrating\nmultiple instructions with a single prompt usually results in incomplete edits\ndue to instruction conflicts. We propose Instruction Influence Disentanglement\n(IID), a novel framework enabling parallel execution of multiple instructions\nin a single denoising process, designed for DiT-based models. By analyzing\nself-attention mechanisms in DiTs, we identify distinctive attention patterns\nin multi-instruction settings and derive instruction-specific attention masks\nto disentangle each instruction's influence. These masks guide the editing\nprocess to ensure localized modifications while preserving consistency in\nnon-edited regions. Extensive experiments on open-source and custom datasets\ndemonstrate that IID reduces diffusion steps while improving fidelity and\ninstruction completion compared to existing baselines. The codes will be\npublicly released upon the acceptance of the paper.", "published": "2025-04-07 07:26:25", "link": "http://arxiv.org/abs/2504.04784v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OCC-MLLM-CoT-Alpha: Towards Multi-stage Occlusion Recognition Based on Large Language Models via 3D-Aware Supervision and Chain-of-Thoughts Guidance", "abstract": "Comprehending occluded objects are not well studied in existing large-scale\nvisual-language multi-modal models. Current state-of-the-art multi-modal large\nmodels struggles to provide satisfactory results in understanding occluded\nobjects through universal visual encoders and supervised learning strategies.\nTherefore, we propose OCC-MLLM-CoT-Alpha, a multi-modal large vision language\nframework that integrates 3D-aware supervision and Chain-of-Thoughts guidance.\nParticularly, (1) we build a multi-modal large vision-language model framework\nwhich is consisted of a large multi-modal vision-language model and a 3D\nreconstruction expert model. (2) the corresponding multi-modal\nChain-of-Thoughts is learned through a combination of supervised and\nreinforcement training strategies, allowing the multi-modal vision-language\nmodel to enhance the recognition ability with learned multi-modal\nchain-of-thoughts guidance. (3) A large-scale multi-modal chain-of-thoughts\nreasoning dataset, consisting of $110k$ samples of occluded objects held in\nhand, is built. In the evaluation, the proposed methods demonstrate decision\nscore improvement of 15.75%,15.30%,16.98%,14.62%, and 4.42%,3.63%,6.94%,10.70%\nfor two settings of a variety of state-of-the-art models.", "published": "2025-04-07 07:15:26", "link": "http://arxiv.org/abs/2504.04781v1", "categories": ["cs.CV", "I.2.10; I.4.8"], "primary_category": "cs.CV"}
{"title": "Bottom-Up Scattering Information Perception Network for SAR target recognition", "abstract": "Deep learning methods based synthetic aperture radar (SAR) image target\nrecognition tasks have been widely studied currently. The existing deep methods\nare insufficient to perceive and mine the scattering information of SAR images,\nresulting in performance bottlenecks and poor robustness of the algorithms. To\nthis end, this paper proposes a novel bottom-up scattering information\nperception network for more interpretable target recognition by constructing\nthe proprietary interpretation network for SAR images. Firstly, the localized\nscattering perceptron is proposed to replace the backbone feature extractor\nbased on CNN networks to deeply mine the underlying scattering information of\nthe target. Then, an unsupervised scattering part feature extraction model is\nproposed to robustly characterize the target scattering part information and\nprovide fine-grained target representation. Finally, by aggregating the\nknowledge of target parts to form the complete target description, the\ninterpretability and discriminative ability of the model is improved. We\nperform experiments on the FAST-Vehicle dataset and the SAR-ACD dataset to\nvalidate the performance of the proposed method.", "published": "2025-04-07 07:15:08", "link": "http://arxiv.org/abs/2504.04780v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Continuous Locomotive Crowd Behavior Generation", "abstract": "Modeling and reproducing crowd behaviors are important in various domains\nincluding psychology, robotics, transport engineering and virtual environments.\nConventional methods have focused on synthesizing momentary scenes, which have\ndifficulty in replicating the continuous nature of real-world crowds. In this\npaper, we introduce a novel method for automatically generating continuous,\nrealistic crowd trajectories with heterogeneous behaviors and interactions\namong individuals. We first design a crowd emitter model. To do this, we obtain\nspatial layouts from single input images, including a segmentation map,\nappearance map, population density map and population probability, prior to\ncrowd generation. The emitter then continually places individuals on the\ntimeline by assigning independent behavior characteristics such as agents'\ntype, pace, and start/end positions using diffusion models. Next, our crowd\nsimulator produces their long-term locomotions. To simulate diverse actions, it\ncan augment their behaviors based on a Markov chain. As a result, our overall\nframework populates the scenes with heterogeneous crowd behaviors by\nalternating between the proposed emitter and simulator. Note that all the\ncomponents in the proposed framework are user-controllable. Lastly, we propose\na benchmark protocol to evaluate the realism and quality of the generated\ncrowds in terms of the scene-level population dynamics and the individual-level\ntrajectory accuracy. We demonstrate that our approach effectively models\ndiverse crowd behavior patterns and generalizes well across different\ngeographical environments. Code is publicly available at\nhttps://github.com/InhwanBae/CrowdES .", "published": "2025-04-07 06:08:59", "link": "http://arxiv.org/abs/2504.04756v1", "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "CADCrafter: Generating Computer-Aided Design Models from Unconstrained Images", "abstract": "Creating CAD digital twins from the physical world is crucial for\nmanufacturing, design, and simulation. However, current methods typically rely\non costly 3D scanning with labor-intensive post-processing. To provide a\nuser-friendly design process, we explore the problem of reverse engineering\nfrom unconstrained real-world CAD images that can be easily captured by users\nof all experiences. However, the scarcity of real-world CAD data poses\nchallenges in directly training such models. To tackle these challenges, we\npropose CADCrafter, an image-to-parametric CAD model generation framework that\ntrains solely on synthetic textureless CAD data while testing on real-world\nimages. To bridge the significant representation disparity between images and\nparametric CAD models, we introduce a geometry encoder to accurately capture\ndiverse geometric features. Moreover, the texture-invariant properties of the\ngeometric features can also facilitate the generalization to real-world\nscenarios. Since compiling CAD parameter sequences into explicit CAD models is\na non-differentiable process, the network training inherently lacks explicit\ngeometric supervision. To impose geometric validity constraints, we employ\ndirect preference optimization (DPO) to fine-tune our model with the automatic\ncode checker feedback on CAD sequence quality. Furthermore, we collected a\nreal-world dataset, comprised of multi-view images and corresponding CAD\ncommand sequence pairs, to evaluate our method. Experimental results\ndemonstrate that our approach can robustly handle real unconstrained CAD\nimages, and even generalize to unseen general objects.", "published": "2025-04-07 06:01:35", "link": "http://arxiv.org/abs/2504.04753v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Vision Transformers with Autoencoders and Explainable AI for Cancer Patient Risk Stratification Using Whole Slide Imaging", "abstract": "Cancer remains one of the leading causes of mortality worldwide,\nnecessitating accurate diagnosis and prognosis. Whole Slide Imaging (WSI) has\nbecome an integral part of clinical workflows with advancements in digital\npathology. While various studies have utilized WSIs, their extracted features\nmay not fully capture the most relevant pathological information, and their\nlack of interpretability limits clinical adoption.\n  In this paper, we propose PATH-X, a framework that integrates Vision\nTransformers (ViT) and Autoencoders with SHAP (Shapley Additive Explanations)\nto enhance model explainability for patient stratification and risk prediction\nusing WSIs from The Cancer Genome Atlas (TCGA). A representative image slice is\nselected from each WSI, and numerical feature embeddings are extracted using\nGoogle's pre-trained ViT. These features are then compressed via an autoencoder\nand used for unsupervised clustering and classification tasks. Kaplan-Meier\nsurvival analysis is applied to evaluate stratification into two and three risk\ngroups. SHAP is used to identify key contributing features, which are mapped\nonto histopathological slices to provide spatial context.\n  PATH-X demonstrates strong performance in breast and glioma cancers, where a\nsufficient number of WSIs enabled robust stratification. However, performance\nin lung cancer was limited due to data availability, emphasizing the need for\nlarger datasets to enhance model reliability and clinical applicability.", "published": "2025-04-07 05:48:42", "link": "http://arxiv.org/abs/2504.04749v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Two is Better than One: Efficient Ensemble Defense for Robust and Compact Models", "abstract": "Deep learning-based computer vision systems adopt complex and large\narchitectures to improve performance, yet they face challenges in deployment on\nresource-constrained mobile and edge devices. To address this issue, model\ncompression techniques such as pruning, quantization, and matrix factorization\nhave been proposed; however, these compressed models are often highly\nvulnerable to adversarial attacks. We introduce the \\textbf{Efficient Ensemble\nDefense (EED)} technique, which diversifies the compression of a single base\nmodel based on different pruning importance scores and enhances ensemble\ndiversity to achieve high adversarial robustness and resource efficiency. EED\ndynamically determines the number of necessary sub-models during the inference\nstage, minimizing unnecessary computations while maintaining high robustness.\nOn the CIFAR-10 and SVHN datasets, EED demonstrated state-of-the-art robustness\nperformance compared to existing adversarial pruning techniques, along with an\ninference speed improvement of up to 1.86 times. This proves that EED is a\npowerful defense solution in resource-constrained environments.", "published": "2025-04-07 05:41:35", "link": "http://arxiv.org/abs/2504.04747v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AnyArtisticGlyph: Multilingual Controllable Artistic Glyph Generation", "abstract": "Artistic Glyph Image Generation (AGIG) differs from current\ncreativity-focused generation models by offering finely controllable\ndeterministic generation. It transfers the style of a reference image to a\nsource while preserving its content. Although advanced and promising, current\nmethods may reveal flaws when scrutinizing synthesized image details, often\nproducing blurred or incorrect textures, posing a significant challenge. Hence,\nwe introduce AnyArtisticGlyph, a diffusion-based, multilingual controllable\nartistic glyph generation model. It includes a font fusion and embedding\nmodule, which generates latent features for detailed structure creation, and a\nvision-text fusion and embedding module that uses the CLIP model to encode\nreferences and blends them with transformation caption embeddings for seamless\nglobal image generation. Moreover, we incorporate a coarse-grained\nfeature-level loss to enhance generation accuracy. Experiments show that it\nproduces natural, detailed artistic glyph images with state-of-the-art\nperformance. Our project will be open-sourced on\nhttps://github.com/jiean001/AnyArtisticGlyph to advance text generation\ntechnology.", "published": "2025-04-07 05:37:39", "link": "http://arxiv.org/abs/2504.04743v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Inverse++: Vision-Centric 3D Semantic Occupancy Prediction Assisted with 3D Object Detection", "abstract": "3D semantic occupancy prediction aims to forecast detailed geometric and\nsemantic information of the surrounding environment for autonomous vehicles\n(AVs) using onboard surround-view cameras. Existing methods primarily focus on\nintricate inner structure module designs to improve model performance, such as\nefficient feature sampling and aggregation processes or intermediate feature\nrepresentation formats. In this paper, we explore multitask learning by\nintroducing an additional 3D supervision signal by incorporating an additional\n3D object detection auxiliary branch. This extra 3D supervision signal enhances\nthe model's overall performance by strengthening the capability of the\nintermediate features to capture small dynamic objects in the scene, and these\nsmall dynamic objects often include vulnerable road users, i.e. bicycles,\nmotorcycles, and pedestrians, whose detection is crucial for ensuring driving\nsafety in autonomous vehicles. Extensive experiments conducted on the nuScenes\ndatasets, including challenging rainy and nighttime scenarios, showcase that\nour approach attains state-of-the-art results, achieving an IoU score of 31.73%\nand a mIoU score of 20.91% and excels at detecting vulnerable road users (VRU).\nThe code will be made available at:https://github.com/DanielMing123/Inverse++", "published": "2025-04-07 05:08:22", "link": "http://arxiv.org/abs/2504.04732v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Exploring Kernel Transformations for Implicit Neural Representations", "abstract": "Implicit neural representations (INRs), which leverage neural networks to\nrepresent signals by mapping coordinates to their corresponding attributes,\nhave garnered significant attention. They are extensively utilized for image\nrepresentation, with pixel coordinates as input and pixel values as output. In\ncontrast to prior works focusing on investigating the effect of the model's\ninside components (activation function, for instance), this work pioneers the\nexploration of the effect of kernel transformation of input/output while\nkeeping the model itself unchanged. A byproduct of our findings is a simple yet\neffective method that combines scale and shift to significantly boost INR with\nnegligible computation overhead. Moreover, we present two perspectives, depth\nand normalization, to interpret the performance benefits caused by scale and\nshift transformation. Overall, our work provides a new avenue for future works\nto understand and improve INR through the lens of kernel transformation.", "published": "2025-04-07 04:43:50", "link": "http://arxiv.org/abs/2504.04728v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TactileNet: Bridging the Accessibility Gap with AI-Generated Tactile Graphics for Individuals with Vision Impairment", "abstract": "Tactile graphics are essential for providing access to visual information for\nthe 43 million people globally living with vision loss, as estimated by global\nprevalence data. However, traditional methods for creating these tactile\ngraphics are labor-intensive and struggle to meet demand. We introduce\nTactileNet, the first comprehensive dataset and AI-driven framework for\ngenerating tactile graphics using text-to-image Stable Diffusion (SD) models.\nBy integrating Low-Rank Adaptation (LoRA) and DreamBooth, our method fine-tunes\nSD models to produce high-fidelity, guideline-compliant tactile graphics while\nreducing computational costs. Evaluations involving tactile experts show that\ngenerated graphics achieve 92.86% adherence to tactile standards and 100%\nalignment with natural images in posture and features. Our framework also\ndemonstrates scalability, generating 32,000 images (7,050 filtered for quality)\nacross 66 classes, with prompt editing enabling customizable outputs (e.g.,\nadding/removing details). Our work empowers designers to focus on refinement,\nsignificantly accelerating accessibility efforts. It underscores the\ntransformative potential of AI for social good, offering a scalable solution to\nbridge the accessibility gap in education and beyond.", "published": "2025-04-07 04:21:31", "link": "http://arxiv.org/abs/2504.04722v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "On the Robustness of GUI Grounding Models Against Image Attacks", "abstract": "Graphical User Interface (GUI) grounding models are crucial for enabling\nintelligent agents to understand and interact with complex visual interfaces.\nHowever, these models face significant robustness challenges in real-world\nscenarios due to natural noise and adversarial perturbations, and their\nrobustness remains underexplored. In this study, we systematically evaluate the\nrobustness of state-of-the-art GUI grounding models, such as UGround, under\nthree conditions: natural noise, untargeted adversarial attacks, and targeted\nadversarial attacks. Our experiments, which were conducted across a wide range\nof GUI environments, including mobile, desktop, and web interfaces, have\nclearly demonstrated that GUI grounding models exhibit a high degree of\nsensitivity to adversarial perturbations and low-resolution conditions. These\nfindings provide valuable insights into the vulnerabilities of GUI grounding\nmodels and establish a strong benchmark for future research aimed at enhancing\ntheir robustness in practical applications. Our code is available at\nhttps://github.com/ZZZhr-1/Robust_GUI_Grounding.", "published": "2025-04-07 03:58:45", "link": "http://arxiv.org/abs/2504.04716v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SapiensID: Foundation for Human Recognition", "abstract": "Existing human recognition systems often rely on separate, specialized models\nfor face and body analysis, limiting their effectiveness in real-world\nscenarios where pose, visibility, and context vary widely. This paper\nintroduces SapiensID, a unified model that bridges this gap, achieving robust\nperformance across diverse settings. SapiensID introduces (i) Retina Patch\n(RP), a dynamic patch generation scheme that adapts to subject scale and\nensures consistent tokenization of regions of interest, (ii) a masked\nrecognition model (MRM) that learns from variable token length, and (iii)\nSemantic Attention Head (SAH), an module that learns pose-invariant\nrepresentations by pooling features around key body parts. To facilitate\ntraining, we introduce WebBody4M, a large-scale dataset capturing diverse poses\nand scale variations. Extensive experiments demonstrate that SapiensID achieves\nstate-of-the-art results on various body ReID benchmarks, outperforming\nspecialized models in both short-term and long-term scenarios while remaining\ncompetitive with dedicated face recognition systems. Furthermore, SapiensID\nestablishes a strong baseline for the newly introduced challenge of Cross\nPose-Scale ReID, demonstrating its ability to generalize to complex, real-world\nconditions.", "published": "2025-04-07 03:38:07", "link": "http://arxiv.org/abs/2504.04708v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DFormerv2: Geometry Self-Attention for RGBD Semantic Segmentation", "abstract": "Recent advances in scene understanding benefit a lot from depth maps because\nof the 3D geometry information, especially in complex conditions (e.g., low\nlight and overexposed). Existing approaches encode depth maps along with RGB\nimages and perform feature fusion between them to enable more robust\npredictions. Taking into account that depth can be regarded as a geometry\nsupplement for RGB images, a straightforward question arises: Do we really need\nto explicitly encode depth information with neural networks as done for RGB\nimages? Based on this insight, in this paper, we investigate a new way to learn\nRGBD feature representations and present DFormerv2, a strong RGBD encoder that\nexplicitly uses depth maps as geometry priors rather than encoding depth\ninformation with neural networks. Our goal is to extract the geometry clues\nfrom the depth and spatial distances among all the image patch tokens, which\nwill then be used as geometry priors to allocate attention weights in\nself-attention. Extensive experiments demonstrate that DFormerv2 exhibits\nexceptional performance in various RGBD semantic segmentation benchmarks. Code\nis available at: https://github.com/VCIP-RGBD/DFormer.", "published": "2025-04-07 03:06:07", "link": "http://arxiv.org/abs/2504.04701v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DeclutterNeRF: Generative-Free 3D Scene Recovery for Occlusion Removal", "abstract": "Recent novel view synthesis (NVS) techniques, including Neural Radiance\nFields (NeRF) and 3D Gaussian Splatting (3DGS) have greatly advanced 3D scene\nreconstruction with high-quality rendering and realistic detail recovery.\nEffectively removing occlusions while preserving scene details can further\nenhance the robustness and applicability of these techniques. However, existing\napproaches for object and occlusion removal predominantly rely on generative\npriors, which, despite filling the resulting holes, introduce new artifacts and\nblurriness. Moreover, existing benchmark datasets for evaluating occlusion\nremoval methods lack realistic complexity and viewpoint variations. To address\nthese issues, we introduce DeclutterSet, a novel dataset featuring diverse\nscenes with pronounced occlusions distributed across foreground, midground, and\nbackground, exhibiting substantial relative motion across viewpoints. We\nfurther introduce DeclutterNeRF, an occlusion removal method free from\ngenerative priors. DeclutterNeRF introduces joint multi-view optimization of\nlearnable camera parameters, occlusion annealing regularization, and employs an\nexplainable stochastic structural similarity loss, ensuring high-quality,\nartifact-free reconstructions from incomplete images. Experiments demonstrate\nthat DeclutterNeRF significantly outperforms state-of-the-art methods on our\nproposed DeclutterSet, establishing a strong baseline for future research.", "published": "2025-04-07 02:22:08", "link": "http://arxiv.org/abs/2504.04679v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Classification of ADHD and Healthy Children Using EEG Based Multi-Band Spatial Features Enhancement", "abstract": "Attention Deficit Hyperactivity Disorder (ADHD) is a common\nneurodevelopmental disorder in children, characterized by difficulties in\nattention, hyperactivity, and impulsivity. Early and accurate diagnosis of ADHD\nis critical for effective intervention and management. Electroencephalogram\n(EEG) signals have emerged as a non-invasive and efficient tool for ADHD\ndetection due to their high temporal resolution and ability to capture neural\ndynamics. In this study, we propose a method for classifying ADHD and healthy\nchildren using EEG data from the benchmark dataset. There were 61 children with\nADHD and 60 healthy children, both boys and girls, aged 7 to 12. The EEG\nsignals, recorded from 19 channels, were processed to extract Power Spectral\nDensity (PSD) and Spectral Entropy (SE) features across five frequency bands,\nresulting in a comprehensive 190-dimensional feature set. To evaluate the\nclassification performance, a Support Vector Machine (SVM) with the RBF kernel\ndemonstrated the best performance with a mean cross-validation accuracy of\n99.2\\% and a standard deviation of 0.0079, indicating high robustness and\nprecision. These results highlight the potential of spatial features in\nconjunction with machine learning for accurately classifying ADHD using EEG\ndata. This work contributes to developing non-invasive, data-driven tools for\nearly diagnosis and assessment of ADHD in children.", "published": "2025-04-07 01:19:14", "link": "http://arxiv.org/abs/2504.04664v1", "categories": ["eess.SP", "cs.CV"], "primary_category": "eess.SP"}
{"title": "3DM-WeConvene: Learned Image Compression with 3D Multi-Level Wavelet-Domain Convolution and Entropy Model", "abstract": "Learned image compression (LIC) has recently made significant progress,\nsurpassing traditional methods. However, most LIC approaches operate mainly in\nthe spatial domain and lack mechanisms for reducing frequency-domain\ncorrelations. To address this, we propose a novel framework that integrates\nlow-complexity 3D multi-level Discrete Wavelet Transform (DWT) into\nconvolutional layers and entropy coding, reducing both spatial and channel\ncorrelations to improve frequency selectivity and rate-distortion (R-D)\nperformance.\n  Our proposed 3D multi-level wavelet-domain convolution (3DM-WeConv) layer\nfirst applies 3D multi-level DWT (e.g., 5/3 and 9/7 wavelets from JPEG 2000) to\ntransform data into the wavelet domain. Then, different-sized convolutions are\napplied to different frequency subbands, followed by inverse 3D DWT to restore\nthe spatial domain. The 3DM-WeConv layer can be flexibly used within existing\nCNN-based LIC models.\n  We also introduce a 3D wavelet-domain channel-wise autoregressive entropy\nmodel (3DWeChARM), which performs slice-based entropy coding in the 3D DWT\ndomain. Low-frequency (LF) slices are encoded first to provide priors for\nhigh-frequency (HF) slices.\n  A two-step training strategy is adopted: first balancing LF and HF rates,\nthen fine-tuning with separate weights.\n  Extensive experiments demonstrate that our framework consistently outperforms\nstate-of-the-art CNN-based LIC methods in R-D performance and computational\ncomplexity, with larger gains for high-resolution images. On the Kodak, Tecnick\n100, and CLIC test sets, our method achieves BD-Rate reductions of -12.24%,\n-15.51%, and -12.97%, respectively, compared to H.266/VVC.", "published": "2025-04-07 01:11:50", "link": "http://arxiv.org/abs/2504.04658v1", "categories": ["cs.CV", "stat.AP"], "primary_category": "cs.CV"}
{"title": "Infinite precedence graphs for consistency verification in P-time event graphs", "abstract": "Precedence constraints are inequalities used to model time dependencies. In\n1958, Gallai proved that a finite system of precedence constraints admits\nsolutions if and only if the corresponding precedence graph does not contain\npositive-weight circuits. We show that this result extends naturally to the\ncase of infinitely many constraints. We then analyze two specific classes of\ninfinite precedence graphs -- $\\mathbb{N}$-periodic and ultimately periodic\ngraphs -- and prove that the existence of solutions of their related\nconstraints can be verified in strongly polynomial time. The obtained\nalgorithms find applications in P-time event graphs, which are a subclass of\nP-time Petri nets able to model production systems under cyclic schedules where\ntasks need to be performed within given time windows.", "published": "2025-04-07 13:26:23", "link": "http://arxiv.org/abs/2504.05056v1", "categories": ["eess.SY", "cs.DM", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Outerplanar and bounded treewidth support for hypergraphs", "abstract": "We study the existence and construction of sparse supports for hypergraphs\nderived from subgraphs of a graph $G$. For a hypergraph $(X,\\mathcal{H})$, a\nsupport $Q$ is a graph on $X$ s.t. $Q[H]$, the graph induced on vertices in $H$\nis connected for every $H\\in\\mathcal{H}$.\n  We consider \\emph{primal}, \\emph{dual}, and \\emph{intersection} hypergraphs\ndefined by subgraphs of a graph $G$ that are \\emph{non-piercing}, (i.e., each\nsubgraph is connected, their pairwise differences remain connected).\n  If $G$ is outerplanar, we show that the primal, dual and intersection\nhypergraphs admit supports that are outerplanar. For a bounded treewidth graph\n$G$, we show that if the subgraphs are non-piercing, then there exist supports\nfor the primal and dual hypergraphs of treewidth $O(2^{tw(G)})$ and\n$O(2^{4tw(G)})$ respectively, and a support of treewidth $2^{O(2^{tw(G)})}$ for\nthe intersection hypergraph. We also show that for the primal and dual\nhypergraphs, the exponential blow-up of treewidth is sometimes essential.\n  All our results are algorithmic and yield polynomial-time algorithms (when\nthe treewidth is bounded). The existence and construction of sparse supports is\na crucial step in the design and analysis of PTASs and/or sub-exponential time\nalgorithms for several packing and covering problems.", "published": "2025-04-07 13:04:30", "link": "http://arxiv.org/abs/2504.05039v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "The Minimum Eternal Vertex Cover Problem on a Subclass of Series-Parallel Graphs", "abstract": "Eternal vertex cover is the following two-player game between a defender and\nan attacker on a graph. Initially, the defender positions k guards on k\nvertices of the graph; the game then proceeds in turns between the defender and\nthe attacker, with the attacker selecting an edge and the defender responding\nto the attack by moving some of the guards along the edges, including the\nattacked one. The defender wins a game on a graph G with k guards if they have\na strategy such that, in every round of the game, the vertices occupied by the\nguards form a vertex cover of G, and the attacker wins otherwise. The eternal\nvertex cover number of a graph G is the smallest number k of guards allowing\nthe defender to win and Eternal Vertex Cover is the problem of computing the\neternal vertex cover number of the given graph.\n  We study this problem when restricted to the well-known class of\nseries-parallel graphs. In particular, we prove that Eternal Vertex Cover can\nbe solved in linear time when restricted to melon graphs, a proper subclass of\nseries-parallel graphs. Moreover, we also conjecture that this problem is\nNP-hard on series-parallel graphs.", "published": "2025-04-07 10:12:09", "link": "http://arxiv.org/abs/2504.04897v1", "categories": ["math.CO", "cs.CC", "cs.DM", "cs.DS", "05C85, 68R10", "G.2.2"], "primary_category": "math.CO"}
{"title": "Strengthening Wilf's lower bound on clique number", "abstract": "Given an integer $k$, deciding whether a graph has a clique of size $k$ is an\nNP-complete problem. Wilf's inequality provides a spectral bound for the clique\nnumber of simple graphs. Wilf's inequality is stated as follows: $\\frac{n}{n -\n\\lambda_{1}} \\leq \\omega$, where $\\lambda_1$ is the largest eigenvalue of the\nadjacency matrix $A(G)$, $n$ is the number of vertices in $G$, and $\\omega$ is\nthe clique number of $G$. Strengthening this bound, Elphick and Wocjan proposed\na conjecture in 2018, which is stated as follows: $\\frac{n}{n - \\sqrt{s^{+}}}\n\\leq \\omega$, where $s^+ = \\sum_{\\lambda_{i} > 0} \\lambda_{i}^2$ and\n$\\lambda_i$ are the eigenvalues of $A(G)$. In this paper, we have settled this\nconjecture for some classes of graphs, such as conference graphs, strongly\nregular graphs with $\\lambda = \\mu$ (i.e., $srg(n, d, \\mu, \\mu)$) and $n\\geq\n2d$, the line graph of $K_{n}$, the Cartesian product of strongly regular\ngraphs, and Ramanujan graph with $n\\geq 11d$.", "published": "2025-04-07 08:46:55", "link": "http://arxiv.org/abs/2504.04836v1", "categories": ["cs.DM", "math.CO", "05C50, 05C69, 05C76, 05C48"], "primary_category": "cs.DM"}
{"title": "LLM-Alignment Live-Streaming Recommendation", "abstract": "In recent years, integrated short-video and live-streaming platforms have\ngained massive global adoption, offering dynamic content creation and\nconsumption. Unlike pre-recorded short videos, live-streaming enables real-time\ninteraction between authors and users, fostering deeper engagement. However,\nthis dynamic nature introduces a critical challenge for recommendation systems\n(RecSys): the same live-streaming vastly different experiences depending on\nwhen a user watching. To optimize recommendations, a RecSys must accurately\ninterpret the real-time semantics of live content and align them with user\npreferences.", "published": "2025-04-07 16:04:00", "link": "http://arxiv.org/abs/2504.05217v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Blending Queries and Conversations: Understanding Tactics, Trust, Verification, and System Choice in Web Search and Chat Interactions", "abstract": "This paper presents a user study (N=22) where participants used an interface\ncombining Web Search and a Generative AI-Chat feature to solve health-related\ninformation tasks. We study how people behaved with the interface, why they\nbehaved in certain ways, and what the outcomes of these behaviours were. A\nthink-aloud protocol captured their thought processes during searches. Our\nfindings suggest that GenAI is neither a search panacea nor a major regression\ncompared to standard Web Search interfaces. Qualitative and quantitative\nanalyses identified 78 tactics across five categories and provided insight into\nhow and why different interface features were used. We find evidence that\npre-task confidence and trust both influenced which interface feature was used.\nIn both systems, but particularly when using the chat feature, trust was often\nmisplaced in favour of ease-of-use and seemingly perfect answers, leading to\nincreased confidence post-search despite having incorrect results. We discuss\nwhat our findings mean in the context of our defined research questions and\noutline several open questions for future research.", "published": "2025-04-07 14:59:55", "link": "http://arxiv.org/abs/2504.05156v1", "categories": ["cs.HC", "cs.IR"], "primary_category": "cs.HC"}
{"title": "Query Smarter, Trust Better? Exploring Search Behaviours for Verifying News Accuracy", "abstract": "While it is often assumed that searching for information to evaluate\nmisinformation will help identify false claims, recent work suggests that\nsearch behaviours can instead reinforce belief in misleading news, particularly\nwhen users generate queries using vocabulary from the source articles. Our\nresearch explores how different query generation strategies affect news\nverification and whether the way people search influences the accuracy of their\ninformation evaluation. A mixed-methods approach was used, consisting of three\nparts: (1) an analysis of existing data to understand how search behaviour\ninfluences trust in fake news, (2) a simulation of query generation strategies\nusing a Large Language Model (LLM) to assess the impact of different query\nformulations on search result quality, and (3) a user study to examine how\n'Boost' interventions in interface design can guide users to adopt more\neffective query strategies. The results show that search behaviour\nsignificantly affects trust in news, with successful searches involving\nmultiple queries and yielding higher-quality results. Queries inspired by\ndifferent parts of a news article produced search results of varying quality,\nand weak initial queries improved when reformulated using full SERP\ninformation. Although 'Boost' interventions had limited impact, the study\nsuggests that interface design encouraging users to thoroughly review search\nresults can enhance query formulation. This study highlights the importance of\nquery strategies in evaluating news and proposes that interface design can play\na key role in promoting more effective search practices, serving as one\ncomponent of a broader set of interventions to combat misinformation.", "published": "2025-04-07 14:50:13", "link": "http://arxiv.org/abs/2504.05146v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Deconstructing Jazz Piano Style Using Machine Learning", "abstract": "Artistic style has been studied for centuries, and recent advances in machine\nlearning create new possibilities for understanding it computationally.\nHowever, ensuring that machine-learning models produce insights aligned with\nthe interests of practitioners and critics remains a significant challenge.\nHere, we focus on musical style, which benefits from a rich theoretical and\nmathematical analysis tradition. We train a variety of supervised-learning\nmodels to identify 20 iconic jazz musicians across a carefully curated dataset\nof 84 hours of recordings, and interpret their decision-making processes. Our\nmodels include a novel multi-input architecture that enables four musical\ndomains (melody, harmony, rhythm, and dynamics) to be analysed separately.\nThese models enable us to address fundamental questions in music theory and\nalso advance the state-of-the-art in music performer identification (94%\naccuracy across 20 classes). We release open-source implementations of our\nmodels and an accompanying web application for exploring musical styles.", "published": "2025-04-07 12:37:39", "link": "http://arxiv.org/abs/2504.05009v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Data Augmentation as Free Lunch: Exploring the Test-Time Augmentation for Sequential Recommendation", "abstract": "Data augmentation has become a promising method of mitigating data sparsity\nin sequential recommendation. Existing methods generate new yet effective data\nduring model training to improve performance. However, deploying them requires\nretraining, architecture modification, or introducing additional learnable\nparameters. The above steps are time-consuming and costly for well-trained\nmodels, especially when the model scale becomes large. In this work, we explore\nthe test-time augmentation (TTA) for sequential recommendation, which augments\nthe inputs during the model inference and then aggregates the model's\npredictions for augmented data to improve final accuracy. It avoids significant\ntime and cost overhead from loss calculation and backward propagation. We first\nexperimentally disclose the potential of existing augmentation operators for\nTTA and find that the Mask and Substitute consistently achieve better\nperformance. Further analysis reveals that these two operators are effective\nbecause they retain the original sequential pattern while adding appropriate\nperturbations. Meanwhile, we argue that these two operators still face\ntime-consuming item selection or interference information from mask tokens.\nBased on the analysis and limitations, we present TNoise and TMask. The former\ninjects uniform noise into the original representation, avoiding the\ncomputational overhead of item selection. The latter blocks mask token from\nparticipating in model calculations or directly removes interactions that\nshould have been replaced with mask tokens. Comprehensive experiments\ndemonstrate the effectiveness, efficiency, and generalizability of our method.\nWe provide an anonymous implementation at https://github.com/KingGugu/TTA4SR.", "published": "2025-04-07 08:56:16", "link": "http://arxiv.org/abs/2504.04843v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Investigating Popularity Bias Amplification in Recommender Systems Employed in the Entertainment Domain", "abstract": "Recommender systems have become an integral part of our daily online\nexperience by analyzing past user behavior to suggest relevant content in\nentertainment domains such as music, movies, and books. Today, they are among\nthe most widely used applications of AI and machine learning. Consequently,\nregulations and guidelines for trustworthy AI, such as the European AI Act,\nwhich addresses issues like bias and fairness, are highly relevant to the\ndesign, development, and evaluation of recommender systems. One particularly\nimportant type of bias in this context is popularity bias, which results in the\nunfair underrepresentation of less popular content in recommendation lists.\nThis work summarizes our research on investigating the amplification of\npopularity bias in recommender systems within the entertainment sector.\nAnalyzing datasets from three entertainment domains, music, movies, and anime,\nwe demonstrate that an item's recommendation frequency is positively correlated\nwith its popularity. As a result, user groups with little interest in popular\ncontent receive less accurate recommendations compared to those who prefer\nwidely popular items. Furthermore, we aim to better understand the connection\nbetween recommendation accuracy, calibration quality of algorithms, and\npopularity bias amplification.", "published": "2025-04-07 05:58:01", "link": "http://arxiv.org/abs/2504.04752v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Can LLM-Driven Hard Negative Sampling Empower Collaborative Filtering? Findings and Potentials", "abstract": "Hard negative samples can accelerate model convergence and optimize decision\nboundaries, which is key to improving the performance of recommender systems.\nAlthough large language models (LLMs) possess strong semantic understanding and\ngeneration capabilities, systematic research has not yet been conducted on how\nto generate hard negative samples effectively. To fill this gap, this paper\nintroduces the concept of Semantic Negative Sampling and exploreshow to\noptimize LLMs for high-quality, hard negative sampling. Specifically, we design\nan experimental pipeline that includes three main modules, profile generation,\nsemantic negative sampling, and semantic alignment, to verify the potential of\nLLM-driven hard negative sampling in enhancing the accuracy of collaborative\nfiltering (CF). Experimental results indicate that hard negative samples\ngenerated based on LLMs, when semantically aligned and integrated into CF, can\nsignificantly improve CF performance, although there is still a certain gap\ncompared to traditional negative sampling methods. Further analysis reveals\nthat this gap primarily arises from two major challenges: noisy samples and\nlack of behavioral constraints. To address these challenges, we propose a\nframework called HNLMRec, based on fine-tuning LLMs supervised by collaborative\nsignals. Experimental results show that this framework outperforms traditional\nnegative sampling and other LLM-driven recommendation methods across multiple\ndatasets, providing new solutions for empowering traditional RS with LLMs.\nAdditionally, we validate the excellent generalization ability of the LLM-based\nsemantic negative sampling method on new datasets, demonstrating its potential\nin alleviating issues such as data sparsity, popularity bias, and the problem\nof false hard negative samples. Our implementation code is available at\nhttps://github.com/user683/HNLMRec.", "published": "2025-04-07 04:39:45", "link": "http://arxiv.org/abs/2504.04726v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "TC-MGC: Text-Conditioned Multi-Grained Contrastive Learning for Text-Video Retrieval", "abstract": "Motivated by the success of coarse-grained or fine-grained contrast in\ntext-video retrieval, there emerge multi-grained contrastive learning methods\nwhich focus on the integration of contrasts with different granularity.\nHowever, due to the wider semantic range of videos, the text-agnostic video\nrepresentations might encode misleading information not described in texts,\nthus impeding the model from capturing precise cross-modal semantic\ncorrespondence. To this end, we propose a Text-Conditioned Multi-Grained\nContrast framework, dubbed TC-MGC. Specifically, our model employs a\nlanguage-video attention block to generate aggregated frame and video\nrepresentations conditioned on the word's and text's attention weights over\nframes. To filter unnecessary similarity interactions and decrease trainable\nparameters in the Interactive Similarity Aggregation (ISA) module, we design a\nSimilarity Reorganization (SR) module to identify attentive similarities and\nreorganize cross-modal similarity vectors and matrices. Next, we argue that the\nimbalance problem among multigrained similarities may result in over- and\nunder-representation issues. We thereby introduce an auxiliary Similarity\nDecorrelation Regularization (SDR) loss to facilitate cooperative relationship\nutilization by similarity variance minimization on matching text-video pairs.\nFinally, we present a Linear Softmax Aggregation (LSA) module to explicitly\nencourage the interactions between multiple similarities and promote the usage\nof multi-grained information. Empirically, TC-MGC achieves competitive results\non multiple text-video retrieval benchmarks, outperforming X-CLIP model by\n+2.8% (+1.3%), +2.2% (+1.0%), +1.5% (+0.9%) relative (absolute) improvements in\ntext-to-video retrieval R@1 on MSR-VTT, DiDeMo and VATEX, respectively. Our\ncode is publicly available at https://github.com/JingXiaolun/TC-MGC.", "published": "2025-04-07 03:33:14", "link": "http://arxiv.org/abs/2504.04707v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Cellular Network Design for UAV Corridors via Data-driven High-dimensional Bayesian Optimization", "abstract": "We address the challenge of designing cellular networks for uncrewed aerial\nvehicles (UAVs) corridors through a novel data-driven approach. We assess\nmultiple state-of-the-art high-dimensional Bayesian optimization (HD-BO)\ntechniques to jointly optimize the cell antenna tilts and half-power beamwidth\n(HPBW). We find that some of these approaches achieve over 20dB gains in median\nSINR along UAV corridors, with negligible degradation to ground user\nperformance. Furthermore, we explore the HD-BO's capabilities in terms of model\ngeneralization via transfer learning, where data from a previously observed\nscenario source is leveraged to predict the optimal solution for a new scenario\ntarget. We provide examples of scenarios where such transfer learning is\nsuccessful and others where it fails. Moreover, we demonstrate that HD-BO\nenables multi-objective optimization, identifying optimal design trade-offs\nbetween data rates on the ground versus UAV coverage reliability. We observe\nthat aiming to provide UAV coverage across the entire sky can lower the rates\nfor ground users compared to setups specifically optimized for UAV corridors.\nFinally, we validate our approach through a case study in a real-world cellular\nnetwork, where HD-BO identifies optimal and non-obvious antenna configurations\nthat result in more than double the rates along 3D UAV corridors with\nnegligible ground performance loss.", "published": "2025-04-07 15:20:14", "link": "http://arxiv.org/abs/2504.05176v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Using AI to Help in the Semantic Lexical Database to Evaluate Ideas", "abstract": "Inside a challenge of ideas there are several phases in a Creative Support\nSystem (CSS), they are problem analysis, ideation, evaluation, and\nimplementation. Our problem: we need a full semantic lexical database SLD in an\noral (voice) and writing way to help stakeholders to create ideas, these ideas\ncontain nouns, verbs, adverbs, adjectives in the English, Spanish, and French\nlanguages. We utilize a Cloud Service Provider to use a service of Artificial\nIntelligence (AI), also we prepare nouns, verbs, adjectives and adverbs files\nin order to create the service text to voice and create our SLD with voice.\nThis paper presents, first, an introduction about some contests that use a\nsemantic lexical database in different languages; second, a SLD management\napproach using analysis of texts; third, a management application approach to\ncomplete all the new elements; fourth, the results of the management\napplication approach, finally the conclusions and future work.", "published": "2025-04-07 11:54:06", "link": "http://arxiv.org/abs/2504.04967v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Feature Importance-Aware Deep Joint Source-Channel Coding for Computationally Efficient and Adjustable Image Transmission", "abstract": "Recent advancements in deep learning-based joint source-channel coding\n(deepJSCC) have significantly improved communication performance, but their\nhigh computational demands restrict practical deployment. Furthermore, some\napplications require the adaptive adjustment of computational complexity. To\naddress these challenges, we propose a computationally efficient and adjustable\ndeepJSCC model for image transmission, which we call feature importance-aware\ndeepJSCC (FAJSCC). Unlike existing deepJSCC models that equally process all\nneural features of images, FAJSCC first classifies features into important and\nless important features and then processes them differently. Specifically,\ncomputationally-intensive self-attention is applied to the important features\nand computationally-efficient spatial attention to the less important ones. The\nfeature classification is based on the available computational budget and\nimportance scores predicted by an importance predictor, which estimates each\nfeature's contribution to performance. It also allows independent adjustment of\nencoder and decoder complexity within a single trained model. With these\nproperties, our FAJSCC is the first deepJSCC that is computationally efficient\nand adjustable while maintaining high performance. Experiments demonstrate that\nour FAJSCC achieves higher image transmission performance across various\nchannel conditions while using less computational complexity than the recent\nstate-of-the-art models. Adding to this, by separately varying the\ncomputational resources of the encoder and decoder, it is concluded that the\ndecoder's error correction function requires the largest computational\ncomplexity in FAJSCC, which is the first observation in deepJSCC literature.\nThe FAJSCC code is publicly available at\nhttps://github.com/hansung-choi/FAJSCC.", "published": "2025-04-07 06:11:39", "link": "http://arxiv.org/abs/2504.04758v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Grant-Free Random Access in Uplink LEO Satellite Communications with OFDM", "abstract": "This paper investigates joint device activity detection and channel\nestimation for grant-free random access in Low-earth orbit (LEO) satellite\ncommunications. We consider uplink communications from multiple single-antenna\nterrestrial users to a LEO satellite equipped with a uniform planar array of\nmultiple antennas, where orthogonal frequency division multiplexing (OFDM)\nmodulation is adopted. To combat the severe Doppler shift, a transmission\nscheme is proposed, where the discrete prolate spheroidal basis expansion model\n(DPS-BEM) is introduced to reduce the number of unknown channel parameters.\nThen the vector approximate message passing (VAMP) algorithm is employed to\napproximate the minimum mean square error estimation of the channel, and the\nMarkov random field is combined to capture the channel sparsity. Meanwhile, the\nexpectation-maximization (EM) approach is integrated to learn the\nhyperparameters in priors. Finally, active devices are detected by calculating\nenergy of the estimated channel. Simulation results demonstrate that the\nproposed method outperforms conventional algorithms in terms of activity error\nrate and channel estimation precision.", "published": "2025-04-07 02:35:46", "link": "http://arxiv.org/abs/2504.04686v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Dimension-Free Convergence of Diffusion Models for Approximate Gaussian Mixtures", "abstract": "Diffusion models are distinguished by their exceptional generative\nperformance, particularly in producing high-quality samples through iterative\ndenoising. While current theory suggests that the number of denoising steps\nrequired for accurate sample generation should scale linearly with data\ndimension, this does not reflect the practical efficiency of widely used\nalgorithms like Denoising Diffusion Probabilistic Models (DDPMs). This paper\ninvestigates the effectiveness of diffusion models in sampling from complex\nhigh-dimensional distributions that can be well-approximated by Gaussian\nMixture Models (GMMs). For these distributions, our main result shows that DDPM\ntakes at most $\\widetilde{O}(1/\\varepsilon)$ iterations to attain an\n$\\varepsilon$-accurate distribution in total variation (TV) distance,\nindependent of both the ambient dimension $d$ and the number of components $K$,\nup to logarithmic factors. Furthermore, this result remains robust to score\nestimation errors. These findings highlight the remarkable effectiveness of\ndiffusion models in high-dimensional settings given the universal approximation\ncapability of GMMs, and provide theoretical insights into their practical\nsuccess.", "published": "2025-04-07 17:59:07", "link": "http://arxiv.org/abs/2504.05300v1", "categories": ["cs.LG", "cs.NA", "math.NA", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Covariant Gradient Descent", "abstract": "We present a manifestly covariant formulation of the gradient descent method,\nensuring consistency across arbitrary coordinate systems and general curved\ntrainable spaces. The optimization dynamics is defined using a covariant force\nvector and a covariant metric tensor, both computed from the first and second\nstatistical moments of the gradients. These moments are estimated through\ntime-averaging with an exponential weight function, which preserves linear\ncomputational complexity. We show that commonly used optimization methods such\nas RMSProp and Adam correspond to special limits of the covariant gradient\ndescent (CGD) and demonstrate how these methods can be further generalized and\nimproved.", "published": "2025-04-07 17:25:50", "link": "http://arxiv.org/abs/2504.05279v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Aggregating time-series and image data: functors and double functors", "abstract": "Aggregation of time-series or image data over subsets of the domain is a\nfundamental task in data science. We show that many known aggregation\noperations can be interpreted as (double) functors on appropriate (double)\ncategories. Such functorial aggregations are amenable to parallel\nimplementation via straightforward extensions of Blelloch's parallel scan\nalgorithm. In addition to providing a unified viewpoint on existing operations,\nit allows us to propose new aggregation operations for time-series and image\ndata.", "published": "2025-04-07 17:12:20", "link": "http://arxiv.org/abs/2504.05274v1", "categories": ["math.CT", "cs.LG", "18D05 68W10"], "primary_category": "math.CT"}
{"title": "PEAKS: Selecting Key Training Examples Incrementally via Prediction Error Anchored by Kernel Similarity", "abstract": "As deep learning continues to be driven by ever-larger datasets,\nunderstanding which examples are most important for generalization has become a\ncritical question. While progress in data selection continues, emerging\napplications require studying this problem in dynamic contexts. To bridge this\ngap, we pose the Incremental Data Selection (IDS) problem, where examples\narrive as a continuous stream, and need to be selected without access to the\nfull data source. In this setting, the learner must incrementally build a\ntraining dataset of predefined size while simultaneously learning the\nunderlying task. We find that in IDS, the impact of a new sample on the model\nstate depends fundamentally on both its geometric relationship in the feature\nspace and its prediction error. Leveraging this insight, we propose PEAKS\n(Prediction Error Anchored by Kernel Similarity), an efficient data selection\nmethod tailored for IDS. Our comprehensive evaluations demonstrate that PEAKS\nconsistently outperforms existing selection strategies. Furthermore, PEAKS\nyields increasingly better performance returns than random selection as\ntraining data size grows on real-world datasets.", "published": "2025-04-07 16:42:09", "link": "http://arxiv.org/abs/2504.05250v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Embedded Federated Feature Selection with Dynamic Sparse Training: Balancing Accuracy-Cost Tradeoffs", "abstract": "Federated Learning (FL) enables multiple resource-constrained edge devices\nwith varying levels of heterogeneity to collaboratively train a global model.\nHowever, devices with limited capacity can create bottlenecks and slow down\nmodel convergence. One effective approach to addressing this issue is to use an\nefficient feature selection method, which reduces overall resource demands by\nminimizing communication and computation costs, thereby mitigating the impact\nof struggling nodes. Existing federated feature selection (FFS) methods are\neither considered as a separate step from FL or rely on a third party. These\napproaches increase computation and communication overhead, making them\nimpractical for real-world high-dimensional datasets. To address this, we\npresent \\textit{Dynamic Sparse Federated Feature Selection} (DSFFS), the first\ninnovative embedded FFS that is efficient in both communication and\ncomputation. In the proposed method, feature selection occurs simultaneously\nwith model training. During training, input-layer neurons, their connections,\nand hidden-layer connections are dynamically pruned and regrown, eliminating\nuninformative features. This process enhances computational efficiency on\ndevices, improves network communication efficiency, and boosts global model\nperformance. Several experiments are conducted on nine real-world datasets of\nvarying dimensionality from diverse domains, including biology, image, speech,\nand text. The results under a realistic non-iid data distribution setting show\nthat our approach achieves a better trade-off between accuracy, computation,\nand communication costs by selecting more informative features compared to\nother state-of-the-art FFS methods.", "published": "2025-04-07 16:33:05", "link": "http://arxiv.org/abs/2504.05245v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "IAEmu: Learning Galaxy Intrinsic Alignment Correlations", "abstract": "The intrinsic alignments (IA) of galaxies, a key contaminant in weak lensing\nanalyses, arise from correlations in galaxy shapes driven by tidal interactions\nand galaxy formation processes. Accurate IA modeling is essential for robust\ncosmological inference, but current approaches rely on perturbative methods\nthat break down on nonlinear scales or on expensive simulations. We introduce\nIAEmu, a neural network-based emulator that predicts the galaxy\nposition-position ($\\xi$), position-orientation ($\\omega$), and\norientation-orientation ($\\eta$) correlation functions and their uncertainties\nusing mock catalogs based on the halo occupation distribution (HOD) framework.\nCompared to simulations, IAEmu achieves ~3% average error for $\\xi$ and ~5% for\n$\\omega$, while capturing the stochasticity of $\\eta$ without overfitting. The\nemulator provides both aleatoric and epistemic uncertainties, helping identify\nregions where predictions may be less reliable. We also demonstrate\ngeneralization to non-HOD alignment signals by fitting to IllustrisTNG\nhydrodynamical simulation data. As a fully differentiable neural network, IAEmu\nenables $\\sim$10,000$\\times$ speed-ups in mapping HOD parameters to correlation\nfunctions on GPUs, compared to CPU-based simulations. This acceleration\nfacilitates inverse modeling via gradient-based sampling, making IAEmu a\npowerful surrogate model for galaxy bias and IA studies with direct\napplications to Stage IV weak lensing surveys.", "published": "2025-04-07 16:19:50", "link": "http://arxiv.org/abs/2504.05235v1", "categories": ["astro-ph.CO", "astro-ph.GA", "cs.LG"], "primary_category": "astro-ph.CO"}
{"title": "Hybrid machine learning data assimilation for marine biogeochemistry", "abstract": "Marine biogeochemistry models are critical for forecasting, as well as\nestimating ecosystem responses to climate change and human activities. Data\nassimilation (DA) improves these models by aligning them with real-world\nobservations, but marine biogeochemistry DA faces challenges due to model\ncomplexity, strong nonlinearity, and sparse, uncertain observations. Existing\nDA methods applied to marine biogeochemistry struggle to update unobserved\nvariables effectively, while ensemble-based methods are computationally too\nexpensive for high-complexity marine biogeochemistry models. This study\ndemonstrates how machine learning (ML) can improve marine biogeochemistry DA by\nlearning statistical relationships between observed and unobserved variables.\nWe integrate ML-driven balancing schemes into a 1D prototype of a system used\nto forecast marine biogeochemistry in the North-West European Shelf seas. ML is\napplied to predict (i) state-dependent correlations from free-run ensembles and\n(ii), in an ``end-to-end'' fashion, analysis increments from an Ensemble Kalman\nFilter. Our results show that ML significantly enhances updates for previously\nnot-updated variables when compared to univariate schemes akin to those used\noperationally. Furthermore, ML models exhibit moderate transferability to new\nlocations, a crucial step toward scaling these methods to 3D operational\nsystems. We conclude that ML offers a clear pathway to overcome current\ncomputational bottlenecks in marine biogeochemistry DA and that refining\ntransferability, optimizing training data sampling, and evaluating scalability\nfor large-scale marine forecasting, should be future research priorities.", "published": "2025-04-07 16:04:10", "link": "http://arxiv.org/abs/2504.05218v1", "categories": ["physics.ao-ph", "cs.LG"], "primary_category": "physics.ao-ph"}
{"title": "Learning symmetries in datasets", "abstract": "We investigate how symmetries present in datasets affect the structure of the\nlatent space learned by Variational Autoencoders (VAEs). By training VAEs on\ndata originating from simple mechanical systems and particle collisions, we\nanalyze the organization of the latent space through a relevance measure that\nidentifies the most meaningful latent directions. We show that when symmetries\nor approximate symmetries are present, the VAE self-organizes its latent space,\neffectively compressing the data along a reduced number of latent variables.\nThis behavior captures the intrinsic dimensionality determined by the symmetry\nconstraints and reveals hidden relations among the features. Furthermore, we\nprovide a theoretical analysis of a simple toy model, demonstrating how, under\nidealized conditions, the latent space aligns with the symmetry directions of\nthe data manifold. We illustrate these findings with examples ranging from\ntwo-dimensional datasets with $O(2)$ symmetry to realistic datasets from\nelectron-positron and proton-proton collisions. Our results highlight the\npotential of unsupervised generative models to expose underlying structures in\ndata and offer a novel approach to symmetry discovery without explicit\nsupervision.", "published": "2025-04-07 15:17:41", "link": "http://arxiv.org/abs/2504.05174v1", "categories": ["cs.LG", "hep-ph"], "primary_category": "cs.LG"}
{"title": "Machine learning interatomic potential can infer electrical response", "abstract": "Modeling the response of material and chemical systems to electric fields\nremains a longstanding challenge. Machine learning interatomic potentials\n(MLIPs) offer an efficient and scalable alternative to quantum mechanical\nmethods but do not by themselves incorporate electrical response. Here, we show\nthat polarization and Born effective charge (BEC) tensors can be directly\nextracted from long-range MLIPs within the Latent Ewald Summation (LES)\nframework, solely by learning from energy and force data. Using this approach,\nwe predict the infrared spectra of bulk water under zero or finite external\nelectric fields, ionic conductivities of high-pressure superionic ice, and the\nphase transition and hysteresis in ferroelectric PbTiO$_3$ perovskite. This\nwork thus extends the capability of MLIPs to predict electrical\nresponse--without training on charges or polarization or BECs--and enables\naccurate modeling of electric-field-driven processes in diverse systems at\nscale.", "published": "2025-04-07 15:14:07", "link": "http://arxiv.org/abs/2504.05169v1", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.chem-ph", "physics.comp-ph"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "DDPM Score Matching and Distribution Learning", "abstract": "Score estimation is the backbone of score-based generative models (SGMs),\nespecially denoising diffusion probabilistic models (DDPMs). A key result in\nthis area shows that with accurate score estimates, SGMs can efficiently\ngenerate samples from any realistic data distribution (Chen et al., ICLR'23;\nLee et al., ALT'23). This distribution learning result, where the learned\ndistribution is implicitly that of the sampler's output, does not explain how\nscore estimation relates to classical tasks of parameter and density\nestimation.\n  This paper introduces a framework that reduces score estimation to these two\ntasks, with various implications for statistical and computational learning\ntheory:\n  Parameter Estimation: Koehler et al. (ICLR'23) demonstrate that a\nscore-matching variant is statistically inefficient for the parametric\nestimation of multimodal densities common in practice. In contrast, we show\nthat under mild conditions, denoising score-matching in DDPMs is asymptotically\nefficient.\n  Density Estimation: By linking generation to score estimation, we lift\nexisting score estimation guarantees to $(\\epsilon,\\delta)$-PAC density\nestimation, i.e., a function approximating the target log-density within\n$\\epsilon$ on all but a $\\delta$-fraction of the space. We provide (i) minimax\nrates for density estimation over H\\\"older classes and (ii) a quasi-polynomial\nPAC density estimation algorithm for the classical Gaussian location mixture\nmodel, building on and addressing an open problem from Gatmiry et al.\n(arXiv'24).\n  Lower Bounds for Score Estimation: Our framework offers the first principled\nmethod to prove computational lower bounds for score estimation across general\ndistributions. As an application, we establish cryptographic lower bounds for\nscore estimation in general Gaussian mixture models, conceptually recovering\nSong's (NeurIPS'24) result and advancing his key open problem.", "published": "2025-04-07 15:07:19", "link": "http://arxiv.org/abs/2504.05161v1", "categories": ["stat.ML", "cs.DS", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "SparsyFed: Sparse Adaptive Federated Training", "abstract": "Sparse training is often adopted in cross-device federated learning (FL)\nenvironments where constrained devices collaboratively train a machine learning\nmodel on private data by exchanging pseudo-gradients across heterogeneous\nnetworks. Although sparse training methods can reduce communication overhead\nand computational burden in FL, they are often not used in practice for the\nfollowing key reasons: (1) data heterogeneity makes it harder for clients to\nreach consensus on sparse models compared to dense ones, requiring longer\ntraining; (2) methods for obtaining sparse masks lack adaptivity to accommodate\nvery heterogeneous data distributions, crucial in cross-device FL; and (3)\nadditional hyperparameters are required, which are notably challenging to tune\nin FL. This paper presents SparsyFed, a practical federated sparse training\nmethod that critically addresses the problems above. Previous works have only\nsolved one or two of these challenges at the expense of introducing new\ntrade-offs, such as clients' consensus on masks versus sparsity pattern\nadaptivity. We show that SparsyFed simultaneously (1) can produce 95% sparse\nmodels, with negligible degradation in accuracy, while only needing a single\nhyperparameter, (2) achieves a per-round weight regrowth 200 times smaller than\nprevious methods, and (3) allows the sparse masks to adapt to highly\nheterogeneous data distributions and outperform all baselines under such\nconditions.", "published": "2025-04-07 14:57:02", "link": "http://arxiv.org/abs/2504.05153v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Pr$\u03b5\u03b5$mpt: Sanitizing Sensitive Prompts for LLMs", "abstract": "The rise of large language models (LLMs) has introduced new privacy\nchallenges, particularly during inference where sensitive information in\nprompts may be exposed to proprietary LLM APIs. In this paper, we address the\nproblem of formally protecting the sensitive information contained in a prompt\nwhile maintaining response quality. To this end, first, we introduce a\ncryptographically inspired notion of a prompt sanitizer which transforms an\ninput prompt to protect its sensitive tokens. Second, we propose\nPr$\\epsilon\\epsilon$mpt, a novel system that implements a prompt sanitizer.\nPr$\\epsilon\\epsilon$mpt categorizes sensitive tokens into two types: (1) those\nwhere the LLM's response depends solely on the format (such as SSNs, credit\ncard numbers), for which we use format-preserving encryption (FPE); and (2)\nthose where the response depends on specific values, (such as age, salary) for\nwhich we apply metric differential privacy (mDP). Our evaluation demonstrates\nthat Pr$\\epsilon\\epsilon$mpt is a practical method to achieve meaningful\nprivacy guarantees, while maintaining high utility compared to unsanitized\nprompts, and outperforming prior methods", "published": "2025-04-07 14:52:40", "link": "http://arxiv.org/abs/2504.05147v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Online Cluster-Based Parameter Control for Metaheuristic", "abstract": "The concept of parameter setting is a crucial and significant process in\nmetaheuristics since it can majorly impact their performance. It is a highly\ncomplex and challenging procedure since it requires a deep understanding of the\noptimization algorithm and the optimization problem at hand. In recent years,\nthe upcoming rise of autonomous decision systems has attracted ongoing\nscientific interest in this direction, utilizing a considerable number of\nparameter-tuning methods. There are two types of methods: offline and online.\nOnline methods usually excel in complex real-world problems, as they can offer\ndynamic parameter control throughout the execution of the algorithm. The\npresent work proposes a general-purpose online parameter-tuning method called\nCluster-Based Parameter Adaptation (CPA) for population-based metaheuristics.\nThe main idea lies in the identification of promising areas within the\nparameter search space and in the generation of new parameters around these\nareas. The method's validity has been demonstrated using the differential\nevolution algorithm and verified in established test suites of low- and\nhigh-dimensional problems. The obtained results are statistically analyzed and\ncompared with state-of-the-art algorithms, including advanced auto-tuning\napproaches. The analysis reveals the promising solid CPA's performance as well\nas its robustness under a variety of benchmark problems and dimensions.", "published": "2025-04-07 14:48:30", "link": "http://arxiv.org/abs/2504.05144v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Unifying Physics- and Data-Driven Modeling via Novel Causal Spatiotemporal Graph Neural Network for Interpretable Epidemic Forecasting", "abstract": "Accurate epidemic forecasting is crucial for effective disease control and\nprevention. Traditional compartmental models often struggle to estimate\ntemporally and spatially varying epidemiological parameters, while deep\nlearning models typically overlook disease transmission dynamics and lack\ninterpretability in the epidemiological context. To address these limitations,\nwe propose a novel Causal Spatiotemporal Graph Neural Network (CSTGNN), a\nhybrid framework that integrates a Spatio-Contact SIR model with Graph Neural\nNetworks (GNNs) to capture the spatiotemporal propagation of epidemics.\nInter-regional human mobility exhibits continuous and smooth spatiotemporal\npatterns, leading to adjacent graph structures that share underlying mobility\ndynamics. To model these dynamics, we employ an adaptive static connectivity\ngraph to represent the stable components of human mobility and utilize a\ntemporal dynamics model to capture fluctuations within these patterns. By\nintegrating the adaptive static connectivity graph with the temporal dynamics\ngraph, we construct a dynamic graph that encapsulates the comprehensive\nproperties of human mobility networks. Additionally, to capture temporal trends\nand variations in infectious disease spread, we introduce a temporal\ndecomposition model to handle temporal dependence. This model is then\nintegrated with a dynamic graph convolutional network for epidemic forecasting.\nWe validate our model using real-world datasets at the provincial level in\nChina and the state level in Germany. Extensive studies demonstrate that our\nmethod effectively models the spatiotemporal dynamics of infectious diseases,\nproviding a valuable tool for forecasting and intervention strategies.\nFurthermore, analysis of the learned parameters offers insights into disease\ntransmission mechanisms, enhancing the interpretability and practical\napplicability of our model.", "published": "2025-04-07 14:46:11", "link": "http://arxiv.org/abs/2504.05140v1", "categories": ["cs.LG", "physics.soc-ph", "q-bio.QM", "stat.ML", "92D30, 68T07", "I.2.6; I.5.1"], "primary_category": "cs.LG"}
{"title": "Towards Optimal Heterogeneous Client Sampling in Multi-Model Federated Learning", "abstract": "Federated learning (FL) allows edge devices to collaboratively train models\nwithout sharing local data. As FL gains popularity, clients may need to train\nmultiple unrelated FL models, but communication constraints limit their ability\nto train all models simultaneously. While clients could train FL models\nsequentially, opportunistically having FL clients concurrently train different\nmodels -- termed multi-model federated learning (MMFL) -- can reduce the\noverall training time. Prior work uses simple client-to-model assignments that\ndo not optimize the contribution of each client to each model over the course\nof its training. Prior work on single-model FL shows that intelligent client\nselection can greatly accelerate convergence, but na\\\"ive extensions to MMFL\ncan violate heterogeneous resource constraints at both the server and the\nclients. In this work, we develop a novel convergence analysis of MMFL with\narbitrary client sampling methods, theoretically demonstrating the strengths\nand limitations of previous well-established gradient-based methods. Motivated\nby this analysis, we propose MMFL-LVR, a loss-based sampling method that\nminimizes training variance while explicitly respecting communication limits at\nthe server and reducing computational costs at the clients. We extend this to\nMMFL-StaleVR, which incorporates stale updates for improved efficiency and\nstability, and MMFL-StaleVRE, a lightweight variant suitable for low-overhead\ndeployment. Experiments show our methods improve average accuracy by up to\n19.1% over random sampling, with only a 5.4% gap from the theoretical optimum\n(full client participation).", "published": "2025-04-07 14:43:17", "link": "http://arxiv.org/abs/2504.05138v1", "categories": ["cs.LG", "cs.DC", "I.2.11"], "primary_category": "cs.LG"}
{"title": "AI-Driven Tactical Communications and Networking for Defense: A Survey and Emerging Trends", "abstract": "The integration of Artificial Intelligence (AI) in military communications\nand networking is reshaping modern defense strategies, enhancing secure data\nexchange, real-time situational awareness, and autonomous decision-making. This\nsurvey explores how AI-driven technologies improve tactical communication\nnetworks, radar-based data transmission, UAV-assisted relay systems, and\nelectronic warfare resilience. The study highlights AI applications in adaptive\nsignal processing, multi-agent coordination for network optimization,\nradar-assisted target tracking, and AI-driven electronic countermeasures. Our\nwork introduces a novel three-criteria evaluation methodology. It\nsystematically assesses AI applications based on general system objectives,\ncommunications constraints in the military domain, and critical tactical\nenvironmental factors. We analyze key AI techniques for different types of\nlearning applied to multi-domain network interoperability and distributed data\ninformation fusion in military operations. We also address challenges such as\nadversarial AI threats, the real-time adaptability of autonomous communication\nnetworks, and the limitations of current AI models under battlefield\nconditions. Finally, we discuss emerging trends in self-healing networks,\nAI-augmented decision support systems, and intelligent spectrum allocation. We\nprovide a structured roadmap for future AI-driven defense communications and\nnetworking research.", "published": "2025-04-07 13:38:32", "link": "http://arxiv.org/abs/2504.05071v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "MIAT: Maneuver-Intention-Aware Transformer for Spatio-Temporal Trajectory Prediction", "abstract": "Accurate vehicle trajectory prediction is critical for safe and efficient\nautonomous driving, especially in mixed traffic environments with both\nhuman-driven and autonomous vehicles. However, uncertainties introduced by\ninherent driving behaviors -- such as acceleration, deceleration, and left and\nright maneuvers -- pose significant challenges for reliable trajectory\nprediction. We introduce a Maneuver-Intention-Aware Transformer (MIAT)\narchitecture, which integrates a maneuver intention awareness mechanism with\nspatiotemporal interaction modeling to enhance long-horizon trajectory\npredictions. We systematically investigate the impact of varying awareness of\nmaneuver intention on both short- and long-horizon trajectory predictions.\nEvaluated on the real-world NGSIM dataset and benchmarked against various\ntransformer- and LSTM-based methods, our approach achieves an improvement of up\nto 4.7% in short-horizon predictions and a 1.6% in long-horizon predictions\ncompared to other intention-aware benchmark methods. Moreover, by leveraging an\nintention awareness control mechanism, MIAT realizes an 11.1% performance boost\nin long-horizon predictions, with a modest drop in short-horizon performance.", "published": "2025-04-07 13:30:00", "link": "http://arxiv.org/abs/2504.05059v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Attention-Augmented Inverse Reinforcement Learning with Graph Convolutions for Multi-Agent Task Allocation", "abstract": "Multi-agent task allocation (MATA) plays a vital role in cooperative\nmulti-agent systems, with significant implications for applications such as\nlogistics, search and rescue, and robotic coordination. Although traditional\ndeep reinforcement learning (DRL) methods have been shown to be promising,\ntheir effectiveness is hindered by a reliance on manually designed reward\nfunctions and inefficiencies in dynamic environments. In this paper, an inverse\nreinforcement learning (IRL)-based framework is proposed, in which multi-head\nself-attention (MHSA) and graph attention mechanisms are incorporated to\nenhance reward function learning and task execution efficiency. Expert\ndemonstrations are utilized to infer optimal reward densities, allowing\ndependence on handcrafted designs to be reduced and adaptability to be\nimproved. Extensive experiments validate the superiority of the proposed method\nover widely used multi-agent reinforcement learning (MARL) algorithms in terms\nof both cumulative rewards and task execution efficiency.", "published": "2025-04-07 13:14:45", "link": "http://arxiv.org/abs/2504.05045v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Multi-level Neural Networks for high-dimensional parametric obstacle problems", "abstract": "A new method to solve computationally challenging (random) parametric\nobstacle problems is developed and analyzed, where the parameters can influence\nthe related partial differential equation (PDE) and determine the position and\nsurface structure of the obstacle. As governing equation, a stationary elliptic\ndiffusion problem is assumed. The high-dimensional solution of the obstacle\nproblem is approximated by a specifically constructed convolutional neural\nnetwork (CNN). This novel algorithm is inspired by a finite element constrained\nmultigrid algorithm to represent the parameter to solution map. This has two\nbenefits: First, it allows for efficient practical computations since\nmulti-level data is used as an explicit output of the NN thanks to an\nappropriate data preprocessing. This improves the efficacy of the training\nprocess and subsequently leads to small errors in the natural energy norm.\nSecond, the comparison of the CNN to a multigrid algorithm provides means to\ncarry out a complete a priori convergence and complexity analysis of the\nproposed NN architecture. Numerical experiments illustrate a state-of-the-art\nperformance for this challenging problem.", "published": "2025-04-07 12:50:56", "link": "http://arxiv.org/abs/2504.05026v1", "categories": ["cs.LG", "cs.NA", "math.FA", "math.NA", "68T07, 68T09, 35J85", "I.2.0; I.5.2; I.5.4; G.1.8; F.1"], "primary_category": "cs.LG"}
{"title": "Concept Extraction for Time Series with ECLAD-ts", "abstract": "Convolutional neural networks (CNNs) for time series classification (TSC) are\nbeing increasingly used in applications ranging from quality prediction to\nmedical diagnosis. The black box nature of these models makes understanding\ntheir prediction process difficult. This issue is crucial because CNNs are\nprone to learning shortcuts and biases, compromising their robustness and\nalignment with human expectations. To assess whether such mechanisms are being\nused and the associated risk, it is essential to provide model explanations\nthat reflect the inner workings of the model. Concept Extraction (CE) methods\noffer such explanations, but have mostly been developed for the image domain so\nfar, leaving a gap in the time series domain. In this work, we present a CE and\nlocalization method tailored to the time series domain, based on the ideas of\nCE methods for images. We propose the novel method ECLAD-ts, which provides\npost-hoc global explanations based on how the models encode subsets of the\ninput at different levels of abstraction. For this, concepts are produced by\nclustering timestep-wise aggregations of CNN activation maps, and their\nimportance is computed based on their impact on the prediction process. We\nevaluate our method on synthetic and natural datasets. Furthermore, we assess\nthe advantages and limitations of CE in time series through empirical results.\nOur results show that ECLAD-ts effectively explains models by leveraging their\ninternal representations, providing useful insights about their prediction\nprocess.", "published": "2025-04-07 12:49:20", "link": "http://arxiv.org/abs/2504.05024v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Joint Pedestrian and Vehicle Traffic Optimization in Urban Environments using Reinforcement Learning", "abstract": "Reinforcement learning (RL) holds significant promise for adaptive traffic\nsignal control. While existing RL-based methods demonstrate effectiveness in\nreducing vehicular congestion, their predominant focus on vehicle-centric\noptimization leaves pedestrian mobility needs and safety challenges\nunaddressed. In this paper, we present a deep RL framework for adaptive control\nof eight traffic signals along a real-world urban corridor, jointly optimizing\nboth pedestrian and vehicular efficiency. Our single-agent policy is trained\nusing real-world pedestrian and vehicle demand data derived from Wi-Fi logs and\nvideo analysis. The results demonstrate significant performance improvements\nover traditional fixed-time signals, reducing average wait times per pedestrian\nand per vehicle by up to 67% and 52%, respectively, while simultaneously\ndecreasing total accumulated wait times for both groups by up to 67% and 53%.\nAdditionally, our results demonstrate generalization capabilities across\nvarying traffic demands, including conditions entirely unseen during training,\nvalidating RL's potential for developing transportation systems that serve all\nroad users.", "published": "2025-04-07 12:41:58", "link": "http://arxiv.org/abs/2504.05018v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Stacking Variational Bayesian Monte Carlo", "abstract": "Variational Bayesian Monte Carlo (VBMC) is a sample-efficient method for\napproximate Bayesian inference with computationally expensive likelihoods.\nWhile VBMC's local surrogate approach provides stable approximations, its\nconservative exploration strategy and limited evaluation budget can cause it to\nmiss regions of complex posteriors. In this work, we introduce Stacking\nVariational Bayesian Monte Carlo (S-VBMC), a method that constructs global\nposterior approximations by merging independent VBMC runs through a principled\nand inexpensive post-processing step. Our approach leverages VBMC's mixture\nposterior representation and per-component evidence estimates, requiring no\nadditional likelihood evaluations while being naturally parallelizable. We\ndemonstrate S-VBMC's effectiveness on two synthetic problems designed to\nchallenge VBMC's exploration capabilities and two real-world applications from\ncomputational neuroscience, showing substantial improvements in posterior\napproximation quality across all cases.", "published": "2025-04-07 12:30:59", "link": "http://arxiv.org/abs/2504.05004v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "A Unified Pairwise Framework for RLHF: Bridging Generative Reward Modeling and Policy Optimization", "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a important\nparadigm for aligning large language models (LLMs) with human preferences\nduring post-training. This framework typically involves two stages: first,\ntraining a reward model on human preference data, followed by optimizing the\nlanguage model using reinforcement learning algorithms. However, current RLHF\napproaches may constrained by two limitations. First, existing RLHF frameworks\noften rely on Bradley-Terry models to assign scalar rewards based on pairwise\ncomparisons of individual responses. However, this approach imposes significant\nchallenges on reward model (RM), as the inherent variability in prompt-response\npairs across different contexts demands robust calibration capabilities from\nthe RM. Second, reward models are typically initialized from generative\nfoundation models, such as pre-trained or supervised fine-tuned models, despite\nthe fact that reward models perform discriminative tasks, creating a mismatch.\nThis paper introduces Pairwise-RL, a RLHF framework that addresses these\nchallenges through a combination of generative reward modeling and a pairwise\nproximal policy optimization (PPO) algorithm. Pairwise-RL unifies reward model\ntraining and its application during reinforcement learning within a consistent\npairwise paradigm, leveraging generative modeling techniques to enhance reward\nmodel performance and score calibration. Experimental evaluations demonstrate\nthat Pairwise-RL outperforms traditional RLHF frameworks across both internal\nevaluation datasets and standard public benchmarks, underscoring its\neffectiveness in improving alignment and model behavior.", "published": "2025-04-07 11:34:48", "link": "http://arxiv.org/abs/2504.04950v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Constrained Gaussian Process Motion Planning via Stein Variational Newton Inference", "abstract": "Gaussian Process Motion Planning (GPMP) is a widely used framework for\ngenerating smooth trajectories within a limited compute time--an essential\nrequirement in many robotic applications. However, traditional GPMP approaches\noften struggle with enforcing hard nonlinear constraints and rely on Maximum a\nPosteriori (MAP) solutions that disregard the full Bayesian posterior. This\nlimits planning diversity and ultimately hampers decision-making. Recent\nefforts to integrate Stein Variational Gradient Descent (SVGD) into motion\nplanning have shown promise in handling complex constraints. Nonetheless, these\nmethods still face persistent challenges, such as difficulties in strictly\nenforcing constraints and inefficiencies when the probabilistic inference\nproblem is poorly conditioned. To address these issues, we propose a novel\nconstrained Stein Variational Gaussian Process Motion Planning (cSGPMP)\nframework, incorporating a GPMP prior specifically designed for trajectory\noptimization under hard constraints. Our approach improves the efficiency of\nparticle-based inference while explicitly handling nonlinear constraints. This\nadvancement significantly broadens the applicability of GPMP to motion planning\nscenarios demanding robust Bayesian inference, strict constraint adherence, and\ncomputational efficiency within a limited time. We validate our method on\nstandard benchmarks, achieving an average success rate of 98.57% across 350\nplanning tasks, significantly outperforming competitive baselines. This\ndemonstrates the ability of our method to discover and use diverse trajectory\nmodes, enhancing flexibility and adaptability in complex environments, and\ndelivering significant improvements over standard baselines without incurring\nmajor computational costs.", "published": "2025-04-07 11:20:11", "link": "http://arxiv.org/abs/2504.04936v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "SoK: LLM-based Log Parsing", "abstract": "Log data, generated by software systems, provides crucial insights for tasks\nlike monitoring, root cause analysis, and anomaly detection. Due to the vast\nvolume of logs, automated log parsing is essential to transform semi-structured\nlog messages into structured representations. Traditional log parsing\ntechniques often require manual configurations, such as defining log formats or\nlabeling data, which limits scalability and usability. Recent advances in large\nlanguage models (LLMs) have introduced the new research field of LLM-based log\nparsing, offering potential improvements in automation and adaptability.\nDespite promising results, there is no structured overview of these approaches\nsince this is a relatively new research field with the earliest advances\npublished in late 2023. This paper systematically reviews 29 LLM-based log\nparsing methods, comparing their capabilities, limitations, and reliance on\nmanual effort. We analyze the learning and prompt-engineering paradigms\nemployed, efficiency- and effectiveness-enhancing techniques, and the role of\nLLMs in the parsing process. We aggregate the results of the survey in a large\ntable comprising the characterizing features of LLM-based log parsing\napproaches and derive the general process of LLM-based log parsing,\nincorporating all reviewed approaches in a single flow chart. Additionally, we\nbenchmark seven open-source LLM-based log parsers on public datasets and\ncritically assess their reproducibility. Our findings summarize the advances of\nthis new research field and provide insights for researchers and practitioners\nseeking efficient and user-friendly log parsing solutions, with all code and\nresults made publicly available for transparency.", "published": "2025-04-07 09:41:04", "link": "http://arxiv.org/abs/2504.04877v1", "categories": ["cs.LG", "I.2; I.5"], "primary_category": "cs.LG"}
{"title": "Closed-Loop Neural Operator-Based Observer of Traffic Density", "abstract": "We consider the problem of traffic density estimation with sparse\nmeasurements from stationary roadside sensors. Our approach uses Fourier neural\noperators to learn macroscopic traffic flow dynamics from high-fidelity\nmicroscopic-level simulations. During inference, the operator functions as an\nopen-loop predictor of traffic evolution. To close the loop, we couple the\nopen-loop operator with a correction operator that combines the predicted\ndensity with sparse measurements from the sensors. Simulations with the SUMO\nsoftware indicate that, compared to open-loop observers, the proposed\nclosed-loop observer exhibit classical closed-loop properties such as\nrobustness to noise and ultimate boundedness of the error. This shows the\nadvantages of combining learned physics with real-time corrections, and opens\navenues for accurate, efficient, and interpretable data-driven observers.", "published": "2025-04-07 09:28:50", "link": "http://arxiv.org/abs/2504.04873v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Nonlocal techniques for the analysis of deep ReLU neural network approximations", "abstract": "Recently, Daubechies, DeVore, Foucart, Hanin, and Petrova introduced a system\nof piece-wise linear functions, which can be easily reproduced by artificial\nneural networks with the ReLU activation function and which form a Riesz basis\nof $L_2([0,1])$. This work was generalized by two of the authors to the\nmultivariate setting. We show that this system serves as a Riesz basis also for\nSobolev spaces $W^s([0,1]^d)$ and Barron classes ${\\mathbb B}^s([0,1]^d)$ with\nsmoothness $0<s<1$. We apply this fact to re-prove some recent results on the\napproximation of functions from these classes by deep neural networks. Our\nproof method avoids using local approximations and allows us to track also the\nimplicit constants as well as to show that we can avoid the curse of dimension.\nMoreover, we also study how well one can approximate Sobolev and Barron\nfunctions by ANNs if only function values are known.", "published": "2025-04-07 09:00:22", "link": "http://arxiv.org/abs/2504.04847v1", "categories": ["cs.LG", "cs.CC", "cs.NA", "math.NA", "68T07, 42C15, 11A25"], "primary_category": "cs.LG"}
{"title": "Attentional Graph Meta-Learning for Indoor Localization Using Extremely Sparse Fingerprints", "abstract": "Fingerprint-based indoor localization is often labor-intensive due to the\nneed for dense grids and repeated measurements across time and space.\nMaintaining high localization accuracy with extremely sparse fingerprints\nremains a persistent challenge. Existing benchmark methods primarily rely on\nthe measured fingerprints, while neglecting valuable spatial and environmental\ncharacteristics. In this paper, we propose a systematic integration of an\nAttentional Graph Neural Network (AGNN) model, capable of learning spatial\nadjacency relationships and aggregating information from neighboring\nfingerprints, and a meta-learning framework that utilizes datasets with similar\nenvironmental characteristics to enhance model training. To minimize the labor\nrequired for fingerprint collection, we introduce two novel data augmentation\nstrategies: 1) unlabeled fingerprint augmentation using moving platforms, which\nenables the semi-supervised AGNN model to incorporate information from\nunlabeled fingerprints, and 2) synthetic labeled fingerprint augmentation\nthrough environmental digital twins, which enhances the meta-learning framework\nthrough a practical distribution alignment, which can minimize the feature\ndiscrepancy between synthetic and real-world fingerprints effectively. By\nintegrating these novel modules, we propose the Attentional Graph Meta-Learning\n(AGML) model. This novel model combines the strengths of the AGNN model and the\nmeta-learning framework to address the challenges posed by extremely sparse\nfingerprints. To validate our approach, we collected multiple datasets from\nboth consumer-grade WiFi devices and professional equipment across diverse\nenvironments. Extensive experiments conducted on both synthetic and real-world\ndatasets demonstrate that the AGML model-based localization method consistently\noutperforms all baseline methods using sparse fingerprints across all evaluated\nmetrics.", "published": "2025-04-07 08:37:18", "link": "http://arxiv.org/abs/2504.04829v1", "categories": ["cs.LG", "eess.SP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Sparse Optimization for Transfer Learning: A L0-Regularized Framework for Multi-Source Domain Adaptation", "abstract": "This paper explores transfer learning in heterogeneous multi-source\nenvironments with distributional divergence between target and auxiliary\ndomains. To address challenges in statistical bias and computational\nefficiency, we propose a Sparse Optimization for Transfer Learning (SOTL)\nframework based on L0-regularization. The method extends the Joint Estimation\nTransferred from Strata (JETS) paradigm with two key innovations: (1)\nL0-constrained exact sparsity for parameter space compression and complexity\nreduction, and (2) refining optimization focus to emphasize target parameters\nover redundant ones. Simulations show that SOTL significantly improves both\nestimation accuracy and computational speed, especially under adversarial\nauxiliary domain conditions. Empirical validation on the Community and Crime\nbenchmarks demonstrates the statistical robustness of the SOTL method in\ncross-domain transfer.", "published": "2025-04-07 08:06:16", "link": "http://arxiv.org/abs/2504.04812v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Topological Schr\u00f6dinger Bridge Matching", "abstract": "Given two boundary distributions, the Schr\\\"odinger Bridge (SB) problem seeks\nthe ``most likely`` random evolution between them with respect to a reference\nprocess. It has revealed rich connections to recent machine learning methods\nfor generative modeling and distribution matching. While these methods perform\nwell in Euclidean domains, they are not directly applicable to topological\ndomains such as graphs and simplicial complexes, which are crucial for data\ndefined over network entities, such as node signals and edge flows. In this\nwork, we propose the Topological Schr\\\"odinger Bridge problem (TSBP) for\nmatching signal distributions on a topological domain. We set the reference\nprocess to follow some linear tractable topology-aware stochastic dynamics such\nas topological heat diffusion. For the case of Gaussian boundary distributions,\nwe derive a closed-form topological SB (TSB) in terms of its time-marginal and\nstochastic differential. In the general case, leveraging the well-known result,\nwe show that the optimal process follows the forward-backward topological\ndynamics governed by some unknowns. Building on these results, we develop\nTSB-based models for matching topological signals by parameterizing the\nunknowns in the optimal process as (topological) neural networks and learning\nthem through likelihood training. We validate the theoretical results and\ndemonstrate the practical applications of TSB-based models on both synthetic\nand real-world networks, emphasizing the role of topology. Additionally, we\ndiscuss the connections of TSB-based models to other emerging models, and\noutline future directions for topological signal matching.", "published": "2025-04-07 07:45:21", "link": "http://arxiv.org/abs/2504.04799v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "TabRep: Training Tabular Diffusion Models with a Simple and Effective Continuous Representation", "abstract": "Diffusion models have been the predominant generative model for tabular data\ngeneration. However, they face the conundrum of modeling under a separate\nversus a unified data representation. The former encounters the challenge of\njointly modeling all multi-modal distributions of tabular data in one model.\nWhile the latter alleviates this by learning a single representation for all\nfeatures, it currently leverages sparse suboptimal encoding heuristics and\nnecessitates additional computation costs. In this work, we address the latter\nby presenting TabRep, a tabular diffusion architecture trained with a unified\ncontinuous representation. To motivate the design of our representation, we\nprovide geometric insights into how the data manifold affects diffusion models.\nThe key attributes of our representation are composed of its density,\nflexibility to provide ample separability for nominal features, and ability to\npreserve intrinsic relationships. Ultimately, TabRep provides a simple yet\neffective approach for training tabular diffusion models under a continuous\ndata manifold. Our results showcase that TabRep achieves superior performance\nacross a broad suite of evaluations. It is the first to synthesize tabular data\nthat exceeds the downstream quality of the original datasets while preserving\nprivacy and remaining computationally efficient.", "published": "2025-04-07 07:44:27", "link": "http://arxiv.org/abs/2504.04798v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Playing Non-Embedded Card-Based Games with Reinforcement Learning", "abstract": "Significant progress has been made in AI for games, including board games,\nMOBA, and RTS games. However, complex agents are typically developed in an\nembedded manner, directly accessing game state information, unlike human\nplayers who rely on noisy visual data, leading to unfair competition.\nDeveloping complex non-embedded agents remains challenging, especially in\ncard-based RTS games with complex features and large state spaces. We propose a\nnon-embedded offline reinforcement learning training strategy using visual\ninputs to achieve real-time autonomous gameplay in the RTS game Clash Royale.\nDue to the lack of a object detection dataset for this game, we designed an\nefficient generative object detection dataset for training. We extract features\nusing state-of-the-art object detection and optical character recognition\nmodels. Our method enables real-time image acquisition, perception feature\nfusion, decision-making, and control on mobile devices, successfully defeating\nbuilt-in AI opponents. All code is open-sourced at\nhttps://github.com/wty-yy/katacr.", "published": "2025-04-07 07:26:02", "link": "http://arxiv.org/abs/2504.04783v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Feedback-Enhanced Hallucination-Resistant Vision-Language Model for Real-Time Scene Understanding", "abstract": "Real-time scene comprehension is a key advance in artificial intelligence,\nenhancing robotics, surveillance, and assistive tools. However, hallucination\nremains a challenge. AI systems often misinterpret visual inputs, detecting\nnonexistent objects or describing events that never happened. These errors, far\nfrom minor, threaten reliability in critical areas like security and autonomous\nnavigation where accuracy is essential.\n  Our approach tackles this by embedding self-awareness into the AI. Instead of\ntrusting initial outputs, our framework continuously assesses them in real\ntime, adjusting confidence thresholds dynamically. When certainty falls below a\nsolid benchmark, it suppresses unreliable claims. Combining YOLOv5's object\ndetection strength with VILA1.5-3B's controlled language generation, we tie\ndescriptions to confirmed visual data. Strengths include dynamic threshold\ntuning for better accuracy, evidence-based text to reduce hallucination, and\nreal-time performance at 18 frames per second.\n  This feedback-driven design cuts hallucination by 37 percent over traditional\nmethods. Fast, flexible, and reliable, it excels in applications from robotic\nnavigation to security monitoring, aligning AI perception with reality.", "published": "2025-04-07 06:59:30", "link": "http://arxiv.org/abs/2504.04772v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MedGNN: Capturing the Links Between Urban Characteristics and Medical Prescriptions", "abstract": "Understanding how urban socio-demographic and environmental factors relate\nwith health is essential for public health and urban planning. However,\ntraditional statistical methods struggle with nonlinear effects, while machine\nlearning models often fail to capture geographical (nearby areas being more\nsimilar) and topological (unequal connectivity between places) effects in an\ninterpretable way. To address this, we propose MedGNN, a spatio-topologically\nexplicit framework that constructs a 2-hop spatial graph, integrating\npositional and locational node embeddings with urban characteristics in a graph\nneural network. Applied to MEDSAT, a comprehensive dataset covering over 150\nenvironmental and socio-demographic factors and six prescription outcomes\n(depression, anxiety, diabetes, hypertension, asthma, and opioids) across 4,835\nGreater London neighborhoods, MedGNN improved predictions by over 25% on\naverage compared to baseline methods. Using depression prescriptions as a case\nstudy, we analyzed graph embeddings via geographical principal component\nanalysis, identifying findings that: align with prior research (e.g., higher\nantidepressant prescriptions among older and White populations), contribute to\nongoing debates (e.g., greenery linked to higher and NO2 to lower\nprescriptions), and warrant further study (e.g., canopy evaporation correlated\nwith fewer prescriptions). These results demonstrate MedGNN's potential, and\nmore broadly, of carefully applied machine learning, to advance\ntransdisciplinary public health research.", "published": "2025-04-07 05:35:16", "link": "http://arxiv.org/abs/2504.04739v1", "categories": ["cs.LG", "cs.CY", "I.2.6; J.3; H.2.8"], "primary_category": "cs.LG"}
{"title": "Large-Scale Mixed-Traffic and Intersection Control using Multi-agent Reinforcement Learning", "abstract": "Traffic congestion remains a significant challenge in modern urban networks.\nAutonomous driving technologies have emerged as a potential solution. Among\ntraffic control methods, reinforcement learning has shown superior performance\nover traffic signals in various scenarios. However, prior research has largely\nfocused on small-scale networks or isolated intersections, leaving large-scale\nmixed traffic control largely unexplored. This study presents the first attempt\nto use decentralized multi-agent reinforcement learning for large-scale mixed\ntraffic control in which some intersections are managed by traffic signals and\nothers by robot vehicles. Evaluating a real-world network in Colorado Springs,\nCO, USA with 14 intersections, we measure traffic efficiency via average\nwaiting time of vehicles at intersections and the number of vehicles reaching\ntheir destinations within a time window (i.e., throughput). At 80% RV\npenetration rate, our method reduces waiting time from 6.17 s to 5.09 s and\nincreases throughput from 454 vehicles per 500 seconds to 493 vehicles per 500\nseconds, outperforming the baseline of fully signalized intersections. These\nfindings suggest that integrating reinforcement learning-based control\nlarge-scale traffic can improve overall efficiency and may inform future urban\nplanning strategies.", "published": "2025-04-07 02:52:39", "link": "http://arxiv.org/abs/2504.04691v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Sparsity-Aware Communication for Distributed Graph Neural Network Training", "abstract": "Graph Neural Networks (GNNs) are a computationally efficient method to learn\nembeddings and classifications on graph data. However, GNN training has low\ncomputational intensity, making communication costs the bottleneck for\nscalability. Sparse-matrix dense-matrix multiplication (SpMM) is the core\ncomputational operation in full-graph training of GNNs. Previous work\nparallelizing this operation focused on sparsity-oblivious algorithms, where\nmatrix elements are communicated regardless of the sparsity pattern. This leads\nto a predictable communication pattern that can be overlapped with computation\nand enables the use of collective communication operations at the expense of\nwasting significant bandwidth by communicating unnecessary data. We develop\nsparsity-aware algorithms that tackle the communication bottlenecks in GNN\ntraining with three novel approaches. First, we communicate only the necessary\nmatrix elements. Second, we utilize a graph partitioning model to reorder the\nmatrix and drastically reduce the amount of communicated elements. Finally, we\naddress the high load imbalance in communication with a tailored partitioning\nmodel, which minimizes both the total communication volume and the maximum\nsending volume. We further couple these sparsity-exploiting approaches with a\ncommunication-avoiding approach (1.5D parallel SpMM) in which submatrices are\nreplicated to reduce communication. We explore the tradeoffs of these combined\noptimizations and show up to 14X improvement on 256 GPUs and on some instances\nreducing communication to almost zero resulting in a communication-free\nparallel training relative to a popular GNN framework based on\ncommunication-oblivious SpMM.", "published": "2025-04-07 01:53:14", "link": "http://arxiv.org/abs/2504.04673v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Scaling Graph Neural Networks for Particle Track Reconstruction", "abstract": "Particle track reconstruction is an important problem in high-energy physics\n(HEP), necessary to study properties of subatomic particles. Traditional track\nreconstruction algorithms scale poorly with the number of particles within the\naccelerator. The Exa.TrkX project, to alleviate this computational burden,\nintroduces a pipeline that reduces particle track reconstruction to edge\nclassification on a graph, and uses graph neural networks (GNNs) to produce\nparticle tracks. However, this GNN-based approach is memory-prohibitive and\nskips graphs that would exceed GPU memory. We introduce improvements to the\nExa.TrkX pipeline to train on samples of input particle graphs, and show that\nthese improvements generalize to higher precision and recall. In addition, we\nadapt performance optimizations, introduced for GNN training, to fit our\naugmented Exa.TrkX pipeline. These optimizations provide a $2\\times$ speedup\nover our baseline implementation in PyTorch Geometric.", "published": "2025-04-07 01:44:32", "link": "http://arxiv.org/abs/2504.04670v1", "categories": ["cs.LG", "cs.CE", "cs.DC"], "primary_category": "cs.LG"}
{"title": "asKAN: Active Subspace embedded Kolmogorov-Arnold Network", "abstract": "The Kolmogorov-Arnold Network (KAN) has emerged as a promising neural network\narchitecture for small-scale AI+Science applications. However, it suffers from\ninflexibility in modeling ridge functions, which is widely used in representing\nthe relationships in physical systems. This study investigates this\ninflexibility through the lens of the Kolmogorov-Arnold theorem, which starts\nthe representation of multivariate functions from constructing the univariate\ncomponents rather than combining the independent variables. Our analysis\nreveals that incorporating linear combinations of independent variables can\nsubstantially simplify the network architecture in representing the ridge\nfunctions. Inspired by this finding, we propose active subspace embedded KAN\n(asKAN), a hierarchical framework that synergizes KAN's function representation\nwith active subspace methodology. The architecture strategically embeds active\nsubspace detection between KANs, where the active subspace method is used to\nidentify the primary ridge directions and the independent variables are\nadaptively projected onto these critical dimensions. The proposed asKAN is\nimplemented in an iterative way without increasing the number of neurons in the\noriginal KAN. The proposed method is validated through function fitting,\nsolving the Poisson equation, and reconstructing sound field. Compared with\nKAN, asKAN significantly reduces the error using the same network architecture.\nThe results suggest that asKAN enhances the capability of KAN in fitting and\nsolving equations with in the form of ridge functions.", "published": "2025-04-07 01:43:13", "link": "http://arxiv.org/abs/2504.04669v1", "categories": ["physics.comp-ph", "cs.LG"], "primary_category": "physics.comp-ph"}
{"title": "Interval-Valued Time Series Classification Using $D_K$-Distance", "abstract": "In recent years, modeling and analysis of interval-valued time series have\ngarnered increasing attention in econometrics, finance, and statistics.\nHowever, these studies have predominantly focused on statistical inference in\nthe forecasting of univariate and multivariate interval-valued time series,\noverlooking another important aspect: classification. In this paper, we\nintroduce a classification approach that treats intervals as unified entities,\napplicable to both univariate and multivariate interval-valued time series.\nSpecifically, we first extend the point-valued time series imaging methods to\ninterval-valued scenarios using the $D_K$-distance, enabling the imaging of\ninterval-valued time series. Then, we employ suitable deep learning model for\nclassification on the obtained imaging dataset, aiming to achieve\nclassification for interval-valued time series. In theory, we derived a sharper\nexcess risk bound for deep multiclassifiers based on offset Rademacher\ncomplexity. Finally, we validate the superiority of the proposed method through\ncomparisons with various existing point-valued time series classification\nmethods in both simulation studies and real data applications.", "published": "2025-04-07 01:31:31", "link": "http://arxiv.org/abs/2504.04667v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "A Simultaneous Approach for Training Neural Differential-Algebraic Systems of Equations", "abstract": "Scientific machine learning is an emerging field that broadly describes the\ncombination of scientific computing and machine learning to address challenges\nin science and engineering. Within the context of differential equations, this\nhas produced highly influential methods, such as neural ordinary differential\nequations (NODEs). Recent works extend this line of research to consider neural\ndifferential-algebraic systems of equations (DAEs), where some unknown\nrelationships within the DAE are learned from data. Training neural DAEs,\nsimilarly to neural ODEs, is computationally expensive, as it requires the\nsolution of a DAE for every parameter update. Further, the rigorous\nconsideration of algebraic constraints is difficult within common deep learning\ntraining algorithms such as stochastic gradient descent. In this work, we apply\nthe simultaneous approach to neural DAE problems, resulting in a fully\ndiscretized nonlinear optimization problem, which is solved to local optimality\nand simultaneously obtains the neural network parameters and the solution to\nthe corresponding DAE. We extend recent work demonstrating the simultaneous\napproach for neural ODEs, by presenting a general framework to solve neural\nDAEs, with explicit consideration of hybrid models, where some components of\nthe DAE are known, e.g. physics-informed constraints. Furthermore, we present a\ngeneral strategy for improving the performance and convergence of the nonlinear\nprogramming solver, based on solving an auxiliary problem for initialization\nand approximating Hessian terms. We achieve promising results in terms of\naccuracy, model generalizability and computational cost, across different\nproblem settings such as sparse data, unobserved states and multiple\ntrajectories. Lastly, we provide several promising future directions to improve\nthe scalability and robustness of our approach.", "published": "2025-04-07 01:26:55", "link": "http://arxiv.org/abs/2504.04665v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "ACE-RLHF: Automated Code Evaluation and Socratic Feedback Generation Tool using Large Language Models and Reinforcement Learning with Human Feedback", "abstract": "Automated Program Repair tools are developed for generating feedback and\nsuggesting a repair method for erroneous code. State of the art (SOTA) code\nrepair methods rely on data-driven approaches and often fail to deliver\nsolution for complicated programming questions. To interpret the natural\nlanguage of unprecedented programming problems, using Large Language Models\n(LLMs) for code-feedback generation is crucial. LLMs generate more\ncomprehensible feedback than compiler-generated error messages, and\nReinforcement Learning with Human Feedback (RLHF) further enhances quality by\nintegrating human-in-the-loop which helps novice students to lean programming\nfrom scratch interactively. We are applying RLHF fine-tuning technique for an\nexpected Socratic response such as a question with hint to solve the\nprogramming issue. We are proposing code feedback generation tool by\nfine-tuning LLM with RLHF, Automated Code Evaluation with RLHF (ACE-RLHF),\ncombining two open-source LLM models with two different SOTA optimization\ntechniques. The quality of feedback is evaluated on two benchmark datasets\ncontaining basic and competition-level programming questions where the later is\nproposed by us. We achieved 2-5% higher accuracy than RL-free SOTA techniques\nusing Llama-3-7B-Proximal-policy optimization in automated evaluation and\nsimilar or slightly higher accuracy compared to reward model-free RL with AI\nFeedback (RLAIF). We achieved almost 40% higher accuracy with GPT-3.5 Best-of-n\noptimization while performing manual evaluation.", "published": "2025-04-07 01:11:22", "link": "http://arxiv.org/abs/2504.04657v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Sub-Clustering for Class Distance Recalculation in Long-Tailed Drug Classification", "abstract": "In the real world, long-tailed data distributions are prevalent, making it\nchallenging for models to effectively learn and classify tail classes. However,\nwe discover that in the field of drug chemistry, certain tail classes exhibit\nhigher identifiability during training due to their unique molecular structural\nfeatures, a finding that significantly contrasts with the conventional\nunderstanding that tail classes are generally difficult to identify. Existing\nimbalance learning methods, such as resampling and cost-sensitive reweighting,\noverly rely on sample quantity priors, causing models to excessively focus on\ntail classes at the expense of head class performance. To address this issue,\nwe propose a novel method that breaks away from the traditional static\nevaluation paradigm based on sample size. Instead, we establish a dynamical\ninter-class separability metric using feature distances between different\nclasses. Specifically, we employ a sub-clustering contrastive learning approach\nto thoroughly learn the embedding features of each class, and we dynamically\ncompute the distances between class embeddings to capture the relative\npositional evolution of samples from different classes in the feature space,\nthereby rebalancing the weights of the classification loss function. We\nconducted experiments on multiple existing long-tailed drug datasets and\nachieved competitive results by improving the accuracy of tail classes without\ncompromising the performance of dominant classes.", "published": "2025-04-07 00:09:10", "link": "http://arxiv.org/abs/2504.04647v1", "categories": ["cs.LG", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Simulating Persuasive Dialogues on Meat Reduction with Generative Agents", "abstract": "Meat reduction benefits human and planetary health, but social norms keep\nmeat central in shared meals. To date, the development of communication\nstrategies that promote meat reduction while minimizing social costs has\nrequired the costly involvement of human participants at each stage of the\nprocess. We present work in progress on simulating multi-round dialogues on\nmeat reduction between Generative Agents based on large language models (LLMs).\nWe measure our main outcome using established psychological questionnaires\nbased on the Theory of Planned Behavior and additionally investigate Social\nCosts. We find evidence that our preliminary simulations produce outcomes that\nare (i) consistent with theoretical expectations; and (ii) valid when compared\nto data from previous studies with human participants. Generative agent-based\nmodels are a promising tool for identifying novel communication strategies on\nmeat reduction-tailored to highly specific participant groups-to then be tested\nin subsequent studies with human participants.", "published": "2025-04-07 09:27:37", "link": "http://arxiv.org/abs/2504.04872v1", "categories": ["cs.CY", "cs.HC", "cs.MA"], "primary_category": "cs.CY"}
{"title": "Autono: ReAct-Based Highly Robust Autonomous Agent Framework", "abstract": "This paper proposes a highly robust autonomous agent framework based on the\nReAct paradigm, designed to solve complex tasks through adaptive decision\nmaking and multi-agent collaboration. Unlike traditional frameworks that rely\non fixed workflows generated by LLM-based planners, this framework dynamically\ngenerates next actions during agent execution based on prior trajectories,\nthereby enhancing its robustness. To address potential termination issues\ncaused by adaptive execution paths, I propose a timely abandonment strategy\nincorporating a probabilistic penalty mechanism. For multi-agent collaboration,\nI introduce a memory transfer mechanism that enables shared and dynamically\nupdated memory among agents. The framework's innovative timely abandonment\nstrategy dynamically adjusts the probability of task abandonment via\nprobabilistic penalties, allowing developers to balance conservative and\nexploratory tendencies in agent execution strategies by tuning hyperparameters.\nThis significantly improves adaptability and task execution efficiency in\ncomplex environments. Additionally, agents can be extended through external\ntool integration, supported by modular design and MCP protocol compatibility,\nwhich enables flexible action space expansion. Through explicit division of\nlabor, the multi-agent collaboration mechanism enables agents to focus on\nspecific task components, thereby significantly improving execution efficiency\nand quality.", "published": "2025-04-07 00:45:10", "link": "http://arxiv.org/abs/2504.04650v1", "categories": ["cs.MA", "cs.HC", "I.2.9; I.2.8; I.2.1"], "primary_category": "cs.MA"}
{"title": "Differential forms: Lagrange interpolation, sampling and approximation on polynomial admissible integral k-meshes", "abstract": "In this work we address the problem of interpolating and approximating\ndifferential forms starting from data defined by integration. We show that many\naspects of nodal interpolation can naturally be carried to this more general\nframework; in contrast, some of them require the introduction of geometric and\nmeasure theoretic hypotheses. After characterizing the norms of the operators\ninvolved, we introduce the concept of admissible integral k-mesh, which allows\nfor the construction of robust approximation schemes, and is used to extract\ninterpolation sets with high stability properties. To this end, the concepts of\nFekete currents and Leja sequences of currents are formalized, and a numerical\nscheme for their approximation is proposed.", "published": "2025-04-07 17:04:51", "link": "http://arxiv.org/abs/2504.05266v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Error formulas for block rational Krylov approximations of matrix functions", "abstract": "This paper investigates explicit expressions for the error associated with\nthe block rational Krylov approximation of matrix functions. Two formulas are\nproposed, both derived from characterizations of the block FOM residual. The\nfirst formula employs a block generalization of the residual polynomial, while\nthe second leverages the block collinearity of the residuals. A posteriori\nerror bounds based on the knowledge of spectral information of the argument are\nderived and tested on a set of examples. Notably, both error formulas and their\ncorresponding upper bounds do not require the use of quadratures for their\npractical evaluation.", "published": "2025-04-07 14:56:55", "link": "http://arxiv.org/abs/2504.05151v1", "categories": ["math.NA", "cs.NA", "65F60"], "primary_category": "math.NA"}
{"title": "Fast Convolutions on $\\mathbb{Z}^2\\backslash SE(2)$ via Radial Translational Dependence and Classical FFT", "abstract": "Let $\\mathbb{Z}^2\\backslash SE(2)$ denote the right coset space of the\nsubgroup consisting of translational isometries of the orthogonal lattice\n$\\mathbb{Z}^2$ in the non-Abelian group of planar motions $SE(2)$. This paper\ndevelops a fast and accurate numerical scheme for approximation of functions on\n$\\mathbb{Z}^2\\backslash SE(2)$. We address finite Fourier series of functions\non the right coset space $\\mathbb{Z}^2\\backslash SE(2)$ using finite Fourier\ncoefficients. The convergence/error analysis of finite Fourier coefficients are\ninvestigated. Conditions are established for the finite Fourier coefficients to\nconverge to the Fourier coefficients. The matrix forms of the finite transforms\nare discussed. The implementation of the discrete method to compute numerical\napproximation of $SE(2)$-convolutions with functions which are radial in\ntranslations are considered. The paper is concluded by discussing capability of\nthe numerical scheme to develop fast algorithms for approximating multiple\nconvolutions with functions with are radial in translations.", "published": "2025-04-07 14:56:32", "link": "http://arxiv.org/abs/2504.05149v1", "categories": ["math.NA", "cs.NA", "math.FA", "math.GR", "42B05, 43A85, 65T50, 20H15, 43A15, 43A20, 70E60"], "primary_category": "math.NA"}
{"title": "Generators of $H^1(\u0393, \\partial \u0393^c)$ with $\\partial \u0393^c \\subset \\partial \u0393$ for Triangulated Surfaces $\u0393$: Construction and Classification of Global Loops", "abstract": "Given a compact surface $\\Gamma$ embedded in $\\mathbb R^3$ with boundary\n$\\partial \\Gamma$, our goal is to construct a set of representatives for a\nbasis of the relative cohomology group $H^1(\\Gamma, \\partial \\Gamma^c)$, where\n$\\Gamma^c$ is a specified subset of $\\partial \\Gamma$. To achieve this, we\npropose a novel graph-based algorithm with two key features: it is applicable\nto non-orientable surfaces, thereby generalizing previous approaches, and it\nhas a worst-case time complexity that is linear in the number of edges of the\nmesh $\\mathcal{K}$ triangulating $\\Gamma$. Importantly, this algorithm serves\nas a critical pre-processing step to address the low-frequency breakdown\nencountered in boundary element discretizations of integral equation\nformulations.", "published": "2025-04-07 14:28:47", "link": "http://arxiv.org/abs/2504.05124v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Turing instability for nonlocal heterogeneous reaction-diffusion systems: A computer-assisted proof approach", "abstract": "This paper provides a computer-assisted proof for the Turing instability\ninduced by heterogeneous nonlocality in reaction-diffusion systems. Due to the\nheterogeneity and nonlocality, the linear Fourier analysis gives rise to\n\\textit{strongly coupled} infinite differential systems. By introducing\nsuitable changes of basis as well as the Gershgorin disks theorem for infinite\nmatrices, we first show that all $N$-th Gershgorin disks lie completely on the\nleft half-plane for sufficiently large $N$. For the remaining finitely many\ndisks, a computer-assisted proof shows that if the intensity $\\delta$ of the\nnonlocal term is large enough, there is precisely one eigenvalue with positive\nreal part, which proves the Turing instability. Moreover, by detailed study of\nthis eigenvalue as a function of $\\delta$, we obtain a sharp threshold\n$\\delta^*$ which is the bifurcation point for Turing instability.", "published": "2025-04-07 13:34:46", "link": "http://arxiv.org/abs/2504.05066v1", "categories": ["math.AP", "cs.NA", "math.DS", "math.NA"], "primary_category": "math.AP"}
{"title": "Hybrid Nitsche for distributed computing", "abstract": "We extend the distributed finite element method of [1], built upon model\norder reduction, to arbitrary polynomial degree using a hybrid Nitsche scheme.\nThis new method considerably simplifies the transformation of the finite\nelement system to the reduced basis for large problems. We prove that the error\nof the reduced Nitsche solution converges optimally with respect to the\napproximation order of the finite element spaces and linearly with respect to\nthe dimension reduction parameter $\\epsilon$. Numerical tests with nontrivial\ntetrahedral meshes using second-degree polynomial bases support the theoretical\nresults.", "published": "2025-04-07 12:57:06", "link": "http://arxiv.org/abs/2504.05036v1", "categories": ["math.NA", "cs.NA", "65F55, 65N30, 65N55, 65Y05"], "primary_category": "math.NA"}
{"title": "Solving the fully nonlinear Monge-Amp\u00e8re equation using the Legendre-Kolmogorov-Arnold Network method", "abstract": "In this paper, we propose a novel neural network framework, the\nLegendre-Kolmogorov-Arnold Network (Legendre-KAN) method, designed to solve\nfully nonlinear Monge-Amp\\`ere equations with Dirichlet boundary conditions.\nThe architecture leverages the orthogonality of Legendre polynomials as basis\nfunctions, significantly enhancing both convergence speed and solution accuracy\ncompared to traditional methods. Furthermore, the Kolmogorov-Arnold\nrepresentation theorem provides a strong theoretical foundation for the\ninterpretability and optimization of the network. We demonstrate the\neffectiveness of the proposed method through numerical examples, involving both\nsmooth and singular solutions in various dimensions. This work not only\naddresses the challenges of solving high-dimensional and singular\nMonge-Amp\\`ere equations but also highlights the potential of neural\nnetwork-based approaches for complex partial differential equations.\nAdditionally, the method is applied to the optimal transport problem in image\nmapping, showcasing its practical utility in geometric image transformation.\nThis approach is expected to pave the way for further enhancement of KAN-based\napplications and numerical solutions of PDEs across a wide range of scientific\nand engineering fields.", "published": "2025-04-07 12:47:47", "link": "http://arxiv.org/abs/2504.05022v1", "categories": ["math.NA", "cs.NA", "65N35, 65N12, 65N15, 35J96"], "primary_category": "math.NA"}
{"title": "Randomized block Krylov method for approximation of truncated tensor SVD", "abstract": "This paper is devoted to studying the application of the block Krylov\nsubspace method for approximation of the truncated tensor SVD (T-SVD). The\ntheoretical results of the proposed randomized approach are presented. Several\nexperimental experiments using synthetics and real-world data are conducted to\nverify the efficiency and feasibility of the proposed randomized approach, and\nthe numerical results show that the proposed method provides promising results.\nApplications of the proposed approach to data completion and data compression\nare presented.", "published": "2025-04-07 12:13:47", "link": "http://arxiv.org/abs/2504.04989v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Anisotropic space-time goal-oriented error control and mesh adaptivity for convection-diffusion-reaction equations", "abstract": "We present an anisotropic goal-oriented error estimator based on the Dual\nWeighted Residual (DWR) method for time-dependent convection-diffusion-reaction\n(CDR) equations. Using anisotropic interpolation operators the estimator is\nelementwise separated with respect to the single directions in space and time\nleading to adaptive, anisotropic mesh refinement in a natural way. To prevent\nspurious oscillations the streamline upwind Petrov-Galerkin (SUPG) method is\napplied to stabilize the underlying system in the case of high P\\'{e}clet\nnumbers. Efficiency and robustness of the underlying algorithm are demonstrated\nfor different goal functionals. The directional error indicators quantify\nanisotropy of the solution with respect to the goal, and produce meshes that\nefficiently capture sharp layers. Numerical examples show the superiority of\nthe proposed approach over isotropic adaptive and global mesh refinement using\nestablished benchmarks for convection-dominated transport.", "published": "2025-04-07 11:34:56", "link": "http://arxiv.org/abs/2504.04951v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "The Linearized Vlasov-Maxwell System as a Hamiltonian System", "abstract": "We present a Hamiltonian formulation for the linearized Vlasov-Maxwell system\nwith a Maxwellian background distribution function. We discuss the geometric\nproperties of the model at the continuous level, and how to discretize the\nmodel in the GEMPIC framework [1]. This method allows us to keep the structure\nof the system at the semi-discrete level. To integrate the model in time, we\nemploy a Poisson splitting and discuss how to integrate each subsystem\nseparately. We test the model against the full Vlasov-Maxwell model with a\ncontrol variate method for noise reduction; the two chosen test-cases are the\nweak Landau damping and the Bernstein waves. Both test-cases exhibit the same\nphysical properties for short simulations but our model enjoys better long-time\nstability and energy conservation due to its geometric construction. The model\nis implemented in the open-source Python library STRUPHY [2, 3].", "published": "2025-04-07 11:13:36", "link": "http://arxiv.org/abs/2504.04929v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An iterative process for the feasibility-seeking problem with sets that are unions of convex sets", "abstract": "In this paper we deal with the feasibility-seeking problem for unions of\nconvex sets (UCS) sets and propose an iterative process for its solution.\nRenewed interest in this problem stems from the fact that it was recently\ndiscovered to serve as a modeling approach in fields of applications and from\nthe ongoing recent research efforts to handle non-convexity in\nfeasibility-seeking.", "published": "2025-04-07 10:41:54", "link": "http://arxiv.org/abs/2504.04912v1", "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "A mechanism for growth of topological entropy and global changes of the shape of chaotic attractors", "abstract": "The theoretical and numerical understanding of the key concept of topological\nentropy is an important problem in dynamical systems. Most studies have been\ncarried out on maps (discrete-time systems). We analyse a scenario of global\nchanges of the structure of an attractor in continuous-time systems leading to\nan unbounded growth of the topological entropy of the underlying dynamical\nsystem. As an example, we consider the classical Roessler system. We show that\nfor an explicit range of parameters a chaotic attractor exists. We also prove\nthe existence of a sequence of bifurcations leading to the growth of the\ntopological entropy. The proofs are computer-aided.", "published": "2025-04-07 09:54:10", "link": "http://arxiv.org/abs/2504.04887v1", "categories": ["math.DS", "cs.NA", "math.NA", "nlin.CD", "34C23, 34C25, 37A35, 37B10, 37B40"], "primary_category": "math.DS"}
{"title": "Block BDDC/FETI-DP Preconditioners for Three-Field mixed finite element Discretizations of Biot's consolidation model", "abstract": "In this paper, we construct and analyze a block dual-primal preconditioner\nfor Biot's consolidation model approximated by three-field mixed finite\nelements based on a displacement, pressure, and total pressure formulation. The\ndomain is decomposed into nonoverlapping subdomains, and the continuity of the\ndisplacement component across the subdomain interface is enforced by\nintroducing a Lagrange multiplier. After eliminating all displacement variables\nand the independent subdomain interior components of pressure and total\npressure, the problem is reduced to a symmetric positive definite linear system\nfor the subdomain interface pressure, total pressure, and the Lagrange\nmultiplier. This reduced system is solved by a preconditioned conjugate\ngradient method, with a block dual-primal preconditioner using a Balancing\nDomain Decomposition by Constraints (BDDC) preconditioner for both the\ninterface total pressure block and the interface pressure blocks, as well as a\nFinite Element Tearing and Interconnecting-Dual Primal (FETI-DP) preconditioner\nfor the Lagrange multiplier block. By analyzing the conditioning of the\npreconditioned subsystem associated with the interface pressure and total\npressure components, we obtain a condition number bound of the preconditioned\nsystem, which is scalable in the number of subdomains, poly-logarithmic in the\nratio of subdomain and mesh sizes, and robust with respect to the parameters of\nthe model. Extensive numerical experiments confirm the theoretical result of\nthe proposed algorithm.", "published": "2025-04-07 09:17:37", "link": "http://arxiv.org/abs/2504.04859v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An invariant-region-preserving scheme for a convection-reaction-Cahn-Hilliard multiphase model of biofilm growth in slow sand filters", "abstract": "A multidimensional model of biofilm growth present in the supernatant water\nof a Slow Sand Filter is derived. The multiphase model, consisting of solid and\nliquid phases, is written as a convection-reaction system with a\nCahn-Hilliard-type equation with degenerate mobility coupled to a Stokes-flow\nequation for the mixture velocity. An upwind discontinuous Galerkin approach is\nused to approximate the convection-reaction equations, whereas an\n$H^1$-conforming primal formulation is proposed for the Stokes system. By means\nof a splitting procedure due to the reaction terms, an invariant-region\nprinciple is shown for the concentration unknowns, namely non-negativity for\nall phases and an upper bound for the total concentration of the solid phases.\nNumerical examples with reduced biofilm reactions are presented to illustrate\nthe performance of the model and numerical scheme.", "published": "2025-04-07 09:10:06", "link": "http://arxiv.org/abs/2504.04852v1", "categories": ["math.NA", "cs.NA", "35Q49, 76T20, 35Q92"], "primary_category": "math.NA"}
{"title": "A structure and asymptotic preserving scheme for the quasineutral limit of the Vlasov-Poisson system", "abstract": "In this work, we propose a new numerical method for the Vlasov-Poisson system\nthat is both asymptotically consistent and stable in the quasineutral regime,\ni.e. when the Debye length is small compared to the characteristic spatial\nscale of the physical domain. Our approach consists in reformulating the\nVlasov-Poisson system as a hyperbolic problem by applying a spectral expansion\nin the basis of Hermite functions in the velocity space and in designing a\nstructure-preserving scheme for the time and spatial variables. Through this\nHermite formulation, we establish a convergence result for the electric field\ntoward its quasineutral limit together with optimal error estimates. Following\nthis path, we then propose a fully discrete numerical method for the\nVlasov-Poisson system, inspired by the approach in arXiv:2306.14605 , and\nrigorously prove that it is uniformly consistent in the quasineutral limit\nregime. Finally, we present several numerical simulations to illustrate the\nbehavior of the proposed scheme. These results demonstrate the capability of\nour method to describe quasineutral plasmas and confirm the theoretical\nfindings: stability and asymptotic preservation.", "published": "2025-04-07 08:32:13", "link": "http://arxiv.org/abs/2504.04826v1", "categories": ["math.NA", "cs.NA", "82C40, 35Q83 (Primary) 65N08, 65N35 (Secondary)"], "primary_category": "math.NA"}
{"title": "Error bound for the asymptotic expansion of the Hartman-Watson integral", "abstract": "This note gives a bound on the error of the leading term of the $t\\to 0$\nasymptotic expansion of the Hartman-Watson distribution $\\theta(r,t)$ in the\nregime $rt=\\rho$ constant. The leading order term has the form\n$\\theta(\\rho/t,t)=\\frac{1}{2\\pi t}e^{-\\frac{1}{t} (F(\\rho)-\\pi^2/2)} G(\\rho) (1\n+ \\vartheta(t,\\rho))$, where the error term is bounded uniformly over $\\rho$ as\n$|\\vartheta(t,\\rho)|\\leq \\frac{1}{70}t$.", "published": "2025-04-07 12:18:19", "link": "http://arxiv.org/abs/2504.04992v1", "categories": ["math.CA", "q-fin.CP"], "primary_category": "math.CA"}
{"title": "Bridging the Gap between Continuous and Informative Discrete Representations by Random Product Quantization", "abstract": "Self-supervised learning has become a core technique in speech processing,\nbut the high dimensionality of its representations makes discretization\nessential for improving efficiency. However, existing discretization methods\nstill suffer from significant information loss, resulting in a notable\nperformance gap compared to continuous representations. To overcome these\nlimitations, we propose two quantization-based discretization methods: Product\nQuantization (PQ) and Random Product Quantization (RPQ). PQ partitions the\noriginal feature space into multiple subspaces and independently quantizes each\nsub-vector, producing a fused set of discrete units that retain diverse\ninformation from different subspaces, thus mitigating the loss associated with\nsingle-cluster quantization. RPQ further enhances representation diversity by\nrandomly sampling a fixed proportion of feature dimensions multiple times to\nconstruct sub-vectors, thereby better capturing the variability in the data\ndistribution. Theoretical analysis shows that RPQ reduces the correlation\ncoefficient rho (where 0 <= rho <= 1) between sub-quantizers. Its quantization\nerror is lower-bounded by the product of rho and epsilon-kms, where epsilon-kms\ndenotes the quantization error of a single K-means quantizer. Experimental\nresults on a combined dataset built from LibriSpeech and ML-SUPERB show that PQ\nand RPQ outperform standard K-means discretization, achieving relative\nimprovements of 21.8 percent and 20.0 percent in WER on LibriSpeech, and 24.1\npercent and 19.6 percent in CER on ML-SUPERB, respectively. Moreover, their\nperformance is competitive with, and in some cases even surpasses, that of\ncontinuous SSL representations.", "published": "2025-04-07 04:18:11", "link": "http://arxiv.org/abs/2504.04721v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Performance and Complexity Analysis of Terahertz-Band MIMO Detection", "abstract": "Achieving terabit-per-second (Tbps) data rates in terahertz (THz)-band\ncommunications requires bridging the complexity gap in baseband transceiver\ndesign. This work addresses the signal processing challenges associated with\ndata detection in THz multiple-input multiple-output (MIMO) systems. We begin\nby analyzing the trade-offs between performance and complexity across various\ndetection schemes and THz channel models, demonstrating significant complexity\nreduction by leveraging spatial parallelizability over subspaces of correlated\nTHz MIMO channels. We derive accurate detection error probability bounds by\naccounting for THz-specific channel models and mismatches introduced by\nsubspace decomposition. Building on this, we propose a subspace detector that\nintegrates layer sorting, QR decomposition, and channel-matrix puncturing to\nbalance performance loss and parallelizability. Furthermore, we introduce a\nchannel-matrix reuse strategy for wideband THz MIMO detection. Simulations over\naccurate, ill-conditioned THz channels show that efficient parallelizability\nachieves multi-dB performance gains, while wideband reuse strategies offer\ncomputational savings with minimal performance degradation.", "published": "2025-04-07 17:06:07", "link": "http://arxiv.org/abs/2504.05268v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On multipolar magnetic anomaly detection: multipolar signal subspaces, an analytical orthonormal basis, multipolar truncature and detection performance", "abstract": "In this paper, we consider the magnetic anomaly detection problem which aims\nto find hidden ferromagnetic masses by estimating the weak perturbation they\ninduce on local Earth's magnetic field. We consider classical detection schemes\nthat rely on signals recorded on a moving sensor, and modeling of the source as\na function of unknown parameters. As the usual spherical harmonic decomposition\nof the anomaly has to be truncated in practice, we study the signal vector\nsubspaces induced by each multipole of the decomposition, proving they are not\nin direct sum, and discussing the impact it has on the choice of the truncation\norder. Further, to ease the detection strategy based on generalized likelihood\nratio test, we rely on orthogonal polynomials theory to derive an analytical\nset of orthonormal functions (multipolar orthonormal basis functions) that\nspans the space of the noise-free measured signal. Finally, based on the\nsubspace structure of the multipole vector spaces, we study the impact of the\ntruncation order on the detection performance, beyond the issue of potential\nsurparametrization, and the behaviour of the information criteria used to\nchoose this order.", "published": "2025-04-07 16:00:24", "link": "http://arxiv.org/abs/2504.05212v1", "categories": ["eess.SP", "math-ph", "math.MP", "stat.ME"], "primary_category": "eess.SP"}
{"title": "Modeling Micro-Doppler Signature of Multi-Propeller Drones in Distributed ISAC", "abstract": "Integrated Sensing and Communication (ISAC) will be one key feature of future\n6G networks, enabling simultaneous communication and radar sensing. The radar\nsensing geometry of ISAC will be multistatic since that corresponds to the\ncommon distributed structure of a mobile communication network. Within this\nframework, micro-Doppler analysis plays a vital role in classifying targets\nbased on their micromotions, such as rotating propellers, vibration, or moving\nlimbs. However, research on bistatic micro-Doppler effects, particularly in\nISAC systems utilizing OFDM waveforms, remains limited. Existing methods,\nincluding electromagnetic simulations often lack scalability for generating the\nlarge datasets required to train machine learning algorithms. To address this\ngap, this work introduces an OFDM-based bistatic micro-Doppler model for\nmulti-propeller drones. The proposed model adapts the classic thin-wire model\nto include bistatic sensing configuration with an OFDM-like signal. Then, it\nextends further by incorporating multiple propellers and integrating the\nreflectivity of the drone's static parts. Measurements were performed to\ncollect ground truth data for verification of the proposed model. Validation\nresults show that the model generates micro-Doppler signatures closely\nresembling those obtained from measurements, demonstrating its potential as a\ntool for data generation. In addition, it offers a comprehensive approach to\nanalyzing bistatic micro-Doppler effects.", "published": "2025-04-07 15:12:24", "link": "http://arxiv.org/abs/2504.05168v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "\"Security for Everyone\" in Finite Blocklength IRS-aided Systems With Perfect and Imperfect CSI", "abstract": "Provisioning secrecy for all users, given the heterogeneity in their channel\nconditions, locations, and the unknown location of the attacker/eavesdropper,\nis challenging and not always feasible. The problem is even more difficult\nunder finite blocklength constraints that are popular in ultra-reliable\nlow-latency communication (URLLC) and massive machine-type communications\n(mMTC). This work takes the first step to guarantee secrecy for all URLLC/mMTC\nusers in the finite blocklength regime (FBR) where intelligent reflecting\nsurfaces (IRS) are used to enhance legitimate users' reception and thwart the\npotential eavesdropper (Eve) from intercepting. To that end, we aim to maximize\nthe minimum secrecy rate (SR) among all users by jointly optimizing the\ntransmitter's beamforming and IRS's passive reflective elements (PREs) under\nthe FBR latency constraints. The resulting optimization problem is non-convex\nand even more complicated under imperfect channel state information (CSI). To\ntackle it, we linearize the objective function, and decompose the problem into\nsequential subproblems. When perfect CSI is not available, we use the\nsuccessive convex approximation (SCA) approach to transform imperfect\nCSI-related semi-infinite constraints into finite linear matrix inequalities\n(LMI).", "published": "2025-04-07 13:36:03", "link": "http://arxiv.org/abs/2504.05067v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Secure Communications for All Users in Low-Resolution IRS-aided Systems Under Imperfect and Unknown CSI", "abstract": "Provisioning secrecy for all users, given the heterogeneity and uncertainty\nof their channel conditions, locations, and the unknown location of the\nattacker/eavesdropper, is challenging and not always feasible. This work takes\nthe first step to guarantee secrecy for all users where a low resolution\nintelligent reflecting surfaces (IRS) is used to enhance legitimate users'\nreception and thwart the potential eavesdropper (Eve) from intercepting. In\nreal-life scenarios, due to hardware limitations of the IRS' passive reflective\nelements (PREs), the use of a full-resolution (continuous) phase shift (CPS) is\nimpractical. In this paper, we thus consider a more practical case where the\nphase shift (PS) is modeled by a low-resolution (quantized) phase shift (QPS)\nwhile addressing the phase shift error (PSE) induced by the imperfect channel\nstate information (CSI). To that end, we aim to maximize the minimum secrecy\nrate (SR) among all users by jointly optimizing the transmitter's beamforming\nvector and the IRS's passive reflective elements (PREs) under\nperfect/imperfect/unknown CSI. The resulting optimization problem is non-convex\nand even more complicated under imperfect/unknown CSI.", "published": "2025-04-07 13:18:03", "link": "http://arxiv.org/abs/2504.05048v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Probabilistic Position-Aided Beam Selection for mmWave MIMO Systems", "abstract": "Millimeter-wave (mmWave) MIMO systems rely on highly directional beamforming\nto overcome severe path loss and ensure robust communication links. However,\nselecting the optimal beam pair efficiently remains a challenge due to the\nlarge search space and the overhead of conventional methods. This paper\nproposes a probabilistic position-aided beam selection approach that exploits\nthe statistical dependence between user equipment (UE) positions and optimal\nbeam indices. We model the underlying joint probability mass function (PMF) of\nthe positions and the beam indices as a low-rank tensor and estimate its\nparameters from training data using Bayesian inference. The estimated model is\nthen used to predict the best (or a list of the top) beam pair indices for new\nUE positions. The proposed method is evaluated using data generated from a\nstate-of-the-art ray tracing simulator and compared with neural network-based\nand fingerprinting approaches. The results show that our approach achieves a\nhigh data rate with fewer training samples and a significantly reduced beam\nsearch space. These advantages render it a promising solution for practical\nmmWave MIMO deployments, reducing the beam search overhead while maintaining a\nreliable connectivity.", "published": "2025-04-07 12:56:51", "link": "http://arxiv.org/abs/2504.05035v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Joint BS Deployment and Power Optimization for Minimum EMF Exposure with RL in Real-World Based Urban Scenario", "abstract": "Conventional base station (BS) deployments typically prioritize coverage,\nquality of service (QoS), or cost reduction, often overlooking electromagnetic\nfield (EMF) exposure. Whereas EMF exposure triggers significant public concern\ndue to its potential health implications, making it crucial to address when\ndeploying BS in densely populated areas. To this end, this paper addresses\nminimizing average EMF exposure while maintaining coverage in a 3D urban\nscenario by jointly optimizing BS deployment and power. To address this,\nfirstly, accurate EMF prediction is essential, as traditional empirical models\nlack the required accuracy, necessitating a deterministic channel model. A\nnovel least-time shoot-and-bounce ray (SBR) ray-launching (RL) algorithm is\ntherefore developed to overcome several limitations of current simulators and\nis validated with real-world measurements. Secondly, to further reduce\ncomputational complexity, unlike using a fixed grid size to discretize the\ntarget area, the adaptive grid refinement (AGR) algorithm is designed with a\nflexible grid to predict the overall EMF exposure. Finally, based on the EMF\nexposure predictions, the Nelder-Mead (NM) method is used in the joint\noptimization, and urban user equipment (UE) distributions are incorporated to\nbetter reflect real-world conditions. When evaluating the benefits of the whole\nprocess, the results are compared against using empirical channel models,\nrevealing notable differences and underestimation of EMF exposure that\nhighlight the importance of considering real-world scenario.", "published": "2025-04-07 12:41:08", "link": "http://arxiv.org/abs/2504.05017v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Low-Rate Semantic Communication with Codebook-based Conditional Generative Models", "abstract": "Generative semantic communication models are reshaping semantic communication\nframeworks by moving beyond pixel-wise optimization to align with human\nperception. However, many existing approaches prioritize image-level perceptual\nquality, often neglecting alignment with downstream tasks, which can lead to\nsuboptimal semantic representation. This paper introduces an Ultra-Low Bitrate\nSemantic Communication (ULBSC) system that employs a conditional generative\nmodel and a learnable condition codebook.By integrating saliency conditions and\nimage-level semantic information, the proposed method enables\nhigh-perceptual-quality and controllable task-oriented image transmission.\nRecognizing shared patterns among objects, we propose a codebook-assisted\ncondition transmission method, integrated with joint source-channel coding\n(JSCC)-based text transmission to establish ULBSC. The codebook serves as a\nknowledge base, reducing communication costs to achieve ultra-low bitrate while\nenhancing robustness against noise and inaccuracies in saliency detection.\nSimulation results indicate that, under ultra-low bitrate conditions with an\naverage compression ratio of 0.57Z%o, the proposed system delivers superior\nvisual quality compared to traditional JSCC techniques and achieves higher\nsaliency similarity between the generated and source images compared to\nstate-of-the-art generative semantic communication methods.", "published": "2025-04-07 12:05:19", "link": "http://arxiv.org/abs/2504.04977v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Grouped Target Tracking and Seamless People Counting with a 24 GHz MIMO FMCW", "abstract": "The problem of radar-based tracking of groups of people moving together and\ncounting their numbers in indoor environments is considered here. A novel\nprocessing pipeline to track groups of people moving together and count their\nnumbers is proposed and validated. The pipeline is specifically designed to\ndeal with frequent changes of direction and stop & go movements typical of\nindoor activities. The proposed approach combines a tracker with a classifier\nto count the number of grouped people; this uses both spatial features\nextracted from range-azimuth maps, and Doppler frequency features extracted\nwith wavelet decomposition. Thus, the pipeline outputs over time both the\nlocation and number of people present. The proposed approach is verified with\nexperimental data collected with a 24 GHz Frequency Modulated Continuous Wave\n(FMCW) radar. It is shown that the proposed method achieves 95.59% accuracy in\ncounting the number of people, and a tracking metric OSPA of 0.338.\nFurthermore, the performance is analyzed as a function of different relevant\nvariables such as feature combinations and scenarios.", "published": "2025-04-07 11:56:03", "link": "http://arxiv.org/abs/2504.04969v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Advanced Codebook Design for SCMA-aided NTNs With Randomly Distributed Users", "abstract": "In this letter, a novel class of sparse codebooks is proposed for sparse code\nmultiple access (SCMA) aided non-terrestrial networks (NTN) with randomly\ndistributed users characterized by Rician fading channels. Specifically, we\nfirst exploit the upper bound of bit error probability (BEP) of an SCMA-aided\nNTN with large-scale fading of different users under Rician fading channels.\nThen, the codebook is designed by employing pulse-amplitude modulation\nconstellation, user-specific rotation and power factors. To further reduce the\noptimization complexity while maintaining the power diversity of different\nusers, an orthogonal layer-assisted joint layer and power assignment strategy\nis proposed. Finally, unlike existing SCMA codebook designs that treat all\nusers as one super-user, we propose to minimize the BEP of the worst user to\nensure user fairness. The simulation results show that the proposed scheme is\ncapable of providing a substantial performance gain over conventional\ncodebooks.", "published": "2025-04-07 11:10:44", "link": "http://arxiv.org/abs/2504.04928v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fault Localisation in Infinite-Dimensional Linear Electrical Networks", "abstract": "We present a novel fault localisation methodology for linear time-invariant\nelectrical networks with infinite-dimensional edge dynamics and uncertain fault\ndynamics. The theory accommodates instability and also bounded propagation\ndelays in the network. The goal is to estimate the location of a fault along a\ngiven network edge, using sensors positioned arbitrarily throughout the\nnetwork. Passive faults of unknown impedance are considered, along with stable\nfaults of known impedance. To illustrate the approach, we tackle a significant\nuse-case: a multi-conductor transmission line, with dynamics modelled by the\nTelegrapher's equation, subject to a line-to-ground fault. Frequency-domain\ninsights are used to reformulate the general fault localisation problem into a\nnon-convex scalar optimisation problem, of which the true fault location is\nguaranteed to be a global minimiser. Numerical experiments are run to quantify\nlocalisation performance over a range of fault resistances.", "published": "2025-04-07 10:40:25", "link": "http://arxiv.org/abs/2504.04910v1", "categories": ["eess.SY", "cs.SY", "eess.SP", "math.DS"], "primary_category": "eess.SY"}
{"title": "Design of a compact low loss 2-way millimetre wave power divider for future communication", "abstract": "In this paper, a rectangular-shaped power divider has been presented\noperating at 27.9 GHz. The power divider has achieved acceptable results for\nimportant parameters such as S11, S12, S21, and S22. The substrate employed for\nthe power divider is Roger 3003 which has a thickness of 1.6 mm. This power\ndivider provides a reflection coefficient of -12.2 dB and an insertion loss of\n3.1 dB at 28 GHz. This ka-band T-junction power divider covers 68% of the\nbandwidth. Dimensions of the ka-band T-junction power divider are 50x80 mm. Due\nto its dimensions and bandwidth this power divider is more suitable for\nmillimetre wave applications like RADAR, beamforming, and 5G applications.", "published": "2025-04-07 10:20:05", "link": "http://arxiv.org/abs/2504.04901v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Asymmetric 4.77 Three-Way Unequal Filtering Power Divider/Combiner for Communication Systems Application", "abstract": "This study presents a novel three-way unequal filtering power\ndivider/combiner, addressing challenges in unequal power distribution while\nincorporating filtering functions in communication systems. Wilkinson power\ndivider (WPD) is the traditional power division approach using\nquarter-wavelength transmission lines [1]. This type of power divider is\npopularly used in communication systems due to its good electrical isolation\nand simple structure. The problem with WPD is that its operation requires the\nuse of an externally connected bandpass filter (BPF) to achieve filtering\nfunctionality. This leads to increased footprint and increased loss\ncoefficients in a system. In contrast to the traditional design approach\ninvolving a BPF, a matching transmission line, and a Wilkinson power divider as\nseparate components, the proposed integrated filtering power divider (FPD)\nconsolidates all three components into a single device, leading to lower\nfootprint and lower loss coefficient in a system. Circuit modelling and\nelectromagnetic (EM) simulations were conducted to ensure alignment between\ntheoretical and practical results. The design demonstrates effective unequal\npower division at the three output ports while maintaining very good filtering\nperformance. Results show a return loss better than 15 dB and a minimum\ninsertion loss of 1.2 dB. The overall size of the device is 32.2 x 50.0 mm.\nThis paper contributes to advancements in power divider design by addressing\nunequal power division challenges and integrating filtering functions. The\nfindings offer a foundation for future developments in advanced power\ndivider/combiner systems, with insights into potential challenges and areas for\nfurther improvements.", "published": "2025-04-07 10:06:59", "link": "http://arxiv.org/abs/2504.04895v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Parallelization is All System Identification Needs: End-to-end Vibration Diagnostics on a multi-core RISC-V edge device", "abstract": "The early detection of structural malfunctions requires the installation of\nreal-time monitoring systems ensuring continuous access to the damage-sensitive\ninformation; nevertheless, it can generate bottlenecks in terms of bandwidth\nand storage. Deploying data reduction techniques at the edge is recognized as a\nproficient solution to reduce the system's network traffic. However, the most\neffective solutions currently employed for the purpose are based on memory and\npower-hungry algorithms, making their embedding on resource-constrained devices\nvery challenging; this is the case of vibration data reduction based on System\nIdentification models. This paper presents PARSY-VDD, a fully optimized\nPArallel end-to-end software framework based on SYstem identification for\nVibration-based Damage Detection, as a suitable solution to perform damage\ndetection at the edge in a time and energy-efficient manner, avoiding streaming\nraw data to the cloud. We evaluate the damage detection capabilities of\nPARSY-VDD with two benchmarks: a bridge and a wind turbine blade, showcasing\nthe robustness of the end-to-end approach. Then, we deploy PARSY-VDD on both\ncommercial single-core and a specific multi-core edge device. We introduce an\narchitecture-agnostic algorithmic optimization for SysId, improving the\nexecution by 90x and reducing the consumption by 85x compared with the\nstate-of-the-art SysId implementation on GAP9. Results show that by utilizing\nthe unique parallel computing capabilities of GAP9, the execution time is\n751{\\mu}s with the high-performance multi-core solution operating at 370MHz and\n0.8V, while the energy consumption is 37{\\mu}J with the low-power solution\noperating at 240MHz and 0.65V. Compared with other single-core implementations\nbased on STM32 microcontrollers, the GAP9 high-performance configuration is 76x\nfaster, while the low-power configuration is 360x more energy efficient.", "published": "2025-04-07 09:51:02", "link": "http://arxiv.org/abs/2504.04884v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Beyond Answers: How LLMs Can Pursue Strategic Thinking in Education", "abstract": "Artificial Intelligence (AI) holds transformative potential in education,\nenabling personalized learning, enhancing inclusivity, and encouraging\ncreativity and curiosity. In this paper, we explore how Large Language Models\n(LLMs) can act as both patient tutors and collaborative partners to enhance\neducation delivery. As tutors, LLMs personalize learning by offering\nstep-by-step explanations and addressing individual needs, making education\nmore inclusive for students with diverse backgrounds or abilities. As\ncollaborators, they expand students' horizons, supporting them in tackling\ncomplex, real-world problems and co-creating innovative projects. However, to\nfully realize these benefits, LLMs must be leveraged not as tools for providing\ndirect solutions but rather to guide students in developing resolving\nstrategies and finding learning paths together. Therefore, a strong emphasis\nshould be placed on educating students and teachers on the successful use of\nLLMs to ensure their effective integration into classrooms. Through practical\nexamples and real-world case studies, this paper illustrates how LLMs can make\neducation more inclusive and engaging while empowering students to reach their\nfull potential.", "published": "2025-04-07 08:09:46", "link": "http://arxiv.org/abs/2504.04815v1", "categories": ["cs.CY", "cs.ET", "eess.SP"], "primary_category": "cs.CY"}
{"title": "Cross-Frame OTFS Parameter Estimation Based On Chinese Remainder Theorem", "abstract": "Orthogonal time-frequency space (OTFS) is a potential waveform for integrated\nsensing and communications (ISAC) systems because it can manage communication\nand sensing metrics in one unified domain, and has better performance in high\nmobility scenarios. In practice, a target might come from far distance or with\nultra-high speed. However, the max unambiguous range and max tolerable velocity\nof OTFS-ISAC system is limited by the unambiguous round-trip delay and Doppler\nshift, which are related to OTFS frame, i.e., time slots and subcarrier\nspacing, respectively. To enlarge the sensing range, a novel OTFS cross-frame\nranging and velocity estimation model as well as its corresponding method based\non the Chinese remainder theorem (CRT) are proposed in this paper. By designing\nco-prime numbers of subcarriers and time slots in different subframes, the\ndifference in the responses of the subframes for a target can be used to\nestimate the distance and velocity of an out-of-range target. Several frame\nstructures are further designed for specific sensing scenarios, such as target\nwith ultra-high speed or at far distance. Simulation results show that the\nproposed method can achieve significantly better performance in NMSE compared\nwith the classic sensing methods under the condition of same time and frequency\nresources.", "published": "2025-04-07 08:05:32", "link": "http://arxiv.org/abs/2504.04811v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Addressing the Curse of Scenario and Task Generalization in AI-6G: A Multi-Modal Paradigm", "abstract": "Existing works on machine learning (ML)-empowered wireless communication\nprimarily focus on monolithic scenarios and single tasks. However, with the\nblooming growth of communication task classes coupled with various task\nrequirements in future 6G systems, this working pattern is obviously\nunsustainable. Therefore, identifying a groundbreaking paradigm that enables a\nuniversal model to solve multiple tasks in the physical layer within diverse\nscenarios is crucial for future system evolution. This paper aims to\nfundamentally address the curse of ML model generalization across diverse\nscenarios and tasks by unleashing multi-modal feature integration capabilities\nin future systems. Given the universality of electromagnetic propagation\ntheory, the communication process is determined by the scattering environment,\nwhich can be more comprehensively characterized by cross-modal perception, thus\nproviding sufficient information for all communication tasks across varied\nenvironments. This fact motivates us to propose a transformative two-stage\nmulti-modal pre-training and downstream task adaptation paradigm...", "published": "2025-04-07 07:43:03", "link": "http://arxiv.org/abs/2504.04797v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Localization and Tracking for Cooperative Users in Multi-RIS-assisted Systems: Theoretical Analysis and Principles of Interpretations", "abstract": "Localization and tracking (LocTrack) are fundamental enablers for a wide\nrange of emerging applications. Reconfigurable intelligent surfaces (RISs) have\nemerged as key components for enhancing the LocTrack performance. This paper\ninvestigates a multi-RIS-assisted multi-user (MRMU) LocTrack system, where\nmultiple RISs collaboratively reflect the position-bearing signals for\ninformation fusion at the base station, leveraging spatial-temporal\ncorrelations in user positions. While studies have shown these correlations\nimprove localization accuracy, their trade-offs with system complexity remain\nunclear. To address this gap, we characterize the effectiveness of\nspatial-temporal correlation priors (STPs) utilization in MRMU LocTrack systems\nusing a metric, termed efficiency of correlation (EoC). To further elucidate\ncorrelation propagation and RIS interactions, we provide a \"correlation\ninformation routing\" interpretation of EoC through random walk theory. EoC\nprovides a principled performance evaluation metric, that enables system\ndesigners to balance localization accuracy enhancement against the increased\ncomplexity. Additionally, we investigate the error propagation phenomenon,\nanalyzing its convergence and asymptotic behavior in MRMU LocTrack systems.\nFinally, we validate the theoretical results through extensive numerical\nsimulations.", "published": "2025-04-07 07:35:41", "link": "http://arxiv.org/abs/2504.04791v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "NoveltyBench: Evaluating Language Models for Humanlike Diversity", "abstract": "Language models have demonstrated remarkable capabilities on standard\nbenchmarks, yet they struggle increasingly from mode collapse, the inability to\ngenerate diverse and novel outputs. Our work introduces NoveltyBench, a\nbenchmark specifically designed to evaluate the ability of language models to\nproduce multiple distinct and high-quality outputs. NoveltyBench utilizes\nprompts curated to elicit diverse answers and filtered real-world user queries.\nEvaluating 20 leading language models, we find that current state-of-the-art\nsystems generate significantly less diversity than human writers. Notably,\nlarger models within a family often exhibit less diversity than their smaller\ncounterparts, challenging the notion that capability on standard benchmarks\ntranslates directly to generative utility. While prompting strategies like\nin-context regeneration can elicit diversity, our findings highlight a\nfundamental lack of distributional diversity in current models, reducing their\nutility for users seeking varied responses and suggesting the need for new\ntraining and evaluation paradigms that prioritize diversity alongside quality.", "published": "2025-04-07 16:14:23", "link": "http://arxiv.org/abs/2504.05228v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging LLMs for Utility-Focused Annotation: Reducing Manual Effort for Retrieval and RAG", "abstract": "Retrieval models typically rely on costly human-labeled query-document\nrelevance annotations for training and evaluation. To reduce this cost and\nleverage the potential of Large Language Models (LLMs) in relevance judgments,\nwe aim to explore whether LLM-generated annotations can effectively replace\nhuman annotations in training retrieval models. Retrieval usually emphasizes\nrelevance, which indicates \"topic-relatedness\" of a document to a query, while\nin RAG, the value of a document (or utility) depends on how it contributes to\nanswer generation. Recognizing this mismatch, some researchers use LLM\nperformance on downstream tasks with documents as labels, but this approach\nrequires manual answers for specific tasks, leading to high costs and limited\ngeneralization. In another line of work, prompting LLMs to select useful\ndocuments as RAG references eliminates the need for human annotation and is not\ntask-specific. If we leverage LLMs' utility judgments to annotate retrieval\ndata, we may retain cross-task generalization without human annotation in\nlarge-scale corpora. Therefore, we investigate utility-focused annotation via\nLLMs for large-scale retriever training data across both in-domain and\nout-of-domain settings on the retrieval and RAG tasks. To reduce the impact of\nlow-quality positives labeled by LLMs, we design a novel loss function, i.e.,\nDisj-InfoNCE. Our experiments reveal that: (1) Retrievers trained on\nutility-focused annotations significantly outperform those trained on human\nannotations in the out-of-domain setting on both tasks, demonstrating superior\ngeneralization capabilities. (2) LLM annotation does not replace human\nannotation in the in-domain setting. However, incorporating just 20%\nhuman-annotated data enables retrievers trained with utility-focused\nannotations to match the performance of models trained entirely with human\nannotations.", "published": "2025-04-07 16:05:52", "link": "http://arxiv.org/abs/2504.05220v2", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Not All Data Are Unlearned Equally", "abstract": "Machine unlearning is concerned with the task of removing knowledge learned\nfrom particular data points from a trained model. In the context of large\nlanguage models (LLMs), unlearning has recently received increased attention,\nparticularly for removing knowledge about named entities from models for\nprivacy purposes. While various approaches have been proposed to address the\nunlearning problem, most existing approaches treat all data points to be\nunlearned equally, i.e., unlearning that Montreal is a city in Canada is\ntreated exactly the same as unlearning the phone number of the first author of\nthis paper. In this work, we show that this all data is equal assumption does\nnot hold for LLM unlearning. We study how the success of unlearning depends on\nthe frequency of the knowledge we want to unlearn in the pre-training data of a\nmodel and find that frequency strongly affects unlearning, i.e., more frequent\nknowledge is harder to unlearn. Additionally, we uncover a misalignment between\nprobability and generation-based evaluations of unlearning and show that this\nproblem worsens as models become larger. Overall, our experiments highlight the\nneed for better evaluation practices and novel methods for LLM unlearning that\ntake the training data of models into account.", "published": "2025-04-07 13:29:02", "link": "http://arxiv.org/abs/2504.05058v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models", "abstract": "Recent advancements in large language models (LLMs) have revolutionized their\nability to handle single-turn tasks, yet real-world applications demand\nsophisticated multi-turn interactions. This survey provides a comprehensive\nreview of recent advancements in evaluating and enhancing multi-turn\ninteractions in LLMs. Focusing on task-specific scenarios, from instruction\nfollowing in diverse domains such as math and coding to complex conversational\nengagements in roleplay, healthcare, education, and even adversarial jailbreak\nsettings, we systematically examine the challenges of maintaining context,\ncoherence, fairness, and responsiveness over prolonged dialogues. The paper\norganizes current benchmarks and datasets into coherent categories that reflect\nthe evolving landscape of multi-turn dialogue evaluation. In addition, we\nreview a range of enhancement methodologies under multi-turn settings,\nincluding model-centric strategies (contextual learning, supervised\nfine-tuning, reinforcement learning, and new architectures), external\nintegration approaches (memory-augmented, retrieval-based methods, and\nknowledge graph), and agent-based techniques for collaborative interactions.\nFinally, we discuss open challenges and propose future directions for research\nto further advance the robustness and effectiveness of multi-turn interactions\nin LLMs. Related resources and papers are available at\nhttps://github.com/yubol-cmu/Awesome-Multi-Turn-LLMs.", "published": "2025-04-07 04:00:08", "link": "http://arxiv.org/abs/2504.04717v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks", "abstract": "We present VAPO, Value-based Augmented Proximal Policy Optimization framework\nfor reasoning models., a novel framework tailored for reasoning models within\nthe value-based paradigm. Benchmarked the AIME 2024 dataset, VAPO, built on the\nQwen 32B pre-trained model, attains a state-of-the-art score of\n$\\mathbf{60.4}$. In direct comparison under identical experimental settings,\nVAPO outperforms the previously reported results of DeepSeek-R1-Zero-Qwen-32B\nand DAPO by more than 10 points. The training process of VAPO stands out for\nits stability and efficiency. It reaches state-of-the-art performance within a\nmere 5,000 steps. Moreover, across multiple independent runs, no training\ncrashes occur, underscoring its reliability. This research delves into long\nchain-of-thought (long-CoT) reasoning using a value-based reinforcement\nlearning framework. We pinpoint three key challenges that plague value-based\nmethods: value model bias, the presence of heterogeneous sequence lengths, and\nthe sparsity of reward signals. Through systematic design, VAPO offers an\nintegrated solution that effectively alleviates these challenges, enabling\nenhanced performance in long-CoT reasoning tasks.", "published": "2025-04-07 14:21:11", "link": "http://arxiv.org/abs/2504.05118v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Taxonomy of Self-Handover", "abstract": "Self-handover, transferring an object between one's own hands, is a common\nbut understudied bimanual action. While it facilitates seamless transitions in\ncomplex tasks, the strategies underlying its execution remain largely\nunexplored. Here, we introduce the first systematic taxonomy of self-handover,\nderived from manual annotation of over 12 hours of cooking activity performed\nby 21 participants. Our analysis reveals that self-handover is not merely a\npassive transition, but a highly coordinated action involving anticipatory\nadjustments by both hands. As a step toward automated analysis of human\nmanipulation, we further demonstrate the feasibility of classifying\nself-handover types using a state-of-the-art vision-language model. These\nfindings offer fresh insights into bimanual coordination, underscoring the role\nof self-handover in enabling smooth task transitions-an ability essential for\nadaptive dual-arm robotics.", "published": "2025-04-07 11:21:42", "link": "http://arxiv.org/abs/2504.04939v2", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Lumina-OmniLV: A Unified Multimodal Framework for General Low-Level Vision", "abstract": "We present Lunima-OmniLV (abbreviated as OmniLV), a universal multimodal\nmulti-task framework for low-level vision that addresses over 100 sub-tasks\nacross four major categories: image restoration, image enhancement,\nweak-semantic dense prediction, and stylization. OmniLV leverages both textual\nand visual prompts to offer flexible and user-friendly interactions. Built on\nDiffusion Transformer (DiT)-based generative priors, our framework supports\narbitrary resolutions -- achieving optimal performance at 1K resolution --\nwhile preserving fine-grained details and high fidelity. Through extensive\nexperiments, we demonstrate that separately encoding text and visual\ninstructions, combined with co-training using shallow feature control, is\nessential to mitigate task ambiguity and enhance multi-task generalization. Our\nfindings also reveal that integrating high-level generative tasks into\nlow-level vision models can compromise detail-sensitive restoration. These\ninsights pave the way for more robust and generalizable low-level vision\nsystems.", "published": "2025-04-07 10:22:00", "link": "http://arxiv.org/abs/2504.04903v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "HypRL: Reinforcement Learning of Control Policies for Hyperproperties", "abstract": "We study the problem of learning control policies for complex tasks whose\nrequirements are given by a hyperproperty. The use of hyperproperties is\nmotivated by their significant power to formally specify requirements of\nmulti-agent systems as well as those that need expressiveness in terms of\nmultiple execution traces (e.g., privacy and fairness). Given a Markov decision\nprocess M with unknown transitions (representing the environment) and a\nHyperLTL formula $\\varphi$, our approach first employs Skolemization to handle\nquantifier alternations in $\\varphi$. We introduce quantitative robustness\nfunctions for HyperLTL to define rewards of finite traces of M with respect to\n$\\varphi$. Finally, we utilize a suitable reinforcement learning algorithm to\nlearn (1) a policy per trace quantifier in $\\varphi$, and (2) the probability\ndistribution of transitions of M that together maximize the expected reward\nand, hence, probability of satisfaction of $\\varphi$ in M. We present a set of\ncase studies on (1) safety-preserving multi-agent path planning, (2) fairness\nin resource allocation, and (3) the post-correspondence problem (PCP).", "published": "2025-04-07 01:58:36", "link": "http://arxiv.org/abs/2504.04675v2", "categories": ["cs.AI", "cs.LO"], "primary_category": "cs.AI"}
{"title": "REWIND: Real-Time Egocentric Whole-Body Motion Diffusion with Exemplar-Based Identity Conditioning", "abstract": "We present REWIND (Real-Time Egocentric Whole-Body Motion Diffusion), a\none-step diffusion model for real-time, high-fidelity human motion estimation\nfrom egocentric image inputs. While an existing method for egocentric\nwhole-body (i.e., body and hands) motion estimation is non-real-time and\nacausal due to diffusion-based iterative motion refinement to capture\ncorrelations between body and hand poses, REWIND operates in a fully causal and\nreal-time manner. To enable real-time inference, we introduce (1) cascaded\nbody-hand denoising diffusion, which effectively models the correlation between\negocentric body and hand motions in a fast, feed-forward manner, and (2)\ndiffusion distillation, which enables high-quality motion estimation with a\nsingle denoising step. Our denoising diffusion model is based on a modified\nTransformer architecture, designed to causally model output motions while\nenhancing generalizability to unseen motion lengths. Additionally, REWIND\noptionally supports identity-conditioned motion estimation when identity prior\nis available. To this end, we propose a novel identity conditioning method\nbased on a small set of pose exemplars of the target identity, which further\nenhances motion estimation quality. Through extensive experiments, we\ndemonstrate that REWIND significantly outperforms the existing baselines both\nwith and without exemplar-based identity conditioning.", "published": "2025-04-07 11:44:11", "link": "http://arxiv.org/abs/2504.04956v2", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Inter-event Interval Microscopy for Event Cameras", "abstract": "Event cameras, an innovative bio-inspired sensor, differ from traditional\ncameras by sensing changes in intensity rather than directly perceiving\nintensity and recording these variations as a continuous stream of \"events\".\nThe intensity reconstruction from these sparse events has long been a\nchallenging problem. Previous approaches mainly focused on transforming\nmotion-induced events into videos or achieving intensity imaging for static\nscenes by integrating modulation devices at the event camera acquisition end.\nIn this paper, for the first time, we achieve event-to-intensity conversion\nusing a static event camera for both static and dynamic scenes in fluorescence\nmicroscopy. Unlike conventional methods that primarily rely on event\nintegration, the proposed Inter-event Interval Microscopy (IEIM) quantifies the\ntime interval between consecutive events at each pixel. With a fixed threshold\nin the event camera, the time interval can precisely represent the intensity.\nAt the hardware level, the proposed IEIM integrates a pulse light modulation\ndevice within a microscope equipped with an event camera, termed Pulse\nModulation-based Event-driven Fluorescence Microscopy. Additionally, we have\ncollected IEIMat dataset under various scenes including high dynamic range and\nhigh-speed scenarios. Experimental results on the IEIMat dataset demonstrate\nthat the proposed IEIM achieves superior spatial and temporal resolution, as\nwell as a higher dynamic range, with lower bandwidth compared to other methods.\nThe code and the IEIMat dataset will be made publicly available.", "published": "2025-04-07 11:05:13", "link": "http://arxiv.org/abs/2504.04924v2", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Vision Transformers with Autoencoders and Explainable AI for Cancer Patient Risk Stratification Using Whole Slide Imaging", "abstract": "Cancer remains one of the leading causes of mortality worldwide,\nnecessitating accurate diagnosis and prognosis. Whole Slide Imaging (WSI) has\nbecome an integral part of clinical workflows with advancements in digital\npathology. While various studies have utilized WSIs, their extracted features\nmay not fully capture the most relevant pathological information, and their\nlack of interpretability limits clinical adoption.\n  In this paper, we propose PATH-X, a framework that integrates Vision\nTransformers (ViT) and Autoencoders with SHAP (Shapley Additive Explanations)\nto enhance model explainability for patient stratification and risk prediction\nusing WSIs from The Cancer Genome Atlas (TCGA). A representative image slice is\nselected from each WSI, and numerical feature embeddings are extracted using\nGoogle's pre-trained ViT. These features are then compressed via an autoencoder\nand used for unsupervised clustering and classification tasks. Kaplan-Meier\nsurvival analysis is applied to evaluate stratification into two and three risk\ngroups. SHAP is used to identify key contributing features, which are mapped\nonto histopathological slices to provide spatial context.\n  PATH-X demonstrates strong performance in breast and glioma cancers, where a\nsufficient number of WSIs enabled robust stratification. However, performance\nin lung cancer was limited due to data availability, emphasizing the need for\nlarger datasets to enhance model reliability and clinical applicability.", "published": "2025-04-07 05:48:42", "link": "http://arxiv.org/abs/2504.04749v2", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Grant-Free Random Access in Uplink LEO Satellite Communications with OFDM", "abstract": "This paper investigates joint device activity detection and channel\nestimation for grant-free random access in Low-earth orbit (LEO) satellite\ncommunications. We consider uplink communications from multiple single-antenna\nterrestrial users to a LEO satellite equipped with a uniform planar array of\nmultiple antennas, where orthogonal frequency division multiplexing (OFDM)\nmodulation is adopted. To combat the severe Doppler shift, a transmission\nscheme is proposed, where the discrete prolate spheroidal basis expansion model\n(DPS-BEM) is introduced to reduce the number of unknown channel parameters.\nThen the vector approximate message passing (VAMP) algorithm is employed to\napproximate the minimum mean square error estimation of the channel, and the\nMarkov random field is combined to capture the channel sparsity. Meanwhile, the\nexpectation-maximization (EM) approach is integrated to learn the\nhyperparameters in priors. Finally, active devices are detected by calculating\nenergy of the estimated channel. Simulation results demonstrate that the\nproposed method outperforms conventional algorithms in terms of activity error\nrate and channel estimation precision.", "published": "2025-04-07 02:35:46", "link": "http://arxiv.org/abs/2504.04686v2", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "PEAKS: Selecting Key Training Examples Incrementally via Prediction Error Anchored by Kernel Similarity", "abstract": "As deep learning continues to be driven by ever-larger datasets,\nunderstanding which examples are most important for generalization has become a\ncritical question. While progress in data selection continues, emerging\napplications require studying this problem in dynamic contexts. To bridge this\ngap, we pose the Incremental Data Selection (IDS) problem, where examples\narrive as a continuous stream, and need to be selected without access to the\nfull data source. In this setting, the learner must incrementally build a\ntraining dataset of predefined size while simultaneously learning the\nunderlying task. We find that in IDS, the impact of a new sample on the model\nstate depends fundamentally on both its geometric relationship in the feature\nspace and its prediction error. Leveraging this insight, we propose PEAKS\n(Prediction Error Anchored by Kernel Similarity), an efficient data selection\nmethod tailored for IDS. Our comprehensive evaluations demonstrate that PEAKS\nconsistently outperforms existing selection strategies. Furthermore, PEAKS\nyields increasingly better performance returns than random selection as\ntraining data size grows on real-world datasets.", "published": "2025-04-07 16:42:09", "link": "http://arxiv.org/abs/2504.05250v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Towards Optimal Heterogeneous Client Sampling in Multi-Model Federated Learning", "abstract": "Federated learning (FL) allows edge devices to collaboratively train models\nwithout sharing local data. As FL gains popularity, clients may need to train\nmultiple unrelated FL models, but communication constraints limit their ability\nto train all models simultaneously. While clients could train FL models\nsequentially, opportunistically having FL clients concurrently train different\nmodels -- termed multi-model federated learning (MMFL) -- can reduce the\noverall training time. Prior work uses simple client-to-model assignments that\ndo not optimize the contribution of each client to each model over the course\nof its training. Prior work on single-model FL shows that intelligent client\nselection can greatly accelerate convergence, but na\\\"ive extensions to MMFL\ncan violate heterogeneous resource constraints at both the server and the\nclients. In this work, we develop a novel convergence analysis of MMFL with\narbitrary client sampling methods, theoretically demonstrating the strengths\nand limitations of previous well-established gradient-based methods. Motivated\nby this analysis, we propose MMFL-LVR, a loss-based sampling method that\nminimizes training variance while explicitly respecting communication limits at\nthe server and reducing computational costs at the clients. We extend this to\nMMFL-StaleVR, which incorporates stale updates for improved efficiency and\nstability, and MMFL-StaleVRE, a lightweight variant suitable for low-overhead\ndeployment. Experiments show our methods improve average accuracy by up to\n19.1% over random sampling, with only a 5.4% gap from the theoretical optimum\n(full client participation).", "published": "2025-04-07 14:43:17", "link": "http://arxiv.org/abs/2504.05138v2", "categories": ["cs.LG", "cs.DC", "I.2.11"], "primary_category": "cs.LG"}
{"title": "Attention-Augmented Inverse Reinforcement Learning with Graph Convolutions for Multi-Agent Task Allocation", "abstract": "Multi-agent task allocation (MATA) plays a vital role in cooperative\nmulti-agent systems, with significant implications for applications such as\nlogistics, search and rescue, and robotic coordination. Although traditional\ndeep reinforcement learning (DRL) methods have been shown to be promising,\ntheir effectiveness is hindered by a reliance on manually designed reward\nfunctions and inefficiencies in dynamic environments. In this paper, an inverse\nreinforcement learning (IRL)-based framework is proposed, in which multi-head\nself-attention (MHSA) and graph attention mechanisms are incorporated to\nenhance reward function learning and task execution efficiency. Expert\ndemonstrations are utilized to infer optimal reward densities, allowing\ndependence on handcrafted designs to be reduced and adaptability to be\nimproved. Extensive experiments validate the superiority of the proposed method\nover widely used multi-agent reinforcement learning (MARL) algorithms in terms\nof both cumulative rewards and task execution efficiency.", "published": "2025-04-07 13:14:45", "link": "http://arxiv.org/abs/2504.05045v2", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Stacking Variational Bayesian Monte Carlo", "abstract": "Variational Bayesian Monte Carlo (VBMC) is a sample-efficient method for\napproximate Bayesian inference with computationally expensive likelihoods.\nWhile VBMC's local surrogate approach provides stable approximations, its\nconservative exploration strategy and limited evaluation budget can cause it to\nmiss regions of complex posteriors. In this work, we introduce Stacking\nVariational Bayesian Monte Carlo (S-VBMC), a method that constructs global\nposterior approximations by merging independent VBMC runs through a principled\nand inexpensive post-processing step. Our approach leverages VBMC's mixture\nposterior representation and per-component evidence estimates, requiring no\nadditional likelihood evaluations while being naturally parallelizable. We\ndemonstrate S-VBMC's effectiveness on two synthetic problems designed to\nchallenge VBMC's exploration capabilities and two real-world applications from\ncomputational neuroscience, showing substantial improvements in posterior\napproximation quality across all cases.", "published": "2025-04-07 12:30:59", "link": "http://arxiv.org/abs/2504.05004v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "TabRep: a Simple and Effective Continuous Representation for Training Tabular Diffusion Models", "abstract": "Diffusion models have been the predominant generative model for tabular data\ngeneration. However, they face the conundrum of modeling under a separate\nversus a unified data representation. The former encounters the challenge of\njointly modeling all multi-modal distributions of tabular data in one model.\nWhile the latter alleviates this by learning a single representation for all\nfeatures, it currently leverages sparse suboptimal encoding heuristics and\nnecessitates additional computation costs. In this work, we address the latter\nby presenting TabRep, a tabular diffusion architecture trained with a unified\ncontinuous representation. To motivate the design of our representation, we\nprovide geometric insights into how the data manifold affects diffusion models.\nThe key attributes of our representation are composed of its density,\nflexibility to provide ample separability for nominal features, and ability to\npreserve intrinsic relationships. Ultimately, TabRep provides a simple yet\neffective approach for training tabular diffusion models under a continuous\ndata manifold. Our results showcase that TabRep achieves superior performance\nacross a broad suite of evaluations. It is the first to synthesize tabular data\nthat exceeds the downstream quality of the original datasets while preserving\nprivacy and remaining computationally efficient.", "published": "2025-04-07 07:44:27", "link": "http://arxiv.org/abs/2504.04798v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Autono: A ReAct-Based Highly Robust Autonomous Agent Framework", "abstract": "This paper proposes a highly robust autonomous agent framework based on the\nReAct paradigm, designed to solve complex tasks through adaptive decision\nmaking and multi-agent collaboration. Unlike traditional frameworks that rely\non fixed workflows generated by LLM-based planners, this framework dynamically\ngenerates next actions during agent execution based on prior trajectories,\nthereby enhancing its robustness. To address potential termination issues\ncaused by adaptive execution paths, I propose a timely abandonment strategy\nincorporating a probabilistic penalty mechanism. For multi-agent collaboration,\nI introduce a memory transfer mechanism that enables shared and dynamically\nupdated memory among agents. The framework's innovative timely abandonment\nstrategy dynamically adjusts the probability of task abandonment via\nprobabilistic penalties, allowing developers to balance conservative and\nexploratory tendencies in agent execution strategies by tuning hyperparameters.\nThis significantly improves adaptability and task execution efficiency in\ncomplex environments. Additionally, agents can be extended through external\ntool integration, supported by modular design and MCP protocol compatibility,\nwhich enables flexible action space expansion. Through explicit division of\nlabor, the multi-agent collaboration mechanism enables agents to focus on\nspecific task components, thereby significantly improving execution efficiency\nand quality.", "published": "2025-04-07 00:45:10", "link": "http://arxiv.org/abs/2504.04650v2", "categories": ["cs.MA", "cs.HC", "I.2.9; I.2.8; I.2.1"], "primary_category": "cs.MA"}
{"title": "Can Large Language Models Match Tutoring System Adaptivity? A Benchmarking Study", "abstract": "Large Language Models (LLMs) hold promise as dynamic instructional aids. Yet,\nit remains unclear whether LLMs can replicate the adaptivity of intelligent\ntutoring systems (ITS)--where student knowledge and pedagogical strategies are\nexplicitly modeled. We propose a prompt variation framework to assess\nLLM-generated instructional moves' adaptivity and pedagogical soundness across\n75 real-world tutoring scenarios from an ITS. We systematically remove key\ncontext components (e.g., student errors and knowledge components) from prompts\nto create variations of each scenario. Three representative LLMs (Llama3-8B,\nLlama3-70B, and GPT-4o) generate 1,350 instructional moves. We use text\nembeddings and randomization tests to measure how the omission of each context\nfeature impacts the LLMs' outputs (adaptivity) and a validated tutor-training\nclassifier to evaluate response quality (pedagogical soundness). Surprisingly,\neven the best-performing model only marginally mimics the adaptivity of ITS.\nSpecifically, Llama3-70B demonstrates statistically significant adaptivity to\nstudent errors. Although Llama3-8B's recommendations receive higher pedagogical\nsoundness scores than the other models, it struggles with instruction-following\nbehaviors, including output formatting. By contrast, GPT-4o reliably adheres to\ninstructions but tends to provide overly direct feedback that diverges from\neffective tutoring, prompting learners with open-ended questions to gauge\nknowledge. Given these results, we discuss how current LLM-based tutoring is\nunlikely to produce learning benefits rivaling known-to-be-effective ITS\ntutoring. Through our open-source benchmarking code, we contribute a\nreproducible method for evaluating LLMs' instructional adaptivity and fidelity.", "published": "2025-04-07 23:57:32", "link": "http://arxiv.org/abs/2504.05570v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "COIG-P: A High-Quality and Large-Scale Chinese Preference Dataset for Alignment with Human Values", "abstract": "Aligning large language models (LLMs) with human preferences has achieved\nremarkable success. However, existing Chinese preference datasets are limited\nby small scale, narrow domain coverage, and lack of rigorous data validation.\nAdditionally, the reliance on human annotators for instruction and response\nlabeling significantly constrains the scalability of human preference datasets.\nTo address these challenges, we design an LLM-based Chinese preference dataset\nannotation pipeline with no human intervention. Specifically, we crawled and\ncarefully filtered 92k high-quality Chinese queries and employed 15 mainstream\nLLMs to generate and score chosen-rejected response pairs. Based on it, we\nintroduce COIG-P (Chinese Open Instruction Generalist - Preference), a\nhigh-quality, large-scale Chinese preference dataset, comprises 1,009k Chinese\npreference pairs spanning 6 diverse domains: Chat, Code, Math, Logic, Novel,\nand Role. Building upon COIG-P, to reduce the overhead of using LLMs for\nscoring, we trained a 8B-sized Chinese Reward Model (CRM) and meticulously\nconstructed a Chinese Reward Benchmark (CRBench). Evaluation results based on\nAlignBench \\citep{liu2024alignbenchbenchmarkingchinesealignment} show that that\nCOIG-P significantly outperforms other Chinese preference datasets, and it\nbrings significant performance improvements ranging from 2% to 12% for the\nQwen2/2.5 and Infinity-Instruct-3M-0625 model series, respectively. The results\non CRBench demonstrate that our CRM has a strong and robust scoring ability. We\napply it to filter chosen-rejected response pairs in a test split of COIG-P,\nand our experiments show that it is comparable to GPT-4o in identifying\nlow-quality samples while maintaining efficiency and cost-effectiveness. Our\ncodes and data are released in\nhttps://github.com/multimodal-art-projection/COIG-P.", "published": "2025-04-07 22:15:51", "link": "http://arxiv.org/abs/2504.05535v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging Industrial Expertise and XR with LLM-Powered Conversational Agents", "abstract": "This paper introduces a novel integration of Retrieval-Augmented Generation\n(RAG) enhanced Large Language Models (LLMs) with Extended Reality (XR)\ntechnologies to address knowledge transfer challenges in industrial\nenvironments. The proposed system embeds domain-specific industrial knowledge\ninto XR environments through a natural language interface, enabling hands-free,\ncontext-aware expert guidance for workers. We present the architecture of the\nproposed system consisting of an LLM Chat Engine with dynamic tool\norchestration and an XR application featuring voice-driven interaction.\nPerformance evaluation of various chunking strategies, embedding models, and\nvector databases reveals that semantic chunking, balanced embedding models, and\nefficient vector stores deliver optimal performance for industrial knowledge\nretrieval. The system's potential is demonstrated through early implementation\nin multiple industrial use cases, including robotic assembly, smart\ninfrastructure maintenance, and aerospace component servicing. Results indicate\npotential for enhancing training efficiency, remote assistance capabilities,\nand operational guidance in alignment with Industry 5.0's human-centric and\nresilient approach to industrial development.", "published": "2025-04-07 22:02:19", "link": "http://arxiv.org/abs/2504.05527v1", "categories": ["cs.CL", "cs.AI", "68T50, 68T40, 68U20, 68U35", "H.5.1; I.2.7; I.2.11; H.3.3; H.5.2; C.3"], "primary_category": "cs.CL"}
{"title": "Pretraining Language Models for Diachronic Linguistic Change Discovery", "abstract": "Large language models (LLMs) have shown potential as tools for scientific\ndiscovery. This has engendered growing interest in their use in humanistic\ndisciplines, such as historical linguistics and literary studies. These fields\noften construct arguments on the basis of delineations like genre, or more\ninflexibly, time period. Although efforts have been made to restrict inference\nto specific domains via fine-tuning or model editing, we posit that the only\ntrue guarantee is domain-restricted pretraining -- typically, a data- and\ncompute-expensive proposition.\n  We show that efficient pretraining techniques can produce useful models over\ncorpora too large for easy manual inspection but too small for \"typical\" LLM\napproaches. We employ a novel date-attribution pipeline in order to obtain a\ntemporally-segmented dataset of five 10-million-word slices. We train two\ncorresponding five-model batteries over these corpus segments, efficient\npretraining and Llama3-8B parameter efficiently finetuned.\n  We find that the pretrained models are faster to train than the finetuned\nbaselines and that they better respect the historical divisions of our corpus.\nEmphasizing speed and precision over a-historical comprehensiveness enables a\nnumber of novel approaches to hypothesis discovery and testing in our target\nfields. Taking up diachronic linguistics as a testbed, we show that our method\nenables the detection of a diverse set of phenomena, including en masse lexical\nchange, non-lexical (grammatical and morphological) change, and word sense\nintroduction/obsolescence. We provide a ready-to-use pipeline that allows\nextension of our approach to other target fields with only minimal adaptation.", "published": "2025-04-07 21:51:32", "link": "http://arxiv.org/abs/2504.05523v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Reinforcement Finetuning via Adaptive Curriculum Learning", "abstract": "Reinforcement finetuning (RFT) has shown great potential for enhancing the\nmathematical reasoning capabilities of large language models (LLMs), but it is\noften sample- and compute-inefficient, requiring extensive training. In this\nwork, we introduce AdaRFT (Adaptive Curriculum Reinforcement Finetuning), a\nmethod that significantly improves both the efficiency and final accuracy of\nRFT through adaptive curriculum learning. AdaRFT dynamically adjusts the\ndifficulty of training problems based on the model's recent reward signals,\nensuring that the model consistently trains on tasks that are challenging but\nsolvable. This adaptive sampling strategy accelerates learning by maintaining\nan optimal difficulty range, avoiding wasted computation on problems that are\ntoo easy or too hard. AdaRFT requires only a lightweight extension to standard\nRFT algorithms like Proximal Policy Optimization (PPO), without modifying the\nreward function or model architecture. Experiments on competition-level math\ndatasets-including AMC, AIME, and IMO-style problems-demonstrate that AdaRFT\nsignificantly improves both training efficiency and reasoning performance. We\nevaluate AdaRFT across multiple data distributions and model sizes, showing\nthat it reduces the number of training steps by up to 2x and improves accuracy\nby a considerable margin, offering a more scalable and effective RFT framework.", "published": "2025-04-07 21:31:31", "link": "http://arxiv.org/abs/2504.05520v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Evaluating the Generalization Capabilities of Large Language Models on Code Reasoning", "abstract": "We assess how the code reasoning abilities of large language models (LLMs)\ngeneralize to different kinds of programs. We present techniques for obtaining\nin- and out-of-distribution programs with different characteristics: code\nsampled from a domain-specific language, code automatically generated by an\nLLM, code collected from competitive programming contests, and mutated versions\nof these programs. We also present an experimental methodology for evaluating\nLLM generalization by comparing their performance on these programs. We perform\nan extensive evaluation across 10 state-of-the-art models from the past year,\nobtaining insights into their generalization capabilities over time and across\ndifferent classes of programs. Our results highlight that while earlier models\nexhibit behavior consistent with pattern matching, the latest models exhibit\nstrong generalization abilities on code reasoning.", "published": "2025-04-07 21:25:31", "link": "http://arxiv.org/abs/2504.05518v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "ChartQAPro: A More Diverse and Challenging Benchmark for Chart Question Answering", "abstract": "Charts are ubiquitous, as people often use them to analyze data, answer\nquestions, and discover critical insights. However, performing complex\nanalytical tasks with charts requires significant perceptual and cognitive\neffort. Chart Question Answering (CQA) systems automate this process by\nenabling models to interpret and reason with visual representations of data.\nHowever, existing benchmarks like ChartQA lack real-world diversity and have\nrecently shown performance saturation with modern large vision-language models\n(LVLMs). To address these limitations, we introduce ChartQAPro, a new benchmark\nthat includes 1,341 charts from 157 diverse sources, spanning various chart\ntypes, including infographics and dashboards, and featuring 1,948 questions in\nvarious types, such as multiple-choice, conversational, hypothetical, and\nunanswerable questions, to better reflect real-world challenges. Our\nevaluations with 21 models show a substantial performance drop for LVLMs on\nChartQAPro; e.g., Claude Sonnet 3.5 scores 90.5% on ChartQA but only 55.81% on\nChartQAPro, underscoring the complexity of chart reasoning. We complement our\nfindings with detailed error analyses and ablation studies, identifying key\nchallenges and opportunities for advancing LVLMs in chart understanding and\nreasoning. We release ChartQAPro at https://github.com/vis-nlp/ChartQAPro.", "published": "2025-04-07 21:05:06", "link": "http://arxiv.org/abs/2504.05506v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Hypothesis Generation for Scientific Discovery in the Era of Large Language Models", "abstract": "Hypothesis generation is a fundamental step in scientific discovery, yet it\nis increasingly challenged by information overload and disciplinary\nfragmentation. Recent advances in Large Language Models (LLMs) have sparked\ngrowing interest in their potential to enhance and automate this process. This\npaper presents a comprehensive survey of hypothesis generation with LLMs by (i)\nreviewing existing methods, from simple prompting techniques to more complex\nframeworks, and proposing a taxonomy that categorizes these approaches; (ii)\nanalyzing techniques for improving hypothesis quality, such as novelty boosting\nand structured reasoning; (iii) providing an overview of evaluation strategies;\nand (iv) discussing key challenges and future directions, including multimodal\nintegration and human-AI collaboration. Our survey aims to serve as a reference\nfor researchers exploring LLMs for hypothesis generation.", "published": "2025-04-07 20:44:33", "link": "http://arxiv.org/abs/2504.05496v1", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "GraphRAFT: Retrieval Augmented Fine-Tuning for Knowledge Graphs on Graph Databases", "abstract": "Large language models have shown remarkable language processing and reasoning\nability but are prone to hallucinate when asked about private data.\nRetrieval-augmented generation (RAG) retrieves relevant data that fit into an\nLLM's context window and prompts the LLM for an answer. GraphRAG extends this\napproach to structured Knowledge Graphs (KGs) and questions regarding entities\nmultiple hops away. The majority of recent GraphRAG methods either overlook the\nretrieval step or have ad hoc retrieval processes that are abstract or\ninefficient. This prevents them from being adopted when the KGs are stored in\ngraph databases supporting graph query languages. In this work, we present\nGraphRAFT, a retrieve-and-reason framework that finetunes LLMs to generate\nprovably correct Cypher queries to retrieve high-quality subgraph contexts and\nproduce accurate answers. Our method is the first such solution that can be\ntaken off-the-shelf and used on KGs stored in native graph DBs. Benchmarks\nsuggest that our method is sample-efficient and scales with the availability of\ntraining data. Our method achieves significantly better results than all\nstate-of-the-art models across all four standard metrics on two challenging\nQ\\&As on large text-attributed KGs.", "published": "2025-04-07 20:16:22", "link": "http://arxiv.org/abs/2504.05478v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "PreSumm: Predicting Summarization Performance Without Summarizing", "abstract": "Despite recent advancements in automatic summarization, state-of-the-art\nmodels do not summarize all documents equally well, raising the question: why?\nWhile prior research has extensively analyzed summarization models, little\nattention has been given to the role of document characteristics in influencing\nsummarization performance. In this work, we explore two key research questions.\nFirst, do documents exhibit consistent summarization quality across multiple\nsystems? If so, can we predict a document's summarization performance without\ngenerating a summary? We answer both questions affirmatively and introduce\nPreSumm, a novel task in which a system predicts summarization performance\nbased solely on the source document. Our analysis sheds light on common\nproperties of documents with low PreSumm scores, revealing that they often\nsuffer from coherence issues, complex content, or a lack of a clear main theme.\nIn addition, we demonstrate PreSumm's practical utility in two key\napplications: improving hybrid summarization workflows by identifying documents\nthat require manual summarization and enhancing dataset quality by filtering\noutliers and noisy documents. Overall, our findings highlight the critical role\nof document properties in summarization performance and offer insights into the\nlimitations of current systems that could serve as the basis for future\nimprovements.", "published": "2025-04-07 18:43:00", "link": "http://arxiv.org/abs/2504.05420v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reasoning Models Know When They're Right: Probing Hidden States for Self-Verification", "abstract": "Reasoning models have achieved remarkable performance on tasks like math and\nlogical reasoning thanks to their ability to search during reasoning. However,\nthey still suffer from overthinking, often performing unnecessary reasoning\nsteps even after reaching the correct answer. This raises the question: can\nmodels evaluate the correctness of their intermediate answers during reasoning?\nIn this work, we study whether reasoning models encode information about answer\ncorrectness through probing the model's hidden states. The resulting probe can\nverify intermediate answers with high accuracy and produces highly calibrated\nscores. Additionally, we find models' hidden states encode correctness of\nfuture answers, enabling early prediction of the correctness before the\nintermediate answer is fully formulated. We then use the probe as a verifier to\ndecide whether to exit reasoning at intermediate answers during inference,\nreducing the number of inference tokens by 24\\% without compromising\nperformance. These findings confirm that reasoning models do encode a notion of\ncorrectness yet fail to exploit it, revealing substantial untapped potential to\nenhance their efficiency.", "published": "2025-04-07 18:42:01", "link": "http://arxiv.org/abs/2504.05419v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Less but Better: Parameter-Efficient Fine-Tuning of Large Language Models for Personality Detection", "abstract": "Personality detection automatically identifies an individual's personality\nfrom various data sources, such as social media texts. However, as the\nparameter scale of language models continues to grow, the computational cost\nbecomes increasingly difficult to manage. Fine-tuning also grows more complex,\nmaking it harder to justify the effort and reliably predict outcomes. We\nintroduce a novel parameter-efficient fine-tuning framework, PersLLM, to\naddress these challenges. In PersLLM, a large language model (LLM) extracts\nhigh-dimensional representations from raw data and stores them in a dynamic\nmemory layer. PersLLM then updates the downstream layers with a replaceable\noutput network, enabling flexible adaptation to various personality detection\nscenarios. By storing the features in the memory layer, we eliminate the need\nfor repeated complex computations by the LLM. Meanwhile, the lightweight output\nnetwork serves as a proxy for evaluating the overall effectiveness of the\nframework, improving the predictability of results. Experimental results on key\nbenchmark datasets like Kaggle and Pandora show that PersLLM significantly\nreduces computational cost while maintaining competitive performance and strong\nadaptability.", "published": "2025-04-07 18:30:39", "link": "http://arxiv.org/abs/2504.05411v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fast Controlled Generation from Language Models with Adaptive Weighted Rejection Sampling", "abstract": "The dominant approach to generating from language models subject to some\nconstraint is locally constrained decoding (LCD), incrementally sampling tokens\nat each time step such that the constraint is never violated. Typically, this\nis achieved through token masking: looping over the vocabulary and excluding\nnon-conforming tokens. There are two important problems with this approach. (i)\nEvaluating the constraint on every token can be prohibitively expensive -- LM\nvocabularies often exceed $100,000$ tokens. (ii) LCD can distort the global\ndistribution over strings, sampling tokens based only on local information,\neven if they lead down dead-end paths. This work introduces a new algorithm\nthat addresses both these problems. First, to avoid evaluating a constraint on\nthe full vocabulary at each step of generation, we propose an adaptive\nrejection sampling algorithm that typically requires orders of magnitude fewer\nconstraint evaluations. Second, we show how this algorithm can be extended to\nproduce low-variance, unbiased estimates of importance weights at a very small\nadditional cost -- estimates that can be soundly used within previously\nproposed sequential Monte Carlo algorithms to correct for the myopic behavior\nof local constraint enforcement. Through extensive empirical evaluation in\ntext-to-SQL, molecular synthesis, goal inference, pattern matching, and JSON\ndomains, we show that our approach is superior to state-of-the-art baselines,\nsupporting a broader class of constraints and improving both runtime and\nperformance. Additional theoretical and empirical analyses show that our\nmethod's runtime efficiency is driven by its dynamic use of computation,\nscaling with the divergence between the unconstrained and constrained LM, and\nas a consequence, runtime improvements are greater for better models.", "published": "2025-04-07 18:30:18", "link": "http://arxiv.org/abs/2504.05410v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SciSciGPT: Advancing Human-AI Collaboration in the Science of Science", "abstract": "The increasing availability of large-scale datasets has fueled rapid progress\nacross many scientific fields, creating unprecedented opportunities for\nresearch and discovery while posing significant analytical challenges. Recent\nadvances in large language models (LLMs) and AI agents have opened new\npossibilities for human-AI collaboration, offering powerful tools to navigate\nthis complex research landscape. In this paper, we introduce SciSciGPT, an\nopen-source, prototype AI collaborator that uses the science of science as a\ntestbed to explore the potential of LLM-powered research tools. SciSciGPT\nautomates complex workflows, supports diverse analytical approaches,\naccelerates research prototyping and iteration, and facilitates\nreproducibility. Through case studies, we demonstrate its ability to streamline\na wide range of empirical and analytical research tasks while highlighting its\nbroader potential to advance research. We further propose an LLM Agent\ncapability maturity model for human-AI collaboration, envisioning a roadmap to\nfurther improve and expand upon frameworks like SciSciGPT. As AI capabilities\ncontinue to evolve, frameworks like SciSciGPT may play increasingly pivotal\nroles in scientific research and discovery, unlocking further opportunities. At\nthe same time, these new advances also raise critical challenges, from ensuring\ntransparency and ethical use to balancing human and AI contributions.\nAddressing these issues may shape the future of scientific inquiry and inform\nhow we train the next generation of scientists to thrive in an increasingly\nAI-integrated research ecosystem.", "published": "2025-04-07 23:19:39", "link": "http://arxiv.org/abs/2504.05559v1", "categories": ["cs.AI", "I.2; J.4"], "primary_category": "cs.AI"}
{"title": "Path Database Guidance for Motion Planning", "abstract": "One approach to using prior experience in robot motion planning is to store\nsolutions to previously seen problems in a database of paths. Methods that use\nsuch databases are characterized by how they query for a path and how they use\nqueries given a new problem. In this work we present a new method, Path\nDatabase Guidance (PDG), which innovates on existing work in two ways. First,\nwe use the database to compute a heuristic for determining which nodes of a\nsearch tree to expand, in contrast to prior work which generally pastes the\n(possibly transformed) queried path or uses it to bias a sampling distribution.\nWe demonstrate that this makes our method more easily composable with other\nsearch methods by dynamically interleaving exploration according to a baseline\nalgorithm with exploitation of the database guidance. Second, in contrast to\nother methods that treat the database as a single fixed prior, our database\n(and thus our queried heuristic) updates as we search the implicitly defined\nrobot configuration space. We experimentally demonstrate the effectiveness of\nPDG in a variety of explicitly defined environment distributions in simulation.", "published": "2025-04-07 23:00:31", "link": "http://arxiv.org/abs/2504.05550v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Towards Efficient Real-Time Video Motion Transfer via Generative Time Series Modeling", "abstract": "We propose a deep learning framework designed to significantly optimize\nbandwidth for motion-transfer-enabled video applications, including video\nconferencing, virtual reality interactions, health monitoring systems, and\nvision-based real-time anomaly detection. To capture complex motion\neffectively, we utilize the First Order Motion Model (FOMM), which encodes\ndynamic objects by detecting keypoints and their associated local affine\ntransformations. These keypoints are identified using a self-supervised\nkeypoint detector and arranged into a time series corresponding to the\nsuccessive frames. Forecasting is performed on these keypoints by integrating\ntwo advanced generative time series models into the motion transfer pipeline,\nnamely the Variational Recurrent Neural Network (VRNN) and the Gated Recurrent\nUnit with Normalizing Flow (GRU-NF). The predicted keypoints are subsequently\nsynthesized into realistic video frames using an optical flow estimator paired\nwith a generator network, thereby facilitating accurate video forecasting and\nenabling efficient, low-frame-rate video transmission. We validate our results\nacross three datasets for video animation and reconstruction using the\nfollowing metrics: Mean Absolute Error, Joint Embedding Predictive Architecture\nEmbedding Distance, Structural Similarity Index, and Average Pair-wise\nDisplacement. Our results confirm that by utilizing the superior reconstruction\nproperty of the Variational Autoencoder, the VRNN integrated FOMM excels in\napplications involving multi-step ahead forecasts such as video conferencing.\nOn the other hand, by leveraging the Normalizing Flow architecture for exact\nlikelihood estimation, and enabling efficient latent space sampling, the GRU-NF\nbased FOMM exhibits superior capabilities for producing diverse future samples\nwhile maintaining high visual quality for tasks like real-time video-based\nanomaly detection.", "published": "2025-04-07 22:21:54", "link": "http://arxiv.org/abs/2504.05537v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "FORCE: Feature-Oriented Representation with Clustering and Explanation", "abstract": "Learning about underlying patterns in data using latent unobserved structures\nto improve the accuracy of predictive models has become an active avenue of\ndeep learning research. Most approaches cluster the original features to\ncapture certain latent structures. However, the information gained in the\nprocess can often be implicitly derived by sufficiently complex models. Thus,\nsuch approaches often provide minimal benefits. We propose a SHAP (Shapley\nAdditive exPlanations) based supervised deep learning framework FORCE which\nrelies on two-stage usage of SHAP values in the neural network architecture,\n(i) an additional latent feature to guide model training, based on clustering\nSHAP values, and (ii) initiating an attention mechanism within the architecture\nusing latent information. This approach gives a neural network an indication\nabout the effect of unobserved values that modify feature importance for an\nobservation. The proposed framework is evaluated on three real life datasets.\nOur results demonstrate that FORCE led to dramatic improvements in overall\nperformance as compared to networks that did not incorporate the latent feature\nand attention framework (e.g., F1 score for presence of heart disease 0.80 vs\n0.72). Using cluster assignments and attention based on SHAP values guides deep\nlearning, enhancing latent pattern learning and overall discriminative\ncapability.", "published": "2025-04-07 22:05:50", "link": "http://arxiv.org/abs/2504.05530v1", "categories": ["cs.LG", "cs.AI", "stat.AP", "I.2.6"], "primary_category": "cs.LG"}
{"title": "Deep Reinforcement Learning Algorithms for Option Hedging", "abstract": "Dynamic hedging is a financial strategy that consists in periodically\ntransacting one or multiple financial assets to offset the risk associated with\na correlated liability. Deep Reinforcement Learning (DRL) algorithms have been\nused to find optimal solutions to dynamic hedging problems by framing them as\nsequential decision-making problems. However, most previous work assesses the\nperformance of only one or two DRL algorithms, making an objective comparison\nacross algorithms difficult. In this paper, we compare the performance of eight\nDRL algorithms in the context of dynamic hedging; Monte Carlo Policy Gradient\n(MCPG), Proximal Policy Optimization (PPO), along with four variants of Deep\nQ-Learning (DQL) and two variants of Deep Deterministic Policy Gradient (DDPG).\nTwo of these variants represent a novel application to the task of dynamic\nhedging. In our experiments, we use the Black-Scholes delta hedge as a baseline\nand simulate the dataset using a GJR-GARCH(1,1) model. Results show that MCPG,\nfollowed by PPO, obtain the best performance in terms of the root\nsemi-quadratic penalty. Moreover, MCPG is the only algorithm to outperform the\nBlack-Scholes delta hedge baseline with the allotted computational budget,\npossibly due to the sparsity of rewards in our environment.", "published": "2025-04-07 21:32:14", "link": "http://arxiv.org/abs/2504.05521v1", "categories": ["q-fin.CP", "cs.AI", "cs.CE"], "primary_category": "q-fin.CP"}
{"title": "Prism: Dynamic and Flexible Benchmarking of LLMs Code Generation with Monte Carlo Tree Search", "abstract": "The rapid advancement of Large Language Models (LLMs) has outpaced\ntraditional evaluation methods. Static benchmarks fail to capture the depth and\nbreadth of LLM capabilities and eventually become obsolete, while most dynamic\napproaches either rely too heavily on LLM-based evaluation or remain\nconstrained by predefined test sets. We introduce Prism, a flexible, dynamic\nbenchmarking framework designed for comprehensive LLM assessment. Prism builds\non three key components: (1) a tree-based state representation that models\nevaluation as a Markov Decision Process, (2) a Monte Carlo Tree Search\nalgorithm adapted to uncover challenging evaluation scenarios, and (3) a\nmulti-agent evaluation pipeline that enables simultaneous assessment of diverse\ncapabilities. To ensure robust evaluation, Prism integrates structural\nmeasurements of tree exploration patterns with performance metrics across\ndifficulty levels, providing detailed diagnostics of error patterns, test\ncoverage, and solution approaches. Through extensive experiments on five\nstate-of-the-art LLMs, we analyze how model architecture and scale influence\ncode generation performance across varying task difficulties. Our results\ndemonstrate Prism's effectiveness as a dynamic benchmark that evolves with\nmodel advancements while offering deeper insights into their limitations.", "published": "2025-04-07 20:53:18", "link": "http://arxiv.org/abs/2504.05500v1", "categories": ["cs.AI", "cs.LG", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Large-Scale Classification of Shortwave Communication Signals with Machine Learning", "abstract": "This paper presents a deep learning approach to the classification of 160\nshortwave radio signals. It addresses the typical challenges of the shortwave\nspectrum, which are the large number of different signal types, the presence of\nvarious analog modulations and ionospheric propagation. As a classifier a deep\nconvolutional neural network is used, that is trained to recognize 160 typical\nshortwave signal classes. The approach is blind and therefore does not require\npreknowledge or special preprocessing of the signal and no manual design of\ndiscriminative features for each signal class. The network is trained on a\nlarge number of synthetically generated signals and high quality recordings.\nFinally, the network is evaluated on real-world radio signals obtained from\nglobally deployed receiver hardware and achieves up to 90% accuracy for an\nobservation time of only 1 second.", "published": "2025-04-07 19:45:08", "link": "http://arxiv.org/abs/2504.05455v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
{"title": "GraphPINE: Graph Importance Propagation for Interpretable Drug Response Prediction", "abstract": "Explainability is necessary for many tasks in biomedical research. Recent\nexplainability methods have focused on attention, gradient, and Shapley value.\nThese do not handle data with strong associated prior knowledge and fail to\nconstrain explainability results based on known relationships between\npredictive features.\n  We propose GraphPINE, a graph neural network (GNN) architecture leveraging\ndomain-specific prior knowledge to initialize node importance optimized during\ntraining for drug response prediction. Typically, a manual post-prediction step\nexamines literature (i.e., prior knowledge) to understand returned predictive\nfeatures. While node importance can be obtained for gradient and attention\nafter prediction, node importance from these methods lacks complementary prior\nknowledge; GraphPINE seeks to overcome this limitation. GraphPINE differs from\nother GNN gating methods by utilizing an LSTM-like sequential format. We\nintroduce an importance propagation layer that unifies 1) updates for feature\nmatrix and node importance and 2) uses GNN-based graph propagation of feature\nvalues. This initialization and updating mechanism allows for informed feature\nlearning and improved graph representation.\n  We apply GraphPINE to cancer drug response prediction using drug screening\nand gene data collected for over 5,000 gene nodes included in a gene-gene graph\nwith a drug-target interaction (DTI) graph for initial importance. The\ngene-gene graph and DTIs were obtained from curated sources and weighted by\narticle count discussing relationships between drugs and genes. GraphPINE\nachieves a PR-AUC of 0.894 and ROC-AUC of 0.796 across 952 drugs. Code is\navailable at https://anonymous.4open.science/r/GraphPINE-40DE.", "published": "2025-04-07 19:42:12", "link": "http://arxiv.org/abs/2504.05454v1", "categories": ["cs.LG", "cs.AI", "cs.CE", "q-bio.GN", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "A Behavior-Based Knowledge Representation Improves Prediction of Players' Moves in Chess by 25%", "abstract": "Predicting player behavior in strategic games, especially complex ones like\nchess, presents a significant challenge. The difficulty arises from several\nfactors. First, the sheer number of potential outcomes stemming from even a\nsingle position, starting from the initial setup, makes forecasting a player's\nnext move incredibly complex. Second, and perhaps even more challenging, is the\ninherent unpredictability of human behavior. Unlike the optimized play of\nengines, humans introduce a layer of variability due to differing playing\nstyles and decision-making processes. Each player approaches the game with a\nunique blend of strategic thinking, tactical awareness, and psychological\ntendencies, leading to diverse and often unexpected actions. This stylistic\nvariation, combined with the capacity for creativity and even irrational moves,\nmakes predicting human play difficult. Chess, a longstanding benchmark of\nartificial intelligence research, has seen significant advancements in tools\nand automation. Engines like Deep Blue, AlphaZero, and Stockfish can defeat\neven the most skilled human players. However, despite their exceptional ability\nto outplay top-level grandmasters, predicting the moves of non-grandmaster\nplayers, who comprise most of the global chess community -- remains complicated\nfor these engines. This paper proposes a novel approach combining expert\nknowledge with machine learning techniques to predict human players' next\nmoves. By applying feature engineering grounded in domain expertise, we seek to\nuncover the patterns in the moves of intermediate-level chess players,\nparticularly during the opening phase of the game. Our methodology offers a\npromising framework for anticipating human behavior, advancing both the fields\nof AI and human-computer interaction.", "published": "2025-04-07 18:49:00", "link": "http://arxiv.org/abs/2504.05425v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Safe Automated Refactoring for Efficient Migration of Imperative Deep Learning Programs to Graph Execution", "abstract": "Efficiency is essential to support responsiveness w.r.t. ever-growing\ndatasets, especially for Deep Learning (DL) systems. DL frameworks have\ntraditionally embraced deferred execution-style DL code -- supporting symbolic,\ngraph-based Deep Neural Network (DNN) computation. While scalable, such\ndevelopment is error-prone, non-intuitive, and difficult to debug.\nConsequently, more natural, imperative DL frameworks encouraging eager\nexecution have emerged at the expense of run-time performance. Though hybrid\napproaches aim for the \"best of both worlds,\" using them effectively requires\nsubtle considerations to make code amenable to safe, accurate, and efficient\ngraph execution. We present an automated refactoring approach that assists\ndevelopers in specifying whether their otherwise eagerly-executed imperative DL\ncode could be reliably and efficiently executed as graphs while preserving\nsemantics. The approach, based on a novel imperative tensor analysis,\nautomatically determines when it is safe and potentially advantageous to\nmigrate imperative DL code to graph execution. The approach is implemented as a\nPyDev Eclipse IDE plug-in that integrates the WALA Ariadne analysis framework\nand evaluated on 19 Python projects consisting of 132.05 KLOC. We found that\n326 of 766 candidate functions (42.56%) were refactorable, and an average\nspeedup of 2.16 on performance tests was observed. The results indicate that\nthe approach is useful in optimizing imperative DL code to its full potential.", "published": "2025-04-07 18:48:43", "link": "http://arxiv.org/abs/2504.05424v1", "categories": ["cs.SE", "cs.AI", "cs.PL", "D.2.7; C.4; D.3.4; I.2.6"], "primary_category": "cs.SE"}
{"title": "SoK: Frontier AI's Impact on the Cybersecurity Landscape", "abstract": "As frontier AI advances rapidly, understanding its impact on cybersecurity\nand inherent risks is essential to ensuring safe AI evolution (e.g., guiding\nrisk mitigation and informing policymakers). While some studies review AI\napplications in cybersecurity, none of them comprehensively discuss AI's future\nimpacts or provide concrete recommendations for navigating its safe and secure\nusage. This paper presents an in-depth analysis of frontier AI's impact on\ncybersecurity and establishes a systematic framework for risk assessment and\nmitigation. To this end, we first define and categorize the marginal risks of\nfrontier AI in cybersecurity and then systemically analyze the current and\nfuture impacts of frontier AI in cybersecurity, qualitatively and\nquantitatively. We also discuss why frontier AI likely benefits attackers more\nthan defenders in the short term from equivalence classes, asymmetry, and\neconomic impact. Next, we explore frontier AI's impact on future software\nsystem development, including enabling complex hybrid systems while introducing\nnew risks. Based on our findings, we provide security recommendations,\nincluding constructing fine-grained benchmarks for risk assessment, designing\nAI agents for defenses, building security mechanisms and provable defenses for\nhybrid systems, enhancing pre-deployment security testing and transparency, and\nstrengthening defenses for users. Finally, we present long-term research\nquestions essential for understanding AI's future impacts and unleashing its\ndefensive capabilities.", "published": "2025-04-07 18:25:18", "link": "http://arxiv.org/abs/2504.05408v1", "categories": ["cs.CR", "cs.AI", "cs.CY"], "primary_category": "cs.CR"}
{"title": "TRATSS: Transformer-Based Task Scheduling System for Autonomous Vehicles", "abstract": "Efficient scheduling remains a critical challenge in various domains,\nrequiring solutions to complex NP-hard optimization problems to achieve optimal\nresource allocation and maximize productivity. In this paper, we introduce a\nframework called Transformer-Based Task Scheduling System (TRATSS), designed to\naddress the intricacies of single agent scheduling in graph-based environments.\nBy integrating the latest advancements in reinforcement learning and\ntransformer architecture, TRATSS provides a novel system that outputs optimized\ntask scheduling decisions while dynamically adapting to evolving task\nrequirements and resource availability. Leveraging the self-attention mechanism\nin transformers, TRATSS effectively captures complex task dependencies, thereby\nproviding solutions with enhanced resource utilization and task completion\nefficiency. Experimental evaluations on benchmark datasets demonstrate TRATSS's\neffectiveness in providing high-quality solutions to scheduling problems that\ninvolve multiple action profiles.", "published": "2025-04-07 18:23:13", "link": "http://arxiv.org/abs/2504.05407v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "The Role of Environment Access in Agnostic Reinforcement Learning", "abstract": "We study Reinforcement Learning (RL) in environments with large state spaces,\nwhere function approximation is required for sample-efficient learning.\nDeparting from a long history of prior work, we consider the weakest possible\nform of function approximation, called agnostic policy learning, where the\nlearner seeks to find the best policy in a given class $\\Pi$, with no guarantee\nthat $\\Pi$ contains an optimal policy for the underlying task. Although it is\nknown that sample-efficient agnostic policy learning is not possible in the\nstandard online RL setting without further assumptions, we investigate the\nextent to which this can be overcome with stronger forms of access to the\nenvironment. Specifically, we show that: 1. Agnostic policy learning remains\nstatistically intractable when given access to a local simulator, from which\none can reset to any previously seen state. This result holds even when the\npolicy class is realizable, and stands in contrast to a positive result of\n[MFR24] showing that value-based learning under realizability is tractable with\nlocal simulator access. 2. Agnostic policy learning remains statistically\nintractable when given online access to a reset distribution with good coverage\nproperties over the state space (the so-called $\\mu$-reset setting). We also\nstudy stronger forms of function approximation for policy learning, showing\nthat PSDP [BKSN03] and CPI [KL02] provably fail in the absence of policy\ncompleteness. 3. On a positive note, agnostic policy learning is statistically\ntractable for Block MDPs with access to both of the above reset models. We\nestablish this via a new algorithm that carefully constructs a policy emulator:\na tabular MDP with a small state space that approximates the value functions of\nall policies $\\pi \\in \\Pi$. These values are approximated without any explicit\nvalue function class.", "published": "2025-04-07 18:19:56", "link": "http://arxiv.org/abs/2504.05405v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "GARF: Learning Generalizable 3D Reassembly for Real-World Fractures", "abstract": "3D reassembly is a challenging spatial intelligence task with broad\napplications across scientific domains. While large-scale synthetic datasets\nhave fueled promising learning-based approaches, their generalizability to\ndifferent domains is limited. Critically, it remains uncertain whether models\ntrained on synthetic datasets can generalize to real-world fractures where\nbreakage patterns are more complex. To bridge this gap, we propose GARF, a\ngeneralizable 3D reassembly framework for real-world fractures. GARF leverages\nfracture-aware pretraining to learn fracture features from individual\nfragments, with flow matching enabling precise 6-DoF alignments. At inference\ntime, we introduce one-step preassembly, improving robustness to unseen objects\nand varying numbers of fractures. In collaboration with archaeologists,\npaleoanthropologists, and ornithologists, we curate Fractura, a diverse dataset\nfor vision and learning communities, featuring real-world fracture types across\nceramics, bones, eggshells, and lithics. Comprehensive experiments have shown\nour approach consistently outperforms state-of-the-art methods on both\nsynthetic and real-world datasets, achieving 82.87\\% lower rotation error and\n25.15\\% higher part accuracy. This sheds light on training on synthetic data to\nadvance real-world 3D puzzle solving, demonstrating its strong generalization\nacross unseen object shapes and diverse fracture types.", "published": "2025-04-07 18:13:16", "link": "http://arxiv.org/abs/2504.05400v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Interactive Explanations for Reinforcement-Learning Agents", "abstract": "As reinforcement learning methods increasingly amass accomplishments, the\nneed for comprehending their solutions becomes more crucial. Most explainable\nreinforcement learning (XRL) methods generate a static explanation depicting\ntheir developers' intuition of what should be explained and how. In contrast,\nliterature from the social sciences proposes that meaningful explanations are\nstructured as a dialog between the explainer and the explainee, suggesting a\nmore active role for the user and her communication with the agent. In this\npaper, we present ASQ-IT -- an interactive explanation system that presents\nvideo clips of the agent acting in its environment based on queries given by\nthe user that describe temporal properties of behaviors of interest. Our\napproach is based on formal methods: queries in ASQ-IT's user interface map to\na fragment of Linear Temporal Logic over finite traces (LTLf), which we\ndeveloped, and our algorithm for query processing is based on automata theory.\nUser studies show that end-users can understand and formulate queries in ASQ-IT\nand that using ASQ-IT assists users in identifying faulty agent behaviors.", "published": "2025-04-07 18:00:50", "link": "http://arxiv.org/abs/2504.05393v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Improved Stochastic Texture Filtering Through Sample Reuse", "abstract": "Stochastic texture filtering (STF) has re-emerged as a technique that can\nbring down the cost of texture filtering of advanced texture compression\nmethods, e.g., neural texture compression. However, during texture\nmagnification, the swapped order of filtering and shading with STF can result\nin aliasing. The inability to smoothly interpolate material properties stored\nin textures, such as surface normals, leads to potentially undesirable\nappearance changes. We present a novel method to improve the quality of\nstochastically-filtered magnified textures and reduce the image difference\ncompared to traditional texture filtering. When textures are magnified, nearby\npixels filter similar sets of texels and we introduce techniques for sharing\ntexel values among pixels with only a small increase in cost (0.04--0.14~ms per\nframe). We propose an improvement to weighted importance sampling that\nguarantees that our method never increases error beyond single-sample\nstochastic texture filtering. Under high magnification, our method has >10 dB\nhigher PSNR than single-sample STF. Our results show greatly improved image\nquality both with and without spatiotemporal denoising.", "published": "2025-04-07 23:28:52", "link": "http://arxiv.org/abs/2504.05562v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Caption Anything in Video: Fine-grained Object-centric Captioning via Spatiotemporal Multimodal Prompting", "abstract": "We present CAT-V (Caption AnyThing in Video), a training-free framework for\nfine-grained object-centric video captioning that enables detailed descriptions\nof user-selected objects through time. CAT-V integrates three key components: a\nSegmenter based on SAMURAI for precise object segmentation across frames, a\nTemporal Analyzer powered by TRACE-Uni for accurate event boundary detection\nand temporal analysis, and a Captioner using InternVL-2.5 for generating\ndetailed object-centric descriptions. Through spatiotemporal visual prompts and\nchain-of-thought reasoning, our framework generates detailed, temporally-aware\ndescriptions of objects' attributes, actions, statuses, interactions, and\nenvironmental contexts without requiring additional training data. CAT-V\nsupports flexible user interactions through various visual prompts (points,\nbounding boxes, and irregular regions) and maintains temporal sensitivity by\ntracking object states and interactions across different time segments. Our\napproach addresses limitations of existing video captioning methods, which\neither produce overly abstract descriptions or lack object-level precision,\nenabling fine-grained, object-specific descriptions while maintaining temporal\ncoherence and spatial accuracy. The GitHub repository for this project is\navailable at https://github.com/yunlong10/CAT-V", "published": "2025-04-07 22:35:36", "link": "http://arxiv.org/abs/2504.05541v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Broadcast via Mobile Agents in a Dynamic Network: Interplay of Graph Properties & Agents", "abstract": "In this paper, we revisit the problem of \\textsc{Broadcast}, introduced by\nDas, Giachoudis, Luccio, and Markou [OPODIS, 2020], where $k+1$ agents are\ninitially placed on an $n$ node dynamic graph, where $1$ agent has a message\nthat must be broadcast to the remaining $k$ ignorant agents. The original paper\nstudied the relationship between the number of agents needed to solve the\nproblem and the edge density of the graph. The paper presented strong evidence\nthat edge density of a graph, or the number of redundant edges within the\ngraph, may be the correct graph property to accurately differentiate whether\n$k= o(n)$ agents (low edge density) or $k = \\Omega(n)$ agents (high edge\ndensity) are needed to solve the problem.\n  In this paper, we show that surprisingly, edge density may not in fact be the\ncorrect differentiating property. The original paper presents graphs with edge\ndensity $1.1\\overline{6}$ that require $\\Omega(n)$ agents, however, we\nconstruct graphs with edge density $> 1.1\\overline{6}$ and develop an algorithm\nto solve the problem on those graphs using only $o(n)$ agents. We subsequently\nshow that the relationship between edge density and number of agents is fairly\nweak by first constructing graphs with edge density tending to $1$ from above\nthat require $\\Omega(n/f(n))$ agents to solve, for any function $f(n) \\to\n\\infty$ as $n \\to \\infty$. We then construct an infinite family of graphs with\nedge density $< \\rho$ requiring exactly $k$ ignorant agents to solve\n\\textsc{Broadcast}, for any $k>0$ and $\\rho>1$.", "published": "2025-04-07 19:07:24", "link": "http://arxiv.org/abs/2504.05442v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "User Feedback Alignment for LLM-powered Exploration in Large-scale Recommendation Systems", "abstract": "Exploration, the act of broadening user experiences beyond their established\npreferences, is challenging in large-scale recommendation systems due to\nfeedback loops and limited signals on user exploration patterns. Large Language\nModels (LLMs) offer potential by leveraging their world knowledge to recommend\nnovel content outside these loops. A key challenge is aligning LLMs with user\npreferences while preserving their knowledge and reasoning. While using LLMs to\nplan for the next novel user interest, this paper introduces a novel approach\ncombining hierarchical planning with LLM inference-time scaling to improve\nrecommendation relevancy without compromising novelty. We decouple novelty and\nuser-alignment, training separate LLMs for each objective. We then scale up the\nnovelty-focused LLM's inference and select the best-of-n predictions using the\nuser-aligned LLM. Live experiments demonstrate efficacy, showing significant\ngains in both user satisfaction (measured by watch activity and active user\ncounts) and exploration diversity.", "published": "2025-04-07 21:44:12", "link": "http://arxiv.org/abs/2504.05522v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Status Updating with Time Stamp Errors", "abstract": "A status updating system is considered in which multiple processes are\nsampled and transmitted through a shared channel. Each process has its\ndedicated server that processes its samples before time stamping them for\ntransmission. Time stamps, however, are prone to errors, and hence the status\nupdates received may not be credible. Our setting models the time stamp error\nrate as a function of the servers' busy times. Hence, to reduce errors and\nenhance credibility, servers need to process samples on a relatively prolonged\nschedule. This, however, deteriorates timeliness, which is captured through the\nage of information (AoI) metric. An optimization problem is formulated whose\ngoal to characterize the optimal processes' schedule and sampling instances to\nachieve the optimal trade-off between timeliness and credibility. The problem\nis first solved for a single process setting, where it is shown that a\nthreshold-based sleep-wake schedule is optimal, in which the server wakes up\nand is allowed to process newly incoming samples only if the AoI surpasses a\ncertain threshold that depends on the required timeliness-credibility\ntrade-off. Such insights are then extended to the multi-process setting, where\ntwo main scheduling and sleep-wake policies, namely round-robin scheduling with\nthreshold-waiting and asymmetric scheduling with zero-waiting, are introduced\nand analyzed.", "published": "2025-04-07 17:52:52", "link": "http://arxiv.org/abs/2504.05371v1", "categories": ["cs.IT", "cs.NI", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Cross-functional transferability in universal machine learning interatomic potentials", "abstract": "The rapid development of universal machine learning interatomic potentials\n(uMLIPs) has demonstrated the possibility for generalizable learning of the\nuniversal potential energy surface. In principle, the accuracy of uMLIPs can be\nfurther improved by bridging the model from lower-fidelity datasets to\nhigh-fidelity ones. In this work, we analyze the challenge of this transfer\nlearning problem within the CHGNet framework. We show that significant energy\nscale shifts and poor correlations between GGA and r$^2$SCAN pose challenges to\ncross-functional data transferability in uMLIPs. By benchmarking different\ntransfer learning approaches on the MP-r$^2$SCAN dataset of 0.24 million\nstructures, we demonstrate the importance of elemental energy referencing in\nthe transfer learning of uMLIPs. By comparing the scaling law with and without\nthe pre-training on a low-fidelity dataset, we show that significant data\nefficiency can still be achieved through transfer learning, even with a target\ndataset of sub-million structures. We highlight the importance of proper\ntransfer learning and multi-fidelity learning in creating next-generation\nuMLIPs on high-fidelity data.", "published": "2025-04-07 23:45:40", "link": "http://arxiv.org/abs/2504.05565v1", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "From Fairness to Truthfulness: Rethinking Data Valuation Design", "abstract": "As large language models increasingly rely on external data sources, fairly\ncompensating data contributors has become a central concern. In this paper, we\nrevisit the design of data markets through a game-theoretic lens, where data\nowners face private, heterogeneous costs for data sharing. We show that\ncommonly used valuation methods--such as Leave-One-Out and Data Shapley--fail\nto ensure truthful reporting of these costs, leading to inefficient market\noutcomes. To address this, we adapt well-established payment rules from\nmechanism design, namely Myerson and Vickrey-Clarke-Groves (VCG), to the data\nmarket setting. We demonstrate that the Myerson payment is the minimal truthful\npayment mechanism, optimal from the buyer's perspective, and that VCG and\nMyerson payments coincide in unconstrained allocation settings. Our findings\nhighlight the importance of incorporating incentive compatibility into data\nvaluation, paving the way for more robust and efficient data markets.", "published": "2025-04-07 23:34:11", "link": "http://arxiv.org/abs/2504.05563v1", "categories": ["cs.GT", "cs.LG"], "primary_category": "cs.GT"}
{"title": "Federated Hierarchical Reinforcement Learning for Adaptive Traffic Signal Control", "abstract": "Multi-agent reinforcement learning (MARL) has shown promise for adaptive\ntraffic signal control (ATSC), enabling multiple intersections to coordinate\nsignal timings in real time. However, in large-scale settings, MARL faces\nconstraints due to extensive data sharing and communication requirements.\nFederated learning (FL) mitigates these challenges by training shared models\nwithout directly exchanging raw data, yet traditional FL methods such as FedAvg\nstruggle with highly heterogeneous intersections. Different intersections\nexhibit varying traffic patterns, demands, and road structures, so performing\nFedAvg across all agents is inefficient. To address this gap, we propose\nHierarchical Federated Reinforcement Learning (HFRL) for ATSC. HFRL employs\nclustering-based or optimization-based techniques to dynamically group\nintersections and perform FedAvg independently within groups of intersections\nwith similar characteristics, enabling more effective coordination and\nscalability than standard FedAvg. Our experiments on synthetic and real-world\ntraffic networks demonstrate that HFRL not only outperforms both decentralized\nand standard federated RL approaches but also identifies suitable grouping\npatterns based on network structure or traffic demand, resulting in a more\nrobust framework for distributed, heterogeneous systems.", "published": "2025-04-07 23:02:59", "link": "http://arxiv.org/abs/2504.05553v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Riemannian Geometry for the classification of brain states with intracortical brain-computer interfaces", "abstract": "This study investigates the application of Riemannian geometry-based methods\nfor brain decoding using invasive electrophysiological recordings. Although\npreviously employed in non-invasive, the utility of Riemannian geometry for\ninvasive datasets, which are typically smaller and scarcer, remains less\nexplored. Here, we propose a Minimum Distance to Mean (MDM) classifier using a\nRiemannian geometry approach based on covariance matrices extracted from\nintracortical Local Field Potential (LFP) recordings across various regions\nduring different brain state dynamics. For benchmarking, we evaluated the\nperformance of our approach against Convolutional Neural Networks (CNNs) and\nEuclidean MDM classifiers. Our results indicate that the Riemannian\ngeometry-based classification not only achieves a superior mean F1\nmacro-averaged score across different channel configurations but also requires\nup to two orders of magnitude less computational training time. Additionally,\nthe geometric framework reveals distinct spatial contributions of brain regions\nacross varying brain states, suggesting a state-dependent organization that\ntraditional time series-based methods often fail to capture. Our findings align\nwith previous studies supporting the efficacy of geometry-based methods and\nextending their application to invasive brain recordings, highlighting their\npotential for broader clinical use, such as brain computer interface\napplications.", "published": "2025-04-07 22:11:59", "link": "http://arxiv.org/abs/2504.05534v1", "categories": ["q-bio.NC", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "L3GS: Layered 3D Gaussian Splats for Efficient 3D Scene Delivery", "abstract": "Traditional 3D content representations include dense point clouds that\nconsume large amounts of data and hence network bandwidth, while newer\nrepresentations such as neural radiance fields suffer from poor frame rates due\nto their non-standard volumetric rendering pipeline. 3D Gaussian splats (3DGS)\ncan be seen as a generalization of point clouds that meet the best of both\nworlds, with high visual quality and efficient rendering for real-time frame\nrates. However, delivering 3DGS scenes from a hosting server to client devices\nis still challenging due to high network data consumption (e.g., 1.5 GB for a\nsingle scene). The goal of this work is to create an efficient 3D content\ndelivery framework that allows users to view high quality 3D scenes with 3DGS\nas the underlying data representation. The main contributions of the paper are:\n(1) Creating new layered 3DGS scenes for efficient delivery, (2) Scheduling\nalgorithms to choose what splats to download at what time, and (3) Trace-driven\nexperiments from users wearing virtual reality headsets to evaluate the visual\nquality and latency. Our system for Layered 3D Gaussian Splats delivery L3GS\ndemonstrates high visual quality, achieving 16.9% higher average SSIM compared\nto baselines, and also works with other compressed 3DGS representations.", "published": "2025-04-07 21:23:32", "link": "http://arxiv.org/abs/2504.05517v1", "categories": ["cs.GR", "cs.LG", "cs.MM"], "primary_category": "cs.GR"}
{"title": "Neural network-enhanced integrators for simulating ordinary differential equations", "abstract": "Numerous applications necessitate the computation of numerical solutions to\ndifferential equations across a wide range of initial conditions and system\nparameters, which feeds the demand for efficient yet accurate numerical\nintegration methods.This study proposes a neural network (NN) enhancement of\nclassical numerical integrators. NNs are trained to learn integration errors,\nwhich are then used as additive correction terms in numerical schemes. The\nperformance of these enhanced integrators is compared with well-established\nmethods through numerical studies, with a particular emphasis on computational\nefficiency. Analytical properties are examined in terms of local errors and\nbackward error analysis. Embedded Runge-Kutta schemes are then employed to\ndevelop enhanced integrators that mitigate generalization risk, ensuring that\nthe neural network's evaluation in previously unseen regions of the state space\ndoes not destabilize the integrator. It is guaranteed that the enhanced\nintegrators perform at least as well as the desired classical Runge-Kutta\nschemes. The effectiveness of the proposed approaches is demonstrated through\nextensive numerical studies using a realistic model of a wind turbine, with\nparameters derived from the established simulation framework OpenFast.", "published": "2025-04-07 20:38:35", "link": "http://arxiv.org/abs/2504.05493v1", "categories": ["math.NA", "cs.LG", "cs.NA", "cs.SY", "eess.SY"], "primary_category": "math.NA"}
{"title": "Optimal Bayesian Affine Estimator and Active Learning for the Wiener Model", "abstract": "This paper presents a Bayesian estimation framework for Wiener models,\nfocusing on learning nonlinear output functions under known linear state\ndynamics. We derive a closed-form optimal affine estimator for the unknown\nparameters, characterized by the so-called \"dynamic basis statistics (DBS).\"\nSeveral features of the proposed estimator are studied, including Bayesian\nunbiasedness, closed-form posterior statistics, error monotonicity in\ntrajectory length, and consistency condition (also known as persistent\nexcitation). In the special case of Fourier basis functions, we demonstrate\nthat the closed-form description is computationally available, as the Fourier\nDBS enjoys explicit expression. Furthermore, we identify an inherent\ninconsistency in single-trajectory measurements, regardless of input\nexcitation. Leveraging the closed-form estimation error, we develop an active\nlearning algorithm synthesizing input signals to minimize estimation error.\nNumerical experiments validate the efficacy of our approach, showing\nsignificant improvements over traditional regularized least-squares methods.", "published": "2025-04-07 20:36:06", "link": "http://arxiv.org/abs/2504.05490v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Graph Neural Networks for Enhancing Ensemble Forecasts of Extreme Rainfall", "abstract": "Climate change is increasing the occurrence of extreme precipitation events,\nthreatening infrastructure, agriculture, and public safety. Ensemble prediction\nsystems provide probabilistic forecasts but exhibit biases and difficulties in\ncapturing extreme weather. While post-processing techniques aim to enhance\nforecast accuracy, they rarely focus on precipitation, which exhibits complex\nspatial dependencies and tail behavior. Our novel framework leverages graph\nneural networks to post-process ensemble forecasts, specifically modeling the\nextremes of the underlying distribution. This allows to capture spatial\ndependencies and improves forecast accuracy for extreme events, thus leading to\nmore reliable forecasts and mitigating risks of extreme precipitation and\nflooding.", "published": "2025-04-07 20:01:55", "link": "http://arxiv.org/abs/2504.05471v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Quantum Mechanics and Neural Networks", "abstract": "We demonstrate that any Euclidean-time quantum mechanical theory may be\nrepresented as a neural network, ensured by the Kosambi-Karhunen-Lo\\`eve\ntheorem, mean-square path continuity, and finite two-point functions. The\nadditional constraint of reflection positivity, which is related to unitarity,\nmay be achieved by a number of mechanisms, such as imposing neural network\nparameter space splitting or the Markov property. Non-differentiability of the\nnetworks is related to the appearance of non-trivial commutators. Neural\nnetworks acting on Markov processes are no longer Markov, but still reflection\npositive, which facilitates the definition of deep neural network quantum\nsystems. We illustrate these principles in several examples using numerical\nimplementations, recovering classic quantum mechanical results such as\nHeisenberg uncertainty, non-trivial commutators, and the spectrum.", "published": "2025-04-07 19:54:00", "link": "http://arxiv.org/abs/2504.05462v1", "categories": ["hep-th", "cs.LG", "math.PR", "quant-ph"], "primary_category": "hep-th"}
{"title": "Intermediate Layer Classifiers for OOD generalization", "abstract": "Deep classifiers are known to be sensitive to data distribution shifts,\nprimarily due to their reliance on spurious correlations in training data. It\nhas been suggested that these classifiers can still find useful features in the\nnetwork's last layer that hold up under such shifts. In this work, we question\nthe use of last-layer representations for out-of-distribution (OOD)\ngeneralisation and explore the utility of intermediate layers. To this end, we\nintroduce \\textit{Intermediate Layer Classifiers} (ILCs). We discover that\nintermediate layer representations frequently offer substantially better\ngeneralisation than those from the penultimate layer. In many cases, zero-shot\nOOD generalisation using earlier-layer representations approaches the few-shot\nperformance of retraining on penultimate layer representations. This is\nconfirmed across multiple datasets, architectures, and types of distribution\nshifts. Our analysis suggests that intermediate layers are less sensitive to\ndistribution shifts compared to the penultimate layer. These findings highlight\nthe importance of understanding how information is distributed across network\nlayers and its role in OOD generalisation, while also pointing to the limits of\npenultimate layer representation utility. Code is available at\nhttps://github.com/oshapio/intermediate-layer-generalization", "published": "2025-04-07 19:50:50", "link": "http://arxiv.org/abs/2504.05461v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Nature-Inspired Colony of Artificial Intelligence System with Fast, Detailed, and Organized Learner Agents for Enhancing Diversity and Quality", "abstract": "The concepts of convolutional neural networks (CNNs) and multi-agent systems\nare two important areas of research in artificial intelligence (AI). In this\npaper, we present an approach that builds a CNN-based colony of AI agents to\nserve as a single system and perform multiple tasks (e.g., predictions or\nclassifications) in an environment. The proposed system impersonates the\nnatural environment of a biological system, like an ant colony or a human\ncolony. The proposed colony of AI that is defined as a role-based system\nuniquely contributes to accomplish tasks in an environment by incorporating AI\nagents that are fast learners, detailed learners, and organized learners. These\nlearners can enhance their localized learning and their collective decisions as\na single system of colony of AI agents. This approach also enhances the\ndiversity and quality of the colony of AI with the help of Genetic Algorithms\nand their crossover and mutation mechanisms. The evolution of fast, detailed,\nand organized learners in the colony of AI is achieved by introducing a unique\none-to-one mapping between these learners and the pretrained VGG16, VGG19, and\nResNet50 models, respectively. This role-based approach creates two parent-AI\nagents using the AI models through the processes, called the intra- and\ninter-marriage of AI, so that they can share their learned knowledge (weights\nand biases) based on a probabilistic rule and produce diversified child-AI\nagents to perform new tasks. This process will form a colony of AI that\nconsists of families of multi-model and mixture-model AI agents to improve\ndiversity and quality. Simulations show that the colony of AI, built using the\nVGG16, VGG19, and ResNet50 models, can provide a single system that generates\nchild-AI agents of excellent predictive performance, ranging between 82% and\n95% of F1-scores, to make diversified collective and quality decisions on a\ntask.", "published": "2025-04-07 12:13:14", "link": "http://arxiv.org/abs/2504.05365v1", "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG", "cs.MA"], "primary_category": "cs.NE"}
{"title": "Debate-Feedback: A Multi-Agent Framework for Efficient Legal Judgment Prediction", "abstract": "The use of AI in legal analysis and prediction (LegalAI) has gained\nwidespread attention, with past research focusing on retrieval-based methods\nand fine-tuning large models. However, these approaches often require large\ndatasets and underutilize the capabilities of modern large language models\n(LLMs). In this paper, inspired by the debate phase of real courtroom trials,\nwe propose a novel legal judgment prediction model based on the Debate-Feedback\narchitecture, which integrates LLM multi-agent debate and reliability\nevaluation models. Unlike traditional methods, our model achieves significant\nimprovements in efficiency by minimizing the need for large historical\ndatasets, thus offering a lightweight yet robust solution. Comparative\nexperiments show that it outperforms several general-purpose and\ndomain-specific legal models, offering a dynamic reasoning process and a\npromising direction for future LegalAI research.", "published": "2025-04-07 09:34:14", "link": "http://arxiv.org/abs/2504.05358v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Chew, Goldberger & Low Equations: Eigensystem Analysis and Applications to One-Dimensional Test Problems", "abstract": "Chew, Goldberger & Low (CGL) equations describe one of the simplest plasma\nflow models that allow anisotropic pressure, i.e., pressure is modeled using a\nsymmetric tensor described by two scalar pressure components, one parallel to\nthe magnetic field, another perpendicular to the magnetic field. The system of\nequations is a non-conservative hyperbolic system. In this work, we analyze the\neigensystem of the CGL equations. We present the eigenvalues and the complete\nset of right eigenvectors. We also prove the linear degeneracy of some of the\ncharacteristic fields. Using the eigensystem for CGL equations, we propose HLL\nand HLLI Riemann solvers for the CGL system. Furthermore, we present the\nAFD-WENO schemes up to the seventh order in one dimension and demonstrate the\nperformance of the schemes on several one-dimensional test cases.", "published": "2025-04-07 21:00:35", "link": "http://arxiv.org/abs/2504.05503v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "primary_category": "math.NA"}
{"title": "BC-ADMM: An Efficient Non-convex Constrained Optimizer with Robotic Applications", "abstract": "Non-convex constrained optimizations are ubiquitous in robotic applications\nsuch as multi-agent navigation, UAV trajectory optimization, and soft robot\nsimulation. For this problem class, conventional optimizers suffer from small\nstep sizes and slow convergence. We propose BC-ADMM, a variant of Alternating\nDirection Method of Multiplier (ADMM), that can solve a class of non-convex\nconstrained optimizations with biconvex constraint relaxation. Our algorithm\nallows larger step sizes by breaking the problem into small-scale sub-problems\nthat can be easily solved in parallel. We show that our method has both\ntheoretical convergence speed guarantees and practical convergence guarantees\nin the asymptotic sense. Through numerical experiments in a row of four robotic\napplications, we show that BC-ADMM has faster convergence than conventional\ngradient descent and Newton's method in terms of wall clock time.", "published": "2025-04-07 19:56:06", "link": "http://arxiv.org/abs/2504.05465v1", "categories": ["math.OC", "cs.NA", "cs.RO", "math.NA"], "primary_category": "math.OC"}
{"title": "Diffusion-based Models for Unpaired Super-resolution in Fluid Dynamics", "abstract": "High-fidelity, high-resolution numerical simulations are crucial for studying\ncomplex multiscale phenomena in fluid dynamics, such as turbulent flows and\nocean waves. However, direct numerical simulations with high-resolution solvers\nare computationally prohibitive. As an alternative, super-resolution techniques\nenable the enhancement of low-fidelity, low-resolution simulations. However,\ntraditional super-resolution approaches rely on paired low-fidelity,\nlow-resolution and high-fidelity, high-resolution datasets for training, which\nare often impossible to acquire in complex flow systems. To address this\nchallenge, we propose a novel two-step approach that eliminates the need for\npaired datasets. First, we perform unpaired domain translation at the\nlow-resolution level using an Enhanced Denoising Diffusion Implicit Bridge.\nThis process transforms low-fidelity, low-resolution inputs into high-fidelity,\nlow-resolution outputs, and we provide a theoretical analysis to highlight the\nadvantages of this enhanced diffusion-based approach. Second, we employ the\ncascaded Super-Resolution via Repeated Refinement model to upscale the\nhigh-fidelity, low-resolution prediction to the high-resolution result. We\ndemonstrate the effectiveness of our approach across three fluid dynamics\nproblems. Moreover, by incorporating a neural operator to learn system\ndynamics, our method can be extended to improve evolutionary simulations of\nlow-fidelity, low-resolution data.", "published": "2025-04-07 19:08:28", "link": "http://arxiv.org/abs/2504.05443v1", "categories": ["math.NA", "cs.NA", "physics.flu-dyn", "65C60, 65M22, 65M50, 68T07, 76F55"], "primary_category": "math.NA"}
{"title": "A Solid-State Nanopore Signal Generator for Training Machine Learning Models", "abstract": "Translocation event detection from raw nanopore current signals is a\nfundamental step in nanopore signal analysis. Traditional data analysis methods\nrely on user-defined parameters to extract event information, making the\ninterpretation of experimental results sensitive to parameter choice. While\nMachine Learning (ML) has seen widespread adoption across various scientific\nfields, its potential remains underexplored in solid-state nanopore research.\n  In this work, we introduce a nanopore signal generator capable of producing\nextensive synthetic datasets for machine learning applications and benchmarking\nnanopore signal analysis platforms. Using this generator, we train deep\nlearning models to detect translocation events directly from raw signals,\nachieving over 99% true event detection with minimal false positives.", "published": "2025-04-07 19:56:35", "link": "http://arxiv.org/abs/2504.05466v1", "categories": ["eess.SP", "physics.bio-ph", "q-bio.BM", "stat.ML"], "primary_category": "eess.SP"}
{"title": "Survey on Algorithms for multi-index models", "abstract": "We review the literature on algorithms for estimating the index space in a\nmulti-index model. The primary focus is on computationally efficient\n(polynomial-time) algorithms in Gaussian space, the assumptions under which\nconsistency is guaranteed by these methods, and their sample complexity. In\nmany cases, a gap is observed between the sample complexity of the best known\ncomputationally efficient methods and the information-theoretical minimum. We\nalso review algorithms based on estimating the span of gradients using\nnonparametric methods, and algorithms based on fitting neural networks using\ngradient descent", "published": "2025-04-07 18:50:11", "link": "http://arxiv.org/abs/2504.05426v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Of All StrIPEs: Investigating Structure-informed Positional Encoding for Efficient Music Generation", "abstract": "While music remains a challenging domain for generative models like\nTransformers, a two-pronged approach has recently proved successful: inserting\nmusically-relevant structural information into the positional encoding (PE)\nmodule and using kernel approximation techniques based on Random Fourier\nFeatures (RFF) to lower the computational cost from quadratic to linear. Yet,\nit is not clear how such RFF-based efficient PEs compare with those based on\nrotation matrices, such as Rotary Positional Encoding (RoPE). In this paper, we\npresent a unified framework based on kernel methods to analyze both families of\nefficient PEs. We use this framework to develop a novel PE method called\nRoPEPool, capable of extracting causal relationships from temporal sequences.\nUsing RFF-based PEs and rotation-based PEs, we demonstrate how seemingly\ndisparate PEs can be jointly studied by considering the content-context\ninteractions they induce. For empirical validation, we use a symbolic music\ngeneration task, namely, melody harmonization. We show that RoPEPool, combined\nwith highly-informative structural priors, outperforms all methods.", "published": "2025-04-07 11:51:29", "link": "http://arxiv.org/abs/2504.05364v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Exploring Local Interpretable Model-Agnostic Explanations for Speech Emotion Recognition with Distribution-Shift", "abstract": "We introduce EmoLIME, a version of local interpretable model-agnostic\nexplanations (LIME) for black-box Speech Emotion Recognition (SER) models. To\nthe best of our knowledge, this is the first attempt to apply LIME in SER.\nEmoLIME generates high-level interpretable explanations and identifies which\nspecific frequency ranges are most influential in determining emotional states.\nThe approach aids in interpreting complex, high-dimensional embeddings such as\nthose generated by end-to-end speech models. We evaluate EmoLIME,\nqualitatively, quantitatively, and statistically, across three emotional speech\ndatasets, using classifiers trained on both hand-crafted acoustic features and\nWav2Vec 2.0 embeddings. We find that EmoLIME exhibits stronger robustness\nacross different models than across datasets with distribution shifts,\nhighlighting its potential for more consistent explanations in SER tasks within\na dataset.", "published": "2025-04-07 17:38:21", "link": "http://arxiv.org/abs/2504.05368v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Pretraining Language Models for Diachronic Linguistic Change Discovery", "abstract": "Large language models (LLMs) have shown potential as tools for scientific\ndiscovery. This has engendered growing interest in their use in humanistic\ndisciplines, such as historical linguistics and literary studies. These fields\noften construct arguments on the basis of delineations like genre, or more\ninflexibly, time period. Although efforts have been made to restrict inference\nto specific domains via fine-tuning or model editing, we posit that the only\ntrue guarantee is domain-restricted pretraining -- typically, a data- and\ncompute-expensive proposition.\n  We show that efficient pretraining techniques can produce useful models over\ncorpora too large for easy manual inspection but too small for \"typical\" LLM\napproaches. We employ a novel date-attribution pipeline in order to obtain a\ntemporally-segmented dataset of five 10-million-word slices. We train two\ncorresponding five-model batteries over these corpus segments, efficient\npretraining and Llama3-8B parameter efficiently finetuned.\n  We find that the pretrained models are faster to train than the finetuned\nbaselines and that they better respect the historical divisions of our corpus.\nEmphasizing speed and precision over a-historical comprehensiveness enables a\nnumber of novel approaches to hypothesis discovery and testing in our target\nfields. Taking up diachronic linguistics as a testbed, we show that our method\nenables the detection of a diverse set of phenomena, including en masse lexical\nchange, non-lexical (grammatical and morphological) change, and word sense\nintroduction/obsolescence. We provide a ready-to-use pipeline that allows\nextension of our approach to other target fields with only minimal adaptation.", "published": "2025-04-07 21:51:32", "link": "http://arxiv.org/abs/2504.05523v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Caption Anything in Video: Fine-grained Object-centric Captioning via Spatiotemporal Multimodal Prompting", "abstract": "We present CAT-V (Caption AnyThing in Video), a training-free framework for\nfine-grained object-centric video captioning that enables detailed descriptions\nof user-selected objects through time. CAT-V integrates three key components: a\nSegmenter based on SAMURAI for precise object segmentation across frames, a\nTemporal Analyzer powered by TRACE-Uni for accurate event boundary detection\nand temporal analysis, and a Captioner using InternVL-2.5 for generating\ndetailed object-centric descriptions. Through spatiotemporal visual prompts and\nchain-of-thought reasoning, our framework generates detailed, temporally-aware\ndescriptions of objects' attributes, actions, statuses, interactions, and\nenvironmental contexts without requiring additional training data. CAT-V\nsupports flexible user interactions through various visual prompts (points,\nbounding boxes, and irregular regions) and maintains temporal sensitivity by\ntracking object states and interactions across different time segments. Our\napproach addresses limitations of existing video captioning methods, which\neither produce overly abstract descriptions or lack object-level precision,\nenabling fine-grained, object-specific descriptions while maintaining temporal\ncoherence and spatial accuracy. The GitHub repository for this project is\navailable at https://github.com/yunlong10/CAT-V", "published": "2025-04-07 22:35:36", "link": "http://arxiv.org/abs/2504.05541v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Supports for Outerplanar and Bounded Treewidth Graphs", "abstract": "We study the existence and construction of sparse supports for hypergraphs\nderived from subgraphs of a graph $G$. For a hypergraph $(X,\\mathcal{H})$, a\nsupport $Q$ is a graph on $X$ s.t. $Q[H]$, the graph induced on vertices in $H$\nis connected for every $H\\in\\mathcal{H}$.\n  We consider \\emph{primal}, \\emph{dual}, and \\emph{intersection} hypergraphs\ndefined by subgraphs of a graph $G$ that are \\emph{non-piercing}, (i.e., each\nsubgraph is connected, their pairwise differences remain connected).\n  If $G$ is outerplanar, we show that the primal, dual and intersection\nhypergraphs admit supports that are outerplanar. For a bounded treewidth graph\n$G$, we show that if the subgraphs are non-piercing, then there exist supports\nfor the primal and dual hypergraphs of treewidth $O(2^{tw(G)})$ and\n$O(2^{4tw(G)})$ respectively, and a support of treewidth $2^{O(2^{tw(G)})}$ for\nthe intersection hypergraph. We also show that for the primal and dual\nhypergraphs, the exponential blow-up of treewidth is sometimes essential.\n  All our results are algorithmic and yield polynomial-time algorithms (when\nthe treewidth is bounded). The existence and construction of sparse supports is\na crucial step in the design and analysis of PTASs and/or sub-exponential time\nalgorithms for several packing and covering problems.", "published": "2025-04-07 13:04:30", "link": "http://arxiv.org/abs/2504.05039v2", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Sequential-NIAH: A Needle-In-A-Haystack Benchmark for Extracting Sequential Needles from Long Contexts", "abstract": "Evaluating the ability of large language models (LLMs) to handle extended\ncontexts is critical, particularly for retrieving information relevant to\nspecific queries embedded within lengthy inputs. We introduce Sequential-NIAH,\na benchmark specifically designed to evaluate the capability of LLMs to extract\nsequential information items (known as needles) from long contexts. The\nbenchmark comprises three types of needle generation pipelines: synthetic,\nreal, and open-domain QA. It includes contexts ranging from 8K to 128K tokens\nin length, with a dataset of 14,000 samples (2,000 reserved for testing). To\nfacilitate evaluation on this benchmark, we trained a synthetic data-driven\nevaluation model capable of evaluating answer correctness based on\nchronological or logical order, achieving an accuracy of 99.49% on synthetic\ntest data. We conducted experiments on six well-known LLMs, revealing that even\nthe best-performing model achieved a maximum accuracy of only 63.15%. Further\nanalysis highlights the growing challenges posed by increasing context lengths\nand the number of needles, underscoring substantial room for improvement.\nAdditionally, noise robustness experiments validate the reliability of the\nbenchmark, making Sequential-NIAH an important reference for advancing research\non long text extraction capabilities of LLMs.", "published": "2025-04-07 03:50:12", "link": "http://arxiv.org/abs/2504.04713v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Replica for our Democracies? On Using Digital Twins to Enhance Deliberative Democracy", "abstract": "Deliberative democracy depends on carefully designed institutional\nframeworks, such as participant selection, facilitation methods, and\ndecision-making mechanisms, that shape how deliberation occurs. However,\ndetermining which institutional design best suits a given context often proves\ndifficult when relying solely on real-world observations or laboratory\nexperiments, which can be resource intensive and hard to replicate. To address\nthese challenges, this paper explores Digital Twin (DT) technology as a\nregulatory sandbox for deliberative democracy. DTs enable researchers and\npolicymakers to run \"what if\" scenarios on varied deliberative designs in a\ncontrolled virtual environment by creating dynamic, computer based models that\nmirror real or synthetic data. This makes systematic analysis of the\ninstitutional design possible without the practical constraints of real world\nor lab-based settings. The paper also discusses the limitations of this\napproach and outlines key considerations for future research.", "published": "2025-04-07 23:14:41", "link": "http://arxiv.org/abs/2504.07138v1", "categories": ["cs.MA", "cs.CY", "cs.ET"], "primary_category": "cs.MA"}
{"title": "Global approximations to the error function of real argument for vectorized computation", "abstract": "The error function of real argument can be uniformly approximated to a given\naccuracy by a single closed-form expression for the whole variable range either\nin terms of addition, multiplication, division, and square root operations\nonly, or also using the exponential function. The coefficients have been\ntabulated for up to 128-bit precision. Tests of a computer code implementation\nusing the standard single- and double-precision floating-point arithmetic show\ngood performance and vectorizability.", "published": "2025-04-07 13:36:28", "link": "http://arxiv.org/abs/2504.05068v1", "categories": ["physics.chem-ph", "cs.NA", "math.NA"], "primary_category": "physics.chem-ph"}
{"title": "Diffusion-based Models for Unpaired Super-resolution in Fluid Dynamics", "abstract": "High-fidelity, high-resolution numerical simulations are crucial for studying\ncomplex multiscale phenomena in fluid dynamics, such as turbulent flows and\nocean waves. However, direct numerical simulations with high-resolution solvers\nare computationally prohibitive. As an alternative, super-resolution techniques\nenable the enhancement of low-fidelity, low-resolution simulations. However,\ntraditional super-resolution approaches rely on paired low-fidelity,\nlow-resolution and high-fidelity, high-resolution datasets for training, which\nare often impossible to acquire in complex flow systems. To address this\nchallenge, we propose a novel two-step approach that eliminates the need for\npaired datasets. First, we perform unpaired domain translation at the\nlow-resolution level using an Enhanced Denoising Diffusion Implicit Bridge.\nThis process transforms low-fidelity, low-resolution inputs into high-fidelity,\nlow-resolution outputs, and we provide a theoretical analysis to highlight the\nadvantages of this enhanced diffusion-based approach. Second, we employ the\ncascaded Super-Resolution via Repeated Refinement model to upscale the\nhigh-fidelity, low-resolution prediction to the high-resolution result. We\ndemonstrate the effectiveness of our approach across three fluid dynamics\nproblems. Moreover, by incorporating a neural operator to learn system\ndynamics, our method can be extended to improve evolutionary simulations of\nlow-fidelity, low-resolution data.", "published": "2025-04-07 19:08:28", "link": "http://arxiv.org/abs/2504.05443v2", "categories": ["math.NA", "cs.NA", "physics.flu-dyn", "65C60, 65M22, 65M50, 68T07, 76F55"], "primary_category": "math.NA"}
{"title": "\"Security for Everyone\" in Finite Blocklength IRS-aided Systems With Perfect and Imperfect CSI", "abstract": "Provisioning secrecy for all users, given the heterogeneity in their channel\nconditions, locations, and the unknown location of the attacker/eavesdropper,\nis challenging and not always feasible. The problem is even more difficult\nunder finite blocklength constraints that are popular in ultra-reliable\nlow-latency communication (URLLC) and massive machine-type communications\n(mMTC). This work takes the first step to guarantee secrecy for all URLLC/mMTC\nusers in the finite blocklength regime (FBR) where intelligent reflecting\nsurfaces (IRS) are used to enhance legitimate users' reception and thwart the\npotential eavesdropper (Eve) from intercepting. To that end, we aim to maximize\nthe minimum secrecy rate (SR) among all users by jointly optimizing the\ntransmitter's beamforming and IRS's passive reflective elements (PREs) under\nthe FBR latency constraints. The resulting optimization problem is non-convex\nand even more complicated under imperfect channel state information (CSI). To\ntackle it, we linearize the objective function, and decompose the problem into\nsequential subproblems. When perfect CSI is not available, we use the\nsuccessive convex approximation (SCA) approach to transform imperfect\nCSI-related semi-infinite constraints into finite linear matrix inequalities\n(LMI). We prove that our proposed algorithm converges to a locally optimal\nsolution with low computational complexity thanks to our closed-form\nlinearization approach. This makes the solution scalable for large IRS\ndeployments. Extensive simulations with practical settings show that our\napproach can ensure secure communication for all users while satisfying FBR\nconstraints even with only imperfect CSI.", "published": "2025-04-07 13:36:03", "link": "http://arxiv.org/abs/2504.05067v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Secure Communications for All Users in Low-Resolution IRS-aided Systems Under Imperfect and Unknown CSI", "abstract": "Provisioning secrecy for all users, given the heterogeneity and uncertainty\nof their channel conditions, locations, and the unknown location of the\nattacker/eavesdropper, is challenging and not always feasible. This work takes\nthe first step to guarantee secrecy for all users where a low resolution\nintelligent reflecting surfaces (IRS) is used to enhance legitimate users'\nreception and thwart the potential eavesdropper (Eve) from intercepting. In\nreal-life scenarios, due to hardware limitations of the IRS' passive reflective\nelements (PREs), the use of a full-resolution (continuous) phase shift (CPS) is\nimpractical. In this paper, we thus consider a more practical case where the\nphase shift (PS) is modeled by a low-resolution (quantized) phase shift (QPS)\nwhile addressing the phase shift error (PSE) induced by the imperfect channel\nstate information (CSI). To that end, we aim to maximize the minimum secrecy\nrate (SR) among all users by jointly optimizing the transmitter's beamforming\nvector and the IRS's passive reflective elements (PREs) under\nperfect/imperfect/unknown CSI. The resulting optimization problem is non-convex\nand even more complicated under imperfect/unknown CSI. The resulting\noptimization problem is non-convex and even more complicated under\nimperfect/unknown CSI. To tackle it, we linearize the objective function and\ndecompose the problem into sequential subproblems. When the perfect CSI is not\navailable, we use the successive convex approximation (SCA) approach to\ntransform imperfect CSI related semi-infinite constraints into finite linear\nmatrix inequalities (LMI). We prove that our proposed algorithm converges to a\nlocally optimal solution with low computational complexity. Extensive\nsimulations with practical settings show that our approach can ensure secure\ncommunication for all users while the IRS's PREs are quantized and are affected\nby the PSE.", "published": "2025-04-07 13:18:03", "link": "http://arxiv.org/abs/2504.05048v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Topic mining based on fine-tuning Sentence-BERT and LDA", "abstract": "Research background: With the continuous development of society, consumers\npay more attention to the key information of product fine-grained attributes\nwhen shopping. Research purposes: This study will fine tune the Sentence-BERT\nword embedding model and LDA model, mine the subject characteristics in online\nreviews of goods, and show consumers the details of various aspects of goods.\nResearch methods: First, the Sentence-BERT model was fine tuned in the field of\ne-commerce online reviews, and the online review text was converted into a word\nvector set with richer semantic information; Secondly, the vectorized word set\nis input into the LDA model for topic feature extraction; Finally, focus on the\nkey functions of the product through keyword analysis under the theme. Results:\nThis study compared this model with other word embedding models and LDA models,\nand compared it with common topic extraction methods. The theme consistency of\nthis model is 0.5 higher than that of other models, which improves the accuracy\nof theme extraction", "published": "2025-04-07 01:17:32", "link": "http://arxiv.org/abs/2504.07984v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Comparative analysis of Realistic EMF Exposure Estimation from Low Density Sensor Network by Finite & Infinite Neural Networks", "abstract": "Understanding the spatial and temporal patterns of environmental exposure to\nradio-frequency electromagnetic fields (RF-EMF) is essential for conducting\nrisk assessments. These assessments aim to explore potential connections\nbetween RF-EMF exposure and its effects on human health, as well as on wildlife\nand plant life. Existing research has used different machine learning tools for\nEMF exposure estimation; however, a comparative analysis of these techniques is\nrequired to better understand their performance for real-world datasets. In\nthis work, we present both finite and infinite-width convolutional\nnetwork-based methods to estimate and assess EMF exposure levels from 70\nreal-world sensors in Lille, France. A comparative analysis has been conducted\nto analyze the performance of the methods' execution time and estimation\naccuracy. To improve estimation accuracy for higher-resolution grids, we\nutilized a preconditioned gradient descent method for kernel estimation. Root\nMean Square Error (RMSE) is used as the evaluation criterion for comparing the\nperformance of these deep learning models.", "published": "2025-04-07 12:31:53", "link": "http://arxiv.org/abs/2504.07990v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Mathematical Approach in Hybrid Beamforming for ISAC Systems", "abstract": "This document serves as supplementary material for a journal paper\nsubmission, presenting detailed mathematical proofs and derivations that\nsupport the results outlined in the main manuscript. In this work, we formulate\nan Integrated sensing and communication (ISAC) optimization problem aimed at\nfairly maximizing beampattern gains across multiple directions of interest,\nwhile ensuring that the signal-to-interference-plus-noise ratio (SINR)\nrequirements for communication users and the overall power constraint are\nsatisfied. To solve this problem, we propose an optimization algorithm and\nprovide a formal proof of its convergence.", "published": "2025-04-07 09:24:01", "link": "http://arxiv.org/abs/2504.07988v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "mixEEG: Enhancing EEG Federated Learning for Cross-subject EEG Classification with Tailored mixup", "abstract": "The cross-subject electroencephalography (EEG) classification exhibits great\nchallenges due to the diversity of cognitive processes and physiological\nstructures between different subjects. Modern EEG models are based on neural\nnetworks, demanding a large amount of data to achieve high performance and\ngeneralizability. However, privacy concerns associated with EEG pose\nsignificant limitations to data sharing between different hospitals and\ninstitutions, resulting in the lack of large dataset for most EEG tasks.\nFederated learning (FL) enables multiple decentralized clients to\ncollaboratively train a global model without direct communication of raw data,\nthus preserving privacy. For the first time, we investigate the cross-subject\nEEG classification in the FL setting. In this paper, we propose a simple yet\neffective framework termed mixEEG. Specifically, we tailor the vanilla mixup\nconsidering the unique properties of the EEG modality. mixEEG shares the\nunlabeled averaged data of the unseen subject rather than simply sharing raw\ndata under the domain adaptation setting, thus better preserving privacy and\noffering an averaged label as pseudo-label. Extensive experiments are conducted\non an epilepsy detection and an emotion recognition dataset. The experimental\nresult demonstrates that our mixEEG enhances the transferability of global\nmodel for cross-subject EEG classification consistently across different\ndatasets and model architectures. Code is published at:\nhttps://github.com/XuanhaoLiu/mixEEG.", "published": "2025-04-07 06:24:23", "link": "http://arxiv.org/abs/2504.07987v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
