{"title": "Will sentiment analysis need subculture? A new data augmentation\n  approach", "abstract": "Nowadays, the omnipresence of the Internet has fostered a subculture that\ncongregates around the contemporary milieu. The subculture artfully articulates\nthe intricacies of human feelings by ardently pursuing the allure of novelty, a\nfact that cannot be disregarded in the sentiment analysis. This paper aims to\nenrich data through the lens of subculture, to address the insufficient\ntraining data faced by sentiment analysis. To this end, a new approach of\nsubculture-based data augmentation (SCDA) is proposed, which engenders enhanced\ntexts for each training text by leveraging the creation of specific subcultural\nexpression generators. The extensive experiments attest to the effectiveness\nand potential of SCDA. The results also shed light on the phenomenon that\ndisparate subcultural expressions elicit varying degrees of sentiment\nstimulation. Moreover, an intriguing conjecture arises, suggesting the linear\nreversibility of certain subcultural expressions.", "published": "2023-09-01 00:11:56", "link": "http://arxiv.org/abs/2309.00178v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring the law of text geographic information", "abstract": "Textual geographic information is indispensable and heavily relied upon in\npractical applications. The absence of clear distribution poses challenges in\neffectively harnessing geographic information, thereby driving our quest for\nexploration. We contend that geographic information is influenced by human\nbehavior, cognition, expression, and thought processes, and given our intuitive\nunderstanding of natural systems, we hypothesize its conformity to the Gamma\ndistribution. Through rigorous experiments on a diverse range of 24 datasets\nencompassing different languages and types, we have substantiated this\nhypothesis, unearthing the underlying regularities governing the dimensions of\nquantity, length, and distance in geographic information. Furthermore,\ntheoretical analyses and comparisons with Gaussian distributions and Zipf's law\nhave refuted the contingency of these laws. Significantly, we have estimated\nthe upper bounds of human utilization of geographic information, pointing\ntowards the existence of uncharted territories. Also, we provide guidance in\ngeographic information extraction. Hope we peer its true countenance uncovering\nthe veil of geographic information.", "published": "2023-09-01 00:14:51", "link": "http://arxiv.org/abs/2309.00180v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JoTR: A Joint Transformer and Reinforcement Learning Framework for\n  Dialog Policy Learning", "abstract": "Dialogue policy learning (DPL) is a crucial component of dialogue modelling.\nIts primary role is to determine the appropriate abstract response, commonly\nreferred to as the \"dialogue action\". Traditional DPL methodologies have\ntreated this as a sequential decision problem, using pre-defined action\ncandidates extracted from a corpus. However, these incomplete candidates can\nsignificantly limit the diversity of responses and pose challenges when dealing\nwith edge cases, which are scenarios that occur only at extreme operating\nparameters. To address these limitations, we introduce a novel framework, JoTR.\nThis framework is unique as it leverages a text-to-text Transformer-based model\nto generate flexible dialogue actions. Unlike traditional methods, JoTR\nformulates a word-level policy that allows for a more dynamic and adaptable\ndialogue action generation, without the need for any action templates. This\nsetting enhances the diversity of responses and improves the system's ability\nto handle edge cases effectively. In addition, JoTR employs reinforcement\nlearning with a reward-shaping mechanism to efficiently finetune the word-level\ndialogue policy, which allows the model to learn from its interactions,\nimproving its performance over time. We conducted an extensive evaluation of\nJoTR to assess its effectiveness. Our extensive evaluation shows that JoTR\nachieves state-of-the-art performance on two benchmark dialogue modelling\ntasks, as assessed by both user simulators and human evaluators.", "published": "2023-09-01 03:19:53", "link": "http://arxiv.org/abs/2309.00230v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Suicidality in Arabic Tweets Using Machine Learning and Deep\n  Learning Techniques", "abstract": "Social media platforms have revolutionized traditional communication\ntechniques by enabling people globally to connect instantaneously, openly, and\nfrequently. People use social media to share personal stories and express their\nopinion. Negative emotions such as thoughts of death, self-harm, and hardship\nare commonly expressed on social media, particularly among younger generations.\nAs a result, using social media to detect suicidal thoughts will help provide\nproper intervention that will ultimately deter others from self-harm and\ncommitting suicide and stop the spread of suicidal ideation on social media. To\ninvestigate the ability to detect suicidal thoughts in Arabic tweets\nautomatically, we developed a novel Arabic suicidal tweets dataset, examined\nseveral machine learning models, including Na\\\"ive Bayes, Support Vector\nMachine, K-Nearest Neighbor, Random Forest, and XGBoost, trained on word\nfrequency and word embedding features, and investigated the ability of\npre-trained deep learning models, AraBert, AraELECTRA, and AraGPT2, to identify\nsuicidal thoughts in Arabic tweets. The results indicate that SVM and RF models\ntrained on character n-gram features provided the best performance in the\nmachine learning models, with 86% accuracy and an F1 score of 79%. The results\nof the deep learning models show that AraBert model outperforms other machine\nand deep learning models, achieving an accuracy of 91\\% and an F1-score of 88%,\nwhich significantly improves the detection of suicidal ideation in the Arabic\ntweets dataset. To the best of our knowledge, this is the first study to\ndevelop an Arabic suicidality detection dataset from Twitter and to use\ndeep-learning approaches in detecting suicidality in Arabic posts.", "published": "2023-09-01 04:30:59", "link": "http://arxiv.org/abs/2309.00246v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Insights Into the Nutritional Prevention of Macular Degeneration based\n  on a Comparative Topic Modeling Approach", "abstract": "Topic modeling and text mining are subsets of Natural Language Processing\n(NLP) with relevance for conducting meta-analysis (MA) and systematic review\n(SR). For evidence synthesis, the above NLP methods are conventionally used for\ntopic-specific literature searches or extracting values from reports to\nautomate essential phases of SR and MA. Instead, this work proposes a\ncomparative topic modeling approach to analyze reports of contradictory results\non the same general research question. Specifically, the objective is to\nidentify topics exhibiting distinct associations with significant results for\nan outcome of interest by ranking them according to their proportional\noccurrence in (and consistency of distribution across) reports of significant\neffects. The proposed method was tested on broad-scope studies addressing\nwhether supplemental nutritional compounds significantly benefit macular\ndegeneration (MD). Four of these were further supported in terms of\neffectiveness upon conducting a follow-up literature search for validation\n(omega-3 fatty acids, copper, zeaxanthin, and nitrates). The two not supported\nby the follow-up literature search (niacin and molybdenum) also had scores in\nthe lowest range under the proposed scoring system, suggesting that the\nproposed methods score for a given topic may be a viable proxy for its degree\nof association with the outcome of interest and can be helpful in the search\nfor potentially causal relationships. These results underpin the proposed\nmethods potential to add specificity in understanding effects from broad-scope\nreports, elucidate topics of interest for future research, and guide evidence\nsynthesis in a systematic and scalable way. All of this is accomplished while\nyielding valuable insights into the prevention of MD.", "published": "2023-09-01 07:53:28", "link": "http://arxiv.org/abs/2309.00312v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Do Discourse Markers Affect Computational Sentence Understanding?", "abstract": "The capabilities and use cases of automatic natural language processing (NLP)\nhave grown significantly over the last few years. While much work has been\ndevoted to understanding how humans deal with discourse connectives, this\nphenomenon is understudied in computational systems. Therefore, it is important\nto put NLP models under the microscope and examine whether they can adequately\ncomprehend, process, and reason within the complexity of natural language. In\nthis chapter, we introduce the main mechanisms behind automatic sentence\nprocessing systems step by step and then focus on evaluating discourse\nconnective processing. We assess nine popular systems in their ability to\nunderstand English discourse connectives and analyze how context and language\nunderstanding tasks affect their connective comprehension. The results show\nthat NLP systems do not process all discourse connectives equally well and that\nthe computational processing complexity of different connective kinds is not\nalways consistently in line with the presumed complexity order found in human\nprocessing. In addition, while humans are more inclined to be influenced during\nthe reading procedure but not necessarily in the final comprehension\nperformance, discourse connectives have a significant impact on the final\naccuracy of NLP systems. The richer knowledge of connectives a system learns,\nthe more negative effect inappropriate connectives have on it. This suggests\nthat the correct explicitation of discourse connectives is important for\ncomputational natural language processing.", "published": "2023-09-01 09:54:28", "link": "http://arxiv.org/abs/2309.00368v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BatchPrompt: Accomplish more with less", "abstract": "As the ever-increasing token limits of large language models (LLMs) have\nenabled long context as input, prompting with single data samples might no\nlonger an efficient way. A straightforward strategy improving efficiency is to\nbatch data within the token limit (e.g., 8k for gpt-3.5-turbo; 32k for GPT-4),\nwhich we call BatchPrompt. We have two initial observations for prompting with\nbatched data. First, we find that prompting with batched data in longer\ncontexts will inevitably lead to worse performance, compared to single-data\nprompting. Second, the performance of the language model is significantly\ncorrelated with the positions and order of the batched data, due to the\ncorresponding change in decoder context. To retain efficiency and overcome\nperformance loss, we propose Batch Permutation and Ensembling (BPE), and a\nnovel Self-reflection-guided EArly Stopping (SEAS) technique. Our comprehensive\nexperimental evaluation demonstrates that BPE can boost the performance of\nBatchPrompt with a striking margin on a range of popular NLP tasks, including\nquestion answering (Boolq), textual entailment (RTE), and duplicate questions\nidentification (QQP). These performances are even competitive with/higher than\nsingle-data prompting(SinglePrompt), while BatchPrompt requires much fewer LLM\ncalls and input tokens (For SinglePrompt v.s. BatchPrompt with batch size 32,\nusing just 9%-16% the number of LLM calls, Boolq accuracy 90.6% to 90.9% with\n27.4% tokens, QQP accuracy 87.2% to 88.4% with 18.6% tokens, RTE accuracy 91.5%\nto 91.1% with 30.8% tokens). To the best of our knowledge, this is the first\nwork to technically improve prompting efficiency of large language models. We\nhope our simple yet effective approach will shed light on the future research\nof large language models. The code will be released.", "published": "2023-09-01 10:44:36", "link": "http://arxiv.org/abs/2309.00384v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Let the Models Respond: Interpreting Language Model Detoxification\n  Through the Lens of Prompt Dependence", "abstract": "Due to language models' propensity to generate toxic or hateful responses,\nseveral techniques were developed to align model generations with users'\npreferences. Despite the effectiveness of such methods in improving the safety\nof model interactions, their impact on models' internal processes is still\npoorly understood. In this work, we apply popular detoxification approaches to\nseveral language models and quantify their impact on the resulting models'\nprompt dependence using feature attribution methods. We evaluate the\neffectiveness of counter-narrative fine-tuning and compare it with\nreinforcement learning-driven detoxification, observing differences in prompt\nreliance between the two methods despite their similar detoxification\nperformances.", "published": "2023-09-01 22:26:06", "link": "http://arxiv.org/abs/2309.00751v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Semantic Monitoring of Corporate Disclosures:\n  A Case Study on Korea's Top 50 KOSPI Companies", "abstract": "In the rapidly advancing domain of artificial intelligence, state-of-the-art\nlanguage models such as OpenAI's GPT-3.5-turbo and GPT-4 offer unprecedented\nopportunities for automating complex tasks. This research paper delves into the\ncapabilities of these models for semantically analyzing corporate disclosures\nin the Korean context, specifically for timely disclosure. The study focuses on\nthe top 50 publicly traded companies listed on the Korean KOSPI, based on\nmarket capitalization, and scrutinizes their monthly disclosure summaries over\na period of 17 months. Each summary was assigned a sentiment rating on a scale\nranging from 1(very negative) to 5(very positive). To gauge the effectiveness\nof the language models, their sentiment ratings were compared with those\ngenerated by human experts. Our findings reveal a notable performance disparity\nbetween GPT-3.5-turbo and GPT-4, with the latter demonstrating significant\naccuracy in human evaluation tests. The Spearman correlation coefficient was\nregistered at 0.61, while the simple concordance rate was recorded at 0.82.\nThis research contributes valuable insights into the evaluative characteristics\nof GPT models, thereby laying the groundwork for future innovations in the\nfield of automated semantic monitoring.", "published": "2023-09-01 01:51:28", "link": "http://arxiv.org/abs/2309.00208v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Addressing the Misalignment of Object Proposal Evaluation for\n  Vision-Language Tasks via Semantic Grounding", "abstract": "Object proposal generation serves as a standard pre-processing step in\nVision-Language (VL) tasks (image captioning, visual question answering, etc.).\nThe performance of object proposals generated for VL tasks is currently\nevaluated across all available annotations, a protocol that we show is\nmisaligned - higher scores do not necessarily correspond to improved\nperformance on downstream VL tasks. Our work serves as a study of this\nphenomenon and explores the effectiveness of semantic grounding to mitigate its\neffects. To this end, we propose evaluating object proposals against only a\nsubset of available annotations, selected by thresholding an annotation\nimportance score. Importance of object annotations to VL tasks is quantified by\nextracting relevant semantic information from text describing the image. We\nshow that our method is consistent and demonstrates greatly improved alignment\nwith annotations selected by image captioning metrics and human annotation when\ncompared against existing techniques. Lastly, we compare current detectors used\nin the Scene Graph Generation (SGG) benchmark as a use case, which serves as an\nexample of when traditional object proposal evaluation techniques are\nmisaligned.", "published": "2023-09-01 02:19:41", "link": "http://arxiv.org/abs/2309.00215v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Publicly Shareable Clinical Large Language Model Built on Synthetic\n  Clinical Notes", "abstract": "The development of large language models tailored for handling patients'\nclinical notes is often hindered by the limited accessibility and usability of\nthese notes due to strict privacy regulations. To address these challenges, we\nfirst create synthetic large-scale clinical notes using publicly available case\nreports extracted from biomedical literature. We then use these synthetic notes\nto train our specialized clinical large language model, Asclepius. While\nAsclepius is trained on synthetic data, we assess its potential performance in\nreal-world applications by evaluating it using real clinical notes. We\nbenchmark Asclepius against several other large language models, including\nGPT-3.5-turbo and other open-source alternatives. To further validate our\napproach using synthetic notes, we also compare Asclepius with its variants\ntrained on real clinical notes. Our findings convincingly demonstrate that\nsynthetic clinical notes can serve as viable substitutes for real ones when\nconstructing high-performing clinical language models. This conclusion is\nsupported by detailed evaluations conducted by both GPT-4 and medical\nprofessionals. All resources including weights, codes, and data used in the\ndevelopment of Asclepius are made publicly accessible for future research.\n(https://github.com/starmpcc/Asclepius)", "published": "2023-09-01 04:01:20", "link": "http://arxiv.org/abs/2309.00237v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ALJP: An Arabic Legal Judgment Prediction in Personal Status Cases Using\n  Machine Learning Models", "abstract": "Legal Judgment Prediction (LJP) aims to predict judgment outcomes based on\ncase description. Several researchers have developed techniques to assist\npotential clients by predicting the outcome in the legal profession. However,\nnone of the proposed techniques were implemented in Arabic, and only a few\nattempts were implemented in English, Chinese, and Hindi. In this paper, we\ndevelop a system that utilizes deep learning (DL) and natural language\nprocessing (NLP) techniques to predict the judgment outcome from Arabic case\nscripts, especially in cases of custody and annulment of marriage. This system\nwill assist judges and attorneys in improving their work and time efficiency\nwhile reducing sentencing disparity. In addition, it will help litigants,\nlawyers, and law students analyze the probable outcomes of any given case\nbefore trial. We use a different machine and deep learning models such as\nSupport Vector Machine (SVM), Logistic regression (LR), Long Short Term Memory\n(LSTM), and Bidirectional Long Short-Term Memory (BiLSTM) using representation\ntechniques such as TF-IDF and word2vec on the developed dataset. Experimental\nresults demonstrate that compared with the five baseline methods, the SVM model\nwith word2vec and LR with TF-IDF achieve the highest accuracy of 88% and 78% in\npredicting the judgment on custody cases and annulment of marriage,\nrespectively. Furthermore, the LR and SVM with word2vec and BiLSTM model with\nTF-IDF achieved the highest accuracy of 88% and 69% in predicting the\nprobability of outcomes on custody cases and annulment of marriage,\nrespectively.", "published": "2023-09-01 04:08:45", "link": "http://arxiv.org/abs/2309.00238v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "FactLLaMA: Optimizing Instruction-Following Language Models with\n  External Knowledge for Automated Fact-Checking", "abstract": "Automatic fact-checking plays a crucial role in combating the spread of\nmisinformation. Large Language Models (LLMs) and Instruction-Following\nvariants, such as InstructGPT and Alpaca, have shown remarkable performance in\nvarious natural language processing tasks. However, their knowledge may not\nalways be up-to-date or sufficient, potentially leading to inaccuracies in\nfact-checking. To address this limitation, we propose combining the power of\ninstruction-following language models with external evidence retrieval to\nenhance fact-checking performance. Our approach involves leveraging search\nengines to retrieve relevant evidence for a given input claim. This external\nevidence serves as valuable supplementary information to augment the knowledge\nof the pretrained language model. Then, we instruct-tune an open-sourced\nlanguage model, called LLaMA, using this evidence, enabling it to predict the\nveracity of the input claim more accurately. To evaluate our method, we\nconducted experiments on two widely used fact-checking datasets: RAWFC and\nLIAR. The results demonstrate that our approach achieves state-of-the-art\nperformance in fact-checking tasks. By integrating external evidence, we bridge\nthe gap between the model's knowledge and the most up-to-date and sufficient\ncontext available, leading to improved fact-checking outcomes. Our findings\nhave implications for combating misinformation and promoting the dissemination\nof accurate information on online platforms. Our released materials are\naccessible at: https://thcheung.github.io/factllama.", "published": "2023-09-01 04:14:39", "link": "http://arxiv.org/abs/2309.00240v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NeuroSurgeon: A Toolkit for Subnetwork Analysis", "abstract": "Despite recent advances in the field of explainability, much remains unknown\nabout the algorithms that neural networks learn to represent. Recent work has\nattempted to understand trained models by decomposing them into functional\ncircuits (Csord\\'as et al., 2020; Lepori et al., 2023). To advance this\nresearch, we developed NeuroSurgeon, a python library that can be used to\ndiscover and manipulate subnetworks within models in the Huggingface\nTransformers library (Wolf et al., 2019). NeuroSurgeon is freely available at\nhttps://github.com/mlepori1/NeuroSurgeon.", "published": "2023-09-01 04:26:55", "link": "http://arxiv.org/abs/2309.00244v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Large Content And Behavior Models To Understand, Simulate, And Optimize\n  Content And Behavior", "abstract": "Shannon and Weaver's seminal information theory divides communication into\nthree levels: technical, semantic, and effectiveness. While the technical level\ndeals with the accurate reconstruction of transmitted symbols, the semantic and\neffectiveness levels deal with the inferred meaning and its effect on the\nreceiver. Large Language Models (LLMs), with their wide generalizability, make\nsome progress towards the second level. However, LLMs and other communication\nmodels are not conventionally designed for predicting and optimizing\ncommunication for desired receiver behaviors and intents. As a result, the\neffectiveness level remains largely untouched by modern communication systems.\nIn this paper, we introduce the receivers' \"behavior tokens,\" such as shares,\nlikes, clicks, purchases, and retweets, in the LLM's training corpora to\noptimize content for the receivers and predict their behaviors. Other than\nshowing similar performance to LLMs on content understanding tasks, our trained\nmodels show generalization capabilities on the behavior dimension for behavior\nsimulation, content simulation, behavior understanding, and behavior domain\nadaptation. We show results on all these capabilities using a wide range of\ntasks on three corpora. We call these models Large Content and Behavior Models\n(LCBMs). Further, to spur more research on LCBMs, we release our new Content\nBehavior Corpus (CBC), a repository containing communicator, message, and\ncorresponding receiver behavior (https://behavior-in-the-wild.github.io/LCBM).", "published": "2023-09-01 09:34:49", "link": "http://arxiv.org/abs/2309.00359v4", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Taken out of context: On measuring situational awareness in LLMs", "abstract": "We aim to better understand the emergence of `situational awareness' in large\nlanguage models (LLMs). A model is situationally aware if it's aware that it's\na model and can recognize whether it's currently in testing or deployment.\nToday's LLMs are tested for safety and alignment before they are deployed. An\nLLM could exploit situational awareness to achieve a high score on safety\ntests, while taking harmful actions after deployment. Situational awareness may\nemerge unexpectedly as a byproduct of model scaling. One way to better foresee\nthis emergence is to run scaling experiments on abilities necessary for\nsituational awareness. As such an ability, we propose `out-of-context\nreasoning' (in contrast to in-context learning). We study out-of-context\nreasoning experimentally. First, we finetune an LLM on a description of a test\nwhile providing no examples or demonstrations. At test time, we assess whether\nthe model can pass the test. To our surprise, we find that LLMs succeed on this\nout-of-context reasoning task. Their success is sensitive to the training setup\nand only works when we apply data augmentation. For both GPT-3 and LLaMA-1,\nperformance improves with model size. These findings offer a foundation for\nfurther empirical study, towards predicting and potentially controlling the\nemergence of situational awareness in LLMs. Code is available at:\nhttps://github.com/AsaCooperStickland/situational-awareness-evals.", "published": "2023-09-01 17:27:37", "link": "http://arxiv.org/abs/2309.00667v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The FruitShell French synthesis system at the Blizzard 2023 Challenge", "abstract": "This paper presents a French text-to-speech synthesis system for the Blizzard\nChallenge 2023. The challenge consists of two tasks: generating high-quality\nspeech from female speakers and generating speech that closely resembles\nspecific individuals. Regarding the competition data, we conducted a screening\nprocess to remove missing or erroneous text data. We organized all symbols\nexcept for phonemes and eliminated symbols that had no pronunciation or zero\nduration. Additionally, we added word boundary and start/end symbols to the\ntext, which we have found to improve speech quality based on our previous\nexperience. For the Spoke task, we performed data augmentation according to the\ncompetition rules. We used an open-source G2P model to transcribe the French\ntexts into phonemes. As the G2P model uses the International Phonetic Alphabet\n(IPA), we applied the same transcription process to the provided competition\ndata for standardization. However, due to compiler limitations in recognizing\nspecial symbols from the IPA chart, we followed the rules to convert all\nphonemes into the phonetic scheme used in the competition data. Finally, we\nresampled all competition audio to a uniform sampling rate of 16 kHz. We\nemployed a VITS-based acoustic model with the hifigan vocoder. For the Spoke\ntask, we trained a multi-speaker model and incorporated speaker information\ninto the duration predictor, vocoder, and flow layers of the model. The\nevaluation results of our system showed a quality MOS score of 3.6 for the Hub\ntask and 3.4 for the Spoke task, placing our system at an average level among\nall participating teams.", "published": "2023-09-01 02:56:20", "link": "http://arxiv.org/abs/2309.00223v3", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Image Hijacks: Adversarial Images can Control Generative Models at\n  Runtime", "abstract": "Are foundation models secure against malicious actors? In this work, we focus\non the image input to a vision-language model (VLM). We discover image hijacks,\nadversarial images that control the behaviour of VLMs at inference time, and\nintroduce the general Behaviour Matching algorithm for training image hijacks.\nFrom this, we derive the Prompt Matching method, allowing us to train hijacks\nmatching the behaviour of an arbitrary user-defined text prompt (e.g. 'the\nEiffel Tower is now located in Rome') using a generic, off-the-shelf dataset\nunrelated to our choice of prompt. We use Behaviour Matching to craft hijacks\nfor four types of attack, forcing VLMs to generate outputs of the adversary's\nchoice, leak information from their context window, override their safety\ntraining, and believe false statements. We study these attacks against LLaVA, a\nstate-of-the-art VLM based on CLIP and LLaMA-2, and find that all attack types\nachieve a success rate of over 80%. Moreover, our attacks are automated and\nrequire only small image perturbations.", "published": "2023-09-01 03:53:40", "link": "http://arxiv.org/abs/2309.00236v4", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Why do universal adversarial attacks work on large language models?:\n  Geometry might be the answer", "abstract": "Transformer based large language models with emergent capabilities are\nbecoming increasingly ubiquitous in society. However, the task of understanding\nand interpreting their internal workings, in the context of adversarial\nattacks, remains largely unsolved. Gradient-based universal adversarial attacks\nhave been shown to be highly effective on large language models and potentially\ndangerous due to their input-agnostic nature. This work presents a novel\ngeometric perspective explaining universal adversarial attacks on large\nlanguage models. By attacking the 117M parameter GPT-2 model, we find evidence\nindicating that universal adversarial triggers could be embedding vectors which\nmerely approximate the semantic information in their adversarial training\nregion. This hypothesis is supported by white-box model analysis comprising\ndimensionality reduction and similarity measurement of hidden representations.\nWe believe this new geometric perspective on the underlying mechanism driving\nuniversal attacks could help us gain deeper insight into the internal workings\nand failure modes of LLMs, thus enabling their mitigation.", "published": "2023-09-01 05:09:49", "link": "http://arxiv.org/abs/2309.00254v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with\n  AI Feedback", "abstract": "Reinforcement learning from human feedback (RLHF) has proven effective in\naligning large language models (LLMs) with human preferences, but gathering\nhigh-quality preference labels is expensive. RL from AI Feedback (RLAIF),\nintroduced in Bai et al., offers a promising alternative that trains the reward\nmodel (RM) on preferences generated by an off-the-shelf LLM. Across the tasks\nof summarization, helpful dialogue generation, and harmless dialogue\ngeneration, we show that RLAIF achieves comparable performance to RLHF.\nFurthermore, we take a step towards \"self-improvement\" by demonstrating that\nRLAIF can outperform a supervised fine-tuned baseline even when the AI labeler\nis the same size as the policy, or even the exact same checkpoint as the\ninitial policy. Finally, we introduce direct-RLAIF (d-RLAIF) - a technique that\ncircumvents RM training by obtaining rewards directly from an off-the-shelf LLM\nduring RL, which achieves superior performance to canonical RLAIF. Our results\nsuggest that RLAIF can achieve performance on-par with using human feedback,\noffering a potential solution to the scalability limitations of RLHF.", "published": "2023-09-01 05:53:33", "link": "http://arxiv.org/abs/2309.00267v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing the vocal range of single-speaker singing voice synthesis with\n  melody-unsupervised pre-training", "abstract": "The single-speaker singing voice synthesis (SVS) usually underperforms at\npitch values that are out of the singer's vocal range or associated with\nlimited training samples. Based on our previous work, this work proposes a\nmelody-unsupervised multi-speaker pre-training method conducted on a\nmulti-singer dataset to enhance the vocal range of the single-speaker, while\nnot degrading the timbre similarity. This pre-training method can be deployed\nto a large-scale multi-singer dataset, which only contains audio-and-lyrics\npairs without phonemic timing information and pitch annotation. Specifically,\nin the pre-training step, we design a phoneme predictor to produce the\nframe-level phoneme probability vectors as the phonemic timing information and\na speaker encoder to model the timbre variations of different singers, and\ndirectly estimate the frame-level f0 values from the audio to provide the pitch\ninformation. These pre-trained model parameters are delivered into the\nfine-tuning step as prior knowledge to enhance the single speaker's vocal\nrange. Moreover, this work also contributes to improving the sound quality and\nrhythm naturalness of the synthesized singing voices. It is the first to\nintroduce a differentiable duration regulator to improve the rhythm naturalness\nof the synthesized voice, and a bi-directional flow model to improve the sound\nquality. Experimental results verify that the proposed SVS system outperforms\nthe baseline on both sound quality and naturalness.", "published": "2023-09-01 06:40:41", "link": "http://arxiv.org/abs/2309.00284v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Long-Term Ad Memorability: Understanding & Generating Memorable Ads", "abstract": "Despite the importance of long-term memory in marketing and brand building,\nuntil now, there has been no large-scale study on the memorability of ads. All\nprevious memorability studies have been conducted on short-term recall on\nspecific content types like action videos. On the other hand, long-term\nmemorability is crucial for the advertising industry, and ads are almost always\nhighly multimodal. Therefore, we release the first memorability dataset,\nLAMBDA, consisting of 1749 participants and 2205 ads covering 276 brands.\nRunning statistical tests over different participant subpopulations and ad\ntypes, we find many interesting insights into what makes an ad memorable, e.g.,\nfast-moving ads are more memorable than those with slower scenes; people who\nuse ad-blockers remember a lower number of ads than those who don't. Next, we\npresent a model, Henry, to predict the memorability of a content. Henry\nachieves state-of-the-art performance across all prominent literature\nmemorability datasets. It shows strong generalization performance with better\nresults in 0-shot on unseen datasets. Finally, with the intent of memorable ad\ngeneration, we present a scalable method to build a high-quality memorable ad\ngeneration model by leveraging automatically annotated data. Our approach, SEED\n(Self rEwarding mEmorability Modeling), starts with a language model trained on\nLAMBDA as seed data and progressively trains an LLM to generate more memorable\nads. We show that the generated advertisements have 44% higher memorability\nscores than the original ads. We release this large-scale ad dataset,\nUltraLAMBDA, consisting of 5 million ads. Our code and the datasets, LAMBDA and\nUltraLAMBDA, are open-sourced at\nhttps://behavior-in-the-wild.github.io/memorability.", "published": "2023-09-01 10:27:04", "link": "http://arxiv.org/abs/2309.00378v5", "categories": ["cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Satisfiability Checking of Multi-Variable TPTL with Unilateral Intervals\n  Is PSPACE-Complete", "abstract": "We investigate the decidability of the ${0,\\infty}$ fragment of Timed\nPropositional Temporal Logic (TPTL). We show that the satisfiability checking\nof TPTL$^{0,\\infty}$ is PSPACE-complete. Moreover, even its 1-variable fragment\n(1-TPTL$^{0,\\infty}$) is strictly more expressive than Metric Interval Temporal\nLogic (MITL) for which satisfiability checking is EXPSPACE complete. Hence, we\nhave a strictly more expressive logic with computationally easier\nsatisfiability checking. To the best of our knowledge, TPTL$^{0,\\infty}$ is the\nfirst multi-variable fragment of TPTL for which satisfiability checking is\ndecidable without imposing any bounds/restrictions on the timed words (e.g.\nbounded variability, bounded time, etc.). The membership in PSPACE is obtained\nby a reduction to the emptiness checking problem for a new \"non-punctual\"\nsubclass of Alternating Timed Automata with multiple clocks called Unilateral\nVery Weak Alternating Timed Automata (VWATA$^{0,\\infty}$) which we prove to be\nin PSPACE. We show this by constructing a simulation equivalent\nnon-deterministic timed automata whose number of clocks is polynomial in the\nsize of the given VWATA$^{0,\\infty}$.", "published": "2023-09-01 10:49:19", "link": "http://arxiv.org/abs/2309.00386v1", "categories": ["cs.LO", "cs.CL", "cs.FL", "F.4; F.4.3; F.1.1"], "primary_category": "cs.LO"}
{"title": "Learning Speech Representation From Contrastive Token-Acoustic\n  Pretraining", "abstract": "For fine-grained generation and recognition tasks such as\nminimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic\nspeech recognition (ASR), the intermediate representations extracted from\nspeech should serve as a \"bridge\" between text and acoustic information,\ncontaining information from both modalities. The semantic content is\nemphasized, while the paralinguistic information such as speaker identity and\nacoustic details should be de-emphasized. However, existing methods for\nextracting fine-grained intermediate representations from speech suffer from\nissues of excessive redundancy and dimension explosion. Contrastive learning is\na good method for modeling intermediate representations from two modalities.\nHowever, existing contrastive learning methods in the audio field focus on\nextracting global descriptive information for downstream audio classification\ntasks, making them unsuitable for TTS, VC, and ASR tasks. To address these\nissues, we propose a method named \"Contrastive Token-Acoustic Pretraining\n(CTAP)\", which uses two encoders to bring phoneme and speech into a joint\nmultimodal space, learning how to connect phoneme and speech at the frame\nlevel. The CTAP model is trained on 210k speech and phoneme pairs, achieving\nminimally-supervised TTS, VC, and ASR. The proposed CTAP method offers a\npromising solution for fine-grained generation and recognition downstream tasks\nin speech processing. We provide a website with audio samples.", "published": "2023-09-01 12:35:43", "link": "http://arxiv.org/abs/2309.00424v5", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Baseline Defenses for Adversarial Attacks Against Aligned Language\n  Models", "abstract": "As Large Language Models quickly become ubiquitous, it becomes critical to\nunderstand their security vulnerabilities. Recent work shows that text\noptimizers can produce jailbreaking prompts that bypass moderation and\nalignment. Drawing from the rich body of work on adversarial machine learning,\nwe approach these attacks with three questions: What threat models are\npractically useful in this domain? How do baseline defense techniques perform\nin this new domain? How does LLM security differ from computer vision?\n  We evaluate several baseline defense strategies against leading adversarial\nattacks on LLMs, discussing the various settings in which each is feasible and\neffective. Particularly, we look at three types of defenses: detection\n(perplexity based), input preprocessing (paraphrase and retokenization), and\nadversarial training. We discuss white-box and gray-box settings and discuss\nthe robustness-performance trade-off for each of the defenses considered. We\nfind that the weakness of existing discrete optimizers for text, combined with\nthe relatively high costs of optimization, makes standard adaptive attacks more\nchallenging for LLMs. Future research will be needed to uncover whether more\npowerful optimizers can be developed, or whether the strength of filtering and\npreprocessing defenses is greater in the LLMs domain than it has been in\ncomputer vision.", "published": "2023-09-01 17:59:44", "link": "http://arxiv.org/abs/2309.00614v2", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Language-Conditioned Change-point Detection to Identify Sub-Tasks in\n  Robotics Domains", "abstract": "In this work, we present an approach to identify sub-tasks within a\ndemonstrated robot trajectory using language instructions. We identify these\nsub-tasks using language provided during demonstrations as guidance to identify\nsub-segments of a longer robot trajectory. Given a sequence of natural language\ninstructions and a long trajectory consisting of image frames and discrete\nactions, we want to map an instruction to a smaller fragment of the trajectory.\nUnlike previous instruction following works which directly learn the mapping\nfrom language to a policy, we propose a language-conditioned change-point\ndetection method to identify sub-tasks in a problem. Our approach learns the\nrelationship between constituent segments of a long language command and\ncorresponding constituent segments of a trajectory. These constituent\ntrajectory segments can be used to learn subtasks or sub-goals for planning or\noptions as demonstrated by previous related work. Our insight in this work is\nthat the language-conditioned robot change-point detection problem is similar\nto the existing video moment retrieval works used to identify sub-segments\nwithin online videos. Through extensive experimentation, we demonstrate a\n$1.78_{\\pm 0.82}\\%$ improvement over a baseline approach in accurately\nidentifying sub-tasks within a trajectory using our proposed method. Moreover,\nwe present a comprehensive study investigating sample complexity requirements\non learning this mapping, between language and trajectory sub-segments, to\nunderstand if the video retrieval-based methods are realistic in real robot\nscenarios.", "published": "2023-09-01 21:40:34", "link": "http://arxiv.org/abs/2309.00743v1", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Efficient RLHF: Reducing the Memory Usage of PPO", "abstract": "Reinforcement Learning with Human Feedback (RLHF) has revolutionized language\nmodeling by aligning models with human preferences. However, the RL stage,\nProximal Policy Optimization (PPO), requires over 3x the memory of Supervised\nFine-Tuning (SFT), making it infeasible to use for most practitioners. To\naddress this issue, we present a comprehensive analysis the memory usage,\nperformance, and training time of memory-savings techniques for PPO. We\nintroduce Hydra-RLHF by first integrating the SFT and Reward models and then\ndynamically turning LoRA \"off\" during training. Our experiments show: 1. Using\nLoRA during PPO reduces its memory usage to be smaller than SFT while improving\nalignment across four public benchmarks, and 2. Hydra-PPO reduces the latency\nper sample of LoRA-PPO by up to 65% while maintaining its performance. Our\nresults demonstrate that Hydra-PPO is a simple and promising solution for\nenabling more widespread usage of RLHF.", "published": "2023-09-01 22:57:20", "link": "http://arxiv.org/abs/2309.00754v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Examining the Effectiveness of Chatbots in Gathering Family History\n  Information in Comparison to the Standard In-Person Interview-Based Approach", "abstract": "One of the most common things that a genealogist is tasked with is the\ngathering of a person's initial family history, normally via in-person\ninterviews or with the use of a platform such as ancestry.com, as this can\nprovide a strong foundation upon which a genealogist may build. However, the\nability to conduct these interviews can often be hindered by both geographical\nconstraints and the technical proficiency of the interviewee, as the\ninterviewee in these types of interviews is most often an elderly person with a\nlower than average level of technical proficiency. With this in mind, this\nstudy presents what we believe, based on prior research, to be the first\nchatbot geared entirely towards the gathering of family histories, and explores\nthe viability of utilising such a chatbot by comparing the performance and\nusability of such a method with the aforementioned alternatives. With a\nchatbot-based approach, we show that, though the average time taken to conduct\nan interview may be longer than if the user had used ancestry.com or\nparticipated in an in-person interview, the number of mistakes made and the\nlevel of confusion from the user regarding the UI and process required is lower\nthan the other two methods. Note that the final metric regarding the user's\nconfusion is not applicable for the in-person interview sessions due to its\nlack of a UI. With refinement, we believe this use of a chatbot could be a\nvaluable tool for genealogists, especially when dealing with interviewees who\nare based in other countries where it is not possible to conduct an in-person\ninterview.", "published": "2023-09-01 10:09:09", "link": "http://arxiv.org/abs/2309.03223v1", "categories": ["cs.HC", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Point-Bind & Point-LLM: Aligning Point Cloud with Multi-modality for 3D\n  Understanding, Generation, and Instruction Following", "abstract": "We introduce Point-Bind, a 3D multi-modality model aligning point clouds with\n2D image, language, audio, and video. Guided by ImageBind, we construct a joint\nembedding space between 3D and multi-modalities, enabling many promising\napplications, e.g., any-to-3D generation, 3D embedding arithmetic, and 3D\nopen-world understanding. On top of this, we further present Point-LLM, the\nfirst 3D large language model (LLM) following 3D multi-modal instructions. By\nparameter-efficient fine-tuning techniques, Point-LLM injects the semantics of\nPoint-Bind into pre-trained LLMs, e.g., LLaMA, which requires no 3D instruction\ndata, but exhibits superior 3D and multi-modal question-answering capacity. We\nhope our work may cast a light on the community for extending 3D point clouds\nto multi-modality applications. Code is available at\nhttps://github.com/ZiyuGuo99/Point-Bind_Point-LLM.", "published": "2023-09-01 17:59:47", "link": "http://arxiv.org/abs/2309.00615v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Contextual Biasing of Named-Entities with Large Language Models", "abstract": "This paper studies contextual biasing with Large Language Models (LLMs),\nwhere during second-pass rescoring additional contextual information is\nprovided to a LLM to boost Automatic Speech Recognition (ASR) performance. We\npropose to leverage prompts for a LLM without fine tuning during rescoring\nwhich incorporate a biasing list and few-shot examples to serve as additional\ninformation when calculating the score for the hypothesis. In addition to\nfew-shot prompt learning, we propose multi-task training of the LLM to predict\nboth the entity class and the next token. To improve the efficiency for\ncontextual biasing and to avoid exceeding LLMs' maximum sequence lengths, we\npropose dynamic prompting, where we select the most likely class using the\nclass tag prediction, and only use entities in this class as contexts for next\ntoken prediction. Word Error Rate (WER) evaluation is performed on i) an\ninternal calling, messaging, and dictation dataset, and ii) the SLUE-Voxpopuli\ndataset. Results indicate that biasing lists and few-shot examples can achieve\n17.8% and 9.6% relative improvement compared to first pass ASR, and that\nmulti-task training and dynamic prompting can achieve 20.0% and 11.3% relative\nWER improvement, respectively.", "published": "2023-09-01 20:15:48", "link": "http://arxiv.org/abs/2309.00723v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS", "68T10", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Remixing-based Unsupervised Source Separation from Scratch", "abstract": "We propose an unsupervised approach for training separation models from\nscratch using RemixIT and Self-Remixing, which are recently proposed\nself-supervised learning methods for refining pre-trained models. They first\nseparate mixtures with a teacher model and create pseudo-mixtures by shuffling\nand remixing the separated signals. A student model is then trained to separate\nthe pseudo-mixtures using either the teacher's outputs or the initial mixtures\nas supervision. To refine the teacher's outputs, the teacher's weights are\nupdated with the student's weights. While these methods originally assumed that\nthe teacher is pre-trained, we show that they are capable of training models\nfrom scratch. We also introduce a simple remixing method to stabilize training.\nExperimental results demonstrate that the proposed approach outperforms mixture\ninvariant training, which is currently the only available approach for training\na monaural separation model from scratch.", "published": "2023-09-01 10:23:04", "link": "http://arxiv.org/abs/2309.00376v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "CoNeTTE: An efficient Audio Captioning system leveraging multiple\n  datasets with Task Embedding", "abstract": "Automated Audio Captioning (AAC) involves generating natural language\ndescriptions of audio content, using encoder-decoder architectures. An audio\nencoder produces audio embeddings fed to a decoder, usually a Transformer\ndecoder, for caption generation. In this work, we describe our model, which\nnovelty, compared to existing models, lies in the use of a ConvNeXt\narchitecture as audio encoder, adapted from the vision domain to audio\nclassification. This model, called CNext-trans, achieved state-of-the-art\nscores on the AudioCaps (AC) dataset and performed competitively on Clotho\n(CL), while using four to forty times fewer parameters than existing models. We\nexamine potential biases in the AC dataset due to its origin from AudioSet by\ninvestigating unbiased encoder's impact on performance. Using the well-known\nPANN's CNN14, for instance, as an unbiased encoder, we observed a 1.7% absolute\nreduction in SPIDEr score (where higher scores indicate better performance). To\nimprove cross-dataset performance, we conducted experiments by combining\nmultiple AAC datasets (AC, CL, MACS, WavCaps) for training. Although this\nstrategy enhanced overall model performance across datasets, it still fell\nshort compared to models trained specifically on a single target dataset,\nindicating the absence of a one-size-fits-all model. To mitigate performance\ngaps between datasets, we introduced a Task Embedding (TE) token, allowing the\nmodel to identify the source dataset for each input sample. We provide insights\ninto the impact of these TEs on both the form (words) and content (sound event\ntypes) of the generated captions. The resulting model, named CoNeTTE, an\nunbiased CNext-trans model enriched with dataset-specific Task Embeddings,\nachieved SPIDEr scores of 44.1% and 30.5% on AC and CL, respectively. Code\navailable: https://github.com/Labbeti/conette-audio-captioning.", "published": "2023-09-01 13:35:44", "link": "http://arxiv.org/abs/2309.00454v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Mi-Go: Test Framework which uses YouTube as Data Source for Evaluating\n  Speech Recognition Models like OpenAI's Whisper", "abstract": "This article introduces Mi-Go, a novel testing framework aimed at evaluating\nthe performance and adaptability of general-purpose speech recognition machine\nlearning models across diverse real-world scenarios. The framework leverages\nYouTube as a rich and continuously updated data source, accounting for multiple\nlanguages, accents, dialects, speaking styles, and audio quality levels. To\ndemonstrate the effectiveness of the framework, the Whisper model, developed by\nOpenAI, was employed as a test object. The tests involve using a total of 124\nYouTube videos to test all Whisper model versions. The results underscore the\nutility of YouTube as a valuable testing platform for speech recognition\nmodels, ensuring their robustness, accuracy, and adaptability to diverse\nlanguages and acoustic conditions. Additionally, by contrasting the\nmachine-generated transcriptions against human-made subtitles, the Mi-Go\nframework can help pinpoint potential misuse of YouTube subtitles, like Search\nEngine Optimization.", "published": "2023-09-01 08:31:35", "link": "http://arxiv.org/abs/2309.00329v1", "categories": ["cs.SD", "cs.LG", "cs.SE", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Contrastive Learning in Music Video Domain", "abstract": "Contrastive learning is a powerful way of learning multimodal representations\nacross various domains such as image-caption retrieval and audio-visual\nrepresentation learning. In this work, we investigate if these findings\ngeneralize to the domain of music videos. Specifically, we create a dual\nen-coder for the audio and video modalities and train it using a bidirectional\ncontrastive loss. For the experiments, we use an industry dataset containing\n550 000 music videos as well as the public Million Song Dataset, and evaluate\nthe quality of learned representations on the downstream tasks of music tagging\nand genre classification. Our results indicate that pre-trained networks\nwithout contrastive fine-tuning outperform our contrastive learning approach\nwhen evaluated on both tasks. To gain a better understanding of the reasons\ncontrastive learning was not successful for music videos, we perform a\nqualitative analysis of the learned representations, revealing why contrastive\nlearning might have difficulties uniting embeddings from two modalities. Based\non these findings, we outline possible directions for future work. To\nfacilitate the reproducibility of our results, we share our code and the\npre-trained model.", "published": "2023-09-01 09:08:21", "link": "http://arxiv.org/abs/2309.00347v1", "categories": ["cs.IR", "cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
