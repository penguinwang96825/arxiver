{"title": "Transforming Question Answering Datasets Into Natural Language Inference\n  Datasets", "abstract": "Existing datasets for natural language inference (NLI) have propelled\nresearch on language understanding. We propose a new method for automatically\nderiving NLI datasets from the growing abundance of large-scale question\nanswering datasets. Our approach hinges on learning a sentence transformation\nmodel which converts question-answer pairs into their declarative forms.\nDespite being primarily trained on a single QA dataset, we show that it can be\nsuccessfully applied to a variety of other QA resources. Using this system, we\nautomatically derive a new freely available dataset of over 500k NLI examples\n(QA-NLI), and show that it exhibits a wide range of inference phenomena rarely\nseen in previous NLI datasets.", "published": "2018-09-09 05:03:34", "link": "http://arxiv.org/abs/1809.02922v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Neural Generators for Dialogue Learn Sentence Planning and Discourse\n  Structuring?", "abstract": "Responses in task-oriented dialogue systems often realize multiple\npropositions whose ultimate form depends on the use of sentence planning and\ndiscourse structuring operations. For example a recommendation may consist of\nan explicitly evaluative utterance e.g. Chanpen Thai is the best option, along\nwith content related by the justification discourse relation, e.g. It has great\nfood and service, that combines multiple propositions into a single phrase.\nWhile neural generation methods integrate sentence planning and surface\nrealization in one end-to-end learning framework, previous work has not shown\nthat neural generators can: (1) perform common sentence planning and discourse\nstructuring operations; (2) make decisions as to whether to realize content in\na single sentence or over multiple sentences; (3) generalize sentence planning\nand discourse relation operations beyond what was seen in training. We\nsystematically create large training corpora that exhibit particular sentence\nplanning operations and then test neural models to see what they learn. We\ncompare models without explicit latent variables for sentence planning with\nones that provide explicit supervision during training. We show that only the\nmodels with additional supervision can reproduce sentence planing and discourse\noperations and generalize to situations unseen in training.", "published": "2018-09-09 18:01:33", "link": "http://arxiv.org/abs/1809.03015v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SHOMA at Parseme Shared Task on Automatic Identification of VMWEs:\n  Neural Multiword Expression Tagging with High Generalisation", "abstract": "This paper presents a language-independent deep learning architecture adapted\nto the task of multiword expression (MWE) identification. We employ a neural\narchitecture comprising of convolutional and recurrent layers with the addition\nof an optional CRF layer at the top. This system participated in the open track\nof the Parseme shared task on automatic identification of verbal MWEs due to\nthe use of pre-trained wikipedia word embeddings. It outperformed all\nparticipating systems in both open and closed tracks with the overall\nmacro-average MWE-based F1 score of 58.09 averaged among all languages. A\nparticular strength of the system is its superior performance on unseen data\nentries.", "published": "2018-09-09 22:46:51", "link": "http://arxiv.org/abs/1809.03056v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speeding Up Neural Machine Translation Decoding by Cube Pruning", "abstract": "Although neural machine translation has achieved promising results, it\nsuffers from slow translation speed. The direct consequence is that a trade-off\nhas to be made between translation quality and speed, thus its performance can\nnot come into full play. We apply cube pruning, a popular technique to speed up\ndynamic programming, into neural machine translation to speed up the\ntranslation. To construct the equivalence class, similar target hidden states\nare combined, leading to less RNN expansion operations on the target side and\nless \\$\\mathrm{softmax}\\$ operations over the large target vocabulary. The\nexperiments show that, at the same or even better translation quality, our\nmethod can translate faster compared with naive beam search by \\$3.3\\times\\$ on\nGPUs and \\$3.5\\times\\$ on CPUs.", "published": "2018-09-09 15:45:25", "link": "http://arxiv.org/abs/1809.02992v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How clever is the FiLM model, and how clever can it be?", "abstract": "The FiLM model achieves close-to-perfect performance on the diagnostic CLEVR\ndataset and is distinguished from other such models by having a comparatively\nsimple and easily transferable architecture. In this paper, we investigate in\nmore detail the ability of FiLM to learn various linguistic constructions. Our\nmain results show that (a) FiLM is not able to learn relational statements\nstraight away except for very simple instances, (b) training on a broader set\nof instances as well as pretraining on simpler instance types can help\nalleviate these learning difficulties, (c) mixing is less robust than\npretraining and very sensitive to the compositional structure of the dataset.\nOverall, our results suggest that the approach of big all-encompassing datasets\nand the paradigm of \"the effectiveness of data\" may have fundamental\nlimitations.", "published": "2018-09-09 21:08:57", "link": "http://arxiv.org/abs/1809.03044v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Attentional Multi-Reading Sarcasm Detection", "abstract": "Recognizing sarcasm often requires a deep understanding of multiple sources\nof information, including the utterance, the conversational context, and real\nworld facts. Most of the current sarcasm detection systems consider only the\nutterance in isolation. There are some limited attempts toward taking into\naccount the conversational context. In this paper, we propose an interpretable\nend-to-end model that combines information from both the utterance and the\nconversational context to detect sarcasm, and demonstrate its effectiveness\nthrough empirical evaluations. We also study the behavior of the proposed model\nto provide explanations for the model's decisions. Importantly, our model is\ncapable of determining the impact of utterance and conversational context on\nthe model's decisions. Finally, we provide an ablation study to illustrate the\nimpact of different components of the proposed model.", "published": "2018-09-09 22:33:20", "link": "http://arxiv.org/abs/1809.03051v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "End-to-end Language Identification using NetFV and NetVLAD", "abstract": "In this paper, we apply the NetFV and NetVLAD layers for the end-to-end\nlanguage identification task. NetFV and NetVLAD layers are the differentiable\nimplementations of the standard Fisher Vector and Vector of Locally Aggregated\nDescriptors (VLAD) methods, respectively. Both of them can encode a sequence of\nfeature vectors into a fixed dimensional vector which is very important to\nprocess those variable-length utterances. We first present the relevances and\ndifferences between the classical i-vector and the aforementioned encoding\nschemes. Then, we construct a flexible end-to-end framework including a\nconvolutional neural network (CNN) architecture and an encoding layer (NetFV or\nNetVLAD) for the language identification task. Experimental results on the NIST\nLRE 2007 close-set task show that the proposed system achieves significant EER\nreductions against the conventional i-vector baseline and the CNN temporal\naverage pooling system, respectively.", "published": "2018-09-09 01:07:11", "link": "http://arxiv.org/abs/1809.02906v1", "categories": ["eess.AS", "cs.AI", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
