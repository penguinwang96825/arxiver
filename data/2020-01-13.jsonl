{"title": "ProphetNet: Predicting Future N-gram for Sequence-to-Sequence\n  Pre-training", "abstract": "This paper presents a new sequence-to-sequence pre-training model called\nProphetNet, which introduces a novel self-supervised objective named future\nn-gram prediction and the proposed n-stream self-attention mechanism. Instead\nof optimizing one-step-ahead prediction in the traditional sequence-to-sequence\nmodel, the ProphetNet is optimized by n-step ahead prediction that predicts the\nnext n tokens simultaneously based on previous context tokens at each time\nstep. The future n-gram prediction explicitly encourages the model to plan for\nthe future tokens and prevent overfitting on strong local correlations. We\npre-train ProphetNet using a base scale dataset (16GB) and a large-scale\ndataset (160GB), respectively. Then we conduct experiments on CNN/DailyMail,\nGigaword, and SQuAD 1.1 benchmarks for abstractive summarization and question\ngeneration tasks. Experimental results show that ProphetNet achieves new\nstate-of-the-art results on all these datasets compared to the models using the\nsame scale pre-training corpus.", "published": "2020-01-13 05:12:38", "link": "http://arxiv.org/abs/2001.04063v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dialectal Layers in West Iranian: a Hierarchical Dirichlet Process\n  Approach to Linguistic Relationships", "abstract": "This paper addresses a series of complex and unresolved issues in the\nhistorical phonology of West Iranian languages. The West Iranian languages\n(Persian, Kurdish, Balochi, and other languages) display a high degree of\nnon-Lautgesetzlich behavior. Most of this irregularity is undoubtedly due to\nlanguage contact; we argue, however, that an oversimplified view of the\nprocesses at work has prevailed in the literature on West Iranian dialectology,\nwith specialists assuming that deviations from an expected outcome in a given\nnon-Persian language are due to lexical borrowing from some chronological stage\nof Persian. It is demonstrated that this qualitative approach yields at times\nproblematic conclusions stemming from the lack of explicit probabilistic\ninferences regarding the distribution of the data: Persian may not be the sole\ndonor language; additionally, borrowing at the lexical level is not always the\nmechanism that introduces irregularity. In many cases, the possibility that\nWest Iranian languages show different reflexes in different conditioning\nenvironments remains under-explored. We employ a novel Bayesian approach\ndesigned to overcome these problems and tease apart the different determinants\nof irregularity in patterns of West Iranian sound change. Our methodology\nallows us to provisionally resolve a number of outstanding questions in the\nliterature on West Iranian dialectology concerning the dialectal affiliation of\ncertain sound changes. We outline future directions for work of this sort.", "published": "2020-01-13 11:23:28", "link": "http://arxiv.org/abs/2001.05297v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A logic-based relational learning approach to relation extraction: The\n  OntoILPER system", "abstract": "Relation Extraction (RE), the task of detecting and characterizing semantic\nrelations between entities in text, has gained much importance in the last two\ndecades, mainly in the biomedical domain. Many papers have been published on\nRelation Extraction using supervised machine learning techniques. Most of these\ntechniques rely on statistical methods, such as feature-based and\ntree-kernels-based methods. Such statistical learning techniques are usually\nbased on a propositional hypothesis space for representing examples, i.e., they\nemploy an attribute-value representation of features. This kind of\nrepresentation has some drawbacks, particularly in the extraction of complex\nrelations which demand more contextual information about the involving\ninstances, i.e., it is not able to effectively capture structural information\nfrom parse trees without loss of information. In this work, we present\nOntoILPER, a logic-based relational learning approach to Relation Extraction\nthat uses Inductive Logic Programming for generating extraction models in the\nform of symbolic extraction rules. OntoILPER takes profit of a rich relational\nrepresentation of examples, which can alleviate the aforementioned drawbacks.\nThe proposed relational approach seems to be more suitable for Relation\nExtraction than statistical ones for several reasons that we argue. Moreover,\nOntoILPER uses a domain ontology that guides the background knowledge\ngeneration process and is used for storing the extracted relation instances.\nThe induced extraction rules were evaluated on three protein-protein\ninteraction datasets from the biomedical domain. The performance of OntoILPER\nextraction models was compared with other state-of-the-art RE systems. The\nencouraging results seem to demonstrate the effectiveness of the proposed\nsolution.", "published": "2020-01-13 12:47:49", "link": "http://arxiv.org/abs/2001.04192v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Mining customer product reviews for product development: A summarization\n  process", "abstract": "This research set out to identify and structure from online reviews the words\nand expressions related to customers' likes and dislikes to guide product\ndevelopment. Previous methods were mainly focused on product features. However,\nreviewers express their preference not only on product features. In this paper,\nbased on an extensive literature review in design science, the authors propose\na summarization model containing multiples aspects of user preference, such as\nproduct affordances, emotions, usage conditions. Meanwhile, the linguistic\npatterns describing these aspects of preference are discovered and drafted as\nannotation guidelines. A case study demonstrates that with the proposed model\nand the annotation guidelines, human annotators can structure the online\nreviews with high inter-agreement. As high inter-agreement human annotation\nresults are essential for automatizing the online review summarization process\nwith the natural language processing, this study provides materials for the\nfuture study of automatization.", "published": "2020-01-13 13:01:14", "link": "http://arxiv.org/abs/2001.04200v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural\n  Architecture Search", "abstract": "Large pre-trained language models such as BERT have shown their effectiveness\nin various natural language processing tasks. However, the huge parameter size\nmakes them difficult to be deployed in real-time applications that require\nquick inference with limited resources. Existing methods compress BERT into\nsmall models while such compression is task-independent, i.e., the same\ncompressed BERT for all different downstream tasks. Motivated by the necessity\nand benefits of task-oriented BERT compression, we propose a novel compression\nmethod, AdaBERT, that leverages differentiable Neural Architecture Search to\nautomatically compress BERT into task-adaptive small models for specific tasks.\nWe incorporate a task-oriented knowledge distillation loss to provide search\nhints and an efficiency-aware loss as search constraints, which enables a good\ntrade-off between efficiency and effectiveness for task-adaptive BERT\ncompression. We evaluate AdaBERT on several NLP tasks, and the results\ndemonstrate that those task-adaptive compressed models are 12.7x to 29.3x\nfaster than BERT in inference time and 11.5x to 17.0x smaller in terms of\nparameter size, while comparable performance is maintained.", "published": "2020-01-13 14:03:26", "link": "http://arxiv.org/abs/2001.04246v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Joint Reasoning for Multi-Faceted Commonsense Knowledge", "abstract": "Commonsense knowledge (CSK) supports a variety of AI applications, from\nvisual understanding to chatbots. Prior works on acquiring CSK, such as\nConceptNet, have compiled statements that associate concepts, like everyday\nobjects or activities, with properties that hold for most or some instances of\nthe concept. Each concept is treated in isolation from other concepts, and the\nonly quantitative measure (or ranking) of properties is a confidence score that\nthe statement is valid. This paper aims to overcome these limitations by\nintroducing a multi-faceted model of CSK statements and methods for joint\nreasoning over sets of inter-related statements. Our model captures four\ndifferent dimensions of CSK statements: plausibility, typicality, remarkability\nand salience, with scoring and ranking along each dimension. For example,\nhyenas drinking water is typical but not salient, whereas hyenas eating\ncarcasses is salient. For reasoning and ranking, we develop a method with soft\nconstraints, to couple the inference over concepts that are related in in a\ntaxonomic hierarchy. The reasoning is cast into an integer linear programming\n(ILP), and we leverage the theory of reduction costs of a relaxed LP to compute\ninformative rankings. This methodology is applied to several large CSK\ncollections. Our evaluation shows that we can consolidate these inputs into\nmuch cleaner and more expressive knowledge. Results are available at\nhttps://dice.mpi-inf.mpg.de.", "published": "2020-01-13 11:34:25", "link": "http://arxiv.org/abs/2001.04170v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Structural Decompositions of Epistemic Logic Programs", "abstract": "Epistemic logic programs (ELPs) are a popular generalization of standard\nAnswer Set Programming (ASP) providing means for reasoning over answer sets\nwithin the language. This richer formalism comes at the price of higher\ncomputational complexity reaching up to the fourth level of the polynomial\nhierarchy. However, in contrast to standard ASP, dedicated investigations\ntowards tractability have not been undertaken yet. In this paper, we give first\nresults in this direction and show that central ELP problems can be solved in\nlinear time for ELPs exhibiting structural properties in terms of bounded\ntreewidth. We also provide a full dynamic programming algorithm that adheres to\nthese bounds. Finally, we show that applying treewidth to a novel dependency\nstructure---given in terms of epistemic literals---allows to bound the number\nof ASP solver calls in typical ELP solving procedures.", "published": "2020-01-13 13:16:13", "link": "http://arxiv.org/abs/2001.04219v1", "categories": ["cs.CC", "cs.AI", "cs.CL", "cs.DS", "68T27", "I.2.8; G.2.2; G.2.3; F.4.1"], "primary_category": "cs.CC"}
{"title": "CLUENER2020: Fine-grained Named Entity Recognition Dataset and Benchmark\n  for Chinese", "abstract": "In this paper, we introduce the NER dataset from CLUE organization\n(CLUENER2020), a well-defined fine-grained dataset for named entity recognition\nin Chinese. CLUENER2020 contains 10 categories. Apart from common labels like\nperson, organization, and location, it contains more diverse categories. It is\nmore challenging than current other Chinese NER datasets and could better\nreflect real-world applications. For comparison, we implement several\nstate-of-the-art baselines as sequence labeling tasks and report human\nperformance, as well as its analysis. To facilitate future work on fine-grained\nNER for Chinese, we release our dataset, baselines, and leader-board.", "published": "2020-01-13 15:39:56", "link": "http://arxiv.org/abs/2001.04351v4", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-Source Domain Adaptation for Text Classification via\n  DistanceNet-Bandits", "abstract": "Domain adaptation performance of a learning algorithm on a target domain is a\nfunction of its source domain error and a divergence measure between the data\ndistribution of these two domains. We present a study of various distance-based\nmeasures in the context of NLP tasks, that characterize the dissimilarity\nbetween domains based on sample estimates. We first conduct analysis\nexperiments to show which of these distance measures can best differentiate\nsamples from same versus different domains, and are correlated with empirical\nresults. Next, we develop a DistanceNet model which uses these distance\nmeasures, or a mixture of these distance measures, as an additional loss\nfunction to be minimized jointly with the task's loss function, so as to\nachieve better unsupervised domain adaptation. Finally, we extend this model to\na novel DistanceNet-Bandit model, which employs a multi-armed bandit controller\nto dynamically switch between multiple source domains and allow the model to\nlearn an optimal trajectory and mixture of domains for transfer to the\nlow-resource target domain. We conduct experiments on popular sentiment\nanalysis datasets with several diverse domains and show that our DistanceNet\nmodel, as well as its dynamic bandit variant, can outperform competitive\nbaselines in the context of unsupervised domain adaptation.", "published": "2020-01-13 15:53:41", "link": "http://arxiv.org/abs/2001.04362v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Negative Statements Considered Useful", "abstract": "Knowledge bases (KBs) about notable entities and their properties are an\nimportant asset in applications such as search, question answering and\ndialogue. All popular KBs capture virtually only positive statements, and\nabstain from taking any stance on statements not stored in the KB. This paper\nmakes the case for explicitly stating salient statements that do not hold.\nNegative statements are useful to overcome limitations of question answering\nsystems that are mainly geared for positive questions; they can also contribute\nto informative summaries of entities. Due to the abundance of such invalid\nstatements, any effort to compile them needs to address ranking by saliency. We\npresent a statisticalinference method for compiling and ranking negative\nstatements, based on expectations from positive statements of related entities\nin peer groups. Experimental results, with a variety of datasets, show that the\nmethod can effectively discover notable negative statements, and extrinsic\nstudies underline their usefulness for entity summarization. Datasets and code\nare released as resources for further research.", "published": "2020-01-13 17:49:37", "link": "http://arxiv.org/abs/2001.04425v6", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.DB"], "primary_category": "cs.IR"}
{"title": "LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured\n  Prediction", "abstract": "Structured prediction requires manipulating a large number of combinatorial\nstructures, e.g., dependency trees or alignments, either as latent or output\nvariables. Recently, the SparseMAP method has been proposed as a\ndifferentiable, sparse alternative to maximum a posteriori (MAP) and marginal\ninference. SparseMAP returns a combination of a small number of structures, a\ndesirable property in some downstream applications. However, SparseMAP requires\na tractable MAP inference oracle. This excludes, e.g., loopy graphical models\nor factor graphs with logic constraints, which generally require approximate\ninference. In this paper, we introduce LP-SparseMAP, an extension of SparseMAP\nthat addresses this limitation via a local polytope relaxation. LP-SparseMAP\nuses the flexible and powerful domain specific language of factor graphs for\ndefining and backpropagating through arbitrary hidden structure, supporting\ncoarse decompositions, hard logic constraints, and higher-order correlations.\nWe derive the forward and backward algorithms needed for using LP-SparseMAP as\na hidden or output layer. Experiments in three structured prediction tasks show\nbenefits compared to SparseMAP and Structured SVM.", "published": "2020-01-13 18:16:13", "link": "http://arxiv.org/abs/2001.04437v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Reformer: The Efficient Transformer", "abstract": "Large Transformer models routinely achieve state-of-the-art results on a\nnumber of tasks but training these models can be prohibitively costly,\nespecially on long sequences. We introduce two techniques to improve the\nefficiency of Transformers. For one, we replace dot-product attention by one\nthat uses locality-sensitive hashing, changing its complexity from O($L^2$) to\nO($L\\log L$), where $L$ is the length of the sequence. Furthermore, we use\nreversible residual layers instead of the standard residuals, which allows\nstoring activations only once in the training process instead of $N$ times,\nwhere $N$ is the number of layers. The resulting model, the Reformer, performs\non par with Transformer models while being much more memory-efficient and much\nfaster on long sequences.", "published": "2020-01-13 18:38:28", "link": "http://arxiv.org/abs/2001.04451v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "On the Replicability of Combining Word Embeddings and Retrieval Models", "abstract": "We replicate recent experiments attempting to demonstrate an attractive\nhypothesis about the use of the Fisher kernel framework and mixture models for\naggregating word embeddings towards document representations and the use of\nthese representations in document classification, clustering, and retrieval.\nSpecifically, the hypothesis was that the use of a mixture model of von\nMises-Fisher (VMF) distributions instead of Gaussian distributions would be\nbeneficial because of the focus on cosine distances of both VMF and the vector\nspace model traditionally used in information retrieval. Previous experiments\nhad validated this hypothesis. Our replication was not able to validate it,\ndespite a large parameter scan space.", "published": "2020-01-13 19:01:07", "link": "http://arxiv.org/abs/2001.04484v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Detecting depression in dyadic conversations with multimodal narratives\n  and visualizations", "abstract": "Conversations contain a wide spectrum of multimodal information that gives us\nhints about the emotions and moods of the speaker. In this paper, we developed\na system that supports humans to analyze conversations. Our main contribution\nis the identification of appropriate multimodal features and the integration of\nsuch features into verbatim conversation transcripts. We demonstrate the\nability of our system to take in a wide range of multimodal information and\nautomatically generated a prediction score for the depression state of the\nindividual. Our experiments showed that this approach yielded better\nperformance than the baseline model. Furthermore, the multimodal narrative\napproach makes it easy to integrate learnings from other disciplines, such as\nconversational analysis and psychology. Lastly, this interdisciplinary and\nautomated approach is a step towards emulating how practitioners record the\ncourse of treatment as well as emulating how conversational analysts have been\nanalyzing conversations by hand.", "published": "2020-01-13 10:47:13", "link": "http://arxiv.org/abs/2001.04809v2", "categories": ["cs.HC", "cs.AI", "cs.CL", "I.2.7"], "primary_category": "cs.HC"}
{"title": "A Differentiable Perceptual Audio Metric Learned from Just Noticeable\n  Differences", "abstract": "Many audio processing tasks require perceptual assessment. The ``gold\nstandard`` of obtaining human judgments is time-consuming, expensive, and\ncannot be used as an optimization criterion. On the other hand, automated\nmetrics are efficient to compute but often correlate poorly with human\njudgment, particularly for audio differences at the threshold of human\ndetection. In this work, we construct a metric by fitting a deep neural network\nto a new large dataset of crowdsourced human judgments. Subjects are prompted\nto answer a straightforward, objective question: are two recordings identical\nor not? These pairs are algorithmically generated under a variety of\nperturbations, including noise, reverb, and compression artifacts; the\nperturbation space is probed with the goal of efficiently identifying the\njust-noticeable difference (JND) level of the subject. We show that the\nresulting learned metric is well-calibrated with human judgments, outperforming\nbaseline methods. Since it is a deep network, the metric is differentiable,\nmaking it suitable as a loss function for other tasks. Thus, simply replacing\nan existing loss (e.g., deep feature loss) with our metric yields significant\nimprovement in a denoising network, as measured by subjective pairwise\ncomparison.", "published": "2020-01-13 18:53:08", "link": "http://arxiv.org/abs/2001.04460v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Two Channel Audio Zooming System For Smartphone", "abstract": "In this paper, two microphone based systems for audio zooming is proposed for\nthe first time. The audio zooming application allows sound capture and\nenhancement from the front direction while attenuating interfering sources from\nall other directions. The complete audio zooming system utilizes beamforming\nbased target extraction. In particular, Minimum Power Distortionless Response\n(MPDR) beamformer and Griffith Jim Beamformer (GJBF) are explored. This is\nfollowed by block thresholding for residual noise and interference suppression,\nand zooming effect creation. A number of simulation and real life experiments\nusing Samsung smartphone (Samsung Galaxy A5) were conducted. Objective and\nsubjective measures confirm the rich user experience.", "published": "2020-01-13 18:06:47", "link": "http://arxiv.org/abs/2001.04940v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "OMAP-L138 LCDK Development Kit", "abstract": "Low cost and low power consumption processor play a vital role in the field\nof Digital Signal Processing (DSP). The OMAP-L138 development kit which is low\ncost, low power consumption, ease and speed, with a wide variety of\napplications includes Digital signal processing, Image processing and video\nprocessing. This paper represents the basic introduction to OMAP-L138 processor\nand quick procedural steps for real time and non-real time implementations with\na set of programs. The real time experiments are based on audio in the\napplications of audio loopback, delay and echo. Whereas the non-real time\nexperiments are generation of a sine wave, low pass and high pass filter.", "published": "2020-01-13 13:09:48", "link": "http://arxiv.org/abs/2001.10094v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Visually Guided Self Supervised Learning of Speech Representations", "abstract": "Self supervised representation learning has recently attracted a lot of\nresearch interest for both the audio and visual modalities. However, most works\ntypically focus on a particular modality or feature alone and there has been\nvery limited work that studies the interaction between the two modalities for\nlearning self supervised representations. We propose a framework for learning\naudio representations guided by the visual modality in the context of\naudiovisual speech. We employ a generative audio-to-video training scheme in\nwhich we animate a still image corresponding to a given audio clip and optimize\nthe generated video to be as close as possible to the real video of the speech\nsegment. Through this process, the audio encoder network learns useful speech\nrepresentations that we evaluate on emotion recognition and speech recognition.\nWe achieve state of the art results for emotion recognition and competitive\nresults for speech recognition. This demonstrates the potential of visual\nsupervision for learning audio representations as a novel way for\nself-supervised learning which has not been explored in the past. The proposed\nunsupervised audio features can leverage a virtually unlimited amount of\ntraining data of unlabelled audiovisual speech and have a large number of\npotentially promising applications.", "published": "2020-01-13 14:53:22", "link": "http://arxiv.org/abs/2001.04316v2", "categories": ["eess.AS", "cs.CV", "cs.MM"], "primary_category": "eess.AS"}
{"title": "Unsupervised Audiovisual Synthesis via Exemplar Autoencoders", "abstract": "We present an unsupervised approach that converts the input speech of any\nindividual into audiovisual streams of potentially-infinitely many output\nspeakers. Our approach builds on simple autoencoders that project out-of-sample\ndata onto the distribution of the training set. We use Exemplar Autoencoders to\nlearn the voice, stylistic prosody, and visual appearance of a specific target\nexemplar speech. In contrast to existing methods, the proposed approach can be\neasily extended to an arbitrarily large number of speakers and styles using\nonly 3 minutes of target audio-video data, without requiring {\\em any} training\ndata for the input speaker. To do so, we learn audiovisual bottleneck\nrepresentations that capture the structured linguistic content of speech. We\noutperform prior approaches on both audio and video synthesis, and provide\nextensive qualitative analysis on our project page --\nhttps://www.cs.cmu.edu/~exemplar-ae/.", "published": "2020-01-13 18:56:45", "link": "http://arxiv.org/abs/2001.04463v3", "categories": ["cs.CV", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
