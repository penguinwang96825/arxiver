{"title": "Evaluation of the Automated Labeling Method for Taxonomic Nomenclature Through Prompt-Optimized Large Language Model", "abstract": "Scientific names of organisms consist of a genus name and a species epithet,\nwith the latter often reflecting aspects such as morphology, ecology,\ndistribution, and cultural background. Traditionally, researchers have manually\nlabeled species names by carefully examining taxonomic descriptions, a process\nthat demands substantial time and effort when dealing with large datasets. This\nstudy evaluates the feasibility of automatic species name labeling using large\nlanguage model (LLM) by leveraging their text classification and semantic\nextraction capabilities. Using the spider name dataset compiled by Mammola et\nal., we compared LLM-based labeling results-enhanced through prompt\nengineering-with human annotations. The results indicate that LLM-based\nclassification achieved high accuracy in Morphology, Geography, and People\ncategories. However, classification accuracy was lower in Ecology & Behavior\nand Modern & Past Culture, revealing challenges in interpreting animal behavior\nand cultural contexts. Future research will focus on improving accuracy through\noptimized few-shot learning and retrieval-augmented generation techniques,\nwhile also expanding the applicability of LLM-based labeling to diverse\nbiological taxa.", "published": "2025-03-08 23:11:43", "link": "http://arxiv.org/abs/2503.10662v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Phraselette: A Poet's Procedural Palette", "abstract": "According to the recently introduced theory of artistic support tools,\ncreativity support tools exert normative influences over artistic production,\ninstantiating a normative ground that shapes both the process and product of\nartistic expression. We argue that the normative ground of most existing\nautomated writing tools is misaligned with writerly values and identify a\npotential alternative frame-material writing support-for experimental poetry\ntools that flexibly support the finding, processing, transforming, and shaping\nof text(s). Based on this frame, we introduce Phraselette, an artistic material\nwriting support interface that helps experimental poets search for words and\nphrases. To provide material writing support, Phraselette is designed to\ncounter the dominant mode of automated writing tools, while offering language\nmodel affordances in line with writerly values. We further report on an\nextended expert evaluation involving 10 published poets that indicates support\nfor both our framing of material writing support and for Phraselette itself.", "published": "2025-03-08 20:40:28", "link": "http://arxiv.org/abs/2503.06335v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "States of LLM-generated Texts and Phase Transitions between them", "abstract": "It is known for some time that autocorrelations of words in human-written\ntexts decay according to a power law. Recent works have also shown that the\nautocorrelations decay in texts generated by LLMs is qualitatively different\nfrom the literary texts. Solid state physics tie the autocorrelations decay\nlaws to the states of matter. In this work, we empirically demonstrate that,\ndepending on the temperature parameter, LLMs can generate text that can be\nclassified as solid, critical state or gas.", "published": "2025-03-08 20:06:50", "link": "http://arxiv.org/abs/2503.06330v1", "categories": ["cs.CL", "cond-mat.stat-mech", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Advancing Autonomous Vehicle Intelligence: Deep Learning and Multimodal LLM for Traffic Sign Recognition and Robust Lane Detection", "abstract": "Autonomous vehicles (AVs) require reliable traffic sign recognition and\nrobust lane detection capabilities to ensure safe navigation in complex and\ndynamic environments. This paper introduces an integrated approach combining\nadvanced deep learning techniques and Multimodal Large Language Models (MLLMs)\nfor comprehensive road perception. For traffic sign recognition, we\nsystematically evaluate ResNet-50, YOLOv8, and RT-DETR, achieving\nstate-of-the-art performance of 99.8% with ResNet-50, 98.0% accuracy with\nYOLOv8, and achieved 96.6% accuracy in RT-DETR despite its higher computational\ncomplexity. For lane detection, we propose a CNN-based segmentation method\nenhanced by polynomial curve fitting, which delivers high accuracy under\nfavorable conditions. Furthermore, we introduce a lightweight, Multimodal,\nLLM-based framework that directly undergoes instruction tuning using small yet\ndiverse datasets, eliminating the need for initial pretraining. This framework\neffectively handles various lane types, complex intersections, and merging\nzones, significantly enhancing lane detection reliability by reasoning under\nadverse conditions. Despite constraints in available training resources, our\nmultimodal approach demonstrates advanced reasoning capabilities, achieving a\nFrame Overall Accuracy (FRM) of 53.87%, a Question Overall Accuracy (QNS) of\n82.83%, lane detection accuracies of 99.6% in clear conditions and 93.0% at\nnight, and robust performance in reasoning about lane invisibility due to rain\n(88.4%) or road degradation (95.6%). The proposed comprehensive framework\nmarkedly enhances AV perception reliability, thus contributing significantly to\nsafer autonomous driving across diverse and challenging road scenarios.", "published": "2025-03-08 19:12:36", "link": "http://arxiv.org/abs/2503.06313v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "MoEMoE: Question Guided Dense and Scalable Sparse Mixture-of-Expert for Multi-source Multi-modal Answering", "abstract": "Question Answering (QA) and Visual Question Answering (VQA) are well-studied\nproblems in the language and vision domain. One challenging scenario involves\nmultiple sources of information, each of a different modality, where the answer\nto the question may exist in one or more sources. This scenario contains richer\ninformation but is highly complex to handle. In this work, we formulate a novel\nquestion-answer generation (QAG) framework in an environment containing\nmulti-source, multimodal information. The answer may belong to any or all\nsources; therefore, selecting the most prominent answer source or an optimal\ncombination of all sources for a given question is challenging. To address this\nissue, we propose a question-guided attention mechanism that learns attention\nacross multiple sources and decodes this information for robust and unbiased\nanswer generation. To learn attention within each source, we introduce an\nexplicit alignment between questions and various information sources, which\nfacilitates identifying the most pertinent parts of the source information\nrelative to the question. Scalability in handling diverse questions poses a\nchallenge. We address this by extending our model to a sparse\nmixture-of-experts (sparse-MoE) framework, enabling it to handle thousands of\nquestion types. Experiments on T5 and Flan-T5 using three datasets demonstrate\nthe model's efficacy, supported by ablation studies.", "published": "2025-03-08 18:09:13", "link": "http://arxiv.org/abs/2503.06296v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "IteRABRe: Iterative Recovery-Aided Block Reduction", "abstract": "Large Language Models (LLMs) have grown increasingly expensive to deploy,\ndriving the need for effective model compression techniques. While block\npruning offers a straightforward approach to reducing model size, existing\nmethods often struggle to maintain performance or require substantial\ncomputational resources for recovery. We present IteRABRe, a simple yet\neffective iterative pruning method that achieves superior compression results\nwhile requiring minimal computational resources. Using only 2.5M tokens for\nrecovery, our method outperforms baseline approaches by ~3% on average when\ncompressing the Llama3.1-8B and Qwen2.5-7B models. IteRABRe demonstrates\nparticular strength in the preservation of linguistic capabilities, showing an\nimprovement 5% over the baselines in language-related tasks. Our analysis\nreveals distinct pruning characteristics between these models, while also\ndemonstrating preservation of multilingual capabilities.", "published": "2025-03-08 17:46:01", "link": "http://arxiv.org/abs/2503.06291v1", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "Critical Foreign Policy Decisions (CFPD)-Benchmark: Measuring Diplomatic Preferences in Large Language Models", "abstract": "As national security institutions increasingly integrate Artificial\nIntelligence (AI) into decision-making and content generation processes,\nunderstanding the inherent biases of large language models (LLMs) is crucial.\nThis study presents a novel benchmark designed to evaluate the biases and\npreferences of seven prominent foundation models-Llama 3.1 8B Instruct, Llama\n3.1 70B Instruct, GPT-4o, Gemini 1.5 Pro-002, Mixtral 8x22B, Claude 3.5 Sonnet,\nand Qwen2 72B-in the context of international relations (IR). We designed a\nbias discovery study around core topics in IR using 400-expert crafted\nscenarios to analyze results from our selected models. These scenarios focused\non four topical domains including: military escalation, military and\nhumanitarian intervention, cooperative behavior in the international system,\nand alliance dynamics. Our analysis reveals noteworthy variation among model\nrecommendations based on scenarios designed for the four tested domains.\nParticularly, Qwen2 72B, Gemini 1.5 Pro-002 and Llama 3.1 8B Instruct models\noffered significantly more escalatory recommendations than Claude 3.5 Sonnet\nand GPT-4o models. All models exhibit some degree of country-specific biases,\noften recommending less escalatory and interventionist actions for China and\nRussia compared to the United States and the United Kingdom. These findings\nhighlight the necessity for controlled deployment of LLMs in high-stakes\nenvironments, emphasizing the need for domain-specific evaluations and model\nfine-tuning to align with institutional objectives.", "published": "2025-03-08 16:19:13", "link": "http://arxiv.org/abs/2503.06263v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CY"}
{"title": "A Noise-Robust Turn-Taking System for Real-World Dialogue Robots: A Field Experiment", "abstract": "Turn-taking is a crucial aspect of human-robot interaction, directly\ninfluencing conversational fluidity and user engagement. While previous\nresearch has explored turn-taking models in controlled environments, their\nrobustness in real-world settings remains underexplored. In this study, we\npropose a noise-robust voice activity projection (VAP) model, based on a\nTransformer architecture, to enhance real-time turn-taking in dialogue robots.\nTo evaluate the effectiveness of the proposed system, we conducted a field\nexperiment in a shopping mall, comparing the VAP system with a conventional\ncloud-based speech recognition system. Our analysis covered both subjective\nuser evaluations and objective behavioral analysis. The results showed that the\nproposed system significantly reduced response latency, leading to a more\nnatural conversation where both the robot and users responded faster. The\nsubjective evaluations suggested that faster responses contribute to a better\ninteraction experience.", "published": "2025-03-08 14:53:20", "link": "http://arxiv.org/abs/2503.06241v1", "categories": ["cs.RO", "cs.CL", "cs.SD"], "primary_category": "cs.RO"}
{"title": "Integrating Chain-of-Thought for Multimodal Alignment: A Study on 3D Vision-Language Learning", "abstract": "Chain-of-Thought (CoT) reasoning has proven effective in natural language\ntasks but remains underexplored in multimodal alignment. This study\ninvestigates its integration into 3D vision-language learning by embedding\nstructured reasoning into alignment training. We introduce the 3D-CoT\nBenchmark, a dataset with hierarchical CoT annotations covering shape\nrecognition, functional inference, and causal reasoning. Through controlled\nexperiments, we compare CoT-structured and standard textual annotations across\nlarge reasoning models (LRMs) and large language models (LLMs). Our evaluation\nemploys a dual-layer framework assessing both intermediate reasoning and final\ninference quality. Extensive experiments demonstrate that CoT significantly\nimproves 3D semantic grounding, with LRMs leveraging CoT more effectively than\nLLMs. Furthermore, we highlight that annotation structure influences\nperformance-explicit reasoning markers aid LLMs, while unmarked CoT better\naligns with LRM inference patterns. Our analyses suggest that CoT is crucial\nfor enhancing multimodal reasoning, with implications beyond 3D tasks. The\ndataset will be publicly available at\nhttps://huggingface.co/datasets/Battam/3D-CoT", "published": "2025-03-08 14:24:54", "link": "http://arxiv.org/abs/2503.06232v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "KnowLogic: A Benchmark for Commonsense Reasoning via Knowledge-Driven Data Synthesis", "abstract": "Current evaluations of commonsense reasoning in LLMs are hindered by the\nscarcity of natural language corpora with structured annotations for reasoning\ntasks. To address this, we introduce KnowLogic, a benchmark generated through a\nknowledge-driven synthetic data strategy. KnowLogic integrates diverse\ncommonsense knowledge, plausible scenarios, and various types of logical\nreasoning. One of the key advantages of KnowLogic is its adjustable difficulty\nlevels, allowing for flexible control over question complexity. It also\nincludes fine-grained labels for in-depth evaluation of LLMs' reasoning\nabilities across multiple dimensions. Our benchmark consists of 3,000 bilingual\n(Chinese and English) questions across various domains, and presents\nsignificant challenges for current LLMs, with the highest-performing model\nachieving only 69.57\\%. Our analysis highlights common errors, such as\nmisunderstandings of low-frequency commonsense, logical inconsistencies, and\noverthinking. This approach, along with our benchmark, provides a valuable tool\nfor assessing and enhancing LLMs' commonsense reasoning capabilities and can be\napplied to a wide range of knowledge domains.", "published": "2025-03-08 13:40:10", "link": "http://arxiv.org/abs/2503.06218v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text-Speech Language Models with Improved Cross-Modal Transfer by Aligning Abstraction Levels", "abstract": "Text-Speech Language Models (TSLMs) -- language models trained to jointly\nprocess and generate text and speech -- aim to enable cross-modal knowledge\ntransfer to overcome the scaling limitations of unimodal speech LMs. The\npredominant approach to TSLM training expands the vocabulary of a pre-trained\ntext LM by appending new embeddings and linear projections for speech, followed\nby fine-tuning on speech data. We hypothesize that this method limits\ncross-modal transfer by neglecting feature compositionality, preventing\ntext-learned functions from being fully leveraged at appropriate abstraction\nlevels. To address this, we propose augmenting vocabulary expansion with\nmodules that better align abstraction levels across layers. Our models,\n\\textsc{SmolTolk}, rival or surpass state-of-the-art TSLMs trained with orders\nof magnitude more compute. Representation analyses and improved multimodal\nperformance suggest our method enhances cross-modal transfer.", "published": "2025-03-08 13:28:50", "link": "http://arxiv.org/abs/2503.06211v1", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "CUPCase: Clinically Uncommon Patient Cases and Diagnoses Dataset", "abstract": "Medical benchmark datasets significantly contribute to developing Large\nLanguage Models (LLMs) for medical knowledge extraction, diagnosis,\nsummarization, and other uses. Yet, current benchmarks are mainly derived from\nexam questions given to medical students or cases described in the medical\nliterature, lacking the complexity of real-world patient cases that deviate\nfrom classic textbook abstractions. These include rare diseases, uncommon\npresentations of common diseases, and unexpected treatment responses. Here, we\nconstruct Clinically Uncommon Patient Cases and Diagnosis Dataset (CUPCase)\nbased on 3,562 real-world case reports from BMC, including diagnoses in\nopen-ended textual format and as multiple-choice options with distractors.\nUsing this dataset, we evaluate the ability of state-of-the-art LLMs, including\nboth general-purpose and Clinical LLMs, to identify and correctly diagnose a\npatient case, and test models' performance when only partial information about\ncases is available. Our findings show that general-purpose GPT-4o attains the\nbest performance in both the multiple-choice task (average accuracy of 87.9%)\nand the open-ended task (BERTScore F1 of 0.764), outperforming several LLMs\nwith a focus on the medical domain such as Meditron-70B and MedLM-Large.\nMoreover, GPT-4o was able to maintain 87% and 88% of its performance with only\nthe first 20% of tokens of the case presentation in multiple-choice and free\ntext, respectively, highlighting the potential of LLMs to aid in early\ndiagnosis in real-world cases. CUPCase expands our ability to evaluate LLMs for\nclinical decision support in an open and reproducible manner.", "published": "2025-03-08 13:21:44", "link": "http://arxiv.org/abs/2503.06204v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Explainable Synthetic Image Detection through Diffusion Timestep Ensembling", "abstract": "Recent advances in diffusion models have enabled the creation of deceptively\nreal images, posing significant security risks when misused. In this study, we\nreveal that natural and synthetic images exhibit distinct differences in the\nhigh-frequency domains of their Fourier power spectra after undergoing\niterative noise perturbations through an inverse multi-step denoising process,\nsuggesting that such noise can provide additional discriminative information\nfor identifying synthetic images. Based on this observation, we propose a novel\ndetection method that amplifies these differences by progressively adding noise\nto the original images across multiple timesteps, and train an ensemble of\nclassifiers on these noised images. To enhance human comprehension, we\nintroduce an explanation generation and refinement module to identify flaws\nlocated in AI-generated images. Additionally, we construct two new datasets,\nGenHard and GenExplain, derived from the GenImage benchmark, providing\ndetection samples of greater difficulty and high-quality rationales for fake\nimages. Extensive experiments show that our method achieves state-of-the-art\nperformance with 98.91% and 95.89% detection accuracy on regular and harder\nsamples, increasing a minimal of 2.51% and 3.46% compared to baselines.\nFurthermore, our method also generalizes effectively to images generated by\nother diffusion models. Our code and datasets will be made publicly available.", "published": "2025-03-08 13:04:20", "link": "http://arxiv.org/abs/2503.06201v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Sample-aware Adaptive Structured Pruning for Large Language Models", "abstract": "Large language models (LLMs) have achieved outstanding performance in natural\nlanguage processing, but enormous model sizes and high computational costs\nlimit their practical deployment. Structured pruning can effectively reduce the\nresource demands for deployment by removing redundant model parameters.\nHowever, the randomly selected calibration data and fixed single importance\nestimation metrics in existing structured pruning methods lead to degraded\nperformance of pruned models. This study introduces AdaPruner, a sample-aware\nadaptive structured pruning framework for LLMs, aiming to optimize the\ncalibration data and importance estimation metrics in the structured pruning\nprocess. Specifically, AdaPruner effectively removes redundant parameters from\nLLMs by constructing a structured pruning solution space and then employing\nBayesian optimization to adaptively search for the optimal calibration data and\nimportance estimation metrics. Experimental results show that the AdaPruner\noutperforms existing structured pruning methods on a family of LLMs with\nvarying pruning ratios, demonstrating its applicability and robustness.\nRemarkably, at a 20\\% pruning ratio, the model pruned with AdaPruner maintains\n97\\% of the performance of the unpruned model.", "published": "2025-03-08 12:00:21", "link": "http://arxiv.org/abs/2503.06184v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bimodal Connection Attention Fusion for Speech Emotion Recognition", "abstract": "Multi-modal emotion recognition is challenging due to the difficulty of\nextracting features that capture subtle emotional differences. Understanding\nmulti-modal interactions and connections is key to building effective bimodal\nspeech emotion recognition systems. In this work, we propose Bimodal Connection\nAttention Fusion (BCAF) method, which includes three main modules: the\ninteractive connection network, the bimodal attention network, and the\ncorrelative attention network. The interactive connection network uses an\nencoder-decoder architecture to model modality connections between audio and\ntext while leveraging modality-specific features. The bimodal attention network\nenhances semantic complementation and exploits intra- and inter-modal\ninteractions. The correlative attention network reduces cross-modal noise and\ncaptures correlations between audio and text. Experiments on the MELD and\nIEMOCAP datasets demonstrate that the proposed BCAF method outperforms existing\nstate-of-the-art baselines.", "published": "2025-03-08 10:20:57", "link": "http://arxiv.org/abs/2503.05858v3", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "GRP: Goal-Reversed Prompting for Zero-Shot Evaluation with LLMs", "abstract": "Using Large Language Models (LLMs) to evaluate and compare two answers from\ndifferent models typically involves having LLM-based judges select the better\nanswer. However, humans often approach problem-solving from a reverse\nperspective, for instance, by choosing the worse option instead of the better\none in a pairwise comparison. Generally, this kind of reverse thinking plays a\ncrucial role in human reasoning and decision-making and can further test the\ndifference between original and reverse thought processes simultaneously. To\naddress the above issue, in this paper, we propose a Goal-Reversed Prompting\n(GRP) approach for pairwise evaluation that shifts the original task from\nselecting the better answer to choosing the worse one. We encourage LLMs to\nthink in reverse by prompting LLMs to identify the worse response. Experiments\non closed-source models demonstrate that GRP significantly enhances evaluation\ncapabilities, outperforming the prompt template with the original goal.", "published": "2025-03-08 09:44:24", "link": "http://arxiv.org/abs/2503.06139v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Discourse Cohesion in Pre-trained Language Models", "abstract": "Large pre-trained neural models have achieved remarkable success in natural\nlanguage process (NLP), inspiring a growing body of research analyzing their\nability from different aspects. In this paper, we propose a test suite to\nevaluate the cohesive ability of pre-trained language models. The test suite\ncontains multiple cohesion phenomena between adjacent and non-adjacent\nsentences. We try to compare different pre-trained language models on these\nphenomena and analyze the experimental results,hoping more attention can be\ngiven to discourse cohesion in the future.", "published": "2025-03-08 09:19:53", "link": "http://arxiv.org/abs/2503.06137v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MARRO: Multi-headed Attention for Rhetorical Role Labeling in Legal Documents", "abstract": "Identification of rhetorical roles like facts, arguments, and final judgments\nis central to understanding a legal case document and can lend power to other\ndownstream tasks like legal case summarization and judgment prediction.\nHowever, there are several challenges to this task. Legal documents are often\nunstructured and contain a specialized vocabulary, making it hard for\nconventional transformer models to understand them. Additionally, these\ndocuments run into several pages, which makes it difficult for neural models to\ncapture the entire context at once. Lastly, there is a dearth of annotated\nlegal documents to train deep learning models. Previous state-of-the-art\napproaches for this task have focused on using neural models like BiLSTM-CRF or\nhave explored different embedding techniques to achieve decent results. While\nsuch techniques have shown that better embedding can result in improved model\nperformance, not many models have focused on utilizing attention for learning\nbetter embeddings in sentences of a document. Additionally, it has been\nrecently shown that advanced techniques like multi-task learning can help the\nmodels learn better representations, thereby improving performance. In this\npaper, we combine these two aspects by proposing a novel family of multi-task\nlearning-based models for rhetorical role labeling, named MARRO, that uses\ntransformer-inspired multi-headed attention. Using label shift as an auxiliary\ntask, we show that models from the MARRO family achieve state-of-the-art\nresults on two labeled datasets for rhetorical role labeling, from the Indian\nand UK Supreme Courts.", "published": "2025-03-08 08:05:20", "link": "http://arxiv.org/abs/2503.10659v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LimTopic: LLM-based Topic Modeling and Text Summarization for Analyzing Scientific Articles limitations", "abstract": "The limitations sections of scientific articles play a crucial role in\nhighlighting the boundaries and shortcomings of research, thereby guiding\nfuture studies and improving research methods. Analyzing these limitations\nbenefits researchers, reviewers, funding agencies, and the broader academic\ncommunity. We introduce LimTopic, a strategy where Topic generation in\nLimitation sections in scientific articles with Large Language Models (LLMs).\nHere, each topic contains the title and Topic Summary. This study focuses on\neffectively extracting and understanding these limitations through topic\nmodeling and text summarization, utilizing the capabilities of LLMs. We\nextracted limitations from research articles and applied an LLM-based topic\nmodeling integrated with the BERtopic approach to generate a title for each\ntopic and Topic Sentences. To enhance comprehension and accessibility, we\nemployed LLM-based text summarization to create concise and generalizable\nsummaries for each topic Topic Sentences and produce a Topic Summary. Our\nexperimentation involved prompt engineering, fine-tuning LLM and BERTopic, and\nintegrating BERTopic with LLM to generate topics, titles, and a topic summary.\nWe also experimented with various LLMs with BERTopic for topic modeling and\nvarious LLMs for text summarization tasks. Our results showed that the\ncombination of BERTopic and GPT 4 performed the best in terms of silhouette and\ncoherence scores in topic modeling, and the GPT4 summary outperformed other LLM\ntasks as a text summarizer.", "published": "2025-03-08 07:59:44", "link": "http://arxiv.org/abs/2503.10658v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AF-KAN: Activation Function-Based Kolmogorov-Arnold Networks for Efficient Representation Learning", "abstract": "Kolmogorov-Arnold Networks (KANs) have inspired numerous works exploring\ntheir applications across a wide range of scientific problems, with the\npotential to replace Multilayer Perceptrons (MLPs). While many KANs are\ndesigned using basis and polynomial functions, such as B-splines, ReLU-KAN\nutilizes a combination of ReLU functions to mimic the structure of B-splines\nand take advantage of ReLU's speed. However, ReLU-KAN is not built for multiple\ninputs, and its limitations stem from ReLU's handling of negative values, which\ncan restrict feature extraction. To address these issues, we introduce\nActivation Function-Based Kolmogorov-Arnold Networks (AF-KAN), expanding\nReLU-KAN with various activations and their function combinations. This novel\nKAN also incorporates parameter reduction methods, primarily attention\nmechanisms and data normalization, to enhance performance on image\nclassification datasets. We explore different activation functions, function\ncombinations, grid sizes, and spline orders to validate the effectiveness of\nAF-KAN and determine its optimal configuration. In the experiments, AF-KAN\nsignificantly outperforms MLP, ReLU-KAN, and other KANs with the same parameter\ncount. It also remains competitive even when using fewer than 6 to 10 times the\nparameters while maintaining the same network structure. However, AF-KAN\nrequires a longer training time and consumes more FLOPs. The repository for\nthis work is available at https://github.com/hoangthangta/All-KAN.", "published": "2025-03-08 07:38:51", "link": "http://arxiv.org/abs/2503.06112v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Theta Theory: operads and coloring", "abstract": "We give an explicit construction of the generating set of a colored operad\nthat implements theta theory in the mathematical model of Minimalism in\ngenerative linguistics, in the form of a coloring algorithm for syntactic\nobjects. We show that the coproduct operation on workspaces allows for a\nrecursive implementation of the theta criterion. We also show that this\nfiltering by coloring rules on structures freely formed by Merge is equivalent\nto a process of structure formation by a colored version of Merge: the form of\nthe generators of the colored operad then implies the dichotomy is semantics\nbetween External and Internal Merge, where Internal Merge only moves to\nnon-theta positions.", "published": "2025-03-08 06:39:51", "link": "http://arxiv.org/abs/2503.06091v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Attribute Multi-Grained Adaptation of Pre-Trained Language Models for Text Understanding from Bayesian Perspective", "abstract": "Current neural networks often employ multi-domain-learning or\nattribute-injecting mechanisms to incorporate non-independent and identically\ndistributed (non-IID) information for text understanding tasks by capturing\nindividual characteristics and the relationships among samples. However, the\nextent of the impact of non-IID information and how these methods affect\npre-trained language models (PLMs) remains unclear. This study revisits the\nassumption that non-IID information enhances PLMs to achieve performance\nimprovements from a Bayesian perspective, which unearths and integrates non-IID\nand IID features. Furthermore, we proposed a multi-attribute multi-grained\nframework for PLM adaptations (M2A), which combines multi-attribute and\nmulti-grained views to mitigate uncertainty in a lightweight manner. We\nevaluate M2A through prevalent text-understanding datasets and demonstrate its\nsuperior performance, mainly when data are implicitly non-IID, and PLMs scale\nlarger.", "published": "2025-03-08 06:17:07", "link": "http://arxiv.org/abs/2503.06085v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of Causal Relation Extraction Transfer: Design and Data", "abstract": "We conduct an empirical analysis of neural network architectures and data\ntransfer strategies for causal relation extraction. By conducting experiments\nwith various contextual embedding layers and architectural components, we show\nthat a relatively straightforward BioBERT-BiGRU relation extraction model\ngeneralizes better than other architectures across varying web-based sources\nand annotation strategies. Furthermore, we introduce a metric for evaluating\ntransfer performance, $F1_{phrase}$ that emphasizes noun phrase localization\nrather than directly matching target tags. Using this metric, we can conduct\ndata transfer experiments, ultimately revealing that augmentation with data\nwith varying domains and annotation styles can improve performance. Data\naugmentation is especially beneficial when an adequate proportion of implicitly\nand explicitly causal sentences are included.", "published": "2025-03-08 05:51:27", "link": "http://arxiv.org/abs/2503.06076v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Conversational AI for Disease Management", "abstract": "While large language models (LLMs) have shown promise in diagnostic dialogue,\ntheir capabilities for effective management reasoning - including disease\nprogression, therapeutic response, and safe medication prescription - remain\nunder-explored. We advance the previously demonstrated diagnostic capabilities\nof the Articulate Medical Intelligence Explorer (AMIE) through a new LLM-based\nagentic system optimised for clinical management and dialogue, incorporating\nreasoning over the evolution of disease and multiple patient visit encounters,\nresponse to therapy, and professional competence in medication prescription. To\nground its reasoning in authoritative clinical knowledge, AMIE leverages\nGemini's long-context capabilities, combining in-context retrieval with\nstructured reasoning to align its output with relevant and up-to-date clinical\npractice guidelines and drug formularies. In a randomized, blinded virtual\nObjective Structured Clinical Examination (OSCE) study, AMIE was compared to 21\nprimary care physicians (PCPs) across 100 multi-visit case scenarios designed\nto reflect UK NICE Guidance and BMJ Best Practice guidelines. AMIE was\nnon-inferior to PCPs in management reasoning as assessed by specialist\nphysicians and scored better in both preciseness of treatments and\ninvestigations, and in its alignment with and grounding of management plans in\nclinical guidelines. To benchmark medication reasoning, we developed RxQA, a\nmultiple-choice question benchmark derived from two national drug formularies\n(US, UK) and validated by board-certified pharmacists. While AMIE and PCPs both\nbenefited from the ability to access external drug information, AMIE\noutperformed PCPs on higher difficulty questions. While further research would\nbe needed before real-world translation, AMIE's strong performance across\nevaluations marks a significant step towards conversational AI as a tool in\ndisease management.", "published": "2025-03-08 05:48:58", "link": "http://arxiv.org/abs/2503.06074v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GEM: Empowering MLLM for Grounded ECG Understanding with Time Series and Images", "abstract": "While recent multimodal large language models (MLLMs) have advanced automated\nECG interpretation, they still face two key limitations: (1) insufficient\nmultimodal synergy between time series signals and visual ECG representations,\nand (2) limited explainability in linking diagnoses to granular waveform\nevidence. We introduce GEM, the first MLLM unifying ECG time series, 12-lead\nECG images and text for grounded and clinician-aligned ECG interpretation. GEM\nenables feature-grounded analysis, evidence-driven reasoning, and a\nclinician-like diagnostic process through three core innovations: a\ndual-encoder framework extracting complementary time series and image features,\ncross-modal alignment for effective multimodal understanding, and\nknowledge-guided instruction generation for generating high-granularity\ngrounding data (ECG-Grounding) linking diagnoses to measurable parameters\n($e.g.$, QRS/PR Intervals). Additionally, we propose the Grounded ECG\nUnderstanding task, a clinically motivated benchmark designed to\ncomprehensively assess the MLLM's capability in grounded ECG understanding.\nExperimental results on both existing and our proposed benchmarks show GEM\nsignificantly improves predictive performance (CSN $7.4\\% \\uparrow$),\nexplainability ($22.7\\% \\uparrow$), and grounding ($24.8\\% \\uparrow$), making\nit more suitable for real-world clinical applications. GitHub repository:\nhttps://github.com/lanxiang1017/GEM.git", "published": "2025-03-08 05:48:53", "link": "http://arxiv.org/abs/2503.06073v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "A Survey on Post-training of Large Language Models", "abstract": "The emergence of Large Language Models (LLMs) has fundamentally transformed\nnatural language processing, making them indispensable across domains ranging\nfrom conversational systems to scientific exploration. However, their\npre-trained architectures often reveal limitations in specialized contexts,\nincluding restricted reasoning capacities, ethical uncertainties, and\nsuboptimal domain-specific performance. These challenges necessitate advanced\npost-training language models (PoLMs) to address these shortcomings, such as\nOpenAI-o1/o3 and DeepSeek-R1 (collectively known as Large Reasoning Models, or\nLRMs). This paper presents the first comprehensive survey of PoLMs,\nsystematically tracing their evolution across five core paradigms: Fine-tuning,\nwhich enhances task-specific accuracy; Alignment, which ensures alignment with\nhuman preferences; Reasoning, which advances multi-step inference despite\nchallenges in reward design; Efficiency, which optimizes resource utilization\namidst increasing complexity; and Integration and Adaptation, which extend\ncapabilities across diverse modalities while addressing coherence issues.\nCharting progress from ChatGPT's foundational alignment strategies to\nDeepSeek-R1's innovative reasoning advancements, we illustrate how PoLMs\nleverage datasets to mitigate biases, deepen reasoning capabilities, and\nenhance domain adaptability. Our contributions include a pioneering synthesis\nof PoLM evolution, a structured taxonomy categorizing techniques and datasets,\nand a strategic agenda emphasizing the role of LRMs in improving reasoning\nproficiency and domain flexibility. As the first survey of its scope, this work\nconsolidates recent PoLM advancements and establishes a rigorous intellectual\nframework for future research, fostering the development of LLMs that excel in\nprecision, ethical robustness, and versatility across scientific and societal\napplications.", "published": "2025-03-08 05:41:42", "link": "http://arxiv.org/abs/2503.06072v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Novel Trustworthy Video Summarization Algorithm Through a Mixture of LoRA Experts", "abstract": "With the exponential growth of user-generated content on video-sharing\nplatforms, the challenge of facilitating efficient searching and browsing of\nvideos has garnered significant attention. To enhance users' ability to swiftly\nlocate and review pertinent videos, the creation of concise and informative\nvideo summaries has become increasingly important. Video-llama is an effective\ntool for generating video summarization, but it cannot effectively unify and\noptimize the modeling of temporal and spatial features and requires a lot of\ncomputational resources and time. Therefore, we propose MiLoRA-ViSum to more\nefficiently capture complex temporal dynamics and spatial relationships\ninherent in video data and to control the number of parameters for training. By\nextending traditional Low-Rank Adaptation (LoRA) into a sophisticated\nmixture-of-experts paradigm, MiLoRA-ViSum incorporates a dual temporal-spatial\nadaptation mechanism tailored specifically for video summarization tasks. This\napproach dynamically integrates specialized LoRA experts, each fine-tuned to\naddress distinct temporal or spatial dimensions. Extensive evaluations of the\nVideoXum and ActivityNet datasets demonstrate that MiLoRA-ViSum achieves the\nbest summarization performance compared to state-of-the-art models, while\nmaintaining significantly lower computational costs. The proposed\nmixture-of-experts strategy, combined with the dual adaptation mechanism,\nhighlights the model's potential to enhance video summarization capabilities,\nparticularly in large-scale applications requiring both efficiency and\nprecision.", "published": "2025-03-08 05:20:52", "link": "http://arxiv.org/abs/2503.06064v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Fine-Grained Bias Detection in LLM: Enhancing detection mechanisms for nuanced biases", "abstract": "Recent advancements in Artificial Intelligence, particularly in Large\nLanguage Models (LLMs), have transformed natural language processing by\nimproving generative capabilities. However, detecting biases embedded within\nthese models remains a challenge. Subtle biases can propagate misinformation,\ninfluence decision-making, and reinforce stereotypes, raising ethical concerns.\nThis study presents a detection framework to identify nuanced biases in LLMs.\nThe approach integrates contextual analysis, interpretability via attention\nmechanisms, and counterfactual data augmentation to capture hidden biases\nacross linguistic contexts. The methodology employs contrastive prompts and\nsynthetic datasets to analyze model behaviour across cultural, ideological, and\ndemographic scenarios.\n  Quantitative analysis using benchmark datasets and qualitative assessments\nthrough expert reviews validate the effectiveness of the framework. Results\nshow improvements in detecting subtle biases compared to conventional methods,\nwhich often fail to highlight disparities in model responses to race, gender,\nand socio-political contexts. The framework also identifies biases arising from\nimbalances in training data and model architectures. Continuous user feedback\nensures adaptability and refinement. This research underscores the importance\nof proactive bias mitigation strategies and calls for collaboration between\npolicymakers, AI developers, and regulators. The proposed detection mechanisms\nenhance model transparency and support responsible LLM deployment in sensitive\napplications such as education, legal systems, and healthcare. Future work will\nfocus on real-time bias monitoring and cross-linguistic generalization to\nimprove fairness and inclusivity in AI-driven communication tools.", "published": "2025-03-08 04:43:01", "link": "http://arxiv.org/abs/2503.06054v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Constructions are Revealed in Word Distributions", "abstract": "Construction grammar posits that constructions (form-meaning pairings) are\nacquired through experience with language (the distributional learning\nhypothesis). But how much information about constructions does this\ndistribution actually contain? Corpus-based analyses provide some answers, but\ntext alone cannot answer counterfactual questions about what caused a\nparticular word to occur. For that, we need computable models of the\ndistribution over strings -- namely, pretrained language models (PLMs). Here we\ntreat a RoBERTa model as a proxy for this distribution and hypothesize that\nconstructions will be revealed within it as patterns of statistical affinity.\nWe support this hypothesis experimentally: many constructions are robustly\ndistinguished, including (i) hard cases where semantically distinct\nconstructions are superficially similar, as well as (ii) schematic\nconstructions, whose \"slots\" can be filled by abstract word classes. Despite\nthis success, we also provide qualitative evidence that statistical affinity\nalone may be insufficient to identify all constructions from text. Thus,\nstatistical affinity is likely an important, but partial, signal available to\nlearners.", "published": "2025-03-08 04:22:28", "link": "http://arxiv.org/abs/2503.06048v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DSGBench: A Diverse Strategic Game Benchmark for Evaluating LLM-based Agents in Complex Decision-Making Environments", "abstract": "Large Language Model~(LLM) based agents have been increasingly popular in\nsolving complex and dynamic tasks, which requires proper evaluation systems to\nassess their capabilities. Nevertheless, existing benchmarks usually either\nfocus on single-objective tasks or use overly broad assessing metrics, failing\nto provide a comprehensive inspection of the actual capabilities of LLM-based\nagents in complicated decision-making tasks. To address these issues, we\nintroduce DSGBench, a more rigorous evaluation platform for strategic\ndecision-making. Firstly, it incorporates six complex strategic games which\nserve as ideal testbeds due to their long-term and multi-dimensional\ndecision-making demands and flexibility in customizing tasks of various\ndifficulty levels or multiple targets. Secondly, DSGBench employs a\nfine-grained evaluation scoring system which examines the decision-making\ncapabilities by looking into the performance in five specific dimensions and\noffering a comprehensive assessment in a well-designed way. Furthermore,\nDSGBench also incorporates an automated decision-tracking mechanism which\nenables in-depth analysis of agent behaviour patterns and the changes in their\nstrategies. We demonstrate the advances of DSGBench by applying it to multiple\npopular LLM-based agents and our results suggest that DSGBench provides\nvaluable insights in choosing LLM-based agents as well as improving their\nfuture development. DSGBench is available at\nhttps://github.com/DeciBrain-Group/DSGBench.", "published": "2025-03-08 04:17:23", "link": "http://arxiv.org/abs/2503.06047v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "RouterEval: A Comprehensive Benchmark for Routing LLMs to Explore Model-level Scaling Up in LLMs", "abstract": "Routing large language models (LLMs) is a novel paradigm that recommends the\nmost suitable LLM from a pool of candidates to process a given input through a\nwell-designed router. Our comprehensive analysis reveals a model-level\nscaling-up phenomenon in LLMs, i.e., a capable router can significantly enhance\nthe performance of this paradigm as the number of candidates increases. This\nimprovement can even easily surpass the performance of the best single model in\nthe pool and most existing strong LLMs, making it a highly promising paradigm.\nHowever, the lack of comprehensive and open-source benchmarks for Routing LLMs\nhas hindered the development of routers. In this paper, we introduce\nRouterEval, a benchmark designed specifically for router research, which\nincludes over 200,000,000 performance records for 12 popular LLM evaluations\nacross areas such as knowledge-based Q&A, commonsense reasoning, semantic\nunderstanding, mathematical reasoning, and instruction following, based on more\nthan 8,500 LLMs. Using RouterEval, extensive evaluations of existing Routing\nLLM methods reveal that most still have significant room for improvement. See\nhttps://github.com/MilkThink-Lab/RouterEval for all data, code, and tutorials.", "published": "2025-03-08 04:07:07", "link": "http://arxiv.org/abs/2503.10657v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mitigating Memorization in LLMs using Activation Steering", "abstract": "The memorization of training data by Large Language Models (LLMs) poses\nsignificant risks, including privacy leaks and the regurgitation of copyrighted\ncontent. Activation steering, a technique that directly intervenes in model\nactivations, has emerged as a promising approach for manipulating LLMs. In this\nwork, we explore the effectiveness of activation steering in reducing\nmemorization while preserving generalization capabilities. We conduct empirical\nevaluations using a controlled memorization benchmark of literary material and\ndemonstrate that our method successfully suppresses memorized content with\nminimal degradation in model performance in Gemma. Additionally, we analyze the\ntrade-offs between suppression effectiveness and linguistic fluency,\nhighlighting the advantages and limitations of activation-based interventions.\nOur findings contribute to ongoing efforts in developing safer and more\nprivacy-preserving LLMs by providing a practical and efficient mechanism to\nmitigate unintended memorization.", "published": "2025-03-08 03:37:07", "link": "http://arxiv.org/abs/2503.06040v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rank-R1: Enhancing Reasoning in LLM-based Document Rerankers via Reinforcement Learning", "abstract": "In this paper, we introduce Rank-R1, a novel LLM-based reranker that performs\nreasoning over both the user query and candidate documents before performing\nthe ranking task. Existing document reranking methods based on large language\nmodels (LLMs) typically rely on prompting or fine-tuning LLMs to order or label\ncandidate documents according to their relevance to a query. For Rank-R1, we\nuse a reinforcement learning algorithm along with only a small set of relevance\nlabels (without any reasoning supervision) to enhance the reasoning ability of\nLLM-based rerankers. Our hypothesis is that adding reasoning capabilities to\nthe rerankers can improve their relevance assessement and ranking capabilities.\nOur experiments on the TREC DL and BRIGHT datasets show that Rank-R1 is highly\neffective, especially for complex queries. In particular, we find that Rank-R1\nachieves effectiveness on in-domain datasets at par with that of supervised\nfine-tuning methods, but utilizing only 18\\% of the training data used by the\nfine-tuning methods. We also find that the model largely outperforms zero-shot\nand supervised fine-tuning when applied to out-of-domain datasets featuring\ncomplex queries, especially when a 14B-size model is used. Finally, we\nqualitatively observe that Rank-R1's reasoning process improves the\nexplainability of the ranking results, opening new opportunities for search\nengine results presentation and fruition.", "published": "2025-03-08 03:14:26", "link": "http://arxiv.org/abs/2503.06034v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "SmartBench: Is Your LLM Truly a Good Chinese Smartphone Assistant?", "abstract": "Large Language Models (LLMs) have become integral to daily life, especially\nadvancing as intelligent assistants through on-device deployment on\nsmartphones. However, existing LLM evaluation benchmarks predominantly focus on\nobjective tasks like mathematics and coding in English, which do not\nnecessarily reflect the practical use cases of on-device LLMs in real-world\nmobile scenarios, especially for Chinese users. To address these gaps, we\nintroduce SmartBench, the first benchmark designed to evaluate the capabilities\nof on-device LLMs in Chinese mobile contexts. We analyze functionalities\nprovided by representative smartphone manufacturers and divide them into five\ncategories: text summarization, text Q\\&A, information extraction, content\ncreation, and notification management, further detailed into 20 specific tasks.\nFor each task, we construct high-quality datasets comprising 50 to 200\nquestion-answer pairs that reflect everyday mobile interactions, and we develop\nautomated evaluation criteria tailored for these tasks. We conduct\ncomprehensive evaluations of on-device LLMs and MLLMs using SmartBench and also\nassess their performance after quantized deployment on real smartphone NPUs.\nOur contributions provide a standardized framework for evaluating on-device\nLLMs in Chinese, promoting further development and optimization in this\ncritical area. Code and data will be available at\nhttps://github.com/Lucky-Lance/SmartBench.", "published": "2025-03-08 03:02:21", "link": "http://arxiv.org/abs/2503.06029v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GenieBlue: Integrating both Linguistic and Multimodal Capabilities for Large Language Models on Mobile Devices", "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have enabled\ntheir deployment on mobile devices. However, challenges persist in maintaining\nstrong language capabilities and ensuring hardware compatibility, both of which\nare crucial for user experience and practical deployment efficiency. In our\ndeployment process, we observe that existing MLLMs often face performance\ndegradation on pure language tasks, and the current NPU platforms on\nsmartphones do not support the MoE architecture, which is commonly used to\npreserve pure language capabilities during multimodal training. To address\nthese issues, we systematically analyze methods to maintain pure language\ncapabilities during the training of MLLMs, focusing on both training data and\nmodel architecture aspects. Based on these analyses, we propose GenieBlue, an\nefficient MLLM structural design that integrates both linguistic and multimodal\ncapabilities for LLMs on mobile devices. GenieBlue freezes the original LLM\nparameters during MLLM training to maintain pure language capabilities. It\nacquires multimodal capabilities by duplicating specific transformer blocks for\nfull fine-tuning and integrating lightweight LoRA modules. This approach\npreserves language capabilities while achieving comparable multimodal\nperformance through extensive training. Deployed on smartphone NPUs, GenieBlue\ndemonstrates efficiency and practicality for applications on mobile devices.", "published": "2025-03-08 02:40:29", "link": "http://arxiv.org/abs/2503.06019v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Intent-Aware Self-Correction for Mitigating Social Biases in Large Language Models", "abstract": "Self-Correction based on feedback improves the output quality of Large\nLanguage Models (LLMs). Moreover, as Self-Correction functions like the slow\nand conscious System-2 thinking from cognitive psychology's perspective, it can\npotentially reduce LLMs' social biases. LLMs are sensitive to contextual\nambiguities and inconsistencies; therefore, explicitly communicating their\nintentions during interactions when applying Self-Correction for debiasing is\ncrucial. In this study, we demonstrate that clarifying intentions is essential\nfor effectively reducing biases in LLMs through Self-Correction. We divide the\ncomponents needed for Self-Correction into three parts: instruction, response,\nand feedback, and clarify intentions at each component. We incorporate an\nexplicit debiasing prompt to convey the intention of bias mitigation from the\ninstruction for response generation. In the response, we use Chain-of-Thought\n(CoT) to clarify the reasoning process. In the feedback, we define evaluation\naspects necessary for debiasing and propose clear feedback through multi-aspect\ncritiques and scoring. Through experiments, we demonstrate that self-correcting\nCoT responses obtained from a debiasing prompt based on multi-aspect feedback\ncan reduce biased responses more robustly and consistently than the baselines.\nWe also find the variation in debiasing efficacy when using models with\ndifferent bias levels or separating models for response and feedback\ngeneration.", "published": "2025-03-08 02:20:43", "link": "http://arxiv.org/abs/2503.06011v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Psycholinguistic Analyses in Software Engineering Text: A Systematic Literature Review", "abstract": "Context: A deeper understanding of human factors in software engineering (SE)\nis essential for improving team collaboration, decision-making, and\nproductivity. Communication channels like code reviews and chats provide\ninsights into developers' psychological and emotional states. While large\nlanguage models excel at text analysis, they often lack transparency and\nprecision. Psycholinguistic tools like Linguistic Inquiry and Word Count (LIWC)\noffer clearer, interpretable insights into cognitive and emotional processes\nexhibited in text. Despite its wide use in SE research, no comprehensive review\nof LIWC's use has been conducted. Objective: We examine the importance of\npsycholinguistic tools, particularly LIWC, and provide a thorough analysis of\nits current and potential future applications in SE research. Methods: We\nconducted a systematic review of six prominent databases, identifying 43\nSE-related papers using LIWC. Our analysis focuses on five research questions.\nResults: Our findings reveal a wide range of applications, including analyzing\nteam communication to detect developer emotions and personality, developing ML\nmodels to predict deleted Stack Overflow posts, and more recently comparing\nAI-generated and human-written text. LIWC has been primarily used with data\nfrom project management platforms (e.g., GitHub) and Q&A forums (e.g., Stack\nOverflow). Key BSE concepts include Communication, Organizational Climate, and\nPositive Psychology. 26 of 43 papers did not formally evaluate LIWC. Concerns\nwere raised about some limitations, including difficulty handling SE-specific\nvocabulary. Conclusion: We highlight the potential of psycholinguistic tools\nand their limitations, and present new use cases for advancing the research of\nhuman factors in SE (e.g., bias in human-LLM conversations).", "published": "2025-03-08 00:23:13", "link": "http://arxiv.org/abs/2503.05992v1", "categories": ["cs.SE", "cs.CL", "cs.CY"], "primary_category": "cs.SE"}
{"title": "The Computational Complexity of Positive Non-Clashing Teaching in Graphs", "abstract": "We study the classical and parameterized complexity of computing the positive\nnon-clashing teaching dimension of a set of concepts, that is, the smallest\nnumber of examples per concept required to successfully teach an intelligent\nlearner under the considered, previously established model. For any class of\nconcepts, it is known that this problem can be effortlessly transferred to the\nsetting of balls in a graph G. We establish (1) the NP-hardness of the problem\neven when restricted to instances with positive non-clashing teaching dimension\nk=2 and where all balls in the graph are present, (2) near-tight running time\nupper and lower bounds for the problem on general graphs, (3) fixed-parameter\ntractability when parameterized by the vertex integrity of G, and (4) a lower\nbound excluding fixed-parameter tractability when parameterized by the feedback\nvertex number and pathwidth of G, even when combined with k. Our results\nprovide a nearly complete understanding of the complexity landscape of\ncomputing the positive non-clashing teaching dimension and answer open\nquestions from the literature.", "published": "2025-03-08 21:48:02", "link": "http://arxiv.org/abs/2503.07665v1", "categories": ["cs.CC", "cs.DM", "cs.DS", "cs.LG", "stat.ML"], "primary_category": "cs.CC"}
{"title": "Characterizing optimal monitoring edge-geodetic sets for some structured graph classes", "abstract": "Given a graph $G=(V,E)$, a set $S\\subseteq V$ is said to be a monitoring\nedge-geodetic set if the deletion of any edge in the graph results in a change\nin the distance between at least one pair of vertices in $S$. The minimum size\nof such a set in $G$ is called the monitoring edge-geodetic number of $G$ and\nis denoted by $meg(G)$.\n  In this work, we compute the monitoring edge-geodetic number efficiently for\nthe following graph classes: distance-hereditary graphs, $P_4$-sparse graphs,\nbipartite permutation graphs, and strongly chordal graphs. The algorithms\nfollow from structural characterizations of the optimal monitoring\nedge-geodetic sets for these graph classes in terms of \\emph{mandatory\nvertices} (those that need to be in every solution). This extends previous\nresults from the literature for cographs, interval graphs and block graphs.", "published": "2025-03-08 06:18:38", "link": "http://arxiv.org/abs/2503.06086v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Higher-Order Belief in Incomplete Information MAIDs", "abstract": "Multi-agent influence diagrams (MAIDs) are probabilistic graphical models\nwhich represent strategic interactions between agents. MAIDs are equivalent to\nextensive form games (EFGs) but have a more compact and informative structure.\nHowever, MAIDs cannot, in general, represent settings of incomplete information\n-- wherein agents have different beliefs about the game being played, and\ndifferent beliefs about each-other's beliefs. In this paper, we introduce\nincomplete information MAIDs (II-MAIDs). We define both infinite and\nfinite-depth II-MAIDs and prove an equivalence relation to EFGs with incomplete\ninformation and no common prior over types. We prove that II-MAIDs inherit\nclassical equilibria concepts via this equivalence, but note that these\nsolution concepts are often unrealistic in the setting with no common prior\nbecause they violate common knowledge of rationality. We define a more\nrealistic solution concept based on recursive best-response. Throughout, we\ndescribe an example with a hypothetical AI agent undergoing evaluation to\nillustrate the applicability of II-MAIDs.", "published": "2025-03-08 19:35:55", "link": "http://arxiv.org/abs/2503.06323v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Optimal Output Feedback Learning Control for Discrete-Time Linear Quadratic Regulation", "abstract": "This paper studies the linear quadratic regulation (LQR) problem of unknown\ndiscrete-time systems via dynamic output feedback learning control. In contrast\nto the state feedback, the optimality of the dynamic output feedback control\nfor solving the LQR problem requires an implicit condition on the convergence\nof the state observer. Moreover, due to unknown system matrices and the\nexistence of observer error, it is difficult to analyze the convergence and\nstability of most existing output feedback learning-based control methods. To\ntackle these issues, we propose a generalized dynamic output feedback learning\ncontrol approach with guaranteed convergence, stability, and optimality\nperformance for solving the LQR problem of unknown discrete-time linear\nsystems. In particular, a dynamic output feedback controller is designed to be\nequivalent to a state feedback controller. This equivalence relationship is an\ninherent property without requiring convergence of the estimated state by the\nstate observer, which plays a key role in establishing the off-policy learning\ncontrol approaches. By value iteration and policy iteration schemes, the\nadaptive dynamic programming based learning control approaches are developed to\nestimate the optimal feedback control gain. In addition, a model-free stability\ncriterion is provided by finding a nonsingular parameterization matrix, which\ncontributes to establishing a switched iteration scheme. Furthermore, the\nconvergence, stability, and optimality analyses of the proposed output feedback\nlearning control approaches are given. Finally, the theoretical results are\nvalidated by two numerical examples.", "published": "2025-03-08 14:02:16", "link": "http://arxiv.org/abs/2503.06226v2", "categories": ["eess.SY", "cs.AI", "cs.MA", "cs.SY", "math.OC"], "primary_category": "eess.SY"}
{"title": "Momentum-based Distributed Resource Scheduling Optimization Subject to Sector-Bound Nonlinearity and Latency", "abstract": "This paper proposes an accelerated consensus-based distributed iterative\nalgorithm for resource allocation and scheduling. The proposed\ngradient-tracking algorithm introduces an auxiliary variable to add momentum\ntowards the optimal state. We prove that this solution is all-time feasible,\nimplying that the coupling constraint always holds along the algorithm\niterative procedure; therefore, the algorithm can be terminated at any time.\nThis is in contrast to the ADMM-based solutions that meet constraint\nfeasibility asymptotically. Further, we show that the proposed algorithm can\nhandle possible link nonlinearity due to logarithmically-quantized data\ntransmission (or any sign-preserving odd sector-bound nonlinear mapping). We\nprove convergence over uniformly-connected dynamic networks (i.e., a hybrid\nsetup) that may occur in mobile and time-varying multi-agent networks. Further,\nthe latency issue over the network is addressed by proposing delay-tolerant\nsolutions. To our best knowledge, accelerated momentum-based convergence,\nnonlinear linking, all-time feasibility, uniform network connectivity, and\nhandling (possible) time delays are not altogether addressed in the literature.\nThese contributions make our solution practical in many real-world\napplications.", "published": "2025-03-08 11:08:59", "link": "http://arxiv.org/abs/2503.06167v1", "categories": ["eess.SY", "cs.DC", "cs.MA", "cs.SY", "eess.SP", "math.OC"], "primary_category": "eess.SY"}
{"title": "HIPPO-MAT: Decentralized Task Allocation Using GraphSAGE and Multi-Agent Deep Reinforcement Learning", "abstract": "This paper tackles decentralized continuous task allocation in heterogeneous\nmulti-agent systems. We present a novel framework HIPPO-MAT that integrates\ngraph neural networks (GNN) employing a GraphSAGE architecture to compute\nindependent embeddings on each agent with an Independent Proximal Policy\nOptimization (IPPO) approach for multi-agent deep reinforcement learning. In\nour system, unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs)\nshare aggregated observation data via communication channels while\nindependently processing these inputs to generate enriched state embeddings.\nThis design enables dynamic, cost-optimal, conflict-aware task allocation in a\n3D grid environment without the need for centralized coordination. A modified\nA* path planner is incorporated for efficient routing and collision avoidance.\nSimulation experiments demonstrate scalability with up to 30 agents and\npreliminary real-world validation on JetBot ROS AI Robots, each running its\nmodel on a Jetson Nano and communicating through an ESP-NOW protocol using\nESP32-S3, which confirms the practical viability of the approach that\nincorporates simultaneous localization and mapping (SLAM). Experimental results\nrevealed that our method achieves a high 92.5% conflict-free success rate, with\nonly a 16.49% performance gap compared to the centralized Hungarian method,\nwhile outperforming the heuristic decentralized baseline based on greedy\napproach. Additionally, the framework exhibits scalability with up to 30 agents\nwith allocation processing of 0.32 simulation step time and robustness in\nresponding to dynamically generated tasks.", "published": "2025-03-08 10:44:14", "link": "http://arxiv.org/abs/2503.07662v1", "categories": ["cs.MA", "cs.RO"], "primary_category": "cs.MA"}
{"title": "Vairiational Stochastic Games", "abstract": "The Control as Inference (CAI) framework has successfully transformed\nsingle-agent reinforcement learning (RL) by reframing control tasks as\nprobabilistic inference problems. However, the extension of CAI to multi-agent,\ngeneral-sum stochastic games (SGs) remains underexplored, particularly in\ndecentralized settings where agents operate independently without centralized\ncoordination. In this paper, we propose a novel variational inference framework\ntailored to decentralized multi-agent systems. Our framework addresses the\nchallenges posed by non-stationarity and unaligned agent objectives, proving\nthat the resulting policies form an $\\epsilon$-Nash equilibrium. Additionally,\nwe demonstrate theoretical convergence guarantees for the proposed\ndecentralized algorithms. Leveraging this framework, we instantiate multiple\nalgorithms to solve for Nash equilibrium, mean-field Nash equilibrium, and\ncorrelated equilibrium, with rigorous theoretical convergence analysis.", "published": "2025-03-08 03:21:23", "link": "http://arxiv.org/abs/2503.06037v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Entropy-Assisted Quality Pattern Identification in Finance", "abstract": "Short-term patterns in financial time series form the cornerstone of many\nalgorithmic trading strategies, yet extracting these patterns reliably from\nnoisy market data remains a formidable challenge. In this paper, we propose an\nentropy-assisted framework for identifying high-quality, non-overlapping\npatterns that exhibit consistent behavior over time. We ground our approach in\nthe premise that historical patterns, when accurately clustered and pruned, can\nyield substantial predictive power for short-term price movements. To achieve\nthis, we incorporate an entropy-based measure as a proxy for information gain.\nPatterns that lead to high one-sided movements in historical data, yet retain\nlow local entropy, are more informative in signaling future market direction.\nCompared to conventional clustering techniques such as K-means and Gaussian\nMixture Models (GMM), which often yield biased or unbalanced groupings, our\napproach emphasizes balance over a forced visual boundary, ensuring that\nquality patterns are not lost due to over-segmentation. By emphasizing both\npredictive purity (low local entropy) and historical profitability, our method\nachieves a balanced representation of Buy and Sell patterns, making it better\nsuited for short-term algorithmic trading strategies.", "published": "2025-03-08 15:19:52", "link": "http://arxiv.org/abs/2503.06251v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "A Neural Score Follower for Computer Accompaniment of Polyphonic Musical Instruments", "abstract": "Real-time computer-based accompaniment for human musical performances entails\nthree critical tasks: identifying what the performer is playing, locating their\nposition within the score, and synchronously playing the accompanying parts.\nAmong these, the second task (score following) has been addressed through\nmethods such as dynamic programming on string sequences, Hidden Markov Models\n(HMMs), and Online Time Warping (OLTW). Yet, the remarkably successful\ntechniques of Deep Learning (DL) have not been directly applied to this\nproblem.\n  Therefore, we introduce HeurMiT, a novel DL-based score-following framework,\nutilizing a neural architecture designed to learn compressed latent\nrepresentations that enables precise performer tracking despite deviations from\nthe score. Parallelly, we implement a real-time MIDI data augmentation toolkit,\naimed at enhancing the robustness of these learned representations.\nAdditionally, we integrate the overall system with simple heuristic rules to\ncreate a comprehensive framework that can interface seamlessly with existing\ntranscription and accompaniment technologies.\n  However, thorough experimentation reveals that despite its impressive\ncomputational efficiency, HeurMiT's underlying limitations prevent it from\nbeing practical in real-world score following scenarios. Consequently, we\npresent our work as an introductory exploration into the world of DL-based\nscore followers, while highlighting some promising avenues to encourage future\nresearch towards robust, state-of-the-art neural score following systems.", "published": "2025-03-08 22:16:40", "link": "http://arxiv.org/abs/2503.06348v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Accompaniment Prompt Adherence: A Measure for Evaluating Music Accompaniment Systems", "abstract": "Generative systems of musical accompaniments are rapidly growing, yet there\nare no standardized metrics to evaluate how well generations align with the\nconditional audio prompt. We introduce a distribution-based measure called\n\"Accompaniment Prompt Adherence\" (APA), and validate it through objective\nexperiments on synthetic data perturbations, and human listening tests. Results\nshow that APA aligns well with human judgments of adherence and is\ndiscriminative to transformations that degrade adherence. We release a Python\nimplementation of the metric using the widely adopted pre-trained CLAP\nembedding model, offering a valuable tool for evaluating and comparing\naccompaniment generation systems.", "published": "2025-03-08 21:53:14", "link": "http://arxiv.org/abs/2503.06346v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Zero-AVSR: Zero-Shot Audio-Visual Speech Recognition with LLMs by Learning Language-Agnostic Speech Representations", "abstract": "We explore a novel zero-shot Audio-Visual Speech Recognition (AVSR)\nframework, dubbed Zero-AVSR, which enables speech recognition in target\nlanguages without requiring any audio-visual speech data in those languages.\nSpecifically, we introduce the Audio-Visual Speech Romanizer (AV-Romanizer),\nwhich learns language-agnostic speech representations by predicting Roman text.\nThen, by leveraging the strong multilingual modeling capabilities of Large\nLanguage Models (LLMs), we propose converting the predicted Roman text into\nlanguage-specific graphemes, forming the proposed Cascaded Zero-AVSR. Taking it\na step further, we explore a unified Zero-AVSR approach by directly integrating\nthe audio-visual speech representations encoded by the AV-Romanizer into the\nLLM. This is achieved through finetuning the adapter and the LLM using our\nproposed multi-task learning scheme. To capture the wide spectrum of phonetic\nand linguistic diversity, we also introduce a Multilingual Audio-Visual\nRomanized Corpus (MARC) consisting of 2,916 hours of audio-visual speech data\nacross 82 languages, along with transcriptions in both language-specific\ngraphemes and Roman text. Extensive analysis and experiments confirm that the\nproposed Zero-AVSR framework has the potential to expand language support\nbeyond the languages seen during the training of the AV-Romanizer.", "published": "2025-03-08 16:40:13", "link": "http://arxiv.org/abs/2503.06273v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
