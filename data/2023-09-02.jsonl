{"title": "LinkTransformer: A Unified Package for Record Linkage with Transformer\n  Language Models", "abstract": "Linking information across sources is fundamental to a variety of analyses in\nsocial science, business, and government. While large language models (LLMs)\noffer enormous promise for improving record linkage in noisy datasets, in many\ndomains approximate string matching packages in popular softwares such as R and\nStata remain predominant. These packages have clean, simple interfaces and can\nbe easily extended to a diversity of languages. Our open-source package\nLinkTransformer aims to extend the familiarity and ease-of-use of popular\nstring matching methods to deep learning. It is a general purpose package for\nrecord linkage with transformer LLMs that treats record linkage as a text\nretrieval problem. At its core is an off-the-shelf toolkit for applying\ntransformer models to record linkage with four lines of code. LinkTransformer\ncontains a rich repository of pre-trained transformer semantic similarity\nmodels for multiple languages and supports easy integration of any transformer\nlanguage model from Hugging Face or OpenAI. It supports standard functionality\nsuch as blocking and linking on multiple noisy fields. LinkTransformer APIs\nalso perform other common text data processing tasks, e.g., aggregation, noisy\nde-duplication, and translation-free cross-lingual linkage. Importantly,\nLinkTransformer also contains comprehensive tools for efficient model tuning,\nto facilitate different levels of customization when off-the-shelf models do\nnot provide the required accuracy. Finally, to promote reusability,\nreproducibility, and extensibility, LinkTransformer makes it easy for users to\ncontribute their custom-trained models to its model hub. By combining\ntransformer language models with intuitive APIs that will be familiar to many\nusers of popular string matching packages, LinkTransformer aims to democratize\nthe benefits of LLMs among those who may be less familiar with deep learning\nframeworks.", "published": "2023-09-02 01:45:27", "link": "http://arxiv.org/abs/2309.00789v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Transformer's Ability to Learn Mildly Context-Sensitive\n  Languages", "abstract": "Despite the fact that Transformers perform well in NLP tasks, recent studies\nsuggest that self-attention is theoretically limited in learning even some\nregular and context-free languages. These findings motivated us to think about\ntheir implications in modeling natural language, which is hypothesized to be\nmildly context-sensitive. We test the Transformer's ability to learn mildly\ncontext-sensitive languages of varying complexities, and find that they\ngeneralize well to unseen in-distribution data, but their ability to\nextrapolate to longer strings is worse than that of LSTMs. Our analyses show\nthat the learned self-attention patterns and representations modeled dependency\nrelations and demonstrated counting behavior, which may have helped the models\nsolve the languages.", "published": "2023-09-02 08:17:29", "link": "http://arxiv.org/abs/2309.00857v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Text Representation", "abstract": "Modern NLP breakthrough includes large multilingual models capable of\nperforming tasks across more than 100 languages. State-of-the-art language\nmodels came a long way, starting from the simple one-hot representation of\nwords capable of performing tasks like natural language understanding,\ncommon-sense reasoning, or question-answering, thus capturing both the syntax\nand semantics of texts. At the same time, language models are expanding beyond\nour known language boundary, even competitively performing over very\nlow-resource dialects of endangered languages. However, there are still\nproblems to solve to ensure an equitable representation of texts through a\nunified modeling space across language and speakers. In this survey, we shed\nlight on this iterative progression of multilingual text representation and\ndiscuss the driving factors that ultimately led to the current\nstate-of-the-art. Subsequently, we discuss how the full potential of language\ndemocratization could be obtained, reaching beyond the known limits and what is\nthe scope of improvement in that space.", "published": "2023-09-02 14:21:22", "link": "http://arxiv.org/abs/2309.00949v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ModelScope-Agent: Building Your Customizable Agent System with\n  Open-source Large Language Models", "abstract": "Large language models (LLMs) have recently demonstrated remarkable\ncapabilities to comprehend human intentions, engage in reasoning, and design\nplanning-like behavior. To further unleash the power of LLMs to accomplish\ncomplex tasks, there is a growing trend to build agent framework that equips\nLLMs, such as ChatGPT, with tool-use abilities to connect with massive external\nAPIs. In this work, we introduce ModelScope-Agent, a general and customizable\nagent framework for real-world applications, based on open-source LLMs as\ncontrollers. It provides a user-friendly system library, with customizable\nengine design to support model training on multiple open-source LLMs, while\nalso enabling seamless integration with both model APIs and common APIs in a\nunified way. To equip the LLMs with tool-use abilities, a comprehensive\nframework has been proposed spanning over tool-use data collection, tool\nretrieval, tool registration, memory control, customized model training, and\nevaluation for practical real-world applications. Finally, we showcase\nModelScopeGPT, a real-world intelligent assistant of ModelScope Community based\non the ModelScope-Agent framework, which is able to connect open-source LLMs\nwith more than 1000 public AI models and localized community knowledge in\nModelScope. The ModelScope-Agent\nlibrary\\footnote{https://github.com/modelscope/modelscope-agent} and online\ndemo\\footnote{https://modelscope.cn/studios/damo/ModelScopeGPT/summary} are now\npublicly available.", "published": "2023-09-02 16:50:30", "link": "http://arxiv.org/abs/2309.00986v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights,\n  and Duties", "abstract": "Human values are crucial to human decision-making. Value pluralism is the\nview that multiple correct values may be held in tension with one another\n(e.g., when considering lying to a friend to protect their feelings, how does\none balance honesty with friendship?). As statistical learners, AI systems fit\nto averages by default, washing out these potentially irreducible value\nconflicts. To improve AI systems to better reflect value pluralism, the\nfirst-order challenge is to explore the extent to which AI systems can model\npluralistic human values, rights, and duties as well as their interaction.\n  We introduce ValuePrism, a large-scale dataset of 218k values, rights, and\nduties connected to 31k human-written situations. ValuePrism's contextualized\nvalues are generated by GPT-4 and deemed high-quality by human annotators 91%\nof the time. We conduct a large-scale study with annotators across diverse\nsocial and demographic backgrounds to try to understand whose values are\nrepresented.\n  With ValuePrism, we build Kaleido, an open, light-weight, and structured\nlanguage-based multi-task model that generates, explains, and assesses the\nrelevance and valence (i.e., support or oppose) of human values, rights, and\nduties within a specific context. Humans prefer the sets of values output by\nour system over the teacher GPT-4, finding them more accurate and with broader\ncoverage. In addition, we demonstrate that Kaleido can help explain variability\nin human decision-making by outputting contrasting values. Finally, we show\nthat Kaleido's representations transfer to other philosophical frameworks and\ndatasets, confirming the benefit of an explicit, modular, and interpretable\napproach to value pluralism. We hope that our work will serve as a step to\nmaking more explicit the implicit values behind human decision-making and to\nsteering AI systems to make decisions that are more in accordance with them.", "published": "2023-09-02 01:24:59", "link": "http://arxiv.org/abs/2309.00779v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Knowledge Graph Embeddings for Multi-Lingual Structured Representations\n  of Radiology Reports", "abstract": "The way we analyse clinical texts has undergone major changes over the last\nyears. The introduction of language models such as BERT led to adaptations for\nthe (bio)medical domain like PubMedBERT and ClinicalBERT. These models rely on\nlarge databases of archived medical documents. While performing well in terms\nof accuracy, both the lack of interpretability and limitations to transfer\nacross languages limit their use in clinical setting. We introduce a novel\nlight-weight graph-based embedding method specifically catering radiology\nreports. It takes into account the structure and composition of the report,\nwhile also connecting medical terms in the report through the multi-lingual\nSNOMED Clinical Terms knowledge base. The resulting graph embedding uncovers\nthe underlying relationships among clinical terms, achieving a representation\nthat is better understandable for clinicians and clinically more accurate,\nwithout reliance on large pre-training datasets. We show the use of this\nembedding on two tasks namely disease classification of X-ray reports and image\nclassification. For disease classification our model is competitive with its\nBERT-based counterparts, while being magnitudes smaller in size and training\ndata requirements. For image classification, we show the effectiveness of the\ngraph embedding leveraging cross-modal knowledge transfer and show how this\nmethod is usable across different languages.", "published": "2023-09-02 11:46:41", "link": "http://arxiv.org/abs/2309.00917v2", "categories": ["cs.CL", "cs.AI", "68T07"], "primary_category": "cs.CL"}
{"title": "Bridge Diffusion Model: bridge non-English language-native text-to-image\n  diffusion model with English communities", "abstract": "Text-to-Image generation (TTI) technologies are advancing rapidly, especially\nin the English language communities. However, English-native TTI models\ninherently carry biases from English world centric training data, which creates\na dilemma for development of other language-native TTI models. One common\nchoice is fine-tuning the English-native TTI model with translated samples from\nnon-English communities. It falls short of fully addressing the model bias\nproblem. Alternatively, training non-English language native models from\nscratch can effectively resolve the English world bias, but diverges from the\nEnglish TTI communities, thus not able to utilize the strides continuously\ngaining in the English TTI communities any more. To build non-English language\nnative TTI model meanwhile keep compatability with the English TTI communities,\nwe propose a novel model structure referred as \"Bridge Diffusion Model\" (BDM).\nThe proposed BDM employs a backbone-branch network structure to learn the\nnon-English language semantics while keep the latent space compatible with the\nEnglish-native TTI backbone, in an end-to-end manner. The unique advantages of\nthe proposed BDM are that it's not only adept at generating images that\nprecisely depict non-English language semantics, but also compatible with\nvarious English-native TTI plugins, such as different checkpoints, LoRA,\nControlNet, Dreambooth, and Textual Inversion, etc. Moreover, BDM can\nconcurrently generate content seamlessly combining both non-English native and\nEnglish-native semantics within a single image, fostering cultural interaction.\nWe verify our method by applying BDM to build a Chinese-native TTI model,\nwhereas the method is generic and applicable to any other language.", "published": "2023-09-02 14:30:56", "link": "http://arxiv.org/abs/2309.00952v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Studying the impacts of pre-training using ChatGPT-generated text on\n  downstream tasks", "abstract": "In recent times, significant advancements have been witnessed in the field of\nlanguage models, particularly with the emergence of Large Language Models\n(LLMs) that are trained on vast amounts of data extracted from internet\narchives. These LLMs, such as ChatGPT, have become widely accessible, allowing\nusers to generate text for various purposes including articles, essays, jokes,\nand poetry. Given that LLMs are trained on a diverse range of text sources,\nencompassing platforms like Reddit and Twitter, it is foreseeable that future\ntraining datasets will also incorporate text generated by previous iterations\nof the models themselves. In light of this development, our research aims to\ninvestigate the influence of artificial text in the pre-training phase of\nlanguage models. Specifically, we conducted a comparative analysis between a\nlanguage model, RoBERTa, pre-trained using CNN/DailyMail news articles, and\nChatGPT, which employed the same articles for its training and evaluated their\nperformance on three downstream tasks as well as their potential gender bias,\nusing sentiment analysis as a metric. Through a series of experiments, we\ndemonstrate that the utilization of artificial text during pre-training does\nnot have a significant impact on either the performance of the models in\ndownstream tasks or their gender bias. In conclusion, our findings suggest that\nthe inclusion of text generated by LLMs in their own pre-training process does\nnot yield substantial effects on the subsequent performance of the models in\ndownstream tasks or their potential gender bias.", "published": "2023-09-02 12:56:15", "link": "http://arxiv.org/abs/2309.05668v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Bias and Fairness in Large Language Models: A Survey", "abstract": "Rapid advancements of large language models (LLMs) have enabled the\nprocessing, understanding, and generation of human-like text, with increasing\nintegration into systems that touch our social sphere. Despite this success,\nthese models can learn, perpetuate, and amplify harmful social biases. In this\npaper, we present a comprehensive survey of bias evaluation and mitigation\ntechniques for LLMs. We first consolidate, formalize, and expand notions of\nsocial bias and fairness in natural language processing, defining distinct\nfacets of harm and introducing several desiderata to operationalize fairness\nfor LLMs. We then unify the literature by proposing three intuitive taxonomies,\ntwo for bias evaluation, namely metrics and datasets, and one for mitigation.\nOur first taxonomy of metrics for bias evaluation disambiguates the\nrelationship between metrics and evaluation datasets, and organizes metrics by\nthe different levels at which they operate in a model: embeddings,\nprobabilities, and generated text. Our second taxonomy of datasets for bias\nevaluation categorizes datasets by their structure as counterfactual inputs or\nprompts, and identifies the targeted harms and social groups; we also release a\nconsolidation of publicly-available datasets for improved access. Our third\ntaxonomy of techniques for bias mitigation classifies methods by their\nintervention during pre-processing, in-training, intra-processing, and\npost-processing, with granular subcategories that elucidate research trends.\nFinally, we identify open problems and challenges for future work. Synthesizing\na wide range of recent research, we aim to provide a clear guide of the\nexisting literature that empowers researchers and practitioners to better\nunderstand and prevent the propagation of bias in LLMs.", "published": "2023-09-02 00:32:55", "link": "http://arxiv.org/abs/2309.00770v3", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LeanContext: Cost-Efficient Domain-Specific Question Answering Using\n  LLMs", "abstract": "Question-answering (QA) is a significant application of Large Language Models\n(LLMs), shaping chatbot capabilities across healthcare, education, and customer\nservice. However, widespread LLM integration presents a challenge for small\nbusinesses due to the high expenses of LLM API usage. Costs rise rapidly when\ndomain-specific data (context) is used alongside queries for accurate\ndomain-specific LLM responses. One option is to summarize the context by using\nLLMs and reduce the context. However, this can also filter out useful\ninformation that is necessary to answer some domain-specific queries. In this\npaper, we shift from human-oriented summarizers to AI model-friendly summaries.\nOur approach, LeanContext, efficiently extracts $k$ key sentences from the\ncontext that are closely aligned with the query. The choice of $k$ is neither\nstatic nor random; we introduce a reinforcement learning technique that\ndynamically determines $k$ based on the query and context. The rest of the less\nimportant sentences are reduced using a free open source text reduction method.\nWe evaluate LeanContext against several recent query-aware and query-unaware\ncontext reduction approaches on prominent datasets (arxiv papers and BBC news\narticles). Despite cost reductions of $37.29\\%$ to $67.81\\%$, LeanContext's\nROUGE-1 score decreases only by $1.41\\%$ to $2.65\\%$ compared to a baseline\nthat retains the entire context (no summarization). Additionally, if free\npretrained LLM-based summarizers are used to reduce context (into human\nconsumable summaries), LeanContext can further modify the reduced context to\nenhance the accuracy (ROUGE-1 score) by $13.22\\%$ to $24.61\\%$.", "published": "2023-09-02 06:33:18", "link": "http://arxiv.org/abs/2309.00841v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment\n  of Continuation Writing", "abstract": "The emergence of large language models (LLMs) has sparked significant\ninterest in extending their remarkable language capabilities to speech.\nHowever, modality alignment between speech and text still remains an open\nproblem. Current solutions can be categorized into two strategies. One is a\ncascaded approach where outputs (tokens or states) of a separately trained\nspeech recognition system are used as inputs for LLMs, which limits their\npotential in modeling alignment between speech and text. The other is an\nend-to-end approach that relies on speech instruction data, which is very\ndifficult to collect in large quantities. In this paper, we address these\nissues and propose the BLSP approach that Bootstraps Language-Speech\nPre-training via behavior alignment of continuation writing. We achieve this by\nlearning a lightweight modality adapter between a frozen speech encoder and an\nLLM, ensuring that the LLM exhibits the same generation behavior regardless of\nthe modality of input: a speech segment or its transcript. The training process\ncan be divided into two steps. The first step prompts an LLM to generate texts\nwith speech transcripts as prefixes, obtaining text continuations. In the\nsecond step, these continuations are used as supervised signals to train the\nmodality adapter in an end-to-end manner. We demonstrate that this\nstraightforward process can extend the capabilities of LLMs to speech, enabling\nspeech recognition, speech translation, spoken language understanding, and\nspeech conversation, even in zero-shot cross-lingual scenarios.", "published": "2023-09-02 11:46:05", "link": "http://arxiv.org/abs/2309.00916v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Explainability for Large Language Models: A Survey", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language processing. However, their internal mechanisms are still\nunclear and this lack of transparency poses unwanted risks for downstream\napplications. Therefore, understanding and explaining these models is crucial\nfor elucidating their behaviors, limitations, and social impacts. In this\npaper, we introduce a taxonomy of explainability techniques and provide a\nstructured overview of methods for explaining Transformer-based language\nmodels. We categorize techniques based on the training paradigms of LLMs:\ntraditional fine-tuning-based paradigm and prompting-based paradigm. For each\nparadigm, we summarize the goals and dominant approaches for generating local\nexplanations of individual predictions and global explanations of overall model\nknowledge. We also discuss metrics for evaluating generated explanations, and\ndiscuss how explanations can be leveraged to debug models and improve\nperformance. Lastly, we examine key challenges and emerging opportunities for\nexplanation techniques in the era of LLMs in comparison to conventional machine\nlearning models.", "published": "2023-09-02 22:14:26", "link": "http://arxiv.org/abs/2309.01029v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Recommendations with Pre-Trained Large Language Models for\n  Multimodal Nudging", "abstract": "We present a method for zero-shot recommendation of multimodal non-stationary\ncontent that leverages recent advancements in the field of generative AI. We\npropose rendering inputs of different modalities as textual descriptions and to\nutilize pre-trained LLMs to obtain their numerical representations by computing\nsemantic embeddings. Once unified representations of all content items are\nobtained, the recommendation can be performed by computing an appropriate\nsimilarity metric between them without any additional learning. We demonstrate\nour approach on a synthetic multimodal nudging environment, where the inputs\nconsist of tabular, textual, and visual data.", "published": "2023-09-02 21:29:53", "link": "http://arxiv.org/abs/2309.01026v2", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG", "cs.MM"], "primary_category": "cs.AI"}
{"title": "DiCLET-TTS: Diffusion Model based Cross-lingual Emotion Transfer for\n  Text-to-Speech -- A Study between English and Mandarin", "abstract": "While the performance of cross-lingual TTS based on monolingual corpora has\nbeen significantly improved recently, generating cross-lingual speech still\nsuffers from the foreign accent problem, leading to limited naturalness.\nBesides, current cross-lingual methods ignore modeling emotion, which is\nindispensable paralinguistic information in speech delivery. In this paper, we\npropose DiCLET-TTS, a Diffusion model based Cross-Lingual Emotion Transfer\nmethod that can transfer emotion from a source speaker to the intra- and\ncross-lingual target speakers. Specifically, to relieve the foreign accent\nproblem while improving the emotion expressiveness, the terminal distribution\nof the forward diffusion process is parameterized into a speaker-irrelevant but\nemotion-related linguistic prior by a prior text encoder with the emotion\nembedding as a condition. To address the weaker emotional expressiveness\nproblem caused by speaker disentanglement in emotion embedding, a novel\northogonal projection based emotion disentangling module (OP-EDM) is proposed\nto learn the speaker-irrelevant but emotion-discriminative embedding. Moreover,\na condition-enhanced DPM decoder is introduced to strengthen the modeling\nability of the speaker and the emotion in the reverse diffusion process to\nfurther improve emotion expressiveness in speech delivery. Cross-lingual\nemotion transfer experiments show the superiority of DiCLET-TTS over various\ncompetitive models and the good design of OP-EDM in learning speaker-irrelevant\nbut emotion-discriminative embedding.", "published": "2023-09-02 09:48:46", "link": "http://arxiv.org/abs/2309.00883v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Timbre-reserved Adversarial Attack in Speaker Identification", "abstract": "As a type of biometric identification, a speaker identification (SID) system\nis confronted with various kinds of attacks. The spoofing attacks typically\nimitate the timbre of the target speakers, while the adversarial attacks\nconfuse the SID system by adding a well-designed adversarial perturbation to an\narbitrary speech. Although the spoofing attack copies a similar timbre as the\nvictim, it does not exploit the vulnerability of the SID model and may not make\nthe SID system give the attacker's desired decision. As for the adversarial\nattack, despite the SID system can be led to a designated decision, it cannot\nmeet the specified text or speaker timbre requirements for the specific attack\nscenarios. In this study, to make the attack in SID not only leverage the\nvulnerability of the SID model but also reserve the timbre of the target\nspeaker, we propose a timbre-reserved adversarial attack in the speaker\nidentification. We generate the timbre-reserved adversarial audios by adding an\nadversarial constraint during the different training stages of the voice\nconversion (VC) model. Specifically, the adversarial constraint is using the\ntarget speaker label to optimize the adversarial perturbation added to the VC\nmodel representations and is implemented by a speaker classifier joining in the\nVC model training. The adversarial constraint can help to control the VC model\nto generate the speaker-wised audio. Eventually, the inference of the VC model\nis the ideal adversarial fake audio, which is timbre-reserved and can fool the\nSID system.", "published": "2023-09-02 12:42:03", "link": "http://arxiv.org/abs/2309.00929v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Pretraining Representations for Bioacoustic Few-shot Detection using\n  Supervised Contrastive Learning", "abstract": "Deep learning has been widely used recently for sound event detection and\nclassification. Its success is linked to the availability of sufficiently large\ndatasets, possibly with corresponding annotations when supervised learning is\nconsidered. In bioacoustic applications, most tasks come with few labelled\ntraining data, because annotating long recordings is time consuming and costly.\nTherefore supervised learning is not the best suited approach to solve\nbioacoustic tasks. The bioacoustic community recasted the problem of sound\nevent detection within the framework of few-shot learning, i.e. training a\nsystem with only few labeled examples. The few-shot bioacoustic sound event\ndetection task in the DCASE challenge focuses on detecting events in long audio\nrecordings given only five annotated examples for each class of interest. In\nthis paper, we show that learning a rich feature extractor from scratch can be\nachieved by leveraging data augmentation using a supervised contrastive\nlearning framework. We highlight the ability of this framework to transfer well\nfor five-shot event detection on previously unseen classes in the training\ndata. We obtain an F-score of 63.46\\% on the validation set and 42.7\\% on the\ntest set, ranking second in the DCASE challenge. We provide an ablation study\nfor the critical choices of data augmentation techniques as well as for the\nlearning strategy applied on the training set.", "published": "2023-09-02 09:38:55", "link": "http://arxiv.org/abs/2309.00878v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
