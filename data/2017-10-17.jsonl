{"title": "CASICT Tibetan Word Segmentation System for MLWS2017", "abstract": "We participated in the MLWS 2017 on Tibetan word segmentation task, our\nsystem is trained in a unrestricted way, by introducing a baseline system and\n76w tibetan segmented sentences of ours. In the system character sequence is\nprocessed by the baseline system into word sequence, then a subword unit (BPE\nalgorithm) split rare words into subwords with its corresponding features,\nafter that a neural network classifier is adopted to token each subword into\n\"B,M,E,S\" label, in decoding step a simple rule is used to recover a final word\nsequence. The candidate system for submition is selected by evaluating the\nF-score in dev set pre-extracted from the 76w sentences. Experiment shows that\nthis method can fix segmentation errors of baseline system and result in a\nsignificant performance gain.", "published": "2017-10-17 06:05:50", "link": "http://arxiv.org/abs/1710.06112v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Paying Attention to Multi-Word Expressions in Neural Machine Translation", "abstract": "Processing of multi-word expressions (MWEs) is a known problem for any\nnatural language processing task. Even neural machine translation (NMT)\nstruggles to overcome it. This paper presents results of experiments on\ninvestigating NMT attention allocation to the MWEs and improving automated\ntranslation of sentences that contain MWEs in English->Latvian and\nEnglish->Czech NMT systems. Two improvement strategies were explored -(1)\nbilingual pairs of automatically extracted MWE candidates were added to the\nparallel corpus used to train the NMT system, and (2) full sentences containing\nthe automatically extracted MWE candidates were added to the parallel corpus.\nBoth approaches allowed to increase automated evaluation results. The best\nresult - 0.99 BLEU point increase - has been reached with the first approach,\nwhile with the second approach minimal improvements achieved. We also provide\nopen-source software and tools used for MWE extraction and alignment\ninspection.", "published": "2017-10-17 14:27:36", "link": "http://arxiv.org/abs/1710.06313v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Specialising Word Vectors for Lexical Entailment", "abstract": "We present LEAR (Lexical Entailment Attract-Repel), a novel post-processing\nmethod that transforms any input word vector space to emphasise the asymmetric\nrelation of lexical entailment (LE), also known as the IS-A or\nhyponymy-hypernymy relation. By injecting external linguistic constraints\n(e.g., WordNet links) into the initial vector space, the LE specialisation\nprocedure brings true hyponymy-hypernymy pairs closer together in the\ntransformed Euclidean space. The proposed asymmetric distance measure adjusts\nthe norms of word vectors to reflect the actual WordNet-style hierarchy of\nconcepts. Simultaneously, a joint objective enforces semantic similarity using\nthe symmetric cosine distance, yielding a vector space specialised for both\nlexical relations at once. LEAR specialisation achieves state-of-the-art\nperformance in the tasks of hypernymy directionality, hypernymy detection, and\ngraded lexical entailment, demonstrating the effectiveness and robustness of\nthe proposed asymmetric specialisation model.", "published": "2017-10-17 16:39:09", "link": "http://arxiv.org/abs/1710.06371v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RETUYT in TASS 2017: Sentiment Analysis for Spanish Tweets using SVM and\n  CNN", "abstract": "This article presents classifiers based on SVM and Convolutional Neural\nNetworks (CNN) for the TASS 2017 challenge on tweets sentiment analysis. The\nclassifier with the best performance in general uses a combination of SVM and\nCNN. The use of word embeddings was particularly useful for improving the\nclassifiers performance.", "published": "2017-10-17 17:02:54", "link": "http://arxiv.org/abs/1710.06393v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Sentence Representations as Word Information Series:\n  Revisiting TF--IDF", "abstract": "Sentence representation at the semantic level is a challenging task for\nNatural Language Processing and Artificial Intelligence. Despite the advances\nin word embeddings (i.e. word vector representations), capturing sentence\nmeaning is an open question due to complexities of semantic interactions among\nwords. In this paper, we present an embedding method, which is aimed at\nlearning unsupervised sentence representations from unlabeled text. We propose\nan unsupervised method that models a sentence as a weighted series of word\nembeddings. The weights of the word embeddings are fitted by using Shannon's\nword entropies provided by the Term Frequency--Inverse Document Frequency\n(TF--IDF) transform. The hyperparameters of the model can be selected according\nto the properties of data (e.g. sentence length and textual gender).\nHyperparameter selection involves word embedding methods and dimensionalities,\nas well as weighting schemata. Our method offers advantages over existing\nmethods: identifiable modules, short-term training, online inference of\n(unseen) sentence representations, as well as independence from domain,\nexternal knowledge and language resources. Results showed that our model\noutperformed the state of the art in well-known Semantic Textual Similarity\n(STS) benchmarks. Moreover, our model reached state-of-the-art performance when\ncompared to supervised and knowledge-based STS systems.", "published": "2017-10-17 23:13:32", "link": "http://arxiv.org/abs/1710.06524v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Embedding-Based Speaker Adaptive Training of Deep Neural Networks", "abstract": "An embedding-based speaker adaptive training (SAT) approach is proposed and\ninvestigated in this paper for deep neural network acoustic modeling. In this\napproach, speaker embedding vectors, which are a constant given a particular\nspeaker, are mapped through a control network to layer-dependent element-wise\naffine transformations to canonicalize the internal feature representations at\nthe output of hidden layers of a main network. The control network for\ngenerating the speaker-dependent mappings is jointly estimated with the main\nnetwork for the overall speaker adaptive acoustic modeling. Experiments on\nlarge vocabulary continuous speech recognition (LVCSR) tasks show that the\nproposed SAT scheme can yield superior performance over the widely-used\nspeaker-aware training using i-vectors with speaker-adapted input features.", "published": "2017-10-17 17:10:11", "link": "http://arxiv.org/abs/1710.06937v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Task Label Embedding for Text Classification", "abstract": "Multi-task learning in text classification leverages implicit correlations\namong related tasks to extract common features and yield performance gains.\nHowever, most previous works treat labels of each task as independent and\nmeaningless one-hot vectors, which cause a loss of potential information and\nmakes it difficult for these models to jointly learn three or more tasks. In\nthis paper, we propose Multi-Task Label Embedding to convert labels in text\nclassification into semantic vectors, thereby turning the original tasks into\nvector matching tasks. We implement unsupervised, supervised and\nsemi-supervised models of Multi-Task Label Embedding, all utilizing semantic\ncorrelations among tasks and making it particularly convenient to scale and\ntransfer as more tasks are involved. Extensive experiments on five benchmark\ndatasets for text classification show that our models can effectively improve\nperformances of related tasks with semantic representations of labels and\nadditional information from each other.", "published": "2017-10-17 23:35:58", "link": "http://arxiv.org/abs/1710.07210v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interactively Picking Real-World Objects with Unconstrained Spoken\n  Language Instructions", "abstract": "Comprehension of spoken natural language is an essential component for robots\nto communicate with human effectively. However, handling unconstrained spoken\ninstructions is challenging due to (1) complex structures including a wide\nvariety of expressions used in spoken language and (2) inherent ambiguity in\ninterpretation of human instructions. In this paper, we propose the first\ncomprehensive system that can handle unconstrained spoken language and is able\nto effectively resolve ambiguity in spoken instructions. Specifically, we\nintegrate deep-learning-based object detection together with natural language\nprocessing technologies to handle unconstrained spoken instructions, and\npropose a method for robots to resolve instruction ambiguity through dialogue.\nThrough our experiments on both a simulated environment as well as a physical\nindustrial robot arm, we demonstrate the ability of our system to understand\nnatural instructions from human operators effectively, and how higher success\nrates of the object picking task can be achieved through an interactive\nclarification process.", "published": "2017-10-17 13:46:59", "link": "http://arxiv.org/abs/1710.06280v2", "categories": ["cs.RO", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Describing Natural Images Containing Novel Objects with Knowledge Guided\n  Assitance", "abstract": "Images in the wild encapsulate rich knowledge about varied abstract concepts\nand cannot be sufficiently described with models built only using image-caption\npairs containing selected objects. We propose to handle such a task with the\nguidance of a knowledge base that incorporate many abstract concepts. Our\nmethod is a two-step process where we first build a multi-entity-label image\nrecognition model to predict abstract concepts as image labels and then\nleverage them in the second step as an external semantic attention and\nconstrained inference in the caption generation model for describing images\nthat depict unseen/novel objects. Evaluations show that our models outperform\nmost of the prior work for out-of-domain captioning on MSCOCO and are useful\nfor integration of knowledge and vision in general.", "published": "2017-10-17 14:11:37", "link": "http://arxiv.org/abs/1710.06303v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Constructing Datasets for Multi-hop Reading Comprehension Across\n  Documents", "abstract": "Most Reading Comprehension methods limit themselves to queries which can be\nanswered using a single sentence, paragraph, or document. Enabling models to\ncombine disjoint pieces of textual evidence would extend the scope of machine\ncomprehension methods, but currently there exist no resources to train and test\nthis capability. We propose a novel task to encourage the development of models\nfor text understanding across multiple documents and to investigate the limits\nof existing methods. In our task, a model learns to seek and combine evidence -\neffectively performing multi-hop (alias multi-step) inference. We devise a\nmethodology to produce datasets for this task, given a collection of\nquery-answer pairs and thematically linked documents. Two datasets from\ndifferent domains are induced, and we identify potential pitfalls and devise\ncircumvention strategies. We evaluate two previously proposed competitive\nmodels and find that one can integrate information across documents. However,\nboth models struggle to select relevant information, as providing documents\nguaranteed to be relevant greatly improves their performance. While the models\noutperform several strong baselines, their best accuracy reaches 42.9% compared\nto human performance at 74.0% - leaving ample room for improvement.", "published": "2017-10-17 19:35:07", "link": "http://arxiv.org/abs/1710.06481v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PubMed 200k RCT: a Dataset for Sequential Sentence Classification in\n  Medical Abstracts", "abstract": "We present PubMed 200k RCT, a new dataset based on PubMed for sequential\nsentence classification. The dataset consists of approximately 200,000\nabstracts of randomized controlled trials, totaling 2.3 million sentences. Each\nsentence of each abstract is labeled with their role in the abstract using one\nof the following classes: background, objective, method, result, or conclusion.\nThe purpose of releasing this dataset is twofold. First, the majority of\ndatasets for sequential short-text classification (i.e., classification of\nshort texts that appear in sequences) are small: we hope that releasing a new\nlarge dataset will help develop more accurate algorithms for this task. Second,\nfrom an application perspective, researchers need better tools to efficiently\nskim through the literature. Automatically classifying each sentence in an\nabstract would help researchers read abstracts more efficiently, especially in\nfields where abstracts may be long, such as the medical field.", "published": "2017-10-17 03:22:00", "link": "http://arxiv.org/abs/1710.06071v1", "categories": ["cs.CL", "cs.AI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Fishing for Clickbaits in Social Images and Texts with\n  Linguistically-Infused Neural Network Models", "abstract": "This paper presents the results and conclusions of our participation in the\nClickbait Challenge 2017 on automatic clickbait detection in social media. We\nfirst describe linguistically-infused neural network models and identify\ninformative representations to predict the level of clickbaiting present in\nTwitter posts. Our models allow to answer the question not only whether a post\nis a clickbait or not, but to what extent it is a clickbait post e.g., not at\nall, slightly, considerably, or heavily clickbaity using a score ranging from 0\nto 1. We evaluate the predictive power of models trained on varied text and\nimage representations extracted from tweets. Our best performing model that\nrelies on the tweet text and linguistic markers of biased language extracted\nfrom the tweet and the corresponding page yields mean squared error (MSE) of\n0.04, mean absolute error (MAE) of 0.16 and R2 of 0.43 on the held-out test\ndata. For the binary classification setup (clickbait vs. non-clickbait), our\nmodel achieved F1 score of 0.69. We have not found that image representations\ncombined with text yield significant performance improvement yet. Nevertheless,\nthis work is the first to present preliminary analysis of objects extracted\nusing Google Tensorflow object detection API from images in clickbait vs.\nnon-clickbait Twitter posts. Finally, we outline several steps to improve model\nperformance as a part of the future work.", "published": "2017-10-17 17:00:59", "link": "http://arxiv.org/abs/1710.06390v1", "categories": ["cs.LG", "cs.CL", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Laying Down the Yellow Brick Road: Development of a Wizard-of-Oz\n  Interface for Collecting Human-Robot Dialogue", "abstract": "We describe the adaptation and refinement of a graphical user interface\ndesigned to facilitate a Wizard-of-Oz (WoZ) approach to collecting human-robot\ndialogue data. The data collected will be used to develop a dialogue system for\nrobot navigation. Building on an interface previously used in the development\nof dialogue systems for virtual agents and video playback, we add templates\nwith open parameters which allow the wizard to quickly produce a wide variety\nof utterances. Our research demonstrates that this approach to data collection\nis viable as an intermediate step in developing a dialogue system for physical\nrobots in remote locations from their users - a domain in which the human and\nrobot need to regularly verify and update a shared understanding of the\nphysical environment. We show that our WoZ interface and the fixed set of\nutterances and templates therein provide for a natural pace of dialogue with\ngood coverage of the navigation domain.", "published": "2017-10-17 17:34:31", "link": "http://arxiv.org/abs/1710.06406v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.RO"], "primary_category": "cs.CL"}
