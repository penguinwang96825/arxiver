{"title": "EmbRACE-3K: Embodied Reasoning and Action in Complex Environments", "abstract": "Recent advanced vision-language models(VLMs) have demonstrated strong\nperformance on passive, offline image and video understanding tasks. However,\ntheir effectiveness in embodied settings, which require online interaction and\nactive scene understanding remains limited. In such scenarios, an agent\nperceives the environment from a first-person perspective, with each action\ndynamically shaping subsequent observations. Even state-of-the-art models such\nas GPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro struggle in open-environment\ninteractions, exhibiting clear limitations in spatial reasoning and\nlong-horizon planning. To address this gap, we introduce EmRACE-3K, a dataset\nof over 3,000 language-guided tasks situated in diverse, photorealistic\nenvironments constructed using Unreal Engine and the UnrealCV-Zoo framework.\nThe tasks encompass a wide range of embodied challenges, including navigation,\nobject manipulation, and multi-stage goal execution. Each task unfolds as a\nmulti-step trajectory, pairing first-person visual observations with high-level\ninstructions, grounded actions, and natural language rationales that express\nthe agent's intent at every step. Using EmRACE-3K, we establish a benchmark to\nevaluate the embodied reasoning capabilities of VLMs across three key\ndimensions: Exploration, Dynamic Spatial-Semantic Reasoning, and Multi-stage\nGoal Execution. In zero-shot settings, all models achieve success rates below\n20%, underscoring the challenge posed by our benchmark and the current\nlimitations of VLMs in interactive environments. To demonstrate the utility of\nEmRACE-3K, we further fine-tune Qwen2.5-VL-7B using supervised learning\nfollowed by reinforcement learning. This approach yields substantial\nimprovements across all three challenge categories, highlighting the dataset's\neffectiveness in enabling the development of embodied reasoning capabilities.", "published": "2025-07-14 17:59:46", "link": "http://arxiv.org/abs/2507.10548v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "REST: Stress Testing Large Reasoning Models by Asking Multiple Problems at Once", "abstract": "Recent Large Reasoning Models (LRMs) have achieved remarkable progress on\ntask-specific benchmarks, yet their evaluation methods remain constrained by\nisolated problem-solving paradigms. Existing benchmarks predominantly assess\nsingle-question reasoning through sequential testing, resulting critical\nlimitations: (1) vulnerability to data contamination and less challenging\n(e.g., DeepSeek-R1 achieves 97.0% on MATH500), forcing costly and perpetual\ncreation of new questions with large human efforts, (2) failure to evaluate\nmodels under multi-context pressure, a key requirement for real-world\ndeployment. To bridge this gap, we present REST (Reasoning Evaluation through\nSimultaneous Testing), a stress-testing framework that concurrently exposes\nLRMs to multiple problems simultaneously. Beyond basic reasoning, REST\nspecifically evaluates several under-tested capabilities: contextual priority\nallocation, cross-problem interference resistance, and dynamic cognitive load\nmanagement. Our evaluation reveals several striking findings: Even\nstate-of-the-art (SOTA) models like DeepSeek-R1 exhibit substantial performance\ndegradation under stress testing. Crucially, REST demonstrates stronger\ndiscriminative power than existing benchmarks, revealing pronounced performance\ndifferences among models that exhibit similar, near-ceiling performance under\nsingle-question evaluations. Some key mechanistic insights emerge from our\nanalysis: (1) the \"overthinking trap\" is a critical factor contributing to the\nperformance degradation; (2) the models trained with \"long2short\" technique\npreserve more accuracy of their single-problem performance under REST,\noutperforming standard-trained counterparts. These results establish REST as a\ncost-efficient, future-proof evaluation paradigm that better reflects\nreal-world reasoning demands while reducing reliance on continuous human\nannotation.", "published": "2025-07-14 17:58:47", "link": "http://arxiv.org/abs/2507.10541v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks", "abstract": "Large Language Models (LLMs) have significantly advanced the state-of-the-art\nin various coding tasks. Beyond directly answering user queries, LLMs can also\nserve as judges, assessing and comparing the quality of responses generated by\nother models. Such an evaluation capability is crucial both for benchmarking\ndifferent LLMs and for improving response quality through response ranking.\nHowever, despite the growing adoption of the LLM-as-a-Judge paradigm, its\neffectiveness in coding scenarios remains underexplored due to the absence of\ndedicated benchmarks. To address this gap, we introduce CodeJudgeBench, a\nbenchmark explicitly designed to evaluate the performance of LLM-as-a-Judge\nmodels across three critical coding tasks: code generation, code repair, and\nunit test generation. Through comprehensive benchmarking of 26 LLM-as-a-Judge\nmodels, we find that recent thinking models significantly outperform\nnon-thinking models on our carefully designed code judging tasks. Notably, even\nrelatively small thinking models, such as Qwen3-8B, can outperform specially\ntrained LLM-as-a-Judge models up to 70B in size. Nevertheless, all models still\nexhibit significant randomness in their judgment of coding tasks. For pairwise\njudging tasks, simply changing the order in which responses are presented can\nsubstantially impact accuracy. In addition, when judging code and unit tests\nwritten by different LLMs, LLM-as-a-Judge models also show variance in\nperformance. This sensitivity raises concerns about the reliability and\nconsistency of LLM-as-a-Judge in coding scenarios. Lastly, we study optimal\nprompting strategies for LLM-as-a-Judge. We find that using pair-wise\ncomparison outperforms scalar point-wise judging. Furthermore, retaining\ncomments and reasoning in the full, unprocessed LLM response leads to improved\njudge performance.", "published": "2025-07-14 17:56:29", "link": "http://arxiv.org/abs/2507.10535v1", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Reasoning or Memorization? Unreliable Results of Reinforcement Learning Due to Data Contamination", "abstract": "The reasoning capabilities of large language models (LLMs) have been a\nlongstanding focus of research. Recent works have further enhanced these\ncapabilities using reinforcement learning (RL), with many new methods claiming\nsignificant improvements with minimal or no external supervision. Surprisingly,\nsome studies even suggest that random or incorrect reward signals can enhance\nreasoning performance. However, these breakthroughs are mostly reported on the\nQwen2.5 model family and evaluated on well-known benchmarks such as MATH-500,\nAMC, and AIME, while failing to achieve similar gains on other models like\nLlama, which warrants further investigation. Our analysis shows that although\nQwen2.5 achieves strong mathematical reasoning performance, its pretraining on\nlarge-scale web corpora makes it vulnerable to data contamination in popular\nbenchmarks. As a result, results derived from these benchmarks may be\nunreliable. To address this, we introduce a generator that produces fully\nsynthetic arithmetic problems of arbitrary length and difficulty, yielding a\nclean dataset we call RandomCalculation. Using these leakage-free datasets, we\nshow that only accurate reward signals consistently improve performance, while\nnoisy or incorrect signals do not. We advocate for evaluating RL methods on\nuncontaminated benchmarks and across diverse model families to ensure\ntrustworthy conclusions.", "published": "2025-07-14 17:55:15", "link": "http://arxiv.org/abs/2507.10532v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation", "abstract": "Scaling language models unlocks impressive capabilities, but the accompanying\ncomputational and memory demands make both training and deployment expensive.\nExisting efficiency efforts typically target either parameter sharing or\nadaptive computation, leaving open the question of how to attain both\nsimultaneously. We introduce Mixture-of-Recursions (MoR), a unified framework\nthat combines the two axes of efficiency inside a single Recursive Transformer.\nMoR reuses a shared stack of layers across recursion steps to achieve parameter\nefficiency, while lightweight routers enable adaptive token-level thinking by\ndynamically assigning different recursion depths to individual tokens. This\nallows MoR to focus quadratic attention computation only among tokens still\nactive at a given recursion depth, further improving memory access efficiency\nby selectively caching only their key-value pairs. Beyond these core\nmechanisms, we also propose a KV sharing variant that reuses KV pairs from the\nfirst recursion, specifically designed to decrease prefill latency and memory\nfootprint. Across model scales ranging from 135M to 1.7B parameters, MoR forms\na new Pareto frontier: at equal training FLOPs and smaller model sizes, it\nsignificantly lowers validation perplexity and improves few-shot accuracy,\nwhile delivering higher throughput compared with vanilla and existing recursive\nbaselines. These gains demonstrate that MoR is an effective path towards\nlarge-model quality without incurring large-model cost.", "published": "2025-07-14 17:49:00", "link": "http://arxiv.org/abs/2507.10524v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DeepResearch$^{\\text{Eco}}$: A Recursive Agentic Workflow for Complex Scientific Question Answering in Ecology", "abstract": "We introduce DeepResearch$^{\\text{Eco}}$, a novel agentic LLM-based system\nfor automated scientific synthesis that supports recursive, depth- and\nbreadth-controlled exploration of original research questions -- enhancing\nsearch diversity and nuance in the retrieval of relevant scientific literature.\nUnlike conventional retrieval-augmented generation pipelines, DeepResearch\nenables user-controllable synthesis with transparent reasoning and\nparameter-driven configurability, facilitating high-throughput integration of\ndomain-specific evidence while maintaining analytical rigor. Applied to 49\necological research questions, DeepResearch achieves up to a 21-fold increase\nin source integration and a 14.9-fold rise in sources integrated per 1,000\nwords. High-parameter settings yield expert-level analytical depth and\ncontextual diversity.\n  Source code available at: https://github.com/sciknoworg/deep-research.", "published": "2025-07-14 17:47:28", "link": "http://arxiv.org/abs/2507.10522v1", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Can You Detect the Difference?", "abstract": "The rapid advancement of large language models (LLMs) has raised concerns\nabout reliably detecting AI-generated text. Stylometric metrics work well on\nautoregressive (AR) outputs, but their effectiveness on diffusion-based models\nis unknown. We present the first systematic comparison of diffusion-generated\ntext (LLaDA) and AR-generated text (LLaMA) using 2 000 samples. Perplexity,\nburstiness, lexical diversity, readability, and BLEU/ROUGE scores show that\nLLaDA closely mimics human text in perplexity and burstiness, yielding high\nfalse-negative rates for AR-oriented detectors. LLaMA shows much lower\nperplexity but reduced lexical fidelity. Relying on any single metric fails to\nseparate diffusion outputs from human writing. We highlight the need for\ndiffusion-aware detectors and outline directions such as hybrid models,\ndiffusion-specific stylometric signatures, and robust watermarking.", "published": "2025-07-14 16:55:57", "link": "http://arxiv.org/abs/2507.10475v1", "categories": ["cs.CL", "cs.AI", "I.2.7; H.3.3"], "primary_category": "cs.CL"}
{"title": "MLAR: Multi-layer Large Language Model-based Robotic Process Automation Applicant Tracking", "abstract": "This paper introduces an innovative Applicant Tracking System (ATS) enhanced\nby a novel Robotic process automation (RPA) framework or as further referred to\nas MLAR. Traditional recruitment processes often encounter bottlenecks in\nresume screening and candidate shortlisting due to time and resource\nconstraints. MLAR addresses these challenges employing Large Language Models\n(LLMs) in three distinct layers: extracting key characteristics from job\npostings in the first layer, parsing applicant resume to identify education,\nexperience, skills in the second layer, and similarity matching in the third\nlayer. These features are then matched through advanced semantic algorithms to\nidentify the best candidates efficiently. Our approach integrates seamlessly\ninto existing RPA pipelines, automating resume parsing, job matching, and\ncandidate notifications. Extensive performance benchmarking shows that MLAR\noutperforms the leading RPA platforms, including UiPath and Automation\nAnywhere, in high-volume resume-processing tasks. When processing 2,400\nresumes, MLAR achieved an average processing time of 5.4 seconds per resume,\nreducing processing time by approximately 16.9% compared to Automation Anywhere\nand 17.1% compared to UiPath. These results highlight the potential of MLAR to\ntransform recruitment workflows by providing an efficient, accurate, and\nscalable solution tailored to modern hiring needs.", "published": "2025-07-14 16:53:19", "link": "http://arxiv.org/abs/2507.10472v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From BERT to Qwen: Hate Detection across architectures", "abstract": "Online platforms struggle to curb hate speech without over-censoring\nlegitimate discourse. Early bidirectional transformer encoders made big\nstrides, but the arrival of ultra-large autoregressive LLMs promises deeper\ncontext-awareness. Whether this extra scale actually improves practical\nhate-speech detection on real-world text remains unverified. Our study puts\nthis question to the test by benchmarking both model families, classic encoders\nand next-generation LLMs, on curated corpora of online interactions for\nhate-speech detection (Hate or No Hate).", "published": "2025-07-14 16:46:30", "link": "http://arxiv.org/abs/2507.10468v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Referential ambiguity and clarification requests: comparing human and LLM behaviour", "abstract": "In this work we examine LLMs' ability to ask clarification questions in\ntask-oriented dialogues that follow the asynchronous\ninstruction-giver/instruction-follower format. We present a new corpus that\ncombines two existing annotations of the Minecraft Dialogue Corpus -- one for\nreference and ambiguity in reference, and one for SDRT including clarifications\n-- into a single common format providing the necessary information to\nexperiment with clarifications and their relation to ambiguity. With this\ncorpus we compare LLM actions with original human-generated clarification\nquestions, examining how both humans and LLMs act in the case of ambiguity. We\nfind that there is only a weak link between ambiguity and humans producing\nclarification questions in these dialogues, and low correlation between humans\nand LLMs. Humans hardly ever produce clarification questions for referential\nambiguity, but often do so for task-based uncertainty. Conversely, LLMs produce\nmore clarification questions for referential ambiguity, but less so for task\nuncertainty. We question if LLMs' ability to ask clarification questions is\npredicated on their recent ability to simulate reasoning, and test this with\ndifferent reasoning approaches, finding that reasoning does appear to increase\nquestion frequency and relevancy.", "published": "2025-07-14 16:28:00", "link": "http://arxiv.org/abs/2507.10445v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multiple Choice Learning of Low Rank Adapters for Language Modeling", "abstract": "We propose LoRA-MCL, a training scheme that extends next-token prediction in\nlanguage models with a method designed to decode diverse, plausible sentence\ncontinuations at inference time. Traditional language modeling is an\nintrinsically ill-posed problem: given a context, multiple futures may be\nequally plausible. Our approach leverages Multiple Choice Learning (MCL) and\nthe Winner-Takes-All (WTA) loss to efficiently handle ambiguity through\nLow-Rank Adaptation (LoRA). We provide a theoretical interpretation of applying\nMultiple Choice Learning to Language Modeling, assuming the data is generated\nfrom a mixture of distributions. To illustrate the proposed approach, we use\ndata sampled from mixtures of Markov chains. We then demonstrate with extensive\nexperiments on real-world visual and audio captioning tasks that our method\nachieves high diversity and relevance in generated outputs.", "published": "2025-07-14 16:00:51", "link": "http://arxiv.org/abs/2507.10419v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Text-to-Remote-Sensing-Image Retrieval beyond RGB Sources", "abstract": "Retrieving relevant imagery from vast satellite archives is crucial for\napplications like disaster response and long-term climate monitoring. However,\nmost text-to-image retrieval systems are limited to RGB data, failing to\nexploit the unique physical information captured by other sensors, such as the\nall-weather structural sensitivity of Synthetic Aperture Radar (SAR) or the\nspectral signatures in optical multispectral data. To bridge this gap, we\nintroduce CrisisLandMark, a new large-scale corpus of over 647,000 Sentinel-1\nSAR and Sentinel-2 multispectral images paired with structured textual\nannotations for land cover, land use, and crisis events harmonized from\nauthoritative land cover systems (CORINE and Dynamic World) and crisis-specific\nsources. We then present CLOSP (Contrastive Language Optical SAR Pretraining),\na novel framework that uses text as a bridge to align unpaired optical and SAR\nimages into a unified embedding space. Our experiments show that CLOSP achieves\na new state-of-the-art, improving retrieval nDGC by 54% over existing models.\nAdditionally, we find that the unified training strategy overcomes the inherent\ndifficulty of interpreting SAR imagery by transferring rich semantic knowledge\nfrom the optical domain with indirect interaction. Furthermore, GeoCLOSP, which\nintegrates geographic coordinates into our framework, creates a powerful\ntrade-off between generality and specificity: while the CLOSP excels at general\nsemantic tasks, the GeoCLOSP becomes a specialized expert for retrieving\nlocation-dependent crisis events and rare geographic features. This work\nhighlights that the integration of diverse sensor data and geographic context\nis essential for unlocking the full potential of remote sensing archives.", "published": "2025-07-14 15:46:56", "link": "http://arxiv.org/abs/2507.10403v1", "categories": ["cs.CV", "cs.CL", "cs.IR", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Devanagari Handwritten Character Recognition using Convolutional Neural Network", "abstract": "Handwritten character recognition is getting popular among researchers\nbecause of its possible applications in facilitating technological search\nengines, social media, recommender systems, etc. The Devanagari script is one\nof the oldest language scripts in India that does not have proper digitization\ntools. With the advancement of computing and technology, the task of this\nresearch is to extract handwritten Hindi characters from an image of Devanagari\nscript with an automated approach to save time and obsolete data. In this\npaper, we present a technique to recognize handwritten Devanagari characters\nusing two deep convolutional neural network layers. This work employs a\nmethodology that is useful to enhance the recognition rate and configures a\nconvolutional neural network for effective Devanagari handwritten text\nrecognition (DHTR). This approach uses the Devanagari handwritten character\ndataset (DHCD), an open dataset with 36 classes of Devanagari characters. Each\nof these classes has 1700 images for training and testing purposes. This\napproach obtains promising results in terms of accuracy by achieving 96.36%\naccuracy in testing and 99.55% in training time.", "published": "2025-07-14 15:38:42", "link": "http://arxiv.org/abs/2507.10398v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "14J60", "I.2.7; I.4; I.5; I.7.5"], "primary_category": "cs.CV"}
{"title": "Meanings are like Onions: a Layered Approach to Metaphor Processing", "abstract": "Metaphorical meaning is not a flat mapping between concepts, but a complex\ncognitive phenomenon that integrates multiple levels of interpretation. In this\npaper, we propose a stratified model of metaphor processing that treats meaning\nas an onion: a multi-layered structure comprising (1) content analysis, (2)\nconceptual blending, and (3) pragmatic intentionality. This three-dimensional\nframework allows for a richer and more cognitively grounded approach to\nmetaphor interpretation in computational systems. At the first level, metaphors\nare annotated through basic conceptual elements. At the second level, we model\nconceptual combinations, linking components to emergent meanings. Finally, at\nthe third level, we introduce a pragmatic vocabulary to capture speaker intent,\ncommunicative function, and contextual effects, aligning metaphor understanding\nwith pragmatic theories. By unifying these layers into a single formal\nframework, our model lays the groundwork for computational methods capable of\nrepresenting metaphorical meaning beyond surface associations, toward deeper,\nmore context-sensitive reasoning.", "published": "2025-07-14 14:56:46", "link": "http://arxiv.org/abs/2507.10354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using AI to replicate human experimental results: a motion study", "abstract": "This paper explores the potential of large language models (LLMs) as reliable\nanalytical tools in linguistic research, focusing on the emergence of affective\nmeanings in temporal expressions involving manner-of-motion verbs. While LLMs\nlike GPT-4 have shown promise across a range of tasks, their ability to\nreplicate nuanced human judgements remains under scrutiny. We conducted four\npsycholinguistic studies (on emergent meanings, valence shifts, verb choice in\nemotional contexts, and sentence-emoji associations) first with human\nparticipants and then replicated the same tasks using an LLM. Results across\nall studies show a striking convergence between human and AI responses, with\nstatistical analyses (e.g., Spearman's rho = .73-.96) indicating strong\ncorrelations in both rating patterns and categorical choices. While minor\ndivergences were observed in some cases, these did not alter the overall\ninterpretative outcomes. These findings offer compelling evidence that LLMs can\naugment traditional human-based experimentation, enabling broader-scale studies\nwithout compromising interpretative validity. This convergence not only\nstrengthens the empirical foundation of prior human-based findings but also\nopens possibilities for hypothesis generation and data expansion through AI.\nUltimately, our study supports the use of LLMs as credible and informative\ncollaborators in linguistic inquiry.", "published": "2025-07-14 14:47:01", "link": "http://arxiv.org/abs/2507.10342v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging Robustness and Generalization Against Word Substitution Attacks in NLP via the Growth Bound Matrix Approach", "abstract": "Despite advancements in Natural Language Processing (NLP), models remain\nvulnerable to adversarial attacks, such as synonym substitutions. While prior\nwork has focused on improving robustness for feed-forward and convolutional\narchitectures, the robustness of recurrent networks and modern state space\nmodels (SSMs), such as S4, remains understudied. These architectures pose\nunique challenges due to their sequential processing and complex parameter\ndynamics. In this paper, we introduce a novel regularization technique based on\nGrowth Bound Matrices (GBM) to improve NLP model robustness by reducing the\nimpact of input perturbations on model outputs. We focus on computing the GBM\nfor three architectures: Long Short-Term Memory (LSTM), State Space models\n(S4), and Convolutional Neural Networks (CNN). Our method aims to (1) enhance\nresilience against word substitution attacks, (2) improve generalization on\nclean text, and (3) providing the first systematic analysis of SSM (S4)\nrobustness. Extensive experiments across multiple architectures and benchmark\ndatasets demonstrate that our method improves adversarial robustness by up to\n8.8% over existing baselines. These results highlight the effectiveness of our\napproach, outperforming several state-of-the-art methods in adversarial\ndefense. Codes are available at https://github.com/BouriMohammed/GBM", "published": "2025-07-14 14:38:48", "link": "http://arxiv.org/abs/2507.10330v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Grammar-Guided Evolutionary Search for Discrete Prompt Optimisation", "abstract": "Prompt engineering has proven to be a crucial step in leveraging pretrained\nlarge language models (LLMs) in solving various real-world tasks. Numerous\nsolutions have been proposed that seek to automate prompt engineering by using\nthe model itself to edit prompts. However, the majority of state-of-the-art\napproaches are evaluated on tasks that require minimal prompt templates and on\nvery large and highly capable LLMs. In contrast, solving complex tasks that\nrequire detailed information to be included in the prompt increases the amount\nof text that needs to be optimised. Furthermore, smaller models have been shown\nto be more sensitive to prompt design. To address these challenges, we propose\nan evolutionary search approach to automated discrete prompt optimisation\nconsisting of two phases. In the first phase, grammar-guided genetic\nprogramming is invoked to synthesise prompt-creating programmes by searching\nthe space of programmes populated by function compositions of syntactic,\ndictionary-based and LLM-based prompt-editing functions. In the second phase,\nlocal search is applied to explore the neighbourhoods of best-performing\nprogrammes in an attempt to further fine-tune their performance. Our approach\noutperforms three state-of-the-art prompt optimisation approaches,\nPromptWizard, OPRO, and RL-Prompt, on three relatively small general-purpose\nLLMs in four domain-specific challenging tasks. We also illustrate several\nexamples where these benchmark methods suffer relatively severe performance\ndegradation, while our approach improves performance in almost all task-model\ncombinations, only incurring minimal degradation when it does not.", "published": "2025-07-14 14:34:15", "link": "http://arxiv.org/abs/2507.10326v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FaceLLM: A Multimodal Large Language Model for Face Understanding", "abstract": "Multimodal large language models (MLLMs) have shown remarkable performance in\nvision-language tasks. However, existing MLLMs are primarily trained on generic\ndatasets, limiting their ability to reason on domain-specific visual cues such\nas those in facial images. In particular, tasks that require detailed\nunderstanding of facial structure, expression, emotion, and demographic\nfeatures remain underexplored by MLLMs due to the lack of large-scale annotated\nface image-text datasets. In this work, we introduce FaceLLM, a multimodal\nlarge language model trained specifically for facial image understanding. To\nconstruct the training data, we propose a novel weakly supervised pipeline that\nuses ChatGPT with attribute-aware prompts to generate high-quality\nquestion-answer pairs based on images from the FairFace dataset. The resulting\ncorpus, called FairFaceGPT, covers a diverse set of attributes including\nexpression, pose, skin texture, and forensic information. Our experiments\ndemonstrate that FaceLLM improves the performance of MLLMs on various\nface-centric tasks and achieves state-of-the-art performance. This work\nhighlights the potential of synthetic supervision via language models for\nbuilding domain-specialized MLLMs, and sets a precedent for trustworthy,\nhuman-centric multimodal AI systems. FairFaceGPT dataset and pretrained FaceLLM\nmodels are publicly available in the project page.", "published": "2025-07-14 14:04:14", "link": "http://arxiv.org/abs/2507.10300v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Absher: A Benchmark for Evaluating Large Language Models Understanding of Saudi Dialects", "abstract": "As large language models (LLMs) become increasingly central to Arabic NLP\napplications, evaluating their understanding of regional dialects and cultural\nnuances is essential, particularly in linguistically diverse settings like\nSaudi Arabia. This paper introduces \\texttt{Absher}, a comprehensive benchmark\nspecifically designed to assess LLMs performance across major Saudi dialects.\n\\texttt{Absher} comprises over 18,000 multiple-choice questions spanning six\ndistinct categories: Meaning, True/False, Fill-in-the-Blank, Contextual Usage,\nCultural Interpretation, and Location Recognition. These questions are derived\nfrom a curated dataset of dialectal words, phrases, and proverbs sourced from\nvarious regions of Saudi Arabia. We evaluate several state-of-the-art LLMs,\nincluding multilingual and Arabic-specific models. We also provide detailed\ninsights into their capabilities and limitations. Our results reveal notable\nperformance gaps, particularly in tasks requiring cultural inference or\ncontextual understanding. Our findings highlight the urgent need for\ndialect-aware training and culturally aligned evaluation methodologies to\nimprove LLMs performance in real-world Arabic applications.", "published": "2025-07-14 12:33:07", "link": "http://arxiv.org/abs/2507.10216v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Natural Language-based Assessment of L2 Oral Proficiency using LLMs", "abstract": "Natural language-based assessment (NLA) is an approach to second language\nassessment that uses instructions - expressed in the form of can-do descriptors\n- originally intended for human examiners, aiming to determine whether large\nlanguage models (LLMs) can interpret and apply them in ways comparable to human\nassessment. In this work, we explore the use of such descriptors with an\nopen-source LLM, Qwen 2.5 72B, to assess responses from the publicly available\nS&I Corpus in a zero-shot setting. Our results show that this approach -\nrelying solely on textual information - achieves competitive performance: while\nit does not outperform state-of-the-art speech LLMs fine-tuned for the task, it\nsurpasses a BERT-based model trained specifically for this purpose. NLA proves\nparticularly effective in mismatched task settings, is generalisable to other\ndata types and languages, and offers greater interpretability, as it is\ngrounded in clearly explainable, widely applicable language descriptors.", "published": "2025-07-14 12:13:50", "link": "http://arxiv.org/abs/2507.10200v1", "categories": ["eess.AS", "cs.AI", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Abusive text transformation using LLMs", "abstract": "Although Large Language Models (LLMs) have demonstrated significant\nadvancements in natural language processing tasks, their effectiveness in the\nclassification and transformation of abusive text into non-abusive versions\nremains an area for exploration. In this study, we aim to use LLMs to transform\nabusive text (tweets and reviews) featuring hate speech and swear words into\nnon-abusive text, while retaining the intent of the text. We evaluate the\nperformance of two state-of-the-art LLMs, such as Gemini, GPT-4o, DeekSeek and\nGroq, on their ability to identify abusive text. We them to transform and\nobtain a text that is clean from abusive and inappropriate content but\nmaintains a similar level of sentiment and semantics, i.e. the transformed text\nneeds to maintain its message. Afterwards, we evaluate the raw and transformed\ndatasets with sentiment analysis and semantic analysis. Our results show Groq\nprovides vastly different results when compared with other LLMs. We have\nidentified similarities between GPT-4o and DeepSeek-V3.", "published": "2025-07-14 11:39:34", "link": "http://arxiv.org/abs/2507.10177v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Task-Based Flexible Feature Distillation for LLMs", "abstract": "Knowledge Distillation (KD) in general and feature distillation in particular\nare promising techniques for reducing the high computational demand of large\nlanguage models (LLMs). However, traditional feature KD methods typically\nassume that the teacher and the student share the same hidden size, limiting\nthe flexibility of the student's architecture. A common solution to this\nproblem involves training a linear projector to align their feature spaces, but\nthis introduces additional parameters that must be learned from scratch and\noften degrades performance on downstream tasks, especially in generative\nsettings. To address this issue, in this work, we propose a novel task-based\nfeature distillation method that enables knowledge transfer between teacher and\nstudent models with different hidden layer dimensions, without introducing any\nnew parameters. Leveraging the insight that only a subset of LLM components\ncontribute significantly to a specific downstream task, our approach identifies\nthe most task-relevant hidden units in the teacher and directly distills their\nactivations to the student. Our method is flexible and easily integrates with\nother distillation frameworks. Empirical results show consistent improvements\nover prior approaches across diverse tasks, including classification,\ninstruction-following, and summarization, achieving up to a 3\\% performance\ngain over the linear projection baseline.", "published": "2025-07-14 11:10:02", "link": "http://arxiv.org/abs/2507.10155v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fusing Large Language Models with Temporal Transformers for Time Series Forecasting", "abstract": "Recently, large language models (LLMs) have demonstrated powerful\ncapabilities in performing various tasks and thus are applied by recent studies\nto time series forecasting (TSF) tasks, which predict future values with the\ngiven historical time series. Existing LLM-based approaches transfer knowledge\nlearned from text data to time series prediction using prompting or fine-tuning\nstrategies. However, LLMs are proficient at reasoning over discrete tokens and\nsemantic patterns but are not initially designed to model continuous numerical\ntime series data. The gaps between text and time series data lead LLMs to\nachieve inferior performance to a vanilla Transformer model that is directly\ntrained on TSF data. However, the vanilla Transformers often struggle to learn\nhigh-level semantic patterns. In this paper, we design a novel\nTransformer-based architecture that complementarily leverages LLMs and vanilla\nTransformers, so as to integrate the high-level semantic representations\nlearned by LLMs into the temporal information encoded by time series\nTransformers, where a hybrid representation is obtained by fusing the\nrepresentations from the LLM and the Transformer. The resulting fused\nrepresentation contains both historical temporal dynamics and semantic\nvariation patterns, allowing our model to predict more accurate future values.\nExperiments on benchmark datasets demonstrate the effectiveness of the proposed\napproach.", "published": "2025-07-14 09:33:40", "link": "http://arxiv.org/abs/2507.10098v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning", "abstract": "Representation Fine-tuning (ReFT), a recently proposed Parameter-Efficient\nFine-Tuning (PEFT) method, has attracted widespread attention for significantly\nimproving parameter efficiency by editing representation space alone. In this\nwork, we investigate applying ReFT to complex reasoning tasks. However,\ndirectly using the native ReFT method, which modifies fixed representations at\nthe beginning and end of each layer, yields suboptimal performance, as these\nfixed-position representations have uncertain impact on the outputs. We observe\nthat, in complex reasoning tasks, there often exist certain critical\nrepresentations. These representations either integrate significant information\nfrom preceding layers or regulate subsequent layer representations. Through\nlayer-by-layer propagation, they exert a substantial influence on the final\noutput. Naturally, fine-tuning these critical representations has the potential\nto greatly enhance reasoning performance. Building upon these insights, we\npropose Critical Representation Fine-Tuning (CRFT), a novel method that\nidentifies and optimizes these critical representations through information\nflow analysis. CRFT operates within a supervised learning framework,\ndynamically optimizing critical representations in a low-rank linear subspace\nwhile freezing the base model. The effectiveness and efficiency of our method\nare validated across eight benchmarks for arithmetic and commonsense reasoning,\nusing LLaMA and Mistral model families. Furthermore, our method also adapts\neffectively to few-shot settings, boosting one-shot accuracy by 16.4%. Our work\nhighlights the untapped potential of representation-level optimization for CoT\nreasoning, offering a lightweight yet powerful alternative to traditional PEFT\nmethods.", "published": "2025-07-14 09:11:33", "link": "http://arxiv.org/abs/2507.10085v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cultural Bias in Large Language Models: Evaluating AI Agents through Moral Questionnaires", "abstract": "Are AI systems truly representing human values, or merely averaging across\nthem? Our study suggests a concerning reality: Large Language Models (LLMs)\nfail to represent diverse cultural moral frameworks despite their linguistic\ncapabilities. We expose significant gaps between AI-generated and human moral\nintuitions by applying the Moral Foundations Questionnaire across 19 cultural\ncontexts. Comparing multiple state-of-the-art LLMs' origins against human\nbaseline data, we find these models systematically homogenize moral diversity.\nSurprisingly, increased model size doesn't consistently improve cultural\nrepresentation fidelity. Our findings challenge the growing use of LLMs as\nsynthetic populations in social science research and highlight a fundamental\nlimitation in current AI alignment approaches. Without data-driven alignment\nbeyond prompting, these systems cannot capture the nuanced, culturally-specific\nmoral intuitions. Our results call for more grounded alignment objectives and\nevaluation metrics to ensure AI systems represent diverse human values rather\nthan flattening the moral landscape.", "published": "2025-07-14 08:59:26", "link": "http://arxiv.org/abs/2507.10073v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GeLaCo: An Evolutionary Approach to Layer Compression", "abstract": "Large Language Models (LLM) have achieved remarkable performance across a\nlarge number of tasks, but face critical deployment and usage barriers due to\nsubstantial computational requirements. Model compression methods, which aim to\nreduce model size while preserving its capacity, are an important means to\nmitigate these issues. Promising approaches along these lines, such as\nstructured pruning, typically require costly empirical search for optimal\nvariants and may run the risk of ignoring better solutions. In this work we\nintroduce GeLaCo, an evolutionary approach to LLM compression via layer\ncollapse. Our approach supports an efficient exploration of the compression\nsolution space via population-based search and a module-wise similarity fitness\nfunction capturing attention, feed-forward, and hidden state representations.\nGeLaCo also supports both single and multi-objective evolutionary compression\nsearch, establishing the first Pareto frontier along compression and quality\naxes. We evaluate GeLaCo solutions via both perplexity-based and generative\nevaluations over foundational and instruction-tuned models, outperforming\nstate-of-the-art alternatives.", "published": "2025-07-14 08:44:59", "link": "http://arxiv.org/abs/2507.10059v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PRISM: Fine-Grained Paper-to-Paper Retrieval with Multi-Aspect-Aware Query Optimization", "abstract": "Scientific paper retrieval, particularly framed as document-to-document\nretrieval, aims to identify relevant papers in response to a long-form query\npaper, rather than a short query string. Previous approaches to this task have\nfocused on abstracts, embedding them into dense vectors as surrogates for full\ndocuments and calculating similarity across them, although abstracts provide\nonly sparse and high-level summaries. To address this, we propose PRISM, a\nnovel document-to-document retrieval method that introduces multiple,\nfine-grained representations for both the query and candidate papers. In\nparticular, each query paper is decomposed into multiple aspect-specific views\nand individually embedded, which are then matched against candidate papers\nsimilarity segmented to consider their multifaceted dimensions. Moreover, we\npresent SciFullBench, a novel benchmark in which the complete and segmented\ncontext of full papers for both queries and candidates is available. Then,\nexperimental results show that PRISM improves performance by an average of 4.3%\nover existing retrieval baselines.", "published": "2025-07-14 08:41:53", "link": "http://arxiv.org/abs/2507.10057v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Automating SPARQL Query Translations between DBpedia and Wikidata", "abstract": "This paper investigates whether state-of-the-art Large Language Models (LLMs)\ncan automatically translate SPARQL between popular Knowledge Graph (KG)\nschemas. We focus on translations between the DBpedia and Wikidata KG, and\nlater on DBLP and OpenAlex KG. This study addresses a notable gap in KG\ninteroperability research by rigorously evaluating LLM performance on\nSPARQL-to-SPARQL translation. Two benchmarks are assembled, where the first\nalign 100 DBpedia-Wikidata queries from QALD-9-Plus; the second contains 100\nDBLP queries aligned to OpenAlex, testing generalizability beyond encyclopaedic\nKGs. Three open LLMs: Llama-3-8B, DeepSeek-R1-Distill-Llama-70B, and\nMistral-Large-Instruct-2407 are selected based on their sizes and architectures\nand tested with zero-shot, few-shot, and two chain-of-thought variants. Outputs\nwere compared with gold answers, and resulting errors were categorized. We find\nthat the performance varies markedly across models and prompting strategies,\nand that translations for Wikidata to DBpedia work far better than translations\nfor DBpedia to Wikidata.", "published": "2025-07-14 08:23:25", "link": "http://arxiv.org/abs/2507.10045v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Cross-modal Associations in Vision and Language Models: Revisiting the bouba-kiki effect", "abstract": "Recent advances in multimodal models have raised questions about whether\nvision-and-language models (VLMs) integrate cross-modal information in ways\nthat reflect human cognition. One well-studied test case in this domain is the\nbouba-kiki effect, where humans reliably associate pseudowords like \"bouba\"\nwith round shapes and \"kiki\" with jagged ones. Given the mixed evidence found\nin prior studies for this effect in VLMs, we present a comprehensive\nre-evaluation focused on two variants of CLIP, ResNet and Vision Transformer\n(ViT), given their centrality in many state-of-the-art VLMs. We apply two\ncomplementary methods closely modelled after human experiments: a prompt-based\nevaluation that uses probabilities as model preference, and we use Grad-CAM as\na novel way to interpret visual attention in shape-word matching tasks. Our\nfindings show that these models do not consistently exhibit the bouba-kiki\neffect. While ResNet shows a preference for round shapes, overall performance\nacross both models lacks the expected associations. Moreover, direct comparison\nwith prior human data on the same task shows that the models' responses fall\nmarkedly short of the robust, modality-integrated behaviour characteristic of\nhuman cognition. These results contribute to the ongoing debate about the\nextent to which VLMs truly understand cross-modal concepts, highlighting\nlimitations in their internal representations and alignment with human\nintuitions.", "published": "2025-07-14 07:48:54", "link": "http://arxiv.org/abs/2507.10013v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Protective Factor-Aware Dynamic Influence Learning for Suicide Risk Prediction on Social Media", "abstract": "Suicide is a critical global health issue that requires urgent attention.\nEven though prior work has revealed valuable insights into detecting current\nsuicide risk on social media, little attention has been paid to developing\nmodels that can predict subsequent suicide risk over time, limiting their\nability to capture rapid fluctuations in individuals' mental state transitions.\nIn addition, existing work ignores protective factors that play a crucial role\nin suicide risk prediction, focusing predominantly on risk factors alone.\nProtective factors such as social support and coping strategies can mitigate\nsuicide risk by moderating the impact of risk factors. Therefore, this study\nproposes a novel framework for predicting subsequent suicide risk by jointly\nlearning the dynamic influence of both risk factors and protective factors on\nusers' suicide risk transitions. We propose a novel Protective Factor-Aware\nDataset, which is built from 12 years of Reddit posts along with comprehensive\nannotations of suicide risk and both risk and protective factors. We also\nintroduce a Dynamic Factors Influence Learning approach that captures the\nvarying impact of risk and protective factors on suicide risk transitions,\nrecognizing that suicide risk fluctuates over time according to established\npsychological theories. Our thorough experiments demonstrate that the proposed\nmodel significantly outperforms state-of-the-art models and large language\nmodels across three datasets. In addition, the proposed Dynamic Factors\nInfluence Learning provides interpretable weights, helping clinicians better\nunderstand suicidal patterns and enabling more targeted intervention\nstrategies.", "published": "2025-07-14 07:41:54", "link": "http://arxiv.org/abs/2507.10008v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On The Role of Intentionality in Knowledge Representation: Analyzing Scene Context for Cognitive Agents with a Tiny Language Model", "abstract": "Since Searle's work deconstructing intent and intentionality in the realm of\nphilosophy, the practical meaning of intent has received little attention in\nscience and technology. Intentionality and context are both central to the\nscope of Promise Theory's model of Semantic Spacetime, used as an effective\nTiny Language Model. One can identify themes and concepts from a text, on a low\nlevel (without knowledge of the specific language) by using process coherence\nas a guide. Any agent process can assess superficially a degree of latent\n`intentionality' in data by looking for anomalous multi-scale anomalies and\nassessing the work done to form them. Scale separation can be used to sort\nparts into `intended' content and `ambient context', using the spacetime\ncoherence as a measure. This offers an elementary but pragmatic interpretation\nof latent intentionality for very low computational cost, and without reference\nto extensive training or reasoning capabilities. The process is well within the\nreach of basic organisms as it does not require large scale artificial\nprobabilistic batch processing. The level of concept formation depends,\nhowever, on the memory capacity of the agent.", "published": "2025-07-14 07:34:58", "link": "http://arxiv.org/abs/2507.10000v1", "categories": ["cs.AI", "cs.CL", "I.2.11; F.4.1; I.2.4; G.2.2"], "primary_category": "cs.AI"}
{"title": "TextOmics-Guided Diffusion for Hit-like Molecular Generation", "abstract": "Hit-like molecular generation with therapeutic potential is essential for\ntarget-specific drug discovery. However, the field lacks heterogeneous data and\nunified frameworks for integrating diverse molecular representations. To bridge\nthis gap, we introduce TextOmics, a pioneering benchmark that establishes\none-to-one correspondences between omics expressions and molecular textual\ndescriptions. TextOmics provides a heterogeneous dataset that facilitates\nmolecular generation through representations alignment. Built upon this\nfoundation, we propose ToDi, a generative framework that jointly conditions on\nomics expressions and molecular textual descriptions to produce biologically\nrelevant, chemically valid, hit-like molecules. ToDi leverages two encoders\n(OmicsEn and TextEn) to capture multi-level biological and semantic\nassociations, and develops conditional diffusion (DiffGen) for controllable\ngeneration. Extensive experiments confirm the effectiveness of TextOmics and\ndemonstrate ToDi outperforms existing state-of-the-art approaches, while also\nshowcasing remarkable potential in zero-shot therapeutic molecular generation.\nSources are available at: https://github.com/hala-ToDi.", "published": "2025-07-14 06:56:37", "link": "http://arxiv.org/abs/2507.09982v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tiny Reward Models", "abstract": "Large decoder-based language models have become the dominant architecture for\nreward modeling in reinforcement learning from human feedback (RLHF). However,\nas reward models are increasingly deployed in test-time strategies, their\ninference costs become a growing concern. We present TinyRM, a family of small,\nbidirectional masked language models (MLMs) with as few as 400 million\nparameters, that rival the capabilities of models over 175 times larger on\nreasoning and safety preference modeling tasks. TinyRM combines FLAN-style\nprompting, Directional Low-Rank Adaptation (DoRA), and layer freezing to\nachieve strong performance on RewardBench, despite using significantly fewer\nresources. Our experiments suggest that small models benefit from\ndomain-specific tuning strategies, particularly in reasoning, where lightweight\nfinetuning methods are especially effective. While challenges remain in\nbuilding generalist models and conversational preference modeling, our\npreliminary results highlight the promise of lightweight bidirectional\narchitectures as efficient, scalable alternatives for preference modeling.", "published": "2025-07-14 06:43:00", "link": "http://arxiv.org/abs/2507.09973v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Retrieval Augmented Generation with Hierarchical Text Segmentation Chunking", "abstract": "Retrieval-Augmented Generation (RAG) systems commonly use chunking strategies\nfor retrieval, which enhance large language models (LLMs) by enabling them to\naccess external knowledge, ensuring that the retrieved information is\nup-to-date and domain-specific. However, traditional methods often fail to\ncreate chunks that capture sufficient semantic meaning, as they do not account\nfor the underlying textual structure. This paper proposes a novel framework\nthat enhances RAG by integrating hierarchical text segmentation and clustering\nto generate more meaningful and semantically coherent chunks. During inference,\nthe framework retrieves information by leveraging both segment-level and\ncluster-level vector representations, thereby increasing the likelihood of\nretrieving more precise and contextually relevant information. Evaluations on\nthe NarrativeQA, QuALITY, and QASPER datasets indicate that the proposed method\nachieved improved results compared to traditional chunking techniques.", "published": "2025-07-14 05:21:58", "link": "http://arxiv.org/abs/2507.09935v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MixLoRA-DSI: Dynamically Expandable Mixture-of-LoRA Experts for Rehearsal-Free Generative Retrieval over Dynamic Corpora", "abstract": "Continually updating model-based indexes in generative retrieval with new\ndocuments remains challenging, as full retraining is computationally expensive\nand impractical under resource constraints. We propose MixLoRA-DSI, a novel\nframework that combines an expandable mixture of Low-Rank Adaptation experts\nwith a layer-wise out-of-distribution (OOD)-driven expansion strategy. Instead\nof allocating new experts for each new corpus, our proposed expansion strategy\nenables sublinear parameter growth by selectively introducing new experts only\nwhen significant number of OOD documents are detected. Experiments on NQ320k\nand MS MARCO Passage demonstrate that MixLoRA-DSI outperforms full-model update\nbaselines, with minimal parameter overhead and substantially lower training\ncosts.", "published": "2025-07-14 05:04:32", "link": "http://arxiv.org/abs/2507.09924v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "ViTCoT: Video-Text Interleaved Chain-of-Thought for Boosting Video Understanding in Large Language Models", "abstract": "Video understanding plays a vital role in bridging low-level visual signals\nwith high-level cognitive reasoning, and is fundamental to applications such as\nautonomous driving, embodied AI, and the broader pursuit of AGI. The rapid\ndevelopment of large language models (LLMs), particularly those utilizing\nChain-of-Thought (CoT) technology, has significantly advanced video reasoning\ncapabilities. However, current approaches primarily depend on textual\ninformation for reasoning, overlooking the visual modality in the actual video\nreasoning process. In contrast, humans naturally re-examine visual content\nwhile reasoning. Motivated by this, we introduce a novel video reasoning\nparadigm: Video-Text Interleaved CoT (ViTCoT), which facilitates more intuitive\nand cognitively aligned reasoning. To the end, first, we construct the\nVideo-Text Interleaved Benchmark (ViTIB), which is created using MLLMs for\nkey-video selection and manually verified. Furthermore, we extensively explore\nthe potential of the ViTCoT paradigm in the video understanding field.\nExtensive experiments demonstrate that ViTCoT significantly enhances\nperformance compared to the traditional text-only CoT paradigm and effectively\nactivates more neuron values in MLLMs.", "published": "2025-07-14 03:21:13", "link": "http://arxiv.org/abs/2507.09876v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Function Induction and Task Generalization: An Interpretability Study with Off-by-One Addition", "abstract": "Large language models demonstrate the intriguing ability to perform unseen\ntasks via in-context learning. However, it remains unclear what mechanisms\ninside the model drive such task-level generalization. In this work, we\napproach this question through the lens of off-by-one addition (i.e., 1+1=3,\n2+2=5, 3+3=?), a two-step, counterfactual task with an unexpected +1 function\nas a second step. Leveraging circuit-style interpretability techniques such as\npath patching, we analyze the models' internal computations behind their\nnotable performance and present three key findings. First, we uncover a\nfunction induction mechanism that explains the model's generalization from\nstandard addition to off-by-one addition. This mechanism resembles the\nstructure of the induction head mechanism found in prior work and elevates it\nto a higher level of abstraction. Second, we show that the induction of the +1\nfunction is governed by multiple attention heads in parallel, each of which\nemits a distinct piece of the +1 function. Finally, we find that this function\ninduction mechanism is reused in a broader range of tasks, including synthetic\ntasks such as shifted multiple-choice QA and algorithmic tasks such as base-8\naddition. Overall, our findings offer deeper insights into how reusable and\ncomposable structures within language models enable task-level generalization.", "published": "2025-07-14 03:20:55", "link": "http://arxiv.org/abs/2507.09875v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Self-supervised Learning on Camera Trap Footage Yields a Strong Universal Face Embedder", "abstract": "Camera traps are revolutionising wildlife monitoring by capturing vast\namounts of visual data; however, the manual identification of individual\nanimals remains a significant bottleneck. This study introduces a fully\nself-supervised approach to learning robust chimpanzee face embeddings from\nunlabeled camera-trap footage. Leveraging the DINOv2 framework, we train Vision\nTransformers on automatically mined face crops, eliminating the need for\nidentity labels. Our method demonstrates strong open-set re-identification\nperformance, surpassing supervised baselines on challenging benchmarks such as\nBossou, despite utilising no labelled data during training. This work\nunderscores the potential of self-supervised learning in biodiversity\nmonitoring and paves the way for scalable, non-invasive population studies.", "published": "2025-07-14 17:59:59", "link": "http://arxiv.org/abs/2507.10552v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Disentangling Neural Disjunctive Normal Form Models", "abstract": "Neural Disjunctive Normal Form (DNF) based models are powerful and\ninterpretable approaches to neuro-symbolic learning and have shown promising\nresults in classification and reinforcement learning settings without prior\nknowledge of the tasks. However, their performance is degraded by the\nthresholding of the post-training symbolic translation process. We show here\nthat part of the performance degradation during translation is due to its\nfailure to disentangle the learned knowledge represented in the form of the\nnetworks' weights. We address this issue by proposing a new disentanglement\nmethod; by splitting nodes that encode nested rules into smaller independent\nnodes, we are able to better preserve the models' performance. Through\nexperiments on binary, multiclass, and multilabel classification tasks\n(including those requiring predicate invention), we demonstrate that our\ndisentanglement method provides compact and interpretable logical\nrepresentations for the neural DNF-based models, with performance closer to\nthat of their pre-translation counterparts. Our code is available at\nhttps://github.com/kittykg/disentangling-ndnf-classification.", "published": "2025-07-14 17:59:33", "link": "http://arxiv.org/abs/2507.10546v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ScaffoldAvatar: High-Fidelity Gaussian Avatars with Patch Expressions", "abstract": "Generating high-fidelity real-time animated sequences of photorealistic 3D\nhead avatars is important for many graphics applications, including immersive\ntelepresence and movies. This is a challenging problem particularly when\nrendering digital avatar close-ups for showing character's facial microfeatures\nand expressions. To capture the expressive, detailed nature of human heads,\nincluding skin furrowing and finer-scale facial movements, we propose to couple\nlocally-defined facial expressions with 3D Gaussian splatting to enable\ncreating ultra-high fidelity, expressive and photorealistic 3D head avatars. In\ncontrast to previous works that operate on a global expression space, we\ncondition our avatar's dynamics on patch-based local expression features and\nsynthesize 3D Gaussians at a patch level. In particular, we leverage a\npatch-based geometric 3D face model to extract patch expressions and learn how\nto translate these into local dynamic skin appearance and motion by coupling\nthe patches with anchor points of Scaffold-GS, a recent hierarchical scene\nrepresentation. These anchors are then used to synthesize 3D Gaussians\non-the-fly, conditioned by patch-expressions and viewing direction. We employ\ncolor-based densification and progressive training to obtain high-quality\nresults and faster convergence for high resolution 3K training images. By\nleveraging patch-level expressions, ScaffoldAvatar consistently achieves\nstate-of-the-art performance with visually natural motion, while encompassing\ndiverse facial expressions and styles in real time.", "published": "2025-07-14 17:59:03", "link": "http://arxiv.org/abs/2507.10542v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "WildFX: A DAW-Powered Pipeline for In-the-Wild Audio FX Graph Modeling", "abstract": "Despite rapid progress in end-to-end AI music generation, AI-driven modeling\nof professional Digital Signal Processing (DSP) workflows remains challenging.\nIn particular, while there is growing interest in neural black-box modeling of\naudio effect graphs (e.g. reverb, compression, equalization), AI-based\napproaches struggle to replicate the nuanced signal flow and parameter\ninteractions used in professional workflows. Existing differentiable plugin\napproaches often diverge from real-world tools, exhibiting inferior performance\nrelative to simplified neural controllers under equivalent computational\nconstraints. We introduce WildFX, a pipeline containerized with Docker for\ngenerating multi-track audio mixing datasets with rich effect graphs, powered\nby a professional Digital Audio Workstation (DAW) backend. WildFX supports\nseamless integration of cross-platform commercial plugins or any plugins in the\nwild, in VST/VST3/LV2/CLAP formats, enabling structural complexity (e.g.,\nsidechains, crossovers) and achieving efficient parallelized processing. A\nminimalist metadata interface simplifies project/plugin configuration.\nExperiments demonstrate the pipeline's validity through blind estimation of\nmixing graphs, plugin/gain parameters, and its ability to bridge AI research\nwith practical DSP demands. The code is available on:\nhttps://github.com/IsaacYQH/WildFX.", "published": "2025-07-14 17:55:38", "link": "http://arxiv.org/abs/2507.10534v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "Accurate generation of chemical reaction transition states by conditional flow matching", "abstract": "Transition state (TS) structures define the critical geometries and energy\nbarriers underlying chemical reactivity, yet their fleeting nature renders them\nexperimentally elusive and drives the reliance on costly, high-throughput\ndensity functional theory (DFT) calculations. Here, we introduce TS-GEN, a\nconditional flow-matching generative model that maps samples from a simple\nGaussian prior directly to transition-state saddle-point geometries in a\nsingle, deterministic pass. By embedding both reactant and product\nconformations as conditioning information, TS-GEN learns to transport latent\nnoise to true TS structures via an optimal-transport path, effectively\nreplacing the iterative optimization common in nudged-elastic band or\nstring-method algorithms. TS-GEN delivers unprecedented accuracy, achieving a\nroot-mean-square deviation of $0.004\\ \\rm{\\mathring{A}}$ (vs. $0.103\\\n\\rm{\\mathring{A}}$ for prior state-of-the-art) and a mean barrier-height error\nof $1.019\\ {\\rm kcal/mol}$ (vs. $2.864\\ {\\rm kcal/mol}$), while requiring only\n$0.06\\ {\\rm s}$ GPU time per inference. Over 87% of generated TSs meet\nchemical-accuracy criteria ($<1.58\\ {\\rm kcal/mol}$ error), substantially\noutpacing existing methods. TS-GEN also exhibits strong transferability to\nout-of-distribution reactions from a larger database. By uniting sub-angstrom\nprecision, sub-second speed, and broad applicability, TS-GEN will be highly\nuseful for high-throughput exploration of complex reaction networks, paving the\nway to the exploration of novel chemical reaction mechanisms.", "published": "2025-07-14 17:54:47", "link": "http://arxiv.org/abs/2507.10530v1", "categories": ["physics.chem-ph", "cs.AI"], "primary_category": "physics.chem-ph"}
{"title": "Chat with AI: The Surprising Turn of Real-time Video Communication from Human to AI", "abstract": "AI Video Chat emerges as a new paradigm for Real-time Communication (RTC),\nwhere one peer is not a human, but a Multimodal Large Language Model (MLLM).\nThis makes interaction between humans and AI more intuitive, as if chatting\nface-to-face with a real person. However, this poses significant challenges to\nlatency, because the MLLM inference takes up most of the response time, leaving\nvery little time for video streaming. Due to network uncertainty and\ninstability, transmission latency becomes a critical bottleneck preventing AI\nfrom being like a real person. To address this, we propose Artic, an\nAI-oriented Real-time Communication framework, exploring the network\nrequirement shift from \"humans watching video\" to \"AI understanding video\". To\nreduce bitrate dramatically while maintaining MLLM accuracy, we propose\nContext-Aware Video Streaming that recognizes the importance of each video\nregion for chat and allocates bitrate almost exclusively to chat-important\nregions. To avoid packet retransmission, we propose Loss-Resilient Adaptive\nFrame Rate that leverages previous frames to substitute for lost/delayed frames\nwhile avoiding bitrate waste. To evaluate the impact of video streaming quality\non MLLM accuracy, we build the first benchmark, named Degraded Video\nUnderstanding Benchmark (DeViBench). Finally, we discuss some open questions\nand ongoing solutions for AI Video Chat.", "published": "2025-07-14 17:34:49", "link": "http://arxiv.org/abs/2507.10510v1", "categories": ["cs.NI", "cs.AI", "cs.HC", "cs.MM"], "primary_category": "cs.NI"}
{"title": "Benchmarking and Evaluation of AI Models in Biology: Outcomes and Recommendations from the CZI Virtual Cells Workshop", "abstract": "Artificial intelligence holds immense promise for transforming biology, yet a\nlack of standardized, cross domain, benchmarks undermines our ability to build\nrobust, trustworthy models. Here, we present insights from a recent workshop\nthat convened machine learning and computational biology experts across\nimaging, transcriptomics, proteomics, and genomics to tackle this gap. We\nidentify major technical and systemic bottlenecks such as data heterogeneity\nand noise, reproducibility challenges, biases, and the fragmented ecosystem of\npublicly available resources and propose a set of recommendations for building\nbenchmarking frameworks that can efficiently compare ML models of biological\nsystems across tasks and data modalities. By promoting high quality data\ncuration, standardized tooling, comprehensive evaluation metrics, and open,\ncollaborative platforms, we aim to accelerate the development of robust\nbenchmarks for AI driven Virtual Cells. These benchmarks are crucial for\nensuring rigor, reproducibility, and biological relevance, and will ultimately\nadvance the field toward integrated models that drive new discoveries,\ntherapeutic insights, and a deeper understanding of cellular systems.", "published": "2025-07-14 17:25:28", "link": "http://arxiv.org/abs/2507.10502v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Scene-Aware Conversational ADAS with Generative AI for Real-Time Driver Assistance", "abstract": "While autonomous driving technologies continue to advance, current Advanced\nDriver Assistance Systems (ADAS) remain limited in their ability to interpret\nscene context or engage with drivers through natural language. These systems\ntypically rely on predefined logic and lack support for dialogue-based\ninteraction, making them inflexible in dynamic environments or when adapting to\ndriver intent. This paper presents Scene-Aware Conversational ADAS (SC-ADAS), a\nmodular framework that integrates Generative AI components including large\nlanguage models, vision-to-text interpretation, and structured function calling\nto enable real-time, interpretable, and adaptive driver assistance. SC-ADAS\nsupports multi-turn dialogue grounded in visual and sensor context, allowing\nnatural language recommendations and driver-confirmed ADAS control. Implemented\nin the CARLA simulator with cloud-based Generative AI, the system executes\nconfirmed user intents as structured ADAS commands without requiring model\nfine-tuning. We evaluate SC-ADAS across scene-aware, conversational, and\nrevisited multi-turn interactions, highlighting trade-offs such as increased\nlatency from vision-based context retrieval and token growth from accumulated\ndialogue history. These results demonstrate the feasibility of combining\nconversational reasoning, scene perception, and modular ADAS control to support\nthe next generation of intelligent driver assistance.", "published": "2025-07-14 17:24:07", "link": "http://arxiv.org/abs/2507.10500v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.HC"], "primary_category": "cs.RO"}
{"title": "Cameras as Relative Positional Encoding", "abstract": "Transformers are increasingly prevalent for multi-view computer vision tasks,\nwhere geometric relationships between viewpoints are critical for 3D\nperception. To leverage these relationships, multi-view transformers must use\ncamera geometry to ground visual tokens in 3D space. In this work, we compare\ntechniques for conditioning transformers on cameras: token-level raymap\nencodings, attention-level relative pose encodings, and a new relative encoding\nwe propose -- Projective Positional Encoding (PRoPE) -- that captures complete\ncamera frustums, both intrinsics and extrinsics, as a relative positional\nencoding. Our experiments begin by showing how relative camera conditioning\nimproves performance in feedforward novel view synthesis, with further gains\nfrom PRoPE. This holds across settings: scenes with both shared and varying\nintrinsics, when combining token- and attention-level conditioning, and for\ngeneralization to inputs with out-of-distribution sequence lengths and camera\nintrinsics. We then verify that these benefits persist for different tasks,\nstereo depth estimation and discriminative spatial cognition, as well as larger\nmodel sizes.", "published": "2025-07-14 17:22:45", "link": "http://arxiv.org/abs/2507.10496v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "BenchReAD: A systematic benchmark for retinal anomaly detection", "abstract": "Retinal anomaly detection plays a pivotal role in screening ocular and\nsystemic diseases. Despite its significance, progress in the field has been\nhindered by the absence of a comprehensive and publicly available benchmark,\nwhich is essential for the fair evaluation and advancement of methodologies.\nDue to this limitation, previous anomaly detection work related to retinal\nimages has been constrained by (1) a limited and overly simplistic set of\nanomaly types, (2) test sets that are nearly saturated, and (3) a lack of\ngeneralization evaluation, resulting in less convincing experimental setups.\nFurthermore, existing benchmarks in medical anomaly detection predominantly\nfocus on one-class supervised approaches (training only with negative samples),\noverlooking the vast amounts of labeled abnormal data and unlabeled data that\nare commonly available in clinical practice. To bridge these gaps, we introduce\na benchmark for retinal anomaly detection, which is comprehensive and\nsystematic in terms of data and algorithm. Through categorizing and\nbenchmarking previous methods, we find that a fully supervised approach\nleveraging disentangled representations of abnormalities (DRA) achieves the\nbest performance but suffers from significant drops in performance when\nencountering certain unseen anomalies. Inspired by the memory bank mechanisms\nin one-class supervised learning, we propose NFM-DRA, which integrates DRA with\na Normal Feature Memory to mitigate the performance degradation, establishing a\nnew SOTA. The benchmark is publicly available at\nhttps://github.com/DopamineLcy/BenchReAD.", "published": "2025-07-14 17:13:08", "link": "http://arxiv.org/abs/2507.10492v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Privacy-Preserving Multi-Stage Fall Detection Framework with Semi-supervised Federated Learning and Robotic Vision Confirmation", "abstract": "The aging population is growing rapidly, and so is the danger of falls in\nolder adults. A major cause of injury is falling, and detection in time can\ngreatly save medical expenses and recovery time. However, to provide timely\nintervention and avoid unnecessary alarms, detection systems must be effective\nand reliable while addressing privacy concerns regarding the user. In this\nwork, we propose a framework for detecting falls using several complementary\nsystems: a semi-supervised federated learning-based fall detection system\n(SF2D), an indoor localization and navigation system, and a vision-based human\nfall recognition system. A wearable device and an edge device identify a fall\nscenario in the first system. On top of that, the second system uses an indoor\nlocalization technique first to localize the fall location and then navigate a\nrobot to inspect the scenario. A vision-based detection system running on an\nedge device with a mounted camera on a robot is used to recognize fallen\npeople. Each of the systems of this proposed framework achieves different\naccuracy rates. Specifically, the SF2D has a 0.81% failure rate equivalent to\n99.19% accuracy, while the vision-based fallen people detection achieves 96.3%\naccuracy. However, when we combine the accuracy of these two systems with the\naccuracy of the navigation system (95% success rate), our proposed framework\ncreates a highly reliable performance for fall detection, with an overall\naccuracy of 99.99%. Not only is the proposed framework safe for older adults,\nbut it is also a privacy-preserving solution for detecting falls.", "published": "2025-07-14 16:55:11", "link": "http://arxiv.org/abs/2507.10474v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "An Empirical Evaluation of AI-Powered Non-Player Characters' Perceived Realism and Performance in Virtual Reality Environments", "abstract": "Advancements in artificial intelligence (AI) have significantly enhanced the\nrealism and interactivity of non-player characters (NPCs) in virtual reality\n(VR), creating more engaging and believable user experiences. This paper\nevaluates AI-driven NPCs within a VR interrogation simulator, focusing on their\nperceived realism, usability, and system performance. The simulator features\ntwo AI-powered NPCs, a suspect, and a partner, using GPT-4 Turbo to engage\nparticipants in a scenario to determine the suspect's guilt or innocence. A\nuser study with 18 participants assessed the system using the System Usability\nScale (SUS), Game Experience Questionnaire (GEQ), and a Virtual Agent\nBelievability Questionnaire, alongside latency measurements for speech-to-text\n(STT), text-to-speech (TTS), OpenAI GPT-4 Turbo, and overall (cycle) latency.\nResults showed an average cycle latency of 7 seconds, influenced by the\nincreasing conversational context. Believability scored 6.67 out of 10, with\nhigh ratings in behavior, social relationships, and intelligence but moderate\nscores in emotion and personality. The system achieved a SUS score of 79.44,\nindicating good usability. These findings demonstrate the potential of large\nlanguage models to improve NPC realism and interaction in VR while highlighting\nchallenges in reducing system latency and enhancing emotional depth. This\nresearch contributes to the development of more sophisticated AI-driven NPCs,\nrevealing the need for performance optimization to achieve increasingly\nimmersive virtual experiences.", "published": "2025-07-14 16:50:29", "link": "http://arxiv.org/abs/2507.10469v1", "categories": ["cs.HC", "cs.AI", "cs.MM"], "primary_category": "cs.HC"}
{"title": "AudioMAE++: learning better masked audio representations with SwiGLU FFNs", "abstract": "Masked Autoencoders (MAEs) trained on audio spectrogram patches have emerged\nas a prominent approach for learning self-supervised audio representations.\nWhile several recent papers have evaluated key aspects of training MAEs on\naudio data, the majority of these approaches still leverage vanilla transformer\nbuilding blocks, whereas the transformer community has seen steady integration\nof newer architectural advancements. In this work, we propose AudioMAE++, a\nrevamped audio masked autoencoder with two such enhancements, namely\nmacaron-style transformer blocks with gated linear units. When pretrained on\nthe AudioSet dataset, the proposed AudioMAE++ models outperform existing MAE\nbased approaches on 10 diverse downstream tasks, demonstrating excellent\nperformance on audio classification and speech-based benchmarks. The proposed\nAudioMAE++ models also demonstrate excellent scaling characteristics,\noutperforming directly comparable standard MAE baselines with up to 4x more\nparameters.", "published": "2025-07-14 16:41:03", "link": "http://arxiv.org/abs/2507.10464v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "RAPNet: A Receptive-Field Adaptive Convolutional Neural Network for Pansharpening", "abstract": "Pansharpening refers to the process of integrating a high resolution\npanchromatic (PAN) image with a lower resolution multispectral (MS) image to\ngenerate a fused product, which is pivotal in remote sensing. Despite the\neffectiveness of CNNs in addressing this challenge, they are inherently\nconstrained by the uniform application of convolutional kernels across all\nspatial positions, overlooking local content variations. To overcome this\nissue, we introduce RAPNet, a new architecture that leverages content-adaptive\nconvolution. At its core, RAPNet employs the Receptive-field Adaptive\nPansharpening Convolution (RAPConv), designed to produce spatially adaptive\nkernels responsive to local feature context, thereby enhancing the precision of\nspatial detail extraction. Additionally, the network integrates the\nPansharpening Dynamic Feature Fusion (PAN-DFF) module, which incorporates an\nattention mechanism to achieve an optimal balance between spatial detail\nenhancement and spectral fidelity. Comprehensive evaluations on publicly\navailable datasets confirm that RAPNet delivers superior performance compared\nto existing approaches, as demonstrated by both quantitative metrics and\nqualitative assessments. Ablation analyses further substantiate the\neffectiveness of the proposed adaptive components.", "published": "2025-07-14 16:39:14", "link": "http://arxiv.org/abs/2507.10461v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Logic layer Prompt Control Injection (LPCI): A Novel Security Vulnerability Class in Agentic Systems", "abstract": "The integration of large language models (LLMs) into enterprise systems has\ncreated a new class of covert security vulnerabilities, particularly within\nlogic-execution layers and persistent-memory contexts. In this paper, we\nintroduce Logic-Layer Prompt Control Injection (LPCI), a novel attack category\nin which encoded, delayed, and conditionally triggered payloads are embedded in\nmemory, vector stores, or tool outputs. These payloads can bypass conventional\ninput filters and trigger unauthorised behaviour across sessions.", "published": "2025-07-14 16:37:05", "link": "http://arxiv.org/abs/2507.10457v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding", "abstract": "Coral reefs are vital yet vulnerable ecosystems that require continuous\nmonitoring to support conservation. While coral reef images provide essential\ninformation in coral monitoring, interpreting such images remains challenging\ndue to the need for domain expertise. Visual Question Answering (VQA), powered\nby Large Vision-Language Models (LVLMs), has great potential in user-friendly\ninteraction with coral reef images. However, applying VQA to coral imagery\ndemands a dedicated dataset that addresses two key challenges: domain-specific\nannotations and multidimensional questions. In this work, we introduce\nCoralVQA, the first large-scale VQA dataset for coral reef analysis. It\ncontains 12,805 real-world coral images from 67 coral genera collected from 3\noceans, along with 277,653 question-answer pairs that comprehensively assess\necological and health-related conditions. To construct this dataset, we develop\na semi-automatic data construction pipeline in collaboration with marine\nbiologists to ensure both scalability and professional-grade data quality.\nCoralVQA presents novel challenges and provides a comprehensive benchmark for\nstudying vision-language reasoning in the context of coral reef images. By\nevaluating several state-of-the-art LVLMs, we reveal key limitations and\nopportunities. These insights form a foundation for future LVLM development,\nwith a particular emphasis on supporting coral conservation efforts.", "published": "2025-07-14 16:29:10", "link": "http://arxiv.org/abs/2507.10449v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Efficient Federated Learning with Heterogeneous Data and Adaptive Dropout", "abstract": "Federated Learning (FL) is a promising distributed machine learning approach\nthat enables collaborative training of a global model using multiple edge\ndevices. The data distributed among the edge devices is highly heterogeneous.\nThus, FL faces the challenge of data distribution and heterogeneity, where\nnon-Independent and Identically Distributed (non-IID) data across edge devices\nmay yield in significant accuracy drop. Furthermore, the limited computation\nand communication capabilities of edge devices increase the likelihood of\nstragglers, thus leading to slow model convergence. In this paper, we propose\nthe FedDHAD FL framework, which comes with two novel methods: Dynamic\nHeterogeneous model aggregation (FedDH) and Adaptive Dropout (FedAD). FedDH\ndynamically adjusts the weights of each local model within the model\naggregation process based on the non-IID degree of heterogeneous data to deal\nwith the statistical data heterogeneity. FedAD performs neuron-adaptive\noperations in response to heterogeneous devices to improve accuracy while\nachieving superb efficiency. The combination of these two methods makes FedDHAD\nsignificantly outperform state-of-the-art solutions in terms of accuracy (up to\n6.7% higher), efficiency (up to 2.02 times faster), and computation cost (up to\n15.0% smaller).", "published": "2025-07-14 16:19:00", "link": "http://arxiv.org/abs/2507.10430v1", "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "cs.DC"}
{"title": "SentiDrop: A Multi Modal Machine Learning model for Predicting Dropout in Distance Learning", "abstract": "School dropout is a serious problem in distance learning, where early\ndetection is crucial for effective intervention and student perseverance.\nPredicting student dropout using available educational data is a widely\nresearched topic in learning analytics. Our partner's distance learning\nplatform highlights the importance of integrating diverse data sources,\nincluding socio-demographic data, behavioral data, and sentiment analysis, to\naccurately predict dropout risks. In this paper, we introduce a novel model\nthat combines sentiment analysis of student comments using the Bidirectional\nEncoder Representations from Transformers (BERT) model with socio-demographic\nand behavioral data analyzed through Extreme Gradient Boosting (XGBoost). We\nfine-tuned BERT on student comments to capture nuanced sentiments, which were\nthen merged with key features selected using feature importance techniques in\nXGBoost. Our model was tested on unseen data from the next academic year,\nachieving an accuracy of 84\\%, compared to 82\\% for the baseline model.\nAdditionally, the model demonstrated superior performance in other metrics,\nsuch as precision and F1-score. The proposed method could be a vital tool in\ndeveloping personalized strategies to reduce dropout rates and encourage\nstudent perseverance", "published": "2025-07-14 16:04:34", "link": "http://arxiv.org/abs/2507.10421v1", "categories": ["cs.AI", "cs.ET", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Energy Efficiency in AI for 5G and Beyond: A DeepRx Case Study", "abstract": "This study addresses the challenge of balancing energy efficiency with\nperformance in AI/ML models, focusing on DeepRX, a deep learning receiver based\non a fully convolutional ResNet architecture. We evaluate the energy\nconsumption of DeepRX, considering factors including FLOPs/Watt and\nFLOPs/clock, and find consistency between estimated and actual energy usage,\ninfluenced by memory access patterns. The research extends to comparing energy\ndynamics during training and inference phases. A key contribution is the\napplication of knowledge distillation (KD) to train a compact DeepRX\n\\textit{student} model that emulates the performance of the \\textit{teacher}\nmodel but with reduced energy consumption. We experiment with different student\nmodel sizes, optimal teacher sizes, and KD hyperparameters. Performance is\nmeasured by comparing the Bit Error Rate (BER) performance versus\nSignal-to-Interference \\& Noise Ratio (SINR) values of the distilled model and\na model trained from scratch. The distilled models demonstrate a lower error\nfloor across SINR levels, highlighting the effectiveness of KD in achieving\nenergy-efficient AI solutions.", "published": "2025-07-14 15:54:06", "link": "http://arxiv.org/abs/2507.10409v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Instance space analysis of the capacitated vehicle routing problem", "abstract": "This paper seeks to advance CVRP research by addressing the challenge of\nunderstanding the nuanced relationships between instance characteristics and\nmetaheuristic (MH) performance. We present Instance Space Analysis (ISA) as a\nvaluable tool that allows for a new perspective on the field. By combining the\nISA methodology with a dataset from the DIMACS 12th Implementation Challenge on\nVehicle Routing, our research enabled the identification of 23 relevant\ninstance characteristics. Our use of the PRELIM, SIFTED, and PILOT stages,\nwhich employ dimensionality reduction and machine learning methods, allowed us\nto create a two-dimensional projection of the instance space to understand how\nthe structure of instances affect the behavior of MHs. A key contribution of\nour work is that we provide a projection matrix, which makes it straightforward\nto incorporate new instances into this analysis and allows for a new method for\ninstance analysis in the CVRP field.", "published": "2025-07-14 15:37:55", "link": "http://arxiv.org/abs/2507.10397v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "TAT: Temporal-Aligned Transformer for Multi-Horizon Peak Demand Forecasting", "abstract": "Multi-horizon time series forecasting has many practical applications such as\ndemand forecasting. Accurate demand prediction is critical to help make buying\nand inventory decisions for supply chain management of e-commerce and physical\nretailers, and such predictions are typically required for future horizons\nextending tens of weeks. This is especially challenging during high-stake sales\nevents when demand peaks are particularly difficult to predict accurately.\nHowever, these events are important not only for managing supply chain\noperations but also for ensuring a seamless shopping experience for customers.\nTo address this challenge, we propose Temporal-Aligned Transformer (TAT), a\nmulti-horizon forecaster leveraging apriori-known context variables such as\nholiday and promotion events information for improving predictive performance.\nOur model consists of an encoder and decoder, both embedded with a novel\nTemporal Alignment Attention (TAA), designed to learn context-dependent\nalignment for peak demand forecasting. We conduct extensive empirical analysis\non two large-scale proprietary datasets from a large e-commerce retailer. We\ndemonstrate that TAT brings up to 30% accuracy improvement on peak demand\nforecasting while maintaining competitive overall performance compared to other\nstate-of-the-art methods.", "published": "2025-07-14 14:51:24", "link": "http://arxiv.org/abs/2507.10349v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Feature Distillation is the Better Choice for Model-Heterogeneous Federated Learning", "abstract": "Model-Heterogeneous Federated Learning (Hetero-FL) has attracted growing\nattention for its ability to aggregate knowledge from heterogeneous models\nwhile keeping private data locally. To better aggregate knowledge from clients,\nensemble distillation, as a widely used and effective technique, is often\nemployed after global aggregation to enhance the performance of the global\nmodel. However, simply combining Hetero-FL and ensemble distillation does not\nalways yield promising results and can make the training process unstable. The\nreason is that existing methods primarily focus on logit distillation, which,\nwhile being model-agnostic with softmax predictions, fails to compensate for\nthe knowledge bias arising from heterogeneous models. To tackle this challenge,\nwe propose a stable and efficient Feature Distillation for model-heterogeneous\nFederated learning, dubbed FedFD, that can incorporate aligned feature\ninformation via orthogonal projection to integrate knowledge from heterogeneous\nmodels better. Specifically, a new feature-based ensemble federated knowledge\ndistillation paradigm is proposed. The global model on the server needs to\nmaintain a projection layer for each client-side model architecture to align\nthe features separately. Orthogonal techniques are employed to re-parameterize\nthe projection layer to mitigate knowledge bias from heterogeneous models and\nthus maximize the distilled knowledge. Extensive experiments show that FedFD\nachieves superior performance compared to state-of-the-art methods.", "published": "2025-07-14 14:51:18", "link": "http://arxiv.org/abs/2507.10348v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Toolsuite for Implementing Multiagent Systems Based on Communication Protocols", "abstract": "Interaction-Oriented Programming (IOP) is an approach to building a\nmultiagent system by modeling the interactions between its roles via a flexible\ninteraction protocol and implementing agents to realize the interactions of the\nroles they play in the protocol.\n  In recent years, we have developed an extensive suite of software that\nenables multiagent system developers to apply IOP. These include tools for\nefficiently verifying protocols for properties such as liveness and safety and\nmiddleware that simplifies the implementation of agents. This paper presents\nsome of that software suite.", "published": "2025-07-14 14:32:09", "link": "http://arxiv.org/abs/2507.10324v1", "categories": ["cs.MA", "cs.AI", "cs.PL", "cs.SE", "I.2.11; I.2.4; I.2.5"], "primary_category": "cs.MA"}
{"title": "Recognizing Dementia from Neuropsychological Tests with State Space Models", "abstract": "Early detection of dementia is critical for timely medical intervention and\nimproved patient outcomes. Neuropsychological tests are widely used for\ncognitive assessment but have traditionally relied on manual scoring. Automatic\ndementia classification (ADC) systems aim to infer cognitive decline directly\nfrom speech recordings of such tests. We propose Demenba, a novel ADC framework\nbased on state space models, which scale linearly in memory and computation\nwith sequence length. Trained on over 1,000 hours of cognitive assessments\nadministered to Framingham Heart Study participants, some of whom were\ndiagnosed with dementia through adjudicated review, our method outperforms\nprior approaches in fine-grained dementia classification by 21\\%, while using\nfewer parameters. We further analyze its scaling behavior and demonstrate that\nour model gains additional improvement when fused with large language models,\npaving the way for more transparent and scalable dementia assessment tools.\nCode: https://anonymous.4open.science/r/Demenba-0861", "published": "2025-07-14 14:15:47", "link": "http://arxiv.org/abs/2507.10311v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Toward Real-World Table Agents: Capabilities, Workflows, and Design Principles for LLM-based Table Intelligence", "abstract": "Tables are fundamental in domains such as finance, healthcare, and public\nadministration, yet real-world table tasks often involve noise, structural\nheterogeneity, and semantic complexity--issues underexplored in existing\nresearch that primarily targets clean academic datasets. This survey focuses on\nLLM-based Table Agents, which aim to automate table-centric workflows by\nintegrating preprocessing, reasoning, and domain adaptation. We define five\ncore competencies--C1: Table Structure Understanding, C2: Table and Query\nSemantic Understanding, C3: Table Retrieval and Compression, C4: Executable\nReasoning with Traceability, and C5: Cross-Domain Generalization--to analyze\nand compare current approaches. In addition, a detailed examination of the\nText-to-SQL Agent reveals a performance gap between academic benchmarks and\nreal-world scenarios, especially for open-source models. Finally, we provide\nactionable insights to improve the robustness, generalization, and efficiency\nof LLM-based Table Agents in practical settings.", "published": "2025-07-14 13:48:13", "link": "http://arxiv.org/abs/2507.10281v1", "categories": ["cs.AI", "cs.DB"], "primary_category": "cs.AI"}
{"title": "DepViT-CAD: Deployable Vision Transformer-Based Cancer Diagnosis in Histopathology", "abstract": "Accurate and timely cancer diagnosis from histopathological slides is vital\nfor effective clinical decision-making. This paper introduces DepViT-CAD, a\ndeployable AI system for multi-class cancer diagnosis in histopathology. At its\ncore is MAViT, a novel Multi-Attention Vision Transformer designed to capture\nfine-grained morphological patterns across diverse tumor types. MAViT was\ntrained on expert-annotated patches from 1008 whole-slide images, covering 11\ndiagnostic categories, including 10 major cancers and non-tumor tissue.\nDepViT-CAD was validated on two independent cohorts: 275 WSIs from The Cancer\nGenome Atlas and 50 routine clinical cases from pathology labs, achieving\ndiagnostic sensitivities of 94.11% and 92%, respectively. By combining\nstate-of-the-art transformer architecture with large-scale real-world\nvalidation, DepViT-CAD offers a robust and scalable approach for AI-assisted\ncancer diagnostics. To support transparency and reproducibility, software and\ncode will be made publicly available at GitHub.", "published": "2025-07-14 13:17:46", "link": "http://arxiv.org/abs/2507.10250v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Visual Analytics for Explainable and Trustworthy Artificial Intelligence", "abstract": "Our society increasingly depends on intelligent systems to solve complex\nproblems, ranging from recommender systems suggesting the next movie to watch\nto AI models assisting in medical diagnoses for hospitalized patients. With the\niterative improvement of diagnostic accuracy and efficiency, AI holds\nsignificant potential to mitigate medical misdiagnoses by preventing numerous\ndeaths and reducing an economic burden of approximately 450 EUR billion\nannually. However, a key obstacle to AI adoption lies in the lack of\ntransparency: many automated systems function as \"black boxes,\" providing\npredictions without revealing the underlying processes. This opacity can hinder\nexperts' ability to trust and rely on AI systems. Visual analytics (VA)\nprovides a compelling solution by combining AI models with interactive\nvisualizations. These specialized charts and graphs empower users to\nincorporate their domain expertise to refine and improve the models, bridging\nthe gap between AI and human understanding. In this work, we define,\ncategorize, and explore how VA solutions can foster trust across the stages of\na typical AI pipeline. We propose a design space for innovative visualizations\nand present an overview of our previously developed VA dashboards, which\nsupport critical tasks within the various pipeline stages, including data\nprocessing, feature engineering, hyperparameter tuning, understanding,\ndebugging, refining, and comparing models.", "published": "2025-07-14 13:03:17", "link": "http://arxiv.org/abs/2507.10240v1", "categories": ["cs.HC", "cs.AI", "cs.LG"], "primary_category": "cs.HC"}
{"title": "ProGait: A Multi-Purpose Video Dataset and Benchmark for Transfemoral Prosthesis Users", "abstract": "Prosthetic legs play a pivotal role in clinical rehabilitation, allowing\nindividuals with lower-limb amputations the ability to regain mobility and\nimprove their quality of life. Gait analysis is fundamental for optimizing\nprosthesis design and alignment, directly impacting the mobility and life\nquality of individuals with lower-limb amputations. Vision-based machine\nlearning (ML) methods offer a scalable and non-invasive solution to gait\nanalysis, but face challenges in correctly detecting and analyzing prosthesis,\ndue to their unique appearances and new movement patterns. In this paper, we\naim to bridge this gap by introducing a multi-purpose dataset, namely ProGait,\nto support multiple vision tasks including Video Object Segmentation, 2D Human\nPose Estimation, and Gait Analysis (GA). ProGait provides 412 video clips from\nfour above-knee amputees when testing multiple newly-fitted prosthetic legs\nthrough walking trials, and depicts the presence, contours, poses, and gait\npatterns of human subjects with transfemoral prosthetic legs. Alongside the\ndataset itself, we also present benchmark tasks and fine-tuned baseline models\nto illustrate the practical application and performance of the ProGait dataset.\nWe compared our baseline models against pre-trained vision models,\ndemonstrating improved generalizability when applying the ProGait dataset for\nprosthesis-specific tasks. Our code is available at\nhttps://github.com/pittisl/ProGait and dataset at\nhttps://huggingface.co/datasets/ericyxy98/ProGait.", "published": "2025-07-14 12:40:57", "link": "http://arxiv.org/abs/2507.10223v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Survey for Categorising Explainable AI Studies Using Data Analysis Task Frameworks", "abstract": "Research into explainable artificial intelligence (XAI) for data analysis\ntasks suffer from a large number of contradictions and lack of concrete design\nrecommendations stemming from gaps in understanding the tasks that require AI\nassistance. In this paper, we drew on multiple fields such as visual analytics,\ncognition, and dashboard design to propose a method for categorising and\ncomparing XAI studies under three dimensions: what, why, and who. We identified\nthe main problems as: inadequate descriptions of tasks, context-free studies,\nand insufficient testing with target users. We propose that studies should\nspecifically report on their users' domain, AI, and data analysis expertise to\nillustrate the generalisability of their findings. We also propose study\nguidelines for designing and reporting XAI tasks to improve the XAI community's\nability to parse the rapidly growing field. We hope that our contribution can\nhelp researchers and designers better identify which studies are most relevant\nto their work, what gaps exist in the research, and how to handle contradictory\nresults regarding XAI design.", "published": "2025-07-14 12:26:45", "link": "http://arxiv.org/abs/2507.10208v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images", "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in vision-language understanding, reasoning, and generation.\nHowever, they struggle with tasks requiring fine-grained localization and\nreasoning in high-resolution images. This constraint stems from the fact that\nMLLMs are fine-tuned with fixed image resolution to align with the pre-trained\nimage encoder used in MLLM. Consequently, feeding high-resolution images\ndirectly into MLLMs leads to poor generalization due to a train-test resolution\ndiscrepancy, while downsampling these images-although ensuring\nconsistency-compromises fine-grained visual details and ultimately degrades\nperformance. To address this challenge, we propose Extract Candidate then\nPredict (ECP), a novel training-free, task-agnostic two-stage framework\ndesigned to enhance MLLM performance on high-resolution images. The key\nintuition behind ECP is that while MLLMs struggle with high-resolution images,\ntheir predictions on downsampled images still contain implicit localization\ncues. By first identifying candidate region using the coarse prediction and\nthen predicting the final output based on candidate region, ECP effectively\npreserves fine-grained details while mitigating the challenges posed by\nhigh-resolution data. We validate our framework on 4K GUI grounding and 4K, 8K\nMLLM perception, achieving +21.3%, +5.8%, +5.2% absolute improvement compared\nto baseline respectively, demonstrating its effectiveness. Code is available at\nhttps://github.com/yenncye/ECP.", "published": "2025-07-14 12:14:53", "link": "http://arxiv.org/abs/2507.10202v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Learning Private Representations through Entropy-based Adversarial Training", "abstract": "How can we learn a representation with high predictive power while preserving\nuser privacy? We present an adversarial representation learning method for\nsanitizing sensitive content from the learned representation. Specifically, we\nintroduce a variant of entropy - focal entropy, which mitigates the potential\ninformation leakage of the existing entropy-based approaches. We showcase\nfeasibility on multiple benchmarks. The results suggest high target utility at\nmoderate privacy leakage.", "published": "2025-07-14 12:01:08", "link": "http://arxiv.org/abs/2507.10194v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Breaking the Myth: Can Small Models Infer Postconditions Too?", "abstract": "Formal specifications are essential for ensuring software correctness, yet\nmanually writing them is tedious and error-prone. Large Language Models (LLMs)\nhave shown promise in generating such specifications from natural language\nintents, but the giant model size and high computational demands raise a\nfundamental question: Do we really need large models for this task? In this\npaper, we show that a small, fine-tuned language model can achieve high-quality\npostcondition generation with much lower computational costs. We construct a\nspecialized dataset of prompts, reasoning logs, and postconditions, then\nsupervise the fine-tuning of a $7$B-parameter code model. Our approach tackles\nreal-world repository dependencies and preserves pre-state information,\nallowing for expressive and accurate specifications. We evaluate the model on a\nbenchmark of real-world Java bugs (Defects4J) and compare against both\nproprietary giants (e.g., GPT-4o) and open-source large models. Empirical\nresults demonstrate that our compact model matches or outperforms significantly\nlarger counterparts in syntax correctness, semantic correctness, and\nbug-distinguishing capability. These findings highlight that targeted\nfine-tuning on a modest dataset can enable small models to achieve results\nformerly seen only in massive, resource-heavy LLMs, offering a practical and\nefficient path for the real-world adoption of automated specification\ngeneration.", "published": "2025-07-14 11:44:04", "link": "http://arxiv.org/abs/2507.10182v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "The Second Machine Turn: From Checking Proofs to Creating Concepts", "abstract": "We identify a second machine turn in the process of mathematical discovery:\nafter automating proof-checking, AI is now poised to automate the *creation* of\nmathematical concepts themselves. We discuss the current state of the art,\nobstacles and potential solutions as well as a preliminary attempt at\nmathematizing the creation of concepts itself. The paper ends with an\nassessment of how these capabilities could reshape mathematics and\nhuman-machine collaboration, and a few different futures we might find\nourselves in.", "published": "2025-07-14 11:42:01", "link": "http://arxiv.org/abs/2507.10179v1", "categories": ["math.HO", "cs.AI"], "primary_category": "math.HO"}
{"title": "Should We Ever Prefer Decision Transformer for Offline Reinforcement Learning?", "abstract": "In recent years, extensive work has explored the application of the\nTransformer architecture to reinforcement learning problems. Among these,\nDecision Transformer (DT) has gained particular attention in the context of\noffline reinforcement learning due to its ability to frame return-conditioned\npolicy learning as a sequence modeling task. Most recently, Bhargava et al.\n(2024) provided a systematic comparison of DT with more conventional MLP-based\noffline RL algorithms, including Behavior Cloning (BC) and Conservative\nQ-Learning (CQL), and claimed that DT exhibits superior performance in\nsparse-reward and low-quality data settings.\n  In this paper, through experimentation on robotic manipulation tasks\n(Robomimic) and locomotion benchmarks (D4RL), we show that MLP-based Filtered\nBehavior Cloning (FBC) achieves competitive or superior performance compared to\nDT in sparse-reward environments. FBC simply filters out low-performing\ntrajectories from the dataset and then performs ordinary behavior cloning on\nthe filtered dataset. FBC is not only very straightforward, but it also\nrequires less training data and is computationally more efficient. The results\ntherefore suggest that DT is not preferable for sparse-reward environments.\nFrom prior work, arguably, DT is also not preferable for dense-reward\nenvironments. Thus, we pose the question: Is DT ever preferable?", "published": "2025-07-14 11:36:31", "link": "http://arxiv.org/abs/2507.10174v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Play Style Identification Using Low-Level Representations of Play Traces in MicroRTS", "abstract": "Play style identification can provide valuable game design insights and\nenable adaptive experiences, with the potential to improve game playing agents.\nPrevious work relies on domain knowledge to construct play trace\nrepresentations using handcrafted features. More recent approaches incorporate\nthe sequential structure of play traces but still require some level of domain\nabstraction. In this study, we explore the use of unsupervised CNN-LSTM\nautoencoder models to obtain latent representations directly from low-level\nplay trace data in MicroRTS. We demonstrate that this approach yields a\nmeaningful separation of different game playing agents in the latent space,\nreducing reliance on domain expertise and its associated biases. This latent\nspace is then used to guide the exploration of diverse play styles within\nstudied AI players.", "published": "2025-07-14 11:35:43", "link": "http://arxiv.org/abs/2507.10172v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Introducing the Swiss Food Knowledge Graph: AI for Context-Aware Nutrition Recommendation", "abstract": "AI has driven significant progress in the nutrition field, especially through\nmultimedia-based automatic dietary assessment. However, existing automatic\ndietary assessment systems often overlook critical non-visual factors, such as\nrecipe-specific ingredient substitutions that can significantly alter\nnutritional content, and rarely account for individual dietary needs, including\nallergies, restrictions, cultural practices, and personal preferences. In\nSwitzerland, while food-related information is available, it remains\nfragmented, and no centralized repository currently integrates all relevant\nnutrition-related aspects within a Swiss context. To bridge this divide, we\nintroduce the Swiss Food Knowledge Graph (SwissFKG), the first resource, to our\nbest knowledge, to unite recipes, ingredients, and their substitutions with\nnutrient data, dietary restrictions, allergen information, and national\nnutrition guidelines under one graph. We establish a LLM-powered enrichment\npipeline for populating the graph, whereby we further present the first\nbenchmark of four off-the-shelf (<70 B parameter) LLMs for food knowledge\naugmentation. Our results demonstrate that LLMs can effectively enrich the\ngraph with relevant nutritional information. Our SwissFKG goes beyond recipe\nrecommendations by offering ingredient-level information such as allergen and\ndietary restriction information, and guidance aligned with nutritional\nguidelines. Moreover, we implement a Graph-RAG application to showcase how the\nSwissFKG's rich natural-language data structure can help LLM answer\nuser-specific nutrition queries, and we evaluate LLM-embedding pairings by\ncomparing user-query responses against predefined expected answers. As such,\nour work lays the foundation for the next generation of dietary assessment\ntools that blend visual, contextual, and cultural dimensions of eating.", "published": "2025-07-14 11:12:30", "link": "http://arxiv.org/abs/2507.10156v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Adaptability in Multi-Agent Reinforcement Learning: A Framework and Unified Review", "abstract": "Multi-Agent Reinforcement Learning (MARL) has shown clear effectiveness in\ncoordinating multiple agents across simulated benchmarks and constrained\nscenarios. However, its deployment in real-world multi-agent systems (MAS)\nremains limited, primarily due to the complex and dynamic nature of such\nenvironments. These challenges arise from multiple interacting sources of\nvariability, including fluctuating agent populations, evolving task goals, and\ninconsistent execution conditions. Together, these factors demand that MARL\nalgorithms remain effective under continuously changing system configurations\nand operational demands. To better capture and assess this capacity for\nadjustment, we introduce the concept of \\textit{adaptability} as a unified and\npractically grounded lens through which to evaluate the reliability of MARL\nalgorithms under shifting conditions, broadly referring to any changes in the\nenvironment dynamics that may occur during learning or execution. Centred on\nthe notion of adaptability, we propose a structured framework comprising three\nkey dimensions: learning adaptability, policy adaptability, and scenario-driven\nadaptability. By adopting this adaptability perspective, we aim to support more\nprincipled assessments of MARL performance beyond narrowly defined benchmarks.\nUltimately, this survey contributes to the development of algorithms that are\nbetter suited for deployment in dynamic, real-world multi-agent systems.", "published": "2025-07-14 10:39:17", "link": "http://arxiv.org/abs/2507.10142v1", "categories": ["cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "A PBN-RL-XAI Framework for Discovering a \"Hit-and-Run'' Therapeutic Strategy in Melanoma", "abstract": "Innate resistance to anti-PD-1 immunotherapy remains a major clinical\nchallenge in metastatic melanoma, with the underlying molecular networks being\npoorly understood. To address this, we constructed a dynamic Probabilistic\nBoolean Network model using transcriptomic data from patient tumor biopsies to\nelucidate the regulatory logic governing therapy response. We then employed a\nreinforcement learning agent to systematically discover optimal, multi-step\ntherapeutic interventions and used explainable artificial intelligence to\nmechanistically interpret the agent's control policy. The analysis revealed\nthat a precisely timed, 4-step temporary inhibition of the lysyl oxidase like 2\nprotein (LOXL2) was the most effective strategy. Our explainable analysis\nshowed that this ``hit-and-run\" intervention is sufficient to erase the\nmolecular signature driving resistance, allowing the network to self-correct\nwithout requiring sustained intervention. This study presents a novel,\ntime-dependent therapeutic hypothesis for overcoming immunotherapy resistance\nand provides a powerful computational framework for identifying non-obvious\nintervention protocols in complex biological systems.", "published": "2025-07-14 10:35:38", "link": "http://arxiv.org/abs/2507.10136v1", "categories": ["q-bio.QM", "cs.AI"], "primary_category": "q-bio.QM"}
{"title": "FRSICL: LLM-Enabled In-Context Learning Flight Resource Allocation for Fresh Data Collection in UAV-Assisted Wildfire Monitoring", "abstract": "Unmanned Aerial Vehicles (UAVs) are vital for public safety, particularly in\nwildfire monitoring, where early detection minimizes environmental impact. In\nUAV-Assisted Wildfire Monitoring (UAWM) systems, joint optimization of sensor\ntransmission scheduling and velocity is critical for minimizing Age of\nInformation (AoI) from stale sensor data. Deep Reinforcement Learning (DRL) has\nbeen used for such optimization; however, its limitations such as low sampling\nefficiency, simulation-to-reality gaps, and complex training render it\nunsuitable for time-critical applications like wildfire monitoring. This paper\nintroduces a new online Flight Resource Allocation scheme based on LLM-Enabled\nIn-Context Learning (FRSICL) to jointly optimize the UAV's flight control and\ndata collection schedule along the trajectory in real time, thereby\nasymptotically minimizing the average AoI across ground sensors. In contrast to\nDRL, FRSICL generates data collection schedules and controls velocity using\nnatural language task descriptions and feedback from the environment, enabling\ndynamic decision-making without extensive retraining. Simulation results\nconfirm the effectiveness of the proposed FRSICL compared to Proximal Policy\nOptimization (PPO) and Nearest-Neighbor baselines.", "published": "2025-07-14 10:24:43", "link": "http://arxiv.org/abs/2507.10134v1", "categories": ["cs.AI", "53-01", "C.2"], "primary_category": "cs.AI"}
{"title": "Extending Defeasibility for Propositional Standpoint Logics", "abstract": "In this paper, we introduce a new defeasible version of propositional\nstandpoint logic by integrating Kraus et al.'s defeasible conditionals, Britz\nand Varzinczak's notions of defeasible necessity and distinct possibility,\nalong with Leisegang et al.'s approach to defeasibility into the standpoint\nlogics of G\\'omez \\'Alvarez and Rudolph. The resulting logical framework allows\nfor the expression of defeasibility on the level of implications, standpoint\nmodal operators, and standpoint-sharpening statements. We provide a\npreferential semantics for this extended language and propose a tableaux\ncalculus, which is shown to be sound and complete with respect to preferential\nentailment. We also establish the computational complexity of the tableaux\nprocedure to be in PSpace.", "published": "2025-07-14 10:23:49", "link": "http://arxiv.org/abs/2507.10133v1", "categories": ["cs.LO", "cs.AI"], "primary_category": "cs.LO"}
{"title": "Wavelet-Enhanced Neural ODE and Graph Attention for Interpretable Energy Forecasting", "abstract": "Accurate forecasting of energy demand and supply is critical for optimizing\nsustainable energy systems, yet it is challenged by the variability of\nrenewable sources and dynamic consumption patterns. This paper introduces a\nneural framework that integrates continuous-time Neural Ordinary Differential\nEquations (Neural ODEs), graph attention, multi-resolution wavelet\ntransformations, and adaptive learning of frequencies to address the issues of\ntime series prediction. The model employs a robust ODE solver, using the\nRunge-Kutta method, paired with graph-based attention and residual connections\nto better understand both structural and temporal patterns. Through\nwavelet-based feature extraction and adaptive frequency modulation, it adeptly\ncaptures and models diverse, multi-scale temporal dynamics. When evaluated\nacross seven diverse datasets: ETTh1, ETTh2, ETTm1, ETTm2 (electricity\ntransformer temperature), and Waste, Solar, and Hydro (renewable energy), this\narchitecture consistently outperforms state-of-the-art baselines in various\nforecasting metrics, proving its robustness in capturing complex temporal\ndependencies. Furthermore, the model enhances interpretability through SHAP\nanalysis, making it suitable for sustainable energy applications.", "published": "2025-07-14 10:23:18", "link": "http://arxiv.org/abs/2507.10132v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Taming Modern Point Tracking for Speckle Tracking Echocardiography via Impartial Motion", "abstract": "Accurate motion estimation for tracking deformable tissues in\nechocardiography is essential for precise cardiac function measurements. While\ntraditional methods like block matching or optical flow struggle with intricate\ncardiac motion, modern point tracking approaches remain largely underexplored\nin this domain. This work investigates the potential of state-of-the-art (SOTA)\npoint tracking methods for ultrasound, with a focus on echocardiography.\nAlthough these novel approaches demonstrate strong performance in general\nvideos, their effectiveness and generalizability in echocardiography remain\nlimited. By analyzing cardiac motion throughout the heart cycle in real B-mode\nultrasound videos, we identify that a directional motion bias across different\nviews is affecting the existing training strategies. To mitigate this, we\nrefine the training procedure and incorporate a set of tailored augmentations\nto reduce the bias and enhance tracking robustness and generalization through\nimpartial cardiac motion. We also propose a lightweight network leveraging\nmulti-scale cost volumes from spatial context alone to challenge the advanced\nspatiotemporal point tracking models. Experiments demonstrate that fine-tuning\nwith our strategies significantly improves models' performances over their\nbaselines, even for out-of-distribution (OOD) cases. For instance, EchoTracker\nboosts overall position accuracy by 60.7% and reduces median trajectory error\nby 61.5% across heart cycle phases. Interestingly, several point tracking\nmodels fail to outperform our proposed simple model in terms of tracking\naccuracy and generalization, reflecting their limitations when applied to\nechocardiography. Nevertheless, clinical evaluation reveals that these methods\nimprove GLS measurements, aligning more closely with expert-validated,\nsemi-automated tools and thus demonstrating better reproducibility in\nreal-world applications.", "published": "2025-07-14 10:18:26", "link": "http://arxiv.org/abs/2507.10127v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Could you be wrong: Debiasing LLMs using a metacognitive prompt for improving human decision making", "abstract": "Identifying bias in LLMs is ongoing. Because they are still in development,\nwhat is true today may be false tomorrow. We therefore need general strategies\nfor debiasing that will outlive current models. Strategies developed for\ndebiasing human decision making offer one promising approach as they\nincorporate an LLM-style prompt intervention designed to bring latent knowledge\ninto awareness during decision making. LLMs trained on vast amounts of\ninformation contain information about potential biases, counter-arguments, and\ncontradictory evidence, but that information may only be brought to bear if\nprompted. Metacognitive prompts developed in the human decision making\nliterature are designed to achieve this, and as I demonstrate here, they show\npromise with LLMs. The prompt I focus on here is \"could you be wrong?\"\nFollowing an LLM response, this prompt leads LLMs to produce additional\ninformation, including why they answered as they did, errors, biases,\ncontradictory evidence, and alternatives, none of which were apparent in their\ninitial response. Indeed, this metaknowledge often reveals that how LLMs and\nusers interpret prompts are not aligned. Here I demonstrate this prompt using a\nset of questions taken from recent articles about LLM biases, including\nimplicit discriminatory biases and failures of metacognition. \"Could you be\nwrong\" prompts the LLM to identify its own biases and produce cogent\nmetacognitive reflection. I also present another example involving convincing\nbut incomplete information, which is readily corrected by the metacognitive\nprompt. In sum, this work argues that human psychology offers a new avenue for\nprompt engineering, leveraging a long history of effective prompt-based\nimprovements to human decision making.", "published": "2025-07-14 10:09:46", "link": "http://arxiv.org/abs/2507.10124v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Variance-Reduced Cubic-Regularized Newton for Policy Optimization", "abstract": "In this paper, we study a second-order approach to policy optimization in\nreinforcement learning. Existing second-order methods often suffer from\nsuboptimal sample complexity or rely on unrealistic assumptions about\nimportance sampling. To overcome these limitations, we propose VR-CR-PN, a\nvariance-reduced cubic-regularized policy Newton algorithm. To the best of our\nknowledge, this is the first algorithm that integrates Hessian-aided variance\nreduction with second-order policy optimization, effectively addressing the\ndistribution shift problem and achieving best-known sample complexity under\ngeneral nonconvex conditions but without the need for importance sampling. We\ntheoretically establish that VR-CR-PN achieves a sample complexity of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-3})$ to reach an $\\epsilon$-second-order\nstationary point, significantly improving upon the previous best result of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-3.5})$ under comparable assumptions. As an\nadditional contribution, we introduce a novel Hessian estimator for the\nexpected return function, which admits a uniform upper bound independent of the\nhorizon length $H$, allowing the algorithm to achieve horizon-independent\nsample complexity.", "published": "2025-07-14 10:04:02", "link": "http://arxiv.org/abs/2507.10120v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Analysis of AI Techniques for Orchestrating Edge-Cloud Application Migration", "abstract": "Application migration in edge-cloud system enables high QoS and cost\neffective service delivery. However, automatically orchestrating such migration\nis typically solved with heuristic approaches. Starting from the Markov\nDecision Process (MDP), in this paper, we identify, analyze and compare\nselected state-of-the-art Artificial Intelligence (AI) planning and\nReinforcement Learning (RL) approaches for solving the class of edge-cloud\napplication migration problems that can be modeled as Towers of Hanoi (ToH)\nproblems. We introduce a new classification based on state space definition and\nanalyze the compared models also through this lense. The aim is to understand\navailable techniques capable of orchestrating such application migration in\nemerging computing continuum environments.", "published": "2025-07-14 10:03:23", "link": "http://arxiv.org/abs/2507.10119v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "BlueGlass: A Framework for Composite AI Safety", "abstract": "As AI systems become increasingly capable and ubiquitous, ensuring the safety\nof these systems is critical. However, existing safety tools often target\ndifferent aspects of model safety and cannot provide full assurance in\nisolation, highlighting a need for integrated and composite methodologies. This\npaper introduces BlueGlass, a framework designed to facilitate composite AI\nsafety workflows by providing a unified infrastructure enabling the integration\nand composition of diverse safety tools that operate across model internals and\noutputs. Furthermore, to demonstrate the utility of this framework, we present\nthree safety-oriented analyses on vision-language models for the task of object\ndetection: (1) distributional evaluation, revealing performance trade-offs and\npotential failure modes across distributions; (2) probe-based analysis of layer\ndynamics highlighting shared hierarchical learning via phase transition; and\n(3) sparse autoencoders identifying interpretable concepts. More broadly, this\nwork contributes foundational infrastructure and findings for building more\nrobust and reliable AI systems.", "published": "2025-07-14 09:45:34", "link": "http://arxiv.org/abs/2507.10106v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "On Gradual Semantics for Assumption-Based Argumentation", "abstract": "In computational argumentation, gradual semantics are fine-grained\nalternatives to extension-based and labelling-based semantics . They ascribe a\ndialectical strength to (components of) arguments sanctioning their degree of\nacceptability. Several gradual semantics have been studied for abstract,\nbipolar and quantitative bipolar argumentation frameworks (QBAFs), as well as,\nto a lesser extent, for some forms of structured argumentation. However, this\nhas not been the case for assumption-based argumentation (ABA), despite it\nbeing a popular form of structured argumentation with several applications\nwhere gradual semantics could be useful. In this paper, we fill this gap and\npropose a family of novel gradual semantics for equipping assumptions, which\nare the core components in ABA frameworks, with dialectical strengths. To do\nso, we use bipolar set-based argumentation frameworks as an abstraction of\n(potentially non-flat) ABA frameworks and generalise state-of-the-art modular\ngradual semantics for QBAFs. We show that our gradual ABA semantics satisfy\nsuitable adaptations of desirable properties of gradual QBAF semantics, such as\nbalance and monotonicity. We also explore an argument-based approach that\nleverages established QBAF modular semantics directly, and use it as baseline.\nFinally, we conduct experiments with synthetic ABA frameworks to compare our\ngradual ABA semantics with its argument-based counterpart and assess\nconvergence.", "published": "2025-07-14 09:02:45", "link": "http://arxiv.org/abs/2507.10076v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "TGLD: A Trust-Aware Game-Theoretic Lane-Changing Decision Framework for Automated Vehicles in Heterogeneous Traffic", "abstract": "Automated vehicles (AVs) face a critical need to adopt socially compatible\nbehaviors and cooperate effectively with human-driven vehicles (HVs) in\nheterogeneous traffic environment. However, most existing lane-changing\nframeworks overlook HVs' dynamic trust levels, limiting their ability to\naccurately predict human driver behaviors. To address this gap, this study\nproposes a trust-aware game-theoretic lane-changing decision (TGLD) framework.\nFirst, we formulate a multi-vehicle coalition game, incorporating fully\ncooperative interactions among AVs and partially cooperative behaviors from HVs\ninformed by real-time trust evaluations. Second, we develop an online trust\nevaluation method to dynamically estimate HVs' trust levels during\nlane-changing interactions, guiding AVs to select context-appropriate\ncooperative maneuvers. Lastly, social compatibility objectives are considered\nby minimizing disruption to surrounding vehicles and enhancing the\npredictability of AV behaviors, thereby ensuring human-friendly and\ncontext-adaptive lane-changing strategies. A human-in-the-loop experiment\nconducted in a highway on-ramp merging scenario validates our TGLD approach.\nResults show that AVs can effectively adjust strategies according to different\nHVs' trust levels and driving styles. Moreover, incorporating a trust mechanism\nsignificantly improves lane-changing efficiency, maintains safety, and\ncontributes to transparent and adaptive AV-HV interactions.", "published": "2025-07-14 09:01:00", "link": "http://arxiv.org/abs/2507.10075v1", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Lightweight Model for Poultry Disease Detection from Fecal Images Using Multi-Color Space Feature Optimization and Machine Learning", "abstract": "Poultry farming is a vital component of the global food supply chain, yet it\nremains highly vulnerable to infectious diseases such as coccidiosis,\nsalmonellosis, and Newcastle disease. This study proposes a lightweight machine\nlearning-based approach to detect these diseases by analyzing poultry fecal\nimages. We utilize multi-color space feature extraction (RGB, HSV, LAB) and\nexplore a wide range of color, texture, and shape-based descriptors, including\ncolor histograms, local binary patterns (LBP), wavelet transforms, and edge\ndetectors. Through a systematic ablation study and dimensionality reduction\nusing PCA and XGBoost feature selection, we identify a compact global feature\nset that balances accuracy and computational efficiency. An artificial neural\nnetwork (ANN) classifier trained on these features achieved 95.85% accuracy\nwhile requiring no GPU and only 638 seconds of execution time in Google Colab.\nCompared to deep learning models such as Xception and MobileNetV3, our proposed\nmodel offers comparable accuracy with drastically lower resource usage. This\nwork demonstrates a cost-effective, interpretable, and scalable alternative to\ndeep learning for real-time poultry disease detection in low-resource\nagricultural settings.", "published": "2025-07-14 08:40:46", "link": "http://arxiv.org/abs/2507.10056v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "(Almost) Free Modality Stitching of Foundation Models", "abstract": "Foundation multi-modal models are often designed by stitching of multiple\nexisting pretrained uni-modal models: for example, an image classifier with an\nautoregressive text model. This stitching process is performed by training a\nconnector module that aims to align the representation-representation or\nrepresentation-input spaces of these uni-modal models. However, given the\ncomplexity of training such connectors on large scale web-based datasets\ncoupled with the ever-increasing number of available pretrained uni-modal\nmodels, the task of uni-modal models selection and subsequent connector module\ntraining becomes computationally demanding. To address this under-studied\ncritical problem, we propose Hypernetwork Model Alignment (Hyma), a novel\nall-in-one solution for optimal uni-modal model selection and connector\ntraining by leveraging hypernetworks. Specifically, our framework utilizes the\nparameter prediction capability of a hypernetwork to obtain jointly trained\nconnector modules for $N \\times M$ combinations of uni-modal models. In our\nexperiments, Hyma reduces the optimal uni-modal model pair search cost by\n$10\\times$ (averaged across all experiments), while matching the ranking and\ntrained connector performance obtained via grid search across a suite of\ndiverse multi-modal benchmarks.", "published": "2025-07-14 07:51:01", "link": "http://arxiv.org/abs/2507.10015v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Deep Hidden Cognition Facilitates Reliable Chain-of-Thought Reasoning", "abstract": "Chain of Thought (CoT) reasoning has demonstrated remarkable deep reasoning\ncapabilities in both large language models (LLMs) and multimodal large language\nmodels (MLLMs). However, its reliability is often undermined by the\naccumulation of errors in intermediate steps. This paper introduces an novel\napproach to calibrate the CoT reasoning accuracy by leveraging the model's\nintrinsic veracity encoding. We discover that specific attention head\nactivations reliably reflect the truthfulness of reasoning steps in CoT. Based\non this insight, we train a confidence predictor to evaluate the correctness of\neach reasoning step using these truthfulness-sensitive activations, dynamically\nselecting the most plausible reasoning path via beam search. Experimental\nresults demonstrate that our method significantly outperforms the\nstate-of-the-art baselines (e.g., Few-Shot CoT, Self-Consistency, and\nSelf-Evaluation Guided Beam Search) across the mathematical, symbolic, and\ncommonsense reasoning tasks, exhibiting superior accuracy and reliability in\nboth unimodal and multimodal settings. We further validate the approach on\nlarge reasoning models, confirming its applicability to specialized reasoning\nmodels. Additionally, we explore the role of the model's self-correction\nability in CoT reasoning. This work provides a novel reliability improvement\npath for CoT reasoning with broad application potential.", "published": "2025-07-14 07:41:35", "link": "http://arxiv.org/abs/2507.10007v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Evolution of Fear and Social Rewards in Prey-Predator Relationship", "abstract": "Fear is a critical brain function for detecting danger and learning to avoid\nspecific stimuli that can lead to danger. While fear is believed to have\nevolved under pressure from predators, experimentally reproducing the evolution\nis challenging. To investigate the relationship between environmental\nconditions, the evolution of fear, and the evolution of other rewards, such as\nfood reward and social reward, we developed a distributed evolutionary\nsimulation. In our simulation, prey and predator agents co-evolve their innate\nreward functions, including a possibly fear-like term for observing predators,\nand learn behaviors via reinforcement learning. Surprisingly, our simulation\nrevealed that social reward for observing the same species is more important\nfor prey to survive, and fear-like negative reward for observing predators\nevolves only after acquiring social reward. We also found that the predator\nwith increased hunting ability (larger mouth) amplified fear emergence, but\nalso that fear evolution is more stable with non-evolving predators that are\nbad at chasing prey. Additionally, unlike for predators, we found that positive\nrewards evolve in opposition to fear for stationary threats, as areas with\nabundant leftover food develop around them. These findings suggest that fear\nand social reward have had a complex interplay with each other through\nevolution, along with the nature of predators and threats.", "published": "2025-07-14 07:27:18", "link": "http://arxiv.org/abs/2507.09992v1", "categories": ["q-bio.PE", "cs.AI", "cs.NE"], "primary_category": "q-bio.PE"}
{"title": "Differentially Private Federated Low Rank Adaptation Beyond Fixed-Matrix", "abstract": "Large language models (LLMs) typically require fine-tuning for\ndomain-specific tasks, and LoRA offers a computationally efficient approach by\ntraining low-rank adapters. LoRA is also communication-efficient for federated\nLLMs when multiple users collaboratively fine-tune a global LLM model without\nsharing their proprietary raw data. However, even the transmission of local\nadapters between a server and clients risks serious privacy leakage. Applying\ndifferential privacy (DP) to federated LoRA encounters a dilemma: adding noise\nto both adapters amplifies synthetic noise on the model, while fixing one\nadapter impairs the learnability of fine-tuning. In this paper, we propose\nFedASK (Differentially Private Federated Low Rank Adaptation with Double\nSketching) , a novel federated LoRA framework to enable effective updating of\nboth low-rank adapters with robust differential privacy. Inspired by randomized\nSVD, our key idea is a two-stage sketching pipeline. This pipeline first\naggregates carefully sketched, privacy-preserving local updates, and then\nreconstructs the global matrices on the server to facilitate effective updating\nof both adapters. We theoretically prove FedASK's differential privacy\nguarantee and its exact aggregation property. Comprehensive experiments\ndemonstrate that FedASK consistently outperforms baseline methods across a\nvariety of privacy settings and data distributions.", "published": "2025-07-14 07:17:24", "link": "http://arxiv.org/abs/2507.09990v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Improving monotonic optimization in heterogeneous multi-agent reinforcement learning with optimal marginal deterministic policy gradient", "abstract": "In heterogeneous multi-agent reinforcement learning (MARL), achieving\nmonotonic improvement plays a pivotal role in enhancing performance. The HAPPO\nalgorithm proposes a feasible solution by introducing a sequential update\nscheme, which requires independent learning with No Parameter-sharing (NoPS).\nHowever, heterogeneous MARL generally requires Partial Parameter-sharing\n(ParPS) based on agent grouping to achieve high cooperative performance. Our\nexperiments prove that directly combining ParPS with the sequential update\nscheme leads to the policy updating baseline drift problem, thereby failing to\nachieve improvement. To solve the conflict between monotonic improvement and\nParPS, we propose the Optimal Marginal Deterministic Policy Gradient (OMDPG)\nalgorithm. First, we replace the sequentially computed $Q_{\\psi}^s(s,a_{1:i})$\nwith the Optimal Marginal Q (OMQ) function $\\phi_{\\psi}^*(s,a_{1:i})$ derived\nfrom Q-functions. This maintains MAAD's monotonic improvement while eliminating\nthe conflict through optimal joint action sequences instead of sequential\npolicy ratio calculations. Second, we introduce the Generalized Q Critic (GQC)\nas the critic function, employing pessimistic uncertainty-constrained loss to\noptimize different Q-value estimations. This provides the required Q-values for\nOMQ computation and stable baselines for actor updates. Finally, we implement a\nCentralized Critic Grouped Actor (CCGA) architecture that simultaneously\nachieves ParPS in local policy networks and accurate global Q-function\ncomputation. Experimental results in SMAC and MAMuJoCo environments demonstrate\nthat OMDPG outperforms various state-of-the-art MARL baselines.", "published": "2025-07-14 07:16:01", "link": "http://arxiv.org/abs/2507.09989v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Demonstrating the Octopi-1.5 Visual-Tactile-Language Model", "abstract": "Touch is recognized as a vital sense for humans and an equally important\nmodality for robots, especially for dexterous manipulation, material\nidentification, and scenarios involving visual occlusion. Building upon very\nrecent work in touch foundation models, this demonstration will feature\nOctopi-1.5, our latest visual-tactile-language model. Compared to its\npredecessor, Octopi-1.5 introduces the ability to process tactile signals from\nmultiple object parts and employs a simple retrieval-augmented generation (RAG)\nmodule to improve performance on tasks and potentially learn new objects\non-the-fly. The system can be experienced live through a new handheld\ntactile-enabled interface, the TMI, equipped with GelSight and TAC-02 tactile\nsensors. This convenient and accessible setup allows users to interact with\nOctopi-1.5 without requiring a robot. During the demonstration, we will\nshowcase Octopi-1.5 solving tactile inference tasks by leveraging tactile\ninputs and commonsense knowledge. For example, in a Guessing Game, Octopi-1.5\nwill identify objects being grasped and respond to follow-up queries about how\nto handle it (e.g., recommending careful handling for soft fruits). We also\nplan to demonstrate Octopi-1.5's RAG capabilities by teaching it new items.\nWith live interactions, this demonstration aims to highlight both the progress\nand limitations of VTLMs such as Octopi-1.5 and to foster further interest in\nthis exciting field. Code for Octopi-1.5 and design files for the TMI gripper\nare available at https://github.com/clear-nus/octopi-1.5.", "published": "2025-07-14 07:05:36", "link": "http://arxiv.org/abs/2507.09985v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "A Brain Tumor Segmentation Method Based on CLIP and 3D U-Net with Cross-Modal Semantic Guidance and Multi-Level Feature Fusion", "abstract": "Precise segmentation of brain tumors from magnetic resonance imaging (MRI) is\nessential for neuro-oncology diagnosis and treatment planning. Despite advances\nin deep learning methods, automatic segmentation remains challenging due to\ntumor morphological heterogeneity and complex three-dimensional spatial\nrelationships. Current techniques primarily rely on visual features extracted\nfrom MRI sequences while underutilizing semantic knowledge embedded in medical\nreports. This research presents a multi-level fusion architecture that\nintegrates pixel-level, feature-level, and semantic-level information,\nfacilitating comprehensive processing from low-level data to high-level\nconcepts. The semantic-level fusion pathway combines the semantic understanding\ncapabilities of Contrastive Language-Image Pre-training (CLIP) models with the\nspatial feature extraction advantages of 3D U-Net through three mechanisms:\n3D-2D semantic bridging, cross-modal semantic guidance, and semantic-based\nattention mechanisms. Experimental validation on the BraTS 2020 dataset\ndemonstrates that the proposed model achieves an overall Dice coefficient of\n0.8567, representing a 4.8% improvement compared to traditional 3D U-Net, with\na 7.3% Dice coefficient increase in the clinically important enhancing tumor\n(ET) region.", "published": "2025-07-14 06:32:59", "link": "http://arxiv.org/abs/2507.09966v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "DeepSeek: Paradigm Shifts and Technical Evolution in Large AI Models", "abstract": "DeepSeek, a Chinese Artificial Intelligence (AI) startup, has released their\nV3 and R1 series models, which attracted global attention due to their low\ncost, high performance, and open-source advantages. This paper begins by\nreviewing the evolution of large AI models focusing on paradigm shifts, the\nmainstream Large Language Model (LLM) paradigm, and the DeepSeek paradigm.\nSubsequently, the paper highlights novel algorithms introduced by DeepSeek,\nincluding Multi-head Latent Attention (MLA), Mixture-of-Experts (MoE),\nMulti-Token Prediction (MTP), and Group Relative Policy Optimization (GRPO).\nThe paper then explores DeepSeek engineering breakthroughs in LLM scaling,\ntraining, inference, and system-level optimization architecture. Moreover, the\nimpact of DeepSeek models on the competitive AI landscape is analyzed,\ncomparing them to mainstream LLMs across various fields. Finally, the paper\nreflects on the insights gained from DeepSeek innovations and discusses future\ntrends in the technical and engineering development of large AI models,\nparticularly in data, training, and reasoning.", "published": "2025-07-14 06:10:30", "link": "http://arxiv.org/abs/2507.09955v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Can GPT-4o mini and Gemini 2.0 Flash Predict Fine-Grained Fashion Product Attributes? A Zero-Shot Analysis", "abstract": "The fashion retail business is centered around the capacity to comprehend\nproducts. Product attribution helps in comprehending products depending on the\nbusiness process. Quality attribution improves the customer experience as they\nnavigate through millions of products offered by a retail website. It leads to\nwell-organized product catalogs. In the end, product attribution directly\nimpacts the 'discovery experience' of the customer. Although large language\nmodels (LLMs) have shown remarkable capabilities in understanding multimodal\ndata, their performance on fine-grained fashion attribute recognition remains\nunder-explored. This paper presents a zero-shot evaluation of state-of-the-art\nLLMs that balance performance with speed and cost efficiency, mainly\nGPT-4o-mini and Gemini 2.0 Flash. We have used the dataset\nDeepFashion-MultiModal (https://github.com/yumingj/DeepFashion-MultiModal) to\nevaluate these models in the attribution tasks of fashion products. Our study\nevaluates these models across 18 categories of fashion attributes, offering\ninsight into where these models excel. We only use images as the sole input for\nproduct information to create a constrained environment. Our analysis shows\nthat Gemini 2.0 Flash demonstrates the strongest overall performance with a\nmacro F1 score of 56.79% across all attributes, while GPT-4o-mini scored a\nmacro F1 score of 43.28%. Through detailed error analysis, our findings provide\npractical insights for deploying these LLMs in production e-commerce product\nattribution-related tasks and highlight the need for domain-specific\nfine-tuning approaches. This work also lays the groundwork for future research\nin fashion AI and multimodal attribute extraction.", "published": "2025-07-14 05:59:50", "link": "http://arxiv.org/abs/2507.09950v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Memorization Sinks: Isolating Memorization during LLM Training", "abstract": "Large language models are susceptible to memorizing repeated sequences,\nposing privacy and copyright concerns. A popular mitigation strategy is to\nremove memorized information from specific neurons post-hoc. However, such\napproaches have shown limited success so far. In a controlled setting, we show\nthat the memorization of natural sequences (those that resemble linguistically\nplausible text) become mechanistically entangled with general language\nabilities, thereby becoming challenging to remove post-hoc. In this work, we\nput forward a new paradigm of MemSinks that promotes isolation of memorization\nby design. We leverage a sequence identifier that activates a unique set of\nmemorization neurons for each sequence across repetitions. By analyzing the\ndynamics of learning and forgetting, we argue that MemSinks facilitates\nisolation of memorized content, making it easier to remove without compromising\ngeneral language capabilities. We implement MemSinks at the billion-parameter\nand billion-token scale, and observe both effective isolation and strong\ngeneralization. To our knowledge, this is the first proof-of-concept on real\ndata demonstrating that simultaneous generalization and isolation is\nachievable. We open-source our code at http://github.com/grghosal/MemSinks.", "published": "2025-07-14 05:23:27", "link": "http://arxiv.org/abs/2507.09937v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Mechanistic Interpretability of LoRA-Adapted Language Models for Nuclear Reactor Safety Applications", "abstract": "The integration of Large Language Models (LLMs) into safety-critical domains,\nsuch as nuclear engineering, necessitates a deep understanding of their\ninternal reasoning processes. This paper presents a novel methodology for\ninterpreting how an LLM encodes and utilizes domain-specific knowledge, using a\nBoiling Water Reactor system as a case study. We adapted a general-purpose LLM\n(Gemma-3-1b-it) to the nuclear domain using a parameter-efficient fine-tuning\ntechnique known as Low-Rank Adaptation. By comparing the neuron activation\npatterns of the base model to those of the fine-tuned model, we identified a\nsparse set of neurons whose behavior was significantly altered during the\nadaptation process. To probe the causal role of these specialized neurons, we\nemployed a neuron silencing technique. Our results demonstrate that while\nsilencing most of these specialized neurons individually did not produce a\nstatistically significant effect, deactivating the entire group collectively\nled to a statistically significant degradation in task performance. Qualitative\nanalysis further revealed that silencing these neurons impaired the model's\nability to generate detailed, contextually accurate technical information. This\npaper provides a concrete methodology for enhancing the transparency of an\nopaque black-box model, allowing domain expertise to be traced to verifiable\nneural circuits. This offers a pathway towards achieving nuclear-grade\nartificial intelligence (AI) assurance, addressing the verification and\nvalidation challenges mandated by nuclear regulatory frameworks (e.g., 10 CFR\n50 Appendix B), which have limited AI deployment in safety-critical nuclear\noperations.", "published": "2025-07-14 05:17:41", "link": "http://arxiv.org/abs/2507.09931v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Aligning Generative Speech Enhancement with Human Preferences via Direct Preference Optimization", "abstract": "This work investigates speech enhancement (SE) from the perspective of\nlanguage models (LMs). We propose a novel method that leverages Direct\nPreference Optimization (DPO) to improve the perceptual quality of enhanced\nspeech. Using UTMOS, a neural MOS prediction model, as a proxy for human\nratings, our approach guides optimization toward perceptually preferred\noutputs. This differs from existing LM-based SE methods that focus on\nmaximizing the likelihood of clean speech tokens, which may misalign with human\nperception and degrade quality despite low prediction error. Experiments on the\n2020 Deep Noise Suppression Challenge test sets demonstrate that applying DPO\nto a pretrained LM-based SE model yields consistent improvements across various\nspeech quality metrics, with relative gains of up to 56%. To our knowledge,\nthis is the first application of DPO to SE and the first to incorporate proxy\nperceptual feedback into LM-based SE training, pointing to a promising\ndirection for perceptually aligned SE.", "published": "2025-07-14 05:15:39", "link": "http://arxiv.org/abs/2507.09929v1", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Large Population Models", "abstract": "Many of society's most pressing challenges, from pandemic response to supply\nchain disruptions to climate adaptation, emerge from the collective behavior of\nmillions of autonomous agents making decisions over time. Large Population\nModels (LPMs) offer an approach to understand these complex systems by\nsimulating entire populations with realistic behaviors and interactions at\nunprecedented scale. LPMs extend traditional modeling approaches through three\nkey innovations: computational methods that efficiently simulate millions of\nagents simultaneously, mathematical frameworks that learn from diverse\nreal-world data streams, and privacy-preserving communication protocols that\nbridge virtual and physical environments. This allows researchers to observe\nhow agent behavior aggregates into system-level outcomes and test interventions\nbefore real-world implementation. While current AI advances primarily focus on\ncreating \"digital humans\" with sophisticated individual capabilities, LPMs\ndevelop \"digital societies\" where the richness of interactions reveals emergent\nphenomena. By bridging individual agent behavior and population-scale dynamics,\nLPMs offer a complementary path in AI research illuminating collective\nintelligence and providing testing grounds for policies and social innovations\nbefore real-world deployment. We discuss the technical foundations and some\nopen problems here. LPMs are implemented by the AgentTorch framework\n(github.com/AgentTorch/AgentTorch)", "published": "2025-07-14 04:11:54", "link": "http://arxiv.org/abs/2507.09901v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Advanced U-Net Architectures with CNN Backbones for Automated Lung Cancer Detection and Segmentation in Chest CT Images", "abstract": "This study investigates the effectiveness of U-Net architectures integrated\nwith various convolutional neural network (CNN) backbones for automated lung\ncancer detection and segmentation in chest CT images, addressing the critical\nneed for accurate diagnostic tools in clinical settings. A balanced dataset of\n832 chest CT images (416 cancerous and 416 non-cancerous) was preprocessed\nusing Contrast Limited Adaptive Histogram Equalization (CLAHE) and resized to\n128x128 pixels. U-Net models were developed with three CNN backbones: ResNet50,\nVGG16, and Xception, to segment lung regions. After segmentation, CNN-based\nclassifiers and hybrid models combining CNN feature extraction with traditional\nmachine learning classifiers (Support Vector Machine, Random Forest, and\nGradient Boosting) were evaluated using 5-fold cross-validation. Metrics\nincluded accuracy, precision, recall, F1-score, Dice coefficient, and ROC-AUC.\nU-Net with ResNet50 achieved the best performance for cancerous lungs (Dice:\n0.9495, Accuracy: 0.9735), while U-Net with VGG16 performed best for\nnon-cancerous segmentation (Dice: 0.9532, Accuracy: 0.9513). For\nclassification, the CNN model using U-Net with Xception achieved 99.1 percent\naccuracy, 99.74 percent recall, and 99.42 percent F1-score. The hybrid\nCNN-SVM-Xception model achieved 96.7 percent accuracy and 97.88 percent\nF1-score. Compared to prior methods, our framework consistently outperformed\nexisting models. In conclusion, combining U-Net with advanced CNN backbones\nprovides a powerful method for both segmentation and classification of lung\ncancer in CT scans, supporting early diagnosis and clinical decision-making.", "published": "2025-07-14 04:08:33", "link": "http://arxiv.org/abs/2507.09898v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Sequence-Model-Guided Measurement Selection for Quantum State Learning", "abstract": "Characterization of quantum systems from experimental data is a central\nproblem in quantum science and technology. But which measurements should be\nused to gather data in the first place? While optimal measurement choices can\nbe worked out for small quantum systems, the optimization becomes intractable\nas the system size grows large. To address this problem, we introduce a deep\nneural network with a sequence model architecture that searches for efficient\nmeasurement choices in a data-driven, adaptive manner. The model can be applied\nto a variety of tasks, including the prediction of linear and nonlinear\nproperties of quantum states, as well as state clustering and state tomography\ntasks. In all these tasks, we find that the measurement choices identified by\nour neural network consistently outperform the uniformly random choice.\nIntriguingly, for topological quantum systems, our model tends to recommend\nmeasurements at the system's boundaries, even when the task is to predict bulk\nproperties. This behavior suggests that the neural network may have\nindependently discovered a connection between boundaries and bulk, without\nhaving been provided any built-in knowledge of quantum physics.", "published": "2025-07-14 03:50:42", "link": "http://arxiv.org/abs/2507.09891v1", "categories": ["quant-ph", "cs.AI", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Soft Graph Clustering for single-cell RNA Sequencing Data", "abstract": "Clustering analysis is fundamental in single-cell RNA sequencing (scRNA-seq)\ndata analysis for elucidating cellular heterogeneity and diversity. Recent\ngraph-based scRNA-seq clustering methods, particularly graph neural networks\n(GNNs), have significantly improved in tackling the challenges of\nhigh-dimension, high-sparsity, and frequent dropout events that lead to\nambiguous cell population boundaries. However, their reliance on hard graph\nconstructions derived from thresholded similarity matrices presents\nchallenges:(i) The simplification of intercellular relationships into binary\nedges (0 or 1) by applying thresholds, which restricts the capture of\ncontinuous similarity features among cells and leads to significant information\nloss.(ii) The presence of significant inter-cluster connections within hard\ngraphs, which can confuse GNN methods that rely heavily on graph structures,\npotentially causing erroneous message propagation and biased clustering\noutcomes. To tackle these challenges, we introduce scSGC, a Soft Graph\nClustering for single-cell RNA sequencing data, which aims to more accurately\ncharacterize continuous similarities among cells through non-binary edge\nweights, thereby mitigating the limitations of rigid data structures. The scSGC\nframework comprises three core components: (i) a zero-inflated negative\nbinomial (ZINB)-based feature autoencoder; (ii) a dual-channel cut-informed\nsoft graph embedding module; and (iii) an optimal transport-based clustering\noptimization module. Extensive experiments across ten datasets demonstrate that\nscSGC outperforms 13 state-of-the-art clustering models in clustering accuracy,\ncell type annotation, and computational efficiency. These results highlight its\nsubstantial potential to advance scRNA-seq data analysis and deepen our\nunderstanding of cellular heterogeneity.", "published": "2025-07-14 03:49:12", "link": "http://arxiv.org/abs/2507.09890v1", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "primary_category": "cs.LG"}
{"title": "NeuTSFlow: Modeling Continuous Functions Behind Time Series Forecasting", "abstract": "Time series forecasting is a fundamental task with broad applications, yet\nconventional methods often treat data as discrete sequences, overlooking their\norigin as noisy samples of continuous processes. Crucially, discrete noisy\nobservations cannot uniquely determine a continuous function; instead, they\ncorrespond to a family of plausible functions. Mathematically, time series can\nbe viewed as noisy observations of a continuous function family governed by a\nshared probability measure. Thus, the forecasting task can be framed as\nlearning the transition from the historical function family to the future\nfunction family. This reframing introduces two key challenges: (1) How can we\nleverage discrete historical and future observations to learn the relationships\nbetween their underlying continuous functions? (2) How can we model the\ntransition path in function space from the historical function family to the\nfuture function family? To address these challenges, we propose NeuTSFlow, a\nnovel framework that leverages Neural Operators to facilitate flow matching for\nlearning path of measure between historical and future function families. By\nparameterizing the velocity field of the flow in infinite-dimensional function\nspaces, NeuTSFlow moves beyond traditional methods that focus on dependencies\nat discrete points, directly modeling function-level features instead.\nExperiments on diverse forecasting tasks demonstrate NeuTSFlow's superior\naccuracy and robustness, validating the effectiveness of the function-family\nperspective.", "published": "2025-07-14 03:48:48", "link": "http://arxiv.org/abs/2507.09888v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "TolerantECG: A Foundation Model for Imperfect Electrocardiogram", "abstract": "The electrocardiogram (ECG) is an essential and effective tool for diagnosing\nheart diseases. However, its effectiveness can be compromised by noise or\nunavailability of one or more leads of the standard 12-lead recordings,\nresulting in diagnostic errors or uncertainty. To address these challenges, we\npropose TolerantECG, a foundation model for ECG signals that is robust to noise\nand capable of functioning with arbitrary subsets of the standard 12-lead ECG.\nTolerantECG training combines contrastive and self-supervised learning\nframeworks to jointly learn ECG signal representations alongside their\ncorresponding knowledge-retrieval-based text report descriptions and corrupted\nor lead-missing signals. Comprehensive benchmarking results demonstrate that\nTolerantECG consistently ranks as the best or second-best performer across\nvarious ECG signal conditions and class levels in the PTB-XL dataset, and\nachieves the highest performance on the MIT-BIH Arrhythmia Database.", "published": "2025-07-14 03:48:35", "link": "http://arxiv.org/abs/2507.09887v1", "categories": ["cs.LG", "cs.AI", "eess.SP"], "primary_category": "cs.LG"}
{"title": "VerifyBench: A Systematic Benchmark for Evaluating Reasoning Verifiers Across Domains", "abstract": "Large language models (LLMs) increasingly rely on reinforcement learning (RL)\nto enhance their reasoning capabilities through feedback. A critical challenge\nis verifying the consistency of model-generated responses and reference\nanswers, since these responses are often lengthy, diverse, and nuanced.\nRule-based verifiers struggle with complexity, prompting the use of model-based\nverifiers. However, specialized verifiers lack flexibility, while general LLM\njudges can be inconsistent. Existing research primarily focuses on building\nbetter verifiers, yet a systematic evaluation of different types of verifiers'\nperformance across domains remains lacking, severely constraining the reliable\ndevelopment of Reinforcement Learning with Verifiable Reward (RLVR). To address\nthis, we propose VerifyBench--a cross-domain comprehensive benchmark for\nsystematically evaluating verifiers. We construct 4,000 expert-level questions\ncovering mathematics, physics, chemistry, and biology. Each question is\nequipped with reference answers and diverse responses. The reliability of the\nevaluation is ensured through a rigorous annotation process conducted by a\nmultidisciplinary expert team. We design a four-dimensional experimental\nframework to comprehensively compare the performance boundaries of specialized\nverifiers and general LLMs under combined conditions of extracted answers vs.\ncomplete responses, and short vs. long outputs. Our evaluation uncovers\nfundamental trade-offs in verifiers: while specialized verifiers achieve\nleading accuracy, they exhibit deficiencies in recall; general models show\nstronger inclusivity but unstable precision. More importantly, we discover\nverifiers' high sensitivity to input structure and inherent limitations in\ncross-domain generalization, providing critical insights into the bottlenecks\nof current verifier technology.", "published": "2025-07-14 03:45:24", "link": "http://arxiv.org/abs/2507.09884v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Covering a Few Submodular Constraints and Applications", "abstract": "We consider the problem of covering multiple submodular constraints. Given a\nfinite ground set $N$, a cost function $c: N \\rightarrow \\mathbb{R}_+$, $r$\nmonotone submodular functions $f_1,f_2,\\ldots,f_r$ over $N$ and requirements\n$b_1,b_2,\\ldots,b_r$ the goal is to find a minimum cost subset $S \\subseteq N$\nsuch that $f_i(S) \\ge b_i$ for $1 \\le i \\le r$. When $r=1$ this is the\nwell-known Submodular Set Cover problem. Previous work\n\\cite{chekuri2022covering} considered the setting when $r$ is large and\ndeveloped bi-criteria approximation algorithms, and approximation algorithms\nfor the important special case when each $f_i$ is a weighted coverage function.\nThese are fairly general models and capture several concrete and interesting\nproblems as special cases. The approximation ratios for these problem are at\nleast $\\Omega(\\log r)$ which is unavoidable when $r$ is part of the input. In\nthis paper, motivated by some recent applications, we consider the problem when\n$r$ is a \\emph{fixed constant} and obtain two main results. For covering\nmultiple submodular constraints we obtain a randomized bi-criteria\napproximation algorithm that for any given integer $\\alpha \\ge 1$ outputs a set\n$S$ such that $f_i(S) \\ge$ $(1-1/e^\\alpha -\\epsilon)b_i$ for each $i \\in [r]$\nand $\\mathbb{E}[c(S)] \\le (1+\\epsilon)\\alpha \\cdot \\sf{OPT}$. Second, when the\n$f_i$ are weighted coverage functions from a deletion-closed set system we\nobtain a $(1+\\epsilon)$ $(\\frac{e}{e-1})$ $(1+\\beta)$-approximation where\n$\\beta$ is the approximation ratio for the underlying set cover instances via\nthe natural LP. These results show that one can obtain nearly as good an\napproximation for any fixed $r$ as what one would achieve for $r=1$. We mention\nsome applications that follow easily from these general results and anticipate\nmore in the future.", "published": "2025-07-14 03:32:42", "link": "http://arxiv.org/abs/2507.09879v1", "categories": ["cs.DS", "cs.AI", "cs.GT"], "primary_category": "cs.DS"}
{"title": "Task Priors: Enhancing Model Evaluation by Considering the Entire Space of Downstream Tasks", "abstract": "The grand goal of AI research, and particularly Self Supervised Learning\n(SSL), is to produce systems that can successfully solve any possible task. In\ncontrast, current evaluation methods available to AI researchers typically rely\non a fixed collection of hand-picked downstream benchmarks. Hence, a large\namount of effort is put into designing and searching for large collection of\nevaluation tasks that can serve as a proxy of our grand goal. We argue that\nsuch a rigid evaluation protocol creates a silent bottleneck in AI research. To\nremedy that, we define a probabilistic space of downstream tasks obtained by\nadopting a distribution of tasks and by defining Task Priors. Under this view,\none can evaluate a model's performance over the set of all possible downstream\ntasks. Our framework is the first to provide answers to key questions such as\n(i) what is the average performance of my model over all possible downstream\ntasks weighted by the probability to encounter each task? or (ii) what is the\nvariance of my model's performance across all downstream tasks under the\ndefined Task Priors? Beyond establishing a new standard for evaluation, we\nbelieve that Task Priors will accelerate the pace of research in SSL - where\ndownstream task evaluation is the sole qualitative signal that researchers have\naccess to.", "published": "2025-07-14 02:53:14", "link": "http://arxiv.org/abs/2507.09871v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Turning the Tide: Repository-based Code Reflection", "abstract": "Code large language models (LLMs) enhance programming by understanding and\ngenerating code across languages, offering intelligent feedback, bug detection,\nand code updates through reflection, improving development efficiency and\naccessibility. While benchmarks (e.g. HumanEval/LiveCodeBench) evaluate code\ngeneration and real-world relevance, previous works ignore the scenario of\nmodifying code in repositories. Considering challenges remaining in improving\nreflection capabilities and avoiding data contamination in dynamic benchmarks,\nwe introduce LiveRepoReflection, a challenging benchmark for evaluating code\nunderstanding and generation in multi-file repository contexts, featuring 1,888\nrigorously filtered test cases across $6$ programming languages to ensure\ndiversity, correctness, and high difficulty. Further, we create\nRepoReflection-Instruct, a large-scale, quality-filtered instruction-tuning\ndataset derived from diverse sources, used to train RepoReflectionCoder through\na two-turn dialogue process involving code generation and error-driven repair.\nThe leaderboard evaluates over 40 LLMs to reflect the model performance of\nrepository-based code reflection.", "published": "2025-07-14 02:36:27", "link": "http://arxiv.org/abs/2507.09866v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Intersection of Reinforcement Learning and Bayesian Optimization for Intelligent Control of Industrial Processes: A Safe MPC-based DPG using Multi-Objective BO", "abstract": "Model Predictive Control (MPC)-based Reinforcement Learning (RL) offers a\nstructured and interpretable alternative to Deep Neural Network (DNN)-based RL\nmethods, with lower computational complexity and greater transparency. However,\nstandard MPC-RL approaches often suffer from slow convergence, suboptimal\npolicy learning due to limited parameterization, and safety issues during\nonline adaptation. To address these challenges, we propose a novel framework\nthat integrates MPC-RL with Multi-Objective Bayesian Optimization (MOBO). The\nproposed MPC-RL-MOBO utilizes noisy evaluations of the RL stage cost and its\ngradient, estimated via a Compatible Deterministic Policy Gradient (CDPG)\napproach, and incorporates them into a MOBO algorithm using the Expected\nHypervolume Improvement (EHVI) acquisition function. This fusion enables\nefficient and safe tuning of the MPC parameters to achieve improved closed-loop\nperformance, even under model imperfections. A numerical example demonstrates\nthe effectiveness of the proposed approach in achieving sample-efficient,\nstable, and high-performance learning for control systems.", "published": "2025-07-14 02:31:52", "link": "http://arxiv.org/abs/2507.09864v1", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY", "math.OC"], "primary_category": "eess.SY"}
{"title": "A Survey on MLLM-based Visually Rich Document Understanding: Methods, Challenges, and Emerging Trends", "abstract": "Visually-Rich Document Understanding (VRDU) has emerged as a critical field,\ndriven by the need to automatically process documents containing complex\nvisual, textual, and layout information. Recently, Multimodal Large Language\nModels (MLLMs) have shown remarkable potential in this domain, leveraging both\nOptical Character Recognition (OCR)-dependent and OCR-free frameworks to\nextract and interpret information in document images. This survey reviews\nrecent advancements in MLLM-based VRDU, highlighting three core components: (1)\nmethods for encoding and fusing textual, visual, and layout features; (2)\ntraining paradigms, including pretraining strategies, instruction-response\ntuning, and the trainability of different model modules; and (3) datasets\nutilized for pretraining, instruction-tuning, and supervised fine-tuning.\nFinally, we discuss the challenges and opportunities in this evolving field and\npropose future directions to advance the efficiency, generalizability, and\nrobustness of VRDU systems.", "published": "2025-07-14 02:10:31", "link": "http://arxiv.org/abs/2507.09861v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Secure and Efficient UAV-Based Face Detection via Homomorphic Encryption and Edge Computing", "abstract": "This paper aims to propose a novel machine learning (ML) approach\nincorporating Homomorphic Encryption (HE) to address privacy limitations in\nUnmanned Aerial Vehicles (UAV)-based face detection. Due to challenges related\nto distance, altitude, and face orientation, high-resolution imagery and\nsophisticated neural networks enable accurate face recognition in dynamic\nenvironments. However, privacy concerns arise from the extensive surveillance\ncapabilities of UAVs. To resolve this issue, we propose a novel framework that\nintegrates HE with advanced neural networks to secure facial data throughout\nthe inference phase. This method ensures that facial data remains secure with\nminimal impact on detection accuracy. Specifically, the proposed system\nleverages the Cheon-Kim-Kim-Song (CKKS) scheme to perform computations directly\non encrypted data, optimizing computational efficiency and security.\nFurthermore, we develop an effective data encoding method specifically designed\nto preprocess the raw facial data into CKKS form in a\nSingle-Instruction-Multiple-Data (SIMD) manner. Building on this, we design a\nsecure inference algorithm to compute on ciphertext without needing decryption.\nThis approach not only protects data privacy during the processing of facial\ndata but also enhances the efficiency of UAV-based face detection systems.\nExperimental results demonstrate that our method effectively balances privacy\nprotection and detection performance, making it a viable solution for UAV-based\nsecure face detection. Significantly, our approach (while maintaining data\nconfidentially with HE encryption) can still achieve an accuracy of less than\n1% compared to the benchmark without using encryption.", "published": "2025-07-14 02:07:08", "link": "http://arxiv.org/abs/2507.09860v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Model-Grounded Symbolic Artificial Intelligence Systems Learning and Reasoning with Model-Grounded Symbolic Artificial Intelligence Systems", "abstract": "Neurosymbolic artificial intelligence (AI) systems combine neural network and\nclassical symbolic AI mechanisms to exploit the complementary strengths of\nlarge scale, generalizable learning and robust, verifiable reasoning. Numerous\nclassifications of neurosymbolic AI illustrate how these two components can be\nintegrated in distinctly different ways. In this work, we propose\nreinterpreting instruction tuned large language models as model grounded\nsymbolic AI systems where natural language serves as the symbolic layer and\ngrounding is achieved through the models internal representation space. Within\nthis framework, we investigate and develop novel learning and reasoning\napproaches that preserve structural similarities to traditional learning and\nreasoning paradigms. Preliminary evaluations across axiomatic deductive\nreasoning procedures of varying complexity provide insights into the\neffectiveness of our approach in improving learning efficiency and reasoning\nreliability.", "published": "2025-07-14 01:34:05", "link": "http://arxiv.org/abs/2507.09854v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Is Human-Written Data Enough? The Challenge of Teaching Reasoning to LLMs Without RL or Distillation", "abstract": "Reasoning-capable language models achieve state-of-the-art performance in\ndiverse complex tasks by generating long, explicit Chain-of-Thought (CoT)\ntraces. While recent works show that base models can acquire such reasoning\ntraces via reinforcement learning or distillation from stronger models like\nDeepSeek-R1, previous works demonstrate that even short CoT prompting without\nfine-tuning is able to improve reasoning. We ask whether long CoT can be\ninduced in a base model using only prompting or minimal tuning. Using just 20\nlong CoT examples from the reasoning model \\texttt{QwQ-32B-Preview}, we lightly\nfine-tune the base model \\texttt{Qwen2.5-32B}. The resulting model outperforms\nthe much larger \\texttt{Qwen2.5-Math-72B-Instruct}, showing that a handful of\nhigh-quality examples can unlock strong reasoning capabilities. We further\nexplore using CoT data from non-reasoning models and human annotators, enhanced\nwith prompt engineering, multi-pass editing, and structural guidance. However,\nneither matches the performance of reasoning model traces, suggesting that\ncertain latent qualities of expert CoT are difficult to replicate. We analyze\nkey properties of reasoning data, such as problem difficulty, diversity, and\nanswer length, that influence reasoning distillation. While challenges remain,\nwe are optimistic that carefully curated human-written CoT, even in small\nquantities, can activate reasoning behaviors in base models. We release our\nhuman-authored dataset across refinement stages and invite further\ninvestigation into what makes small-scale reasoning supervision so effective.", "published": "2025-07-14 01:14:50", "link": "http://arxiv.org/abs/2507.09850v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Through the River: Understanding the Benefit of Schedule-Free Methods for Language Model Training", "abstract": "As both model and dataset sizes continue to scale rapidly, conventional\npretraining strategies with fixed compute budgets-such as cosine learning rate\nschedules-are increasingly inadequate for large-scale training. Recent\nalternatives, including warmup-stable-decay (WSD) schedules and weight\naveraging, offer greater flexibility. However, WSD relies on explicit decay\nphases to track progress, while weight averaging addresses this limitation at\nthe cost of additional memory. In search of a more principled and scalable\nalternative, we revisit the Schedule-Free (SF) method [Defazio et al., 2024],\nwhich has shown strong empirical performance across diverse settings. We show\nthat SF-AdamW effectively navigates the \"river\" structure of the loss landscape\nwithout decay phases or auxiliary averaging, making it particularly suitable\nfor continuously scaling training workloads. To understand this behavior, we\nconduct a theoretical and empirical analysis of SF dynamics, revealing that it\nimplicitly performs weight averaging without memory overhead. Guided by this\nanalysis, we propose a refined variant of SF that improves robustness to\nmomentum and performs better under large batch sizes, addressing key\nlimitations of the original method. Together, these results establish SF as a\npractical, scalable, and theoretically grounded approach for language model\ntraining.", "published": "2025-07-14 00:54:48", "link": "http://arxiv.org/abs/2507.09846v1", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Pre-training Framework for Relational Data with Information-theoretic Principles", "abstract": "Relational databases underpin critical infrastructure across a wide range of\ndomains, yet the design of generalizable pre-training strategies for learning\nfrom relational databases remains an open challenge due to task heterogeneity.\nSpecifically, there exist infinitely many possible downstream tasks, as tasks\nare defined based on relational schema graphs, temporal dependencies, and\nSQL-defined label logics. An effective pre-training framework is desired to\ntake these factors into account in order to obtain task-aware representations.\nBy incorporating knowledge of the underlying distribution that drives label\ngeneration, downstream tasks can benefit from relevant side-channel\ninformation. To bridge this gap, we introduce Task Vector Estimation (TVE), a\nnovel pre-training framework that constructs predictive supervisory signals via\nset-based aggregation over schema traversal graphs, explicitly modeling\nnext-window relational dynamics. We formalize our approach through an\ninformation-theoretic lens, demonstrating that task-informed representations\nretain more relevant signals than those obtained without task priors. Extensive\nexperiments on the RelBench benchmark show that TVE consistently outperforms\ntraditional pre-training baselines. Our findings advocate for pre-training\nobjectives that encode task heterogeneity and temporal structure as design\nprinciples for predictive modeling on relational databases.", "published": "2025-07-14 00:17:21", "link": "http://arxiv.org/abs/2507.09837v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Quantize-then-Rectify: Efficient VQ-VAE Training", "abstract": "Visual tokenizers are pivotal in multimodal large models, acting as bridges\nbetween continuous inputs and discrete tokens. Nevertheless, training\nhigh-compression-rate VQ-VAEs remains computationally demanding, often\nnecessitating thousands of GPU hours. This work demonstrates that a pre-trained\nVAE can be efficiently transformed into a VQ-VAE by controlling quantization\nnoise within the VAE's tolerance threshold. We present\n\\textbf{Quantize-then-Rectify (ReVQ)}, a framework leveraging pre-trained VAEs\nto enable rapid VQ-VAE training with minimal computational overhead. By\nintegrating \\textbf{channel multi-group quantization} to enlarge codebook\ncapacity and a \\textbf{post rectifier} to mitigate quantization errors, ReVQ\ncompresses ImageNet images into at most 512 tokens while sustaining competitive\nreconstruction quality (rFID = 1.06). Significantly, ReVQ reduces training\ncosts by over two orders of magnitude relative to state-of-the-art approaches:\nReVQ finishes full training on a single NVIDIA 4090 in approximately 22 hours,\nwhereas comparable methods require 4.5 days on 32 A100 GPUs. Experimental\nresults show that ReVQ achieves superior efficiency-reconstruction trade-offs.", "published": "2025-07-14 17:59:41", "link": "http://arxiv.org/abs/2507.10547v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "National level satellite-based crop field inventories in smallholder landscapes", "abstract": "The design of science-based policies to improve the sustainability of\nsmallholder agriculture is challenged by a limited understanding of fundamental\nsystem properties, such as the spatial distribution of active cropland and\nfield size. We integrate very high spatial resolution (1.5 m) Earth observation\ndata and deep transfer learning to derive crop field delineations in complex\nagricultural systems at the national scale, while maintaining minimum reference\ndata requirements and enhancing transferability. We provide the first\nnational-level dataset of 21 million individual fields for Mozambique (covering\n~800,000 km2) for 2023. Our maps separate active cropland from non-agricultural\nland use with an overall accuracy of 93% and balanced omission and commission\nerrors. Field-level spatial agreement reached median intersection over union\n(IoU) scores of 0.81, advancing the state-of-the-art in large-area field\ndelineation in complex smallholder systems. The active cropland maps capture\nfragmented rural regions with low cropland shares not yet identified in global\nland cover or cropland maps. These regions are mostly located in agricultural\nfrontier regions which host 7-9% of the Mozambican population. Field size in\nMozambique is very low overall, with half of the fields being smaller than 0.16\nha, and 83% smaller than 0.5 ha. Mean field size at aggregate spatial\nresolution (0.05{\\deg}) is 0.32 ha, but it varies strongly across gradients of\naccessibility, population density, and net forest cover change. This variation\nreflects a diverse set of actors, ranging from semi-subsistence smallholder\nfarms to medium-scale commercial farming, and large-scale farming operations.\nOur results highlight that field size is a key indicator relating to\nsocio-economic and environmental outcomes of agriculture (e.g., food\nproduction, livelihoods, deforestation, biodiversity), as well as their\ntrade-offs.", "published": "2025-07-14 17:23:43", "link": "http://arxiv.org/abs/2507.10499v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "The Power of Certainty: How Confident Models Lead to Better Segmentation", "abstract": "Deep learning models have been proposed for automatic polyp detection and\nprecise segmentation of polyps during colonoscopy procedures. Although these\nstate-of-the-art models achieve high performance, they often require a large\nnumber of parameters. Their complexity can make them prone to overfitting,\nparticularly when trained on biased datasets, and can result in poor\ngeneralization across diverse datasets. Knowledge distillation and\nself-distillation are proposed as promising strategies to mitigate the\nlimitations of large, over-parameterized models. These approaches, however, are\nresource-intensive, often requiring multiple models and significant memory\nduring training. We propose a confidence-based self-distillation approach that\noutperforms state-of-the-art models by utilizing only previous iteration data\nstorage during training, without requiring extra computation or memory usage\nduring testing. Our approach calculates the loss between the previous and\ncurrent iterations within a batch using a dynamic confidence coefficient. To\nevaluate the effectiveness of our approach, we conduct comprehensive\nexperiments on the task of polyp segmentation. Our approach outperforms\nstate-of-the-art models and generalizes well across datasets collected from\nmultiple clinical centers. The code will be released to the public once the\npaper is accepted.", "published": "2025-07-14 17:12:43", "link": "http://arxiv.org/abs/2507.10490v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GT-Loc: Unifying When and Where in Images Through a Joint Embedding Space", "abstract": "Timestamp prediction aims to determine when an image was captured using only\nvisual information, supporting applications such as metadata correction,\nretrieval, and digital forensics. In outdoor scenarios, hourly estimates rely\non cues like brightness, hue, and shadow positioning, while seasonal changes\nand weather inform date estimation. However, these visual cues significantly\ndepend on geographic context, closely linking timestamp prediction to\ngeo-localization. To address this interdependence, we introduce GT-Loc, a novel\nretrieval-based method that jointly predicts the capture time (hour and month)\nand geo-location (GPS coordinates) of an image. Our approach employs separate\nencoders for images, time, and location, aligning their embeddings within a\nshared high-dimensional feature space. Recognizing the cyclical nature of time,\ninstead of conventional contrastive learning with hard positives and negatives,\nwe propose a temporal metric-learning objective providing soft targets by\nmodeling pairwise time differences over a cyclical toroidal surface. We present\nnew benchmarks demonstrating that our joint optimization surpasses previous\ntime prediction methods, even those using the ground-truth geo-location as an\ninput during inference. Additionally, our approach achieves competitive results\non standard geo-localization tasks, and the unified embedding space facilitates\ncompositional and text-based image retrieval.", "published": "2025-07-14 16:54:57", "link": "http://arxiv.org/abs/2507.10473v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RefSTAR: Blind Facial Image Restoration with Reference Selection, Transfer, and Reconstruction", "abstract": "Blind facial image restoration is highly challenging due to unknown complex\ndegradations and the sensitivity of humans to faces. Although existing methods\nintroduce auxiliary information from generative priors or high-quality\nreference images, they still struggle with identity preservation problems,\nmainly due to improper feature introduction on detailed textures. In this\npaper, we focus on effectively incorporating appropriate features from\nhigh-quality reference images, presenting a novel blind facial image\nrestoration method that considers reference selection, transfer, and\nreconstruction (RefSTAR). In terms of selection, we construct a reference\nselection (RefSel) module. For training the RefSel module, we construct a\nRefSel-HQ dataset through a mask generation pipeline, which contains annotating\nmasks for 10,000 ground truth-reference pairs. As for the transfer, due to the\ntrivial solution in vanilla cross-attention operations, a feature fusion\nparadigm is designed to force the features from the reference to be integrated.\nFinally, we propose a reference image reconstruction mechanism that further\nensures the presence of reference image features in the output image. The cycle\nconsistency loss is also redesigned in conjunction with the mask. Extensive\nexperiments on various backbone models demonstrate superior performance,\nshowing better identity preservation ability and reference feature transfer\nquality. Source code, dataset, and pre-trained models are available at\nhttps://github.com/yinzhicun/RefSTAR.", "published": "2025-07-14 16:50:29", "link": "http://arxiv.org/abs/2507.10470v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "4D-Animal: Freely Reconstructing Animatable 3D Animals from Videos", "abstract": "Existing methods for reconstructing animatable 3D animals from videos\ntypically rely on sparse semantic keypoints to fit parametric models. However,\nobtaining such keypoints is labor-intensive, and keypoint detectors trained on\nlimited animal data are often unreliable. To address this, we propose\n4D-Animal, a novel framework that reconstructs animatable 3D animals from\nvideos without requiring sparse keypoint annotations. Our approach introduces a\ndense feature network that maps 2D representations to SMAL parameters,\nenhancing both the efficiency and stability of the fitting process.\nFurthermore, we develop a hierarchical alignment strategy that integrates\nsilhouette, part-level, pixel-level, and temporal cues from pre-trained 2D\nvisual models to produce accurate and temporally coherent reconstructions\nacross frames. Extensive experiments demonstrate that 4D-Animal outperforms\nboth model-based and model-free baselines. Moreover, the high-quality 3D assets\ngenerated by our method can benefit other 3D tasks, underscoring its potential\nfor large-scale applications. The code is released at\nhttps://github.com/zhongshsh/4D-Animal.", "published": "2025-07-14 16:24:31", "link": "http://arxiv.org/abs/2507.10437v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CLA: Latent Alignment for Online Continual Self-Supervised Learning", "abstract": "Self-supervised learning (SSL) is able to build latent representations that\ngeneralize well to unseen data. However, only a few SSL techniques exist for\nthe online CL setting, where data arrives in small minibatches, the model must\ncomply with a fixed computational budget, and task boundaries are absent. We\nintroduce Continual Latent Alignment (CLA), a novel SSL strategy for Online CL\nthat aligns the representations learned by the current model with past\nrepresentations to mitigate forgetting. We found that our CLA is able to speed\nup the convergence of the training process in the online scenario,\noutperforming state-of-the-art approaches under the same computational budget.\nSurprisingly, we also discovered that using CLA as a pretraining protocol in\nthe early stages of pretraining leads to a better final performance when\ncompared to a full i.i.d. pretraining.", "published": "2025-07-14 16:23:39", "link": "http://arxiv.org/abs/2507.10434v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Text-Visual Semantic Constrained AI-Generated Image Quality Assessment", "abstract": "With the rapid advancements in Artificial Intelligence Generated Image (AGI)\ntechnology, the accurate assessment of their quality has become an increasingly\nvital requirement. Prevailing methods typically rely on cross-modal models like\nCLIP or BLIP to evaluate text-image alignment and visual quality. However, when\napplied to AGIs, these methods encounter two primary challenges: semantic\nmisalignment and details perception missing. To address these limitations, we\npropose Text-Visual Semantic Constrained AI-Generated Image Quality Assessment\n(SC-AGIQA), a unified framework that leverages text-visual semantic constraints\nto significantly enhance the comprehensive evaluation of both text-image\nconsistency and perceptual distortion in AI-generated images. Our approach\nintegrates key capabilities from multiple models and tackles the aforementioned\nchallenges by introducing two core modules: the Text-assisted Semantic\nAlignment Module (TSAM), which leverages Multimodal Large Language Models\n(MLLMs) to bridge the semantic gap by generating an image description and\ncomparing it against the original prompt for a refined consistency check, and\nthe Frequency-domain Fine-Grained Degradation Perception Module (FFDPM), which\ndraws inspiration from Human Visual System (HVS) properties by employing\nfrequency domain analysis combined with perceptual sensitivity weighting to\nbetter quantify subtle visual distortions and enhance the capture of\nfine-grained visual quality details in images. Extensive experiments conducted\non multiple benchmark datasets demonstrate that SC-AGIQA outperforms existing\nstate-of-the-art methods. The code is publicly available at\nhttps://github.com/mozhu1/SC-AGIQA.", "published": "2025-07-14 16:21:05", "link": "http://arxiv.org/abs/2507.10432v1", "categories": ["cs.CV", "I.4.7"], "primary_category": "cs.CV"}
{"title": "Numerically Computing Galois Groups of Minimal Problems", "abstract": "I discuss a seemingly unlikely confluence of topics in algebra, numerical\ncomputation, and computer vision. The motivating problem is that of solving\nmultiples instances of a parametric family of systems of algebraic (polynomial\nor rational function) equations. No doubt already of interest to ISSAC\nattendees, this problem arises in the context of robust model-fitting paradigms\ncurrently utilized by the computer vision community (namely \"Random Sampling\nand Consensus\", aka \"RanSaC\".) This talk will give an overview of work in the\nlast 5+ years that aspires to measure the intrinsic difficulty of solving such\nparametric systems, and makes strides towards practical solutions.", "published": "2025-07-14 15:53:58", "link": "http://arxiv.org/abs/2507.10407v1", "categories": ["cs.CV", "cs.SC", "math.AG", "68W30"], "primary_category": "cs.CV"}
{"title": "Improving Remote Sensing Classification using Topological Data Analysis and Convolutional Neural Networks", "abstract": "Topological data analysis (TDA) is a relatively new field that is gaining\nrapid adoption due to its robustness and ability to effectively describe\ncomplex datasets by quantifying geometric information. In imaging contexts, TDA\ntypically models data as filtered cubical complexes from which we can extract\ndiscriminative features using persistence homology. Meanwhile, convolutional\nneural networks (CNNs) have been shown to be biased towards texture based local\nfeatures. To address this limitation, we propose a TDA feature engineering\npipeline and a simple method to integrate topological features with deep\nlearning models on remote sensing classification. Our method improves the\nperformance of a ResNet18 model on the EuroSAT dataset by 1.44% achieving\n99.33% accuracy, which surpasses all previously reported single-model\naccuracies, including those with larger architectures, such as ResNet50 (2x\nlarger) and XL Vision Transformers (197x larger). We additionally show that our\nmethod's accuracy is 1.82% higher than our ResNet18 baseline on the RESISC45\ndataset. To our knowledge, this is the first application of TDA features in\nsatellite scene classification with deep learning. This demonstrates that TDA\nfeatures can be integrated with deep learning models, even on datasets without\nexplicit topological structures, thereby increasing the applicability of TDA. A\nclean implementation of our method will be made publicly available upon\npublication.", "published": "2025-07-14 15:22:29", "link": "http://arxiv.org/abs/2507.10381v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Test-Time Canonicalization by Foundation Models for Robust Perception", "abstract": "Real-world visual perception requires invariance to diverse transformations,\nyet current methods rely heavily on specialized architectures or training on\npredefined augmentations, limiting generalization. We propose FOCAL, a\ntest-time, data-driven framework that achieves robust perception by leveraging\ninternet-scale visual priors from foundation models. By generating and\noptimizing candidate transformations toward visually typical, \"canonical\"\nviews, FOCAL enhances robustness without re-training or architectural changes.\nOur experiments demonstrate improved robustness of CLIP and SAM across\nchallenging transformations, including 2D/3D rotations, illumination shifts\n(contrast and color), and day-night variations. We also highlight potential\napplications in active vision. Our approach challenges the assumption that\ntransform-specific training is necessary, instead offering a scalable path to\ninvariance. Our code is available at: https://github.com/sutkarsh/focal.", "published": "2025-07-14 15:14:38", "link": "http://arxiv.org/abs/2507.10375v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Fine-Grained Zero-Shot Object Detection", "abstract": "Zero-shot object detection (ZSD) aims to leverage semantic descriptions to\nlocalize and recognize objects of both seen and unseen classes. Existing ZSD\nworks are mainly coarse-grained object detection, where the classes are\nvisually quite different, thus are relatively easy to distinguish. However, in\nreal life we often have to face fine-grained object detection scenarios, where\nthe classes are too similar to be easily distinguished. For example, detecting\ndifferent kinds of birds, fishes, and flowers.\n  In this paper, we propose and solve a new problem called Fine-Grained\nZero-Shot Object Detection (FG-ZSD for short), which aims to detect objects of\ndifferent classes with minute differences in details under the ZSD paradigm. We\ndevelop an effective method called MSHC for the FG-ZSD task, which is based on\nan improved two-stage detector and employs a multi-level semantics-aware\nembedding alignment loss, ensuring tight coupling between the visual and\nsemantic spaces. Considering that existing ZSD datasets are not suitable for\nthe new FG-ZSD task, we build the first FG-ZSD benchmark dataset FGZSD-Birds,\nwhich contains 148,820 images falling into 36 orders, 140 families, 579 genera\nand 1432 species. Extensive experiments on FGZSD-Birds show that our method\noutperforms existing ZSD models.", "published": "2025-07-14 15:00:00", "link": "http://arxiv.org/abs/2507.10358v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond Graph Model: Reliable VLM Fine-Tuning via Random Graph Adapter", "abstract": "Textual adapter-based tuning methods have shown significant potential in\ntransferring knowledge from pre-trained Vision-Language Models (VLMs) to\ndownstream tasks. Existing works generally employ the deterministic textual\nfeature adapter to refine each category textual representation. However, due to\ninherent factors such as different attributes and contexts, there exists\nsignificant diversity in textual descriptions for each category. Such\ndescription diversity offers rich discriminative semantic knowledge that can\nbenefit downstream visual learning tasks. Obviously, traditional deterministic\nadapter model cannot adequately capture this varied semantic information. Also,\nit is desirable to exploit the inter-class relationships in VLM adapter. To\naddress these issues, we propose to exploit random graph model into VLM adapter\nand develop a novel Vertex Random Graph Adapter (VRGAdapter). VRGAdapter first\nmodels the inherent diverse descriptions of each category and inter-class\nrelationships of different categories simultaneously by leveraging a Vertex\nRandom Knowledge Graph (VRKG) model. Then, it employs probabilistic message\npropagation on VRKG to learn context-aware distribution representation for each\nclass node. Finally, it adopts a reparameterized sampling function to achieve\ntextual adapter learning. Note that, VRGAdapter provides a more general adapter\nsolution that encompasses traditional graph-based adapter as a special case. In\naddition, to enable more robust performance for downstream tasks, we also\nintroduce a new Uncertainty-guided Multi-branch Fusion (UMF) scheme that\ndynamically integrates multiple pre-trained models for ensemble prediction.\nExtensive experiments on multiple benchmark datasets demonstrate the\neffectiveness of our approach.", "published": "2025-07-14 14:56:49", "link": "http://arxiv.org/abs/2507.10355v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FGSSNet: Feature-Guided Semantic Segmentation of Real World Floorplans", "abstract": "We introduce FGSSNet, a novel multi-headed feature-guided semantic\nsegmentation (FGSS) architecture designed to improve the generalization ability\nof wall segmentation on floorplans. FGSSNet features a U-Net segmentation\nbackbone with a multi-headed dedicated feature extractor used to extract\ndomain-specific feature maps which are injected into the latent space of U-Net\nto guide the segmentation process. This dedicated feature extractor is trained\nas an encoder-decoder with selected wall patches, representative of the walls\npresent in the input floorplan, to produce a compressed latent representation\nof wall patches while jointly trained to predict the wall width. In doing so,\nwe expect that the feature extractor encodes texture and width features of wall\npatches that are useful to guide the wall segmentation process. Our experiments\nshow increased performance by the use of such injected features in comparison\nto the vanilla U-Net, highlighting the validity of the proposed approach.", "published": "2025-07-14 14:47:11", "link": "http://arxiv.org/abs/2507.10343v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Text Embedding Knows How to Quantize Text-Guided Diffusion Models", "abstract": "Despite the success of diffusion models in image generation tasks such as\ntext-to-image, the enormous computational complexity of diffusion models limits\ntheir use in resource-constrained environments. To address this, network\nquantization has emerged as a promising solution for designing efficient\ndiffusion models. However, existing diffusion model quantization methods do not\nconsider input conditions, such as text prompts, as an essential source of\ninformation for quantization. In this paper, we propose a novel quantization\nmethod dubbed Quantization of Language-to-Image diffusion models using text\nPrompts (QLIP). QLIP leverages text prompts to guide the selection of bit\nprecision for every layer at each time step. In addition, QLIP can be\nseamlessly integrated into existing quantization methods to enhance\nquantization efficiency. Our extensive experiments demonstrate the\neffectiveness of QLIP in reducing computational complexity and improving the\nquality of the generated images across various datasets.", "published": "2025-07-14 14:44:59", "link": "http://arxiv.org/abs/2507.10340v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mind the Gap: Aligning Vision Foundation Models to Image Feature Matching", "abstract": "Leveraging the vision foundation models has emerged as a mainstream paradigm\nthat improves the performance of image feature matching. However, previous\nworks have ignored the misalignment when introducing the foundation models into\nfeature matching. The misalignment arises from the discrepancy between the\nfoundation models focusing on single-image understanding and the cross-image\nunderstanding requirement of feature matching. Specifically, 1) the embeddings\nderived from commonly used foundation models exhibit discrepancies with the\noptimal embeddings required for feature matching; 2) lacking an effective\nmechanism to leverage the single-image understanding ability into cross-image\nunderstanding. A significant consequence of the misalignment is they struggle\nwhen addressing multi-instance feature matching problems. To address this, we\nintroduce a simple but effective framework, called IMD (Image feature Matching\nwith a pre-trained Diffusion model) with two parts: 1) Unlike the dominant\nsolutions employing contrastive-learning based foundation models that emphasize\nglobal semantics, we integrate the generative-based diffusion models to\neffectively capture instance-level details. 2) We leverage the prompt mechanism\nin generative model as a natural tunnel, propose a novel cross-image\ninteraction prompting module to facilitate bidirectional information\ninteraction between image pairs. To more accurately measure the misalignment,\nwe propose a new benchmark called IMIM, which focuses on multi-instance\nscenarios. Our proposed IMD establishes a new state-of-the-art in commonly\nevaluated benchmarks, and the superior improvement 12% in IMIM indicates our\nmethod efficiently mitigates the misalignment.", "published": "2025-07-14 14:28:15", "link": "http://arxiv.org/abs/2507.10318v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Contrastive Pretraining with Dual Visual Encoders for Gloss-Free Sign Language Translation", "abstract": "Sign Language Translation (SLT) aims to convert sign language videos into\nspoken or written text. While early systems relied on gloss annotations as an\nintermediate supervision, such annotations are costly to obtain and often fail\nto capture the full complexity of continuous signing. In this work, we propose\na two-phase, dual visual encoder framework for gloss-free SLT, leveraging\ncontrastive visual-language pretraining. During pretraining, our approach\nemploys two complementary visual backbones whose outputs are jointly aligned\nwith each other and with sentence-level text embeddings via a contrastive\nobjective. During the downstream SLT task, we fuse the visual features and\ninput them into an encoder-decoder model. On the Phoenix-2014T benchmark, our\ndual encoder architecture consistently outperforms its single stream variants\nand achieves the highest BLEU-4 score among existing gloss-free SLT approaches.", "published": "2025-07-14 14:09:36", "link": "http://arxiv.org/abs/2507.10306v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DisCo: Towards Distinct and Coherent Visual Encapsulation in Video MLLMs", "abstract": "In video Multimodal Large Language Models (video MLLMs), the visual\nencapsulation process plays a pivotal role in converting video contents into\nrepresentative tokens for LLM input. While linear projectors are widely\nemployed for encapsulation, they introduce semantic indistinctness and temporal\nincoherence when applied to videos. Conversely, the structure of resamplers\nshows promise in tackling these challenges, but an effective solution remains\nunexplored. Drawing inspiration from resampler structures, we introduce DisCo,\na novel visual encapsulation method designed to yield semantically distinct and\ntemporally coherent visual tokens for video MLLMs. DisCo integrates two key\ncomponents: (1) A Visual Concept Discriminator (VCD) module, assigning unique\nsemantics for visual tokens by associating them in pair with discriminative\nconcepts in the video. (2) A Temporal Focus Calibrator (TFC) module, ensuring\nconsistent temporal focus of visual tokens to video elements across every video\nframe. Through extensive experiments on multiple video MLLM frameworks, we\ndemonstrate that DisCo remarkably outperforms previous state-of-the-art methods\nacross a variety of video understanding benchmarks, while also achieving higher\ntoken efficiency thanks to the reduction of semantic indistinctness. The code:\nhttps://github.com/ZJHTerry18/DisCo.", "published": "2025-07-14 14:05:19", "link": "http://arxiv.org/abs/2507.10302v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Show and Polish: Reference-Guided Identity Preservation in Face Video Restoration", "abstract": "Face Video Restoration (FVR) aims to recover high-quality face videos from\ndegraded versions. Traditional methods struggle to preserve fine-grained,\nidentity-specific features when degradation is severe, often producing\naverage-looking faces that lack individual characteristics. To address these\nchallenges, we introduce IP-FVR, a novel method that leverages a high-quality\nreference face image as a visual prompt to provide identity conditioning during\nthe denoising process. IP-FVR incorporates semantically rich identity\ninformation from the reference image using decoupled cross-attention\nmechanisms, ensuring detailed and identity consistent results. For intra-clip\nidentity drift (within 24 frames), we introduce an identity-preserving feedback\nlearning method that combines cosine similarity-based reward signals with\nsuffix-weighted temporal aggregation. This approach effectively minimizes drift\nwithin sequences of frames. For inter-clip identity drift, we develop an\nexponential blending strategy that aligns identities across clips by\niteratively blending frames from previous clips during the denoising process.\nThis method ensures consistent identity representation across different clips.\nAdditionally, we enhance the restoration process with a multi-stream negative\nprompt, guiding the model's attention to relevant facial attributes and\nminimizing the generation of low-quality or incorrect features. Extensive\nexperiments on both synthetic and real-world datasets demonstrate that IP-FVR\noutperforms existing methods in both quality and identity preservation,\nshowcasing its substantial potential for practical applications in face video\nrestoration.", "published": "2025-07-14 14:01:37", "link": "http://arxiv.org/abs/2507.10293v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FTCFormer: Fuzzy Token Clustering Transformer for Image Classification", "abstract": "Transformer-based deep neural networks have achieved remarkable success\nacross various computer vision tasks, largely attributed to their long-range\nself-attention mechanism and scalability. However, most transformer\narchitectures embed images into uniform, grid-based vision tokens, neglecting\nthe underlying semantic meanings of image regions, resulting in suboptimal\nfeature representations. To address this issue, we propose Fuzzy Token\nClustering Transformer (FTCFormer), which incorporates a novel clustering-based\ndownsampling module to dynamically generate vision tokens based on the semantic\nmeanings instead of spatial positions. It allocates fewer tokens to less\ninformative regions and more to represent semantically important regions,\nregardless of their spatial adjacency or shape irregularity. To further enhance\nfeature extraction and representation, we propose a Density Peak\nClustering-Fuzzy K-Nearest Neighbor (DPC-FKNN) mechanism for clustering center\ndetermination, a Spatial Connectivity Score (SCS) for token assignment, and a\nchannel-wise merging (Cmerge) strategy for token merging. Extensive experiments\non 32 datasets across diverse domains validate the effectiveness of FTCFormer\non image classification, showing consistent improvements over the TCFormer\nbaseline, achieving gains of improving 1.43% on five fine-grained datasets,\n1.09% on six natural image datasets, 0.97% on three medical datasets and 0.55%\non four remote sensing datasets. The code is available at:\nhttps://github.com/BaoBao0926/FTCFormer/tree/main.", "published": "2025-07-14 13:49:47", "link": "http://arxiv.org/abs/2507.10283v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Kaleidoscopic Background Attack: Disrupting Pose Estimation with Multi-Fold Radial Symmetry Textures", "abstract": "Camera pose estimation is a fundamental computer vision task that is\nessential for applications like visual localization and multi-view stereo\nreconstruction. In the object-centric scenarios with sparse inputs, the\naccuracy of pose estimation can be significantly influenced by background\ntextures that occupy major portions of the images across different viewpoints.\nIn light of this, we introduce the Kaleidoscopic Background Attack (KBA), which\nuses identical segments to form discs with multi-fold radial symmetry. These\ndiscs maintain high similarity across different viewpoints, enabling effective\nattacks on pose estimation models even with natural texture segments.\nAdditionally, a projected orientation consistency loss is proposed to optimize\nthe kaleidoscopic segments, leading to significant enhancement in the attack\neffectiveness. Experimental results show that optimized adversarial\nkaleidoscopic backgrounds can effectively attack various camera pose estimation\nmodels.", "published": "2025-07-14 13:37:31", "link": "http://arxiv.org/abs/2507.10265v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Transferring Styles for Reduced Texture Bias and Improved Robustness in Semantic Segmentation Networks", "abstract": "Recent research has investigated the shape and texture biases of deep neural\nnetworks (DNNs) in image classification which influence their generalization\ncapabilities and robustness. It has been shown that, in comparison to regular\nDNN training, training with stylized images reduces texture biases in image\nclassification and improves robustness with respect to image corruptions. In an\neffort to advance this line of research, we examine whether style transfer can\nlikewise deliver these two effects in semantic segmentation. To this end, we\nperform style transfer with style varying across artificial image areas. Those\nrandom areas are formed by a chosen number of Voronoi cells. The resulting\nstyle-transferred data is then used to train semantic segmentation DNNs with\nthe objective of reducing their dependence on texture cues while enhancing\ntheir reliance on shape-based features. In our experiments, it turns out that\nin semantic segmentation, style transfer augmentation reduces texture bias and\nstrongly increases robustness with respect to common image corruptions as well\nas adversarial attacks. These observations hold for convolutional neural\nnetworks and transformer architectures on the Cityscapes dataset as well as on\nPASCAL Context, showing the generality of the proposed method.", "published": "2025-07-14 13:02:19", "link": "http://arxiv.org/abs/2507.10239v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Navigating the Challenges of AI-Generated Image Detection in the Wild: What Truly Matters?", "abstract": "The rapid advancement of generative technologies presents both unprecedented\ncreative opportunities and significant challenges, particularly in maintaining\nsocial trust and ensuring the integrity of digital information. Following these\nconcerns, the challenge of AI-Generated Image Detection (AID) becomes\nincreasingly critical. As these technologies become more sophisticated, the\nquality of AI-generated images has reached a level that can easily deceive even\nthe most discerning observers. Our systematic evaluation highlights a critical\nweakness in current AI-Generated Image Detection models: while they perform\nexceptionally well on controlled benchmark datasets, they struggle\nsignificantly with real-world variations. To assess this, we introduce ITW-SM,\na new dataset of real and AI-generated images collected from major social media\nplatforms. In this paper, we identify four key factors that influence AID\nperformance in real-world scenarios: backbone architecture, training data\ncomposition, pre-processing strategies and data augmentation combinations. By\nsystematically analyzing these components, we shed light on their impact on\ndetection efficacy. Our modifications result in an average AUC improvement of\n26.87% across various AID models under real-world conditions.", "published": "2025-07-14 12:56:55", "link": "http://arxiv.org/abs/2507.10236v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Synthesizing Near-Boundary OOD Samples for Out-of-Distribution Detection", "abstract": "Pre-trained vision-language models have exhibited remarkable abilities in\ndetecting out-of-distribution (OOD) samples. However, some challenging OOD\nsamples, which lie close to in-distribution (InD) data in image feature space,\ncan still lead to misclassification. The emergence of foundation models like\ndiffusion models and multimodal large language models (MLLMs) offers a\npotential solution to this issue. In this work, we propose SynOOD, a novel\napproach that harnesses foundation models to generate synthetic, challenging\nOOD data for fine-tuning CLIP models, thereby enhancing boundary-level\ndiscrimination between InD and OOD samples. Our method uses an iterative\nin-painting process guided by contextual prompts from MLLMs to produce nuanced,\nboundary-aligned OOD samples. These samples are refined through noise\nadjustments based on gradients from OOD scores like the energy score,\neffectively sampling from the InD/OOD boundary. With these carefully\nsynthesized images, we fine-tune the CLIP image encoder and negative label\nfeatures derived from the text encoder to strengthen connections between\nnear-boundary OOD samples and a set of negative labels. Finally, SynOOD\nachieves state-of-the-art performance on the large-scale ImageNet benchmark,\nwith minimal increases in parameters and runtime. Our approach significantly\nsurpasses existing methods, improving AUROC by 2.80% and reducing FPR95 by\n11.13%. Codes are available in https://github.com/Jarvisgivemeasuit/SynOOD.", "published": "2025-07-14 12:43:50", "link": "http://arxiv.org/abs/2507.10225v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Spatial Lifting for Dense Prediction", "abstract": "We present Spatial Lifting (SL), a novel methodology for dense prediction\ntasks. SL operates by lifting standard inputs, such as 2D images, into a\nhigher-dimensional space and subsequently processing them using networks\ndesigned for that higher dimension, such as a 3D U-Net. Counterintuitively,\nthis dimensionality lifting allows us to achieve good performance on benchmark\ntasks compared to conventional approaches, while reducing inference costs and\nsignificantly lowering the number of model parameters. The SL framework\nproduces intrinsically structured outputs along the lifted dimension. This\nemergent structure facilitates dense supervision during training and enables\nrobust, near-zero-additional-cost prediction quality assessment at test time.\nWe validate our approach across 19 benchmark datasets (13 for semantic\nsegmentation and 6 for depth estimation), demonstrating competitive dense\nprediction performance while reducing the model parameter count by over 98% (in\nthe U-Net case) and lowering inference costs. Spatial Lifting introduces a new\nvision modeling paradigm that offers a promising path toward more efficient,\naccurate, and reliable deep networks for dense prediction tasks in vision.", "published": "2025-07-14 12:39:07", "link": "http://arxiv.org/abs/2507.10222v1", "categories": ["cs.CV", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Straighten Viscous Rectified Flow via Noise Optimization", "abstract": "The Reflow operation aims to straighten the inference trajectories of the\nrectified flow during training by constructing deterministic couplings between\nnoises and images, thereby improving the quality of generated images in\nsingle-step or few-step generation. However, we identify critical limitations\nin Reflow, particularly its inability to rapidly generate high-quality images\ndue to a distribution gap between images in its constructed deterministic\ncouplings and real images. To address these shortcomings, we propose a novel\nalternative called Straighten Viscous Rectified Flow via Noise Optimization\n(VRFNO), which is a joint training framework integrating an encoder and a\nneural velocity field. VRFNO introduces two key innovations: (1) a historical\nvelocity term that enhances trajectory distinction, enabling the model to more\naccurately predict the velocity of the current trajectory, and (2) the noise\noptimization through reparameterization to form optimized couplings with real\nimages which are then utilized for training, effectively mitigating errors\ncaused by Reflow's limitations. Comprehensive experiments on synthetic data and\nreal datasets with varying resolutions show that VRFNO significantly mitigates\nthe limitations of Reflow, achieving state-of-the-art performance in both\none-step and few-step generation tasks.", "published": "2025-07-14 12:35:17", "link": "http://arxiv.org/abs/2507.10218v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Wardrobe to Canvas: Wardrobe Polyptych LoRA for Part-level Controllable Human Image Generation", "abstract": "Recent diffusion models achieve personalization by learning specific\nsubjects, allowing learned attributes to be integrated into generated images.\nHowever, personalized human image generation remains challenging due to the\nneed for precise and consistent attribute preservation (e.g., identity,\nclothing details). Existing subject-driven image generation methods often\nrequire either (1) inference-time fine-tuning with few images for each new\nsubject or (2) large-scale dataset training for generalization. Both approaches\nare computationally expensive and impractical for real-time applications. To\naddress these limitations, we present Wardrobe Polyptych LoRA, a novel\npart-level controllable model for personalized human image generation. By\ntraining only LoRA layers, our method removes the computational burden at\ninference while ensuring high-fidelity synthesis of unseen subjects. Our key\nidea is to condition the generation on the subject's wardrobe and leverage\nspatial references to reduce information loss, thereby improving fidelity and\nconsistency. Additionally, we introduce a selective subject region loss, which\nencourages the model to disregard some of reference images during training. Our\nloss ensures that generated images better align with text prompts while\nmaintaining subject integrity. Notably, our Wardrobe Polyptych LoRA requires no\nadditional parameters at the inference stage and performs generation using a\nsingle model trained on a few training samples. We construct a new dataset and\nbenchmark tailored for personalized human image generation. Extensive\nexperiments show that our approach significantly outperforms existing\ntechniques in fidelity and consistency, enabling realistic and\nidentity-preserving full-body synthesis.", "published": "2025-07-14 12:34:25", "link": "http://arxiv.org/abs/2507.10217v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Boosting Multimodal Learning via Disentangled Gradient Learning", "abstract": "Multimodal learning often encounters the under-optimized problem and may have\nworse performance than unimodal learning. Existing methods attribute this\nproblem to the imbalanced learning between modalities and rebalance them\nthrough gradient modulation. However, they fail to explain why the dominant\nmodality in multimodal models also underperforms that in unimodal learning. In\nthis work, we reveal the optimization conflict between the modality encoder and\nmodality fusion module in multimodal models. Specifically, we prove that the\ncross-modal fusion in multimodal models decreases the gradient passed back to\neach modality encoder compared with unimodal models. Consequently, the\nperformance of each modality in the multimodal model is inferior to that in the\nunimodal model. To this end, we propose a disentangled gradient learning (DGL)\nframework to decouple the optimization of the modality encoder and modality\nfusion module in the multimodal model. DGL truncates the gradient\nback-propagated from the multimodal loss to the modality encoder and replaces\nit with the gradient from unimodal loss. Besides, DGL removes the gradient\nback-propagated from the unimodal loss to the modality fusion module. This\nhelps eliminate the gradient interference between the modality encoder and\nmodality fusion module while ensuring their respective optimization processes.\nFinally, extensive experiments on multiple types of modalities, tasks, and\nframeworks with dense cross-modal interaction demonstrate the effectiveness and\nversatility of the proposed DGL. Code is available at\n\\href{https://github.com/shicaiwei123/ICCV2025-GDL}{https://github.com/shicaiwei123/ICCV2025-GDL}", "published": "2025-07-14 12:31:28", "link": "http://arxiv.org/abs/2507.10213v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Is Micro-expression Ethnic Leaning?", "abstract": "How much does ethnicity play its part in emotional expression? Emotional\nexpression and micro-expression research probe into understanding human\npsychological responses to emotional stimuli, thereby revealing substantial\nhidden yet authentic emotions that can be useful in the event of diagnosis and\ninterviews. While increased attention had been provided to micro-expression\nanalysis, the studies were done under Ekman's assumption of emotion\nuniversality, where emotional expressions are identical across cultures and\nsocial contexts. Our computational study uncovers some of the influences of\nethnic background in expression analysis, leading to an argument that the\nemotional universality hypothesis is an overgeneralization from the perspective\nof manual psychological analysis. In this research, we propose to investigate\nthe level of influence of ethnicity in a simulated micro-expression scenario.\nWe construct a cross-cultural micro-expression database and algorithmically\nannotate the ethnic labels to facilitate the investigation. With the ethnically\nannotated dataset, we perform a prima facie study to compare mono-ethnicity and\nstereo-ethnicity in a controlled environment, which uncovers a certain\ninfluence of ethnic bias via an experimental way. Building on this finding, we\npropose a framework that integrates ethnic context into the emotional feature\nlearning process, yielding an ethnically aware framework that recognises\nethnicity differences in micro-expression recognition. For improved\nunderstanding, qualitative analyses have been done to solidify the preliminary\ninvestigation into this new realm of research. Code is publicly available at\nhttps://github.com/IcedDoggie/ICMEW2025_EthnicMER", "published": "2025-07-14 12:27:09", "link": "http://arxiv.org/abs/2507.10209v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Improving Multimodal Learning via Imbalanced Learning", "abstract": "Multimodal learning often encounters the under-optimized problem and may\nperform worse than unimodal learning. Existing approaches attribute this issue\nto imbalanced learning across modalities and tend to address it through\ngradient balancing. However, this paper argues that balanced learning is not\nthe optimal setting for multimodal learning. With bias-variance analysis, we\nprove that imbalanced dependency on each modality obeying the inverse ratio of\ntheir variances contributes to optimal performance. To this end, we propose the\nAsymmetric Representation Learning(ARL) strategy to assist multimodal learning\nvia imbalanced optimization. ARL introduces auxiliary regularizers for each\nmodality encoder to calculate their prediction variance. ARL then calculates\ncoefficients via the unimodal variance to re-weight the optimization of each\nmodality, forcing the modality dependence ratio to be inversely proportional to\nthe modality variance ratio. Moreover, to minimize the generalization error,\nARL further introduces the prediction bias of each modality and jointly\noptimizes them with multimodal loss. Notably, all auxiliary regularizers share\nparameters with the multimodal model and rely only on the modality\nrepresentation. Thus the proposed ARL strategy introduces no extra parameters\nand is independent of the structures and fusion methods of the multimodal\nmodel. Finally, extensive experiments on various datasets validate the\neffectiveness and versatility of ARL. Code is available at\n\\href{https://github.com/shicaiwei123/ICCV2025-ARL}{https://github.com/shicaiwei123/ICCV2025-ARL}", "published": "2025-07-14 12:14:57", "link": "http://arxiv.org/abs/2507.10203v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Minimizing the Pretraining Gap: Domain-aligned Text-Based Person Retrieval", "abstract": "In this work, we focus on text-based person retrieval, which aims to identify\nindividuals based on textual descriptions. Given the significant privacy issues\nand the high cost associated with manual annotation, synthetic data has become\na popular choice for pretraining models, leading to notable advancements.\nHowever, the considerable domain gap between synthetic pretraining datasets and\nreal-world target datasets, characterized by differences in lighting, color,\nand viewpoint, remains a critical obstacle that hinders the effectiveness of\nthe pretrain-finetune paradigm. To bridge this gap, we introduce a unified\ntext-based person retrieval pipeline considering domain adaptation at both\nimage and region levels. In particular, it contains two primary components,\ni.e., Domain-aware Diffusion (DaD) for image-level adaptation and\nMulti-granularity Relation Alignment (MRA) for region-level adaptation. As the\nname implies, Domain-aware Diffusion is to migrate the distribution of images\nfrom the pretraining dataset domain to the target real-world dataset domain,\ne.g., CUHK-PEDES. Subsequently, MRA performs a meticulous region-level\nalignment by establishing correspondences between visual regions and their\ndescriptive sentences, thereby addressing disparities at a finer granularity.\nExtensive experiments show that our dual-level adaptation method has achieved\nstate-of-the-art results on the CUHK-PEDES, ICFG-PEDES, and RSTPReid datasets,\noutperforming existing methodologies. The dataset, model, and code are\navailable at https://github.com/Shuyu-XJTU/MRA.", "published": "2025-07-14 12:03:04", "link": "http://arxiv.org/abs/2507.10195v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SlumpGuard: An AI-Powered Real-Time System for Automated Concrete Slump Prediction via Video Analysis", "abstract": "Concrete workability is essential for construction quality, with the slump\ntest being the most common on-site method for its assessment. However,\ntraditional slump testing is manual, time-consuming, and prone to\ninconsistency, limiting its applicability for real-time monitoring. To address\nthese challenges, we propose SlumpGuard, an AI-powered, video-based system that\nautomatically analyzes concrete flow from the truck chute to assess workability\nin real time. Our system enables full-batch inspection without manual\nintervention, improving both the accuracy and efficiency of quality control. We\npresent the system design, a the construction of a dedicated dataset, and\nempirical results from real-world deployment, demonstrating the effectiveness\nof SlumpGuard as a practical solution for modern concrete quality assurance.", "published": "2025-07-14 11:33:47", "link": "http://arxiv.org/abs/2507.10171v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Deep Recurrence for Dynamical Segmentation Models", "abstract": "While biological vision systems rely heavily on feedback connections to\niteratively refine perception, most artificial neural networks remain purely\nfeedforward, processing input in a single static pass. In this work, we propose\na predictive coding inspired feedback mechanism that introduces a recurrent\nloop from output to input, allowing the model to refine its internal state over\ntime. We implement this mechanism within a standard U-Net architecture and\nintroduce two biologically motivated operations, softmax projection and\nexponential decay, to ensure stability of the feedback loop. Through controlled\nexperiments on a synthetic segmentation task, we show that the feedback model\nsignificantly outperforms its feedforward counterpart in noisy conditions and\ngeneralizes more effectively with limited supervision. Notably, feedback\nachieves above random performance with just two training examples, while the\nfeedforward model requires at least four. Our findings demonstrate that\nfeedback enhances robustness and data efficiency, and offer a path toward more\nadaptive and biologically inspired neural architectures. Code is available at:\ngithub.com/DCalhas/feedback_segmentation.", "published": "2025-07-14 10:41:07", "link": "http://arxiv.org/abs/2507.10143v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Probabilistic Human Intent Prediction for Mobile Manipulation: An Evaluation with Human-Inspired Constraints", "abstract": "Accurate inference of human intent enables human-robot collaboration without\nconstraining human control or causing conflicts between humans and robots. We\npresent GUIDER (Global User Intent Dual-phase Estimation for Robots), a\nprobabilistic framework that enables a robot to estimate the intent of human\noperators. GUIDER maintains two coupled belief layers, one tracking navigation\ngoals and the other manipulation goals. In the Navigation phase, a Synergy Map\nblends controller velocity with an occupancy grid to rank interaction areas.\nUpon arrival at a goal, an autonomous multi-view scan builds a local 3D cloud.\nThe Manipulation phase combines U2Net saliency, FastSAM instance saliency, and\nthree geometric grasp-feasibility tests, with an end-effector kinematics-aware\nupdate rule that evolves object probabilities in real-time. GUIDER can\nrecognize areas and objects of intent without predefined goals. We evaluated\nGUIDER on 25 trials (five participants x five task variants) in Isaac Sim, and\ncompared it with two baselines, one for navigation and one for manipulation.\nAcross the 25 trials, GUIDER achieved a median stability of 93-100% during\nnavigation, compared with 60-100% for the BOIR baseline, with an improvement of\n39.5% in a redirection scenario (T5). During manipulation, stability reached\n94-100% (versus 69-100% for Trajectron), with a 31.4% difference in a\nredirection task (T3). In geometry-constrained trials (manipulation), GUIDER\nrecognized the object intent three times earlier than Trajectron (median\nremaining time to confident prediction 23.6 s vs 7.8 s). These results validate\nour dual-phase framework and show improvements in intent inference in both\nphases of mobile manipulation tasks.", "published": "2025-07-14 10:21:27", "link": "http://arxiv.org/abs/2507.10131v1", "categories": ["cs.RO", "cs.CV", "cs.HC"], "primary_category": "cs.RO"}
{"title": "DEARLi: Decoupled Enhancement of Recognition and Localization for Semi-supervised Panoptic Segmentation", "abstract": "Pixel-level annotation is expensive and time-consuming. Semi-supervised\nsegmentation methods address this challenge by learning models on few labeled\nimages alongside a large corpus of unlabeled images. Although foundation models\ncould further account for label scarcity, effective mechanisms for their\nexploitation remain underexplored. We address this by devising a novel\nsemi-supervised panoptic approach fueled by two dedicated foundation models. We\nenhance recognition by complementing unsupervised mask-transformer consistency\nwith zero-shot classification of CLIP features. We enhance localization by\nclass-agnostic decoder warm-up with respect to SAM pseudo-labels. The resulting\ndecoupled enhancement of recognition and localization (DEARLi) particularly\nexcels in the most challenging semi-supervised scenarios with large taxonomies\nand limited labeled data. Moreover, DEARLi outperforms the state of the art in\nsemi-supervised semantic segmentation by a large margin while requiring 8x less\nGPU memory, in spite of being trained only for the panoptic objective. We\nobserve 29.9 PQ and 38.9 mIoU on ADE20K with only 158 labeled images. The\nsource code is available at https://github.com/helen1c/DEARLi.", "published": "2025-07-14 10:01:02", "link": "http://arxiv.org/abs/2507.10118v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Glance-MCMT: A General MCMT Framework with Glance Initialization and Progressive Association", "abstract": "We propose a multi-camera multi-target (MCMT) tracking framework that ensures\nconsistent global identity assignment across views using trajectory and\nappearance cues. The pipeline starts with BoT-SORT-based single-camera\ntracking, followed by an initial glance phase to initialize global IDs via\ntrajectory-feature matching. In later frames, new tracklets are matched to\nexisting global identities through a prioritized global matching strategy. New\nglobal IDs are only introduced when no sufficiently similar trajectory or\nfeature match is found. 3D positions are estimated using depth maps and\ncalibration for spatial validation.", "published": "2025-07-14 09:57:53", "link": "http://arxiv.org/abs/2507.10115v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FIX-CLIP: Dual-Branch Hierarchical Contrastive Learning via Synthetic Captions for Better Understanding of Long Text", "abstract": "CLIP has shown promising performance across many short-text tasks in a\nzero-shot manner. However, limited by the input length of the text encoder,\nCLIP struggles on under-stream tasks with long-text inputs (>77 tokens). To\nremedy this issue, we propose FIX-CLIP which includes three novel modules: (1)\nA dual-branch training pipeline that aligns short and long texts with masked\nand raw images respectively, which boosts the long-text representation while\npreserving the short-text ability. (2) Multiple learnable regional prompts with\nunidirectional masks in Transformer layers for regional information extraction.\n(3) A hierarchical feature alignment module in the intermediate encoder layers\nto promote the consistency of multi-scale features. Furthermore, we collect 30M\nimages and utilize existing MLLMs to synthesize long-text captions for\ntraining. Extensive experiments show that FIX-CLIP achieves state-of-the-art\nperformance on both long-text and short-text retrieval benchmarks. For\ndownstream applications, we reveal that FIX-CLIP's text encoder delivers\npromising performance in a plug-and-play manner for diffusion models with\nlong-text input.", "published": "2025-07-14 09:31:34", "link": "http://arxiv.org/abs/2507.10095v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Transfer Learning-Based Method for Water Body Segmentation in Remote Sensing Imagery: A Case Study of the Zhada Tulin Area", "abstract": "To address the prevalent challenges of domain shift and small sample sizes in\nremote sensing image water body segmentation, this study proposes and validates\na two-stage transfer learning strategy based on the SegFormer model. The\napproach begins by training a foundational segmentation model on a diverse\nsource domain, where it achieves an Intersection over Union (IoU) of 68.80% on\nits validation set, followed by fine-tuning on data from the distinct target\ndomain. Focusing on the Zhada Tulin area in Tibet -- a region characterized by\nhighly complex topography and spectral features -- the experimental results\ndemonstrate that this strategy significantly boosts the IoU for the water body\nsegmentation task from 25.50% (for direct transfer) to 64.84%. This not only\neffectively resolves the model performance degradation caused by domain\ndiscrepancy but also provides an effective technical paradigm for\nhigh-precision thematic information extraction in data-scarce and\nenvironmentally unique remote sensing scenarios.", "published": "2025-07-14 09:11:33", "link": "http://arxiv.org/abs/2507.10084v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Frequency Regulation for Exposure Bias Mitigation in Diffusion Models", "abstract": "Diffusion models exhibit impressive generative capabilities but are\nsignificantly impacted by exposure bias. In this paper, we make a key\nobservation: the energy of the predicted noisy images decreases during the\ndiffusion process. Building on this, we identify two important findings: 1) The\nreduction in energy follows distinct patterns in the low-frequency and\nhigh-frequency subbands; 2) This energy reduction results in amplitude\nvariations between the network-reconstructed clean data and the real clean\ndata. Based on the first finding, we introduce a frequency-domain regulation\nmechanism utilizing wavelet transforms, which separately adjusts the low- and\nhigh-frequency subbands. Leveraging the second insight, we provide a more\naccurate analysis of exposure bias in the two subbands. Our method is\ntraining-free and plug-and-play, significantly improving the generative quality\nof various diffusion models and providing a robust solution to exposure bias\nacross different model architectures. The source code is available at\nhttps://github.com/kunzhan/wpp.", "published": "2025-07-14 08:58:38", "link": "http://arxiv.org/abs/2507.10072v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LayLens: Improving Deepfake Understanding through Simplified Explanations", "abstract": "This demonstration paper presents $\\mathbf{LayLens}$, a tool aimed to make\ndeepfake understanding easier for users of all educational backgrounds. While\nprior works often rely on outputs containing technical jargon, LayLens bridges\nthe gap between model reasoning and human understanding through a three-stage\npipeline: (1) explainable deepfake detection using a state-of-the-art forgery\nlocalization model, (2) natural language simplification of technical\nexplanations using a vision-language model, and (3) visual reconstruction of a\nplausible original image via guided image editing. The interface presents both\ntechnical and layperson-friendly explanations in addition to a side-by-side\ncomparison of the uploaded and reconstructed images. A user study with 15\nparticipants shows that simplified explanations significantly improve clarity\nand reduce cognitive load, with most users expressing increased confidence in\nidentifying deepfakes. LayLens offers a step toward transparent, trustworthy,\nand user-centric deepfake forensics.", "published": "2025-07-14 08:52:03", "link": "http://arxiv.org/abs/2507.10066v1", "categories": ["cs.MM", "cs.CV"], "primary_category": "cs.MM"}
{"title": "MoVieS: Motion-Aware 4D Dynamic View Synthesis in One Second", "abstract": "We present MoVieS, a novel feed-forward model that synthesizes 4D dynamic\nnovel views from monocular videos in one second. MoVieS represents dynamic 3D\nscenes using pixel-aligned grids of Gaussian primitives, explicitly supervising\ntheir time-varying motion. This allows, for the first time, the unified\nmodeling of appearance, geometry and motion, and enables view synthesis,\nreconstruction and 3D point tracking within a single learning-based framework.\nBy bridging novel view synthesis with dynamic geometry reconstruction, MoVieS\nenables large-scale training on diverse datasets with minimal dependence on\ntask-specific supervision. As a result, it also naturally supports a wide range\nof zero-shot applications, such as scene flow estimation and moving object\nsegmentation. Extensive experiments validate the effectiveness and efficiency\nof MoVieS across multiple tasks, achieving competitive performance while\noffering several orders of magnitude speedups.", "published": "2025-07-14 08:49:57", "link": "http://arxiv.org/abs/2507.10065v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CoSMo: A Multimodal Transformer for Page Stream Segmentation in Comic Books", "abstract": "This paper introduces CoSMo, a novel multimodal Transformer for Page Stream\nSegmentation (PSS) in comic books, a critical task for automated content\nunderstanding, as it is a necessary first stage for many downstream tasks like\ncharacter analysis, story indexing, or metadata enrichment. We formalize PSS\nfor this unique medium and curate a new 20,800-page annotated dataset. CoSMo,\ndeveloped in vision-only and multimodal variants, consistently outperforms\ntraditional baselines and significantly larger general-purpose vision-language\nmodels across F1-Macro, Panoptic Quality, and stream-level metrics. Our\nfindings highlight the dominance of visual features for comic PSS\nmacro-structure, yet demonstrate multimodal benefits in resolving challenging\nambiguities. CoSMo establishes a new state-of-the-art, paving the way for\nscalable comic book analysis.", "published": "2025-07-14 08:35:37", "link": "http://arxiv.org/abs/2507.10053v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LifelongPR: Lifelong knowledge fusion for point cloud place recognition based on replay and prompt learning", "abstract": "Point cloud place recognition (PCPR) plays a crucial role in photogrammetry\nand robotics applications such as autonomous driving, intelligent\ntransportation, and augmented reality. In real-world large-scale deployments of\na positioning system, PCPR models must continuously acquire, update, and\naccumulate knowledge to adapt to diverse and dynamic environments, i.e., the\nability known as continual learning (CL). However, existing PCPR models often\nsuffer from catastrophic forgetting, leading to significant performance\ndegradation in previously learned scenes when adapting to new environments or\nsensor types. This results in poor model scalability, increased maintenance\ncosts, and system deployment difficulties, undermining the practicality of\nPCPR. To address these issues, we propose LifelongPR, a novel continual\nlearning framework for PCPR, which effectively extracts and fuses knowledge\nfrom sequential point cloud data. First, to alleviate the knowledge loss, we\npropose a replay sample selection method that dynamically allocates sample\nsizes according to each dataset's information quantity and selects spatially\ndiverse samples for maximal representativeness. Second, to handle domain\nshifts, we design a prompt learning-based CL framework with a lightweight\nprompt module and a two-stage training strategy, enabling domain-specific\nfeature adaptation while minimizing forgetting. Comprehensive experiments on\nlarge-scale public and self-collected datasets are conducted to validate the\neffectiveness of the proposed method. Compared with state-of-the-art (SOTA)\nmethods, our method achieves 6.50% improvement in mIR@1, 7.96% improvement in\nmR@1, and an 8.95% reduction in F. The code and pre-trained models are publicly\navailable at https://github.com/zouxianghong/LifelongPR.", "published": "2025-07-14 08:13:33", "link": "http://arxiv.org/abs/2507.10034v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Memory-Efficient Personalization of Text-to-Image Diffusion Models via Selective Optimization Strategies", "abstract": "Memory-efficient personalization is critical for adapting text-to-image\ndiffusion models while preserving user privacy and operating within the limited\ncomputational resources of edge devices. To this end, we propose a selective\noptimization framework that adaptively chooses between backpropagation on\nlow-resolution images (BP-low) and zeroth-order optimization on high-resolution\nimages (ZO-high), guided by the characteristics of the diffusion process. As\nobserved in our experiments, BP-low efficiently adapts the model to\ntarget-specific features, but suffers from structural distortions due to\nresolution mismatch. Conversely, ZO-high refines high-resolution details with\nminimal memory overhead but faces slow convergence when applied without prior\nadaptation. By complementing both methods, our framework leverages BP-low for\neffective personalization while using ZO-high to maintain structural\nconsistency, achieving memory-efficient and high-quality fine-tuning. To\nmaximize the efficacy of both BP-low and ZO-high, we introduce a timestep-aware\nprobabilistic function that dynamically selects the appropriate optimization\nstrategy based on diffusion timesteps. This function mitigates the overfitting\nfrom BP-low at high timesteps, where structural information is critical, while\nensuring ZO-high is applied more effectively as training progresses.\nExperimental results demonstrate that our method achieves competitive\nperformance while significantly reducing memory consumption, enabling scalable,\nhigh-quality on-device personalization without increasing inference latency.", "published": "2025-07-14 08:08:55", "link": "http://arxiv.org/abs/2507.10029v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Binomial Self-Compensation: Mechanism and Suppression of Motion Error in Phase-Shifting Profilometry", "abstract": "Phase shifting profilometry (PSP) is widely used in high-precision 3D\nscanning due to its high accuracy, robustness, and pixel-wise handling.\nHowever, a fundamental assumption of PSP that the object should remain static\ndoes not hold in dynamic measurement, making PSP susceptible to object motion.\nTo address this challenge, our proposed solution, phase-sequential binomial\nself-compensation (P-BSC), sums successive motion-affected phase frames\nweighted by binomial coefficients. This approach exponentially reduces the\nmotion error in a pixel-wise and frame-wise loopable manner. Despite its\nefficacy, P-BSC suffers from high computational overhead and error accumulation\ndue to its reliance on multi-frame phase calculations and weighted summations.\nInspired by P-BSC, we propose an image-sequential binomial self-compensation\n(I-BSC) to weight sum the homogeneous fringe images instead of successive phase\nframes, which generalizes the BSC concept from phase sequences to image\nsequences. I-BSC computes the arctangent function only once, resolving both\nlimitations in P-BSC. Extensive analysis, simulations, and experiments show\nthat 1) the proposed BSC outperforms existing methods in reducing motion error\nwhile achieving a quasi-single-shot frame rate, i.e., depth map frame rate\nequals to the camera's acquisition rate, enabling 3D reconstruction with high\npixel-depth-temporal resolution; 2) compared to P-BSC, our I-BSC reduces the\ncomputational complexity by one polynomial order, thereby accelerating the\ncomputational frame rate by several to dozen times, while also reaching faster\nmotion error convergence.", "published": "2025-07-14 07:41:56", "link": "http://arxiv.org/abs/2507.10009v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Vision-Based Anti Unmanned Aerial Technology: Opportunities and Challenges", "abstract": "With the rapid advancement of UAV technology and its extensive application in\nvarious fields such as military reconnaissance, environmental monitoring, and\nlogistics, achieving efficient and accurate Anti-UAV tracking has become\nessential. The importance of Anti-UAV tracking is increasingly prominent,\nespecially in scenarios such as public safety, border patrol, search and\nrescue, and agricultural monitoring, where operations in complex environments\ncan provide enhanced security. Current mainstream Anti-UAV tracking\ntechnologies are primarily centered around computer vision techniques,\nparticularly those that integrate multi-sensor data fusion with advanced\ndetection and tracking algorithms. This paper first reviews the characteristics\nand current challenges of Anti-UAV detection and tracking technologies. Next,\nit investigates and compiles several publicly available datasets, providing\naccessible links to support researchers in efficiently addressing related\nchallenges. Furthermore, the paper analyzes the major vision-based and\nvision-fusion-based Anti-UAV detection and tracking algorithms proposed in\nrecent years. Finally, based on the above research, this paper outlines future\nresearch directions, aiming to provide valuable insights for advancing the\nfield.", "published": "2025-07-14 07:39:55", "link": "http://arxiv.org/abs/2507.10006v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Leveraging Swin Transformer for enhanced diagnosis of Alzheimer's disease using multi-shell diffusion MRI", "abstract": "Objective: This study aims to support early diagnosis of Alzheimer's disease\nand detection of amyloid accumulation by leveraging the microstructural\ninformation available in multi-shell diffusion MRI (dMRI) data, using a vision\ntransformer-based deep learning framework.\n  Methods: We present a classification pipeline that employs the Swin\nTransformer, a hierarchical vision transformer model, on multi-shell dMRI data\nfor the classification of Alzheimer's disease and amyloid presence. Key metrics\nfrom DTI and NODDI were extracted and projected onto 2D planes to enable\ntransfer learning with ImageNet-pretrained models. To efficiently adapt the\ntransformer to limited labeled neuroimaging data, we integrated Low-Rank\nAdaptation. We assessed the framework on diagnostic group prediction\n(cognitively normal, mild cognitive impairment, Alzheimer's disease dementia)\nand amyloid status classification.\n  Results: The framework achieved competitive classification results within the\nscope of multi-shell dMRI-based features, with the best balanced accuracy of\n95.2% for distinguishing cognitively normal individuals from those with\nAlzheimer's disease dementia using NODDI metrics. For amyloid detection, it\nreached 77.2% balanced accuracy in distinguishing amyloid-positive mild\ncognitive impairment/Alzheimer's disease dementia subjects from\namyloid-negative cognitively normal subjects, and 67.9% for identifying\namyloid-positive individuals among cognitively normal subjects. Grad-CAM-based\nexplainability analysis identified clinically relevant brain regions, including\nthe parahippocampal gyrus and hippocampus, as key contributors to model\npredictions.\n  Conclusion: This study demonstrates the promise of diffusion MRI and\ntransformer-based architectures for early detection of Alzheimer's disease and\namyloid pathology, supporting biomarker-driven diagnostics in data-limited\nbiomedical settings.", "published": "2025-07-14 07:31:40", "link": "http://arxiv.org/abs/2507.09996v1", "categories": ["cs.CV", "q-bio.NC", "q-bio.QM"], "primary_category": "cs.CV"}
{"title": "Graph-based Multi-Modal Interaction Lightweight Network for Brain Tumor Segmentation (GMLN-BTS) in Edge Iterative MRI Lesion Localization System (EdgeIMLocSys)", "abstract": "Brain tumor segmentation plays a critical role in clinical diagnosis and\ntreatment planning, yet the variability in imaging quality across different MRI\nscanners presents significant challenges to model generalization. To address\nthis, we propose the Edge Iterative MRI Lesion Localization System\n(EdgeIMLocSys), which integrates Continuous Learning from Human Feedback to\nadaptively fine-tune segmentation models based on clinician feedback, thereby\nenhancing robustness to scanner-specific imaging characteristics. Central to\nthis system is the Graph-based Multi-Modal Interaction Lightweight Network for\nBrain Tumor Segmentation (GMLN-BTS), which employs a Modality-Aware Adaptive\nEncoder (M2AE) to extract multi-scale semantic features efficiently, and a\nGraph-based Multi-Modal Collaborative Interaction Module (G2MCIM) to model\ncomplementary cross-modal relationships via graph structures. Additionally, we\nintroduce a novel Voxel Refinement UpSampling Module (VRUM) that\nsynergistically combines linear interpolation and multi-scale transposed\nconvolutions to suppress artifacts while preserving high-frequency details,\nimproving segmentation boundary accuracy. Our proposed GMLN-BTS model achieves\na Dice score of 85.1% on the BraTS2017 dataset with only 4.58 million\nparameters, representing a 98% reduction compared to mainstream 3D Transformer\nmodels, and significantly outperforms existing lightweight approaches. This\nwork demonstrates a synergistic breakthrough in achieving high-accuracy,\nresource-efficient brain tumor segmentation suitable for deployment in\nresource-constrained clinical environments.", "published": "2025-07-14 07:29:49", "link": "http://arxiv.org/abs/2507.09995v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "3DGAA: Realistic and Robust 3D Gaussian-based Adversarial Attack for Autonomous Driving", "abstract": "Camera-based object detection systems play a vital role in autonomous\ndriving, yet they remain vulnerable to adversarial threats in real-world\nenvironments. While existing 2D and 3D physical attacks typically optimize\ntexture, they often struggle to balance physical realism and attack robustness.\nIn this work, we propose 3D Gaussian-based Adversarial Attack (3DGAA), a novel\nadversarial object generation framework that leverages the full 14-dimensional\nparameterization of 3D Gaussian Splatting (3DGS) to jointly optimize geometry\nand appearance in physically realizable ways. Unlike prior works that rely on\npatches or texture, 3DGAA jointly perturbs both geometric attributes (shape,\nscale, rotation) and appearance attributes (color, opacity) to produce\nphysically realistic and transferable adversarial objects. We further introduce\na physical filtering module to preserve geometric fidelity, and a physical\naugmentation module to simulate complex physical scenarios, thus enhancing\nattack generalization under real-world conditions. We evaluate 3DGAA on both\nvirtual benchmarks and physical-world setups using miniature vehicle models.\nExperimental results show that 3DGAA achieves to reduce the detection mAP from\n87.21% to 7.38%, significantly outperforming existing 3D physical attacks.\nMoreover, our method maintains high transferability across different physical\nconditions, demonstrating a new state-of-the-art in physically realizable\nadversarial attacks. These results validate 3DGAA as a practical attack\nframework for evaluating the safety of perception systems in autonomous\ndriving.", "published": "2025-07-14 07:27:52", "link": "http://arxiv.org/abs/2507.09993v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Latent Diffusion Models with Masked AutoEncoders", "abstract": "In spite of remarkable potential of the Latent Diffusion Models (LDMs) in\nimage generation, the desired properties and optimal design of the autoencoders\nhave been underexplored. In this work, we analyze the role of autoencoders in\nLDMs and identify three key properties: latent smoothness, perceptual\ncompression quality, and reconstruction quality. We demonstrate that existing\nautoencoders fail to simultaneously satisfy all three properties, and propose\nVariational Masked AutoEncoders (VMAEs), taking advantage of the hierarchical\nfeatures maintained by Masked AutoEncoder. We integrate VMAEs into the LDM\nframework, introducing Latent Diffusion Models with Masked AutoEncoders\n(LDMAEs). Through comprehensive experiments, we demonstrate significantly\nenhanced image generation quality and computational efficiency.", "published": "2025-07-14 07:00:43", "link": "http://arxiv.org/abs/2507.09984v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Uncertainty Quantification for Incomplete Multi-View Data Using Divergence Measures", "abstract": "Existing multi-view classification and clustering methods typically improve\ntask accuracy by leveraging and fusing information from different views.\nHowever, ensuring the reliability of multi-view integration and final decisions\nis crucial, particularly when dealing with noisy or corrupted data. Current\nmethods often rely on Kullback-Leibler (KL) divergence to estimate uncertainty\nof network predictions, ignoring domain gaps between different modalities. To\naddress this issue, KPHD-Net, based on H\\\"older divergence, is proposed for\nmulti-view classification and clustering tasks. Generally, our KPHD-Net employs\na variational Dirichlet distribution to represent class probability\ndistributions, models evidences from different views, and then integrates it\nwith Dempster-Shafer evidence theory (DST) to improve uncertainty estimation\neffects. Our theoretical analysis demonstrates that Proper H\\\"older divergence\noffers a more effective measure of distribution discrepancies, ensuring\nenhanced performance in multi-view learning. Moreover, Dempster-Shafer evidence\ntheory, recognized for its superior performance in multi-view fusion tasks, is\nintroduced and combined with the Kalman filter to provide future state\nestimations. This integration further enhances the reliability of the final\nfusion results. Extensive experiments show that the proposed KPHD-Net\noutperforms the current state-of-the-art methods in both classification and\nclustering tasks regarding accuracy, robustness, and reliability, with\ntheoretical guarantees.", "published": "2025-07-14 06:55:32", "link": "http://arxiv.org/abs/2507.09980v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "4D-MISR: A unified model for low-dose super-resolution imaging via feature fusion", "abstract": "While electron microscopy offers crucial atomic-resolution insights into\nstructure-property relationships, radiation damage severely limits its use on\nbeam-sensitive materials like proteins and 2D materials. To overcome this\nchallenge, we push beyond the electron dose limits of conventional electron\nmicroscopy by adapting principles from multi-image super-resolution (MISR) that\nhave been widely used in remote sensing. Our method fuses multiple\nlow-resolution, sub-pixel-shifted views and enhances the reconstruction with a\nconvolutional neural network (CNN) that integrates features from synthetic,\nmulti-angle observations. We developed a dual-path, attention-guided network\nfor 4D-STEM that achieves atomic-scale super-resolution from ultra-low-dose\ndata. This provides robust atomic-scale visualization across amorphous,\nsemi-crystalline, and crystalline beam-sensitive specimens. Systematic\nevaluations on representative materials demonstrate comparable spatial\nresolution to conventional ptychography under ultra-low-dose conditions. Our\nwork expands the capabilities of 4D-STEM, offering a new and generalizable\nmethod for the structural analysis of radiation-vulnerable materials.", "published": "2025-07-14 06:02:05", "link": "http://arxiv.org/abs/2507.09953v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ESG-Net: Event-Aware Semantic Guided Network for Dense Audio-Visual Event Localization", "abstract": "Dense audio-visual event localization (DAVE) aims to identify event\ncategories and locate the temporal boundaries in untrimmed videos. Most studies\nonly employ event-related semantic constraints on the final outputs, lacking\ncross-modal semantic bridging in intermediate layers. This causes modality\nsemantic gap for further fusion, making it difficult to distinguish between\nevent-related content and irrelevant background content. Moreover, they rarely\nconsider the correlations between events, which limits the model to infer\nconcurrent events among complex scenarios. In this paper, we incorporate\nmulti-stage semantic guidance and multi-event relationship modeling, which\nrespectively enable hierarchical semantic understanding of audio-visual events\nand adaptive extraction of event dependencies, thereby better focusing on\nevent-related information. Specifically, our eventaware semantic guided network\n(ESG-Net) includes a early semantics interaction (ESI) module and a mixture of\ndependency experts (MoDE) module. ESI applys multi-stage semantic guidance to\nexplicitly constrain the model in learning semantic information through\nmulti-modal early fusion and several classification loss functions, ensuring\nhierarchical understanding of event-related content. MoDE promotes the\nextraction of multi-event dependencies through multiple serial mixture of\nexperts with adaptive weight allocation. Extensive experiments demonstrate that\nour method significantly surpasses the state-of-the-art methods, while greatly\nreducing parameters and computational load. Our code will be released on\nhttps://github.com/uchiha99999/ESG-Net.", "published": "2025-07-14 05:42:00", "link": "http://arxiv.org/abs/2507.09945v1", "categories": ["cs.MM", "cs.CV"], "primary_category": "cs.MM"}
{"title": "IM-LUT: Interpolation Mixing Look-Up Tables for Image Super-Resolution", "abstract": "Super-resolution (SR) has been a pivotal task in image processing, aimed at\nenhancing image resolution across various applications. Recently, look-up table\n(LUT)-based approaches have attracted interest due to their efficiency and\nperformance. However, these methods are typically designed for fixed scale\nfactors, making them unsuitable for arbitrary-scale image SR (ASISR). Existing\nASISR techniques often employ implicit neural representations, which come with\nconsiderable computational cost and memory demands. To address these\nlimitations, we propose Interpolation Mixing LUT (IM-LUT), a novel framework\nthat operates ASISR by learning to blend multiple interpolation functions to\nmaximize their representational capacity. Specifically, we introduce IM-Net, a\nnetwork trained to predict mixing weights for interpolation functions based on\nlocal image patterns and the target scale factor. To enhance efficiency of\ninterpolation-based methods, IM-Net is transformed into IM-LUT, where LUTs are\nemployed to replace computationally expensive operations, enabling lightweight\nand fast inference on CPUs while preserving reconstruction quality.\nExperimental results on several benchmark datasets demonstrate that IM-LUT\nconsistently achieves a superior balance between image quality and efficiency\ncompared to existing methods, highlighting its potential as a promising\nsolution for resource-constrained applications.", "published": "2025-07-14 05:02:57", "link": "http://arxiv.org/abs/2507.09923v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Crucial-Diff: A Unified Diffusion Model for Crucial Image and Annotation Synthesis in Data-scarce Scenarios", "abstract": "The scarcity of data in various scenarios, such as medical, industry and\nautonomous driving, leads to model overfitting and dataset imbalance, thus\nhindering effective detection and segmentation performance. Existing studies\nemploy the generative models to synthesize more training samples to mitigate\ndata scarcity. However, these synthetic samples are repetitive or simplistic\nand fail to provide \"crucial information\" that targets the downstream model's\nweaknesses. Additionally, these methods typically require separate training for\ndifferent objects, leading to computational inefficiencies. To address these\nissues, we propose Crucial-Diff, a domain-agnostic framework designed to\nsynthesize crucial samples. Our method integrates two key modules. The Scene\nAgnostic Feature Extractor (SAFE) utilizes a unified feature extractor to\ncapture target information. The Weakness Aware Sample Miner (WASM) generates\nhard-to-detect samples using feedback from the detection results of downstream\nmodel, which is then fused with the output of SAFE module. Together, our\nCrucial-Diff framework generates diverse, high-quality training data, achieving\na pixel-level AP of 83.63% and an F1-MAX of 78.12% on MVTec. On polyp dataset,\nCrucial-Diff reaches an mIoU of 81.64% and an mDice of 87.69%. Code will be\nreleased after acceptance.", "published": "2025-07-14 04:41:38", "link": "http://arxiv.org/abs/2507.09915v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "IGD: Instructional Graphic Design with Multimodal Layer Generation", "abstract": "Graphic design visually conveys information and data by creating and\ncombining text, images and graphics. Two-stage methods that rely primarily on\nlayout generation lack creativity and intelligence, making graphic design still\nlabor-intensive. Existing diffusion-based methods generate non-editable graphic\ndesign files at image level with poor legibility in visual text rendering,\nwhich prevents them from achieving satisfactory and practical automated graphic\ndesign. In this paper, we propose Instructional Graphic Designer (IGD) to\nswiftly generate multimodal layers with editable flexibility with only natural\nlanguage instructions. IGD adopts a new paradigm that leverages parametric\nrendering and image asset generation. First, we develop a design platform and\nestablish a standardized format for multi-scenario design files, thus laying\nthe foundation for scaling up data. Second, IGD utilizes the multimodal\nunderstanding and reasoning capabilities of MLLM to accomplish attribute\nprediction, sequencing and layout of layers. It also employs a diffusion model\nto generate image content for assets. By enabling end-to-end training, IGD\narchitecturally supports scalability and extensibility in complex graphic\ndesign tasks. The superior experimental results demonstrate that IGD offers a\nnew solution for graphic design.", "published": "2025-07-14 04:31:15", "link": "http://arxiv.org/abs/2507.09910v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Measuring the Impact of Rotation Equivariance on Aerial Object Detection", "abstract": "Due to the arbitrary orientation of objects in aerial images, rotation\nequivariance is a critical property for aerial object detectors. However,\nrecent studies on rotation-equivariant aerial object detection remain scarce.\nMost detectors rely on data augmentation to enable models to learn\napproximately rotation-equivariant features. A few detectors have constructed\nrotation-equivariant networks, but due to the breaking of strict rotation\nequivariance by typical downsampling processes, these networks only achieve\napproximately rotation-equivariant backbones. Whether strict rotation\nequivariance is necessary for aerial image object detection remains an open\nquestion. In this paper, we implement a strictly rotation-equivariant backbone\nand neck network with a more advanced network structure and compare it with\napproximately rotation-equivariant networks to quantitatively measure the\nimpact of rotation equivariance on the performance of aerial image detectors.\nAdditionally, leveraging the inherently grouped nature of rotation-equivariant\nfeatures, we propose a multi-branch head network that reduces the parameter\ncount while improving detection accuracy. Based on the aforementioned\nimprovements, this study proposes the Multi-branch head rotation-equivariant\nsingle-stage Detector (MessDet), which achieves state-of-the-art performance on\nthe challenging aerial image datasets DOTA-v1.0, DOTA-v1.5 and DIOR-R with an\nexceptionally low parameter count.", "published": "2025-07-14 04:04:23", "link": "http://arxiv.org/abs/2507.09896v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MCGA: Mixture of Codebooks Hyperspectral Reconstruction via Grayscale-Aware Attention", "abstract": "Reconstructing hyperspectral images (HSI) from RGB images is a cost-effective\nsolution for various vision-based applications. However, most existing\nlearning-based hyperspectral reconstruction methods directly learn the\nRGB-to-HSI mapping using complex attention mechanisms, neglecting the inherent\nchallenge of transitioning from low-dimensional to high-dimensional\ninformation. To address this limitation, we propose a two-stage approach, MCGA,\nwhich first learns spectral patterns before estimating the mapping. In the\nfirst stage, a multi-scale VQ-VAE learns representations from heterogeneous HSI\ndatasets, extracting a Mixture of Codebooks (MoC). In the second stage, the\nRGB-to-HSI mapping is refined by querying features from the MoC to replace\nlatent HSI representations, incorporating prior knowledge rather than forcing a\ndirect high-dimensional transformation. To further enhance reconstruction\nquality, we introduce Grayscale-Aware Attention and Quantized Self-Attention,\nwhich adaptively adjust feature map intensities to meet hyperspectral\nreconstruction requirements. This physically motivated attention mechanism\nensures lightweight and efficient HSI recovery. Moreover, we propose an\nentropy-based Test-Time Adaptation strategy to improve robustness in real-world\nscenarios. Extensive experiments demonstrate that our method, MCGA, achieves\nstate-of-the-art performance. The code and models will be released at\nhttps://github.com/Fibonaccirabbit/MCGA", "published": "2025-07-14 03:46:06", "link": "http://arxiv.org/abs/2507.09885v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Counterfactual Visual Explanation via Causally-Guided Adversarial Steering", "abstract": "Recent work on counterfactual visual explanations has contributed to making\nartificial intelligence models more explainable by providing visual\nperturbation to flip the prediction. However, these approaches neglect the\ncausal relationships and the spurious correlations behind the image generation\nprocess, which often leads to unintended alterations in the counterfactual\nimages and renders the explanations with limited quality. To address this\nchallenge, we introduce a novel framework CECAS, which first leverages a\ncausally-guided adversarial method to generate counterfactual explanations. It\ninnovatively integrates a causal perspective to avoid unwanted perturbations on\nspurious factors in the counterfactuals. Extensive experiments demonstrate that\nour method outperforms existing state-of-the-art approaches across multiple\nbenchmark datasets and ultimately achieves a balanced trade-off among various\naspects of validity, sparsity, proximity, and realism.", "published": "2025-07-14 03:36:36", "link": "http://arxiv.org/abs/2507.09881v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OpenHuman4D: Open-Vocabulary 4D Human Parsing", "abstract": "Understanding dynamic 3D human representation has become increasingly\ncritical in virtual and extended reality applications. However, existing human\npart segmentation methods are constrained by reliance on closed-set datasets\nand prolonged inference times, which significantly restrict their\napplicability. In this paper, we introduce the first 4D human parsing framework\nthat simultaneously addresses these challenges by reducing the inference time\nand introducing open-vocabulary capabilities. Building upon state-of-the-art\nopen-vocabulary 3D human parsing techniques, our approach extends the support\nto 4D human-centric video with three key innovations: 1) We adopt mask-based\nvideo object tracking to efficiently establish spatial and temporal\ncorrespondences, avoiding the necessity of segmenting all frames. 2) A novel\nMask Validation module is designed to manage new target identification and\nmitigate tracking failures. 3) We propose a 4D Mask Fusion module, integrating\nmemory-conditioned attention and logits equalization for robust embedding\nfusion. Extensive experiments demonstrate the effectiveness and flexibility of\nthe proposed method on 4D human-centric parsing tasks, achieving up to 93.3%\nacceleration compared to the previous state-of-the-art method, which was\nlimited to parsing fixed classes.", "published": "2025-07-14 03:35:06", "link": "http://arxiv.org/abs/2507.09880v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Resolution Revolution: A Physics-Guided Deep Learning Framework for Spatiotemporal Temperature Reconstruction", "abstract": "Central to Earth observation is the trade-off between spatial and temporal\nresolution. For temperature, this is especially critical because real-world\napplications require high spatiotemporal resolution data. Current technology\nallows for hourly temperature observations at 2 km, but only every 16 days at\n100 m, a gap further exacerbated by cloud cover. Earth system models offer\ncontinuous hourly temperature data, but at a much coarser spatial resolution\n(9-31 km). Here, we present a physics-guided deep learning framework for\ntemperature data reconstruction that integrates these two data sources. The\nproposed framework uses a convolutional neural network that incorporates the\nannual temperature cycle and includes a linear term to amplify the coarse Earth\nsystem model output into fine-scale temperature values observed from\nsatellites. We evaluated this framework using data from two satellites, GOES-16\n(2 km, hourly) and Landsat (100 m, every 16 days), and demonstrated effective\ntemperature reconstruction with hold-out and in situ data across four datasets.\nThis physics-guided deep learning framework opens new possibilities for\ngenerating high-resolution temperature data across spatial and temporal scales,\nunder all weather conditions and globally.", "published": "2025-07-14 03:03:25", "link": "http://arxiv.org/abs/2507.09872v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "SpeakerVid-5M: A Large-Scale High-Quality Dataset for Audio-Visual Dyadic Interactive Human Generation", "abstract": "The rapid development of large-scale models has catalyzed significant\nbreakthroughs in the digital human domain. These advanced methodologies offer\nhigh-fidelity solutions for avatar driving and rendering, leading academia to\nfocus on the next major challenge: audio-visual dyadic interactive virtual\nhuman. To facilitate research in this emerging area, we present SpeakerVid-5M\ndataset, the first large-scale, high-quality dataset designed for audio-visual\ndyadic interactive virtual human generation. Totaling over 8,743 hours,\nSpeakerVid-5M contains more than 5.2 million video clips of human portraits. It\ncovers diverse scales and interaction types, including monadic talking,\nlistening, and dyadic conversations. Crucially, the dataset is structured along\ntwo key dimensions: interaction type and data quality. First, it is categorized\ninto four types (dialogue branch, single branch, listening branch and\nmulti-turn branch) based on the interaction scenario. Second, it is stratified\ninto a large-scale pre-training subset and a curated, high-quality subset for\nSupervised Fine-Tuning (SFT). This dual structure accommodates a wide array of\n2D virtual human tasks. In addition, we provide an autoregressive (AR)-based\nvideo chat baseline trained on this data, accompanied by a dedicated set of\nmetrics and test data to serve as a benchmark VidChatBench for future work.\nBoth the dataset and the corresponding data processing code will be publicly\nreleased. Project page: https://dorniwang.github.io/SpeakerVid-5M/", "published": "2025-07-14 02:22:47", "link": "http://arxiv.org/abs/2507.09862v1", "categories": ["cs.CV", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Generative Audio Language Modeling with Continuous-valued Tokens and Masked Next-Token Prediction", "abstract": "Autoregressive next-token prediction with the Transformer decoder has become\na de facto standard in large language models (LLMs), achieving remarkable\nsuccess in Natural Language Processing (NLP) at scale. Extending this paradigm\nto audio poses unique challenges due to its inherently continuous nature. We\nresearch audio generation with a causal language model (LM) without discrete\ntokens. We leverage token-wise diffusion to model the continuous distribution\nof the next continuous-valued token. Our approach delivers significant\nimprovements over previous discrete solution, AudioGen, achieving 20% and 40%\nrelative gains on AudioCaps in Frechet Audio Distance (FAD) and\nKullback-Leibler (KL) divergence, respectively. Additionally, we propose a\nnovel masked next-token prediction task that incorporates masked prediction\ninto the causal LM framework. On AudioCaps, the innovation yields 41% and 33%\nrelative FAD improvements over AudioGen Base (285M) and AudioGen Large (1B)\nmodels, respectively, and is on par with the state-of-the-art (SOTA) diffusion\nmodels. Furthermore, we achieve these results with significantly fewer\nparameters -- 193M for our Base and 462M for our Large models.", "published": "2025-07-14 00:14:54", "link": "http://arxiv.org/abs/2507.09834v1", "categories": ["eess.AS", "cs.CV", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Quantitative central limit theorems for exponential random graphs", "abstract": "Ferromagnetic exponential random graph models (ERGMs) are nonlinear\nexponential tilts of Erd\\H{o}s-R\\'enyi models, under which the presence of\ncertain subgraphs such as triangles may be emphasized. These models are\nmixtures of metastable wells which each behave macroscopically like new\nErd\\H{o}s-R\\'enyi models themselves, exhibiting the same laws of large numbers\nfor the overall edge count as well as all subgraph counts. However, the\nmicroscopic fluctuations of these quantities remained elusive for some time.\nBuilding on a recent breakthrough by Fang, Liu, Shao and Zhao [FLSZ24] driven\nby Stein's method, we prove quantitative central limit theorems (CLTs) for\nthese quantities and more in metastable wells under ferromagnetic ERGMs. One\nmain novelty of our results is that they apply also in the supercritical (low\ntemperature) regime of parameters, which has previously been relatively\nunexplored. To accomplish this, we develop a novel probabilistic technique\nbased on the careful analysis of the evolution of relevant quantities under the\nERGM Glauber dynamics. Our technique allows us to deliver the main input to the\nmethod developed by [FLSZ24], which is the fact that the fluctuations of\nsubgraph counts are driven by those of the overall edge count. This was first\nshown for the triangle count by Sambale and Sinulis [SS20] in the Dobrushin\n(very high temperature) regime via functional-analytic methods. We feel our\ntechnique clarifies the underlying mechanisms at play, and it also supplies\nimproved bounds on the Wasserstein and Kolmogorov distances between the\nobservables at hand and the limiting Gaussians, as compared to the results of\n[FLSZ24] in the subcritical (high temperature) regime beyond the Dobrushin\nregime. Moreover, our technique is flexible enough to also yield quantitative\nCLTs for vertex degrees and local subgraph counts, which have not appeared\nbefore in any parameter regime.", "published": "2025-07-14 17:54:58", "link": "http://arxiv.org/abs/2507.10531v1", "categories": ["math.PR", "cond-mat.stat-mech", "cs.DM", "math-ph", "math.MP", "math.ST", "stat.TH", "60C05 (Primary) 60B20, 05C80 (Secondary)", "G.3; G.2.2"], "primary_category": "math.PR"}
{"title": "Colorful Minors", "abstract": "We introduce the notion of colorful minors, which generalizes the classical\nconcept of rooted minors in graphs. $q$-colorful graph is defined as a pair\n$(G, \\chi),$ where $G$ is a graph and $\\chi$ assigns to each vertex a (possibly\nempty) subset of at most $q$ colors. The colorful minor relation enhances the\nclassical minor relation by merging color sets at contracted edges and allowing\nthe removal of colors from vertices. This framework naturally models\nalgorithmic problems involving graphs with (possibly overlapping) annotated\nvertex sets. We develop a structural theory for colorful minors by establishing\nseveral theorems characterizing $\\mathcal{H}$-colorful minor-free graphs, where\n$\\mathcal{H}$ consists either of a clique or a grid with all vertices assigned\nall colors, or of grids with colors segregated and ordered on the outer face.\nLeveraging our structural insights, we provide a complete classification -\nparameterized by the number $q$ of colors - of all colorful graphs that exhibit\nthe Erd\\H{o}s-P\\'osa property with respect to colorful minors. On the\nalgorithmic side, we provide a fixed-parameter tractable algorithm for colorful\nminor testing and a variant of the $k$-disjoint paths problem. Together with\nthe fact that the colorful minor relation forms a well-quasi-order, this\nimplies that every colorful minor-monotone parameter on colorful graphs admits\na fixed-parameter algorithm. Furthermore, we derive two algorithmic\nmeta-theorems (AMTs) whose structural conditions are linked to extensions of\ntreewidth and Hadwiger number on colorful graphs. Our results suggest how known\nAMTs can be extended to incorporate not only the structure of the input graph\nbut also the way the colored vertices are distributed in it.", "published": "2025-07-14 16:46:29", "link": "http://arxiv.org/abs/2507.10467v1", "categories": ["math.CO", "cs.DM", "cs.DS", "05C83, 05C85, 05C10, 05C75, 68R10", "G.2.2"], "primary_category": "math.CO"}
{"title": "$(\u0394-1)$-dicolouring of digraphs", "abstract": "In 1977, Borodin and Kostochka conjectured that every graph with maximum\ndegree $\\Delta \\geq 9$ is $(\\Delta-1)$-colourable, unless it contains a clique\nof size $\\Delta$. In 1999, Reed confirmed the conjecture when $\\Delta\\geq\n10^{14}$.\n  We propose different generalisations of this conjecture for digraphs, and\nprove the analogue of Reed's result for each of them. The chromatic number and\nclique number are replaced respectively by the dichromatic number and the\nbiclique number of digraphs. If $D$ is a digraph such that\n$\\min(\\tilde{\\Delta}(D),\\Delta^+(D)) = \\Delta \\geq 9$, we conjecture that $D$\nhas dichromatic number at most $\\Delta-1$, unless either (i) $D$ contains a\nbiclique of size $\\Delta$, or (ii) $D$ contains a biclique $K$ of size\n$\\Delta-2$, a directed $3$-cycle $\\vec{C_3}$ disjoint from $K$, and all\npossible arcs in both directions between $\\vec{C_3}$ and $K$. If true, this\nimplies the conjecture of Borodin and Kostochka. We prove it when $\\Delta$ is\nlarge enough, thereby generalising the result of Reed.\n  We finally give a sufficient condition for a digraph $D$ to have dichromatic\nnumber at most $\\Delta_{\\min}(D)-1$, assuming that $\\Delta_{\\min}(D)$ is large\nenough. In particular, this holds when the underlying graph of $D$ has no\nclique of size $\\Delta_{\\min}(D)$, thus yielding a third independent\ngeneralisation of Reed's result. We further give a hardness result witnessing\nthat our sufficient condition is best possible.\n  To obtain these new upper bounds on the dichromatic number, we prove a dense\ndecomposition lemma for digraphs having large maximum degree, which generalises\nto the directed setting the so-called dense decomposition of graphs due to\nMolloy and Reed. We believe this may be of independent interest, especially as\na tool in various applications.", "published": "2025-07-14 13:37:44", "link": "http://arxiv.org/abs/2507.10266v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Bicriteria Submodular Maximization", "abstract": "Submodular functions and their optimization have found applications in\ndiverse settings ranging from machine learning and data mining to game theory\nand economics. In this work, we consider the constrained maximization of a\nsubmodular function, for which we conduct a principled study of bicriteria\napproximation algorithms -- algorithms which can violate the constraint, but\nonly up to a bounded factor. Bicrteria optimization allows constrained\nsubmodular maximization to capture additional important settings, such as the\nwell-studied submodular cover problem and optimization under soft constraints.\nWe provide results that span both multiple types of constraints (cardinality,\nknapsack, matroid and convex set) and multiple classes of submodular functions\n(monotone, symmetric and general). For many of the cases considered, we provide\noptimal results. In other cases, our results improve over the state-of-the-art,\nsometimes even over the state-of-the-art for the special case of\nsingle-criterion (standard) optimization. Results of the last kind demonstrate\nthat relaxing the feasibility constraint may give a perspective about the\nproblem that is useful even if one only desires feasible solutions.", "published": "2025-07-14 13:14:45", "link": "http://arxiv.org/abs/2507.10248v1", "categories": ["cs.DS", "cs.DM", "68R05 (Primary) 68W25, 90C26 (Secondary)", "F.2.2; G.2.1"], "primary_category": "cs.DS"}
{"title": "Overcoming catastrophic forgetting in neural networks", "abstract": "Catastrophic forgetting is the primary challenge that hinders continual\nlearning, which refers to a neural network ability to sequentially learn\nmultiple tasks while retaining previously acquired knowledge. Elastic Weight\nConsolidation, a regularization-based approach inspired by synaptic\nconsolidation in biological neural systems, has been used to overcome this\nproblem. In this study prior research is replicated and extended by evaluating\nEWC in supervised learning settings using the PermutedMNIST and RotatedMNIST\nbenchmarks. Through systematic comparisons with L2 regularization and\nstochastic gradient descent (SGD) without regularization, we analyze how\ndifferent approaches balance knowledge retention and adaptability. Our results\nconfirm what was shown in previous research, showing that EWC significantly\nreduces forgetting compared to naive training while slightly compromising\nlearning efficiency on new tasks. Moreover, we investigate the impact of\ndropout regularization and varying hyperparameters, offering insights into the\ngeneralization of EWC across diverse learning scenarios. These results\nunderscore EWC's potential as a viable solution for lifelong learning in neural\nnetworks.", "published": "2025-07-14 17:04:05", "link": "http://arxiv.org/abs/2507.10485v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Am I on the Right Track? What Can Predicted Query Performance Tell Us about the Search Behaviour of Agentic RAG", "abstract": "Agentic Retrieval-Augmented Generation (RAG) is a new paradigm where the\nreasoning model decides when to invoke a retriever (as a \"tool\") when answering\na question. This paradigm, exemplified by recent research works such as\nSearch-R1, enables the model to decide when to search and obtain external\ninformation. However, the queries generated by such Agentic RAG models and the\nrole of the retriever in obtaining high-quality answers remain understudied. To\nthis end, this initial study examines the applicability of query performance\nprediction (QPP) within the recent Agentic RAG models Search-R1 and\nR1-Searcher. We find that applying effective retrievers can achieve higher\nanswer quality within a shorter reasoning process. Moreover, the QPP estimates\nof the generated queries, used as an approximation of their retrieval quality,\nare positively correlated with the quality of the final answer. Ultimately, our\nwork is a step towards adaptive retrieval within Agentic RAG, where QPP is used\nto inform the model if the retrieved results are likely to be useful.", "published": "2025-07-14 15:54:50", "link": "http://arxiv.org/abs/2507.10411v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Riding the Carousel: The First Extensive Eye Tracking Analysis of Browsing Behavior in Carousel Recommenders", "abstract": "Carousels have become the de-facto interface in online services. However,\nthere is a lack of research in carousels, particularly examining how\nrecommender systems may be designed differently than the traditional\nsingle-list interfaces. One of the key elements for understanding how to design\na system for a particular interface is understanding how users browse. For\ncarousels, users may browse in a number of different ways due to the added\ncomplexity of multiple topic defined-lists and swiping to see more items.\n  Eye tracking is the key to understanding user behavior by providing valuable,\ndirect information on how users see and navigate. In this work, we provide the\nfirst extensive analysis of the eye tracking behavior in carousel recommenders\nunder the free-browsing setting. To understand how users browse, we examine the\nfollowing research questions : 1) where do users start browsing, 2) how do\nusers transition from item to item within the same carousel and across\ncarousels, and 3) how does genre preference impact transitions?\n  This work addresses a gap in the field and provides the first extensive\nempirical results of eye tracked browsing behavior in carousels for improving\nrecommenders. Taking into account the insights learned from the above\nquestions, our final contribution is to provide suggestions to help carousel\nrecommender system designers optimize their systems for user browsing behavior.\nThe most important suggestion being to reorder the ranked item positions to\naccount for browsing after swiping.These contributions aim not only to help\nimprove current systems, but also to encourage and allow the design of new user\nmodels, systems, and metrics that are better suited to the complexity of\ncarousel interfaces.", "published": "2025-07-14 10:26:27", "link": "http://arxiv.org/abs/2507.10135v1", "categories": ["cs.IR", "cs.HC"], "primary_category": "cs.IR"}
{"title": "User Long-Term Multi-Interest Retrieval Model for Recommendation", "abstract": "User behavior sequence modeling, which captures user interest from rich\nhistorical interactions, is pivotal for industrial recommendation systems.\nDespite breakthroughs in ranking-stage models capable of leveraging ultra-long\nbehavior sequences with length scaling up to thousands, existing retrieval\nmodels remain constrained to sequences of hundreds of behaviors due to two main\nchallenges. One is strict latency budget imposed by real-time service over\nlarge-scale candidate pool. The other is the absence of target-aware mechanisms\nand cross-interaction architectures, which prevent utilizing ranking-like\ntechniques to simplify long sequence modeling. To address these limitations, we\npropose a new framework named User Long-term Multi-Interest Retrieval\nModel(ULIM), which enables thousand-scale behavior modeling in retrieval\nstages. ULIM includes two novel components: 1)Category-Aware Hierarchical\nDual-Interest Learning partitions long behavior sequences into multiple\ncategory-aware subsequences representing multi-interest and jointly optimizes\nlong-term and short-term interests within specific interest cluster.\n2)Pointer-Enhanced Cascaded Category-to-Item Retrieval introduces\nPointer-Generator Interest Network(PGIN) for next-category prediction, followed\nby next-item retrieval upon the top-K predicted categories. Comprehensive\nexperiments on Taobao dataset show that ULIM achieves substantial improvement\nover state-of-the-art methods, and brings 5.54% clicks, 11.01% orders and 4.03%\nGMV lift for Taobaomiaosha, a notable mini-app of Taobao.", "published": "2025-07-14 09:32:26", "link": "http://arxiv.org/abs/2507.10097v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "SLIF-MR: Self-loop Iterative Fusion of Heterogeneous Auxiliary Information for Multimodal Recommendation", "abstract": "Knowledge graphs (KGs) and multimodal item information, which respectively\ncapture relational and attribute features, play a crucial role in improving\nrecommender system accuracy. Recent studies have attempted to integrate them\nvia multimodal knowledge graphs (MKGs) to further enhance recommendation\nperformance. However, existing methods typically freeze the MKG structure\nduring training, which limits the full integration of structural information\nfrom heterogeneous graphs (e.g., KG and user-item interaction graph), and\nresults in sub-optimal performance. To address this challenge, we propose a\nnovel framework, termed Self-loop Iterative Fusion of Heterogeneous Auxiliary\nInformation for Multimodal Recommendation (SLIF-MR), which leverages item\nrepresentations from previous training epoch as feedback signals to dynamically\noptimize the heterogeneous graph structures composed of KG, multimodal item\nfeature graph, and user-item interaction graph. Through this iterative fusion\nmechanism, both user and item representations are refined, thus improving the\nfinal recommendation performance. Specifically, based on the feedback item\nrepresentations, SLIF-MR constructs an item-item correlation graph, then\nintegrated into the establishment process of heterogeneous graphs as additional\nnew structural information in a self-loop manner. Consequently, the internal\nstructures of heterogeneous graphs are updated with the feedback item\nrepresentations during training. Moreover, a semantic consistency learning\nstrategy is proposed to align heterogeneous item representations across\nmodalities. The experimental results show that SLIF-MR significantly\noutperforms existing methods, particularly in terms of accuracy and robustness.", "published": "2025-07-14 07:32:16", "link": "http://arxiv.org/abs/2507.09998v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Non-parametric Graph Convolution for Re-ranking in Recommendation Systems", "abstract": "Graph knowledge has been proven effective in enhancing item rankings in\nrecommender systems (RecSys), particularly during the retrieval stage. However,\nits application in the ranking stage, especially when richer contextual\ninformation in user-item interactions is available, remains underexplored. A\nmajor challenge lies in the substantial computational cost associated with\nrepeatedly retrieving neighborhood information from billions of items stored in\ndistributed systems. This resource-intensive requirement makes it difficult to\nscale graph-based methods in practical RecSys. To bridge this gap, we first\ndemonstrate that incorporating graphs in the ranking stage improves ranking\nqualities. Notably, while the improvement is evident, we show that the\nsubstantial computational overheads entailed by graphs are prohibitively\nexpensive for real-world recommendations. In light of this, we propose a\nnon-parametric strategy that utilizes graph convolution for re-ranking only\nduring test time. Our strategy circumvents the notorious computational\noverheads from graph convolution during training, and utilizes structural\nknowledge hidden in graphs on-the-fly during testing. It can be used as a\nplug-and-play module and easily employed to enhance the ranking ability of\nvarious ranking layers of a real-world RecSys with significantly reduced\ncomputational overhead. Through comprehensive experiments across four benchmark\ndatasets with varying levels of sparsity, we demonstrate that our strategy\nyields noticeable improvements (i.e., 8.1% on average) during testing time with\nlittle to no additional computational overheads (i.e., 0.5 on average). Code:\nhttps://github.com/zyouyang/RecSys2025_NonParamGC.git", "published": "2025-07-14 06:35:18", "link": "http://arxiv.org/abs/2507.09969v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A mapping of the Min-Sum decoder to reduction operations, and its implementation using CUDA kernels", "abstract": "Decoders for Low Density Parity Check (LDPC) codes are usually tailored to an\napplication and optimized once the specific content and structure of the parity\nmatrix are known. In this work we consider the parity matrix as an argument of\nthe Min-Sum decoder, and provide a GPU implementation that is independent of\nthe content of the parity matrix, and relies only on its dimensions.", "published": "2025-07-14 16:10:10", "link": "http://arxiv.org/abs/2507.10424v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Matrix Completion Approach for the Construction of MDP Convolutional Codes", "abstract": "Maximum Distance Profile (MDP) convolutional codes are an important class of\nchannel codes due to their maximal delay-constrained error correction\ncapabilities. The design of MDP codes has attracted significant attention from\nthe research community. However, only limited attention was given to addressing\nthe complexity of encoding and decoding operations. This paper aims to reduce\nencoding complexity by constructing partial unit-memory MDP codes with\nstructured and sparse generator matrices. In particular, we present a matrix\ncompletion framework that extends a structured superregular matrix (e.g.,\nCauchy) over a small field to a sparse sliding generator matrix of an MDP code.\nWe show that the proposed construction can reduce the encoding complexity\ncompared to the current state-of-the-art MDP code designs.", "published": "2025-07-14 15:59:43", "link": "http://arxiv.org/abs/2507.10417v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Consensus, Inconsistency, Emergence: what's paraconsistency got to do with it?", "abstract": "The consensus problem, briefly stated, consists of having processes in an\nasynchronous distributed system agree on a value. It is widely known that the\nconsensus problem does not have a deterministic solution that ensures both\ntermination and consistency, if there is at least one faulty process in the\nsystem. This result, known as the FLP impossibility theorem, led to several\ngeneralizations and developments in theoretical distributed computing. This\npaper argues that the FLP impossibility theorem holds even under a generalized\ndefinition of computation through oracles. Furthermore, using a theoretical\nmachinery from complex systems, this paper also posits that inconsistency may\nbe an emergent feature of consensus over distributed systems by examining how a\nsystem transitions phases. Under the same complex systems framework, this paper\nexamines paraconsistent logics, arguing that while inconsistency is not an\nemergent feature for these logics, triviality may be. Lastly, some attention is\ngiven to the possibility of developing consensus algorithms capable of\nparaconsistent reasoning.", "published": "2025-07-14 15:55:14", "link": "http://arxiv.org/abs/2507.10413v1", "categories": ["cs.DC", "cs.CC", "cs.IT", "cs.LO", "math.IT"], "primary_category": "cs.DC"}
{"title": "Fault-Tolerant Quantum Error Correction for Constant-Excitation Stabilizer Codes under Coherent Noise", "abstract": "Collective coherent noise poses challenges for fault-tolerant quantum error\ncorrection (FTQEC), as it falls outside the usual stochastic noise models.\nWhile constant excitation (CE) codes can naturally avoid coherent noise, a\ncomplete fault-tolerant framework for the use of these codes under realistic\nnoise models has been elusive. Here, we introduce a complete fault-tolerant\narchitecture for CE CSS codes based on dual-rail concatenation. After showing\nthat transversal CNOT gates violate CE code constraints, we introduce\nCE-preserving logical CNOT gates and modified Shor- and Steane-type syndrome\nextraction schemes using zero-controlled NOT gates and CE-compatible ancilla.\nThis enables fault-tolerant syndrome-extraction circuits fully compatible with\nCE constraints. We also present an extended stabilizer simulation algorithm\nthat efficiently tracks both stochastic and collective coherent noise. Using\nour framework, we identify minimal CE codes, including the $[[12,1,3]]$ and\n$[[14,3,3]]$ codes, and demonstrate that the $[[12,1,3]]$ code achieves strong\nperformance under coherent noise. Our results establish the first complete\nFTQEC framework for CE codes, demonstrating their robustness to coherent noise.\nThis highlights the potential of CE codes as a possible solution for quantum\nprocessors dominated by collective coherent noise.", "published": "2025-07-14 15:37:12", "link": "http://arxiv.org/abs/2507.10395v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Dimensionality increase for error correction in the interaction between information space and the physical world", "abstract": "The evolution of human intelligence led to the huge amount of data in the\ninformation space. Accessing and processing this data helps in finding\nsolutions to applied problems based on finite-dimensional models. We argue,\nthat formally, such a mathematical model can be embedded into a\nhigher-dimensional model inside of which a desired solution will exist.", "published": "2025-07-14 12:56:18", "link": "http://arxiv.org/abs/2507.10234v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Low-Power Wake-Up Signal Design in 3GPP 5G-Advanced Release 19", "abstract": "The Low-Power Wake-Up Signal (LP-WUS) and Low-Power Synchronization Signal\n(LP-SS), introduced in 3GPP 5G-Advanced Release 19, represent a major step\nforward in enabling power-efficient IoT communications. This paper presents a\ncomprehensive overview of the LP-WUS and LP-SS procedures in the RRC_IDLE and\nRRC_INACTIVE states, and outlines key physical layer design choices. The LP-WUS\nis designed to be detected by a low-power energy detector (ED), allowing the\nmain radio (MR) to remain switched off. This architecture enables power savings\nof up to 80% compared to conventional 5G paging mechanisms.", "published": "2025-07-14 12:26:14", "link": "http://arxiv.org/abs/2507.10207v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "High Girth Spatially-Coupled LDPC Codes with Hierarchical Structure", "abstract": "Quasi-cyclic (QC) low-density parity-check (LDPC) codes are a class of LDPC\ncodes with a simple construction facilitating hardware implementation while\nachieving excellent performance. In this paper, we introduce an algorithm that\nconstructs QC spatially-coupled (SC) LDPC codes with large girth while keeping\nthe constraint length small. The algorithm offers a \"protograph to basegraph\"\nconstruction, focusing on finding small lifting sizes of QC codes while\navoiding short cycles. This work extends the hierarchical quasi-cyclic (HQC)\nconstruction for block LDPC codes proposed by Wang et al. to the spatially\ncoupled case. The construction is based on the cycle relevant matrix (CRM)\nderived from the periodic structure of time-invariant SC-LDPC codes. Numerical\nresults show that the proposed algorithm effectively achieves the target girth\nwith a small lifting factor, enabling low-complexity SC code construction.", "published": "2025-07-14 11:50:59", "link": "http://arxiv.org/abs/2507.10185v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Improved Differential Evolution for Enhancing the Aggregated Channel Estimation of RIS-Aided Cell-Free Massive MIMO", "abstract": "Cell-Free Massive multiple-input multiple-output (MIMO) systems are\ninvestigated with the support of a reconfigurable intelligent surface (RIS).\nThe RIS phase shifts are designed for improved channel estimation in the\npresence of spatial correlation. Specifically, we formulate the channel\nestimate and estimation error expressions using linear minimum mean square\nerror (LMMSE) estimation for the aggregated channels. An optimization problem\nis then formulated to minimize the average normalized mean square error (NMSE)\nsubject to practical phase shift constraints. To circumvent the problem of\ninherent nonconvexity, we then conceive an enhanced version of the differential\nevolution algorithm that is capable of avoiding local minima by introducing an\naugmentation operator applied to some high-performing Diffential Evolution (DE)\nindividuals. Numerical results indicate that our proposed algorithm can\nsignificantly improve the channel estimation quality of the state-of-the-art\nbenchmarks.", "published": "2025-07-14 09:57:20", "link": "http://arxiv.org/abs/2507.10113v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Learning-Aided Iterative Receiver for Superimposed Pilots: Design and Experimental Evaluation", "abstract": "The superimposed pilot transmission scheme offers substantial potential for\nimproving spectral efficiency in MIMO-OFDM systems, but it presents significant\nchallenges for receiver design due to pilot contamination and data\ninterference. To address these issues, we propose an advanced iterative\nreceiver based on joint channel estimation, detection, and decoding, which\nrefines the receiver outputs through iterative feedback. The proposed receiver\nincorporates two adaptive channel estimation strategies to enhance robustness\nunder time-varying and mismatched channel conditions. First, a variational\nmessage passing (VMP) method and its low-complexity variant (VMP-L) are\nintroduced to perform inference without relying on time-domain correlation.\nSecond, a deep learning (DL) based estimator is developed, featuring a\nconvolutional neural network with a despreading module and an attention\nmechanism to extract and fuse relevant channel features. Extensive simulations\nunder multi-stream and high-mobility scenarios demonstrate that the proposed\nreceiver consistently outperforms conventional orthogonal pilot baselines in\nboth throughput and block error rate. Moreover, over-the-air experiments\nvalidate the practical effectiveness of the proposed design. Among the methods,\nthe DL based estimator achieves a favorable trade-off between performance and\ncomplexity, highlighting its suitability for real-world deployment in dynamic\nwireless environments.", "published": "2025-07-14 09:00:27", "link": "http://arxiv.org/abs/2507.10074v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "BiD Codes: Algebraic Codes from $3 \\times 3$ Kernel", "abstract": "We introduce Berman-intersection-dual Berman (BiD) codes. These are abelian\ncodes of length $3^m$ that can be constructed using Kronecker products of a $3\n\\times 3$ kernel matrix. BiD codes offer minimum distance close to that of\nReed-Muller (RM) codes at practical blocklengths, and larger distance than RM\ncodes asymptotically in the blocklength. Simulations of BiD codes of length\n$3^5=243$ in the erasure and Gaussian channels show that their block error\nrates under maximum-likelihood decoding are similar to, and sometimes better,\nthan RM, RM-Polar, and CRC-aided Polar codes.", "published": "2025-07-14 08:52:58", "link": "http://arxiv.org/abs/2507.10068v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Precoded Zak-OTFS for Per-Carrier Equalization", "abstract": "In Zak-OTFS (orthogonal time frequency space) modulation the carrier waveform\nis a pulse in the delay-Doppler (DD) domain, formally a quasi-periodic\nlocalized function with specific periods along delay and Doppler. When the\nchannel delay spread is less than the delay period, and the channel Doppler\nspread is less than the Doppler period, the response to a single Zak-OTFS\ncarrier provides an image of the scattering environment and can be used to\npredict the effective channel at all other carriers. The image of the\nscattering environment changes slowly, making it possible to employ precoding\nat the transmitter. Precoding techniques were developed more than thirty years\nago for wireline modem channels (V.34 standard) defined by linear convolution\nwhere a pulse in the time domain (TD) is used to probe the one-dimensional\npartial response channel. The action of a doubly spread channel on Zak-OTFS\nmodulation determines a two-dimensional partial response channel defined by\ntwisted convolution, and we develop a novel precoding technique for this\nchannel. The proposed precoder leads to separate equalization of each DD\ncarrier which has significantly lower complexity than joint equalization of all\ncarriers. Further, the effective precoded channel results in non-interfering DD\ncarriers which significantly reduces the overhead of guard carriers separating\ndata and pilot carriers, which improves the spectral efficiency significantly.", "published": "2025-07-14 03:58:48", "link": "http://arxiv.org/abs/2507.09894v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Several new classes of self-orthogonal minimal linear codes violating the Ashikhmin-Barg condition", "abstract": "Linear codes have attracted considerable attention in coding theory and\ncryptography due to their significant applications in secret sharing schemes,\nsecure two-party computation, Galois geometries, among others. As two special\nsubclasses of linear codes, minimal linear codes and self-orthogonal linear\ncodes are of particular interest. Constructing linear codes that possess both\nminimality and self-orthogonality is very interesting. The main purpose of this\npaper is to construct self-orthogonal minimal linear codes that violate the\nAshikhmin-Barg (AB for short) condition over the finite field $\\mathbb{F}_p$.\nFirst, we present several classes of self-orthogonal minimal linear codes\nviolating the AB condition over the finite field $\\mathbb{F}_2$ and determine\ntheir weight distributions. Next, for any odd prime $p$, we construct two\nclasses of self-orthogonal linear codes from $p$-ary functions, which contain\nsome optimal or almost optimal codes. Finally, based on plateaued functions, we\nconstruct two classes of self-orthogonal linear codes that violate the AB\ncondition. Their weight distributions are also provided. To the best of our\nknowledge, this paper is the first to investigate the constructions of linear\ncodes that violate the AB condition and satisfy self-orthogonality.", "published": "2025-07-14 01:42:18", "link": "http://arxiv.org/abs/2507.09856v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Incomplete Multiview Learning via Wyner Common Information", "abstract": "Incomplete multiview clustering is of high recent interest, fueled by the\nadvancement of common information-based deep multiview learning. The practical\nscenarios where unpaired multiview data with missing values have wide\napplications in generative learning, cross-modal retrieval, and wireless device\nidentification problems. Following the perspective that the shared information\nbetween the incomplete multiview data aligns with the cluster targets, recent\nworks have generalized the well-known common information frameworks in\ninformation theory multiview learning problems, with improved performance\nreported. Different from previous works, we extend the frameworks to incomplete\nmultiview clustering problems and propose an efficient solver: Wyner Incomplete\nMultiView Clustering (WyIMVC). Interestingly, the common randomness in WyIMVC\nallows for joint clustering and missing value inference in contrast to the\ncompared methods in the literature. Moreover, leveraging the\ndifference-of-convex structure of the formulated problems, we propose an\nefficient solver with a convergence guarantee independent of initialization.\nEmpirically, our solver outperforms the state-of-the-art solvers in a range of\nincomplete multiview datasets with varying numbers of views and dimensions.", "published": "2025-07-14 00:50:58", "link": "http://arxiv.org/abs/2507.09843v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Remote Safety Monitoring: Significance-Aware Status Updating for Situational Awareness", "abstract": "In this study, we consider a problem of remote safety monitoring, where a\nmonitor pulls status updates from multiple sensors monitoring several\nsafety-critical situations. Based on the received updates, multiple estimators\ndetermine the current safety-critical situations. Due to transmission errors\nand limited channel resources, the received status updates may not be fresh,\nresulting in the possibility of misunderstanding the current safety situation.\nIn particular, if a dangerous situation is misinterpreted as safe, the safety\nrisk is high. We study the joint design of transmission scheduling and\nestimation for multi-sensor, multi-channel remote safety monitoring, aiming to\nminimize the loss due to the unawareness of potential danger. We show that the\njoint design of transmission scheduling and estimation can be reduced to a\nsequential optimization of estimation and scheduling. The scheduling problem\ncan be formulated as a Restless Multi-armed Bandit (RMAB) , for which it is\ndifficult to establish indexability. We propose a low-complexity Maximum Gain\nFirst (MGF) policy and prove it is asymptotically optimal as the numbers of\nsources and channels scale up proportionally, without requiring the\nindexability condition. We also provide an information-theoretic interpretation\nof the transmission scheduling problem. Numerical results show that our\nestimation and scheduling policies achieves higher performance gain over\nperiodic updating, randomized policy, and Maximum Age First (MAF) policy.", "published": "2025-07-14 00:04:38", "link": "http://arxiv.org/abs/2507.09833v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Fusing LLM Capabilities with Routing Data", "abstract": "The rapid advancement of large language models (LLMs) has created a vibrant\necosystem of diverse architectures, each with unique strengths due to\ndifferences in design, training data, and objectives. However, most\napplications still rely on a single backend model, limiting coverage of\ncapabilities and leading to inefficiencies in performance and token cost when\ntackling complex tasks. We highlight an underexploited opportunity: LLM routing\ndata, produced when hosting platforms route diverse queries to different\nmodels, which can reveal comparative strengths across tasks. To address this,\nwe propose FusionBench, a comprehensive routing benchmark covering 14 tasks\nacross five domains with 20 open-source LLMs (8B to 671B parameters), capturing\n103M tokens and summarizing reusable thought templates from top models.\nBuilding on this, we introduce FusionFactory, a systematic fusion framework\nwith three levels: (1) query-level fusion, tailoring routers for each query\nusing both direct responses and reasoning-augmented outputs; (2) thought-level\nfusion, leveraging abstract templates derived from top-performing LLMs' answers\nto similar queries; and (3) model-level fusion, transferring capabilities\nbetween models via distillation, using top responses or highest judge scores as\ntraining data. Experiments show FusionFactory consistently outperforms the best\nindividual LLM across all 14 benchmarks, with optimal fusion configurations\nvarying by benchmark, demonstrating the value of systematic LLM fusion in\nharnessing complementary strengths and improving overall performance.", "published": "2025-07-14 17:58:02", "link": "http://arxiv.org/abs/2507.10540v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Graph World Model", "abstract": "World models (WMs) demonstrate strong capabilities in prediction, generation,\nand planning tasks. Existing WMs primarily focus on unstructured data and\ncannot leverage the ubiquitous structured data, often represented as graphs, in\nthe digital world. While multiple graph foundation models have been proposed,\nthey focus on graph learning tasks and cannot extend to diverse multi-modal\ndata and interdisciplinary tasks. To address these challenges, we propose the\nGraph World Model (GWM), a world model that supports both unstructured and\ngraph-structured states with multi-modal information and represents diverse\ntasks as actions. The core of a GWM is a generic message-passing algorithm to\naggregate structured information, either over a unified multi-modal token space\nby converting multi-modal data into text (GWM-T) or a unified multi-modal\nembedding space by modality-specific encoders (GWM-E). Notably, GWM introduces\naction nodes to support diverse tasks, where action nodes are linked to other\nnodes via direct reference or similarity computation. Extensive experiments on\nsix tasks from diverse domains, including multi-modal generation and matching,\nrecommendation, graph prediction, multi-agent, retrieval-augmented generation,\nand planning and optimization, show that the same GWM outperforms or matches\ndomain-specific baselines' performance, benefits from multi-hop structures, and\ndemonstrates strong zero-shot/few-shot capabilities on unseen new tasks. Our\ncode for GWM is released at https://github.com/ulab-uiuc/GWM.", "published": "2025-07-14 17:57:45", "link": "http://arxiv.org/abs/2507.10539v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "On the Performance of Differentially Private Optimization with Heavy-Tail Class Imbalance", "abstract": "In this work, we analyze the optimization behaviour of common private\nlearning optimization algorithms under heavy-tail class imbalanced\ndistribution. We show that, in a stylized model, optimizing with Gradient\nDescent with differential privacy (DP-GD) suffers when learning low-frequency\nclasses, whereas optimization algorithms that estimate second-order information\ndo not. In particular, DP-AdamBC that removes the DP bias from estimating loss\ncurvature is a crucial component to avoid the ill-condition caused by\nheavy-tail class imbalance, and empirically fits the data better with\n$\\approx8\\%$ and $\\approx5\\%$ increase in training accuracy when learning the\nleast frequent classes on both controlled experiments and real data\nrespectively.", "published": "2025-07-14 17:57:08", "link": "http://arxiv.org/abs/2507.10536v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Split Happens: Combating Advanced Threats with Split Learning and Function Secret Sharing", "abstract": "Split Learning (SL) -- splits a model into two distinct parts to help protect\nclient data while enhancing Machine Learning (ML) processes. Though promising,\nSL has proven vulnerable to different attacks, thus raising concerns about how\neffective it may be in terms of data privacy. Recent works have shown promising\nresults for securing SL through the use of a novel paradigm, named Function\nSecret Sharing (FSS), in which servers obtain shares of a function they compute\nand operate on a public input hidden with a random mask. However, these works\nfall short in addressing the rising number of attacks which exist on SL. In\nSplitHappens, we expand the combination of FSS and SL to U-shaped SL. Similarly\nto other works, we are able to make use of the benefits of SL by reducing the\ncommunication and computational costs of FSS. However, a U-shaped SL provides a\nhigher security guarantee than previous works, allowing a client to keep the\nlabels of the training data secret, without having to share them with the\nserver. Through this, we are able to generalize the security analysis of\nprevious works and expand it to different attack vectors, such as modern model\ninversion attacks as well as label inference attacks. We tested our approach\nfor two different convolutional neural networks on different datasets. These\nexperiments show the effectiveness of our approach in reducing the training\ntime as well as the communication costs when compared to simply using FSS while\nmatching prior accuracy.", "published": "2025-07-14 17:18:07", "link": "http://arxiv.org/abs/2507.10494v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "The Target Polish: A New Approach to Outlier-Resistant Non-Negative Matrix and Tensor Factorization", "abstract": "This paper introduces the \"Target Polish,\" a robust and computationally\nefficient framework for nonnegative matrix and tensor factorization. Although\nconventional weighted NMF approaches are resistant to outliers, they converge\nslowly due to the use of multiplicative updates to minimize the objective\ncriterion. In contrast, the Target Polish approach remains compatible with the\nFast-HALS algorithm, which is renowned for its speed, by adaptively smoothing\nthe data with a weighted median-based transformation. This innovation provides\noutlier resistance while maintaining the highly efficient additive update\nstructure of Fast-HALS. Empirical evaluations using image datasets corrupted\nwith structured (block) and unstructured (salt) noise demonstrate that the\nTarget Polish approach matches or exceeds the accuracy of state-of-the-art\nrobust NMF methods and reduces computational time by an order of magnitude in\nthe studied scenarios.", "published": "2025-07-14 17:04:03", "link": "http://arxiv.org/abs/2507.10484v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Some remarks on gradient dominance and LQR policy optimization", "abstract": "Solutions of optimization problems, including policy optimization in\nreinforcement learning, typically rely upon some variant of gradient descent.\nThere has been much recent work in the machine learning, control, and\noptimization communities applying the Polyak-{\\L}ojasiewicz Inequality (PLI) to\nsuch problems in order to establish an exponential rate of convergence (a.k.a.\n``linear convergence'' in the local-iteration language of numerical analysis)\nof loss functions to their minima under the gradient flow. Often, as is the\ncase of policy iteration for the continuous-time LQR problem, this rate\nvanishes for large initial conditions, resulting in a mixed globally linear /\nlocally exponential behavior. This is in sharp contrast with the discrete-time\nLQR problem, where there is global exponential convergence. That gap between CT\nand DT behaviors motivates the search for various generalized PLI-like\nconditions, and this talk will address that topic. Moreover, these\ngeneralizations are key to understanding the transient and asymptotic effects\nof errors in the estimation of the gradient, errors which might arise from\nadversarial attacks, wrong evaluation by an oracle, early stopping of a\nsimulation, inaccurate and very approximate digital twins, stochastic\ncomputations (algorithm ``reproducibility''), or learning by sampling from\nlimited data. We describe an ``input to state stability'' (ISS) analysis of\nthis issue. The lecture also discussed convergence and PLI-like properties of\n``linear feedforward neural networks'' in feedback control, but this arXiv\nskips that part (to be updated). Much of the work described here was done in\ncollaboration with Arthur Castello B. de Oliveira, Leilei Cui, Zhong-Ping\nJiang, and Milad Siami.", "published": "2025-07-14 16:31:06", "link": "http://arxiv.org/abs/2507.10452v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Non-exchangeable Conformal Prediction with Optimal Transport: Tackling Distribution Shifts with Unlabeled Data", "abstract": "Conformal prediction is a distribution-free uncertainty quantification method\nthat has gained popularity in the machine learning community due to its\nfinite-sample guarantees and ease of use. Its most common variant, dubbed split\nconformal prediction, is also computationally efficient as it boils down to\ncollecting statistics of the model predictions on some calibration data not yet\nseen by the model. Nonetheless, these guarantees only hold if the calibration\nand test data are exchangeable, a condition that is difficult to verify and\noften violated in practice due to so-called distribution shifts. The literature\nis rife with methods to mitigate the loss in coverage in this non-exchangeable\nsetting, but these methods require some prior information on the type of\ndistribution shift to be expected at test time. In this work, we study this\nproblem via a new perspective, through the lens of optimal transport, and show\nthat it is possible to estimate the loss in coverage and mitigate it in case of\ndistribution shift.", "published": "2025-07-14 16:10:55", "link": "http://arxiv.org/abs/2507.10425v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Anticipating the Selectivity of Cyclization Reaction Pathways with Neural Network Potentials", "abstract": "Reaction mechanism search tools have demonstrated the ability to provide\ninsights into likely products and rate-limiting steps of reacting systems.\nHowever, reactions involving several concerted bond changes - as can be found\nin many key steps of natural product synthesis - can complicate the search\nprocess. To mitigate these complications, we present a mechanism search\nstrategy particularly suited to help expedite exploration of an exemplary\nfamily of such complex reactions, cyclizations. We provide a cost-effective\nstrategy for identifying relevant elementary reaction steps by combining\ngraph-based enumeration schemes and machine learning techniques for\nintermediate filtering. Key to this approach is our use of a neural network\npotential (NNP), AIMNet2-rxn, for computational evaluation of each candidate\nreaction pathway. In this article, we evaluate the NNP's ability to estimate\nactivation energies, demonstrate the correct anticipation of stereoselectivity,\nand recapitulate complex enabling steps in natural product synthesis.", "published": "2025-07-14 15:43:59", "link": "http://arxiv.org/abs/2507.10400v1", "categories": ["cs.LG", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Extracting Important Tokens in E-Commerce Queries with a Tag Interaction-Aware Transformer Model", "abstract": "The major task of any e-commerce search engine is to retrieve the most\nrelevant inventory items, which best match the user intent reflected in a\nquery. This task is non-trivial due to many reasons, including ambiguous\nqueries, misaligned vocabulary between buyers, and sellers, over- or\nunder-constrained queries by the presence of too many or too few tokens. To\naddress these challenges, query reformulation is used, which modifies a user\nquery through token dropping, replacement or expansion, with the objective to\nbridge semantic gap between query tokens and users' search intent. Early\nmethods of query reformulation mostly used statistical measures derived from\ntoken co-occurrence frequencies from selective user sessions having clicks or\npurchases. In recent years, supervised deep learning approaches, specifically\ntransformer-based neural language models, or sequence-to-sequence models are\nbeing used for query reformulation task. However, these models do not utilize\nthe semantic tags of a query token, which are significant for capturing user\nintent of an e-commerce query. In this work, we pose query reformulation as a\ntoken classification task, and solve this task by designing a dependency-aware\ntransformer-based language model, TagBERT, which makes use of semantic tags of\na token for learning superior query phrase embedding. Experiments on large,\nreal-life e-commerce datasets show that TagBERT exhibits superior performance\nthan plethora of competing models, including BERT, eBERT, and\nSequence-to-Sequence transformer model for important token classification task.", "published": "2025-07-14 15:25:13", "link": "http://arxiv.org/abs/2507.10385v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Dynamical stability for dense patterns in discrete attractor neural networks", "abstract": "Neural networks storing multiple discrete attractors are canonical models of\nbiological memory. Previously, the dynamical stability of such networks could\nonly be guaranteed under highly restrictive conditions. Here, we derive a\ntheory of the local stability of discrete fixed points in a broad class of\nnetworks with graded neural activities and in the presence of noise. By\ndirectly analyzing the bulk and outliers of the Jacobian spectrum, we show that\nall fixed points are stable below a critical load that is distinct from the\nclassical \\textit{critical capacity} and depends on the statistics of neural\nactivities in the fixed points as well as the single-neuron activation\nfunction. Our analysis highlights the computational benefits of\nthreshold-linear activation and sparse-like patterns.", "published": "2025-07-14 15:23:24", "link": "http://arxiv.org/abs/2507.10383v1", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG", "cs.NE", "q-bio.NC"], "primary_category": "cond-mat.dis-nn"}
{"title": "Leveraging RAG-LLMs for Urban Mobility Simulation and Analysis", "abstract": "With the rise of smart mobility and shared e-mobility services, numerous\nadvanced technologies have been applied to this field. Cloud-based traffic\nsimulation solutions have flourished, offering increasingly realistic\nrepresentations of the evolving mobility landscape. LLMs have emerged as\npioneering tools, providing robust support for various applications, including\nintelligent decision-making, user interaction, and real-time traffic analysis.\nAs user demand for e-mobility continues to grow, delivering comprehensive\nend-to-end solutions has become crucial. In this paper, we present a\ncloud-based, LLM-powered shared e-mobility platform, integrated with a mobile\napplication for personalized route recommendations. The optimization module is\nevaluated based on travel time and cost across different traffic scenarios.\nAdditionally, the LLM-powered RAG framework is evaluated at the schema level\nfor different users, using various evaluation methods. Schema-level RAG with\nXiYanSQL achieves an average execution accuracy of 0.81 on system operator\nqueries and 0.98 on user queries.", "published": "2025-07-14 15:23:11", "link": "http://arxiv.org/abs/2507.10382v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Enhanced DeepONet for 1-D consolidation operator learning: an architectural investigation", "abstract": "Deep Operator Networks (DeepONets) have emerged as a powerful surrogate\nmodeling framework for learning solution operators in PDE-governed systems.\nWhile their use is expanding across engineering disciplines, applications in\ngeotechnical engineering remain limited. This study systematically evaluates\nseveral DeepONet architectures for the one-dimensional consolidation problem.\nWe initially consider three architectures: a standard DeepONet with the\ncoefficient of consolidation embedded in the branch net (Models 1 and 2), and a\nphysics-inspired architecture with the coefficient embedded in the trunk net\n(Model 3). Results show that Model 3 outperforms the standard configurations\n(Models 1 and 2) but still has limitations when the target solution (excess\npore pressures) exhibits significant variation. To overcome this limitation, we\npropose a Trunknet Fourier feature-enhanced DeepONet (Model 4) that addresses\nthe identified limitations by capturing rapidly varying functions. All proposed\narchitectures achieve speedups ranging from 1.5 to 100 times over traditional\nexplicit and implicit solvers, with Model 4 being the most efficient. Larger\ncomputational savings are expected for more complex systems than the explored\n1D case, which is promising. Overall, the study highlights the potential of\nDeepONets to enable efficient, generalizable surrogate modeling in geotechnical\napplications, advancing the integration of scientific machine learning in\ngeotechnics, which is at an early stage.", "published": "2025-07-14 15:09:58", "link": "http://arxiv.org/abs/2507.10368v1", "categories": ["cs.LG", "physics.geo-ph"], "primary_category": "cs.LG"}
{"title": "Parallel Sampling of Diffusion Models on $SO(3)$", "abstract": "In this paper, we design an algorithm to accelerate the diffusion process on\nthe $SO(3)$ manifold. The inherently sequential nature of diffusion models\nnecessitates substantial time for denoising perturbed data. To overcome this\nlimitation, we proposed to adapt the numerical Picard iteration for the $SO(3)$\nspace. We demonstrate our algorithm on an existing method that employs\ndiffusion models to address the pose ambiguity problem. Moreover, we show that\nthis acceleration advantage occurs without any measurable degradation in task\nreward. The experiments reveal that our algorithm achieves a speed-up of up to\n4.9$\\times$, significantly reducing the latency for generating a single sample.", "published": "2025-07-14 14:51:02", "link": "http://arxiv.org/abs/2507.10347v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Some Super-approximation Rates of ReLU Neural Networks for Korobov Functions", "abstract": "This paper examines the $L_p$ and $W^1_p$ norm approximation errors of ReLU\nneural networks for Korobov functions. In terms of network width and depth, we\nderive nearly optimal super-approximation error bounds of order $2m$ in the\n$L_p$ norm and order $2m-2$ in the $W^1_p$ norm, for target functions with\n$L_p$ mixed derivative of order $m$ in each direction. The analysis leverages\nsparse grid finite elements and the bit extraction technique. Our results\nimprove upon classical lowest order $L_\\infty$ and $H^1$ norm error bounds and\ndemonstrate that the expressivity of neural networks is largely unaffected by\nthe curse of dimensionality.", "published": "2025-07-14 14:48:47", "link": "http://arxiv.org/abs/2507.10345v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MoCap-Impute: A Comprehensive Benchmark and Comparative Analysis of Imputation Methods for IMU-based Motion Capture Data", "abstract": "Motion capture (MoCap) data from wearable Inertial Measurement Units (IMUs)\nis vital for applications in sports science, but its utility is often\ncompromised by missing data. Despite numerous imputation techniques, a\nsystematic performance evaluation for IMU-derived MoCap time-series data is\nlacking. We address this gap by conducting a comprehensive comparative analysis\nof statistical, machine learning, and deep learning imputation methods. Our\nevaluation considers three distinct contexts: univariate time-series,\nmultivariate across subjects, and multivariate across kinematic angles. To\nfacilitate this benchmark, we introduce the first publicly available MoCap\ndataset designed specifically for imputation, featuring data from 53 karate\npractitioners. We simulate three controlled missingness mechanisms: missing\ncompletely at random (MCAR), block missingness, and a novel value-dependent\npattern at signal transition points. Our experiments, conducted on 39 kinematic\nvariables across all subjects, reveal that multivariate imputation frameworks\nconsistently outperform univariate approaches, particularly for complex\nmissingness. For instance, multivariate methods achieve up to a 50% mean\nabsolute error reduction (MAE from 10.8 to 5.8) compared to univariate\ntechniques for transition point missingness. Advanced models like Generative\nAdversarial Imputation Networks (GAIN) and Iterative Imputers demonstrate the\nhighest accuracy in these challenging scenarios. This work provides a critical\nbaseline for future research and offers practical recommendations for improving\nthe integrity and robustness of Mo-Cap data analysis.", "published": "2025-07-14 14:41:19", "link": "http://arxiv.org/abs/2507.10334v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Convergence of Agnostic Federated Averaging", "abstract": "Federated learning (FL) enables decentralized model training without\ncentralizing raw data. However, practical FL deployments often face a key\nrealistic challenge: Clients participate intermittently in server aggregation\nand with unknown, possibly biased participation probabilities. Most existing\nconvergence results either assume full-device participation, or rely on\nknowledge of (in fact uniform) client availability distributions -- assumptions\nthat rarely hold in practice. In this work, we characterize the optimization\nproblem that consistently adheres to the stochastic dynamics of the well-known\n\\emph{agnostic Federated Averaging (FedAvg)} algorithm under random (and\nvariably-sized) client availability, and rigorously establish its convergence\nfor convex, possibly nonsmooth losses, achieving a standard rate of order\n$\\mathcal{O}(1/\\sqrt{T})$, where $T$ denotes the aggregation horizon. Our\nanalysis provides the first convergence guarantees for agnostic FedAvg under\ngeneral, non-uniform, stochastic client participation, without knowledge of the\nparticipation distribution. We also empirically demonstrate that agnostic\nFedAvg in fact outperforms common (and suboptimal) weighted aggregation FedAvg\nvariants, even with server-side knowledge of participation weights.", "published": "2025-07-14 14:32:46", "link": "http://arxiv.org/abs/2507.10325v1", "categories": ["cs.LG", "cs.DC", "eess.SP"], "primary_category": "cs.LG"}
{"title": "MF-GLaM: A multifidelity stochastic emulator using generalized lambda models", "abstract": "Stochastic simulators exhibit intrinsic stochasticity due to unobservable,\nuncontrollable, or unmodeled input variables, resulting in random outputs even\nat fixed input conditions. Such simulators are common across various scientific\ndisciplines; however, emulating their entire conditional probability\ndistribution is challenging, as it is a task traditional deterministic\nsurrogate modeling techniques are not designed for. Additionally, accurately\ncharacterizing the response distribution can require prohibitively large\ndatasets, especially for computationally expensive high-fidelity (HF)\nsimulators. When lower-fidelity (LF) stochastic simulators are available, they\ncan enhance limited HF information within a multifidelity surrogate modeling\n(MFSM) framework. While MFSM techniques are well-established for deterministic\nsettings, constructing multifidelity emulators to predict the full conditional\nresponse distribution of stochastic simulators remains a challenge. In this\npaper, we propose multifidelity generalized lambda models (MF-GLaMs) to\nefficiently emulate the conditional response distribution of HF stochastic\nsimulators by exploiting data from LF stochastic simulators. Our approach\nbuilds upon the generalized lambda model (GLaM), which represents the\nconditional distribution at each input by a flexible, four-parameter\ngeneralized lambda distribution. MF-GLaMs are non-intrusive, requiring no\naccess to the internal stochasticity of the simulators nor multiple\nreplications of the same input values. We demonstrate the efficacy of MF-GLaM\nthrough synthetic examples of increasing complexity and a realistic earthquake\napplication. Results show that MF-GLaMs can achieve improved accuracy at the\nsame cost as single-fidelity GLaMs, or comparable performance at significantly\nreduced cost.", "published": "2025-07-14 14:06:56", "link": "http://arxiv.org/abs/2507.10303v1", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Average Sensitivity of Hierarchical $k$-Median Clustering", "abstract": "Hierarchical clustering is a widely used method for unsupervised learning\nwith numerous applications. However, in the application of modern algorithms,\nthe datasets studied are usually large and dynamic. If the hierarchical\nclustering is sensitive to small perturbations of the dataset, the usability of\nthe algorithm will be greatly reduced. In this paper, we focus on the\nhierarchical $k$ -median clustering problem, which bridges hierarchical and\ncentroid-based clustering while offering theoretical appeal, practical utility,\nand improved interpretability. We analyze the average sensitivity of algorithms\nfor this problem by measuring the expected change in the output when a random\ndata point is deleted. We propose an efficient algorithm for hierarchical\n$k$-median clustering and theoretically prove its low average sensitivity and\nhigh clustering quality. Additionally, we show that single linkage clustering\nand a deterministic variant of the CLNSS algorithm exhibit high average\nsensitivity, making them less stable. Finally, we validate the robustness and\neffectiveness of our algorithm through experiments.", "published": "2025-07-14 14:02:31", "link": "http://arxiv.org/abs/2507.10296v1", "categories": ["cs.LG", "cs.DS"], "primary_category": "cs.LG"}
{"title": "Conditional Chemical Language Models are Versatile Tools in Drug Discovery", "abstract": "Generative chemical language models (CLMs) have demonstrated strong\ncapabilities in molecular design, yet their impact in drug discovery remains\nlimited by the absence of reliable reward signals and the lack of\ninterpretability in their outputs. We present SAFE-T, a generalist chemical\nmodeling framework that conditions on biological context -- such as protein\ntargets or mechanisms of action -- to prioritize and design molecules without\nrelying on structural information or engineered scoring functions. SAFE-T\nmodels the conditional likelihood of fragment-based molecular sequences given a\nbiological prompt, enabling principled scoring of molecules across tasks such\nas virtual screening, drug-target interaction prediction, and activity cliff\ndetection. Moreover, it supports goal-directed generation by sampling from this\nlearned distribution, aligning molecular design with biological objectives. In\ncomprehensive zero-shot evaluations across predictive (LIT-PCBA, DAVIS, KIBA,\nACNet) and generative (DRUG, PMO) benchmarks, SAFE-T consistently achieves\nperformance comparable to or better than existing approaches while being\nsignificantly faster. Fragment-level attribution further reveals that SAFE-T\ncaptures known structure-activity relationships, supporting interpretable and\nbiologically grounded design. Together with its computational efficiency, these\nresults demonstrate that conditional generative CLMs can unify scoring and\ngeneration to accelerate early-stage drug discovery.", "published": "2025-07-14 13:42:39", "link": "http://arxiv.org/abs/2507.10273v1", "categories": ["cs.LG", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "DNS Tunneling: Threat Landscape and Improved Detection Solutions", "abstract": "Detecting Domain Name System (DNS) tunneling is a significant challenge in\nsecurity due to its capacity to hide harmful actions within DNS traffic that\nappears to be normal and legitimate. Traditional detection methods are based on\nrule-based approaches or signature matching methods that are often insufficient\nto accurately identify such covert communication channels. This research is\nabout effectively detecting DNS tunneling. We propose a novel approach to\ndetect DNS tunneling with machine learning algorithms. We combine machine\nlearning algorithms to analyze the traffic by using features extracted from DNS\ntraffic. Analyses results show that the proposed approach is a good candidate\nto detect DNS tunneling accurately.", "published": "2025-07-14 13:37:48", "link": "http://arxiv.org/abs/2507.10267v1", "categories": ["cs.CR", "cs.LG", "cs.NI"], "primary_category": "cs.CR"}
{"title": "Kernel-Adaptive PI-ELMs for Forward and Inverse Problems in PDEs with Sharp Gradients", "abstract": "This paper introduces the Kernel Adaptive Physics-Informed Extreme Learning\nMachine (KAPI-ELM), an adaptive Radial Basis Function (RBF)-based extension of\nPI-ELM designed to solve both forward and inverse Partial Differential Equation\n(PDE) problems involving localized sharp gradients. While PI-ELMs outperform\nthe traditional Physics-Informed Neural Networks (PINNs) in speed due to their\nsingle-shot, least square optimization, this advantage comes at a cost: their\nfixed, randomly initialized input layer limits their ability to capture sharp\ngradients. To overcome this limitation, we introduce a lightweight Bayesian\nOptimization (BO) framework that, instead of adjusting each input layer\nparameter individually as in traditional backpropagation, learns a small set of\nhyperparameters defining the statistical distribution from which the input\nweights are drawn. This novel distributional optimization strategy -- combining\nBO for input layer distributional parameters with least-squares optimization\nfor output layer network parameters -- enables KAPI-ELM to preserve PI-ELM's\nspeed while matching or exceeding the expressiveness of PINNs. We validate the\nproposed methodology on several challenging forward and inverse PDE benchmarks,\nincluding a 1D singularly perturbed convection-diffusion equation, a 2D Poisson\nequation with sharp localized sources, and a time-dependent advection equation.\nNotably, KAPI-ELM achieves state-of-the-art accuracy in both forward and\ninverse settings. In stiff PDE regimes, it matches or even outperforms advanced\nmethods such as the Extended Theory of Functional Connections (XTFC), while\nrequiring nearly an order of magnitude fewer tunable parameters. These results\nestablish the potential of KAPI-ELM as a scalable, interpretable, and\ngeneralizable physics-informed learning framework, especially in stiff PDE\nregimes.", "published": "2025-07-14 13:03:53", "link": "http://arxiv.org/abs/2507.10241v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Graph Sufficiency Perspective for Neural Networks", "abstract": "This paper analyzes neural networks through graph variables and statistical\nsufficiency. We interpret neural network layers as graph-based transformations,\nwhere neurons act as pairwise functions between inputs and learned anchor\npoints. Within this formulation, we establish conditions under which layer\noutputs are sufficient for the layer inputs, that is, each layer preserves the\nconditional distribution of the target variable given the input variable. Under\ndense anchor point assumptions, we prove that asymptotic sufficiency holds in\nthe infinite-width limit and is preserved throughout training. To align more\nclosely with practical architectures, we further show that sufficiency can be\nachieved with finite-width networks by assuming region-separated input\ndistributions and constructing appropriate anchor points. Our framework covers\nfully connected layers, general pairwise functions, ReLU and sigmoid\nactivations, and convolutional neural networks. This work bridges statistical\nsufficiency, graph-theoretic representations, and deep learning, providing a\nnew statistical understanding of neural networks.", "published": "2025-07-14 12:31:47", "link": "http://arxiv.org/abs/2507.10215v1", "categories": ["cs.LG", "stat.AP"], "primary_category": "cs.LG"}
{"title": "History Matching under Uncertainty of Geological Scenarios with Implicit Geological Realism Control with Generative Deep Learning and Graph Convolutions", "abstract": "The graph-based variational autoencoder represents an architecture that can\nhandle the uncertainty of different geological scenarios, such as depositional\nor structural, through the concept of a lowerdimensional latent space. The main\ndifference from recent studies is utilisation of a graph-based approach in\nreservoir modelling instead of the more traditional lattice-based deep learning\nmethods. We provide a solution to implicitly control the geological realism\nthrough the latent variables of a generative model and Geodesic metrics. Our\nexperiments of AHM with synthetic dataset that consists of 3D realisations of\nchannelised geological representations with two distinct scenarios with one and\ntwo channels shows the viability of the approach. We offer in-depth analysis of\nthe latent space using tools such as PCA, t-SNE, and TDA to illustrate its\nstructure.", "published": "2025-07-14 12:14:17", "link": "http://arxiv.org/abs/2507.10201v1", "categories": ["stat.AP", "cs.LG", "physics.data-an"], "primary_category": "stat.AP"}
{"title": "T-GRAB: A Synthetic Diagnostic Benchmark for Learning on Temporal Graphs", "abstract": "Dynamic graph learning methods have recently emerged as powerful tools for\nmodelling relational data evolving through time. However, despite extensive\nbenchmarking efforts, it remains unclear whether current Temporal Graph Neural\nNetworks (TGNNs) effectively capture core temporal patterns such as\nperiodicity, cause-and-effect, and long-range dependencies. In this work, we\nintroduce the Temporal Graph Reasoning Benchmark (T-GRAB), a comprehensive set\nof synthetic tasks designed to systematically probe the capabilities of TGNNs\nto reason across time. T-GRAB provides controlled, interpretable tasks that\nisolate key temporal skills: counting/memorizing periodic repetitions,\ninferring delayed causal effects, and capturing long-range dependencies over\nboth spatial and temporal dimensions. We evaluate 11 temporal graph learning\nmethods on these tasks, revealing fundamental shortcomings in their ability to\ngeneralize temporal patterns. Our findings offer actionable insights into the\nlimitations of current models, highlight challenges hidden by traditional\nreal-world benchmarks, and motivate the development of architectures with\nstronger temporal reasoning abilities. The code for T-GRAB can be found at:\nhttps://github.com/alirezadizaji/T-GRAB.", "published": "2025-07-14 11:47:43", "link": "http://arxiv.org/abs/2507.10183v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Pimba: A Processing-in-Memory Acceleration for Post-Transformer Large Language Model Serving", "abstract": "Transformers are the driving force behind today's Large Language Models\n(LLMs), serving as the foundation for their performance and versatility. Yet,\ntheir compute and memory costs grow with sequence length, posing scalability\nchallenges for long-context inferencing. In response, the algorithm community\nis exploring alternative architectures, such as state space models (SSMs),\nlinear attention, and recurrent neural networks (RNNs), which we refer to as\npost-transformers. This shift presents a key challenge: building a serving\nsystem that efficiently supports both transformer and post-transformer LLMs\nwithin a unified framework. To address this challenge, we analyze the\nperformance characteristics of transformer and post-transformer LLMs. Despite\ntheir algorithmic differences, both are fundamentally limited by memory\nbandwidth under batched inference due to attention in transformers and state\nupdates in post-transformers. Further analyses suggest two additional insights:\n(1) state update operations, unlike attention, incur high hardware cost, making\nper-bank PIM acceleration inefficient, and (2) different low-precision\narithmetic methods offer varying accuracy-area tradeoffs, while we identify\nMicrosoft's MX as the Pareto-optimal choice. Building on these insights, we\ndesign Pimba as an array of State-update Processing Units (SPUs), each shared\nbetween two banks to enable interleaved access to PIM. Each SPU includes a\nState-update Processing Engine (SPE) that comprises element-wise multipliers\nand adders using MX-based quantized arithmetic, enabling efficient execution of\nstate update and attention operations. Our evaluation shows that, compared to\nLLM-optimized GPU and GPU+PIM systems, Pimba achieves up to 3.2x and 2.1x\nhigher token generation throughput, respectively.", "published": "2025-07-14 11:40:17", "link": "http://arxiv.org/abs/2507.10178v1", "categories": ["cs.AR", "cs.LG"], "primary_category": "cs.AR"}
{"title": "Understanding the Rank of Tensor Networks via an Intuitive Example-Driven Approach", "abstract": "Tensor Network (TN) decompositions have emerged as an indispensable tool in\nBig Data analytics owing to their ability to provide compact low-rank\nrepresentations, thus alleviating the ``Curse of Dimensionality'' inherent in\nhandling higher-order data. At the heart of their success lies the concept of\nTN ranks, which governs the efficiency and expressivity of TN decompositions.\nHowever, unlike matrix ranks, TN ranks often lack a universal meaning and an\nintuitive interpretation, with their properties varying significantly across\ndifferent TN structures. Consequently, TN ranks are frequently treated as\nempirically tuned hyperparameters, rather than as key design parameters\ninferred from domain knowledge. The aim of this Lecture Note is therefore to\ndemystify the foundational yet frequently misunderstood concept of TN ranks\nthrough real-life examples and intuitive visualizations. We begin by\nillustrating how domain knowledge can guide the selection of TN ranks in\nwidely-used models such as the Canonical Polyadic (CP) and Tucker\ndecompositions. For more complex TN structures, we employ a self-explanatory\ngraphical approach that generalizes to tensors of arbitrary order. Such a\nperspective naturally reveals the relationship between TN ranks and the\ncorresponding ranks of tensor unfoldings (matrices), thereby circumventing\ncumbersome multi-index tensor algebra while facilitating domain-informed TN\ndesign. It is our hope that this Lecture Note will equip readers with a clear\nand unified understanding of the concept of TN rank, along with the necessary\nphysical insight and intuition to support the selection, explainability, and\ndeployment of tensor methods in both practical applications and educational\ncontexts.", "published": "2025-07-14 11:33:14", "link": "http://arxiv.org/abs/2507.10170v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Domain Borders Are There to Be Crossed With Federated Few-Shot Adaptation", "abstract": "Federated Learning has emerged as a leading paradigm for decentralized,\nprivacy-preserving learning, particularly relevant in the era of interconnected\nedge devices equipped with sensors. However, the practical implementation of\nFederated Learning faces three primary challenges: the need for human\ninvolvement in costly data labelling processes for target adaptation, covariate\nshift in client device data collection due to environmental factors affecting\nsensors, leading to discrepancies between source and target samples, and the\nimpracticality of continuous or regular model updates in resource-constrained\nenvironments due to limited data transmission capabilities and technical\nconstraints on channel availability and energy efficiency. To tackle these\nissues, we expand upon an efficient and scalable Federated Learning framework\ntailored for real-world client adaptation in industrial settings. This\nframework leverages a pre-trained source model comprising a deep backbone, an\nadaptation module, and a classifier running on a powerful server. By freezing\nthe backbone and classifier during client adaptation on resource-constrained\ndevices, we allow the domain adaptive linear layer to handle target domain\nadaptation, thus minimizing overall computational overhead. Furthermore, this\nsetup, designated as FedAcross+, is extended to encompass the processing of\nstreaming data, thereby rendering the solution suitable for non-stationary\nenvironments. Extensive experimental results demonstrate the effectiveness of\nFedAcross+ in achieving competitive adaptation on low-end client devices with\nlimited target samples, successfully addressing the challenge of domain shift.\nMoreover, our framework accommodates sporadic model updates within\nresource-constrained environments, ensuring practical and seamless deployment.", "published": "2025-07-14 11:18:33", "link": "http://arxiv.org/abs/2507.10160v1", "categories": ["cs.LG", "cs.CR", "cs.DC"], "primary_category": "cs.LG"}
{"title": "MTF-Grasp: A Multi-tier Federated Learning Approach for Robotic Grasping", "abstract": "Federated Learning (FL) is a promising machine learning paradigm that enables\nparticipating devices to train privacy-preserved and collaborative models. FL\nhas proven its benefits for robotic manipulation tasks. However, grasping tasks\nlack exploration in such settings where robots train a global model without\nmoving data and ensuring data privacy. The main challenge is that each robot\nlearns from data that is nonindependent and identically distributed (non-IID)\nand of low quantity. This exhibits performance degradation, particularly in\nrobotic grasping. Thus, in this work, we propose MTF-Grasp, a multi-tier FL\napproach for robotic grasping, acknowledging the unique challenges posed by the\nnon-IID data distribution across robots, including quantitative skewness.\nMTF-Grasp harnesses data quality and quantity across robots to select a set of\n\"top-level\" robots with better data distribution and higher sample count. It\nthen utilizes top-level robots to train initial seed models and distribute them\nto the remaining \"low-level\" robots, reducing the risk of model performance\ndegradation in low-level robots. Our approach outperforms the conventional FL\nsetup by up to 8% on the quantity-skewed Cornell and Jacquard grasping\ndatasets.", "published": "2025-07-14 11:17:28", "link": "http://arxiv.org/abs/2507.10158v1", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Simulating Biases for Interpretable Fairness in Offline and Online Classifiers", "abstract": "Predictive models often reinforce biases which were originally embedded in\ntheir training data, through skewed decisions. In such cases, mitigation\nmethods are critical to ensure that, regardless of the prevailing disparities,\nmodel outcomes are adjusted to be fair. To assess this, datasets could be\nsystematically generated with specific biases, to train machine learning\nclassifiers. Then, predictive outcomes could aid in the understanding of this\nbias embedding process. Hence, an agent-based model (ABM), depicting a loan\napplication process that represents various systemic biases across two\ndemographic groups, was developed to produce synthetic datasets. Then, by\napplying classifiers trained on them to predict loan outcomes, we can assess\nhow biased data leads to unfairness. This highlights a main contribution of\nthis work: a framework for synthetic dataset generation with controllable bias\ninjection. We also contribute with a novel explainability technique, which\nshows how mitigations affect the way classifiers leverage data features, via\nsecond-order Shapley values. In experiments, both offline and online learning\napproaches are employed. Mitigations are applied at different stages of the\nmodelling pipeline, such as during pre-processing and in-processing.", "published": "2025-07-14 11:04:24", "link": "http://arxiv.org/abs/2507.10154v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Large-Scale Graph Building in Dynamic Environments: Low Latency and High Quality", "abstract": "Learning and constructing large-scale graphs has attracted attention in\nrecent decades, resulting in a rich literature that introduced various systems,\ntools, and algorithms. Grale is one of such tools that is designed for offline\nenvironments and is deployed in more than 50 different industrial settings at\nGoogle. Grale is widely applicable because of its ability to efficiently learn\nand construct a graph on datasets with multiple types of features. However, it\nis often the case that applications require the underlying data to evolve\ncontinuously and rapidly and the updated graph needs to be available with low\nlatency. Such setting make the use of Grale prohibitive. While there are\nApproximate Nearest Neighbor (ANN) systems that handle dynamic updates with low\nlatency, they are mostly limited to similarities over a single embedding.\n  In this work, we introduce a system that inherits the advantages and the\nquality of Grale, and maintains a graph construction in a dynamic setting with\ntens of milliseconds of latency per request. We call the system Dynamic Grale\nUsing ScaNN (Dynamic GUS). Our system has a wide range of applications with\nover 10 deployments at Google. One of the applications is in Android Security\nand Privacy, where Dynamic Grale Using ScaNN enables capturing harmful\napplications 4 times faster, before they can reach users.", "published": "2025-07-14 10:36:15", "link": "http://arxiv.org/abs/2507.10139v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Towards High Supervised Learning Utility Training Data Generation: Data Pruning and Column Reordering", "abstract": "Tabular data synthesis for supervised learning ('SL') model training is\ngaining popularity in industries such as healthcare, finance, and retail.\nDespite the progress made in tabular data generators, models trained with\nsynthetic data often underperform compared to those trained with original data.\nThis low SL utility of synthetic data stems from class imbalance exaggeration\nand SL data relationship overlooked by tabular generator. To address these\nchallenges, we draw inspirations from techniques in emerging data-centric\nartificial intelligence and elucidate Pruning and ReOrdering ('PRRO'), a novel\npipeline that integrates data-centric techniques into tabular data synthesis.\nPRRO incorporates data pruning to guide the table generator towards\nobservations with high signal-to-noise ratio, ensuring that the class\ndistribution of synthetic data closely matches that of the original data.\nBesides, PRRO employs a column reordering algorithm to align the data modeling\nstructure of generators with that of SL models. These two modules enable PRRO\nto optimize SL utility of synthetic data. Empirical experiments on 22 public\ndatasets show that synthetic data generated using PRRO enhances predictive\nperformance compared to data generated without PRRO. Specifically, synthetic\nreplacement of original data yields an average improvement of 26.74% and up to\n871.46% improvement using PRRO, while synthetic appendant to original data\nresults with PRRO-generated data results in an average improvement of 6.13% and\nup to 200.32%. Furthermore, experiments on six highly imbalanced datasets show\nthat PRRO enables the generator to produce synthetic data with a class\ndistribution that resembles the original data more closely, achieving a\nsimilarity improvement of 43%. Through PRRO, we foster a seamless integration\nof data synthesis to subsequent SL prediction, promoting quality and accessible\ndata analysis.", "published": "2025-07-14 09:15:22", "link": "http://arxiv.org/abs/2507.10088v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Compression Method for Deep Diagonal State Space Model Based on $H^2$ Optimal Reduction", "abstract": "Deep learning models incorporating linear SSMs have gained attention for\ncapturing long-range dependencies in sequential data. However, their large\nparameter sizes pose challenges for deployment on resource-constrained devices.\nIn this study, we propose an efficient parameter reduction method for these\nmodels by applying $H^{2}$ model order reduction techniques from control theory\nto their linear SSM components. In experiments, the LRA benchmark results show\nthat the model compression based on our proposed method outperforms an existing\nmethod using the Balanced Truncation, while successfully reducing the number of\nparameters in the SSMs to $1/32$ without sacrificing the performance of the\noriginal models.", "published": "2025-07-14 09:03:44", "link": "http://arxiv.org/abs/2507.10078v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "ElasticMM: Efficient Multimodal LLMs Serving with Elastic Multimodal Parallelism", "abstract": "Multimodal large language models (MLLMs) extend LLMs to handle images,\nvideos, and audio by incorporating feature extractors and projection modules.\nHowever, these additional components -- combined with complex inference\npipelines and heterogeneous workloads -- introduce significant inference\noverhead. Therefore, efficiently serving MLLMs remains a major challenge.\nCurrent tightly coupled serving architectures struggle to distinguish between\nmixed request types or adapt parallelism strategies to different inference\nstages, leading to increased time-to-first-token (TTFT) latency and poor\nresource utilization. To address this, we propose Elastic Multimodal\nParallelism (EMP), a new serving paradigm that elastically adapts to resource\nheterogeneity across request types and inference stages. Building upon EMP, we\ndevelop ElasticMM, an MLLM serving system that (1) separates requests into\nindependent modality groups with dynamic resource allocation via a\nmodality-aware load balancer; (2) decouples inference stages and enables\nparallelism adjustment and adaptive scaling via elastic partition scheduling;\nand (3) improves inference efficiency through unified multimodal prefix caching\nand non-blocking encoding. Experiments on diverse real-world datasets show that\nElasticMM outperforms state-of-the-art (SOTA) serving systems, reducing TTFT by\nup to 4.2x and achieving 3.2-4.5x higher throughput while meeting service-level\nobjectives (SLOs).", "published": "2025-07-14 08:53:48", "link": "http://arxiv.org/abs/2507.10069v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "On the Efficiency of Training Robust Decision Trees", "abstract": "As machine learning gets adopted into the industry quickly, trustworthiness\nis increasingly in focus. Yet, efficiency and sustainability of robust training\npipelines still have to be established. In this work, we consider a simple\npipeline for training adversarially robust decision trees and investigate the\nefficiency of each step. Our pipeline consists of three stages. Firstly, we\nchoose the perturbation size automatically for each dataset. For that, we\nintroduce a simple algorithm, instead of relying on intuition or prior work.\nMoreover, we show that the perturbation size can be estimated from smaller\nmodels than the one intended for full training, and thus significant gains in\nefficiency can be achieved. Secondly, we train state-of-the-art adversarial\ntraining methods and evaluate them regarding both their training time and\nadversarial accuracy. Thirdly, we certify the robustness of each of the models\nthus obtained and investigate the time required for this. We find that\nverification time, which is critical to the efficiency of the full pipeline, is\nnot correlated with training time.", "published": "2025-07-14 08:27:42", "link": "http://arxiv.org/abs/2507.10048v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Applying Large Language Models to Complement Single-Cell Foundation Models", "abstract": "Single-cell foundation models such as scGPT represent a significant\nadvancement in single-cell omics, with an ability to achieve state-of-the-art\nperformance on various downstream biological tasks. However, these models are\ninherently limited in that a vast amount of information in biology exists as\ntext, which they are unable to leverage. There have therefore been several\nrecent works that propose the use of LLMs as an alternative to single-cell\nfoundation models, achieving competitive results. However, there is little\nunderstanding of what factors drive this performance, along with a strong focus\non using LLMs as an alternative, rather than complementary approach to\nsingle-cell foundation models. In this study, we therefore investigate what\nbiological insights contribute toward the performance of LLMs when applied to\nsingle-cell data, and introduce scMPT; a model which leverages synergies\nbetween scGPT, and single-cell representations from LLMs that capture these\ninsights. scMPT demonstrates stronger, more consistent performance than either\nof its component models, which frequently have large performance gaps between\neach other across datasets. We also experiment with alternate fusion methods,\ndemonstrating the potential of combining specialized reasoning models with\nscGPT to improve performance. This study ultimately showcases the potential for\nLLMs to complement single-cell foundation models and drive improvements in\nsingle-cell analysis.", "published": "2025-07-14 08:16:58", "link": "http://arxiv.org/abs/2507.10039v1", "categories": ["cs.LG", "q-bio.GN"], "primary_category": "cs.LG"}
{"title": "Forecasting Coccidioidomycosis (Valley Fever) in Arizona: A Graph Neural Network Approach", "abstract": "Coccidioidomycosis, commonly known as Valley Fever, remains a significant\npublic health concern in endemic regions of the southwestern United States.\nThis study develops the first graph neural network (GNN) model for forecasting\nValley Fever incidence in Arizona. The model integrates surveillance case data\nwith environmental predictors using graph structures, including soil\nconditions, atmospheric variables, agricultural indicators, and air quality\nmetrics. Our approach explores correlation-based relationships among variables\ninfluencing disease transmission. The model captures critical delays in disease\nprogression through lagged effects, enhancing its capacity to reflect complex\ntemporal dependencies in disease ecology. Results demonstrate that the GNN\narchitecture effectively models Valley Fever trends and provides insights into\nkey environmental drivers of disease incidence. These findings can inform early\nwarning systems and guide resource allocation for disease prevention efforts in\nhigh-risk areas.", "published": "2025-07-14 07:50:25", "link": "http://arxiv.org/abs/2507.10014v1", "categories": ["cs.LG", "92D30, 62M10, 68T07", "G.3; I.6.3; I.2.6; I.5.1"], "primary_category": "cs.LG"}
{"title": "Effects of structural properties of neural networks on machine learning performance", "abstract": "In recent years, graph-based machine learning techniques, such as\nreinforcement learning and graph neural networks, have garnered significant\nattention. While some recent studies have started to explore the relationship\nbetween the graph structure of neural networks and their predictive\nperformance, they often limit themselves to a narrow range of model networks,\nparticularly lacking mesoscale structures such as communities. Our work\nadvances this area by conducting a more comprehensive investigation,\nincorporating realistic network structures characterized by heterogeneous\ndegree distributions and community structures, which are typical\ncharacteristics of many real networks. These community structures offer a\nnuanced perspective on network architecture. Our analysis employs model\nnetworks such as random and scale-free networks, alongside a comparison with a\nbiological neural network and its subsets for more detailed analysis. We\nexamine the impact of these structural attributes on the performance of image\nclassification tasks. Our findings reveal that structural properties do affect\nperformance to some extent. Specifically, networks featuring coherent, densely\ninterconnected communities demonstrate enhanced learning capabilities. The\ncomparison with the biological neural network emphasizes the relevance of our\nfindings to real-world structures, suggesting an intriguing connection worth\nfurther exploration. This study contributes meaningfully to network science and\nmachine learning, providing insights that could inspire the design of more\nbiologically informed neural networks.", "published": "2025-07-14 07:39:19", "link": "http://arxiv.org/abs/2507.10005v1", "categories": ["cs.LG", "cond-mat.stat-mech", "cs.NE", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Compliance Minimization via Physics-Informed Gaussian Processes", "abstract": "Machine learning (ML) techniques have recently gained significant attention\nfor solving compliance minimization (CM) problems. However, these methods\ntypically provide poor feature boundaries, are very expensive, and lack a\nsystematic mechanism to control the design complexity. Herein, we address these\nlimitations by proposing a mesh-free and simultaneous framework based on\nphysics-informed Gaussian processes (GPs). In our approach, we parameterize the\ndesign and state variables with GP priors which have independent kernels but\nshare a multi-output neural network (NN) as their mean function. The\narchitecture of this NN is based on Parametric Grid Convolutional Attention\nNetworks (PGCANs) which not only mitigate spectral bias issues, but also\nprovide an interpretable mechanism to control design complexity. We estimate\nall the parameters of our GP-based representations by simultaneously minimizing\nthe compliance, total potential energy, and residual of volume fraction\nconstraint. Importantly, our loss function exclude all data-based residuals as\nGPs automatically satisfy them. We also develop computational schemes based on\ncurriculum training and numerical integration to increase the efficiency and\nrobustness of our approach which is shown to (1) produce super-resolution\ntopologies with fast convergence, (2) achieve smaller compliance and less gray\narea fraction compared to traditional numerical methods, (3) provide control\nover fine-scale features, and (4) outperform competing ML-based methods.", "published": "2025-07-14 06:34:29", "link": "http://arxiv.org/abs/2507.09968v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Text-Driven Causal Representation Learning for Source-Free Domain Generalization", "abstract": "Deep learning often struggles when training and test data distributions\ndiffer. Traditional domain generalization (DG) tackles this by including data\nfrom multiple source domains, which is impractical due to expensive data\ncollection and annotation. Recent vision-language models like CLIP enable\nsource-free domain generalization (SFDG) by using text prompts to simulate\nvisual representations, reducing data demands. However, existing SFDG methods\nstruggle with domain-specific confounders, limiting their generalization\ncapabilities. To address this issue, we propose TDCRL\n(\\textbf{T}ext-\\textbf{D}riven \\textbf{C}ausal \\textbf{R}epresentation\n\\textbf{L}earning), the first method to integrate causal inference into the\nSFDG setting. TDCRL operates in two steps: first, it employs data augmentation\nto generate style word vectors, combining them with class information to\ngenerate text embeddings to simulate visual representations; second, it trains\na causal intervention network with a confounder dictionary to extract\ndomain-invariant features. Grounded in causal learning, our approach offers a\nclear and effective mechanism to achieve robust, domain-invariant features,\nensuring robust generalization. Extensive experiments on PACS, VLCS,\nOfficeHome, and DomainNet show state-of-the-art performance, proving TDCRL\neffectiveness in SFDG.", "published": "2025-07-14 06:20:42", "link": "http://arxiv.org/abs/2507.09961v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Rethinking Inductive Bias in Geographically Neural Network Weighted Regression", "abstract": "Inductive bias is a key factor in spatial regression models, determining how\nwell a model can learn from limited data and capture spatial patterns. This\nwork revisits the inductive biases in Geographically Neural Network Weighted\nRegression (GNNWR) and identifies limitations in current approaches for\nmodeling spatial non-stationarity. While GNNWR extends traditional\nGeographically Weighted Regression by using neural networks to learn spatial\nweighting functions, existing implementations are often restricted by fixed\ndistance-based schemes and limited inductive bias. We propose to generalize\nGNNWR by incorporating concepts from convolutional neural networks, recurrent\nneural networks, and transformers, introducing local receptive fields,\nsequential context, and self-attention into spatial regression. Through\nextensive benchmarking on synthetic spatial datasets with varying\nheterogeneity, noise, and sample sizes, we show that GNNWR outperforms classic\nmethods in capturing nonlinear and complex spatial relationships. Our results\nalso reveal that model performance depends strongly on data characteristics,\nwith local models excelling in highly heterogeneous or small-sample scenarios,\nand global models performing better with larger, more homogeneous data. These\nfindings highlight the importance of inductive bias in spatial modeling and\nsuggest future directions, including learnable spatial weighting functions,\nhybrid neural architectures, and improved interpretability for models handling\nnon-stationary spatial data.", "published": "2025-07-14 06:13:18", "link": "http://arxiv.org/abs/2507.09958v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Radial Neighborhood Smoothing Recommender System", "abstract": "Recommender systems inherently exhibit a low-rank structure in latent space.\nA key challenge is to define meaningful and measurable distances in the latent\nspace to capture user-user, item-item, user-item relationships effectively. In\nthis work, we establish that distances in the latent space can be\nsystematically approximated using row-wise and column-wise distances in the\nobserved matrix, providing a novel perspective on distance estimation. To\nrefine the distance estimation, we introduce the correction based on empirical\nvariance estimator to account for noise-induced non-centrality. The novel\ndistance estimation enables a more structured approach to constructing\nneighborhoods, leading to the Radial Neighborhood Estimator (RNE), which\nconstructs neighborhoods by including both overlapped and partially overlapped\nuser-item pairs and employs neighborhood smoothing via localized kernel\nregression to improve imputation accuracy. We provide the theoretical\nasymptotic analysis for the proposed estimator. We perform evaluations on both\nsimulated and real-world datasets, demonstrating that RNE achieves superior\nperformance compared to existing collaborative filtering and matrix\nfactorization methods. While our primary focus is on distance estimation in\nlatent space, we find that RNE also mitigates the ``cold-start'' problem.", "published": "2025-07-14 06:01:58", "link": "http://arxiv.org/abs/2507.09952v1", "categories": ["cs.LG", "stat.AP", "stat.ME", "68T01(General topics in artificial intelligence),\n  62G05(Nonparametric estimation)"], "primary_category": "cs.LG"}
{"title": "Hierarchical Job Classification with Similarity Graph Integration", "abstract": "In the dynamic realm of online recruitment, accurate job classification is\nparamount for optimizing job recommendation systems, search rankings, and labor\nmarket analyses. As job markets evolve, the increasing complexity of job titles\nand descriptions necessitates sophisticated models that can effectively\nleverage intricate relationships within job data. Traditional text\nclassification methods often fall short, particularly due to their inability to\nfully utilize the hierarchical nature of industry categories. To address these\nlimitations, we propose a novel representation learning and classification\nmodel that embeds jobs and hierarchical industry categories into a latent\nembedding space. Our model integrates the Standard Occupational Classification\n(SOC) system and an in-house hierarchical taxonomy, Carotene, to capture both\ngraph and hierarchical relationships, thereby improving classification\naccuracy. By embedding hierarchical industry categories into a shared latent\nspace, we tackle cold start issues and enhance the dynamic matching of\ncandidates to job opportunities. Extensive experimentation on a large-scale\ndataset of job postings demonstrates the model's superior ability to leverage\nhierarchical structures and rich semantic features, significantly outperforming\nexisting methods. This research provides a robust framework for improving job\nclassification accuracy, supporting more informed decision-making in the\nrecruitment industry.", "published": "2025-07-14 05:54:57", "link": "http://arxiv.org/abs/2507.09949v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Iceberg: Enhancing HLS Modeling with Synthetic Data", "abstract": "Deep learning-based prediction models for High-Level Synthesis (HLS) of\nhardware designs often struggle to generalize. In this paper, we study how to\nclose the generalizability gap of these models through pretraining on synthetic\ndata and introduce Iceberg, a synthetic data augmentation approach that expands\nboth large language model (LLM)-generated programs and weak labels of unseen\ndesign configurations. Our weak label generation method is integrated with an\nin-context model architecture, enabling meta-learning from actual and proximate\nlabels. Iceberg improves the geometric mean modeling accuracy by $86.4\\%$ when\nadapt to six real-world applications with few-shot examples and achieves a\n$2.47\\times$ and a $1.12\\times$ better offline DSE performance when adapting to\ntwo different test datasets. Our open-sourced code is here:\n\\href{https://github.com/UCLA-VAST/iceberg}{https://github.com/UCLA-VAST/iceberg}", "published": "2025-07-14 05:48:09", "link": "http://arxiv.org/abs/2507.09948v1", "categories": ["cs.LG", "cs.AR"], "primary_category": "cs.LG"}
{"title": "Long-Tailed Data Classification by Increasing and Decreasing Neurons During Training", "abstract": "In conventional deep learning, the number of neurons typically remains fixed\nduring training. However, insights from biology suggest that the human\nhippocampus undergoes continuous neuron generation and pruning of neurons over\nthe course of learning, implying that a flexible allocation of capacity can\ncontribute to enhance performance. Real-world datasets often exhibit class\nimbalance situations where certain classes have far fewer samples than others,\nleading to significantly reduce recognition accuracy for minority classes when\nrelying on fixed size networks.To address the challenge, we propose a method\nthat periodically adds and removes neurons during training, thereby boosting\nrepresentational power for minority classes. By retaining critical features\nlearned from majority classes while selectively increasing neurons for\nunderrepresented classes, our approach dynamically adjusts capacity during\ntraining. Importantly, while the number of neurons changes throughout training,\nthe final network size and structure remain unchanged, ensuring efficiency and\ncompatibility with deployment.Furthermore, by experiments on three different\ndatasets and five representative models, we demonstrate that the proposed\nmethod outperforms fixed size networks and shows even greater accuracy when\ncombined with other imbalance-handling techniques. Our results underscore the\neffectiveness of dynamic, biologically inspired network designs in improving\nperformance on class-imbalanced data.", "published": "2025-07-14 05:29:16", "link": "http://arxiv.org/abs/2507.09940v1", "categories": ["cs.LG", "stat.AP"], "primary_category": "cs.LG"}
{"title": "Extracting Cause-Effect Pairs from a Sentence with a Dependency-Aware Transformer Model", "abstract": "Extracting cause and effect phrases from a sentence is an important NLP task,\nwith numerous applications in various domains, including legal, medical,\neducation, and scientific research. There are many unsupervised and supervised\nmethods proposed for solving this task. Among these, unsupervised methods\nutilize various linguistic tools, including syntactic patterns, dependency\ntree, dependency relations, etc. among different sentential units for\nextracting the cause and effect phrases. On the other hand, the contemporary\nsupervised methods use various deep learning based mask language models\nequipped with a token classification layer for extracting cause and effect\nphrases. Linguistic tools, specifically, dependency tree, which organizes a\nsentence into different semantic units have been shown to be very effective for\nextracting semantic pairs from a sentence, but existing supervised methods do\nnot have any provision for utilizing such tools within their model framework.\nIn this work, we propose DepBERT, which extends a transformer-based model by\nincorporating dependency tree of a sentence within the model framework.\nExtensive experiments over three datasets show that DepBERT is better than\nvarious state-of-the art supervised causality extraction methods.", "published": "2025-07-14 05:06:37", "link": "http://arxiv.org/abs/2507.09925v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Algorithm Development in Neural Networks: Insights from the Streaming Parity Task", "abstract": "Even when massively overparameterized, deep neural networks show a remarkable\nability to generalize. Research on this phenomenon has focused on\ngeneralization within distribution, via smooth interpolation. Yet in some\nsettings neural networks also learn to extrapolate to data far beyond the\nbounds of the original training set, sometimes even allowing for infinite\ngeneralization, implying that an algorithm capable of solving the task has been\nlearned. Here we undertake a case study of the learning dynamics of recurrent\nneural networks (RNNs) trained on the streaming parity task in order to develop\nan effective theory of algorithm development. The streaming parity task is a\nsimple but nonlinear task defined on sequences up to arbitrary length. We show\nthat, with sufficient finite training experience, RNNs exhibit a phase\ntransition to perfect infinite generalization. Using an effective theory for\nthe representational dynamics, we find an implicit representational merger\neffect which can be interpreted as the construction of a finite automaton that\nreproduces the task. Overall, our results disclose one mechanism by which\nneural networks can generalize infinitely from finite training experience.", "published": "2025-07-14 04:07:43", "link": "http://arxiv.org/abs/2507.09897v1", "categories": ["cs.LG", "q-bio.NC"], "primary_category": "cs.LG"}
{"title": "AdaBrain-Bench: Benchmarking Brain Foundation Models for Brain-Computer Interface Applications", "abstract": "Non-invasive Brain-Computer Interfaces (BCI) offer a safe and accessible\nmeans of connecting the human brain to external devices, with broad\napplications in home and clinical settings to enhance human capabilities.\nHowever, the high noise level and limited task-specific data in non-invasive\nsignals constrain decoding capabilities. Recently, the adoption of\nself-supervised pre-training is transforming the landscape of non-invasive BCI\nresearch, enabling the development of brain foundation models to capture\ngeneric neural representations from large-scale unlabeled\nelectroencephalography (EEG) signals with substantial noises. However, despite\nthese advances, the field currently lacks comprehensive, practical and\nextensible benchmarks to assess the utility of the public foundation models\nacross diverse BCI tasks, hindering their widespread adoption. To address this\nchallenge, we present AdaBrain-Bench, a large-scale standardized benchmark to\nsystematically evaluate brain foundation models in widespread non-invasive BCI\ntasks. AdaBrain-Bench encompasses a diverse collection of representative BCI\ndecoding datasets spanning 7 key applications. It introduces a streamlined task\nadaptation pipeline integrated with multi-dimensional evaluation metrics and a\nset of adaptation tools. The benchmark delivers an inclusive framework for\nassessing generalizability of brain foundation models across key transfer\nsettings, including cross-subject, multi-subject, and few-shot scenarios. We\nleverage AdaBrain-Bench to evaluate a suite of publicly available brain\nfoundation models and offer insights into practices for selecting appropriate\nmodels in various scenarios. We make our benchmark pipeline available to enable\nreproducible research and external use, offering a continuously evolving\nplatform to foster progress toward robust and generalized neural decoding\nsolutions.", "published": "2025-07-14 03:37:41", "link": "http://arxiv.org/abs/2507.09882v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Prompt Informed Reinforcement Learning for Visual Coverage Path Planning", "abstract": "Visual coverage path planning with unmanned aerial vehicles (UAVs) requires\nagents to strategically coordinate UAV motion and camera control to maximize\ncoverage, minimize redundancy, and maintain battery efficiency. Traditional\nreinforcement learning (RL) methods rely on environment-specific reward\nformulations that lack semantic adaptability. This study proposes\nPrompt-Informed Reinforcement Learning (PIRL), a novel approach that integrates\nthe zero-shot reasoning ability and in-context learning capability of large\nlanguage models with curiosity-driven RL. PIRL leverages semantic feedback from\nan LLM, GPT-3.5, to dynamically shape the reward function of the Proximal\nPolicy Optimization (PPO) RL policy guiding the agent in position and camera\nadjustments for optimal visual coverage. The PIRL agent is trained using OpenAI\nGym and evaluated in various environments. Furthermore, the sim-to-real-like\nability and zero-shot generalization of the agent are tested by operating the\nagent in Webots simulator which introduces realistic physical dynamics. Results\nshow that PIRL outperforms multiple learning-based baselines such as PPO with\nstatic rewards, PPO with exploratory weight initialization, imitation learning,\nand an LLM-only controller. Across different environments, PIRL outperforms the\nbest-performing baseline by achieving up to 14% higher visual coverage in\nOpenAI Gym and 27% higher in Webots, up to 25% higher battery efficiency, and\nup to 18\\% lower redundancy, depending on the environment. The results\nhighlight the effectiveness of LLM-guided reward shaping in complex spatial\nexploration tasks and suggest a promising direction for integrating natural\nlanguage priors into RL for robotics.", "published": "2025-07-14 13:51:28", "link": "http://arxiv.org/abs/2507.10284v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "ToMacVF : Temporal Macro-action Value Factorization for Asynchronous Multi-Agent Reinforcement Learning", "abstract": "Existing asynchronous MARL methods based on MacDec-POMDP typically construct\ntraining trajectory buffers by simply sampling limited and biased data at the\nendpoints of macro-actions, and directly apply conventional MARL methods on the\nbuffers. As a result, these methods lead to an incomplete and inaccurate\nrepresentation of the macro-action execution process, along with unsuitable\ncredit assignments. To solve these problems, the Temporal Macro-action Value\nFactorization (ToMacVF) is proposed to achieve fine-grained temporal credit\nassignment for macro-action contributions. A centralized training buffer,\ncalled Macro-action Segmented Joint Experience Replay Trajectory (Mac-SJERT),\nis designed to incorporate with ToMacVF to collect accurate and complete\nmacro-action execution information, supporting a more comprehensive and precise\nrepresentation of the macro-action process. To ensure principled and\nfine-grained asynchronous value factorization, the consistency requirement\nbetween joint and individual macro-action selection called Temporal\nMacro-action based IGM (To-Mac-IGM) is formalized, proving that it generalizes\nthe synchronous cases. Based on To-Mac-IGM, a modularized ToMacVF architecture,\nwhich satisfies CTDE principle, is designed to conveniently integrate previous\nvalue factorization methods. Next, the ToMacVF algorithm is devised as an\nimplementation of the ToMacVF architecture. Experimental results demonstrate\nthat, compared to asynchronous baselines, our ToMacVF algorithm not only\nachieves optimal performance but also exhibits strong adaptability and\nrobustness across various asynchronous multi-agent experimental scenarios.", "published": "2025-07-14 13:18:13", "link": "http://arxiv.org/abs/2507.10251v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Multi-Robot Cooperative Herding through Backstepping Control Barrier Functions", "abstract": "We propose a novel cooperative herding strategy through backstepping control\nbarrier functions (CBFs), which coordinates multiple herders to herd a group of\nevaders safely towards a designated goal region. For the herding system with\nheterogeneous groups involving herders and evaders, the behavior of the evaders\ncan only be influenced indirectly by the herders' motion, especially when the\nevaders follow an inverse dynamics model and respond solely to repulsive\ninteractions from the herders. This indirect interaction mechanism inherently\nrenders the overall system underactuated. To address this issue, we first\nconstruct separate CBFs for the dual objectives of goal reaching and collision\navoidance, which ensure both herding completion and safety guarantees. Then, we\nreformulate the underactuated herding dynamics into a control-affine structure\nand employ a backstepping approach to recursively design control inputs for the\nhierarchical barrier functions, avoiding taking derivatives of the higher-order\nsystem. Finally, we present a cooperative herding strategy based on\nbackstepping CBFs that allow herders to safely herd multiple evaders into the\ngoal region. In addition, centralized and decentralized implementations of the\nproposed algorithm are developed, further enhancing its flexibility and\napplicability. Extensive simulations and real-world experiments validate the\neffectiveness and safety of the proposed strategy in multi-robot herding.", "published": "2025-07-14 13:16:35", "link": "http://arxiv.org/abs/2507.10249v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "AnalogTester: A Large Language Model-Based Framework for Automatic Testbench Generation in Analog Circuit Design", "abstract": "Recent advancements have demonstrated the significant potential of large\nlanguage models (LLMs) in analog circuit design. Nevertheless, testbench\nconstruction for analog circuits remains manual, creating a critical bottleneck\nin achieving fully automated design processes. Particularly when replicating\ncircuit designs from academic papers, manual Testbench construction demands\ntime-intensive implementation and frequent adjustments, which fails to address\nthe dynamic diversity and flexibility requirements for automation. AnalogTester\ntackles automated analog design challenges through an LLM-powered pipeline: a)\ndomain-knowledge integration, b) paper information extraction, c) simulation\nscheme synthesis, and d) testbench code generation with Tsinghua Electronic\nDesign (TED). AnalogTester has demonstrated automated Testbench generation\ncapabilities for three fundamental analog circuit types: operational amplifiers\n(op-amps), bandgap references (BGRs), and low-dropout regulators (LDOs), while\nmaintaining a scalable framework for adaptation to broader circuit topologies.\nFurthermore, AnalogTester can generate circuit knowledge data and TED code\ncorpus, establishing fundamental training datasets for LLM specialization in\nanalog circuit design automation.", "published": "2025-07-14 06:32:23", "link": "http://arxiv.org/abs/2507.09965v1", "categories": ["cs.MA", "cs.AR"], "primary_category": "cs.MA"}
{"title": "Multi-residual Mixture of Experts Learning for Cooperative Control in Multi-vehicle Systems", "abstract": "Autonomous vehicles (AVs) are becoming increasingly popular, with their\napplications now extending beyond just a mode of transportation to serving as\nmobile actuators of a traffic flow to control flow dynamics. This contrasts\nwith traditional fixed-location actuators, such as traffic signals, and is\nreferred to as Lagrangian traffic control. However, designing effective\nLagrangian traffic control policies for AVs that generalize across traffic\nscenarios introduces a major challenge. Real-world traffic environments are\nhighly diverse, and developing policies that perform robustly across such\ndiverse traffic scenarios is challenging. It is further compounded by the joint\ncomplexity of the multi-agent nature of traffic systems, mixed motives among\nparticipants, and conflicting optimization objectives subject to strict\nphysical and external constraints. To address these challenges, we introduce\nMulti-Residual Mixture of Expert Learning (MRMEL), a novel framework for\nLagrangian traffic control that augments a given suboptimal nominal policy with\na learned residual while explicitly accounting for the structure of the traffic\nscenario space. In particular, taking inspiration from residual reinforcement\nlearning, MRMEL augments a suboptimal nominal AV control policy by learning a\nresidual correction, but at the same time dynamically selects the most suitable\nnominal policy from a pool of nominal policies conditioned on the traffic\nscenarios and modeled as a mixture of experts. We validate MRMEL using a case\nstudy in cooperative eco-driving at signalized intersections in Atlanta, Dallas\nFort Worth, and Salt Lake City, with real-world data-driven traffic scenarios.\nThe results show that MRMEL consistently yields superior performance-achieving\nan additional 4%-9% reduction in aggregate vehicle emissions relative to the\nstrongest baseline in each setting.", "published": "2025-07-14 00:17:12", "link": "http://arxiv.org/abs/2507.09836v1", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Splitting Method for a Multilayered Poroelastic Solid Interacting with Stokes Flow", "abstract": "Multilayered poroelastic structures are found in many biological tissues such\nas cartilage and the cornea, and play a key role in the design of bioartificial\norgans and other bioengineering applications. Motivated by these applications,\nwe study the interaction between a free fluid flow, governed by the\ntime-dependent Stokes equations, and a multilayered poroelastic structure\ncomposed of a thick Biot layer and a thin, linear poroelastic plate located at\nthe interface. The resulting equations are linearly coupled across the thin\nstructure domain through physical coupling conditions. We develop a partitioned\nnumerical scheme for this poroelastic fluid-structure interaction problem,\ncombining the backward Euler Stokes-Biot splitting method with the fixed-strain\nBiot splitting approach. The first decouples the Stokes problem from the\nmultilayered structure problem, while the second decouples the flow and\nmechanical subproblems within the poroelastic structures. Stability of the\nsplitting scheme is proven under different combinations of time-step conditions\nand parameter constraints. The method is validated using manufactured\nsolutions, and further applied to a biologically inspired blood vessel flow\nproblem. We also demonstrate convergence of the solution to the limiting case\nwithout the plate as its thickness tends to zero, providing additional\nvalidation of the numerical method.", "published": "2025-07-14 17:57:20", "link": "http://arxiv.org/abs/2507.10538v1", "categories": ["math.NA", "cs.NA", "74F10, 76S05, 74L15, 34A01, 74S05, 76M10, 65M60, 65M12, 65M22, 74H15"], "primary_category": "math.NA"}
{"title": "A new time-stepping strategy and boundary treatment to improve recent 2d traffic model", "abstract": "We show how a recently published 2d model for traffic flow can be further\nimproved. Besides other improvements and simplifications, we present not only a\nmethod to compute the necessary time step restrictions, but also a subcycling\nfor the inflow and outflow. This drastically reduces computational cost on\nlarge domains with coarse grids, i.\\,e.\\ for simulations of a whole region\ninstead of a small part of a city or town.", "published": "2025-07-14 12:20:30", "link": "http://arxiv.org/abs/2507.10205v1", "categories": ["eess.SY", "cs.NA", "cs.SY", "math.NA"], "primary_category": "eess.SY"}
{"title": "A structural bound for cluster robustness of randomized small-block Lanczos", "abstract": "The Lanczos method is a fast and memory-efficient algorithm for solving\nlarge-scale symmetric eigenvalue problems. However, its rapid convergence can\ndeteriorate significantly when computing clustered eigenvalues due to a lack of\ncluster robustness. A promising strategy to enhance cluster robustness --\nwithout substantially compromising convergence speed or memory efficiency -- is\nto use a random small-block initial, where the block size is greater than one\nbut still much smaller than the cluster size. This leads to the Randomized\nSmall-Block Lanczos (RSBL) method. Despite its empirical effectiveness, RSBL\nlacks the comprehensive theoretical understanding already available for\nsingle-vector and large-block variants. In this paper, we develop a structural\nbound that supports the cluster robustness of RSBL by leveraging tools from\nmatrix polynomials. We identify an intrinsic theoretical challenge stemming\nfrom the non-commuting nature of matrix multiplication. To provide further\ninsight, we propose a conjectured probabilistic bound for cluster robustness\nand validate it through empirical experiments. Finally, we discuss how insights\ninto cluster robustness can enhance our understanding of RSBL for both\neigenvalue computation and low-rank approximation.", "published": "2025-07-14 10:43:21", "link": "http://arxiv.org/abs/2507.10144v1", "categories": ["math.NA", "cs.NA", "65F15"], "primary_category": "math.NA"}
{"title": "On the Convergence of the Policy Iteration for Infinite-Horizon Nonlinear Optimal Control Problems", "abstract": "Policy iteration (PI) is a widely used algorithm for synthesizing optimal\nfeedback control policies across many engineering and scientific applications.\nWhen PI is deployed on infinite-horizon, nonlinear, autonomous optimal-control\nproblems, however, a number of significant theoretical challenges emerge -\nparticularly when the computational state space is restricted to a bounded\ndomain. In this paper, we investigate these challenges and show that the\nviability of PI in this setting hinges on the existence, uniqueness, and\nregularity of solutions to the Generalized Hamilton-Jacobi-Bellman (GHJB)\nequation solved at each iteration. To ensure a well-posed iterative scheme, the\nGHJB solution must possess sufficient smoothness, and the domain on which the\nGHJB equation is solved must remain forward-invariant under the closed-loop\ndynamics induced by the current policy. Although fundamental to the method's\nconvergence, previous studies have largely overlooked these aspects. This paper\ncloses that gap by introducing a constructive procedure that guarantees forward\ninvariance of the computational domain throughout the entire PI sequence and by\nestablishing sufficient conditions under which a suitably regular GHJB solution\nexists at every iteration. Numerical results are presented for a grid-based\nimplementation of PI to support the theoretical findings.", "published": "2025-07-14 07:28:19", "link": "http://arxiv.org/abs/2507.09994v1", "categories": ["math.OC", "cs.NA", "math.NA", "49L20, 49N35, 49J15, 49L12"], "primary_category": "math.OC"}
{"title": "Numerical Analysis of a Bio-Polymerization Model", "abstract": "This work studies a stabilization technique for first-order hyperbolic\ndifferential equations used in DNA transcription modeling. Specifically we use\nthe Lighthill-Whitham-Richards Model with a nonlinear Greenshield's velocity\nproposed in [1]. Standard finite element methods are known to produce spurious\noscillations when applied to nonsmooth solutions. To address this, we\nincorporate stabilization terms involving spatial and temporal filtering into\nthe system. We present numerical stability and prove convergence results for\nboth the backwards Euler and time filtered formulations. We also present\nseveral computational results to demonstrate the rates in space and in time as\nwell as for selected biological scenarios.", "published": "2025-07-14 04:59:58", "link": "http://arxiv.org/abs/2507.09921v1", "categories": ["math.NA", "cs.NA", "65M12, 65M60, 92-08, 92-10"], "primary_category": "math.NA"}
{"title": "Energy-Stable Swarm-Based Inertial Algorithms for Optimization", "abstract": "We formulate the swarming optimization problem as a weakly coupled,\ndissipative dynamical system governed by a controlled energy dissipation rate\nand initial velocities that adhere to the nonequilibrium Onsager principle. In\nthis framework, agents' inertia, positions, and masses are dynamically coupled.\nTo numerically solve the system, we develop a class of efficient, energy-stable\nalgorithms that either preserve or enhance energy dissipation at the discrete\nlevel. At equilibrium, the system tends to converge toward one of the lowest\nlocal minima explored by the agents, thereby improving the likelihood of\nidentifying the global minimum. Numerical experiments confirm the effectiveness\nof the proposed approach, demonstrating significant advantages over traditional\nswarm-based gradient descent methods, especially when operating with a limited\nnumber of agents.", "published": "2025-07-14 04:30:43", "link": "http://arxiv.org/abs/2507.09909v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Gromov-Wasserstein Barycenters: The Analysis Problem", "abstract": "This paper considers the problem of estimating a matrix that encodes pairwise\ndistances in a finite metric space (or, more generally, the edge weight matrix\nof a network) under the barycentric coding model (BCM) with respect to the\nGromov-Wasserstein (GW) distance function. We frame this task as estimating the\nunknown barycentric coordinates with respect to the GW distance, assuming that\nthe target matrix (or kernel) belongs to the set of GW barycenters of a finite\ncollection of known templates. In the language of harmonic analysis, if\ncomputing GW barycenters can be viewed as a synthesis problem, this paper aims\nto solve the corresponding analysis problem. We propose two methods: one\nutilizing fixed-point iteration for computing GW barycenters, and another\nemploying a differentiation-based approach to the GW structure using a blow-up\ntechnique. Finally, we demonstrate the application of the proposed GW analysis\napproach in a series of numerical experiments and applications to machine\nlearning.", "published": "2025-07-14 02:34:31", "link": "http://arxiv.org/abs/2507.09865v1", "categories": ["math.OC", "cs.NA", "math.FA", "math.MG", "math.NA", "42B99, 49Q22, 68T01, 68T09, 90C35, 94A12"], "primary_category": "math.OC"}
{"title": "Towards Realistic and Interpretable Market Simulations: Factorizing Financial Power Law using Optimal Transport", "abstract": "We investigate the mechanisms behind the power-law distribution of stock\nreturns using artificial market simulations. While traditional financial theory\nassumes Gaussian price fluctuations, empirical studies consistently show that\nthe tails of return distributions follow a power law. Previous research has\nproposed hypotheses for this phenomenon -- some attributing it to investor\nbehavior, others to institutional demand imbalances. However, these factors\nhave rarely been modeled together to assess their individual and joint\ncontributions. The complexity of real financial markets complicates the\nisolation of the contribution of a single component using existing data. To\naddress this, we construct artificial markets and conduct controlled\nexperiments using optimal transport (OT) as a quantitative similarity measure.\nOur proposed framework incrementally introduces behavioral components into the\nagent models, allowing us to compare each simulation output with empirical data\nvia OT distances. The results highlight that informational effect of prices\nplays a dominant role in reproducing power-law behavior and that multiple\ncomponents interact synergistically to amplify this effect.", "published": "2025-07-14 02:28:56", "link": "http://arxiv.org/abs/2507.09863v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Analyzing the Crowding-Out Effect of Investment Herding on Consumption: An Optimal Control Theory Approach", "abstract": "Investment herding, a phenomenon where households mimic the decisions of\nothers rather than relying on their own analysis, has significant effects on\nfinancial markets and household behavior. Excessive investment herding may\nreduce investments and lead to a depletion of household consumption, which is\ncalled the crowding-out effect. While existing research has qualitatively\nexamined the impact of investment herding on consumption, quantitative studies\nin this area remain limited. In this work, we investigate the optimal\ninvestment and consumption decisions of households under the impact of\ninvestment herding. We formulate an optimization problem to model how\ninvestment herding influences household decisions over time. Based on the\noptimal control theory, we solve for the analytical solutions of optimal\ninvestment and consumption decisions. We theoretically analyze the impact of\ninvestment herding on household consumption decisions and demonstrate the\nexistence of the crowding-out effect. We further explore how parameters, such\nas interest rate, excess return rate, and volatility, influence the\ncrowding-out effect. Finally, we conduct a real data test to validate our\ntheoretical analysis of the crowding-out effect. This study is crucial to\nunderstanding the impact of investment herding on household consumption and\noffering valuable insights for policymakers seeking to stimulate consumption\nand mitigate the negative effects of investment herding on economic growth.", "published": "2025-07-14 08:33:20", "link": "http://arxiv.org/abs/2507.10052v1", "categories": ["q-fin.PM", "cs.SY", "econ.GN", "eess.SY", "q-fin.EC", "q-fin.MF"], "primary_category": "q-fin.PM"}
{"title": "An Accurate Discretized Approach to Parameter Estimation in the CKLS Model via the CIR Framework", "abstract": "This paper provides insight into the estimation and asymptotic behavior of\nparameters in interest rate models, focusing primarily on the\nCox-Ingersoll-Ross (CIR) process and its extension -- the more general\nChan-Karolyi-Longstaff-Sanders (CKLS) framework ($\\alpha\\in[0.5,1]$). The CIR\nprocess is widely used in modeling interest rates which possess the mean\nreverting feature. An Extension of CIR model, CKLS model serves as a\nfoundational case for analyzing more complex dynamics. We employ Euler-Maruyama\ndiscretization to transform the continuous-time stochastic differential\nequations (SDEs) of these models into a discretized form that facilitates\nefficient simulation and estimation of parameters using linear regression\ntechniques. We established the strong consistency and asymptotic normality of\nthe estimators for the drift and volatility parameters, providing a theoretical\nunderpinning for the parameter estimation process. Additionally, we explore the\nboundary behavior of these models, particularly in the context of\nunattainability at zero and infinity, by examining the scale and speed density\nfunctions associated with generalized SDEs involving polynomial drift and\ndiffusion terms. Furthermore, we derive sufficient conditions for the existence\nof a stationary distribution within the CKLS framework and the corresponding\nstationary density function; and discuss its dependence on model parameters for\n$\\alpha\\in[0.5,1]$.", "published": "2025-07-14 08:17:29", "link": "http://arxiv.org/abs/2507.10041v1", "categories": ["stat.AP", "q-fin.ST"], "primary_category": "stat.AP"}
{"title": "A Coincidence of Wants Mechanism for Swap Trade Execution in Decentralized Exchanges", "abstract": "We propose a mathematically rigorous framework for identifying and completing\nCoincidence of Wants (CoW) cycles in decentralized exchange (DEX) aggregators.\nUnlike existing auction based systems such as CoWSwap, our approach introduces\nan asset matrix formulation that not only verifies feasibility using oracle\nprices and formal conservation laws but also completes partial CoW cycles of\nswap orders that are discovered using graph traversal and are settled using\nimbalance correction. We define bridging orders and show that the resulting\nexecution is slippage free and capital preserving for LPs. Applied to real\nworld Arbitrum swap data, our algorithm demonstrates efficient discovery of CoW\ncycles and supports the insertion of synthetic orders for atomic cycle closure.\nThis work can be thought of as the detailing of a potential delta-neutral\nstrategy by liquidity providing market makers: a structured CoW cycle\nexecution.", "published": "2025-07-14 10:53:25", "link": "http://arxiv.org/abs/2507.10149v1", "categories": ["cs.GT", "cs.CE", "q-fin.TR"], "primary_category": "cs.GT"}
{"title": "Sampling-Based Estimation of Jaccard Containment and Similarity", "abstract": "This paper addresses the problem of estimating the containment and similarity\nbetween two sets using only random samples from each set, without relying on\nsketches or full data access. The study introduces a binomial model for\npredicting the overlap between samples, demonstrating that it is both accurate\nand practical when sample sizes are small compared to the original sets. The\npaper compares this model to previous approaches and shows that it provides\nbetter estimates under the considered conditions. It also analyzes the\nstatistical properties of the estimator, including error bounds and sample size\nrequirements needed to achieve a desired level of accuracy and confidence. The\nframework is extended to estimate set similarity, and the paper provides\nguidance for applying these methods in large scale data systems where only\npartial or sampled data is available.", "published": "2025-07-14 07:56:29", "link": "http://arxiv.org/abs/2507.10019v1", "categories": ["stat.CO", "cs.DB", "stat.ML"], "primary_category": "stat.CO"}
{"title": "Solving dynamic portfolio selection problems via score-based diffusion models", "abstract": "In this paper, we tackle the dynamic mean-variance portfolio selection\nproblem in a {\\it model-free} manner, based on (generative) diffusion models.\nWe propose using data sampled from the real model $\\mathcal P$ (which is\nunknown) with limited size to train a generative model $\\mathcal Q$ (from which\nwe can easily and adequately sample). With adaptive training and sampling\nmethods that are tailor-made for time series data, we obtain quantification\nbounds between $\\mathcal P$ and $\\mathcal Q$ in terms of the adapted\nWasserstein metric $\\mathcal A W_2$. Importantly, the proposed adapted sampling\nmethod also facilitates {\\it conditional sampling}. In the second part of this\npaper, we provide the stability of the mean-variance portfolio optimization\nproblems in $\\mathcal A W _2$. Then, combined with the error bounds and the\nstability result, we propose a policy gradient algorithm based on the\ngenerative environment, in which our innovative adapted sampling method\nprovides approximate scenario generators. We illustrate the performance of our\nalgorithm on both simulated and real data. For real data, the algorithm based\non the generative environment produces portfolios that beat several important\nbaselines, including the Markowitz portfolio, the equal weight (naive)\nportfolio, and S\\&P 500.", "published": "2025-07-14 04:41:49", "link": "http://arxiv.org/abs/2507.09916v1", "categories": ["q-fin.PM", "stat.ML"], "primary_category": "q-fin.PM"}
{"title": "Statistical Inference for Conditional Group Distributionally Robust Optimization with Cross-Entropy Loss", "abstract": "In multi-source learning with discrete labels, distributional heterogeneity\nacross domains poses a central challenge to developing predictive models that\ntransfer reliably to unseen domains. We study multi-source unsupervised domain\nadaptation, where labeled data are drawn from multiple source domains and only\nunlabeled data from a target domain. To address potential distribution shifts,\nwe propose a novel Conditional Group Distributionally Robust Optimization\n(CG-DRO) framework that learns a classifier by minimizing the worst-case\ncross-entropy loss over the convex combinations of the conditional outcome\ndistributions from the sources. To solve the resulting minimax problem, we\ndevelop an efficient Mirror Prox algorithm, where we employ a double machine\nlearning procedure to estimate the risk function. This ensures that the errors\nof the machine learning estimators for the nuisance models enter only at\nhigher-order rates, thereby preserving statistical efficiency under covariate\nshift. We establish fast statistical convergence rates for the estimator by\nconstructing two surrogate minimax optimization problems that serve as\ntheoretical bridges. A distinguishing challenge for CG-DRO is the emergence of\nnonstandard asymptotics: the empirical estimator may fail to converge to a\nstandard limiting distribution due to boundary effects and system instability.\nTo address this, we introduce a perturbation-based inference procedure that\nenables uniformly valid inference, including confidence interval construction\nand hypothesis testing.", "published": "2025-07-14 04:21:23", "link": "http://arxiv.org/abs/2507.09905v1", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Radif corpus: a symbolic dataset for non-metric iranian classical music", "abstract": "Non-metric music forms the core of the repertoire in Iranian classical music.\nDastgahi music serves as the underlying theoretical system for both Iranian art\nmusic and certain folk traditions. At the heart of Iranian classical music lies\nthe radif, a foundational repertoire that organizes melodic material central to\nperformance and pedagogy.\n  In this study, we introduce the first digital corpus representing the\ncomplete non-metrical radif repertoire, covering all 13 existing components of\nthis repertoire. We provide MIDI files (about 281 minutes in total) and data\nspreadsheets describing notes, note durations, intervals, and hierarchical\nstructures for 228 pieces of music. We faithfully represent the tonality\nincluding quarter-tones, and the non-metric aspect. Furthermore, we provide\nsupporting basic statistics, and measures of complexity and similarity over the\ncorpus.\n  Our corpus provides a platform for computational studies of Iranian classical\nmusic. Researchers might employ it in studying melodic patterns, investigating\nimprovisational styles, or for other tasks in music information retrieval,\nmusic theory, and computational (ethno)musicology.", "published": "2025-07-14 16:35:09", "link": "http://arxiv.org/abs/2507.10456v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DQLoRA: A Lightweight Domain-Aware Denoising ASR via Adapter-guided Distillation", "abstract": "We present a demo of DQLoRA, an Adapter-Guided Distillation framework for\nrobust speech recognition under low-resource and noisy conditions. Our method\nemploys a frozen Whisper model as the teacher to provide semantic supervision,\nand a lightweight Wav2Vec2 student equipped with QLoRA-based Adapters. Training\nis conducted on the FLEURS dataset augmented with DNS-style noise. The student\nis optimized by jointly minimizing CTC loss and KL-based distillation loss,\nenabling efficient adaptation while preserving recognition accuracy.", "published": "2025-07-14 14:16:40", "link": "http://arxiv.org/abs/2507.10313v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ASDKit: A Toolkit for Comprehensive Evaluation of Anomalous Sound Detection Methods", "abstract": "In this paper, we introduce ASDKit, a toolkit for anomalous sound detection\n(ASD) task. Our aim is to facilitate ASD research by providing an open-source\nframework that collects and carefully evaluates various ASD methods. First,\nASDKit provides training and evaluation scripts for a wide range of ASD\nmethods, all handled within a unified framework. For instance, it includes the\nautoencoder-based official DCASE baseline, representative discriminative\nmethods, and self-supervised learning-based methods. Second, it supports\ncomprehensive evaluation on the DCASE 2020--2024 datasets, enabling careful\nassessment of ASD performance, which is highly sensitive to factors such as\ndatasets and random seeds. In our experiments, we re-evaluate various ASD\nmethods using ASDKit and identify consistently effective techniques across\nmultiple datasets and trials. We also demonstrate that ASDKit reproduces the\nstate-of-the-art-level performance on the considered datasets.", "published": "2025-07-14 13:36:57", "link": "http://arxiv.org/abs/2507.10264v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Harmonics to the Rescue: Why Voiced Speech is Not a Wss Process", "abstract": "Speech processing algorithms often rely on statistical knowledge of the\nunderlying process. Despite many years of research, however, the debate on the\nmost appropriate statistical model for speech still continues. Speech is\ncommonly modeled as a wide-sense stationary (WSS) process. However, the use of\nthe WSS model for spectrally correlated processes is fundamentally wrong, as\nWSS implies spectral uncorrelation. In this paper, we demonstrate that voiced\nspeech can be more accurately represented as a cyclostationary (CS) process. By\nemploying the CS rather than the WSS model for processes that are inherently\ncorrelated across frequency, it is possible to improve the estimation of\ncross-power spectral densities (PSDs), source separation, and beamforming. We\nillustrate how the correlation between harmonic frequencies of CS processes can\nenhance system identification, and validate our findings using both simulated\nand real speech data.", "published": "2025-07-14 11:38:51", "link": "http://arxiv.org/abs/2507.10176v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Cyclic Multichannel Wiener Filter for Acoustic Beamforming", "abstract": "Acoustic beamforming models typically assume wide-sense stationarity of\nspeech signals within short time frames. However, voiced speech is better\nmodeled as a cyclostationary (CS) process, a random process whose mean and\nautocorrelation are $T_1$-periodic, where $\\alpha_1=1/T_1$ corresponds to the\nfundamental frequency of vowels. Higher harmonic frequencies are found at\ninteger multiples of the fundamental. This work introduces a cyclic\nmultichannel Wiener filter (cMWF) for speech enhancement derived from a\ncyclostationary model. This beamformer exploits spectral correlation across the\nharmonic frequencies of the signal to further reduce the mean-squared error\n(MSE) between the target and the processed input. The proposed cMWF is optimal\nin the MSE sense and reduces to the MWF when the target is wide-sense\nstationary. Experiments on simulated data demonstrate considerable improvements\nin scale-invariant signal-to-distortion ratio (SI-SDR) on synthetic data but\nalso indicate high sensitivity to the accuracy of the estimated fundamental\nfrequency $\\alpha_1$, which limits effectiveness on real data.", "published": "2025-07-14 11:18:29", "link": "http://arxiv.org/abs/2507.10159v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "DualDub: Video-to-Soundtrack Generation via Joint Speech and Background Audio Synthesis", "abstract": "While recent video-to-audio (V2A) models can generate realistic background\naudio from visual input, they largely overlook speech, an essential part of\nmany video soundtracks. This paper proposes a new task, video-to-soundtrack\n(V2ST) generation, which aims to jointly produce synchronized background audio\nand speech within a unified framework. To tackle V2ST, we introduce DualDub, a\nunified framework built on a multimodal language model that integrates a\nmultimodal encoder, a cross-modal aligner, and dual decoding heads for\nsimultaneous background audio and speech generation. Specifically, our proposed\ncross-modal aligner employs causal and non-causal attention mechanisms to\nimprove synchronization and acoustic harmony. Besides, to handle data scarcity,\nwe design a curriculum learning strategy that progressively builds the\nmultimodal capability. Finally, we introduce DualBench, the first benchmark for\nV2ST evaluation with a carefully curated test set and comprehensive metrics.\nExperimental results demonstrate that DualDub achieves state-of-the-art\nperformance, generating high-quality and well-synchronized soundtracks with\nboth speech and background audio.", "published": "2025-07-14 09:50:53", "link": "http://arxiv.org/abs/2507.10109v1", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "The Man Behind the Sound: Demystifying Audio Private Attribute Profiling via Multimodal Large Language Model Agents", "abstract": "Our research uncovers a novel privacy risk associated with multimodal large\nlanguage models (MLLMs): the ability to infer sensitive personal attributes\nfrom audio data -- a technique we term audio private attribute profiling. This\ncapability poses a significant threat, as audio can be covertly captured\nwithout direct interaction or visibility. Moreover, compared to images and\ntext, audio carries unique characteristics, such as tone and pitch, which can\nbe exploited for more detailed profiling. However, two key challenges exist in\nunderstanding MLLM-employed private attribute profiling from audio: (1) the\nlack of audio benchmark datasets with sensitive attribute annotations and (2)\nthe limited ability of current MLLMs to infer such attributes directly from\naudio. To address these challenges, we introduce AP^2, an audio benchmark\ndataset that consists of two subsets collected and composed from real-world\ndata, and both are annotated with sensitive attribute labels. Additionally, we\npropose Gifts, a hybrid multi-agent framework that leverages the complementary\nstrengths of audio-language models (ALMs) and large language models (LLMs) to\nenhance inference capabilities. Gifts employs an LLM to guide the ALM in\ninferring sensitive attributes, then forensically analyzes and consolidates the\nALM's inferences, overcoming severe hallucinations of existing ALMs in\ngenerating long-context responses. Our evaluations demonstrate that Gifts\nsignificantly outperforms baseline approaches in inferring sensitive\nattributes. Finally, we investigate model-level and data-level defense\nstrategies to mitigate the risks of audio private attribute profiling. Our work\nvalidates the feasibility of audio-based privacy attacks using MLLMs,\nhighlighting the need for robust defenses, and provides a dataset and framework\nto facilitate future research.", "published": "2025-07-14 07:51:56", "link": "http://arxiv.org/abs/2507.10016v1", "categories": ["cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "ASTAR-NTU solution to AudioMOS Challenge 2025 Track1", "abstract": "Evaluation of text-to-music systems is constrained by the cost and\navailability of collecting experts for assessment. AudioMOS 2025 Challenge\ntrack 1 is created to automatically predict music impression (MI) as well as\ntext alignment (TA) between the prompt and the generated musical piece. This\npaper reports our winning system, which uses a dual-branch architecture with\npre-trained MuQ and RoBERTa models as audio and text encoders. A\ncross-attention mechanism fuses the audio and text representations. For\ntraining, we reframe the MI and TA prediction as a classification task. To\nincorporate the ordinal nature of MOS scores, one-hot labels are converted to a\nsoft distribution using a Gaussian kernel. On the official test set, a single\nmodel trained with this method achieves a system-level Spearman's Rank\nCorrelation Coefficient (SRCC) of 0.991 for MI and 0.952 for TA, corresponding\nto a relative improvement of 21.21\\% in MI SRCC and 31.47\\% in TA SRCC over the\nchallenge baseline.", "published": "2025-07-14 04:18:15", "link": "http://arxiv.org/abs/2507.09904v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhanced Throughput and Seamless Handover Solutions for Urban 5G-Vehicle C-Band Integrated Satellite-Terrestrial Networks", "abstract": "This paper investigates downlink transmission in 5G Integrated\nSatellite-Terrestrial Networks (ISTNs) supporting automotive users (UEs) in\nurban environments, where base stations (BSs) and Low Earth Orbit (LEO)\nsatellites (LSats) cooperate to serve moving UEs over shared C-band frequency\ncarriers. Urban settings, characterized by dense obstructions, together with UE\nmobility, and the dynamic movement and coverage of LSats pose significant\nchallenges to user association and resource allocation. To address these\nchallenges, we formulate a multi-objective optimization problem designed to\nimprove both throughput and seamless handover (HO). Particularly, the\nformulated problem balances sum-rate (SR) maximization and connection change\n(CC) minimization through a weighted trade-off by jointly optimizing power\nallocation and BS-UE/LSat-UE associations over a given time window. This is a\nmixed-integer and non-convex problem which is inherently difficult to solve. To\nsolve this problem efficiently, we propose an iterative algorithm based on the\nSuccessive Convex Approximation (SCA) technique. Furthermore, we introduce a\npractical prediction-based algorithm capable of providing efficient solutions\nin real-world implementations. Especially, the simulations use a realistic 3D\nmap of London and UE routes obtained from the Google Navigator application to\nensure practical examination. Thanks to these realistic data, the simulation\nresults can show valuable insights into the link budget assessment in urban\nareas due to the impact of buildings on transmission links under the blockage,\nreflection, and diffraction effects. Furthermore, the numerical results\ndemonstrate the effectiveness of our proposed algorithms in terms of SR and the\nCC-number compared to the greedy and benchmark algorithms.", "published": "2025-07-14 14:11:32", "link": "http://arxiv.org/abs/2507.10308v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pinching-Antenna Systems with LoS Blockages", "abstract": "The aim of this letter is to explore the capability of pinching-antenna\nsystems to construct line-of-sight (LoS) links in the presence of LoS\nblockages. Specifically, pinching antennas are pre-installed at preconfigured\npositions along waveguides and can be selectively activated to create LoS links\nfor enhancing desired signals and non-line-of-sight (NLoS) links for\neliminating inter-user interference. On this basis, a sum-rate maximization\nproblem is formulated by jointly optimizing waveguide assignment and antenna\nactivation. To solve this problem, a matching based algorithm is proposed using\ntwo distinct preference designs. Simulation results demonstrate that the\nconsidered pinching-antenna system and proposed solutions can dynamically\nestablish LoS links and effectively exploit LoS blockages to mitigate\ninterference, thereby significantly improving system throughput.", "published": "2025-07-14 11:36:12", "link": "http://arxiv.org/abs/2507.10173v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pinching-Antenna Systems for Physical Layer Security", "abstract": "This letter investigates the potential of pinching-antenna systems for\nenhancing physical layer security. By pre-installing multiple pinching antennas\nat discrete positions along a waveguide, the capability of the considered\nsystem to perform amplitude and phase adjustment is validated through the\nformulation of a secrecy rate maximization problem. Specifically, amplitude\ncontrol is applied to enhance the signal quality at the legitimate user, while\nphase alignment is designed to degrade the received signal quality at the\neavesdropper. This cooperation among pinching antennas is modeled as a\ncoalitional game, and a corresponding antenna activation algorithm is proposed.\nThe individual impact of each antenna is quantified based on the Shapley value\nand marginal contribution, providing a fair and efficient method for\nperformance evaluation. Simulation results show that the considered\npinching-antenna system achieves significant improvements in secrecy rate, and\nthat the Shapley value based algorithm outperforms conventional coalition value\nbased solutions.", "published": "2025-07-14 11:28:26", "link": "http://arxiv.org/abs/2507.10167v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Intrinsic frequency distribution characterises neural dynamics", "abstract": "Decomposing multivariate time series with certain basic dynamics is crucial\nfor understanding, predicting and controlling nonlinear spatiotemporally\ndynamic systems such as the brain. Dynamic mode decomposition (DMD) is a method\nfor decomposing nonlinear spatiotemporal dynamics into several basic dynamics\n(dynamic modes; DMs) with intrinsic frequencies and decay rates. In particular,\nunlike Fourier transform-based methods, which are used to decompose a\nsingle-channel signal into the amplitudes of sinusoidal waves with discrete\nfrequencies at a regular interval, DMD can derive the intrinsic frequencies of\na multichannel signal on the basis of the available data; furthermore, it can\ncapture nonstationary components such as alternations between states with\ndifferent intrinsic frequencies. Here, we propose the use of the distribution\nof intrinsic frequencies derived from DMDs (DM frequencies) to characterise\nneural activities. The distributions of DM frequencies in the\nelectroencephalograms of healthy subjects and patients with dementia or\nParkinson's disease in a resting state were evaluated. By using the\ndistributions, these patients were distinguished from healthy subjects with\nsignificantly greater accuracy than when using amplitude spectra derived by\ndiscrete Fourier transform. This finding suggests that the distribution of DM\nfrequencies exhibits distinct behaviour from amplitude spectra, and therefore,\nthe distribution may serve as a new biomarker by characterising the nonlinear\nspatiotemporal dynamics of electrophysiological signals.", "published": "2025-07-14 10:44:23", "link": "http://arxiv.org/abs/2507.10145v1", "categories": ["eess.SP", "q-bio.NC"], "primary_category": "eess.SP"}
{"title": "Unscented Kalman Filter with a Nonlinear Propagation Model for Navigation Applications", "abstract": "The unscented Kalman filter is a nonlinear estimation algorithm commonly used\nin navigation applications. The prediction of the mean and covariance matrix is\ncrucial to the stable behavior of the filter. This prediction is done by\npropagating the sigma points according to the dynamic model at hand. In this\npaper, we introduce an innovative method to propagate the sigma points\naccording to the nonlinear dynamic model of the navigation error state vector.\nThis improves the filter accuracy and navigation performance. We demonstrate\nthe benefits of our proposed approach using real sensor data recorded by an\nautonomous underwater vehicle during several scenarios.", "published": "2025-07-14 09:08:29", "link": "http://arxiv.org/abs/2507.10082v1", "categories": ["cs.RO", "eess.SP"], "primary_category": "cs.RO"}
{"title": "Deep Learning-Based Beamforming Design Using Target Beam Patterns", "abstract": "This paper proposes a deep learning-based beamforming design framework that\ndirectly maps a target beam pattern to optimal beamforming vectors across\nmultiple antenna array architectures, including digital, analog, and hybrid\nbeamforming. The proposed method employs a lightweight encoder-decoder network\nwhere the encoder compresses the complex beam pattern into a low-dimensional\nfeature vector and the decoder reconstructs the beamforming vector while\nsatisfying hardware constraints. To address training challenges under diverse\nand limited channel station information (CSI) conditions, a two-stage training\nprocess is introduced, which consists of an offline pre-training for robust\nfeature extraction using an auxiliary module, followed by online training of\nthe decoder with a composite loss function that ensures alignment between the\nsynthesized and target beam patterns in terms of the main lobe shape and side\nlobe suppression. Simulation results based on NYUSIM-generated channels show\nthat the proposed method can achieve spectral efficiency close to that of fully\ndigital beamforming under limited CSI and outperforms representative existing\nmethods.", "published": "2025-07-14 08:49:08", "link": "http://arxiv.org/abs/2507.10063v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Sparsity-Aware Extended Kalman Filter for Tracking Dynamic Graphs", "abstract": "A broad range of applications involve signals with irregular structures that\ncan be represented as a graph. As the underlying structures can change over\ntime, the tracking dynamic graph topologies from observed signals is a\nfundamental challenge in graph signal processing (GSP), with applications in\nvarious domains, such as power systems, the brain-machine interface, and\ncommunication systems. In this paper, we propose a method for tracking dynamic\nchanges in graph topologies. Our approach builds on a representation of the\ndynamics as a graph-based nonlinear state-space model (SSM), where the\nobservations are graph signals generated through graph filtering, and the\nunderlying evolving topology serves as the latent states. In our formulation,\nthe graph Laplacian matrix is parameterized using the incidence matrix and edge\nweights, enabling a structured representation of the state. In order to track\nthe evolving topology in the resulting SSM, we develop a sparsity-aware\nextended Kalman filter (EKF) that integrates $\\ell_1$-regularized updates\nwithin the filtering process. Furthermore, a dynamic programming scheme to\nefficiently compute the Jacobian of the graph filter is introduced. Our\nnumerical study demonstrates the ability of the proposed method to accurately\ntrack sparse and time-varying graphs under realistic conditions, with highly\nnonlinear measurements, various noise levels, and different change rates, while\nmaintaining low computational complexity.", "published": "2025-07-14 07:33:45", "link": "http://arxiv.org/abs/2507.09999v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "VoxelRF: Voxelized Radiance Field for Fast Wireless Channel Modeling", "abstract": "Wireless channel modeling in complex environments is crucial for wireless\ncommunication system design and deployment. Traditional channel modeling\napproaches face challenges in balancing accuracy, efficiency, and scalability,\nwhile recent neural approaches such as neural radiance field (NeRF) suffer from\nlong training and slow inference. To tackle these challenges, we propose\nvoxelized radiance field (VoxelRF), a novel neural representation for wireless\nchannel modeling that enables fast and accurate synthesis of spatial spectra.\nVoxelRF replaces the costly multilayer perception (MLP) used in NeRF-based\nmethods with trilinear interpolation of voxel grid-based representation, and\ntwo shallow MLPs to model both propagation and transmitter-dependent effects.\nTo further accelerate training and improve generalization, we introduce\nprogressive learning, empty space skipping, and an additional background\nentropy loss function. Experimental results demonstrate that VoxelRF achieves\ncompetitive accuracy with significantly reduced computation and limited\ntraining data, making it more practical for real-time and resource-constrained\nwireless applications.", "published": "2025-07-14 07:12:16", "link": "http://arxiv.org/abs/2507.09987v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "AI-Enhanced Wide-Area Data Imaging via Massive Non-Orthogonal Direct Device-to-HAPS Transmission", "abstract": "Massive Aerial Processing for X MAP-X is an innovative framework for\nreconstructing spatially correlated ground data, such as environmental or\nindustrial measurements distributed across a wide area, into data maps using a\nsingle high altitude pseudo-satellite (HAPS) and a large number of distributed\nsensors. With subframe-level data reconstruction, MAP-X provides a\ntransformative solution for latency-sensitive IoT applications. This article\nexplores two distinct approaches for AI integration in the post-processing\nstage of MAP-X. The DNN-based pointwise estimation approach enables real-time,\nadaptive reconstruction through online training, while the CNN-based image\nreconstruction approach improves reconstruction accuracy through offline\ntraining with non-real-time data. Simulation results show that both approaches\nsignificantly outperform the conventional inverse discrete Fourier transform\n(IDFT)-based linear post-processing method. Furthermore, to enable AI-enhanced\nMAP-X, we propose a ground-HAPS cooperation framework, where terrestrial\nstations collect, process, and relay training data to the HAPS. With its\nenhanced capability in reconstructing field data, AI-enhanced MAP-X is\napplicable to various real-world use cases, including disaster response and\nnetwork management.", "published": "2025-07-14 04:03:54", "link": "http://arxiv.org/abs/2507.09895v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "REST: Stress Testing Large Reasoning Models by Asking Multiple Problems at Once", "abstract": "Recent Large Reasoning Models (LRMs) have achieved remarkable progress on\ntask-specific benchmarks, yet their evaluation methods remain constrained by\nisolated problem-solving paradigms. Existing benchmarks predominantly assess\nsingle-question reasoning through sequential testing, resulting critical\nlimitations: (1) vulnerability to data contamination and less challenging\n(e.g., DeepSeek-R1 achieves 97.0% on MATH500), forcing costly creation of new\nquestions with large human efforts, (2) failure to evaluate models under\nmulti-context pressure, a key requirement for real-world deployment. To bridge\nthis gap, we present REST (Reasoning Evaluation through Simultaneous Testing),\na stress-testing framework that exposes LRMs to multiple problems\nsimultaneously. Beyond basic reasoning, REST evaluates several under-tested\ncapabilities: contextual priority allocation, cross-problem interference\nresistance, and dynamic cognitive load management. Our evaluation reveals\nseveral striking findings: Even state-of-the-art (SOTA) models like DeepSeek-R1\nexhibit substantial performance degradation under stress testing. Crucially,\nREST demonstrates stronger discriminative power than existing benchmarks,\nrevealing pronounced performance differences among models that exhibit similar,\nnear-ceiling performance under single-question evaluations. Some key insights\nemerge from our analysis: (1) the \"overthinking trap\" is a critical factor\ncontributing to the performance degradation; (2) the models trained with\n\"long2short\" technique preserve more accuracy of their single-problem\nperformance under REST, outperforming standard-trained counterparts. These\nresults establish REST as a cost-efficient, future-proof evaluation paradigm\nthat better reflects real-world reasoning demands while reducing reliance on\ncontinuous human annotation. Code and results are available at\nhttps://opendatalab.github.io/REST.", "published": "2025-07-14 17:58:47", "link": "http://arxiv.org/abs/2507.10541v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Federated Learning with Heterogeneous Data and Adaptive Dropout", "abstract": "Federated Learning (FL) is a promising distributed machine learning approach\nthat enables collaborative training of a global model using multiple edge\ndevices. The data distributed among the edge devices is highly heterogeneous.\nThus, FL faces the challenge of data distribution and heterogeneity, where\nnon-Independent and Identically Distributed (non-IID) data across edge devices\nmay yield in significant accuracy drop. Furthermore, the limited computation\nand communication capabilities of edge devices increase the likelihood of\nstragglers, thus leading to slow model convergence. In this paper, we propose\nthe FedDHAD FL framework, which comes with two novel methods: Dynamic\nHeterogeneous model aggregation (FedDH) and Adaptive Dropout (FedAD). FedDH\ndynamically adjusts the weights of each local model within the model\naggregation process based on the non-IID degree of heterogeneous data to deal\nwith the statistical data heterogeneity. FedAD performs neuron-adaptive\noperations in response to heterogeneous devices to improve accuracy while\nachieving superb efficiency. The combination of these two methods makes FedDHAD\nsignificantly outperform state-of-the-art solutions in terms of accuracy (up to\n6.7% higher), efficiency (up to 2.02 times faster), and computation cost (up to\n15.0% smaller).", "published": "2025-07-14 16:19:00", "link": "http://arxiv.org/abs/2507.10430v2", "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Energy Efficiency in AI for 5G and Beyond: A DeepRx Case Study", "abstract": "This study addresses the challenge of balancing energy efficiency with\nperformance in AI/ML models, focusing on DeepRX, a deep learning receiver based\non a fully convolutional ResNet architecture. We evaluate the energy\nconsumption of DeepRX, considering factors including FLOPs/Watt and\nFLOPs/clock, and find consistency between estimated and actual energy usage,\ninfluenced by memory access patterns. The research extends to comparing energy\ndynamics during training and inference phases. A key contribution is the\napplication of knowledge distillation (KD) to train a compact DeepRX student\nmodel that emulates the performance of the teacher model but with reduced\nenergy consumption. We experiment with different student model sizes, optimal\nteacher sizes, and KD hyperparameters. Performance is measured by comparing the\nBit Error Rate (BER) performance versus Signal-to-Interference & Noise Ratio\n(SINR) values of the distilled model and a model trained from scratch. The\ndistilled models demonstrate a lower error floor across SINR levels,\nhighlighting the effectiveness of KD in achieving energy-efficient AI\nsolutions.", "published": "2025-07-14 15:54:06", "link": "http://arxiv.org/abs/2507.10409v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A PBN-RL-XAI Framework for Discovering a \"Hit-and-Run\" Therapeutic Strategy in Melanoma", "abstract": "Innate resistance to anti-PD-1 immunotherapy remains a major clinical\nchallenge in metastatic melanoma, with the underlying molecular networks being\npoorly understood. To address this, we constructed a dynamic Probabilistic\nBoolean Network model using transcriptomic data from patient tumor biopsies to\nelucidate the regulatory logic governing therapy response. We then employed a\nreinforcement learning agent to systematically discover optimal, multi-step\ntherapeutic interventions and used explainable artificial intelligence to\nmechanistically interpret the agent's control policy. The analysis revealed\nthat a precisely timed, 4-step temporary inhibition of the lysyl oxidase like 2\nprotein (LOXL2) was the most effective strategy. Our explainable analysis\nshowed that this ``hit-and-run\" intervention is sufficient to erase the\nmolecular signature driving resistance, allowing the network to self-correct\nwithout requiring sustained intervention. This study presents a novel,\ntime-dependent therapeutic hypothesis for overcoming immunotherapy resistance\nand provides a powerful computational framework for identifying non-obvious\nintervention protocols in complex biological systems.", "published": "2025-07-14 10:35:38", "link": "http://arxiv.org/abs/2507.10136v2", "categories": ["q-bio.QM", "cs.AI"], "primary_category": "q-bio.QM"}
{"title": "(Almost) Free Modality Stitching of Foundation Models", "abstract": "Foundation multi-modal models are often designed by stitching of multiple\nexisting pretrained uni-modal models: for example, an image classifier with an\ntext model. This stitching process is performed by training a connector module\nthat aims to align the representation spaces of these uni-modal models towards\na multi-modal objective. However, given the complexity of training such\nconnectors on large scale web-based datasets coupled with the ever-increasing\nnumber of available pretrained uni-modal models, the task of uni-modal models\nselection and subsequent connector module training becomes computationally\ndemanding. To address this under-studied critical problem, we propose\nHypernetwork Model Alignment (Hyma), a novel all-in-one solution for optimal\nuni-modal model selection and connector training by leveraging hypernetworks.\nSpecifically, our framework utilizes the parameter prediction capability of a\nhypernetwork to obtain jointly trained connector modules for $N \\times M$\ncombinations of uni-modal models. In our experiments, Hyma reduces the cost of\nsearching for the best performing uni-modal model pair by $10\\times$, while\nmatching the ranking and trained connector performance obtained via grid search\nacross a suite of diverse multi-modal benchmarks.", "published": "2025-07-14 07:51:01", "link": "http://arxiv.org/abs/2507.10015v2", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "VerifyBench: A Systematic Benchmark for Evaluating Reasoning Verifiers Across Domains", "abstract": "Large language models (LLMs) increasingly rely on reinforcement learning (RL)\nto enhance their reasoning capabilities through feedback. A critical challenge\nis verifying the consistency of model-generated responses and reference\nanswers, since these responses are often lengthy, diverse, and nuanced.\nRule-based verifiers struggle with complexity, prompting the use of model-based\nverifiers. However, specialized verifiers lack flexibility, while general LLM\njudges can be inconsistent. Existing research primarily focuses on building\nbetter verifiers, yet a systematic evaluation of different types of verifiers'\nperformance across domains remains lacking, severely constraining the reliable\ndevelopment of Reinforcement Learning with Verifiable Reward (RLVR). To address\nthis, we propose VerifyBench--a cross-domain comprehensive benchmark for\nsystematically evaluating verifiers. We construct 4,000 expert-level questions\ncovering mathematics, physics, chemistry, and biology. Each question is\nequipped with reference answers and diverse responses. The reliability of the\nevaluation is ensured through a rigorous annotation process conducted by a\nmultidisciplinary expert team. We design a four-dimensional experimental\nframework to comprehensively compare the performance boundaries of specialized\nverifiers and general LLMs under combined conditions of extracted answers vs.\ncomplete responses, and short vs. long outputs. Our evaluation uncovers\nfundamental trade-offs in verifiers: while specialized verifiers achieve\nleading accuracy, they exhibit deficiencies in recall; general models show\nstronger inclusivity but unstable precision. More importantly, we discover\nverifiers' high sensitivity to input structure and inherent limitations in\ncross-domain generalization, providing critical insights into the bottlenecks\nof current verifier technology.", "published": "2025-07-14 03:45:24", "link": "http://arxiv.org/abs/2507.09884v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Is Human-Written Data Enough? The Challenge of Teaching Reasoning to LLMs Without RL or Distillation", "abstract": "Reasoning-capable language models achieve state-of-the-art performance in\ndiverse complex tasks by generating long, explicit Chain-of-Thought (CoT)\ntraces. While recent works show that base models can acquire such reasoning\ntraces via reinforcement learning or distillation from stronger models like\nDeepSeek-R1, previous works demonstrate that even short CoT prompting without\nfine-tuning is able to improve reasoning. We ask whether long CoT can be\ninduced in a base model using only prompting or minimal tuning. Using just 20\nlong CoT examples from the reasoning model \\texttt{QwQ-32B-Preview}, we lightly\nfine-tune the base model \\texttt{Qwen2.5-32B}. The resulting model outperforms\nthe much larger \\texttt{Qwen2.5-Math-72B-Instruct}, showing that a handful of\nhigh-quality examples can unlock strong reasoning capabilities. We further\nexplore using CoT data from non-reasoning models and human annotators, enhanced\nwith prompt engineering, multi-pass editing, and structural guidance. However,\nneither matches the performance of reasoning model traces, suggesting that\ncertain latent qualities of expert CoT are difficult to replicate. We analyze\nkey properties of reasoning data, such as problem difficulty, diversity, and\nanswer length, that influence reasoning distillation. While challenges remain,\nwe are optimistic that carefully curated human-written CoT, even in small\nquantities, can activate reasoning behaviors in base models. We release our\nhuman-authored dataset across refinement stages and invite further\ninvestigation into what makes small-scale reasoning supervision so effective.", "published": "2025-07-14 01:14:50", "link": "http://arxiv.org/abs/2507.09850v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "CLA: Latent Alignment for Online Continual Self-Supervised Learning", "abstract": "Self-supervised learning (SSL) is able to build latent representations that\ngeneralize well to unseen data. However, only a few SSL techniques exist for\nthe online CL setting, where data arrives in small minibatches, the model must\ncomply with a fixed computational budget, and task boundaries are absent. We\nintroduce Continual Latent Alignment (CLA), a novel SSL strategy for Online CL\nthat aligns the representations learned by the current model with past\nrepresentations to mitigate forgetting. We found that our CLA is able to speed\nup the convergence of the training process in the online scenario,\noutperforming state-of-the-art approaches under the same computational budget.\nSurprisingly, we also discovered that using CLA as a pretraining protocol in\nthe early stages of pretraining leads to a better final performance when\ncompared to a full i.i.d. pretraining.", "published": "2025-07-14 16:23:39", "link": "http://arxiv.org/abs/2507.10434v2", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Text-Visual Semantic Constrained AI-Generated Image Quality Assessment", "abstract": "With the rapid advancements in Artificial Intelligence Generated Image (AGI)\ntechnology, the accurate assessment of their quality has become an increasingly\nvital requirement. Prevailing methods typically rely on cross-modal models like\nCLIP or BLIP to evaluate text-image alignment and visual quality. However, when\napplied to AGIs, these methods encounter two primary challenges: semantic\nmisalignment and details perception missing. To address these limitations, we\npropose Text-Visual Semantic Constrained AI-Generated Image Quality Assessment\n(SC-AGIQA), a unified framework that leverages text-visual semantic constraints\nto significantly enhance the comprehensive evaluation of both text-image\nconsistency and perceptual distortion in AI-generated images. Our approach\nintegrates key capabilities from multiple models and tackles the aforementioned\nchallenges by introducing two core modules: the Text-assisted Semantic\nAlignment Module (TSAM), which leverages Multimodal Large Language Models\n(MLLMs) to bridge the semantic gap by generating an image description and\ncomparing it against the original prompt for a refined consistency check, and\nthe Frequency-domain Fine-Grained Degradation Perception Module (FFDPM), which\ndraws inspiration from Human Visual System (HVS) properties by employing\nfrequency domain analysis combined with perceptual sensitivity weighting to\nbetter quantify subtle visual distortions and enhance the capture of\nfine-grained visual quality details in images. Extensive experiments conducted\non multiple benchmark datasets demonstrate that SC-AGIQA outperforms existing\nstate-of-the-art methods. The code is publicly available at\nhttps://github.com/mozhu1/SC-AGIQA.", "published": "2025-07-14 16:21:05", "link": "http://arxiv.org/abs/2507.10432v2", "categories": ["cs.CV", "I.4.7"], "primary_category": "cs.CV"}
{"title": "Text Embedding Knows How to Quantize Text-Guided Diffusion Models", "abstract": "Despite the success of diffusion models in image generation tasks such as\ntext-to-image, the enormous computational complexity of diffusion models limits\ntheir use in resource-constrained environments. To address this, network\nquantization has emerged as a promising solution for designing efficient\ndiffusion models. However, existing diffusion model quantization methods do not\nconsider input conditions, such as text prompts, as an essential source of\ninformation for quantization. In this paper, we propose a novel quantization\nmethod dubbed Quantization of Language-to-Image diffusion models using text\nPrompts (QLIP). QLIP leverages text prompts to guide the selection of bit\nprecision for every layer at each time step. In addition, QLIP can be\nseamlessly integrated into existing quantization methods to enhance\nquantization efficiency. Our extensive experiments demonstrate the\neffectiveness of QLIP in reducing computational complexity and improving the\nquality of the generated images across various datasets.", "published": "2025-07-14 14:44:59", "link": "http://arxiv.org/abs/2507.10340v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Graph-based Multi-Modal Interaction Lightweight Network for Brain Tumor Segmentation (GMLN-BTS) in Edge Iterative MRI Lesion Localization System (EdgeIMLocSys)", "abstract": "Brain tumor segmentation plays a critical role in clinical diagnosis and\ntreatment planning, yet the variability in imaging quality across different MRI\nscanners presents significant challenges to model generalization. To address\nthis, we propose the Edge Iterative MRI Lesion Localization System\n(EdgeIMLocSys), which integrates Continuous Learning from Human Feedback to\nadaptively fine-tune segmentation models based on clinician feedback, thereby\nenhancing robustness to scanner-specific imaging characteristics. Central to\nthis system is the Graph-based Multi-Modal Interaction Lightweight Network for\nBrain Tumor Segmentation (GMLN-BTS), which employs a Modality-Aware Adaptive\nEncoder (M2AE) to extract multi-scale semantic features efficiently, and a\nGraph-based Multi-Modal Collaborative Interaction Module (G2MCIM) to model\ncomplementary cross-modal relationships via graph structures. Additionally, we\nintroduce a novel Voxel Refinement UpSampling Module (VRUM) that\nsynergistically combines linear interpolation and multi-scale transposed\nconvolutions to suppress artifacts while preserving high-frequency details,\nimproving segmentation boundary accuracy. Our proposed GMLN-BTS model achieves\na Dice score of 85.1% on the BraTS2017 dataset with only 4.58 million\nparameters, representing a 98% reduction compared to mainstream 3D Transformer\nmodels, and significantly outperforms existing lightweight approaches. This\nwork demonstrates a synergistic breakthrough in achieving high-accuracy,\nresource-efficient brain tumor segmentation suitable for deployment in\nresource-constrained clinical environments.", "published": "2025-07-14 07:29:49", "link": "http://arxiv.org/abs/2507.09995v2", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "IM-LUT: Interpolation Mixing Look-Up Tables for Image Super-Resolution", "abstract": "Super-resolution (SR) has been a pivotal task in image processing, aimed at\nenhancing image resolution across various applications. Recently, look-up table\n(LUT)-based approaches have attracted interest due to their efficiency and\nperformance. However, these methods are typically designed for fixed scale\nfactors, making them unsuitable for arbitrary-scale image SR (ASISR). Existing\nASISR techniques often employ implicit neural representations, which come with\nconsiderable computational cost and memory demands. To address these\nlimitations, we propose Interpolation Mixing LUT (IM-LUT), a novel framework\nthat operates ASISR by learning to blend multiple interpolation functions to\nmaximize their representational capacity. Specifically, we introduce IM-Net, a\nnetwork trained to predict mixing weights for interpolation functions based on\nlocal image patterns and the target scale factor. To enhance efficiency of\ninterpolation-based methods, IM-Net is transformed into IM-LUT, where LUTs are\nemployed to replace computationally expensive operations, enabling lightweight\nand fast inference on CPUs while preserving reconstruction quality.\nExperimental results on several benchmark datasets demonstrate that IM-LUT\nconsistently achieves a superior balance between image quality and efficiency\ncompared to existing methods, highlighting its potential as a promising\nsolution for resource-constrained applications.", "published": "2025-07-14 05:02:57", "link": "http://arxiv.org/abs/2507.09923v2", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
