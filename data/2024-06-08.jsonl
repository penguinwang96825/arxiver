{"title": "Advancing Semantic Textual Similarity Modeling: A Regression Framework\n  with Translated ReLU and Smooth K2 Loss", "abstract": "Since the introduction of BERT and RoBERTa, research on Semantic Textual\nSimilarity (STS) has made groundbreaking progress. Particularly, the adoption\nof contrastive learning has substantially elevated state-of-the-art performance\nacross various STS benchmarks. However, contrastive learning categorizes text\npairs as either semantically similar or dissimilar, failing to leverage\nfine-grained annotated information and necessitating large batch sizes to\nprevent model collapse. These constraints pose challenges for researchers\nengaged in STS tasks that involve nuanced similarity levels or those with\nlimited computational resources, compelling them to explore alternatives like\nSentence-BERT. Despite its efficiency, Sentence-BERT tackles STS tasks from a\nclassification perspective, overlooking the progressive nature of semantic\nrelationships, which results in suboptimal performance. To bridge this gap,\nthis paper presents an innovative regression framework and proposes two simple\nyet effective loss functions: Translated ReLU and Smooth K2 Loss. Experimental\nresults demonstrate that our method achieves convincing performance across\nseven established STS benchmarks and offers the potential for further\noptimization of contrastive learning pre-trained models.", "published": "2024-06-08 02:52:43", "link": "http://arxiv.org/abs/2406.05326v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MemeGuard: An LLM and VLM-based Framework for Advancing Content\n  Moderation via Meme Intervention", "abstract": "In the digital world, memes present a unique challenge for content moderation\ndue to their potential to spread harmful content. Although detection methods\nhave improved, proactive solutions such as intervention are still limited, with\ncurrent research focusing mostly on text-based content, neglecting the\nwidespread influence of multimodal content like memes. Addressing this gap, we\npresent \\textit{MemeGuard}, a comprehensive framework leveraging Large Language\nModels (LLMs) and Visual Language Models (VLMs) for meme intervention.\n\\textit{MemeGuard} harnesses a specially fine-tuned VLM, \\textit{VLMeme}, for\nmeme interpretation, and a multimodal knowledge selection and ranking mechanism\n(\\textit{MKS}) for distilling relevant knowledge. This knowledge is then\nemployed by a general-purpose LLM to generate contextually appropriate\ninterventions. Another key contribution of this work is the\n\\textit{\\textbf{I}ntervening} \\textit{\\textbf{C}yberbullying in\n\\textbf{M}ultimodal \\textbf{M}emes (ICMM)} dataset, a high-quality, labeled\ndataset featuring toxic memes and their corresponding human-annotated\ninterventions. We leverage \\textit{ICMM} to test \\textit{MemeGuard},\ndemonstrating its proficiency in generating relevant and effective responses to\ntoxic memes.", "published": "2024-06-08 04:09:20", "link": "http://arxiv.org/abs/2406.05344v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Flexible and Adaptable Summarization via Expertise Separation", "abstract": "A proficient summarization model should exhibit both flexibility -- the\ncapacity to handle a range of in-domain summarization tasks, and adaptability\n-- the competence to acquire new knowledge and adjust to unseen out-of-domain\ntasks. Unlike large language models (LLMs) that achieve this through parameter\nscaling, we propose a more parameter-efficient approach in this study. Our\nmotivation rests on the principle that the general summarization ability to\ncapture salient information can be shared across different tasks, while the\ndomain-specific summarization abilities need to be distinct and tailored.\nConcretely, we propose MoeSumm, a Mixture-of-Expert Summarization architecture,\nwhich utilizes a main expert for gaining the general summarization capability\nand deputy experts that selectively collaborate to meet specific summarization\ntask requirements. We further propose a max-margin loss to stimulate the\nseparation of these abilities. Our model's distinct separation of general and\ndomain-specific summarization abilities grants it with notable flexibility and\nadaptability, all while maintaining parameter efficiency. MoeSumm achieves\nflexibility by managing summarization across multiple domains with a single\nmodel, utilizing a shared main expert and selected deputy experts. It exhibits\nadaptability by tailoring deputy experts to cater to out-of-domain few-shot and\nzero-shot scenarios. Experimental results on 11 datasets show the superiority\nof our model compared with recent baselines and LLMs. We also provide\nstatistical and visual evidence of the distinct separation of the two abilities\nin MoeSumm (https://github.com/iriscxy/MoE_Summ).", "published": "2024-06-08 05:31:19", "link": "http://arxiv.org/abs/2406.05360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Write Summary Step-by-Step: A Pilot Study of Stepwise Summarization", "abstract": "Nowadays, neural text generation has made tremendous progress in abstractive\nsummarization tasks. However, most of the existing summarization models take in\nthe whole document all at once, which sometimes cannot meet the needs in\npractice. Practically, social text streams such as news events and tweets keep\ngrowing from time to time, and can only be fed to the summarization system step\nby step. Hence, in this paper, we propose the task of Stepwise Summarization,\nwhich aims to generate a new appended summary each time a new document is\nproposed. The appended summary should not only summarize the newly added\ncontent but also be coherent with the previous summary, to form an up-to-date\ncomplete summary. To tackle this challenge, we design an adversarial learning\nmodel, named Stepwise Summary Generator (SSG). First, SSG selectively processes\nthe new document under the guidance of the previous summary, obtaining polished\ndocument representation. Next, SSG generates the summary considering both the\nprevious summary and the document. Finally, a convolutional-based discriminator\nis employed to determine whether the newly generated summary is coherent with\nthe previous summary. For the experiment, we extend the traditional two-step\nupdate summarization setting to a multi-step stepwise setting, and re-propose a\nlarge-scale stepwise summarization dataset based on a public story generation\ndataset. Extensive experiments on this dataset show that SSG achieves\nstate-of-the-art performance in terms of both automatic metrics and human\nevaluations. Ablation studies demonstrate the effectiveness of each module in\nour framework. We also discuss the benefits and limitations of recent large\nlanguage models on this task.", "published": "2024-06-08 05:37:26", "link": "http://arxiv.org/abs/2406.05361v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Planning Like Human: A Dual-process Framework for Dialogue Planning", "abstract": "In proactive dialogue, the challenge lies not just in generating responses\nbut in steering conversations toward predetermined goals, a task where Large\nLanguage Models (LLMs) typically struggle due to their reactive nature.\nTraditional approaches to enhance dialogue planning in LLMs, ranging from\nelaborate prompt engineering to the integration of policy networks, either face\nefficiency issues or deliver suboptimal performance. Inspired by the\ndualprocess theory in psychology, which identifies two distinct modes of\nthinking - intuitive (fast) and analytical (slow), we propose the Dual-Process\nDialogue Planning (DPDP) framework. DPDP embodies this theory through two\ncomplementary planning systems: an instinctive policy model for familiar\ncontexts and a deliberative Monte Carlo Tree Search (MCTS) mechanism for\ncomplex, novel scenarios. This dual strategy is further coupled with a novel\ntwo-stage training regimen: offline Reinforcement Learning for robust initial\npolicy model formation followed by MCTS-enhanced on-the-fly learning, which\nensures a dynamic balance between efficiency and strategic depth. Our empirical\nevaluations across diverse dialogue tasks affirm DPDP's superiority in\nachieving both high-quality dialogues and operational efficiency, outpacing\nexisting methods.", "published": "2024-06-08 06:52:47", "link": "http://arxiv.org/abs/2406.05374v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MaTableGPT: GPT-based Table Data Extractor from Materials Science\n  Literature", "abstract": "Efficiently extracting data from tables in the scientific literature is\npivotal for building large-scale databases. However, the tables reported in\nmaterials science papers exist in highly diverse forms; thus, rule-based\nextractions are an ineffective approach. To overcome this challenge, we present\nMaTableGPT, which is a GPT-based table data extractor from the materials\nscience literature. MaTableGPT features key strategies of table data\nrepresentation and table splitting for better GPT comprehension and filtering\nhallucinated information through follow-up questions. When applied to a vast\nvolume of water splitting catalysis literature, MaTableGPT achieved an\nextraction accuracy (total F1 score) of up to 96.8%. Through comprehensive\nevaluations of the GPT usage cost, labeling cost, and extraction accuracy for\nthe learning methods of zero-shot, few-shot and fine-tuning, we present a\nPareto-front mapping where the few-shot learning method was found to be the\nmost balanced solution owing to both its high extraction accuracy (total F1\nscore>95%) and low cost (GPT usage cost of 5.97 US dollars and labeling cost of\n10 I/O paired examples). The statistical analyses conducted on the database\ngenerated by MaTableGPT revealed valuable insights into the distribution of the\noverpotential and elemental utilization across the reported catalysts in the\nwater splitting literature.", "published": "2024-06-08 10:31:18", "link": "http://arxiv.org/abs/2406.05431v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating and Addressing Hallucinations of LLMs in Tasks Involving\n  Negation", "abstract": "Large Language Models (LLMs) have achieved remarkable performance across a\nwide variety of natural language tasks. However, they have been shown to suffer\nfrom a critical limitation pertinent to 'hallucination' in their output. Recent\nresearch has focused on investigating and addressing this problem for a variety\nof tasks such as biography generation, question answering, abstractive\nsummarization, and dialogue generation. However, the crucial aspect pertaining\nto 'negation' has remained considerably underexplored. Negation is important\nbecause it adds depth and nuance to the understanding of language and is also\ncrucial for logical reasoning and inference. In this work, we address the above\nlimitation and particularly focus on studying the impact of negation in LLM\nhallucinations. Specifically, we study four tasks with negation: 'false premise\ncompletion', 'constrained fact generation', 'multiple choice question\nanswering', and 'fact generation'. We show that open-source state-of-the-art\nLLMs such as LLaMA-2-chat, Vicuna, and Orca-2 hallucinate considerably on all\nthese tasks involving negation which underlines a critical shortcoming of these\nmodels. Addressing this problem, we further study numerous strategies to\nmitigate these hallucinations and demonstrate their impact.", "published": "2024-06-08 15:20:56", "link": "http://arxiv.org/abs/2406.05494v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalist Multimodal AI: A Review of Architectures, Challenges and\n  Opportunities", "abstract": "Multimodal models are expected to be a critical component to future advances\nin artificial intelligence. This field is starting to grow rapidly with a surge\nof new design elements motivated by the success of foundation models in natural\nlanguage processing (NLP) and vision. It is widely hoped that further extending\nthe foundation models to multiple modalities (e.g., text, image, video, sensor,\ntime series, graph, etc.) will ultimately lead to generalist multimodal models,\ni.e. one model across different data modalities and tasks. However, there is\nlittle research that systematically analyzes recent multimodal models\n(particularly the ones that work beyond text and vision) with respect to the\nunderling architecture proposed. Therefore, this work provides a fresh\nperspective on generalist multimodal models (GMMs) via a novel architecture and\ntraining configuration specific taxonomy. This includes factors such as\nUnifiability, Modularity, and Adaptability that are pertinent and essential to\nthe wide adoption and application of GMMs. The review further highlights key\nchallenges and prospects for the field and guide the researchers into the new\nadvancements.", "published": "2024-06-08 15:30:46", "link": "http://arxiv.org/abs/2406.05496v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do LLMs Recognize me, When I is not me: Assessment of LLMs Understanding\n  of Turkish Indexical Pronouns in Indexical Shift Contexts", "abstract": "Large language models (LLMs) have shown impressive capabilities in tasks such\nas machine translation, text summarization, question answering, and solving\ncomplex mathematical problems. However, their primary training on data-rich\nlanguages like English limits their performance in low-resource languages. This\nstudy addresses this gap by focusing on the Indexical Shift problem in Turkish.\nThe Indexical Shift problem involves resolving pronouns in indexical shift\ncontexts, a grammatical challenge not present in high-resource languages like\nEnglish. We present the first study examining indexical shift in any language,\nreleasing a Turkish dataset specifically designed for this purpose. Our\nIndexical Shift Dataset consists of 156 multiple-choice questions, each\nannotated with necessary linguistic details, to evaluate LLMs in a few-shot\nsetting. We evaluate recent multilingual LLMs, including GPT-4, GPT-3.5,\nCohere-AYA, Trendyol-LLM, and Turkcell-LLM, using this dataset. Our analysis\nreveals that even advanced models like GPT-4 struggle with the grammatical\nnuances of indexical shift in Turkish, achieving only moderate performance.\nThese findings underscore the need for focused research on the grammatical\nchallenges posed by low-resource languages. We released the dataset and code\n\\href{https://anonymous.4open.science/r/indexical_shift_llm-E1B4} {here}.", "published": "2024-06-08 20:30:53", "link": "http://arxiv.org/abs/2406.05569v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DeviceBERT: Applied Transfer Learning With Targeted Annotations and\n  Vocabulary Enrichment to Identify Medical Device and Component Terminology in\n  FDA Recall Summaries", "abstract": "FDA Medical Device recalls are critical and time-sensitive events, requiring\nswift identification of impacted devices to inform the public of a recall event\nand ensure patient safety. The OpenFDA device recall dataset contains valuable\ninformation about ongoing device recall actions, but manually extracting\nrelevant device information from the recall action summaries is a\ntime-consuming task. Named Entity Recognition (NER) is a task in Natural\nLanguage Processing (NLP) that involves identifying and categorizing named\nentities in unstructured text. Existing NER models, including domain-specific\nmodels like BioBERT, struggle to correctly identify medical device trade names,\npart numbers and component terms within these summaries. To address this, we\npropose DeviceBERT, a medical device annotation, pre-processing and enrichment\npipeline, which builds on BioBERT to identify and label medical device\nterminology in the device recall summaries with improved accuracy. Furthermore,\nwe demonstrate that our approach can be applied effectively for performing\nentity recognition tasks where training data is limited or sparse.", "published": "2024-06-08 00:33:22", "link": "http://arxiv.org/abs/2406.05307v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LoCoCo: Dropping In Convolutions for Long Context Compression", "abstract": "This paper tackles the memory hurdle of processing long context sequences in\nLarge Language Models (LLMs), by presenting a novel approach, Dropping In\nConvolutions for Long Context Compression (LoCoCo). LoCoCo employs only a\nfixed-size Key-Value (KV) cache, and can enhance efficiency in both inference\nand fine-tuning stages. Diverging from prior methods that selectively drop KV\npairs based on heuristics, LoCoCo leverages a data-driven adaptive fusion\ntechnique, blending previous KV pairs with incoming tokens to minimize the loss\nof contextual information and ensure accurate attention modeling. This token\nintegration is achieved through injecting one-dimensional convolutional kernels\nthat dynamically calculate mixing weights for each KV cache slot. Designed for\nbroad compatibility with existing LLM frameworks, LoCoCo allows for\nstraightforward \"drop-in\" integration without needing architectural\nmodifications, while incurring minimal tuning overhead. Experiments demonstrate\nthat LoCoCo maintains consistently outstanding performance across various\ncontext lengths and can achieve a high context compression rate during both\ninference and fine-tuning phases. During inference, we successfully compressed\nup to 3482 tokens into a 128-size KV cache, while retaining comparable\nperformance to the full sequence - an accuracy improvement of up to 0.2791\ncompared to baselines at the same cache size. During post-training tuning, we\nalso effectively extended the context length from 4K to 32K using a KV cache of\nfixed size 512, achieving performance similar to fine-tuning with entire\nsequences.", "published": "2024-06-08 01:35:11", "link": "http://arxiv.org/abs/2406.05317v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Teaching-Assistant-in-the-Loop: Improving Knowledge Distillation from\n  Imperfect Teacher Models in Low-Budget Scenarios", "abstract": "There is increasing interest in distilling task-specific knowledge from large\nlanguage models (LLM) to smaller student models. Nonetheless, LLM distillation\npresents a dual challenge: 1) there is a high cost associated with querying the\nteacher LLM, such as GPT-4, for gathering an ample number of demonstrations; 2)\nthe teacher LLM might provide imperfect outputs with a negative impact on the\nstudent's learning process. To enhance sample efficiency within\nresource-constrained, imperfect teacher scenarios, we propose a three-component\nframework leveraging three signal types. The first signal is the student's\nself-consistency (consistency of student multiple outputs), which is a proxy of\nthe student's confidence. Specifically, we introduce a ``teaching assistant''\n(TA) model to assess the uncertainty of both the student's and the teacher's\noutputs via confidence scoring, which serves as another two signals for student\ntraining. Furthermore, we propose a two-stage training schema to first warm up\nthe student with a small proportion of data to better utilize student's signal.\nExperiments have shown the superiority of our proposed framework for four\ncomplex reasoning tasks. On average, our proposed two-stage framework brings a\nrelative improvement of up to 20.79% compared to fine-tuning without any\nsignals across datasets.", "published": "2024-06-08 02:17:43", "link": "http://arxiv.org/abs/2406.05322v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FacLens: Transferable Probe for Foreseeing Non-Factuality in Large\n  Language Models", "abstract": "Despite advancements in large language models (LLMs), non-factual responses\nremain prevalent. Unlike extensive studies on post-hoc detection of such\nresponses, this work studies non-factuality prediction (NFP), aiming to predict\nwhether an LLM will generate a non-factual response to a question before the\ngeneration process. Previous efforts on NFP have demonstrated LLMs' awareness\nof their internal knowledge, but they still face challenges in efficiency and\ntransferability. In this work, we propose a lightweight NFP model named\nFactuality Lens (FacLens), which effectively probes hidden representations of\nquestions for the NFP task. Besides, we discover that hidden question\nrepresentations sourced from different LLMs exhibit similar NFP patterns, which\nenables the transferability of FacLens across LLMs to reduce development costs.\nExtensive experiments highlight FacLens's superiority in both effectiveness and\nefficiency.", "published": "2024-06-08 02:59:52", "link": "http://arxiv.org/abs/2406.05328v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "M3GIA: A Cognition Inspired Multilingual and Multimodal General\n  Intelligence Ability Benchmark", "abstract": "As recent multi-modality large language models (MLLMs) have shown formidable\nproficiency on various complex tasks, there has been increasing attention on\ndebating whether these models could eventually mirror human intelligence.\nHowever, existing benchmarks mainly focus on evaluating solely on task\nperformance, such as the accuracy of identifying the attribute of an object.\nCombining well-developed cognitive science to understand the intelligence of\nMLLMs beyond superficial achievements remains largely unexplored. To this end,\nwe introduce the first cognitive-driven multi-lingual and multi-modal benchmark\nto evaluate the general intelligence ability of MLLMs, dubbed M3GIA.\nSpecifically, we identify five key cognitive factors based on the\nwell-recognized Cattell-Horn-Carrol (CHC) model of intelligence and propose a\nnovel evaluation metric. In addition, since most MLLMs are trained to perform\nin different languages, a natural question arises: is language a key factor\ninfluencing the cognitive ability of MLLMs? As such, we go beyond English to\nencompass other languages based on their popularity, including Chinese, French,\nSpanish, Portuguese and Korean, to construct our M3GIA. We make sure all the\ndata relevant to the cultural backgrounds are collected from their native\ncontext to avoid English-centric bias. We collected a significant corpus of\ndata from human participants, revealing that the most advanced MLLM reaches the\nlower boundary of human intelligence in English. Yet, there remains a\npronounced disparity in the other five languages assessed. We also reveals an\ninteresting winner takes all phenomenon that are aligned with the discovery in\ncognitive studies. Our benchmark will be open-sourced, with the aspiration of\nfacilitating the enhancement of cognitive capabilities in MLLMs.", "published": "2024-06-08 04:07:09", "link": "http://arxiv.org/abs/2406.05343v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "MLLM-SR: Conversational Symbolic Regression base Multi-Modal Large\n  Language Models", "abstract": "Formulas are the language of communication between humans and nature. It is\nan important research topic of artificial intelligence to find expressions from\nobserved data to reflect the relationship between each variable in the data,\nwhich is called a symbolic regression problem. The existing symbolic regression\nmethods directly generate expressions according to the given observation data,\nand we cannot require the algorithm to generate expressions that meet specific\nrequirements according to the known prior knowledge. For example, the\nexpression needs to contain $\\sin$ or be symmetric, and so on. Even if it can,\nit often requires very complex operations, which is very inconvenient. In this\npaper, based on multi-modal large language models, we propose MLLM-SR, a\nconversational symbolic regression method that can generate expressions that\nmeet the requirements simply by describing the requirements with natural\nlanguage instructions. By experimenting on the Nguyen dataset, we can\ndemonstrate that MLLM-SR leads the state-of-the-art baselines in fitting\nperformance. More notably, we experimentally demonstrate that MLLM-SR can well\nunderstand the prior knowledge we add to the natural language instructions.\nMoreover, the addition of prior knowledge can effectively guide MLLM-SR to\ngenerate correct expressions.", "published": "2024-06-08 09:17:54", "link": "http://arxiv.org/abs/2406.05410v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Recent advancements in computational morphology : A comprehensive survey", "abstract": "Computational morphology handles the language processing at the word level.\nIt is one of the foundational tasks in the NLP pipeline for the development of\nhigher level NLP applications. It mainly deals with the processing of words and\nword forms. Computational Morphology addresses various sub problems such as\nmorpheme boundary detection, lemmatization, morphological feature tagging,\nmorphological reinflection etc. In this paper, we present exhaustive survey of\nthe methods for developing computational morphology related tools. We survey\nthe literature in the chronological order starting from the conventional\nmethods till the recent evolution of deep neural network based approaches. We\nalso review the existing datasets available for this task across the languages.\nWe discuss about the effectiveness of neural model compared with the\ntraditional models and present some unique challenges associated with building\nthe computational morphology tools. We conclude by discussing some recent and\nopen research issues in this field.", "published": "2024-06-08 10:07:33", "link": "http://arxiv.org/abs/2406.05424v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Design of reliable technology valuation model with calibrated machine\n  learning of patent indicators", "abstract": "Machine learning (ML) has revolutionized the digital transformation of\ntechnology valuation by predicting the value of patents with high accuracy.\nHowever, the lack of validation regarding the reliability of these models\nhinders experts from fully trusting the confidence of model predictions. To\naddress this issue, we propose an analytical framework for reliable technology\nvaluation using calibrated ML models, which provide robust confidence levels in\nmodel predictions. We extract quantitative patent indicators that represent\nvarious technology characteristics as input data, using the patent maintenance\nperiod as a proxy for technology values. Multiple ML models are developed to\ncapture the nonlinear relationship between patent indicators and technology\nvalue. The reliability and accuracy of these models are evaluated, presenting a\nPareto-front map where the expected calibration error, Matthews correlation\ncoefficient and F1-scores are compared. After identifying the best-performing\nmodel, we apply SHapley Additive exPlanation (SHAP) analysis to pinpoint the\nmost significant input features by confidence bin. Through a case study, we\nconfirmed that the proposed approach offers a practical guideline for\ndeveloping reliable and accurate ML-based technology valuation models, with\nsignificant implications for both academia and industry.", "published": "2024-06-08 11:52:37", "link": "http://arxiv.org/abs/2406.05446v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fighting Against the Repetitive Training and Sample Dependency Problem\n  in Few-shot Named Entity Recognition", "abstract": "Few-shot named entity recognition (NER) systems recognize entities using a\nfew labeled training examples. The general pipeline consists of a span detector\nto identify entity spans in text and an entity-type classifier to assign types\nto entities. Current span detectors rely on extensive manual labeling to guide\ntraining. Almost every span detector requires initial training on basic span\nfeatures followed by adaptation to task-specific features. This process leads\nto repetitive training of the basic span features among span detectors.\nAdditionally, metric-based entity-type classifiers, such as prototypical\nnetworks, typically employ a specific metric that gauges the distance between\nthe query sample and entity-type referents, ultimately assigning the most\nprobable entity type to the query sample. However, these classifiers encounter\nthe sample dependency problem, primarily stemming from the limited samples\navailable for each entity-type referent. To address these challenges, we\nproposed an improved few-shot NER pipeline. First, we introduce a steppingstone\nspan detector that is pre-trained on open-domain Wikipedia data. It can be used\nto initialize the pipeline span detector to reduce the repetitive training of\nbasic features. Second, we leverage a large language model (LLM) to set\nreliable entity-type referents, eliminating reliance on few-shot samples of\neach type. Our model exhibits superior performance with fewer training steps\nand human-labeled data compared with baselines, as demonstrated through\nextensive experiments on various datasets. Particularly in fine-grained\nfew-shot NER settings, our model outperforms strong baselines, including\nChatGPT. We will publicly release the code, datasets, LLM outputs, and model\ncheckpoints.", "published": "2024-06-08 12:36:30", "link": "http://arxiv.org/abs/2406.05460v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Representation Learning with Conditional Information Flow Maximization", "abstract": "This paper proposes an information-theoretic representation learning\nframework, named conditional information flow maximization, to extract\nnoise-invariant sufficient representations for the input data and target task.\nIt promotes the learned representations have good feature uniformity and\nsufficient predictive ability, which can enhance the generalization of\npre-trained language models (PLMs) for the target task. Firstly, an information\nflow maximization principle is proposed to learn more sufficient\nrepresentations for the input and target by simultaneously maximizing both\ninput-representation and representation-label mutual information. Unlike the\ninformation bottleneck, we handle the input-representation information in an\nopposite way to avoid the over-compression issue of latent representations.\nBesides, to mitigate the negative effect of potential redundant features from\nthe input, we design a conditional information minimization principle to\neliminate negative redundant features while preserve noise-invariant features.\nExperiments on 13 language understanding benchmarks demonstrate that our method\neffectively improves the performance of PLMs for classification and regression.\nExtensive experiments show that the learned representations are more\nsufficient, robust and transferable.", "published": "2024-06-08 16:19:18", "link": "http://arxiv.org/abs/2406.05510v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ThatiAR: Subjectivity Detection in Arabic News Sentences", "abstract": "Detecting subjectivity in news sentences is crucial for identifying media\nbias, enhancing credibility, and combating misinformation by flagging\nopinion-based content. It provides insights into public sentiment, empowers\nreaders to make informed decisions, and encourages critical thinking. While\nresearch has developed methods and systems for this purpose, most efforts have\nfocused on English and other high-resourced languages. In this study, we\npresent the first large dataset for subjectivity detection in Arabic,\nconsisting of ~3.6K manually annotated sentences, and GPT-4o based explanation.\nIn addition, we included instructions (both in English and Arabic) to\nfacilitate LLM based fine-tuning. We provide an in-depth analysis of the\ndataset, annotation process, and extensive benchmark results, including PLMs\nand LLMs. Our analysis of the annotation process highlights that annotators\nwere strongly influenced by their political, cultural, and religious\nbackgrounds, especially at the beginning of the annotation process. The\nexperimental results suggest that LLMs with in-context learning provide better\nperformance. We aim to release the dataset and resources for the community.", "published": "2024-06-08 19:24:17", "link": "http://arxiv.org/abs/2406.05559v1", "categories": ["cs.CL", "cs.AI", "68T50", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Creativity Has Left the Chat: The Price of Debiasing Language Models", "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\nbut can exhibit biases and may generate toxic content. While alignment\ntechniques like Reinforcement Learning from Human Feedback (RLHF) reduce these\nissues, their impact on creativity, defined as syntactic and semantic\ndiversity, remains unexplored. We investigate the unintended consequences of\nRLHF on the creativity of LLMs through three experiments focusing on the\nLlama-2 series. Our findings reveal that aligned models exhibit lower entropy\nin token predictions, form distinct clusters in the embedding space, and\ngravitate towards \"attractor states\", indicating limited output diversity. Our\nfindings have significant implications for marketers who rely on LLMs for\ncreative tasks such as copywriting, ad creation, and customer persona\ngeneration. The trade-off between consistency and creativity in aligned models\nshould be carefully considered when selecting the appropriate model for a given\napplication. We also discuss the importance of prompt engineering in harnessing\nthe creative potential of base models.", "published": "2024-06-08 22:14:51", "link": "http://arxiv.org/abs/2406.05587v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "QCQA: Quality and Capacity-aware grouped Query Attention", "abstract": "Excessive memory requirements of key and value features (KV-cache) present\nsignificant challenges in the autoregressive inference of large language models\n(LLMs), restricting both the speed and length of text generation. Approaches\nsuch as Multi-Query Attention (MQA) and Grouped Query Attention (GQA) mitigate\nthese challenges by grouping query heads and consequently reducing the number\nof corresponding key and value heads. However, MQA and GQA decrease the\nKV-cache size requirements at the expense of LLM accuracy (quality of text\ngeneration). These methods do not ensure an optimal tradeoff between KV-cache\nsize and text generation quality due to the absence of quality-aware grouping\nof query heads. To address this issue, we propose Quality and Capacity-Aware\nGrouped Query Attention (QCQA), which identifies optimal query head groupings\nusing an evolutionary algorithm with a computationally efficient and\ninexpensive fitness function. We demonstrate that QCQA achieves a significantly\nbetter tradeoff between KV-cache capacity and LLM accuracy compared to GQA. For\nthe Llama2 $7\\,$B model, QCQA achieves $\\mathbf{20}$\\% higher accuracy than GQA\nwith similar KV-cache size requirements in the absence of fine-tuning. After\nfine-tuning both QCQA and GQA, for a similar KV-cache size, QCQA provides\n$\\mathbf{10.55}\\,$\\% higher accuracy than GQA. Furthermore, QCQA requires\n$40\\,$\\% less KV-cache size than GQA to attain similar accuracy. The proposed\nquality and capacity-aware grouping of query heads can serve as a new paradigm\nfor KV-cache optimization in autoregressive LLM inference.", "published": "2024-06-08 07:49:55", "link": "http://arxiv.org/abs/2406.10247v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Worst Prompt Performance of Large Language Models", "abstract": "The performance of large language models (LLMs) is acutely sensitive to the\nphrasing of prompts, which raises significant concerns about their reliability\nin real-world scenarios. Existing studies often divide prompts into task-level\ninstructions and case-level inputs and primarily focus on evaluating and\nimproving robustness against variations in tasks-level instructions. However,\nthis setup fails to fully address the diversity of real-world user queries and\nassumes the existence of task-specific datasets. To address these limitations,\nwe introduce RobustAlpacaEval, a new benchmark that consists of semantically\nequivalent case-level queries and emphasizes the importance of using the worst\nprompt performance to gauge the lower bound of model performance. Extensive\nexperiments on RobustAlpacaEval with ChatGPT and six open-source LLMs from the\nLlama, Mistral, and Gemma families uncover substantial variability in model\nperformance; for instance, a difference of 45.48% between the worst and best\nperformance for the Llama-2-70B-chat model, with its worst performance dipping\nas low as 9.38%. We further illustrate the difficulty in identifying the worst\nprompt from both model-agnostic and model-dependent perspectives, emphasizing\nthe absence of a shortcut to characterize the worst prompt. We also attempt to\nenhance the worst prompt performance using existing prompt engineering and\nprompt consistency methods, but find that their impact is limited. These\nfindings underscore the need to create more resilient LLMs that can maintain\nhigh performance across diverse prompts. Data and code are available at\nhttps://github.com/cbwbuaa/On-the-Worst-Prompt- Performance-of-LLMs.", "published": "2024-06-08 13:40:38", "link": "http://arxiv.org/abs/2406.10248v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Aligned at the Start: Conceptual Groupings in LLM Embeddings", "abstract": "This paper shifts focus to the often-overlooked input embeddings - the\ninitial representations fed into transformer blocks. Using fuzzy graph,\nk-nearest neighbor (k-NN), and community detection, we analyze embeddings from\ndiverse LLMs, finding significant categorical community structure aligned with\npredefined concepts and categories aligned with humans. We observe these\ngroupings exhibit within-cluster organization (such as hierarchies, topological\nordering, etc.), hypothesizing a fundamental structure that precedes contextual\nprocessing. To further investigate the conceptual nature of these groupings, we\nexplore cross-model alignments across different LLM categories within their\ninput embeddings, observing a medium to high degree of alignment. Furthermore,\nprovide evidence that manipulating these groupings can play a functional role\nin mitigating ethnicity bias in LLM tasks.", "published": "2024-06-08 01:27:19", "link": "http://arxiv.org/abs/2406.05315v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Toward Reliable Ad-hoc Scientific Information Extraction: A Case Study\n  on Two Materials Datasets", "abstract": "We explore the ability of GPT-4 to perform ad-hoc schema based information\nextraction from scientific literature. We assess specifically whether it can,\nwith a basic prompting approach, replicate two existing material science\ndatasets, given the manuscripts from which they were originally manually\nextracted. We employ materials scientists to perform a detailed manual error\nanalysis to assess where the model struggles to faithfully extract the desired\ninformation, and draw on their insights to suggest research directions to\naddress this broadly important task.", "published": "2024-06-08 04:24:16", "link": "http://arxiv.org/abs/2406.05348v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CaLM: Contrasting Large and Small Language Models to Verify Grounded\n  Generation", "abstract": "Grounded generation aims to equip language models (LMs) with the ability to\nproduce more credible and accountable responses by accurately citing verifiable\nsources. However, existing methods, by either feeding LMs with raw or\npreprocessed materials, remain prone to errors. To address this, we introduce\nCaLM, a novel verification framework. CaLM leverages the insight that a robust\ngrounded response should be consistent with information derived solely from its\ncited sources. Our framework empowers smaller LMs, which rely less on\nparametric memory and excel at processing relevant information given a query,\nto validate the output of larger LMs. Larger LM responses that closely align\nwith the smaller LMs' output, which relies exclusively on cited documents, are\nverified. Responses showing discrepancies are iteratively refined through a\nfeedback loop. Experiments on three open-domain question-answering datasets\ndemonstrate significant performance gains of 1.5% to 7% absolute average\nwithout any required model fine-tuning.", "published": "2024-06-08 06:04:55", "link": "http://arxiv.org/abs/2406.05365v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Venn Diagram Prompting : Accelerating Comprehension with Scaffolding\n  Effect", "abstract": "We introduce Venn Diagram (VD) Prompting, an innovative prompting technique\nwhich allows Large Language Models (LLMs) to combine and synthesize information\nacross complex, diverse and long-context documents in knowledge-intensive\nquestion-answering tasks. Generating answers from multiple documents involves\nnumerous steps to extract relevant and unique information and amalgamate it\ninto a cohesive response. To improve the quality of the final answer, multiple\nLLM calls or pretrained models are used to perform different tasks such as\nsummarization, reorganization and customization. The approach covered in the\npaper focuses on replacing the multi-step strategy via a single LLM call using\nVD prompting. Our proposed technique also aims to eliminate the inherent\nposition bias in the LLMs, enhancing consistency in answers by removing\nsensitivity to the sequence of input information. It overcomes the challenge of\ninconsistency traditionally associated with varying input sequences. We also\nexplore the practical applications of the VD prompt based on our examination of\nthe prompt's outcomes. In the experiments performed on four public benchmark\nquestion-answering datasets, VD prompting continually matches or surpasses the\nperformance of a meticulously crafted instruction prompt which adheres to\noptimal guidelines and practices.", "published": "2024-06-08 06:27:26", "link": "http://arxiv.org/abs/2406.05369v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text\n  to Speech Synthesizers", "abstract": "This paper introduces VALL-E 2, the latest advancement in neural codec\nlanguage models that marks a milestone in zero-shot text-to-speech synthesis\n(TTS), achieving human parity for the first time. Based on its predecessor,\nVALL-E, the new iteration introduces two significant enhancements: Repetition\nAware Sampling refines the original nucleus sampling process by accounting for\ntoken repetition in the decoding history. It not only stabilizes the decoding\nbut also circumvents the infinite loop issue. Grouped Code Modeling organizes\ncodec codes into groups to effectively shorten the sequence length, which not\nonly boosts inference speed but also addresses the challenges of long sequence\nmodeling. Our experiments on the LibriSpeech and VCTK datasets show that VALL-E\n2 surpasses previous systems in speech robustness, naturalness, and speaker\nsimilarity. It is the first of its kind to reach human parity on these\nbenchmarks. Moreover, VALL-E 2 consistently synthesizes high-quality speech,\neven for sentences that are traditionally challenging due to their complexity\nor repetitive phrases. The advantages of this work could contribute to valuable\nendeavors, such as generating speech for individuals with aphasia or people\nwith amyotrophic lateral sclerosis. See https://aka.ms/valle2 for demos of\nVALL-E 2.", "published": "2024-06-08 06:31:03", "link": "http://arxiv.org/abs/2406.05370v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Deconstructing The Ethics of Large Language Models from Long-standing\n  Issues to New-emerging Dilemmas: A Survey", "abstract": "Large Language Models (LLMs) have achieved unparalleled success across\ndiverse language modeling tasks in recent years. However, this progress has\nalso intensified ethical concerns, impacting the deployment of LLMs in everyday\ncontexts. This paper provides a comprehensive survey of ethical challenges\nassociated with LLMs, from longstanding issues such as copyright infringement,\nsystematic bias, and data privacy, to emerging problems like truthfulness and\nsocial norms. We critically analyze existing research aimed at understanding,\nexamining, and mitigating these ethical risks. Our survey underscores\nintegrating ethical standards and societal values into the development of LLMs,\nthereby guiding the development of responsible and ethically aligned language\nmodels.", "published": "2024-06-08 07:55:01", "link": "http://arxiv.org/abs/2406.05392v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mmm whatcha say? Uncovering distal and proximal context effects in first\n  and second-language word perception using psychophysical reverse correlation", "abstract": "Acoustic context effects, where surrounding changes in pitch, rate or timbre\ninfluence the perception of a sound, are well documented in speech perception,\nbut how they interact with language background remains unclear. Using a\nreverse-correlation approach, we systematically varied the pitch and speech\nrate in phrases around different pairs of vowels for second language (L2)\nspeakers of English (/i/-/I/) and French (/u/-/y/), thus reconstructing, in a\ndata-driven manner, the prosodic profiles that bias their perception. Testing\nEnglish and French speakers (n=25), we showed that vowel perception is in fact\ninfluenced by conflicting effects from the surrounding pitch and speech rate: a\ncongruent proximal effect 0.2s pre-target and a distal contrastive effect up to\n1s before; and found that L1 and L2 speakers exhibited strikingly similar\nprosodic profiles in perception. We provide a novel method to investigate\nacoustic context effects across stimuli, timescales, and acoustic domain.", "published": "2024-06-08 16:25:30", "link": "http://arxiv.org/abs/2406.05515v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Verbalized Probabilistic Graphical Modeling", "abstract": "Human cognition excels at transcending sensory input and forming latent\nrepresentations that structure our understanding of the world. Although Large\nLanguage Models (LLMs) can produce chain-of-thought reasoning, they lack a\nprincipled framework to capture latent structures and model uncertainty,\nespecially in compositional reasoning tasks. We propose Verbalized\nProbabilistic Graphical Modeling (vPGM), a Bayesian prompting framework that\nguides LLMs to simulate key principles of Probabilistic Graphical Models (PGMs)\nin natural language. Unlike many traditional probabilistic methods requiring\nsubstantial domain expertise or specialized training, vPGM bypasses\nexpert-driven model design, making it well-suited for scenarios with limited\nassumptions or scarce data. We evaluated our model on several compositional\nreasoning tasks, both close-ended and open-ended. Our results indicate that the\nmodel effectively enhances confidence calibration and text generation quality.", "published": "2024-06-08 16:35:31", "link": "http://arxiv.org/abs/2406.05516v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Online DPO: Online Direct Preference Optimization with Fast-Slow Chasing", "abstract": "Direct Preference Optimization (DPO) improves the alignment of large language\nmodels (LLMs) with human values by training directly on human preference\ndatasets, eliminating the need for reward models. However, due to the presence\nof cross-domain human preferences, direct continual training can lead to\ncatastrophic forgetting, limiting DPO's performance and efficiency. Inspired by\nintraspecific competition driving species evolution, we propose a Online\nFast-Slow chasing DPO (OFS-DPO) for preference alignment, simulating\ncompetition through fast and slow chasing among models to facilitate rapid\nadaptation. Specifically, we first derive the regret upper bound for online\nlearning, validating our motivation with a min-max optimization pattern. Based\non this, we introduce two identical modules using Low-rank Adaptive (LoRA) with\ndifferent optimization speeds to simulate intraspecific competition, and\npropose a new regularization term to guide their learning. To further mitigate\ncatastrophic forgetting in cross-domain scenarios, we extend the OFS-DPO with\nLoRA modules combination strategy, resulting in the Cross domain Online\nFast-Slow chasing DPO (COFS-DPO). This method leverages linear combinations of\nfast modules parameters from different task domains, fully utilizing historical\ninformation to achive continual value alignment. Experimental results show that\nOFS-DPO outperforms DPO in in-domain alignment, while COFS-DPO excels in\ncross-domain continual learning scenarios.", "published": "2024-06-08 17:30:54", "link": "http://arxiv.org/abs/2406.05534v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A Fine-tuning Dataset and Benchmark for Large Language Models for\n  Protein Understanding", "abstract": "The parallels between protein sequences and natural language in their\nsequential structures have inspired the application of large language models\n(LLMs) to protein understanding. Despite the success of LLMs in NLP, their\neffectiveness in comprehending protein sequences remains an open question,\nlargely due to the absence of datasets linking protein sequences to descriptive\ntext. Researchers have then attempted to adapt LLMs for protein understanding\nby integrating a protein sequence encoder with a pre-trained LLM. However, this\nadaptation raises a fundamental question: \"Can LLMs, originally designed for\nNLP, effectively comprehend protein sequences as a form of language?\" Current\ndatasets fall short in addressing this question due to the lack of a direct\ncorrelation between protein sequences and corresponding text descriptions,\nlimiting the ability to train and evaluate LLMs for protein understanding\neffectively. To bridge this gap, we introduce ProteinLMDataset, a dataset\nspecifically designed for further self-supervised pretraining and supervised\nfine-tuning (SFT) of LLMs to enhance their capability for protein sequence\ncomprehension. Specifically, ProteinLMDataset includes 17.46 billion tokens for\npretraining and 893,000 instructions for SFT. Additionally, we present\nProteinLMBench, the first benchmark dataset consisting of 944 manually verified\nmultiple-choice questions for assessing the protein understanding capabilities\nof LLMs. ProteinLMBench incorporates protein-related details and sequences in\nmultiple languages, establishing a new standard for evaluating LLMs' abilities\nin protein comprehension. The large language model InternLM2-7B, pretrained and\nfine-tuned on the ProteinLMDataset, outperforms GPT-4 on ProteinLMBench,\nachieving the highest accuracy score.", "published": "2024-06-08 18:11:30", "link": "http://arxiv.org/abs/2406.05540v2", "categories": ["q-bio.QM", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "q-bio.QM"}
{"title": "Exploring the Benefits of Tokenization of Discrete Acoustic Units", "abstract": "Tokenization algorithms that merge the units of a base vocabulary into\nlarger, variable-rate units have become standard in natural language processing\ntasks. This idea, however, has been mostly overlooked when the vocabulary\nconsists of phonemes or Discrete Acoustic Units (DAUs), an audio-based\nrepresentation that is playing an increasingly important role due to the\nsuccess of discrete language-modeling techniques. In this paper, we showcase\nthe advantages of tokenization of phonetic units and of DAUs on three\nprediction tasks: grapheme-to-phoneme, grapheme-to-DAUs, and unsupervised\nspeech generation using DAU language modeling. We demonstrate that tokenization\nyields significant improvements in terms of performance, as well as training\nand inference speed, across all three tasks. We also offer theoretical insights\nto provide some explanation for the superior performance observed.", "published": "2024-06-08 18:34:28", "link": "http://arxiv.org/abs/2406.05547v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automata Extraction from Transformers", "abstract": "In modern machine (ML) learning systems, Transformer-based architectures have\nachieved milestone success across a broad spectrum of tasks, yet understanding\ntheir operational mechanisms remains an open problem. To improve the\ntransparency of ML systems, automata extraction methods, which interpret\nstateful ML models as automata typically through formal languages, have proven\neffective for explaining the mechanism of recurrent neural networks (RNNs).\nHowever, few works have been applied to this paradigm to Transformer models. In\nparticular, understanding their processing of formal languages and identifying\ntheir limitations in this area remains unexplored. In this paper, we propose an\nautomata extraction algorithm specifically designed for Transformer models.\nTreating the Transformer model as a black-box system, we track the model\nthrough the transformation process of their internal latent representations\nduring their operations, and then use classical pedagogical approaches like L*\nalgorithm to interpret them as deterministic finite-state automata (DFA).\nOverall, our study reveals how the Transformer model comprehends the structure\nof formal languages, which not only enhances the interpretability of the\nTransformer-based ML systems but also marks a crucial step toward a deeper\nunderstanding of how ML systems process formal languages. Code and data are\navailable at https://github.com/Zhang-Yihao/Transfomer2DFA.", "published": "2024-06-08 20:07:24", "link": "http://arxiv.org/abs/2406.05564v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.FL"], "primary_category": "cs.LG"}
{"title": "CERET: Cost-Effective Extrinsic Refinement for Text Generation", "abstract": "Large Language Models (LLMs) are powerful models for generation tasks, but\nthey may not generate good quality outputs in their first attempt. Apart from\nmodel fine-tuning, existing approaches to improve prediction accuracy and\nquality typically involve LLM self-improvement / self-reflection that\nincorporate feedback from models themselves. Despite their effectiveness, these\nmethods are hindered by their high computational cost and lack of scalability.\nIn this work, we propose CERET, a method for refining text generations by\nconsidering semantic stability, entailment and inter-sample uncertainty\nmeasures. Experimental results show that CERET outperforms Self-consistency and\nSelf-rerank baselines consistently under various task setups, by ~1.6% in\nRouge-1 for abstractive summarization and ~3.5% in hit rate for question\nanswering. Compared to LLM Self-rerank method, our approach only requires 9.4%\nof its latency and is more cost-effective.", "published": "2024-06-08 22:17:52", "link": "http://arxiv.org/abs/2406.05588v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Autoregressive Diffusion Transformer for Text-to-Speech Synthesis", "abstract": "Audio language models have recently emerged as a promising approach for\nvarious audio generation tasks, relying on audio tokenizers to encode waveforms\ninto sequences of discrete symbols. Audio tokenization often poses a necessary\ncompromise between code bitrate and reconstruction accuracy. When dealing with\nlow-bitrate audio codes, language models are constrained to process only a\nsubset of the information embedded in the audio, which in turn restricts their\ngenerative capabilities. To circumvent these issues, we propose encoding audio\nas vector sequences in continuous space $\\mathbb R^d$ and autoregressively\ngenerating these sequences using a decoder-only diffusion transformer (ARDiT).\nOur findings indicate that ARDiT excels in zero-shot text-to-speech and\nexhibits performance that compares to or even surpasses that of\nstate-of-the-art models. High-bitrate continuous speech representation enables\nalmost flawless reconstruction, allowing our model to achieve nearly perfect\nspeech editing. Our experiments reveal that employing Integral Kullback-Leibler\n(IKL) divergence for distillation at each autoregressive step significantly\nboosts the perceived quality of the samples. Simultaneously, it condenses the\niterative sampling process of the diffusion model into a single step.\nFurthermore, ARDiT can be trained to predict several continuous vectors in one\nstep, significantly reducing latency during sampling. Impressively, one of our\nmodels can generate $170$ ms of $24$ kHz speech per evaluation step with\nminimal degradation in performance. Audio samples are available at\nhttp://ardit-tts.github.io/ .", "published": "2024-06-08 18:57:13", "link": "http://arxiv.org/abs/2406.05551v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "LDM-SVC: Latent Diffusion Model Based Zero-Shot Any-to-Any Singing Voice\n  Conversion with Singer Guidance", "abstract": "Any-to-any singing voice conversion (SVC) is an interesting audio editing\ntechnique, aiming to convert the singing voice of one singer into that of\nanother, given only a few seconds of singing data. However, during the\nconversion process, the issue of timbre leakage is inevitable: the converted\nsinging voice still sounds like the original singer's voice. To tackle this, we\npropose a latent diffusion model for SVC (LDM-SVC) in this work, which attempts\nto perform SVC in the latent space using an LDM. We pretrain a variational\nautoencoder structure using the noted open-source So-VITS-SVC project based on\nthe VITS framework, which is then used for the LDM training. Besides, we\npropose a singer guidance training method based on classifier-free guidance to\nfurther suppress the timbre of the original singer. Experimental results show\nthe superiority of the proposed method over previous works in both subjective\nand objective evaluations of timbre similarity.", "published": "2024-06-08 02:42:52", "link": "http://arxiv.org/abs/2406.05325v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "To what extent can ASV systems naturally defend against spoofing\n  attacks?", "abstract": "The current automatic speaker verification (ASV) task involves making binary\ndecisions on two types of trials: target and non-target. However, emerging\nadvancements in speech generation technology pose significant threats to the\nreliability of ASV systems. This study investigates whether ASV effortlessly\nacquires robustness against spoofing attacks (i.e., zero-shot capability) by\nsystematically exploring diverse ASV systems and spoofing attacks, ranging from\ntraditional to cutting-edge techniques. Through extensive analyses conducted on\neight distinct ASV systems and 29 spoofing attack systems, we demonstrate that\nthe evolution of ASV inherently incorporates defense mechanisms against\nspoofing attacks. Nevertheless, our findings also underscore that the\nadvancement of spoofing attacks far outpaces that of ASV systems, hence\nnecessitating further research on spoofing-robust ASV methodologies.", "published": "2024-06-08 03:44:39", "link": "http://arxiv.org/abs/2406.05339v3", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Diversifying and Expanding Frequency-Adaptive Convolution Kernels for\n  Sound Event Detection", "abstract": "Frequency dynamic convolution (FDY conv) has shown the state-of-the-art\nperformance in sound event detection (SED) using frequency-adaptive kernels\nobtained by frequency-varying combination of basis kernels. However, FDY conv\nlacks an explicit mean to diversify frequency-adaptive kernels, potentially\nlimiting the performance. In addition, size of basis kernels is limited while\ntime-frequency patterns span larger spectro-temporal range. Therefore, we\npropose dilated frequency dynamic convolution (DFD conv) which diversifies and\nexpands frequency-adaptive kernels by introducing different dilation sizes to\nbasis kernels. Experiments showed advantages of varying dilation sizes along\nfrequency dimension, and analysis on attention weight variance proved dilated\nbasis kernels are effectively diversified. By adapting class-wise median filter\nwith intersection-based F1 score, proposed DFD-CRNN outperforms FDY-CRNN by\n3.12% in terms of polyphonic sound detection score (PSDS).", "published": "2024-06-08 03:50:33", "link": "http://arxiv.org/abs/2406.05341v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards Lightweight Speaker Verification via Adaptive Neural Network\n  Quantization", "abstract": "Modern speaker verification (SV) systems typically demand expensive storage\nand computing resources, thereby hindering their deployment on mobile devices.\nIn this paper, we explore adaptive neural network quantization for lightweight\nspeaker verification. Firstly, we propose a novel adaptive uniform precision\nquantization method which enables the dynamic generation of quantization\ncentroids customized for each network layer based on k-means clustering. By\napplying it to the pre-trained SV systems, we obtain a series of quantized\nvariants with different bit widths. To enhance the performance of low-bit\nquantized models, a mixed precision quantization algorithm along with a\nmulti-stage fine-tuning (MSFT) strategy is further introduced. Unlike uniform\nprecision quantization, mixed precision approach allows for the assignment of\nvarying bit widths to different network layers. When bit combination is\ndetermined, MSFT is employed to progressively quantize and fine-tune network in\na specific order. Finally, we design two distinct binary quantization schemes\nto mitigate performance degradation of 1-bit quantized models: the static and\nadaptive quantizers. Experiments on VoxCeleb demonstrate that lossless 4-bit\nuniform precision quantization is achieved on both ResNets and DF-ResNets,\nyielding a promising compression ratio of around 8. Moreover, compared to\nuniform precision approach, mixed precision quantization not only obtains\nadditional performance improvements with a similar model size but also offers\nthe flexibility to generate bit combination for any desirable model size. In\naddition, our suggested 1-bit quantization schemes remarkably boost the\nperformance of binarized models. Finally, a thorough comparison with existing\nlightweight SV systems reveals that our proposed models outperform all previous\nmethods by a large margin across various model size ranges.", "published": "2024-06-08 05:29:46", "link": "http://arxiv.org/abs/2406.05359v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Relational Proxy Loss for Audio-Text based Keyword Spotting", "abstract": "In recent years, there has been an increasing focus on user convenience,\nleading to increased interest in text-based keyword enrollment systems for\nkeyword spotting (KWS). Since the system utilizes text input during the\nenrollment phase and audio input during actual usage, we call this task\naudio-text based KWS. To enable this task, both acoustic and text encoders are\ntypically trained using deep metric learning loss functions, such as triplet-\nand proxy-based losses. This study aims to improve existing methods by\nleveraging the structural relations within acoustic embeddings and within text\nembeddings. Unlike previous studies that only compare acoustic and text\nembeddings on a point-to-point basis, our approach focuses on the relational\nstructures within the embedding space by introducing the concept of Relational\nProxy Loss (RPL). By incorporating RPL, we demonstrated improved performance on\nthe Wall Street Journal (WSJ) corpus.", "published": "2024-06-08 01:21:17", "link": "http://arxiv.org/abs/2406.05314v1", "categories": ["eess.AS", "cs.AI", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Should you use a probabilistic duration model in TTS? Probably!\n  Especially for spontaneous speech", "abstract": "Converting input symbols to output audio in TTS requires modelling the\ndurations of speech sounds. Leading non-autoregressive (NAR) TTS models treat\nduration modelling as a regression problem. The same utterance is then spoken\nwith identical timings every time, unlike when a human speaks. Probabilistic\nmodels of duration have been proposed, but there is mixed evidence of their\nbenefits. However, prior studies generally only consider speech read aloud, and\nignore spontaneous speech, despite the latter being both a more common and a\nmore variable mode of speaking. We compare the effect of conventional\ndeterministic duration modelling to durations sampled from a powerful\nprobabilistic model based on conditional flow matching (OT-CFM), in three\ndifferent NAR TTS approaches: regression-based, deep generative, and\nend-to-end. Across four different corpora, stochastic duration modelling\nimproves probabilistic NAR TTS approaches, especially for spontaneous speech.\nPlease see https://shivammehta25.github.io/prob_dur/ for audio and resources.", "published": "2024-06-08 08:49:22", "link": "http://arxiv.org/abs/2406.05401v1", "categories": ["eess.AS", "cs.HC", "cs.SD", "68T07", "I.2.7; I.2.6; H.5.5"], "primary_category": "eess.AS"}
{"title": "DAISY: Data Adaptive Self-Supervised Early Exit for Speech\n  Representation Models", "abstract": "Self-supervised speech models have shown to be useful for various tasks, but\ntheir large size limits the use in devices with low computing power and memory.\nIn this work, we explore early exit, an approach for reducing latency by\nexiting the forward process of a network early. Most approaches of early exit\nneed a separate early exit model for each task, with some even requiring\nfine-tuning of the entire pretrained model. We introduce Data Adaptive\nSelf-Supervised Early Exit (DAISY), an approach that decides when to exit based\non the self-supervised loss, eliminating the need for multiple round of\ntraining and fine-tuning. DAISY matches the performance of HuBERT on the\nMiniSUPERB benchmark, but with much faster inference times. Our analysis on the\nadaptivity of DAISY shows that the model exits early (using fewer layers) on\nclean data while exits late (using more layers) on noisy data, dynamically\nadjusting the computational cost of inference based on the noise level of each\nsample.", "published": "2024-06-08 12:58:13", "link": "http://arxiv.org/abs/2406.05464v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
