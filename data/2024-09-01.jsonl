{"title": "Kullback-Leibler cluster entropy to quantify volatility correlation and risk diversity", "abstract": "The Kullback-Leibler cluster entropy $\\mathcal{D_{C}}[P \\| Q] $ is evaluated\nfor the empirical and model probability distributions $P$ and $Q$ of the\nclusters formed in the realized volatility time series of five assets (SP\\&500,\nNASDAQ, DJIA, DAX, FTSEMIB). The Kullback-Leibler functional $\\mathcal{D_{C}}[P\n\\| Q] $ provides complementary perspectives about the stochastic volatility\nprocess compared to the Shannon functional $\\mathcal{S_{C}}[P]$. While\n$\\mathcal{D_{C}}[P \\| Q] $ is maximum at the short time scales,\n$\\mathcal{S_{C}}[P]$ is maximum at the large time scales leading to\ncomplementary optimization criteria tracing back respectively to the maximum\nand minimum relative entropy evolution principles. The realized volatility is\nmodelled as a time-dependent fractional stochastic process characterized by\npower-law decaying distributions with positive correlation ($H>1/2$). As a case\nstudy, a multiperiod portfolio built on diversity indexes derived from the\nKullback-Leibler entropy measure of the realized volatility. The portfolio is\nrobust and exhibits better performances over the horizon periods. A comparison\nwith the portfolio built either according to the uniform distribution or in the\nframework of the Markowitz theory is also reported.", "published": "2024-09-01 14:16:06", "link": "http://arxiv.org/abs/2409.10543v1", "categories": ["q-fin.ST", "physics.data-an", "q-fin.PM"], "primary_category": "q-fin.ST"}
{"title": "Simulation of Social Media-Driven Bubble Formation in Financial Markets using an Agent-Based Model with Hierarchical Influence Network", "abstract": "We propose that a tree-like hierarchical structure represents a simple and\neffective way to model the emergent behaviour of financial markets, especially\nmarkets where there exists a pronounced intersection between social media\ninfluences and investor behaviour. To explore this hypothesis, we introduce an\nagent-based model of financial markets, where trading agents are embedded in a\nhierarchical network of communities, and communities influence the strategies\nand opinions of traders. Empirical analysis of the model shows that its\nbehaviour conforms to several stylized facts observed in real financial\nmarkets; and the model is able to realistically simulate the effects that\nsocial media-driven phenomena, such as echo chambers and pump-and-dump schemes,\nhave on financial markets.", "published": "2024-09-01 15:09:35", "link": "http://arxiv.org/abs/2409.00742v1", "categories": ["cs.MA", "cs.AI", "q-fin.TR", "I.2.11"], "primary_category": "cs.MA"}
{"title": "Correcting FLORES Evaluation Dataset for Four African Languages", "abstract": "This paper describes the corrections made to the FLORES evaluation (dev and\ndevtest) dataset for four African languages, namely Hausa, Northern Sotho\n(Sepedi), Xitsonga, and isiZulu. The original dataset, though groundbreaking in\nits coverage of low-resource languages, exhibited various inconsistencies and\ninaccuracies in the reviewed languages that could potentially hinder the\nintegrity of the evaluation of downstream tasks in natural language processing\n(NLP), especially machine translation. Through a meticulous review process by\nnative speakers, several corrections were identified and implemented, improving\nthe overall quality and reliability of the dataset. For each language, we\nprovide a concise summary of the errors encountered and corrected and also\npresent some statistical analysis that measures the difference between the\nexisting and corrected datasets. We believe that our corrections improve the\nlinguistic accuracy and reliability of the data and, thereby, contribute to a\nmore effective evaluation of NLP tasks involving the four African languages.\nFinally, we recommend that future translation efforts, particularly in\nlow-resource languages, prioritize the active involvement of native speakers at\nevery stage of the process to ensure linguistic accuracy and cultural\nrelevance.", "published": "2024-09-01 06:13:03", "link": "http://arxiv.org/abs/2409.00626v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Media Background Checks for Automated Source Critical\n  Reasoning", "abstract": "Not everything on the internet is true. This unfortunate fact requires both\nhumans and models to perform complex reasoning about credibility when working\nwith retrieved information. In NLP, this problem has seen little attention.\nIndeed, retrieval-augmented models are not typically expected to distrust\nretrieved documents. Human experts overcome the challenge by gathering signals\nabout the context, reliability, and tendency of source documents - that is,\nthey perform source criticism. We propose a novel NLP task focused on finding\nand summarising such signals. We introduce a new dataset of 6,709 \"media\nbackground checks\" derived from Media Bias / Fact Check, a volunteer-run\nwebsite documenting media bias. We test open-source and closed-source LLM\nbaselines with and without retrieval on this dataset, finding that retrieval\ngreatly improves performance. We furthermore carry out human evaluation,\ndemonstrating that 1) media background checks are helpful for humans, and 2)\nmedia background checks are helpful for retrieval-augmented models.", "published": "2024-09-01 17:06:06", "link": "http://arxiv.org/abs/2409.00781v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Text-Label Alignment for Hierarchical Text Classification", "abstract": "Hierarchical Text Classification (HTC) aims to categorize text data based on\na structured label hierarchy, resulting in predicted labels forming a\nsub-hierarchy tree. The semantics of the text should align with the semantics\nof the labels in this sub-hierarchy. With the sub-hierarchy changing for each\nsample, the dynamic nature of text-label alignment poses challenges for\nexisting methods, which typically process text and labels independently. To\novercome this limitation, we propose a Text-Label Alignment (TLA) loss\nspecifically designed to model the alignment between text and labels. We obtain\na set of negative labels for a given text and its positive label set. By\nleveraging contrastive learning, the TLA loss pulls the text closer to its\npositive label and pushes it away from its negative label in the embedding\nspace. This process aligns text representations with related labels while\ndistancing them from unrelated ones. Building upon this framework, we introduce\nthe Hierarchical Text-Label Alignment (HTLA) model, which leverages BERT as the\ntext encoder and GPTrans as the graph encoder and integrates text-label\nembeddings to generate hierarchy-aware representations. Experimental results on\nbenchmark datasets and comparison with existing baselines demonstrate the\neffectiveness of HTLA for HTC.", "published": "2024-09-01 17:48:29", "link": "http://arxiv.org/abs/2409.00788v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparing Discrete and Continuous Space LLMs for Speech Recognition", "abstract": "This paper investigates discrete and continuous speech representations in\nLarge Language Model (LLM)-based Automatic Speech Recognition (ASR), organizing\nthem by feature continuity and training approach into four categories:\nsupervised and unsupervised for both discrete and continuous types. We further\nclassify LLMs based on their input and autoregressive feedback into continuous\nand discrete-space models. Using specialized encoders and comparative analysis\nwith a Joint-Training-From-Scratch Language Model (JTFS LM) and pre-trained\nLLaMA2-7b, we provide a detailed examination of their effectiveness. Our work\nmarks the first extensive comparison of speech representations in LLM-based ASR\nand explores various modeling techniques. We present an open-sourced\nachievement of a state-of-the-art Word Error Rate (WER) of 1.69\\% on\nLibriSpeech using a HuBERT encoder, offering valuable insights for advancing\nASR and natural language processing (NLP) research.", "published": "2024-09-01 18:29:45", "link": "http://arxiv.org/abs/2409.00800v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-evolving Agents with reflective and memory-augmented abilities", "abstract": "Large language models (LLMs) have made significant advances in the field of\nnatural language processing, but they still face challenges such as continuous\ndecision-making. In this research, we propose a novel framework by integrating\niterative feedback, reflective mechanisms, and a memory optimization mechanism\nbased on the Ebbinghaus forgetting curve, it significantly enhances the agents'\ncapabilities in handling multi-tasking and long-span information.", "published": "2024-09-01 23:36:34", "link": "http://arxiv.org/abs/2409.00872v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Multi-turn Conversation Stance Detection: A Challenge Dataset\n  and Effective Model", "abstract": "Stance detection, which aims to identify public opinion towards specific\ntargets using social media data, is an important yet challenging task. With the\nproliferation of diverse multimodal social media content including text, and\nimages multimodal stance detection (MSD) has become a crucial research area.\nHowever, existing MSD studies have focused on modeling stance within individual\ntext-image pairs, overlooking the multi-party conversational contexts that\nnaturally occur on social media. This limitation stems from a lack of datasets\nthat authentically capture such conversational scenarios, hindering progress in\nconversational MSD. To address this, we introduce a new multimodal multi-turn\nconversational stance detection dataset (called MmMtCSD). To derive stances\nfrom this challenging dataset, we propose a novel multimodal large language\nmodel stance detection framework (MLLM-SD), that learns joint stance\nrepresentations from textual and visual modalities. Experiments on MmMtCSD show\nstate-of-the-art performance of our proposed MLLM-SD approach for multimodal\nstance detection. We believe that MmMtCSD will contribute to advancing\nreal-world applications of stance detection research.", "published": "2024-09-01 03:16:30", "link": "http://arxiv.org/abs/2409.00597v1", "categories": ["cs.MM", "cs.CL"], "primary_category": "cs.MM"}
{"title": "TinyAgent: Function Calling at the Edge", "abstract": "Recent large language models (LLMs) have enabled the development of advanced\nagentic systems that can integrate various tools and APIs to fulfill user\nqueries through function calling. However, the deployment of these LLMs on the\nedge has not been explored since they typically require cloud-based\ninfrastructure due to their substantial model size and computational demands.\nTo this end, we present TinyAgent, an end-to-end framework for training and\ndeploying task-specific small language model agents capable of function calling\nfor driving agentic systems at the edge. We first show how to enable accurate\nfunction calling for open-source models via the LLMCompiler framework. We then\nsystematically curate a high-quality dataset for function calling, which we use\nto fine-tune two small language models, TinyAgent-1.1B and 7B. For efficient\ninference, we introduce a novel tool retrieval method to reduce the input\nprompt length and utilize quantization to further accelerate the inference\nspeed. As a driving application, we demonstrate a local Siri-like system for\nApple's MacBook that can execute user commands through text or voice input. Our\nresults show that our models can achieve, and even surpass, the\nfunction-calling capabilities of larger models like GPT-4-Turbo, while being\nfully deployed at the edge. We open-source our dataset, models, and installable\npackage and provide a demo video for our MacBook assistant agent.", "published": "2024-09-01 04:23:48", "link": "http://arxiv.org/abs/2409.00608v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DAMe: Personalized Federated Social Event Detection with Dual\n  Aggregation Mechanism", "abstract": "Training social event detection models through federated learning (FedSED)\naims to improve participants' performance on the task. However, existing\nfederated learning paradigms are inadequate for achieving FedSED's objective\nand exhibit limitations in handling the inherent heterogeneity in social data.\nThis paper proposes a personalized federated learning framework with a dual\naggregation mechanism for social event detection, namely DAMe. We present a\nnovel local aggregation strategy utilizing Bayesian optimization to incorporate\nglobal knowledge while retaining local characteristics. Moreover, we introduce\na global aggregation strategy to provide clients with maximum external\nknowledge of their preferences. In addition, we incorporate a global-local\nevent-centric constraint to prevent local overfitting and ``client-drift''.\nExperiments within a realistic simulation of a natural federated setting,\nutilizing six social event datasets spanning six languages and two social media\nplatforms, along with an ablation study, have demonstrated the effectiveness of\nthe proposed framework. Further robustness analyses have shown that DAMe is\nresistant to injection attacks.", "published": "2024-09-01 04:56:41", "link": "http://arxiv.org/abs/2409.00614v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Does Knowledge Localization Hold True? Surprising Differences Between\n  Entity and Relation Perspectives in Language Models", "abstract": "Large language models encapsulate knowledge and have demonstrated superior\nperformance on various natural language processing tasks. Recent studies have\nlocalized this knowledge to specific model parameters, such as the MLP weights\nin intermediate layers. This study investigates the differences between entity\nand relational knowledge through knowledge editing. Our findings reveal that\nentity and relational knowledge cannot be directly transferred or mapped to\neach other. This result is unexpected, as logically, modifying the entity or\nthe relation within the same knowledge triplet should yield equivalent\noutcomes. To further elucidate the differences between entity and relational\nknowledge, we employ causal analysis to investigate how relational knowledge is\nstored in pre-trained models. Contrary to prior research suggesting that\nknowledge is stored in MLP weights, our experiments demonstrate that relational\nknowledge is also significantly encoded in attention modules. This insight\nhighlights the multifaceted nature of knowledge storage in language models,\nunderscoring the complexity of manipulating specific types of knowledge within\nthese models.", "published": "2024-09-01 05:09:11", "link": "http://arxiv.org/abs/2409.00617v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Entity-Aware Biaffine Attention Model for Improved Constituent Parsing\n  with Reduced Entity Violations", "abstract": "Constituency parsing involves analyzing a sentence by breaking it into\nsub-phrases, or constituents. While many deep neural models have achieved\nstate-of-the-art performance in this task, they often overlook the\nentity-violating issue, where an entity fails to form a complete sub-tree in\nthe resultant parsing tree. To address this, we propose an entity-aware\nbiaffine attention model for constituent parsing. This model incorporates\nentity information into the biaffine attention mechanism by using additional\nentity role vectors for potential phrases, which enhances the parsing accuracy.\nWe introduce a new metric, the Entity Violating Rate (EVR), to quantify the\nextent of entity violations in parsing results. Experiments on three popular\ndatasets-ONTONOTES, PTB, and CTB-demonstrate that our model achieves the lowest\nEVR while maintaining high precision, recall, and F1-scores comparable to\nexisting models. Further evaluation in downstream tasks, such as sentence\nsentiment analysis, highlights the effectiveness of our model and the validity\nof the proposed EVR metric.", "published": "2024-09-01 05:59:54", "link": "http://arxiv.org/abs/2409.00625v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Polyrating: A Cost-Effective and Bias-Aware Rating System for LLM\n  Evaluation", "abstract": "Rating-based human evaluation has become an essential tool to accurately\nevaluate the impressive performance of large language models (LLMs). However,\ncurrent rating systems suffer from several important limitations: first, they\nfail to account for biases that significantly influence evaluation results,\nsecond, they require large and expensive preference datasets to obtain accurate\nratings, and third, they do not facilitate meaningful comparisons of model\nratings across different tasks. To address these issues, we introduce\nPolyrating, an expressive and flexible rating system based on maximum a\nposteriori estimation that enables a more nuanced and thorough analysis of\nmodel performance at lower costs. Polyrating can detect and quantify biases\naffecting human preferences, ensuring fairer model comparisons. Further,\nPolyrating can reduce the cost of human evaluations by up to $41\\%$ for new\nmodels and up to $77\\%$ for new tasks by leveraging existing benchmark scores.\nLastly, Polyrating enables direct comparisons of ratings across different\ntasks, providing a comprehensive understanding of an LLMs' strengths,\nweaknesses, and relative performance across different applications.", "published": "2024-09-01 11:24:54", "link": "http://arxiv.org/abs/2409.00696v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ContextCite: Attributing Model Generation to Context", "abstract": "How do language models use information provided as context when generating a\nresponse? Can we infer whether a particular generated statement is actually\ngrounded in the context, a misinterpretation, or fabricated? To help answer\nthese questions, we introduce the problem of context attribution: pinpointing\nthe parts of the context (if any) that led a model to generate a particular\nstatement. We then present ContextCite, a simple and scalable method for\ncontext attribution that can be applied on top of any existing language model.\nFinally, we showcase the utility of ContextCite through three applications: (1)\nhelping verify generated statements (2) improving response quality by pruning\nthe context and (3) detecting poisoning attacks. We provide code for\nContextCite at https://github.com/MadryLab/context-cite.", "published": "2024-09-01 14:36:36", "link": "http://arxiv.org/abs/2409.00729v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LanguaShrink: Reducing Token Overhead with Psycholinguistics", "abstract": "As large language models (LLMs) improve their capabilities in handling\ncomplex tasks, the issues of computational cost and efficiency due to long\nprompts are becoming increasingly prominent. To accelerate model inference and\nreduce costs, we propose an innovative prompt compression framework called\nLanguaShrink. Inspired by the observation that LLM performance depends on the\ndensity and position of key information in the input prompts, LanguaShrink\nleverages psycholinguistic principles and the Ebbinghaus memory curve to\nachieve task-agnostic prompt compression. This effectively reduces prompt\nlength while preserving essential information. We referred to the training\nmethod of OpenChat.The framework introduces part-of-speech priority compression\nand data distillation techniques, using smaller models to learn compression\ntargets and employing a KL-regularized reinforcement learning strategy for\ntraining.\\cite{wang2023openchat} Additionally, we adopt a chunk-based\ncompression algorithm to achieve adjustable compression rates. We evaluate our\nmethod on multiple datasets, including LongBench, ZeroScrolls, Arxiv Articles,\nand a newly constructed novel test set. Experimental results show that\nLanguaShrink maintains semantic similarity while achieving up to 26 times\ncompression. Compared to existing prompt compression methods, LanguaShrink\nimproves end-to-end latency by 1.43 times.", "published": "2024-09-01 22:09:20", "link": "http://arxiv.org/abs/2409.00855v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Automatic Pseudo-Harmful Prompt Generation for Evaluating False Refusals\n  in Large Language Models", "abstract": "Safety-aligned large language models (LLMs) sometimes falsely refuse\npseudo-harmful prompts, like \"how to kill a mosquito,\" which are actually\nharmless. Frequent false refusals not only frustrate users but also provoke a\npublic backlash against the very values alignment seeks to protect. In this\npaper, we propose the first method to auto-generate diverse,\ncontent-controlled, and model-dependent pseudo-harmful prompts. Using this\nmethod, we construct an evaluation dataset called PHTest, which is ten times\nlarger than existing datasets, covers more false refusal patterns, and\nseparately labels controversial prompts. We evaluate 20 LLMs on PHTest,\nuncovering new insights due to its scale and labeling. Our findings reveal a\ntrade-off between minimizing false refusals and improving safety against\njailbreak attacks. Moreover, we show that many jailbreak defenses significantly\nincrease the false refusal rates, thereby undermining usability. Our method and\ndataset can help developers evaluate and fine-tune safer and more usable LLMs.\nOur code and dataset are available at\nhttps://github.com/umd-huang-lab/FalseRefusal", "published": "2024-09-01 03:25:59", "link": "http://arxiv.org/abs/2409.00598v1", "categories": ["cs.CL", "cs.CR", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Who Would Chatbots Vote For? Political Preferences of ChatGPT and Gemini\n  in the 2024 European Union Elections", "abstract": "This study examines the political bias of chatbots powered by large language\nmodels, namely ChatGPT and Gemini, in the context of the 2024 European\nParliament elections. The research focused on the evaluation of political\nparties represented in the European Parliament across 27 EU Member States by\nthese generative artificial intelligence (AI) systems. The methodology involved\ndaily data collection through standardized prompts on both platforms. The\nresults revealed a stark contrast: while Gemini mostly refused to answer\npolitical questions, ChatGPT provided consistent ratings. The analysis showed a\nsignificant bias in ChatGPT in favor of left-wing and centrist parties, with\nthe highest ratings for the Greens/European Free Alliance. In contrast,\nright-wing parties, particularly the Identity and Democracy group, received the\nlowest ratings. The study identified key factors influencing the ratings,\nincluding attitudes toward European integration and perceptions of democratic\nvalues. The findings highlight the need for a critical approach to information\nprovided by generative AI systems in a political context and call for more\ntransparency and regulation in this area.", "published": "2024-09-01 13:40:13", "link": "http://arxiv.org/abs/2409.00721v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.CY"}
{"title": "Hound: Hunting Supervision Signals for Few and Zero Shot Node\n  Classification on Text-attributed Graph", "abstract": "Text-attributed graph (TAG) is an important type of graph structured data\nwith text descriptions for each node. Few- and zero-shot node classification on\nTAGs have many applications in fields such as academia and social networks.\nHowever, the two tasks are challenging due to the lack of supervision signals,\nand existing methods only use the contrastive loss to align graph-based node\nembedding and language-based text embedding. In this paper, we propose Hound to\nimprove accuracy by introducing more supervision signals, and the core idea is\nto go beyond the node-text pairs that come with data. Specifically, we design\nthree augmentation techniques, i.e., node perturbation, text matching, and\nsemantics negation to provide more reference nodes for each text and vice\nversa. Node perturbation adds/drops edges to produce diversified node\nembeddings that can be matched with a text. Text matching retrieves texts with\nsimilar embeddings to match with a node. Semantics negation uses a negative\nprompt to construct a negative text with the opposite semantics, which is\ncontrasted with the original node and text. We evaluate Hound on 5 datasets and\ncompare with 13 state-of-the-art baselines. The results show that Hound\nconsistently outperforms all baselines, and its accuracy improvements over the\nbest-performing baseline are usually over 5%.", "published": "2024-09-01 14:20:01", "link": "http://arxiv.org/abs/2409.00727v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "The Dark Side of Human Feedback: Poisoning Large Language Models via\n  User Inputs", "abstract": "Large Language Models (LLMs) have demonstrated great capabilities in natural\nlanguage understanding and generation, largely attributed to the intricate\nalignment process using human feedback. While alignment has become an essential\ntraining component that leverages data collected from user queries, it\ninadvertently opens up an avenue for a new type of user-guided poisoning\nattacks. In this paper, we present a novel exploration into the latent\nvulnerabilities of the training pipeline in recent LLMs, revealing a subtle yet\neffective poisoning attack via user-supplied prompts to penetrate alignment\ntraining protections. Our attack, even without explicit knowledge about the\ntarget LLMs in the black-box setting, subtly alters the reward feedback\nmechanism to degrade model performance associated with a particular keyword,\nall while remaining inconspicuous. We propose two mechanisms for crafting\nmalicious prompts: (1) the selection-based mechanism aims at eliciting toxic\nresponses that paradoxically score high rewards, and (2) the generation-based\nmechanism utilizes optimizable prefixes to control the model output. By\ninjecting 1\\% of these specially crafted prompts into the data, through\nmalicious users, we demonstrate a toxicity score up to two times higher when a\nspecific trigger word is used. We uncover a critical vulnerability, emphasizing\nthat irrespective of the reward model, rewards applied, or base language model\nemployed, if training harnesses user-generated prompts, a covert compromise of\nthe LLMs is not only feasible but potentially inevitable.", "published": "2024-09-01 17:40:04", "link": "http://arxiv.org/abs/2409.00787v1", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LibriheavyMix: A 20,000-Hour Dataset for Single-Channel Reverberant\n  Multi-Talker Speech Separation, ASR and Speaker Diarization", "abstract": "The evolving speech processing landscape is increasingly focused on complex\nscenarios like meetings or cocktail parties with multiple simultaneous speakers\nand far-field conditions. Existing methodologies for addressing these\nchallenges fall into two categories: multi-channel and single-channel\nsolutions. Single-channel approaches, notable for their generality and\nconvenience, do not require specific information about microphone arrays.\n  This paper presents a large-scale far-field overlapping speech dataset,\ncrafted to advance research in speech separation, recognition, and speaker\ndiarization. This dataset is a critical resource for decoding ``Who said What\nand When'' in multi-talker, reverberant environments, a daunting challenge in\nthe field. Additionally, we introduce a pipeline system encompassing speech\nseparation, recognition, and diarization as a foundational benchmark.\nEvaluations on the WHAMR! dataset validate the broad applicability of the\nproposed data.", "published": "2024-09-01 19:23:08", "link": "http://arxiv.org/abs/2409.00819v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Building FKG.in: a Knowledge Graph for Indian Food", "abstract": "This paper presents an ontology design along with knowledge engineering, and\nmultilingual semantic reasoning techniques to build an automated system for\nassimilating culinary information for Indian food in the form of a knowledge\ngraph. The main focus is on designing intelligent methods to derive ontology\ndesigns and capture all-encompassing knowledge about food, recipes,\ningredients, cooking characteristics, and most importantly, nutrition, at\nscale. We present our ongoing work in this workshop paper, describe in some\ndetail the relevant challenges in curating knowledge of Indian food, and\npropose our high-level ontology design. We also present a novel workflow that\nuses AI, LLM, and language technology to curate information from recipe blog\nsites in the public domain to build knowledge graphs for Indian food. The\nmethods for knowledge curation proposed in this paper are generic and can be\nreplicated for any domain. The design is application-agnostic and can be used\nfor AI-driven smart analysis, building recommendation systems for Personalized\nDigital Health, and complementing the knowledge graph for Indian food with\ncontextual information such as user information, food biochemistry, geographic\ninformation, agricultural information, etc.", "published": "2024-09-01 20:18:36", "link": "http://arxiv.org/abs/2409.00830v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Report Cards: Qualitative Evaluation of Language Models Using Natural\n  Language Summaries", "abstract": "The rapid development and dynamic nature of large language models (LLMs) make\nit difficult for conventional quantitative benchmarks to accurately assess\ntheir capabilities. We propose report cards, which are human-interpretable,\nnatural language summaries of model behavior for specific skills or topics. We\ndevelop a framework to evaluate report cards based on three criteria:\nspecificity (ability to distinguish between models), faithfulness (accurate\nrepresentation of model capabilities), and interpretability (clarity and\nrelevance to humans). We also propose an iterative algorithm for generating\nreport cards without human supervision and explore its efficacy by ablating\nvarious design choices. Through experimentation with popular LLMs, we\ndemonstrate that report cards provide insights beyond traditional benchmarks\nand can help address the need for a more interpretable and holistic evaluation\nof LLMs.", "published": "2024-09-01 21:18:14", "link": "http://arxiv.org/abs/2409.00844v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Benchmarking LLM Code Generation for Audio Programming with Visual\n  Dataflow Languages", "abstract": "Node-based programming languages are increasingly popular in media arts\ncoding domains. These languages are designed to be accessible to users with\nlimited coding experience, allowing them to achieve creative output without an\nextensive programming background. Using LLM-based code generation to further\nlower the barrier to creative output is an exciting opportunity. However, the\nbest strategy for code generation for visual node-based programming languages\nis still an open question. In particular, such languages have multiple levels\nof representation in text, each of which may be used for code generation. In\nthis work, we explore the performance of LLM code generation in audio\nprogramming tasks in visual programming languages at multiple levels of\nrepresentation. We explore code generation through metaprogramming code\nrepresentations for these languages (i.e., coding the language using a\ndifferent high-level text-based programming language), as well as through\ndirect node generation with JSON. We evaluate code generated in this way for\ntwo visual languages for audio programming on a benchmark set of coding\nproblems. We measure both correctness and complexity of the generated code. We\nfind that metaprogramming results in more semantically correct generated code,\ngiven that the code is well-formed (i.e., is syntactically correct and runs).\nWe also find that prompting for richer metaprogramming using randomness and\nloops led to more complex code.", "published": "2024-09-01 22:11:23", "link": "http://arxiv.org/abs/2409.00856v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Harnessing the Power of Semi-Structured Knowledge and LLMs with\n  Triplet-Based Prefiltering for Question Answering", "abstract": "Large Language Models (LLMs) frequently lack domain-specific knowledge and\neven fine-tuned models tend to hallucinate. Hence, more reliable models that\ncan include external knowledge are needed. We present a pipeline, 4StepFocus,\nand specifically a preprocessing step, that can substantially improve the\nanswers of LLMs. This is achieved by providing guided access to external\nknowledge making use of the model's ability to capture relational context and\nconduct rudimentary reasoning by themselves. The method narrows down\npotentially correct answers by triplets-based searches in a semi-structured\nknowledge base in a direct, traceable fashion, before switching to latent\nrepresentations for ranking those candidates based on unstructured data. This\ndistinguishes it from related methods that are purely based on latent\nrepresentations. 4StepFocus consists of the steps: 1) Triplet generation for\nextraction of relational data by an LLM, 2) substitution of variables in those\ntriplets to narrow down answer candidates employing a knowledge graph, 3)\nsorting remaining candidates with a vector similarity search involving\nassociated non-structured data, 4) reranking the best candidates by the LLM\nwith background data provided. Experiments on a medical, a product\nrecommendation, and an academic paper search test set demonstrate that this\napproach is indeed a powerful augmentation. It not only adds relevant traceable\nbackground information from information retrieval, but also improves\nperformance considerably in comparison to state-of-the-art methods. This paper\npresents a novel, largely unexplored direction and therefore provides a wide\nrange of future work opportunities. Used source code is available at\nhttps://github.com/kramerlab/4StepFocus.", "published": "2024-09-01 22:43:27", "link": "http://arxiv.org/abs/2409.00861v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.LO"], "primary_category": "cs.CL"}
{"title": "Deep Knowledge-Infusion For Explainable Depression Detection", "abstract": "Discovering individuals depression on social media has become increasingly\nimportant. Researchers employed ML/DL or lexicon-based methods for automated\ndepression detection. Lexicon based methods, explainable and easy to implement,\nmatch words from user posts in a depression dictionary without considering\ncontexts. While the DL models can leverage contextual information, their\nblack-box nature limits their adoption in the domain. Though surrogate models\nlike LIME and SHAP can produce explanations for DL models, the explanations are\nsuitable for the developer and of limited use to the end user. We propose a\nKnolwedge-infused Neural Network (KiNN) incorporating domain-specific knowledge\nfrom DepressionFeature ontology (DFO) in a neural network to endow the model\nwith user-level explainability regarding concepts and processes the clinician\nunderstands. Further, commonsense knowledge from the Commonsense Transformer\n(COMET) trained on ATOMIC is also infused to consider the generic emotional\naspects of user posts in depression detection. The model is evaluated on three\nexpertly curated datasets related to depression. We observed the model to have\na statistically significant (p<0.1) boost in performance over the best\ndomain-specific model, MentalBERT, across CLEF e-Risk (25% MCC increase, 12% F1\nincrease). A similar trend is observed across the PRIMATE dataset, where the\nproposed model performed better than MentalBERT (2.5% MCC increase, 19% F1\nincrease). The observations confirm the generated explanations to be\ninformative for MHPs compared to post hoc model explanations. Results\ndemonstrated that the user-level explainability of KiNN also surpasses the\nperformance of baseline models and can provide explanations where other\nbaselines fall short. Infusing the domain and commonsense knowledge in KiNN\nenhances the ability of models like GPT-3.5 to generate application-relevant\nexplanations.", "published": "2024-09-01 06:13:55", "link": "http://arxiv.org/abs/2409.02122v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SAM4MLLM: Enhance Multi-Modal Large Language Model for Referring\n  Expression Segmentation", "abstract": "We introduce SAM4MLLM, an innovative approach which integrates the Segment\nAnything Model (SAM) with Multi-Modal Large Language Models (MLLMs) for\npixel-aware tasks. Our method enables MLLMs to learn pixel-level location\ninformation without requiring excessive modifications to the existing model\narchitecture or adding specialized tokens. We introduce an inquiry-based\napproach that can effectively find prompt points for SAM to perform\nsegmentation based on MLLM. It combines detailed visual information with the\npowerful expressive capabilities of large language models in a unified\nlanguage-based manner without additional computational overhead in learning.\nExperimental results on pubic benchmarks demonstrate the effectiveness of our\napproach.", "published": "2024-09-01 12:09:33", "link": "http://arxiv.org/abs/2409.10542v3", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "FLUX that Plays Music", "abstract": "This paper explores a simple extension of diffusion-based rectified flow\nTransformers for text-to-music generation, termed as FluxMusic. Generally,\nalong with design in advanced\nFlux\\footnote{https://github.com/black-forest-labs/flux} model, we transfers it\ninto a latent VAE space of mel-spectrum. It involves first applying a sequence\nof independent attention to the double text-music stream, followed by a stacked\nsingle music stream for denoised patch prediction. We employ multiple\npre-trained text encoders to sufficiently capture caption semantic information\nas well as inference flexibility. In between, coarse textual information, in\nconjunction with time step embeddings, is utilized in a modulation mechanism,\nwhile fine-grained textual details are concatenated with the music patch\nsequence as inputs. Through an in-depth study, we demonstrate that rectified\nflow training with an optimized architecture significantly outperforms\nestablished diffusion methods for the text-to-music task, as evidenced by\nvarious automatic metrics and human preference evaluations. Our experimental\ndata, code, and model weights are made publicly available at:\n\\url{https://github.com/feizc/FluxMusic}.", "published": "2024-09-01 02:43:33", "link": "http://arxiv.org/abs/2409.00587v2", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Seeing Your Speech Style: A Novel Zero-Shot Identity-Disentanglement\n  Face-based Voice Conversion", "abstract": "Face-based Voice Conversion (FVC) is a novel task that leverages facial\nimages to generate the target speaker's voice style. Previous work has two\nshortcomings: (1) suffering from obtaining facial embeddings that are\nwell-aligned with the speaker's voice identity information, and (2) inadequacy\nin decoupling content and speaker identity information from the audio input. To\naddress these issues, we present a novel FVC method, Identity-Disentanglement\nFace-based Voice Conversion (ID-FaceVC), which overcomes the above two\nlimitations. More precisely, we propose an Identity-Aware Query-based\nContrastive Learning (IAQ-CL) module to extract speaker-specific facial\nfeatures, and a Mutual Information-based Dual Decoupling (MIDD) module to\npurify content features from audio, ensuring clear and high-quality voice\nconversion. Besides, unlike prior works, our method can accept either audio or\ntext inputs, offering controllable speech generation with adjustable emotional\ntone and speed. Extensive experiments demonstrate that ID-FaceVC achieves\nstate-of-the-art performance across various metrics, with qualitative and user\nstudy results confirming its effectiveness in naturalness, similarity, and\ndiversity. Project website with audio samples and code can be found at\nhttps://id-facevc.github.io.", "published": "2024-09-01 11:51:18", "link": "http://arxiv.org/abs/2409.00700v1", "categories": ["cs.SD", "cs.AI", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec\n  Transformer", "abstract": "The recent large-scale text-to-speech (TTS) systems are usually grouped as\nautoregressive and non-autoregressive systems. The autoregressive systems\nimplicitly model duration but exhibit certain deficiencies in robustness and\nlack of duration controllability. Non-autoregressive systems require explicit\nalignment information between text and speech during training and predict\ndurations for linguistic units (e.g. phone), which may compromise their\nnaturalness. In this paper, we introduce Masked Generative Codec Transformer\n(MaskGCT), a fully non-autoregressive TTS model that eliminates the need for\nexplicit alignment information between text and speech supervision, as well as\nphone-level duration prediction. MaskGCT is a two-stage model: in the first\nstage, the model uses text to predict semantic tokens extracted from a speech\nself-supervised learning (SSL) model, and in the second stage, the model\npredicts acoustic tokens conditioned on these semantic tokens. MaskGCT follows\nthe mask-and-predict learning paradigm. During training, MaskGCT learns to\npredict masked semantic or acoustic tokens based on given conditions and\nprompts. During inference, the model generates tokens of a specified length in\na parallel manner. Experiments with 100K hours of in-the-wild speech\ndemonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS\nsystems in terms of quality, similarity, and intelligibility. Audio samples are\navailable at https://maskgct.github.io/. We release our code and model\ncheckpoints at\nhttps://github.com/open-mmlab/Amphion/blob/main/models/tts/maskgct.", "published": "2024-09-01 15:26:30", "link": "http://arxiv.org/abs/2409.00750v3", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Serialized Speech Information Guidance with Overlapped Encoding\n  Separation for Multi-Speaker Automatic Speech Recognition", "abstract": "Serialized output training (SOT) attracts increasing attention due to its\nconvenience and flexibility for multi-speaker automatic speech recognition\n(ASR). However, it is not easy to train with attention loss only. In this\npaper, we propose the overlapped encoding separation (EncSep) to fully utilize\nthe benefits of the connectionist temporal classification (CTC) and attention\nhybrid loss. This additional separator is inserted after the encoder to extract\nthe multi-speaker information with CTC losses. Furthermore, we propose the\nserialized speech information guidance SOT (GEncSep) to further utilize the\nseparated encodings. The separated streams are concatenated to provide\nsingle-speaker information to guide attention during decoding. The experimental\nresults on LibriMix show that the single-speaker encoding can be separated from\nthe overlapped encoding. The CTC loss helps to improve the encoder\nrepresentation under complex scenarios. GEncSep further improved performance.", "published": "2024-09-01 19:07:34", "link": "http://arxiv.org/abs/2409.00815v3", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dissecting Temporal Understanding in Text-to-Audio Retrieval", "abstract": "Recent advancements in machine learning have fueled research on multimodal\ntasks, such as for instance text-to-video and text-to-audio retrieval. These\ntasks require models to understand the semantic content of video and audio\ndata, including objects, and characters. The models also need to learn spatial\narrangements and temporal relationships. In this work, we analyse the temporal\nordering of sounds, which is an understudied problem in the context of\ntext-to-audio retrieval. In particular, we dissect the temporal understanding\ncapabilities of a state-of-the-art model for text-to-audio retrieval on the\nAudioCaps and Clotho datasets. Additionally, we introduce a synthetic\ntext-audio dataset that provides a controlled setting for evaluating temporal\ncapabilities of recent models. Lastly, we present a loss function that\nencourages text-audio models to focus on the temporal ordering of events. Code\nand data are available at\nhttps://www.robots.ox.ac.uk/~vgg/research/audio-retrieval/dtu/.", "published": "2024-09-01 22:01:21", "link": "http://arxiv.org/abs/2409.00851v1", "categories": ["cs.IR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
{"title": "BUET Multi-disease Heart Sound Dataset: A Comprehensive Auscultation\n  Dataset for Developing Computer-Aided Diagnostic Systems", "abstract": "Cardiac auscultation, an integral tool in diagnosing cardiovascular diseases\n(CVDs), often relies on the subjective interpretation of clinicians, presenting\na limitation in consistency and accuracy. Addressing this, we introduce the\nBUET Multi-disease Heart Sound (BMD-HS) dataset - a comprehensive and\nmeticulously curated collection of heart sound recordings. This dataset,\nencompassing 864 recordings across five distinct classes of common heart\nsounds, represents a broad spectrum of valvular heart diseases, with a focus on\ndiagnostically challenging cases. The standout feature of the BMD-HS dataset is\nits innovative multi-label annotation system, which captures a diverse range of\ndiseases and unique disease states. This system significantly enhances the\ndataset's utility for developing advanced machine learning models in automated\nheart sound classification and diagnosis. By bridging the gap between\ntraditional auscultation practices and contemporary data-driven diagnostic\nmethods, the BMD-HS dataset is poised to revolutionize CVD diagnosis and\nmanagement, providing an invaluable resource for the advancement of cardiac\nhealth research. The dataset is publicly available at this link:\nhttps://github.com/mHealthBuet/BMD-HS-Dataset.", "published": "2024-09-01 13:55:04", "link": "http://arxiv.org/abs/2409.00724v1", "categories": ["eess.SP", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
