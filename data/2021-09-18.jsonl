{"title": "DyLex: Incorporating Dynamic Lexicons into BERT for Sequence Labeling", "abstract": "Incorporating lexical knowledge into deep learning models has been proved to\nbe very effective for sequence labeling tasks. However, previous works commonly\nhave difficulty dealing with large-scale dynamic lexicons which often cause\nexcessive matching noise and problems of frequent updates. In this paper, we\npropose DyLex, a plug-in lexicon incorporation approach for BERT based sequence\nlabeling tasks. Instead of leveraging embeddings of words in the lexicon as in\nconventional methods, we adopt word-agnostic tag embeddings to avoid\nre-training the representation while updating the lexicon. Moreover, we employ\nan effective supervised lexical knowledge denoising method to smooth out\nmatching noise. Finally, we introduce a col-wise attention based knowledge\nfusion mechanism to guarantee the pluggability of the proposed framework.\nExperiments on ten datasets of three tasks show that the proposed framework\nachieves new SOTA, even with very large scale lexicons.", "published": "2021-09-18 03:15:49", "link": "http://arxiv.org/abs/2109.08818v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Perspective-taking and Pragmatics for Generating Empathetic Responses\n  Focused on Emotion Causes", "abstract": "Empathy is a complex cognitive ability based on the reasoning of others'\naffective states. In order to better understand others and express stronger\nempathy in dialogues, we argue that two issues must be tackled at the same\ntime: (i) identifying which word is the cause for the other's emotion from his\nor her utterance and (ii) reflecting those specific words in the response\ngeneration. However, previous approaches for recognizing emotion cause words in\ntext require sub-utterance level annotations, which can be demanding. Taking\ninspiration from social cognition, we leverage a generative estimator to infer\nemotion cause words from utterances with no word-level label. Also, we\nintroduce a novel method based on pragmatics to make dialogue models focus on\ntargeted words in the input during generation. Our method is applicable to any\ndialogue models with no additional training on the fly. We show our approach\nimproves multiple best-performing dialogue agents on generating more focused\nempathetic responses in terms of both automatic and human evaluation.", "published": "2021-09-18 04:22:49", "link": "http://arxiv.org/abs/2109.08828v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TVStoryGen: A Dataset for Generating Stories with Character Descriptions", "abstract": "We introduce TVStoryGen, a story generation dataset that requires generating\ndetailed TV show episode recaps from a brief summary and a set of documents\ndescribing the characters involved. Unlike other story generation datasets,\nTVStoryGen contains stories that are authored by professional screen-writers\nand that feature complex interactions among multiple characters. Generating\nstories in TVStoryGen requires drawing relevant information from the lengthy\nprovided documents about characters based on the brief summary. In addition, we\npropose to train reverse models on our dataset for evaluating the faithfulness\nof generated stories. We create TVStoryGen from fan-contributed websites, which\nallows us to collect 26k episode recaps with 1868.7 tokens on average.\nEmpirically, we take a hierarchical story generation approach and find that the\nneural model that uses oracle content selectors for character descriptions\ndemonstrates the best performance on automatic metrics, showing the potential\nof our dataset to inspire future research on story generation with constraints.\nQualitative analysis shows that the best-performing model sometimes generates\ncontent that is unfaithful to the short summaries, suggesting promising\ndirections for future work.", "published": "2021-09-18 05:02:29", "link": "http://arxiv.org/abs/2109.08833v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emily: Developing An Emotion-affective Open-Domain Chatbot with\n  Knowledge Graph-based Persona", "abstract": "In this paper, we describe approaches for developing Emily, an\nemotion-affective open-domain chatbot. Emily can perceive a user's negative\nemotion state and offer supports by positively converting the user's emotion\nstates. This is done by finetuning a pretrained dialogue model upon data\ncapturing dialogue contexts and desirable emotion states transition across\nturns. Emily can differentiate a general open-domain dialogue utterance with\nquestions relating to personal information. By leveraging a question-answering\napproach based on knowledge graphs to handle personal information, Emily\nmaintains personality consistency. We evaluate Emily against a few\nstate-of-the-art open-domain chatbots and show the effects of the proposed\napproaches in emotion affecting and addressing personality inconsistency.", "published": "2021-09-18 08:19:58", "link": "http://arxiv.org/abs/2109.08875v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Joint Intent Detection and Slot Filling via Higher-order\n  Attention", "abstract": "Intent detection (ID) and Slot filling (SF) are two major tasks in spoken\nlanguage understanding (SLU). Recently, attention mechanism has been shown to\nbe effective in jointly optimizing these two tasks in an interactive manner.\nHowever, latest attention-based works concentrated only on the first-order\nattention design, while ignoring the exploration of higher-order attention\nmechanisms. In this paper, we propose a BiLinear attention block, which\nleverages bilinear pooling to simultaneously exploit both the contextual and\nchannel-wise bilinear attention distributions to capture the second-order\ninteractions between the input intent or slot features. Higher and even\ninfinity order interactions are built by stacking numerous blocks and assigning\nExponential Linear Unit (ELU) to blocks. Before the decoding stage, we\nintroduce the Dynamic Feature Fusion Layer to implicitly fuse intent and slot\ninformation in a more effective way. Technically, instead of simply\nconcatenating intent and slot features, we first compute two correlation\nmatrices to weight on two features. Furthermore, we present Higher-order\nAttention Network for the SLU tasks. Experiments on two benchmark datasets show\nthat our approach yields improvements compared with the state-of-the-art\napproach. We also provide discussion to demonstrate the effectiveness of the\nproposed approach.", "published": "2021-09-18 09:50:23", "link": "http://arxiv.org/abs/2109.08890v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking the Combinatorial Generalizability of Complex Query\n  Answering on Knowledge Graphs", "abstract": "Complex Query Answering (CQA) is an important reasoning task on knowledge\ngraphs. Current CQA learning models have been shown to be able to generalize\nfrom atomic operators to more complex formulas, which can be regarded as the\ncombinatorial generalizability. In this paper, we present EFO-1-QA, a new\ndataset to benchmark the combinatorial generalizability of CQA models by\nincluding 301 different queries types, which is 20 times larger than existing\ndatasets. Besides, our work, for the first time, provides a benchmark to\nevaluate and analyze the impact of different operators and normal forms by\nusing (a) 7 choices of the operator systems and (b) 9 forms of complex queries.\nSpecifically, we provide the detailed study of the combinatorial\ngeneralizability of two commonly used operators, i.e., projection and\nintersection, and justify the impact of the forms of queries given the\ncanonical choice of operators. Our code and data can provide an effective\npipeline to benchmark CQA models.", "published": "2021-09-18 12:58:55", "link": "http://arxiv.org/abs/2109.08925v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReaSCAN: Compositional Reasoning in Language Grounding", "abstract": "The ability to compositionally map language to referents, relations, and\nactions is an essential component of language understanding. The recent gSCAN\ndataset (Ruis et al. 2020, NeurIPS) is an inspiring attempt to assess the\ncapacity of models to learn this kind of grounding in scenarios involving\nnavigational instructions. However, we show that gSCAN's highly constrained\ndesign means that it does not require compositional interpretation and that\nmany details of its instructions and scenarios are not required for task\nsuccess. To address these limitations, we propose ReaSCAN, a benchmark dataset\nthat builds off gSCAN but requires compositional language interpretation and\nreasoning about entities and relations. We assess two models on ReaSCAN: a\nmulti-modal baseline and a state-of-the-art graph convolutional neural model.\nThese experiments show that ReaSCAN is substantially harder than gSCAN for both\nneural architectures. This suggests that ReaSCAN can serve as a valuable\nbenchmark for advancing our understanding of models' compositional\ngeneralization and reasoning capabilities.", "published": "2021-09-18 19:46:08", "link": "http://arxiv.org/abs/2109.08994v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Solar cell patent classification method based on keyword extraction and\n  deep neural network", "abstract": "With the growing impact of ESG on businesses, research related to renewable\nenergy is receiving great attention. Solar cells are one of them, and\naccordingly, it can be said that the research value of solar cell patent\nanalysis is very high. Patent documents have high research value. Being able to\naccurately analyze and classify patent documents can reveal several important\ntechnical relationships. It can also describe the business trends in that\ntechnology. And when it comes to investment, new industrial solutions will also\nbe inspired and proposed to make important decisions. Therefore, we must\ncarefully analyze patent documents and utilize the value of patents. To solve\nthe solar cell patent classification problem, we propose a keyword extraction\nmethod and a deep neural network-based solar cell patent classification method.\nFirst, solar cell patents are analyzed for pretreatment. It then uses the\nKeyBERT algorithm to extract keywords and key phrases from the patent abstract\nto construct a lexical dictionary. We then build a solar cell patent\nclassification model according to the deep neural network. Finally, we use a\ndeep neural network-based solar cell patent classification model to classify\npower patents, and the training accuracy is greater than 95%. Also, the\nvalidation accuracy is about 87.5%. It can be seen that the deep neural network\nmethod can not only realize the classification of complex and difficult solar\ncell patents, but also have a good classification effect.", "published": "2021-09-18 01:30:08", "link": "http://arxiv.org/abs/2109.08796v3", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Structured Pattern Pruning Using Regularization", "abstract": "Iterative Magnitude Pruning (IMP) is a network pruning method that repeats\nthe process of removing weights with the least magnitudes and retraining the\nmodel. When visualizing the weight matrices of language models pruned by IMP,\nprevious research has shown that a structured pattern emerges, wherein the\nresulting surviving weights tend to prominently cluster in a select few rows\nand columns of the matrix. Though the need for further research in utilizing\nthese structured patterns for potential performance gains has previously been\nindicated, it has yet to be thoroughly studied. We propose SPUR (Structured\nPattern pruning Using Regularization), a novel pruning mechanism that\npreemptively induces structured patterns in compression by adding a\nregularization term to the objective function in the IMP. Our results show that\nSPUR can significantly preserve model performance under high sparsity settings\nregardless of the language or the task. Our contributions are as follows: (i)\nWe propose SPUR, a network pruning mechanism that improves upon IMP regardless\nof the language or the task. (ii) We are the first to empirically verify the\nefficacy of \"structured patterns\" observed previously in pruning research.\n(iii) SPUR is a resource-efficient mechanism in that it does not require\nsignificant additional computations.", "published": "2021-09-18 03:01:29", "link": "http://arxiv.org/abs/2109.08814v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Feature Engineering for US State Legislative Hearings: Stance,\n  Affiliation, Engagement and Absentees", "abstract": "In US State government legislatures, most of the activity occurs in\ncommittees made up of lawmakers discussing bills. When analyzing, classifying\nor summarizing these committee proceedings, some important features become\nbroadly interesting. In this paper, we engineer four useful features, two\napplying to lawmakers (engagement and absence), and two to non-lawmakers\n(stance and affiliation). We propose a system to automatically track the\naffiliation of organizations in public comments and whether the organizational\nrepresentative supports or opposes the bill. The model tracking affiliation\nachieves an F1 of 0.872 while the support determination has an F1 of 0.979.\nAdditionally, a metric to compute legislator engagement and absenteeism is also\nproposed and as proof-of-concept, a list of the most and least engaged\nlegislators over one full California legislative session is presented.", "published": "2021-09-18 06:50:35", "link": "http://arxiv.org/abs/2109.08855v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "DuRecDial 2.0: A Bilingual Parallel Corpus for Conversational\n  Recommendation", "abstract": "In this paper, we provide a bilingual parallel human-to-human recommendation\ndialog dataset (DuRecDial 2.0) to enable researchers to explore a challenging\ntask of multilingual and cross-lingual conversational recommendation. The\ndifference between DuRecDial 2.0 and existing conversational recommendation\ndatasets is that the data item (Profile, Goal, Knowledge, Context, Response) in\nDuRecDial 2.0 is annotated in two languages, both English and Chinese, while\nother datasets are built with the setting of a single language. We collect 8.2k\ndialogs aligned across English and Chinese languages (16.5k dialogs and 255k\nutterances in total) that are annotated by crowdsourced workers with strict\nquality control procedure. We then build monolingual, multilingual, and\ncross-lingual conversational recommendation baselines on DuRecDial 2.0.\nExperiment results show that the use of additional English data can bring\nperformance improvement for Chinese conversational recommendation, indicating\nthe benefits of DuRecDial 2.0. Finally, this dataset provides a challenging\ntestbed for future studies of monolingual, multilingual, and cross-lingual\nconversational recommendation.", "published": "2021-09-18 08:23:21", "link": "http://arxiv.org/abs/2109.08877v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dependency distance minimization predicts compression", "abstract": "Dependency distance minimization (DDm) is a well-established principle of\nword order. It has been predicted theoretically that DDm implies compression,\nnamely the minimization of word lengths. This is a second order prediction\nbecause it links a principle with another principle, rather than a principle\nand a manifestation as in a first order prediction. Here we test that second\norder prediction with a parallel collection of treebanks controlling for\nannotation style with Universal Dependencies and Surface-Syntactic Universal\nDependencies. To test it, we use a recently introduced score that has many\nmathematical and statistical advantages with respect to the widely used sum of\ndependency distances. We find that the prediction is confirmed by the new score\nwhen word lengths are measured in phonemes, independently of the annotation\nstyle, but not when word lengths are measured in syllables. In contrast, one of\nthe most widely used scores, i.e. the sum of dependency distances, fails to\nconfirm that prediction, showing the weakness of raw dependency distances for\nresearch on word order. Finally, our findings expand the theory of natural\ncommunication by linking two distinct levels of organization, namely syntax\n(word order) and word internal structure.", "published": "2021-09-18 10:53:39", "link": "http://arxiv.org/abs/2109.08900v2", "categories": ["cs.CL", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "Text Detoxification using Large Pre-trained Neural Models", "abstract": "We present two novel unsupervised methods for eliminating toxicity in text.\nOur first method combines two recent ideas: (1) guidance of the generation\nprocess with small style-conditional language models and (2) use of\nparaphrasing models to perform style transfer. We use a well-performing\nparaphraser guided by style-trained language models to keep the text content\nand remove toxicity. Our second method uses BERT to replace toxic words with\ntheir non-offensive synonyms. We make the method more flexible by enabling BERT\nto replace mask tokens with a variable number of words. Finally, we present the\nfirst large-scale comparative study of style transfer models on the task of\ntoxicity removal. We compare our models with a number of methods for style\ntransfer. The models are evaluated in a reference-free way using a combination\nof unsupervised style transfer metrics. Both methods we suggest yield new SOTA\nresults.", "published": "2021-09-18 11:55:32", "link": "http://arxiv.org/abs/2109.08914v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Weakly Supervised Explainable Phrasal Reasoning with Neural Fuzzy Logic", "abstract": "Natural language inference (NLI) aims to determine the logical relationship\nbetween two sentences, such as Entailment, Contradiction, and Neutral. In\nrecent years, deep learning models have become a prevailing approach to NLI,\nbut they lack interpretability and explainability. In this work, we address the\nexplainability of NLI by weakly supervised logical reasoning, and propose an\nExplainable Phrasal Reasoning (EPR) approach. Our model first detects phrases\nas the semantic unit and aligns corresponding phrases in the two sentences.\nThen, the model predicts the NLI label for the aligned phrases, and induces the\nsentence label by fuzzy logic formulas. Our EPR is almost everywhere\ndifferentiable and thus the system can be trained end to end. In this way, we\nare able to provide explicit explanations of phrasal logical relationships in a\nweakly supervised manner. We further show that such reasoning results help\ntextual explanation generation.", "published": "2021-09-18 13:04:23", "link": "http://arxiv.org/abs/2109.08927v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Complex Temporal Question Answering on Knowledge Graphs", "abstract": "Question answering over knowledge graphs (KG-QA) is a vital topic in IR.\nQuestions with temporal intent are a special class of practical importance, but\nhave not received much attention in research. This work presents EXAQT, the\nfirst end-to-end system for answering complex temporal questions that have\nmultiple entities and predicates, and associated temporal conditions. EXAQT\nanswers natural language questions over KGs in two stages, one geared towards\nhigh recall, the other towards precision at top ranks. The first step computes\nquestion-relevant compact subgraphs within the KG, and judiciously enhances\nthem with pertinent temporal facts, using Group Steiner Trees and fine-tuned\nBERT models. The second step constructs relational graph convolutional networks\n(R-GCNs) from the first step's output, and enhances the R-GCNs with time-aware\nentity embeddings and attention over temporal relations. We evaluate EXAQT on\nTimeQuestions, a large dataset of 16k temporal questions we compiled from a\nvariety of general purpose KG-QA benchmarks. Results show that EXAQT\noutperforms three state-of-the-art systems for answering complex questions over\nKGs, thereby justifying specialized treatment of temporal QA.", "published": "2021-09-18 13:41:43", "link": "http://arxiv.org/abs/2109.08935v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "BERT-Beta: A Proactive Probabilistic Approach to Text Moderation", "abstract": "Text moderation for user generated content, which helps to promote healthy\ninteraction among users, has been widely studied and many machine learning\nmodels have been proposed. In this work, we explore an alternative perspective\nby augmenting reactive reviews with proactive forecasting. Specifically, we\npropose a new concept {\\it text toxicity propensity} to characterize the extent\nto which a text tends to attract toxic comments. Beta regression is then\nintroduced to do the probabilistic modeling, which is demonstrated to function\nwell in comprehensive experiments. We also propose an explanation method to\ncommunicate the model decision clearly. Both propensity scoring and\ninterpretation benefit text moderation in a novel manner. Finally, the proposed\nscaling mechanism for the linear model offers useful insights beyond this work.", "published": "2021-09-18 02:04:50", "link": "http://arxiv.org/abs/2109.08805v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Zero and Few-shot Knowledge-seeking Turn Detection in\n  Task-orientated Dialogue Systems", "abstract": "Most prior work on task-oriented dialogue systems is restricted to supporting\ndomain APIs. However, users may have requests that are out of the scope of\nthese APIs. This work focuses on identifying such user requests. Existing\nmethods for this task mainly rely on fine-tuning pre-trained models on large\nannotated data. We propose a novel method, REDE, based on adaptive\nrepresentation learning and density estimation. REDE can be applied to\nzero-shot cases, and quickly learns a high-performing detector with only a few\nshots by updating less than 3K parameters. We demonstrate REDE's competitive\nperformance on DSTC9 data and our newly collected test set.", "published": "2021-09-18 03:33:19", "link": "http://arxiv.org/abs/2109.08820v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multilingual Molecular Representation Learning via Contrastive\n  Pre-training", "abstract": "Molecular representation learning plays an essential role in cheminformatics.\nRecently, language model-based approaches have gained popularity as an\nalternative to traditional expert-designed features to encode molecules.\nHowever, these approaches only utilize a single molecular language for\nrepresentation learning. Motivated by the fact that a given molecule can be\ndescribed using different languages such as Simplified Molecular Line Entry\nSystem (SMILES), The International Union of Pure and Applied Chemistry (IUPAC),\nand The IUPAC International Chemical Identifier (InChI), we propose a\nmultilingual molecular embedding generation approach called MM-Deacon\n(multilingual molecular domain embedding analysis via contrastive learning).\nMM-Deacon is pre-trained using SMILES and IUPAC as two different languages on\nlarge-scale molecules. We evaluated the robustness of our method on seven\nmolecular property prediction tasks from MoleculeNet benchmark, zero-shot\ncross-lingual retrieval, and a drug-drug interaction prediction task.", "published": "2021-09-18 04:46:39", "link": "http://arxiv.org/abs/2109.08830v3", "categories": ["cs.LG", "cs.CL", "physics.chem-ph"], "primary_category": "cs.LG"}
{"title": "Augmenting semantic lexicons using word embeddings and transfer learning", "abstract": "Sentiment-aware intelligent systems are essential to a wide array of\napplications. These systems are driven by language models which broadly fall\ninto two paradigms: Lexicon-based and contextual. Although recent contextual\nmodels are increasingly dominant, we still see demand for lexicon-based models\nbecause of their interpretability and ease of use. For example, lexicon-based\nmodels allow researchers to readily determine which words and phrases\ncontribute most to a change in measured sentiment. A challenge for any\nlexicon-based approach is that the lexicon needs to be routinely expanded with\nnew words and expressions. Here, we propose two models for automatic lexicon\nexpansion. Our first model establishes a baseline employing a simple and\nshallow neural network initialized with pre-trained word embeddings using a\nnon-contextual approach. Our second model improves upon our baseline, featuring\na deep Transformer-based network that brings to bear word definitions to\nestimate their lexical polarity. Our evaluation shows that both models are able\nto score new words with a similar accuracy to reviewers from Amazon Mechanical\nTurk, but at a fraction of the cost.", "published": "2021-09-18 20:59:52", "link": "http://arxiv.org/abs/2109.09010v2", "categories": ["cs.CL", "cs.LG", "cs.SI", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "A Machine Learning Pipeline to Examine Political Bias with Congressional\n  Speeches", "abstract": "Computational methods to model political bias in social media involve several\nchallenges due to heterogeneity, high-dimensional, multiple modalities, and the\nscale of the data. Political bias in social media has been studied in multiple\nviewpoints like media bias, political ideology, echo chambers, and\ncontroversies using machine learning pipelines. Most of the current methods\nrely heavily on the manually-labeled ground-truth data for the underlying\npolitical bias prediction tasks. Limitations of such methods include\nhuman-intensive labeling, labels related to only a specific problem, and the\ninability to determine the near future bias state of a social media\nconversation. In this work, we address such problems and give machine learning\napproaches to study political bias in two ideologically diverse social media\nforums: Gab and Twitter without the availability of human-annotated data. Our\nproposed methods exploit the use of transcripts collected from political\nspeeches in US congress to label the data and achieve the highest accuracy of\n70.5% and 65.1% in Twitter and Gab data respectively to predict political bias.\nWe also present a machine learning approach that combines features from\ncascades and text to forecast cascade's political bias with an accuracy of\nabout 85%.", "published": "2021-09-18 21:15:21", "link": "http://arxiv.org/abs/2109.09014v1", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "SpeechNAS: Towards Better Trade-off between Latency and Accuracy for\n  Large-Scale Speaker Verification", "abstract": "Recently, x-vector has been a successful and popular approach for speaker\nverification, which employs a time delay neural network (TDNN) and statistics\npooling to extract speaker characterizing embedding from variable-length\nutterances. Improvement upon the x-vector has been an active research area, and\nenormous neural networks have been elaborately designed based on the x-vector,\neg, extended TDNN (E-TDNN), factorized TDNN (F-TDNN), and densely connected\nTDNN (D-TDNN). In this work, we try to identify the optimal architectures from\na TDNN based search space employing neural architecture search (NAS), named\nSpeechNAS. Leveraging the recent advances in the speaker recognition, such as\nhigh-order statistics pooling, multi-branch mechanism, D-TDNN and angular\nadditive margin softmax (AAM) loss with a minimum hyper-spherical energy (MHE),\nSpeechNAS automatically discovers five network architectures, from SpeechNAS-1\nto SpeechNAS-5, of various numbers of parameters and GFLOPs on the large-scale\ntext-independent speaker recognition dataset VoxCeleb1. Our derived best neural\nnetwork achieves an equal error rate (EER) of 1.02% on the standard test set of\nVoxCeleb1, which surpasses previous TDNN based state-of-the-art approaches by a\nlarge margin. Code and trained weights are in\nhttps://github.com/wentaozhu/speechnas.git", "published": "2021-09-18 05:31:27", "link": "http://arxiv.org/abs/2109.08839v1", "categories": ["cs.SD", "cs.CL", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "V-SlowFast Network for Efficient Visual Sound Separation", "abstract": "The objective of this paper is to perform visual sound separation: i) we\nstudy visual sound separation on spectrograms of different temporal\nresolutions; ii) we propose a new light yet efficient three-stream framework\nV-SlowFast that operates on Visual frame, Slow spectrogram, and Fast\nspectrogram. The Slow spectrogram captures the coarse temporal resolution while\nthe Fast spectrogram contains the fine-grained temporal resolution; iii) we\nintroduce two contrastive objectives to encourage the network to learn\ndiscriminative visual features for separating sounds; iv) we propose an\naudio-visual global attention module for audio and visual feature fusion; v)\nthe introduced V-SlowFast model outperforms previous state-of-the-art in\nsingle-frame based visual sound separation on small- and large-scale datasets:\nMUSIC-21, AVE, and VGG-Sound. We also propose a small V-SlowFast architecture\nvariant, which achieves 74.2% reduction in the number of model parameters and\n81.4% reduction in GMACs compared to the previous multi-stage models. Project\npage: https://ly-zhu.github.io/V-SlowFast", "published": "2021-09-18 07:44:31", "link": "http://arxiv.org/abs/2109.08867v2", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Fast query-by-example speech search using separable model", "abstract": "Traditional Query-by-Example (QbE) speech search approaches usually use\nmethods based on frame-level features, while state-of-the-art approaches tend\nto use models based on acoustic word embeddings (AWEs) to transform variable\nlength audio signals into fixed length feature vector representations. However,\nthese approaches cannot meet the requirements of the search quality as well as\nspeed at the same time. In this paper, we propose a novel fast QbE speech\nsearch method based on separable models to fix this problem. First, a QbE\nspeech search training framework is introduced. Second, we design a novel model\ninference scheme based on RepVGG which can efficiently improve the QbE search\nquality. Third, we modify and improve our QbE speech search model according to\nthe proposed model inference scheme. Experiments on keywords dataset shows that\nour proposed method can improve the GPU Real-time Factor (RTF) from 1/150 to\n1/2300 by just applying separable model scheme and outperforms other\nstate-of-the-art methods.", "published": "2021-09-18 07:57:24", "link": "http://arxiv.org/abs/2109.08870v1", "categories": ["eess.AS", "cs.IR", "cs.SD"], "primary_category": "eess.AS"}
{"title": "MS-SincResNet: Joint learning of 1D and 2D kernels using multi-scale\n  SincNet and ResNet for music genre classification", "abstract": "In this study, we proposed a new end-to-end convolutional neural network,\ncalled MS-SincResNet, for music genre classification. MS-SincResNet appends 1D\nmulti-scale SincNet (MS-SincNet) to 2D ResNet as the first convolutional layer\nin an attempt to jointly learn 1D kernels and 2D kernels during the training\nstage. First, an input music signal is divided into a number of fixed-duration\n(3 seconds in this study) music clips, and the raw waveform of each music clip\nis fed into 1D MS-SincNet filter learning module to obtain three-channel 2D\nrepresentations. The learned representations carry rich timbral, harmonic, and\npercussive characteristics comparing with spectrograms, harmonic spectrograms,\npercussive spectrograms and Mel-spectrograms. ResNet is then used to extract\ndiscriminative embeddings from these 2D representations. The spatial pyramid\npooling (SPP) module is further used to enhance the feature discriminability,\nin terms of both time and frequency aspects, to obtain the classification label\nof each music clip. Finally, the voting strategy is applied to summarize the\nclassification results from all 3-second music clips. In our experimental\nresults, we demonstrate that the proposed MS-SincResNet outperforms the\nbaseline SincNet and many well-known hand-crafted features. Considering\nindividual 2D representation, MS-SincResNet also yields competitive results\nwith the state-of-the-art methods on the GTZAN dataset and the ISMIR2004\ndataset. The code is available at https://github.com/PeiChunChang/MS-SincResNet", "published": "2021-09-18 11:39:53", "link": "http://arxiv.org/abs/2109.08910v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Hybrid Data Augmentation and Deep Attention-based Dilated\n  Convolutional-Recurrent Neural Networks for Speech Emotion Recognition", "abstract": "Speech emotion recognition (SER) has been one of the significant tasks in\nHuman-Computer Interaction (HCI) applications. However, it is hard to choose\nthe optimal features and deal with imbalance labeled data. In this article, we\ninvestigate hybrid data augmentation (HDA) methods to generate and balance data\nbased on traditional and generative adversarial networks (GAN) methods. To\nevaluate the effectiveness of HDA methods, a deep learning framework namely\n(ADCRNN) is designed by integrating deep dilated convolutional-recurrent neural\nnetworks with an attention mechanism. Besides, we choose 3D log Mel-spectrogram\n(MelSpec) features as the inputs for the deep learning framework. Furthermore,\nwe reconfigure a loss function by combining a softmax loss and a center loss to\nclassify the emotions. For validating our proposed methods, we use the EmoDB\ndataset that consists of several emotions with imbalanced samples. Experimental\nresults prove that the proposed methods achieve better accuracy than the\nstate-of-the-art methods on the EmoDB with 87.12% and 88.47% for the\ntraditional and GAN-based methods, respectively.", "published": "2021-09-18 23:13:44", "link": "http://arxiv.org/abs/2109.09026v1", "categories": ["cs.SD", "cs.HC", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
