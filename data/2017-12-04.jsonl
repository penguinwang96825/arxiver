{"title": "Mining Supervisor Evaluation and Peer Feedback in Performance Appraisals", "abstract": "Performance appraisal (PA) is an important HR process to periodically measure\nand evaluate every employee's performance vis-a-vis the goals established by\nthe organization. A PA process involves purposeful multi-step multi-modal\ncommunication between employees, their supervisors and their peers, such as\nself-appraisal, supervisor assessment and peer feedback. Analysis of the\nstructured data and text produced in PA is crucial for measuring the quality of\nappraisals and tracking actual improvements. In this paper, we apply text\nmining techniques to produce insights from PA text. First, we perform sentence\nclassification to identify strengths, weaknesses and suggestions of\nimprovements found in the supervisor assessments and then use clustering to\ndiscover broad categories among them. Next we use multi-class multi-label\nclassification techniques to match supervisor assessments to predefined broad\nperspectives on performance. Finally, we propose a short-text summarization\ntechnique to produce a summary of peer feedback comments for a given employee\nand compare it with manual summaries. All techniques are illustrated using a\nreal-life dataset of supervisor assessment and peer feedback text produced\nduring the PA of 4528 employees in a large multi-national IT company.", "published": "2017-12-04 10:30:18", "link": "http://arxiv.org/abs/1712.00991v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Encoder-Decoder Model for ICD-10 Coding of Death Certificates", "abstract": "Information extraction from textual documents such as hospital records and\nhealthrelated user discussions has become a topic of intense interest. The task\nof medical concept coding is to map a variable length text to medical concepts\nand corresponding classification codes in some external system or ontology. In\nthis work, we utilize recurrent neural networks to automatically assign ICD-10\ncodes to fragments of death certificates written in English. We develop\nend-to-end neural architectures directly tailored to the task, including basic\nencoder-decoder architecture for statistical translation. In order to\nincorporate prior knowledge, we concatenate cosine similarities vector among\nthe text and dictionary entry to the encoded state. Being applied to a standard\nbenchmark from CLEF eHealth 2017 challenge, our model achieved F-measure of\n85.01% on a full test set with significant improvement as compared to the\naverage score of 62.2% for all official participants approaches.", "published": "2017-12-04 17:39:51", "link": "http://arxiv.org/abs/1712.01213v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "#anorexia, #anarexia, #anarexyia: Characterizing Online Community\n  Practices with Orthographic Variation", "abstract": "Distinctive linguistic practices help communities build solidarity and\ndifferentiate themselves from outsiders. In an online community, one such\npractice is variation in orthography, which includes spelling, punctuation, and\ncapitalization. Using a dataset of over two million Instagram posts, we\ninvestigate orthographic variation in a community that shares pro-eating\ndisorder (pro-ED) content. We find that not only does orthographic variation\ngrow more frequent over time, it also becomes more profound or deep, with\nvariants becoming increasingly distant from the original: as, for example,\n#anarexyia is more distant than #anarexia from the original spelling #anorexia.\nThese changes are driven by newcomers, who adopt the most extreme linguistic\npractices as they enter the community. Moreover, this behavior correlates with\nengagement: the newcomers who adopt deeper orthographic variants tend to remain\nactive for longer in the community, and the posts that contain deeper variation\nreceive more positive feedback in the form of \"likes.\" Previous work has linked\ncommunity membership change with language change, and our work casts this\nconnection in a new light, with newcomers driving an evolving practice, rather\nthan adapting to it. We also demonstrate the utility of orthographic variation\nas a new lens to study sociolinguistic change in online communities,\nparticularly when the change results from an exogenous force such as a content\nban.", "published": "2017-12-04 23:27:11", "link": "http://arxiv.org/abs/1712.01411v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Topics and Label Propagation: Best of Both Worlds for Weakly Supervised\n  Text Classification", "abstract": "We propose a Label Propagation based algorithm for weakly supervised text\nclassification. We construct a graph where each document is represented by a\nnode and edge weights represent similarities among the documents. Additionally,\nwe discover underlying topics using Latent Dirichlet Allocation (LDA) and\nenrich the document graph by including the topics in the form of additional\nnodes. The edge weights between a topic and a text document represent level of\n\"affinity\" between them. Our approach does not require document level\nlabelling, instead it expects manual labels only for topic nodes. This\nsignificantly minimizes the level of supervision needed as only a few topics\nare observed to be enough for achieving sufficiently high accuracy. The Label\nPropagation Algorithm is employed on this enriched graph to propagate labels\namong the nodes. Our approach combines the advantages of Label Propagation\n(through document-document similarities) and Topic Modelling (for minimal but\nsmart supervision). We demonstrate the effectiveness of our approach on various\ndatasets and compare with state-of-the-art weakly supervised text\nclassification approaches.", "published": "2017-12-04 06:05:21", "link": "http://arxiv.org/abs/1712.02767v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning by Asking Questions", "abstract": "We introduce an interactive learning framework for the development and\ntesting of intelligent visual systems, called learning-by-asking (LBA). We\nexplore LBA in context of the Visual Question Answering (VQA) task. LBA differs\nfrom standard VQA training in that most questions are not observed during\ntraining time, and the learner must ask questions it wants answers to. Thus,\nLBA more closely mimics natural learning and has the potential to be more\ndata-efficient than the traditional VQA setting. We present a model that\nperforms LBA on the CLEVR dataset, and show that it automatically discovers an\neasy-to-hard curriculum when learning interactively from an oracle. Our LBA\ngenerated data consistently matches or outperforms the CLEVR train data and is\nmore sample efficient. We also show that our model asks questions that\ngeneralize to state-of-the-art VQA models and to novel test time distributions.", "published": "2017-12-04 18:23:19", "link": "http://arxiv.org/abs/1712.01238v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Examining Cooperation in Visual Dialog Models", "abstract": "In this work we propose a blackbox intervention method for visual dialog\nmodels, with the aim of assessing the contribution of individual linguistic or\nvisual components. Concretely, we conduct structured or randomized\ninterventions that aim to impair an individual component of the model, and\nobserve changes in task performance. We reproduce a state-of-the-art visual\ndialog model and demonstrate that our methodology yields surprising insights,\nnamely that both dialog and image information have minimal contributions to\ntask performance. The intervention method presented here can be applied as a\nsanity check for the strength and robustness of each component in visual dialog\nsystems.", "published": "2017-12-04 20:16:52", "link": "http://arxiv.org/abs/1712.01329v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A text-independent speaker verification model: A comparative analysis", "abstract": "The most pressing challenge in the field of voice biometrics is selecting the\nmost efficient technique of speaker recognition. Every individual's voice is\npeculiar, factors like physical differences in vocal organs, accent and\npronunciation contributes to the problem's complexity. In this paper, we\nexplore the various methods available in each block in the process of speaker\nrecognition with the objective to identify best of techniques that could be\nused to get precise results. We study the results on text independent corpora.\nWe use MFCC (Melfrequency cepstral coefficient), LPCC (linear predictive\ncepstral coefficient) and PLP (perceptual linear prediction) algorithms for\nfeature extraction, PCA (Principal Component Analysis) and tSNE for\ndimensionality reduction and SVM (Support Vector Machine), feed forward,\nnearest neighbor and decision tree algorithms for classification block in\nspeaker recognition system and comparatively analyze each block to determine\nthe best technique", "published": "2017-12-04 06:09:02", "link": "http://arxiv.org/abs/1712.00917v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Precision Scaling of Neural Networks for Efficient Audio Processing", "abstract": "While deep neural networks have shown powerful performance in many audio\napplications, their large computation and memory demand has been a challenge\nfor real-time processing. In this paper, we study the impact of scaling the\nprecision of neural networks on the performance of two common audio processing\ntasks, namely, voice-activity detection and single-channel speech enhancement.\nWe determine the optimal pair of weight/neuron bit precision by exploring its\nimpact on both the performance and processing time. Through experiments\nconducted with real user data, we demonstrate that deep neural networks that\nuse lower bit precision significantly reduce the processing time (up to 30x).\nHowever, their performance impact is low (< 3.14%) only in the case of\nclassification tasks such as those present in voice activity detection.", "published": "2017-12-04 20:39:05", "link": "http://arxiv.org/abs/1712.01340v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Raw Waveform-based Audio Classification Using Sample-level CNN\n  Architectures", "abstract": "Music, speech, and acoustic scene sound are often handled separately in the\naudio domain because of their different signal characteristics. However, as the\nimage domain grows rapidly by versatile image classification models, it is\nnecessary to study extensible classification models in the audio domain as\nwell. In this study, we approach this problem using two types of sample-level\ndeep convolutional neural networks that take raw waveforms as input and uses\nfilters with small granularity. One is a basic model that consists of\nconvolution and pooling layers. The other is an improved model that\nadditionally has residual connections, squeeze-and-excitation modules and\nmulti-level concatenation. We show that the sample-level models reach\nstate-of-the-art performance levels for the three different categories of\nsound. Also, we visualize the filters along layers and compare the\ncharacteristics of learned filters.", "published": "2017-12-04 00:58:58", "link": "http://arxiv.org/abs/1712.00866v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Chord Generation from Symbolic Melody Using BLSTM Networks", "abstract": "Generating a chord progression from a monophonic melody is a challenging\nproblem because a chord progression requires a series of layered notes played\nsimultaneously. This paper presents a novel method of generating chord\nsequences from a symbolic melody using bidirectional long short-term memory\n(BLSTM) networks trained on a lead sheet database. To this end, a group of\nfeature vectors composed of 12 semitones is extracted from the notes in each\nbar of monophonic melodies. In order to ensure that the data shares uniform key\nand duration characteristics, the key and the time signatures of the vectors\nare normalized. The BLSTM networks then learn from the data to incorporate the\ntemporal dependencies to produce a chord progression. Both quantitative and\nqualitative evaluations are conducted by comparing the proposed method with the\nconventional HMM and DNN-HMM based approaches. Proposed model achieves 23.8%\nand 11.4% performance increase from the other models, respectively. User\nstudies further confirm that the chord sequences generated by the proposed\nmethod are preferred by listeners.", "published": "2017-12-04 11:18:08", "link": "http://arxiv.org/abs/1712.01011v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
