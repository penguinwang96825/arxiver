{"title": "Multimodal Grounding for Language Processing", "abstract": "This survey discusses how recent developments in multimodal processing\nfacilitate conceptual grounding of language. We categorize the information flow\nin multimodal processing with respect to cognitive models of human information\nprocessing and analyze different methods for combining multimodal\nrepresentations. Based on this methodological inventory, we discuss the benefit\nof multimodal grounding for a variety of language processing tasks and the\nchallenges that arise. We particularly focus on multimodal grounding of verbs\nwhich play a crucial role for the compositional power of language.", "published": "2018-06-17 12:13:37", "link": "http://arxiv.org/abs/1806.06371v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Improved Text Sentiment Classification Model Using TF-IDF and Next\n  Word Negation", "abstract": "With the rapid growth of Text sentiment analysis, the demand for automatic\nclassification of electronic documents has increased by leaps and bound. The\nparadigm of text classification or text mining has been the subject of many\nresearch works in recent time. In this paper we propose a technique for text\nsentiment classification using term frequency- inverse document frequency\n(TF-IDF) along with Next Word Negation (NWN). We have also compared the\nperformances of binary bag of words model, TF-IDF model and TF-IDF with next\nword negation (TF-IDF-NWN) model for text classification. Our proposed model is\nthen applied on three different text mining algorithms and we found the Linear\nSupport vector machine (LSVM) is the most appropriate to work with our proposed\nmodel. The achieved results show significant increase in accuracy compared to\nearlier methods.", "published": "2018-06-17 16:25:57", "link": "http://arxiv.org/abs/1806.06407v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Measuring Semantic Coherence of a Conversation", "abstract": "Conversational systems have become increasingly popular as a way for humans\nto interact with computers. To be able to provide intelligent responses,\nconversational systems must correctly model the structure and semantics of a\nconversation. We introduce the task of measuring semantic (in)coherence in a\nconversation with respect to background knowledge, which relies on the\nidentification of semantic relations between concepts introduced during a\nconversation. We propose and evaluate graph-based and machine learning-based\napproaches for measuring semantic coherence using knowledge graphs, their\nvector space embeddings and word embedding models, as sources of background\nknowledge. We demonstrate how these approaches are able to uncover different\ncoherence patterns in conversations on the Ubuntu Dialogue Corpus.", "published": "2018-06-17 16:38:48", "link": "http://arxiv.org/abs/1806.06411v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Extending Recurrent Neural Aligner for Streaming End-to-End Speech\n  Recognition in Mandarin", "abstract": "End-to-end models have been showing superiority in Automatic Speech\nRecognition (ASR). At the same time, the capacity of streaming recognition has\nbecome a growing requirement for end-to-end models. Following these trends, an\nencoder-decoder recurrent neural network called Recurrent Neural Aligner (RNA)\nhas been freshly proposed and shown its competitiveness on two English ASR\ntasks. However, it is not clear if RNA can be further improved and applied to\nother spoken language. In this work, we explore the applicability of RNA in\nMandarin Chinese and present four effective extensions: In the encoder, we\nredesign the temporal down-sampling and introduce a powerful convolutional\nstructure. In the decoder, we utilize a regularizer to smooth the output\ndistribution and conduct joint training with a language model. On two Mandarin\nChinese conversational telephone speech recognition (MTS) datasets, our\nExtended-RNA obtains promising performance. Particularly, it achieves 27.7%\ncharacter error rate (CER), which is superior to current state-of-the-art\nresult on the popular HKUST task.", "published": "2018-06-17 06:57:30", "link": "http://arxiv.org/abs/1806.06342v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Incorporating Chinese Characters of Words for Lexical Sememe Prediction", "abstract": "Sememes are minimum semantic units of concepts in human languages, such that\neach word sense is composed of one or multiple sememes. Words are usually\nmanually annotated with their sememes by linguists, and form linguistic\ncommon-sense knowledge bases widely used in various NLP tasks. Recently, the\nlexical sememe prediction task has been introduced. It consists of\nautomatically recommending sememes for words, which is expected to improve\nannotation efficiency and consistency. However, existing methods of lexical\nsememe prediction typically rely on the external context of words to represent\nthe meaning, which usually fails to deal with low-frequency and\nout-of-vocabulary words. To address this issue for Chinese, we propose a novel\nframework to take advantage of both internal character information and external\ncontext information of words. We experiment on HowNet, a Chinese sememe\nknowledge base, and demonstrate that our framework outperforms state-of-the-art\nbaselines by a large margin, and maintains a robust performance even for\nlow-frequency words.", "published": "2018-06-17 08:44:55", "link": "http://arxiv.org/abs/1806.06349v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cover Song Synthesis by Analogy", "abstract": "In this work, we pose and address the following \"cover song analogies\"\nproblem: given a song A by artist 1 and a cover song A' of this song by artist\n2, and given a different song B by artist 1, synthesize a song B' which is a\ncover of B in the style of artist 2. Normally, such a polyphonic style transfer\nproblem would be quite challenging, but we show how the cover songs example\nconstrains the problem, making it easier to solve. First, we extract the\nlongest common beat-synchronous subsequence between A and A', and we time\nstretch the corresponding beat intervals in A' so that they align with A. We\nthen derive a version of joint 2D convolutional NMF, which we apply to the\nconstant-Q spectrograms of the synchronized segments to learn a translation\ndictionary of sound templates from A to A'. Finally, we apply the learned\ntemplates as filters to the song B, and we mash up the translated filtered\ncomponents into the synthesized song B' using audio mosaicing. We showcase our\nalgorithm on several examples, including a synthesized cover version of Michael\nJackson's \"Bad\" by Alien Ant Farm, learned from the latter's \"Smooth Criminal\"\ncover.'", "published": "2018-06-17 08:09:20", "link": "http://arxiv.org/abs/1806.06347v2", "categories": ["cs.SD", "eess.AS", "H.5.5; H.5.1"], "primary_category": "cs.SD"}
