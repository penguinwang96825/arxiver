{"title": "Evaluating the Portability of an NLP System for Processing\n  Echocardiograms: A Retrospective, Multi-site Observational Study", "abstract": "While natural language processing (NLP) of unstructured clinical narratives\nholds the potential for patient care and clinical research, portability of NLP\napproaches across multiple sites remains a major challenge. This study\ninvestigated the portability of an NLP system developed initially at the\nDepartment of Veterans Affairs (VA) to extract 27 key cardiac concepts from\nfree-text or semi-structured echocardiograms from three academic medical\ncenters: Weill Cornell Medicine, Mayo Clinic and Northwestern Medicine. While\nthe NLP system showed high precision and recall measurements for four target\nconcepts (aortic valve regurgitation, left atrium size at end systole, mitral\nvalve regurgitation, tricuspid valve regurgitation) across all sites, we found\nmoderate or poor results for the remaining concepts and the NLP system\nperformance varied between individual sites.", "published": "2019-04-02 02:01:28", "link": "http://arxiv.org/abs/1905.01961v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recent Advances in Natural Language Inference: A Survey of Benchmarks,\n  Resources, and Approaches", "abstract": "In the NLP community, recent years have seen a surge of research activities\nthat address machines' ability to perform deep language understanding which\ngoes beyond what is explicitly stated in text, rather relying on reasoning and\nknowledge of the world. Many benchmark tasks and datasets have been created to\nsupport the development and evaluation of such natural language inference\nability. As these benchmarks become instrumental and a driving force for the\nNLP research community, this paper aims to provide an overview of recent\nbenchmarks, relevant knowledge resources, and state-of-the-art learning and\ninference approaches in order to support a better understanding of this growing\nfield.", "published": "2019-04-02 02:09:01", "link": "http://arxiv.org/abs/1904.01172v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-Task Approach for Disentangling Syntax and Semantics in Sentence\n  Representations", "abstract": "We propose a generative model for a sentence that uses two latent variables,\nwith one intended to represent the syntax of the sentence and the other to\nrepresent its semantics. We show we can achieve better disentanglement between\nsemantic and syntactic representations by training with multiple losses,\nincluding losses that exploit aligned paraphrastic sentences and word-order\ninformation. We also investigate the effect of moving from bag-of-words to\nrecurrent neural network modules. We evaluate our models as well as several\npopular pretrained embeddings on standard semantic similarity tasks and novel\nsyntactic similarity tasks. Empirically, we find that the model with the best\nperforming syntactic and semantic representations also gives rise to the most\ndisentangled representations.", "published": "2019-04-02 02:09:05", "link": "http://arxiv.org/abs/1904.01173v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UHop: An Unrestricted-Hop Relation Extraction Framework for\n  Knowledge-Based Question Answering", "abstract": "In relation extraction for knowledge-based question answering, searching from\none entity to another entity via a single relation is called \"one hop\". In\nrelated work, an exhaustive search from all one-hop relations, two-hop\nrelations, and so on to the max-hop relations in the knowledge graph is\nnecessary but expensive. Therefore, the number of hops is generally restricted\nto two or three. In this paper, we propose UHop, an unrestricted-hop framework\nwhich relaxes this restriction by use of a transition-based search framework to\nreplace the relation-chain-based search one. We conduct experiments on\nconventional 1- and 2-hop questions as well as lengthy questions, including\ndatasets such as WebQSP, PathQuestion, and Grid World. Results show that the\nproposed framework enables the ability to halt, works well with\nstate-of-the-art models, achieves competitive performance without exhaustive\nsearches, and opens the performance gap for long relation paths.", "published": "2019-04-02 07:08:25", "link": "http://arxiv.org/abs/1904.01246v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Temporal and Aspectual Entailment", "abstract": "Inferences regarding \"Jane's arrival in London\" from predications such as\n\"Jane is going to London\" or \"Jane has gone to London\" depend on tense and\naspect of the predications. Tense determines the temporal location of the\npredication in the past, present or future of the time of utterance. The\naspectual auxiliaries on the other hand specify the internal constituency of\nthe event, i.e. whether the event of \"going to London\" is completed and whether\nits consequences hold at that time or not. While tense and aspect are among the\nmost important factors for determining natural language inference, there has\nbeen very little work to show whether modern NLP models capture these semantic\nconcepts. In this paper we propose a novel entailment dataset and analyse the\nability of a range of recently proposed NLP models to perform inference on\ntemporal predications. We show that the models encode a substantial amount of\nmorphosyntactic information relating to tense and aspect, but fail to model\ninferences that require reasoning with these semantic properties.", "published": "2019-04-02 08:57:55", "link": "http://arxiv.org/abs/1904.01297v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pragmatically Informative Text Generation", "abstract": "We improve the informativeness of models for conditional text generation\nusing techniques from computational pragmatics. These techniques formulate\nlanguage production as a game between speakers and listeners, in which a\nspeaker should generate output text that a listener can use to correctly\nidentify the original input that the text describes. While such approaches are\nwidely used in cognitive science and grounded language learning, they have\nreceived less attention for more standard language generation tasks. We\nconsider two pragmatic modeling methods for text generation: one where\npragmatics is imposed by information preservation, and another where pragmatics\nis imposed by explicit modeling of distractors. We find that these methods\nimprove the performance of strong existing systems for abstractive\nsummarization and generation from structured meaning representations.", "published": "2019-04-02 09:04:57", "link": "http://arxiv.org/abs/1904.01301v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Training Data Augmentation for Context-Sensitive Neural Lemmatization\n  Using Inflection Tables and Raw Text", "abstract": "Lemmatization aims to reduce the sparse data problem by relating the\ninflected forms of a word to its dictionary form. Using context can help, both\nfor unseen and ambiguous words. Yet most context-sensitive approaches require\nfull lemma-annotated sentences for training, which may be scarce or unavailable\nin low-resource languages. In addition (as shown here), in a low-resource\nsetting, a lemmatizer can learn more from $n$ labeled examples of distinct\nwords (types) than from $n$ (contiguous) labeled tokens, since the latter\ncontain far fewer distinct types. To combine the efficiency of type-based\nlearning with the benefits of context, we propose a way to train a\ncontext-sensitive lemmatizer with little or no labeled corpus data, using\ninflection tables from the UniMorph project and raw text examples from\nWikipedia that provide sentence contexts for the unambiguous UniMorph examples.\nDespite these being unambiguous examples, the model successfully generalizes\nfrom them, leading to improved results (both overall, and especially on unseen\nwords) in comparison to a baseline that does not use context.", "published": "2019-04-02 14:38:37", "link": "http://arxiv.org/abs/1904.01464v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Asking the Right Question: Inferring Advice-Seeking Intentions from\n  Personal Narratives", "abstract": "People often share personal narratives in order to seek advice from others.\nTo properly infer the narrator's intention, one needs to apply a certain degree\nof common sense and social intuition. To test the capabilities of NLP systems\nto recover such intuition, we introduce the new task of inferring what is the\nadvice-seeking goal behind a personal narrative. We formulate this as a cloze\ntest, where the goal is to identify which of two advice-seeking questions was\nremoved from a given narrative.\n  The main challenge in constructing this task is finding pairs of semantically\nplausible advice-seeking questions for given narratives. To address this\nchallenge, we devise a method that exploits commonalities in experiences people\nshare online to automatically extract pairs of questions that are appropriate\ncandidates for the cloze task. This results in a dataset of over 20,000\npersonal narratives, each matched with a pair of related advice-seeking\nquestions: one actually intended by the narrator, and the other one not. The\ndataset covers a very broad array of human experiences, from dating, to career\noptions, to stolen iPads. We use human annotation to determine the degree to\nwhich the task relies on common sense and social intuition in addition to a\nsemantic understanding of the narrative. By introducing several baselines for\nthis new task we demonstrate its feasibility and identify avenues for better\nmodeling the intention of the narrator.", "published": "2019-04-02 18:00:02", "link": "http://arxiv.org/abs/1904.01587v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Polarization in Social Media: Method and Application to Tweets\n  on 21 Mass Shootings", "abstract": "We provide an NLP framework to uncover four linguistic dimensions of\npolitical polarization in social media: topic choice, framing, affect and\nillocutionary force. We quantify these aspects with existing lexical methods,\nand propose clustering of tweet embeddings as a means to identify salient\ntopics for analysis across events; human evaluations show that our approach\ngenerates more cohesive topics than traditional LDA-based models. We apply our\nmethods to study 4.4M tweets on 21 mass shootings. We provide evidence that the\ndiscussion of these events is highly polarized politically and that this\npolarization is primarily driven by partisan differences in framing rather than\ntopic choice. We identify framing devices, such as grounding and the\ncontrasting use of the terms \"terrorist\" and \"crazy\", that contribute to\npolarization. Results pertaining to topic choice, affect and illocutionary\nforce suggest that Republicans focus more on the shooter and event-specific\nfacts (news) while Democrats focus more on the victims and call for policy\nchanges. Our work contributes to a deeper understanding of the way group\ndivisions manifest in language and to computational methods for studying them.", "published": "2019-04-02 18:00:09", "link": "http://arxiv.org/abs/1904.01596v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inferring Which Medical Treatments Work from Reports of Clinical Trials", "abstract": "How do we know if a particular medical treatment actually works? Ideally one\nwould consult all available evidence from relevant clinical trials.\nUnfortunately, such results are primarily disseminated in natural language\nscientific articles, imposing substantial burden on those trying to make sense\nof them. In this paper, we present a new task and corpus for making this\nunstructured evidence actionable. The task entails inferring reported findings\nfrom a full-text article describing a randomized controlled trial (RCT) with\nrespect to a given intervention, comparator, and outcome of interest, e.g.,\ninferring if an article provides evidence supporting the use of aspirin to\nreduce risk of stroke, as compared to placebo.\n  We present a new corpus for this task comprising 10,000+ prompts coupled with\nfull-text articles describing RCTs. Results using a suite of models --- ranging\nfrom heuristic (rule-based) approaches to attentive neural architectures ---\ndemonstrate the difficulty of the task, which we believe largely owes to the\nlengthy, technical input texts. To facilitate further work on this important,\nchallenging problem we make the corpus, documentation, a website and\nleaderboard, and code for baselines and evaluation available at\nhttp://evidence-inference.ebm-nlp.com/.", "published": "2019-04-02 18:17:49", "link": "http://arxiv.org/abs/1904.01606v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Structural Scaffolds for Citation Intent Classification in Scientific\n  Publications", "abstract": "Identifying the intent of a citation in scientific papers (e.g., background\ninformation, use of methods, comparing results) is critical for machine reading\nof individual publications and automated analysis of the scientific literature.\nWe propose structural scaffolds, a multitask model to incorporate structural\ninformation of scientific papers into citations for effective classification of\ncitation intents. Our model achieves a new state-of-the-art on an existing ACL\nanthology dataset (ACL-ARC) with a 13.3% absolute increase in F1 score, without\nrelying on external linguistic resources or hand-engineered features as done in\nexisting methods. In addition, we introduce a new dataset of citation intents\n(SciCite) which is more than five times larger and covers multiple scientific\ndomains compared with existing datasets. Our code and data are available at:\nhttps://github.com/allenai/scicite.", "published": "2019-04-02 18:22:09", "link": "http://arxiv.org/abs/1904.01608v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attentive Mimicking: Better Word Embeddings by Attending to Informative\n  Contexts", "abstract": "Learning high-quality embeddings for rare words is a hard problem because of\nsparse context information. Mimicking (Pinter et al., 2017) has been proposed\nas a solution: given embeddings learned by a standard algorithm, a model is\nfirst trained to reproduce embeddings of frequent words from their surface form\nand then used to compute embeddings for rare words. In this paper, we introduce\nattentive mimicking: the mimicking model is given access not only to a word's\nsurface form, but also to all available contexts and learns to attend to the\nmost informative and reliable contexts for computing an embedding. In an\nevaluation on four tasks, we show that attentive mimicking outperforms previous\nwork for both rare and medium-frequency words. Thus, compared to previous work,\nattentive mimicking improves embeddings for a much larger part of the\nvocabulary, including the medium-frequency range.", "published": "2019-04-02 18:44:04", "link": "http://arxiv.org/abs/1904.01617v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Impact of ASR on Alzheimer's Disease Detection: All Errors are Equal,\n  but Deletions are More Equal than Others", "abstract": "Automatic Speech Recognition (ASR) is a critical component of any\nfully-automated speech-based dementia detection model. However, despite years\nof speech recognition research, little is known about the impact of ASR\naccuracy on dementia detection. In this paper, we experiment with controlled\namounts of artificially generated ASR errors and investigate their influence on\ndementia detection. We find that deletion errors affect detection performance\nthe most, due to their impact on the features of syntactic complexity and\ndiscourse representation in speech. We show the trend to be generalisable\nacross two different datasets for cognitive impairment detection. As a\nconclusion, we propose optimising the ASR to reflect a higher penalty for\ndeletion errors in order to improve dementia detection performance.", "published": "2019-04-02 21:59:35", "link": "http://arxiv.org/abs/1904.01684v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Short Text Classification Improved by Feature Space Extension", "abstract": "With the explosive development of mobile Internet, short text has been\napplied extensively. The difference between classifying short text and long\ndocuments is that short text is of shortness and sparsity. Thus, it is\nchallenging to deal with short text classification owing to its less semantic\ninformation. In this paper, we propose a novel topic-based convolutional neural\nnetwork (TB-CNN) based on Latent Dirichlet Allocation (LDA) model and\nconvolutional neural network. Comparing to traditional CNN methods, TB-CNN\ngenerates topic words with LDA model to reduce the sparseness and combines the\nembedding vectors of topic words and input words to extend feature space of\nshort text. The validation results on IMDB movie review dataset show the\nimprovement and effectiveness of TB-CNN.", "published": "2019-04-02 10:00:58", "link": "http://arxiv.org/abs/1904.01313v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Aiding Intra-Text Representations with Visual Context for Multimodal\n  Named Entity Recognition", "abstract": "With massive explosion of social media such as Twitter and Instagram, people\ndaily share billions of multimedia posts, containing images and text.\nTypically, text in these posts is short, informal and noisy, leading to\nambiguities which can be resolved using images. In this paper we explore\ntext-centric Named Entity Recognition task on these multimedia posts. We\npropose an end to end model which learns a joint representation of a text and\nan image. Our model extends multi-dimensional self attention technique, where\nnow image helps to enhance relationship between words. Experiments show that\nour model is capable of capturing both textual and visual contexts with greater\naccuracy, achieving state-of-the-art results on Twitter multimodal Named Entity\nRecognition dataset.", "published": "2019-04-02 11:57:40", "link": "http://arxiv.org/abs/1904.01356v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Using Multi-Sense Vector Embeddings for Reverse Dictionaries", "abstract": "Popular word embedding methods such as word2vec and GloVe assign a single\nvector representation to each word, even if a word has multiple distinct\nmeanings. Multi-sense embeddings instead provide different vectors for each\nsense of a word. However, they typically cannot serve as a drop-in replacement\nfor conventional single-sense embeddings, because the correct sense vector\nneeds to be selected for each word. In this work, we study the effect of\nmulti-sense embeddings on the task of reverse dictionaries. We propose a\ntechnique to easily integrate them into an existing neural network architecture\nusing an attention mechanism. Our experiments demonstrate that large\nimprovements can be obtained when employing multi-sense embeddings both in the\ninput sequence as well as for the target representation. An analysis of the\nsense distributions and of the learned attention is provided as well.", "published": "2019-04-02 14:17:19", "link": "http://arxiv.org/abs/1904.01451v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural Vector Conceptualization for Word Vector Space Interpretation", "abstract": "Distributed word vector spaces are considered hard to interpret which hinders\nthe understanding of natural language processing (NLP) models. In this work, we\nintroduce a new method to interpret arbitrary samples from a word vector space.\nTo this end, we train a neural model to conceptualize word vectors, which means\nthat it activates higher order concepts it recognizes in a given vector.\nContrary to prior approaches, our model operates in the original vector space\nand is capable of learning non-linear relations between word vectors and\nconcepts. Furthermore, we show that it produces considerably less entropic\nconcept activation profiles than the popular cosine similarity.", "published": "2019-04-02 15:39:27", "link": "http://arxiv.org/abs/1904.01500v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Understanding language-elicited EEG data by predicting it from a\n  fine-tuned language model", "abstract": "Electroencephalography (EEG) recordings of brain activity taken while\nparticipants read or listen to language are widely used within the cognitive\nneuroscience and psycholinguistics communities as a tool to study language\ncomprehension. Several time-locked stereotyped EEG responses to\nword-presentations -- known collectively as event-related potentials (ERPs) --\nare thought to be markers for semantic or syntactic processes that take place\nduring comprehension. However, the characterization of each individual ERP in\nterms of what features of a stream of language trigger the response remains\ncontroversial. Improving this characterization would make ERPs a more useful\ntool for studying language comprehension. We take a step towards better\nunderstanding the ERPs by fine-tuning a language model to predict them. This\nnew approach to analysis shows for the first time that all of the ERPs are\npredictable from embeddings of a stream of language. Prior work has only found\ntwo of the ERPs to be predictable. In addition to this analysis, we examine\nwhich ERPs benefit from sharing parameters during joint training. We find that\ntwo pairs of ERPs previously identified in the literature as being related to\neach other benefit from joint training, while several other pairs of ERPs that\nbenefit from joint training are suggestive of potential relationships.\nExtensions of this analysis that further examine what kinds of information in\nthe model embeddings relate to each ERP have the potential to elucidate the\nprocesses involved in human language comprehension.", "published": "2019-04-02 17:02:19", "link": "http://arxiv.org/abs/1904.01548v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Identification, Interpretability, and Bayesian Word Embeddings", "abstract": "Social scientists have recently turned to analyzing text using tools from\nnatural language processing like word embeddings to measure concepts like\nideology, bias, and affinity. However, word embeddings are difficult to use in\nthe regression framework familiar to social scientists: embeddings are are\nneither identified, nor directly interpretable. I offer two advances on\nstandard embedding models to remedy these problems. First, I develop Bayesian\nWord Embeddings with Automatic Relevance Determination priors, relaxing the\nassumption that all embedding dimensions have equal weight. Second, I apply\nwork identifying latent variable models to anchor the dimensions of the\nresulting embeddings, identifying them, and making them interpretable and\nusable in a regression. I then apply this model and anchoring approach to two\ncases, the shift in internationalist rhetoric in the American presidents'\ninaugural addresses, and the relationship between bellicosity in American\nforeign policy decision-makers' deliberations. I find that inaugural addresses\nbecame less internationalist after 1945, which goes against the conventional\nwisdom, and that an increase in bellicosity is associated with an increase in\nhostile actions by the United States, showing that elite deliberations are not\ncheap talk, and helping confirm the validity of the model.", "published": "2019-04-02 19:12:35", "link": "http://arxiv.org/abs/1904.01628v1", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "A frame semantic overview of NLP-based information extraction for\n  cancer-related EHR notes", "abstract": "Objective: There is a lot of information about cancer in Electronic Health\nRecord (EHR) notes that can be useful for biomedical research provided natural\nlanguage processing (NLP) methods are available to extract and structure this\ninformation. In this paper, we present a scoping review of existing clinical\nNLP literature for cancer. Methods: We identified studies describing an NLP\nmethod to extract specific cancer-related information from EHR sources from\nPubMed, Google Scholar, ACL Anthology, and existing reviews. Two exclusion\ncriteria were used in this study. We excluded articles where the extraction\ntechniques used were too broad to be represented as frames and also where very\nlow-level extraction methods were used. 79 articles were included in the final\nreview. We organized this information according to frame semantic principles to\nhelp identify common areas of overlap and potential gaps. Results: Frames were\ncreated from the reviewed articles pertaining to cancer information such as\ncancer diagnosis, tumor description, cancer procedure, breast cancer diagnosis,\nprostate cancer diagnosis and pain in prostate cancer patients. These frames\nincluded both a definition as well as specific frame elements (i.e. extractable\nattributes). We found that cancer diagnosis was the most common frame among the\nreviewed papers (36 out of 79), with recent work focusing on extracting\ninformation related to treatment and breast cancer diagnosis. Conclusion: The\nlist of common frames described in this paper identifies important\ncancer-related information extracted by existing NLP techniques and serves as a\nuseful resource for future researchers requiring cancer information extracted\nfrom EHR notes. We also argue, due to the heavy duplication of cancer NLP\nsystems, that a general purpose resource of annotated cancer frames and\ncorresponding NLP tools would be valuable.", "published": "2019-04-02 20:27:42", "link": "http://arxiv.org/abs/1904.01655v1", "categories": ["q-bio.QM", "cs.CL"], "primary_category": "q-bio.QM"}
{"title": "The Tower of Babel Meets Web 2.0: User-Generated Content and its\n  Applications in a Multilingual Context", "abstract": "This study explores language's fragmenting effect on user-generated content\nby examining the diversity of knowledge representations across 25 different\nWikipedia language editions. This diversity is measured at two levels: the\nconcepts that are included in each edition and the ways in which these concepts\nare described. We demonstrate that the diversity present is greater than has\nbeen presumed in the literature and has a significant influence on applications\nthat use Wikipedia as a source of world knowledge. We close by explicating how\nknowledge diversity can be beneficially leveraged to create \"culturally-aware\napplications\" and \"hyperlingual applications\".", "published": "2019-04-02 22:23:05", "link": "http://arxiv.org/abs/1904.01689v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Improving Robot Success Detection using Static Object Data", "abstract": "We use static object data to improve success detection for stacking objects\non and nesting objects in one another. Such actions are necessary for certain\nrobotics tasks, e.g., clearing a dining table or packing a warehouse bin.\nHowever, using an RGB-D camera to detect success can be insufficient:\nsame-colored objects can be difficult to differentiate, and reflective\nsilverware cause noisy depth camera perception. We show that adding static data\nabout the objects themselves improves the performance of an end-to-end pipeline\nfor classifying action outcomes. Images of the objects, and language\nexpressions describing them, encode prior geometry, shape, and size information\nthat refine classification accuracy. We collect over 13 hours of egocentric\nmanipulation data for training a model to reason about whether a robot\nsuccessfully placed unseen objects in or on one another. The model achieves up\nto a 57% absolute gain over the task baseline on pairs of previously unseen\nobjects.", "published": "2019-04-02 20:18:52", "link": "http://arxiv.org/abs/1904.01650v2", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Mirroring to Build Trust in Digital Assistants", "abstract": "We describe experiments towards building a conversational digital assistant\nthat considers the preferred conversational style of the user. In particular,\nthese experiments are designed to measure whether users prefer and trust an\nassistant whose conversational style matches their own. To this end we\nconducted a user study where subjects interacted with a digital assistant that\nresponded in a way that either matched their conversational style, or did not.\nUsing self-reported personality attributes and subjects' feedback on the\ninteractions, we built models that can reliably predict a user's preferred\nconversational style.", "published": "2019-04-02 20:51:27", "link": "http://arxiv.org/abs/1904.01664v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Effectiveness of Data-Driven Induction of Semantic Spaces and\n  Traditional Classifiers for Sarcasm Detection", "abstract": "Irony and sarcasm are two complex linguistic phenomena that are widely used\nin everyday language and especially over the social media, but they represent\ntwo serious issues for automated text understanding. Many labeled corpora have\nbeen extracted from several sources to accomplish this task, and it seems that\nsarcasm is conveyed in different ways for different domains. Nonetheless, very\nlittle work has been done for comparing different methods among the available\ncorpora. Furthermore, usually, each author collects and uses their own datasets\nto evaluate his own method. In this paper, we show that sarcasm detection can\nbe tackled by applying classical machine learning algorithms to input texts\nsub-symbolically represented in a Latent Semantic space. The main consequence\nis that our studies establish both reference datasets and baselines for the\nsarcasm detection problem that could serve the scientific community to test\nnewly proposed methods.", "published": "2019-04-02 15:49:02", "link": "http://arxiv.org/abs/1904.04019v4", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Software Tools for Big Data Resources in Family Names Dictionaries", "abstract": "This paper describes the design and development of specific software tools\nused during the creation of Family Names in Britain and Ireland (FaNBI)\nresearch project, started by the University of the West of England in 2010 and\nfinished successfully in 2016. First, the overview of the project and\nmethodology is provided. Next section contains the description of dictionary\nmanagement tools and software tools to combine input data resources.", "published": "2019-04-02 08:25:40", "link": "http://arxiv.org/abs/1904.09234v1", "categories": ["cs.DL", "cs.CL", "cs.IR"], "primary_category": "cs.DL"}
{"title": "Habitat: A Platform for Embodied AI Research", "abstract": "We present Habitat, a platform for research in embodied artificial\nintelligence (AI). Habitat enables training embodied agents (virtual robots) in\nhighly efficient photorealistic 3D simulation. Specifically, Habitat consists\nof: (i) Habitat-Sim: a flexible, high-performance 3D simulator with\nconfigurable agents, sensors, and generic 3D dataset handling. Habitat-Sim is\nfast -- when rendering a scene from Matterport3D, it achieves several thousand\nframes per second (fps) running single-threaded, and can reach over 10,000 fps\nmulti-process on a single GPU. (ii) Habitat-API: a modular high-level library\nfor end-to-end development of embodied AI algorithms -- defining tasks (e.g.,\nnavigation, instruction following, question answering), configuring, training,\nand benchmarking embodied agents.\n  These large-scale engineering contributions enable us to answer scientific\nquestions requiring experiments that were till now impracticable or 'merely'\nimpractical. Specifically, in the context of point-goal navigation: (1) we\nrevisit the comparison between learning and SLAM approaches from two recent\nworks and find evidence for the opposite conclusion -- that learning\noutperforms SLAM if scaled to an order of magnitude more experience than\nprevious investigations, and (2) we conduct the first cross-dataset\ngeneralization experiments {train, test} x {Matterport3D, Gibson} for multiple\nsensors {blind, RGB, RGBD, D} and find that only agents with depth (D) sensors\ngeneralize across datasets. We hope that our open-source platform and these\nfindings will advance research in embodied AI.", "published": "2019-04-02 03:52:27", "link": "http://arxiv.org/abs/1904.01201v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Experiments on Open-Set Speaker Identification with Discriminatively\n  Trained Neural Networks", "abstract": "This paper presents a study on discriminative artificial neural network\nclassifiers in the context of open-set speaker identification. Both 2-class and\nmulti-class architectures are tested against the conventional Gaussian mixture\nmodel based classifier on enrolled speaker sets of different sizes. The\nperformance evaluation shows that the multi-class neural network system has\nsuperior performance for large population sizes.", "published": "2019-04-02 07:59:49", "link": "http://arxiv.org/abs/1904.01269v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Speech denoising by parametric resynthesis", "abstract": "This work proposes the use of clean speech vocoder parameters as the target\nfor a neural network performing speech enhancement. These parameters have been\ndesigned for text-to-speech synthesis so that they both produce high-quality\nresyntheses and also are straightforward to model with neural networks, but\nhave not been utilized in speech enhancement until now. In comparison to a\nmatched text-to-speech system that is given the ground truth transcripts of the\nnoisy speech, our model is able to produce more natural speech because it has\naccess to the true prosody in the noisy speech. In comparison to two denoising\nsystems, the oracle Wiener mask and a DNN-based mask predictor, our model\nequals the oracle Wiener mask in subjective quality and intelligibility and\nsurpasses the realistic system. A vocoder-based upper bound shows that there is\nstill room for improvement with this approach beyond the oracle Wiener mask. We\ntest speaker-dependence with two speakers and show that a single model can be\nused for multiple speakers.", "published": "2019-04-02 16:50:46", "link": "http://arxiv.org/abs/1904.01537v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Lessons from Building Acoustic Models with a Million Hours of Speech", "abstract": "This is a report of our lessons learned building acoustic models from 1\nMillion hours of unlabeled speech, while labeled speech is restricted to 7,000\nhours. We employ student/teacher training on unlabeled data, helping scale out\ntarget generation in comparison to confidence model based methods, which\nrequire a decoder and a confidence model. To optimize storage and to\nparallelize target generation, we store high valued logits from the teacher\nmodel. Introducing the notion of scheduled learning, we interleave learning on\nunlabeled and labeled data. To scale distributed training across a large number\nof GPUs, we use BMUF with 64 GPUs, while performing sequence training only on\nlabeled data with gradient threshold compression SGD using 16 GPUs. Our\nexperiments show that extremely large amounts of data are indeed useful; with\nlittle hyper-parameter tuning, we obtain relative WER improvements in the 10 to\n20% range, with higher gains in noisier conditions.", "published": "2019-04-02 18:58:41", "link": "http://arxiv.org/abs/1904.01624v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
