{"title": "Detecting Satire in the News with Machine Learning", "abstract": "We built models with Logistic Regression and linear Support Vector Machines\non a large dataset consisting of regular news articles and news from satirical\nwebsites, and showed that such linear classifiers on a corpus with about 60,000\narticles can perform with a precision of 98.7% and a recall of 95.2% on a\nrandom test set of the news. On the other hand, when testing the classifier on\n\"publication sources\" which are completely unknown during training, only an\naccuracy of 88.2% and an F1-score of 76.3% are achieved. As another result, we\nshowed that the same algorithm can distinguish between news written by the news\nagency itself and paid articles from customers. Here the results had an\naccuracy of 99%.", "published": "2018-10-01 09:26:43", "link": "http://arxiv.org/abs/1810.00593v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient and Accurate Abnormality Mining from Radiology Reports with\n  Customized False Positive Reduction", "abstract": "Obtaining datasets labeled to facilitate model development is a challenge for\nmost machine learning tasks. The difficulty is heightened for medical imaging,\nwhere data itself is limited in accessibility and labeling requires costly time\nand effort by trained medical specialists. Medical imaging studies, however,\nare often accompanied by a medical report produced by a radiologist,\nidentifying important features on the corresponding scan for other physicians\nnot specifically trained in radiology. We propose a methodology for\napproximating image-level labels for radiology studies from associated reports\nusing a general purpose language processing tool for medical concept extraction\nand sentiment analysis, and simple manually crafted heuristics for false\npositive reduction. Using this approach, we label more than 175,000 Head CT\nstudies for the presence of 33 features indicative of 11 clinically relevant\nconditions. For 27 of the 30 keywords that yielded positive results (3 had no\noccurrences), the lower bound of the confidence intervals created to estimate\nthe percentage of accurately labeled reports was above 85%, with the average\nbeing above 95%. Though noisier then manual labeling, these results suggest\nthis method to be a viable means of labeling medical images at scale.", "published": "2018-10-01 20:40:15", "link": "http://arxiv.org/abs/1810.00967v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ranking Paragraphs for Improving Answer Recall in Open-Domain Question\n  Answering", "abstract": "Recently, open-domain question answering (QA) has been combined with machine\ncomprehension models to find answers in a large knowledge source. As\nopen-domain QA requires retrieving relevant documents from text corpora to\nanswer questions, its performance largely depends on the performance of\ndocument retrievers. However, since traditional information retrieval systems\nare not effective in obtaining documents with a high probability of containing\nanswers, they lower the performance of QA systems. Simply extracting more\ndocuments increases the number of irrelevant documents, which also degrades the\nperformance of QA systems. In this paper, we introduce Paragraph Ranker which\nranks paragraphs of retrieved documents for a higher answer recall with less\nnoise. We show that ranking paragraphs and aggregating answers using Paragraph\nRanker improves performance of open-domain QA pipeline on the four open-domain\nQA datasets by 7.8% on average.", "published": "2018-10-01 00:51:25", "link": "http://arxiv.org/abs/1810.00494v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Joint On-line Learning of a Zero-shot Spoken Semantic Parser and a\n  Reinforcement Learning Dialogue Manager", "abstract": "Despite many recent advances for the design of dialogue systems, a true\nbottleneck remains the acquisition of data required to train its components.\nUnlike many other language processing applications, dialogue systems require\ninteractions with users, therefore it is complex to develop them with\npre-recorded data. Building on previous works, on-line learning is pursued here\nas a most convenient way to address the issue. Data collection, annotation and\nuse in learning algorithms are performed in a single process. The main\ndifficulties are then: to bootstrap an initial basic system, and to control the\nlevel of additional cost on the user side. Considering that well-performing\nsolutions can be used directly off the shelf for speech recognition and\nsynthesis, the study is focused on learning the spoken language understanding\nand dialogue management modules only. Several variants of joint learning are\ninvestigated and tested with user trials to confirm that the overall on-line\nlearning can be obtained after only a few hundred training dialogues and can\noverstep an expert-based system.", "published": "2018-10-01 19:15:57", "link": "http://arxiv.org/abs/1810.00924v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Challenges of Using Text Classifiers for Causal Inference", "abstract": "Causal understanding is essential for many kinds of decision-making, but\ncausal inference from observational data has typically only been applied to\nstructured, low-dimensional datasets. While text classifiers produce\nlow-dimensional outputs, their use in causal inference has not previously been\nstudied. To facilitate causal analyses based on language data, we consider the\nrole that text classifiers can play in causal inference through established\nmodeling mechanisms from the causality literature on missing data and\nmeasurement error. We demonstrate how to conduct causal analyses using text\nclassifiers on simulated and Yelp data, and discuss the opportunities and\nchallenges of future work that uses text data in causal inference.", "published": "2018-10-01 20:08:40", "link": "http://arxiv.org/abs/1810.00956v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Utilizing a Transparency-driven Environment toward Trusted Automatic\n  Genre Classification: A Case Study in Journalism History", "abstract": "With the growing abundance of unlabeled data in real-world tasks, researchers\nhave to rely on the predictions given by black-boxed computational models.\nHowever, it is an often neglected fact that these models may be scoring high on\naccuracy for the wrong reasons. In this paper, we present a practical impact\nanalysis of enabling model transparency by various presentation forms. For this\npurpose, we developed an environment that empowers non-computer scientists to\nbecome practicing data scientists in their own research field. We demonstrate\nthe gradually increasing understanding of journalism historians through a\nreal-world use case study on automatic genre classification of newspaper\narticles. This study is a first step towards trusted usage of machine learning\npipelines in a responsible way.", "published": "2018-10-01 20:40:59", "link": "http://arxiv.org/abs/1810.00968v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Simple Machine Learning Method for Commonsense Reasoning? A Short\n  Commentary on Trinh & Le (2018)", "abstract": "This is a short Commentary on Trinh & Le (2018) (\"A Simple Method for\nCommonsense Reasoning\") that outlines three serious flaws in the cited paper\nand discusses why data-driven approaches cannot be considered as serious models\nfor the commonsense reasoning needed in natural language understanding in\ngeneral, and in reference resolution, in particular.", "published": "2018-10-01 03:58:00", "link": "http://arxiv.org/abs/1810.00521v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "The Profiling Machine: Active Generalization over Knowledge", "abstract": "The human mind is a powerful multifunctional knowledge storage and management\nsystem that performs generalization, type inference, anomaly detection,\nstereotyping, and other tasks. A dynamic KR system that appropriately profiles\nover sparse inputs to provide complete expectations for unknown facets can help\nwith all these tasks. In this paper, we introduce the task of profiling,\ninspired by theories and findings in social psychology about the potential of\nprofiles for reasoning and information processing. We describe two generic\nstate-of-the-art neural architectures that can be easily instantiated as\nprofiling machines to generate expectations and applied to any kind of\nknowledge to fill gaps. We evaluate these methods against Wikidata and crowd\nexpectations, and compare the results to gain insight in the nature of\nknowledge captured by various profiling methods. We make all code and data\navailable to facilitate future research.", "published": "2018-10-01 16:03:49", "link": "http://arxiv.org/abs/1810.00782v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Eigentriads and Eigenprogressions on the Tonnetz", "abstract": "We introduce a new multidimensional representation, named eigenprogression\ntransform, that characterizes some essential patterns of Western tonal harmony\nwhile being equivariant to time shifts and pitch transpositions. This\nrepresentation is deep, multiscale, and convolutional in the piano-roll domain,\nyet incurs no prior training, and is thus suited to both supervised and\nunsupervised MIR tasks. The eigenprogression transform combines ideas from the\nspiral scattering transform, spectral graph theory, and wavelet shrinkage\ndenoising. We report state-of-the-art results on a task of supervised composer\nrecognition (Haydn vs. Mozart) from polyphonic music pieces in MIDI format.", "published": "2018-10-01 16:21:55", "link": "http://arxiv.org/abs/1810.00790v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Convolutional Neural Networks and x-vector Embedding for DCASE2018\n  Acoustic Scene Classification Challenge", "abstract": "In this paper, the Brno University of Technology (BUT) team submissions for\nTask 1 (Acoustic Scene Classification, ASC) of the DCASE-2018 challenge are\ndescribed. Also, the analysis of different methods on the leaderboard set is\nprovided. The proposed approach is a fusion of two different Convolutional\nNeural Network (CNN) topologies. The first one is the common two-dimensional\nCNNs which is mainly used in image classification. The second one is a\none-dimensional CNN for extracting fixed-length audio segment embeddings, so\ncalled x-vectors, which has also been used in speech processing, especially for\nspeaker recognition. In addition to the different topologies, two types of\nfeatures were tested: log mel-spectrogram and CQT features. Finally, the\noutputs of different systems are fused using a simple output averaging in the\nbest performing system. Our submissions ranked third among 24 teams in the ASC\nsub-task A (task1a).", "published": "2018-10-01 18:45:12", "link": "http://arxiv.org/abs/1810.04273v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
