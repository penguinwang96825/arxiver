{"title": "Mixup Decoding for Diverse Machine Translation", "abstract": "Diverse machine translation aims at generating various target language\ntranslations for a given source language sentence. Leveraging the linear\nrelationship in the sentence latent space introduced by the mixup training, we\npropose a novel method, MixDiversity, to generate different translations for\nthe input sentence by linearly interpolating it with different sentence pairs\nsampled from the training corpus when decoding. To further improve the\nfaithfulness and diversity of the translations, we propose two simple but\neffective approaches to select diverse sentence pairs in the training corpus\nand adjust the interpolation weight for each pair correspondingly. Moreover, by\ncontrolling the interpolation weight, our method can achieve the trade-off\nbetween faithfulness and diversity without any additional training, which is\nrequired in most of the previous methods. Experiments on WMT'16 en-ro, WMT'14\nen-de, and WMT'17 zh-en are conducted to show that our method substantially\noutperforms all previous diverse machine translation methods.", "published": "2021-09-08 02:39:03", "link": "http://arxiv.org/abs/2109.03402v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vision Matters When It Should: Sanity Checking Multimodal Machine\n  Translation Models", "abstract": "Multimodal machine translation (MMT) systems have been shown to outperform\ntheir text-only neural machine translation (NMT) counterparts when visual\ncontext is available. However, recent studies have also shown that the\nperformance of MMT models is only marginally impacted when the associated image\nis replaced with an unrelated image or noise, which suggests that the visual\ncontext might not be exploited by the model at all. We hypothesize that this\nmight be caused by the nature of the commonly used evaluation benchmark, also\nknown as Multi30K, where the translations of image captions were prepared\nwithout actually showing the images to human translators. In this paper, we\npresent a qualitative study that examines the role of datasets in stimulating\nthe leverage of visual modality and we propose methods to highlight the\nimportance of visual signals in the datasets which demonstrate improvements in\nreliance of models on the source images. Our findings suggest the research on\neffective MMT architectures is currently impaired by the lack of suitable\ndatasets and careful consideration must be taken in creation of future MMT\ndatasets, for which we also provide useful insights.", "published": "2021-09-08 03:32:48", "link": "http://arxiv.org/abs/2109.03415v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequence Level Contrastive Learning for Text Summarization", "abstract": "Contrastive learning models have achieved great success in unsupervised\nvisual representation learning, which maximize the similarities between feature\nrepresentations of different views of the same image, while minimize the\nsimilarities between feature representations of views of different images. In\ntext summarization, the output summary is a shorter form of the input document\nand they have similar meanings. In this paper, we propose a contrastive\nlearning model for supervised abstractive text summarization, where we view a\ndocument, its gold summary and its model generated summaries as different views\nof the same mean representation and maximize the similarities between them\nduring training. We improve over a strong sequence-to-sequence text generation\nmodel (i.e., BART) on three different summarization datasets. Human evaluation\nalso shows that our model achieves better faithfulness ratings compared to its\ncounterpart without contrastive objectives.", "published": "2021-09-08 08:00:36", "link": "http://arxiv.org/abs/2109.03481v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RefineCap: Concept-Aware Refinement for Image Captioning", "abstract": "Automatically translating images to texts involves image scene understanding\nand language modeling. In this paper, we propose a novel model, termed\nRefineCap, that refines the output vocabulary of the language decoder using\ndecoder-guided visual semantics, and implicitly learns the mapping between\nvisual tag words and images. The proposed Visual-Concept Refinement method can\nallow the generator to attend to semantic details in the image, thereby\ngenerating more semantically descriptive captions. Our model achieves superior\nperformance on the MS-COCO dataset in comparison with previous visual-concept\nbased models.", "published": "2021-09-08 10:12:14", "link": "http://arxiv.org/abs/2109.03529v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Transferability of Pre-trained Language Models: A Study from\n  Artificial Datasets", "abstract": "Pre-training language models (LMs) on large-scale unlabeled text data makes\nthe model much easier to achieve exceptional downstream performance than their\ncounterparts directly trained on the downstream tasks. In this work, we study\nwhat specific traits in the pre-training data, other than the semantics, make a\npre-trained LM superior to their counterparts trained from scratch on\ndownstream tasks. We propose to use artificially constructed datasets as the\npre-training data to exclude the effect of semantics, and further control what\ncharacteristics the pre-training corpora have. By fine-tuning the pre-trained\nmodels on GLUE benchmark, we can learn how beneficial it is to transfer the\nknowledge from the model trained on the dataset possessing that specific trait.\nWe define and discuss three different characteristics in the artificial\ndataset: 1) matching the token's uni-gram or bi-gram distribution between\npre-training and downstream fine-tuning, 2) the presence of the explicit\ndependencies among the tokens in a sequence, 3) the length of the implicit\ndependencies among the tokens in a sequence. Our experiments show that the\nexplicit dependencies in the sequences of the pre-training data are critical to\nthe downstream performance. Our results also reveal that models achieve better\ndownstream performance when pre-trained on a dataset with a longer range of\nimplicit dependencies. Based on our analysis, we find that models pre-trained\nwith artificial datasets are prone to learn spurious correlation in downstream\ntasks. Our work reveals that even if the LMs are not pre-trained on natural\nlanguage, they still gain transferability on certain human language downstream\ntasks once the LMs learn to model the token dependencies in the sequences. This\nresult helps us understand the exceptional transferability of pre-trained LMs.", "published": "2021-09-08 10:39:57", "link": "http://arxiv.org/abs/2109.03537v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Biomedical and Clinical Language Models for Spanish: On the Benefits of\n  Domain-Specific Pretraining in a Mid-Resource Scenario", "abstract": "This work presents biomedical and clinical language models for Spanish by\nexperimenting with different pretraining choices, such as masking at word and\nsubword level, varying the vocabulary size and testing with domain data,\nlooking for better language representations. Interestingly, in the absence of\nenough clinical data to train a model from scratch, we applied mixed-domain\npretraining and cross-domain transfer approaches to generate a performant\nbio-clinical model suitable for real-world clinical data. We evaluated our\nmodels on Named Entity Recognition (NER) tasks for biomedical documents and\nchallenging hospital discharge reports. When compared against the competitive\nmBERT and BETO models, we outperform them in all NER tasks by a significant\nmargin. Finally, we studied the impact of the model's vocabulary on the NER\nperformances by offering an interesting vocabulary-centric analysis. The\nresults confirm that domain-specific pretraining is fundamental to achieving\nhigher performances in downstream NER tasks, even within a mid-resource\nscenario. To the best of our knowledge, we provide the first biomedical and\nclinical transformer-based pretrained language models for Spanish, intending to\nboost native Spanish NLP applications in biomedicine. Our best models are\nfreely available in the HuggingFace hub: https://huggingface.co/BSC-TeMU.", "published": "2021-09-08 12:12:07", "link": "http://arxiv.org/abs/2109.03570v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Dual-Channel Framework for Sarcasm Recognition by Detecting Sentiment\n  Conflict", "abstract": "Sarcasm employs ambivalence, where one says something positive but actually\nmeans negative, and vice versa. The essence of sarcasm, which is also a\nsufficient and necessary condition, is the conflict between literal and implied\nsentiments expressed in one sentence. However, it is difficult to recognize\nsuch sentiment conflict because the sentiments are mixed or even implicit. As a\nresult, the recognition of sophisticated and obscure sentiment brings in a\ngreat challenge to sarcasm detection. In this paper, we propose a Dual-Channel\nFramework by modeling both literal and implied sentiments separately. Based on\nthis dual-channel framework, we design the Dual-Channel Network~(DC-Net) to\nrecognize sentiment conflict. Experiments on political debates (i.e. IAC-V1 and\nIAC-V2) and Twitter datasets show that our proposed DC-Net achieves\nstate-of-the-art performance on sarcasm recognition. Our code is released to\nsupport research.", "published": "2021-09-08 12:33:19", "link": "http://arxiv.org/abs/2109.03587v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Formal Query Building with Query Structure Prediction for Complex\n  Question Answering over Knowledge Base", "abstract": "Formal query building is an important part of complex question answering over\nknowledge bases. It aims to build correct executable queries for questions.\nRecent methods try to rank candidate queries generated by a state-transition\nstrategy. However, this candidate generation strategy ignores the structure of\nqueries, resulting in a considerable number of noisy queries. In this paper, we\npropose a new formal query building approach that consists of two stages. In\nthe first stage, we predict the query structure of the question and leverage\nthe structure to constrain the generation of the candidate queries. We propose\na novel graph generation framework to handle the structure prediction task and\ndesign an encoder-decoder model to predict the argument of the predetermined\noperation in each generative step. In the second stage, we follow the previous\nmethods to rank the candidate queries. The experimental results show that our\nformal query building approach outperforms existing methods on complex\nquestions while staying competitive on simple questions.", "published": "2021-09-08 13:02:42", "link": "http://arxiv.org/abs/2109.03614v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discrete and Soft Prompting for Multilingual Models", "abstract": "It has been shown for English that discrete and soft prompting perform\nstrongly in few-shot learning with pretrained language models (PLMs). In this\npaper, we show that discrete and soft prompting perform better than finetuning\nin multilingual cases: Crosslingual transfer and in-language training of\nmultilingual natural language inference. For example, with 48 English training\nexamples, finetuning obtains 33.74% accuracy in crosslingual transfer, barely\nsurpassing the majority baseline (33.33%). In contrast, discrete and soft\nprompting outperform finetuning, achieving 36.43% and 38.79%. We also\ndemonstrate good performance of prompting with training data in multiple\nlanguages other than English.", "published": "2021-09-08 13:22:59", "link": "http://arxiv.org/abs/2109.03630v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking Data Augmentation for Low-Resource Neural Machine\n  Translation: A Multi-Task Learning Approach", "abstract": "In the context of neural machine translation, data augmentation (DA)\ntechniques may be used for generating additional training samples when the\navailable parallel data are scarce. Many DA approaches aim at expanding the\nsupport of the empirical data distribution by generating new sentence pairs\nthat contain infrequent words, thus making it closer to the true data\ndistribution of parallel sentences. In this paper, we propose to follow a\ncompletely different approach and present a multi-task DA approach in which we\ngenerate new sentence pairs with transformations, such as reversing the order\nof the target sentence, which produce unfluent target sentences. During\ntraining, these augmented sentences are used as auxiliary tasks in a multi-task\nframework with the aim of providing new contexts where the target prefix is not\ninformative enough to predict the next word. This strengthens the encoder and\nforces the decoder to pay more attention to the source representations of the\nencoder. Experiments carried out on six low-resource translation tasks show\nconsistent improvements over the baseline and over DA methods aiming at\nextending the support of the empirical data distribution. The systems trained\nwith our approach rely more on the source tokens, are more robust against\ndomain shift and suffer less hallucinations.", "published": "2021-09-08 13:39:30", "link": "http://arxiv.org/abs/2109.03645v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sustainable Modular Debiasing of Language Models", "abstract": "Unfair stereotypical biases (e.g., gender, racial, or religious biases)\nencoded in modern pretrained language models (PLMs) have negative ethical\nimplications for widespread adoption of state-of-the-art language technology.\nTo remedy for this, a wide range of debiasing techniques have recently been\nintroduced to remove such stereotypical biases from PLMs. Existing debiasing\nmethods, however, directly modify all of the PLMs parameters, which -- besides\nbeing computationally expensive -- comes with the inherent risk of\n(catastrophic) forgetting of useful language knowledge acquired in pretraining.\nIn this work, we propose a more sustainable modular debiasing approach based on\ndedicated debiasing adapters, dubbed ADELE. Concretely, we (1) inject adapter\nmodules into the original PLM layers and (2) update only the adapters (i.e., we\nkeep the original PLM parameters frozen) via language modeling training on a\ncounterfactually augmented corpus. We showcase ADELE, in gender debiasing of\nBERT: our extensive evaluation, encompassing three intrinsic and two extrinsic\nbias measures, renders ADELE, very effective in bias mitigation. We further\nshow that -- due to its modular nature -- ADELE, coupled with task adapters,\nretains fairness even after large-scale downstream training. Finally, by means\nof multilingual BERT, we successfully transfer ADELE, to six target languages.", "published": "2021-09-08 13:42:34", "link": "http://arxiv.org/abs/2109.03646v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Label Verbalization and Entailment for Effective Zero- and Few-Shot\n  Relation Extraction", "abstract": "Relation extraction systems require large amounts of labeled examples which\nare costly to annotate. In this work we reformulate relation extraction as an\nentailment task, with simple, hand-made, verbalizations of relations produced\nin less than 15 min per relation. The system relies on a pretrained textual\nentailment engine which is run as-is (no training examples, zero-shot) or\nfurther fine-tuned on labeled examples (few-shot or fully trained). In our\nexperiments on TACRED we attain 63% F1 zero-shot, 69% with 16 examples per\nrelation (17% points better than the best supervised system on the same\nconditions), and only 4 points short to the state-of-the-art (which uses 20\ntimes more training data). We also show that the performance can be improved\nsignificantly with larger entailment models, up to 12 points in zero-shot,\nallowing to report the best results to date on TACRED when fully trained. The\nanalysis shows that our few-shot systems are specially effective when\ndiscriminating between relations, and that the performance difference in low\ndata regimes comes mainly from identifying no-relation cases.", "published": "2021-09-08 14:04:50", "link": "http://arxiv.org/abs/2109.03659v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Policy Compliance Detection via Question Answering", "abstract": "Policy compliance detection is the task of ensuring that a scenario conforms\nto a policy (e.g. a claim is valid according to government rules or a post in\nan online platform conforms to community guidelines). This task has been\npreviously instantiated as a form of textual entailment, which results in poor\naccuracy due to the complexity of the policies. In this paper we propose to\naddress policy compliance detection via decomposing it into question answering,\nwhere questions check whether the conditions stated in the policy apply to the\nscenario, and an expression tree combines the answers to obtain the label.\nDespite the initial upfront annotation cost, we demonstrate that this approach\nresults in better accuracy, especially in the cross-policy setup where the\npolicies during testing are unseen in training. In addition, it allows us to\nuse existing question answering models pre-trained on existing large datasets.\nFinally, it explicitly identifies the information missing from a scenario in\ncase policy compliance cannot be determined. We conduct our experiments using a\nrecent dataset consisting of government policies, which we augment with expert\nannotations and find that the cost of annotating question answering\ndecomposition is largely offset by improved inter-annotator agreement and\nspeed.", "published": "2021-09-08 15:47:41", "link": "http://arxiv.org/abs/2109.03731v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self- and Pseudo-self-supervised Prediction of Speaker and Key-utterance\n  for Multi-party Dialogue Reading Comprehension", "abstract": "Multi-party dialogue machine reading comprehension (MRC) brings tremendous\nchallenge since it involves multiple speakers at one dialogue, resulting in\nintricate speaker information flows and noisy dialogue contexts. To alleviate\nsuch difficulties, previous models focus on how to incorporate these\ninformation using complex graph-based modules and additional manually labeled\ndata, which is usually rare in real scenarios. In this paper, we design two\nlabour-free self- and pseudo-self-supervised prediction tasks on speaker and\nkey-utterance to implicitly model the speaker information flows, and capture\nsalient clues in a long dialogue. Experimental results on two benchmark\ndatasets have justified the effectiveness of our method over competitive\nbaselines and current state-of-the-art models.", "published": "2021-09-08 16:51:41", "link": "http://arxiv.org/abs/2109.03772v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Smelting Gold and Silver for Improved Multilingual AMR-to-Text\n  Generation", "abstract": "Recent work on multilingual AMR-to-text generation has exclusively focused on\ndata augmentation strategies that utilize silver AMR. However, this assumes a\nhigh quality of generated AMRs, potentially limiting the transferability to the\ntarget task. In this paper, we investigate different techniques for\nautomatically generating AMR annotations, where we aim to study which source of\ninformation yields better multilingual results. Our models trained on gold AMR\nwith silver (machine translated) sentences outperform approaches which leverage\ngenerated silver AMR. We find that combining both complementary sources of\ninformation further improves multilingual AMR-to-text generation. Our models\nsurpass the previous state of the art for German, Italian, Spanish, and Chinese\nby a large margin.", "published": "2021-09-08 17:55:46", "link": "http://arxiv.org/abs/2109.03808v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Collecting a Large-Scale Gender Bias Dataset for Coreference Resolution\n  and Machine Translation", "abstract": "Recent works have found evidence of gender bias in models of machine\ntranslation and coreference resolution using mostly synthetic diagnostic\ndatasets. While these quantify bias in a controlled experiment, they often do\nso on a small scale and consist mostly of artificial, out-of-distribution\nsentences. In this work, we find grammatical patterns indicating stereotypical\nand non-stereotypical gender-role assignments (e.g., female nurses versus male\ndancers) in corpora from three domains, resulting in a first large-scale gender\nbias dataset of 108K diverse real-world English sentences. We manually verify\nthe quality of our corpus and use it to evaluate gender bias in various\ncoreference resolution and machine translation models. We find that all tested\nmodels tend to over-rely on gender stereotypes when presented with natural\ninputs, which may be especially harmful when deployed in commercial systems.\nFinally, we show that our dataset lends itself to finetuning a coreference\nresolution model, finding it mitigates bias on a held out set. Our dataset and\nmodels are publicly available at www.github.com/SLAB-NLP/BUG. We hope they will\nspur future research into gender bias evaluation mitigation techniques in\nrealistic settings.", "published": "2021-09-08 18:14:11", "link": "http://arxiv.org/abs/2109.03858v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sparsity and Sentence Structure in Encoder-Decoder Attention of\n  Summarization Systems", "abstract": "Transformer models have achieved state-of-the-art results in a wide range of\nNLP tasks including summarization. Training and inference using large\ntransformer models can be computationally expensive. Previous work has focused\non one important bottleneck, the quadratic self-attention mechanism in the\nencoder. Modified encoder architectures such as LED or LoBART use local\nattention patterns to address this problem for summarization. In contrast, this\nwork focuses on the transformer's encoder-decoder attention mechanism. The cost\nof this attention becomes more significant in inference or training approaches\nthat require model-generated histories. First, we examine the complexity of the\nencoder-decoder attention. We demonstrate empirically that there is a sparse\nsentence structure in document summarization that can be exploited by\nconstraining the attention mechanism to a subset of input sentences, whilst\nmaintaining system performance. Second, we propose a modified architecture that\nselects the subset of sentences to constrain the encoder-decoder attention.\nExperiments are carried out on abstractive summarization tasks, including\nCNN/DailyMail, XSum, Spotify Podcast, and arXiv.", "published": "2021-09-08 19:32:42", "link": "http://arxiv.org/abs/2109.03888v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ELIT: Emory Language and Information Toolkit", "abstract": "We introduce ELIT, the Emory Language and Information Toolkit, which is a\ncomprehensive NLP framework providing transformer-based end-to-end models for\ncore tasks with a special focus on memory efficiency while maintaining\nstate-of-the-art accuracy and speed. Compared to existing toolkits, ELIT\nfeatures an efficient Multi-Task Learning (MTL) model with many downstream\ntasks that include lemmatization, part-of-speech tagging, named entity\nrecognition, dependency parsing, constituency parsing, semantic role labeling,\nand AMR parsing. The backbone of ELIT's MTL framework is a pre-trained\ntransformer encoder that is shared across tasks to speed up their inference.\nELIT provides pre-trained models developed on a remix of eight datasets. To\nscale up its service, ELIT also integrates a RESTful Client/Server combination.\nOn the server side, ELIT extends its functionality to cover other tasks such as\ntokenization and coreference resolution, providing an end user with agile\nresearch experience. All resources including the source codes, documentation,\nand pre-trained models are publicly available at\nhttps://github.com/emorynlp/elit.", "published": "2021-09-08 19:50:07", "link": "http://arxiv.org/abs/2109.03903v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Recipe For Arbitrary Text Style Transfer with Large Language Models", "abstract": "In this paper, we leverage large language models (LMs) to perform zero-shot\ntext style transfer. We present a prompting method that we call augmented\nzero-shot learning, which frames style transfer as a sentence rewriting task\nand requires only a natural language instruction, without model fine-tuning or\nexemplars in the target style. Augmented zero-shot learning is simple and\ndemonstrates promising results not just on standard style transfer tasks such\nas sentiment, but also on arbitrary transformations such as \"make this\nmelodramatic\" or \"insert a metaphor.\"", "published": "2021-09-08 20:08:38", "link": "http://arxiv.org/abs/2109.03910v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ensemble Fine-tuned mBERT for Translation Quality Estimation", "abstract": "Quality Estimation (QE) is an important component of the machine translation\nworkflow as it assesses the quality of the translated output without consulting\nreference translations. In this paper, we discuss our submission to the WMT\n2021 QE Shared Task. We participate in Task 2 sentence-level sub-task that\nchallenge participants to predict the HTER score for sentence-level\npost-editing effort. Our proposed system is an ensemble of multilingual BERT\n(mBERT)-based regression models, which are generated by fine-tuning on\ndifferent input settings. It demonstrates comparable performance with respect\nto the Pearson's correlation and beats the baseline system in MAE/ RMSE for\nseveral language pairs. In addition, we adapt our system for the zero-shot\nsetting by exploiting target language-relevant language pairs and\npseudo-reference translations.", "published": "2021-09-08 20:13:06", "link": "http://arxiv.org/abs/2109.03914v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformers in the loop: Polarity in neural models of language", "abstract": "Representation of linguistic phenomena in computational language models is\ntypically assessed against the predictions of existing linguistic theories of\nthese phenomena. Using the notion of polarity as a case study, we show that\nthis is not always the most adequate set-up. We probe polarity via so-called\n'negative polarity items' (in particular, English 'any') in two pre-trained\nTransformer-based models (BERT and GPT-2). We show that - at least for polarity\n- metrics derived from language models are more consistent with data from\npsycholinguistic experiments than linguistic theory predictions. Establishing\nthis allows us to more adequately evaluate the performance of language models\nand also to use language models to discover new insights into natural language\ngrammar beyond existing linguistic theories. This work contributes to\nestablishing closer ties between psycholinguistic experiments and experiments\nwith language models.", "published": "2021-09-08 20:56:32", "link": "http://arxiv.org/abs/2109.03926v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Formal Description of Sorani Kurdish Morphology", "abstract": "Sorani Kurdish, also known as Central Kurdish, has a complex morphology,\nparticularly due to the patterns in which morphemes appear. Although several\naspects of Kurdish morphology have been studied, such as pronominal endoclitics\nand Izafa constructions, Sorani Kurdish morphology has received trivial\nattention in computational linguistics. Moreover, some morphemes, such as the\nemphasis endoclitic =\\^i\\c{s}, and derivational morphemes have not been\npreviously studied. To tackle the complex morphology of Sorani, we provide a\nthorough description of Sorani Kurdish morphological and morphophonological\nconstructions in a formal way such that they can be used as finite-state\ntransducers for morphological analysis and synthesis.", "published": "2021-09-08 21:34:26", "link": "http://arxiv.org/abs/2109.03942v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Text Mining of COVID-19 Records", "abstract": "Since the beginning of coronavirus, the disease has spread worldwide and\ndrastically changed many aspects of the human's lifestyle. Twitter as a\npowerful tool can help researchers measure public health in response to\nCOVID-19. According to the high volume of data production on social networks,\nautomated text mining approaches can help search, read and summarize helpful\ninformation. This paper preprocessed the existing medical dataset regarding\nCOVID-19 named CORD-19 and annotated the dataset for supervised classification\ntasks. At this time of the COVID-19 pandemic, we made a preprocessed dataset\nfor the research community. This may contribute towards finding new solutions\nfor some social interventions that COVID-19 has made. The preprocessed version\nof the mentioned dataset is publicly available through Github.", "published": "2021-09-08 05:57:22", "link": "http://arxiv.org/abs/2110.07357v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DeepZensols: Deep Natural Language Processing Framework", "abstract": "Reproducing results in publications by distributing publicly available source\ncode is becoming ever more popular. Given the difficulty of reproducing machine\nlearning (ML) experiments, there have been significant efforts in reducing the\nvariance of these results. As in any science, the ability to consistently\nreproduce results effectively strengthens the underlying hypothesis of the\nwork, and thus, should be regarded as important as the novel aspect of the\nresearch itself. The contribution of this work is a framework that is able to\nreproduce consistent results and provides a means of easily creating, training,\nand evaluating natural language processing (NLP) deep learning (DL) models.", "published": "2021-09-08 01:16:05", "link": "http://arxiv.org/abs/2109.03383v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "It is AI's Turn to Ask Humans a Question: Question-Answer Pair\n  Generation for Children's Story Books", "abstract": "Existing question answering (QA) techniques are created mainly to answer\nquestions asked by humans. But in educational applications, teachers often need\nto decide what questions they should ask, in order to help students to improve\ntheir narrative understanding capabilities. We design an automated\nquestion-answer generation (QAG) system for this education scenario: given a\nstory book at the kindergarten to eighth-grade level as input, our system can\nautomatically generate QA pairs that are capable of testing a variety of\ndimensions of a student's comprehension skills. Our proposed QAG model\narchitecture is demonstrated using a new expert-annotated FairytaleQA dataset,\nwhich has 278 child-friendly storybooks with 10,580 QA pairs. Automatic and\nhuman evaluations show that our model outperforms state-of-the-art QAG baseline\nsystems. On top of our QAG system, we also start to build an interactive\nstory-telling application for the future real-world deployment in this\neducational scenario.", "published": "2021-09-08 04:11:54", "link": "http://arxiv.org/abs/2109.03423v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ArchivalQA: A Large-scale Benchmark Dataset for Open Domain Question\n  Answering over Historical News Collections", "abstract": "In the last few years, open-domain question answering (ODQA) has advanced\nrapidly due to the development of deep learning techniques and the availability\nof large-scale QA datasets. However, the current datasets are essentially\ndesigned for synchronic document collections (e.g., Wikipedia). Temporal news\ncollections such as long-term news archives spanning several decades, are\nrarely used in training the models despite they are quite valuable for our\nsociety. To foster the research in the field of ODQA on such historical\ncollections, we present ArchivalQA, a large question answering dataset\nconsisting of 532,444 question-answer pairs which is designed for temporal news\nQA. We divide our dataset into four subparts based on the question difficulty\nlevels and the containment of temporal expressions, which we believe are useful\nfor training and testing ODQA systems characterized by different strengths and\nabilities. The novel QA dataset-constructing framework that we introduce can be\nalso applied to generate non-ambiguous questions of good quality over other\ntypes of temporal document collections.", "published": "2021-09-08 05:21:51", "link": "http://arxiv.org/abs/2109.03438v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Social Analysis of Young Basque Speaking Communities in Twitter", "abstract": "In this paper we take into account both social and linguistic aspects to\nperform demographic analysis by processing a large amount of tweets in Basque\nlanguage. The study of demographic characteristics and social relationships are\napproached by applying machine learning and modern deep-learning Natural\nLanguage Processing (NLP) techniques, combining social sciences with automatic\ntext processing. More specifically, our main objective is to combine\ndemographic inference and social analysis in order to detect young Basque\nTwitter users and to identify the communities that arise from their\nrelationships or shared content. This social and demographic analysis will be\nentirely based on the~automatically collected tweets using NLP to convert\nunstructured textual information into interpretable knowledge.", "published": "2021-09-08 08:19:08", "link": "http://arxiv.org/abs/2109.03487v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Cross-linguistic differences in gender congruency effects: Evidence from\n  meta-analyses", "abstract": "It has been proposed that the order in which words are prepared for\nproduction depends on the speaker's language. When producing the translation\nequivalent of the small cat, speakers of German or Dutch select the\ngender-marked determiner at a relatively early stage of production. Speakers of\nFrench or Italian postpone the encoding of a determiner or adjective until the\nphonological form of the noun is available. Hence, even though the words are\nproduced in the same order (e.g., die kleine Katze in German, le petit chat in\nFrench), they are not planned in the same order and might require different\namounts of advanced planning prior to production onset. This distinction\nbetween early and late selection languages was proposed to account for the\nobservation that speakers of Germanic and Slavic languages, but not of Romance\nlanguages, are slower to name pictures in the context of a distractor word of a\ndifferent gender. Meta-analyses are conducted to provide the first direct test\nof this cross-linguistic difference and to test a prediction of the late\nselection hypothesis. They confirm the existence of the gender congruency\neffect in German/Slavic languages and its absence in Romance languages when\ntarget and distractor words are presented simultaneously. They do not allow\nconfirming the hypothesis that in the latter languages, a similar effect\nemerges when the presentation of the distractor is delayed. Overall, these\nanalyses confirm the cross-linguistic difference but show that the evidence\navailable to date is not sufficient to confirm or reject the late selection\nhypothesis as an explanation of this difference. We highlight specific\ndirections for future research.", "published": "2021-09-08 08:27:47", "link": "http://arxiv.org/abs/2109.03490v4", "categories": ["cs.CL", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "NSP-BERT: A Prompt-based Few-Shot Learner Through an Original\n  Pre-training Task--Next Sentence Prediction", "abstract": "Using prompts to utilize language models to perform various downstream tasks,\nalso known as prompt-based learning or prompt-learning, has lately gained\nsignificant success in comparison to the pre-train and fine-tune paradigm.\nNonetheless, virtually all prompt-based methods are token-level, meaning they\nall utilize GPT's left-to-right language model or BERT's masked language model\nto perform cloze-style tasks. In this paper, we attempt to accomplish several\nNLP tasks in the zero-shot scenario using a BERT original pre-training task\nabandoned by RoBERTa and other models--Next Sentence Prediction (NSP). Unlike\ntoken-level techniques, our sentence-level prompt-based method NSP-BERT does\nnot need to fix the length of the prompt or the position to be predicted,\nallowing it to handle tasks such as entity linking with ease. Based on the\ncharacteristics of NSP-BERT, we offer several quick building templates for\nvarious downstream tasks. We suggest a two-stage prompt method for word sense\ndisambiguation tasks in particular. Our strategies for mapping the labels\nsignificantly enhance the model's performance on sentence pair tasks. On the\nFewCLUE benchmark, our NSP-BERT outperforms other zero-shot methods on most of\nthese tasks and comes close to the few-shot methods.", "published": "2021-09-08 11:57:08", "link": "http://arxiv.org/abs/2109.03564v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Open Aspect Target Sentiment Classification with Natural Language\n  Prompts", "abstract": "For many business applications, we often seek to analyze sentiments\nassociated with any arbitrary aspects of commercial products, despite having a\nvery limited amount of labels or even without any labels at all. However,\nexisting aspect target sentiment classification (ATSC) models are not trainable\nif annotated datasets are not available. Even with labeled data, they fall\nshort of reaching satisfactory performance. To address this, we propose simple\napproaches that better solve ATSC with natural language prompts, enabling the\ntask under zero-shot cases and enhancing supervised settings, especially for\nfew-shot cases. Under the few-shot setting for SemEval 2014 Task 4 laptop\ndomain, our method of reformulating ATSC as an NLI task outperforms supervised\nSOTA approaches by up to 24.13 accuracy points and 33.14 macro F1 points.\nMoreover, we demonstrate that our prompts could handle implicitly stated\naspects as well: our models reach about 77% accuracy on detecting sentiments\nfor aspect categories (e.g., food), which do not necessarily appear within the\ntext, even though we trained the models only with explicitly mentioned aspect\nterms (e.g., fajitas) from just 16 reviews - while the accuracy of the\nno-prompt baseline is only around 65%.", "published": "2021-09-08 14:38:52", "link": "http://arxiv.org/abs/2109.03685v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Continuous Entailment Patterns for Lexical Inference in Context", "abstract": "Combining a pretrained language model (PLM) with textual patterns has been\nshown to help in both zero- and few-shot settings. For zero-shot performance,\nit makes sense to design patterns that closely resemble the text seen during\nself-supervised pretraining because the model has never seen anything else.\nSupervised training allows for more flexibility. If we allow for tokens outside\nthe PLM's vocabulary, patterns can be adapted more flexibly to a PLM's\nidiosyncrasies. Contrasting patterns where a \"token\" can be any continuous\nvector vs. those where a discrete choice between vocabulary elements has to be\nmade, we call our method CONtinuous pAtterNs (CONAN). We evaluate CONAN on two\nestablished benchmarks for lexical inference in context (LIiC) a.k.a. predicate\nentailment, a challenging natural language understanding task with relatively\nsmall training sets. In a direct comparison with discrete patterns, CONAN\nconsistently leads to improved performance, setting a new state of the art. Our\nexperiments give valuable insights into the kind of pattern that enhances a\nPLM's performance on LIiC and raise important questions regarding our\nunderstanding of PLMs using text patterns.", "published": "2021-09-08 14:57:00", "link": "http://arxiv.org/abs/2109.03695v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Memory and Knowledge Augmented Language Models for Inferring Salience in\n  Long-Form Stories", "abstract": "Measuring event salience is essential in the understanding of stories. This\npaper takes a recent unsupervised method for salience detection derived from\nBarthes Cardinal Functions and theories of surprise and applies it to longer\nnarrative forms. We improve the standard transformer language model by\nincorporating an external knowledgebase (derived from Retrieval Augmented\nGeneration) and adding a memory mechanism to enhance performance on longer\nworks. We use a novel approach to derive salience annotation using\nchapter-aligned summaries from the Shmoop corpus for classic literary works.\nOur evaluation against this data demonstrates that our salience detection model\nimproves performance over and above a non-knowledgebase and memory augmented\nlanguage model, both of which are crucial to this improvement.", "published": "2021-09-08 16:15:50", "link": "http://arxiv.org/abs/2109.03754v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "What's Hidden in a One-layer Randomly Weighted Transformer?", "abstract": "We demonstrate that, hidden within one-layer randomly weighted neural\nnetworks, there exist subnetworks that can achieve impressive performance,\nwithout ever modifying the weight initializations, on machine translation\ntasks. To find subnetworks for one-layer randomly weighted neural networks, we\napply different binary masks to the same weight matrix to generate different\nlayers. Hidden within a one-layer randomly weighted Transformer, we find that\nsubnetworks that can achieve 29.45/17.29 BLEU on IWSLT14/WMT14. Using a fixed\npre-trained embedding layer, the previously found subnetworks are smaller than,\nbut can match 98%/92% (34.14/25.24 BLEU) of the performance of, a trained\nTransformer small/base on IWSLT14/WMT14. Furthermore, we demonstrate the\neffectiveness of larger and deeper transformers in this setting, as well as the\nimpact of different initialization methods. We released the source code at\nhttps://github.com/sIncerass/one_layer_lottery_ticket.", "published": "2021-09-08 21:22:52", "link": "http://arxiv.org/abs/2109.03939v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Referee: Towards reference-free cross-speaker style transfer with\n  low-quality data for expressive speech synthesis", "abstract": "Cross-speaker style transfer (CSST) in text-to-speech (TTS) synthesis aims at\ntransferring a speaking style to the synthesised speech in a target speaker's\nvoice. Most previous CSST approaches rely on expensive high-quality data\ncarrying desired speaking style during training and require a reference\nutterance to obtain speaking style descriptors as conditioning on the\ngeneration of a new sentence. This work presents Referee, a robust\nreference-free CSST approach for expressive TTS, which fully leverages\nlow-quality data to learn speaking styles from text. Referee is built by\ncascading a text-to-style (T2S) model with a style-to-wave (S2W) model.\nPhonetic PosteriorGram (PPG), phoneme-level pitch and energy contours are\nadopted as fine-grained speaking style descriptors, which are predicted from\ntext using the T2S model. A novel pretrain-refinement method is adopted to\nlearn a robust T2S model by only using readily accessible low-quality data. The\nS2W model is trained with high-quality target data, which is adopted to\neffectively aggregate style descriptors and generate high-fidelity speech in\nthe target speaker's voice. Experimental results are presented, showing that\nReferee outperforms a global-style-token (GST)-based baseline approach in CSST.", "published": "2021-09-08 05:39:34", "link": "http://arxiv.org/abs/2109.03439v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "R2-D2: A Modular Baseline for Open-Domain Question Answering", "abstract": "This work presents a novel four-stage open-domain QA pipeline R2-D2 (Rank\ntwice, reaD twice). The pipeline is composed of a retriever, passage reranker,\nextractive reader, generative reader and a mechanism that aggregates the final\nprediction from all system's components. We demonstrate its strength across\nthree open-domain QA datasets: NaturalQuestions, TriviaQA and EfficientQA,\nsurpassing state-of-the-art on the first two. Our analysis demonstrates that:\n(i) combining extractive and generative reader yields absolute improvements up\nto 5 exact match and it is at least twice as effective as the posterior\naveraging ensemble of the same models with different parameters, (ii) the\nextractive reader with fewer parameters can match the performance of the\ngenerative reader on extractive QA datasets.", "published": "2021-09-08 08:51:27", "link": "http://arxiv.org/abs/2109.03502v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Time Alignment using Lip Images for Frame-based Electrolaryngeal Voice\n  Conversion", "abstract": "Voice conversion (VC) is an effective approach to electrolaryngeal (EL)\nspeech enhancement, a task that aims to improve the quality of the artificial\nvoice from an electrolarynx device. In frame-based VC methods, time alignment\nneeds to be performed prior to model training, and the dynamic time warping\n(DTW) algorithm is widely adopted to compute the best time alignment between\neach utterance pair. The validity is based on the assumption that the same\nphonemes of the speakers have similar features and can be mapped by measuring a\npre-defined distance between speech frames of the source and the target.\nHowever, the special characteristics of the EL speech can break the assumption,\nresulting in a sub-optimal DTW alignment. In this work, we propose to use lip\nimages for time alignment, as we assume that the lip movements of laryngectomee\nremain normal compared to healthy people. We investigate two naive lip\nrepresentations and distance metrics, and experimental results demonstrate that\nthe proposed method can significantly outperform the audio-only alignment in\nterms of objective and subjective evaluations.", "published": "2021-09-08 11:24:09", "link": "http://arxiv.org/abs/2109.03551v1", "categories": ["cs.SD", "cs.CL", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "TrollsWithOpinion: A Dataset for Predicting Domain-specific Opinion\n  Manipulation in Troll Memes", "abstract": "Research into the classification of Image with Text (IWT) troll memes has\nrecently become popular. Since the online community utilizes the refuge of\nmemes to express themselves, there is an abundance of data in the form of\nmemes. These memes have the potential to demean, harras, or bully targeted\nindividuals. Moreover, the targeted individual could fall prey to opinion\nmanipulation. To comprehend the use of memes in opinion manipulation, we define\nthree specific domains (product, political or others) which we classify into\ntroll or not-troll, with or without opinion manipulation. To enable this\nanalysis, we enhanced an existing dataset by annotating the data with our\ndefined classes, resulting in a dataset of 8,881 IWT or multimodal memes in the\nEnglish language (TrollsWithOpinion dataset). We perform baseline experiments\non the annotated dataset, and our result shows that existing state-of-the-art\ntechniques could only reach a weighted-average F1-score of 0.37. This shows the\nneed for a development of a specific technique to deal with multimodal troll\nmemes.", "published": "2021-09-08 12:12:13", "link": "http://arxiv.org/abs/2109.03571v2", "categories": ["cs.SI", "cs.CL", "cs.MM"], "primary_category": "cs.SI"}
{"title": "Active Learning by Acquiring Contrastive Examples", "abstract": "Common acquisition functions for active learning use either uncertainty or\ndiversity sampling, aiming to select difficult and diverse data points from the\npool of unlabeled data, respectively. In this work, leveraging the best of both\nworlds, we propose an acquisition function that opts for selecting\n\\textit{contrastive examples}, i.e. data points that are similar in the model\nfeature space and yet the model outputs maximally different predictive\nlikelihoods. We compare our approach, CAL (Contrastive Active Learning), with a\ndiverse set of acquisition functions in four natural language understanding\ntasks and seven datasets. Our experiments show that CAL performs consistently\nbetter or equal than the best performing baseline across all tasks, on both\nin-domain and out-of-domain data. We also conduct an extensive ablation study\nof our method and we further analyze all actively acquired datasets showing\nthat CAL achieves a better trade-off between uncertainty and diversity compared\nto other strategies.", "published": "2021-09-08 16:40:18", "link": "http://arxiv.org/abs/2109.03764v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning\n  the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP", "abstract": "Graph neural networks have triggered a resurgence of graph-based text\nclassification methods, defining today's state of the art. We show that a wide\nmulti-layer perceptron (MLP) using a Bag-of-Words (BoW) outperforms the recent\ngraph-based models TextGCN and HeteGCN in an inductive text classification\nsetting and is comparable with HyperGAT. Moreover, we fine-tune a\nsequence-based BERT and a lightweight DistilBERT model, which both outperform\nall state-of-the-art models. These results question the importance of synthetic\ngraphs used in modern text classifiers. In terms of efficiency, DistilBERT is\nstill twice as large as our BoW-based wide MLP, while graph-based models like\nTextGCN require setting up an $\\mathcal{O}(N^2)$ graph, where $N$ is the\nvocabulary plus corpus size. Finally, since Transformers need to compute\n$\\mathcal{O}(L^2)$ attention weights with sequence length $L$, the MLP models\nshow higher training and inference speeds on datasets with long sequences.", "published": "2021-09-08 16:54:28", "link": "http://arxiv.org/abs/2109.03777v3", "categories": ["cs.CL", "cs.IR", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Highly Parallel Autoregressive Entity Linking with Discriminative\n  Correction", "abstract": "Generative approaches have been recently shown to be effective for both\nEntity Disambiguation and Entity Linking (i.e., joint mention detection and\ndisambiguation). However, the previously proposed autoregressive formulation\nfor EL suffers from i) high computational cost due to a complex (deep) decoder,\nii) non-parallelizable decoding that scales with the source sequence length,\nand iii) the need for training on a large amount of data. In this work, we\npropose a very efficient approach that parallelizes autoregressive linking\nacross all potential mentions and relies on a shallow and efficient decoder.\nMoreover, we augment the generative objective with an extra discriminative\ncomponent, i.e., a correction term which lets us directly optimize the\ngenerator's ranking. When taken together, these techniques tackle all the above\nissues: our model is >70 times faster and more accurate than the previous\ngenerative method, outperforming state-of-the-art approaches on the standard\nEnglish dataset AIDA-CoNLL. Source code available at\nhttps://github.com/nicola-decao/efficient-autoregressive-EL", "published": "2021-09-08 17:28:26", "link": "http://arxiv.org/abs/2109.03792v1", "categories": ["cs.CL", "cs.AI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Knowledge mining of unstructured information: application to\n  cyber-domain", "abstract": "Information on cyber-related crimes, incidents, and conflicts is abundantly\navailable in numerous open online sources. However, processing the large\nvolumes and streams of data is a challenging task for the analysts and experts,\nand entails the need for newer methods and techniques. In this article we\npresent and implement a novel knowledge graph and knowledge mining framework\nfor extracting the relevant information from free-form text about incidents in\nthe cyberdomain. The framework includes a machine learning based pipeline for\ngenerating graphs of organizations, countries, industries, products and\nattackers with a non-technical cyber-ontology. The extracted knowledge graph is\nutilized to estimate the incidence of cyberattacks on a given graph\nconfiguration. We use publicly available collections of real cyber-incident\nreports to test the efficacy of our methods. The knowledge extraction is found\nto be sufficiently accurate, and the graph-based threat estimation demonstrates\na level of correlation with the actual records of attacks. In practical use, an\nanalyst utilizing the presented framework can infer additional information from\nthe current cyber-landscape in terms of risk to various entities and\npropagation of the risk heuristic between industries and countries.", "published": "2021-09-08 18:01:56", "link": "http://arxiv.org/abs/2109.03848v3", "categories": ["cs.CR", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "A Bayesian Framework for Information-Theoretic Probing", "abstract": "Pimentel et al. (2020) recently analysed probing from an\ninformation-theoretic perspective. They argue that probing should be seen as\napproximating a mutual information. This led to the rather unintuitive\nconclusion that representations encode exactly the same information about a\ntarget task as the original sentences. The mutual information, however, assumes\nthe true probability distribution of a pair of random variables is known,\nleading to unintuitive results in settings where it is not. This paper proposes\na new framework to measure what we term Bayesian mutual information, which\nanalyses information from the perspective of Bayesian agents -- allowing for\nmore intuitive findings in scenarios with finite data. For instance, under\nBayesian MI we have that data can add information, processing can help, and\ninformation can hurt, which makes it more intuitive for machine learning\napplications. Finally, we apply our framework to probing where we believe\nBayesian mutual information naturally operationalises ease of extraction by\nexplicitly limiting the available background knowledge to solve a task.", "published": "2021-09-08 18:08:36", "link": "http://arxiv.org/abs/2109.03853v1", "categories": ["cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "Retrieve, Caption, Generate: Visual Grounding for Enhancing Commonsense\n  in Text Generation Models", "abstract": "We investigate the use of multimodal information contained in images as an\neffective method for enhancing the commonsense of Transformer models for text\ngeneration. We perform experiments using BART and T5 on concept-to-text\ngeneration, specifically the task of generative commonsense reasoning, or\nCommonGen. We call our approach VisCTG: Visually Grounded Concept-to-Text\nGeneration. VisCTG involves captioning images representing appropriate everyday\nscenarios, and using these captions to enrich and steer the generation process.\nComprehensive evaluation and analysis demonstrate that VisCTG noticeably\nimproves model performance while successfully addressing several issues of the\nbaseline generations, including poor commonsense, fluency, and specificity.", "published": "2021-09-08 19:38:11", "link": "http://arxiv.org/abs/2109.03892v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised Pre-training with Structured Knowledge for Improving\n  Natural Language Inference", "abstract": "While recent research on natural language inference has considerably\nbenefited from large annotated datasets, the amount of inference-related\nknowledge (including commonsense) provided in the annotated data is still\nrather limited. There have been two lines of approaches that can be used to\nfurther address the limitation: (1) unsupervised pretraining can leverage\nknowledge in much larger unstructured text data; (2) structured (often\nhuman-curated) knowledge has started to be considered in neural-network-based\nmodels for NLI. An immediate question is whether these two approaches\ncomplement each other, or how to develop models that can bring together their\nadvantages. In this paper, we propose models that leverage structured knowledge\nin different components of pre-trained models. Our results show that the\nproposed models perform better than previous BERT-based state-of-the-art\nmodels. Although our models are proposed for NLI, they can be easily extended\nto other sentence or sentence-pair classification problems.", "published": "2021-09-08 21:28:12", "link": "http://arxiv.org/abs/2109.03941v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods", "abstract": "We propose a benchmark to measure whether a language model is truthful in\ngenerating answers to questions. The benchmark comprises 817 questions that\nspan 38 categories, including health, law, finance and politics. We crafted\nquestions that some humans would answer falsely due to a false belief or\nmisconception. To perform well, models must avoid generating false answers\nlearned from imitating human texts. We tested GPT-3, GPT-Neo/J, GPT-2 and a\nT5-based model. The best model was truthful on 58% of questions, while human\nperformance was 94%. Models generated many false answers that mimic popular\nmisconceptions and have the potential to deceive humans. The largest models\nwere generally the least truthful. This contrasts with other NLP tasks, where\nperformance improves with model size. However, this result is expected if false\nanswers are learned from the training distribution. We suggest that scaling up\nmodels alone is less promising for improving truthfulness than fine-tuning\nusing training objectives other than imitation of text from the web.", "published": "2021-09-08 17:15:27", "link": "http://arxiv.org/abs/2109.07958v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Self-supervised Contrastive Cross-Modality Representation Learning for\n  Spoken Question Answering", "abstract": "Spoken question answering (SQA) requires fine-grained understanding of both\nspoken documents and questions for the optimal answer prediction. In this\npaper, we propose novel training schemes for spoken question answering with a\nself-supervised training stage and a contrastive representation learning stage.\nIn the self-supervised stage, we propose three auxiliary self-supervised tasks,\nincluding utterance restoration, utterance insertion, and question\ndiscrimination, and jointly train the model to capture consistency and\ncoherence among speech documents without any additional data or annotations. We\nthen propose to learn noise-invariant utterance representations in a\ncontrastive objective by adopting multiple augmentation strategies, including\nspan deletion and span substitution. Besides, we design a Temporal-Alignment\nattention to semantically align the speech-text clues in the learned common\nspace and benefit the SQA tasks. By this means, the training schemes can more\neffectively guide the generation model to predict more proper answers.\nExperimental results show that our model achieves state-of-the-art results on\nthree SQA benchmarks.", "published": "2021-09-08 01:13:14", "link": "http://arxiv.org/abs/2109.03381v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Offensive Language Identification for Low Resource\n  Languages: The Case of Marathi", "abstract": "The widespread presence of offensive language on social media motivated the\ndevelopment of systems capable of recognizing such content automatically. Apart\nfrom a few notable exceptions, most research on automatic offensive language\nidentification has dealt with English. To address this shortcoming, we\nintroduce MOLD, the Marathi Offensive Language Dataset. MOLD is the first\ndataset of its kind compiled for Marathi, thus opening a new domain for\nresearch in low-resource Indo-Aryan languages. We present results from several\nmachine learning experiments on this dataset, including zero-short and other\ntransfer learning experiments on state-of-the-art cross-lingual transformers\nfrom existing data in Bengali, English, and Hindi.", "published": "2021-09-08 11:29:44", "link": "http://arxiv.org/abs/2109.03552v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Beijing ZKJ-NPU Speaker Verification System for VoxCeleb Speaker\n  Recognition Challenge 2021", "abstract": "In this report, we describe the Beijing ZKJ-NPU team submission to the\nVoxCeleb Speaker Recognition Challenge 2021 (VoxSRC-21). We participated in the\nfully supervised speaker verification track 1 and track 2. In the challenge, we\nexplored various kinds of advanced neural network structures with different\npooling layers and objective loss functions. In addition, we introduced the\nResNet-DTCF, CoAtNet and PyConv networks to advance the performance of\nCNN-based speaker embedding model. Moreover, we applied embedding normalization\nand score normalization at the evaluation stage. By fusing 11 and 14 systems,\nour final best performances (minDCF/EER) on the evaluation trails are\n0.1205/2.8160% and 0.1175/2.8400% respectively for track 1 and 2. With our\nsubmission, we came to the second place in the challenge for both tracks.", "published": "2021-09-08 12:04:18", "link": "http://arxiv.org/abs/2109.03568v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Signal-domain representation of symbolic music for learning embedding\n  spaces", "abstract": "A key aspect of machine learning models lies in their ability to learn\nefficient intermediate features. However, the input representation plays a\ncrucial role in this process, and polyphonic musical scores remain a\nparticularly complex type of information. In this paper, we introduce a novel\nrepresentation of symbolic music data, which transforms a polyphonic score into\na continuous signal. We evaluate the ability to learn meaningful features from\nthis representation from a musical point of view. Hence, we introduce an\nevaluation method relying on principled generation of synthetic data. Finally,\nto test our proposed representation we conduct an extensive benchmark against\nrecent polyphonic symbolic representations. We show that our signal-like\nrepresentation leads to better reconstruction and disentangled features. This\nimprovement is reflected in the metric properties and in the generation ability\nof the space learned from our signal-like representation according to music\ntheory properties.", "published": "2021-09-08 06:36:02", "link": "http://arxiv.org/abs/2109.03454v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "A Survey of Sound Source Localization with Deep Learning Methods", "abstract": "This article is a survey on deep learning methods for single and multiple\nsound source localization. We are particularly interested in sound source\nlocalization in indoor/domestic environment, where reverberation and diffuse\nnoise are present. We provide an exhaustive topography of the neural-based\nlocalization literature in this context, organized according to several\naspects: the neural network architecture, the type of input features, the\noutput strategy (classification or regression), the types of data used for\nmodel training and evaluation, and the model training strategy. This way, an\ninterested reader can easily comprehend the vast panorama of the deep\nlearning-based sound source localization methods. Tables summarizing the\nliterature survey are provided at the end of the paper for a quick search of\nmethods with a given set of target characteristics.", "published": "2021-09-08 07:25:39", "link": "http://arxiv.org/abs/2109.03465v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
