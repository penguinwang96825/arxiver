{"title": "Sieve-based Coreference Resolution in the Biomedical Domain", "abstract": "We describe challenges and advantages unique to coreference resolution in the\nbiomedical domain, and a sieve-based architecture that leverages domain\nknowledge for both entity and event coreference resolution. Domain-general\ncoreference resolution algorithms perform poorly on biomedical documents,\nbecause the cues they rely on such as gender are largely absent in this domain,\nand because they do not encode domain-specific knowledge such as the number and\ntype of participants required in chemical reactions. Moreover, it is difficult\nto directly encode this knowledge into most coreference resolution algorithms\nbecause they are not rule-based. Our rule-based architecture uses sequentially\napplied hand-designed \"sieves\", with the output of each sieve informing and\nconstraining subsequent sieves. This architecture provides a 3.2% increase in\nthroughput to our Reach event extraction system with precision parallel to that\nof the stricter system that relies solely on syntactic patterns for extraction.", "published": "2016-03-11 20:48:49", "link": "http://arxiv.org/abs/1603.03758v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Training with Exploration Improves a Greedy Stack-LSTM Parser", "abstract": "We adapt the greedy Stack-LSTM dependency parser of Dyer et al. (2015) to\nsupport a training-with-exploration procedure using dynamic oracles(Goldberg\nand Nivre, 2013) instead of cross-entropy minimization. This form of training,\nwhich accounts for model predictions at training time rather than assuming an\nerror-free action history, improves parsing accuracies for both English and\nChinese, obtaining very strong results for both languages. We discuss some\nmodifications needed in order to get training with exploration to work well for\na probabilistic neural-network.", "published": "2016-03-11 21:34:20", "link": "http://arxiv.org/abs/1603.03793v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A short proof that $O_2$ is an MCFL", "abstract": "We present a new proof that $O_2$ is a multiple context-free language. It\ncontrasts with a recent proof by Salvati (2015) in its avoidance of concepts\nthat seem specific to two-dimensional geometry, such as the complex exponential\nfunction. Our simple proof creates realistic prospects of widening the results\nto higher dimensions. This finding is of central importance to the relation\nbetween extreme free word order and classes of grammars used to describe the\nsyntax of natural language.", "published": "2016-03-11 12:32:29", "link": "http://arxiv.org/abs/1603.03610v1", "categories": ["cs.FL", "cs.CL", "68T50", "I.2.7; F.4.2"], "primary_category": "cs.FL"}
{"title": "Towards using social media to identify individuals at risk for\n  preventable chronic illness", "abstract": "We describe a strategy for the acquisition of training data necessary to\nbuild a social-media-driven early detection system for individuals at risk for\n(preventable) type 2 diabetes mellitus (T2DM). The strategy uses a game-like\nquiz with data and questions acquired semi-automatically from Twitter. The\nquestions are designed to inspire participant engagement and collect relevant\ndata to train a public-health model applied to individuals. Prior systems\ndesigned to use social media such as Twitter to predict obesity (a risk factor\nfor T2DM) operate on entire communities such as states, counties, or cities,\nbased on statistics gathered by government agencies. Because there is\nconsiderable variation among individuals within these groups, training data on\nthe individual level would be more effective, but this data is difficult to\nacquire. The approach proposed here aims to address this issue. Our strategy\nhas two steps. First, we trained a random forest classifier on data gathered\nfrom (public) Twitter statuses and state-level statistics with state-of-the-art\naccuracy. We then converted this classifier into a 20-questions-style quiz and\nmade it available online. In doing so, we achieved high engagement with\nindividuals that took the quiz, while also building a training set of\nvoluntarily supplied individual-level data for future classification.", "published": "2016-03-11 21:09:19", "link": "http://arxiv.org/abs/1603.03784v1", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
