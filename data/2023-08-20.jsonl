{"title": "Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A.\n  Will LLMs Replace Knowledge Graphs?", "abstract": "Since the recent prosperity of Large Language Models (LLMs), there have been\ninterleaved discussions regarding how to reduce hallucinations from LLM\nresponses, how to increase the factuality of LLMs, and whether Knowledge Graphs\n(KGs), which store the world knowledge in a symbolic form, will be replaced\nwith LLMs. In this paper, we try to answer these questions from a new angle:\nHow knowledgeable are LLMs?\n  To answer this question, we constructed Head-to-Tail, a benchmark that\nconsists of 18K question-answer (QA) pairs regarding head, torso, and tail\nfacts in terms of popularity. We designed an automated evaluation method and a\nset of metrics that closely approximate the knowledge an LLM confidently\ninternalizes. Through a comprehensive evaluation of 16 publicly available LLMs,\nwe show that existing LLMs are still far from being perfect in terms of their\ngrasp of factual knowledge, especially for facts of torso-to-tail entities.", "published": "2023-08-20 05:31:03", "link": "http://arxiv.org/abs/2308.10168v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FoodGPT: A Large Language Model in Food Testing Domain with Incremental\n  Pre-training and Knowledge Graph Prompt", "abstract": "Currently, the construction of large language models in specific domains is\ndone by fine-tuning on a base model. Some models also incorporate knowledge\nbases without the need for pre-training. This is because the base model already\ncontains domain-specific knowledge during the pre-training process. We build a\nlarge language model for food testing. Unlike the above approach, a significant\namount of data in this domain exists in Scanning format for domain standard\ndocuments. In addition, there is a large amount of untrained structured\nknowledge. Therefore, we introduce an incremental pre-training step to inject\nthis knowledge into a large language model. In this paper, we propose a method\nfor handling structured knowledge and scanned documents in incremental\npre-training. To overcome the problem of machine hallucination, we constructe a\nknowledge graph to serve as an external knowledge base for supporting retrieval\nin the large language model. It is worth mentioning that this paper is a\ntechnical report of our pre-release version, and we will report our specific\nexperimental data in future versions.", "published": "2023-08-20 05:58:33", "link": "http://arxiv.org/abs/2308.10173v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Good Are LLMs at Out-of-Distribution Detection?", "abstract": "Out-of-distribution (OOD) detection plays a vital role in enhancing the\nreliability of machine learning (ML) models. The emergence of large language\nmodels (LLMs) has catalyzed a paradigm shift within the ML community,\nshowcasing their exceptional capabilities across diverse natural language\nprocessing tasks. While existing research has probed OOD detection with\nrelative small-scale Transformers like BERT, RoBERTa and GPT-2, the stark\ndifferences in scales, pre-training objectives, and inference paradigms call\ninto question the applicability of these findings to LLMs. This paper embarks\non a pioneering empirical investigation of OOD detection in the domain of LLMs,\nfocusing on LLaMA series ranging from 7B to 65B in size. We thoroughly evaluate\ncommonly-used OOD detectors, scrutinizing their performance in both zero-grad\nand fine-tuning scenarios. Notably, we alter previous discriminative\nin-distribution fine-tuning into generative fine-tuning, aligning the\npre-training objective of LLMs with downstream tasks. Our findings unveil that\na simple cosine distance OOD detector demonstrates superior efficacy,\noutperforming other OOD detectors. We provide an intriguing explanation for\nthis phenomenon by highlighting the isotropic nature of the embedding spaces of\nLLMs, which distinctly contrasts with the anisotropic property observed in\nsmaller BERT family models. The new insight enhances our understanding of how\nLLMs detect OOD data, thereby enhancing their adaptability and reliability in\ndynamic environments. We have released the source code at\n\\url{https://github.com/Awenbocc/LLM-OOD} for other researchers to reproduce\nour results.", "published": "2023-08-20 13:15:18", "link": "http://arxiv.org/abs/2308.10261v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scaling up Discovery of Latent Concepts in Deep NLP Models", "abstract": "Despite the revolution caused by deep NLP models, they remain black boxes,\nnecessitating research to understand their decision-making processes. A recent\nwork by Dalvi et al. (2022) carried out representation analysis through the\nlens of clustering latent spaces within pre-trained models (PLMs), but that\napproach is limited to small scale due to the high cost of running\nAgglomerative hierarchical clustering. This paper studies clustering algorithms\nin order to scale the discovery of encoded concepts in PLM representations to\nlarger datasets and models. We propose metrics for assessing the quality of\ndiscovered latent concepts and use them to compare the studied clustering\nalgorithms. We found that K-Means-based concept discovery significantly\nenhances efficiency while maintaining the quality of the obtained concepts.\nFurthermore, we demonstrate the practicality of this newfound efficiency by\nscaling latent concept discovery to LLMs and phrasal concepts.", "published": "2023-08-20 13:20:54", "link": "http://arxiv.org/abs/2308.10263v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CharacterChat: Learning towards Conversational AI with Personalized\n  Social Support", "abstract": "In our modern, fast-paced, and interconnected world, the importance of mental\nwell-being has grown into a matter of great urgency. However, traditional\nmethods such as Emotional Support Conversations (ESC) face challenges in\neffectively addressing a diverse range of individual personalities. In\nresponse, we introduce the Social Support Conversation (S2Conv) framework. It\ncomprises a series of support agents and the interpersonal matching mechanism,\nlinking individuals with persona-compatible virtual supporters. Utilizing\npersona decomposition based on the MBTI (Myers-Briggs Type Indicator), we have\ncreated the MBTI-1024 Bank, a group that of virtual characters with distinct\nprofiles. Through improved role-playing prompts with behavior preset and\ndynamic memory, we facilitate the development of the MBTI-S2Conv dataset, which\ncontains conversations between the characters in the MBTI-1024 Bank. Building\nupon these foundations, we present CharacterChat, a comprehensive S2Conv\nsystem, which includes a conversational model driven by personas and memories,\nalong with an interpersonal matching plugin model that dispatches the optimal\nsupporters from the MBTI-1024 Bank for individuals with specific personas.\nEmpirical results indicate the remarkable efficacy of CharacterChat in\nproviding personalized social support and highlight the substantial advantages\nderived from interpersonal matching. The source code is available in\n\\url{https://github.com/morecry/CharacterChat}.", "published": "2023-08-20 14:24:26", "link": "http://arxiv.org/abs/2308.10278v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "cantnlp@LT-EDI-2023: Homophobia/Transphobia Detection in Social Media\n  Comments using Spatio-Temporally Retrained Language Models", "abstract": "This paper describes our multiclass classification system developed as part\nof the LTEDI@RANLP-2023 shared task. We used a BERT-based language model to\ndetect homophobic and transphobic content in social media comments across five\nlanguage conditions: English, Spanish, Hindi, Malayalam, and Tamil. We\nretrained a transformer-based crosslanguage pretrained language model,\nXLMRoBERTa, with spatially and temporally relevant social media language data.\nWe also retrained a subset of models with simulated script-mixed social media\nlanguage data with varied performance. We developed the best performing\nseven-label classification system for Malayalam based on weighted macro\naveraged F1 score (ranked first out of six) with variable performance for other\nlanguage and class-label conditions. We found the inclusion of this\nspatio-temporal data improved the classification performance for all language\nand task conditions when compared with the baseline. The results suggests that\ntransformer-based language classification systems are sensitive to\nregister-specific and language-specific retraining.", "published": "2023-08-20 21:30:34", "link": "http://arxiv.org/abs/2308.10370v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LibriSQA: A Novel Dataset and Framework for Spoken Question Answering\n  with Large Language Models", "abstract": "While Large Language Models (LLMs) have demonstrated commendable performance\nacross a myriad of domains and tasks, existing LLMs still exhibit a palpable\ndeficit in handling multimodal functionalities, especially for the Spoken\nQuestion Answering (SQA) task which necessitates precise alignment and deep\ninteraction between speech and text features. To address the SQA challenge on\nLLMs, we initially curated the free-form and open-ended LibriSQA dataset from\nLibrispeech, comprising Part I with natural conversational formats and Part II\nencompassing multiple-choice questions followed by answers and analytical\nsegments. Both parts collectively include 107k SQA pairs that cover various\ntopics. Given the evident paucity of existing speech-text LLMs, we propose a\nlightweight, end-to-end framework to execute the SQA task on the LibriSQA,\nwitnessing significant results. By reforming ASR into the SQA format, we\nfurther substantiate our framework's capability in handling ASR tasks. Our\nempirical findings bolster the LLMs' aptitude for aligning and comprehending\nmultimodal information, paving the way for the development of universal\nmultimodal LLMs. The dataset and demo can be found at\nhttps://github.com/ZihanZhaoSJTU/LibriSQA.", "published": "2023-08-20 23:47:23", "link": "http://arxiv.org/abs/2308.10390v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Fairness in Large Language Models", "abstract": "Large Language Models (LLMs) have shown powerful performance and development\nprospects and are widely deployed in the real world. However, LLMs can capture\nsocial biases from unprocessed training data and propagate the biases to\ndownstream tasks. Unfair LLM systems have undesirable social impacts and\npotential harms. In this paper, we provide a comprehensive review of related\nresearch on fairness in LLMs. Considering the influence of parameter magnitude\nand training paradigm on research strategy, we divide existing fairness\nresearch into oriented to medium-sized LLMs under pre-training and fine-tuning\nparadigms and oriented to large-sized LLMs under prompting paradigms. First,\nfor medium-sized LLMs, we introduce evaluation metrics and debiasing methods\nfrom the perspectives of intrinsic bias and extrinsic bias, respectively. Then,\nfor large-sized LLMs, we introduce recent fairness research, including fairness\nevaluation, reasons for bias, and debiasing methods. Finally, we discuss and\nprovide insight on the challenges and future directions for the development of\nfairness in LLMs.", "published": "2023-08-20 03:30:22", "link": "http://arxiv.org/abs/2308.10149v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FashionNTM: Multi-turn Fashion Image Retrieval via Cascaded Memory", "abstract": "Multi-turn textual feedback-based fashion image retrieval focuses on a\nreal-world setting, where users can iteratively provide information to refine\nretrieval results until they find an item that fits all their requirements. In\nthis work, we present a novel memory-based method, called FashionNTM, for such\na multi-turn system. Our framework incorporates a new Cascaded Memory Neural\nTuring Machine (CM-NTM) approach for implicit state management, thereby\nlearning to integrate information across all past turns to retrieve new images,\nfor a given turn. Unlike vanilla Neural Turing Machine (NTM), our CM-NTM\noperates on multiple inputs, which interact with their respective memories via\nindividual read and write heads, to learn complex relationships. Extensive\nevaluation results show that our proposed method outperforms the previous\nstate-of-the-art algorithm by 50.5%, on Multi-turn FashionIQ -- the only\nexisting multi-turn fashion dataset currently, in addition to having a relative\nimprovement of 12.6% on Multi-turn Shoes -- an extension of the single-turn\nShoes dataset that we created in this work. Further analysis of the model in a\nreal-world interactive setting demonstrates two important capabilities of our\nmodel -- memory retention across turns, and agnosticity to turn order for\nnon-contradictory feedback. Finally, user study results show that images\nretrieved by FashionNTM were favored by 83.1% over other multi-turn models.\nProject page: https://sites.google.com/eng.ucsd.edu/fashionntm", "published": "2023-08-20 05:44:18", "link": "http://arxiv.org/abs/2308.10170v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Steering Language Models With Activation Engineering", "abstract": "Prompt engineering and finetuning aim to maximize language model performance\non a given metric (like toxicity reduction). However, these methods do not\nfully elicit a model's capabilities. To reduce this gap, we introduce\nactivation engineering: the inference-time modification of activations in order\nto control (or steer) model outputs. Specifically, we introduce the Activation\nAddition (ActAdd) technique, which contrasts the intermediate activations on\nprompt pairs (such as \"Love\" versus \"Hate\") to compute a steering vector\n(Subramani et al. 2022). By tactically adding in e.g. the \"Love\" - \"Hate\"\nsteering vector during the forward pass, we achieve SOTA on\nnegative-to-positive sentiment shift and detoxification using models including\nLLaMA-3 and OPT. ActAdd yields inference-time control over high-level output\nproperties (like topic and sentiment) while preserving performance on\noff-target tasks. ActAdd is lightweight: it does not require any machine\noptimization and works with a single pair of data points, which enables rapid\niteration over steering. ActAdd demonstrates the power of activation\nengineering.", "published": "2023-08-20 12:21:05", "link": "http://arxiv.org/abs/2308.10248v5", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LMTuner: An user-friendly and highly-integrable Training Framework for\n  fine-tuning Large Language Models", "abstract": "With the burgeoning development in the realm of large language models (LLMs),\nthe demand for efficient incremental training tailored to specific industries\nand domains continues to increase. Currently, the predominantly employed\nframeworks lack modular design, it often takes a lot of coding work to\nkickstart the training of LLM. To address this, we present \"LMTuner\", a highly\nusable, integrable, and scalable system for training LLMs expeditiously and\nwith minimal user-input. LMTuner comprises three main modules - the\nInteraction, Training, and Inference Modules. We advocate that LMTuner's\nusability and integrality alleviate the complexities in training large language\nmodels. Remarkably, even a novice user could commence training large language\nmodels within five minutes. Furthermore, it integrates DeepSpeed frameworks and\nsupports Efficient Fine-Tuning methodologies like Low Rank Adaptation (LoRA),\nQuantized LoRA (QLoRA), etc., enabling the training of language models scaling\nfrom 300M to a whopping 130B parameters using a single server. The LMTuner's\nhomepage (https://wengsyx.github.io/LMTuner/)and screencast video\n(https://youtu.be/nsXmWOmN3rE) are now publicly available.", "published": "2023-08-20 12:42:19", "link": "http://arxiv.org/abs/2308.10252v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Economic Policy Uncertainty: A Review on Applications and Measurement\n  Methods with Focus on Text Mining Methods", "abstract": "Economic Policy Uncertainty (EPU) represents the uncertainty realized by the\ninvestors during economic policy alterations. EPU is a critical indicator in\neconomic studies to predict future investments, the unemployment rate, and\nrecessions. EPU values can be estimated based on financial parameters directly\nor implied uncertainty indirectly using the text mining methods. Although EPU\nis a well-studied topic within the economy, the methods utilized to measure it\nare understudied. In this article, we define the EPU briefly and review the\nmethods used to measure the EPU, and survey the areas influenced by the changes\nin EPU level. We divide the EPU measurement methods into three major groups\nwith respect to their input data. Examples of each group of methods are\nenlisted, and the pros and cons of the groups are discussed. Among the EPU\nmeasures, text mining-based ones are dominantly studied. These methods measure\nthe realized uncertainty by taking into account the uncertainty represented in\nthe news and publicly available sources of financial information. Finally, we\nsurvey the research areas that rely on measuring the EPU index with the hope\nthat studying the impacts of uncertainty would attract further attention of\nresearchers from various research fields. In addition, we propose a list of\nfuture research approaches focusing on measuring EPU using textual material.", "published": "2023-08-20 16:00:53", "link": "http://arxiv.org/abs/2308.10304v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Imaginations of WALL-E : Reconstructing Experiences with an\n  Imagination-Inspired Module for Advanced AI Systems", "abstract": "In this paper, we introduce a novel Artificial Intelligence (AI) system\ninspired by the philosophical and psychoanalytical concept of imagination as a\n``Re-construction of Experiences\". Our AI system is equipped with an\nimagination-inspired module that bridges the gap between textual inputs and\nother modalities, enriching the derived information based on previously learned\nexperiences. A unique feature of our system is its ability to formulate\nindependent perceptions of inputs. This leads to unique interpretations of a\nconcept that may differ from human interpretations but are equally valid, a\nphenomenon we term as ``Interpretable Misunderstanding\". We employ large-scale\nmodels, specifically a Multimodal Large Language Model (MLLM), enabling our\nproposed system to extract meaningful information across modalities while\nprimarily remaining unimodal. We evaluated our system against other large\nlanguage models across multiple tasks, including emotion recognition and\nquestion-answering, using a zero-shot methodology to ensure an unbiased\nscenario that may happen by fine-tuning. Significantly, our system outperformed\nthe best Large Language Models (LLM) on the MELD, IEMOCAP, and CoQA datasets,\nachieving Weighted F1 (WF1) scores of 46.74%, 25.23%, and Overall F1 (OF1)\nscore of 17%, respectively, compared to 22.89%, 12.28%, and 7% from the\nwell-performing LLM. The goal is to go beyond the statistical view of language\nprocessing and tie it to human concepts such as philosophy and psychoanalysis.\nThis work represents a significant advancement in the development of\nimagination-inspired AI systems, opening new possibilities for AI to generate\ndeep and interpretable information across modalities, thereby enhancing\nhuman-AI interaction.", "published": "2023-08-20 20:10:55", "link": "http://arxiv.org/abs/2308.10354v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language\n  Models", "abstract": "Current literature, aiming to surpass the \"Chain-of-Thought\" approach, often\nresorts to external modi operandi involving halting, modifying, and then\nresuming the generation process to boost Large Language Models' (LLMs)\nreasoning capacities. Due to their myopic perspective, they escalate the number\nof query requests, leading to increased costs, memory, and computational\noverheads. Addressing this, we propose the Algorithm of Thoughts -- a novel\nstrategy that propels LLMs through algorithmic reasoning pathways. By employing\nalgorithmic examples fully in-context, this overarching view of the whole\nprocess exploits the innate recurrence dynamics of LLMs, expanding their idea\nexploration with merely one or a few queries. Our technique outperforms earlier\nsingle-query methods and even more recent multi-query strategies that employ an\nextensive tree search algorithms while using significantly fewer tokens.\nIntriguingly, our results suggest that instructing an LLM using an algorithm\ncan lead to performance surpassing that of the algorithm itself, hinting at\nLLM's inherent ability to weave its intuition into optimized searches. We probe\ninto the underpinnings of our method's efficacy and its nuances in application.\nThe code and related content can be found in:\nhttps://algorithm-of-thoughts.github.io.", "published": "2023-08-20 22:36:23", "link": "http://arxiv.org/abs/2308.10379v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Human-on-the-Loop Optimization Autoformalism Approach for\n  Sustainability", "abstract": "This paper outlines a natural conversational approach to solving personalized\nenergy-related problems using large language models (LLMs). We focus on\ncustomizable optimization problems that necessitate repeated solving with\nslight variations in modeling and are user-specific, hence posing a challenge\nto devising a one-size-fits-all model. We put forward a strategy that augments\nan LLM with an optimization solver, enhancing its proficiency in understanding\nand responding to user specifications and preferences while providing nonlinear\nreasoning capabilities. Our approach pioneers the novel concept of human-guided\noptimization autoformalism, translating a natural language task specification\nautomatically into an optimization instance. This enables LLMs to analyze,\nexplain, and tackle a variety of instance-specific energy-related problems,\npushing beyond the limits of current prompt-based techniques.\n  Our research encompasses various commonplace tasks in the energy sector, from\nelectric vehicle charging and Heating, Ventilation, and Air Conditioning (HVAC)\ncontrol to long-term planning problems such as cost-benefit evaluations for\ninstalling rooftop solar photovoltaics (PVs) or heat pumps. This pilot study\nmarks an essential stride towards the context-based formulation of optimization\nusing LLMs, with the potential to democratize optimization processes. As a\nresult, stakeholders are empowered to optimize their energy consumption,\npromoting sustainable energy practices customized to personal needs and\npreferences.", "published": "2023-08-20 22:42:04", "link": "http://arxiv.org/abs/2308.10380v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ExpeL: LLM Agents Are Experiential Learners", "abstract": "The recent surge in research interest in applying large language models\n(LLMs) to decision-making tasks has flourished by leveraging the extensive\nworld knowledge embedded in LLMs. While there is a growing demand to tailor\nLLMs for custom decision-making tasks, finetuning them for specific tasks is\nresource-intensive and may diminish the model's generalization capabilities.\nMoreover, state-of-the-art language models like GPT-4 and Claude are primarily\naccessible through API calls, with their parametric weights remaining\nproprietary and unavailable to the public. This scenario emphasizes the growing\nneed for new methodologies that allow learning from agent experiences without\nrequiring parametric updates. To address these problems, we introduce the\nExperiential Learning (ExpeL) agent. Our agent autonomously gathers experiences\nand extracts knowledge using natural language from a collection of training\ntasks. At inference, the agent recalls its extracted insights and past\nexperiences to make informed decisions. Our empirical results highlight the\nrobust learning efficacy of the ExpeL agent, indicating a consistent\nenhancement in its performance as it accumulates experiences. We further\nexplore the emerging capabilities and transfer learning potential of the ExpeL\nagent through qualitative observations and additional experiments.", "published": "2023-08-20 03:03:34", "link": "http://arxiv.org/abs/2308.10144v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "WMFormer++: Nested Transformer for Visible Watermark Removal via Implict\n  Joint Learning", "abstract": "Watermarking serves as a widely adopted approach to safeguard media\ncopyright. In parallel, the research focus has extended to watermark removal\ntechniques, offering an adversarial means to enhance watermark robustness and\nfoster advancements in the watermarking field. Existing watermark removal\nmethods mainly rely on UNet with task-specific decoder branches--one for\nwatermark localization and the other for background image restoration. However,\nwatermark localization and background restoration are not isolated tasks;\nprecise watermark localization inherently implies regions necessitating\nrestoration, and the background restoration process contributes to more\naccurate watermark localization. To holistically integrate information from\nboth branches, we introduce an implicit joint learning paradigm. This empowers\nthe network to autonomously navigate the flow of information between implicit\nbranches through a gate mechanism. Furthermore, we employ cross-channel\nattention to facilitate local detail restoration and holistic structural\ncomprehension, while harnessing nested structures to integrate multi-scale\ninformation. Extensive experiments are conducted on various challenging\nbenchmarks to validate the effectiveness of our proposed method. The results\ndemonstrate our approach's remarkable superiority, surpassing existing\nstate-of-the-art methods by a large margin.", "published": "2023-08-20 07:56:34", "link": "http://arxiv.org/abs/2308.10195v2", "categories": ["cs.MM", "cs.CL", "cs.CV", "eess.IV"], "primary_category": "cs.MM"}
{"title": "StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized\n  Image-Dialogue Data", "abstract": "The remarkable multimodal capabilities demonstrated by OpenAI's GPT-4 have\nsparked significant interest in the development of multimodal Large Language\nModels (LLMs). A primary research objective of such models is to align visual\nand textual modalities effectively while comprehending human instructions.\nCurrent methodologies often rely on annotations derived from benchmark datasets\nto construct image-dialogue datasets for training purposes, akin to instruction\ntuning in LLMs. However, these datasets often exhibit domain bias, potentially\nconstraining the generative capabilities of the models. In an effort to\nmitigate these limitations, we propose a novel data collection methodology that\nsynchronously synthesizes images and dialogues for visual instruction tuning.\nThis approach harnesses the power of generative models, marrying the abilities\nof ChatGPT and text-to-image generative models to yield a diverse and\ncontrollable dataset with varied image content. Additionally, datasets can be\narbitrarily scaled. This not only provides greater flexibility compared to\nexisting methodologies but also significantly enhances several model\ncapabilities. Our research includes comprehensive experiments conducted on\nvarious datasets. The results emphasize substantial enhancements in more than\nten commonly assessed capabilities. Additionally, our model achieves\nstate-of-the-art results across multiple widely recognized multimodal\nbenchmarks.", "published": "2023-08-20 12:43:52", "link": "http://arxiv.org/abs/2308.10253v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Can ChatGPT replace StackOverflow? A Study on Robustness and Reliability\n  of Large Language Model Code Generation", "abstract": "Recently, the large language models (LLMs) have shown extraordinary ability\nin understanding natural language and generating programming code. It has been\na common practice of software engineers to consult LLMs when encountering\ncoding questions. Although efforts have been made to avoid syntax errors and\nalign the code with the intended semantics, the reliability and robustness of\nthe code generationfrom LLMs have not yet been thoroughly studied. The\nexecutable code is not equivalent to the reliable and robust code, especially\nin the context of real-world software development. The misuse of APIs in the\ngenerated code could lead to severe problem, such as resource leaks, program\ncrashes. To make things worse, the users of LLM code generation services are\nactually the developers that are most vulnerable to these code that seems right\n-- They are always novice developers that are not familiar with the APIs that\nLLMs generate code for them. Therefore, they could hardly tell the misuse in\nthe code generated by LLMs, which further facilitates the incorrect code\napplied in real-world software. Existing code evaluation benchmark and datasets\nfocus on crafting small tasks such as programming questions in coding\ninterviews, which however deviates from the problem that developers would ask\nLLM for real-world coding help. To fill the missing piece, in this work, we\npropose a dataset RobustAPI for evaluating the reliability and robustness of\ncode generated by LLMs. We collect 1208 coding questions from StackOverflow on\n24 representative Java APIs. We summarize thecommon misuse patterns of these\nAPIs and evaluate them oncurrent popular LLMs. The evaluation results show that\nevenfor GPT-4, 62% of the generated code contains API misuses,which would cause\nunexpected consequences if the code isintroduced into real-world software.", "published": "2023-08-20 18:36:28", "link": "http://arxiv.org/abs/2308.10335v5", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal\n  Reasoning in Large Language Models", "abstract": "The advent of large language models (LLMs) and their adoption by the legal\ncommunity has given rise to the question: what types of legal reasoning can\nLLMs perform? To enable greater study of this question, we present LegalBench:\na collaboratively constructed legal reasoning benchmark consisting of 162 tasks\ncovering six different types of legal reasoning. LegalBench was built through\nan interdisciplinary process, in which we collected tasks designed and\nhand-crafted by legal professionals. Because these subject matter experts took\na leading role in construction, tasks either measure legal reasoning\ncapabilities that are practically useful, or measure reasoning skills that\nlawyers find interesting. To enable cross-disciplinary conversations about LLMs\nin the law, we additionally show how popular legal frameworks for describing\nlegal reasoning -- which distinguish between its many forms -- correspond to\nLegalBench tasks, thus giving lawyers and LLM developers a common vocabulary.\nThis paper describes LegalBench, presents an empirical evaluation of 20\nopen-source and commercial LLMs, and illustrates the types of research\nexplorations LegalBench enables.", "published": "2023-08-20 22:08:03", "link": "http://arxiv.org/abs/2308.11462v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Indonesian Automatic Speech Recognition with XLSR-53", "abstract": "This study focuses on the development of Indonesian Automatic Speech\nRecognition (ASR) using the XLSR-53 pre-trained model, the XLSR stands for\ncross-lingual speech representations. The use of this XLSR-53 pre-trained model\nis to significantly reduce the amount of training data in non-English languages\nrequired to achieve a competitive Word Error Rate (WER). The total amount of\ndata used in this study is 24 hours, 18 minutes, and 1 second: (1) TITML-IDN 14\nhours and 31 minutes; (2) Magic Data 3 hours and 33 minutes; and (3) Common\nVoice 6 hours, 14 minutes, and 1 second. With a WER of 20%, the model built in\nthis study can compete with similar models using the Common Voice dataset split\ntest. WER can be decreased by around 8% using a language model, resulted in WER\nfrom 20% to 12%. Thus, the results of this study have succeeded in perfecting\nprevious research in contributing to the creation of a better Indonesian ASR\nwith a smaller amount of data.", "published": "2023-08-20 09:59:40", "link": "http://arxiv.org/abs/2308.11589v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Local Periodicity-Based Beat Tracking for Expressive Classical Piano\n  Music", "abstract": "To model the periodicity of beats, state-of-the-art beat tracking systems use\n\"post-processing trackers\" (PPTs) that rely on several empirically determined\nglobal assumptions for tempo transition, which work well for music with a\nsteady tempo. For expressive classical music, however, these assumptions can be\ntoo rigid. With two large datasets of Western classical piano music, namely the\nAligned Scores and Performances (ASAP) dataset and a dataset of Chopin's\nMazurkas (Maz-5), we report on experiments showing the failure of existing PPTs\nto cope with local tempo changes, thus calling for new methods. In this paper,\nwe propose a new local periodicity-based PPT, called predominant local\npulse-based dynamic programming (PLPDP) tracking, that allows for more flexible\ntempo transitions. Specifically, the new PPT incorporates a method called\n\"predominant local pulses\" (PLP) in combination with a dynamic programming (DP)\ncomponent to jointly consider the locally detected periodicity and beat\nactivation strength at each time instant. Accordingly, PLPDP accounts for the\nlocal periodicity, rather than relying on a global tempo assumption. Compared\nto existing PPTs, PLPDP particularly enhances the recall values at the cost of\na lower precision, resulting in an overall improvement of F1-score for beat\ntracking in ASAP (from 0.473 to 0.493) and Maz-5 (from 0.595 to 0.838).", "published": "2023-08-20 20:12:03", "link": "http://arxiv.org/abs/2308.10355v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "The DKU-DUKEECE System for the Manipulation Region Location Task of ADD\n  2023", "abstract": "This paper introduces our system designed for Track 2, which focuses on\nlocating manipulated regions, in the second Audio Deepfake Detection Challenge\n(ADD 2023). Our approach involves the utilization of multiple detection systems\nto identify splicing regions and determine their authenticity. Specifically, we\ntrain and integrate two frame-level systems: one for boundary detection and the\nother for deepfake detection. Additionally, we employ a third VAE model trained\nexclusively on genuine data to determine the authenticity of a given audio\nclip. Through the fusion of these three systems, our top-performing solution\nfor the ADD challenge achieves an impressive 82.23% sentence accuracy and an F1\nscore of 60.66%. This results in a final ADD score of 0.6713, securing the\nfirst rank in Track 2 of ADD 2023.", "published": "2023-08-20 14:29:04", "link": "http://arxiv.org/abs/2308.10281v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Neural Architectures Learning Fourier Transforms, Signal Processing and\n  Much More....", "abstract": "This report will explore and answer fundamental questions about taking\nFourier Transforms and tying it with recent advances in AI and neural\narchitecture. One interpretation of the Fourier Transform is decomposing a\nsignal into its constituent components by projecting them onto complex\nexponentials. Variants exist, such as discrete cosine transform that does not\noperate on the complex domain and projects an input signal to only cosine\nfunctions oscillating at different frequencies. However, this is a fundamental\nlimitation, and it needs to be more suboptimal. The first one is that all\nkernels are sinusoidal: What if we could have some kernels adapted or learned\naccording to the problem? What if we can use neural architectures for this? We\nshow how one can learn these kernels from scratch for audio signal processing\napplications. We find that the neural architecture not only learns sinusoidal\nkernel shapes but discovers all kinds of incredible signal-processing\nproperties. E.g., windowing functions, onset detectors, high pass filters, low\npass filters, modulations, etc. Further, upon analysis of the filters, we find\nthat the neural architecture has a comb filter-like structure on top of the\nlearned kernels. Comb filters that allow harmonic frequencies to pass through\nare one of the core building blocks/types of filters similar to high-pass,\nlow-pass, and band-pass filters of various traditional signal processing\nalgorithms. Further, we can also use the convolution operation with a signal to\nbe learned from scratch, and we will explore papers in the literature that uses\nthis with that robust Transformer architectures. Further, we would also explore\nmaking the learned kernel's content adaptive, i.e., learning different kernels\nfor different inputs.", "published": "2023-08-20 23:30:27", "link": "http://arxiv.org/abs/2308.10388v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
