{"title": "American Call Options Pricing With Modular Neural Networks", "abstract": "An accurate valuation of American call options is critical in most financial\ndecision making environments. However, traditional models like the Barone-Adesi\nWhaley (B-AW) and Binomial Option Pricing (BOP) methods fall short in handling\nthe complexities of early exercise and market dynamics present in American\noptions. This paper proposes a Modular Neural Network (MNN) model which aims to\ncapture the key aspects of American options pricing. By dividing the prediction\nprocess into specialized modules, the MNN effectively models the non-linear\ninteractions that drive American call options pricing. Experimental results\nindicate that the MNN model outperform both traditional models as well as a\nsimpler Feed-forward Neural Network (FNN) across multiple stocks (AAPL, NVDA,\nQQQ), with significantly lower RMSE and nRMSE (by mean). These findings\nhighlight the potential of MNNs as a powerful tool to improve the accuracy of\npredicting option prices.", "published": "2024-09-29 13:50:34", "link": "http://arxiv.org/abs/2409.19706v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Stock Price Prediction and Traditional Models: An Approach to Achieve Short-, Medium- and Long-Term Goals", "abstract": "A comparative analysis of deep learning models and traditional statistical\nmethods for stock price prediction uses data from the Nigerian stock exchange.\nHistorical data, including daily prices and trading volumes, are employed to\nimplement models such as Long Short Term Memory (LSTM) networks, Gated\nRecurrent Units (GRUs), Autoregressive Integrated Moving Average (ARIMA), and\nAutoregressive Moving Average (ARMA). These models are assessed over three-time\nhorizons: short-term (1 year), medium-term (2.5 years), and long-term (5\nyears), with performance measured by Mean Squared Error (MSE) and Mean Absolute\nError (MAE). The stability of the time series is tested using the Augmented\nDickey-Fuller (ADF) test. Results reveal that deep learning models,\nparticularly LSTM, outperform traditional methods by capturing complex,\nnonlinear patterns in the data, resulting in more accurate predictions.\nHowever, these models require greater computational resources and offer less\ninterpretability than traditional approaches. The findings highlight the\npotential of deep learning for improving financial forecasting and investment\nstrategies. Future research could incorporate external factors such as social\nmedia sentiment and economic indicators, refine model architectures, and\nexplore real-time applications to enhance prediction accuracy and scalability.", "published": "2024-09-29 11:20:20", "link": "http://arxiv.org/abs/2410.07220v1", "categories": ["q-fin.ST", "cs.LG", "q-fin.CP"], "primary_category": "q-fin.ST"}
{"title": "Signal inference in financial stock return correlations through phase-ordering kinetics in the quenched regime", "abstract": "Financial stock return correlations have been analyzed through the lens of\nrandom matrix theory to differentiate the underlying signal from spurious\ncorrelations. The continuous spectrum of the eigenvalue distribution derived\nfrom the stock return correlation matrix typically aligns with a rescaled\nMarchenko-Pastur distribution, indicating no detectable signal. In this study,\nwe introduce a stochastic field theory model to establish a detection threshold\nfor signals present in the limit where the eigenvalues are within the\ncontinuous spectrum, which itself closely resembles that of a random matrix\nwhere standard methods such as principal component analysis fail to infer a\nsignal. We then apply our method to Standard & Poor's 500 financial stocks'\nreturn correlations, detecting the presence of a signal in the largest\neigenvalues within the continuous spectrum.", "published": "2024-09-29 14:07:36", "link": "http://arxiv.org/abs/2409.19711v1", "categories": ["q-fin.ST", "cond-mat.stat-mech", "q-fin.MF"], "primary_category": "q-fin.ST"}
{"title": "The Nature of NLP: Analyzing Contributions in NLP Papers", "abstract": "Natural Language Processing (NLP) is a dynamic, interdisciplinary field that\nintegrates intellectual traditions from computer science, linguistics, social\nscience, and more. Despite its established presence, the definition of what\nconstitutes NLP research remains debated. In this work, we quantitatively\ninvestigate what constitutes NLP by examining research papers. For this\npurpose, we propose a taxonomy and introduce NLPContributions, a dataset of\nnearly $2k$ research paper abstracts, expertly annotated to identify scientific\ncontributions and classify their types according to this taxonomy. We also\npropose a novel task to automatically identify these elements, for which we\ntrain a strong baseline on our dataset. We present experimental results from\nthis task and apply our model to $\\sim$$29k$ NLP research papers to analyze\ntheir contributions, aiding in the understanding of the nature of NLP research.\nOur findings reveal a rising involvement of machine learning in NLP since the\nearly nineties, alongside a declining focus on adding knowledge about language\nor people; again, in post-2020, there has been a resurgence of focus on\nlanguage and people. We hope this work will spark discussions on our community\nnorms and inspire efforts to consciously shape the future.", "published": "2024-09-29 01:29:28", "link": "http://arxiv.org/abs/2409.19505v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Critical Look at Meta-evaluating Summarisation Evaluation Metrics", "abstract": "Effective summarisation evaluation metrics enable researchers and\npractitioners to compare different summarisation systems efficiently.\nEstimating the effectiveness of an automatic evaluation metric, termed\nmeta-evaluation, is a critically important research question. In this position\npaper, we review recent meta-evaluation practices for summarisation evaluation\nmetrics and find that (1) evaluation metrics are primarily meta-evaluated on\ndatasets consisting of examples from news summarisation datasets, and (2) there\nhas been a noticeable shift in research focus towards evaluating the\nfaithfulness of generated summaries. We argue that the time is ripe to build\nmore diverse benchmarks that enable the development of more robust evaluation\nmetrics and analyze the generalization ability of existing evaluation metrics.\nIn addition, we call for research focusing on user-centric quality dimensions\nthat consider the generated summary's communicative goal and the role of\nsummarisation in the workflow.", "published": "2024-09-29 01:30:13", "link": "http://arxiv.org/abs/2409.19507v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transforming Scholarly Landscapes: Influence of Large Language Models on\n  Academic Fields beyond Computer Science", "abstract": "Large Language Models (LLMs) have ushered in a transformative era in Natural\nLanguage Processing (NLP), reshaping research and extending NLP's influence to\nother fields of study. However, there is little to no work examining the degree\nto which LLMs influence other research fields. This work empirically and\nsystematically examines the influence and use of LLMs in fields beyond NLP. We\ncurate $106$ LLMs and analyze $\\sim$$148k$ papers citing LLMs to quantify their\ninfluence and reveal trends in their usage patterns. Our analysis reveals not\nonly the increasing prevalence of LLMs in non-CS fields but also the\ndisparities in their usage, with some fields utilizing them more frequently\nthan others since 2018, notably Linguistics and Engineering together accounting\nfor $\\sim$$45\\%$ of LLM citations. Our findings further indicate that most of\nthese fields predominantly employ task-agnostic LLMs, proficient in zero or\nfew-shot learning without requiring further fine-tuning, to address their\ndomain-specific problems. This study sheds light on the cross-disciplinary\nimpact of NLP through LLMs, providing a better understanding of the\nopportunities and challenges.", "published": "2024-09-29 01:32:35", "link": "http://arxiv.org/abs/2409.19508v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoT-ST: Enhancing LLM-based Speech Translation with Multimodal\n  Chain-of-Thought", "abstract": "Speech Language Models (SLMs) have demonstrated impressive performance on\nspeech translation tasks. However, existing research primarily focuses on\ndirect instruction fine-tuning and often overlooks the inherent reasoning\ncapabilities of SLMs. In this paper, we introduce a three-stage training\nframework designed to activate the chain-of-thought (CoT) capabilities of SLMs.\nWe propose CoT-ST, a speech translation model that utilizes multimodal CoT to\ndecompose speech translation into sequential steps of speech recognition and\ntranslation. We validated the effectiveness of our method on two datasets: the\nCoVoST-2 dataset and MuST-C dataset. The experimental results demonstrate that\nCoT-ST outperforms previous state-of-the-art methods, achieving higher BLEU\nscores (CoVoST-2 en-ja: 30.5->30.8, en-zh: 45.2->47.7, MuST-C en-zh:\n19.6->21.2). This work is open sourced at\nhttps://github.com/X-LANCE/SLAM-LLM/tree/main/examples/st_covost2 .", "published": "2024-09-29 01:48:09", "link": "http://arxiv.org/abs/2409.19510v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LANDeRMT: Detecting and Routing Language-Aware Neurons for Selectively\n  Finetuning LLMs to Machine Translation", "abstract": "Recent advancements in large language models (LLMs) have shown promising\nresults in multilingual translation even with limited bilingual supervision.\nThe major challenges are catastrophic forgetting and parameter interference for\nfinetuning LLMs when provided parallel training data. To address these\nchallenges, we propose LANDeRMT, a \\textbf{L}anguage-\\textbf{A}ware\n\\textbf{N}euron \\textbf{De}tecting and \\textbf{R}outing framework that\nselectively finetunes LLMs to \\textbf{M}achine \\textbf{T}ranslation with\ndiverse translation training data. In LANDeRMT, we evaluate the awareness of\nneurons to MT tasks and categorize them into language-general and\nlanguage-specific neurons. This categorization enables selective parameter\nupdates during finetuning, mitigating parameter interference and catastrophic\nforgetting issues. For the detected neurons, we further propose a conditional\nawareness-based routing mechanism to dynamically adjust language-general and\nlanguage-specific capacity within LLMs, guided by translation signals.\nExperimental results demonstrate that the proposed LANDeRMT is very effective\nin learning translation knowledge, significantly improving translation quality\nover various strong baselines for multiple language pairs.", "published": "2024-09-29 02:39:42", "link": "http://arxiv.org/abs/2409.19523v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mixed Chain-of-Psychotherapies for Emotional Support Chatbot", "abstract": "In the realm of mental health support chatbots, it is vital to show empathy\nand encourage self-exploration to provide tailored solutions. However, current\napproaches tend to provide general insights or solutions without fully\nunderstanding the help-seeker's situation. Therefore, we propose PsyMix, a\nchatbot that integrates the analyses of the seeker's state from the perspective\nof a psychotherapy approach (Chain-of-Psychotherapies, CoP) before generating\nthe response, and learns to incorporate the strength of various psychotherapies\nby fine-tuning on a mixture of CoPs. Through comprehensive evaluation, we found\nthat PsyMix can outperform the ChatGPT baseline, and demonstrate a comparable\nlevel of empathy in its responses to that of human counselors.", "published": "2024-09-29 03:34:13", "link": "http://arxiv.org/abs/2409.19533v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DiMB-RE: Mining the Scientific Literature for Diet-Microbiome\n  Associations", "abstract": "Objective: To develop a corpus annotated for diet-microbiome associations\nfrom the biomedical literature and train natural language processing (NLP)\nmodels to identify these associations, thereby improving the understanding of\ntheir role in health and disease, and supporting personalized nutrition\nstrategies. Materials and Methods: We constructed DiMB-RE, a comprehensive\ncorpus annotated with 15 entity types (e.g., Nutrient, Microorganism) and 13\nrelation types (e.g., INCREASES, IMPROVES) capturing diet-microbiome\nassociations. We fine-tuned and evaluated state-of-the-art NLP models for named\nentity, trigger, and relation extraction as well as factuality detection using\nDiMB-RE. In addition, we benchmarked two generative large language models\n(GPT-4o-mini and GPT-4o) on a subset of the dataset in zero- and one-shot\nsettings. Results: DiMB-RE consists of 14,450 entities and 4,206 relationships\nfrom 165 publications (including 30 full-text Results sections). Fine-tuned NLP\nmodels performed reasonably well for named entity recognition (0.800 F1 score),\nwhile end-to-end relation extraction performance was modest (0.445 F1). The use\nof Results section annotations improved relation extraction. The impact of\ntrigger detection was mixed. Generative models showed lower accuracy compared\nto fine-tuned models. Discussion: To our knowledge, DiMB-RE is the largest and\nmost diverse corpus focusing on diet-microbiome interactions. NLP models\nfine-tuned on DiMB-RE exhibit lower performance compared to similar corpora,\nhighlighting the complexity of information extraction in this domain.\nMisclassified entities, missed triggers, and cross-sentence relations are the\nmajor sources of relation extraction errors. Conclusions: DiMB-RE can serve as\na benchmark corpus for biomedical literature mining. DiMB-RE and the NLP models\nare available at https://github.com/ScienceNLP-Lab/DiMB-RE.", "published": "2024-09-29 06:58:26", "link": "http://arxiv.org/abs/2409.19581v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Attentional Mixture of LoRAs for Language Model Continual\n  Learning", "abstract": "Fine-tuning large language models (LLMs) with Low-Rank adaption (LoRA) is\nwidely acknowledged as an effective approach for continual learning for new\ntasks. However, it often suffers from catastrophic forgetting when dealing with\nmultiple tasks sequentially. To this end, we propose Attentional Mixture of\nLoRAs (AM-LoRA), a continual learning approach tailored for LLMs. Specifically,\nAM-LoRA learns a sequence of LoRAs for a series of tasks to continually learn\nknowledge from different tasks. The key of our approach is that we devise an\nattention mechanism as a knowledge mixture module to adaptively integrate\ninformation from each LoRA. With the attention mechanism, AM-LoRA can\nefficiently leverage the distinctive contributions of each LoRA, while\nmitigating the risk of mutually negative interactions among them that may lead\nto catastrophic forgetting. Moreover, we further introduce $L1$ norm in the\nlearning process to make the attention vector more sparse. The sparse\nconstraints can enable the model to lean towards selecting a few highly\nrelevant LoRAs, rather than aggregating and weighting all LoRAs collectively,\nwhich can further reduce the impact stemming from mutual interference.\nExperimental results on continual learning benchmarks indicate the superiority\nof our proposed method.", "published": "2024-09-29 08:34:54", "link": "http://arxiv.org/abs/2409.19611v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Misinformation Detection by Learning from Synthetic Data with\n  Multimodal LLMs", "abstract": "Detecting multimodal misinformation, especially in the form of image-text\npairs, is crucial. Obtaining large-scale, high-quality real-world fact-checking\ndatasets for training detectors is costly, leading researchers to use synthetic\ndatasets generated by AI technologies. However, the generalizability of\ndetectors trained on synthetic data to real-world scenarios remains unclear due\nto the distribution gap. To address this, we propose learning from synthetic\ndata for detecting real-world multimodal misinformation through two\nmodel-agnostic data selection methods that match synthetic and real-world data\ndistributions. Experiments show that our method enhances the performance of a\nsmall MLLM (13B) on real-world fact-checking datasets, enabling it to even\nsurpass GPT-4V~\\cite{GPT-4V}.", "published": "2024-09-29 11:01:14", "link": "http://arxiv.org/abs/2409.19656v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical\n  Understanding and Generation in Essays", "abstract": "Existing rhetorical understanding and generation datasets or corpora\nprimarily focus on single coarse-grained categories or fine-grained categories,\nneglecting the common interrelations between different rhetorical devices by\ntreating them as independent sub-tasks. In this paper, we propose the Chinese\nEssay Rhetoric Dataset (CERD), consisting of 4 commonly used coarse-grained\ncategories including metaphor, personification, hyperbole and parallelism and\n23 fine-grained categories across both form and content levels. CERD is a\nmanually annotated and comprehensive Chinese rhetoric dataset with five\ninterrelated sub-tasks. Unlike previous work, our dataset aids in understanding\nvarious rhetorical devices, recognizing corresponding rhetorical components,\nand generating rhetorical sentences under given conditions, thereby improving\nthe author's writing proficiency and language usage skills. Extensive\nexperiments are conducted to demonstrate the interrelations between multiple\ntasks in CERD, as well as to establish a benchmark for future research on\nrhetoric. The experimental results indicate that Large Language Models achieve\nthe best performance across most tasks, and jointly fine-tuning with multiple\ntasks further enhances performance.", "published": "2024-09-29 12:47:25", "link": "http://arxiv.org/abs/2409.19691v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "2D-TPE: Two-Dimensional Positional Encoding Enhances Table Understanding\n  for Large Language Models", "abstract": "Tables are ubiquitous across various domains for concisely representing\nstructured information. Empowering large language models (LLMs) to reason over\ntabular data represents an actively explored direction. However, since typical\nLLMs only support one-dimensional~(1D) inputs, existing methods often flatten\nthe two-dimensional~(2D) table structure into a sequence of tokens, which can\nseverely disrupt the spatial relationships and result in an inevitable loss of\nvital contextual information. In this paper, we first empirically demonstrate\nthe detrimental impact of such flattening operations on the performance of LLMs\nin capturing the spatial information of tables through two elaborate proxy\ntasks. Subsequently, we introduce a simple yet effective positional encoding\nmethod, termed ``2D-TPE'' (Two-Dimensional Table Positional Encoding), to\naddress this challenge. 2D-TPE enables each attention head to dynamically\nselect a permutation order of tokens within the context for attending to them,\nwhere each permutation represents a distinct traversal mode for the table, such\nas column-wise or row-wise traversal. 2D-TPE effectively mitigates the risk of\nlosing essential spatial information while preserving computational efficiency,\nthus better preserving the table structure. Extensive experiments across five\nbenchmarks demonstrate that 2D-TPE outperforms strong baselines, underscoring\nthe importance of preserving the table structure for accurate table\ncomprehension. Comprehensive analysis further reveals the substantially better\nscalability of 2D-TPE to large tables than baselines.", "published": "2024-09-29 13:16:37", "link": "http://arxiv.org/abs/2409.19700v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Coffee-Gym: An Environment for Evaluating and Improving Natural Language\n  Feedback on Erroneous Code", "abstract": "This paper presents Coffee-Gym, a comprehensive RL environment for training\nmodels that provide feedback on code editing. Coffee-Gym includes two major\ncomponents: (1) Coffee, a dataset containing humans' code edit traces for\ncoding questions and machine-written feedback for editing erroneous code; (2)\nCoffeeEval, a reward function that faithfully reflects the helpfulness of\nfeedback by assessing the performance of the revised code in unit tests. With\nthem, Coffee-Gym addresses the unavailability of high-quality datasets for\ntraining feedback models with RL, and provides more accurate rewards than the\nSOTA reward model (i.e., GPT-4). By applying Coffee-Gym, we elicit feedback\nmodels that outperform baselines in enhancing open-source code LLMs' code\nediting, making them comparable with closed-source LLMs. We make the dataset\nand the model checkpoint publicly available.", "published": "2024-09-29 14:14:25", "link": "http://arxiv.org/abs/2409.19715v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revealing Personality Traits: A New Benchmark Dataset for Explainable\n  Personality Recognition on Dialogues", "abstract": "Personality recognition aims to identify the personality traits implied in\nuser data such as dialogues and social media posts. Current research\npredominantly treats personality recognition as a classification task, failing\nto reveal the supporting evidence for the recognized personality. In this\npaper, we propose a novel task named Explainable Personality Recognition,\naiming to reveal the reasoning process as supporting evidence of the\npersonality trait. Inspired by personality theories, personality traits are\nmade up of stable patterns of personality state, where the states are\nshort-term characteristic patterns of thoughts, feelings, and behaviors in a\nconcrete situation at a specific moment in time. We propose an explainable\npersonality recognition framework called Chain-of-Personality-Evidence (CoPE),\nwhich involves a reasoning process from specific contexts to short-term\npersonality states to long-term personality traits. Furthermore, based on the\nCoPE framework, we construct an explainable personality recognition dataset\nfrom dialogues, PersonalityEvd. We introduce two explainable personality state\nrecognition and explainable personality trait recognition tasks, which require\nmodels to recognize the personality state and trait labels and their\ncorresponding support evidence. Our extensive experiments based on Large\nLanguage Models on the two tasks show that revealing personality traits is very\nchallenging and we present some insights for future research. Our data and code\nare available at https://github.com/Lei-Sun-RUC/PersonalityEvd.", "published": "2024-09-29 14:41:43", "link": "http://arxiv.org/abs/2409.19723v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scrambled text: training Language Models to correct OCR errors using\n  synthetic data", "abstract": "OCR errors are common in digitised historical archives significantly\naffecting their usability and value. Generative Language Models (LMs) have\nshown potential for correcting these errors using the context provided by the\ncorrupted text and the broader socio-cultural context, a process called Context\nLeveraging OCR Correction (CLOCR-C). However, getting sufficient training data\nfor fine-tuning such models can prove challenging. This paper shows that\nfine-tuning a language model on synthetic data using an LM and using a\ncharacter level Markov corruption process can significantly improve the ability\nto correct OCR errors. Models trained on synthetic data reduce the character\nerror rate by 55% and word error rate by 32% over the base LM and outperform\nmodels trained on real data. Key findings include; training on under-corrupted\ndata is better than over-corrupted data; non-uniform character level corruption\nis better than uniform corruption; More tokens-per-observation outperforms more\nobservations for a fixed token budget. The outputs for this paper are a set of\n8 heuristics for training effective CLOCR-C models, a dataset of 11,000\nsynthetic 19th century newspaper articles and scrambledtext a python library\nfor creating synthetic corrupted data.", "published": "2024-09-29 15:20:37", "link": "http://arxiv.org/abs/2409.19735v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Systematic Review of NLP for Dementia -- Tasks, Datasets and\n  Opportunities", "abstract": "The close link between cognitive decline and language has fostered\nlong-standing collaboration between the NLP and medical communities in dementia\nresearch. To examine this, we reviewed over 240 papers applying NLP to\ndementia-related efforts, drawing from medical, technological, and NLP-focused\nliterature. We identify key research areas, including dementia detection,\nlinguistic biomarker extraction, caregiver support, and patient assistance,\nshowing that half of all papers focus solely on dementia detection using\nclinical data. Yet, many directions remain unexplored -- artificially degraded\nlanguage models, synthetic data, digital twins, and more. We highlight gaps and\nopportunities around trust, scientific rigor, applicability and cross-community\ncollaboration. We raise ethical dilemmas in the field, and highlight the\ndiverse datasets encountered throughout our review -- recorded, written,\nstructured, spontaneous, synthetic, clinical, social media-based, and more.\nThis review aims to inspire more creative, impactful, and rigorous research on\nNLP for dementia.", "published": "2024-09-29 15:30:59", "link": "http://arxiv.org/abs/2409.19737v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural Language Generation for Visualizations: State of the Art,\n  Challenges and Future Directions", "abstract": "Natural language and visualization are two complementary modalities of human\ncommunication that play a crucial role in conveying information effectively.\nWhile visualizations help people discover trends, patterns, and anomalies in\ndata, natural language descriptions help explain these insights. Thus,\ncombining text with visualizations is a prevalent technique for effectively\ndelivering the core message of the data. Given the rise of natural language\ngeneration (NLG), there is a growing interest in automatically creating natural\nlanguage descriptions for visualizations, which can be used as chart captions,\nanswering questions about charts, or telling data-driven stories. In this\nsurvey, we systematically review the state of the art on NLG for visualizations\nand introduce a taxonomy of the problem. The NLG tasks fall within the domain\nof Natural Language Interfaces (NLI) for visualization, an area that has\ngarnered significant attention from both the research community and industry.\nTo narrow down the scope of the survey, we primarily concentrate on the\nresearch works that focus on text generation for visualizations. To\ncharacterize the NLG problem and the design space of proposed solutions, we\npose five Wh-questions, why and how NLG tasks are performed for visualizations,\nwhat the task inputs and outputs are, as well as where and when the generated\ntexts are integrated with visualizations. We categorize the solutions used in\nthe surveyed papers based on these \"five Wh-questions.\" Finally, we discuss the\nkey challenges and potential avenues for future research in this domain.", "published": "2024-09-29 15:53:18", "link": "http://arxiv.org/abs/2409.19747v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual\n  Information and Group Topic Regularization", "abstract": "Recent advances in neural topic models have concentrated on two primary\ndirections: the integration of the inference network (encoder) with a\npre-trained language model (PLM) and the modeling of the relationship between\nwords and topics in the generative model (decoder). However, the use of large\nPLMs significantly increases inference costs, making them less practical for\nsituations requiring low inference times. Furthermore, it is crucial to\nsimultaneously model the relationships between topics and words as well as the\ninterrelationships among topics themselves. In this work, we propose a novel\nframework called NeuroMax (Neural Topic Model with Maximizing Mutual\nInformation with Pretrained Language Model and Group Topic Regularization) to\naddress these challenges. NeuroMax maximizes the mutual information between the\ntopic representation obtained from the encoder in neural topic models and the\nrepresentation derived from the PLM. Additionally, NeuroMax employs optimal\ntransport to learn the relationships between topics by analyzing how\ninformation is transported among them. Experimental results indicate that\nNeuroMax reduces inference time, generates more coherent topics and topic\ngroups, and produces more representative document embeddings, thereby enhancing\nperformance on downstream tasks.", "published": "2024-09-29 15:59:36", "link": "http://arxiv.org/abs/2409.19749v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex\n  Knowledge Graph Question Answering", "abstract": "Recent studies have explored the use of Large Language Models (LLMs) with\nRetrieval Augmented Generation (RAG) for Knowledge Graph Question Answering\n(KGQA). They typically require rewriting retrieved subgraphs into natural\nlanguage formats comprehensible to LLMs. However, when tackling complex\nquestions, the knowledge rewritten by existing methods may include irrelevant\ninformation, omit crucial details, or fail to align with the question's\nsemantics. To address them, we propose a novel rewriting method CoTKR,\nChain-of-Thought Enhanced Knowledge Rewriting, for generating reasoning traces\nand corresponding knowledge in an interleaved manner, thereby mitigating the\nlimitations of single-step knowledge rewriting. Additionally, to bridge the\npreference gap between the knowledge rewriter and the question answering (QA)\nmodel, we propose a training strategy PAQAF, Preference Alignment from Question\nAnswering Feedback, for leveraging feedback from the QA model to further\noptimize the knowledge rewriter. We conduct experiments using various LLMs\nacross several KGQA benchmarks. Experimental results demonstrate that, compared\nwith previous knowledge rewriting methods, CoTKR generates the most beneficial\nknowledge representation for QA models, which significantly improves the\nperformance of LLMs in KGQA.", "published": "2024-09-29 16:08:45", "link": "http://arxiv.org/abs/2409.19753v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Adversarial Robustness in Classification tasks using DNA\n  Language Models", "abstract": "DNA Language Models, such as GROVER, DNABERT2 and the Nucleotide Transformer,\noperate on DNA sequences that inherently contain sequencing errors, mutations,\nand laboratory-induced noise, which may significantly impact model performance.\nDespite the importance of this issue, the robustness of DNA language models\nremains largely underexplored. In this paper, we comprehensivly investigate\ntheir robustness in DNA classification by applying various adversarial attack\nstrategies: the character (nucleotide substitutions), word (codon\nmodifications), and sentence levels (back-translation-based transformations) to\nsystematically analyze model vulnerabilities. Our results demonstrate that DNA\nlanguage models are highly susceptible to adversarial attacks, leading to\nsignificant performance degradation. Furthermore, we explore adversarial\ntraining method as a defense mechanism, which enhances both robustness and\nclassification accuracy. This study highlights the limitations of DNA language\nmodels and underscores the necessity of robustness in bioinformatics.", "published": "2024-09-29 21:20:57", "link": "http://arxiv.org/abs/2409.19788v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Black-Box Segmentation of Electronic Medical Records", "abstract": "Electronic medical records (EMRs) contain the majority of patients'\nhealthcare details. It is an abundant resource for developing an automatic\nhealthcare system. Most of the natural language processing (NLP) studies on EMR\nprocessing, such as concept extraction, are adversely affected by the\ninaccurate segmentation of EMR sections. At the same time, not enough attention\nhas been given to the accurate sectioning of EMRs. The information that may\noccur in section structures is unvalued. This work focuses on the segmentation\nof EMRs and proposes a black-box segmentation method using a simple sentence\nembedding model and neural network, along with a proper training method. To\nachieve universal adaptivity, we train our model on the dataset with different\nsection headings formats. We compare several advanced deep learning-based NLP\nmethods, and our method achieves the best segmentation accuracies (above 98%)\non various test data with a proper training corpus.", "published": "2024-09-29 21:45:53", "link": "http://arxiv.org/abs/2409.19796v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does RAG Introduce Unfairness in LLMs? Evaluating Fairness in\n  Retrieval-Augmented Generation Systems", "abstract": "Retrieval-Augmented Generation (RAG) has recently gained significant\nattention for its enhanced ability to integrate external knowledge sources into\nopen-domain question answering (QA) tasks. However, it remains unclear how\nthese models address fairness concerns, particularly with respect to sensitive\nattributes such as gender, geographic location, and other demographic factors.\nFirst, as language models evolve to prioritize utility, like improving exact\nmatch accuracy, fairness considerations may have been largely overlooked.\nSecond, the complex, multi-component architecture of RAG methods poses\nchallenges in identifying and mitigating biases, as each component is optimized\nfor distinct objectives. In this paper, we aim to empirically evaluate fairness\nin several RAG methods. We propose a fairness evaluation framework tailored to\nRAG, using scenario-based questions and analyzing disparities across\ndemographic attributes. Our experimental results indicate that, despite recent\nadvances in utility-driven optimization, fairness issues persist in both the\nretrieval and generation stages. These findings underscore the need for\ntargeted interventions to address fairness concerns throughout the RAG\npipeline. The dataset and code used in this study are publicly available at\nthis GitHub Repository https://github.com/elviswxy/RAG_fairness .", "published": "2024-09-29 22:04:26", "link": "http://arxiv.org/abs/2409.19804v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transforming Hidden States into Binary Semantic Features", "abstract": "Large language models follow a lineage of many NLP applications that were\ndirectly inspired by distributional semantics, but do not seem to be closely\nrelated to it anymore. In this paper, we propose to employ the distributional\ntheory of meaning once again. Using Independent Component Analysis to overcome\nsome of its challenging aspects, we show that large language models represent\nsemantic features in their hidden states.", "published": "2024-09-29 22:23:52", "link": "http://arxiv.org/abs/2409.19813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Realtime, multimodal invasive ventilation risk monitoring using language\n  models and BoXHED", "abstract": "Objective: realtime monitoring of invasive ventilation (iV) in intensive care\nunits (ICUs) plays a crucial role in ensuring prompt interventions and better\npatient outcomes. However, conventional methods often overlook valuable\ninsights embedded within clinical notes, relying solely on tabular data. In\nthis study, we propose an innovative approach to enhance iV risk monitoring by\nincorporating clinical notes into the monitoring pipeline through using\nlanguage models for text summarization. Results: We achieve superior\nperformance in all metrics reported by the state-of-the-art in iV risk\nmonitoring, namely: an AUROC of 0.86, an AUC-PR of 0.35, and an AUCt of up to\n0.86. We also demonstrate that our methodology allows for more lead time in\nflagging iV for certain time buckets. Conclusion: Our study underscores the\npotential of integrating clinical notes and language models into realtime iV\nrisk monitoring, paving the way for improved patient care and informed clinical\ndecision-making in ICU settings.", "published": "2024-09-29 21:04:44", "link": "http://arxiv.org/abs/2410.03725v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MedHalu: Hallucinations in Responses to Healthcare Queries by Large\n  Language Models", "abstract": "The remarkable capabilities of large language models (LLMs) in language\nunderstanding and generation have not rendered them immune to hallucinations.\nLLMs can still generate plausible-sounding but factually incorrect or\nfabricated information. As LLM-empowered chatbots become popular, laypeople may\nfrequently ask health-related queries and risk falling victim to these LLM\nhallucinations, resulting in various societal and healthcare implications. In\nthis work, we conduct a pioneering study of hallucinations in LLM-generated\nresponses to real-world healthcare queries from patients. We propose MedHalu, a\ncarefully crafted first-of-its-kind medical hallucination dataset with a\ndiverse range of health-related topics and the corresponding hallucinated\nresponses from LLMs with labeled hallucination types and hallucinated text\nspans. We also introduce MedHaluDetect framework to evaluate capabilities of\nvarious LLMs in detecting hallucinations. We also employ three groups of\nevaluators -- medical experts, LLMs, and laypeople -- to study who are more\nvulnerable to these medical hallucinations. We find that LLMs are much worse\nthan the experts. They also perform no better than laypeople and even worse in\nfew cases in detecting hallucinations. To fill this gap, we propose\nexpert-in-the-loop approach to improve hallucination detection through LLMs by\ninfusing expert reasoning. We observe significant performance gains for all the\nLLMs with an average macro-F1 improvement of 6.3 percentage points for GPT-4.", "published": "2024-09-29 00:09:01", "link": "http://arxiv.org/abs/2409.19492v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance\n  Regularization", "abstract": "Language models frequently inherit societal biases from their training data.\nNumerous techniques have been proposed to mitigate these biases during both the\npre-training and fine-tuning stages. However, fine-tuning a pre-trained\ndebiased language model on a downstream task can reintroduce biases into the\nmodel. Additionally, existing debiasing methods for downstream tasks either (i)\nrequire labels of protected attributes (e.g., age, race, or political views)\nthat are often not available or (ii) rely on indicators of bias, which\nrestricts their applicability to gender debiasing since they rely on\ngender-specific words. To address this, we introduce a novel debiasing\nregularization technique based on the class-wise variance of embeddings.\nCrucially, our method does not require attribute labels and targets any\nattribute, thus addressing the shortcomings of existing debiasing methods. Our\nexperiments on encoder language models and three datasets demonstrate that our\nmethod outperforms existing strong debiasing baselines that rely on target\nattribute labels while maintaining performance on the target task.", "published": "2024-09-29 03:56:50", "link": "http://arxiv.org/abs/2409.19541v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Abstractive Summarization of Low resourced Nepali language using\n  Multilingual Transformers", "abstract": "Automatic text summarization in Nepali language is an unexplored area in\nnatural language processing (NLP). Although considerable research has been\ndedicated to extractive summarization, the area of abstractive summarization,\nespecially for low-resource languages such as Nepali, remains largely\nunexplored. This study explores the use of multilingual transformer models,\nspecifically mBART and mT5, for generating headlines for Nepali news articles\nthrough abstractive summarization. The research addresses key challenges\nassociated with summarizing texts in Nepali by first creating a summarization\ndataset through web scraping from various Nepali news portals. These\nmultilingual models were then fine-tuned using different strategies. The\nperformance of the fine-tuned models were then assessed using ROUGE scores and\nhuman evaluation to ensure the generated summaries were coherent and conveyed\nthe original meaning. During the human evaluation, the participants were asked\nto select the best summary among those generated by the models, based on\ncriteria such as relevance, fluency, conciseness, informativeness, factual\naccuracy, and coverage. During the evaluation with ROUGE scores, the 4-bit\nquantized mBART with LoRA model was found to be effective in generating better\nNepali news headlines in comparison to other models and also it was selected\n34.05% of the time during the human evaluation, outperforming all other\nfine-tuned models created for Nepali News headline generation.", "published": "2024-09-29 05:58:27", "link": "http://arxiv.org/abs/2409.19566v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mitigating the Negative Impact of Over-association for Conversational\n  Query Production", "abstract": "Conversational query generation aims at producing search queries from\ndialogue histories, which are then used to retrieve relevant knowledge from a\nsearch engine to help knowledge-based dialogue systems. Trained to maximize the\nlikelihood of gold queries, previous models suffer from the data hunger issue,\nand they tend to both drop important concepts from dialogue histories and\ngenerate irrelevant concepts at inference time. We attribute these issues to\nthe over-association phenomenon where a large number of gold queries are\nindirectly related to the dialogue topics, because annotators may unconsciously\nperform reasoning with their background knowledge when generating these gold\nqueries. We carefully analyze the negative effects of this phenomenon on\npretrained Seq2seq query producers and then propose effective instance-level\nweighting strategies for training to mitigate these issues from multiple\nperspectives. Experiments on two benchmarks, Wizard-of-Internet and DuSinc,\nshow that our strategies effectively alleviate the negative effects and lead to\nsignificant performance gains (2%-5% across automatic metrics and human\nevaluation). Further analysis shows that our model selects better concepts from\ndialogue histories and is 10 times more data efficient than the baseline. The\ncode is available at https://github.com/DeepLearnXMU/QG-OverAsso.", "published": "2024-09-29 06:19:59", "link": "http://arxiv.org/abs/2409.19572v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Crucial Role of Samplers in Online Direct Preference Optimization", "abstract": "Direct Preference Optimization (DPO) has emerged as a stable, scalable, and\nefficient solution for language model alignment. Despite its empirical success,\nthe optimization properties, particularly the impact of samplers on its\nconvergence rates, remain under-explored. In this paper, we provide a rigorous\nanalysis of DPO's convergence rates with different sampling strategies under\nthe exact gradient setting, revealing a surprising separation: uniform sampling\nachieves $\\textbf{linear}$ convergence, while our proposed online sampler\nachieves $\\textbf{quadratic}$ convergence. We further adapt the sampler to\npractical settings by incorporating posterior distributions and logit mixing,\ndemonstrating improvements over previous methods. For example, it outperforms\nvanilla DPO by over $7.4$% on Safe-RLHF dataset. Our results not only offer\ninsights into the theoretical understanding of DPO but also pave the way for\nfurther algorithm designs.", "published": "2024-09-29 07:53:50", "link": "http://arxiv.org/abs/2409.19605v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Assessment and manipulation of latent constructs in pre-trained language\n  models using psychometric scales", "abstract": "Human-like personality traits have recently been discovered in large language\nmodels, raising the hypothesis that their (known and as yet undiscovered)\nbiases conform with human latent psychological constructs. While large\nconversational models may be tricked into answering psychometric\nquestionnaires, the latent psychological constructs of thousands of simpler\ntransformers, trained for other tasks, cannot be assessed because appropriate\npsychometric methods are currently lacking. Here, we show how standard\npsychological questionnaires can be reformulated into natural language\ninference prompts, and we provide a code library to support the psychometric\nassessment of arbitrary models. We demonstrate, using a sample of 88 publicly\navailable models, the existence of human-like mental health-related constructs\n(including anxiety, depression, and Sense of Coherence) which conform with\nstandard theories in human psychology and show similar correlations and\nmitigation strategies. The ability to interpret and rectify the performance of\nlanguage models by using psychological tools can boost the development of more\nexplainable, controllable, and trustworthy models.", "published": "2024-09-29 11:00:41", "link": "http://arxiv.org/abs/2409.19655v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Identifying Knowledge Editing Types in Large Language Models", "abstract": "Knowledge editing has emerged as an efficient technology for updating the\nknowledge of large language models (LLMs), attracting increasing attention in\nrecent years. However, there is a lack of effective measures to prevent the\nmalicious misuse of this technology, which could lead to harmful edits in LLMs.\nThese malicious modifications could cause LLMs to generate toxic content,\nmisleading users into inappropriate actions. In front of this risk, we\nintroduce a new task, Knowledge Editing Type Identification (KETI), aimed at\nidentifying different types of edits in LLMs, thereby providing timely alerts\nto users when encountering illicit edits. As part of this task, we propose\nKETIBench, which includes five types of harmful edits covering most popular\ntoxic types, as well as one benign factual edit. We develop four classical\nclassification models and three BERT-based models as baseline identifiers for\nboth open-source and closed-source LLMs. Our experimental results, across 42\ntrials involving two models and three knowledge editing methods, demonstrate\nthat all seven baseline identifiers achieve decent identification performance,\nhighlighting the feasibility of identifying malicious edits in LLMs. Additional\nanalyses reveal that the performance of the identifiers is independent of the\nreliability of the knowledge editing methods and exhibits cross-domain\ngeneralization, enabling the identification of edits from unknown sources. All\ndata and code are available in https://github.com/xpq-tech/KETI. Warning: This\npaper contains examples of toxic text.", "published": "2024-09-29 11:29:57", "link": "http://arxiv.org/abs/2409.19663v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can Large Language Models Analyze Graphs like Professionals? A\n  Benchmark, Datasets and Models", "abstract": "The need to analyze graphs is ubiquitous across various fields, from social\nnetworks to biological research and recommendation systems. Therefore, enabling\nthe ability of large language models (LLMs) to process graphs is an important\nstep toward more advanced general intelligence. However, current LLM benchmarks\non graph analysis require models to directly reason over the prompts describing\ngraph topology, and are thus limited to small graphs with only a few dozens of\nnodes. In contrast, human experts typically write programs based on popular\nlibraries for task solving, and can thus handle graphs with different scales.\nTo this end, a question naturally arises: can LLMs analyze graphs like\nprofessionals? In this paper, we introduce ProGraph, a manually crafted\nbenchmark containing 3 categories of graph tasks. The benchmark expects\nsolutions based on programming instead of directly reasoning over raw inputs.\nOur findings reveal that the performance of current LLMs is unsatisfactory,\nwith the best model achieving only 36% accuracy. To bridge this gap, we propose\nLLM4Graph datasets, which include crawled documents and auto-generated codes\nbased on 6 widely used graph libraries. By augmenting closed-source LLMs with\ndocument retrieval and fine-tuning open-source ones on the codes, we show\n11-32% absolute improvements in their accuracies. Our results underscore that\nthe capabilities of LLMs in handling structured data are still under-explored,\nand show the effectiveness of LLM4Graph in enhancing LLMs' proficiency of graph\nanalysis. The benchmark, datasets and enhanced open-source models are available\nat https://github.com/BUPT-GAMMA/ProGraph.", "published": "2024-09-29 11:38:45", "link": "http://arxiv.org/abs/2409.19667v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Modeling Layout Reading Order as Ordering Relations for Visually-rich\n  Document Understanding", "abstract": "Modeling and leveraging layout reading order in visually-rich documents\n(VrDs) is critical in document intelligence as it captures the rich structure\nsemantics within documents. Previous works typically formulated layout reading\norder as a permutation of layout elements, i.e. a sequence containing all the\nlayout elements. However, we argue that this formulation does not adequately\nconvey the complete reading order information in the layout, which may\npotentially lead to performance decline in downstream VrD tasks. To address\nthis issue, we propose to model the layout reading order as ordering relations\nover the set of layout elements, which have sufficient expressive capability\nfor the complete reading order information. To enable empirical evaluation on\nmethods towards the improved form of reading order prediction (ROP), we\nestablish a comprehensive benchmark dataset including the reading order\nannotation as relations over layout elements, together with a\nrelation-extraction-based method that outperforms previous methods. Moreover,\nto highlight the practical benefits of introducing the improved form of layout\nreading order, we propose a reading-order-relation-enhancing pipeline to\nimprove model performance on any arbitrary VrD task by introducing additional\nreading order relation inputs. Comprehensive results demonstrate that the\npipeline generally benefits downstream VrD tasks: (1) with utilizing the\nreading order relation information, the enhanced downstream models achieve SOTA\nresults on both two task settings of the targeted dataset; (2) with utilizing\nthe pseudo reading order information generated by the proposed ROP model, the\nperformance of the enhanced models has improved across all three models and\neight cross-domain VrD-IE/QA task settings without targeted optimization.", "published": "2024-09-29 12:00:57", "link": "http://arxiv.org/abs/2409.19672v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Instruction Embedding: Latent Representations of Instructions Towards\n  Task Identification", "abstract": "Instruction data is crucial for improving the capability of Large Language\nModels (LLMs) to align with human-level performance. Recent research LIMA\ndemonstrates that alignment is essentially a process where the model adapts\ninstructions' interaction style or format to solve various tasks, leveraging\npre-trained knowledge and skills. Therefore, for instructional data, the most\nimportant aspect is the task it represents, rather than the specific semantics\nand knowledge information. The latent representations of instructions play\nroles for some instruction-related tasks like data selection and demonstrations\nretrieval. However, they are always derived from text embeddings, encompass\noverall semantic information that influences the representation of task\ncategories. In this work, we introduce a new concept, instruction embedding,\nand construct Instruction Embedding Benchmark (IEB) for its training and\nevaluation. Then, we propose a baseline Prompt-based Instruction Embedding\n(PIE) method to make the representations more attention on tasks. The\nevaluation of PIE, alongside other embedding methods on IEB with two designed\ntasks, demonstrates its superior performance in accurately identifying task\ncategories. Moreover, the application of instruction embeddings in four\ndownstream tasks showcases its effectiveness and suitability for\ninstruction-related tasks.", "published": "2024-09-29 12:12:24", "link": "http://arxiv.org/abs/2409.19680v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PEAR: Position-Embedding-Agnostic Attention Re-weighting Enhances\n  Retrieval-Augmented Generation with Zero Inference Overhead", "abstract": "Large language models (LLMs) enhanced with retrieval-augmented generation\n(RAG) have introduced a new paradigm for web search. However, the limited\ncontext awareness of LLMs degrades their performance on RAG tasks. Existing\nmethods to enhance context awareness are often inefficient, incurring time or\nmemory overhead during inference, and many are tailored to specific position\nembeddings. In this paper, we propose Position-Embedding-Agnostic attention\nRe-weighting (PEAR), which enhances the context awareness of LLMs with zero\ninference overhead. Specifically, on a proxy task focused on context copying,\nwe first detect heads which suppress the models' context awareness thereby\ndiminishing RAG performance. To weaken the impact of these heads, we re-weight\ntheir outputs with learnable coefficients. The LLM (with frozen parameters) is\noptimized by adjusting these coefficients to minimize loss on the proxy task.\nAs a result, the coefficients are optimized to values less than one, thereby\nreducing their tendency to suppress RAG performance. During inference, the\noptimized coefficients are fixed to re-weight these heads, regardless of the\nspecific task at hand. Our proposed PEAR offers two major advantages over\nprevious approaches: (1) It introduces zero additional inference overhead in\nterms of memory usage or inference time, while outperforming competitive\nbaselines in accuracy and efficiency across various RAG tasks. (2) It is\nindependent of position embedding algorithms, ensuring broader applicability.", "published": "2024-09-29 15:40:54", "link": "http://arxiv.org/abs/2409.19745v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AstroMLab 2: AstroLLaMA-2-70B Model and Benchmarking Specialised LLMs\n  for Astronomy", "abstract": "Continual pretraining of large language models on domain-specific data has\nbeen proposed to enhance performance on downstream tasks. In astronomy, the\nprevious absence of astronomy-focused benchmarks has hindered objective\nevaluation of these specialized LLM models. Leveraging a recent initiative to\ncurate high-quality astronomical MCQs, this study aims to quantitatively assess\nspecialized LLMs in astronomy. We find that the previously released AstroLLaMA\nseries, based on LLaMA-2-7B, underperforms compared to the base model. We\ndemonstrate that this performance degradation can be partially mitigated by\nutilizing high-quality data for continual pretraining, such as summarized text\nfrom arXiv. Despite the observed catastrophic forgetting in smaller models, our\nresults indicate that continual pretraining on the 70B model can yield\nsignificant improvements. However, the current supervised fine-tuning dataset\nstill constrains the performance of instruct models. In conjunction with this\nstudy, we introduce a new set of models, AstroLLaMA-3-8B and AstroLLaMA-2-70B,\nbuilding upon the previous AstroLLaMA series.", "published": "2024-09-29 16:02:22", "link": "http://arxiv.org/abs/2409.19750v1", "categories": ["astro-ph.IM", "cs.CL"], "primary_category": "astro-ph.IM"}
{"title": "Balancing Cost and Effectiveness of Synthetic Data Generation Strategies\n  for LLMs", "abstract": "As large language models (LLMs) are applied to more use cases, creating high\nquality, task-specific datasets for fine-tuning becomes a bottleneck for model\nimprovement. Using high quality human data has been the most common approach to\nunlock model performance, but is prohibitively expensive in many scenarios.\nSeveral alternative methods have also emerged, such as generating synthetic or\nhybrid data, but the effectiveness of these approaches remain unclear,\nespecially in resource-constrained scenarios and tasks that are not easily\nverified. To investigate this, we group various synthetic data generation\nstrategies into three representative categories -- Answer Augmentation,\nQuestion Rephrase and New Question -- and study the performance of student LLMs\ntrained under various constraints, namely seed instruction set size and query\nbudget. We demonstrate that these strategies are not equally effective across\nsettings. Notably, the optimal data generation strategy depends strongly on the\nratio between the available teacher query budget and the size of the seed\ninstruction set. When this ratio is low, generating new answers to existing\nquestions proves most effective, but as this ratio increases, generating new\nquestions becomes optimal. Across all tasks, we find that choice of\naugmentation method and other design choices matter substantially more in low\nto mid data regimes than in high data regimes. We provide a practical framework\nfor selecting the appropriate augmentation method across settings, taking into\naccount additional factors such as the scalability of each method, the\nimportance of verifying synthetic data, and the use of different LLMs for\nsynthetic data generation.", "published": "2024-09-29 20:14:50", "link": "http://arxiv.org/abs/2409.19759v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Robust Extractive Question Answering Models: Rethinking the\n  Training Methodology", "abstract": "This paper proposes a novel training method to improve the robustness of\nExtractive Question Answering (EQA) models. Previous research has shown that\nexisting models, when trained on EQA datasets that include unanswerable\nquestions, demonstrate a significant lack of robustness against distribution\nshifts and adversarial attacks. Despite this, the inclusion of unanswerable\nquestions in EQA training datasets is essential for ensuring real-world\nreliability. Our proposed training method includes a novel loss function for\nthe EQA problem and challenges an implicit assumption present in numerous EQA\ndatasets. Models trained with our method maintain in-domain performance while\nachieving a notable improvement on out-of-domain datasets. This results in an\noverall F1 score improvement of 5.7 across all testing sets. Furthermore, our\nmodels exhibit significantly enhanced robustness against two types of\nadversarial attacks, with a performance decrease of only about a third compared\nto the default models.", "published": "2024-09-29 20:35:57", "link": "http://arxiv.org/abs/2409.19766v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Video DataFlywheel: Resolving the Impossible Data Trinity in\n  Video-Language Understanding", "abstract": "Recently, video-language understanding has achieved great success through\nlarge-scale pre-training. However, data scarcity remains a prevailing\nchallenge. This study quantitatively reveals an \"impossible trinity\" among data\nquantity, diversity, and quality in pre-training datasets. Recent efforts seek\nto refine large-scale, diverse ASR datasets compromised by low quality through\nsynthetic annotations. These methods successfully leverage useful information\nin multimodal video content (frames, tags, ASR transcripts, etc.) to refine the\noriginal annotations. Nevertheless, they struggle to mitigate noise within\nsynthetic annotations and lack scalability as the dataset size expands. To\naddress these issues, we introduce the Video DataFlywheel framework, which\niteratively refines video annotations with improved noise control methods. For\niterative refinement, we first leverage a video-language model to generate\nsynthetic annotations, resulting in a refined dataset. Then, we pre-train on it\nand fine-tune on human refinement examples for a stronger model. These\nprocesses are repeated for continuous improvement. For noise control, we\npresent AdaTaiLr, a novel noise control method that requires weaker assumptions\non noise distribution, thereby proving more effective in large datasets with\ntheoretical guarantees. The combination of iterative refinement and AdaTaiLr\ncan achieve better scalability in video-language understanding. Extensive\nexperiments show that our framework outperforms existing data refinement\nbaselines, delivering a 3% performance boost and improving dataset quality with\nminimal diversity loss. Furthermore, our refined dataset facilitates\nsignificant improvements in various video-language understanding tasks,\nincluding video question answering and text-video retrieval.", "published": "2024-09-29 03:33:35", "link": "http://arxiv.org/abs/2409.19532v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Quantitative Analysis of Audio-Visual Tasks: An Information-Theoretic\n  Perspective", "abstract": "In the field of spoken language processing, audio-visual speech processing is\nreceiving increasing research attention. Key components of this research\ninclude tasks such as lip reading, audio-visual speech recognition, and\nvisual-to-speech synthesis. Although significant success has been achieved,\ntheoretical analysis is still insufficient for audio-visual tasks. This paper\npresents a quantitative analysis based on information theory, focusing on\ninformation intersection between different modalities. Our results show that\nthis analysis is valuable for understanding the difficulties of audio-visual\nprocessing tasks as well as the benefits that could be obtained by modality\nintegration.", "published": "2024-09-29 06:30:46", "link": "http://arxiv.org/abs/2409.19575v1", "categories": ["cs.SD", "cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Two-stage Framework for Robust Speech Emotion Recognition Using Target\n  Speaker Extraction in Human Speech Noise Conditions", "abstract": "Developing a robust speech emotion recognition (SER) system in noisy\nconditions faces challenges posed by different noise properties. Most previous\nstudies have not considered the impact of human speech noise, thus limiting the\napplication scope of SER. In this paper, we propose a novel two-stage framework\nfor the problem by cascading target speaker extraction (TSE) method and SER. We\nfirst train a TSE model to extract the speech of target speaker from a mixture.\nThen, in the second stage, we utilize the extracted speech for SER training.\nAdditionally, we explore a joint training of TSE and SER models in the second\nstage. Our developed system achieves a 14.33% improvement in unweighted\naccuracy (UA) compared to a baseline without using TSE method, demonstrating\nthe effectiveness of our framework in mitigating the impact of human speech\nnoise. Moreover, we conduct experiments considering speaker gender, showing\nthat our framework performs particularly well in different-gender mixture.", "published": "2024-09-29 07:04:50", "link": "http://arxiv.org/abs/2409.19585v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Hyper-Connections", "abstract": "We present hyper-connections, a simple yet effective method that can serve as\nan alternative to residual connections. This approach specifically addresses\ncommon drawbacks observed in residual connection variants, such as the seesaw\neffect between gradient vanishing and representation collapse. Theoretically,\nhyper-connections allow the network to adjust the strength of connections\nbetween features at different depths and dynamically rearrange layers. We\nconduct experiments focusing on the pre-training of large language models,\nincluding dense and sparse models, where hyper-connections show significant\nperformance improvements over residual connections. Additional experiments\nconducted on vision tasks also demonstrate similar improvements. We anticipate\nthat this method will be broadly applicable and beneficial across a wide range\nof AI problems.", "published": "2024-09-29 07:57:07", "link": "http://arxiv.org/abs/2409.19606v3", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Federated Learning from Vision-Language Foundation Models: Theoretical\n  Analysis and Method", "abstract": "Integrating pretrained vision-language foundation models like CLIP into\nfederated learning has attracted significant attention for enhancing\ngeneralization across diverse tasks. Typically, federated learning of\nvision-language models employs prompt learning to reduce communication and\ncomputational costs, i.e., prompt-based federated learning. However, there is\nlimited theoretical analysis to understand the performance of prompt-based\nfederated learning. In this work, we construct a theoretical analysis framework\nfor prompt-based federated learning via feature learning theory. Specifically,\nwe monitor the evolution of signal learning and noise memorization in\nprompt-based federated learning, demonstrating that performance can be assessed\nby the ratio of task-relevant to task-irrelevant coefficients. Furthermore, we\ndraw an analogy between income and risk in portfolio optimization and the\ntask-relevant and task-irrelevant terms in feature learning. Leveraging\ninspiration from portfolio optimization that combining two independent assets\nwill maintain the income while reducing the risk, we introduce two prompts:\nglobal prompt and local prompt to construct a prompt portfolio to balance the\ngeneralization and personalization. Consequently, we showed the performance\nadvantage of the prompt portfolio and derived the optimal mixing coefficient.\nThese theoretical claims have been further supported by empirical experiments.", "published": "2024-09-29 08:31:26", "link": "http://arxiv.org/abs/2409.19610v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "CRScore: Grounding Automated Evaluation of Code Review Comments in Code\n  Claims and Smells", "abstract": "The task of automated code review has recently gained a lot of attention from\nthe machine learning community. However, current review comment evaluation\nmetrics rely on comparisons with a human-written reference for a given code\nchange (also called a diff). Furthermore, code review is a one-to-many problem,\nlike generation and summarization, with many \"valid reviews\" for a diff. Thus,\nwe develop CRScore - a reference-free metric to measure dimensions of review\nquality like conciseness, comprehensiveness, and relevance. We design CRScore\nto evaluate reviews in a way that is grounded in claims and potential issues\ndetected in the code by LLMs and static analyzers. We demonstrate that CRScore\ncan produce valid, fine-grained scores of review quality that have the greatest\nalignment with human judgment among open source metrics (0.54 Spearman\ncorrelation) and are more sensitive than reference-based metrics. We also\nrelease a corpus of 2.9k human-annotated review quality scores for\nmachine-generated and GitHub review comments to support the development of\nautomated metrics.", "published": "2024-09-29 21:53:18", "link": "http://arxiv.org/abs/2409.19801v2", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Can Models Learn Skill Composition from Examples?", "abstract": "As large language models (LLMs) become increasingly advanced, their ability\nto exhibit compositional generalization -- the capacity to combine learned\nskills in novel ways not encountered during training -- has garnered\nsignificant attention. This type of generalization, particularly in scenarios\nbeyond training data, is also of great interest in the study of AI safety and\nalignment. A recent study introduced the SKILL-MIX evaluation, where models are\ntasked with composing a short paragraph demonstrating the use of a specified\n$k$-tuple of language skills. While small models struggled with composing even\nwith $k=3$, larger models like GPT-4 performed reasonably well with $k=5$ and\n$6$.\n  In this paper, we employ a setup akin to SKILL-MIX to evaluate the capacity\nof smaller models to learn compositional generalization from examples.\nUtilizing a diverse set of language skills -- including rhetorical, literary,\nreasoning, theory of mind, and common sense -- GPT-4 was used to generate text\nsamples that exhibit random subsets of $k$ skills. Subsequent fine-tuning of 7B\nand 13B parameter models on these combined skill texts, for increasing values\nof $k$, revealed the following findings: (1) Training on combinations of $k=2$\nand $3$ skills results in noticeable improvements in the ability to compose\ntexts with $k=4$ and $5$ skills, despite models never having seen such examples\nduring training. (2) When skill categories are split into training and held-out\ngroups, models significantly improve at composing texts with held-out skills\nduring testing despite having only seen training skills during fine-tuning,\nillustrating the efficacy of the training approach even with previously unseen\nskills. This study also suggests that incorporating skill-rich (potentially\nsynthetic) text into training can substantially enhance the compositional\ncapabilities of models.", "published": "2024-09-29 22:14:02", "link": "http://arxiv.org/abs/2409.19808v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Calibrating Language Models with Adaptive Temperature Scaling", "abstract": "The effectiveness of large language models (LLMs) is not only measured by\ntheir ability to generate accurate outputs but also by their calibration-how\nwell their confidence scores reflect the probability of their outputs being\ncorrect. While unsupervised pre-training has been shown to yield LLMs with\nwell-calibrated conditional probabilities, recent studies have shown that after\nfine-tuning with reinforcement learning from human feedback (RLHF), the\ncalibration of these models degrades significantly. In this work, we introduce\nAdaptive Temperature Scaling (ATS), a post-hoc calibration method that predicts\na temperature scaling parameter for each token prediction. The predicted\ntemperature values adapt based on token-level features and are fit over a\nstandard supervised fine-tuning (SFT) dataset. The adaptive nature of ATS\naddresses the varying degrees of calibration shift that can occur after RLHF\nfine-tuning. ATS improves calibration by over 10-50% across three downstream\nnatural language evaluation benchmarks compared to prior calibration methods\nand does not impede performance improvements from RLHF.", "published": "2024-09-29 22:54:31", "link": "http://arxiv.org/abs/2409.19817v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Human Bias in the Face of AI: The Role of Human Judgement in AI\n  Generated Text Evaluation", "abstract": "As AI advances in text generation, human trust in AI generated content\nremains constrained by biases that go beyond concerns of accuracy. This study\nexplores how bias shapes the perception of AI versus human generated content.\nThrough three experiments involving text rephrasing, news article\nsummarization, and persuasive writing, we investigated how human raters respond\nto labeled and unlabeled content. While the raters could not differentiate the\ntwo types of texts in the blind test, they overwhelmingly favored content\nlabeled as \"Human Generated,\" over those labeled \"AI Generated,\" by a\npreference score of over 30%. We observed the same pattern even when the labels\nwere deliberately swapped. This human bias against AI has broader societal and\ncognitive implications, as it undervalues AI performance. This study highlights\nthe limitations of human judgment in interacting with AI and offers a\nfoundation for improving human-AI collaboration, especially in creative fields.", "published": "2024-09-29 04:31:45", "link": "http://arxiv.org/abs/2410.03723v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "A multimodal LLM for the non-invasive decoding of spoken text from brain\n  recordings", "abstract": "Brain-related research topics in artificial intelligence have recently gained\npopularity, particularly due to the expansion of what multimodal architectures\ncan do from computer vision to natural language processing. Our main goal in\nthis work is to explore the possibilities and limitations of these\narchitectures in spoken text decoding from non-invasive fMRI recordings.\nContrary to vision and textual data, fMRI data represent a complex modality due\nto the variety of brain scanners, which implies (i) the variety of the recorded\nsignal formats, (ii) the low resolution and noise of the raw signals, and (iii)\nthe scarcity of pretrained models that can be leveraged as foundation models\nfor generative learning. These points make the problem of the non-invasive\ndecoding of text from fMRI recordings very challenging. In this paper, we\npropose and end-to-end multimodal LLM for decoding spoken text from fMRI\nsignals. The proposed architecture is founded on (i) an encoder derived from a\nspecific transformer incorporating an augmented embedding layer for the encoder\nand a better-adjusted attention mechanism than that present in the state of the\nart, and (ii) a frozen large language model adapted to align the embedding of\nthe input text and the encoded embedding of brain activity to decode the output\ntext. A benchmark in performed on a corpus consisting of a set of interactions\nhuman-human and human-robot interactions where fMRI and conversational signals\nare recorded synchronously. The obtained results are very promising, as our\nproposal outperforms the evaluated models, and is able to generate text\ncapturing more accurate semantics present in the ground truth. The\nimplementation code is provided in https://github.com/Hmamouche/brain_decode.", "published": "2024-09-29 14:03:39", "link": "http://arxiv.org/abs/2409.19710v1", "categories": ["q-bio.NC", "cs.CL", "cs.LG", "cs.SD", "eess.AS", "eess.SP", "q-bio.QM"], "primary_category": "q-bio.NC"}
{"title": "Improved Architecture for High-resolution Piano Transcription to\n  Efficiently Capture Acoustic Characteristics of Music Signals", "abstract": "Automatic music transcription (AMT), aiming to convert musical signals into\nmusical notation, is one of the important tasks in music information retrieval.\nRecently, previous works have applied high-resolution labels, i.e., the\ncontinuous onset and offset times of piano notes, as training targets,\nachieving substantial improvements in transcription performance. However, there\nstill remain some issues to be addressed, e.g., the harmonics of notes are\nsometimes recognized as false positive notes, and the size of AMT model tends\nto be larger to improve the transcription performance. To address these issues,\nwe propose an improved high-resolution piano transcription model to well\ncapture specific acoustic characteristics of music signals. First, we employ\nthe Constant-Q Transform as the input representation to better adapt to musical\nsignals. Moreover, we have designed two architectures: the first is based on a\nconvolutional recurrent neural network (CRNN) with dilated convolution, and the\nsecond is an encoder-decoder architecture that combines CRNN with a\nnon-autoregressive Transformer decoder. We conduct systematic experiments for\nour models. Compared to the high-resolution AMT system used as a baseline, our\nmodels effectively achieve 1) consistent improvement in note-level metrics, and\n2) the significant smaller model size, which shed lights on future work.", "published": "2024-09-29 08:53:16", "link": "http://arxiv.org/abs/2409.19614v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Efficient Long-Form Speech Recognition for General Speech In-Context\n  Learning", "abstract": "We propose a novel approach to end-to-end automatic speech recognition (ASR)\nto achieve efficient speech in-context learning (SICL) for (i) long-form speech\ndecoding, (ii) test-time speaker adaptation, and (iii) test-time contextual\nbiasing. Specifically, we introduce an attention-based encoder-decoder (AED)\nmodel with SICL capability (referred to as SICL-AED), where the decoder\nutilizes an utterance-level cross-attention to integrate information from the\nencoder's output efficiently, and a document-level self-attention to learn\ncontextual information. Evaluated on the benchmark TEDLIUM3 dataset, SICL-AED\nachieves an 8.64% relative word error rate (WER) reduction compared to a\nbaseline utterance-level AED model by leveraging previously decoded outputs as\nin-context examples. It also demonstrates comparable performance to\nconventional long-form AED systems with significantly reduced runtime and\nmemory complexity. Additionally, we introduce an in-context fine-tuning (ICFT)\ntechnique that further enhances SICL effectiveness during inference.\nExperiments on speaker adaptation and contextual biasing highlight the general\nspeech in-context learning capabilities of our system, achieving effective\nresults with provided contexts. Without specific fine-tuning, SICL-AED matches\nthe performance of supervised AED baselines for speaker adaptation and improves\nentity recall by 64% for contextual biasing task.", "published": "2024-09-29 20:08:36", "link": "http://arxiv.org/abs/2409.19757v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Guitar Pickups I: Analysis of the Effect of Winding and Wire Gauge on\n  Single Coil Electric Guitar Pickups", "abstract": "Guitar Pickups have been in production for nearly 100 years, and the question\nof how exactly one pickup is tonally superior to another is still subject to a\nhigh level of debate. This paper is the first in a set demystifying the\nproduction of guitar pickups and introducing a level of scientific procedure to\nthe conversation. Previous studies have analysed commercial off-the-shelf\npickups, but these differ from each other in multiple ways. The novelty of this\nstudy is that dedicated experimental pickups were created, which vary only one\nparameter at a time in order to allow scientific study. The most fundamental\nqualities of a single-coil pickup are investigated: in this paper, number of\nturns and gauge of wire. A set of single-coil stratocaster-style pickups were\ncreated, with the number of turns of wire varied across the commercially\navailable range (5000-12000 turns), and this was done for two widely used wire\ngauges (42 and 44 AWG). A frequency response analyser was used to obtain\nimpedance across a frequency range. It is shown that resonant frequency\ndecreases exponentially with number of turns, while the magnitude of the\nresonant peak increases linearly with number of turns. The wire gauge used has\na significant impact on both parameters, with the thicker wire giving higher\nresonant frequencies and higher magnitudes than the thinner wire for the same\nnumber of turns. These impact the sound associated with the pickup: the\nresonant frequency is linked to the perceived tone of the pickup, and the\nmagnitude to the output amplitude and hence 'gain.' Increasing the number of\nturns will give a higher output pickup with a darker tone, and thicker wire\ngives louder outputs and brighter tones - consistent with what can be observed\nin commercial pickups.", "published": "2024-09-29 21:10:48", "link": "http://arxiv.org/abs/2409.19782v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Fine-Tuning Automatic Speech Recognition for People with Parkinson's: An\n  Effective Strategy for Enhancing Speech Technology Accessibility", "abstract": "This paper enhances dysarthric and dysphonic speech recognition by\nfine-tuning pretrained automatic speech recognition (ASR) models on the\n2023-10-05 data package of the Speech Accessibility Project (SAP), which\ncontains the speech of 253 people with Parkinson's disease. Experiments tested\nmethods that have been effective for Cerebral Palsy, including the use of\nspeaker clustering and severity-dependent models, weighted fine-tuning, and\nmulti-task learning. Best results were obtained using a multi-task learning\nmodel, in which the ASR is trained to produce an estimate of the speaker's\nimpairment severity as an auxiliary output. The resulting word error rates are\nconsiderably improved relative to a baseline model fine-tuned using only\nLibrispeech data, with word error rate improvements of 37.62\\% and 26.97\\%\ncompared to fine-tuning on 100h and 960h of LibriSpeech data, respectively.", "published": "2024-09-29 22:56:01", "link": "http://arxiv.org/abs/2409.19818v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Learning Frame-Wise Emotion Intensity for Audio-Driven Talking-Head\n  Generation", "abstract": "Human emotional expression is inherently dynamic, complex, and fluid,\ncharacterized by smooth transitions in intensity throughout verbal\ncommunication. However, the modeling of such intensity fluctuations has been\nlargely overlooked by previous audio-driven talking-head generation methods,\nwhich often results in static emotional outputs. In this paper, we explore how\nemotion intensity fluctuates during speech, proposing a method for capturing\nand generating these subtle shifts for talking-head generation. Specifically,\nwe develop a talking-head framework that is capable of generating a variety of\nemotions with precise control over intensity levels. This is achieved by\nlearning a continuous emotion latent space, where emotion types are encoded\nwithin latent orientations and emotion intensity is reflected in latent norms.\nIn addition, to capture the dynamic intensity fluctuations, we adopt an\naudio-to-intensity predictor by considering the speaking tone that reflects the\nintensity. The training signals for this predictor are obtained through our\nemotion-agnostic intensity pseudo-labeling method without the need of\nframe-wise intensity labeling. Extensive experiments and analyses validate the\neffectiveness of our proposed method in accurately capturing and reproducing\nemotion intensity fluctuations in talking-head generation, thereby\nsignificantly enhancing the expressiveness and realism of the generated\noutputs.", "published": "2024-09-29 01:02:01", "link": "http://arxiv.org/abs/2409.19501v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Solution for Temporal Sound Localisation Task of ECCV Second Perception\n  Test Challenge 2024", "abstract": "This report proposes an improved method for the Temporal Sound Localisation\n(TSL) task, which localizes and classifies the sound events occurring in the\nvideo according to a predefined set of sound classes. The champion solution\nfrom last year's first competition has explored the TSL by fusing audio and\nvideo modalities with the same weight. Considering the TSL task aims to\nlocalize sound events, we conduct relevant experiments that demonstrated the\nsuperiority of sound features (Section 3). Based on our findings, to enhance\naudio modality features, we employ various models to extract audio features,\nsuch as InterVideo, CaVMAE, and VideoMAE models. Our approach ranks first in\nthe final test with a score of 0.4925.", "published": "2024-09-29 07:28:21", "link": "http://arxiv.org/abs/2409.19595v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "IDEAW: Robust Neural Audio Watermarking with Invertible Dual-Embedding", "abstract": "The audio watermarking technique embeds messages into audio and accurately\nextracts messages from the watermarked audio. Traditional methods develop\nalgorithms based on expert experience to embed watermarks into the time-domain\nor transform-domain of signals. With the development of deep neural networks,\ndeep learning-based neural audio watermarking has emerged. Compared to\ntraditional algorithms, neural audio watermarking achieves better robustness by\nconsidering various attacks during training. However, current neural\nwatermarking methods suffer from low capacity and unsatisfactory\nimperceptibility. Additionally, the issue of watermark locating, which is\nextremely important and even more pronounced in neural audio watermarking, has\nnot been adequately studied. In this paper, we design a dual-embedding\nwatermarking model for efficient locating. We also consider the impact of the\nattack layer on the invertible neural network in robustness training, improving\nthe model to enhance both its reasonableness and stability. Experiments show\nthat the proposed model, IDEAW, can withstand various attacks with higher\ncapacity and more efficient locating ability compared to existing methods.", "published": "2024-09-29 09:32:54", "link": "http://arxiv.org/abs/2409.19627v1", "categories": ["cs.MM", "cs.CR", "cs.SD", "eess.AS", "K.6.5; D.4.6"], "primary_category": "cs.MM"}
{"title": "PALM: Few-Shot Prompt Learning for Audio Language Models", "abstract": "Audio-Language Models (ALMs) have recently achieved remarkable success in\nzero-shot audio recognition tasks, which match features of audio waveforms with\nclass-specific text prompt features, inspired by advancements in\nVision-Language Models (VLMs). Given the sensitivity of zero-shot performance\nto the choice of hand-crafted text prompts, many prompt learning techniques\nhave been developed for VLMs. We explore the efficacy of these approaches in\nALMs and propose a novel method, Prompt Learning in Audio Language Models\n(PALM), which optimizes the feature space of the text encoder branch. Unlike\nexisting methods that work in the input space, our approach results in greater\ntraining efficiency. We demonstrate the effectiveness of our approach on 11\naudio recognition datasets, encompassing a variety of speech-processing tasks,\nand compare the results with three baselines in a few-shot learning setup. Our\nmethod is either on par with or outperforms other approaches while being\ncomputationally less demanding. Code is available at\nhttps://asif-hanif.github.io/palm/", "published": "2024-09-29 22:06:07", "link": "http://arxiv.org/abs/2409.19806v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "InfantCryNet: A Data-driven Framework for Intelligent Analysis of Infant\n  Cries", "abstract": "Understanding the meaning of infant cries is a significant challenge for\nyoung parents in caring for their newborns. The presence of background noise\nand the lack of labeled data present practical challenges in developing systems\nthat can detect crying and analyze its underlying reasons. In this paper, we\npresent a novel data-driven framework, \"InfantCryNet,\" for accomplishing these\ntasks. To address the issue of data scarcity, we employ pre-trained audio\nmodels to incorporate prior knowledge into our model. We propose the use of\nstatistical pooling and multi-head attention pooling techniques to extract\nfeatures more effectively. Additionally, knowledge distillation and model\nquantization are applied to enhance model efficiency and reduce the model size,\nbetter supporting industrial deployment in mobile devices. Experiments on\nreal-life datasets demonstrate the superior performance of the proposed\nframework, outperforming state-of-the-art baselines by 4.4% in classification\naccuracy. The model compression effectively reduces the model size by 7%\nwithout compromising performance and by up to 28% with only an 8% decrease in\naccuracy, offering practical insights for model selection and system design.", "published": "2024-09-29 12:35:47", "link": "http://arxiv.org/abs/2409.19689v2", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
