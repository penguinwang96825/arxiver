{"title": "HLT@SUDA at SemEval 2019 Task 1: UCCA Graph Parsing as Constituent Tree\n  Parsing", "abstract": "This paper describes a simple UCCA semantic graph parsing approach. The key\nidea is to convert a UCCA semantic graph into a constituent tree, in which\nextra labels are deliberately designed to mark remote edges and discontinuous\nnodes for future recovery. In this way, we can make use of existing syntactic\nparsing techniques. Based on the data statistics, we recover discontinuous\nnodes directly according to the output labels of the constituent parser and use\na biaffine classification model to recover the more complex remote edges. The\nclassification model and the constituent parser are simultaneously trained\nunder the multi-task learning framework. We use the multilingual BERT as extra\nfeatures in the open tracks. Our system ranks the first place in the six\nEnglish/German closed/open tracks among seven participating systems. For the\nseventh cross-lingual track, where there is little training data for French, we\npropose a language embedding approach to utilize English and German training\ndata, and our result ranks the second place.", "published": "2019-03-11 07:46:03", "link": "http://arxiv.org/abs/1903.04153v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Partially Shuffling the Training Data to Improve Language Models", "abstract": "Although SGD requires shuffling the training data between epochs, currently\nnone of the word-level language modeling systems do this. Naively shuffling all\nsentences in the training data would not permit the model to learn\ninter-sentence dependencies. Here we present a method that partially shuffles\nthe training data between epochs. This method makes each batch random, while\nkeeping most sentence ordering intact. It achieves new state of the art results\non word-level language modeling on both the Penn Treebank and WikiText-2\ndatasets.", "published": "2019-03-11 08:20:13", "link": "http://arxiv.org/abs/1903.04167v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toward Fast and Accurate Neural Chinese Word Segmentation with\n  Multi-Criteria Learning", "abstract": "The ambiguous annotation criteria lead to divergence of Chinese Word\nSegmentation (CWS) datasets in various granularities. Multi-criteria Chinese\nword segmentation aims to capture various annotation criteria among datasets\nand leverage their common underlying knowledge. In this paper, we propose a\ndomain adaptive segmenter to exploit diverse criteria of various datasets. Our\nmodel is based on Bidirectional Encoder Representations from Transformers\n(BERT), which is responsible for introducing open-domain knowledge. Private and\nshared projection layers are proposed to capture domain-specific knowledge and\ncommon knowledge, respectively. We also optimize computational efficiency via\ndistillation, quantization, and compiler optimization. Experiments show that\nour segmenter outperforms the previous state of the art (SOTA) models on 10 CWS\ndatasets with superior efficiency.", "published": "2019-03-11 09:48:39", "link": "http://arxiv.org/abs/1903.04190v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ETNLP: a visual-aided systematic approach to select pre-trained\n  embeddings for a downstream task", "abstract": "Given many recent advanced embedding models, selecting pre-trained word\nembedding (a.k.a., word representation) models best fit for a specific\ndownstream task is non-trivial. In this paper, we propose a systematic\napproach, called ETNLP, for extracting, evaluating, and visualizing multiple\nsets of pre-trained word embeddings to determine which embeddings should be\nused in a downstream task. For extraction, we provide a method to extract\nsubsets of the embeddings to be used in the downstream task. For evaluation, we\nanalyse the quality of pre-trained embeddings using an input word analogy list.\nFinally, we visualize the word representations in the embedding space to\nexplore the embedded words interactively.\n  We demonstrate the effectiveness of the proposed approach on our pre-trained\nword embedding models in Vietnamese to select which models are suitable for a\nnamed entity recognition (NER) task. Specifically, we create a large Vietnamese\nword analogy list to evaluate and select the pre-trained embedding models for\nthe task. We then utilize the selected embeddings for the NER task and achieve\nthe new state-of-the-art results on the task benchmark dataset. We also apply\nthe approach to another downstream task of privacy-guaranteed embedding\nselection, and show that it helps users quickly select the most suitable\nembeddings. In addition, we create an open-source system using the proposed\nsystematic approach to facilitate similar studies on other NLP tasks. The\nsource code and data are available at https://github.com/vietnlp/etnlp.", "published": "2019-03-11 16:48:25", "link": "http://arxiv.org/abs/1903.04433v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Truth and Nothing but the Truth: Multimodal Analysis for Deception\n  Detection", "abstract": "We propose a data-driven method for automatic deception detection in\nreal-life trial data using visual and verbal cues. Using OpenFace with facial\naction unit recognition, we analyze the movement of facial features of the\nwitness when posed with questions and the acoustic patterns using OpenSmile. We\nthen perform a lexical analysis on the spoken words, emphasizing the use of\npauses and utterance breaks, feeding that to a Support Vector Machine to test\ndeceit or truth prediction. We then try out a method to incorporate\nutterance-based fusion of visual and lexical analysis, using string based\nmatching.", "published": "2019-03-11 18:11:23", "link": "http://arxiv.org/abs/1903.04484v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Practical Semantic Parsing for Spoken Language Understanding", "abstract": "Executable semantic parsing is the task of converting natural language\nutterances into logical forms that can be directly used as queries to get a\nresponse. We build a transfer learning framework for executable semantic\nparsing. We show that the framework is effective for Question Answering (Q&A)\nas well as for Spoken Language Understanding (SLU). We further investigate the\ncase where a parser on a new domain can be learned by exploiting data on other\ndomains, either via multi-task learning between the target domain and an\nauxiliary domain or via pre-training on the auxiliary domain and fine-tuning on\nthe target domain. With either flavor of transfer learning, we are able to\nimprove performance on most domains; we experiment with public data sets such\nas Overnight and NLmaps as well as with commercial SLU data. The experiments\ncarried out on data sets that are different in nature show how executable\nsemantic parsing can unify different areas of NLP such as Q&A and SLU.", "published": "2019-03-11 18:12:28", "link": "http://arxiv.org/abs/1903.04521v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Un duel probabiliste pour d\u00e9partager deux pr\u00e9sidents (LIA @\n  DEFT'2005)", "abstract": "We present a set of probabilistic models applied to binary classification as\ndefined in the DEFT'05 challenge. The challenge consisted a mixture of two\ndifferents problems in Natural Language Processing : identification of author\n(a sequence of Fran\\c{c}ois Mitterrand's sentences might have been inserted\ninto a speech of Jacques Chirac) and thematic break detection (the subjects\naddressed by the two authors are supposed to be different). Markov chains,\nBayes models and an adaptative process have been used to identify the paternity\nof these sequences. A probabilistic model of the internal coherence of speeches\nwhich has been employed to identify thematic breaks. Adding this model has\nshown to improve the quality results. A comparison with different approaches\ndemostrates the superiority of a strategy that combines learning, coherence and\nadaptation. Applied to the DEFT'05 data test the results in terms of precision\n(0.890), recall (0.955) and Fscore (0.925) measure are very promising.", "published": "2019-03-11 11:02:24", "link": "http://arxiv.org/abs/1903.07397v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Redditors in Recovery: Text Mining Reddit to Investigate Transitions\n  into Drug Addiction", "abstract": "Increasing rates of opioid drug abuse and heightened prevalence of online\nsupport communities underscore the necessity of employing data mining\ntechniques to better understand drug addiction using these rapidly developing\nonline resources. In this work, we obtain data from Reddit, an online\ncollection of forums, to gather insight into drug use/misuse using text data\nfrom users themselves. Specifically, using user posts, we trained 1) a binary\nclassifier which predicts transitions from casual drug discussion forums to\ndrug recovery forums and 2) a Cox regression model that outputs likelihoods of\nsuch transitions. In doing so, we found that utterances of select drugs and\ncertain linguistic features contained in one's posts can help predict these\ntransitions. Using unfiltered drug-related posts, our research delineates drugs\nthat are associated with higher rates of transitions from recreational drug\ndiscussion to support/recovery discussion, offers insight into modern drug\nculture, and provides tools with potential applications in combating the opioid\ncrisis.", "published": "2019-03-11 00:10:29", "link": "http://arxiv.org/abs/1903.04081v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "An Innovative Word Encoding Method For Text Classification Using\n  Convolutional Neural Network", "abstract": "Text classification plays a vital role today especially with the intensive\nuse of social networking media. Recently, different architectures of\nconvolutional neural networks have been used for text classification in which\none-hot vector, and word embedding methods are commonly used. This paper\npresents a new language independent word encoding method for text\nclassification. The proposed model converts raw text data to low-level feature\ndimension with minimal or no preprocessing steps by using a new approach called\nbinary unique number of word \"BUNOW\". BUNOW allows each unique word to have an\ninteger ID in a dictionary that is represented as a k-dimensional vector of its\nbinary equivalent. The output vector of this encoding is fed into a\nconvolutional neural network (CNN) model for classification. Moreover, the\nproposed model reduces the neural network parameters, allows faster computation\nwith few network layers, where a word is atomic representation the document as\nin word level, and decrease memory consumption for character level\nrepresentation. The provided CNN model is able to work with other languages or\nmulti-lingual text without the need for any changes in the encoding method. The\nmodel outperforms the character level and very deep character level CNNs models\nin terms of accuracy, network parameters, and memory consumption; the results\nshow total classification accuracy 91.99% and error 8.01% using AG's News\ndataset compared to the state of art methods that have total classification\naccuracy 91.45% and error 8.55%, in addition to the reduction in input feature\nvector and neural network parameters by 62% and 34%, respectively.", "published": "2019-03-11 07:08:39", "link": "http://arxiv.org/abs/1903.04146v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Text-to-Speech System with Seq2Seq Model", "abstract": "Recent trends in neural network based text-to-speech/speech synthesis\npipelines have employed recurrent Seq2seq architectures that can synthesize\nrealistic sounding speech directly from text characters. These systems however\nhave complex architectures and takes a substantial amount of time to train. We\nintroduce several modifications to these Seq2seq architectures that allow for\nfaster training time, and also allows us to reduce the complexity of the model\narchitecture at the same time. We show that our proposed model can achieve\nattention alignment much faster than previous architectures and that good audio\nquality can be achieved with a model that's much smaller in size. Sample audio\navailable at https://soundcloud.com/gary-wang-23/sets/tts-samples-for-cmpt-419.", "published": "2019-03-11 18:18:38", "link": "http://arxiv.org/abs/1903.07398v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Scaling in Words on Twitter", "abstract": "Scaling properties of language are a useful tool for understanding generative\nprocesses in texts. We investigate the scaling relations in citywise Twitter\ncorpora coming from the Metropolitan and Micropolitan Statistical Areas of the\nUnited States. We observe a slightly superlinear urban scaling with the city\npopulation for the total volume of the tweets and words created in a city. We\nthen find that a certain core vocabulary follows the scaling relationship of\nthat of the bulk text, but most words are sensitive to city size, exhibiting a\nsuper- or a sublinear urban scaling. For both regimes we can offer a plausible\nexplanation based on the meaning of the words. We also show that the parameters\nfor Zipf's law and Heaps law differ on Twitter from that of other texts, and\nthat the exponent of Zipf's law changes with city size.", "published": "2019-03-11 14:41:07", "link": "http://arxiv.org/abs/1903.04329v1", "categories": ["physics.soc-ph", "cs.CL", "cs.SI"], "primary_category": "physics.soc-ph"}
{"title": "Nuanced Metrics for Measuring Unintended Bias with Real Data for Text\n  Classification", "abstract": "Unintended bias in Machine Learning can manifest as systemic differences in\nperformance for different demographic groups, potentially compounding existing\nchallenges to fairness in society at large. In this paper, we introduce a suite\nof threshold-agnostic metrics that provide a nuanced view of this unintended\nbias, by considering the various ways that a classifier's score distribution\ncan vary across designated groups. We also introduce a large new test set of\nonline comments with crowd-sourced annotations for identity references. We use\nthis to show how our metrics can be used to find new and potentially subtle\nunintended bias in existing public models.", "published": "2019-03-11 19:45:54", "link": "http://arxiv.org/abs/1903.04561v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Bridging the Gap Between Monaural Speech Enhancement and Recognition\n  with Distortion-Independent Acoustic Modeling", "abstract": "Monaural speech enhancement has made dramatic advances since the introduction\nof deep learning a few years ago. Although enhanced speech has been\ndemonstrated to have better intelligibility and quality for human listeners,\nfeeding it directly to automatic speech recognition (ASR) systems trained with\nnoisy speech has not produced expected improvements in ASR performance. The\nlack of an enhancement benefit on recognition, or the gap between monaural\nspeech enhancement and recognition, is often attributed to speech distortions\nintroduced in the enhancement process. In this study, we analyze the distortion\nproblem, compare different acoustic models, and investigate a\ndistortion-independent training scheme for monaural speech recognition.\nExperimental results suggest that distortion-independent acoustic modeling is\nable to overcome the distortion problem. Such an acoustic model can also work\nwith speech enhancement models different from the one used during training.\nMoreover, the models investigated in this paper outperform the previous best\nsystem on the CHiME-2 corpus.", "published": "2019-03-11 19:51:34", "link": "http://arxiv.org/abs/1903.04567v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Singing voice conversion with non-parallel data", "abstract": "Singing voice conversion is a task to convert a song sang by a source singer\nto the voice of a target singer. In this paper, we propose using a parallel\ndata free, many-to-one voice conversion technique on singing voices. A phonetic\nposterior feature is first generated by decoding singing voices through a\nrobust Automatic Speech Recognition Engine (ASR). Then, a trained Recurrent\nNeural Network (RNN) with a Deep Bidirectional Long Short Term Memory (DBLSTM)\nstructure is used to model the mapping from person-independent content to the\nacoustic features of the target person. F0 and aperiodic are obtained through\nthe original singing voice, and used with acoustic features to reconstruct the\ntarget singing voice through a vocoder. In the obtained singing voice, the\ntargeted and sourced singers sound similar. To our knowledge, this is the first\nstudy that uses non parallel data to train a singing voice conversion system.\nSubjective evaluations demonstrate that the proposed method effectively\nconverts singing voices.", "published": "2019-03-11 04:52:36", "link": "http://arxiv.org/abs/1903.04124v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
