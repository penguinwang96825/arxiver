{"title": "Empower Entity Set Expansion via Language Model Probing", "abstract": "Entity set expansion, aiming at expanding a small seed entity set with new\nentities belonging to the same semantic class, is a critical task that benefits\nmany downstream NLP and IR applications, such as question answering, query\nunderstanding, and taxonomy construction. Existing set expansion methods\nbootstrap the seed entity set by adaptively selecting context features and\nextracting new entities. A key challenge for entity set expansion is to avoid\nselecting ambiguous context features which will shift the class semantics and\nlead to accumulative errors in later iterations. In this study, we propose a\nnovel iterative set expansion framework that leverages automatically generated\nclass names to address the semantic drift issue. In each iteration, we select\none positive and several negative class names by probing a pre-trained language\nmodel, and further score each candidate entity based on selected class names.\nExperiments on two datasets show that our framework generates high-quality\nclass names and outperforms previous state-of-the-art methods significantly.", "published": "2020-04-29 00:09:43", "link": "http://arxiv.org/abs/2004.13897v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting Pre-Trained Models for Chinese Natural Language Processing", "abstract": "Bidirectional Encoder Representations from Transformers (BERT) has shown\nmarvelous improvements across various NLP tasks, and consecutive variants have\nbeen proposed to further improve the performance of the pre-trained language\nmodels. In this paper, we target on revisiting Chinese pre-trained language\nmodels to examine their effectiveness in a non-English language and release the\nChinese pre-trained language model series to the community. We also propose a\nsimple but effective model called MacBERT, which improves upon RoBERTa in\nseveral ways, especially the masking strategy that adopts MLM as correction\n(Mac). We carried out extensive experiments on eight Chinese NLP tasks to\nrevisit the existing pre-trained language models as well as the proposed\nMacBERT. Experimental results show that MacBERT could achieve state-of-the-art\nperformances on many NLP tasks, and we also ablate details with several\nfindings that may help future research. Resources available:\nhttps://github.com/ymcui/MacBERT", "published": "2020-04-29 02:08:30", "link": "http://arxiv.org/abs/2004.13922v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Transformer-Based Multilingual Text Classification", "abstract": "As NLP tools become ubiquitous in today's technological landscape, they are\nincreasingly applied to languages with a variety of typological structures.\nHowever, NLP research does not focus primarily on typological differences in\nits analysis of state-of-the-art language models. As a result, NLP tools\nperform unequally across languages with different syntactic and morphological\nstructures. Through a detailed discussion of word order typology, morphological\ntypology, and comparative linguistics, we identify which variables most affect\nlanguage modeling efficacy; in addition, we calculate word order and\nmorphological similarity indices to aid our empirical study. We then use this\nbackground to support our analysis of an experiment we conduct using\nmulti-class text classification on eight languages and eight models.", "published": "2020-04-29 03:34:53", "link": "http://arxiv.org/abs/2004.13939v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linguistic Resources for Bhojpuri, Magahi and Maithili: Statistics about\n  them, their Similarity Estimates, and Baselines for Three Applications", "abstract": "Corpus preparation for low-resource languages and for development of human\nlanguage technology to analyze or computationally process them is a laborious\ntask, primarily due to the unavailability of expert linguists who are native\nspeakers of these languages and also due to the time and resources required.\nBhojpuri, Magahi, and Maithili, languages of the Purvanchal region of India (in\nthe north-eastern parts), are low-resource languages belonging to the\nIndo-Aryan (or Indic) family. They are closely related to Hindi, which is a\nrelatively high-resource language, which is why we compare with Hindi. We\ncollected corpora for these three languages from various sources and cleaned\nthem to the extent possible, without changing the data in them. The text\nbelongs to different domains and genres. We calculated some basic statistical\nmeasures for these corpora at character, word, syllable, and morpheme levels.\nThese corpora were also annotated with parts-of-speech (POS) and chunk tags.\nThe basic statistical measures were both absolute and relative and were\nexptected to indicate of linguistic properties such as morphological, lexical,\nphonological, and syntactic complexities (or richness). The results were\ncompared with a standard Hindi corpus. For most of the measures, we tried to\nthe corpus size the same across the languages to avoid the effect of corpus\nsize, but in some cases it turned out that using the full corpus was better,\neven if sizes were very different. Although the results are not very clear, we\ntry to draw some conclusions about the languages and the corpora. For POS\ntagging and chunking, the BIS tagset was used to manually annotate the data.\nThe POS tagged data sizes are 16067, 14669 and 12310 sentences, respectively,\nfor Bhojpuri, Magahi and Maithili. The sizes for chunking are 9695 and 1954\nsentences for Bhojpuri and Maithili, respectively.", "published": "2020-04-29 03:58:55", "link": "http://arxiv.org/abs/2004.13945v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BURT: BERT-inspired Universal Representation from Twin Structure", "abstract": "Pre-trained contextualized language models such as BERT have shown great\neffectiveness in a wide range of downstream Natural Language Processing (NLP)\ntasks. However, the effective representations offered by the models target at\neach token inside a sequence rather than each sequence and the fine-tuning step\ninvolves the input of both sequences at one time, leading to unsatisfying\nrepresentations of various sequences with different granularities. Especially,\nas sentence-level representations taken as the full training context in these\nmodels, there comes inferior performance on lower-level linguistic units\n(phrases and words). In this work, we present BURT (BERT inspired Universal\nRepresentation from Twin Structure) that is capable of generating universal,\nfixed-size representations for input sequences of any granularity, i.e., words,\nphrases, and sentences, using a large scale of natural language inference and\nparaphrase data with multiple training objectives. Our proposed BURT adopts the\nSiamese network, learning sentence-level representations from natural language\ninference dataset and word/phrase-level representations from paraphrasing\ndataset, respectively. We evaluate BURT across different granularities of text\nsimilarity tasks, including STS tasks, SemEval2013 Task 5(a) and some commonly\nused word similarity tasks, where BURT substantially outperforms other\nrepresentation models on sentence-level datasets and achieves significant\nimprovements in word/phrase-level representation.", "published": "2020-04-29 04:01:52", "link": "http://arxiv.org/abs/2004.13947v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Augmentation for Spoken Language Understanding via Pretrained\n  Language Models", "abstract": "The training of spoken language understanding (SLU) models often faces the\nproblem of data scarcity. In this paper, we put forward a data augmentation\nmethod using pretrained language models to boost the variability and accuracy\nof generated utterances. Furthermore, we investigate and propose solutions to\ntwo previously overlooked semi-supervised learning scenarios of data scarcity\nin SLU: i) Rich-in-Ontology: ontology information with numerous valid dialogue\nacts is given; ii) Rich-in-Utterance: a large number of unlabelled utterances\nare available. Empirical results show that our method can produce synthetic\ntraining data that boosts the performance of language understanding models in\nvarious scenarios.", "published": "2020-04-29 04:07:12", "link": "http://arxiv.org/abs/2004.13952v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-shot topic generation", "abstract": "We present an approach to generating topics using a model trained only for\ndocument title generation, with zero examples of topics given during training.\nWe leverage features that capture the relevance of a candidate span in a\ndocument for the generation of a title for that document. The output is a\nweighted collection of the phrases that are most relevant for describing the\ndocument and distinguishing it within a corpus, without requiring access to the\nrest of the corpus. We conducted a double-blind trial in which human annotators\nscored the quality of our machine-generated topics along with original\nhuman-written topics associated with news articles from The Guardian and The\nHuffington Post. The results show that our zero-shot model generates topic\nlabels for news documents that are on average equal to or higher quality than\nthose written by humans, as judged by humans.", "published": "2020-04-29 04:39:28", "link": "http://arxiv.org/abs/2004.13956v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conditional Neural Generation using Sub-Aspect Functions for Extractive\n  News Summarization", "abstract": "Much progress has been made in text summarization, fueled by neural\narchitectures using large-scale training corpora. However, in the news domain,\nneural models easily overfit by leveraging position-related features due to the\nprevalence of the inverted pyramid writing style. In addition, there is an\nunmet need to generate a variety of summaries for different users. In this\npaper, we propose a neural framework that can flexibly control summary\ngeneration by introducing a set of sub-aspect functions (i.e. importance,\ndiversity, position). These sub-aspect functions are regulated by a set of\ncontrol codes to decide which sub-aspect to focus on during summary generation.\nWe demonstrate that extracted summaries with minimal position bias is\ncomparable with those generated by standard models that take advantage of\nposition preference. We also show that news summaries generated with a focus on\ndiversity can be more preferred by human raters. These results suggest that a\nmore flexible neural summarization framework providing more control options\ncould be desirable in tailoring to different user preferences, which is useful\nsince it is often impractical to articulate such preferences for different\napplications a priori.", "published": "2020-04-29 06:52:15", "link": "http://arxiv.org/abs/2004.13983v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledgeable Dialogue Reading Comprehension on Key Turns", "abstract": "Multi-choice machine reading comprehension (MRC) requires models to choose\nthe correct answer from candidate options given a passage and a question. Our\nresearch focuses dialogue-based MRC, where the passages are multi-turn\ndialogues. It suffers from two challenges, the answer selection decision is\nmade without support of latently helpful commonsense, and the multi-turn\ncontext may hide considerable irrelevant information. This work thus makes the\nfirst attempt to tackle those two challenges by extracting substantially\nimportant turns and utilizing external knowledge to enhance the representation\nof context. In this paper, the relevance of each turn to the question are\ncalculated to choose key turns. Besides, terms related to the context and the\nquestion in a knowledge graph are extracted as external knowledge. The original\ncontext, question and external knowledge are encoded with the pre-trained\nlanguage model, then the language representation and key turns are combined\ntogether with a will-designed mechanism to predict the answer. Experimental\nresults on a DREAM dataset show that our proposed model achieves great\nimprovements on baselines.", "published": "2020-04-29 07:04:43", "link": "http://arxiv.org/abs/2004.13988v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking Robustness of Machine Reading Comprehension Models", "abstract": "Machine Reading Comprehension (MRC) is an important testbed for evaluating\nmodels' natural language understanding (NLU) ability. There has been rapid\nprogress in this area, with new models achieving impressive performance on\nvarious benchmarks. However, existing benchmarks only evaluate models on\nin-domain test sets without considering their robustness under test-time\nperturbations or adversarial attacks. To fill this important gap, we construct\nAdvRACE (Adversarial RACE), a new model-agnostic benchmark for evaluating the\nrobustness of MRC models under four different types of adversarial attacks,\nincluding our novel distractor extraction and generation attacks. We show that\nstate-of-the-art (SOTA) models are vulnerable to all of these attacks. We\nconclude that there is substantial room for building more robust MRC models and\nour benchmark can help motivate and measure progress in this area. We release\nour data and code at https://github.com/NoviScl/AdvRACE .", "published": "2020-04-29 08:05:32", "link": "http://arxiv.org/abs/2004.14004v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Filtering Noisy Dialogue Corpora by Connectivity and Content Relatedness", "abstract": "Large-scale dialogue datasets have recently become available for training\nneural dialogue agents. However, these datasets have been reported to contain a\nnon-negligible number of unacceptable utterance pairs. In this paper, we\npropose a method for scoring the quality of utterance pairs in terms of their\nconnectivity and relatedness. The proposed scoring method is designed based on\nfindings widely shared in the dialogue and linguistics research communities. We\ndemonstrate that it has a relatively good correlation with the human judgment\nof dialogue quality. Furthermore, the method is applied to filter out\npotentially unacceptable utterance pairs from a large-scale noisy dialogue\ncorpus to ensure its quality. We experimentally confirm that training data\nfiltered by the proposed method improves the quality of neural dialogue agents\nin response generation.", "published": "2020-04-29 08:08:32", "link": "http://arxiv.org/abs/2004.14008v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multiscale Collaborative Deep Models for Neural Machine Translation", "abstract": "Recent evidence reveals that Neural Machine Translation (NMT) models with\ndeeper neural networks can be more effective but are difficult to train. In\nthis paper, we present a MultiScale Collaborative (MSC) framework to ease the\ntraining of NMT models that are substantially deeper than those used\npreviously. We explicitly boost the gradient back-propagation from top to\nbottom levels by introducing a block-scale collaboration mechanism into deep\nNMT models. Then, instead of forcing the whole encoder stack directly learns a\ndesired representation, we let each encoder block learns a fine-grained\nrepresentation and enhance it by encoding spatial dependencies using a\ncontext-scale collaboration. We provide empirical evidence showing that the MSC\nnets are easy to optimize and can obtain improvements of translation quality\nfrom considerably increased depth. On IWSLT translation tasks with three\ntranslation directions, our extremely deep models (with 72-layer encoders)\nsurpass strong baselines by +2.2~+3.1 BLEU points. In addition, our deep MSC\nachieves a BLEU score of 30.56 on WMT14 English-German task that significantly\noutperforms state-of-the-art deep NMT models.", "published": "2020-04-29 08:36:08", "link": "http://arxiv.org/abs/2004.14021v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Morphological Disambiguation of South S\u00e1mi with FSTs and Neural\n  Networks", "abstract": "We present a method for conducting morphological disambiguation for South\nS\\'ami, which is an endangered language. Our method uses an FST-based\nmorphological analyzer to produce an ambiguous set of morphological readings\nfor each word in a sentence. These readings are disambiguated with a Bi-RNN\nmodel trained on the related North S\\'ami UD Treebank and some synthetically\ngenerated South S\\'ami data. The disambiguation is done on the level of\nmorphological tags ignoring word forms and lemmas; this makes it possible to\nuse North S\\'ami training data for South S\\'ami without the need for a\nbilingual dictionary or aligned word embeddings. Our approach requires only\nminimal resources for South S\\'ami, which makes it usable and applicable in the\ncontexts of any other endangered language as well.", "published": "2020-04-29 10:30:25", "link": "http://arxiv.org/abs/2004.14062v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatically Identifying Gender Issues in Machine Translation using\n  Perturbations", "abstract": "The successful application of neural methods to machine translation has\nrealized huge quality advances for the community. With these improvements, many\nhave noted outstanding challenges, including the modeling and treatment of\ngendered language. While previous studies have identified issues using\nsynthetic examples, we develop a novel technique to mine examples from real\nworld data to explore challenges for deployed systems. We use our method to\ncompile an evaluation benchmark spanning examples for four languages from three\nlanguage families, which we publicly release to facilitate research. The\nexamples in our benchmark expose where model representations are gendered, and\nthe unintended consequences these gendered representations can have in\ndownstream application.", "published": "2020-04-29 10:38:09", "link": "http://arxiv.org/abs/2004.14065v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Long Context for Task-Oriented Dialogue State Generation", "abstract": "Based on the recently proposed transferable dialogue state generator (TRADE)\nthat predicts dialogue states from utterance-concatenated dialogue context, we\npropose a multi-task learning model with a simple yet effective utterance\ntagging technique and a bidirectional language model as an auxiliary task for\ntask-oriented dialogue state generation. By enabling the model to learn a\nbetter representation of the long dialogue context, our approaches attempt to\nsolve the problem that the performance of the baseline significantly drops when\nthe input dialogue context sequence is long. In our experiments, our proposed\nmodel achieves a 7.03% relative improvement over the baseline, establishing a\nnew state-of-the-art joint goal accuracy of 52.04% on the MultiWOZ 2.0 dataset.", "published": "2020-04-29 11:02:25", "link": "http://arxiv.org/abs/2004.14080v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Subword Regularization for Robust Neural Machine Translation", "abstract": "Exposing diverse subword segmentations to neural machine translation (NMT)\nmodels often improves the robustness of machine translation as NMT models can\nexperience various subword candidates. However, the diversification of subword\nsegmentations mostly relies on the pre-trained subword language models from\nwhich erroneous segmentations of unseen words are less likely to be sampled. In\nthis paper, we present adversarial subword regularization (ADVSR) to study\nwhether gradient signals during training can be a substitute criterion for\nexposing diverse subword segmentations. We experimentally show that our\nmodel-based adversarial samples effectively encourage NMT models to be less\nsensitive to segmentation errors and improve the performance of NMT models in\nlow-resource and out-domain datasets.", "published": "2020-04-29 12:06:42", "link": "http://arxiv.org/abs/2004.14109v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entity Candidate Network for Whole-Aware Named Entity Recognition", "abstract": "Named Entity Recognition (NER) is a crucial upstream task in Natural Language\nProcessing (NLP). Traditional tag scheme approaches offer a single recognition\nthat does not meet the needs of many downstream tasks such as coreference\nresolution. Meanwhile, Tag scheme approaches ignore the continuity of entities.\nInspired by one-stage object detection models in computer vision (CV), this\npaper proposes a new no-tag scheme, the Whole-Aware Detection, which makes NER\nan object detection task. Meanwhile, this paper presents a novel model, Entity\nCandidate Network (ECNet), and a specific convolution network, Adaptive Context\nConvolution Network (ACCN), to fuse multi-scale contexts and encode entity\ninformation at each position. ECNet identifies the full span of a named entity\nand its type at each position based on Entity Loss. Furthermore, ECNet is\nregulable between the highest precision and the highest recall, while the tag\nscheme approaches are not. Experimental results on the CoNLL 2003 English\ndataset and the WNUT 2017 dataset show that ECNet outperforms other previous\nstate-of-the-art methods.", "published": "2020-04-29 12:47:02", "link": "http://arxiv.org/abs/2004.14145v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Routing: Improving Local and Global Interpretability of\n  Multimodal Language Analysis", "abstract": "The human language can be expressed through multiple sources of information\nknown as modalities, including tones of voice, facial gestures, and spoken\nlanguage. Recent multimodal learning with strong performances on human-centric\ntasks such as sentiment analysis and emotion recognition are often black-box,\nwith very limited interpretability. In this paper we propose Multimodal\nRouting, which dynamically adjusts weights between input modalities and output\nrepresentations differently for each input sample. Multimodal routing can\nidentify relative importance of both individual modalities and cross-modality\nfeatures. Moreover, the weight assignment by routing allows us to interpret\nmodality-prediction relationships not only globally (i.e. general trends over\nthe whole dataset), but also locally for each single input sample, meanwhile\nkeeping competitive performance compared to state-of-the-art methods.", "published": "2020-04-29 13:42:22", "link": "http://arxiv.org/abs/2004.14198v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntax-aware Data Augmentation for Neural Machine Translation", "abstract": "Data augmentation is an effective performance enhancement in neural machine\ntranslation (NMT) by generating additional bilingual data. In this paper, we\npropose a novel data augmentation enhancement strategy for neural machine\ntranslation. Different from existing data augmentation methods which simply\nchoose words with the same probability across different sentences for\nmodification, we set sentence-specific probability for word selection by\nconsidering their roles in sentence. We use dependency parse tree of input\nsentence as an effective clue to determine selecting probability for every\nwords in each sentence. Our proposed method is evaluated on WMT14\nEnglish-to-German dataset and IWSLT14 German-to-English dataset. The result of\nextensive experiments show our proposed syntax-aware data augmentation method\nmay effectively boost existing sentence-independent methods for significant\ntranslation performance improvement.", "published": "2020-04-29 13:45:30", "link": "http://arxiv.org/abs/2004.14200v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Normalizing Compositional Structures Across Graphbanks", "abstract": "The emergence of a variety of graph-based meaning representations (MRs) has\nsparked an important conversation about how to adequately represent semantic\nstructure. These MRs exhibit structural differences that reflect different\ntheoretical and design considerations, presenting challenges to uniform\nlinguistic analysis and cross-framework semantic parsing. Here, we ask the\nquestion of which design differences between MRs are meaningful and\nsemantically-rooted, and which are superficial. We present a methodology for\nnormalizing discrepancies between MRs at the compositional level (Lindemann et\nal., 2019), finding that we can normalize the majority of divergent phenomena\nusing linguistically-grounded rules. Our work significantly increases the match\nin compositional structure between MRs and improves multi-task learning (MTL)\nin a low-resource setting, demonstrating the usefulness of careful MR design\nanalysis and comparison.", "published": "2020-04-29 14:35:50", "link": "http://arxiv.org/abs/2004.14236v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Transparent and Explainable Attention Models", "abstract": "Recent studies on interpretability of attention distributions have led to\nnotions of faithful and plausible explanations for a model's predictions.\nAttention distributions can be considered a faithful explanation if a higher\nattention weight implies a greater impact on the model's prediction. They can\nbe considered a plausible explanation if they provide a human-understandable\njustification for the model's predictions. In this work, we first explain why\ncurrent attention mechanisms in LSTM based encoders can neither provide a\nfaithful nor a plausible explanation of the model's predictions. We observe\nthat in LSTM based encoders the hidden representations at different time-steps\nare very similar to each other (high conicity) and attention weights in these\nsituations do not carry much meaning because even a random permutation of the\nattention weights does not affect the model's predictions. Based on experiments\non a wide variety of tasks and datasets, we observe attention distributions\noften attribute the model's predictions to unimportant words such as\npunctuation and fail to offer a plausible explanation for the predictions. To\nmake attention mechanisms more faithful and plausible, we propose a modified\nLSTM cell with a diversity-driven training objective that ensures that the\nhidden representations learned at different time steps are diverse. We show\nthat the resulting attention distributions offer more transparency as they (i)\nprovide a more precise importance ranking of the hidden states (ii) are better\nindicative of words important for the model's predictions (iii) correlate\nbetter with gradient-based attribution methods. Human evaluations indicate that\nthe attention distributions learned by our model offer a plausible explanation\nof the model's predictions. Our code has been made publicly available at\nhttps://github.com/akashkm99/Interpretable-Attention", "published": "2020-04-29 14:47:50", "link": "http://arxiv.org/abs/2004.14243v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GePpeTto Carves Italian into a Language Model", "abstract": "In the last few years, pre-trained neural architectures have provided\nimpressive improvements across several NLP tasks. Still, generative language\nmodels are available mainly for English. We develop GePpeTto, the first\ngenerative language model for Italian, built using the GPT-2 architecture. We\nprovide a thorough analysis of GePpeTto's quality by means of both an automatic\nand a human-based evaluation. The automatic assessment consists in (i)\ncalculating perplexity across different genres and (ii) a profiling analysis\nover GePpeTto's writing characteristics. We find that GePpeTto's production is\na sort of bonsai version of human production, with shorter but yet complex\nsentences. Human evaluation is performed over a sentence completion task, where\nGePpeTto's output is judged as natural more often than not, and much closer to\nthe original human texts than to a simpler language model which we take as\nbaseline.", "published": "2020-04-29 15:02:01", "link": "http://arxiv.org/abs/2004.14253v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Politeness Transfer: A Tag and Generate Approach", "abstract": "This paper introduces a new task of politeness transfer which involves\nconverting non-polite sentences to polite sentences while preserving the\nmeaning. We also provide a dataset of more than 1.39 instances automatically\nlabeled for politeness to encourage benchmark evaluations on this new task. We\ndesign a tag and generate pipeline that identifies stylistic attributes and\nsubsequently generates a sentence in the target style while preserving most of\nthe source content. For politeness as well as five other transfer tasks, our\nmodel outperforms the state-of-the-art methods on automatic metrics for content\npreservation, with a comparable or better performance on style transfer\naccuracy. Additionally, our model surpasses existing methods on human\nevaluations for grammaticality, meaning preservation and transfer accuracy\nacross all the six style transfer tasks. The data and code is located at\nhttps://github.com/tag-and-generate.", "published": "2020-04-29 15:08:53", "link": "http://arxiv.org/abs/2004.14257v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Reasonably-Sized Character-Level Transformer NMT by Finetuning\n  Subword Systems", "abstract": "Applying the Transformer architecture on the character level usually requires\nvery deep architectures that are difficult and slow to train. These problems\ncan be partially overcome by incorporating a segmentation into tokens in the\nmodel. We show that by initially training a subword model and then finetuning\nit on characters, we can obtain a neural machine translation model that works\nat the character level without requiring token segmentation. We use only the\nvanilla 6-layer Transformer Base architecture. Our character-level models\nbetter capture morphological phenomena and show more robustness to noise at the\nexpense of somewhat worse overall translation quality. Our study is a\nsignificant step towards high-performance and easy to train character-based\nmodels that are not extremely large.", "published": "2020-04-29 15:56:02", "link": "http://arxiv.org/abs/2004.14280v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "General Purpose Text Embeddings from Pre-trained Language Models for\n  Scalable Inference", "abstract": "The state of the art on many NLP tasks is currently achieved by large\npre-trained language models, which require a considerable amount of\ncomputation. We explore a setting where many different predictions are made on\na single piece of text. In that case, some of the computational cost during\ninference can be amortized over the different tasks using a shared text\nencoder. We compare approaches for training such an encoder and show that\nencoders pre-trained over multiple tasks generalize well to unseen tasks. We\nalso compare ways of extracting fixed- and limited-size representations from\nthis encoder, including different ways of pooling features extracted from\nmultiple layers or positions. Our best approach compares favorably to knowledge\ndistillation, achieving higher accuracy and lower computational cost once the\nsystem is handling around 7 tasks. Further, we show that through binary\nquantization, we can reduce the size of the extracted representations by a\nfactor of 16 making it feasible to store them for later use. The resulting\nmethod offers a compelling solution for using large-scale pre-trained models at\na fraction of the computational cost when multiple tasks are performed on the\nsame text.", "published": "2020-04-29 16:11:26", "link": "http://arxiv.org/abs/2004.14287v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Dialogue Generation Systems via Response Selection", "abstract": "Existing automatic evaluation metrics for open-domain dialogue response\ngeneration systems correlate poorly with human evaluation. We focus on\nevaluating response generation systems via response selection. To evaluate\nsystems properly via response selection, we propose the method to construct\nresponse selection test sets with well-chosen false candidates. Specifically,\nwe propose to construct test sets filtering out some types of false candidates:\n(i) those unrelated to the ground-truth response and (ii) those acceptable as\nappropriate responses. Through experiments, we demonstrate that evaluating\nsystems via response selection with the test sets developed by our method\ncorrelates more strongly with human evaluation, compared with widely used\nautomatic evaluation metrics such as BLEU.", "published": "2020-04-29 16:21:50", "link": "http://arxiv.org/abs/2004.14302v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Cross-Genre Ensemble Approach to Robust Reddit Part of Speech Tagging", "abstract": "Part of speech tagging is a fundamental NLP task often regarded as solved for\nhigh-resource languages such as English. Current state-of-the-art models have\nachieved high accuracy, especially on the news domain. However, when these\nmodels are applied to other corpora with different genres, and especially\nuser-generated data from the Web, we see substantial drops in performance. In\nthis work, we study how a state-of-the-art tagging model trained on different\ngenres performs on Web content from unfiltered Reddit forum discussions. More\nspecifically, we use data from multiple sources: OntoNotes, a large benchmark\ncorpus with 'well-edited' text, the English Web Treebank with 5 Web genres, and\nGUM, with 7 further genres other than Reddit. We report the results when\ntraining on different splits of the data, tested on Reddit. Our results show\nthat even small amounts of in-domain data can outperform the contribution of\ndata an order of magnitude larger coming from other Web domains. To make\nprogress on out-of-domain tagging, we also evaluate an ensemble approach using\nmultiple single-genre taggers as input features to a meta-classifier. We\npresent state of the art performance on tagging Reddit data, as well as error\nanalysis of the results of these models, and offer a typology of the most\ncommon error types among them, broken down by training corpus.", "published": "2020-04-29 16:36:38", "link": "http://arxiv.org/abs/2004.14312v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Don't Neglect the Obvious: On the Role of Unambiguous Words in Word\n  Sense Disambiguation", "abstract": "State-of-the-art methods for Word Sense Disambiguation (WSD) combine two\ndifferent features: the power of pre-trained language models and a propagation\nmethod to extend the coverage of such models. This propagation is needed as\ncurrent sense-annotated corpora lack coverage of many instances in the\nunderlying sense inventory (usually WordNet). At the same time, unambiguous\nwords make for a large portion of all words in WordNet, while being poorly\ncovered in existing sense-annotated corpora. In this paper, we propose a simple\nmethod to provide annotations for most unambiguous words in a large corpus. We\nintroduce the UWA (Unambiguous Word Annotations) dataset and show how a\nstate-of-the-art propagation-based model can use it to extend the coverage and\nquality of its word sense embeddings by a significant margin, improving on its\noriginal results on WSD.", "published": "2020-04-29 16:51:21", "link": "http://arxiv.org/abs/2004.14325v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UDapter: Language Adaptation for Truly Universal Dependency Parsing", "abstract": "Recent advances in multilingual dependency parsing have brought the idea of a\ntruly universal parser closer to reality. However, cross-language interference\nand restrained model capacity remain major obstacles. To address this, we\npropose a novel multilingual task adaptation approach based on contextual\nparameter generation and adapter modules. This approach enables to learn\nadapters via language embeddings while sharing model parameters across\nlanguages. It also allows for an easy but effective integration of existing\nlinguistic typology features into the parsing network. The resulting parser,\nUDapter, outperforms strong monolingual and multilingual baselines on the\nmajority of both high-resource and low-resource (zero-shot) languages, showing\nthe success of the proposed adaptation approach. Our in-depth analyses show\nthat soft parameter sharing via typological features is key to this success.", "published": "2020-04-29 16:52:50", "link": "http://arxiv.org/abs/2004.14327v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Domain Polarity-Changes of Words in a Sentiment Lexicon", "abstract": "Sentiment lexicons are instrumental for sentiment analysis. One can use a set\nof sentiment words provided in a sentiment lexicon and a lexicon-based\nclassifier to perform sentiment classification. One major issue with this\napproach is that many sentiment words are domain dependent. That is, they may\nbe positive in some domains but negative in some others. We refer to this\nproblem as domain polarity-changes of words. Detecting such words and\ncorrecting their sentiment for an application domain is very important. In this\npaper, we propose a graph-based technique to tackle this problem. Experimental\nresults show its effectiveness on multiple real-world datasets.", "published": "2020-04-29 17:35:05", "link": "http://arxiv.org/abs/2004.14357v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Benchmark Dataset of Check-worthy Factual Claims", "abstract": "In this paper we present the ClaimBuster dataset of 23,533 statements\nextracted from all U.S. general election presidential debates and annotated by\nhuman coders. The ClaimBuster dataset can be leveraged in building\ncomputational methods to identify claims that are worth fact-checking from the\nmyriad of sources of digital or traditional media. The ClaimBuster dataset is\npublicly available to the research community, and it can be found at\nhttp://doi.org/10.5281/zenodo.3609356.", "published": "2020-04-29 18:39:15", "link": "http://arxiv.org/abs/2004.14425v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Happens To BERT Embeddings During Fine-tuning?", "abstract": "While there has been much recent work studying how linguistic information is\nencoded in pre-trained sentence representations, comparatively little is\nunderstood about how these models change when adapted to solve downstream\ntasks. Using a suite of analysis techniques (probing classifiers,\nRepresentational Similarity Analysis, and model ablations), we investigate how\nfine-tuning affects the representations of the BERT model. We find that while\nfine-tuning necessarily makes significant changes, it does not lead to\ncatastrophic forgetting of linguistic phenomena. We instead find that\nfine-tuning primarily affects the top layers of BERT, but with noteworthy\nvariation across tasks. In particular, dependency parsing reconfigures most of\nthe model, whereas SQuAD and MNLI appear to involve much shallower processing.\nFinally, we also find that fine-tuning has a weaker effect on representations\nof out-of-domain sentences, suggesting room for improvement in model\ngeneralization.", "published": "2020-04-29 19:46:26", "link": "http://arxiv.org/abs/2004.14448v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SOLID: A Large-Scale Semi-Supervised Dataset for Offensive Language\n  Identification", "abstract": "The widespread use of offensive content in social media has led to an\nabundance of research in detecting language such as hate speech, cyberbullying,\nand cyber-aggression. Recent work presented the OLID dataset, which follows a\ntaxonomy for offensive language identification that provides meaningful\ninformation for understanding the type and the target of offensive messages.\nHowever, it is limited in size and it might be biased towards offensive\nlanguage as it was collected using keywords. In this work, we present SOLID, an\nexpanded dataset, where the tweets were collected in a more principled manner.\nSOLID contains over nine million English tweets labeled in a semi-supervised\nfashion. We demonstrate that using SOLID along with OLID yields sizable\nperformance gains on the OLID test set for two different models, especially for\nthe lower levels of the taxonomy.", "published": "2020-04-29 20:02:58", "link": "http://arxiv.org/abs/2004.14454v2", "categories": ["cs.CL", "68T50, 68T07", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "\"The Boating Store Had Its Best Sail Ever\": Pronunciation-attentive\n  Contextualized Pun Recognition", "abstract": "Humor plays an important role in human languages and it is essential to model\nhumor when building intelligence systems. Among different forms of humor, puns\nperform wordplay for humorous effects by employing words with double entendre\nand high phonetic similarity. However, identifying and modeling puns are\nchallenging as puns usually involved implicit semantic or phonological tricks.\nIn this paper, we propose Pronunciation-attentive Contextualized Pun\nRecognition (PCPR) to perceive human humor, detect if a sentence contains puns\nand locate them in the sentence. PCPR derives contextualized representation for\neach word in a sentence by capturing the association between the surrounding\ncontext and its corresponding phonetic symbols. Extensive experiments are\nconducted on two benchmark datasets. Results demonstrate that the proposed\napproach significantly outperforms the state-of-the-art methods in pun\ndetection and location tasks. In-depth analyses verify the effectiveness and\nrobustness of PCPR.", "published": "2020-04-29 20:12:20", "link": "http://arxiv.org/abs/2004.14457v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Asking without Telling: Exploring Latent Ontologies in Contextual\n  Representations", "abstract": "The success of pretrained contextual encoders, such as ELMo and BERT, has\nbrought a great deal of interest in what these models learn: do they, without\nexplicit supervision, learn to encode meaningful notions of linguistic\nstructure? If so, how is this structure encoded? To investigate this, we\nintroduce latent subclass learning (LSL): a modification to existing\nclassifier-based probing methods that induces a latent categorization (or\nontology) of the probe's inputs. Without access to fine-grained gold labels,\nLSL extracts emergent structure from input representations in an interpretable\nand quantifiable form. In experiments, we find strong evidence of familiar\ncategories, such as a notion of personhood in ELMo, as well as novel\nontological distinctions, such as a preference for fine-grained semantic roles\non core arguments. Our results provide unique new evidence of emergent\nstructure in pretrained encoders, including departures from existing\nannotations which are inaccessible to earlier methods.", "published": "2020-04-29 23:20:40", "link": "http://arxiv.org/abs/2004.14513v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "A Supervised Word Alignment Method based on Cross-Language Span\n  Prediction using Multilingual BERT", "abstract": "We present a novel supervised word alignment method based on cross-language\nspan prediction. We first formalize a word alignment problem as a collection of\nindependent predictions from a token in the source sentence to a span in the\ntarget sentence. As this is equivalent to a SQuAD v2.0 style question answering\ntask, we then solve this problem by using multilingual BERT, which is\nfine-tuned on a manually created gold word alignment data. We greatly improved\nthe word alignment accuracy by adding the context of the token to the question.\nIn the experiments using five word alignment datasets among Chinese, Japanese,\nGerman, Romanian, French, and English, we show that the proposed method\nsignificantly outperformed previous supervised and unsupervised word alignment\nmethods without using any bitexts for pretraining. For example, we achieved an\nF1 score of 86.7 for the Chinese-English data, which is 13.3 points higher than\nthe previous state-of-the-art supervised methods.", "published": "2020-04-29 23:40:08", "link": "http://arxiv.org/abs/2004.14516v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bilingual Text Extraction as Reading Comprehension", "abstract": "In this paper, we propose a method to extract bilingual texts automatically\nfrom noisy parallel corpora by framing the problem as a token-level span\nprediction, such as SQuAD-style Reading Comprehension. To extract a span of the\ntarget document that is a translation of a given source sentence (span), we use\neither QANet or multilingual BERT. QANet can be trained for a specific parallel\ncorpus from scratch, while multilingual BERT can utilize pre-trained\nmultilingual representations. For the span prediction method using QANet, we\nintroduce a total optimization method using integer linear programming to\nachieve consistency in the predicted parallel spans. We conduct a parallel\nsentence extraction experiment using simulated noisy parallel corpora with two\nlanguage pairs (En-Fr and En-Ja) and find that the proposed method using QANet\nachieves significantly better accuracy than a baseline method using two\nbi-directional RNN encoders, particularly for distant language pairs (En-Ja).\nWe also conduct a sentence alignment experiment using En-Ja newspaper articles\nand find that the proposed method using multilingual BERT achieves\nsignificantly better accuracy than a baseline method using a bilingual\ndictionary and dynamic programming.", "published": "2020-04-29 23:41:32", "link": "http://arxiv.org/abs/2004.14517v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Span-based Localizing Network for Natural Language Video Localization", "abstract": "Given an untrimmed video and a text query, natural language video\nlocalization (NLVL) is to locate a matching span from the video that\nsemantically corresponds to the query. Existing solutions formulate NLVL either\nas a ranking task and apply multimodal matching architecture, or as a\nregression task to directly regress the target video span. In this work, we\naddress NLVL task with a span-based QA approach by treating the input video as\ntext passage. We propose a video span localizing network (VSLNet), on top of\nthe standard span-based QA framework, to address NLVL. The proposed VSLNet\ntackles the differences between NLVL and span-based QA through a simple yet\neffective query-guided highlighting (QGH) strategy. The QGH guides VSLNet to\nsearch for matching video span within a highlighted region. Through extensive\nexperiments on three benchmark datasets, we show that the proposed VSLNet\noutperforms the state-of-the-art methods; and adopting span-based QA framework\nis a promising direction to solve NLVL.", "published": "2020-04-29 02:47:04", "link": "http://arxiv.org/abs/2004.13931v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Revisiting Round-Trip Translation for Quality Estimation", "abstract": "Quality estimation (QE) is the task of automatically evaluating the quality\nof translations without human-translated references. Calculating BLEU between\nthe input sentence and round-trip translation (RTT) was once considered as a\nmetric for QE, however, it was found to be a poor predictor of translation\nquality. Recently, various pre-trained language models have made breakthroughs\nin NLP tasks by providing semantically meaningful word and sentence embeddings.\nIn this paper, we employ semantic embeddings to RTT-based QE. Our method\nachieves the highest correlations with human judgments, compared to previous\nWMT 2019 quality estimation metric task submissions. While backward translation\nmodels can be a drawback when using RTT, we observe that with semantic-level\nmetrics, RTT-based QE is robust to the choice of the backward translation\nsystem. Additionally, the proposed method shows consistent performance for both\nSMT and NMT forward translation systems, implying the method does not penalize\na certain type of model.", "published": "2020-04-29 03:20:22", "link": "http://arxiv.org/abs/2004.13937v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Measuring Information Propagation in Literary Social Networks", "abstract": "We present the task of modeling information propagation in literature, in\nwhich we seek to identify pieces of information passing from character A to\ncharacter B to character C, only given a description of their activity in text.\nWe describe a new pipeline for measuring information propagation in this domain\nand publish a new dataset for speaker attribution, enabling the evaluation of\nan important component of this pipeline on a wider range of literary texts than\npreviously studied. Using this pipeline, we analyze the dynamics of information\npropagation in over 5,000 works of fiction, finding that information flows\nthrough characters that fill structural holes connecting different communities,\nand that characters who are women are depicted as filling this role much more\nfrequently than characters who are men.", "published": "2020-04-29 06:41:26", "link": "http://arxiv.org/abs/2004.13980v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Multi-View Attention Network for Visual Dialog", "abstract": "Visual dialog is a challenging vision-language task in which a series of\nquestions visually grounded by a given image are answered. To resolve the\nvisual dialog task, a high-level understanding of various multimodal inputs\n(e.g., question, dialog history, and image) is required. Specifically, it is\nnecessary for an agent to 1) determine the semantic intent of question and 2)\nalign question-relevant textual and visual contents among heterogeneous\nmodality inputs. In this paper, we propose Multi-View Attention Network (MVAN),\nwhich leverages multiple views about heterogeneous inputs based on attention\nmechanisms. MVAN effectively captures the question-relevant information from\nthe dialog history with two complementary modules (i.e., Topic Aggregation and\nContext Matching), and builds multimodal representations through sequential\nalignment processes (i.e., Modality Alignment). Experimental results on VisDial\nv1.0 dataset show the effectiveness of our proposed model, which outperforms\nthe previous state-of-the-art methods with respect to all evaluation metrics.", "published": "2020-04-29 08:46:38", "link": "http://arxiv.org/abs/2004.14025v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Topic Propagation in Conversational Search", "abstract": "In a conversational context, a user expresses her multi-faceted information\nneed as a sequence of natural-language questions, i.e., utterances. Starting\nfrom a given topic, the conversation evolves through user utterances and system\nreplies. The retrieval of documents relevant to a given utterance in a\nconversation is challenging due to ambiguity of natural language and to the\ndifficulty of detecting possible topic shifts and semantic relationships among\nutterances. We adopt the 2019 TREC Conversational Assistant Track (CAsT)\nframework to experiment with a modular architecture performing: (i) topic-aware\nutterance rewriting, (ii) retrieval of candidate passages for the rewritten\nutterances, and (iii) neural-based re-ranking of candidate passages. We present\na comprehensive experimental evaluation of the architecture assessed in terms\nof traditional IR metrics at small cutoffs. Experimental results show the\neffectiveness of our techniques that achieve an improvement up to 0.28 (+93%)\nfor P@1 and 0.19 (+89.9%) for nDCG@3 w.r.t. the CAsT baseline.", "published": "2020-04-29 10:06:00", "link": "http://arxiv.org/abs/2004.14054v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Enhancing Answer Boundary Detection for Multilingual Machine Reading\n  Comprehension", "abstract": "Multilingual pre-trained models could leverage the training data from a rich\nsource language (such as English) to improve performance on low resource\nlanguages. However, the transfer quality for multilingual Machine Reading\nComprehension (MRC) is significantly worse than sentence classification tasks\nmainly due to the requirement of MRC to detect the word level answer boundary.\nIn this paper, we propose two auxiliary tasks in the fine-tuning stage to\ncreate additional phrase boundary supervision: (1) A mixed MRC task, which\ntranslates the question or passage to other languages and builds cross-lingual\nquestion-passage pairs; (2) A language-agnostic knowledge masking task by\nleveraging knowledge phrases mined from web. Besides, extensive experiments on\ntwo cross-lingual MRC datasets show the effectiveness of our proposed approach.", "published": "2020-04-29 10:44:00", "link": "http://arxiv.org/abs/2004.14069v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Pre-training Is (Almost) All You Need: An Application to Commonsense\n  Reasoning", "abstract": "Fine-tuning of pre-trained transformer models has become the standard\napproach for solving common NLP tasks. Most of the existing approaches rely on\na randomly initialized classifier on top of such networks. We argue that this\nfine-tuning procedure is sub-optimal as the pre-trained model has no prior on\nthe specific classifier labels, while it might have already learned an\nintrinsic textual representation of the task. In this paper, we introduce a new\nscoring method that casts a plausibility ranking task in a full-text format and\nleverages the masked language modeling head tuned during the pre-training\nphase. We study commonsense reasoning tasks where the model must rank a set of\nhypotheses given a premise, focusing on the COPA, Swag, HellaSwag and\nCommonsenseQA datasets. By exploiting our scoring method without fine-tuning,\nwe are able to produce strong baselines (e.g. 80% test accuracy on COPA) that\nare comparable to supervised approaches. Moreover, when fine-tuning directly on\nthe proposed scoring function, we show that our method provides a much more\nstable training phase across random restarts (e.g $\\times 10$ standard\ndeviation reduction on COPA test accuracy) and requires less annotated data\nthan the standard classifier approach to reach equivalent performances.", "published": "2020-04-29 10:54:40", "link": "http://arxiv.org/abs/2004.14074v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Do Neural Language Models Show Preferences for Syntactic Formalisms?", "abstract": "Recent work on the interpretability of deep neural language models has\nconcluded that many properties of natural language syntax are encoded in their\nrepresentational spaces. However, such studies often suffer from limited scope\nby focusing on a single language and a single linguistic formalism. In this\nstudy, we aim to investigate the extent to which the semblance of syntactic\nstructure captured by language models adheres to a surface-syntactic or deep\nsyntactic style of analysis, and whether the patterns are consistent across\ndifferent languages. We apply a probe for extracting directed dependency trees\nto BERT and ELMo models trained on 13 different languages, probing for two\ndifferent syntactic annotation styles: Universal Dependencies (UD),\nprioritizing deep syntactic relations, and Surface-Syntactic Universal\nDependencies (SUD), focusing on surface structure. We find that both models\nexhibit a preference for UD over SUD - with interesting variations across\nlanguages and layers - and that the strength of this preference is correlated\nwith differences in tree shape.", "published": "2020-04-29 11:37:53", "link": "http://arxiv.org/abs/2004.14096v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Analysing Lexical Semantic Change with Contextualised Word\n  Representations", "abstract": "This paper presents the first unsupervised approach to lexical semantic\nchange that makes use of contextualised word representations. We propose a\nnovel method that exploits the BERT neural language model to obtain\nrepresentations of word usages, clusters these representations into usage\ntypes, and measures change along time with three proposed metrics. We create a\nnew evaluation dataset and show that the model representations and the detected\nsemantic shifts are positively correlated with human judgements. Our extensive\nqualitative analysis demonstrates that our method captures a variety of\nsynchronic and diachronic linguistic phenomena. We expect our work to inspire\nfurther research in this direction.", "published": "2020-04-29 12:18:14", "link": "http://arxiv.org/abs/2004.14118v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Exploring Fine-tuning Techniques for Pre-trained Cross-lingual Models\n  via Continual Learning", "abstract": "Recently, fine-tuning pre-trained language models (e.g., multilingual BERT)\nto downstream cross-lingual tasks has shown promising results. However, the\nfine-tuning process inevitably changes the parameters of the pre-trained model\nand weakens its cross-lingual ability, which leads to sub-optimal performance.\nTo alleviate this problem, we leverage continual learning to preserve the\noriginal cross-lingual ability of the pre-trained model when we fine-tune it to\ndownstream tasks. The experimental result shows that our fine-tuning methods\ncan better preserve the cross-lingual ability of the pre-trained model in a\nsentence retrieval task. Our methods also achieve better performance than other\nfine-tuning baselines on the zero-shot cross-lingual part-of-speech tagging and\nnamed entity recognition tasks.", "published": "2020-04-29 14:07:18", "link": "http://arxiv.org/abs/2004.14218v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploiting Structured Knowledge in Text via Graph-Guided Representation\n  Learning", "abstract": "In this work, we aim at equipping pre-trained language models with structured\nknowledge. We present two self-supervised tasks learning over raw text with the\nguidance from knowledge graphs. Building upon entity-level masked language\nmodels, our first contribution is an entity masking scheme that exploits\nrelational knowledge underlying the text. This is fulfilled by using a linked\nknowledge graph to select informative entities and then masking their mentions.\nIn addition we use knowledge graphs to obtain distractors for the masked\nentities, and propose a novel distractor-suppressed ranking objective which is\noptimized jointly with masked language model. In contrast to existing\nparadigms, our approach uses knowledge graphs implicitly, only during\npre-training, to inject language models with structured knowledge via learning\nfrom raw text. It is more efficient than retrieval-based methods that perform\nentity linking and integration during finetuning and inference, and generalizes\nmore effectively than the methods that directly learn from concatenated graph\ntriples. Experiments show that our proposed model achieves improved performance\non five benchmark datasets, including question answering and knowledge base\ncompletion tasks.", "published": "2020-04-29 14:22:42", "link": "http://arxiv.org/abs/2004.14224v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hierarchical Reinforcement Learning for Automatic Disease Diagnosis", "abstract": "Motivation: Disease diagnosis oriented dialogue system models the interactive\nconsultation procedure as Markov Decision Process and reinforcement learning\nalgorithms are used to solve the problem. Existing approaches usually employ a\nflat policy structure that treat all symptoms and diseases equally for action\nmaking. This strategy works well in the simple scenario when the action space\nis small, however, its efficiency will be challenged in the real environment.\nInspired by the offline consultation process, we propose to integrate a\nhierarchical policy structure of two levels into the dialogue systemfor policy\nlearning. The high-level policy consists of amastermodel that is responsible\nfor triggering a low-levelmodel, the lowlevel policy consists of several\nsymptom checkers and a disease classifier. The proposed policy structure is\ncapable to deal with diagnosis problem including large number of diseases and\nsymptoms.\n  Results: Experimental results on three real-world datasets and a synthetic\ndataset demonstrate that our hierarchical framework achieves higher accuracy\nand symptom recall in disease diagnosis compared with existing systems. We\nconstruct a benchmark including datasets and implementation of existing\nalgorithms to encourage follow-up researches.\n  Availability: The code and data is available from\nhttps://github.com/FudanDISC/DISCOpen-MedBox-DialoDiagnosis\n  Contact: 21210980124@m.fudan.edu.cn\n  Supplementary information: Supplementary data are available at Bioinformatics\nonline.", "published": "2020-04-29 15:02:41", "link": "http://arxiv.org/abs/2004.14254v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "SubjQA: A Dataset for Subjectivity and Review Comprehension", "abstract": "Subjectivity is the expression of internal opinions or beliefs which cannot\nbe objectively observed or verified, and has been shown to be important for\nsentiment analysis and word-sense disambiguation. Furthermore, subjectivity is\nan important aspect of user-generated data. In spite of this, subjectivity has\nnot been investigated in contexts where such data is widespread, such as in\nquestion answering (QA). We therefore investigate the relationship between\nsubjectivity and QA, while developing a new dataset. We compare and contrast\nwith analyses from previous work, and verify that findings regarding\nsubjectivity still hold when using recently developed NLP architectures. We\nfind that subjectivity is also an important feature in the case of QA, albeit\nwith more intricate interactions between subjectivity and QA performance. For\ninstance, a subjective question may or may not be associated with a subjective\nanswer. We release an English QA dataset (SubjQA) based on customer reviews,\ncontaining subjectivity annotations for questions and answer spans across 6\ndistinct domains.", "published": "2020-04-29 15:59:30", "link": "http://arxiv.org/abs/2004.14283v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Detecting Perceived Emotions in Hurricane Disasters", "abstract": "Natural disasters (e.g., hurricanes) affect millions of people each year,\ncausing widespread destruction in their wake. People have recently taken to\nsocial media websites (e.g., Twitter) to share their sentiments and feelings\nwith the larger community. Consequently, these platforms have become\ninstrumental in understanding and perceiving emotions at scale. In this paper,\nwe introduce HurricaneEmo, an emotion dataset of 15,000 English tweets spanning\nthree hurricanes: Harvey, Irma, and Maria. We present a comprehensive study of\nfine-grained emotions and propose classification tasks to discriminate between\ncoarse-grained emotion groups. Our best BERT model, even after task-guided\npre-training which leverages unlabeled Twitter data, achieves only 68% accuracy\n(averaged across all groups). HurricaneEmo serves not only as a challenging\nbenchmark for models but also as a valuable resource for analyzing emotions in\ndisaster-centric domains.", "published": "2020-04-29 16:17:49", "link": "http://arxiv.org/abs/2004.14299v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "TUNIZI: a Tunisian Arabizi sentiment analysis Dataset", "abstract": "On social media, Arabic people tend to express themselves in their own local\ndialects. More particularly, Tunisians use the informal way called \"Tunisian\nArabizi\". Analytical studies seek to explore and recognize online opinions\naiming to exploit them for planning and prediction purposes such as measuring\nthe customer satisfaction and establishing sales and marketing strategies.\nHowever, analytical studies based on Deep Learning are data hungry. On the\nother hand, African languages and dialects are considered low resource\nlanguages. For instance, to the best of our knowledge, no annotated Tunisian\nArabizi dataset exists. In this paper, we introduce TUNIZI a sentiment analysis\nTunisian Arabizi Dataset, collected from social networks, preprocessed for\nanalytical studies and annotated manually by Tunisian native speakers.", "published": "2020-04-29 16:24:02", "link": "http://arxiv.org/abs/2004.14303v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UniConv: A Unified Conversational Neural Architecture for Multi-domain\n  Task-oriented Dialogues", "abstract": "Building an end-to-end conversational agent for multi-domain task-oriented\ndialogues has been an open challenge for two main reasons. First, tracking\ndialogue states of multiple domains is non-trivial as the dialogue agent must\nobtain complete states from all relevant domains, some of which might have\nshared slots among domains as well as unique slots specifically for one domain\nonly. Second, the dialogue agent must also process various types of information\nacross domains, including dialogue context, dialogue states, and database, to\ngenerate natural responses to users. Unlike the existing approaches that are\noften designed to train each module separately, we propose \"UniConv\" -- a novel\nunified neural architecture for end-to-end conversational systems in\nmulti-domain task-oriented dialogues, which is designed to jointly train (i) a\nBi-level State Tracker which tracks dialogue states by learning signals at both\nslot and domain level independently, and (ii) a Joint Dialogue Act and Response\nGenerator which incorporates information from various input components and\nmodels dialogue acts and target responses simultaneously. We conduct\ncomprehensive experiments in dialogue state tracking, context-to-text, and\nend-to-end settings on the MultiWOZ2.1 benchmark, achieving superior\nperformance over competitive baselines.", "published": "2020-04-29 16:28:22", "link": "http://arxiv.org/abs/2004.14307v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Beyond Instructional Videos: Probing for More Diverse Visual-Textual\n  Grounding on YouTube", "abstract": "Pretraining from unlabelled web videos has quickly become the de-facto means\nof achieving high performance on many video understanding tasks. Features are\nlearned via prediction of grounded relationships between visual content and\nautomatic speech recognition (ASR) tokens. However, prior pretraining work has\nbeen limited to only instructional videos; a priori, we expect this domain to\nbe relatively \"easy:\" speakers in instructional videos will often reference the\nliteral objects/actions being depicted. We ask: can similar models be trained\non more diverse video corpora? And, if so, what types of videos are \"grounded\"\nand what types are not? We fit a representative pretraining model to the\ndiverse YouTube8M dataset, and study its success and failure cases. We find\nthat visual-textual grounding is indeed possible across previously unexplored\nvideo categories, and that pretraining on a more diverse set results in\nrepresentations that generalize to both non-instructional and instructional\ndomains.", "published": "2020-04-29 17:10:10", "link": "http://arxiv.org/abs/2004.14338v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "End-to-End Slot Alignment and Recognition for Cross-Lingual NLU", "abstract": "Natural language understanding (NLU) in the context of goal-oriented dialog\nsystems typically includes intent classification and slot labeling tasks.\nExisting methods to expand an NLU system to new languages use machine\ntranslation with slot label projection from source to the translated\nutterances, and thus are sensitive to projection errors. In this work, we\npropose a novel end-to-end model that learns to align and predict target slot\nlabels jointly for cross-lingual transfer. We introduce MultiATIS++, a new\nmultilingual NLU corpus that extends the Multilingual ATIS corpus to nine\nlanguages across four language families, and evaluate our method using the\ncorpus. Results show that our method outperforms a simple label projection\nmethod using fast-align on most languages, and achieves competitive performance\nto the more complex, state-of-the-art projection method with only half of the\ntraining time. We release our MultiATIS++ corpus to the community to continue\nfuture research on cross-lingual NLU.", "published": "2020-04-29 17:31:11", "link": "http://arxiv.org/abs/2004.14353v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning to Learn to Disambiguate: Meta-Learning for Few-Shot Word Sense\n  Disambiguation", "abstract": "The success of deep learning methods hinges on the availability of large\ntraining datasets annotated for the task of interest. In contrast to human\nintelligence, these methods lack versatility and struggle to learn and adapt\nquickly to new tasks, where labeled data is scarce. Meta-learning aims to solve\nthis problem by training a model on a large number of few-shot tasks, with an\nobjective to learn new tasks quickly from a small number of examples. In this\npaper, we propose a meta-learning framework for few-shot word sense\ndisambiguation (WSD), where the goal is to learn to disambiguate unseen words\nfrom only a few labeled instances. Meta-learning approaches have so far been\ntypically tested in an $N$-way, $K$-shot classification setting where each task\nhas $N$ classes with $K$ examples per class. Owing to its nature, WSD deviates\nfrom this controlled setup and requires the models to handle a large number of\nhighly unbalanced classes. We extend several popular meta-learning approaches\nto this scenario, and analyze their strengths and weaknesses in this new\nchallenging setting.", "published": "2020-04-29 17:33:31", "link": "http://arxiv.org/abs/2004.14355v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AxCell: Automatic Extraction of Results from Machine Learning Papers", "abstract": "Tracking progress in machine learning has become increasingly difficult with\nthe recent explosion in the number of papers. In this paper, we present AxCell,\nan automatic machine learning pipeline for extracting results from papers.\nAxCell uses several novel components, including a table segmentation subtask,\nto learn relevant structural knowledge that aids extraction. When compared with\nexisting methods, our approach significantly improves the state of the art for\nresults extraction. We also release a structured, annotated dataset for\ntraining models for results extraction, and a dataset for evaluating the\nperformance of models on this task. Lastly, we show the viability of our\napproach enables it to be used for semi-automated results extraction in\nproduction, suggesting our improvements make this task practically viable for\nthe first time. Code is available on GitHub.", "published": "2020-04-29 17:33:41", "link": "http://arxiv.org/abs/2004.14356v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Informed Sampling for Diversity in Concept-to-Text NLG", "abstract": "Deep-learning models for language generation tasks tend to produce repetitive\noutput. Various methods have been proposed to encourage lexical diversity\nduring decoding, but this often comes at a cost to the perceived fluency and\nadequacy of the output. In this work, we propose to ameliorate this cost by\nusing an Imitation Learning approach to explore the level of diversity that a\nlanguage generation model can reliably produce. Specifically, we augment the\ndecoding process with a meta-classifier trained to distinguish which words at\nany given timestep will lead to high-quality output. We focus our experiments\non concept-to-text generation where models are sensitive to the inclusion of\nirrelevant words due to the strict relation between input and output. Our\nanalysis shows that previous methods for diversity underperform in this\nsetting, while human evaluation suggests that our proposed method achieves a\nhigh level of diversity with minimal effect to the output's fluency and\nadequacy.", "published": "2020-04-29 17:43:24", "link": "http://arxiv.org/abs/2004.14364v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Elastic weight consolidation for better bias inoculation", "abstract": "The biases present in training datasets have been shown to affect models for\nsentence pair classification tasks such as natural language inference (NLI) and\nfact verification. While fine-tuning models on additional data has been used to\nmitigate them, a common issue is that of catastrophic forgetting of the\noriginal training dataset. In this paper, we show that elastic weight\nconsolidation (EWC) allows fine-tuning of models to mitigate biases while being\nless susceptible to catastrophic forgetting. In our evaluation on fact\nverification and NLI stress tests, we show that fine-tuning with EWC dominates\nstandard fine-tuning, yielding models with lower levels of forgetting on the\noriginal (biased) dataset for equivalent gains in accuracy on the fine-tuning\n(unbiased) dataset.", "published": "2020-04-29 17:45:12", "link": "http://arxiv.org/abs/2004.14366v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ToTTo: A Controlled Table-To-Text Generation Dataset", "abstract": "We present ToTTo, an open-domain English table-to-text dataset with over\n120,000 training examples that proposes a controlled generation task: given a\nWikipedia table and a set of highlighted table cells, produce a one-sentence\ndescription. To obtain generated targets that are natural but also faithful to\nthe source table, we introduce a dataset construction process where annotators\ndirectly revise existing candidate sentences from Wikipedia. We present\nsystematic analyses of our dataset and annotation process as well as results\nachieved by several state-of-the-art baselines. While usually fluent, existing\nmethods often hallucinate phrases that are not supported by the table,\nsuggesting that this dataset can serve as a useful research benchmark for\nhigh-precision conditional text generation.", "published": "2020-04-29 17:53:45", "link": "http://arxiv.org/abs/2004.14373v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pragmatic Issue-Sensitive Image Captioning", "abstract": "Image captioning systems have recently improved dramatically, but they still\ntend to produce captions that are insensitive to the communicative goals that\ncaptions should meet. To address this, we propose Issue-Sensitive Image\nCaptioning (ISIC). In ISIC, a captioning system is given a target image and an\nissue, which is a set of images partitioned in a way that specifies what\ninformation is relevant. The goal of the captioner is to produce a caption that\nresolves this issue. To model this task, we use an extension of the Rational\nSpeech Acts model of pragmatic language use. Our extension is built on top of\nstate-of-the-art pretrained neural image captioners and explicitly reasons\nabout issues in our sense. We establish experimentally that these models\ngenerate captions that are both highly descriptive and issue-sensitive, and we\nshow how ISIC can complement and enrich the related task of Visual Question\nAnswering.", "published": "2020-04-29 20:00:53", "link": "http://arxiv.org/abs/2004.14451v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Zero-shot Neural Passage Retrieval via Domain-targeted Synthetic\n  Question Generation", "abstract": "A major obstacle to the wide-spread adoption of neural retrieval models is\nthat they require large supervised training sets to surpass traditional\nterm-based techniques, which are constructed from raw corpora. In this paper,\nwe propose an approach to zero-shot learning for passage retrieval that uses\nsynthetic question generation to close this gap. The question generation system\nis trained on general domain data, but is applied to documents in the targeted\ndomain. This allows us to create arbitrarily large, yet noisy, question-passage\nrelevance pairs that are domain specific. Furthermore, when this is coupled\nwith a simple hybrid term-neural model, first-stage retrieval performance can\nbe improved further. Empirically, we show that this is an effective strategy\nfor building neural passage retrieval models in the absence of large training\ncorpora. Depending on the domain, this technique can even approach the accuracy\nof supervised models.", "published": "2020-04-29 22:21:31", "link": "http://arxiv.org/abs/2004.14503v3", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Instance-Based Learning of Span Representations: A Case Study through\n  Named Entity Recognition", "abstract": "Interpretable rationales for model predictions play a critical role in\npractical applications. In this study, we develop models possessing\ninterpretable inference process for structured prediction. Specifically, we\npresent a method of instance-based learning that learns similarities between\nspans. At inference time, each span is assigned a class label based on its\nsimilar spans in the training set, where it is easy to understand how much each\ntraining instance contributes to the predictions. Through empirical analysis on\nnamed entity recognition, we demonstrate that our method enables to build\nmodels that have high interpretability without sacrificing performance.", "published": "2020-04-29 23:32:42", "link": "http://arxiv.org/abs/2004.14514v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Reference and Document Aware Semantic Evaluation Methods for Korean\n  Language Summarization", "abstract": "Text summarization refers to the process that generates a shorter form of\ntext from the source document preserving salient information. Many existing\nworks for text summarization are generally evaluated by using recall-oriented\nunderstudy for gisting evaluation (ROUGE) scores. However, as ROUGE scores are\ncomputed based on n-gram overlap, they do not reflect semantic meaning\ncorrespondences between generated and reference summaries. Because Korean is an\nagglutinative language that combines various morphemes into a word that express\nseveral meanings, ROUGE is not suitable for Korean summarization. In this\npaper, we propose evaluation metrics that reflect semantic meanings of a\nreference summary and the original document, Reference and Document Aware\nSemantic Score (RDASS). We then propose a method for improving the correlation\nof the metrics with human judgment. Evaluation results show that the\ncorrelation with human judgment is significantly higher for our evaluation\nmetrics than for ROUGE scores.", "published": "2020-04-29 08:26:30", "link": "http://arxiv.org/abs/2005.03510v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and\n  Adversarial Training in NLP", "abstract": "While there has been substantial research using adversarial attacks to\nanalyze NLP models, each attack is implemented in its own code repository. It\nremains challenging to develop NLP attacks and utilize them to improve model\nperformance. This paper introduces TextAttack, a Python framework for\nadversarial attacks, data augmentation, and adversarial training in NLP.\nTextAttack builds attacks from four components: a goal function, a set of\nconstraints, a transformation, and a search method. TextAttack's modular design\nenables researchers to easily construct attacks from combinations of novel and\nexisting components. TextAttack provides implementations of 16 adversarial\nattacks from the literature and supports a variety of models and datasets,\nincluding BERT and other transformers, and all GLUE tasks. TextAttack also\nincludes data augmentation and adversarial training modules for using\ncomponents of adversarial attacks to improve model accuracy and robustness.\nTextAttack is democratizing NLP: anyone can try data augmentation and\nadversarial training on any model or dataset, with just a few lines of code.\nCode and tutorials are available at https://github.com/QData/TextAttack.", "published": "2020-04-29 21:33:35", "link": "http://arxiv.org/abs/2005.05909v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Which bills are lobbied? Predicting and interpreting lobbying activity\n  in the US", "abstract": "Using lobbying data from OpenSecrets.org, we offer several experiments\napplying machine learning techniques to predict if a piece of legislation (US\nbill) has been subjected to lobbying activities or not. We also investigate the\ninfluence of the intensity of the lobbying activity on how discernible a\nlobbied bill is from one that was not subject to lobbying. We compare the\nperformance of a number of different models (logistic regression, random\nforest, CNN and LSTM) and text embedding representations (BOW, TF-IDF, GloVe,\nLaw2Vec). We report results of above 0.85% ROC AUC scores, and 78% accuracy.\nModel performance significantly improves (95% ROC AUC, and 88% accuracy) when\nbills with higher lobbying intensity are looked at. We also propose a method\nthat could be used for unlabelled data. Through this we show that there is a\nconsiderably large number of previously unlabelled US bills where our\npredictions suggest that some lobbying activity took place. We believe our\nmethod could potentially contribute to the enforcement of the US Lobbying\nDisclosure Act (LDA) by indicating the bills that were likely to have been\naffected by lobbying but were not filed as such.", "published": "2020-04-29 10:46:33", "link": "http://arxiv.org/abs/2005.06386v1", "categories": ["econ.GN", "cs.CL", "cs.LG", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "Demographics Should Not Be the Reason of Toxicity: Mitigating\n  Discrimination in Text Classifications with Instance Weighting", "abstract": "With the recent proliferation of the use of text classifications, researchers\nhave found that there are certain unintended biases in text classification\ndatasets. For example, texts containing some demographic identity-terms (e.g.,\n\"gay\", \"black\") are more likely to be abusive in existing abusive language\ndetection datasets. As a result, models trained with these datasets may\nconsider sentences like \"She makes me happy to be gay\" as abusive simply\nbecause of the word \"gay.\" In this paper, we formalize the unintended biases in\ntext classification datasets as a kind of selection bias from the\nnon-discrimination distribution to the discrimination distribution. Based on\nthis formalization, we further propose a model-agnostic debiasing training\nframework by recovering the non-discrimination distribution using instance\nweighting, which does not require any extra resources or annotations apart from\na pre-defined set of demographic identity-terms. Experiments demonstrate that\nour method can effectively alleviate the impacts of the unintended biases\nwithout significantly hurting models' generalization ability.", "published": "2020-04-29 11:22:19", "link": "http://arxiv.org/abs/2004.14088v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Learning Non-Monotonic Automatic Post-Editing of Translations from Human\n  Orderings", "abstract": "Recent research in neural machine translation has explored flexible\ngeneration orders, as an alternative to left-to-right generation. However,\ntraining non-monotonic models brings a new complication: how to search for a\ngood ordering when there is a combinatorial explosion of orderings arriving at\nthe same final result? Also, how do these automatic orderings compare with the\nactual behaviour of human translators? Current models rely on manually built\nbiases or are left to explore all possibilities on their own. In this paper, we\nanalyze the orderings produced by human post-editors and use them to train an\nautomatic post-editing system. We compare the resulting system with those\ntrained with left-to-right and random post-editing orderings. We observe that\nhumans tend to follow a nearly left-to-right order, but with interesting\ndeviations, such as preferring to start by correcting punctuation or verbs.", "published": "2020-04-29 12:19:50", "link": "http://arxiv.org/abs/2004.14120v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging Declarative Knowledge in Text and First-Order Logic for\n  Fine-Grained Propaganda Detection", "abstract": "We study the detection of propagandistic text fragments in news articles.\nInstead of merely learning from input-output datapoints in training data, we\nintroduce an approach to inject declarative knowledge of fine-grained\npropaganda techniques. Specifically, we leverage the declarative knowledge\nexpressed in both first-order logic and natural language. The former refers to\nthe logical consistency between coarse- and fine-grained predictions, which is\nused to regularize the training process with propositional Boolean expressions.\nThe latter refers to the literal definition of each propaganda technique, which\nis utilized to get class representations for regularizing the model parameters.\nWe conduct experiments on Propaganda Techniques Corpus, a large manually\nannotated dataset for fine-grained propaganda detection. Experiments show that\nour method achieves superior performance, demonstrating that leveraging\ndeclarative knowledge can help the model to make more accurate predictions.", "published": "2020-04-29 13:46:15", "link": "http://arxiv.org/abs/2004.14201v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Meta-Transfer Learning for Code-Switched Speech Recognition", "abstract": "An increasing number of people in the world today speak a mixed-language as a\nresult of being multilingual. However, building a speech recognition system for\ncode-switching remains difficult due to the availability of limited resources\nand the expense and significant effort required to collect mixed-language data.\nWe therefore propose a new learning method, meta-transfer learning, to transfer\nlearn on a code-switched speech recognition system in a low-resource setting by\njudiciously extracting information from high-resource monolingual datasets. Our\nmodel learns to recognize individual languages, and transfer them so as to\nbetter recognize mixed-language speech by conditioning the optimization on the\ncode-switching data. Based on experimental results, our model outperforms\nexisting baselines on speech recognition and language modeling tasks, and is\nfaster to converge.", "published": "2020-04-29 14:27:19", "link": "http://arxiv.org/abs/2004.14228v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Exploring the Suitability of Semantic Spaces as Word Association Models\n  for the Extraction of Semantic Relationships", "abstract": "Given the recent advances and progress in Natural Language Processing (NLP),\nextraction of semantic relationships has been at the top of the research agenda\nin the last few years. This work has been mainly motivated by the fact that\nbuilding knowledge graphs (KG) and bases (KB), as a key ingredient of\nintelligent applications, is a never-ending challenge, since new knowledge\nneeds to be harvested while old knowledge needs to be revised. Currently,\napproaches towards relation extraction from text are dominated by neural models\npracticing some sort of distant (weak) supervision in machine learning from\nlarge corpora, with or without consulting external knowledge sources. In this\npaper, we empirically study and explore the potential of a novel idea of using\nclassical semantic spaces and models, e.g., Word Embedding, generated for\nextracting word association, in conjunction with relation extraction\napproaches. The goal is to use these word association models to reinforce\ncurrent relation extraction approaches. We believe that this is a first attempt\nof this kind and the results of the study should shed some light on the extent\nto which these word association models can be used as well as the most\npromising types of relationships to be considered for extraction.", "published": "2020-04-29 15:25:28", "link": "http://arxiv.org/abs/2004.14265v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "I.7"], "primary_category": "cs.CL"}
{"title": "Distantly-Supervised Neural Relation Extraction with Side Information\n  using BERT", "abstract": "Relation extraction (RE) consists in categorizing the relationship between\nentities in a sentence. A recent paradigm to develop relation extractors is\nDistant Supervision (DS), which allows the automatic creation of new datasets\nby taking an alignment between a text corpus and a Knowledge Base (KB). KBs can\nsometimes also provide additional information to the RE task. One of the\nmethods that adopt this strategy is the RESIDE model, which proposes a\ndistantly-supervised neural relation extraction using side information from\nKBs. Considering that this method outperformed state-of-the-art baselines, in\nthis paper, we propose a related approach to RESIDE also using additional side\ninformation, but simplifying the sentence encoding with BERT embeddings.\nThrough experiments, we show the effectiveness of the proposed method in Google\nDistant Supervision and Riedel datasets concerning the BGWA and RESIDE baseline\nmethods. Although Area Under the Curve is decreased because of unbalanced\ndatasets, P@N results have shown that the use of BERT as sentence encoding\nallows superior performance to baseline methods.", "published": "2020-04-29 19:29:10", "link": "http://arxiv.org/abs/2004.14443v3", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Effect of Natural Distribution Shift on Question Answering Models", "abstract": "We build four new test sets for the Stanford Question Answering Dataset\n(SQuAD) and evaluate the ability of question-answering systems to generalize to\nnew data. Our first test set is from the original Wikipedia domain and measures\nthe extent to which existing systems overfit the original test set. Despite\nseveral years of heavy test set re-use, we find no evidence of adaptive\noverfitting. The remaining three test sets are constructed from New York Times\narticles, Reddit posts, and Amazon product reviews and measure robustness to\nnatural distribution shifts. Across a broad range of models, we observe average\nperformance drops of 3.8, 14.0, and 17.4 F1 points, respectively. In contrast,\na strong human baseline matches or exceeds the performance of SQuAD models on\nthe original domain and exhibits little to no drop in new domains. Taken\ntogether, our results confirm the surprising resilience of the holdout method\nand emphasize the need to move towards evaluation metrics that incorporate\nrobustness to natural distribution shifts.", "published": "2020-04-29 19:34:19", "link": "http://arxiv.org/abs/2004.14444v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Posterior Calibrated Training on Sentence Classification Tasks", "abstract": "Most classification models work by first predicting a posterior probability\ndistribution over all classes and then selecting that class with the largest\nestimated probability. In many settings however, the quality of posterior\nprobability itself (e.g., 65% chance having diabetes), gives more reliable\ninformation than the final predicted class alone. When these methods are shown\nto be poorly calibrated, most fixes to date have relied on posterior\ncalibration, which rescales the predicted probabilities but often has little\nimpact on final classifications. Here we propose an end-to-end training\nprocedure called posterior calibrated (PosCal) training that directly optimizes\nthe objective while minimizing the difference between the predicted and\nempirical posterior probabilities.We show that PosCal not only helps reduce the\ncalibration error but also improve task performance by penalizing drops in\nperformance of both objectives. Our PosCal achieves about 2.5% of task\nperformance gain and 16.1% of calibration error reduction on GLUE (Wang et al.,\n2018) compared to the baseline. We achieved the comparable task performance\nwith 13.2% calibration error reduction on xSLUE (Kang and Hovy, 2019), but not\noutperforming the two-stage calibration baseline. PosCal training can be easily\nextendable to any types of classification tasks as a form of regularization\nterm. Also, PosCal has the advantage that it incrementally tracks needed\nstatistics for the calibration objective during the training process, making\nefficient use of large training sets.", "published": "2020-04-29 22:13:15", "link": "http://arxiv.org/abs/2004.14500v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Counterfactual Off-Policy Training for Neural Response Generation", "abstract": "Open-domain dialogue generation suffers from the data insufficiency problem\ndue to the vast size of potential responses. In this paper, we propose to\nexplore potential responses by counterfactual reasoning. Given an observed\nresponse, the counterfactual reasoning model automatically infers the outcome\nof an alternative policy that could have been taken. The resulting\ncounterfactual response synthesized in hindsight is of higher quality than the\nresponse synthesized from scratch. Training on the counterfactual responses\nunder the adversarial learning framework helps to explore the high-reward area\nof the potential response space. An empirical study on the DailyDialog dataset\nshows that our approach significantly outperforms the HRED model as well as the\nconventional adversarial learning approaches.", "published": "2020-04-29 22:46:28", "link": "http://arxiv.org/abs/2004.14507v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Time-domain speaker extraction network", "abstract": "Speaker extraction is to extract a target speaker's voice from multi-talker\nspeech. It simulates humans' cocktail party effect or the selective listening\nability. The prior work mostly performs speaker extraction in frequency domain,\nthen reconstructs the signal with some phase approximation. The inaccuracy of\nphase estimation is inherent to the frequency domain processing, that affects\nthe quality of signal reconstruction. In this paper, we propose a time-domain\nspeaker extraction network (TseNet) that doesn't decompose the speech signal\ninto magnitude and phase spectrums, therefore, doesn't require phase\nestimation. The TseNet consists of a stack of dilated depthwise separable\nconvolutional networks, that capture the long-range dependency of the speech\nsignal with a manageable number of parameters. It is also conditioned on a\nreference voice from the target speaker, that is characterized by speaker\ni-vector, to perform the selective listening to the target speaker. Experiments\nshow that the proposed TseNet achieves 16.3% and 7.0% relative improvements\nover the baseline in terms of signal-to-distortion ratio (SDR) and perceptual\nevaluation of speech quality (PESQ) under open evaluation condition.", "published": "2020-04-29 07:42:31", "link": "http://arxiv.org/abs/2004.14762v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Robust Phonetic Segmentation Using Spectral Transition measure for\n  Non-Standard Recording Environments", "abstract": "Phone level localization of mis-articulation is a key requirement for an\nautomatic articulation error assessment system. A robust phone segmentation\ntechnique is essential to aid in real-time assessment of phone level\nmis-articulations of speech, wherein the audio is recorded on mobile phones or\ntablets. This is a non-standard recording set-up with little control over the\nquality of recording. We propose a novel post processing technique to aid\nSpectral Transition Measure(STM)-based phone segmentation under noisy\nconditions such as environment noise and clipping, commonly present during a\nmobile phone recording. A comparison of the performance of our approach and\nphone segmentation using traditional MFCC and PLPCC speech features for\nGaussian noise and clipping is shown. The proposed approach was validated on\nTIMIT and Hindi speech corpus and was used to compute phone boundaries for a\nset of speech, recorded simultaneously on three devices - a laptop, a\nstationarily placed tablet and a handheld mobile phone, to simulate different\naudio qualities in a real-time non-standard recording environment. F-ratio was\nthe metric used to compute the accuracy in phone boundary marking. Experimental\nresults show an improvement of 7% for TIMIT and 10% for Hindi data over the\nbaseline approach. Similar results were seen for the set of three of recordings\ncollected in-house.", "published": "2020-04-29 16:32:52", "link": "http://arxiv.org/abs/2004.14859v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Determined BSS based on time-frequency masking and its application to\n  harmonic vector analysis", "abstract": "This paper proposes harmonic vector analysis (HVA) based on a general\nalgorithmic framework of audio blind source separation (BSS) that is also\npresented in this paper. BSS for a convolutive audio mixture is usually\nperformed by multichannel linear filtering when the numbers of microphones and\nsources are equal (determined situation). This paper addresses such determined\nBSS based on batch processing. To estimate the demixing filters, effective\nmodeling of the source signals is important. One successful example is\nindependent vector analysis (IVA) that models the signals via co-occurrence\namong the frequency components in each source. To give more freedom to the\nsource modeling, a general framework of determined BSS is presented in this\npaper. It is based on the plug-and-play scheme using a primal-dual splitting\nalgorithm and enables us to model the source signals implicitly through a\ntime-frequency mask. By using the proposed framework, determined BSS algorithms\ncan be developed by designing masks that enhance the source signals. As an\nexample of its application, we propose HVA by defining a time-frequency mask\nthat enhances the harmonic structure of audio signals via sparsity of cepstrum.\nThe experiments showed that HVA outperforms IVA and independent low-rank matrix\nanalysis (ILRMA) for both speech and music signals. A MATLAB code is provided\nalong with the paper for a reference ( https://doi.org/10.24433/CO.9507820.v1\n).", "published": "2020-04-29 11:29:55", "link": "http://arxiv.org/abs/2004.14091v4", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Seeing voices and hearing voices: learning discriminative embeddings\n  using cross-modal self-supervision", "abstract": "The goal of this work is to train discriminative cross-modal embeddings\nwithout access to manually annotated data. Recent advances in self-supervised\nlearning have shown that effective representations can be learnt from natural\ncross-modal synchrony. We build on earlier work to train embeddings that are\nmore discriminative for uni-modal downstream tasks. To this end, we propose a\nnovel training strategy that not only optimises metrics across modalities, but\nalso enforces intra-class feature separation within each of the modalities. The\neffectiveness of the method is demonstrated on two downstream tasks: lip\nreading using the features trained on audio-visual synchronisation, and speaker\nrecognition using the features trained for cross-modal biometric matching. The\nproposed method outperforms state-of-the-art self-supervised baselines by a\nsignficant margin.", "published": "2020-04-29 16:51:50", "link": "http://arxiv.org/abs/2004.14326v2", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VGGSound: A Large-scale Audio-Visual Dataset", "abstract": "Our goal is to collect a large-scale audio-visual dataset with low label\nnoise from videos in the wild using computer vision techniques. The resulting\ndataset can be used for training and evaluating audio recognition models. We\nmake three contributions. First, we propose a scalable pipeline based on\ncomputer vision techniques to create an audio dataset from open-source media.\nOur pipeline involves obtaining videos from YouTube; using image classification\nalgorithms to localize audio-visual correspondence; and filtering out ambient\nnoise using audio verification. Second, we use this pipeline to curate the\nVGGSound dataset consisting of more than 210k videos for 310 audio classes.\nThird, we investigate various Convolutional Neural Network~(CNN) architectures\nand aggregation approaches to establish audio recognition baselines for our new\ndataset. Compared to existing audio datasets, VGGSound ensures audio-visual\ncorrespondence and is collected under unconstrained conditions. Code and the\ndataset are available at http://www.robots.ox.ac.uk/~vgg/data/vggsound/", "published": "2020-04-29 17:46:54", "link": "http://arxiv.org/abs/2004.14368v2", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Multiresolution and Multimodal Speech Recognition with Transformers", "abstract": "This paper presents an audio visual automatic speech recognition (AV-ASR)\nsystem using a Transformer-based architecture. We particularly focus on the\nscene context provided by the visual information, to ground the ASR. We extract\nrepresentations for audio features in the encoder layers of the transformer and\nfuse video features using an additional crossmodal multihead attention layer.\nAdditionally, we incorporate a multitask training criterion for multiresolution\nASR, where we train the model to generate both character and subword level\ntranscriptions.\n  Experimental results on the How2 dataset, indicate that multiresolution\ntraining can speed up convergence by around 50% and relatively improves word\nerror rate (WER) performance by upto 18% over subword prediction models.\nFurther, incorporating visual information improves performance with relative\ngains upto 3.76% over audio only models.\n  Our results are comparable to state-of-the-art Listen, Attend and Spell-based\narchitectures.", "published": "2020-04-29 09:32:11", "link": "http://arxiv.org/abs/2004.14840v1", "categories": ["eess.AS", "cs.CV", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
