{"title": "A Comparison of Techniques for Sentiment Classification of Film Reviews", "abstract": "We undertake the task of comparing lexicon-based sentiment classification of\nfilm reviews with machine learning approaches. We look at existing\nmethodologies and attempt to emulate and improve on them using a 'given'\nlexicon and a bag-of-words approach. We also utilise syntactical information\nsuch as part-of-speech and dependency relations. We will show that a simple\nlexicon-based classification achieves good results however machine learning\ntechniques prove to be the superior tool. We also show that more features do\nnot necessarily deliver better performance as well as elaborate on three\nfurther enhancements not tested in this article.", "published": "2019-05-12 14:19:28", "link": "http://arxiv.org/abs/1905.04727v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Secret Lives of Names? Name Embeddings from Social Media", "abstract": "Your name tells a lot about you: your gender, ethnicity and so on. It has\nbeen shown that name embeddings are more effective in representing names than\ntraditional substring features. However, our previous name embedding model is\ntrained on private email data and are not publicly accessible. In this paper,\nwe explore learning name embeddings from public Twitter data. We argue that\nTwitter embeddings have two key advantages: \\textit{(i)} they can and will be\npublicly released to support research community. \\textit{(ii)} even with a\nsmaller training corpus, Twitter embeddings achieve similar performances on\nmultiple tasks comparing to email embeddings.\n  As a test case to show the power of name embeddings, we investigate the\nmodeling of lifespans. We find it interesting that adding name embeddings can\nfurther improve the performances of models using demographic features, which\nare traditionally used for lifespan modeling. Through residual analysis, we\nobserve that fine-grained groups (potentially reflecting socioeconomic status)\nare the latent contributing factors encoded in name embeddings. These were\npreviously hidden to demographic models, and may help to enhance the predictive\npower of a wide class of research studies.", "published": "2019-05-12 22:20:44", "link": "http://arxiv.org/abs/1905.04799v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "The relational processing limits of classic and contemporary neural\n  network models of language processing", "abstract": "The ability of neural networks to capture relational knowledge is a matter of\nlong-standing controversy. Recently, some researchers in the PDP side of the\ndebate have argued that (1) classic PDP models can handle relational structure\n(Rogers & McClelland, 2008, 2014) and (2) the success of deep learning\napproaches to text processing suggests that structured representations are\nunnecessary to capture the gist of human language (Rabovsky et al., 2018). In\nthe present study we tested the Story Gestalt model (St. John, 1992), a classic\nPDP model of text comprehension, and a Sequence-to-Sequence with Attention\nmodel (Bahdanau et al., 2015), a contemporary deep learning architecture for\ntext processing. Both models were trained to answer questions about stories\nbased on the thematic roles that several concepts played on the stories. In\nthree critical test we varied the statistical structure of new stories while\nkeeping their relational structure constant with respect to the training data.\nEach model was susceptible to each statistical structure manipulation to a\ndifferent degree, with their performance failing below chance at least under\none manipulation. We argue that the failures of both models are due to the fact\nthat they cannotperform dynamic binding of independent roles and fillers.\nUltimately, these results cast doubts onthe suitability of traditional neural\nnetworks models for explaining phenomena based on relational reasoning,\nincluding language processing.", "published": "2019-05-12 11:19:25", "link": "http://arxiv.org/abs/1905.05708v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Natural Language Interaction with Robots Using Advice", "abstract": "Over the last few years, there has been growing interest in learning models\nfor physically grounded language understanding tasks, such as the popular\nblocks world domain. These works typically view this problem as a single-step\nprocess, in which a human operator gives an instruction and an automated agent\nis evaluated on its ability to execute it. In this paper we take the first step\ntowards increasing the bandwidth of this interaction, and suggest a protocol\nfor including advice, high-level observations about the task, which can help\nconstrain the agent's prediction. We evaluate our approach on the blocks world\ntask, and show that even simple advice can help lead to significant performance\nimprovements. To help reduce the effort involved in supplying the advice, we\nalso explore model self-generated advice which can still improve results.", "published": "2019-05-12 06:11:30", "link": "http://arxiv.org/abs/1905.04655v1", "categories": ["cs.CL", "cs.AI", "cs.RO", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Benchmark Study of Machine Learning Models for Online Fake News\n  Detection", "abstract": "The proliferation of fake news and its propagation on social media has become\na major concern due to its ability to create devastating impacts. Different\nmachine learning approaches have been suggested to detect fake news. However,\nmost of those focused on a specific type of news (such as political) which\nleads us to the question of dataset-bias of the models used. In this research,\nwe conducted a benchmark study to assess the performance of different\napplicable machine learning approaches on three different datasets where we\naccumulated the largest and most diversified one. We explored a number of\nadvanced pre-trained language models for fake news detection along with the\ntraditional and deep learning ones and compared their performances from\ndifferent aspects for the first time to the best of our knowledge. We find that\nBERT and similar pre-trained models perform the best for fake news detection,\nespecially with very small dataset. Hence, these models are significantly\nbetter option for languages with limited electronic contents, i.e., training\ndata. We also carried out several analysis based on the models' performance,\narticle's topic, article's length, and discussed different lessons learned from\nthem. We believe that this benchmark study will help the research community to\nexplore further and news sites/blogs to select the most appropriate fake news\ndetection method.", "published": "2019-05-12 17:15:11", "link": "http://arxiv.org/abs/1905.04749v2", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Improving Opus Low Bit Rate Quality with Neural Speech Synthesis", "abstract": "The voice mode of the Opus audio coder can compress wideband speech at bit\nrates ranging from 6 kb/s to 40 kb/s. However, Opus is at its core a waveform\nmatching coder, and as the rate drops below 10 kb/s, quality degrades quickly.\nAs the rate reduces even further, parametric coders tend to perform better than\nwaveform coders. In this paper we propose a backward-compatible way of\nimproving low bit rate Opus quality by re-synthesizing speech from the decoded\nparameters. We compare two different neural generative models, WaveNet and\nLPCNet. WaveNet is a powerful, high-complexity, and high-latency architecture\nthat is not feasible for a practical system, yet provides a best known\nachievable quality with generative models. LPCNet is a low-complexity,\nlow-latency RNN-based generative model, and practically implementable on mobile\nphones. We apply these systems with parameters from Opus coded at 6 kb/s as\nconditioning features for the generative models. A listening test shows that\nfor the same 6 kb/s Opus bit stream, synthesized speech using LPCNet clearly\noutperforms the output of the standard Opus decoder. This opens up ways to\nimprove the decoding quality of existing speech and audio waveform coders\nwithout breaking compatibility.", "published": "2019-05-12 02:17:05", "link": "http://arxiv.org/abs/1905.04628v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep Vocoder: Low Bit Rate Compression of Speech with Deep Autoencoder", "abstract": "Inspired by the success of deep neural networks (DNNs) in speech processing,\nthis paper presents Deep Vocoder, a direct end-to-end low bit rate speech\ncompression method with deep autoencoder (DAE). In Deep Vocoder, DAE is used\nfor extracting the latent representing features (LRFs) of speech, which are\nthen efficiently quantized by an analysis-by-synthesis vector quantization (AbS\nVQ) method. AbS VQ aims to minimize the perceptual spectral reconstruction\ndistortion rather than the distortion of LRFs vector itself. Also, a suboptimal\ncodebook searching technique is proposed to further reduce the computational\ncomplexity. Experimental results demonstrate that Deep Vocoder yields\nsubstantial improvements in terms of frequency-weighted segmental SNR, STOI and\nPESQ score when compared to the output of the conventional SQ- or VQ-based\ncodec. The yielded PESQ score over the TIMIT corpus is 3.34 and 3.08 for speech\ncoding at 2400 bit/s and 1200 bit/s, respectively.", "published": "2019-05-12 12:24:27", "link": "http://arxiv.org/abs/1905.04709v2", "categories": ["cs.MM", "cs.IT", "cs.SD", "eess.AS", "math.IT"], "primary_category": "cs.MM"}
