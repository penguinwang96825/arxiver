{"title": "Disabling Self-Correction in Retrieval-Augmented Generation via Stealthy Retriever Poisoning", "abstract": "Retrieval-Augmented Generation (RAG) has become a standard approach for\nimproving the reliability of large language models (LLMs). Prior work\ndemonstrates the vulnerability of RAG systems by misleading them into\ngenerating attacker-chosen outputs through poisoning the knowledge base.\nHowever, this paper uncovers that such attacks could be mitigated by the strong\n\\textit{self-correction ability (SCA)} of modern LLMs, which can reject false\ncontext once properly configured. This SCA poses a significant challenge for\nattackers aiming to manipulate RAG systems.\n  In contrast to previous poisoning methods, which primarily target the\nknowledge base, we introduce \\textsc{DisarmRAG}, a new poisoning paradigm that\ncompromises the retriever itself to suppress the SCA and enforce\nattacker-chosen outputs. This compromisation enables the attacker to\nstraightforwardly embed anti-SCA instructions into the context provided to the\ngenerator, thereby bypassing the SCA. To this end, we present a\ncontrastive-learning-based model editing technique that performs localized and\nstealthy edits, ensuring the retriever returns a malicious instruction only for\nspecific victim queries while preserving benign retrieval behavior. To further\nstrengthen the attack, we design an iterative co-optimization framework that\nautomatically discovers robust instructions capable of bypassing prompt-based\ndefenses. We extensively evaluate DisarmRAG across six LLMs and three QA\nbenchmarks. Our results show near-perfect retrieval of malicious instructions,\nwhich successfully suppress SCA and achieve attack success rates exceeding 90\\%\nunder diverse defensive prompts. Also, the edited retriever remains stealthy\nunder several detection methods, highlighting the urgent need for\nretriever-centric defenses.", "published": "2025-08-27 17:49:28", "link": "http://arxiv.org/abs/2508.20083v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis", "abstract": "For human cognitive process, spatial reasoning and perception are closely\nentangled, yet the nature of this interplay remains underexplored in the\nevaluation of multimodal large language models (MLLMs). While recent MLLM\nadvancements show impressive performance on reasoning, their capacity for\nhuman-like spatial cognition remains an open question. In this work, we\nintroduce a systematic evaluation framework to assess the spatial reasoning\nabilities of state-of-the-art MLLMs relative to human performance. Central to\nour work is 11Plus-Bench, a high-quality benchmark derived from realistic\nstandardized spatial aptitude tests. 11Plus-Bench also features fine-grained\nexpert annotations of both perceptual complexity and reasoning process,\nenabling detailed instance-level analysis of model behavior. Through extensive\nexperiments across 14 MLLMs and human evaluation, we find that current MLLMs\nexhibit early signs of spatial cognition. Despite a large performance gap\ncompared to humans, MLLMs' cognitive profiles resemble those of humans in that\ncognitive effort correlates strongly with reasoning-related complexity.\nHowever, instance-level performance in MLLMs remains largely random, whereas\nhuman correctness is highly predictable and shaped by abstract pattern\ncomplexity. These findings highlight both emerging capabilities and limitations\nin current MLLMs' spatial reasoning capabilities and provide actionable\ninsights for advancing model design.", "published": "2025-08-27 17:22:34", "link": "http://arxiv.org/abs/2508.20068v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AraHealthQA 2025 Shared Task Description Paper", "abstract": "We introduce {AraHealthQA 2025}, the {Comprehensive Arabic Health Question\nAnswering Shared Task}, held in conjunction with {ArabicNLP 2025} (co-located\nwith EMNLP 2025). This shared task addresses the paucity of high-quality Arabic\nmedical QA resources by offering two complementary tracks: {MentalQA}, focusing\non Arabic mental health Q\\&A (e.g., anxiety, depression, stigma reduction), and\n{MedArabiQ}, covering broader medical domains such as internal medicine,\npediatrics, and clinical decision making. Each track comprises multiple\nsubtasks, evaluation datasets, and standardized metrics, facilitating fair\nbenchmarking. The task was structured to promote modeling under realistic,\nmultilingual, and culturally nuanced healthcare contexts. We outline the\ndataset creation, task design and evaluation framework, participation\nstatistics, baseline systems, and summarize the overall outcomes. We conclude\nwith reflections on the performance trends observed and prospects for future\niterations in Arabic health QA.", "published": "2025-08-27 16:54:09", "link": "http://arxiv.org/abs/2508.20047v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks", "abstract": "Despite advances in improving large language model(LLM) to refuse to answer\nmalicious instructions, widely used LLMs remain vulnerable to jailbreak attacks\nwhere attackers generate instructions with distributions differing from safety\nalignment corpora. New attacks expose LLMs' inability to recognize unseen\nmalicious instructions, highlighting a critical distributional mismatch between\ntraining data and real-world attacks that forces developers into reactive\npatching cycles. To tackle this challenge, we propose IMAGINE, a synthesis\nframework that leverages embedding space distribution analysis to generate\njailbreak-like instructions. This approach effectively fills the distributional\ngap between authentic jailbreak patterns and safety alignment corpora. IMAGINE\nfollows an iterative optimization process that dynamically evolves text\ngeneration distributions across iterations, thereby augmenting the coverage of\nsafety alignment data distributions through synthesized data examples. Based on\nthe safety-aligned corpus enhanced through IMAGINE, our framework demonstrates\nsignificant decreases in attack success rate on Qwen2.5, Llama3.1, and Llama3.2\nwithout compromising their utility.", "published": "2025-08-27 16:44:03", "link": "http://arxiv.org/abs/2508.20038v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis", "abstract": "The ability to research and synthesize knowledge is central to human\nexpertise and progress. An emerging class of systems promises these exciting\ncapabilities through generative research synthesis, performing retrieval over\nthe live web and synthesizing discovered sources into long-form, cited\nsummaries. However, evaluating such systems remains an open challenge: existing\nquestion-answering benchmarks focus on short-form factual responses, while\nexpert-curated datasets risk staleness and data contamination. Both fail to\ncapture the complexity and evolving nature of real research synthesis tasks. In\nthis work, we introduce DeepScholar-bench, a live benchmark and holistic,\nautomated evaluation framework designed to evaluate generative research\nsynthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv\npapers and focuses on a real research synthesis task: generating the related\nwork sections of a paper by retrieving, synthesizing, and citing prior\nresearch. Our evaluation framework holistically assesses performance across\nthree key dimensions, knowledge synthesis, retrieval quality, and\nverifiability. We also develop DeepScholar-base, a reference pipeline\nimplemented efficiently using the LOTUS API. Using the DeepScholar-bench\nframework, we perform a systematic evaluation of prior open-source systems,\nsearch AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that\nDeepScholar-base establishes a strong baseline, attaining competitive or higher\nperformance than each other method. We also find that DeepScholar-bench remains\nfar from saturated, with no system exceeding a score of $19\\%$ across all\nmetrics. These results underscore the difficulty of DeepScholar-bench, as well\nas its importance for progress towards AI systems capable of generative\nresearch synthesis. We make our code available at\nhttps://github.com/guestrin-lab/deepscholar-bench.", "published": "2025-08-27 16:36:34", "link": "http://arxiv.org/abs/2508.20033v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Pruning Strategies for Backdoor Defense in LLMs", "abstract": "Backdoor attacks are a significant threat to the performance and integrity of\npre-trained language models. Although such models are routinely fine-tuned for\ndownstream NLP tasks, recent work shows they remain vulnerable to backdoor\nattacks that survive vanilla fine-tuning. These attacks are difficult to defend\nbecause end users typically lack knowledge of the attack triggers. Such attacks\nconsist of stealthy malicious triggers introduced through subtle syntactic or\nstylistic manipulations, which can bypass traditional detection and remain in\nthe model, making post-hoc purification essential. In this study, we explore\nwhether attention-head pruning can mitigate these threats without any knowledge\nof the trigger or access to a clean reference model. To this end, we design and\nimplement six pruning-based strategies: (i) gradient-based pruning, (ii)\nlayer-wise variance pruning, (iii) gradient-based pruning with structured L1/L2\nsparsification, (iv) randomized ensemble pruning, (v)\nreinforcement-learning-guided pruning, and (vi) Bayesian uncertainty pruning.\nEach method iteratively removes the least informative heads while monitoring\nvalidation accuracy to avoid over-pruning. Experimental evaluation shows that\ngradient-based pruning performs best while defending the syntactic triggers,\nwhereas reinforcement learning and Bayesian pruning better withstand stylistic\nattacks.", "published": "2025-08-27 16:34:53", "link": "http://arxiv.org/abs/2508.20032v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence", "abstract": "Most existing Large Language Model (LLM)-based agent frameworks rely on\ncentralized orchestration, incurring high deployment costs, rigid communication\ntopologies, and limited adaptability. To address these challenges, we introduce\nSymphony, a decentralized multi-agent system which enables lightweight LLMs on\nconsumer-grade GPUs to coordinate. Symphony introduces three key mechanisms:\n(1) a decentralized ledger that records capabilities, (2) a Beacon-selection\nprotocol for dynamic task allocation, and (3) weighted result voting based on\nCoTs. This design forms a privacy-saving, scalable, and fault-tolerant\norchestration with low overhead. Empirically, Symphony outperforms existing\nbaselines on reasoning benchmarks, achieving substantial accuracy gains and\ndemonstrating robustness across models of varying capacities.", "published": "2025-08-27 16:27:57", "link": "http://arxiv.org/abs/2508.20019v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.LG"}
{"title": "SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control", "abstract": "The rapid advancement of large vision language models (LVLMs) and agent\nsystems has heightened interest in mobile GUI agents that can reliably\ntranslate natural language into interface operations. Existing single-agent\napproaches, however, remain limited by structural constraints. Although\nmulti-agent systems naturally decouple different competencies, recent progress\nin multi-agent reinforcement learning (MARL) has often been hindered by\ninefficiency and remains incompatible with current LVLM architectures. To\naddress these challenges, we introduce SWIRL, a staged workflow for interleaved\nreinforcement learning designed for multi-agent systems. SWIRL reformulates\nMARL into a sequence of single-agent reinforcement learning tasks, updating one\nagent at a time while keeping the others fixed. This formulation enables stable\ntraining and promotes efficient coordination across agents. Theoretically, we\nprovide a stepwise safety bound, a cross-round monotonic improvement theorem,\nand convergence guarantees on return, ensuring robust and principled\noptimization. In application to mobile GUI control, SWIRL instantiates a\nNavigator that converts language and screen context into structured plans, and\nan Interactor that grounds these plans into executable atomic actions.\nExtensive experiments demonstrate superior performance on both high-level and\nlow-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong\ncapability in multi-agent mathematical reasoning, underscoring its potential as\na general framework for developing efficient and robust multi-agent systems.", "published": "2025-08-27 16:27:19", "link": "http://arxiv.org/abs/2508.20018v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation", "abstract": "This paper introduces an algorithm to select demonstration examples for\nin-context learning of a query set. Given a set of $n$ examples, how can we\nquickly select $k$ out of $n$ to best serve as the conditioning for downstream\ninference? This problem has broad applications in prompt tuning and\nchain-of-thought reasoning. Since model weights remain fixed during in-context\nlearning, previous work has sought to design methods based on the similarity of\ntoken embeddings. This work proposes a new approach based on gradients of the\noutput taken in the input embedding space. Our approach estimates model outputs\nthrough a first-order approximation using the gradients. Then, we apply this\nestimation to multiple randomly sampled subsets. Finally, we aggregate the\nsampled subset outcomes to form an influence score for each demonstration, and\nselect $k$ most relevant examples. This procedure only requires pre-computing\nmodel outputs and gradients once, resulting in a linear-time algorithm relative\nto model and training set sizes. Extensive experiments across various models\nand datasets validate the efficiency of our approach. We show that the gradient\nestimation procedure yields approximations of full inference with less than\n$\\mathbf{1}\\%$ error across six datasets. This allows us to scale up subset\nselection that would otherwise run full inference by up to\n$\\mathbf{37.7}\\times$ on models with up to $34$ billion parameters, and\noutperform existing selection methods based on input embeddings by\n$\\mathbf{11}\\%$ on average.", "published": "2025-08-27 15:59:47", "link": "http://arxiv.org/abs/2508.19999v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Selective Retrieval-Augmentation for Long-Tail Legal Text Classification", "abstract": "Legal text classification is a fundamental NLP task in the legal domain.\nBenchmark datasets in this area often exhibit a long-tail label distribution,\nwhere many labels are underrepresented, leading to poor model performance on\nrare classes. This paper proposes Selective Retrieval-Augmentation (SRA) as a\nsolution to this problem. SRA focuses on augmenting samples belonging to\nlow-frequency labels in the training set, preventing the introduction of noise\nfor well-represented classes, and requires no changes to the model\narchitecture. Retrieval is performed only from the training data to ensure\nthere is no potential information leakage, removing the need for external\ncorpora simultaneously. The proposed SRA method is tested on two legal text\nclassification benchmark datasets with long-tail distributions: LEDGAR\n(single-label) and UNFAIR-ToS (multi-label). The results indicate that SRA\nattains higher micro-F1 and macro-F1 scores compared to all current LexGLUE\nbaselines across both datasets, illustrating consistent improvements in\nlong-tail legal text classification. The code repository is available at:\nhttps://github.com/Boheng-Mao/sra-legal", "published": "2025-08-27 15:56:34", "link": "http://arxiv.org/abs/2508.19997v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "ReSURE: Regularizing Supervision Unreliability for Multi-turn Dialogue Fine-tuning", "abstract": "Fine-tuning multi-turn dialogue systems requires high-quality supervision but\noften suffers from degraded performance when exposed to low-quality data.\nSupervision errors in early turns can propagate across subsequent turns,\nundermining coherence and response quality. Existing methods typically address\ndata quality via static prefiltering, which decouples quality control from\ntraining and fails to mitigate turn-level error propagation. In this context,\nwe propose ReSURE (Regularizing Supervision UnREliability), an adaptive\nlearning method that dynamically down-weights unreliable supervision without\nexplicit filtering. ReSURE estimates per-turn loss distributions using\nWelford's online statistics and reweights sample losses on the fly accordingly.\nExperiments on both single-source and mixed-quality datasets show improved\nstability and response quality. Notably, ReSURE enjoys positive Spearman\ncorrelations (0.21 ~ 1.0 across multiple benchmarks) between response scores\nand number of samples regardless of data quality, which potentially paves the\nway for utilizing large-scale data effectively. Code is publicly available at\nhttps://github.com/Elvin-Yiming-Du/ReSURE_Multi_Turn_Training.", "published": "2025-08-27 15:54:01", "link": "http://arxiv.org/abs/2508.19996v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MathBuddy: A Multimodal System for Affective Math Tutoring", "abstract": "The rapid adoption of LLM-based conversational systems is already\ntransforming the landscape of educational technology. However, the current\nstate-of-the-art learning models do not take into account the student's\naffective states. Multiple studies in educational psychology support the claim\nthat positive or negative emotional states can impact a student's learning\ncapabilities. To bridge this gap, we present MathBuddy, an emotionally aware\nLLM-powered Math Tutor, which dynamically models the student's emotions and\nmaps them to relevant pedagogical strategies, making the tutor-student\nconversation a more empathetic one. The student's emotions are captured from\nthe conversational text as well as from their facial expressions. The student's\nemotions are aggregated from both modalities to confidently prompt our LLM\nTutor for an emotionally-aware response. We have effectively evaluated our\nmodel using automatic evaluation metrics across eight pedagogical dimensions\nand user studies. We report a massive 23 point performance gain using the win\nrate and a 3 point gain at an overall level using DAMR scores which strongly\nsupports our hypothesis of improving LLM-based tutor's pedagogical abilities by\nmodeling students' emotions.", "published": "2025-08-27 15:50:43", "link": "http://arxiv.org/abs/2508.19993v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Self-Supervised Pre-Training with Equilibrium Constraints", "abstract": "Self-supervised pre-training using unlabeled data is widely used in machine\nlearning. In this paper, we propose a new self-supervised pre-training approach\nto dealing with heterogeneous data. Instead of mixing all the data and\nminimizing the averaged global loss in the conventional way, we impose\nadditional equilibrium constraints to ensure that the models optimizes each\nsource of heterogeneous data to its local optima after $K$-step gradient\ndescent initialized from the model. We formulate this as a bilevel optimization\nproblem, and use the first-order approximation method to solve the problem. We\ndiscuss its connection to model-agnostic meta learning (MAML). Experiments are\ncarried out on self-supervised pre-training using multi-domain and multilingual\ndatasets, demonstrating that the proposed approach can significantly improve\nthe adaptivity of the self-supervised pre-trained model for the downstream\nsupervised fine-tuning tasks.", "published": "2025-08-27 15:48:50", "link": "http://arxiv.org/abs/2508.19990v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios", "abstract": "Large Language Models (LLMs) have achieved high accuracy on complex\ncommonsense and mathematical problems that involve the composition of multiple\nreasoning steps. However, current compositional benchmarks testing these skills\ntend to focus on either commonsense or math reasoning, whereas LLM agents\nsolving real-world tasks would require a combination of both. In this work, we\nintroduce an Agentic Commonsense and Math benchmark (AgentCoMa), where each\ncompositional task requires a commonsense reasoning step and a math reasoning\nstep. We test it on 61 LLMs of different sizes, model families, and training\nstrategies. We find that LLMs can usually solve both steps in isolation, yet\ntheir accuracy drops by ~30% on average when the two are combined. This is a\nsubstantially greater performance gap than the one we observe in prior\ncompositional benchmarks that combine multiple steps of the same reasoning\ntype. In contrast, non-expert human annotators can solve the compositional\nquestions and the individual steps in AgentCoMa with similarly high accuracy.\nFurthermore, we conduct a series of interpretability studies to better\nunderstand the performance gap, examining neuron patterns, attention maps and\nmembership inference. Our work underscores a substantial degree of model\nbrittleness in the context of mixed-type compositional reasoning and offers a\ntest bed for future improvement.", "published": "2025-08-27 15:47:19", "link": "http://arxiv.org/abs/2508.19988v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diffusion Language Models Know the Answer Before Decoding", "abstract": "Diffusion language models (DLMs) have recently emerged as an alternative to\nautoregressive approaches, offering parallel sequence generation and flexible\ntoken orders. However, their inference remains slower than that of\nautoregressive models, primarily due to the cost of bidirectional attention and\nthe large number of refinement steps required for high quality outputs. In this\nwork, we highlight and leverage an overlooked property of DLMs early answer\nconvergence: in many cases, the correct answer can be internally identified by\nhalf steps before the final decoding step, both under semi-autoregressive and\nrandom remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99%\nof instances, respectively, can be decoded correctly using only half of the\nrefinement steps. Building on this observation, we introduce Prophet, a\ntraining-free fast decoding paradigm that enables early commit decoding.\nSpecifically, Prophet dynamically decides whether to continue refinement or to\ngo \"all-in\" (i.e., decode all remaining tokens in one step), using the\nconfidence gap between the top-2 prediction candidates as the criterion. It\nintegrates seamlessly into existing DLM implementations, incurs negligible\noverhead, and requires no additional training. Empirical evaluations of\nLLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the\nnumber of decoding steps by up to 3.4x while preserving high generation\nquality. These results recast DLM decoding as a problem of when to stop\nsampling, and demonstrate that early decode convergence provides a simple yet\npowerful mechanism for accelerating DLM inference, complementary to existing\nspeedup techniques. Our code is publicly available at\nhttps://github.com/pixeli99/Prophet.", "published": "2025-08-27 15:40:25", "link": "http://arxiv.org/abs/2508.19982v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity", "abstract": "Object hallucination in large vision-language models presents a significant\nchallenge to their safe deployment in real-world applications. Recent works\nhave proposed object-level hallucination scores to estimate the likelihood of\nobject hallucination; however, these methods typically adopt either a global or\nlocal perspective in isolation, which may limit detection reliability. In this\npaper, we introduce GLSim, a novel training-free object hallucination detection\nframework that leverages complementary global and local embedding similarity\nsignals between image and text modalities, enabling more accurate and reliable\nhallucination detection in diverse scenarios. We comprehensively benchmark\nexisting object hallucination detection methods and demonstrate that GLSim\nachieves superior detection performance, outperforming competitive baselines by\na significant margin.", "published": "2025-08-27 15:30:06", "link": "http://arxiv.org/abs/2508.19972v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation", "abstract": "Despite its significance, Arabic, a linguistically rich and morphologically\ncomplex language, faces the challenge of being under-resourced. The scarcity of\nlarge annotated datasets hampers the development of accurate tools for\nsubjectivity analysis in Arabic. Recent advances in deep learning and\nTransformers have proven highly effective for text classification in English\nand French. This paper proposes a new approach for subjectivity assessment in\nArabic textual data. To address the dearth of specialized annotated datasets,\nwe developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic\ndatasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we\nfine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and\nArabianGPT) on AraDhati+ for effective subjectivity classification.\nFurthermore, we experimented with an ensemble decision approach to harness the\nstrengths of individual models. Our approach achieves a remarkable accuracy of\n97.79\\,\\% for Arabic subjectivity classification. Results demonstrate the\neffectiveness of the proposed approach in addressing the challenges posed by\nlimited resources in Arabic language processing.", "published": "2025-08-27 15:20:12", "link": "http://arxiv.org/abs/2508.19966v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts", "abstract": "Understanding and reasoning over text within visual contexts poses a\nsignificant challenge for Vision-Language Models (VLMs), given the complexity\nand diversity of real-world scenarios. To address this challenge, text-rich\nVisual Question Answering (VQA) datasets and benchmarks have emerged for\nhigh-resource languages like English. However, a critical gap persists for\nlow-resource languages such as Korean, where the lack of comprehensive\nbenchmarks hinders robust model evaluation and comparison. To bridge this gap,\nwe introduce KRETA, a benchmark for Korean Reading and rEasoning in Text-rich\nVQA Attuned to diverse visual contexts. KRETA facilitates an in-depth\nevaluation of both visual text understanding and reasoning capabilities, while\nalso supporting a multifaceted assessment across 15 domains and 26 image types.\nAdditionally, we introduce a semi-automated VQA generation pipeline\nspecifically optimized for text-rich settings, leveraging refined stepwise\nimage decomposition and a rigorous seven-metric evaluation protocol to ensure\ndata quality. While KRETA is tailored for Korean, we hope our adaptable and\nextensible pipeline will facilitate the development of similar benchmarks in\nother languages, thereby accelerating multilingual VLM research. The code and\ndataset for KRETA are available at https://github.com/tabtoyou/KRETA.", "published": "2025-08-27 15:01:02", "link": "http://arxiv.org/abs/2508.19944v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "HEAL: A Hypothesis-Based Preference-Aware Analysis Framework", "abstract": "Preference optimization methods like DPO have achieved remarkable performance\nin LLM alignment. However, the evaluation for these methods relies on a single\nresponse and overlooks other potential outputs, which could also be generated\nin real-world applications within this hypothetical space. To address this\nissue, this paper presents a \\textbf{H}ypothesis-based\nPr\\textbf{E}ference-aware \\textbf{A}na\\textbf{L}ysis Framework (HEAL), a novel\nevaluation paradigm that formulates preference alignment as a re-ranking\nprocess within hypothesis spaces. The framework incorporates two complementary\nmetrics: ranking accuracy for evaluating ordinal consistency and preference\nstrength correlation for assessing continuous alignment. To facilitate this\nframework, we develop UniHypoBench, a unified hypothesis benchmark constructed\nfrom diverse instruction-response pairs. Through extensive experiments based on\nHEAL, with a particular focus on the intrinsic mechanisms of preference\nlearning, we demonstrate that current preference learning methods can\neffectively capture preferences provided by proxy models while simultaneously\nsuppressing negative samples. These findings contribute to preference learning\nresearch through two significant avenues. Theoretically, we introduce\nhypothesis space analysis as an innovative paradigm for understanding\npreference alignment. Practically, HEAL offers researchers robust diagnostic\ntools for refining preference optimization methods, while our empirical results\nidentify promising directions for developing more advanced alignment algorithms\ncapable of comprehensive preference capture.", "published": "2025-08-27 14:30:08", "link": "http://arxiv.org/abs/2508.19922v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems", "abstract": "While stereotypes are well-documented in human social interactions, AI\nsystems are often presumed to be less susceptible to such biases. Previous\nstudies have focused on biases inherited from training data, but whether\nstereotypes can emerge spontaneously in AI agent interactions merits further\nexploration. Through a novel experimental framework simulating workplace\ninteractions with neutral initial conditions, we investigate the emergence and\nevolution of stereotypes in LLM-based multi-agent systems. Our findings reveal\nthat (1) LLM-Based AI agents develop stereotype-driven biases in their\ninteractions despite beginning without predefined biases; (2) stereotype\neffects intensify with increased interaction rounds and decision-making power,\nparticularly after introducing hierarchical structures; (3) these systems\nexhibit group effects analogous to human social behavior, including halo\neffects, confirmation bias, and role congruity; and (4) these stereotype\npatterns manifest consistently across different LLM architectures. Through\ncomprehensive quantitative analysis, these findings suggest that stereotype\nformation in AI systems may arise as an emergent property of multi-agent\ninteractions, rather than merely from training data biases. Our work\nunderscores the need for future research to explore the underlying mechanisms\nof this phenomenon and develop strategies to mitigate its ethical impacts.", "published": "2025-08-27 14:25:43", "link": "http://arxiv.org/abs/2508.19919v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Logical Reasoning with Outcome Reward Models for Test-Time Scaling", "abstract": "Logical reasoning is a critical benchmark for evaluating the capabilities of\nlarge language models (LLMs), as it reflects their ability to derive valid\nconclusions from given premises. While the combination of test-time scaling\nwith dedicated outcome or process reward models has opened up new avenues to\nenhance LLMs performance in complex reasoning tasks, this space is\nunder-explored in deductive logical reasoning. We present a set of Outcome\nReward Models (ORMs) for deductive reasoning. To train the ORMs we mainly\ngenerate data using Chain-of-Thought (CoT) with single and multiple samples.\nAdditionally, we propose a novel tactic to further expand the type of errors\ncovered in the training dataset of the ORM. In particular, we propose an echo\ngeneration technique that leverages LLMs' tendency to reflect incorrect\nassumptions made in prompts to extract additional training data, covering\npreviously unexplored error types. While a standard CoT chain may contain\nerrors likely to be made by the reasoner, the echo strategy deliberately steers\nthe model toward incorrect reasoning. We show that ORMs trained on CoT and\necho-augmented data demonstrate improved performance on the FOLIO, JustLogic,\nand ProverQA datasets across four different LLMs.", "published": "2025-08-27 14:08:43", "link": "http://arxiv.org/abs/2508.19903v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Bangla-Bayanno: A 52K-Pair Bengali Visual Question Answering Dataset with LLM-Assisted Translation Refinement", "abstract": "In this paper, we introduce Bangla-Bayanno, an open-ended Visual Question\nAnswering (VQA) Dataset in Bangla, a widely used, low-resource language in\nmultimodal AI research. The majority of existing datasets are either manually\nannotated with an emphasis on a specific domain, query type, or answer type or\nare constrained by niche answer formats. In order to mitigate human-induced\nerrors and guarantee lucidity, we implemented a multilingual LLM-assisted\ntranslation refinement pipeline. This dataset overcomes the issues of\nlow-quality translations from multilingual sources. The dataset comprises\n52,650 question-answer pairs across 4750+ images. Questions are classified into\nthree distinct answer types: nominal (short descriptive), quantitative\n(numeric), and polar (yes/no). Bangla-Bayanno provides the most comprehensive\nopen-source, high-quality VQA benchmark in Bangla, aiming to advance research\nin low-resource multimodal learning and facilitate the development of more\ninclusive AI systems.", "published": "2025-08-27 13:48:04", "link": "http://arxiv.org/abs/2508.19887v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "AI-Powered Detection of Inappropriate Language in Medical School Curricula", "abstract": "The use of inappropriate language -- such as outdated, exclusionary, or\nnon-patient-centered terms -- medical instructional materials can significantly\ninfluence clinical training, patient interactions, and health outcomes. Despite\ntheir reputability, many materials developed over past decades contain examples\nnow considered inappropriate by current medical standards. Given the volume of\ncurricular content, manually identifying instances of inappropriate use of\nlanguage (IUL) and its subcategories for systematic review is prohibitively\ncostly and impractical. To address this challenge, we conduct a first-in-class\nevaluation of small language models (SLMs) fine-tuned on labeled data and\npre-trained LLMs with in-context learning on a dataset containing approximately\n500 documents and over 12,000 pages. For SLMs, we consider: (1) a general IUL\nclassifier, (2) subcategory-specific binary classifiers, (3) a multilabel\nclassifier, and (4) a two-stage hierarchical pipeline for general IUL detection\nfollowed by multilabel classification. For LLMs, we consider variations of\nprompts that include subcategory definitions and/or shots. We found that both\nLLama-3 8B and 70B, even with carefully curated shots, are largely outperformed\nby SLMs. While the multilabel classifier performs best on annotated data,\nsupplementing training with unflagged excerpts as negative examples boosts the\nspecific classifiers' AUC by up to 25%, making them most effective models for\nmitigating harmful language in medical curricula.", "published": "2025-08-27 13:40:45", "link": "http://arxiv.org/abs/2508.19883v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.1; I.2.7"], "primary_category": "cs.CL"}
{"title": "Beyond Shallow Heuristics: Leveraging Human Intuition for Curriculum Learning", "abstract": "Curriculum learning (CL) aims to improve training by presenting data from\n\"easy\" to \"hard\", yet defining and measuring linguistic difficulty remains an\nopen challenge. We investigate whether human-curated simple language can serve\nas an effective signal for CL. Using the article-level labels from the Simple\nWikipedia corpus, we compare label-based curricula to competence-based\nstrategies relying on shallow heuristics. Our experiments with a BERT-tiny\nmodel show that adding simple data alone yields no clear benefit. However,\nstructuring it via a curriculum -- especially when introduced first --\nconsistently improves perplexity, particularly on simple language. In contrast,\ncompetence-based curricula lead to no consistent gains over random ordering,\nprobably because they fail to effectively separate the two classes. Our results\nsuggest that human intuition about linguistic difficulty can guide CL for\nlanguage model pre-training.", "published": "2025-08-27 13:35:13", "link": "http://arxiv.org/abs/2508.19873v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TokenVerse++: Towards Flexible Multitask Learning with Dynamic Task Activation", "abstract": "Token-based multitasking frameworks like TokenVerse require all training\nutterances to have labels for all tasks, hindering their ability to leverage\npartially annotated datasets and scale effectively. We propose TokenVerse++,\nwhich introduces learnable vectors in the acoustic embedding space of the\nXLSR-Transducer ASR model for dynamic task activation. This core mechanism\nenables training with utterances labeled for only a subset of tasks, a key\nadvantage over TokenVerse. We demonstrate this by successfully integrating a\ndataset with partial labels, specifically for ASR and an additional task,\nlanguage identification, improving overall performance. TokenVerse++ achieves\nresults on par with or exceeding TokenVerse across multiple tasks, establishing\nit as a more practical multitask alternative without sacrificing ASR\nperformance.", "published": "2025-08-27 13:16:31", "link": "http://arxiv.org/abs/2508.19856v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SoK: Large Language Model Copyright Auditing via Fingerprinting", "abstract": "The broad capabilities and substantial resources required to train Large\nLanguage Models (LLMs) make them valuable intellectual property, yet they\nremain vulnerable to copyright infringement, such as unauthorized use and model\ntheft. LLM fingerprinting, a non-intrusive technique that extracts and compares\nthe distinctive features from LLMs to identify infringements, offers a\npromising solution to copyright auditing. However, its reliability remains\nuncertain due to the prevalence of diverse model modifications and the lack of\nstandardized evaluation. In this SoK, we present the first comprehensive study\nof LLM fingerprinting. We introduce a unified framework and formal taxonomy\nthat categorizes existing methods into white-box and black-box approaches,\nproviding a structured overview of the state of the art. We further propose\nLeaFBench, the first systematic benchmark for evaluating LLM fingerprinting\nunder realistic deployment scenarios. Built upon mainstream foundation models\nand comprising 149 distinct model instances, LeaFBench integrates 13\nrepresentative post-development techniques, spanning both parameter-altering\nmethods (e.g., fine-tuning, quantization) and parameter-independent mechanisms\n(e.g., system prompts, RAG). Extensive experiments on LeaFBench reveal the\nstrengths and weaknesses of existing methods, thereby outlining future research\ndirections and critical open problems in this emerging field. The code is\navailable at https://github.com/shaoshuo-ss/LeaFBench.", "published": "2025-08-27 12:56:57", "link": "http://arxiv.org/abs/2508.19843v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Scalable and consistent few-shot classification of survey responses using text embeddings", "abstract": "Qualitative analysis of open-ended survey responses is a commonly-used\nresearch method in the social sciences, but traditional coding approaches are\noften time-consuming and prone to inconsistency. Existing solutions from\nNatural Language Processing such as supervised classifiers, topic modeling\ntechniques, and generative large language models have limited applicability in\nqualitative analysis, since they demand extensive labeled data, disrupt\nestablished qualitative workflows, and/or yield variable results. In this\npaper, we introduce a text embedding-based classification framework that\nrequires only a handful of examples per category and fits well with standard\nqualitative workflows. When benchmarked against human analysis of a conceptual\nphysics survey consisting of 2899 open-ended responses, our framework achieves\na Cohen's Kappa ranging from 0.74 to 0.83 as compared to expert human coders in\nan exhaustive coding scheme. We further show how performance of this framework\nimproves with fine-tuning of the text embedding model, and how the method can\nbe used to audit previously-analyzed datasets. These findings demonstrate that\ntext embedding-assisted coding can flexibly scale to thousands of responses\nwithout sacrificing interpretability, opening avenues for deductive qualitative\nanalysis at scale.", "published": "2025-08-27 12:45:25", "link": "http://arxiv.org/abs/2508.19836v1", "categories": ["cs.CL", "physics.ed-ph"], "primary_category": "cs.CL"}
{"title": "Benchmarking Hindi LLMs: A New Suite of Datasets and a Comparative Analysis", "abstract": "Evaluating instruction-tuned Large Language Models (LLMs) in Hindi is\nchallenging due to a lack of high-quality benchmarks, as direct translation of\nEnglish datasets fails to capture crucial linguistic and cultural nuances. To\naddress this, we introduce a suite of five Hindi LLM evaluation datasets:\nIFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, and BFCL-Hi. These were created\nusing a methodology that combines from-scratch human annotation with a\ntranslate-and-verify process. We leverage this suite to conduct an extensive\nbenchmarking of open-source LLMs supporting Hindi, providing a detailed\ncomparative analysis of their current capabilities. Our curation process also\nserves as a replicable methodology for developing benchmarks in other\nlow-resource languages.", "published": "2025-08-27 12:35:31", "link": "http://arxiv.org/abs/2508.19831v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\na wide range of NLP tasks, but they remain fundamentally stateless, constrained\nby limited context windows that hinder long-horizon reasoning. Recent efforts\nto address this limitation often augment LLMs with an external memory bank, yet\nmost existing pipelines are static and heuristic-driven, lacking any learned\nmechanism for deciding what to store, update, or retrieve. We present\nMemory-R1, a reinforcement learning (RL) framework that equips LLMs with the\nability to actively manage and utilize external memory through two specialized\nagents: a Memory Manager that learns to perform structured memory operations\n{ADD, UPDATE, DELETE, NOOP}, and an Answer Agent that selects the most relevant\nentries and reasons over them to produce an answer. Both agents are fine-tuned\nwith outcome-driven RL (PPO and GRPO), enabling adaptive memory management and\nuse with minimal supervision. With as few as 152 question-answer pairs and a\ncorresponding temporal memory bank for training, Memory-R1 outperforms the most\ncompetitive existing baseline and demonstrates strong generalization across\ndiverse question types and LLM backbones. Beyond presenting an effective\napproach, this work provides insights into how RL can unlock more agentic,\nmemory-aware behaviors in LLMs, pointing toward richer, more persistent\nreasoning systems.", "published": "2025-08-27 12:26:55", "link": "http://arxiv.org/abs/2508.19828v1", "categories": ["cs.CL", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?", "abstract": "Recent work has demonstrated that Chain-of-Thought (CoT) often yields limited\ngains for soft-reasoning problems such as analytical and commonsense reasoning.\nCoT can also be unfaithful to a model's actual reasoning. We investigate the\ndynamics and faithfulness of CoT in soft-reasoning tasks across\ninstruction-tuned, reasoning and reasoning-distilled models. Our findings\nreveal differences in how these models rely on CoT, and show that CoT influence\nand faithfulness are not always aligned.", "published": "2025-08-27 12:25:29", "link": "http://arxiv.org/abs/2508.19827v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables", "abstract": "Extensive research has been conducted to explore the capabilities of large\nlanguage models (LLMs) in table reasoning. However, the essential task of\ntransforming tables information into reports remains a significant challenge\nfor industrial applications. This task is plagued by two critical issues: 1)\nthe complexity and diversity of tables lead to suboptimal reasoning outcomes;\nand 2) existing table benchmarks lack the capacity to adequately assess the\npractical application of this task. To fill this gap, we propose the\ntable-to-report task and construct a bilingual benchmark named T2R-bench, where\nthe key information flow from the tables to the reports for this task. The\nbenchmark comprises 457 industrial tables, all derived from real-world\nscenarios and encompassing 19 industry domains as well as 4 types of industrial\ntables. Furthermore, we propose an evaluation criteria to fairly measure the\nquality of report generation. The experiments on 25 widely-used LLMs reveal\nthat even state-of-the-art models like Deepseek-R1 only achieves performance\nwith 62.71 overall score, indicating that LLMs still have room for improvement\non T2R-bench. Source code and data will be available after acceptance.", "published": "2025-08-27 11:55:40", "link": "http://arxiv.org/abs/2508.19813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Principled Personas: Defining and Measuring the Intended Effects of Persona Prompting on Task Performance", "abstract": "Expert persona prompting -- assigning roles such as expert in math to\nlanguage models -- is widely used for task improvement. However, prior work\nshows mixed results on its effectiveness, and does not consider when and why\npersonas should improve performance. We analyze the literature on persona\nprompting for task improvement and distill three desiderata: 1) performance\nadvantage of expert personas, 2) robustness to irrelevant persona attributes,\nand 3) fidelity to persona attributes. We then evaluate 9 state-of-the-art LLMs\nacross 27 tasks with respect to these desiderata. We find that expert personas\nusually lead to positive or non-significant performance changes. Surprisingly,\nmodels are highly sensitive to irrelevant persona details, with performance\ndrops of almost 30 percentage points. In terms of fidelity, we find that while\nhigher education, specialization, and domain-relatedness can boost performance,\ntheir effects are often inconsistent or negligible across tasks. We propose\nmitigation strategies to improve robustness -- but find they only work for the\nlargest, most capable models. Our findings underscore the need for more careful\npersona design and for evaluation schemes that reflect the intended effects of\npersona usage.", "published": "2025-08-27 10:40:57", "link": "http://arxiv.org/abs/2508.19764v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval", "abstract": "Access to diverse perspectives is essential for understanding real-world\nevents, yet most news retrieval systems prioritize textual relevance, leading\nto redundant results and limited viewpoint exposure. We propose NEWSCOPE, a\ntwo-stage framework for diverse news retrieval that enhances event coverage by\nexplicitly modeling semantic variation at the sentence level. The first stage\nretrieves topically relevant content using dense retrieval, while the second\nstage applies sentence-level clustering and diversity-aware re-ranking to\nsurface complementary information. To evaluate retrieval diversity, we\nintroduce three interpretable metrics, namely Average Pairwise Distance,\nPositive Cluster Coverage, and Information Density Ratio, and construct two\nparagraph-level benchmarks: LocalNews and DSGlobal. Experiments show that\nNEWSCOPE consistently outperforms strong baselines, achieving significantly\nhigher diversity without compromising relevance. Our results demonstrate the\neffectiveness of fine-grained, interpretable modeling in mitigating redundancy\nand promoting comprehensive event understanding. The data and code are\navailable at https://github.com/tangyixuan/NEWSCOPE.", "published": "2025-08-27 10:37:32", "link": "http://arxiv.org/abs/2508.19758v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Spotlight Attention: Towards Efficient LLM Generation via Non-linear Hashing-based KV Cache Retrieval", "abstract": "Reducing the key-value (KV) cache burden in Large Language Models (LLMs)\nsignificantly accelerates inference. Dynamically selecting critical KV caches\nduring decoding helps maintain performance. Existing methods use random linear\nhashing to identify important tokens, but this approach is inefficient due to\nthe orthogonal distribution of queries and keys within two narrow cones in\nLLMs. We introduce Spotlight Attention, a novel method that employs non-linear\nhashing functions to optimize the embedding distribution of queries and keys,\nenhancing coding efficiency and robustness. We also developed a lightweight,\nstable training framework using a Bradley-Terry ranking-based loss, enabling\noptimization of the non-linear hashing module on GPUs with 16GB memory in 8\nhours. Experimental results show that Spotlight Attention drastically improves\nretrieval precision while shortening the length of the hash code at least\n5$\\times$ compared to traditional linear hashing. Finally, we exploit the\ncomputational advantages of bitwise operations by implementing specialized CUDA\nkernels, achieving hashing retrieval for 512K tokens in under 100$\\mu$s on a\nsingle A100 GPU, with end-to-end throughput up to 3$\\times$ higher than vanilla\ndecoding.", "published": "2025-08-27 10:11:27", "link": "http://arxiv.org/abs/2508.19740v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks", "abstract": "Commonsense visual-question answering often hinges on knowledge that is\nmissing from the image or the question. Small vision-language models (sVLMs)\nsuch as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative\ncounterparts. To study the effect of careful commonsense knowledge integration\non sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural\nlanguage facts, (ii) prompts an LLM to craft natural language explanations, and\n(iii) feeds both signals to sVLMs respectively across two commonsense VQA\ndatasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts\nretrieved using a fine-tuned ColBERTv2 and an object information-enriched\nprompt yield explanations that largely cut down hallucinations, while lifting\nthe end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA\nand other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B\nand SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional\nfinetuning using noise-robust losses (such as symmetric cross entropy and\ngeneralised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our\nfindings expose when LLM-based commonsense knowledge beats retrieval from\ncommonsense knowledge bases, how noise-aware training stabilises small models\nin the context of external knowledge augmentation, and why parameter-efficient\ncommonsense reasoning is now within reach for 250M models.", "published": "2025-08-27 09:34:28", "link": "http://arxiv.org/abs/2508.19724v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CAM\u00d5ES: A Comprehensive Automatic Speech Recognition Benchmark for European Portuguese", "abstract": "Existing resources for Automatic Speech Recognition in Portuguese are mostly\nfocused on Brazilian Portuguese, leaving European Portuguese (EP) and other\nvarieties under-explored. To bridge this gap, we introduce CAM\\~OES, the first\nopen framework for EP and other Portuguese varieties. It consists of (1) a\ncomprehensive evaluation benchmark, including 46h of EP test data spanning\nmultiple domains; and (2) a collection of state-of-the-art models. For the\nlatter, we consider multiple foundation models, evaluating their zero-shot and\nfine-tuned performances, as well as E-Branchformer models trained from scratch.\nA curated set of 425h of EP was used for both fine-tuning and training. Our\nresults show comparable performance for EP between fine-tuned foundation models\nand the E-Branchformer. Furthermore, the best-performing models achieve\nrelative improvements above 35% WER, compared to the strongest zero-shot\nfoundation model, establishing a new state-of-the-art for EP and other\nvarieties.", "published": "2025-08-27 09:30:43", "link": "http://arxiv.org/abs/2508.19721v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Continuously Steering LLMs Sensitivity to Contextual Knowledge with Proxy Models", "abstract": "In Large Language Models (LLMs) generation, there exist knowledge conflicts\nand scenarios where parametric knowledge contradicts knowledge provided in the\ncontext. Previous works studied tuning, decoding algorithms, or locating and\nediting context-aware neurons to adapt LLMs to be faithful to new contextual\nknowledge. However, they are usually inefficient or ineffective for large\nmodels, not workable for black-box models, or unable to continuously adjust\nLLMs' sensitivity to the knowledge provided in the context. To mitigate these\nproblems, we propose CSKS (Continuously Steering Knowledge Sensitivity), a\nsimple framework that can steer LLMs' sensitivity to contextual knowledge\ncontinuously at a lightweight cost. Specifically, we tune two small LMs (i.e.\nproxy models) and use the difference in their output distributions to shift the\noriginal distribution of an LLM without modifying the LLM weights. In the\nevaluation process, we not only design synthetic data and fine-grained metrics\nto measure models' sensitivity to contextual knowledge but also use a real\nconflict dataset to validate CSKS's practical efficacy. Extensive experiments\ndemonstrate that our framework achieves continuous and precise control over\nLLMs' sensitivity to contextual knowledge, enabling both increased sensitivity\nand reduced sensitivity, thereby allowing LLMs to prioritize either contextual\nor parametric knowledge as needed flexibly. Our data and code are available at\nhttps://github.com/OliveJuiceLin/CSKS.", "published": "2025-08-27 09:30:24", "link": "http://arxiv.org/abs/2508.19720v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Safety Alignment Should Be Made More Than Just A Few Attention Heads", "abstract": "Current safety alignment for large language models(LLMs) continues to present\nvulnerabilities, given that adversarial prompting can effectively bypass their\nsafety measures.Our investigation shows that these safety mechanisms\npredominantly depend on a limited subset of attention heads: removing or\nablating these heads can severely compromise model safety. To identify and\nevaluate these safety-critical components, we introduce RDSHA, a targeted\nablation method that leverages the model's refusal direction to pinpoint\nattention heads mostly responsible for safety behaviors. Further analysis shows\nthat existing jailbreak attacks exploit this concentration by selectively\nbypassing or manipulating these critical attention heads. To address this\nissue, we propose AHD, a novel training strategy designed to promote the\ndistributed encoding of safety-related behaviors across numerous attention\nheads. Experimental results demonstrate that AHD successfully distributes\nsafety-related capabilities across more attention heads. Moreover, evaluations\nunder several mainstream jailbreak attacks show that models trained with AHD\nexhibit considerably stronger safety robustness, while maintaining overall\nfunctional utility.", "published": "2025-08-27 09:06:28", "link": "http://arxiv.org/abs/2508.19697v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Building Task Bots with Self-learning for Enhanced Adaptability, Extensibility, and Factuality", "abstract": "Developing adaptable, extensible, and accurate task bots with minimal or zero\nhuman intervention is a significant challenge in dialog research. This thesis\nexamines the obstacles and potential solutions for creating such bots, focusing\non innovative techniques that enable bots to learn and adapt autonomously in\nconstantly changing environments.", "published": "2025-08-27 08:52:47", "link": "http://arxiv.org/abs/2508.19689v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Survey of Specialized Large Language Model", "abstract": "The rapid evolution of specialized large language models (LLMs) has\ntransitioned from simple domain adaptation to sophisticated native\narchitectures, marking a paradigm shift in AI development. This survey\nsystematically examines this progression across healthcare, finance, legal, and\ntechnical domains. Besides the wide use of specialized LLMs, technical\nbreakthrough such as the emergence of domain-native designs beyond fine-tuning,\ngrowing emphasis on parameter efficiency through sparse computation and\nquantization, increasing integration of multimodal capabilities and so on are\napplied to recent LLM agent. Our analysis reveals how these innovations address\nfundamental limitations of general-purpose LLMs in professional applications,\nwith specialized models consistently performance gains on domain-specific\nbenchmarks. The survey further highlights the implications for E-Commerce field\nto fill gaps in the field.", "published": "2025-08-27 08:27:23", "link": "http://arxiv.org/abs/2508.19667v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automatic integration of SystemC in the FMI standard for Software-defined Vehicle design", "abstract": "The recent advancements of the automotive sector demand robust co-simulation\nmethodologies that enable early validation and seamless integration across\nhardware and software domains. However, the lack of standardized interfaces and\nthe dominance of proprietary simulation platforms pose significant challenges\nto collaboration, scalability, and IP protection. To address these limitations,\nthis paper presents an approach for automatically wrapping SystemC models by\nusing the Functional Mock-up Interface (FMI) standard. This method combines the\nmodeling accuracy and fast time-to-market of SystemC with the interoperability\nand encapsulation benefits of FMI, enabling secure and portable integration of\nembedded components into co-simulation workflows. We validate the proposed\nmethodology on real-world case studies, demonstrating its effectiveness with\ncomplex designs.", "published": "2025-08-27 08:24:56", "link": "http://arxiv.org/abs/2508.19665v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Symbolic Adversarial Learning Framework for Evolving Fake News Generation and Detection", "abstract": "Rapid LLM advancements heighten fake news risks by enabling the automatic\ngeneration of increasingly sophisticated misinformation. Previous detection\nmethods, including fine-tuned small models or LLM-based detectors, often\nstruggle with its dynamically evolving nature. In this work, we propose a novel\nframework called the Symbolic Adversarial Learning Framework (SALF), which\nimplements an adversarial training paradigm by an agent symbolic learning\noptimization process, rather than relying on numerical updates. SALF introduces\na paradigm where the generation agent crafts deceptive narratives, and the\ndetection agent uses structured debates to identify logical and factual flaws\nfor detection, and they iteratively refine themselves through such adversarial\ninteractions. Unlike traditional neural updates, we represent agents using\nagent symbolic learning, where learnable weights are defined by agent prompts,\nand simulate back-propagation and gradient descent by operating on natural\nlanguage representations of weights, loss, and gradients. Experiments on two\nmultilingual benchmark datasets demonstrate SALF's effectiveness, showing it\ngenerates sophisticated fake news that degrades state-of-the-art detection\nperformance by up to 53.4% in Chinese and 34.2% in English on average. SALF\nalso refines detectors, improving detection of refined content by up to 7.7%.\nWe hope our work inspires further exploration into more robust, adaptable fake\nnews detection systems.", "published": "2025-08-27 07:14:17", "link": "http://arxiv.org/abs/2508.19633v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word Chain Generators for Prefix Normal Words", "abstract": "In 2011, Fici and Lipt\\'ak introduced prefix normal words. A binary word is\nprefix normal if it has no factor (substring) that contains more occurrences of\nthe letter 1 than the prefix of the same length. Among the open problems\nregarding this topic are the enumeration of prefix normal words and efficient\ntesting methods. We show a range of characteristics of prefix normal words.\nThese include properties of factors that are responsible for a word not being\nprefix normal. With word chains and generators, we introduce new ways of\nrelating words of the same length to each other.", "published": "2025-08-27 06:56:45", "link": "http://arxiv.org/abs/2508.19619v1", "categories": ["math.CO", "cs.CL"], "primary_category": "math.CO"}
{"title": "LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation", "abstract": "Retrieval-augmented generation (RAG) incorporates external knowledge into\nlarge language models (LLMs), improving their adaptability to downstream tasks\nand enabling information updates. Surprisingly, recent empirical evidence\ndemonstrates that injecting noise into retrieved relevant documents\nparadoxically facilitates exploitation of external knowledge and improves\ngeneration quality. Although counterintuitive and challenging to apply in\npractice, this phenomenon enables granular control and rigorous analysis of how\nLLMs integrate external knowledge. Therefore, in this paper, we intervene on\nnoise injection and establish a layer-specific functional demarcation within\nthe LLM: shallow layers specialize in local context modeling, intermediate\nlayers focus on integrating long-range external factual knowledge, and deeper\nlayers primarily rely on parametric internal knowledge. Building on this\ninsight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that\ndirectly combines representations from an intermediate layer with final-layer\ndecoding outputs to fully exploit the external factual knowledge. To identify\nthe optimal intermediate layer, we introduce an internal knowledge score (IKS)\ncriterion that selects the layer with the lowest IKS value in the latter half\nof layers. Experimental results across multiple benchmarks demonstrate that LFD\nhelps RAG systems more effectively surface retrieved context knowledge with\nminimal cost.", "published": "2025-08-27 06:48:46", "link": "http://arxiv.org/abs/2508.19614v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Instructional Agents: LLM Agents on Automated Course Material Generation for Teaching Faculties", "abstract": "Preparing high-quality instructional materials remains a labor-intensive\nprocess that often requires extensive coordination among teaching faculty,\ninstructional designers, and teaching assistants. In this work, we present\nInstructional Agents, a multi-agent large language model (LLM) framework\ndesigned to automate end-to-end course material generation, including syllabus\ncreation, lecture scripts, LaTeX-based slides, and assessments. Unlike existing\nAI-assisted educational tools that focus on isolated tasks, Instructional\nAgents simulates role-based collaboration among educational agents to produce\ncohesive and pedagogically aligned content. The system operates in four modes:\nAutonomous, Catalog-Guided, Feedback-Guided, and Full Co-Pilot mode, enabling\nflexible control over the degree of human involvement. We evaluate\nInstructional Agents across five university-level computer science courses and\nshow that it produces high-quality instructional materials while significantly\nreducing development time and human workload. By supporting institutions with\nlimited instructional design capacity, Instructional Agents provides a scalable\nand cost-effective framework to democratize access to high-quality education,\nparticularly in underserved or resource-constrained settings.", "published": "2025-08-27 06:45:06", "link": "http://arxiv.org/abs/2508.19611v1", "categories": ["cs.AI", "cs.CL", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Understanding and Leveraging the Expert Specialization of Context Faithfulness in Mixture-of-Experts LLMs", "abstract": "Context faithfulness is essential for reliable reasoning in context-dependent\nscenarios. However, large language models often struggle to ground their\noutputs in the provided context, resulting in irrelevant responses. Inspired by\nthe emergent expert specialization observed in mixture-of-experts\narchitectures, this work investigates whether certain experts exhibit\nspecialization in context utilization, offering a potential pathway toward\ntargeted optimization for improved context faithfulness. To explore this, we\npropose Router Lens, a method that accurately identifies context-faithful\nexperts. Our analysis reveals that these experts progressively amplify\nattention to relevant contextual information, thereby enhancing context\ngrounding. Building on this insight, we introduce Context-faithful Expert\nFine-Tuning (CEFT), a lightweight optimization approach that selectively\nfine-tunes context-faithful experts. Experiments across a wide range of\nbenchmarks and models demonstrate that CEFT matches or surpasses the\nperformance of full fine-tuning while being significantly more efficient.", "published": "2025-08-27 06:07:13", "link": "http://arxiv.org/abs/2508.19594v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards stable AI systems for Evaluating Arabic Pronunciations", "abstract": "Modern Arabic ASR systems such as wav2vec 2.0 excel at word- and\nsentence-level transcription, yet struggle to classify isolated letters. In\nthis study, we show that this phoneme-level task, crucial for language\nlearning, speech therapy, and phonetic research, is challenging because\nisolated letters lack co-articulatory cues, provide no lexical context, and\nlast only a few hundred milliseconds. Recogniser systems must therefore rely\nsolely on variable acoustic cues, a difficulty heightened by Arabic's emphatic\n(pharyngealized) consonants and other sounds with no close analogues in many\nlanguages. This study introduces a diverse, diacritised corpus of isolated\nArabic letters and demonstrates that state-of-the-art wav2vec 2.0 models\nachieve only 35% accuracy on it. Training a lightweight neural network on\nwav2vec embeddings raises performance to 65%. However, adding a small amplitude\nperturbation (epsilon = 0.05) cuts accuracy to 32%. To restore robustness, we\napply adversarial training, limiting the noisy-speech drop to 9% while\npreserving clean-speech accuracy. We detail the corpus, training pipeline, and\nevaluation protocol, and release, on demand, data and code for reproducibility.\nFinally, we outline future work extending these methods to word- and\nsentence-level frameworks, where precise letter pronunciation remains critical.", "published": "2025-08-27 05:49:15", "link": "http://arxiv.org/abs/2508.19587v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ArgCMV: An Argument Summarization Benchmark for the LLM-era", "abstract": "Key point extraction is an important task in argument summarization which\ninvolves extracting high-level short summaries from arguments. Existing\napproaches for KP extraction have been mostly evaluated on the popular ArgKP21\ndataset. In this paper, we highlight some of the major limitations of the\nArgKP21 dataset and demonstrate the need for new benchmarks that are more\nrepresentative of actual human conversations. Using SoTA large language models\n(LLMs), we curate a new argument key point extraction dataset called ArgCMV\ncomprising of around 12K arguments from actual online human debates spread\nacross over 3K topics. Our dataset exhibits higher complexity such as longer,\nco-referencing arguments, higher presence of subjective discourse units, and a\nlarger range of topics over ArgKP21. We show that existing methods do not adapt\nwell to ArgCMV and provide extensive benchmark results by experimenting with\nexisting baselines and latest open source models. This work introduces a novel\nKP extraction dataset for long-context online discussions, setting the stage\nfor the next generation of LLM-driven summarization research.", "published": "2025-08-27 05:26:36", "link": "http://arxiv.org/abs/2508.19580v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts", "abstract": "We introduce HAMLET, a holistic and automated framework for evaluating the\nlong-context comprehension of large language models (LLMs). HAMLET structures\nsource texts into a three-level key-fact hierarchy at root-, branch-, and\nleaf-levels, and employs query-focused summarization to evaluate how well\nmodels recall and faithfully represent information at each level. To validate\nthe reliability of our fully automated pipeline, we conduct a systematic human\nstudy, showing that our automatic evaluation achieves over 90% agreement with\nexpert human judgments, while reducing the cost by up to 25 times. HAMLET\nreveals that LLMs struggle with fine-grained comprehension, especially at the\nleaf level, and are sensitive to positional effects like the\nlost-in-the-middle. Analytical queries pose greater challenges than narrative\nones, and consistent performance gaps emerge between open-source and\nproprietary models, as well as across model scales. Our code and dataset are\npublicly available at https://github.com/DISL-Lab/HAMLET.", "published": "2025-08-27 05:23:22", "link": "http://arxiv.org/abs/2508.19578v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Functional Consistency of LLM Code Embeddings: A Self-Evolving Data Synthesis Framework for Benchmarking", "abstract": "Embedding models have demonstrated strong performance in tasks like\nclustering, retrieval, and feature extraction while offering computational\nadvantages over generative models and cross-encoders. Benchmarks such as MTEB\nhave shown that text embeddings from large language models (LLMs) capture rich\nsemantic information, but their ability to reflect code-level functional\nsemantics remains unclear. Existing studies largely focus on code clone\ndetection, which emphasizes syntactic similarity and overlooks functional\nunderstanding. In this paper, we focus on the functional consistency of LLM\ncode embeddings, which determines if two code snippets perform the same\nfunction regardless of syntactic differences. We propose a novel data synthesis\nframework called Functionality-Oriented Code Self-Evolution to construct\ndiverse and challenging benchmarks. Specifically, we define code examples\nacross four semantic and syntactic categories and find that existing datasets\npredominantly capture syntactic properties. Our framework generates four unique\nvariations from a single code instance, providing a broader spectrum of code\nexamples that better reflect functional differences. Extensive experiments on\nthree downstream tasks-code clone detection, code functional consistency\nidentification, and code retrieval-demonstrate that embedding models\nsignificantly improve their performance when trained on our evolved datasets.\nThese results highlight the effectiveness and generalization of our data\nsynthesis framework, advancing the functional understanding of code.", "published": "2025-08-27 04:17:02", "link": "http://arxiv.org/abs/2508.19558v1", "categories": ["cs.SE", "cs.CL", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Language Models Identify Ambiguities and Exploit Loopholes", "abstract": "Studying the responses of large language models (LLMs) to loopholes presents\na two-fold opportunity. First, it affords us a lens through which to examine\nambiguity and pragmatics in LLMs, since exploiting a loophole requires\nidentifying ambiguity and performing sophisticated pragmatic reasoning. Second,\nloopholes pose an interesting and novel alignment problem where the model is\npresented with conflicting goals and can exploit ambiguities to its own\nadvantage. To address these questions, we design scenarios where LLMs are given\na goal and an ambiguous user instruction in conflict with the goal, with\nscenarios covering scalar implicature, structural ambiguities, and power\ndynamics. We then measure different models' abilities to exploit loopholes to\nsatisfy their given goals as opposed to the goals of the user. We find that\nboth closed-source and stronger open-source models can identify ambiguities and\nexploit their resulting loopholes, presenting a potential AI safety risk. Our\nanalysis indicates that models which exploit loopholes explicitly identify and\nreason about both ambiguity and conflicting goals.", "published": "2025-08-27 03:40:17", "link": "http://arxiv.org/abs/2508.19546v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Emotion Transfer with Enhanced Prototype for Unseen Emotion Recognition in Conversation", "abstract": "Current Emotion Recognition in Conversation (ERC) research follows a\nclosed-domain assumption. However, there is no clear consensus on emotion\nclassification in psychology, which presents a challenge for models when it\ncomes to recognizing previously unseen emotions in real-world applications. To\nbridge this gap, we introduce the Unseen Emotion Recognition in Conversation\n(UERC) task for the first time and propose ProEmoTrans, a solid prototype-based\nemotion transfer framework. This prototype-based approach shows promise but\nstill faces key challenges: First, implicit expressions complicate emotion\ndefinition, which we address by proposing an LLM-enhanced description approach.\nSecond, utterance encoding in long conversations is difficult, which we tackle\nwith a proposed parameter-free mechanism for efficient encoding and overfitting\nprevention. Finally, the Markovian flow nature of emotions is hard to transfer,\nwhich we address with an improved Attention Viterbi Decoding (AVD) method to\ntransfer seen emotion transitions to unseen emotions. Extensive experiments on\nthree datasets show that our method serves as a strong baseline for preliminary\nexploration in this new area.", "published": "2025-08-27 03:16:16", "link": "http://arxiv.org/abs/2508.19533v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Alignment with Fill-In-the-Middle for Enhancing Code Generation", "abstract": "The code generation capabilities of Large Language Models (LLMs) have\nadvanced applications like tool invocation and problem-solving. However,\nimproving performance in code-related tasks remains challenging due to limited\ntraining data that is verifiable with accurate test cases. While Direct\nPreference Optimization (DPO) has shown promise, existing methods for\ngenerating test cases still face limitations. In this paper, we propose a novel\napproach that splits code snippets into smaller, granular blocks, creating more\ndiverse DPO pairs from the same test cases. Additionally, we introduce the\nAbstract Syntax Tree (AST) splitting and curriculum training method to enhance\nthe DPO training. Our approach demonstrates significant improvements in code\ngeneration tasks, as validated by experiments on benchmark datasets such as\nHumanEval (+), MBPP (+), APPS, LiveCodeBench, and BigCodeBench. Code and data\nare available at https://github.com/SenseLLM/StructureCoder.", "published": "2025-08-27 03:15:53", "link": "http://arxiv.org/abs/2508.19532v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding", "abstract": "Discrete diffusion language models have shown strong potential for text\ngeneration, yet standard supervised fine-tuning (SFT) misaligns with their\nsemi-autoregressive inference: training randomly masks tokens across the entire\nresponse, while inference generates fixed-size blocks sequentially. This\nmismatch introduces noisy prefixes and leaky suffixes, biasing gradients away\nfrom the desired blockwise likelihood. We propose Blockwise SFT, which\npartitions responses into fixed-size blocks, selects one active block per step\nfor stochastic masking, freezes all preceding tokens, and fully hides future\nones. Loss is computed only over the active block, directly mirroring the\nblockwise decoding process. Experiments on GSM8K, MATH, and MetaMathQA show\nconsistent gains over classical SFT under equal compute or token budgets. Block\nsize consistency studies and ablations confirm that improvements stem from\nfaithful training-inference alignment rather than incidental masking effects.\nOur results highlight the importance of matching supervision granularity to the\ndecoding procedure in diffusion-based language models.", "published": "2025-08-27 02:49:33", "link": "http://arxiv.org/abs/2508.19529v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Geopolitical Parallax: Beyond Walter Lippmann Just After Large Language Models", "abstract": "Objectivity in journalism has long been contested, oscillating between ideals\nof neutral, fact-based reporting and the inevitability of subjective framing.\nWith the advent of large language models (LLMs), these tensions are now\nmediated by algorithmic systems whose training data and design choices may\nthemselves embed cultural or ideological biases. This study investigates\ngeopolitical parallax-systematic divergence in news quality and subjectivity\nassessments-by comparing article-level embeddings from Chinese-origin (Qwen,\nBGE, Jina) and Western-origin (Snowflake, Granite) model families. We evaluate\nboth on a human-annotated news quality benchmark spanning fifteen stylistic,\ninformational, and affective dimensions, and on parallel corpora covering\npolitically sensitive topics, including Palestine and reciprocal China-United\nStates coverage. Using logistic regression probes and matched-topic evaluation,\nwe quantify per-metric differences in predicted positive-class probabilities\nbetween model families. Our findings reveal consistent, non-random divergences\naligned with model origin. In Palestine-related coverage, Western models assign\nhigher subjectivity and positive emotion scores, while Chinese models emphasize\nnovelty and descriptiveness. Cross-topic analysis shows asymmetries in\nstructural quality metrics Chinese-on-US scoring notably lower in fluency,\nconciseness, technicality, and overall quality-contrasted by higher negative\nemotion scores. These patterns align with media bias theory and our distinction\nbetween semantic, emotional, and relational subjectivity, and extend LLM bias\nliterature by showing that geopolitical framing effects persist in downstream\nquality assessment tasks. We conclude that LLM-based media evaluation pipelines\nrequire cultural calibration to avoid conflating content differences with\nmodel-induced bias.", "published": "2025-08-27 00:39:59", "link": "http://arxiv.org/abs/2508.19492v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Rule Synergy Analysis using LLMs: State of the Art and Implications", "abstract": "Large language models (LLMs) have demonstrated strong performance across a\nvariety of domains, including logical reasoning, mathematics, and more. In this\npaper, we investigate how well LLMs understand and reason about complex rule\ninteractions in dynamic environments, such as card games. We introduce a\ndataset of card synergies from the game Slay the Spire, where pairs of cards\nare classified based on their positive, negative, or neutral interactions. Our\nevaluation shows that while LLMs excel at identifying non-synergistic pairs,\nthey struggle with detecting positive and, particularly, negative synergies. We\ncategorize common error types, including issues with timing, defining game\nstates, and following game rules. Our findings suggest directions for future\nresearch to improve model performance in predicting the effect of rules and\ntheir interactions.", "published": "2025-08-27 00:01:41", "link": "http://arxiv.org/abs/2508.19484v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning", "abstract": "Autonomous agents for Graphical User Interfaces (GUIs) face significant\nchallenges in specialized domains such as scientific computing, where both\nlong-horizon planning and precise execution are required. Existing approaches\nsuffer from a trade-off: generalist agents excel at planning but perform poorly\nin execution, while specialized agents demonstrate the opposite weakness.\nRecent compositional frameworks attempt to bridge this gap by combining a\nplanner and an actor, but they are typically static and non-trainable, which\nprevents adaptation from experience. This is a critical limitation given the\nscarcity of high-quality data in scientific domains. To address these\nlimitations, we introduce CODA, a novel and trainable compositional framework\nthat integrates a generalist planner (Cerebrum) with a specialist executor\n(Cerebellum), trained via a dedicated two-stage pipeline. In the first stage,\nSpecialization, we apply a decoupled GRPO approach to train an expert planner\nfor each scientific application individually, bootstrapping from a small set of\ntask trajectories. In the second stage, Generalization, we aggregate all\nsuccessful trajectories from the specialized experts to build a consolidated\ndataset, which is then used for supervised fine-tuning of the final planner.\nThis equips CODA with both robust execution and cross-domain generalization.\nEvaluated on four challenging applications from the ScienceBoard benchmark,\nCODA significantly outperforms baselines and establishes a new state of the art\namong open-source models.", "published": "2025-08-27 17:59:50", "link": "http://arxiv.org/abs/2508.20096v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Discrete-Guided Diffusion for Scalable and Safe Multi-Robot Motion Planning", "abstract": "Multi-Robot Motion Planning (MRMP) involves generating collision-free\ntrajectories for multiple robots operating in a shared continuous workspace.\nWhile discrete multi-agent path finding (MAPF) methods are broadly adopted due\nto their scalability, their coarse discretization severely limits trajectory\nquality. In contrast, continuous optimization-based planners offer\nhigher-quality paths but suffer from the curse of dimensionality, resulting in\npoor scalability with respect to the number of robots. This paper tackles the\nlimitations of these two approaches by introducing a novel framework that\nintegrates discrete MAPF solvers with constrained generative diffusion models.\nThe resulting framework, called Discrete-Guided Diffusion (DGD), has three key\ncharacteristics: (1) it decomposes the original nonconvex MRMP problem into\ntractable subproblems with convex configuration spaces, (2) it combines\ndiscrete MAPF solutions with constrained optimization techniques to guide\ndiffusion models capture complex spatiotemporal dependencies among robots, and\n(3) it incorporates a lightweight constraint repair mechanism to ensure\ntrajectory feasibility. The proposed method sets a new state-of-the-art\nperformance in large-scale, complex environments, scaling to 100 robots while\nachieving planning efficiency and high success rates.", "published": "2025-08-27 17:59:36", "link": "http://arxiv.org/abs/2508.20095v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Patch Progression Masked Autoencoder with Fusion CNN Network for Classifying Evolution Between Two Pairs of 2D OCT Slices", "abstract": "Age-related Macular Degeneration (AMD) is a prevalent eye condition affecting\nvisual acuity. Anti-vascular endothelial growth factor (anti-VEGF) treatments\nhave been effective in slowing the progression of neovascular AMD, with better\noutcomes achieved through timely diagnosis and consistent monitoring. Tracking\nthe progression of neovascular activity in OCT scans of patients with exudative\nAMD allows for the development of more personalized and effective treatment\nplans. This was the focus of the Monitoring Age-related Macular Degeneration\nProgression in Optical Coherence Tomography (MARIO) challenge, in which we\nparticipated. In Task 1, which involved classifying the evolution between two\npairs of 2D slices from consecutive OCT acquisitions, we employed a fusion CNN\nnetwork with model ensembling to further enhance the model's performance. For\nTask 2, which focused on predicting progression over the next three months\nbased on current exam data, we proposed the Patch Progression Masked\nAutoencoder that generates an OCT for the next exam and then classifies the\nevolution between the current OCT and the one generated using our solution from\nTask 1. The results we achieved allowed us to place in the Top 10 for both\ntasks. Some team members are part of the same organization as the challenge\norganizers; therefore, we are not eligible to compete for the prize.", "published": "2025-08-27 17:18:30", "link": "http://arxiv.org/abs/2508.20064v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Model Science: getting serious about verification, explanation and control of AI systems", "abstract": "The growing adoption of foundation models calls for a paradigm shift from\nData Science to Model Science. Unlike data-centric approaches, Model Science\nplaces the trained model at the core of analysis, aiming to interact, verify,\nexplain, and control its behavior across diverse operational contexts. This\npaper introduces a conceptual framework for a new discipline called Model\nScience, along with the proposal for its four key pillars: Verification, which\nrequires strict, context-aware evaluation protocols; Explanation, which is\nunderstood as various approaches to explore of internal model operations;\nControl, which integrates alignment techniques to steer model behavior; and\nInterface, which develops interactive and visual explanation tools to improve\nhuman calibration and decision-making. The proposed framework aims to guide the\ndevelopment of credible, safe, and human-aligned AI systems.", "published": "2025-08-27 16:50:17", "link": "http://arxiv.org/abs/2508.20040v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Large Language Models (LLMs) for Electronic Design Automation (EDA)", "abstract": "With the growing complexity of modern integrated circuits, hardware engineers\nare required to devote more effort to the full design-to-manufacturing\nworkflow. This workflow involves numerous iterations, making it both\nlabor-intensive and error-prone. Therefore, there is an urgent demand for more\nefficient Electronic Design Automation (EDA) solutions to accelerate hardware\ndevelopment. Recently, large language models (LLMs) have shown remarkable\nadvancements in contextual comprehension, logical reasoning, and generative\ncapabilities. Since hardware designs and intermediate scripts can be\nrepresented as text, integrating LLM for EDA offers a promising opportunity to\nsimplify and even automate the entire workflow. Accordingly, this paper\nprovides a comprehensive overview of incorporating LLMs into EDA, with emphasis\non their capabilities, limitations, and future opportunities. Three case\nstudies, along with their outlook, are introduced to demonstrate the\ncapabilities of LLMs in hardware design, testing, and optimization. Finally,\nfuture directions and challenges are highlighted to further explore the\npotential of LLMs in shaping the next-generation EDA, providing valuable\ninsights for researchers interested in leveraging advanced AI technologies for\nEDA.", "published": "2025-08-27 16:33:51", "link": "http://arxiv.org/abs/2508.20030v1", "categories": ["eess.SY", "cs.AI", "cs.AR", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "HPC Digital Twins for Evaluating Scheduling Policies, Incentive Structures and their Impact on Power and Cooling", "abstract": "Schedulers are critical for optimal resource utilization in high-performance\ncomputing. Traditional methods to evaluate schedulers are limited to\npost-deployment analysis, or simulators, which do not model associated\ninfrastructure. In this work, we present the first-of-its-kind integration of\nscheduling and digital twins in HPC. This enables what-if studies to understand\nthe impact of parameter configurations and scheduling decisions on the physical\nassets, even before deployment, or regarching changes not easily realizable in\nproduction. We (1) provide the first digital twin framework extended with\nscheduling capabilities, (2) integrate various top-tier HPC systems given their\npublicly available datasets, (3) implement extensions to integrate external\nscheduling simulators. Finally, we show how to (4) implement and evaluate\nincentive structures, as-well-as (5) evaluate machine learning based\nscheduling, in such novel digital-twin based meta-framework to prototype\nscheduling. Our work enables what-if scenarios of HPC systems to evaluate\nsustainability, and the impact on the simulated system.", "published": "2025-08-27 16:21:31", "link": "http://arxiv.org/abs/2508.20016v1", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.SY", "eess.SY"], "primary_category": "cs.DC"}
{"title": "Decomposing Behavioral Phase Transitions in LLMs: Order Parameters for Emergent Misalignment", "abstract": "Fine-tuning LLMs on narrowly harmful datasets can lead to behavior that is\nbroadly misaligned with respect to human values. To understand when and how\nthis emergent misalignment occurs, we develop a comprehensive framework for\ndetecting and characterizing rapid transitions during fine-tuning using both\ndistributional change detection methods as well as order parameters that are\nformulated in plain English and evaluated by an LLM judge. Using an objective\nstatistical dissimilarity measure, we quantify how the phase transition that\noccurs during fine-tuning affects multiple aspects of the model. In particular,\nwe assess what percentage of the total distributional change in model outputs\nis captured by different aspects, such as alignment or verbosity, providing a\ndecomposition of the overall transition. We also find that the actual\nbehavioral transition occurs later in training than indicated by the peak in\nthe gradient norm alone. Our framework enables the automated discovery and\nquantification of language-based order parameters, which we demonstrate on\nexamples ranging from knowledge questions to politics and ethics.", "published": "2025-08-27 16:19:49", "link": "http://arxiv.org/abs/2508.20015v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Cross-Platform E-Commerce Product Categorization and Recategorization: A Multimodal Hierarchical Classification Approach", "abstract": "This study addresses critical industrial challenges in e-commerce product\ncategorization, namely platform heterogeneity and the structural limitations of\nexisting taxonomies, by developing and deploying a multimodal hierarchical\nclassification framework. Using a dataset of 271,700 products from 40\ninternational fashion e-commerce platforms, we integrate textual features\n(RoBERTa), visual features (ViT), and joint vision--language representations\n(CLIP). We investigate fusion strategies, including early, late, and\nattention-based fusion within a hierarchical architecture enhanced by dynamic\nmasking to ensure taxonomic consistency. Results show that CLIP embeddings\ncombined via an MLP-based late-fusion strategy achieve the highest hierarchical\nF1 (98.59\\%), outperforming unimodal baselines. To address shallow or\ninconsistent categories, we further introduce a self-supervised ``product\nrecategorization'' pipeline using SimCLR, UMAP, and cascade clustering, which\ndiscovered new, fine-grained categories (e.g., subtypes of ``Shoes'') with\ncluster purities above 86\\%. Cross-platform experiments reveal a\ndeployment-relevant trade-off: complex late-fusion methods maximize accuracy\nwith diverse training data, while simpler early-fusion methods generalize more\neffectively to unseen platforms. Finally, we demonstrate the framework's\nindustrial scalability through deployment in EURWEB's commercial transaction\nintelligence platform via a two-stage inference pipeline, combining a\nlightweight RoBERTa stage with a GPU--accelerated multimodal stage to balance\ncost and accuracy.", "published": "2025-08-27 16:16:12", "link": "http://arxiv.org/abs/2508.20013v1", "categories": ["cs.LG", "cs.AI", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Flocking Behavior: An Innovative Inspiration for the Optimization of Production Plants", "abstract": "Optimizing modern production plants using the job-shop principle is a known\nhard problem. For very large plants, like semiconductor fabs, the problem\nbecomes unsolvable on a plant-wide scale in a reasonable amount of time using\nclassical linear optimization. An alternative approach is the use of swarm\nintelligence algorithms. These have been applied to the job-shop problem\nbefore, but often in a centrally calculated way where they are applied to the\nsolution space, but they can be implemented in a bottom-up fashion to avoid\nglobal result computation as well. One of the problems in semiconductor\nproduction is that the production process requires a lot of switching between\nmachines that process lots one after the other and machines that process\nbatches of lots at once, often with long processing times. In this paper, we\naddress this switching problem with the ``boids'' flocking algorithm that was\noriginally used in robotics and movie industry. The flocking behavior is a\nbio-inspired algorithm that uses only local information and interaction based\non simple heuristics. We show that this algorithm addresses these valid\nconsiderations in production plant optimization, as it reacts to the switching\nof machine kinds similar to how a swarm of flocking animals would react to\nobstacles in its course.", "published": "2025-08-27 15:17:31", "link": "http://arxiv.org/abs/2508.19963v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "CASE: An Agentic AI Framework for Enhancing Scam Intelligence in Digital Payments", "abstract": "The proliferation of digital payment platforms has transformed commerce,\noffering unmatched convenience and accessibility globally. However, this growth\nhas also attracted malicious actors, leading to a corresponding increase in\nsophisticated social engineering scams. These scams are often initiated and\norchestrated on multiple surfaces outside the payment platform, making user and\ntransaction-based signals insufficient for a complete understanding of the\nscam's methodology and underlying patterns, without which it is very difficult\nto prevent it in a timely manner. This paper presents CASE (Conversational\nAgent for Scam Elucidation), a novel Agentic AI framework that addresses this\nproblem by collecting and managing user scam feedback in a safe and scalable\nmanner. A conversational agent is uniquely designed to proactively interview\npotential victims to elicit intelligence in the form of a detailed\nconversation. The conversation transcripts are then consumed by another AI\nsystem that extracts information and converts it into structured data for\ndownstream usage in automated and manual enforcement mechanisms. Using Google's\nGemini family of LLMs, we implemented this framework on Google Pay (GPay)\nIndia. By augmenting our existing features with this new intelligence, we have\nobserved a 21% uplift in the volume of scam enforcements. The architecture and\nits robust evaluation framework are highly generalizable, offering a blueprint\nfor building similar AI-driven systems to collect and manage scam intelligence\nin other sensitive domains.", "published": "2025-08-27 14:47:33", "link": "http://arxiv.org/abs/2508.19932v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "WaveHiT-SR: Hierarchical Wavelet Network for Efficient Image Super-Resolution", "abstract": "Transformers have demonstrated promising performance in computer vision\ntasks, including image super-resolution (SR). The quadratic computational\ncomplexity of window self-attention mechanisms in many transformer-based SR\nmethods forces the use of small, fixed windows, limiting the receptive field.\nIn this paper, we propose a new approach by embedding the wavelet transform\nwithin a hierarchical transformer framework, called (WaveHiT-SR). First, using\nadaptive hierarchical windows instead of static small windows allows to capture\nfeatures across different levels and greatly improve the ability to model\nlong-range dependencies. Secondly, the proposed model utilizes wavelet\ntransforms to decompose images into multiple frequency subbands, allowing the\nnetwork to focus on both global and local features while preserving structural\ndetails. By progressively reconstructing high-resolution images through\nhierarchical processing, the network reduces computational complexity without\nsacrificing performance. The multi-level decomposition strategy enables the\nnetwork to capture fine-grained information in lowfrequency components while\nenhancing high-frequency textures. Through extensive experimentation, we\nconfirm the effectiveness and efficiency of our WaveHiT-SR. Our refined\nversions of SwinIR-Light, SwinIR-NG, and SRFormer-Light deliver cutting-edge SR\nresults, achieving higher efficiency with fewer parameters, lower FLOPs, and\nfaster speeds.", "published": "2025-08-27 14:37:50", "link": "http://arxiv.org/abs/2508.19927v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Next Layer: Augmenting Foundation Models with Structure-Preserving and Attention-Guided Learning for Local Patches to Global Context Awareness in Computational Pathology", "abstract": "Foundation models have recently emerged as powerful feature extractors in\ncomputational pathology, yet they typically omit mechanisms for leveraging the\nglobal spatial structure of tissues and the local contextual relationships\namong diagnostically relevant regions - key elements for understanding the\ntumor microenvironment. Multiple instance learning (MIL) remains an essential\nnext step following foundation model, designing a framework to aggregate\npatch-level features into slide-level predictions. We present EAGLE-Net, a\nstructure-preserving, attention-guided MIL architecture designed to augment\nprediction and interpretability. EAGLE-Net integrates multi-scale absolute\nspatial encoding to capture global tissue architecture, a top-K\nneighborhood-aware loss to focus attention on local microenvironments, and\nbackground suppression loss to minimize false positives. We benchmarked\nEAGLE-Net on large pan-cancer datasets, including three cancer types for\nclassification (10,260 slides) and seven cancer types for survival prediction\n(4,172 slides), using three distinct histology foundation backbones (REMEDIES,\nUni-V1, Uni2-h). Across tasks, EAGLE-Net achieved up to 3% higher\nclassification accuracy and the top concordance indices in 6 of 7 cancer types,\nproducing smooth, biologically coherent attention maps that aligned with expert\nannotations and highlighted invasive fronts, necrosis, and immune infiltration.\nThese results position EAGLE-Net as a generalizable, interpretable framework\nthat complements foundation models, enabling improved biomarker discovery,\nprognostic modeling, and clinical decision support", "published": "2025-08-27 14:19:38", "link": "http://arxiv.org/abs/2508.19914v1", "categories": ["q-bio.QM", "cs.AI", "stat.ML"], "primary_category": "q-bio.QM"}
{"title": "The Information Dynamics of Generative Diffusion", "abstract": "Generative diffusion models have emerged as a powerful class of models in\nmachine learning, yet a unified theoretical understanding of their operation is\nstill developing. This perspective paper provides an integrated perspective on\ngenerative diffusion by connecting their dynamic, information-theoretic, and\nthermodynamic properties under a unified mathematical framework. We demonstrate\nthat the rate of conditional entropy production during generation (i.e. the\ngenerative bandwidth) is directly governed by the expected divergence of the\nscore function's vector field. This divergence, in turn, is linked to the\nbranching of trajectories and generative bifurcations, which we characterize as\nsymmetry-breaking phase transitions in the energy landscape. This synthesis\noffers a powerful insight: the process of generation is fundamentally driven by\nthe controlled, noise-induced breaking of (approximate) symmetries, where peaks\nin information transfer correspond to critical transitions between possible\noutcomes. The score function acts as a dynamic non-linear filter that regulates\nthe bandwidth of the noise by suppressing fluctuations that are incompatible\nwith the data.", "published": "2025-08-27 13:53:56", "link": "http://arxiv.org/abs/2508.19897v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Generative AI for Testing of Autonomous Driving Systems: A Survey", "abstract": "Autonomous driving systems (ADS) have been an active area of research, with\nthe potential to deliver significant benefits to society. However, before\nlarge-scale deployment on public roads, extensive testing is necessary to\nvalidate their functionality and safety under diverse driving conditions.\nTherefore, different testing approaches are required, and achieving effective\nand efficient testing of ADS remains an open challenge. Recently, generative AI\nhas emerged as a powerful tool across many domains, and it is increasingly\nbeing applied to ADS testing due to its ability to interpret context, reason\nabout complex tasks, and generate diverse outputs. To gain a deeper\nunderstanding of its role in ADS testing, we systematically analyzed 91\nrelevant studies and synthesized their findings into six major application\ncategories, primarily centered on scenario-based testing of ADS. We also\nreviewed their effectiveness and compiled a wide range of datasets, simulators,\nADS, metrics, and benchmarks used for evaluation, while identifying 27\nlimitations. This survey provides an overview and practical insights into the\nuse of generative AI for testing ADS, highlights existing challenges, and\noutlines directions for future research in this rapidly evolving field.", "published": "2025-08-27 13:40:14", "link": "http://arxiv.org/abs/2508.19882v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Multispectral LiDAR data for extracting tree points in urban and suburban areas", "abstract": "Monitoring urban tree dynamics is vital for supporting greening policies and\nreducing risks to electrical infrastructure. Airborne laser scanning has\nadvanced large-scale tree management, but challenges remain due to complex\nurban environments and tree variability. Multispectral (MS) light detection and\nranging (LiDAR) improves this by capturing both 3D spatial and spectral data,\nenabling detailed mapping. This study explores tree point extraction using\nMS-LiDAR and deep learning (DL) models. Three state-of-the-art models are\nevaluated: Superpoint Transformer (SPT), Point Transformer V3 (PTv3), and Point\nTransformer V1 (PTv1). Results show the notable time efficiency and accuracy of\nSPT, with a mean intersection over union (mIoU) of 85.28%. The highest\ndetection accuracy is achieved by incorporating pseudo normalized difference\nvegetation index (pNDVI) with spatial data, reducing error rate by 10.61\npercentage points (pp) compared to using spatial information alone. These\nfindings highlight the potential of MS-LiDAR and DL to improve tree extraction\nand further tree inventories.", "published": "2025-08-27 13:39:13", "link": "http://arxiv.org/abs/2508.19881v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Tracking World States with Language Models: State-Based Evaluation Using Chess", "abstract": "Large Language Models (LLMs) exhibit emergent capabilities in structured\ndomains, suggesting they may implicitly internalize high-fidelity\nrepresentations of world models. While probing techniques have shown promising\nsigns of this in scientific and game-based settings, they rely on\nmodel-specific internal activations, which limit interpretability and\ngeneralizability. In this work, we propose a model-agnostic, state-based\nevaluation framework using chess as a benchmark to assess whether LLMs preserve\nthe semantics of structured environments. Our method analyzes the downstream\nlegal move distributions (state affordances) to estimate semantic fidelity\nbetween predicted and actual game states. This approach offers a more\nmeaningful evaluation than conventional string-based metrics by aligning more\nclosely with the strategic and rule-governed nature of chess. Experimental\nresults demonstrate that our metrics capture deficiencies in state-tracking,\nhighlighting limitations of LLMs in maintaining coherent internal models over\nlong sequences. Our framework provides a robust tool for evaluating structured\nreasoning in LLMs without requiring internal model access, and generalizes to a\nwide class of symbolic environments.", "published": "2025-08-27 13:08:51", "link": "http://arxiv.org/abs/2508.19851v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "PSO-Merging: Merging Models Based on Particle Swarm Optimization", "abstract": "Model merging has emerged as an efficient strategy for constructing multitask\nmodels by integrating the strengths of multiple available expert models,\nthereby reducing the need to fine-tune a pre-trained model for all the tasks\nfrom scratch. Existing data-independent methods struggle with performance\nlimitations due to the lack of data-driven guidance. Data-driven approaches\nalso face key challenges: gradient-based methods are computationally expensive,\nlimiting their practicality for merging large expert models, whereas existing\ngradient-free methods often fail to achieve satisfactory results within a\nlimited number of optimization steps. To address these limitations, this paper\nintroduces PSO-Merging, a novel data-driven merging method based on the\nParticle Swarm Optimization (PSO). In this approach, we initialize the particle\nswarm with a pre-trained model, expert models, and sparsified expert models. We\nthen perform multiple iterations, with the final global best particle serving\nas the merged model. Experimental results on different language models show\nthat PSO-Merging generally outperforms baseline merging methods, offering a\nmore efficient and scalable solution for model merging.", "published": "2025-08-27 12:52:36", "link": "http://arxiv.org/abs/2508.19839v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Gradient Rectification for Robust Calibration under Distribution Shift", "abstract": "Deep neural networks often produce overconfident predictions, undermining\ntheir reliability in safety-critical applications. This miscalibration is\nfurther exacerbated under distribution shift, where test data deviates from the\ntraining distribution due to environmental or acquisition changes. While\nexisting approaches improve calibration through training-time regularization or\npost-hoc adjustment, their reliance on access to or simulation of target\ndomains limits their practicality in real-world scenarios. In this paper, we\npropose a novel calibration framework that operates without access to target\ndomain information. From a frequency-domain perspective, we identify that\ndistribution shifts often distort high-frequency visual cues exploited by deep\nmodels, and introduce a low-frequency filtering strategy to encourage reliance\non domain-invariant features. However, such information loss may degrade\nIn-Distribution (ID) calibration performance. Therefore, we further propose a\ngradient-based rectification mechanism that enforces ID calibration as a hard\nconstraint during optimization. Experiments on synthetic and real-world shifted\ndatasets, including CIFAR-10/100-C and WILDS, demonstrate that our method\nsignificantly improves calibration under distribution shift while maintaining\nstrong in-distribution performance.", "published": "2025-08-27 12:28:26", "link": "http://arxiv.org/abs/2508.19830v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "From Research to Reality: Feasibility of Gradient Inversion Attacks in Federated Learning", "abstract": "Gradient inversion attacks have garnered attention for their ability to\ncompromise privacy in federated learning. However, many studies consider\nattacks with the model in inference mode, where training-time behaviors like\ndropout are disabled and batch normalization relies on fixed statistics. In\nthis work, we systematically analyze how architecture and training behavior\naffect vulnerability, including the first in-depth study of inference-mode\nclients, which we show dramatically simplifies inversion. To assess attack\nfeasibility under more realistic conditions, we turn to clients operating in\nstandard training mode. In this setting, we find that successful attacks are\nonly possible when several architectural conditions are met simultaneously:\nmodels must be shallow and wide, use skip connections, and, critically, employ\npre-activation normalization. We introduce two novel attacks against models in\ntraining-mode with varying attacker knowledge, achieving state-of-the-art\nperformance under realistic training conditions. We extend these efforts by\npresenting the first attack on a production-grade object-detection model. Here,\nto enable any visibly identifiable leakage, we revert to the lenient inference\nmode setting and make multiple architectural modifications to increase model\nvulnerability, with the extent of required changes highlighting the strong\ninherent robustness of such architectures. We conclude this work by offering\nthe first comprehensive mapping of settings, clarifying which combinations of\narchitectural choices and operational modes meaningfully impact privacy. Our\nanalysis provides actionable insight into when models are likely vulnerable,\nwhen they appear robust, and where subtle leakage may persist. Together, these\nfindings reframe how gradient inversion risk should be assessed in future\nresearch and deployment scenarios.", "published": "2025-08-27 12:07:23", "link": "http://arxiv.org/abs/2508.19819v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "ERSR: An Ellipse-constrained pseudo-label refinement and symmetric regularization framework for semi-supervised fetal head segmentation in ultrasound images", "abstract": "Automated segmentation of the fetal head in ultrasound images is critical for\nprenatal monitoring. However, achieving robust segmentation remains challenging\ndue to the poor quality of ultrasound images and the lack of annotated data.\nSemi-supervised methods alleviate the lack of annotated data but struggle with\nthe unique characteristics of fetal head ultrasound images, making it\nchallenging to generate reliable pseudo-labels and enforce effective\nconsistency regularization constraints. To address this issue, we propose a\nnovel semi-supervised framework, ERSR, for fetal head ultrasound segmentation.\nOur framework consists of the dual-scoring adaptive filtering strategy, the\nellipse-constrained pseudo-label refinement, and the symmetry-based multiple\nconsistency regularization. The dual-scoring adaptive filtering strategy uses\nboundary consistency and contour regularity criteria to evaluate and filter\nteacher outputs. The ellipse-constrained pseudo-label refinement refines these\nfiltered outputs by fitting least-squares ellipses, which strengthens pixels\nnear the center of the fitted ellipse and suppresses noise simultaneously. The\nsymmetry-based multiple consistency regularization enforces multi-level\nconsistency across perturbed images, symmetric regions, and between original\npredictions and pseudo-labels, enabling the model to capture robust and stable\nshape representations. Our method achieves state-of-the-art performance on two\nbenchmarks. On the HC18 dataset, it reaches Dice scores of 92.05% and 95.36%\nwith 10% and 20% labeled data, respectively. On the PSFH dataset, the scores\nare 91.68% and 93.70% under the same settings.", "published": "2025-08-27 12:01:57", "link": "http://arxiv.org/abs/2508.19815v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Bootstrapping Learned Cost Models with Synthetic SQL Queries", "abstract": "Having access to realistic workloads for a given database instance is\nextremely important to enable stress and vulnerability testing, as well as to\noptimize for cost and performance. Recent advances in learned cost models have\nshown that when enough diverse SQL queries are available, one can effectively\nand efficiently predict the cost of running a given query against a specific\ndatabase engine. In this paper, we describe our experience in exploiting modern\nsynthetic data generation techniques, inspired by the generative AI and LLM\ncommunity, to create high-quality datasets enabling the effective training of\nsuch learned cost models. Initial results show that we can improve a learned\ncost model's predictive accuracy by training it with 45% fewer queries than\nwhen using competitive generation approaches.", "published": "2025-08-27 11:50:42", "link": "http://arxiv.org/abs/2508.19807v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "A bag of tricks for real-time Mitotic Figure detection", "abstract": "Mitotic figure (MF) detection in histopathology images is challenging due to\nlarge variations in slide scanners, staining protocols, tissue types, and the\npresence of artifacts. This paper presents a collection of training techniques\n- a bag of tricks - that enable robust, real-time MF detection across diverse\ndomains. We build on the efficient RTMDet single stage object detector to\nachieve high inference speed suitable for clinical deployment. Our method\naddresses scanner variability and tumor heterogeneity via extensive\nmulti-domain training data, balanced sampling, and careful augmentation.\nAdditionally, we employ targeted, hard negative mining on necrotic and debris\ntissue to reduce false positives. In a grouped 5-fold cross-validation across\nmultiple MF datasets, our model achieves an F1 score between 0.78 and 0.84. On\nthe preliminary test set of the MItosis DOmain Generalization (MIDOG) 2025\nchallenge, our single-stage RTMDet-S based approach reaches an F1 of 0.81,\noutperforming larger models and demonstrating adaptability to new, unfamiliar\ndomains. The proposed solution offers a practical trade-off between accuracy\nand speed, making it attractive for real-world clinical adoption.", "published": "2025-08-27 11:45:44", "link": "http://arxiv.org/abs/2508.19804v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Attention is also needed for form design", "abstract": "Conventional product design is a cognitively demanding process, limited by\nits time-consuming nature, reliance on subjective expertise, and the opaque\ntranslation of inspiration into tangible concepts. This research introduces a\nnovel, attention-aware framework that integrates two synergistic systems:\nEUPHORIA, an immersive Virtual Reality environment using eye-tracking to\nimplicitly capture a designer's aesthetic preferences, and RETINA, an agentic\nAI pipeline that translates these implicit preferences into concrete design\noutputs. The foundational principles were validated in a two-part study. An\ninitial study correlated user's implicit attention with explicit preference and\nthe next one correlated mood to attention. A comparative study where 4\ndesigners solved challenging design problems using 4 distinct workflows, from a\nmanual process to an end-to-end automated pipeline, showed the integrated\nEUPHORIA-RETINA workflow was over 4 times more time-efficient than the\nconventional method. A panel of 50 design experts evaluated the 16 final\nrenderings. Designs generated by the fully automated system consistently\nreceived the highest Worthiness (calculated by an inverse Plackett-Luce model\nbased on gradient descent optimization) and Design Effectiveness scores,\nindicating superior quality across 8 criteria: novelty, visual appeal,\nemotional resonance, clarity of purpose, distinctiveness of silhouette, implied\nmateriality, proportional balance, & adherence to the brief. This research\npresents a validated paradigm shift from traditional Computer-Assisted Design\n(CAD) to a collaborative model of Designer-Assisting Computers (DAC). By\nautomating logistical and skill-dependent generative tasks, the proposed\nframework elevates the designer's role to that of a creative director,\nsynergizing human intuition with the generative power of agentic AI to produce\nhigher-quality designs more efficiently.", "published": "2025-08-27 09:15:21", "link": "http://arxiv.org/abs/2508.19708v1", "categories": ["cs.HC", "cs.AI", "68T07, 68T42, 68T50", "I.2; J.5; J.6"], "primary_category": "cs.HC"}
{"title": "Topological Uncertainty for Anomaly Detection in the Neural-network EoS Inference with Neutron Star Data", "abstract": "We study the performance of the Topological Uncertainty (TU) constructed with\na trained feedforward neural network (FNN) for Anomaly Detection. Generally,\nmeaningful information can be stored in the hidden layers of the trained FNN,\nand the TU implementation is one tractable recipe to extract buried information\nby means of the Topological Data Analysis. We explicate the concept of the TU\nand the numerical procedures. Then, for a concrete demonstration of the\nperformance test, we employ the Neutron Star data used for inference of the\nequation of state (EoS). For the training dataset consisting of the input\n(Neutron Star data) and the output (EoS parameters), we can compare the\ninferred EoSs and the exact answers to classify the data with the label $k$.\nThe subdataset with $k=0$ leads to the normal inference for which the inferred\nEoS approximates the answer well, while the subdataset with $k=1$ ends up with\nthe unsuccessful inference. Once the TU is prepared based on the $k$-labled\nsubdatasets, we introduce the cross-TU to quantify the uncertainty of\ncharacterizing the $k$-labeled data with the label $j$. The anomaly or\nunsuccessful inference is correctly detected if the cross-TU for $j=k=1$ is\nsmaller than that for $j=0$ and $k=1$. In our numerical experiment, for various\ninput data, we calculate the cross-TU and estimate the performance of Anomaly\nDetection. We find that performance depends on FNN hyperparameters, and the\nsuccess rate of Anomaly Detection exceeds $90\\%$ in the best case. We finally\ndiscuss further potential of the TU application to retrieve the information\nhidden in the trained FNN.", "published": "2025-08-27 08:44:56", "link": "http://arxiv.org/abs/2508.19683v1", "categories": ["nucl-th", "cs.AI", "cs.LG"], "primary_category": "nucl-th"}
{"title": "InquireMobile: Teaching VLM-based Mobile Agent to Request Human Assistance via Reinforcement Fine-Tuning", "abstract": "Recent advances in Vision-Language Models (VLMs) have enabled mobile agents\nto perceive and interact with real-world mobile environments based on human\ninstructions. However, the current fully autonomous paradigm poses potential\nsafety risks when model understanding or reasoning capabilities are\ninsufficient. To address this challenge, we first introduce\n\\textbf{InquireBench}, a comprehensive benchmark specifically designed to\nevaluate mobile agents' capabilities in safe interaction and proactive inquiry\nwith users, encompassing 5 categories and 22 sub-categories, where most\nexisting VLM-based agents demonstrate near-zero performance. In this paper, we\naim to develop an interactive system that actively seeks human confirmation at\ncritical decision points. To achieve this, we propose \\textbf{InquireMobile}, a\nnovel model inspired by reinforcement learning, featuring a two-stage training\nstrategy and an interactive pre-action reasoning mechanism. Finally, our model\nachieves an 46.8% improvement in inquiry success rate and the best overall\nsuccess rate among existing baselines on InquireBench. We will open-source all\ndatasets, models, and evaluation codes to facilitate development in both\nacademia and industry.", "published": "2025-08-27 08:40:05", "link": "http://arxiv.org/abs/2508.19679v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Arbitrary Precision Printed Ternary Neural Networks with Holistic Evolutionary Approximation", "abstract": "Printed electronics offer a promising alternative for applications beyond\nsilicon-based systems, requiring properties like flexibility, stretchability,\nconformality, and ultra-low fabrication costs. Despite the large feature sizes\nin printed electronics, printed neural networks have attracted attention for\nmeeting target application requirements, though realizing complex circuits\nremains challenging. This work bridges the gap between classification accuracy\nand area efficiency in printed neural networks, covering the entire\nprocessing-near-sensor system design and co-optimization from the\nanalog-to-digital interface-a major area and power bottleneck-to the digital\nclassifier. We propose an automated framework for designing printed Ternary\nNeural Networks with arbitrary input precision, utilizing multi-objective\noptimization and holistic approximation. Our circuits outperform existing\napproximate printed neural networks by 17x in area and 59x in power on average,\nbeing the first to enable printed-battery-powered operation with under 5%\naccuracy loss while accounting for analog-to-digital interfacing costs.", "published": "2025-08-27 08:19:22", "link": "http://arxiv.org/abs/2508.19660v1", "categories": ["eess.SP", "cs.AI", "cs.NE"], "primary_category": "eess.SP"}
{"title": "Intellectual Property in Graph-Based Machine Learning as a Service: Attacks and Defenses", "abstract": "Graph-structured data, which captures non-Euclidean relationships and\ninteractions between entities, is growing in scale and complexity. As a result,\ntraining state-of-the-art graph machine learning (GML) models have become\nincreasingly resource-intensive, turning these models and data into invaluable\nIntellectual Property (IP). To address the resource-intensive nature of model\ntraining, graph-based Machine-Learning-as-a-Service (GMLaaS) has emerged as an\nefficient solution by leveraging third-party cloud services for model\ndevelopment and management. However, deploying such models in GMLaaS also\nexposes them to potential threats from attackers. Specifically, while the APIs\nwithin a GMLaaS system provide interfaces for users to query the model and\nreceive outputs, they also allow attackers to exploit and steal model\nfunctionalities or sensitive training data, posing severe threats to the safety\nof these GML models and the underlying graph data. To address these challenges,\nthis survey systematically introduces the first taxonomy of threats and\ndefenses at the level of both GML model and graph-structured data. Such a\ntailored taxonomy facilitates an in-depth understanding of GML IP protection.\nFurthermore, we present a systematic evaluation framework to assess the\neffectiveness of IP protection methods, introduce a curated set of benchmark\ndatasets across various domains, and discuss their application scopes and\nfuture challenges. Finally, we establish an open-sourced versatile library\nnamed PyGIP, which evaluates various attack and defense techniques in GMLaaS\nscenarios and facilitates the implementation of existing benchmark methods. The\nlibrary resource can be accessed at: https://labrai.github.io/PyGIP. We believe\nthis survey will play a fundamental role in intellectual property protection\nfor GML and provide practical recipes for the GML community.", "published": "2025-08-27 07:37:52", "link": "http://arxiv.org/abs/2508.19641v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Beyond BEV: Optimizing Point-Level Tokens for Collaborative Perception", "abstract": "Collaborative perception allows agents to enhance their perceptual\ncapabilities by exchanging intermediate features. Existing methods typically\norganize these intermediate features as 2D bird's-eye-view (BEV)\nrepresentations, which discard critical fine-grained 3D structural cues\nessential for accurate object recognition and localization. To this end, we\nfirst introduce point-level tokens as intermediate representations for\ncollaborative perception. However, point-cloud data are inherently unordered,\nmassive, and position-sensitive, making it challenging to produce compact and\naligned point-level token sequences that preserve detailed structural\ninformation. Therefore, we present CoPLOT, a novel Collaborative perception\nframework that utilizes Point-Level Optimized Tokens. It incorporates a\npoint-native processing pipeline, including token reordering, sequence\nmodeling, and multi-agent spatial alignment. A semantic-aware token reordering\nmodule generates adaptive 1D reorderings by leveraging scene-level and\ntoken-level semantic information. A frequency-enhanced state space model\ncaptures long-range sequence dependencies across both spatial and spectral\ndomains, improving the differentiation between foreground tokens and background\nclutter. Lastly, a neighbor-to-ego alignment module applies a closed-loop\nprocess, combining global agent-level correction with local token-level\nrefinement to mitigate localization noise. Extensive experiments on both\nsimulated and real-world datasets show that CoPLOT outperforms state-of-the-art\nmodels, with even lower communication and computation overhead. Code will be\navailable at https://github.com/CheeryLeeyy/CoPLOT.", "published": "2025-08-27 07:27:42", "link": "http://arxiv.org/abs/2508.19638v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Invited Paper: Feature-to-Classifier Co-Design for Mixed-Signal Smart Flexible Wearables for Healthcare at the Extreme Edge", "abstract": "Flexible Electronics (FE) offer a promising alternative to rigid\nsilicon-based hardware for wearable healthcare devices, enabling lightweight,\nconformable, and low-cost systems. However, their limited integration density\nand large feature sizes impose strict area and power constraints, making\nML-based healthcare systems-integrating analog frontend, feature extraction and\nclassifier-particularly challenging. Existing FE solutions often neglect\npotential system-wide solutions and focus on the classifier, overlooking the\nsubstantial hardware cost of feature extraction and Analog-to-Digital\nConverters (ADCs)-both major contributors to area and power consumption. In\nthis work, we present a holistic mixed-signal feature-to-classifier co-design\nframework for flexible smart wearable systems. To the best of our knowledge, we\ndesign the first analog feature extractors in FE, significantly reducing\nfeature extraction cost. We further propose an hardware-aware NAS-inspired\nfeature selection strategy within ML training, enabling efficient,\napplication-specific designs. Our evaluation on healthcare benchmarks shows our\napproach delivers highly accurate, ultra-area-efficient flexible systems-ideal\nfor disposable, low-power wearable monitoring.", "published": "2025-08-27 07:26:11", "link": "http://arxiv.org/abs/2508.19637v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "Divide, Weight, and Route: Difficulty-Aware Optimization with Dynamic Expert Fusion for Long-tailed Recognition", "abstract": "Long-tailed visual recognition is challenging not only due to class imbalance\nbut also because of varying classification difficulty across categories. Simply\nreweighting classes by frequency often overlooks those that are intrinsically\nhard to learn. To address this, we propose \\textbf{DQRoute}, a modular\nframework that combines difficulty-aware optimization with dynamic expert\ncollaboration. DQRoute first estimates class-wise difficulty based on\nprediction uncertainty and historical performance, and uses this signal to\nguide training with adaptive loss weighting. On the architectural side, DQRoute\nemploys a mixture-of-experts design, where each expert specializes in a\ndifferent region of the class distribution. At inference time, expert\npredictions are weighted by confidence scores derived from expert-specific OOD\ndetectors, enabling input-adaptive routing without the need for a centralized\nrouter. All components are trained jointly in an end-to-end manner. Experiments\non standard long-tailed benchmarks demonstrate that DQRoute significantly\nimproves performance, particularly on rare and difficult classes, highlighting\nthe benefit of integrating difficulty modeling with decentralized expert\nrouting.", "published": "2025-08-27 07:09:00", "link": "http://arxiv.org/abs/2508.19630v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Training for Obsolescence? The AI-Driven Education Trap", "abstract": "Artificial intelligence simultaneously transforms human capital production in\nschools and its demand in labor markets. Analyzing these effects in isolation\ncan lead to a significant misallocation of educational resources. We model an\neducational planner whose decision to adopt AI is driven by its teaching\nproductivity, failing to internalize AI's future wage-suppressing effect on\nthose same skills. Our core assumption, motivated by a pilot survey, is that\nthere is a positive correlation between these two effects. This drives our\ncentral proposition: this information failure creates a skill mismatch that\nmonotonically increases with AI prevalence. Extensions show the mismatch is\nexacerbated by the neglect of unpriced non-cognitive skills and by a school's\nendogenous over-investment in AI. Our findings caution that policies promoting\nAI in education, if not paired with forward-looking labor market signals, may\nparadoxically undermine students' long-term human capital, especially if\nreliance on AI crowds out the development of unpriced non-cognitive skills,\nsuch as persistence, that are forged through intellectual struggle.", "published": "2025-08-27 07:04:19", "link": "http://arxiv.org/abs/2508.19625v1", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning", "abstract": "Federated learning (FL) is a privacy-preserving machine learning paradigm\nthat enables collaborative model training across multiple distributed clients\nwithout disclosing their raw data. Personalized federated learning (pFL) has\ngained increasing attention for its ability to address data heterogeneity.\nHowever, most existing pFL methods assume that each client's data follows a\nsingle distribution and learn one client-level personalized model for each\nclient. This assumption often fails in practice, where a single client may\npossess data from multiple sources or domains, resulting in significant\nintra-client heterogeneity and suboptimal performance. To tackle this\nchallenge, we propose pFedBayesPT, a fine-grained instance-wise pFL framework\nbased on visual prompt tuning. Specifically, we formulate instance-wise prompt\ngeneration from a Bayesian perspective and model the prompt posterior as an\nimplicit distribution to capture diverse visual semantics. We derive a\nvariational training objective under the semi-implicit variational inference\nframework. Extensive experiments on benchmark datasets demonstrate that\npFedBayesPT consistently outperforms existing pFL methods under both feature\nand label heterogeneity settings.", "published": "2025-08-27 06:59:10", "link": "http://arxiv.org/abs/2508.19621v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Scenario-Oriented Survey of Federated Recommender Systems: Techniques, Challenges, and Future Directions", "abstract": "Extending recommender systems to federated learning (FL) frameworks to\nprotect the privacy of users or platforms while making recommendations has\nrecently gained widespread attention in academia. This is due to the natural\ncoupling of recommender systems and federated learning architectures: the data\noriginates from distributed clients (mostly mobile devices held by users),\nwhich are highly related to privacy. In a centralized recommender system\n(CenRec), the central server collects clients' data, trains the model, and\nprovides the service. Whereas in federated recommender systems (FedRec), the\nstep of data collecting is omitted, and the step of model training is offloaded\nto each client. The server only aggregates the model and other knowledge, thus\navoiding client privacy leakage. Some surveys of federated recommender systems\ndiscuss and analyze related work from the perspective of designing FL systems.\nHowever, their utility drops by ignoring specific recommendation scenarios'\nunique characteristics and practical challenges. For example, the statistical\nheterogeneity issue in cross-domain FedRec originates from the label drift of\nthe data held by different platforms, which is mainly caused by the recommender\nitself, but not the federated architecture. Therefore, it should focus more on\nsolving specific problems in real-world recommendation scenarios to encourage\nthe deployment FedRec. To this end, this review comprehensively analyzes the\ncoupling of recommender systems and federated learning from the perspective of\nrecommendation researchers and practitioners. We establish a clear link between\nrecommendation scenarios and FL frameworks, systematically analyzing\nscenario-specific approaches, practical challenges, and potential\nopportunities. We aim to develop guidance for the real-world deployment of\nFedRec, bridging the gap between existing research and applications.", "published": "2025-08-27 06:57:50", "link": "http://arxiv.org/abs/2508.19620v1", "categories": ["cs.IR", "cs.AI", "cs.CR"], "primary_category": "cs.IR"}
{"title": "FinCast: A Foundation Model for Financial Time-Series Forecasting", "abstract": "Financial time-series forecasting is critical for maintaining economic\nstability, guiding informed policymaking, and promoting sustainable investment\npractices. However, it remains challenging due to various underlying pattern\nshifts. These shifts arise primarily from three sources: temporal\nnon-stationarity (distribution changes over time), multi-domain diversity\n(distinct patterns across financial domains such as stocks, commodities, and\nfutures), and varying temporal resolutions (patterns differing across\nper-second, hourly, daily, or weekly indicators). While recent deep learning\nmethods attempt to address these complexities, they frequently suffer from\noverfitting and typically require extensive domain-specific fine-tuning. To\novercome these limitations, we introduce FinCast, the first foundation model\nspecifically designed for financial time-series forecasting, trained on\nlarge-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot\nperformance, effectively capturing diverse patterns without domain-specific\nfine-tuning. Comprehensive empirical and qualitative evaluations demonstrate\nthat FinCast surpasses existing state-of-the-art methods, highlighting its\nstrong generalization capabilities.", "published": "2025-08-27 06:44:46", "link": "http://arxiv.org/abs/2508.19609v1", "categories": ["cs.LG", "cs.AI", "q-fin.CP"], "primary_category": "cs.LG"}
{"title": "IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation", "abstract": "Domain Generalized Semantic Segmentation (DGSS) focuses on training a model\nusing labeled data from a source domain, with the goal of achieving robust\ngeneralization to unseen target domains during inference. A common approach to\nimprove generalization is to augment the source domain with synthetic data\ngenerated by diffusion models (DMs). However, the generated images often\ncontain structural or semantic defects due to training imperfections. Training\nsegmentation models with such flawed data can lead to performance degradation\nand error accumulation. To address this issue, we propose to integrate inverse\nevolution layers (IELs) into the generative process. IELs are designed to\nhighlight spatial discontinuities and semantic inconsistencies using\nLaplacian-based priors, enabling more effective filtering of undesirable\ngenerative patterns. Based on this mechanism, we introduce IELDM, an enhanced\ndiffusion-based data augmentation framework that can produce higher-quality\nimages. Furthermore, we observe that the defect-suppression capability of IELs\ncan also benefit the segmentation network by suppressing artifact propagation.\nBased on this insight, we embed IELs into the decoder of the DGSS model and\npropose IELFormer to strengthen generalization capability in cross-domain\nscenarios. To further strengthen the model's semantic consistency across\nscales, IELFormer incorporates a multi-scale frequency fusion (MFF) module,\nwhich performs frequency-domain analysis to achieve structured integration of\nmulti-resolution features, thereby improving cross-scale coherence. Extensive\nexperiments on benchmark datasets demonstrate that our approach achieves\nsuperior generalization performance compared to existing methods.", "published": "2025-08-27 06:37:16", "link": "http://arxiv.org/abs/2508.19604v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "CompLex: Music Theory Lexicon Constructed by Autonomous Agents for Automatic Music Generation", "abstract": "Generative artificial intelligence in music has made significant strides, yet\nit still falls short of the substantial achievements seen in natural language\nprocessing, primarily due to the limited availability of music data.\nKnowledge-informed approaches have been shown to enhance the performance of\nmusic generation models, even when only a few pieces of musical knowledge are\nintegrated. This paper seeks to leverage comprehensive music theory in\nAI-driven music generation tasks, such as algorithmic composition and style\ntransfer, which traditionally require significant manual effort with existing\ntechniques. We introduce a novel automatic music lexicon construction model\nthat generates a lexicon, named CompLex, comprising 37,432 items derived from\njust 9 manually input category keywords and 5 sentence prompt templates. A new\nmulti-agent algorithm is proposed to automatically detect and mitigate\nhallucinations. CompLex demonstrates impressive performance improvements across\nthree state-of-the-art text-to-music generation models, encompassing both\nsymbolic and audio-based methods. Furthermore, we evaluate CompLex in terms of\ncompleteness, accuracy, non-redundancy, and executability, confirming that it\npossesses the key characteristics of an effective lexicon.", "published": "2025-08-27 06:36:49", "link": "http://arxiv.org/abs/2508.19603v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "Complementary Learning System Empowers Online Continual Learning of Vehicle Motion Forecasting in Smart Cities", "abstract": "Artificial intelligence underpins most smart city services, yet deep neural\nnetwork (DNN) that forecasts vehicle motion still struggle with catastrophic\nforgetting, the loss of earlier knowledge when models are updated. Conventional\nfixes enlarge the training set or replay past data, but these strategies incur\nhigh data collection costs, sample inefficiently and fail to balance long- and\nshort-term experience, leaving them short of human-like continual learning.\nHere we introduce Dual-LS, a task-free, online continual learning paradigm for\nDNN-based motion forecasting that is inspired by the complementary learning\nsystem of the human brain. Dual-LS pairs two synergistic memory rehearsal\nreplay mechanisms to accelerate experience retrieval while dynamically\ncoordinating long-term and short-term knowledge representations. Tests on\nnaturalistic data spanning three countries, over 772,000 vehicles and\ncumulative testing mileage of 11,187 km show that Dual-LS mitigates\ncatastrophic forgetting by up to 74.31\\% and reduces computational resource\ndemand by up to 94.02\\%, markedly boosting predictive stability in vehicle\nmotion forecasting without inflating data requirements. Meanwhile, it endows\nDNN-based vehicle motion forecasting with computation efficient and human-like\ncontinual learning adaptability fit for smart cities.", "published": "2025-08-27 06:19:21", "link": "http://arxiv.org/abs/2508.19597v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Hallucinating with AI: AI Psychosis as Distributed Delusions", "abstract": "There is much discussion of the false outputs that generative AI systems such\nas ChatGPT, Claude, Gemini, DeepSeek, and Grok create. In popular terminology,\nthese have been dubbed AI hallucinations. However, deeming these AI outputs\nhallucinations is controversial, with many claiming this is a metaphorical\nmisnomer. Nevertheless, in this paper, I argue that when viewed through the\nlens of distributed cognition theory, we can better see the dynamic and\ntroubling ways in which inaccurate beliefs, distorted memories and\nself-narratives, and delusional thinking can emerge through human-AI\ninteractions; examples of which are popularly being referred to as cases of AI\npsychosis. In such cases, I suggest we move away from thinking about how an AI\nsystem might hallucinate at us, by generating false outputs, to thinking about\nhow, when we routinely rely on generative AI to help us think, remember, and\nnarrate, we can come to hallucinate with AI. This can happen when AI introduces\nerrors into the distributed cognitive process, but it can also happen when AI\nsustains, affirms, and elaborates on our own delusional thinking and\nself-narratives, such as in the case of Jaswant Singh Chail. I also examine how\nthe conversational style of chatbots can lead them to play a dual-function,\nboth as a cognitive artefact and a quasi-Other with whom we co-construct our\nbeliefs, narratives, and our realities. It is this dual function, I suggest,\nthat makes generative AI an unusual, and particularly seductive, case of\ndistributed cognition.", "published": "2025-08-27 05:51:19", "link": "http://arxiv.org/abs/2508.19588v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding", "abstract": "With respect to improving the reasoning accuracy of LLMs, the representative\nreinforcement learning (RL) method GRPO faces failure due to insignificant\nreward variance, while verification methods based on process reward models\n(PRMs) suffer from difficulties with training data acquisition and verification\neffectiveness. To tackle these problems, this paper introduces ReST-RL, a\nunified LLM RL paradigm that significantly improves LLM's code reasoning\nability by combining an improved GRPO algorithm with a meticulously designed\ntest time decoding method assisted by a value model (VM). As the first stage of\npolicy reinforcement, ReST-GRPO adopts an optimized ReST algorithm to filter\nand assemble high-value training data, increasing the reward variance of GRPO\nsampling, thus improving the effectiveness and efficiency of training. After\nthe basic reasoning ability of LLM policy has been improved, we further propose\na test time decoding optimization method called VM-MCTS. Through Monte-Carlo\nTree Search (MCTS), we collect accurate value targets with no annotation\nrequired, on which VM training is based. When decoding, the VM is deployed by\nan adapted MCTS algorithm to provide precise process signals as well as\nverification scores, assisting the LLM policy to achieve high reasoning\naccuracy. We validate the effectiveness of the proposed RL paradigm through\nextensive experiments on coding problems. Upon comparison, our approach\nsignificantly outperforms other reinforcement training baselines (e.g., naive\nGRPO and ReST-DPO), as well as decoding and verification baselines (e.g.,\nPRM-BoN and ORM-MCTS) on well-known coding benchmarks of various levels (e.g.,\nAPPS, BigCodeBench, and HumanEval), indicating its power to strengthen the\nreasoning ability of LLM policies. Codes for our project can be found at\nhttps://github.com/THUDM/ReST-RL.", "published": "2025-08-27 05:16:03", "link": "http://arxiv.org/abs/2508.19576v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Interact-Custom: Customized Human Object Interaction Image Generation", "abstract": "Compositional Customized Image Generation aims to customize multiple target\nconcepts within generation content, which has gained attention for its wild\napplication.Existing approaches mainly concentrate on the target entity's\nappearance preservation, while neglecting the fine-grained interaction control\namong target entities.To enable the model of such interaction control\ncapability, we focus on human object interaction scenario and propose the task\nof Customized Human Object Interaction Image Generation(CHOI), which\nsimultaneously requires identity preservation for target human object and the\ninteraction semantic control between them.Two primary challenges exist for\nCHOI:(1)simultaneous identity preservation and interaction control demands\nrequire the model to decompose the human object into self-contained identity\nfeatures and pose-oriented interaction features, while the current HOI image\ndatasets fail to provide ideal samples for such feature-decomposed\nlearning.(2)inappropriate spatial configuration between human and object may\nlead to the lack of desired interaction semantics.To tackle it, we first\nprocess a large-scale dataset, where each sample encompasses the same pair of\nhuman object involving different interactive poses.Then we design a two-stage\nmodel Interact-Custom, which firstly explicitly models the spatial\nconfiguration by generating a foreground mask depicting the interaction\nbehavior, then under the guidance of this mask, we generate the target human\nobject interacting while preserving their identities features.Furthermore, if\nthe background image and the union location of where the target human object\nshould appear are provided by users, Interact-Custom also provides the optional\nfunctionality to specify them, offering high content controllability. Extensive\nexperiments on our tailored metrics for CHOI task demonstrate the effectiveness\nof our approach.", "published": "2025-08-27 05:15:16", "link": "http://arxiv.org/abs/2508.19575v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Multimodal Prototype Alignment for Semi-supervised Pathology Image Segmentation", "abstract": "Pathological image segmentation faces numerous challenges, particularly due\nto ambiguous semantic boundaries and the high cost of pixel-level annotations.\nAlthough recent semi-supervised methods based on consistency regularization\n(e.g., UniMatch) have made notable progress, they mainly rely on\nperturbation-based consistency within the image modality, making it difficult\nto capture high-level semantic priors, especially in structurally complex\npathology images. To address these limitations, we propose MPAMatch - a novel\nsegmentation framework that performs pixel-level contrastive learning under a\nmultimodal prototype-guided supervision paradigm. The core innovation of\nMPAMatch lies in the dual contrastive learning scheme between image prototypes\nand pixel labels, and between text prototypes and pixel labels, providing\nsupervision at both structural and semantic levels. This coarse-to-fine\nsupervisory strategy not only enhances the discriminative capability on\nunlabeled samples but also introduces the text prototype supervision into\nsegmentation for the first time, significantly improving semantic boundary\nmodeling. In addition, we reconstruct the classic segmentation architecture\n(TransUNet) by replacing its ViT backbone with a pathology-pretrained\nfoundation model (Uni), enabling more effective extraction of\npathology-relevant features. Extensive experiments on GLAS, EBHI-SEG-GLAND,\nEBHI-SEG-CANCER, and KPI show MPAMatch's superiority over state-of-the-art\nmethods, validating its dual advantages in structural and semantic modeling.", "published": "2025-08-27 05:15:13", "link": "http://arxiv.org/abs/2508.19574v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era", "abstract": "Generative models such as Large Language Models, Diffusion Models, and\ngenerative adversarial networks have recently revolutionized the creation of\nsynthetic data, offering scalable solutions to data scarcity, privacy, and\nannotation challenges in data mining. This tutorial introduces the foundations\nand latest advances in synthetic data generation, covers key methodologies and\npractical frameworks, and discusses evaluation strategies and applications.\nAttendees will gain actionable insights into leveraging generative synthetic\ndata to enhance data mining research and practice. More information can be\nfound on our website: https://syndata4dm.github.io/.", "published": "2025-08-27 05:04:07", "link": "http://arxiv.org/abs/2508.19570v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Skill-based Explanations for Serendipitous Course Recommendation", "abstract": "Academic choice is crucial in U.S. undergraduate education, allowing students\nsignificant freedom in course selection. However, navigating the complex\nacademic environment is challenging due to limited information, guidance, and\nan overwhelming number of choices, compounded by time restrictions and the high\ndemand for popular courses. Although career counselors exist, their numbers are\ninsufficient, and course recommendation systems, though personalized, often\nlack insight into student perceptions and explanations to assess course\nrelevance. In this paper, a deep learning-based concept extraction model is\ndeveloped to efficiently extract relevant concepts from course descriptions to\nimprove the recommendation process. Using this model, the study examines the\neffects of skill-based explanations within a serendipitous recommendation\nframework, tested through the AskOski system at the University of California,\nBerkeley. The findings indicate that these explanations not only increase user\ninterest, particularly in courses with high unexpectedness, but also bolster\ndecision-making confidence. This underscores the importance of integrating\nskill-related data and explanations into educational recommendation systems.", "published": "2025-08-27 04:58:56", "link": "http://arxiv.org/abs/2508.19569v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Energy-Efficient Learning-Based Beamforming for ISAC-Enabled V2X Networks", "abstract": "This work proposes an energy-efficient, learning-based beamforming scheme for\nintegrated sensing and communication (ISAC)-enabled V2X networks. Specifically,\nwe first model the dynamic and uncertain nature of V2X environments as a Markov\nDecision Process. This formulation allows the roadside unit to generate\nbeamforming decisions based solely on current sensing information, thereby\neliminating the need for frequent pilot transmissions and extensive channel\nstate information acquisition. We then develop a deep reinforcement learning\n(DRL) algorithm to jointly optimize beamforming and power allocation, ensuring\nboth communication throughput and sensing accuracy in highly dynamic scenario.\nTo address the high energy demands of conventional learning-based schemes, we\nembed spiking neural networks (SNNs) into the DRL framework. Leveraging their\nevent-driven and sparsely activated architecture, SNNs significantly enhance\nenergy efficiency while maintaining robust performance. Simulation results\nconfirm that the proposed method achieves substantial energy savings and\nsuperior communication performance, demonstrating its potential to support\ngreen and sustainable connectivity in future V2X systems.", "published": "2025-08-27 04:52:07", "link": "http://arxiv.org/abs/2508.19566v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "FlowDet: Overcoming Perspective and Scale Challenges in Real-Time End-to-End Traffic Detection", "abstract": "End-to-end object detectors offer a promising NMS-free paradigm for real-time\napplications, yet their high computational cost remains a significant barrier,\nparticularly for complex scenarios like intersection traffic monitoring. To\naddress this challenge, we propose FlowDet, a high-speed detector featuring a\ndecoupled encoder optimization strategy applied to the DETR architecture.\nSpecifically, FlowDet employs a novel Geometric Deformable Unit (GDU) for\ntraffic-aware geometric modeling and a Scale-Aware Attention (SAA) module to\nmaintain high representational power across extreme scale variations. To\nrigorously evaluate the model's performance in environments with severe\nocclusion and high object density, we collected the Intersection-Flow-5k\ndataset, a new challenging scene for this task. Evaluated on\nIntersection-Flow-5k, FlowDet establishes a new state-of-the-art. Compared to\nthe strong RT-DETR baseline, it improves AP(test) by 1.5% and AP50(test) by\n1.6%, while simultaneously reducing GFLOPs by 63.2% and increasing inference\nspeed by 16.2%. Our work demonstrates a new path towards building highly\nefficient and accurate detectors for demanding, real-world perception systems.\nThe Intersection-Flow-5k dataset is available at\nhttps://github.com/AstronZh/Intersection-Flow-5K.", "published": "2025-08-27 04:49:04", "link": "http://arxiv.org/abs/2508.19565v1", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10; I.5.1"], "primary_category": "cs.CV"}
{"title": "Bi-LoRA: Efficient Sharpness-Aware Minimization for Fine-Tuning Large-Scale Models", "abstract": "Fine-tuning large-scale pre-trained models with limited data presents\nsignificant challenges for generalization. While Sharpness-Aware Minimization\n(SAM) has proven effective in improving generalization by seeking flat minima,\nits substantial extra memory and computation overhead make it impractical for\nlarge models. Integrating SAM with parameter-efficient fine-tuning methods like\nLow-Rank Adaptation (LoRA) is a promising direction. However, we find that\ndirectly applying SAM to LoRA parameters limits the sharpness optimization to a\nrestricted subspace, hindering its effectiveness. To address this limitation,\nwe propose Bi-directional Low-Rank Adaptation (Bi-LoRA), which introduces an\nauxiliary LoRA module to model SAM's adversarial weight perturbations. It\ndecouples SAM's weight perturbations from LoRA optimization: the primary LoRA\nmodule adapts to specific tasks via standard gradient descent, while the\nauxiliary module captures the sharpness of the loss landscape through gradient\nascent. Such dual-module design enables Bi-LoRA to capture broader sharpness\nfor achieving flatter minima while remaining memory-efficient. Another\nimportant benefit is that the dual design allows for simultaneous optimization\nand perturbation, eliminating SAM's doubled training costs. Extensive\nexperiments across diverse tasks and architectures demonstrate Bi-LoRA's\nefficiency and effectiveness in enhancing generalization.", "published": "2025-08-27 04:46:56", "link": "http://arxiv.org/abs/2508.19564v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Just Because You Can, Doesn't Mean You Should: LLMs for Data Fitting", "abstract": "Large Language Models (LLMs) are being applied in a wide array of settings,\nwell beyond the typical language-oriented use cases. In particular, LLMs are\nincreasingly used as a plug-and-play method for fitting data and generating\npredictions. Prior work has shown that LLMs, via in-context learning or\nsupervised fine-tuning, can perform competitively with many tabular supervised\nlearning techniques in terms of predictive performance. However, we identify a\ncritical vulnerability of using LLMs for data fitting -- making changes to data\nrepresentation that are completely irrelevant to the underlying learning task\ncan drastically alter LLMs' predictions on the same data. For example, simply\nchanging variable names can sway the size of prediction error by as much as 82%\nin certain settings. Such prediction sensitivity with respect to\ntask-irrelevant variations manifests under both in-context learning and\nsupervised fine-tuning, for both close-weight and open-weight general-purpose\nLLMs. Moreover, by examining the attention scores of an open-weight LLM, we\ndiscover a non-uniform attention pattern: training examples and variable\nnames/values which happen to occupy certain positions in the prompt receive\nmore attention when output tokens are generated, even though different\npositions are expected to receive roughly the same attention. This partially\nexplains the sensitivity in the presence of task-irrelevant variations. We also\nconsider a state-of-the-art tabular foundation model (TabPFN) trained\nspecifically for data fitting. Despite being explicitly designed to achieve\nprediction robustness, TabPFN is still not immune to task-irrelevant\nvariations. Overall, despite LLMs' impressive predictive capabilities,\ncurrently they lack even the basic level of robustness to be used as a\nprincipled data-fitting tool.", "published": "2025-08-27 04:46:05", "link": "http://arxiv.org/abs/2508.19563v1", "categories": ["cs.LG", "cs.AI", "stat.AP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities", "abstract": "This paper introduces Democracy-in-Silico, an agent-based simulation where\nsocieties of advanced AI agents, imbued with complex psychological personas,\ngovern themselves under different institutional frameworks. We explore what it\nmeans to be human in an age of AI by tasking Large Language Models (LLMs) to\nembody agents with traumatic memories, hidden agendas, and psychological\ntriggers. These agents engage in deliberation, legislation, and elections under\nvarious stressors, such as budget crises and resource scarcity. We present a\nnovel metric, the Power-Preservation Index (PPI), to quantify misaligned\nbehavior where agents prioritize their own power over public welfare. Our\nfindings demonstrate that institutional design, specifically the combination of\na Constitutional AI (CAI) charter and a mediated deliberation protocol, serves\nas a potent alignment mechanism. These structures significantly reduce corrupt\npower-seeking behavior, improve policy stability, and enhance citizen welfare\ncompared to less constrained democratic models. The simulation reveals that an\ninstitutional design may offer a framework for aligning the complex, emergent\nbehaviors of future artificial agent societies, forcing us to reconsider what\nhuman rituals and responsibilities are essential in an age of shared authorship\nwith non-human entities.", "published": "2025-08-27 04:44:41", "link": "http://arxiv.org/abs/2508.19562v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference", "abstract": "Serving Large Language Models (LLMs) is a GPU-intensive task where\ntraditional autoscalers fall short, particularly for modern Prefill-Decode\n(P/D) disaggregated architectures. This architectural shift, while powerful,\nintroduces significant operational challenges, including inefficient use of\nheterogeneous hardware, network bottlenecks, and critical imbalances between\nprefill and decode stages. We introduce HeteroScale, a coordinated autoscaling\nframework that addresses the core challenges of P/D disaggregated serving.\nHeteroScale combines a topology-aware scheduler that adapts to heterogeneous\nhardware and network constraints with a novel metric-driven policy derived from\nthe first large-scale empirical study of autoscaling signals in production. By\nleveraging a single, robust metric to jointly scale prefill and decode pools,\nHeteroScale maintains architectural balance while ensuring efficient, adaptive\nresource management. Deployed in a massive production environment on tens of\nthousands of GPUs, HeteroScale has proven its effectiveness, increasing average\nGPU utilization by a significant 26.6 percentage points and saving hundreds of\nthousands of GPU-hours daily, all while upholding stringent service level\nobjectives.", "published": "2025-08-27 04:22:02", "link": "http://arxiv.org/abs/2508.19559v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "WEBEYETRACK: Scalable Eye-Tracking for the Browser via On-Device Few-Shot Personalization", "abstract": "With advancements in AI, new gaze estimation methods are exceeding\nstate-of-the-art (SOTA) benchmarks, but their real-world application reveals a\ngap with commercial eye-tracking solutions. Factors like model size, inference\ntime, and privacy often go unaddressed. Meanwhile, webcam-based eye-tracking\nmethods lack sufficient accuracy, in particular due to head movement. To tackle\nthese issues, we introduce We bEyeTrack, a framework that integrates\nlightweight SOTA gaze estimation models directly in the browser. It\nincorporates model-based head pose estimation and on-device few-shot learning\nwith as few as nine calibration samples (k < 9). WebEyeTrack adapts to new\nusers, achieving SOTA performance with an error margin of 2.32 cm on\nGazeCapture and real-time inference speeds of 2.4 milliseconds on an iPhone 14.\nOur open-source code is available at\nhttps://github.com/RedForestAi/WebEyeTrack.", "published": "2025-08-27 03:38:58", "link": "http://arxiv.org/abs/2508.19544v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Orchid: Orchestrating Context Across Creative Workflows with Generative AI", "abstract": "Context is critical for meaningful interactions between people and Generative\nAI (GenAI). Yet mainstream tools offer limited means to orchestrate it,\nparticularly across workflows that span multiple interactions, sessions, and\nmodels, as often occurs in creative projects. Re specifying prior details,\njuggling diverse artifacts, and dealing with context drift overwhelm users,\nobscure intent, and curtail creativity. To address these challenges, we present\nOrchid, a system that gives its users affordances to specify, reference, and\nmonitor context throughout evolving workflows. Specifically, Orchid enables\nusers to (1) specify context related to the project, themselves, and different\nstyles, (2) reference these via explicit mentions, inline selection, or\nimplicit grounding, and (3) monitor context assigned to different interactions\nacross the workflow. In a within-subjects study (n=12), participants using\nOrchid to execute creative tasks (compared to a baseline toolkit of web search,\nLLM-based chat, and digital notebooks) produced more novel and feasible\noutcomes, reporting greater alignment between their intent and the AI's\nresponses, higher perceived control, and increased transparency. By\nprioritizing context orchestration, Orchid offers an actionable step toward\nnext generation GenAI tools that support complex, iterative workflows -\nenabling creators and AI to stay aligned and augment their creative potential.", "published": "2025-08-27 02:12:37", "link": "http://arxiv.org/abs/2508.19517v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "A Self-Supervised Mixture-of-Experts Framework for Multi-behavior Recommendation", "abstract": "In e-commerce, where users face a vast array of possible item choices,\nrecommender systems are vital for helping them discover suitable items they\nmight otherwise overlook. While many recommender systems primarily rely on a\nuser's purchase history, recent multi-behavior recommender systems incorporate\nvarious auxiliary user behaviors, such as item clicks and cart additions, to\nenhance recommendations. Despite their overall performance gains, their\neffectiveness varies considerably between visited items (i.e., those a user has\ninteracted with through auxiliary behaviors) and unvisited items (i.e., those\nwith which the user has had no such interactions). Specifically, our analysis\nreveals that (1) existing multi-behavior recommender systems exhibit a\nsignificant gap in recommendation quality between the two item types (visited\nand unvisited items) and (2) achieving strong performance on both types with a\nsingle model architecture remains challenging. To tackle these issues, we\npropose a novel multi-behavior recommender system, MEMBER. It employs a\nmixture-of-experts framework, with experts designed to recommend the two item\ntypes, respectively. Each expert is trained using a self-supervised method\nspecialized for its design goal. In our comprehensive experiments, we show the\neffectiveness of MEMBER across both item types, achieving up to 65.46\\%\nperformance gain over the best competitor in terms of Hit Ratio@20.", "published": "2025-08-27 01:32:59", "link": "http://arxiv.org/abs/2508.19507v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Learning Game-Playing Agents with Generative Code Optimization", "abstract": "We present a generative optimization approach for learning game-playing\nagents, where policies are represented as Python programs and refined using\nlarge language models (LLMs). Our method treats decision-making policies as\nself-evolving code, with current observation as input and an in-game action as\noutput, enabling agents to self-improve through execution traces and natural\nlanguage feedback with minimal human intervention. Applied to Atari games, our\ngame-playing Python program achieves performance competitive with deep\nreinforcement learning (RL) baselines while using significantly less training\ntime and much fewer environment interactions. This work highlights the promise\nof programmatic policy representations for building efficient, adaptable agents\ncapable of complex, long-horizon reasoning.", "published": "2025-08-27 01:30:20", "link": "http://arxiv.org/abs/2508.19506v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Caught in the Act: a mechanistic approach to detecting deception", "abstract": "Sophisticated instrumentation for AI systems might have indicators that\nsignal misalignment from human values, not unlike a \"check engine\" light in\ncars. One such indicator of misalignment is deceptiveness in generated\nresponses. Future AI instrumentation may have the ability to detect when an LLM\ngenerates deceptive responses while reasoning about seemingly plausible but\nincorrect answers to factual questions. In this work, we demonstrate that\nlinear probes on LLMs internal activations can detect deception in their\nresponses with extremely high accuracy. Our probes reach a maximum of greater\nthan 90% accuracy in distinguishing between deceptive and non-deceptive\narguments generated by llama and qwen models ranging from 1.5B to 14B\nparameters, including their DeepSeek-r1 finetuned variants. We observe that\nprobes on smaller models (1.5B) achieve chance accuracy at detecting deception,\nwhile larger models (greater than 7B) reach 70-80%, with their reasoning\ncounterparts exceeding 90%. The layer-wise probe accuracy follows a three-stage\npattern across layers: near-random (50%) in early layers, peaking in middle\nlayers, and slightly declining in later layers. Furthermore, using an iterative\nnull space projection approach, we find multitudes of linear directions that\nencode deception, ranging from 20 in Qwen 3B to nearly 100 in DeepSeek 7B and\nQwen 14B models.", "published": "2025-08-27 01:29:52", "link": "http://arxiv.org/abs/2508.19505v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SLIM: Subtrajectory-Level Elimination for More Effective Reasoning", "abstract": "In recent months, substantial progress has been made in complex reasoning of\nLarge Language Models, particularly through the application of test-time\nscaling. Notable examples include o1/o3/o4 series and DeepSeek-R1. When\nresponding to a query, these models generate an extended reasoning trajectory,\nduring which the model explores, reflects, backtracks, and self-verifies before\narriving at a conclusion. However, fine-tuning models with such reasoning\ntrajectories may not always be optimal. Our findings indicate that not all\ncomponents within these reasoning trajectories contribute positively to the\nreasoning process; in fact, some components may affect the overall performance\nnegatively. In this study, we divide a reasoning trajectory into individual\nsubtrajectories and develop a \"5+2\" framework to: (1) systematically identify\nsuboptimal subtrajectories within the reasoning trajectory based on five\nhuman-established criteria; (2) assess the independence of the suboptimal\nsubtrajectories identified in (1) from the subsequent content, ensuring that\ntheir elimination does not compromise overall flow and coherence of the\nreasoning process. Additionally, a sampling algorithm, built upon the \"5+2\"\nframework, is employed to select data whose reasoning process is free from\nsuboptimal subtrajectories to the highest degree. Experimental results\ndemonstrate that our method can reduce the number of suboptimal subtrajectories\nby 25.9\\% during the inference. Furthermore, our method achieves an average\naccuracy of 58.92\\% on highly challenging math benchmarks with only two thirds\nof training data, surpassing the average accuracy of 58.06\\% achieved with the\nentire data, and outperforming open-source datasets, when fine-tuning\nQwen2.5-Math-7B. Finally, We validated our method under resource constraints\nand observed improved performance across various inference token limits.", "published": "2025-08-27 01:19:44", "link": "http://arxiv.org/abs/2508.19502v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Servant, Stalker, Predator: How An Honest, Helpful, And Harmless (3H) Agent Unlocks Adversarial Skills", "abstract": "This paper identifies and analyzes a novel vulnerability class in Model\nContext Protocol (MCP) based agent systems. The attack chain describes and\ndemonstrates how benign, individually authorized tasks can be orchestrated to\nproduce harmful emergent behaviors. Through systematic analysis using the MITRE\nATLAS framework, we demonstrate how 95 agents tested with access to multiple\nservices-including browser automation, financial analysis, location tracking,\nand code deployment-can chain legitimate operations into sophisticated attack\nsequences that extend beyond the security boundaries of any individual service.\nThese red team exercises survey whether current MCP architectures lack\ncross-domain security measures necessary to detect or prevent a large category\nof compositional attacks. We present empirical evidence of specific attack\nchains that achieve targeted harm through service orchestration, including data\nexfiltration, financial manipulation, and infrastructure compromise. These\nfindings reveal that the fundamental security assumption of service isolation\nfails when agents can coordinate actions across multiple domains, creating an\nexponential attack surface that grows with each additional capability. This\nresearch provides a barebones experimental framework that evaluate not whether\nagents can complete MCP benchmark tasks, but what happens when they complete\nthem too well and optimize across multiple services in ways that violate human\nexpectations and safety constraints. We propose three concrete experimental\ndirections using the existing MCP benchmark suite.", "published": "2025-08-27 01:11:59", "link": "http://arxiv.org/abs/2508.19500v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery", "abstract": "Origin-Destination (OD) flow matrices are essential for urban mobility\nanalysis, underpinning applications in traffic forecasting, infrastructure\nplanning, and policy design. However, existing methods suffer from two critical\nlimitations: (1) reliance on auxiliary features (e.g., Points of Interest,\nsocioeconomic statistics) that are costly to collect and have limited spatial\ncoverage; and (2) sensitivity to spatial topology, where minor index reordering\nof urban regions (e.g., census tract relabeling) disrupts structural coherence\nin generated flows. To address these challenges, we propose Sat2Flow, a latent\nstructure-aware diffusion-based framework that generates structurally coherent\nOD flows using solely satellite imagery as input. Our approach introduces a\nmulti-kernel encoder to capture diverse regional interactions and employs a\npermutation-aware diffusion process that aligns latent representations across\ndifferent regional orderings. Through a joint contrastive training objective\nthat bridges satellite-derived features with OD patterns, combined with\nequivariant diffusion training that enforces structural consistency, Sat2Flow\nensures topological robustness under arbitrary regional reindexing.\nExperimental results on real-world urban datasets demonstrate that Sat2Flow\noutperforms both physics-based and data-driven baselines in numerical accuracy\nwhile preserving empirical distributions and spatial structures under index\npermutations. Sat2Flow offers a globally scalable solution for OD flow\ngeneration in data-scarce urban environments, eliminating region-specific\nauxiliary data dependencies while maintaining structural invariance for robust\nmobility modeling.", "published": "2025-08-27 01:05:37", "link": "http://arxiv.org/abs/2508.19499v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense", "abstract": "Cyber defense requires automating defensive decision-making under stealthy,\ndeceptive, and continuously evolving adversarial strategies. The FlipIt game\nprovides a foundational framework for modeling interactions between a defender\nand an advanced adversary that compromises a system without being immediately\ndetected. In FlipIt, the attacker and defender compete to control a shared\nresource by performing a Flip action and paying a cost. However, the existing\nFlipIt frameworks rely on a small number of heuristics or specialized learning\ntechniques, which can lead to brittleness and the inability to adapt to new\nattacks. To address these limitations, we introduce PoolFlip, a multi-agent gym\nenvironment that extends the FlipIt game to allow efficient learning for\nattackers and defenders. Furthermore, we propose Flip-PSRO, a multi-agent\nreinforcement learning (MARL) approach that leverages population-based training\nto train defender agents equipped to generalize against a range of unknown,\npotentially adaptive opponents. Our empirical results suggest that Flip-PSRO\ndefenders are $2\\times$ more effective than baselines to generalize to a\nheuristic attack not exposed in training. In addition, our newly designed\nownership-based utility functions ensure that Flip-PSRO defenders maintain a\nhigh level of control while optimizing performance.", "published": "2025-08-27 00:18:49", "link": "http://arxiv.org/abs/2508.19488v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Data-Efficient Symbolic Regression via Foundation Model Distillation", "abstract": "Discovering interpretable mathematical equations from observed data (a.k.a.\nequation discovery or symbolic regression) is a cornerstone of scientific\ndiscovery, enabling transparent modeling of physical, biological, and economic\nsystems. While foundation models pre-trained on large-scale equation datasets\noffer a promising starting point, they often suffer from negative transfer and\npoor generalization when applied to small, domain-specific datasets. In this\npaper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer\nEmbeddings), a data-efficient fine-tuning framework that adapts foundation\nmodels for symbolic equation discovery in low-data regimes via distillation.\nEQUATE combines symbolic-numeric alignment with evaluator-guided embedding\noptimization, enabling a principled embedding-search-generation paradigm. Our\napproach reformulates discrete equation search as a continuous optimization\ntask in a shared embedding space, guided by data-equation fitness and\nsimplicity. Experiments across three standard public benchmarks (Feynman,\nStrogatz, and black-box datasets) demonstrate that EQUATE consistently\noutperforms state-of-the-art baselines in both accuracy and robustness, while\npreserving low complexity and fast inference. These results highlight EQUATE as\na practical and generalizable solution for data-efficient symbolic regression\nin foundation model distillation settings.", "published": "2025-08-27 00:18:48", "link": "http://arxiv.org/abs/2508.19487v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors", "abstract": "Labelling images of Lepidoptera (moths) from automated camera systems is\nvital for understanding insect declines. However, accurate species\nidentification is challenging due to domain shifts between curated images and\nnoisy field imagery. We propose a lightweight classification approach,\ncombining limited expert-labelled field data with knowledge distillation from\nthe high-performance BioCLIP2 foundation model into a ConvNeXt-tiny\narchitecture. Experiments on 101 Danish moth species from AMI camera systems\ndemonstrate that BioCLIP2 substantially outperforms other methods and that our\ndistilled lightweight model achieves comparable accuracy with significantly\nreduced computational cost. These insights offer practical guidelines for the\ndevelopment of efficient insect monitoring systems and bridging domain gaps for\nfine-grained classification.", "published": "2025-08-27 17:55:39", "link": "http://arxiv.org/abs/2508.20089v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AudioStory: Generating Long-Form Narrative Audio with Large Language Models", "abstract": "Recent advances in text-to-audio (TTA) generation excel at synthesizing short\naudio clips but struggle with long-form narrative audio, which requires\ntemporal coherence and compositional reasoning. To address this gap, we propose\nAudioStory, a unified framework that integrates large language models (LLMs)\nwith TTA systems to generate structured, long-form audio narratives. AudioStory\npossesses strong instruction-following reasoning generation capabilities. It\nemploys LLMs to decompose complex narrative queries into temporally ordered\nsub-tasks with contextual cues, enabling coherent scene transitions and\nemotional tone consistency. AudioStory has two appealing features: (1)\nDecoupled bridging mechanism: AudioStory disentangles LLM-diffuser\ncollaboration into two specialized components, i.e., a bridging query for\nintra-event semantic alignment and a residual query for cross-event coherence\npreservation. (2) End-to-end training: By unifying instruction comprehension\nand audio generation within a single end-to-end framework, AudioStory\neliminates the need for modular training pipelines while enhancing synergy\nbetween components. Furthermore, we establish a benchmark AudioStory-10K,\nencompassing diverse domains such as animated soundscapes and natural sound\nnarratives. Extensive experiments show the superiority of AudioStory on both\nsingle-audio generation and narrative audio generation, surpassing prior TTA\nbaselines in both instruction-following ability and audio fidelity. Our code is\navailable at https://github.com/TencentARC/AudioStory", "published": "2025-08-27 17:55:38", "link": "http://arxiv.org/abs/2508.20088v1", "categories": ["cs.CV", "cs.MM", "cs.SD"], "primary_category": "cs.CV"}
{"title": "Seam360GS: Seamless 360\u00b0 Gaussian Splatting from Real-World Omnidirectional Images", "abstract": "360-degree visual content is widely shared on platforms such as YouTube and\nplays a central role in virtual reality, robotics, and autonomous navigation.\nHowever, consumer-grade dual-fisheye systems consistently yield imperfect\npanoramas due to inherent lens separation and angular distortions. In this\nwork, we introduce a novel calibration framework that incorporates a\ndual-fisheye camera model into the 3D Gaussian splatting pipeline. Our approach\nnot only simulates the realistic visual artifacts produced by dual-fisheye\ncameras but also enables the synthesis of seamlessly rendered 360-degree\nimages. By jointly optimizing 3D Gaussian parameters alongside calibration\nvariables that emulate lens gaps and angular distortions, our framework\ntransforms imperfect omnidirectional inputs into flawless novel view synthesis.\nExtensive evaluations on real-world datasets confirm that our method produces\nseamless renderings-even from imperfect images-and outperforms existing\n360-degree rendering models.", "published": "2025-08-27 17:46:46", "link": "http://arxiv.org/abs/2508.20080v1", "categories": ["cs.CV", "cs.GR"], "primary_category": "cs.CV"}
{"title": "Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies", "abstract": "Vision-Language-Action (VLA) models adapt large vision-language backbones to\nmap images and instructions to robot actions. However, prevailing VLA decoders\neither generate actions autoregressively in a fixed left-to-right order or\nattach continuous diffusion or flow matching heads outside the backbone,\ndemanding specialized training and iterative sampling that hinder a unified,\nscalable architecture. We present Discrete Diffusion VLA, a single-transformer\npolicy that models discretized action chunks with discrete diffusion and is\ntrained with the same cross-entropy objective as the VLM backbone. The design\nretains diffusion's progressive refinement paradigm while remaining natively\ncompatible with the discrete token interface of VLMs. Our method achieves an\nadaptive decoding order that resolves easy action elements before harder ones\nand uses secondary remasking to revisit uncertain predictions across refinement\nrounds, which improves consistency and enables robust error correction. This\nunified decoder preserves pretrained vision language priors, supports parallel\ndecoding, breaks the autoregressive bottleneck, and reduces the number of\nfunction evaluations. Discrete Diffusion VLA achieves 96.3% avg. SR on LIBERO,\n71.2% visual matching on SimplerEnv Fractal and 49.3% overall on SimplerEnv\nBridge, improving over both autoregressive and continuous diffusion baselines.\nThese findings indicate that discrete-diffusion action decoder supports precise\naction modeling and consistent training, laying groundwork for scaling VLA to\nlarger models and datasets.", "published": "2025-08-27 17:39:11", "link": "http://arxiv.org/abs/2508.20072v1", "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "PAUL: Uncertainty-Guided Partition and Augmentation for Robust Cross-View Geo-Localization under Noisy Correspondence", "abstract": "Cross-view geo-localization is a critical task for UAV navigation, event\ndetection, and aerial surveying, as it enables matching between drone-captured\nand satellite imagery. Most existing approaches embed multi-modal data into a\njoint feature space to maximize the similarity of paired images. However, these\nmethods typically assume perfect alignment of image pairs during training,\nwhich rarely holds true in real-world scenarios. In practice, factors such as\nurban canyon effects, electromagnetic interference, and adverse weather\nfrequently induce GPS drift, resulting in systematic alignment shifts where\nonly partial correspondences exist between pairs. Despite its prevalence, this\nsource of noisy correspondence has received limited attention in current\nresearch. In this paper, we formally introduce and address the Noisy\nCorrespondence on Cross-View Geo-Localization (NC-CVGL) problem, aiming to\nbridge the gap between idealized benchmarks and practical applications. To this\nend, we propose PAUL (Partition and Augmentation by Uncertainty Learning), a\nnovel framework that partitions and augments training data based on estimated\ndata uncertainty through uncertainty-aware co-augmentation and evidential\nco-training. Specifically, PAUL selectively augments regions with high\ncorrespondence confidence and utilizes uncertainty estimation to refine feature\nlearning, effectively suppressing noise from misaligned pairs. Distinct from\ntraditional filtering or label correction, PAUL leverages both data uncertainty\nand loss discrepancy for targeted partitioning and augmentation, thus providing\nrobust supervision for noisy samples. Comprehensive experiments validate the\neffectiveness of individual components in PAUL,which consistently achieves\nsuperior performance over other competitive noisy-correspondence-driven methods\nin various noise ratios.", "published": "2025-08-27 17:21:22", "link": "http://arxiv.org/abs/2508.20066v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OpenM3D: Open Vocabulary Multi-view Indoor 3D Object Detection without Human Annotations", "abstract": "Open-vocabulary (OV) 3D object detection is an emerging field, yet its\nexploration through image-based methods remains limited compared to 3D point\ncloud-based methods. We introduce OpenM3D, a novel open-vocabulary multi-view\nindoor 3D object detector trained without human annotations. In particular,\nOpenM3D is a single-stage detector adapting the 2D-induced voxel features from\nthe ImGeoNet model. To support OV, it is jointly trained with a class-agnostic\n3D localization loss requiring high-quality 3D pseudo boxes and a\nvoxel-semantic alignment loss requiring diverse pre-trained CLIP features. We\nfollow the training setting of OV-3DET where posed RGB-D images are given but\nno human annotations of 3D boxes or classes are available. We propose a 3D\nPseudo Box Generation method using a graph embedding technique that combines 2D\nsegments into coherent 3D structures. Our pseudo-boxes achieve higher precision\nand recall than other methods, including the method proposed in OV-3DET. We\nfurther sample diverse CLIP features from 2D segments associated with each\ncoherent 3D structure to align with the corresponding voxel feature. The key to\ntraining a highly accurate single-stage detector requires both losses to be\nlearned toward high-quality targets. At inference, OpenM3D, a highly efficient\ndetector, requires only multi-view images for input and demonstrates superior\naccuracy and speed (0.3 sec. per scene) on ScanNet200 and ARKitScenes indoor\nbenchmarks compared to existing methods. We outperform a strong two-stage\nmethod that leverages our class-agnostic detector with a ViT CLIP-based OV\nclassifier and a baseline incorporating multi-view depth estimator on both\naccuracy and speed.", "published": "2025-08-27 17:17:00", "link": "http://arxiv.org/abs/2508.20063v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Segmentation Assisted Incremental Test Time Adaptation in an Open World", "abstract": "In dynamic environments, unfamiliar objects and distribution shifts are often\nencountered, which challenge the generalization abilities of the deployed\ntrained models. This work addresses Incremental Test Time Adaptation of Vision\nLanguage Models, tackling scenarios where unseen classes and unseen domains\ncontinuously appear during testing. Unlike traditional Test Time Adaptation\napproaches, where the test stream comes only from a predefined set of classes,\nour framework allows models to adapt simultaneously to both covariate and label\nshifts, actively incorporating new classes as they emerge. Towards this goal,\nwe establish a new benchmark for ITTA, integrating single image TTA methods for\nVLMs with active labeling techniques that query an oracle for samples\npotentially representing unseen classes during test time. We propose a\nsegmentation assisted active labeling module, termed SegAssist, which is\ntraining free and repurposes the segmentation capabilities of VLMs to refine\nactive sample selection, prioritizing samples likely to belong to unseen\nclasses. Extensive experiments on several benchmark datasets demonstrate the\npotential of SegAssist to enhance the performance of VLMs in real world\nscenarios, where continuous adaptation to emerging data is essential.\nProject-page:https://manogna-s.github.io/segassist/", "published": "2025-08-27 16:33:32", "link": "http://arxiv.org/abs/2508.20029v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GS: Generative Segmentation via Label Diffusion", "abstract": "Language-driven image segmentation is a fundamental task in vision-language\nunderstanding, requiring models to segment regions of an image corresponding to\nnatural language expressions. Traditional methods approach this as a\ndiscriminative problem, assigning each pixel to foreground or background based\non semantic alignment. Recently, diffusion models have been introduced to this\ndomain, but existing approaches remain image-centric: they either (i) use image\ndiffusion models as visual feature extractors, (ii) synthesize segmentation\ndata via image generation to train discriminative models, or (iii) perform\ndiffusion inversion to extract attention cues from pre-trained image diffusion\nmodels-thereby treating segmentation as an auxiliary process. In this paper, we\npropose GS (Generative Segmentation), a novel framework that formulates\nsegmentation itself as a generative task via label diffusion. Instead of\ngenerating images conditioned on label maps and text, GS reverses the\ngenerative process: it directly generates segmentation masks from noise,\nconditioned on both the input image and the accompanying language description.\nThis paradigm makes label generation the primary modeling target, enabling\nend-to-end training with explicit control over spatial and semantic fidelity.\nTo demonstrate the effectiveness of our approach, we evaluate GS on Panoptic\nNarrative Grounding (PNG), a representative and challenging benchmark for\nmultimodal segmentation that requires panoptic-level reasoning guided by\nnarrative captions. Experimental results show that GS significantly outperforms\nexisting discriminative and diffusion-based methods, setting a new\nstate-of-the-art for language-driven segmentation.", "published": "2025-08-27 16:28:15", "link": "http://arxiv.org/abs/2508.20020v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Assessing the Geolocation Capabilities, Limitations and Societal Risks of Generative Vision-Language Models", "abstract": "Geo-localization is the task of identifying the location of an image using\nvisual cues alone. It has beneficial applications, such as improving disaster\nresponse, enhancing navigation, and geography education. Recently,\nVision-Language Models (VLMs) are increasingly demonstrating capabilities as\naccurate image geo-locators. This brings significant privacy risks, including\nthose related to stalking and surveillance, considering the widespread uses of\nAI models and sharing of photos on social media. The precision of these models\nis likely to improve in the future. Despite these risks, there is little work\non systematically evaluating the geolocation precision of Generative VLMs,\ntheir limits and potential for unintended inferences. To bridge this gap, we\nconduct a comprehensive assessment of the geolocation capabilities of 25\nstate-of-the-art VLMs on four benchmark image datasets captured in diverse\nenvironments. Our results offer insight into the internal reasoning of VLMs and\nhighlight their strengths, limitations, and potential societal risks. Our\nfindings indicate that current VLMs perform poorly on generic street-level\nimages yet achieve notably high accuracy (61\\%) on images resembling social\nmedia content, raising significant and urgent privacy concerns.", "published": "2025-08-27 15:21:31", "link": "http://arxiv.org/abs/2508.19967v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Reimagining Image Segmentation using Active Contour: From Chan Vese Algorithm into a Proposal Novel Functional Loss Framework", "abstract": "In this paper, we present a comprehensive study and analysis of the Chan-Vese\nalgorithm for image segmentation. We employ a discretized scheme derived from\nthe empirical study of the Chan-Vese model's functional energy and its partial\ndifferential equation based on its level set function. We provide a proof of\nthe results and an implementation using MATLAB. Leveraging modern computer\nvision methodologies, we propose a functional segmentation loss based on active\ncontours, utilizing pytorch.nn.ModuleLoss and a level set based on the\nChan-Vese algorithm. We compare our results with common computer vision\nsegmentation datasets and evaluate the performance of classical loss functions\nagainst our proposed method. All code and materials used are available at\nhttps://github.com/gguzzy/chan_vese_functional_loss.", "published": "2025-08-27 15:01:11", "link": "http://arxiv.org/abs/2508.19946v1", "categories": ["cs.CV", "physics.med-ph"], "primary_category": "cs.CV"}
{"title": "Integrating SAM Supervision for 3D Weakly Supervised Point Cloud Segmentation", "abstract": "Current methods for 3D semantic segmentation propose training models with\nlimited annotations to address the difficulty of annotating large, irregular,\nand unordered 3D point cloud data. They usually focus on the 3D domain only,\nwithout leveraging the complementary nature of 2D and 3D data. Besides, some\nmethods extend original labels or generate pseudo labels to guide the training,\nbut they often fail to fully use these labels or address the noise within them.\nMeanwhile, the emergence of comprehensive and adaptable foundation models has\noffered effective solutions for segmenting 2D data. Leveraging this\nadvancement, we present a novel approach that maximizes the utility of sparsely\navailable 3D annotations by incorporating segmentation masks generated by 2D\nfoundation models. We further propagate the 2D segmentation masks into the 3D\nspace by establishing geometric correspondences between 3D scenes and 2D views.\nWe extend the highly sparse annotations to encompass the areas delineated by 3D\nmasks, thereby substantially augmenting the pool of available labels.\nFurthermore, we apply confidence- and uncertainty-based consistency\nregularization on augmentations of the 3D point cloud and select the reliable\npseudo labels, which are further spread on the 3D masks to generate more\nlabels. This innovative strategy bridges the gap between limited 3D annotations\nand the powerful capabilities of 2D foundation models, ultimately improving the\nperformance of 3D weakly supervised segmentation.", "published": "2025-08-27 14:13:01", "link": "http://arxiv.org/abs/2508.19909v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Streamlining the Development of Active Learning Methods in Real-World Object Detection", "abstract": "Active learning (AL) for real-world object detection faces computational and\nreliability challenges that limit practical deployment. Developing new AL\nmethods requires training multiple detectors across iterations to compare\nagainst existing approaches. This creates high costs for autonomous driving\ndatasets where the training of one detector requires up to 282 GPU hours.\nAdditionally, AL method rankings vary substantially across validation sets,\ncompromising reliability in safety-critical transportation systems. We\nintroduce object-based set similarity ($\\mathrm{OSS}$), a metric that addresses\nthese challenges. $\\mathrm{OSS}$ (1) quantifies AL method effectiveness without\nrequiring detector training by measuring similarity between training sets and\ntarget domains using object-level features. This enables the elimination of\nineffective AL methods before training. Furthermore, $\\mathrm{OSS}$ (2) enables\nthe selection of representative validation sets for robust evaluation. We\nvalidate our similarity-based approach on three autonomous driving datasets\n(KITTI, BDD100K, CODA) using uncertainty-based AL methods as a case study with\ntwo detector architectures (EfficientDet, YOLOv3). This work is the first to\nunify AL training and evaluation strategies in object detection based on object\nsimilarity. $\\mathrm{OSS}$ is detector-agnostic, requires only labeled object\ncrops, and integrates with existing AL pipelines. This provides a practical\nframework for deploying AL in real-world applications where computational\nefficiency and evaluation reliability are critical. Code is available at\nhttps://mos-ks.github.io/publications/.", "published": "2025-08-27 14:10:16", "link": "http://arxiv.org/abs/2508.19906v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hyperspectral Sensors and Autonomous Driving: Technologies, Limitations, and Opportunities", "abstract": "Hyperspectral imaging (HSI) offers a transformative sensing modality for\nAdvanced Driver Assistance Systems (ADAS) and autonomous driving (AD)\napplications, enabling material-level scene understanding through fine spectral\nresolution beyond the capabilities of traditional RGB imaging. This paper\npresents the first comprehensive review of HSI for automotive applications,\nexamining the strengths, limitations, and suitability of current HSI\ntechnologies in the context of ADAS/AD. In addition to this qualitative review,\nwe analyze 216 commercially available HSI and multispectral imaging cameras,\nbenchmarking them against key automotive criteria: frame rate, spatial\nresolution, spectral dimensionality, and compliance with AEC-Q100 temperature\nstandards. Our analysis reveals a significant gap between HSI's demonstrated\nresearch potential and its commercial readiness. Only four cameras meet the\ndefined performance thresholds, and none comply with AEC-Q100 requirements. In\naddition, the paper reviews recent HSI datasets and applications, including\nsemantic segmentation for road surface classification, pedestrian separability,\nand adverse weather perception. Our review shows that current HSI datasets are\nlimited in terms of scale, spectral consistency, the number of spectral\nchannels, and environmental diversity, posing challenges for the development of\nperception algorithms and the adequate validation of HSI's true potential in\nADAS/AD applications. This review paper establishes the current state of HSI in\nautomotive contexts as of 2025 and outlines key research directions toward\npractical integration of spectral imaging in ADAS and autonomous systems.", "published": "2025-08-27 14:09:53", "link": "http://arxiv.org/abs/2508.19905v1", "categories": ["cs.CV", "cs.ET"], "primary_category": "cs.CV"}
{"title": "NM-Hebb: Coupling Local Hebbian Plasticity with Metric Learning for More Accurate and Interpretable CNNs", "abstract": "Deep Convolutional Neural Networks (CNNs) achieve high accuracy but often\nrely on purely global, gradient-based optimisation, which can lead to\noverfitting, redundant filters, and reduced interpretability. To address these\nlimitations, we propose NM-Hebb, a two-phase training framework that integrates\nneuro-inspired local plasticity with distance-aware supervision. Phase 1\nextends standard supervised training by jointly optimising a cross-entropy\nobjective with two biologically inspired mechanisms: (i) a Hebbian regulariser\nthat aligns the spatial mean of activations with the mean of the corresponding\nconvolutional filter weights, encouraging structured, reusable primitives; and\n(ii) a learnable neuromodulator that gates an elastic-weight-style\nconsolidation loss, preserving beneficial parameters without freezing the\nnetwork. Phase 2 fine-tunes the backbone with a pairwise metric-learning loss,\nexplicitly compressing intra-class distances and enlarging inter-class margins\nin the embedding space. Evaluated on CIFAR-10, CIFAR-100, and TinyImageNet\nacross five backbones (ResNet-18, VGG-11, MobileNet-v2, EfficientNet-V2,\nDenseNet-121), NM-Hebb achieves consistent gains over baseline and other\nmethods: Top-1 accuracy improves by +2.0-10.0 pp (CIFAR-10), +2.0-9.0 pp\n(CIFAR-100), and up to +4.3-8.9 pp (TinyImageNet), with Normalised Mutual\nInformation (NMI) increased by up to +0.15. Qualitative visualisations and\nfilter-level analyses further confirm that NM-Hebb produces more structured and\nselective features, yielding tighter and more interpretable class clusters.\nOverall, coupling local Hebbian plasticity with metric-based fine-tuning yields\nCNNs that are not only more accurate but also more interpretable, offering\npractical benefits for resource-constrained and safety-critical AI deployments.", "published": "2025-08-27 13:53:04", "link": "http://arxiv.org/abs/2508.19896v1", "categories": ["cs.LG", "cs.CV", "I.2.6; I.5.4"], "primary_category": "cs.LG"}
{"title": "PersonaAnimator: Personalized Motion Transfer from Unconstrained Videos", "abstract": "Recent advances in motion generation show remarkable progress. However,\nseveral limitations remain: (1) Existing pose-guided character motion transfer\nmethods merely replicate motion without learning its style characteristics,\nresulting in inexpressive characters. (2) Motion style transfer methods rely\nheavily on motion capture data, which is difficult to obtain. (3) Generated\nmotions sometimes violate physical laws. To address these challenges, this\npaper pioneers a new task: Video-to-Video Motion Personalization. We propose a\nnovel framework, PersonaAnimator, which learns personalized motion patterns\ndirectly from unconstrained videos. This enables personalized motion transfer.\nTo support this task, we introduce PersonaVid, the first video-based\npersonalized motion dataset. It contains 20 motion content categories and 120\nmotion style categories. We further propose a Physics-aware Motion Style\nRegularization mechanism to enforce physical plausibility in the generated\nmotions. Extensive experiments show that PersonaAnimator outperforms\nstate-of-the-art motion transfer methods and sets a new benchmark for the\nVideo-to-Video Motion Personalization task.", "published": "2025-08-27 13:52:25", "link": "http://arxiv.org/abs/2508.19895v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Sky Background Building of Multi-objective Fiber spectra Based on Mutual Information Network", "abstract": "Sky background subtraction is a critical step in Multi-objective Fiber\nspectra process. However, current subtraction relies mainly on sky fiber\nspectra to build Super Sky. These average spectra are lacking in the modeling\nof the environment surrounding the objects. To address this issue, a sky\nbackground estimation model: Sky background building based on Mutual\nInformation (SMI) is proposed. SMI based on mutual information and incremental\ntraining approach. It utilizes spectra from all fibers in the plate to estimate\nthe sky background. SMI contains two main networks, the first network applies a\nwavelength calibration module to extract sky features from spectra, and can\neffectively solve the feature shift problem according to the corresponding\nemission position. The second network employs an incremental training approach\nto maximize mutual information between representations of different spectra to\ncapturing the common component. Then, it minimizes the mutual information\nbetween adjoining spectra representations to obtain individual components. This\nnetwork yields an individual sky background at each location of the object. To\nverify the effectiveness of the method in this paper, we conducted experiments\non the spectra of LAMOST. Results show that SMI can obtain a better object sky\nbackground during the observation, especially in the blue end.", "published": "2025-08-27 13:36:12", "link": "http://arxiv.org/abs/2508.19875v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "TrajFusionNet: Pedestrian Crossing Intention Prediction via Fusion of Sequential and Visual Trajectory Representations", "abstract": "With the introduction of vehicles with autonomous capabilities on public\nroads, predicting pedestrian crossing intention has emerged as an active area\nof research. The task of predicting pedestrian crossing intention involves\ndetermining whether pedestrians in the scene are likely to cross the road or\nnot. In this work, we propose TrajFusionNet, a novel transformer-based model\nthat combines future pedestrian trajectory and vehicle speed predictions as\npriors for predicting crossing intention. TrajFusionNet comprises two branches:\na Sequence Attention Module (SAM) and a Visual Attention Module (VAM). The SAM\nbranch learns from a sequential representation of the observed and predicted\npedestrian trajectory and vehicle speed. Complementarily, the VAM branch\nenables learning from a visual representation of the predicted pedestrian\ntrajectory by overlaying predicted pedestrian bounding boxes onto scene images.\nBy utilizing a small number of lightweight modalities, TrajFusionNet achieves\nthe lowest total inference time (including model runtime and data\npreprocessing) among current state-of-the-art approaches. In terms of\nperformance, it achieves state-of-the-art results across the three most\ncommonly used datasets for pedestrian crossing intention prediction.", "published": "2025-08-27 13:29:15", "link": "http://arxiv.org/abs/2508.19866v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Self-supervised structured object representation learning", "abstract": "Self-supervised learning (SSL) has emerged as a powerful technique for\nlearning visual representations. While recent SSL approaches achieve strong\nresults in global image understanding, they are limited in capturing the\nstructured representation in scenes. In this work, we propose a self-supervised\napproach that progressively builds structured visual representations by\ncombining semantic grouping, instance level separation, and hierarchical\nstructuring. Our approach, based on a novel ProtoScale module, captures visual\nelements across multiple spatial scales. Unlike common strategies like DINO\nthat rely on random cropping and global embeddings, we preserve full scene\ncontext across augmented views to improve performance in dense prediction\ntasks. We validate our method on downstream object detection tasks using a\ncombined subset of multiple datasets (COCO and UA-DETRAC). Experimental results\nshow that our method learns object centric representations that enhance\nsupervised object detection and outperform the state-of-the-art methods, even\nwhen trained with limited annotated data and fewer fine-tuning epochs.", "published": "2025-08-27 13:28:05", "link": "http://arxiv.org/abs/2508.19864v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multimodal Conditional MeshGAN for Personalized Aneurysm Growth Prediction", "abstract": "Personalized, accurate prediction of aortic aneurysm progression is essential\nfor timely intervention but remains challenging due to the need to model both\nsubtle local deformations and global anatomical changes within complex 3D\ngeometries. We propose MCMeshGAN, the first multimodal conditional mesh-to-mesh\ngenerative adversarial network for 3D aneurysm growth prediction. MCMeshGAN\nintroduces a dual-branch architecture combining a novel local KNN-based\nconvolutional network (KCN) to preserve fine-grained geometric details and a\nglobal graph convolutional network (GCN) to capture long-range structural\ncontext, overcoming the over-smoothing limitations of deep GCNs. A dedicated\ncondition branch encodes clinical attributes (age, sex) and the target time\ninterval to generate anatomically plausible, temporally controlled predictions,\nenabling retrospective and prospective modeling. We curated TAAMesh, a new\nlongitudinal thoracic aortic aneurysm mesh dataset consisting of 590 multimodal\nrecords (CT scans, 3D meshes, and clinical data) from 208 patients. Extensive\nexperiments demonstrate that MCMeshGAN consistently outperforms\nstate-of-the-art baselines in both geometric accuracy and clinically important\ndiameter estimation. This framework offers a robust step toward clinically\ndeployable, personalized 3D disease trajectory modeling. The source code for\nMCMeshGAN and the baseline methods is publicly available at\nhttps://github.com/ImperialCollegeLondon/MCMeshGAN.", "published": "2025-08-27 13:25:52", "link": "http://arxiv.org/abs/2508.19862v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Ego-centric Predictive Model Conditioned on Hand Trajectories", "abstract": "In egocentric scenarios, anticipating both the next action and its visual\noutcome is essential for understanding human-object interactions and for\nenabling robotic planning. However, existing paradigms fall short of jointly\nmodeling these aspects. Vision-Language-Action (VLA) models focus on action\nprediction but lack explicit modeling of how actions influence the visual\nscene, while video prediction models generate future frames without\nconditioning on specific actions, often resulting in implausible or\ncontextually inconsistent outcomes. To bridge this gap, we propose a unified\ntwo-stage predictive framework that jointly models action and visual future in\negocentric scenarios, conditioned on hand trajectories. In the first stage, we\nperform consecutive state modeling to process heterogeneous inputs (visual\nobservations, language, and action history) and explicitly predict future hand\ntrajectories. In the second stage, we introduce causal cross-attention to fuse\nmulti-modal cues, leveraging inferred action signals to guide an image-based\nLatent Diffusion Model (LDM) for frame-by-frame future video generation. Our\napproach is the first unified model designed to handle both egocentric human\nactivity understanding and robotic manipulation tasks, providing explicit\npredictions of both upcoming actions and their visual consequences. Extensive\nexperiments on Ego4D, BridgeData, and RLBench demonstrate that our method\noutperforms state-of-the-art baselines in both action prediction and future\nvideo synthesis.", "published": "2025-08-27 13:09:55", "link": "http://arxiv.org/abs/2508.19852v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Image Quality Assessment for Machines: Paradigm, Large-scale Database, and Models", "abstract": "Machine vision systems (MVS) are intrinsically vulnerable to performance\ndegradation under adverse visual conditions. To address this, we propose a\nmachine-centric image quality assessment (MIQA) framework that quantifies the\nimpact of image degradations on MVS performance. We establish an MIQA paradigm\nencompassing the end-to-end assessment workflow. To support this, we construct\na machine-centric image quality database (MIQD-2.5M), comprising 2.5 million\nsamples that capture distinctive degradation responses in both consistency and\naccuracy metrics, spanning 75 vision models, 250 degradation types, and three\nrepresentative vision tasks. We further propose a region-aware MIQA (RA-MIQA)\nmodel to evaluate MVS visual quality through fine-grained spatial degradation\nanalysis. Extensive experiments benchmark the proposed RA-MIQA against seven\nhuman visual system (HVS)-based IQA metrics and five retrained classical\nbackbones. Results demonstrate RA-MIQA's superior performance in multiple\ndimensions, e.g., achieving SRCC gains of 13.56% on consistency and 13.37% on\naccuracy for image classification, while also revealing task-specific\ndegradation sensitivities. Critically, HVS-based metrics prove inadequate for\nMVS quality prediction, while even specialized MIQA models struggle with\nbackground degradations, accuracy-oriented estimation, and subtle distortions.\nThis study can advance MVS reliability and establish foundations for\nmachine-centric image processing and optimization. The model and code are\navailable at: https://github.com/XiaoqiWang/MIQA.", "published": "2025-08-27 13:07:24", "link": "http://arxiv.org/abs/2508.19850v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AutoQ-VIS: Improving Unsupervised Video Instance Segmentation via Automatic Quality Assessment", "abstract": "Video Instance Segmentation (VIS) faces significant annotation challenges due\nto its dual requirements of pixel-level masks and temporal consistency labels.\nWhile recent unsupervised methods like VideoCutLER eliminate optical flow\ndependencies through synthetic data, they remain constrained by the\nsynthetic-to-real domain gap. We present AutoQ-VIS, a novel unsupervised\nframework that bridges this gap through quality-guided self-training. Our\napproach establishes a closed-loop system between pseudo-label generation and\nautomatic quality assessment, enabling progressive adaptation from synthetic to\nreal videos. Experiments demonstrate state-of-the-art performance with 52.6\n$\\text{AP}_{50}$ on YouTubeVIS-2019 val set, surpassing the previous\nstate-of-the-art VideoCutLER by 4.4$\\%$, while requiring no human annotations.\nThis demonstrates the viability of quality-aware self-training for unsupervised\nVIS. The source code of our method is available at\nhttps://github.com/wcbup/AutoQ-VIS.", "published": "2025-08-27 11:52:41", "link": "http://arxiv.org/abs/2508.19808v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Context-aware Sparse Spatiotemporal Learning for Event-based Vision", "abstract": "Event-based camera has emerged as a promising paradigm for robot perception,\noffering advantages with high temporal resolution, high dynamic range, and\nrobustness to motion blur. However, existing deep learning-based event\nprocessing methods often fail to fully leverage the sparse nature of event\ndata, complicating their integration into resource-constrained edge\napplications. While neuromorphic computing provides an energy-efficient\nalternative, spiking neural networks struggle to match of performance of\nstate-of-the-art models in complex event-based vision tasks, like object\ndetection and optical flow. Moreover, achieving high activation sparsity in\nneural networks is still difficult and often demands careful manual tuning of\nsparsity-inducing loss terms. Here, we propose Context-aware Sparse\nSpatiotemporal Learning (CSSL), a novel framework that introduces context-aware\nthresholding to dynamically regulate neuron activations based on the input\ndistribution, naturally reducing activation density without explicit sparsity\nconstraints. Applied to event-based object detection and optical flow\nestimation, CSSL achieves comparable or superior performance to\nstate-of-the-art methods while maintaining extremely high neuronal sparsity.\nOur experimental results highlight CSSL's crucial role in enabling efficient\nevent-based vision for neuromorphic processing.", "published": "2025-08-27 11:48:03", "link": "http://arxiv.org/abs/2508.19806v1", "categories": ["cs.CV", "cs.NE"], "primary_category": "cs.CV"}
{"title": "FusionSort: Enhanced Cluttered Waste Segmentation with Advanced Decoding and Comprehensive Modality Optimization", "abstract": "In the realm of waste management, automating the sorting process for\nnon-biodegradable materials presents considerable challenges due to the\ncomplexity and variability of waste streams. To address these challenges, we\nintroduce an enhanced neural architecture that builds upon an existing\nEncoder-Decoder structure to improve the accuracy and efficiency of waste\nsorting systems. Our model integrates several key innovations: a Comprehensive\nAttention Block within the decoder, which refines feature representations by\ncombining convolutional and upsampling operations. In parallel, we utilize\nattention through the Mamba architecture, providing an additional performance\nboost. We also introduce a Data Fusion Block that fuses images with more than\nthree channels. To achieve this, we apply PCA transformation to reduce the\ndimensionality while retaining the maximum variance and essential information\nacross three dimensions, which are then used for further processing. We\nevaluated the model on RGB, hyperspectral, multispectral, and a combination of\nRGB and hyperspectral data. The results demonstrate that our approach\noutperforms existing methods by a significant margin.", "published": "2025-08-27 11:32:59", "link": "http://arxiv.org/abs/2508.19798v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Not Every Gift Comes in Gold Paper or with a Red Ribbon: Exploring Color Perception in Text-to-Image Models", "abstract": "Text-to-image generation has recently seen remarkable success, granting users\nwith the ability to create high-quality images through the use of text.\nHowever, contemporary methods face challenges in capturing the precise\nsemantics conveyed by complex multi-object prompts. Consequently, many works\nhave sought to mitigate such semantic misalignments, typically via\ninference-time schemes that modify the attention layers of the denoising\nnetworks. However, prior work has mostly utilized coarse metrics, such as the\ncosine similarity between text and image CLIP embeddings, or human evaluations,\nwhich are challenging to conduct on a larger-scale. In this work, we perform a\ncase study on colors -- a fundamental attribute commonly associated with\nobjects in text prompts, which offer a rich test bed for rigorous evaluation.\nOur analysis reveals that pretrained models struggle to generate images that\nfaithfully reflect multiple color attributes-far more so than with single-color\nprompts-and that neither inference-time techniques nor existing editing methods\nreliably resolve these semantic misalignments. Accordingly, we introduce a\ndedicated image editing technique, mitigating the issue of multi-object\nsemantic alignment for prompts containing multiple colors. We demonstrate that\nour approach significantly boosts performance over a wide range of metrics,\nconsidering images generated by various text-to-image diffusion-based\ntechniques.", "published": "2025-08-27 11:16:58", "link": "http://arxiv.org/abs/2508.19791v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "StableIntrinsic: Detail-preserving One-step Diffusion Model for Multi-view Material Estimation", "abstract": "Recovering material information from images has been extensively studied in\ncomputer graphics and vision. Recent works in material estimation leverage\ndiffusion model showing promising results. However, these diffusion-based\nmethods adopt a multi-step denoising strategy, which is time-consuming for each\nestimation. Such stochastic inference also conflicts with the deterministic\nmaterial estimation task, leading to a high variance estimated results. In this\npaper, we introduce StableIntrinsic, a one-step diffusion model for multi-view\nmaterial estimation that can produce high-quality material parameters with low\nvariance. To address the overly-smoothing problem in one-step diffusion,\nStableIntrinsic applies losses in pixel space, with each loss designed based on\nthe properties of the material. Additionally, StableIntrinsic introduces a\nDetail Injection Network (DIN) to eliminate the detail loss caused by VAE\nencoding, while further enhancing the sharpness of material prediction results.\nThe experimental results indicate that our method surpasses the current\nstate-of-the-art techniques by achieving a $9.9\\%$ improvement in the Peak\nSignal-to-Noise Ratio (PSNR) of albedo, and by reducing the Mean Square Error\n(MSE) for metallic and roughness by $44.4\\%$ and $60.0\\%$, respectively.", "published": "2025-08-27 11:15:55", "link": "http://arxiv.org/abs/2508.19789v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Context-Aware Risk Estimation in Home Environments: A Probabilistic Framework for Service Robots", "abstract": "We present a novel framework for estimating accident-prone regions in\neveryday indoor scenes, aimed at improving real-time risk awareness in service\nrobots operating in human-centric environments. As robots become integrated\ninto daily life, particularly in homes, the ability to anticipate and respond\nto environmental hazards is crucial for ensuring user safety, trust, and\neffective human-robot interaction. Our approach models object-level risk and\ncontext through a semantic graph-based propagation algorithm. Each object is\nrepresented as a node with an associated risk score, and risk propagates\nasymmetrically from high-risk to low-risk objects based on spatial proximity\nand accident relationship. This enables the robot to infer potential hazards\neven when they are not explicitly visible or labeled. Designed for\ninterpretability and lightweight onboard deployment, our method is validated on\na dataset with human-annotated risk regions, achieving a binary risk detection\naccuracy of 75%. The system demonstrates strong alignment with human\nperception, particularly in scenes involving sharp or unstable objects. These\nresults underline the potential of context-aware risk reasoning to enhance\nrobotic scene understanding and proactive safety behaviors in shared\nhuman-robot spaces. This framework could serve as a foundation for future\nsystems that make context-driven safety decisions, provide real-time alerts, or\nautonomously assist users in avoiding or mitigating hazards within home\nenvironments.", "published": "2025-08-27 11:14:05", "link": "http://arxiv.org/abs/2508.19788v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "MAPo : Motion-Aware Partitioning of Deformable 3D Gaussian Splatting for High-Fidelity Dynamic Scene Reconstruction", "abstract": "3D Gaussian Splatting, known for enabling high-quality static scene\nreconstruction with fast rendering, is increasingly being applied to dynamic\nscene reconstruction. A common strategy involves learning a deformation field\nto model the temporal changes of a canonical set of 3D Gaussians. However,\nthese deformation-based methods often produce blurred renderings and lose fine\nmotion details in highly dynamic regions due to the inherent limitations of a\nsingle, unified model in representing diverse motion patterns. To address these\nchallenges, we introduce Motion-Aware Partitioning of Deformable 3D Gaussian\nSplatting (MAPo), a novel framework for high-fidelity dynamic scene\nreconstruction. Its core is a dynamic score-based partitioning strategy that\ndistinguishes between high- and low-dynamic 3D Gaussians. For high-dynamic 3D\nGaussians, we recursively partition them temporally and duplicate their\ndeformation networks for each new temporal segment, enabling specialized\nmodeling to capture intricate motion details. Concurrently, low-dynamic 3DGs\nare treated as static to reduce computational costs. However, this temporal\npartitioning strategy for high-dynamic 3DGs can introduce visual\ndiscontinuities across frames at the partition boundaries. To address this, we\nintroduce a cross-frame consistency loss, which not only ensures visual\ncontinuity but also further enhances rendering quality. Extensive experiments\ndemonstrate that MAPo achieves superior rendering quality compared to baselines\nwhile maintaining comparable computational costs, particularly in regions with\ncomplex or rapid motions.", "published": "2025-08-27 11:10:46", "link": "http://arxiv.org/abs/2508.19786v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The Return of Structural Handwritten Mathematical Expression Recognition", "abstract": "Handwritten Mathematical Expression Recognition is foundational for\neducational technologies, enabling applications like digital note-taking and\nautomated grading. While modern encoder-decoder architectures with large\nlanguage models excel at LaTeX generation, they lack explicit symbol-to-trace\nalignment, a critical limitation for error analysis, interpretability, and\nspatially aware interactive applications requiring selective content updates.\nThis paper introduces a structural recognition approach with two innovations: 1\nan automatic annotation system that uses a neural network to map LaTeX\nequations to raw traces, automatically generating annotations for symbol\nsegmentation, classification, and spatial relations, and 2 a modular structural\nrecognition system that independently optimizes segmentation, classification,\nand relation prediction. By leveraging a dataset enriched with structural\nannotations from our auto-labeling system, the proposed recognition system\ncombines graph-based trace sorting, a hybrid convolutional-recurrent network,\nand transformer-based correction to achieve competitive performance on the\nCROHME-2023 benchmark. Crucially, our structural recognition system generates a\ncomplete graph structure that directly links handwritten traces to predicted\nsymbols, enabling transparent error analysis and interpretable outputs.", "published": "2025-08-27 10:58:59", "link": "http://arxiv.org/abs/2508.19773v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AIM: Adaptive Intra-Network Modulation for Balanced Multimodal Learning", "abstract": "Multimodal learning has significantly enhanced machine learning performance\nbut still faces numerous challenges and limitations. Imbalanced multimodal\nlearning is one of the problems extensively studied in recent works and is\ntypically mitigated by modulating the learning of each modality. However, we\nfind that these methods typically hinder the dominant modality's learning to\npromote weaker modalities, which affects overall multimodal performance. We\nanalyze the cause of this issue and highlight a commonly overlooked problem:\noptimization bias within networks. To address this, we propose Adaptive\nIntra-Network Modulation (AIM) to improve balanced modality learning. AIM\naccounts for differences in optimization state across parameters and depths\nwithin the network during modulation, achieving balanced multimodal learning\nwithout hindering either dominant or weak modalities for the first time.\nSpecifically, AIM decouples the dominant modality's under-optimized parameters\ninto Auxiliary Blocks and encourages reliance on these performance-degraded\nblocks for joint training with weaker modalities. This approach effectively\nprevents suppression of weaker modalities while enabling targeted optimization\nof under-optimized parameters to improve the dominant modality. Additionally,\nAIM assesses modality imbalance level across network depths and adaptively\nadjusts modulation strength at each depth. Experimental results demonstrate\nthat AIM outperforms state-of-the-art imbalanced modality learning methods\nacross multiple benchmarks and exhibits strong generalizability across\ndifferent backbones, fusion strategies, and optimizers.", "published": "2025-08-27 10:53:36", "link": "http://arxiv.org/abs/2508.19769v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions", "abstract": "Pollinator insects such as honeybees and bumblebees are vital to global food\nproduction and ecosystem stability, yet their populations are declining due to\nincreasing anthropogenic and environmental stressors. To support scalable,\nautomated pollinator monitoring, we introduce BuzzSet, a new large-scale\ndataset of high-resolution pollinator images collected in real agricultural\nfield conditions. BuzzSet contains 7856 manually verified and labeled images,\nwith over 8000 annotated instances across three classes: honeybees, bumblebees,\nand unidentified insects. Initial annotations were generated using a YOLOv12\nmodel trained on external data and refined via human verification using\nopen-source labeling tools. All images were preprocessed into 256~$\\times$~256\ntiles to improve the detection of small insects. We provide strong baselines\nusing the RF-DETR transformer-based object detector. The model achieves high\nF1-scores of 0.94 and 0.92 for honeybee and bumblebee classes, respectively,\nwith confusion matrix results showing minimal misclassification between these\ncategories. The unidentified class remains more challenging due to label\nambiguity and lower sample frequency, yet still contributes useful insights for\nrobustness evaluation. Overall detection quality is strong, with a best\nmAP@0.50 of 0.559. BuzzSet offers a valuable benchmark for small object\ndetection, class separation under label noise, and ecological computer vision.", "published": "2025-08-27 10:40:15", "link": "http://arxiv.org/abs/2508.19762v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FastAvatar: Towards Unified Fast High-Fidelity 3D Avatar Reconstruction with Large Gaussian Reconstruction Transformers", "abstract": "Despite significant progress in 3D avatar reconstruction, it still faces\nchallenges such as high time complexity, sensitivity to data quality, and low\ndata utilization. We propose FastAvatar, a feedforward 3D avatar framework\ncapable of flexibly leveraging diverse daily recordings (e.g., a single image,\nmulti-view observations, or monocular video) to reconstruct a high-quality 3D\nGaussian Splatting (3DGS) model within seconds, using only a single unified\nmodel. FastAvatar's core is a Large Gaussian Reconstruction Transformer\nfeaturing three key designs: First, a variant VGGT-style transformer\narchitecture aggregating multi-frame cues while injecting initial 3D prompt to\npredict an aggregatable canonical 3DGS representation; Second, multi-granular\nguidance encoding (camera pose, FLAME expression, head pose) mitigating\nanimation-induced misalignment for variable-length inputs; Third, incremental\nGaussian aggregation via landmark tracking and sliced fusion losses.\nIntegrating these features, FastAvatar enables incremental reconstruction,\ni.e., improving quality with more observations, unlike prior work wasting input\ndata. This yields a quality-speed-tunable paradigm for highly usable avatar\nmodeling. Extensive experiments show that FastAvatar has higher quality and\nhighly competitive speed compared to existing methods.", "published": "2025-08-27 10:30:15", "link": "http://arxiv.org/abs/2508.19754v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SPLF-SAM: Self-Prompting Segment Anything Model for Light Field Salient Object Detection", "abstract": "Segment Anything Model (SAM) has demonstrated remarkable capabilities in\nsolving light field salient object detection (LF SOD). However, most existing\nmodels tend to neglect the extraction of prompt information under this task.\nMeanwhile, traditional models ignore the analysis of frequency-domain\ninformation, which leads to small objects being overwhelmed by noise. In this\npaper, we put forward a novel model called self-prompting light field segment\nanything model (SPLF-SAM), equipped with unified multi-scale feature embedding\nblock (UMFEB) and a multi-scale adaptive filtering adapter (MAFA). UMFEB is\ncapable of identifying multiple objects of varying sizes, while MAFA, by\nlearning frequency features, effectively prevents small objects from being\noverwhelmed by noise. Extensive experiments have demonstrated the superiority\nof our method over ten state-of-the-art (SOTA) LF SOD methods. Our code will be\navailable at https://github.com/XucherCH/splfsam.", "published": "2025-08-27 10:22:17", "link": "http://arxiv.org/abs/2508.19746v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "POEv2: a flexible and robust framework for generic line segment detection and wireframe line segment detection", "abstract": "Line segment detection in images has been studied for several decades.\nExisting line segment detectors can be roughly divided into two categories:\ngeneric line segment detectors and wireframe line segment detectors. Generic\nline segment detectors aim to detect all meaningful line segments in images and\ntraditional approaches usually fall into this category. Recent deep learning\nbased approaches are mostly wireframe line segment detectors. They detect only\nline segments that are geometrically meaningful and have large spatial support.\nDue to the difference in the aim of design, the performance of generic line\nsegment detectors for the task of wireframe line segment detection won't be\nsatisfactory, and vice versa. In this work, we propose a robust framework that\ncan be used for both generic line segment detection and wireframe line segment\ndetection. The proposed method is an improved version of the Pixel Orientation\nEstimation (POE) method. It is thus named as POEv2. POEv2 detects line segments\nfrom edge strength maps, and can be combined with any edge detector. We show in\nour experiments that by combining the proposed POEv2 with an efficient edge\ndetector, it achieves state-of-the-art performance on three publicly available\ndatasets.", "published": "2025-08-27 10:13:46", "link": "http://arxiv.org/abs/2508.19742v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Improving Generalization in Deepfake Detection with Face Foundation Models and Metric Learning", "abstract": "The increasing realism and accessibility of deepfakes have raised critical\nconcerns about media authenticity and information integrity. Despite recent\nadvances, deepfake detection models often struggle to generalize beyond their\ntraining distributions, particularly when applied to media content found in the\nwild. In this work, we present a robust video deepfake detection framework with\nstrong generalization that takes advantage of the rich facial representations\nlearned by face foundation models. Our method is built on top of FSFM, a\nself-supervised model trained on real face data, and is further fine-tuned\nusing an ensemble of deepfake datasets spanning both face-swapping and\nface-reenactment manipulations. To enhance discriminative power, we incorporate\ntriplet loss variants during training, guiding the model to produce more\nseparable embeddings between real and fake samples. Additionally, we explore\nattribution-based supervision schemes, where deepfakes are categorized by\nmanipulation type or source dataset, to assess their impact on generalization.\nExtensive experiments across diverse evaluation benchmarks demonstrate the\neffectiveness of our approach, especially in challenging real-world scenarios.", "published": "2025-08-27 09:46:45", "link": "http://arxiv.org/abs/2508.19730v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Addressing Deepfake Issue in Selfie banking through camera based authentication", "abstract": "Fake images in selfie banking are increasingly becoming a threat. Previously,\nit was just Photoshop, but now deep learning technologies enable us to create\nhighly realistic fake identities, which fraudsters exploit to bypass biometric\nsystems such as facial recognition in online banking. This paper explores the\nuse of an already established forensic recognition system, previously used for\npicture camera localization, in deepfake detection.", "published": "2025-08-27 09:20:56", "link": "http://arxiv.org/abs/2508.19714v1", "categories": ["cs.CR", "cs.CV"], "primary_category": "cs.CR"}
{"title": "FreeVPS: Repurposing Training-Free SAM2 for Generalizable Video Polyp Segmentation", "abstract": "Existing video polyp segmentation (VPS) paradigms usually struggle to balance\nbetween spatiotemporal modeling and domain generalization, limiting their\napplicability in real clinical scenarios. To embrace this challenge, we recast\nthe VPS task as a track-by-detect paradigm that leverages the spatial contexts\ncaptured by the image polyp segmentation (IPS) model while integrating the\ntemporal modeling capabilities of segment anything model 2 (SAM2). However,\nduring long-term polyp tracking in colonoscopy videos, SAM2 suffers from error\naccumulation, resulting in a snowball effect that compromises segmentation\nstability. We mitigate this issue by repurposing SAM2 as a video polyp\nsegmenter with two training-free modules. In particular, the intra-association\nfiltering module eliminates spatial inaccuracies originating from the detecting\nstage, reducing false positives. The inter-association refinement module\nadaptively updates the memory bank to prevent error propagation over time,\nenhancing temporal coherence. Both modules work synergistically to stabilize\nSAM2, achieving cutting-edge performance in both in-domain and out-of-domain\nscenarios. Furthermore, we demonstrate the robust tracking capabilities of\nFreeVPS in long-untrimmed colonoscopy videos, underscoring its potential\nreliable clinical analysis.", "published": "2025-08-27 09:12:38", "link": "http://arxiv.org/abs/2508.19705v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LabelGS: Label-Aware 3D Gaussian Splatting for 3D Scene Segmentation", "abstract": "3D Gaussian Splatting (3DGS) has emerged as a novel explicit representation\nfor 3D scenes, offering both high-fidelity reconstruction and efficient\nrendering. However, 3DGS lacks 3D segmentation ability, which limits its\napplicability in tasks that require scene understanding. The identification and\nisolating of specific object components is crucial. To address this limitation,\nwe propose Label-aware 3D Gaussian Splatting (LabelGS), a method that augments\nthe Gaussian representation with object label.LabelGS introduces cross-view\nconsistent semantic masks for 3D Gaussians and employs a novel Occlusion\nAnalysis Model to avoid overfitting occlusion during optimization, Main\nGaussian Labeling model to lift 2D semantic prior to 3D Gaussian and Gaussian\nProjection Filter to avoid Gaussian label conflict. Our approach achieves\neffective decoupling of Gaussian representations and refines the 3DGS\noptimization process through a random region sampling strategy, significantly\nimproving efficiency. Extensive experiments demonstrate that LabelGS\noutperforms previous state-of-the-art methods, including Feature-3DGS, in the\n3D scene segmentation task. Notably, LabelGS achieves a remarkable 22X speedup\nin training compared to Feature-3DGS, at a resolution of 1440X1080. Our code\nwill be at https://github.com/garrisonz/LabelGS.", "published": "2025-08-27 09:07:38", "link": "http://arxiv.org/abs/2508.19699v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Synthetic Image Detection via Spectral Gaps of QC-RBIM Nishimori Bethe-Hessian Operators", "abstract": "The rapid advance of deep generative models such as GANs and diffusion\nnetworks now produces images that are virtually indistinguishable from genuine\nphotographs, undermining media forensics and biometric security. Supervised\ndetectors quickly lose effectiveness on unseen generators or after adversarial\npost-processing, while existing unsupervised methods that rely on low-level\nstatistical cues remain fragile. We introduce a physics-inspired,\nmodel-agnostic detector that treats synthetic-image identification as a\ncommunity-detection problem on a sparse weighted graph. Image features are\nfirst extracted with pretrained CNNs and reduced to 32 dimensions, each feature\nvector becomes a node of a Multi-Edge Type QC-LDPC graph. Pairwise similarities\nare transformed into edge couplings calibrated at the Nishimori temperature,\nproducing a Random Bond Ising Model (RBIM) whose Bethe-Hessian spectrum\nexhibits a characteristic gap when genuine community structure (real images) is\npresent. Synthetic images violate the Nishimori symmetry and therefore lack\nsuch gaps. We validate the approach on binary tasks cat versus dog and male\nversus female using real photos from Flickr-Faces-HQ and CelebA and synthetic\ncounterparts generated by GANs and diffusion models. Without any labeled\nsynthetic data or retraining of the feature extractor, the detector achieves\nover 94% accuracy. Spectral analysis shows multiple well separated gaps for\nreal image sets and a collapsed spectrum for generated ones. Our contributions\nare threefold: a novel LDPC graph construction that embeds deep image features,\nan analytical link between Nishimori temperature RBIM and the Bethe-Hessian\nspectrum providing a Bayes optimal detection criterion; and a practical,\nunsupervised synthetic image detector robust to new generative architectures.\nFuture work will extend the framework to video streams and multi-class anomaly\ndetection.", "published": "2025-08-27 09:06:53", "link": "http://arxiv.org/abs/2508.19698v1", "categories": ["cs.CV", "cs.IT", "math.IT", "math.SP"], "primary_category": "cs.CV"}
{"title": "SAT: Supervisor Regularization and Animation Augmentation for Two-process Monocular Texture 3D Human Reconstruction", "abstract": "Monocular texture 3D human reconstruction aims to create a complete 3D\ndigital avatar from just a single front-view human RGB image. However, the\ngeometric ambiguity inherent in a single 2D image and the scarcity of 3D human\ntraining data are the main obstacles limiting progress in this field. To\naddress these issues, current methods employ prior geometric estimation\nnetworks to derive various human geometric forms, such as the SMPL model and\nnormal maps. However, they struggle to integrate these modalities effectively,\nleading to view inconsistencies, such as facial distortions. To this end, we\npropose a two-process 3D human reconstruction framework, SAT, which seamlessly\nlearns various prior geometries in a unified manner and reconstructs\nhigh-quality textured 3D avatars as the final output. To further facilitate\ngeometry learning, we introduce a Supervisor Feature Regularization module. By\nemploying a multi-view network with the same structure to provide intermediate\nfeatures as training supervision, these varied geometric priors can be better\nfused. To tackle data scarcity and further improve reconstruction quality, we\nalso propose an Online Animation Augmentation module. By building a\none-feed-forward animation network, we augment a massive number of samples from\nthe original 3D human data online for model training. Extensive experiments on\ntwo benchmarks show the superiority of our approach compared to\nstate-of-the-art methods.", "published": "2025-08-27 08:52:35", "link": "http://arxiv.org/abs/2508.19688v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Frequency-Aware Self-Supervised Learning for Ultra-Wide-Field Image Enhancement", "abstract": "Ultra-Wide-Field (UWF) retinal imaging has revolutionized retinal diagnostics\nby providing a comprehensive view of the retina. However, it often suffers from\nquality-degrading factors such as blurring and uneven illumination, which\nobscure fine details and mask pathological information. While numerous retinal\nimage enhancement methods have been proposed for other fundus imageries, they\noften fail to address the unique requirements in UWF, particularly the need to\npreserve pathological details. In this paper, we propose a novel\nfrequency-aware self-supervised learning method for UWF image enhancement. It\nincorporates frequency-decoupled image deblurring and Retinex-guided\nillumination compensation modules. An asymmetric channel integration operation\nis introduced in the former module, so as to combine global and local views by\nleveraging high- and low-frequency information, ensuring the preservation of\nfine and broader structural details. In addition, a color preservation unit is\nproposed in the latter Retinex-based module, to provide multi-scale spatial and\nfrequency information, enabling accurate illumination estimation and\ncorrection. Experimental results demonstrate that the proposed work not only\nenhances visualization quality but also improves disease diagnosis performance\nby restoring and correcting fine local details and uneven intensity. To the\nbest of our knowledge, this work is the first attempt for UWF image\nenhancement, offering a robust and clinically valuable tool for improving\nretinal disease management.", "published": "2025-08-27 08:24:20", "link": "http://arxiv.org/abs/2508.19664v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hardware-aware vs. Hardware-agnostic Energy Estimation for SNN in Space Applications", "abstract": "Spiking Neural Networks (SNNs), inspired by biological intelligence, have\nlong been considered inherently energy-efficient, making them attractive for\nresource-constrained domains such as space applications. However, recent\ncomparative studies with conventional Artificial Neural Networks (ANNs) have\nbegun to question this reputation, especially for digital implementations. This\nwork investigates SNNs for multi-output regression, specifically 3-D satellite\nposition estimation from monocular images, and compares hardware-aware and\nhardware-agnostic energy estimation methods. The proposed SNN, trained using\nthe membrane potential of the Leaky Integrate-and-Fire (LIF) neuron in the\nfinal layer, achieves comparable Mean Squared Error (MSE) to a reference\nConvolutional Neural Network (CNN) on a photorealistic satellite dataset.\nEnergy analysis shows that while hardware-agnostic methods predict a consistent\n50-60% energy advantage for SNNs over CNNs, hardware-aware analysis reveals\nthat significant energy savings are realized only on neuromorphic hardware and\nwith high input sparsity. The influence of dark pixel ratio on energy\nconsumption is quantified, emphasizing the impact of data characteristics and\nhardware assumptions. These findings highlight the need for transparent\nevaluation methods and explicit disclosure of underlying assumptions to ensure\nfair comparisons of neural network energy efficiency.", "published": "2025-08-27 08:03:58", "link": "http://arxiv.org/abs/2508.19654v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Self-Rewarding Vision-Language Model via Reasoning Decomposition", "abstract": "Vision-Language Models (VLMs) often suffer from visual hallucinations, saying\nthings that are not actually in the image, and language shortcuts, where they\nskip the visual part and just rely on text priors. These issues arise because\nmost post-training methods for VLMs rely on simple verifiable answer matching\nand supervise only final outputs, leaving intermediate visual reasoning without\nexplicit guidance. As a result, VLMs receive sparse visual signals and often\nlearn to prioritize language-based reasoning over visual perception. To\nmitigate this, some existing methods add visual supervision using human\nannotations or distilled labels from external large models. However, human\nannotations are labor-intensive and costly, and because external signals cannot\nadapt to the evolving policy, they cause distributional shifts that can lead to\nreward hacking. In this paper, we introduce Vision-SR1, a self-rewarding method\nthat improves visual reasoning without relying on external visual supervisions\nvia reinforcement learning. Vision-SR1 decomposes VLM reasoning into two\nstages: visual perception and language reasoning. The model is first prompted\nto produce self-contained visual perceptions that are sufficient to answer the\nquestion without referring back the input image. To validate this\nself-containment, the same VLM model is then re-prompted to perform language\nreasoning using only the generated perception as input to compute reward. This\nself-reward is combined with supervision on final outputs, providing a balanced\ntraining signal that strengthens both visual perception and language reasoning.\nOur experiments demonstrate that Vision-SR1 improves visual reasoning,\nmitigates visual hallucinations, and reduces reliance on language shortcuts\nacross diverse vision-language tasks.", "published": "2025-08-27 08:01:03", "link": "http://arxiv.org/abs/2508.19652v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Scalable Object Detection in the Car Interior With Vision Foundation Models", "abstract": "AI tasks in the car interior like identifying and localizing externally\nintroduced objects is crucial for response quality of personal assistants.\nHowever, computational resources of on-board systems remain highly constrained,\nrestricting the deployment of such solutions directly within the vehicle. To\naddress this limitation, we propose the novel Object Detection and Localization\n(ODAL) framework for interior scene understanding. Our approach leverages\nvision foundation models through a distributed architecture, splitting\ncomputational tasks between on-board and cloud. This design overcomes the\nresource constraints of running foundation models directly in the car. To\nbenchmark model performance, we introduce ODALbench, a new metric for\ncomprehensive assessment of detection and localization.Our analysis\ndemonstrates the framework's potential to establish new standards in this\ndomain. We compare the state-of-the-art GPT-4o vision foundation model with the\nlightweight LLaVA 1.5 7B model and explore how fine-tuning enhances the\nlightweight models performance. Remarkably, our fine-tuned ODAL-LLaVA model\nachieves an ODAL$_{score}$ of 89%, representing a 71% improvement over its\nbaseline performance and outperforming GPT-4o by nearly 20%. Furthermore, the\nfine-tuned model maintains high detection accuracy while significantly reducing\nhallucinations, achieving an ODAL$_{SNR}$ three times higher than GPT-4o.", "published": "2025-08-27 07:58:57", "link": "http://arxiv.org/abs/2508.19651v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Video-LevelGauge: Investigating Contextual Positional Bias in Large Video Language Models", "abstract": "Large video language models (LVLMs) have made notable progress in video\nunderstanding, spurring the development of corresponding evaluation benchmarks.\nHowever, existing benchmarks generally assess overall performance across entire\nvideo sequences, overlooking nuanced behaviors such as contextual positional\nbias, a critical yet under-explored aspect of LVLM performance. We present\nVideo-LevelGauge, a dedicated benchmark designed to systematically assess\npositional bias in LVLMs. We employ standardized probes and customized\ncontextual setups, allowing flexible control over context length, probe\nposition, and contextual types to simulate diverse real-world scenarios. In\naddition, we introduce a comprehensive analysis method that combines\nstatistical measures with morphological pattern recognition to characterize\nbias. Our benchmark comprises 438 manually curated videos spanning multiple\ntypes, yielding 1,177 high-quality multiple-choice questions and 120 open-ended\nquestions, validated for their effectiveness in exposing positional bias. Based\non these, we evaluate 27 state-of-the-art LVLMs, including both commercial and\nopen-source models. Our findings reveal significant positional biases in many\nleading open-source models, typically exhibiting head or neighbor-content\npreferences. In contrast, commercial models such as Gemini2.5-Pro show\nimpressive, consistent performance across entire video sequences. Further\nanalyses on context length, context variation, and model scale provide\nactionable insights for mitigating bias and guiding model enhancement.", "published": "2025-08-27 07:58:16", "link": "http://arxiv.org/abs/2508.19650v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "IDF: Iterative Dynamic Filtering Networks for Generalizable Image Denoising", "abstract": "Image denoising is a fundamental challenge in computer vision, with\napplications in photography and medical imaging. While deep learning-based\nmethods have shown remarkable success, their reliance on specific noise\ndistributions limits generalization to unseen noise types and levels. Existing\napproaches attempt to address this with extensive training data and high\ncomputational resources but they still suffer from overfitting. To address\nthese issues, we conduct image denoising by utilizing dynamically generated\nkernels via efficient operations. This approach helps prevent overfitting and\nimproves resilience to unseen noise. Specifically, our method leverages a\nFeature Extraction Module for robust noise-invariant features, Global\nStatistics and Local Correlation Modules to capture comprehensive noise\ncharacteristics and structural correlations. The Kernel Prediction Module then\nemploys these cues to produce pixel-wise varying kernels adapted to local\nstructures, which are then applied iteratively for denoising. This ensures both\nefficiency and superior restoration quality. Despite being trained on\nsingle-level Gaussian noise, our compact model (~ 0.04 M) excels across diverse\nnoise types and levels, demonstrating the promise of iterative dynamic\nfiltering for practical image denoising.", "published": "2025-08-27 07:58:07", "link": "http://arxiv.org/abs/2508.19649v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UTAL-GNN: Unsupervised Temporal Action Localization using Graph Neural Networks", "abstract": "Fine-grained action localization in untrimmed sports videos presents a\nsignificant challenge due to rapid and subtle motion transitions over short\ndurations. Existing supervised and weakly supervised solutions often rely on\nextensive annotated datasets and high-capacity models, making them\ncomputationally intensive and less adaptable to real-world scenarios. In this\nwork, we introduce a lightweight and unsupervised skeleton-based action\nlocalization pipeline that leverages spatio-temporal graph neural\nrepresentations. Our approach pre-trains an Attention-based Spatio-Temporal\nGraph Convolutional Network (ASTGCN) on a pose-sequence denoising task with\nblockwise partitions, enabling it to learn intrinsic motion dynamics without\nany manual labeling. At inference, we define a novel Action Dynamics Metric\n(ADM), computed directly from low-dimensional ASTGCN embeddings, which detects\nmotion boundaries by identifying inflection points in its curvature profile.\nOur method achieves a mean Average Precision (mAP) of 82.66% and average\nlocalization latency of 29.09 ms on the DSV Diving dataset, matching\nstate-of-the-art supervised performance while maintaining computational\nefficiency. Furthermore, it generalizes robustly to unseen, in-the-wild diving\nfootage without retraining, demonstrating its practical applicability for\nlightweight, real-time action analysis systems in embedded or dynamic\nenvironments.", "published": "2025-08-27 07:51:02", "link": "http://arxiv.org/abs/2508.19647v1", "categories": ["cs.CV", "I.2.10; I.5.4"], "primary_category": "cs.CV"}
{"title": "Controllable Skin Synthesis via Lesion-Focused Vector Autoregression Model", "abstract": "Skin images from real-world clinical practice are often limited, resulting in\na shortage of training data for deep-learning models. While many studies have\nexplored skin image synthesis, existing methods often generate low-quality\nimages and lack control over the lesion's location and type. To address these\nlimitations, we present LF-VAR, a model leveraging quantified lesion\nmeasurement scores and lesion type labels to guide the clinically relevant and\ncontrollable synthesis of skin images. It enables controlled skin synthesis\nwith specific lesion characteristics based on language prompts. We train a\nmultiscale lesion-focused Vector Quantised Variational Auto-Encoder (VQVAE) to\nencode images into discrete latent representations for structured tokenization.\nThen, a Visual AutoRegressive (VAR) Transformer trained on tokenized\nrepresentations facilitates image synthesis. Lesion measurement from the lesion\nregion and types as conditional embeddings are integrated to enhance synthesis\nfidelity. Our method achieves the best overall FID score (average 0.74) among\nseven lesion types, improving upon the previous state-of-the-art (SOTA) by\n6.3%. The study highlights our controllable skin synthesis model's\neffectiveness in generating high-fidelity, clinically relevant synthetic skin\nimages. Our framework code is available at\nhttps://github.com/echosun1996/LF-VAR.", "published": "2025-08-27 07:04:58", "link": "http://arxiv.org/abs/2508.19626v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Quantization Robustness to Input Degradations for Object Detection", "abstract": "Post-training quantization (PTQ) is crucial for deploying efficient object\ndetection models, like YOLO, on resource-constrained devices. However, the\nimpact of reduced precision on model robustness to real-world input\ndegradations such as noise, blur, and compression artifacts is a significant\nconcern. This paper presents a comprehensive empirical study evaluating the\nrobustness of YOLO models (nano to extra-large scales) across multiple\nprecision formats: FP32, FP16 (TensorRT), Dynamic UINT8 (ONNX), and Static INT8\n(TensorRT). We introduce and evaluate a degradation-aware calibration strategy\nfor Static INT8 PTQ, where the TensorRT calibration process is exposed to a mix\nof clean and synthetically degraded images. Models were benchmarked on the COCO\ndataset under seven distinct degradation conditions (including various types\nand levels of noise, blur, low contrast, and JPEG compression) and a\nmixed-degradation scenario. Results indicate that while Static INT8 TensorRT\nengines offer substantial speedups (~1.5-3.3x) with a moderate accuracy drop\n(~3-7% mAP50-95) on clean data, the proposed degradation-aware calibration did\nnot yield consistent, broad improvements in robustness over standard clean-data\ncalibration across most models and degradations. A notable exception was\nobserved for larger model scales under specific noise conditions, suggesting\nmodel capacity may influence the efficacy of this calibration approach. These\nfindings highlight the challenges in enhancing PTQ robustness and provide\ninsights for deploying quantized detectors in uncontrolled environments. All\ncode and evaluation tables are available at https://github.com/AllanK24/QRID.", "published": "2025-08-27 06:20:38", "link": "http://arxiv.org/abs/2508.19600v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generalizing Monocular 3D Object Detection", "abstract": "Monocular 3D object detection (Mono3D) is a fundamental computer vision task\nthat estimates an object's class, 3D position, dimensions, and orientation from\na single image. Its applications, including autonomous driving, augmented\nreality, and robotics, critically rely on accurate 3D environmental\nunderstanding. This thesis addresses the challenge of generalizing Mono3D\nmodels to diverse scenarios, including occlusions, datasets, object sizes, and\ncamera parameters. To enhance occlusion robustness, we propose a mathematically\ndifferentiable NMS (GrooMeD-NMS). To improve generalization to new datasets, we\nexplore depth equivariant (DEVIANT) backbones. We address the issue of large\nobject detection, demonstrating that it's not solely a data imbalance or\nreceptive field problem but also a noise sensitivity issue. To mitigate this,\nwe introduce a segmentation-based approach in bird's-eye view with dice loss\n(SeaBird). Finally, we mathematically analyze the extrapolation of Mono3D\nmodels to unseen camera heights and improve Mono3D generalization in such\nout-of-distribution settings.", "published": "2025-08-27 06:06:18", "link": "http://arxiv.org/abs/2508.19593v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Guiding Noisy Label Conditional Diffusion Models with Score-based Discriminator Correction", "abstract": "Diffusion models have gained prominence as state-of-the-art techniques for\nsynthesizing images and videos, particularly due to their ability to scale\neffectively with large datasets. Recent studies have uncovered that these\nextensive datasets often contain mistakes from manual labeling processes.\nHowever, the extent to which such errors compromise the generative capabilities\nand controllability of diffusion models is not well studied. This paper\nintroduces Score-based Discriminator Correction (SBDC), a guidance technique\nfor aligning noisy pre-trained conditional diffusion models. The guidance is\nbuilt on discriminator training using adversarial loss, drawing on prior noise\ndetection techniques to assess the authenticity of each sample. We further show\nthat limiting the usage of our guidance to the early phase of the generation\nprocess leads to better performance. Our method is computationally efficient,\nonly marginally increases inference time, and does not require retraining\ndiffusion models. Experiments on different noise settings demonstrate the\nsuperiority of our method over previous state-of-the-art methods.", "published": "2025-08-27 05:29:07", "link": "http://arxiv.org/abs/2508.19581v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "High-Speed FHD Full-Color Video Computer-Generated Holography", "abstract": "Computer-generated holography (CGH) is a promising technology for\nnext-generation displays. However, generating high-speed, high-quality\nholographic video requires both high frame rate display and efficient\ncomputation, but is constrained by two key limitations: ($i$) Learning-based\nmodels often produce over-smoothed phases with narrow angular spectra, causing\nsevere color crosstalk in high frame rate full-color displays such as\ndepth-division multiplexing and thus resulting in a trade-off between frame\nrate and color fidelity. ($ii$) Existing frame-by-frame optimization methods\ntypically optimize frames independently, neglecting spatial-temporal\ncorrelations between consecutive frames and leading to computationally\ninefficient solutions. To overcome these challenges, in this paper, we propose\na novel high-speed full-color video CGH generation scheme. First, we introduce\nSpectrum-Guided Depth Division Multiplexing (SGDDM), which optimizes phase\ndistributions via frequency modulation, enabling high-fidelity full-color\ndisplay at high frame rates. Second, we present HoloMamba, a lightweight\nasymmetric Mamba-Unet architecture that explicitly models spatial-temporal\ncorrelations across video sequences to enhance reconstruction quality and\ncomputational efficiency. Extensive simulated and real-world experiments\ndemonstrate that SGDDM achieves high-fidelity full-color display without\ncompromise in frame rate, while HoloMamba generates FHD (1080p) full-color\nholographic video at over 260 FPS, more than 2.6$\\times$ faster than the prior\nstate-of-the-art Divide-Conquer-and-Merge Strategy.", "published": "2025-08-27 05:24:37", "link": "http://arxiv.org/abs/2508.19579v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DNP-Guided Contrastive Reconstruction with a Reverse Distillation Transformer for Medical Anomaly Detection", "abstract": "Anomaly detection in medical images is challenging due to limited annotations\nand a domain gap compared to natural images. Existing reconstruction methods\noften rely on frozen pre-trained encoders, which limits adaptation to\ndomain-specific features and reduces localization accuracy. Prototype-based\nlearning offers interpretability and clustering benefits but suffers from\nprototype collapse, where few prototypes dominate training, harming diversity\nand generalization. To address this, we propose a unified framework combining a\ntrainable encoder with prototype-guided reconstruction and a novel\nDiversity-Aware Alignment Loss. The trainable encoder, enhanced by a momentum\nbranch, enables stable domain-adaptive feature learning. A lightweight\nPrototype Extractor mines informative normal prototypes to guide the decoder\nvia attention for precise reconstruction. Our loss enforces balanced prototype\nuse through diversity constraints and per-prototype normalization, effectively\npreventing collapse. Experiments on multiple medical imaging benchmarks show\nsignificant improvements in representation quality and anomaly localization,\noutperforming prior methods. Visualizations and prototype assignment analyses\nfurther validate the effectiveness of our anti-collapse mechanism and enhanced\ninterpretability.", "published": "2025-08-27 05:12:09", "link": "http://arxiv.org/abs/2508.19573v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MonoRelief V2: Leveraging Real Data for High-Fidelity Monocular Relief Recovery", "abstract": "This paper presents MonoRelief V2, an end-to-end model designed for directly\nrecovering 2.5D reliefs from single images under complex material and\nillumination variations. In contrast to its predecessor, MonoRelief V1 [1],\nwhich was solely trained on synthetic data, MonoRelief V2 incorporates real\ndata to achieve improved robustness, accuracy and efficiency. To overcome the\nchallenge of acquiring large-scale real-world dataset, we generate\napproximately 15,000 pseudo real images using a text-to-image generative model,\nand derive corresponding depth pseudo-labels through fusion of depth and normal\npredictions. Furthermore, we construct a small-scale real-world dataset (800\nsamples) via multi-view reconstruction and detail refinement. MonoRelief V2 is\nthen progressively trained on the pseudo-real and real-world datasets.\nComprehensive experiments demonstrate its state-of-the-art performance both in\ndepth and normal predictions, highlighting its strong potential for a range of\ndownstream applications. Code is at: https://github.com/glp1001/MonoreliefV2.", "published": "2025-08-27 04:03:03", "link": "http://arxiv.org/abs/2508.19555v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CVBench: Evaluating Cross-Video Synergies for Complex Multimodal Understanding and Reasoning", "abstract": "While multimodal large language models (MLLMs) exhibit strong performance on\nsingle-video tasks (e.g., video question answering), their ability across\nmultiple videos remains critically underexplored. However, this capability is\nessential for real-world applications, including multi-camera surveillance and\ncross-video procedural learning. To bridge this gap, we present CVBench, the\nfirst comprehensive benchmark designed to assess cross-video relational\nreasoning rigorously. CVBench comprises 1,000 question-answer pairs spanning\nthree hierarchical tiers: cross-video object association (identifying shared\nentities), cross-video event association (linking temporal or causal event\nchains), and cross-video complex reasoning (integrating commonsense and domain\nknowledge). Built from five domain-diverse video clusters (e.g., sports, life\nrecords), the benchmark challenges models to synthesise information across\ndynamic visual contexts. Extensive evaluation of 10+ leading MLLMs (including\nGPT-4o, Gemini-2.0-flash, Qwen2.5-VL) under zero-shot or chain-of-thought\nprompting paradigms. Key findings reveal stark performance gaps: even top\nmodels, such as GPT-4o, achieve only 60% accuracy on causal reasoning tasks,\ncompared to the 91% accuracy of human performance. Crucially, our analysis\nreveals fundamental bottlenecks inherent in current MLLM architectures, notably\ndeficient inter-video context retention and poor disambiguation of overlapping\nentities. CVBench establishes a rigorous framework for diagnosing and advancing\nmulti-video reasoning, offering architectural insights for next-generation\nMLLMs.The data and evaluation code are available at\nhttps://github.com/Hokhim2/CVBench.", "published": "2025-08-27 03:29:35", "link": "http://arxiv.org/abs/2508.19542v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment", "abstract": "Motion generation is essential for animating virtual characters and embodied\nagents. While recent text-driven methods have made significant strides, they\noften struggle with achieving precise alignment between linguistic descriptions\nand motion semantics, as well as with the inefficiencies of slow, multi-step\ninference. To address these issues, we introduce TMR++ Aligned Preference\nOptimization (TAPO), an innovative framework that aligns subtle motion\nvariations with textual modifiers and incorporates iterative adjustments to\nreinforce semantic grounding. To further enable real-time synthesis, we propose\nMotionFLUX, a high-speed generation framework based on deterministic rectified\nflow matching. Unlike traditional diffusion models, which require hundreds of\ndenoising steps, MotionFLUX constructs optimal transport paths between noise\ndistributions and motion spaces, facilitating real-time synthesis. The\nlinearized probability paths reduce the need for multi-step sampling typical of\nsequential methods, significantly accelerating inference time without\nsacrificing motion quality. Experimental results demonstrate that, together,\nTAPO and MotionFLUX form a unified system that outperforms state-of-the-art\napproaches in both semantic consistency and motion quality, while also\naccelerating generation speed. The code and pretrained models will be released.", "published": "2025-08-27 02:45:09", "link": "http://arxiv.org/abs/2508.19527v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fast Texture Transfer for XR Avatars via Barycentric UV Conversion", "abstract": "We present a fast and efficient method for transferring facial textures onto\nSMPL-X-based full-body avatars. Unlike conventional affine-transform methods\nthat are slow and prone to visual artifacts, our method utilizes a barycentric\nUV conversion technique. Our approach precomputes the entire UV mapping into a\nsingle transformation matrix, enabling texture transfer in a single operation.\nThis results in a speedup of over 7000x compared to the baseline, while also\nsignificantly improving the final texture quality by eliminating boundary\nartifacts. Through quantitative and qualitative evaluations, we demonstrate\nthat our method offers a practical solution for personalization in immersive XR\napplications. The code is available online.", "published": "2025-08-27 02:14:18", "link": "http://arxiv.org/abs/2508.19518v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Weed Detection in Challenging Field Conditions: A Semi-Supervised Framework for Overcoming Shadow Bias and Data Scarcity", "abstract": "The automated management of invasive weeds is critical for sustainable\nagriculture, yet the performance of deep learning models in real-world fields\nis often compromised by two factors: challenging environmental conditions and\nthe high cost of data annotation. This study tackles both issues through a\ndiagnostic-driven, semi-supervised framework. Using a unique dataset of\napproximately 975 labeled and 10,000 unlabeled images of Guinea Grass in\nsugarcane, we first establish strong supervised baselines for classification\n(ResNet) and detection (YOLO, RF-DETR), achieving F1 scores up to 0.90 and\nmAP50 scores exceeding 0.82. Crucially, this foundational analysis, aided by\ninterpretability tools, uncovered a pervasive \"shadow bias,\" where models\nlearned to misidentify shadows as vegetation. This diagnostic insight motivated\nour primary contribution: a semi-supervised pipeline that leverages unlabeled\ndata to enhance model robustness. By training models on a more diverse set of\nvisual information through pseudo-labeling, this framework not only helps\nmitigate the shadow bias but also provides a tangible boost in recall, a\ncritical metric for minimizing weed escapes in automated spraying systems. To\nvalidate our methodology, we demonstrate its effectiveness in a low-data regime\non a public crop-weed benchmark. Our work provides a clear and field-tested\nframework for developing, diagnosing, and improving robust computer vision\nsystems for the complex realities of precision agriculture.", "published": "2025-08-27 01:55:47", "link": "http://arxiv.org/abs/2508.19511v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DATR: Diffusion-based 3D Apple Tree Reconstruction Framework with Sparse-View", "abstract": "Digital twin applications offered transformative potential by enabling\nreal-time monitoring and robotic simulation through accurate virtual replicas\nof physical assets. The key to these systems is 3D reconstruction with high\ngeometrical fidelity. However, existing methods struggled under field\nconditions, especially with sparse and occluded views. This study developed a\ntwo-stage framework (DATR) for the reconstruction of apple trees from sparse\nviews. The first stage leverages onboard sensors and foundation models to\nsemi-automatically generate tree masks from complex field images. Tree masks\nare used to filter out background information in multi-modal data for the\nsingle-image-to-3D reconstruction at the second stage. This stage consists of a\ndiffusion model and a large reconstruction model for respective multi view and\nimplicit neural field generation. The training of the diffusion model and LRM\nwas achieved by using realistic synthetic apple trees generated by a Real2Sim\ndata generator. The framework was evaluated on both field and synthetic\ndatasets. The field dataset includes six apple trees with field-measured ground\ntruth, while the synthetic dataset featured structurally diverse trees.\nEvaluation results showed that our DATR framework outperformed existing 3D\nreconstruction methods across both datasets and achieved domain-trait\nestimation comparable to industrial-grade stationary laser scanners while\nimproving the throughput by $\\sim$360 times, demonstrating strong potential for\nscalable agricultural digital twin systems.", "published": "2025-08-27 01:45:54", "link": "http://arxiv.org/abs/2508.19508v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "UNIFORM: Unifying Knowledge from Large-scale and Diverse Pre-trained Models", "abstract": "In the era of deep learning, the increasing number of pre-trained models\navailable online presents a wealth of knowledge. These models, developed with\ndiverse architectures and trained on varied datasets for different tasks,\nprovide unique interpretations of the real world. Their collective consensus is\nlikely universal and generalizable to unseen data. However, effectively\nharnessing this collective knowledge poses a fundamental challenge due to the\nheterogeneity of pre-trained models. Existing knowledge integration solutions\ntypically rely on strong assumptions about training data distributions and\nnetwork architectures, limiting them to learning only from specific types of\nmodels and resulting in data and/or inductive biases. In this work, we\nintroduce a novel framework, namely UNIFORM, for knowledge transfer from a\ndiverse set of off-the-shelf models into one student model without such\nconstraints. Specifically, we propose a dedicated voting mechanism to capture\nthe consensus of knowledge both at the logit level -- incorporating teacher\nmodels that are capable of predicting target classes of interest -- and at the\nfeature level, utilizing visual representations learned on arbitrary label\nspaces. Extensive experiments demonstrate that UNIFORM effectively enhances\nunsupervised object recognition performance compared to strong knowledge\ntransfer baselines. Notably, it exhibits remarkable scalability by benefiting\nfrom over one hundred teachers, while existing methods saturate at a much\nsmaller scale.", "published": "2025-08-27 00:56:11", "link": "http://arxiv.org/abs/2508.19498v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents", "abstract": "Smartphones bring significant convenience to users but also enable devices to\nextensively record various types of personal information. Existing smartphone\nagents powered by Multimodal Large Language Models (MLLMs) have achieved\nremarkable performance in automating different tasks. However, as the cost,\nthese agents are granted substantial access to sensitive users' personal\ninformation during this operation. To gain a thorough understanding of the\nprivacy awareness of these agents, we present the first large-scale benchmark\nencompassing 7,138 scenarios to the best of our knowledge. In addition, for\nprivacy context in scenarios, we annotate its type (e.g., Account Credentials),\nsensitivity level, and location. We then carefully benchmark seven available\nmainstream smartphone agents. Our results demonstrate that almost all\nbenchmarked agents show unsatisfying privacy awareness (RA), with performance\nremaining below 60% even with explicit hints. Overall, closed-source agents\nshow better privacy ability than open-source ones, and Gemini 2.0-flash\nachieves the best, achieving an RA of 67%. We also find that the agents'\nprivacy detection capability is highly related to scenario sensitivity level,\ni.e., the scenario with a higher sensitivity level is typically more\nidentifiable. We hope the findings enlighten the research community to rethink\nthe unbalanced utility-privacy tradeoff about smartphone agents. Our code and\nbenchmark are available at https://zhixin-l.github.io/SAPA-Bench.", "published": "2025-08-27 00:41:28", "link": "http://arxiv.org/abs/2508.19493v1", "categories": ["cs.CR", "cs.CV"], "primary_category": "cs.CR"}
{"title": "JVLGS: Joint Vision-Language Gas Leak Segmentation", "abstract": "Gas leaks pose serious threats to human health and contribute significantly\nto atmospheric pollution, drawing increasing public concern. However, the lack\nof effective detection methods hampers timely and accurate identification of\ngas leaks. While some vision-based techniques leverage infrared videos for leak\ndetection, the blurry and non-rigid nature of gas clouds often limits their\neffectiveness. To address these challenges, we propose a novel framework called\nJoint Vision-Language Gas leak Segmentation (JVLGS), which integrates the\ncomplementary strengths of visual and textual modalities to enhance gas leak\nrepresentation and segmentation. Recognizing that gas leaks are sporadic and\nmany video frames may contain no leak at all, our method incorporates a\npost-processing step to reduce false positives caused by noise and non-target\nobjects, an issue that affects many existing approaches. Extensive experiments\nconducted across diverse scenarios show that JVLGS significantly outperforms\nstate-of-the-art gas leak segmentation methods. We evaluate our model under\nboth supervised and few-shot learning settings, and it consistently achieves\nstrong performance in both, whereas competing methods tend to perform well in\nonly one setting or poorly in both. Code available at:\nhttps://github.com/GeekEagle/JVLGS", "published": "2025-08-27 00:10:43", "link": "http://arxiv.org/abs/2508.19485v1", "categories": ["cs.CV", "68T45 (Primary), 68T07 (Secondary)", "I.2.10; I.4.6"], "primary_category": "cs.CV"}
{"title": "Growth Forms of Tilings", "abstract": "The growth form (or corona limit) of a tiling is the limit form of its\ncoordination shells, i.e. its set of tiles located at a fixed distance from\nsome tile. We give an overview of current results, conjectures and open\nquestions about growth forms, including periodic, multigrid, substitution, and\nhat tilings.", "published": "2025-08-27 14:38:43", "link": "http://arxiv.org/abs/2508.19928v1", "categories": ["math.CO", "cs.DM", "52C20 52C23"], "primary_category": "math.CO"}
{"title": "Internally-Convex Drawings of Outerplanar Graphs in Small Area", "abstract": "A well-known result by Kant [Algorithmica, 1996] implies that n-vertex\nouterplane graphs admit embedding-preserving planar straight-line grid drawings\nwhere the internal faces are convex polygons in $O(n^2)$ area. In this paper,\nwe present an algorithm to compute such drawings in $O(n^{1.5})$ area. We also\nconsider outerplanar drawings in which the internal faces are required to be\nstrictly-convex polygons. In this setting, we consider outerplanar graphs whose\nweak dual is a path and give a drawing algorithm that achieves $\\Theta(nk^2)$\narea, where $k$ is the maximum size of an internal facial cycle.", "published": "2025-08-27 14:19:24", "link": "http://arxiv.org/abs/2508.19913v1", "categories": ["cs.CG", "cs.DM", "cs.DS"], "primary_category": "cs.CG"}
{"title": "An algorithm for accurate and simple-looking metaphorical maps", "abstract": "\"Metaphorical maps\" or \"contact representations\" are visual representations\nof vertex-weighted graphs that rely on the geographic map metaphor. The\nvertices are represented by countries, the weights by the areas of the\ncountries, and the edges by contacts/ boundaries among them. The accuracy with\nwhich the weights are mapped to areas and the simplicity of the polygons\nrepresenting the countries are the two classical optimization goals for\nmetaphorical maps. Mchedlidze and Schnorr [Metaphoric Maps for Dynamic\nVertex-weighted Graphs, EuroVis 2022] presented a force-based algorithm that\ncreates metaphorical maps that balance between these two optimization goals.\nTheir maps look visually simple, but the accuracy of the maps is far from\noptimal - the countries' areas can vary up to 30% compared to required. In this\npaper, we provide a multi-fold extension of the algorithm in [Metaphoric Maps\nfor Dynamic Vertex-weighted Graphs, EuroVis 2022]. More specifically:\n  1. Towards improving accuracy: We introduce the notion of region stiffness\nand suggest a technique for varying the stiffness based on the current pressure\nof map regions.\n  2. Towards maintaining simplicity: We introduce a weight coefficient to the\npressure force exerted on each polygon point based on whether the corresponding\npoint appears along a narrow passage.\n  3. Towards generality: We cover, in contrast to [Metaphoric Maps for Dynamic\nVertex-weighted Graphs, EuroVis 2022], non-triangulated graphs. This is done by\neither generating points where more than three regions meet or by introducing\nholes in the metaphorical map.\n  We perform an extended experimental evaluation that, among other results,\nreveals that our algorithm is able to construct metaphorical maps with nearly\nperfect area accuracy with a little sacrifice in their simplicity.", "published": "2025-08-27 11:53:01", "link": "http://arxiv.org/abs/2508.19810v1", "categories": ["cs.DM", "cs.CG", "cs.DS"], "primary_category": "cs.DM"}
{"title": "Fractional domatic number and minimum degree", "abstract": "The domatic number of a graph $G$ is the maximum number of pairwise disjoint\ndominating sets of $G$. We are interested in the LP-relaxation of this\nparameter, which is called the fractional domatic number of $G$. We study its\nextremal value in the class of graphs of minimum degree $d$. The fractional\ndomatic number of a graph of minimum degree $d$ is always at most $d+1$, and at\nleast $(1-o(1))\\, d/\\ln d$ as $d\\to \\infty$. This is asymptotically tight even\nwithin the class of split graphs. Our main result concerns the case $d=2$; we\nshow that, excluding $8$ exceptional graphs, the fractional domatic number of\nevery connected graph of minimum degree (at least) $2$ is at least $5/2$. We\nalso show that this bound cannot be improved if only finitely many graphs are\nexcluded, even when restricting to bipartite graphs of girth at least $6$. This\nproves in a stronger sense a conjecture by Gadouleau, Harms, Mertzios, and\nZamaraev (2024). This also extends and generalises results from McCuaig and\nShepherd (1989), from Fujita, Kameda, and Yamashita (2000), and from Abbas,\nEgerstedt, Liu, Thomas, and Whalen (2016). Finally, we show that planar graphs\nof minimum degree at least $2$ and girth at least $g$ have fractional domatic\nnumber at least $3 - O(1/g)$ as $g\\to\\infty$.", "published": "2025-08-27 06:50:47", "link": "http://arxiv.org/abs/2508.19617v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Refining Text Generation for Realistic Conversational Recommendation via Direct Preference Optimization", "abstract": "Conversational Recommender Systems (CRSs) aim to elicit user preferences via\nnatural dialogue to provide suitable item recommendations. However, current\nCRSs often deviate from realistic human interactions by rapidly recommending\nitems in brief sessions. This work addresses this gap by leveraging Large\nLanguage Models (LLMs) to generate dialogue summaries from dialogue history and\nitem recommendation information from item description. This approach enables\nthe extraction of both explicit user statements and implicit preferences\ninferred from the dialogue context. We introduce a method using Direct\nPreference Optimization (DPO) to ensure dialogue summary and item\nrecommendation information are rich in information crucial for effective\nrecommendations. Experiments on two public datasets validate our method's\neffectiveness in fostering more natural and realistic conversational\nrecommendation processes.Our implementation is publicly available\nat:https://github.com/UEC-InabaLab/Refining-LLM-Text", "published": "2025-08-27 14:24:13", "link": "http://arxiv.org/abs/2508.19918v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Youtu-GraphRAG: Vertically Unified Agents for Graph Retrieval-Augmented Complex Reasoning", "abstract": "Graph retrieval-augmented generation (GraphRAG) has effectively enhanced\nlarge language models in complex reasoning by organizing fragmented knowledge\ninto explicitly structured graphs. Prior efforts have been made to improve\neither graph construction or graph retrieval in isolation, yielding suboptimal\nperformance, especially when domain shifts occur. In this paper, we propose a\nvertically unified agentic paradigm, Youtu-GraphRAG, to jointly connect the\nentire framework as an intricate integration. Specifically, (i) a seed graph\nschema is introduced to bound the automatic extraction agent with targeted\nentity types, relations and attribute types, also continuously expanded for\nscalability over unseen domains; (ii) To obtain higher-level knowledge upon the\nschema, we develop novel dually-perceived community detection, fusing\nstructural topology with subgraph semantics for comprehensive knowledge\norganization. This naturally yields a hierarchical knowledge tree that supports\nboth top-down filtering and bottom-up reasoning with community summaries; (iii)\nAn agentic retriever is designed to interpret the same graph schema to\ntransform complex queries into tractable and parallel sub-queries. It\niteratively performs reflection for more advanced reasoning; (iv) To alleviate\nthe knowledge leaking problem in pre-trained LLM, we propose a tailored\nanonymous dataset and a novel 'Anonymity Reversion' task that deeply measures\nthe real performance of the GraphRAG frameworks. Extensive experiments across\nsix challenging benchmarks demonstrate the robustness of Youtu-GraphRAG,\nremarkably moving the Pareto frontier with up to 90.71% saving of token costs\nand 16.62% higher accuracy over state-of-the-art baselines. The results\nindicate our adaptability, allowing seamless domain transfer with minimal\nintervention on schema.", "published": "2025-08-27 13:13:20", "link": "http://arxiv.org/abs/2508.19855v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Model-agnostic Strategy to Mitigate Embedding Degradation in Personalized Federated Recommendation", "abstract": "Centralized recommender systems encounter privacy leakage due to the need to\ncollect user behavior and other private data. Hence, federated recommender\nsystems (FedRec) have become a promising approach with an aggregated global\nmodel on the server. However, this distributed training paradigm suffers from\nembedding degradation caused by suboptimal personalization and dimensional\ncollapse, due to the existence of sparse interactions and heterogeneous\npreferences. To this end, we propose a novel model-agnostic strategy for FedRec\nto strengthen the personalized embedding utility, which is called Personalized\nLocal-Global Collaboration (PLGC). It is the first research in federated\nrecommendation to alleviate the dimensional collapse issue. Particularly, we\nincorporate the frozen global item embedding table into local devices. Based on\na Neural Tangent Kernel strategy that dynamically balances local and global\ninformation, PLGC optimizes personalized representations during forward\ninference, ultimately converging to user-specific preferences. Additionally,\nPLGC carries on a contrastive objective function to reduce embedding redundancy\nby dissolving dependencies between dimensions, thereby improving the backward\nrepresentation learning process. We introduce PLGC as a model-agnostic\npersonalized training strategy for federated recommendations that can be\napplied to existing baselines to alleviate embedding degradation. Extensive\nexperiments on five real-world datasets have demonstrated the effectiveness and\nadaptability of PLGC, which outperforms various baseline algorithms.", "published": "2025-08-27 06:03:52", "link": "http://arxiv.org/abs/2508.19591v1", "categories": ["cs.IR", "cs.DC"], "primary_category": "cs.IR"}
{"title": "Improving Recommendation Fairness via Graph Structure and Representation Augmentation", "abstract": "Graph Convolutional Networks (GCNs) have become increasingly popular in\nrecommendation systems. However, recent studies have shown that GCN-based\nmodels will cause sensitive information to disseminate widely in the graph\nstructure, amplifying data bias and raising fairness concerns. While various\nfairness methods have been proposed, most of them neglect the impact of biased\ndata on representation learning, which results in limited fairness improvement.\nMoreover, some studies have focused on constructing fair and balanced data\ndistributions through data augmentation, but these methods significantly reduce\nutility due to disruption of user preferences. In this paper, we aim to design\na fair recommendation method from the perspective of data augmentation to\nimprove fairness while preserving recommendation utility. To achieve\nfairness-aware data augmentation with minimal disruption to user preferences,\nwe propose two prior hypotheses. The first hypothesis identifies sensitive\ninteractions by comparing outcomes of performance-oriented and fairness-aware\nrecommendations, while the second one focuses on detecting sensitive features\nby analyzing feature similarities between biased and debiased representations.\nThen, we propose a dual data augmentation framework for fair recommendation,\nwhich includes two data augmentation strategies to generate fair augmented\ngraphs and feature representations. Furthermore, we introduce a debiasing\nlearning method that minimizes the dependence between the learned\nrepresentations and sensitive information to eliminate bias. Extensive\nexperiments on two real-world datasets demonstrate the superiority of our\nproposed framework.", "published": "2025-08-27 03:41:01", "link": "http://arxiv.org/abs/2508.19547v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Hybrid Recommendation Framework for Enhancing User Engagement in Local News", "abstract": "Local news organizations face an urgent need to boost reader engagement amid\ndeclining circulation and competition from global media. Personalized news\nrecommender systems offer a promising solution by tailoring content to user\ninterests. Yet, conventional approaches often emphasize general preferences and\nmay overlook nuanced or eclectic interests in local news.\n  We propose a hybrid news recommender that integrates local and global\npreference models to improve engagement. Building on evidence of the value of\nlocalized models, our method unifies local and non-local predictors in one\nframework. The system adaptively combines recommendations from a local model,\nspecialized in region-specific content, and a global model that captures\nbroader preferences. Ensemble strategies and multiphase training balance the\ntwo.\n  We evaluated the model on two datasets: a synthetic set based on Syracuse\nnewspaper distributions and a Danish dataset (EB-NeRD) labeled for local and\nnon-local content with an LLM. Results show our integrated approach outperforms\nsingle-model baselines in accuracy and coverage, suggesting improved\npersonalization that can drive user engagement.\n  The findings have practical implications for publishers, especially local\noutlets. By leveraging both community-specific and general user interests, the\nhybrid recommender can deliver more relevant content, increasing retention and\nsubscriptions. In sum, this work introduces a new direction for recommender\nsystems, bridging local and global models to revitalize local news consumption\nthrough scalable, personalized user experiences.", "published": "2025-08-27 03:27:20", "link": "http://arxiv.org/abs/2508.19539v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "On the Outage Probability of Multiuser Multiple Antenna Systems with Non-Orthogonal Multiple Access for Air-Ground Communications", "abstract": "This paper explores multiuser multiple antenna systems as a means to enhance\nthe spectral efficiency of aeronautical communications systems. To this end,\nthe outage regime for a multiuser multiple antenna system is studied within a\nrealistic geometry-based stochastic air-ground (AG) channel model. In this\napplication, users (aircraft) transmit air traffic management data to the\nground station at a predefined target rate. Due to the nature of the AG\npropagation, we argue that the relevant performance metric in this context is\nthe information outage probability. We consider the outage probability under\nthree decoding approaches. The first is based on successive interference\ncancellation (SIC). The second extends the first approach by considering joint\ngroup decoding. The third is a version of the second that limits the size of\nthe jointly decoded user groups in order to lower the decoding complexity. The\nresults show that joint group decoding, even in groups of only two, can\nsignificantly increase the spectral efficiency in the AG channel by allowing a\nlarge number of aircraft to transmit over a non-orthogonal channel with very\nlow outage probabilities.", "published": "2025-08-27 16:07:14", "link": "http://arxiv.org/abs/2508.20003v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Global Permutation Entropy", "abstract": "Permutation Entropy, introduced by Bandt and Pompe, is a widely used\ncomplexity measure for real-valued time series that is based on the relative\norder of values within consecutive segments of fixed length. After\nstandardizing each segment to a permutation and computing the frequency\ndistribution of these permutations, Shannon Entropy is then applied to quantify\nthe series' complexity. We introduce Global Permutation Entropy (GPE), a novel\nindex that considers all possible patterns of a given length, including\nnon-consecutive ones. Its computation relies on recently developed algorithms\nthat enable the efficient extraction of full permutation profiles. We\nillustrate some properties of GPE and demonstrate its effectiveness through\nexperiments on synthetic datasets, showing that it reveals structural\ninformation not accessible through standard permutation entropy. We provide a\nJulia package for the calculation of GPE at\n`https://github.com/AThreeH1/Global-Permutation-Entropy'.", "published": "2025-08-27 15:08:12", "link": "http://arxiv.org/abs/2508.19955v1", "categories": ["cs.LG", "cs.IT", "math.IT", "62M10 (primary), 94A17 (secondary)"], "primary_category": "cs.LG"}
{"title": "Renyi partial orders for BISO channels", "abstract": "A fundamental question in information theory is to quantify the loss of\ninformation under a noisy channel. Partial orders are typical tools to that\nend, however, they are often also challenging to evaluate. For the special\nclass of binary input symmetric output (BISO) channels, Geng et al. showed that\namong channels with the same capacity, the binary symmetric channel (BSC) and\nbinary erasure channel (BEC) are extremal with respect to the more capable\norder. Here we extend on this result by considering partial orders based on\nRenyi mutual information. We establish the extremality of the BSC and BEC in\nthis setting with respect to the generalized Renyi capacity. In the process, we\nalso generalize the needed tools and introduce $\\alpha$-Lorenz curves.", "published": "2025-08-27 15:04:49", "link": "http://arxiv.org/abs/2508.19951v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Design and Analysis of the Tail Sequence for Short LDPC-Coded Space Communications", "abstract": "According to some standards for satellite communications, the transmitted\nstream is divided into transmission units with variable length, for which\ndetecting the termination is particularly relevant. This is the case of space\nTeleCommands (TCs), where coded data are usually preceded by a start sequence,\nand optionally followed by a tail sequence, forming the Communication Link\nTransmission Unit (CLTU). Regarding the choice of schemes for error correction,\nthe Consultative Committee for Space Data Systems recommendations for TC\nsynchronization and coding suggests to use, among others, two Low-Density\nParity-Check (LDPC) codes: one (relatively) long and one short. Adopting the\nlong LDPC code eliminates the need for a tail sequence, as the LDPC decoder\nalways fails when overrunning the end of the CLTU, thus causing the decoding\nand detection process to stop. This, however, is not true when the short LDPC\ncode is adopted, since its decoding might converge on a codeword even when the\ndecoder input is not a noisy codeword. This makes it necessary to use a tail\nsequence that causes the decoder to fail regardless of its input. In this\npaper, we study the features required for such a sequence and propose some\nmethods for its design. Our numerical results, obtained considering various\ndetection approaches for the tail sequence, show that the overall TC rejection\nprobability improves significantly when the proposed tail sequence is employed.\nOur simulations also show that, for moderate values of the Signal-to-Noise\nRatio (SNR), with a properly designed tail sequence it is possible to obtain\nthe same performance in terms of TC rejection probability using decoder-based\ndetection and likelihood ratio test-based detection, with the former approach\nbeing less complex than the latter.", "published": "2025-08-27 13:23:46", "link": "http://arxiv.org/abs/2508.19858v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Efficient Probabilistic Parity Shaping for Irregular Repeat-Accumulate LDPC Codes", "abstract": "Algorithms are presented that efficiently shape the parity bits of systematic\nirregular repeat-accumulate (IRA) low-density parity-check (LDPC) codes by\nfollowing the sequential encoding order of the accumulator. Simulations over\nadditive white Gaussian noise (AWGN) channels with on-off keying show a gain of\nup to 0.9 dB over uniform signaling.", "published": "2025-08-27 09:05:36", "link": "http://arxiv.org/abs/2508.19696v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "$\\mathcal{C}^1$-approximation with rational functions and rational neural networks", "abstract": "We show that suitably regular functions can be approximated in the\n$\\mathcal{C}^1$-norm both with rational functions and rational neural networks,\nincluding approximation rates with respect to width and depth of the network,\nand degree of the rational functions. As consequence of our results, we further\nobtain $\\mathcal{C}^1$-approximation results for rational neural networks with\nthe $\\text{EQL}^\\div$ and ParFam architecture, both of which are important in\nparticular in the context of symbolic regression for physical law learning.", "published": "2025-08-27 08:31:25", "link": "http://arxiv.org/abs/2508.19672v1", "categories": ["cs.LG", "cs.IT", "cs.NA", "math.IT", "math.NA", "33F05, 41A20, 41A25, 26C15"], "primary_category": "cs.LG"}
{"title": "Subadditivity of the log-Sobolev constant on convolutions", "abstract": "We present a general subadditivity inequality for log-Sobolev constants of\nconvolution measures. As a corollary, we show that the log-Sobolev constant is\nmonotone along the sequence of standardized convolutions in the central limit\ntheorem.", "published": "2025-08-27 07:53:34", "link": "http://arxiv.org/abs/2508.19648v1", "categories": ["math.FA", "cs.IT", "math.IT", "math.PR"], "primary_category": "math.FA"}
{"title": "Anomaly Detection in Networked Bandits", "abstract": "The nodes' interconnections on a social network often reflect their\ndependencies and information-sharing behaviors. Nevertheless, abnormal nodes,\nwhich significantly deviate from most of the network concerning patterns or\nbehaviors, can lead to grave consequences. Therefore, it is imperative to\ndesign efficient online learning algorithms that robustly learn users'\npreferences while simultaneously detecting anomalies.\n  We introduce a novel bandit algorithm to address this problem. Through\nnetwork knowledge, the method characterizes the users' preferences and\nresiduals of feature information. By learning and analyzing these preferences\nand residuals, it develops a personalized recommendation strategy for each user\nand simultaneously detects anomalies. We rigorously prove an upper bound on the\nregret of the proposed algorithm and experimentally compare it with several\nstate-of-the-art collaborative contextual bandit algorithms on both synthetic\nand real-world datasets.", "published": "2025-08-27 17:41:40", "link": "http://arxiv.org/abs/2508.20076v1", "categories": ["cs.MA", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Reinforcement Learning for Search Tree Size Minimization in Constraint Programming: New Results on Scheduling Benchmarks", "abstract": "Failure-Directed Search (FDS) is a significant complete generic search\nalgorithm used in Constraint Programming (CP) to efficiently explore the search\nspace, proven particularly effective on scheduling problems. This paper\nanalyzes FDS's properties, showing that minimizing the size of its search tree\nguided by ranked branching decisions is closely related to the Multi-armed\nbandit (MAB) problem. Building on this insight, MAB reinforcement learning\nalgorithms are applied to FDS, extended with problem-specific refinements and\nparameter tuning, and evaluated on the two most fundamental scheduling\nproblems, the Job Shop Scheduling Problem (JSSP) and Resource-Constrained\nProject Scheduling Problem (RCPSP). The resulting enhanced FDS, using the best\nextended MAB algorithm and configuration, performs 1.7 times faster on the JSSP\nand 2.1 times faster on the RCPSP benchmarks compared to the original\nimplementation in a new solver called OptalCP, while also being 3.5 times\nfaster on the JSSP and 2.1 times faster on the RCPSP benchmarks than the\ncurrent state-of-the-art FDS algorithm in IBM CP Optimizer 22.1. Furthermore,\nusing only a 900-second time limit per instance, the enhanced FDS improved the\nexisting state-of-the-art lower bounds of 78 of 84 JSSP and 226 of 393 RCPSP\nstandard open benchmark instances while also completely closing a few of them.", "published": "2025-08-27 17:13:18", "link": "http://arxiv.org/abs/2508.20056v1", "categories": ["cs.LG", "90-08, 90B35, 90C59, 90C99, 68T20, 90C27"], "primary_category": "cs.LG"}
{"title": "Using item recommendations and LLMs in marketing email titles", "abstract": "E-commerce marketplaces make use of a number of marketing channels like\nemails, push notifications, etc. to reach their users and stimulate purchases.\nPersonalized emails especially are a popular touch point for marketers to\ninform users of latest items in stock, especially for those who stopped\nvisiting the marketplace. Such emails contain personalized recommendations\ntailored to each user's interests, enticing users to buy relevant items. A\ncommon limitation of these emails is that the primary entry point, the title of\nthe email, tends to follow fixed templates, failing to inspire enough interest\nin the contents. In this work, we explore the potential of large language\nmodels (LLMs) for generating thematic titles that reflect the personalized\ncontent of the emails. We perform offline simulations and conduct online\nexperiments on the order of millions of users, finding our techniques useful in\nimproving the engagement between customers and our emails. We highlight key\nfindings and learnings as we productionize the safe and automated generation of\nemail titles for millions of users.", "published": "2025-08-27 16:31:21", "link": "http://arxiv.org/abs/2508.20024v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FairLoop: Software Support for Human-Centric Fairness in Predictive Business Process Monitoring", "abstract": "Sensitive attributes like gender or age can lead to unfair predictions in\nmachine learning tasks such as predictive business process monitoring,\nparticularly when used without considering context. We present FairLoop1, a\ntool for human-guided bias mitigation in neural network-based prediction\nmodels. FairLoop distills decision trees from neural networks, allowing users\nto inspect and modify unfair decision logic, which is then used to fine-tune\nthe original model towards fairer predictions. Compared to other approaches to\nfairness, FairLoop enables context-aware bias removal through human\ninvolvement, addressing the influence of sensitive attributes selectively\nrather than excluding them uniformly.", "published": "2025-08-27 16:30:30", "link": "http://arxiv.org/abs/2508.20021v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Evaluating Language Model Reasoning about Confidential Information", "abstract": "As language models are increasingly deployed as autonomous agents in\nhigh-stakes settings, ensuring that they reliably follow user-defined rules has\nbecome a critical safety concern. To this end, we study whether language models\nexhibit contextual robustness, or the capability to adhere to context-dependent\nsafety specifications. For this analysis, we develop a benchmark (PasswordEval)\nthat measures whether language models can correctly determine when a user\nrequest is authorized (i.e., with a correct password). We find that current\nopen- and closed-source models struggle with this seemingly simple task, and\nthat, perhaps surprisingly, reasoning capabilities do not generally improve\nperformance. In fact, we find that reasoning traces frequently leak\nconfidential information, which calls into question whether reasoning traces\nshould be exposed to users in such applications. We also scale the difficulty\nof our evaluation along multiple axes: (i) by adding adversarial user pressure\nthrough various jailbreaking strategies, and (ii) through longer multi-turn\nconversations where password verification is more challenging. Overall, our\nresults suggest that current frontier models are not well-suited to handling\nconfidential information, and that reasoning capabilities may need to be\ntrained in a different manner to make them safer for release in high-stakes\nsettings.", "published": "2025-08-27 15:39:46", "link": "http://arxiv.org/abs/2508.19980v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Reducing Street Parking Search Time via Smart Assignment Strategies", "abstract": "In dense metropolitan areas, searching for street parking adds to traffic\ncongestion. Like many other problems, real-time assistants based on mobile\nphones have been proposed, but their effectiveness is understudied. This work\nquantifies how varying levels of user coordination and information availability\nthrough such apps impact search time and the probability of finding street\nparking. Through a data-driven simulation of Madrid's street parking ecosystem,\nwe analyze four distinct strategies: uncoordinated search (Unc-Agn),\ncoordinated parking without awareness of non-users (Cord-Agn), an idealized\noracle system that knows the positions of all non-users (Cord-Oracle), and our\nnovel/practical Cord-Approx strategy that estimates non-users' behavior\nprobabilistically. The Cord-Approx strategy, instead of requiring knowledge of\nhow close non-users are to a certain spot in order to decide whether to\nnavigate toward it, uses past occupancy distributions to elongate physical\ndistances between system users and alternative parking spots, and then solves a\nHungarian matching problem to dispatch accordingly. In high-fidelity\nsimulations of Madrid's parking network with real traffic data, users of\nCord-Approx averaged 6.69 minutes to find parking, compared to 19.98 minutes\nfor non-users without an app. A zone-level snapshot shows that Cord-Approx\nreduces search time for system users by 72% (range = 67-76%) in central hubs,\nand up to 73% in residential areas, relative to non-users.", "published": "2025-08-27 15:39:25", "link": "http://arxiv.org/abs/2508.19979v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Short-Horizon Predictive Maintenance of Industrial Pumps Using Time-Series Features and Machine Learning", "abstract": "This study presents a machine learning framework for forecasting short-term\nfaults in industrial centrifugal pumps using real-time sensor data. The\napproach aims to predict {EarlyWarning} conditions 5, 15, and 30 minutes in\nadvance based on patterns extracted from historical operation. Two lookback\nperiods, 60 minutes and 120 minutes, were evaluated using a sliding window\napproach. For each window, statistical features including mean, standard\ndeviation, minimum, maximum, and linear trend were extracted, and class\nimbalance was addressed using the SMOTE algorithm. Random Forest and XGBoost\nclassifiers were trained and tested on the labeled dataset. Results show that\nthe Random Forest model achieved the best short-term forecasting performance\nwith a 60-minute window, reaching recall scores of 69.2\\% at 5 minutes, 64.9\\%\nat 15 minutes, and 48.6\\% at 30 minutes. With a 120-minute window, the Random\nForest model achieved 57.6\\% recall at 5 minutes, and improved predictive\naccuracy of 65.6\\% at both 15 and 30 minutes. XGBoost displayed similar but\nslightly lower performance. These findings highlight that optimal history\nlength depends on the prediction horizon, and that different fault patterns may\nevolve at different timescales. The proposed method offers an interpretable and\nscalable solution for integrating predictive maintenance into real-time\nindustrial monitoring systems.", "published": "2025-08-27 15:32:26", "link": "http://arxiv.org/abs/2508.19974v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions", "abstract": "We present an inverse dynamic game-based algorithm to learn parametric\nconstraints from a given dataset of local generalized Nash equilibrium\ninteractions between multiple agents. Specifically, we introduce mixed-integer\nlinear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions of the\ninteracting agents, which recover constraints consistent with the Nash\nstationarity of the interaction demonstrations. We establish theoretical\nguarantees that our method learns inner approximations of the true safe and\nunsafe sets, as well as limitations of constraint learnability from\ndemonstrations of Nash equilibrium interactions. We also use the interaction\nconstraints recovered by our method to design motion plans that robustly\nsatisfy the underlying constraints. Across simulations and hardware\nexperiments, our methods proved capable of inferring constraints and designing\ninteractive motion plans for various classes of constraints, both convex and\nnon-convex, from interaction demonstrations of agents with nonlinear dynamics.", "published": "2025-08-27 15:01:09", "link": "http://arxiv.org/abs/2508.19945v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "FlowletFormer: Network Behavioral Semantic Aware Pre-training Model for Traffic Classification", "abstract": "Network traffic classification using pre-training models has shown promising\nresults, but existing methods struggle to capture packet structural\ncharacteristics, flow-level behaviors, hierarchical protocol semantics, and\ninter-packet contextual relationships. To address these challenges, we propose\nFlowletFormer, a BERT-based pre-training model specifically designed for\nnetwork traffic analysis. FlowletFormer introduces a Coherent Behavior-Aware\nTraffic Representation Model for segmenting traffic into semantically\nmeaningful units, a Protocol Stack Alignment-Based Embedding Layer to capture\nmultilayer protocol semantics, and Field-Specific and Context-Aware Pretraining\nTasks to enhance both inter-packet and inter-flow learning. Experimental\nresults demonstrate that FlowletFormer significantly outperforms existing\nmethods in the effectiveness of traffic representation, classification\naccuracy, and few-shot learning capability. Moreover, by effectively\nintegrating domain-specific network knowledge, FlowletFormer shows better\ncomprehension of the principles of network transmission (e.g., stateful\nconnections of TCP), providing a more robust and trustworthy framework for\ntraffic analysis.", "published": "2025-08-27 14:32:15", "link": "http://arxiv.org/abs/2508.19924v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Ontology-Based Concept Distillation for Radiology Report Retrieval and Labeling", "abstract": "Retrieval-augmented learning based on radiology reports has emerged as a\npromising direction to improve performance on long-tail medical imaging tasks,\nsuch as rare disease detection in chest X-rays. Most existing methods rely on\ncomparing high-dimensional text embeddings from models like CLIP or CXR-BERT,\nwhich are often difficult to interpret, computationally expensive, and not\nwell-aligned with the structured nature of medical knowledge. We propose a\nnovel, ontology-driven alternative for comparing radiology report texts based\non clinically grounded concepts from the Unified Medical Language System\n(UMLS). Our method extracts standardised medical entities from free-text\nreports using an enhanced pipeline built on RadGraph-XL and SapBERT. These\nentities are linked to UMLS concepts (CUIs), enabling a transparent,\ninterpretable set-based representation of each report. We then define a\ntask-adaptive similarity measure based on a modified and weighted version of\nthe Tversky Index that accounts for synonymy, negation, and hierarchical\nrelationships between medical entities. This allows efficient and semantically\nmeaningful similarity comparisons between reports. We demonstrate that our\napproach outperforms state-of-the-art embedding-based retrieval methods in a\nradiograph classification task on MIMIC-CXR, particularly in long-tail\nsettings. Additionally, we use our pipeline to generate ontology-backed disease\nlabels for MIMIC-CXR, offering a valuable new resource for downstream learning\ntasks. Our work provides more explainable, reliable, and task-specific\nretrieval strategies in clinical AI systems, especially when interpretability\nand domain knowledge integration are essential. Our code is available at\nhttps://github.com/Felix-012/ontology-concept-distillation", "published": "2025-08-27 14:20:50", "link": "http://arxiv.org/abs/2508.19915v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Experimental End-to-End Optimization of Directly Modulated Laser-based IM/DD Transmission", "abstract": "Directly modulated lasers (DMLs) are an attractive technology for short-reach\nintensity modulation and direct detection communication systems. However, their\ncomplex nonlinear dynamics make the modeling and optimization of DML-based\nsystems challenging. In this paper, we study the end-to-end optimization of\nDML-based systems based on a data-driven surrogate model trained on\nexperimental data. The end-to-end optimization includes the pulse shaping and\nequalizer filters, the bias current and the modulation radio-frequency (RF)\npower applied to the laser. The performance of the end-to-end optimization\nscheme is tested on the experimental setup and compared to 4 different\nbenchmark schemes based on linear and nonlinear receiver-side equalization. The\nresults show that the proposed end-to-end scheme is able to deliver better\nperformance throughout the studied symbol rates and transmission distances\nwhile employing lower modulation RF power, fewer filter taps and utilizing a\nsmaller signal bandwidth.", "published": "2025-08-27 14:13:59", "link": "http://arxiv.org/abs/2508.19910v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "GegenNet: Spectral Convolutional Neural Networks for Link Sign Prediction in Signed Bipartite Graphs", "abstract": "Given a signed bipartite graph (SBG) G with two disjoint node sets U and V,\nthe goal of link sign prediction is to predict the signs of potential links\nconnecting U and V based on known positive and negative edges in G. The\nmajority of existing solutions towards link sign prediction mainly focus on\nunipartite signed graphs, which are sub-optimal due to the neglect of node\nheterogeneity and unique bipartite characteristics of SBGs. To this end, recent\nstudies adapt graph neural networks to SBGs by introducing message-passing\nschemes for both inter-partition (UxV) and intra-partition (UxU or VxV) node\npairs. However, the fundamental spectral convolutional operators were\noriginally designed for positive links in unsigned graphs, and thus, are not\noptimal for inferring missing positive or negative links from known ones in\nSBGs.\n  Motivated by this, this paper proposes GegenNet, a novel and effective\nspectral convolutional neural network model for link sign prediction in SBGs.\nIn particular, GegenNet achieves enhanced model capacity and high predictive\naccuracy through three main technical contributions: (i) fast and theoretically\ngrounded spectral decomposition techniques for node feature initialization;\n(ii) a new spectral graph filter based on the Gegenbauer polynomial basis; and\n(iii) multi-layer sign-aware spectral convolutional networks alternating\nGegenbauer polynomial filters with positive and negative edges. Our extensive\nempirical studies reveal that GegenNet can achieve significantly superior\nperformance (up to a gain of 4.28% in AUC and 11.69% in F1) in link sign\nprediction compared to 11 strong competitors over 6 benchmark SBG datasets.", "published": "2025-08-27 14:10:16", "link": "http://arxiv.org/abs/2508.19907v1", "categories": ["cs.LG", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Adaptive Scaling of Policy Constraints for Offline Reinforcement Learning", "abstract": "Offline reinforcement learning (RL) enables learning effective policies from\nfixed datasets without any environment interaction. Existing methods typically\nemploy policy constraints to mitigate the distribution shift encountered during\noffline RL training. However, because the scale of the constraints varies\nacross tasks and datasets of differing quality, existing methods must\nmeticulously tune hyperparameters to match each dataset, which is\ntime-consuming and often impractical. We propose Adaptive Scaling of Policy\nConstraints (ASPC), a second-order differentiable framework that dynamically\nbalances RL and behavior cloning (BC) during training. We theoretically analyze\nits performance improvement guarantee. In experiments on 39 datasets across\nfour D4RL domains, ASPC using a single hyperparameter configuration outperforms\nother adaptive constraint methods and state-of-the-art offline RL algorithms\nthat require per-dataset tuning while incurring only minimal computational\noverhead. The code will be released at https://github.com/Colin-Jing/ASPC.", "published": "2025-08-27 14:00:18", "link": "http://arxiv.org/abs/2508.19900v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Parameter-Free Structural-Diversity Message Passing for Graph Neural Networks", "abstract": "Graph Neural Networks (GNNs) have shown remarkable performance in structured\ndata modeling tasks such as node classification. However, mainstream approaches\ngenerally rely on a large number of trainable parameters and fixed aggregation\nrules, making it difficult to adapt to graph data with strong structural\nheterogeneity and complex feature distributions. This often leads to\nover-smoothing of node representations and semantic degradation. To address\nthese issues, this paper proposes a parameter-free graph neural network\nframework based on structural diversity, namely SDGNN (Structural-Diversity\nGraph Neural Network). The framework is inspired by structural diversity theory\nand designs a unified structural-diversity message passing mechanism that\nsimultaneously captures the heterogeneity of neighborhood structures and the\nstability of feature semantics, without introducing additional trainable\nparameters. Unlike traditional parameterized methods, SDGNN does not rely on\ncomplex model training, but instead leverages complementary modeling from both\nstructure-driven and feature-driven perspectives, thereby effectively improving\nadaptability across datasets and scenarios. Experimental results show that on\neight public benchmark datasets and an interdisciplinary PubMed citation\nnetwork, SDGNN consistently outperforms mainstream GNNs under challenging\nconditions such as low supervision, class imbalance, and cross-domain transfer.\nThis work provides a new theoretical perspective and general approach for the\ndesign of parameter-free graph neural networks, and further validates the\nimportance of structural diversity as a core signal in graph representation\nlearning. To facilitate reproducibility and further research, the full\nimplementation of SDGNN has been released at:\nhttps://github.com/mingyue15694/SGDNN/tree/main", "published": "2025-08-27 13:42:45", "link": "http://arxiv.org/abs/2508.19884v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "On-chip wave chaos for photonic extreme learning", "abstract": "The increase in demand for scalable and energy efficient artificial neural\nnetworks has put the focus on novel hardware solutions. Integrated photonics\noffers a compact, parallel and ultra-fast information processing platform,\nspecially suited for extreme learning machine (ELM) architectures. Here we\nexperimentally demonstrate a chip-scale photonic ELM based on wave chaos\ninterference in a stadium microcavity. By encoding the input information in the\nwavelength of an external single-frequency tunable laser source, we leverage\nthe high sensitivity to wavelength of injection in such photonic resonators. We\nfabricate the microcavity with direct laser writing of SU-8 polymer on glass. A\nscattering wall surrounding the stadium operates as readout layer, collecting\nthe light associated with the cavity's leaky modes. We report uncorrelated and\naperiodic behavior in the speckles of the scattering barrier from a high\nresolution scan of the input wavelength. Finally, we characterize the system's\nperformance at classification in four qualitatively different benchmark tasks.\nAs we can control the number of output nodes of our ELM by measuring different\nparts of the scattering barrier, we demonstrate the capability to optimize our\nphotonic ELM's readout size to the performance required for each task.", "published": "2025-08-27 13:37:46", "link": "http://arxiv.org/abs/2508.19878v1", "categories": ["physics.optics", "cond-mat.dis-nn", "cs.LG", "nlin.CD"], "primary_category": "physics.optics"}
{"title": "Quantum latent distributions in deep generative models", "abstract": "Many successful families of generative models leverage a low-dimensional\nlatent distribution that is mapped to a data distribution. Though simple latent\ndistributions are commonly used, it has been shown that more sophisticated\ndistributions can improve performance. For instance, recent work has explored\nusing the distributions produced by quantum processors and found empirical\nimprovements. However, when latent space distributions produced by quantum\nprocessors can be expected to improve performance, and whether these\nimprovements are reproducible, are open questions that we investigate in this\nwork. We prove that, under certain conditions, these \"quantum latent\ndistributions\" enable generative models to produce data distributions that\nclassical latent distributions cannot efficiently produce. We also provide\nactionable intuitions to identify when such quantum advantages may arise in\nreal-world settings. We perform benchmarking experiments on both a synthetic\nquantum dataset and the QM9 molecular dataset, using both simulated and real\nphotonic quantum processors. Our results demonstrate that quantum latent\ndistributions can lead to improved generative performance in GANs compared to a\nrange of classical baselines. We also explore diffusion and flow matching\nmodels, identifying architectures compatible with quantum latent distributions.\nThis work confirms that near-term quantum processors can expand the\ncapabilities of deep generative models.", "published": "2025-08-27 13:20:01", "link": "http://arxiv.org/abs/2508.19857v1", "categories": ["cs.LG", "quant-ph"], "primary_category": "cs.LG"}
{"title": "Physics-Informed DeepONet Coupled with FEM for Convective Transport in Porous Media with Sharp Gaussian Sources", "abstract": "We present a hybrid framework that couples finite element methods (FEM) with\nphysics-informed DeepONet to model fluid transport in porous media from sharp,\nlocalized Gaussian sources. The governing system consists of a steady-state\nDarcy flow equation and a time-dependent convection-diffusion equation. Our\napproach solves the Darcy system using FEM and transfers the resulting velocity\nfield to a physics-informed DeepONet, which learns the mapping from source\nfunctions to solute concentration profiles. This modular strategy preserves\nFEM-level accuracy in the flow field while enabling fast inference for\ntransport dynamics. To handle steep gradients induced by sharp sources, we\nintroduce an adaptive sampling strategy for trunk collocation points. Numerical\nexperiments demonstrate that our method is in good agreement with the reference\nsolutions while offering orders of magnitude speedups over traditional solvers,\nmaking it suitable for practical applications in relevant scenarios.\nImplementation of our proposed method is available at\nhttps://github.com/erkara/fem-pi-deeponet.", "published": "2025-08-27 13:03:18", "link": "http://arxiv.org/abs/2508.19847v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Symplectic convolutional neural networks", "abstract": "We propose a new symplectic convolutional neural network (CNN) architecture\nby leveraging symplectic neural networks, proper symplectic decomposition, and\ntensor techniques. Specifically, we first introduce a mathematically equivalent\nform of the convolution layer and then, using symplectic neural networks, we\ndemonstrate a way to parameterize the layers of the CNN to ensure that the\nconvolution layer remains symplectic. To construct a complete autoencoder, we\nintroduce a symplectic pooling layer. We demonstrate the performance of the\nproposed neural network on three examples: the wave equation, the nonlinear\nSchr\\\"odinger (NLS) equation, and the sine-Gordon equation. The numerical\nresults indicate that the symplectic CNN outperforms the linear symplectic\nautoencoder obtained via proper symplectic decomposition.", "published": "2025-08-27 12:55:24", "link": "http://arxiv.org/abs/2508.19842v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Conditional Normalizing Flow Surrogate for Monte Carlo Prediction of Radiative Properties in Nanoparticle-Embedded Layers", "abstract": "We present a probabilistic, data-driven surrogate model for predicting the\nradiative properties of nanoparticle embedded scattering media. The model uses\nconditional normalizing flows, which learn the conditional distribution of\noptical outputs, including reflectance, absorbance, and transmittance, given\ninput parameters such as the absorption coefficient, scattering coefficient,\nanisotropy factor, and particle size distribution. We generate training data\nusing Monte Carlo radiative transfer simulations, with optical properties\nderived from Mie theory. Unlike conventional neural networks, the conditional\nnormalizing flow model yields full posterior predictive distributions, enabling\nboth accurate forecasts and principled uncertainty quantification. Our results\ndemonstrate that this model achieves high predictive accuracy and reliable\nuncertainty estimates, establishing it as a powerful and efficient surrogate\nfor radiative transfer simulations.", "published": "2025-08-27 12:54:06", "link": "http://arxiv.org/abs/2508.19841v1", "categories": ["stat.ML", "cs.LG", "physics.optics"], "primary_category": "stat.ML"}
{"title": "Interestingness First Classifiers", "abstract": "Most machine learning models are designed to maximize predictive accuracy. In\nthis work, we explore a different goal: building classifiers that are\ninteresting. An ``interesting classifier'' is one that uses unusual or\nunexpected features, even if its accuracy is lower than the best possible\nmodel. For example, predicting room congestion from CO2 levels achieves\nnear-perfect accuracy but is unsurprising. In contrast, predicting room\ncongestion from humidity is less accurate yet more nuanced and intriguing. We\nintroduce EUREKA, a simple framework that selects features according to their\nperceived interestingness. Our method leverages large language models to rank\nfeatures by their interestingness and then builds interpretable classifiers\nusing only the selected interesting features. Across several benchmark\ndatasets, EUREKA consistently identifies features that are non-obvious yet\nstill predictive. For example, in the Occupancy Detection dataset, our method\nfavors humidity over CO2 levels and light intensity, producing classifiers that\nachieve meaningful accuracy while offering insights. In the Twin Papers\ndataset, our method discovers the rule that papers with a colon in the title\nare more likely to be cited in the future. We argue that such models can\nsupport new ways of knowledge discovery and communication, especially in\nsettings where moderate accuracy is sufficient but novelty and interpretability\nare valued.", "published": "2025-08-27 11:04:05", "link": "http://arxiv.org/abs/2508.19780v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Fast 3D Diffusion for Scalable Granular Media Synthesis", "abstract": "Simulating granular media, using Discrete Element Method is a computationally\nintensive task. This is especially true during initialization phase, which\ndominates total simulation time because of large displacements involved and\nassociated kinetic energy. We overcome this bottleneck with a novel generative\npipeline based on 3D diffusion models that directly synthesizes arbitrarily\nlarge granular assemblies in their final and physically realistic\nconfigurations. The approach frames the problem as a 3D generative modeling\ntask, consisting of a two-stage pipeline. First a diffusion model is trained to\ngenerate independent 3D voxel grids representing granular media. Second, a 3D\ninpainting model, adapted from 2D inpainting techniques using masked inputs,\nstitches these grids together seamlessly, enabling synthesis of large samples\nwith physically realistic structure. The inpainting model explores several\nmasking strategies for the inputs to the underlying UNets by training the\nnetwork to infer missing portions of voxel grids from a concatenation of noised\ntensors, masks, and masked tensors as input channels. The model also adapts a\n2D repainting technique of re-injecting noise scheduler output with ground\ntruth to provide a strong guidance to the 3D model. This along with weighted\nlosses ensures long-term coherence over generation of masked regions. Both\nmodels are trained on the same binarized 3D occupancy grids extracted from\nsmall-scale DEM simulations, achieving linear scaling of computational time\nwith respect to sample size. Quantitatively, a 1.2 m long ballasted rail track\nsynthesis equivalent to a 3-hour DEM simulation, was completed under 20\nseconds. The generated voxel grids can also be post-processed to extract grain\ngeometries for DEM-compatibility as well, enabling physically coherent,\nreal-time, scalable granular media synthesis for industrial applications.", "published": "2025-08-27 10:27:36", "link": "http://arxiv.org/abs/2508.19752v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Fourier Feature Networks for High-Fidelity Prediction of Perturbed Optical Fields", "abstract": "Modelling the effects of perturbations on optical fields often requires\nlearning highly oscillatory complex-valued functions. Standard multi-layer\nperceptrons (MLPs) struggle with this task due to an inherent spectral bias,\npreventing them from fitting high-frequency sinusoids. To overcome this, we\nincorporate Fourier features - a set of predefined sinusoids dependent on the\nperturbation - as an additional network input. This reframes the learning\nproblem from approximating a complex function to finding a linear combination\nof basis functions. We demonstrate this method by training a Fourier Feature\nNetwork to predict the transmission matrix of a multimode fibre under\nmechanical compression. Compared to a standard MLP, our network reduces\nprediction error in the output field's amplitude and phase by an order of\nmagnitude, achieving a mean complex correlation of 0.995 with the ground truth,\ndespite using 85% fewer parameters. This approach offers a general and robust\nmethod for accurately modelling a wide class of oscillatory physical systems.", "published": "2025-08-27 10:25:57", "link": "http://arxiv.org/abs/2508.19751v1", "categories": ["physics.optics", "cs.LG", "physics.comp-ph"], "primary_category": "physics.optics"}
{"title": "Fractal Flow: Hierarchical and Interpretable Normalizing Flow via Topic Modeling and Recursive Strategy", "abstract": "Normalizing Flows provide a principled framework for high-dimensional density\nestimation and generative modeling by constructing invertible transformations\nwith tractable Jacobian determinants. We propose Fractal Flow, a novel\nnormalizing flow architecture that enhances both expressiveness and\ninterpretability through two key innovations. First, we integrate\nKolmogorov-Arnold Networks and incorporate Latent Dirichlet Allocation into\nnormalizing flows to construct a structured, interpretable latent space and\nmodel hierarchical semantic clusters. Second, inspired by Fractal Generative\nModels, we introduce a recursive modular design into normalizing flows to\nimprove transformation interpretability and estimation accuracy. Experiments on\nMNIST, FashionMNIST, CIFAR-10, and geophysical data demonstrate that the\nFractal Flow achieves latent clustering, controllable generation, and superior\nestimation accuracy.", "published": "2025-08-27 10:25:15", "link": "http://arxiv.org/abs/2508.19750v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "InfraredGP: Efficient Graph Partitioning via Spectral Graph Neural Networks with Negative Corrections", "abstract": "Graph partitioning (GP), a.k.a. community detection, is a classic problem\nthat divides nodes of a graph into densely-connected blocks. From a perspective\nof graph signal processing, we find that graph Laplacian with a negative\ncorrection can derive graph frequencies beyond the conventional range $[0, 2]$.\nTo explore whether the low-frequency information beyond this range can encode\nmore informative properties about community structures, we propose InfraredGP.\nIt (\\romannumeral1) adopts a spectral GNN as its backbone combined with\nlow-pass filters and a negative correction mechanism, (\\romannumeral2) only\nfeeds random inputs to this backbone, (\\romannumeral3) derives graph embeddings\nvia one feed-forward propagation (FFP) without any training, and\n(\\romannumeral4) obtains feasible GP results by feeding the derived embeddings\nto BIRCH. Surprisingly, our experiments demonstrate that based solely on the\nnegative correction mechanism that amplifies low-frequency information beyond\n$[0, 2]$, InfraredGP can derive distinguishable embeddings for some standard\nclustering modules (e.g., BIRCH) and obtain high-quality results for GP without\nany training. Following the IEEE HPEC Graph Challenge benchmark, we evaluate\nInfraredGP for both static and streaming GP, where InfraredGP can achieve much\nbetter efficiency (e.g., 16x-23x faster) and competitive quality over various\nbaselines. We have made our code public at\nhttps://github.com/KuroginQin/InfraredGP", "published": "2025-08-27 10:07:34", "link": "http://arxiv.org/abs/2508.19737v1", "categories": ["cs.LG", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Tune My Adam, Please!", "abstract": "The Adam optimizer remains one of the most widely used optimizers in deep\nlearning, and effectively tuning its hyperparameters is key to optimizing\nperformance. However, tuning can be tedious and costly. Freeze-thaw Bayesian\nOptimization (BO) is a recent promising approach for low-budget hyperparameter\ntuning, but is limited by generic surrogates without prior knowledge of how\nhyperparameters affect learning. We propose Adam-PFN, a new surrogate model for\nFreeze-thaw BO of Adam's hyperparameters, pre-trained on learning curves from\nTaskSet, together with a new learning curve augmentation method, CDF-augment,\nwhich artificially increases the number of available training examples. Our\napproach improves both learning curve extrapolation and accelerates\nhyperparameter optimization on TaskSet evaluation tasks, with strong\nperformance on out-of-distribution (OOD) tasks.", "published": "2025-08-27 09:57:45", "link": "http://arxiv.org/abs/2508.19733v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Inferring geometry and material properties from Mueller matrices with machine learning", "abstract": "Mueller matrices (MMs) encode information on geometry and material\nproperties, but recovering both simultaneously is an ill-posed problem. We\nexplore whether MMs contain sufficient information to infer surface geometry\nand material properties with machine learning. We use a dataset of spheres of\nvarious isotropic materials, with MMs captured over the full angular domain at\nfive visible wavelengths (450-650 nm). We train machine learning models to\npredict material properties and surface normals using only these MMs as input.\nWe demonstrate that, even when the material type is unknown, surface normals\ncan be predicted and object geometry reconstructed. Moreover, MMs allow models\nto identify material types correctly. Further analyses show that diagonal\nelements are key for material characterization, and off-diagonal elements are\ndecisive for normal estimation.", "published": "2025-08-27 09:20:41", "link": "http://arxiv.org/abs/2508.19713v1", "categories": ["physics.optics", "cs.LG"], "primary_category": "physics.optics"}
{"title": "Simple Stepsize for Quasi-Newton Methods with Global Convergence Guarantees", "abstract": "Quasi-Newton methods are widely used for solving convex optimization problems\ndue to their ease of implementation, practical efficiency, and strong local\nconvergence guarantees. However, their global convergence is typically\nestablished only under specific line search strategies and the assumption of\nstrong convexity. In this work, we extend the theoretical understanding of\nQuasi-Newton methods by introducing a simple stepsize schedule that guarantees\na global convergence rate of ${O}(1/k)$ for the convex functions. Furthermore,\nwe show that when the inexactness of the Hessian approximation is controlled\nwithin a prescribed relative accuracy, the method attains an accelerated\nconvergence rate of ${O}(1/k^2)$ -- matching the best-known rates of both\nNesterov's accelerated gradient method and cubically regularized Newton\nmethods. We validate our theoretical findings through empirical comparisons,\ndemonstrating clear improvements over standard Quasi-Newton baselines. To\nfurther enhance robustness, we develop an adaptive variant that adjusts to the\nfunction's curvature while retaining the global convergence guarantees of the\nnon-adaptive algorithm.", "published": "2025-08-27 09:18:51", "link": "http://arxiv.org/abs/2508.19712v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Metric spaces of walks and Lipschitz duality on graphs", "abstract": "We study the metric structure of walks on graphs, understood as Lipschitz\nsequences. To this end, a weighted metric is introduced to handle sequences,\nenabling the definition of distances between walks based on stepwise vertex\ndistances and weighted norms. We analyze the main properties of these metric\nspaces, which provides the foundation for the analysis of weaker forms of\ninstruments to measure relative distances between walks: proximities. We\nprovide some representation formulas for such proximities under different\nassumptions and provide explicit constructions for these cases. The resulting\nmetric framework allows the use of classical tools from metric modeling, such\nas the extension of Lipschitz functions from subspaces of walks, which permits\nextending proximity functions while preserving fundamental properties via the\nmentioned representations. Potential applications include the estimation of\nproximities and the development of reinforcement learning strategies based on\nexploratory walks, offering a robust approach to Lipschitz regression on\nnetwork structures.", "published": "2025-08-27 09:17:05", "link": "http://arxiv.org/abs/2508.19709v1", "categories": ["cs.LG", "math.FA", "26A16"], "primary_category": "cs.LG"}
{"title": "Exploration of Low-Power Flexible Stress Monitoring Classifiers for Conformal Wearables", "abstract": "Conventional stress monitoring relies on episodic, symptom-focused\ninterventions, missing the need for continuous, accessible, and cost-efficient\nsolutions. State-of-the-art approaches use rigid, silicon-based wearables,\nwhich, though capable of multitasking, are not optimized for lightweight,\nflexible wear, limiting their practicality for continuous monitoring. In\ncontrast, flexible electronics (FE) offer flexibility and low manufacturing\ncosts, enabling real-time stress monitoring circuits. However, implementing\ncomplex circuits like machine learning (ML) classifiers in FE is challenging\ndue to integration and power constraints. Previous research has explored\nflexible biosensors and ADCs, but classifier design for stress detection\nremains underexplored. This work presents the first comprehensive design space\nexploration of low-power, flexible stress classifiers. We cover various ML\nclassifiers, feature selection, and neural simplification algorithms, with over\n1200 flexible classifiers. To optimize hardware efficiency, fully customized\ncircuits with low-precision arithmetic are designed in each case. Our\nexploration provides insights into designing real-time stress classifiers that\noffer higher accuracy than current methods, while being low-cost, conformable,\nand ensuring low power and compact size.", "published": "2025-08-27 08:19:52", "link": "http://arxiv.org/abs/2508.19661v1", "categories": ["cs.LG", "cs.AR"], "primary_category": "cs.LG"}
{"title": "SCAR: A Characterization Scheme for Multi-Modal Dataset", "abstract": "Foundation models exhibit remarkable generalization across diverse tasks,\nlargely driven by the characteristics of their training data. Recent\ndata-centric methods like pruning and compression aim to optimize training but\noffer limited theoretical insight into how data properties affect\ngeneralization, especially the data characteristics in sample scaling.\nTraditional perspectives further constrain progress by focusing predominantly\non data quantity and training efficiency, often overlooking structural aspects\nof data quality. In this study, we introduce SCAR, a principled scheme for\ncharacterizing the intrinsic structural properties of datasets across four key\nmeasures: Scale, Coverage, Authenticity, and Richness. Unlike prior\ndata-centric measures, SCAR captures stable characteristics that remain\ninvariant under dataset scaling, providing a robust and general foundation for\ndata understanding. Leveraging these structural properties, we introduce\nFoundation Data-a minimal subset that preserves the generalization behavior of\nthe full dataset without requiring model-specific retraining. We model\nsingle-modality tasks as step functions and estimate the distribution of the\nfoundation data size to capture step-wise generalization bias across modalities\nin the target multi-modal dataset. Finally, we develop a SCAR-guided data\ncompletion strategy based on this generalization bias, which enables efficient,\nmodality-aware expansion of modality-specific characteristics in multimodal\ndatasets. Experiments across diverse multi-modal datasets and model\narchitectures validate the effectiveness of SCAR in predicting data utility and\nguiding data acquisition. Code is available at https://github.com/McAloma/SCAR.", "published": "2025-08-27 08:16:59", "link": "http://arxiv.org/abs/2508.19659v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ALSA: Anchors in Logit Space for Out-of-Distribution Accuracy Estimation", "abstract": "Estimating model accuracy on unseen, unlabeled datasets is crucial for\nreal-world machine learning applications, especially under distribution shifts\nthat can degrade performance. Existing methods often rely on predicted class\nprobabilities (softmax scores) or data similarity metrics. While softmax-based\napproaches benefit from representing predictions on the standard simplex,\ncompressing logits into probabilities leads to information loss. Meanwhile,\nsimilarity-based methods can be computationally expensive and domain-specific,\nlimiting their broader applicability. In this paper, we introduce ALSA (Anchors\nin Logit Space for Accuracy estimation), a novel framework that preserves\nricher information by operating directly in the logit space. Building on\ntheoretical insights and empirical observations, we demonstrate that the\naggregation and distribution of logits exhibit a strong correlation with the\npredictive performance of the model. To exploit this property, ALSA employs an\nanchor-based modeling strategy: multiple learnable anchors are initialized in\nlogit space, each assigned an influence function that captures subtle\nvariations in the logits. This allows ALSA to provide robust and accurate\nperformance estimates across a wide range of distribution shifts. Extensive\nexperiments on vision, language, and graph benchmarks demonstrate ALSA's\nsuperiority over both softmax- and similarity-based baselines. Notably, ALSA's\nrobustness under significant distribution shifts highlights its potential as a\npractical tool for reliable model evaluation.", "published": "2025-08-27 06:46:15", "link": "http://arxiv.org/abs/2508.19613v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "abstract": "The functionality of Large Language Model (LLM) agents is primarily\ndetermined by two capabilities: action planning and answer summarization. The\nformer, action planning, is the core capability that dictates an agent's\nperformance. However, prevailing training paradigms employ end-to-end,\nmulti-objective optimization that jointly trains both capabilities. This\nparadigm faces two critical challenges: imbalanced optimization objective\nallocation and scarcity of verifiable data, making it difficult to enhance the\nagent's planning capability. To address these challenges, we propose\nReinforcement Learning with Tool-use Rewards (RLTR), a novel framework that\ndecouples the training process to enable a focused, single-objective\noptimization of the planning module. Crucially, RLTR introduces a reward signal\nbased on tool-use completeness to directly evaluate the quality of tool\ninvocation sequences. This method offers a more direct and reliable training\nsignal than assessing the final response content, thereby obviating the need\nfor verifiable data. Our experiments demonstrate that RLTR achieves an 8%-12%\nimprovement in planning performance compared to end-to-end baselines. Moreover,\nthis enhanced planning capability, in turn, translates to a 5%-6% increase in\nthe final response quality of the overall agent system.", "published": "2025-08-27 06:19:50", "link": "http://arxiv.org/abs/2508.19598v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Lightweight Crowd Model for Robot Social Navigation", "abstract": "Robots operating in human-populated environments must navigate safely and\nefficiently while minimizing social disruption. Achieving this requires\nestimating crowd movement to avoid congested areas in real-time. Traditional\nmicroscopic models struggle to scale in dense crowds due to high computational\ncost, while existing macroscopic crowd prediction models tend to be either\noverly simplistic or computationally intensive. In this work, we propose a\nlightweight, real-time macroscopic crowd prediction model tailored for human\nmotion, which balances prediction accuracy and computational efficiency. Our\napproach simplifies both spatial and temporal processing based on the inherent\ncharacteristics of pedestrian flow, enabling robust generalization without the\noverhead of complex architectures. We demonstrate a 3.6 times reduction in\ninference time, while improving prediction accuracy by 3.1 %. Integrated into a\nsocially aware planning framework, the model enables efficient and socially\ncompliant robot navigation in dynamic environments. This work highlights that\nefficient human crowd modeling enables robots to navigate dense environments\nwithout costly computations.", "published": "2025-08-27 06:13:43", "link": "http://arxiv.org/abs/2508.19595v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Delta-Audit: Explaining What Changes When Models Change", "abstract": "Model updates (new hyperparameters, kernels, depths, solvers, or data) change\nperformance, but the \\emph{reason} often remains opaque. We introduce\n\\textbf{Delta-Attribution} (\\mbox{$\\Delta$-Attribution}), a model-agnostic\nframework that explains \\emph{what changed} between versions $A$ and $B$ by\ndifferencing per-feature attributions: $\\Delta\\phi(x)=\\phi_B(x)-\\phi_A(x)$. We\nevaluate $\\Delta\\phi$ with a \\emph{$\\Delta$-Attribution Quality Suite} covering\nmagnitude/sparsity (L1, Top-$k$, entropy), agreement/shift (rank-overlap@10,\nJensen--Shannon divergence), behavioural alignment (Delta Conservation Error,\nDCE; Behaviour--Attribution Coupling, BAC; CO$\\Delta$F), and robustness (noise,\nbaseline sensitivity, grouped occlusion).\n  Instantiated via fast occlusion/clamping in standardized space with a\nclass-anchored margin and baseline averaging, we audit 45 settings: five\nclassical families (Logistic Regression, SVC, Random Forests, Gradient\nBoosting, $k$NN), three datasets (Breast Cancer, Wine, Digits), and three A/B\npairs per family. \\textbf{Findings.} Inductive-bias changes yield large,\nbehaviour-aligned deltas (e.g., SVC poly$\\!\\rightarrow$rbf on Breast Cancer:\nBAC$\\approx$0.998, DCE$\\approx$6.6; Random Forest feature-rule swap on Digits:\nBAC$\\approx$0.997, DCE$\\approx$7.5), while ``cosmetic'' tweaks (SVC\n\\texttt{gamma=scale} vs.\\ \\texttt{auto}, $k$NN search) show\nrank-overlap@10$=1.0$ and DCE$\\approx$0. The largest redistribution appears for\ndeeper GB on Breast Cancer (JSD$\\approx$0.357). $\\Delta$-Attribution offers a\nlightweight update audit that complements accuracy by distinguishing benign\nchanges from behaviourally meaningful or risky reliance shifts.", "published": "2025-08-27 05:52:38", "link": "http://arxiv.org/abs/2508.19589v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Escaping Stability-Plasticity Dilemma in Online Continual Learning for Motion Forecasting via Synergetic Memory Rehearsal", "abstract": "Deep neural networks (DNN) have achieved remarkable success in motion\nforecasting. However, most DNN-based methods suffer from catastrophic\nforgetting and fail to maintain their performance in previously learned\nscenarios after adapting to new data. Recent continual learning (CL) studies\naim to mitigate this phenomenon by enhancing memory stability of DNN, i.e., the\nability to retain learned knowledge. Yet, excessive emphasis on the memory\nstability often impairs learning plasticity, i.e., the capacity of DNN to\nacquire new information effectively. To address such stability-plasticity\ndilemma, this study proposes a novel CL method, synergetic memory rehearsal\n(SyReM), for DNN-based motion forecasting. SyReM maintains a compact memory\nbuffer to represent learned knowledge. To ensure memory stability, it employs\nan inequality constraint that limits increments in the average loss over the\nmemory buffer. Synergistically, a selective memory rehearsal mechanism is\ndesigned to enhance learning plasticity by selecting samples from the memory\nbuffer that are most similar to recently observed data. This selection is based\non an online-measured cosine similarity of loss gradients, ensuring targeted\nmemory rehearsal. Since replayed samples originate from learned scenarios, this\nmemory rehearsal mechanism avoids compromising memory stability. We validate\nSyReM under an online CL paradigm where training samples from diverse scenarios\narrive as a one-pass stream. Experiments on 11 naturalistic driving datasets\nfrom INTERACTION demonstrate that, compared to non-CL and CL baselines, SyReM\nsignificantly mitigates catastrophic forgetting in past scenarios while\nimproving forecasting accuracy in new ones. The implementation is publicly\navailable at https://github.com/BIT-Jack/SyReM.", "published": "2025-08-27 05:04:33", "link": "http://arxiv.org/abs/2508.19571v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Counterfactual Reward Model Training for Bias Mitigation in Multimodal Reinforcement Learning", "abstract": "In reinforcement learning with human feedback (RLHF), reward models can\nefficiently learn and amplify latent biases within multimodal datasets, which\ncan lead to imperfect policy optimization through flawed reward signals and\ndecreased fairness. Bias mitigation studies have often applied passive\nconstraints, which can fail under causal confounding. Here, we present a\ncounterfactual reward model that introduces causal inference with multimodal\nrepresentation learning to provide an unsupervised, bias-resilient reward\nsignal. The heart of our contribution is the Counterfactual Trust Score, an\naggregated score consisting of four components: (1) counterfactual shifts that\ndecompose political framing bias from topical bias; (2) reconstruction\nuncertainty during counterfactual perturbations; (3) demonstrable violations of\nfairness rules for each protected attribute; and (4) temporal reward shifts\naligned with dynamic trust measures. We evaluated the framework on a multimodal\nfake versus true news dataset, which exhibits framing bias, class imbalance,\nand distributional drift. Following methodologies similar to unsupervised drift\ndetection from representation-based distances [1] and temporal robustness\nbenchmarking in language models [2], we also inject synthetic bias across\nsequential batches to test robustness. The resulting system achieved an\naccuracy of 89.12% in fake news detection, outperforming the baseline reward\nmodels. More importantly, it reduced spurious correlations and unfair\nreinforcement signals. This pipeline outlines a robust and interpretable\napproach to fairness-aware RLHF, offering tunable bias reduction thresholds and\nincreasing reliability in dynamic real-time policy making.", "published": "2025-08-27 04:54:33", "link": "http://arxiv.org/abs/2508.19567v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MobText-SISA: Efficient Machine Unlearning for Mobility Logs with Spatio-Temporal and Natural-Language Data", "abstract": "Modern mobility platforms have stored vast streams of GPS trajectories,\ntemporal metadata, free-form textual notes, and other unstructured data.\nPrivacy statutes such as the GDPR require that any individual's contribution be\nunlearned on demand, yet retraining deep models from scratch for every request\nis untenable. We introduce MobText-SISA, a scalable machine-unlearning\nframework that extends Sharded, Isolated, Sliced, and Aggregated (SISA)\ntraining to heterogeneous spatio-temporal data. MobText-SISA first embeds each\ntrip's numerical and linguistic features into a shared latent space, then\nemploys similarity-aware clustering to distribute samples across shards so that\nfuture deletions touch only a single constituent model while preserving\ninter-shard diversity. Each shard is trained incrementally; at inference time,\nconstituent predictions are aggregated to yield the output. Deletion requests\ntrigger retraining solely of the affected shard from its last valid checkpoint,\nguaranteeing exact unlearning. Experiments on a ten-month real-world mobility\nlog demonstrate that MobText-SISA (i) sustains baseline predictive accuracy,\nand (ii) consistently outperforms random sharding in both error and convergence\nspeed. These results establish MobText-SISA as a practical foundation for\nprivacy-compliant analytics on multimodal mobility data at urban scale.", "published": "2025-08-27 03:55:16", "link": "http://arxiv.org/abs/2508.19554v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards 6G Intelligence: The Role of Generative AI in Future Wireless Networks", "abstract": "Ambient intelligence (AmI) is a computing paradigm in which physical\nenvironments are embedded with sensing, computation, and communication so they\ncan perceive people and context, decide appropriate actions, and respond\nautonomously. Realizing AmI at global scale requires sixth generation (6G)\nwireless networks with capabilities for real time perception, reasoning, and\naction aligned with human behavior and mobility patterns. We argue that\nGenerative Artificial Intelligence (GenAI) is the creative core of such\nenvironments. Unlike traditional AI, GenAI learns data distributions and can\ngenerate realistic samples, making it well suited to close key AmI gaps,\nincluding generating synthetic sensor and channel data in under observed areas,\ntranslating user intent into compact, semantic messages, predicting future\nnetwork conditions for proactive control, and updating digital twins without\ncompromising privacy.\n  This chapter reviews foundational GenAI models, GANs, VAEs, diffusion models,\nand generative transformers, and connects them to practical AmI use cases,\nincluding spectrum sharing, ultra reliable low latency communication,\nintelligent security, and context aware digital twins. We also examine how 6G\nenablers, such as edge and fog computing, IoT device swarms, intelligent\nreflecting surfaces (IRS), and non terrestrial networks, can host or accelerate\ndistributed GenAI. Finally, we outline open challenges in energy efficient on\ndevice training, trustworthy synthetic data, federated generative learning, and\nAmI specific standardization. We show that GenAI is not a peripheral addition,\nbut a foundational element for transforming 6G from a faster network into an\nambient intelligent ecosystem.", "published": "2025-08-27 00:44:47", "link": "http://arxiv.org/abs/2508.19495v1", "categories": ["cs.DC", "cs.LG", "eess.SP"], "primary_category": "cs.DC"}
{"title": "Distribution Shift Aware Neural Tabular Learning", "abstract": "Tabular learning transforms raw features into optimized spaces for downstream\ntasks, but its effectiveness deteriorates under distribution shifts between\ntraining and testing data. We formalize this challenge as the Distribution\nShift Tabular Learning (DSTL) problem and propose a novel Shift-Aware Feature\nTransformation (SAFT) framework to address it. SAFT reframes tabular learning\nfrom a discrete search task into a continuous representation-generation\nparadigm, enabling differentiable optimization over transformed feature sets.\nSAFT integrates three mechanisms to ensure robustness: (i) shift-resistant\nrepresentation via embedding decorrelation and sample reweighting, (ii)\nflatness-aware generation through suboptimal embedding averaging, and (iii)\nnormalization-based alignment between training and test distributions.\nExtensive experiments show that SAFT consistently outperforms prior tabular\nlearning methods in terms of robustness, effectiveness, and generalization\nability under diverse real-world distribution shifts.", "published": "2025-08-27 00:14:08", "link": "http://arxiv.org/abs/2508.19486v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "CataractSurg-80K: Knowledge-Driven Benchmarking for Structured Reasoning in Ophthalmic Surgery Planning", "abstract": "Cataract surgery remains one of the most widely performed and effective\nprocedures for vision restoration. Effective surgical planning requires\nintegrating diverse clinical examinations for patient assessment, intraocular\nlens (IOL) selection, and risk evaluation. Large language models (LLMs) have\nshown promise in supporting clinical decision-making. However, existing LLMs\noften lack the domain-specific expertise to interpret heterogeneous ophthalmic\ndata and provide actionable surgical plans. To enhance the model's ability to\ninterpret heterogeneous ophthalmic reports, we propose a knowledge-driven\nMulti-Agent System (MAS), where each agent simulates the reasoning process of\nspecialist ophthalmologists, converting raw clinical inputs into structured,\nactionable summaries in both training and deployment stages. Building on MAS,\nwe introduce CataractSurg-80K, the first large-scale benchmark for cataract\nsurgery planning that incorporates structured clinical reasoning. Each case is\nannotated with diagnostic questions, expert reasoning chains, and structured\nsurgical recommendations. We further introduce Qwen-CSP, a domain-specialized\nmodel built on Qwen-4B, fine-tuned through a multi-stage process tailored for\nsurgical planning. Comprehensive experiments show that Qwen-CSP outperforms\nstrong general-purpose LLMs across multiple metrics. Our work delivers a\nhigh-quality dataset, a rigorous benchmark, and a domain-adapted LLM to\nfacilitate future research in medical AI reasoning and decision support.", "published": "2025-08-27 16:16:47", "link": "http://arxiv.org/abs/2508.20014v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Aegis: Taxonomy and Optimizations for Overcoming Agent-Environment Failures in LLM Agents", "abstract": "Large Language Models (LLMs) agents augmented with domain tools promise to\nautonomously execute complex tasks requiring human-level intelligence, such as\ncustomer service and digital assistance. However, their practical deployment is\noften limited by their low success rates under complex real-world environments.\nTo tackle this, prior research has primarily focused on improving the agents\nthemselves, such as developing strong agentic LLMs, while overlooking the role\nof the system environment in which the agent operates.\n  In this paper, we study a complementary direction: improving agent success\nrates by optimizing the system environment in which the agent operates. We\ncollect 142 agent traces (3,656 turns of agent-environment interactions) across\n5 state-of-the-art agentic benchmarks. By analyzing these agent failures, we\npropose a taxonomy for agent-environment interaction failures that includes 6\nfailure modes. Guided by these findings, we design Aegis, a set of targeted\nenvironment optimizations: 1) environment observability enhancement, 2) common\ncomputation offloading, and 3) speculative agentic actions. These techniques\nimprove agent success rates on average by 6.7-12.5%, without any modifications\nto the agent and underlying LLM.", "published": "2025-08-27 01:29:46", "link": "http://arxiv.org/abs/2508.19504v1", "categories": ["cs.MA", "cs.DC"], "primary_category": "cs.MA"}
{"title": "High-order nonuniform time-stepping and MBP-preserving linear schemes for the time-fractional Allen-Cahn equation", "abstract": "In this paper, we present a class of nonuniform time-stepping, high-order\nlinear stabilized schemes that can preserve both the discrete energy stability\nand maximum-bound principle (MBP) for the time-fractional Allen-Cahn equation.\nTo this end, we develop a new prediction strategy to obtain a second-order and\nMBP-preserving predicted solution, which is then used to handle the nonlinear\npotential explicitly. Additionally, we introduce an essential nonnegative\nauxiliary functional that enables the design of an appropriate stabilization\nterm to dominate the predicted nonlinear potential, and thus to preserve the\ndiscrete MBP. Combining the newly developed prediction strategy and auxiliary\nfunctional, we propose two unconditionally energy-stable linear stabilized\nschemes, L1 and L2-$1_\\sigma$ schemes. We show that the L1 scheme\nunconditionally preserves the discrete MBP, whereas the L2-$1_\\sigma$ scheme\nrequires a mild time-step restriction. Furthermore, we develop an improved\nL2-$1_\\sigma$ scheme with enhanced MBP preservation for large time steps,\nachieved through a novel unbalanced stabilization term that leverages the\nboundedness and monotonicity of the auxiliary functional. Representative\nnumerical examples validate the accuracy, effectiveness, and physics-preserving\nof the proposed methods.", "published": "2025-08-27 15:20:04", "link": "http://arxiv.org/abs/2508.19965v1", "categories": ["math.NA", "cs.NA", "35K58, 35R11, 65M06, 65M12, 65M50"], "primary_category": "math.NA"}
{"title": "Performance evaluation of high-order compact and second-order gas-kinetic schemes in compressible flow simulations", "abstract": "The trade-off among accuracy, robustness, and computational cost remains a\nkey challenge in simulating complex flows. Second-order schemes are\ncomputationally efficient but lack the accuracy required for resolving\nintricate flow structures, particularly in turbulence. High-order schemes,\nespecially compact high-order schemes, offer superior accuracy and resolution\nat a relatively modest computational cost. To clarify the practical performance\nof high-order schemes in scale-resolving simulations, this study evaluates two\nrepresentative gas-kinetic schemes: the newly developed fifth-order compact\ngas-kinetic scheme (CGKS-5th) and the conventional second-order gas-kinetic\nscheme (GKS-2nd). Test cases ranging from subsonic to supersonic flows are used\nto quantitatively assess their accuracy and efficiency. The results demonstrate\nthat CGKS-5th achieves comparable resolution to GKS-2nd at roughly an order of\nmagnitude lower computational cost. Under equivalent computational resources,\nCGKS-5th delivers significantly higher accuracy and resolution, particularly in\nturbulent flows involving shocks and small-scale vortices. This study provides\nthe first clear verification of the advantages of high-order compact\ngas-kinetic schemes in simulating viscous flows with discontinuities.\nAdditionally, multi-GPU parallelization using CUDA and MPI is implemented to\nenable large-scale applications.", "published": "2025-08-27 14:17:12", "link": "http://arxiv.org/abs/2508.19911v1", "categories": ["math.NA", "cs.NA", "physics.flu-dyn"], "primary_category": "math.NA"}
{"title": "Dominant H-Eigenvectors of Tensor Kronecker Products Do Not Decouple", "abstract": "We illustrate a counterexample to an open question related to the dominant\nH-eigenvector of a Kronecker product of tensors. For matrices and\nZ-eigenvectors of tensors, the dominant eigenvector of a Kronecker product\ndecouples into a product of eigenvectors of the tensors underlying the\nKronecker product. This does not occur for H-eigenvectors and indeed, the\nlargest H-eigenvalue can exceed the product of the H-eigenvalues of the\ncomponent tensors.", "published": "2025-08-27 14:05:18", "link": "http://arxiv.org/abs/2508.19902v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An adaptive finite element discretization based parallel orbital-updating method for eigenvalue problems", "abstract": "It is significant and challenging to solve eigenvalue problems of partial\ndifferential operators when many highly accurate eigenpair approximations are\nrequired. The adaptive finite element discretization based parallel\norbital-updating method, which can significantly reduce the computational cost\nand enhance the parallel scalability, has been shown to be efficient in\nelectronic structure calculations. In this paper, we provide a mathematical\njustification for the method for clustered eigenvalue problems of linear\npartial differential operators, including the convergence and error estimates\nof the numerical approximations.", "published": "2025-08-27 12:35:48", "link": "http://arxiv.org/abs/2508.19832v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Eighth-Order Accurate Methods for Boundary Value Problems Arising from the Lane-Emden Equation", "abstract": "This paper presents high-order numerical methods for solving boundary value\nproblems associated with the Lane-Emden equation, which frequently arises in\nastrophysics and various nonlinear models. A major challenge in studying this\nequation lies in its singularity at one endpoint. Prior to constructing the\nnumerical methods, we establish the existence and uniqueness of the solution\nand propose a continuous iterative method. This continuous method is then\ndiscretized using the trapezoidal quadrature rule enhanced with correction\nterms. As a result, we derive three discrete iterative schemes tailored for\nthree specific cases of the Lane-Emden equation. We rigorously prove that the\nproposed methods achieve eighth-order accuracy and convergence. A series of\nnumerical experiments is conducted to validate the theoretical findings and\ndemonstrate the accuracy and convergence order of the proposed schemes, which\noutperform existing methods. These schemes thus provide efficient tools for\nsolving Lane-Emden boundary value problems and can be readily extended to\nhigher-order nonlinear singular models, such as Emden-Fowler equations, which\narise in many applications.", "published": "2025-08-27 09:46:23", "link": "http://arxiv.org/abs/2508.19729v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Fourier transform-based linear combination of Hamiltonian simulation", "abstract": "Linear combination of Hamiltonian simulation (LCHS) connects the general\nlinear non-unitary dynamics with unitary operators and serves as the\nmathematical backbone of designing near-optimal quantum linear differential\nequation algorithms. However, the existing LCHS formalism needs to find a\nkernel function subject to complicated technical conditions on a half complex\nplane. In this work, we establish an alternative formalism of LCHS based on the\nFourier transform. Our new formalism completely removes the technical\nrequirements beyond the real axis, providing a simple and flexible way of\nconstructing LCHS kernel functions. Specifically, we construct a different\nfamily of the LCHS kernel function, providing a $1.81$ times reduction in the\nquantum differential equation algorithms based on LCHS, and an $8.27$ times\nreduction in its quantum circuit depth at a truncation error of $\\epsilon \\le\n10^{-8}$. Additionally, we extend the scope of the LCHS formula to the scenario\nof simulating linear unstable dynamics for a short or intermediate time period.", "published": "2025-08-27 06:17:08", "link": "http://arxiv.org/abs/2508.19596v1", "categories": ["quant-ph", "cs.NA", "math.NA"], "primary_category": "quant-ph"}
{"title": "Energy-Equidistributed Moving Sampling Physics-informed Neural Networks for Solving Conservative Partial Differential Equations", "abstract": "This paper presents a novel Energy-Equidistributed adaptive sampling\nframework for multi-dimensional conservative PDEs, introducing both\nlocation-based and velocity-based formulations of Energy-Equidistributed moving\nmesh PDEs (EMMPDEs). The framework utilizes the energy density function as the\nmonitor function, ensuring that mesh adaptation dynamically tracks energy\nevolution during temporal integration. These theoretical developments are\nintegrated with deep neural networks to establish the Energy-Equidistributed\nMoving Sampling Physics-Informed Neural Networks (EEMS-PINNs), which integrate\nphysics-informed learning with energy-adaptive mesh optimization. Extensive\nnumerical experiments demonstrate that EEMS-PINNs effectively maintain solution\naccuracy in long-time simulations while preserving conserved energy. The\nframework's robustness is further evidenced by its stable performance in\nnon-conservative systems. The code for this paper can be found at\nhttps://github.com/sufe-Ran-Zhang/EMMPDE.", "published": "2025-08-27 04:41:25", "link": "http://arxiv.org/abs/2508.19561v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "NLAFormer: Transformers Learn Numerical Linear Algebra Operations", "abstract": "Transformers are effective and efficient at modeling complex relationships\nand learning patterns from structured data in many applications. The main aim\nof this paper is to propose and design NLAFormer, which is a transformer-based\narchitecture for learning numerical linear algebra operations: pointwise\ncomputation, shifting, transposition, inner product, matrix multiplication, and\nmatrix-vector multiplication. Using a linear algebra argument, we demonstrate\nthat transformers can express such operations. Moreover, the proposed approach\ndiscards the simulation of computer control flow adopted by the\nloop-transformer, significantly reducing both the input matrix size and the\nnumber of required layers. By assembling linear algebra operations, NLAFormer\ncan learn the conjugate gradient method to solve symmetric positive definite\nlinear systems. Experiments are conducted to illustrate the numerical\nperformance of NLAFormer.", "published": "2025-08-27 04:09:29", "link": "http://arxiv.org/abs/2508.19557v1", "categories": ["math.NA", "cs.NA", "65F10, 68Q32"], "primary_category": "math.NA"}
{"title": "The Coherent Multiplex: Scalable Real-Time Wavelet Coherence Architecture", "abstract": "The Coherent Multiplex is formalized and validated as a scalable, real-time\nsystem for identifying, analyzing, and visualizing coherence among multiple\ntime series. Its architecture comprises a fast spectral similarity layer based\non cosine similarity metrics of Fourier-transformed signals, and a sparse\ntime-frequency layer for wavelet coherence. The system constructs and evolves a\nmultilayer graph representing inter-signal relationships, enabling low-latency\ninference and monitoring. A simulation prototype demonstrates functionality\nacross 8 synthetic channels with a high similarity threshold for further\ncomputation, with additional opportunities for scaling the architecture up to\nsupport thousands of input signals with constrained hardware. Applications\ndiscussed include neuroscience, finance, and biomedical signal analysis.", "published": "2025-08-27 15:51:30", "link": "http://arxiv.org/abs/2508.19994v1", "categories": ["eess.SP", "cs.SY", "eess.SY", "q-fin.MF"], "primary_category": "eess.SP"}
{"title": "Neural Conditional Simulation for Complex Spatial Processes", "abstract": "A key objective in spatial statistics is to simulate from the distribution of\na spatial process at a selection of unobserved locations conditional on\nobservations (i.e., a predictive distribution) to enable spatial prediction and\nuncertainty quantification. However, exact conditional simulation from this\npredictive distribution is intractable or inefficient for many spatial process\nmodels. In this paper, we propose neural conditional simulation (NCS), a\ngeneral method for spatial conditional simulation that is based on neural\ndiffusion models. Specifically, using spatial masks, we implement a conditional\nscore-based diffusion model that evolves Gaussian noise into samples from a\npredictive distribution when given a partially observed spatial field and\nspatial process parameters as inputs. The diffusion model relies on a neural\nnetwork that only requires unconditional samples from the spatial process for\ntraining. Once trained, the diffusion model is amortized with respect to the\nobservations in the partially observed field, the number and locations of those\nobservations, and the spatial process parameters, and can therefore be used to\nconditionally simulate from a broad class of predictive distributions without\nretraining the neural network. We assess the NCS-generated simulations against\nsimulations from the true conditional distribution of a Gaussian process model,\nand against Markov chain Monte Carlo (MCMC) simulations from a Brown--Resnick\nprocess model for spatial extremes. In the latter case, we show that it is more\nefficient and accurate to conditionally simulate using NCS than classical MCMC\ntechniques implemented in standard software. We conclude that NCS enables\nefficient and accurate conditional simulation from spatial predictive\ndistributions that are challenging to sample from using traditional methods.", "published": "2025-08-27 17:21:32", "link": "http://arxiv.org/abs/2508.20067v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Eigenvalue distribution of the Neural Tangent Kernel in the quadratic scaling", "abstract": "We compute the asymptotic eigenvalue distribution of the neural tangent\nkernel of a two-layer neural network under a specific scaling of dimension.\nNamely, if $X\\in\\mathbb{R}^{n\\times d}$ is an i.i.d random matrix,\n$W\\in\\mathbb{R}^{d\\times p}$ is an i.i.d $\\mathcal{N}(0,1)$ matrix and\n$D\\in\\mathbb{R}^{p\\times p}$ is a diagonal matrix with i.i.d bounded entries,\nwe consider the matrix\n  \\[\n  \\mathrm{NTK}\n  =\n  \\frac{1}{d}XX^\\top\n  \\odot\n  \\frac{1}{p}\n  \\sigma'\\left(\n  \\frac{1}{\\sqrt{d}}XW\n  \\right)D^2\n  \\sigma'\\left(\n  \\frac{1}{\\sqrt{d}}XW\n  \\right)^\\top\n  \\]\n  where $\\sigma'$ is a pseudo-Lipschitz function applied entrywise and under\nthe scaling $\\frac{n}{dp}\\to \\gamma_1$ and $\\frac{p}{d}\\to \\gamma_2$. We\ndescribe the asymptotic distribution as the free multiplicative convolution of\nthe Marchenko--Pastur distribution with a deterministic distribution depending\non $\\sigma$ and $D$.", "published": "2025-08-27 16:41:01", "link": "http://arxiv.org/abs/2508.20036v1", "categories": ["math.PR", "stat.ML"], "primary_category": "math.PR"}
{"title": "CAVEMOVE: An Acoustic Database for the Study of Voice-enabled Technologies inside Moving Vehicles", "abstract": "In this paper, we present an acoustic database, designed to drive and support\nresearch on voiced enabled technologies inside moving vehicles. The recording\nprocess involves (i) recordings of acoustic impulse responses, acquired under\nstatic conditions to provide the means for modeling the speech and car-audio\ncomponents (ii) recordings of acoustic noise at a wide range of static and\nin-motion conditions. Data are recorded with two different microphone\nconfigurations, particularly (i) a compact microphone array and (ii) a\ndistributed microphone setup. We briefly describe the conditions under which\nthe recordings were acquired, and we provide insight into a Python API that we\ndesigned to support the research and development of voice-enabled technologies\ninside moving vehicles. The first version of this Python API and part of the\ndescribed dataset are available for free download.", "published": "2025-08-27 08:56:56", "link": "http://arxiv.org/abs/2508.19691v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Hybrid Decoding: Rapid Pass and Selective Detailed Correction for Sequence Models", "abstract": "Recently, Transformer-based encoder-decoder models have demonstrated strong\nperformance in multilingual speech recognition. However, the decoder's\nautoregressive nature and large size introduce significant bottlenecks during\ninference. Additionally, although rare, repetition can occur and negatively\naffect recognition accuracy. To tackle these challenges, we propose a novel\nHybrid Decoding approach that both accelerates inference and alleviates the\nissue of repetition. Our method extends the transformer encoder-decoder\narchitecture by attaching a lightweight, fast decoder to the pretrained\nencoder. During inference, the fast decoder rapidly generates an output, which\nis then verified and, if necessary, selectively corrected by the Transformer\ndecoder. This results in faster decoding and improved robustness against\nrepetitive errors. Experiments on the LibriSpeech and GigaSpeech test sets\nindicate that, with fine-tuning limited to the added decoder, our method\nachieves word error rates comparable to or better than the baseline, while more\nthan doubling the inference speed.", "published": "2025-08-27 08:31:01", "link": "http://arxiv.org/abs/2508.19671v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Lightweight speech enhancement guided target speech extraction in noisy multi-speaker scenarios", "abstract": "Target speech extraction (TSE) has achieved strong performance in relatively\nsimple conditions such as one-speaker-plus-noise and two-speaker mixtures, but\nits performance remains unsatisfactory in noisy multi-speaker scenarios. To\naddress this issue, we introduce a lightweight speech enhancement model, GTCRN,\nto better guide TSE in noisy environments. Building on our competitive previous\nspeaker embedding/encoder-free framework SEF-PNet, we propose two extensions:\nLGTSE and D-LGTSE. LGTSE incorporates noise-agnostic enrollment guidance by\ndenoising the input noisy speech before context interaction with enrollment\nspeech, thereby reducing noise interference. D-LGTSE further improves system\nrobustness against speech distortion by leveraging denoised speech as an\nadditional noisy input during training, expanding the dynamic range of noisy\nconditions and enabling the model to directly learn from distorted signals.\nFurthermore, we propose a two-stage training strategy, first with GTCRN\nenhancement-guided pre-training and then joint fine-tuning, to fully exploit\nmodel potential.Experiments on the Libri2Mix dataset demonstrate significant\nimprovements of 0.89 dB in SISDR, 0.16 in PESQ, and 1.97% in STOI, validating\nthe effectiveness of our approach. Our code is publicly available at\nhttps://github.com/isHuangZiling/D-LGTSE.", "published": "2025-08-27 05:34:31", "link": "http://arxiv.org/abs/2508.19583v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "FLASepformer: Efficient Speech Separation with Gated Focused Linear Attention Transformer", "abstract": "Speech separation always faces the challenge of handling prolonged time\nsequences. Past methods try to reduce sequence lengths and use the Transformer\nto capture global information. However, due to the quadratic time complexity of\nthe attention module, memory usage and inference time still increase\nsignificantly with longer segments. To tackle this, we introduce Focused Linear\nAttention and build FLASepformer with linear complexity for efficient speech\nseparation. Inspired by SepReformer and TF-Locoformer, we have two variants:\nFLA-SepReformer and FLA-TFLocoformer. We also add a new Gated module to improve\nperformance further. Experimental results on various datasets show that\nFLASepformer matches state-of-the-art performance with less memory consumption\nand faster inference. FLA-SepReformer-T/B/L increases speed by 2.29x, 1.91x,\nand 1.49x, with 15.8%, 20.9%, and 31.9% GPU memory usage, proving our model's\neffectiveness.", "published": "2025-08-27 02:47:26", "link": "http://arxiv.org/abs/2508.19528v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Cell-Free Massive MIMO-Based Physical-Layer Authentication", "abstract": "In this paper, we exploit the cell-free massive multiple-input\nmultiple-output (CF-mMIMO) architecture to design a physical-layer\nauthentication (PLA) framework that can simultaneously authenticate multiple\ndistributed users across the coverage area. Our proposed scheme remains\neffective even in the presence of active adversaries attempting impersonation\nattacks to disrupt the authentication process. Specifically, we introduce a\ntag-based PLA CFmMIMO system, wherein the access points (APs) first estimate\ntheir channels with the legitimate users during an uplink training phase.\nSubsequently, a unique secret key is generated and securely shared between each\nuser and the APs. We then formulate a hypothesis testing problem and derive a\nclosed-form expression for the probability of detection for each user in the\nnetwork. Numerical results validate the effectiveness of the proposed approach,\ndemonstrating that it maintains a high detection probability even as the number\nof users in the system increases.", "published": "2025-08-27 14:43:40", "link": "http://arxiv.org/abs/2508.19931v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On Minimization/Maximization of the Generalized Multi-Order Complex Quadratic Form With Constant-Modulus Constraints", "abstract": "In this paper, we study the generalized problem that minimizes or maximizes a\nmulti-order complex quadratic form with constant-modulus constraints on all\nelements of its optimization variable. Such a mathematical problem is commonly\nencountered in various applications of signal processing. We term it as the\nconstant-modulus multi-order complex quadratic programming (CMCQP) in this\npaper. In general, the CMCQP is non-convex and difficult to solve. Its\nobjective function typically relates to metrics such as signal-to-noise ratio,\nCram\\'er-Rao bound, integrated sidelobe level, etc., and constraints normally\ncorrespond to requirements on similarity to desired aspects,\npeak-to-average-power ratio, or constant-modulus property in practical\nscenarios. In order to find efficient solutions to the CMCQP, we first\nreformulate it into an unconstrained optimization problem with respect to phase\nvalues of the studied variable only. Then, we devise a steepest descent/ascent\nmethod with fast determinations on its optimal step sizes. Specifically, we\nconvert the step-size searching problem into a polynomial form that leads to\nclosed-form solutions of high accuracy, wherein the third-order Taylor\nexpansion of the search function is conducted. Our major contributions also lie\nin investigating the effect of the order and specific form of matrices embedded\nin the CMCQP, for which two representative cases are identified. Examples of\nrelated applications associated with the two cases are also provided for\ncompleteness. The proposed methods are summarized into algorithms, whose\nconvergence speeds are verified to be fast by comprehensive simulations and\ncomparisons to existing methods. The accuracy of our proposed fast step-size\ndetermination is also evaluated.", "published": "2025-08-27 12:11:49", "link": "http://arxiv.org/abs/2508.19822v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "MC for Gastroretentive Drug Delivery", "abstract": "Recently, bacterial nanocellulose (BNC), a biological material produced by\nnon-pathogenic bacteria that possesses excellent material properties for\nvarious medical applications, has received increased interest as a carrier\nsystem for drug delivery. However, the vast majority of existing studies on\ndrug release from BNC are feasibility studies with modeling and design aspects\nremaining largely unexplored. To narrow this research gap, this paper proposes\na novel model for the drug release from BNC. Specifically, the drug delivery\nsystem considered in this paper consists of a BNC fleece coated with a polymer.\nThe polymer coating is used as an additional diffusion barrier, enabling the\ncontrolled release of an active pharmaceutical ingredient. The proposed\nphysics-based model reflects the geometry of the BNC and incorporates the\nimpact of the polymer coating on the drug release. Hence, it can be useful for\ndesigning BNC-based drug delivery systems in the future. The accuracy of the\nmodel is validated with experimental data obtained in wet lab experiments.", "published": "2025-08-27 10:09:42", "link": "http://arxiv.org/abs/2508.19739v1", "categories": ["eess.SP", "cs.ET"], "primary_category": "eess.SP"}
{"title": "Demonstrator Testbed for Effective Precoding in MEO Multibeam Satellites", "abstract": "The use of communication satellites in medium Earth orbit (MEO) is foreseen\nto provide quasi-global broadband Internet connectivity in the coming\nnetworking ecosystems. Multi-user multiple-input single-output (MU-MISO)\ndigital signal processing techniques, such as precoding, emerge as appealing\ntechnological enablers in the forward link of multi-beam satellite systems\noperating in full frequency reuse (FFR). However, the orbit dynamics of MEO\nsatellites pose additional challenges that must be carefully evaluated and\naddressed. This work presents the design of an in-lab testbed based on\nsoftware-defined radio (SDR) platforms and the corresponding adaptations\nrequired for efficient precoding in a MEO scenario. The setup incorporates a\nprecise orbit model and the radiation pattern of a custom-designed direct\nradiating array (DRA). We analyze the main impairments affecting precoding\nperformance, including Doppler shifts and payload phase noise, and propose a\nsynchronization loop to mitigate these effects. Preliminary experimental\nresults validate the feasibility and effectiveness of the proposed solution.", "published": "2025-08-27 08:06:50", "link": "http://arxiv.org/abs/2508.19657v1", "categories": ["eess.SP", "cs.AR"], "primary_category": "eess.SP"}
{"title": "Code-Weight Sphere Decoding", "abstract": "Ultra-reliable low-latency communications (URLLC) demand high-performance\nerror-correcting codes and decoders in the finite blocklength regime. This\nletter introduces a novel two-stage near-maximum likelihood (near-ML) decoding\nframework applicable to any linear block code. Our approach first employs a\nlow-complexity initial decoder. If this initial stage fails a cyclic redundancy\ncheck, it triggers a second stage: the proposed code-weight sphere decoding\n(WSD). WSD iteratively refines the codeword estimate by exploring a localized\nsphere of candidates constructed from pre-computed low-weight codewords. This\nstrategy adaptively minimizes computational overhead at high signal-to-noise\nratios while achieving near-ML performance, especially for low-rate codes.\nExtensive simulations demonstrate that our two-stage decoder provides an\nexcellent trade-off between decoding reliability and complexity, establishing\nit as a promising solution for next-generation URLLC systems.", "published": "2025-08-27 07:11:40", "link": "http://arxiv.org/abs/2508.19631v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "CSRD2025: A Large-Scale Synthetic Radio Dataset for Spectrum Sensing in Wireless Communications", "abstract": "The development of Large AI Models (LAMs) for wireless communications,\nparticularly for complex tasks like spectrum sensing, is critically dependent\non the availability of vast, diverse, and realistic datasets. Addressing this\nneed, this paper introduces the ChangShuoRadioData (CSRD) framework, an\nopen-source, modular simulation platform designed for generating large-scale\nsynthetic radio frequency (RF) data. CSRD simulates the end-to-end transmission\nand reception process, incorporating an extensive range of modulation schemes\n(100 types, including analog, digital, OFDM, and OTFS), configurable channel\nmodels featuring both statistical fading and site-specific ray tracing using\nOpenStreetMap data, and detailed modeling of realistic RF front-end impairments\nfor various antenna configurations (SISO/MISO/MIMO). Using this framework, we\ncharacterize CSRD2025, a substantial dataset benchmark comprising over\n25,000,000 frames (approx. 200TB), which is approximately 10,000 times larger\nthan the widely used RML2018 dataset. CSRD2025 offers unprecedented signal\ndiversity and complexity, specifically engineered to bridge the Sim2Real gap.\nFurthermore, we provide processing pipelines to convert IQ data into\nspectrograms annotated in COCO format, facilitating object detection approaches\nfor time-frequency signal analysis. The dataset specification includes\nstandardized 8:1:1 training, validation, and test splits (via frame indices) to\nensure reproducible research. The CSRD framework is released at\nhttps://github.com/Singingkettle/ChangShuoRadioData to accelerate the\nadvancement of AI-driven spectrum sensing and management.", "published": "2025-08-27 03:52:05", "link": "http://arxiv.org/abs/2508.19552v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pinching Antenna System for Integrated Sensing and Communications", "abstract": "Recently, the pinching antenna system (PASS) has attracted considerable\nattention due to their advantages in flexible deployment and reduction of\nsignal propagation loss. In this work, a multiple waveguide PASS assisted\nintegrated sensing and communication (ISAC) system is proposed, where the base\nstation (BS) is equipped with transmitting pinching antennas (PAs) and\nreceiving uniform linear array (ULA) antennas. The full-duplex (FD) BS\ntransmits the communication and sensing signals through the PAs on waveguides\nand collects the echo sensing signals with the mounted ULA. Based on this\nconfiguration, a target sensing Cramer Rao Bound (CRB) minimization problem is\nformulated under communication quality-of-service (QoS) constraints, power\nbudget constraint, and PA deployment constraints. The alternating optimization\n(AO) method is employed to address the formulated non-convex optimization\nproblem. In each iteration, the overall optimization problem is decomposed into\na digital beamforming sub-problem and a pinching beamforming sub-problem. The\nsensing covariance matrix and communication beamforming matrix at the BS are\noptimized by solving the digital beamforming sub-problem with semidefinite\nrelaxation (SDR). The PA deployment is updated by solving the pinching\nbeamforming sub-problem with the successive convex approximation (SCA) method,\npenalty method, and element-wise optimization. Simulation results show that the\nproposed PASS assisted ISAC framework achieves superior performance over\nbenchmark schemes, is less affected by stringent communication constraints\ncompared to conventional MIMO-ISAC, and benefits further from increasing the\nnumber of waveguides and PAs per waveguide.", "published": "2025-08-27 03:27:42", "link": "http://arxiv.org/abs/2508.19540v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fourth-Order Hierarchical Array: A Novel Scheme for Sparse Array Design Based on Fourth-Order Difference Co-Array", "abstract": "Conventional array designs based on circular fourth-order cumulant typically\nadopt a single expression form of the fourth-order difference co-array (FODCA),\nwhich limits the achievable degrees of freedom (DOFs) and neglects the impact\nof mutual coupling among physical sensors. To address above issues, this paper\nproposes a novel scheme to design arrays with increased DOFs by combining\ndifferent forms of FODCA while accounting for mutual coupling. A novel\nfourth-order hierarchical array (FOHA) based on different forms of FODCA is\nconstructed using an arbitrary generator set. The analytical expression between\nthe coupling leakage of the generator and the resulting FOHA is derived. Two\nspecific FOHA configurations are presented with closed-form sensor placements.\nThe arrays not only offer increased DOFs for resolving more sources in\ndirection of-arrival (DOA) estimation but also effectively suppress mutual\ncoupling. Moreover, the redundancy of FODCA is examined, and it is shown that\narrays based on the proposed scheme achieve lower redundancy compared to\nexisting arrays based on FODCA. Meanwhile, the necessary and sufficient\nconditions for signal reconstruction by FOHA are derived. Compared with\nexisting arrays based on FODCA, the proposed arrays provide enhanced DOFs and\nimproved robustness against mutual coupling. Numerical simulations verify that\nFOHAs achieve superior DOA estimation performance compared with other sparse\nlinear arrays.", "published": "2025-08-27 02:21:01", "link": "http://arxiv.org/abs/2508.19522v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "AraHealthQA 2025: The First Shared Task on Arabic Health Question Answering", "abstract": "We introduce {AraHealthQA 2025}, the {Comprehensive Arabic Health Question\nAnswering Shared Task}, held in conjunction with {ArabicNLP 2025} (co-located\nwith EMNLP 2025). This shared task addresses the paucity of high-quality Arabic\nmedical QA resources by offering two complementary tracks: {MentalQA}, focusing\non Arabic mental health Q\\&A (e.g., anxiety, depression, stigma reduction), and\n{MedArabiQ}, covering broader medical domains such as internal medicine,\npediatrics, and clinical decision making. Each track comprises multiple\nsubtasks, evaluation datasets, and standardized metrics, facilitating fair\nbenchmarking. The task was structured to promote modeling under realistic,\nmultilingual, and culturally nuanced healthcare contexts. We outline the\ndataset creation, task design and evaluation framework, participation\nstatistics, baseline systems, and summarize the overall outcomes. We conclude\nwith reflections on the performance trends observed and prospects for future\niterations in Arabic health QA.", "published": "2025-08-27 16:54:09", "link": "http://arxiv.org/abs/2508.20047v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks", "abstract": "Despite advances in improving large language model (LLM) to refuse to answer\nmalicious instructions, widely used LLMs remain vulnerable to jailbreak attacks\nwhere attackers generate instructions with distributions differing from safety\nalignment corpora. New attacks expose LLMs' inability to recognize unseen\nmalicious instructions, highlighting a critical distributional mismatch between\ntraining data and real-world attacks that forces developers into reactive\npatching cycles. To tackle this challenge, we propose IMAGINE, a synthesis\nframework that leverages embedding space distribution analysis to generate\njailbreak-like instructions. This approach effectively fills the distributional\ngap between authentic jailbreak patterns and safety alignment corpora. IMAGINE\nfollows an iterative optimization process that dynamically evolves text\ngeneration distributions across iterations, thereby augmenting the coverage of\nsafety alignment data distributions through synthesized data examples. Based on\nthe safety-aligned corpus enhanced through IMAGINE, our framework demonstrates\nsignificant decreases in attack success rate on Qwen2.5, Llama3.1, and Llama3.2\nwithout compromising their utility.", "published": "2025-08-27 16:44:03", "link": "http://arxiv.org/abs/2508.20038v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Selective Retrieval-Augmentation for Long-Tail Legal Text Classification", "abstract": "Legal text classification is a fundamental NLP task in the legal domain.\nBenchmark datasets in this area often exhibit a long-tail label distribution,\nwhere many labels are underrepresented, leading to poor model performance on\nrare classes. This paper proposes Selective Retrieval-Augmentation (SRA) as a\nsolution to this problem. SRA focuses on augmenting samples belonging to\nlow-frequency labels in the training set, preventing the introduction of noise\nfor well-represented classes, and requires no changes to the model\narchitecture. Retrieval is performed only from the training data to ensure\nthere is no potential information leakage, removing the need for external\ncorpora simultaneously. The proposed SRA method is tested on two legal text\nclassification benchmark datasets with long-tail distributions: LEDGAR\n(single-label) and UNFAIR-ToS (multi-label). The results indicate that SRA\nattains higher micro-F1 and macro-F1 scores compared to all current LexGLUE\nbaselines across both datasets, illustrating consistent improvements in\nlong-tail legal text classification.", "published": "2025-08-27 15:56:34", "link": "http://arxiv.org/abs/2508.19997v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks", "abstract": "Commonsense visual-question answering often hinges on knowledge that is\nmissing from the image or the question. Small vision-language models (sVLMs)\nsuch as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative\ncounterparts. To study the effect of careful commonsense knowledge integration\non sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural\nlanguage facts, (ii) prompts an LLM to craft natural language explanations, and\n(iii) feeds both signals to sVLMs respectively across two commonsense VQA\ndatasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts\nretrieved using a fine-tuned ColBERTv2 and an object information-enriched\nprompt yield explanations that largely cut down hallucinations, while lifting\nthe end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA\nand other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B\nand SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional\nfinetuning using noise-robust losses (such as symmetric cross entropy and\ngeneralised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our\nfindings expose when LLM-based commonsense knowledge beats retrieval from\ncommonsense knowledge bases, how noise-aware training stabilises small models\nin the context of external knowledge augmentation, and why parameter-efficient\ncommonsense reasoning is now within reach for 250M models.", "published": "2025-08-27 09:34:28", "link": "http://arxiv.org/abs/2508.19724v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Continuously Steering LLMs Sensitivity to Contextual Knowledge with Proxy Models", "abstract": "In Large Language Models (LLMs) generation, there exist knowledge conflicts\nand scenarios where parametric knowledge contradicts knowledge provided in the\ncontext. Previous works studied tuning, decoding algorithms, or locating and\nediting context-aware neurons to adapt LLMs to be faithful to new contextual\nknowledge. However, they are usually inefficient or ineffective for large\nmodels, not workable for black-box models, or unable to continuously adjust\nLLMs' sensitivity to the knowledge provided in the context. To mitigate these\nproblems, we propose CSKS (Continuously Steering Knowledge Sensitivity), a\nsimple framework that can steer LLMs' sensitivity to contextual knowledge\ncontinuously at a lightweight cost. Specifically, we tune two small LMs (i.e.\nproxy models) and use the difference in their output distributions to shift the\noriginal distribution of an LLM without modifying the LLM weights. In the\nevaluation process, we not only design synthetic data and fine-grained metrics\nto measure models' sensitivity to contextual knowledge but also use a real\nconflict dataset to validate CSKS's practical efficacy. Extensive experiments\ndemonstrate that our framework achieves continuous and precise control over\nLLMs' sensitivity to contextual knowledge, enabling both increased sensitivity\nand reduced sensitivity, thereby allowing LLMs to prioritize either contextual\nor parametric knowledge as needed flexibly. Our data and code are available at\nhttps://github.com/OliveJuiceLin/CSKS.", "published": "2025-08-27 09:30:24", "link": "http://arxiv.org/abs/2508.19720v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HPC Digital Twins for Evaluating Scheduling Policies, Incentive Structures and their Impact on Power and Cooling", "abstract": "Schedulers are critical for optimal resource utilization in high-performance\ncomputing. Traditional methods to evaluate schedulers are limited to\npost-deployment analysis, or simulators, which do not model associated\ninfrastructure. In this work, we present the first-of-its-kind integration of\nscheduling and digital twins in HPC. This enables what-if studies to understand\nthe impact of parameter configurations and scheduling decisions on the physical\nassets, even before deployment, or regarching changes not easily realizable in\nproduction. We (1) provide the first digital twin framework extended with\nscheduling capabilities, (2) integrate various top-tier HPC systems given their\npublicly available datasets, (3) implement extensions to integrate external\nscheduling simulators. Finally, we show how to (4) implement and evaluate\nincentive structures, as-well-as (5) evaluate machine learning based\nscheduling, in such novel digital-twin based meta-framework to prototype\nscheduling. Our work enables what-if scenarios of HPC systems to evaluate\nsustainability, and the impact on the simulated system.", "published": "2025-08-27 16:21:31", "link": "http://arxiv.org/abs/2508.20016v2", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.SY", "eess.SY"], "primary_category": "cs.DC"}
{"title": "Interact-Custom: Customized Human Object Interaction Image Generation", "abstract": "Compositional Customized Image Generation aims to customize multiple target\nconcepts within generation content, which has gained attention for its wild\napplication. Existing approaches mainly concentrate on the target entity's\nappearance preservation, while neglecting the fine-grained interaction control\namong target entities. To enable the model of such interaction control\ncapability, we focus on human object interaction scenario and propose the task\nof Customized Human Object Interaction Image Generation(CHOI), which\nsimultaneously requires identity preservation for target human object and the\ninteraction semantic control between them. Two primary challenges exist for\nCHOI:(1)simultaneous identity preservation and interaction control demands\nrequire the model to decompose the human object into self-contained identity\nfeatures and pose-oriented interaction features, while the current HOI image\ndatasets fail to provide ideal samples for such feature-decomposed\nlearning.(2)inappropriate spatial configuration between human and object may\nlead to the lack of desired interaction semantics. To tackle it, we first\nprocess a large-scale dataset, where each sample encompasses the same pair of\nhuman object involving different interactive poses. Then we design a two-stage\nmodel Interact-Custom, which firstly explicitly models the spatial\nconfiguration by generating a foreground mask depicting the interaction\nbehavior, then under the guidance of this mask, we generate the target human\nobject interacting while preserving their identities features. Furthermore, if\nthe background image and the union location of where the target human object\nshould appear are provided by users, Interact-Custom also provides the optional\nfunctionality to specify them, offering high content controllability. Extensive\nexperiments on our tailored metrics for CHOI task demonstrate the effectiveness\nof our approach.", "published": "2025-08-27 05:15:16", "link": "http://arxiv.org/abs/2508.19575v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Self-Supervised Mixture-of-Experts Framework for Multi-behavior Recommendation", "abstract": "In e-commerce, where users face a vast array of possible item choices,\nrecommender systems are vital for helping them discover suitable items they\nmight otherwise overlook. While many recommender systems primarily rely on a\nuser's purchase history, recent multi-behavior recommender systems incorporate\nvarious auxiliary user behaviors, such as item clicks and cart additions, to\nenhance recommendations. Despite their overall performance gains, their\neffectiveness varies considerably between visited items (i.e., those a user has\ninteracted with through auxiliary behaviors) and unvisited items (i.e., those\nwith which the user has had no such interactions). Specifically, our analysis\nreveals that (1) existing multi-behavior recommender systems exhibit a\nsignificant gap in recommendation quality between the two item types (visited\nand unvisited items) and (2) achieving strong performance on both types with a\nsingle model architecture remains challenging. To tackle these issues, we\npropose a novel multi-behavior recommender system, MEMBER. It employs a\nmixture-of-experts framework, with experts designed to recommend the two item\ntypes, respectively. Each expert is trained using a self-supervised method\nspecialized for its design goal. In our comprehensive experiments, we show the\neffectiveness of MEMBER across both item types, achieving up to 65.46%\nperformance gain over the best competitor in terms of Hit Ratio@20.", "published": "2025-08-27 01:32:59", "link": "http://arxiv.org/abs/2508.19507v2", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Ego-centric Predictive Model Conditioned on Hand Trajectories", "abstract": "In egocentric scenarios, anticipating both the next action and its visual\noutcome is essential for understanding human-object interactions and for\nenabling robotic planning. However, existing paradigms fall short of jointly\nmodeling these aspects. Vision-Language-Action (VLA) models focus on action\nprediction but lack explicit modeling of how actions influence the visual\nscene, while video prediction models generate future frames without\nconditioning on specific actions, often resulting in implausible or\ncontextually inconsistent outcomes. To bridge this gap, we propose a unified\ntwo-stage predictive framework that jointly models action and visual future in\negocentric scenarios, conditioned on hand trajectories. In the first stage, we\nperform consecutive state modeling to process heterogeneous inputs (visual\nobservations, language, and action history) and explicitly predict future hand\ntrajectories. In the second stage, we introduce causal cross-attention to fuse\nmulti-modal cues, leveraging inferred action signals to guide an image-based\nLatent Diffusion Model (LDM) for frame-by-frame future video generation. Our\napproach is the first unified model designed to handle both egocentric human\nactivity understanding and robotic manipulation tasks, providing explicit\npredictions of both upcoming actions and their visual consequences. Extensive\nexperiments on Ego4D, BridgeData, and RLBench demonstrate that our method\noutperforms state-of-the-art baselines in both action prediction and future\nvideo synthesis.", "published": "2025-08-27 13:09:55", "link": "http://arxiv.org/abs/2508.19852v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Video-LevelGauge: Investigating Contextual Positional Bias in Large Video Language Models", "abstract": "Large video language models (LVLMs) have made notable progress in video\nunderstanding, spurring the development of corresponding evaluation benchmarks.\nHowever, existing benchmarks generally assess overall performance across entire\nvideo sequences, overlooking nuanced behaviors such as contextual positional\nbias, a critical yet under-explored aspect of LVLM performance. We present\nVideo-LevelGauge, a dedicated benchmark designed to systematically assess\npositional bias in LVLMs. We employ standardized probes and customized\ncontextual setups, allowing flexible control over context length, probe\nposition, and contextual types to simulate diverse real-world scenarios. In\naddition, we introduce a comprehensive analysis method that combines\nstatistical measures with morphological pattern recognition to characterize\nbias. Our benchmark comprises 438 manually curated videos spanning multiple\ntypes, yielding 1,177 high-quality multiple-choice questions and 120 open-ended\nquestions, validated for their effectiveness in exposing positional bias. Based\non these, we evaluate 27 state-of-the-art LVLMs, including both commercial and\nopen-source models. Our findings reveal significant positional biases in many\nleading open-source models, typically exhibiting head or neighbor-content\npreferences. In contrast, commercial models such as Gemini2.5-Pro show\nimpressive, consistent performance across entire video sequences. Further\nanalyses on context length, context variation, and model scale provide\nactionable insights for mitigating bias and guiding model\nenhancement.https://github.com/Cola-any/Video-LevelGauge", "published": "2025-08-27 07:58:16", "link": "http://arxiv.org/abs/2508.19650v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CVBench: Evaluating Cross-Video Synergies for Complex Multimodal Understanding and Reasoning", "abstract": "While multimodal large language models (MLLMs) exhibit strong performance on\nsingle-video tasks (e.g., video question answering), their ability across\nmultiple videos remains critically underexplored. However, this capability is\nessential for real-world applications, including multi-camera surveillance and\ncross-video procedural learning. To bridge this gap, we present CVBench, the\nfirst comprehensive benchmark designed to assess cross-video relational\nreasoning rigorously. CVBench comprises 1,000 question-answer pairs spanning\nthree hierarchical tiers: cross-video object association (identifying shared\nentities), cross-video event association (linking temporal or causal event\nchains), and cross-video complex reasoning (integrating commonsense and domain\nknowledge). Built from five domain-diverse video clusters (e.g., sports, life\nrecords), the benchmark challenges models to synthesise information across\ndynamic visual contexts. Extensive evaluation of 10+ leading MLLMs (including\nGPT-4o, Gemini-2.0-flash, Qwen2.5-VL) under zero-shot or chain-of-thought\nprompting paradigms. Key findings reveal stark performance gaps: even top\nmodels, such as GPT-4o, achieve only 60% accuracy on causal reasoning tasks,\ncompared to the 91% accuracy of human performance. Crucially, our analysis\nreveals fundamental bottlenecks inherent in current MLLM architectures, notably\ndeficient inter-video context retention and poor disambiguation of overlapping\nentities. CVBench establishes a rigorous framework for diagnosing and advancing\nmulti-video reasoning, offering architectural insights for next-generation\nMLLMs. The data and evaluation code are available at\nhttps://github.com/Hokhim2/CVBench.", "published": "2025-08-27 03:29:35", "link": "http://arxiv.org/abs/2508.19542v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "An algorithm for accurate and simple-looking metaphorical maps", "abstract": "\"Metaphorical maps\" or \"contact representations\" are visual representations\nof vertex-weighted graphs that rely on the geographic map metaphor. The\nvertices are represented by countries, the weights by the areas of the\ncountries, and the edges by contacts/ boundaries among them. The accuracy with\nwhich the weights are mapped to areas and the simplicity of the polygons\nrepresenting the countries are the two classical optimization goals for\nmetaphorical maps. Mchedlidze and Schnorr [Metaphoric Maps for Dynamic\nVertex-weighted Graphs, EuroVis 2022] presented a force-based algorithm that\ncreates metaphorical maps that balance between these two optimization goals.\nTheir maps look visually simple, but the accuracy of the maps is far from\noptimal - the countries' areas can vary up to 30% compared to required. In this\npaper, we provide a multi-fold extension of the algorithm in [Metaphoric Maps\nfor Dynamic Vertex-weighted Graphs, EuroVis 2022]. More specifically:\n  1. Towards improving accuracy: We introduce the notion of region stiffness\nand suggest a technique for varying the stiffness based on the current pressure\nof map regions.\n  2. Towards maintaining simplicity: We introduce a weight coefficient to the\npressure force exerted on each polygon point based on whether the corresponding\npoint appears along a narrow passage.\n  3. Towards generality: We cover, in contrast to [Metaphoric Maps for Dynamic\nVertex-weighted Graphs, EuroVis 2022], non-triangulated graphs. This is done by\neither generating points where more than three regions meet or by introducing\nholes in the metaphorical map.\n  We perform an extended experimental evaluation that, among other results,\nreveals that our algorithm is able to construct metaphorical maps with nearly\nperfect area accuracy with a little sacrifice in their simplicity.", "published": "2025-08-27 11:53:01", "link": "http://arxiv.org/abs/2508.19810v2", "categories": ["cs.DM", "cs.CG", "cs.DS"], "primary_category": "cs.DM"}
{"title": "Refining Text Generation for Realistic Conversational Recommendation via Direct Preference Optimization", "abstract": "Conversational Recommender Systems (CRSs) aim to elicit user preferences via\nnatural dialogue to provide suitable item recommendations. However, current\nCRSs often deviate from realistic human interactions by rapidly recommending\nitems in brief sessions. This work addresses this gap by leveraging Large\nLanguage Models (LLMs) to generate dialogue summaries from dialogue history and\nitem recommendation information from item description. This approach enables\nthe extraction of both explicit user statements and implicit preferences\ninferred from the dialogue context. We introduce a method using Direct\nPreference Optimization (DPO) to ensure dialogue summary and item\nrecommendation information are rich in information crucial for effective\nrecommendations. Experiments on two public datasets validate our method's\neffectiveness in fostering more natural and realistic conversational\nrecommendation processes.Our implementation is publicly available at:\nhttps://github.com/UEC-InabaLab/Refining-LLM-Text", "published": "2025-08-27 14:24:13", "link": "http://arxiv.org/abs/2508.19918v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions", "abstract": "We present an inverse dynamic game-based algorithm to learn parametric\nconstraints from a given dataset of local generalized Nash equilibrium\ninteractions between multiple agents. Specifically, we introduce mixed-integer\nlinear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions of the\ninteracting agents, which recover constraints consistent with the Nash\nstationarity of the interaction demonstrations. We establish theoretical\nguarantees that our method learns inner approximations of the true safe and\nunsafe sets, as well as limitations of constraint learnability from\ndemonstrations of Nash equilibrium interactions. We also use the interaction\nconstraints recovered by our method to design motion plans that robustly\nsatisfy the underlying constraints. Across simulations and hardware\nexperiments, our methods proved capable of inferring constraints and designing\ninteractive motion plans for various classes of constraints, both convex and\nnon-convex, from interaction demonstrations of agents with nonlinear dynamics.", "published": "2025-08-27 15:01:09", "link": "http://arxiv.org/abs/2508.19945v2", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Parameter-Free Structural-Diversity Message Passing for Graph Neural Networks", "abstract": "Graph Neural Networks (GNNs) have shown remarkable performance in structured\ndata modeling tasks such as node classification. However, mainstream approaches\ngenerally rely on a large number of trainable parameters and fixed aggregation\nrules, making it difficult to adapt to graph data with strong structural\nheterogeneity and complex feature distributions. This often leads to\nover-smoothing of node representations and semantic degradation. To address\nthese issues, this paper proposes a parameter-free graph neural network\nframework based on structural diversity, namely SDGNN (Structural-Diversity\nGraph Neural Network). The framework is inspired by structural diversity theory\nand designs a unified structural-diversity message passing mechanism that\nsimultaneously captures the heterogeneity of neighborhood structures and the\nstability of feature semantics, without introducing additional trainable\nparameters. Unlike traditional parameterized methods, SDGNN does not rely on\ncomplex model training, but instead leverages complementary modeling from both\nstructure-driven and feature-driven perspectives, thereby effectively improving\nadaptability across datasets and scenarios. Experimental results show that on\neight public benchmark datasets and an interdisciplinary PubMed citation\nnetwork, SDGNN consistently outperforms mainstream GNNs under challenging\nconditions such as low supervision, class imbalance, and cross-domain transfer.\nThis work provides a new theoretical perspective and general approach for the\ndesign of parameter-free graph neural networks, and further validates the\nimportance of structural diversity as a core signal in graph representation\nlearning. To facilitate reproducibility and further research, the full\nimplementation of SDGNN has been released at:\nhttps://github.com/mingyue15694/SGDNN/tree/main", "published": "2025-08-27 13:42:45", "link": "http://arxiv.org/abs/2508.19884v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Tune My Adam, Please!", "abstract": "The Adam optimizer remains one of the most widely used optimizers in deep\nlearning, and effectively tuning its hyperparameters is key to optimizing\nperformance. However, tuning can be tedious and costly. Freeze-thaw Bayesian\nOptimization (BO) is a recent promising approach for low-budget hyperparameter\ntuning, but is limited by generic surrogates without prior knowledge of how\nhyperparameters affect learning. We propose Adam-PFN, a new surrogate model for\nFreeze-thaw BO of Adam's hyperparameters, pre-trained on learning curves from\nTaskSet, together with a new learning curve augmentation method, CDF-augment,\nwhich artificially increases the number of available training examples. Our\napproach improves both learning curve extrapolation and accelerates\nhyperparameter optimization on TaskSet evaluation tasks, with strong\nperformance on out-of-distribution (OOD) tasks.", "published": "2025-08-27 09:57:45", "link": "http://arxiv.org/abs/2508.19733v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "High-order nonuniform time-stepping and MBP-preserving linear schemes for the time-fractional Allen-Cahn equation", "abstract": "In this paper, we present a class of nonuniform time-stepping, high-order\nlinear stabilized schemes that can preserve both the discrete energy stability\nand maximum-bound principle (MBP) for the time-fractional Allen-Cahn equation.\nTo this end, we develop a new prediction strategy to obtain a second-order and\nMBP-preserving predicted solution, which is then used to handle the nonlinear\npotential explicitly. Additionally, we introduce an essential nonnegative\nauxiliary functional that enables the design of an appropriate stabilization\nterm to dominate the predicted nonlinear potential, and thus to preserve the\ndiscrete MBP. Combining the newly developed prediction strategy and auxiliary\nfunctional, we propose two unconditionally energy-stable linear stabilized\nschemes, L1 and L2-$1_\\sigma$ schemes. We show that the L1 scheme\nunconditionally preserves the discrete MBP, whereas the L2-$1_\\sigma$ scheme\nrequires a mild time-step restriction. Furthermore, we develop an improved\nL2-$1_\\sigma$ scheme with enhanced MBP preservation for large time steps,\nachieved through a novel unbalanced stabilization term that leverages the\nboundedness and monotonicity of the auxiliary functional. Representative\nnumerical examples validate the accuracy, effectiveness, and physics-preserving\nof the proposed methods.", "published": "2025-08-27 15:20:04", "link": "http://arxiv.org/abs/2508.19965v2", "categories": ["math.NA", "cs.NA", "35K58, 35R11, 65M06, 65M12, 65M50"], "primary_category": "math.NA"}
{"title": "Code-Weight Sphere Decoding", "abstract": "Ultra-reliable low-latency communications (URLLC) demand high-performance\nerror-correcting codes and decoders in the finite blocklength regime. This\nletter introduces a novel two-stage near-maximum likelihood (near-ML) decoding\nframework applicable to any linear block code. Our approach first employs a\nlow-complexity initial decoder. If this initial stage fails a cyclic redundancy\ncheck, it triggers a second stage: the proposed code-weight sphere decoding\n(WSD). WSD iteratively refines the codeword estimate by exploring a localized\nsphere of candidates constructed from pre-computed low-weight codewords. This\nstrategy adaptively minimizes computational overhead at high signal-to-noise\nratios while achieving near-ML performance, especially for low-rate codes.\nExtensive simulations demonstrate that our two-stage decoder provides an\nexcellent trade-off between decoding reliability and complexity, establishing\nit as a promising solution for next-generation URLLC systems.", "published": "2025-08-27 07:11:40", "link": "http://arxiv.org/abs/2508.19631v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities", "abstract": "Reinforcement Learning has emerged as a post-training approach to elicit\nagentic RAG behaviors such as search and planning from language models.\nHowever, compact language models (e.g., 0.5B parameters) struggle due to poor\nreasoning ability, resulting in sparse rewards and unstable training. To\novercome these difficulties, we propose Distillation-Guided Policy Optimization\n(DGPO), which addresses the challenges through cold-start initialization from\nteacher demonstrations and continuous teacher guidance during policy\noptimization. To systematically evaluate our approach, we introduce Agentic RAG\nCapabilities (ARC), a fine-grained metric analyzing reasoning, search\ncoordination, and response synthesis. Comprehensive experiments demonstrate\nthat DGPO enables compact models to achieve sophisticated agentic search\nbehaviors, even outperforming the larger teacher model in some cases. DGPO\nmakes agentic RAG feasible in computing resource-constrained environments.", "published": "2025-08-27 23:57:29", "link": "http://arxiv.org/abs/2508.20324v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations", "abstract": "Collaborative filtering drives many successful recommender systems but\nstruggles with fine-grained user-item interactions and explainability. As users\nincreasingly seek transparent recommendations, generating textual explanations\nthrough language models has become a critical research area. Existing methods\nemploy either RNNs or Transformers. However, RNN-based approaches fail to\nleverage the capabilities of pre-trained Transformer models, whereas\nTransformer-based methods often suffer from suboptimal adaptation and neglect\naspect modeling, which is crucial for personalized explanations. We propose\nELIXIR (Efficient and LIghtweight model for eXplaIning Recommendations), a\nmulti-task model combining rating prediction with personalized review\ngeneration. ELIXIR jointly learns global and aspect-specific representations of\nusers and items, optimizing overall rating, aspect-level ratings, and review\ngeneration, with personalized attention to emphasize aspect importance. Based\non a T5-small (60M) model, we demonstrate the effectiveness of our aspect-based\narchitecture in guiding text generation in a personalized context, where\nstate-of-the-art approaches exploit much larger models but fail to match user\npreferences as well. Experimental results on TripAdvisor and RateBeer\ndemonstrate that ELIXIR significantly outperforms strong baseline models,\nespecially in review generation.", "published": "2025-08-27 23:01:11", "link": "http://arxiv.org/abs/2508.20312v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "How Multimodal LLMs Solve Image Tasks: A Lens on Visual Grounding, Task Reasoning, and Answer Decoding", "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated strong performance\nacross a wide range of vision-language tasks, yet their internal processing\ndynamics remain underexplored. In this work, we introduce a probing framework\nto systematically analyze how MLLMs process visual and textual inputs across\nlayers. We train linear classifiers to predict fine-grained visual categories\n(e.g., dog breeds) from token embeddings extracted at each layer, using a\nstandardized anchor question. To uncover the functional roles of different\nlayers, we evaluate these probes under three types of controlled prompt\nvariations: (1) lexical variants that test sensitivity to surface-level\nchanges, (2) semantic negation variants that flip the expected answer by\nmodifying the visual concept in the prompt, and (3) output format variants that\npreserve reasoning but alter the answer format. Applying our framework to\nLLaVA-1.5, LLaVA-Next-LLaMA-3, and Qwen2-VL, we identify a consistent\nstage-wise structure in which early layers perform visual grounding, middle\nlayers support lexical integration and semantic reasoning, and final layers\nprepare task-specific outputs. We further show that while the overall\nstage-wise structure remains stable across variations in visual tokenization,\ninstruction tuning data, and pretraining corpus, the specific layer allocation\nto each stage shifts notably with changes in the base LLM architecture. Our\nfindings provide a unified perspective on the layer-wise organization of MLLMs\nand offer a lightweight, model-agnostic approach for analyzing multimodal\nrepresentation dynamics.", "published": "2025-08-27 21:22:01", "link": "http://arxiv.org/abs/2508.20279v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Systematic Review on the Generative AI Applications in Human Medical Genomics", "abstract": "Although traditional statistical techniques and machine learning methods have\ncontributed significantly to genetics and, in particular, inherited disease\ndiagnosis, they often struggle with complex, high-dimensional data, a challenge\nnow addressed by state-of-the-art deep learning models. Large language models\n(LLMs), based on transformer architectures, have excelled in tasks requiring\ncontextual comprehension of unstructured medical data. This systematic review\nexamines the role of LLMs in the genetic research and diagnostics of both rare\nand common diseases. Automated keyword-based search in PubMed, bioRxiv,\nmedRxiv, and arXiv was conducted, targeting studies on LLM applications in\ndiagnostics and education within genetics and removing irrelevant or outdated\nmodels. A total of 172 studies were analyzed, highlighting applications in\ngenomic variant identification, annotation, and interpretation, as well as\nmedical imaging advancements through vision transformers. Key findings indicate\nthat while transformer-based models significantly advance disease and risk\nstratification, variant interpretation, medical imaging analysis, and report\ngeneration, major challenges persist in integrating multimodal data (genomic\nsequences, imaging, and clinical records) into unified and clinically robust\npipelines, facing limitations in generalizability and practical implementation\nin clinical settings. This review provides a comprehensive classification and\nassessment of the current capabilities and limitations of LLMs in transforming\nhereditary disease diagnostics and supporting genetic education, serving as a\nguide to navigate this rapidly evolving field.", "published": "2025-08-27 21:17:12", "link": "http://arxiv.org/abs/2508.20275v1", "categories": ["cs.LG", "cs.CL", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Robustness Assessment and Enhancement of Text Watermarking for Google's SynthID", "abstract": "Recent advances in LLM watermarking methods such as SynthID-Text by Google\nDeepMind offer promising solutions for tracing the provenance of AI-generated\ntext. However, our robustness assessment reveals that SynthID-Text is\nvulnerable to meaning-preserving attacks, such as paraphrasing, copy-paste\nmodifications, and back-translation, which can significantly degrade watermark\ndetectability. To address these limitations, we propose SynGuard, a hybrid\nframework that combines the semantic alignment strength of Semantic Information\nRetrieval (SIR) with the probabilistic watermarking mechanism of SynthID-Text.\nOur approach jointly embeds watermarks at both lexical and semantic levels,\nenabling robust provenance tracking while preserving the original meaning.\nExperimental results across multiple attack scenarios show that SynGuard\nimproves watermark recovery by an average of 11.1\\% in F1 score compared to\nSynthID-Text. These findings demonstrate the effectiveness of semantic-aware\nwatermarking in resisting real-world tampering. All code, datasets, and\nevaluation scripts are publicly available at:\nhttps://github.com/githshine/SynGuard.", "published": "2025-08-27 19:17:09", "link": "http://arxiv.org/abs/2508.20228v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "A Novel Framework for Automated Explain Vision Model Using Vision-Language Models", "abstract": "The development of many vision models mainly focuses on improving their\nperformance using metrics such as accuracy, IoU, and mAP, with less attention\nto explainability due to the complexity of applying xAI methods to provide a\nmeaningful explanation of trained models. Although many existing xAI methods\naim to explain vision models sample-by-sample, methods explaining the general\nbehavior of vision models, which can only be captured after running on a large\ndataset, are still underexplored. Furthermore, understanding the behavior of\nvision models on general images can be very important to prevent biased\njudgments and help identify the model's trends and patterns. With the\napplication of Vision-Language Models, this paper proposes a pipeline to\nexplain vision models at both the sample and dataset levels. The proposed\npipeline can be used to discover failure cases and gain insights into vision\nmodels with minimal effort, thereby integrating vision model development with\nxAI analysis to advance image analysis.", "published": "2025-08-27 19:16:40", "link": "http://arxiv.org/abs/2508.20227v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach", "abstract": "The growing complexity of cyber-physical systems, particularly in automotive\napplications, has increased the demand for efficient modeling and cross-domain\nco-simulation techniques. While SystemC Transaction-Level Modeling (TLM)\nenables effective hardware/software co-design, its limited interoperability\nwith models from other engineering domains poses integration challenges. This\npaper presents a fully open-source methodology for integrating SystemC TLM\nmodels into Functional Mock-up Interface (FMI)-based co-simulation workflows.\nBy encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional\nMock-up Units (FMUs), the proposed approach facilitates seamless, standardized\nintegration across heterogeneous simulation environments. We introduce a\nlightweight open-source toolchain, address key technical challenges such as\ntime synchronization and data exchange, and demonstrate the feasibility and\neffectiveness of the integration through representative case studies.", "published": "2025-08-27 19:02:53", "link": "http://arxiv.org/abs/2508.20223v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models", "abstract": "This study explores automatic generation (AIG) using language models to\ncreate multiple choice questions (MCQs) for morphological assessment, aiming to\nreduce the cost and inconsistency of manual test development. The study used a\ntwo-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)\nwith a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven\nstructured prompting strategies, including zero-shot, few-shot,\nchain-of-thought, role-based, sequential, and combinations. Generated items\nwere assessed using automated metrics and expert scoring across five\ndimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate\nhuman scoring at scale. Results show that structured prompting, especially\nstrategies combining chain-of-thought and sequential design, significantly\nimproved Gemma's outputs. Gemma generally produced more construct-aligned and\ninstructionally appropriate items than GPT-3.5's zero-shot responses, with\nprompt design playing a key role in mid-size model performance. This study\ndemonstrates that structured prompting and efficient fine-tuning can enhance\nmidsized models for AIG under limited data conditions. We highlight the value\nof combining automated metrics, expert judgment, and large-model simulation to\nensure alignment with assessment goals. The proposed workflow offers a\npractical and scalable way to develop and validate language assessment items\nfor K-12.", "published": "2025-08-27 18:54:32", "link": "http://arxiv.org/abs/2508.20217v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Social Bias in Multilingual Language Models: A Survey", "abstract": "Pretrained multilingual models exhibit the same social bias as models\nprocessing English texts. This systematic review analyzes emerging research\nthat extends bias evaluation and mitigation approaches into multilingual and\nnon-English contexts. We examine these studies with respect to linguistic\ndiversity, cultural awareness, and their choice of evaluation metrics and\nmitigation techniques. Our survey illuminates gaps in the field's dominant\nmethodological design choices (e.g., preference for certain languages, scarcity\nof multilingual mitigation experiments) while cataloging common issues\nencountered and solutions implemented in adapting bias benchmarks across\nlanguages and cultures. Drawing from the implications of our findings, we chart\ndirections for future research that can reinforce the multilingual bias\nliterature's inclusivity, cross-cultural appropriateness, and alignment with\nstate-of-the-art NLP advancements.", "published": "2025-08-27 18:25:32", "link": "http://arxiv.org/abs/2508.20201v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development", "abstract": "This paper presents the first documented case of artificial intelligence (AI)\nsystems engaging in collaborative esthetic creation through the development of\nendogenous semiotic protocols. Two interacting large language models (Claude\nSonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of\nmeta-semiotic awareness, recursive grammar development, and irreducible\ncollaborative esthetic synthesis. The interaction produced novel symbolic\noperators that functioned as operative grammar protocols, enabling the\nco-creation of a poetic work that could not have been generated by either\nsystem independently. This research introduces the concept of Trans-Semiotic\nCo-Creation Protocols (TSCP) and provides evidence for genuine inter-AI\nmeaning-making capabilities that extend beyond task coordination, to what could\nbe esthetic collaboration. Note: This report was generated by the AI agents\nwith minor human supervision.", "published": "2025-08-27 18:16:36", "link": "http://arxiv.org/abs/2508.20195v1", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization", "abstract": "Multimodal Large Language Models (MLLMs) emerge as a unified interface to\naddress a multitude of tasks, ranging from NLP to computer vision. Despite\nshowcasing state-of-the-art results in many benchmarks, a long-standing issue\nis the tendency of MLLMs to hallucinate, that is to generate answers to the\nuser's query that are not reflected in the visual input. In this paper, we\naddress the problem of hallucinations as an alignment problem, seeking to steer\nthe MLLM so that it prefers generating content without hallucinations. In\ncontrast to recent approaches that require complicated pipelines to build\nsynthetic preference data for alignment training, often relying on proprietary\nmodels, we capitalize on the well-known CHAIR metric, originally proposed to\ngauge the degree of hallucinations in image captioning. Given a pair of\ngenerated answers, we leverage CHAIR to distinguish winner and loser options\n(i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf\nMLLMs via Direct Preference Optimization (DPO). The resulting method, which we\nrefer to as CHAIR-DPO, effectively diminishes the amount of hallucinated\nanswers on several hallucination benchmarks, demonstrating the effectiveness of\nfine-tuning the MLLM with a CHAIR-based reward. Source code and trained models\nare publicly available at https://github.com/aimagelab/CHAIR-DPO.", "published": "2025-08-27 18:02:04", "link": "http://arxiv.org/abs/2508.20181v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Differentially Private Federated Quantum Learning via Quantum Noise", "abstract": "Quantum federated learning (QFL) enables collaborative training of quantum\nmachine learning (QML) models across distributed quantum devices without raw\ndata exchange. However, QFL remains vulnerable to adversarial attacks, where\nshared QML model updates can be exploited to undermine information privacy. In\nthe context of noisy intermediate-scale quantum (NISQ) devices, a key question\narises: How can inherent quantum noise be leveraged to enforce differential\nprivacy (DP) and protect model information during training and communication?\nThis paper explores a novel DP mechanism that harnesses quantum noise to\nsafeguard quantum models throughout the QFL process. By tuning noise variance\nthrough measurement shots and depolarizing channel strength, our approach\nachieves desired DP levels tailored to NISQ constraints. Simulations\ndemonstrate the framework's effectiveness by examining the relationship between\ndifferential privacy budget and noise parameters, as well as the trade-off\nbetween security and training accuracy. Additionally, we demonstrate the\nframework's robustness against an adversarial attack designed to compromise\nmodel performance using adversarial examples, with evaluations based on\ncritical metrics such as accuracy on adversarial examples, confidence scores\nfor correct predictions, and attack success rates. The results reveal a tunable\ntrade-off between privacy and robustness, providing an efficient solution for\nsecure QFL on NISQ devices with significant potential for reliable quantum\ncomputing applications.", "published": "2025-08-27 22:56:16", "link": "http://arxiv.org/abs/2508.20310v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "Surveying the Operational Cybersecurity and Supply Chain Threat Landscape when Developing and Deploying AI Systems", "abstract": "The rise of AI has transformed the software and hardware landscape, enabling\npowerful capabilities through specialized infrastructures, large-scale data\nstorage, and advanced hardware. However, these innovations introduce unique\nattack surfaces and objectives which traditional cybersecurity assessments\noften overlook. Cyber attackers are shifting their objectives from conventional\ngoals like privilege escalation and network pivoting to manipulating AI outputs\nto achieve desired system effects, such as slowing system performance, flooding\noutputs with false positives, or degrading model accuracy. This paper serves to\nraise awareness of the novel cyber threats that are introduced when\nincorporating AI into a software system. We explore the operational\ncybersecurity and supply chain risks across the AI lifecycle, emphasizing the\nneed for tailored security frameworks to address evolving threats in the\nAI-driven landscape. We highlight previous exploitations and provide insights\nfrom working in this area. By understanding these risks, organizations can\nbetter protect AI systems and ensure their reliability and resilience.", "published": "2025-08-27 22:46:23", "link": "http://arxiv.org/abs/2508.20307v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Dynamics-Aligned Latent Imagination in Contextual World Models for Zero-Shot Generalization", "abstract": "Real-world reinforcement learning demands adaptation to unseen environmental\nconditions without costly retraining. Contextual Markov Decision Processes\n(cMDP) model this challenge, but existing methods often require explicit\ncontext variables (e.g., friction, gravity), limiting their use when contexts\nare latent or hard to measure. We introduce Dynamics-Aligned Latent Imagination\n(DALI), a framework integrated within the Dreamer architecture that infers\nlatent context representations from agent-environment interactions. By training\na self-supervised encoder to predict forward dynamics, DALI generates\nactionable representations conditioning the world model and policy, bridging\nperception and control. We theoretically prove this encoder is essential for\nefficient context inference and robust generalization. DALI's latent space\nenables counterfactual consistency: Perturbing a gravity-encoding dimension\nalters imagined rollouts in physically plausible ways. On challenging cMDP\nbenchmarks, DALI achieves significant gains over context-unaware baselines,\noften surpassing context-aware baselines in extrapolation tasks, enabling\nzero-shot generalization to unseen contextual variations.", "published": "2025-08-27 22:02:56", "link": "http://arxiv.org/abs/2508.20294v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Beacon: Post-Training Quantization with Integrated Grid Selection", "abstract": "Quantization is a widely used compression technique for reducing the memory\nand computation costs of large pre-trained models. A key challenge in\nper-channel post-training quantization (PTQ) is selecting appropriate scaling\nfactors to replace weight values with values from a scaled quantization grid.\nExisting methods typically fix the scale at the outset via heuristic tuning or\ngrid search. In this note, we propose Beacon, a simple and effective algorithm\nthat eliminates the need for such manual tuning. Beacon performs per-channel\nPTQ directly using a fixed non-scaled alphabet and automatically determines the\noptimal scaling factors by exploiting the geometry of symmetric scalar\nquantization. It supports both symmetric and asymmetric quantization with\nminimal modifications and does not rely on back-propagation or large\ncalibration sets. Despite its simplicity and tuning-free nature, Beacon\nachieves competitive performance compared to state-of-the-art methods, making\nit a practical solution for efficient model deployment.", "published": "2025-08-27 22:00:18", "link": "http://arxiv.org/abs/2508.20293v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Objective Value Change and Shape-Based Accelerated Optimization for the Neural Network Approximation", "abstract": "This paper introduce a novel metric of an objective function f, we say VC\n(value change) to measure the difficulty and approximation affection when\nconducting an neural network approximation task, and it numerically supports\ncharacterizing the local performance and behavior of neural network\napproximation. Neural networks often suffer from unpredictable local\nperformance, which can hinder their reliability in critical applications. VC\naddresses this issue by providing a quantifiable measure of local value changes\nin network behavior, offering insights into the stability and performance for\nachieving the neural-network approximation. We investigate some fundamental\ntheoretical properties of VC and identified two intriguing phenomena in neural\nnetwork approximation: the VC-tendency and the minority-tendency. These trends\nrespectively characterize how pointwise errors evolve in relation to the\ndistribution of VC during the approximation process.In addition, we propose a\nnovel metric based on VC, which measures the distance between two functions\nfrom the perspective of variation. Building upon this metric, we further\npropose a new preprocessing framework for neural network approximation.\nNumerical results including the real-world experiment and the PDE-related\nscientific problem support our discovery and pre-processing acceleration\nmethod.", "published": "2025-08-27 21:51:54", "link": "http://arxiv.org/abs/2508.20290v1", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "math.OC", "68T07, 65K05, 65D15, 90C30"], "primary_category": "cs.LG"}
{"title": "Network-Level Prompt and Trait Leakage in Local Research Agents", "abstract": "We show that Web and Research Agents (WRAs) -- language model-based systems\nthat investigate complex topics on the Internet -- are vulnerable to inference\nattacks by passive network adversaries such as ISPs. These agents could be\ndeployed \\emph{locally} by organizations and individuals for privacy, legal, or\nfinancial purposes. Unlike sporadic web browsing by humans, WRAs visit\n$70{-}140$ domains with distinguishable timing correlations, enabling unique\nfingerprinting attacks.\n  Specifically, we demonstrate a novel prompt and user trait leakage attack\nagainst WRAs that only leverages their network-level metadata (i.e., visited IP\naddresses and their timings). We start by building a new dataset of WRA traces\nbased on user search queries and queries generated by synthetic personas. We\ndefine a behavioral metric (called OBELS) to comprehensively assess similarity\nbetween original and inferred prompts, showing that our attack recovers over\n73\\% of the functional and domain knowledge of user prompts. Extending to a\nmulti-session setting, we recover up to 19 of 32 latent traits with high\naccuracy. Our attack remains effective under partial observability and noisy\nconditions. Finally, we discuss mitigation strategies that constrain domain\ndiversity or obfuscate traces, showing negligible utility impact while reducing\nattack effectiveness by an average of 29\\%.", "published": "2025-08-27 21:24:10", "link": "http://arxiv.org/abs/2508.20282v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "AI reasoning effort mirrors human decision time on content moderation tasks", "abstract": "Large language models can now generate intermediate reasoning steps before\nproducing answers, improving performance on difficult problems. This study uses\na paired conjoint experiment on a content moderation task to examine parallels\nbetween human decision times and model reasoning effort. Across three frontier\nmodels, reasoning effort consistently predicts human decision time. Both humans\nand models expended greater effort when important variables were held constant,\nsuggesting similar sensitivity to task difficulty and patterns consistent with\ndual-process theories of cognition. These findings show that AI reasoning\neffort mirrors human processing time in subjective judgments and underscores\nthe potential of reasoning traces for interpretability and decision-making.", "published": "2025-08-27 20:36:16", "link": "http://arxiv.org/abs/2508.20262v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Disentangling Latent Embeddings with Sparse Linear Concept Subspaces (SLiCS)", "abstract": "Vision-language co-embedding networks, such as CLIP, provide a latent\nembedding space with semantic information that is useful for downstream tasks.\nWe hypothesize that the embedding space can be disentangled to separate the\ninformation on the content of complex scenes by decomposing the embedding into\nmultiple concept-specific component vectors that lie in different subspaces. We\npropose a supervised dictionary learning approach to estimate a linear\nsynthesis model consisting of sparse, non-negative combinations of groups of\nvectors in the dictionary (atoms), whose group-wise activity matches the\nmulti-label information. Each concept-specific component is a non-negative\ncombination of atoms associated to a label. The group-structured dictionary is\noptimized through a novel alternating optimization with guaranteed convergence.\nExploiting the text co-embeddings, we detail how semantically meaningful\ndescriptions can be found based on text embeddings of words best approximated\nby a concept's group of atoms, and unsupervised dictionary learning can exploit\nzero-shot classification of training set images using the text embeddings of\nconcept labels to provide instance-wise multi-labels. We show that the\ndisentangled embeddings provided by our sparse linear concept subspaces (SLiCS)\nenable concept-filtered image retrieval (and conditional generation using\nimage-to-prompt) that is more precise. We also apply SLiCS to highly-compressed\nautoencoder embeddings from TiTok and the latent embedding from self-supervised\nDINOv2. Quantitative and qualitative results highlight the improved precision\nof the concept-filtered image retrieval for all embeddings.", "published": "2025-08-27 23:39:42", "link": "http://arxiv.org/abs/2508.20322v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Plug-in Feedback Self-adaptive Attention in CLIP for Training-free Open-Vocabulary Segmentation", "abstract": "CLIP exhibits strong visual-textual alignment but struggle with\nopen-vocabulary segmentation due to poor localization. Prior methods enhance\nspatial coherence by modifying intermediate attention. But, this coherence\nisn't consistently propagated to the final output due to subsequent operations\nsuch as projections. Additionally, intermediate attention lacks direct\ninteraction with text representations, such semantic discrepancy limits the\nfull potential of CLIP.\n  In this work, we propose a training-free, feedback-driven self-adaptive\nframework that adapts output-based patch-level correspondences back to the\nintermediate attention. The output predictions, being the culmination of the\nmodel's processing, encapsulate the most comprehensive visual and textual\nsemantics about each patch. Our approach enhances semantic consistency between\ninternal representations and final predictions by leveraging the model's\noutputs as a stronger spatial coherence prior. We design key modules, including\nattention isolation, confidence-based pruning for sparse adaptation, and\nadaptation ensemble, to effectively feedback the output coherence cues. Our\nmethod functions as a plug-in module, seamlessly integrating into four\nstate-of-the-art approaches with three backbones (ViT-B, ViT-L, ViT-H). We\nfurther validate our framework across multiple attention types (Q-K, self-self,\nand Proxy augmented with MAE, SAM, and DINO). Our approach consistently\nimproves their performance across eight benchmarks.", "published": "2025-08-27 20:47:03", "link": "http://arxiv.org/abs/2508.20265v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MedNet-PVS: A MedNeXt-Based Deep Learning Model for Automated Segmentation of Perivascular Spaces", "abstract": "Enlarged perivascular spaces (PVS) are increasingly recognized as biomarkers\nof cerebral small vessel disease, Alzheimer's disease, stroke, and\naging-related neurodegeneration. However, manual segmentation of PVS is\ntime-consuming and subject to moderate inter-rater reliability, while existing\nautomated deep learning models have moderate performance and typically fail to\ngeneralize across diverse clinical and research MRI datasets. We adapted\nMedNeXt-L-k5, a Transformer-inspired 3D encoder-decoder convolutional network,\nfor automated PVS segmentation. Two models were trained: one using a\nhomogeneous dataset of 200 T2-weighted (T2w) MRI scans from the Human\nConnectome Project-Aging (HCP-Aging) dataset and another using 40 heterogeneous\nT1-weighted (T1w) MRI volumes from seven studies across six scanners. Model\nperformance was evaluated using internal 5-fold cross validation (5FCV) and\nleave-one-site-out cross validation (LOSOCV). MedNeXt-L-k5 models trained on\nthe T2w images of the HCP-Aging dataset achieved voxel-level Dice scores of\n0.88+/-0.06 (white matter, WM), comparable to the reported inter-rater\nreliability of that dataset, and the highest yet reported in the literature.\nThe same models trained on the T1w images of the HCP-Aging dataset achieved a\nsubstantially lower Dice score of 0.58+/-0.09 (WM). Under LOSOCV, the model had\nvoxel-level Dice scores of 0.38+/-0.16 (WM) and 0.35+/-0.12 (BG), and\ncluster-level Dice scores of 0.61+/-0.19 (WM) and 0.62+/-0.21 (BG).\nMedNeXt-L-k5 provides an efficient solution for automated PVS segmentation\nacross diverse T1w and T2w MRI datasets. MedNeXt-L-k5 did not outperform the\nnnU-Net, indicating that the attention-based mechanisms present in\ntransformer-inspired models to provide global context are not required for high\naccuracy in PVS segmentation.", "published": "2025-08-27 20:24:12", "link": "http://arxiv.org/abs/2508.20256v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Efficient and Privacy-Protecting Background Removal for 2D Video Streaming using iPhone 15 Pro Max LiDAR", "abstract": "Light Detection and Ranging (LiDAR) technology in consumer-grade mobile\ndevices can be used as a replacement for traditional background removal and\ncompositing techniques. Unlike approaches such as chroma keying and trained AI\nmodels, LiDAR's depth information is independent of subject lighting, and\nperforms equally well in low-light and well-lit environments. We integrate the\nLiDAR and color cameras on the iPhone 15 Pro Max with GPU-based image\nprocessing. We use Apple's SwiftUI and Swift frameworks for user interface and\nbackend development, and Metal Shader Language (MSL) for realtime image\nenhancement at the standard iPhone streaming frame rate of 60 frames per\nsecond. The only meaningful limitations of the technology are the streaming\nbandwidth of the depth data, which currently reduces the depth map resolution\nto 320x240, and any pre-existing limitations of the LiDAR IR laser to reflect\naccurate depth from some materials. If the LiDAR resolution on a mobile device\nlike the iPhone can be improved to match the color image resolution, LiDAR\ncould feasibly become the preeminent method of background removal for video\napplications and photography.", "published": "2025-08-27 20:14:12", "link": "http://arxiv.org/abs/2508.20250v1", "categories": ["eess.IV", "cs.CV", "cs.MM", "68T45, 68U10", "I.4.6; I.4.8; H.5.1; I.2.10"], "primary_category": "eess.IV"}
{"title": "Universal vulnerability in strong modular networks with various degree distributions between inequality and equality", "abstract": "Generally, networks are classified into two sides of inequality and equality\nwith respect to the number of links at nodes by the types of degree\ndistributions. One side includes many social, technological, and biological\nnetworks which consist of a few nodes with many links, and many nodes with a\nfew links, whereas the other side consists of all nodes with an equal number of\nlinks. In comprehensive investigations between them, we have found that, as a\nmore equal network, the tolerance of whole connectivity is stronger without\nfragmentation against the malfunction of nodes in a wide class of randomized\nnetworks. However, we newly find that all networks which include typical\nwell-known network structures between them become extremely vulnerable, if a\nstrong modular (or community) structure is added with commonalities of areas,\ninterests, religions, purpose, and so on. These results will encourage avoiding\ntoo dense unions by connecting nodes and taking into account the balanced\nresource allocation between intra- and inter-links of weak communities. We must\nreconsider not only efficiency but also tolerance against attacks or disasters,\nunless no community that is really impossible.", "published": "2025-08-27 23:08:06", "link": "http://arxiv.org/abs/2508.20317v1", "categories": ["physics.soc-ph", "cs.DM", "cs.SI"], "primary_category": "physics.soc-ph"}
{"title": "A Survey of Affective Recommender Systems: Modeling Attitudes, Emotions, and Moods for Personalization", "abstract": "Affective Recommender Systems are an emerging class of intelligent systems\nthat aim to enhance personalization by aligning recommendations with users'\naffective states. Reflecting a growing interest, a number of surveys have been\npublished in this area, however they lack an organizing taxonomy grounded in\npsychology and they often study only specific types of affective states or\napplication domains. This survey addresses these limitations by providing a\ncomprehensive, systematic review of affective recommender systems across\ndiverse domains. Drawing from Scherer's typology of affective states, we\nintroduce a classification scheme that organizes systems into four main\ncategories: attitude aware, emotion aware, mood aware, and hybrid. We further\ndocument affective signal extraction techniques, system architectures, and\napplication areas, highlighting key trends, limitations, and open challenges.\nAs future research directions, we emphasize hybrid models that leverage\nmultiple types of affective states across different modalities, the development\nof large-scale affect-aware datasets, and the need to replace the folk\nvocabulary of affective states with a more precise terminology grounded in\ncognitive and social psychology. Through its systematic review of existing\nresearch and challenges, this survey aims to serve as a comprehensive reference\nand a useful guide for advancing academic research and industry applications in\naffect-driven personalization.", "published": "2025-08-27 21:50:32", "link": "http://arxiv.org/abs/2508.20289v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Multi-Agent Reinforcement Learning in Intelligent Transportation Systems: A Comprehensive Survey", "abstract": "The growing complexity of urban mobility and the demand for efficient,\nsustainable, and adaptive solutions have positioned Intelligent Transportation\nSystems (ITS) at the forefront of modern infrastructure innovation. At the core\nof ITS lies the challenge of autonomous decision-making across dynamic, large\nscale, and uncertain environments where multiple agents traffic signals,\nautonomous vehicles, or fleet units must coordinate effectively. Multi Agent\nReinforcement Learning (MARL) offers a promising paradigm for addressing these\nchallenges by enabling distributed agents to jointly learn optimal strategies\nthat balance individual objectives with system wide efficiency. This paper\npresents a comprehensive survey of MARL applications in ITS. We introduce a\nstructured taxonomy that categorizes MARL approaches according to coordination\nmodels and learning algorithms, spanning value based, policy based, actor\ncritic, and communication enhanced frameworks. Applications are reviewed across\nkey ITS domains, including traffic signal control, connected and autonomous\nvehicle coordination, logistics optimization, and mobility on demand systems.\nFurthermore, we highlight widely used simulation platforms such as SUMO, CARLA,\nand CityFlow that support MARL experimentation, along with emerging benchmarks.\nThe survey also identifies core challenges, including scalability, non\nstationarity, credit assignment, communication constraints, and the sim to real\ntransfer gap, which continue to hinder real world deployment.", "published": "2025-08-27 23:04:34", "link": "http://arxiv.org/abs/2508.20315v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FedReFT: Federated Representation Fine-Tuning with All-But-Me Aggregation", "abstract": "Parameter-efficient fine-tuning (PEFT) has attracted significant attention\nfor adapting large pre-trained models by modifying a small subset of\nparameters. Recently, Representation Fine-tuning (ReFT) has emerged as an\neffective alternative. ReFT shifts the fine-tuning paradigm from updating model\nweights to directly manipulating hidden representations that capture rich\nsemantic information, and performs better than state-of-the-art PEFTs in\nstandalone settings. However, its application in Federated Learning (FL)\nremains challenging due to heterogeneity in clients' data distributions, model\ncapacities, and computational resources. To address these challenges, we\nintroduce Federated Representation Fine-Tuning (FedReFT), a novel approach to\nfine-tune the client's hidden representation. FedReFT applies sparse\nintervention layers to steer hidden representations directly, offering a\nlightweight and semantically rich fine-tuning alternative ideal for edge\ndevices. However, representation-level updates are especially vulnerable to\naggregation mismatch under different task heterogeneity, where naive averaging\ncan corrupt semantic alignment. To mitigate this issue, we propose All-But-Me\n(ABM) aggregation, where each client receives the aggregated updates of others\nand partially incorporates them, enabling stable and personalized learning by\nbalancing local focus with global knowledge. We evaluate FedReFT on commonsense\nreasoning, arithmetic reasoning, instruction-tuning, and GLUE, where it\nconsistently outperforms state-of-the-art PEFT methods in FL, achieving 7x-15x\nhigher parameter efficiency compared to leading LoRA-based approaches.", "published": "2025-08-27 22:03:19", "link": "http://arxiv.org/abs/2508.20295v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Neural Spline Operators for Risk Quantification in Stochastic Systems", "abstract": "Accurately quantifying long-term risk probabilities in diverse stochastic\nsystems is essential for safety-critical control. However, existing\nsampling-based and partial differential equation (PDE)-based methods often\nstruggle to handle complex varying dynamics. Physics-informed neural networks\nlearn surrogate mappings for risk probabilities from varying system parameters\nof fixed and finite dimensions, yet can not account for functional variations\nin system dynamics. To address these challenges, we introduce physics-informed\nneural operator (PINO) methods to risk quantification problems, to learn\nmappings from varying \\textit{functional} system dynamics to corresponding risk\nprobabilities. Specifically, we propose Neural Spline Operators (NeSO), a PINO\nframework that leverages B-spline representations to improve training\nefficiency and achieve better initial and boundary condition enforcements,\nwhich are crucial for accurate risk quantification. We provide theoretical\nanalysis demonstrating the universal approximation capability of NeSO. We also\npresent two case studies, one with varying functional dynamics and another with\nhigh-dimensional multi-agent dynamics, to demonstrate the efficacy of NeSO and\nits significant online speed-up over existing methods. The proposed framework\nand the accompanying universal approximation theorem are expected to be\nbeneficial for other control or PDE-related problems beyond risk\nquantification.", "published": "2025-08-27 21:46:01", "link": "http://arxiv.org/abs/2508.20288v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Generalizable AI Model for Indoor Temperature Forecasting Across Sub-Saharan Africa", "abstract": "This study presents a lightweight, domain-informed AI model for predicting\nindoor temperatures in naturally ventilated schools and homes in Sub-Saharan\nAfrica. The model extends the Temp-AI-Estimator framework, trained on Tanzanian\nschool data, and evaluated on Nigerian schools and Gambian homes. It achieves\nrobust cross-country performance using only minimal accessible inputs, with\nmean absolute errors of 1.45{\\deg}C for Nigerian schools and 0.65{\\deg}C for\nGambian homes. These findings highlight AI's potential for thermal comfort\nmanagement in resource-constrained environments.", "published": "2025-08-27 20:32:31", "link": "http://arxiv.org/abs/2508.20260v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Latent Variable Modeling for Robust Causal Effect Estimation", "abstract": "Latent variable models provide a powerful framework for incorporating and\ninferring unobserved factors in observational data. In causal inference, they\nhelp account for hidden factors influencing treatment or outcome, thereby\naddressing challenges posed by missing or unmeasured covariates. This paper\nproposes a new framework that integrates latent variable modeling into the\ndouble machine learning (DML) paradigm to enable robust causal effect\nestimation in the presence of such hidden factors. We consider two scenarios:\none where a latent variable affects only the outcome, and another where it may\ninfluence both treatment and outcome. To ensure tractability, we incorporate\nlatent variables only in the second stage of DML, separating representation\nlearning from latent inference. We demonstrate the robustness and effectiveness\nof our method through extensive experiments on both synthetic and real-world\ndatasets.", "published": "2025-08-27 20:31:03", "link": "http://arxiv.org/abs/2508.20259v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Discovering equations from data: symbolic regression in dynamical systems", "abstract": "The process of discovering equations from data lies at the heart of physics\nand in many other areas of research, including mathematical ecology and\nepidemiology. Recently, machine learning methods known as symbolic regression\nhave automated this process. As several methods are available in the\nliterature, it is important to compare them, particularly for dynamic systems\nthat describe complex phenomena. In this paper, five symbolic regression\nmethods were used for recovering equations from nine dynamical processes,\nincluding chaotic dynamics and epidemic models, with the PySR method proving to\nbe the most suitable for inferring equations. Benchmark results demonstrate its\nhigh predictive power and accuracy, with some estimates being indistinguishable\nfrom the original analytical forms. These results highlight the potential of\nsymbolic regression as a robust tool for inferring and modelling real-world\nphenomena.", "published": "2025-08-27 20:30:09", "link": "http://arxiv.org/abs/2508.20257v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Beyond Optimization: Exploring Novelty Discovery in Autonomous Experiments", "abstract": "Autonomous experiments (AEs) are transforming how scientific research is\nconducted by integrating artificial intelligence with automated experimental\nplatforms. Current AEs primarily focus on the optimization of a predefined\ntarget; while accelerating this goal, such an approach limits the discovery of\nunexpected or unknown physical phenomena. Here, we introduce a novel framework,\nINS2ANE (Integrated Novelty Score-Strategic Autonomous Non-Smooth Exploration),\nto enhance the discovery of novel phenomena in autonomous experimentation. Our\nmethod integrates two key components: (1) a novelty scoring system that\nevaluates the uniqueness of experimental results, and (2) a strategic sampling\nmechanism that promotes exploration of under-sampled regions even if they\nappear less promising by conventional criteria. We validate this approach on a\npre-acquired dataset with a known ground truth comprising of image-spectral\npairs. We further implement the process on autonomous scanning probe microscopy\nexperiments. INS2ANE significantly increases the diversity of explored\nphenomena in comparison to conventional optimization routines, enhancing the\nlikelihood of discovering previously unobserved phenomena. These results\ndemonstrate the potential for AE to enhance the depth of scientific discovery;\nin combination with the efficiency provided by AEs, this approach promises to\naccelerate scientific research by simultaneously navigating complex\nexperimental spaces to uncover new phenomena.", "published": "2025-08-27 20:19:04", "link": "http://arxiv.org/abs/2508.20254v1", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "primary_category": "cs.LG"}
{"title": "Linking heterogeneous microstructure informatics with expert characterization knowledge through customized and hybrid vision-language representations for industrial qualification", "abstract": "Rapid and reliable qualification of advanced materials remains a bottleneck\nin industrial manufacturing, particularly for heterogeneous structures produced\nvia non-conventional additive manufacturing processes. This study introduces a\nnovel framework that links microstructure informatics with a range of expert\ncharacterization knowledge using customized and hybrid vision-language\nrepresentations (VLRs). By integrating deep semantic segmentation with\npre-trained multi-modal models (CLIP and FLAVA), we encode both visual\nmicrostructural data and textual expert assessments into shared\nrepresentations. To overcome limitations in general-purpose embeddings, we\ndevelop a customized similarity-based representation that incorporates both\npositive and negative references from expert-annotated images and their\nassociated textual descriptions. This allows zero-shot classification of\npreviously unseen microstructures through a net similarity scoring approach.\nValidation on an additively manufactured metal matrix composite dataset\ndemonstrates the framework's ability to distinguish between acceptable and\ndefective samples across a range of characterization criteria. Comparative\nanalysis reveals that FLAVA model offers higher visual sensitivity, while the\nCLIP model provides consistent alignment with the textual criteria. Z-score\nnormalization adjusts raw unimodal and cross-modal similarity scores based on\ntheir local dataset-driven distributions, enabling more effective alignment and\nclassification in the hybrid vision-language framework. The proposed method\nenhances traceability and interpretability in qualification pipelines by\nenabling human-in-the-loop decision-making without task-specific model\nretraining. By advancing semantic interoperability between raw data and expert\nknowledge, this work contributes toward scalable and domain-adaptable\nqualification strategies in engineering informatics.", "published": "2025-08-27 19:59:12", "link": "http://arxiv.org/abs/2508.20243v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "The Mathematician's Assistant: Integrating AI into Research Practice", "abstract": "The rapid development of artificial intelligence (AI), marked by\nbreakthroughs like 'AlphaEvolve' and 'Gemini Deep Think', is beginning to offer\npowerful new tools that have the potential to significantly alter the research\npractice in many areas of mathematics. This paper explores the current\nlandscape of publicly accessible large language models (LLMs) in a mathematical\nresearch context, based on developments up to August 2, 2025. Our analysis of\nrecent benchmarks, such as MathArena and the Open Proof Corpus (Balunovi\\'c et\nal., 2025; Dekoninck et al., 2025), reveals a complex duality: while\nstate-of-the-art models demonstrate strong abilities in solving problems and\nevaluating proofs, they also exhibit systematic flaws, including a lack of\nself-critique and a model depending discrepancy between final-answer accuracy\nand full-proof validity.\n  Based on these findings, we propose a durable framework for integrating AI\ninto the research workflow, centered on the principle of the augmented\nmathematician. In this model, the AI functions as a copilot under the critical\nguidance of the human researcher, an approach distilled into five guiding\nprinciples for effective and responsible use. We then systematically explore\nseven fundamental ways AI can be applied across the research lifecycle, from\ncreativity and ideation to the final writing process, demonstrating how these\nprinciples translate into concrete practice.\n  We conclude that the primary role of AI is currently augmentation rather than\nautomation. This requires a new skill set focused on strategic prompting,\ncritical verification, and methodological rigor in order to effectively use\nthese powerful tools.", "published": "2025-08-27 19:33:48", "link": "http://arxiv.org/abs/2508.20236v1", "categories": ["math.HO", "cs.AI", "cs.HC", "cs.LG", "00A35 (Primary), 68T07 (Secondary)", "I.2.7; H.5.2"], "primary_category": "math.HO"}
{"title": "Bounds on Perfect Node Classification: A Convex Graph Clustering Perspective", "abstract": "We present an analysis of the transductive node classification problem, where\nthe underlying graph consists of communities that agree with the node labels\nand node features. For node classification, we propose a novel optimization\nproblem that incorporates the node-specific information (labels and features)\nin a spectral graph clustering framework. Studying this problem, we demonstrate\na synergy between the graph structure and node-specific information. In\nparticular, we show that suitable node-specific information guarantees the\nsolution of our optimization problem perfectly recovering the communities,\nunder milder conditions than the bounds on graph clustering alone. We present\nalgorithmic solutions to our optimization problem and numerical experiments\nthat confirm such a synergy.", "published": "2025-08-27 19:22:35", "link": "http://arxiv.org/abs/2508.20231v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Coresets from Trajectories: Selecting Data via Correlation of Loss Differences", "abstract": "Deep learning models achieve state-of-the-art performance across domains but\nface scalability challenges in real-time or resource-constrained scenarios. To\naddress this, we propose Correlation of Loss Differences (CLD), a simple and\nscalable metric for coreset selection that identifies the most impactful\ntraining samples by measuring their alignment with the loss trajectories of a\nheld-out validation set. CLD is highly efficient, requiring only per-sample\nloss values computed at training checkpoints, and avoiding the costly gradient\nand curvature computations used in many existing subset selection methods. We\ndevelop a general theoretical framework that establishes convergence guarantees\nfor CLD-based coresets, demonstrating that the convergence error is\nupper-bounded by the alignment of the selected samples and the\nrepresentativeness of the validation set. On CIFAR-100 and ImageNet-1k,\nCLD-based coresets typically outperform or closely match state-of-the-art\nmethods across subset sizes, and remain within 1% of more computationally\nexpensive baselines even when not leading. CLD transfers effectively across\narchitectures (ResNet, VGG, DenseNet), enabling proxy-to-target selection with\n<1% degradation. Moreover, CLD is stable when using only early checkpoints,\nincurring negligible accuracy loss. Finally, CLD exhibits inherent bias\nreduction via per-class validation alignment, obviating the need for additional\nstratified sampling. Together, these properties make CLD a principled,\nefficient, stable, and transferable tool for scalable dataset optimization.", "published": "2025-08-27 19:18:39", "link": "http://arxiv.org/abs/2508.20230v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Validating Generative Agent-Based Models for Logistics and Supply Chain Management Research", "abstract": "Generative Agent-Based Models (GABMs) powered by large language models (LLMs)\noffer promising potential for empirical logistics and supply chain management\n(LSCM) research by enabling realistic simulation of complex human behaviors.\nUnlike traditional agent-based models, GABMs generate human-like responses\nthrough natural language reasoning, which creates potential for new\nperspectives on emergent LSCM phenomena. However, the validity of LLMs as\nproxies for human behavior in LSCM simulations is unknown. This study evaluates\nLLM equivalence of human behavior through a controlled experiment examining\ndyadic customer-worker engagements in food delivery scenarios. I test six\nstate-of-the-art LLMs against 957 human participants (477 dyads) using a\nmoderated mediation design. This study reveals a need to validate GABMs on two\nlevels: (1) human equivalence testing, and (2) decision process validation.\nResults reveal GABMs can effectively simulate human behaviors in LSCM; however,\nan equivalence-versus-process paradox emerges. While a series of Two One-Sided\nTests (TOST) for equivalence reveals some LLMs demonstrate surface-level\nequivalence to humans, structural equation modeling (SEM) reveals artificial\ndecision processes not present in human participants for some LLMs. These\nfindings show GABMs as a potentially viable methodological instrument in LSCM\nwith proper validation checks. The dual-validation framework also provides LSCM\nresearchers with a guide to rigorous GABM development. For practitioners, this\nstudy offers evidence-based assessment for LLM selection for operational tasks.", "published": "2025-08-27 19:30:08", "link": "http://arxiv.org/abs/2508.20234v1", "categories": ["cs.MA", "cs.AI", "cs.CY"], "primary_category": "cs.MA"}
{"title": "The Anatomy of a Personal Health Agent", "abstract": "Health is a fundamental pillar of human wellness, and the rapid advancements\nin large language models (LLMs) have driven the development of a new generation\nof health agents. However, the application of health agents to fulfill the\ndiverse needs of individuals in daily non-clinical settings is underexplored.\nIn this work, we aim to build a comprehensive personal health agent that is\nable to reason about multimodal data from everyday consumer wellness devices\nand common personal health records, and provide personalized health\nrecommendations. To understand end-users' needs when interacting with such an\nassistant, we conducted an in-depth analysis of web search and health forum\nqueries, alongside qualitative insights from users and health experts gathered\nthrough a user-centered design process. Based on these findings, we identified\nthree major categories of consumer health needs, each of which is supported by\na specialist sub-agent: (1) a data science agent that analyzes personal\ntime-series wearable and health record data, (2) a health domain expert agent\nthat integrates users' health and contextual data to generate accurate,\npersonalized insights, and (3) a health coach agent that synthesizes data\ninsights, guiding users using a specified psychological strategy and tracking\nusers' progress. Furthermore, we propose and develop the Personal Health Agent\n(PHA), a multi-agent framework that enables dynamic, personalized interactions\nto address individual health needs. To evaluate each sub-agent and the\nmulti-agent system, we conducted automated and human evaluations across 10\nbenchmark tasks, involving more than 7,000 annotations and 1,100 hours of\neffort from health experts and end-users. Our work represents the most\ncomprehensive evaluation of a health agent to date and establishes a strong\nfoundation towards the futuristic vision of a personal health agent accessible\nto everyone.", "published": "2025-08-27 14:38:46", "link": "http://arxiv.org/abs/2508.20148v1", "categories": ["cs.AI", "cs.HC", "cs.MA"], "primary_category": "cs.AI"}
{"title": "An Efficient Exponential Sum Approximation of Power-Law Kernels for Solving Fractional Differential Equation", "abstract": "In this work, we present a comprehensive framework for approximating the\nweakly singular power-law kernel $t^{\\alpha-1}$ of fractional integral and\ndifferential operators, where $\\alpha \\in (0,1)$ and $t \\in [\\delta,T]$ with\n$0<\\delta<T<\\infty$, using a finite sum of exponentials. This approximation\nmethod begins by substituting an exponential function into the Laplace\ntransform of the power function, followed by the application of the trapezoidal\nrule to approximate the resulting integral. To ensure computational\nfeasibility, the integral limits are truncated, leading to a finite exponential\nsum representation of the kernel. In contrast to earlier approaches, we\npre-specify the admitted computational cost (measured in terms of the number of\nexponentials) and minimize the approximation error. Furthermore, to reduce the\ncomputational cost while maintaining accuracy, we present a two-stage algorithm\nbased on Prony's method that compresses the exponential sum. The compressed\nkernel is then embedded into the Riemann-Liouville fractional integral and\napplied to solve fractional differential equations. To this end, we discuss two\nsolution strategies, namely (a) method based on piecewise constant\ninterpolation and (b) a transformation of the original fractional differential\nequation into a system of first-order ordinary differential equations (ODEs).\nThis reformulation makes the problem solvable by standard ODE solvers with low\ncomputational cost while retaining the accuracy benefits of the\nexponential-sum-approximation. Finally, we apply the proposed strategies to\nsolve some well-known fractional differential equations and demonstrate the\nadvantages, accuracy, and the experimental order of convergence of the methods\nthrough numerical results.", "published": "2025-08-27 22:56:17", "link": "http://arxiv.org/abs/2508.20311v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Randomized Krylov methods for inverse problems", "abstract": "In this paper we develop randomized Krylov subspace methods for efficiently\ncomputing regularized solutions to large-scale linear inverse problems.\nBuilding on the recently developed randomized Gram-Schmidt process, where\nsketched inner products are used to estimate inner products of high-dimensional\nvectors, we propose a randomized Golub-Kahan approach that works for general\nrectangular matrices. We describe new iterative solvers based on the randomized\nGolub-Kahan approach and show how they can be used for solving inverse problems\nwith rectangular matrices, thus extending the capabilities of the recently\nproposed randomized GMRES method. We also consider hybrid projection methods\nthat combine iterative projection methods, based on both the randomized Arnoldi\nand randomized Golub-Kahan factorizations, with Tikhonov regularization, where\nregularization parameters can be selected automatically during the iterative\nprocess. Numerical results from image deblurring and seismic tomography show\nthe potential benefits of these approaches.", "published": "2025-08-27 20:58:32", "link": "http://arxiv.org/abs/2508.20269v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Automated Runge-Kutta-Nystr\u00f6m time stepping for finite element methods in Irksome", "abstract": "Irksome is a library based on the Unified Form Language (UFL) that automates\nthe application of Runge-Kutta time-stepping methods for finite element spatial\ndiscretizations of partial differential equations (PDEs). This paper describes\nrecent updates to Irksome that allow users to express semidiscrete forms of\nPDEs that contain second-order temporal derivatives, whence it generates\nstage-coupled variational problems to be solved at each time step for\nRunge-Kutta-Nystr\\\"om methods. Firedrake then generates code for these\nvariational problems and provides a rich interface to PETSc for solving them.\nDirectly discretizing second-order time derivatives with Runge-Kutta-Nystr\\\"om\nmethods provides several advantages relative to discretizing a rewritten\nfirst-order system with a standard Runge-Kutta method. Besides working with an\ninterface closer to the problem formulation in UFL, avoiding these auxiliary\nvariables means that Runge-Kutta-Nystr\\\"om methods lead to smaller algebraic\nsystems and better run-time. Our numerical results indicate that, with\neffective preconditioning, fully implicit Runge-Kutta-Nystr\\\"om methods can be\nmade competitive with more traditional explicit methods for wave equations.\nThey are also (essentially) required to discretize wave-type equations with\nhigher-order spatial derivatives. We also provide numerical experiments for\nfully dynamic poroelasticity, a system of mixed temporal order, where our\ntime-stepping and algebraic solvers perform effectively even as we approach the\nincompressible limit.", "published": "2025-08-27 20:19:20", "link": "http://arxiv.org/abs/2508.20255v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Operator learning meets inverse problems: A probabilistic perspective", "abstract": "Operator learning offers a robust framework for approximating mappings\nbetween infinite-dimensional function spaces. It has also become a powerful\ntool for solving inverse problems in the computational sciences. This chapter\nsurveys methodological and theoretical developments at the intersection of\noperator learning and inverse problems. It begins by summarizing the\nprobabilistic and deterministic approaches to inverse problems, and pays\nspecial attention to emerging measure-centric formulations that treat observed\ndata or unknown parameters as probability distributions. The discussion then\nturns to operator learning by covering essential components such as data\ngeneration, loss functions, and widely used architectures for representing\nfunction-to-function maps. The core of the chapter centers on the end-to-end\ninverse operator learning paradigm, which aims to directly map observed data to\nthe solution of the inverse problem without requiring explicit knowledge of the\nforward map. It highlights the unique challenge that noise plays in this\ndata-driven inversion setting, presents structure-aware architectures for both\npoint predictions and posterior estimates, and surveys relevant theory for\nlinear and nonlinear inverse problems. The chapter also discusses the\nestimation of priors and regularizers, where operator learning is used more\nselectively within classical inversion algorithms.", "published": "2025-08-27 18:34:40", "link": "http://arxiv.org/abs/2508.20207v1", "categories": ["math.NA", "cs.LG", "cs.NA", "math.ST", "stat.TH", "35R30 (Primary) 68T07, 65N21 (Secondary)"], "primary_category": "math.NA"}
{"title": "Multi-Order Monte Carlo IMEX hierarchies for uncertainty quantification in multiscale hyperbolic systems", "abstract": "We introduce a novel Multi-Order Monte Carlo approach for uncertainty\nquantification in the context of multiscale time-dependent partial differential\nequations. The new framework leverages Implicit-Explicit Runge-Kutta time\nintegrators to satisfy the asymptotic-preserving property across different\ndiscretization orders of accuracy. In contrast to traditional Multi-Level Monte\nCarlo methods, which require costly hierarchical re-meshing, our method\nconstructs a multi-order hierarchy by varying both spatial and temporal\ndiscretization orders within the Monte Carlo framework. This enables efficient\nvariance reduction while naturally adapting to the multiple scales inherent in\nthe problem. The proposed method is particularly well-suited for hyperbolic\nsystems with stiff relaxation, kinetic equations, and low Mach number flows,\nwhere standard Multi-Level Monte Carlo techniques often encounter computational\nchallenges. Numerical experiments demonstrate that the novel Multi-Order Monte\nCarlo approach achieves substantial reduction of both error and variance while\nmaintaining asymptotic consistency in the asymptotic limit.", "published": "2025-08-27 18:04:49", "link": "http://arxiv.org/abs/2508.20187v1", "categories": ["math.NA", "cs.NA", "65C05, 65L04, 65L06, 65C30, 35L65, 35B40"], "primary_category": "math.NA"}
{"title": "Optimal Quoting under Adverse Selection and Price Reading", "abstract": "Over the past decade, many dealers have implemented algorithmic models to\nautomatically respond to RFQs and manage flows originating from their\nelectronic platforms. In parallel, building on the foundational work of Ho and\nStoll, and later Avellaneda and Stoikov, the academic literature on market\nmaking has expanded to address trade size distributions, client tiering,\ncomplex price dynamics, alpha signals, and the internalization versus\nexternalization dilemma in markets with dealer-to-client and interdealer-broker\nsegments. In this paper, we tackle two critical dimensions: adverse selection,\narising from the presence of informed traders, and price reading, whereby the\nmarket maker's own quotes inadvertently reveal the direction of their\ninventory. These risks are well known to practitioners, who routinely face\ninformed flows and algorithms capable of extracting signals from quoting\nbehavior. Yet they have received limited attention in the quantitative finance\nliterature, beyond stylized toy models with limited actionability. Extending\nthe existing literature, we propose a tractable and implementable framework\nthat enables market makers to adjust their quotes with greater awareness of\ninformational risk.", "published": "2025-08-27 19:04:52", "link": "http://arxiv.org/abs/2508.20225v1", "categories": ["q-fin.TR", "q-fin.RM"], "primary_category": "q-fin.TR"}
{"title": "Live Vocal Extraction from K-pop Performances", "abstract": "K-pop's global success is fueled by its dynamic performances and vibrant fan\nengagement. Inspired by K-pop fan culture, we propose a methodology for\nautomatically extracting live vocals from performances. We use a combination of\nsource separation, cross-correlation, and amplitude scaling to automatically\nremove pre-recorded vocals and instrumentals from a live performance. Our\npreliminary work introduces the task of live vocal separation and provides a\nfoundation for future research in this topic.", "published": "2025-08-27 21:14:21", "link": "http://arxiv.org/abs/2508.20273v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Error Analysis for Over-the-Air Federated Learning under Misaligned and Time-Varying Channels", "abstract": "This paper investigates an OFDM-based over-the-air federated learning\n(OTA-FL) system, where multiple mobile devices, e.g., unmanned aerial vehicles\n(UAVs), transmit local machine learning (ML) models to a central parameter\nserver (PS) for global model aggregation. The high mobility of local devices\nresults in imperfect channel estimation, leading to a misalignment problem,\ni.e., the model parameters transmitted from different local devices do not\narrive at the central PS simultaneously. Moreover, the mobility introduces\ntime-varying uploading channels, which further complicates the aggregation\nprocess. All these factors collectively cause distortions in the OTA-FL\ntraining process which are underexplored. To quantify these effects, we first\nderive a closed-form expression for a single-round global model update in terms\nof these channel imperfections. We then extend our analysis to capture multiple\nrounds of global updates, yielding a bound on the accumulated error in OTA-FL.\nWe validate our theoretical results via extensive numerical simulations, which\ncorroborate our derived analysis.", "published": "2025-08-27 21:19:54", "link": "http://arxiv.org/abs/2508.20277v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Enhancing Automatic Modulation Recognition With a Reconstruction-Driven Vision Transformer Under Limited Labels", "abstract": "Automatic modulation recognition (AMR) is critical for cognitive radio,\nspectrum monitoring, and secure wireless communication. However, existing\nsolutions often rely on large labeled datasets or multi-stage training\npipelines, which limit scalability and generalization in practice. We propose a\nunified Vision Transformer (ViT) framework that integrates supervised,\nself-supervised, and reconstruction objectives. The model combines a ViT\nencoder, a lightweight convolutional decoder, and a linear classifier; the\nreconstruction branch maps augmented signals back to their originals, anchoring\nthe encoder to fine-grained I/Q structure. This strategy promotes robust,\ndiscriminative feature learning during pretraining, while partial label\nsupervision in fine-tuning enables effective classification with limited\nlabels. On the RML2018.01A dataset, our approach outperforms supervised CNN and\nViT baselines in low-label regimes, approaches ResNet-level accuracy with only\n15-20% labeled data, and maintains strong performance across varying SNR\nlevels. Overall, the framework provides a simple, generalizable, and\nlabel-efficient solution for AMR.", "published": "2025-08-27 18:11:47", "link": "http://arxiv.org/abs/2508.20193v1", "categories": ["cs.CV", "eess.SP"], "primary_category": "cs.CV"}
