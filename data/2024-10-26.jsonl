{"title": "Vulnerability of LLMs to Vertically Aligned Text Manipulations", "abstract": "Text classification involves categorizing a given text, such as determining\nits sentiment or identifying harmful content. With the advancement of large\nlanguage models (LLMs), these models have become highly effective at performing\ntext classification tasks. However, they still show vulnerabilities to\nvariations in text formatting. Recent research demonstrates that modifying\ninput formats, such as vertically aligning words for encoder-based models, can\nsubstantially lower accuracy in text classification tasks. While easily\nunderstood by humans, these inputs can significantly mislead models, posing a\npotential risk of bypassing detection in real-world scenarios involving harmful\nor sensitive information. With the expanding application of LLMs, a crucial\nquestion arises: Do decoder-based LLMs exhibit similar vulnerabilities to\nvertically formatted text input? In this paper, we investigate the impact of\nvertical text input on the performance of various LLMs across multiple text\nclassification datasets and analyze the underlying causes. Our findings are as\nfollows: (i) Vertical text input significantly degrades the accuracy of LLMs in\ntext classification tasks. (ii) Chain of Thought (CoT) reasoning does not help\nLLMs recognize vertical input or mitigate its vulnerability, but few-shot\nlearning with careful analysis does. (iii) We explore the underlying cause of\nthe vulnerability by analyzing the inherent issues in tokenization and\nattention matrices.", "published": "2024-10-26 00:16:08", "link": "http://arxiv.org/abs/2410.20016v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hybrid Deep Learning for Legal Text Analysis: Predicting Punishment\n  Durations in Indonesian Court Rulings", "abstract": "Limited public understanding of legal processes and inconsistent verdicts in\nthe Indonesian court system led to widespread dissatisfaction and increased\nstress on judges. This study addresses these issues by developing a deep\nlearning-based predictive system for court sentence lengths. Our hybrid model,\ncombining CNN and BiLSTM with attention mechanism, achieved an R-squared score\nof 0.5893, effectively capturing both local patterns and long-term dependencies\nin legal texts. While document summarization proved ineffective, using only the\ntop 30% most frequent tokens increased prediction performance, suggesting that\nfocusing on core legal terminology balances information retention and\ncomputational efficiency. We also implemented a modified text normalization\nprocess, addressing common errors like misspellings and incorrectly merged\nwords, which significantly improved the model's performance. These findings\nhave important implications for automating legal document processing, aiding\nboth professionals and the public in understanding court judgments. By\nleveraging advanced NLP techniques, this research contributes to enhancing\ntransparency and accessibility in the Indonesian legal system, paving the way\nfor more consistent and comprehensible legal decisions.", "published": "2024-10-26 07:07:48", "link": "http://arxiv.org/abs/2410.20104v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reasoning or a Semblance of it? A Diagnostic Study of Transitive\n  Reasoning in LLMs", "abstract": "Evaluating Large Language Models (LLMs) on reasoning benchmarks demonstrates\ntheir ability to solve compositional questions. However, little is known of\nwhether these models engage in genuine logical reasoning or simply rely on\nimplicit cues to generate answers. In this paper, we investigate the transitive\nreasoning capabilities of two distinct LLM architectures, LLaMA 2 and Flan-T5,\nby manipulating facts within two compositional datasets: QASC and Bamboogle. We\ncontrolled for potential cues that might influence the models' performance,\nincluding (a) word/phrase overlaps across sections of test input; (b) models'\ninherent knowledge during pre-training or fine-tuning; and (c) Named Entities.\nOur findings reveal that while both models leverage (a), Flan-T5 shows more\nresilience to experiments (b and c), having less variance than LLaMA 2. This\nsuggests that models may develop an understanding of transitivity through\nfine-tuning on knowingly relevant datasets, a hypothesis we leave to future\nwork.", "published": "2024-10-26 15:09:07", "link": "http://arxiv.org/abs/2410.20200v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DAWN-ICL: Strategic Planning of Problem-solving Trajectories for\n  Zero-Shot In-Context Learning", "abstract": "Zero-shot in-context learning (ZS-ICL) aims to conduct in-context learning\n(ICL) without using human-annotated demonstrations. Most ZS-ICL methods use\nlarge language models (LLMs) to generate (input, label) pairs as\npseudo-demonstrations and leverage historical pseudo-demonstrations to help\nsolve the current problem. They assume that problems are from the same task and\ntraverse them in a random order. However, in real-world scenarios, problems\nusually come from diverse tasks, and only a few belong to the same task. The\nrandom traversing order may generate unreliable pseudo-demonstrations and lead\nto error accumulation. To address this problem, we reformulate ZS-ICL as a\nplanning problem and propose a Demonstration-aware Monte Carlo Tree Search\n(MCTS) approach (DAWN-ICL), which leverages MCTS to strategically plan the\nproblem-solving trajectories for ZS-ICL. In addition, to achieve effective and\nefficient Q value estimation, we propose a novel demonstration-aware Q-value\nfunction and use it to enhance the selection phase and accelerate the expansion\nand simulation phases in MCTS. Extensive experiments demonstrate the\neffectiveness and efficiency of DAWN-ICL on in-domain and cross-domain\nscenarios, and it even outperforms ICL using human-annotated labels. The code\nis available at https://github.com/RUCAIBox/MCTS4ZSICL.", "published": "2024-10-26 16:17:02", "link": "http://arxiv.org/abs/2410.20215v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed\n  Intent Discovery", "abstract": "New intent discovery is a crucial capability for task-oriented dialogue\nsystems. Existing methods focus on transferring in-domain (IND) prior knowledge\nto out-of-domain (OOD) data through pre-training and clustering stages. They\neither handle the two processes in a pipeline manner, which exhibits a gap\nbetween intent representation and clustering process or use typical contrastive\nclustering that overlooks the potential supervised signals from the whole data.\nBesides, they often individually deal with open intent discovery or OOD\nsettings. To this end, we propose a Pseudo-Label enhanced Prototypical\nContrastive Learning (PLPCL) model for uniformed intent discovery. We\niteratively utilize pseudo-labels to explore potential positive/negative\nsamples for contrastive learning and bridge the gap between representation and\nclustering. To enable better knowledge transfer, we design a prototype learning\nmethod integrating the supervised and pseudo signals from IND and OOD samples.\nIn addition, our method has been proven effective in two different settings of\ndiscovering new intents. Experiments on three benchmark datasets and two task\nsettings demonstrate the effectiveness of our approach.", "published": "2024-10-26 16:22:45", "link": "http://arxiv.org/abs/2410.20219v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative linguistics contribution to artificial intelligence: Where\n  this contribution lies?", "abstract": "This article aims to characterize Generative linguistics (GL) contribution to\nartificial intelligence (AI), alluding to the debate among linguists and AI\nscientists on whether linguistics belongs to humanities or science. In this\narticle, I will try not to be biased as a linguist, studying the phenomenon\nfrom an independent scientific perspective. The article walks the\nresearcher/reader through the scientific theorems and rationales involved in AI\nwhich belong from GL, specifically the Chomsky School. It, thus, provides good\nevidence from syntax, semantics, language faculty, Universal Grammar,\ncomputational system of human language, language acquisition, human brain,\nprogramming languages (e.g. Python), Large Language Models, and unbiased AI\nscientists that this contribution is huge, and that this contribution cannot be\ndenied. It concludes that however the huge GL contribution to AI, there are\nstill points of divergence including the nature and type of language input.", "published": "2024-10-26 16:27:34", "link": "http://arxiv.org/abs/2410.20221v3", "categories": ["cs.CL", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Ambiguity is the last thing you need", "abstract": "Clear legal language forms the backbone of a contract for numerous reasons.\nDisputes often arise between contract parties where ambiguous language has been\nused and parties often disagree on the meaning or effect of the words.\nUnambiguous language can also be important where there is an imbalance of\nbargaining strength between the parties, for instance where a business is\ncontracting with a consumer, where the law actually requires plain language to\nbe used. Thus, plain language minimises misinterpretation and prevents future\nlitigation. Contracts become ambiguous when the language used is vague,\nimprecise, or open to multiple interpretations and this is due to the vast\nnumber of synonyms in the English Language which creates differences in\ninterpretation between the meaning of the language. Ambiguity has always formed\na prevalent issue in case-law, with a large percentage of cases based on\nambiguous language. Thus, from an outside perspective the legal sector should\nlook forward to ways of reducing this.", "published": "2024-10-26 16:35:45", "link": "http://arxiv.org/abs/2410.20222v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fast Best-of-N Decoding via Speculative Rejection", "abstract": "The safe and effective deployment of Large Language Models (LLMs) involves a\ncritical step called alignment, which ensures that the model's responses are in\naccordance with human preferences. Prevalent alignment techniques, such as DPO,\nPPO and their variants, align LLMs by changing the pre-trained model weights\nduring a phase called post-training. While predominant, these post-training\nmethods add substantial complexity before LLMs can be deployed. Inference-time\nalignment methods avoid the complex post-training step and instead bias the\ngeneration towards responses that are aligned with human preferences. The\nbest-known inference-time alignment method, called Best-of-N, is as effective\nas the state-of-the-art post-training procedures. Unfortunately, Best-of-N\nrequires vastly more resources at inference time than standard decoding\nstrategies, which makes it computationally not viable. In this work, we\nintroduce Speculative Rejection, a computationally-viable inference-time\nalignment algorithm. It generates high-scoring responses according to a given\nreward model, like Best-of-N does, while being between 16 to 32 times more\ncomputationally efficient.", "published": "2024-10-26 23:20:48", "link": "http://arxiv.org/abs/2410.20290v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attacks against Abstractive Text Summarization Models through Lead Bias\n  and Influence Functions", "abstract": "Large Language Models have introduced novel opportunities for text\ncomprehension and generation. Yet, they are vulnerable to adversarial\nperturbations and data poisoning attacks, particularly in tasks like text\nclassification and translation. However, the adversarial robustness of\nabstractive text summarization models remains less explored. In this work, we\nunveil a novel approach by exploiting the inherent lead bias in summarization\nmodels, to perform adversarial perturbations. Furthermore, we introduce an\ninnovative application of influence functions, to execute data poisoning, which\ncompromises the model's integrity. This approach not only shows a skew in the\nmodels behavior to produce desired outcomes but also shows a new behavioral\nchange, where models under attack tend to generate extractive summaries rather\nthan abstractive summaries.", "published": "2024-10-26 00:35:15", "link": "http://arxiv.org/abs/2410.20019v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Think Carefully and Check Again! Meta-Generation Unlocking LLMs for\n  Low-Resource Cross-Lingual Summarization", "abstract": "Cross-lingual summarization (CLS) aims to generate a summary for the source\ntext in a different target language. Currently, instruction-tuned large\nlanguage models (LLMs) excel at various English tasks. However, unlike\nlanguages such as English, Chinese or Spanish, for those relatively\nlow-resource languages with limited usage or data, recent studies have shown\nthat LLMs' performance on CLS tasks remains unsatisfactory even with few-shot\nsettings. This raises the question: Are LLMs capable of handling cross-lingual\nsummarization tasks for low-resource languages? To resolve this question, we\nfully explore the potential of large language models on cross-lingual\nsummarization task for low-resource languages through our four-step zero-shot\nmethod: Summarization, Improvement, Translation and Refinement (SITR) with\ncorrespondingly designed prompts. We test our proposed method with multiple\nLLMs on two well-known cross-lingual summarization datasets with various\nlow-resource target languages. The results show that: i) GPT-3.5 and GPT-4\nsignificantly and consistently outperform other baselines when using our\nzero-shot SITR methods. ii) By employing our proposed method, we unlock the\npotential of LLMs, enabling them to effectively handle cross-lingual\nsummarization tasks for relatively low-resource languages.", "published": "2024-10-26 00:39:44", "link": "http://arxiv.org/abs/2410.20021v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dynamic layer selection in decoder-only transformers", "abstract": "The vast size of Large Language Models (LLMs) has prompted a search to\noptimize inference. One effective approach is dynamic inference, which adapts\nthe architecture to the sample-at-hand to reduce the overall computational\ncost. We empirically examine two common dynamic inference methods for natural\nlanguage generation (NLG): layer skipping and early exiting. We find that a\npre-trained decoder-only model is significantly more robust to layer removal\nvia layer skipping, as opposed to early exit. We demonstrate the difficulty of\nusing hidden state information to adapt computation on a per-token basis for\nlayer skipping. Finally, we show that dynamic computation allocation on a\nper-sequence basis holds promise for significant efficiency gains by\nconstructing an oracle controller. Remarkably, we find that there exists an\nallocation which achieves equal performance to the full model using only 23.3%\nof its layers on average.", "published": "2024-10-26 00:44:11", "link": "http://arxiv.org/abs/2410.20022v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Beyond Fine-Tuning: Effective Strategies for Mitigating Hallucinations\n  in Large Language Models for Data Analytics", "abstract": "Large Language Models (LLMs) have become increasingly important in natural\nlanguage processing, enabling advanced data analytics through natural language\nqueries. However, these models often generate \"hallucinations\"-inaccurate or\nfabricated information-that can undermine their reliability in critical\ndata-driven decision-making. Addressing the challenge of hallucinations is\nessential to improve the accuracy and trustworthiness of LLMs in processing\nnatural language queries. This research focuses on mitigating hallucinations in\nLLMs, specifically within the context of data analytics. We introduce and\nevaluate four targeted strategies: Structured Output Generation, Strict Rules\nEnforcement, System Prompt Enhancements, and Semantic Layer Integration. Our\nfindings show that these methods are more effective than traditional\nfine-tuning approaches in reducing hallucinations, offering a more reliable\nframework for deploying LLMs in natural language queries for data analytics.\nThis research demonstrates the potential of these strategies to enhance the\naccuracy of LLM-driven data queries, ensuring more dependable results in\ndata-driven environments.", "published": "2024-10-26 00:45:42", "link": "http://arxiv.org/abs/2410.20024v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LinBridge: A Learnable Framework for Interpreting Nonlinear Neural\n  Encoding Models", "abstract": "Neural encoding of artificial neural networks (ANNs) links their\ncomputational representations to brain responses, offering insights into how\nthe brain processes information. Current studies mostly use linear encoding\nmodels for clarity, even though brain responses are often nonlinear. This has\nsparked interest in developing nonlinear encoding models that are still\ninterpretable. To address this problem, we propose LinBridge, a learnable and\nflexible framework based on Jacobian analysis for interpreting nonlinear\nencoding models. LinBridge posits that the nonlinear mapping between ANN\nrepresentations and neural responses can be factorized into a linear inherent\ncomponent that approximates the complex nonlinear relationship, and a mapping\nbias that captures sample-selective nonlinearity. The Jacobian matrix, which\nreflects output change rates relative to input, enables the analysis of\nsample-selective mapping in nonlinear models. LinBridge employs a\nself-supervised learning strategy to extract both the linear inherent component\nand nonlinear mapping biases from the Jacobian matrices of the test set,\nallowing it to adapt effectively to various nonlinear encoding models. We\nvalidate the LinBridge framework in the scenario of neural visual encoding,\nusing computational visual representations from CLIP-ViT to predict brain\nactivity recorded via functional magnetic resonance imaging (fMRI). Our\nexperimental results demonstrate that: 1) the linear inherent component\nextracted by LinBridge accurately reflects the complex mappings of nonlinear\nneural encoding models; 2) the sample-selective mapping bias elucidates the\nvariability of nonlinearity across different levels of the visual processing\nhierarchy. This study presents a novel tool for interpreting nonlinear neural\nencoding models and offers fresh evidence about hierarchical nonlinearity\ndistribution in the visual cortex.", "published": "2024-10-26 03:02:34", "link": "http://arxiv.org/abs/2410.20053v1", "categories": ["q-bio.NC", "cs.CL"], "primary_category": "q-bio.NC"}
{"title": "Multi-Field Adaptive Retrieval", "abstract": "Document retrieval for tasks such as search and retrieval-augmented\ngeneration typically involves datasets that are unstructured: free-form text\nwithout explicit internal structure in each document. However, documents can\nhave a structured form, consisting of fields such as an article title, message\nbody, or HTML header. To address this gap, we introduce Multi-Field Adaptive\nRetrieval (MFAR), a flexible framework that accommodates any number of and any\ntype of document indices on structured data. Our framework consists of two main\nsteps: (1) the decomposition of an existing document into fields, each indexed\nindependently through dense and lexical methods, and (2) learning a model which\nadaptively predicts the importance of a field by conditioning on the document\nquery, allowing on-the-fly weighting of the most likely field(s). We find that\nour approach allows for the optimized use of dense versus lexical\nrepresentations across field types, significantly improves in document ranking\nover a number of existing retrievers, and achieves state-of-the-art performance\nfor multi-field structured data.", "published": "2024-10-26 03:07:22", "link": "http://arxiv.org/abs/2410.20056v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "UniHGKR: Unified Instruction-aware Heterogeneous Knowledge Retrievers", "abstract": "Existing information retrieval (IR) models often assume a homogeneous\nstructure for knowledge sources and user queries, limiting their applicability\nin real-world settings where retrieval is inherently heterogeneous and diverse.\nIn this paper, we introduce UniHGKR, a unified instruction-aware heterogeneous\nknowledge retriever that (1) builds a unified retrieval space for heterogeneous\nknowledge and (2) follows diverse user instructions to retrieve knowledge of\nspecified types. UniHGKR consists of three principal stages: heterogeneous\nself-supervised pretraining, text-anchored embedding alignment, and\ninstruction-aware retriever fine-tuning, enabling it to generalize across\nvaried retrieval contexts. This framework is highly scalable, with a BERT-based\nversion and a UniHGKR-7B version trained on large language models. Also, we\nintroduce CompMix-IR, the first native heterogeneous knowledge retrieval\nbenchmark. It includes two retrieval scenarios with various instructions, over\n9,400 question-answer (QA) pairs, and a corpus of 10 million entries, covering\nfour different types of data. Extensive experiments show that UniHGKR\nconsistently outperforms state-of-the-art methods on CompMix-IR, achieving up\nto 6.36% and 54.23% relative improvements in two scenarios, respectively.\nFinally, by equipping our retriever for open-domain heterogeneous QA systems,\nwe achieve a new state-of-the-art result on the popular ConvMix task, with an\nabsolute improvement of up to 5.90 points.", "published": "2024-10-26 12:34:07", "link": "http://arxiv.org/abs/2410.20163v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "A Stack-Propagation Framework for Low-Resource Personalized Dialogue\n  Generation", "abstract": "With the resurgent interest in building open-domain dialogue systems, the\ndialogue generation task has attracted increasing attention over the past few\nyears. This task is usually formulated as a conditional generation problem,\nwhich aims to generate a natural and meaningful response given dialogue\ncontexts and specific constraints, such as persona. And maintaining a\nconsistent persona is essential for the dialogue systems to gain trust from the\nusers. Although tremendous advancements have been brought, traditional\npersona-based dialogue models are typically trained by leveraging a large\nnumber of persona-dense dialogue examples. Yet, such persona-dense training\ndata are expensive to obtain, leading to a limited scale. This work presents a\nnovel approach to learning from limited training examples by regarding\nconsistency understanding as a regularization of response generation. To this\nend, we propose a novel stack-propagation framework for learning a generation\nand understanding pipeline.Specifically, the framework stacks a Transformer\nencoder and two Transformer decoders, where the first decoder models response\ngeneration and the second serves as a regularizer and jointly models response\ngeneration and consistency understanding. The proposed framework can benefit\nfrom the stacked encoder and decoders to learn from much smaller personalized\ndialogue data while maintaining competitive performance. Under different\nlow-resource settings, subjective and objective evaluations prove that the\nstack-propagation framework outperforms strong baselines in response quality\nand persona consistency and largely overcomes the shortcomings of traditional\nmodels that rely heavily on the persona-dense dialogue data.", "published": "2024-10-26 13:09:21", "link": "http://arxiv.org/abs/2410.20174v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Inflation Nowcasting with LLM: Sentiment Analysis on News", "abstract": "This study explores the integration of large language models (LLMs) into\nclassic inflation nowcasting frameworks, particularly in light of high\ninflation volatility periods such as the COVID-19 pandemic. We propose\nInflaBERT, a BERT-based LLM fine-tuned to predict inflation-related sentiment\nin news. We use this model to produce NEWS, an index capturing the monthly\nsentiment of the news regarding inflation. Incorporating our expectation index\ninto the Cleveland Fed's model, which is only based on macroeconomic\nautoregressive processes, shows a marginal improvement in nowcast accuracy\nduring the pandemic. This highlights the potential of combining sentiment\nanalysis with traditional economic indicators, suggesting further research to\nrefine these methodologies for better real-time inflation monitoring. The\nsource code is available at https://github.com/paultltc/InflaBERT.", "published": "2024-10-26 15:05:01", "link": "http://arxiv.org/abs/2410.20198v1", "categories": ["cs.CE", "cs.CL"], "primary_category": "cs.CE"}
{"title": "Looking Beyond The Top-1: Transformers Determine Top Tokens In Order", "abstract": "Understanding the inner workings of Transformers is crucial for achieving\nmore accurate and efficient predictions. In this work, we analyze the\ncomputation performed by Transformers in the layers after the top-1 prediction\nhas become fixed, which has been previously referred to as the \"saturation\nevent\". We expand the concept of saturation events for top-k tokens,\ndemonstrating that similar saturation events occur across language, vision, and\nspeech models. We find that these saturation events happen in order of the\ncorresponding tokens' ranking, i.e., the model first decides on the top ranking\ntoken, then the second highest ranking token, and so on. This phenomenon seems\nintrinsic to the Transformer architecture, occurring across different\narchitectural variants (decoder-only, encoder-only, and to a lesser extent\nfull-Transformer), and even in untrained Transformers. We propose an underlying\nmechanism of task transition for this sequential saturation, where task k\ncorresponds to predicting the k-th most probable token, and the saturation\nevents are in fact discrete transitions between the tasks. In support of this\nwe show that it is possible to predict the current task from hidden layer\nembedding. Furthermore, using an intervention method we demonstrate that we can\ncause the model to switch from one task to the next. Finally, leveraging our\nfindings, we introduce a novel token-level early-exit strategy, which surpasses\nexisting methods in balancing performance and efficiency.", "published": "2024-10-26 16:00:38", "link": "http://arxiv.org/abs/2410.20210v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Survey of Large Language Models for Arabic Language and its Dialects", "abstract": "This survey offers a comprehensive overview of Large Language Models (LLMs)\ndesigned for Arabic language and its dialects. It covers key architectures,\nincluding encoder-only, decoder-only, and encoder-decoder models, along with\nthe datasets used for pre-training, spanning Classical Arabic, Modern Standard\nArabic, and Dialectal Arabic. The study also explores monolingual, bilingual,\nand multilingual LLMs, analyzing their architectures and performance across\ndownstream tasks, such as sentiment analysis, named entity recognition, and\nquestion answering. Furthermore, it assesses the openness of Arabic LLMs based\non factors, such as source code availability, training data, model weights, and\ndocumentation. The survey highlights the need for more diverse dialectal\ndatasets and attributes the importance of openness for research reproducibility\nand transparency. It concludes by identifying key challenges and opportunities\nfor future research and stressing the need for more inclusive and\nrepresentative models.", "published": "2024-10-26 17:48:20", "link": "http://arxiv.org/abs/2410.20238v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Training the Untrainable: Introducing Inductive Bias via\n  Representational Alignment", "abstract": "We demonstrate that architectures which traditionally are considered to be\nill-suited for a task can be trained using inductive biases from another\narchitecture. Networks are considered untrainable when they overfit, underfit,\nor converge to poor results even when tuning their hyperparameters. For\nexample, plain fully connected networks overfit on object recognition while\ndeep convolutional networks without residual connections underfit. The\ntraditional answer is to change the architecture to impose some inductive bias,\nalthough what that bias is remains unknown. We introduce guidance, where a\nguide network guides a target network using a neural distance function. The\ntarget is optimized to perform well and to match its internal representations,\nlayer-by-layer, to those of the guide; the guide is unchanged. If the guide is\ntrained, this transfers over part of the architectural prior and knowledge of\nthe guide to the target. If the guide is untrained, this transfers over only\npart of the architectural prior of the guide. In this manner, we can\ninvestigate what kinds of priors different architectures place on untrainable\nnetworks such as fully connected networks. We demonstrate that this method\novercomes the immediate overfitting of fully connected networks on vision\ntasks, makes plain CNNs competitive to ResNets, closes much of the gap between\nplain vanilla RNNs and Transformers, and can even help Transformers learn tasks\nwhich RNNs can perform more easily. We also discover evidence that better\ninitializations of fully connected networks likely exist to avoid overfitting.\nOur method provides a mathematical tool to investigate priors and\narchitectures, and in the long term, may demystify the dark art of architecture\ncreation, even perhaps turning architectures into a continuous optimizable\nparameter of the network.", "published": "2024-10-26 01:04:03", "link": "http://arxiv.org/abs/2410.20035v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Architectural Flaw Detection in Civil Engineering Using GPT-4", "abstract": "The application of artificial intelligence (AI) in civil engineering presents\na transformative approach to enhancing design quality and safety. This paper\ninvestigates the potential of the advanced LLM GPT4 Turbo vision model in\ndetecting architectural flaws during the design phase, with a specific focus on\nidentifying missing doors and windows. The study evaluates the model's\nperformance through metrics such as precision, recall, and F1 score,\ndemonstrating AI's effectiveness in accurately detecting flaws compared to\nhuman-verified data. Additionally, the research explores AI's broader\ncapabilities, including identifying load-bearing issues, material weaknesses,\nand ensuring compliance with building codes. The findings highlight how AI can\nsignificantly improve design accuracy, reduce costly revisions, and support\nsustainable practices, ultimately revolutionizing the civil engineering field\nby ensuring safer, more efficient, and aesthetically optimized structures.", "published": "2024-10-26 01:10:04", "link": "http://arxiv.org/abs/2410.20036v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RARe: Retrieval Augmented Retrieval with In-Context Examples", "abstract": "We investigate whether in-context examples, widely used in decoder-only\nlanguage models (LLMs), can improve embedding model performance in retrieval\ntasks. Unlike in LLMs, naively prepending in-context examples (query-document\npairs) to the target query at inference time does not work out of the box. We\nintroduce a simple approach to enable retrievers to use in-context examples.\nOur approach, RARe, finetunes a pre-trained model with in-context examples\nwhose query is semantically similar to the target query. This can be applied to\nadapt various base architectures (i.e., decoder-only language models, retriever\nmodels) and consistently achieves performance gains of up to +2.72% nDCG across\nvarious open-domain retrieval datasets (BeIR, RAR-b). In particular, we find\nRARe exhibits stronger out-of-domain generalization compared to models using\nqueries without in-context examples, similar to what is seen for in-context\nlearning in LLMs. We further provide analysis on the design choices of\nin-context example augmentation and lay the foundation for future work in this\nspace.", "published": "2024-10-26 05:46:20", "link": "http://arxiv.org/abs/2410.20088v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Causal Abstraction in Model Interpretability: A Compact Survey", "abstract": "The pursuit of interpretable artificial intelligence has led to significant\nadvancements in the development of methods that aim to explain the\ndecision-making processes of complex models, such as deep learning systems.\nAmong these methods, causal abstraction stands out as a theoretical framework\nthat provides a principled approach to understanding and explaining the causal\nmechanisms underlying model behavior. This survey paper delves into the realm\nof causal abstraction, examining its theoretical foundations, practical\napplications, and implications for the field of model interpretability.", "published": "2024-10-26 12:24:28", "link": "http://arxiv.org/abs/2410.20161v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLMs Can Evolve Continually on Modality for X-Modal Reasoning", "abstract": "Multimodal Large Language Models (MLLMs) have gained significant attention\ndue to their impressive capabilities in multimodal understanding. However,\nexisting methods rely heavily on extensive modal-specific pretraining and\njoint-modal tuning, leading to significant computational burdens when expanding\nto new modalities. In this paper, we propose PathWeave, a flexible and scalable\nframework with modal-Path sWitching and ExpAnsion abilities that enables MLLMs\nto continually EVolve on modalities for $\\mathbb{X}$-modal reasoning. We\nleverage the concept of Continual Learning and develop an incremental training\nstrategy atop pre-trained MLLMs, enabling their expansion to new modalities\nusing uni-modal data, without executing joint-modal pretraining. In detail, a\nnovel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal and\ncross-modal adapters are seamlessly integrated to facilitate efficient modality\nalignment and collaboration. Additionally, an MoE-based gating module is\napplied between two types of adapters to further enhance the multimodal\ninteraction. To investigate the proposed method, we establish a challenging\nbenchmark called Continual Learning of Modality (MCL), which consists of\nhigh-quality QA data from five distinct modalities: image, video, audio, depth\nand point cloud. Extensive experiments demonstrate the effectiveness of the\nproposed AnA framework on learning plasticity and memory stability during\ncontinual learning. Furthermore, PathWeave performs comparably to\nstate-of-the-art MLLMs while concurrently reducing parameter training burdens\nby 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave", "published": "2024-10-26 13:19:57", "link": "http://arxiv.org/abs/2410.20178v2", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Improving Model Evaluation using SMART Filtering of Benchmark Datasets", "abstract": "One of the most challenging problems facing NLP today is evaluation. Some of\nthe most pressing issues pertain to benchmark saturation, data contamination,\nand diversity in the quality of test examples. To address these concerns, we\npropose Selection Methodology for Accurate, Reduced, and Targeted (SMART)\nfiltering, a novel approach to select a high-quality subset of examples from\nexisting benchmark datasets by systematically removing less informative and\nless challenging examples. Our approach applies three filtering criteria,\nremoving (i) easy examples, (ii) data-contaminated examples, and (iii) examples\nthat are similar to each other based on distance in an embedding space. We\ndemonstrate the effectiveness of SMART on three multiple choice QA datasets,\nwhere our methodology increases efficiency by reducing dataset size by 48\\% on\naverage, while increasing Pearson correlation with rankings from ChatBot Arena,\na more open-ended human evaluation setting. Our method enables us to be more\nefficient, whether using SMART to make new benchmarks more challenging or to\nrevitalize older datasets, while still preserving the relative model rankings.", "published": "2024-10-26 18:21:44", "link": "http://arxiv.org/abs/2410.20245v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Library Learning Doesn't: The Curious Case of the Single-Use \"Library\"", "abstract": "Advances in Large Language Models (LLMs) have spurred a wave of LLM library\nlearning systems for mathematical reasoning. These systems aim to learn a\nreusable library of tools, such as formal Isabelle lemmas or Python programs\nthat are tailored to a family of tasks. Many of these systems are inspired by\nthe human structuring of knowledge into reusable and extendable concepts, but\ndo current methods actually learn reusable libraries of tools?\n  We study two library learning systems for mathematics which both reported\nincreased accuracy: LEGO-Prover and TroVE. We find that function reuse is\nextremely infrequent on miniF2F and MATH. Our followup ablation experiments\nsuggest that, rather than reuse, self-correction and self-consistency are the\nprimary drivers of the observed performance gains. Our code and data are\navailable at https://github.com/ikb-a/curious-case", "published": "2024-10-26 21:05:08", "link": "http://arxiv.org/abs/2410.20274v1", "categories": ["cs.LG", "cs.CL", "cs.SC"], "primary_category": "cs.LG"}
{"title": "MatExpert: Decomposing Materials Discovery by Mimicking Human Experts", "abstract": "Material discovery is a critical research area with profound implications for\nvarious industries. In this work, we introduce MatExpert, a novel framework\nthat leverages Large Language Models (LLMs) and contrastive learning to\naccelerate the discovery and design of new solid-state materials. Inspired by\nthe workflow of human materials design experts, our approach integrates three\nkey stages: retrieval, transition, and generation. First, in the retrieval\nstage, MatExpert identifies an existing material that closely matches the\ndesired criteria. Second, in the transition stage, MatExpert outlines the\nnecessary modifications to transform this material formulation to meet specific\nrequirements outlined by the initial user query. Third, in the generation\nstate, MatExpert performs detailed computations and structural generation to\ncreate new materials based on the provided information. Our experimental\nresults demonstrate that MatExpert outperforms state-of-the-art methods in\nmaterial generation tasks, achieving superior performance across various\nmetrics including validity, distribution, and stability. As such, MatExpert\nrepresents a meaningful advancement in computational material discovery using\nlangauge-based generative models.", "published": "2024-10-26 00:44:54", "link": "http://arxiv.org/abs/2410.21317v1", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.CL"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "User-Aware Multilingual Abusive Content Detection in Social Media", "abstract": "Despite growing efforts to halt distasteful content on social media,\nmultilingualism has added a new dimension to this problem. The scarcity of\nresources makes the challenge even greater when it comes to low-resource\nlanguages. This work focuses on providing a novel method for abusive content\ndetection in multiple low-resource Indic languages. Our observation indicates\nthat a post's tendency to attract abusive comments, as well as features such as\nuser history and social context, significantly aid in the detection of abusive\ncontent. The proposed method first learns social and text context features in\ntwo separate modules. The integrated representation from these modules is\nlearned and used for the final prediction. To evaluate the performance of our\nmethod against different classical and state-of-the-art methods, we have\nperformed extensive experiments on SCIDN and MACI datasets consisting of 1.5M\nand 665K multilingual comments, respectively. Our proposed method outperforms\nstate-of-the-art baseline methods with an average increase of 4.08% and 9.52%\nin F1-scores on SCIDN and MACI datasets, respectively.", "published": "2024-10-26 05:44:24", "link": "http://arxiv.org/abs/2410.21321v1", "categories": ["cs.SI", "cs.AI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Mathematical Derivation Graphs: A Task for Summarizing Equation\n  Dependencies in STEM Manuscripts", "abstract": "Recent advances in natural language processing (NLP), particularly with the\nemergence of large language models (LLMs), have significantly enhanced the\nfield of textual analysis. However, while these developments have yielded\nsubstantial progress in analyzing textual data, applying analysis to\nmathematical equations and their relationships within texts has produced mixed\nresults. In this paper, we take the initial steps toward understanding the\ndependency relationships between mathematical expressions in STEM articles. Our\ndataset, sourced from a random sampling of the arXiv corpus, contains an\nanalysis of 107 published STEM manuscripts whose inter-equation dependency\nrelationships have been hand-labeled, resulting in a new object we refer to as\na derivation graph that summarizes the mathematical content of the manuscript.\nWe exhaustively evaluate analytical and NLP-based models to assess their\ncapability to identify and extract the derivation relationships for each\narticle and compare the results with the ground truth. Our comprehensive\ntesting finds that both analytical and NLP models (including LLMs) achieve\n$\\sim$40-50% F1 scores for extracting derivation graphs from articles,\nrevealing that the recent advances in NLP have not made significant inroads in\ncomprehending mathematical texts compared to simpler analytic models. While\ncurrent approaches offer a solid foundation for extracting mathematical\ninformation, further research is necessary to improve accuracy and depth in\nthis area.", "published": "2024-10-26 16:52:22", "link": "http://arxiv.org/abs/2410.21324v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Quantifying Risk Propensities of Large Language Models: Ethical Focus\n  and Bias Detection through Role-Play", "abstract": "As Large Language Models (LLMs) become more prevalent, concerns about their\nsafety, ethics, and potential biases have risen. Systematically evaluating\nLLMs' risk decision-making tendencies and attitudes, particularly in the\nethical domain, has become crucial. This study innovatively applies the\nDomain-Specific Risk-Taking (DOSPERT) scale from cognitive science to LLMs and\nproposes a novel Ethical Decision-Making Risk Attitude Scale (EDRAS) to assess\nLLMs' ethical risk attitudes in depth. We further propose a novel approach\nintegrating risk scales and role-playing to quantitatively evaluate systematic\nbiases in LLMs. Through systematic evaluation and analysis of multiple\nmainstream LLMs, we assessed the \"risk personalities\" of LLMs across multiple\ndomains, with a particular focus on the ethical domain, and revealed and\nquantified LLMs' systematic biases towards different groups. This research\nhelps understand LLMs' risk decision-making and ensure their safe and reliable\napplication. Our approach provides a tool for identifying and mitigating\nbiases, contributing to fairer and more trustworthy AI systems. The code and\ndata are available.", "published": "2024-10-26 15:55:21", "link": "http://arxiv.org/abs/2411.08884v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Personality Analysis from Online Short Video Platforms with Multi-domain\n  Adaptation", "abstract": "Personality analysis from online short videos has gained prominence due to\nits applications in personalized recommendation systems, sentiment analysis,\nand human-computer interaction. Traditional assessment methods, such as\nquestionnaires based on the Big Five Personality Framework, are limited by\nself-report biases and are impractical for large-scale or real-time analysis.\nLeveraging the rich, multi-modal data present in short videos offers a\npromising alternative for more accurate personality inference. However,\nintegrating these diverse and asynchronous modalities poses significant\nchallenges, particularly in aligning time-varying data and ensuring models\ngeneralize well to new domains with limited labeled data. In this paper, we\npropose a novel multi-modal personality analysis framework that addresses these\nchallenges by synchronizing and integrating features from multiple modalities\nand enhancing model generalization through domain adaptation. We introduce a\ntimestamp-based modality alignment mechanism that synchronizes data based on\nspoken word timestamps, ensuring accurate correspondence across modalities and\nfacilitating effective feature integration. To capture temporal dependencies\nand inter-modal interactions, we employ Bidirectional Long Short-Term Memory\nnetworks and self-attention mechanisms, allowing the model to focus on the most\ninformative features for personality prediction. Furthermore, we develop a\ngradient-based domain adaptation method that transfers knowledge from multiple\nsource domains to improve performance in target domains with scarce labeled\ndata. Extensive experiments on real-world datasets demonstrate that our\nframework significantly outperforms existing methods in personality prediction\ntasks, highlighting its effectiveness in capturing complex behavioral cues and\nrobustness in adapting to new domains.", "published": "2024-10-26 03:29:32", "link": "http://arxiv.org/abs/2411.00813v1", "categories": ["cs.MM", "cs.AI", "cs.CL", "cs.CV", "cs.CY", "cs.LG", "cs.SI", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Analyzing long-term rhythm variations in Mising and Assamese using\n  frequency domain correlates", "abstract": "The current work explores long-term speech rhythm variations to classify\nMising and Assamese, two low-resourced languages from Assam, Northeast India.\nWe study the temporal information of speech rhythm embedded in low-frequency\n(LF) spectrograms derived from amplitude (AM) and frequency modulation (FM)\nenvelopes. This quantitative frequency domain analysis of rhythm is supported\nby the idea of rhythm formant analysis (RFA), originally proposed by Gibbon\n[1]. We attempt to make the investigation by extracting features derived from\ntrajectories of first six rhythm formants along with two-dimensional discrete\ncosine transform-based characterizations of the AM and FM LF spectrograms. The\nderived features are fed as input to a machine learning tool to contrast\nrhythms of Assamese and Mising. In this way, an improved methodology for\nempirically investigating rhythm variation structure without prior annotation\nof the larger unit of the speech signal is illustrated for two low-resourced\nlanguages of Northeast India.", "published": "2024-10-26 06:22:32", "link": "http://arxiv.org/abs/2410.20095v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "emg2qwerty: A Large Dataset with Baselines for Touch Typing using\n  Surface Electromyography", "abstract": "Surface electromyography (sEMG) non-invasively measures signals generated by\nmuscle activity with sufficient sensitivity to detect individual spinal neurons\nand richness to identify dozens of gestures and their nuances. Wearable\nwrist-based sEMG sensors have the potential to offer low friction, subtle,\ninformation rich, always available human-computer inputs. To this end, we\nintroduce emg2qwerty, a large-scale dataset of non-invasive electromyographic\nsignals recorded at the wrists while touch typing on a QWERTY keyboard,\ntogether with ground-truth annotations and reproducible baselines. With 1,135\nsessions spanning 108 users and 346 hours of recording, this is the largest\nsuch public dataset to date. These data demonstrate non-trivial, but well\ndefined hierarchical relationships both in terms of the generative process,\nfrom neurons to muscles and muscle combinations, as well as in terms of domain\nshift across users and user sessions. Applying standard modeling techniques\nfrom the closely related field of Automatic Speech Recognition (ASR), we show\nstrong baseline performance on predicting key-presses using sEMG signals alone.\nWe believe the richness of this task and dataset will facilitate progress in\nseveral problems of interest to both the machine learning and neuroscientific\ncommunities. Dataset and code can be accessed at\nhttps://github.com/facebookresearch/emg2qwerty.", "published": "2024-10-26 05:18:48", "link": "http://arxiv.org/abs/2410.20081v3", "categories": ["cs.LG", "cs.HC", "eess.AS", "I.2.1; I.2.7; H.5.2; H.1.2"], "primary_category": "cs.LG"}
{"title": "Enhancing Lie Detection Accuracy: A Comparative Study of Classic ML,\n  CNN, and GCN Models using Audio-Visual Features", "abstract": "Inaccuracies in polygraph tests often lead to wrongful convictions, false\ninformation, and bias, all of which have significant consequences for both\nlegal and political systems. Recently, analyzing facial micro-expressions has\nemerged as a method for detecting deception; however, current models have not\nreached high accuracy and generalizability. The purpose of this study is to aid\nin remedying these problems. The unique multimodal transformer architecture\nused in this study improves upon previous approaches by using auditory inputs,\nvisual facial micro-expressions, and manually transcribed gesture annotations,\nmoving closer to a reliable non-invasive lie detection model. Visual and\nauditory features were extracted using the Vision Transformer and OpenSmile\nmodels respectively, which were then concatenated with the transcriptions of\nparticipants micro-expressions and gestures. Various models were trained for\nthe classification of lies and truths using these processed and concatenated\nfeatures. The CNN Conv1D multimodal model achieved an average accuracy of\n95.4%. However, further research is still required to create higher-quality\ndatasets and even more generalized models for more diverse applications.", "published": "2024-10-26 22:17:36", "link": "http://arxiv.org/abs/2411.08885v1", "categories": ["cs.MM", "cs.AI", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
