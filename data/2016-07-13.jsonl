{"title": "Re-presenting a Story by Emotional Factors using Sentimental Analysis\n  Method", "abstract": "Remembering an event is affected by personal emotional status. We examined\nthe psychological status and personal factors; depression (Center for\nEpidemiological Studies - Depression, Radloff, 1977), present affective\n(Positive Affective and Negative Affective Schedule, Watson et al., 1988), life\norient (Life Orient Test, Scheier & Carver, 1985), self-awareness (Core Self\nEvaluation Scale, Judge et al., 2003), and social factor (Social Support,\nSarason et al., 1983) of undergraduate students (N=64) and got summaries of a\nstory, Chronicle of a Death Foretold (Gabriel Garcia Marquez, 1981) from them.\nWe implement a sentimental analysis model based on convolutional neural network\n(LeCun & Bengio, 1995) to evaluate each summary. From the same vein used for\ntransfer learning (Pan & Yang, 2010), we collected 38,265 movie review data to\ntrain the model and then use them to score summaries of each student. The\nresults of CES-D and PANAS show the relationship between emotion and memory\nretrieval as follows: depressed people have shown a tendency of representing a\nstory more negatively, and they seemed less expressive. People with full of\nemotion - high in PANAS - have retrieved their memory more expressively than\nothers, using more negative words then others. The contributions of this study\ncan be summarized as follows: First, lightening the relationship between\nemotion and its effect during times of storing or retrieving a memory. Second,\nsuggesting objective methods to evaluate the intensity of emotion in natural\nlanguage format, using a sentimental analysis model.", "published": "2016-07-13 12:48:33", "link": "http://arxiv.org/abs/1607.03707v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AudioPairBank: Towards A Large-Scale Tag-Pair-Based Audio Content\n  Analysis", "abstract": "Recently, sound recognition has been used to identify sounds, such as car and\nriver. However, sounds have nuances that may be better described by\nadjective-noun pairs such as slow car, and verb-noun pairs such as flying\ninsects, which are under explored. Therefore, in this work we investigate the\nrelation between audio content and both adjective-noun pairs and verb-noun\npairs. Due to the lack of datasets with these kinds of annotations, we\ncollected and processed the AudioPairBank corpus consisting of a combined total\nof 1,123 pairs and over 33,000 audio files. One contribution is the previously\nunavailable documentation of the challenges and implications of collecting\naudio recordings with these type of labels. A second contribution is to show\nthe degree of correlation between the audio content and the labels through\nsound recognition experiments, which yielded results of 70% accuracy, hence\nalso providing a performance benchmark. The results and study in this paper\nencourage further exploration of the nuances in audio and are meant to\ncomplement similar research performed on images and text in multimedia\nanalysis.", "published": "2016-07-13 14:31:54", "link": "http://arxiv.org/abs/1607.03766v3", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "A Vector Space for Distributional Semantics for Entailment", "abstract": "Distributional semantics creates vector-space representations that capture\nmany forms of semantic similarity, but their relation to semantic entailment\nhas been less clear. We propose a vector-space model which provides a formal\nfoundation for a distributional semantics of entailment. Using a mean-field\napproximation, we develop approximate inference procedures and entailment\noperators over vectors of probabilities of features being known (versus\nunknown). We use this framework to reinterpret an existing\ndistributional-semantic model (Word2Vec) as approximating an entailment-based\nmodel of the distributions of words in contexts, thereby predicting lexical\nentailment relations. In both unsupervised and semi-supervised experiments on\nhyponymy detection, we get substantial improvements over previous results.", "published": "2016-07-13 15:08:26", "link": "http://arxiv.org/abs/1607.03780v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tie-breaker: Using language models to quantify gender bias in sports\n  journalism", "abstract": "Gender bias is an increasingly important issue in sports journalism. In this\nwork, we propose a language-model-based approach to quantify differences in\nquestions posed to female vs. male athletes, and apply it to tennis post-match\ninterviews. We find that journalists ask male players questions that are\ngenerally more focused on the game when compared with the questions they ask\ntheir female counterparts. We also provide a fine-grained analysis of the\nextent to which the salience of this bias depends on various factors, such as\nquestion type, game outcome or player rank.", "published": "2016-07-13 20:00:01", "link": "http://arxiv.org/abs/1607.03895v1", "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "A Supervised Authorship Attribution Framework for Bengali Language", "abstract": "Authorship Attribution is a long-standing problem in Natural Language\nProcessing. Several statistical and computational methods have been used to\nfind a solution to this problem. In this paper, we have proposed methods to\ndeal with the authorship attribution problem in Bengali.", "published": "2016-07-13 06:57:38", "link": "http://arxiv.org/abs/1607.05650v2", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "The KIT Motion-Language Dataset", "abstract": "Linking human motion and natural language is of great interest for the\ngeneration of semantic representations of human activities as well as for the\ngeneration of robot activities based on natural language input. However, while\nthere have been years of research in this area, no standardized and openly\navailable dataset exists to support the development and evaluation of such\nsystems. We therefore propose the KIT Motion-Language Dataset, which is large,\nopen, and extensible. We aggregate data from multiple motion capture databases\nand include them in our dataset using a unified representation that is\nindependent of the capture system or marker set, making it easy to work with\nthe data regardless of its origin. To obtain motion annotations in natural\nlanguage, we apply a crowd-sourcing approach and a web-based tool that was\nspecifically build for this purpose, the Motion Annotation Tool. We thoroughly\ndocument the annotation process itself and discuss gamification methods that we\nused to keep annotators motivated. We further propose a novel method,\nperplexity-based selection, which systematically selects motions for further\nannotation that are either under-represented in our dataset or that have\nerroneous annotations. We show that our method mitigates the two aforementioned\nproblems and ensures a systematic annotation process. We provide an in-depth\nanalysis of the structure and contents of our resulting dataset, which, as of\nOctober 10, 2016, contains 3911 motions with a total duration of 11.23 hours\nand 6278 annotations in natural language that contain 52,903 words. We believe\nthis makes our dataset an excellent choice that enables more transparent and\ncomparable research in this important area.", "published": "2016-07-13 17:08:01", "link": "http://arxiv.org/abs/1607.03827v2", "categories": ["cs.RO", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
