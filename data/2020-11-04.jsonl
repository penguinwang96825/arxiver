{"title": "Generative Inverse Deep Reinforcement Learning for Online Recommendation", "abstract": "Deep reinforcement learning enables an agent to capture user's interest through interactions with the environment dynamically. It has attracted great interest in the recommendation research. Deep reinforcement learning uses a reward function to learn user's interest and to control the learning process. However, most reward functions are manually designed; they are either unrealistic or imprecise to reflect the high variety, dimensionality, and non-linearity properties of the recommendation problem. That makes it difficult for the agent to learn an optimal policy to generate the most satisfactory recommendations. To address the above issue, we propose a novel generative inverse reinforcement learning approach, namely InvRec, which extracts the reward function from user's behaviors automatically, for online recommendation. We conduct experiments on an online platform, VirtualTB, and compare with several state-of-the-art methods to demonstrate the feasibility and effectiveness of our proposed approach.", "published": "2020-11-04 12:12:25", "link": "http://arxiv.org/abs/2011.02248v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Learning in your voice: Non-parallel voice conversion based on speaker consistency loss", "abstract": "In this paper, we propose a novel voice conversion strategy to resolve the mismatch between the training and conversion scenarios when parallel speech corpus is unavailable for training. Based on auto-encoder and disentanglement frameworks, we design the proposed model to extract identity and content representations while reconstructing the input speech signal itself. Since we use other speaker's identity information in the training process, the training philosophy is naturally matched with the objective of voice conversion process. In addition, we effectively design the disentanglement framework to reliably preserve linguistic information and to enhance the quality of converted speech signals. The superiority of the proposed method is shown in subjective listening tests as well as objective measures.", "published": "2020-11-04 07:58:35", "link": "http://arxiv.org/abs/2011.02168v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Correlation based Multi-phasal models for improved imagined speech EEG recognition", "abstract": "Translation of imagined speech electroencephalogram(EEG) into human understandable commands greatly facilitates the design of naturalistic brain computer interfaces. To achieve improved imagined speech unit classification, this work aims to profit from the parallel information contained in multi-phasal EEG data recorded while speaking, imagining and performing articulatory movements corresponding to specific speech units. A bi-phase common representation learning module using neural networks is designed to model the correlation and reproducibility between an analysis phase and a support phase. The trained Correlation Network is then employed to extract discriminative features of the analysis phase. These features are further classified into five binary phonological categories using machine learning models such as Gaussian mixture based hidden Markov model and deep neural networks. The proposed approach further handles the non-availability of multi-phasal data during decoding. Topographic visualizations along with result-based inferences suggest that the multi-phasal correlation modelling approach proposed in the paper enhances imagined-speech EEG recognition performance.", "published": "2020-11-04 09:39:53", "link": "http://arxiv.org/abs/2011.02195v1", "categories": ["eess.SP", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Widely-distributed Radar Imaging Based on Consensus ADMM", "abstract": "A widely-distributed radar system is a promising architecture to enhance radar imaging performance. However, most existing algorithms rely on isotropic scattering assumption, which is only satisfied in collocated radar systems. Moreover, due to noise and imaging model imperfections, artifacts such as layovers are common in radar images. In this paper, a novel $l_1$-regularized, consensus alternating direction method of multipliers (CADMM) based algorithm is proposed to mitigate artifacts by exploiting a widely-distributed radar system's spatial diversity. By imposing the consensus constraints on the local images formed by distributed antenna clusters and solving the resulting distributed optimization problem, the scenario's spatial-invariant common features are retained. Simultaneously, the spatial-variant artifacts are mitigated, and it will finally converge to a high-quality global image in the consensus of all distributed measurements. The proposed algorithm outperforms the joint sparsity-based composite imaging (JSC) algorithm in terms of artifacts mitigation. It can also reduce the computation and storage burden of large-scale imaging problems through its distributed and parallelizable optimization scheme.", "published": "2020-11-04 14:39:12", "link": "http://arxiv.org/abs/2011.02319v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
