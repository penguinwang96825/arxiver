{"title": "Improved Word Sense Disambiguation Using Pre-Trained Contextualized Word\n  Representations", "abstract": "Contextualized word representations are able to give different\nrepresentations for the same word in different contexts, and they have been\nshown to be effective in downstream natural language processing tasks, such as\nquestion answering, named entity recognition, and sentiment analysis. However,\nevaluation on word sense disambiguation (WSD) in prior work shows that using\ncontextualized word representations does not outperform the state-of-the-art\napproach that makes use of non-contextualized word embeddings. In this paper,\nwe explore different strategies of integrating pre-trained contextualized word\nrepresentations and our best strategy achieves accuracies exceeding the best\nprior published accuracies by significant margins on multiple benchmark WSD\ndatasets. We make the source code available at\nhttps://github.com/nusnlp/contextemb-wsd.", "published": "2019-10-01 04:11:33", "link": "http://arxiv.org/abs/1910.00194v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Sentence Fusion in Abstractive Summarization", "abstract": "While recent work in abstractive summarization has resulted in higher scores\nin automatic metrics, there is little understanding on how these systems\ncombine information taken from multiple document sentences. In this paper, we\nanalyze the outputs of five state-of-the-art abstractive summarizers, focusing\non summary sentences that are formed by sentence fusion. We ask assessors to\njudge the grammaticality, faithfulness, and method of fusion for summary\nsentences. Our analysis reveals that system sentences are mostly grammatical,\nbut often fail to remain faithful to the original article.", "published": "2019-10-01 05:22:19", "link": "http://arxiv.org/abs/1910.00203v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When and Why is Document-level Context Useful in Neural Machine\n  Translation?", "abstract": "Document-level context has received lots of attention for compensating neural\nmachine translation (NMT) of isolated sentences. However, recent advances in\ndocument-level NMT focus on sophisticated integration of the context,\nexplaining its improvement with only a few selected examples or targeted test\nsets. We extensively quantify the causes of improvements by a document-level\nmodel in general test sets, clarifying the limit of the usefulness of\ndocument-level context in NMT. We show that most of the improvements are not\ninterpretable as utilizing the context. We also show that a minimal encoding is\nsufficient for the context modeling and very long context is not helpful for\nNMT.", "published": "2019-10-01 10:40:26", "link": "http://arxiv.org/abs/1910.00294v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grammatical Error Correction in Low-Resource Scenarios", "abstract": "Grammatical error correction in English is a long studied problem with many\nexisting systems and datasets. However, there has been only a limited research\non error correction of other languages. In this paper, we present a new dataset\nAKCES-GEC on grammatical error correction for Czech. We then make experiments\non Czech, German and Russian and show that when utilizing synthetic parallel\ncorpus, Transformer neural machine translation model can reach new\nstate-of-the-art results on these datasets. AKCES-GEC is published under CC\nBY-NC-SA 4.0 license at https://hdl.handle.net/11234/1-3057 and the source code\nof the GEC model is available at\nhttps://github.com/ufal/low-resource-gec-wnut2019.", "published": "2019-10-01 12:58:44", "link": "http://arxiv.org/abs/1910.00353v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Application of Low-resource Machine Translation Techniques to\n  Russian-Tatar Language Pair", "abstract": "Neural machine translation is the current state-of-the-art in machine\ntranslation. Although it is successful in a resource-rich setting, its\napplicability for low-resource language pairs is still debatable. In this\npaper, we explore the effect of different techniques to improve machine\ntranslation quality when a parallel corpus is as small as 324 000 sentences,\ntaking as an example previously unexplored Russian-Tatar language pair. We\napply such techniques as transfer learning and semi-supervised learning to the\nbase Transformer model, and empirically show that the resulting models improve\nRussian to Tatar and Tatar to Russian translation quality by +2.57 and +3.66\nBLEU, respectively.", "published": "2019-10-01 13:24:56", "link": "http://arxiv.org/abs/1910.00368v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Methods to Leverage Monolingual Data in Low-resource Neural\n  Machine Translation", "abstract": "Neural machine translation has become the state-of-the-art for language pairs\nwith large parallel corpora. However, the quality of machine translation for\nlow-resource languages leaves much to be desired. There are several approaches\nto mitigate this problem, such as transfer learning, semi-supervised and\nunsupervised learning techniques. In this paper, we review the existing\nmethods, where the main idea is to exploit the power of monolingual data,\nwhich, compared to parallel, is usually easier to obtain and significantly\ngreater in amount.", "published": "2019-10-01 13:29:53", "link": "http://arxiv.org/abs/1910.00373v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine Translation for Machines: the Sentiment Classification Use Case", "abstract": "We propose a neural machine translation (NMT) approach that, instead of\npursuing adequacy and fluency (\"human-oriented\" quality criteria), aims to\ngenerate translations that are best suited as input to a natural language\nprocessing component designed for a specific downstream task (a\n\"machine-oriented\" criterion). Towards this objective, we present a\nreinforcement learning technique based on a new candidate sampling strategy,\nwhich exploits the results obtained on the downstream task as weak feedback.\nExperiments in sentiment classification of Twitter data in German and Italian\nshow that feeding an English classifier with machine-oriented translations\nsignificantly improves its performance. Classification results outperform those\nobtained with translations produced by general-purpose NMT models as well as by\nan approach based on reinforcement learning. Moreover, our results on both\nlanguages approximate the classification accuracy computed on gold standard\nEnglish tweets.", "published": "2019-10-01 15:24:57", "link": "http://arxiv.org/abs/1910.00478v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dialogue Transformers", "abstract": "We introduce a dialogue policy based on a transformer architecture, where the\nself-attention mechanism operates over the sequence of dialogue turns. Recent\nwork has used hierarchical recurrent neural networks to encode multiple\nutterances in a dialogue context, but we argue that a pure self-attention\nmechanism is more suitable. By default, an RNN assumes that every item in a\nsequence is relevant for producing an encoding of the full sequence, but a\nsingle conversation can consist of multiple overlapping discourse segments as\nspeakers interleave multiple topics. A transformer picks which turns to include\nin its encoding of the current dialogue state, and is naturally suited to\nselectively ignoring or attending to dialogue history. We compare the\nperformance of the Transformer Embedding Dialogue (TED) policy to an LSTM and\nto the REDP, which was specifically designed to overcome this limitation of\nRNNs.", "published": "2019-10-01 15:36:27", "link": "http://arxiv.org/abs/1910.00486v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BillSum: A Corpus for Automatic Summarization of US Legislation", "abstract": "Automatic summarization methods have been studied on a variety of domains,\nincluding news and scientific articles. Yet, legislation has not previously\nbeen considered for this task, despite US Congress and state governments\nreleasing tens of thousands of bills every year. In this paper, we introduce\nBillSum, the first dataset for summarization of US Congressional and California\nstate bills (https://github.com/FiscalNote/BillSum). We explain the properties\nof the dataset that make it more challenging to process than other domains.\nThen, we benchmark extractive methods that consider neural sentence\nrepresentations and traditional contextual features. Finally, we demonstrate\nthat models built on Congressional bills can be used to summarize California\nbills, thus, showing that methods developed on this dataset can transfer to\nstates without human-written summaries.", "published": "2019-10-01 16:25:12", "link": "http://arxiv.org/abs/1910.00523v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Type-aware Convolutional Neural Networks for Slot Filling", "abstract": "The slot filling task aims at extracting answers for queries about entities\nfrom text, such as \"Who founded Apple\". In this paper, we focus on the relation\nclassification component of a slot filling system. We propose type-aware\nconvolutional neural networks to benefit from the mutual dependencies between\nentity and relation classification. In particular, we explore different ways of\nintegrating the named entity types of the relation arguments into a neural\nnetwork for relation classification, including a joint training and a\nstructured prediction approach. To the best of our knowledge, this is the first\nstudy on type-aware neural networks for slot filling. The type-aware models\nlead to the best results of our slot filling pipeline. Joint training performs\ncomparable to structured prediction. To understand the impact of the different\ncomponents of the slot filling pipeline, we perform a recall analysis, a manual\nerror analysis and several ablation studies. Such analyses are of particular\nimportance to other slot filling researchers since the official slot filling\nevaluations only assess pipeline outputs. The analyses show that especially\ncoreference resolution and our convolutional neural networks have a large\npositive impact on the final performance of the slot filling pipeline. The\npresented models, the source code of our system as well as our coreference\nresource is publicy available.", "published": "2019-10-01 17:09:29", "link": "http://arxiv.org/abs/1910.00546v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Essentia: Mining Domain-Specific Paraphrases with Word-Alignment Graphs", "abstract": "Paraphrases are important linguistic resources for a wide variety of NLP\napplications. Many techniques for automatic paraphrase mining from general\ncorpora have been proposed. While these techniques are successful at\ndiscovering generic paraphrases, they often fail to identify domain-specific\nparaphrases (e.g., {staff, concierge} in the hospitality domain). This is\nbecause current techniques are often based on statistical methods, while\ndomain-specific corpora are too small to fit statistical methods. In this\npaper, we present an unsupervised graph-based technique to mine paraphrases\nfrom a small set of sentences that roughly share the same topic or intent. Our\nsystem, Essentia, relies on word-alignment techniques to create a\nword-alignment graph that merges and organizes tokens from input sentences. The\nresulting graph is then used to generate candidate paraphrases. We demonstrate\nthat our system obtains high-quality paraphrases, as evaluated by crowd\nworkers. We further show that the majority of the identified paraphrases are\ndomain-specific and thus complement existing paraphrase databases.", "published": "2019-10-01 19:51:57", "link": "http://arxiv.org/abs/1910.00637v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robust Semantic Parsing with Adversarial Learning for Domain\n  Generalization", "abstract": "This paper addresses the issue of generalization for Semantic Parsing in an\nadversarial framework. Building models that are more robust to inter-document\nvariability is crucial for the integration of Semantic Parsing technologies in\nreal applications. The underlying question throughout this study is whether\nadversarial learning can be used to train models on a higher level of\nabstraction in order to increase their robustness to lexical and stylistic\nvariations.We propose to perform Semantic Parsing with a domain classification\nadversarial task without explicit knowledge of the domain. The strategy is\nfirst evaluated on a French corpus of encyclopedic documents, annotated with\nFrameNet, in an information retrieval perspective, then on PropBank Semantic\nRole Labeling task on the CoNLL-2005 benchmark. We show that adversarial\nlearning increases all models generalization capabilities both on in and\nout-of-domain data.", "published": "2019-10-01 09:23:35", "link": "http://arxiv.org/abs/1910.06700v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Specializing Word Embeddings (for Parsing) by Information Bottleneck", "abstract": "Pre-trained word embeddings like ELMo and BERT contain rich syntactic and\nsemantic information, resulting in state-of-the-art performance on various\ntasks. We propose a very fast variational information bottleneck (VIB) method\nto nonlinearly compress these embeddings, keeping only the information that\nhelps a discriminative parser. We compress each word embedding to either a\ndiscrete tag or a continuous vector. In the discrete version, our automatically\ncompressed tags form an alternative tag set: we show experimentally that our\ntags capture most of the information in traditional POS tag annotations, but\nour tag sequences can be parsed more accurately at the same level of tag\ngranularity. In the continuous version, we show experimentally that moderately\ncompressing the word embeddings by our method yields a more accurate parser in\n8 of 9 languages, unlike simple dimensionality reduction.", "published": "2019-10-01 00:47:31", "link": "http://arxiv.org/abs/1910.00163v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Writing habits and telltale neighbors: analyzing clinical concept usage\n  patterns with sublanguage embeddings", "abstract": "Natural language processing techniques are being applied to increasingly\ndiverse types of electronic health records, and can benefit from in-depth\nunderstanding of the distinguishing characteristics of medical document types.\nWe present a method for characterizing the usage patterns of clinical concepts\namong different document types, in order to capture semantic differences beyond\nthe lexical level. By training concept embeddings on clinical documents of\ndifferent types and measuring the differences in their nearest neighborhood\nstructures, we are able to measure divergences in concept usage while\ncorrecting for noise in embedding learning. Experiments on the MIMIC-III corpus\ndemonstrate that our approach captures clinically-relevant differences in\nconcept usage and provides an intuitive way to explore semantic characteristics\nof clinical document collections.", "published": "2019-10-01 04:07:15", "link": "http://arxiv.org/abs/1910.00192v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multilingual End-to-End Speech Translation", "abstract": "In this paper, we propose a simple yet effective framework for multilingual\nend-to-end speech translation (ST), in which speech utterances in source\nlanguages are directly translated to the desired target languages with a\nuniversal sequence-to-sequence architecture. While multilingual models have\nshown to be useful for automatic speech recognition (ASR) and machine\ntranslation (MT), this is the first time they are applied to the end-to-end ST\nproblem. We show the effectiveness of multilingual end-to-end ST in two\nscenarios: one-to-many and many-to-many translations with publicly available\ndata. We experimentally confirm that multilingual end-to-end ST models\nsignificantly outperform bilingual ones in both scenarios. The generalization\nof multilingual training is also evaluated in a transfer learning scenario to a\nvery low-resource language pair. All of our codes and the database are publicly\navailable to encourage further research in this emergent multilingual ST topic.", "published": "2019-10-01 08:38:26", "link": "http://arxiv.org/abs/1910.00254v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Bad Form: Comparing Context-Based and Form-Based Few-Shot Learning in\n  Distributional Semantic Models", "abstract": "Word embeddings are an essential component in a wide range of natural\nlanguage processing applications. However, distributional semantic models are\nknown to struggle when only a small number of context sentences are available.\nSeveral methods have been proposed to obtain higher-quality vectors for these\nwords, leveraging both this context information and sometimes the word forms\nthemselves through a hybrid approach. We show that the current tasks do not\nsuffice to evaluate models that use word-form information, as such models can\neasily leverage word forms in the training data that are related to word forms\nin the test data. We introduce 3 new tasks, allowing for a more balanced\ncomparison between models. Furthermore, we show that hyperparameters that have\nlargely been ignored in previous work can consistently improve the performance\nof both baseline and advanced models, achieving a new state of the art on 4 out\nof 6 tasks.", "published": "2019-10-01 09:39:07", "link": "http://arxiv.org/abs/1910.00275v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TMLab: Generative Enhanced Model (GEM) for adversarial attacks", "abstract": "We present our Generative Enhanced Model (GEM) that we used to create samples\nawarded the first prize on the FEVER 2.0 Breakers Task. GEM is the extended\nlanguage model developed upon GPT-2 architecture. The addition of novel target\nvocabulary input to the already existing context input enabled controlled text\ngeneration. The training procedure resulted in creating a model that inherited\nthe knowledge of pretrained GPT-2, and therefore was ready to generate\nnatural-like English sentences in the task domain with some additional control.\nAs a result, GEM generated malicious claims that mixed facts from various\narticles, so it became difficult to classify their truthfulness.", "published": "2019-10-01 12:25:44", "link": "http://arxiv.org/abs/1910.00337v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VOnDA: A Framework for Ontology-Based Dialogue Management", "abstract": "We present VOnDA, a framework to implement the dialogue management\nfunctionality in dialogue systems. Although domain-independent, VOnDA is\ntailored towards dialogue systems with a focus on social communication, which\nimplies the need of long-term memory and high user adaptivity. For these\nsystems, which are used in health environments or elderly care, margin of error\nis very low and control over the dialogue process is of topmost importance. The\nsame holds for commercial applications, where customer trust is at risk.\nVOnDA's specification and memory layer relies upon (extended) RDF/OWL, which\nprovides a universal and uniform representation, and facilitates\ninteroperability with external data sources, e.g., from physical sensors.", "published": "2019-10-01 12:33:16", "link": "http://arxiv.org/abs/1910.00340v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Latent-Variable Generative Models for Data-Efficient Text Classification", "abstract": "Generative classifiers offer potential advantages over their discriminative\ncounterparts, namely in the areas of data efficiency, robustness to data shift\nand adversarial examples, and zero-shot learning (Ng and Jordan,2002; Yogatama\net al., 2017; Lewis and Fan,2019). In this paper, we improve generative text\nclassifiers by introducing discrete latent variables into the generative story,\nand explore several graphical model configurations. We parameterize the\ndistributions using standard neural architectures used in conditional language\nmodeling and perform learning by directly maximizing the log marginal\nlikelihood via gradient-based optimization, which avoids the need to do\nexpectation-maximization. We empirically characterize the performance of our\nmodels on six text classification datasets. The choice of where to include the\nlatent variable has a significant impact on performance, with the strongest\nresults obtained when using the latent variable as an auxiliary conditioning\nvariable in the generation of the textual input. This model consistently\noutperforms both the generative and discriminative classifiers in small-data\nsettings. We analyze our model by using it for controlled generation, finding\nthat the latent variable captures interpretable properties of the data, even\nwith very small training sets.", "published": "2019-10-01 13:45:56", "link": "http://arxiv.org/abs/1910.00382v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MMM: Multi-stage Multi-task Learning for Multi-choice Reading\n  Comprehension", "abstract": "Machine Reading Comprehension (MRC) for question answering (QA), which aims\nto answer a question given the relevant context passages, is an important way\nto test the ability of intelligence systems to understand human language.\nMultiple-Choice QA (MCQA) is one of the most difficult tasks in MRC because it\noften requires more advanced reading comprehension skills such as logical\nreasoning, summarization, and arithmetic operations, compared to the extractive\ncounterpart where answers are usually spans of text within given passages.\nMoreover, most existing MCQA datasets are small in size, making the learning\ntask even harder. We introduce MMM, a Multi-stage Multi-task learning framework\nfor Multi-choice reading comprehension. Our method involves two sequential\nstages: coarse-tuning stage using out-of-domain datasets and multi-task\nlearning stage using a larger in-domain dataset to help model generalize better\nwith limited data. Furthermore, we propose a novel multi-step attention network\n(MAN) as the top-level classifier for this task. We demonstrate MMM\nsignificantly advances the state-of-the-art on four representative MCQA\ndatasets.", "published": "2019-10-01 14:43:37", "link": "http://arxiv.org/abs/1910.00458v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Detecting Alzheimer's Disease by estimating attention and elicitation\n  path through the alignment of spoken picture descriptions with the picture\n  prompt", "abstract": "Cognitive decline is a sign of Alzheimer's disease (AD), and there is\nevidence that tracking a person's eye movement, using eye tracking devices, can\nbe used for the automatic identification of early signs of cognitive decline.\nHowever, such devices are expensive and may not be easy-to-use for people with\ncognitive problems. In this paper, we present a new way of capturing similar\nvisual features, by using the speech of people describing the Cookie Theft\npicture - a common cognitive testing task - to identify regions in the picture\nprompt that will have caught the speaker's attention and elicited their speech.\nAfter aligning the automatically recognised words with different regions of the\npicture prompt, we extract information inspired by eye tracking metrics such as\ncoordinates of the area of interests (AOI)s, time spent in AOI, time to reach\nthe AOI, and the number of AOI visits. Using the DementiaBank dataset we train\na binary classifier (AD vs. healthy control) using 10-fold cross-validation and\nachieve an 80% F1-score using the timing information from the forced alignments\nof the automatic speech recogniser (ASR); this achieved around 72% using the\ntiming information from the ASR outputs.", "published": "2019-10-01 16:06:44", "link": "http://arxiv.org/abs/1910.00515v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Better Document-Level Machine Translation with Bayes' Rule", "abstract": "We show that Bayes' rule provides an effective mechanism for creating\ndocument translation models that can be learned from only parallel sentences\nand monolingual documents---a compelling benefit as parallel documents are not\nalways available. In our formulation, the posterior probability of a candidate\ntranslation is the product of the unconditional (prior) probability of the\ncandidate output document and the \"reverse translation probability\" of\ntranslating the candidate output back into the source language. Our proposed\nmodel uses a powerful autoregressive language model as the prior on target\nlanguage documents, but it assumes that each sentence is translated\nindependently from the target to the source language. Crucially, at test time,\nwhen a source document is observed, the document language model prior induces\ndependencies between the translations of the source sentences in the posterior.\nThe model's independence assumption not only enables efficient use of available\ndata, but it additionally admits a practical left-to-right beam-search\nalgorithm for carrying out inference. Experiments show that our model benefits\nfrom using cross-sentence context in the language model, and it outperforms\nexisting document translation approaches.", "published": "2019-10-01 17:30:56", "link": "http://arxiv.org/abs/1910.00553v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DyKgChat: Benchmarking Dialogue Generation Grounding on Dynamic\n  Knowledge Graphs", "abstract": "Data-driven, knowledge-grounded neural conversation models are capable of\ngenerating more informative responses. However, these models have not yet\ndemonstrated that they can zero-shot adapt to updated, unseen knowledge graphs.\nThis paper proposes a new task about how to apply dynamic knowledge graphs in\nneural conversation model and presents a novel TV series conversation corpus\n(DyKgChat) for the task. Our new task and corpus aids in understanding the\ninfluence of dynamic knowledge graphs on responses generation. Also, we propose\na preliminary model that selects an output from two networks at each time step:\na sequence-to-sequence model (Seq2Seq) and a multi-hop reasoning model, in\norder to support dynamic knowledge graphs. To benchmark this new task and\nevaluate the capability of adaptation, we introduce several evaluation metrics\nand the experiments show that our proposed approach outperforms previous\nknowledge-grounded conversation models. The proposed corpus and model can\nmotivate the future research directions.", "published": "2019-10-01 18:29:08", "link": "http://arxiv.org/abs/1910.00610v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning to estimate label uncertainty for automatic radiology report\n  parsing", "abstract": "Bootstrapping labels from radiology reports has become the scalable\nalternative to provide inexpensive ground truth for medical imaging. Because of\nthe domain specific nature, state-of-the-art report labeling tools are\npredominantly rule-based. These tools, however, typically yield a binary 0 or 1\nprediction that indicates the presence or absence of abnormalities. These hard\ntargets are then used as ground truth to train image models in the downstream,\nforcing models to express high degree of certainty even on cases where\nspecificity is low. This could negatively impact the statistical efficiency of\nimage models. We address such an issue by training a Bidirectional Long-Short\nTerm Memory Network to augment heuristic-based discrete labels of X-ray reports\nfrom all body regions and achieve performance comparable or better than\ndomain-specific NLP, but with additional uncertainty estimates which enable\nfiner downstream image model training.", "published": "2019-10-01 21:20:33", "link": "http://arxiv.org/abs/1910.00673v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Identifying Supporting Facts for Multi-hop Question Answering with\n  Document Graph Networks", "abstract": "Recent advances in reading comprehension have resulted in models that surpass\nhuman performance when the answer is contained in a single, continuous passage\nof text. However, complex Question Answering (QA) typically requires multi-hop\nreasoning - i.e. the integration of supporting facts from different sources, to\ninfer the correct answer. This paper proposes Document Graph Network (DGN), a\nmessage passing architecture for the identification of supporting facts over a\ngraph-structured representation of text. The evaluation on HotpotQA shows that\nDGN obtains competitive results when compared to a reading comprehension\nbaseline operating on raw text, confirming the relevance of structured\nrepresentations for supporting multi-hop reasoning.", "published": "2019-10-01 10:26:08", "link": "http://arxiv.org/abs/1910.00290v1", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Generalization in Generation: A closer look at Exposure Bias", "abstract": "Exposure bias refers to the train-test discrepancy that seemingly arises when\nan autoregressive generative model uses only ground-truth contexts at training\ntime but generated ones at test time. We separate the contributions of the\nmodel and the learning framework to clarify the debate on consequences and\nreview proposed counter-measures. In this light, we argue that generalization\nis the underlying property to address and propose unconditional generation as\nits fundamental benchmark. Finally, we combine latent variable modeling with a\nrecent formulation of exploration in reinforcement learning to obtain a\nrigorous handling of true and generated contexts. Results on language modeling\nand variational sentence auto-encoding confirm the model's generalization\ncapability.", "published": "2019-10-01 10:28:32", "link": "http://arxiv.org/abs/1910.00292v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "BioNLP-OST 2019 RDoC Tasks: Multi-grain Neural Relevance Ranking Using\n  Topics and Attention Based Query-Document-Sentence Interactions", "abstract": "This paper presents our system details and results of participation in the\nRDoC Tasks of BioNLP-OST 2019. Research Domain Criteria (RDoC) construct is a\nmulti-dimensional and broad framework to describe mental health disorders by\ncombining knowledge from genomics to behaviour. Non-availability of RDoC\nlabelled dataset and tedious labelling process hinders the use of RDoC\nframework to reach its full potential in Biomedical research community and\nHealthcare industry. Therefore, Task-1 aims at retrieval and ranking of PubMed\nabstracts relevant to a given RDoC construct and Task-2 aims at extraction of\nthe most relevant sentence from a given PubMed abstract. We investigate (1)\nattention based supervised neural topic model and SVM for retrieval and ranking\nof PubMed abstracts and, further utilize BM25 and other relevance measures for\nre-ranking, (2) supervised and unsupervised sentence ranking models utilizing\nmulti-view representations comprising of query-aware attention-based sentence\nrepresentation (QAR), bag-of-words (BoW) and TF-IDF. Our best systems achieved\n1st rank and scored 0.86 mean average precision (mAP) and 0.58 macro average\naccuracy (MAA) in Task-1 and Task-2 respectively.", "published": "2019-10-01 11:47:36", "link": "http://arxiv.org/abs/1910.00314v2", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Multi-Modal Feature Embedding Approach to Diagnose Alzheimer Disease\n  from Spoken Language", "abstract": "Introduction: Alzheimer's disease is a type of dementia in which early\ndiagnosis plays a major rule in the quality of treatment. Among new works in\nthe diagnosis of Alzheimer's disease, there are many of them analyzing the\nvoice stream acoustically, syntactically or both. The mostly used tools to\nperform these analysis usually include machine learning techniques. Objective:\nDesigning an automatic machine learning based diagnosis system will help in the\nprocedure of early detection. Also, systems, using noninvasive data are\npreferable. Methods: We used are classification system based on spoken\nlanguage. We use three (statistical and neural) approaches to classify audio\nsignals from spoken language into two classes of dementia and control. Result:\nThis work designs a multi-modal feature embedding on the spoken language audio\nsignal using three approaches; N-gram, i-vector, and x-vector. The evaluation\nof the system is done on the cookie picture description task from Pitt Corpus\ndementia bank with the accuracy of 83:6", "published": "2019-10-01 12:03:24", "link": "http://arxiv.org/abs/1910.00330v1", "categories": ["cs.LG", "cs.CL", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Towards French Smart Building Code: Compliance Checking Based on\n  Semantic Rules", "abstract": "Manually checking models for compliance against building regulation is a\ntime-consuming task for architects and construction engineers. There is thus a\nneed for algorithms that process information from construction projects and\nreport non-compliant elements. Still automated code-compliance checking raises\nseveral obstacles. Building regulations are usually published as human readable\ntexts and their content is often ambiguous or incomplete. Also, the vocabulary\nused for expressing such regulations is very different from the vocabularies\nused to express Building Information Models (BIM). Furthermore, the high level\nof details associated to BIM-contained geometries induces complex calculations.\nFinally, the level of complexity of the IFC standard also hinders the\nautomation of IFC processing tasks. Model chart, formal rules and\npre-processors approach allows translating construction regulations into\nsemantic queries. We further demonstrate the usefulness of this approach\nthrough several use cases. We argue our approach is a step forward in bridging\nthe gap between regulation texts and automated checking algorithms. Finally\nwith the recent building ontology BOT recommended by the W3C Linked Building\nData Community Group, we identify perspectives for standardizing and extending\nour approach.", "published": "2019-10-01 12:18:42", "link": "http://arxiv.org/abs/1910.00334v1", "categories": ["cs.AI", "cs.CL", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Global Voices: Crossing Borders in Automatic News Summarization", "abstract": "We construct Global Voices, a multilingual dataset for evaluating\ncross-lingual summarization methods. We extract social-network descriptions of\nGlobal Voices news articles to cheaply collect evaluation data for into-English\nand from-English summarization in 15 languages. Especially, for the\ninto-English summarization task, we crowd-source a high-quality evaluation\ndataset based on guidelines that emphasize accuracy, coverage, and\nunderstandability. To ensure the quality of this dataset, we collect human\nratings to filter out bad summaries, and conduct a survey on humans, which\nshows that the remaining summaries are preferred over the social-network\nsummaries. We study the effect of translation quality in cross-lingual\nsummarization, comparing a translate-then-summarize approach with several\nbaselines. Our results highlight the limitations of the ROUGE metric that are\noverlooked in monolingual summarization. Our dataset is available for download\nat https://forms.gle/gpkJDT6RJWHM1Ztz9 .", "published": "2019-10-01 14:19:40", "link": "http://arxiv.org/abs/1910.00421v4", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Domain Expansion in DNN-based Acoustic Models for Robust Speech\n  Recognition", "abstract": "Training acoustic models with sequentially incoming data -- while both\nleveraging new data and avoiding the forgetting effect-- is an essential\nobstacle to achieving human intelligence level in speech recognition. An\nobvious approach to leverage data from a new domain (e.g., new accented speech)\nis to first generate a comprehensive dataset of all domains, by combining all\navailable data, and then use this dataset to retrain the acoustic models.\nHowever, as the amount of training data grows, storing and retraining on such a\nlarge-scale dataset becomes practically impossible. To deal with this problem,\nin this study, we study several domain expansion techniques which exploit only\nthe data of the new domain to build a stronger model for all domains. These\ntechniques are aimed at learning the new domain with a minimal forgetting\neffect (i.e., they maintain original model performance). These techniques\nmodify the adaptation procedure by imposing new constraints including (1)\nweight constraint adaptation (WCA): keeping the model parameters close to the\noriginal model parameters; (2) elastic weight consolidation (EWC): slowing down\ntraining for parameters that are important for previously established domains;\n(3) soft KL-divergence (SKLD): restricting the KL-divergence between the\noriginal and the adapted model output distributions; and (4) hybrid SKLD-EWC:\nincorporating both SKLD and EWC constraints. We evaluate these techniques in an\naccent adaptation task in which we adapt a deep neural network (DNN) acoustic\nmodel trained with native English to three different English accents:\nAustralian, Hispanic, and Indian. The experimental results show that SKLD\nsignificantly outperforms EWC, and EWC works better than WCA. The hybrid\nSKLD-EWC technique results in the best overall performance.", "published": "2019-10-01 17:40:49", "link": "http://arxiv.org/abs/1910.00565v1", "categories": ["eess.AS", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "TransGCN:Coupling Transformation Assumptions with Graph Convolutional\n  Networks for Link Prediction", "abstract": "Link prediction is an important and frequently studied task that contributes\nto an understanding of the structure of knowledge graphs (KGs) in statistical\nrelational learning. Inspired by the success of graph convolutional networks\n(GCN) in modeling graph data, we propose a unified GCN framework, named\nTransGCN, to address this task, in which relation and entity embeddings are\nlearned simultaneously. To handle heterogeneous relations in KGs, we introduce\na novel way of representing heterogeneous neighborhood by introducing\ntransformation assumptions on the relationship between the subject, the\nrelation, and the object of a triple. Specifically, a relation is treated as a\ntransformation operator transforming a head entity to a tail entity. Both\ntranslation assumption in TransE and rotation assumption in RotatE are explored\nin our framework. Additionally, instead of only learning entity embeddings in\nthe convolution-based encoder while learning relation embeddings in the decoder\nas done by the state-of-art models, e.g., R-GCN, the TransGCN framework trains\nrelation embeddings and entity embeddings simultaneously during the graph\nconvolution operation, thus having fewer parameters compared with R-GCN.\nExperiments show that our models outperform the-state-of-arts methods on both\nFB15K-237 and WN18RR.", "published": "2019-10-01 22:34:40", "link": "http://arxiv.org/abs/1910.00702v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "State-of-the-Art Speech Recognition Using Multi-Stream Self-Attention\n  With Dilated 1D Convolutions", "abstract": "Self-attention has been a huge success for many downstream tasks in NLP,\nwhich led to exploration of applying self-attention to speech problems as well.\nThe efficacy of self-attention in speech applications, however, seems not fully\nblown yet since it is challenging to handle highly correlated speech frames in\nthe context of self-attention. In this paper we propose a new neural network\nmodel architecture, namely multi-stream self-attention, to address the issue\nthus make the self-attention mechanism more effective for speech recognition.\nThe proposed model architecture consists of parallel streams of self-attention\nencoders, and each stream has layers of 1D convolutions with dilated kernels\nwhose dilation rates are unique given stream, followed by a self-attention\nlayer. The self-attention mechanism in each stream pays attention to only one\nresolution of input speech frames and the attentive computation can be more\nefficient. In a later stage, outputs from all the streams are concatenated then\nlinearly projected to the final embedding. By stacking the proposed\nmulti-stream self-attention encoder blocks and rescoring the resultant lattices\nwith neural network language models, we achieve the word error rate of 2.2% on\nthe test-clean dataset of the LibriSpeech corpus, the best number reported thus\nfar on the dataset.", "published": "2019-10-01 23:41:28", "link": "http://arxiv.org/abs/1910.00716v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Auto-Sizing the Transformer Network: Improving Speed, Efficiency, and\n  Performance for Low-Resource Machine Translation", "abstract": "Neural sequence-to-sequence models, particularly the Transformer, are the\nstate of the art in machine translation. Yet these neural networks are very\nsensitive to architecture and hyperparameter settings. Optimizing these\nsettings by grid or random search is computationally expensive because it\nrequires many training runs. In this paper, we incorporate architecture search\ninto a single training run through auto-sizing, which uses regularization to\ndelete neurons in a network over the course of training. On very low-resource\nlanguage pairs, we show that auto-sizing can improve BLEU scores by up to 3.9\npoints while removing one-third of the parameters from the model.", "published": "2019-10-01 19:21:26", "link": "http://arxiv.org/abs/1910.06717v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Modularized Neural Network with Language-Specific Output Layers for\n  Cross-lingual Voice Conversion", "abstract": "This paper presents a cross-lingual voice conversion framework that adopts a\nmodularized neural network. The modularized neural network has a common input\nstructure that is shared for both languages, and two separate output modules,\none for each language. The idea is motivated by the fact that phonetic systems\nof languages are similar because humans share a common vocal production system,\nbut acoustic renderings, such as prosody and phonotactic, vary a lot from\nlanguage to language. The modularized neural network is trained to map Phonetic\nPosteriorGram (PPG) to acoustic features for multiple speakers. It is\nconditioned on a speaker i-vector to generate the desired target voice. We\nvalidated the idea between English and Mandarin languages in objective and\nsubjective tests. In addition, mixed-lingual PPG derived from a unified\nEnglish-Mandarin acoustic model is proposed to capture the linguistic\ninformation from both languages. It is found that our proposed modularized\nneural network significantly outperforms the baseline approaches in terms of\nspeech quality and speaker individuality, and mixed-lingual PPG representation\nfurther improves the conversion performance.", "published": "2019-10-01 15:52:01", "link": "http://arxiv.org/abs/1910.00496v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Latent space representation for multi-target speaker detection and\n  identification with a sparse dataset using Triplet neural networks", "abstract": "We present an approach to tackle the speaker recognition problem using\nTriplet Neural Networks. Currently, the $i$-vector representation with\nprobabilistic linear discriminant analysis (PLDA) is the most commonly used\ntechnique to solve this problem, due to high classification accuracy with a\nrelatively short computation time. In this paper, we explore a neural network\napproach, namely Triplet Neural Networks (TNNs), to built a latent space for\ndifferent classifiers to solve the Multi-Target Speaker Detection and\nIdentification Challenge Evaluation 2018 (MCE 2018) dataset. This training set\ncontains $i$-vectors from 3,631 speakers, with only 3 samples for each speaker,\nthus making speaker recognition a challenging task. When using the train and\ndevelopment set for training both the TNN and baseline model (i.e., similarity\nevaluation directly on the $i$-vector representation), our proposed model\noutperforms the baseline by 23%. When reducing the training data to only using\nthe train set, our method results in 309 confusions for the Multi-target\nspeaker identification task, which is 46% better than the baseline model. These\nresults show that the representational power of TNNs is especially evident when\ntraining on small datasets with few instances available per class.", "published": "2019-10-01 04:59:24", "link": "http://arxiv.org/abs/1910.01463v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "68T10, 68Txx"], "primary_category": "cs.SD"}
{"title": "Additional Shared Decoder on Siamese Multi-view Encoders for Learning\n  Acoustic Word Embeddings", "abstract": "Acoustic word embeddings --- fixed-dimensional vector representations of\narbitrary-length words --- have attracted increasing interest in\nquery-by-example spoken term detection. Recently, on the fact that the\northography of text labels partly reflects the phonetic similarity between the\nwords' pronunciation, a multi-view approach has been introduced that jointly\nlearns acoustic and text embeddings. It showed that it is possible to learn\ndiscriminative embeddings by designing the objective which takes text labels as\nwell as word segments. In this paper, we propose a network architecture that\nexpands the multi-view approach by combining the Siamese multi-view encoders\nwith a shared decoder network to maximize the effect of the relationship\nbetween acoustic and text embeddings in embedding space. Discriminatively\ntrained with multi-view triplet loss and decoding loss, our proposed approach\nachieves better performance on acoustic word discrimination task with the WSJ\ndataset, resulting in 11.1% relative improvement in average precision. We also\npresent experimental results on cross-view word discrimination and word level\nspeech recognition tasks.", "published": "2019-10-01 12:36:18", "link": "http://arxiv.org/abs/1910.00341v1", "categories": ["eess.AS", "cs.IR", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
