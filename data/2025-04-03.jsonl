{"title": "AD-GPT: Large Language Models in Alzheimer's Disease", "abstract": "Large language models (LLMs) have emerged as powerful tools for medical\ninformation retrieval, yet their accuracy and depth remain limited in\nspecialized domains such as Alzheimer's disease (AD), a growing global health\nchallenge. To address this gap, we introduce AD-GPT, a domain-specific\ngenerative pre-trained transformer designed to enhance the retrieval and\nanalysis of AD-related genetic and neurobiological information. AD-GPT\nintegrates diverse biomedical data sources, including potential AD-associated\ngenes, molecular genetic information, and key gene variants linked to brain\nregions. We develop a stacked LLM architecture combining Llama3 and BERT,\noptimized for four critical tasks in AD research: (1) genetic information\nretrieval, (2) gene-brain region relationship assessment, (3) gene-AD\nrelationship analysis, and (4) brain region-AD relationship mapping.\nComparative evaluations against state-of-the-art LLMs demonstrate AD-GPT's\nsuperior precision and reliability across these tasks, underscoring its\npotential as a robust and specialized AI tool for advancing AD research and\nbiomarker discovery.", "published": "2025-04-03 22:49:10", "link": "http://arxiv.org/abs/2504.03071v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Task as Context Prompting for Accurate Medical Symptom Coding Using Large Language Models", "abstract": "Accurate medical symptom coding from unstructured clinical text, such as\nvaccine safety reports, is a critical task with applications in\npharmacovigilance and safety monitoring. Symptom coding, as tailored in this\nstudy, involves identifying and linking nuanced symptom mentions to\nstandardized vocabularies like MedDRA, differentiating it from broader medical\ncoding tasks. Traditional approaches to this task, which treat symptom\nextraction and linking as independent workflows, often fail to handle the\nvariability and complexity of clinical narratives, especially for rare cases.\nRecent advancements in Large Language Models (LLMs) offer new opportunities but\nface challenges in achieving consistent performance. To address these issues,\nwe propose Task as Context (TACO) Prompting, a novel framework that unifies\nextraction and linking tasks by embedding task-specific context into LLM\nprompts. Our study also introduces SYMPCODER, a human-annotated dataset derived\nfrom Vaccine Adverse Event Reporting System (VAERS) reports, and a two-stage\nevaluation framework to comprehensively assess both symptom linking and mention\nfidelity. Our comprehensive evaluation of multiple LLMs, including Llama2-chat,\nJackalope-7b, GPT-3.5 Turbo, GPT-4 Turbo, and GPT-4o, demonstrates TACO's\neffectiveness in improving flexibility and accuracy for tailored tasks like\nsymptom coding, paving the way for more specific coding tasks and advancing\nclinical text processing methodologies.", "published": "2025-04-03 21:57:17", "link": "http://arxiv.org/abs/2504.03051v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLM Library Learning Fails: A LEGO-Prover Case Study", "abstract": "Recent advancements in the coding, reasoning, and tool-using abilities of\nLLMs have spurred interest in library learning (i.e., online learning through\nthe creation, storage, and retrieval of reusable and composable functions,\nknowledge, checklists, or lemmas). Such systems often promise improved task\nperformance through the automatic creation of broadly applicable tools, as well\nas superior computational performance through the caching of reasoning (i.e.,\nthe storage of generated tools). However, we find strong reason to be\nskeptical. We perform a deep dive into one such system, LEGO-Prover, which\npurports to learn reusable lemmas for mathematical reasoning. We find no\nevidence of the direct reuse of learned lemmas, and find evidence against the\nsoft reuse of learned lemmas (i.e., reuse by modifying relevant examples).\nCrucially, we find that LEGO-Prover does not in fact improve over the simple\nbaseline of prompting the model - the improvements in task accuracy vanish once\ncomputational cost is accounted for. Our findings suggest that serious\nmisconceptions exist as to the effectiveness of these techniques, that a\nserious re-examination of the state of LLM-based library learning is required,\nand that we require much stronger standards for evaluation including\nbehavioural analysis and ensuring that an equal computational budget is used\nfor baselines.", "published": "2025-04-03 21:53:51", "link": "http://arxiv.org/abs/2504.03048v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Extending CREAMT: Leveraging Large Language Models for Literary Translation Post-Editing", "abstract": "Post-editing machine translation (MT) for creative texts, such as literature,\nrequires balancing efficiency with the preservation of creativity and style.\nWhile neural MT systems struggle with these challenges, large language models\n(LLMs) offer improved capabilities for context-aware and creative translation.\nThis study evaluates the feasibility of post-editing literary translations\ngenerated by LLMs. Using a custom research tool, we collaborated with\nprofessional literary translators to analyze editing time, quality, and\ncreativity. Our results indicate that post-editing LLM-generated translations\nsignificantly reduces editing time compared to human translation while\nmaintaining a similar level of creativity. The minimal difference in creativity\nbetween PE and MT, combined with substantial productivity gains, suggests that\nLLMs may effectively support literary translators working with high-resource\nlanguages.", "published": "2025-04-03 21:48:09", "link": "http://arxiv.org/abs/2504.03045v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IPA-CHILDES & G2P+: Feature-Rich Resources for Cross-Lingual Phonology and Phonemic Language Modeling", "abstract": "In this paper, we introduce two resources: (i) G2P+, a tool for converting\northographic datasets to a consistent phonemic representation; and (ii) IPA\nCHILDES, a phonemic dataset of child-centered speech across 31 languages. Prior\ntools for grapheme-to-phoneme conversion result in phonemic vocabularies that\nare inconsistent with established phonemic inventories, an issue which G2P+\naddresses by leveraging the inventories in the Phoible database. Using this\ntool, we augment CHILDES with phonemic transcriptions to produce IPA CHILDES.\nThis new resource fills several gaps in existing phonemic datasets, which often\nlack multilingual coverage, spontaneous speech, and a focus on child-directed\nlanguage. We demonstrate the utility of this dataset for phonological research\nby training phoneme language models on 11 languages and probing them for\ndistinctive features, finding that the distributional properties of phonemes\nare sufficient to learn major class and place features cross-lingually.", "published": "2025-04-03 21:22:19", "link": "http://arxiv.org/abs/2504.03036v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ontologies in Design: How Imagining a Tree Reveals Possibilites and Assumptions in Large Language Models", "abstract": "Amid the recent uptake of Generative AI, sociotechnical scholars and critics\nhave traced a multitude of resulting harms, with analyses largely focused on\nvalues and axiology (e.g., bias). While value-based analyses are crucial, we\nargue that ontologies -- concerning what we allow ourselves to think or talk\nabout -- is a vital but under-recognized dimension in analyzing these systems.\nProposing a need for a practice-based engagement with ontologies, we offer four\norientations for considering ontologies in design: pluralism, groundedness,\nliveliness, and enactment. We share examples of potentialities that are opened\nup through these orientations across the entire LLM development pipeline by\nconducting two ontological analyses: examining the responses of four LLM-based\nchatbots in a prompting exercise, and analyzing the architecture of an\nLLM-based agent simulation. We conclude by sharing opportunities and\nlimitations of working with ontologies in the design and development of\nsociotechnical systems.", "published": "2025-04-03 21:04:36", "link": "http://arxiv.org/abs/2504.03029v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "The Dual-Route Model of Induction", "abstract": "Prior work on in-context copying has shown the existence of induction heads,\nwhich attend to and promote individual tokens during copying. In this work we\nintroduce a new type of induction head: concept-level induction heads, which\ncopy entire lexical units instead of individual tokens. Concept induction heads\nlearn to attend to the ends of multi-token words throughout training, working\nin parallel with token-level induction heads to copy meaningful text. We show\nthat these heads are responsible for semantic tasks like word-level\ntranslation, whereas token induction heads are vital for tasks that can only be\ndone verbatim, like copying nonsense tokens. These two \"routes\" operate\nindependently: in fact, we show that ablation of token induction heads causes\nmodels to paraphrase where they would otherwise copy verbatim. In light of\nthese findings, we argue that although token induction heads are vital for\nspecific tasks, concept induction heads may be more broadly relevant for\nin-context learning.", "published": "2025-04-03 20:40:31", "link": "http://arxiv.org/abs/2504.03022v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Language Models Guidance with Multi-Aspect-Cueing: A Case Study for Competitor Analysis", "abstract": "Competitor analysis is essential in modern business due to the influence of\nindustry rivals on strategic planning. It involves assessing multiple aspects\nand balancing trade-offs to make informed decisions. Recent Large Language\nModels (LLMs) have demonstrated impressive capabilities to reason about such\ntrade-offs but grapple with inherent limitations such as a lack of knowledge\nabout contemporary or future realities and an incomplete understanding of a\nmarket's competitive landscape. In this paper, we address this gap by\nincorporating business aspects into LLMs to enhance their understanding of a\ncompetitive market. Through quantitative and qualitative experiments, we\nillustrate how integrating such aspects consistently improves model\nperformance, thereby enhancing analytical efficacy in competitor analysis.", "published": "2025-04-03 19:18:11", "link": "http://arxiv.org/abs/2504.02984v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Hummus: A Dataset of Humorous Multimodal Metaphor Use", "abstract": "Metaphor and humor share a lot of common ground, and metaphor is one of the\nmost common humorous mechanisms. This study focuses on the humorous capacity of\nmultimodal metaphors, which has not received due attention in the community. We\ntake inspiration from the Incongruity Theory of humor, the Conceptual Metaphor\nTheory, and the annotation scheme behind the VU Amsterdam Metaphor Corpus, and\ndeveloped a novel annotation scheme for humorous multimodal metaphor use in\nimage-caption pairs. We create the Hummus Dataset of Humorous Multimodal\nMetaphor Use, providing expert annotation on 1k image-caption pairs sampled\nfrom the New Yorker Caption Contest corpus. Using the dataset, we test\nstate-of-the-art multimodal large language models (MLLMs) on their ability to\ndetect and understand humorous multimodal metaphor use. Our experiments show\nthat current MLLMs still struggle with processing humorous multimodal\nmetaphors, particularly with regard to integrating visual and textual\ninformation. We release our dataset and code at\ngithub.com/xiaoyuisrain/humorous-multimodal-metaphor-use.", "published": "2025-04-03 19:15:01", "link": "http://arxiv.org/abs/2504.02983v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "A Bayesian account of pronoun and neopronoun acquisition", "abstract": "A major challenge to equity among members of queer communities is the use of\none's chosen forms of reference, such as personal names or pronouns. Speakers\noften dismiss their misuses of pronouns as \"unintentional\", and claim that\ntheir errors reflect many decades of fossilized mainstream language use, as\nwell as attitudes or expectations about the relationship between one's\nappearance and acceptable forms of reference. We argue for explicitly modeling\nindividual differences in pronoun selection and present a probabilistic\ngraphical modeling approach based on the nested Chinese Restaurant Franchise\nProcess (nCRFP) (Ahmed et al., 2013) to account for flexible pronominal\nreference such as chosen names and neopronouns while moving beyond\nform-to-meaning mappings and without lexical co-occurrence statistics to learn\nreferring expressions, as in contemporary language models. We show that such a\nmodel can account for variability in how quickly pronouns or names are\nintegrated into symbolic knowledge and can empower computational systems to be\nboth flexible and respectful of queer people with diverse gender expression.", "published": "2025-04-03 18:49:08", "link": "http://arxiv.org/abs/2504.02973v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "QID: Efficient Query-Informed ViTs in Data-Scarce Regimes for OCR-free Visual Document Understanding", "abstract": "In Visual Document Understanding (VDU) tasks, fine-tuning a pre-trained\nVision-Language Model (VLM) with new datasets often falls short in optimizing\nthe vision encoder to identify query-specific regions in text-rich document\nimages. Existing methods that directly inject queries into model layers by\nmodifying the network architecture often struggle to adapt to new datasets with\nlimited annotations. To address this, we introduce QID, a novel, streamlined,\narchitecture-preserving approach that integrates query embeddings into the\nvision encoder, leading to notable performance gains, particularly in\ndata-scarce fine-tuning scenarios. Specifically, our approach introduces a\ndual-module framework: a query-aware module that generates a unique query\nvector to precisely guide the model's focus, as well as a query-agnostic module\nthat captures the positional relationships among tokens, ensuring robust\nspatial understanding. Notably, both modules operate independently of the\nvision attention blocks, facilitating targeted learning of query embeddings and\nenhancing visual semantic identification. Experiments with OCR-free VLMs across\nmultiple datasets demonstrate significant performance improvements using our\nmethod, especially in handling text-rich documents in data-scarce environments.", "published": "2025-04-03 18:47:16", "link": "http://arxiv.org/abs/2504.02971v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "CoLa -- Learning to Interactively Collaborate with Large LMs", "abstract": "LLMs' remarkable ability to tackle a wide range of language tasks opened new\nopportunities for collaborative human-AI problem solving. LLMs can amplify\nhuman capabilities by applying their intuitions and reasoning strategies at\nscale. We explore whether human guides can be simulated, by generalizing from\nhuman demonstrations of guiding an AI system to solve complex language\nproblems. We introduce CoLa, a novel self-guided learning paradigm for training\nautomated $\\textit{guides}$ and evaluate it on two QA datasets, a\npuzzle-solving task, and a constrained text generation task. Our empirical\nresults show that CoLa consistently outperforms competitive approaches across\nall domains. Moreover, a small-sized trained guide outperforms a strong model\nlike GPT-4 when acting as a guide. We compare the strategies employed by humans\nand automated guides by conducting a human study on a QA dataset. We show that\nautomated guides outperform humans by adapting their strategies to reasoners'\ncapabilities and conduct qualitative analyses highlighting distinct differences\nin guiding strategies.", "published": "2025-04-03 18:34:36", "link": "http://arxiv.org/abs/2504.02965v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Understanding Aha Moments: from External Observations to Internal Mechanisms", "abstract": "Large Reasoning Models (LRMs), capable of reasoning through complex problems,\nhave become crucial for tasks like programming, mathematics, and commonsense\nreasoning. However, a key challenge lies in understanding how these models\nacquire reasoning capabilities and exhibit \"aha moments\" when they reorganize\ntheir methods to allocate more thinking time to problems. In this work, we\nsystematically study \"aha moments\" in LRMs, from linguistic patterns,\ndescription of uncertainty, \"Reasoning Collapse\" to analysis in latent space.\nWe demonstrate that the \"aha moment\" is externally manifested in a more\nfrequent use of anthropomorphic tones for self-reflection and an adaptive\nadjustment of uncertainty based on problem difficulty. This process helps the\nmodel complete reasoning without succumbing to \"Reasoning Collapse\".\nInternally, it corresponds to a separation between anthropomorphic\ncharacteristics and pure reasoning, with an increased anthropomorphic tone for\nmore difficult problems. Furthermore, we find that the \"aha moment\" helps\nmodels solve complex problems by altering their perception of problem\ndifficulty. As the layer of the model increases, simpler problems tend to be\nperceived as more complex, while more difficult problems appear simpler.", "published": "2025-04-03 18:22:20", "link": "http://arxiv.org/abs/2504.02956v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cultural Learning-Based Culture Adaptation of Language Models", "abstract": "Adapting large language models (LLMs) to diverse cultural values is a\nchallenging task, as existing LLMs often reflect the values of specific groups\nby default, and potentially causing harm to others. In this paper, we present\nCLCA, a novel framework for enhancing LLM alignment with cultural values based\non cultural learning. The framework leverages simulated social interactions to\ngenerate conversations in which LLMs engage in role-playing within culturally\nadapted social scenarios, capturing implicit cultural norms for model\nfine-tuning. CLCA improves cultural value alignment across various model\narchitectures measured using World Value Survey data, demonstrating the\neffectiveness of our proposed approach. Our results provide early evidence that\nunderstanding intent and social interactions can enhance cultural value\nadaptation in LLMs, highlighting the promise of training approaches based on\ncultural learning.", "published": "2025-04-03 18:16:26", "link": "http://arxiv.org/abs/2504.02953v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Concept Lancet: Image Editing with Compositional Representation Transplant", "abstract": "Diffusion models are widely used for image editing tasks. Existing editing\nmethods often design a representation manipulation procedure by curating an\nedit direction in the text embedding or score space. However, such a procedure\nfaces a key challenge: overestimating the edit strength harms visual\nconsistency while underestimating it fails the editing task. Notably, each\nsource image may require a different editing strength, and it is costly to\nsearch for an appropriate strength via trial-and-error. To address this\nchallenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play\nframework for principled representation manipulation in diffusion-based image\nediting. At inference time, we decompose the source input in the latent (text\nembedding or diffusion score) space as a sparse linear combination of the\nrepresentations of the collected visual concepts. This allows us to accurately\nestimate the presence of concepts in each image, which informs the edit. Based\non the editing task (replace/add/remove), we perform a customized concept\ntransplant process to impose the corresponding editing direction. To\nsufficiently model the concept space, we curate a conceptual representation\ndataset, CoLan-150K, which contains diverse descriptions and scenarios of\nvisual terms and phrases for the latent dictionary. Experiments on multiple\ndiffusion-based image editing baselines show that methods equipped with CoLan\nachieve state-of-the-art performance in editing effectiveness and consistency\npreservation.", "published": "2025-04-03 17:59:58", "link": "http://arxiv.org/abs/2504.02828v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Generative Evaluation of Complex Reasoning in Large Language Models", "abstract": "With powerful large language models (LLMs) demonstrating superhuman reasoning\ncapabilities, a critical question arises: Do LLMs genuinely reason, or do they\nmerely recall answers from their extensive, web-scraped training datasets?\nPublicly released benchmarks inevitably become contaminated once incorporated\ninto subsequent LLM training sets, undermining their reliability as faithful\nassessments. To address this, we introduce KUMO, a generative evaluation\nframework designed specifically for assessing reasoning in LLMs. KUMO\nsynergistically combines LLMs with symbolic engines to dynamically produce\ndiverse, multi-turn reasoning tasks that are partially observable and\nadjustable in difficulty. Through an automated pipeline, KUMO continuously\ngenerates novel tasks across open-ended domains, compelling models to\ndemonstrate genuine generalization rather than memorization. We evaluated 23\nstate-of-the-art LLMs on 5,000 tasks across 100 domains created by KUMO,\nbenchmarking their reasoning abilities against university students. Our\nfindings reveal that many LLMs have outperformed university-level performance\non easy reasoning tasks, and reasoning-scaled LLMs reach university-level\nperformance on complex reasoning challenges. Moreover, LLM performance on KUMO\ntasks correlates strongly with results on newly released real-world reasoning\nbenchmarks, underscoring KUMO's value as a robust, enduring assessment tool for\ngenuine LLM reasoning capabilities.", "published": "2025-04-03 17:54:18", "link": "http://arxiv.org/abs/2504.02810v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MegaMath: Pushing the Limits of Open Math Corpora", "abstract": "Mathematical reasoning is a cornerstone of human intelligence and a key\nbenchmark for advanced capabilities in large language models (LLMs). However,\nthe research community still lacks an open, large-scale, high-quality corpus\ntailored to the demands of math-centric LLM pre-training. We present MegaMath,\nan open dataset curated from diverse, math-focused sources through following\npractices: (1) Revisiting web data: We re-extracted mathematical documents from\nCommon Crawl with math-oriented HTML optimizations, fasttext-based filtering\nand deduplication, all for acquiring higher-quality data on the Internet. (2)\nRecalling Math-related code data: We identified high quality math-related code\nfrom large code training corpus, Stack-V2, further enhancing data diversity.\n(3) Exploring Synthetic data: We synthesized QA-style text, math-related code,\nand interleaved text-code blocks from web data or code data. By integrating\nthese strategies and validating their effectiveness through extensive\nablations, MegaMath delivers 371B tokens with the largest quantity and top\nquality among existing open math pre-training datasets.", "published": "2025-04-03 17:52:07", "link": "http://arxiv.org/abs/2504.02807v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Robustly identifying concepts introduced during chat fine-tuning using crosscoders", "abstract": "Model diffing is the study of how fine-tuning changes a model's\nrepresentations and internal algorithms. Many behaviours of interest are\nintroduced during fine-tuning, and model diffing offers a promising lens to\ninterpret such behaviors. Crosscoders are a recent model diffing method that\nlearns a shared dictionary of interpretable concepts represented as latent\ndirections in both the base and fine-tuned models, allowing us to track how\nconcepts shift or emerge during fine-tuning. Notably, prior work has observed\nconcepts with no direction in the base model, and it was hypothesized that\nthese model-specific latents were concepts introduced during fine-tuning.\nHowever, we identify two issues which stem from the crosscoders L1 training\nloss that can misattribute concepts as unique to the fine-tuned model, when\nthey really exist in both models. We develop Latent Scaling to flag these\nissues by more accurately measuring each latent's presence across models. In\nexperiments comparing Gemma 2 2B base and chat models, we observe that the\nstandard crosscoder suffers heavily from these issues. Building on these\ninsights, we train a crosscoder with BatchTopK loss and show that it\nsubstantially mitigates these issues, finding more genuinely chat-specific and\nhighly interpretable concepts. We recommend practitioners adopt similar\ntechniques. Using the BatchTopK crosscoder, we successfully identify a set of\ngenuinely chat-specific latents that are both interpretable and causally\neffective, representing concepts such as $\\textit{false information}$ and\n$\\textit{personal question}$, along with multiple refusal-related latents that\nshow nuanced preferences for different refusal triggers. Overall, our work\nadvances best practices for the crosscoder-based methodology for model diffing\nand demonstrates that it can provide concrete insights into how chat tuning\nmodifies language model behavior.", "published": "2025-04-03 17:50:24", "link": "http://arxiv.org/abs/2504.02922v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Do \"New Snow Tablets\" Contain Snow? Large Language Models Over-Rely on Names to Identify Ingredients of Chinese Drugs", "abstract": "Traditional Chinese Medicine (TCM) has seen increasing adoption in\nhealthcare, with specialized Large Language Models (LLMs) emerging to support\nclinical applications. A fundamental requirement for these models is accurate\nidentification of TCM drug ingredients. In this paper, we evaluate how general\nand TCM-specialized LLMs perform when identifying ingredients of Chinese drugs.\nOur systematic analysis reveals consistent failure patterns: models often\ninterpret drug names literally, overuse common herbs regardless of relevance,\nand exhibit erratic behaviors when faced with unfamiliar formulations. LLMs\nalso fail to understand the verification task. These findings demonstrate that\ncurrent LLMs rely primarily on drug names rather than possessing systematic\npharmacological knowledge. To address these limitations, we propose a Retrieval\nAugmented Generation (RAG) approach focused on ingredient names. Experiments\nacross 220 TCM formulations show our method significantly improves accuracy\nfrom approximately 50% to 82% in ingredient verification tasks. Our work\nhighlights critical weaknesses in current TCM-specific LLMs and offers a\npractical solution for enhancing their clinical reliability.", "published": "2025-04-03 17:43:45", "link": "http://arxiv.org/abs/2504.03786v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Large Language Models in Mental Health Disorder Detection on Social Media", "abstract": "The detection and intervention of mental health issues represent a critical\nglobal research focus, and social media data has been recognized as an\nimportant resource for mental health research. However, how to utilize Large\nLanguage Models (LLMs) for mental health problem detection on social media\nposes significant challenges. Hence, this paper aims to explore the potential\nof LLM applications in social media data analysis, focusing not only on the\nmost common psychological disorders such as depression and anxiety but also\nincorporating psychotic disorders and externalizing disorders, summarizing the\napplication methods of LLM from different dimensions, such as text data\nanalysis and detection of mental disorders, and revealing the major challenges\nand shortcomings of current research. In addition, the paper provides an\noverview of popular datasets, and evaluation metrics. The survey in this paper\nprovides a comprehensive frame of reference for researchers in the field of\nmental health, while demonstrating the great potential of LLMs in mental health\ndetection to facilitate the further application of LLMs in future mental health\ninterventions.", "published": "2025-04-03 17:43:14", "link": "http://arxiv.org/abs/2504.02800v2", "categories": ["cs.CL", "I.2.7; J.3; J.4"], "primary_category": "cs.CL"}
{"title": "A Framework for Situating Innovations, Opportunities, and Challenges in Advancing Vertical Systems with Large AI Models", "abstract": "Large artificial intelligence (AI) models have garnered significant attention\nfor their remarkable, often \"superhuman\", performance on standardized\nbenchmarks. However, when these models are deployed in high-stakes verticals\nsuch as healthcare, education, and law, they often reveal notable limitations.\nFor instance, they exhibit brittleness to minor variations in input data,\npresent contextually uninformed decisions in critical settings, and undermine\nuser trust by confidently producing or reproducing inaccuracies. These\nchallenges in applying large models necessitate cross-disciplinary innovations\nto align the models' capabilities with the needs of real-world applications. We\nintroduce a framework that addresses this gap through a layer-wise abstraction\nof innovations aimed at meeting users' requirements with large models. Through\nmultiple case studies, we illustrate how researchers and practitioners across\nvarious fields can operationalize this framework. Beyond modularizing the\npipeline of transforming large models into useful \"vertical systems\", we also\nhighlight the dynamism that exists within different layers of the framework.\nFinally, we discuss how our framework can guide researchers and practitioners\nto (i) optimally situate their innovations (e.g., when vertical-specific\ninsights can empower broadly impactful vertical-agnostic innovations), (ii)\nuncover overlooked opportunities (e.g., spotting recurring problems across\nverticals to develop practically useful foundation models instead of chasing\nbenchmarks), and (iii) facilitate cross-disciplinary communication of critical\nchallenges (e.g., enabling a shared vocabulary for AI developers, domain\nexperts, and human-computer interaction scholars).", "published": "2025-04-03 17:40:11", "link": "http://arxiv.org/abs/2504.02793v1", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC"], "primary_category": "cs.AI"}
{"title": "A Framework for Robust Cognitive Evaluation of LLMs", "abstract": "Emergent cognitive abilities in large language models (LLMs) have been widely\nobserved, but their nature and underlying mechanisms remain poorly understood.\nA growing body of research draws on cognitive science to investigate LLM\ncognition, but standard methodologies and experimen-tal pipelines have not yet\nbeen established. To address this gap we develop CognitivEval, a framework for\nsystematically evaluating the artificial cognitive capabilities of LLMs, with a\nparticular emphasis on robustness in response collection. The key features of\nCognitivEval include: (i) automatic prompt permutations, and (ii) testing that\ngathers both generations and model probability estimates. Our experiments\ndemonstrate that these features lead to more robust experimental outcomes.\nUsing CognitivEval, we replicate five classic experiments in cognitive science,\nillustrating the framework's generalizability across various experimental tasks\nand obtaining a cognitive profile of several state of the art LLMs.\nCognitivEval will be released publicly to foster broader collaboration within\nthe cognitive science community.", "published": "2025-04-03 17:35:54", "link": "http://arxiv.org/abs/2504.02789v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HyperRAG: Enhancing Quality-Efficiency Tradeoffs in Retrieval-Augmented Generation with Reranker KV-Cache Reuse", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for\nenhancing the performance of large language models (LLMs) by integrating\nexternal knowledge into the generation process. A key component of RAG\npipelines is the reranker, which selects the most relevant documents from a\npool of retrieved candidates and significantly improves the quality of the\ngenerated responses. While rerankers refine the selection of retrieved\ndocuments in RAG pipelines, they introduce computational challenges that hinder\nhigh throughput and low latency. To address this problem, we propose HyperRAG,\na system that optimizes the trade-off between quality and efficiency in RAG\npipelines by leveraging KV-cache reuse for efficient reranker inference. By\nreusing document-side KV-cache, HyperRAG achieves both high-quality generation\nand system-level efficiency. To fully realize the benefits of KV-cache reuse,\nHyperRAG incorporates a range of system-level optimizations designed to enhance\nefficiency and scalability. Experiments show that HyperRAG achieves a 2 - 3\nthroughput improvement with decoder-only rerankers while also delivering higher\ndownstream performance compared with traditional RAG service.", "published": "2025-04-03 17:08:42", "link": "http://arxiv.org/abs/2504.02921v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MultiBLiMP 1.0: A Massively Multilingual Benchmark of Linguistic Minimal Pairs", "abstract": "We introduce MultiBLiMP 1.0, a massively multilingual benchmark of linguistic\nminimal pairs, covering 101 languages, 6 linguistic phenomena and containing\nmore than 125,000 minimal pairs. Our minimal pairs are created using a fully\nautomated pipeline, leveraging the large-scale linguistic resources of\nUniversal Dependencies and UniMorph. MultiBLiMP 1.0 evaluates abilities of LLMs\nat an unprecedented multilingual scale, and highlights the shortcomings of the\ncurrent state-of-the-art in modelling low-resource languages.", "published": "2025-04-03 17:05:50", "link": "http://arxiv.org/abs/2504.02768v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing LLM Robustness to Perturbed Instructions: An Empirical Study", "abstract": "Large Language Models (LLMs) are highly vulnerable to input perturbations, as\neven a small prompt change may result in a substantially different output.\nExisting methods to enhance LLM robustness are primarily focused on perturbed\ndata samples, whereas improving resiliency to perturbations of task-level\ninstructions has remained relatively underexplored. In this work, we focus on\ncharacter- and word-level edits of task-specific instructions, which\nsubstantially degrade downstream performance. We experiment with a variety of\ntechniques to enhance the robustness of LLMs, including self-denoising and\nrepresentation alignment, testing different models (Llama 3 and Flan-T5),\ndatasets (CoLA, QNLI, SST-2) and instructions (both task-oriented and\nrole-oriented). We find that, on average, self-denoising -- whether performed\nby a frozen LLM or a fine-tuned model -- achieves substantially higher\nperformance gains than alternative strategies, including more complex baselines\nsuch as ensembling and supervised methods.", "published": "2025-04-03 16:17:56", "link": "http://arxiv.org/abs/2504.02733v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Why do LLMs attend to the first token?", "abstract": "Large Language Models (LLMs) tend to attend heavily to the first token in the\nsequence -- creating a so-called attention sink. Many works have studied this\nphenomenon in detail, proposing various ways to either leverage or alleviate\nit. Attention sinks have been connected to quantisation difficulties, security\nissues, and streaming attention. Yet, while many works have provided conditions\nin which they occur or not, a critical question remains shallowly answered: Why\ndo LLMs learn such patterns and how are they being used? In this work, we argue\ntheoretically and empirically that this mechanism provides a method for LLMs to\navoid over-mixing, connecting this to existing lines of work that study\nmathematically how information propagates in Transformers. We conduct\nexperiments to validate our theoretical intuitions and show how choices such as\ncontext length, depth, and data packing influence the sink behaviour. We hope\nthat this study provides a new practical perspective on why attention sinks are\nuseful in LLMs, leading to a better understanding of the attention patterns\nthat form during training.", "published": "2025-04-03 16:17:55", "link": "http://arxiv.org/abs/2504.02732v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ERPO: Advancing Safety Alignment via Ex-Ante Reasoning Preference Optimization", "abstract": "Recent advancements in large language models (LLMs) have accelerated progress\ntoward artificial general intelligence, yet their potential to generate harmful\ncontent poses critical safety challenges. Existing alignment methods often\nstruggle to cover diverse safety scenarios and remain vulnerable to adversarial\nattacks. In this work, we propose Ex-Ante Reasoning Preference Optimization\n(ERPO), a novel safety alignment framework that equips LLMs with explicit\npreemptive reasoning through Chain-of-Thought and provides clear evidence for\nsafety judgments by embedding predefined safety rules. Specifically, our\napproach consists of three stages: first, equipping the model with Ex-Ante\nreasoning through supervised fine-tuning (SFT) using a constructed reasoning\nmodule; second, enhancing safety, usefulness, and efficiency via Direct\nPreference Optimization (DPO); and third, mitigating inference latency with a\nlength-controlled iterative preference optimization strategy. Experiments on\nmultiple open-source LLMs demonstrate that ERPO significantly enhances safety\nperformance while maintaining response efficiency.", "published": "2025-04-03 16:07:38", "link": "http://arxiv.org/abs/2504.02725v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Hidden Space of Safety: Understanding Preference-Tuned LLMs in Multilingual context", "abstract": "Alignment tuning has enabled large language models to excel in reasoning,\ninstruction-following, and minimizing harmful generations. However, despite\ntheir widespread deployment, these models exhibit a monolingual bias, raising\nconcerns about the effectiveness of alignment across languages. Current\nalignment methods predominantly focus on English, leaving it unclear how\nalignment mechanism generalize to multilingual settings. To address this, we\nconduct a systematic analysis of distributional shifts in the embedding space\nof LLMs before and after alignment, uncovering its impact on model behavior\nacross diverse languages. We leverage the alignment-induced separation in\nsafety space as a quantitative tool to measure how alignment enforces safety\nconstraints. Our study evaluates seven LLMs using balanced toxicity datasets\nand parallel text-detoxification benchmarks, revealing substantial disparities\nin the latent representation space between high-resource and low-resource\nlanguages. These findings underscore the need for language-specific fine-tuning\nto ensure fair, reliable and robust multilingual alignment. Our insights\nprovide a foundation for developing truly safe multilingual LLMs, emphasizing\nthe urgency of addressing alignment gaps in underrepresented languages.", "published": "2025-04-03 15:46:46", "link": "http://arxiv.org/abs/2504.02708v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Limitations of Religious Data and the Importance of the Target Domain: Towards Machine Translation for Guinea-Bissau Creole", "abstract": "We introduce a new dataset for machine translation of Guinea-Bissau Creole\n(Kiriol), comprising around 40 thousand parallel sentences to English and\nPortuguese. This dataset is made up of predominantly religious data (from the\nBible and texts from the Jehovah's Witnesses), but also a small amount of\ngeneral domain data (from a dictionary). This mirrors the typical resource\navailability of many low resource languages. We train a number of\ntransformer-based models to investigate how to improve domain transfer from\nreligious data to a more general domain. We find that adding even 300 sentences\nfrom the target domain when training substantially improves the translation\nperformance, highlighting the importance and need for data collection for\nlow-resource languages, even on a small-scale. We additionally find that\nPortuguese-to-Kiriol translation models perform better on average than other\nsource and target language pairs, and investigate how this relates to the\nmorphological complexity of the languages involved and the degree of lexical\noverlap between creoles and lexifiers. Overall, we hope our work will stimulate\nresearch into Kiriol and into how machine translation might better support\ncreole languages in general.", "published": "2025-04-03 15:14:19", "link": "http://arxiv.org/abs/2504.02674v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM for Complex Reasoning Task: An Exploratory Study in Fermi Problems", "abstract": "Fermi Problems (FPs) are mathematical reasoning tasks that require human-like\nlogic and numerical reasoning. Unlike other reasoning questions, FPs often\ninvolve real-world impracticalities or ambiguous concepts, making them\nchallenging even for humans to solve. Despite advancements in AI, particularly\nwith large language models (LLMs) in various reasoning tasks, FPs remain\nrelatively under-explored. This work conducted an exploratory study to examine\nthe capabilities and limitations of LLMs in solving FPs. We first evaluated the\noverall performance of three advanced LLMs using a publicly available FP\ndataset. We designed prompts according to the recently proposed TELeR taxonomy,\nincluding a zero-shot scenario. Results indicated that all three LLMs achieved\na fp_score (range between 0 - 1) below 0.5, underscoring the inherent\ndifficulty of these reasoning tasks. To further investigate, we categorized FPs\ninto standard and specific questions, hypothesizing that LLMs would perform\nbetter on standard questions, which are characterized by clarity and\nconciseness, than on specific ones. Comparative experiments confirmed this\nhypothesis, demonstrating that LLMs performed better on standard FPs in terms\nof both accuracy and efficiency.", "published": "2025-04-03 15:13:36", "link": "http://arxiv.org/abs/2504.02671v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Affordable AI Assistants with Knowledge Graph of Thoughts", "abstract": "Large Language Models (LLMs) are revolutionizing the development of AI\nassistants capable of performing diverse tasks across domains. However, current\nstate-of-the-art LLM-driven agents face significant challenges, including high\noperational costs and limited success rates on complex benchmarks like GAIA. To\naddress these issues, we propose the Knowledge Graph of Thoughts (KGoT), an\ninnovative AI assistant architecture that integrates LLM reasoning with\ndynamically constructed knowledge graphs (KGs). KGoT extracts and structures\ntask-relevant knowledge into a dynamic KG representation, iteratively enhanced\nthrough external tools such as math solvers, web crawlers, and Python scripts.\nSuch structured representation of task-relevant knowledge enables low-cost\nmodels to solve complex tasks effectively. For example, KGoT achieves a 29%\nimprovement in task success rates on the GAIA benchmark compared to Hugging\nFace Agents with GPT-4o mini, while reducing costs by over 36x compared to\nGPT-4o. Improvements for recent reasoning models are similar, e.g., 36% and\n37.5% for Qwen2.5-32B and Deepseek-R1-70B, respectively. KGoT offers a\nscalable, affordable, and high-performing solution for AI assistants.", "published": "2025-04-03 15:11:55", "link": "http://arxiv.org/abs/2504.02670v1", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Efficient Model Editing with Task-Localized Sparse Fine-tuning", "abstract": "Task arithmetic has emerged as a promising approach for editing models by\nrepresenting task-specific knowledge as composable task vectors. However,\nexisting methods rely on network linearization to derive task vectors, leading\nto computational bottlenecks during training and inference. Moreover,\nlinearization alone does not ensure weight disentanglement, the key property\nthat enables conflict-free composition of task vectors. To address this, we\npropose TaLoS which allows to build sparse task vectors with minimal\ninterference without requiring explicit linearization and sharing information\nacross tasks. We find that pre-trained models contain a subset of parameters\nwith consistently low gradient sensitivity across tasks, and that sparsely\nupdating only these parameters allows for promoting weight disentanglement\nduring fine-tuning. Our experiments prove that TaLoS improves training and\ninference efficiency while outperforming current methods in task addition and\nnegation. By enabling modular parameter editing, our approach fosters practical\ndeployment of adaptable foundation models in real-world applications.", "published": "2025-04-03 14:20:06", "link": "http://arxiv.org/abs/2504.02620v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving", "abstract": "The task of issue resolving is to modify a codebase to generate a patch that\naddresses a given issue. However, existing benchmarks, such as SWE-bench, focus\nalmost exclusively on Python, making them insufficient for evaluating Large\nLanguage Models (LLMs) across diverse software ecosystems. To address this, we\nintroduce a multilingual issue-resolving benchmark, called Multi-SWE-bench,\ncovering Java, TypeScript, JavaScript, Go, Rust, C, and C++. It includes a\ntotal of 1,632 high-quality instances, which were carefully annotated from\n2,456 candidates by 68 expert annotators, ensuring that the benchmark can\nprovide an accurate and reliable evaluation. Based on Multi-SWE-bench, we\nevaluate a series of state-of-the-art models using three representative methods\n(Agentless, SWE-agent, and OpenHands) and present a comprehensive analysis with\nkey empirical insights. In addition, we launch a Multi-SWE-RL open-source\ncommunity, aimed at building large-scale reinforcement learning (RL) training\ndatasets for issue-resolving tasks. As an initial contribution, we release a\nset of 4,723 well-structured instances spanning seven programming languages,\nlaying a solid foundation for RL research in this domain. More importantly, we\nopen-source our entire data production pipeline, along with detailed tutorials,\nencouraging the open-source community to continuously contribute and expand the\ndataset. We envision our Multi-SWE-bench and the ever-growing Multi-SWE-RL\ncommunity as catalysts for advancing RL toward its full potential, bringing us\none step closer to the dawn of AGI.", "published": "2025-04-03 14:06:17", "link": "http://arxiv.org/abs/2504.02605v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "LinTO Audio and Textual Datasets to Train and Evaluate Automatic Speech Recognition in Tunisian Arabic Dialect", "abstract": "Developing Automatic Speech Recognition (ASR) systems for Tunisian Arabic\nDialect is challenging due to the dialect's linguistic complexity and the\nscarcity of annotated speech datasets. To address these challenges, we propose\nthe LinTO audio and textual datasets -- comprehensive resources that capture\nphonological and lexical features of Tunisian Arabic Dialect. These datasets\ninclude a variety of texts from numerous sources and real-world audio samples\nfeaturing diverse speakers and code-switching between Tunisian Arabic Dialect\nand English or French. By providing high-quality audio paired with precise\ntranscriptions, the LinTO audio and textual datasets aim to provide qualitative\nmaterial to build and benchmark ASR systems for the Tunisian Arabic Dialect.\n  Keywords -- Tunisian Arabic Dialect, Speech-to-Text, Low-Resource Languages,\nAudio Data Augmentation", "published": "2025-04-03 14:05:56", "link": "http://arxiv.org/abs/2504.02604v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LexPam: Legal Procedure Awareness-Guided Mathematical Reasoning", "abstract": "The legal mathematical reasoning ability of LLMs is crucial when applying\nthem to real-world scenarios, as it directly affects the credibility of the\nLLM. While existing legal LLMs can perform general judicial question answering,\ntheir legal mathematical reasoning capabilities have not been trained.\nOpen-domain reasoning models, though able to generate detailed calculation\nsteps, do not follow the reasoning logic required for legal scenarios.\nAdditionally, there is currently a lack of legal mathematical reasoning\ndatasets to help validate and enhance LLMs' reasoning abilities in legal\ncontexts. To address these issues, we propose the first Chinese legal\nMathematical Reasoning Dataset, LexNum, which includes three common legal\nmathematical reasoning scenarios: economic compensation, work injury\ncompensation, and traffic accident compensation. Based on LexNum, we tested the\nperformance of existing legal LLMs and reasoning LLMs, and introduced LexPam, a\nreinforcement learning algorithm guided by legal procedural awareness to train\nLLMs, enhancing their mathematical reasoning abilities in legal scenarios.\nExperiments on tasks in the three legal scenarios show that the performance of\nexisting legal LLMs and reasoning models in legal mathematical reasoning tasks\nis unsatisfactory. LexPam can enhance the LLM's ability in these tasks.", "published": "2025-04-03 13:54:53", "link": "http://arxiv.org/abs/2504.02590v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking RL Scaling for Vision Language Models: A Transparent, From-Scratch Framework and Comprehensive Evaluation Scheme", "abstract": "Reinforcement learning (RL) has recently shown strong potential in improving\nthe reasoning capabilities of large language models and is now being actively\nextended to vision-language models (VLMs). However, existing RL applications in\nVLMs often rely on heavily engineered frameworks that hinder reproducibility\nand accessibility, while lacking standardized evaluation protocols, making it\ndifficult to compare results or interpret training dynamics. This work\nintroduces a transparent, from-scratch framework for RL in VLMs, offering a\nminimal yet functional four-step pipeline validated across multiple models and\ndatasets. In addition, a standardized evaluation scheme is proposed to assess\ntraining dynamics and reflective behaviors. Extensive experiments on visual\nreasoning tasks uncover key empirical findings: response length is sensitive to\nrandom seeds, reflection correlates with output length, and RL consistently\noutperforms supervised fine-tuning (SFT) in generalization, even with\nhigh-quality data. These findings, together with the proposed framework, aim to\nestablish a reproducible baseline and support broader engagement in RL-based\nVLM research.", "published": "2025-04-03 13:53:28", "link": "http://arxiv.org/abs/2504.02587v2", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Reasoning Inconsistencies and How to Mitigate Them in Deep Learning", "abstract": "The recent advancements in Deep Learning models and techniques have led to\nsignificant strides in performance across diverse tasks and modalities.\nHowever, while the overall capabilities of models show promising growth, our\nunderstanding of their internal reasoning processes remains limited,\nparticularly concerning systematic inconsistencies or errors patterns of\nlogical or inferential flaws. These inconsistencies may manifest as\ncontradictory outputs, failure to generalize across similar tasks, or erroneous\nconclusions in specific contexts. Even detecting and measuring such reasoning\ndiscrepancies is challenging, as they may arise from opaque internal\nprocedures, biases and imbalances in training data, or the inherent complexity\nof the task. Without effective methods to detect, measure, and mitigate these\nerrors, there is a risk of deploying models that are biased, exploitable, or\nlogically unreliable. This thesis aims to address these issues by producing\nnovel methods for deep learning models that reason over knowledge graphs,\nnatural language, and images. The thesis contributes two techniques for\ndetecting and quantifying predictive inconsistencies originating from opaque\ninternal procedures in natural language and image processing models. To\nmitigate inconsistencies from biases in training data, this thesis presents a\ndata efficient sampling method to improve fairness and performance and a\nsynthetic dataset generation approach in low resource scenarios. Finally, the\nthesis offers two techniques to optimize the models for complex reasoning\ntasks. These methods enhance model performance while allowing for more faithful\nand interpretable exploration and exploitation during inference. Critically,\nthis thesis provides a comprehensive framework to improve the robustness,\nfairness, and interpretability of deep learning models across diverse tasks and\nmodalities.", "published": "2025-04-03 13:40:55", "link": "http://arxiv.org/abs/2504.02577v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Language Models reach higher Agreement than Humans in Historical Interpretation", "abstract": "This paper compares historical annotations by humans and Large Language\nModels. The findings reveal that both exhibit some cultural bias, but Large\nLanguage Models achieve a higher consensus on the interpretation of historical\nfacts from short texts. While humans tend to disagree on the basis of their\npersonal biases, Large Models disagree when they skip information or produce\nhallucinations. These findings have significant implications for digital\nhumanities, enabling large-scale annotation and quantitative analysis of\nhistorical data. This offers new educational and research opportunities to\nexplore historical interpretations from different Language Models, fostering\ncritical thinking about bias.", "published": "2025-04-03 13:37:45", "link": "http://arxiv.org/abs/2504.02572v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bias in Large Language Models Across Clinical Applications: A Systematic Review", "abstract": "Background: Large language models (LLMs) are rapidly being integrated into\nhealthcare, promising to enhance various clinical tasks. However, concerns\nexist regarding their potential for bias, which could compromise patient care\nand exacerbate health inequities. This systematic review investigates the\nprevalence, sources, manifestations, and clinical implications of bias in LLMs.\nMethods: We conducted a systematic search of PubMed, OVID, and EMBASE from\ndatabase inception through 2025, for studies evaluating bias in LLMs applied to\nclinical tasks. We extracted data on LLM type, bias source, bias manifestation,\naffected attributes, clinical task, evaluation methods, and outcomes. Risk of\nbias was assessed using a modified ROBINS-I tool. Results: Thirty-eight studies\nmet inclusion criteria, revealing pervasive bias across various LLMs and\nclinical applications. Both data-related bias (from biased training data) and\nmodel-related bias (from model training) were significant contributors. Biases\nmanifested as: allocative harm (e.g., differential treatment recommendations);\nrepresentational harm (e.g., stereotypical associations, biased image\ngeneration); and performance disparities (e.g., variable output quality). These\nbiases affected multiple attributes, most frequently race/ethnicity and gender,\nbut also age, disability, and language. Conclusions: Bias in clinical LLMs is a\npervasive and systemic issue, with a potential to lead to misdiagnosis and\ninappropriate treatment, particularly for marginalized patient populations.\nRigorous evaluation of the model is crucial. Furthermore, the development and\nimplementation of effective mitigation strategies, coupled with continuous\nmonitoring in real-world clinical settings, are essential to ensure the safe,\nequitable, and trustworthy deployment of LLMs in healthcare.", "published": "2025-04-03 13:32:08", "link": "http://arxiv.org/abs/2504.02917v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging LLM For Synchronizing Information Across Multilingual Tables", "abstract": "The vast amount of online information today poses challenges for non-English\nspeakers, as much of it is concentrated in high-resource languages such as\nEnglish and French. Wikipedia reflects this imbalance, with content in\nlow-resource languages frequently outdated or incomplete. Recent research has\nsought to improve cross-language synchronization of Wikipedia tables using\nrule-based methods. These approaches can be effective, but they struggle with\ncomplexity and generalization. This paper explores large language models (LLMs)\nfor multilingual information synchronization, using zero-shot prompting as a\nscalable solution. We introduce the Information Updation dataset, simulating\nthe real-world process of updating outdated Wikipedia tables, and evaluate LLM\nperformance. Our findings reveal that single-prompt approaches often produce\nsuboptimal results, prompting us to introduce a task decomposition strategy\nthat enhances coherence and accuracy. Our proposed method outperforms existing\nbaselines, particularly in Information Updation (1.79%) and Information\nAddition (20.58%), highlighting the model strength in dynamically updating and\nenriching data across architectures.", "published": "2025-04-03 13:15:18", "link": "http://arxiv.org/abs/2504.02559v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UNDO: Understanding Distillation as Optimization", "abstract": "Knowledge distillation has emerged as an effective strategy for compressing\nlarge language models' (LLMs) knowledge into smaller, more efficient student\nmodels. However, standard one-shot distillation methods often produce\nsuboptimal results due to a mismatch between teacher-generated rationales and\nthe student's specific learning requirements. In this paper, we introduce the\nUNDO: UNderstanding Distillation as Optimization framework, designed to bridge\nthis gap by iteratively identifying the student's errors and prompting the\nteacher to refine its explanations accordingly. Each iteration directly targets\nthe student's learning deficiencies, motivating the teacher to provide tailored\nand enhanced rationales that specifically address these weaknesses. Empirical\nevaluations on various challenging mathematical and commonsense reasoning tasks\ndemonstrate that our iterative distillation method, UNDO, significantly\noutperforms standard one-step distillation methods, achieving performance gains\nof up to 20%. Additionally, we show that teacher-generated data refined through\nour iterative process remains effective even when applied to different student\nmodels, underscoring the broad applicability of our approach. Our work\nfundamentally reframes knowledge distillation as an iterative teacher-student\ninteraction, effectively leveraging dynamic refinement by the teacher for\nbetter knowledge distillation.", "published": "2025-04-03 12:18:51", "link": "http://arxiv.org/abs/2504.02521v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ZClip: Adaptive Spike Mitigation for LLM Pre-Training", "abstract": "Training large language models (LLMs) presents numerous challenges, including\ngradient instability and loss spikes. These phenomena can lead to catastrophic\ndivergence, requiring costly checkpoint restoration and data batch skipping.\nTraditional gradient clipping techniques, such as constant or norm-based\nmethods, fail to address these issues effectively due to their reliance on\nfixed thresholds or heuristics, leading to inefficient learning and requiring\nfrequent manual intervention. In this work, we propose ZClip, an adaptive\ngradient clipping algorithm that dynamically adjusts the clipping threshold\nbased on statistical properties of gradient norms over time. Unlike prior\nreactive strategies, ZClip proactively adapts to training dynamics without\nmaking any prior assumptions on the scale and the temporal evolution of\ngradient norms. At its core, it leverages z-score-based anomaly detection to\nidentify and mitigate large gradient spikes, preventing malignant loss spikes\nwhile not interfering with convergence otherwise. Our code is available at:\nhttps://github.com/bluorion-com/ZClip.", "published": "2025-04-03 11:41:55", "link": "http://arxiv.org/abs/2504.02507v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Inference-Time Scaling for Generalist Reward Modeling", "abstract": "Reinforcement learning (RL) has been widely adopted in post-training for\nlarge language models (LLMs) at scale. Recently, the incentivization of\nreasoning capabilities in LLMs from RL indicates that $\\textit{proper learning\nmethods could enable effective inference-time scalability}$. A key challenge of\nRL is to obtain accurate reward signals for LLMs in various domains beyond\nverifiable questions or artificial rules. In this work, we investigate how to\nimprove reward modeling (RM) with more inference compute for general queries,\ni.e. the $\\textbf{inference-time scalability of generalist RM}$, and further,\nhow to improve the effectiveness of performance-compute scaling with proper\nlearning methods. For the RM approach, we adopt pointwise generative reward\nmodeling (GRM) to enable flexibility for different input types and potential\nfor inference-time scaling. For the learning method, we propose Self-Principled\nCritique Tuning (SPCT) to foster scalable reward generation behaviors in GRMs\nthrough online RL, to generate principles adaptively and critiques accurately,\nresulting in $\\textbf{DeepSeek-GRM}$ models. Furthermore, for effective\ninference-time scaling, we use parallel sampling to expand compute usage, and\nintroduce a meta RM to guide voting process for better scaling performance.\nEmpirically, we show that SPCT significantly improves the quality and\nscalability of GRMs, outperforming existing methods and models in various RM\nbenchmarks without severe biases, and could achieve better performance compared\nto training-time scaling. DeepSeek-GRM still meets challenges in some tasks,\nwhich we believe can be addressed by future efforts in generalist reward\nsystems. The models will be released and open-sourced.", "published": "2025-04-03 11:19:49", "link": "http://arxiv.org/abs/2504.02495v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Noiser: Bounded Input Perturbations for Attributing Large Language Models", "abstract": "Feature attribution (FA) methods are common post-hoc approaches that explain\nhow Large Language Models (LLMs) make predictions. Accordingly, generating\nfaithful attributions that reflect the actual inner behavior of the model is\ncrucial. In this paper, we introduce Noiser, a perturbation-based FA method\nthat imposes bounded noise on each input embedding and measures the robustness\nof the model against partially noised input to obtain the input attributions.\nAdditionally, we propose an answerability metric that employs an instructed\njudge model to assess the extent to which highly scored tokens suffice to\nrecover the predicted output. Through a comprehensive evaluation across six\nLLMs and three tasks, we demonstrate that Noiser consistently outperforms\nexisting gradient-based, attention-based, and perturbation-based FA methods in\nterms of both faithfulness and answerability, making it a robust and effective\napproach for explaining language model predictions.", "published": "2025-04-03 10:59:37", "link": "http://arxiv.org/abs/2504.02911v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cognitive Memory in Large Language Models", "abstract": "This paper examines memory mechanisms in Large Language Models (LLMs),\nemphasizing their importance for context-rich responses, reduced\nhallucinations, and improved efficiency. It categorizes memory into sensory,\nshort-term, and long-term, with sensory memory corresponding to input prompts,\nshort-term memory processing immediate context, and long-term memory\nimplemented via external databases or structures. The text-based memory section\ncovers acquisition (selection and summarization), management (updating,\naccessing, storing, and resolving conflicts), and utilization (full-text\nsearch, SQL queries, semantic search). The KV cache-based memory section\ndiscusses selection methods (regularity-based summarization, score-based\napproaches, special token embeddings) and compression techniques (low-rank\ncompression, KV merging, multimodal compression), along with management\nstrategies like offloading and shared attention mechanisms. Parameter-based\nmemory methods (LoRA, TTT, MoE) transform memories into model parameters to\nenhance efficiency, while hidden-state-based memory approaches (chunk\nmechanisms, recurrent transformers, Mamba model) improve long-text processing\nby combining RNN hidden states with current methods. Overall, the paper offers\na comprehensive analysis of LLM memory mechanisms, highlighting their\nsignificance and future research directions.", "published": "2025-04-03 09:58:19", "link": "http://arxiv.org/abs/2504.02441v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation", "abstract": "Long-form video processing fundamentally challenges vision-language models\n(VLMs) due to the high computational costs of handling extended temporal\nsequences. Existing token pruning and feature merging methods often sacrifice\ncritical temporal dependencies or dilute semantic information. We introduce\ndifferential distillation, a principled approach that systematically preserves\ntask-relevant information while suppressing redundancy. Based on this\nprinciple, we develop ViLaMP, a hierarchical video-language model that\nprocesses hour-long videos at ``mixed precision'' through two key mechanisms:\n(1) differential keyframe selection that maximizes query relevance while\nmaintaining temporal distinctiveness at the frame level and (2) differential\nfeature merging that preserves query-salient features in non-keyframes at the\npatch level. Hence, ViLaMP retains full information in keyframes while reducing\nnon-keyframes to their most salient features, resembling mixed-precision\ntraining. Extensive experiments demonstrate ViLaMP's superior performance\nacross four video understanding benchmarks, particularly on long-form content.\nNotably, ViLaMP can process ultra-long videos (up to 10K frames) on a single\nNVIDIA A100 GPU, achieving substantial computational efficiency while\nmaintaining state-of-the-art performance.", "published": "2025-04-03 09:55:09", "link": "http://arxiv.org/abs/2504.02438v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adapting Large Language Models for Multi-Domain Retrieval-Augmented-Generation", "abstract": "Retrieval-Augmented Generation (RAG) enhances LLM factuality, but\nmulti-domain applications face challenges like lack of diverse benchmarks and\npoor out-of-domain generalization. The first contribution of this work is to\nintroduce a diverse benchmark comprising a variety of question-answering tasks\nfrom 8 sources and covering 13 domains. Our second contribution consists in\nsystematically testing out-of-domain generalization for typical RAG tuning\nstrategies. While our findings reveal that standard fine-tuning fails to\ngeneralize effectively, we show that sequence-level distillation with\nteacher-generated labels improves out-of-domain performance by providing more\ncoherent supervision. Our findings highlight key strategies for improving\nmulti-domain RAG robustness.", "published": "2025-04-03 09:03:40", "link": "http://arxiv.org/abs/2504.02411v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FlowKV: A Disaggregated Inference Framework with Low-Latency KV Cache Transfer and Load-Aware Scheduling", "abstract": "Disaggregated inference has become an essential framework that separates the\nprefill (P) and decode (D) stages in large language model inference to improve\nthroughput. However, the KV cache transfer faces significant delays between\nprefill and decode nodes. The block-wise calling method and discontinuous KV\ncache memory allocation increase the number of calls to the transmission\nkernel. Additionally, existing frameworks often fix the roles of P and D nodes,\nleading to computational imbalances. In this paper, we propose FlowKV, a novel\ndisaggregated inference framework, which reduces the average transmission\nlatency of KV cache by 96%, from 0.944s to 0.053s, almost eliminating the\ntransfer time relative to the total request latency by optimizing the KV cache\ntransfer. FlowKV introduces the Load-Aware Scheduler for balanced request\nscheduling and flexible PD node allocation. This design maximizes hardware\nresource utilization, achieving peak system throughput across various\nscenarios, including normal, computational imbalance, and extreme overload\nconditions. Experimental results demonstrate that FlowKV significantly\naccelerates inference by 15.2%-48.9% on LongBench dataset compared to the\nbaseline and supports applications with heterogeneous GPUs.", "published": "2025-04-03 08:58:05", "link": "http://arxiv.org/abs/2504.03775v1", "categories": ["cs.DC", "cs.AI", "cs.CL"], "primary_category": "cs.DC"}
{"title": "AnesBench: Multi-Dimensional Evaluation of LLM Reasoning in Anesthesiology", "abstract": "The application of large language models (LLMs) in the medical field has\ngained significant attention, yet their reasoning capabilities in more\nspecialized domains like anesthesiology remain underexplored. In this paper, we\nsystematically evaluate the reasoning capabilities of LLMs in anesthesiology\nand analyze key factors influencing their performance. To this end, we\nintroduce AnesBench, a cross-lingual benchmark designed to assess\nanesthesiology-related reasoning across three levels: factual retrieval (System\n1), hybrid reasoning (System 1.x), and complex decision-making (System 2).\nThrough extensive experiments, we first explore how model characteristics,\nincluding model scale, Chain of Thought (CoT) length, and language\ntransferability, affect reasoning performance. Then, we further evaluate the\neffectiveness of different training strategies, leveraging our curated\nanesthesiology-related dataset, including continuous pre-training (CPT) and\nsupervised fine-tuning (SFT). Additionally, we also investigate how the\ntest-time reasoning techniques, such as Best-of-N sampling and beam search,\ninfluence reasoning performance, and assess the impact of reasoning-enhanced\nmodel distillation, specifically DeepSeek-R1. We will publicly release\nAnesBench, along with our CPT and SFT training datasets and evaluation code at\nhttps://github.com/MiliLab/AnesBench.", "published": "2025-04-03 08:54:23", "link": "http://arxiv.org/abs/2504.02404v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DaKultur: Evaluating the Cultural Awareness of Language Models for Danish with Native Speakers", "abstract": "Large Language Models (LLMs) have seen widespread societal adoption. However,\nwhile they are able to interact with users in languages beyond English, they\nhave been shown to lack cultural awareness, providing anglocentric or\ninappropriate responses for underrepresented language communities. To\ninvestigate this gap and disentangle linguistic versus cultural proficiency, we\nconduct the first cultural evaluation study for the mid-resource language of\nDanish, in which native speakers prompt different models to solve tasks\nrequiring cultural awareness. Our analysis of the resulting 1,038 interactions\nfrom 63 demographically diverse participants highlights open challenges to\ncultural adaptation: Particularly, how currently employed automatically\ntranslated data are insufficient to train or measure cultural adaptation, and\nhow training on native-speaker data can more than double response acceptance\nrates. We release our study data as DaKultur - the first native Danish cultural\nawareness dataset.", "published": "2025-04-03 08:52:42", "link": "http://arxiv.org/abs/2504.02403v1", "categories": ["cs.CL", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Scaling Analysis of Interleaved Speech-Text Language Models", "abstract": "Existing Speech Language Model (SLM) scaling analysis paints a bleak picture.\nThey predict that SLMs require much more compute and data compared to text,\nleading some to question the feasibility of training high-quality SLMs.\nHowever, modern SLMs are often initialised from pre-trained TextLMs using\nspeech-text interleaving to allow knowledge transfer. This raises the question\n- Do interleaved SLMs scale more efficiently than textless-SLMs? In this paper\nwe answer a resounding, yes! We conduct scaling analysis of interleaved SLMs by\ntraining several dozen and analysing the scaling trends. We see that under this\nsetup SLMs scale more efficiently with compute. Additionally, our results\nindicate that the scaling-dynamics are significantly different than\ntextless-SLMs, suggesting one should allocate notably more of the compute\nbudget for increasing model size over training tokens. We also study the role\nof synthetic data and TextLM model families in unlocking this potential.\nResults suggest, that our scaled up model achieves comparable performance with\nleading models on speech semantic metrics while using less compute and data\nthan other approaches. We open source models, samples, and data -\nhttps://pages.cs.huji.ac.il/adiyoss-lab/sims.", "published": "2025-04-03 08:46:56", "link": "http://arxiv.org/abs/2504.02398v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "The quasi-semantic competence of LLMs: a case study on the part-whole relation", "abstract": "Understanding the extent and depth of the semantic competence of \\emph{Large\nLanguage Models} (LLMs) is at the center of the current scientific agenda in\nArtificial Intelligence (AI) and Computational Linguistics (CL). We contribute\nto this endeavor by investigating their knowledge of the \\emph{part-whole}\nrelation, a.k.a. \\emph{meronymy}, which plays a crucial role in lexical\norganization, but it is significantly understudied. We used data from\nConceptNet relations \\citep{speer2016conceptnet} and human-generated semantic\nfeature norms \\citep{McRae:2005} to explore the abilities of LLMs to deal with\n\\textit{part-whole} relations. We employed several methods based on three\nlevels of analysis: i.) \\textbf{behavioral} testing via prompting, where we\ndirectly queried the models on their knowledge of meronymy, ii.) sentence\n\\textbf{probability} scoring, where we tested models' abilities to discriminate\ncorrect (real) and incorrect (asymmetric counterfactual) \\textit{part-whole}\nrelations, and iii.) \\textbf{concept representation} analysis in vector space,\nwhere we proved the linear organization of the \\textit{part-whole} concept in\nthe embedding and unembedding spaces. These analyses present a complex picture\nthat reveals that the LLMs' knowledge of this relation is only partial. They\nhave just a ``\\emph{quasi}-semantic'' competence and still fall short of\ncapturing deep inferential properties.", "published": "2025-04-03 08:41:26", "link": "http://arxiv.org/abs/2504.02395v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Chart-to-Code Generation in Multimodal Large Language Models via Iterative Dual Preference Learning", "abstract": "Chart-to-code generation, the process of converting chart images into\nexecutable plotting scripts, provides a lossless representation of chart\ninformation, requiring models to accurately capture and summarize all visual\nand structural elements. However, this remains a significant challenge for\nmultimodal large language models (MLLMs), which are not inherently well-aligned\nwith code generation tasks. To bridge this gap, we introduce Chart2Code, a\nnovel iterative dual preference learning framework designed to enhance MLLMs'\nchart-to-code generation capabilities through structured code variant\ngeneration and fine-grained dual reward signals. We validate Chart2Code across\nthree MLLMs and find that iterative preference learning consistently improves\nout-of-distribution chart-to-code generation quality. Throughout this process,\nour dual scoring method, which evaluates both the textual code structure and\nits visual representation, leads to greater performance improvements, even with\na reduced preference dataset size. Further analysis explores the key components\nof our framework and highlights the interplay between chart-to-code generation\nand broader chart reasoning, paving the way for future advancements in chart\ncomprehension.", "published": "2025-04-03 07:51:20", "link": "http://arxiv.org/abs/2504.02906v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LearNAT: Learning NL2SQL with AST-guided Task Decomposition for Large Language Models", "abstract": "Natural Language to SQL (NL2SQL) has emerged as a critical task for enabling\nseamless interaction with databases. Recent advancements in Large Language\nModels (LLMs) have demonstrated remarkable performance in this domain. However,\nexisting NL2SQL methods predominantly rely on closed-source LLMs leveraging\nprompt engineering, while open-source models typically require fine-tuning to\nacquire domain-specific knowledge. Despite these efforts, open-source LLMs\nstruggle with complex NL2SQL tasks due to the indirect expression of user query\nobjectives and the semantic gap between user queries and database schemas.\nInspired by the application of reinforcement learning in mathematical\nproblem-solving to encourage step-by-step reasoning in LLMs, we propose LearNAT\n(Learning NL2SQL with AST-guided Task Decomposition), a novel framework that\nimproves the performance of open-source LLMs on complex NL2SQL tasks through\ntask decomposition and reinforcement learning. LearNAT introduces three key\ncomponents: (1) a Decomposition Synthesis Procedure that leverages Abstract\nSyntax Trees (ASTs) to guide efficient search and pruning strategies for task\ndecomposition, (2) Margin-aware Reinforcement Learning, which employs\nfine-grained step-level optimization via DPO with AST margins, and (3) Adaptive\nDemonstration Reasoning, a mechanism for dynamically selecting relevant\nexamples to enhance decomposition capabilities. Extensive experiments on two\nbenchmark datasets, Spider and BIRD, demonstrate that LearNAT enables a\n7B-parameter open-source LLM to achieve performance comparable to GPT-4, while\noffering improved efficiency and accessibility.", "published": "2025-04-03 06:59:44", "link": "http://arxiv.org/abs/2504.02327v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoTAL: Human-in-the-Loop Prompt Engineering, Chain-of-Thought Reasoning, and Active Learning for Generalizable Formative Assessment Scoring", "abstract": "Large language models (LLMs) have created new opportunities to assist\nteachers and support student learning. Methods such as chain-of-thought (CoT)\nprompting enable LLMs to grade formative assessments in science, providing\nscores and relevant feedback to students. However, the extent to which these\nmethods generalize across curricula in multiple domains (such as science,\ncomputing, and engineering) remains largely untested. In this paper, we\nintroduce Chain-of-Thought Prompting + Active Learning (CoTAL), an LLM-based\napproach to formative assessment scoring that (1) leverages Evidence-Centered\nDesign (ECD) principles to develop curriculum-aligned formative assessments and\nrubrics, (2) applies human-in-the-loop prompt engineering to automate response\nscoring, and (3) incorporates teacher and student feedback to iteratively\nrefine assessment questions, grading rubrics, and LLM prompts for automated\ngrading. Our findings demonstrate that CoTAL improves GPT-4's scoring\nperformance, achieving gains of up to 24.5% over a non-prompt-engineered\nbaseline. Both teachers and students view CoTAL as effective in scoring and\nexplaining student responses, each providing valuable refinements to enhance\ngrading accuracy and explanation quality.", "published": "2025-04-03 06:53:34", "link": "http://arxiv.org/abs/2504.02323v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Harmful Text Detection with Joint Retrieval and External Knowledge", "abstract": "Harmful text detection has become a crucial task in the development and\ndeployment of large language models, especially as AI-generated content\ncontinues to expand across digital platforms. This study proposes a joint\nretrieval framework that integrates pre-trained language models with knowledge\ngraphs to improve the accuracy and robustness of harmful text detection.\nExperimental results demonstrate that the joint retrieval approach\nsignificantly outperforms single-model baselines, particularly in low-resource\ntraining scenarios and multilingual environments. The proposed method\neffectively captures nuanced harmful content by leveraging external contextual\ninformation, addressing the limitations of traditional detection models. Future\nresearch should focus on optimizing computational efficiency, enhancing model\ninterpretability, and expanding multimodal detection capabilities to better\ntackle evolving harmful content patterns. This work contributes to the\nadvancement of AI safety, ensuring more trustworthy and reliable content\nmoderation systems.", "published": "2025-04-03 06:37:55", "link": "http://arxiv.org/abs/2504.02310v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Post-Training Reshapes LLMs: A Mechanistic View on Knowledge, Truthfulness, Refusal, and Confidence", "abstract": "Post-training is essential for the success of large language models (LLMs),\ntransforming pre-trained base models into more useful and aligned post-trained\nmodels. While plenty of works have studied post-training algorithms and\nevaluated post-training models by their outputs, it remains understudied how\npost-training reshapes LLMs internally. In this paper, we compare base and\npost-trained LLMs mechanistically from four perspectives to better understand\npost-training effects. Our findings across model families and datasets reveal\nthat: (1) Post-training does not change the factual knowledge storage\nlocations, and it adapts knowledge representations from the base model while\ndeveloping new knowledge representations; (2) Both truthfulness and refusal can\nbe represented by linear vectors in the hidden representation space. The\ntruthfulness direction is highly similar between the base and post-trained\nmodel, and it is effectively transferable for interventions; (3) The refusal\ndirection is different between the base and post-trained models, and it shows\nlimited forward transferability; (4) Differences in confidence between the base\nand post-trained models cannot be attributed to entropy neurons. Our study\nprovides insights into the fundamental mechanisms preserved and altered during\npost-training, facilitates downstream tasks like model steering, and could\npotentially benefit future research in interpretability and LLM post-training.", "published": "2025-04-03 06:30:55", "link": "http://arxiv.org/abs/2504.02904v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Measurement of LLM's Philosophies of Human Nature", "abstract": "The widespread application of artificial intelligence (AI) in various tasks,\nalong with frequent reports of conflicts or violations involving AI, has\nsparked societal concerns about interactions with AI systems. Based on\nWrightsman's Philosophies of Human Nature Scale (PHNS), a scale empirically\nvalidated over decades to effectively assess individuals' attitudes toward\nhuman nature, we design the standardized psychological scale specifically\ntargeting large language models (LLM), named the Machine-based Philosophies of\nHuman Nature Scale (M-PHNS). By evaluating LLMs' attitudes toward human nature\nacross six dimensions, we reveal that current LLMs exhibit a systemic lack of\ntrust in humans, and there is a significant negative correlation between the\nmodel's intelligence level and its trust in humans. Furthermore, we propose a\nmental loop learning framework, which enables LLM to continuously optimize its\nvalue system during virtual interactions by constructing moral scenarios,\nthereby improving its attitude toward human nature. Experiments demonstrate\nthat mental loop learning significantly enhances their trust in humans compared\nto persona or instruction prompts. This finding highlights the potential of\nhuman-based psychological assessments for LLM, which can not only diagnose\ncognitive biases but also provide a potential solution for ethical learning in\nartificial intelligence. We release the M-PHNS evaluation code and data at\nhttps://github.com/kodenii/M-PHNS.", "published": "2025-04-03 06:22:19", "link": "http://arxiv.org/abs/2504.02304v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "State-of-the-Art Translation of Text-to-Gloss using mBART : A case study of Bangla", "abstract": "Despite a large deaf and dumb population of 1.7 million, Bangla Sign Language\n(BdSL) remains a understudied domain. Specifically, there are no works on\nBangla text-to-gloss translation task. To address this gap, we begin by\naddressing the dataset problem. We take inspiration from grammatical rule based\ngloss generation used in Germany and American sign langauage (ASL) and adapt it\nfor BdSL. We also leverage LLM to generate synthetic data and use\nback-translation, text generation for data augmentation. With dataset prepared,\nwe started experimentation. We fine-tuned pretrained mBART-50 and\nmBERT-multiclass-uncased model on our dataset. We also trained GRU, RNN and a\nnovel seq-to-seq model with multi-head attention. We observe significant high\nperformance (ScareBLEU=79.53) with fine-tuning pretrained mBART-50 multilingual\nmodel from Facebook. We then explored why we observe such high performance with\nmBART. We soon notice an interesting property of mBART -- it was trained on\nshuffled and masked text data. And as we know, gloss form has shuffling\nproperty. So we hypothesize that mBART is inherently good at text-to-gloss\ntasks. To find support against this hypothesis, we trained mBART-50 on\nPHOENIX-14T benchmark and evaluated it with existing literature. Our mBART-50\nfinetune demonstrated State-of-the-Art performance on PHOENIX-14T benchmark,\nfar outperforming existing models in all 6 metrics (ScareBLEU = 63.89, BLEU-1 =\n55.14, BLEU-2 = 38.07, BLEU-3 = 27.13, BLEU-4 = 20.68, COMET = 0.624). Based on\nthe results, this study proposes a new paradigm for text-to-gloss task using\nmBART models. Additionally, our results show that BdSL text-to-gloss task can\ngreatly benefit from rule-based synthetic dataset.", "published": "2025-04-03 05:47:51", "link": "http://arxiv.org/abs/2504.02293v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Accuracy: The Role of Calibration in Self-Improving Large Language Models", "abstract": "Large Language Models (LLMs) have demonstrated remarkable self-improvement\ncapabilities, whereby models iteratively revise their outputs through\nself-generated feedback. While this reflective mechanism has shown promise in\nenhancing task performance, recent studies suggest that it may also introduce\nundesirable biases-most notably, self-bias, or the tendency of LLMs to favor\ntheir own prior outputs. In this work, we extend this line of inquiry by\ninvestigating the impact on confidence estimation. We evaluate three\nrepresentative self-improvement paradigms-basic prompting, Chain-of-Thought\n(CoT) prompting, and tuning-based methods and find that iterative\nself-improvement can lead to systematic overconfidence, as evidenced by a\nsteadily increasing Expected Calibration Error (ECE) and lower accuracy with\nhigh confidence. We then further explore the integration of confidence\ncalibration techniques with self-improvement. Specifically, we compare three\nstrategies: (1) applying calibration after multiple rounds of self-improvement,\n(2) calibrating before self-improvement, and (3) applying calibration\niteratively at each self-improvement step. Our results show that iterative\ncalibration is most effective in reducing ECE, yielding improved calibration.\nOur work pioneers the study of self-improving LLMs from a calibration\nperspective, offering valuable insights into balancing model performance and\nreliability.", "published": "2025-04-03 04:39:54", "link": "http://arxiv.org/abs/2504.02902v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Advancing Semantic Caching for LLMs with Domain-Specific Embeddings and Synthetic Data", "abstract": "This report investigates enhancing semantic caching effectiveness by\nemploying specialized, fine-tuned embedding models. Semantic caching relies on\nembedding similarity rather than exact key matching, presenting unique\nchallenges in balancing precision, query latency, and computational efficiency.\nWe propose leveraging smaller, domain-specific embedding models, fine-tuned\nwith targeted real-world and synthetically generated datasets. Our empirical\nevaluations demonstrate that compact embedding models fine-tuned for just one\nepoch on specialized datasets significantly surpass both state-of-the-art\nopen-source and proprietary alternatives in precision and recall. Moreover, we\nintroduce a novel synthetic data generation pipeline for the semantic cache\nthat mitigates the challenge of limited domain-specific annotated data, further\nboosting embedding performance. Our approach effectively balances computational\noverhead and accuracy, establishing a viable and efficient strategy for\npractical semantic caching implementations.", "published": "2025-04-03 04:27:02", "link": "http://arxiv.org/abs/2504.02268v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLMs as Deceptive Agents: How Role-Based Prompting Induces Semantic Ambiguity in Puzzle Tasks", "abstract": "Recent advancements in Large Language Models (LLMs) have not only showcased\nimpressive creative capabilities but also revealed emerging agentic behaviors\nthat exploit linguistic ambiguity in adversarial settings. In this study, we\ninvestigate how an LLM, acting as an autonomous agent, leverages semantic\nambiguity to generate deceptive puzzles that mislead and challenge human users.\nInspired by the popular puzzle game \"Connections\", we systematically compare\npuzzles produced through zero-shot prompting, role-injected adversarial\nprompts, and human-crafted examples, with an emphasis on understanding the\nunderlying agent decision-making processes. Employing computational analyses\nwith HateBERT to quantify semantic ambiguity, alongside subjective human\nevaluations, we demonstrate that explicit adversarial agent behaviors\nsignificantly heighten semantic ambiguity -- thereby increasing cognitive load\nand reducing fairness in puzzle solving. These findings provide critical\ninsights into the emergent agentic qualities of LLMs and underscore important\nethical considerations for evaluating and safely deploying autonomous language\nsystems in both educational technologies and entertainment.", "published": "2025-04-03 03:45:58", "link": "http://arxiv.org/abs/2504.02254v1", "categories": ["cs.CL", "cs.AI", "68T50, 68T05, 68U35"], "primary_category": "cs.CL"}
{"title": "LLM Social Simulations Are a Promising Research Method", "abstract": "Accurate and verifiable large language model (LLM) simulations of human\nresearch subjects promise an accessible data source for understanding human\nbehavior and training new AI systems. However, results to date have been\nlimited, and few social scientists have adopted these methods. In this position\npaper, we argue that the promise of LLM social simulations can be achieved by\naddressing five tractable challenges. We ground our argument in a literature\nsurvey of empirical comparisons between LLMs and human research subjects,\ncommentaries on the topic, and related work. We identify promising directions\nwith prompting, fine-tuning, and complementary methods. We believe that LLM\nsocial simulations can already be used for exploratory research, such as pilot\nexperiments for psychology, economics, sociology, and marketing. More\nwidespread use may soon be possible with rapidly advancing LLM capabilities,\nand researchers should prioritize developing conceptual models and evaluations\nthat can be iteratively deployed and refined at pace with ongoing AI advances.", "published": "2025-04-03 03:01:26", "link": "http://arxiv.org/abs/2504.02234v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.HC"}
{"title": "From Questions to Insights: Exploring XAI Challenges Reported on Stack Overflow Questions", "abstract": "The lack of interpretability is a major barrier that limits the practical\nusage of AI models. Several eXplainable AI (XAI) techniques (e.g., SHAP, LIME)\nhave been employed to interpret these models' performance. However, users often\nface challenges when leveraging these techniques in real-world scenarios and\nthus submit questions in technical Q&A forums like Stack Overflow (SO) to\nresolve these challenges. We conducted an exploratory study to expose these\nchallenges, their severity, and features that can make XAI techniques more\naccessible and easier to use. Our contributions to this study are fourfold.\nFirst, we manually analyzed 663 SO questions that discussed challenges related\nto XAI techniques. Our careful investigation produced a catalog of seven\nchallenges (e.g., disagreement issues). We then analyzed their prevalence and\nfound that model integration and disagreement issues emerged as the most\nprevalent challenges. Second, we attempt to estimate the severity of each XAI\nchallenge by determining the correlation between challenge types and answer\nmetadata (e.g., the presence of accepted answers). Our analysis suggests that\nmodel integration issues is the most severe challenge. Third, we attempt to\nperceive the severity of these challenges based on practitioners' ability to\nuse XAI techniques effectively in their work. Practitioners' responses suggest\nthat disagreement issues most severely affect the use of XAI techniques.\nFourth, we seek agreement from practitioners on improvements or features that\ncould make XAI techniques more accessible and user-friendly. The majority of\nthem suggest consistency in explanations and simplified integration. Our study\nfindings might (a) help to enhance the accessibility and usability of XAI and\n(b) act as the initial benchmark that can inspire future research.", "published": "2025-04-03 23:33:46", "link": "http://arxiv.org/abs/2504.03085v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Integrating Identity-Based Identification against Adaptive Adversaries in Federated Learning", "abstract": "Federated Learning (FL) has recently emerged as a promising paradigm for\nprivacy-preserving, distributed machine learning. However, FL systems face\nsignificant security threats, particularly from adaptive adversaries capable of\nmodifying their attack strategies to evade detection. One such threat is the\npresence of Reconnecting Malicious Clients (RMCs), which exploit FLs open\nconnectivity by reconnecting to the system with modified attack strategies. To\naddress this vulnerability, we propose integration of Identity-Based\nIdentification (IBI) as a security measure within FL environments. By\nleveraging IBI, we enable FL systems to authenticate clients based on\ncryptographic identity schemes, effectively preventing previously disconnected\nmalicious clients from re-entering the system. Our approach is implemented\nusing the TNC-IBI (Tan-Ng-Chin) scheme over elliptic curves to ensure\ncomputational efficiency, particularly in resource-constrained environments\nlike Internet of Things (IoT). Experimental results demonstrate that\nintegrating IBI with secure aggregation algorithms, such as Krum and Trimmed\nMean, significantly improves FL robustness by mitigating the impact of RMCs. We\nfurther discuss the broader implications of IBI in FL security, highlighting\nresearch directions for adaptive adversary detection, reputation-based\nmechanisms, and the applicability of identity-based cryptographic frameworks in\ndecentralized FL architectures. Our findings advocate for a holistic approach\nto FL security, emphasizing the necessity of proactive defence strategies\nagainst evolving adaptive adversarial threats.", "published": "2025-04-03 22:58:27", "link": "http://arxiv.org/abs/2504.03077v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Properties of Fixed Points of Generalised Extra Gradient Methods Applied to Min-Max Problems", "abstract": "This paper studies properties of fixed points of generalised Extra-gradient\n(GEG) algorithms applied to min-max problems. We discuss connections between\nsaddle points of the objective function of the min-max problem and GEG fixed\npoints. We show that, under appropriate step-size selections, the set of saddle\npoints (Nash equilibria) is a subset of stable fixed points of GEG. Convergence\nproperties of the GEG algorithm are obtained through a stability analysis of a\ndiscrete-time dynamical system. The results and benefits when compared to\nexisting methods are illustrated through numerical examples.", "published": "2025-04-03 22:48:39", "link": "http://arxiv.org/abs/2504.03069v1", "categories": ["math.OC", "cs.AI", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "Design of AI-Powered Tool for Self-Regulation Support in Programming Education", "abstract": "Large Language Model (LLM) tools have demonstrated their potential to deliver\nhigh-quality assistance by providing instant, personalized feedback that is\ncrucial for effective programming education. However, many of these tools\noperate independently from institutional Learning Management Systems, which\ncreates a significant disconnect. This isolation limits the ability to leverage\nlearning materials and exercise context for generating tailored, context-aware\nfeedback. Furthermore, previous research on self-regulated learning and LLM\nsupport mainly focused on knowledge acquisition, not the development of\nimportant self-regulation skills. To address these challenges, we developed\nCodeRunner Agent, an LLM-based programming assistant that integrates the\nCodeRunner, a student-submitted code executing and automated grading plugin in\nMoodle. CodeRunner Agent empowers educators to customize AI-generated feedback\nby incorporating detailed context from lecture materials, programming\nquestions, student answers, and execution results. Additionally, it enhances\nstudents' self-regulated learning by providing strategy-based AI responses.\nThis integrated, context-aware, and skill-focused approach offers promising\navenues for data-driven improvements in programming education.", "published": "2025-04-03 22:47:33", "link": "http://arxiv.org/abs/2504.03068v2", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Context-Aware Self-Adaptation for Domain Generalization", "abstract": "Domain generalization aims at developing suitable learning algorithms in\nsource training domains such that the model learned can generalize well on a\ndifferent unseen testing domain. We present a novel two-stage approach called\nContext-Aware Self-Adaptation (CASA) for domain generalization. CASA simulates\nan approximate meta-generalization scenario and incorporates a self-adaptation\nmodule to adjust pre-trained meta source models to the meta-target domains\nwhile maintaining their predictive capability on the meta-source domains. The\ncore concept of self-adaptation involves leveraging contextual information,\nsuch as the mean of mini-batch features, as domain knowledge to automatically\nadapt a model trained in the first stage to new contexts in the second stage.\nLastly, we utilize an ensemble of multiple meta-source models to perform\ninference on the testing domain. Experimental results demonstrate that our\nproposed method achieves state-of-the-art performance on standard benchmarks.", "published": "2025-04-03 22:33:38", "link": "http://arxiv.org/abs/2504.03064v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Cooperative Inference for Real-Time 3D Human Pose Estimation in Multi-Device Edge Networks", "abstract": "Accurate and real-time three-dimensional (3D) pose estimation is challenging\nin resource-constrained and dynamic environments owing to its high\ncomputational complexity. To address this issue, this study proposes a novel\ncooperative inference method for real-time 3D human pose estimation in mobile\nedge computing (MEC) networks. In the proposed method, multiple end devices\nequipped with lightweight inference models employ dual confidence thresholds to\nfilter ambiguous images. Only the filtered images are offloaded to an edge\nserver with a more powerful inference model for re-evaluation, thereby\nimproving the estimation accuracy under computational and communication\nconstraints. We numerically analyze the performance of the proposed inference\nmethod in terms of the inference accuracy and end-to-end delay and formulate a\njoint optimization problem to derive the optimal confidence thresholds and\ntransmission time for each device, with the objective of minimizing the mean\nper-joint position error (MPJPE) while satisfying the required end-to-end delay\nconstraint. To solve this problem, we demonstrate that minimizing the MPJPE is\nequivalent to maximizing the sum of the inference accuracies for all devices,\ndecompose the problem into manageable subproblems, and present a low-complexity\noptimization algorithm to obtain a near-optimal solution. The experimental\nresults show that a trade-off exists between the MPJPE and end-to-end delay\ndepending on the confidence thresholds. Furthermore, the results confirm that\nthe proposed cooperative inference method achieves a significant reduction in\nthe MPJPE through the optimal selection of confidence thresholds and\ntransmission times, while consistently satisfying the end-to-end delay\nrequirement in various MEC environments.", "published": "2025-04-03 21:58:29", "link": "http://arxiv.org/abs/2504.03052v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Safety Modulation: Enhancing Safety in Reinforcement Learning through Cost-Modulated Rewards", "abstract": "Safe Reinforcement Learning (Safe RL) aims to train an RL agent to maximize\nits performance in real-world environments while adhering to safety\nconstraints, as exceeding safety violation limits can result in severe\nconsequences. In this paper, we propose a novel safe RL approach called Safety\nModulated Policy Optimization (SMPO), which enables safe policy function\nlearning within the standard policy optimization framework through safety\nmodulated rewards. In particular, we consider safety violation costs as\nfeedback from the RL environments that are parallel to the standard awards, and\nintroduce a Q-cost function as safety critic to estimate expected future\ncumulative costs. Then we propose to modulate the rewards using a cost-aware\nweighting function, which is carefully designed to ensure the safety limits\nbased on the estimation of the safety critic, while maximizing the expected\nrewards. The policy function and the safety critic are simultaneously learned\nthrough gradient descent during online interactions with the environment. We\nconduct experiments using multiple RL environments and the experimental results\ndemonstrate that our method outperforms several classic and state-of-the-art\ncomparison methods in terms of overall safe RL performance.", "published": "2025-04-03 21:35:22", "link": "http://arxiv.org/abs/2504.03040v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Deep Reinforcement Learning via Object-Centric Attention", "abstract": "Deep reinforcement learning agents, trained on raw pixel inputs, often fail\nto generalize beyond their training environments, relying on spurious\ncorrelations and irrelevant background details. To address this issue,\nobject-centric agents have recently emerged. However, they require different\nrepresentations tailored to the task specifications. Contrary to deep agents,\nno single object-centric architecture can be applied to any environment.\nInspired by principles of cognitive science and Occam's Razor, we introduce\nObject-Centric Attention via Masking (OCCAM), which selectively preserves\ntask-relevant entities while filtering out irrelevant visual information.\nSpecifically, OCCAM takes advantage of the object-centric inductive bias.\nEmpirical evaluations on Atari benchmarks demonstrate that OCCAM significantly\nimproves robustness to novel perturbations and reduces sample complexity while\nshowing similar or improved performance compared to conventional pixel-based\nRL. These results suggest that structured abstraction can enhance\ngeneralization without requiring explicit symbolic representations or\ndomain-specific object extraction pipelines.", "published": "2025-04-03 20:48:27", "link": "http://arxiv.org/abs/2504.03024v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Localized Definitions and Distributed Reasoning: A Proof-of-Concept Mechanistic Interpretability Study via Activation Patching", "abstract": "This study investigates the localization of knowledge representation in\nfine-tuned GPT-2 models using Causal Layer Attribution via Activation Patching\n(CLAP), a method that identifies critical neural layers responsible for correct\nanswer generation. The model was fine-tuned on 9,958 PubMed abstracts\n(epilepsy: 20,595 mentions, EEG: 11,674 mentions, seizure: 13,921 mentions)\nusing two configurations with validation loss monitoring for early stopping.\nCLAP involved (1) caching clean (correct answer) and corrupted (incorrect\nanswer) activations, (2) computing logit difference to quantify model\npreference, and (3) patching corrupted activations with clean ones to assess\nrecovery. Results revealed three findings: First, patching the first\nfeedforward layer recovered 56% of correct preference, demonstrating that\nassociative knowledge is distributed across multiple layers. Second, patching\nthe final output layer completely restored accuracy (100% recovery), indicating\nthat definitional knowledge is localised. The stronger clean logit difference\nfor definitional questions further supports this localized representation.\nThird, minimal recovery from convolutional layer patching (13.6%) suggests\nlow-level features contribute marginally to high-level reasoning. Statistical\nanalysis confirmed significant layer-specific effects (p<0.01). These findings\ndemonstrate that factual knowledge is more localized and associative knowledge\ndepends on distributed representations. We also showed that editing efficacy\ndepends on task type. Our findings not only reconcile conflicting observations\nabout localization in model editing but also emphasize on using task-adaptive\ntechniques for reliable, interpretable updates.", "published": "2025-04-03 18:54:50", "link": "http://arxiv.org/abs/2504.02976v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Improved Compact Genetic Algorithms with Efficient Caching", "abstract": "Compact Genetic Algorithms (cGAs) are condensed variants of classical Genetic\nAlgorithms (GAs) that use a probability vector representation of the population\ninstead of the complete population. cGAs have been shown to significantly\nreduce the number of function evaluations required while producing outcomes\nsimilar to those of classical GAs. However, cGAs have a tendency to repeatedly\ngenerate the same chromosomes as they approach convergence, resulting in\nunnecessary evaluations of identical chromosomes. This article introduces the\nconcept of caching in cGAs as a means of avoiding redundant evaluations of the\nsame chromosomes. Our proposed approach operates equivalently to cGAs, but\nenhances the algorithm's time efficiency by reducing the number of function\nevaluations. We also present a data structure for efficient cache maintenance\nto ensure low overhead. The proposed caching approach has an asymptotically\nconstant time complexity on average. The proposed method further generalizes\nthe caching mechanism with higher selection pressure for elitism-based cGAs. We\nconduct a rigorous analysis based on experiments on benchmark optimization\nproblems using two well-known cache replacement strategies. The results\ndemonstrate that caching significantly reduces the number of function\nevaluations required while maintaining the same level of performance accuracy.", "published": "2025-04-03 18:47:26", "link": "http://arxiv.org/abs/2504.02972v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "Global-Order GFlowNets", "abstract": "Order-Preserving (OP) GFlowNets have demonstrated remarkable success in\ntackling complex multi-objective (MOO) black-box optimization problems using\nstochastic optimization techniques. Specifically, they can be trained online to\nefficiently sample diverse candidates near the Pareto front. A key advantage of\nOP GFlowNets is their ability to impose a local order on training samples based\non Pareto dominance, eliminating the need for scalarization - a common\nrequirement in other approaches like Preference-Conditional GFlowNets. However,\nwe identify an important limitation of OP GFlowNets: imposing a local order on\ntraining samples can lead to conflicting optimization objectives. To address\nthis issue, we introduce Global-Order GFlowNets, which transform the local\norder into a global one, thereby resolving these conflicts. Our experimental\nevaluations on various benchmarks demonstrate the efficacy and promise of our\nproposed method.", "published": "2025-04-03 18:43:52", "link": "http://arxiv.org/abs/2504.02968v1", "categories": ["cs.LG", "cs.AI", "I.2.6"], "primary_category": "cs.LG"}
{"title": "Digital Forensics in the Age of Large Language Models", "abstract": "Digital forensics plays a pivotal role in modern investigative processes,\nutilizing specialized methods to systematically collect, analyze, and interpret\ndigital evidence for judicial proceedings. However, traditional digital\nforensic techniques are primarily based on manual labor-intensive processes,\nwhich become increasingly insufficient with the rapid growth and complexity of\ndigital data. To this end, Large Language Models (LLMs) have emerged as\npowerful tools capable of automating and enhancing various digital forensic\ntasks, significantly transforming the field. Despite the strides made, general\npractitioners and forensic experts often lack a comprehensive understanding of\nthe capabilities, principles, and limitations of LLM, which limits the full\npotential of LLM in forensic applications. To fill this gap, this paper aims to\nprovide an accessible and systematic overview of how LLM has revolutionized the\ndigital forensics approach. Specifically, it takes a look at the basic concepts\nof digital forensics, as well as the evolution of LLM, and emphasizes the\nsuperior capabilities of LLM. To connect theory and practice, relevant examples\nand real-world scenarios are discussed. We also critically analyze the current\nlimitations of applying LLMs to digital forensics, including issues related to\nillusion, interpretability, bias, and ethical considerations. In addition, this\npaper outlines the prospects for future research, highlighting the need for\neffective use of LLMs for transparency, accountability, and robust\nstandardization in the forensic process.", "published": "2025-04-03 18:32:15", "link": "http://arxiv.org/abs/2504.02963v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Level Up Peer Review in Education: Investigating genAI-driven Gamification system and its influence on Peer Feedback Effectiveness", "abstract": "In software engineering (SE), the ability to review code and critique designs\nis essential for professional practice. However, these skills are rarely\nemphasized in formal education, and peer feedback quality and engagement can\nvary significantly among students. This paper introduces Socratique, a gamified\npeer-assessment platform integrated with Generative AI (GenAI) assistance,\ndesigned to develop students' peer-review skills in a functional programming\ncourse. By incorporating game elements, Socratique aims to motivate students to\nprovide more feedback, while the GenAI assistant offers real-time support in\ncrafting high quality, constructive comments. To evaluate the impact of this\napproach, we conducted a randomized controlled experiment with master's\nstudents comparing a treatment group with a gamified, GenAI-driven setup\nagainst a control group with minimal gamification. Results show that students\nin the treatment group provided significantly more voluntary feedback, with\nhigher scores on clarity, relevance, and specificity - all key aspects of\neffective code and design reviews. This study provides evidence for the\neffectiveness of combining gamification and AI to improve peer review\nprocesses, with implications for fostering review-related competencies in\nsoftware engineering curricula.", "published": "2025-04-03 18:30:25", "link": "http://arxiv.org/abs/2504.02962v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "VARGPT-v1.1: Improve Visual Autoregressive Large Unified Model via Iterative Instruction Tuning and Reinforcement Learning", "abstract": "In this work, we present VARGPT-v1.1, an advanced unified visual\nautoregressive model that builds upon our previous framework VARGPT. The model\npreserves the dual paradigm of next-token prediction for visual understanding\nand next-scale generation for image synthesis. Specifically, VARGPT-v1.1\nintegrates: (1) a novel training strategy combining iterative visual\ninstruction tuning with reinforcement learning through Direct Preference\nOptimization (DPO), (2) an expanded training corpus containing 8.3M\nvisual-generative instruction pairs, (3) an upgraded language model backbone\nusing Qwen2, (4) enhanced image generation resolution, and (5) emergent image\nediting capabilities without architectural modifications. These advancements\nenable VARGPT-v1.1 to achieve state-of-the-art performance in multimodal\nunderstanding and text-to-image instruction-following tasks, demonstrating\nsignificant improvements in both comprehension and generation metrics. Notably,\nthrough visual instruction tuning, the model acquires image editing\nfunctionality while maintaining architectural consistency with its predecessor,\nrevealing the potential for unified visual understanding, generation, and\nediting. Our findings suggest that well-designed unified visual autoregressive\nmodels can effectively adopt flexible training strategies from large language\nmodels (LLMs), exhibiting promising scalability. The codebase and model weights\nare publicly available at https://github.com/VARGPT-family/VARGPT-v1.1.", "published": "2025-04-03 18:06:28", "link": "http://arxiv.org/abs/2504.02949v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Graph Attention for Heterogeneous Graphs with Positional Encoding", "abstract": "Graph Neural Networks (GNNs) have emerged as the de facto standard for\nmodeling graph data, with attention mechanisms and transformers significantly\nenhancing their performance on graph-based tasks. Despite these advancements,\nthe performance of GNNs on heterogeneous graphs often remains complex, with\nnetworks generally underperforming compared to their homogeneous counterparts.\nThis work benchmarks various GNN architectures to identify the most effective\nmethods for heterogeneous graphs, with a particular focus on node\nclassification and link prediction. Our findings reveal that graph attention\nnetworks excel in these tasks. As a main contribution, we explore enhancements\nto these attention networks by integrating positional encodings for node\nembeddings. This involves utilizing the full Laplacian spectrum to accurately\ncapture both the relative and absolute positions of each node within the graph,\nfurther enhancing performance on downstream tasks such as node classification\nand link prediction.", "published": "2025-04-03 18:00:02", "link": "http://arxiv.org/abs/2504.02938v1", "categories": ["cs.LG", "cs.AI", "cs.DM", "math.DG", "stat.ML", "53-02", "G.2.2; I.2.0; I.2.4; G.3"], "primary_category": "cs.LG"}
{"title": "On Vanishing Variance in Transformer Length Generalization", "abstract": "It is a widely known issue that Transformers, when trained on shorter\nsequences, fail to generalize robustly to longer ones at test time. This raises\nthe question of whether Transformer models are real reasoning engines, despite\ntheir impressive abilities in mathematical problem solving and code synthesis.\nIn this paper, we offer a vanishing variance perspective on this issue. To the\nbest of our knowledge, we are the first to demonstrate that even for today's\nfrontier models, a longer sequence length results in a decrease in variance in\nthe output of the multi-head attention modules. On the argmax retrieval and\ndictionary lookup tasks, our experiments show that applying layer normalization\nafter the attention outputs leads to significantly better length\ngeneralization. Our analyses attribute this improvement to a reduction-though\nnot a complete elimination-of the distribution shift caused by vanishing\nvariance.", "published": "2025-04-03 17:59:56", "link": "http://arxiv.org/abs/2504.02827v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Do Two AI Scientists Agree?", "abstract": "When two AI models are trained on the same scientific task, do they learn the\nsame theory or two different theories? Throughout history of science, we have\nwitnessed the rise and fall of theories driven by experimental validation or\nfalsification: many theories may co-exist when experimental data is lacking,\nbut the space of survived theories become more constrained with more\nexperimental data becoming available. We show the same story is true for AI\nscientists. With increasingly more systems provided in training data, AI\nscientists tend to converge in the theories they learned, although sometimes\nthey form distinct groups corresponding to different theories. To\nmechanistically interpret what theories AI scientists learn and quantify their\nagreement, we propose MASS, Hamiltonian-Lagrangian neural networks as AI\nScientists, trained on standard problems in physics, aggregating training\nresults across many seeds simulating the different configurations of AI\nscientists. Our findings suggests for AI scientists switch from learning a\nHamiltonian theory in simple setups to a Lagrangian formulation when more\ncomplex systems are introduced. We also observe strong seed dependence of the\ntraining dynamics and final learned weights, controlling the rise and fall of\nrelevant theories. We finally demonstrate that not only can our neural networks\naid interpretability, it can also be applied to higher dimensional problems.", "published": "2025-04-03 17:58:44", "link": "http://arxiv.org/abs/2504.02822v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Sparse Autoencoders Learn Monosemantic Features in Vision-Language Models", "abstract": "Sparse Autoencoders (SAEs) have recently been shown to enhance\ninterpretability and steerability in Large Language Models (LLMs). In this\nwork, we extend the application of SAEs to Vision-Language Models (VLMs), such\nas CLIP, and introduce a comprehensive framework for evaluating monosemanticity\nin vision representations. Our experimental results reveal that SAEs trained on\nVLMs significantly enhance the monosemanticity of individual neurons while also\nexhibiting hierarchical representations that align well with expert-defined\nstructures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that\napplying SAEs to intervene on a CLIP vision encoder, directly steer output from\nmultimodal LLMs (e.g., LLaVA) without any modifications to the underlying\nmodel. These findings emphasize the practicality and efficacy of SAEs as an\nunsupervised approach for enhancing both the interpretability and control of\nVLMs.", "published": "2025-04-03 17:58:35", "link": "http://arxiv.org/abs/2504.02821v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "GMR-Conv: An Efficient Rotation and Reflection Equivariant Convolution Kernel Using Gaussian Mixture Rings", "abstract": "Symmetry, where certain features remain invariant under geometric\ntransformations, can often serve as a powerful prior in designing convolutional\nneural networks (CNNs). While conventional CNNs inherently support\ntranslational equivariance, extending this property to rotation and reflection\nhas proven challenging, often forcing a compromise between equivariance,\nefficiency, and information loss. In this work, we introduce Gaussian Mixture\nRing Convolution (GMR-Conv), an efficient convolution kernel that smooths\nradial symmetry using a mixture of Gaussian-weighted rings. This design\nmitigates discretization errors of circular kernels, thereby preserving robust\nrotation and reflection equivariance without incurring computational overhead.\nWe further optimize both the space and speed efficiency of GMR-Conv via a novel\nparameterization and computation strategy, allowing larger kernels at an\nacceptable cost. Extensive experiments on eight classification and one\nsegmentation datasets demonstrate that GMR-Conv not only matches conventional\nCNNs' performance but can also surpass it in applications with orientation-less\ndata. GMR-Conv is also proven to be more robust and efficient than the\nstate-of-the-art equivariant learning methods. Our work provides inspiring\nempirical evidence that carefully applied radial symmetry can alleviate the\nchallenges of information loss, marking a promising advance in equivariant\nnetwork architectures. The code is available at\nhttps://github.com/XYPB/GMR-Conv.", "published": "2025-04-03 17:58:18", "link": "http://arxiv.org/abs/2504.02819v1", "categories": ["cs.CV", "cs.AI", "eess.IV", "eess.SP"], "primary_category": "cs.CV"}
{"title": "Systematic Evaluation of Large Vision-Language Models for Surgical Artificial Intelligence", "abstract": "Large Vision-Language Models offer a new paradigm for AI-driven image\nunderstanding, enabling models to perform tasks without task-specific training.\nThis flexibility holds particular promise across medicine, where\nexpert-annotated data is scarce. Yet, VLMs' practical utility in\nintervention-focused domains--especially surgery, where decision-making is\nsubjective and clinical scenarios are variable--remains uncertain. Here, we\npresent a comprehensive analysis of 11 state-of-the-art VLMs across 17 key\nvisual understanding tasks in surgical AI--from anatomy recognition to skill\nassessment--using 13 datasets spanning laparoscopic, robotic, and open\nprocedures. In our experiments, VLMs demonstrate promising generalizability, at\ntimes outperforming supervised models when deployed outside their training\nsetting. In-context learning, incorporating examples during testing, boosted\nperformance up to three-fold, suggesting adaptability as a key strength. Still,\ntasks requiring spatial or temporal reasoning remained difficult. Beyond\nsurgery, our findings offer insights into VLMs' potential for tackling complex\nand dynamic scenarios in clinical and broader real-world applications.", "published": "2025-04-03 17:42:56", "link": "http://arxiv.org/abs/2504.02799v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets", "abstract": "Imitation learning has emerged as a promising approach towards building\ngeneralist robots. However, scaling imitation learning for large robot\nfoundation models remains challenging due to its reliance on high-quality\nexpert demonstrations. Meanwhile, large amounts of video data depicting a wide\nrange of environments and diverse behaviors are readily available. This data\nprovides a rich source of information about real-world dynamics and\nagent-environment interactions. Leveraging this data directly for imitation\nlearning, however, has proven difficult due to the lack of action annotation\nrequired for most contemporary methods. In this work, we present Unified World\nModels (UWM), a framework that allows for leveraging both video and action data\nfor policy learning. Specifically, a UWM integrates an action diffusion process\nand a video diffusion process within a unified transformer architecture, where\nindependent diffusion timesteps govern each modality. We show that by simply\ncontrolling each diffusion timestep, UWM can flexibly represent a policy, a\nforward dynamics, an inverse dynamics, and a video generator. Through simulated\nand real-world experiments, we show that: (1) UWM enables effective pretraining\non large-scale multitask robot datasets with both dynamics and action\npredictions, resulting in more generalizable and robust policies than imitation\nlearning, (2) UWM naturally facilitates learning from action-free video data\nthrough independent control of modality-specific diffusion timesteps, further\nimproving the performance of finetuned policies. Our results suggest that UWM\noffers a promising step toward harnessing large, heterogeneous datasets for\nscalable robot learning, and provides a simple unification between the often\ndisparate paradigms of imitation learning and world modeling. Videos and code\nare available at https://weirdlabuw.github.io/uwm/.", "published": "2025-04-03 17:38:59", "link": "http://arxiv.org/abs/2504.02792v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Towards Green AI-Native Networks: Evaluation of Neural Circuit Policy for Estimating Energy Consumption of Base Stations", "abstract": "Optimization of radio hardware and AI-based network management software yield\nsignificant energy savings in radio access networks. The execution of\nunderlying Machine Learning (ML) models, which enable energy savings through\nrecommended actions, may require additional compute and energy, highlighting\nthe opportunity to explore and adopt accurate and energy-efficient ML\ntechnologies. This work evaluates the novel use of sparsely structured Neural\nCircuit Policies (NCPs) in a use case to estimate the energy consumption of\nbase stations. Sparsity in ML models yields reduced memory, computation and\nenergy demand, hence facilitating a low-cost and scalable solution. We also\nevaluate the generalization capability of NCPs in comparison to traditional and\nwidely used ML models such as Long Short Term Memory (LSTM), via quantifying\ntheir sensitivity to varying model hyper-parameters (HPs). NCPs demonstrated a\nclear reduction in computational overhead and energy consumption. Moreover,\nresults indicated that the NCPs are robust to varying HPs such as number of\nepochs and neurons in each layer, making them a suitable option to ease model\nmanagement and to reduce energy consumption in Machine Learning Operations\n(MLOps) in telecommunications.", "published": "2025-04-03 17:22:39", "link": "http://arxiv.org/abs/2504.02781v1", "categories": ["cs.LG", "cs.AI", "cs.NE", "eess.SP"], "primary_category": "cs.LG"}
{"title": "From Consumption to Collaboration: Measuring Interaction Patterns to Augment Human Cognition in Open-Ended Tasks", "abstract": "The rise of Generative AI, and Large Language Models (LLMs) in particular, is\nfundamentally changing cognitive processes in knowledge work, raising critical\nquestions about their impact on human reasoning and problem-solving\ncapabilities. As these AI systems become increasingly integrated into\nworkflows, they offer unprecedented opportunities for augmenting human thinking\nwhile simultaneously risking cognitive erosion through passive consumption of\ngenerated answers. This tension is particularly pronounced in open-ended tasks,\nwhere effective solutions require deep contextualization and integration of\ndomain knowledge. Unlike structured tasks with established metrics, measuring\nthe quality of human-LLM interaction in such open-ended tasks poses significant\nchallenges due to the absence of ground truth and the iterative nature of\nsolution development. To address this, we present a framework that analyzes\ninteraction patterns along two dimensions: cognitive activity mode (exploration\nvs. exploitation) and cognitive engagement mode (constructive vs. detrimental).\nThis framework provides systematic measurements to evaluate when LLMs are\neffective tools for thought rather than substitutes for human cognition,\nadvancing theoretical understanding and practical guidance for developing AI\nsystems that protect and augment human cognitive capabilities.", "published": "2025-04-03 17:20:36", "link": "http://arxiv.org/abs/2504.02780v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Multi-Head Adaptive Graph Convolution Network for Sparse Point Cloud-Based Human Activity Recognition", "abstract": "Human activity recognition is increasingly vital for supporting independent\nliving, particularly for the elderly and those in need of assistance. Domestic\nservice robots with monitoring capabilities can enhance safety and provide\nessential support. Although image-based methods have advanced considerably in\nthe past decade, their adoption remains limited by concerns over privacy and\nsensitivity to low-light or dark conditions. As an alternative, millimetre-wave\n(mmWave) radar can produce point cloud data which is privacy-preserving.\nHowever, processing the sparse and noisy point clouds remains a long-standing\nchallenge. While graph-based methods and attention mechanisms show promise,\nthey predominantly rely on \"fixed\" kernels; kernels that are applied uniformly\nacross all neighbourhoods, highlighting the need for adaptive approaches that\ncan dynamically adjust their kernels to the specific geometry of each local\nneighbourhood in point cloud data. To overcome this limitation, we introduce an\nadaptive approach within the graph convolutional framework. Instead of a single\nshared weight function, our Multi-Head Adaptive Kernel (MAK) module generates\nmultiple dynamic kernels, each capturing different aspects of the local feature\nspace. By progressively refining local features while maintaining global\nspatial context, our method enables convolution kernels to adapt to varying\nlocal features. Experimental results on benchmark datasets confirm the\neffectiveness of our approach, achieving state-of-the-art performance in human\nactivity recognition. Our source code is made publicly available at:\nhttps://github.com/Gbouna/MAK-GCN", "published": "2025-04-03 17:19:20", "link": "http://arxiv.org/abs/2504.02778v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "How Deep Do Large Language Models Internalize Scientific Literature and Citation Practices?", "abstract": "The spread of scientific knowledge depends on how researchers discover and\ncite previous work. The adoption of large language models (LLMs) in the\nscientific research process introduces a new layer to these citation practices.\nHowever, it remains unclear to what extent LLMs align with human citation\npractices, how they perform across domains, and may influence citation\ndynamics. Here, we show that LLMs systematically reinforce the Matthew effect\nin citations by consistently favoring highly cited papers when generating\nreferences. This pattern persists across scientific domains despite significant\nfield-specific variations in existence rates, which refer to the proportion of\ngenerated references that match existing records in external bibliometric\ndatabases. Analyzing 274,951 references generated by GPT-4o for 10,000 papers,\nwe find that LLM recommendations diverge from traditional citation patterns by\npreferring more recent references with shorter titles and fewer authors.\nEmphasizing their content-level relevance, the generated references are\nsemantically aligned with the content of each paper at levels comparable to the\nground truth references and display similar network effects while reducing\nauthor self-citations. These findings illustrate how LLMs may reshape citation\npractices and influence the trajectory of scientific discovery by reflecting\nand amplifying established trends. As LLMs become more integrated into the\nscientific research process, it is important to understand their role in\nshaping how scientific communities discover and build upon prior work.", "published": "2025-04-03 17:04:56", "link": "http://arxiv.org/abs/2504.02767v1", "categories": ["cs.DL", "cs.AI", "cs.LG", "cs.SI"], "primary_category": "cs.DL"}
{"title": "Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model", "abstract": "In this paper, we propose Scene Splatter, a momentum-based paradigm for video\ndiffusion to generate generic scenes from single image. Existing methods, which\nemploy video generation models to synthesize novel views, suffer from limited\nvideo length and scene inconsistency, leading to artifacts and distortions\nduring further reconstruction. To address this issue, we construct noisy\nsamples from original features as momentum to enhance video details and\nmaintain scene consistency. However, for latent features with the perception\nfield that spans both known and unknown regions, such latent-level momentum\nrestricts the generative ability of video diffusion in unknown regions.\nTherefore, we further introduce the aforementioned consistent video as a\npixel-level momentum to a directly generated video without momentum for better\nrecovery of unseen regions. Our cascaded momentum enables video diffusion\nmodels to generate both high-fidelity and consistent novel views. We further\nfinetune the global Gaussian representations with enhanced frames and render\nnew frames for momentum update in the next step. In this manner, we can\niteratively recover a 3D scene, avoiding the limitation of video length.\nExtensive experiments demonstrate the generalization capability and superior\nperformance of our method in high-fidelity and consistent scene generation.", "published": "2025-04-03 17:00:44", "link": "http://arxiv.org/abs/2504.02764v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "RBT4DNN: Requirements-based Testing of Neural Networks", "abstract": "Deep neural network (DNN) testing is crucial for the reliability and safety\nof critical systems, where failures can have severe consequences. Although\nvarious techniques have been developed to create robustness test suites,\nrequirements-based testing for DNNs remains largely unexplored - yet such tests\nare recognized as an essential component of software validation of critical\nsystems. In this work, we propose a requirements-based test suite generation\nmethod that uses structured natural language requirements formulated in a\nsemantic feature space to create test suites by prompting text-conditional\nlatent diffusion models with the requirement precondition and then using the\nassociated postcondition to define a test oracle to judge outputs of the DNN\nunder test. We investigate the approach using fine-tuned variants of\npre-trained generative models. Our experiments on the MNIST, CelebA-HQ,\nImageNet, and autonomous car driving datasets demonstrate that the generated\ntest suites are realistic, diverse, consistent with preconditions, and capable\nof revealing faults.", "published": "2025-04-03 16:24:49", "link": "http://arxiv.org/abs/2504.02737v2", "categories": ["cs.SE", "cs.AI", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Robust Reinforcement Learning from Human Feedback for Large Language Models Fine-Tuning", "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as a key\ntechnique for aligning the output of large language models (LLMs) with human\npreferences. To learn the reward function, most existing RLHF algorithms use\nthe Bradley-Terry model, which relies on assumptions about human preferences\nthat may not reflect the complexity and variability of real-world judgments. In\nthis paper, we propose a robust algorithm to enhance the performance of\nexisting approaches under such reward model misspecifications. Theoretically,\nour algorithm reduces the variance of reward and policy estimators, leading to\nimproved regret bounds. Empirical evaluations on LLM benchmark datasets\ndemonstrate that the proposed algorithm consistently outperforms existing\nmethods, with 77-81% of responses being favored over baselines on the Anthropic\nHelpful and Harmless dataset.", "published": "2025-04-03 16:16:35", "link": "http://arxiv.org/abs/2504.03784v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "FAST: Federated Active Learning with Foundation Models for Communication-efficient Sampling and Training", "abstract": "Federated Active Learning (FAL) has emerged as a promising framework to\nleverage large quantities of unlabeled data across distributed clients while\npreserving data privacy. However, real-world deployments remain limited by high\nannotation costs and communication-intensive sampling processes, particularly\nin a cross-silo setting, when clients possess substantial local datasets. This\npaper addresses the crucial question: What is the best practice to reduce\ncommunication costs in human-in-the-loop learning with minimal annotator\neffort? Existing FAL methods typically rely on iterative annotation processes\nthat separate active sampling from federated updates, leading to multiple\nrounds of expensive communication and annotation. In response, we introduce\nFAST, a two-pass FAL framework that harnesses foundation models for weak\nlabeling in a preliminary pass, followed by a refinement pass focused\nexclusively on the most uncertain samples. By leveraging representation\nknowledge from foundation models and integrating refinement steps into a\nstreamlined workflow, FAST substantially reduces the overhead incurred by\niterative active sampling. Extensive experiments on diverse medical and natural\nimage benchmarks demonstrate that FAST outperforms existing FAL methods by an\naverage of 4.36% while reducing communication rounds eightfold under a limited\n5% labeling budget.", "published": "2025-04-03 16:12:03", "link": "http://arxiv.org/abs/2504.03783v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Autonomous Human-Robot Interaction via Operator Imitation", "abstract": "Teleoperated robotic characters can perform expressive interactions with\nhumans, relying on the operators' experience and social intuition. In this\nwork, we propose to create autonomous interactive robots, by training a model\nto imitate operator data. Our model is trained on a dataset of human-robot\ninteractions, where an expert operator is asked to vary the interactions and\nmood of the robot, while the operator commands as well as the pose of the human\nand robot are recorded. Our approach learns to predict continuous operator\ncommands through a diffusion process and discrete commands through a\nclassifier, all unified within a single transformer architecture. We evaluate\nthe resulting model in simulation and with a user study on the real system. We\nshow that our method enables simple autonomous human-robot interactions that\nare comparable to the expert-operator baseline, and that users can recognize\nthe different robot moods as generated by our model. Finally, we demonstrate a\nzero-shot transfer of our model onto a different robotic platform with the same\noperator interface.", "published": "2025-04-03 16:06:44", "link": "http://arxiv.org/abs/2504.02724v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Responsible Development of Offensive AI", "abstract": "As AI advances, broader consensus is needed to determine research priorities.\nThis endeavor discusses offensive AI and provides guidance by leveraging\nSustainable Development Goals (SDGs) and interpretability techniques. The\nobjective is to more effectively establish priorities that balance societal\nbenefits against risks. The two forms of offensive AI evaluated in this study\nare vulnerability detection agents, which solve Capture- The-Flag challenges,\nand AI-powered malware.", "published": "2025-04-03 15:37:38", "link": "http://arxiv.org/abs/2504.02701v2", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "SCMPPI: Supervised Contrastive Multimodal Framework for Predicting Protein-Protein Interactions", "abstract": "Protein-Protein Interaction (PPI) prediction is a key task in uncovering\ncellular functional networks and disease mechanisms. However, traditional\nexperimental methods are time-consuming and costly, and existing computational\nmodels face challenges in cross-modal feature fusion, robustness, and\nfalse-negative suppression. In this paper, we propose a novel supervised\ncontrastive multimodal framework, SCMPPI, for PPI prediction. By integrating\nprotein sequence features (AAC, DPC, CKSAAP-ESMC) with PPI network topology\ninformation (Node2Vec graph embedding), and combining an improved supervised\ncontrastive learning strategy, SCMPPI significantly enhances PPI prediction\nperformance. For the PPI task, SCMPPI introduces a negative sample filtering\nmechanism and modifies the contrastive loss function, effectively optimizing\nmultimodal features. Experiments on eight benchmark datasets, including yeast,\nhuman, and H.pylori, show that SCMPPI outperforms existing state-of-the-art\nmethods (such as DF-PPI and TAGPPI) in key metrics such as accuracy ( 98.01%)\nand AUC (99.62%), and demonstrates strong generalization in cross-species\nprediction (AUC > 99% on multi-species datasets). Furthermore, SCMPPI has been\nsuccessfully applied to CD9 networks, the Wnt pathway, and cancer-specific\nnetworks, providing a reliable tool for disease target discovery. This\nframework also offers a new paradigm for multimodal biological information\nfusion and contrastive learning in collaborative optimization for various\ncombined predictions.", "published": "2025-04-03 15:34:02", "link": "http://arxiv.org/abs/2504.02698v1", "categories": ["cs.LG", "cs.AI", "q-bio.QM", "92C40, 68T07", "I.2.6; J.3"], "primary_category": "cs.LG"}
{"title": "STOOD-X methodology: using statistical nonparametric test for OOD Detection Large-Scale datasets enhanced with explainability", "abstract": "Out-of-Distribution (OOD) detection is a critical task in machine learning,\nparticularly in safety-sensitive applications where model failures can have\nserious consequences. However, current OOD detection methods often suffer from\nrestrictive distributional assumptions, limited scalability, and a lack of\ninterpretability. To address these challenges, we propose STOOD-X, a two-stage\nmethodology that combines a Statistical nonparametric Test for OOD Detection\nwith eXplainability enhancements. In the first stage, STOOD-X uses\nfeature-space distances and a Wilcoxon-Mann-Whitney test to identify OOD\nsamples without assuming a specific feature distribution. In the second stage,\nit generates user-friendly, concept-based visual explanations that reveal the\nfeatures driving each decision, aligning with the BLUE XAI paradigm. Through\nextensive experiments on benchmark datasets and multiple architectures, STOOD-X\nachieves competitive performance against state-of-the-art post hoc OOD\ndetectors, particularly in high-dimensional and complex settings. In addition,\nits explainability framework enables human oversight, bias detection, and model\ndebugging, fostering trust and collaboration between humans and AI systems. The\nSTOOD-X methodology therefore offers a robust, explainable, and scalable\nsolution for real-world OOD detection tasks.", "published": "2025-04-03 15:26:03", "link": "http://arxiv.org/abs/2504.02685v1", "categories": ["cs.LG", "cs.AI", "cs.HC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based Reinforcement Learning", "abstract": "We propose a learning architecture that allows symbolic control and guidance\nin reinforcement learning with deep neural networks. We introduce SymDQN, a\nnovel modular approach that augments the existing Dueling Deep Q-Networks\n(DuelDQN) architecture with modules based on the neuro-symbolic framework of\nLogic Tensor Networks (LTNs). The modules guide action policy learning and\nallow reinforcement learning agents to display behaviour consistent with\nreasoning about the environment. Our experiment is an ablation study performed\non the modules. It is conducted in a reinforcement learning environment of a\n5x5 grid navigated by an agent that encounters various shapes, each associated\nwith a given reward. The underlying DuelDQN attempts to learn the optimal\nbehaviour of the agent in this environment, while the modules facilitate shape\nrecognition and reward prediction. We show that our architecture significantly\nimproves learning, both in terms of performance and the precision of the agent.\nThe modularity of SymDQN allows reflecting on the intricacies and complexities\nof combining neural and symbolic approaches in reinforcement learning.", "published": "2025-04-03 14:51:11", "link": "http://arxiv.org/abs/2504.02654v1", "categories": ["cs.AI", "cs.LO", "cs.NE", "I.2.6"], "primary_category": "cs.AI"}
{"title": "Prompt Optimization with Logged Bandit Data", "abstract": "We study how to use naturally available user feedback, such as clicks, to\noptimize large language model (LLM) pipelines for generating personalized\nsentences using prompts. Naive approaches, which estimate the policy gradient\nin the prompt space, suffer either from variance caused by the large action\nspace of prompts or bias caused by inaccurate reward predictions. To circumvent\nthese challenges, we propose a novel kernel-based off-policy gradient method,\nwhich estimates the policy gradient by leveraging similarity among generated\nsentences, substantially reducing variance while suppressing the bias.\nEmpirical results on our newly established suite of benchmarks demonstrate the\neffectiveness of the proposed approach in generating personalized descriptions\nfor movie recommendations, particularly when the number of candidate prompts is\nlarge.", "published": "2025-04-03 14:40:40", "link": "http://arxiv.org/abs/2504.02646v1", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multi-Mission Tool Bench: Assessing the Robustness of LLM based Agents through Related and Dynamic Missions", "abstract": "Large language models (LLMs) demonstrate strong potential as agents for tool\ninvocation due to their advanced comprehension and planning capabilities. Users\nincreasingly rely on LLM-based agents to solve complex missions through\niterative interactions. However, existing benchmarks predominantly access\nagents in single-mission scenarios, failing to capture real-world complexity.\nTo bridge this gap, we propose the Multi-Mission Tool Bench. In the benchmark,\neach test case comprises multiple interrelated missions. This design requires\nagents to dynamically adapt to evolving demands. Moreover, the proposed\nbenchmark explores all possible mission-switching patterns within a fixed\nmission number. Specifically, we propose a multi-agent data generation\nframework to construct the benchmark. We also propose a novel method to\nevaluate the accuracy and efficiency of agent decisions with dynamic decision\ntrees. Experiments on diverse open-source and closed-source LLMs reveal\ncritical factors influencing agent robustness and provide actionable insights\nto the tool invocation society.", "published": "2025-04-03 14:21:33", "link": "http://arxiv.org/abs/2504.02623v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Learning Geometrically-Informed Lyapunov Functions with Deep Diffeomorphic RBF Networks", "abstract": "The practical deployment of learning-based autonomous systems would greatly\nbenefit from tools that flexibly obtain safety guarantees in the form of\ncertificate functions from data. While the geometrical properties of such\ncertificate functions are well understood, synthesizing them using machine\nlearning techniques still remains a challenge. To mitigate this issue, we\npropose a diffeomorphic function learning framework where prior structural\nknowledge of the desired output is encoded in the geometry of a simple\nsurrogate function, which is subsequently augmented through an expressive,\ntopology-preserving state-space transformation. Thereby, we achieve an indirect\nfunction approximation framework that is guaranteed to remain in the desired\nhypothesis space. To this end, we introduce a novel approach to construct\ndiffeomorphic maps based on RBF networks, which facilitate precise, local\ntransformations around data. Finally, we demonstrate our approach by learning\ndiffeomorphic Lyapunov functions from real-world data and apply our method to\ndifferent attractor systems.", "published": "2025-04-03 14:09:17", "link": "http://arxiv.org/abs/2504.02607v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Improving Counterfactual Truthfulness for Molecular Property Prediction through Uncertainty Quantification", "abstract": "Explainable AI (xAI) interventions aim to improve interpretability for\ncomplex black-box models, not only to improve user trust but also as a means to\nextract scientific insights from high-performing predictive systems. In\nmolecular property prediction, counterfactual explanations offer a way to\nunderstand predictive behavior by highlighting which minimal perturbations in\nthe input molecular structure cause the greatest deviation in the predicted\nproperty. However, such explanations only allow for meaningful scientific\ninsights if they reflect the distribution of the true underlying property -- a\nfeature we define as counterfactual truthfulness. To increase this\ntruthfulness, we propose the integration of uncertainty estimation techniques\nto filter counterfactual candidates with high predicted uncertainty. Through\ncomputational experiments with synthetic and real-world datasets, we\ndemonstrate that traditional uncertainty estimation methods, such as ensembles\nand mean-variance estimation, can already substantially reduce the average\nprediction error and increase counterfactual truthfulness, especially for\nout-of-distribution settings. Our results highlight the importance and\npotential impact of incorporating uncertainty estimation into explainability\nmethods, especially considering the relatively high effectiveness of low-effort\ninterventions like model ensembles.", "published": "2025-04-03 14:07:30", "link": "http://arxiv.org/abs/2504.02606v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Knowledge Graph Completion with Mixed Geometry Tensor Factorization", "abstract": "In this paper, we propose a new geometric approach for knowledge graph\ncompletion via low rank tensor approximation. We augment a pretrained and\nwell-established Euclidean model based on a Tucker tensor decomposition with a\nnovel hyperbolic interaction term. This correction enables more nuanced\ncapturing of distributional properties in data better aligned with real-world\nknowledge graphs. By combining two geometries together, our approach improves\nexpressivity of the resulting model achieving new state-of-the-art link\nprediction accuracy with a significantly lower number of parameters compared to\nthe previous Euclidean and hyperbolic models.", "published": "2025-04-03 13:54:43", "link": "http://arxiv.org/abs/2504.02589v1", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Deep learning for music generation. Four approaches and their comparative evaluation", "abstract": "This paper introduces four different artificial intelligence algorithms for\nmusic generation and aims to compare these methods not only based on the\naesthetic quality of the generated music but also on their suitability for\nspecific applications. The first set of melodies is produced by a slightly\nmodified visual transformer neural network that is used as a language model.\nThe second set of melodies is generated by combining chat sonification with a\nclassic transformer neural network (the same method of music generation is\npresented in a previous research), the third set of melodies is generated by\ncombining the Schillinger rhythm theory together with a classic transformer\nneural network, and the fourth set of melodies is generated using GPT3\ntransformer provided by OpenAI. A comparative analysis is performed on the\nmelodies generated by these approaches and the results indicate that\nsignificant differences can be observed between them and regarding the\naesthetic value of them, GPT3 produced the most pleasing melodies, and the\nnewly introduced Schillinger method proved to generate better sounding music\nthan previous sonification methods.", "published": "2025-04-03 13:51:07", "link": "http://arxiv.org/abs/2504.02586v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Rip Current Segmentation: A Novel Benchmark and YOLOv8 Baseline Results", "abstract": "Rip currents are the leading cause of fatal accidents and injuries on many\nbeaches worldwide, emphasizing the importance of automatically detecting these\nhazardous surface water currents. In this paper, we address a novel task: rip\ncurrent instance segmentation. We introduce a comprehensive dataset containing\n$2,466$ images with newly created polygonal annotations for instance\nsegmentation, used for training and validation. Additionally, we present a\nnovel dataset comprising $17$ drone videos (comprising about $24K$ frames)\ncaptured at $30 FPS$, annotated with both polygons for instance segmentation\nand bounding boxes for object detection, employed for testing purposes. We\ntrain various versions of YOLOv8 for instance segmentation on static images and\nassess their performance on the test dataset (videos). The best results were\nachieved by the YOLOv8-nano model (runnable on a portable device), with an\nmAP50 of $88.94%$ on the validation dataset and $81.21%$ macro average on the\ntest dataset. The results provide a baseline for future research in rip current\nsegmentation. Our work contributes to the existing literature by introducing a\ndetailed, annotated dataset, and training a deep learning model for instance\nsegmentation of rip currents. The code, training details and the annotated\ndataset are made publicly available at https://github.com/Irikos/rip_currents.", "published": "2025-04-03 13:14:16", "link": "http://arxiv.org/abs/2504.02558v1", "categories": ["cs.CV", "cs.AI", "I.4.0; I.4.9"], "primary_category": "cs.CV"}
{"title": "GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning", "abstract": "Reinforcement Learning (RL) can directly enhance the reasoning capabilities\nof large language models without extensive reliance on Supervised Fine-Tuning\n(SFT). In this work, we revisit the traditional Policy Gradient (PG) mechanism\nand propose a minimalist RL approach termed Group Policy Gradient (GPG). Unlike\nconventional methods, GPG directly optimize the original RL objective, thus\nobviating the need for surrogate loss functions. As illustrated in our paper,\nby eliminating both the critic and reference models, and avoiding KL divergence\nconstraints, our approach significantly simplifies the training process when\ncompared to Group Relative Policy Optimization (GRPO). Our approach achieves\nsuperior performance without relying on auxiliary techniques or adjustments.\nExtensive experiments demonstrate that our method not only reduces\ncomputational costs but also consistently outperforms GRPO across various\nunimodal and multimodal tasks. Our code is available at\nhttps://github.com/AMAP-ML/GPG.", "published": "2025-04-03 12:53:41", "link": "http://arxiv.org/abs/2504.02546v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Fourier Sliced-Wasserstein Embedding for Multisets and Measures", "abstract": "We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to\nembed multisets and measures over $\\mathbb{R}^d$ into Euclidean space.\n  Our proposed embedding approximately preserves the sliced Wasserstein\ndistance on distributions, thereby yielding geometrically meaningful\nrepresentations that better capture the structure of the input. Moreover, it is\ninjective on measures and bi-Lipschitz on multisets - a significant advantage\nover prevalent methods based on sum- or max-pooling, which are provably not\nbi-Lipschitz, and, in many cases, not even injective. The required output\ndimension for these guarantees is near-optimal: roughly $2 N d$, where $N$ is\nthe maximal input multiset size.\n  Furthermore, we prove that it is impossible to embed distributions over\n$\\mathbb{R}^d$ into Euclidean space in a bi-Lipschitz manner. Thus, the metric\nproperties of our embedding are, in a sense, the best possible.\n  Through numerical experiments, we demonstrate that our method yields superior\nmultiset representations that improve performance in practical learning tasks.\nSpecifically, we show that (a) a simple combination of the FSW embedding with\nan MLP achieves state-of-the-art performance in learning the (non-sliced)\nWasserstein distance; and (b) replacing max-pooling with the FSW embedding\nmakes PointNet significantly more robust to parameter reduction, with only\nminor performance degradation even after a 40-fold reduction.", "published": "2025-04-03 12:51:40", "link": "http://arxiv.org/abs/2504.02544v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Improving User Experience with FAICO: Towards a Framework for AI Communication in Human-AI Co-Creativity", "abstract": "How AI communicates with humans is crucial for effective human-AI\nco-creation. However, many existing co-creative AI tools cannot communicate\neffectively, limiting their potential as collaborators. This paper introduces\nour initial design of a Framework for designing AI Communication (FAICO) for\nco-creative AI based on a systematic review of 107 full-length papers. FAICO\npresents key aspects of AI communication and their impacts on user experience\nto guide the design of effective AI communication. We then show actionable ways\nto translate our framework into two practical tools: design cards for designers\nand a configuration tool for users. The design cards enable designers to\nconsider AI communication strategies that cater to a diverse range of users in\nco-creative contexts, while the configuration tool empowers users to customize\nAI communication based on their needs and creative workflows. This paper\ncontributes new insights within the literature on human-AI co-creativity and\nHuman-Computer Interaction, focusing on designing AI communication to enhance\nuser experience.", "published": "2025-04-03 12:29:53", "link": "http://arxiv.org/abs/2504.02526v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Towards Generalizing Temporal Action Segmentation to Unseen Views", "abstract": "While there has been substantial progress in temporal action segmentation,\nthe challenge to generalize to unseen views remains unaddressed. Hence, we\ndefine a protocol for unseen view action segmentation where camera views for\nevaluating the model are unavailable during training. This includes changing\nfrom top-frontal views to a side view or even more challenging from exocentric\nto egocentric views. Furthermore, we present an approach for temporal action\nsegmentation that tackles this challenge. Our approach leverages a shared\nrepresentation at both the sequence and segment levels to reduce the impact of\nview differences during training. We achieve this by introducing a sequence\nloss and an action loss, which together facilitate consistent video and action\nrepresentations across different views. The evaluation on the Assembly101,\nIkeaASM, and EgoExoLearn datasets demonstrate significant improvements, with a\n12.8% increase in F1@50 for unseen exocentric views and a substantial 54%\nimprovement for unseen egocentric views.", "published": "2025-04-03 11:53:59", "link": "http://arxiv.org/abs/2504.02512v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Memory-Augmented LLM-Driven Method for Autonomous Merging of 3D Printing Work Orders", "abstract": "With the rapid development of 3D printing, the demand for personalized and\ncustomized production on the manufacturing line is steadily increasing.\nEfficient merging of printing workpieces can significantly enhance the\nprocessing efficiency of the production line. Addressing the challenge, a Large\nLanguage Model (LLM)-driven method is established in this paper for the\nautonomous merging of 3D printing work orders, integrated with a\nmemory-augmented learning strategy. In industrial scenarios, both device and\norder features are modeled into LLM-readable natural language prompt templates,\nand develop an order-device matching tool along with a merging interference\nchecking module. By incorporating a self-memory learning strategy, an\nintelligent agent for autonomous order merging is constructed, resulting in\nimproved accuracy and precision in order allocation. The proposed method\neffectively leverages the strengths of LLMs in industrial applications while\nreducing hallucination.", "published": "2025-04-03 11:50:29", "link": "http://arxiv.org/abs/2504.02509v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Explainable and Interpretable Forecasts on Non-Smooth Multivariate Time Series for Responsible Gameplay", "abstract": "Multi-variate Time Series (MTS) forecasting has made large strides (with very\nnegligible errors) through recent advancements in neural networks, e.g.,\nTransformers. However, in critical situations like predicting gaming\noverindulgence that affects one's mental well-being; an accurate forecast\nwithout a contributing evidence (explanation) is irrelevant. Hence, it becomes\nimportant that the forecasts are Interpretable - intermediate representation of\nthe forecasted trajectory is comprehensible; as well as Explainable - attentive\ninput features and events are accessible for a personalized and timely\nintervention of players at risk. While the contributing state of the art\nresearch on interpretability primarily focuses on temporally-smooth\nsingle-process driven time series data, our online multi-player gameplay data\ndemonstrates intractable temporal randomness due to intrinsic orthogonality\nbetween player's game outcome and their intent to engage further. We introduce\na novel deep Actionable Forecasting Network (AFN), which addresses the\ninter-dependent challenges associated with three exclusive objectives - 1)\nforecasting accuracy; 2) smooth comprehensible trajectory and 3) explanations\nvia multi-dimensional input features while tackling the challenges introduced\nby our non-smooth temporal data, together in one single solution. AFN\nestablishes a \\it{new benchmark} via: (i) achieving 25% improvement on the MSE\nof the forecasts on player data in comparison to the SOM-VAE based SOTA\nnetworks; (ii) attributing unfavourable progression of a player's time series\nto a specific future time step(s), with the premise of eliminating near-future\noverindulgent player volume by over 18% with player specific actionable inputs\nfeature(s) and (iii) proactively detecting over 23% (100% jump from SOTA) of\nthe to-be overindulgent, players on an average, 4 weeks in advance.", "published": "2025-04-03 11:49:24", "link": "http://arxiv.org/abs/2504.03777v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Industrial Internet Robot Collaboration System and Edge Computing Optimization", "abstract": "In a complex environment, for a mobile robot to safely and collision - free\navoid all obstacles, it poses high requirements for its intelligence level.\nGiven that the information such as the position and geometric characteristics\nof obstacles is random, the control parameters of the robot, such as velocity\nand angular velocity, are also prone to random deviations. To address this\nissue in the framework of the Industrial Internet Robot Collaboration System,\nthis paper proposes a global path control scheme for mobile robots based on\ndeep learning. First of all, the dynamic equation of the mobile robot is\nestablished. According to the linear velocity and angular velocity of the\nmobile robot, its motion behaviors are divided into obstacle - avoidance\nbehavior, target - turning behavior, and target approaching behavior.\nSubsequently, the neural network method in deep learning is used to build a\nglobal path planning model for the robot. On this basis, a fuzzy controller is\ndesigned with the help of a fuzzy control algorithm to correct the deviations\nthat occur during path planning, thereby achieving optimized control of the\nrobot's global path. In addition, considering edge computing optimization, the\nproposed model can process local data at the edge device, reducing the\ncommunication burden between the robot and the central server, and improving\nthe real time performance of path planning. The experimental results show that\nfor the mobile robot controlled by the research method in this paper, the\ndeviation distance of the path angle is within 5 cm, the deviation convergence\ncan be completed within 10 ms, and the planned path is shorter. This indicates\nthat the proposed scheme can effectively improve the global path planning\nability of mobile robots in the industrial Internet environment and promote the\ncollaborative operation of robots through edge computing optimization.", "published": "2025-04-03 11:15:10", "link": "http://arxiv.org/abs/2504.02492v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Haphazard Inputs as Images in Online Learning", "abstract": "The field of varying feature space in online learning settings, also known as\nhaphazard inputs, is very prominent nowadays due to its applicability in\nvarious fields. However, the current solutions to haphazard inputs are\nmodel-dependent and cannot benefit from the existing advanced deep-learning\nmethods, which necessitate inputs of fixed dimensions. Therefore, we propose to\ntransform the varying feature space in an online learning setting to a\nfixed-dimension image representation on the fly. This simple yet novel approach\nis model-agnostic, allowing any vision-based models to be applicable for\nhaphazard inputs, as demonstrated using ResNet and ViT. The image\nrepresentation handles the inconsistent input data seamlessly, making our\nproposed approach scalable and robust. We show the efficacy of our method on\nfour publicly available datasets. The code is available at\nhttps://github.com/Rohit102497/HaphazardInputsAsImages.", "published": "2025-04-03 11:14:05", "link": "http://arxiv.org/abs/2504.02912v1", "categories": ["cs.CV", "cs.AI", "cs.ET", "cs.LG"], "primary_category": "cs.CV"}
{"title": "The Self-Learning Agent with a Progressive Neural Network Integrated Transformer", "abstract": "This paper introduces a self-learning agent that integrates LLaMA 3.2 with a\nProgressive Neural Network (PNN) for continual learning in conversational AI\nand code generation. The framework dynamically collects data, fine-tunes tasks\nwith minimal samples, and leverages Meta-Learning for rapid adaptation. LoRA\noptimizes fine-tuning, while Elastic Weight Consolidation (EWC) enhances\nknowledge retention. Experimental results demonstrate improved adaptability and\nmemory stability, positioning this approach as a scalable step toward\nArtificial General Intelligence (AGI).", "published": "2025-04-03 11:13:31", "link": "http://arxiv.org/abs/2504.02489v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "We Need Improved Data Curation and Attribution in AI for Scientific Discovery", "abstract": "As the interplay between human-generated and synthetic data evolves, new\nchallenges arise in scientific discovery concerning the integrity of the data\nand the stability of the models. In this work, we examine the role of synthetic\ndata as opposed to that of real experimental data for scientific research. Our\nanalyses indicate that nearly three-quarters of experimental datasets available\non open-access platforms have relatively low adoption rates, opening new\nopportunities to enhance their discoverability and usability by automated\nmethods. Additionally, we observe an increasing difficulty in distinguishing\nsynthetic from real experimental data. We propose supplementing ongoing efforts\nin automating synthetic data detection by increasing the focus on watermarking\nreal experimental data, thereby strengthening data traceability and integrity.\nOur estimates suggest that watermarking even less than half of the real world\ndata generated annually could help sustain model robustness, while promoting a\nbalanced integration of synthetic and human-generated content.", "published": "2025-04-03 11:07:52", "link": "http://arxiv.org/abs/2504.02486v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Graph Attention-Driven Bayesian Deep Unrolling for Dual-Peak Single-Photon Lidar Imaging", "abstract": "Single-photon Lidar imaging offers a significant advantage in 3D imaging due\nto its high resolution and long-range capabilities, however it is challenging\nto apply in noisy environments with multiple targets per pixel. To tackle these\nchallenges, several methods have been proposed. Statistical methods demonstrate\ninterpretability on the inferred parameters, but they are often limited in\ntheir ability to handle complex scenes. Deep learning-based methods have shown\nsuperior performance in terms of accuracy and robustness, but they lack\ninterpretability or they are limited to a single-peak per pixel. In this paper,\nwe propose a deep unrolling algorithm for dual-peak single-photon Lidar\nimaging. We introduce a hierarchical Bayesian model for multiple targets and\npropose a neural network that unrolls the underlying statistical method. To\nsupport multiple targets, we adopt a dual depth maps representation and exploit\ngeometric deep learning to extract features from the point cloud. The proposed\nmethod takes advantages of statistical methods and learning-based methods in\nterms of accuracy and quantifying uncertainty. The experimental results on\nsynthetic and real data demonstrate the competitive performance when compared\nto existing methods, while also providing uncertainty information.", "published": "2025-04-03 10:57:26", "link": "http://arxiv.org/abs/2504.02480v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Hierarchical Policy-Gradient Reinforcement Learning for Multi-Agent Shepherding Control of Non-Cohesive Targets", "abstract": "We propose a decentralized reinforcement learning solution for multi-agent\nshepherding of non-cohesive targets using policy-gradient methods. Our\narchitecture integrates target-selection with target-driving through Proximal\nPolicy Optimization, overcoming discrete-action constraints of previous Deep\nQ-Network approaches and enabling smoother agent trajectories. This model-free\nframework effectively solves the shepherding problem without prior dynamics\nknowledge. Experiments demonstrate our method's effectiveness and scalability\nwith increased target numbers and limited sensing capabilities.", "published": "2025-04-03 10:56:57", "link": "http://arxiv.org/abs/2504.02479v1", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SY", "eess.SY", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Advancing Air Quality Monitoring: TinyML-Based Real-Time Ozone Prediction with Cost-Effective Edge Devices", "abstract": "The escalation of urban air pollution necessitates innovative solutions for\nreal-time air quality monitoring and prediction. This paper introduces a novel\nTinyML-based system designed to predict ozone concentration in real-time. The\nsystem employs an Arduino Nano 33 BLE Sense microcontroller equipped with an\nMQ7 sensor for carbon monoxide (CO) detection and built-in sensors for\ntemperature and pressure measurements. The data, sourced from a Kaggle dataset\non air quality parameters from India, underwent thorough cleaning and\npreprocessing. Model training and evaluation were performed using Edge Impulse,\nconsidering various combinations of input parameters (CO, temperature, and\npressure). The optimal model, incorporating all three variables, achieved a\nmean squared error (MSE) of 0.03 and an R-squared value of 0.95, indicating\nhigh predictive accuracy. The regression model was deployed on the\nmicrocontroller via the Arduino IDE, showcasing robust real-time performance.\nSensitivity analysis identified CO levels as the most critical predictor of\nozone concentration, followed by pressure and temperature. The system's\nlow-cost and low-power design makes it suitable for widespread implementation,\nparticularly in resource-constrained settings. This TinyML approach provides\nprecise real-time predictions of ozone levels, enabling prompt responses to\npollution events and enhancing public health protection.", "published": "2025-04-03 10:48:24", "link": "http://arxiv.org/abs/2504.03776v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "Systematic Literature Review: Explainable AI Definitions and Challenges in Education", "abstract": "Explainable AI (XAI) seeks to transform black-box algorithmic processes into\ntransparent ones, enhancing trust in AI applications across various sectors\nsuch as education. This review aims to examine the various definitions of XAI\nwithin the literature and explore the challenges of XAI in education. Our goal\nis to shed light on how XAI can contribute to enhancing the educational field.\nThis systematic review, utilising the PRISMA method for rigorous and\ntransparent research, identified 19 relevant studies. Our findings reveal 15\ndefinitions and 62 challenges. These challenges are categorised using thematic\nanalysis into seven groups: explainability, ethical, technical, human-computer\ninteraction (HCI), trustworthiness, policy and guideline, and others, thereby\ndeepening our understanding of the implications of XAI in education. Our\nanalysis highlights the absence of standardised definitions for XAI, leading to\nconfusion, especially because definitions concerning ethics, trustworthiness,\ntechnicalities, and explainability tend to overlap and vary.", "published": "2025-04-03 10:43:35", "link": "http://arxiv.org/abs/2504.02910v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "BOOST: Bootstrapping Strategy-Driven Reasoning Programs for Program-Guided Fact-Checking", "abstract": "Program-guided reasoning has shown promise in complex claim fact-checking by\ndecomposing claims into function calls and executing reasoning programs.\nHowever, prior work primarily relies on few-shot in-context learning (ICL) with\nad-hoc demonstrations, which limit program diversity and require manual design\nwith substantial domain knowledge. Fundamentally, the underlying principles of\neffective reasoning program generation still remain underexplored, making it\nchallenging to construct effective demonstrations. To address this, we propose\nBOOST, a bootstrapping-based framework for few-shot reasoning program\ngeneration. BOOST explicitly integrates claim decomposition and\ninformation-gathering strategies as structural guidance for program generation,\niteratively refining bootstrapped demonstrations in a strategy-driven and\ndata-centric manner without human intervention. This enables a seamless\ntransition from zero-shot to few-shot strategic program-guided learning,\nenhancing interpretability and effectiveness. Experimental results show that\nBOOST outperforms prior few-shot baselines in both zero-shot and few-shot\nsettings for complex claim verification.", "published": "2025-04-03 10:38:45", "link": "http://arxiv.org/abs/2504.02467v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Evaluating AI Recruitment Sourcing Tools by Human Preference", "abstract": "This study introduces a benchmarking methodology designed to evaluate the\nperformance of AI-driven recruitment sourcing tools. We created and utilized a\ndataset to perform a comparative analysis of search results generated by\nleading AI-based solutions, LinkedIn Recruiter, and our proprietary system,\nPearch.ai. Human experts assessed the relevance of the returned candidates, and\nan Elo rating system was applied to quantitatively measure each tool's\ncomparative performance. Our findings indicate that AI-driven recruitment\nsourcing tools consistently outperform LinkedIn Recruiter in candidate\nrelevance, with Pearch.ai achieving the highest performance scores.\nFurthermore, we found a strong alignment between AI-based evaluations and human\njudgments, highlighting the potential for advanced AI technologies to\nsubstantially enhance talent acquisition effectiveness. Code and supporting\ndata are publicly available at\nhttps://github.com/vslaykovsky/ai-sourcing-benchmark", "published": "2025-04-03 10:33:43", "link": "http://arxiv.org/abs/2504.02463v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "CornerPoint3D: Look at the Nearest Corner Instead of the Center", "abstract": "3D object detection aims to predict object centers, dimensions, and rotations\nfrom LiDAR point clouds. Despite its simplicity, LiDAR captures only the near\nside of objects, making center-based detectors prone to poor localization\naccuracy in cross-domain tasks with varying point distributions. Meanwhile,\nexisting evaluation metrics designed for single-domain assessment also suffer\nfrom overfitting due to dataset-specific size variations. A key question\narises: Do we really need models to maintain excellent performance in the\nentire 3D bounding boxes after being applied across domains? Actually, one of\nour main focuses is on preventing collisions between vehicles and other\nobstacles, especially in cross-domain scenarios where correctly predicting the\nsizes is much more difficult. To address these issues, we rethink cross-domain\n3D object detection from a practical perspective. We propose two new metrics\nthat evaluate a model's ability to detect objects' closer-surfaces to the LiDAR\nsensor. Additionally, we introduce EdgeHead, a refinement head that guides\nmodels to focus more on learnable closer surfaces, significantly improving\ncross-domain performance under both our new and traditional BEV/3D metrics.\nFurthermore, we argue that predicting the nearest corner rather than the object\ncenter enhances robustness. We propose a novel 3D object detector, coined as\nCornerPoint3D, which is built upon CenterPoint and uses heatmaps to supervise\nthe learning and detection of the nearest corner of each object. Our proposed\nmethods realize a balanced trade-off between the detection quality of entire\nbounding boxes and the locating accuracy of closer surfaces to the LiDAR\nsensor, outperforming the traditional center-based detector CenterPoint in\nmultiple cross-domain tasks and providing a more practically reasonable and\nrobust cross-domain 3D object detection solution.", "published": "2025-04-03 10:33:43", "link": "http://arxiv.org/abs/2504.02464v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Am I Being Treated Fairly? A Conceptual Framework for Individuals to Ascertain Fairness", "abstract": "Current fairness metrics and mitigation techniques provide tools for\npractitioners to asses how non-discriminatory Automatic Decision Making (ADM)\nsystems are. What if I, as an individual facing a decision taken by an ADM\nsystem, would like to know: Am I being treated fairly? We explore how to create\nthe affordance for users to be able to ask this question of ADM. In this paper,\nwe argue for the reification of fairness not only as a property of ADM, but\nalso as an epistemic right of an individual to acquire information about the\ndecisions that affect them and use that information to contest and seek\neffective redress against those decisions, in case they are proven to be\ndiscriminatory. We examine key concepts from existing research not only in\nalgorithmic fairness but also in explainable artificial intelligence,\naccountability, and contestability. Integrating notions from these domains, we\npropose a conceptual framework to ascertain fairness by combining different\ntools that empower the end-users of ADM systems. Our framework shifts the focus\nfrom technical solutions aimed at practitioners to mechanisms that enable\nindividuals to understand, challenge, and verify the fairness of decisions, and\nalso serves as a blueprint for organizations and policymakers, bridging the gap\nbetween technical requirements and practical, user-centered accountability.", "published": "2025-04-03 10:28:19", "link": "http://arxiv.org/abs/2504.02461v1", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LG", "cs.MA", "I.2; J.4"], "primary_category": "cs.CY"}
{"title": "Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation", "abstract": "Recently, Large Language Model (LLM)-empowered recommender systems have\nrevolutionized personalized recommendation frameworks and attracted extensive\nattention. Despite the remarkable success, existing LLM-empowered RecSys have\nbeen demonstrated to be highly vulnerable to minor perturbations. To mitigate\nthe negative impact of such vulnerabilities, one potential solution is to\nemploy collaborative signals based on item-item co-occurrence to purify the\nmalicious collaborative knowledge from the user's historical interactions\ninserted by attackers. On the other hand, due to the capabilities to expand\ninsufficient internal knowledge of LLMs, Retrieval-Augmented Generation (RAG)\ntechniques provide unprecedented opportunities to enhance the robustness of\nLLM-empowered recommender systems by introducing external collaborative\nknowledge. Therefore, in this paper, we propose a novel framework (RETURN) by\nretrieving external collaborative signals to purify the poisoned user profiles\nand enhance the robustness of LLM-empowered RecSys in a plug-and-play manner.\nSpecifically, retrieval-augmented perturbation positioning is proposed to\nidentify potential perturbations within the users' historical sequences by\nretrieving external knowledge from collaborative item graphs. After that, we\nfurther retrieve the collaborative knowledge to cleanse the perturbations by\nusing either deletion or replacement strategies and introduce a robust ensemble\nrecommendation strategy to generate final robust predictions. Extensive\nexperiments on three real-world datasets demonstrate the effectiveness of the\nproposed RETURN.", "published": "2025-04-03 10:22:30", "link": "http://arxiv.org/abs/2504.02458v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "CHARMS: Cognitive Hierarchical Agent with Reasoning and Motion Styles", "abstract": "To address the current challenges of low intelligence and simplistic vehicle\nbehavior modeling in autonomous driving simulation scenarios, this paper\nproposes the Cognitive Hierarchical Agent with Reasoning and Motion Styles\n(CHARMS). The model can reason about the behavior of other vehicles like a\nhuman driver and respond with different decision-making styles, thereby\nimproving the intelligence and diversity of the surrounding vehicles in the\ndriving scenario. By introducing the Level-k behavioral game theory, the paper\nmodels the decision-making process of human drivers and employs deep\nreinforcement learning to train the models with diverse decision styles,\nsimulating different reasoning approaches and behavioral characteristics.\nBuilding on the Poisson cognitive hierarchy theory, this paper also presents a\nnovel driving scenario generation method. The method controls the proportion of\nvehicles with different driving styles in the scenario using Poisson and\nbinomial distributions, thus generating controllable and diverse driving\nenvironments. Experimental results demonstrate that CHARMS not only exhibits\nsuperior decision-making capabilities as ego vehicles, but also generates more\ncomplex and diverse driving scenarios as surrounding vehicles. We will release\ncode for CHARMS at https://github.com/WUTAD-Wjy/CHARMS.", "published": "2025-04-03 10:15:19", "link": "http://arxiv.org/abs/2504.02450v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "How Artificial Intelligence Leads to Knowledge Why: An Inquiry Inspired by Aristotle's Posterior Analytics", "abstract": "Bayesian networks and causal models provide frameworks for handling queries\nabout external interventions and counterfactuals, enabling tasks that go beyond\nwhat probability distributions alone can address. While these formalisms are\noften informally described as capturing causal knowledge, there is a lack of a\nformal theory characterizing the type of knowledge required to predict the\neffects of external interventions. This work introduces the theoretical\nframework of causal systems to clarify Aristotle's distinction between\nknowledge that and knowledge why within artificial intelligence. By\ninterpreting existing artificial intelligence technologies as causal systems,\nit investigates the corresponding types of knowledge. Furthermore, it argues\nthat predicting the effects of external interventions is feasible only with\nknowledge why, providing a more precise understanding of the knowledge\nnecessary for such tasks.", "published": "2025-04-03 09:37:05", "link": "http://arxiv.org/abs/2504.02430v1", "categories": ["cs.AI", "cs.LO", "I.2.4"], "primary_category": "cs.AI"}
{"title": "Narrative Studio: Visual narrative exploration using LLMs and Monte Carlo Tree Search", "abstract": "Interactive storytelling benefits from planning and exploring multiple 'what\nif' scenarios. Modern LLMs are useful tools for ideation and exploration, but\ncurrent chat-based user interfaces restrict users to a single linear flow. To\naddress this limitation, we propose Narrative Studio -- a novel in-browser\nnarrative exploration environment featuring a tree-like interface that allows\nbranching exploration from user-defined points in a story. Each branch is\nextended via iterative LLM inference guided by system and user-defined prompts.\nAdditionally, we employ Monte Carlo Tree Search (MCTS) to automatically expand\npromising narrative paths based on user-specified criteria, enabling more\ndiverse and robust story development. We also allow users to enhance narrative\ncoherence by grounding the generated text in an entity graph that represents\nthe actors and environment of the story.", "published": "2025-04-03 09:31:07", "link": "http://arxiv.org/abs/2504.02426v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Leveraging Static Relationships for Intra-Type and Inter-Type Message Passing in Video Question Answering", "abstract": "Video Question Answering (VideoQA) is an important research direction in the\nfield of artificial intelligence, enabling machines to understand video content\nand perform reasoning and answering based on natural language questions.\nAlthough methods based on static relationship reasoning have made certain\nprogress, there are still deficiencies in the accuracy of static relationship\nrecognition and representation, and they have not fully utilized the static\nrelationship information in videos for in-depth reasoning and analysis.\nTherefore, this paper proposes a reasoning method for intra-type and inter-type\nmessage passing based on static relationships. This method constructs a dual\ngraph for intra-type message passing reasoning and builds a heterogeneous graph\nbased on static relationships for inter-type message passing reasoning. The\nintra-type message passing reasoning model captures the neighborhood\ninformation of targets and relationships related to the question in the dual\ngraph, updating the dual graph to obtain intra-type clues for answering the\nquestion. The inter-type message passing reasoning model captures the\nneighborhood information of targets and relationships from different categories\nrelated to the question in the heterogeneous graph, updating the heterogeneous\ngraph to obtain inter-type clues for answering the question. Finally, the\nanswers are inferred by combining the intra-type and inter-type clues based on\nstatic relationships. Experimental results on the ANetQA and Next-QA datasets\ndemonstrate the effectiveness of this method.", "published": "2025-04-03 09:14:41", "link": "http://arxiv.org/abs/2504.02417v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Translation of Fetal Brain Ultrasound Images into Pseudo-MRI Images using Artificial Intelligence", "abstract": "Ultrasound is a widely accessible and cost-effective medical imaging tool\ncommonly used for prenatal evaluation of the fetal brain. However, it has\nlimitations, particularly in the third trimester, where the complexity of the\nfetal brain requires high image quality for extracting quantitative data. In\ncontrast, magnetic resonance imaging (MRI) offers superior image quality and\ntissue differentiation but is less available, expensive, and requires\ntime-consuming acquisition. Thus, transforming ultrasonic images into an\nMRI-mimicking display may be advantageous and allow better tissue anatomy\npresentation. To address this goal, we have examined the use of artificial\nintelligence, implementing a diffusion model renowned for generating\nhigh-quality images. The proposed method, termed \"Dual Diffusion Imposed\nCorrelation\" (DDIC), leverages a diffusion-based translation methodology,\nassuming a shared latent space between ultrasound and MRI domains. Model\ntraining was obtained utilizing the \"HC18\" dataset for ultrasound and the \"CRL\nfetal brain atlas\" along with the \"FeTA \" datasets for MRI. The generated\npseudo-MRI images provide notable improvements in visual discrimination of\nbrain tissue, especially in the lateral ventricles and the Sylvian fissure,\ncharacterized by enhanced contrast clarity. Improvement was demonstrated in\nMutual information, Peak signal-to-noise ratio, Fr\\'echet Inception Distance,\nand Contrast-to-noise ratio. Findings from these evaluations indicate\nstatistically significant superior performance of the DDIC compared to other\ntranslation methodologies. In addition, a Medical Opinion Test was obtained\nfrom 5 gynecologists. The results demonstrated display improvement in 81% of\nthe tested images. In conclusion, the presented pseudo-MRI images hold the\npotential for streamlining diagnosis and enhancing clinical outcomes through\nimproved representation.", "published": "2025-04-03 08:59:33", "link": "http://arxiv.org/abs/2504.02408v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "EvMic: Event-based Non-contact sound recovery from effective spatial-temporal modeling", "abstract": "When sound waves hit an object, they induce vibrations that produce\nhigh-frequency and subtle visual changes, which can be used for recovering the\nsound. Early studies always encounter trade-offs related to sampling rate,\nbandwidth, field of view, and the simplicity of the optical path. Recent\nadvances in event camera hardware show good potential for its application in\nvisual sound recovery, because of its superior ability in capturing\nhigh-frequency signals. However, existing event-based vibration recovery\nmethods are still sub-optimal for sound recovery. In this work, we propose a\nnovel pipeline for non-contact sound recovery, fully utilizing spatial-temporal\ninformation from the event stream. We first generate a large training set using\na novel simulation pipeline. Then we designed a network that leverages the\nsparsity of events to capture spatial information and uses Mamba to model\nlong-term temporal information. Lastly, we train a spatial aggregation block to\naggregate information from different locations to further improve signal\nquality. To capture event signals caused by sound waves, we also designed an\nimaging system using a laser matrix to enhance the gradient and collected\nmultiple data sequences for testing. Experimental results on synthetic and\nreal-world data demonstrate the effectiveness of our method.", "published": "2025-04-03 08:51:17", "link": "http://arxiv.org/abs/2504.02402v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Steiner Traveling Salesman Problem with Quantum Annealing", "abstract": "The Steiner Traveling Salesman Problem (STSP) is a variant of the classical\nTraveling Salesman Problem. The STSP involves incorporating steiner nodes,\nwhich are extra nodes not originally part of the required visit set but that\ncan be added to the route to enhance the overall solution and minimize the\ntotal travel cost. Given the NP-hard nature of the STSP, we propose a quantum\napproach to address it. Specifically, we employ quantum annealing using\nD-Wave's hardware to explore its potential for solving this problem. To enhance\ncomputational feasibility, we develop a preprocessing method that effectively\nreduces the network size. Our experimental results demonstrate that this\nreduction technique significantly decreases the problem complexity, making the\nQuadratic Unconstrained Binary Optimization formulation, the standard input for\nquantum annealers, better suited for existing quantum hardware. Furthermore,\nthe results highlight the potential of quantum annealing as a promising and\ninnovative approach for solving the STSP.", "published": "2025-04-03 08:29:57", "link": "http://arxiv.org/abs/2504.02388v1", "categories": ["quant-ph", "cs.AI", "cs.ET"], "primary_category": "quant-ph"}
{"title": "Exploring energy consumption of AI frameworks on a 64-core RV64 Server CPU", "abstract": "In today's era of rapid technological advancement, artificial intelligence\n(AI) applications require large-scale, high-performance, and data-intensive\ncomputations, leading to significant energy demands. Addressing this challenge\nnecessitates a combined approach involving both hardware and software\ninnovations. Hardware manufacturers are developing new, efficient, and\nspecialized solutions, with the RISC-V architecture emerging as a prominent\nplayer due to its open, extensible, and energy-efficient instruction set\narchitecture (ISA). Simultaneously, software developers are creating new\nalgorithms and frameworks, yet their energy efficiency often remains unclear.\nIn this study, we conduct a comprehensive benchmark analysis of machine\nlearning (ML) applications on the 64-core SOPHON SG2042 RISC-V architecture. We\nspecifically analyze the energy consumption of deep learning inference models\nacross three leading AI frameworks: PyTorch, ONNX Runtime, and TensorFlow. Our\nfindings show that frameworks using the XNNPACK back-end, such as ONNX Runtime\nand TensorFlow, consume less energy compared to PyTorch, which is compiled with\nthe native OpenBLAS back-end.", "published": "2025-04-03 08:27:10", "link": "http://arxiv.org/abs/2504.03774v1", "categories": ["cs.DC", "cs.AI", "cs.AR"], "primary_category": "cs.DC"}
{"title": "Benchmark of Segmentation Techniques for Pelvic Fracture in CT and X-ray: Summary of the PENGWIN 2024 Challenge", "abstract": "The segmentation of pelvic fracture fragments in CT and X-ray images is\ncrucial for trauma diagnosis, surgical planning, and intraoperative guidance.\nHowever, accurately and efficiently delineating the bone fragments remains a\nsignificant challenge due to complex anatomy and imaging limitations. The\nPENGWIN challenge, organized as a MICCAI 2024 satellite event, aimed to advance\nautomated fracture segmentation by benchmarking state-of-the-art algorithms on\nthese complex tasks. A diverse dataset of 150 CT scans was collected from\nmultiple clinical centers, and a large set of simulated X-ray images was\ngenerated using the DeepDRR method. Final submissions from 16 teams worldwide\nwere evaluated under a rigorous multi-metric testing scheme. The top-performing\nCT algorithm achieved an average fragment-wise intersection over union (IoU) of\n0.930, demonstrating satisfactory accuracy. However, in the X-ray task, the\nbest algorithm attained an IoU of 0.774, highlighting the greater challenges\nposed by overlapping anatomical structures. Beyond the quantitative evaluation,\nthe challenge revealed methodological diversity in algorithm design. Variations\nin instance representation, such as primary-secondary classification versus\nboundary-core separation, led to differing segmentation strategies. Despite\npromising results, the challenge also exposed inherent uncertainties in\nfragment definition, particularly in cases of incomplete fractures. These\nfindings suggest that interactive segmentation approaches, integrating human\ndecision-making with task-relevant information, may be essential for improving\nmodel reliability and clinical applicability.", "published": "2025-04-03 08:19:36", "link": "http://arxiv.org/abs/2504.02382v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "SHapley Estimated Explanation (SHEP): A Fast Post-Hoc Attribution Method for Interpreting Intelligent Fault Diagnosis", "abstract": "Despite significant progress in intelligent fault diagnosis (IFD), the lack\nof interpretability remains a critical barrier to practical industrial\napplications, driving the growth of interpretability research in IFD. Post-hoc\ninterpretability has gained popularity due to its ability to preserve network\nflexibility and scalability without modifying model structures. However, these\nmethods often yield suboptimal time-domain explanations. Recently, combining\ndomain transform with SHAP has improved interpretability by extending\nexplanations to more informative domains. Nonetheless, the computational\nexpense of SHAP, exacerbated by increased dimensions from domain transforms,\nremains a major challenge. To address this, we propose patch-wise attribution\nand SHapley Estimated Explanation (SHEP). Patch-wise attribution reduces\nfeature dimensions at the cost of explanation granularity, while SHEP\nsimplifies subset enumeration to approximate SHAP, reducing complexity from\nexponential to linear. Together, these methods significantly enhance SHAP's\ncomputational efficiency, providing feasibility for real-time interpretation in\nmonitoring tasks. Extensive experiments confirm SHEP's efficiency,\ninterpretability, and reliability in approximating SHAP. Additionally, with\nopen-source code, SHEP has the potential to serve as a benchmark for post-hoc\ninterpretability in IFD. The code is available on\nhttps://github.com/ChenQian0618/SHEP.", "published": "2025-04-03 07:56:07", "link": "http://arxiv.org/abs/2504.03773v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Agglomerating Large Vision Encoders via Distillation for VFSS Segmentation", "abstract": "The deployment of foundation models for medical imaging has demonstrated\nconsiderable success. However, their training overheads associated with\ndownstream tasks remain substantial due to the size of the image encoders\nemployed, and the inference complexity is also significantly high. Although\nlightweight variants have been obtained for these foundation models, their\nperformance is constrained by their limited model capacity and suboptimal\ntraining strategies. In order to achieve an improved tradeoff between\ncomplexity and performance, we propose a new framework to improve the\nperformance of low complexity models via knowledge distillation from multiple\nlarge medical foundation models (e.g., MedSAM, RAD-DINO, MedCLIP), each\nspecializing in different vision tasks, with the goal to effectively bridge the\nperformance gap for medical image segmentation tasks. The agglomerated model\ndemonstrates superior generalization across 12 segmentation tasks, whereas\nspecialized models require explicit training for each task. Our approach\nachieved an average performance gain of 2\\% in Dice coefficient compared to\nsimple distillation.", "published": "2025-04-03 07:38:09", "link": "http://arxiv.org/abs/2504.02351v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Temporal Gaussian Copula For Clinical Multivariate Time Series Data Imputation", "abstract": "The imputation of the Multivariate time series (MTS) is particularly\nchallenging since the MTS typically contains irregular patterns of missing\nvalues due to various factors such as instrument failures, interference from\nirrelevant data, and privacy regulations. Existing statistical methods and deep\nlearning methods have shown promising results in time series imputation. In\nthis paper, we propose a Temporal Gaussian Copula Model (TGC) for three-order\nMTS imputation. The key idea is to leverage the Gaussian Copula to explore the\ncross-variable and temporal relationships based on the latent Gaussian\nrepresentation. Subsequently, we employ an Expectation-Maximization (EM)\nalgorithm to improve robustness in managing data with varying missing rates.\nComprehensive experiments were conducted on three real-world MTS datasets. The\nresults demonstrate that our TGC substantially outperforms the state-of-the-art\nimputation methods. Additionally, the TGC model exhibits stronger robustness to\nthe varying missing ratios in the test dataset. Our code is available at\nhttps://github.com/MVL-Lab/TGC-MTS.", "published": "2025-04-03 06:44:05", "link": "http://arxiv.org/abs/2504.02317v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ConsDreamer: Advancing Multi-View Consistency for Zero-Shot Text-to-3D Generation", "abstract": "Recent advances in zero-shot text-to-3D generation have revolutionized 3D\ncontent creation by enabling direct synthesis from textual descriptions. While\nstate-of-the-art methods leverage 3D Gaussian Splatting with score distillation\nto enhance multi-view rendering through pre-trained text-to-image (T2I) models,\nthey suffer from inherent view biases in T2I priors. These biases lead to\ninconsistent 3D generation, particularly manifesting as the multi-face Janus\nproblem, where objects exhibit conflicting features across views. To address\nthis fundamental challenge, we propose ConsDreamer, a novel framework that\nmitigates view bias by refining both the conditional and unconditional terms in\nthe score distillation process: (1) a View Disentanglement Module (VDM) that\neliminates viewpoint biases in conditional prompts by decoupling irrelevant\nview components and injecting precise camera parameters; and (2) a\nsimilarity-based partial order loss that enforces geometric consistency in the\nunconditional term by aligning cosine similarities with azimuth relationships.\nExtensive experiments demonstrate that ConsDreamer effectively mitigates the\nmulti-face Janus problem in text-to-3D generation, outperforming existing\nmethods in both visual quality and consistency.", "published": "2025-04-03 06:43:23", "link": "http://arxiv.org/abs/2504.02316v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "OmniCam: Unified Multimodal Video Generation via Camera Control", "abstract": "Camera control, which achieves diverse visual effects by changing camera\nposition and pose, has attracted widespread attention. However, existing\nmethods face challenges such as complex interaction and limited control\ncapabilities. To address these issues, we present OmniCam, a unified multimodal\ncamera control framework. Leveraging large language models and video diffusion\nmodels, OmniCam generates spatio-temporally consistent videos. It supports\nvarious combinations of input modalities: the user can provide text or video\nwith expected trajectory as camera path guidance, and image or video as content\nreference, enabling precise control over camera motion. To facilitate the\ntraining of OmniCam, we introduce the OmniTr dataset, which contains a large\ncollection of high-quality long-sequence trajectories, videos, and\ncorresponding descriptions. Experimental results demonstrate that our model\nachieves state-of-the-art performance in high-quality camera-controlled video\ngeneration across various metrics.", "published": "2025-04-03 06:38:30", "link": "http://arxiv.org/abs/2504.02312v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Flow State: Humans Enabling AI Systems to Program Themselves", "abstract": "Compound AI systems, orchestrating multiple AI components and external APIs,\nare increasingly vital but face challenges in managing complexity, handling\nambiguity, and enabling effective development workflows. Existing frameworks\noften introduce significant overhead, implicit complexity, or restrictive\nabstractions, hindering maintainability and iterative refinement, especially in\nHuman-AI collaborative settings. We argue that overcoming these hurdles\nrequires a foundational architecture prioritizing structural clarity and\nexplicit control. To this end, we introduce Pocketflow, a platform centered on\nHuman-AI co-design, enabled by Pocketflow. Pocketflow is a Python framework\nbuilt upon a deliberately minimal yet synergistic set of core abstractions:\nmodular Nodes with a strict lifecycle, declarative Flow orchestration, native\nhierarchical nesting (Flow-as-Node), and explicit action-based conditional\nlogic. This unique combination provides a robust, vendor-agnostic foundation\nwith very little code that demonstrably reduces overhead while offering the\nexpressiveness needed for complex patterns like agentic workflows and RAG.\nComplemented by Pocket AI, an assistant leveraging this structure for system\ndesign, Pocketflow provides an effective environment for iteratively\nprototyping, refining, and deploying the adaptable, scalable AI systems\ndemanded by modern enterprises.", "published": "2025-04-03 05:25:46", "link": "http://arxiv.org/abs/2504.03771v1", "categories": ["cs.AI", "68T99, 68N19, 68U35", "I.2.1; D.2.11; H.5.2"], "primary_category": "cs.AI"}
{"title": "Tree-based Models for Vertical Federated Learning: A Survey", "abstract": "Tree-based models have achieved great success in a wide range of real-world\napplications due to their effectiveness, robustness, and interpretability,\nwhich inspired people to apply them in vertical federated learning (VFL)\nscenarios in recent years. In this paper, we conduct a comprehensive study to\ngive an overall picture of applying tree-based models in VFL, from the\nperspective of their communication and computation protocols. We categorize\ntree-based models in VFL into two types, i.e., feature-gathering models and\nlabel-scattering models, and provide a detailed discussion regarding their\ncharacteristics, advantages, privacy protection mechanisms, and applications.\nThis study also focuses on the implementation of tree-based models in VFL,\nsummarizing several design principles for better satisfying various\nrequirements from both academic research and industrial deployment. We conduct\na series of experiments to provide empirical observations on the differences\nand advances of different types of tree-based models.", "published": "2025-04-03 05:16:09", "link": "http://arxiv.org/abs/2504.02285v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model", "abstract": "Multimodal large language models (MLLMs) excel in vision-language tasks but\nalso pose significant risks of generating harmful content, particularly through\njailbreak attacks. Jailbreak attacks refer to intentional manipulations that\nbypass safety mechanisms in models, leading to the generation of inappropriate\nor unsafe content. Detecting such attacks is critical to ensuring the\nresponsible deployment of MLLMs. Existing jailbreak detection methods face\nthree primary challenges: (1) Many rely on model hidden states or gradients,\nlimiting their applicability to white-box models, where the internal workings\nof the model are accessible; (2) They involve high computational overhead from\nuncertainty-based analysis, which limits real-time detection, and (3) They\nrequire fully labeled harmful datasets, which are often scarce in real-world\nsettings. To address these issues, we introduce a test-time adaptive framework\ncalled JAILDAM. Our method leverages a memory-based approach guided by\npolicy-driven unsafe knowledge representations, eliminating the need for\nexplicit exposure to harmful data. By dynamically updating unsafe knowledge\nduring test-time, our framework improves generalization to unseen jailbreak\nstrategies while maintaining efficiency. Experiments on multiple VLM jailbreak\nbenchmarks demonstrate that JAILDAM delivers state-of-the-art performance in\nharmful content detection, improving both accuracy and speed.", "published": "2025-04-03 05:00:28", "link": "http://arxiv.org/abs/2504.03770v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Beyond Conventional Transformers: The Medical X-ray Attention (MXA) Block for Improved Multi-Label Diagnosis Using Knowledge Distillation", "abstract": "Medical imaging, particularly X-ray analysis, often involves detecting\nmultiple conditions simultaneously within a single scan, making multi-label\nclassification crucial for real-world clinical applications. We present the\nMedical X-ray Attention (MXA) block, a novel attention mechanism tailored\nspecifically to address the unique challenges of X-ray abnormality detection.\nThe MXA block enhances traditional Multi-Head Self Attention (MHSA) by\nintegrating a specialized module that efficiently captures both detailed local\ninformation and broader global context. To the best of our knowledge, this is\nthe first work to propose a task-specific attention mechanism for diagnosing\nchest X-rays, as well as to attempt multi-label classification using an\nEfficient Vision Transformer (EfficientViT). By embedding the MXA block within\nthe EfficientViT architecture and employing knowledge distillation, our\nproposed model significantly improves performance on the CheXpert dataset, a\nwidely used benchmark for multi-label chest X-ray abnormality detection. Our\napproach achieves an area under the curve (AUC) of 0.85, an absolute\nimprovement of 0.19 compared to our baseline model's AUC of 0.66, corresponding\nto a substantial approximate 233% relative improvement over random guessing\n(AUC = 0.5).", "published": "2025-04-03 04:55:42", "link": "http://arxiv.org/abs/2504.02277v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Hide and Seek in Noise Labels: Noise-Robust Collaborative Active Learning with LLM-Powered Assistance", "abstract": "Learning from noisy labels (LNL) is a challenge that arises in many\nreal-world scenarios where collected training data can contain incorrect or\ncorrupted labels. Most existing solutions identify noisy labels and adopt\nactive learning to query human experts on them for denoising. In the era of\nlarge language models (LLMs), although we can reduce the human effort to\nimprove these methods, their performances are still subject to accurately\nseparating the clean and noisy samples from noisy data. In this paper, we\npropose an innovative collaborative learning framework NoiseAL based on active\nlearning to combine LLMs and small models (SMs) for learning from noisy labels.\nDuring collaborative training, we first adopt two SMs to form a co-prediction\nnetwork and propose a dynamic-enhanced threshold strategy to divide the noisy\ndata into different subsets, then select the clean and noisy samples from these\nsubsets to feed the active annotator LLMs to rectify noisy samples. Finally, we\nemploy different optimization objectives to conquer subsets with different\ndegrees of label noises. Extensive experiments on synthetic and real-world\nnoise datasets further demonstrate the superiority of our framework over\nstate-of-the-art baselines.", "published": "2025-04-03 04:36:39", "link": "http://arxiv.org/abs/2504.02901v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Engineering Artificial Intelligence: Framework, Challenges, and Future Direction", "abstract": "Over the past ten years, the application of artificial intelligence (AI) and\nmachine learning (ML) in engineering domains has gained significant popularity,\nshowcasing their potential in data-driven contexts. However, the complexity and\ndiversity of engineering problems often require the development of\ndomain-specific AI approaches, which are frequently hindered by a lack of\nsystematic methodologies, scalability, and robustness during the development\nprocess. To address this gap, this paper introduces the \"ABCDE\" as the key\nelements of Engineering AI and proposes a unified, systematic engineering AI\necosystem framework, including eight essential layers, along with attributes,\ngoals, and applications, to guide the development and deployment of AI\nsolutions for specific engineering needs. Additionally, key challenges are\nexamined, and nine future research directions are highlighted. By providing a\ncomprehensive perspective, this paper aims to advance the strategic\nimplementation of AI, fostering the development of next-generation engineering\nAI solutions.", "published": "2025-04-03 04:30:10", "link": "http://arxiv.org/abs/2504.02269v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Implicit Neural Differential Model for Spatiotemporal Dynamics", "abstract": "Hybrid neural-physics modeling frameworks through differentiable programming\nhave emerged as powerful tools in scientific machine learning, enabling the\nintegration of known physics with data-driven learning to improve prediction\naccuracy and generalizability. However, most existing hybrid frameworks rely on\nexplicit recurrent formulations, which suffer from numerical instability and\nerror accumulation during long-horizon forecasting. In this work, we introduce\nIm-PiNDiff, a novel implicit physics-integrated neural differentiable solver\nfor stable and accurate modeling of spatiotemporal dynamics. Inspired by deep\nequilibrium models, Im-PiNDiff advances the state using implicit fixed-point\nlayers, enabling robust long-term simulation while remaining fully end-to-end\ndifferentiable. To enable scalable training, we introduce a hybrid gradient\npropagation strategy that integrates adjoint-state methods with reverse-mode\nautomatic differentiation. This approach eliminates the need to store\nintermediate solver states and decouples memory complexity from the number of\nsolver iterations, significantly reducing training overhead. We further\nincorporate checkpointing techniques to manage memory in long-horizon rollouts.\nNumerical experiments on various spatiotemporal PDE systems, including\nadvection-diffusion processes, Burgers' dynamics, and multi-physics chemical\nvapor infiltration processes, demonstrate that Im-PiNDiff achieves superior\npredictive performance, enhanced numerical stability, and substantial\nreductions in memory and runtime cost relative to explicit and naive implicit\nbaselines. This work provides a principled, efficient, and scalable framework\nfor hybrid neural-physics modeling.", "published": "2025-04-03 04:07:18", "link": "http://arxiv.org/abs/2504.02260v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Adapting World Models with Latent-State Dynamics Residuals", "abstract": "Simulation-to-reality reinforcement learning (RL) faces the critical\nchallenge of reconciling discrepancies between simulated and real-world\ndynamics, which can severely degrade agent performance. A promising approach\ninvolves learning corrections to simulator forward dynamics represented as a\nresidual error function, however this operation is impractical with\nhigh-dimensional states such as images. To overcome this, we propose ReDRAW, a\nlatent-state autoregressive world model pretrained in simulation and calibrated\nto target environments through residual corrections of latent-state dynamics\nrather than of explicit observed states. Using this adapted world model, ReDRAW\nenables RL agents to be optimized with imagined rollouts under corrected\ndynamics and then deployed in the real world. In multiple vision-based MuJoCo\ndomains and a physical robot visual lane-following task, ReDRAW effectively\nmodels changes to dynamics and avoids overfitting in low data regimes where\ntraditional transfer methods fail.", "published": "2025-04-03 03:41:30", "link": "http://arxiv.org/abs/2504.02252v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "AC-LoRA: Auto Component LoRA for Personalized Artistic Style Image Generation", "abstract": "Personalized image generation allows users to preserve styles or subjects of\na provided small set of images for further image generation. With the\nadvancement in large text-to-image models, many techniques have been developed\nto efficiently fine-tune those models for personalization, such as Low Rank\nAdaptation (LoRA). However, LoRA-based methods often face the challenge of\nadjusting the rank parameter to achieve satisfactory results. To address this\nchallenge, AutoComponent-LoRA (AC-LoRA) is proposed, which is able to\nautomatically separate the signal component and noise component of the LoRA\nmatrices for fast and efficient personalized artistic style image generation.\nThis method is based on Singular Value Decomposition (SVD) and dynamic\nheuristics to update the hyperparameters during training. Superior performance\nover existing methods in overcoming model underfitting or overfitting problems\nis demonstrated. The results were validated using FID, CLIP, DINO, and\nImageReward, achieving an average of 9% improvement.", "published": "2025-04-03 02:56:01", "link": "http://arxiv.org/abs/2504.02231v1", "categories": ["cs.CV", "cs.AI", "68T05, 68U10", "I.2.6; I.4.0"], "primary_category": "cs.CV"}
{"title": "VEGAS: Towards Visually Explainable and Grounded Artificial Social Intelligence", "abstract": "Social Intelligence Queries (Social-IQ) serve as the primary multimodal\nbenchmark for evaluating a model's social intelligence level. While impressive\nmultiple-choice question(MCQ) accuracy is achieved by current solutions,\nincreasing evidence shows that they are largely, and in some cases entirely,\ndependent on language modality, overlooking visual context. Additionally, the\nclosed-set nature further prevents the exploration of whether and to what\nextent the reasoning path behind selection is correct. To address these\nlimitations, we propose the Visually Explainable and Grounded Artificial Social\nIntelligence (VEGAS) model. As a generative multimodal model, VEGAS leverages\nopen-ended answering to provide explainable responses, which enhances the\nclarity and evaluation of reasoning paths. To enable visually grounded\nanswering, we propose a novel sampling strategy to provide the model with more\nrelevant visual frames. We then enhance the model's interpretation of these\nframes through Generalist Instruction Fine-Tuning (GIFT), which aims to: i)\nlearn multimodal-language transformations for fundamental emotional social\ntraits, and ii) establish multimodal joint reasoning capabilities. Extensive\nexperiments, comprising modality ablation, open-ended assessments, and\nsupervised MCQ evaluations, consistently show that VEGAS effectively utilizes\nvisual information in reasoning to produce correct and also credible answers.\nWe expect this work to of fer a new perspective on Social-IQ and advance the\ndevelopment of human-like social AI.", "published": "2025-04-03 02:48:21", "link": "http://arxiv.org/abs/2504.02227v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Learning and Improving Backgammon Strategy", "abstract": "A novel approach to learning is presented, combining features of on-line and\noff-line methods to achieve considerable performance in the task of learning a\nbackgammon value function in a process that exploits the processing power of\nparallel supercomputers. The off-line methods comprise a set of techniques for\nparallelizing neural network training and $TD(\\lambda)$ reinforcement learning;\nhere Monte-Carlo ``Rollouts'' are introduced as a massively parallel on-line\npolicy improvement technique which applies resources to the decision points\nencountered during the search of the game tree to further augment the learned\nvalue function estimate. A level of play roughly as good as, or possibly better\nthan, the current champion human and computer backgammon players has been\nachieved in a short period of learning.", "published": "2025-04-03 02:27:22", "link": "http://arxiv.org/abs/2504.02221v1", "categories": ["cs.LG", "cs.AI", "cs.NE"], "primary_category": "cs.LG"}
{"title": "FT-Transformer: Resilient and Reliable Transformer with End-to-End Fault Tolerant Attention", "abstract": "Transformer models leverage self-attention mechanisms to capture complex\ndependencies, demonstrating exceptional performance in various applications.\nHowever, the long-duration high-load computations required for model inference\nimpose stringent reliability demands on the computing platform, as soft errors\nthat occur during execution can significantly degrade model performance.\nExisting fault tolerance methods protect each operation separately using\ndecoupled kernels, incurring substantial computational and memory overhead. In\nthis paper, we propose a novel error-resilient framework for Transformer\nmodels, integrating end-to-end fault tolerant attention (EFTA) to improve\ninference reliability against soft errors. Our approach enables error detection\nand correction within a fully fused attention kernel, reducing redundant data\naccess and thereby mitigating memory faults. To further enhance error coverage\nand reduce overhead, we design a hybrid fault tolerance scheme tailored for the\nEFTA, introducing for the first time: 1) architecture-aware algorithm-based\nfault tolerance (ABFT) using tensor checksum, which minimizes inter-thread\ncommunication overhead on tensor cores during error detection; 2) selective\nneuron value restriction, which selectively applies adaptive fault tolerance\nconstraints to neuron values, balancing error coverage and overhead; 3) unified\nverification, reusing checksums to streamline multiple computation steps into a\nsingle verification process. Experimental results show that EFTA achieves up to\n7.56x speedup over traditional methods with an average fault tolerance overhead\nof 13.9%.", "published": "2025-04-03 02:05:08", "link": "http://arxiv.org/abs/2504.02211v1", "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "cs.DC"}
{"title": "ESC: Erasing Space Concept for Knowledge Deletion", "abstract": "As concerns regarding privacy in deep learning continue to grow, individuals\nare increasingly apprehensive about the potential exploitation of their\npersonal knowledge in trained models. Despite several research efforts to\naddress this, they often fail to consider the real-world demand from users for\ncomplete knowledge erasure. Furthermore, our investigation reveals that\nexisting methods have a risk of leaking personal knowledge through embedding\nfeatures. To address these issues, we introduce a novel concept of Knowledge\nDeletion (KD), an advanced task that considers both concerns, and provides an\nappropriate metric, named Knowledge Retention score (KR), for assessing\nknowledge retention in feature space. To achieve this, we propose a novel\ntraining-free erasing approach named Erasing Space Concept (ESC), which\nrestricts the important subspace for the forgetting knowledge by eliminating\nthe relevant activations in the feature. In addition, we suggest ESC with\nTraining (ESC-T), which uses a learnable mask to better balance the trade-off\nbetween forgetting and preserving knowledge in KD. Our extensive experiments on\nvarious datasets and models demonstrate that our proposed methods achieve the\nfastest and state-of-the-art performance. Notably, our methods are applicable\nto diverse forgetting scenarios, such as facial domain setting, demonstrating\nthe generalizability of our methods. The code is available at\nhttp://github.com/KU-VGI/ESC .", "published": "2025-04-03 00:53:09", "link": "http://arxiv.org/abs/2504.02199v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment", "abstract": "Aligning large language models (LLMs) with human values is an increasingly\ncritical step in post-training. Direct Preference Optimization (DPO) has\nemerged as a simple, yet effective alternative to reinforcement learning from\nhuman feedback (RLHF). Synthetic preference data with its low cost and high\nquality enable effective alignment through single- or multi-model generated\npreference data. Our study reveals a striking, safety-specific phenomenon\nassociated with DPO alignment: Although multi-model generated data enhances\nperformance on general tasks (ARC, Hellaswag, MMLU, TruthfulQA, Winogrande) by\nproviding diverse responses, it also tends to facilitate reward hacking during\ntraining. This can lead to a high attack success rate (ASR) when models\nencounter jailbreaking prompts. The issue is particularly pronounced when\nemploying stronger models like GPT-4o or larger models in the same family to\ngenerate chosen responses paired with target model self-generated rejected\nresponses, resulting in dramatically poorer safety outcomes. Furthermore, with\nrespect to safety, using solely self-generated responses (single-model\ngeneration) for both chosen and rejected pairs significantly outperforms\nconfigurations that incorporate responses from stronger models, whether used\ndirectly as chosen data or as part of a multi-model response pool. We\ndemonstrate that multi-model preference data exhibits high linear separability\nbetween chosen and rejected responses, which allows models to exploit\nsuperficial cues rather than internalizing robust safety constraints. Our\nexperiments, conducted on models from the Llama, Mistral, and Qwen families,\nconsistently validate these findings.", "published": "2025-04-03 00:36:40", "link": "http://arxiv.org/abs/2504.02193v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Optimal Erasure Codes and Codes on Graphs", "abstract": "We construct constant-sized ensembles of linear error-correcting codes over\nany fixed alphabet that can correct a given fraction of adversarial erasures at\nrates approaching the Singleton bound arbitrarily closely. We provide several\napplications of our results:\n  1. Explicit constructions of strong linear seeded symbol-fixing extractors\nand lossless condensers, over any fixed alphabet, with only a constant seed\nlength and optimal output lengths;\n  2. A strongly explicit construction of erasure codes on bipartite graphs\n(more generally, linear codes on matrices of arbitrary dimensions) with optimal\nrate and erasure-correction trade-offs;\n  3. A strongly explicit construction of erasure codes on non-bipartite graphs\n(more generally, linear codes on symmetric square matrices) achieving improved\nrates;\n  4. A strongly explicit construction of linear nearly-MDS codes over\nconstant-sized alphabets that can be encoded and decoded in quasi-linear time.", "published": "2025-04-03 23:53:52", "link": "http://arxiv.org/abs/2504.03090v1", "categories": ["cs.IT", "cs.DM", "math.CO", "math.IT"], "primary_category": "cs.IT"}
{"title": "The Generalized Double Pouring Problem: Analysis, Bounds and Algorithms", "abstract": "We consider a logical puzzle which we call double pouring problem, which was\noriginal defined for $k=3$ vessels. We generalize this definition to $k \\ge 2 $\nas follows. Each of the $k$ vessels contains an integer amount of water, called\nits value, where the values are $a_i$ for $i=1,2,\\dots,k$ and the sum of values\nis $n$. A pouring step means pouring water from one vessel with value $a_i$ to\nanother vessel with value $a_j$, where $ 1 \\le i \\not= j \\le k $ and $a_i \\le\na_j $. After this pouring step the first vessel has value $2a_i$ and the second\none value $a_j-a_i$. Now the pouring problem is to find as few pourings steps\nas possible to empty at least one vessel, or to show that such an emptying is\nnot possible (which is possible only in the case $k=2$).\n  For $k=2$ each pouring step is unique. We give a necessary and sufficient\ncondition, when for a given $ (a_1,a_2)$ with $a_1+a_2=n$ the pouring problem\nis solvable. For $k=3$ we improve the upper bound of the pouring problem for\nsome special cases. For $k \\ge 4 $ we extend the known lower bound for $k=3$\nand improve the known upper bound $\\mathcal{O}((\\log n)^2)$ for $k=3$ to\n$\\mathcal{O}(\\log n\\log\\log n)$. Finally, for $k \\ge 3$, we investigate values\nand bounds for some functions related to the pouring problem.", "published": "2025-04-03 21:34:17", "link": "http://arxiv.org/abs/2504.03039v1", "categories": ["math.CO", "cs.DM", "90C27, 68W40"], "primary_category": "math.CO"}
{"title": "Vanishing of Schubert coefficients is in ${\\sf AM}\\cap {\\sf coAM}$ assuming the GRH", "abstract": "The Schubert vanishing problem is a central decision problem in algebraic\ncombinatorics and Schubert calculus, with applications to representation theory\nand enumerative algebraic geometry. The problem has been studied for over 50\nyears in different settings, with much progress given in the last two decades.\n  We prove that the Schubert vanishing problem is in ${\\sf AM}$ assuming the\nGeneralized Riemann Hypothesis (GRH). This complements our earlier result in\narXiv:2412.02064, that the problem is in ${\\sf coAM}$ assuming the GRH. In\nparticular, this implies that the Schubert vanishing problem is unlikely to be\n${\\sf coNP}$-hard, as we previously conjectured in arXiv:2412.02064.\n  The proof is of independent interest as we formalize and expand the notion of\na lifted formulation partly inspired by algebraic computations of Schubert\nproblems, and extended formulations of linear programs. We use a result by\nMahajan--Vinay to show that the determinant has a lifted formulation of\npolynomial size. We combine this with Purbhoo's algebraic criterion to derive\nthe result.", "published": "2025-04-03 19:54:33", "link": "http://arxiv.org/abs/2504.03004v1", "categories": ["math.CO", "cs.CC", "cs.DM", "math.AG", "Primary: 05E14, Secondary: 14M15, 14N15, 68Q17, 68Q25, 90C27"], "primary_category": "math.CO"}
{"title": "A Dense Neighborhood Lemma, with Applications to Domination and Chromatic Number", "abstract": "In its Euclidean form, the Dense Neighborhood Lemma (DNL) asserts that if $V$\nis a finite set of points of $\\mathbb{R}^N$ such that for each $v \\in V$ the\nball $B(v,1)$ intersects $V$ on at least $\\delta |V|$ points, then for every\n$\\varepsilon >0$, the points of $V$ can be covered with $f(\\delta,\\varepsilon)$\nballs $B(v,1+\\varepsilon)$ with $v \\in V$. DNL also applies to other metric\nspaces and to abstract set systems, where elements are compared pairwise with\nrespect to (near) disjointness. In its strongest form, DNL provides an\n$\\varepsilon$-clustering with size exponential in $\\varepsilon^{-1}$, which\namounts to a Regularity Lemma with 0/1 densities of some trigraph.\n  Trigraphs are graphs with additional red edges. For instance, in the\nEuclidean case the black edges would connect points at distance at most 1, and\nthe red edges would connect points at distance between $1$ and $1+\\varepsilon$.\nThis paper is mainly a study of the generalization of Vapnik-Cervonenkis\ndimension to trigraphs. The main point is to show how trigraphs can sometimes\nexplain the success of random sampling even though the VC-dimension of the\nunderlying graph is unbounded. All the results presented here are effective in\nthe sense of computation: they primarily rely on uniform sampling with the same\nsuccess rate as in classical VC-dimension theory.\n  Among some applications of DNL, we show that\n$\\left(\\frac{3t-8}{3t-5}+\\varepsilon\\right)\\cdot n$-regular $K_t$-free graphs\nhave bounded chromatic number. Similarly, triangle-free graphs with minimum\ndegree $n/3-n^{1-\\varepsilon}$ have bounded chromatic number (this does not\nhold with $n/3-n^{1-o(1)}$). For tournaments, DNL implies that the domination\nnumber is bounded in terms of the fractional chromatic number. Also,\n$(1/2-\\varepsilon)$-majority digraphs have bounded domination, independently of\nthe number of voters.", "published": "2025-04-03 19:31:05", "link": "http://arxiv.org/abs/2504.02992v1", "categories": ["cs.DM", "math.CO"], "primary_category": "cs.DM"}
{"title": "Vertex-Based Localization of Tur\u00e1n's Theorem", "abstract": "For a simple graph $G$, let $n$ and $m$ denote the number of vertices and\nedges in $G$, respectively. Tur\\'{a}n's theorem states that in a simple\n$K_{r+1}$ free graph, $m \\leq \\frac{n^2(r-1)}{2r}$. In this paper, we\ngeneralize this result as follows: For each $v \\in V(G)$, let $c(v)$ be the\norder of the largest clique that contains $v$. We show that \\[ m \\leq\n\\frac{n}{2}\\sum_{v\\in V(G)}\\frac{c(v)-1}{c(v)}\\] Furthermore, we characterize\nthe class of extremal graphs that attain equality in this bound.", "published": "2025-04-03 17:51:50", "link": "http://arxiv.org/abs/2504.02806v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Faster Mixing of the Jerrum-Sinclair Chain", "abstract": "We show that the Jerrum-Sinclair Markov chain on matchings mixes in time\n$\\widetilde{O}(\\Delta^2 m)$ on any graph with $n$ vertices, $m$ edges, and\nmaximum degree $\\Delta$, for any constant edge weight $\\lambda>0$. For general\ngraphs with arbitrary, potentially unbounded $\\Delta$, this provides the first\nimprovement over the classic $\\widetilde{O}(n^2 m)$ mixing time bound of Jerrum\nand Sinclair (1989) and Sinclair (1992).\n  To achieve this, we develop a general framework for analyzing mixing times,\ncombining ideas from the classic canonical path method with the\n\"local-to-global\" approaches recently developed in high-dimensional expanders,\nintroducing key innovations to both techniques.", "published": "2025-04-03 16:26:20", "link": "http://arxiv.org/abs/2504.02740v1", "categories": ["cs.DS", "cs.DM", "math.PR"], "primary_category": "cs.DS"}
{"title": "Investigating Simple Drawings of $K_n$ using SAT", "abstract": "We present a SAT framework which allows to investigate properties of simple\ndrawings of the complete graph $K_n$ using the power of AI. In contrast to\nclassic imperative programming, where a program is operated step by step, our\nframework models mathematical questions as Boolean formulas which are then\nsolved using modern SAT solvers. Our framework for simple drawings is based on\na characterization via rotation systems and finite forbidden substructures. We\nshowcase its universality by addressing various open problems, reproving\nprevious computational results and deriving several new computational results.\nIn particular, we test and progress on several unavoidable configurations such\nas variants of Rafla's conjecture on plane Hamiltonian cycles, Harborth's\nconjecture on empty triangles, and crossing families for general simple\ndrawings as well as for various subclasses. Moreover, based our computational\nresults we propose some new challenging conjectures.", "published": "2025-04-03 14:48:47", "link": "http://arxiv.org/abs/2504.02650v1", "categories": ["cs.CG", "cs.DM", "math.CO"], "primary_category": "cs.CG"}
{"title": "On Average Distance, Level-1 Fourier Weight, and Chang's Lemma", "abstract": "In this paper, we improve the well-known level-1 weight bound, also known as\nChang's lemma, by using an induction method. Our bounds are close to optimal no\nmatter when the set is large or small. Our bounds can be seen as bounds on the\nminimum average distance problem, since maximizing the level-1 weight is\nequivalent to minimizing the average distance. We apply our new bounds to\nimprove the Friedgut--Kalai--Naor theorem. We also derive the sharp version for\nChang's original lemma for $\\mathbb{F}_{2}^{n}$. That is, we show that in\n$\\mathbb{F}_{2}^{n}$, Hamming balls maximize the dimension of the space spanned\nby large Fourier coefficients.", "published": "2025-04-03 13:55:39", "link": "http://arxiv.org/abs/2504.02593v1", "categories": ["math.CO", "cs.DM", "cs.IT", "math.IT"], "primary_category": "math.CO"}
{"title": "Polynomial Bounds for the Graph Minor Structure Theorem", "abstract": "The Graph Minor Structure Theorem, originally proven by Robertson and Seymour\n[JCTB, 2003], asserts that there exist functions $f_1, f_2 \\colon \\mathbb{N}\n\\to \\mathbb{N}$ such that for every non-planar graph $H$ with $t := |V(H)|$,\nevery $H$-minor-free graph can be obtained via the clique-sum operation from\ngraphs which embed into surfaces where $H$ does not embed after deleting at\nmost $f_1(t)$ many vertices with up to at most $t^2-1$ many ``vortices'' which\nare of ``depth'' at most $f_2(t)$. In the proof presented by Robertson and\nSeymour the functions $f_1$ and $f_2$ are non-constructive. Kawarabayashi,\nThomas, and Wollan [arXiv, 2020] found a new proof showing that $f_1(t), f_2(t)\n\\in 2^{\\mathbf{poly}(t)}$. While believing that this bound was the best their\nmethods could achieve, Kawarabayashi, Thomas, and Wollan conjectured that $f_1$\nand $f_2$ can be improved to be polynomials.\n  In this paper we confirm their conjecture and prove that $f_1(t), f_2(t) \\in\n\\mathbf{O}(t^{2300})$. Our proofs are fully constructive and yield a\npolynomial-time algorithm that either finds $H$ as a minor in a graph $G$ or\nproduces a clique-sum decomposition for $G$ as above.", "published": "2025-04-03 12:35:45", "link": "http://arxiv.org/abs/2504.02532v1", "categories": ["math.CO", "cs.DM", "05C10, 05C40, 05C75, 05C83, 05C85, 68R05, 68R10", "G.2.1; G.2.2"], "primary_category": "math.CO"}
{"title": "Edge-weighted balanced connected partitions: Hardness and formulations", "abstract": "The balanced connected $k$-partition problem (BCP) is a classic problem which\nconsists in partitioning the set of vertices of a vertex-weighted connected\ngraph into a collection of $k$ sets such that each of them induces a connected\nsubgraph of roughly the same weight. There exists a vast literature on BCP that\nincludes hardness results, approximation algorithms, integer programming\nformulations, and a polyhedral study. We investigate edge-weighted variants of\nBCP where we are given a connected graph $G$, $k \\in \\mathbb{Z}_\\ge$, and an\nedge-weight function $w \\colon E(G)\\to\\mathbb{Q}_\\ge$, and the goal is to\ncompute a spanning $k$-forest $\\mathcal{T}$ of $G$ (i.e., a forest with exactly\n$k$ trees) that minimizes the weight of the heaviest tree in $\\mathcal{T}$ in\nthe min-max version, or maximizes the weight of the lightest tree in\n$\\mathcal{T}$ in the max-min version. We show that both versions of this\nproblem are $\\mathsf{NP}$-hard on complete graphs with $k=2$, unweighted split\ngraphs, and unweighted bipartite graphs with $k\\geq 2$ fixed. Moreover, we\nprove that these problems do not admit subexponential-time algorithms, unless\nthe Exponential-Time Hypothesis fails. Finally, we devise compact and\nnon-compact integer linear programming formulations, valid inequalities, and\nseparation algorithms.", "published": "2025-04-03 09:23:31", "link": "http://arxiv.org/abs/2504.02421v1", "categories": ["cs.DS", "cs.DM", "90C11, 68Q25"], "primary_category": "cs.DS"}
{"title": "Interval Graphs are Reconstructible", "abstract": "A graph is reconstructible if it is determined up to isomorphism by the\nmultiset of its proper induced subgraphs. The reconstruction conjecture\npostulates that every graph of order at least 3 is reconstructible. We show\nthat interval graphs with at least three vertices are reconstructible. For this\npurpose we develop a technique to handle separations in the context of\nreconstruction. This resolves a major roadblock to using graph structure theory\nin the context of reconstruction. To apply our novel technique, we also develop\na resilient combinatorial structure theory for interval graphs. A consequence\nof our result is that interval graphs can be reconstructed in polynomial time.", "published": "2025-04-03 07:42:05", "link": "http://arxiv.org/abs/2504.02353v1", "categories": ["math.CO", "cs.DM", "cs.DS", "68R10, 68Q25", "F.2.2; G.2.2"], "primary_category": "math.CO"}
{"title": "Graphs are everywhere -- Psst! In Music Recommendation too", "abstract": "In recent years, graphs have gained prominence across various domains,\nespecially in recommendation systems. Within the realm of music recommendation,\ngraphs play a crucial role in enhancing genre-based recommendations by\nintegrating Mel-Frequency Cepstral Coefficients (MFCC) with advanced graph\nembeddings. This study explores the efficacy of Graph Convolutional Networks\n(GCN), GraphSAGE, and Graph Transformer (GT) models in learning embeddings that\neffectively capture intricate relationships between music items and genres\nrepresented within graph structures. Through comprehensive empirical\nevaluations on diverse real-world music datasets, our findings consistently\ndemonstrate that these graph-based approaches outperform traditional methods\nthat rely solely on MFCC features or collaborative filtering techniques.\nSpecifically, the graph-enhanced models achieve notably higher accuracy in\npredicting genre-specific preferences and offering relevant music suggestions\nto users. These results underscore the effectiveness of utilizing graph\nembeddings to enrich feature representations and exploit latent associations\nwithin music data, thereby illustrating their potential to advance the\ncapabilities of personalized and context-aware music recommendation systems.\nKeywords: graphs, recommendation systems, neural networks, MFCC", "published": "2025-04-03 14:00:52", "link": "http://arxiv.org/abs/2504.02598v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Research Paper Recommender System by Considering Users' Information Seeking Behaviors", "abstract": "With the rapid growth of scientific publications, researchers need to spend\nmore time and effort searching for papers that align with their research\ninterests. To address this challenge, paper recommendation systems have been\ndeveloped to help researchers in effectively identifying relevant paper. One of\nthe leading approaches to paper recommendation is content-based filtering\nmethod. Traditional content-based filtering methods recommend relevant papers\nto users based on the overall similarity of papers. However, these approaches\ndo not take into account the information seeking behaviors that users commonly\nemploy when searching for literature. Such behaviors include not only\nevaluating the overall similarity among papers, but also focusing on specific\nsections, such as the method section, to ensure that the approach aligns with\nthe user's interests. In this paper, we propose a content-based filtering\nrecommendation method that takes this information seeking behavior into\naccount. Specifically, in addition to considering the overall content of a\npaper, our approach also takes into account three specific sections\n(background, method, and results) and assigns weights to them to better reflect\nuser preferences. We conduct offline evaluations on the publicly available DBLP\ndataset, and the results demonstrate that the proposed method outperforms six\nbaseline methods in terms of precision, recall, F1-score, MRR, and MAP.", "published": "2025-04-03 08:11:58", "link": "http://arxiv.org/abs/2504.02377v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "FEASE: Shallow AutoEncoding Recommender with Cold Start Handling via Side Features", "abstract": "User and item cold starts present significant challenges in industrial\napplications of recommendation systems. Supplementing user-item interaction\ndata with metadata is a common solution-but often at the cost of introducing\nadditional biases. In this work, we introduce an augmented EASE model, i.e.\nFEASE, that seamlessly integrates both user and item side information to\naddress these cold start issues. Our straightforward, autoencoder-based method\nproduces a closed-form solution that leverages rich content signals for cold\nitems while refining user representations in data-sparse environments.\nImportantly, our method strikes a balance by effectively recommending cold\nstart items and handling cold start users without incurring extra bias, and it\nmaintains strong performance in warm settings. Experimental results demonstrate\nimproved recommendation accuracy and robustness compared to previous\ncollaborative filtering approaches. Moreover, our model serves as a strong\nbaseline for future comparative studies.", "published": "2025-04-03 05:27:55", "link": "http://arxiv.org/abs/2504.02288v2", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "LLM-Augmented Graph Neural Recommenders: Integrating User Reviews", "abstract": "Recommender systems increasingly aim to combine signals from both user\nreviews and purchase (or other interaction) behaviors. While user-written\ncomments provide explicit insights about preferences, merging these textual\nrepresentations from large language models (LLMs) with graph-based embeddings\nof user actions remains a challenging task. In this work, we propose a\nframework that employs both a Graph Neural Network (GNN)-based model and an LLM\nto produce review-aware representations, preserving review semantics while\nmitigating textual noise. Our approach utilizes a hybrid objective that\nbalances user-item interactions against text-derived features, ensuring that\nuser's both behavioral and linguistic signals are effectively captured. We\nevaluate this method on multiple datasets from diverse application domains,\ndemonstrating consistent improvements over a baseline GNN-based recommender\nmodel. Notably, our model achieves significant gains in recommendation accuracy\nwhen review data is sparse or unevenly distributed. These findings highlight\nthe importance of integrating LLM-driven textual feedback with GNN-derived user\nbehavioral patterns to develop robust, context-aware recommender systems.", "published": "2025-04-03 00:40:09", "link": "http://arxiv.org/abs/2504.02195v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Low-Complexity Permutational Index Modulation for Noncoherent Massive SIMO Communications", "abstract": "This work presents a massive SIMO scheme for wireless communications with\none-shot noncoherent detection. It is based on permutational index modulation\nover OFDM. Its core principle is to convey information on the ordering in which\na fixed collection of values is mapped onto a set of OFDM subcarriers. A\nspherical code is obtained which provides improved robustness against channel\nimpairments. A simple detector based on the sorting of quadratic metrics of\ndata is proposed. By exploiting statistical channel state information and\nhardening, it reaches a near-ML error performance with a low-complexity\nimplementation.", "published": "2025-04-03 18:02:38", "link": "http://arxiv.org/abs/2504.02946v1", "categories": ["cs.IT", "eess.SP", "math.IT", "94A13", "E.4"], "primary_category": "cs.IT"}
{"title": "Bacon-Shor Board Games", "abstract": "We identify a period-4 measurement schedule for the checks of the Bacon-Shor\ncode that fully covers spacetime with constant-weight detectors, and is\nnumerically observed to provide the code with a threshold. Unlike previous\napproaches, our method does not rely on code concatenation and instead arises\nas the solution to a coloring game on a square grid. Under a uniform\ncircuit-level noise model, we observe a threshold of approximately $0.3\\%$ when\ndecoding with minimum weight perfect matching, and we conjecture that this\ncould be improved using a more tailored decoder.", "published": "2025-04-03 16:36:03", "link": "http://arxiv.org/abs/2504.02749v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "TeleMoM: Consensus-Driven Telecom Intelligence via Mixture of Models", "abstract": "Large language models (LLMs) face significant challenges in specialized\ndomains like telecommunication (Telecom) due to technical complexity,\nspecialized terminology, and rapidly evolving knowledge. Traditional methods,\nsuch as scaling model parameters or retraining on domain-specific corpora, are\ncomputationally expensive and yield diminishing returns, while existing\napproaches like retrieval-augmented generation, mixture of experts, and\nfine-tuning struggle with accuracy, efficiency, and coordination. To address\nthis issue, we propose Telecom mixture of models (TeleMoM), a consensus-driven\nensemble framework that integrates multiple LLMs for enhanced decision-making\nin Telecom. TeleMoM employs a two-stage process: proponent models generate\njustified responses, and an adjudicator finalizes decisions, supported by a\nquality-checking mechanism. This approach leverages strengths of diverse models\nto improve accuracy, reduce biases, and handle domain-specific complexities\neffectively. Evaluation results demonstrate that TeleMoM achieves a 9.7\\%\nincrease in answer accuracy, highlighting its effectiveness in Telecom\napplications.", "published": "2025-04-03 15:52:20", "link": "http://arxiv.org/abs/2504.02712v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Data-Driven Design of 3GPP Handover Parameters with Bayesian Optimization and Transfer Learning", "abstract": "Mobility management in dense cellular networks is challenging due to varying\nuser speeds and deployment conditions. Traditional 3GPP handover (HO) schemes,\nrelying on fixed A3-offset and time-to-trigger (TTT) parameters, struggle to\nbalance radio link failures (RLFs) and ping-pongs. We propose a data-driven HO\noptimization framework based on high-dimensional Bayesian optimization (HD-BO)\nand enhanced with transfer learning to reduce training time and improve\ngeneralization across different user speeds. Evaluations on a real-world\ndeployment show that HD-BO outperforms 3GPP set-1 and set-5 benchmarks, while\ntransfer learning enables rapid adaptation without loss in performance. This\nhighlights the potential of data-driven, site-specific mobility management in\nlarge-scale networks.", "published": "2025-04-03 14:31:20", "link": "http://arxiv.org/abs/2504.02633v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "VISTA: Unsupervised 2D Temporal Dependency Representations for Time Series Anomaly Detection", "abstract": "Time Series Anomaly Detection (TSAD) is essential for uncovering rare and\npotentially harmful events in unlabeled time series data. Existing methods are\nhighly dependent on clean, high-quality inputs, making them susceptible to\nnoise and real-world imperfections. Additionally, intricate temporal\nrelationships in time series data are often inadequately captured in\ntraditional 1D representations, leading to suboptimal modeling of dependencies.\nWe introduce VISTA, a training-free, unsupervised TSAD algorithm designed to\novercome these challenges. VISTA features three core modules: 1) Time Series\nDecomposition using Seasonal and Trend Decomposition via Loess (STL) to\ndecompose noisy time series into trend, seasonal, and residual components; 2)\nTemporal Self-Attention, which transforms 1D time series into 2D temporal\ncorrelation matrices for richer dependency modeling and anomaly detection; and\n3) Multivariate Temporal Aggregation, which uses a pretrained feature extractor\nto integrate cross-variable information into a unified, memory-efficient\nrepresentation. VISTA's training-free approach enables rapid deployment and\neasy hyperparameter tuning, making it suitable for industrial applications. It\nachieves state-of-the-art performance on five multivariate TSAD benchmarks.", "published": "2025-04-03 11:20:49", "link": "http://arxiv.org/abs/2504.02498v1", "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Revolutionizing Medical Data Transmission with IoMT: A Comprehensive Survey of Wireless Communication Solutions and Future Directions", "abstract": "Traditional hospital-based medical examination methods face unprecedented\nchallenges due to the aging global population. The Internet of Medical Things\n(IoMT), an advanced extension of the Internet of Things (IoT) tailored for the\nmedical field, offers a transformative solution for delivering medical care.\nIoMT consists of interconnected medical devices that collect and transmit\npatients' vital signs online. This data can be analyzed to identify potential\nhealth issues, support medical decision-making, enhance patient outcomes, and\nstreamline healthcare operations. Additionally, IoMT helps individuals make\ninformed decisions about their health and fitness. There is a natural synergy\nwith emerging communication technologies to ensure the secure and timely\ntransmission of medical data. This paper presents the first comprehensive\ntutorial on cutting-edge IoMT research focusing on wireless communication-based\nsolutions. It introduces a systematic three-tier framework to analyze IoMT\nnetworks and identify application scenarios. The paper examines the medical\ndata transmission process, including intra-wireless Body Area Networks (WBAN),\ninter-WBAN, and beyond-WBAN communications. It also discusses the challenges of\nimplementing IoMT applications, such as the longevity of biosensors, co-channel\ninterference management, information security, and data processing delays.\nProposed solutions to these challenges are explored from a wireless\ncommunication perspective, and future research directions are outlined. The\nsurvey concludes with a summary of key findings and insights.", "published": "2025-04-03 10:00:42", "link": "http://arxiv.org/abs/2504.02446v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Improved universal approximation with neural networks studied via affine-invariant subspaces of $L_2(\\mathbb{R}^n)$", "abstract": "We show that there are no non-trivial closed subspaces of $L_2(\\mathbb{R}^n)$\nthat are invariant under invertible affine transformations. We apply this\nresult to neural networks showing that any nonzero $L_2(\\mathbb{R})$ function\nis an adequate activation function in a one hidden layer neural network in\norder to approximate every function in $L_2(\\mathbb{R})$ with any desired\naccuracy. This generalizes the universal approximation properties of neural\nnetworks in $L_2(\\mathbb{R})$ related to Wiener's Tauberian Theorems. Our\nresults extend to the spaces $L_p(\\mathbb{R})$ with $p>1$.", "published": "2025-04-03 10:00:40", "link": "http://arxiv.org/abs/2504.02445v1", "categories": ["math.FA", "cs.IT", "math.IT"], "primary_category": "math.FA"}
{"title": "An Efficient Reservation Protocol for Medium Access: When Tree Splitting Meets Reinforcement Learning", "abstract": "As an enhanced version of massive machine-type communication in 5G, massive\ncommunication has emerged as one of the six usage scenarios anticipated for 6G,\nowing to its potential in industrial internet-of-things and smart metering.\nDriven by the need for random multiple-access (RMA) in massive communication,\nas well as, next-generation Wi-Fi, medium access control has attracted\nconsiderable recent attention. Holding the promise of attaining\nbandwidth-efficient collision resolution, multiaccess reservation no doubt\nplays a central role in RMA, e.g., the distributed coordination function (DCF)\nin IEEE 802.11. In this paper, we are interested in maximizing the bandwidth\nefficiency of reservation protocols for RMA under quality-of-service\nconstraints. Particularly, we present a tree splitting based reservation\nscheme, in which the attempting probability is dynamically optimized by\npartially observable Markov decision process or reinforcement learning (RL).\nThe RL-empowered tree-splitting algorithm guarantees that all these terminals\nwith backlogged packets at the beginning of a contention cycle can be\nscheduled, thereby providing a first-in-first-out service. More importantly, it\nsubstantially reduces the reservation bandwidth determined by the communication\ncomplexity of DCF, through judiciously conceived coding and interaction for\nexchanging information required by distributed ordering. Simulations\ndemonstrate that the proposed algorithm outperforms the CSMA/CA based DCF in\nIEEE 802.11.", "published": "2025-04-03 08:10:25", "link": "http://arxiv.org/abs/2504.02376v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Liquid Neural Networks: Next-Generation AI for Telecom from First Principles", "abstract": "Artificial intelligence (AI) has emerged as a transformative technology with\nimmense potential to reshape the next-generation of wireless networks. By\nleveraging advanced algorithms and machine learning techniques, AI offers\nunprecedented capabilities in optimizing network performance, enhancing data\nprocessing efficiency, and enabling smarter decision-making processes. However,\nexisting AI solutions face significant challenges in terms of robustness and\ninterpretability. Specifically, current AI models exhibit substantial\nperformance degradation in dynamic environments with varying data\ndistributions, and the black-box nature of these algorithms raises concerns\nregarding safety, transparency, and fairness. This presents a major challenge\nin integrating AI into practical communication systems. Recently, a novel type\nof neural network, known as the liquid neural networks (LNNs), has been\ndesigned from first principles to address these issues. In this paper, we\nexplore the potential of LNNs in telecommunications. First, we illustrate the\nmechanisms of LNNs and highlight their unique advantages over traditional\nnetworks. Then we unveil the opportunities that LNNs bring to future wireless\nnetworks. Furthermore, we discuss the challenges and design directions for the\nimplementation of LNNs. Finally, we summarize the performance of LNNs in two\ncase studies.", "published": "2025-04-03 07:41:04", "link": "http://arxiv.org/abs/2504.02352v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Asymmetric graph alignment and the phase transition for asymmetric tree correlation testing", "abstract": "Graph alignment - identifying node correspondences between two graphs - is a\nfundamental problem with applications in network analysis, biology, and privacy\nresearch. While substantial progress has been made in aligning correlated\nErd\\H{o}s-R\\'enyi graphs under symmetric settings, real-world networks often\nexhibit asymmetry in both node numbers and edge densities. In this work, we\nintroduce a novel framework for asymmetric correlated Erd\\H{o}s-R\\'enyi graphs,\ngeneralizing existing models to account for these asymmetries. We conduct a\nrigorous theoretical analysis of graph alignment in the sparse regime, where\nlocal neighborhoods exhibit tree-like structures. Our approach leverages tree\ncorrelation testing as the central tool in our polynomial-time algorithm,\nMPAlign, which achieves one-sided partial alignment under certain conditions.\n  A key contribution of our work is characterizing these conditions under which\nasymmetric tree correlation testing is feasible: If two correlated graphs $G$\nand $G'$ have average degrees $\\lambda s$ and $\\lambda s'$ respectively, where\n$\\lambda$ is their common density and $s,s'$ are marginal correlation\nparameters, their tree neighborhoods can be aligned if $ss' > \\alpha$, where\n$\\alpha$ denotes Otter's constant and $\\lambda$ is supposed large enough. The\nfeasibility of this tree comparison problem undergoes a sharp phase transition\nsince $ss' \\leq \\alpha$ implies its impossibility. These new results on tree\ncorrelation testing allow us to solve a class of random subgraph isomorphism\nproblems, resolving an open problem in the field.", "published": "2025-04-03 06:10:00", "link": "http://arxiv.org/abs/2504.02299v1", "categories": ["cs.IT", "cs.DS", "math.IT"], "primary_category": "cs.IT"}
{"title": "Steve: LLM Powered ChatBot for Career Progression", "abstract": "The advancements in systems deploying large language models (LLMs), as well\nas improvements in their ability to act as agents with predefined templates,\nprovide an opportunity to conduct qualitative, individualized assessments,\ncreating a bridge between qualitative and quantitative methods for candidates\nseeking career progression. In this paper, we develop a platform that allows\ncandidates to run AI-led interviews to assess their current career stage and\ncurate coursework to enable progression to the next level. Our approach\nincorporates predefined career trajectories, associated skills, and a method to\nrecommend the best resources for gaining the necessary skills for advancement.\nWe employ OpenAI API calls along with expertly compiled chat templates to\nassess candidate competence. Our platform is highly configurable due to the\nmodularity of the development, is easy to deploy and use, and available as a\nweb interface where the only requirement is candidate resumes in PDF format. We\ndemonstrate a use-case centered on software engineering and intend to extend\nthis platform to be domain-agnostic, requiring only regular updates to chat\ntemplates as industries evolve.", "published": "2025-04-03 22:24:22", "link": "http://arxiv.org/abs/2504.03789v1", "categories": ["cs.CY", "cs.MA"], "primary_category": "cs.CY"}
{"title": "Sequential Binary Hypothesis Testing with Competing Agents under Information Asymmetry", "abstract": "This paper concerns sequential hypothesis testing in competitive multi-agent\nsystems where agents exchange potentially manipulated information.\nSpecifically, a two-agent scenario is studied where each agent aims to\ncorrectly infer the true state of nature while optimizing decision speed and\naccuracy. At each iteration, agents collect private observations, update their\nbeliefs, and share (possibly corrupted) belief signals with their counterparts\nbefore deciding whether to stop and declare a state, or continue gathering more\ninformation. The analysis yields three main results: (1)~when agents share\ninformation strategically, the optimal signaling policy involves\nequal-probability randomization between truthful and inverted beliefs;\n(2)~agents maximize performance by relying solely on their own observations for\nbelief updating while using received information only to anticipate their\ncounterpart's stopping decision; and (3)~the agent reaching their confidence\nthreshold first cause the other agent to achieve a higher conditional\nprobability of error. Numerical simulations further demonstrate that agents\nwith higher KL divergence in their conditional distributions gain competitive\nadvantage. Furthermore, our results establish that information sharing --\ndespite strategic manipulation -- reduces overall system stopping time compared\nto non-interactive scenarios, which highlights the inherent value of\ncommunication even in this competitive setup.", "published": "2025-04-03 16:30:40", "link": "http://arxiv.org/abs/2504.02743v1", "categories": ["eess.SY", "cs.MA", "cs.SY", "math.OC"], "primary_category": "eess.SY"}
{"title": "On Word-of-Mouth and Private-Prior Sequential Social Learning", "abstract": "Social learning provides a fundamental framework in economics and social\nsciences for studying interactions among rational agents who observe each\nother's actions but lack direct access to individual beliefs. This paper\ninvestigates a specific social learning paradigm known as Word-of-Mouth (WoM),\nwhere a series of agents seeks to estimate the state of a dynamical system. The\nfirst agent receives noisy measurements of the state, while each subsequent\nagent relies solely on a degraded version of her predecessor's estimate. A\ndefining feature of WoM is that the final agent's belief is publicly broadcast\nand adopted by all agents, in place of their own. We analyze this setting both\ntheoretically and through numerical simulations, showing that some agents\nbenefit from using the public belief broadcast by the last agent, while others\nsuffer from performance deterioration.", "published": "2025-04-03 11:20:53", "link": "http://arxiv.org/abs/2504.02913v2", "categories": ["cs.MA", "cs.SI", "cs.SY", "eess.SY"], "primary_category": "cs.MA"}
{"title": "An Optimal O(N) Helmholtz Solver for Complex Geometry using WaveHoltz and Overset Grids", "abstract": "We develop efficient and high-order accurate solvers for the Helmholtz\nequation on complex geometry. The schemes are based on the WaveHoltz algorithm\nwhich computes solutions of the Helmholtz equation by time-filtering solutions\nof the wave equation. The approach avoids the need to invert an indefinite\nmatrix which can cause convergence difficulties for many iterative solvers for\nindefinite Helmholtz problems. Complex geometry is treated with overset grids\nwhich use Cartesian grids throughout most of the domain together with\ncurvilinear grids near boundaries. The basic WaveHoltz fixed-point iteration is\naccelerated using GMRES and also by a deflation technique using a set of\nprecomputed eigenmodes. The solution of the wave equation is solved efficiently\nwith implicit time-stepping using as few as five time-steps per period,\nindependent of the mesh size. The time-domain solver is adjusted to remove\ndispersion errors in time and this enables the use of such large time-steps\nwithout degrading the accuracy. When multigrid is used to solve the implicit\ntime-stepping equations, the cost of the resulting WaveHoltz scheme scales\nlinearly with the total number of grid points N (at fixed frequency) and is\nthus optimal in CPU-time and memory usage as the mesh is refined. A simple\nrule-of-thumb formula is provided to estimate the number of\npoints-per-wavelength required for a p-th order accurate scheme which accounts\nfor pollution (dispersion) errors. Numerical results are given for problems in\ntwo and three space dimensions, to second and fourth-order accuracy, and they\nshow the potential of the approach to solve a wide range of large-scale\nproblems.", "published": "2025-04-03 22:53:38", "link": "http://arxiv.org/abs/2504.03074v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Characterizing and computing solutions to regularized semi-discrete optimal transport via an ordinary differential equation", "abstract": "This paper investigates the semi-discrete optimal transport (OT) problem with\nentropic regularization. We characterize the solution using a governing,\nwell-posed ordinary differential equation (ODE). This naturally yields an\nalgorithm to solve the problem numerically, which we prove has desirable\nproperties, notably including global strong convexity of a value function whose\nHessian must be inverted in the numerical scheme. Extensive numerical\nexperiments are conducted to validate our approach. We compare the solutions\nobtained using the ODE method with those derived from Newton's method. Our\nresults demonstrate that the proposed algorithm is competitive for problems\ninvolving the squared Euclidean distance and exhibits superior performance when\napplied to various powers of the Euclidean distance. Finally, we note that the\nODE approach yields an estimate on the rate of convergence of the solution as\nthe regularization parameter vanishes, for a generic cost function.", "published": "2025-04-03 21:07:42", "link": "http://arxiv.org/abs/2504.03030v1", "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "math.NA"}
{"title": "Convergence of the Markovian iteration for coupled FBSDEs via a differentiation approach", "abstract": "In this paper, we investigate the Markovian iteration method for solving\ncoupled forward-backward stochastic differential equations (FBSDEs) featuring a\nfully coupled forward drift, meaning the drift term explicitly depends on both\nthe forward and backward processes. An FBSDE system typically involves three\nstochastic processes: the forward process $X$, the backward process $Y$\nrepresenting the solution, and the $Z$ process corresponding to the scaled\nderivative of $Y$. Prior research by Bender and Zhang (2008) has established\nconvergence results for iterative schemes dealing with $Y$-coupled FBSDEs.\nHowever, extending these results to equations with $Z$ coupling poses\nsignificant challenges, especially in uniformly controlling the Lipschitz\nconstant of the decoupling fields across iterations and time steps within a\nfixed-point framework.\n  To overcome this issue, we propose a novel differentiation-based method for\nhandling the $Z$ process. This approach enables improved management of the\nLipschitz continuity of decoupling fields, facilitating the well-posedness of\nthe discretized FBSDE system with fully coupled drift. We rigorously prove the\nconvergence of our Markovian iteration method in this more complex setting.\nFinally, numerical experiments confirm our theoretical insights, showcasing the\neffectiveness and accuracy of the proposed methodology.", "published": "2025-04-03 17:56:36", "link": "http://arxiv.org/abs/2504.02814v1", "categories": ["math.NA", "cs.NA", "math.PR", "q-fin.CP"], "primary_category": "math.NA"}
{"title": "Phase transitions for interacting particle systems on random graphs", "abstract": "In this paper, we study weakly interacting diffusion processes on random\ngraphs. Our main focus is on the properties of the mean-field limit and, in\nparticular, on the nonuniqueness of stationary states. By extending classical\nbifurcation analysis to include multichromatic interaction potentials and\nrandom graph structures, we explicitly identify bifurcation points and relate\nthem to the eigenvalues of the graphon integral operator. Furthermore, we\ncharacterize the resulting McKean-Vlasov PDE as a gradient flow with respect to\na suitable metric. We combine these theoretical results with the spectral\nanalysis of the linearized McKean-Vlasov operator and extensive numerical\nsimulations to gain insight into the stability and long-term behaviour of\nstationary solutions. In addition, we provide strong evidence that (minus) the\ninteraction energy of the interacting particle system serves as a natural order\nparameter. In particular, beyond the transition point and for multichromatic\ninteractions, we observe an energy cascade that is strongly linked to the\ndynamical metastability of the system.", "published": "2025-04-03 16:04:23", "link": "http://arxiv.org/abs/2504.02721v1", "categories": ["math.DS", "cs.NA", "math-ph", "math.MP", "math.NA", "math.PR"], "primary_category": "math.DS"}
{"title": "Centroidal Voronoi Tessellations as Electrostatic Equilibria: A Generalized Thomson Problem in Convex Domains", "abstract": "We present a variational framework in which Centroidal Voronoi Tessellations\n(CVTs) arise as local minimizers of a generalized electrostatic energy\nfunctional. By modeling interior point distributions in a convex domain as\nrepelling charges balanced against a continuous boundary charge, we show that\nthe resulting equilibrium configurations converge to CVT structures. We prove\nthis by showing that CVTs minimize both the classical centroidal energy and the\nelectrostatic potential, establishing a connection between geometric\nquantization and potential theory. Finally, we introduce a thermodynamic\nannealing scheme for global CVT optimization, rooted in Boltzmann statistics\nand random walk dynamics. By introducing a scheme for varying time steps\n(faster or slower cooling) we show that the set of minima of the centroid\nenergy functional (and therefore the electrostatic potential) can be recovered.\nBy recovering a set of generator locations corresponding to each minimum we can\ncreate a lattice continuation that allows for a customizable framework for\nindividual minimum seeking.", "published": "2025-04-03 15:36:15", "link": "http://arxiv.org/abs/2504.02700v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MG", "math.MP", "math.OC", "49Q10, 65K10, 52C35, 78A30, 49M30, 35J20"], "primary_category": "math.NA"}
{"title": "Certified Model Order Reduction for parametric Hermitian eigenproblems", "abstract": "This article deals with the efficient and certified numerical approximation\nof the smallest eigenvalue and the associated eigenspace of a large-scale\nparametric Hermitian matrix. For this aim, we rely on projection-based model\norder reduction (MOR), i.e., we approximate the large-scale problem by\nprojecting it onto a suitable subspace and reducing it to one of a much smaller\ndimension. Such a subspace is constructed by means of weak greedy-type\nstrategies. After detailing the connections with the reduced basis method for\nsource problems, we introduce a novel error estimate for the approximation\nerror related to the eigenspace associated with the smallest eigenvalue. Since\nthe difference between the second smallest and the smallest eigenvalue, the\nso-called spectral gap, is crucial for the reliability of the error estimate,\nwe propose efficiently computable upper and lower bounds for higher eigenvalues\nand for the spectral gap, which enable the assembly of a subspace for the MOR\napproximation of the spectral gap. Based on that, a second subspace is then\ngenerated for the MOR approximation of the eigenspace associated with the\nsmallest eigenvalue. We also provide efficiently computable conditions to\nensure that the multiplicity of the smallest eigenvalue is fully captured in\nthe reduced space. This work is motivated by a specific application: the\nrepeated identifications of the states with minimal energy, the so-called\nground states, of parametric quantum spin system models.", "published": "2025-04-03 15:14:08", "link": "http://arxiv.org/abs/2504.02672v1", "categories": ["math.NA", "cs.NA", "41A63, 65F15, 65N25, 65F30, 65F50, 65K10, 81P68"], "primary_category": "math.NA"}
{"title": "An efficient and energy-stable IMEX splitting scheme for dispersed multiphase flows", "abstract": "Volume-averaged Navier--Stokes equations are used in various applications to\nmodel systems with two or more interpenetrating phases. Each fluid obeys its\nown momentum and mass equations, and the phases are typically coupled via drag\nforces and a shared pressure. Monolithic solvers can therefore be very\nexpensive and difficult to implement. On the other hand, designing robust\nsplitting schemes requires making both pressure and drag forces explicit\nwithout sacrificing temporal stability. In this context, we derive a new\nfirst-order pressure-correction method based on the incompressibility of the\nmean velocity field, combined with an explicit treatment of the drag forces.\nFurthermore, the convective terms are linearised using extrapolated velocities,\nwhile the viscous terms are treated semi-implicitly. This gives us an\nimplicit-explicit (IMEX) method that is very robust not only due to its\nunconditional energy stability, but also because it does not require any type\nof fixed-point iterations. Each time step involves only linear, scalar\ntransport equations and a single Poisson problem as building blocks, thereby\noffering both efficiency and simplicity. We rigorously prove temporal stability\nwithout any time-step size restrictions, and the theory is confirmed through\ntwo-phase numerical examples.", "published": "2025-04-03 14:27:53", "link": "http://arxiv.org/abs/2504.02629v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Adaptive Bivariate Quarklet Tree Approximation via Anisotropic Tensor Quarklets", "abstract": "This paper deals with near-best approximation of a given bivariate function\nusing elements of quarkonial tensor frames. For that purpose we apply\nanisotropic tensor products of the univariate B-spline quarklets introduced\naround 2017 by Dahlke, Keding and Raasch. We introduce the concept of bivariate\nquarklet trees and develop an adaptive algorithm which allows for generalized\nhp-approximation of a given bivariate function by selected frame elements. It\nis proved that this algorithm is near-best, which means that as long as some\nstandard conditions concerning local errors are fulfilled it provides an\napproximation with an error close to that one of the best possible quarklet\ntree approximation. For this algorithm the complexity is investigated.\nMoreover, we use our techniques to approximate a bivariate test function with\ninverse-exponential rates of convergence. It can be expected that the results\npresented in this paper serve as important building block for the design of\nadaptive wavelet-hp-methods for solving PDEs in the bivariate setting with very\ngood convergence properties.", "published": "2025-04-03 11:55:32", "link": "http://arxiv.org/abs/2504.02513v1", "categories": ["math.NA", "cs.NA", "math.FA", "41A15, 42C40, 65D15, 65T60"], "primary_category": "math.NA"}
{"title": "Heat Conduction with Phase Change in Permafrost Modules of Vegetation Models", "abstract": "We consider the problem of heat conduction with phase change, that is\nessential for permafrost modeling in Land Surface Models and Dynamic Global\nVegetation Models. These models require minimal computational effort and an\nextremely robust solver for large-scale, long-term simulations. The weak\nenthalpy formulation of the Stefan problem is used as the mathematical model\nand a finite element method is employed for the discretization. Leveraging the\npiecewise affine structure of the nonlinear time-stepping equation system, we\ndemonstrate that this system has a unique solution and provide a solver that is\nguaranteed to find this solution in a finite number of steps from any initial\nguess. Comparisons with the Neumann analytical solution and tests in the\nLund-Potsdam-Jena managed Land vegetation model reveal that the new method does\nnot introduce significantly higher computational costs than the widely used\nDECP method while providing greater accuracy. In particular, it avoids a known\nnonphysical artifact in the solution.", "published": "2025-04-03 10:52:35", "link": "http://arxiv.org/abs/2504.02475v1", "categories": ["math.NA", "cs.NA", "65M60, 65M22"], "primary_category": "math.NA"}
{"title": "Robust Randomized Low-Rank Approximation with Row-Wise Outlier Detection", "abstract": "Robust low-rank approximation under row-wise adversarial corruption can be\nachieved with a single pass, randomized procedure that detects and removes\noutlier rows by thresholding their projected norms. We propose a scalable,\nnon-iterative algorithm that efficiently recovers the underlying low-rank\nstructure in the presence of row-wise adversarial corruption. By first\ncompressing the data with a Johnson Lindenstrauss projection, our approach\npreserves the geometry of clean rows while dramatically reducing\ndimensionality. Robust statistical techniques based on the median and median\nabsolute deviation then enable precise identification and removal of outlier\nrows with abnormally high norms. The subsequent rank-k approximation achieves\nnear-optimal error bounds with a one pass procedure that scales linearly with\nthe number of observations. Empirical results confirm that combining random\nsketches with robust statistics yields efficient, accurate decompositions even\nin the presence of large fractions of corrupted rows.", "published": "2025-04-03 09:43:27", "link": "http://arxiv.org/abs/2504.02432v1", "categories": ["cs.LG", "cs.NA", "math.NA", "65F30, 62G35", "G.1.2; G.2.2"], "primary_category": "cs.LG"}
{"title": "Traffic Flow Data Completion and Anomaly Diagnosis via Sparse and Low-Rank Tensor Optimization", "abstract": "Spatiotemporal traffic time series, such as traffic speed data, collected\nfrom sensing systems are often incomplete, with considerable corruption and\nlarge amounts of missing values. A vast amount of data conceals implicit data\nstructures, which poses significant challenges for data recovery issues, such\nas mining the potential spatio-temporal correlations of data and identifying\nabnormal data. In this paper, we propose a Tucker decomposition-based sparse\nlow-rank high-order tensor optimization model (TSLTO) for data imputation and\nanomaly diagnosis. We decompose the traffic tensor data into low-rank and\nsparse tensors, and establish a sparse low-rank high-order tensor optimization\nmodel based on Tucker decomposition. By utilizing tools of non-smooth analysis\nfor tensor functions, we explore the optimality conditions of the proposed\ntensor optimization model and design an ADMM optimization algorithm for solving\nthe model. Finally, numerical experiments are conducted on both synthetic data\nand a real-world dataset: the urban traffic speed dataset of Guangzhou.\nNumerical comparisons with several representative existing algorithms\ndemonstrate that our proposed approach achieves higher accuracy and efficiency\nin traffic flow data recovery and anomaly diagnosis tasks.", "published": "2025-04-03 03:21:30", "link": "http://arxiv.org/abs/2504.02245v1", "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "Stochastic positivity-preserving symplectic splitting methods for stochastic Lotka--Volterra predator-prey model", "abstract": "In this paper, we present two stochastic positive-preserving symplectic\nmethods for the stochastic Lotka-Volterra predator-prey model driven by a\nmultiplicative noise. To inherit the intrinsic characteristic of the original\nsystem, the stochastic Lie--Trotter splitting method and the stochastic Strang\nsplitting method are introduced, which are proved to preserve the positivity of\nthe numerical solution and possess the discrete stochastic symplectic\nconservation law as well. By deriving the uniform boundedness of the $p$-th\nmoment of the numerical solution, we prove that the strong convergence orders\nof these two methods are both one in the $L^2(\\Omega)$-norm. Finally, we\nvalidate the theoretical results through two and four dimensional numerical\nexamples.", "published": "2025-04-03 02:49:40", "link": "http://arxiv.org/abs/2504.02228v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Error analysis of the diffuse domain finite element method for second order parabolic equations", "abstract": "In this paper, we analyze the diffuse domain finite element method (DDFE) to\nsolve a class of second-order parabolic partial differential equations defined\nin general irregular domains. The proposed method first applies the diffuse\ndomain method (DDM) with a phase-field function to extend the target parabolic\nequation to a similar problem defined over a larger rectangular domain that\ncontains the original physical domain. The transformed equation is then\ndiscretized by using the finite element method with continuous piecewise\nmultilinear basis functions in space and the BDF2 scheme in time to produce a\nfully discrete numerical scheme. Based on the weighted Sobolev spaces, we prove\nthe convergence of the DDM solution to the original solution as the interface\nthickness parameter goes to zero, with the corresponding approximation errors\nunder the $L^2$ and $H^1$ norms. Furthermore, the optimal error estimate for\nthe fully discrete DDFE scheme is also obtained under the $H^1$ norm. Various\nnumerical experiments are finally carried out to validate the theoretical\nresults and demonstrate the performance of the proposed method.", "published": "2025-04-03 02:48:16", "link": "http://arxiv.org/abs/2504.02226v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Error Analysis of Sampling Algorithms for Approximating Stochastic Optimal Control", "abstract": "This paper is concerned with the error analysis of two types of sampling\nalgorithms, namely model predictive path integral (MPPI) and an interacting\nparticle system (\\IPS) algorithm, that have been proposed in the literature for\nnumerical approximation of the stochastic optimal control. The analysis is\npresented through the lens of Gibbs variational principle. For an illustrative\nexample of a single-stage stochastic optimal control problem, analytical\nexpressions for approximation error and scaling laws, with respect to the state\ndimension and sample size, are derived. The analytical results are illustrated\nwith numerical simulations.", "published": "2025-04-03 00:48:19", "link": "http://arxiv.org/abs/2504.02198v1", "categories": ["eess.SY", "cs.NA", "cs.SY", "math.NA", "math.OC"], "primary_category": "eess.SY"}
{"title": "Online Multivariate Regularized Distributional Regression for High-dimensional Probabilistic Electricity Price Forecasting", "abstract": "Probabilistic electricity price forecasting (PEPF) is a key task for market\nparticipants in short-term electricity markets. The increasing availability of\nhigh-frequency data and the need for real-time decision-making in energy\nmarkets require online estimation methods for efficient model updating. We\npresent an online, multivariate, regularized distributional regression model,\nallowing for the modeling of all distribution parameters conditional on\nexplanatory variables. Our approach is based on the combination of the\nmultivariate distributional regression and an efficient online learning\nalgorithm based on online coordinate descent for LASSO-type regularization.\nAdditionally, we propose to regularize the estimation along a path of\nincreasingly complex dependence structures of the multivariate distribution,\nallowing for parsimonious estimation and early stopping. We validate our\napproach through one of the first forecasting studies focusing on multivariate\nprobabilistic forecasting in the German day-ahead electricity market while\nusing only online estimation methods. We compare our approach to online\nLASSO-ARX-models with adaptive marginal distribution and to online univariate\ndistributional models combined with an adaptive Copula. We show that the\nmultivariate distributional regression, which allows modeling all distribution\nparameters - including the mean and the dependence structure - conditional on\nexplanatory variables such as renewable in-feed or past prices provide superior\nforecasting performance compared to modeling of the marginals only and keeping\na static/unconditional dependence structure. Additionally, online estimation\nyields a speed-up by a factor of 80 to over 400 times compared to batch\nfitting.", "published": "2025-04-03 12:08:51", "link": "http://arxiv.org/abs/2504.02518v1", "categories": ["stat.ML", "econ.EM", "q-fin.ST", "stat.AP", "stat.CO"], "primary_category": "stat.ML"}
{"title": "High-dimensional ridge regression with random features for non-identically distributed data with a variance profile", "abstract": "The behavior of the random feature model in the high-dimensional regression\nframework has become a popular issue of interest in the machine learning\nliterature}. This model is generally considered for feature vectors $x_i =\n\\Sigma^{1/2} x_i'$, where $x_i'$ is a random vector made of independent and\nidentically distributed (iid) entries, and $\\Sigma$ is a positive definite\nmatrix representing the covariance of the features.\n  In this paper, we move beyond {\\CB this standard assumption by studying the\nperformances of the random features model in the setting of non-iid feature\nvectors}. Our approach is related to the analysis of the spectrum of large\nrandom matrices through random matrix theory (RMT) {\\CB and free probability}\nresults. We turn to the analysis of non-iid data by using the notion of\nvariance profile {\\CB which} is {\\CB well studied in RMT.} Our main\ncontribution is then the study of the limits of the training and {\\CB\nprediction} risks associated to the ridge estimator in the random features\nmodel when its dimensions grow. We provide asymptotic equivalents of these\nrisks that capture the behavior of ridge regression with random features in a\n{\\CB high-dimensional} framework. These asymptotic equivalents, {\\CB which\nprove to be sharp in numerical experiments}, are retrieved by adapting, to our\nsetting, established results from operator-valued free probability theory.\nMoreover, {\\CB for various classes of random feature vectors that have not been\nconsidered so far in the literature}, our approach allows to show the\nappearance of the double descent phenomenon when the ridge regularization\nparameter is small enough.", "published": "2025-04-03 21:20:08", "link": "http://arxiv.org/abs/2504.03035v1", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.ME", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Computing High-dimensional Confidence Sets for Arbitrary Distributions", "abstract": "We study the problem of learning a high-density region of an arbitrary\ndistribution over $\\mathbb{R}^d$. Given a target coverage parameter $\\delta$,\nand sample access to an arbitrary distribution $D$, we want to output a\nconfidence set $S \\subset \\mathbb{R}^d$ such that $S$ achieves $\\delta$\ncoverage of $D$, i.e., $\\mathbb{P}_{y \\sim D} \\left[ y \\in S \\right] \\ge\n\\delta$, and the volume of $S$ is as small as possible. This is a central\nproblem in high-dimensional statistics with applications in finding confidence\nsets, uncertainty quantification, and support estimation.\n  In the most general setting, this problem is statistically intractable, so we\nrestrict our attention to competing with sets from a concept class $C$ with\nbounded VC-dimension. An algorithm is competitive with class $C$ if, given\nsamples from an arbitrary distribution $D$, it outputs in polynomial time a set\nthat achieves $\\delta$ coverage of $D$, and whose volume is competitive with\nthe smallest set in $C$ with the required coverage $\\delta$. This problem is\ncomputationally challenging even in the basic setting when $C$ is the set of\nall Euclidean balls. Existing algorithms based on coresets find in polynomial\ntime a ball whose volume is $\\exp(\\tilde{O}( d/ \\log d))$-factor competitive\nwith the volume of the best ball.\n  Our main result is an algorithm that finds a confidence set whose volume is\n$\\exp(\\tilde{O}(d^{2/3}))$ factor competitive with the optimal ball having the\ndesired coverage. The algorithm is improper (it outputs an ellipsoid). Combined\nwith our computational intractability result for proper learning balls within\nan $\\exp(\\tilde{O}(d^{1-o(1)}))$ approximation factor in volume, our results\nprovide an interesting separation between proper and (improper) learning of\nconfidence sets.", "published": "2025-04-03 16:05:10", "link": "http://arxiv.org/abs/2504.02723v1", "categories": ["cs.DS", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.DS"}
{"title": "ConfEviSurrogate: A Conformalized Evidential Surrogate Model for Uncertainty Quantification", "abstract": "Surrogate models, crucial for approximating complex simulation data across\nsciences, inherently carry uncertainties that range from simulation noise to\nmodel prediction errors. Without rigorous uncertainty quantification,\npredictions become unreliable and hence hinder analysis. While methods like\nMonte Carlo dropout and ensemble models exist, they are often costly, fail to\nisolate uncertainty types, and lack guaranteed coverage in prediction\nintervals. To address this, we introduce ConfEviSurrogate, a novel\nConformalized Evidential Surrogate Model that can efficiently learn high-order\nevidential distributions, directly predict simulation outcomes, separate\nuncertainty sources, and provide prediction intervals. A conformal\nprediction-based calibration step further enhances interval reliability to\nensure coverage and improve efficiency. Our ConfEviSurrogate demonstrates\naccurate predictions and robust uncertainty estimates in diverse simulations,\nincluding cosmology, ocean dynamics, and fluid dynamics.", "published": "2025-04-03 15:44:14", "link": "http://arxiv.org/abs/2504.02919v1", "categories": ["stat.ML", "cs.GR", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Semiparametric Counterfactual Regression", "abstract": "We study counterfactual regression, which aims to map input features to\noutcomes under hypothetical scenarios that differ from those observed in the\ndata. This is particularly useful for decision-making when adapting to sudden\nshifts in treatment patterns is essential. We propose a doubly robust-style\nestimator for counterfactual regression within a generalizable framework that\naccommodates a broad class of risk functions and flexible constraints, drawing\non tools from semiparametric theory and stochastic optimization. Our approach\nuses incremental interventions to enhance adaptability while maintaining\nconsistency with standard methods. We formulate the target estimand as the\noptimal solution to a stochastic optimization problem and develop an efficient\nestimation strategy, where we can leverage rapid development of modern\noptimization algorithms. We go on to analyze the rates of convergence and\ncharacterize the asymptotic distributions. Our analysis shows that the proposed\nestimators can achieve $\\sqrt{n}$-consistency and asymptotic normality for a\nbroad class of problems. Numerical illustrations highlight their effectiveness\nin adapting to unseen counterfactual scenarios while maintaining parametric\nconvergence rates.", "published": "2025-04-03 15:32:26", "link": "http://arxiv.org/abs/2504.02694v2", "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Incorporating the ChEES Criterion into Sequential Monte Carlo Samplers", "abstract": "Markov chain Monte Carlo (MCMC) methods are a powerful but computationally\nexpensive way of performing non-parametric Bayesian inference. MCMC proposals\nwhich utilise gradients, such as Hamiltonian Monte Carlo (HMC), can better\nexplore the parameter space of interest if the additional hyper-parameters are\nchosen well. The No-U-Turn Sampler (NUTS) is a variant of HMC which is\nextremely effective at selecting these hyper-parameters but is slow to run and\nis not suited to GPU architectures. An alternative to NUTS, Change in the\nEstimator of the Expected Square HMC (ChEES-HMC) was shown not only to run\nfaster than NUTS on GPU but also sample from posteriors more efficiently.\nSequential Monte Carlo (SMC) samplers are another sampling method which instead\noutput weighted samples from the posterior. They are very amenable to\nparallelisation and therefore being run on GPUs while having additional\nflexibility in their choice of proposal over MCMC. We incorporate (ChEEs-HMC)\nas a proposal into SMC samplers and demonstrate competitive but faster\nperformance than NUTS on a number of tasks.", "published": "2025-04-03 14:25:19", "link": "http://arxiv.org/abs/2504.02627v1", "categories": ["stat.CO", "cs.LG", "cs.SY", "eess.SY", "stat.ML"], "primary_category": "stat.CO"}
{"title": "Variational Online Mirror Descent for Robust Learning in Schr\u00f6dinger Bridge", "abstract": "Sch\\\"odinger bridge (SB) has evolved into a universal class of probabilistic\ngenerative models. In practice, however, estimated learning signals are often\nuncertain, and the reliability promised by existing methods is often based on\nspeculative optimal-case scenarios. Recent studies regarding the Sinkhorn\nalgorithm through mirror descent (MD) have gained attention, revealing\ngeometric insights into solution acquisition of the SB problems. In this paper,\nwe propose a variational online MD (OMD) framework for the SB problems, which\nprovides further stability to SB solvers. We formally prove convergence and a\nregret bound for the novel OMD formulation of SB acquisition. As a result, we\npropose a simulation-free SB algorithm called Variational Mirrored\nSchr\\\"odinger Bridge (VMSB) by utilizing the Wasserstein-Fisher-Rao geometry of\nthe Gaussian mixture parameterization for Schr\\\"odinger potentials. Based on\nthe Wasserstein gradient flow theory, the algorithm offers tractable learning\ndynamics that precisely approximate each OMD step. In experiments, we validate\nthe performance of the proposed VMSB algorithm across an extensive suite of\nbenchmarks. VMSB consistently outperforms contemporary SB solvers on a range of\nSB problems, demonstrating the robustness predicted by our theory.", "published": "2025-04-03 14:18:47", "link": "http://arxiv.org/abs/2504.02618v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Analytical Discovery of Manifold with Machine Learning", "abstract": "Understanding low-dimensional structures within high-dimensional data is\ncrucial for visualization, interpretation, and denoising in complex datasets.\nDespite the advancements in manifold learning techniques, key challenges-such\nas limited global insight and the lack of interpretable analytical\ndescriptions-remain unresolved. In this work, we introduce a novel framework,\nGAMLA (Global Analytical Manifold Learning using Auto-encoding). GAMLA employs\na two-round training process within an auto-encoding framework to derive both\ncharacter and complementary representations for the underlying manifold. With\nthe character representation, the manifold is represented by a parametric\nfunction which unfold the manifold to provide a global coordinate. While with\nthe complementary representation, an approximate explicit manifold description\nis developed, offering a global and analytical representation of smooth\nmanifolds underlying high-dimensional datasets. This enables the analytical\nderivation of geometric properties such as curvature and normal vectors.\nMoreover, we find the two representations together decompose the whole latent\nspace and can thus characterize the local spatial structure surrounding the\nmanifold, proving particularly effective in anomaly detection and\ncategorization. Through extensive experiments on benchmark datasets and\nreal-world applications, GAMLA demonstrates its ability to achieve\ncomputational efficiency and interpretability while providing precise geometric\nand structural insights. This framework bridges the gap between data-driven\nmanifold learning and analytical geometry, presenting a versatile tool for\nexploring the intrinsic properties of complex data sets.", "published": "2025-04-03 11:53:00", "link": "http://arxiv.org/abs/2504.02511v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Bridging the Theoretical Gap in Randomized Smoothing", "abstract": "Randomized smoothing has become a leading approach for certifying adversarial\nrobustness in machine learning models. However, a persistent gap remains\nbetween theoretical certified robustness and empirical robustness accuracy.\nThis paper introduces a new framework that bridges this gap by leveraging\nLipschitz continuity for certification and proposing a novel, less conservative\nmethod for computing confidence intervals in randomized smoothing. Our approach\ntightens the bounds of certified robustness, offering a more accurate\nreflection of model robustness in practice. Through rigorous experimentation we\nshow that our method improves the robust accuracy, compressing the gap between\nempirical findings and previous theoretical results. We argue that\ninvestigating local Lipschitz constants and designing ad-hoc confidence\nintervals can further enhance the performance of randomized smoothing. These\nresults pave the way for a deeper understanding of the relationship between\nLipschitz continuity and certified robustness.", "published": "2025-04-03 09:05:49", "link": "http://arxiv.org/abs/2504.02412v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Dynamic Assortment Selection and Pricing with Censored Preference Feedback", "abstract": "In this study, we investigate the problem of dynamic multi-product selection\nand pricing by introducing a novel framework based on a \\textit{censored\nmultinomial logit} (C-MNL) choice model. In this model, sellers present a set\nof products with prices, and buyers filter out products priced above their\nvaluation, purchasing at most one product from the remaining options based on\ntheir preferences. The goal is to maximize seller revenue by dynamically\nadjusting product offerings and prices, while learning both product valuations\nand buyer preferences through purchase feedback. To achieve this, we propose a\nLower Confidence Bound (LCB) pricing strategy. By combining this pricing\nstrategy with either an Upper Confidence Bound (UCB) or Thompson Sampling (TS)\nproduct selection approach, our algorithms achieve regret bounds of\n$\\tilde{O}(d^{\\frac{3}{2}}\\sqrt{T/\\kappa})$ and\n$\\tilde{O}(d^{2}\\sqrt{T/\\kappa})$, respectively. Finally, we validate the\nperformance of our methods through simulations, demonstrating their\neffectiveness.", "published": "2025-04-03 06:56:08", "link": "http://arxiv.org/abs/2504.02324v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Comparative Analysis of Deepfake Detection Models: New Approaches and Perspectives", "abstract": "The growing threat posed by deepfake videos, capable of manipulating\nrealities and disseminating misinformation, drives the urgent need for\neffective detection methods. This work investigates and compares different\napproaches for identifying deepfakes, focusing on the GenConViT model and its\nperformance relative to other architectures present in the DeepfakeBenchmark.\nTo contextualize the research, the social and legal impacts of deepfakes are\naddressed, as well as the technical fundamentals of their creation and\ndetection, including digital image processing, machine learning, and artificial\nneural networks, with emphasis on Convolutional Neural Networks (CNNs),\nGenerative Adversarial Networks (GANs), and Transformers. The performance\nevaluation of the models was conducted using relevant metrics and new datasets\nestablished in the literature, such as WildDeep-fake and DeepSpeak, aiming to\nidentify the most effective tools in the battle against misinformation and\nmedia manipulation. The obtained results indicated that GenConViT, after\nfine-tuning, exhibited superior performance in terms of accuracy (93.82%) and\ngeneralization capacity, surpassing other architectures in the\nDeepfakeBenchmark on the DeepSpeak dataset. This study contributes to the\nadvancement of deepfake detection techniques, offering contributions to the\ndevelopment of more robust and effective solutions against the dissemination of\nfalse information.", "published": "2025-04-03 02:10:27", "link": "http://arxiv.org/abs/2504.02900v1", "categories": ["cs.CV", "cs.LG", "stat.CO", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Generating Diverse Audio-Visual 360 Soundscapes for Sound Event Localization and Detection", "abstract": "We present SELDVisualSynth, a tool for generating synthetic videos for\naudio-visual sound event localization and detection (SELD). Our approach\nincorporates real-world background images to improve realism in synthetic\naudio-visual SELD data while also ensuring audio-visual spatial alignment. The\ntool creates 360 synthetic videos where objects move matching synthetic SELD\naudio data and its annotations. Experimental results demonstrate that a model\ntrained with this data attains performance gains across multiple metrics,\nachieving superior localization recall (56.4 LR) and competitive localization\nerror (21.9deg LE). We open-source our data generation tool for maximal use by\nmembers of the SELD research community.", "published": "2025-04-03 19:27:43", "link": "http://arxiv.org/abs/2504.02988v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "F5R-TTS: Improving Flow Matching based Text-to-Speech with Group Relative Policy Optimization", "abstract": "We present F5R-TTS, a novel text-to-speech (TTS) system that integrates\nGradient Reward Policy Optimization (GRPO) into a flow-matching based\narchitecture. By reformulating the deterministic outputs of flow-matching TTS\ninto probabilistic Gaussian distributions, our approach enables seamless\nintegration of reinforcement learning algorithms. During pretraining, we train\na probabilistically reformulated flow-matching based model which is derived\nfrom F5-TTS with an open-source dataset. In the subsequent reinforcement\nlearning (RL) phase, we employ a GRPO-driven enhancement stage that leverages\ndual reward metrics: word error rate (WER) computed via automatic speech\nrecognition and speaker similarity (SIM) assessed by verification models.\nExperimental results on zero-shot voice cloning demonstrate that F5R-TTS\nachieves significant improvements in both speech intelligibility (relatively\n29.5\\% WER reduction) and speaker similarity (relatively 4.6\\% SIM score\nincrease) compared to conventional flow-matching based TTS systems. Audio\nsamples are available at https://frontierlabs.github.io/F5R.", "published": "2025-04-03 08:57:15", "link": "http://arxiv.org/abs/2504.02407v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VoiceCraft-Dub: Automated Video Dubbing with Neural Codec Language Models", "abstract": "We present VoiceCraft-Dub, a novel approach for automated video dubbing that\nsynthesizes high-quality speech from text and facial cues. This task has broad\napplications in filmmaking, multimedia creation, and assisting voice-impaired\nindividuals. Building on the success of Neural Codec Language Models (NCLMs)\nfor speech synthesis, our method extends their capabilities by incorporating\nvideo features, ensuring that synthesized speech is time-synchronized and\nexpressively aligned with facial movements while preserving natural prosody. To\ninject visual cues, we design adapters to align facial features with the NCLM\ntoken space and introduce audio-visual fusion layers to merge audio-visual\ninformation within the NCLM framework. Additionally, we curate CelebV-Dub, a\nnew dataset of expressive, real-world videos specifically designed for\nautomated video dubbing. Extensive experiments show that our model achieves\nhigh-quality, intelligible, and natural speech synthesis with accurate lip\nsynchronization, outperforming existing methods in human perception and\nperforming favorably in objective evaluations. We also adapt VoiceCraft-Dub for\nthe video-to-speech task, demonstrating its versatility for various\napplications.", "published": "2025-04-03 08:24:47", "link": "http://arxiv.org/abs/2504.02386v1", "categories": ["cs.CV", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Causal Self-supervised Pretrained Frontend with Predictive Code for Speech Separation", "abstract": "Speech separation (SS) seeks to disentangle a multi-talker speech mixture\ninto single-talker speech streams. Although SS can be generally achieved using\noffline methods, such a processing paradigm is not suitable for real-time\nstreaming applications. Causal separation models, which rely only on past and\npresent information, offer a promising solution for real-time streaming.\nHowever, these models typically suffer from notable performance degradation due\nto the absence of future context. In this paper, we introduce a novel frontend\nthat is designed to mitigate the mismatch between training and run-time\ninference by implicitly incorporating future information into causal models\nthrough predictive patterns. The pretrained frontend employs a transformer\ndecoder network with a causal convolutional encoder as the backbone and is\npretrained in a self-supervised manner with two innovative pretext tasks:\nautoregressive hybrid prediction and contextual knowledge distillation. These\ntasks enable the model to capture predictive patterns directly from mixtures in\na self-supervised manner. The pretrained frontend subsequently serves as a\nfeature extractor to generate high-quality predictive patterns. Comprehensive\nevaluations on synthetic and real-world datasets validated the effectiveness of\nthe proposed pretrained frontend.", "published": "2025-04-03 06:18:30", "link": "http://arxiv.org/abs/2504.02302v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Detecting Plant VOC Traces Using Indoor Air Quality Sensors", "abstract": "In the era of growing interest in healthy buildings and smart homes, the\nimportance of sustainable, health conscious indoor environments is paramount.\nSmart tools, especially VOC sensors, are crucial for monitoring indoor air\nquality, yet interpreting signals from various VOC sources remains challenging.\nA promising approach involves understanding how indoor plants respond to\nenvironmental conditions. Plants produce terpenes, a type of VOC, when exposed\nto abiotic and biotic stressors - including pathogens, predators, light, and\ntemperature - offering a novel pathway for monitoring indoor air quality. While\nprior work often relies on specialized laboratory sensors, our research\nleverages readily available commercial sensors to detect and classify plant\nemitted VOCs that signify changes in indoor conditions. We quantified the\nsensitivity of these sensors by measuring 16 terpenes in controlled\nexperiments, then identified and tested the most promising terpenes in\nrealistic environments. We also examined physics based models to map VOC\nresponses but found them lacking for real world complexity. Consequently, we\ntrained machine learning models to classify terpenes using commercial sensors\nand identified optimal sensor placement. To validate this approach, we analyzed\nemissions from a living basil plant, successfully detecting terpene output. Our\nfindings establish a foundation for overcoming challenges in plant VOC\ndetection, paving the way for advanced plant based sensors to enhance indoor\nenvironmental quality in future smart buildings.", "published": "2025-04-03 16:18:35", "link": "http://arxiv.org/abs/2504.03785v1", "categories": ["eess.SP", "cs.CE", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Handover and SINR-Aware Path Optimization in 5G-UAV mmWave Communication using DRL", "abstract": "Path planning and optimization for unmanned aerial vehicles (UAVs)-assisted\nnext-generation wireless networks is critical for mobility management and\nensuring UAV safety and ubiquitous connectivity, especially in dense urban\nenvironments with street canyons and tall buildings. Traditional statistical\nand model-based techniques have been successfully used for path optimization in\ncommunication networks. However, when dynamic channel propagation\ncharacteristics such as line-of-sight (LOS), interference, handover, and\nsignal-to-interference and noise ratio (SINR) are included in path\noptimization, statistical and model-based path planning solutions become\nobsolete since they cannot adapt to the dynamic and time-varying wireless\nchannels, especially in the mmWave bands. In this paper, we propose a novel\nmodel-free actor-critic deep reinforcement learning (AC-DRL) framework for path\noptimization in UAV-assisted 5G mmWave wireless networks, which combines four\nimportant aspects of UAV communication: \\textit{flight time, handover,\nconnectivity and SINR}. We train an AC-RL agent that enables a UAV connected to\na gNB to determine the optimal path to a desired destination in the shortest\npossible time with minimal gNB handover, while maintaining connectivity and the\nhighest possible SINR. We train our model with data from a powerful ray tracing\ntool called Wireless InSite, which uses 3D images of the propagation\nenvironment and provides data that closely resembles the real propagation\nenvironment. The simulation results show that our system has superior\nperformance in tracking high SINR compared to other selected RL algorithms.", "published": "2025-04-03 15:28:04", "link": "http://arxiv.org/abs/2504.02688v1", "categories": ["cs.NI", "cs.LG", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Utilizing 5G NR SSB Blocks for Passive Detection and Localization of Low-Altitude Drones", "abstract": "With the exponential growth of the unmanned aerial vehicle (UAV) industry and\na broad range of applications expected to appear in the coming years, the\nemployment of traditional radar systems is becoming increasingly cumbersome for\nUAV supervision. Motivated by this emerging challenge, this paper investigates\nthe feasibility of employing integrated sensing and communication (ISAC)\nsystems implemented over current and future wireless networks to perform this\ntask. We propose a sensing mechanism based on the synchronization signal block\n(SSB) in the fifth-generation (5G) standard that performs sensing in a passive\nbistatic setting. By assuming planar arrays at the sensing nodes and according\nto the 5G standard, we consider that the SSB signal is sent in a grid of\northogonal beams that are multiplexed in time, with some of them pointing\ntoward a surveillance region where low-altitude drones can be flying. The\nCramer-Rao Bound (CRB) is derived as the theoretical bound for range and\nvelocity estimation. Our results demonstrate the potential of employing SSB\nsignals for UAV-like target localization at low SNR.", "published": "2025-04-03 14:36:11", "link": "http://arxiv.org/abs/2504.02641v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "UAV-Assisted 5G Networks: Mobility-Aware 3D Trajectory Optimization and Resource Allocation for Dynamic Environments", "abstract": "This paper proposes a framework for robust design of UAV-assisted wireless\nnetworks that combine 3D trajectory optimization with user mobility prediction\nto address dynamic resource allocation challenges. We proposed a sparse\nsecond-order prediction model for real-time user tracking coupled with\nheuristic user clustering to balance service quality and computational\ncomplexity. The joint optimization problem is formulated to maximize the\nminimum rate. It is then decomposed into user association, 3D trajectory\ndesign, and resource allocation subproblems, which are solved iteratively via\nsuccessive convex approximation (SCA). Extensive simulations demonstrate: (1)\nnear-optimal performance with $\\epsilon \\approx 0.67\\%$ deviation from\nupper-bound solutions, (2) $16\\%$ higher minimum rates for distant users\ncompared to non-predictive 3D designs, and (3) $10-30\\%$ faster outage\nmitigation than time-division benchmarks. The framework's adaptive speed\ncontrol enables precise mobile user tracking while maintaining energy\nefficiency under constrained flight time. Results demonstrate superior\nrobustness in edge-coverage scenarios, making it particularly suitable for\n$5G/6G$ networks.", "published": "2025-04-03 14:12:58", "link": "http://arxiv.org/abs/2504.02613v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Ambiguity Function Analysis of Affine Frequency Division Multiplexing for Integrated Sensing and Communication", "abstract": "Affine frequency division multiplexing (AFDM) is a chirp-based multicarrier\nwaveform that was recently proposed for communication over doubly dispersive\nchannels. Given its chirp nature, AFDM is expected to have superior sensing\ncapabilities compared to orthogonal frequency division multiplexing (OFDM) and\nis thus a promising candidate for integrated sensing and communication (ISAC)\napplications. In this paper, we derive a closed-form expression for the\nambiguity function of AFDM waveforms modulated with $M$-ary quadrature\namplitude modulation (QAM) data symbols. We determine the condition on the\nchirp rate of the AFDM waveform that minimizes the sidelobes in the delay/range\ndomain in the presence of random $M$-ary QAM symbols, thereby improving overall\nsensing performance. Additionally, we find an approximate statistical\ndistribution for the magnitude of the derived ambiguity function. Simulation\nresults are presented to evaluate the sensing performance of the AFDM waveform\nfor various system parameters and to compare its peak-to-sidelobe ratio (PSLR)\nand integrated sidelobe ratio (ISLR) with those of OFDM.", "published": "2025-04-03 13:46:42", "link": "http://arxiv.org/abs/2504.02582v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Beyond Traditional Coherence Time: An Electromagnetic Perspective for Mobile Channels", "abstract": "Channel coherence time has been widely regarded as a critical parameter in\nthe design of mobile systems. However, a prominent challenge lies in\nintegrating electromagnetic (EM) polarization effects into the derivation of\nthe channel coherence time. In this paper, we develop a framework to analyze\nthe impact of polarization mismatch on the channel coherence time.\nSpecifically, we first establish an EM channel model to capture the essence of\nEM wave propagation. Based on this model, we then derive the EM temporal\ncorrelation function, incorporating the effects of polarization mismatch and\nbeam misalignment. Further, considering the random orientation of the mobile\nuser equipment (UE), we derive a closed-form solution for the EM coherence time\nin the turning scenario. When the trajectory degenerates into a straight line,\nwe also provide a closed-form lower bound on the EM coherence time. The\nsimulation results validate our theoretical analysis and reveal that neglecting\nthe EM polarization effects leads to overly optimistic estimates of the EM\ncoherence time.", "published": "2025-04-03 12:17:30", "link": "http://arxiv.org/abs/2504.02520v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Secrecy Performance of a Keyhole-based Multi-user System with Multiple Eavesdroppers", "abstract": "This paper investigates the secrecy performance of a keyhole-aided multi-user\ncommunication network in the presence of multiple eavesdroppers. The\ncommunication happens through the same keyhole for legitimate users and\neavesdroppers. In this context, the secrecy performance is evaluated for a user\nscheduling technique by obtaining the exact closed-form expression of secrecy\noutage probability (SOP). Further, a simplified asymptotic SOP expression is\nderived assuming high signal-to-noise ratio (SNR) scenario for a better\nunderstanding of the impact of system parameters. The effect of the keyhole\nparameters, number of users, number of eavesdroppers, and threshold secrecy\nrate on the SOP performance are also investigated for the considered system\nmodel. In the high-SNR regime, the asymptotic SOP saturates to a constant value\nand does not depend on the keyhole parameter and the channel parameter of the\nsource-to-keyhole channel.", "published": "2025-04-03 11:38:08", "link": "http://arxiv.org/abs/2504.02506v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Low-cost Embedded Breathing Rate Determination Using 802.15.4z IR-UWB Hardware for Remote Healthcare", "abstract": "Respiratory diseases account for a significant portion of global mortality.\nAffordable and early detection is an effective way of addressing these\nailments. To this end, a low-cost commercial off-the-shelf (COTS), IEEE\n802.15.4z standard compliant impulse-radio ultra-wideband (IR-UWB) radar system\nis exploited to estimate human respiration rates. We propose a convolutional\nneural network (CNN) to predict breathing rates from ultra-wideband (UWB)\nchannel impulse response (CIR) data, and compare its performance with other\nrule-based algorithms. The study uses a diverse dataset of 16 individuals,\nincorporating various real-life environments to evaluate system robustness.\nResults show that the CNN achieves a mean absolute error (MAE) of 1.73 breaths\nper minute (BPM) in unseen situations, significantly outperforming rule-based\nmethods (3.40 BPM). By incorporating calibration data from other individuals in\nthe unseen situations, the error is further reduced to 0.84 BPM. In addition,\nthis work evaluates the feasibility of running the pipeline on a low-cost\nembedded device. Applying 8-bit quantization to both the weights and\ninput/ouput tensors, reduces memory requirements by 67% and inference time by\n64% with only a 3% increase in MAE. As a result, we show it is feasible to\ndeploy the algorithm on an nRF52840 system-on-chip (SoC) requiring only 46 KB\nof memory and operating with an inference time of only 192 ms. Once deployed,\nthe system can last up to 268 days without recharging using a 20 000 mAh\nbattery pack. For breathing monitoring in bed, the sampling rate can be\nlowered, extending battery life to 313 days, making the solution highly\nefficient for real-world, low-cost deployments.", "published": "2025-04-03 07:54:25", "link": "http://arxiv.org/abs/2504.03772v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Optimal Sensor Placement Using Combinations of Hybrid Measurements for Source Localization", "abstract": "This paper focuses on static source localization employing different\ncombinations of measurements, including time-difference-of-arrival (TDOA),\nreceived-signal-strength (RSS), angle-of-arrival (AOA), and time-of-arrival\n(TOA) measurements. Since sensor-source geometry significantly impacts\nlocalization accuracy, the strategies of optimal sensor placement are proposed\nsystematically using combinations of hybrid measurements. Firstly, the\nrelationship between sensor placement and source estimation accuracy is\nformulated by a derived Cram\\'er-Rao bound (CRB). Secondly, the A-optimality\ncriterion, i.e., minimizing the trace of the CRB, is selected to calculate the\nsmallest reachable estimation mean-squared-error (MSE) in a unified manner.\nThirdly, the optimal sensor placement strategies are developed to achieve the\noptimal estimation bound. Specifically, the specific constraints of the optimal\ngeometries deduced by specific measurement, i.e., TDOA, AOA, RSS, and TOA, are\nfound and discussed theoretically. Finally, the new findings are verified by\nsimulation studies.", "published": "2025-04-03 03:40:51", "link": "http://arxiv.org/abs/2504.03769v1", "categories": ["eess.SP", "cs.RO"], "primary_category": "eess.SP"}
{"title": "Variational Online Mirror Descent for Robust Learning in Schr\u00f6dinger Bridge", "abstract": "Sch\\\"odinger bridge (SB) has evolved into a universal class of probabilistic\ngenerative models. In practice, however, estimated learning signals are often\nuncertain, and the reliability promised by existing methods is often based on\nspeculative optimal-case scenarios. Recent studies regarding the Sinkhorn\nalgorithm through mirror descent (MD) have gained attention, revealing\ngeometric insights into solution acquisition of the SB problems. In this paper,\nwe propose a variational online MD (OMD) framework for the SB problems, which\nprovides further stability to SB solvers. We formally prove convergence and a\nregret bound for the novel OMD formulation of SB acquisition. As a result, we\npropose a simulation-free SB algorithm called Variational Mirrored\nSchr\\\"odinger Bridge (VMSB) by utilizing the Wasserstein-Fisher-Rao geometry of\nthe Gaussian mixture parameterization for Schr\\\"odinger potentials. Based on\nthe Wasserstein gradient flow theory, the algorithm offers tractable learning\ndynamics that precisely approximate each OMD step. In experiments, we validate\nthe performance of the proposed VMSB algorithm across an extensive suite of\nbenchmarks. VMSB consistently outperforms contemporary SB solvers on a range of\nSB problems, demonstrating the robustness predicted by our theory.", "published": "2025-04-03 14:18:47", "link": "http://arxiv.org/abs/2504.02618v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Robust Reinforcement Learning from Human Feedback for Large Language Models Fine-Tuning", "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as a key\ntechnique for aligning the output of large language models (LLMs) with human\npreferences. To learn the reward function, most existing RLHF algorithms use\nthe Bradley-Terry model, which relies on assumptions about human preferences\nthat may not reflect the complexity and variability of real-world judgments. In\nthis paper, we propose a robust algorithm to enhance the performance of\nexisting approaches under such reward model misspecifications. Theoretically,\nour algorithm reduces the variance of reward and policy estimators, leading to\nimproved regret bounds. Empirical evaluations on LLM benchmark datasets\ndemonstrate that the proposed algorithm consistently outperforms existing\nmethods, with 77-81% of responses being favored over baselines on the Anthropic\nHelpful and Harmless dataset.", "published": "2025-04-03 16:16:35", "link": "http://arxiv.org/abs/2504.03784v2", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Bridging the Theoretical Gap in Randomized Smoothing", "abstract": "Randomized smoothing has become a leading approach for certifying adversarial\nrobustness in machine learning models. However, a persistent gap remains\nbetween theoretical certified robustness and empirical robustness accuracy.\nThis paper introduces a new framework that bridges this gap by leveraging\nLipschitz continuity for certification and proposing a novel, less conservative\nmethod for computing confidence intervals in randomized smoothing. Our approach\ntightens the bounds of certified robustness, offering a more accurate\nreflection of model robustness in practice. Through rigorous experimentation we\nshow that our method improves the robust accuracy, compressing the gap between\nempirical findings and previous theoretical results. We argue that\ninvestigating local Lipschitz constants and designing ad-hoc confidence\nintervals can further enhance the performance of randomized smoothing. These\nresults pave the way for a deeper understanding of the relationship between\nLipschitz continuity and certified robustness.", "published": "2025-04-03 09:05:49", "link": "http://arxiv.org/abs/2504.02412v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "F5R-TTS: Improving Flow-Matching based Text-to-Speech with Group Relative Policy Optimization", "abstract": "We present F5R-TTS, a novel text-to-speech (TTS) system that integrates\nGradient Reward Policy Optimization (GRPO) into a flow-matching based\narchitecture. By reformulating the deterministic outputs of flow-matching TTS\ninto probabilistic Gaussian distributions, our approach enables seamless\nintegration of reinforcement learning algorithms. During pretraining, we train\na probabilistically reformulated flow-matching based model which is derived\nfrom F5-TTS with an open-source dataset. In the subsequent reinforcement\nlearning (RL) phase, we employ a GRPO-driven enhancement stage that leverages\ndual reward metrics: word error rate (WER) computed via automatic speech\nrecognition and speaker similarity (SIM) assessed by verification models.\nExperimental results on zero-shot voice cloning demonstrate that F5R-TTS\nachieves significant improvements in both speech intelligibility (a 29.5%\nrelative reduction in WER) and speaker similarity (a 4.6% relative increase in\nSIM score) compared to conventional flow-matching based TTS systems. Audio\nsamples are available at https://frontierlabs.github.io/F5R.", "published": "2025-04-03 08:57:15", "link": "http://arxiv.org/abs/2504.02407v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Optimal Sensor Placement Using Combinations of Hybrid Measurements for Source Localization", "abstract": "This paper focuses on static source localization employing different\ncombinations of measurements, including time-difference-of-arrival (TDOA),\nreceived-signal-strength (RSS), angle-of-arrival (AOA), and time-of-arrival\n(TOA) measurements. Since sensor-source geometry significantly impacts\nlocalization accuracy, the strategies of optimal sensor placement are proposed\nsystematically using combinations of hybrid measurements. Firstly, the\nrelationship between sensor placement and source estimation accuracy is\nformulated by a derived Cram\\'er-Rao bound (CRB). Secondly, the A-optimality\ncriterion, i.e., minimizing the trace of the CRB, is selected to calculate the\nsmallest reachable estimation mean-squared-error (MSE) in a unified manner.\nThirdly, the optimal sensor placement strategies are developed to achieve the\noptimal estimation bound. Specifically, the specific constraints of the optimal\ngeometries deduced by specific measurement, i.e., TDOA, AOA, RSS, and TOA, are\nfound and discussed theoretically. Finally, the new findings are verified by\nsimulation studies.", "published": "2025-04-03 03:40:51", "link": "http://arxiv.org/abs/2504.03769v2", "categories": ["eess.SP", "cs.RO"], "primary_category": "eess.SP"}
{"title": "Affordable AI Assistants with Knowledge Graph of Thoughts", "abstract": "Large Language Models (LLMs) are revolutionizing the development of AI\nassistants capable of performing diverse tasks across domains. However, current\nstate-of-the-art LLM-driven agents face significant challenges, including high\noperational costs and limited success rates on complex benchmarks like GAIA. To\naddress these issues, we propose the Knowledge Graph of Thoughts (KGoT), an\ninnovative AI assistant architecture that integrates LLM reasoning with\ndynamically constructed knowledge graphs (KGs). KGoT extracts and structures\ntask-relevant knowledge into a dynamic KG representation, iteratively enhanced\nthrough external tools such as math solvers, web crawlers, and Python scripts.\nSuch structured representation of task-relevant knowledge enables low-cost\nmodels to solve complex tasks effectively. For example, KGoT achieves a 29%\nimprovement in task success rates on the GAIA benchmark compared to Hugging\nFace Agents with GPT-4o mini, while reducing costs by over 36x compared to\nGPT-4o. Improvements for recent reasoning models are similar, e.g., 36% and\n37.5% for Qwen2.5-32B and Deepseek-R1-70B, respectively. KGoT offers a\nscalable, affordable, and high-performing solution for AI assistants.", "published": "2025-04-03 15:11:55", "link": "http://arxiv.org/abs/2504.02670v2", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "An Efficient Reservation Protocol for Medium Access: When Tree Splitting Meets Reinforcement Learning", "abstract": "As an enhanced version of massive machine-type communication in 5G, massive\ncommunication has emerged as one of the six usage scenarios anticipated for 6G,\nowing to its potential in industrial internet-of-things and smart metering.\nDriven by the need for random multiple-access (RMA) in massive communication,\nas well as, next-generation Wi-Fi, medium access control has attracted\nconsiderable recent attention. Holding the promise of attaining\nbandwidth-efficient collision resolution, multiaccess reservation no doubt\nplays a central role in RMA, e.g., the distributed coordination function (DCF)\nin IEEE 802.11. In this paper, we are interested in maximizing the bandwidth\nefficiency of reservation protocols for RMA under quality-of-service\nconstraints. Particularly, we present a tree splitting based reservation\nscheme, in which the attempting probability is dynamically optimized by\npartially observable Markov decision process or reinforcement learning (RL).\nThe RL-empowered tree-splitting algorithm guarantees that all these terminals\nwith backlogged packets at the beginning of a contention cycle can be\nscheduled, thereby providing a first-in-first-out service. More importantly, it\nsubstantially reduces the reservation bandwidth determined by the communication\ncomplexity of DCF, through judiciously conceived coding and interaction for\nexchanging information required by distributed ordering. Simulations\ndemonstrate that the proposed algorithm outperforms the CSMA/CA based DCF in\nIEEE 802.11.", "published": "2025-04-03 08:10:25", "link": "http://arxiv.org/abs/2504.02376v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
