{"title": "$k$Folden: $k$-Fold Ensemble for Out-Of-Distribution Detection", "abstract": "Out-of-Distribution (OOD) detection is an important problem in natural\nlanguage processing (NLP). In this work, we propose a simple yet effective\nframework $k$Folden, which mimics the behaviors of OOD detection during\ntraining without the use of any external data. For a task with $k$ training\nlabels, $k$Folden induces $k$ sub-models, each of which is trained on a subset\nwith $k-1$ categories with the left category masked unknown to the sub-model.\nExposing an unknown label to the sub-model during training, the model is\nencouraged to learn to equally attribute the probability to the seen $k-1$\nlabels for the unknown label, enabling this framework to simultaneously resolve\nin- and out-distribution examples in a natural way via OOD simulations. Taking\ntext classification as an archetype, we develop benchmarks for OOD detection\nusing existing text classification datasets. By conducting comprehensive\ncomparisons and analyses on the developed benchmarks, we demonstrate the\nsuperiority of $k$Folden against current methods in terms of improving OOD\ndetection performances while maintaining improved in-domain classification\naccuracy. The code and datasets can be found at:\n\\url{https://github.com/ShannonAI/kfolden-ood-detection}.", "published": "2021-08-29 01:52:11", "link": "http://arxiv.org/abs/2108.12731v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SummerTime: Text Summarization Toolkit for Non-experts", "abstract": "Recent advances in summarization provide models that can generate summaries\nof higher quality. Such models now exist for a number of summarization tasks,\nincluding query-based summarization, dialogue summarization, and multi-document\nsummarization. While such models and tasks are rapidly growing in the research\nfield, it has also become challenging for non-experts to keep track of them. To\nmake summarization methods more accessible to a wider audience, we develop\nSummerTime by rethinking the summarization task from the perspective of an NLP\nnon-expert. SummerTime is a complete toolkit for text summarization, including\nvarious models, datasets and evaluation metrics, for a full spectrum of\nsummarization-related tasks. SummerTime integrates with libraries designed for\nNLP researchers, and enables users with easy-to-use APIs. With SummerTime,\nusers can locate pipeline solutions and search for the best model with their\nown data, and visualize the differences, all with a few lines of code. We also\nprovide explanations for models and evaluation metrics to help users understand\nthe model behaviors and select models that best suit their needs. Our library,\nalong with a notebook demo, is available at\nhttps://github.com/Yale-LILY/SummerTime.", "published": "2021-08-29 03:24:48", "link": "http://arxiv.org/abs/2108.12738v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentence Structure and Word Relationship Modeling for Emphasis Selection", "abstract": "Emphasis Selection is a newly proposed task which focuses on choosing words\nfor emphasis in short sentences. Traditional methods only consider the sequence\ninformation of a sentence while ignoring the rich sentence structure and word\nrelationship information. In this paper, we propose a new framework that\nconsiders sentence structure via a sentence structure graph and word\nrelationship via a word similarity graph. The sentence structure graph is\nderived from the parse tree of a sentence. The word similarity graph allows\nnodes to share information with their neighbors since we argue that in emphasis\nselection, similar words are more likely to be emphasized together. Graph\nneural networks are employed to learn the representation of each node of these\ntwo graphs. Experimental results demonstrate that our framework can achieve\nsuperior performance.", "published": "2021-08-29 04:43:25", "link": "http://arxiv.org/abs/2108.12750v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Searching for an Effective Defender: Benchmarking Defense against\n  Adversarial Word Substitution", "abstract": "Recent studies have shown that deep neural networks are vulnerable to\nintentionally crafted adversarial examples, and various methods have been\nproposed to defend against adversarial word-substitution attacks for neural NLP\nmodels. However, there is a lack of systematic study on comparing different\ndefense approaches under the same attacking setting. In this paper, we seek to\nfill the gap of systematic studies through comprehensive researches on\nunderstanding the behavior of neural text classifiers trained by various\ndefense methods under representative adversarial attacks. In addition, we\npropose an effective method to further improve the robustness of neural text\nclassifiers against such attacks and achieved the highest accuracy on both\nclean and adversarial examples on AGNEWS and IMDB datasets by a significant\nmargin.", "published": "2021-08-29 08:11:36", "link": "http://arxiv.org/abs/2108.12777v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extractive and Abstractive Sentence Labelling of Sentiment-bearing\n  Topics", "abstract": "This paper tackles the problem of automatically labelling sentiment-bearing\ntopics with descriptive sentence labels. We propose two approaches to the\nproblem, one extractive and the other abstractive. Both approaches rely on a\nnovel mechanism to automatically learn the relevance of each sentence in a\ncorpus to sentiment-bearing topics extracted from that corpus. The extractive\napproach uses a sentence ranking algorithm for label selection which for the\nfirst time jointly optimises topic--sentence relevance as well as\naspect--sentiment co-coverage. The abstractive approach instead addresses\naspect--sentiment co-coverage by using sentence fusion to generate a sentential\nlabel that includes relevant content from multiple sentences. To our knowledge,\nwe are the first to study the problem of labelling sentiment-bearing topics.\nOur experimental results on three real-world datasets show that both the\nextractive and abstractive approaches outperform four strong baselines in terms\nof facilitating topic understanding and interpretation. In addition, when\ncomparing extractive and abstractive labels, our evaluation shows that our best\nperforming abstractive method is able to provide more topic information\ncoverage in fewer words, at the cost of generating less grammatical labels than\nthe extractive method. We conclude that abstractive methods can effectively\nsynthesise the rich information contained in sentiment-bearing topics.", "published": "2021-08-29 11:08:39", "link": "http://arxiv.org/abs/2108.12822v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Behind the Scenes: An Exploration of Trigger Biases Problem in Few-Shot\n  Event Classification", "abstract": "Few-Shot Event Classification (FSEC) aims at developing a model for event\nprediction, which can generalize to new event types with a limited number of\nannotated data. Existing FSEC studies have achieved high accuracy on different\nbenchmarks. However, we find they suffer from trigger biases that signify the\nstatistical homogeneity between some trigger words and target event types,\nwhich we summarize as trigger overlapping and trigger separability. The biases\ncan result in context-bypassing problem, i.e., correct classifications can be\ngained by looking at only the trigger words while ignoring the entire context.\nTherefore, existing models can be weak in generalizing to unseen data in real\nscenarios. To further uncover the trigger biases and assess the generalization\nability of the models, we propose two new sampling methods, Trigger-Uniform\nSampling (TUS) and COnfusion Sampling (COS), for the meta tasks construction\nduring evaluation. Besides, to cope with the context-bypassing problem in FSEC\nmodels, we introduce adversarial training and trigger reconstruction\ntechniques. Experiments show these techniques help not only improve the\nperformance, but also enhance the generalization ability of models.", "published": "2021-08-29 13:46:42", "link": "http://arxiv.org/abs/2108.12844v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Span Fine-tuning for Pre-trained Language Models", "abstract": "Pre-trained language models (PrLM) have to carefully manage input units when\ntraining on a very large text with a vocabulary consisting of millions of\nwords. Previous works have shown that incorporating span-level information over\nconsecutive words in pre-training could further improve the performance of\nPrLMs. However, given that span-level clues are introduced and fixed in\npre-training, previous methods are time-consuming and lack of flexibility. To\nalleviate the inconvenience, this paper presents a novel span fine-tuning\nmethod for PrLMs, which facilitates the span setting to be adaptively\ndetermined by specific downstream tasks during the fine-tuning phase. In\ndetail, any sentences processed by the PrLM will be segmented into multiple\nspans according to a pre-sampled dictionary. Then the segmentation information\nwill be sent through a hierarchical CNN module together with the representation\noutputs of the PrLM and ultimately generate a span-enhanced representation.\nExperiments on GLUE benchmark show that the proposed span fine-tuning method\nsignificantly enhances the PrLM, and at the same time, offer more flexibility\nin an efficient way.", "published": "2021-08-29 14:11:38", "link": "http://arxiv.org/abs/2108.12848v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multiplex Graph Neural Network for Extractive Text Summarization", "abstract": "Extractive text summarization aims at extracting the most representative\nsentences from a given document as its summary. To extract a good summary from\na long text document, sentence embedding plays an important role. Recent\nstudies have leveraged graph neural networks to capture the inter-sentential\nrelationship (e.g., the discourse graph) to learn contextual sentence\nembedding. However, those approaches neither consider multiple types of\ninter-sentential relationships (e.g., semantic similarity & natural\nconnection), nor model intra-sentential relationships (e.g, semantic &\nsyntactic relationship among words). To address these problems, we propose a\nnovel Multiplex Graph Convolutional Network (Multi-GCN) to jointly model\ndifferent types of relationships among sentences and words. Based on Multi-GCN,\nwe propose a Multiplex Graph Summarization (Multi-GraS) model for extractive\ntext summarization. Finally, we evaluate the proposed models on the\nCNN/DailyMail benchmark dataset to demonstrate the effectiveness of our method.", "published": "2021-08-29 16:11:01", "link": "http://arxiv.org/abs/2108.12870v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigations on Speech Recognition Systems for Low-Resource Dialectal\n  Arabic-English Code-Switching Speech", "abstract": "Code-switching (CS), defined as the mixing of languages in conversations, has\nbecome a worldwide phenomenon. The prevalence of CS has been recently met with\na growing demand and interest to build CS ASR systems. In this paper, we\npresent our work on code-switched Egyptian Arabic-English automatic speech\nrecognition (ASR). We first contribute in filling the huge gap in resources by\ncollecting, analyzing and publishing our spontaneous CS Egyptian Arabic-English\nspeech corpus. We build our ASR systems using DNN-based hybrid and\nTransformer-based end-to-end models. In this paper, we present a thorough\ncomparison between both approaches under the setting of a low-resource,\northographically unstandardized, and morphologically rich language pair. We\nshow that while both systems give comparable overall recognition results, each\nsystem provides complementary sets of strength points. We show that recognition\ncan be improved by combining the outputs of both systems. We propose several\neffective system combination approaches, where hypotheses of both systems are\nmerged on sentence- and word-levels. Our approaches result in overall WER\nrelative improvement of 4.7%, over a baseline performance of 32.1% WER. In the\ncase of intra-sentential CS sentences, we achieve WER relative improvement of\n4.8%. Our best performing system achieves 30.6% WER on ArzEn test set.", "published": "2021-08-29 17:23:30", "link": "http://arxiv.org/abs/2108.12881v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mischievous Nominal Constructions in Universal Dependencies", "abstract": "While the highly multilingual Universal Dependencies (UD) project provides\nextensive guidelines for clausal structure as well as structure within\ncanonical nominal phrases, a standard treatment is lacking for many\n\"mischievous\" nominal phenomena that break the mold. As a result, numerous\ninconsistencies within and across corpora can be found, even in languages with\nextensive UD treebanking work, such as English. This paper surveys the kinds of\nmischievous nominal expressions attested in English UD corpora and proposes\nsolutions primarily with English in mind, but which may offer paths to\nsolutions for a variety of UD languages.", "published": "2021-08-29 22:30:15", "link": "http://arxiv.org/abs/2108.12928v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NoiER: An Approach for Training more Reliable Fine-TunedDownstream Task\n  Models", "abstract": "The recent development in pretrained language models trained in a\nself-supervised fashion, such as BERT, is driving rapid progress in the field\nof NLP. However, their brilliant performance is based on leveraging syntactic\nartifacts of the training data rather than fully understanding the intrinsic\nmeaning of language. The excessive exploitation of spurious artifacts causes a\nproblematic issue: The distribution collapse problem, which is the phenomenon\nthat the model fine-tuned on downstream tasks is unable to distinguish\nout-of-distribution (OOD) sentences while producing a high confidence score. In\nthis paper, we argue that distribution collapse is a prevalent issue in\npretrained language models and propose noise entropy regularisation (NoiER) as\nan efficient learning paradigm that solves the problem without auxiliary models\nand additional~data. The proposed approach improved traditional OOD detection\nevaluation metrics by 55% on average compared to the original fine-tuned\nmodels.", "published": "2021-08-29 06:58:28", "link": "http://arxiv.org/abs/2110.02054v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DEGREE: A Data-Efficient Generation-Based Event Extraction Model", "abstract": "Event extraction requires high-quality expert human annotations, which are\nusually expensive. Therefore, learning a data-efficient event extraction model\nthat can be trained with only a few labeled examples has become a crucial\nchallenge. In this paper, we focus on low-resource end-to-end event extraction\nand propose DEGREE, a data-efficient model that formulates event extraction as\na conditional generation problem. Given a passage and a manually designed\nprompt, DEGREE learns to summarize the events mentioned in the passage into a\nnatural sentence that follows a predefined pattern. The final event predictions\nare then extracted from the generated sentence with a deterministic algorithm.\nDEGREE has three advantages to learn well with less training data. First, our\ndesigned prompts provide semantic guidance for DEGREE to leverage DEGREE and\nthus better capture the event arguments. Moreover, DEGREE is capable of using\nadditional weakly-supervised information, such as the description of events\nencoded in the prompts. Finally, DEGREE learns triggers and arguments jointly\nin an end-to-end manner, which encourages the model to better utilize the\nshared knowledge and dependencies among them. Our experimental results\ndemonstrate the strong performance of DEGREE for low-resource event extraction.", "published": "2021-08-29 00:27:31", "link": "http://arxiv.org/abs/2108.12724v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Analyzing and Mitigating Interference in Neural Architecture Search", "abstract": "Weight sharing is a popular approach to reduce the cost of neural\narchitecture search (NAS) by reusing the weights of shared operators from\npreviously trained child models. However, the rank correlation between the\nestimated accuracy and ground truth accuracy of those child models is low due\nto the interference among different child models caused by weight sharing. In\nthis paper, we investigate the interference issue by sampling different child\nmodels and calculating the gradient similarity of shared operators, and\nobserve: 1) the interference on a shared operator between two child models is\npositively correlated with the number of different operators; 2) the\ninterference is smaller when the inputs and outputs of the shared operator are\nmore similar. Inspired by these two observations, we propose two approaches to\nmitigate the interference: 1) MAGIC-T: rather than randomly sampling child\nmodels for optimization, we propose a gradual modification scheme by modifying\none operator between adjacent optimization steps to minimize the interference\non the shared operators; 2) MAGIC-A: forcing the inputs and outputs of the\noperator across all child models to be similar to reduce the interference.\nExperiments on a BERT search space verify that mitigating interference via each\nof our proposed methods improves the rank correlation of super-pet and\ncombining both methods can achieve better results. Our discovered architecture\noutperforms RoBERTa$_{\\rm base}$ by 1.1 and 0.6 points and ELECTRA$_{\\rm base}$\nby 1.6 and 1.1 points on the dev and test set of GLUE benchmark. Extensive\nresults on the BERT compression, reading comprehension and ImageNet task\ndemonstrate the effectiveness and generality of our proposed methods.", "published": "2021-08-29 11:07:46", "link": "http://arxiv.org/abs/2108.12821v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fine-Grained Chemical Entity Typing with Multimodal Knowledge\n  Representation", "abstract": "Automated knowledge discovery from trending chemical literature is essential\nfor more efficient biomedical research. How to extract detailed knowledge about\nchemical reactions from the core chemistry literature is a new emerging\nchallenge that has not been well studied. In this paper, we study the new\nproblem of fine-grained chemical entity typing, which poses interesting new\nchallenges especially because of the complex name mentions frequently occurring\nin chemistry literature and graphic representation of entities. We introduce a\nnew benchmark data set (CHEMET) to facilitate the study of the new task and\npropose a novel multi-modal representation learning framework to solve the\nproblem of fine-grained chemical entity typing by leveraging external resources\nwith chemical structures and using cross-modal attention to learn effective\nrepresentation of text in the chemistry domain. Experiment results show that\nthe proposed framework outperforms multiple state-of-the-art methods.", "published": "2021-08-29 19:41:35", "link": "http://arxiv.org/abs/2108.12899v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HAT4RD: Hierarchical Adversarial Training for Rumor Detection on Social\n  Media", "abstract": "With the development of social media, social communication has changed. While\nthis facilitates people's communication and access to information, it also\nprovides an ideal platform for spreading rumors. In normal or critical\nsituations, rumors will affect people's judgment and even endanger social\nsecurity. However, natural language is high-dimensional and sparse, and the\nsame rumor may be expressed in hundreds of ways on social media. As such, the\nrobustness and generalization of the current rumor detection model are put into\nquestion. We proposed a novel \\textbf{h}ierarchical \\textbf{a}dversarial\n\\textbf{t}raining method for \\textbf{r}umor \\textbf{d}etection (HAT4RD) on\nsocial media. Specifically, HAT4RD is based on gradient ascent by adding\nadversarial perturbations to the embedding layers of post-level and event-level\nmodules to deceive the detector. At the same time, the detector uses stochastic\ngradient descent to minimize the adversarial risk to learn a more robust model.\nIn this way, the post-level and event-level sample spaces are enhanced, and we\nhave verified the robustness of our model under a variety of adversarial\nattacks. Moreover, visual experiments indicate that the proposed model drifts\ninto an area with a flat loss landscape, leading to better generalization. We\nevaluate our proposed method on three public rumors datasets from two commonly\nused social platforms (Twitter and Weibo). Experiment results demonstrate that\nour model achieves better results than state-of-the-art methods.", "published": "2021-08-29 10:10:34", "link": "http://arxiv.org/abs/2110.00425v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Are Training Resources Insufficient? Predict First Then Explain!", "abstract": "Natural language free-text explanation generation is an efficient approach to\ntrain explainable language processing models for\ncommonsense-knowledge-requiring tasks. The most predominant form of these\nmodels is the explain-then-predict (EtP) structure, which first generates\nexplanations and uses them for making decisions. The performance of EtP models\nis highly dependent on that of the explainer by the nature of their structure.\nTherefore, large-sized explanation data are required to train a good explainer\nmodel. However, annotating explanations is expensive. Also, recent works reveal\nthat free-text explanations might not convey sufficient information for\ndecision making. These facts cast doubts on the effectiveness of EtP models. In\nthis paper, we argue that the predict-then-explain (PtE) architecture is a more\nefficient approach in terms of the modelling perspective. Our main contribution\nis twofold. First, we show that the PtE structure is the most data-efficient\napproach when explanation data are lacking. Second, we reveal that the PtE\nstructure is always more training-efficient than the EtP structure. We also\nprovide experimental results that confirm the theoretical advantages.", "published": "2021-08-29 07:04:50", "link": "http://arxiv.org/abs/2110.02056v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Interpretable Propaganda Detection in News Articles", "abstract": "Online users today are exposed to misleading and propagandistic news articles\nand media posts on a daily basis. To counter thus, a number of approaches have\nbeen designed aiming to achieve a healthier and safer online news and media\nconsumption. Automatic systems are able to support humans in detecting such\ncontent; yet, a major impediment to their broad adoption is that besides being\naccurate, the decisions of such systems need also to be interpretable in order\nto be trusted and widely adopted by users. Since misleading and propagandistic\ncontent influences readers through the use of a number of deception techniques,\nwe propose to detect and to show the use of such techniques as a way to offer\ninterpretability. In particular, we define qualitatively descriptive features\nand we analyze their suitability for detecting deception techniques. We further\nshow that our interpretable features can be easily combined with pre-trained\nlanguage models, yielding state-of-the-art results.", "published": "2021-08-29 09:57:01", "link": "http://arxiv.org/abs/2108.12802v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "DropAttack: A Masked Weight Adversarial Training Method to Improve\n  Generalization of Neural Networks", "abstract": "Adversarial training has been proven to be a powerful regularization method\nto improve the generalization of models. However, current adversarial training\nmethods only attack the original input sample or the embedding vectors, and\ntheir attacks lack coverage and diversity. To further enhance the breadth and\ndepth of attack, we propose a novel masked weight adversarial training method\ncalled DropAttack, which enhances generalization of model by adding\nintentionally worst-case adversarial perturbations to both the input and hidden\nlayers in different dimensions and minimize the adversarial risks generated by\neach layer. DropAttack is a general technique and can be adopt to a wide\nvariety of neural networks with different architectures. To validate the\neffectiveness of the proposed method, we used five public datasets in the\nfields of natural language processing (NLP) and computer vision (CV) for\nexperimental evaluating. We compare the proposed method with other adversarial\ntraining methods and regularization methods, and our method achieves\nstate-of-the-art on all datasets. In addition, Dropattack can achieve the same\nperformance when it use only a half training data compared to other standard\ntraining method. Theoretical analysis reveals that DropAttack can perform\ngradient regularization at random on some of the input and wight parameters of\nthe model. Further visualization experiments show that DropAttack can push the\nminimum risk of the model to a lower and flatter loss landscapes. Our source\ncode is publicly available on https://github.com/nishiwen1214/DropAttack.", "published": "2021-08-29 10:09:43", "link": "http://arxiv.org/abs/2108.12805v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Student Surpasses Teacher: Imitation Attack for Black-Box NLP APIs", "abstract": "Machine-learning-as-a-service (MLaaS) has attracted millions of users to\ntheir splendid large-scale models. Although published as black-box APIs, the\nvaluable models behind these services are still vulnerable to imitation\nattacks. Recently, a series of works have demonstrated that attackers manage to\nsteal or extract the victim models. Nonetheless, none of the previous stolen\nmodels can outperform the original black-box APIs. In this work, we conduct\nunsupervised domain adaptation and multi-victim ensemble to showing that\nattackers could potentially surpass victims, which is beyond previous\nunderstanding of model extraction. Extensive experiments on both benchmark\ndatasets and real-world APIs validate that the imitators can succeed in\noutperforming the original black-box models on transferred domains. We consider\nour work as a milestone in the research of imitation attack, especially on NLP\nAPIs, as the superior performance could influence the defense or even\npublishing strategy of API providers.", "published": "2021-08-29 10:52:04", "link": "http://arxiv.org/abs/2108.13873v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Zero-shot Natural Language Video Localization", "abstract": "Understanding videos to localize moments with natural language often requires\nlarge expensive annotated video regions paired with language queries. To\neliminate the annotation costs, we make a first attempt to train a natural\nlanguage video localization model in zero-shot manner. Inspired by unsupervised\nimage captioning setup, we merely require random text corpora, unlabeled video\ncollections, and an off-the-shelf object detector to train a model. With the\nunpaired data, we propose to generate pseudo-supervision of candidate temporal\nregions and corresponding query sentences, and develop a simple NLVL model to\ntrain with the pseudo-supervision. Our empirical validations show that the\nproposed pseudo-supervised method outperforms several baseline approaches and a\nnumber of methods using stronger supervision on Charades-STA and\nActivityNet-Captions.", "published": "2021-08-29 13:21:50", "link": "http://arxiv.org/abs/2110.00428v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Generating Answer Candidates for Quizzes and Answer-Aware Question\n  Generators", "abstract": "In education, open-ended quiz questions have become an important tool for\nassessing the knowledge of students. Yet, manually preparing such questions is\na tedious task, and thus automatic question generation has been proposed as a\npossible alternative. So far, the vast majority of research has focused on\ngenerating the question text, relying on question answering datasets with\nreadily picked answers, and the problem of how to come up with answer\ncandidates in the first place has been largely ignored. Here, we aim to bridge\nthis gap. In particular, we propose a model that can generate a specified\nnumber of answer candidates for a given passage of text, which can then be used\nby instructors to write questions manually or can be passed as an input to\nautomatic answer-aware question generators. Our experiments show that our\nproposed answer candidate generation model outperforms several baselines.", "published": "2021-08-29 19:33:51", "link": "http://arxiv.org/abs/2108.12898v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.IR", "cs.LG", "68T50", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
