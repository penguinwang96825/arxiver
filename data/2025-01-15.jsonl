{"title": "Eigenvector Overlaps of Random Covariance Matrices and their Submatrices", "abstract": "We consider the singular vectors of any $m \\times n$ submatrix of a\nrectangular $M \\times N$ Gaussian matrix and study their asymptotic overlaps\nwith those of the full matrix, in the macroscopic regime where $N \\,/\\, M\\,$,\n$m \\,/\\, M$ as well as $n \\,/\\, N$ converge to fixed ratios. Our method makes\nuse of the dynamics of the singular vectors and of specific resolvents when the\nmatrix coefficients follow Brownian trajectories. We obtain explicit forms for\nthe limiting rescaled mean squared overlaps for right and left singular vectors\nin the bulk of both spectra, for any initial matrix $A\\,$. When it is null,\nthis corresponds to the Marchenko-Pastur setup for covariance matrices, and our\nformulas simplify into Cauchy-like functions.", "published": "2025-01-15 12:41:19", "link": "http://arxiv.org/abs/2501.08768v1", "categories": ["math.PR", "cond-mat.stat-mech", "q-fin.MF"], "primary_category": "math.PR"}
{"title": "Empirical Study on the Factors Influencing Stock Market Volatility in China", "abstract": "This paper mainly utilizes the ARDL model and principal component analysis to\ninvestigate the relationship between the volatility of China's Shanghai\nComposite Index returns and the variables of exchange rate and domestic and\nforeign bond yields in an internationally integrated stock market. This paper\nuses a daily data set for the period from July 1, 2010 to April 30, 2024, in\nwhich the dependent variable is the Shanghai Composite Index return, and the\nmain independent variables are the spot exchange rate of the RMB against the US\ndollar, the 10-year treasury bond yields in China and the United States and\ntheir lagged variables, with the effect of the time factor added. Firstly, the\ndevelopment of the stock, foreign exchange and bond markets and the basic\ntheories are reviewed, and then each variable is analyzed by descriptive\nstatistics, the correlation between the independent variables and the dependent\nvariable is expanded theoretically, and the corresponding empirical analyses\nare briefly introduced, and then the empirical analyses and modeling of the\nrelationship between the independent variables and the dependent variable are\ncarried out on the basis of the theoretical foundations mentioned above with\nthe support of the daily data, and the model conclusions are analyzed\neconomically through a large number of tests, then the model conclusions are\nanalyzed economically. economic analysis of the model conclusions, and finally,\nthe author proposes three suggestions to enhance the stability and return of\nthe Chinese stock market, respectively.\n  Key Words: Chinese Stock Market, Volatility, GARCH, ARDL Model", "published": "2025-01-15 09:02:54", "link": "http://arxiv.org/abs/2501.08668v1", "categories": ["econ.GN", "q-fin.EC", "q-fin.ST"], "primary_category": "econ.GN"}
{"title": "Deep Learning Meets Queue-Reactive: A Framework for Realistic Limit Order Book Simulation", "abstract": "The Queue-Reactive model introduced by Huang et al. (2015) has become a\nstandard tool for limit order book modeling, widely adopted by both researchers\nand practitioners for its simplicity and effectiveness. We present the\nMultidimensional Deep Queue-Reactive (MDQR) model, which extends this framework\nin three ways: it relaxes the assumption of queue independence, enriches the\nstate space with market features, and models the distribution of order sizes.\nThrough a neural network architecture, the model learns complex dependencies\nbetween different price levels and adapts to varying market conditions, while\npreserving the interpretable point-process foundation of the original\nframework. Using data from the Bund futures market, we show that MDQR captures\nkey market properties including the square-root law of market impact,\ncross-queue correlations, and realistic order size patterns. The model\ndemonstrates particular strength in reproducing both conditional and stationary\ndistributions of order sizes, as well as various stylized facts of market\nmicrostructure. The model achieves this while maintaining the computational\nefficiency needed for practical applications such as strategy development\nthrough reinforcement learning or realistic backtesting.", "published": "2025-01-15 14:19:20", "link": "http://arxiv.org/abs/2501.08822v1", "categories": ["q-fin.TR", "cs.LG"], "primary_category": "q-fin.TR"}
{"title": "Information Entropy Invariance: Enhancing Length Extrapolation in\n  Attention Mechanisms", "abstract": "Since the emergence of research on improving the length extrapolation\ncapabilities of large language models in 2021, some studies have made\nmodifications to the scaling factor in the scaled dot-product attention\nmechanism as part of their proposed methods without rigorous theoretical\njustifications. To fill this gap, we propose two new scaled temperatures based\non information entropy invariance to enhance length extrapolation. First, a\ntraining-free method InfoScale is designed for dotproduct attention, and\npreserves focus on original tokens during length extrapolation by ensuring\nconsistent entropy. Second, we theoretically analyze the impact of scaling\n(CosScale) on cosine attention. Experimental data demonstrates that combining\nInfoScale and CosScale achieves state-ofthe-art performance on the GAU-{\\alpha}\nmodel with a context window extended to 64 times the training length, and\noutperforms seven existing methods. Our analysis reveals that significantly\nincreasing CosScale approximates the Windowed Attention, and highlights the\nsignificance of attention score dilution as a key challenge in long-range\ncontext handling. The code and data are available at\nhttps://github.com/HT-NEKO/ Information-Entropy-Invariance.", "published": "2025-01-15 04:32:41", "link": "http://arxiv.org/abs/2501.08570v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Limits LLM-based Human Simulation: LLMs or Our Design?", "abstract": "We argue that advancing LLM-based human simulation requires addressing both\nLLM's inherent limitations and simulation framework design challenges. Recent\nstudies have revealed significant gaps between LLM-based human simulations and\nreal-world observations, highlighting these dual challenges. To address these\ngaps, we present a comprehensive analysis of LLM limitations and our design\nissues, proposing targeted solutions for both aspects. Furthermore, we explore\nfuture directions that address both challenges simultaneously, particularly in\ndata collection, LLM generation, and evaluation. To support further research in\nthis field, we provide a curated collection of LLM-based human simulation\nresources.\\footnote{https://github.com/Persdre/llm-human-simulation}", "published": "2025-01-15 04:59:49", "link": "http://arxiv.org/abs/2501.08579v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model", "abstract": "Existing low-rank adaptation (LoRA) methods face challenges on sparse large\nlanguage models (LLMs) due to the inability to maintain sparsity. Recent works\nintroduced methods that maintain sparsity by augmenting LoRA techniques with\nadditional masking mechanisms. Despite these successes, such approaches suffer\nfrom an increased memory and computation overhead, which affects efficiency of\nLoRA methods. In response to this limitation, we introduce LoRS, an innovative\nmethod designed to achieve both memory and computation efficiency when\nfine-tuning sparse LLMs. To mitigate the substantial memory and computation\ndemands associated with preserving sparsity, our approach incorporates\nstrategies of weight recompute and computational graph rearrangement. In\naddition, we also improve the effectiveness of LoRS through better adapter\ninitialization. These innovations lead to a notable reduction in memory and\ncomputation consumption during the fine-tuning phase, all while achieving\nperformance levels that outperform existing LoRA approaches.", "published": "2025-01-15 05:07:06", "link": "http://arxiv.org/abs/2501.08582v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Dynamic Knowledge Integration for Enhanced Vision-Language Reasoning", "abstract": "Large Vision-Language Models (LVLMs) have demonstrated impressive\ncapabilities in multimodal tasks, but their performance is often constrained by\nthe lack of external knowledge integration, limiting their ability to handle\nknowledge-intensive tasks such as visual question answering and reasoning. To\naddress this challenge, we propose a novel method, Adaptive Knowledge-Guided\nPretraining for Large Vision-Language Models (AKGP-LVLM), which dynamically\nincorporates structured and unstructured knowledge into LVLMs during\npretraining and fine-tuning. Our approach employs a knowledge encoder to\nrepresent external knowledge, a retrieval mechanism to select task-relevant\ninformation, and a dynamic adaptor to align multimodal and knowledge\nrepresentations effectively. We evaluate our method on four benchmark datasets,\ndemonstrating significant performance improvements over state-of-the-art\nmodels. Furthermore, human evaluations highlight the superior correctness and\nrelevance of our model's outputs. Extensive analyses confirm the robustness,\nefficiency, and scalability of AKGP-LVLM, making it a compelling solution for\nreal-world knowledge-intensive tasks.", "published": "2025-01-15 05:45:04", "link": "http://arxiv.org/abs/2501.08597v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing the Alignment of FOL Closeness Metrics with Human Judgement", "abstract": "The recent successful paradigm of solving logical reasoning problems with\ntool-augmented large language models (LLMs) leverages translation of natural\nlanguage statements into First-Order Logic~(FOL) and external theorem provers.\nHowever, the correctness of FOL statements, comprising operators and text\npredicates, often goes unverified due to the lack of a reliable evaluation\nmetric for comparing generated and ground-truth FOLs. In this paper, we present\na comprehensive study of sensitivity of existing metrics and their alignment\nwith human judgement on FOL evaluation. Using ground-truth FOLs, we carefully\ndesigned various perturbations on the ground-truth to assess metric\nsensitivity. We sample FOL translation candidates for natural language\nstatements and measure the ranking alignment between automatic metrics and\nhuman annotators. Our empirical findings highlight oversensitivity in the\nn-gram metric BLEU for text perturbations, the semantic graph metric Smatch++\nfor structural perturbations, and FOL metric for operator perturbation. We also\nobserve a closer alignment between BertScore and human judgement. Additionally,\nwe show that combining metrics enhances both alignment and sensitivity compared\nto using individual metrics.", "published": "2025-01-15 06:22:35", "link": "http://arxiv.org/abs/2501.08613v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Learning-Based Feature Fusion for Emotion Analysis and Suicide Risk\n  Differentiation in Chinese Psychological Support Hotlines", "abstract": "Mental health is a critical global public health issue, and psychological\nsupport hotlines play a pivotal role in providing mental health assistance and\nidentifying suicide risks at an early stage. However, the emotional expressions\nconveyed during these calls remain underexplored in current research. This\nstudy introduces a method that combines pitch acoustic features with deep\nlearning-based features to analyze and understand emotions expressed during\nhotline interactions. Using data from China's largest psychological support\nhotline, our method achieved an F1-score of 79.13% for negative binary emotion\nclassification.Additionally, the proposed approach was validated on an open\ndataset for multi-class emotion classification,where it demonstrated better\nperformance compared to the state-of-the-art methods. To explore its clinical\nrelevance, we applied the model to analysis the frequency of negative emotions\nand the rate of emotional change in the conversation, comparing 46 subjects\nwith suicidal behavior to those without. While the suicidal group exhibited\nmore frequent emotional changes than the non-suicidal group, the difference was\nnot statistically significant.Importantly, our findings suggest that emotional\nfluctuation intensity and frequency could serve as novel features for\npsychological assessment scales and suicide risk prediction.The proposed method\nprovides valuable insights into emotional dynamics and has the potential to\nadvance early intervention and improve suicide prevention strategies through\nintegration with clinical tools and assessments The source code is publicly\navailable at https://github.com/Sco-field/Speechemotionrecognition/tree/main.", "published": "2025-01-15 10:09:38", "link": "http://arxiv.org/abs/2501.08696v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Inherent Limits of Pretrained LLMs: The Unexpected Convergence of\n  Instruction Tuning and In-Context Learning Capabilities", "abstract": "Large Language Models (LLMs), trained on extensive web-scale corpora, have\ndemonstrated remarkable abilities across diverse tasks, especially as they are\nscaled up. Nevertheless, even state-of-the-art models struggle in certain\ncases, sometimes failing at problems solvable by young children, indicating\nthat traditional notions of task complexity are insufficient for explaining LLM\ncapabilities. However, exploring LLM capabilities is complicated by the fact\nthat most widely-used models are also \"instruction-tuned\" to respond\nappropriately to prompts. With the goal of disentangling the factors\ninfluencing LLM performance, we investigate whether instruction-tuned models\npossess fundamentally different capabilities from base models that are prompted\nusing in-context examples. Through extensive experiments across various model\nfamilies, scales and task types, which included instruction tuning 90 different\nLLMs, we demonstrate that the performance of instruction-tuned models is\nsignificantly correlated with the in-context performance of their base\ncounterparts. By clarifying what instruction-tuning contributes, we extend\nprior research into in-context learning, which suggests that base models use\npriors from pretraining data to solve tasks. Specifically, we extend this\nunderstanding to instruction-tuned models, suggesting that their pretraining\ndata similarly sets a limiting boundary on the tasks they can solve, with the\nadded influence of the instruction-tuning dataset.", "published": "2025-01-15 10:57:55", "link": "http://arxiv.org/abs/2501.08716v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Expanding Vietnamese SentiWordNet to Improve Performance of Vietnamese\n  Sentiment Analysis Models", "abstract": "Sentiment analysis is one of the most crucial tasks in Natural Language\nProcessing (NLP), involving the training of machine learning models to classify\ntext based on the polarity of opinions. Pre-trained Language Models (PLMs) can\nbe applied to downstream tasks through fine-tuning, eliminating the need to\ntrain the model from scratch. Specifically, PLMs have been employed for\nSentiment Analysis, a process that involves detecting, analyzing, and\nextracting the polarity of text sentiments. Numerous models have been proposed\nto address this task, with pre-trained PhoBERT-V2 models standing out as the\nstate-of-the-art language models for Vietnamese. The PhoBERT-V2 pre-training\napproach is based on RoBERTa, optimizing the BERT pre-training method for more\nrobust performance. In this paper, we introduce a novel approach that combines\nPhoBERT-V2 and SentiWordnet for Sentiment Analysis of Vietnamese reviews. Our\nproposed model utilizes PhoBERT-V2 for Vietnamese, offering a robust\noptimization for the prominent BERT model in the context of Vietnamese\nlanguage, and leverages SentiWordNet, a lexical resource explicitly designed to\nsupport sentiment classification applications. Experimental results on the VLSP\n2016 and AIVIVN 2019 datasets demonstrate that our sentiment analysis system\nhas achieved excellent performance in comparison to other models.", "published": "2025-01-15 12:22:37", "link": "http://arxiv.org/abs/2501.08758v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhanced Large Language Models for Effective Screening of Depression and\n  Anxiety", "abstract": "Depressive and anxiety disorders are widespread, necessitating timely\nidentification and management. Recent advances in Large Language Models (LLMs)\noffer potential solutions, yet high costs and ethical concerns about training\ndata remain challenges. This paper introduces a pipeline for synthesizing\nclinical interviews, resulting in 1,157 interactive dialogues (PsyInterview),\nand presents EmoScan, an LLM-based emotional disorder screening system. EmoScan\ndistinguishes between coarse (e.g., anxiety or depressive disorders) and fine\ndisorders (e.g., major depressive disorders) and conducts high-quality\ninterviews. Evaluations showed that EmoScan exceeded the performance of base\nmodels and other LLMs like GPT-4 in screening emotional disorders\n(F1-score=0.7467). It also delivers superior explanations (BERTScore=0.9408)\nand demonstrates robust generalizability (F1-score of 0.67 on an external\ndataset). Furthermore, EmoScan outperforms baselines in interviewing skills, as\nvalidated by automated ratings and human evaluations. This work highlights the\nimportance of scalable data-generative pipelines for developing effective\nmental health LLM tools.", "published": "2025-01-15 12:42:09", "link": "http://arxiv.org/abs/2501.08769v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Extract Cross-Domain Aspects and Understanding Sentiments\n  Using Large Language Models", "abstract": "Aspect-based sentiment analysis (ASBA) is a refined approach to sentiment\nanalysis that aims to extract and classify sentiments based on specific aspects\nor features of a product, service, or entity. Unlike traditional sentiment\nanalysis, which assigns a general sentiment score to entire reviews or texts,\nABSA focuses on breaking down the text into individual components or aspects\n(e.g., quality, price, service) and evaluating the sentiment towards each. This\nallows for a more granular level of understanding of customer opinions,\nenabling businesses to pinpoint specific areas of strength and improvement. The\nprocess involves several key steps, including aspect extraction, sentiment\nclassification, and aspect-level sentiment aggregation for a review paragraph\nor any other form that the users have provided. ABSA has significant\napplications in areas such as product reviews, social media monitoring,\ncustomer feedback analysis, and market research. By leveraging techniques from\nnatural language processing (NLP) and machine learning, ABSA facilitates the\nextraction of valuable insights, enabling companies to make data-driven\ndecisions that enhance customer satisfaction and optimize offerings. As ABSA\nevolves, it holds the potential to greatly improve personalized customer\nexperiences by providing a deeper understanding of sentiment across various\nproduct aspects. In this work, we have analyzed the strength of LLMs for a\ncomplete cross-domain aspect-based sentiment analysis with the aim of defining\nthe framework for certain products and using it for other similar situations.\nWe argue that it is possible to that at an effectiveness of 92\\% accuracy for\nthe Aspect Based Sentiment Analysis dataset of SemEval-2015 Task 12.", "published": "2025-01-15 17:36:56", "link": "http://arxiv.org/abs/2501.08974v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aegis2.0: A Diverse AI Safety Dataset and Risks Taxonomy for Alignment\n  of LLM Guardrails", "abstract": "As Large Language Models (LLMs) and generative AI become increasingly\nwidespread, concerns about content safety have grown in parallel. Currently,\nthere is a clear lack of high-quality, human-annotated datasets that address\nthe full spectrum of LLM-related safety risks and are usable for commercial\napplications. To bridge this gap, we propose a comprehensive and adaptable\ntaxonomy for categorizing safety risks, structured into 12 top-level hazard\ncategories with an extension to 9 fine-grained subcategories. This taxonomy is\ndesigned to meet the diverse requirements of downstream users, offering more\ngranular and flexible tools for managing various risk types. Using a hybrid\ndata generation pipeline that combines human annotations with a multi-LLM\n\"jury\" system to assess the safety of responses, we obtain Aegis 2.0, a\ncarefully curated collection of 34,248 samples of human-LLM interactions,\nannotated according to our proposed taxonomy. To validate its effectiveness, we\ndemonstrate that several lightweight models, trained using parameter-efficient\ntechniques on Aegis 2.0, achieve performance competitive with leading safety\nmodels fully fine-tuned on much larger, non-commercial datasets. In addition,\nwe introduce a novel training blend that combines safety with topic following\ndata.This approach enhances the adaptability of guard models, enabling them to\ngeneralize to new risk categories defined during inference. We plan to\nopen-source Aegis 2.0 data and models to the research community to aid in the\nsafety guardrailing of LLMs.", "published": "2025-01-15 18:37:08", "link": "http://arxiv.org/abs/2501.09004v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual LLMs Struggle to Link Orthography and Semantics in\n  Bilingual Word Processing", "abstract": "Bilingual lexical processing is shaped by the complex interplay of\nphonological, orthographic, and semantic features of two languages within an\nintegrated mental lexicon. In humans, this is evident in the ease with which\ncognate words - words similar in both orthographic form and meaning (e.g.,\nblind, meaning \"sightless\" in both English and German) - are processed,\ncompared to the challenges posed by interlingual homographs, which share\northographic form but differ in meaning (e.g., gift, meaning \"present\" in\nEnglish but \"poison\" in German). We investigate how multilingual Large Language\nModels (LLMs) handle such phenomena, focusing on English-Spanish,\nEnglish-French, and English-German cognates, non-cognate, and interlingual\nhomographs. Specifically, we evaluate their ability to disambiguate meanings\nand make semantic judgments, both when these word types are presented in\nisolation or within sentence contexts. Our findings reveal that while certain\nLLMs demonstrate strong performance in recognizing cognates and non-cognates in\nisolation, they exhibit significant difficulty in disambiguating interlingual\nhomographs, often performing below random baselines. This suggests LLMs tend to\nrely heavily on orthographic similarities rather than semantic understanding\nwhen interpreting interlingual homographs. Further, we find LLMs exhibit\ndifficulty in retrieving word meanings, with performance in isolative\ndisambiguation tasks having no correlation with semantic understanding.\nFinally, we study how the LLM processes interlingual homographs in incongruent\nsentences. We find models to opt for different strategies in understanding\nEnglish and non-English homographs, highlighting a lack of a unified approach\nto handling cross-lingual ambiguities.", "published": "2025-01-15 20:22:35", "link": "http://arxiv.org/abs/2501.09127v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating GenAI for Simplifying Texts for Education: Improving Accuracy\n  and Consistency for Enhanced Readability", "abstract": "Generative artificial intelligence (GenAI) holds great promise as a tool to\nsupport personalized learning. Teachers need tools to efficiently and\neffectively enhance content readability of educational texts so that they are\nmatched to individual students reading levels, while retaining key details.\nLarge Language Models (LLMs) show potential to fill this need, but previous\nresearch notes multiple shortcomings in current approaches. In this study, we\nintroduced a generalized approach and metrics for the systematic evaluation of\nthe accuracy and consistency in which LLMs, prompting techniques, and a novel\nmulti-agent architecture to simplify sixty informational reading passages,\nreducing each from the twelfth grade level down to the eighth, sixth, and\nfourth grade levels. We calculated the degree to which each LLM and prompting\ntechnique accurately achieved the targeted grade level for each passage,\npercentage change in word count, and consistency in maintaining keywords and\nkey phrases (semantic similarity). One-sample t-tests and multiple regression\nmodels revealed significant differences in the best performing LLM and prompt\ntechnique for each of the four metrics. Both LLMs and prompting techniques\ndemonstrated variable utility in grade level accuracy and consistency of\nkeywords and key phrases when attempting to level content down to the fourth\ngrade reading level. These results demonstrate the promise of the application\nof LLMs for efficient and precise automated text simplification, the\nshortcomings of current models and prompting methods in attaining an ideal\nbalance across various evaluation criteria, and a generalizable method to\nevaluate future systems.", "published": "2025-01-15 21:19:01", "link": "http://arxiv.org/abs/2501.09158v1", "categories": ["cs.CL", "68", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Adapting Whisper for Regional Dialects: Enhancing Public Services for\n  Vulnerable Populations in the United Kingdom", "abstract": "We collect novel data in the public service domain to evaluate the capability\nof the state-of-the-art automatic speech recognition (ASR) models in capturing\nregional differences in accents in the United Kingdom (UK), specifically\nfocusing on two accents from Scotland with distinct dialects. This study\naddresses real-world problems where biased ASR models can lead to\nmiscommunication in public services, disadvantaging individuals with regional\naccents particularly those in vulnerable populations. We first examine the\nout-of-the-box performance of the Whisper large-v3 model on a baseline dataset\nand our data. We then explore the impact of fine-tuning Whisper on the\nperformance in the two UK regions and investigate the effectiveness of existing\nmodel evaluation techniques for our real-world application through manual\ninspection of model errors. We observe that the Whisper model has a higher word\nerror rate (WER) on our test datasets compared to the baseline data and\nfine-tuning on a given data improves performance on the test dataset with the\nsame domain and accent. The fine-tuned models also appear to show improved\nperformance when applied to the test data outside of the region it was trained\non suggesting that fine-tuned models may be transferable within parts of the\nUK. Our manual analysis of model outputs reveals the benefits and drawbacks of\nusing WER as an evaluation metric and fine-tuning to adapt to regional\ndialects.", "published": "2025-01-15 00:39:21", "link": "http://arxiv.org/abs/2501.08502v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Doc-Guided Sent2Sent++: A Sent2Sent++ Agent with Doc-Guided memory for\n  Document-level Machine Translation", "abstract": "The field of artificial intelligence has witnessed significant advancements\nin natural language processing, largely attributed to the capabilities of Large\nLanguage Models (LLMs). These models form the backbone of Agents designed to\naddress long-context dependencies, particularly in Document-level Machine\nTranslation (DocMT). DocMT presents unique challenges, with quality,\nconsistency, and fluency being the key metrics for evaluation. Existing\napproaches, such as Doc2Doc and Doc2Sent, either omit sentences or compromise\nfluency. This paper introduces Doc-Guided Sent2Sent++, an Agent that employs an\nincremental sentence-level forced decoding strategy \\textbf{to ensure every\nsentence is translated while enhancing the fluency of adjacent sentences.} Our\nAgent leverages a Doc-Guided Memory, focusing solely on the summary and its\ntranslation, which we find to be an efficient approach to maintaining\nconsistency. Through extensive testing across multiple languages and domains,\nwe demonstrate that Sent2Sent++ outperforms other methods in terms of quality,\nconsistency, and fluency. The results indicate that, our approach has achieved\nsignificant improvements in metrics such as s-COMET, d-COMET, LTCR-$1_f$, and\ndocument-level perplexity (d-ppl). The contributions of this paper include a\ndetailed analysis of current DocMT research, the introduction of the\nSent2Sent++ decoding method, the Doc-Guided Memory mechanism, and validation of\nits effectiveness across languages and domains.", "published": "2025-01-15 02:25:35", "link": "http://arxiv.org/abs/2501.08523v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Complexity Control Facilitates Reasoning-Based Compositional\n  Generalization in Transformers", "abstract": "Transformers have demonstrated impressive capabilities across various tasks,\nyet their performance on compositional problems remains a subject of debate. In\nthis study, we investigate the internal mechanisms underlying Transformers'\nbehavior in compositional tasks. We find that complexity control strategies\nsignificantly influence whether the model learns primitive-level rules that\ngeneralize out-of-distribution (reasoning-based solutions) or relies solely on\nmemorized mappings (memory-based solutions). By applying masking strategies to\nthe model's information circuits and employing multiple complexity metrics, we\nreveal distinct internal working mechanisms associated with different solution\ntypes. Further analysis reveals that reasoning-based solutions exhibit a lower\ncomplexity bias, which aligns with the well-studied neuron condensation\nphenomenon. This lower complexity bias is hypothesized to be the key factor\nenabling these solutions to learn reasoning rules. We validate these\nconclusions across multiple real-world datasets, including image generation and\nnatural language processing tasks, confirming the broad applicability of our\nfindings.", "published": "2025-01-15 02:54:52", "link": "http://arxiv.org/abs/2501.08537v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Disjoint Processing Mechanisms of Hierarchical and Linear Grammars in\n  Large Language Models", "abstract": "All natural languages are structured hierarchically. In humans, this\nstructural restriction is neurologically coded: when two grammars are presented\nwith identical vocabularies, brain areas responsible for language processing\nare only sensitive to hierarchical grammars. Using large language models\n(LLMs), we investigate whether such functionally distinct hierarchical\nprocessing regions can arise solely from exposure to large-scale language\ndistributions. We generate inputs using English, Italian, Japanese, or nonce\nwords, varying the underlying grammars to conform to either hierarchical or\nlinear/positional rules. Using these grammars, we first observe that language\nmodels show distinct behaviors on hierarchical versus linearly structured\ninputs. Then, we find that the components responsible for processing\nhierarchical grammars are distinct from those that process linear grammars; we\ncausally verify this in ablation experiments. Finally, we observe that\nhierarchy-selective components are also active on nonce grammars; this suggests\nthat hierarchy sensitivity is not tied to meaning, nor in-distribution inputs.", "published": "2025-01-15 06:34:34", "link": "http://arxiv.org/abs/2501.08618v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ViBidirectionMT-Eval: Machine Translation for Vietnamese-Chinese and\n  Vietnamese-Lao language pair", "abstract": "This paper presents an results of the VLSP 2022-2023 Machine Translation\nShared Tasks, focusing on Vietnamese-Chinese and Vietnamese-Lao machine\ntranslation. The tasks were organized as part of the 9th, 10th annual workshop\non Vietnamese Language and Speech Processing (VLSP 2022, VLSP 2023). The\nobjective of the shared task was to build machine translation systems,\nspecifically targeting Vietnamese-Chinese and Vietnamese-Lao translation\n(corresponding to 4 translation directions). The submission were evaluated on\n1,000 pairs for testing (news and general domains) using established metrics\nlike BLEU [11] and SacreBLEU [12]. Additionally, system outputs also were\nevaluated with human judgment provided by experts in Chinese and Lao languages.\nThese human assessments played a crucial role in ranking the performance of the\nmachine translation models, ensuring a more comprehensive evaluation.", "published": "2025-01-15 06:40:26", "link": "http://arxiv.org/abs/2501.08621v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SWSC: Shared Weight for Similar Channel in LLM", "abstract": "Large language models (LLMs) have spurred development in multiple industries.\nHowever, the growing number of their parameters brings substantial storage and\ncomputing burdens, making it essential to explore model compression techniques\nfor parameter reduction and easier deployment. We propose SWSC, an LLM\ncompression method based on the concept of Shared Weight for Similar Channel.\nIt uses the K-Means clustering algorithm to cluster model weights\nchannel-by-channel, generating clusters with highly similar vectors within\neach. A representative vector from each cluster is selected to approximately\nreplace all vectors in the cluster, significantly reducing the number of model\nweight parameters. However, approximate restoration will inevitably cause\ndamage to the performance of the model. To tackle this issue, we perform\nsingular value decomposition on the weight error values before and after\ncompression and retain the larger singular values and their corresponding\nsingular vectors to compensate for the accuracy. The experimental results show\nthat our method can effectively ensure the performance of the compressed LLM\neven under low-precision conditions.", "published": "2025-01-15 07:36:19", "link": "http://arxiv.org/abs/2501.08631v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Reassessing the Role of Chain-of-Thought in Sentiment Analysis: Insights\n  and Limitations", "abstract": "The relationship between language and thought remains an unresolved\nphilosophical issue. Existing viewpoints can be broadly categorized into two\nschools: one asserting their independence, and another arguing that language\nconstrains thought. In the context of large language models, this debate raises\na crucial question: Does a language model's grasp of semantic meaning depend on\nthought processes? To explore this issue, we investigate whether reasoning\ntechniques can facilitate semantic understanding. Specifically, we\nconceptualize thought as reasoning, employ chain-of-thought prompting as a\nreasoning technique, and examine its impact on sentiment analysis tasks. The\nexperiments show that chain-of-thought has a minimal impact on sentiment\nanalysis tasks. Both the standard and chain-of-thought prompts focus on aspect\nterms rather than sentiment in the generated content. Furthermore,\ncounterfactual experiments reveal that the model's handling of sentiment tasks\nprimarily depends on information from demonstrations. The experimental results\nsupport the first viewpoint.", "published": "2025-01-15 08:07:22", "link": "http://arxiv.org/abs/2501.08641v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MAGNET: Augmenting Generative Decoders with Representation Learning and\n  Infilling Capabilities", "abstract": "While originally designed for unidirectional generative modeling,\ndecoder-only large language models (LLMs) are increasingly being adapted for\nbidirectional modeling. However, unidirectional and bidirectional models are\ntypically trained separately with distinct objectives (generation and\nrepresentation learning). This separation overlooks the opportunity for\ndeveloping a more versatile language model and for these objectives to\ncomplement each other. In this work, we propose MAGNET, a method for adapting\ndecoder-only LLMs to generate robust representations and infill missing text\nspans. MAGNET employs three self-supervised training objectives and introduces\nan attention mechanism that combines bidirectional and causal attention,\nenabling unified training across all objectives. Our results demonstrate that\nLLMs adapted with MAGNET (1) surpass strong text encoders on token-level and\nsentence-level representation learning tasks, (2) generate contextually\nappropriate text infills by leveraging past and future contexts, (3) perform\nopen-ended text generation without excessive repetition of words or phrases,\nand (4) preserve the knowledge and reasoning capability gained by the LLM\nduring pretraining.", "published": "2025-01-15 08:24:03", "link": "http://arxiv.org/abs/2501.08648v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ToMATO: Verbalizing the Mental States of Role-Playing LLMs for\n  Benchmarking Theory of Mind", "abstract": "Existing Theory of Mind (ToM) benchmarks diverge from real-world scenarios in\nthree aspects: 1) they assess a limited range of mental states such as beliefs,\n2) false beliefs are not comprehensively explored, and 3) the diverse\npersonality traits of characters are overlooked. To address these challenges,\nwe introduce ToMATO, a new ToM benchmark formulated as multiple-choice QA over\nconversations. ToMATO is generated via LLM-LLM conversations featuring\ninformation asymmetry. By employing a prompting method that requires\nrole-playing LLMs to verbalize their thoughts before each utterance, we capture\nboth first- and second-order mental states across five categories: belief,\nintention, desire, emotion, and knowledge. These verbalized thoughts serve as\nanswers to questions designed to assess the mental states of characters within\nconversations. Furthermore, the information asymmetry introduced by hiding\nthoughts from others induces the generation of false beliefs about various\nmental states. Assigning distinct personality traits to LLMs further\ndiversifies both utterances and thoughts. ToMATO consists of 5.4k questions,\n753 conversations, and 15 personality trait patterns. Our analysis shows that\nthis dataset construction approach frequently generates false beliefs due to\nthe information asymmetry between role-playing LLMs, and effectively reflects\ndiverse personalities. We evaluate nine LLMs on ToMATO and find that even\nGPT-4o mini lags behind human performance, especially in understanding false\nbeliefs, and lacks robustness to various personality traits.", "published": "2025-01-15 14:47:02", "link": "http://arxiv.org/abs/2501.08838v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GenAI Content Detection Task 3: Cross-Domain Machine-Generated Text\n  Detection Challenge", "abstract": "Recently there have been many shared tasks targeting the detection of\ngenerated text from Large Language Models (LLMs). However, these shared tasks\ntend to focus either on cases where text is limited to one particular domain or\ncases where text can be from many domains, some of which may not be seen during\ntest time. In this shared task, using the newly released RAID benchmark, we aim\nto answer whether or not models can detect generated text from a large, yet\nfixed, number of domains and LLMs, all of which are seen during training. Over\nthe course of three months, our task was attempted by 9 teams with 23 detector\nsubmissions. We find that multiple participants were able to obtain accuracies\nof over 99% on machine-generated text from RAID while maintaining a 5% False\nPositive Rate -- suggesting that detectors are able to robustly detect text\nfrom many domains and models simultaneously. We discuss potential\ninterpretations of this result and provide directions for future research.", "published": "2025-01-15 16:21:09", "link": "http://arxiv.org/abs/2501.08913v1", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Applying General Turn-taking Models to Conversational Human-Robot\n  Interaction", "abstract": "Turn-taking is a fundamental aspect of conversation, but current Human-Robot\nInteraction (HRI) systems often rely on simplistic, silence-based models,\nleading to unnatural pauses and interruptions. This paper investigates, for the\nfirst time, the application of general turn-taking models, specifically TurnGPT\nand Voice Activity Projection (VAP), to improve conversational dynamics in HRI.\nThese models are trained on human-human dialogue data using self-supervised\nlearning objectives, without requiring domain-specific fine-tuning. We propose\nmethods for using these models in tandem to predict when a robot should begin\npreparing responses, take turns, and handle potential interruptions. We\nevaluated the proposed system in a within-subject study against a traditional\nbaseline system, using the Furhat robot with 39 adults in a conversational\nsetting, in combination with a large language model for autonomous response\ngeneration. The results show that participants significantly prefer the\nproposed system, and it significantly reduces response delays and\ninterruptions.", "published": "2025-01-15 16:49:22", "link": "http://arxiv.org/abs/2501.08946v1", "categories": ["cs.CL", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Generative Visual Commonsense Answering and Explaining with Generative\n  Scene Graph Constructing", "abstract": "Visual Commonsense Reasoning, which is regarded as one challenging task to\npursue advanced visual scene comprehension, has been used to diagnose the\nreasoning ability of AI systems. However, reliable reasoning requires a good\ngrasp of the scene's details. Existing work fails to effectively exploit the\nreal-world object relationship information present within the scene, and\ninstead overly relies on knowledge from training memory. Based on these\nobservations, we propose a novel scene-graph-enhanced visual commonsense\nreasoning generation method named \\textit{\\textbf{G2}}, which first utilizes\nthe image patches and LLMs to construct a location-free scene graph, and then\nanswer and explain based on the scene graph's information. We also propose\nautomatic scene graph filtering and selection strategies to absorb valuable\nscene graph information during training. Extensive experiments are conducted on\nthe tasks and datasets of scene graph constructing and visual commonsense\nanswering and explaining, respectively. Experimental results and ablation\nanalysis demonstrate the effectiveness of our proposed framework.", "published": "2025-01-15 04:00:36", "link": "http://arxiv.org/abs/2501.09041v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Decompose-ToM: Enhancing Theory of Mind Reasoning in Large Language\n  Models through Simulation and Task Decomposition", "abstract": "Theory of Mind (ToM) is the ability to understand and reflect on the mental\nstates of others. Although this capability is crucial for human interaction,\ntesting on Large Language Models (LLMs) reveals that they possess only a\nrudimentary understanding of it. Although the most capable closed-source LLMs\nhave come close to human performance on some ToM tasks, they still perform\npoorly on complex variations of the task that involve more structured\nreasoning. In this work, we utilize the concept of \"pretend-play\", or\n``Simulation Theory'' from cognitive psychology to propose ``Decompose-ToM'':\nan LLM-based inference algorithm that improves model performance on complex ToM\ntasks. We recursively simulate user perspectives and decompose the ToM task\ninto a simpler set of functions: subject identification, question-reframing,\nworld model updation, and knowledge availability. We test the algorithm on\nhigher-order ToM tasks and a task testing for ToM capabilities in a\nconversational setting, demonstrating that our approach shows significant\nimprovement across models compared to baseline methods while requiring minimal\nprompt tuning across tasks and no additional model training.", "published": "2025-01-15 18:44:01", "link": "http://arxiv.org/abs/2501.09056v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Multilingual LLM Evaluation for Baltic and Nordic languages: A\n  study on Lithuanian History", "abstract": "In this work, we evaluated Lithuanian and general history knowledge of\nmultilingual Large Language Models (LLMs) on a multiple-choice\nquestion-answering task. The models were tested on a dataset of Lithuanian\nnational and general history questions translated into Baltic, Nordic, and\nother languages (English, Ukrainian, Arabic) to assess the knowledge sharing\nfrom culturally and historically connected groups. We evaluated GPT-4o,\nLLaMa3.1 8b and 70b, QWEN2.5 7b and 72b, Mistral Nemo 12b, LLaMa3 8b, Mistral\n7b, LLaMa3.2 3b, and Nordic fine-tuned models (GPT-SW3 and LLaMa3 8b).\n  Our results show that GPT-4o consistently outperformed all other models\nacross language groups, with slightly better results for Baltic and Nordic\nlanguages. Larger open-source models like QWEN2.5 72b and LLaMa3.1 70b\nperformed well but showed weaker alignment with Baltic languages. Smaller\nmodels (Mistral Nemo 12b, LLaMa3.2 3b, QWEN 7B, LLaMa3.1 8B, and LLaMa3 8b)\ndemonstrated gaps with LT-related alignment with Baltic languages while\nperforming better on Nordic and other languages. The Nordic fine-tuned models\ndid not surpass multilingual models, indicating that shared cultural or\nhistorical context alone does not guarantee better performance.", "published": "2025-01-15 21:14:09", "link": "http://arxiv.org/abs/2501.09154v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VCRScore: Image captioning metric based on V\\&L Transformers, CLIP, and\n  precision-recall", "abstract": "Image captioning has become an essential Vision & Language research task. It\nis about predicting the most accurate caption given a specific image or video.\nThe research community has achieved impressive results by continuously\nproposing new models and approaches to improve the overall model's performance.\nNevertheless, despite increasing proposals, the performance metrics used to\nmeasure their advances have remained practically untouched through the years. A\nprobe of that, nowadays metrics like BLEU, METEOR, CIDEr, and ROUGE are still\nvery used, aside from more sophisticated metrics such as BertScore and\nClipScore.\n  Hence, it is essential to adjust how are measure the advances, limitations,\nand scopes of the new image captioning proposals, as well as to adapt new\nmetrics to these new advanced image captioning approaches.\n  This work proposes a new evaluation metric for the image captioning problem.\nTo do that, first, it was generated a human-labeled dataset to assess to which\ndegree the captions correlate with the image's content. Taking these human\nscores as ground truth, we propose a new metric, and compare it with several\nwell-known metrics, from classical to newer ones. Outperformed results were\nalso found, and interesting insights were presented and discussed.", "published": "2025-01-15 21:14:36", "link": "http://arxiv.org/abs/2501.09155v2", "categories": ["cs.CV", "cs.CL", "68Txx", "I.5; I.4"], "primary_category": "cs.CV"}
{"title": "The Veln(ia)s is in the Details: Evaluating LLM Judgment on Latvian and\n  Lithuanian Short Answer Matching", "abstract": "In this work, we address the challenge of evaluating large language models\n(LLMs) on the short answer matching task for Latvian and Lithuanian languages.\nWe introduce novel datasets consisting of 502 Latvian and 690 Lithuanian\nquestion-answer pairs. For each question-answer pair, we generated matched and\nnon-matched answers using a set of alteration rules specifically designed to\nintroduce small but meaningful changes in the text. These generated answers\nserve as test cases to assess the ability of LLMs to detect subtle differences\nin matching of the original answers. A subset of the datasets was manually\nverified for quality and accuracy. Our results show that while larger LLMs,\nsuch as QWEN2.5 72b and LLaMa3.1 70b, demonstrate near-perfect performance in\ndistinguishing matched and non-matched answers, smaller models show more\nvariance. For instance, LLaMa3.1 8b and EuroLLM 9b benefited from few-shot\nexamples, while Mistral Nemo 12b underperformed on detection of subtle text\nalteration, particularly in Lithuanian, even with additional examples. QWEN2.5\n7b and Mistral 7b were able to obtain a strong and comparable performance to\nthe larger 70b models in zero and few shot experiments. Moreover, the\nperformance of Mistral 7b was weaker in few shot experiments.", "published": "2025-01-15 21:30:03", "link": "http://arxiv.org/abs/2501.09164v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LeMo: Enabling LEss Token Involvement for MOre Context Fine-tuning", "abstract": "The escalating demand for long-context applications has intensified the\nnecessity of extending the LLM context windows. Despite recent fine-tuning\napproaches successfully expanding context lengths, their high memory\nfootprints, especially for activations, present a critical practical\nlimitation. Current parameter-efficient fine-tuning methods prioritize reducing\nparameter update overhead over addressing activation memory constraints.\nSimilarly, existing sparsity mechanisms improve computational efficiency but\noverlook activation memory optimization due to the phenomenon of Shadowy\nActivation.\n  In this paper, we propose LeMo, the first LLM fine-tuning system that\nexplores and exploits a new token-level sparsity mechanism inherent in\nlong-context scenarios, termed Contextual Token Sparsity. LeMo minimizes\nredundant token involvement by assessing the informativeness of token\nembeddings while preserving model accuracy. Specifically, LeMo introduces three\nkey techniques: (1) Token Elimination, dynamically identifying and excluding\nredundant tokens across varying inputs and layers. (2) Pattern Prediction,\nutilizing well-trained predictors to approximate token sparsity patterns with\nminimal overhead. (3) Kernel Optimization, employing permutation-free and\nsegment-based strategies to boost system performance. We implement LeMo as an\nend-to-end fine-tuning system compatible with various LLM architectures and\nother optimization techniques. Comprehensive evaluations demonstrate that LeMo\nreduces memory consumption by up to 1.93x and achieves up to 1.36x speedups,\noutperforming state-of-the-art fine-tuning systems.", "published": "2025-01-15 05:17:12", "link": "http://arxiv.org/abs/2501.09767v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can Large Language Models Predict the Outcome of Judicial Decisions?", "abstract": "Large Language Models (LLMs) have shown exceptional capabilities in Natural\nLanguage Processing (NLP) across diverse domains. However, their application in\nspecialized tasks such as Legal Judgment Prediction (LJP) for low-resource\nlanguages like Arabic remains underexplored. In this work, we address this gap\nby developing an Arabic LJP dataset, collected and preprocessed from Saudi\ncommercial court judgments. We benchmark state-of-the-art open-source LLMs,\nincluding LLaMA-3.2-3B and LLaMA-3.1-8B, under varying configurations such as\nzero-shot, one-shot, and fine-tuning using LoRA. Additionally, we employed a\ncomprehensive evaluation framework that integrates both quantitative metrics\n(such as BLEU, ROUGE, and BERT) and qualitative assessments (including\nCoherence, Legal Language, Clarity, etc.) using an LLM. Our results demonstrate\nthat fine-tuned smaller models achieve comparable performance to larger models\nin task-specific contexts while offering significant resource efficiency.\nFurthermore, we investigate the impact of fine-tuning the model on a diverse\nset of instructions, offering valuable insights into the development of a more\nhuman-centric and adaptable LLM. We have made the dataset, code, and models\npublicly available to provide a solid foundation for future research in Arabic\nlegal NLP.", "published": "2025-01-15 11:32:35", "link": "http://arxiv.org/abs/2501.09768v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Coordination-based Approach for Focused Learning in Knowledge-Based\n  Systems", "abstract": "Recent progress in Learning by Reading and Machine Reading systems has\nsignificantly increased the capacity of knowledge-based systems to learn new\nfacts. In this work, we discuss the problem of selecting a set of learning\nrequests for these knowledge-based systems which would lead to maximum Q/A\nperformance. To understand the dynamics of this problem, we simulate the\nproperties of a learning strategy, which sends learning requests to an external\nknowledge source. We show that choosing an optimal set of facts for these\nlearning systems is similar to a coordination game, and use reinforcement\nlearning to solve this problem. Experiments show that such an approach can\nsignificantly improve Q/A performance.", "published": "2025-01-15 23:45:02", "link": "http://arxiv.org/abs/2502.10394v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Knowledge prompt chaining for semantic modeling", "abstract": "The task of building semantics for structured data such as CSV, JSON, and XML\nfiles is highly relevant in the knowledge representation field. Even though we\nhave a vast of structured data on the internet, mapping them to domain\nontologies to build semantics for them is still very challenging as it requires\nthe construction model to understand and learn graph-structured knowledge.\nOtherwise, the task will require human beings' effort and cost. In this paper,\nwe proposed a novel automatic semantic modeling framework: Knowledge Prompt\nChaining. It can serialize the graph-structured knowledge and inject it into\nthe LLMs properly in a Prompt Chaining architecture. Through this knowledge\ninjection and prompting chaining, the model in our framework can learn the\nstructure information and latent space of the graph and generate the semantic\nlabels and semantic graphs following the chains' insturction naturally. Based\non experimental results, our method achieves better performance than existing\nleading techniques, despite using reduced structured input data.", "published": "2025-01-15 03:00:57", "link": "http://arxiv.org/abs/2501.08540v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "RLHS: Mitigating Misalignment in RLHF with Hindsight Simulation", "abstract": "While Reinforcement Learning from Human Feedback (RLHF) has shown promise in\naligning generative AI, we present empirical evidence that it can also cause\nsevere, systematic misalignment. We hypothesize that this stems from evaluator\nfeedback depending on downstream outcome predictions (foresight) that can be\ninfluenced by the AI's output, inducing Goodhart's law dynamics. Conversely,\nour theoretical analysis shows that conditioning evaluator feedback on\ndownstream observations (hindsight) inhibits this effect by decoupling the\nalignment signal from potentially compromised predictions-crucially, the result\nholds even if the observed outcomes are sampled from the AI's own world model.\nBuilding on this insight, we introduce Reinforcement Learning from Hindsight\nSimulation (RLHS), which presents plausible simulated outcomes to evaluators\nbefore eliciting feedback. We demonstrate RLHS on online (PPO) and offline\n(DPO) large language model fine-tuning, obtaining superior alignment over RLHF\nin controlled consultancy-type experiments and user studies. We evaluate\npost-hoc on the TruthfulQA benchmark and find that, even after single-task\nfine-tuning, both RLHF misalignment and RLHS alignment carry over to\nsubstantially different settings.", "published": "2025-01-15 06:33:15", "link": "http://arxiv.org/abs/2501.08617v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching", "abstract": "Traditional similarity-based schema matching methods are incapable of\nresolving semantic ambiguities and conflicts in domain-specific complex mapping\nscenarios due to missing commonsense and domain-specific knowledge. The\nhallucination problem of large language models (LLMs) also makes it challenging\nfor LLM-based schema matching to address the above issues. Therefore, we\npropose a Knowledge Graph-based Retrieval-Augmented Generation model for Schema\nMatching, referred to as the KG-RAG4SM. In particular, KG-RAG4SM introduces\nnovel vector-based, graph traversal-based, and query-based graph retrievals, as\nwell as a hybrid approach and ranking schemes that identify the most relevant\nsubgraphs from external large knowledge graphs (KGs). We showcase that KG-based\nretrieval-augmented LLMs are capable of generating more accurate results for\ncomplex matching cases without any re-training. Our experimental results show\nthat KG-RAG4SM outperforms the LLM-based state-of-the-art (SOTA) methods (e.g.,\nJellyfish-8B) by 35.89% and 30.50% in terms of precision and F1 score on the\nMIMIC dataset, respectively; KG-RAG4SM with GPT-4o-mini outperforms the\npre-trained language model (PLM)-based SOTA methods (e.g., SMAT) by 69.20% and\n21.97% in terms of precision and F1 score on the Synthea dataset, respectively.\nThe results also demonstrate that our approach is more efficient in end-to-end\nschema matching, and scales to retrieve from large KGs. Our case studies on the\ndataset from the real-world schema matching scenario exhibit that the\nhallucination problem of LLMs for schema matching is well mitigated by our\nsolution.", "published": "2025-01-15 09:32:37", "link": "http://arxiv.org/abs/2501.08686v1", "categories": ["cs.DB", "cs.CL", "cs.IR"], "primary_category": "cs.DB"}
{"title": "SAIF: A Comprehensive Framework for Evaluating the Risks of Generative\n  AI in the Public Sector", "abstract": "The rapid adoption of generative AI in the public sector, encompassing\ndiverse applications ranging from automated public assistance to welfare\nservices and immigration processes, highlights its transformative potential\nwhile underscoring the pressing need for thorough risk assessments. Despite its\ngrowing presence, evaluations of risks associated with AI-driven systems in the\npublic sector remain insufficiently explored. Building upon an established\ntaxonomy of AI risks derived from diverse government policies and corporate\nguidelines, we investigate the critical risks posed by generative AI in the\npublic sector while extending the scope to account for its multimodal\ncapabilities. In addition, we propose a Systematic dAta generatIon Framework\nfor evaluating the risks of generative AI (SAIF). SAIF involves four key\nstages: breaking down risks, designing scenarios, applying jailbreak methods,\nand exploring prompt types. It ensures the systematic and consistent generation\nof prompt data, facilitating a comprehensive evaluation while providing a solid\nfoundation for mitigating the risks. Furthermore, SAIF is designed to\naccommodate emerging jailbreak methods and evolving prompt types, thereby\nenabling effective responses to unforeseen risk scenarios. We believe that this\nstudy can play a crucial role in fostering the safe and responsible integration\nof generative AI into the public sector.", "published": "2025-01-15 14:12:38", "link": "http://arxiv.org/abs/2501.08814v2", "categories": ["cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.AI"}
{"title": "MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents", "abstract": "Multi-modal document retrieval is designed to identify and retrieve various\nforms of multi-modal content, such as figures, tables, charts, and layout\ninformation from extensive documents. Despite its significance, there is a\nnotable lack of a robust benchmark to effectively evaluate the performance of\nsystems in multi-modal document retrieval. To address this gap, this work\nintroduces a new benchmark, named as MMDocIR, encompassing two distinct tasks:\npage-level and layout-level retrieval. The former focuses on localizing the\nmost relevant pages within a long document, while the latter targets the\ndetection of specific layouts, offering a more fine-grained granularity than\nwhole-page analysis. A layout can refer to a variety of elements such as\ntextual paragraphs, equations, figures, tables, or charts. The MMDocIR\nbenchmark comprises a rich dataset featuring expertly annotated labels for\n1,685 questions and bootstrapped labels for 173,843 questions, making it a\npivotal resource for advancing multi-modal document retrieval for both training\nand evaluation. Through rigorous experiments, we reveal that (i) visual\nretrievers significantly outperform their text counterparts, (ii) MMDocIR train\nset can effectively benefit the training process of multi-modal document\nretrieval and (iii) text retrievers leveraging on VLM-text perform much better\nthan those using OCR-text. These findings underscores the potential advantages\nof integrating visual elements for multi-modal document retrieval.", "published": "2025-01-15 14:30:13", "link": "http://arxiv.org/abs/2501.08828v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.IR"}
{"title": "Disentangling Exploration of Large Language Models by Optimal\n  Exploitation", "abstract": "Exploration is a crucial skill for self-improvement and open-ended\nproblem-solving. However, it remains unclear if large language models can\neffectively explore the state-space within an unknown environment. This work\nisolates exploration as the sole objective, tasking the agent with delivering\ninformation that enhances future returns. Within this framework, we argue that\nmeasuring agent returns is not sufficient for a fair evaluation and decompose\nmissing rewards into exploration and exploitation components based on the\noptimal achievable return. Comprehensive experiments with various models reveal\nthat most struggle to sufficiently explore the state-space and weak exploration\nis insufficient. We observe a positive correlation between parameter count and\nexploration performance, with larger models demonstrating superior\ncapabilities. Furthermore, we show that our decomposition provides insights\ninto differences in behaviors driven by prompt engineering, offering a valuable\ntool for refining performance in exploratory tasks.", "published": "2025-01-15 16:30:29", "link": "http://arxiv.org/abs/2501.08925v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Personality Modeling for Persuasion of Misinformation using AI Agent", "abstract": "The proliferation of misinformation on social media platforms has highlighted\nthe need to understand how individual personality traits influence\nsusceptibility to and propagation of misinformation. This study employs an\ninnovative agent-based modeling approach to investigate the relationship\nbetween personality traits and misinformation dynamics. Using six AI agents\nembodying different dimensions of the Big Five personality traits\n(Extraversion, Agreeableness, and Neuroticism), we simulated interactions\nacross six diverse misinformation topics. The experiment, implemented through\nthe AgentScope framework using the GLM-4-Flash model, generated 90 unique\ninteractions, revealing complex patterns in how personality combinations affect\npersuasion and resistance to misinformation. Our findings demonstrate that\nanalytical and critical personality traits enhance effectiveness in\nevidence-based discussions, while non-aggressive persuasion strategies show\nunexpected success in misinformation correction. Notably, agents with critical\ntraits achieved a 59.4% success rate in HIV-related misinformation discussions,\nwhile those employing non-aggressive approaches maintained consistent\npersuasion rates above 40% across different personality combinations. The study\nalso revealed a non-transitive pattern in persuasion effectiveness, challenging\nconventional assumptions about personality-based influence. These results\nprovide crucial insights for developing personality-aware interventions in\ndigital environments and suggest that effective misinformation countermeasures\nshould prioritize emotional connection and trust-building over confrontational\napproaches. The findings contribute to both theoretical understanding of\npersonality-misinformation dynamics and practical strategies for combating\nmisinformation in social media contexts.", "published": "2025-01-15 18:04:21", "link": "http://arxiv.org/abs/2501.08985v1", "categories": ["cs.CL", "cs.AI", "cs.GT"], "primary_category": "cs.CL"}
{"title": "Multimodal LLMs Can Reason about Aesthetics in Zero-Shot", "abstract": "We present the first study on how Multimodal LLMs' (MLLMs) reasoning ability\nshall be elicited to evaluate the aesthetics of artworks. To facilitate this\ninvestigation, we construct MM-StyleBench, a novel high-quality dataset for\nbenchmarking artistic stylization. We then develop a principled method for\nhuman preference modeling and perform a systematic correlation analysis between\nMLLMs' responses and human preference. Our experiments reveal an inherent\nhallucination issue of MLLMs in art evaluation, associated with response\nsubjectivity. ArtCoT is proposed, demonstrating that art-specific task\ndecomposition and the use of concrete language boost MLLMs' reasoning ability\nfor aesthetics. Our findings offer valuable insights into MLLMs for art and can\nbenefit a wide range of downstream applications, such as style transfer and\nartistic image generation. Code available at\nhttps://github.com/songrise/MLLM4Art.", "published": "2025-01-15 18:56:22", "link": "http://arxiv.org/abs/2501.09012v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "SteLLA: A Structured Grading System Using LLMs with RAG", "abstract": "Large Language Models (LLMs) have shown strong general capabilities in many\napplications. However, how to make them reliable tools for some specific tasks\nsuch as automated short answer grading (ASAG) remains a challenge. We present\nSteLLA (Structured Grading System Using LLMs with RAG) in which a) Retrieval\nAugmented Generation (RAG) approach is used to empower LLMs specifically on the\nASAG task by extracting structured information from the highly relevant and\nreliable external knowledge based on the instructor-provided reference answer\nand rubric, b) an LLM performs a structured and question-answering-based\nevaluation of student answers to provide analytical grades and feedback. A\nreal-world dataset that contains students' answers in an exam was collected\nfrom a college-level Biology course. Experiments show that our proposed system\ncan achieve substantial agreement with the human grader while providing\nbreak-down grades and feedback on all the knowledge points examined in the\nproblem. A qualitative and error analysis of the feedback generated by GPT4\nshows that GPT4 is good at capturing facts while may be prone to inferring too\nmuch implication from the given text in the grading task which provides\ninsights into the usage of LLMs in the ASAG system.", "published": "2025-01-15 19:24:48", "link": "http://arxiv.org/abs/2501.09092v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Augmenting Human-Annotated Training Data with Large Language Model\n  Generation and Distillation in Open-Response Assessment", "abstract": "Large Language Models (LLMs) like GPT-4o can help automate text\nclassification tasks at low cost and scale. However, there are major concerns\nabout the validity and reliability of LLM outputs. By contrast, human coding is\ngenerally more reliable but expensive to procure at scale. In this study, we\npropose a hybrid solution to leverage the strengths of both. We combine\nhuman-coded data and synthetic LLM-produced data to fine-tune a classical\nmachine learning classifier, distilling both into a smaller BERT model. We\nevaluate our method on a human-coded test set as a validity measure for LLM\noutput quality. In three experiments, we systematically vary LLM-generated\nsamples' size, variety, and consistency, informed by best practices in LLM\ntuning. Our findings indicate that augmenting datasets with synthetic samples\nimproves classifier performance, with optimal results achieved at an 80%\nsynthetic to 20% human-coded data ratio. Lower temperature settings of 0.3,\ncorresponding to less variability in LLM generations, produced more stable\nimprovements but also limited model learning from augmented samples. In\ncontrast, higher temperature settings (0.7 and above) introduced greater\nvariability in performance estimates and, at times, lower performance. Hence,\nLLMs may produce more uniform output that classifiers overfit to earlier or\nproduce more diverse output that runs the risk of deteriorating model\nperformance through information irrelevant to the prediction task. Filtering\nout inconsistent synthetic samples did not enhance performance. We conclude\nthat integrating human and LLM-generated data to improve text classification\nmodels in assessment offers a scalable solution that leverages both the\naccuracy of human coding and the variety of LLM outputs.", "published": "2025-01-15 20:13:46", "link": "http://arxiv.org/abs/2501.09126v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG", "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence (AI)\nby enabling human like text generation and natural language understanding.\nHowever, their reliance on static training data limits their ability to respond\nto dynamic, real time queries, resulting in outdated or inaccurate outputs.\nRetrieval Augmented Generation (RAG) has emerged as a solution, enhancing LLMs\nby integrating real time data retrieval to provide contextually relevant and\nup-to-date responses. Despite its promise, traditional RAG systems are\nconstrained by static workflows and lack the adaptability required for\nmultistep reasoning and complex task management.\n  Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these\nlimitations by embedding autonomous AI agents into the RAG pipeline. These\nagents leverage agentic design patterns reflection, planning, tool use, and\nmultiagent collaboration to dynamically manage retrieval strategies,\niteratively refine contextual understanding, and adapt workflows to meet\ncomplex task requirements. This integration enables Agentic RAG systems to\ndeliver unparalleled flexibility, scalability, and context awareness across\ndiverse applications.\n  This survey provides a comprehensive exploration of Agentic RAG, beginning\nwith its foundational principles and the evolution of RAG paradigms. It\npresents a detailed taxonomy of Agentic RAG architectures, highlights key\napplications in industries such as healthcare, finance, and education, and\nexamines practical implementation strategies. Additionally, it addresses\nchallenges in scaling these systems, ensuring ethical decision making, and\noptimizing performance for real-world applications, while providing detailed\ninsights into frameworks and tools for implementing Agentic RAG.", "published": "2025-01-15 20:40:25", "link": "http://arxiv.org/abs/2501.09136v3", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "iTool: Boosting Tool Use of Large Language Models via Iterative\n  Reinforced Fine-Tuning", "abstract": "Augmenting large language models (LLMs) with external tools is known as a\npromising approach to enhancing their capabilities, especially for complex\ntasks. Synthesizing tool-use data through real-world simulations is an\neffective way to achieve it. Nevertheless, our investigation reveals that (1)\ntraining gains significantly decay as synthetic data increases. The model\nstruggles to benefit from more synthetic data due to potential data diversity\nissues, resulting in poor performance in complex scenarios. Moreover, we find\nthat (2) this challenge primarily manifests as minor discrepancies between the\nmodel's output and the ground truth response (termed as deficiency), such as\nerrors in parameter values that require complex reasoning from the context to\nresolve. To this end, we propose an iterative reinforced fine-tuning strategy\ndesigned to alleviate these challenges. This strategy involves: (1) enhancing\nthe diversity of synthetic data through path exploration of Monte Carlo Tree\nSearch. (2) iteratively identifying deficiency-related data, constructing\nfine-grained preference pairs to pinpoint deficiencies, and then applying\npreference optimization to optimize these deficiencies. Our experiments show\nthat models trained using our method achieve about 12\\% better performance than\nbaseline models, outperforming larger open-source and closed-source models.", "published": "2025-01-15 04:52:34", "link": "http://arxiv.org/abs/2501.09766v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Scopes of Alignment", "abstract": "Much of the research focus on AI alignment seeks to align large language\nmodels and other foundation models to the context-less and generic values of\nhelpfulness, harmlessness, and honesty. Frontier model providers also strive to\nalign their models with these values. In this paper, we motivate why we need to\nmove beyond such a limited conception and propose three dimensions for doing\nso. The first scope of alignment is competence: knowledge, skills, or behaviors\nthe model must possess to be useful for its intended purpose. The second scope\nof alignment is transience: either semantic or episodic depending on the\ncontext of use. The third scope of alignment is audience: either mass, public,\nsmall-group, or dyadic. At the end of the paper, we use the proposed framework\nto position some technologies and workflows that go beyond prevailing notions\nof alignment.", "published": "2025-01-15 03:06:59", "link": "http://arxiv.org/abs/2501.12405v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "WhiSPA: Semantically and Psychologically Aligned Whisper with\n  Self-Supervised Contrastive and Student-Teacher Learning", "abstract": "Current speech encoding pipelines often rely on an additional text-based LM\nto get robust representations of human communication, even though SotA\nspeech-to-text models often have a LM within. This work proposes an approach to\nimprove the LM within an audio model such that the subsequent text-LM is\nunnecessary. We introduce WhiSPA (Whisper with Semantic and Psychological\nAlignment), which leverages a novel audio training objective: contrastive loss\nwith a language model embedding as a teacher. Using over 500k speech segments\nfrom mental health audio interviews, we evaluate the utility of aligning\nWhisper's latent space with semantic representations from a text autoencoder\n(SBERT) and lexically derived embeddings of basic psychological dimensions:\nemotion and personality. Over self-supervised affective tasks and downstream\npsychological tasks, WhiSPA surpasses current speech encoders, achieving an\naverage error reduction of 73.4% and 83.8%, respectively. WhiSPA demonstrates\nthat it is not always necessary to run a subsequent text LM on speech-to-text\noutput in order to get a rich psychological representation of human\ncommunication.", "published": "2025-01-15 06:30:17", "link": "http://arxiv.org/abs/2501.16344v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Benchmarking Robustness of Contrastive Learning Models for Medical\n  Image-Report Retrieval", "abstract": "Medical images and reports offer invaluable insights into patient health. The\nheterogeneity and complexity of these data hinder effective analysis. To bridge\nthis gap, we investigate contrastive learning models for cross-domain\nretrieval, which associates medical images with their corresponding clinical\nreports. This study benchmarks the robustness of four state-of-the-art\ncontrastive learning models: CLIP, CXR-RePaiR, MedCLIP, and CXR-CLIP. We\nintroduce an occlusion retrieval task to evaluate model performance under\nvarying levels of image corruption. Our findings reveal that all evaluated\nmodels are highly sensitive to out-of-distribution data, as evidenced by the\nproportional decrease in performance with increasing occlusion levels. While\nMedCLIP exhibits slightly more robustness, its overall performance remains\nsignificantly behind CXR-CLIP and CXR-RePaiR. CLIP, trained on a\ngeneral-purpose dataset, struggles with medical image-report retrieval,\nhighlighting the importance of domain-specific training data. The evaluation of\nthis work suggests that more effort needs to be spent on improving the\nrobustness of these models. By addressing these limitations, we can develop\nmore reliable cross-domain retrieval models for medical applications.", "published": "2025-01-15 20:37:04", "link": "http://arxiv.org/abs/2501.09134v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "IITKGP-ABSP Submission to LRE22: Language Recognition in Low-Resource\n  Settings", "abstract": "This is the detailed system description of the IITKGP-ABSP lab's submission\nto the NIST language recognition evaluation (LRE) 2022. The objective of this\nLRE (LRE22) is focused on recognizing 14 low-resourced African languages. Even\nthough NIST has provided additional training and development data, we develop\nour systems with additional constraints of extreme low-resource. Our primary\nfixed-set submission ensures the usage of only the LRE 22 development data that\ncontains the utterances of 14 target languages. We further restrict our system\nfrom using any pre-trained models for feature extraction or classifier\nfine-tuning. To address the issue of low-resource, our system relies on diverse\naudio augmentations followed by classifier fusions. Abiding by all the\nconstraints, the proposed methods achieve an EER of 11.43% and cost metric of\n0.41 in the LRE22 development set. For users with limited computational\nresources or limited storage/network capabilities, the proposed system will\nhelp achieve efficient LID performance.", "published": "2025-01-15 06:33:03", "link": "http://arxiv.org/abs/2501.08616v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Adaptive Data Augmentation with NaturalSpeech3 for Far-field Speaker\n  Verification", "abstract": "The scarcity of speaker-annotated far-field speech presents a significant\nchallenge in developing high-performance far-field speaker verification (SV)\nsystems. While data augmentation using large-scale near-field speech has been a\ncommon strategy to address this limitation, the mismatch in acoustic\nenvironments between near-field and far-field speech significantly hinders the\nimprovement of far-field SV effectiveness. In this paper, we propose an\nadaptive speech augmentation approach leveraging NaturalSpeech3, a pre-trained\nfoundation text-to-speech (TTS) model, to convert near-field speech into\nfar-field speech by incorporating far-field acoustic ambient noise for data\naugmentation. Specifically, we utilize FACodec from NaturalSpeech3 to decompose\nthe speech waveform into distinct embedding subspaces-content, prosody,\nspeaker, and residual (acoustic details) embeddings-and reconstruct the speech\nwaveform from these disentangled representations. In our method, the prosody,\ncontent, and residual embeddings of far-field speech are combined with speaker\nembeddings from near-field speech to generate augmented pseudo far-field speech\nthat maintains the speaker identity from the out-domain near-field speech while\npreserving the acoustic environment of the in-domain far-field speech. This\napproach not only serves as an effective strategy for augmenting training data\nfor far-field speaker verification but also extends to cross-data augmentation\nfor enrollment and test speech in evaluation trials.Experimental results on\nFFSVC demonstrate that the adaptive data augmentation method significantly\noutperforms traditional approaches, such as random noise addition and\nreverberation, as well as other competitive data augmentation strategies.", "published": "2025-01-15 09:50:19", "link": "http://arxiv.org/abs/2501.08691v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speech Synthesis along Perceptual Voice Quality Dimensions", "abstract": "While expressive speech synthesis or voice conversion systems mainly focus on\ncontrolling or manipulating abstract prosodic characteristics of speech, such\nas emotion or accent, we here address the control of perceptual voice qualities\n(PVQs) recognized by phonetic experts, which are speech properties at a lower\nlevel of abstraction. The ability to manipulate PVQs can be a valuable tool for\nteaching speech pathologists in training or voice actors. In this paper, we\nintegrate a Conditional Continuous-Normalizing-Flow-based method into a\nText-to-Speech system to modify perceptual voice attributes on a continuous\nscale. Unlike previous approaches, our system avoids direct manipulation of\nacoustic correlates and instead learns from examples. We demonstrate the\nsystem's capability by manipulating four voice qualities: Roughness,\nbreathiness, resonance and weight. Phonetic experts evaluated these\nmodifications, both for seen and unseen speaker conditions. The results\nhighlight both the system's strengths and areas for improvement.", "published": "2025-01-15 13:33:40", "link": "http://arxiv.org/abs/2501.08791v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "persoDA: Personalized Data Augmentation for Personalized ASR", "abstract": "Data augmentation (DA) is ubiquitously used in training of Automatic Speech\nRecognition (ASR) models. DA offers increased data variability, robustness and\ngeneralization against different acoustic distortions. Recently,\npersonalization of ASR models on mobile devices has been shown to improve Word\nError Rate (WER). This paper evaluates data augmentation in this context and\nproposes persoDA; a DA method driven by user's data utilized to personalize\nASR. persoDA aims to augment training with data specifically tuned towards\nacoustic characteristics of the end-user, as opposed to standard augmentation\nbased on Multi-Condition Training (MCT) that applies random reverberation and\nnoises. Our evaluation with an ASR conformer-based baseline trained on\nLibrispeech and personalized for VOICES shows that persoDA achieves a 13.9%\nrelative WER reduction over using standard data augmentation (using random\nnoise & reverberation). Furthermore, persoDA shows 16% to 20% faster\nconvergence over MCT.", "published": "2025-01-15 19:46:42", "link": "http://arxiv.org/abs/2501.09113v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards detecting the pathological subharmonic voicing with fully\n  convolutional neural networks", "abstract": "Many voice disorders induce subharmonic phonation, but voice signal analysis\nis currently lacking a technique to detect the presence of subharmonics\nreliably. Distinguishing subharmonic phonation from normal phonation is a\nchallenging task as both are nearly periodic phenomena. Subharmonic phonation\nadds cyclical variations to the normal glottal cycles. Hence, the estimation of\nsubharmonic period requires a wholistic analysis of the signals. Deep learning\nis an effective solution to this type of complex problem. This paper describes\nfully convolutional neural networks which are trained with synthesized\nsubharmonic voice signals to classify the subharmonic periods. Synthetic\nevaluation shows over 98% classification accuracy, and assessment of sustained\nvowel recordings demonstrates encouraging outcomes as well as the areas for\nfuture improvements.", "published": "2025-01-15 21:22:07", "link": "http://arxiv.org/abs/2501.09159v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Beyond Speaker Identity: Text Guided Target Speech Extraction", "abstract": "Target Speech Extraction (TSE) traditionally relies on explicit clues about\nthe speaker's identity like enrollment audio, face images, or videos, which may\nnot always be available. In this paper, we propose a text-guided TSE model\nStyleTSE that uses natural language descriptions of speaking style in addition\nto the audio clue to extract the desired speech from a given mixture. Our model\nintegrates a speech separation network adapted from SepFormer with a\nbi-modality clue network that flexibly processes both audio and text clues. To\ntrain and evaluate our model, we introduce a new dataset TextrolMix with speech\nmixtures and natural language descriptions. Experimental results demonstrate\nthat our method effectively separates speech based not only on who is speaking,\nbut also on how they are speaking, enhancing TSE in scenarios where traditional\naudio clues are absent. Demos are at:\nhttps://mingyue66.github.io/TextrolMix/demo/", "published": "2025-01-15 21:43:49", "link": "http://arxiv.org/abs/2501.09169v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards Lightweight and Stable Zero-shot TTS with Self-distilled\n  Representation Disentanglement", "abstract": "Zero-shot Text-To-Speech (TTS) synthesis shows great promise for personalized\nvoice customization through voice cloning. However, current methods for\nachieving zero-shot TTS heavily rely on large model scales and extensive\ntraining datasets to ensure satisfactory performance and generalizability\nacross various speakers. This raises concerns regarding both deployment costs\nand data security. In this paper, we present a lightweight and stable zero-shot\nTTS system. We introduce a novel TTS architecture designed to effectively model\nlinguistic content and various speaker attributes from source speech and prompt\nspeech, respectively. Furthermore, we present a two-stage self-distillation\nframework that constructs parallel data pairs for effectively disentangling\nlinguistic content and speakers from the perspective of training data.\nExtensive experiments show that our system exhibits excellent performance and\nsuperior stability on the zero-shot TTS tasks. Moreover, it shows markedly\nsuperior computational efficiency, with RTFs of 0.13 and 0.012 on the CPU and\nGPU, respectively.", "published": "2025-01-15 04:17:48", "link": "http://arxiv.org/abs/2501.08566v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sound Scene Synthesis at the DCASE 2024 Challenge", "abstract": "This paper presents Task 7 at the DCASE 2024 Challenge: sound scene\nsynthesis. Recent advances in sound synthesis and generative models have\nenabled the creation of realistic and diverse audio content. We introduce a\nstandardized evaluation framework for comparing different sound scene synthesis\nsystems, incorporating both objective and subjective metrics. The challenge\nattracted four submissions, which are evaluated using the Fr\\'echet Audio\nDistance (FAD) and human perceptual ratings. Our analysis reveals significant\ninsights into the current capabilities and limitations of sound scene synthesis\nsystems, while also highlighting areas for future improvement in this rapidly\nevolving field.", "published": "2025-01-15 05:15:54", "link": "http://arxiv.org/abs/2501.08587v1", "categories": ["cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
{"title": "Subject Disentanglement Neural Network for Speech Envelope\n  Reconstruction from EEG", "abstract": "Reconstructing speech envelopes from EEG signals is essential for exploring\nneural mechanisms underlying speech perception. Yet, EEG variability across\nsubjects and physiological artifacts complicate accurate reconstruction. To\naddress this problem, we introduce Subject Disentangling Neural Network\n(SDN-Net), which disentangles subject identity information from reconstructed\nspeech envelopes to enhance cross-subject reconstruction accuracy. SDN-Net\nintegrates three key components: MLA-Codec, MPN-MI, and CTA-MTDNN. The\nMLA-Codec, a fully convolutional neural network, decodes EEG signals into\nspeech envelopes. The CTA-MTDNN module, a multi-scale time-delay neural network\nwith channel and temporal attention, extracts subject identity features from\nEEG signals. Lastly, the MPN-MI module, a mutual information estimator with a\nmulti-layer perceptron, supervises the removal of subject identity information\nfrom the reconstructed speech envelope. Experiments on the Auditory EEG\nDecoding Dataset demonstrate that SDN-Net achieves superior performance in\ninner- and cross-subject speech envelope reconstruction compared to recent\nstate-of-the-art methods.", "published": "2025-01-15 10:08:07", "link": "http://arxiv.org/abs/2501.08693v1", "categories": ["eess.SP", "cs.HC", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "XMusic: Towards a Generalized and Controllable Symbolic Music Generation\n  Framework", "abstract": "In recent years, remarkable advancements in artificial intelligence-generated\ncontent (AIGC) have been achieved in the fields of image synthesis and text\ngeneration, generating content comparable to that produced by humans. However,\nthe quality of AI-generated music has not yet reached this standard, primarily\ndue to the challenge of effectively controlling musical emotions and ensuring\nhigh-quality outputs. This paper presents a generalized symbolic music\ngeneration framework, XMusic, which supports flexible prompts (i.e., images,\nvideos, texts, tags, and humming) to generate emotionally controllable and\nhigh-quality symbolic music. XMusic consists of two core components, XProjector\nand XComposer. XProjector parses the prompts of various modalities into\nsymbolic music elements (i.e., emotions, genres, rhythms and notes) within the\nprojection space to generate matching music. XComposer contains a Generator and\na Selector. The Generator generates emotionally controllable and melodious\nmusic based on our innovative symbolic music representation, whereas the\nSelector identifies high-quality symbolic music by constructing a multi-task\nlearning scheme involving quality assessment, emotion recognition, and genre\nrecognition tasks. In addition, we build XMIDI, a large-scale symbolic music\ndataset that contains 108,023 MIDI files annotated with precise emotion and\ngenre labels. Objective and subjective evaluations show that XMusic\nsignificantly outperforms the current state-of-the-art methods with impressive\nmusic quality. Our XMusic has been awarded as one of the nine Highlights of\nCollectibles at WAIC 2023. The project homepage of XMusic is\nhttps://xmusic-project.github.io.", "published": "2025-01-15 14:08:44", "link": "http://arxiv.org/abs/2501.08809v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Non-autoregressive Model for Joint STT and TTS", "abstract": "In this paper, we take a step towards jointly modeling automatic speech\nrecognition (STT) and speech synthesis (TTS) in a fully non-autoregressive way.\nWe develop a novel multimodal framework capable of handling the speech and text\nmodalities as input either individually or together. The proposed model can\nalso be trained with unpaired speech or text data owing to its multimodal\nnature. We further propose an iterative refinement strategy to improve the STT\nand TTS performance of our model such that the partial hypothesis at the output\ncan be fed back to the input of our model, thus iteratively improving both STT\nand TTS predictions. We show that our joint model can effectively perform both\nSTT and TTS tasks, outperforming the STT-specific baseline in all tasks and\nperforming competitively with the TTS-specific baseline across a wide range of\nevaluation metrics.", "published": "2025-01-15 19:42:41", "link": "http://arxiv.org/abs/2501.09104v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
