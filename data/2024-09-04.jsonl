{"title": "Comparative Study of Long Short-Term Memory (LSTM) and Quantum Long Short-Term Memory (QLSTM): Prediction of Stock Market Movement", "abstract": "In recent years, financial analysts have been trying to develop models to\npredict the movement of a stock price index. The task becomes challenging in\nvague economic, social, and political situations like in Pakistan. In this\nstudy, we employed efficient models of machine learning such as long short-term\nmemory (LSTM) and quantum long short-term memory (QLSTM) to predict the Karachi\nStock Exchange (KSE) 100 index by taking monthly data of twenty-six economic,\nsocial, political, and administrative indicators from February 2004 to December\n2020. The comparative results of LSTM and QLSTM predicted values of the KSE 100\nindex with the actual values suggested QLSTM a potential technique to predict\nstock market trends.", "published": "2024-09-04 19:34:37", "link": "http://arxiv.org/abs/2409.08297v1", "categories": ["q-fin.ST", "cs.AI", "cs.LG", "quant-ph"], "primary_category": "q-fin.ST"}
{"title": "Predicting Foreign Exchange EUR/USD direction using machine learning", "abstract": "The Foreign Exchange market is a significant market for speculators,\ncharacterized by substantial transaction volumes and high volatility.\nAccurately predicting the directional movement of currency pairs is essential\nfor formulating a sound financial investment strategy. This paper conducts a\ncomparative analysis of various machine learning models for predicting the\ndaily directional movement of the EUR/USD currency pair in the Foreign Exchange\nmarket. The analysis includes both decorrelated and non-decorrelated feature\nsets using Principal Component Analysis. Additionally, this study explores\nmeta-estimators, which involve stacking multiple estimators as input for\nanother estimator, aiming to achieve improved predictive performance.\nUltimately, our approach yielded a prediction accuracy of 58.52% for one-day\nahead forecasts, coupled with an annual return of 32.48% for the year 2022.", "published": "2024-09-04 12:05:03", "link": "http://arxiv.org/abs/2409.04471v2", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "Fitting an Equation to Data Impartially", "abstract": "We consider the problem of fitting a relationship (e.g. a potential\nscientific law) to data involving multiple variables. Ordinary (least squares)\nregression is not suitable for this because the estimated relationship will\ndiffer according to which variable is chosen as being dependent, and the\ndependent variable is unrealistically assumed to be the only variable which has\nany measurement error (noise). We present a very general method for estimating\na linear functional relationship between multiple noisy variables, which are\ntreated impartially, i.e. no distinction between dependent and independent\nvariables. The data are not assumed to follow any distribution, but all\nvariables are treated as being equally reliable. Our approach extends the\ngeometric mean functional relationship to multiple dimensions. This is\nespecially useful with variables measured in different units, as it is\nnaturally scale-invariant, whereas orthogonal regression is not. This is\nbecause our approach is not based on minimizing distances, but on the symmetric\nconcept of correlation. The estimated coefficients are easily obtained from the\ncovariances or correlations, and correspond to geometric means of associated\nleast squares coefficients. The ease of calculation will hopefully allow\nwidespread application of impartial fitting to estimate relationships in a\nneutral way.", "published": "2024-09-04 09:48:26", "link": "http://arxiv.org/abs/2409.02573v1", "categories": ["stat.ME", "econ.EM", "math.ST", "physics.data-an", "q-fin.ST", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Fundamental properties of linear factor models", "abstract": "We study conditional linear factor models in the context of asset pricing\npanels. Our analysis focuses on conditional means and covariances to\ncharacterize the cross-sectional and inter-temporal properties of returns and\nfactors as well as their interrelationships. We also review the conditions\noutlined in Kozak and Nagel (2024) and show how the conditional mean-variance\nefficient portfolio of an unbalanced panel can be spanned by low-dimensional\nfactor portfolios, even without assuming invertibility of the conditional\ncovariance matrices. Our analysis provides a comprehensive foundation for the\nspecification and estimation of conditional linear factor models.", "published": "2024-09-04 08:29:45", "link": "http://arxiv.org/abs/2409.02521v3", "categories": ["q-fin.ST", "stat.AP", "62P20"], "primary_category": "q-fin.ST"}
{"title": "MarS: a Financial Market Simulation Engine Powered by Generative Foundation Model", "abstract": "Generative models aim to simulate realistic effects of various actions across\ndifferent contexts, from text generation to visual effects. Despite significant\nefforts to build real-world simulators, the application of generative models to\nvirtual worlds, like financial markets, remains under-explored. In financial\nmarkets, generative models can simulate complex market effects of participants\nwith various behaviors, enabling interaction under different market conditions,\nand training strategies without financial risk. This simulation relies on the\nfinest structured data in financial market like orders thus building the finest\nrealistic simulation. We propose Large Market Model (LMM), an order-level\ngenerative foundation model, for financial market simulation, akin to language\nmodeling in the digital world. Our financial Market Simulation engine (MarS),\npowered by LMM, addresses the domain-specific need for realistic, interactive\nand controllable order generation. Key observations include LMM's strong\nscalability across data size and model complexity, and MarS's robust and\npracticable realism in controlled generation with market impact. We showcase\nMarS as a forecast tool, detection system, analysis platform, and agent\ntraining environment, thus demonstrating MarS's \"paradigm shift\" potential for\na variety of financial applications. We release the code of MarS at\nhttps://github.com/microsoft/MarS/.", "published": "2024-09-04 08:16:22", "link": "http://arxiv.org/abs/2409.07486v2", "categories": ["q-fin.CP", "cs.AI", "cs.CE", "cs.LG", "q-fin.TR"], "primary_category": "q-fin.CP"}
{"title": "Diversify-verify-adapt: Efficient and Robust Retrieval-Augmented\n  Ambiguous Question Answering", "abstract": "The retrieval augmented generation (RAG) framework addresses an ambiguity in\nuser queries in QA systems by retrieving passages that cover all plausible\ninterpretations and generating comprehensive responses based on the passages.\nHowever, our preliminary studies reveal that a single retrieval process often\nsuffers from low quality results, as the retrieved passages frequently fail to\ncapture all plausible interpretations. Although the iterative RAG approach has\nbeen proposed to address this problem, it comes at the cost of significantly\nreduced efficiency. To address these issues, we propose the\ndiversify-verify-adapt (DIVA) framework. DIVA first diversifies the retrieved\npassages to encompass diverse interpretations. Subsequently, DIVA verifies the\nquality of the passages and adapts the most suitable approach tailored to their\nquality. This approach improves the QA systems accuracy and robustness by\nhandling low quality retrieval issue in ambiguous questions, while enhancing\nefficiency.", "published": "2024-09-04 01:14:04", "link": "http://arxiv.org/abs/2409.02361v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Privacy-Savvy Are Large Language Models? A Case Study on Compliance\n  and Privacy Technical Review", "abstract": "The recent advances in large language models (LLMs) have significantly\nexpanded their applications across various fields such as language generation,\nsummarization, and complex question answering. However, their application to\nprivacy compliance and technical privacy reviews remains under-explored,\nraising critical concerns about their ability to adhere to global privacy\nstandards and protect sensitive user data. This paper seeks to address this gap\nby providing a comprehensive case study evaluating LLMs' performance in\nprivacy-related tasks such as privacy information extraction (PIE), legal and\nregulatory key point detection (KPD), and question answering (QA) with respect\nto privacy policies and data protection regulations. We introduce a Privacy\nTechnical Review (PTR) framework, highlighting its role in mitigating privacy\nrisks during the software development life-cycle. Through an empirical\nassessment, we investigate the capacity of several prominent LLMs, including\nBERT, GPT-3.5, GPT-4, and custom models, in executing privacy compliance checks\nand technical privacy reviews. Our experiments benchmark the models across\nmultiple dimensions, focusing on their precision, recall, and F1-scores in\nextracting privacy-sensitive information and detecting key regulatory\ncompliance points. While LLMs show promise in automating privacy reviews and\nidentifying regulatory discrepancies, significant gaps persist in their ability\nto fully comply with evolving legal standards. We provide actionable\nrecommendations for enhancing LLMs' capabilities in privacy compliance,\nemphasizing the need for robust model improvements and better integration with\nlegal and regulatory requirements. This study underscores the growing\nimportance of developing privacy-aware LLMs that can both support businesses in\ncompliance efforts and safeguard user privacy rights.", "published": "2024-09-04 01:51:37", "link": "http://arxiv.org/abs/2409.02375v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Determination of language families using deep learning", "abstract": "We use a c-GAN (convolutional generative adversarial) neural network to\nanalyze transliterated text fragments of extant, dead comprehensible, and one\ndead non-deciphered (Cypro-Minoan) language to establish linguistic affinities.\nThe paper is agnostic with respect to translation and/or deciphering. However,\nthere is hope that the proposed approach can be useful for decipherment with\nmore sophisticated neural network techniques.", "published": "2024-09-04 02:41:44", "link": "http://arxiv.org/abs/2409.02393v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "DetectiveQA: Evaluating Long-Context Reasoning on Detective Novels", "abstract": "Recently, significant efforts have been devoted to enhancing the long-context\ncapabilities of Large Language Models (LLMs), particularly in long-context\nreasoning. To facilitate this research, we propose \\textbf{DetectiveQA}, a\ndataset specifically designed for narrative reasoning within long contexts. We\nleverage detective novels, averaging over 100k tokens, to create a dataset\ncontaining 1200 human-annotated questions in both Chinese and English, each\npaired with corresponding reference reasoning steps. Furthermore, we introduce\na step-wise reasoning metric, which enhances the evaluation of LLMs' reasoning\nprocesses. We validate our approach and evaluate the mainstream LLMs, including\nGPT-4, Claude, and LLaMA, revealing persistent long-context reasoning\nchallenges and demonstrating their evidence-retrieval challenges. Our findings\noffer valuable insights into the study of long-context reasoning and lay the\nbase for more rigorous evaluations.", "published": "2024-09-04 06:28:22", "link": "http://arxiv.org/abs/2409.02465v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word and Phrase Features in Graph Convolutional Network for Automatic\n  Question Classification", "abstract": "Effective question classification is crucial for AI-driven educational tools,\nenabling adaptive learning systems to categorize questions by skill area,\ndifficulty level, and competence. This classification not only supports\neducational diagnostics and analytics but also enhances complex tasks like\ninformation retrieval and question answering by associating questions with\nrelevant categories. Traditional methods, often based on word embeddings and\nconventional classifiers, struggle to capture the nuanced relationships in\nnatural language, leading to suboptimal performance. To address this, we\npropose a novel approach leveraging graph convolutional networks, named Phrase\nQuestion-Graph Convolutional Network (PQ-GCN) to better model the inherent\nstructure of questions. By representing questions as graphs-where nodes signify\nwords or phrases and edges denote syntactic or semantic relationships-our\nmethod allows the model to learn from the interconnected nature of language\nmore effectively. Additionally, we explore the incorporation of phrase-based\nfeatures to enhance classification performance on question datasets of various\ndomains and characteristics. Our findings demonstrate that the proposed model,\naugmented with these features, offer a promising solution for more robust and\ncontext-aware question classification, bridging the gap between graph neural\nnetwork research and practical educational applications of AI.", "published": "2024-09-04 07:13:30", "link": "http://arxiv.org/abs/2409.02481v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PUB: Plot Understanding Benchmark and Dataset for Evaluating Large\n  Language Models on Synthetic Visual Data Interpretation", "abstract": "The ability of large language models (LLMs) to interpret visual\nrepresentations of data is crucial for advancing their application in data\nanalysis and decision-making processes. This paper presents a novel synthetic\ndataset designed to evaluate the proficiency of LLMs in interpreting various\nforms of data visualizations, including plots like time series, histograms,\nviolins, boxplots, and clusters. Our dataset is generated using controlled\nparameters to ensure comprehensive coverage of potential real-world scenarios.\nWe employ multimodal text prompts with questions related to visual data in\nimages to benchmark several state-of-the-art models like ChatGPT or Gemini,\nassessing their understanding and interpretative accuracy.\n  To ensure data integrity, our benchmark dataset is generated automatically,\nmaking it entirely new and free from prior exposure to the models being tested.\nThis strategy allows us to evaluate the models' ability to truly interpret and\nunderstand the data, eliminating possibility of pre-learned responses, and\nallowing for an unbiased evaluation of the models' capabilities. We also\nintroduce quantitative metrics to assess the performance of the models,\nproviding a robust and comprehensive evaluation tool.\n  Benchmarking several state-of-the-art LLMs with this dataset reveals varying\ndegrees of success, highlighting specific strengths and weaknesses in\ninterpreting diverse types of visual data. The results provide valuable\ninsights into the current capabilities of LLMs and identify key areas for\nimprovement. This work establishes a foundational benchmark for future research\nand development aimed at enhancing the visual interpretative abilities of\nlanguage models. In the future, improved LLMs with robust visual interpretation\nskills can significantly aid in automated data analysis, scientific research,\neducational tools, and business intelligence applications.", "published": "2024-09-04 11:19:17", "link": "http://arxiv.org/abs/2409.02617v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Creating Domain-Specific Translation Memories for Machine Translation\n  Fine-tuning: The TRENCARD Bilingual Cardiology Corpus", "abstract": "This article investigates how translation memories (TM) can be created by\ntranslators or other language professionals in order to compile domain-specific\nparallel corpora , which can then be used in different scenarios, such as\nmachine translation training and fine-tuning, TM leveraging, and/or large\nlanguage model fine-tuning. The article introduces a semi-automatic TM\npreparation methodology leveraging primarily translation tools used by\ntranslators in favor of data quality and control by the translators. This\nsemi-automatic methodology is then used to build a cardiology-based Turkish ->\nEnglish corpus from bilingual abstracts of Turkish cardiology journals. The\nresulting corpus called TRENCARD Corpus has approximately 800,000 source words\nand 50,000 sentences. Using this methodology, translators can build their\ncustom TMs in a reasonable time and use them in their bilingual data requiring\ntasks.", "published": "2024-09-04 12:48:30", "link": "http://arxiv.org/abs/2409.02667v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pre-training data selection for biomedical domain adaptation using\n  journal impact metrics", "abstract": "Domain adaptation is a widely used method in natural language processing\n(NLP) to improve the performance of a language model within a specific domain.\nThis method is particularly common in the biomedical domain, which sees regular\npublication of numerous scientific articles. PubMed, a significant corpus of\ntext, is frequently used in the biomedical domain. The primary objective of\nthis study is to explore whether refining a pre-training dataset using specific\nquality metrics for scientific papers can enhance the performance of the\nresulting model. To accomplish this, we employ two straightforward journal\nimpact metrics and conduct experiments by continually pre-training BERT on\nvarious subsets of the complete PubMed training set, we then evaluate the\nresulting models on biomedical language understanding tasks from the BLURB\nbenchmark. Our results show that pruning using journal impact metrics is not\nefficient. But we also show that pre-training using fewer abstracts (but with\nthe same number of training steps) does not necessarily decrease the resulting\nmodel's performance.", "published": "2024-09-04 13:59:48", "link": "http://arxiv.org/abs/2409.02725v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "A Comparative Study of Pre-training and Self-training", "abstract": "Pre-training and self-training are two approaches to semi-supervised\nlearning. The comparison between pre-training and self-training has been\nexplored. However, the previous works led to confusing findings: self-training\noutperforms pre-training experienced on some tasks in computer vision, and\ncontrarily, pre-training outperforms self-training experienced on some tasks in\nnatural language processing, under certain conditions of incomparable settings.\nWe propose, comparatively and exhaustively, an ensemble method to empirical\nstudy all feasible training paradigms combining pre-training, self-training,\nand fine-tuning within consistent foundational settings comparable to data\naugmentation. We conduct experiments on six datasets, four data augmentation,\nand imbalanced data for sentiment analysis and natural language inference\ntasks. Our findings confirm that the pre-training and fine-tuning paradigm\nyields the best overall performances. Moreover, self-training offers no\nadditional benefits when combined with semi-supervised pre-training.", "published": "2024-09-04 14:30:13", "link": "http://arxiv.org/abs/2409.02751v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards a Unified View of Preference Learning for Large Language Models:\n  A Survey", "abstract": "Large Language Models (LLMs) exhibit remarkably powerful capabilities. One of\nthe crucial factors to achieve success is aligning the LLM's output with human\npreferences. This alignment process often requires only a small amount of data\nto efficiently enhance the LLM's performance. While effective, research in this\narea spans multiple domains, and the methods involved are relatively complex to\nunderstand. The relationships between different methods have been\nunder-explored, limiting the development of the preference alignment. In light\nof this, we break down the existing popular alignment strategies into different\ncomponents and provide a unified framework to study the current alignment\nstrategies, thereby establishing connections among them. In this survey, we\ndecompose all the strategies in preference learning into four components:\nmodel, data, feedback, and algorithm. This unified view offers an in-depth\nunderstanding of existing alignment algorithms and also opens up possibilities\nto synergize the strengths of different strategies. Furthermore, we present\ndetailed working examples of prevalent existing algorithms to facilitate a\ncomprehensive understanding for the readers. Finally, based on our unified\nperspective, we explore the challenges and future research directions for\naligning large language models with human preferences.", "published": "2024-09-04 15:11:55", "link": "http://arxiv.org/abs/2409.02795v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CMM-Math: A Chinese Multimodal Math Dataset To Evaluate and Enhance the\n  Mathematics Reasoning of Large Multimodal Models", "abstract": "Large language models (LLMs) have obtained promising results in mathematical\nreasoning, which is a foundational skill for human intelligence. Most previous\nstudies focus on improving and measuring the performance of LLMs based on\ntextual math reasoning datasets (e.g., MATH, GSM8K). Recently, a few\nresearchers have released English multimodal math datasets (e.g., MATHVISTA and\nMATH-V) to evaluate the effectiveness of large multimodal models (LMMs). In\nthis paper, we release a Chinese multimodal math (CMM-Math) dataset, including\nbenchmark and training parts, to evaluate and enhance the mathematical\nreasoning of LMMs. CMM-Math contains over 28,000 high-quality samples,\nfeaturing a variety of problem types (e.g., multiple-choice, fill-in-the-blank,\nand so on) with detailed solutions across 12 grade levels from elementary to\nhigh school in China. Specifically, the visual context may be present in the\nquestions or opinions, which makes this dataset more challenging. Through\ncomprehensive analysis, we discover that state-of-the-art LMMs on the CMM-Math\ndataset face challenges, emphasizing the necessity for further improvements in\nLMM development. We also propose a Multimodal Mathematical LMM (Math-LMM) to\nhandle the problems with mixed input of multiple images and text segments. We\ntrain our model using three stages, including foundational pre-training,\nfoundational fine-tuning, and mathematical fine-tuning. The extensive\nexperiments indicate that our model effectively improves math reasoning\nperformance by comparing it with the SOTA LMMs over three multimodal\nmathematical datasets.", "published": "2024-09-04 16:00:21", "link": "http://arxiv.org/abs/2409.02834v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Historical German Text Normalization Using Type- and Token-Based\n  Language Modeling", "abstract": "Historic variations of spelling poses a challenge for full-text search or\nnatural language processing on historical digitized texts. To minimize the gap\nbetween the historic orthography and contemporary spelling, usually an\nautomatic orthographic normalization of the historical source material is\npursued. This report proposes a normalization system for German literary texts\nfrom c. 1700-1900, trained on a parallel corpus. The proposed system makes use\nof a machine learning approach using Transformer language models, combining an\nencoder-decoder model to normalize individual word types, and a pre-trained\ncausal language model to adjust these normalizations within their context. An\nextensive evaluation shows that the proposed system provides state-of-the-art\naccuracy, comparable with a much larger fully end-to-end sentence-based\nnormalization system, fine-tuning a pre-trained Transformer large language\nmodel. However, the normalization of historical text remains a challenge due to\ndifficulties for models to generalize, and the lack of extensive high-quality\nparallel data.", "published": "2024-09-04 16:14:05", "link": "http://arxiv.org/abs/2409.02841v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LongCite: Enabling LLMs to Generate Fine-grained Citations in\n  Long-context QA", "abstract": "Though current long-context large language models (LLMs) have demonstrated\nimpressive capacities in answering user questions based on extensive text, the\nlack of citations in their responses makes user verification difficult, leading\nto concerns about their trustworthiness due to their potential hallucinations.\nIn this work, we aim to enable long-context LLMs to generate responses with\nfine-grained sentence-level citations, improving their faithfulness and\nverifiability. We first introduce LongBench-Cite, an automated benchmark for\nassessing current LLMs' performance in Long-Context Question Answering with\nCitations (LQAC), revealing considerable room for improvement. To this end, we\npropose CoF (Coarse to Fine), a novel pipeline that utilizes off-the-shelf LLMs\nto automatically generate long-context QA instances with precise sentence-level\ncitations, and leverage this pipeline to construct LongCite-45k, a large-scale\nSFT dataset for LQAC. Finally, we train LongCite-8B and LongCite-9B using the\nLongCite-45k dataset, successfully enabling their generation of accurate\nresponses and fine-grained sentence-level citations in a single output. The\nevaluation results on LongBench-Cite show that our trained models achieve\nstate-of-the-art citation quality, surpassing advanced proprietary models\nincluding GPT-4o.", "published": "2024-09-04 17:41:19", "link": "http://arxiv.org/abs/2409.02897v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Oddballness: universal anomaly detection with language models", "abstract": "We present a new method to detect anomalies in texts (in general: in\nsequences of any data), using language models, in a totally unsupervised\nmanner. The method considers probabilities (likelihoods) generated by a\nlanguage model, but instead of focusing on low-likelihood tokens, it considers\na new metric introduced in this paper: oddballness. Oddballness measures how\n``strange'' a given token is according to the language model. We demonstrate in\ngrammatical error detection tasks (a specific case of text anomaly detection)\nthat oddballness is better than just considering low-likelihood events, if a\ntotally unsupervised setup is assumed.", "published": "2024-09-04 19:31:20", "link": "http://arxiv.org/abs/2409.03046v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantification of stylistic differences in human- and ASR-produced\n  transcripts of African American English", "abstract": "Common measures of accuracy used to assess the performance of automatic\nspeech recognition (ASR) systems, as well as human transcribers, conflate\nmultiple sources of error. Stylistic differences, such as verbatim vs\nnon-verbatim, can play a significant role in ASR performance evaluation when\ndifferences exist between training and test datasets. The problem is compounded\nfor speech from underrepresented varieties, where the speech to orthography\nmapping is not as standardized. We categorize the kinds of stylistic\ndifferences between 6 transcription versions, 4 human- and 2 ASR-produced, of\n10 hours of African American English (AAE) speech. Focusing on verbatim\nfeatures and AAE morphosyntactic features, we investigate the interactions of\nthese categories with how well transcripts can be compared via word error rate\n(WER). The results, and overall analysis, help clarify how ASR outputs are a\nfunction of the decisions made by the training data's human transcribers.", "published": "2024-09-04 20:18:59", "link": "http://arxiv.org/abs/2409.03059v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Large Language Models Possess Sensitive to Sentiment?", "abstract": "Large Language Models (LLMs) have recently displayed their extraordinary\ncapabilities in language understanding. However, how to comprehensively assess\nthe sentiment capabilities of LLMs continues to be a challenge. This paper\ninvestigates the ability of LLMs to detect and react to sentiment in text\nmodal. As the integration of LLMs into diverse applications is on the rise, it\nbecomes highly critical to comprehend their sensitivity to emotional tone, as\nit can influence the user experience and the efficacy of sentiment-driven\ntasks. We conduct a series of experiments to evaluate the performance of\nseveral prominent LLMs in identifying and responding appropriately to\nsentiments like positive, negative, and neutral emotions. The models' outputs\nare analyzed across various sentiment benchmarks, and their responses are\ncompared with human evaluations. Our discoveries indicate that although LLMs\nshow a basic sensitivity to sentiment, there are substantial variations in\ntheir accuracy and consistency, emphasizing the requirement for further\nenhancements in their training processes to better capture subtle emotional\ncues. Take an example in our findings, in some cases, the models might wrongly\nclassify a strongly positive sentiment as neutral, or fail to recognize sarcasm\nor irony in the text. Such misclassifications highlight the complexity of\nsentiment analysis and the areas where the models need to be refined. Another\naspect is that different LLMs might perform differently on the same set of\ndata, depending on their architecture and training datasets. This variance\ncalls for a more in-depth study of the factors that contribute to the\nperformance differences and how they can be optimized.", "published": "2024-09-04 01:40:20", "link": "http://arxiv.org/abs/2409.02370v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models and Cognitive Science: A Comprehensive Review of\n  Similarities, Differences, and Challenges", "abstract": "This comprehensive review explores the intersection of Large Language Models\n(LLMs) and cognitive science, examining similarities and differences between\nLLMs and human cognitive processes. We analyze methods for evaluating LLMs\ncognitive abilities and discuss their potential as cognitive models. The review\ncovers applications of LLMs in various cognitive fields, highlighting insights\ngained for cognitive science research. We assess cognitive biases and\nlimitations of LLMs, along with proposed methods for improving their\nperformance. The integration of LLMs with cognitive architectures is examined,\nrevealing promising avenues for enhancing artificial intelligence (AI)\ncapabilities. Key challenges and future research directions are identified,\nemphasizing the need for continued refinement of LLMs to better align with\nhuman cognition. This review provides a balanced perspective on the current\nstate and future potential of LLMs in advancing our understanding of both\nartificial and human intelligence.", "published": "2024-09-04 02:30:12", "link": "http://arxiv.org/abs/2409.02387v6", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Comparative Study on Large Language Models for Log Parsing", "abstract": "Background: Log messages provide valuable information about the status of\nsoftware systems. This information is provided in an unstructured fashion and\nautomated approaches are applied to extract relevant parameters. To ease this\nprocess, log parsing can be applied, which transforms log messages into\nstructured log templates. Recent advances in language models have led to\nseveral studies that apply ChatGPT to the task of log parsing with promising\nresults. However, the performance of other state-of-the-art large language\nmodels (LLMs) on the log parsing task remains unclear.\n  Aims: In this study, we investigate the current capability of\nstate-of-the-art LLMs to perform log parsing.\n  Method: We select six recent LLMs, including both paid proprietary (GPT-3.5,\nClaude 2.1) and four free-to-use open models, and compare their performance on\nsystem logs obtained from a selection of mature open-source projects. We design\ntwo different prompting approaches and apply the LLMs on 1, 354 log templates\nacross 16 different projects. We evaluate their effectiveness, in the number of\ncorrectly identified templates, and the syntactic similarity between the\ngenerated templates and the ground truth.\n  Results: We found that free-to-use models are able to compete with paid\nmodels, with CodeLlama extracting 10% more log templates correctly than\nGPT-3.5. Moreover, we provide qualitative insights into the usability of\nlanguage models (e.g., how easy it is to use their responses).\n  Conclusions: Our results reveal that some of the smaller, free-to-use LLMs\ncan considerably assist log parsing compared to their paid proprietary\ncompetitors, especially code-specialized models.", "published": "2024-09-04 06:46:31", "link": "http://arxiv.org/abs/2409.02474v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic\n  Reasoning with Argumentation Theory-Driven Prompts", "abstract": "We propose misogyny detection as an Argumentative Reasoning task and we\ninvestigate the capacity of large language models (LLMs) to understand the\nimplicit reasoning used to convey misogyny in both Italian and English. The\ncentral aim is to generate the missing reasoning link between a message and the\nimplied meanings encoding the misogyny. Our study uses argumentation theory as\na foundation to form a collection of prompts in both zero-shot and few-shot\nsettings. These prompts integrate different techniques, including\nchain-of-thought reasoning and augmented knowledge. Our findings show that LLMs\nfall short on reasoning capabilities about misogynistic comments and that they\nmostly rely on their implicit knowledge derived from internalized common\nstereotypes about women to generate implied assumptions, rather than on\ninductive reasoning.", "published": "2024-09-04 08:27:43", "link": "http://arxiv.org/abs/2409.02519v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Emergent Language: A Survey and Taxonomy", "abstract": "The field of emergent language represents a novel area of research within the\ndomain of artificial intelligence, particularly within the context of\nmulti-agent reinforcement learning. Although the concept of studying language\nemergence is not new, early approaches were primarily concerned with explaining\nhuman language formation, with little consideration given to its potential\nutility for artificial agents. In contrast, studies based on reinforcement\nlearning aim to develop communicative capabilities in agents that are\ncomparable to or even superior to human language. Thus, they extend beyond the\nlearned statistical representations that are common in natural language\nprocessing research. This gives rise to a number of fundamental questions, from\nthe prerequisites for language emergence to the criteria for measuring its\nsuccess. This paper addresses these questions by providing a comprehensive\nreview of 181 scientific publications on emergent language in artificial\nintelligence. Its objective is to serve as a reference for researchers\ninterested in or proficient in the field. Consequently, the main contributions\nare the definition and overview of the prevailing terminology, the analysis of\nexisting evaluation methods and metrics, and the description of the identified\nresearch gaps.", "published": "2024-09-04 12:22:05", "link": "http://arxiv.org/abs/2409.02645v2", "categories": ["cs.MA", "cs.CL"], "primary_category": "cs.MA"}
{"title": "OpenFact at CheckThat! 2024: Combining Multiple Attack Methods for\n  Effective Adversarial Text Generation", "abstract": "This paper presents the experiments and results for the CheckThat! Lab at\nCLEF 2024 Task 6: Robustness of Credibility Assessment with Adversarial\nExamples (InCrediblAE). The primary objective of this task was to generate\nadversarial examples in five problem domains in order to evaluate the\nrobustness of widely used text classification methods (fine-tuned BERT, BiLSTM,\nand RoBERTa) when applied to credibility assessment issues.\n  This study explores the application of ensemble learning to enhance\nadversarial attacks on natural language processing (NLP) models. We\nsystematically tested and refined several adversarial attack methods, including\nBERT-Attack, Genetic algorithms, TextFooler, and CLARE, on five datasets across\nvarious misinformation tasks. By developing modified versions of BERT-Attack\nand hybrid methods, we achieved significant improvements in attack\neffectiveness. Our results demonstrate the potential of modification and\ncombining multiple methods to create more sophisticated and effective\nadversarial attack strategies, contributing to the development of more robust\nand secure systems.", "published": "2024-09-04 12:26:26", "link": "http://arxiv.org/abs/2409.02649v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Detecting Calls to Action in Multimodal Content: Analysis of the 2021\n  German Federal Election Campaign on Instagram", "abstract": "This study investigates the automated classification of Calls to Action\n(CTAs) within the 2021 German Instagram election campaign to advance the\nunderstanding of mobilization in social media contexts. We analyzed over 2,208\nInstagram stories and 712 posts using fine-tuned BERT models and OpenAI's GPT-4\nmodels. The fine-tuned BERT model incorporating synthetic training data\nachieved a macro F1 score of 0.93, demonstrating a robust classification\nperformance. Our analysis revealed that 49.58% of Instagram posts and 10.64% of\nstories contained CTAs, highlighting significant differences in mobilization\nstrategies between these content types. Additionally, we found that FDP and the\nGreens had the highest prevalence of CTAs in posts, whereas CDU and CSU led in\nstory CTAs.", "published": "2024-09-04 13:23:50", "link": "http://arxiv.org/abs/2409.02690v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "A Data Selection Approach for Enhancing Low Resource Machine Translation\n  Using Cross-Lingual Sentence Representations", "abstract": "Machine translation in low-resource language pairs faces significant\nchallenges due to the scarcity of parallel corpora and linguistic resources.\nThis study focuses on the case of English-Marathi language pairs, where\nexisting datasets are notably noisy, impeding the performance of machine\ntranslation models. To mitigate the impact of data quality issues, we propose a\ndata filtering approach based on cross-lingual sentence representations. Our\nmethodology leverages a multilingual SBERT model to filter out problematic\ntranslations in the training data. Specifically, we employ an IndicSBERT\nsimilarity model to assess the semantic equivalence between original and\ntranslated sentences, allowing us to retain linguistically correct translations\nwhile discarding instances with substantial deviations. The results demonstrate\na significant improvement in translation quality over the baseline\npost-filtering with IndicSBERT. This illustrates how cross-lingual sentence\nrepresentations can reduce errors in machine translation scenarios with limited\nresources. By integrating multilingual sentence BERT models into the\ntranslation pipeline, this research contributes to advancing machine\ntranslation techniques in low-resource environments. The proposed method not\nonly addresses the challenges in English-Marathi language pairs but also\nprovides a valuable framework for enhancing translation quality in other\nlow-resource language translation tasks.", "published": "2024-09-04 13:49:45", "link": "http://arxiv.org/abs/2409.02712v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "\"Yes, My LoRD.\" Guiding Language Model Extraction with Locality\n  Reinforced Distillation", "abstract": "Model extraction attacks (MEAs) on large language models (LLMs) have received\nincreasing attention in recent research. However, existing attack methods\ntypically adapt the extraction strategies originally developed for deep neural\nnetworks (DNNs). They neglect the underlying inconsistency between the training\ntasks of MEA and LLM alignment, leading to suboptimal attack performance. To\ntackle this issue, we propose Locality Reinforced Distillation (LoRD), a novel\nmodel extraction algorithm specifically designed for LLMs. In particular, LoRD\nemploys a newly defined policy-gradient-style training task that utilizes the\nresponses of victim model as the signal to guide the crafting of preference for\nthe local model. Theoretical analyses demonstrate that I) The convergence\nprocedure of LoRD in model extraction is consistent with the alignment\nprocedure of LLMs, and II) LoRD can reduce query complexity while mitigating\nwatermark protection through our exploration-based stealing. Extensive\nexperiments validate the superiority of our method in extracting various\nstate-of-the-art commercial LLMs. Our code is available at:\nhttps://github.com/liangzid/LoRD-MEA.", "published": "2024-09-04 13:54:38", "link": "http://arxiv.org/abs/2409.02718v2", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Pooling And Attention: What Are Effective Designs For LLM-Based\n  Embedding Models?", "abstract": "The significant advancements of Large Language Models (LLMs) in generative\ntasks have led to a growing body of work exploring LLM-based embedding models.\nWhile these models, employing different pooling and attention strategies, have\nachieved state-of-the-art performance on public embedding benchmarks, questions\nstill arise about what constitutes an effective design for LLM-based embedding\nmodels. However, these models are often trained on different datasets, using\ndifferent LLM base models or training settings. Moreover, evaluations on public\nembedding benchmarks often fail to report statistical significance, making it\ndifficult to determine which designs truly contribute to final performance.\nThis complicates the process for practitioners seeking optimal training recipes\nfor LLM-based embedding models. In this study, we conduct a large-scale\nexperiment by training a series of LLM-based embedding models using the same\ntraining data and base model but differing in their pooling and attention\nstrategies. The results show that there is no one-size-fits-all solution: while\nbidirectional attention and an additional trainable pooling layer outperform in\ntext similarity and information retrieval tasks, they do not significantly\nsurpass simpler designs like EOS-last token pooling and default causal\nattention in clustering and classification tasks. Furthermore, we propose a new\npooling strategy, Multi-Layers Trainable Pooling, which transforms the outputs\nof all hidden layers, rather than just the last layer, using a cross-attention\nnetwork. This method proves to be statistically superior in text similarity and\nretrieval tasks compared to existing pooling methods. Overall, this paper sheds\nlight on effective training strategies for LLM-based embedding models.", "published": "2024-09-04 14:01:48", "link": "http://arxiv.org/abs/2409.02727v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding\n  Benchmark", "abstract": "This paper introduces MMMU-Pro, a robust version of the Massive\nMulti-discipline Multimodal Understanding and Reasoning (MMMU) benchmark.\nMMMU-Pro rigorously assesses multimodal models' true understanding and\nreasoning capabilities through a three-step process based on MMMU: (1)\nfiltering out questions answerable by text-only models, (2) augmenting\ncandidate options, and (3) introducing a vision-only input setting where\nquestions are embedded within images. This setting challenges AI to truly \"see\"\nand \"read\" simultaneously, testing a fundamental human cognitive skill of\nseamlessly integrating visual and textual information. Results show that model\nperformance is substantially lower on MMMU-Pro than on MMMU, ranging from 16.8%\nto 26.9% across models. We explore the impact of OCR prompts and Chain of\nThought (CoT) reasoning, finding that OCR prompts have minimal effect while CoT\ngenerally improves performance. MMMU-Pro provides a more rigorous evaluation\ntool, closely mimicking real-world scenarios and offering valuable directions\nfor future research in multimodal AI.", "published": "2024-09-04 15:31:26", "link": "http://arxiv.org/abs/2409.02813v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "R2GQA: Retriever-Reader-Generator Question Answering System to Support\n  Students Understanding Legal Regulations in Higher Education", "abstract": "In this article, we propose the R2GQA system, a Retriever-Reader-Generator\nQuestion Answering system, consisting of three main components: Document\nRetriever, Machine Reader, and Answer Generator. The Retriever module employs\nadvanced information retrieval techniques to extract the context of articles\nfrom a dataset of legal regulation documents. The Machine Reader module\nutilizes state-of-the-art natural language understanding algorithms to\ncomprehend the retrieved documents and extract answers. Finally, the Generator\nmodule synthesizes the extracted answers into concise and informative responses\nto questions of students regarding legal regulations. Furthermore, we built the\nViRHE4QA dataset in the domain of university training regulations, comprising\n9,758 question-answer pairs with a rigorous construction process. This is the\nfirst Vietnamese dataset in the higher regulations domain with various types of\nanswers, both extractive and abstractive. In addition, the R2GQA system is the\nfirst system to offer abstractive answers in Vietnamese. This paper discusses\nthe design and implementation of each module within the R2GQA system on the\nViRHE4QA dataset, highlighting their functionalities and interactions.\nFurthermore, we present experimental results demonstrating the effectiveness\nand utility of the proposed system in supporting the comprehension of students\nof legal regulations in higher education settings. In general, the R2GQA system\nand the ViRHE4QA dataset promise to contribute significantly to related\nresearch and help students navigate complex legal documents and regulations,\nempowering them to make informed decisions and adhere to institutional policies\neffectively. Our dataset is available for research purposes.", "published": "2024-09-04 16:12:30", "link": "http://arxiv.org/abs/2409.02840v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CLUE: Concept-Level Uncertainty Estimation for Large Language Models", "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in\nvarious natural language generation (NLG) tasks. Previous studies suggest that\nLLMs' generation process involves uncertainty. However, existing approaches to\nuncertainty estimation mainly focus on sequence-level uncertainty, overlooking\nindividual pieces of information within sequences. These methods fall short in\nseparately assessing the uncertainty of each component in a sequence. In\nresponse, we propose a novel framework for Concept-Level Uncertainty Estimation\n(CLUE) for LLMs. We leverage LLMs to convert output sequences into\nconcept-level representations, breaking down sequences into individual concepts\nand measuring the uncertainty of each concept separately. We conduct\nexperiments to demonstrate that CLUE can provide more interpretable uncertainty\nestimation results compared with sentence-level uncertainty, and could be a\nuseful tool for various tasks such as hallucination detection and story\ngeneration.", "published": "2024-09-04 18:27:12", "link": "http://arxiv.org/abs/2409.03021v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Probing self-attention in self-supervised speech models for\n  cross-linguistic differences", "abstract": "Speech models have gained traction thanks to increase in accuracy from novel\ntransformer architectures. While this impressive increase in performance across\nautomatic speech recognition (ASR) benchmarks is noteworthy, there is still\nmuch that is unknown about the use of attention mechanisms for speech-related\ntasks. For example, while it is assumed that these models are learning\nlanguage-independent (i.e., universal) speech representations, there has not\nyet been an in-depth exploration of what it would mean for the models to be\nlanguage-independent. In the current paper, we explore this question within the\nrealm of self-attention mechanisms of one small self-supervised speech\ntransformer model (TERA). We find that even with a small model, the attention\nheads learned are diverse ranging from almost entirely diagonal to almost\nentirely global regardless of the training language. We highlight some notable\ndifferences in attention patterns between Turkish and English and demonstrate\nthat the models do learn important phonological information during pretraining.\nWe also present a head ablation study which shows that models across languages\nprimarily rely on diagonal heads to classify phonemes.", "published": "2024-09-04 22:47:33", "link": "http://arxiv.org/abs/2409.03115v1", "categories": ["cs.CL", "cs.LG", "68T10"], "primary_category": "cs.CL"}
{"title": "Well, that escalated quickly: The Single-Turn Crescendo Attack (STCA)", "abstract": "This paper introduces a new method for adversarial attacks on large language\nmodels (LLMs) called the Single-Turn Crescendo Attack (STCA). Building on the\nmulti-turn crescendo attack method introduced by Russinovich, Salem, and Eldan\n(2024), which gradually escalates the context to provoke harmful responses, the\nSTCA achieves similar outcomes in a single interaction. By condensing the\nescalation into a single, well-crafted prompt, the STCA bypasses typical\nmoderation filters that LLMs use to prevent inappropriate outputs. This\ntechnique reveals vulnerabilities in current LLMs and emphasizes the importance\nof stronger safeguards in responsible AI (RAI). The STCA offers a novel method\nthat has not been previously explored.", "published": "2024-09-04 23:45:10", "link": "http://arxiv.org/abs/2409.03131v2", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "NESTFUL: A Benchmark for Evaluating LLMs on Nested Sequences of API\n  Calls", "abstract": "The resurgence of autonomous agents built using large language models (LLMs)\nto solve complex real-world tasks has brought increased focus on LLMs'\nfundamental ability of tool or function calling. At the core of these agents,\nan LLM must plan, execute, and respond using external tools, APIs, and custom\nfunctions. Research on tool calling has gathered momentum, but evaluation\nbenchmarks and datasets representing the complexity of the tasks have lagged\nbehind. In this work, we focus on one such complexity, nested sequencing, with\nthe goal of extending existing benchmarks and evaluation. Specifically, we\npresent NESTFUL, a benchmark to evaluate LLMs on nested sequences of API calls,\ni.e., sequences where the output of one API call is passed as input to a\nsubsequent call. NESTFUL contains 1800+ nested sequences where all the function\ncalls are executable. Experimental results on multiple models and settings show\nthat the best-performing model on the dataset has a full sequence match\naccuracy of 25% and win-rate of 34% necessitating a large scope for improvement\nin the nested sequencing aspect of function calling. Our analysis of these\nresults provides possible future research directions for the community, in\naddition to a benchmark to track progress. We have released the NESTFUL dataset\nunder the Apache 2.0 license at https://github.com/IBM/NESTFUL.", "published": "2024-09-04 17:53:24", "link": "http://arxiv.org/abs/2409.03797v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Prompt Baking", "abstract": "Two primary ways to change LLM behavior are prompting and weight updates\n(e.g., fine-tuning). Prompting LLMs is simple and effective, specifying the\ndesired changes explicitly in natural language, whereas weight updates provide\nmore expressive and permanent behavior changes, specified implicitly via\ntraining on large datasets. We present a technique for \"baking\" prompts into\nthe weights of an LLM. Prompt Baking converts a prompt $u$ and initial weights\n$\\theta$ to a new set of weights $\\theta_u$ such that new \"baked\" LLM behaves\nlike the original prompted LLM. Mathematically, we minimize the KL divergence\nbetween $P_\\theta(\\cdot | u)$ and $P_{\\theta_u}(\\cdot)$, where $P$ is the LLM's\nprobability distribution over token sequences. Across all our experiments, we\nfind prompts can be readily baked into weight updates. Baking chain-of-thought\nprompts improves zero-shot performance on GSM8K, ASDiv, MBPP, ARC-Easy,\nARC-Challenge, and CommonsenseQA benchmarks. Baking news headlines directly\nupdates an LLM's knowledge. And baking instructions & personas alleviates\n\"prompt forgetting\" over long sequences. Furthermore, stopping baking early\ncreates \"half-baked\" models, continuously scaling prompt strength. Baked models\nretain their sensitivity to further prompting and baking, including\nre-prompting with the baked-in prompt. Surprisingly, the re-prompted models\nyield further performance gains in instruction following, as well as math\nreasoning and coding benchmarks. Taking re-prompting and re-baking to the limit\nyields a form of iterative self-improvement we call Prompt Pursuit, and\npreliminary results on instruction following exhibit dramatic performance\ngains. Finally, we discuss implications for AI safety, continuous model\nupdating, enhancing real-time learning capabilities in LLM-based agents, and\ngenerating more stable AI personas.", "published": "2024-09-04 04:13:16", "link": "http://arxiv.org/abs/2409.13697v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NUDGE: Lightweight Non-Parametric Fine-Tuning of Embeddings for\n  Retrieval", "abstract": "$k$-Nearest Neighbor search on dense vector embeddings ($k$-NN retrieval)\nfrom pre-trained embedding models is the predominant retrieval method for text\nand images, as well as Retrieval-Augmented Generation (RAG) pipelines. In\npractice, application developers often fine-tune the embeddings to improve\ntheir accuracy on the dataset and query workload in hand. Existing approaches\neither fine-tune the pre-trained model itself or, more efficiently, but at the\ncost of accuracy, train adaptor models to transform the output of the\npre-trained model. We present NUDGE, a family of novel non-parametric embedding\nfine-tuning approaches that are significantly more accurate and efficient than\nboth sets of existing approaches. NUDGE directly modifies the embeddings of\ndata records to maximize the accuracy of $k$-NN retrieval. We present a\nthorough theoretical and experimental study of NUDGE's non-parametric approach.\nWe show that even though the underlying problem is NP-Hard, constrained\nvariations can be solved efficiently. These constraints additionally ensure\nthat the changes to the embeddings are modest, avoiding large distortions to\nthe semantics learned during pre-training. In experiments across five\npre-trained models and nine standard text and image retrieval datasets, NUDGE\nruns in minutes and often improves NDCG@10 by more than 10% over existing\nfine-tuning methods. On average, NUDGE provides 3.3x and 4.3x higher increase\nin accuracy and runs 200x and 3x faster, respectively, over fine-tuning the\npre-trained model and training adaptors.", "published": "2024-09-04 00:10:36", "link": "http://arxiv.org/abs/2409.02343v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "STAB: Speech Tokenizer Assessment Benchmark", "abstract": "Representing speech as discrete tokens provides a framework for transforming\nspeech into a format that closely resembles text, thus enabling the use of\nspeech as an input to the widely successful large language models (LLMs).\nCurrently, while several speech tokenizers have been proposed, there is\nambiguity regarding the properties that are desired from a tokenizer for\nspecific downstream tasks and its overall generalizability. Evaluating the\nperformance of tokenizers across different downstream tasks is a\ncomputationally intensive effort that poses challenges for scalability. To\ncircumvent this requirement, we present STAB (Speech Tokenizer Assessment\nBenchmark), a systematic evaluation framework designed to assess speech\ntokenizers comprehensively and shed light on their inherent characteristics.\nThis framework provides a deeper understanding of the underlying mechanisms of\nspeech tokenization, thereby offering a valuable resource for expediting the\nadvancement of future tokenizer models and enabling comparative analysis using\na standardized benchmark. We evaluate the STAB metrics and correlate this with\ndownstream task performance across a range of speech tasks and tokenizer\nchoices.", "published": "2024-09-04 02:20:59", "link": "http://arxiv.org/abs/2409.02384v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Abstractive Text Summarization: State of the Art, Challenges, and\n  Improvements", "abstract": "Specifically focusing on the landscape of abstractive text summarization, as\nopposed to extractive techniques, this survey presents a comprehensive\noverview, delving into state-of-the-art techniques, prevailing challenges, and\nprospective research directions. We categorize the techniques into traditional\nsequence-to-sequence models, pre-trained large language models, reinforcement\nlearning, hierarchical methods, and multi-modal summarization. Unlike prior\nworks that did not examine complexities, scalability and comparisons of\ntechniques in detail, this review takes a comprehensive approach encompassing\nstate-of-the-art methods, challenges, solutions, comparisons, limitations and\ncharts out future improvements - providing researchers an extensive overview to\nadvance abstractive summarization research. We provide vital comparison tables\nacross techniques categorized - offering insights into model complexity,\nscalability and appropriate applications. The paper highlights challenges such\nas inadequate meaning representation, factual consistency, controllable text\nsummarization, cross-lingual summarization, and evaluation metrics, among\nothers. Solutions leveraging knowledge incorporation and other innovative\nstrategies are proposed to address these challenges. The paper concludes by\nhighlighting emerging research areas like factual inconsistency,\ndomain-specific, cross-lingual, multilingual, and long-document summarization,\nas well as handling noisy data. Our objective is to provide researchers and\npractitioners with a structured overview of the domain, enabling them to better\nunderstand the current landscape and identify potential areas for further\nresearch and improvement.", "published": "2024-09-04 03:39:23", "link": "http://arxiv.org/abs/2409.02413v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What is lost in Normalization? Exploring Pitfalls in Multilingual ASR\n  Model Evaluations", "abstract": "This paper explores the pitfalls in evaluating multilingual automatic speech\nrecognition (ASR) models, with a particular focus on Indic language scripts. We\ninvestigate the text normalization routine employed by leading ASR models,\nincluding OpenAI Whisper, Meta's MMS, Seamless, and Assembly AI's Conformer,\nand their unintended consequences on performance metrics. Our research reveals\nthat current text normalization practices, while aiming to standardize ASR\noutputs for fair comparison, by removing inconsistencies such as variations in\nspelling, punctuation, and special characters, are fundamentally flawed when\napplied to Indic scripts. Through empirical analysis using text similarity\nscores and in-depth linguistic examination, we demonstrate that these flaws\nlead to artificially improved performance metrics for Indic languages. We\nconclude by proposing a shift towards developing text normalization routines\nthat leverage native linguistic expertise, ensuring more robust and accurate\nevaluations of multilingual ASR models.", "published": "2024-09-04 05:08:23", "link": "http://arxiv.org/abs/2409.02449v4", "categories": ["cs.CL", "cs.AI", "cs.HC", "68T50, 91F20, 68T10", "I.2.1; I.2.7"], "primary_category": "cs.CL"}
{"title": "More is More: Addition Bias in Large Language Models", "abstract": "In this paper, we investigate the presence of additive bias in Large Language\nModels (LLMs), drawing a parallel to the cognitive bias observed in humans\nwhere individuals tend to favor additive over subtractive changes. Using a\nseries of controlled experiments, we tested various LLMs, including GPT-3.5\nTurbo, Claude 3.5 Sonnet, Mistral, Math$\\Sigma$tral, and Llama 3.1, on tasks\ndesigned to measure their propensity for additive versus subtractive\nmodifications. Our findings demonstrate a significant preference for additive\nchanges across all tested models. For example, in a palindrome creation task,\nLlama 3.1 favored adding letters 97.85% of the time over removing them.\nSimilarly, in a Lego tower balancing task, GPT-3.5 Turbo chose to add a brick\n76.38% of the time rather than remove one. In a text summarization task,\nMistral 7B produced longer summaries in 59.40% to 75.10% of cases when asked to\nimprove its own or others' writing. These results indicate that, similar to\nhumans, LLMs exhibit a marked additive bias, which might have implications when\nLLMs are used on a large scale. Addittive bias might increase resource use and\nenvironmental impact, leading to higher economic costs due to overconsumption\nand waste. This bias should be considered in the development and application of\nLLMs to ensure balanced and efficient problem-solving approaches.", "published": "2024-09-04 09:39:07", "link": "http://arxiv.org/abs/2409.02569v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "An Analysis of Linear Complexity Attention Substitutes with BEST-RQ", "abstract": "Self-Supervised Learning (SSL) has proven to be effective in various domains,\nincluding speech processing. However, SSL is computationally and memory\nexpensive. This is in part due the quadratic complexity of multi-head\nself-attention (MHSA). Alternatives for MHSA have been proposed and used in the\nspeech domain, but have yet to be investigated properly in an SSL setting. In\nthis work, we study the effects of replacing MHSA with recent state-of-the-art\nalternatives that have linear complexity, namely, HyperMixing, Fastformer,\nSummaryMixing, and Mamba. We evaluate these methods by looking at the speed,\nthe amount of VRAM consumed, and the performance on the SSL MP3S benchmark.\nResults show that these linear alternatives maintain competitive performance\ncompared to MHSA while, on average, decreasing VRAM consumption by around 20%\nto 60% and increasing speed from 7% to 65% for input sequences ranging from 20\nto 80 seconds.", "published": "2024-09-04 10:27:07", "link": "http://arxiv.org/abs/2409.02596v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for\n  Problem-Solving Improvement of LLMs", "abstract": "Large Language Models (LLMs) have demonstrated remarkable efficiency in\ntackling various tasks based on human instructions, but studies reveal that\nthey often struggle with tasks requiring reasoning, such as math or physics.\nThis limitation raises questions about whether LLMs truly comprehend embedded\nknowledge or merely learn to replicate the token distribution without a true\nunderstanding of the content. In this paper, we delve into this problem and aim\nto enhance the reasoning capabilities of LLMs. First, we investigate if the\nmodel has genuine reasoning capabilities by visualizing the text generation\nprocess at the attention and representation level. Then, we formulate the\nreasoning process of LLMs into a causal framework, which provides a formal\nexplanation of the problems observed in the visualization. Finally, building\nupon this causal framework, we propose Deconfounded Causal Adaptation (DCA), a\nnovel parameter-efficient fine-tuning (PEFT) method to enhance the model's\nreasoning capabilities by encouraging the model to extract the general\nproblem-solving skills and apply these skills to different questions.\nExperiments show that our method outperforms the baseline consistently across\nmultiple benchmarks, and with only 1.2M tunable parameters, we achieve better\nor comparable results to other fine-tuning methods. This demonstrates the\neffectiveness and efficiency of our method in improving the overall accuracy\nand reliability of LLMs.", "published": "2024-09-04 13:17:09", "link": "http://arxiv.org/abs/2409.02686v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring Sentiment Dynamics and Predictive Behaviors in Cryptocurrency\n  Discussions by Few-Shot Learning with Large Language Models", "abstract": "This study performs analysis of Predictive statements, Hope speech, and\nRegret Detection behaviors within cryptocurrency-related discussions,\nleveraging advanced natural language processing techniques. We introduce a\nnovel classification scheme named \"Prediction statements,\" categorizing\ncomments into Predictive Incremental, Predictive Decremental, Predictive\nNeutral, or Non-Predictive categories. Employing GPT-4o, a cutting-edge large\nlanguage model, we explore sentiment dynamics across five prominent\ncryptocurrencies: Cardano, Binance, Matic, Fantom, and Ripple. Our analysis\nreveals distinct patterns in predictive sentiments, with Matic demonstrating a\nnotably higher propensity for optimistic predictions. Additionally, we\ninvestigate hope and regret sentiments, uncovering nuanced interplay between\nthese emotions and predictive behaviors. Despite encountering limitations\nrelated to data volume and resource availability, our study reports valuable\ndiscoveries concerning investor behavior and sentiment trends within the\ncryptocurrency market, informing strategic decision-making and future research\nendeavors.", "published": "2024-09-04 16:02:30", "link": "http://arxiv.org/abs/2409.02836v1", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Configurable Foundation Models: Building LLMs from a Modular Perspective", "abstract": "Advancements in LLMs have recently unveiled challenges tied to computational\nefficiency and continual scalability due to their requirements of huge\nparameters, making the applications and evolution of these models on devices\nwith limited computation resources and scenarios requiring various abilities\nincreasingly cumbersome. Inspired by modularity within the human brain, there\nis a growing tendency to decompose LLMs into numerous functional modules,\nallowing for inference with part of modules and dynamic assembly of modules to\ntackle complex tasks, such as mixture-of-experts. To highlight the inherent\nefficiency and composability of the modular approach, we coin the term brick to\nrepresent each functional module, designating the modularized structure as\nconfigurable foundation models. In this paper, we offer a comprehensive\noverview and investigation of the construction, utilization, and limitation of\nconfigurable foundation models. We first formalize modules into emergent bricks\n- functional neuron partitions that emerge during the pre-training phase, and\ncustomized bricks - bricks constructed via additional post-training to improve\nthe capabilities and knowledge of LLMs. Based on diverse functional bricks, we\nfurther present four brick-oriented operations: retrieval and routing, merging,\nupdating, and growing. These operations allow for dynamic configuration of LLMs\nbased on instructions to handle complex tasks. To verify our perspective, we\nconduct an empirical analysis on widely-used LLMs. We find that the FFN layers\nfollow modular patterns with functional specialization of neurons and\nfunctional neuron partitions. Finally, we highlight several open issues and\ndirections for future research. Overall, this paper aims to offer a fresh\nmodular perspective on existing LLM research and inspire the future creation of\nmore efficient and scalable foundational models.", "published": "2024-09-04 17:01:02", "link": "http://arxiv.org/abs/2409.02877v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via a\n  Hybrid Architecture", "abstract": "Expanding the long-context capabilities of Multi-modal Large Language\nModels~(MLLMs) is crucial for video understanding, high-resolution image\nunderstanding, and multi-modal agents. This involves a series of systematic\noptimizations, including model architecture, data construction and training\nstrategy, particularly addressing challenges such as \\textit{degraded\nperformance with more images} and \\textit{high computational costs}. In this\npaper, we adapt the model architecture to a hybrid of Mamba and Transformer\nblocks, approach data construction with both temporal and spatial dependencies\namong multiple images and employ a progressive training strategy. The released\nmodel \\textbf{LongLLaVA}~(\\textbf{Long}-Context \\textbf{L}arge\n\\textbf{L}anguage \\textbf{a}nd \\textbf{V}ision \\textbf{A}ssistant) is the first\nhybrid MLLM, which achieved a better balance between efficiency and\neffectiveness. LongLLaVA not only achieves competitive results across various\nbenchmarks, but also maintains high throughput and low memory consumption.\nEspecially, it could process nearly a thousand images on a single A100 80GB\nGPU, showing promising application prospects for a wide range of tasks.", "published": "2024-09-04 17:25:21", "link": "http://arxiv.org/abs/2409.02889v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Masked Diffusion Models are Secretly Time-Agnostic Masked Models and\n  Exploit Inaccurate Categorical Sampling", "abstract": "Masked diffusion models (MDMs) have emerged as a popular research topic for\ngenerative modeling of discrete data, thanks to their superior performance over\nother discrete diffusion models, and are rivaling the auto-regressive models\n(ARMs) for language modeling tasks. The recent effort in simplifying the masked\ndiffusion framework further leads to alignment with continuous-space diffusion\nmodels and more principled training and sampling recipes. In this paper,\nhowever, we reveal that both training and sampling of MDMs are theoretically\nfree from the time variable, arguably the key signature of diffusion models,\nand are instead equivalent to masked models. The connection on the sampling\naspect is drawn by our proposed first-hitting sampler (FHS). Specifically, we\nshow that the FHS is theoretically equivalent to MDMs' original generation\nprocess while significantly alleviating the time-consuming categorical sampling\nand achieving a 20$\\times$ speedup. In addition, our investigation raises\ndoubts about whether MDMs can truly beat ARMs in text generation. We identify,\nfor the first time, an underlying numerical issue, even with the commonly used\n32-bit floating-point precision, which results in inaccurate categorical\nsampling. We show that it lowers the effective temperature both theoretically\nand empirically, and the resulting decrease in token diversity makes previous\nevaluations, which assess the generation quality solely through the incomplete\ngenerative perplexity metric, somewhat unfair.", "published": "2024-09-04 17:48:19", "link": "http://arxiv.org/abs/2409.02908v5", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins (early\n  version)", "abstract": "In the rapidly advancing field of robotics, dual-arm coordination and complex\nobject manipulation are essential capabilities for developing advanced\nautonomous systems. However, the scarcity of diverse, high-quality\ndemonstration data and real-world-aligned evaluation benchmarks severely limits\nsuch development. To address this, we introduce RoboTwin, a generative digital\ntwin framework that uses 3D generative foundation models and large language\nmodels to produce diverse expert datasets and provide a real-world-aligned\nevaluation platform for dual-arm robotic tasks. Specifically, RoboTwin creates\nvaried digital twins of objects from single 2D images, generating realistic and\ninteractive scenarios. It also introduces a spatial relation-aware code\ngeneration framework that combines object annotations with large language\nmodels to break down tasks, determine spatial constraints, and generate precise\nrobotic movement code. Our framework offers a comprehensive benchmark with both\nsimulated and real-world data, enabling standardized evaluation and better\nalignment between simulated training and real-world performance. We validated\nour approach using the open-source COBOT Magic Robot platform. Policies\npre-trained on RoboTwin-generated data and fine-tuned with limited real-world\nsamples improve the success rate of over 70% for single-arm tasks and over 40%\nfor dual-arm tasks compared to models trained solely on real-world data. This\nsignificant improvement demonstrates RoboTwin's potential to enhance the\ndevelopment and evaluation of dual-arm robotic manipulation systems. Project\nPage: https://robotwin-benchmark.github.io/early-version/.", "published": "2024-09-04 17:59:52", "link": "http://arxiv.org/abs/2409.02920v2", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Hallucination Detection in LLMs: Fast and Memory-Efficient Fine-Tuned\n  Models", "abstract": "Uncertainty estimation is a necessary component when implementing AI in\nhigh-risk settings, such as autonomous cars, medicine, or insurances. Large\nLanguage Models (LLMs) have seen a surge in popularity in recent years, but\nthey are subject to hallucinations, which may cause serious harm in high-risk\nsettings. Despite their success, LLMs are expensive to train and run: they need\na large amount of computations and memory, preventing the use of ensembling\nmethods in practice. In this work, we present a novel method that allows for\nfast and memory-friendly training of LLM ensembles. We show that the resulting\nensembles can detect hallucinations and are a viable approach in practice as\nonly one GPU is needed for training and inference.", "published": "2024-09-04 13:59:38", "link": "http://arxiv.org/abs/2409.02976v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ISO: Overlap of Computation and Communication within Seqenence For LLM\n  Inference", "abstract": "In the realm of Large Language Model (LLM) inference, the inherent structure\nof transformer models coupled with the multi-GPU tensor parallelism strategy\nleads to a sequential execution of computation and communication. This results\nin substantial underutilization of computing resources during the communication\nphase. To mitigate this inefficiency, various techniques have been developed to\noptimize the use of computational power throughout the communication process.\nThese strategies primarily involve overlapping matrix computations and\ncommunications, as well as interleaving micro-batches across different\nrequests. Nonetheless, these approaches either fall short of achieving ideal\noverlap or impose certain limitations on their application. To overcome these\nchallenges, this paper introduces a novel strategy for\ncomputation-communication overlap that operates at the sequence level. This\nmethod not only enhances the degree of overlap but also minimizes the\nconstraints on its applicability. Experimental evaluations conducted using\n30b/70b models have demonstrated significant improvements in efficiency.\nSpecifically, the proposed technique has been shown to reduce time consumption\nby approximately 35% on 4090 GPU and by roughly 15% on A800 GPU during the\nprefill stage of LLM inference.", "published": "2024-09-04 05:22:17", "link": "http://arxiv.org/abs/2409.11155v1", "categories": ["cs.DC", "cs.CL", "cs.LG", "cs.PF"], "primary_category": "cs.DC"}
{"title": "Sorbet: A Neuromorphic Hardware-Compatible Transformer-Based Spiking\n  Language Model", "abstract": "For reasons such as privacy, there are use cases for language models at the\nedge. This has given rise to small language models (SLMs) targeted for\ndeployment in resource-constrained devices where energy efficiency is a\nsignificant concern. Spiking neural networks (SNNs) offer a promising solution\ndue to their energy efficiency, and there are already works on realizing\ntransformer-based models on SNNs. However, key operations like softmax and\nlayer normalization (LN) are difficult to implement on neuromorphic hardware,\nand many of these early works sidestepped them. To address these challenges, we\nintroduce Sorbet, a transformer-based spiking language model that is more\nneuromorphic hardware-compatible. Sorbet incorporates a novel shifting-based\nsoftmax called PTsoftmax and a power normalization method using bit-shifting\n(BSPN), both designed to replace the respective energy-intensive operations. By\nleveraging knowledge distillation and model quantization, Sorbet achieved a\nhighly compressed binary weight model that maintains competitive performance\nwhile significantly reducing energy consumption. We validate Sorbet's\neffectiveness through extensive testing on the GLUE benchmark and a series of\nablation studies, demonstrating its potential as an energy-efficient solution\nfor language model inference.", "published": "2024-09-04 10:20:50", "link": "http://arxiv.org/abs/2409.15298v1", "categories": ["cs.NE", "cs.CL", "cs.LG"], "primary_category": "cs.NE"}
{"title": "Large Language Models as Efficient Reward Function Searchers for\n  Custom-Environment Multi-Objective Reinforcement Learning", "abstract": "Achieving the effective design and improvement of reward functions in\nreinforcement learning (RL) tasks with complex custom environments and multiple\nrequirements presents considerable challenges. In this paper, we propose ERFSL,\nan efficient reward function searcher using LLMs, which enables LLMs to be\neffective white-box searchers and highlights their advanced semantic\nunderstanding capabilities. Specifically, we generate reward components for\neach numerically explicit user requirement and employ a reward critic to\nidentify the correct code form. Then, LLMs assign weights to the reward\ncomponents to balance their values and iteratively adjust the weights without\nambiguity and redundant adjustments by flexibly adopting directional mutation\nand crossover strategies, similar to genetic algorithms, based on the context\nprovided by the training log analyzer. We applied the framework to an\nunderwater data collection RL task without direct human feedback or reward\nexamples (zero-shot learning). The reward critic successfully corrects the\nreward code with only one feedback instance for each requirement, effectively\npreventing unrectifiable errors. The initialization of weights enables the\nacquisition of different reward functions within the Pareto solution set\nwithout the need for weight search. Even in cases where a weight is 500 times\noff, on average, only 5.2 iterations are needed to meet user requirements. The\nERFSL also works well with most prompts utilizing GPT-4o mini, as we decompose\nthe weight searching process to reduce the requirement for numerical and\nlong-context understanding capabilities", "published": "2024-09-04 04:15:14", "link": "http://arxiv.org/abs/2409.02428v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Wavelet GPT: Wavelet Inspired Large Language Models", "abstract": "Large Language Models (LLMs) have ushered in a new wave of artificial\nintelligence advancements impacting every scientific field and discipline. We\nlive in a world where most of the data around us, e.g., text, audio, and music,\nhas a multi-scale structure. This paper infuses LLMs with a traditional signal\nprocessing idea, namely wavelets, during pre-training to take advantage of the\nstructure. Without adding \\textbf{any extra parameters} to a GPT-style LLM\narchitecture in an academic setup, we achieve the same pre-training performance\nalmost twice as fast in text, audio, and images. This is done by imposing a\nstructure on intermediate embeddings. When trained for the same number of\ntraining steps, we achieve significant gains in performance, which is\ncomparable to pre-training a larger neural architecture. Further, we show this\nextends to the Long Range Arena benchmark and several input representations\nsuch as characters, BPE tokens, bytes, waveform, math expression, and image\npixels. Our architecture allows every next token prediction access to\nintermediate embeddings at different temporal resolutions in every decoder\nblock. We hope this will pave the way for incorporating multi-rate signal\nprocessing into pre-training.", "published": "2024-09-04 03:17:19", "link": "http://arxiv.org/abs/2409.12924v4", "categories": ["eess.SP", "cs.AI", "cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "MusicMamba: A Dual-Feature Modeling Approach for Generating Chinese\n  Traditional Music with Modal Precision", "abstract": "In recent years, deep learning has significantly advanced the MIDI domain,\nsolidifying music generation as a key application of artificial intelligence.\nHowever, existing research primarily focuses on Western music and encounters\nchallenges in generating melodies for Chinese traditional music, especially in\ncapturing modal characteristics and emotional expression. To address these\nissues, we propose a new architecture, the Dual-Feature Modeling Module, which\nintegrates the long-range dependency modeling of the Mamba Block with the\nglobal structure capturing capabilities of the Transformer Block. Additionally,\nwe introduce the Bidirectional Mamba Fusion Layer, which integrates local\ndetails and global structures through bidirectional scanning, enhancing the\nmodeling of complex sequences. Building on this architecture, we propose the\nREMI-M representation, which more accurately captures and generates modal\ninformation in melodies. To support this research, we developed FolkDB, a\nhigh-quality Chinese traditional music dataset encompassing various styles and\ntotaling over 11 hours of music. Experimental results demonstrate that the\nproposed architecture excels in generating melodies with Chinese traditional\nmusic characteristics, offering a new and effective solution for music\ngeneration.", "published": "2024-09-04 04:00:22", "link": "http://arxiv.org/abs/2409.02421v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CUEMPATHY: A Counseling Speech Dataset for Psychotherapy Research", "abstract": "Psychotherapy or counseling is typically conducted through spoken\nconversation between a therapist and a client. Analyzing the speech\ncharacteristics of psychotherapeutic interactions can help understand the\nfactors associated with effective psychotherapy. This paper introduces\nCUEMPATHY, a large-scale speech dataset collected from actual counseling\nsessions. The dataset consists of 156 counseling sessions involving 39\ntherapist-client dyads. The process of speech data collection, subjective\nratings (one observer and two client ratings), and transcription are described.\nAn automatic speech and text processing system is developed to locate the time\nstamps of speaker turns in each session. Examining the relationships among the\nthree subjective ratings suggests that observer and client ratings have no\nsignificant correlation, while the client-rated measures are significantly\ncorrelated. The intensity similarity between the therapist and the client,\nmeasured by the averaged absolute difference of speaker-turn-level intensities,\nis associated with the psychotherapy outcomes. Recent studies on the acoustic\nand linguistic characteristics of the CUEMPATHY are introduced.", "published": "2024-09-04 06:29:42", "link": "http://arxiv.org/abs/2409.02466v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Efficient Extraction of Noise-Robust Discrete Units from Self-Supervised\n  Speech Models", "abstract": "Continuous speech can be converted into a discrete sequence by deriving\ndiscrete units from the hidden features of self-supervised learned (SSL) speech\nmodels. Although SSL models are becoming larger and trained on more data, they\nare often sensitive to real-life distortions like additive noise or\nreverberation, which translates to a shift in discrete units. We propose a\nparameter-efficient approach to generate noise-robust discrete units from\npre-trained SSL models by training a small encoder-decoder model, with or\nwithout adapters, to simultaneously denoise and discretise the hidden features\nof the SSL model. The model learns to generate a clean discrete sequence for a\nnoisy utterance, conditioned on the SSL features. The proposed denoiser\noutperforms several pre-training methods on the tasks of noisy discretisation\nand noisy speech recognition, and can be finetuned to the target environment\nwith a few recordings of unlabeled target data.", "published": "2024-09-04 09:31:58", "link": "http://arxiv.org/abs/2409.02565v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "USEF-TSE: Universal Speaker Embedding Free Target Speaker Extraction", "abstract": "Target speaker extraction aims to isolate the voice of a specific speaker\nfrom mixed speech. Traditionally, this process has relied on extracting a\nspeaker embedding from a reference speech, necessitating a speaker recognition\nmodel. However, identifying an appropriate speaker recognition model can be\nchallenging, and using the target speaker embedding as reference information\nmay not be optimal for target speaker extraction tasks. This paper introduces a\nUniversal Speaker Embedding-Free Target Speaker Extraction (USEF-TSE) framework\nthat operates without relying on speaker embeddings. USEF-TSE utilizes a\nmulti-head cross-attention mechanism as a frame-level target speaker feature\nextractor. This innovative approach allows mainstream speaker extraction\nsolutions to bypass the dependency on speaker recognition models and to fully\nleverage the information available in the enrollment speech, including speaker\ncharacteristics and contextual details. Additionally, USEF-TSE can seamlessly\nintegrate with any time-domain or time-frequency domain speech separation model\nto achieve effective speaker extraction. Experimental results show that our\nproposed method achieves state-of-the-art (SOTA) performance in terms of\nScale-Invariant Signal-to-Distortion Ratio (SI-SDR) on the WSJ0-2mix, WHAM!,\nand WHAMR! datasets, which are standard benchmarks for monaural anechoic, noisy\nand noisy-reverberant two-speaker speech separation and speaker extraction.", "published": "2024-09-04 11:12:30", "link": "http://arxiv.org/abs/2409.02615v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Effects of Recording Condition and Number of Monitored Days on\n  Discriminative Power of the Daily Phonotrauma Index", "abstract": "Objective: The Daily Phonotrauma Index (DPI) can quantify pathophysiological\nmechanisms associated with daily voice use in individuals with phonotraumatic\nvocal hyperfunction (PVH). Since DPI was developed based on week-long\nambulatory voice monitoring, this study investigated if DPI can achieve\ncomparable performance using (1) short laboratory speech tasks and (2) fewer\nthan seven days of ambulatory data. Method: An ambulatory voice monitoring\nsystem recorded the vocal function/behavior of 134 females with PVH and vocally\nhealthy matched controls in two different conditions. In the lab, the\nparticipants read the first paragraph of the Rainbow Passage and produced\nspontaneous speech (in-lab data). They were then monitored for seven days\n(in-field data). Separate DPI models were trained from in-lab and in-field data\nusing the standard deviation of the difference between the magnitude of the\nfirst two harmonics (H1-H2) and the skewness of neck-surface acceleration\nmagnitude. First, 10-fold cross-validation evaluated classification performance\nof in-lab and in-field DPIs. Second, the effect of the number of ambulatory\nmonitoring days on the accuracy of in-field DPI classification was quantified.\nResults: The average in-lab DPI accuracy computed from the Rainbow passage and\nspontaneous speech were, respectively, 57.9% and 48.9%, which are close to\nchance performance. The average classification accuracy of in-field DPI was\nsignificantly higher with a very large effect size (73.4%, Cohens D = 1.8).\nSecond, the average in-field DPI accuracy increased from 66.5% for one day to\n75.0% for seven days, with the gain of including an additional day on accuracy\ndropping below 1 percentage point after 4 days.", "published": "2024-09-04 15:16:53", "link": "http://arxiv.org/abs/2409.02800v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Latent Watermarking of Audio Generative Models", "abstract": "The advancements in audio generative models have opened up new challenges in\ntheir responsible disclosure and the detection of their misuse. In response, we\nintroduce a method to watermark latent generative models by a specific\nwatermarking of their training data. The resulting watermarked models produce\nlatent representations whose decoded outputs are detected with high confidence,\nregardless of the decoding method used. This approach enables the detection of\nthe generated content without the need for a post-hoc watermarking step. It\nprovides a more secure solution for open-sourced models and facilitates the\nidentification of derivative works that fine-tune or use these models without\nadhering to their license terms. Our results indicate for instance that\ngenerated outputs are detected with an accuracy of more than 75% at a false\npositive rate of $10^{-3}$, even after fine-tuning the latent generative model.", "published": "2024-09-04 17:52:44", "link": "http://arxiv.org/abs/2409.02915v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SymPAC: Scalable Symbolic Music Generation With Prompts And Constraints", "abstract": "Progress in the task of symbolic music generation may be lagging behind other\ntasks like audio and text generation, in part because of the scarcity of\nsymbolic training data. In this paper, we leverage the greater scale of audio\nmusic data by applying pre-trained MIR models (for transcription, beat\ntracking, structure analysis, etc.) to extract symbolic events and encode them\ninto token sequences. To the best of our knowledge, this work is the first to\ndemonstrate the feasibility of training symbolic generation models solely from\nauto-transcribed audio data. Furthermore, to enhance the controllability of the\ntrained model, we introduce SymPAC (Symbolic Music Language Model with\nPrompting And Constrained Generation), which is distinguished by using (a)\nprompt bars in encoding and (b) a technique called Constrained Generation via\nFinite State Machines (FSMs) during inference time. We show the flexibility and\ncontrollability of this approach, which may be critical in making music AI\nuseful to creators and users.", "published": "2024-09-04 20:04:53", "link": "http://arxiv.org/abs/2409.03055v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fast, High-Quality and Parameter-Efficient Articulatory Synthesis using\n  Differentiable DSP", "abstract": "Articulatory trajectories like electromagnetic articulography (EMA) provide a\nlow-dimensional representation of the vocal tract filter and have been used as\nnatural, grounded features for speech synthesis. Differentiable digital signal\nprocessing (DDSP) is a parameter-efficient framework for audio synthesis.\nTherefore, integrating low-dimensional EMA features with DDSP can significantly\nenhance the computational efficiency of speech synthesis. In this paper, we\npropose a fast, high-quality, and parameter-efficient DDSP articulatory vocoder\nthat can synthesize speech from EMA, F0, and loudness. We incorporate several\ntechniques to solve the harmonics / noise imbalance problem, and add a\nmulti-resolution adversarial loss for better synthesis quality. Our model\nachieves a transcription word error rate (WER) of 6.67% and a mean opinion\nscore (MOS) of 3.74, with an improvement of 1.63% and 0.16 compared to the\nstate-of-the-art (SOTA) baseline. Our DDSP vocoder is 4.9x faster than the\nbaseline on CPU during inference, and can generate speech of comparable quality\nwith only 0.4M parameters, in contrast to the 9M parameters required by the\nSOTA.", "published": "2024-09-04 05:12:15", "link": "http://arxiv.org/abs/2409.02451v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "NeuroSpex: Neuro-Guided Speaker Extraction with Cross-Modal Attention", "abstract": "In the study of auditory attention, it has been revealed that there exists a\nrobust correlation between attended speech and elicited neural responses,\nmeasurable through electroencephalography (EEG). Therefore, it is possible to\nuse the attention information available within EEG signals to guide the\nextraction of the target speaker in a cocktail party computationally. In this\npaper, we present a neuro-guided speaker extraction model, i.e. NeuroSpex,\nusing the EEG response of the listener as the sole auxiliary reference cue to\nextract attended speech from monaural speech mixtures. We propose a novel EEG\nsignal encoder that captures the attention information. Additionally, we\npropose a cross-attention (CA) mechanism to enhance the speech feature\nrepresentations, generating a speaker extraction mask. Experimental results on\na publicly available dataset demonstrate that our proposed model outperforms\ntwo baseline models across various evaluation metrics.", "published": "2024-09-04 07:33:01", "link": "http://arxiv.org/abs/2409.02489v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Training Universal Vocoders with Feature Smoothing-Based Augmentation\n  Methods for High-Quality TTS Systems", "abstract": "While universal vocoders have achieved proficient waveform generation across\ndiverse voices, their integration into text-to-speech (TTS) tasks often results\nin degraded synthetic quality. To address this challenge, we present a novel\naugmentation technique for training universal vocoders. Our training scheme\nrandomly applies linear smoothing filters to input acoustic features,\nfacilitating vocoder generalization across a wide range of smoothings. It\nsignificantly mitigates the training-inference mismatch, enhancing the\nnaturalness of synthetic output even when the acoustic model produces overly\nsmoothed features. Notably, our method is applicable to any vocoder without\nrequiring architectural modifications or dependencies on specific acoustic\nmodels. The experimental results validate the superiority of our vocoder over\nconventional methods, achieving 11.99% and 12.05% improvements in mean opinion\nscores when integrated with Tacotron 2 and FastSpeech 2 TTS acoustic models,\nrespectively.", "published": "2024-09-04 08:25:54", "link": "http://arxiv.org/abs/2409.02517v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-Track MusicLDM: Towards Versatile Music Generation with Latent\n  Diffusion Model", "abstract": "Diffusion models have shown promising results in cross-modal generation tasks\ninvolving audio and music, such as text-to-sound and text-to-music generation.\nThese text-controlled music generation models typically focus on generating\nmusic by capturing global musical attributes like genre and mood. However,\nmusic composition is a complex, multilayered task that often involves musical\narrangement as an integral part of the process. This process involves composing\neach instrument to align with existing ones in terms of beat, dynamics,\nharmony, and melody, requiring greater precision and control over tracks than\ntext prompts usually provide. In this work, we address these challenges by\nextending the MusicLDM, a latent diffusion model for music, into a multi-track\ngenerative model. By learning the joint probability of tracks sharing a\ncontext, our model is capable of generating music across several tracks that\ncorrespond well to each other, either conditionally or unconditionally.\nAdditionally, our model is capable of arrangement generation, where the model\ncan generate any subset of tracks given the others (e.g., generating a piano\ntrack complementing given bass and drum tracks). We compared our model with an\nexisting multi-track generative model and demonstrated that our model achieves\nconsiderable improvements across objective metrics for both total and\narrangement generation tasks.", "published": "2024-09-04 16:17:41", "link": "http://arxiv.org/abs/2409.02845v3", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
