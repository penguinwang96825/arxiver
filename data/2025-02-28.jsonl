{"title": "Using quantile time series and historical simulation to forecast financial risk multiple steps ahead", "abstract": "A method for quantile-based, semi-parametric historical simulation estimation\nof multiple step ahead Value-at-Risk (VaR) and Expected Shortfall (ES) models\nis developed. It uses the quantile loss function, analogous to how the\nquasi-likelihood is employed by standard historical simulation methods. The\nreturns data are scaled by the estimated quantile series, then resampling is\nemployed to estimate the forecast distribution one and multiple steps ahead,\nallowing tail risk forecasting. The proposed method is applicable to any data\nor model where the relationship between VaR and ES does not change over time\nand can be extended to allow a measurement equation incorporating realized\nmeasures, thus including Realized GARCH and Realized CAViaR type models. Its\nfinite sample properties, and its comparison with existing historical\nsimulation methods, are evaluated via a simulation study. A forecasting study\nassesses the relative accuracy of the 1% and 2.5% VaR and ES one-day-ahead and\nten-day-ahead forecasting results for the proposed class of models compared to\nseveral competitors.", "published": "2025-02-28 11:48:35", "link": "http://arxiv.org/abs/2502.20978v2", "categories": ["q-fin.ST", "q-fin.CP", "q-fin.RM"], "primary_category": "q-fin.ST"}
{"title": "Enhanced Derivative-Free Optimization Using Adaptive Correlation-Induced Finite Difference Estimators", "abstract": "Gradient-based methods are well-suited for derivative-free optimization\n(DFO), where finite-difference (FD) estimates are commonly used as gradient\nsurrogates. Traditional stochastic approximation methods, such as\nKiefer-Wolfowitz (KW) and simultaneous perturbation stochastic approximation\n(SPSA), typically utilize only two samples per iteration, resulting in\nimprecise gradient estimates and necessitating diminishing step sizes for\nconvergence. In this paper, we first explore an efficient FD estimate, referred\nto as correlation-induced FD estimate, which is a batch-based estimate. Then,\nwe propose an adaptive sampling strategy that dynamically determines the batch\nsize at each iteration. By combining these two components, we develop an\nalgorithm designed to enhance DFO in terms of both gradient estimation\nefficiency and sample efficiency. Furthermore, we establish the consistency of\nour proposed algorithm and demonstrate that, despite using a batch of samples\nper iteration, it achieves the same convergence rate as the KW and SPSA\nmethods. Additionally, we propose a novel stochastic line search technique to\nadaptively tune the step size in practice. Finally, comprehensive numerical\nexperiments confirm the superior empirical performance of the proposed\nalgorithm.", "published": "2025-02-28 08:05:54", "link": "http://arxiv.org/abs/2502.20819v1", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "q-fin.CP", "stat.ML", "90-05", "I.6.1; I.6.6"], "primary_category": "math.OC"}
{"title": "Strong Solutions and Quantization-Based Numerical Schemes for a Class of Non-Markovian Volatility Models", "abstract": "We investigate a class of non-Markovian processes that hold particular\nrelevance in the realm of mathematical finance. This family encompasses\npath-dependent volatility models, including those pioneered by [Platen and\nRendek, 2018] and, more recently, by [Guyon and Lekeufack, 2023], as well as an\nextension of the framework proposed by [Blanc et al., 2017]. Our study unfolds\nin two principal phases. In the first phase, we introduce a functional\nquantization scheme based on an extended version of the Lamperti transformation\nthat we propose to handle the presence of a memory term incorporated into the\ndiffusion coefficient. For scenarios involving a Brownian integral in the\ndiffusion term, we propose alternative numerical schemes that leverage the\npower of marginal recursive quantization. In the second phase, we study the\nproblem of existence and uniqueness of a strong solution for the SDEs related\nto the examples that motivate our study, in order to provide a theoretical\nbasis to correctly apply the proposed numerical schemes.", "published": "2025-02-28 23:21:44", "link": "http://arxiv.org/abs/2503.00243v1", "categories": ["q-fin.MF", "60F10, 91G99, 91B25"], "primary_category": "q-fin.MF"}
{"title": "Short-Rate Derivatives in a Higher-for-Longer Environment", "abstract": "We introduce a class of short-rate models that exhibit a ``higher for\nlonger'' phenomenon. Specifically, the short-rate is modeled as a general\ntime-homogeneous one-factor Markov diffusion on a finite interval. The lower\nendpoint is assumed to be regular, exit or natural according to boundary\nclassification while the upper endpoint is assumed to be regular with absorbing\nbehavior. In this setting, we give an explicit expression for price of a\nzero-coupon bond (as well as more general interest rate derivatives) in terms\nof the transition density of the short-rate under a new probability measure,\nand the solution of a non-linear ordinary differential equation (ODE). We then\nnarrow our focus to a class of models for which the transition density and ODE\ncan be solved explicitly. For models within this class, we provide conditions\nunder which the lower endpoint is regular, exit and natural. Finally, we study\ntwo specific models -- one in which the lower endpoint is exit and another in\nwhich the lower endpoint is natural. In these two models, we give an explicit\nsolution of transition density of the short-rate as a (generalized)\neigenfunction expansion. We provide plots of the transition density,\n(generalized) eigenfunctions, bond prices and the associated yield curve.", "published": "2025-02-28 17:27:51", "link": "http://arxiv.org/abs/2502.21252v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Chronologically Consistent Large Language Models", "abstract": "Large language models are increasingly used in social sciences, but their\ntraining data can introduce lookahead bias and training leakage. A good\nchronologically consistent language model requires efficient use of training\ndata to maintain accuracy despite time-restricted data. Here, we overcome this\nchallenge by training a suite of chronologically consistent large language\nmodels, ChronoBERT and ChronoGPT, which incorporate only the text data that\nwould have been available at each point in time. Despite this strict temporal\nconstraint, our models achieve strong performance on natural language\nprocessing benchmarks, outperforming or matching widely used models (e.g.,\nBERT), and remain competitive with larger open-weight models. Lookahead bias is\nmodel and application-specific because even if a chronologically consistent\nlanguage model has poorer language comprehension, a regression or prediction\nmodel applied on top of the language model can compensate. In an asset pricing\napplication predicting next-day stock returns from financial news, we find that\nChronoBERT's real-time outputs achieve a Sharpe ratio comparable to\nstate-of-the-art models, indicating that lookahead bias is modest. Our results\ndemonstrate a scalable, practical framework to mitigate training leakage,\nensuring more credible backtests and predictions across finance and other\nsocial science domains.", "published": "2025-02-28 16:25:50", "link": "http://arxiv.org/abs/2502.21206v2", "categories": ["q-fin.GN", "q-fin.TR"], "primary_category": "q-fin.GN"}
