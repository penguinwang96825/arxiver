{"title": "Drug-Drug Interaction Extraction from Biomedical Text Using Long Short\n  Term Memory Network", "abstract": "Simultaneous administration of multiple drugs can have synergistic or\nantagonistic effects as one drug can affect activities of other drugs.\nSynergistic effects lead to improved therapeutic outcomes, whereas,\nantagonistic effects can be life-threatening, may lead to increased healthcare\ncost, or may even cause death. Thus identification of unknown drug-drug\ninteraction (DDI) is an important concern for efficient and effective\nhealthcare. Although multiple resources for DDI exist, they are often unable to\nkeep pace with rich amount of information available in fast growing biomedical\ntexts. Most existing methods model DDI extraction from text as a classification\nproblem and mainly rely on handcrafted features. Some of these features further\ndepend on domain specific tools. Recently neural network models using latent\nfeatures have been shown to give similar or better performance than the other\nexisting models dependent on handcrafted features. In this paper, we present\nthree models namely, {\\it B-LSTM}, {\\it AB-LSTM} and {\\it Joint AB-LSTM} based\non long short-term memory (LSTM) network. All three models utilize word and\nposition embedding as latent features and thus do not rely on explicit feature\nengineering. Further use of bidirectional long short-term memory (Bi-LSTM)\nnetworks allow implicit feature extraction from the whole sentence. The two\nmodels, {\\it AB-LSTM} and {\\it Joint AB-LSTM} also use attentive pooling in the\noutput of Bi-LSTM layer to assign weights to features. Our experimental results\non the SemEval-2013 DDI extraction dataset show that the {\\it Joint AB-LSTM}\nmodel outperforms all the existing methods, including those relying on\nhandcrafted features. The other two proposed LSTM models also perform\ncompetitively with state-of-the-art methods.", "published": "2017-01-28 17:04:21", "link": "http://arxiv.org/abs/1701.08303v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Feature Studies to Inform the Classification of Depressive Symptoms from\n  Twitter Data for Population Health", "abstract": "The utility of Twitter data as a medium to support population-level mental\nhealth monitoring is not well understood. In an effort to better understand the\npredictive power of supervised machine learning classifiers and the influence\nof feature sets for efficiently classifying depression-related tweets on a\nlarge-scale, we conducted two feature study experiments. In the first\nexperiment, we assessed the contribution of feature groups such as lexical\ninformation (e.g., unigrams) and emotions (e.g., strongly negative) using a\nfeature ablation study. In the second experiment, we determined the percentile\nof top ranked features that produced the optimal classification performance by\napplying a three-step feature elimination approach. In the first experiment, we\nobserved that lexical features are critical for identifying depressive\nsymptoms, specifically for depressed mood (-35 points) and for disturbed sleep\n(-43 points). In the second experiment, we observed that the optimal F1-score\nperformance of top ranked features in percentiles variably ranged across\nclasses e.g., fatigue or loss of energy (5th percentile, 288 features) to\ndepressed mood (55th percentile, 3,168 features) suggesting there is no\nconsistent count of features for predicting depressive-related tweets. We\nconclude that simple lexical features and reduced feature sets can produce\ncomparable results to larger feature sets.", "published": "2017-01-28 00:32:40", "link": "http://arxiv.org/abs/1701.08229v1", "categories": ["cs.IR", "cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.IR"}
{"title": "Image-Grounded Conversations: Multimodal Context for Natural Question\n  and Response Generation", "abstract": "The popularity of image sharing on social media and the engagement it creates\nbetween users reflects the important role that visual context plays in everyday\nconversations. We present a novel task, Image-Grounded Conversations (IGC), in\nwhich natural-sounding conversations are generated about a shared image. To\nbenchmark progress, we introduce a new multiple-reference dataset of\ncrowd-sourced, event-centric conversations on images. IGC falls on the\ncontinuum between chit-chat and goal-directed conversation models, where visual\ngrounding constrains the topic of conversation to event-driven utterances.\nExperiments with models trained on social media data show that the combination\nof visual and textual context enhances the quality of generated conversational\nturns. In human evaluation, the gap between human performance and that of both\nneural and retrieval architectures suggests that multi-modal IGC presents an\ninteresting challenge for dialogue research.", "published": "2017-01-28 05:06:11", "link": "http://arxiv.org/abs/1701.08251v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Systems of natural-language-facilitated human-robot cooperation: A\n  review", "abstract": "Natural-language-facilitated human-robot cooperation (NLC), in which natural\nlanguage (NL) is used to share knowledge between a human and a robot for\nconducting intuitive human-robot cooperation (HRC), is continuously developing\nin the recent decade. Currently, NLC is used in several robotic domains such as\nmanufacturing, daily assistance and health caregiving. It is necessary to\nsummarize current NLC-based robotic systems and discuss the future developing\ntrends, providing helpful information for future NLC research. In this review,\nwe first analyzed the driving forces behind the NLC research. Regarding to a\nrobot s cognition level during the cooperation, the NLC implementations then\nwere categorized into four types {NL-based control, NL-based robot training,\nNL-based task execution, NL-based social companion} for comparison and\ndiscussion. Last based on our perspective and comprehensive paper review, the\nfuture research trends were discussed.", "published": "2017-01-28 08:32:35", "link": "http://arxiv.org/abs/1701.08269v2", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.RO"}
