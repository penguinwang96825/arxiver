{"title": "Generalization through Memorization: Nearest Neighbor Language Models", "abstract": "We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM)\nby linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The\nnearest neighbors are computed according to distance in the pre-trained LM\nembedding space, and can be drawn from any text collection, including the\noriginal LM training data. Applying this augmentation to a strong Wikitext-103\nLM, with neighbors drawn from the original training set, our $k$NN-LM achieves\na new state-of-the-art perplexity of 15.79 - a 2.9 point improvement with no\nadditional training. We also show that this approach has implications for\nefficiently scaling up to larger training sets and allows for effective domain\nadaptation, by simply varying the nearest neighbor datastore, again without\nfurther training. Qualitatively, the model is particularly helpful in\npredicting rare patterns, such as factual knowledge. Together, these results\nstrongly suggest that learning similarity between sequences of text is easier\nthan predicting the next word, and that nearest neighbor search is an effective\napproach for language modeling in the long tail.", "published": "2019-11-01 01:09:53", "link": "http://arxiv.org/abs/1911.00172v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequence Modeling with Unconstrained Generation Order", "abstract": "The dominant approach to sequence generation is to produce a sequence in some\npredefined order, e.g. left to right. In contrast, we propose a more general\nmodel that can generate the output sequence by inserting tokens in any\narbitrary order. Our model learns decoding order as a result of its training\nprocedure. Our experiments show that this model is superior to fixed order\nmodels on a number of sequence generation tasks, such as Machine Translation,\nImage-to-LaTeX and Image Captioning.", "published": "2019-11-01 01:36:24", "link": "http://arxiv.org/abs/1911.00176v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Choosing Plausible Alternatives, Clever Hans can be Clever", "abstract": "Pretrained language models, such as BERT and RoBERTa, have shown large\nimprovements in the commonsense reasoning benchmark COPA. However, recent work\nfound that many improvements in benchmarks of natural language understanding\nare not due to models learning the task, but due to their increasing ability to\nexploit superficial cues, such as tokens that occur more often in the correct\nanswer than the wrong one. Are BERT's and RoBERTa's good performance on COPA\nalso caused by this? We find superficial cues in COPA, as well as evidence that\nBERT exploits these cues. To remedy this problem, we introduce Balanced COPA,\nan extension of COPA that does not suffer from easy-to-exploit single token\ncues. We analyze BERT's and RoBERTa's performance on original and Balanced\nCOPA, finding that BERT relies on superficial cues when they are present, but\nstill achieves comparable performance once they are made ineffective,\nsuggesting that BERT learns the task to a certain degree when forced to. In\ncontrast, RoBERTa does not appear to rely on superficial cues.", "published": "2019-11-01 06:48:07", "link": "http://arxiv.org/abs/1911.00225v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Robust Data-Driven Approach for Dialogue State Tracking of Unseen Slot\n  Values", "abstract": "A Dialogue State Tracker is a key component in dialogue systems which\nestimates the beliefs of possible user goals at each dialogue turn. Deep\nlearning approaches using recurrent neural networks have shown state-of-the-art\nperformance for the task of dialogue state tracking. Generally, these\napproaches assume a predefined candidate list and struggle to predict any new\ndialogue state values that are not seen during training. This makes extending\nthe candidate list for a slot without model retaining infeasible and also has\nlimitations in modelling for low resource domains where training data for slot\nvalues are expensive. In this paper, we propose a novel dialogue state tracker\nbased on copying mechanism that can effectively track such unseen slot values\nwithout compromising performance on slot values seen during training. The\nproposed model is also flexible in extending the candidate list without\nrequiring any retraining or change in the model. We evaluate the proposed model\non various benchmark datasets (DSTC2, DSTC3 and WoZ2.0) and show that our\napproach, outperform other end-to-end data-driven approaches in tracking unseen\nslot values and also provides significant advantages in modelling for DST.", "published": "2019-11-01 09:08:58", "link": "http://arxiv.org/abs/1911.00269v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Linguistic Representational Power of Neural Machine Translation\n  Models", "abstract": "Despite the recent success of deep neural networks in natural language\nprocessing (NLP), their interpretability remains a challenge. We analyze the\nrepresentations learned by neural machine translation models at various levels\nof granularity and evaluate their quality through relevant extrinsic\nproperties. In particular, we seek answers to the following questions: (i) How\naccurately is word-structure captured within the learned representations, an\nimportant aspect in translating morphologically-rich languages? (ii) Do the\nrepresentations capture long-range dependencies, and effectively handle\nsyntactically divergent languages? (iii) Do the representations capture lexical\nsemantics? We conduct a thorough investigation along several parameters: (i)\nWhich layers in the architecture capture each of these linguistic phenomena;\n(ii) How does the choice of translation unit (word, character, or subword unit)\nimpact the linguistic properties captured by the underlying representations?\n(iii) Do the encoder and decoder learn differently and independently? (iv) Do\nthe representations learned by multilingual NMT models capture the same amount\nof linguistic information as their bilingual counterparts? Our data-driven,\nquantitative evaluation illuminates important aspects in NMT models and their\nability to capture various linguistic phenomena. We show that deep NMT models\nlearn a non-trivial amount of linguistic information. Notable findings include:\ni) Word morphology and part-of-speech information are captured at the lower\nlayers of the model; (ii) In contrast, lexical semantics or non-local syntactic\nand semantic dependencies are better represented at the higher layers; (iii)\nRepresentations learned using characters are more informed about wordmorphology\ncompared to those learned using subword units; and (iv) Representations learned\nby multilingual models are richer compared to bilingual models.", "published": "2019-11-01 12:13:45", "link": "http://arxiv.org/abs/1911.00317v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Select, Answer and Explain: Interpretable Multi-hop Reading\n  Comprehension over Multiple Documents", "abstract": "Interpretable multi-hop reading comprehension (RC) over multiple documents is\na challenging problem because it demands reasoning over multiple information\nsources and explaining the answer prediction by providing supporting evidences.\nIn this paper, we propose an effective and interpretable Select, Answer and\nExplain (SAE) system to solve the multi-document RC problem. Our system first\nfilters out answer-unrelated documents and thus reduce the amount of\ndistraction information. This is achieved by a document classifier trained with\na novel pairwise learning-to-rank loss. The selected answer-related documents\nare then input to a model to jointly predict the answer and supporting\nsentences. The model is optimized with a multi-task learning objective on both\ntoken level for answer prediction and sentence level for supporting sentences\nprediction, together with an attention-based interaction between these two\ntasks. Evaluated on HotpotQA, a challenging multi-hop RC data set, the proposed\nSAE system achieves top competitive performance in distractor setting compared\nto other existing systems on the leaderboard.", "published": "2019-11-01 17:48:38", "link": "http://arxiv.org/abs/1911.00484v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncover Sexual Harassment Patterns from Personal Stories by Joint Key\n  Element Extraction and Categorization", "abstract": "The number of personal stories about sexual harassment shared online has\nincreased exponentially in recent years. This is in part inspired by the\n\\#MeToo and \\#TimesUp movements. Safecity is an online forum for people who\nexperienced or witnessed sexual harassment to share their personal experiences.\nIt has collected \\textgreater 10,000 stories so far. Sexual harassment occurred\nin a variety of situations, and categorization of the stories and extraction of\ntheir key elements will provide great help for the related parties to\nunderstand and address sexual harassment. In this study, we manually annotated\nthose stories with labels in the dimensions of location, time, and harassers'\ncharacteristics, and marked the key elements related to these dimensions.\nFurthermore, we applied natural language processing technologies with joint\nlearning schemes to automatically categorize these stories in those dimensions\nand extract key elements at the same time. We also uncovered significant\npatterns from the categorized sexual harassment stories. We believe our\nannotated data set, proposed algorithms, and analysis will help people who have\nbeen harassed, authorities, researchers and other related parties in various\nways, such as automatically filling reports, enlightening the public in order\nto prevent future harassment, and enabling more effective, faster action to be\ntaken.", "published": "2019-11-01 18:38:27", "link": "http://arxiv.org/abs/1911.00547v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Forget Me Not: Reducing Catastrophic Forgetting for Domain Adaptation in\n  Reading Comprehension", "abstract": "The creation of large-scale open domain reading comprehension data sets in\nrecent years has enabled the development of end-to-end neural comprehension\nmodels with promising results. To use these models for domains with limited\ntraining data, one of the most effective approach is to first pretrain them on\nlarge out-of-domain source data and then fine-tune them with the limited target\ndata. The caveat of this is that after fine-tuning the comprehension models\ntend to perform poorly in the source domain, a phenomenon known as catastrophic\nforgetting. In this paper, we explore methods that overcome catastrophic\nforgetting during fine-tuning without assuming access to data from the source\ndomain. We introduce new auxiliary penalty terms and observe the best\nperformance when a combination of auxiliary penalty terms is used to regularise\nthe fine-tuning process for adapting comprehension models. To test our methods,\nwe develop and release 6 narrow domain data sets that could potentially be used\nas reading comprehension benchmarks.", "published": "2019-11-01 05:07:06", "link": "http://arxiv.org/abs/1911.00202v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Generalization of Transformer for Speech Recognition with\n  Parallel Schedule Sampling and Relative Positional Embedding", "abstract": "Transformer has shown promising results in many sequence to sequence\ntransformation tasks recently. It utilizes a number of feed-forward\nself-attention layers to replace the recurrent neural networks (RNN) in\nattention-based encoder decoder (AED) architecture. Self-attention layer learns\ntemporal dependence by incorporating sinusoidal positional embedding of tokens\nin a sequence for parallel computing. Quicker iteration speed in training than\nsequential operation of RNN can be obtained. Deeper layers of the transformer\nalso make it perform better than RNN-based AED. However, this parallelization\nability is lost when applying scheduled sampling training. Self-attention with\nsinusoidal positional embedding may cause performance degradations for longer\nsequences that have similar acoustic or semantic information at different\npositions as well. To address these problems, we propose to use parallel\nscheduled sampling (PSS) and relative positional embedding (RPE) to help the\ntransformer generalize to unseen data. Our proposed methods achieve a 7%\nrelative improvement for short utterances and a 70% relative gain for long\nutterances on a 10,000-hour Mandarin ASR task.", "published": "2019-11-01 05:16:12", "link": "http://arxiv.org/abs/1911.00203v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Generating Justifications for Norm-Related Agent Decisions", "abstract": "We present an approach to generating natural language justifications of\ndecisions derived from norm-based reasoning. Assuming an agent which maximally\nsatisfies a set of rules specified in an object-oriented temporal logic, the\nuser can ask factual questions (about the agent's rules, actions, and the\nextent to which the agent violated the rules) as well as \"why\" questions that\nrequire the agent comparing actual behavior to counterfactual trajectories with\nrespect to these rules. To produce natural-sounding explanations, we focus on\nthe subproblem of producing natural language clauses from statements in a\nfragment of temporal logic, and then describe how to embed these clauses into\nexplanatory sentences. We use a human judgment evaluation on a testbed task to\ncompare our approach to variants in terms of intelligibility, mental model and\nperceived trust.", "published": "2019-11-01 06:53:12", "link": "http://arxiv.org/abs/1911.00226v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Engaging in Dialogue about an Agent's Norms and Behaviors", "abstract": "We present a set of capabilities allowing an agent planning with moral and\nsocial norms represented in temporal logic to respond to queries about its\nnorms and behaviors in natural language, and for the human user to add and\nremove norms directly in natural language. The user may also pose hypothetical\nmodifications to the agent's norms and inquire about their effects.", "published": "2019-11-01 07:01:52", "link": "http://arxiv.org/abs/1911.00229v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Kernelized Bayesian Softmax for Text Generation", "abstract": "Neural models for text generation require a softmax layer with proper token\nembeddings during the decoding phase. Most existing approaches adopt single\npoint embedding for each token. However, a word may have multiple senses\naccording to different context, some of which might be distinct. In this paper,\nwe propose KerBS, a novel approach for learning better embeddings for text\ngeneration. KerBS embodies two advantages: (a) it employs a Bayesian\ncomposition of embeddings for words with multiple senses; (b) it is adaptive to\nsemantic variances of words and robust to rare sentence context by imposing\nlearned kernels to capture the closeness of words (senses) in the embedding\nspace. Empirical studies show that KerBS significantly boosts the performance\nof several text generation tasks.", "published": "2019-11-01 09:20:14", "link": "http://arxiv.org/abs/1911.00274v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Feature Selection techniques for Sentiment Analysis", "abstract": "Sentiment analysis is a domain of study that focuses on identifying and\nclassifying the ideas expressed in the form of text into positive, negative and\nneutral polarities. Feature selection is a crucial process in machine learning.\nIn this paper, we aim to study the performance of different feature selection\ntechniques for sentiment analysis. Term Frequency Inverse Document Frequency\n(TF-IDF) is used as the feature extraction technique for creating feature\nvocabulary. Various Feature Selection (FS) techniques are experimented to\nselect the best set of features from feature vocabulary. The selected features\nare trained using different machine learning classifiers Logistic Regression\n(LR), Support Vector Machines (SVM), Decision Tree (DT) and Naive Bayes (NB).\nEnsemble techniques Bagging and Random Subspace are applied on classifiers to\nenhance the performance on sentiment analysis. We show that, when the best FS\ntechniques are trained using ensemble methods achieve remarkable results on\nsentiment analysis. We also compare the performance of FS methods trained using\nBagging, Random Subspace with varied neural network architectures. We show that\nFS techniques trained using ensemble classifiers outperform neural networks\nrequiring significantly less training time and parameters thereby eliminating\nthe need for extensive hyper-parameter tuning.", "published": "2019-11-01 10:20:05", "link": "http://arxiv.org/abs/1911.00288v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Unintended Social Bias of Training Language Generation Models\n  with Data from Local Media", "abstract": "There are concerns that neural language models may preserve some of the\nstereotypes of the underlying societies that generate the large corpora needed\nto train these models. For example, gender bias is a significant problem when\ngenerating text, and its unintended memorization could impact the user\nexperience of many applications (e.g., the smart-compose feature in Gmail).\n  In this paper, we introduce a novel architecture that decouples the\nrepresentation learning of a neural model from its memory management role. This\narchitecture allows us to update a memory module with an equal ratio across\ngender types addressing biased correlations directly in the latent space. We\nexperimentally show that our approach can mitigate the gender bias\namplification in the automatic generation of articles news while providing\nsimilar perplexity values when extending the Sequence2Sequence architecture.", "published": "2019-11-01 16:52:02", "link": "http://arxiv.org/abs/1911.00461v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Reasoning Over Paths via Knowledge Base Completion", "abstract": "Reasoning over paths in large scale knowledge graphs is an important problem\nfor many applications. In this paper we discuss a simple approach to\nautomatically build and rank paths between a source and target entity pair with\nlearned embeddings using a knowledge base completion model (KBC). We assembled\na knowledge graph by mining the available biomedical scientific literature and\nextracted a set of high frequency paths to use for validation. We demonstrate\nthat our method is able to effectively rank a list of known paths between a\npair of entities and also come up with plausible paths that are not present in\nthe knowledge graph. For a given entity pair we are able to reconstruct the\nhighest ranking path 60% of the time within the the top 10 ranked paths and\nachieve 49% mean average precision. Our approach is compositional since any KBC\nmodel that can produce vector representations of entities can be used.", "published": "2019-11-01 17:59:38", "link": "http://arxiv.org/abs/1911.00492v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "DialoGPT: Large-Scale Generative Pre-training for Conversational\n  Response Generation", "abstract": "We present a large, tunable neural conversational response generation model,\nDialoGPT (dialogue generative pre-trained transformer). Trained on 147M\nconversation-like exchanges extracted from Reddit comment chains over a period\nspanning from 2005 through 2017, DialoGPT extends the Hugging Face PyTorch\ntransformer to attain a performance close to human both in terms of automatic\nand human evaluation in single-turn dialogue settings. We show that\nconversational systems that leverage DialoGPT generate more relevant,\ncontentful and context-consistent responses than strong baseline systems. The\npre-trained model and training pipeline are publicly released to facilitate\nresearch into neural response generation and the development of more\nintelligent open-domain dialogue systems.", "published": "2019-11-01 18:16:54", "link": "http://arxiv.org/abs/1911.00536v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Low-Rank HOCA: Efficient High-Order Cross-Modal Attention for Video\n  Captioning", "abstract": "This paper addresses the challenging task of video captioning which aims to\ngenerate descriptions for video data. Recently, the attention-based\nencoder-decoder structures have been widely used in video captioning. In\nexisting literature, the attention weights are often built from the information\nof an individual modality, while, the association relationships between\nmultiple modalities are neglected. Motivated by this observation, we propose a\nvideo captioning model with High-Order Cross-Modal Attention (HOCA) where the\nattention weights are calculated based on the high-order correlation tensor to\ncapture the frame-level cross-modal interaction of different modalities\nsufficiently. Furthermore, we novelly introduce Low-Rank HOCA which adopts\ntensor decomposition to reduce the extremely large space requirement of HOCA,\nleading to a practical and efficient implementation in real-world applications.\nExperimental results on two benchmark datasets, MSVD and MSR-VTT, show that\nLow-rank HOCA establishes a new state-of-the-art.", "published": "2019-11-01 05:53:50", "link": "http://arxiv.org/abs/1911.00212v1", "categories": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Finding the most similar textual documents using Case-Based Reasoning", "abstract": "In recent years, huge amounts of unstructured textual data on the Internet\nare a big difficulty for AI algorithms to provide the best recommendations for\nusers and their search queries. Since the Internet became widespread, a lot of\nresearch has been done in the field of Natural Language Processing (NLP) and\nmachine learning. Almost every solution transforms documents into Vector Space\nModels (VSM) in order to apply AI algorithms over them. One such approach is\nbased on Case-Based Reasoning (CBR). Therefore, the most important part of\nthose systems is to compute the similarity between numerical data points. In\n2016, the new similarity TS-SS metric is proposed, which showed\nstate-of-the-art results in the field of textual mining for unsupervised\nlearning. However, no one before has investigated its performances for\nsupervised learning (classification task). In this work, we devised a CBR\nsystem capable of finding the most similar documents for a given query aiming\nto investigate performances of the new state-of-the-art metric, TS-SS, in\naddition to the two other geometrical similarity measures --- Euclidean\ndistance and Cosine similarity --- that showed the best predictive results over\nseveral benchmark corpora. The results show surprising inappropriateness of\nTS-SS measure for high dimensional features.", "published": "2019-11-01 08:46:35", "link": "http://arxiv.org/abs/1911.00262v1", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data", "abstract": "Pre-training text representations have led to significant improvements in\nmany areas of natural language processing. The quality of these models benefits\ngreatly from the size of the pretraining corpora as long as its quality is\npreserved. In this paper, we describe an automatic pipeline to extract massive\nhigh-quality monolingual datasets from Common Crawl for a variety of languages.\nOur pipeline follows the data processing introduced in fastText (Mikolov et\nal., 2017; Grave et al., 2018), that deduplicates documents and identifies\ntheir language. We augment this pipeline with a filtering step to select\ndocuments that are close to high quality corpora like Wikipedia.", "published": "2019-11-01 13:09:28", "link": "http://arxiv.org/abs/1911.00359v2", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "BERT Goes to Law School: Quantifying the Competitive Advantage of Access\n  to Large Legal Corpora in Contract Understanding", "abstract": "Fine-tuning language models, such as BERT, on domain specific corpora has\nproven to be valuable in domains like scientific papers and biomedical text. In\nthis paper, we show that fine-tuning BERT on legal documents similarly provides\nvaluable improvements on NLP tasks in the legal domain. Demonstrating this\noutcome is significant for analyzing commercial agreements, because obtaining\nlarge legal corpora is challenging due to their confidential nature. As such,\nwe show that having access to large legal corpora is a competitive advantage\nfor commercial applications, and academic research on analyzing contracts.", "published": "2019-11-01 17:30:21", "link": "http://arxiv.org/abs/1911.00473v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What Gets Echoed? Understanding the \"Pointers\" in Explanations of\n  Persuasive Arguments", "abstract": "Explanations are central to everyday life, and are a topic of growing\ninterest in the AI community. To investigate the process of providing natural\nlanguage explanations, we leverage the dynamics of the /r/ChangeMyView\nsubreddit to build a dataset with 36K naturally occurring explanations of why\nan argument is persuasive. We propose a novel word-level prediction task to\ninvestigate how explanations selectively reuse, or echo, information from what\nis being explained (henceforth, explanandum). We develop features to capture\nthe properties of a word in the explanandum, and show that our proposed\nfeatures not only have relatively strong predictive power on the echoing of a\nword in an explanation, but also enhance neural methods of generating\nexplanations. In particular, while the non-contextual properties of a word\nitself are more valuable for stopwords, the interaction between the constituent\nparts of an explanandum is crucial in predicting the echoing of content words.\nWe also find intriguing patterns of a word being echoed. For example, although\nnouns are generally less likely to be echoed, subjects and objects can,\ndepending on their source, be more likely to be echoed in the explanations.", "published": "2019-11-01 18:00:05", "link": "http://arxiv.org/abs/1911.00523v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep neural networks for emotion recognition combining audio and\n  transcripts", "abstract": "In this paper, we propose to improve emotion recognition by combining\nacoustic information and conversation transcripts. On the one hand, an LSTM\nnetwork was used to detect emotion from acoustic features like f0, shimmer,\njitter, MFCC, etc. On the other hand, a multi-resolution CNN was used to detect\nemotion from word sequences. This CNN consists of several parallel convolutions\nwith different kernel sizes to exploit contextual information at different\nlevels. A temporal pooling layer aggregates the hidden representations of\ndifferent words into a unique sequence level embedding, from which we computed\nthe emotion posteriors. We optimized a weighted sum of classification and\nverification losses. The verification loss tries to bring embeddings from the\nsame emotions closer while separating embeddings from different emotions. We\nalso compared our CNN with state-of-the-art text-based hand-crafted features\n(e-vector). We evaluated our approach on the USC-IEMOCAP dataset as well as the\ndataset consisting of US English telephone speech. In the former, we used\nhuman-annotated transcripts while in the latter, we used ASR transcripts. The\nresults showed fusing audio and transcript information improved unweighted\naccuracy by relative 24% for IEMOCAP and relative 3.4% for the telephone data\ncompared to a single acoustic system.", "published": "2019-11-01 15:44:52", "link": "http://arxiv.org/abs/1911.00432v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Predicting word error rate for reverberant speech", "abstract": "Reverberation negatively impacts the performance of automatic speech\nrecognition (ASR). Prior work on quantifying the effect of reverberation has\nshown that clarity (C50), a parameter that can be estimated from the acoustic\nimpulse response, is correlated with ASR performance. In this paper we propose\npredicting ASR performance in terms of the word error rate (WER) directly from\nacoustic parameters via a polynomial, sigmoidal, or neural network fit, as well\nas blindly from reverberant speech samples using a convolutional neural network\n(CNN). We carry out experiments on two state-of-the-art ASR models and a large\nset of acoustic impulse responses (AIRs). The results confirm C50 and C80 to be\nhighly correlated with WER, allowing WER to be predicted with the proposed\nfitting approaches. The proposed non-intrusive CNN model outperforms C50-based\nWER prediction, indicating that WER can be estimated blindly, i.e., directly\nfrom the reverberant speech samples without knowledge of the acoustic\nparameters.", "published": "2019-11-01 19:45:50", "link": "http://arxiv.org/abs/1911.00566v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards Robust Deep Neural Networks for Affect and Depression\n  Recognition from Speech", "abstract": "Intelligent monitoring systems and affective computing applications have\nemerged in recent years to enhance healthcare. Examples of these applications\ninclude assessment of affective states such as Major Depressive Disorder (MDD).\nMDD describes the constant expression of certain emotions: negative emotions\n(low Valence) and lack of interest (low Arousal). High-performing intelligent\nsystems would enhance MDD diagnosis in its early stages. In this paper, we\npresent a new deep neural network architecture, called EmoAudioNet, for emotion\nand depression recognition from speech. Deep EmoAudioNet learns from the\ntime-frequency representation of the audio signal and the visual representation\nof its spectrum of frequencies. Our model shows very promising results in\npredicting affect and depression. It works similarly or outperforms the\nstate-of-the-art methods according to several evaluation metrics on RECOLA and\non DAIC-WOZ datasets in predicting arousal, valence, and depression. Code of\nEmoAudioNet is publicly available on GitHub:\nhttps://github.com/AliceOTHMANI/EmoAudioNet", "published": "2019-11-01 11:38:58", "link": "http://arxiv.org/abs/1911.00310v4", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Learning a Representation for Cover Song Identification Using\n  Convolutional Neural Network", "abstract": "Cover song identification represents a challenging task in the field of Music\nInformation Retrieval (MIR) due to complex musical variations between query\ntracks and cover versions. Previous works typically utilize hand-crafted\nfeatures and alignment algorithms for the task. More recently, further\nbreakthroughs are achieved employing neural network approaches. In this paper,\nwe propose a novel Convolutional Neural Network (CNN) architecture based on the\ncharacteristics of the cover song task. We first train the network through\nclassification strategies; the network is then used to extract music\nrepresentation for cover song identification. A scheme is designed to train\nrobust models against tempo changes. Experimental results show that our\napproach outperforms state-of-the-art methods on all public datasets, improving\nthe performance especially on the large dataset.", "published": "2019-11-01 12:32:40", "link": "http://arxiv.org/abs/1911.00334v1", "categories": ["cs.MM", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Long-distance Detection of Bioacoustic Events with Per-channel Energy\n  Normalization", "abstract": "This paper proposes to perform unsupervised detection of bioacoustic events\nby pooling the magnitudes of spectrogram frames after per-channel energy\nnormalization (PCEN). Although PCEN was originally developed for speech\nrecognition, it also has beneficial effects in enhancing animal vocalizations,\ndespite the presence of atmospheric absorption and intermittent noise. We prove\nthat PCEN generalizes logarithm-based spectral flux, yet with a tunable time\nscale for background noise estimation. In comparison with pointwise logarithm,\nPCEN reduces false alarm rate by 50x in the near field and 5x in the far field,\nboth on avian and marine bioacoustic datasets. Such improvements come at\nmoderate computational cost and require no human intervention, thus heralding a\npromising future for PCEN in bioacoustics.", "published": "2019-11-01 14:50:33", "link": "http://arxiv.org/abs/1911.00417v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Memory Requirement Reduction of Deep Neural Networks Using Low-bit\n  Quantization of Parameters", "abstract": "Effective employment of deep neural networks (DNNs) in mobile devices and\nembedded systems is hampered by requirements for memory and computational\npower. This paper presents a non-uniform quantization approach which allows for\ndynamic quantization of DNN parameters for different layers and within the same\nlayer. A virtual bit shift (VBS) scheme is also proposed to improve the\naccuracy of the proposed scheme. Our method reduces the memory requirements,\npreserving the performance of the network. The performance of our method is\nvalidated in a speech enhancement application, where a fully connected DNN is\nused to predict the clean speech spectrum from the input noisy speech spectrum.\nA DNN is optimized and its memory footprint and performance are evaluated using\nthe short-time objective intelligibility, STOI, metric. The application of the\nlow-bit quantization allows a 50% reduction of the DNN memory footprint while\nthe STOI performance drops only by 2.7%.", "published": "2019-11-01 18:03:12", "link": "http://arxiv.org/abs/1911.00527v1", "categories": ["eess.AS", "cs.LG", "cs.PF", "cs.SD"], "primary_category": "eess.AS"}
