{"title": "Investigating Reinforcement Learning for Communication Strategies in a\n  Task-Initiative Setting", "abstract": "Many conversational domains require the system to present nuanced information\nto users. Such systems must follow up what they say to address clarification\nquestions and repair misunderstandings. In this work, we explore this\ninteractive strategy in a referential communication task. Using simulation, we\nanalyze the communication trade-offs between initial presentation and\nsubsequent followup as a function of user clarification strategy, and compare\nthe performance of several baseline strategies to policies derived by\nreinforcement learning. We find surprising advantages to coherence-based\nrepresentations of dialogue strategy, which bring minimal data requirements,\nexplainable choices, and strong audit capabilities, but incur little loss in\npredicted outcomes across a wide range of user models.", "published": "2023-08-03 00:10:23", "link": "http://arxiv.org/abs/2308.01479v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Model Displays Emergent Ability to Interpret Novel\n  Literary Metaphors", "abstract": "Recent advances in the performance of large language models (LLMs) have\nsparked debate over whether, given sufficient training, high-level human\nabilities emerge in such generic forms of artificial intelligence (AI). Despite\nthe exceptional performance of LLMs on a wide range of tasks involving natural\nlanguage processing and reasoning, there has been sharp disagreement as to\nwhether their abilities extend to more creative human abilities. A core example\nis the ability to interpret novel metaphors. Given the enormous and non curated\ntext corpora used to train LLMs, a serious obstacle to designing tests is the\nrequirement of finding novel yet high quality metaphors that are unlikely to\nhave been included in the training data. Here we assessed the ability of GPT4,\na state of the art large language model, to provide natural-language\ninterpretations of novel literary metaphors drawn from Serbian poetry and\ntranslated into English. Despite exhibiting no signs of having been exposed to\nthese metaphors previously, the AI system consistently produced detailed and\nincisive interpretations. Human judges, blind to the fact that an AI model was\ninvolved, rated metaphor interpretations generated by GPT4 as superior to those\nprovided by a group of college students. In interpreting reversed metaphors,\nGPT4, as well as humans, exhibited signs of sensitivity to the Gricean\ncooperative principle. In addition, for several novel English poems GPT4\nproduced interpretations that were rated as excellent or good by a human\nliterary critic. These results indicate that LLMs such as GPT4 have acquired an\nemergent ability to interpret complex metaphors, including those embedded in\nnovel poems.", "published": "2023-08-03 01:46:27", "link": "http://arxiv.org/abs/2308.01497v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Baby's CoThought: Leveraging Large Language Models for Enhanced\n  Reasoning in Compact Models", "abstract": "Large Language Models (LLMs) demonstrate remarkable performance on a variety\nof natural language understanding (NLU) tasks, primarily due to their\nin-context learning ability. This ability could be applied to building babylike\nmodels, i.e. models at small scales, improving training efficiency. In this\npaper, we propose a \"CoThought\" pipeline, which efficiently trains smaller\n\"baby\" language models (BabyLMs) by leveraging the Chain of Thought prompting\nof LLMs. Our pipeline restructures a dataset of less than 100M in size using\nGPT-3.5-turbo, transforming it into task-oriented, human-readable texts that\nare comparable to the school texts for language learners. The BabyLM is then\npretrained on this restructured dataset in a RoBERTa fashion. In evaluations\nacross 4 benchmarks, our BabyLM outperforms the vanilla RoBERTa in 10\nlinguistic, NLU, and question-answering tasks by more than 3 points, showing a\nsuperior ability to extract contextual information. These results suggest that\ncompact LMs pretrained on small, LLM-restructured data can better understand\ntasks and achieve improved performance.", "published": "2023-08-03 10:52:52", "link": "http://arxiv.org/abs/2308.01684v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Supply chain emission estimation using large language models", "abstract": "Large enterprises face a crucial imperative to achieve the Sustainable\nDevelopment Goals (SDGs), especially goal 13, which focuses on combating\nclimate change and its impacts. To mitigate the effects of climate change,\nreducing enterprise Scope 3 (supply chain emissions) is vital, as it accounts\nfor more than 90\\% of total emission inventories. However, tracking Scope 3\nemissions proves challenging, as data must be collected from thousands of\nupstream and downstream suppliers.To address the above mentioned challenges, we\npropose a first-of-a-kind framework that uses domain-adapted NLP foundation\nmodels to estimate Scope 3 emissions, by utilizing financial transactions as a\nproxy for purchased goods and services. We compared the performance of the\nproposed framework with the state-of-art text classification models such as\nTF-IDF, word2Vec, and Zero shot learning. Our results show that the\ndomain-adapted foundation model outperforms state-of-the-art text mining\ntechniques and performs as well as a subject matter expert (SME). The proposed\nframework could accelerate the Scope 3 estimation at Enterprise scale and will\nhelp to take appropriate climate actions to achieve SDG 13.", "published": "2023-08-03 13:06:37", "link": "http://arxiv.org/abs/2308.01741v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Correction Remain A Problem For Large Language Models?", "abstract": "As large language models, such as GPT, continue to advance the capabilities\nof natural language processing (NLP), the question arises: does the problem of\ncorrection still persist? This paper investigates the role of correction in the\ncontext of large language models by conducting two experiments. The first\nexperiment focuses on correction as a standalone task, employing few-shot\nlearning techniques with GPT-like models for error correction. The second\nexperiment explores the notion of correction as a preparatory task for other\nNLP tasks, examining whether large language models can tolerate and perform\nadequately on texts containing certain levels of noise or errors. By addressing\nthese experiments, we aim to shed light on the significance of correction in\nthe era of large language models and its implications for various NLP\napplications.", "published": "2023-08-03 14:09:31", "link": "http://arxiv.org/abs/2308.01776v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lexicon and Rule-based Word Lemmatization Approach for the Somali\n  Language", "abstract": "Lemmatization is a Natural Language Processing (NLP) technique used to\nnormalize text by changing morphological derivations of words to their root\nforms. It is used as a core pre-processing step in many NLP tasks including\ntext indexing, information retrieval, and machine learning for NLP, among\nothers. This paper pioneers the development of text lemmatization for the\nSomali language, a low-resource language with very limited or no prior\neffective adoption of NLP methods and datasets. We especially develop a lexicon\nand rule-based lemmatizer for Somali text, which is a starting point for a\nfull-fledged Somali lemmatization system for various NLP tasks. With\nconsideration of the language morphological rules, we have developed an initial\nlexicon of 1247 root words and 7173 derivationally related terms enriched with\nrules for lemmatizing words not present in the lexicon. We have tested the\nalgorithm on 120 documents of various lengths including news articles, social\nmedia posts, and text messages. Our initial results demonstrate that the\nalgorithm achieves an accuracy of 57\\% for relatively long documents (e.g. full\nnews articles), 60.57\\% for news article extracts, and high accuracy of 95.87\\%\nfor short texts such as social media messages.", "published": "2023-08-03 14:31:57", "link": "http://arxiv.org/abs/2308.01785v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scaling Relationship on Learning Mathematical Reasoning with Large\n  Language Models", "abstract": "Mathematical reasoning is a challenging task for large language models\n(LLMs), while the scaling relationship of it with respect to LLM capacity is\nunder-explored. In this paper, we investigate how the pre-training loss,\nsupervised data amount, and augmented data amount influence the reasoning\nperformances of a supervised LLM. We find that pre-training loss is a better\nindicator of the model's performance than the model's parameter count. We apply\nsupervised fine-tuning (SFT) with different amounts of supervised data and\nempirically find a log-linear relation between data amount and model\nperformance, and we find better models improve less with enlarged supervised\ndatasets. To augment more data samples for improving model performances without\nany human effort, we propose to apply Rejection sampling Fine-Tuning (RFT). RFT\nuses supervised models to generate and collect correct reasoning paths as\naugmented fine-tuning datasets. We find with augmented samples containing more\ndistinct reasoning paths, RFT improves mathematical reasoning performance more\nfor LLMs. We also find RFT brings more improvement for less performant LLMs.\nFurthermore, we combine rejection samples from multiple models which push\nLLaMA-7B to an accuracy of 49.3\\% on GSM8K which outperforms the supervised\nfine-tuning (SFT) accuracy of 35.9\\% significantly.", "published": "2023-08-03 15:34:01", "link": "http://arxiv.org/abs/2308.01825v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "XNLP: An Interactive Demonstration System for Universal Structured NLP", "abstract": "Structured Natural Language Processing (XNLP) is an important subset of NLP\nthat entails understanding the underlying semantic or syntactic structure of\ntexts, which serves as a foundational component for many downstream\napplications. Despite certain recent efforts to explore universal solutions for\nspecific categories of XNLP tasks, a comprehensive and effective approach for\nunifying all XNLP tasks long remains underdeveloped. In the meanwhile, while\nXNLP demonstration systems are vital for researchers exploring various XNLP\ntasks, existing platforms can be limited to, e.g., supporting few XNLP tasks,\nlacking interactivity and universalness. To this end, we propose an advanced\nXNLP demonstration platform, where we propose leveraging LLM to achieve\nuniversal XNLP, with one model for all with high generalizability. Overall, our\nsystem advances in multiple aspects, including universal XNLP modeling, high\nperformance, interpretability, scalability, and interactivity, providing a\nunified platform for exploring diverse XNLP tasks in the community. XNLP is\nonline: https://xnlp.haofei.vip", "published": "2023-08-03 16:13:05", "link": "http://arxiv.org/abs/2308.01846v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Wider and Deeper LLM Networks are Fairer LLM Evaluators", "abstract": "Measuring the quality of responses generated by LLMs is a challenging task,\nparticularly when it comes to evaluating whether the response is aligned with\nhuman preference. A novel approach involves using the LLM itself to make\nevaluation and stabilizing the results through multiple independent\nevaluations, similar to a single-layer narrow LLM network. This network\nconsists of a fixed number of neurons, with each neuron being the same LLM. In\nthis paper, we draw upon the extensive research on deep neural networks to\nexplore whether deeper and wider networks can lead to fairer evaluations.\nSpecifically, inspired by the observation that different neurons in a neural\nnetwork are responsible for detecting different concepts, we first adaptively\ngenerate as many neuron roles as possible for each evaluation sample. Each\nperspective corresponds to the role of a specific LLM neuron in the first\nlayer. In subsequent layers, we follow the idea that higher layers in deep\nnetworks are responsible for more comprehensive features, each layer receives\nrepresentations from all neurons in the previous layer, integrating the locally\nlearned evaluation information to obtain a more comprehensive evaluation\nresult. Interestingly, this network design resembles the process of academic\npaper reviewing. To validate the effectiveness of our method, we construct the\nlargest and most diverse English evaluation benchmark LLMEval$^2$ for LLM\nevaluators, comprising 15 tasks, 8 abilities, and 2,553 samples. Experimental\nresults demonstrate that a wider network (involving many reviewers) with 2\nlayers (one round of discussion) performs the best, improving kappa correlation\ncoefficient from 0.28 to 0.34. We also leverage WideDeep to aid in the\nassessment of Chinese LLMs, which has accelerated the evaluation time by 4.6\ntimes, resulting in a 60% cost saving. WideDeep achieves a remarkable 93%\nagreement level among humans.", "published": "2023-08-03 16:38:34", "link": "http://arxiv.org/abs/2308.01862v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tag Prediction of Competitive Programming Problems using Deep Learning\n  Techniques", "abstract": "In the past decade, the amount of research being done in the fields of\nmachine learning and deep learning, predominantly in the area of natural\nlanguage processing (NLP), has risen dramatically. A well-liked method for\ndeveloping programming abilities like logic building and problem solving is\ncompetitive programming. It can be tough for novices and even veteran\nprogrammers to traverse the wide collection of questions due to the massive\nnumber of accessible questions and the variety of themes, levels of difficulty,\nand questions offered. In order to help programmers find questions that are\nappropriate for their knowledge and interests, there is a need for an automated\nmethod. This can be done using automated tagging of the questions using Text\nClassification. Text classification is one of the important tasks widely\nresearched in the field of Natural Language Processing. In this paper, we\npresent a way to use text classification techniques to determine the domain of\na competitive programming problem. A variety of models, including are\nimplemented LSTM, GRU, and MLP. The dataset has been scraped from Codeforces, a\nmajor competitive programming website. A total of 2400 problems were scraped\nand preprocessed, which we used as a dataset for our training and testing of\nmodels. The maximum accuracy reached using our model is 78.0% by MLP(Multi\nLayer Perceptron).", "published": "2023-08-03 16:39:02", "link": "http://arxiv.org/abs/2308.01863v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Athena 2.0: Discourse and User Modeling in Open Domain Dialogue", "abstract": "Conversational agents are consistently growing in popularity and many people\ninteract with them every day. While many conversational agents act as personal\nassistants, they can have many different goals. Some are task-oriented, such as\nproviding customer support for a bank or making a reservation. Others are\ndesigned to be empathetic and to form emotional connections with the user. The\nAlexa Prize Challenge aims to create a socialbot, which allows the user to\nengage in coherent conversations, on a range of popular topics that will\ninterest the user. Here we describe Athena 2.0, UCSC's conversational agent for\nAmazon's Socialbot Grand Challenge 4. Athena 2.0 utilizes a novel\nknowledge-grounded discourse model that tracks the entity links that Athena\nintroduces into the dialogue, and uses them to constrain named-entity\nrecognition and linking, and coreference resolution. Athena 2.0 also relies on\na user model to personalize topic selection and other aspects of the\nconversation to individual users.", "published": "2023-08-03 17:30:39", "link": "http://arxiv.org/abs/2308.01887v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bengali Fake Reviews: A Benchmark Dataset and Detection System", "abstract": "The proliferation of fake reviews on various online platforms has created a\nmajor concern for both consumers and businesses. Such reviews can deceive\ncustomers and cause damage to the reputation of products or services, making it\ncrucial to identify them. Although the detection of fake reviews has been\nextensively studied in English language, detecting fake reviews in non-English\nlanguages such as Bengali is still a relatively unexplored research area. This\npaper introduces the Bengali Fake Review Detection (BFRD) dataset, the first\npublicly available dataset for identifying fake reviews in Bengali. The dataset\nconsists of 7710 non-fake and 1339 fake food-related reviews collected from\nsocial media posts. To convert non-Bengali words in a review, a unique pipeline\nhas been proposed that translates English words to their corresponding Bengali\nmeaning and also back transliterates Romanized Bengali to Bengali. We have\nconducted rigorous experimentation using multiple deep learning and pre-trained\ntransformer language models to develop a reliable detection system. Finally, we\npropose a weighted ensemble model that combines four pre-trained transformers:\nBanglaBERT, BanglaBERT Base, BanglaBERT Large, and BanglaBERT Generator .\nAccording to the experiment results, the proposed ensemble model obtained a\nweighted F1-score of 0.9843 on 13390 reviews, including 1339 actual fake\nreviews and 5356 augmented fake reviews generated with the nlpaug library. The\nremaining 6695 reviews were randomly selected from the 7710 non-fake instances.\nThe model achieved a 0.9558 weighted F1-score when the fake reviews were\naugmented using the bnaug library.", "published": "2023-08-03 18:49:45", "link": "http://arxiv.org/abs/2308.01987v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Baby Llama: knowledge distillation from an ensemble of teachers trained\n  on a small dataset with no performance penalty", "abstract": "We present our submission to the BabyLM challenge, whose goal was to improve\nthe sample efficiency of language models. We trained an ensemble consisting of\na GPT-2 and small LLaMA models on the developmentally-plausible, 10M-word\nBabyLM dataset, then distilled it into a small, 58M-parameter LLaMA model,\nwhich exceeds in performance both of its teachers as well as a similar model\ntrained without distillation. This suggests that distillation can not only\nretain the full performance of the teacher model when the latter is trained on\na sufficiently small dataset; it can exceed it, and lead to significantly\nbetter performance than direct training.", "published": "2023-08-03 20:20:01", "link": "http://arxiv.org/abs/2308.02019v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Efficient Sentiment Analysis: A Resource-Aware Evaluation of Feature\n  Extraction Techniques, Ensembling, and Deep Learning Models", "abstract": "While reaching for NLP systems that maximize accuracy, other important\nmetrics of system performance are often overlooked. Prior models are easily\nforgotten despite their possible suitability in settings where large computing\nresources are unavailable or relatively more costly. In this paper, we perform\na broad comparative evaluation of document-level sentiment analysis models with\na focus on resource costs that are important for the feasibility of model\ndeployment and general climate consciousness. Our experiments consider\ndifferent feature extraction techniques, the effect of ensembling,\ntask-specific deep learning modeling, and domain-independent large language\nmodels (LLMs). We find that while a fine-tuned LLM achieves the best accuracy,\nsome alternate configurations provide huge (up to 24, 283 *) resource savings\nfor a marginal (<1%) loss in accuracy. Furthermore, we find that for smaller\ndatasets, the differences in accuracy shrink while the difference in resource\nconsumption grows further.", "published": "2023-08-03 20:29:27", "link": "http://arxiv.org/abs/2308.02022v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BioBERT Based SNP-traits Associations Extraction from Biomedical\n  Literature", "abstract": "Scientific literature contains a considerable amount of information that\nprovides an excellent opportunity for developing text mining methods to extract\nbiomedical relationships. An important type of information is the relationship\nbetween singular nucleotide polymorphisms (SNP) and traits. In this paper, we\npresent a BioBERT-GRU method to identify SNP- traits associations. Based on the\nevaluation of our method on the SNPPhenA dataset, it is concluded that this new\nmethod performs better than previous machine learning and deep learning based\nmethods. BioBERT-GRU achieved the result a precision of 0.883, recall of 0.882\nand F1-score of 0.881.", "published": "2023-08-03 09:40:27", "link": "http://arxiv.org/abs/2308.02569v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Neurons in Pretrained Text-Only Transformers", "abstract": "Language models demonstrate remarkable capacity to generalize representations\nlearned in one modality to downstream tasks in other modalities. Can we trace\nthis ability to individual neurons? We study the case where a frozen text\ntransformer is augmented with vision using a self-supervised visual encoder and\na single linear projection learned on an image-to-text task. Outputs of the\nprojection layer are not immediately decodable into language describing image\ncontent; instead, we find that translation between modalities occurs deeper\nwithin the transformer. We introduce a procedure for identifying \"multimodal\nneurons\" that convert visual representations into corresponding text, and\ndecoding the concepts they inject into the model's residual stream. In a series\nof experiments, we show that multimodal neurons operate on specific visual\nconcepts across inputs, and have a systematic causal effect on image\ncaptioning.", "published": "2023-08-03 05:27:12", "link": "http://arxiv.org/abs/2308.01544v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Evaluating ChatGPT text-mining of clinical records for obesity\n  monitoring", "abstract": "Background: Veterinary clinical narratives remain a largely untapped resource\nfor addressing complex diseases. Here we compare the ability of a large\nlanguage model (ChatGPT) and a previously developed regular expression (RegexT)\nto identify overweight body condition scores (BCS) in veterinary narratives.\nMethods: BCS values were extracted from 4,415 anonymised clinical narratives\nusing either RegexT or by appending the narrative to a prompt sent to ChatGPT\ncoercing the model to return the BCS information. Data were manually reviewed\nfor comparison. Results: The precision of RegexT was higher (100%, 95% CI\n94.81-100%) than the ChatGPT (89.3%; 95% CI82.75-93.64%). However, the recall\nof ChatGPT (100%. 95% CI 96.18-100%) was considerably higher than that of\nRegexT (72.6%, 95% CI 63.92-79.94%). Limitations: Subtle prompt engineering is\nneeded to improve ChatGPT output. Conclusions: Large language models create\ndiverse opportunities and, whilst complex, present an intuitive interface to\ninformation but require careful implementation to avoid unpredictable errors.", "published": "2023-08-03 10:11:42", "link": "http://arxiv.org/abs/2308.01666v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "NBIAS: A Natural Language Processing Framework for Bias Identification\n  in Text", "abstract": "Bias in textual data can lead to skewed interpretations and outcomes when the\ndata is used. These biases could perpetuate stereotypes, discrimination, or\nother forms of unfair treatment. An algorithm trained on biased data may end up\nmaking decisions that disproportionately impact a certain group of people.\nTherefore, it is crucial to detect and remove these biases to ensure the fair\nand ethical use of data. To this end, we develop a comprehensive and robust\nframework NBIAS that consists of four main layers: data, corpus construction,\nmodel development and an evaluation layer. The dataset is constructed by\ncollecting diverse data from various domains, including social media,\nhealthcare, and job hiring portals. As such, we applied a transformer-based\ntoken classification model that is able to identify bias words/ phrases through\na unique named entity BIAS. In the evaluation procedure, we incorporate a blend\nof quantitative and qualitative measures to gauge the effectiveness of our\nmodels. We achieve accuracy improvements ranging from 1% to 8% compared to\nbaselines. We are also able to generate a robust understanding of the model\nfunctioning. The proposed approach is applicable to a variety of biases and\ncontributes to the fair and ethical use of textual data.", "published": "2023-08-03 10:48:30", "link": "http://arxiv.org/abs/2308.01681v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Local Large Language Models for Complex Structured Medical Tasks", "abstract": "This paper introduces an approach that combines the language reasoning\ncapabilities of large language models (LLMs) with the benefits of local\ntraining to tackle complex, domain-specific tasks. Specifically, the authors\ndemonstrate their approach by extracting structured condition codes from\npathology reports. The proposed approach utilizes local LLMs, which can be\nfine-tuned to respond to specific generative instructions and provide\nstructured outputs. The authors collected a dataset of over 150k uncurated\nsurgical pathology reports, containing gross descriptions, final diagnoses, and\ncondition codes. They trained different model architectures, including LLaMA,\nBERT and LongFormer and evaluated their performance. The results show that the\nLLaMA-based models significantly outperform BERT-style models across all\nevaluated metrics, even with extremely reduced precision. The LLaMA models\nperformed especially well with large datasets, demonstrating their ability to\nhandle complex, multi-label tasks. Overall, this work presents an effective\napproach for utilizing LLMs to perform domain-specific tasks using accessible\nhardware, with potential applications in the medical domain, where complex data\nextraction and classification are required.", "published": "2023-08-03 12:36:13", "link": "http://arxiv.org/abs/2308.01727v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Ambient Adventures: Teaching ChatGPT on Developing Complex Stories", "abstract": "Imaginative play is an area of creativity that could allow robots to engage\nwith the world around them in a much more personified way. Imaginary play can\nbe seen as taking real objects and locations and using them as imaginary\nobjects and locations in virtual scenarios. We adopted the story generation\ncapability of large language models (LLMs) to obtain the stories used for\nimaginary play with human-written prompts. Those generated stories will be\nsimplified and mapped into action sequences that can guide the agent in\nimaginary play. To evaluate whether the agent can successfully finish the\nimaginary play, we also designed a text adventure game to simulate a house as\nthe playground for the agent to interact.", "published": "2023-08-03 12:52:49", "link": "http://arxiv.org/abs/2308.01734v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Curricular Transfer Learning for Sentence Encoded Tasks", "abstract": "Fine-tuning language models in a downstream task is the standard approach for\nmany state-of-the-art methodologies in the field of NLP. However, when the\ndistribution between the source task and target task drifts, \\textit{e.g.},\nconversational environments, these gains tend to be diminished. This article\nproposes a sequence of pre-training steps (a curriculum) guided by \"data\nhacking\" and grammar analysis that allows further gradual adaptation between\npre-training distributions. In our experiments, we acquire a considerable\nimprovement from our method compared to other known pre-training approaches for\nthe MultiWoZ task.", "published": "2023-08-03 16:18:19", "link": "http://arxiv.org/abs/2308.01849v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on\n  Class-level Code Generation", "abstract": "In this work, we make the first attempt to evaluate LLMs in a more\nchallenging code generation scenario, i.e. class-level code generation. We\nfirst manually construct the first class-level code generation benchmark\nClassEval of 100 class-level Python code generation tasks with approximately\n500 person-hours. Based on it, we then perform the first study of 11\nstate-of-the-art LLMs on class-level code generation. Based on our results, we\nhave the following main findings. First, we find that all existing LLMs show\nmuch worse performance on class-level code generation compared to on standalone\nmethod-level code generation benchmarks like HumanEval; and the method-level\ncoding ability cannot equivalently reflect the class-level coding ability among\nLLMs. Second, we find that GPT-4 and GPT-3.5 still exhibit dominate superior\nthan other LLMs on class-level code generation, and the second-tier models\nincludes Instruct-Starcoder, Instruct-Codegen, and Wizardcoder with very\nsimilar performance. Third, we find that generating the entire class all at\nonce (i.e. holistic generation strategy) is the best generation strategy only\nfor GPT-4 and GPT-3.5, while method-by-method generation (i.e. incremental and\ncompositional) is better strategies for the other models with limited ability\nof understanding long instructions and utilizing the middle information.\nLastly, we find the limited model ability of generating method-dependent code\nand discuss the frequent error types in generated classes. Our benchmark is\navailable at https://github.com/FudanSELab/ClassEval.", "published": "2023-08-03 16:31:02", "link": "http://arxiv.org/abs/2308.01861v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Thespian: Multi-Character Text Role-Playing Game Agents", "abstract": "Text-adventure games and text role-playing games are grand challenges for\nreinforcement learning game playing agents. Text role-playing games are\nopen-ended environments where an agent must faithfully play a particular\ncharacter. We consider the distinction between characters and actors, where an\nactor agent has the ability to play multiple characters. We present a framework\nwe call a thespian agent that can learn to emulate multiple characters along\nwith a soft prompt that can be used to direct it as to which character to play\nat any time. We further describe an attention mechanism that allows the agent\nto learn new characters that are based on previously learned characters in a\nfew-shot fashion. We show that our agent outperforms the state of the art agent\nframework in multi-character learning and few-shot learning.", "published": "2023-08-03 16:53:53", "link": "http://arxiv.org/abs/2308.01872v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Causality Guided Disentanglement for Cross-Platform Hate Speech\n  Detection", "abstract": "Social media platforms, despite their value in promoting open discourse, are\noften exploited to spread harmful content. Current deep learning and natural\nlanguage processing models used for detecting this harmful content overly rely\non domain-specific terms affecting their capabilities to adapt to generalizable\nhate speech detection. This is because they tend to focus too narrowly on\nparticular linguistic signals or the use of certain categories of words.\nAnother significant challenge arises when platforms lack high-quality annotated\ndata for training, leading to a need for cross-platform models that can adapt\nto different distribution shifts. Our research introduces a cross-platform hate\nspeech detection model capable of being trained on one platform's data and\ngeneralizing to multiple unseen platforms. To achieve good generalizability\nacross platforms, one way is to disentangle the input representations into\ninvariant and platform-dependent features. We also argue that learning causal\nrelationships, which remain constant across diverse environments, can\nsignificantly aid in understanding invariant representations in hate speech. By\ndisentangling input into platform-dependent features (useful for predicting\nhate targets) and platform-independent features (used to predict the presence\nof hate), we learn invariant representations resistant to distribution shifts.\nThese features are then used to predict hate speech across unseen platforms.\nOur extensive experiments across four platforms highlight our model's enhanced\nefficacy compared to existing state-of-the-art methods in detecting generalized\nhate speech.", "published": "2023-08-03 23:39:03", "link": "http://arxiv.org/abs/2308.02080v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SimTeG: A Frustratingly Simple Approach Improves Textual Graph Learning", "abstract": "Textual graphs (TGs) are graphs whose nodes correspond to text (sentences or\ndocuments), which are widely prevalent. The representation learning of TGs\ninvolves two stages: (i) unsupervised feature extraction and (ii) supervised\ngraph representation learning. In recent years, extensive efforts have been\ndevoted to the latter stage, where Graph Neural Networks (GNNs) have dominated.\nHowever, the former stage for most existing graph benchmarks still relies on\ntraditional feature engineering techniques. More recently, with the rapid\ndevelopment of language models (LMs), researchers have focused on leveraging\nLMs to facilitate the learning of TGs, either by jointly training them in a\ncomputationally intensive framework (merging the two stages), or designing\ncomplex self-supervised training tasks for feature extraction (enhancing the\nfirst stage). In this work, we present SimTeG, a frustratingly Simple approach\nfor Textual Graph learning that does not innovate in frameworks, models, and\ntasks. Instead, we first perform supervised parameter-efficient fine-tuning\n(PEFT) on a pre-trained LM on the downstream task, such as node classification.\nWe then generate node embeddings using the last hidden states of finetuned LM.\nThese derived features can be further utilized by any GNN for training on the\nsame task. We evaluate our approach on two fundamental graph representation\nlearning tasks: node classification and link prediction. Through extensive\nexperiments, we show that our approach significantly improves the performance\nof various GNNs on multiple graph benchmarks.", "published": "2023-08-03 07:00:04", "link": "http://arxiv.org/abs/2308.02565v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings", "abstract": "This study investigates the consistency of feedback ratings generated by\nOpenAI's GPT-4, a state-of-the-art artificial intelligence language model,\nacross multiple iterations, time spans and stylistic variations. The model\nrated responses to tasks within the Higher Education (HE) subject domain of\nmacroeconomics in terms of their content and style. Statistical analysis was\nconducted in order to learn more about the interrater reliability, consistency\nof the ratings across iterations and the correlation between ratings in terms\nof content and style. The results revealed a high interrater reliability with\nICC scores ranging between 0.94 and 0.99 for different timespans, suggesting\nthat GPT-4 is capable of generating consistent ratings across repetitions with\na clear prompt. Style and content ratings show a high correlation of 0.87. When\napplying a non-adequate style the average content ratings remained constant,\nwhile style ratings decreased, which indicates that the large language model\n(LLM) effectively distinguishes between these two criteria during evaluation.\nThe prompt used in this study is furthermore presented and explained. Further\nresearch is necessary to assess the robustness and reliability of AI models in\nvarious use cases.", "published": "2023-08-03 12:47:17", "link": "http://arxiv.org/abs/2308.02575v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Comparing scalable strategies for generating numerical perspectives", "abstract": "Numerical perspectives help people understand extreme and unfamiliar numbers\n(e.g., \\$330 billion is about \\$1,000 per person in the United States). While\nresearch shows perspectives to be helpful, generating them at scale is\nchallenging both because it is difficult to identify what makes some analogies\nmore helpful than others, and because what is most helpful can vary based on\nthe context in which a given number appears. Here we present and compare three\npolicies for large-scale perspective generation: a rule-based approach, a\ncrowdsourced system, and a model that uses Wikipedia data and semantic\nsimilarity (via BERT embeddings) to generate context-specific perspectives. We\nfind that the combination of these three approaches dominates any single\nmethod, with different approaches excelling in different settings and users\ndisplaying heterogeneous preferences across approaches. We conclude by\ndiscussing our deployment of perspectives in a widely-used online word\nprocessor.", "published": "2023-08-03 04:35:46", "link": "http://arxiv.org/abs/2308.01535v1", "categories": ["cs.HC", "cs.CL", "cs.CY"], "primary_category": "cs.HC"}
{"title": "InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent", "abstract": "This research paper delves into the integration of OpenAI's ChatGPT into\nembodied agent systems, evaluating its influence on interactive decision-making\nbenchmark. Drawing a parallel to the concept of people assuming roles according\nto their unique strengths, we introduce InterAct. In this approach, we feed\nChatGPT with varied prompts, assigning it a numerous roles like a checker and a\nsorter, then integrating them with the original language model. Our research\nshows a remarkable success rate of 98% in AlfWorld, which consists of 6\ndifferent tasks in a simulated household environment, emphasizing the\nsignificance of proficient prompt engineering. The results highlight ChatGPT's\ncompetence in comprehending and performing intricate tasks effectively in\nreal-world settings, thus paving the way for further advancements in task\nplanning.", "published": "2023-08-03 06:19:58", "link": "http://arxiv.org/abs/2308.01552v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Holy Grail 2.0: From Natural Language to Constraint Models", "abstract": "Twenty-seven years ago, E. Freuder highlighted that \"Constraint programming\nrepresents one of the closest approaches computer science has yet made to the\nHoly Grail of programming: the user states the problem, the computer solves\nit\". Nowadays, CP users have great modeling tools available (like Minizinc and\nCPMpy), allowing them to formulate the problem and then let a solver do the\nrest of the job, getting closer to the stated goal. However, this still\nrequires the CP user to know the formalism and respect it. Another significant\nchallenge lies in the expertise required to effectively model combinatorial\nproblems. All this limits the wider adoption of CP. In this position paper, we\ninvestigate a possible approach to leverage pre-trained Large Language Models\nto extract models from textual problem descriptions. More specifically, we take\ninspiration from the Natural Language Processing for Optimization (NL4OPT)\nchallenge and present early results with a decomposition-based prompting\napproach to GPT Models.", "published": "2023-08-03 07:48:02", "link": "http://arxiv.org/abs/2308.01589v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Textless Unit-to-Unit training for Many-to-Many Multilingual\n  Speech-to-Speech Translation", "abstract": "This paper proposes a textless training method for many-to-many multilingual\nspeech-to-speech translation that can also benefit the transfer of pre-trained\nknowledge to text-based systems, text-to-speech synthesis and text-to-speech\ntranslation. To this end, we represent multilingual speech with speech units\nthat are the discretized representations of speech features derived from a\nself-supervised speech model. By treating the speech units as pseudo-text, we\ncan focus on the linguistic content of the speech, which can be easily\nassociated with both speech and text modalities at the phonetic level\ninformation. By setting both the inputs and outputs of our learning problem as\nspeech units, we propose to train an encoder-decoder model in a many-to-many\nspoken language translation setting, namely Unit-to-Unit Translation (UTUT).\nSpecifically, the encoder is conditioned on the source language token to\ncorrectly understand the input spoken language, while the decoder is\nconditioned on the target language token to generate the translated speech in\nthe target language. Therefore, during the training, the model can build the\nknowledge of how languages are comprehended and how to relate them to different\nlanguages. Since speech units can be easily associated from both audio and text\nby quantization and phonemization respectively, the trained model can easily\ntransferred to text-related tasks, even if it is trained in a textless manner.\nWe demonstrate that the proposed UTUT model can be effectively utilized not\nonly for Speech-to-Speech Translation (S2ST) but also for multilingual\nText-to-Speech Synthesis (T2S) and Text-to-Speech Translation (T2ST), requiring\nonly minimal fine-tuning steps on text inputs. By conducting comprehensive\nexperiments encompassing various languages, we validate the efficacy of the\nproposed method across diverse multilingual tasks.", "published": "2023-08-03 15:47:04", "link": "http://arxiv.org/abs/2308.01831v2", "categories": ["cs.CL", "eess.AS", "eess.SP"], "primary_category": "cs.CL"}
{"title": "The Capability of Large Language Models to Measure Psychiatric\n  Functioning", "abstract": "The current work investigates the capability of Large language models (LLMs)\nthat are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2)\nto predict psychiatric functioning from patient interviews and clinical\ndescriptions without being trained to do so. To assess this, n = 145 depression\nand n =115 PTSD assessments and n = 46 clinical case studies across high\nprevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma\nand stress, Addictive disorders) were analyzed using prompts to extract\nestimated clinical scores and diagnoses. Results demonstrate that Med-PaLM 2 is\ncapable of assessing psychiatric functioning across a range of psychiatric\nconditions with the strongest performance being the prediction of depression\nscores based on standardized assessments (Accuracy range= 0.80 - 0.84) which\nwere statistically indistinguishable from human clinical raters t(1,144) =\n1.20; p = 0.23. Results show the potential for general clinical language models\nto flexibly predict psychiatric risk based on free descriptions of functioning\nfrom both patients and clinicians.", "published": "2023-08-03 15:52:27", "link": "http://arxiv.org/abs/2308.01834v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How many preprints have actually been printed and why: a case study of\n  computer science preprints on arXiv", "abstract": "Preprints play an increasingly critical role in academic communities. There\nare many reasons driving researchers to post their manuscripts to preprint\nservers before formal submission to journals or conferences, but the use of\npreprints has also sparked considerable controversy, especially surrounding the\nclaim of priority. In this paper, a case study of computer science preprints\nsubmitted to arXiv from 2008 to 2017 is conducted to quantify how many\npreprints have eventually been printed in peer-reviewed venues. Among those\npublished manuscripts, some are published under different titles and without an\nupdate to their preprints on arXiv. In the case of these manuscripts, the\ntraditional fuzzy matching method is incapable of mapping the preprint to the\nfinal published version. In view of this issue, we introduce a semantics-based\nmapping method with the employment of Bidirectional Encoder Representations\nfrom Transformers (BERT). With this new mapping method and a plurality of data\nsources, we find that 66% of all sampled preprints are published under\nunchanged titles and 11% are published under different titles and with other\nmodifications. A further analysis was then performed to investigate why these\npreprints but not others were accepted for publication. Our comparison reveals\nthat in the field of computer science, published preprints feature adequate\nrevisions, multiple authorship, detailed abstract and introduction, extensive\nand authoritative references and available source code.", "published": "2023-08-03 17:56:16", "link": "http://arxiv.org/abs/2308.01899v1", "categories": ["cs.DL", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.DL"}
{"title": "Reasoning in Large Language Models Through Symbolic Math Word Problems", "abstract": "Large language models (LLMs) have revolutionized NLP by solving downstream\ntasks with little to no labeled data. Despite their versatile abilities, the\nlarger question of their ability to reason remains ill-understood. This paper\naddresses reasoning in math word problems (MWPs) by studying symbolic versions\nof the numeric problems, since a symbolic expression is a \"concise explanation\"\nof the numeric answer. We create and use a symbolic version of the SVAMP\ndataset and find that GPT-3's davinci-002 model also has good zero-shot\naccuracy on symbolic MWPs. To evaluate the faithfulness of the model's\nreasoning, we go beyond accuracy and additionally evaluate the alignment\nbetween the final answer and the outputted reasoning, which correspond to\nnumeric and symbolic answers respectively for MWPs. We explore a self-prompting\napproach to encourage the symbolic reasoning to align with the numeric answer,\nthus equipping the LLM with the ability to provide a concise and verifiable\nreasoning and making it more interpretable. Surprisingly, self-prompting also\nimproves the symbolic accuracy to be higher than both the numeric and symbolic\naccuracies, thus providing an ensembling effect. The SVAMP_Sym dataset will be\nreleased for future research on symbolic math problems.", "published": "2023-08-03 17:59:27", "link": "http://arxiv.org/abs/2308.01906v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Domain specificity and data efficiency in typo tolerant spell checkers:\n  the case of search in online marketplaces", "abstract": "Typographical errors are a major source of frustration for visitors of online\nmarketplaces. Because of the domain-specific nature of these marketplaces and\nthe very short queries users tend to search for, traditional spell cheking\nsolutions do not perform well in correcting typos. We present a data\naugmentation method to address the lack of annotated typo data and train a\nrecurrent neural network to learn context-limited domain-specific embeddings.\nThose embeddings are deployed in a real-time inferencing API for the Microsoft\nAppSource marketplace to find the closest match between a misspelled user query\nand the available product names. Our data efficient solution shows that\ncontrolled high quality synthetic data may be a powerful tool especially\nconsidering the current climate of large language models which rely on\nprohibitively huge and often uncontrolled datasets.", "published": "2023-08-03 18:11:00", "link": "http://arxiv.org/abs/2308.01976v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Federated Representation Learning for Automatic Speech Recognition", "abstract": "Federated Learning (FL) is a privacy-preserving paradigm, allowing edge\ndevices to learn collaboratively without sharing data. Edge devices like Alexa\nand Siri are prospective sources of unlabeled audio data that can be tapped to\nlearn robust audio representations. In this work, we bring Self-supervised\nLearning (SSL) and FL together to learn representations for Automatic Speech\nRecognition respecting data privacy constraints. We use the speaker and chapter\ninformation in the unlabeled speech dataset, Libri-Light, to simulate non-IID\nspeaker-siloed data distributions and pre-train an LSTM encoder with the\nContrastive Predictive Coding framework with FedSGD. We show that the\npre-trained ASR encoder in FL performs as well as a centrally pre-trained model\nand produces an improvement of 12-15% (WER) compared to no pre-training. We\nfurther adapt the federated pre-trained models to a new language, French, and\nshow a 20% (WER) improvement over no pre-training.", "published": "2023-08-03 20:08:23", "link": "http://arxiv.org/abs/2308.02013v2", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The Unequal Opportunities of Large Language Models: Revealing\n  Demographic Bias through Job Recommendations", "abstract": "Large Language Models (LLMs) have seen widespread deployment in various\nreal-world applications. Understanding these biases is crucial to comprehend\nthe potential downstream consequences when using LLMs to make decisions,\nparticularly for historically disadvantaged groups. In this work, we propose a\nsimple method for analyzing and comparing demographic bias in LLMs, through the\nlens of job recommendations. We demonstrate the effectiveness of our method by\nmeasuring intersectional biases within ChatGPT and LLaMA, two cutting-edge\nLLMs. Our experiments primarily focus on uncovering gender identity and\nnationality bias; however, our method can be extended to examine biases\nassociated with any intersection of demographic identities. We identify\ndistinct biases in both models toward various demographic identities, such as\nboth models consistently suggesting low-paying jobs for Mexican workers or\npreferring to recommend secretarial roles to women. Our study highlights the\nimportance of measuring the bias of LLMs in downstream applications to\nunderstand the potential for harm and inequitable outcomes.", "published": "2023-08-03 21:12:54", "link": "http://arxiv.org/abs/2308.02053v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Seasonality Based Reranking of E-commerce Autocomplete Using Natural\n  Language Queries", "abstract": "Query autocomplete (QAC) also known as typeahead, suggests list of complete\nqueries as user types prefix in the search box. It is one of the key features\nof modern search engines specially in e-commerce. One of the goals of typeahead\nis to suggest relevant queries to users which are seasonally important. In this\npaper we propose a neural network based natural language processing (NLP)\nalgorithm to incorporate seasonality as a signal and present end to end\nevaluation of the QAC ranking model. Incorporating seasonality into\nautocomplete ranking model can improve autocomplete relevance and business\nmetric.", "published": "2023-08-03 21:14:25", "link": "http://arxiv.org/abs/2308.02055v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Learning Implicit Entity-object Relations by Bidirectional Generative\n  Alignment for Multimodal NER", "abstract": "The challenge posed by multimodal named entity recognition (MNER) is mainly\ntwo-fold: (1) bridging the semantic gap between text and image and (2) matching\nthe entity with its associated object in image. Existing methods fail to\ncapture the implicit entity-object relations, due to the lack of corresponding\nannotation. In this paper, we propose a bidirectional generative alignment\nmethod named BGA-MNER to tackle these issues. Our BGA-MNER consists of\n\\texttt{image2text} and \\texttt{text2image} generation with respect to\nentity-salient content in two modalities. It jointly optimizes the\nbidirectional reconstruction objectives, leading to aligning the implicit\nentity-object relations under such direct and powerful constraints.\nFurthermore, image-text pairs usually contain unmatched components which are\nnoisy for generation. A stage-refined context sampler is proposed to extract\nthe matched cross-modal content for generation. Extensive experiments on two\nbenchmarks demonstrate that our method achieves state-of-the-art performance\nwithout image input during inference.", "published": "2023-08-03 10:37:20", "link": "http://arxiv.org/abs/2308.02570v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Optimizing multi-user indoor sound communications with acoustic\n  reconfigurable metasurfaces", "abstract": "Sound in indoor spaces forms a complex wavefield due to multiple scattering\nencountered by the sound. Indoor acoustic communication involving multiple\nsources and receivers thus inevitably suffers from cross-talks. Here, we\ndemonstrate the isolation of acoustic communication channels in a room by\nwavefield shaping using acoustic reconfigurable metasurfaces (ARMs) controlled\nby optimization protocols based on communication theories. The ARMs have 200\nelectrically switchable units, each selectively offering 0 or {\\pi} phase\nshifts in the reflected waves. The sound field is reshaped for maximal Shannon\ncapacity and minimal cross-talk simultaneously. We demonstrate diverse acoustic\nfunctionalities over a spectrum much larger than the coherence bandwidth of the\nroom, including multi-channel, multi-spectral channel isolations, and\nfrequency-multiplexed acoustic communication. Our work shows that wavefield\nshaping in complex media can offer new strategies for future acoustic\nengineering.", "published": "2023-08-03 04:10:12", "link": "http://arxiv.org/abs/2308.01531v2", "categories": ["cs.SD", "eess.AS", "physics.app-ph"], "primary_category": "cs.SD"}
{"title": "Adversarial Training of Denoising Diffusion Model Using Dual\n  Discriminators for High-Fidelity Multi-Speaker TTS", "abstract": "The diffusion model is capable of generating high-quality data through a\nprobabilistic approach. However, it suffers from the drawback of slow\ngeneration speed due to the requirement of a large number of time steps. To\naddress this limitation, recent models such as denoising diffusion implicit\nmodels (DDIM) focus on generating samples without directly modeling the\nprobability distribution, while models like denoising diffusion generative\nadversarial networks (GAN) combine diffusion processes with GANs. In the field\nof speech synthesis, a recent diffusion speech synthesis model called\nDiffGAN-TTS, utilizing the structure of GANs, has been introduced and\ndemonstrates superior performance in both speech quality and generation speed.\nIn this paper, to further enhance the performance of DiffGAN-TTS, we propose a\nspeech synthesis model with two discriminators: a diffusion discriminator for\nlearning the distribution of the reverse process and a spectrogram\ndiscriminator for learning the distribution of the generated data. Objective\nmetrics such as structural similarity index measure (SSIM), mel-cepstral\ndistortion (MCD), F0 root mean squared error (F0 RMSE), short-time objective\nintelligibility (STOI), perceptual evaluation of speech quality (PESQ), as well\nas subjective metrics like mean opinion score (MOS), are used to evaluate the\nperformance of the proposed model. The evaluation results show that the\nproposed model outperforms recent state-of-the-art models such as FastSpeech2\nand DiffGAN-TTS in various metrics. Our implementation and audio samples are\nlocated on GitHub.", "published": "2023-08-03 07:22:04", "link": "http://arxiv.org/abs/2308.01573v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Versatile Time-Frequency Representations Realized by Convex Penalty on\n  Magnitude Spectrogram", "abstract": "Sparse time-frequency (T-F) representations have been an important research\ntopic for more than several decades. Among them, optimization-based methods (in\nparticular, extensions of basis pursuit) allow us to design the representations\nthrough objective functions. Since acoustic signal processing utilizes models\nof spectrogram, the flexibility of optimization-based T-F representations is\nhelpful for adjusting the representation for each application. However,\nacoustic applications often require models of \\textit{magnitude} of T-F\nrepresentations obtained by discrete Gabor transform (DGT). Adjusting a T-F\nrepresentation to such a magnitude model (e.g., smoothness of magnitude of DGT\ncoefficients) results in a non-convex optimization problem that is difficult to\nsolve. In this paper, instead of tackling difficult non-convex problems, we\npropose a convex optimization-based framework that realizes a T-F\nrepresentation whose magnitude has characteristics specified by the user. We\nanalyzed the properties of the proposed method and provide numerical examples\nof sparse T-F representations having, e.g., low-rank or smooth magnitude, which\nhave not been realized before.", "published": "2023-08-03 10:08:51", "link": "http://arxiv.org/abs/2308.01665v1", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "MusicLDM: Enhancing Novelty in Text-to-Music Generation Using\n  Beat-Synchronous Mixup Strategies", "abstract": "Diffusion models have shown promising results in cross-modal generation\ntasks, including text-to-image and text-to-audio generation. However,\ngenerating music, as a special type of audio, presents unique challenges due to\nlimited availability of music data and sensitive issues related to copyright\nand plagiarism. In this paper, to tackle these challenges, we first construct a\nstate-of-the-art text-to-music model, MusicLDM, that adapts Stable Diffusion\nand AudioLDM architectures to the music domain. We achieve this by retraining\nthe contrastive language-audio pretraining model (CLAP) and the Hifi-GAN\nvocoder, as components of MusicLDM, on a collection of music data samples.\nThen, to address the limitations of training data and to avoid plagiarism, we\nleverage a beat tracking model and propose two different mixup strategies for\ndata augmentation: beat-synchronous audio mixup and beat-synchronous latent\nmixup, which recombine training audio directly or via a latent embeddings\nspace, respectively. Such mixup strategies encourage the model to interpolate\nbetween musical training samples and generate new music within the convex hull\nof the training data, making the generated music more diverse while still\nstaying faithful to the corresponding style. In addition to popular evaluation\nmetrics, we design several new evaluation metrics based on CLAP score to\ndemonstrate that our proposed MusicLDM and beat-synchronous mixup strategies\nimprove both the quality and novelty of generated music, as well as the\ncorrespondence between input text and generated music.", "published": "2023-08-03 05:35:37", "link": "http://arxiv.org/abs/2308.01546v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
