{"title": "Semi-Supervised Learning for Neural Machine Translation", "abstract": "While end-to-end neural machine translation (NMT) has made remarkable\nprogress recently, NMT systems only rely on parallel corpora for parameter\nestimation. Since parallel corpora are usually limited in quantity, quality,\nand coverage, especially for low-resource languages, it is appealing to exploit\nmonolingual corpora to improve NMT. We propose a semi-supervised approach for\ntraining NMT models on the concatenation of labeled (parallel corpora) and\nunlabeled (monolingual corpora) data. The central idea is to reconstruct the\nmonolingual corpora using an autoencoder, in which the source-to-target and\ntarget-to-source translation models serve as the encoder and decoder,\nrespectively. Our approach can not only exploit the monolingual corpora of the\ntarget language, but also of the source language. Experiments on the\nChinese-English dataset show that our approach achieves significant\nimprovements over state-of-the-art SMT and NMT systems.", "published": "2016-06-15 00:22:27", "link": "http://arxiv.org/abs/1606.04596v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Agreement-based Learning of Parallel Lexicons and Phrases from\n  Non-Parallel Corpora", "abstract": "We introduce an agreement-based approach to learning parallel lexicons and\nphrases from non-parallel corpora. The basic idea is to encourage two\nasymmetric latent-variable translation models (i.e., source-to-target and\ntarget-to-source) to agree on identifying latent phrase and word alignments.\nThe agreement is defined at both word and phrase levels. We develop a Viterbi\nEM algorithm for jointly training the two unidirectional models efficiently.\nExperiments on the Chinese-English dataset show that agreement-based learning\nsignificantly improves both alignment and translation performance.", "published": "2016-06-15 00:28:51", "link": "http://arxiv.org/abs/1606.04597v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Siamese CBOW: Optimizing Word Embeddings for Sentence Representations", "abstract": "We present the Siamese Continuous Bag of Words (Siamese CBOW) model, a neural\nnetwork for efficient estimation of high-quality sentence embeddings. Averaging\nthe embeddings of words in a sentence has proven to be a surprisingly\nsuccessful and efficient way of obtaining sentence embeddings. However, word\nembeddings trained with the methods currently available are not optimized for\nthe task of sentence representation, and, thus, likely to be suboptimal.\nSiamese CBOW handles this problem by training word embeddings directly for the\npurpose of being averaged. The underlying neural network learns word embeddings\nby predicting, from a sentence representation, its surrounding sentences. We\nshow the robustness of the Siamese CBOW model by evaluating it on 20 datasets\nstemming from a wide variety of sources.", "published": "2016-06-15 04:47:43", "link": "http://arxiv.org/abs/1606.04640v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Correlational Encoder Decoder Architecture for Pivot Based Sequence\n  Generation", "abstract": "Interlingua based Machine Translation (MT) aims to encode multiple languages\ninto a common linguistic representation and then decode sentences in multiple\ntarget languages from this representation. In this work we explore this idea in\nthe context of neural encoder decoder architectures, albeit on a smaller scale\nand without MT as the end goal. Specifically, we consider the case of three\nlanguages or modalities X, Z and Y wherein we are interested in generating\nsequences in Y starting from information available in X. However, there is no\nparallel training data available between X and Y but, training data is\navailable between X & Z and Z & Y (as is often the case in many real world\napplications). Z thus acts as a pivot/bridge. An obvious solution, which is\nperhaps less elegant but works very well in practice is to train a two stage\nmodel which first converts from X to Z and then from Z to Y. Instead we explore\nan interlingua inspired solution which jointly learns to do the following (i)\nencode X and Z to a common representation and (ii) decode Y from this common\nrepresentation. We evaluate our model on two tasks: (i) bridge transliteration\nand (ii) bridge captioning. We report promising results in both these\napplications and believe that this is a right step towards truly interlingua\ninspired encoder decoder architectures.", "published": "2016-06-15 13:27:16", "link": "http://arxiv.org/abs/1606.04754v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Word Sense Embeddings from Word Sense Definitions", "abstract": "Word embeddings play a significant role in many modern NLP systems. Since\nlearning one representation per word is problematic for polysemous words and\nhomonymous words, researchers propose to use one embedding per word sense.\nTheir approaches mainly train word sense embeddings on a corpus. In this paper,\nwe propose to use word sense definitions to learn one embedding per word sense.\nExperimental results on word similarity tasks and a word sense disambiguation\ntask show that word sense embeddings produced by our approach are of high\nquality.", "published": "2016-06-15 16:14:09", "link": "http://arxiv.org/abs/1606.04835v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Smart Reply: Automated Response Suggestion for Email", "abstract": "In this paper we propose and investigate a novel end-to-end method for\nautomatically generating short email responses, called Smart Reply. It\ngenerates semantically diverse suggestions that can be used as complete email\nresponses with just one tap on mobile. The system is currently used in Inbox by\nGmail and is responsible for assisting with 10% of all mobile responses. It is\ndesigned to work at very high throughput and process hundreds of millions of\nmessages daily. The system exploits state-of-the-art, large-scale deep\nlearning.\n  We describe the architecture of the system as well as the challenges that we\nfaced while building it, like response diversity and scalability. We also\nintroduce a new method for semantic clustering of user-generated content that\nrequires only a modest amount of explicitly labeled data.", "published": "2016-06-15 17:23:12", "link": "http://arxiv.org/abs/1606.04870v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Edit Distance Transducer in Action: The University of Cambridge\n  English-German System at WMT16", "abstract": "This paper presents the University of Cambridge submission to WMT16.\nMotivated by the complementary nature of syntactical machine translation and\nneural machine translation (NMT), we exploit the synergies of Hiero and NMT in\ndifferent combination schemes. Starting out with a simple neural lattice\nrescoring approach, we show that the Hiero lattices are often too narrow for\nNMT ensembles. Therefore, instead of a hard restriction of the NMT search space\nto the lattice, we propose to loosely couple NMT and Hiero by composition with\na modified version of the edit distance transducer. The loose combination\noutperforms lattice rescoring, especially when using multiple NMT systems in an\nensemble.", "published": "2016-06-15 20:08:01", "link": "http://arxiv.org/abs/1606.04963v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bidirectional Long-Short Term Memory for Video Description", "abstract": "Video captioning has been attracting broad research attention in multimedia\ncommunity. However, most existing approaches either ignore temporal information\namong video frames or just employ local contextual temporal knowledge. In this\nwork, we propose a novel video captioning framework, termed as\n\\emph{Bidirectional Long-Short Term Memory} (BiLSTM), which deeply captures\nbidirectional global temporal structure in video. Specifically, we first devise\na joint visual modelling approach to encode video data by combining a forward\nLSTM pass, a backward LSTM pass, together with visual features from\nConvolutional Neural Networks (CNNs). Then, we inject the derived video\nrepresentation into the subsequent language model for initialization. The\nbenefits are in two folds: 1) comprehensively preserving sequential and visual\ninformation; and 2) adaptively learning dense visual features and sparse\nsemantic representations for videos and sentences, respectively. We verify the\neffectiveness of our proposed video captioning framework on a commonly-used\nbenchmark, i.e., Microsoft Video Description (MSVD) corpus, and the\nexperimental results demonstrate that the superiority of the proposed approach\nas compared to several state-of-the-art methods.", "published": "2016-06-15 03:26:53", "link": "http://arxiv.org/abs/1606.04631v1", "categories": ["cs.MM", "cs.CL"], "primary_category": "cs.MM"}
{"title": "Constitutional Precedent of Amicus Briefs", "abstract": "We investigate shared language between U.S. Supreme Court majority opinions\nand interest groups' corresponding amicus briefs. Specifically, we evaluate\nwhether language that originated in an amicus brief acquired legal precedent\nstatus by being cited in the Court's opinion. Using plagiarism detection\nsoftware, automated querying of a large legal database, and manual analysis, we\nestablish seven instances where interest group amici were able to formulate\nconstitutional case law, setting binding legal precedent. We discuss several\nsuch instances for their implications in the Supreme Court's creation of case\nlaw.", "published": "2016-06-15 08:21:29", "link": "http://arxiv.org/abs/1606.04672v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Natural Language Generation as Planning under Uncertainty Using\n  Reinforcement Learning", "abstract": "We present and evaluate a new model for Natural Language Generation (NLG) in\nSpoken Dialogue Systems, based on statistical planning, given noisy feedback\nfrom the current generation context (e.g. a user and a surface realiser). We\nstudy its use in a standard NLG problem: how to present information (in this\ncase a set of search results) to users, given the complex trade- offs between\nutterance length, amount of information conveyed, and cognitive load. We set\nthese trade-offs by analysing existing MATCH data. We then train a NLG pol- icy\nusing Reinforcement Learning (RL), which adapts its behaviour to noisy feed-\nback from the current generation context. This policy is compared to several\nbase- lines derived from previous work in this area. The learned policy\nsignificantly out- performs all the prior approaches.", "published": "2016-06-15 09:05:56", "link": "http://arxiv.org/abs/1606.04686v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Personality Traits and Echo Chambers on Facebook", "abstract": "In online social networks, users tend to select information that adhere to\ntheir system of beliefs and to form polarized groups of like minded people.\nPolarization as well as its effects on online social interactions have been\nextensively investigated. Still, the relation between group formation and\npersonality traits remains unclear. A better understanding of the cognitive and\npsychological determinants of online social dynamics might help to design more\nefficient communication strategies and to challenge the digital misinformation\nthreat. In this work, we focus on users commenting posts published by US\nFacebook pages supporting scientific and conspiracy-like narratives, and we\nclassify the personality traits of those users according to their online\nbehavior. We show that different and conflicting communities are populated by\nusers showing similar psychological profiles, and that the dominant personality\nmodel is the same in both scientific and conspiracy echo chambers. Moreover, we\nobserve that the permanence within echo chambers slightly shapes users'\npsychological profiles. Our results suggest that the presence of specific\npersonality traits in individuals lead to their considerable involvement in\nsupporting narratives inside virtual echo chambers.", "published": "2016-06-15 11:08:24", "link": "http://arxiv.org/abs/1606.04721v1", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.HC"], "primary_category": "cs.SI"}
{"title": "Automatic Pronunciation Generation by Utilizing a Semi-supervised Deep\n  Neural Networks", "abstract": "Phonemic or phonetic sub-word units are the most commonly used atomic\nelements to represent speech signals in modern ASRs. However they are not the\noptimal choice due to several reasons such as: large amount of effort required\nto handcraft a pronunciation dictionary, pronunciation variations, human\nmistakes and under-resourced dialects and languages. Here, we propose a\ndata-driven pronunciation estimation and acoustic modeling method which only\ntakes the orthographic transcription to jointly estimate a set of sub-word\nunits and a reliable dictionary. Experimental results show that the proposed\nmethod which is based on semi-supervised training of a deep neural network\nlargely outperforms phoneme based continuous speech recognition on the TIMIT\ndataset.", "published": "2016-06-15 23:45:33", "link": "http://arxiv.org/abs/1606.05007v1", "categories": ["cs.CL", "cs.LG", "cs.SD"], "primary_category": "cs.CL"}
