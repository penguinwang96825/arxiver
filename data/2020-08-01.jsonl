{"title": "The test set for the TransCoder system", "abstract": "The TransCoder system translates source code between Java, C++, and Python 3.\nThe test set that was used to evaluate its quality is missing important\nfeatures of Java, including the ability to define and use classes and the\nability to call user-defined functions other than recursively. Therefore, the\naccuracy of TransCoder over programs with those features remains unknown.", "published": "2020-08-01 16:28:47", "link": "http://arxiv.org/abs/2008.00293v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting actionable information from microtexts", "abstract": "Microblogs such as Twitter represent a powerful source of information. Part\nof this information can be aggregated beyond the level of individual posts.\nSome of this aggregated information is referring to events that could or should\nbe acted upon in the interest of e-governance, public safety, or other levels\nof public interest. Moreover, a significant amount of this information, if\naggregated, could complement existing information networks in a non-trivial\nway. This dissertation proposes a semi-automatic method for extracting\nactionable information that serves this purpose. First, we show that predicting\ntime to event is possible for both in-domain and cross-domain scenarios.\nSecond, we suggest a method which facilitates the definition of relevance for\nan analyst's context and the use of this definition to analyze new data.\nFinally, we propose a method to integrate the machine learning based relevant\ninformation classification method with a rule-based information classification\ntechnique to classify microtexts. Fully automatizing microtext analysis has\nbeen our goal since the first day of this research project. Our efforts in this\ndirection informed us about the extent this automation can be realized. We\nmostly first developed an automated approach, then we extended and improved it\nby integrating human intervention at various steps of the automated approach.\nOur experience confirms previous work that states that a well-designed human\nintervention or contribution in design, realization, or evaluation of an\ninformation system either improves its performance or enables its realization.\nAs our studies and results directed us toward its necessity and value, we were\ninspired from previous studies in designing human involvement and customized\nour approaches to benefit from human input.", "published": "2020-08-01 21:22:53", "link": "http://arxiv.org/abs/2008.00343v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overview of CLEF 2019 Lab ProtestNews: Extracting Protests from News in\n  a Cross-context Setting", "abstract": "We present an overview of the CLEF-2019 Lab ProtestNews on Extracting\nProtests from News in the context of generalizable natural language processing.\nThe lab consists of document, sentence, and token level information\nclassification and extraction tasks that were referred as task 1, task 2, and\ntask 3 respectively in the scope of this lab. The tasks required the\nparticipants to identify protest relevant information from English local news\nat one or more aforementioned levels in a cross-context setting, which is\ncross-country in the scope of this lab. The training and development data were\ncollected from India and test data was collected from India and China. The lab\nattracted 58 teams to participate in the lab. 12 and 9 of these teams submitted\nresults and working notes respectively. We have observed neural networks yield\nthe best results and the performance drops significantly for majority of the\nsubmissions in the cross-country setting, which is China.", "published": "2020-08-01 21:39:54", "link": "http://arxiv.org/abs/2008.00345v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-context News Corpus for Protest Events related Knowledge Base\n  Construction", "abstract": "We describe a gold standard corpus of protest events that comprise of various\nlocal and international sources from various countries in English. The corpus\ncontains document, sentence, and token level annotations. This corpus\nfacilitates creating machine learning models that automatically classify news\narticles and extract protest event-related information, constructing knowledge\nbases which enable comparative social and political science studies. For each\nnews source, the annotation starts on random samples of news articles and\ncontinues with samples that are drawn using active learning. Each batch of\nsamples was annotated by two social and political scientists, adjudicated by an\nannotation supervisor, and was improved by identifying annotation errors\nsemi-automatically. We found that the corpus has the variety and quality to\ndevelop and benchmark text classification and event extraction systems in a\ncross-context setting, which contributes to the generalizability and robustness\nof automated text processing systems. This corpus and the reported results will\nset the currently lacking common ground in automated protest event collection\nstudies.", "published": "2020-08-01 22:20:48", "link": "http://arxiv.org/abs/2008.00351v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tense, aspect and mood based event extraction for situation analysis and\n  crisis management", "abstract": "Nowadays event extraction systems mainly deal with a relatively small amount\nof information about temporal and modal qualifications of situations, primarily\nprocessing assertive sentences in the past tense. However, systems with a wider\ncoverage of tense, aspect and mood can provide better analyses and can be used\nin a wider range of text analysis applications. This thesis develops such a\nsystem for Turkish language. This is accomplished by extending Open Source\nInformation Mining and Analysis (OPTIMA) research group's event extraction\nsoftware, by implementing appropriate extensions in the semantic representation\nformat, by adding a partial grammar which improves the TAM (Tense, Aspect and\nMood) marker, adverb analysis and matching functions of ExPRESS, and by\nconstructing an appropriate lexicon in the standard of CORLEONE. These\nextensions are based on iv the theory of anchoring relations (Tem\\\"urc\\\"u,\n2007, 2011) which is a crosslinguistically applicable semantic framework for\nanalyzing tense, aspect and mood related categories. The result is a system\nwhich can, in addition to extracting basic event structures, classify sentences\ngiven in news reports according to their temporal, modal and\nvolitional/illocutionary values. Although the focus is on news reports of\nnatural disasters, disease outbreaks and man-made disasters in Turkish\nlanguage, the approach can be adapted to other languages, domains and genres.\nThis event extraction and classification system, with further developments, can\nprovide a basis for automated browsing systems for preventing environmental and\nhumanitarian risk.", "published": "2020-08-01 19:22:51", "link": "http://arxiv.org/abs/2008.01555v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Experiments in Extractive Summarization: Integer Linear Programming,\n  Term/Sentence Scoring, and Title-driven Models", "abstract": "In this paper, we revisit the challenging problem of unsupervised\nsingle-document summarization and study the following aspects: Integer linear\nprogramming (ILP) based algorithms, Parameterized normalization of term and\nsentence scores, and Title-driven approaches for summarization. We describe a\nnew framework, NewsSumm, that includes many existing and new approaches for\nsummarization including ILP and title-driven approaches. NewsSumm's flexibility\nallows to combine different algorithms and sentence scoring schemes seamlessly.\nOur results combining sentence scoring with ILP and normalization are in\ncontrast to previous work on this topic, showing the importance of a broader\nsearch for optimal parameters. We also show that the new title-driven reduction\nidea leads to improvement in performance for both unsupervised and supervised\napproaches considered.", "published": "2020-08-01 01:05:55", "link": "http://arxiv.org/abs/2008.00140v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "An Empirical Study of Clarifying Question-Based Systems", "abstract": "Search and recommender systems that take the initiative to ask clarifying\nquestions to better understand users' information needs are receiving\nincreasing attention from the research community. However, to the best of our\nknowledge, there is no empirical study to quantify whether and to what extent\nusers are willing or able to answer these questions. In this work, we conduct\nan online experiment by deploying an experimental system, which interacts with\nusers by asking clarifying questions against a product repository. We collect\nboth implicit interaction behavior data and explicit feedback from users\nshowing that: (a) users are willing to answer a good number of clarifying\nquestions (11-21 on average), but not many more than that; (b) most users\nanswer questions until they reach the target product, but also a fraction of\nthem stops due to fatigue or due to receiving irrelevant questions; (c) part of\nthe users' answers (12-17%) are actually opposite to the description of the\ntarget product; while (d) most of the users (66-84%) find the question-based\nsystem helpful towards completing their tasks. Some of the findings of the\nstudy contradict current assumptions on simulated evaluations in the field,\nwhile they point towards improvements in the evaluation framework and can\ninspire future interactive search/recommender system designs.", "published": "2020-08-01 15:10:11", "link": "http://arxiv.org/abs/2008.00279v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "SemEval-2020 Task 7: Assessing Humor in Edited News Headlines", "abstract": "This paper describes the SemEval-2020 shared task \"Assessing Humor in Edited\nNews Headlines.\" The task's dataset contains news headlines in which short\nedits were applied to make them funny, and the funniness of these edited\nheadlines was rated using crowdsourcing. This task includes two subtasks, the\nfirst of which is to estimate the funniness of headlines on a humor scale in\nthe interval 0-3. The second subtask is to predict, for a pair of edited\nversions of the same original headline, which is the funnier version. To date,\nthis task is the most popular shared computational humor task, attracting 48\nteams for the first subtask and 31 teams for the second.", "published": "2020-08-01 17:34:37", "link": "http://arxiv.org/abs/2008.00304v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LXPER Index: a curriculum-specific text readability assessment model for\n  EFL students in Korea", "abstract": "Automatic readability assessment is one of the most important applications of\nNatural Language Processing (NLP) in education. Since automatic readability\nassessment allows the fast selection of appropriate reading material for\nreaders at all levels of proficiency, it can be particularly useful for the\nEnglish education of English as Foreign Language (EFL) students around the\nworld. Most readability assessment models are developed for the native readers\nof English and have low accuracy for texts in the non-native English Language\nTraining (ELT) curriculum. We introduce LXPER Index, which is a readability\nassessment model for non-native EFL readers in the ELT curriculum of Korea. Our\nexperiments show that our new model, trained with CoKEC-text (Text Corpus of\nthe Korean ELT Curriculum), significantly improves the accuracy of automatic\nreadability assessment for texts in the Korean ELT curriculum.", "published": "2020-08-01 11:55:03", "link": "http://arxiv.org/abs/2008.01564v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-node Bert-pretraining: Cost-efficient Approach", "abstract": "Recently, large scale Transformer-based language models such as BERT, GPT-2,\nand XLNet have brought about exciting leaps in state-of-the-art results for\nmany Natural Language Processing (NLP) tasks. One of the common trends in these\nrecent models is a significant increase in model complexity, which introduces\nboth more weights and computation. Moreover, with the advent of large-scale\nunsupervised datasets, training time is further extended due to the increased\namount of data samples within a single training epoch. As a result, to train\nthese models within a reasonable time, machine learning (ML) programmers often\nrequire advanced hardware setups such as the premium GPU-enabled NVIDIA DGX\nworkstations or specialized accelerators such as Google's TPU Pods. Our work\naddresses this limitation and demonstrates that the BERT pre-trained model can\nbe trained within 2 weeks on an academic-size cluster of widely available GPUs\nthrough careful algorithmic and software optimizations. In this paper, we\npresent these optimizations on how to improve single device training\nthroughput, distribute the training workload over multiple nodes and GPUs, and\novercome the communication bottleneck introduced by the large data exchanges\nover the network. We show that we are able to perform pre-training on BERT\nwithin a reasonable time budget (12 days) in an academic setting, but with a\nmuch less expensive and less aggressive hardware resource requirement than in\npreviously demonstrated industrial settings based on NVIDIA DGX machines or\nGoogle's TPU Pods.", "published": "2020-08-01 05:49:20", "link": "http://arxiv.org/abs/2008.00177v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Trojaning Language Models for Fun and Profit", "abstract": "Recent years have witnessed the emergence of a new paradigm of building\nnatural language processing (NLP) systems: general-purpose, pre-trained\nlanguage models (LMs) are composed with simple downstream models and fine-tuned\nfor a variety of NLP tasks. This paradigm shift significantly simplifies the\nsystem development cycles. However, as many LMs are provided by untrusted third\nparties, their lack of standardization or regulation entails profound security\nimplications, which are largely unexplored.\n  To bridge this gap, this work studies the security threats posed by malicious\nLMs to NLP systems. Specifically, we present TROJAN-LM, a new class of\ntrojaning attacks in which maliciously crafted LMs trigger host NLP systems to\nmalfunction in a highly predictable manner. By empirically studying three\nstate-of-the-art LMs (BERT, GPT-2, XLNet) in a range of security-critical NLP\ntasks (toxic comment detection, question answering, text completion) as well as\nuser studies on crowdsourcing platforms, we demonstrate that TROJAN-LM\npossesses the following properties: (i) flexibility - the adversary is able to\nflexibly dene logical combinations (e.g., 'and', 'or', 'xor') of arbitrary\nwords as triggers, (ii) efficacy - the host systems misbehave as desired by the\nadversary with high probability when trigger-embedded inputs are present, (iii)\nspecificity - the trojan LMs function indistinguishably from their benign\ncounterparts on clean inputs, and (iv) fluency - the trigger-embedded inputs\nappear as fluent natural language and highly relevant to their surrounding\ncontexts. We provide analytical justification for the practicality of\nTROJAN-LM, and further discuss potential countermeasures and their challenges,\nwhich lead to several promising research directions.", "published": "2020-08-01 18:22:38", "link": "http://arxiv.org/abs/2008.00312v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Neural text-to-speech with a modeling-by-generation excitation vocoder", "abstract": "This paper proposes a modeling-by-generation (MbG) excitation vocoder for a\nneural text-to-speech (TTS) system. Recently proposed neural excitation\nvocoders can realize qualified waveform generation by combining a vocal tract\nfilter with a WaveNet-based glottal excitation generator. However, when these\nvocoders are used in a TTS system, the quality of synthesized speech is often\ndegraded owing to a mismatch between training and synthesis steps.\nSpecifically, the vocoder is separately trained from an acoustic model\nfront-end. Therefore, estimation errors of the acoustic model are inevitably\nboosted throughout the synthesis process of the vocoder back-end. To address\nthis problem, we propose to incorporate an MbG structure into the vocoder's\ntraining process. In the proposed method, the excitation signal is extracted by\nthe acoustic model's generated spectral parameters, and the neural vocoder is\nthen optimized not only to learn the target excitation's distribution but also\nto compensate for the estimation errors occurring from the acoustic model.\nFurthermore, as the generated spectral parameters are shared in the training\nand synthesis steps, their mismatch conditions can be reduced effectively. The\nexperimental results verify that the proposed system provides high-quality\nsynthetic speech by achieving a mean opinion score of 4.57 within the TTS\nframework.", "published": "2020-08-01 00:30:47", "link": "http://arxiv.org/abs/2008.00132v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Efficient Independent Vector Extraction of Dominant Target Speech", "abstract": "The complete decomposition performed by blind source separation is\ncomputationally demanding and superfluous when only the speech of one specific\ntarget speaker is desired. In this paper, we propose a computationally\nefficient blind speech extraction method based on a proper modification of the\ncommonly utilized independent vector analysis algorithm, under the mild\nassumption that the average power of signal of interest outweighs interfering\nspeech sources. Considering that the minimum distortion principle cannot be\nimplemented since the full demixing matrix is not available, we also design a\none-unit scaling operation to solve the scaling ambiguity. Simulations validate\nthe efficacy of the proposed method in extracting the dominant speech.", "published": "2020-08-01 01:23:36", "link": "http://arxiv.org/abs/2008.00143v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Singer Identification Using Convolutional Acoustic Motif Embeddings", "abstract": "Flamenco singing is characterized by pitch instability, micro-tonal\nornamentations, large vibrato ranges, and a high degree of melodic variability.\nThese musical features make the automatic identification of flamenco singers a\ndifficult computational task. In this article we present an end-to-end pipeline\nfor flamenco singer identification based on acoustic motif embeddings. In the\napproach taken, the fundamental frequency obtained directly from the raw audio\nsignal is approximated. This approximation reduces the high variability of the\naudio signal and allows for small melodic patterns to be discovered using a\nsequential pattern mining technique, thus creating a dictionary of motifs.\nSeveral acoustic features are then used to extract fixed length embeddings of\nvariable length motifs by using convolutional architectures. We test the\nquality of the embeddings in a flamenco singer identification task, comparing\nour approach with previous deep learning architectures, and study the effect of\nmotivic patterns and acoustic features in the identification task. Results\nindicate that motivic patterns play a crucial role in identifying flamenco\nsingers by minimizing the size of the signal to be learned, discarding\ninformation that is not relevant in the identification task. The deep learning\narchitecture presented outperforms denser models used in large-scale audio\nclassification problems.", "published": "2020-08-01 07:27:18", "link": "http://arxiv.org/abs/2008.00198v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DCCRN: Deep Complex Convolution Recurrent Network for Phase-Aware Speech\n  Enhancement", "abstract": "Speech enhancement has benefited from the success of deep learning in terms\nof intelligibility and perceptual quality. Conventional time-frequency (TF)\ndomain methods focus on predicting TF-masks or speech spectrum, via a naive\nconvolution neural network (CNN) or recurrent neural network (RNN). Some recent\nstudies use complex-valued spectrogram as a training target but train in a\nreal-valued network, predicting the magnitude and phase component or real and\nimaginary part, respectively. Particularly, convolution recurrent network (CRN)\nintegrates a convolutional encoder-decoder (CED) structure and long short-term\nmemory (LSTM), which has been proven to be helpful for complex targets. In\norder to train the complex target more effectively, in this paper, we design a\nnew network structure simulating the complex-valued operation, called Deep\nComplex Convolution Recurrent Network (DCCRN), where both CNN and RNN\nstructures can handle complex-valued operation. The proposed DCCRN models are\nvery competitive over other previous networks, either on objective or\nsubjective metric. With only 3.7M parameters, our DCCRN models submitted to the\nInterspeech 2020 Deep Noise Suppression (DNS) challenge ranked first for the\nreal-time-track and second for the non-real-time track in terms of Mean Opinion\nScore (MOS).", "published": "2020-08-01 13:42:29", "link": "http://arxiv.org/abs/2008.00264v4", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Score-informed Networks for Music Performance Assessment", "abstract": "The assessment of music performances in most cases takes into account the\nunderlying musical score being performed. While there have been several\nautomatic approaches for objective music performance assessment (MPA) based on\nextracted features from both the performance audio and the score, deep neural\nnetwork-based methods incorporating score information into MPA models have not\nyet been investigated. In this paper, we introduce three different models\ncapable of score-informed performance assessment. These are (i) a convolutional\nneural network that utilizes a simple time-series input comprising of aligned\npitch contours and score, (ii) a joint embedding model which learns a joint\nlatent space for pitch contours and scores, and (iii) a distance matrix-based\nconvolutional neural network which utilizes patterns in the distance matrix\nbetween pitch contours and musical score to predict assessment ratings. Our\nresults provide insights into the suitability of different architectures and\ninput representations and demonstrate the benefits of score-informed models as\ncompared to score-independent models.", "published": "2020-08-01 07:46:24", "link": "http://arxiv.org/abs/2008.00203v1", "categories": ["eess.AS", "cs.IR", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Neural ODE with Temporal Convolution and Time Delay Neural Networks for\n  Small-Footprint Keyword Spotting", "abstract": "In this paper, we propose neural network models based on the neural ordinary\ndifferential equation (NODE) for small-footprint keyword spotting (KWS). We\npresent techniques to apply NODE to KWS that make it possible to adopt Batch\nNormalization to NODE-based network and to reduce the number of computations\nduring inference. Finally, we show that the number of model parameters of the\nproposed model is smaller by 68% than that of the conventional KWS model.", "published": "2020-08-01 08:01:20", "link": "http://arxiv.org/abs/2008.00209v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
