{"title": "Competence-based Curriculum Learning for Multilingual Machine\n  Translation", "abstract": "Currently, multilingual machine translation is receiving more and more\nattention since it brings better performance for low resource languages (LRLs)\nand saves more space. However, existing multilingual machine translation models\nface a severe challenge: imbalance. As a result, the translation performance of\ndifferent languages in multilingual translation models are quite different. We\nargue that this imbalance problem stems from the different learning\ncompetencies of different languages. Therefore, we focus on balancing the\nlearning competencies of different languages and propose Competence-based\nCurriculum Learning for Multilingual Machine Translation, named CCL-M.\nSpecifically, we firstly define two competencies to help schedule the high\nresource languages (HRLs) and the low resource languages: 1) Self-evaluated\nCompetence, evaluating how well the language itself has been learned; and 2)\nHRLs-evaluated Competence, evaluating whether an LRL is ready to be learned\naccording to HRLs' Self-evaluated Competence. Based on the above competencies,\nwe utilize the proposed CCL-M algorithm to gradually add new languages into the\ntraining set in a curriculum learning manner. Furthermore, we propose a novel\ncompetenceaware dynamic balancing sampling strategy for better selecting\ntraining samples in multilingual training. Experimental results show that our\napproach has achieved a steady and significant performance gain compared to the\nprevious state-of-the-art approach on the TED talks dataset.", "published": "2021-09-09 02:52:34", "link": "http://arxiv.org/abs/2109.04002v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph Based Network with Contextualized Representations of Turns in\n  Dialogue", "abstract": "Dialogue-based relation extraction (RE) aims to extract relation(s) between\ntwo arguments that appear in a dialogue. Because dialogues have the\ncharacteristics of high personal pronoun occurrences and low information\ndensity, and since most relational facts in dialogues are not supported by any\nsingle sentence, dialogue-based relation extraction requires a comprehensive\nunderstanding of dialogue. In this paper, we propose the TUrn COntext awaRE\nGraph Convolutional Network (TUCORE-GCN) modeled by paying attention to the way\npeople understand dialogues. In addition, we propose a novel approach which\ntreats the task of emotion recognition in conversations (ERC) as a\ndialogue-based RE. Experiments on a dialogue-based RE dataset and three ERC\ndatasets demonstrate that our model is very effective in various dialogue-based\nnatural language understanding tasks. In these experiments, TUCORE-GCN\noutperforms the state-of-the-art models on most of the benchmark datasets. Our\ncode is available at https://github.com/BlackNoodle/TUCORE-GCN.", "published": "2021-09-09 03:09:08", "link": "http://arxiv.org/abs/2109.04008v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Weakly-Supervised Visual-Retriever-Reader for Knowledge-based Question\n  Answering", "abstract": "Knowledge-based visual question answering (VQA) requires answering questions\nwith external knowledge in addition to the content of images. One dataset that\nis mostly used in evaluating knowledge-based VQA is OK-VQA, but it lacks a gold\nstandard knowledge corpus for retrieval. Existing work leverage different\nknowledge bases (e.g., ConceptNet and Wikipedia) to obtain external knowledge.\nBecause of varying knowledge bases, it is hard to fairly compare models'\nperformance. To address this issue, we collect a natural language knowledge\nbase that can be used for any VQA system. Moreover, we propose a Visual\nRetriever-Reader pipeline to approach knowledge-based VQA. The visual retriever\naims to retrieve relevant knowledge, and the visual reader seeks to predict\nanswers based on given knowledge. We introduce various ways to retrieve\nknowledge using text and images and two reader styles: classification and\nextraction. Both the retriever and reader are trained with weak supervision.\nOur experimental results show that a good retriever can significantly improve\nthe reader's performance on the OK-VQA challenge. The code and corpus are\nprovided in https://github.com/luomancs/retriever\\_reader\\_for\\_okvqa.git", "published": "2021-09-09 03:21:32", "link": "http://arxiv.org/abs/2109.04014v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graphine: A Dataset for Graph-aware Terminology Definition Generation", "abstract": "Precisely defining the terminology is the first step in scientific\ncommunication. Developing neural text generation models for definition\ngeneration can circumvent the labor-intensity curation, further accelerating\nscientific discovery. Unfortunately, the lack of large-scale terminology\ndefinition dataset hinders the process toward definition generation. In this\npaper, we present a large-scale terminology definition dataset Graphine\ncovering 2,010,648 terminology definition pairs, spanning 227 biomedical\nsubdisciplines. Terminologies in each subdiscipline further form a directed\nacyclic graph, opening up new avenues for developing graph-aware text\ngeneration models. We then proposed a novel graph-aware definition generation\nmodel Graphex that integrates transformer with graph neural network. Our model\noutperforms existing text generation models by exploiting the graph structure\nof terminologies. We further demonstrated how Graphine can be used to evaluate\npretrained language models, compare graph representation learning methods and\npredict sentence granularity. We envision Graphine to be a unique resource for\ndefinition generation and many other NLP tasks in biomedicine.", "published": "2021-09-09 03:29:23", "link": "http://arxiv.org/abs/2109.04018v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhanced Speaker-aware Multi-party Multi-turn Dialogue Comprehension", "abstract": "Multi-party multi-turn dialogue comprehension brings unprecedented challenges\non handling the complicated scenarios from multiple speakers and criss-crossed\ndiscourse relationship among speaker-aware utterances. Most existing methods\ndeal with dialogue contexts as plain texts and pay insufficient attention to\nthe crucial speaker-aware clues. In this work, we propose an enhanced\nspeaker-aware model with masking attention and heterogeneous graph networks to\ncomprehensively capture discourse clues from both sides of speaker property and\nspeaker-aware relationships. With such comprehensive speaker-aware modeling,\nexperimental results show that our speaker-aware model helps achieves\nstate-of-the-art performance on the benchmark dataset Molweni. Case analysis\nshows that our model enhances the connections between utterances and their own\nspeakers and captures the speaker-aware discourse relations, which are critical\nfor dialogue modeling.", "published": "2021-09-09 07:12:22", "link": "http://arxiv.org/abs/2109.04066v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Low-Resource Dialogue Summarization with Domain-Agnostic Multi-Source\n  Pretraining", "abstract": "With the rapid increase in the volume of dialogue data from daily life, there\nis a growing demand for dialogue summarization. Unfortunately, training a large\nsummarization model is generally infeasible due to the inadequacy of dialogue\ndata with annotated summaries. Most existing works for low-resource dialogue\nsummarization directly pretrain models in other domains, e.g., the news domain,\nbut they generally neglect the huge difference between dialogues and\nconventional articles. To bridge the gap between out-of-domain pretraining and\nin-domain fine-tuning, in this work, we propose a multi-source pretraining\nparadigm to better leverage the external summary data. Specifically, we exploit\nlarge-scale in-domain non-summary data to separately pretrain the dialogue\nencoder and the summary decoder. The combined encoder-decoder model is then\npretrained on the out-of-domain summary data using adversarial critics, aiming\nto facilitate domain-agnostic summarization. The experimental results on two\npublic datasets show that with only limited training data, our approach\nachieves competitive performance and generalizes well in different dialogue\nscenarios.", "published": "2021-09-09 07:47:16", "link": "http://arxiv.org/abs/2109.04080v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Thinking Clearly, Talking Fast: Concept-Guided Non-Autoregressive\n  Generation for Open-Domain Dialogue Systems", "abstract": "Human dialogue contains evolving concepts, and speakers naturally associate\nmultiple concepts to compose a response. However, current dialogue models with\nthe seq2seq framework lack the ability to effectively manage concept\ntransitions and can hardly introduce multiple concepts to responses in a\nsequential decoding manner. To facilitate a controllable and coherent dialogue,\nin this work, we devise a concept-guided non-autoregressive model (CG-nAR) for\nopen-domain dialogue generation. The proposed model comprises a multi-concept\nplanning module that learns to identify multiple associated concepts from a\nconcept graph and a customized Insertion Transformer that performs\nconcept-guided non-autoregressive generation to complete a response. The\nexperimental results on two public datasets show that CG-nAR can produce\ndiverse and coherent responses, outperforming state-of-the-art baselines in\nboth automatic and human evaluations with substantially faster inference speed.", "published": "2021-09-09 08:00:44", "link": "http://arxiv.org/abs/2109.04084v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Debiasing Methods in Natural Language Understanding Make Bias More\n  Accessible", "abstract": "Model robustness to bias is often determined by the generalization on\ncarefully designed out-of-distribution datasets. Recent debiasing methods in\nnatural language understanding (NLU) improve performance on such datasets by\npressuring models into making unbiased predictions. An underlying assumption\nbehind such methods is that this also leads to the discovery of more robust\nfeatures in the model's inner representations. We propose a general\nprobing-based framework that allows for post-hoc interpretation of biases in\nlanguage models, and use an information-theoretic approach to measure the\nextractability of certain biases from the model's representations. We\nexperiment with several NLU datasets and known biases, and show that,\ncounter-intuitively, the more a language model is pushed towards a debiased\nregime, the more bias is actually encoded in its inner representations.", "published": "2021-09-09 08:28:22", "link": "http://arxiv.org/abs/2109.04095v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "ARMAN: Pre-training with Semantically Selecting and Reordering of\n  Sentences for Persian Abstractive Summarization", "abstract": "Abstractive text summarization is one of the areas influenced by the\nemergence of pre-trained language models. Current pre-training works in\nabstractive summarization give more points to the summaries with more words in\ncommon with the main text and pay less attention to the semantic similarity\nbetween generated sentences and the original document. We propose ARMAN, a\nTransformer-based encoder-decoder model pre-trained with three novel objectives\nto address this issue. In ARMAN, salient sentences from a document are selected\naccording to a modified semantic score to be masked and form a pseudo summary.\nTo summarize more accurately and similar to human writing patterns, we applied\nmodified sentence reordering. We evaluated our proposed models on six\ndownstream Persian summarization tasks. Experimental results show that our\nproposed model achieves state-of-the-art performance on all six summarization\ntasks measured by ROUGE and BERTScore. Our models also outperform prior works\nin textual entailment, question paraphrasing, and multiple choice question\nanswering. Finally, we established a human evaluation and show that using the\nsemantic score significantly improves summarization results.", "published": "2021-09-09 08:35:39", "link": "http://arxiv.org/abs/2109.04098v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word-Level Coreference Resolution", "abstract": "Recent coreference resolution models rely heavily on span representations to\nfind coreference links between word spans. As the number of spans is $O(n^2)$\nin the length of text and the number of potential links is $O(n^4)$, various\npruning techniques are necessary to make this approach computationally\nfeasible. We propose instead to consider coreference links between individual\nwords rather than word spans and then reconstruct the word spans. This reduces\nthe complexity of the coreference model to $O(n^2)$ and allows it to consider\nall potential mentions without pruning any of them out. We also demonstrate\nthat, with these changes, SpanBERT for coreference resolution will be\nsignificantly outperformed by RoBERTa. While being highly efficient, our model\nperforms competitively with recent coreference resolution systems on the\nOntoNotes benchmark.", "published": "2021-09-09 09:26:02", "link": "http://arxiv.org/abs/2109.04127v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Efficient Nearest Neighbor Language Models", "abstract": "Non-parametric neural language models (NLMs) learn predictive distributions\nof text utilizing an external datastore, which allows them to learn through\nexplicitly memorizing the training datapoints. While effective, these models\noften require retrieval from a large datastore at test time, significantly\nincreasing the inference overhead and thus limiting the deployment of\nnon-parametric NLMs in practical applications. In this paper, we take the\nrecently proposed $k$-nearest neighbors language model (Khandelwal et al.,\n2020) as an example, exploring methods to improve its efficiency along various\ndimensions. Experiments on the standard WikiText-103 benchmark and\ndomain-adaptation datasets show that our methods are able to achieve up to a 6x\nspeed-up in inference speed while retaining comparable performance. The\nempirical analysis we present may provide guidelines for future research\nseeking to develop or deploy more efficient non-parametric NLMs.", "published": "2021-09-09 12:32:28", "link": "http://arxiv.org/abs/2109.04212v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalised Unsupervised Domain Adaptation of Neural Machine Translation\n  with Cross-Lingual Data Selection", "abstract": "This paper considers the unsupervised domain adaptation problem for neural\nmachine translation (NMT), where we assume the access to only monolingual text\nin either the source or target language in the new domain. We propose a\ncross-lingual data selection method to extract in-domain sentences in the\nmissing language side from a large generic monolingual corpus. Our proposed\nmethod trains an adaptive layer on top of multilingual BERT by contrastive\nlearning to align the representation between the source and target language.\nThis then enables the transferability of the domain classifier between the\nlanguages in a zero-shot manner. Once the in-domain data is detected by the\nclassifier, the NMT model is then adapted to the new domain by jointly learning\ntranslation and domain discrimination tasks. We evaluate our cross-lingual data\nselection method on NMT across five diverse domains in three language pairs, as\nwell as a real-world scenario of translation for COVID-19. The results show\nthat our proposed method outperforms other selection baselines up to +1.5 BLEU\nscore.", "published": "2021-09-09 14:12:12", "link": "http://arxiv.org/abs/2109.04292v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Variational Latent-State GPT for Semi-Supervised Task-Oriented Dialog\n  Systems", "abstract": "Recently, two approaches, fine-tuning large pre-trained language models and\nvariational training, have attracted significant interests, separately, for\nsemi-supervised end-to-end task-oriented dialog (TOD) systems. In this paper,\nwe propose Variational Latent-State GPT model (VLS-GPT), which is the first to\ncombine the strengths of the two approaches. Among many options of models, we\npropose the generative model and the inference model for variational learning\nof the end-to-end TOD system, both as auto-regressive language models based on\nGPT-2, which can be further trained over a mix of labeled and unlabeled dialog\ndata in a semi-supervised manner. Variational training of VLS-GPT is both\nstatistically and computationally more challenging than previous variational\nlearning works for sequential latent variable models, which use turn-level\nfirst-order Markovian. The inference model in VLS-GPT is non-Markovian due to\nthe use of the Transformer architecture. In this work, we establish Recursive\nMonte Carlo Approximation (RMCA) to the variational objective with\nnon-Markovian inference model and prove its unbiasedness. Further, we develop\nthe computational strategy of sampling-then-forward-computation to realize\nRMCA, which successfully overcomes the memory explosion issue of using GPT in\nvariational learning and speeds up training. Semi-supervised TOD experiments\nare conducted on two benchmark multi-domain datasets of different languages -\nMultiWOZ2.1 and CrossWOZ. VLS-GPT is shown to significantly outperform both\nsupervised-only and semi-supervised self-training baselines.", "published": "2021-09-09 14:42:29", "link": "http://arxiv.org/abs/2109.04314v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PPT: Pre-trained Prompt Tuning for Few-shot Learning", "abstract": "Prompts for pre-trained language models (PLMs) have shown remarkable\nperformance by bridging the gap between pre-training tasks and various\ndownstream tasks. Among these methods, prompt tuning, which freezes PLMs and\nonly tunes soft prompts, provides an efficient and effective solution for\nadapting large-scale PLMs to downstream tasks. However, prompt tuning is yet to\nbe fully explored. In our pilot experiments, we find that prompt tuning\nperforms comparably with conventional full-model fine-tuning when downstream\ndata are sufficient, whereas it performs much worse under few-shot learning\nsettings, which may hinder the application of prompt tuning in practice. We\nattribute this low performance to the manner of initializing soft prompts.\nTherefore, in this work, we propose to pre-train prompts by adding soft prompts\ninto the pre-training stage to obtain a better initialization. We name this\nPre-trained Prompt Tuning framework \"PPT\". To ensure the generalization of PPT,\nwe formulate similar classification tasks into a unified task form and\npre-train soft prompts for this unified task. Extensive experiments show that\ntuning pre-trained prompts for downstream tasks can reach or even outperform\nfull-model fine-tuning under both full-data and few-shot settings. Our approach\nis effective and efficient for using large-scale PLMs in practice.", "published": "2021-09-09 15:11:04", "link": "http://arxiv.org/abs/2109.04332v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncertainty Measures in Neural Belief Tracking and the Effects on\n  Dialogue Policy Performance", "abstract": "The ability to identify and resolve uncertainty is crucial for the robustness\nof a dialogue system. Indeed, this has been confirmed empirically on systems\nthat utilise Bayesian approaches to dialogue belief tracking. However, such\nsystems consider only confidence estimates and have difficulty scaling to more\ncomplex settings. Neural dialogue systems, on the other hand, rarely take\nuncertainties into account. They are therefore overconfident in their decisions\nand less robust. Moreover, the performance of the tracking task is often\nevaluated in isolation, without consideration of its effect on the downstream\npolicy optimisation. We propose the use of different uncertainty measures in\nneural belief tracking. The effects of these measures on the downstream task of\npolicy optimisation are evaluated by adding selected measures of uncertainty to\nthe feature space of the policy and training policies through interaction with\na user simulator. Both human and simulated user results show that incorporating\nthese measures leads to improvements both of the performance and of the\nrobustness of the downstream dialogue policy. This highlights the importance of\ndeveloping neural dialogue belief trackers that take uncertainty into account.", "published": "2021-09-09 15:41:50", "link": "http://arxiv.org/abs/2109.04349v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tracking Turbulence Through Financial News During COVID-19", "abstract": "Grave human toll notwithstanding, the COVID-19 pandemic created uniquely\nunstable conditions in financial markets. In this work we uncover and discuss\nrelationships involving sentiment in financial publications during the 2020\npandemic-motivated U.S. financial crash. First, we introduce a set of expert\nannotations of financial sentiment for articles from major American financial\nnews publishers. After an exploratory data analysis, we then describe a\nCNN-based architecture to address the task of predicting financial sentiment in\nthis anomalous, tumultuous setting. Our best performing model achieves a\nmaximum weighted F1 score of 0.746, establishing a strong performance\nbenchmark. Using predictions from our top performing model, we close by\nconducting a statistical correlation study with real stock market data, finding\ninteresting and strong relationships between financial news and the S\\&P 500\nindex, trading volume, market volatility, and different single-factor ETFs.", "published": "2021-09-09 15:55:32", "link": "http://arxiv.org/abs/2109.04369v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contrasting Human- and Machine-Generated Word-Level Adversarial Examples\n  for Text Classification", "abstract": "Research shows that natural language processing models are generally\nconsidered to be vulnerable to adversarial attacks; but recent work has drawn\nattention to the issue of validating these adversarial inputs against certain\ncriteria (e.g., the preservation of semantics and grammaticality). Enforcing\nconstraints to uphold such criteria may render attacks unsuccessful, raising\nthe question of whether valid attacks are actually feasible. In this work, we\ninvestigate this through the lens of human language ability. We report on\ncrowdsourcing studies in which we task humans with iteratively modifying words\nin an input text, while receiving immediate model feedback, with the aim of\ncausing a sentiment classification model to misclassify the example. Our\nfindings suggest that humans are capable of generating a substantial amount of\nadversarial examples using semantics-preserving word substitutions. We analyze\nhow human-generated adversarial examples compare to the recently proposed\nTextFooler, Genetic, BAE and SememePSO attack algorithms on the dimensions\nnaturalness, preservation of sentiment, grammaticality and substitution rate.\nOur findings suggest that human-generated adversarial examples are not more\nable than the best algorithms to generate natural-reading, sentiment-preserving\nexamples, though they do so by being much more computationally efficient.", "published": "2021-09-09 16:16:04", "link": "http://arxiv.org/abs/2109.04385v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AStitchInLanguageModels: Dataset and Methods for the Exploration of\n  Idiomaticity in Pre-Trained Language Models", "abstract": "Despite their success in a variety of NLP tasks, pre-trained language models,\ndue to their heavy reliance on compositionality, fail in effectively capturing\nthe meanings of multiword expressions (MWEs), especially idioms. Therefore,\ndatasets and methods to improve the representation of MWEs are urgently needed.\nExisting datasets are limited to providing the degree of idiomaticity of\nexpressions along with the literal and, where applicable, (a single)\nnon-literal interpretation of MWEs. This work presents a novel dataset of\nnaturally occurring sentences containing MWEs manually classified into a\nfine-grained set of meanings, spanning both English and Portuguese. We use this\ndataset in two tasks designed to test i) a language model's ability to detect\nidiom usage, and ii) the effectiveness of a language model in generating\nrepresentations of sentences containing idioms. Our experiments demonstrate\nthat, on the task of detecting idiomatic usage, these models perform reasonably\nwell in the one-shot and few-shot scenarios, but that there is significant\nscope for improvement in the zero-shot scenario. On the task of representing\nidiomaticity, we find that pre-training is not always effective, while\nfine-tuning could provide a sample efficient method of learning representations\nof sentences containing MWEs.", "published": "2021-09-09 16:53:17", "link": "http://arxiv.org/abs/2109.04413v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analysis of Language Change in Collaborative Instruction Following", "abstract": "We analyze language change over time in a collaborative, goal-oriented\ninstructional task, where utility-maximizing participants form conventions and\nincrease their expertise. Prior work studied such scenarios mostly in the\ncontext of reference games, and consistently found that language complexity is\nreduced along multiple dimensions, such as utterance length, as conventions are\nformed. In contrast, we find that, given the ability to increase instruction\nutility, instructors increase language complexity along these previously\nstudied dimensions to better collaborate with increasingly skilled instruction\nfollowers.", "published": "2021-09-09 17:51:59", "link": "http://arxiv.org/abs/2109.04452v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Parsing in Task-Oriented Dialog with Recursive Insertion-based\n  Encoder", "abstract": "We introduce a Recursive INsertion-based Encoder (RINE), a novel approach for\nsemantic parsing in task-oriented dialog. Our model consists of an encoder\nnetwork that incrementally builds the semantic parse tree by predicting the\nnon-terminal label and its positions in the linearized tree. At the generation\ntime, the model constructs the semantic parse tree by recursively inserting the\npredicted non-terminal labels at the predicted positions until termination.\nRINE achieves state-of-the-art exact match accuracy on low- and high-resource\nversions of the conversational semantic parsing benchmark TOP (Gupta et al.,\n2018; Chen et al., 2020), outperforming strong sequence-to-sequence models and\ntransition-based parsers. We also show that our model design is applicable to\nnested named entity recognition task, where it performs on par with\nstate-of-the-art approach designed for that task. Finally, we demonstrate that\nour approach is 2-3.5 times faster than the sequence-to-sequence model at\ninference time.", "published": "2021-09-09 18:23:45", "link": "http://arxiv.org/abs/2109.04500v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Filling the Gaps in Ancient Akkadian Texts: A Masked Language Modelling\n  Approach", "abstract": "We present models which complete missing text given transliterations of\nancient Mesopotamian documents, originally written on cuneiform clay tablets\n(2500 BCE - 100 CE). Due to the tablets' deterioration, scholars often rely on\ncontextual cues to manually fill in missing parts in the text in a subjective\nand time-consuming process. We identify that this challenge can be formulated\nas a masked language modelling task, used mostly as a pretraining objective for\ncontextualized language models. Following, we develop several architectures\nfocusing on the Akkadian language, the lingua franca of the time. We find that\ndespite data scarcity (1M tokens) we can achieve state of the art performance\non missing tokens prediction (89% hit@5) using a greedy decoding scheme and\npretraining on data from other languages and different time periods. Finally,\nwe conduct human evaluations showing the applicability of our models in\nassisting experts to transcribe texts in extinct languages.", "published": "2021-09-09 18:58:14", "link": "http://arxiv.org/abs/2109.04513v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generic resources are what you need: Style transfer tasks without\n  task-specific parallel training data", "abstract": "Style transfer aims to rewrite a source text in a different target style\nwhile preserving its content. We propose a novel approach to this task that\nleverages generic resources, and without using any task-specific parallel\n(source-target) data outperforms existing unsupervised approaches on the two\nmost popular style transfer tasks: formality transfer and polarity swap. In\npractice, we adopt a multi-step procedure which builds on a generic pre-trained\nsequence-to-sequence model (BART). First, we strengthen the model's ability to\nrewrite by further pre-training BART on both an existing collection of generic\nparaphrases, as well as on synthetic pairs created using a general-purpose\nlexical resource. Second, through an iterative back-translation approach, we\ntrain two models, each in a transfer direction, so that they can provide each\nother with synthetically generated pairs, dynamically in the training process.\nLastly, we let our best reresulting model generate static synthetic pairs to be\nused in a supervised training regime. Besides methodology and state-of-the-art\nresults, a core contribution of this work is a reflection on the nature of the\ntwo tasks we address, and how their differences are highlighted by their\nresponse to our approach.", "published": "2021-09-09 20:15:02", "link": "http://arxiv.org/abs/2109.04543v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Math Word Problem Generation with Mathematical Consistency and Problem\n  Context Constraints", "abstract": "We study the problem of generating arithmetic math word problems (MWPs) given\na math equation that specifies the mathematical computation and a context that\nspecifies the problem scenario. Existing approaches are prone to generating\nMWPs that are either mathematically invalid or have unsatisfactory language\nquality. They also either ignore the context or require manual specification of\na problem template, which compromises the diversity of the generated MWPs. In\nthis paper, we develop a novel MWP generation approach that leverages i)\npre-trained language models and a context keyword selection model to improve\nthe language quality of the generated MWPs and ii) an equation consistency\nconstraint for math equations to improve the mathematical validity of the\ngenerated MWPs. Extensive quantitative and qualitative experiments on three\nreal-world MWP datasets demonstrate the superior performance of our approach\ncompared to various baselines.", "published": "2021-09-09 20:24:25", "link": "http://arxiv.org/abs/2109.04546v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Subword Mapping and Anchoring across Languages", "abstract": "State-of-the-art multilingual systems rely on shared vocabularies that\nsufficiently cover all considered languages. To this end, a simple and\nfrequently used approach makes use of subword vocabularies constructed jointly\nover several languages. We hypothesize that such vocabularies are suboptimal\ndue to false positives (identical subwords with different meanings across\nlanguages) and false negatives (different subwords with similar meanings). To\naddress these issues, we propose Subword Mapping and Anchoring across Languages\n(SMALA), a method to construct bilingual subword vocabularies. SMALA extracts\nsubword alignments using an unsupervised state-of-the-art mapping technique and\nuses them to create cross-lingual anchors based on subword similarities. We\ndemonstrate the benefits of SMALA for cross-lingual natural language inference\n(XNLI), where it improves zero-shot transfer to an unseen language without\ntask-specific data, but only by sharing subword embeddings. Moreover, in neural\nmachine translation, we show that joint subword vocabularies obtained with\nSMALA lead to higher BLEU scores on sentences that contain many false positives\nand false negatives.", "published": "2021-09-09 20:46:27", "link": "http://arxiv.org/abs/2109.04556v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TIAGE: A Benchmark for Topic-Shift Aware Dialog Modeling", "abstract": "Human conversations naturally evolve around different topics and fluently\nmove between them. In research on dialog systems, the ability to actively and\nsmoothly transition to new topics is often ignored. In this paper we introduce\nTIAGE, a new topic-shift aware dialog benchmark constructed utilizing human\nannotations on topic shifts. Based on TIAGE, we introduce three tasks to\ninvestigate different scenarios of topic-shift modeling in dialog settings:\ntopic-shift detection, topic-shift triggered response generation and\ntopic-aware dialog generation. Experiments on these tasks show that the\ntopic-shift signals in TIAGE are useful for topic-shift response generation. On\nthe other hand, dialog systems still struggle to decide when to change topic.\nThis indicates further research is needed in topic-shift aware dialog modeling.", "published": "2021-09-09 21:06:12", "link": "http://arxiv.org/abs/2109.04562v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speechformer: Reducing Information Loss in Direct Speech Translation", "abstract": "Transformer-based models have gained increasing popularity achieving\nstate-of-the-art performance in many research fields including speech\ntranslation. However, Transformer's quadratic complexity with respect to the\ninput sequence length prevents its adoption as is with audio signals, which are\ntypically represented by long sequences. Current solutions resort to an initial\nsub-optimal compression based on a fixed sampling of raw audio features.\nTherefore, potentially useful linguistic information is not accessible to\nhigher-level layers in the architecture. To solve this issue, we propose\nSpeechformer, an architecture that, thanks to reduced memory usage in the\nattention layers, avoids the initial lossy compression and aggregates\ninformation only at a higher level according to more informed linguistic\ncriteria. Experiments on three language pairs (en->de/es/nl) show the efficacy\nof our solution, with gains of up to 0.8 BLEU on the standard MuST-C corpus and\nof up to 4.0 BLEU in a low resource scenario.", "published": "2021-09-09 22:08:42", "link": "http://arxiv.org/abs/2109.04574v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BERT, mBERT, or BiBERT? A Study on Contextualized Embeddings for Neural\n  Machine Translation", "abstract": "The success of bidirectional encoders using masked language models, such as\nBERT, on numerous natural language processing tasks has prompted researchers to\nattempt to incorporate these pre-trained models into neural machine translation\n(NMT) systems. However, proposed methods for incorporating pre-trained models\nare non-trivial and mainly focus on BERT, which lacks a comparison of the\nimpact that other pre-trained models may have on translation performance. In\nthis paper, we demonstrate that simply using the output (contextualized\nembeddings) of a tailored and suitable bilingual pre-trained language model\n(dubbed BiBERT) as the input of the NMT encoder achieves state-of-the-art\ntranslation performance. Moreover, we also propose a stochastic layer selection\napproach and a concept of dual-directional translation model to ensure the\nsufficient utilization of contextualized embeddings. In the case of without\nusing back translation, our best models achieve BLEU scores of 30.45 for En->De\nand 38.61 for De->En on the IWSLT'14 dataset, and 31.26 for En->De and 34.94\nfor De->En on the WMT'14 dataset, which exceeds all published numbers.", "published": "2021-09-09 23:43:41", "link": "http://arxiv.org/abs/2109.04588v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Measuring of Readability to Improve Documents Accessibility\n  for Arabic Language Learners", "abstract": "This paper presents an approach based on supervised machine learning methods\nto build a classifier that can identify text complexity in order to present\nArabic language learners with texts suitable to their levels. The approach is\nbased on machine learning classification methods to discriminate between the\ndifferent levels of difficulty in reading and understanding a text. Several\nmodels were trained on a large corpus mined from online Arabic websites and\nmanually annotated. The model uses both Count and TF-IDF representations and\napplies five machine learning algorithms; Multinomial Naive Bayes, Bernoulli\nNaive Bayes, Logistic Regression, Support Vector Machine and Random Forest,\nusing unigrams and bigrams features. With the goal of extracting the text\ncomplexity, the problem is usually addressed by formulating the level\nidentification as a classification task. Experimental results showed that\nn-gram features could be indicative of the reading level of a text and could\nsubstantially improve performance, and showed that SVM and Multinomial Naive\nBayes are the most accurate in predicting the complexity level. Best results\nwere achieved using TF-IDF Vectors trained by a combination of word-based\nunigrams and bigrams with an overall accuracy of 87.14% over four classes of\ncomplexity.", "published": "2021-09-09 10:05:38", "link": "http://arxiv.org/abs/2109.08648v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Three-Stage Learning Framework for Low-Resource Knowledge-Grounded\n  Dialogue Generation", "abstract": "Neural conversation models have shown great potentials towards generating\nfluent and informative responses by introducing external background knowledge.\nNevertheless, it is laborious to construct such knowledge-grounded dialogues,\nand existing models usually perform poorly when transfer to new domains with\nlimited training samples. Therefore, building a knowledge-grounded dialogue\nsystem under the low-resource setting is a still crucial issue. In this paper,\nwe propose a novel three-stage learning framework based on weakly supervised\nlearning which benefits from large scale ungrounded dialogues and unstructured\nknowledge base. To better cooperate with this framework, we devise a variant of\nTransformer with decoupled decoder which facilitates the disentangled learning\nof response generation and knowledge incorporation. Evaluation results on two\nbenchmarks indicate that our approach can outperform other state-of-the-art\nmethods with less training data, and even in zero-resource scenario, our\napproach still performs well.", "published": "2021-09-09 08:32:02", "link": "http://arxiv.org/abs/2109.04096v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MapRE: An Effective Semantic Mapping Approach for Low-resource Relation\n  Extraction", "abstract": "Neural relation extraction models have shown promising results in recent\nyears; however, the model performance drops dramatically given only a few\ntraining samples. Recent works try leveraging the advance in few-shot learning\nto solve the low resource problem, where they train label-agnostic models to\ndirectly compare the semantic similarities among context sentences in the\nembedding space. However, the label-aware information, i.e., the relation label\nthat contains the semantic knowledge of the relation itself, is often neglected\nfor prediction. In this work, we propose a framework considering both\nlabel-agnostic and label-aware semantic mapping information for low resource\nrelation extraction. We show that incorporating the above two types of mapping\ninformation in both pretraining and fine-tuning can significantly improve the\nmodel performance on low-resource relation extraction tasks.", "published": "2021-09-09 09:02:23", "link": "http://arxiv.org/abs/2109.04108v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fixing exposure bias with imitation learning needs powerful oracles", "abstract": "We apply imitation learning (IL) to tackle the NMT exposure bias problem with\nerror-correcting oracles, and evaluate an SMT lattice-based oracle which,\ndespite its excellent performance in an unconstrained oracle translation task,\nturned out to be too pruned and idiosyncratic to serve as the oracle for IL.", "published": "2021-09-09 09:10:07", "link": "http://arxiv.org/abs/2109.04114v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fusing task-oriented and open-domain dialogues in conversational agents", "abstract": "The goal of building intelligent dialogue systems has largely been separately\npursued under two paradigms: task-oriented dialogue (TOD) systems, which\nperform goal-oriented functions, and open-domain dialogue (ODD) systems, which\nfocus on non-goal-oriented chitchat. The two dialogue modes can potentially be\nintertwined together seamlessly in the same conversation, as easily done by a\nfriendly human assistant. Such ability is desirable in conversational agents,\nas the integration makes them more accessible and useful. Our paper addresses\nthis problem of fusing TODs and ODDs in multi-turn dialogues. Based on the\npopular TOD dataset MultiWOZ, we build a new dataset FusedChat, by rewriting\nthe existing TOD turns and adding new ODD turns. This procedure constructs\nconversation sessions containing exchanges from both dialogue modes. It\nfeatures inter-mode contextual dependency, i.e., the dialogue turns from the\ntwo modes depend on each other. Rich dependency patterns including co-reference\nand ellipsis are features. The new dataset, with 60k new human-written ODD\nturns and 5k re-written TOD turns, offers a benchmark to test a dialogue\nmodel's ability to perform inter-mode conversations. This is a more challenging\ntask since the model has to determine the appropriate dialogue mode and\ngenerate the response based on the inter-mode context. But such models would\nbetter mimic human-level conversation capabilities. We evaluate baseline models\non this task, including classification-based two-stage models and two-in-one\nfused models. We publicly release FusedChat and the baselines to propel future\nwork on inter-mode dialogue systems https://github.com/tomyoung903/FusedChat.", "published": "2021-09-09 09:48:26", "link": "http://arxiv.org/abs/2109.04137v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Avoiding Inference Heuristics in Few-shot Prompt-based Finetuning", "abstract": "Recent prompt-based approaches allow pretrained language models to achieve\nstrong performances on few-shot finetuning by reformulating downstream tasks as\na language modeling problem. In this work, we demonstrate that, despite its\nadvantages on low data regimes, finetuned prompt-based models for sentence pair\nclassification tasks still suffer from a common pitfall of adopting inference\nheuristics based on lexical overlap, e.g., models incorrectly assuming a\nsentence pair is of the same meaning because they consist of the same set of\nwords. Interestingly, we find that this particular inference heuristic is\nsignificantly less present in the zero-shot evaluation of the prompt-based\nmodel, indicating how finetuning can be destructive to useful knowledge learned\nduring the pretraining. We then show that adding a regularization that\npreserves pretraining weights is effective in mitigating this destructive\ntendency of few-shot finetuning. Our evaluation on three datasets demonstrates\npromising improvements on the three corresponding challenge datasets used to\ndiagnose the inference heuristics.", "published": "2021-09-09 10:10:29", "link": "http://arxiv.org/abs/2109.04144v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Lexico-semantic and affective modelling of Spanish poetry: A\n  semi-supervised learning approach", "abstract": "Text classification tasks have improved substantially during the last years\nby the usage of transformers. However, the majority of researches focus on\nprose texts, with poetry receiving less attention, specially for Spanish\nlanguage. In this paper, we propose a semi-supervised learning approach for\ninferring 21 psychological categories evoked by a corpus of 4572 sonnets, along\nwith 10 affective and lexico-semantic multiclass ones. The subset of poems used\nfor training an evaluation includes 270 sonnets. With our approach, we achieve\nan AUC beyond 0.7 for 76% of the psychological categories, and an AUC over 0.65\nfor 60% on the multiclass ones. The sonnets are modelled using transformers,\nthrough sentence embeddings, along with lexico-semantic and affective features,\nobtained by using external lexicons. Consequently, we see that this approach\nprovides an AUC increase of up to 0.12, as opposed to using transformers alone.", "published": "2021-09-09 10:26:16", "link": "http://arxiv.org/abs/2109.04152v2", "categories": ["cs.AI", "cs.CL", "J.5.5; I.7.m; I.5.4; I.2.7"], "primary_category": "cs.AI"}
{"title": "KELM: Knowledge Enhanced Pre-Trained Language Representations with\n  Message Passing on Hierarchical Relational Graphs", "abstract": "Incorporating factual knowledge into pre-trained language models (PLM) such\nas BERT is an emerging trend in recent NLP studies. However, most of the\nexisting methods combine the external knowledge integration module with a\nmodified pre-training loss and re-implement the pre-training process on the\nlarge-scale corpus. Re-pretraining these models is usually resource-consuming,\nand difficult to adapt to another domain with a different knowledge graph (KG).\nBesides, those works either cannot embed knowledge context dynamically\naccording to textual context or struggle with the knowledge ambiguity issue. In\nthis paper, we propose a novel knowledge-aware language model framework based\non fine-tuning process, which equips PLM with a unified knowledge-enhanced text\ngraph that contains both text and multi-relational sub-graphs extracted from\nKG. We design a hierarchical relational-graph-based message passing mechanism,\nwhich can allow the representations of injected KG and text to mutually update\neach other and can dynamically select ambiguous mentioned entities that share\nthe same text. Our empirical results show that our model can efficiently\nincorporate world knowledge from KGs into existing language models such as\nBERT, and achieve significant improvement on the machine reading comprehension\n(MRC) task compared with other knowledge-enhanced models.", "published": "2021-09-09 12:39:17", "link": "http://arxiv.org/abs/2109.04223v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MetaXT: Meta Cross-Task Transfer between Disparate Label Spaces", "abstract": "Albeit the universal representational power of pre-trained language models,\nadapting them onto a specific NLP task still requires a considerably large\namount of labeled data. Effective task fine-tuning meets challenges when only a\nfew labeled examples are present for the task. In this paper, we aim to the\naddress of the problem of few shot task learning by exploiting and transferring\nfrom a different task which admits a related but disparate label space.\nSpecifically, we devise a label transfer network (LTN) to transform the labels\nfrom source task to the target task of interest for training. Both the LTN and\nthe model for task prediction are learned via a bi-level optimization\nframework, which we term as MetaXT. MetaXT offers a principled solution to best\nadapt a pre-trained language model to the target task by transferring knowledge\nfrom the source task. Empirical evaluations on cross-task transfer settings for\nfour NLP tasks, from two different types of label space disparities,\ndemonstrate the effectiveness of MetaXT, especially when the labeled data in\nthe target task is limited.", "published": "2021-09-09 12:59:01", "link": "http://arxiv.org/abs/2109.04240v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Cartography Active Learning", "abstract": "We propose Cartography Active Learning (CAL), a novel Active Learning (AL)\nalgorithm that exploits the behavior of the model on individual instances\nduring training as a proxy to find the most informative instances for labeling.\nCAL is inspired by data maps, which were recently proposed to derive insights\ninto dataset quality (Swayamdipta et al., 2020). We compare our method on\npopular text classification tasks to commonly used AL strategies, which instead\nrely on post-training behavior. We demonstrate that CAL is competitive to other\ncommon AL methods, showing that training dynamics derived from small seed data\ncan be successfully used for AL. We provide insights into our new AL method by\nanalyzing batch-level statistics utilizing the data maps. Our results further\nshow that CAL results in a more data-efficient learning strategy, achieving\ncomparable or better results with considerably less training data.", "published": "2021-09-09 14:02:02", "link": "http://arxiv.org/abs/2109.04282v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Smoothed Contrastive Learning for Unsupervised Sentence Embedding", "abstract": "Contrastive learning has been gradually applied to learn high-quality\nunsupervised sentence embedding. Among the previous un-supervised methods, the\nlatest state-of-the-art method, as far as we know, is unsupervised SimCSE\n(unsup-SimCSE). Unsup-SimCSE uses the InfoNCE1loss function in the training\nstage by pulling semantically similar sentences together and pushing apart\ndis-similar ones.Theoretically, we expect to use larger batches in unsup-SimCSE\nto get more adequate comparisons among samples and avoid overfitting. However,\nincreasing the batch size does not always lead to improvements, but instead\neven lead to performance degradation when the batch size exceeds a threshold.\nThrough statistical observation, we find that this is probably due to the\nintroduction of low-confidence negative pairs after in-creasing the batch size.\nTo alleviate this problem, we introduce a simple smoothing strategy upon the\nInfoNCE loss function, termedGaussian Smoothing InfoNCE\n(GS-InfoNCE).Specifically, we add random Gaussian noise vectors as negative\nsamples, which act asa smoothing of the negative sample space.Though being\nsimple, the proposed smooth-ing strategy brings substantial improvements to\nunsup-SimCSE. We evaluate GS-InfoNCEon the standard semantic text similarity\n(STS)task. GS-InfoNCE outperforms the state-of-the-art unsup-SimCSE by an\naverage Spear-man correlation of 1.38%, 0.72%, 1.17% and0.28% on the base of\nBERT-base, BERT-large,RoBERTa-base and RoBERTa-large, respectively.", "published": "2021-09-09 14:54:24", "link": "http://arxiv.org/abs/2109.04321v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ESimCSE: Enhanced Sample Building Method for Contrastive Learning of\n  Unsupervised Sentence Embedding", "abstract": "Contrastive learning has been attracting much attention for learning\nunsupervised sentence embeddings. The current state-of-the-art unsupervised\nmethod is the unsupervised SimCSE (unsup-SimCSE). Unsup-SimCSE takes dropout as\na minimal data augmentation method, and passes the same input sentence to a\npre-trained Transformer encoder (with dropout turned on) twice to obtain the\ntwo corresponding embeddings to build a positive pair. As the length\ninformation of a sentence will generally be encoded into the sentence\nembeddings due to the usage of position embedding in Transformer, each positive\npair in unsup-SimCSE actually contains the same length information. And thus\nunsup-SimCSE trained with these positive pairs is probably biased, which would\ntend to consider that sentences of the same or similar length are more similar\nin semantics. Through statistical observations, we find that unsup-SimCSE does\nhave such a problem. To alleviate it, we apply a simple repetition operation to\nmodify the input sentence, and then pass the input sentence and its modified\ncounterpart to the pre-trained Transformer encoder, respectively, to get the\npositive pair. Additionally, we draw inspiration from the community of computer\nvision and introduce a momentum contrast, enlarging the number of negative\npairs without additional calculations. The proposed two modifications are\napplied on positive and negative pairs separately, and build a new sentence\nembedding method, termed Enhanced Unsup-SimCSE (ESimCSE). We evaluate the\nproposed ESimCSE on several benchmark datasets w.r.t the semantic text\nsimilarity (STS) task. Experimental results show that ESimCSE outperforms the\nstate-of-the-art unsup-SimCSE by an average Spearman correlation of 2.02% on\nBERT-base.", "published": "2021-09-09 16:07:31", "link": "http://arxiv.org/abs/2109.04380v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "All Bark and No Bite: Rogue Dimensions in Transformer Language Models\n  Obscure Representational Quality", "abstract": "Similarity measures are a vital tool for understanding how language models\nrepresent and process language. Standard representational similarity measures\nsuch as cosine similarity and Euclidean distance have been successfully used in\nstatic word embedding models to understand how words cluster in semantic space.\nRecently, these measures have been applied to embeddings from contextualized\nmodels such as BERT and GPT-2. In this work, we call into question the\ninformativity of such measures for contextualized language models. We find that\na small number of rogue dimensions, often just 1-3, dominate these measures.\nMoreover, we find a striking mismatch between the dimensions that dominate\nsimilarity measures and those which are important to the behavior of the model.\nWe show that simple postprocessing techniques such as standardization are able\nto correct for rogue dimensions and reveal underlying representational quality.\nWe argue that accounting for rogue dimensions is essential for any\nsimilarity-based analysis of contextual language models.", "published": "2021-09-09 16:45:15", "link": "http://arxiv.org/abs/2109.04404v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TxT: Crossmodal End-to-End Learning with Transformers", "abstract": "Reasoning over multiple modalities, e.g. in Visual Question Answering (VQA),\nrequires an alignment of semantic concepts across domains. Despite the\nwidespread success of end-to-end learning, today's multimodal pipelines by and\nlarge leverage pre-extracted, fixed features from object detectors, typically\nFaster R-CNN, as representations of the visual world. The obvious downside is\nthat the visual representation is not specifically tuned to the multimodal task\nat hand. At the same time, while transformer-based object detectors have gained\npopularity, they have not been employed in today's multimodal pipelines. We\naddress both shortcomings with TxT, a transformer-based crossmodal pipeline\nthat enables fine-tuning both language and visual components on the downstream\ntask in a fully end-to-end manner. We overcome existing limitations of\ntransformer-based detectors for multimodal reasoning regarding the integration\nof global context and their scalability. Our transformer-based multimodal model\nachieves considerable gains from end-to-end learning for multimodal question\nanswering.", "published": "2021-09-09 17:12:20", "link": "http://arxiv.org/abs/2109.04422v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Vision-and-Language or Vision-for-Language? On Cross-Modal Influence in\n  Multimodal Transformers", "abstract": "Pretrained vision-and-language BERTs aim to learn representations that\ncombine information from both modalities. We propose a diagnostic method based\non cross-modal input ablation to assess the extent to which these models\nactually integrate cross-modal information. This method involves ablating\ninputs from one modality, either entirely or selectively based on cross-modal\ngrounding alignments, and evaluating the model prediction performance on the\nother modality. Model performance is measured by modality-specific tasks that\nmirror the model pretraining objectives (e.g. masked language modelling for\ntext). Models that have learned to construct cross-modal representations using\nboth modalities are expected to perform worse when inputs are missing from a\nmodality. We find that recently proposed models have much greater relative\ndifficulty predicting text when visual information is ablated, compared to\npredicting visual object categories when text is ablated, indicating that these\nmodels are not symmetrically cross-modal.", "published": "2021-09-09 17:47:50", "link": "http://arxiv.org/abs/2109.04448v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "SeDyT: A General Framework for Multi-Step Event Forecasting via Sequence\n  Modeling on Dynamic Entity Embeddings", "abstract": "Temporal Knowledge Graphs store events in the form of subjects, relations,\nobjects, and timestamps which are often represented by dynamic heterogeneous\ngraphs. Event forecasting is a critical and challenging task in Temporal\nKnowledge Graph reasoning that predicts the subject or object of an event in\nthe future. To obtain temporal embeddings multi-step away in the future,\nexisting methods learn generative models that capture the joint distribution of\nthe observed events. To reduce the high computation costs, these methods rely\non unrealistic assumptions of independence and approximations in training and\ninference. In this work, we propose SeDyT, a discriminative framework that\nperforms sequence modeling on the dynamic entity embeddings to solve the\nmulti-step event forecasting problem. SeDyT consists of two components: a\nTemporal Graph Neural Network that generates dynamic entity embeddings in the\npast and a sequence model that predicts the entity embeddings in the future.\nCompared with the generative models, SeDyT does not rely on any heuristic-based\nprobability model and has low computation complexity in both training and\ninference. SeDyT is compatible with most Temporal Graph Neural Networks and\nsequence models. We also design an efficient training method that trains the\ntwo components in one gradient descent propagation. We evaluate the performance\nof SeDyT on five popular datasets. By combining temporal Graph Neural Network\nmodels and sequence models, SeDyT achieves an average of 2.4% MRR improvement\nwhen not using the validation set and more than 10% MRR improvement when using\nthe validation set.", "published": "2021-09-09 20:32:48", "link": "http://arxiv.org/abs/2109.04550v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SPECTRA: Sparse Structured Text Rationalization", "abstract": "Selective rationalization aims to produce decisions along with rationales\n(e.g., text highlights or word alignments between two sentences). Commonly,\nrationales are modeled as stochastic binary masks, requiring sampling-based\ngradient estimators, which complicates training and requires careful\nhyperparameter tuning. Sparse attention mechanisms are a deterministic\nalternative, but they lack a way to regularize the rationale extraction (e.g.,\nto control the sparsity of a text highlight or the number of alignments). In\nthis paper, we present a unified framework for deterministic extraction of\nstructured explanations via constrained inference on a factor graph, forming a\ndifferentiable layer. Our approach greatly eases training and rationale\nregularization, generally outperforming previous work on what comes to\nperformance and plausibility of the extracted rationales. We further provide a\ncomparative study of stochastic and deterministic methods for rationale\nextraction for classification and natural language inference tasks, jointly\nassessing their predictive power, quality of the explanations, and model\nvariability.", "published": "2021-09-09 20:39:56", "link": "http://arxiv.org/abs/2109.04552v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Graph-Based Decoding for Task Oriented Semantic Parsing", "abstract": "The dominant paradigm for semantic parsing in recent years is to formulate\nparsing as a sequence-to-sequence task, generating predictions with\nauto-regressive sequence decoders. In this work, we explore an alternative\nparadigm. We formulate semantic parsing as a dependency parsing task, applying\ngraph-based decoding techniques developed for syntactic parsing. We compare\nvarious decoding techniques given the same pre-trained Transformer encoder on\nthe TOP dataset, including settings where training data is limited or contains\nonly partially-annotated examples. We find that our graph-based approach is\ncompetitive with sequence decoders on the standard setting, and offers\nsignificant improvements in data efficiency and settings where\npartially-annotated data is available.", "published": "2021-09-09 23:22:09", "link": "http://arxiv.org/abs/2109.04587v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Large-Scale Study of Machine Translation in the Turkic Languages", "abstract": "Recent advances in neural machine translation (NMT) have pushed the quality\nof machine translation systems to the point where they are becoming widely\nadopted to build competitive systems. However, there is still a large number of\nlanguages that are yet to reap the benefits of NMT. In this paper, we provide\nthe first large-scale case study of the practical application of MT in the\nTurkic language family in order to realize the gains of NMT for Turkic\nlanguages under high-resource to extremely low-resource scenarios. In addition\nto presenting an extensive analysis that identifies the bottlenecks towards\nbuilding competitive systems to ameliorate data scarcity, our study has several\nkey contributions, including, i) a large parallel corpus covering 22 Turkic\nlanguages consisting of common public datasets in combination with new datasets\nof approximately 2 million parallel sentences, ii) bilingual baselines for 26\nlanguage pairs, iii) novel high-quality test sets in three different\ntranslation domains and iv) human evaluation scores. All models, scripts, and\ndata will be released to the public.", "published": "2021-09-09 23:56:30", "link": "http://arxiv.org/abs/2109.04593v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distributionally Robust Multilingual Machine Translation", "abstract": "Multilingual neural machine translation (MNMT) learns to translate multiple\nlanguage pairs with a single model, potentially improving both the accuracy and\nthe memory-efficiency of deployed models. However, the heavy data imbalance\nbetween languages hinders the model from performing uniformly across language\npairs. In this paper, we propose a new learning objective for MNMT based on\ndistributionally robust optimization, which minimizes the worst-case expected\nloss over the set of language pairs. We further show how to practically\noptimize this objective for large translation corpora using an iterated best\nresponse scheme, which is both effective and incurs negligible additional\ncomputational cost compared to standard empirical risk minimization. We perform\nextensive experiments on three sets of languages from two datasets and show\nthat our method consistently outperforms strong baseline methods in terms of\naverage and per-language performance under both many-to-one and one-to-many\ntranslation settings.", "published": "2021-09-09 03:48:35", "link": "http://arxiv.org/abs/2109.04020v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Table-based Fact Verification with Salience-aware Learning", "abstract": "Tables provide valuable knowledge that can be used to verify textual\nstatements. While a number of works have considered table-based fact\nverification, direct alignments of tabular data with tokens in textual\nstatements are rarely available. Moreover, training a generalized fact\nverification model requires abundant labeled training data. In this paper, we\npropose a novel system to address these problems. Inspired by counterfactual\ncausality, our system identifies token-level salience in the statement with\nprobing-based salience estimation. Salience estimation allows enhanced learning\nof fact verification from two perspectives. From one perspective, our system\nconducts masked salient token prediction to enhance the model for alignment and\nreasoning between the table and the statement. From the other perspective, our\nsystem applies salience-aware data augmentation to generate a more diverse set\nof training instances by replacing non-salient terms. Experimental results on\nTabFact show the effective improvement by the proposed salience-aware learning\ntechniques, leading to the new SOTA performance on the benchmark. Our code is\npublicly available at https://github.com/luka-group/Salience-aware-Learning .", "published": "2021-09-09 06:18:46", "link": "http://arxiv.org/abs/2109.04053v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TimeTraveler: Reinforcement Learning for Temporal Knowledge Graph\n  Forecasting", "abstract": "Temporal knowledge graph (TKG) reasoning is a crucial task that has gained\nincreasing research interest in recent years. Most existing methods focus on\nreasoning at past timestamps to complete the missing facts, and there are only\na few works of reasoning on known TKGs to forecast future facts. Compared with\nthe completion task, the forecasting task is more difficult that faces two main\nchallenges: (1) how to effectively model the time information to handle future\ntimestamps? (2) how to make inductive inference to handle previously unseen\nentities that emerge over time? To address these challenges, we propose the\nfirst reinforcement learning method for forecasting. Specifically, the agent\ntravels on historical knowledge graph snapshots to search for the answer. Our\nmethod defines a relative time encoding function to capture the timespan\ninformation, and we design a novel time-shaped reward based on Dirichlet\ndistribution to guide the model learning. Furthermore, we propose a novel\nrepresentation method for unseen entities to improve the inductive inference\nability of the model. We evaluate our method for this link prediction task at\nfuture timestamps. Extensive experiments on four benchmark datasets demonstrate\nsubstantial performance improvement meanwhile with higher explainability, less\ncalculation, and fewer parameters when compared with existing state-of-the-art\nmethods.", "published": "2021-09-09 08:41:01", "link": "http://arxiv.org/abs/2109.04101v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MATE: Multi-view Attention for Table Transformer Efficiency", "abstract": "This work presents a sparse-attention Transformer architecture for modeling\ndocuments that contain large tables. Tables are ubiquitous on the web, and are\nrich in information. However, more than 20% of relational tables on the web\nhave 20 or more rows (Cafarella et al., 2008), and these large tables present a\nchallenge for current Transformer models, which are typically limited to 512\ntokens. Here we propose MATE, a novel Transformer architecture designed to\nmodel the structure of web tables. MATE uses sparse attention in a way that\nallows heads to efficiently attend to either rows or columns in a table. This\narchitecture scales linearly with respect to speed and memory, and can handle\ndocuments containing more than 8000 tokens with current accelerators. MATE also\nhas a more appropriate inductive bias for tabular data, and sets a new\nstate-of-the-art for three table reasoning datasets. For HybridQA (Chen et al.,\n2020b), a dataset that involves large documents containing tables, we improve\nthe best prior result by 19 points.", "published": "2021-09-09 14:39:30", "link": "http://arxiv.org/abs/2109.04312v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Translate & Fill: Improving Zero-Shot Multilingual Semantic Parsing with\n  Synthetic Data", "abstract": "While multilingual pretrained language models (LMs) fine-tuned on a single\nlanguage have shown substantial cross-lingual task transfer capabilities, there\nis still a wide performance gap in semantic parsing tasks when target language\nsupervision is available. In this paper, we propose a novel Translate-and-Fill\n(TaF) method to produce silver training data for a multilingual semantic\nparser. This method simplifies the popular Translate-Align-Project (TAP)\npipeline and consists of a sequence-to-sequence filler model that constructs a\nfull parse conditioned on an utterance and a view of the same parse. Our filler\nis trained on English data only but can accurately complete instances in other\nlanguages (i.e., translations of the English training utterances), in a\nzero-shot fashion. Experimental results on three multilingual semantic parsing\ndatasets show that data augmentation with TaF reaches accuracies competitive\nwith similar systems which rely on traditional alignment techniques.", "published": "2021-09-09 14:51:11", "link": "http://arxiv.org/abs/2109.04319v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Opinion Summarizers by Selecting Informative Reviews", "abstract": "Opinion summarization has been traditionally approached with unsupervised,\nweakly-supervised and few-shot learning techniques. In this work, we collect a\nlarge dataset of summaries paired with user reviews for over 31,000 products,\nenabling supervised training. However, the number of reviews per product is\nlarge (320 on average), making summarization - and especially training a\nsummarizer - impractical. Moreover, the content of many reviews is not\nreflected in the human-written summaries, and, thus, the summarizer trained on\nrandom review subsets hallucinates. In order to deal with both of these\nchallenges, we formulate the task as jointly learning to select informative\nsubsets of reviews and summarizing the opinions expressed in these subsets. The\nchoice of the review subset is treated as a latent variable, predicted by a\nsmall and simple selector. The subset is then fed into a more powerful\nsummarizer. For joint training, we use amortized variational inference and\npolicy gradient methods. Our experiments demonstrate the importance of\nselecting informative reviews resulting in improved quality of summaries and\nreduced hallucinations.", "published": "2021-09-09 15:01:43", "link": "http://arxiv.org/abs/2109.04325v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-granularity Textual Adversarial Attack with Behavior Cloning", "abstract": "Recently, the textual adversarial attack models become increasingly popular\ndue to their successful in estimating the robustness of NLP models. However,\nexisting works have obvious deficiencies. (1) They usually consider only a\nsingle granularity of modification strategies (e.g. word-level or\nsentence-level), which is insufficient to explore the holistic textual space\nfor generation; (2) They need to query victim models hundreds of times to make\na successful attack, which is highly inefficient in practice. To address such\nproblems, in this paper we propose MAYA, a Multi-grAnularitY Attack model to\neffectively generate high-quality adversarial samples with fewer queries to\nvictim models. Furthermore, we propose a reinforcement-learning based method to\ntrain a multi-granularity attack agent through behavior cloning with the expert\nknowledge from our MAYA algorithm to further reduce the query times.\nAdditionally, we also adapt the agent to attack black-box models that only\noutput labels without confidence scores. We conduct comprehensive experiments\nto evaluate our attack models by attacking BiLSTM, BERT and RoBERTa in two\ndifferent black-box attack settings and three benchmark datasets. Experimental\nresults show that our models achieve overall better attacking performance and\nproduce more fluent and grammatical adversarial samples compared to baseline\nmodels. Besides, our adversarial attack agent significantly reduces the query\ntimes in both attack settings. Our codes are released at\nhttps://github.com/Yangyi-Chen/MAYA.", "published": "2021-09-09 15:46:45", "link": "http://arxiv.org/abs/2109.04367v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Transfer for Text Classification with Dictionary-based\n  Heterogeneous Graph", "abstract": "In cross-lingual text classification, it is required that task-specific\ntraining data in high-resource source languages are available, where the task\nis identical to that of a low-resource target language. However, collecting\nsuch training data can be infeasible because of the labeling cost, task\ncharacteristics, and privacy concerns. This paper proposes an alternative\nsolution that uses only task-independent word embeddings of high-resource\nlanguages and bilingual dictionaries. First, we construct a dictionary-based\nheterogeneous graph (DHG) from bilingual dictionaries. This opens the\npossibility to use graph neural networks for cross-lingual transfer. The\nremaining challenge is the heterogeneity of DHG because multiple languages are\nconsidered. To address this challenge, we propose dictionary-based\nheterogeneous graph neural network (DHGNet) that effectively handles the\nheterogeneity of DHG by two-step aggregations, which are word-level and\nlanguage-level aggregations. Experimental results demonstrate that our method\noutperforms pretrained models even though it does not access to large corpora.\nFurthermore, it can perform well even though dictionaries contain many\nincorrect translations. Its robustness allows the usage of a wider range of\ndictionaries such as an automatically constructed dictionary and crowdsourced\ndictionary, which are convenient for real-world applications.", "published": "2021-09-09 16:40:40", "link": "http://arxiv.org/abs/2109.04400v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning with Different Amounts of Annotation: From Zero to Many Labels", "abstract": "Training NLP systems typically assumes access to annotated data that has a\nsingle human label per example. Given imperfect labeling from annotators and\ninherent ambiguity of language, we hypothesize that single label is not\nsufficient to learn the spectrum of language interpretation. We explore new\nannotation distribution schemes, assigning multiple labels per example for a\nsmall subset of training examples. Introducing such multi label examples at the\ncost of annotating fewer examples brings clear gains on natural language\ninference task and entity typing task, even when we simply first train with a\nsingle label data and then fine tune with multi label examples. Extending a\nMixUp data augmentation framework, we propose a learning algorithm that can\nlearn from training examples with different amount of annotation (with zero,\none, or multiple labels). This algorithm efficiently combines signals from\nuneven training data and brings additional gains in low annotation budget and\ncross domain settings. Together, our method achieves consistent gains in two\ntasks, suggesting distributing labels unevenly among training examples can be\nbeneficial for many NLP tasks.", "published": "2021-09-09 16:48:41", "link": "http://arxiv.org/abs/2109.04408v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Non-autoregressive End-to-end Speech Translation with Parallel\n  Autoregressive Rescoring", "abstract": "This article describes an efficient end-to-end speech translation (E2E-ST)\nframework based on non-autoregressive (NAR) models. End-to-end speech\ntranslation models have several advantages over traditional cascade systems\nsuch as inference latency reduction. However, conventional AR decoding methods\nare not fast enough because each token is generated incrementally. NAR models,\nhowever, can accelerate the decoding speed by generating multiple tokens in\nparallel on the basis of the token-wise conditional independence assumption. We\npropose a unified NAR E2E-ST framework called Orthros, which has an NAR decoder\nand an auxiliary shallow AR decoder on top of the shared encoder. The auxiliary\nshallow AR decoder selects the best hypothesis by rescoring multiple candidates\ngenerated from the NAR decoder in parallel (parallel AR rescoring). We adopt\nconditional masked language model (CMLM) and a connectionist temporal\nclassification (CTC)-based model as NAR decoders for Orthros, referred to as\nOrthros-CMLM and Orthros-CTC, respectively. We also propose two training\nmethods to enhance the CMLM decoder. Experimental evaluations on three\nbenchmark datasets with six language directions demonstrated that Orthros\nachieved large improvements in translation quality with a very small overhead\ncompared with the baseline NAR model. Moreover, the Conformer encoder\narchitecture enabled large quality improvements, especially for CTC-based\nmodels. Orthros-CTC with the Conformer encoder increased decoding speed by\n3.63x on CPU with translation quality comparable to that of an AR model.", "published": "2021-09-09 16:50:16", "link": "http://arxiv.org/abs/2109.04411v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "HintedBT: Augmenting Back-Translation with Quality and Transliteration\n  Hints", "abstract": "Back-translation (BT) of target monolingual corpora is a widely used data\naugmentation strategy for neural machine translation (NMT), especially for\nlow-resource language pairs. To improve effectiveness of the available BT data,\nwe introduce HintedBT -- a family of techniques which provides hints (through\ntags) to the encoder and decoder. First, we propose a novel method of using\nboth high and low quality BT data by providing hints (as source tags on the\nencoder) to the model about the quality of each source-target pair. We don't\nfilter out low quality data but instead show that these hints enable the model\nto learn effectively from noisy data. Second, we address the problem of\npredicting whether a source token needs to be translated or transliterated to\nthe target language, which is common in cross-script translation tasks (i.e.,\nwhere source and target do not share the written script). For such cases, we\npropose training the model with additional hints (as target tags on the\ndecoder) that provide information about the operation required on the source\n(translation or both translation and transliteration). We conduct experiments\nand detailed analyses on standard WMT benchmarks for three cross-script\nlow/medium-resource language pairs: {Hindi,Gujarati,Tamil}-to-English. Our\nmethods compare favorably with five strong and well established baselines. We\nshow that using these hints, both separately and together, significantly\nimproves translation quality and leads to state-of-the-art performance in all\nthree language pairs in corresponding bilingual settings.", "published": "2021-09-09 17:43:20", "link": "http://arxiv.org/abs/2109.04443v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Identifying Morality Frames in Political Tweets using Relational\n  Learning", "abstract": "Extracting moral sentiment from text is a vital component in understanding\npublic opinion, social movements, and policy decisions. The Moral Foundation\nTheory identifies five moral foundations, each associated with a positive and\nnegative polarity. However, moral sentiment is often motivated by its targets,\nwhich can correspond to individuals or collective entities. In this paper, we\nintroduce morality frames, a representation framework for organizing moral\nattitudes directed at different entities, and come up with a novel and\nhigh-quality annotated dataset of tweets written by US politicians. Then, we\npropose a relational learning model to predict moral attitudes towards entities\nand moral foundations jointly. We do qualitative and quantitative evaluations,\nshowing that moral sentiment towards entities differs highly across political\nideologies.", "published": "2021-09-09 19:48:57", "link": "http://arxiv.org/abs/2109.04535v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Medically Aware GPT-3 as a Data Generator for Medical Dialogue\n  Summarization", "abstract": "In medical dialogue summarization, summaries must be coherent and must\ncapture all the medically relevant information in the dialogue. However,\nlearning effective models for summarization require large amounts of labeled\ndata which is especially hard to obtain. We present an algorithm to create\nsynthetic training data with an explicit focus on capturing medically relevant\ninformation. We utilize GPT-3 as the backbone of our algorithm and scale 210\nhuman labeled examples to yield results comparable to using 6400 human labeled\nexamples (~30x) leveraging low-shot learning and an ensemble method. In\ndetailed experiments, we show that this approach produces high quality training\ndata that can further be combined with human labeled data to get summaries that\nare strongly preferable to those produced by models trained on human data alone\nboth in terms of medical accuracy and coherency.", "published": "2021-09-09 18:32:56", "link": "http://arxiv.org/abs/2110.07356v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The IDLAB VoxCeleb Speaker Recognition Challenge 2021 System Description", "abstract": "This technical report describes the IDLab submission for track 1 and 2 of the\nVoxCeleb Speaker Recognition Challenge 2021 (VoxSRC-21). This speaker\nverification competition focuses on short duration test recordings and\ncross-lingual trials. Currently, both Time Delay Neural Networks (TDNNs) and\nResNets achieve state-of-the-art results in speaker verification. We opt to use\na system fusion of hybrid architectures in our final submission. An ECAPA-TDNN\nbaseline is enhanced with a 2D convolutional stem to transfer some of the\nstrong characteristics of a ResNet based model to this hybrid CNN-TDNN\narchitecture. Similarly, we incorporate absolute frequency positional\ninformation in the SE-ResNet architectures. All models are trained with a\nspecial mini-batch data sampling technique which constructs mini-batches with\ndata that is the most challenging for the system on the level of intra-speaker\nvariability. This intra-speaker variability is mainly caused by differences in\nlanguage and background conditions between the speaker's utterances. The\ncross-lingual effects on the speaker verification scores are further\ncompensated by introducing a binary cross-linguality trial feature in the\nlogistic regression based system calibration. The final system fusion with two\nECAPA CNN-TDNNs and three SE-ResNets enhanced with frequency positional\ninformation achieved a third place on the VoxSRC-21 leaderboard for both track\n1 and 2 with a minDCF of 0.1291 and 0.1313 respectively.", "published": "2021-09-09 07:23:38", "link": "http://arxiv.org/abs/2109.04070v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Robust single- and multi-loudspeaker least-squares-based equalization\n  for hearing devices", "abstract": "To improve the sound quality of hearing devices, equalization filters can be\nused that aim at achieving acoustic transparency, i.e., listening with the\ndevice in the ear is perceptually similar to the open ear. The equalization\nfilter needs to ensure that the superposition of the equalized signal played by\nthe device and the signal leaking through the device into the ear canal matches\na processed version of the signal reaching the eardrum of the open ear.\nDepending on the processing delay of the hearing device, comb-filtering\nartifacts can occur due to this superposition, which may degrade the perceived\nsound quality. In this paper we propose a unified least-squares-based procedure\nto design single- and multi-loudspeaker equalization filters for hearing\ndevices aiming at achieving acoustic transparency. To account for non-minimum\nphase components, we introduce a so-called acausality management. To reduce\ncomb-filtering artifacts, we propose to use a frequency-dependent\nregularization. Experimental results using measured acoustic transfer functions\nfrom a multi-loudspeaker earpiece show that the proposed equalization filter\ndesign procedure enables to achieve robust acoustic transparency and reduces\nthe impact of comb-filtering artifacts. A comparison between single- and\nmulti-loudspeaker equalization shows that for both cases a robust equalization\nperformance can be achieved for different desired open ear transfer functions.", "published": "2021-09-09 12:59:23", "link": "http://arxiv.org/abs/2109.04241v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "BeamTransformer: Microphone Array-based Overlapping Speech Detection", "abstract": "We propose BeamTransformer, an efficient architecture to leverage\nbeamformer's edge in spatial filtering and transformer's capability in context\nsequence modeling. BeamTransformer seeks to optimize modeling of sequential\nrelationship among signals from different spatial direction. Overlapping speech\ndetection is one of the tasks where such optimization is favorable. In this\npaper we effectively apply BeamTransformer to detect overlapping segments.\nComparing to single-channel approach, BeamTransformer exceeds in learning to\nidentify the relationship among different beam sequences and hence able to make\npredictions not only from the acoustic signals but also the localization of the\nsource. The results indicate that a successful incorporation of microphone\narray signals can lead to remarkable gains. Moreover, BeamTransformer takes one\nstep further, as speech from overlapped speakers have been internally separated\ninto different beams.", "published": "2021-09-09 06:10:48", "link": "http://arxiv.org/abs/2109.04049v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DeepEMO: Deep Learning for Speech Emotion Recognition", "abstract": "We proposed the industry level deep learning approach for speech emotion\nrecognition task. In industry, carefully proposed deep transfer learning\ntechnology shows real results due to mostly low amount of training data\navailability, machine training cost, and specialized learning on dedicated AI\ntasks. The proposed speech recognition framework, called DeepEMO, consists of\ntwo main pipelines such that preprocessing to extract efficient main features\nand deep transfer learning model to train and recognize. Main source code is in\nhttps://github.com/enkhtogtokh/deepemo repository", "published": "2021-09-09 07:51:57", "link": "http://arxiv.org/abs/2109.04081v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Directional MCLP Analysis and Reconstruction for Spatial Speech\n  Communication", "abstract": "Spatial speech communication, i.e., the reconstruction of spoken signal along\nwith the relative speaker position in the enclosure (reverberation information)\nis considered in this paper. Directional, diffuse components and the source\nposition information are estimated at the transmitter, and perceptually\neffective reproduction is considered at the receiver. We consider spatially\ndistributed microphone arrays for signal acquisition, and node specific signal\nestimation, along with its direction of arrival (DoA) estimation. Short-time\nFourier transform (STFT) domain multi-channel linear prediction (MCLP) approach\nis used to model the diffuse component and relative acoustic transfer function\nis used to model the direct signal component. Distortion-less array response\nconstraint and the time-varying complex Gaussian source model are used in the\njoint estimation of source DoA and the constituent signal components,\nseparately at each node. The intersection between DoA directions at each node\nis used to compute the source position. Signal components computed at the node\nnearest to the estimated source position are taken as the signals for\ntransmission.\n  At the receiver, a four channel loud speaker (LS) setup is used for spatial\nreproduction, in which the source spatial image is reproduced relative to a\nchosen virtual listener position in the transmitter enclosure. Vector base\namplitude panning (VBAP) method is used for direct component reproduction using\nthe LS setup and the diffuse component is reproduced equally from all the loud\nspeakers after decorrelation. This scheme of spatial speech communication is\nshown to be effective and more natural for hands-free telecommunication,\nthrough either loudspeaker listening or binaural headphone listening with head\nrelated transfer function (HRTF) based presentation.", "published": "2021-09-09 20:16:48", "link": "http://arxiv.org/abs/2109.04544v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
