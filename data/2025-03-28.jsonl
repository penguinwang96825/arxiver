{"title": "Resona: Improving Context Copying in Linear Recurrence Models with Retrieval", "abstract": "Recent shifts in the space of large language model (LLM) research have shown\nan increasing focus on novel architectures to compete with prototypical\nTransformer-based models that have long dominated this space. Linear recurrent\nmodels have proven to be a viable competitor due to their computational\nefficiency. However, such models still demonstrate a sizable gap compared to\nTransformers in terms of in-context learning among other tasks that require\nrecalling information from a context. In this work, we introduce __Resona__, a\nsimple and scalable framework for augmenting linear recurrent models with\nretrieval. __Resona__~augments models with the ability to integrate retrieved\ninformation from the provided input context, enabling tailored behavior to\ndiverse task requirements. Experiments on a variety of linear recurrent models\ndemonstrate that __Resona__-augmented models observe significant performance\ngains on a variety of synthetic as well as real-world natural language tasks,\nhighlighting its ability to act as a general purpose method to improve the\nin-context learning and language modeling abilities of linear recurrent LLMs.", "published": "2025-03-28 23:43:33", "link": "http://arxiv.org/abs/2503.22913v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Token-Driven GammaTune: Adaptive Calibration for Enhanced Speculative Decoding", "abstract": "Speculative decoding accelerates large language model (LLM) inference by\nusing a smaller draft model to propose tokens, which are then verified by a\nlarger target model. However, selecting an optimal speculation length is\ncritical for maximizing speedup while minimizing wasted computation. We\nintroduce \\textit{GammaTune} and \\textit{GammaTune+}, training-free adaptive\nalgorithms that dynamically adjust speculation length based on token acceptance\nrates using a heuristic-based switching mechanism. Evaluated on SpecBench\nacross multiple tasks and model pairs, our method outperforms other\nheuristic-based approaches and fixed-length speculative decoding, achieving an\naverage speedup of 15\\% ($\\pm$5\\%) with \\textit{GammaTune} and 16\\% ($\\pm$3\\%)\nwith \\textit{GammaTune+}, while reducing performance variance. This makes\n\\textit{GammaTune} a robust and efficient solution for real-world deployment.", "published": "2025-03-28 23:41:55", "link": "http://arxiv.org/abs/2504.00030v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Quamba2: A Robust and Scalable Post-training Quantization Framework for Selective State Space Models", "abstract": "State Space Models (SSMs) are emerging as a compelling alternative to\nTransformers because of their consistent memory usage and high performance.\nDespite this, scaling up SSMs on cloud services or limited-resource devices is\nchallenging due to their storage requirements and computational power. To\novercome this, quantizing SSMs with low bit-width data formats can reduce model\nsize and benefit from hardware acceleration. As SSMs are prone to\nquantization-induced errors, recent efforts have focused on optimizing a\nparticular model or bit-width for efficiency without sacrificing performance.\nHowever, distinct bit-width configurations are essential for different\nscenarios, like W4A8 for boosting large-batch decoding speed, and W4A16 for\nenhancing generation speed in short prompt applications for a single user. To\nthis end, we present Quamba2, compatible with W8A8, W4A8, and W4A16 for both\nMamba1 and Mamba2 backbones, addressing the growing demand for SSM deployment\non various platforms. Based on the channel order preserving and activation\npersistence of SSMs, we propose an offline approach to quantize inputs of a\nlinear recurrence in 8-bit by sorting and clustering for input $x$, combined\nwith a per-state-group quantization for input-dependent parameters $B$ and $C$.\nTo ensure compute-invariance in the SSM output, we rearrange weights offline\naccording to the clustering sequence. The experiments show that Quamba2-8B\noutperforms several state-of-the-art SSM quantization methods and delivers\n1.3$\\times$ and 3$\\times$ speed-ups in the pre-filling and generation stages,\nrespectively, while offering 4$\\times$ memory reduction with only a $1.6\\%$\naverage accuracy drop. The evaluation on MMLU shows the generalizability and\nrobustness of our framework. The code and quantized models will be released at:\nhttps://github.com/enyac-group/Quamba.", "published": "2025-03-28 21:10:39", "link": "http://arxiv.org/abs/2503.22879v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.PF"], "primary_category": "cs.LG"}
{"title": "Understanding Inequality of LLM Fact-Checking over Geographic Regions with Agent and Retrieval models", "abstract": "Fact-checking is a potentially useful application of Large Language Models\n(LLMs) to combat the growing dissemination of disinformation. However, the\nperformance of LLMs varies across geographic regions. In this paper, we\nevaluate the factual accuracy of open and private models across a diverse set\nof regions and scenarios.\n  Using a dataset containing 600 fact-checked statements balanced across six\nglobal regions we examine three experimental setups of fact-checking a\nstatement: (1) when just the statement is available, (2) when an LLM-based\nagent with Wikipedia access is utilized, and (3) as a best case scenario when a\nRetrieval-Augmented Generation (RAG) system provided with the official fact\ncheck is employed. Our findings reveal that regardless of the scenario and LLM\nused, including GPT-4, Claude Sonnet, and LLaMA, statements from the Global\nNorth perform substantially better than those from the Global South.\nFurthermore, this gap is broadened for the more realistic case of a Wikipedia\nagent-based system, highlighting that overly general knowledge bases have a\nlimited ability to address region-specific nuances. These results underscore\nthe urgent need for better dataset balancing and robust retrieval strategies to\nenhance LLM fact-checking capabilities, particularly in geographically diverse\ncontexts.", "published": "2025-03-28 21:07:43", "link": "http://arxiv.org/abs/2503.22877v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Opioid Named Entity Recognition (ONER-2025) from Reddit", "abstract": "The opioid overdose epidemic remains a critical public health crisis,\nparticularly in the United States, leading to significant mortality and\nsocietal costs. Social media platforms like Reddit provide vast amounts of\nunstructured data that offer insights into public perceptions, discussions, and\nexperiences related to opioid use. This study leverages Natural Language\nProcessing (NLP), specifically Opioid Named Entity Recognition (ONER-2025), to\nextract actionable information from these platforms. Our research makes four\nkey contributions. First, we created a unique, manually annotated dataset\nsourced from Reddit, where users share self-reported experiences of opioid use\nvia different administration routes. This dataset contains 331,285 tokens and\nincludes eight major opioid entity categories. Second, we detail our annotation\nprocess and guidelines while discussing the challenges of labeling the\nONER-2025 dataset. Third, we analyze key linguistic challenges, including\nslang, ambiguity, fragmented sentences, and emotionally charged language, in\nopioid discussions. Fourth, we propose a real-time monitoring system to process\nstreaming data from social media, healthcare records, and emergency services to\nidentify overdose events. Using 5-fold cross-validation in 11 experiments, our\nsystem integrates machine learning, deep learning, and transformer-based\nlanguage models with advanced contextual embeddings to enhance understanding.\nOur transformer-based models (bert-base-NER and roberta-base) achieved 97%\naccuracy and F1-score, outperforming baselines by 10.23% (RF=0.88).", "published": "2025-03-28 20:51:06", "link": "http://arxiv.org/abs/2504.00027v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generating Synthetic Oracle Datasets to Analyze Noise Impact: A Study on Building Function Classification Using Tweets", "abstract": "Tweets provides valuable semantic context for earth observation tasks and\nserves as a complementary modality to remote sensing imagery. In building\nfunction classification (BFC), tweets are often collected using geographic\nheuristics and labeled via external databases, an inherently weakly supervised\nprocess that introduces both label noise and sentence level feature noise\n(e.g., irrelevant or uninformative tweets). While label noise has been widely\nstudied, the impact of sentence level feature noise remains underexplored,\nlargely due to the lack of clean benchmark datasets for controlled analysis. In\nthis work, we propose a method for generating a synthetic oracle dataset using\nLLM, designed to contain only tweets that are both correctly labeled and\nsemantically relevant to their associated buildings. This oracle dataset\nenables systematic investigation of noise impacts that are otherwise difficult\nto isolate in real-world data. To assess its utility, we compare model\nperformance using Naive Bayes and mBERT classifiers under three configurations:\nreal vs. synthetic training data, and cross-domain generalization. Results show\nthat noise in real tweets significantly degrades the contextual learning\ncapacity of mBERT, reducing its performance to that of a simple keyword-based\nmodel. In contrast, the clean synthetic dataset allows mBERT to learn\neffectively, outperforming Naive Bayes Bayes by a large margin. These findings\nhighlight that addressing feature noise is more critical than model complexity\nin this task. Our synthetic dataset offers a novel experimental environment for\nfuture noise injection studies and is publicly available on GitHub.", "published": "2025-03-28 20:18:28", "link": "http://arxiv.org/abs/2503.22856v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalization Bias in Large Language Model Summarization of Scientific Research", "abstract": "Artificial intelligence chatbots driven by large language models (LLMs) have\nthe potential to increase public science literacy and support scientific\nresearch, as they can quickly summarize complex scientific information in\naccessible terms. However, when summarizing scientific texts, LLMs may omit\ndetails that limit the scope of research conclusions, leading to\ngeneralizations of results broader than warranted by the original study. We\ntested 10 prominent LLMs, including ChatGPT-4o, ChatGPT-4.5, DeepSeek, LLaMA\n3.3 70B, and Claude 3.7 Sonnet, comparing 4900 LLM-generated summaries to their\noriginal scientific texts. Even when explicitly prompted for accuracy, most\nLLMs produced broader generalizations of scientific results than those in the\noriginal texts, with DeepSeek, ChatGPT-4o, and LLaMA 3.3 70B overgeneralizing\nin 26 to 73% of cases. In a direct comparison of LLM-generated and\nhuman-authored science summaries, LLM summaries were nearly five times more\nlikely to contain broad generalizations (OR = 4.85, 95% CI [3.06, 7.70]).\nNotably, newer models tended to perform worse in generalization accuracy than\nearlier ones. Our results indicate a strong bias in many widely used LLMs\ntowards overgeneralizing scientific conclusions, posing a significant risk of\nlarge-scale misinterpretations of research findings. We highlight potential\nmitigation strategies, including lowering LLM temperature settings and\nbenchmarking LLMs for generalization accuracy.", "published": "2025-03-28 19:23:41", "link": "http://arxiv.org/abs/2504.00025v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "L0-Reasoning Bench: Evaluating Procedural Correctness in Language Models via Simple Program Execution", "abstract": "Complex reasoning tasks often rely on the ability to consistently and\naccurately apply simple rules across incremental steps, a foundational\ncapability which we term \"level-0\" reasoning. To systematically evaluate this\ncapability, we introduce L0-Bench, a language model benchmark for testing\nprocedural correctness -- the ability to generate correct reasoning processes,\ncomplementing existing benchmarks that primarily focus on outcome correctness.\nGiven synthetic Python functions with simple operations, L0-Bench grades models\non their ability to generate step-by-step, error-free execution traces. The\nsynthetic nature of L0-Bench enables systematic and scalable generation of test\nprograms along various axes (e.g., number of trace steps). We evaluate a\ndiverse array of recent closed-source and open-weight models on a baseline test\nset. All models exhibit degradation as the number of target trace steps\nincreases, while larger models and reasoning-enhanced models better maintain\ncorrectness over multiple steps. Additionally, we use L0-Bench to explore\ntest-time scaling along three dimensions: input context length, number of\nsolutions for majority voting, and inference steps. Our results suggest\nsubstantial room to improve \"level-0\" reasoning and potential directions to\nbuild more reliable reasoning systems.", "published": "2025-03-28 18:54:56", "link": "http://arxiv.org/abs/2503.22832v1", "categories": ["cs.PL", "cs.CL"], "primary_category": "cs.PL"}
{"title": "Learning to Reason for Long-Form Story Generation", "abstract": "Generating high-quality stories spanning thousands of tokens requires\ncompetency across a variety of skills, from tracking plot and character arcs to\nkeeping a consistent and engaging style. Due to the difficulty of sourcing\nlabeled datasets and precise quality measurements, most work using large\nlanguage models (LLMs) for long-form story generation uses combinations of\nhand-designed prompting techniques to elicit author-like behavior. This is a\nmanual process that is highly dependent on the specific story-generation task.\nMotivated by the recent success of applying RL with Verifiable Rewards to\ndomains like math and coding, we propose a general story-generation task\n(Next-Chapter Prediction) and a reward formulation (Verified Rewards via\nCompletion Likelihood Improvement) that allows us to use an unlabeled book\ndataset as a learning signal for reasoning. We learn to reason over a story's\ncondensed information and generate a detailed plan for the next chapter. Our\nreasoning is evaluated via the chapters it helps a story-generator create, and\ncompared against non-trained and supervised finetuning (SFT) baselines.\nPairwise human judgments reveal the chapters our learned reasoning produces are\npreferred across almost all metrics, and the effect is more pronounced in Scifi\nand Fantasy genres.", "published": "2025-03-28 18:48:26", "link": "http://arxiv.org/abs/2503.22828v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions", "abstract": "In this work, we introduce MedAgentSim, an open-source simulated clinical\nenvironment with doctor, patient, and measurement agents designed to evaluate\nand enhance LLM performance in dynamic diagnostic settings. Unlike prior\napproaches, our framework requires doctor agents to actively engage with\npatients through multi-turn conversations, requesting relevant medical\nexaminations (e.g., temperature, blood pressure, ECG) and imaging results\n(e.g., MRI, X-ray) from a measurement agent to mimic the real-world diagnostic\nprocess. Additionally, we incorporate self improvement mechanisms that allow\nmodels to iteratively refine their diagnostic strategies. We enhance LLM\nperformance in our simulated setting by integrating multi-agent discussions,\nchain-of-thought reasoning, and experience-based knowledge retrieval,\nfacilitating progressive learning as doctor agents interact with more patients.\nWe also introduce an evaluation benchmark for assessing the LLM's ability to\nengage in dynamic, context-aware diagnostic interactions. While MedAgentSim is\nfully automated, it also supports a user-controlled mode, enabling human\ninteraction with either the doctor or patient agent. Comprehensive evaluations\nin various simulated diagnostic scenarios demonstrate the effectiveness of our\napproach. Our code, simulation tool, and benchmark are available at\n\\href{https://medagentsim.netlify.app/}.", "published": "2025-03-28 17:59:53", "link": "http://arxiv.org/abs/2503.22678v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation", "abstract": "Sequential Recommendation (SeqRec) aims to predict the next item by capturing\nsequential patterns from users' historical interactions, playing a crucial role\nin many real-world recommender systems. However, existing approaches\npredominantly adopt a direct forward computation paradigm, where the final\nhidden state of the sequence encoder serves as the user representation. We\nargue that this inference paradigm, due to its limited computational depth,\nstruggles to model the complex evolving nature of user preferences and lacks a\nnuanced understanding of long-tail items, leading to suboptimal performance. To\naddress this issue, we propose \\textbf{ReaRec}, the first inference-time\ncomputing framework for recommender systems, which enhances user\nrepresentations through implicit multi-step reasoning. Specifically, ReaRec\nautoregressively feeds the sequence's last hidden state into the sequential\nrecommender while incorporating special reasoning position embeddings to\ndecouple the original item encoding space from the multi-step reasoning space.\nMoreover, we introduce two lightweight reasoning-based learning methods,\nEnsemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to\nfurther effectively exploit ReaRec's reasoning potential. Extensive experiments\non five public real-world datasets and different SeqRec architectures\ndemonstrate the generality and effectiveness of our proposed ReaRec.\nRemarkably, post-hoc analyses reveal that ReaRec significantly elevates the\nperformance ceiling of multiple sequential recommendation backbones by\napproximately 30\\%-50\\%. Thus, we believe this work can open a new and\npromising avenue for future research in inference-time computing for sequential\nrecommendation.", "published": "2025-03-28 17:59:03", "link": "http://arxiv.org/abs/2503.22675v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?", "abstract": "Recently, a large amount of work has focused on improving large language\nmodels' (LLMs') performance on reasoning benchmarks such as math and logic.\nHowever, past work has largely assumed that tasks are well-defined. In the real\nworld, queries to LLMs are often underspecified, only solvable through\nacquiring missing information. We formalize this as a constraint satisfaction\nproblem (CSP) with missing variable assignments. Using a special case of this\nformalism where only one necessary variable assignment is missing, we can\nrigorously evaluate an LLM's ability to identify the minimal necessary question\nto ask and quantify axes of difficulty levels for each problem. We present\nQuestBench, a set of underspecified reasoning tasks solvable by asking at most\none question, which includes: (1) Logic-Q: Logical reasoning tasks with one\nmissing proposition, (2) Planning-Q: PDDL planning problems with initial states\nthat are partially-observed, (3) GSM-Q: Human-annotated grade school math\nproblems with one missing variable assignment, and (4) GSME-Q: a version of\nGSM-Q where word problems are translated into equations by human annotators.\nThe LLM is tasked with selecting the correct clarification question(s) from a\nlist of options. While state-of-the-art models excel at GSM-Q and GSME-Q, their\naccuracy is only 40-50% on Logic-Q and Planning-Q. Analysis demonstrates that\nthe ability to solve well-specified reasoning problems may not be sufficient\nfor success on our benchmark: models have difficulty identifying the right\nquestion to ask, even when they can solve the fully specified version of the\nproblem. Furthermore, in the Planning-Q domain, LLMs tend not to hedge, even\nwhen explicitly presented with the option to predict ``not sure.'' This\nhighlights the need for deeper investigation into models' information\nacquisition capabilities.", "published": "2025-03-28 17:58:40", "link": "http://arxiv.org/abs/2503.22674v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "ActionStudio: A Lightweight Framework for Data and Training of Large Action Models", "abstract": "Action models are essential for enabling autonomous agents to perform complex\ntasks. However, training large action models remains challenging due to the\ndiversity of agent environments and the complexity of agentic data. Despite\ngrowing interest, existing infrastructure provides limited support for\nscalable, agent-specific fine-tuning. We present ActionStudio, a lightweight\nand extensible data and training framework designed for large action models.\nActionStudio unifies heterogeneous agent trajectories through a standardized\nformat, supports diverse training paradigms including LoRA, full fine-tuning,\nand distributed setups, and integrates robust preprocessing and verification\ntools. We validate its effectiveness across both public and realistic industry\nbenchmarks, demonstrating strong performance and practical scalability. We\nopen-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to\nfacilitate research in the community.", "published": "2025-03-28 17:58:33", "link": "http://arxiv.org/abs/2503.22673v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Improving Applicability of Deep Learning based Token Classification models during Training", "abstract": "This paper shows that further evaluation metrics during model training are\nneeded to decide about its applicability in inference. As an example, a\nLayoutLM-based model is trained for token classification in documents. The\ndocuments are German receipts. We show that conventional classification\nmetrics, represented by the F1-Score in our experiments, are insufficient for\nevaluating the applicability of machine learning models in practice. To address\nthis problem, we introduce a novel metric, Document Integrity Precision (DIP),\nas a solution for visual document understanding and the token classification\ntask. To the best of our knowledge, nothing comparable has been introduced in\nthis context. DIP is a rigorous metric, describing how many documents of the\ntest dataset require manual interventions. It enables AI researchers and\nsoftware developers to conduct an in-depth investigation of the level of\nprocess automation in business software. In order to validate DIP, we conduct\nexperiments with our created models to highlight and analyze the impact and\nrelevance of DIP to evaluate if the model should be deployed or not in\ndifferent training settings. Our results demonstrate that existing metrics\nbarely change for isolated model impairments, whereas DIP indicates that the\nmodel requires substantial human interventions in deployment. The larger the\nset of entities being predicted, the less sensitive conventional metrics are,\nentailing poor automation quality. DIP, in contrast, remains a single value to\nbe interpreted for entire entity sets. This highlights the importance of having\nmetrics that focus on the business task for model training in production. Since\nDIP is created for the token classification task, more research is needed to\nfind suitable metrics for other training tasks.", "published": "2025-03-28 17:01:19", "link": "http://arxiv.org/abs/2504.01028v1", "categories": ["cs.CV", "cs.CL", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users", "abstract": "This paper explores the effectiveness of Multimodal Large Language models\n(MLLMs) as assistive technologies for visually impaired individuals. We conduct\na user survey to identify adoption patterns and key challenges users face with\nsuch technologies. Despite a high adoption rate of these models, our findings\nhighlight concerns related to contextual understanding, cultural sensitivity,\nand complex scene understanding, particularly for individuals who may rely\nsolely on them for visual interpretation. Informed by these results, we collate\nfive user-centred tasks with image and video inputs, including a novel task on\nOptical Braille Recognition. Our systematic evaluation of twelve MLLMs reveals\nthat further advancements are necessary to overcome limitations related to\ncultural context, multilingual support, Braille reading comprehension,\nassistive object recognition, and hallucinations. This work provides critical\ninsights into the future direction of multimodal AI for accessibility,\nunderscoring the need for more inclusive, robust, and trustworthy visual\nassistance technologies.", "published": "2025-03-28 16:54:25", "link": "http://arxiv.org/abs/2503.22610v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish", "abstract": "This study explores the use of large language models (LLMs) to enhance\ndatasets and improve irony detection in 19th-century Latin American newspapers.\nTwo strategies were employed to evaluate the efficacy of BERT and GPT-4o models\nin capturing the subtle nuances nature of irony, through both multi-class and\nbinary classification tasks. First, we implemented dataset enhancements focused\non enriching emotional and contextual cues; however, these showed limited\nimpact on historical language analysis. The second strategy, a semi-automated\nannotation process, effectively addressed class imbalance and augmented the\ndataset with high-quality annotations. Despite the challenges posed by the\ncomplexity of irony, this work contributes to the advancement of sentiment\nanalysis through two key contributions: introducing a new historical Spanish\ndataset tagged for sentiment analysis and irony detection, and proposing a\nsemi-automated annotation methodology where human expertise is crucial for\nrefining LLMs results, enriched by incorporating historical and cultural\ncontexts as core features.", "published": "2025-03-28 16:33:24", "link": "http://arxiv.org/abs/2503.22585v1", "categories": ["cs.CL", "cs.AI", "cs.DL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Beyond Vanilla Fine-Tuning: Leveraging Multistage, Multilingual, and Domain-Specific Methods for Low-Resource Machine Translation", "abstract": "Fine-tuning multilingual sequence-to-sequence large language models (msLLMs)\nhas shown promise in developing neural machine translation (NMT) systems for\nlow-resource languages (LRLs). However, conventional single-stage fine-tuning\nmethods struggle in extremely low-resource NMT settings, where training data is\nvery limited. This paper contributes to artificial intelligence by proposing\ntwo approaches for adapting msLLMs in these challenging scenarios: (1)\ncontinual pre-training (CPT), where the msLLM is further trained with\ndomain-specific monolingual data to compensate for the under-representation of\nLRLs, and (2) intermediate task transfer learning (ITTL), a method that\nfine-tunes the msLLM with both in-domain and out-of-domain parallel data to\nenhance its translation capabilities across various domains and tasks. As an\napplication in engineering, these methods are implemented in NMT systems for\nSinhala, Tamil, and English (six language pairs) in domain-specific, extremely\nlow-resource settings (datasets containing fewer than 100,000 samples). Our\nexperiments reveal that these approaches enhance translation performance by an\naverage of +1.47 bilingual evaluation understudy (BLEU) score compared to the\nstandard single-stage fine-tuning baseline across all translation directions.\nAdditionally, a multi-model ensemble further improves performance by an\nadditional BLEU score.", "published": "2025-03-28 16:30:28", "link": "http://arxiv.org/abs/2503.22582v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Breach in the Shield: Unveiling the Vulnerabilities of Large Language Models", "abstract": "Large Language Models (LLMs) and Vision-Language Models (VLMs) have become\nessential to general artificial intelligence, exhibiting remarkable\ncapabilities in task understanding and problem-solving. However, the real-world\nreliability of these models critically depends on their stability, which\nremains an underexplored area. Despite their widespread use, rigorous studies\nexamining the stability of LLMs under various perturbations are still lacking.\nIn this paper, we address this gap by proposing a novel stability measure for\nLLMs, inspired by statistical methods rooted in information geometry. Our\nmeasure possesses desirable invariance properties, making it well-suited for\nanalyzing model sensitivity to both parameter and input perturbations. To\nassess the effectiveness of our approach, we conduct extensive experiments on\nmodels ranging in size from 1.5B to 13B parameters. Our results demonstrate the\nutility of our measure in identifying salient parameters and detecting\nvulnerable regions in input images or critical dimensions in token embeddings.\nFurthermore, leveraging our stability framework, we enhance model robustness\nduring model merging, leading to improved performance.", "published": "2025-03-28 16:23:59", "link": "http://arxiv.org/abs/2504.03714v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Bridging the Dimensional Chasm: Uncover Layer-wise Dimensional Reduction in Transformers through Token Correlation", "abstract": "The geometric evolution of token representations in large language models\n(LLMs) presents a fundamental paradox: while human language inherently\norganizes semantic information in low-dimensional spaces ($\\sim 10^1$\ndimensions), modern LLMs employ high-dimensional embeddings ($\\sim 10^3$\ndimensions) processed through Transformer architectures. To resolve this\nparadox, this work bridges this conceptual gap by developing a geometric\nframework that tracks token dynamics across Transformers layers. Through\nlayer-wise analysis of intrinsic dimensions across multiple architectures, we\nreveal an expansion-contraction pattern where tokens diffuse to a \"working\nspace\" and then progressively project onto lower-dimensional submanifolds. Our\nfinding implies a negative correlation between the working space dimension and\nparameter-sensitive performance of the LLMs, and indicates that effective\nmodels tend to compress tokens into approximately 10-dimensional submanifolds,\nclosely resembling human semantic spaces. This work not only advances LLM\ninterpretability by reframing Transformers layers as projectors that mediate\nbetween high-dimensional computation and low-dimensional semantics, but also\nprovides practical tools for model diagnostics that do not rely on\ntask-specific evaluations.", "published": "2025-03-28 15:47:30", "link": "http://arxiv.org/abs/2503.22547v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploiting Mixture-of-Experts Redundancy Unlocks Multimodal Generative Abilities", "abstract": "In this work, we undertake the challenge of augmenting the existing\ngenerative capabilities of pre-trained text-only large language models (LLMs)\nwith multi-modal generation capability while satisfying two core constraints:\nC1 preserving the preservation of original language generative capabilities\nwith negligible performance degradation, and C2 adhering to a small parameter\nbudget to learn the new modality, ensuring scalability and efficiency. In\ncontrast to current approaches that add dedicated modules, thereby\nsignificantly increasing the parameter count, we propose a method that\nleverages the underutilized capacity inherent in deep models. Specifically, we\nexploit the parameter redundancy within Mixture-of-Experts (MoEs) as a source\nof additional capacity for learning a new modality, enabling better parameter\nefficiency (C1). Moreover, we preserve the original language generation\ncapabilities by applying low-rank adaptation exclusively to the tokens of the\nnew modality (C2). Furthermore, we introduce a novel parameter initialization\nscheme based on the Gromov-Wasserstein distance to improve convergence and\ntraining stability. Through an extensive analysis of the routing mechanism, we\nuncover the emergence of modality-specific pathways and decreased redundancy\nwithin the experts that can efficiently unlock multi-modal generative\ncapabilities. Overall, our method can be seamlessly applied to a wide range of\ncontemporary LLMs, providing a new pathway for transitioning from uni-modal to\nmulti-modal architectures.", "published": "2025-03-28 15:21:24", "link": "http://arxiv.org/abs/2503.22517v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "WorkTeam: Constructing Workflows from Natural Language with Multi-Agents", "abstract": "Workflows play a crucial role in enhancing enterprise efficiency by\norchestrating complex processes with multiple tools or components. However,\nhand-crafted workflow construction requires expert knowledge, presenting\nsignificant technical barriers. Recent advancements in Large Language Models\n(LLMs) have improved the generation of workflows from natural language\ninstructions (aka NL2Workflow), yet existing single LLM agent-based methods\nface performance degradation on complex tasks due to the need for specialized\nknowledge and the strain of task-switching. To tackle these challenges, we\npropose WorkTeam, a multi-agent NL2Workflow framework comprising a supervisor,\norchestrator, and filler agent, each with distinct roles that collaboratively\nenhance the conversion process. As there are currently no publicly available\nNL2Workflow benchmarks, we also introduce the HW-NL2Workflow dataset, which\nincludes 3,695 real-world business samples for training and evaluation.\nExperimental results show that our approach significantly increases the success\nrate of workflow construction, providing a novel and effective solution for\nenterprise NL2Workflow services.", "published": "2025-03-28 14:33:29", "link": "http://arxiv.org/abs/2503.22473v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey", "abstract": "This survey examines evaluation methods for large language model (LLM)-based\nagents in multi-turn conversational settings. Using a PRISMA-inspired\nframework, we systematically reviewed nearly 250 scholarly sources, capturing\nthe state of the art from various venues of publication, and establishing a\nsolid foundation for our analysis. Our study offers a structured approach by\ndeveloping two interrelated taxonomy systems: one that defines \\emph{what to\nevaluate} and another that explains \\emph{how to evaluate}. The first taxonomy\nidentifies key components of LLM-based agents for multi-turn conversations and\ntheir evaluation dimensions, including task completion, response quality, user\nexperience, memory and context retention, as well as planning and tool\nintegration. These components ensure that the performance of conversational\nagents is assessed in a holistic and meaningful manner. The second taxonomy\nsystem focuses on the evaluation methodologies. It categorizes approaches into\nannotation-based evaluations, automated metrics, hybrid strategies that combine\nhuman assessments with quantitative measures, and self-judging methods\nutilizing LLMs. This framework not only captures traditional metrics derived\nfrom language understanding, such as BLEU and ROUGE scores, but also\nincorporates advanced techniques that reflect the dynamic, interactive nature\nof multi-turn dialogues.", "published": "2025-03-28 14:08:40", "link": "http://arxiv.org/abs/2503.22458v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Scaling Laws in Scientific Discovery with AI and Robot Scientists", "abstract": "Scientific discovery is poised for rapid advancement through advanced\nrobotics and artificial intelligence. Current scientific practices face\nsubstantial limitations as manual experimentation remains time-consuming and\nresource-intensive, while multidisciplinary research demands knowledge\nintegration beyond individual researchers' expertise boundaries. Here, we\nenvision an autonomous generalist scientist (AGS) concept combines agentic AI\nand embodied robotics to automate the entire research lifecycle. This system\ncould dynamically interact with both physical and virtual environments while\nfacilitating the integration of knowledge across diverse scientific\ndisciplines. By deploying these technologies throughout every research stage --\nspanning literature review, hypothesis generation, experimentation, and\nmanuscript writing -- and incorporating internal reflection alongside external\nfeedback, this system aims to significantly reduce the time and resources\nneeded for scientific discovery. Building on the evolution from virtual AI\nscientists to versatile generalist AI-based robot scientists, AGS promises\ngroundbreaking potential. As these autonomous systems become increasingly\nintegrated into the research process, we hypothesize that scientific discovery\nmight adhere to new scaling laws, potentially shaped by the number and\ncapabilities of these autonomous systems, offering novel perspectives on how\nknowledge is generated and evolves. The adaptability of embodied robots to\nextreme environments, paired with the flywheel effect of accumulating\nscientific knowledge, holds the promise of continually pushing beyond both\nphysical and intellectual frontiers.", "published": "2025-03-28 14:00:27", "link": "http://arxiv.org/abs/2503.22444v2", "categories": ["cs.CL", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Long-Tail Crisis in Nearest Neighbor Language Models", "abstract": "The $k$-nearest-neighbor language model ($k$NN-LM), one of the\nretrieval-augmented language models, improves the perplexity for given text by\ndirectly accessing a large datastore built from any text data during inference.\nA widely held hypothesis for the success of $k$NN-LM is that its explicit\nmemory, i.e., the datastore, enhances predictions for long-tail phenomena.\nHowever, prior works have primarily shown its ability to retrieve long-tail\ncontexts, leaving the model's performance remain underexplored in estimating\nthe probabilities of long-tail target tokens during inference. In this paper,\nwe investigate the behavior of $k$NN-LM on low-frequency tokens, examining\nprediction probability, retrieval accuracy, token distribution in the\ndatastore, and approximation error of the product quantization. Our\nexperimental results reveal that $k$NN-LM does not improve prediction\nperformance for low-frequency tokens but mainly benefits high-frequency tokens\nregardless of long-tail contexts in the datastore.", "published": "2025-03-28 13:41:07", "link": "http://arxiv.org/abs/2503.22426v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoSIL: Software Issue Localization via LLM-Driven Code Repository Graph Searching", "abstract": "Large language models (LLMs) have significantly advanced autonomous software\nengineering, leading to a growing number of software engineering agents that\nassist developers in automatic program repair. Issue localization forms the\nbasis for accurate patch generation. However, because of limitations caused by\nthe context window length of LLMs, existing issue localization methods face\nchallenges in balancing concise yet effective contexts and adequately\ncomprehensive search spaces. In this paper, we introduce CoSIL, an LLM driven,\nsimple yet powerful function level issue localization method without training\nor indexing. CoSIL reduces the search space through module call graphs,\niteratively searches the function call graph to obtain relevant contexts, and\nuses context pruning to control the search direction and manage contexts\neffectively. Importantly, the call graph is dynamically constructed by the LLM\nduring search, eliminating the need for pre-parsing. Experiment results\ndemonstrate that CoSIL achieves a Top-1 localization success rate of 43 percent\nand 44.6 percent on SWE bench Lite and SWE bench Verified, respectively, using\nQwen2.5 Coder 32B, outperforming existing methods by 8.6 to 98.2 percent. When\nCoSIL is applied to guide the patch generation stage, the resolved rate further\nimproves by 9.3 to 31.5 percent.", "published": "2025-03-28 13:36:26", "link": "http://arxiv.org/abs/2503.22424v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Elite Political Discourse has Become More Toxic in Western Countries", "abstract": "Toxic and uncivil politics is widely seen as a growing threat to democratic\nvalues and governance, yet our understanding of the drivers and evolution of\npolitical incivility remains limited. Leveraging a novel dataset of nearly 18\nmillion Twitter messages from parliamentarians in 17 countries over five years,\nthis paper systematically investigates whether politics internationally is\nbecoming more uncivil, and what are the determinants of political incivility.\nOur analysis reveals a marked increase in toxic discourse among political\nelites, and that it is associated to radical-right parties and parties in\nopposition. Toxicity diminished markedly during the early phase of the COVID-19\npandemic and, surprisingly, during election campaigns. Furthermore, our results\nindicate that posts relating to ``culture war'' topics, such as migration and\nLGBTQ+ rights, are substantially more toxic than debates focused on welfare or\neconomic issues. These findings underscore a troubling shift in international\ndemocracies toward an erosion of constructive democratic dialogue.", "published": "2025-03-28 13:21:49", "link": "http://arxiv.org/abs/2503.22411v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EllieSQL: Cost-Efficient Text-to-SQL with Complexity-Aware Routing", "abstract": "Text-to-SQL automatically translates natural language queries to SQL,\nallowing non-technical users to retrieve data from databases without\nspecialized SQL knowledge. Despite the success of advanced LLM-based\nText-to-SQL approaches on leaderboards, their unsustainable computational\ncosts--often overlooked--stand as the \"elephant in the room\" in current\nleaderboard-driven research, limiting their economic practicability for\nreal-world deployment and widespread adoption. To tackle this, we exploratively\npropose EllieSQL, a complexity-aware routing framework that assigns queries to\nsuitable SQL generation pipelines based on estimated complexity. We investigate\nmultiple routers to direct simple queries to efficient approaches while\nreserving computationally intensive methods for complex cases. Drawing from\neconomics, we introduce the Token Elasticity of Performance (TEP) metric,\ncapturing cost-efficiency by quantifying the responsiveness of performance\ngains relative to token investment in SQL generation. Experiments show that\ncompared to always using the most advanced methods in our study, EllieSQL with\nthe Qwen2.5-0.5B-DPO router reduces token use by over 40% without compromising\nperformance on Bird development set, achieving more than a 2x boost in TEP over\nnon-routing approaches. This not only advances the pursuit of cost-efficient\nText-to-SQL but also invites the community to weigh resource efficiency\nalongside performance, contributing to progress in sustainable Text-to-SQL.", "published": "2025-03-28 13:11:27", "link": "http://arxiv.org/abs/2503.22402v1", "categories": ["cs.DB", "cs.AI", "cs.CL"], "primary_category": "cs.DB"}
{"title": "Negation: A Pink Elephant in the Large Language Models' Room?", "abstract": "Negations are key to determining sentence meaning, making them essential for\nlogical reasoning. Despite their importance, negations pose a substantial\nchallenge for large language models (LLMs) and remain underexplored.\n  We construct two multilingual natural language inference (NLI) datasets with\n\\textit{paired} examples differing in negation. We investigate how model size\nand language impact its ability to handle negation correctly by evaluating\npopular LLMs.\n  Contrary to previous work, we show that increasing the model size\nconsistently improves the models' ability to handle negations. Furthermore, we\nfind that both the models' reasoning accuracy and robustness to negation are\nlanguage-dependent and that the length and explicitness of the premise have a\ngreater impact on robustness than language.\n  Our datasets can facilitate further research and improvements of language\nmodel reasoning in multilingual settings.", "published": "2025-03-28 13:04:41", "link": "http://arxiv.org/abs/2503.22395v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Why Stop at One Error? Benchmarking LLMs as Data Science Code Debuggers for Multi-Hop and Multi-Bug Errors", "abstract": "LLMs are transforming software development, yet current code generation and\ncode repair benchmarks mainly assess syntactic and functional correctness in\nsimple, single-error cases. LLMs' capabilities to autonomously find and fix\nruntime logical errors in complex data science code remain largely unexplored.\nTo address this gap, we introduce DSDBench: the Data Science Debugging\nBenchmark, the first benchmark for systematic evaluation of LLMs on multi-hop\nerror tracing and multi-bug detection in data science code debugging. DSDBench\nadapts datasets from existing data science task benchmarks, such as DABench and\nMatPlotBench, featuring realistic data science debugging tasks with\nautomatically synthesized multi-hop, multi-bug code snippets. DSDBench includes\n1,117 annotated samples with 741 cause-effect error pairs and runtime error\nmessages. Evaluations of state-of-the-art LLMs on DSDBench show significant\nperformance gaps, highlighting challenges in debugging logical runtime errors\nin data science code. DSDBench offers a crucial resource to evaluate and\nimprove LLMs' debugging and reasoning capabilities, enabling more reliable\nAI-assisted data science in the future.DSDBench is publicly available at\nhttps://github.com/KevinCL16/DSDBench.", "published": "2025-03-28 12:46:54", "link": "http://arxiv.org/abs/2503.22388v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Spend Your Budget Wisely: Towards an Intelligent Distribution of the Privacy Budget in Differentially Private Text Rewriting", "abstract": "The task of $\\textit{Differentially Private Text Rewriting}$ is a class of\ntext privatization techniques in which (sensitive) input textual documents are\n$\\textit{rewritten}$ under Differential Privacy (DP) guarantees. The motivation\nbehind such methods is to hide both explicit and implicit identifiers that\ncould be contained in text, while still retaining the semantic meaning of the\noriginal text, thus preserving utility. Recent years have seen an uptick in\nresearch output in this field, offering a diverse array of word-, sentence-,\nand document-level DP rewriting methods. Common to these methods is the\nselection of a privacy budget (i.e., the $\\varepsilon$ parameter), which\ngoverns the degree to which a text is privatized. One major limitation of\nprevious works, stemming directly from the unique structure of language itself,\nis the lack of consideration of $\\textit{where}$ the privacy budget should be\nallocated, as not all aspects of language, and therefore text, are equally\nsensitive or personal. In this work, we are the first to address this\nshortcoming, asking the question of how a given privacy budget can be\nintelligently and sensibly distributed amongst a target document. We construct\nand evaluate a toolkit of linguistics- and NLP-based methods used to allocate a\nprivacy budget to constituent tokens in a text document. In a series of privacy\nand utility experiments, we empirically demonstrate that given the same privacy\nbudget, intelligent distribution leads to higher privacy levels and more\npositive trade-offs than a naive distribution of $\\varepsilon$. Our work\nhighlights the intricacies of text privatization with DP, and furthermore, it\ncalls for further work on finding more efficient ways to maximize the\nprivatization benefits offered by DP in text rewriting.", "published": "2025-03-28 12:33:46", "link": "http://arxiv.org/abs/2503.22379v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Supposedly Equivalent Facts That Aren't? Entity Frequency in Pre-training Induces Asymmetry in LLMs", "abstract": "Understanding and mitigating hallucinations in Large Language Models (LLMs)\nis crucial for ensuring reliable content generation. While previous research\nhas primarily focused on \"when\" LLMs hallucinate, our work explains \"why\" and\ndirectly links model behaviour to the pre-training data that forms their prior\nknowledge. Specifically, we demonstrate that an asymmetry exists in the\nrecognition of logically equivalent facts, which can be attributed to frequency\ndiscrepancies of entities appearing as subjects versus objects. Given that most\npre-training datasets are inaccessible, we leverage the fully open-source OLMo\nseries by indexing its Dolma dataset to estimate entity frequencies. Using\nrelational facts (represented as triples) from Wikidata5M, we construct probing\ndatasets to isolate this effect. Our experiments reveal that facts with a\nhigh-frequency subject and a low-frequency object are better recognised than\ntheir inverse, despite their logical equivalence. The pattern reverses in\nlow-to-high frequency settings, and no statistically significant asymmetry\nemerges when both entities are high-frequency. These findings highlight the\ninfluential role of pre-training data in shaping model predictions and provide\ninsights for inferring the characteristics of pre-training data in closed or\npartially closed LLMs.", "published": "2025-03-28 12:12:38", "link": "http://arxiv.org/abs/2503.22362v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Firm or Fickle? Evaluating Large Language Models Consistency in Sequential Interactions", "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious tasks, but their deployment in high-stake domains requires consistent\nperformance across multiple interaction rounds. This paper introduces a\ncomprehensive framework for evaluating and improving LLM response consistency,\nmaking three key contributions. First, we propose a novel Position-Weighted\nConsistency (PWC) score that captures both the importance of early-stage\nstability and recovery patterns in multi-turn interactions. Second, we present\na carefully curated benchmark dataset spanning diverse domains and difficulty\nlevels, specifically designed to evaluate LLM consistency under various\nchallenging follow-up scenarios. Third, we introduce Confidence-Aware Response\nGeneration (CARG), a framework that significantly improves response stability\nby incorporating model confidence signals into the generation process.\nEmpirical results demonstrate that CARG significantly improves response\nstability without sacrificing accuracy, underscoring its potential for reliable\nLLM deployment in critical applications.", "published": "2025-03-28 11:49:56", "link": "http://arxiv.org/abs/2503.22353v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SKDU at De-Factify 4.0: Natural Language Features for AI-Generated Text-Detection", "abstract": "The rapid advancement of large language models (LLMs) has introduced new\nchallenges in distinguishing human-written text from AI-generated content. In\nthis work, we explored a pipelined approach for AI-generated text detection\nthat includes a feature extraction step (i.e. prompt-based rewriting features\ninspired by RAIDAR and content-based features derived from the NELA toolkit)\nfollowed by a classification module. Comprehensive experiments were conducted\non the Defactify4.0 dataset, evaluating two tasks: binary classification to\ndifferentiate human-written and AI-generated text, and multi-class\nclassification to identify the specific generative model used to generate the\ninput text. Our findings reveal that NELA features significantly outperform\nRAIDAR features in both tasks, demonstrating their ability to capture nuanced\nlinguistic, stylistic, and content-based differences. Combining RAIDAR and NELA\nfeatures provided minimal improvement, highlighting the redundancy introduced\nby less discriminative features. Among the classifiers tested, XGBoost emerged\nas the most effective, leveraging the rich feature sets to achieve high\naccuracy and generalisation.", "published": "2025-03-28 11:25:05", "link": "http://arxiv.org/abs/2503.22338v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Refined Analysis of Massive Activations in LLMs", "abstract": "Motivated in part by their relevance for low-precision training and\nquantization, massive activations in large language models (LLMs) have recently\nemerged as a topic of interest. However, existing analyses are limited in\nscope, and generalizability across architectures is unclear. This paper helps\naddress some of these gaps by conducting an analysis of massive activations\nacross a broad range of LLMs, including both GLU-based and non-GLU-based\narchitectures. Our findings challenge several prior assumptions, most\nimportantly: (1) not all massive activations are detrimental, i.e. suppressing\nthem does not lead to an explosion of perplexity or a collapse in downstream\ntask performance; (2) proposed mitigation strategies such as Attention KV bias\nare model-specific and ineffective in certain cases. We consequently\ninvestigate novel hybrid mitigation strategies; in particular pairing Target\nVariance Rescaling (TVR) with Attention KV bias or Dynamic Tanh (DyT)\nsuccessfully balances the mitigation of massive activations with preserved\ndownstream model performance in the scenarios we investigated. Our code is\navailable at: https://github.com/bluorion-com/refine_massive_activations.", "published": "2025-03-28 11:08:34", "link": "http://arxiv.org/abs/2503.22329v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Preference-based Learning with Retrieval Augmented Generation for Conversational Question Answering", "abstract": "Conversational Question Answering (ConvQA) involves multiple subtasks, i) to\nunderstand incomplete questions in their context, ii) to retrieve relevant\ninformation, and iii) to generate answers. This work presents PRAISE, a\npipeline-based approach for ConvQA that trains LLM adapters for each of the\nthree subtasks. As labeled training data for individual subtasks is unavailable\nin practice, PRAISE learns from its own generations using the final answering\nperformance as feedback signal without human intervention and treats\nintermediate information, like relevant evidence, as weakly labeled data. We\napply Direct Preference Optimization by contrasting successful and unsuccessful\nsamples for each subtask. In our experiments, we show the effectiveness of this\ntraining paradigm: PRAISE shows improvements per subtask and achieves new\nstate-of-the-art performance on a popular ConvQA benchmark, by gaining 15.5\npercentage points increase in precision over baselines.", "published": "2025-03-28 10:26:49", "link": "http://arxiv.org/abs/2503.22303v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "MultiClaimNet: A Massively Multilingual Dataset of Fact-Checked Claim Clusters", "abstract": "In the context of fact-checking, claims are often repeated across various\nplatforms and in different languages, which can benefit from a process that\nreduces this redundancy. While retrieving previously fact-checked claims has\nbeen investigated as a solution, the growing number of unverified claims and\nexpanding size of fact-checked databases calls for alternative, more efficient\nsolutions. A promising solution is to group claims that discuss the same\nunderlying facts into clusters to improve claim retrieval and validation.\nHowever, research on claim clustering is hindered by the lack of suitable\ndatasets. To bridge this gap, we introduce \\textit{MultiClaimNet}, a collection\nof three multilingual claim cluster datasets containing claims in 86 languages\nacross diverse topics. Claim clusters are formed automatically from\nclaim-matching pairs with limited manual intervention. We leverage two existing\nclaim-matching datasets to form the smaller datasets within\n\\textit{MultiClaimNet}. To build the larger dataset, we propose and validate an\napproach involving retrieval of approximate nearest neighbors to form candidate\nclaim pairs and an automated annotation of claim similarity using large\nlanguage models. This larger dataset contains 85.3K fact-checked claims written\nin 78 languages. We further conduct extensive experiments using various\nclustering techniques and sentence embedding models to establish baseline\nperformance. Our datasets and findings provide a strong foundation for scalable\nclaim clustering, contributing to efficient fact-checking pipelines.", "published": "2025-03-28 09:49:45", "link": "http://arxiv.org/abs/2503.22280v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CFiCS: Graph-Based Classification of Common Factors and Microcounseling Skills", "abstract": "Common factors and microcounseling skills are critical to the effectiveness\nof psychotherapy. Understanding and measuring these elements provides valuable\ninsights into therapeutic processes and outcomes. However, automatic\nidentification of these change principles from textual data remains challenging\ndue to the nuanced and context-dependent nature of therapeutic dialogue. This\npaper introduces CFiCS, a hierarchical classification framework integrating\ngraph machine learning with pretrained contextual embeddings. We represent\ncommon factors, intervention concepts, and microcounseling skills as a\nheterogeneous graph, where textual information from ClinicalBERT enriches each\nnode. This structure captures both the hierarchical relationships (e.g.,\nskill-level nodes linking to broad factors) and the semantic properties of\ntherapeutic concepts. By leveraging graph neural networks, CFiCS learns\ninductive node embeddings that generalize to unseen text samples lacking\nexplicit connections. Our results demonstrate that integrating ClinicalBERT\nnode features and graph structure significantly improves classification\nperformance, especially in fine-grained skill prediction. CFiCS achieves\nsubstantial gains in both micro and macro F1 scores across all tasks compared\nto baselines, including random forests, BERT-based multi-task models, and\ngraph-based methods.", "published": "2025-03-28 09:46:08", "link": "http://arxiv.org/abs/2503.22277v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Process Reward Modeling with Entropy-Driven Uncertainty", "abstract": "This paper presents the Entropy-Driven Unified Process Reward Model\n(EDU-PRM), a novel framework that approximates state-of-the-art performance in\nprocess supervision while drastically reducing training costs. EDU-PRM\nintroduces an entropy-guided dynamic step partitioning mechanism, using logit\ndistribution entropy to pinpoint high-uncertainty regions during token\ngeneration dynamically. This self-assessment capability enables precise\nstep-level feedback without manual fine-grained annotation, addressing a\ncritical challenge in process supervision. Experiments on the Qwen2.5-72B model\nwith only 7,500 EDU-PRM-generated training queries demonstrate accuracy closely\napproximating the full Qwen2.5-72B-PRM (71.1% vs. 71.6%), achieving a 98%\nreduction in query cost compared to prior methods. This work establishes\nEDU-PRM as an efficient approach for scalable process reward model training.", "published": "2025-03-28 08:33:37", "link": "http://arxiv.org/abs/2503.22233v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Learning to Instruct for Visual Instruction Tuning", "abstract": "We propose LIT, an advancement of visual instruction tuning (VIT). While VIT\nequips Multimodal LLMs (MLLMs) with promising multimodal capabilities, the\ncurrent design choices for VIT often result in overfitting and shortcut\nlearning, potentially degrading performance. This gap arises from an\noveremphasis on instruction-following abilities, while neglecting the proactive\nunderstanding of visual information. Inspired by this, LIT adopts a simple yet\neffective approach by incorporating the loss function into both the instruction\nand response sequences. It seamlessly expands the training data, and\nregularizes the MLLMs from overly relying on language priors. Based on this\nmerit, LIT achieves a significant relative improvement of up to 9% on\ncomprehensive multimodal benchmarks, requiring no additional training data and\nincurring negligible computational overhead. Surprisingly, LIT attains\nexceptional fundamental visual capabilities, yielding up to an 18% improvement\nin captioning performance, while simultaneously alleviating hallucination in\nMLLMs.", "published": "2025-03-28 08:04:51", "link": "http://arxiv.org/abs/2503.22215v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "EdgeInfinite: A Memory-Efficient Infinite-Context Transformer for Edge Devices", "abstract": "Transformer-based large language models (LLMs) encounter challenges in\nprocessing long sequences on edge devices due to the quadratic complexity of\nattention mechanisms and growing memory demands from Key-Value (KV) cache.\nExisting KV cache optimizations struggle with irreversible token eviction in\nlong-output tasks, while alternative sequence modeling architectures prove\ncostly to adopt within established Transformer infrastructure. We present\nEdgeInfinite, a memory-efficient solution for infinite contexts that integrates\ncompressed memory into Transformer-based LLMs through a trainable memory-gating\nmodule. This approach maintains full compatibility with standard Transformer\narchitectures, requiring fine-tuning only a small part of parameters, and\nenables selective activation of the memory-gating module for long and short\ncontext task routing. The experimental result shows that EdgeInfinite achieves\ncomparable performance to baseline Transformer-based LLM on long context\nbenchmarks while optimizing memory consumption and time to first token.", "published": "2025-03-28 07:26:37", "link": "http://arxiv.org/abs/2503.22196v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FUSE : A Ridge and Random Forest-Based Metric for Evaluating MT in Indigenous Languages", "abstract": "This paper presents the winning submission of the RaaVa team to the\nAmericasNLP 2025 Shared Task 3 on Automatic Evaluation Metrics for Machine\nTranslation (MT) into Indigenous Languages of America, where our system ranked\nfirst overall based on average Pearson correlation with the human annotations.\nWe introduce Feature-Union Scorer (FUSE) for Evaluation, FUSE integrates Ridge\nregression and Gradient Boosting to model translation quality. In addition to\nFUSE, we explore five alternative approaches leveraging different combinations\nof linguistic similarity features and learning paradigms. FUSE Score highlights\nthe effectiveness of combining lexical, phonetic, semantic, and fuzzy token\nsimilarity with learning-based modeling to improve MT evaluation for\nmorphologically rich and low-resource languages. MT into Indigenous languages\nposes unique challenges due to polysynthesis, complex morphology, and\nnon-standardized orthography. Conventional automatic metrics such as BLEU, TER,\nand ChrF often fail to capture deeper aspects like semantic adequacy and\nfluency. Our proposed framework, formerly referred to as FUSE, incorporates\nmultilingual sentence embeddings and phonological encodings to better align\nwith human evaluation. We train supervised models on human-annotated\ndevelopment sets and evaluate held-out test data. Results show that FUSE\nconsistently achieves higher Pearson and Spearman correlations with human\njudgments, offering a robust and linguistically informed solution for MT\nevaluation in low-resource settings.", "published": "2025-03-28 06:58:55", "link": "http://arxiv.org/abs/2504.00021v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tokenization of Gaze Data", "abstract": "A considerable part of the performance of today's large language models\n(LLM's) and multimodal large language models (MLLM's) depends on their\ntokenization strategies. While tokenizers are extensively researched for\ntextual and visual input, there is no research on tokenization strategies for\ngaze data due to its nature. However, a corresponding tokenization strategy\nwould allow using the vision capabilities of pre-trained MLLM's for gaze data,\nfor example, through fine-tuning.\n  In this paper, we aim to close this research gap by analyzing five different\ntokenizers for gaze data on three different datasets for the forecasting and\ngeneration of gaze data through LLMs (cf.~\\cref{fig:teaser}). We evaluate the\ntokenizers regarding their reconstruction and compression abilities. Further,\nwe train an LLM for each tokenization strategy, measuring its generative and\npredictive performance. Overall, we found that a quantile tokenizer outperforms\nall others in predicting the gaze positions and k-means is best when predicting\ngaze velocities.", "published": "2025-03-28 04:41:09", "link": "http://arxiv.org/abs/2503.22145v1", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.LG"}
{"title": "FRASE: Structured Representations for Generalizable SPARQL Query Generation", "abstract": "Translating natural language questions into SPARQL queries enables Knowledge\nBase querying for factual and up-to-date responses. However, existing datasets\nfor this task are predominantly template-based, leading models to learn\nsuperficial mappings between question and query templates rather than\ndeveloping true generalization capabilities. As a result, models struggle when\nencountering naturally phrased, template-free questions. This paper introduces\nFRASE (FRAme-based Semantic Enhancement), a novel approach that leverages Frame\nSemantic Role Labeling (FSRL) to address this limitation. We also present\nLC-QuAD 3.0, a new dataset derived from LC-QuAD 2.0, in which each question is\nenriched using FRASE through frame detection and the mapping of frame-elements\nto their argument. We evaluate the impact of this approach through extensive\nexperiments on recent large language models (LLMs) under different fine-tuning\nconfigurations. Our results demonstrate that integrating frame-based structured\nrepresentations consistently improves SPARQL generation performance,\nparticularly in challenging generalization scenarios when test questions\nfeature unseen templates (unknown template splits) and when they are all\nnaturally phrased (reformulated questions).", "published": "2025-03-28 04:39:52", "link": "http://arxiv.org/abs/2503.22144v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Convolutional optimization with convex kernel and power lift", "abstract": "We focus on establishing the foundational paradigm of a novel optimization\ntheory based on convolution with convex kernels. Our goal is to devise a\nmorally deterministic model of locating the global optima of an arbitrary\nfunction, which is distinguished from most commonly used statistical models.\nLimited preliminary numerical results are provided to test the efficiency of\nsome specific algorithms derived from our paradigm, which we hope to stimulate\nfurther practical interest.", "published": "2025-03-28 04:19:16", "link": "http://arxiv.org/abs/2503.22135v1", "categories": ["math.OC", "cs.CE", "cs.CL"], "primary_category": "math.OC"}
{"title": "REMAC: Self-Reflective and Self-Evolving Multi-Agent Collaboration for Long-Horizon Robot Manipulation", "abstract": "Vision-language models (VLMs) have demonstrated remarkable capabilities in\nrobotic planning, particularly for long-horizon tasks that require a holistic\nunderstanding of the environment for task decomposition. Existing methods\ntypically rely on prior environmental knowledge or carefully designed\ntask-specific prompts, making them struggle with dynamic scene changes or\nunexpected task conditions, e.g., a robot attempting to put a carrot in the\nmicrowave but finds the door was closed. Such challenges underscore two\ncritical issues: adaptability and efficiency. To address them, in this work, we\npropose an adaptive multi-agent planning framework, termed REMAC, that enables\nefficient, scene-agnostic multi-robot long-horizon task planning and execution\nthrough continuous reflection and self-evolution. REMAC incorporates two key\nmodules: a self-reflection module performing pre-condition and post-condition\nchecks in the loop to evaluate progress and refine plans, and a self-evolvement\nmodule dynamically adapting plans based on scene-specific reasoning. It offers\nseveral appealing benefits: 1) Robots can initially explore and reason about\nthe environment without complex prompt design. 2) Robots can keep reflecting on\npotential planning errors and adapting the plan based on task-specific\ninsights. 3) After iterations, a robot can call another one to coordinate tasks\nin parallel, maximizing the task execution efficiency. To validate REMAC's\neffectiveness, we build a multi-agent environment for long-horizon robot\nmanipulation and navigation based on RoboCasa, featuring 4 task categories with\n27 task styles and 50+ different objects. Based on it, we further benchmark\nstate-of-the-art reasoning models, including DeepSeek-R1, o3-mini, QwQ, and\nGrok3, demonstrating REMAC's superiority by boosting average success rates by\n40% and execution efficiency by 52.7% over the single robot baseline.", "published": "2025-03-28 03:51:40", "link": "http://arxiv.org/abs/2503.22122v1", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Beyond Single-Sentence Prompts: Upgrading Value Alignment Benchmarks with Dialogues and Stories", "abstract": "Evaluating the value alignment of large language models (LLMs) has\ntraditionally relied on single-sentence adversarial prompts, which directly\nprobe models with ethically sensitive or controversial questions. However, with\nthe rapid advancements in AI safety techniques, models have become increasingly\nadept at circumventing these straightforward tests, limiting their\neffectiveness in revealing underlying biases and ethical stances. To address\nthis limitation, we propose an upgraded value alignment benchmark that moves\nbeyond single-sentence prompts by incorporating multi-turn dialogues and\nnarrative-based scenarios. This approach enhances the stealth and adversarial\nnature of the evaluation, making it more robust against superficial safeguards\nimplemented in modern LLMs. We design and implement a dataset that includes\nconversational traps and ethically ambiguous storytelling, systematically\nassessing LLMs' responses in more nuanced and context-rich settings.\nExperimental results demonstrate that this enhanced methodology can effectively\nexpose latent biases that remain undetected in traditional single-shot\nevaluations. Our findings highlight the necessity of contextual and dynamic\ntesting for value alignment in LLMs, paving the way for more sophisticated and\nrealistic assessments of AI ethics and safety.", "published": "2025-03-28 03:31:37", "link": "http://arxiv.org/abs/2503.22115v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Few-Shot Graph Out-of-Distribution Detection with LLMs", "abstract": "Existing methods for graph out-of-distribution (OOD) detection typically\ndepend on training graph neural network (GNN) classifiers using a substantial\namount of labeled in-distribution (ID) data. However, acquiring high-quality\nlabeled nodes in text-attributed graphs (TAGs) is challenging and costly due to\ntheir complex textual and structural characteristics. Large language models\n(LLMs), known for their powerful zero-shot capabilities in textual tasks, show\npromise but struggle to naturally capture the critical structural information\ninherent to TAGs, limiting their direct effectiveness.\n  To address these challenges, we propose LLM-GOOD, a general framework that\neffectively combines the strengths of LLMs and GNNs to enhance data efficiency\nin graph OOD detection. Specifically, we first leverage LLMs' strong zero-shot\ncapabilities to filter out likely OOD nodes, significantly reducing the human\nannotation burden. To minimize the usage and cost of the LLM, we employ it only\nto annotate a small subset of unlabeled nodes. We then train a lightweight GNN\nfilter using these noisy labels, enabling efficient predictions of ID status\nfor all other unlabeled nodes by leveraging both textual and structural\ninformation. After obtaining node embeddings from the GNN filter, we can apply\ninformativeness-based methods to select the most valuable nodes for precise\nhuman annotation. Finally, we train the target ID classifier using these\naccurately annotated ID nodes. Extensive experiments on four real-world TAG\ndatasets demonstrate that LLM-GOOD significantly reduces human annotation costs\nand outperforms state-of-the-art baselines in terms of both ID classification\naccuracy and OOD detection performance.", "published": "2025-03-28 02:37:18", "link": "http://arxiv.org/abs/2503.22097v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Leveraging LLMs for Predicting Unknown Diagnoses from Clinical Notes", "abstract": "Electronic Health Records (EHRs) often lack explicit links between\nmedications and diagnoses, making clinical decision-making and research more\ndifficult. Even when links exist, diagnosis lists may be incomplete, especially\nduring early patient visits. Discharge summaries tend to provide more complete\ninformation, which can help infer accurate diagnoses, especially with the help\nof large language models (LLMs). This study investigates whether LLMs can\npredict implicitly mentioned diagnoses from clinical notes and link them to\ncorresponding medications. We address two research questions: (1) Does majority\nvoting across diverse LLM configurations outperform the best single\nconfiguration in diagnosis prediction? (2) How sensitive is majority voting\naccuracy to LLM hyperparameters such as temperature, top-p, and summary length?\nTo evaluate, we created a new dataset of 240 expert-annotated\nmedication-diagnosis pairs from 20 MIMIC-IV notes. Using GPT-3.5 Turbo, we ran\n18 prompting configurations across short and long summary lengths, generating\n8568 test cases. Results show that majority voting achieved 75 percent\naccuracy, outperforming the best single configuration at 66 percent. No single\nhyperparameter setting dominated, but combining deterministic, balanced, and\nexploratory strategies improved performance. Shorter summaries generally led to\nhigher accuracy.In conclusion, ensemble-style majority voting with diverse LLM\nconfigurations improves diagnosis prediction in EHRs and offers a promising\nmethod to link medications and diagnoses in clinical texts.", "published": "2025-03-28 02:15:57", "link": "http://arxiv.org/abs/2503.22092v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Penrose Tiled Low-Rank Compression and Section-Wise Q&A Fine-Tuning: A General Framework for Domain-Specific Large Language Model Adaptation", "abstract": "Large language models (LLMs) hold great promise for specialized scientific\ndomains such as materials science, yet adapting them efficiently and accurately\nto domain-specific knowledge remains challenging due to limited data and high\nknowledge density. We propose a two-stage framework that combines structured\nmodel compression with a scientific fine-tuning regimen to address this\nchallenge. In the compression stage, we decompose the LLM's weight matrices\ninto local low-rank \"rank blocks\" and arrange these blocks in a Penrose-like\nnon-periodic tiling pattern. Each block is then compacted via spectral\ntransformations (e.g., discrete cosine or Fourier transforms), and a\nKullback-Leibler (KL) divergence-based alignment loss preserves the\ndistributional similarity between the compressed model's representations and\nthose of the original full model. In the adaptation stage, the compressed model\nis further tuned using a human-like scientific reading protocol: it processes\ntechnical materials science documents section by section, engaging in a\nstructured question-and-answer routine for each section. This section-wise Q&A\nfine-tuning strategy extracts explicit reasoning traces and gradually injects\ndomain knowledge, while minimizing catastrophic forgetting of the model's\ngeneral language capabilities. By balancing efficient compression with targeted\nadaptation, our two-stage approach enables precise specialization of LLMs to\nhigh-value domains under data-scarce conditions. We present this principled yet\nexploratory pipeline and outline its potential for advancing materials science\nknowledge integration, laying the groundwork for comprehensive empirical\nevaluation in future work.", "published": "2025-03-28 01:33:05", "link": "http://arxiv.org/abs/2503.22074v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Non-Monotonic Attention-based Read/Write Policy Learning for Simultaneous Translation", "abstract": "Simultaneous or streaming machine translation generates translation while\nreading the input stream. These systems face a quality/latency trade-off,\naiming to achieve high translation quality similar to non-streaming models with\nminimal latency. We propose an approach that efficiently manages this\ntrade-off. By enhancing a pretrained non-streaming model, which was trained\nwith a seq2seq mechanism and represents the upper bound in quality, we convert\nit into a streaming model by utilizing the alignment between source and target\ntokens. This alignment is used to learn a read/write decision boundary for\nreliable translation generation with minimal input. During training, the model\nlearns the decision boundary through a read/write policy module, employing\nsupervised learning on the alignment points (pseudo labels). The read/write\npolicy module, a small binary classification unit, can control the\nquality/latency trade-off during inference. Experimental results show that our\nmodel outperforms several strong baselines and narrows the gap with the\nnon-streaming baseline model.", "published": "2025-03-28 00:00:33", "link": "http://arxiv.org/abs/2503.22051v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing DeepLabV3+ to Fuse Aerial and Satellite Images for Semantic Segmentation", "abstract": "Aerial and satellite imagery are inherently complementary remote sensing\nsources, offering high-resolution detail alongside expansive spatial coverage.\nHowever, the use of these sources for land cover segmentation introduces\nseveral challenges, prompting the development of a variety of segmentation\nmethods. Among these approaches, the DeepLabV3+ architecture is considered as a\npromising approach in the field of single-source image segmentation. However,\ndespite its reliable results for segmentation, there is still a need to\nincrease its robustness and improve its performance. This is particularly\ncrucial for multimodal image segmentation, where the fusion of diverse types of\ninformation is essential.\n  An interesting approach involves enhancing this architectural framework\nthrough the integration of novel components and the modification of certain\ninternal processes.\n  In this paper, we enhance the DeepLabV3+ architecture by introducing a new\ntransposed conventional layers block for upsampling a second entry to fuse it\nwith high level features. This block is designed to amplify and integrate\ninformation from satellite images, thereby enriching the segmentation process\nthrough fusion with aerial images.\n  For experiments, we used the LandCover.ai (Land Cover from Aerial Imagery)\ndataset for aerial images, alongside the corresponding dataset sourced from\nSentinel 2 data.\n  Through the fusion of both sources, the mean Intersection over Union (mIoU)\nachieved a total mIoU of 84.91% without data augmentation.", "published": "2025-03-28 23:07:39", "link": "http://arxiv.org/abs/2503.22909v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Generating Structured Plan Representation of Procedures with LLMs", "abstract": "In this paper, we address the challenges of managing Standard Operating\nProcedures (SOPs), which often suffer from inconsistencies in language, format,\nand execution, leading to operational inefficiencies. Traditional process\nmodeling demands significant manual effort, domain expertise, and familiarity\nwith complex languages like Business Process Modeling Notation (BPMN), creating\nbarriers for non-techincal users. We introduce SOP Structuring (SOPStruct), a\nnovel approach that leverages Large Language Models (LLMs) to transform SOPs\ninto decision-tree-based structured representations. SOPStruct produces a\nstandardized representation of SOPs across different domains, reduces cognitive\nload, and improves user comprehension by effectively capturing task\ndependencies and ensuring sequential integrity. Our approach enables leveraging\nthe structured information to automate workflows as well as empower the human\nusers. By organizing procedures into logical graphs, SOPStruct facilitates\nbacktracking and error correction, offering a scalable solution for process\noptimization. We employ a novel evaluation framework, combining deterministic\nmethods with the Planning Domain Definition Language (PDDL) to verify graph\nsoundness, and non-deterministic assessment by an LLM to ensure completeness.\nWe empirically validate the robustness of our LLM-based structured SOP\nrepresentation methodology across SOPs from different domains and varying\nlevels of complexity. Despite the current lack of automation readiness in many\norganizations, our research highlights the transformative potential of LLMs to\nstreamline process modeling, paving the way for future advancements in\nautomated procedure optimization.", "published": "2025-03-28 22:38:24", "link": "http://arxiv.org/abs/2504.00029v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents", "abstract": "The rapid growth of artificial intelligence (AI) technologies has changed\ndecision-making in many fields. But, it has also raised major privacy and\nethical concerns. However, many AI incidents taxonomies and guidelines for\nacademia, industry, and government lack grounding in real-world incidents. We\nanalyzed 202 real-world AI privacy and ethical incidents. This produced a\ntaxonomy that classifies incident types across AI lifecycle stages. It accounts\nfor contextual factors such as causes, responsible entities, disclosure\nsources, and impacts. Our findings show insufficient incident reporting from AI\ndevelopers and users. Many incidents are caused by poor organizational\ndecisions and legal non-compliance. Only a few legal actions and corrective\nmeasures exist, while risk-mitigation efforts are limited. Our taxonomy\ncontributes a structured approach in reporting of future AI incidents. Our\nfindings demonstrate that current AI governance frameworks are inadequate. We\nurgently need child-specific protections and AI policies on social media. They\nmust moderate and reduce the spread of harmful AI-generated content. Our\nresearch provides insights for policymakers and practitioners, which lets them\ndesign ethical AI. It also support AI incident detection and risk management.\nFinally, it guides AI policy development. Improved policies will protect people\nfrom harmful AI applications and support innovation in AI systems.", "published": "2025-03-28 21:57:38", "link": "http://arxiv.org/abs/2504.01029v1", "categories": ["cs.CY", "cs.AI", "cs.DB", "cs.HC"], "primary_category": "cs.CY"}
{"title": "Pairwise Matching of Intermediate Representations for Fine-grained Explainability", "abstract": "The differences between images belonging to fine-grained categories are often\nsubtle and highly localized, and existing explainability techniques for deep\nlearning models are often too diffuse to provide useful and interpretable\nexplanations. We propose a new explainability method (PAIR-X) that leverages\nboth intermediate model activations and backpropagated relevance scores to\ngenerate fine-grained, highly-localized pairwise visual explanations. We use\nanimal and building re-identification (re-ID) as a primary case study of our\nmethod, and we demonstrate qualitatively improved results over a diverse set of\nexplainability baselines on 35 public re-ID datasets. In interviews, animal\nre-ID experts were in unanimous agreement that PAIR-X was an improvement over\nexisting baselines for deep model explainability, and suggested that its\nvisualizations would be directly applicable to their work. We also propose a\nnovel quantitative evaluation metric for our method, and demonstrate that\nPAIR-X visualizations appear more plausible for correct image matches than\nincorrect ones even when the model similarity score for the pairs is the same.\nBy improving interpretability, PAIR-X enables humans to better distinguish\ncorrect and incorrect matches. Our code is available at:\nhttps://github.com/pairx-explains/pairx", "published": "2025-03-28 21:13:43", "link": "http://arxiv.org/abs/2503.22881v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Diffusion models applied to skin and oral cancer classification", "abstract": "This study investigates the application of diffusion models in medical image\nclassification (DiffMIC), focusing on skin and oral lesions. Utilizing the\ndatasets PAD-UFES-20 for skin cancer and P-NDB-UFES for oral cancer, the\ndiffusion model demonstrated competitive performance compared to\nstate-of-the-art deep learning models like Convolutional Neural Networks (CNNs)\nand Transformers. Specifically, for the PAD-UFES-20 dataset, the model achieved\na balanced accuracy of 0.6457 for six-class classification and 0.8357 for\nbinary classification (cancer vs. non-cancer). For the P-NDB-UFES dataset, it\nattained a balanced accuracy of 0.9050. These results suggest that diffusion\nmodels are viable models for classifying medical images of skin and oral\nlesions. In addition, we investigate the robustness of the model trained on\nPAD-UFES-20 for skin cancer but tested on the clinical images of the HIBA\ndataset.", "published": "2025-03-28 20:29:35", "link": "http://arxiv.org/abs/2504.00026v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Teaching LLMs Music Theory with In-Context Learning and Chain-of-Thought Prompting: Pedagogical Strategies for Machines", "abstract": "This study evaluates the baseline capabilities of Large Language Models\n(LLMs) like ChatGPT, Claude, and Gemini to learn concepts in music theory\nthrough in-context learning and chain-of-thought prompting. Using carefully\ndesigned prompts (in-context learning) and step-by-step worked examples\n(chain-of-thought prompting), we explore how LLMs can be taught increasingly\ncomplex material and how pedagogical strategies for human learners translate to\neducating machines. Performance is evaluated using questions from an official\nCanadian Royal Conservatory of Music (RCM) Level 6 examination, which covers a\ncomprehensive range of topics, including interval and chord identification, key\ndetection, cadence classification, and metrical analysis. Additionally, we\nevaluate the suitability of various music encoding formats for these tasks\n(ABC, Humdrum, MEI, MusicXML). All experiments were run both with and without\ncontextual prompts. Results indicate that without context, ChatGPT with MEI\nperforms the best at 52%, while with context, Claude with MEI performs the best\nat 75%. Future work will further refine prompts and expand to cover more\nadvanced music theory concepts. This research contributes to the broader\nunderstanding of teaching LLMs and has applications for educators, students,\nand developers of AI music tools alike.", "published": "2025-03-28 20:15:24", "link": "http://arxiv.org/abs/2503.22853v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "RobuNFR: Evaluating the Robustness of Large Language Models on Non-Functional Requirements Aware Code Generation", "abstract": "When using LLMs to address Non-Functional Requirements (NFRs), developers may\nbehave differently (e.g., expressing the same NFR in different words). Robust\nLLMs should output consistent results across these variations; however, this\naspect remains underexplored. We propose RobuNFR for evaluating the robustness\nof LLMs in NFR-aware code generation across four NFR dimensions: design,\nreadability, reliability, and performance, using three methodologies: prompt\nvariation, regression testing, and diverse workflows. Our experiments show that\nRobuNFR reveals robustness issues in the tested LLMs when considering NFRs in\ncode generation. Specifically, under prompt variation, including NFRs leads to\na decrease in Pass@1 by up to 39 percent and an increase in the standard\ndeviation from 0.48 to 2.48 compared to the baseline without NFRs (i.e.,\nFunction-Only). While incorporating NFRs generally improves overall NFR\nmetrics, it also results in higher prompt sensitivity. In regression settings,\nsome LLMs exhibit differences across versions, with improvements in one aspect\n(e.g., reduced code smells) often accompanied by regressions in another (e.g.,\ndecreased correctness), revealing inconsistencies that challenge their\nrobustness. When varying workflows, the tested LLMs show significantly\ndifferent NFR-aware code generation capabilities between two workflows: (1)\nintegrating NFRs and functional requirements into the initial prompt and (2)\nenhancing Function-Only-generated code with the same NFR.", "published": "2025-03-28 20:05:33", "link": "http://arxiv.org/abs/2503.22851v2", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Nonhuman Primate Brain Tissue Segmentation Using a Transfer Learning Approach", "abstract": "Non-human primates (NHPs) serve as critical models for understanding human\nbrain function and neurological disorders due to their close evolutionary\nrelationship with humans. Accurate brain tissue segmentation in NHPs is\ncritical for understanding neurological disorders, but challenging due to the\nscarcity of annotated NHP brain MRI datasets, the small size of the NHP brain,\nthe limited resolution of available imaging data and the anatomical differences\nbetween human and NHP brains. To address these challenges, we propose a novel\napproach utilizing STU-Net with transfer learning to leverage knowledge\ntransferred from human brain MRI data to enhance segmentation accuracy in the\nNHP brain MRI, particularly when training data is limited. The combination of\nSTU-Net and transfer learning effectively delineates complex tissue boundaries\nand captures fine anatomical details specific to NHP brains. Notably, our\nmethod demonstrated improvement in segmenting small subcortical structures such\nas putamen and thalamus that are challenging to resolve with limited spatial\nresolution and tissue contrast, and achieved DSC of over 0.88, IoU over 0.8 and\nHD95 under 7. This study introduces a robust method for multi-class brain\ntissue segmentation in NHPs, potentially accelerating research in evolutionary\nneuroscience and preclinical studies of neurological disorders relevant to\nhuman health.", "published": "2025-03-28 18:51:22", "link": "http://arxiv.org/abs/2503.22829v2", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Data-driven worker activity recognition and picking efficiency estimation in manual strawberry harvesting", "abstract": "Manual fruit harvesting is common in agriculture, but the amount of time that\npickers spend on nonproductive activities can make it very inefficient.\nAccurately identifying picking vs. non-picking activity is crucial for\nestimating picker efficiency and optimizing labor management and the harvest\nprocess. In this study, a practical system was developed to calculate the\nefficiency of pickers in commercial strawberry harvesting. Instrumented picking\ncarts were used to record in real-time the harvested fruit weight,\ngeo-location, and cart movement. A fleet of these carts was deployed during the\ncommercial strawberry harvest season in Santa Maria, CA. The collected data was\nthen used to train a CNN-LSTM-based deep neural network to classify a picker's\nactivity into ``Pick\" and ``NoPick\" classes. Experimental evaluations showed\nthat the CNN-LSTM model showed promising activity recognition performance with\nan F1 score accuracy of up to 0.974. The classification results were then used\nto compute two worker efficiency metrics: the percentage of time spent actively\npicking, and the time required to fill a tray. Analysis of the season-long\nharvest data showed that the pickers spent an average of 73.56% of their total\nharvest time actively picking strawberries, with an average tray fill time of\n6.22 minutes. The mean accuracies of these metrics were 96.29% and 95.42%,\nrespectively. When integrated on a commercial scale, the proposed technology\ncould aid growers in automated worker activity monitoring and harvest\noptimization, ultimately helping to reduce non-productive time and enhance\noverall harvest efficiency.", "published": "2025-03-28 18:16:28", "link": "http://arxiv.org/abs/2503.22809v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DiTFastAttnV2: Head-wise Attention Compression for Multi-Modality Diffusion Transformers", "abstract": "Text-to-image generation models, especially Multimodal Diffusion Transformers\n(MMDiT), have shown remarkable progress in generating high-quality images.\nHowever, these models often face significant computational bottlenecks,\nparticularly in attention mechanisms, which hinder their scalability and\nefficiency. In this paper, we introduce DiTFastAttnV2, a post-training\ncompression method designed to accelerate attention in MMDiT. Through an\nin-depth analysis of MMDiT's attention patterns, we identify key differences\nfrom prior DiT-based methods and propose head-wise arrow attention and caching\nmechanisms to dynamically adjust attention heads, effectively bridging this\ngap. We also design an Efficient Fused Kernel for further acceleration. By\nleveraging local metric methods and optimization techniques, our approach\nsignificantly reduces the search time for optimal compression schemes to just\nminutes while maintaining generation quality. Furthermore, with the customized\nkernel, DiTFastAttnV2 achieves a 68% reduction in attention FLOPs and 1.5x\nend-to-end speedup on 2K image generation without compromising visual fidelity.", "published": "2025-03-28 18:00:12", "link": "http://arxiv.org/abs/2503.22796v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness", "abstract": "Most 3D object generators focus on aesthetic quality, often neglecting\nphysical constraints necessary in applications. One such constraint is that the\n3D object should be self-supporting, i.e., remains balanced under gravity.\nPrior approaches to generating stable 3D objects used differentiable physics\nsimulators to optimize geometry at test-time, which is slow, unstable, and\nprone to local optima. Inspired by the literature on aligning generative models\nto external feedback, we propose Direct Simulation Optimization (DSO), a\nframework to use the feedback from a (non-differentiable) simulator to increase\nthe likelihood that the 3D generator outputs stable 3D objects directly. We\nconstruct a dataset of 3D objects labeled with a stability score obtained from\nthe physics simulator. We can then fine-tune the 3D generator using the\nstability score as the alignment metric, via direct preference optimization\n(DPO) or direct reward optimization (DRO), a novel objective, which we\nintroduce, to align diffusion models without requiring pairwise preferences.\nOur experiments show that the fine-tuned feed-forward generator, using either\nDPO or DRO objective, is much faster and more likely to produce stable objects\nthan test-time optimization. Notably, the DSO framework works even without any\nground-truth 3D objects for training, allowing the 3D generator to self-improve\nby automatically collecting simulation feedback on its own outputs.", "published": "2025-03-28 17:59:53", "link": "http://arxiv.org/abs/2503.22677v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Exploring the Effectiveness of Multi-stage Fine-tuning for Cross-encoder Re-rankers", "abstract": "State-of-the-art cross-encoders can be fine-tuned to be highly effective in\npassage re-ranking. The typical fine-tuning process of cross-encoders as\nre-rankers requires large amounts of manually labelled data, a contrastive\nlearning objective, and a set of heuristically sampled negatives. An\nalternative recent approach for fine-tuning instead involves teaching the model\nto mimic the rankings of a highly effective large language model using a\ndistillation objective. These fine-tuning strategies can be applied either\nindividually, or in sequence. In this work, we systematically investigate the\neffectiveness of point-wise cross-encoders when fine-tuned independently in a\nsingle stage, or sequentially in two stages. Our experiments show that the\neffectiveness of point-wise cross-encoders fine-tuned using contrastive\nlearning is indeed on par with that of models fine-tuned with multi-stage\napproaches. Code is available for reproduction at\nhttps://github.com/fpezzuti/multistage-finetuning.", "published": "2025-03-28 17:58:31", "link": "http://arxiv.org/abs/2503.22672v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Evaluation of Machine-generated Biomedical Images via A Tally-based Similarity Measure", "abstract": "Super-resolution, in-painting, whole-image generation, unpaired\nstyle-transfer, and network-constrained image reconstruction each include an\naspect of machine-learned image synthesis where the actual ground truth is not\nknown at time of use. It is generally difficult to quantitatively and\nauthoritatively evaluate the quality of synthetic images; however, in\nmission-critical biomedical scenarios robust evaluation is paramount. In this\nwork, all practical image-to-image comparisons really are relative\nqualifications, not absolute difference quantifications; and, therefore,\nmeaningful evaluation of generated image quality can be accomplished using the\nTversky Index, which is a well-established measure for assessing perceptual\nsimilarity. This evaluation procedure is developed and then demonstrated using\nmultiple image data sets, both real and simulated. The main result is that when\nthe subjectivity and intrinsic deficiencies of any feature-encoding choice are\nput upfront, Tversky's method leads to intuitive results, whereas traditional\nmethods based on summarizing distances in deep feature spaces do not.", "published": "2025-03-28 17:44:01", "link": "http://arxiv.org/abs/2503.22658v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Unicorn: Text-Only Data Synthesis for Vision Language Model Training", "abstract": "Training vision-language models (VLMs) typically requires large-scale,\nhigh-quality image-text pairs, but collecting or synthesizing such data is\ncostly. In contrast, text data is abundant and inexpensive, prompting the\nquestion: can high-quality multimodal training data be synthesized purely from\ntext? To tackle this, we propose a cross-integrated three-stage multimodal data\nsynthesis framework, which generates two datasets: Unicorn-1.2M and\nUnicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we\nconstruct 1.2M semantically diverse high-quality captions by expanding sparse\ncaption seeds using large language models (LLMs). In Stage 2:\nInstruction-Tuning Data Generation, we further process 471K captions into\nmulti-turn instruction-tuning tasks to support complex reasoning. Finally, in\nStage 3: Modality Representation Transfer, these textual captions\nrepresentations are transformed into visual representations, resulting in\ndiverse synthetic image representations. This three-stage process enables us to\nconstruct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for\ninstruction-tuning, without relying on real images. By eliminating the\ndependency on real images while maintaining data quality and diversity, our\nframework offers a cost-effective and scalable solution for VLMs training. Code\nis available at https://github.com/Yu-xm/Unicorn.git.", "published": "2025-03-28 17:43:00", "link": "http://arxiv.org/abs/2503.22655v1", "categories": ["cs.AI", "cs.CV", "cs.MM"], "primary_category": "cs.AI"}
{"title": "Patronus: Bringing Transparency to Diffusion Models with Prototypes", "abstract": "Diffusion-based generative models, such as Denoising Diffusion Probabilistic\nModels (DDPMs), have achieved remarkable success in image generation, but their\nstep-by-step denoising process remains opaque, leaving critical aspects of the\ngeneration mechanism unexplained. To address this, we introduce\n\\emph{Patronus}, an interpretable diffusion model inspired by ProtoPNet.\nPatronus integrates a prototypical network into DDPMs, enabling the extraction\nof prototypes and conditioning of the generation process on their prototype\nactivation vector. This design enhances interpretability by showing the learned\nprototypes and how they influence the generation process. Additionally, the\nmodel supports downstream tasks like image manipulation, enabling more\ntransparent and controlled modifications. Moreover, Patronus could reveal\nshortcut learning in the generation process by detecting unwanted correlations\nbetween learned prototypes. Notably, Patronus operates entirely without any\nannotations or text prompts. This work opens new avenues for understanding and\ncontrolling diffusion models through prototype-based interpretability. Our code\nis available at\n\\href{https://github.com/nina-weng/patronus}{https://github.com/nina-weng/patronus}.", "published": "2025-03-28 17:31:40", "link": "http://arxiv.org/abs/2503.22782v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels", "abstract": "In imitation learning for robotics, cotraining with demonstration data\ngenerated both in simulation and on real hardware has emerged as a powerful\nrecipe to overcome the sim2real gap. This work seeks to elucidate basic\nprinciples of this sim-and-real cotraining to help inform simulation design,\nsim-and-real dataset creation, and policy training. Focusing narrowly on the\ncanonical task of planar pushing from camera inputs enabled us to be thorough\nin our study. These experiments confirm that cotraining with simulated data\n\\emph{can} dramatically improve performance in real, especially when real data\nis limited. Performance gains scale with simulated data, but eventually\nplateau; real-world data increases this performance ceiling. The results also\nsuggest that reducing the domain gap in physics may be more important than\nvisual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly,\nhaving some visual domain gap actually helps the cotrained policy -- binary\nprobes reveal that high-performing policies learn to distinguish simulated\ndomains from real. We conclude by investigating this nuance and mechanisms that\nfacilitate positive transfer between sim-and-real. In total, our experiments\nspan over 40 real-world policies (evaluated on 800+ trials) and 200 simulated\npolicies (evaluated on 40,000+ trials).", "published": "2025-03-28 17:25:57", "link": "http://arxiv.org/abs/2503.22634v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Challenges and Paths Towards AI for Software Engineering", "abstract": "AI for software engineering has made remarkable progress recently, becoming a\nnotable success within generative AI. Despite this, there are still many\nchallenges that need to be addressed before automated software engineering\nreaches its full potential. It should be possible to reach high levels of\nautomation where humans can focus on the critical decisions of what to build\nand how to balance difficult tradeoffs while most routine development effort is\nautomated away. Reaching this level of automation will require substantial\nresearch and engineering efforts across academia and industry. In this paper,\nwe aim to discuss progress towards this in a threefold manner. First, we\nprovide a structured taxonomy of concrete tasks in AI for software engineering,\nemphasizing the many other tasks in software engineering beyond code generation\nand completion. Second, we outline several key bottlenecks that limit current\napproaches. Finally, we provide an opinionated list of promising research\ndirections toward making progress on these bottlenecks, hoping to inspire\nfuture research in this rapidly maturing field.", "published": "2025-03-28 17:17:57", "link": "http://arxiv.org/abs/2503.22625v1", "categories": ["cs.SE", "cs.AI", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Multi-Objective Quality-Diversity in Unstructured and Unbounded Spaces", "abstract": "Quality-Diversity algorithms are powerful tools for discovering diverse,\nhigh-performing solutions. Recently, Multi-Objective Quality-Diversity (MOQD)\nextends QD to problems with several objectives while preserving solution\ndiversity. MOQD has shown promise in fields such as robotics and materials\nscience, where finding trade-offs between competing objectives like energy\nefficiency and speed, or material properties is essential. However, existing\nmethods in MOQD rely on tessellating the feature space into a grid structure,\nwhich prevents their application in domains where feature spaces are unknown or\nmust be learned, such as complex biological systems or latent exploration\ntasks. In this work, we introduce Multi-Objective Unstructured Repertoire for\nQuality-Diversity (MOUR-QD), a MOQD algorithm designed for unstructured and\nunbounded feature spaces. We evaluate MOUR-QD on five robotic tasks.\nImportantly, we show that our method excels in tasks where features must be\nlearned, paving the way for applying MOQD to unsupervised domains. We also\ndemonstrate that MOUR-QD is advantageous in domains with unbounded feature\nspaces, outperforming existing grid-based methods. Finally, we demonstrate that\nMOUR-QD is competitive with established MOQD methods on existing MOQD tasks and\nachieves double the MOQD-score in some environments. MOUR-QD opens up new\nopportunities for MOQD in domains like protein design and image generation.", "published": "2025-03-28 16:55:39", "link": "http://arxiv.org/abs/2504.03715v1", "categories": ["cs.LG", "cs.AI", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Generative Latent Neural PDE Solver using Flow Matching", "abstract": "Autoregressive next-step prediction models have become the de-facto standard\nfor building data-driven neural solvers to forecast time-dependent partial\ndifferential equations (PDEs). Denoise training that is closely related to\ndiffusion probabilistic model has been shown to enhance the temporal stability\nof neural solvers, while its stochastic inference mechanism enables ensemble\npredictions and uncertainty quantification. In principle, such training\ninvolves sampling a series of discretized diffusion timesteps during both\ntraining and inference, inevitably increasing computational overhead. In\naddition, most diffusion models apply isotropic Gaussian noise on structured,\nuniform grids, limiting their adaptability to irregular domains. We propose a\nlatent diffusion model for PDE simulation that embeds the PDE state in a\nlower-dimensional latent space, which significantly reduces computational\ncosts. Our framework uses an autoencoder to map different types of meshes onto\na unified structured latent grid, capturing complex geometries. By analyzing\ncommon diffusion paths, we propose to use a coarsely sampled noise schedule\nfrom flow matching for both training and testing. Numerical experiments show\nthat the proposed model outperforms several deterministic baselines in both\naccuracy and long-term stability, highlighting the potential of diffusion-based\napproaches for robust data-driven PDE learning.", "published": "2025-03-28 16:44:28", "link": "http://arxiv.org/abs/2503.22600v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "KEVS: Enhancing Segmentation of Visceral Adipose Tissue in Pre-Cystectomy CT with Gaussian Kernel Density Estimation", "abstract": "Purpose: The distribution of visceral adipose tissue (VAT) in cystectomy\npatients is indicative of the incidence of post-operative complications.\nExisting VAT segmentation methods for computed tomography (CT) employing\nintensity thresholding have limitations relating to inter-observer variability.\nMoreover, the difficulty in creating ground-truth masks limits the development\nof deep learning (DL) models for this task. This paper introduces a novel\nmethod for VAT prediction in pre-cystectomy CT, which is fully automated and\ndoes not require ground-truth VAT masks for training, overcoming aforementioned\nlimitations. Methods: We introduce the Kernel density Enhanced VAT Segmentator\n( KEVS), combining a DL semantic segmentation model, for multi-body feature\nprediction, with Gaussian kernel density estimation analysis of predicted\nsubcutaneous adipose tissue to achieve accurate scan-specific predictions of\nVAT in the abdominal cavity. Uniquely for a DL pipeline, KEVS does not require\nground-truth VAT masks. Results: We verify the ability of KEVS to accurately\nsegment abdominal organs in unseen CT data and compare KEVS VAT segmentation\npredictions to existing state-of-the-art (SOTA) approaches in a dataset of 20\npre-cystectomy CT scans, collected from University College London Hospital\n(UCLH-Cyst), with expert ground-truth annotations. KEVS presents a 4.80% and\n6.02% improvement in Dice Coefficient over the second best DL and\nthresholding-based VAT segmentation techniques respectively when evaluated on\nUCLH-Cyst. Conclusion: This research introduces KEVS; an automated, SOTA method\nfor the prediction of VAT in pre-cystectomy CT which eliminates inter-observer\nvariability and is trained entirely on open-source CT datasets which do not\ncontain ground-truth VAT masks.", "published": "2025-03-28 16:41:09", "link": "http://arxiv.org/abs/2503.22592v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012", "abstract": "This paper introduces the largest and most comprehensive dataset of US\npresidential campaign television advertisements, available in digital format.\nThe dataset also includes machine-searchable transcripts and high-quality\nsummaries designed to facilitate a variety of academic research. To date, there\nhas been great interest in collecting and analyzing US presidential campaign\nadvertisements, but the need for manual procurement and annotation led many to\nrely on smaller subsets. We design a large-scale parallelized, AI-based\nanalysis pipeline that automates the laborious process of preparing,\ntranscribing, and summarizing videos. We then apply this methodology to the\n9,707 presidential ads from the Julian P. Kanter Political Commercial Archive.\nWe conduct extensive human evaluations to show that these transcripts and\nsummaries match the quality of manually generated alternatives. We illustrate\nthe value of this data by including an application that tracks the genesis and\nevolution of current focal issue areas over seven decades of presidential\nelections. Our analysis pipeline and codebase also show how to use LLM-based\ntools to obtain high-quality summaries for other video datasets.", "published": "2025-03-28 16:36:23", "link": "http://arxiv.org/abs/2503.22589v1", "categories": ["cs.MM", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.MM"}
{"title": "Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization", "abstract": "Rapid advancements in Visual Language Models (VLMs) have transformed\nmultimodal understanding but are often constrained by generating English\nresponses regardless of the input language. This phenomenon has been termed as\nImage-induced Fidelity Loss (IFL) and stems from limited multimodal\nmultilingual training data. To address this, we propose a continuous\nmultilingual integration strategy that injects text-only multilingual data\nduring visual instruction tuning, preserving the language model's original\nmultilingual capabilities. Extensive evaluations demonstrate that our approach\nsignificantly improves linguistic fidelity across languages without degradation\nin visual performance. We also explore model merging, which improves language\nfidelity but comes at the cost of visual performance. In contrast, our core\nmethod achieves robust multilingual alignment without trade-offs, offering a\nscalable and effective path to mitigating IFL for global VLM adoption.", "published": "2025-03-28 16:26:52", "link": "http://arxiv.org/abs/2503.22577v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations", "abstract": "Deep Reinforcement Learning (DRL) is a paradigm of artificial intelligence\nwhere an agent uses a neural network to learn which actions to take in a given\nenvironment. DRL has recently gained traction from being able to solve complex\nenvironments like driving simulators, 3D robotic control, and\nmultiplayer-online-battle-arena video games. Numerous implementations of the\nstate-of-the-art algorithms responsible for training these agents, like the\nDeep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms,\ncurrently exist. However, studies make the mistake of assuming implementations\nof the same algorithm to be consistent and thus, interchangeable. In this\npaper, through a differential testing lens, we present the results of studying\nthe extent of implementation inconsistencies, their effect on the\nimplementations' performance, as well as their impact on the conclusions of\nprior studies under the assumption of interchangeable implementations. The\noutcomes of our differential tests showed significant discrepancies between the\ntested algorithm implementations, indicating that they are not interchangeable.\nIn particular, out of the five PPO implementations tested on 56 games, three\nimplementations achieved superhuman performance for 50% of their total trials\nwhile the other two implementations only achieved superhuman performance for\nless than 15% of their total trials. As part of a meticulous manual analysis of\nthe implementations' source code, we analyzed implementation discrepancies and\ndetermined that code-level inconsistencies primarily caused these\ndiscrepancies. Lastly, we replicated a study and showed that this assumption of\nimplementation interchangeability was sufficient to flip experiment outcomes.\nTherefore, this calls for a shift in how implementations are being used.", "published": "2025-03-28 16:25:06", "link": "http://arxiv.org/abs/2503.22575v1", "categories": ["cs.SE", "cs.AI", "D.2.5; I.2.6"], "primary_category": "cs.SE"}
{"title": "A Framework for Cryptographic Verifiability of End-to-End AI Pipelines", "abstract": "The increasing integration of Artificial Intelligence across multiple\nindustry sectors necessitates robust mechanisms for ensuring transparency,\ntrust, and auditability of its development and deployment. This topic is\nparticularly important in light of recent calls in various jurisdictions to\nintroduce regulation and legislation on AI safety. In this paper, we propose a\nframework for complete verifiable AI pipelines, identifying key components and\nanalyzing existing cryptographic approaches that contribute to verifiability\nacross different stages of the AI lifecycle, from data sourcing to training,\ninference, and unlearning. This framework could be used to combat\nmisinformation by providing cryptographic proofs alongside AI-generated assets\nto allow downstream verification of their provenance and correctness. Our\nfindings underscore the importance of ongoing research to develop cryptographic\ntools that are not only efficient for isolated AI processes, but that are\nefficiently `linkable' across different processes within the AI pipeline, to\nsupport the development of end-to-end verifiable AI technologies.", "published": "2025-03-28 16:20:57", "link": "http://arxiv.org/abs/2503.22573v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Niyama : Breaking the Silos of LLM Inference Serving", "abstract": "The widespread adoption of Large Language Models (LLMs) has enabled diverse\napplications with very different latency requirements. Existing LLM serving\nframeworks rely on siloed infrastructure with coarse-grained workload\nsegregation -- interactive and batch -- leading to inefficient resource\nutilization and limited support for fine-grained Quality-of-Service (QoS)\ndifferentiation. This results in operational inefficiencies, over-provisioning\nand poor load management during traffic surges.\n  We present Niyama, a novel QoS-driven inference serving system that enables\nefficient co-scheduling of diverse workloads on shared infrastructure. Niyama\nintroduces fine-grained QoS classification allowing applications to specify\nprecise latency requirements, and dynamically adapts scheduling decisions based\non real-time system state. Leveraging the predictable execution characteristics\nof LLM inference, Niyama implements a dynamic chunking mechanism to improve\noverall throughput while maintaining strict QoS guarantees. Additionally,\nNiyama employs a hybrid prioritization policy that balances fairness and\nefficiency, and employs selective request relegation that enables graceful\nservice degradation during overload conditions. Our evaluation demonstrates\nthat Niyama increases serving capacity by 32% compared to current siloed\ndeployments, while maintaining QoS guarantees. Notably, under extreme load, our\nsystem reduces SLO violations by an order of magnitude compared to current\nstrategies.", "published": "2025-03-28 16:04:20", "link": "http://arxiv.org/abs/2503.22562v1", "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "cs.LG"}
{"title": "A multi-locus predictiveness curve and its summary assessment for genetic risk prediction", "abstract": "With the advance of high-throughput genotyping and sequencing technologies,\nit becomes feasible to comprehensive evaluate the role of massive genetic\npredictors in disease prediction. There exists, therefore, a critical need for\ndeveloping appropriate statistical measurements to access the combined effects\nof these genetic variants in disease prediction. Predictiveness curve is\ncommonly used as a graphical tool to measure the predictive ability of a risk\nprediction model on a single continuous biomarker. Yet, for most complex\ndiseases, risk prediciton models are formed on multiple genetic variants. We\ntherefore propose a multi-marker predictiveness curve and provide a\nnon-parametric method to construct the curve for case-control studies. We\nfurther introduce a global predictiveness U and a partial predictiveness U to\nsummarize prediction curve across the whole population and sub-population of\nclinical interest, respectively. We also demonstrate the connections of\npredictiveness curve with ROC curve and Lorenz curve. Through simulation, we\ncompared the performance of the predictiveness U to other three summary\nindices: R square, Total Gain, and Average Entropy, and showed that\nPredictiveness U outperformed the other three indexes in terms of unbiasedness\nand robustness. Moreover, we simulated a series of rare-variants disease model,\nfound partial predictiveness U performed better than global predictiveness U.\nFinally, we conducted a real data analysis, using predictiveness curve and\npredictiveness U to evaluate a risk prediction model for Nicotine Dependence.", "published": "2025-03-28 15:49:39", "link": "http://arxiv.org/abs/2504.00024v1", "categories": ["stat.ME", "cs.AI", "cs.LG"], "primary_category": "stat.ME"}
{"title": "NLS: Natural-Level Synthesis for Hardware Implementation Through GenAI", "abstract": "This paper introduces Natural-Level Synthesis, an innovative approach for\ngenerating hardware using generative artificial intelligence on both the system\nlevel and component-level. NLS bridges a gap in current hardware development\nprocesses, where algorithm and application engineers' involvement typically\nends at the requirements stage. With NLS, engineers can participate more deeply\nin the development, synthesis, and test stages by using Gen-AI models to\nconvert natural language descriptions directly into Hardware Description\nLanguage code. This approach not only streamlines hardware development but also\nimproves accessibility, fostering a collaborative workflow between hardware and\nalgorithm engineers. We developed the NLS tool to facilitate natural\nlanguage-driven HDL synthesis, enabling rapid generation of system-level HDL\ndesigns while significantly reducing development complexity. Evaluated through\ncase studies and benchmarks using Performance, Power, and Area metrics, NLS\nshows its potential to enhance resource efficiency in hardware development.\nThis work provides a extensible, efficient solution for hardware synthesis and\nestablishes a Visual Studio Code Extension to assess Gen-AI-driven HDL\ngeneration and system integration, laying a foundation for future AI-enhanced\nand AI-in-the-loop Electronic Design Automation tools.", "published": "2025-03-28 15:46:01", "link": "http://arxiv.org/abs/2504.01981v1", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "SafeCast: Risk-Responsive Motion Forecasting for Autonomous Vehicles", "abstract": "Accurate motion forecasting is essential for the safety and reliability of\nautonomous driving (AD) systems. While existing methods have made significant\nprogress, they often overlook explicit safety constraints and struggle to\ncapture the complex interactions among traffic agents, environmental factors,\nand motion dynamics. To address these challenges, we present SafeCast, a\nrisk-responsive motion forecasting model that integrates safety-aware\ndecision-making with uncertainty-aware adaptability. SafeCast is the first to\nincorporate the Responsibility-Sensitive Safety (RSS) framework into motion\nforecasting, encoding interpretable safety rules--such as safe distances and\ncollision avoidance--based on traffic norms and physical principles. To further\nenhance robustness, we introduce the Graph Uncertainty Feature (GUF), a\ngraph-based module that injects learnable noise into Graph Attention Networks,\ncapturing real-world uncertainties and enhancing generalization across diverse\nscenarios. We evaluate SafeCast on four real-world benchmark datasets--Next\nGeneration Simulation (NGSIM), Highway Drone (HighD), ApolloScape, and the\nMacao Connected Autonomous Driving (MoCAD)--covering highway, urban, and\nmixed-autonomy traffic environments. Our model achieves state-of-the-art (SOTA)\naccuracy while maintaining a lightweight architecture and low inference\nlatency, underscoring its potential for real-time deployment in safety-critical\nAD systems.", "published": "2025-03-28 15:38:21", "link": "http://arxiv.org/abs/2503.22541v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "LIM: Large Interpolator Model for Dynamic Reconstruction", "abstract": "Reconstructing dynamic assets from video data is central to many in computer\nvision and graphics tasks. Existing 4D reconstruction approaches are limited by\ncategory-specific models or slow optimization-based methods. Inspired by the\nrecent Large Reconstruction Model (LRM), we present the Large Interpolation\nModel (LIM), a transformer-based feed-forward solution, guided by a novel\ncausal consistency loss, for interpolating implicit 3D representations across\ntime. Given implicit 3D representations at times $t_0$ and $t_1$, LIM produces\na deformed shape at any continuous time $t\\in[t_0,t_1]$, delivering\nhigh-quality interpolated frames in seconds. Furthermore, LIM allows explicit\nmesh tracking across time, producing a consistently uv-textured mesh sequence\nready for integration into existing production pipelines. We also use LIM, in\nconjunction with a diffusion-based multiview generator, to produce dynamic 4D\nreconstructions from monocular videos. We evaluate LIM on various dynamic\ndatasets, benchmarking against image-space interpolation methods (e.g., FiLM)\nand direct triplane linear interpolation, and demonstrate clear advantages. In\nsummary, LIM is the first feed-forward model capable of high-speed tracked 4D\nasset reconstruction across diverse categories.", "published": "2025-03-28 15:36:53", "link": "http://arxiv.org/abs/2503.22537v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization", "abstract": "We introduce the AnnoPage Dataset, a novel collection of 7550 pages from\nhistorical documents, primarily in Czech and German, spanning from 1485 to the\npresent, focusing on the late 19th and early 20th centuries. The dataset is\ndesigned to support research in document layout analysis and object detection.\nEach page is annotated with axis-aligned bounding boxes (AABB) representing\nelements of 25 categories of non-textual elements, such as images, maps,\ndecorative elements, or charts, following the Czech Methodology of image\ndocument processing. The annotations were created by expert librarians to\nensure accuracy and consistency. The dataset also incorporates pages from\nmultiple, mainly historical, document datasets to enhance variability and\nmaintain continuity. The dataset is divided into development and test subsets,\nwith the test set carefully selected to maintain the category distribution. We\nprovide baseline results using YOLO and DETR object detectors, offering a\nreference point for future research. The AnnoPage Dataset is publicly available\non Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth\nannotations in YOLO format.", "published": "2025-03-28 15:30:42", "link": "http://arxiv.org/abs/2503.22526v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Robust Offline Imitation Learning Through State-level Trajectory Stitching", "abstract": "Imitation learning (IL) has proven effective for enabling robots to acquire\nvisuomotor skills through expert demonstrations. However, traditional IL\nmethods are limited by their reliance on high-quality, often scarce, expert\ndata, and suffer from covariate shift. To address these challenges, recent\nadvances in offline IL have incorporated suboptimal, unlabeled datasets into\nthe training. In this paper, we propose a novel approach to enhance policy\nlearning from mixed-quality offline datasets by leveraging task-relevant\ntrajectory fragments and rich environmental dynamics. Specifically, we\nintroduce a state-based search framework that stitches state-action pairs from\nimperfect demonstrations, generating more diverse and informative training\ntrajectories. Experimental results on standard IL benchmarks and real-world\nrobotic tasks showcase that our proposed method significantly improves both\ngeneralization and performance.", "published": "2025-03-28 15:28:36", "link": "http://arxiv.org/abs/2503.22524v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Masked Self-Supervised Pre-Training for Text Recognition Transformers on Large-Scale Datasets", "abstract": "Self-supervised learning has emerged as a powerful approach for leveraging\nlarge-scale unlabeled data to improve model performance in various domains. In\nthis paper, we explore masked self-supervised pre-training for text recognition\ntransformers. Specifically, we propose two modifications to the pre-training\nphase: progressively increasing the masking probability, and modifying the loss\nfunction to incorporate both masked and non-masked patches. We conduct\nextensive experiments using a dataset of 50M unlabeled text lines for\npre-training and four differently sized annotated datasets for fine-tuning.\nFurthermore, we compare our pre-trained models against those trained with\ntransfer learning, demonstrating the effectiveness of the self-supervised\npre-training. In particular, pre-training consistently improves the character\nerror rate of models, in some cases up to 30 % relatively. It is also on par\nwith transfer learning but without relying on extra annotated text lines.", "published": "2025-03-28 15:16:48", "link": "http://arxiv.org/abs/2503.22513v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Information Gain Is Not All You Need", "abstract": "Autonomous exploration in mobile robotics is driven by two competing\nobjectives: coverage, to exhaustively observe the environment; and path length,\nto do so with the shortest path possible. Though it is difficult to evaluate\nthe best course of action without knowing the unknown, the unknown can often be\nunderstood through models, maps, or common sense. However, previous work has\nshown that improving estimates of information gain through such prior knowledge\nleads to greedy behavior and ultimately causes backtracking, which degrades\ncoverage performance. In fact, any information gain maximization will exhibit\nthis behavior, even without prior knowledge. Information gained at task\ncompletion is constant, and cannot be maximized for. It is therefore an\nunsuitable choice as an optimization objective. Instead, information gain is a\ndecision criterion for determining which candidate states should still be\nconsidered for exploration. The task therefore becomes to reach completion with\nthe shortest total path. Since determining the shortest path is typically\nintractable, it is necessary to rely on a heuristic or estimate to identify\ncandidate states that minimize the total path length. To address this, we\npropose a heuristic that reduces backtracking by preferring candidate states\nthat are close to the robot, but far away from other candidate states. We\nevaluate the performance of the proposed heuristic in simulation against an\ninformation gain-based approach and frontier exploration, and show that our\nmethod significantly decreases total path length, both with and without prior\nknowledge of the environment.", "published": "2025-03-28 15:03:52", "link": "http://arxiv.org/abs/2504.01980v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Almost Bayesian: The Fractal Dynamics of Stochastic Gradient Descent", "abstract": "We show that the behavior of stochastic gradient descent is related to\nBayesian statistics by showing that SGD is effectively diffusion on a fractal\nlandscape, where the fractal dimension can be accounted for in a purely\nBayesian way. By doing this we show that SGD can be regarded as a modified\nBayesian sampler which accounts for accessibility constraints induced by the\nfractal structure of the loss landscape. We verify our results experimentally\nby examining the diffusion of weights during training. These results offer\ninsight into the factors which determine the learning process, and seemingly\nanswer the question of how SGD and purely Bayesian sampling are related.", "published": "2025-03-28 14:38:39", "link": "http://arxiv.org/abs/2503.22478v1", "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "cs.LG"}
{"title": "RLDBF: Enhancing LLMs Via Reinforcement Learning With DataBase FeedBack", "abstract": "While current large language models (LLMs) demonstrate remarkable linguistic\ncapabilities through training on massive unstructured text corpora, they remain\ninadequate in leveraging structured scientific data (e.g., chemical molecular\nproperties in databases) that encapsulate centuries of accumulated scientific\nexpertise. These structured datasets hold strategic significance for advancing\nAI for Science yet current approaches merely treat them as auxiliary\nsupplements to unstructured text. This study pioneers a systematic\ninvestigation into enhancing LLMs with structured scientific data, using\nchemical molecular science as a testbed. We investigate the impact of\nincorporating molecular property data on LLM across distinct training phases,\nincluding continual pre-training, supervised fine-tuning, and reinforcement\nlearning. Notably, to address the inherent limitation of numerical\ninsensitivity in large models, we propose an innovative methodology termed\n\"Reinforcement Learning with Database Feedback\" (RLDBF). Experimental\nevaluations demonstrate the efficacy of the proposed approach, with the model\nexhibiting remarkable generalization capabilities on previously unseen data and\nother chemical tasks. The results substantiate the potential of our method in\nadvancing the field of structured scientific data processing within LLMs.", "published": "2025-03-28 14:18:29", "link": "http://arxiv.org/abs/2504.03713v1", "categories": ["cs.LG", "cs.AI", "cs.CE"], "primary_category": "cs.LG"}
{"title": "Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning", "abstract": "We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach that\nenhances the exploration-exploitation tradeoff by dynamically assigning weights\nto generated outputs based on their advantage and entropy for Reinforcement\nLearning-based Large Language Model fine-tuning. EGSW integrates entropy\nregularization with advantage-based weighting to balance policy updates,\nenabling efficient exploration in high-dimensional state spaces. By employing\ntemperature-scaled softmax weighting over sequences, EGSW prioritizing\nhigh-reward, high-uncertainty steps while maintaining training stability.\nAlthough originally developed to improve Group Relative Policy Optimization\n(GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable to\nother reinforcement learning (RL) algorithms and can be implemented in both\nstep-wise and trajectory-wise settings. Empirical evaluations demonstrate that\nEGSW enhances GRPO reasoning ability, yielding improvements in sample\nefficiency. Future work will explore the application of EGSW to advanced RL\nmethodologies.", "published": "2025-03-28 14:07:51", "link": "http://arxiv.org/abs/2503.22456v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Causal Framework to Measure and Mitigate Non-binary Treatment Discrimination", "abstract": "Fairness studies of algorithmic decision-making systems often simplify\ncomplex decision processes, such as bail or loan approvals, into binary\nclassification tasks. However, these approaches overlook that such decisions\nare not inherently binary (e.g., approve or not approve bail or loan); they\nalso involve non-binary treatment decisions (e.g., bail conditions or loan\nterms) that can influence the downstream outcomes (e.g., loan repayment or\nreoffending). In this paper, we argue that non-binary treatment decisions are\nintegral to the decision process and controlled by decision-makers and,\ntherefore, should be central to fairness analyses in algorithmic\ndecision-making. We propose a causal framework that extends fairness analyses\nand explicitly distinguishes between decision-subjects' covariates and the\ntreatment decisions. This specification allows decision-makers to use our\nframework to (i) measure treatment disparity and its downstream effects in\nhistorical data and, using counterfactual reasoning, (ii) mitigate the impact\nof past unfair treatment decisions when automating decision-making. We use our\nframework to empirically analyze four widely used loan approval datasets to\nreveal potential disparity in non-binary treatment decisions and their\ndiscriminatory impact on outcomes, highlighting the need to incorporate\ntreatment decisions in fairness assessments. Moreover, by intervening in\ntreatment decisions, we show that our framework effectively mitigates treatment\ndiscrimination from historical data to ensure fair risk score estimation and\n(non-binary) decision-making processes that benefit all stakeholders.", "published": "2025-03-28 14:06:35", "link": "http://arxiv.org/abs/2503.22454v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Training Large Language Models for Advanced Typosquatting Detection", "abstract": "Typosquatting is a long-standing cyber threat that exploits human error in\ntyping URLs to deceive users, distribute malware, and conduct phishing attacks.\nWith the proliferation of domain names and new Top-Level Domains (TLDs),\ntyposquatting techniques have grown more sophisticated, posing significant\nrisks to individuals, businesses, and national cybersecurity infrastructure.\nTraditional detection methods primarily focus on well-known impersonation\npatterns, leaving gaps in identifying more complex attacks. This study\nintroduces a novel approach leveraging large language models (LLMs) to enhance\ntyposquatting detection. By training an LLM on character-level transformations\nand pattern-based heuristics rather than domain-specific data, a more adaptable\nand resilient detection mechanism develops. Experimental results indicate that\nthe Phi-4 14B model outperformed other tested models when properly fine tuned\nachieving a 98% accuracy rate with only a few thousand training samples. This\nresearch highlights the potential of LLMs in cybersecurity applications,\nspecifically in mitigating domain-based deception tactics, and provides\ninsights into optimizing machine learning strategies for threat detection.", "published": "2025-03-28 13:16:27", "link": "http://arxiv.org/abs/2503.22406v1", "categories": ["cs.CR", "cs.AI", "cs.NI"], "primary_category": "cs.CR"}
{"title": "Scalable heliostat surface predictions from focal spots: Sim-to-Real transfer of inverse Deep Learning Raytracing", "abstract": "Concentrating Solar Power (CSP) plants are a key technology in the transition\ntoward sustainable energy. A critical factor for their safe and efficient\noperation is the distribution of concentrated solar flux on the receiver.\nHowever, flux distributions from individual heliostats are sensitive to surface\nimperfections. Measuring these surfaces across many heliostats remains\nimpractical in real-world deployments. As a result, control systems often\nassume idealized heliostat surfaces, leading to suboptimal performance and\npotential safety risks. To address this, inverse Deep Learning Raytracing\n(iDLR) has been introduced as a novel method for inferring heliostat surface\nprofiles from target images recorded during standard calibration procedures. In\nthis work, we present the first successful Sim-to-Real transfer of iDLR,\nenabling accurate surface predictions directly from real-world target images.\nWe evaluate our method on 63 heliostats under real operational conditions. iDLR\nsurface predictions achieve a median mean absolute error (MAE) of 0.17 mm and\nshow good agreement with deflectometry ground truth in 84% of cases. When used\nin raytracing simulations, it enables flux density predictions with a mean\naccuracy of 90% compared to deflectometry over our dataset, and outperforms the\ncommonly used ideal heliostat surface assumption by 26%. We tested this\napproach in a challenging double-extrapolation scenario-involving unseen sun\npositions and receiver projection-and found that iDLR maintains high predictive\naccuracy, highlighting its generalization capabilities. Our results demonstrate\nthat iDLR is a scalable, automated, and cost-effective solution for integrating\nrealistic heliostat surface models into digital twins. This opens the door to\nimproved flux control, more precise performance modeling, and ultimately,\nenhanced efficiency and safety in future CSP plants.", "published": "2025-03-28 13:15:05", "link": "http://arxiv.org/abs/2504.03712v1", "categories": ["cs.CV", "cs.AI", "cs.CE", "cs.LG"], "primary_category": "cs.CV"}
{"title": "On-site estimation of battery electrochemical parameters via transfer learning based physics-informed neural network approach", "abstract": "This paper presents a novel physical parameter estimation framework for\non-site model characterization, using a two-phase modelling strategy with\nPhysics-Informed Neural Networks (PINNs) and transfer learning (TL). In the\nfirst phase, a PINN is trained using only the physical principles of the single\nparticle model (SPM) equations. In the second phase, the majority of the PINN\nparameters are frozen, while critical electrochemical parameters are set as\ntrainable and adjusted using real-world voltage profile data. The proposed\napproach significantly reduces computational costs, making it suitable for\nreal-time implementation on Battery Management Systems (BMS). Additionally, as\nthe initial phase does not require field data, the model is easy to deploy with\nminimal setup requirements. With the proposed methodology, we have been able to\neffectively estimate relevant electrochemical parameters with operating data.\nThis has been proved estimating diffusivities and active material volume\nfractions with charge data in different degradation conditions. The methodology\nis experimentally validated in a Raspberry Pi device using data from a standard\ncharge profile with a 3.89\\% relative accuracy estimating the active material\nvolume fractions of a NMC cell with 82.09\\% of its nominal capacity.", "published": "2025-03-28 13:06:41", "link": "http://arxiv.org/abs/2503.22396v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Endo-TTAP: Robust Endoscopic Tissue Tracking via Multi-Facet Guided Attention and Hybrid Flow-point Supervision", "abstract": "Accurate tissue point tracking in endoscopic videos is critical for\nrobotic-assisted surgical navigation and scene understanding, but remains\nchallenging due to complex deformations, instrument occlusion, and the scarcity\nof dense trajectory annotations. Existing methods struggle with long-term\ntracking under these conditions due to limited feature utilization and\nannotation dependence. We present Endo-TTAP, a novel framework addressing these\nchallenges through: (1) A Multi-Facet Guided Attention (MFGA) module that\nsynergizes multi-scale flow dynamics, DINOv2 semantic embeddings, and explicit\nmotion patterns to jointly predict point positions with uncertainty and\nocclusion awareness; (2) A two-stage curriculum learning strategy employing an\nAuxiliary Curriculum Adapter (ACA) for progressive initialization and hybrid\nsupervision. Stage I utilizes synthetic data with optical flow ground truth for\nuncertainty-occlusion regularization, while Stage II combines unsupervised flow\nconsistency and semi-supervised learning with refined pseudo-labels from\noff-the-shelf trackers. Extensive validation on two MICCAI Challenge datasets\nand our collected dataset demonstrates that Endo-TTAP achieves state-of-the-art\nperformance in tissue point tracking, particularly in scenarios characterized\nby complex endoscopic conditions. The source code and dataset will be available\nat https://anonymous.4open.science/r/Endo-TTAP-36E5.", "published": "2025-03-28 13:00:07", "link": "http://arxiv.org/abs/2503.22394v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ViSketch-GPT: Collaborative Multi-Scale Feature Extraction for Sketch Recognition and Generation", "abstract": "Understanding the nature of human sketches is challenging because of the wide\nvariation in how they are created. Recognizing complex structural patterns\nimproves both the accuracy in recognizing sketches and the fidelity of the\ngenerated sketches. In this work, we introduce ViSketch-GPT, a novel algorithm\ndesigned to address these challenges through a multi-scale context extraction\napproach. The model captures intricate details at multiple scales and combines\nthem using an ensemble-like mechanism, where the extracted features work\ncollaboratively to enhance the recognition and generation of key details\ncrucial for classification and generation tasks.\n  The effectiveness of ViSketch-GPT is validated through extensive experiments\non the QuickDraw dataset. Our model establishes a new benchmark, significantly\noutperforming existing methods in both classification and generation tasks,\nwith substantial improvements in accuracy and the fidelity of generated\nsketches.\n  The proposed algorithm offers a robust framework for understanding complex\nstructures by extracting features that collaborate to recognize intricate\ndetails, enhancing the understanding of structures like sketches and making it\na versatile tool for various applications in computer vision and machine\nlearning.", "published": "2025-03-28 12:28:30", "link": "http://arxiv.org/abs/2503.22374v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ForcePose: A Deep Learning Approach for Force Calculation Based on Action Recognition Using MediaPipe Pose Estimation Combined with Object Detection", "abstract": "Force estimation in human-object interactions is crucial for various fields\nlike ergonomics, physical therapy, and sports science. Traditional methods\ndepend on specialized equipment such as force plates and sensors, which makes\naccurate assessments both expensive and restricted to laboratory settings. In\nthis paper, we introduce ForcePose, a novel deep learning framework that\nestimates applied forces by combining human pose estimation with object\ndetection. Our approach leverages MediaPipe for skeletal tracking and SSD\nMobileNet for object recognition to create a unified representation of\nhuman-object interaction. We've developed a specialized neural network that\nprocesses both spatial and temporal features to predict force magnitude and\ndirection without needing any physical sensors. After training on our dataset\nof 850 annotated videos with corresponding force measurements, our model\nachieves a mean absolute error of 5.83 N in force magnitude and 7.4 degrees in\nforce direction. When compared to existing computer vision approaches, our\nmethod performs 27.5% better while still offering real-time performance on\nstandard computing hardware. ForcePose opens up new possibilities for force\nanalysis in diverse real-world scenarios where traditional measurement tools\nare impractical or intrusive. This paper discusses our methodology, the dataset\ncreation process, evaluation metrics, and potential applications across\nrehabilitation, ergonomics assessment, and athletic performance analysis.", "published": "2025-03-28 12:13:56", "link": "http://arxiv.org/abs/2503.22363v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Shapley Revisited: Tractable Responsibility Measures for Query Answers", "abstract": "The Shapley value, originating from cooperative game theory, has been\nemployed to define responsibility measures that quantify the contributions of\ndatabase facts to obtaining a given query answer. For non-numeric queries, this\nis done by considering a cooperative game whose players are the facts and whose\nwealth function assigns 1 or 0 to each subset of the database, depending on\nwhether the query answer holds in the given subset. While conceptually simple,\nthis approach suffers from a notable drawback: the problem of computing such\nShapley values is #P-hard in data complexity, even for simple conjunctive\nqueries. This motivates us to revisit the question of what constitutes a\nreasonable responsibility measure and to introduce a new family of\nresponsibility measures -- weighted sums of minimal supports (WSMS) -- which\nsatisfy intuitive properties. Interestingly, while the definition of WSMSs is\nsimple and bears no obvious resemblance to the Shapley value formula, we prove\nthat every WSMS measure can be equivalently seen as the Shapley value of a\nsuitably defined cooperative game. Moreover, WSMS measures enjoy tractable data\ncomplexity for a large class of queries, including all unions of conjunctive\nqueries. We further explore the combined complexity of WSMS computation and\nestablish (in)tractability results for various subclasses of conjunctive\nqueries.", "published": "2025-03-28 11:52:26", "link": "http://arxiv.org/abs/2503.22358v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "CPPO: Accelerating the Training of Group Relative Policy Optimization-Based Reasoning Models", "abstract": "This paper introduces Completion Pruning Policy Optimization (CPPO) to\naccelerate the training of reasoning models based on Group Relative Policy\nOptimization (GRPO). GRPO, while effective, incurs high training costs due to\nthe need for sampling multiple completions for each question. Our experiment\nand theoretical analysis reveals that the number of completions impacts model\naccuracy yet increases training time multiplicatively, and not all completions\ncontribute equally to policy training -- their contribution depends on their\nrelative advantage. To address these issues, we propose CPPO, which prunes\ncompletions with low absolute advantages, significantly reducing the number\nneeded for gradient calculation and updates. Additionally, we introduce a\ndynamic completion allocation strategy to maximize GPU utilization by\nincorporating additional questions, further enhancing training efficiency.\nExperimental results demonstrate that CPPO achieves up to $8.32\\times$ speedup\non GSM8K and $3.51\\times$ on Math while preserving or even enhancing the\naccuracy compared to the original GRPO. We release our code at\nhttps://github.com/lzhxmu/CPPO.", "published": "2025-03-28 11:30:05", "link": "http://arxiv.org/abs/2503.22342v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "VoteFlow: Enforcing Local Rigidity in Self-Supervised Scene Flow", "abstract": "Scene flow estimation aims to recover per-point motion from two adjacent\nLiDAR scans. However, in real-world applications such as autonomous driving,\npoints rarely move independently of others, especially for nearby points\nbelonging to the same object, which often share the same motion. Incorporating\nthis locally rigid motion constraint has been a key challenge in\nself-supervised scene flow estimation, which is often addressed by\npost-processing or appending extra regularization. While these approaches are\nable to improve the rigidity of predicted flows, they lack an architectural\ninductive bias for local rigidity within the model structure, leading to\nsuboptimal learning efficiency and inferior performance. In contrast, we\nenforce local rigidity with a lightweight add-on module in neural network\ndesign, enabling end-to-end learning. We design a discretized voting space that\naccommodates all possible translations and then identify the one shared by\nnearby points by differentiable voting. Additionally, to ensure computational\nefficiency, we operate on pillars rather than points and learn representative\nfeatures for voting per pillar. We plug the Voting Module into popular model\ndesigns and evaluate its benefit on Argoverse 2 and Waymo datasets. We\noutperform baseline works with only marginal compute overhead. Code is\navailable at https://github.com/tudelft-iv/VoteFlow.", "published": "2025-03-28 11:06:27", "link": "http://arxiv.org/abs/2503.22328v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Post-Incorporating Code Structural Knowledge into LLMs via In-Context Learning for Code Translation", "abstract": "Code translation migrates codebases across programming languages. Recently,\nlarge language models (LLMs) have achieved significant advancements in software\nmining. However, handling the syntactic structure of source code remains a\nchallenge. Classic syntax-aware methods depend on intricate model architectures\nand loss functions, rendering their integration into LLM training\nresource-intensive. This paper employs in-context learning (ICL), which\ndirectly integrates task exemplars into the input context, to post-incorporate\ncode structural knowledge into pre-trained LLMs. We revisit exemplar selection\nin ICL from an information-theoretic perspective, proposing that list-wise\nselection based on information coverage is more precise and general objective\nthan traditional methods based on combining similarity and diversity. To\naddress the challenges of quantifying information coverage, we introduce a\nsurrogate measure, Coverage of Abstract Syntax Tree (CAST). Furthermore, we\nformulate the NP-hard CAST maximization for exemplar selection and prove that\nit is a standard submodular maximization problem. Therefore, we propose a\ngreedy algorithm for CAST submodular maximization, which theoretically\nguarantees a (1-1/e)-approximate solution in polynomial time complexity. Our\nmethod is the first training-free and model-agnostic approach to\npost-incorporate code structural knowledge into existing LLMs at test time.\nExperimental results show that our method significantly improves LLMs\nperformance and reveals two meaningful insights: 1) Code structural knowledge\ncan be effectively post-incorporated into pre-trained LLMs during inference,\ndespite being overlooked during training; 2) Scaling up model size or training\ndata does not lead to the emergence of code structural knowledge, underscoring\nthe necessity of explicitly considering code syntactic structure.", "published": "2025-03-28 10:59:42", "link": "http://arxiv.org/abs/2503.22776v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "AH-GS: Augmented 3D Gaussian Splatting for High-Frequency Detail Representation", "abstract": "The 3D Gaussian Splatting (3D-GS) is a novel method for scene representation\nand view synthesis. Although Scaffold-GS achieves higher quality real-time\nrendering compared to the original 3D-GS, its fine-grained rendering of the\nscene is extremely dependent on adequate viewing angles. The spectral bias of\nneural network learning results in Scaffold-GS's poor ability to perceive and\nlearn high-frequency information in the scene. In this work, we propose\nenhancing the manifold complexity of input features and using network-based\nfeature map loss to improve the image reconstruction quality of 3D-GS models.\nWe introduce AH-GS, which enables 3D Gaussians in structurally complex regions\nto obtain higher-frequency encodings, allowing the model to more effectively\nlearn the high-frequency information of the scene. Additionally, we incorporate\nhigh-frequency reinforce loss to further enhance the model's ability to capture\ndetailed frequency information. Our result demonstrates that our model\nsignificantly improves rendering fidelity, and in specific scenarios (e.g.,\nMipNeRf360-garden), our method exceeds the rendering quality of Scaffold-GS in\njust 15K iterations.", "published": "2025-03-28 10:57:33", "link": "http://arxiv.org/abs/2503.22324v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Machine Learning Models for Soil Parameter Prediction Based on Satellite, Weather, Clay and Yield Data", "abstract": "Efficient nutrient management and precise fertilization are essential for\nadvancing modern agriculture, particularly in regions striving to optimize crop\nyields sustainably. The AgroLens project endeavors to address this challenge by\ndevelop ing Machine Learning (ML)-based methodologies to predict soil nutrient\nlevels without reliance on laboratory tests. By leveraging state of the art\ntechniques, the project lays a foundation for acionable insights to improve\nagricultural productivity in resource-constrained areas, such as Africa. The\napproach begins with the development of a robust European model using the LUCAS\nSoil dataset and Sentinel-2 satellite imagery to estimate key soil properties,\nincluding phosphorus, potassium, nitrogen, and pH levels. This model is then\nenhanced by integrating supplementary features, such as weather data, harvest\nrates, and Clay AI-generated embeddings. This report details the methodological\nframework, data preprocessing strategies, and ML pipelines employed in this\nproject. Advanced algorithms, including Random Forests, Extreme Gradient\nBoosting (XGBoost), and Fully Connected Neural Networks (FCNN), were\nimplemented and finetuned for precise nutrient prediction. Results showcase\nrobust model performance, with root mean square error values meeting stringent\naccuracy thresholds. By establishing a reproducible and scalable pipeline for\nsoil nutrient prediction, this research paves the way for transformative\nagricultural applications, including precision fertilization and improved\nresource allocation in underresourced regions like Africa.", "published": "2025-03-28 09:44:32", "link": "http://arxiv.org/abs/2503.22276v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Make Some Noise: Towards LLM audio reasoning and generation using sound tokens", "abstract": "Integrating audio comprehension and generation into large language models\n(LLMs) remains challenging due to the continuous nature of audio and the\nresulting high sampling rates. Here, we introduce a novel approach that\ncombines Variational Quantization with Conditional Flow Matching to convert\naudio into ultra-low bitrate discrete tokens of 0.23kpbs, allowing for seamless\nintegration with text tokens in LLMs. We fine-tuned a pretrained text-based LLM\nusing Low-Rank Adaptation (LoRA) to assess its effectiveness in achieving true\nmultimodal capabilities, i.e., audio comprehension and generation. Our\ntokenizer outperforms a traditional VQ-VAE across various datasets with diverse\nacoustic events. Despite the substantial loss of fine-grained details through\naudio tokenization, our multimodal LLM trained with discrete tokens achieves\ncompetitive results in audio comprehension with state-of-the-art methods,\nthough audio generation is poor. Our results highlight the need for larger,\nmore diverse datasets and improved evaluation metrics to advance multimodal LLM\nperformance.", "published": "2025-03-28 09:43:47", "link": "http://arxiv.org/abs/2503.22275v1", "categories": ["eess.AS", "cs.AI", "cs.SD", "68T07", "I.2.7; I.2.6; H.5.5"], "primary_category": "eess.AS"}
{"title": "Beyond the Script: Testing LLMs for Authentic Patient Communication Styles in Healthcare", "abstract": "Effective patient communication is pivotal in healthcare, yet traditional\nmedical training often lacks exposure to diverse, challenging interpersonal\ndynamics. To bridge this gap, this study proposes the use of Large Language\nModels (LLMs) to simulate authentic patient communication styles, specifically\nthe \"accuser\" and \"rationalizer\" personas derived from the Satir model, while\nalso ensuring multilingual applicability to accommodate diverse cultural\ncontexts and enhance accessibility for medical professionals. Leveraging\nadvanced prompt engineering, including behavioral prompts, author's notes, and\nstubbornness mechanisms, we developed virtual patients (VPs) that embody\nnuanced emotional and conversational traits. Medical professionals evaluated\nthese VPs, rating their authenticity (accuser: $3.8 \\pm 1.0$; rationalizer:\n$3.7 \\pm 0.8$ on a 5-point Likert scale (from one to five)) and correctly\nidentifying their styles. Emotion analysis revealed distinct profiles: the\naccuser exhibited pain, anger, and distress, while the rationalizer displayed\ncontemplation and calmness, aligning with predefined, detailed patient\ndescription including medical history. Sentiment scores (on a scale from zero\nto nine) further validated these differences in the communication styles, with\nthe accuser adopting negative ($3.1 \\pm 0.6$) and the rationalizer more neutral\n($4.0 \\pm 0.4$) tone. These results underscore LLMs' capability to replicate\ncomplex communication styles, offering transformative potential for medical\neducation. This approach equips trainees to navigate challenging clinical\nscenarios by providing realistic, adaptable patient interactions, enhancing\nempathy and diagnostic acumen. Our findings advocate for AI-driven tools as\nscalable, cost-effective solutions to cultivate nuanced communication skills,\nsetting a foundation for future innovations in healthcare training.", "published": "2025-03-28 09:04:10", "link": "http://arxiv.org/abs/2503.22250v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Agent-Centric Personalized Multiple Clustering with Multi-Modal LLMs", "abstract": "Personalized multiple clustering aims to generate diverse partitions of a\ndataset based on different user-specific aspects, rather than a single\nclustering. It has recently drawn research interest for accommodating varying\nuser preferences. Recent approaches primarily use CLIP embeddings with proxy\nlearning to extract representations biased toward user clustering preferences.\nHowever, CLIP primarily focuses on coarse image-text alignment, lacking a deep\ncontextual understanding of user interests. To overcome these limitations, we\npropose an agent-centric personalized clustering framework that leverages\nmulti-modal large language models (MLLMs) as agents to comprehensively traverse\na relational graph to search for clusters based on user interests. Due to the\nadvanced reasoning mechanism of MLLMs, the obtained clusters align more closely\nwith user-defined criteria than those obtained from CLIP-based representations.\nTo reduce computational overhead, we shorten the agents' traversal path by\nconstructing a relational graph using user-interest-biased embeddings extracted\nby MLLMs. A large number of weakly connected edges can be filtered out based on\nembedding similarity, facilitating an efficient traversal search for agents.\nExperimental results show that the proposed method achieves NMI scores of\n0.9667 and 0.9481 on the Card Order and Card Suits benchmarks, respectively,\nlargely improving the SOTA model by over 140%.", "published": "2025-03-28 08:45:15", "link": "http://arxiv.org/abs/2503.22241v2", "categories": ["cs.AI", "68T07, 68T05, 05C82"], "primary_category": "cs.AI"}
{"title": "WeatherMesh-3: Fast and accurate operational global weather forecasting", "abstract": "We present WeatherMesh-3 (WM-3), an operational transformer-based global\nweather forecasting system that improves the state of the art in both accuracy\nand computational efficiency. We introduce the following advances: 1) a latent\nrollout that enables arbitrary-length predictions in latent space without\nintermediate encoding or decoding; and 2) a modular architecture that flexibly\nutilizes mixed-horizon processors and encodes multiple real-time analyses to\ncreate blended initial conditions. WM-3 generates 14-day global forecasts at\n0.25-degree resolution in 12 seconds on a single RTX 4090. This represents a\n>100,000-fold speedup over traditional NWP approaches while achieving superior\naccuracy with up to 37.7% improvement in RMSE over operational models,\nrequiring only a single consumer-grade GPU for deployment. We aim for WM-3 to\ndemocratize weather forecasting by providing an accessible, lightweight model\nfor operational use while pushing the performance boundaries of machine\nlearning-based weather prediction.", "published": "2025-03-28 08:37:59", "link": "http://arxiv.org/abs/2503.22235v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MFH: A Multi-faceted Heuristic Algorithm Selection Approach for Software Verification", "abstract": "Currently, many verification algorithms are available to improve the\nreliability of software systems. Selecting the appropriate verification\nalgorithm typically demands domain expertise and non-trivial manpower. An\nautomated algorithm selector is thus desired. However, existing selectors,\neither depend on machine-learned strategies or manually designed heuristics,\nencounter issues such as reliance on high-quality samples with algorithm labels\nand limited scalability. In this paper, an automated algorithm selection\napproach, namely MFH, is proposed for software verification. Our approach\nleverages the heuristics that verifiers producing correct results typically\nimplement certain appropriate algorithms, and the supported algorithms by these\nverifiers indirectly reflect which ones are potentially applicable.\nSpecifically, MFH embeds the code property graph (CPG) of a semantic-preserving\ntransformed program to enhance the robustness of the prediction model.\nFurthermore, our approach decomposes the selection task into the sub-tasks of\npredicting potentially applicable algorithms and matching the most appropriate\nverifiers. Additionally, MFH also introduces a feedback loop on incorrect\npredictions to improve model prediction accuracy. We evaluate MFH on 20\nverifiers and over 15,000 verification tasks. Experimental results demonstrate\nthe effectiveness of MFH, achieving a prediction accuracy of 91.47% even\nwithout ground truth algorithm labels provided during the training phase.\nMoreover, the prediction accuracy decreases only by 0.84% when introducing 10\nnew verifiers, indicating the strong scalability of the proposed approach.", "published": "2025-03-28 08:21:00", "link": "http://arxiv.org/abs/2503.22228v1", "categories": ["cs.SE", "cs.AI", "cs.LG", "I.2.6; I.2.11; D.2.4"], "primary_category": "cs.SE"}
{"title": "Sell It Before You Make It: Revolutionizing E-Commerce with Personalized AI-Generated Items", "abstract": "E-commerce has revolutionized retail, yet its traditional workflows remain\ninefficient, with significant time and resource costs tied to product design\nand manufacturing inventory. This paper introduces a novel system deployed at\nAlibaba that leverages AI-generated items (AIGI) to address these challenges\nwith personalized text-to-image generation for e-commercial product design.\nAIGI enables an innovative business mode called \"sell it before you make it\",\nwhere merchants can design fashion items and generate photorealistic images\nwith digital models based on textual descriptions. Only when the items have\nreceived a certain number of orders, do the merchants start to produce them,\nwhich largely reduces reliance on physical prototypes and thus accelerates time\nto market. For such a promising application, we identify the underlying key\nscientific challenge, i.e., capturing the users' group-level personalized\npreferences towards multiple generated candidate images. To this end, we\npropose a Personalized Group-Level Preference Alignment Framework for Diffusion\nModels (i.e., PerFusion). We first design PerFusion Reward Model for user\npreference estimation with a feature-crossing-based personalized plug-in. Then\nwe develop PerFusion with a personalized adaptive network to model diverse\npreferences across users, and meanwhile derive the group-level preference\noptimization objective to capture the comparative behaviors among multiple\ncandidates. Both offline and online experiments demonstrate the effectiveness\nof our proposed algorithm. The AI-generated items have achieved over 13%\nrelative improvements for both click-through rate and conversion rate compared\nto their human-designed counterparts, validating the revolutionary potential of\nAI-generated items for e-commercial platforms.", "published": "2025-03-28 07:00:33", "link": "http://arxiv.org/abs/2503.22182v1", "categories": ["cs.IR", "cs.AI", "cs.CV"], "primary_category": "cs.IR"}
{"title": "e-person Architecture and Framework for Human-AI Co-adventure Relationship", "abstract": "This paper proposes the e-person architecture for constructing a unified and\nincremental development of AI ethics. The e-person architecture takes the\nreduction of uncertainty through collaborative cognition and action with others\nas a unified basis for ethics. By classifying and defining uncertainty along\ntwo axes - (1) first, second, and third person perspectives, and (2) the\ndifficulty of inference based on the depth of information - we support the\ndevelopment of unified and incremental development of AI ethics. In addition,\nwe propose the e-person framework based on the free energy principle, which\nconsiders the reduction of uncertainty as a unifying principle of brain\nfunction, with the aim of implementing the e-person architecture, and we show\nour previous works and future challenges based on the proposed framework.", "published": "2025-03-28 06:54:44", "link": "http://arxiv.org/abs/2503.22181v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "AdaRank: Adaptive Rank Pruning for Enhanced Model Merging", "abstract": "Model merging has emerged as a promising approach for unifying independently\nfine-tuned models into an integrated framework, significantly enhancing\ncomputational efficiency in multi-task learning. Recently, several SVD-based\ntechniques have been introduced to exploit low-rank structures for enhanced\nmerging, but their reliance on such manually designed rank selection often\nleads to cross-task interference and suboptimal performance. In this paper, we\npropose AdaRank, a novel model merging framework that adaptively selects the\nmost beneficial singular directions of task vectors to merge multiple models.\nWe empirically show that the dominant singular components of task vectors can\ncause critical interference with other tasks, and that naive truncation across\ntasks and layers degrades performance. In contrast, AdaRank dynamically prunes\nthe singular components that cause interference and offers an optimal amount of\ninformation to each task vector by learning to prune ranks during test-time via\nentropy minimization. Our analysis demonstrates that such method mitigates\ndetrimental overlaps among tasks, while empirical results show that AdaRank\nconsistently achieves state-of-the-art performance with various backbones and\nnumber of tasks, reducing the performance gap between fine-tuned models to\nnearly 1%.", "published": "2025-03-28 06:49:06", "link": "http://arxiv.org/abs/2503.22178v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "PharmAgents: Building a Virtual Pharma with Large Language Model Agents", "abstract": "The discovery of novel small molecule drugs remains a critical scientific\nchallenge with far-reaching implications for treating diseases and advancing\nhuman health. Traditional drug development--especially for small molecule\ntherapeutics--is a highly complex, resource-intensive, and time-consuming\nprocess that requires multidisciplinary collaboration. Recent breakthroughs in\nartificial intelligence (AI), particularly the rise of large language models\n(LLMs), present a transformative opportunity to streamline and accelerate this\nprocess. In this paper, we introduce PharmAgents, a virtual pharmaceutical\necosystem driven by LLM-based multi-agent collaboration. PharmAgents simulates\nthe full drug discovery workflow--from target discovery to preclinical\nevaluation--by integrating explainable, LLM-driven agents equipped with\nspecialized machine learning models and computational tools. Through structured\nknowledge exchange and automated optimization, PharmAgents identifies potential\ntherapeutic targets, discovers promising lead compounds, enhances binding\naffinity and key molecular properties, and performs in silico analyses of\ntoxicity and synthetic feasibility. Additionally, the system supports\ninterpretability, agent interaction, and self-evolvement, enabling it to refine\nfuture drug designs based on prior experience. By showcasing the potential of\nLLM-powered multi-agent systems in drug discovery, this work establishes a new\nparadigm for autonomous, explainable, and scalable pharmaceutical research,\nwith future extensions toward comprehensive drug lifecycle management.", "published": "2025-03-28 06:02:53", "link": "http://arxiv.org/abs/2503.22164v2", "categories": ["q-bio.BM", "cs.AI"], "primary_category": "q-bio.BM"}
{"title": "EgoToM: Benchmarking Theory of Mind Reasoning from Egocentric Videos", "abstract": "We introduce EgoToM, a new video question-answering benchmark that extends\nTheory-of-Mind (ToM) evaluation to egocentric domains. Using a causal ToM\nmodel, we generate multi-choice video QA instances for the Ego4D dataset to\nbenchmark the ability to predict a camera wearer's goals, beliefs, and next\nactions. We study the performance of both humans and state of the art\nmultimodal large language models (MLLMs) on these three interconnected\ninference problems. Our evaluation shows that MLLMs achieve close to\nhuman-level accuracy on inferring goals from egocentric videos. However, MLLMs\n(including the largest ones we tested with over 100B parameters) fall short of\nhuman performance when inferring the camera wearers' in-the-moment belief\nstates and future actions that are most consistent with the unseen video\nfuture. We believe that our results will shape the future design of an\nimportant class of egocentric digital assistants which are equipped with a\nreasonable model of the user's internal mental states.", "published": "2025-03-28 05:10:59", "link": "http://arxiv.org/abs/2503.22152v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "When Autonomy Breaks: The Hidden Existential Risk of AI", "abstract": "AI risks are typically framed around physical threats to humanity, a loss of\ncontrol or an accidental error causing humanity's extinction. However, I argue\nin line with the gradual disempowerment thesis, that there is an\nunderappreciated risk in the slow and irrevocable decline of human autonomy. As\nAI starts to outcompete humans in various areas of life, a tipping point will\nbe reached where it no longer makes sense to rely on human decision-making,\ncreativity, social care or even leadership.\n  What may follow is a process of gradual de-skilling, where we lose skills\nthat we currently take for granted. Traditionally, it is argued that AI will\ngain human skills over time, and that these skills are innate and immutable in\nhumans. By contrast, I argue that humans may lose such skills as critical\nthinking, decision-making and even social care in an AGI world. The biggest\nthreat to humanity is therefore not that machines will become more like humans,\nbut that humans will become more like machines.", "published": "2025-03-28 05:10:32", "link": "http://arxiv.org/abs/2503.22151v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "GroundHog: Revolutionizing GLDAS Groundwater Storage Downscaling for Enhanced Recharge Estimation in Bangladesh", "abstract": "Long-term groundwater level (GWL) measurement is vital for effective\npolicymaking and recharge estimation using annual maxima and minima. However,\ncurrent methods prioritize short-term predictions and lack multi-year\napplicability, limiting their utility. Moreover, sparse in-situ measurements\nlead to reliance on low-resolution satellite data like GLDAS as the ground\ntruth for Machine Learning models, further constraining accuracy. To overcome\nthese challenges, we first develop an ML model to mitigate data gaps, achieving\n$R^2$ scores of 0.855 and 0.963 for maximum and minimum GWL predictions,\nrespectively. Subsequently, using these predictions and well observations as\nground truth, we train an Upsampling Model that uses low-resolution (25 km)\nGLDAS data as input to produce high-resolution (2 km) GWLs, achieving an\nexcellent $R^2$ score of 0.96. Our approach successfully upscales GLDAS data\nfor 2003-2024, allowing high-resolution recharge estimations and revealing\ncritical trends for proactive resource management. Our method allows upsampling\nof groundwater storage (GWS) from GLDAS to high-resolution GWLs for any points\nindependently of officially curated piezometer data, making it a valuable tool\nfor decision-making.", "published": "2025-03-28 04:56:01", "link": "http://arxiv.org/abs/2503.22771v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Self-Supervised Learning of a Foundation Model for Analog Layout Design Automation", "abstract": "We propose a UNet-based foundation model and its self-supervised learning\nmethod to address two key challenges: 1) lack of qualified annotated analog\nlayout data, and 2) excessive variety in analog layout design tasks. For\nself-supervised learning, we propose random patch sampling and random masking\ntechniques automatically to obtain enough training data from a small\nunannotated layout dataset. The obtained data are greatly augmented, less\nbiased, equally sized, and contain enough information for excessive varieties\nof qualified layout patterns. By pre-training with the obtained data, the\nproposed foundation model can learn implicit general knowledge on layout\npatterns so that it can be fine-tuned for various downstream layout tasks with\nsmall task-specific datasets. Fine-tuning provides an efficient and\nconsolidated methodology for diverse downstream tasks, reducing the enormous\nhuman effort to develop a model per task separately. In experiments, the\nfoundation model was pre-trained using 324,000 samples obtained from 6\nsilicon-proved manually designed analog circuits, then it was fine-tuned for\nthe five example downstream tasks: generating contacts, vias, dummy fingers,\nN-wells, and metal routings. The fine-tuned models successfully performed these\ntasks for more than one thousand unseen layout inputs, generating DRC/LVS-clean\nlayouts for 96.6% of samples. Compared with training the model from scratch for\nthe metal routing task, fine-tuning required only 1/8 of the data to achieve\nthe same dice score of 0.95. With the same data, fine-tuning achieved a 90%\nlower validation loss and a 40% higher benchmark score than training from\nscratch.", "published": "2025-03-28 04:37:33", "link": "http://arxiv.org/abs/2503.22143v1", "categories": ["eess.SP", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Integrating Artificial Intelligence with Human Expertise: An In-depth Analysis of ChatGPT's Capabilities in Generating Metamorphic Relations", "abstract": "Context: This paper provides an in-depth examination of the generation and\nevaluation of Metamorphic Relations (MRs) using GPT models developed by OpenAI,\nwith a particular focus on the capabilities of GPT-4 in software testing\nenvironments.\n  Objective: The aim is to examine the quality of MRs produced by GPT-3.5 and\nGPT-4 for a specific System Under Test (SUT) adopted from an earlier study, and\nto introduce and apply an improved set of evaluation criteria for a diverse\nrange of SUTs.\n  Method: The initial phase evaluates MRs generated by GPT-3.5 and GPT-4 using\ncriteria from a prior study, followed by an application of an enhanced\nevaluation framework on MRs created by GPT-4 for a diverse range of nine SUTs,\nvarying from simple programs to complex systems incorporating AI/ML components.\nA custom-built GPT evaluator, alongside human evaluators, assessed the MRs,\nenabling a direct comparison between automated and human evaluation methods.\n  Results: The study finds that GPT-4 outperforms GPT-3.5 in generating\naccurate and useful MRs. With the advanced evaluation criteria, GPT-4\ndemonstrates a significant ability to produce high-quality MRs across a wide\nrange of SUTs, including complex systems incorporating AI/ML components.\n  Conclusions: GPT-4 exhibits advanced capabilities in generating MRs suitable\nfor various applications. The research underscores the growing potential of AI\nin software testing, particularly in the generation and evaluation of MRs, and\npoints towards the complementarity of human and AI skills in this domain.", "published": "2025-03-28 04:31:32", "link": "http://arxiv.org/abs/2503.22141v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Sharpe Ratio-Guided Active Learning for Preference Optimization in RLHF", "abstract": "Reinforcement learning from human feedback (RLHF) has become a cornerstone of\nthe training and alignment pipeline for large language models (LLMs). Recent\nadvances, such as direct preference optimization (DPO), have simplified the\npreference learning step. However, collecting preference data remains a\nchallenging and costly process, often requiring expert annotation. This cost\ncan be mitigated by carefully selecting the data points presented for\nannotation. In this work, we propose an active learning approach to efficiently\nselect prompt and preference pairs using a risk assessment strategy based on\nthe Sharpe Ratio. To address the challenge of unknown preferences prior to\nannotation, our method evaluates the gradients of all potential preference\nannotations to assess their impact on model updates. These gradient-based\nevaluations enable risk assessment of data points regardless of the annotation\noutcome. By leveraging the DPO loss derivations, we derive a closed-form\nexpression for computing these Sharpe ratios on a per-tuple basis, ensuring our\napproach remains both tractable and computationally efficient. We also\nintroduce two variants of our method, each making different assumptions about\nprior information. Experimental results demonstrate that our method outperforms\nthe baseline by up to 5% in win rates against the chosen completion with\nlimited human preference data across several language models and real-world\ndatasets.", "published": "2025-03-28 04:22:53", "link": "http://arxiv.org/abs/2503.22137v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "MediTools -- Medical Education Powered by LLMs", "abstract": "Artificial Intelligence (AI) has been advancing rapidly and with the advent\nof large language models (LLMs) in late 2022, numerous opportunities have\nemerged for adopting this technology across various domains, including\nmedicine. These innovations hold immense potential to revolutionize and\nmodernize medical education. Our research project leverages large language\nmodels to enhance medical education and address workflow challenges through the\ndevelopment of MediTools - AI Medical Education. This prototype application\nfocuses on developing interactive tools that simulate real-life clinical\nscenarios, provide access to medical literature, and keep users updated with\nthe latest medical news. Our first tool is a dermatology case simulation tool\nthat uses real patient images depicting various dermatological conditions and\nenables interaction with LLMs acting as virtual patients. This platform allows\nusers to practice their diagnostic skills and enhance their clinical\ndecision-making abilities. The application also features two additional tools:\nan AI-enhanced PubMed tool for engaging with LLMs to gain deeper insights into\nresearch papers, and a Google News tool that offers LLM generated summaries of\narticles for various medical specialties. A comprehensive survey has been\nconducted among medical professionals and students to gather initial feedback\non the effectiveness and user satisfaction of MediTools, providing insights for\nfurther development and refinement of the application. This research\ndemonstrates the potential of AI-driven tools in transforming and\nrevolutionizing medical education, offering a scalable and interactive platform\nfor continuous learning and skill development.", "published": "2025-03-28 03:57:32", "link": "http://arxiv.org/abs/2503.22769v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "How Well Can Vison-Language Models Understand Humans' Intention? An Open-ended Theory of Mind Question Evaluation Benchmark", "abstract": "Vision Language Models (VLMs) have demonstrated strong reasoning capabilities\nin Visual Question Answering (VQA) tasks; However, their ability to perform\nTheory of Mind (ToM) tasks such as accurately inferring human intentions,\nbeliefs, and other mental states remains underexplored. In this work, we\npropose an open-ended question framework to comprehensively evaluate VLMs'\nperformance across diverse categories of ToM tasks. We curated and annotated a\nbenchmark dataset composed of 30 images. We then assessed the performance of\nfour VLMs of varying sizes on this dataset. Our experimental results show that\nthe GPT-4 model outperformed all others, with only one smaller model,\nGPT-4o-mini, achieving comparable performance. Additionally, we observed that\nVLMs often struggle to accurately infer intentions in complex scenarios such as\nbullying or cheating. Moreover, our findings also reveal that smaller models\ncan sometimes infer correct intentions despite relying on incorrect visual\ncues.", "published": "2025-03-28 02:26:32", "link": "http://arxiv.org/abs/2503.22093v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Correlation-Attention Masked Temporal Transformer for User Identity Linkage Using Heterogeneous Mobility Data", "abstract": "With the rise of social media and Location-Based Social Networks (LBSN),\ncheck-in data across platforms has become crucial for User Identity Linkage\n(UIL). These data not only reveal users' spatio-temporal information but also\nprovide insights into their behavior patterns and interests. However,\ncross-platform identity linkage faces challenges like poor data quality, high\nsparsity, and noise interference, which hinder existing methods from extracting\ncross-platform user information. To address these issues, we propose a\nCorrelation-Attention Masked Transformer for User Identity Linkage Network\n(MT-Link), a transformer-based framework to enhance model performance by\nlearning spatio-temporal co-occurrence patterns of cross-platform users. Our\nmodel effectively captures spatio-temporal co-occurrence in cross-platform user\ncheck-in sequences. It employs a correlation attention mechanism to detect the\nspatio-temporal co-occurrence between user check-in sequences. Guided by\nattention weight maps, the model focuses on co-occurrence points while\nfiltering out noise, ultimately improving classification performance.\nExperimental results show that our model significantly outperforms\nstate-of-the-art baselines by 12.92%~17.76% and 5.80%~8.38% improvements in\nterms of Macro-F1 and Area Under Curve (AUC).", "published": "2025-03-28 02:18:16", "link": "http://arxiv.org/abs/2504.01979v1", "categories": ["cs.SI", "cs.AI"], "primary_category": "cs.SI"}
{"title": "Celler:A Genomic Language Model for Long-Tailed Single-Cell Annotation", "abstract": "Recent breakthroughs in single-cell technology have ushered in unparalleled\nopportunities to decode the molecular intricacy of intricate biological\nsystems, especially those linked to diseases unique to humans. However, these\nprogressions have also ushered in novel obstacles-specifically, the efficient\nannotation of extensive, long-tailed single-cell data pertaining to disease\nconditions. To effectively surmount this challenge, we introduce Celler, a\nstate-of-the-art generative pre-training model crafted specifically for the\nannotation of single-cell data. Celler incorporates two groundbreaking\nelements: First, we introduced the Gaussian Inflation (GInf) Loss function. By\ndynamically adjusting sample weights, GInf Loss significantly enhances the\nmodel's ability to learn from rare categories while reducing the risk of\noverfitting for common categories. Secondly, we introduce an innovative Hard\nData Mining (HDM) strategy into the training process, specifically targeting\nthe challenging-to-learn minority data samples, which significantly improved\nthe model's predictive accuracy. Additionally, to further advance research in\nthis field, we have constructed a large-scale single-cell dataset: Celler-75,\nwhich encompasses 40 million cells distributed across 80 human tissues and 75\nspecific diseases. This dataset provides critical support for comprehensively\nexploring the potential of single-cell technology in disease research. Our code\nis available at https://github.com/AI4science-ym/HiCeller.", "published": "2025-03-28 02:04:26", "link": "http://arxiv.org/abs/2504.00020v1", "categories": ["q-bio.GN", "cs.AI", "cs.LG"], "primary_category": "q-bio.GN"}
{"title": "Contrasting Low and High-Resolution Features for HER2 Scoring using Deep Learning", "abstract": "Breast cancer, the most common malignancy among women, requires precise\ndetection and classification for effective treatment. Immunohistochemistry\n(IHC) biomarkers like HER2, ER, and PR are critical for identifying breast\ncancer subtypes. However, traditional IHC classification relies on\npathologists' expertise, making it labor-intensive and subject to significant\ninter-observer variability. To address these challenges, this study introduces\nthe India Pathology Breast Cancer Dataset (IPD-Breast), comprising of 1,272 IHC\nslides (HER2, ER, and PR) aimed at automating receptor status classification.\nThe primary focus is on developing predictive models for HER2 3-way\nclassification (0, Low, High) to enhance prognosis. Evaluation of multiple deep\nlearning models revealed that an end-to-end ConvNeXt network utilizing\nlow-resolution IHC images achieved an AUC, F1, and accuracy of 91.79%, 83.52%,\nand 83.56%, respectively, for 3-way classification, outperforming patch-based\nmethods by over 5.35% in F1 score. This study highlights the potential of\nsimple yet effective deep learning techniques to significantly improve accuracy\nand reproducibility in breast cancer classification, supporting their\nintegration into clinical workflows for better patient outcomes.", "published": "2025-03-28 01:24:08", "link": "http://arxiv.org/abs/2503.22069v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Proposal for Networks Capable of Continual Learning", "abstract": "We analyze the ability of computational units to retain past responses after\nparameter updates, a key property for system-wide continual learning. Neural\nnetworks trained with gradient descent lack this capability, prompting us to\npropose Modelleyen, an alternative approach with inherent response\npreservation. We demonstrate through experiments on modeling the dynamics of a\nsimple environment and on MNIST that, despite increased computational\ncomplexity and some representational limitations at its current stage,\nModelleyen achieves continual learning without relying on sample replay or\npredefined task boundaries.", "published": "2025-03-28 01:23:18", "link": "http://arxiv.org/abs/2503.22068v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Diagnosis of Pulmonary Hypertension by Integrating Multimodal Data with a Hybrid Graph Convolutional and Transformer Network", "abstract": "Early and accurate diagnosis of pulmonary hypertension (PH) is essential for\noptimal patient management. Differentiating between pre-capillary and\npost-capillary PH is critical for guiding treatment decisions. This study\ndevelops and validates a deep learning-based diagnostic model for PH, designed\nto classify patients as non-PH, pre-capillary PH, or post-capillary PH. This\nretrospective study analyzed data from 204 patients (112 with pre-capillary PH,\n32 with post-capillary PH, and 60 non-PH controls) at the First Affiliated\nHospital of Nanjing Medical University. Diagnoses were confirmed through right\nheart catheterization. We selected 6 samples from each category for the test\nset (18 samples, 10%), with the remaining 186 samples used for the training\nset. This process was repeated 35 times for testing. This paper proposes a deep\nlearning model that combines Graph convolutional networks (GCN), Convolutional\nneural networks (CNN), and Transformers. The model was developed to process\nmultimodal data, including short-axis (SAX) sequences, four-chamber (4CH)\nsequences, and clinical parameters. Our model achieved a performance of Area\nunder the receiver operating characteristic curve (AUC) = 0.81 +- 0.06(standard\ndeviation) and Accuracy (ACC) = 0.73 +- 0.06 on the test set. The\ndiscriminative abilities were as follows: non-PH subjects (AUC = 0.74 +- 0.11),\npre-capillary PH (AUC = 0.86 +- 0.06), and post-capillary PH (AUC = 0.83 +-\n0.10). It has the potential to support clinical decision-making by effectively\nintegrating multimodal data to assist physicians in making accurate and timely\ndiagnoses.", "published": "2025-03-28 01:14:17", "link": "http://arxiv.org/abs/2504.01025v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "physics.med-ph"], "primary_category": "eess.IV"}
{"title": "Multi-Task Semantic Communications via Large Models", "abstract": "Artificial intelligence (AI) promises to revolutionize the design,\noptimization and management of next-generation communication systems. In this\narticle, we explore the integration of large AI models (LAMs) into semantic\ncommunications (SemCom) by leveraging their multi-modal data processing and\ngeneration capabilities. Although LAMs bring unprecedented abilities to extract\nsemantics from raw data, this integration entails multifaceted challenges\nincluding high resource demands, model complexity, and the need for\nadaptability across diverse modalities and tasks. To overcome these challenges,\nwe propose a LAM-based multi-task SemCom (MTSC) architecture, which includes an\nadaptive model compression strategy and a federated split fine-tuning approach\nto facilitate the efficient deployment of LAM-based semantic models in\nresource-limited networks. Furthermore, a retrieval-augmented generation scheme\nis implemented to synthesize the most recent local and global knowledge bases\nto enhance the accuracy of semantic extraction and content generation, thereby\nimproving the inference performance. Finally, simulation results demonstrate\nthe efficacy of the proposed LAM-based MTSC architecture, highlighting the\nperformance enhancements across various downstream tasks under varying channel\nconditions.", "published": "2025-03-28 00:57:34", "link": "http://arxiv.org/abs/2503.22064v1", "categories": ["cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "On Finding All Connected Maximum-Sized Common Subgraphs in Multiple Labeled Graphs", "abstract": "We present an exact algorithm for computing all common subgraphs with the\nmaximum number of vertices across multiple graphs. Our approach is further\nextended to handle the connected Maximum Common Subgraph (MCS), identifying the\nlargest common subgraph in terms of either vertices or edges across multiple\ngraphs, where edges or vertices may additionally be labeled to account for\npossible atom types or bond types, a classical labeling used in molecular\ngraphs. Our approach leverages modular product graphs and a modified\nBron-Kerbosch algorithm to enumerate maximal cliques, ensuring all intermediate\nsolutions are retained. A pruning heuristic efficiently reduces the modular\nproduct size, improving computational feasibility. Additionally, we introduce a\ngraph ordering strategy based on graph-kernel similarity measures to optimize\nthe search process. Our method is particularly relevant for bioinformatics and\ncheminformatics, where identifying conserved structural motifs in molecular\ngraphs is crucial. Empirical results on molecular datasets demonstrate that our\napproach is scalable and fast.", "published": "2025-03-28 12:20:05", "link": "http://arxiv.org/abs/2503.22368v2", "categories": ["cs.DS", "cs.DM", "math.CO", "q-bio.MN"], "primary_category": "cs.DS"}
{"title": "Valid Cuts for the Design of Potential-based Flow Networks", "abstract": "The construction of a cost minimal network for flows obeying physical laws is\nan important problem for the design of electricity, water, hydrogen, and\nnatural gas infrastructures. We formulate this problem as a mixed-integer\nnon-linear program with potential-based flows. The non-convexity of the\nconstraints stemming from the potential-based flow model together with the\nbinary variables indicating the decision to build a connection make these\nprograms challenging to solve. We develop a novel class of valid inequalities\non the fractional relaxations of the binary variables. Further, we show that\nthis class of inequalities can be separated in polynomial time for solutions to\na fractional relaxation. This makes it possible to incorporate these\ninequalities into a branch-and-cut framework. The advantage of these\ninequalities is lastly demonstrated in a computational study on the design of\nreal-world gas transport networks.", "published": "2025-03-28 11:05:48", "link": "http://arxiv.org/abs/2503.22327v1", "categories": ["math.OC", "cs.DM", "math.CO"], "primary_category": "math.OC"}
{"title": "Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer", "abstract": "Globalisation and colonisation have led the vast majority of the world to use\nonly a fraction of languages, such as English and French, to communicate,\nexcluding many others. This has severely affected the survivability of many\nnow-deemed vulnerable or endangered languages, such as Occitan and Sicilian.\nThese languages often share some characteristics, such as elements of their\ngrammar and lexicon, with other high-resource languages, e.g. French or\nItalian. They can be clustered into groups of language varieties with various\ndegrees of mutual intelligibility. Current search systems are not usually\ntrained on many of these low-resource varieties, leading search users to\nexpress their needs in a high-resource language instead. This problem is\nfurther complicated when most information content is expressed in a\nhigh-resource language, inhibiting even more retrieval in low-resource\nlanguages. We show that current search systems are not robust across language\nvarieties, severely affecting retrieval effectiveness. Therefore, it would be\ndesirable for these systems to leverage the capabilities of neural models to\nbridge the differences between these varieties. This can allow users to express\ntheir needs in their low-resource variety and retrieve the most relevant\ndocuments in a high-resource one. To address this, we propose fine-tuning\nneural rankers on pairs of language varieties, thereby exposing them to their\nlinguistic similarities. We find that this approach improves the performance of\nthe varieties upon which the models were directly trained, thereby regularising\nthese models to generalise and perform better even on unseen language variety\npairs. We also explore whether this approach can transfer across language\nfamilies and observe mixed results that open doors for future research.", "published": "2025-03-28 15:10:19", "link": "http://arxiv.org/abs/2503.22508v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "CLuP-Based Dual-Deconvolution in Automotive ISAC Scenarios", "abstract": "Accurate target parameter estimation of range, velocity, and angle is\nessential for vehicle safety in advanced driver assistance systems (ADAS) and\nautonomous vehicles. To enable spectrum sharing, ADAS may employ integrated\nsensing and communications (ISAC). This paper examines a dual-deconvolution\nautomotive ISAC scenario where the radar waveform is known but the propagation\nchannel is not, while in the communications domain, the channel is known but\nthe transmitted message is not. Conventional maximum likelihood (ML) estimation\nfor automotive target parameters is computationally demanding. To address this,\nwe propose a low-complexity approach using the controlled loosening-up (CLuP)\nalgorithm, which employs iterative refinement for efficient separation and\nestimation of radar targets. We achieve this through a nuclear norm restriction\nthat stabilizes the problem. Numerical experiments demonstrate the robustness\nof this approach under high-mobility and noisy automotive environments,\nhighlighting CLuP's potential as a scalable, real-time solution for ISAC in\nfuture vehicular networks.", "published": "2025-03-28 21:37:22", "link": "http://arxiv.org/abs/2503.22889v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "SOGRAND Assisted Guesswork Reduction", "abstract": "Proposals have been made to reduce the guesswork of Guessing Random Additive\nNoise Decoding (GRAND) for binary linear codes by leveraging codebook structure\nat the expense of degraded block error rate (BLER). We establish one can\npreserve guesswork reduction while eliminating BLER degradation through dynamic\nlist decoding terminated based on Soft Output GRAND's error probability\nestimate. We illustrate the approach with a method inspired by published\nliterature and compare performance with Guessing Codeword Decoding (GCD). We\nestablish that it is possible to provide the same BLER performance as GCD while\nreducing guesswork by up to a factor of 32.", "published": "2025-03-28 21:25:09", "link": "http://arxiv.org/abs/2503.22885v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Quantum Doeblin Coefficients: Interpretations and Applications", "abstract": "In classical information theory, the Doeblin coefficient of a classical\nchannel provides an efficiently computable upper bound on the total-variation\ncontraction coefficient of the channel, leading to what is known as a strong\ndata-processing inequality. Here, we investigate quantum Doeblin coefficients\nas a generalization of the classical concept. In particular, we define various\nnew quantum Doeblin coefficients, one of which has several desirable\nproperties, including concatenation and multiplicativity, in addition to being\nefficiently computable. We also develop various interpretations of two of the\nquantum Doeblin coefficients, including representations as minimal singlet\nfractions, exclusion values, reverse max-mutual and oveloH informations,\nreverse robustnesses, and hypothesis testing reverse mutual and oveloH\ninformations. Our interpretations of quantum Doeblin coefficients as either\nentanglement-assisted or unassisted exclusion values are particularly\nappealing, indicating that they are proportional to the best possible error\nprobabilities one could achieve in state-exclusion tasks by making use of the\nchannel. We also outline various applications of quantum Doeblin coefficients,\nranging from limitations on quantum machine learning algorithms that use\nparameterized quantum circuits (noise-induced barren plateaus), on error\nmitigation protocols, on the sample complexity of noisy quantum hypothesis\ntesting, on the fairness of noisy quantum models, and on mixing times of\ntime-varying channels. All of these applications make use of the fact that\nquantum Doeblin coefficients appear in upper bounds on various trace-distance\ncontraction coefficients of a channel. Furthermore, in all of these\napplications, our analysis using Doeblin coefficients provides improvements of\nvarious kinds over contributions from prior literature, both in terms of\ngenerality and being efficiently computable.", "published": "2025-03-28 18:45:44", "link": "http://arxiv.org/abs/2503.22823v1", "categories": ["quant-ph", "cs.IT", "cs.LG", "math.IT"], "primary_category": "quant-ph"}
{"title": "Optimal Locality and Parameter Tradeoffs for Subsystem Codes", "abstract": "We study the tradeoffs between the locality and parameters of subsystem\ncodes. We prove lower bounds on both the number and lengths of interactions in\nany $D$-dimensional embedding of a subsystem code. Specifically, we show that\nany embedding of a subsystem code with parameters $[[n,k,d]]$ into\n$\\mathbb{R}^D$ must have at least $M^*$ interactions of length at least\n$\\ell^*$, where\n  \\[ M^* = \\Omega(\\max(k,d)), \\quad\\text{and}\\quad \\ell^* =\n\\Omega\\bigg(\\max\\bigg(\\frac{d}{n^\\frac{D-1}{D}},\n\\bigg(\\frac{kd^\\frac{1}{D-1}}{n}\\bigg)^\\frac{D-1}{D}\\bigg)\\bigg). \\] We also\ngive tradeoffs between the locality and parameters of commuting projector codes\nin $D$-dimensions, generalizing a result of Dai and Li. We provide explicit\nconstructions of embedded codes that show our bounds are optimal in both the\ninteraction count and interaction length.", "published": "2025-03-28 17:38:54", "link": "http://arxiv.org/abs/2503.22651v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Movable Antenna Enhanced Downlink Multi-User Integrated Sensing and Communication System", "abstract": "This work investigates the potential of exploiting movable antennas (MAs) to\nenhance the performance of a multi-user downlink integrated sensing and\ncommunication (ISAC) system. Specifically, we formulate an optimization problem\nto maximize the transmit beampattern gain for sensing while simultaneously\nmeeting each user's communication requirement by jointly optimizing antenna\npositions and beamforming design. The problem formulated is highly non-convex\nand involves multivariate-coupled constraints. To address these challenges, we\nintroduce a series of auxiliary random variables and transform the original\nproblem into an augmented Lagrangian problem. A double-loop algorithm based on\na penalty dual decomposition framework is then developed to solve the problem.\nNumerical results validate the effectiveness of the proposed design,\ndemonstrating its superiority over MA designs based on successive convex\napproximation optimization and other baseline approaches in ISAC systems. The\nresults also highlight the advantages of MAs in achieving better sensing\nperformance and improved beam control, especially for sparse arrays with large\napertures.", "published": "2025-03-28 14:52:53", "link": "http://arxiv.org/abs/2503.22486v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Quantum error correction for long chains of trapped ions", "abstract": "We propose a model for quantum computing with long chains of trapped ions and\nwe design quantum error correction schemes for this model. The main components\nof a quantum error correction scheme are the quantum code and a quantum circuit\ncalled the syndrome extraction circuit, which is executed to perform error\ncorrection with this code. In this work, we design syndrome extraction circuits\ntailored to our ion chain model, a syndrome extraction tuning protocol to\noptimize these circuits, and we construct new quantum codes that outperform the\nstate-of-the-art for chains of about $50$ qubits. To establish a baseline under\nthe ion chain model, we simulate the performance of surface codes and bivariate\nbicycle (BB) codes equipped with our optimized syndrome extraction circuits.\nThen, we propose a new variant of BB codes defined by weight-five measurements,\nthat we refer to as BB5 codes, and we identify BB5 codes that achieve a better\nminimum distance than any BB codes with the same number of logical qubits and\ndata qubits, such as $[[30, 4, 5]]$ and $[[48, 4, 7]]$ BB5 codes. For a\nphysical error rate of $10^{-3}$, the $[[48, 4, 7]]$ BB5 code achieves a\nlogical error rate per logical qubit of $5 \\cdot 10^{-5}$, which is four times\nsmaller than the best BB code in our baseline family. It also achieves the same\nlogical error rate per logical qubit as the distance-7 surface code but using\nfour times fewer physical qubits per logical qubit.", "published": "2025-03-28 01:28:24", "link": "http://arxiv.org/abs/2503.22071v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Policy Optimization and Multi-agent Reinforcement Learning for Mean-variance Team Stochastic Games", "abstract": "We study a long-run mean-variance team stochastic game (MV-TSG), where each\nagent shares a common mean-variance objective for the system and takes actions\nindependently to maximize it. MV-TSG has two main challenges. First, the\nvariance metric is neither additive nor Markovian in a dynamic setting. Second,\nsimultaneous policy updates of all agents lead to a non-stationary environment\nfor each individual agent. Both challenges make dynamic programming\ninapplicable. In this paper, we study MV-TSGs from the perspective of\nsensitivity-based optimization. The performance difference and performance\nderivative formulas for joint policies are derived, which provide optimization\ninformation for MV-TSGs. We prove the existence of a deterministic Nash policy\nfor this problem. Subsequently, we propose a Mean-Variance Multi-Agent Policy\nIteration (MV-MAPI) algorithm with a sequential update scheme, where individual\nagent policies are updated one by one in a given order. We prove that the\nMV-MAPI algorithm converges to a first-order stationary point of the objective\nfunction. By analyzing the local geometry of stationary points, we derive\nspecific conditions for stationary points to be (local) Nash equilibria, and\nfurther, strict local optima. To solve large-scale MV-TSGs in scenarios with\nunknown environmental parameters, we extend the idea of trust region methods to\nMV-MAPI and develop a multi-agent reinforcement learning algorithm named\nMean-Variance Multi-Agent Trust Region Policy Optimization (MV-MATRPO). We\nderive a performance lower bound for each update of joint policies. Finally,\nnumerical experiments on energy management in multiple microgrid systems are\nconducted.", "published": "2025-03-28 16:21:05", "link": "http://arxiv.org/abs/2503.22779v1", "categories": ["cs.MA", "cs.GT", "cs.LG", "math.OC"], "primary_category": "cs.MA"}
{"title": "Cooperative Hybrid Multi-Agent Pathfinding Based on Shared Exploration Maps", "abstract": "Multi-Agent Pathfinding is used in areas including multi-robot formations,\nwarehouse logistics, and intelligent vehicles. However, many environments are\nincomplete or frequently change, making it difficult for standard centralized\nplanning or pure reinforcement learning to maintain both global solution\nquality and local flexibility. This paper introduces a hybrid framework that\nintegrates D* Lite global search with multi-agent reinforcement learning, using\na switching mechanism and a freeze-prevention strategy to handle dynamic\nconditions and crowded settings. We evaluate the framework in the discrete\nPOGEMA environment and compare it with baseline methods. Experimental outcomes\nindicate that the proposed framework substantially improves success rate,\ncollision rate, and path efficiency. The model is further tested on the EyeSim\nplatform, where it maintains feasible Pathfinding under frequent changes and\nlarge-scale robot deployments.", "published": "2025-03-28 05:57:23", "link": "http://arxiv.org/abs/2503.22162v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "A Hidden Variable Resultant Method for the Polynomial Multiparameter Eigenvalue Problem", "abstract": "We present a novel, global algorithm for solving polynomial multiparameter\neigenvalue problems (PMEPs) by leveraging a hidden variable tensor Dixon\nresultant framework. Our method transforms a PMEP into one or more univariate\npolynomial eigenvalue problems, which are solved as generalized eigenvalue\nproblems. Our general approach avoids the need for custom linearizations of\nPMEPs. We provide rigorous theoretical guarantees for generic PMEPs and give\npractical strategies for nongeneric systems. Benchmarking on applications from\naeroelastic flutter and leaky wave propagation confirms that our algorithm\nattains high accuracy and robustness while being broadly applicable to many\nPMEPs.", "published": "2025-03-28 21:34:00", "link": "http://arxiv.org/abs/2503.22887v1", "categories": ["math.NA", "cs.NA", "65F15, 15A18, 15A22, 15A69", "G.1.3"], "primary_category": "math.NA"}
{"title": "Solving the Fokker-Planck equation of discretized Dean-Kawasaki models with functional hierarchical tensor", "abstract": "We introduce a novel numerical scheme for solving the Fokker-Planck equation\nof discretized Dean-Kawasaki models with a functional tensor network ansatz.\nThe Dean-Kawasaki model describes density fluctuations of interacting particle\nsystems, and it is a highly singular stochastic partial differential equation.\nBy performing a finite-volume discretization of the Dean-Kawasaki model, we\nderive a stochastic differential equation (SDE). To fully characterize the\ndiscretized Dean-Kawasaki model, we solve the associated Fokker-Planck equation\nof the SDE dynamics. In particular, we use a particle-based approach whereby\nthe solution to the Fokker-Planck equation is obtained by performing a series\nof density estimation tasks from the simulated trajectories, and we use a\nfunctional hierarchical tensor model to represent the density. To address the\nchallenge that the sample trajectories are supported on a simplex, we apply a\ncoordinate transformation from the simplex to a Euclidean space by logarithmic\nparameterization, after which we apply a sketching-based density estimation\nprocedure on the transformed variables. Our approach is general and can be\napplied to general density estimation tasks over a simplex. We apply the\nproposed method successfully to the 1D and 2D Dean-Kawasaki models. Moreover,\nwe show that the proposed approach is highly accurate in the presence of\nexternal potential and particle interaction.", "published": "2025-03-28 18:27:59", "link": "http://arxiv.org/abs/2503.22816v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Many facets of cohomology: Differential complexes and structure-aware formulations", "abstract": "Complexes and cohomology, traditionally central to topology, have emerged as\nfundamental tools across applied mathematics and the sciences. This survey\nexplores their roles in diverse areas, from partial differential equations and\ncontinuum mechanics to reformulations of the Einstein equations and network\ntheory. Motivated by advances in compatible and structure-preserving\ndiscretisation such as Finite Element Exterior Calculus (FEEC), we examine how\ndifferential complexes encode critical properties such as existence,\nuniqueness, stability and rigidity of solutions to differential equations. We\ndemonstrate that various fundamental concepts and models in solid and fluid\nmechanics are essentially formulated in terms of differential complexes.", "published": "2025-03-28 18:20:20", "link": "http://arxiv.org/abs/2503.22813v2", "categories": ["math.NA", "cs.NA", "math-ph", "math.AP", "math.DG", "math.MP"], "primary_category": "math.NA"}
{"title": "Residual-based Chebyshev filtered subspace iteration for sparse Hermitian eigenvalue problems tolerant to inexact matrix-vector products", "abstract": "Chebyshev Filtered Subspace Iteration (ChFSI) has been widely adopted for\ncomputing a small subset of extreme eigenvalues in large sparse matrices. This\nwork introduces a residual-based reformulation of ChFSI, referred to as\nR-ChFSI, designed to accommodate inexact matrix-vector products while\nmaintaining robust convergence properties. By reformulating the traditional\nChebyshev recurrence to operate on residuals rather than eigenvector estimates,\nthe R-ChFSI approach effectively suppresses the errors made in matrix-vector\nproducts, improving the convergence behaviour for both standard and generalized\neigenproblems. This ability of R-ChFSI to be tolerant to inexact matrix-vector\nproducts allows one to incorporate approximate inverses for large-scale\ngeneralized eigenproblems, making the method particularly attractive where\nexact matrix factorizations or iterative methods become computationally\nexpensive for evaluating inverses. It also allows us to compute the\nmatrix-vector products in lower-precision arithmetic allowing us to leverage\nmodern hardware accelerators. Through extensive benchmarking, we demonstrate\nthat R-ChFSI achieves desired residual tolerances while leveraging\nlow-precision arithmetic. For problems with millions of degrees of freedom and\nthousands of eigenvalues, R-ChFSI attains final residual norms in the range of\n10$^{-12}$ to 10$^{-14}$, even with FP32 and TF32 arithmetic, significantly\noutperforming standard ChFSI in similar settings. In generalized eigenproblems,\nwhere approximate inverses are used, R-ChFSI achieves residual tolerances up to\nten orders of magnitude lower, demonstrating its robustness to approximation\nerrors. Finally, R-ChFSI provides a scalable and computationally efficient\nalternative for solving large-scale eigenproblems in high-performance computing\nenvironments.", "published": "2025-03-28 17:41:09", "link": "http://arxiv.org/abs/2503.22652v2", "categories": ["physics.comp-ph", "cs.NA", "math.NA"], "primary_category": "physics.comp-ph"}
{"title": "Finding Unknown Unknowns using Cyber-Physical System Simulators (Extended Report)", "abstract": "Simulation-based approaches are among the most practical means to search for\nsafety violations, bugs, and other unexpected events in cyber-physical systems\n(CPS). Where existing approaches search for simulations violating a formal\nspecification or maximizing a notion of coverage, in this work we propose a new\ngoal for testing: to discover unknown rare behaviors by examining discrete mode\nsequences. We assume a CPS simulator outputs mode information, and strive to\nexplore the sequences of modes produced by varying the initial state or\ntime-varying uncertainties. We hypothesize that rare mode sequences are often\nthe most interesting to a designer, and we develop two accelerated sampling\nalgorithms that speed up the process of finding such sequences. We evaluate our\napproach on several benchmarks, ranging from synthetic examples to Simulink\ndiagrams of a CPS, demonstrating in some cases a speedup of over 100x compared\nwith a random sampling strategy.", "published": "2025-03-28 17:32:26", "link": "http://arxiv.org/abs/2503.22646v1", "categories": ["eess.SY", "cs.NA", "cs.SY", "math.NA"], "primary_category": "eess.SY"}
{"title": "Continuous data assimilation for problems with limited regularity using non-interpolant observables", "abstract": "Continuous data assimilation addresses time-dependent problems with unknown\ninitial conditions by incorporating observations of the solution into a nudging\nterm. For the prototypical heat equation with variable conductivity and the\nNeumann boundary condition, we consider data assimilation schemes with\nnon-interpolant observables unlike previous studies. These generalized nudging\nstrategies are notably useful for problems which possess limited or even no\nadditional regularity beyond the minimal framework. We demonstrate that a\nspatially discretized nudged solution converges exponentially fast in time to\nthe true solution with the rate guaranteed by the choice of the nudging\nstrategy independent of the discretization. Furthermore, the long-term discrete\nerror is optimal as it matches the estimates available for problems of limited\nregularity with known initial conditions. Three particular strategies --\nnudging by a conforming finite element subspace, nudging by piecewise constants\non the boundary mesh, and nudging by the mean value -- are explored numerically\nfor three test cases, including a problem with Dirac delta forcing and the\nKellogg problem with discontinuous conductivity.", "published": "2025-03-28 17:27:24", "link": "http://arxiv.org/abs/2503.22780v1", "categories": ["math.NA", "cs.NA", "65M60"], "primary_category": "math.NA"}
{"title": "Accelerating a restarted Krylov method for matrix functions with randomization", "abstract": "Many scientific applications require the evaluation of the action of the\nmatrix function over a vector and the most common methods for this task are\nthose based on the Krylov subspace. Since the orthogonalization cost and memory\nrequirement can quickly become overwhelming as the basis grows, the Krylov\nmethod is often restarted after a few iterations. This paper proposes a new\nacceleration technique for restarted Krylov methods based on randomization. The\nnumerical experiments show that the randomized method greatly outperforms the\nclassical approach with the same level of accuracy. In fact, randomization can\nactually improve the convergence rate of restarted methods in some cases. The\npaper also compares the performance and stability of the randomized methods\nproposed so far for solving very large finite element problems, complementing\nthe numerical analyses from previous studies.", "published": "2025-03-28 17:22:37", "link": "http://arxiv.org/abs/2503.22631v2", "categories": ["math.NA", "cs.NA", "68W20, 65F60, 65F50, 65M20"], "primary_category": "math.NA"}
{"title": "Improved error estimates for low-regularity integrators using space-time bounds", "abstract": "We prove optimal convergence rates for certain low-regularity integrators\napplied to the one-dimensional periodic nonlinear Schr\\\"odinger and wave\nequations under the assumption of $H^1$ solutions. For the Schr\\\"odinger\nequation we analyze the exponential-type scheme proposed by Ostermann and\nSchratz in 2018, whereas in the wave case we treat the corrected Lie splitting\nproposed by Li, Schratz, and Zivcovich in 2023. We show that the integrators\nconverge with their full order of one and two, respectively. In this situation\nonly fractional convergence rates were previously known. The crucial\ningredients in the proofs are known space-time bounds for the solutions to the\ncorresponding linear problems. More precisely, in the Schr\\\"odinger case we use\nthe $L^4$ Strichartz inequality, and for the wave equation a null form\nestimate. To our knowledge, this is the first time that a null form estimate is\nexploited in numerical analysis. We apply the estimates for continuous time,\nthus avoiding potential losses resulting from discrete-time estimates.", "published": "2025-03-28 17:14:16", "link": "http://arxiv.org/abs/2503.22621v1", "categories": ["math.NA", "cs.NA", "math.AP", "65M15 (Primary) 35L71, 35Q55, 65M12 (Secondary)"], "primary_category": "math.NA"}
{"title": "A high order multigrid-preconditioned immersed interface solver for the Poisson equation with boundary and interface conditions", "abstract": "This work presents a multigrid preconditioned high order immersed finite\ndifference solver to accurately and efficiently solve the Poisson equation on\ncomplex 2D and 3D domains. The solver employs a low order Shortley-Weller\nmultigrid method to precondition a high order matrix-free Krylov subspace\nsolver. The matrix-free approach enables full compatibility with high order IIM\ndiscretizations of boundary and interface conditions, as well as high order\nwavelet-adapted multiresolution grids. Through verification and analysis on 2D\ndomains, we demonstrate the ability of the algorithm to provide high order\naccurate results to Laplace and Poisson problems with Dirichlet, Neumann,\nand/or interface jump boundary conditions, all effectively preconditioned using\nthe multigrid method. We further show that the proposed method is able to\nefficiently solve high order discretizations of Laplace and Poisson problems on\ncomplex 3D domains using thousands of compute cores and on multiresolution\ngrids. To our knowledge, this work presents the largest problem sizes tackled\nwith high order immersed methods applied to elliptic partial differential\nequations, and the first high order results on 3D multiresolution adaptive\ngrids. Together, this work paves the way for employing high order immersed\nmethods to a variety of 3D partial differential equations with boundary or\ninter-face conditions, including linear and non-linear elasticity problems, the\nincompressible Navier-Stokes equations, and fluid-structure interactions.", "published": "2025-03-28 14:06:54", "link": "http://arxiv.org/abs/2503.22455v1", "categories": ["math.NA", "cs.CE", "cs.NA"], "primary_category": "math.NA"}
{"title": "Spectral coefficient learning physics informed neural network for time-dependent fractional parametric differential problems", "abstract": "The study of parametric differential equations plays a crucial role in\nweather forecasting and epidemiological modeling. These phenomena are better\nrepresented using fractional derivatives due to their inherent memory or\nhereditary effects. This paper introduces a novel scientific machine learning\napproach for solving parametric time-fractional differential equations by\ncombining traditional spectral methods with neural networks. Instead of relying\non automatic differentiation techniques, commonly used in traditional\nPhysics-Informed Neural Networks (PINNs), we propose a more efficient global\ndiscretization method based on Legendre polynomials. This approach eliminates\nthe need to simulate the parametric fractional differential equations across\nmultiple parameter values. By applying the Legendre-Galerkin weak formulation\nto the differential equation, we construct a loss function for training the\nneural network. The trial solutions are represented as linear combinations of\nLegendre polynomials, with the coefficients learned by the neural network. The\nconvergence of this method is theoretically established, and the theoretical\nresults are validated through numerical experiments on several well-known\ndifferential equations.", "published": "2025-03-28 12:44:39", "link": "http://arxiv.org/abs/2503.22386v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Improvement of conformal maps combined with the Sinc approximation for derivatives over infinite intervals", "abstract": "F. Stenger proposed efficient approximation formulas for derivatives over\ninfinite intervals. Those formulas were derived by the combination of the Sinc\napproximation and appropriate conformal maps. It has been shown that those\nformulas can attain root-exponential convergence. In this study, we enhance the\nconvergence rate by improving the conformal maps employed in those formulas. We\nprovide theoretical error analysis and numerical experiments that confirm the\neffectiveness of our new formulas.", "published": "2025-03-28 12:01:16", "link": "http://arxiv.org/abs/2503.22360v1", "categories": ["math.NA", "cs.NA", "65D25"], "primary_category": "math.NA"}
{"title": "A numerical Bernstein splines approach for nonlinear initial value problems with Hilfer fractional derivative", "abstract": "The Hilfer fractional derivative interpolates the commonly used\nRiemann-Liouville and Caputo fractional derivative. In general, solutions to\nHilfer fractional differential equations are singular for $t \\downarrow 0$ and\nare difficult to approximate with high numerical accuracy. We propose a\nnumerical Bernstein splines technique to approximate solutions to generalized\nnonlinear initial values problems with Hilfer fractional derivatives.\nConvergent approximations are obtained using an efficient vectorized solution\nsetup with few convergence requirements for a wide range of nonlinear\nfractional differential equations. We demonstrate efficiency of the developed\nmethod by applying it to the fractional Van der Pol oscillator, a system with\napplications in control systems and electronic circuits.", "published": "2025-03-28 11:15:53", "link": "http://arxiv.org/abs/2503.22335v1", "categories": ["math.NA", "cs.NA", "65L05 (Primary), 34A08 (Secondary)"], "primary_category": "math.NA"}
{"title": "Approximation results on neural network operators of convolution type", "abstract": "In the present paper, we introduce three neural network operators of\nconvolution type activated by symmetrized, deformed and parametrized\nB-generalized logistic function. We deal with the approximation properties of\nthese operators to the identity by using modulus of continuity. Furthermore, we\nshow that our operators preserve global smoothness and consider the iterated\nversions of them. Here, we find it is worthy to mention that these operators\nplay important roles in neural network approximation since most of the basic\nnetwork models are activated by logistic functions.", "published": "2025-03-28 10:26:30", "link": "http://arxiv.org/abs/2503.22301v1", "categories": ["math.NA", "cs.NA", "41A17, 41A25, 41A35, 47A58"], "primary_category": "math.NA"}
{"title": "A posteriori error estimates for the finite element discretization of second-order PDEs set in unbounded domains", "abstract": "We consider second-order PDE problems set in unbounded domains and\ndiscretized by Lagrange finite elements on a finite mesh, thus introducing an\nartificial boundary in the discretization. Specifically, we consider the\nreaction diffusion equation as well as Helmholtz problems in waveguides with\nperfectly matched layers. The usual procedure to deal with such problems is to\nfirst consider a modeling error due to the introduction of the artificial\nboundary, and estimate the remaining discretization error with a standard a\nposteriori technique. A shortcoming of this method, however, is that it is\ntypically hard to obtain sharp bounds on the modeling error. In this work, we\npropose a new technique that allows to control the whole error by an a\nposteriori error estimator. Specifically, we propose a flux-equilibrated\nestimator that is slightly modified to handle the truncation boundary. For the\nreaction diffusion equation, we obtain fully-computable guaranteed error\nbounds, and the estimator is locally efficient and polynomial-degree-robust\nprovided that the elements touching the truncation boundary are not too\nrefined. This last condition may be seen as an extension of the notion of\nshape-regularity of the mesh, and does not prevent the design of efficient\nadaptive algorithms. For the Helmholtz problem, as usual, these statements\nremain valid if the mesh is sufficiently refined. Our theoretical findings are\ncompleted with numerical examples which indicate that the estimator is suited\nto drive optimal adaptive mesh refinements.", "published": "2025-03-28 10:20:55", "link": "http://arxiv.org/abs/2503.22297v1", "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "math.NA"}
{"title": "Connecting Kaporin's condition number and the Bregman log determinant divergence", "abstract": "This paper presents some theoretical results relating the Bregman log\ndeterminant matrix divergence to Kaporin's condition number. These can be\nviewed as nearness measures between a preconditioner and a given matrix, and we\nshow under which conditions these two functions coincide. We also give examples\nof constraint sets over which it is equivalent to minimise these two\nobjectives. We focus on preconditioners that are the sum of a positive definite\nand low-rank matrix, which were developed in a previous work. These were\nconstructed as minimisers of the aforementioned divergence, and we show that\nthey are only a constant scaling from also minimising Kaporin's condition\nnumber. We highlight connections to information geometry and comment on future\ndirections.", "published": "2025-03-28 10:02:48", "link": "http://arxiv.org/abs/2503.22286v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "General form of the Gauss-Seidel equation to linearly approximate the Moore-Penrose pseudoinverse in random non-square systems and high order tensors", "abstract": "The Gauss-Seidel method has been used for more than 100 years as the standard\nmethod for the solution of linear systems of equations under certain\nrestrictions. This method, as well as Cramer and Jacobi, is widely used in\neducation and engineering, but there is a theoretical gap when we want to solve\nless restricted systems, or even non-square or non-exact systems of equation.\nHere, the solution goes through the use of numerical systems, such as the\nminimization theories or the Moore-Penrose pseudoinverse. In this paper we fill\nthis gap with a global analytical iterative formulation that is capable to\nreach the solutions obtained with the Moore-Penrose pseudoinverse and the\nminimization methodologies, but that analytically lies to the solutions of\nGauss-Seidel, Jacobi, or Cramer when the system is simplified.", "published": "2025-03-28 09:41:56", "link": "http://arxiv.org/abs/2503.22273v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "On the convergence of the Euler-Maruyama scheme for McKean-Vlasov SDEs", "abstract": "Building on the well-posedness of the backward Kolmogorov partial\ndifferential equation in the Wasserstein space, we analyze the strong and weak\nconvergence rates for approximating the unique solution of a class of\nMcKean-Vlasov stochastic differential equations via the Euler-Maruyama time\ndiscretization scheme applied to the associated system of interacting\nparticles. We consider two distinct settings. In the first, the coefficients\nand test function are irregular, but the diffusion coefficient remains\nnon-degenerate. Leveraging the smoothing properties of the underlying heat\nkernel, we establish the strong and weak convergence rates of the scheme in\nterms of the number of particles N and the mesh size h. In the second setting,\nwhere both the coefficients and the test function are smooth, we demonstrate\nthat the weak error rate at the level of the semigroup is optimal, achieving an\nerror of order N -1 + h.", "published": "2025-03-28 08:20:17", "link": "http://arxiv.org/abs/2503.22226v1", "categories": ["math.PR", "cs.NA", "math.NA"], "primary_category": "math.PR"}
{"title": "An Advanced Ensemble Deep Learning Framework for Stock Price Prediction Using VAE, Transformer, and LSTM Model", "abstract": "This research proposes a cutting-edge ensemble deep learning framework for\nstock price prediction by combining three advanced neural network\narchitectures: The particular areas of interest for the research include but\nare not limited to: Variational Autoencoder (VAE), Transformer, and Long\nShort-Term Memory (LSTM) networks. The presented framework is aimed to\nsubstantially utilize the advantages of each model which would allow for\nachieving the identification of both linear and non-linear relations in stock\nprice movements. To improve the accuracy of its predictions it uses rich set of\ntechnical indicators and it scales its predictors based on the current market\nsituation. By trying out the framework on several stock data sets, and\nbenchmarking the results against single models and conventional forecasting,\nthe ensemble method exhibits consistently high accuracy and reliability. The\nVAE is able to learn linear representation on high-dimensional data while the\nTransformer outstandingly perform in recognizing long-term patterns on the\nstock price data. LSTM, based on its characteristics of being a model that can\ndeal with sequences, brings additional improvements to the given framework,\nespecially regarding temporal dynamics and fluctuations. Combined, these\ncomponents provide exceptional directional performance and a very small\ndisparity in the predicted results. The present solution has given a probable\nconcept that can handle the inherent problem of stock price prediction with\nhigh reliability and scalability. Compared to the performance of individual\nproposals based on the neural network, as well as classical methods, the\nproposed ensemble framework demonstrates the advantages of combining different\narchitectures. It has a very important application in algorithmic trading, risk\nanalysis, and control and decision-making for finance professions and scholars.", "published": "2025-03-28 07:20:40", "link": "http://arxiv.org/abs/2503.22192v1", "categories": ["q-fin.CP", "cs.LG"], "primary_category": "q-fin.CP"}
{"title": "Short-time behavior of the At-The-Money implied volatility for the jump-diffusion stochastic volatility Bachelier model", "abstract": "In this paper we use Malliavin Calculus techniques in order to obtain\nexpressions for the short-time behavior of the at-the-money implied volatility\n(ATM-IV) level and skew for a jump-diffusion stock price. The diffusion part is\nassumed to be the stochastic volatility Bachelier model and the jumps are\nmodeled by a pure-jump L\\'evy process with drift so that the stock price is a\nmartingale. Regarding the level, we show that the short-time behavior of the\nATM-IV level is the same for all pure-jump L\\'evy processes and, regarding the\nskew, we give conditions on the law of the jumps for the skew to exist. We also\ngive several numerical examples of stochastic volatilities and L\\'evy processes\nthat confirm the theoretical results found in the paper.", "published": "2025-03-28 09:55:54", "link": "http://arxiv.org/abs/2503.22282v1", "categories": ["q-fin.MF", "math.PR", "60H07 60J76 91G20 91G60 (Primary)"], "primary_category": "q-fin.MF"}
{"title": "Equilibrium Reward for Liquidity Providers in Automated Market Makers", "abstract": "We find the equilibrium contract that an automated market maker (AMM) offers\nto their strategic liquidity providers (LPs) in order to maximize the order\nflow that gets processed by the venue. Our model is formulated as a\nleader-follower stochastic game, where the venue is the leader and a\nrepresentative LP is the follower. We derive approximate closed-form\nequilibrium solutions to the stochastic game and analyze the reward structure.\nOur findings suggest that under the equilibrium contract, LPs have incentives\nto add liquidity to the pool only when higher liquidity on average attracts\nmore noise trading. The equilibrium contract depends on the external price, the\npool reference price, and the pool reserves. Our framework offers insights into\nAMM design for maximizing order flow while ensuring LP profitability.", "published": "2025-03-28 15:07:02", "link": "http://arxiv.org/abs/2503.22502v1", "categories": ["q-fin.TR", "math.OC"], "primary_category": "q-fin.TR"}
{"title": "A formula for the area of a triangle: Useless, but explicitly in Deep Sets form", "abstract": "Any permutation-invariant function of data points $\\vec{r}_i$ can be written\nin the form $\\rho(\\sum_i\\phi(\\vec{r}_i))$ for suitable functions $\\rho$ and\n$\\phi$. This form - known in the machine-learning literature as Deep Sets -\nalso generates a map-reduce algorithm. The area of a triangle is a\npermutation-invariant function of the locations $\\vec{r}_i$ of the three\ncorners $1\\leq i\\leq 3$. We find the polynomial formula for the area of a\ntriangle that is explicitly in Deep Sets form. This project was motivated by\nquestions about the fundamental computational complexity of $n$-point\nstatistics in cosmology; that said, no insights of any kind were gained from\nthese results.", "published": "2025-03-28 18:00:00", "link": "http://arxiv.org/abs/2503.22786v1", "categories": ["astro-ph.CO", "stat.ML"], "primary_category": "astro-ph.CO"}
{"title": "Low Rank and Sparse Fourier Structure in Recurrent Networks Trained on Modular Addition", "abstract": "Modular addition tasks serve as a useful test bed for observing empirical\nphenomena in deep learning, including the phenomenon of \\emph{grokking}. Prior\nwork has shown that one-layer transformer architectures learn Fourier\nMultiplication circuits to solve modular addition tasks. In this paper, we show\nthat Recurrent Neural Networks (RNNs) trained on modular addition tasks also\nuse a Fourier Multiplication strategy. We identify low rank structures in the\nmodel weights, and attribute model components to specific Fourier frequencies,\nresulting in a sparse representation in the Fourier space. We also show\nempirically that the RNN is robust to removing individual frequencies, while\nthe performance degrades drastically as more frequencies are ablated from the\nmodel.", "published": "2025-03-28 00:40:03", "link": "http://arxiv.org/abs/2503.22059v1", "categories": ["cs.LG", "eess.SP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "tempdisagg: A Python Framework for Temporal Disaggregation of Time Series Data", "abstract": "tempdisagg is a modern, extensible, and production-ready Python framework for\ntemporal disaggregation of time series data. It transforms low-frequency\naggregates into consistent, high-frequency estimates using a wide array of\neconometric techniques-including Chow-Lin, Denton, Litterman, Fernandez, and\nuniform interpolation-as well as enhanced variants with automated estimation of\nkey parameters such as the autocorrelation coefficient rho. The package\nintroduces features beyond classical methods, including robust ensemble\nmodeling via non-negative least squares optimization, post-estimation\ncorrection of negative values under multiple aggregation rules, and optional\nregression-based imputation of missing values through a dedicated\nRetropolarizer module. Architecturally, it follows a modular design inspired by\nscikit-learn, offering a clean API for validation, modeling, visualization, and\nresult interpretation.", "published": "2025-03-28 00:15:52", "link": "http://arxiv.org/abs/2503.22054v1", "categories": ["econ.EM", "stat.CO", "stat.ML", "I.2.6"], "primary_category": "econ.EM"}
{"title": "Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis", "abstract": "Talking head synthesis has become a key research area in computer graphics\nand multimedia, yet most existing methods often struggle to balance generation\nquality with computational efficiency. In this paper, we present a novel\napproach that leverages an Audio Factorization Plane (Audio-Plane) based\nGaussian Splatting for high-quality and real-time talking head generation. For\nmodeling a dynamic talking head, 4D volume representation is needed. However,\ndirectly storing a dense 4D grid is impractical due to the high cost and lack\nof scalability for longer durations. We overcome this challenge with the\nproposed Audio-Plane, where the 4D volume representation is decomposed into\naudio-independent space planes and audio-dependent planes. This provides a\ncompact and interpretable feature representation for talking head, facilitating\nmore precise audio-aware spatial encoding and enhanced audio-driven lip dynamic\nmodeling. To further improve speech dynamics, we develop a dynamic splatting\nmethod that helps the network more effectively focus on modeling the dynamics\nof the mouth region. Extensive experiments demonstrate that by integrating\nthese innovations with the powerful Gaussian Splatting, our method is capable\nof synthesizing highly realistic talking videos in real time while ensuring\nprecise audio-lip synchronization. Synthesized results are available in\nhttps://sstzal.github.io/Audio-Plane/.", "published": "2025-03-28 16:50:27", "link": "http://arxiv.org/abs/2503.22605v1", "categories": ["cs.GR", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.GR"}
{"title": "Cross-Technology Generalization in Synthesized Speech Detection: Evaluating AST Models with Modern Voice Generators", "abstract": "This paper evaluates the Audio Spectrogram Transformer (AST) architecture for\nsynthesized speech detection, with focus on generalization across modern voice\ngeneration technologies. Using differentiated augmentation strategies, the\nmodel achieves 0.91% EER overall when tested against ElevenLabs, NotebookLM,\nand Minimax AI voice generators. Notably, after training with only 102 samples\nfrom a single technology, the model demonstrates strong cross-technology\ngeneralization, achieving 3.3% EER on completely unseen voice generators. This\nwork establishes benchmarks for rapid adaptation to emerging synthesis\ntechnologies and provides evidence that transformer-based architectures can\nidentify common artifacts across different neural voice synthesis methods,\ncontributing to more robust speech verification systems.", "published": "2025-03-28 15:07:26", "link": "http://arxiv.org/abs/2503.22503v1", "categories": ["cs.SD", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DeepAudio-V1:Towards Multi-Modal Multi-Stage End-to-End Video to Speech and Audio Generation", "abstract": "Currently, high-quality, synchronized audio is synthesized using various\nmulti-modal joint learning frameworks, leveraging video and optional text\ninputs. In the video-to-audio benchmarks, video-to-audio quality, semantic\nalignment, and audio-visual synchronization are effectively achieved. However,\nin real-world scenarios, speech and audio often coexist in videos\nsimultaneously, and the end-to-end generation of synchronous speech and audio\ngiven video and text conditions are not well studied. Therefore, we propose an\nend-to-end multi-modal generation framework that simultaneously produces speech\nand audio based on video and text conditions. Furthermore, the advantages of\nvideo-to-audio (V2A) models for generating speech from videos remain unclear.\nThe proposed framework, DeepAudio, consists of a video-to-audio (V2A) module, a\ntext-to-speech (TTS) module, and a dynamic mixture of modality fusion (MoF)\nmodule. In the evaluation, the proposed end-to-end framework achieves\nstate-of-the-art performance on the video-audio benchmark, video-speech\nbenchmark, and text-speech benchmark. In detail, our framework achieves\ncomparable results in the comparison with state-of-the-art models for the\nvideo-audio and text-speech benchmarks, and surpassing state-of-the-art models\nin the video-speech benchmark, with WER 16.57% to 3.15% (+80.99%), SPK-SIM\n78.30% to 89.38% (+14.15%), EMO-SIM 66.24% to 75.56% (+14.07%), MCD 8.59 to\n7.98 (+7.10%), MCD SL 11.05 to 9.40 (+14.93%) across a variety of dubbing\nsettings.", "published": "2025-03-28 09:29:08", "link": "http://arxiv.org/abs/2503.22265v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "DeepSound-V1: Start to Think Step-by-Step in the Audio Generation from Videos", "abstract": "Currently, high-quality, synchronized audio is synthesized from video and\noptional text inputs using various multi-modal joint learning frameworks.\nHowever, the precise alignment between the visual and generated audio domains\nremains far from satisfactory. One key factor is the lack of sufficient\ntemporal and semantic alignment annotations in open-source video-audio and\ntext-audio benchmarks. Therefore, we propose a framework for audio generation\nfrom videos, leveraging the internal chain-of-thought (CoT) of a multi-modal\nlarge language model (MLLM) to enable step-by-step reasoning without requiring\nadditional annotations. Additionally, a corresponding multi-modal reasoning\ndataset is constructed to facilitate the learning of initial reasoning in audio\ngeneration. In the experiments, we demonstrate the effectiveness of the\nproposed framework in reducing misalignment (voice-over) in generated audio and\nachieving competitive performance compared to various state-of-the-art models.\nThe evaluation results show that the proposed method outperforms\nstate-of-the-art approaches across multiple metrics. Specifically, the F DP\naSST indicator is reduced by up to 10.07%, the F DP AN N s indicator by up to\n11.62%, and the F DV GG indicator by up to 38.61%. Furthermore, the IS\nindicator improves by up to 4.95%, the IB-score indicator increases by up to\n6.39%, and the DeSync indicator is reduced by up to 0.89%.", "published": "2025-03-28 07:56:19", "link": "http://arxiv.org/abs/2503.22208v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhance Generation Quality of Flow Matching V2A Model via Multi-Step CoT-Like Guidance and Combined Preference Optimization", "abstract": "Creating high-quality sound effects from videos and text prompts requires\nprecise alignment between visual and audio domains, both semantically and\ntemporally, along with step-by-step guidance for professional audio generation.\nHowever, current state-of-the-art video-guided audio generation models often\nfall short of producing high-quality audio for both general and specialized use\ncases. To address this challenge, we introduce a multi-stage, multi-modal,\nend-to-end generative framework with Chain-of-Thought-like (CoT-like) guidance\nlearning, termed Chain-of-Perform (CoP). First, we employ a transformer-based\nnetwork architecture designed to achieve CoP guidance, enabling the generation\nof both general and professional audio. Second, we implement a multi-stage\ntraining framework that follows step-by-step guidance to ensure the generation\nof high-quality sound effects. Third, we develop a CoP multi-modal dataset,\nguided by video, to support step-by-step sound effects generation. Evaluation\nresults highlight the advantages of the proposed multi-stage CoP generative\nframework compared to the state-of-the-art models on a variety of datasets,\nwith FAD 0.79 to 0.74 (+6.33%), CLIP 16.12 to 17.70 (+9.80%) on VGGSound,\nSI-SDR 1.98dB to 3.35dB (+69.19%), MOS 2.94 to 3.49(+18.71%) on PianoYT-2h, and\nSI-SDR 2.22dB to 3.21dB (+44.59%), MOS 3.07 to 3.42 (+11.40%) on Piano-10h.", "published": "2025-03-28 07:32:14", "link": "http://arxiv.org/abs/2503.22200v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Congenital Heart Disease Classification Using Phonocardiograms: A Scalable Screening Tool for Diverse Environments", "abstract": "Congenital heart disease (CHD) is a critical condition that demands early\ndetection, particularly in infancy and childhood. This study presents a deep\nlearning model designed to detect CHD using phonocardiogram (PCG) signals, with\na focus on its application in global health. We evaluated our model on several\ndatasets, including the primary dataset from Bangladesh, achieving a high\naccuracy of 94.1%, sensitivity of 92.7%, specificity of 96.3%. The model also\ndemonstrated robust performance on the public PhysioNet Challenge 2022 and 2016\ndatasets, underscoring its generalizability to diverse populations and data\nsources. We assessed the performance of the algorithm for single and multiple\nauscultation sites on the chest, demonstrating that the model maintains over\n85% accuracy even when using a single location. Furthermore, our algorithm was\nable to achieve an accuracy of 80% on low-quality recordings, which\ncardiologists deemed non-diagnostic. This research suggests that an AI- driven\ndigital stethoscope could serve as a cost-effective screening tool for CHD in\nresource-limited settings, enhancing clinical decision support and ultimately\nimproving patient outcomes.", "published": "2025-03-28 05:47:44", "link": "http://arxiv.org/abs/2503.22773v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Enhancing Dance-to-Music Generation via Negative Conditioning Latent Diffusion Model", "abstract": "Conditional diffusion models have gained increasing attention since their\nimpressive results for cross-modal synthesis, where the strong alignment\nbetween conditioning input and generated output can be achieved by training a\ntime-conditioned U-Net augmented with cross-attention mechanism. In this paper,\nwe focus on the problem of generating music synchronized with rhythmic visual\ncues of the given dance video. Considering that bi-directional guidance is more\nbeneficial for training a diffusion model, we propose to enhance the quality of\ngenerated music and its synchronization with dance videos by adopting both\npositive rhythmic information and negative ones (PN-Diffusion) as conditions,\nwhere a dual diffusion and reverse processes is devised. Specifically, to train\na sequential multi-modal U-Net structure, PN-Diffusion consists of a noise\nprediction objective for positive conditioning and an additional noise\nprediction objective for negative conditioning. To accurately define and select\nboth positive and negative conditioning, we ingeniously utilize temporal\ncorrelations in dance videos, capturing positive and negative rhythmic cues by\nplaying them forward and backward, respectively. Through subjective and\nobjective evaluations of input-output correspondence in terms of dance-music\nbeat alignment and the quality of generated music, experimental results on the\nAIST++ and TikTok dance video datasets demonstrate that our model outperforms\nSOTA dance-to-music generation models.", "published": "2025-03-28 04:23:03", "link": "http://arxiv.org/abs/2503.22138v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "M2D2: Exploring General-purpose Audio-Language Representations Beyond CLAP", "abstract": "Contrastive language-audio pre-training (CLAP) has addressed audio-language\ntasks such as audio-text retrieval by aligning audio and text in a common\nfeature space. While CLAP addresses general audio-language tasks, its audio\nfeatures do not generalize well in audio tasks. In contrast, self-supervised\nlearning (SSL) models learn general-purpose audio features that perform well in\ndiverse audio tasks. We pursue representation learning that can be widely used\nin audio applications and hypothesize that a method that learns both general\naudio features and CLAP features should achieve our goal, which we call a\ngeneral-purpose audio-language representation. To implement our hypothesis, we\npropose M2D2, a second-generation masked modeling duo (M2D) that combines an\nSSL M2D and CLAP. M2D2 learns two types of features using two modalities (audio\nand text) in a two-stage training process. It also utilizes advanced LLM-based\nsentence embeddings in CLAP training for powerful semantic supervision. In the\nfirst stage, M2D2 learns generalizable audio features from M2D and CLAP, where\nCLAP aligns the features with the fine LLM-based semantic embeddings. In the\nsecond stage, it learns CLAP features using the audio features learned from the\nLLM-based embeddings. Through these pre-training stages, M2D2 should enhance\ngeneralizability and performance in its audio and CLAP features. Experiments\nvalidated that M2D2 achieves effective general-purpose audio-language\nrepresentation, highlighted with SOTA fine-tuning mAP of 49.0 for AudioSet,\nSOTA performance in music tasks, and top-level performance in audio-language\ntasks.", "published": "2025-03-28 02:55:39", "link": "http://arxiv.org/abs/2503.22104v1", "categories": ["eess.AS", "68T07", "I.2.4"], "primary_category": "eess.AS"}
{"title": "Baseline Systems and Evaluation Metrics for Spatial Semantic Segmentation of Sound Scenes", "abstract": "Immersive communication has made significant advancements, especially with\nthe release of the codec for Immersive Voice and Audio Services. Aiming at its\nfurther realization, the DCASE 2025 Challenge has recently introduced a task\nfor spatial semantic segmentation of sound scenes (S5), which focuses on\ndetecting and separating sound events in spatial sound scenes. In this paper,\nwe explore methods for addressing the S5 task. Specifically, we present\nbaseline S5 systems that combine audio tagging (AT) and label-queried source\nseparation (LSS) models. We investigate two LSS approaches based on the ResUNet\narchitecture: a) extracting a single source for each detected event and b)\nquerying multiple sources concurrently. Since each separated source in S5 is\nidentified by its sound event class label, we propose new class-aware metrics\nto evaluate both the sound sources and labels simultaneously. Experimental\nresults on first-order ambisonics spatial audio demonstrate the effectiveness\nof the proposed systems and confirm the efficacy of the metrics.", "published": "2025-03-28 02:08:58", "link": "http://arxiv.org/abs/2503.22088v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "MCRB for Parameter Estimation from One-Bit Quantized and Oversampled Measurements", "abstract": "One-bit quantization has garnered significant attention in recent years for\nvarious signal processing and communication applications. Estimating model\nparameters from one bit quantized data can be challenging, particularly when\nthe quantization process is explicitly accounted for in the estimator. In many\ncases, the estimator disregards quantization effects, leading to model\nmisspecification. Consequently, estimation errors arise from both quantization\nand misspecification. Traditional performance bounds, such as the Cramer-Rao\nbound (CRB), fail to capture the impact of misspecification on estimation\nperformance. To address this limitation, we derive the misspecified CRB (MCRB)\nfor parameter estimation in a quantized data model consisting of a signal\ncomponent in additive Gaussian noise. We apply this bound to\ndirection-of-arrival estimation using quantized measurements from a sensor\narray and to frequency estimation with oversampled quantized data. The\nsimulations show that the MCRB is asymptotically achieved by the\nmean-squared-error of the misspecified maximum-likelihood estimator. Our\nresults demonstrate that, unlike in finely quantized scenarios, oversampling\ncan significantly enhance the estimation performance in the presence of\nmisspecified one-bit quantized measurements.", "published": "2025-03-28 20:25:27", "link": "http://arxiv.org/abs/2503.22860v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Optimized Vehicular Antenna Placement for Phase-Coherent Positioning", "abstract": "Distributed multi-antenna systems are an important enabling technology for\nfuture intelligent transportation systems (ITS), showing promising performance\nin vehicular communications and near-field (NF) localization applications. This\nwork investigates optimal deployments of phase-coherent sub-arrays on a vehicle\nfor NF localization in terms of a Cram\\'er-Rao lower bound (CRLB)-based metric.\nSub-array placements consider practical geometrical constraints on a\nthree-dimensional vehicle model accounting for self-occlusions. Results show\nthat, for coherent NF localization of the vehicle, the aperture spanned by the\nsub-arrays should be maximized and a larger number of sub-arrays results in\nmore even coverage over the vehicle orientations under a fixed total number of\nantenna elements, contrasting with the outcomes of incoherent localization.\nMoreover, while coherent NF processing significantly enhances accuracy, it also\nleads to more intricate cost functions, necessitating computationally more\ncomplex algorithms than incoherent processing.", "published": "2025-03-28 15:33:19", "link": "http://arxiv.org/abs/2503.22530v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fighting Fire with Fire: Channel-Independent RF Fingerprinting via the Ratio of Linear to Logarithmic Differential Spectrum", "abstract": "Eliminating the influence of temporally varying channel components on the\nradio frequency fingerprint (RFF) extraction has been an enduring and\nchallenging issue. To overcome this problem, we propose a channel-independent\nRFF extraction method inspired by the idea of 'fighting fire with fire'.\nSpecifically, we derive the linear differential spectrum and the logarithmic\ndifferential spectrum of the channel frequency responses (CFRs) from the\nreceived signals at different times, and then calculate the ratio of the two\nspectrums. It is found that the division operation effectively counteracts the\nchannel effects, while simultaneously preserving the integrity of the RFFs. Our\nexperiments on LTE-V2X, LoRa and Wi-Fi devices show that the proposed method\nachieves an average identification accuracy exceeding 95% across various\nenvironments.", "published": "2025-03-28 12:33:45", "link": "http://arxiv.org/abs/2503.22378v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multi-Target Acquisition in Multistatic MIMO-OFDM Joint Sensing and Communication", "abstract": "In this work, we investigate a multistatic MIMO-OFDM joint sensing and\ncommunication (JSC) system that leverages cooperation among spatially\ndistributed base stations (BSs) to detect and localize multiple targets through\nsoft fusion of range-angle maps. We propose an innovative selective data fusion\nstrategy that combines only the most reliable regions of range-angle maps from\neach bistatic pair, mitigating the adverse effects of residual clutter and\ntarget smearing inherent to bistatic configurations. To further enhance\nmulti-view perception, we introduce a round-robin transmitter role strategy,\nenabling BSs to cooperate and exploit target spatial diversity. Finally, we\nassess the system performance in a cluttered environment using the generalized\noptimal subpattern assignment (GOSPA) and root mean squared error (RMSE)\nmetrics, demonstrating the effectiveness of our approaches in improving\ndetection and localization.", "published": "2025-03-28 11:26:57", "link": "http://arxiv.org/abs/2503.22340v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Caract{\u00e9}risation d'une Source Diffuse {\u00e0} partir des Moments de sa Densit{\u00e9} de Puissance en Tomographie SAR", "abstract": "This paper presents a method for estimating the characteristics of a diffuse\nsource from interferometric measurements in the context of SAR tomography. The\nproposed method is based on the use of central moments of the reflectivity\ndensity and does not use any a priori model. The method's performance is\ndiscussed as a function of antenna array parameters (resolution and ambiguity).", "published": "2025-03-28 10:35:10", "link": "http://arxiv.org/abs/2503.22310v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "mmHRR: Monitoring Heart Rate Recovery with Millimeter Wave Radar", "abstract": "Heart rate recovery (HRR) within the initial minute following exercise is a\nwidely utilized metric for assessing cardiac autonomic function in individuals\nand predicting mortality risk in patients with cardiovascular disease. However,\nprevailing solutions for HRR monitoring typically involve the use of\nspecialized medical equipment or contact wearable sensors, resulting in high\ncosts and poor user experience. In this paper, we propose a contactless HRR\nmonitoring technique, mmHRR, which achieves accurate heart rate (HR) estimation\nwith a commercial mmWave radar. Unlike HR estimation at rest, the HR varies\nquickly after exercise and the heartbeat signal entangles with the respiration\nharmonics. To overcome these hurdles and effectively estimate the HR from the\nweak and non-stationary heartbeat signal, we propose a novel signal processing\npipeline, including dynamic target tracking, adaptive heartbeat signal\nextraction, and accurate HR estimation with composite sliding windows.\nReal-world experiments demonstrate that mmHRR exhibits exceptional robustness\nacross diverse environmental conditions, and achieves an average HR estimation\nerror of 3.31 bpm (beats per minute), 71% lower than that of the\nstate-of-the-art method.", "published": "2025-03-28 07:34:56", "link": "http://arxiv.org/abs/2503.22202v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Score-Based Turbo Message Passing for Plug-and-Play Compressive Image Recovery", "abstract": "Message passing algorithms have been tailored for compressive imaging\napplications by plugging in different types of off-the-shelf image denoisers.\nThese off-the-shelf denoisers mostly rely on some generic or hand-crafted\npriors for denoising. Due to their insufficient accuracy in capturing the true\nimage prior, these methods often fail to produce satisfactory results,\nespecially in largely underdetermined scenarios. On the other hand, score-based\ngenerative modeling offers a promising way to accurately characterize the\nsophisticated image distribution. In this paper, by exploiting the close\nrelation between score-based modeling and empirical Bayes-optimal denoising, we\ndevise a message passing framework that integrates a score-based minimum mean\nsquared error (MMSE) denoiser for compressive image recovery. This framework is\nfirmly rooted in Bayesian formalism, in which state evolution (SE) equations\naccurately predict its asymptotic performance. Experiments on the FFHQ dataset\ndemonstrate that our method strikes a significantly better\nperformance-complexity tradeoff than conventional message passing, regularized\nlinear regression, and score-based posterior sampling baselines. Remarkably,\nour method typically requires less than 20 neural function evaluations (NFEs)\nto converge.", "published": "2025-03-28 04:30:58", "link": "http://arxiv.org/abs/2503.22140v1", "categories": ["eess.IV", "cs.CV", "eess.SP"], "primary_category": "eess.IV"}
