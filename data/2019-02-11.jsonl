{"title": "BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field\n  Language Model", "abstract": "We show that BERT (Devlin et al., 2018) is a Markov random field language\nmodel. This formulation gives way to a natural procedure to sample sentences\nfrom BERT. We generate from BERT and find that it can produce high-quality,\nfluent generations. Compared to the generations of a traditional left-to-right\nlanguage model, BERT generates sentences that are more diverse but of slightly\nworse quality.", "published": "2019-02-11 19:02:27", "link": "http://arxiv.org/abs/1902.04094v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LS-Tree: Model Interpretation When the Data Are Linguistic", "abstract": "We study the problem of interpreting trained classification models in the\nsetting of linguistic data sets. Leveraging a parse tree, we propose to assign\nleast-squares based importance scores to each word of an instance by exploiting\nsyntactic constituency structure. We establish an axiomatic characterization of\nthese importance scores by relating them to the Banzhaf value in coalitional\ngame theory. Based on these importance scores, we develop a principled method\nfor detecting and quantifying interactions between words in a sentence. We\ndemonstrate that the proposed method can aid in interpretability and\ndiagnostics for several widely-used language models.", "published": "2019-02-11 23:58:22", "link": "http://arxiv.org/abs/1902.04187v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Vocoder-free WaveNet Voice Conversion with Non-Parallel Data", "abstract": "In a typical voice conversion system, vocoder is commonly used for\nspeech-to-features analysis and features-to-speech synthesis. However, vocoder\ncan be a source of speech quality degradation. This paper presents a\nvocoder-free voice conversion approach using WaveNet for non-parallel training\ndata. Instead of dealing with the intermediate features, the proposed approach\nutilizes the WaveNet to map the Phonetic PosteriorGrams (PPGs) to the waveform\nsamples directly. In this way, we avoid the estimation errors caused by vocoder\nand feature conversion. Additionally, as PPG is assumed to be speaker\nindependent, the proposed method also reduces the feature mismatch problem in\nWaveNet vocoder based approaches. Experimental results conducted on the\nCMU-ARCTIC database show that the proposed approach significantly outperforms\nthe baseline approaches in terms of speech quality.", "published": "2019-02-11 02:36:41", "link": "http://arxiv.org/abs/1902.03705v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Adversarial Generation of Time-Frequency Features with application in\n  audio synthesis", "abstract": "Time-frequency (TF) representations provide powerful and intuitive features\nfor the analysis of time series such as audio. But still, generative modeling\nof audio in the TF domain is a subtle matter. Consequently, neural audio\nsynthesis widely relies on directly modeling the waveform and previous attempts\nat unconditionally synthesizing audio from neurally generated invertible TF\nfeatures still struggle to produce audio at satisfying quality. In this\narticle, focusing on the short-time Fourier transform, we discuss the\nchallenges that arise in audio synthesis based on generated invertible TF\nfeatures and how to overcome them. We demonstrate the potential of deliberate\ngenerative TF modeling by training a generative adversarial network (GAN) on\nshort-time Fourier features. We show that by applying our guidelines, our\nTF-based network was able to outperform a state-of-the-art GAN generating\nwaveforms directly, despite the similar architecture in the two networks.", "published": "2019-02-11 14:11:04", "link": "http://arxiv.org/abs/1902.04072v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
