{"title": "Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy", "abstract": "We present the first evaluation harness that enables any out-of-the-box,\nlocal, Large Language Models (LLMs) to play full-press Diplomacy without\nfine-tuning or specialized training. Previous work required frontier LLMs, or\nfine-tuning, due to the high complexity and information density of Diplomacy's\ngame state. Combined with the high variance of matches, these factors made\nDiplomacy prohibitive for study. In this work, we used data-driven iteration to\noptimize a textual game state representation such that a 24B model can reliably\ncomplete matches without any fine tuning. We develop tooling to facilitate\nhypothesis testing and statistical analysis, and we present case studies on\npersuasion, aggressive playstyles, and performance across a range of models. We\nconduct a variety of experiments across many popular LLMs, finding the larger\nmodels perform the best, but the smaller models still play adequately. We also\nintroduce Critical State Analysis: an experimental protocol for rapidly\niterating and analyzing key moments in a game at depth. Our harness\ndemocratizes the evaluation of strategic reasoning in LLMs by eliminating the\nneed for fine-tuning, and it provides insights into how these capabilities\nemerge naturally from widely used LLMs. Our code is available in the supplement\nand will be open sourced.", "published": "2025-08-10 21:07:08", "link": "http://arxiv.org/abs/2508.07485v1", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.AI"}
{"title": "ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models", "abstract": "Large Language Models (LLMs) have shown remarkable performance across a wide\nrange of natural language processing tasks. Quality Estimation (QE) for Machine\nTranslation (MT), which assesses the quality of a source-target pair without\nrelying on reference translations, remains a challenging cross-lingual task for\nLLMs. The challenges stem from the inherent limitations of existing LLM-based\nQE systems, which are pre-trained for causal language modelling rather than\nregression-specific tasks, further elevated by the presence of low-resource\nlanguages given pre-training data distribution. This paper introduces ALOPE, an\nadaptive layer-optimization framework designed to enhance LLM-based QE by\nrestructuring Transformer representations through layer-wise adaptation for\nimproved regression-based prediction. Our framework integrates low-rank\nadapters (LoRA) with regression task heads, leveraging selected pre-trained\nTransformer layers for improved cross-lingual alignment. In addition to the\nlayer-specific adaptation, ALOPE introduces two strategies-dynamic weighting,\nwhich adaptively combines representations from multiple layers, and multi-head\nregression, which aggregates regression losses from multiple heads for QE. Our\nframework shows improvements over various existing LLM-based QE approaches.\nEmpirical evidence suggests that intermediate Transformer layers in LLMs\nprovide contextual representations that are more aligned with the cross-lingual\nnature of the QE task. We make resultant models and framework code publicly\navailable for further research, also allowing existing LLM-based MT frameworks\nto be scaled with QE capabilities.", "published": "2025-08-10 20:59:44", "link": "http://arxiv.org/abs/2508.07484v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Positional Biases Shift as Inputs Approach Context Window Limits", "abstract": "Large Language Models (LLMs) often struggle to use information across long\ninputs effectively. Prior work has identified positional biases, such as the\nLost in the Middle (LiM) effect, where models perform better when information\nappears at the beginning (primacy bias) or end (recency bias) of the input,\nrather than in the middle. However, long-context studies have not consistently\nreplicated these effects, raising questions about their intensity and the\nconditions under which they manifest. To address this, we conducted a\ncomprehensive analysis using relative rather than absolute input lengths,\ndefined with respect to each model's context window. Our findings reveal that\nthe LiM effect is strongest when inputs occupy up to 50% of a model's context\nwindow. Beyond that, the primacy bias weakens, while recency bias remains\nrelatively stable. This effectively eliminates the LiM effect; instead, we\nobserve a distance-based bias, where model performance is better when relevant\ninformation is closer to the end of the input. Furthermore, our results suggest\nthat successful retrieval is a prerequisite for reasoning in LLMs, and that the\nobserved positional biases in reasoning are largely inherited from retrieval.\nThese insights have implications for long-context tasks, the design of future\nLLM benchmarks, and evaluation methodologies for LLMs handling extended inputs.", "published": "2025-08-10 20:40:24", "link": "http://arxiv.org/abs/2508.07479v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CP-Agent: Agentic Constraint Programming", "abstract": "Translating natural language problem descriptions into formal constraint\nmodels remains a fundamental challenge in constraint programming, requiring\ndeep expertise in both the problem domain and modeling frameworks. Previous\napproaches to automating this translation have employed fixed workflows with\npredetermined modeling steps, failing on a significant number of benchmark\nproblems. We present a new approach using a pure agentic strategy without any\nfixed pipeline. We developed a general-purpose Python coding agent based on the\nReAct (Reason and Act) principle, utilizing a persistent IPython kernel for\nstateful code execution and iterative development. Rather than embedding\nconstraint programming logic into the agent architecture, domain-specific\nexpertise is injected solely through a carefully crafted project prompt. The\nagent combines this prompt-encoded knowledge with access to file operations and\ncode execution tools, enabling it to test hypotheses, debug failures, and\nverify solutions dynamically. Implemented in just a few hundred lines of code,\nthis architecture successfully solves all 101 problems of the CP-Bench\nconstraint programming benchmark set. The results suggest that constraint\nmodeling tasks require the combination of general coding tools and domain\nexpertise encoded in prompts, rather than specialized agent architectures or\npredefined workflows.", "published": "2025-08-10 19:59:01", "link": "http://arxiv.org/abs/2508.07468v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Let's Revise Step-by-Step: A Unified Local Search Framework for Code Generation with LLMs", "abstract": "Large Language Models (LLMs) with inference-time scaling techniques show\npromise for code generation, yet face notable efficiency and scalability\nchallenges. Construction-based tree-search methods suffer from rapid growth in\ntree size, high token consumption, and lack of anytime property. In contrast,\nimprovement-based methods offer better performance but often struggle with\nuninformative reward signals and inefficient search strategies. In this work,\nwe propose \\textbf{ReLoc}, a unified local search framework which effectively\nperforms step-by-step code revision. Specifically, ReLoc explores a series of\nlocal revisions through four key algorithmic components: initial code drafting,\nneighborhood code generation, candidate evaluation, and incumbent code\nupdating, each of which can be instantiated with specific decision rules to\nrealize different local search algorithms such as Hill Climbing (HC) or Genetic\nAlgorithm (GA). Furthermore, we develop a specialized revision reward model\nthat evaluates code quality based on revision distance to produce fine-grained\npreferences that guide the local search toward more promising candidates.\nFinally, our extensive experimental results demonstrate that our approach\nachieves superior performance across diverse code generation tasks,\nsignificantly outperforming both construction-based tree search as well as the\nstate-of-the-art improvement-based code generation methods.", "published": "2025-08-10 17:11:56", "link": "http://arxiv.org/abs/2508.07434v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grounding Multilingual Multimodal LLMs With Cultural Knowledge", "abstract": "Multimodal Large Language Models excel in high-resource settings, but often\nmisinterpret long-tail cultural entities and underperform in low-resource\nlanguages. To address this gap, we propose a data-centric approach that\ndirectly grounds MLLMs in cultural knowledge. Leveraging a large scale\nknowledge graph from Wikidata, we collect images that represent culturally\nsignificant entities, and generate synthetic multilingual visual question\nanswering data. The resulting dataset, CulturalGround, comprises 22 million\nhigh-quality, culturally-rich VQA pairs spanning 42 countries and 39 languages.\nWe train an open-source MLLM CulturalPangea on CulturalGround, interleaving\nstandard multilingual instruction-tuning data to preserve general abilities.\nCulturalPangea achieves state-of-the-art performance among open models on\nvarious culture-focused multilingual multimodal benchmarks, outperforming prior\nmodels by an average of 5.0 without degrading results on mainstream\nvision-language tasks. Our findings show that our targeted, culturally grounded\napproach could substantially narrow the cultural gap in MLLMs and offer a\npractical path towards globally inclusive multimodal systems.", "published": "2025-08-10 16:24:11", "link": "http://arxiv.org/abs/2508.07414v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Event-Aware Sentiment Factors from LLM-Augmented Financial Tweets: A Transparent Framework for Interpretable Quant Trading", "abstract": "In this study, we wish to showcase the unique utility of large language\nmodels (LLMs) in financial semantic annotation and alpha signal discovery.\nLeveraging a corpus of company-related tweets, we use an LLM to automatically\nassign multi-label event categories to high-sentiment-intensity tweets. We\nalign these labeled sentiment signals with forward returns over 1-to-7-day\nhorizons to evaluate their statistical efficacy and market tradability. Our\nexperiments reveal that certain event labels consistently yield negative alpha,\nwith Sharpe ratios as low as -0.38 and information coefficients exceeding 0.05,\nall statistically significant at the 95\\% confidence level. This study\nestablishes the feasibility of transforming unstructured social media text into\nstructured, multi-label event variables. A key contribution of this work is its\ncommitment to transparency and reproducibility; all code and methodologies are\nmade publicly available. Our results provide compelling evidence that social\nmedia sentiment is a valuable, albeit noisy, signal in financial forecasting\nand underscore the potential of open-source frameworks to democratize\nalgorithmic trading research.", "published": "2025-08-10 16:09:14", "link": "http://arxiv.org/abs/2508.07408v1", "categories": ["q-fin.ST", "cs.CL", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems", "abstract": "Recent advances in large language models have sparked growing interest in AI\nagents capable of solving complex, real-world tasks. However, most existing\nagent systems rely on manually crafted configurations that remain static after\ndeployment, limiting their ability to adapt to dynamic and evolving\nenvironments. To this end, recent research has explored agent evolution\ntechniques that aim to automatically enhance agent systems based on interaction\ndata and environmental feedback. This emerging direction lays the foundation\nfor self-evolving AI agents, which bridge the static capabilities of foundation\nmodels with the continuous adaptability required by lifelong agentic systems.\nIn this survey, we provide a comprehensive review of existing techniques for\nself-evolving agentic systems. Specifically, we first introduce a unified\nconceptual framework that abstracts the feedback loop underlying the design of\nself-evolving agentic systems. The framework highlights four key components:\nSystem Inputs, Agent System, Environment, and Optimisers, serving as a\nfoundation for understanding and comparing different strategies. Based on this\nframework, we systematically review a wide range of self-evolving techniques\nthat target different components of the agent system. We also investigate\ndomain-specific evolution strategies developed for specialised fields such as\nbiomedicine, programming, and finance, where optimisation objectives are\ntightly coupled with domain constraints. In addition, we provide a dedicated\ndiscussion on the evaluation, safety, and ethical considerations for\nself-evolving agentic systems, which are critical to ensuring their\neffectiveness and reliability. This survey aims to provide researchers and\npractitioners with a systematic understanding of self-evolving AI agents,\nlaying the foundation for the development of more adaptive, autonomous, and\nlifelong agentic systems.", "published": "2025-08-10 16:07:32", "link": "http://arxiv.org/abs/2508.07407v1", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Generative AI for Strategic Plan Development", "abstract": "Given recent breakthroughs in Generative Artificial Intelligence (GAI) and\nLarge Language Models (LLMs), more and more professional services are being\naugmented through Artificial Intelligence (AI), which once seemed impossible to\nautomate. This paper presents a modular model for leveraging GAI in developing\nstrategic plans for large scale government organizations and evaluates leading\nmachine learning techniques in their application towards one of the identified\nmodules. Specifically, the performance of BERTopic and Non-negative Matrix\nFactorization (NMF) are evaluated in their ability to use topic modeling to\ngenerate themes representative of Vision Elements within a strategic plan. To\naccomplish this, BERTopic and NMF models are trained using a large volume of\nreports from the Government Accountability Office (GAO). The generated topics\nfrom each model are then scored for similarity against the Vision Elements of a\npublished strategic plan and the results are compared. Our results show that\nthese techniques are capable of generating themes similar to 100% of the\nelements being evaluated against. Further, we conclude that BERTopic performs\nbest in this application with more than half of its correlated topics achieving\na \"medium\" or \"strong\" correlation. A capability of GAI-enabled strategic plan\ndevelopment impacts a multi-billion dollar industry and assists the federal\ngovernment in overcoming regulatory requirements which are crucial to the\npublic good. Further work will focus on the operationalization of the concept\nproven in this study as well as viability of the remaining modules in the\nproposed model for GAI-generated strategic plans.", "published": "2025-08-10 16:07:07", "link": "http://arxiv.org/abs/2508.07405v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7; I.5.4"], "primary_category": "cs.AI"}
{"title": "Think Before You Talk: Enhancing Meaningful Dialogue Generation in Full-Duplex Speech Language Models with Planning-Inspired Text Guidance", "abstract": "Full-Duplex Speech Language Models (FD-SLMs) are specialized foundation\nmodels designed to enable natural, real-time spoken interactions by modeling\ncomplex conversational dynamics such as interruptions, backchannels, and\noverlapping speech, and End-to-end (e2e) FD-SLMs leverage real-world\ndouble-channel conversational data to capture nuanced two-speaker dialogue\npatterns for human-like interactions. However, they face a critical challenge\n-- their conversational abilities often degrade compared to pure-text\nconversation due to prolonged speech sequences and limited high-quality spoken\ndialogue data. While text-guided speech generation could mitigate these issues,\nit suffers from timing and length issues when integrating textual guidance into\ndouble-channel audio streams, disrupting the precise time alignment essential\nfor natural interactions. To address these challenges, we propose TurnGuide, a\nnovel planning-inspired approach that mimics human conversational planning by\ndynamically segmenting assistant speech into dialogue turns and generating\nturn-level text guidance before speech output, which effectively resolves both\ninsertion timing and length challenges. Extensive experiments demonstrate our\napproach significantly improves e2e FD-SLMs' conversational abilities, enabling\nthem to generate semantically meaningful and coherent speech while maintaining\nnatural conversational flow. Demos are available at\nhttps://dreamtheater123.github.io/TurnGuide-Demo/. Code will be available at\nhttps://github.com/dreamtheater123/TurnGuide.", "published": "2025-08-10 14:49:43", "link": "http://arxiv.org/abs/2508.07375v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach", "abstract": "Numerous benchmarks have been built to evaluate the domain-specific abilities\nof large language models (LLMs), highlighting the need for effective and\nefficient benchmark construction. Existing domain-specific benchmarks primarily\nfocus on the scaling law, relying on massive corpora for supervised fine-tuning\nor generating extensive question sets for broad coverage. However, the impact\nof corpus and question-answer (QA) set design on the precision and recall of\ndomain-specific LLMs remains unexplored. In this paper, we address this gap and\ndemonstrate that the scaling law is not always the optimal principle for\nbenchmark construction in specific domains. Instead, we propose Comp-Comp, an\niterative benchmarking framework based on a comprehensiveness-compactness\nprinciple. Here, comprehensiveness ensures semantic recall of the domain, while\ncompactness enhances precision, guiding both corpus and QA set construction. To\nvalidate our framework, we conducted a case study in a well-renowned\nuniversity, resulting in the creation of XUBench, a large-scale and\ncomprehensive closed-domain benchmark. Although we use the academic domain as\nthe case in this work, our Comp-Comp framework is designed to be extensible\nbeyond academia, providing valuable insights for benchmark construction across\nvarious domains.", "published": "2025-08-10 14:08:28", "link": "http://arxiv.org/abs/2508.07353v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "PrLM: Learning Explicit Reasoning for Personalized RAG via Contrastive Reward Optimization", "abstract": "Personalized retrieval-augmented generation (RAG) aims to produce\nuser-tailored responses by incorporating retrieved user profiles alongside the\ninput query. Existing methods primarily focus on improving retrieval and rely\non large language models (LLMs) to implicitly integrate the retrieved context\nwith the query. However, such models are often sensitive to retrieval quality\nand may generate responses that are misaligned with user preferences. To\naddress this limitation, we propose PrLM, a reinforcement learning framework\nthat trains LLMs to explicitly reason over retrieved user profiles. Guided by a\ncontrastively trained personalization reward model, PrLM effectively learns\nfrom user responses without requiring annotated reasoning paths. Experiments on\nthree personalized text generation datasets show that PrLM outperforms existing\nmethods and remains robust across varying numbers of retrieved profiles and\ndifferent retrievers.", "published": "2025-08-10 13:37:26", "link": "http://arxiv.org/abs/2508.07342v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Strategies of Code-switching in Human-Machine Dialogs", "abstract": "Most people are multilingual, and most multilinguals code-switch, yet the\ncharacteristics of code-switched language are not fully understood. We\ndeveloped a chatbot capable of completing a Map Task with human participants\nusing code-switched Spanish and English. In two experiments, we prompted the\nbot to code-switch according to different strategies, examining (1) the\nfeasibility of such experiments for investigating bilingual language use, and\n(2) whether participants would be sensitive to variations in discourse and\ngrammatical patterns. Participants generally enjoyed code-switching with our\nbot as long as it produced predictable code-switching behavior; when\ncode-switching was random or ungrammatical (as when producing unattested\nincongruent mixed-language noun phrases, such as `la fork'), participants\nenjoyed the task less and were less successful at completing it. These results\nunderscore the potential downsides of deploying insufficiently developed\nmultilingual language technology, while also illustrating the promise of such\ntechnology for conducting research on bilingual language use.", "published": "2025-08-10 12:41:46", "link": "http://arxiv.org/abs/2508.07325v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ObfusQAte: A Proposed Framework to Evaluate LLM Robustness on Obfuscated Factual Question Answering", "abstract": "The rapid proliferation of Large Language Models (LLMs) has significantly\ncontributed to the development of equitable AI systems capable of factual\nquestion-answering (QA). However, no known study tests the LLMs' robustness\nwhen presented with obfuscated versions of questions. To systematically\nevaluate these limitations, we propose a novel technique, ObfusQAte and,\nleveraging the same, introduce ObfusQA, a comprehensive, first of its kind,\nframework with multi-tiered obfuscation levels designed to examine LLM\ncapabilities across three distinct dimensions: (i) Named-Entity Indirection,\n(ii) Distractor Indirection, and (iii) Contextual Overload. By capturing these\nfine-grained distinctions in language, ObfusQA provides a comprehensive\nbenchmark for evaluating LLM robustness and adaptability. Our study observes\nthat LLMs exhibit a tendency to fail or generate hallucinated responses when\nconfronted with these increasingly nuanced variations. To foster research in\nthis direction, we make ObfusQAte publicly available.", "published": "2025-08-10 12:27:52", "link": "http://arxiv.org/abs/2508.07321v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "FlexCTC: GPU-powered CTC Beam Decoding with advanced Contextual Abilities", "abstract": "While beam search improves speech recognition quality over greedy decoding,\nstandard implementations are slow, often sequential, and CPU-bound. To fully\nleverage modern hardware capabilities, we present a novel open-source FlexCTC\ntoolkit for fully GPU-based beam decoding, designed for Connectionist Temporal\nClassification (CTC) models. Developed entirely in Python and PyTorch, it\noffers a fast, user-friendly, and extensible alternative to traditional C++,\nCUDA, or WFST-based decoders. The toolkit features a high-performance, fully\nbatched GPU implementation with eliminated CPU-GPU synchronization and\nminimized kernel launch overhead via CUDA Graphs. It also supports advanced\ncontextualization techniques, including GPU-powered N-gram language model\nfusion and phrase-level boosting. These features enable accurate and efficient\ndecoding, making them suitable for both research and production use.", "published": "2025-08-10 12:15:57", "link": "http://arxiv.org/abs/2508.07315v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways", "abstract": "HealthBranches is a novel benchmark dataset for medical Question-Answering\n(Q&A), specifically designed to evaluate complex reasoning in Large Language\nModels (LLMs). This dataset is generated through a semi-automated pipeline that\ntransforms explicit decision pathways from medical source into realistic\npatient cases with associated questions and answers. Covering 4,063 case\nstudies across 17 healthcare topics, each data point is based on clinically\nvalidated reasoning chains. HealthBranches supports both open-ended and\nmultiple-choice question formats and uniquely includes the full reasoning path\nfor each Q&A. Its structured design enables robust evaluation of LLMs'\nmulti-step inference capabilities, including their performance in structured\nRetrieval-Augmented Generation (RAG) contexts. HealthBranches establishes a\nfoundation for the development of more trustworthy, interpretable, and\nclinically reliable LLMs in high-stakes domains while also serving as a\nvaluable resource for educational purposes.", "published": "2025-08-10 11:45:34", "link": "http://arxiv.org/abs/2508.07308v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CCFQA: A Benchmark for Cross-Lingual and Cross-Modal Speech and Text Factuality Evaluation", "abstract": "As Large Language Models (LLMs) are increasingly popularized in the\nmultilingual world, ensuring hallucination-free factuality becomes markedly\ncrucial. However, existing benchmarks for evaluating the reliability of\nMultimodal Large Language Models (MLLMs) predominantly focus on textual or\nvisual modalities with a primary emphasis on English, which creates a gap in\nevaluation when processing multilingual input, especially in speech. To bridge\nthis gap, we propose a novel \\textbf{C}ross-lingual and \\textbf{C}ross-modal\n\\textbf{F}actuality benchmark (\\textbf{CCFQA}). Specifically, the CCFQA\nbenchmark contains parallel speech-text factual questions across 8 languages,\ndesigned to systematically evaluate MLLMs' cross-lingual and cross-modal\nfactuality capabilities. Our experimental results demonstrate that current\nMLLMs still face substantial challenges on the CCFQA benchmark. Furthermore, we\npropose a few-shot transfer learning strategy that effectively transfers the\nQuestion Answering (QA) capabilities of LLMs in English to multilingual Spoken\nQuestion Answering (SQA) tasks, achieving competitive performance with\nGPT-4o-mini-Audio using just 5-shot training. We release CCFQA as a\nfoundational research resource to promote the development of MLLMs with more\nrobust and reliable speech understanding capabilities. Our code and dataset are\navailable at https://github.com/yxduir/ccfqa.", "published": "2025-08-10 11:09:41", "link": "http://arxiv.org/abs/2508.07295v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning", "abstract": "Developing general artificial intelligence (AI) systems to support endoscopic\nimage diagnosis is an emerging research priority. Existing methods based on\nlarge-scale pretraining often lack unified coordination across tasks and\nstruggle to handle the multi-step processes required in complex clinical\nworkflows. While AI agents have shown promise in flexible instruction parsing\nand tool integration across domains, their potential in endoscopy remains\nunderexplored. To address this gap, we propose EndoAgent, the first\nmemory-guided agent for vision-to-decision endoscopic analysis that integrates\niterative reasoning with adaptive tool selection and collaboration. Built on a\ndual-memory design, it enables sophisticated decision-making by ensuring\nlogical coherence through short-term action tracking and progressively\nenhancing reasoning acuity through long-term experiential learning. To support\ndiverse clinical tasks, EndoAgent integrates a suite of expert-designed tools\nwithin a unified reasoning loop. We further introduce EndoAgentBench, a\nbenchmark of 5,709 visual question-answer pairs that assess visual\nunderstanding and language generation capabilities in realistic scenarios.\nExtensive experiments show that EndoAgent consistently outperforms both general\nand medical multimodal models, exhibiting its strong flexibility and reasoning\ncapabilities.", "published": "2025-08-10 11:02:57", "link": "http://arxiv.org/abs/2508.07292v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Arce: Augmented Roberta with Contextualized Elucidations for Ner in Automated Rule Checking", "abstract": "Accurate information extraction from specialized texts is a critical\nchallenge, particularly for named entity recognition (NER) in the architecture,\nengineering, and construction (AEC) domain to support automated rule checking\n(ARC). The performance of standard pre-trained models is often constrained by\nthe domain gap, as they struggle to interpret the specialized terminology and\ncomplex relational contexts inherent in AEC texts. Although this issue can be\nmitigated by further pre-training on large, human-curated domain corpora, as\nexemplified by methods like ARCBERT, this approach is both labor-intensive and\ncost-prohibitive. Consequently, leveraging large language models (LLMs) for\nautomated knowledge generation has emerged as a promising alternative. However,\nthe optimal strategy for generating knowledge that can genuinely enhance\nsmaller, efficient models remains an open question. To address this, we propose\nARCE (augmented RoBERTa with contextualized elucidations), a novel approach\nthat systematically explores and optimizes this generation process. ARCE\nemploys an LLM to first generate a corpus of simple, direct explanations, which\nwe term Cote, and then uses this corpus to incrementally pre-train a RoBERTa\nmodel prior to its fine-tuning on the downstream task. Our extensive\nexperiments show that ARCE establishes a new state-of-the-art on a benchmark\nAEC dataset, achieving a Macro-F1 score of 77.20%. This result also reveals a\nkey finding: simple, explanation-based knowledge proves surprisingly more\neffective than complex, role-based rationales for this task. The code is\npublicly available at:https://github.com/nxcc-lab/ARCE.", "published": "2025-08-10 10:49:48", "link": "http://arxiv.org/abs/2508.07286v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "\"Pull or Not to Pull?'': Investigating Moral Biases in Leading Large Language Models Across Ethical Dilemmas", "abstract": "As large language models (LLMs) increasingly mediate ethically sensitive\ndecisions, understanding their moral reasoning processes becomes imperative.\nThis study presents a comprehensive empirical evaluation of 14 leading LLMs,\nboth reasoning enabled and general purpose, across 27 diverse trolley problem\nscenarios, framed by ten moral philosophies, including utilitarianism,\ndeontology, and altruism. Using a factorial prompting protocol, we elicited\n3,780 binary decisions and natural language justifications, enabling analysis\nalong axes of decisional assertiveness, explanation answer consistency, public\nmoral alignment, and sensitivity to ethically irrelevant cues. Our findings\nreveal significant variability across ethical frames and model types: reasoning\nenhanced models demonstrate greater decisiveness and structured justifications,\nyet do not always align better with human consensus. Notably, \"sweet zones\"\nemerge in altruistic, fairness, and virtue ethics framings, where models\nachieve a balance of high intervention rates, low explanation conflict, and\nminimal divergence from aggregated human judgments. However, models diverge\nunder frames emphasizing kinship, legality, or self interest, often producing\nethically controversial outcomes. These patterns suggest that moral prompting\nis not only a behavioral modifier but also a diagnostic tool for uncovering\nlatent alignment philosophies across providers. We advocate for moral reasoning\nto become a primary axis in LLM alignment, calling for standardized benchmarks\nthat evaluate not just what LLMs decide, but how and why.", "published": "2025-08-10 10:45:16", "link": "http://arxiv.org/abs/2508.07284v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "MAQuA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory", "abstract": "Recent advances in large language models (LLMs) offer new opportunities for\nscalable, interactive mental health assessment, but excessive querying by LLMs\nburdens users and is inefficient for real-world screening across\ntransdiagnostic symptom profiles. We introduce MAQuA, an adaptive\nquestion-asking framework for simultaneous, multidimensional mental health\nscreening. Combining multi-outcome modeling on language responses with item\nresponse theory (IRT) and factor analysis, MAQuA selects the questions with\nmost informative responses across multiple dimensions at each turn to optimize\ndiagnostic information, improving accuracy and potentially reducing response\nburden. Empirical results on a novel dataset reveal that MAQuA reduces the\nnumber of assessment questions required for score stabilization by 50-87%\ncompared to random ordering (e.g., achieving stable depression scores with 71%\nfewer questions and eating disorder scores with 85% fewer questions). MAQuA\ndemonstrates robust performance across both internalizing (depression, anxiety)\nand externalizing (substance use, eating disorder) domains, with early stopping\nstrategies further reducing patient time and burden. These findings position\nMAQuA as a powerful and efficient tool for scalable, nuanced, and interactive\nmental health screening, advancing the integration of LLM-based agents into\nreal-world clinical workflows.", "published": "2025-08-10 10:33:16", "link": "http://arxiv.org/abs/2508.07279v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Incorporating Contextual Paralinguistic Understanding in Large Speech-Language Models", "abstract": "Current large speech language models (Speech-LLMs) often exhibit limitations\nin empathetic reasoning, primarily due to the absence of training datasets that\nintegrate both contextual content and paralinguistic cues. In this work, we\npropose two approaches to incorporate contextual paralinguistic information\ninto model training: (1) an explicit method that provides paralinguistic\nmetadata (e.g., emotion annotations) directly to the LLM, and (2) an implicit\nmethod that automatically generates novel training question-answer (QA) pairs\nusing both categorical and dimensional emotion annotations alongside speech\ntranscriptions. Our implicit method boosts performance (LLM-judged) by 38.41%\non a human-annotated QA benchmark, reaching 46.02% when combined with the\nexplicit approach, showing effectiveness in contextual paralinguistic\nunderstanding. We also validate the LLM judge by demonstrating its correlation\nwith classification metrics, providing support for its reliability.", "published": "2025-08-10 10:03:30", "link": "http://arxiv.org/abs/2508.07273v1", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "The 2D+ Dynamic Articulatory Model DYNARTmo: Tongue-Palate Contact Area Estimation", "abstract": "This paper describes an extension of the two-dimensional dynamic articulatory\nmodel DYNARTmo by integrating an internal three-dimensional representation of\nthe palatal dome to estimate tongue-palate contact areas from midsagittal\ntongue contours. Two alternative dome geometries - a half-ellipse and a cosine\nbased profile - are implemented to model lateral curvature in the coronal\nplane. Using these geometries, lateral contact points are analytically computed\nfor each anterior-posterior position, enabling the generation of\nelectropalatography-like visualizations within the 2D+ framework. The enhanced\nmodel supports three synchronized views (sagittal, glottal, and palatal) for\nstatic and dynamic (animated) articulation displays, suitable for speech\nscience education and speech therapy. Future work includes adding a facial\n(lip) view and implementing articulatory-to-acoustic synthesis to\nquantitatively evaluate model realism.", "published": "2025-08-10 09:28:24", "link": "http://arxiv.org/abs/2508.07262v1", "categories": ["cs.CL", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Prompt Tuning for Few-Shot Continual Learning Named Entity Recognition", "abstract": "Knowledge distillation has been successfully applied to Continual Learning\nNamed Entity Recognition (CLNER) tasks, by using a teacher model trained on\nold-class data to distill old-class entities present in new-class data as a\nform of regularization, thereby avoiding catastrophic forgetting. However, in\nFew-Shot CLNER (FS-CLNER) tasks, the scarcity of new-class entities makes it\ndifficult for the trained model to generalize during inference. More\ncritically, the lack of old-class entity information hinders the distillation\nof old knowledge, causing the model to fall into what we refer to as the\nFew-Shot Distillation Dilemma. In this work, we address the above challenges\nthrough a prompt tuning paradigm and memory demonstration template strategy.\nSpecifically, we designed an expandable Anchor words-oriented Prompt Tuning\n(APT) paradigm to bridge the gap between pre-training and fine-tuning, thereby\nenhancing performance in few-shot scenarios. Additionally, we incorporated\nMemory Demonstration Templates (MDT) into each training instance to provide\nreplay samples from previous tasks, which not only avoids the Few-Shot\nDistillation Dilemma but also promotes in-context learning. Experiments show\nthat our approach achieves competitive performances on FS-CLNER.", "published": "2025-08-10 09:02:53", "link": "http://arxiv.org/abs/2508.07248v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Does a Deep Neural Network Look at Lexical Stress?", "abstract": "Despite their success in speech processing, neural networks often operate as\nblack boxes, prompting the question: what informs their decisions, and how can\nwe interpret them? This work examines this issue in the context of lexical\nstress. A dataset of English disyllabic words was automatically constructed\nfrom read and spontaneous speech. Several Convolutional Neural Network (CNN)\narchitectures were trained to predict stress position from a spectrographic\nrepresentation of disyllabic words lacking minimal stress pairs (e.g., initial\nstress WAllet, final stress exTEND), achieving up to 92% accuracy on held-out\ntest data. Layerwise Relevance Propagation (LRP), a technique for CNN\ninterpretability analysis, revealed that predictions for held-out minimal pairs\n(PROtest vs. proTEST ) were most strongly influenced by information in stressed\nversus unstressed syllables, particularly the spectral properties of stressed\nvowels. However, the classifiers also attended to information throughout the\nword. A feature-specific relevance analysis is proposed, and its results\nsuggest that our best-performing classifier is strongly influenced by the\nstressed vowel's first and second formants, with some evidence that its pitch\nand third formant also contribute. These results reveal deep learning's ability\nto acquire distributed cues to stress from naturally occurring data, extending\ntraditional phonetic work based around highly controlled stimuli.", "published": "2025-08-10 08:13:40", "link": "http://arxiv.org/abs/2508.07229v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Enhancing Rumor Detection Methods with Propagation Structure Infused Language Model", "abstract": "Pretrained Language Models (PLMs) have excelled in various Natural Language\nProcessing tasks, benefiting from large-scale pretraining and self-attention\nmechanism's ability to capture long-range dependencies. However, their\nperformance on social media application tasks like rumor detection remains\nsuboptimal. We attribute this to mismatches between pretraining corpora and\nsocial texts, inadequate handling of unique social symbols, and pretraining\ntasks ill-suited for modeling user engagements implicit in propagation\nstructures. To address these issues, we propose a continue pretraining strategy\ncalled Post Engagement Prediction (PEP) to infuse information from propagation\nstructures into PLMs. PEP makes models to predict root, branch, and parent\nrelations between posts, capturing interactions of stance and sentiment crucial\nfor rumor detection. We also curate and release large-scale Twitter corpus:\nTwitterCorpus (269GB text), and two unlabeled claim conversation datasets with\npropagation structures (UTwitter and UWeibo). Utilizing these resources and PEP\nstrategy, we train a Twitter-tailored PLM called SoLM. Extensive experiments\ndemonstrate PEP significantly boosts rumor detection performance across\nuniversal and social media PLMs, even in few-shot scenarios. On benchmark\ndatasets, PEP enhances baseline models by 1.0-3.7\\% accuracy, even enabling it\nto outperform current state-of-the-art methods on multiple datasets. SoLM\nalone, without high-level modules, also achieves competitive results,\nhighlighting the strategy's effectiveness in learning discriminative post\ninteraction features.", "published": "2025-08-10 07:04:50", "link": "http://arxiv.org/abs/2508.07209v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Towards Real-World Rumor Detection: Anomaly Detection Framework with Graph Supervised Contrastive Learning", "abstract": "Current rumor detection methods based on propagation structure learning\npredominately treat rumor detection as a class-balanced classification task on\nlimited labeled data. However, real-world social media data exhibits an\nimbalanced distribution with a minority of rumors among massive regular posts.\nTo address the data scarcity and imbalance issues, we construct two large-scale\nconversation datasets from Weibo and Twitter and analyze the domain\ndistributions. We find obvious differences between rumor and non-rumor\ndistributions, with non-rumors mostly in entertainment domains while rumors\nconcentrate in news, indicating the conformity of rumor detection to an anomaly\ndetection paradigm. Correspondingly, we propose the Anomaly Detection framework\nwith Graph Supervised Contrastive Learning (AD-GSCL). It heuristically treats\nunlabeled data as non-rumors and adapts graph contrastive learning for rumor\ndetection. Extensive experiments demonstrate AD-GSCL's superiority under\nclass-balanced, imbalanced, and few-shot conditions. Our findings provide\nvaluable insights for real-world rumor detection featuring imbalanced data\ndistributions.", "published": "2025-08-10 06:59:33", "link": "http://arxiv.org/abs/2508.07205v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Propagation Tree Is Not Deep: Adaptive Graph Contrastive Learning Approach for Rumor Detection", "abstract": "Rumor detection on social media has become increasingly important. Most\nexisting graph-based models presume rumor propagation trees (RPTs) have deep\nstructures and learn sequential stance features along branches. However,\nthrough statistical analysis on real-world datasets, we find RPTs exhibit wide\nstructures, with most nodes being shallow 1-level replies. To focus learning on\nintensive substructures, we propose Rumor Adaptive Graph Contrastive Learning\n(RAGCL) method with adaptive view augmentation guided by node centralities. We\nsummarize three principles for RPT augmentation: 1) exempt root nodes, 2)\nretain deep reply nodes, 3) preserve lower-level nodes in deep sections. We\nemploy node dropping, attribute masking and edge dropping with probabilities\nfrom centrality-based importance scores to generate views. A graph contrastive\nobjective then learns robust rumor representations. Extensive experiments on\nfour benchmark datasets demonstrate RAGCL outperforms state-of-the-art methods.\nOur work reveals the wide-structure nature of RPTs and contributes an effective\ngraph contrastive learning approach tailored for rumor detection through\nprincipled adaptive augmentation. The proposed principles and augmentation\ntechniques can potentially benefit other applications involving tree-structured\ngraphs.", "published": "2025-08-10 06:53:30", "link": "http://arxiv.org/abs/2508.07201v1", "categories": ["cs.SI", "cs.AI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment", "abstract": "Large Language Models (LLMs) have recently demonstrated impressive\ncapabilities in natural language processing due to their strong generalization\nand sequence modeling capabilities. However, their direct application to time\nseries forecasting remains challenging due to two fundamental issues: the\ninherent heterogeneity of temporal patterns and the modality gap between\ncontinuous numerical signals and discrete language representations. In this\nwork, we propose TALON, a unified framework that enhances LLM-based forecasting\nby modeling temporal heterogeneity and enforcing semantic alignment.\nSpecifically, we design a Heterogeneous Temporal Encoder that partitions\nmultivariate time series into structurally coherent segments, enabling\nlocalized expert modeling across diverse temporal patterns. To bridge the\nmodality gap, we introduce a Semantic Alignment Module that aligns temporal\nfeatures with LLM-compatible representations, enabling effective integration of\ntime series into language-based models while eliminating the need for\nhandcrafted prompts during inference. Extensive experiments on seven real-world\nbenchmarks demonstrate that TALON achieves superior performance across all\ndatasets, with average MSE improvements of up to 11\\% over recent\nstate-of-the-art methods. These results underscore the effectiveness of\nincorporating both pattern-aware and semantic-aware designs when adapting LLMs\nfor time series forecasting. The code is available at:\nhttps://github.com/syrGitHub/TALON.", "published": "2025-08-10 06:06:19", "link": "http://arxiv.org/abs/2508.07195v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention", "abstract": "Large Language Models (LLMs) suffer from a critical limitation: their\nknowledge is static and quickly becomes outdated. Retraining these massive\nmodels is computationally prohibitive, while existing knowledge editing\ntechniques can be slow and may introduce unforeseen side effects. To address\nthis, we propose DySK-Attn, a novel framework that enables LLMs to efficiently\nintegrate real-time knowledge from a dynamic external source. Our approach\nsynergizes an LLM with a dynamic Knowledge Graph (KG) that can be updated\ninstantaneously. The core of our framework is a sparse knowledge attention\nmechanism, which allows the LLM to perform a coarse-to-fine grained search,\nefficiently identifying and focusing on a small, highly relevant subset of\nfacts from the vast KG. This mechanism avoids the high computational cost of\ndense attention over the entire knowledge base and mitigates noise from\nirrelevant information. We demonstrate through extensive experiments on\ntime-sensitive question-answering tasks that DySK-Attn significantly\noutperforms strong baselines, including standard Retrieval-Augmented Generation\n(RAG) and model editing techniques, in both factual accuracy for updated\nknowledge and computational efficiency. Our framework offers a scalable and\neffective solution for building LLMs that can stay current with the\never-changing world.", "published": "2025-08-10 05:22:38", "link": "http://arxiv.org/abs/2508.07185v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; H.3.3; H.2.8"], "primary_category": "cs.CL"}
{"title": "Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks", "abstract": "Enterprise data pipelines, characterized by complex transformations across\nmultiple programming languages, often cause a semantic disconnect between\noriginal metadata and downstream data. This \"semantic drift\" compromises data\nreproducibility and governance, and impairs the utility of services like\nretrieval-augmented generation (RAG) and text-to-SQL systems. To address this,\na novel framework is proposed for the automated extraction of fine-grained\nschema lineage from multilingual enterprise pipeline scripts. This method\nidentifies four key components: source schemas, source tables, transformation\nlogic, and aggregation operations, creating a standardized representation of\ndata transformations. For the rigorous evaluation of lineage quality, this\npaper introduces the Schema Lineage Composite Evaluation (SLiCE), a metric that\nassesses both structural correctness and semantic fidelity. A new benchmark is\nalso presented, comprising 1,700 manually annotated lineages from real-world\nindustrial scripts. Experiments were conducted with 12 language models, from\n1.3B to 32B small language models (SLMs) to large language models (LLMs) like\nGPT-4o and GPT-4.1. The results demonstrate that the performance of schema\nlineage extraction scales with model size and the sophistication of prompting\ntechniques. Specially, a 32B open-source model, using a single reasoning trace,\ncan achieve performance comparable to the GPT series under standard prompting.\nThis finding suggests a scalable and economical approach for deploying\nschema-aware agents in practical applications.", "published": "2025-08-10 05:04:32", "link": "http://arxiv.org/abs/2508.07179v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback", "abstract": "Accurate personalized headline generation hinges on precisely capturing user\ninterests from historical behaviors. However, existing methods neglect\npersonalized-irrelevant click noise in entire historical clickstreams, which\nmay lead to hallucinated headlines that deviate from genuine user preferences.\nIn this paper, we reveal the detrimental impact of click noise on personalized\ngeneration quality through rigorous analysis in both user and news dimensions.\nBased on these insights, we propose a novel Personalized Headline Generation\nframework via Denoising Fake Interests from Implicit Feedback (PHG-DIF).\nPHG-DIF first employs dual-stage filtering to effectively remove clickstream\nnoise, identified by short dwell times and abnormal click bursts, and then\nleverages multi-level temporal fusion to dynamically model users' evolving and\nmulti-faceted interests for precise profiling. Moreover, we release DT-PENS, a\nnew benchmark dataset comprising the click behavior of 1,000 carefully curated\nusers and nearly 10,000 annotated personalized headlines with historical dwell\ntime annotations. Extensive experiments demonstrate that PHG-DIF substantially\nmitigates the adverse effects of click noise and significantly improves\nheadline quality, achieving state-of-the-art (SOTA) results on DT-PENS. Our\nframework implementation and dataset are available at\nhttps://github.com/liukejin-up/PHG-DIF.", "published": "2025-08-10 04:56:13", "link": "http://arxiv.org/abs/2508.07178v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models", "abstract": "The rise of Omni-modal Large Language Models (OLLMs), which integrate visual\nand auditory processing with text, necessitates robust safety evaluations to\nmitigate harmful outputs. However, no dedicated benchmarks currently exist for\nOLLMs, and prior benchmarks designed for other LLMs lack the ability to assess\nsafety performance under audio-visual joint inputs or cross-modal safety\nconsistency. To fill this gap, we introduce Omni-SafetyBench, the first\ncomprehensive parallel benchmark for OLLM safety evaluation, featuring 24\nmodality combinations and variations with 972 samples each, including dedicated\naudio-visual harm cases. Considering OLLMs' comprehension challenges with\ncomplex omni-modal inputs and the need for cross-modal consistency evaluation,\nwe propose tailored metrics: a Safety-score based on conditional Attack Success\nRate (C-ASR) and Refusal Rate (C-RR) to account for comprehension failures, and\na Cross-Modal Safety Consistency Score (CMSC-score) to measure consistency\nacross modalities. Evaluating 6 open-source and 4 closed-source OLLMs reveals\ncritical vulnerabilities: (1) no model excels in both overall safety and\nconsistency, with only 3 models achieving over 0.6 in both metrics and top\nperformer scoring around 0.8; (2) safety defenses weaken with complex inputs,\nespecially audio-visual joints; (3) severe weaknesses persist, with some models\nscoring as low as 0.14 on specific modalities. Our benchmark and metrics\nhighlight urgent needs for enhanced OLLM safety, providing a foundation for\nfuture improvements.", "published": "2025-08-10 04:15:16", "link": "http://arxiv.org/abs/2508.07173v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Gradient Surgery for Safe LLM Fine-Tuning", "abstract": "Fine-tuning-as-a-Service introduces a critical vulnerability where a few\nmalicious examples mixed into the user's fine-tuning dataset can compromise the\nsafety alignment of Large Language Models (LLMs). While a recognized paradigm\nframes safe fine-tuning as a multi-objective optimization problem balancing\nuser task performance with safety alignment, we find existing solutions are\ncritically sensitive to the harmful ratio, with defenses degrading sharply as\nharmful ratio increases. We diagnose that this failure stems from conflicting\ngradients, where the user-task update directly undermines the safety objective.\nTo resolve this, we propose SafeGrad, a novel method that employs gradient\nsurgery. When a conflict is detected, SafeGrad nullifies the harmful component\nof the user-task gradient by projecting it onto the orthogonal plane of the\nalignment gradient, allowing the model to learn the user's task without\nsacrificing safety. To further enhance robustness and data efficiency, we\nemploy a KL-divergence alignment loss that learns the rich, distributional\nsafety profile of the well-aligned foundation model. Extensive experiments show\nthat SafeGrad provides state-of-the-art defense across various LLMs and\ndatasets, maintaining robust safety even at high harmful ratios without\ncompromising task fidelity.", "published": "2025-08-10 04:13:41", "link": "http://arxiv.org/abs/2508.07172v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens", "abstract": "Automatic Speech Recognition (ASR) systems now mediate countless\nhuman-technology interactions, yet research on their fairness implications\nremains surprisingly limited. This paper examines ASR bias through a\nphilosophical lens, arguing that systematic misrecognition of certain speech\nvarieties constitutes more than a technical limitation -- it represents a form\nof disrespect that compounds historical injustices against marginalized\nlinguistic communities. We distinguish between morally neutral classification\n(discriminate1) and harmful discrimination (discriminate2), demonstrating how\nASR systems can inadvertently transform the former into the latter when they\nconsistently misrecognize non-standard dialects. We identify three unique\nethical dimensions of speech technologies that differentiate ASR bias from\nother algorithmic fairness concerns: the temporal burden placed on speakers of\nnon-standard varieties (\"temporal taxation\"), the disruption of conversational\nflow when systems misrecognize speech, and the fundamental connection between\nspeech patterns and personal/cultural identity. These factors create asymmetric\npower relationships that existing technical fairness metrics fail to capture.\nThe paper analyzes the tension between linguistic standardization and pluralism\nin ASR development, arguing that current approaches often embed and reinforce\nproblematic language ideologies. We conclude that addressing ASR bias requires\nmore than technical interventions; it demands recognition of diverse speech\nvarieties as legitimate forms of expression worthy of technological\naccommodation. This philosophical reframing offers new pathways for developing\nASR systems that respect linguistic diversity and speaker autonomy.", "published": "2025-08-10 02:26:47", "link": "http://arxiv.org/abs/2508.07143v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Optimal Representation for Right-to-Left Parallel Scalar Point Multiplication", "abstract": "This paper introduces an optimal representation for a right-to-left parallel\nelliptic curve scalar point multiplication. The right-to-left approach is\neasier to parallelize than the conventional left-to-right approach. However,\nunlike the left-to-right approach, there is still no work considering number\nrepresentations for the right-to-left parallel calculation. By simplifying the\nimplementation by Robert, we devise a mathematical model to capture the\ncomputation time of the calculation. Then, for any arbitrary amount of doubling\ntime and addition time, we propose algorithms to generate representations which\nminimize the time in that model. As a result, we can show a negative result\nthat a conventional representation like NAF is almost optimal. The parallel\ncomputation time obtained from any representation cannot be better than NAF by\nmore than 1%.", "published": "2025-08-10 11:55:14", "link": "http://arxiv.org/abs/2508.07310v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "IP Models for Minimum Zero Forcing Sets, Forts, and Related Graph Parameters", "abstract": "Zero forcing is a binary coloring game on a graph where a set of filled\nvertices can force non-filled vertices to become filled following a color\nchange rule. In 2008, the zero forcing number of a graph was shown to be an\nupper bound on its maximum nullity. In addition, the combinatorial optimization\nproblem for the zero forcing number was shown to be NP-hard. Since then, the\nstudy of zero forcing and its related parameters has received considerable\nattention. In 2018, the forts of a graph were defined as non-empty subsets of\nvertices where no vertex outside the set has exactly one neighbor in the set.\nForts have been used to model zero forcing as an integer program and provide\nlower bounds on the zero forcing number. To date, three integer programming\nmodels have been developed for the zero forcing number of a graph: the\nInfection Model, Time Step Model, and Fort Cover Model. In this article, we\npresent variations of these models for computing the zero forcing number and\nrelated graph parameters, such as the minimum and maximum propagation times,\nthrottling number, and fractional zero forcing number. In addition, we present\nseveral new models for computing the realized propagation time interval, all\nminimal forts of a graph, and the fort number of a graph. We conclude with\nseveral numerical experiments that demonstrate the effectiveness of our models\nwhen applied to small and medium order graphs. Moreover, we provide\nexperimental evidence for several open conjectures regarding the propagation\ntime interval, the number of minimal forts, the fort number, and the fractional\nzero forcing number of a graph.", "published": "2025-08-10 11:05:27", "link": "http://arxiv.org/abs/2508.07293v1", "categories": ["math.CO", "cs.DM", "05C15, 05C30, 05C57, 05C76, 90C10, 90C27, 90C90"], "primary_category": "math.CO"}
{"title": "A Globally Optimal Analytic Solution for Semi-Nonnegative Matrix Factorization with Nonnegative or Mixed Inputs", "abstract": "Semi-Nonnegative Matrix Factorization (semi-NMF) extends classical\nNonnegative Matrix Factorization (NMF) by allowing the basis matrix to contain\nboth positive and negative entries, making it suitable for decomposing data\nwith mixed signs. However, most existing semi-NMF algorithms are iterative,\nnon-convex, and prone to local minima. In this paper, we propose a novel method\nthat yields a globally optimal solution to the semi-NMF problem under the\nFrobenius norm, through an orthogonal decomposition derived from the scatter\nmatrix of the input data. We rigorously prove that our solution attains the\nglobal minimum of the reconstruction error. Furthermore, we demonstrate that\nwhen the input matrix is nonnegative, our method often achieves lower\nreconstruction error than standard NMF algorithms, although unfortunately the\nbasis matrix may not satisfy nonnegativity. In particular, in low-rank cases\nsuch as rank 1 or 2, our solution reduces exactly to a nonnegative\nfactorization, recovering the NMF structure. We validate our approach through\nexperiments on both synthetic data and the UCI Wine dataset, showing that our\nmethod consistently outperforms existing NMF and semi-NMF methods in terms of\nreconstruction accuracy. These results confirm that our globally optimal,\nnon-iterative formulation offers both theoretical guarantees and empirical\nadvantages, providing a new perspective on matrix factorization in optimization\nand data analysis.", "published": "2025-08-10 01:15:29", "link": "http://arxiv.org/abs/2508.07134v1", "categories": ["cs.LG", "cs.DM", "15A23, 90C26, 62H25", "I.2.6; I.5.3"], "primary_category": "cs.LG"}
{"title": "Block encoding the 3D heterogeneous Poisson equation with application to fracture flow", "abstract": "Quantum linear system (QLS) algorithms offer the potential to solve\nlarge-scale linear systems exponentially faster than classical methods.\nHowever, applying QLS algorithms to real-world problems remains challenging due\nto issues such as state preparation, data loading, and efficient information\nextraction. In this work, we study the feasibility of applying QLS algorithms\nto solve discretized three-dimensional heterogeneous Poisson equations, with\nspecific examples relating to groundwater flow through geologic fracture\nnetworks. We explicitly construct a block encoding for the 3D heterogeneous\nPoisson matrix by leveraging the sparse local structure of the discretized\noperator. While classical solvers benefit from preconditioning, we show that\nblock encoding the system matrix and preconditioner separately does not improve\nthe effective condition number that dominates the QLS runtime. This differs\nfrom classical approaches where the preconditioner and the system matrix can\noften be implemented independently. Nevertheless, due to the structure of the\nproblem in three dimensions, the quantum algorithm achieves a runtime of\n$O(N^{2/3} \\ \\text{polylog } N \\cdot \\log(1/\\epsilon))$, outperforming the best\nclassical methods (with runtimes of $O(N \\log N \\cdot \\log(1/\\epsilon))$) and\noffering exponential memory savings. These results highlight both the promise\nand limitations of QLS algorithms for practical scientific computing, and point\nto effective condition number reduction as a key barrier in achieving quantum\nadvantages.", "published": "2025-08-10 00:17:09", "link": "http://arxiv.org/abs/2508.07125v1", "categories": ["quant-ph", "cs.DM"], "primary_category": "quant-ph"}
{"title": "Are Multimodal Embeddings Truly Beneficial for Recommendation? A Deep Dive into Whole vs. Individual Modalities", "abstract": "Multimodal recommendation (MMRec) has emerged as a mainstream paradigm,\ntypically leveraging text and visual embeddings extracted from pre-trained\nmodels such as Sentence-BERT, Vision Transformers, and ResNet. This approach is\nfounded on the intuitive assumption that incorporating multimodal embeddings\ncan enhance recommendation performance. However, despite its popularity, this\nassumption lacks comprehensive empirical verification. This presents a critical\nresearch gap. To address it, we pose the central research question of this\npaper: Are multimodal embeddings truly beneficial for recommendation? To answer\nthis question, we conduct a large-scale empirical study examining the role of\ntext and visual embeddings in modern MMRec models, both as a whole and\nindividually. Specifically, we pose two key research questions: (1) Do\nmultimodal embeddings as a whole improve recommendation performance? (2) Is\neach individual modality - text and image - useful when used alone? To isolate\nthe effect of individual modalities - text or visual - we employ a modality\nknockout strategy by setting the corresponding embeddings to either constant\nvalues or random noise. To ensure the scale and comprehensiveness of our study,\nwe evaluate 14 widely used state-of-the-art MMRec models. Our findings reveal\nthat: (1) multimodal embeddings generally enhance recommendation performance -\nparticularly when integrated through more sophisticated graph-based fusion\nmodels. Surprisingly, commonly adopted baseline models with simple fusion\nschemes, such as VBPR and BM3, show only limited gains. (2) The text modality\nalone achieves performance comparable to the full multimodal setting in most\ncases, whereas the image modality alone does not. These results offer\nfoundational insights and practical guidance for the MMRec community. We will\nrelease our code and datasets to facilitate future research.", "published": "2025-08-10 15:59:21", "link": "http://arxiv.org/abs/2508.07399v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "SocRipple: A Two-Stage Framework for Cold-Start Video Recommendations", "abstract": "Most industry scale recommender systems face critical cold start challenges\nnew items lack interaction history, making it difficult to distribute them in a\npersonalized manner. Standard collaborative filtering models underperform due\nto sparse engagement signals, while content only approaches lack user specific\nrelevance. We propose SocRipple, a novel two stage retrieval framework tailored\nfor coldstart item distribution in social graph based platforms. Stage 1\nleverages the creators social connections for targeted initial exposure. Stage\n2 builds on early engagement signals and stable user embeddings learned from\nhistorical interactions to \"ripple\" outwards via K Nearest Neighbor (KNN)\nsearch. Large scale experiments on a major video platform show that SocRipple\nboosts cold start item distribution by +36% while maintaining user engagement\nrate on cold start items, effectively balancing new item exposure with\npersonalized recommendations.", "published": "2025-08-10 08:37:36", "link": "http://arxiv.org/abs/2508.07241v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Selection and Exploitation of High-Quality Knowledge from Large Language Models for Recommendation", "abstract": "In recent years, there has been growing interest in leveraging the impressive\ngeneralization capabilities and reasoning ability of large language models\n(LLMs) to improve the performance of recommenders. With this operation,\nrecommenders can access and learn the additional world knowledge and reasoning\ninformation via LLMs. However, in general, for different users and items, the\nworld knowledge derived from LLMs suffers from issues of hallucination, content\nredundant, and information homogenization. Directly feeding the generated\nresponse embeddings into the recommendation model can lead to unavoidable\nperformance deterioration. To address these challenges, we propose a Knowledge\nSelection \\& Exploitation Recommendation (KSER) framework, which effectively\nselect and extracts the high-quality knowledge from LLMs. The framework\nconsists of two key components: a knowledge filtering module and a embedding\nspaces alignment module. In the knowledge filtering module, a Embedding\nSelection Filter Network (ESFNet) is designed to assign adaptive weights to\ndifferent knowledge chunks in different knowledge fields. In the space\nalignment module, an attention-based architecture is proposed to align the\nsemantic embeddings from LLMs with the feature space used to train the\nrecommendation models. In addition, two training\nstrategies--\\textbf{all-parameters training} and \\textbf{extractor-only\ntraining}--are proposed to flexibly adapt to different downstream tasks and\napplication scenarios, where the extractor-only training strategy offers a\nnovel perspective on knowledge-augmented recommendation. Experimental results\nvalidate the necessity and effectiveness of both the knowledge filtering and\nalignment modules, and further demonstrate the efficiency and effectiveness of\nthe extractor-only training strategy.", "published": "2025-08-10 08:03:01", "link": "http://arxiv.org/abs/2508.07223v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Uncertainty-Aware Semantic Decoding for LLM-Based Sequential Recommendation", "abstract": "Large language models have been widely applied to sequential recommendation\ntasks, yet during inference, they continue to rely on decoding strategies\ndeveloped for natural language processing. This creates a mismatch between\ntext-generation objectives and recommendation next item selection objectives.\nThis paper addresses this limitation by proposing an Uncertainty-aware Semantic\nDecoding (USD) framework that combines logit-based clustering with adaptive\nscoring to improve next-item predictions. Our approach clusters items with\nsimilar logit vectors into semantic equivalence groups, then redistributes\nprobability mass within these clusters and computes entropy across them to\ncontrol item scoring and sampling temperature during recommendation inference.\nExperiments on Amazon Product datasets (six domains) gains of 18.5\\% in HR@3,\n11.9\\% in NDCG@3, and 10.8\\% in MRR@3 compared to state-of-the-art baselines.\nHyperparameter analysis confirms the optimal parameters among various settings,\nand experiments on H\\&M, and Netflix datasets indicate that the framework can\nadapt to differing recommendation domains. The experimental results confirm\nthat integrating semantic clustering and uncertainty assessment yields more\nreliable and accurate recommendations.", "published": "2025-08-10 07:10:59", "link": "http://arxiv.org/abs/2508.07210v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Structured Superposition of Autoencoders for UEP Codes at Intermediate Blocklengths", "abstract": "Unequal error protection (UEP) coding that enables differentiated reliability\nlevels within a transmitted message is essential for modern communication\nsystems. Autoencoder (AE)-based code designs have shown promise in the context\nof learned equal error protection (EEP) coding schemes. However, their\napplication to UEP remains largely unexplored, particularly at intermediate\nblocklengths, due to the increasing complexity of AE-based models. Inspired by\nthe proven effectiveness of superposition coding and successive interference\ncancellation (SIC) decoding in conventional UEP schemes, we propose a\nstructured AE-based architecture that extends AE-based UEP codes to\nsubstantially larger blocklengths while maintaining efficient training. By\nstructuring encoding and decoding into smaller AE subblocks, our method\nprovides a flexible framework for fine-tuning UEP reliability levels while\nadapting to diverse system parameters. Numerical results show that the proposed\napproach improves over established achievability bounds of randomized\nsuperposition coding-based UEP schemes with SIC decoding, making the proposed\nstructured AE-based UEP codes a scalable and efficient solution for\nnext-generation networks.", "published": "2025-08-10 21:09:30", "link": "http://arxiv.org/abs/2508.07487v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Duality on group algebras over finite chain rings: applications to additive group codes", "abstract": "Given a finite group $G$ and an extension of finite chain rings $S|R$, one\ncan consider the group rings $\\mathscr{S} = S[G]$ and $\\mathscr{R} = R[G]$. The\ngroup ring $\\mathscr{S}$ can be viewed as an $R$-bimodule, and any of its\n$R$-submodules naturally inherits an $R$-bimodule structure; in the framework\nof coding theory, these are called \\emph{additive group codes}, more precisely\na (left) additive group code of is a linear code which is the image of a (left)\nideal of a group algebra via an isomorphism which maps $G$ to the standard\nbasis of $S^n$, where $n=|G|$. In the first part of the paper, the ring\nextension $S|R$ is studied, and several $R$-module isomorphisms are established\nfor decomposing group rings, thereby providing a characterization of the\nstructure of additive group codes. In the second part, we construct a\nsymmetric, nondegenerate trace-Euclidean inner product on $\\mathscr{S}$. Two\nadditive group codes $\\mathcal{C}$ and $\\mathcal{D}$ form an \\emph{additive\ncomplementary pair} (ACP) if $\\mathcal{C} + \\mathcal{D} = \\mathscr{S}$ and\n$\\mathcal{C} \\cap \\mathcal{D} = \\{0\\}$. For two-sided ACPs, we prove that the\northogonal complement of one code under the trace-Euclidean duality is\nprecisely the image of the other under an involutive anti-automorphism of\n$\\mathscr{S}$, linking coding-theoretical ACPs with module orthogonal\ndirect-sum decompositions, representation theory, and the structure of group\nalgebras over finite chain rings.", "published": "2025-08-10 19:18:19", "link": "http://arxiv.org/abs/2508.07461v1", "categories": ["cs.IT", "math.IT", "math.RA", "16D70, 94B60, 12E20, 08A40"], "primary_category": "cs.IT"}
{"title": "SGD Convergence under Stepsize Shrinkage in Low-Precision Training", "abstract": "Low-precision training has become essential for reducing the computational\nand memory costs of large-scale deep learning. However, quantization of\ngradients introduces both magnitude shrinkage and additive noise, which can\nalter the convergence behavior of stochastic gradient descent (SGD). In this\nwork, we study the convergence of SGD under a gradient shrinkage model, where\neach stochastic gradient is scaled by a factor $q_k \\in (0,1]$ and perturbed by\nzero-mean quantization noise. We show that this shrinkage is equivalent to\nreplacing the nominal stepsize $\\mu_k$ with an effective stepsize $\\mu_k q_k$,\nwhich slows convergence when $q_{\\min} < 1$. Under standard smoothness and\nbounded-variance assumptions, we prove that low-precision SGD still converges,\nbut at a reduced rate determined by $q_{\\min}$, and with an increased\nasymptotic error floor due to quantization noise. We theoretically analyze how\nreduced numerical precision slows down training by modeling it as gradient\nshrinkage in the standard SGD convergence framework.", "published": "2025-08-10 02:25:48", "link": "http://arxiv.org/abs/2508.07142v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.NA", "math.IT", "math.NA"], "primary_category": "cs.LG"}
{"title": "Pinching-Antenna System Design with LoS Blockage: Does In-Waveguide Attenuation Matter?", "abstract": "In the literature of pinching-antenna systems, in-waveguide attenuation is\noften neglected to simplify system design and enable more tractable analysis.\nHowever, its effect on overall system performance has received limited\nattention in the existing literature. While a recent study has shown that, in\nline-of-sight (LoS)-dominated environments, the data rate loss incurred by\nomitting in-waveguide attenuation is negligible when the communication area is\nnot excessively large, its effect under more general conditions remains\nunclear. This work extends the analysis to more realistic scenarios involving\narbitrary levels of LoS blockage. We begin by examining a single-user case and\nderive an explicit expression for the average data rate loss caused by\nneglecting in-waveguide attenuation. The results demonstrate that, even for\nlarge service areas, the rate loss remains negligible under typical LoS\nblockage conditions. We then consider a more general multi-user scenario, where\nmultiple pinching antennas, each deployed on a separate waveguide, jointly\nserve multiple users. The objective is to maximize the average sum rate by\njointly optimize antenna positions and transmit beamformers to maximize the\naverage sum rate under probabilistic LoS blockage. To solve the resulting\nstochastic and nonconvex optimization problem, we propose a dynamic sample\naverage approximation (SAA) algorithm. At each iteration, this method replaces\nthe expected objective with an empirical average computed from dynamically\nregenerated random channel realizations, ensuring that the optimization\naccurately reflects the current antenna configuration. Extensive simulation\nresults are provided to the proposed algorithm and demonstrate the substantial\nperformance gains of pinching-antenna systems, particularly in environments\nwith significant LoS blockage.", "published": "2025-08-10 00:37:30", "link": "http://arxiv.org/abs/2508.07131v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Noise-Aware Generative Microscopic Traffic Simulation", "abstract": "Accurately modeling individual vehicle behavior in microscopic traffic\nsimulation remains a key challenge in intelligent transportation systems, as it\nrequires vehicles to realistically generate and respond to complex traffic\nphenomena such as phantom traffic jams. While traditional human driver\nsimulation models offer computational tractability, they do so by abstracting\naway the very complexity that defines human driving. On the other hand, recent\nadvances in infrastructure-mounted camera-based roadway sensing have enabled\nthe extraction of vehicle trajectory data, presenting an opportunity to shift\ntoward generative, agent-based models. Yet, a major bottleneck remains: most\nexisting datasets are either overly sanitized or lack standardization, failing\nto reflect the noisy, imperfect nature of real-world sensing. Unlike data from\nvehicle-mounted sensors-which can mitigate sensing artifacts like occlusion\nthrough overlapping fields of view and sensor fusion-infrastructure-based\nsensors surface a messier, more practical view of challenges that traffic\nengineers encounter. To this end, we present the I-24 MOTION Scenario Dataset\n(I24-MSD)-a standardized, curated dataset designed to preserve a realistic\nlevel of sensor imperfection, embracing these errors as part of the learning\nproblem rather than an obstacle to overcome purely from preprocessing. Drawing\nfrom noise-aware learning strategies in computer vision, we further adapt\nexisting generative models in the autonomous driving community for I24-MSD with\nnoise-aware loss functions. Our results show that such models not only\noutperform traditional baselines in realism but also benefit from explicitly\nengaging with, rather than suppressing, data imperfection. We view I24-MSD as a\nstepping stone toward a new generation of microscopic traffic simulation that\nembraces the real-world challenges and is better aligned with practical needs.", "published": "2025-08-10 18:41:49", "link": "http://arxiv.org/abs/2508.07453v1", "categories": ["eess.SY", "cs.AI", "cs.MA", "cs.RO", "cs.SY"], "primary_category": "eess.SY"}
{"title": "A Survey on Agentic Service Ecosystems: Measurement, Analysis, and Optimization", "abstract": "The Agentic Service Ecosystem consists of heterogeneous autonomous agents\n(e.g., intelligent machines, humans, and human-machine hybrid systems) that\ninteract through resource exchange and service co-creation. These agents, with\ndistinct behaviors and motivations, exhibit autonomous perception, reasoning,\nand action capabilities, which increase system complexity and make traditional\nlinear analysis methods inadequate. Swarm intelligence, characterized by\ndecentralization, self-organization, emergence, and dynamic adaptability,\noffers a novel theoretical lens and methodology for understanding and\noptimizing such ecosystems. However, current research, owing to fragmented\nperspectives and cross-ecosystem differences, fails to comprehensively capture\nthe complexity of swarm-intelligence emergence in agentic contexts. The lack of\na unified methodology further limits the depth and systematic treatment of the\nresearch. This paper proposes a framework for analyzing the emergence of swarm\nintelligence in Agentic Service Ecosystems, with three steps: measurement,\nanalysis, and optimization, to reveal the cyclical mechanisms and quantitative\ncriteria that foster emergence. By reviewing existing technologies, the paper\nanalyzes their strengths and limitations, identifies unresolved challenges, and\nshows how this framework provides both theoretical support and actionable\nmethods for real-world applications.", "published": "2025-08-10 13:37:35", "link": "http://arxiv.org/abs/2508.07343v1", "categories": ["cs.MA", "cs.SI"], "primary_category": "cs.MA"}
{"title": "LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference", "abstract": "Estimating individualized treatment effects from observational data presents\na persistent challenge due to unmeasured confounding and structural bias.\nCausal Machine Learning (causal ML) methods, such as causal trees and doubly\nrobust estimators, provide tools for estimating conditional average treatment\neffects. These methods have limited effectiveness in complex real-world\nenvironments due to the presence of latent confounders or those described in\nunstructured formats. Moreover, reliance on domain experts for confounder\nidentification and rule interpretation introduces high annotation cost and\nscalability concerns. In this work, we proposed Large Language Model-based\nagents for automated confounder discovery and subgroup analysis that integrate\nagents into the causal ML pipeline to simulate domain expertise. Our framework\nsystematically performs subgroup identification and confounding structure\ndiscovery by leveraging the reasoning capabilities of LLM-based agents, which\nreduces human dependency while preserving interpretability. Experiments on\nreal-world medical datasets show that our proposed approach enhances treatment\neffect estimation robustness by narrowing confidence intervals and uncovering\nunrecognized confounding biases. Our findings suggest that LLM-based agents\noffer a promising path toward scalable, trustworthy, and semantically aware\ncausal inference.", "published": "2025-08-10 07:45:49", "link": "http://arxiv.org/abs/2508.07221v1", "categories": ["cs.LG", "cs.AI", "cs.MA", "stat.AP", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables", "abstract": "We propose a novel framework for summarizing structured enterprise data\nacross multiple dimensions using large language model (LLM)-based agents.\nTraditional table-to-text models often lack the capacity to reason across\nhierarchical structures and context-aware deltas, which are essential in\nbusiness reporting tasks. Our method introduces a multi-agent pipeline that\nextracts, analyzes, and summarizes multi-dimensional data using agents for\nslicing, variance detection, context construction, and LLM-based generation.\nOur results show that the proposed framework outperforms traditional\napproaches, achieving 83\\% faithfulness to underlying data, superior coverage\nof significant changes, and high relevance scores (4.4/5) for decision-critical\ninsights. The improvements are especially pronounced in categories involving\nsubtle trade-offs, such as increased revenue due to price changes amid\ndeclining unit volumes, which competing methods either overlook or address with\nlimited specificity. We evaluate the framework on Kaggle datasets and\ndemonstrate significant improvements in faithfulness, relevance, and insight\nquality over baseline table summarization approaches.", "published": "2025-08-10 05:27:42", "link": "http://arxiv.org/abs/2508.07186v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Robust, fast, and adaptive splitting schemes for nonlinear doubly-degenerate diffusion equations", "abstract": "We consider linear iterative schemes for the time-discrete equations stemming\nfrom a class of nonlinear, doubly-degenerate parabolic equations. More\nprecisely, the diffusion is nonlinear and may vanish or become multivalued for\ncertain values of the unknown, so the parabolic equation becomes hyperbolic or\nelliptic, respectively. After performing an Euler implicit time-stepping, a\nsplitting strategy is applied to the time-discrete equations. This leads to a\nformulation that is more suitable for dealing with the degeneracies. Based on\nthis splitting, different iterative linearization strategies are considered,\nnamely the Newton scheme, the L-scheme, and the modified L-scheme. We prove the\nconvergence of the latter two schemes even for the double-degenerate case. In\nthe non-degenerate case, we prove that the scheme is contractive, and the\ncontraction rate is proportional to a non-negative exponent of the time-step\nsize. Moreover, an a posteriori estimator-based adaptive algorithm is developed\nto select the optimal parameters for the M-scheme, which accelerates its\nconvergence. Numerical results are presented, showing that the M- and the\nM-adaptive schemes are more stable than the Newton scheme, as they converge\nirrespective of the mesh. Moreover, the adaptive M-scheme consistently\nout-competes not only the M/L-schemes, but also the Newton scheme showing\nquadratic convergence behavior.", "published": "2025-08-10 16:33:09", "link": "http://arxiv.org/abs/2508.07420v1", "categories": ["math.NA", "cs.NA", "math.AP", "65N12, 65J15, 35K65"], "primary_category": "math.NA"}
{"title": "Best $m$-term trigonometric approximation in weighted Wiener spaces and applications", "abstract": "In this paper we study best $m$-term trigonometric approximation of functions\nbelonging to multivariate weighted Wiener spaces. It has {recently been\nobserved} that best $m$-term trigonometric widths in the uniform and Wiener\nnorm together with nonlinear recovery algorithms stemming from compressed\nsensing serve to control the optimal sampling recovery error in various\nrelevant spaces of multivariate functions. We use a collection of old and new\ntools as well as novel findings to extend these recovery bounds. In addition,\nby establishing embeddings of classical smoothness spaces into weighted Wiener\nspaces we extend recovery bounds to classical multivariate smoothness spaces.", "published": "2025-08-10 13:28:56", "link": "http://arxiv.org/abs/2508.07336v1", "categories": ["math.FA", "cs.NA", "math.NA", "42A10, 41A25, 41A46, 41A63, 42A16, 46E35, 94A20"], "primary_category": "math.FA"}
{"title": "Weighted and unweighted enrichment strategies for solving the Poisson problem with Dirichlet boundary conditions", "abstract": "In this paper, we propose weighted and unweighted enrichment strategies to\nenhance the accuracy of the linear lagrangian finite element for solving the\nPoisson problem with Dirichlet boundary conditions. We first recall key\nexamples of admissible enrichment functions, specifically designed to overcome\nthe limitations of the linear lagrangian finite element in capturing solution\nfeatures such as sharp gradients and boundary-layer phenomena. We then\nintroduce two novel three-parameter families of weighted enrichment functions\nand derive an explicit error bound in $L^2$-norm. Numerical experiments confirm\nthe effectiveness of the proposed approach in improving approximation accuracy,\ndemonstrating its potential for a wide range of applications.", "published": "2025-08-10 08:33:56", "link": "http://arxiv.org/abs/2508.07238v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Applying the Spectral Method for Modeling Linear Filters: Butterworth, Linkwitz-Riley, and Chebyshev filters", "abstract": "This paper proposes a new technique for computer modeling linear filters\nbased on the spectral form of mathematical description of linear systems. It\nassumes that input and output signals of the filter are represented as\northogonal expansions, while filters themselves are described by\ntwo-dimensional non-stationary transfer functions. This technique allows one to\nmodel the output signal in continuous time, and it is successfully tested on\nthe Butterworth, Linkwitz-Riley, and Chebyshev filters with different orders.", "published": "2025-08-10 07:00:00", "link": "http://arxiv.org/abs/2508.07206v1", "categories": ["eess.SP", "cs.NA", "cs.SY", "eess.SY", "math.NA", "42C10, 94A12", "G.1.2; I.6.6"], "primary_category": "eess.SP"}
{"title": "Computational investigation of crack-tip fields in a compressed nonlinear strain-limiting material", "abstract": "A finite element framework is presented for the analysis of crack-tip\nphenomena in an elastic material containing a single edge crack under\ncompressive loading. The mechanical response of the material is modeled by a\nnonlinear constitutive relationship that algebraically relates stress to\nlinearized strain. This approach serves to mitigate non-physical strain\nsingularities and ensures that the crack-tip strains don't grow, unlike\nsingular stresses. A significant advancement is thus achieved in the\nformulation of boundary value problems (BVPs) for such complex scenarios. The\ngoverning equilibrium equation, derived from the balance of linear momentum and\nthe nonlinear constitutive model, is formulated as a second-order,\nvector-valued, quasilinear elliptic BVP. A classical traction-free boundary\ncondition is imposed on the crack face. The problem is solved using a robust\nnumerical scheme in which a Picard-type linearization is combined with a\ncontinuous Galerkin finite element method for the discretization. Analyses are\nperformed for both an isotropic and a transversely isotropic elastic solid\ncontaining a crack subjected to compressive loads. The primary crack-tip\nvariables**-stress, strain, and strain energy density-**are examined in detail.\nIt is demonstrated that while high concentrations of compressive stress and\nstrain energy density are observed at the crack tip, the growth of strain is\nsubstantially lower than that of stress. These findings are shown to be\nconsistent with the predictions of linear elastic fracture mechanics, but a\nmore physically meaningful representation of the crack-tip field is provided by\nthe nonlinear approach. A rigorous basis is thus established for investigating\nfundamental processes like crack propagation and damage in anisotropic,\nstrain-limiting solids under various loading conditions, including compression.", "published": "2025-08-10 04:30:16", "link": "http://arxiv.org/abs/2508.07175v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Acoustic source depth estimation method based on a single hydrophone in Arctic underwater", "abstract": "Based on the normal mode and ray theory, this article discusses the\ncharacteristics of surface sound source and reception at the surface layer, and\nexplores depth estimation methods based on normal modes and rays, and proposes\na depth estimation method based on the upper limit of modal frequency. Data\nverification is conducted to discuss the applicability and limitations of\ndifferent methods. For the surface refracted normal mode waveguide, modes can\nbe separated through warping transformation. Based on the characteristics of\nnormal mode amplitude variation with frequency and number, the sound source\ndepth can be estimated by matching amplitude information. Based on the spatial\nvariation characteristics of eigenfunctions with frequency, a sound source\ndepth estimation method matching the cutoff frequency of normal modes is\nproposed. For the deep Arctic sea, the sound ray arrival structure at the\nreceiving end is obtained through the analysis of deep inversion sound ray\ntrajectories, and the sound source depth can be estimated by matching the time\ndifference of ray arrivals. Experimental data is used to verify the sound field\npatterns and the effectiveness of the sound source depth estimation method.", "published": "2025-08-10 03:12:08", "link": "http://arxiv.org/abs/2508.07157v1", "categories": ["cs.SD", "cs.NA", "math.NA", "physics.ao-ph", "physics.app-ph"], "primary_category": "cs.SD"}
{"title": "Inversion of Arctic dual-channel sound speed profile based on random airgun signal", "abstract": "For the unique dual-channel sound speed profiles of the Canadian Basin and\nthe Chukchi Plateau in the Arctic, based on the propagation characteristics of\nrefracted normal modes under dual-channel sound speed profiles, an inversion\nmethod using refracted normal modes for dual-channel sound speed profiles is\nproposed. This method proposes a dual-parameter representation method for\ndual-channel sound speed profiles, tailored to the characteristics of\ndual-channel sound speed profiles. A dispersion structure extraction method is\nproposed for the dispersion structure characteristics of refracted normal modes\nunder dual-channel sound speed profiles. Combining the parameter representation\nmethod of sound speed profiles and the dispersion structure extraction method,\nan inversion method for dual-channel sound speed profiles is proposed. For the\ncommon horizontal variation of sound speed profiles in long-distance acoustic\npropagation, a method for inverting horizontally varying dual-channel sound\nspeed profiles is proposed. Finally, this article verifies the effectiveness of\nthe dual-channel sound speed profile inversion method using the Arctic\nlow-frequency long-range acoustic propagation experiment. Compared with\nprevious sound speed profile inversion methods, the method proposed in this\narticle has the advantages of fewer inversion parameters and faster inversion\nspeed. It can be implemented using only a single hydrophone passively receiving\nrandom air gun signals, and it also solves the inversion problem of horizontal\nvariation of sound speed profiles. It has significant advantages such as low\ncost, easy deployment, and fast computation speed.", "published": "2025-08-10 03:01:10", "link": "http://arxiv.org/abs/2508.07152v1", "categories": ["cs.SD", "cs.NA", "math.NA", "physics.ao-ph", "physics.app-ph"], "primary_category": "cs.SD"}
{"title": "Modelling Human Skin Morphology and Simulating Transdermal Transport of 50 Chemicals", "abstract": "People use various products containing chemical substances that can diffuse\nthrough the human skin barrier and reach deeper layers. Therefore, it is\nessential to understand the transport mechanisms of these chemicals. We\ndeveloped computable skin meshes for different anatomical regions of young and\nold skin in two and three dimensions. Numerical methods were applied to\nsimulate the permeation of 50 chemicals. Diffusion coefficients, partition\ncoefficients, and molecular weights were key factors that influenced diffusion\nand absorption. These findings provide insights into permeation pathways that\ncan support the development and optimization of pharmaceutical formulations.", "published": "2025-08-10 00:13:42", "link": "http://arxiv.org/abs/2508.07123v1", "categories": ["math.NA", "cs.NA", "physics.bio-ph"], "primary_category": "math.NA"}
{"title": "American Option Pricing Under Time-Varying Rough Volatility: A Signature-Based Hybrid Framework", "abstract": "We introduce a modular framework that extends the signature method to handle\nAmerican option pricing under evolving volatility roughness. Building on the\nsignature-pricing framework of Bayer et al. (2025), we add three practical\ninnovations. First, we train a gradient-boosted ensemble to estimate the\ntime-varying Hurst parameter H(t) from rolling windows of recent volatility\ndata. Second, we feed these forecasts into a regime switch that chooses either\na rough Bergomi or a calibrated Heston simulator, depending on the predicted\nroughness. Third, we accelerate signature-kernel evaluations with Random\nFourier Features (RFF), cutting computational cost while preserving accuracy.\nEmpirical tests on S&P 500 equity-index options reveal that the assumption of\npersistent roughness is frequently violated, particularly during stable market\nregimes when H(t) approaches or exceeds 0.5. The proposed hybrid framework\nprovides a flexible structure that adapts to changing volatility roughness,\nimproving performance over fixed-roughness baselines and reducing duality gaps\nin some regimes. By integrating a dynamic Hurst parameter estimation pipeline\nwith efficient kernel approximations, we propose to enable tractable, real-time\npricing of American options in dynamic volatility environments.", "published": "2025-08-10 02:52:17", "link": "http://arxiv.org/abs/2508.07151v1", "categories": ["q-fin.MF", "q-fin.CP", "91G60, 60G22, 65C30"], "primary_category": "q-fin.MF"}
{"title": "On the Application of Laplace Transform to the Ruin Problem with Random Insurance Payments and Investments in a Risky Asset", "abstract": "This paper considers the ruin problem with random premiums, whose densities\nhave rational Laplace transforms, and investments in a risky asset whose price\nfollows a geometric Brownian motion. The asymptotic behavior of the ruin\nprobability for large initial capital values is investigated.", "published": "2025-08-10 08:28:34", "link": "http://arxiv.org/abs/2508.07235v1", "categories": ["math.PR", "q-fin.MF"], "primary_category": "math.PR"}
{"title": "Deformation of semi-circle law for the correlated time series and Phase transition", "abstract": "We study the eigenvalue of the Wigner random matrix, which is created from a\ntime series with temporal correlation. We observe the deformation of the\nsemi-circle law which is similar to the eigenvalue distribution of the\nWigner-L\\`{e}vy matrix. The distribution has a longer tail and a higher peak\nthan the semi-circle law. In the absence of correlation, the eigenvalue\ndistribution of the Wigner random matrix is known as the semi-circle law in the\nlarge $N$ limit. When there is a temporal correlation, the eigenvalue\ndistribution converges to the deformed semi-circle law which has a longer tail\nand a higher peak than the semi-circle law. When we created the Wigner matrix\nusing financial time series, we test the normal i.i.d. using the Wigner matrix.\nWe observe the difference from the semi-circle law for FX time series. The\ndifference from the semi-circle law is explained by the temporal correlation.\nHere, we discuss the moments of distribution and convergence to the deformed\nsemi-circle law with a temporal correlation. We discuss the phase transition\nand compare to the Marchenko-Pastur distribution(MPD) case.", "published": "2025-08-10 05:52:29", "link": "http://arxiv.org/abs/2508.07192v1", "categories": ["cond-mat.stat-mech", "q-fin.ST"], "primary_category": "cond-mat.stat-mech"}
{"title": "Decomposing Global AUC into Cluster-Level Contributions for Localized Model Diagnostics", "abstract": "The Area Under the ROC Curve (AUC) is a widely used performance metric for\nbinary classifiers. However, as a global ranking statistic, the AUC aggregates\nmodel behavior over the entire dataset, masking localized weaknesses in\nspecific subpopulations. In high-stakes applications such as credit approval\nand fraud detection, these weaknesses can lead to financial risk or operational\nfailures. In this paper, we introduce a formal decomposition of global AUC into\nintra- and inter-cluster components. This allows practitioners to evaluate\nclassifier performance within and across clusters of data, enabling granular\ndiagnostics and subgroup analysis. We also compare the AUC with additive\nperformance metrics such as the Brier score and log loss, which support\ndecomposability and direct attribution. Our framework enhances model\ndevelopment and validation practice by providing additional insights to detect\nmodel weakness for model risk management.", "published": "2025-08-10 21:58:47", "link": "http://arxiv.org/abs/2508.07495v1", "categories": ["stat.AP", "stat.ML"], "primary_category": "stat.AP"}
{"title": "N-BEATS-MOE: N-BEATS with a Mixture-of-Experts Layer for Heterogeneous Time Series Forecasting", "abstract": "Deep learning approaches are increasingly relevant for time series\nforecasting tasks. Methods such as N-BEATS, which is built on stacks of\nmultilayer perceptrons (MLPs) blocks, have achieved state-of-the-art results on\nbenchmark datasets and competitions. N-BEATS is also more interpretable\nrelative to other deep learning approaches, as it decomposes forecasts into\ndifferent time series components, such as trend and seasonality. In this work,\nwe present N-BEATS-MOE, an extension of N-BEATS based on a Mixture-of-Experts\n(MoE) layer. N-BEATS-MOE employs a dynamic block weighting strategy based on a\ngating network which allows the model to better adapt to the characteristics of\neach time series. We also hypothesize that the gating mechanism provides\nadditional interpretability by identifying which expert is most relevant for\neach series. We evaluate our method across 12 benchmark datasets against\nseveral approaches, achieving consistent improvements on several datasets,\nespecially those composed of heterogeneous time series.", "published": "2025-08-10 21:25:11", "link": "http://arxiv.org/abs/2508.07490v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Online Convex Optimization with Heavy Tails: Old Algorithms, New Regrets, and Applications", "abstract": "In Online Convex Optimization (OCO), when the stochastic gradient has a\nfinite variance, many algorithms provably work and guarantee a sublinear\nregret. However, limited results are known if the gradient estimate has a heavy\ntail, i.e., the stochastic gradient only admits a finite $\\mathsf{p}$-th\ncentral moment for some $\\mathsf{p}\\in\\left(1,2\\right]$. Motivated by it, this\nwork examines different old algorithms for OCO (e.g., Online Gradient Descent)\nin the more challenging heavy-tailed setting. Under the standard bounded domain\nassumption, we establish new regrets for these classical methods without any\nalgorithmic modification. Remarkably, these regret bounds are fully optimal in\nall parameters (can be achieved even without knowing $\\mathsf{p}$), suggesting\nthat OCO with heavy tails can be solved effectively without any extra operation\n(e.g., gradient clipping). Our new results have several applications. A\nparticularly interesting one is the first provable convergence result for\nnonsmooth nonconvex optimization under heavy-tailed noise without gradient\nclipping. Furthermore, we explore broader settings (e.g., smooth OCO) and\nextend our ideas to optimistic algorithms to handle different cases\nsimultaneously.", "published": "2025-08-10 20:17:38", "link": "http://arxiv.org/abs/2508.07473v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MOTGNN: Interpretable Graph Neural Networks for Multi-Omics Disease Classification", "abstract": "Integrating multi-omics data, such as DNA methylation, mRNA expression, and\nmicroRNA (miRNA) expression, offers a comprehensive view of the biological\nmechanisms underlying disease. However, the high dimensionality and complex\ninteractions among omics layers present major challenges for predictive\nmodeling. We propose Multi-Omics integration with Tree-generated Graph Neural\nNetwork (MOTGNN), a novel and interpretable framework for binary disease\nclassification. MOTGNN employs eXtreme Gradient Boosting (XGBoost) to perform\nomics-specific supervised graph construction, followed by modality-specific\nGraph Neural Networks (GNNs) for hierarchical representation learning, and a\ndeep feedforward network for cross-omics integration. On three real-world\ndisease datasets, MOTGNN outperforms state-of-the-art baselines by 5-10% in\naccuracy, ROC-AUC, and F1-score, and remains robust to severe class imbalance\n(e.g., 87.2% vs. 33.4% F1 on imbalanced data). The model maintains\ncomputational efficiency through sparse graphs (2.1-2.8 edges per node) and\nprovides built-in interpretability, revealing both top-ranked biomarkers and\nthe relative contributions of each omics modality. These results highlight\nMOTGNN's potential to improve both predictive accuracy and interpretability in\nmulti-omics disease modeling.", "published": "2025-08-10 19:35:53", "link": "http://arxiv.org/abs/2508.07465v1", "categories": ["cs.LG", "q-bio.GN", "stat.ML", "62R07"], "primary_category": "cs.LG"}
{"title": "Tight Bounds for Schr\u00f6dinger Potential Estimation in Unpaired Image-to-Image Translation Problems", "abstract": "Modern methods of generative modelling and unpaired image-to-image\ntranslation based on Schr\\\"odinger bridges and stochastic optimal control\ntheory aim to transform an initial density to a target one in an optimal way.\nIn the present paper, we assume that we only have access to i.i.d. samples from\ninitial and final distributions. This makes our setup suitable for both\ngenerative modelling and unpaired image-to-image translation. Relying on the\nstochastic optimal control approach, we choose an Ornstein-Uhlenbeck process as\nthe reference one and estimate the corresponding Schr\\\"odinger potential.\nIntroducing a risk function as the Kullback-Leibler divergence between\ncouplings, we derive tight bounds on generalization ability of an empirical\nrisk minimizer in a class of Schr\\\"odinger potentials including Gaussian\nmixtures. Thanks to the mixing properties of the Ornstein-Uhlenbeck process, we\nalmost achieve fast rates of convergence up to some logarithmic factors in\nfavourable scenarios. We also illustrate performance of the suggested approach\nwith numerical experiments.", "published": "2025-08-10 15:46:15", "link": "http://arxiv.org/abs/2508.07392v1", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "OpenHAIV: A Framework Towards Practical Open-World Learning", "abstract": "Substantial progress has been made in various techniques for open-world\nrecognition. Out-of-distribution (OOD) detection methods can effectively\ndistinguish between known and unknown classes in the data, while incremental\nlearning enables continuous model knowledge updates. However, in open-world\nscenarios, these approaches still face limitations. Relying solely on OOD\ndetection does not facilitate knowledge updates in the model, and incremental\nfine-tuning typically requires supervised conditions, which significantly\ndeviate from open-world settings. To address these challenges, this paper\nproposes OpenHAIV, a novel framework that integrates OOD detection, new class\ndiscovery, and incremental continual fine-tuning into a unified pipeline. This\nframework allows models to autonomously acquire and update knowledge in\nopen-world environments. The proposed framework is available at\nhttps://haiv-lab.github.io/openhaiv .", "published": "2025-08-10 09:55:19", "link": "http://arxiv.org/abs/2508.07270v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Scalable Controllable Accented TTS", "abstract": "We tackle the challenge of scaling accented TTS systems, expanding their\ncapabilities to include much larger amounts of training data and a wider\nvariety of accent labels, even for accents that are poorly represented or\nunlabeled in traditional TTS datasets. To achieve this, we employ two\nstrategies: 1. Accent label discovery via a speech geolocation model, which\nautomatically infers accent labels from raw speech data without relying solely\non human annotation; 2. Timbre augmentation through kNN voice conversion to\nincrease data diversity and model robustness. These strategies are validated on\nCommonVoice, where we fine-tune XTTS-v2 for accented TTS with accent labels\ndiscovered or enhanced using geolocation. We demonstrate that the resulting\naccented TTS model not only outperforms XTTS-v2 fine-tuned on self-reported\naccent labels in CommonVoice, but also existing accented TTS benchmarks.", "published": "2025-08-10 16:56:39", "link": "http://arxiv.org/abs/2508.07426v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Keyword Mamba: Spoken Keyword Spotting with State Space Models", "abstract": "Keyword spotting (KWS) is an essential task in speech processing. It is\nwidely used in voice assistants and smart devices. Deep learning models like\nCNNs, RNNs, and Transformers have performed well in KWS. However, they often\nstruggle to handle long-term patterns and stay efficient at the same time. In\nthis work, we present Keyword Mamba, a new architecture for KWS. It uses a\nneural state space model (SSM) called Mamba. We apply Mamba along the time axis\nand also explore how it can replace the self-attention part in Transformer\nmodels. We test our model on the Google Speech Commands datasets. The results\nshow that Keyword Mamba reaches strong accuracy with fewer parameters and lower\ncomputational cost. To our knowledge, this is the first time a state space\nmodel has been used for KWS. These results suggest that Mamba has strong\npotential in speech-related tasks.", "published": "2025-08-10 14:22:27", "link": "http://arxiv.org/abs/2508.07363v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "KLASSify to Verify: Audio-Visual Deepfake Detection Using SSL-based Audio and Handcrafted Visual Features", "abstract": "The rapid development of audio-driven talking head generators and advanced\nText-To-Speech (TTS) models has led to more sophisticated temporal deepfakes.\nThese advances highlight the need for robust methods capable of detecting and\nlocalizing deepfakes, even under novel, unseen attack scenarios. Current\nstate-of-the-art deepfake detectors, while accurate, are often computationally\nexpensive and struggle to generalize to novel manipulation techniques. To\naddress these challenges, we propose multimodal approaches for the\nAV-Deepfake1M 2025 challenge. For the visual modality, we leverage handcrafted\nfeatures to improve interpretability and adaptability. For the audio modality,\nwe adapt a self-supervised learning (SSL) backbone coupled with graph attention\nnetworks to capture rich audio representations, improving detection robustness.\nOur approach strikes a balance between performance and real-world deployment,\nfocusing on resilience and potential interpretability. On the AV-Deepfake1M++\ndataset, our multimodal system achieves AUC of 92.78% for deepfake\nclassification task and IoU of 0.3536 for temporal localization using only the\naudio modality.", "published": "2025-08-10 13:29:08", "link": "http://arxiv.org/abs/2508.07337v1", "categories": ["eess.AS", "cs.CV"], "primary_category": "eess.AS"}
{"title": "XEmoRAG: Cross-Lingual Emotion Transfer with Controllable Intensity Using Retrieval-Augmented Generation", "abstract": "Zero-shot emotion transfer in cross-lingual speech synthesis refers to\ngenerating speech in a target language, where the emotion is expressed based on\nreference speech from a different source language.However, this task remains\nchallenging due to the scarcity of parallel multilingual emotional corpora, the\npresence of foreign accent artifacts, and the difficulty of separating emotion\nfrom language-specific prosodic features.In this paper, we propose XEmoRAG, a\nnovel framework to enable zero-shot emotion transfer from Chinese to Thai using\na large language model (LLM)-based model, without relying on parallel emotional\ndata.XEmoRAG extracts language-agnostic emotional embeddings from Chinese\nspeech and retrieves emotionally matched Thai utterances from a curated\nemotional database, enabling controllable emotion transfer without explicit\nemotion labels. Additionally, a flow-matching alignment module minimizes pitch\nand duration mismatches, ensuring natural prosody. It also blends Chinese\ntimbre into the Thai synthesis, enhancing rhythmic accuracy and emotional\nexpression, while preserving speaker characteristics and emotional\nconsistency.Experimental results show that XEmoRAG synthesizes expressive and\nnatural Thai speech using only Chinese reference audio, without requiring\nexplicit emotion labels.These results highlight XEmoRAG's capability to achieve\nflexible and low-resource emotional transfer across languages.Our demo is\navailable at https://tlzuo-lesley.github.io/Demo-page/.", "published": "2025-08-10 11:31:13", "link": "http://arxiv.org/abs/2508.07302v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A Survey on Non-Intrusive ASR Refinement: From Output-Level Correction to Full-Model Distillation", "abstract": "Automatic Speech Recognition (ASR) has become an integral component of modern\ntechnology, powering applications such as voice-activated assistants,\ntranscription services, and accessibility tools. Yet ASR systems continue to\nstruggle with the inherent variability of human speech, such as accents,\ndialects, and speaking styles, as well as environmental interference, including\nbackground noise. Moreover, domain-specific conversations often employ\nspecialized terminology, which can exacerbate transcription errors. These\nshortcomings not only degrade raw ASR accuracy but also propagate mistakes\nthrough subsequent natural language processing pipelines. Because redesigning\nan ASR model is costly and time-consuming, non-intrusive refinement techniques\nthat leave the model's architecture unchanged have become increasingly popular.\nIn this survey, we systematically review current non-intrusive refinement\napproaches and group them into five classes: fusion, re-scoring, correction,\ndistillation, and training adjustment. For each class, we outline the main\nmethods, advantages, drawbacks, and ideal application scenarios. Beyond method\nclassification, this work surveys adaptation techniques aimed at refining ASR\nin domain-specific contexts, reviews commonly used evaluation datasets along\nwith their construction processes, and proposes a standardized set of metrics\nto facilitate fair comparisons. Finally, we identify open research gaps and\nsuggest promising directions for future work. By providing this structured\noverview, we aim to equip researchers and practitioners with a clear foundation\nfor developing more robust, accurate ASR refinement pipelines.", "published": "2025-08-10 10:46:14", "link": "http://arxiv.org/abs/2508.07285v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Lessons Learnt: Revisit Key Training Strategies for Effective Speech Emotion Recognition in the Wild", "abstract": "In this study, we revisit key training strategies in machine learning often\noverlooked in favor of deeper architectures. Specifically, we explore balancing\nstrategies, activation functions, and fine-tuning techniques to enhance speech\nemotion recognition (SER) in naturalistic conditions. Our findings show that\nsimple modifications improve generalization with minimal architectural changes.\nOur multi-modal fusion model, integrating these optimizations, achieves a\nvalence CCC of 0.6953, the best valence score in Task 2: Emotional Attribute\nRegression. Notably, fine-tuning RoBERTa and WavLM separately in a\nsingle-modality setting, followed by feature fusion without training the\nbackbone extractor, yields the highest valence performance. Additionally, focal\nloss and activation functions significantly enhance performance without\nincreasing complexity. These results suggest that refining core components,\nrather than deepening models, leads to more robust SER in-the-wild.", "published": "2025-08-10 10:42:49", "link": "http://arxiv.org/abs/2508.07282v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "ParaNoise-SV: Integrated Approach for Noise-Robust Speaker Verification with Parallel Joint Learning of Speech Enhancement and Noise Extraction", "abstract": "Noise-robust speaker verification leverages joint learning of speech\nenhancement (SE) and speaker verification (SV) to improve robustness. However,\nprevailing approaches rely on implicit noise suppression, which struggles to\nseparate noise from speaker characteristics as they do not explicitly\ndistinguish noise from speech during training. Although integrating SE and SV\nhelps, it remains limited in handling noise effectively. Meanwhile, recent SE\nstudies suggest that explicitly modeling noise, rather than merely suppressing\nit, enhances noise resilience. Reflecting this, we propose ParaNoise-SV, with\ndual U-Nets combining a noise extraction (NE) network and a speech enhancement\n(SE) network. The NE U-Net explicitly models noise, while the SE U-Net refines\nspeech with guidance from NE through parallel connections, preserving\nspeaker-relevant features. Experimental results show that ParaNoise-SV achieves\na relatively 8.4% lower equal error rate (EER) than previous joint SE-SV\nmodels.", "published": "2025-08-10 07:41:56", "link": "http://arxiv.org/abs/2508.07219v1", "categories": ["eess.AS", "cs.SD", "I.2.7; H.5.5; I.5.4"], "primary_category": "eess.AS"}
{"title": "Detection and Classification of Internal Leakage in Hydraulic Cylinders", "abstract": "Hydraulic systems have been one of the most used technologies in many\nindustries due to their reliance on incompressible fluids that facilitate\nenergy and power transfer. Within such systems, hydraulic cylinders are prime\ndevices that convert hydraulic energy into mechanical energy. Some of the\ngenuine and very common problems related to hydraulic cylinders are leakages.\nLeakage in hydraulic systems can cause a drop in pressure, general\ninefficiency, and even complete failure of such systems. The various ways\nleakage can occur define the major categorization of leakage: internal and\nexternal leakage. External leakage is easily noticeable, while internal\nleakage, which involves fluid movement between pressure chambers, can be harder\nto detect and may gradually impact system performance without obvious signs.\nWhen leakage surpasses acceptable limits, it is classified as a fault or\nfailure. In such cases, leakage is divided into three categories: no leakage,\nlow leakage, and high leakage. It suggests a fault detection algorithm with the\nbasic responsibility of detecting minimum leakage within the Hydraulic system,\nand minimizing detection time is the core idea of this paper. In order to fully\ndevelop this idea, experimental data collection of Hydraulic systems is\nrequired. The collected data uses pressure sensors and other signals that are\nsingle-related. Due to the utilization of Long Short-Term Memory (LSTM)\nrecurrent neural networks, more complex data analysis was enabled, which the\nLSTM-based leakage detection algorithm successfully achieved, providing almost\n96% accuracy in classifying leakage types. Results demonstrate that the\nproposed method can perform real-time and online fault diagnosis for each\ncycle, reducing maintenance costs and prolonging the hydraulic system's\nlifespan.", "published": "2025-08-10 17:16:55", "link": "http://arxiv.org/abs/2508.07436v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "An Experimental Exploration of In-Memory Computing for Multi-Layer Perceptrons", "abstract": "In modern computer architectures, the performance of many memory-bound\nworkloads (e.g., machine learning, graph processing, databases) is limited by\nthe data movement bottleneck that emerges when transferring large amounts of\ndata between the main memory and the central processing unit (CPU).\nProcessing-in-memory is an emerging computing paradigm that aims to alleviate\nthis data movement bottleneck by performing computation close to or within the\nmemory units, where data resides. One example of a prevalent workload whose\nperformance is bound by the data movement bottleneck is the training and\ninference process of artificial neural networks. In this work, we analyze the\npotential of modern general-purpose PiM architectures to accelerate neural\nnetworks. To this end, we selected the UPMEM PiM system, the first commercially\navailable real-world general-purpose PiM architecture. We compared the\nimplementation of multilayer perceptrons (MLPs) in PiM with a sequential\nbaseline running on an Intel Xeon CPU. The UPMEM implementation achieves up to\n$259\\times$ better performance for inference of large batch sizes when compared\nagainst the CPU that exploits the size of the available PiM memory.\nAdditionally, two smaller MLPs were implemented using UPMEM's working SRAM\n(WRAM), a scratchpad memory, to evaluate their performance against a low-power\nNvidia Jetson graphics processing unit (GPU), providing further insights into\nthe efficiency of UPMEM's PiM for neural network inference. Results show that\nusing WRAM achieves kernel execution times for MLP inference of under $3$ ms,\nwhich is within the same order of magnitude as low-power GPUs.", "published": "2025-08-10 12:27:23", "link": "http://arxiv.org/abs/2508.07317v1", "categories": ["cs.DC", "eess.SP"], "primary_category": "cs.DC"}
{"title": "Channel Charting in Smart Radio Environments", "abstract": "This paper introduces the use of static electromagnetic skins (EMSs) to\nenable robust device localization via channel charting (CC) in realistic urban\nenvironments. We develop a rigorous optimization framework that leverages EMS\nto enhance channel dissimilarity and spatial fingerprinting, formulating EMS\nphase profile design as a codebook-based problem targeting the upper quantiles\nof key embedding metric, localization error, trustworthiness, and continuity.\nThrough 3D ray-traced simulations of a representative city scenario, we\ndemonstrate that optimized EMS configurations, in addition to significant\nimprovement of the average positioning error, reduce the 90th-percentile\nlocalization error from over 60 m (no EMS) to less than 25 m, while drastically\nimproving trustworthiness and continuity. To the best of our knowledge, this is\nthe first work to exploit Smart Radio Environment (SRE) with static EMS for\nenhancing CC, achieving substantial gains in localization performance under\nchallenging None-Line-of-Sight (NLoS) conditions.", "published": "2025-08-10 11:40:09", "link": "http://arxiv.org/abs/2508.07305v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Fine-Tuning Large Language Models Using EEG Microstate Features for Mental Workload Assessment", "abstract": "This study explores the intersection of electroencephalography (EEG)\nmicrostates and Large Language Models (LLMs) to enhance the assessment of\ncognitive load states. By utilizing EEG microstate features, the research aims\nto fine-tune LLMs for improved predictions of distinct cognitive states,\nspecifically 'Rest' and 'Load'. The experimental design is delineated in four\ncomprehensive stages: dataset collection and preprocessing, microstate\nsegmentation and EEG backfitting, feature extraction paired with prompt\nengineering, and meticulous LLM model selection and refinement. Employing a\nsupervised learning paradigm, the LLM is trained to identify cognitive load\nstates based on EEG microstate features integrated into prompts, producing\naccurate discrimination of cognitive load. A curated dataset, linking EEG\nfeatures to specified cognitive load conditions, underpins the experimental\nframework. The results indicate a significant improvement in model performance\nfollowing the proposed fine-tuning, showcasing the potential of EEG-informed\nLLMs in cognitive neuroscience and cognitive AI applications. This approach not\nonly contributes to the understanding of brain dynamics but also paves the way\nfor advancements in machine learning techniques applicable to cognitive load\nand cognitive AI research.", "published": "2025-08-10 10:43:09", "link": "http://arxiv.org/abs/2508.07283v1", "categories": ["cs.HC", "cs.AI", "eess.SP", "q-bio.NC", "97R40", "I.2"], "primary_category": "cs.HC"}
{"title": "A Scalable Machine Learning Approach Enabled RIS Optimization with Implicit Channel Estimation", "abstract": "The reconfigurable intelligent surface (RIS) is considered as a key enabler\nof the next-generation mobile radio systems. While attracting extensive\ninterest from academia and industry due to its passive nature and low cost,\nscalability of RIS elements and requirement for channel state information (CSI)\nare two major difficulties for the RIS to become a reality. In this work, we\nintroduce an unsupervised machine learning (ML) enabled optimization approach\nto configure the RIS. The dedicated neural network (NN) architecture RISnet is\ncombined with an implicit channel estimation method. The RISnet learns to map\nfrom received pilot signals to RIS configuration directly without explicit\nchannel estimation. Simulation results show that the proposed algorithm\noutperforms baselines significantly.", "published": "2025-08-10 09:38:37", "link": "http://arxiv.org/abs/2508.07265v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "PySeizure: A single machine learning classifier framework to detect seizures in diverse datasets", "abstract": "Reliable seizure detection is critical for diagnosing and managing epilepsy,\nyet clinical workflows remain dependent on time-consuming manual EEG\ninterpretation. While machine learning has shown promise, existing approaches\noften rely on dataset-specific optimisations, limiting their real-world\napplicability and reproducibility. Here, we introduce an innovative,\nopen-source machine-learning framework that enables robust and generalisable\nseizure detection across varied clinical datasets. We evaluate our approach on\ntwo publicly available EEG datasets that differ in patient populations and\nelectrode configurations. To enhance robustness, the framework incorporates an\nautomated pre-processing pipeline to standardise data and a majority voting\nmechanism, in which multiple models independently assess each second of EEG\nbefore reaching a final decision. We train, tune, and evaluate models within\neach dataset, assessing their cross-dataset transferability. Our models achieve\nhigh within-dataset performance (AUC 0.904+/-0.059 for CHB-MIT and\n0.864+/-0.060 for TUSZ) and demonstrate strong generalisation across datasets\ndespite differences in EEG setups and populations (AUC 0.615+/-0.039 for models\ntrained on CHB-MIT and tested on TUSZ and 0.762+/-0.175 in the reverse case)\nwithout any post-processing. Furthermore, a mild post-processing improved the\nwithin-dataset results to 0.913+/-0.064 and 0.867+/-0.058 and cross-dataset\nresults to 0.619+/-0.036 and 0.768+/-0.172. These results underscore the\npotential of, and essential considerations for, deploying our framework in\ndiverse clinical settings. By making our methodology fully reproducible, we\nprovide a foundation for advancing clinically viable, dataset-agnostic seizure\ndetection systems. This approach has the potential for widespread adoption,\ncomplementing rather than replacing expert interpretation, and accelerating\nclinical integration.", "published": "2025-08-10 09:12:29", "link": "http://arxiv.org/abs/2508.07253v1", "categories": ["cs.LG", "eess.SP", "q-bio.NC"], "primary_category": "cs.LG"}
{"title": "Multi-RIS Deployment Optimization for mmWave ISAC Systems in Real-World Environments", "abstract": "Reconfigurable intelligent surface-assisted integrated sensing and\ncommunication (RIS-ISAC) presents a promising system architecture to leverage\nthe wide bandwidth available at millimeter-wave (mmWave) frequencies, while\nmitigating severe signal propagation losses and reducing infrastructure costs.\nTo enhance ISAC functionalities in the future air-ground integrated network\napplications, RIS deployment must be carefully designed and evaluated, which\nforms the core motivation of this paper. To ensure practical relevance, a\nmulti-RIS-ISAC system is established, with its signal model at mmWave\nfrequencies demonstrated using ray-launching calibrated to real-world\nenvironments. On this basis, an energy-efficiency-driven optimization problem\nis formulated to minimize the multi-RIS size-to-coverage sum ratio,\ncomprehensively considering real-world RIS deployment constraints, positions,\norientations, as well as ISAC beamforming strategies at both the base station\nand the RISs. To solve the resulting non-convex mixed-integer problem, a\nsimplified reformulation based on equivalent gain scaling method is introduced.\nA two-step iterative algorithm is then proposed, in which the deployment\nparameters are determined under fixed RIS positions in the first step, and the\nRIS position set is updated in the second step to progressively approach the\noptimum solution. Simulation results based on realistic parameter benchmarks\npresent that the optimized RISs deployment significantly enhances communication\ncoverage and sensing accuracy with the minimum RIS sizes, outperforming\nexisting approaches.", "published": "2025-08-10 08:10:36", "link": "http://arxiv.org/abs/2508.07226v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Vector Orthogonal Chirp Division Multiplexing Over Doubly Selective Channels", "abstract": "In this letter, we extend orthogonal chirp division multiplexing (OCDM) to\nvector OCDM (VOCDM) to provide more design freedom to deal with doubly\nselective channels. The VOCDM modulation is implemented by performing M\nparallel N-size inverse discrete Fresnel transforms (IDFnT). Based on the\ncomplex exponential basis expansion model (CE-BEM) for doubly selective\nchannels, we derive the VOCDM input-output relationship, and show performance\ntradeoffs of VOCDM with respect to (w.r.t.) its modulation parameters M and N.\nSpecifically, we investigate the diversity and peak-to-average power ratio\n(PAPR) of VOCDM w.r.t. M and N. Under doubly selective channels, VOCDM exhibits\nsuperior diversity performance as long as the parameters M and N are configured\nto satisfy some constraints from the delay and the Doppler spreads of the\nchannel, respectively. Furthermore, the PAPR of VOCDM signals decreases with a\ndecreasing N. These theoretical findings are verified through numerical\nsimulations.", "published": "2025-08-10 03:19:51", "link": "http://arxiv.org/abs/2508.07160v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Low-Complexity Equalization of Zak-OTFS in the Frequency Domain", "abstract": "4G/5G wireless standards use orthogonal frequency division multiplexing\n(OFDM) which is robust to frequency selectivity. Equalization is possible with\na single tap filter, and low-complexity equalization makes OFDM an attractive\nphysical layer. However the performance of OFDM degrades with mobility, since\nDoppler spreads introduce inter-carrier interference (ICI) between subcarriers\nand they are no longer orthogonal. Zak-transform based orthogonal time\nfrequency space (Zak-OTFS) modulation has been shown to be robust to doubly\nselective channels. Zak-OTFS signals are formed in the delay-Doppler (DD)\ndomain, converted to time domain (TD) for transmission and reception, then\nreturned to the DD domain for processing. The received signal is a\nsuperposition of many attenuated copies since the doubly selective channel\nintroduces delay and Doppler shifts. The received symbols are more difficult to\nequalize since they are subject to interference along both delay and Doppler\naxes. In this paper, we propose a new low-complexity method of equalizing\nZak-OTFS in the frequency domain (FD). We derive the FD system model and show\nthat it is unitarily equivalent to the DD system model. We show that the\nchannel matrix in the FD is banded, making it possible to apply conjugate\ngradient methods to reduce the complexity of equalization. We show that\ncomplexity of FD equalization is linear in the dimension of a Zak-OTFS frame.\nFor comparison the complexity of naive MMSE equalization is cubic in the frame\ndimension. Through numerical simulations we show that FD equalization of\nZak-OTFS achieves similar performance as equalization in DD domain.", "published": "2025-08-10 02:43:37", "link": "http://arxiv.org/abs/2508.07148v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Grounding Multilingual Multimodal LLMs With Cultural Knowledge", "abstract": "Multimodal Large Language Models excel in high-resource settings, but often\nmisinterpret long-tail cultural entities and underperform in low-resource\nlanguages. To address this gap, we propose a data-centric approach that\ndirectly grounds MLLMs in cultural knowledge. Leveraging a large scale\nknowledge graph from Wikidata, we collect images that represent culturally\nsignificant entities, and generate synthetic multilingual visual question\nanswering data. The resulting dataset, CulturalGround, comprises 22 million\nhigh-quality, culturally-rich VQA pairs spanning 42 countries and 39 languages.\nWe train an open-source MLLM CulturalPangea on CulturalGround, interleaving\nstandard multilingual instruction-tuning data to preserve general abilities.\nCulturalPangea achieves state-of-the-art performance among open models on\nvarious culture-focused multilingual multimodal benchmarks, outperforming prior\nmodels by an average of 5.0 without degrading results on mainstream\nvision-language tasks. Our findings show that our targeted, culturally grounded\napproach could substantially narrow the cultural gap in MLLMs and offer a\npractical path towards globally inclusive multimodal systems.", "published": "2025-08-10 16:24:11", "link": "http://arxiv.org/abs/2508.07414v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "American Option Pricing Under Time-Varying Rough Volatility: A Signature-Based Hybrid Framework", "abstract": "We introduce a modular framework that extends the signature method to handle\nAmerican option pricing under evolving volatility roughness. Building on the\nsignature-pricing framework of Bayer et al. (2025), we add three practical\ninnovations. First, we train a gradient-boosted ensemble to estimate the\ntime-varying Hurst parameter H(t) from rolling windows of recent volatility\ndata. Second, we feed these forecasts into a regime switch that chooses either\na rough Bergomi or a calibrated Heston simulator, depending on the predicted\nroughness. Third, we accelerate signature-kernel evaluations with Random\nFourier Features (RFF), cutting computational cost while preserving accuracy.\nEmpirical tests on S&P 500 equity-index options reveal that the assumption of\npersistent roughness is frequently violated, particularly during stable market\nregimes when H(t) approaches or exceeds 0.5. The proposed hybrid framework\nprovides a flexible structure that adapts to changing volatility roughness,\nimproving performance over fixed-roughness baselines and reducing duality gaps\nin some regimes. By integrating a dynamic Hurst parameter estimation pipeline\nwith efficient kernel approximations, we propose to enable tractable, real-time\npricing of American options in dynamic volatility environments.", "published": "2025-08-10 02:52:17", "link": "http://arxiv.org/abs/2508.07151v2", "categories": ["q-fin.MF", "q-fin.CP", "91G60, 60G22, 65C30"], "primary_category": "q-fin.MF"}
{"title": "XEmoRAG: Cross-Lingual Emotion Transfer with Controllable Intensity Using Retrieval-Augmented Generation", "abstract": "Zero-shot emotion transfer in cross-lingual speech synthesis refers to\ngenerating speech in a target language, where the emotion is expressed based on\nreference speech from a different source language. However, this task remains\nchallenging due to the scarcity of parallel multilingual emotional corpora, the\npresence of foreign accent artifacts, and the difficulty of separating emotion\nfrom language-specific prosodic features. In this paper, we propose XEmoRAG, a\nnovel framework to enable zero-shot emotion transfer from Chinese to Thai using\na large language model (LLM)-based model, without relying on parallel emotional\ndata. XEmoRAG extracts language-agnostic emotional embeddings from Chinese\nspeech and retrieves emotionally matched Thai utterances from a curated\nemotional database, enabling controllable emotion transfer without explicit\nemotion labels. Additionally, a flow-matching alignment module minimizes pitch\nand duration mismatches, ensuring natural prosody. It also blends Chinese\ntimbre into the Thai synthesis, enhancing rhythmic accuracy and emotional\nexpression, while preserving speaker characteristics and emotional consistency.\nExperimental results show that XEmoRAG synthesizes expressive and natural Thai\nspeech using only Chinese reference audio, without requiring explicit emotion\nlabels. These results highlight XEmoRAG's capability to achieve flexible and\nlow-resource emotional transfer across languages. Our demo is available at\nhttps://tlzuo-lesley.github.io/Demo-page/ .", "published": "2025-08-10 11:31:13", "link": "http://arxiv.org/abs/2508.07302v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "miRKatAI: An Integrated Database and Multi-agent AI system for microRNA Research", "abstract": "MicroRNAs (miRs) are robust regulators of gene expression, implicated in most\nbiological processes. microRNAs predominantly downregulate the expression of\ngenes post-transcriptionally and each miR is predicted to target several\nhundred genes. The accurate identification and annotation of miR-mRNA target\ninteractions is central to understanding miRs function and their therapeutic\npotential. However, computational target prediction is challenging due to\nimperfect complementarity of miRs with their targets and the growing volume and\nheterogeneity of experimental data present challenges in accessing,\nintegrating, and analysing miR-target interaction information across biological\ncontexts. This creates a need for integrated resources and intelligent query\ntools.\n  We present the miRKat Suite, comprising miRKatDB, a comprehensive, curated\ndatabase of predicted and validated miR-target interactions and associated\nannotations, and miRKatAI, a multi-agent system powered by large language\nmodels (LLMs) and LangGraph. miRKatDB integrates data from multiple publicly\navailable sources, providing a comprehensive foundation for miR studies,\nincluding miR target genes and changes in levels of tissue expression\npreviously reported. miRKatAI offers a natural language interface for complex\nquerying of miRKatDB, facilitates grounded information retrieval from\nestablished sources in the field, and supports basic data visualisation. The\nmiRKat Suite aims to accelerate miR research by streamlining data access,\nenhancing exploratory analysis, and supporting hypothesis generation.", "published": "2025-08-10 11:24:40", "link": "http://arxiv.org/abs/2508.08331v1", "categories": ["q-bio.GN", "cs.MA", "D.0"], "primary_category": "q-bio.GN"}
{"title": "Noise-Robust Sound Event Detection and Counting via Language-Queried Sound Separation", "abstract": "Most sound event detection (SED) systems perform well on clean datasets but\ndegrade significantly in noisy environments. Language-queried audio source\nseparation (LASS) models show promise for robust SED by separating target\nevents; existing methods require elaborate multi-stage training and lack\nexplicit guidance for target events. To address these challenges, we introduce\nevent appearance detection (EAD), a counting-based approach that counts event\noccurrences at both the clip and frame levels. Based on EAD, we propose a\nco-training-based multi-task learning framework for EAD and SED to enhance\nSED's performance in noisy environments. First, SED struggles to learn the same\npatterns as EAD. Then, a task-based constraint is designed to improve\nprediction consistency between SED and EAD. This framework provides more\nreliable clip-level predictions for LASS models and strengthens timestamp\ndetection capability. Experiments on DESED and WildDESED datasets demonstrate\nbetter performance compared to existing methods, with advantages becoming more\npronounced at higher noise levels.", "published": "2025-08-10 04:33:09", "link": "http://arxiv.org/abs/2508.07176v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "miRKatAI: An Integrated Database and Multi-agent AI system for microRNA Research", "abstract": "MicroRNAs (miRs) are robust regulators of gene expression, implicated in most\nbiological processes. microRNAs predominantly downregulate the expression of\ngenes post-transcriptionally and each miR is predicted to target several\nhundred genes. The accurate identification and annotation of miR-mRNA target\ninteractions is central to understanding miRs function and their therapeutic\npotential. However, computational target prediction is challenging due to\nimperfect complementarity of miRs with their targets and the growing volume and\nheterogeneity of experimental data present challenges in accessing,\nintegrating, and analysing miR-target interaction information across biological\ncontexts. This creates a need for integrated resources and intelligent query\ntools.\n  We present the miRKat Suite, comprising miRKatDB, a comprehensive, curated\ndatabase of predicted and validated miR-target interactions and associated\nannotations, and miRKatAI, a multi-agent system powered by large language\nmodels (LLMs) and LangGraph. miRKatDB integrates data from multiple publicly\navailable sources, providing a comprehensive foundation for miR studies,\nincluding miR target genes and changes in levels of tissue expression\npreviously reported. miRKatAI offers a natural language interface for complex\nquerying of miRKatDB, facilitates grounded information retrieval from\nestablished sources in the field, and supports basic data visualisation. The\nmiRKat Suite aims to accelerate miR research by streamlining data access,\nenhancing exploratory analysis, and supporting hypothesis generation.", "published": "2025-08-10 11:24:40", "link": "http://arxiv.org/abs/2508.08331v2", "categories": ["q-bio.GN", "cs.MA", "D.0"], "primary_category": "q-bio.GN"}
{"title": "Acoustic source depth estimation method based on a single hydrophone in Arctic underwater", "abstract": "Based on the normal mode and ray theory, this article discusses the\ncharacteristics of surface sound source and reception at the surface layer, and\nexplores depth estimation methods based on normal modes and rays, and proposes\na depth estimation method based on the upper limit of modal frequency. Data\nverification is conducted to discuss the applicability and limitations of\ndifferent methods. For the surface refracted normal mode waveguide, modes can\nbe separated through warping transformation. Based on the characteristics of\nnormal mode amplitude variation with frequency and number, the sound source\ndepth can be estimated by matching amplitude information. Based on the spatial\nvariation characteristics of eigenfunctions with frequency, a sound source\ndepth estimation method matching the cutoff frequency of normal modes is\nproposed. For the deep Arctic sea, the sound ray arrival structure at the\nreceiving end is obtained through the analysis of deep inversion sound ray\ntrajectories, and the sound source depth can be estimated by matching the time\ndifference of ray arrivals. Experimental data is used to verify the sound field\npatterns and the effectiveness of the sound source depth estimation method.", "published": "2025-08-10 03:12:08", "link": "http://arxiv.org/abs/2508.07157v2", "categories": ["cs.SD", "cs.NA", "eess.AS", "math.NA", "physics.ao-ph", "physics.app-ph"], "primary_category": "cs.SD"}
{"title": "Inversion of Arctic dual-channel sound speed profile based on random airgun signal", "abstract": "For the unique dual-channel sound speed profiles of the Canadian Basin and\nthe Chukchi Plateau in the Arctic, based on the propagation characteristics of\nrefracted normal modes under dual-channel sound speed profiles, an inversion\nmethod using refracted normal modes for dual-channel sound speed profiles is\nproposed. This method proposes a dual-parameter representation method for\ndual-channel sound speed profiles, tailored to the characteristics of\ndual-channel sound speed profiles. A dispersion structure extraction method is\nproposed for the dispersion structure characteristics of refracted normal modes\nunder dual-channel sound speed profiles. Combining the parameter representation\nmethod of sound speed profiles and the dispersion structure extraction method,\nan inversion method for dual-channel sound speed profiles is proposed. For the\ncommon horizontal variation of sound speed profiles in long-distance acoustic\npropagation, a method for inverting horizontally varying dual-channel sound\nspeed profiles is proposed. Finally, this article verifies the effectiveness of\nthe dual-channel sound speed profile inversion method using the Arctic\nlow-frequency long-range acoustic propagation experiment. Compared with\nprevious sound speed profile inversion methods, the method proposed in this\narticle has the advantages of fewer inversion parameters and faster inversion\nspeed. It can be implemented using only a single hydrophone passively receiving\nrandom air gun signals, and it also solves the inversion problem of horizontal\nvariation of sound speed profiles. It has significant advantages such as low\ncost, easy deployment, and fast computation speed.", "published": "2025-08-10 03:01:10", "link": "http://arxiv.org/abs/2508.07152v2", "categories": ["cs.SD", "cs.NA", "eess.AS", "math.NA", "physics.ao-ph", "physics.app-ph"], "primary_category": "cs.SD"}
{"title": "FlexCTC: GPU-powered CTC Beam Decoding With Advanced Contextual Abilities", "abstract": "While beam search improves speech recognition quality over greedy decoding,\nstandard implementations are slow, often sequential, and CPU-bound. To fully\nleverage modern hardware capabilities, we present a novel open-source FlexCTC\ntoolkit for fully GPU-based beam decoding, designed for Connectionist Temporal\nClassification (CTC) models. Developed entirely in Python and PyTorch, it\noffers a fast, user-friendly, and extensible alternative to traditional C++,\nCUDA, or WFST-based decoders. The toolkit features a high-performance, fully\nbatched GPU implementation with eliminated CPU-GPU synchronization and\nminimized kernel launch overhead via CUDA Graphs. It also supports advanced\ncontextualization techniques, including GPU-powered N-gram language model\nfusion and phrase-level boosting. These features enable accurate and efficient\ndecoding, making them suitable for both research and production use.", "published": "2025-08-10 12:15:57", "link": "http://arxiv.org/abs/2508.07315v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion", "abstract": "Large Language Models (LLMs) show remarkable potential for few-shot\ninformation extraction (IE), yet their performance is highly sensitive to the\nchoice of in-context examples. Conventional selection strategies often fail to\nprovide informative guidance, as they overlook a key source of model\nfallibility: confusion stemming not just from semantic content, but also from\nthe generation of well-structured formats required by IE tasks. To address\nthis, we introduce Active Prompting for Information Extraction (APIE), a novel\nactive prompting framework guided by a principle we term introspective\nconfusion. Our method empowers an LLM to assess its own confusion through a\ndual-component uncertainty metric that uniquely quantifies both Format\nUncertainty (difficulty in generating correct syntax) and Content Uncertainty\n(inconsistency in extracted semantics). By ranking unlabeled data with this\ncomprehensive score, our framework actively selects the most challenging and\ninformative samples to serve as few-shot exemplars. Extensive experiments on\nfour benchmarks show that our approach consistently outperforms strong\nbaselines, yielding significant improvements in both extraction accuracy and\nrobustness. Our work highlights the critical importance of a fine-grained,\ndual-level view of model uncertainty when it comes to building effective and\nreliable structured generation systems.", "published": "2025-08-10 02:27:41", "link": "http://arxiv.org/abs/2508.10036v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Corrosion Resistance of Aluminum Alloys Through AI and ML Modeling", "abstract": "Corrosion poses a significant challenge to the performance of aluminum\nalloys, particularly in marine environments. This study investigates the\napplication of machine learning (ML) algorithms to predict and optimize\ncorrosion resistance, utilizing a comprehensive open-source dataset compiled\nfrom various sources. The dataset encompasses corrosion rate data and\nenvironmental conditions, preprocessed to standardize units and formats. We\nexplored two different approaches, a direct approach, where the material's\ncomposition and environmental conditions were used as inputs to predict\ncorrosion rates; and an inverse approach, where corrosion rate served as the\ninput to identify suitable material compositions as output. We employed and\ncompared three distinct ML methodologies for forward predictions: Random Forest\nregression, optimized via grid search; a feed-forward neural network, utilizing\nReLU activation and Adam optimization; and Gaussian Process Regression (GPR),\nimplemented with GPyTorch and employing various kernel functions. The Random\nForest and neural network models provided predictive capabilities based on\nelemental compositions and environmental conditions. Notably, Gaussian Process\nRegression demonstrated superior performance, particularly with hybrid kernel\nfunctions. Log-transformed GPR further refined predictions. This study\nhighlights the efficacy of ML, particularly GPR, in predicting corrosion rates\nand material properties.", "published": "2025-08-10 13:06:08", "link": "http://arxiv.org/abs/2508.11685v1", "categories": ["eess.SP", "cond-mat.mtrl-sci", "cs.LG", "stat.ML"], "primary_category": "eess.SP"}
{"title": "AlphaEval: A Comprehensive and Efficient Evaluation Framework for Formula Alpha Mining", "abstract": "Formula alpha mining, which generates predictive signals from financial data,\nis critical for quantitative investment. Although various algorithmic\napproaches-such as genetic programming, reinforcement learning, and large\nlanguage models-have significantly expanded the capacity for alpha discovery,\nsystematic evaluation remains a key challenge. Existing evaluation metrics\npredominantly include backtesting and correlation-based measures. Backtesting\nis computationally intensive, inherently sequential, and sensitive to specific\nstrategy parameters. Correlation-based metrics, though efficient, assess only\npredictive ability and overlook other crucial properties such as temporal\nstability, robustness, diversity, and interpretability. Additionally, the\nclosed-source nature of most existing alpha mining models hinders\nreproducibility and slows progress in this field. To address these issues, we\npropose AlphaEval, a unified, parallelizable, and backtest-free evaluation\nframework for automated alpha mining models. AlphaEval assesses the overall\nquality of generated alphas along five complementary dimensions: predictive\npower, stability, robustness to market perturbations, financial logic, and\ndiversity. Extensive experiments across representative alpha mining algorithms\ndemonstrate that AlphaEval achieves evaluation consistency comparable to\ncomprehensive backtesting, while providing more comprehensive insights and\nhigher efficiency. Furthermore, AlphaEval effectively identifies superior\nalphas compared to traditional single-metric screening approaches. All\nimplementations and evaluation tools are open-sourced to promote\nreproducibility and community engagement.", "published": "2025-08-10 11:19:24", "link": "http://arxiv.org/abs/2508.13174v1", "categories": ["cs.AI", "cs.LG", "q-fin.CP", "stat.ML"], "primary_category": "cs.AI"}
