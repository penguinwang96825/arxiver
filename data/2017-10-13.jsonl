{"title": "End-to-end Network for Twitter Geolocation Prediction and Hashing", "abstract": "We propose an end-to-end neural network to predict the geolocation of a\ntweet. The network takes as input a number of raw Twitter metadata such as the\ntweet message and associated user account information. Our model is language\nindependent, and despite minimal feature engineering, it is interpretable and\ncapable of learning location indicative words and timing patterns. Compared to\nstate-of-the-art systems, our model outperforms them by 2%-6%. Additionally, we\npropose extensions to the model to compress representation learnt by the\nnetwork into binary codes. Experiments show that it produces compact codes\ncompared to benchmark hashing algorithms. An implementation of the model is\nreleased publicly.", "published": "2017-10-13 04:51:18", "link": "http://arxiv.org/abs/1710.04802v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Complex Word Identification: Challenges in Data Annotation and System\n  Performance", "abstract": "This paper revisits the problem of complex word identification (CWI)\nfollowing up the SemEval CWI shared task. We use ensemble classifiers to\ninvestigate how well computational methods can discriminate between complex and\nnon-complex words. Furthermore, we analyze the classification performance to\nunderstand what makes lexical complexity challenging. Our findings show that\nmost systems performed poorly on the SemEval CWI dataset, and one of the\nreasons for that is the way in which human annotation was performed.", "published": "2017-10-13 16:24:23", "link": "http://arxiv.org/abs/1710.04989v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Phrase Embeddings from Paraphrases with GRUs", "abstract": "Learning phrase representations has been widely explored in many Natural\nLanguage Processing (NLP) tasks (e.g., Sentiment Analysis, Machine Translation)\nand has shown promising improvements. Previous studies either learn\nnon-compositional phrase representations with general word embedding learning\ntechniques or learn compositional phrase representations based on syntactic\nstructures, which either require huge amounts of human annotations or cannot be\neasily generalized to all phrases. In this work, we propose to take advantage\nof large-scaled paraphrase database and present a pair-wise gated recurrent\nunits (pairwise-GRU) framework to generate compositional phrase\nrepresentations. Our framework can be re-used to generate representations for\nany phrases. Experimental results show that our framework achieves\nstate-of-the-art results on several phrase similarity tasks.", "published": "2017-10-13 22:55:43", "link": "http://arxiv.org/abs/1710.05094v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
