{"title": "Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction\n  Tasks", "abstract": "There is a lot of research interest in encoding variable length sentences\ninto fixed length vectors, in a way that preserves the sentence meanings. Two\ncommon methods include representations based on averaging word vectors, and\nrepresentations based on the hidden states of recurrent neural networks such as\nLSTMs. The sentence vectors are used as features for subsequent machine\nlearning tasks or for pre-training in the context of deep learning. However,\nnot much is known about the properties that are encoded in these sentence\nrepresentations and about the language information they capture. We propose a\nframework that facilitates better understanding of the encoded representations.\nWe define prediction tasks around isolated aspects of sentence structure\n(namely sentence length, word content, and word order), and score\nrepresentations by the ability to train a classifier to solve each prediction\ntask when using the representation as input. We demonstrate the potential\ncontribution of the approach by analyzing different sentence representation\nmechanisms. The analysis sheds light on the relative strengths of different\nsentence embedding methods with respect to these low level prediction tasks,\nand on the effect of the encoded vector's dimensionality on the resulting\nrepresentations.", "published": "2016-08-15 08:51:38", "link": "http://arxiv.org/abs/1608.04207v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural Language Processing using Hadoop and KOSHIK", "abstract": "Natural language processing, as a data analytics related technology, is used\nwidely in many research areas such as artificial intelligence, human language\nprocessing, and translation. At present, due to explosive growth of data, there\nare many challenges for natural language processing. Hadoop is one of the\nplatforms that can process the large amount of data required for natural\nlanguage processing. KOSHIK is one of the natural language processing\narchitectures, and utilizes Hadoop and contains language processing components\nsuch as Stanford CoreNLP and OpenNLP. This study describes how to build a\nKOSHIK platform with the relevant tools, and provides the steps to analyze wiki\ndata. Finally, it evaluates and discusses the advantages and disadvantages of\nthe KOSHIK architecture, and gives recommendations on improving the processing\nperformance.", "published": "2016-08-15 23:09:21", "link": "http://arxiv.org/abs/1608.04434v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attribute Extraction from Product Titles in eCommerce", "abstract": "This paper presents a named entity extraction system for detecting attributes\nin product titles of eCommerce retailers like Walmart. The absence of syntactic\nstructure in such short pieces of text makes extracting attribute values a\nchallenging problem. We find that combining sequence labeling algorithms such\nas Conditional Random Fields and Structured Perceptron with a curated\nnormalization scheme produces an effective system for the task of extracting\nproduct attribute values from titles. To keep the discussion concrete, we will\nillustrate the mechanics of the system from the point of view of a particular\nattribute - brand. We also discuss the importance of an attribute extraction\nsystem in the context of retail websites with large product catalogs, compare\nour approach to other potential approaches to this problem and end the paper\nwith a discussion of the performance of our system for extracting attributes.", "published": "2016-08-15 03:34:13", "link": "http://arxiv.org/abs/1608.04670v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
