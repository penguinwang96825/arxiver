{"title": "Federated Learning Of Out-Of-Vocabulary Words", "abstract": "We demonstrate that a character-level recurrent neural network is able to\nlearn out-of-vocabulary (OOV) words under federated learning settings, for the\npurpose of expanding the vocabulary of a virtual keyboard for smartphones\nwithout exporting sensitive text to servers. High-frequency words can be\nsampled from the trained generative model by drawing from the joint posterior\ndirectly. We study the feasibility of the approach in two settings: (1) using\nsimulated federated learning on a publicly available non-IID per-user dataset\nfrom a popular social networking website, (2) using federated learning on data\nhosted on user mobile devices. The model achieves good recall and precision\ncompared to ground-truth OOV words in setting (1). With (2) we demonstrate the\npracticality of this approach by showing that we can learn meaningful OOV words\nwith good character-level prediction accuracy and cross entropy loss.", "published": "2019-03-26 00:01:47", "link": "http://arxiv.org/abs/1903.10635v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reinforcement Learning Based Text Style Transfer without Parallel\n  Training Corpus", "abstract": "Text style transfer rephrases a text from a source style (e.g., informal) to\na target style (e.g., formal) while keeping its original meaning. Despite the\nsuccess existing works have achieved using a parallel corpus for the two\nstyles, transferring text style has proven significantly more challenging when\nthere is no parallel training corpus. In this paper, we address this challenge\nby using a reinforcement-learning-based generator-evaluator architecture. Our\ngenerator employs an attention-based encoder-decoder to transfer a sentence\nfrom the source style to the target style. Our evaluator is an adversarially\ntrained style discriminator with semantic and syntactic constraints that score\nthe generated sentence for style, meaning preservation, and fluency.\nExperimental results on two different style transfer tasks (sentiment transfer\nand formality transfer) show that our model outperforms state-of-the-art\napproaches. Furthermore, we perform a manual evaluation that demonstrates the\neffectiveness of the proposed method using subjective metrics of generated text\nquality.", "published": "2019-03-26 04:33:23", "link": "http://arxiv.org/abs/1903.10671v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Document Similarity for Texts of Varying Lengths via Hidden Topics", "abstract": "Measuring similarity between texts is an important task for several\napplications. Available approaches to measure document similarity are\ninadequate for document pairs that have non-comparable lengths, such as a long\ndocument and its summary. This is because of the lexical, contextual and the\nabstraction gaps between a long document of rich details and its concise\nsummary of abstract information. In this paper, we present a document matching\napproach to bridge this gap, by comparing the texts in a common space of hidden\ntopics. We evaluate the matching algorithm on two matching tasks and find that\nit consistently and widely outperforms strong baselines. We also highlight the\nbenefits of incorporating domain knowledge to text matching.", "published": "2019-03-26 04:42:17", "link": "http://arxiv.org/abs/1903.10675v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SciBERT: A Pretrained Language Model for Scientific Text", "abstract": "Obtaining large-scale annotated data for NLP tasks in the scientific domain\nis challenging and expensive. We release SciBERT, a pretrained language model\nbased on BERT (Devlin et al., 2018) to address the lack of high-quality,\nlarge-scale labeled scientific data. SciBERT leverages unsupervised pretraining\non a large multi-domain corpus of scientific publications to improve\nperformance on downstream scientific NLP tasks. We evaluate on a suite of tasks\nincluding sequence tagging, sentence classification and dependency parsing,\nwith datasets from a variety of scientific domains. We demonstrate\nstatistically significant improvements over BERT and achieve new\nstate-of-the-art results on several of these tasks. The code and pretrained\nmodels are available at https://github.com/allenai/scibert/.", "published": "2019-03-26 05:11:46", "link": "http://arxiv.org/abs/1903.10676v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Silver Standard Corpus of Human Phenotype-Gene Relations", "abstract": "Human phenotype-gene relations are fundamental to fully understand the origin\nof some phenotypic abnormalities and their associated diseases. Biomedical\nliterature is the most comprehensive source of these relations, however, we\nneed Relation Extraction tools to automatically recognize them. Most of these\ntools require an annotated corpus and to the best of our knowledge, there is no\ncorpus available annotated with human phenotype-gene relations. This paper\npresents the Phenotype-Gene Relations (PGR) corpus, a silver standard corpus of\nhuman phenotype and gene annotations and their relations. The corpus consists\nof 1712 abstracts, 5676 human phenotype annotations, 13835 gene annotations,\nand 4283 relations. We generated this corpus using Named-Entity Recognition\ntools, whose results were partially evaluated by eight curators, obtaining a\nprecision of 87.01%. By using the corpus we were able to obtain promising\nresults with two state-of-the-art deep learning tools, namely 78.05% of\nprecision. The PGR corpus was made publicly available to the research\ncommunity.", "published": "2019-03-26 08:26:58", "link": "http://arxiv.org/abs/1903.10728v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Model Adaptation for Language and Dialect Identification of\n  Text", "abstract": "This article describes an unsupervised language model adaptation approach\nthat can be used to enhance the performance of language identification methods.\nThe approach is applied to a current version of the HeLI language\nidentification method, which is now called HeLI 2.0. We describe the HeLI 2.0\nmethod in detail. The resulting system is evaluated using the datasets from the\nGerman dialect identification and Indo-Aryan language identification shared\ntasks of the VarDial workshops 2017 and 2018. The new approach with language\nidentification provides considerably higher F1-scores than the previous HeLI\nmethod or the other systems which participated in the shared tasks. The results\nindicate that unsupervised language model adaptation should be considered as an\noption in all language identification tasks, especially in those where\nencountering out-of-domain data is likely.", "published": "2019-03-26 14:19:19", "link": "http://arxiv.org/abs/1903.10915v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A New Approach for Semi-automatic Building and Extending a Multilingual\n  Terminology Thesaurus", "abstract": "This paper describes a new system for semi-automatically building, extending\nand managing a terminological thesaurus---a multilingual terminology dictionary\nenriched with relationships between the terms themselves to form a thesaurus.\nThe system allows to radically enhance the workflow of current terminology\nexpert groups, where most of the editing decisions still come from\nintrospection. The presented system supplements the lexicographic process with\nnatural language processing techniques, which are seamlessly integrated to the\nthesaurus editing environment. The system's methodology and the resulting\nthesaurus are closely connected to new domain corpora in the six languages\ninvolved. They are used for term usage examples as well as for the automatic\nextraction of new candidate terms. The terminological thesaurus is now\naccessible via a web-based application, which a) presents rich detailed\ninformation on each term, b) visualizes term relations, and c) displays\nreal-life usage examples of the term in the domain-related documents and in the\ncontext-based similar terms. Furthermore, the specialized corpora are used to\ndetect candidate translations of terms from the central language (Czech) to the\nother languages (English, French, German, Russian and Slovak) as well as to\ndetect broader Czech terms, which help to place new terms in the actual\nthesaurus hierarchy. This project has been realized as a terminological\nthesaurus of land surveying, but the presented tools and methodology are\nreusable for other terminology domains.", "published": "2019-03-26 14:32:55", "link": "http://arxiv.org/abs/1903.10921v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Probabilistic Generative Model of Linguistic Typology", "abstract": "In the principles-and-parameters framework, the structural features of\nlanguages depend on parameters that may be toggled on or off, with a single\nparameter often dictating the status of multiple features. The implied\ncovariance between features inspires our probabilisation of this line of\nlinguistic inquiry---we develop a generative model of language based on\nexponential-family matrix factorisation. By modelling all languages and\nfeatures within the same architecture, we show how structural similarities\nbetween languages can be exploited to predict typological features with\nnear-perfect accuracy, outperforming several baselines on the task of\npredicting held-out features. Furthermore, we show that language embeddings\npre-trained on monolingual text allow for generalisation to unobserved\nlanguages. This finding has clear practical and also theoretical implications:\nthe results confirm what linguists have hypothesised, i.e.~that there are\nsignificant correlations between typological features and languages.", "published": "2019-03-26 15:14:31", "link": "http://arxiv.org/abs/1903.10950v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain Representation for Knowledge Graph Embedding", "abstract": "Embedding entities and relations into a continuous multi-dimensional vector\nspace have become the dominant method for knowledge graph embedding in\nrepresentation learning. However, most existing models ignore to represent\nhierarchical knowledge, such as the similarities and dissimilarities of\nentities in one domain. We proposed to learn a Domain Representations over\nexisting knowledge graph embedding models, such that entities that have similar\nattributes are organized into the same domain. Such hierarchical knowledge of\ndomains can give further evidence in link prediction. Experimental results show\nthat domain embeddings give a significant improvement over the most recent\nstate-of-art baseline knowledge graph embedding models.", "published": "2019-03-26 07:44:39", "link": "http://arxiv.org/abs/1903.10716v4", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Interoperability and machine-to-machine translation model with mappings\n  to machine learning tasks", "abstract": "Modern large-scale automation systems integrate thousands to hundreds of\nthousands of physical sensors and actuators. Demands for more flexible\nreconfiguration of production systems and optimization across different\ninformation models, standards and legacy systems challenge current system\ninteroperability concepts. Automatic semantic translation across information\nmodels and standards is an increasingly important problem that needs to be\naddressed to fulfill these demands in a cost-efficient manner under constraints\nof human capacity and resources in relation to timing requirements and system\ncomplexity. Here we define a translator-based operational interoperability\nmodel for interacting cyber-physical systems in mathematical terms, which\nincludes system identification and ontology-based translation as special cases.\nWe present alternative mathematical definitions of the translator learning task\nand mappings to similar machine learning tasks and solutions based on recent\ndevelopments in machine learning. Possibilities to learn translators between\nartefacts without a common physical context, for example in simulations of\ndigital twins and across layers of the automation pyramid are briefly\ndiscussed.", "published": "2019-03-26 08:43:38", "link": "http://arxiv.org/abs/1903.10735v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Extracting Success from IBM's 20-Qubit Machines Using Error-Aware\n  Compilation", "abstract": "NISQ (Noisy, Intermediate-Scale Quantum) computing requires error mitigation\nto achieve meaningful computation. Our compilation tool development focuses on\nthe fact that the error rates of individual qubits are not equal, with a goal\nof maximizing the success probability of real-world subroutines such as an\nadder circuit. We begin by establishing a metric for choosing among possible\npaths and circuit alternatives for executing gates between variables placed far\napart within the processor, and test our approach on two IBM 20-qubit systems\nnamed Tokyo and Poughkeepsie. We find that a single-number metric describing\nthe fidelity of individual gates is a useful but imperfect guide. Our compiler\nuses this subsystem and maps complete circuits onto the machine using a beam\nsearch-based heuristic that will scale as processor and program sizes grow. To\nevaluate the whole compilation process, we compiled and executed adder\ncircuits, then calculated the KL-divergence (a measure of the distance between\ntwo probability distributions). For a circuit within the capabilities of the\nhardware, our compilation increases estimated success probability and reduces\nKL-divergence relative to an error-oblivious placement.", "published": "2019-03-26 15:43:36", "link": "http://arxiv.org/abs/1903.10963v1", "categories": ["quant-ph", "cs.CL"], "primary_category": "quant-ph"}
{"title": "Simple Applications of BERT for Ad Hoc Document Retrieval", "abstract": "Following recent successes in applying BERT to question answering, we explore\nsimple applications to ad hoc document retrieval. This required confronting the\nchallenge posed by documents that are typically longer than the length of input\nBERT was designed to handle. We address this issue by applying inference on\nsentences individually, and then aggregating sentence scores to produce\ndocument scores. Experiments on TREC microblog and newswire test collections\nshow that our approach is simple yet effective, as we report the highest\naverage precision on these datasets by neural approaches that we are aware of.", "published": "2019-03-26 15:58:33", "link": "http://arxiv.org/abs/1903.10972v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Deep Learning and Word Embeddings for Tweet Classification for Crisis\n  Response", "abstract": "Tradition tweet classification models for crisis response focus on\nconvolutional layers and domain-specific word embeddings. In this paper, we\nstudy the application of different neural networks with general-purpose and\ndomain-specific word embeddings to investigate their ability to improve the\nperformance of tweet classification models. We evaluate four tweet\nclassification models on CrisisNLP dataset and obtain comparable results which\nindicates that general-purpose word embedding such as GloVe can be used instead\nof domain-specific word embedding especially with Bi-LSTM where results\nreported the highest performance of 62.04% F1 score.", "published": "2019-03-26 17:10:07", "link": "http://arxiv.org/abs/1903.11024v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improve Diverse Text Generation by Self Labeling Conditional Variational\n  Auto Encoder", "abstract": "Diversity plays a vital role in many text generating applications. In recent\nyears, Conditional Variational Auto Encoders (CVAE) have shown promising\nperformances for this task. However, they often encounter the so called\nKL-Vanishing problem. Previous works mitigated such problem by heuristic\nmethods such as strengthening the encoder or weakening the decoder while\noptimizing the CVAE objective function. Nevertheless, the optimizing direction\nof these methods are implicit and it is hard to find an appropriate degree to\nwhich these methods should be applied. In this paper, we propose an explicit\noptimizing objective to complement the CVAE to directly pull away from\nKL-vanishing. In fact, this objective term guides the encoder towards the \"best\nencoder\" of the decoder to enhance the expressiveness. A labeling network is\nintroduced to estimate the \"best encoder\". It provides a continuous label in\nthe latent space of CVAE to help build a close connection between latent\nvariables and targets. The whole proposed method is named Self Labeling\nCVAE~(SLCVAE). To accelerate the research of diverse text generation, we also\npropose a large native one-to-many dataset. Extensive experiments are conducted\non two tasks, which show that our method largely improves the generating\ndiversity while achieving comparable accuracy compared with state-of-art\nalgorithms.", "published": "2019-03-26 12:53:26", "link": "http://arxiv.org/abs/1903.10842v1", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Privacy-preserving Active Learning on Sensitive Data for User Intent\n  Classification", "abstract": "Active learning holds promise of significantly reducing data annotation costs\nwhile maintaining reasonable model performance. However, it requires sending\ndata to annotators for labeling. This presents a possible privacy leak when the\ntraining set includes sensitive user data. In this paper, we describe an\napproach for carrying out privacy preserving active learning with quantifiable\nguarantees. We evaluate our approach by showing the tradeoff between privacy,\nutility and annotation budget on a binary classification task in a active\nlearning setting.", "published": "2019-03-26 18:48:43", "link": "http://arxiv.org/abs/1903.11112v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "WGANSing: A Multi-Voice Singing Voice Synthesizer Based on the\n  Wasserstein-GAN", "abstract": "We present a deep neural network based singing voice synthesizer, inspired by\nthe Deep Convolutions Generative Adversarial Networks (DCGAN) architecture and\noptimized using the Wasserstein-GAN algorithm. We use vocoder parameters for\nacoustic modelling, to separate the influence of pitch and timbre. This\nfacilitates the modelling of the large variability of pitch in the singing\nvoice. Our network takes a block of consecutive frame-wise linguistic and\nfundamental frequency features, along with global singer identity as input and\noutputs vocoder features, corresponding to the block of features. This\nblock-wise approach, along with the training methodology allows us to model\ntemporal dependencies within the features of the input block. For inference,\nsequential blocks are concatenated using an overlap-add procedure. We show that\nthe performance of our model is competitive with regards to the\nstate-of-the-art and the original sample using objective metrics and a\nsubjective listening test. We also present examples of the synthesis on a\nsupplementary website and the source code via GitHub.", "published": "2019-03-26 08:30:46", "link": "http://arxiv.org/abs/1903.10729v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Conditioning a Recurrent Neural Network to synthesize musical instrument\n  transients", "abstract": "A recurrent Neural Network (RNN) is trained to predict sound samples based on\naudio input augmented by control parameter information for pitch, volume, and\ninstrument identification. During the generative phase following training,\naudio input is taken from the output of the previous time step, and the\nparameters are externally controlled allowing the network to be played as a\nmusical instrument. Building on an architecture developed in previous work, we\nfocus on the learning and synthesis of transients - the temporal response of\nthe network during the short time (tens of milliseconds) following the onset\nand offset of a control signal. We find that the network learns the particular\ntransient characteristics of two different synthetic instruments, and\nfurthermore shows some ability to interpolate between the characteristics of\nthe instruments used in training in response to novel parameter settings. We\nalso study the behaviour of the units in hidden layers of the RNN using various\nvisualisation techniques and find a variety of volume-specific response\ncharacteristics.", "published": "2019-03-26 06:33:35", "link": "http://arxiv.org/abs/1903.10703v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "H.5.5"], "primary_category": "cs.SD"}
{"title": "Multiscale CNN based Deep Metric Learning for Bioacoustic\n  Classification: Overcoming Training Data Scarcity Using Dynamic Triplet Loss", "abstract": "This paper proposes multiscale convolutional neural network (CNN)-based deep\nmetric learning for bioacoustic classification, under low training data\nconditions. The proposed CNN is characterized by the utilization of four\ndifferent filter sizes at each level to analyze input feature maps. This\nmultiscale nature helps in describing different bioacoustic events effectively:\nsmaller filters help in learning the finer details of bioacoustic events,\nwhereas, larger filters help in analyzing a larger context leading to global\ndetails. A dynamic triplet loss is employed in the proposed CNN architecture to\nlearn a transformation from the input space to the embedding space, where\nclassification is performed. The triplet loss helps in learning this\ntransformation by analyzing three examples, referred to as triplets, at a time\nwhere intra-class distance is minimized while maximizing the inter-class\nseparation by a dynamically increasing margin. The number of possible triplets\nincreases cubically with the dataset size, making triplet loss more suitable\nthan the softmax cross-entropy loss in low training data conditions.\nExperiments on three different publicly available datasets show that the\nproposed framework performs better than existing bioacoustic classification\nframeworks. Experimental results also confirm the superiority of the triplet\nloss over the cross-entropy loss in low training data conditions", "published": "2019-03-26 07:16:38", "link": "http://arxiv.org/abs/1903.10713v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Musical Tempo and Key Estimation using Convolutional Neural Networks\n  with Directional Filters", "abstract": "In this article we explore how the different semantics of spectrograms' time\nand frequency axes can be exploited for musical tempo and key estimation using\nConvolutional Neural Networks (CNN). By addressing both tasks with the same\nnetwork architectures ranging from shallow, domain-specific approaches to deep\nvariants with directional filters, we show that axis-aligned architectures\nperform similarly well as common VGG-style networks developed for computer\nvision, while being less vulnerable to confounding factors and requiring fewer\nmodel parameters.", "published": "2019-03-26 12:43:09", "link": "http://arxiv.org/abs/1903.10839v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Augmented Ultrasonic Data for Machine Learning", "abstract": "Flaw detection in non-destructive testing, especially in complex signals like\nultrasonic data, has thus far relied heavily on the expertise and judgement of\ntrained human inspectors. While automated systems have been used for a long\ntime, these have mostly been limited to using simple decision automation, such\nas signal amplitude threshold. The recent advances in various machine learning\nalgorithms have solved many similarly difficult classification problems, that\nhave previously been considered intractable. For non-destructive testing,\nencouraging results have already been reported in the open literature, but the\nuse of machine learning is still very limited in NDT applications in the field.\nKey issue hindering their use, is the limited availability of representative\nflawed data-sets to be used for training. In the present paper, we develop\nmodern, very deep convolutional network to detect flaws from phased-array\nultrasonic data. We make extensive use of data augmentation to enhance the\ninitially limited raw data and to aid learning. The data augmentation utilizes\nvirtual flaws - a technique, that has successfully been used in training human\ninspectors and is soon to be used in nuclear inspection qualification. The\nresults from the machine learning classifier are compared to human performance.\nWe show, that using sophisticated data augmentation, modern deep learning\nnetworks can be trained to achieve superhuman performance by significant\nmargin.", "published": "2019-03-26 09:03:37", "link": "http://arxiv.org/abs/1903.11399v1", "categories": ["eess.SP", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
