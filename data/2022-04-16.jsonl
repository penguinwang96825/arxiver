{"title": "Calibrating Trust of Multi-Hop Question Answering Systems with\n  Decompositional Probes", "abstract": "Multi-hop Question Answering (QA) is a challenging task since it requires an\naccurate aggregation of information from multiple context paragraphs and a\nthorough understanding of the underlying reasoning chains. Recent work in\nmulti-hop QA has shown that performance can be boosted by first decomposing the\nquestions into simpler, single-hop questions. In this paper, we explore one\nadditional utility of the multi-hop decomposition from the perspective of\nexplainable NLP: to create explanation by probing a neural QA model with them.\nWe hypothesize that in doing so, users will be better able to predict when the\nunderlying QA system will give the correct answer. Through human participant\nstudies, we verify that exposing the decomposition probes and answers to the\nprobes to users can increase their ability to predict system performance on a\nquestion instance basis. We show that decomposition is an effective form of\nprobing QA systems as well as a promising approach to explanation generation.\nIn-depth analyses show the need for improvements in decomposition systems.", "published": "2022-04-16 01:03:36", "link": "http://arxiv.org/abs/2204.07693v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BLCU-ICALL at SemEval-2022 Task 1: Cross-Attention Multitasking\n  Framework for Definition Modeling", "abstract": "This paper describes the BLCU-ICALL system used in the SemEval-2022 Task 1\nComparing Dictionaries and Word Embeddings, the Definition Modeling subtrack,\nachieving 1st on Italian, 2nd on Spanish and Russian, and 3rd on English and\nFrench. We propose a transformer-based multitasking framework to explore the\ntask. The framework integrates multiple embedding architectures through the\ncross-attention mechanism, and captures the structure of glosses through a\nmasking language model objective. Additionally, we also investigate a simple\nbut effective model ensembling strategy to further improve the robustness. The\nevaluation results show the effectiveness of our solution. We release our code\nat: https://github.com/blcuicall/SemEval2022-Task1-DM.", "published": "2022-04-16 02:33:28", "link": "http://arxiv.org/abs/2204.07701v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Attention-based Sentence-Level Meta-Embeddings from\n  Contextualised Language Models", "abstract": "A variety of contextualised language models have been proposed in the NLP\ncommunity, which are trained on diverse corpora to produce numerous Neural\nLanguage Models (NLMs). However, different NLMs have reported different levels\nof performances in downstream NLP applications when used as text\nrepresentations. We propose a sentence-level meta-embedding learning method\nthat takes independently trained contextualised word embedding models and\nlearns a sentence embedding that preserves the complementary strengths of the\ninput source NLMs. Our proposed method is unsupervised and is not tied to a\nparticular downstream task, which makes the learnt meta-embeddings in principle\napplicable to different tasks that require sentence representations.\nSpecifically, we first project the token-level embeddings obtained by the\nindividual NLMs and learn attention weights that indicate the contributions of\nsource embeddings towards their token-level meta-embeddings. Next, we apply\nmean and max pooling to produce sentence-level meta-embeddings from token-level\nmeta-embeddings. Experimental results on semantic textual similarity benchmarks\nshow that our proposed unsupervised sentence-level meta-embedding method\noutperforms previously proposed sentence-level meta-embedding methods as well\nas a supervised baseline.", "published": "2022-04-16 08:20:24", "link": "http://arxiv.org/abs/2204.07746v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SimpleBERT: A Pre-trained Model That Learns to Generate Simple Words", "abstract": "Pre-trained models are widely used in the tasks of natural language\nprocessing nowadays. However, in the specific field of text simplification, the\nresearch on improving pre-trained models is still blank. In this work, we\npropose a continued pre-training method for text simplification. Specifically,\nwe propose a new masked language modeling (MLM) mechanism, which does not\nrandomly mask words but only masks simple words. The new mechanism can make the\nmodel learn to generate simple words. We use a small-scale simple text dataset\nfor continued pre-training and employ two methods to identify simple words from\nthe texts. We choose BERT, a representative pre-trained model, and continue\npre-training it using our proposed method. Finally, we obtain SimpleBERT, which\nsurpasses BERT in both lexical simplification and sentence simplification tasks\nand has achieved state-of-the-art results on multiple datasets. What's more,\nSimpleBERT can replace BERT in existing simplification models without\nmodification.", "published": "2022-04-16 11:28:01", "link": "http://arxiv.org/abs/2204.07779v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Unification of Discourse Annotation Frameworks", "abstract": "Discourse information is difficult to represent and annotate. Among the major\nframeworks for annotating discourse information, RST, PDTB and SDRT are widely\ndiscussed and used, each having its own theoretical foundation and focus.\nCorpora annotated under different frameworks vary considerably. To make better\nuse of the existing discourse corpora and achieve the possible synergy of\ndifferent frameworks, it is worthwhile to investigate the systematic relations\nbetween different frameworks and devise methods of unifying the frameworks.\nAlthough the issue of framework unification has been a topic of discussion for\na long time, there is currently no comprehensive approach which considers\nunifying both discourse structure and discourse relations and evaluates the\nunified framework intrinsically and extrinsically. We plan to use automatic\nmeans for the unification task and evaluate the result with structural\ncomplexity and downstream tasks. We will also explore the application of the\nunified framework in multi-task learning and graphical models.", "published": "2022-04-16 11:34:00", "link": "http://arxiv.org/abs/2204.07781v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Logical Inference for Counting on Semi-structured Tables", "abstract": "Recently, the Natural Language Inference (NLI) task has been studied for\nsemi-structured tables that do not have a strict format. Although neural\napproaches have achieved high performance in various types of NLI, including\nNLI between semi-structured tables and texts, they still have difficulty in\nperforming a numerical type of inference, such as counting. To handle a\nnumerical type of inference, we propose a logical inference system for\nreasoning between semi-structured tables and texts. We use logical\nrepresentations as meaning representations for tables and texts and use model\nchecking to handle a numerical type of inference between texts and tables. To\nevaluate the extent to which our system can perform inference with numerical\ncomparatives, we make an evaluation protocol that focuses on numerical\nunderstanding between semi-structured tables and texts in English. We show that\nour system can more robustly perform inference between tables and texts that\nrequires numerical understanding compared with current neural approaches.", "published": "2022-04-16 14:08:43", "link": "http://arxiv.org/abs/2204.07803v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Classify Open Intent via Soft Labeling and Manifold Mixup", "abstract": "Open intent classification is a practical yet challenging task in dialogue\nsystems. Its objective is to accurately classify samples of known intents while\nat the same time detecting those of open (unknown) intents. Existing methods\nusually use outlier detection algorithms combined with K-class classifier to\ndetect open intents, where K represents the class number of known intents.\nDifferent from them, in this paper, we consider another way without using\noutlier detection algorithms. Specifically, we directly train a (K+1)-class\nclassifier for open intent classification, where the (K+1)-th class represents\nopen intents. To address the challenge that training a (K+1)-class classifier\nwith training samples of only K classes, we propose a deep model based on Soft\nLabeling and Manifold Mixup (SLMM). In our method, soft labeling is used to\nreshape the label distribution of the known intent samples, aiming at reducing\nmodel's overconfident on known intents. Manifold mixup is used to generate\npseudo samples for open intents, aiming at well optimizing the decision\nboundary of open intents. Experiments on four benchmark datasets demonstrate\nthat our method outperforms previous methods and achieves state-of-the-art\nperformance. All the code and data of this work can be obtained at\nhttps://github.com/zifengcheng/SLMM.", "published": "2022-04-16 14:10:07", "link": "http://arxiv.org/abs/2204.07804v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Contrastive Cross-Channel Data Augmentation Framework for Aspect-based\n  Sentiment Analysis", "abstract": "Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis\ntask, which focuses on detecting the sentiment polarity towards the aspect in a\nsentence. However, it is always sensitive to the multi-aspect challenge, where\nfeatures of multiple aspects in a sentence will affect each other. To mitigate\nthis issue, we design a novel training framework, called Contrastive\nCross-Channel Data Augmentation (C3 DA), which leverages an in-domain generator\nto construct more multi-aspect samples and then boosts the robustness of ABSA\nmodels via contrastive learning on these generated data. In practice, given a\ngenerative pretrained language model and some limited ABSA labeled data, we\nfirst employ some parameter-efficient approaches to perform the in-domain\nfine-tuning. Then, the obtained in-domain generator is used to generate the\nsynthetic sentences from two channels, i.e., Aspect Augmentation Channel and\nPolarity Augmentation Channel, which generate the sentence condition on a given\naspect and polarity respectively. Specifically, our C3 DA performs the sentence\ngeneration in a cross-channel manner to obtain more sentences, and proposes an\nEntropy-Minimization Filter to filter low-quality generated samples. Extensive\nexperiments show that our C3 DA can outperform those baselines without any\naugmentations by about 1% on accuracy and Macro- F1. Code and data are released\nin https://github.com/wangbing1416/C3DA.", "published": "2022-04-16 16:05:58", "link": "http://arxiv.org/abs/2204.07832v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging Cross-Lingual Gaps During Leveraging the Multilingual\n  Sequence-to-Sequence Pretraining for Text Generation and Understanding", "abstract": "For multilingual sequence-to-sequence pretrained language models\n(multilingual Seq2Seq PLMs), e.g. mBART, the self-supervised pretraining task\nis trained on a wide range of monolingual languages, e.g. 25 languages from\nCommonCrawl, while the downstream cross-lingual tasks generally progress on a\nbilingual language subset, e.g. English-German, making there exists the data\ndiscrepancy, namely domain discrepancy, and cross-lingual learning objective\ndiscrepancy, namely task discrepancy, between the pretraining and finetuning\nstages. To bridge the above cross-lingual domain and task gaps, we extend the\nvanilla pretrain-finetune pipeline with extra code-switching restore task.\nSpecifically, the first stage employs the self-supervised code-switching\nrestore task as a pretext task, allowing the multilingual Seq2Seq PLMs to\nacquire some in-domain alignment information. And for the second stage, we\nfine-tune the model on downstream data normally. Experiments on both NLG\nevaluation (12 bilingual translation tasks, 30 zero-shot translation tasks, and\n2 cross-lingual summarization tasks) and NLU evaluation (7 cross-lingual\nnatural language inference tasks) show our model outperforms the strong\nbaseline mBART with standard finetuning strategy, consistently. Analyses\nindicate our approach could narrow the Euclidean distance of cross-lingual\nsentence representations, and improve the model generalization with trivial\ncomputational cost. We release the code at:\nhttps://github.com/zanchangtong/CSR4mBART.", "published": "2022-04-16 16:08:38", "link": "http://arxiv.org/abs/2204.07834v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BLISS: Robust Sequence-to-Sequence Learning via Self-Supervised Input\n  Representation", "abstract": "Data augmentations (DA) are the cores to achieving robust\nsequence-to-sequence learning on various natural language processing (NLP)\ntasks. However, most of the DA approaches force the decoder to make predictions\nconditioned on the perturbed input representation, underutilizing supervised\ninformation provided by perturbed input. In this work, we propose a\nframework-level robust sequence-to-sequence learning approach, named BLISS, via\nself-supervised input representation, which has the great potential to\ncomplement the data-level augmentation approaches. The key idea is to supervise\nthe sequence-to-sequence framework with both the \\textit{supervised}\n(\"input$\\rightarrow$output\") and \\textit{self-supervised} (\"perturbed\ninput$\\rightarrow$input\") information. We conduct comprehensive experiments to\nvalidate the effectiveness of BLISS on various tasks, including machine\ntranslation, grammatical error correction, and text summarization. The results\nshow that BLISS outperforms significantly the vanilla Transformer and\nconsistently works well across tasks than the other five contrastive baselines.\nExtensive analyses reveal that BLISS learns robust representations and rich\nlinguistic knowledge, confirming our claim. Source code will be released upon\npublication.", "published": "2022-04-16 16:19:47", "link": "http://arxiv.org/abs/2204.07837v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sparsely Activated Mixture-of-Experts are Robust Multi-Task Learners", "abstract": "Traditional multi-task learning (MTL) methods use dense networks that use the\nsame set of shared weights across several different tasks. This often creates\ninterference where two or more tasks compete to pull model parameters in\ndifferent directions. In this work, we study whether sparsely activated\nMixture-of-Experts (MoE) improve multi-task learning by specializing some\nweights for learning shared representations and using the others for learning\ntask-specific information. To this end, we devise task-aware gating functions\nto route examples from different tasks to specialized experts which share\nsubsets of network weights conditioned on the task. This results in a sparsely\nactivated multi-task model with a large number of parameters, but with the same\ncomputational cost as that of a dense model. We demonstrate such sparse\nnetworks to improve multi-task learning along three key dimensions: (i)\ntransfer to low-resource tasks from related tasks in the training mixture; (ii)\nsample-efficient generalization to tasks not seen during training by making use\nof task-aware routing from seen related tasks; (iii) robustness to the addition\nof unrelated tasks by avoiding catastrophic forgetting of existing tasks.", "published": "2022-04-16 00:56:12", "link": "http://arxiv.org/abs/2204.07689v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Efficient Reinforcement Learning for Unsupervised Controlled Text\n  Generation", "abstract": "Controlled text generation tasks such as unsupervised text style transfer\nhave increasingly adopted the use of Reinforcement Learning (RL). A major\nchallenge in applying RL to such tasks is the sparse reward, which is available\nonly after the full text is generated. Sparse rewards, combined with a large\naction space make RL training sample-inefficient and difficult to converge.\nRecently proposed reward-shaping strategies to address this issue have shown\nonly negligible gains. In contrast, this work proposes a novel approach that\nprovides dense rewards to each generated token. We evaluate our approach by its\nusage in unsupervised text style transfer. Averaged across datasets, our style\ntransfer system improves upon current state-of-art systems by 21\\% on human\nevaluation and 12\\% on automatic evaluation. Upon ablated comparison with the\ncurrent reward shaping approach (the `roll-out strategy'), using dense rewards\nimproves the overall style transfer quality by 22\\% based on human evaluation.\nFurther the RL training is 2.5 times as sample efficient, and 7 times faster.", "published": "2022-04-16 01:54:24", "link": "http://arxiv.org/abs/2204.07696v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Super-NaturalInstructions: Generalization via Declarative Instructions\n  on 1600+ NLP Tasks", "abstract": "How well can NLP models generalize to a variety of unseen tasks when provided\nwith task instructions? To address this question, we first introduce\nSuper-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their\nexpert-written instructions. Our collection covers 76 distinct task types,\nincluding but not limited to classification, extraction, infilling, sequence\ntagging, text rewriting, and text composition. This large and diverse\ncollection of tasks enables rigorous benchmarking of cross-task generalization\nunder instructions -- training models to follow instructions on a subset of\ntasks and evaluating them on the remaining unseen ones. Furthermore, we build\nTk-Instruct, a transformer model trained to follow a variety of in-context\ninstructions (plain language task definitions or k-shot examples). Our\nexperiments show that Tk-Instruct outperforms existing instruction-following\nmodels such as InstructGPT by over 9% on our benchmark despite being an order\nof magnitude smaller. We further analyze generalization as a function of\nvarious scaling parameters, such as the number of observed tasks, the number of\ninstances per task, and model sizes. We hope our dataset and model facilitate\nfuture progress towards more general-purpose NLP models.", "published": "2022-04-16 03:12:30", "link": "http://arxiv.org/abs/2204.07705v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TVShowGuess: Character Comprehension in Stories as Speaker Guessing", "abstract": "We propose a new task for assessing machines' skills of understanding\nfictional characters in narrative stories. The task, TVShowGuess, builds on the\nscripts of TV series and takes the form of guessing the anonymous main\ncharacters based on the backgrounds of the scenes and the dialogues. Our human\nstudy supports that this form of task covers comprehension of multiple types of\ncharacter persona, including understanding characters' personalities, facts and\nmemories of personal experience, which are well aligned with the psychological\nand literary theories about the theory of mind (ToM) of human beings on\nunderstanding fictional characters during reading. We further propose new model\narchitectures to support the contextualized encoding of long scene texts.\nExperiments show that our proposed approaches significantly outperform\nbaselines, yet still largely lag behind the (nearly perfect) human performance.\nOur work serves as a first step toward the goal of narrative character\ncomprehension.", "published": "2022-04-16 05:15:04", "link": "http://arxiv.org/abs/2204.07721v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UniGDD: A Unified Generative Framework for Goal-Oriented\n  Document-Grounded Dialogue", "abstract": "The goal-oriented document-grounded dialogue aims at responding to the user\nquery based on the dialogue context and supporting document. Existing studies\ntackle this problem by decomposing it into two sub-tasks: knowledge\nidentification and response generation. However, such pipeline methods would\nunavoidably suffer from the error propagation issue. This paper proposes to\nunify these two sub-tasks via sequentially generating the grounding knowledge\nand the response. We further develop a prompt-connected multi-task learning\nstrategy to model the characteristics and connections of different tasks and\nintroduce linear temperature scheduling to reduce the negative effect of\nirrelevant document information. Experimental results demonstrate the\neffectiveness of our framework.", "published": "2022-04-16 10:01:38", "link": "http://arxiv.org/abs/2204.07770v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Contrastive Learning with Hard Negative Entities for Entity Set\n  Expansion", "abstract": "Entity Set Expansion (ESE) is a promising task which aims to expand entities\nof the target semantic class described by a small seed entity set. Various NLP\nand IR applications will benefit from ESE due to its ability to discover\nknowledge. Although previous ESE methods have achieved great progress, most of\nthem still lack the ability to handle hard negative entities (i.e., entities\nthat are difficult to distinguish from the target entities), since two entities\nmay or may not belong to the same semantic class based on different granularity\nlevels we analyze on. To address this challenge, we devise an entity-level\nmasked language model with contrastive learning to refine the representation of\nentities. In addition, we propose the ProbExpan, a novel probabilistic ESE\nframework utilizing the entity representation obtained by the aforementioned\nlanguage model to expand entities. Extensive experiments and detailed analyses\non three datasets show that our method outperforms previous state-of-the-art\nmethods.", "published": "2022-04-16 12:26:42", "link": "http://arxiv.org/abs/2204.07789v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "What If: Generating Code to Answer Simulation Questions", "abstract": "Many texts, especially in chemistry and biology, describe complex processes.\nWe focus on texts that describe a chemical reaction process and questions that\nask about the process's outcome under different environmental conditions. To\nanswer questions about such processes, one needs to understand the interactions\nbetween the different entities involved in the process and to simulate their\nstate transitions during the process execution under different conditions. A\nstate transition is defined as the memory modification the program does to the\nvariables during the execution. We hypothesize that generating code and\nexecuting it to simulate the process will allow answering such questions. We,\ntherefore, define a domain-specific language (DSL) to represent processes. We\ncontribute to the community a unique dataset curated by chemists and annotated\nby computer scientists. The dataset is composed of process texts, simulation\nquestions, and their corresponding computer codes represented by the DSL.We\npropose a neural program synthesis approach based on reinforcement learning\nwith a novel state-transition semantic reward. The novel reward is based on the\nrun-time semantic similarity between the predicted code and the reference code.\nThis allows simulating complex process transitions and thus answering\nsimulation questions. Our approach yields a significant boost in accuracy for\nsimulation questions: 88\\% accuracy as opposed to 83\\% accuracy of the\nstate-of-the-art neural program synthesis approaches and 54\\% accuracy of\nstate-of-the-art end-to-end text-based approaches.", "published": "2022-04-16 16:10:41", "link": "http://arxiv.org/abs/2204.07835v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "COVIBOT: A Smart Chatbot for Assistance and E-Awareness during COVID-19\n  Pandemic", "abstract": "The coronavirus pandemic has spread over the past two years in our highly\nconnected and information-dense society. Nonetheless, disseminating accurate\nand up-to-date information on the spread of this pandemic remains a challenge.\nIn this context, opting for a solution based on conversational artificial\nintelligence, also known under the name of the chatbot, is proving to be an\nunavoidable solution, especially since it has already shown its effectiveness\nin fighting the coronavirus crisis in several countries. This work proposes to\ndesign and implement a smart chatbot on the theme of COVID-19, called COVIBOT,\nwhich will be useful in the context of Saudi Arabia. COVIBOT is a\ngenerative-based contextual chatbot, which is built using machine learning APIs\nthat are offered by the cloud-based Azure Cognitive Services. Two versions of\nCOVIBOT are offered: English and Arabic versions. Use cases of COVIBOT are\ntested and validated using a scenario-based approach.", "published": "2022-04-16 18:07:46", "link": "http://arxiv.org/abs/2204.07851v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Probing Script Knowledge from Pre-Trained Models", "abstract": "Script knowledge is critical for humans to understand the broad daily tasks\nand routine activities in the world. Recently researchers have explored the\nlarge-scale pre-trained language models (PLMs) to perform various script\nrelated tasks, such as story generation, temporal ordering of event, future\nevent prediction and so on. However, it's still not well studied in terms of\nhow well the PLMs capture the script knowledge. To answer this question, we\ndesign three probing tasks: inclusive sub-event selection, starting sub-event\nselection and temporal ordering to investigate the capabilities of PLMs with\nand without fine-tuning. The three probing tasks can be further used to\nautomatically induce a script for each main event given all the possible\nsub-events. Taking BERT as a case study, by analyzing its performance on script\ninduction as well as each individual probing task, we conclude that the\nstereotypical temporal knowledge among the sub-events is well captured in BERT,\nhowever the inclusive or starting sub-event knowledge is barely encoded.", "published": "2022-04-16 05:13:39", "link": "http://arxiv.org/abs/2204.10176v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WordAlchemy: A transformer-based Reverse Dictionary", "abstract": "A reverse dictionary takes a target word's description as input and returns\nthe words that fit the description. Reverse Dictionaries are useful for new\nlanguage learners, anomia patients, and for solving common tip-of-the-tongue\nproblems (lethologica). Currently, there does not exist any Reverse Dictionary\nprovider with support for any Indian Language. We present a novel open-source\ncross-lingual reverse dictionary system with support for Indian languages. In\nthis paper, we propose a transformer-based deep learning approach to tackle the\nlimitations faced by the existing systems using the mT5 model. This\narchitecture uses the Translation Language Modeling (TLM) technique, rather\nthan the conventional BERT's Masked Language Modeling (MLM) technique.", "published": "2022-04-16 11:41:48", "link": "http://arxiv.org/abs/2204.10181v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Investigating User Radicalization: A Novel Dataset for Identifying\n  Fine-Grained Temporal Shifts in Opinion", "abstract": "There is an increasing need for the ability to model fine-grained opinion\nshifts of social media users, as concerns about the potential polarizing social\neffects increase. However, the lack of publicly available datasets that are\nsuitable for the task presents a major challenge. In this paper, we introduce\nan innovative annotated dataset for modeling subtle opinion fluctuations and\ndetecting fine-grained stances. The dataset includes a sufficient amount of\nstance polarity and intensity labels per user over time and within entire\nconversational threads, thus making subtle opinion fluctuations detectable both\nin long term and in short term. All posts are annotated by non-experts and a\nsignificant portion of the data is also annotated by experts. We provide a\nstrategy for recruiting suitable non-experts. Our analysis of the\ninter-annotator agreements shows that the resulting annotations obtained from\nthe majority vote of the non-experts are of comparable quality to the\nannotations of the experts. We provide analyses of the stance evolution in\nshort term and long term levels, a comparison of language usage between users\nwith vacillating and resolute attitudes, and fine-grained stance detection\nbaselines.", "published": "2022-04-16 09:31:25", "link": "http://arxiv.org/abs/2204.10190v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "A Hierarchical N-Gram Framework for Zero-Shot Link Prediction", "abstract": "Due to the incompleteness of knowledge graphs (KGs), zero-shot link\nprediction (ZSLP) which aims to predict unobserved relations in KGs has\nattracted recent interest from researchers. A common solution is to use textual\nfeatures of relations (e.g., surface name or textual descriptions) as auxiliary\ninformation to bridge the gap between seen and unseen relations. Current\napproaches learn an embedding for each word token in the text. These methods\nlack robustness as they suffer from the out-of-vocabulary (OOV) problem.\nMeanwhile, models built on character n-grams have the capability of generating\nexpressive representations for OOV words. Thus, in this paper, we propose a\nHierarchical N-Gram framework for Zero-Shot Link Prediction (HNZSLP), which\nconsiders the dependencies among character n-grams of the relation surface name\nfor ZSLP. Our approach works by first constructing a hierarchical n-gram graph\non the surface name to model the organizational structure of n-grams that leads\nto the surface name. A GramTransformer, based on the Transformer is then\npresented to model the hierarchical n-gram graph to construct the relation\nembedding for ZSLP. Experimental results show the proposed HNZSLP achieved\nstate-of-the-art performance on two ZSLP datasets.", "published": "2022-04-16 14:52:05", "link": "http://arxiv.org/abs/2204.10293v6", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Persua: A Visual Interactive System to Enhance the Persuasiveness of\n  Arguments in Online Discussion", "abstract": "Persuading people to change their opinions is a common practice in online\ndiscussion forums on topics ranging from political campaigns to relationship\nconsultation. Enhancing people's ability to write persuasive arguments could\nnot only practice their critical thinking and reasoning but also contribute to\nthe effectiveness and civility in online communication. It is, however, not an\neasy task in online discussion settings where written words are the primary\ncommunication channel. In this paper, we derived four design goals for a tool\nthat helps users improve the persuasiveness of arguments in online discussions\nthrough a survey with 123 online forum users and interviews with five debating\nexperts. To satisfy these design goals, we analyzed and built a labeled dataset\nof fine-grained persuasive strategies (i.e., logos, pathos, ethos, and\nevidence) in 164 arguments with high ratings on persuasiveness from\nChangeMyView, a popular online discussion forum. We then designed an\ninteractive visual system, Persua, which provides example-based guidance on\npersuasive strategies to enhance the persuasiveness of arguments. In\nparticular, the system constructs portfolios of arguments based on different\npersuasive strategies applied to a given discussion topic. It then presents\nconcrete examples based on the difference between the portfolios of user input\nand high-quality arguments in the dataset. A between-subjects study shows\nsuggestive evidence that Persua encourages users to submit more times for\nfeedback and helps users improve more on the persuasiveness of their arguments\nthan a baseline system. Finally, a set of design considerations was summarized\nto guide future intelligent systems that improve the persuasiveness in text.", "published": "2022-04-16 08:07:53", "link": "http://arxiv.org/abs/2204.07741v2", "categories": ["cs.HC", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "TASTEset -- Recipe Dataset and Food Entities Recognition Benchmark", "abstract": "Food Computing is currently a fast-growing field of research. Natural\nlanguage processing (NLP) is also increasingly essential in this field,\nespecially for recognising food entities. However, there are still only a few\nwell-defined tasks that serve as benchmarks for solutions in this area. We\nintroduce a new dataset -- called \\textit{TASTEset} -- to bridge this gap. In\nthis dataset, Named Entity Recognition (NER) models are expected to find or\ninfer various types of entities helpful in processing recipes, e.g.~food\nproducts, quantities and their units, names of cooking processes, physical\nquality of ingredients, their purpose, taste.\n  The dataset consists of 700 recipes with more than 13,000 entities to\nextract. We provide a few state-of-the-art baselines of named entity\nrecognition models, which show that our dataset poses a solid challenge to\nexisting models. The best model achieved, on average, 0.95 $F_1$ score,\ndepending on the entity type -- from 0.781 to 0.982. We share the dataset and\nthe task to encourage progress on more in-depth and complex information\nextraction from recipes.", "published": "2022-04-16 10:52:21", "link": "http://arxiv.org/abs/2204.07775v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "STRATA: Word Boundaries & Phoneme Recognition From Continuous Urdu\n  Speech using Transfer Learning, Attention, & Data Augmentation", "abstract": "Phoneme recognition is a largely unsolved problem in NLP, especially for\nlow-resource languages like Urdu. The systems that try to extract the phonemes\nfrom audio speech require hand-labeled phonetic transcriptions. This requires\nexpert linguists to annotate speech data with its relevant phonetic\nrepresentation which is both an expensive and a tedious task. In this paper, we\npropose STRATA, a framework for supervised phoneme recognition that overcomes\nthe data scarcity issue for low resource languages using a seq2seq neural\narchitecture integrated with transfer learning, attention mechanism, and data\naugmentation. STRATA employs transfer learning to reduce the network loss in\nhalf. It uses attention mechanism for word boundaries and frame alignment\ndetection which further reduces the network loss by 4% and is able to identify\nthe word boundaries with 92.2% accuracy. STRATA uses various data augmentation\ntechniques to further reduce the loss by 1.5% and is more robust towards new\nsignals both in terms of generalization and accuracy. STRATA is able to achieve\na Phoneme Error Rate of 16.5% and improves upon the state of the art by 1.1%\nfor TIMIT dataset (English) and 11.5% for CSaLT dataset (Urdu).", "published": "2022-04-16 17:43:17", "link": "http://arxiv.org/abs/2204.07848v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "nigam@COLIEE-22: Legal Case Retrieval and Entailment using Cascading of\n  Lexical and Semantic-based models", "abstract": "This paper describes our submission to the Competition on Legal Information\nExtraction/Entailment 2022 (COLIEE-2022) workshop on case law competition for\ntasks 1 and 2. Task 1 is a legal case retrieval task, which involves reading a\nnew case and extracting supporting cases from the provided case law corpus to\nsupport the decision. Task 2 is the legal case entailment task, which involves\nthe identification of a paragraph from existing cases that entails the decision\nin a relevant case. We employed the neural models Sentence-BERT and Sent2Vec\nfor semantic understanding and the traditional retrieval model BM25 for exact\nmatching in both tasks. As a result, our team (\"nigam\") ranked 5th among all\nthe teams in Tasks 1 and 2. Experimental results indicate that the traditional\nretrieval model BM25 still outperforms neural network-based models.", "published": "2022-04-16 18:10:02", "link": "http://arxiv.org/abs/2204.07853v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "UFRC: A Unified Framework for Reliable COVID-19 Detection on\n  Crowdsourced Cough Audio", "abstract": "We suggested a unified system with core components of data augmentation,\nImageNet-pretrained ResNet-50, cost-sensitive loss, deep ensemble learning, and\nuncertainty estimation to quickly and consistently detect COVID-19 using\nacoustic evidence. To increase the model's capacity to identify a minority\nclass, data augmentation and cost-sensitive loss are incorporated (infected\nsamples). In the COVID-19 detection challenge, ImageNet-pretrained ResNet-50\nhas been found to be effective. The unified framework also integrates deep\nensemble learning and uncertainty estimation to integrate predictions from\nvarious base classifiers for generalisation and reliability. We ran a series of\ntests using the DiCOVA2021 challenge dataset to assess the efficacy of our\nproposed method, and the results show that our method has an AUC-ROC of 85.43\npercent, making it a promising method for COVID-19 detection. The unified\nframework also demonstrates that audio may be used to quickly diagnose\ndifferent respiratory disorders.", "published": "2022-04-16 09:24:16", "link": "http://arxiv.org/abs/2204.07763v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
