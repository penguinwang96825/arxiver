{"title": "A Taxonomy of Ambiguity Types for NLP", "abstract": "Ambiguity is an critical component of language that allows for more effective\ncommunication between speakers, but is often ignored in NLP. Recent work\nsuggests that NLP systems may struggle to grasp certain elements of human\nlanguage understanding because they may not handle ambiguities at the level\nthat humans naturally do in communication. Additionally, different types of\nambiguity may serve different purposes and require different approaches for\nresolution, and we aim to investigate how language models' abilities vary\nacross types. We propose a taxonomy of ambiguity types as seen in English to\nfacilitate NLP analysis. Our taxonomy can help make meaningful splits in\nlanguage ambiguity data, allowing for more fine-grained assessments of both\ndatasets and model performance.", "published": "2024-03-21 01:47:22", "link": "http://arxiv.org/abs/2403.14072v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking Chinese Commonsense Reasoning of LLMs: From\n  Chinese-Specifics to Reasoning-Memorization Correlations", "abstract": "We introduce CHARM, the first benchmark for comprehensively and in-depth\nevaluating the commonsense reasoning ability of large language models (LLMs) in\nChinese, which covers both globally known and Chinese-specific commonsense. We\nevaluated 7 English and 12 Chinese-oriented LLMs on CHARM, employing 5\nrepresentative prompt strategies for improving LLMs' reasoning ability, such as\nChain-of-Thought. Our findings indicate that the LLM's language orientation and\nthe task's domain influence the effectiveness of the prompt strategy, which\nenriches previous research findings. We built closely-interconnected reasoning\nand memorization tasks, and found that some LLMs struggle with memorizing\nChinese commonsense, affecting their reasoning ability, while others show\ndifferences in reasoning despite similar memorization performance. We also\nevaluated the LLMs' memorization-independent reasoning abilities and analyzed\nthe typical errors. Our study precisely identified the LLMs' strengths and\nweaknesses, providing the clear direction for optimization. It can also serve\nas a reference for studies in other fields. We will release CHARM at\nhttps://github.com/opendatalab/CHARM .", "published": "2024-03-21 03:52:01", "link": "http://arxiv.org/abs/2403.14112v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Handcrafted Features to LLMs: A Brief Survey for Machine\n  Translation Quality Estimation", "abstract": "Machine Translation Quality Estimation (MTQE) is the task of estimating the\nquality of machine-translated text in real time without the need for reference\ntranslations, which is of great importance for the development of MT. After two\ndecades of evolution, QE has yielded a wealth of results. This article provides\na comprehensive overview of QE datasets, annotation methods, shared tasks,\nmethodologies, challenges, and future research directions. It begins with an\nintroduction to the background and significance of QE, followed by an\nexplanation of the concepts and evaluation metrics for word-level QE,\nsentence-level QE, document-level QE, and explainable QE. The paper categorizes\nthe methods developed throughout the history of QE into those based on\nhandcrafted features, deep learning, and Large Language Models (LLMs), with a\nfurther division of deep learning-based methods into classic deep learning and\nthose incorporating pre-trained language models (LMs). Additionally, the\narticle details the advantages and limitations of each method and offers a\nstraightforward comparison of different approaches. Finally, the paper\ndiscusses the current challenges in QE research and provides an outlook on\nfuture research directions.", "published": "2024-03-21 04:07:40", "link": "http://arxiv.org/abs/2403.14118v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "M$^3$AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual\n  Academic Lecture Dataset", "abstract": "Publishing open-source academic video recordings is an emergent and prevalent\napproach to sharing knowledge online. Such videos carry rich multimodal\ninformation including speech, the facial and body movements of the speakers, as\nwell as the texts and pictures in the slides and possibly even the papers.\nAlthough multiple academic video datasets have been constructed and released,\nfew of them support both multimodal content recognition and understanding\ntasks, which is partially due to the lack of high-quality human annotations. In\nthis paper, we propose a novel multimodal, multigenre, and multipurpose\naudio-visual academic lecture dataset (M$^3$AV), which has almost 367 hours of\nvideos from five sources covering computer science, mathematics, and medical\nand biology topics. With high-quality human annotations of the slide text and\nspoken words, in particular high-valued name entities, the dataset can be used\nfor multiple audio-visual recognition and understanding tasks. Evaluations\nperformed on contextual speech recognition, speech synthesis, and slide and\nscript generation tasks demonstrate that the diversity of M$^3$AV makes it a\nchallenging dataset.", "published": "2024-03-21 06:43:59", "link": "http://arxiv.org/abs/2403.14168v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MMIDR: Teaching Large Language Model to Interpret Multimodal\n  Misinformation via Knowledge Distillation", "abstract": "Automatic detection of multimodal misinformation has gained a widespread\nattention recently. However, the potential of powerful Large Language Models\n(LLMs) for multimodal misinformation detection remains underexplored. Besides,\nhow to teach LLMs to interpret multimodal misinformation in cost-effective and\naccessible way is still an open question. To address that, we propose MMIDR, a\nframework designed to teach LLMs in providing fluent and high-quality textual\nexplanations for their decision-making process of multimodal misinformation. To\nconvert multimodal misinformation into an appropriate instruction-following\nformat, we present a data augmentation perspective and pipeline. This pipeline\nconsists of a visual information processing module and an evidence retrieval\nmodule. Subsequently, we prompt the proprietary LLMs with processed contents to\nextract rationales for interpreting the authenticity of multimodal\nmisinformation. Furthermore, we design an efficient knowledge distillation\napproach to distill the capability of proprietary LLMs in explaining multimodal\nmisinformation into open-source LLMs. To explore several research questions\nregarding the performance of LLMs in multimodal misinformation detection tasks,\nwe construct an instruction-following multimodal misinformation dataset and\nconduct comprehensive experiments. The experimental findings reveal that our\nMMIDR exhibits sufficient detection performance and possesses the capacity to\nprovide compelling rationales to support its assessments.", "published": "2024-03-21 06:47:28", "link": "http://arxiv.org/abs/2403.14171v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context Quality Matters in Training Fusion-in-Decoder for Extractive\n  Open-Domain Question Answering", "abstract": "Retrieval-augmented generation models augment knowledge encoded in a language\nmodel by providing additional relevant external knowledge (context) during\ngeneration. Although it has been shown that the quantity and quality of context\nimpact the performance of retrieval-augmented generation models during\ninference, limited research explores how these characteristics affect model\ntraining. This paper explores how context quantity and quality during model\ntraining affect the performance of Fusion-in-Decoder (FiD), the\nstate-of-the-art retrieval-augmented generation model, in extractive\nopen-domain question answering tasks. Experimental results suggest that FiD\nmodels overfit to context quality during training and show suboptimal\nperformance when evaluated on different context quality. Through the\nexperimental results, we also reveal FiD models trained with different context\nquality have different cross-attention distribution patterns. Specifically, as\ncontext quality during training increases, FiD models tend to attend more\nuniformly to each passage in context. Finally, based on these observations, we\npropose a method to mitigate overfitting to specific context quality by\nintroducing bias to the cross-attention distribution, which we demonstrate to\nbe effective in improving the performance of FiD models on different context\nquality.", "published": "2024-03-21 07:47:57", "link": "http://arxiv.org/abs/2403.14197v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Annotation of Grammaticality in Child-Caregiver Conversations", "abstract": "The acquisition of grammar has been a central question to adjudicate between\ntheories of language acquisition. In order to conduct faster, more\nreproducible, and larger-scale corpus studies on grammaticality in\nchild-caregiver conversations, tools for automatic annotation can offer an\neffective alternative to tedious manual annotation. We propose a coding scheme\nfor context-dependent grammaticality in child-caregiver conversations and\nannotate more than 4,000 utterances from a large corpus of transcribed\nconversations. Based on these annotations, we train and evaluate a range of NLP\nmodels. Our results show that fine-tuned Transformer-based models perform best,\nachieving human inter-annotation agreement levels.As a first application and\nsanity check of this tool, we use the trained models to annotate a corpus\nalmost two orders of magnitude larger than the manually annotated data and\nverify that children's grammaticality shows a steady increase with age.This\nwork contributes to the growing literature on applying state-of-the-art NLP\nmethods to help study child language acquisition at scale.", "published": "2024-03-21 08:00:05", "link": "http://arxiv.org/abs/2403.14208v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving the Robustness of Large Language Models via Consistency\n  Alignment", "abstract": "Large language models (LLMs) have shown tremendous success in following user\ninstructions and generating helpful responses. Nevertheless, their robustness\nis still far from optimal, as they may generate significantly inconsistent\nresponses due to minor changes in the verbalized instructions. Recent\nliterature has explored this inconsistency issue, highlighting the importance\nof continued improvement in the robustness of response generation. However,\nsystematic analysis and solutions are still lacking. In this paper, we\nquantitatively define the inconsistency problem and propose a two-stage\ntraining framework consisting of instruction-augmented supervised fine-tuning\nand consistency alignment training. The first stage helps a model generalize on\nfollowing instructions via similar instruction augmentations. In the second\nstage, we improve the diversity and help the model understand which responses\nare more aligned with human expectations by differentiating subtle differences\nin similar responses. The training process is accomplished by self-rewards\ninferred from the trained model at the first stage without referring to\nexternal human preference resources. We conduct extensive experiments on recent\npublicly available LLMs on instruction-following tasks and demonstrate the\neffectiveness of our training framework.", "published": "2024-03-21 08:21:12", "link": "http://arxiv.org/abs/2403.14221v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large-Scale Label Interpretation Learning for Few-Shot Named Entity\n  Recognition", "abstract": "Few-shot named entity recognition (NER) detects named entities within text\nusing only a few annotated examples. One promising line of research is to\nleverage natural language descriptions of each entity type: the common label\nPER might, for example, be verbalized as ''person entity.'' In an initial label\ninterpretation learning phase, the model learns to interpret such verbalized\ndescriptions of entity types. In a subsequent few-shot tagset extension phase,\nthis model is then given a description of a previously unseen entity type (such\nas ''music album'') and optionally a few training examples to perform few-shot\nNER for this type. In this paper, we systematically explore the impact of a\nstrong semantic prior to interpret verbalizations of new entity types by\nmassively scaling up the number and granularity of entity types used for label\ninterpretation learning. To this end, we leverage an entity linking benchmark\nto create a dataset with orders of magnitude of more distinct entity types and\ndescriptions as currently used datasets. We find that this increased signal\nyields strong results in zero- and few-shot NER in in-domain, cross-domain, and\neven cross-lingual settings. Our findings indicate significant potential for\nimproving few-shot NER through heuristical data-based optimization.", "published": "2024-03-21 08:22:44", "link": "http://arxiv.org/abs/2403.14222v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "K-Act2Emo: Korean Commonsense Knowledge Graph for Indirect Emotional\n  Expression", "abstract": "In many literary texts, emotions are indirectly conveyed through descriptions\nof actions, facial expressions, and appearances, necessitating emotion\ninference for narrative understanding. In this paper, we introduce K-Act2Emo, a\nKorean commonsense knowledge graph (CSKG) comprising 1,900 indirect emotional\nexpressions and the emotions inferable from them. We categorize reasoning types\ninto inferences in positive situations, inferences in negative situations, and\ninferences when expressions do not serve as emotional cues. Unlike existing\nCSKGs, K-Act2Emo specializes in emotional contexts, and experimental results\nvalidate its effectiveness for training emotion inference models.\nSignificantly, the BART-based knowledge model fine-tuned with K-Act2Emo\noutperforms various existing Korean large language models, achieving\nperformance levels comparable to GPT-4 Turbo.", "published": "2024-03-21 09:26:04", "link": "http://arxiv.org/abs/2403.14253v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-based Extraction of Contradictions from Patents", "abstract": "Already since the 1950s TRIZ shows that patents and the technical\ncontradictions they solve are an important source of inspiration for the\ndevelopment of innovative products. However, TRIZ is a heuristic based on a\nhistoric patent analysis and does not make use of the ever-increasing number of\nlatest technological solutions in current patents. Because of the huge number\nof patents, their length, and, last but not least, their complexity there is a\nneed for modern patent retrieval and patent analysis to go beyond\nkeyword-oriented methods. Recent advances in patent retrieval and analysis\nmainly focus on dense vectors based on neural AI Transformer language models\nlike Google BERT. They are, for example, used for dense retrieval, question\nanswering or summarization and key concept extraction. A research focus within\nthe methods for patent summarization and key concept extraction are generic\ninventive concepts respectively TRIZ concepts like problems, solutions,\nadvantage of invention, parameters, and contradictions. Succeeding rule-based\napproaches, finetuned BERT-like language models for sentence-wise\nclassification represent the state-of-the-art of inventive concept extraction.\nWhile they work comparatively well for basic concepts like problems or\nsolutions, contradictions - as a more complex abstraction - remain a challenge\nfor these models. This paper goes one step further, as it presents a method to\nextract TRIZ contradictions from patent texts based on Prompt Engineering using\na generative Large Language Model (LLM), namely OpenAI's GPT-4. Contradiction\ndetection, sentence extraction, contradiction summarization, parameter\nextraction and assignment to the 39 abstract TRIZ engineering parameters are\nall performed in a single prompt using the LangChain framework. Our results\nshow that \"off-the-shelf\" GPT-4 is a serious alternative to existing\napproaches.", "published": "2024-03-21 09:36:36", "link": "http://arxiv.org/abs/2403.14258v1", "categories": ["cs.CL", "I.2.7; H.3.1"], "primary_category": "cs.CL"}
{"title": "Is Reference Necessary in the Evaluation of NLG Systems? When and Where?", "abstract": "The majority of automatic metrics for evaluating NLG systems are\nreference-based. However, the challenge of collecting human annotation results\nin a lack of reliable references in numerous application scenarios. Despite\nrecent advancements in reference-free metrics, it has not been well understood\nwhen and where they can be used as an alternative to reference-based metrics.\nIn this study, by employing diverse analytical approaches, we comprehensively\nassess the performance of both metrics across a wide range of NLG tasks,\nencompassing eight datasets and eight evaluation models. Based on solid\nexperiments, the results show that reference-free metrics exhibit a higher\ncorrelation with human judgment and greater sensitivity to deficiencies in\nlanguage quality. However, their effectiveness varies across tasks and is\ninfluenced by the quality of candidate texts. Therefore, it's important to\nassess the performance of reference-free metrics before applying them to a new\ntask, especially when inputs are in uncommon form or when the answer space is\nhighly variable. Our study can provide insight into the appropriate application\nof automatic metrics and the impact of metric choice on evaluation performance.", "published": "2024-03-21 10:31:11", "link": "http://arxiv.org/abs/2403.14275v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChainLM: Empowering Large Language Models with Improved Chain-of-Thought\n  Prompting", "abstract": "Chain-of-Thought (CoT) prompting can enhance the reasoning capabilities of\nlarge language models (LLMs), establishing itself as a primary approach to\nsolving complex reasoning tasks. Existing CoT synthesis approaches usually\nfocus on simpler reasoning tasks and thus result in low-quality and\ninconsistent CoT prompts. In response to this challenge, we present an\nempirical investigation of CoT prompting and introduce CoTGenius, a novel\nframework designed for the automatic generation of superior CoT prompts.\nCoTGenius is developed based on three major evolution strategies, i.e.,\ncomplicate, diversify, and specify-alongside two filtering mechanisms:\nevolutionary success judgement and correctness verification. We further employ\nCoTGenius to create an extensive CoT dataset, and subsequently fine-tune the\nLlama 2-Chat 7B and 13B models on this dataset. We call the resulting model\nChainLM. To deal with the cumulative error issue in reasoning steps, we propose\na step-level debating method, wherein multiple debaters discuss each reasoning\nstep to arrive at the correct answer. Extensive experiments demonstrate that\nour ChainLM models exhibit enhanced proficiency in addressing a spectrum of\ncomplex reasoning problems compared to existing models. In addition, we conduct\nan in-depth analysis of the impact of data categories within CoTGenius on the\nmodel performance. We release our dataset and code at\nhttps://github.com/RUCAIBox/ChainLM.", "published": "2024-03-21 11:34:26", "link": "http://arxiv.org/abs/2403.14312v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Surface Similarity: Detecting Subtle Semantic Shifts in Financial\n  Narratives", "abstract": "In this paper, we introduce the Financial-STS task, a financial\ndomain-specific NLP task designed to measure the nuanced semantic similarity\nbetween pairs of financial narratives. These narratives originate from the\nfinancial statements of the same company but correspond to different periods,\nsuch as year-over-year comparisons. Measuring the subtle semantic differences\nbetween these paired narratives enables market stakeholders to gauge changes\nover time in the company's financial and operational situations, which is\ncritical for financial decision-making. We find that existing pretrained\nembedding models and LLM embeddings fall short in discerning these subtle\nfinancial narrative shifts. To address this gap, we propose an LLM-augmented\npipeline specifically designed for the Financial-STS task. Evaluation on a\nhuman-annotated dataset demonstrates that our proposed method outperforms\nexisting methods trained on classic STS tasks and generic LLM embeddings.", "published": "2024-03-21 12:17:59", "link": "http://arxiv.org/abs/2403.14341v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WikiFactDiff: A Large, Realistic, and Temporally Adaptable Dataset for\n  Atomic Factual Knowledge Update in Causal Language Models", "abstract": "The factuality of large language model (LLMs) tends to decay over time since\nevents posterior to their training are \"unknown\" to them. One way to keep\nmodels up-to-date could be factual update: the task of inserting, replacing, or\nremoving certain simple (atomic) facts within the model. To study this task, we\npresent WikiFactDiff, a dataset that describes the evolution of factual\nknowledge between two dates as a collection of simple facts divided into three\ncategories: new, obsolete, and static. We describe several update scenarios\narising from various combinations of these three types of basic update. The\nfacts are represented by subject-relation-object triples; indeed, WikiFactDiff\nwas constructed by comparing the state of the Wikidata knowledge base at 4\nJanuary 2021 and 27 February 2023. Those fact are accompanied by verbalization\ntemplates and cloze tests that enable running update algorithms and their\nevaluation metrics. Contrary to other datasets, such as zsRE and CounterFact,\nWikiFactDiff constitutes a realistic update setting that involves various\nupdate scenarios, including replacements, archival, and new entity insertions.\nWe also present an evaluation of existing update algorithms on WikiFactDiff.", "published": "2024-03-21 12:45:12", "link": "http://arxiv.org/abs/2403.14364v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Large to Tiny: Distilling and Refining Mathematical Expertise for\n  Math Word Problems with Weakly Supervision", "abstract": "Addressing the challenge of high annotation costs in solving Math Word\nProblems (MWPs) through full supervision with intermediate equations, recent\nworks have proposed weakly supervised task settings that rely solely on the\nfinal answer as a supervised signal. Existing leading approaches typically\nemploy various search techniques to infer intermediate equations, but cannot\nensure their semantic consistency with natural language descriptions. The rise\nof Large Language Models (LLMs) like ChatGPT has opened up new possibilities\nfor addressing MWPs directly. However, the computational demands of LLMs make\nthem less than ideal for use in settings where resources are tight. In light of\nthese challenges, we introduce an innovative two-stage framework that adeptly\ntransfers mathematical Expertise from large to tiny language models. In\n\\emph{Distillation Stage}, we propose a series of extraction processes that\nsatisfy the properties of MWPs to distill mathematical knowledge from LLMs to\nconstruct problem-equation pairs required for supervised training. In\n\\emph{Refinement Stage}, Due to Knowledge distilling method cannot guarantee\nthe full utilization of all data, we further utilize the unsuccessfully\nsearched data effectively by Knowledge Refine method. Finally, We train a small\nmodel using distilled data generated through two-stage methods. As our method\nfully leverages the semantic understanding capabilities during the searching\n'problem-equation' pair, it demonstrates significantly improved performance on\nthe Math23K and Weak12K datasets compared to existing small model methods,\nwhile maintaining a much lower computational cost than ChatGPT.", "published": "2024-03-21 13:29:54", "link": "http://arxiv.org/abs/2403.14390v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning and communication pressures in neural networks: Lessons from\n  emergent communication", "abstract": "Finding and facilitating commonalities between the linguistic behaviors of\nlarge language models and humans could lead to major breakthroughs in our\nunderstanding of the acquisition, processing, and evolution of language.\nHowever, most findings on human-LLM similarity can be attributed to training on\nhuman data. The field of emergent machine-to-machine communication provides an\nideal testbed for discovering which pressures are neural agents naturally\nexposed to when learning to communicate in isolation, without any human\nlanguage to start with. Here, we review three cases where mismatches between\nthe emergent linguistic behavior of neural agents and humans were resolved\nthanks to introducing theoretically-motivated inductive biases. By contrasting\nhumans, large language models, and emergent communication agents, we then\nidentify key pressures at play for language learning and emergence:\ncommunicative success, production effort, learnability, and other\npsycho-/sociolinguistic factors. We discuss their implications and relevance to\nthe field of language evolution and acquisition. By mapping out the necessary\ninductive biases that make agents' emergent languages more human-like, we not\nonly shed light on the underlying principles of human cognition and\ncommunication, but also inform and improve the very use of these models as\nvaluable scientific tools for studying language learning, processing, use, and\nrepresentation more broadly.", "published": "2024-03-21 14:33:34", "link": "http://arxiv.org/abs/2403.14427v3", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "More than Just Statistical Recurrence: Human and Machine Unsupervised\n  Learning of M\u0101ori Word Segmentation across Morphological Processes", "abstract": "Non-M\\=aori-speaking New Zealanders (NMS)are able to segment M\\=aori words in\na highlysimilar way to fluent speakers (Panther et al.,2024). This ability is\nassumed to derive through the identification and extraction of statistically\nrecurrent forms. We examine this assumption by asking how NMS segmentations\ncompare to those produced by Morfessor, an unsupervised machine learning model\nthat operates based on statistical recurrence, across words formed by a variety\nof morphological processes. Both NMS and Morfessor succeed in segmenting words\nformed by concatenative processes (compounding and affixation without\nallomorphy), but NMS also succeed for words that invoke templates\n(reduplication and allomorphy) and other cues to morphological structure,\nimplying that their learning process is sensitive to more than just statistical\nrecurrence.", "published": "2024-03-21 14:51:51", "link": "http://arxiv.org/abs/2403.14444v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prediction of Translation Techniques for the Translation Process", "abstract": "Machine translation (MT) encompasses a variety of methodologies aimed at\nenhancing the accuracy of translations. In contrast, the process of\nhuman-generated translation relies on a wide range of translation techniques,\nwhich are crucial for ensuring linguistic adequacy and fluency. This study\nsuggests that these translation techniques could further optimize machine\ntranslation if they are automatically identified before being applied to guide\nthe translation process effectively. The study differentiates between two\nscenarios of the translation process: from-scratch translation and\npost-editing. For each scenario, a specific set of experiments has been\ndesigned to forecast the most appropriate translation techniques. The findings\nindicate that the predictive accuracy for from-scratch translation reaches 82%,\nwhile the post-editing process exhibits even greater potential, achieving an\naccuracy rate of 93%.", "published": "2024-03-21 15:02:03", "link": "http://arxiv.org/abs/2403.14454v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Building a Language-Learning Game for Brazilian Indigenous Languages: A\n  Case of Study", "abstract": "In this paper we discuss a first attempt to build a language learning game\nfor brazilian indigenous languages and the challenges around it. We present a\ndesign for the tool with gamification aspects. Then we describe a process to\nautomatically generate language exercises and questions from a dependency\ntreebank and a lexical database for Tupian languages. We discuss the\nlimitations of our prototype highlighting ethical and practical implementation\nconcerns. Finally, we conclude that new data gathering processes should be\nestablished in partnership with indigenous communities and oriented for\neducational purposes.", "published": "2024-03-21 16:11:44", "link": "http://arxiv.org/abs/2403.14515v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EDT: Improving Large Language Models' Generation by Entropy-based\n  Dynamic Temperature Sampling", "abstract": "Recently, Large Language Models (LLMs) have demonstrated outstanding\nperformance across a wide range of downstream language tasks. Temperature\nsampling is a commonly used decoding strategy for LLMs' generation process.\nHowever, a fixed temperature parameter is used in most cases, which may not\nalways be an optimal choice for balancing generation quality and diversity. In\nthis paper, we propose an effective Entropy-based Dynamic Temperature (EDT)\nSampling method, to achieve a more balanced performance in terms of both\ngeneration quality and diversity by dynamically selecting the temperature\nparameter. Additionally, we also show model performance and comprehensive\nanalyses for 4 different generation benchmarks. Our experiments show that EDT\nsignificantly outperforms the existing strategies across different tasks.", "published": "2024-03-21 16:41:12", "link": "http://arxiv.org/abs/2403.14541v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students'\n  Formative Assessment Responses in Science", "abstract": "This paper explores the use of large language models (LLMs) to score and\nexplain short-answer assessments in K-12 science. While existing methods can\nscore more structured math and computer science assessments, they often do not\nprovide explanations for the scores. Our study focuses on employing GPT-4 for\nautomated assessment in middle school Earth Science, combining few-shot and\nactive learning with chain-of-thought reasoning. Using a human-in-the-loop\napproach, we successfully score and provide meaningful explanations for\nformative assessment responses. A systematic analysis of our method's pros and\ncons sheds light on the potential for human-in-the-loop techniques to enhance\nautomated grading for open-ended science assessments.", "published": "2024-03-21 17:09:08", "link": "http://arxiv.org/abs/2403.14565v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Collection of Pragmatic-Similarity Judgments over Spoken Dialog\n  Utterances", "abstract": "Automatic measures of similarity between utterances are invaluable for\ntraining speech synthesizers, evaluating machine translation, and assessing\nlearner productions. While there exist measures for semantic similarity and\nprosodic similarity, there are as yet none for pragmatic similarity. To enable\nthe training of such measures, we developed the first collection of human\njudgments of pragmatic similarity between utterance pairs. Each pair consisting\nof an utterance extracted from a recorded dialog and a re-enactment of that\nutterance. Re-enactments were done under various conditions designed to create\na variety of degrees of similarity. Each pair was rated on a continuous scale\nby 6 to 9 judges. The average inter-judge correlation was as high as 0.72 for\nEnglish and 0.66 for Spanish. We make this data available at\nhttps://github.com/divettemarco/PragSim .", "published": "2024-03-21 19:46:42", "link": "http://arxiv.org/abs/2403.14808v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TAMS: Translation-Assisted Morphological Segmentation", "abstract": "Canonical morphological segmentation is the process of analyzing words into\nthe standard (aka underlying) forms of their constituent morphemes. This is a\ncore task in language documentation, and NLP systems have the potential to\ndramatically speed up this process. But in typical language documentation\nsettings, training data for canonical morpheme segmentation is scarce, making\nit difficult to train high quality models. However, translation data is often\nmuch more abundant, and, in this work, we present a method that attempts to\nleverage this data in the canonical segmentation task. We propose a\ncharacter-level sequence-to-sequence model that incorporates representations of\ntranslations obtained from pretrained high-resource monolingual language models\nas an additional signal. Our model outperforms the baseline in a super-low\nresource setting but yields mixed results on training splits with more data.\nWhile further work is needed to make translations useful in higher-resource\nsettings, our model shows promise in severely resource-constrained settings.", "published": "2024-03-21 21:23:35", "link": "http://arxiv.org/abs/2403.14840v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open Conversational LLMs do not know most Spanish words", "abstract": "The growing interest in Large Language Models (LLMs) and in particular in\nconversational models with which users can interact has led to the development\nof a large number of open-source chat LLMs. These models are evaluated on a\nwide range of benchmarks to assess their capabilities in answering questions or\nsolving problems on almost any possible topic or to test their ability to\nreason or interpret texts. Instead, the evaluation of the knowledge that these\nmodels have of the languages has received much less attention. For example, the\nwords that they can recognize and use in different languages. In this paper, we\nevaluate the knowledge that open-source chat LLMs have of Spanish words by\ntesting a sample of words in a reference dictionary. The results show that\nopen-source chat LLMs produce incorrect meanings for an important fraction of\nthe words and are not able to use most of the words correctly to write\nsentences with context. These results show how Spanish is left behind in the\nopen-source LLM race and highlight the need to push for linguistic fairness in\nconversational LLMs ensuring that they provide similar performance across\nlanguages.", "published": "2024-03-21 15:41:02", "link": "http://arxiv.org/abs/2403.15491v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visual Analytics for Fine-grained Text Classification Models and\n  Datasets", "abstract": "In natural language processing (NLP), text classification tasks are\nincreasingly fine-grained, as datasets are fragmented into a larger number of\nclasses that are more difficult to differentiate from one another. As a\nconsequence, the semantic structures of datasets have become more complex, and\nmodel decisions more difficult to explain. Existing tools, suited for\ncoarse-grained classification, falter under these additional challenges. In\nresponse to this gap, we worked closely with NLP domain experts in an iterative\ndesign-and-evaluation process to characterize and tackle the growing\nrequirements in their workflow of developing fine-grained text classification\nmodels. The result of this collaboration is the development of SemLa, a novel\nvisual analytics system tailored for 1) dissecting complex semantic structures\nin a dataset when it is spatialized in model embedding space, and 2)\nvisualizing fine-grained nuances in the meaning of text samples to faithfully\nexplain model reasoning. This paper details the iterative design study and the\nresulting innovations featured in SemLa. The final design allows contrastive\nanalysis at different levels by unearthing lexical and conceptual patterns\nincluding biases and artifacts in data. Expert feedback on our final design and\ncase studies confirm that SemLa is a useful tool for supporting model\nvalidation and debugging as well as data annotation.", "published": "2024-03-21 17:26:28", "link": "http://arxiv.org/abs/2403.15492v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Design Space for Intelligent and Interactive Writing Assistants", "abstract": "In our era of rapid technological advancement, the research landscape for\nwriting assistants has become increasingly fragmented across various research\ncommunities. We seek to address this challenge by proposing a design space as a\nstructured way to examine and explore the multidimensional space of intelligent\nand interactive writing assistants. Through a large community collaboration, we\nexplore five aspects of writing assistants: task, user, technology,\ninteraction, and ecosystem. Within each aspect, we define dimensions (i.e.,\nfundamental components of an aspect) and codes (i.e., potential options for\neach dimension) by systematically reviewing 115 papers. Our design space aims\nto offer researchers and designers a practical tool to navigate, comprehend,\nand compare the various possibilities of writing assistants, and aid in the\nenvisioning and design of new writing assistants.", "published": "2024-03-21 04:03:16", "link": "http://arxiv.org/abs/2403.14117v2", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Reinforcement Learning from Reflective Feedback (RLRF): Aligning and\n  Improving LLMs via Fine-Grained Self-Reflection", "abstract": "Despite the promise of RLHF in aligning LLMs with human preferences, it often\nleads to superficial alignment, prioritizing stylistic changes over improving\ndownstream performance of LLMs. Underspecified preferences could obscure\ndirections to align the models. Lacking exploration restricts identification of\ndesirable outputs to improve the models. To overcome these challenges, we\npropose a novel framework: Reinforcement Learning from Reflective Feedback\n(RLRF), which leverages fine-grained feedback based on detailed criteria to\nimprove the core capabilities of LLMs. RLRF employs a self-reflection mechanism\nto systematically explore and refine LLM responses, then fine-tuning the models\nvia a RL algorithm along with promising responses. Our experiments across\nJust-Eval, Factuality, and Mathematical Reasoning demonstrate the efficacy and\ntransformative potential of RLRF beyond superficial surface-level adjustment.", "published": "2024-03-21 08:57:27", "link": "http://arxiv.org/abs/2403.14238v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ERD: A Framework for Improving LLM Reasoning for Cognitive Distortion\n  Classification", "abstract": "Improving the accessibility of psychotherapy with the aid of Large Language\nModels (LLMs) is garnering a significant attention in recent years. Recognizing\ncognitive distortions from the interviewee's utterances can be an essential\npart of psychotherapy, especially for cognitive behavioral therapy. In this\npaper, we propose ERD, which improves LLM-based cognitive distortion\nclassification performance with the aid of additional modules of (1) extracting\nthe parts related to cognitive distortion, and (2) debating the reasoning steps\nby multiple agents. Our experimental results on a public dataset show that ERD\nimproves the multi-class F1 score as well as binary specificity score.\nRegarding the latter score, it turns out that our method is effective in\ndebiasing the baseline method which has high false positive rate, especially\nwhen the summary of multi-agent debate is provided to LLMs.", "published": "2024-03-21 09:28:38", "link": "http://arxiv.org/abs/2403.14255v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FIT-RAG: Black-Box RAG with Factual Information and Token Reduction", "abstract": "Due to the extraordinarily large number of parameters, fine-tuning Large\nLanguage Models (LLMs) to update long-tail or out-of-date knowledge is\nimpractical in lots of applications. To avoid fine-tuning, we can alternatively\ntreat a LLM as a black-box (i.e., freeze the parameters of the LLM) and augment\nit with a Retrieval-Augmented Generation (RAG) system, namely black-box RAG.\nRecently, black-box RAG has achieved success in knowledge-intensive tasks and\nhas gained much attention. Existing black-box RAG methods typically fine-tune\nthe retriever to cater to LLMs' preferences and concatenate all the retrieved\ndocuments as the input, which suffers from two issues: (1) Ignorance of Factual\nInformation. The LLM preferred documents may not contain the factual\ninformation for the given question, which can mislead the retriever and hurt\nthe effectiveness of black-box RAG; (2) Waste of Tokens. Simply concatenating\nall the retrieved documents brings large amounts of unnecessary tokens for\nLLMs, which degenerates the efficiency of black-box RAG. To address these\nissues, this paper proposes a novel black-box RAG framework which utilizes the\nfactual information in the retrieval and reduces the number of tokens for\naugmentation, dubbed FIT-RAG. FIT-RAG utilizes the factual information by\nconstructing a bi-label document scorer. Besides, it reduces the tokens by\nintroducing a self-knowledge recognizer and a sub-document-level token reducer.\nFIT-RAG achieves both superior effectiveness and efficiency, which is validated\nby extensive experiments across three open-domain question-answering datasets:\nTriviaQA, NQ and PopQA. FIT-RAG can improve the answering accuracy of\nLlama2-13B-Chat by 14.3\\% on TriviaQA, 19.9\\% on NQ and 27.5\\% on PopQA,\nrespectively. Furthermore, it can save approximately half of the tokens on\naverage across the three datasets.", "published": "2024-03-21 13:05:18", "link": "http://arxiv.org/abs/2403.14374v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Editing Knowledge Representation of Language Model via Rephrased Prefix\n  Prompts", "abstract": "Neural language models (LMs) have been extensively trained on vast corpora to\nstore factual knowledge about various aspects of the world described in texts.\nCurrent technologies typically employ knowledge editing methods or specific\nprompts to modify LM outputs. However, existing knowledge editing methods are\ncostly and inefficient, struggling to produce appropriate text. Additionally,\nprompt engineering is opaque and requires significant effort to find suitable\nprompts. To address these issues, we introduce a new method called PSPEM\n(Prefix Soft Prompt Editing Method), that can be used for a lifetime with just\none training. It resolves the inefficiencies and generalizability issues in\nknowledge editing methods and overcomes the opacity of prompt engineering by\nautomatically seeking optimal soft prompts. Specifically, PSPEM utilizes a\nprompt encoder and an encoding converter to refine key information in prompts\nand uses prompt alignment techniques to guide model generation, ensuring text\nconsistency and adherence to the intended structure and content, thereby\nmaintaining an optimal balance between efficiency and accuracy. We have\nvalidated the effectiveness of PSPEM through knowledge editing and attribute\ninserting. On the COUNTERFACT dataset, PSPEM achieved nearly 100\\% editing\naccuracy and demonstrated the highest level of fluency. We further analyzed the\nsimilarities between PSPEM and original prompts and their impact on the model's\ninternals. The results indicate that PSPEM can serve as an alternative to\noriginal prompts, supporting the model in effective editing.", "published": "2024-03-21 13:15:25", "link": "http://arxiv.org/abs/2403.14381v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Building Accurate Translation-Tailored LLMs with Language Aware\n  Instruction Tuning", "abstract": "Translation-tailored Large language models (LLMs) exhibit remarkable\ntranslation capabilities, even competing with supervised-trained commercial\ntranslation systems. However, off-target translation remains an unsolved\nproblem, especially for low-resource languages, hindering us from developing\naccurate LLMs-based translation models. To mitigate the off-target translation\nproblem and enhance the performance of LLMs on translation, recent works have\neither designed advanced prompting strategies to highlight the functionality of\ntranslation instructions or exploited the in-context learning ability of LLMs\nby feeding few-shot demonstrations. However, these methods essentially do not\nimprove LLM's ability to follow translation instructions, especially the\nlanguage direction information. In this work, we design a two-stage fine-tuning\nalgorithm to improve the instruction-following ability (especially the\ntranslation direction) of LLMs. Specifically, we first tune LLMs with the\nmaximum likelihood estimation loss on the translation dataset to elicit the\nbasic translation capabilities. In the second stage, we construct\ninstruction-conflicting samples by randomly replacing the translation\ndirections with a wrong one within the instruction, and then introduce an extra\nunlikelihood loss to learn those samples. Experiments on IWSLT and WMT\nbenchmarks upon the LLaMA model spanning 16 zero-shot directions show that,\ncompared to the competitive baseline -- translation-finetuned LLama, our method\ncould effectively reduce the off-target translation ratio (averagely -53.3\\%),\nthus improving translation quality with average +5.7 SacreBLEU and +16.4\nBLEURT. Analysis shows that our method could preserve the model's general task\nperformance on AlpacaEval. Code and models will be released at\n\\url{https://github.com/alphadl/LanguageAware_Tuning}.", "published": "2024-03-21 13:47:40", "link": "http://arxiv.org/abs/2403.14399v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language\n  Models through Question Complexity", "abstract": "Retrieval-Augmented Large Language Models (LLMs), which incorporate the\nnon-parametric knowledge from external knowledge bases into LLMs, have emerged\nas a promising approach to enhancing response accuracy in several tasks, such\nas Question-Answering (QA). However, even though there are various approaches\ndealing with queries of different complexities, they either handle simple\nqueries with unnecessary computational overhead or fail to adequately address\ncomplex multi-step queries; yet, not all user requests fall into only one of\nthe simple or complex categories. In this work, we propose a novel adaptive QA\nframework, that can dynamically select the most suitable strategy for\n(retrieval-augmented) LLMs from the simplest to the most sophisticated ones\nbased on the query complexity. Also, this selection process is operationalized\nwith a classifier, which is a smaller LM trained to predict the complexity\nlevel of incoming queries with automatically collected labels, obtained from\nactual predicted outcomes of models and inherent inductive biases in datasets.\nThis approach offers a balanced strategy, seamlessly adapting between the\niterative and single-step retrieval-augmented LLMs, as well as the no-retrieval\nmethods, in response to a range of query complexities. We validate our model on\na set of open-domain QA datasets, covering multiple query complexities, and\nshow that ours enhances the overall efficiency and accuracy of QA systems,\ncompared to relevant baselines including the adaptive retrieval approaches.\nCode is available at: https://github.com/starsuzi/Adaptive-RAG.", "published": "2024-03-21 13:52:30", "link": "http://arxiv.org/abs/2403.14403v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Locating and Mitigating Gender Bias in Large Language Models", "abstract": "Large language models(LLM) are pre-trained on extensive corpora to learn\nfacts and human cognition which contain human preferences. However, this\nprocess can inadvertently lead to these models acquiring biases and stereotypes\nprevalent in society. Prior research has typically tackled the issue of bias\nthrough a one-dimensional perspective, concentrating either on locating or\nmitigating it. This limited perspective has created obstacles in facilitating\nresearch on bias to synergistically complement and progressively build upon one\nanother. In this study, we integrate the processes of locating and mitigating\nbias within a unified framework. Initially, we use causal mediation analysis to\ntrace the causal effects of different components' activation within a large\nlanguage model. Building on this, we propose the LSDM (Least Square Debias\nMethod), a knowledge-editing based method for mitigating gender bias in\noccupational pronouns, and compare it against two baselines on three gender\nbias datasets and seven knowledge competency test datasets. The experimental\nresults indicate that the primary contributors to gender bias are the bottom\nMLP modules acting on the last token of occupational pronouns and the top\nattention module acting on the final word in the sentence. Furthermore, LSDM\nmitigates gender bias in the model more effectively than the other baselines,\nwhile fully preserving the model's capabilities in all other aspects.", "published": "2024-03-21 13:57:43", "link": "http://arxiv.org/abs/2403.14409v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Level Explanations for Generative Language Models", "abstract": "Perturbation-based explanation methods such as LIME and SHAP are commonly\napplied to text classification. This work focuses on their extension to\ngenerative language models. To address the challenges of text as output and\nlong text inputs, we propose a general framework called MExGen that can be\ninstantiated with different attribution algorithms. To handle text output, we\nintroduce the notion of scalarizers for mapping text to real numbers and\ninvestigate multiple possibilities. To handle long inputs, we take a\nmulti-level approach, proceeding from coarser levels of granularity to finer\nones, and focus on algorithms with linear scaling in model queries. We conduct\na systematic evaluation, both automated and human, of perturbation-based\nattribution methods for summarization and context-grounded question answering.\nThe results show that our framework can provide more locally faithful\nexplanations of generated outputs.", "published": "2024-03-21 15:06:14", "link": "http://arxiv.org/abs/2403.14459v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ChatGPT Alternative Solutions: Large Language Models Survey", "abstract": "In recent times, the grandeur of Large Language Models (LLMs) has not only\nshone in the realm of natural language processing but has also cast its\nbrilliance across a vast array of applications. This remarkable display of LLM\ncapabilities has ignited a surge in research contributions within this domain,\nspanning a diverse spectrum of topics. These contributions encompass\nadvancements in neural network architecture, context length enhancements, model\nalignment, training datasets, benchmarking, efficiency improvements, and more.\nRecent years have witnessed a dynamic synergy between academia and industry,\npropelling the field of LLM research to new heights. A notable milestone in\nthis journey is the introduction of ChatGPT, a powerful AI chatbot grounded in\nLLMs, which has garnered widespread societal attention. The evolving technology\nof LLMs has begun to reshape the landscape of the entire AI community,\npromising a revolutionary shift in the way we create and employ AI algorithms.\nGiven this swift-paced technical evolution, our survey embarks on a journey to\nencapsulate the recent strides made in the world of LLMs. Through an\nexploration of the background, key discoveries, and prevailing methodologies,\nwe offer an up-to-the-minute review of the literature. By examining multiple\nLLM models, our paper not only presents a comprehensive overview but also\ncharts a course that identifies existing challenges and points toward potential\nfuture research trajectories. This survey furnishes a well-rounded perspective\non the current state of generative AI, shedding light on opportunities for\nfurther exploration, enhancement, and innovation.", "published": "2024-03-21 15:16:50", "link": "http://arxiv.org/abs/2403.14469v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Multi-Choice Question Classification of\n  Medical Subjects", "abstract": "The aim of this paper is to evaluate whether large language models trained on\nmulti-choice question data can be used to discriminate between medical\nsubjects. This is an important and challenging task for automatic question\nanswering. To achieve this goal, we train deep neural networks for multi-class\nclassification of questions into the inferred medical subjects. Using our\nMulti-Question (MQ) Sequence-BERT method, we outperform the state-of-the-art\nresults on the MedMCQA dataset with an accuracy of 0.68 and 0.60 on their\ndevelopment and test sets, respectively. In this sense, we show the capability\nof AI and LLMs in particular for multi-classification tasks in the Healthcare\ndomain.", "published": "2024-03-21 17:36:08", "link": "http://arxiv.org/abs/2403.14582v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Log Probabilities Are a Reliable Estimate of Semantic Plausibility in\n  Base and Instruction-Tuned Language Models", "abstract": "Semantic plausibility (e.g. knowing that \"the actor won the award\" is more\nlikely than \"the actor won the battle\") serves as an effective proxy for\ngeneral world knowledge. Language models (LMs) capture vast amounts of world\nknowledge by learning distributional patterns in text, accessible via log\nprobabilities (LogProbs) they assign to plausible vs. implausible outputs. The\nnew generation of instruction-tuned LMs can now also provide explicit estimates\nof plausibility via prompting. Here, we evaluate the effectiveness of LogProbs\nand basic prompting to measure semantic plausibility, both in single-sentence\nminimal pairs (Experiment 1) and short context-dependent scenarios (Experiment\n2). We find that (i) in both base and instruction-tuned LMs, LogProbs offers a\nmore reliable measure of semantic plausibility than direct zero-shot prompting,\nwhich yields inconsistent and often poor results; (ii) instruction-tuning\ngenerally does not alter the sensitivity of LogProbs to semantic plausibility\n(although sometimes decreases it); (iii) across models, context mostly\nmodulates LogProbs in expected ways, as measured by three novel metrics of\ncontext-sensitive plausibility and their match to explicit human plausibility\njudgments. We conclude that, even in the era of prompt-based evaluations,\nLogProbs constitute a useful metric of semantic plausibility, both in base and\ninstruction-tuned LMs.", "published": "2024-03-21 22:08:44", "link": "http://arxiv.org/abs/2403.14859v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AutoRE: Document-Level Relation Extraction with Large Language Models", "abstract": "Large Language Models (LLMs) have demonstrated exceptional abilities in\ncomprehending and generating text, motivating numerous researchers to utilize\nthem for Information Extraction (IE) purposes, including Relation Extraction\n(RE). Nonetheless, most existing methods are predominantly designed for\nSentence-level Relation Extraction (SentRE) tasks, which typically encompass a\nrestricted set of relations and triplet facts within a single sentence.\nFurthermore, certain approaches resort to treating relations as candidate\nchoices integrated into prompt templates, leading to inefficient processing and\nsuboptimal performance when tackling Document-Level Relation Extraction (DocRE)\ntasks, which entail handling multiple relations and triplet facts distributed\nacross a given document, posing distinct challenges. To overcome these\nlimitations, we introduce AutoRE, an end-to-end DocRE model that adopts a novel\nRE extraction paradigm named RHF (Relation-Head-Facts). Unlike existing\napproaches, AutoRE does not rely on the assumption of known relation options,\nmaking it more reflective of real-world scenarios. Additionally, we have\ndeveloped an easily extensible RE framework using a Parameters Efficient Fine\nTuning (PEFT) algorithm (QLoRA). Our experiments on the RE-DocRED dataset\nshowcase AutoRE's best performance, achieving state-of-the-art results,\nsurpassing TAG by 10.03\\% and 9.03\\% respectively on the dev and test set. The\ncode is available at https://github.com/THUDM/AutoRE and the demonstration\nvideo is provided at https://www.youtube.com/watch?v=IhKRsZUAxKk.", "published": "2024-03-21 23:48:21", "link": "http://arxiv.org/abs/2403.14888v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RakutenAI-7B: Extending Large Language Models for Japanese", "abstract": "We introduce RakutenAI-7B, a suite of Japanese-oriented large language models\nthat achieve the best performance on the Japanese LM Harness benchmarks among\nthe open 7B models. Along with the foundation model, we release instruction-\nand chat-tuned models, RakutenAI-7B-instruct and RakutenAI-7B-chat\nrespectively, under the Apache 2.0 license.", "published": "2024-03-21 06:56:07", "link": "http://arxiv.org/abs/2403.15484v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sequence-to-Sequence Language Models for Character and Emotion Detection\n  in Dream Narratives", "abstract": "The study of dreams has been central to understanding human\n(un)consciousness, cognition, and culture for centuries. Analyzing dreams\nquantitatively depends on labor-intensive, manual annotation of dream\nnarratives. We automate this process through a natural language\nsequence-to-sequence generation framework. This paper presents the first study\non character and emotion detection in the English portion of the open DreamBank\ncorpus of dream narratives. Our results show that language models can\neffectively address this complex task. To get insight into prediction\nperformance, we evaluate the impact of model size, prediction order of\ncharacters, and the consideration of proper names and character traits. We\ncompare our approach with a large language model using in-context learning. Our\nsupervised models perform better while having 28 times fewer parameters. Our\nmodel and its generated annotations are made publicly available.", "published": "2024-03-21 08:27:49", "link": "http://arxiv.org/abs/2403.15486v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Emergent World Models and Latent Variable Estimation in Chess-Playing\n  Language Models", "abstract": "Language models have shown unprecedented capabilities, sparking debate over\nthe source of their performance. Is it merely the outcome of learning syntactic\npatterns and surface level statistics, or do they extract semantics and a world\nmodel from the text? Prior work by Li et al. investigated this by training a\nGPT model on synthetic, randomly generated Othello games and found that the\nmodel learned an internal representation of the board state. We extend this\nwork into the more complex domain of chess, training on real games and\ninvestigating our model's internal representations using linear probes and\ncontrastive activations. The model is given no a priori knowledge of the game\nand is solely trained on next character prediction, yet we find evidence of\ninternal representations of board state. We validate these internal\nrepresentations by using them to make interventions on the model's activations\nand edit its internal board state. Unlike Li et al's prior synthetic dataset\napproach, our analysis finds that the model also learns to estimate latent\nvariables like player skill to better predict the next character. We derive a\nplayer skill vector and add it to the model, improving the model's win rate by\nup to 2.6 times.", "published": "2024-03-21 18:53:23", "link": "http://arxiv.org/abs/2403.15498v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Enhancing Medical Support in the Arabic Language Through Personalized\n  ChatGPT Assistance", "abstract": "This Paper discusses the growing popularity of online medical diagnosis as an\nalternative to traditional doctor visits. It highlights the limitations of\nexisting tools and emphasizes the advantages of using ChatGPT, which provides\nreal-time, personalized medical diagnosis at no cost. The paragraph summarizes\na research study that evaluated the performance of ChatGPT in Arabic medical\ndiagnosis. The study involved compiling a dataset of disease information and\ngenerating multiple messages for each disease using different prompting\ntechniques. ChatGPT's performance was assessed by measuring the similarity\nbetween its responses and the actual diseases. The results showed promising\nperformance, with average scores of around 76% for similarity measures. Various\nprompting techniques were used, and chain prompting demonstrated a relative\nadvantage. The study also recorded an average response time of 6.12 seconds for\nthe ChatGPT API, which is considered acceptable but has room for improvement.\nWhile ChatGPT cannot replace human doctors entirely, the findings suggest its\npotential in emergency cases and addressing general medical inquiries. Overall,\nthe study highlights ChatGPT's viability as a valuable tool in the medical\nfield.", "published": "2024-03-21 21:28:07", "link": "http://arxiv.org/abs/2403.15501v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Evaluating the Performance of LLMs on Technical Language Processing\n  tasks", "abstract": "In this paper we present the results of an evaluation study of the\nperfor-mance of LLMs on Technical Language Processing tasks. Humans are often\nconfronted with tasks in which they have to gather information from dispar-ate\nsources and require making sense of large bodies of text. These tasks can be\nsignificantly complex for humans and often require deep study including\nrereading portions of a text. Towards simplifying the task of gathering\nin-formation we evaluated LLMs with chat interfaces for their ability to\nprovide answers to standard questions that a human can be expected to answer\nbased on their reading of a body of text. The body of text under study is Title\n47 of the United States Code of Federal Regulations (CFR) which describes\nregula-tions for commercial telecommunications as governed by the Federal\nCom-munications Commission (FCC). This has been a body of text of interest\nbe-cause our larger research concerns the issue of making sense of information\nrelated to Wireless Spectrum Governance and usage in an automated manner to\nsupport Dynamic Spectrum Access. The information concerning this wireless\nspectrum domain is found in many disparate sources, with Title 47 of the CFR\nbeing just one of many. Using a range of LLMs and providing the required CFR\ntext as context we were able to quantify the performance of those LLMs on the\nspecific task of answering the questions below.", "published": "2024-03-21 23:40:42", "link": "http://arxiv.org/abs/2403.15503v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "The NeurIPS 2023 Machine Learning for Audio Workshop: Affective Audio\n  Benchmarks and Novel Data", "abstract": "The NeurIPS 2023 Machine Learning for Audio Workshop brings together machine\nlearning (ML) experts from various audio domains. There are several valuable\naudio-driven ML tasks, from speech emotion recognition to audio event\ndetection, but the community is sparse compared to other ML areas, e.g.,\ncomputer vision or natural language processing. A major limitation with audio\nis the available data; with audio being a time-dependent modality, high-quality\ndata collection is time-consuming and costly, making it challenging for\nacademic groups to apply their often state-of-the-art strategies to a larger,\nmore generalizable dataset. In this short white paper, to encourage researchers\nwith limited access to large-datasets, the organizers first outline several\nopen-source datasets that are available to the community, and for the duration\nof the workshop are making several propriety datasets available. Namely, three\nvocal datasets, Hume-Prosody, Hume-VocalBurst, an acted emotional speech\ndataset Modulate-Sonata, and an in-game streamer dataset Modulate-Stream. We\noutline the current baselines on these datasets but encourage researchers from\nacross audio to utilize them outside of the initial baseline tasks.", "published": "2024-03-21 00:13:59", "link": "http://arxiv.org/abs/2403.14048v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Extracting Emotion Phrases from Tweets using BART", "abstract": "Sentiment analysis is a natural language processing task that aims to\nidentify and extract the emotional aspects of a text. However, many existing\nsentiment analysis methods primarily classify the overall polarity of a text,\noverlooking the specific phrases that convey sentiment. In this paper, we\napplied an approach to sentiment analysis based on a question-answering\nframework. Our approach leverages the power of Bidirectional Autoregressive\nTransformer (BART), a pre-trained sequence-to-sequence model, to extract a\nphrase from a given text that amplifies a given sentiment polarity. We create a\nnatural language question that identifies the specific emotion to extract and\nthen guide BART to pay attention to the relevant emotional cues in the text. We\nuse a classifier within BART to predict the start and end positions of the\nanswer span within the text, which helps to identify the precise boundaries of\nthe extracted emotion phrase. Our approach offers several advantages over most\nsentiment analysis studies, including capturing the complete context and\nmeaning of the text and extracting precise token spans that highlight the\nintended sentiment. We achieved an end loss of 87% and Jaccard score of 0.61.", "published": "2024-03-21 00:20:16", "link": "http://arxiv.org/abs/2403.14050v3", "categories": ["cs.CL", "cs.LG", "stat.AP"], "primary_category": "cs.CL"}
{"title": "M3: A Multi-Task Mixed-Objective Learning Framework for Open-Domain\n  Multi-Hop Dense Sentence Retrieval", "abstract": "In recent research, contrastive learning has proven to be a highly effective\nmethod for representation learning and is widely used for dense retrieval.\nHowever, we identify that relying solely on contrastive learning can lead to\nsuboptimal retrieval performance. On the other hand, despite many retrieval\ndatasets supporting various learning objectives beyond contrastive learning,\ncombining them efficiently in multi-task learning scenarios can be challenging.\nIn this paper, we introduce M3, an advanced recursive Multi-hop dense sentence\nretrieval system built upon a novel Multi-task Mixed-objective approach for\ndense text representation learning, addressing the aforementioned challenges.\nOur approach yields state-of-the-art performance on a large-scale open-domain\nfact verification benchmark dataset, FEVER. Code and data are available at:\nhttps://github.com/TonyBY/M3", "published": "2024-03-21 01:52:07", "link": "http://arxiv.org/abs/2403.14074v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Text-Enhanced Data-free Approach for Federated Class-Incremental\n  Learning", "abstract": "Federated Class-Incremental Learning (FCIL) is an underexplored yet pivotal\nissue, involving the dynamic addition of new classes in the context of\nfederated learning. In this field, Data-Free Knowledge Transfer (DFKT) plays a\ncrucial role in addressing catastrophic forgetting and data privacy problems.\nHowever, prior approaches lack the crucial synergy between DFKT and the model\ntraining phases, causing DFKT to encounter difficulties in generating\nhigh-quality data from a non-anchored latent space of the old task model. In\nthis paper, we introduce LANDER (Label Text Centered Data-Free Knowledge\nTransfer) to address this issue by utilizing label text embeddings (LTE)\nproduced by pretrained language models. Specifically, during the model training\nphase, our approach treats LTE as anchor points and constrains the feature\nembeddings of corresponding training samples around them, enriching the\nsurrounding area with more meaningful information. In the DFKT phase, by using\nthese LTE anchors, LANDER can synthesize more meaningful samples, thereby\neffectively addressing the forgetting problem. Additionally, instead of tightly\nconstraining embeddings toward the anchor, the Bounding Loss is introduced to\nencourage sample embeddings to remain flexible within a defined radius. This\napproach preserves the natural differences in sample embeddings and mitigates\nthe embedding overlap caused by heterogeneous federated settings. Extensive\nexperiments conducted on CIFAR100, Tiny-ImageNet, and ImageNet demonstrate that\nLANDER significantly outperforms previous methods and achieves state-of-the-art\nperformance in FCIL. The code is available at\nhttps://github.com/tmtuan1307/lander.", "published": "2024-03-21 03:24:01", "link": "http://arxiv.org/abs/2403.14101v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via\n  Text Feature Dispersion", "abstract": "In deep learning, test-time adaptation has gained attention as a method for\nmodel fine-tuning without the need for labeled data. A prime exemplification is\nthe recently proposed test-time prompt tuning for large-scale vision-language\nmodels such as CLIP. Unfortunately, these prompts have been mainly developed to\nimprove accuracy, overlooking the importance of calibration, which is a crucial\naspect for quantifying prediction uncertainty. However, traditional calibration\nmethods rely on substantial amounts of labeled data, making them impractical\nfor test-time scenarios. To this end, this paper explores calibration during\ntest-time prompt tuning by leveraging the inherent properties of CLIP. Through\na series of observations, we find that the prompt choice significantly affects\nthe calibration in CLIP, where the prompts leading to higher text feature\ndispersion result in better-calibrated predictions. Introducing the Average\nText Feature Dispersion (ATFD), we establish its relationship with calibration\nerror and present a novel method, Calibrated Test-time Prompt Tuning (C-TPT),\nfor optimizing prompts during test-time with enhanced calibration. Through\nextensive experiments on different CLIP architectures and datasets, we show\nthat C-TPT can effectively improve the calibration of test-time prompt tuning\nwithout needing labeled data. The code is publicly accessible at\nhttps://github.com/hee-suk-yoon/C-TPT.", "published": "2024-03-21 04:08:29", "link": "http://arxiv.org/abs/2403.14119v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Unified Framework for Model Editing", "abstract": "ROME and MEMIT are largely believed to be two different model editing\nalgorithms, with the major difference between them being the ability to perform\nbatched edits. In this paper, we unify these two algorithms under a single\nconceptual umbrella, optimizing for the same goal, which we call the\npreservation-memorization objective. ROME uses an equality constraint to\noptimize this objective to perform one edit at a time, whereas MEMIT employs a\nmore flexible least-square constraint that allows for batched edits. We\ngeneralize ROME and enable batched editing with equality constraint in the form\nof EMMET - an Equality-constrained Mass Model Editing algorithm for\nTransformers, a new batched memory-editing algorithm. EMMET can perform\nbatched-edits up to a batch-size of 10,000, with very similar performance to\nMEMIT across multiple dimensions. With the introduction of EMMET, we truly\nunify ROME and MEMIT and show that both algorithms are equivalent in terms of\ntheir optimization objective, their abilities (singular and batched editing),\ntheir model editing performance and their limitations.", "published": "2024-03-21 08:54:24", "link": "http://arxiv.org/abs/2403.14236v5", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large\n  Language Models with Machine Learning in tele-dermatology", "abstract": "The rise of Artificial Intelligence creates great promise in the field of\nmedical discovery, diagnostics and patient management. However, the vast\ncomplexity of all medical domains require a more complex approach that combines\nmachine learning algorithms, classifiers, segmentation algorithms and, lately,\nlarge language models. In this paper, we describe, implement and assess an\nArtificial Intelligence-empowered system and methodology aimed at assisting the\ndiagnosis process of skin lesions and other skin conditions within the field of\ndermatology that aims to holistically address the diagnostic process in this\ndomain. The workflow integrates large language, transformer-based vision models\nand sophisticated machine learning tools. This holistic approach achieves a\nnuanced interpretation of dermatological conditions that simulates and\nfacilitates a dermatologist's workflow. We assess our proposed methodology\nthrough a thorough cross-model validation technique embedded in an evaluation\npipeline that utilizes publicly available medical case studies of skin\nconditions and relevant images. To quantitatively score the system performance,\nadvanced machine learning and natural language processing tools are employed\nwhich focus on similarity comparison and natural language inference.\nAdditionally, we incorporate a human expert evaluation process based on a\nstructured checklist to further validate our results. We implemented the\nproposed methodology in a system which achieved approximate (weighted) scores\nof 0.87 for both contextual understanding and diagnostic accuracy,\ndemonstrating the efficacy of our approach in enhancing dermatological\nanalysis. The proposed methodology is expected to prove useful in the\ndevelopment of next-generation tele-dermatology applications, enhancing remote\nconsultation capabilities and access to care, especially in underserved areas.", "published": "2024-03-21 09:02:17", "link": "http://arxiv.org/abs/2403.14243v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "LayoutLLM: Large Language Model Instruction Tuning for Visually Rich\n  Document Understanding", "abstract": "This paper proposes LayoutLLM, a more flexible document analysis method for\nunderstanding imaged documents. Visually Rich Document Understanding tasks,\nsuch as document image classification and information extraction, have gained\nsignificant attention due to their importance. Existing methods have been\ndeveloped to enhance document comprehension by incorporating pre-training\nawareness of images, text, and layout structure. However, these methods require\nfine-tuning for each task and dataset, and the models are expensive to train\nand operate. To overcome this limitation, we propose a new LayoutLLM that\nintegrates these with large-scale language models (LLMs). By leveraging the\nstrengths of existing research in document image understanding and LLMs'\nsuperior language understanding capabilities, the proposed model, fine-tuned\nwith multimodal instruction datasets, performs an understanding of document\nimages in a single model. Our experiments demonstrate improvement over the\nbaseline model in various document analysis tasks.", "published": "2024-03-21 09:25:24", "link": "http://arxiv.org/abs/2403.14252v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Scene-Graph ViT: End-to-End Open-Vocabulary Visual Relationship\n  Detection", "abstract": "Visual relationship detection aims to identify objects and their\nrelationships in images. Prior methods approach this task by adding separate\nrelationship modules or decoders to existing object detection architectures.\nThis separation increases complexity and hinders end-to-end training, which\nlimits performance. We propose a simple and highly efficient decoder-free\narchitecture for open-vocabulary visual relationship detection. Our model\nconsists of a Transformer-based image encoder that represents objects as tokens\nand models their relationships implicitly. To extract relationship information,\nwe introduce an attention mechanism that selects object pairs likely to form a\nrelationship. We provide a single-stage recipe to train this model on a mixture\nof object and relationship detection data. Our approach achieves\nstate-of-the-art relationship detection performance on Visual Genome and on the\nlarge-vocabulary GQA benchmark at real-time inference speeds. We provide\nablations, real-world qualitative examples, and analyses of zero-shot\nperformance.", "published": "2024-03-21 10:15:57", "link": "http://arxiv.org/abs/2403.14270v2", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "$\\nabla \u03c4$: Gradient-based and Task-Agnostic machine Unlearning", "abstract": "Machine Unlearning, the process of selectively eliminating the influence of\ncertain data examples used during a model's training, has gained significant\nattention as a means for practitioners to comply with recent data protection\nregulations. However, existing unlearning methods face critical drawbacks,\nincluding their prohibitively high cost, often associated with a large number\nof hyperparameters, and the limitation of forgetting only relatively small data\nportions. This often makes retraining the model from scratch a quicker and more\neffective solution. In this study, we introduce Gradient-based and\nTask-Agnostic machine Unlearning ($\\nabla \\tau$), an optimization framework\ndesigned to remove the influence of a subset of training data efficiently. It\napplies adaptive gradient ascent to the data to be forgotten while using\nstandard gradient descent for the remaining data. $\\nabla \\tau$ offers multiple\nbenefits over existing approaches. It enables the unlearning of large sections\nof the training dataset (up to 30%). It is versatile, supporting various\nunlearning tasks (such as subset forgetting or class removal) and applicable\nacross different domains (images, text, etc.). Importantly, $\\nabla \\tau$\nrequires no hyperparameter adjustments, making it a more appealing option than\nretraining the model from scratch. We evaluate our framework's effectiveness\nusing a set of well-established Membership Inference Attack metrics,\ndemonstrating up to 10% enhancements in performance compared to\nstate-of-the-art methods without compromising the original model's accuracy.", "published": "2024-03-21 12:11:26", "link": "http://arxiv.org/abs/2403.14339v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for\n  Noise-Robust Speech Perception", "abstract": "Speech recognition and translation systems perform poorly on noisy inputs,\nwhich are frequent in realistic environments. Augmenting these systems with\nvisual signals has the potential to improve robustness to noise. However,\naudio-visual (AV) data is only available in limited amounts and for fewer\nlanguages than audio-only resources. To address this gap, we present XLAVS-R, a\ncross-lingual audio-visual speech representation model for noise-robust speech\nrecognition and translation in over 100 languages. It is designed to maximize\nthe benefits of limited multilingual AV pre-training data, by building on top\nof audio-only multilingual pre-training and simplifying existing pre-training\nschemes. Extensive evaluation on the MuAViC benchmark shows the strength of\nXLAVS-R on downstream audio-visual speech recognition and translation tasks,\nwhere it outperforms the previous state of the art by up to 18.5% WER and 4.7\nBLEU given noisy AV inputs, and enables strong zero-shot audio-visual ability\nwith audio-only fine-tuning.", "published": "2024-03-21 13:52:17", "link": "http://arxiv.org/abs/2403.14402v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Multimodal Approach to Device-Directed Speech Detection with Large\n  Language Models", "abstract": "Interactions with virtual assistants typically start with a predefined\ntrigger phrase followed by the user command. To make interactions with the\nassistant more intuitive, we explore whether it is feasible to drop the\nrequirement that users must begin each command with a trigger phrase. We\nexplore this task in three ways: First, we train classifiers using only\nacoustic information obtained from the audio waveform. Second, we take the\ndecoder outputs of an automatic speech recognition (ASR) system, such as 1-best\nhypotheses, as input features to a large language model (LLM). Finally, we\nexplore a multimodal system that combines acoustic and lexical features, as\nwell as ASR decoder signals in an LLM. Using multimodal information yields\nrelative equal-error-rate improvements over text-only and audio-only models of\nup to 39% and 61%. Increasing the size of the LLM and training with low-rank\nadaption leads to further relative EER reductions of up to 18% on our dataset.", "published": "2024-03-21 14:44:03", "link": "http://arxiv.org/abs/2403.14438v2", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "gTBLS: Generating Tables from Text by Conditional Question Answering", "abstract": "Distilling large, unstructured text into a structured, condensed form such as\ntables is an open research problem. One of the primary challenges in\nautomatically generating tables is ensuring their syntactic validity. Prior\napproaches address this challenge by including additional parameters in the\nTransformer's attention mechanism to attend to specific rows and column\nheaders. In contrast to this single-stage method, this paper presents a\ntwo-stage approach called Generative Tables (gTBLS). The first stage infers\ntable structure (row and column headers) from the text. The second stage\nformulates questions using these headers and fine-tunes a causal language model\nto answer them. Furthermore, the gTBLS approach is amenable to the utilization\nof pre-trained Large Language Models in a zero-shot configuration, presenting a\nsolution for table generation in situations where fine-tuning is not feasible.\ngTBLS improves prior approaches by up to 10% in BERTScore on the table\nconstruction task and up to 20% on the table content generation task of the\nE2E, WikiTableText, WikiBio, and RotoWire datasets.", "published": "2024-03-21 15:04:32", "link": "http://arxiv.org/abs/2403.14457v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Single-System Illusion in Software-Defined Vehicles --\n  Automated, AI-Powered Workflow", "abstract": "We propose a novel model- and feature-based approach to development of\nvehicle software systems, where the end architecture is not explicitly defined.\nInstead, it emerges from an iterative process of search and optimization given\ncertain constraints, requirements and hardware architecture, while retaining\nthe property of single-system illusion, where applications run in a logically\nuniform environment. One of the key points of the presented approach is the\ninclusion of modern generative AI, specifically Large Language Models (LLMs),\nin the loop. With the recent advances in the field, we expect that the LLMs\nwill be able to assist in processing of requirements, generation of formal\nsystem models, as well as generation of software deployment specification and\ntest code. The resulting pipeline is automated to a large extent, with feedback\nbeing generated at each step.", "published": "2024-03-21 15:07:57", "link": "http://arxiv.org/abs/2403.14460v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "D.2.1; D.2.2; D.2.4; I.2.7; I.2.2; I.7.0"], "primary_category": "cs.SE"}
{"title": "Recourse for reclamation: Chatting with generative language models", "abstract": "Researchers and developers increasingly rely on toxicity scoring to moderate\ngenerative language model outputs, in settings such as customer service,\ninformation retrieval, and content generation. However, toxicity scoring may\nrender pertinent information inaccessible, rigidify or \"value-lock\" cultural\nnorms, and prevent language reclamation processes, particularly for\nmarginalized people. In this work, we extend the concept of algorithmic\nrecourse to generative language models: we provide users a novel mechanism to\nachieve their desired prediction by dynamically setting thresholds for toxicity\nfiltering. Users thereby exercise increased agency relative to interactions\nwith the baseline system. A pilot study ($n = 30$) supports the potential of\nour proposed recourse mechanism, indicating improvements in usability compared\nto fixed-threshold toxicity-filtering of model outputs. Future work should\nexplore the intersection of toxicity scoring, model controllability, user\nagency, and language reclamation processes -- particularly with regard to the\nbias that many communities encounter when interacting with generative language\nmodels.", "published": "2024-03-21 15:14:25", "link": "http://arxiv.org/abs/2403.14467v2", "categories": ["cs.HC", "cs.CL", "cs.CY"], "primary_category": "cs.HC"}
{"title": "Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling", "abstract": "Today's most accurate language models are trained on orders of magnitude more\nlanguage data than human language learners receive - but with no supervision\nfrom other sensory modalities that play a crucial role in human learning. Can\nwe make LMs' representations and predictions more accurate (and more\nhuman-like) with more ecologically plausible supervision? This paper describes\nLexiContrastive Grounding (LCG), a grounded language learning procedure that\nleverages visual supervision to improve textual representations.\nLexiContrastive Grounding combines a next token prediction strategy with a\ncontrastive visual grounding objective, focusing on early-layer representations\nthat encode lexical information. Across multiple word-learning and\nsentence-understanding benchmarks, LexiContrastive Grounding not only\noutperforms standard language-only models in learning efficiency, but also\nimproves upon vision-and-language learning procedures including CLIP, GIT,\nFlamingo, and Vokenization. Moreover, LexiContrastive Grounding improves\nperplexity by around 5% on multiple language modeling tasks. This work\nunderscores the potential of incorporating visual grounding into language\nmodels, aligning more closely with the multimodal nature of human language\nacquisition.", "published": "2024-03-21 16:52:01", "link": "http://arxiv.org/abs/2403.14551v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Era of Semantic Decoding", "abstract": "Recent work demonstrated great promise in the idea of orchestrating\ncollaborations between LLMs, human input, and various tools to address the\ninherent limitations of LLMs. We propose a novel perspective called semantic\ndecoding, which frames these collaborative processes as optimization procedures\nin semantic space. Specifically, we conceptualize LLMs as semantic processors\nthat manipulate meaningful pieces of information that we call semantic tokens\n(known thoughts). LLMs are among a large pool of other semantic processors,\nincluding humans and tools, such as search engines or code executors.\nCollectively, semantic processors engage in dynamic exchanges of semantic\ntokens to progressively construct high-utility outputs. We refer to these\norchestrated interactions among semantic processors, optimizing and searching\nin semantic space, as semantic decoding algorithms. This concept draws a direct\nparallel to the well-studied problem of syntactic decoding, which involves\ncrafting algorithms to best exploit auto-regressive language models for\nextracting high-utility sequences of syntactic tokens. By focusing on the\nsemantic level and disregarding syntactic details, we gain a fresh perspective\non the engineering of AI systems, enabling us to imagine systems with much\ngreater complexity and capabilities. In this position paper, we formalize the\ntransition from syntactic to semantic tokens as well as the analogy between\nsyntactic and semantic decoding. Subsequently, we explore the possibilities of\noptimizing within the space of semantic tokens via semantic decoding\nalgorithms. We conclude with a list of research opportunities and questions\narising from this fresh perspective. The semantic decoding perspective offers a\npowerful abstraction for search and optimization directly in the space of\nmeaningful concepts, with semantic tokens as the fundamental units of a new\ntype of computation.", "published": "2024-03-21 17:06:17", "link": "http://arxiv.org/abs/2403.14562v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.MA"], "primary_category": "cs.CL"}
{"title": "ReAct Meets ActRe: When Language Agents Enjoy Training Data Autonomy", "abstract": "Language agents have demonstrated autonomous decision-making abilities by\nreasoning with foundation models. Recently, efforts have been made to train\nlanguage agents for performance improvement, with multi-step reasoning and\naction trajectories as the training data. However, collecting such trajectories\nstill requires considerable human effort, by either artificial annotation or\nimplementations of diverse prompting frameworks. In this work, we propose\nA$^3$T, a framework that enables the Autonomous Annotation of Agent\nTrajectories in the style of ReAct. The central role is an ActRe prompting\nagent, which explains the reason for an arbitrary action. When randomly\nsampling an external action, the ReAct-style agent could query the ActRe agent\nwith the action to obtain its textual rationales. Novel trajectories are then\nsynthesized by prepending the posterior reasoning from ActRe to the sampled\naction. In this way, the ReAct-style agent executes multiple trajectories for\nthe failed tasks, and selects the successful ones to supplement its failed\ntrajectory for contrastive self-training. Realized by policy gradient methods\nwith binarized rewards, the contrastive self-training with accumulated\ntrajectories facilitates a closed loop for multiple rounds of language agent\nself-improvement. We conduct experiments using QLoRA fine-tuning with the\nopen-sourced Mistral-7B-Instruct-v0.2. In AlfWorld, the agent trained with\nA$^3$T obtains a 1-shot success rate of 96%, and 100% success with 4 iterative\nrounds. In WebShop, the 1-shot performance of the A$^3$T agent matches human\naverage, and 4 rounds of iterative refinement lead to the performance\napproaching human experts. A$^3$T agents significantly outperform existing\ntechniques, including prompting with GPT-4, advanced agent frameworks, and\nfully fine-tuned LLMs.", "published": "2024-03-21 17:43:44", "link": "http://arxiv.org/abs/2403.14589v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "DreamReward: Text-to-3D Generation with Human Preference", "abstract": "3D content creation from text prompts has shown remarkable success recently.\nHowever, current text-to-3D methods often generate 3D results that do not align\nwell with human preferences. In this paper, we present a comprehensive\nframework, coined DreamReward, to learn and improve text-to-3D models from\nhuman preference feedback. To begin with, we collect 25k expert comparisons\nbased on a systematic annotation pipeline including rating and ranking. Then,\nwe build Reward3D -- the first general-purpose text-to-3D human preference\nreward model to effectively encode human preferences. Building upon the 3D\nreward model, we finally perform theoretical analysis and present the Reward3D\nFeedback Learning (DreamFL), a direct tuning algorithm to optimize the\nmulti-view diffusion models with a redefined scorer. Grounded by theoretical\nproof and extensive experiment comparisons, our DreamReward successfully\ngenerates high-fidelity and 3D consistent results with significant boosts in\nprompt alignment with human intention. Our results demonstrate the great\npotential for learning from human feedback to improve text-to-3D models.", "published": "2024-03-21 17:58:04", "link": "http://arxiv.org/abs/2403.14613v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual\n  Math Problems?", "abstract": "The remarkable progress of Multi-modal Large Language Models (MLLMs) has\ngarnered unparalleled attention, due to their superior performance in visual\ncontexts. However, their capabilities in visual math problem-solving remain\ninsufficiently evaluated and understood. We investigate current benchmarks to\nincorporate excessive visual content within textual questions, which\npotentially assist MLLMs in deducing answers without truly interpreting the\ninput diagrams. To this end, we introduce MathVerse, an all-around visual math\nbenchmark designed for an equitable and in-depth evaluation of MLLMs. We\nmeticulously collect 2,612 high-quality, multi-subject math problems with\ndiagrams from publicly available sources. Each problem is then transformed by\nhuman annotators into six distinct versions, each offering varying degrees of\ninformation content in multi-modality, contributing to 15K test samples in\ntotal. This approach allows MathVerse to comprehensively assess whether and how\nmuch MLLMs can truly understand the visual diagrams for mathematical reasoning.\nIn addition, we propose a Chain-of-Thought (CoT) evaluation strategy for a\nfine-grained assessment of the output answers. Rather than naively judging True\nor False, we employ GPT-4(V) to adaptively extract crucial reasoning steps, and\nthen score each step with detailed error analysis, which can reveal the\nintermediate CoT reasoning quality by MLLMs. We hope the MathVerse benchmark\nmay provide unique insights to guide the future development of MLLMs. Project\npage: https://mathverse-cuhk.github.io", "published": "2024-03-21 17:59:50", "link": "http://arxiv.org/abs/2403.14624v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Protected group bias and stereotypes in Large Language Models", "abstract": "As modern Large Language Models (LLMs) shatter many state-of-the-art\nbenchmarks in a variety of domains, this paper investigates their behavior in\nthe domains of ethics and fairness, focusing on protected group bias. We\nconduct a two-part study: first, we solicit sentence continuations describing\nthe occupations of individuals from different protected groups, including\ngender, sexuality, religion, and race. Second, we have the model generate\nstories about individuals who hold different types of occupations. We collect\n>10k sentence completions made by a publicly available LLM, which we subject to\nhuman annotation. We find bias across minoritized groups, but in particular in\nthe domains of gender and sexuality, as well as Western bias, in model\ngenerations. The model not only reflects societal biases, but appears to\namplify them. The model is additionally overly cautious in replies to queries\nrelating to minoritized groups, providing responses that strongly emphasize\ndiversity and equity to an extent that other group characteristics are\novershadowed. This suggests that artificially constraining potentially harmful\noutputs may itself lead to harm, and should be applied in a careful and\ncontrolled manner.", "published": "2024-03-21 00:21:38", "link": "http://arxiv.org/abs/2403.14727v1", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Reversible Jump Attack to Textual Classifiers with Modification\n  Reduction", "abstract": "Recent studies on adversarial examples expose vulnerabilities of natural\nlanguage processing (NLP) models. Existing techniques for generating\nadversarial examples are typically driven by deterministic hierarchical rules\nthat are agnostic to the optimal adversarial examples, a strategy that often\nresults in adversarial samples with a suboptimal balance between magnitudes of\nchanges and attack successes. To this end, in this research we propose two\nalgorithms, Reversible Jump Attack (RJA) and Metropolis-Hasting Modification\nReduction (MMR), to generate highly effective adversarial examples and to\nimprove the imperceptibility of the examples, respectively. RJA utilizes a\nnovel randomization mechanism to enlarge the search space and efficiently\nadapts to a number of perturbed words for adversarial examples. With these\ngenerated adversarial examples, MMR applies the Metropolis-Hasting sampler to\nenhance the imperceptibility of adversarial examples. Extensive experiments\ndemonstrate that RJA-MMR outperforms current state-of-the-art methods in attack\nperformance, imperceptibility, fluency and grammar correctness.", "published": "2024-03-21 04:54:31", "link": "http://arxiv.org/abs/2403.14731v1", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Open Knowledge Base Canonicalization with Multi-task Learning", "abstract": "The construction of large open knowledge bases (OKBs) is integral to many\nknowledge-driven applications on the world wide web such as web search.\nHowever, noun phrases and relational phrases in OKBs often suffer from\nredundancy and ambiguity, which calls for the investigation on OKB\ncanonicalization. Current solutions address OKB canonicalization by devising\nadvanced clustering algorithms and using knowledge graph embedding (KGE) to\nfurther facilitate the canonicalization process. Nevertheless, these works fail\nto fully exploit the synergy between clustering and KGE learning, and the\nmethods designed for these subtasks are sub-optimal. To this end, we put\nforward a multi-task learning framework, namely MulCanon, to tackle OKB\ncanonicalization. In addition, diffusion model is used in the soft clustering\nprocess to improve the noun phrase representations with neighboring\ninformation, which can lead to more accurate representations. MulCanon unifies\nthe learning objectives of these sub-tasks, and adopts a two-stage multi-task\nlearning paradigm for training. A thorough experimental study on popular OKB\ncanonicalization benchmarks validates that MulCanon can achieve competitive\ncanonicalization results.", "published": "2024-03-21 08:03:46", "link": "http://arxiv.org/abs/2403.14733v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond", "abstract": "Neural Code Intelligence -- leveraging deep learning to understand, generate,\nand optimize code -- holds immense potential for transformative impacts on the\nwhole society. Bridging the gap between Natural Language and Programming\nLanguage, this domain has drawn significant attention from researchers in both\nresearch communities over the past few years. This survey presents a systematic\nand chronological review of the advancements in code intelligence, encompassing\nover 50 representative models and their variants, more than 20 categories of\ntasks, and an extensive coverage of over 680 related works. We follow the\nhistorical progression to trace the paradigm shifts across different research\nphases (e.g., from modeling code with recurrent neural networks to the era of\nLarge Language Models). Concurrently, we highlight the major technical\ntransitions in models, tasks, and evaluations spanning through different\nstages. For applications, we also observe a co-evolving shift. It spans from\ninitial endeavors to tackling specific scenarios, through exploring a diverse\narray of tasks during its rapid expansion, to currently focusing on tackling\nincreasingly complex and varied real-world challenges. Building on our\nexamination of the developmental trajectories, we further investigate the\nemerging synergies between code intelligence and broader machine intelligence,\nuncovering new cross-domain opportunities and illustrating the substantial\ninfluence of code intelligence across various domains. Finally, we delve into\nboth the opportunities and challenges associated with this field, alongside\nelucidating our insights on the most promising research directions. An ongoing,\ndynamically updated project and resources associated with this survey have been\nreleased at https://github.com/QiushiSun/Awesome-Code-Intelligence.", "published": "2024-03-21 08:54:56", "link": "http://arxiv.org/abs/2403.14734v5", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Few-Shot Adversarial Prompt Learning on Vision-Language Models", "abstract": "The vulnerability of deep neural networks to imperceptible adversarial\nperturbations has attracted widespread attention. Inspired by the success of\nvision-language foundation models, previous efforts achieved zero-shot\nadversarial robustness by aligning adversarial visual features with text\nsupervision. However, in practice, they are still unsatisfactory due to several\nissues, including heavy adaptation cost, suboptimal text supervision, and\nuncontrolled natural generalization capacity. In this paper, to address these\nissues, we propose a few-shot adversarial prompt framework where adapting input\nsequences with limited data makes significant adversarial robustness\nimprovement. Specifically, we achieve this by providing adversarially\ncorrelated text supervision that is end-to-end learned from adversarial\nexamples. We also propose a novel training objective that enhances the\nconsistency of multi-modal features while encourages differentiated uni-modal\nfeatures between natural and adversarial examples. The proposed framework gives\naccess to learn adversarial text supervision, which provides superior\ncross-modal adversarial alignment and matches state-of-the-art zero-shot\nadversarial robustness with only 1% training data. Code is available at:\nhttps://github.com/lionel-w2/FAP.", "published": "2024-03-21 18:28:43", "link": "http://arxiv.org/abs/2403.14774v2", "categories": ["cs.CV", "cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "VidLA: Video-Language Alignment at Scale", "abstract": "In this paper, we propose VidLA, an approach for video-language alignment at\nscale. There are two major limitations of previous video-language alignment\napproaches. First, they do not capture both short-range and long-range temporal\ndependencies and typically employ complex hierarchical deep network\narchitectures that are hard to integrate with existing pretrained image-text\nfoundation models. To effectively address this limitation, we instead keep the\nnetwork architecture simple and use a set of data tokens that operate at\ndifferent temporal resolutions in a hierarchical manner, accounting for the\ntemporally hierarchical nature of videos. By employing a simple two-tower\narchitecture, we are able to initialize our video-language model with\npretrained image-text foundation models, thereby boosting the final\nperformance. Second, existing video-language alignment works struggle due to\nthe lack of semantically aligned large-scale training data. To overcome it, we\nleverage recent LLMs to curate the largest video-language dataset to date with\nbetter visual grounding. Furthermore, unlike existing video-text datasets which\nonly contain short clips, our dataset is enriched with video clips of varying\ndurations to aid our temporally hierarchical data tokens in extracting better\nrepresentations at varying temporal scales. Overall, empirical results show\nthat our proposed approach surpasses state-of-the-art methods on multiple\nretrieval benchmarks, especially on longer videos, and performs competitively\non classification benchmarks.", "published": "2024-03-21 22:36:24", "link": "http://arxiv.org/abs/2403.14870v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Multi-Level Feedback Generation with Large Language Models for\n  Empowering Novice Peer Counselors", "abstract": "Realistic practice and tailored feedback are key processes for training peer\ncounselors with clinical skills. However, existing mechanisms of providing\nfeedback largely rely on human supervision. Peer counselors often lack\nmechanisms to receive detailed feedback from experienced mentors, making it\ndifficult for them to support the large number of people with mental health\nissues who use peer counseling. Our work aims to leverage large language models\nto provide contextualized and multi-level feedback to empower peer counselors,\nespecially novices, at scale. To achieve this, we co-design with a group of\nsenior psychotherapy supervisors to develop a multi-level feedback taxonomy,\nand then construct a publicly available dataset with comprehensive feedback\nannotations of 400 emotional support conversations. We further design a\nself-improvement method on top of large language models to enhance the\nautomatic generation of feedback. Via qualitative and quantitative evaluation\nwith domain experts, we demonstrate that our method minimizes the risk of\npotentially harmful and low-quality feedback generation which is desirable in\nsuch high-stakes scenarios.", "published": "2024-03-21 04:23:56", "link": "http://arxiv.org/abs/2403.15482v1", "categories": ["cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MOGAM: A Multimodal Object-oriented Graph Attention Model for Depression\n  Detection", "abstract": "Early detection plays a crucial role in the treatment of depression.\nTherefore, numerous studies have focused on social media platforms, where\nindividuals express their emotions, aiming to achieve early detection of\ndepression. However, the majority of existing approaches often rely on specific\nfeatures, leading to limited scalability across different types of social media\ndatasets, such as text, images, or videos. To overcome this limitation, we\nintroduce a Multimodal Object-Oriented Graph Attention Model (MOGAM), which can\nbe applied to diverse types of data, offering a more scalable and versatile\nsolution. Furthermore, to ensure that our model can capture authentic symptoms\nof depression, we only include vlogs from users with a clinical diagnosis. To\nleverage the diverse features of vlogs, we adopt a multimodal approach and\ncollect additional metadata such as the title, description, and duration of the\nvlogs. To effectively aggregate these multimodal features, we employed a\ncross-attention mechanism. MOGAM achieved an accuracy of 0.871 and an F1-score\nof 0.888. Moreover, to validate the scalability of MOGAM, we evaluated its\nperformance with a benchmark dataset and achieved comparable results with prior\nstudies (0.61 F1-score). In conclusion, we believe that the proposed model,\nMOGAM, is an effective solution for detecting depression in social media,\noffering potential benefits in the early detection and treatment of this mental\nhealth condition.", "published": "2024-03-21 07:45:58", "link": "http://arxiv.org/abs/2403.15485v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sequential Decision-Making for Inline Text Autocomplete", "abstract": "Autocomplete suggestions are fundamental to modern text entry systems, with\napplications in domains such as messaging and email composition. Typically,\nautocomplete suggestions are generated from a language model with a confidence\nthreshold. However, this threshold does not directly take into account the\ncognitive load imposed on the user by surfacing suggestions, such as the effort\nto switch contexts from typing to reading the suggestion, and the time to\ndecide whether to accept the suggestion. In this paper, we study the problem of\nimproving inline autocomplete suggestions in text entry systems via a\nsequential decision-making formulation, and use reinforcement learning to learn\nsuggestion policies through repeated interactions with a target user over time.\nThis formulation allows us to factor cognitive load into the objective of\ntraining an autocomplete model, through a reward function based on text entry\nspeed. We acquired theoretical and experimental evidence that, under certain\nobjectives, the sequential decision-making formulation of the autocomplete\nproblem provides a better suggestion policy than myopic single-step reasoning.\nHowever, aligning these objectives with real users requires further\nexploration. In particular, we hypothesize that the objectives under which\nsequential decision-making can improve autocomplete systems are not tailored\nsolely to text entry speed, but more broadly to metrics such as user\nsatisfaction and convenience.", "published": "2024-03-21 22:33:16", "link": "http://arxiv.org/abs/2403.15502v2", "categories": ["cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Semantically Aligned Question and Code Generation for Automated Insight\n  Generation", "abstract": "Automated insight generation is a common tactic for helping knowledge\nworkers, such as data scientists, to quickly understand the potential value of\nnew and unfamiliar data. Unfortunately, automated insights produced by\nlarge-language models can generate code that does not correctly correspond (or\nalign) to the insight. In this paper, we leverage the semantic knowledge of\nlarge language models to generate targeted and insightful questions about data\nand the corresponding code to answer those questions. Then through an empirical\nstudy on data from Open-WikiTable, we show that embeddings can be effectively\nused for filtering out semantically unaligned pairs of question and code.\nAdditionally, we found that generating questions and code together yields more\ndiverse questions.", "published": "2024-03-21 10:01:05", "link": "http://arxiv.org/abs/2405.01556v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Detoxifying Large Language Models via Knowledge Editing", "abstract": "This paper investigates using knowledge editing techniques to detoxify Large\nLanguage Models (LLMs). We construct a benchmark, SafeEdit, which covers nine\nunsafe categories with various powerful attack prompts and equips comprehensive\nmetrics for systematic evaluation. We conduct experiments with several\nknowledge editing approaches, indicating that knowledge editing has the\npotential to detoxify LLMs with a limited impact on general performance\nefficiently. Then, we propose a simple yet effective baseline, dubbed\nDetoxifying with Intraoperative Neural Monitoring (DINM), to diminish the\ntoxicity of LLMs within a few tuning steps via only one instance. We further\nprovide an in-depth analysis of the internal mechanism for various detoxifying\napproaches, demonstrating that previous methods like SFT and DPO may merely\nsuppress the activations of toxic parameters, while DINM mitigates the toxicity\nof the toxic parameters to a certain extent, making permanent adjustments. We\nhope that these insights could shed light on future work of developing\ndetoxifying approaches and the underlying knowledge mechanisms of LLMs. Code\nand benchmark are available at https://github.com/zjunlp/EasyEdit.", "published": "2024-03-21 15:18:30", "link": "http://arxiv.org/abs/2403.14472v5", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-Agent VQA: Exploring Multi-Agent Foundation Models in Zero-Shot\n  Visual Question Answering", "abstract": "This work explores the zero-shot capabilities of foundation models in Visual\nQuestion Answering (VQA) tasks. We propose an adaptive multi-agent system,\nnamed Multi-Agent VQA, to overcome the limitations of foundation models in\nobject detection and counting by using specialized agents as tools. Unlike\nexisting approaches, our study focuses on the system's performance without\nfine-tuning it on specific VQA datasets, making it more practical and robust in\nthe open world. We present preliminary experimental results under zero-shot\nscenarios and highlight some failure cases, offering new directions for future\nresearch.", "published": "2024-03-21 18:57:25", "link": "http://arxiv.org/abs/2403.14783v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MA"], "primary_category": "cs.CV"}
{"title": "The opportunities and risks of large language models in mental health", "abstract": "Global rates of mental health concerns are rising, and there is increasing\nrealization that existing models of mental health care will not adequately\nexpand to meet the demand. With the emergence of large language models (LLMs)\nhas come great optimism regarding their promise to create novel, large-scale\nsolutions to support mental health. Despite their nascence, LLMs have already\nbeen applied to mental health related tasks. In this paper, we summarize the\nextant literature on efforts to use LLMs to provide mental health education,\nassessment, and intervention and highlight key opportunities for positive\nimpact in each area. We then highlight risks associated with LLMs' application\nto mental health and encourage the adoption of strategies to mitigate these\nrisks. The urgent need for mental health support must be balanced with\nresponsible development, testing, and deployment of mental health LLMs. It is\nespecially critical to ensure that mental health LLMs are fine-tuned for mental\nhealth, enhance mental health equity, and adhere to ethical standards and that\npeople, including those with lived experience with mental health concerns, are\ninvolved in all stages from development through deployment. Prioritizing these\nefforts will minimize potential harms to mental health and maximize the\nlikelihood that LLMs will positively impact mental health globally.", "published": "2024-03-21 19:59:52", "link": "http://arxiv.org/abs/2403.14814v3", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Language Models Can Reduce Asymmetry in Information Markets", "abstract": "This work addresses the buyer's inspection paradox for information markets.\nThe paradox is that buyers need to access information to determine its value,\nwhile sellers need to limit access to prevent theft. To study this, we\nintroduce an open-source simulated digital marketplace where intelligent\nagents, powered by language models, buy and sell information on behalf of\nexternal participants. The central mechanism enabling this marketplace is the\nagents' dual capabilities: they not only have the capacity to assess the\nquality of privileged information but also come equipped with the ability to\nforget. This ability to induce amnesia allows vendors to grant temporary access\nto proprietary information, significantly reducing the risk of unauthorized\nretention while enabling agents to accurately gauge the information's relevance\nto specific queries or tasks. To perform well, agents must make rational\ndecisions, strategically explore the marketplace through generated sub-queries,\nand synthesize answers from purchased information. Concretely, our experiments\n(a) uncover biases in language models leading to irrational behavior and\nevaluate techniques to mitigate these biases, (b) investigate how price affects\ndemand in the context of informational goods, and (c) show that inspection and\nhigher budgets both lead to higher quality outcomes.", "published": "2024-03-21 14:48:37", "link": "http://arxiv.org/abs/2403.14443v1", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.LG", "cs.MA", "cs.SI"], "primary_category": "cs.AI"}
{"title": "StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation\n  from Text", "abstract": "Text-to-video diffusion models enable the generation of high-quality videos\nthat follow text instructions, making it easy to create diverse and individual\ncontent. However, existing approaches mostly focus on high-quality short video\ngeneration (typically 16 or 24 frames), ending up with hard-cuts when naively\nextended to the case of long video synthesis. To overcome these limitations, we\nintroduce StreamingT2V, an autoregressive approach for long video generation of\n80, 240, 600, 1200 or more frames with smooth transitions. The key components\nare:(i) a short-term memory block called conditional attention module (CAM),\nwhich conditions the current generation on the features extracted from the\nprevious chunk via an attentional mechanism, leading to consistent chunk\ntransitions, (ii) a long-term memory block called appearance preservation\nmodule, which extracts high-level scene and object features from the first\nvideo chunk to prevent the model from forgetting the initial scene, and (iii) a\nrandomized blending approach that enables to apply a video enhancer\nautoregressively for infinitely long videos without inconsistencies between\nchunks. Experiments show that StreamingT2V generates high motion amount. In\ncontrast, all competing image-to-video methods are prone to video stagnation\nwhen applied naively in an autoregressive manner. Thus, we propose with\nStreamingT2V a high-quality seamless text-to-long video generator that\noutperforms competitors with consistency and motion. Our code will be available\nat: https://github.com/Picsart-AI-Research/StreamingT2V", "published": "2024-03-21 18:27:29", "link": "http://arxiv.org/abs/2403.14773v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM", "eess.IV"], "primary_category": "cs.CV"}
{"title": "AdaProj: Adaptively Scaled Angular Margin Subspace Projections for\n  Anomalous Sound Detection with Auxiliary Classification Tasks", "abstract": "The state-of-the-art approach for semi-supervised anomalous sound detection\nis to first learn an embedding space by using auxiliary classification tasks\nbased on meta information or self-supervised learning and then estimate the\ndistribution of normal data. In this work, AdaProj a novel loss function for\ntraining the embedding model is presented. In contrast to commonly used angular\nmargin losses, which project data of each class as close as possible to their\ncorresponding class centers, AdaProj learns to project data onto class-specific\nsubspaces while still ensuring an angular margin between classes. By doing so,\nthe resulting distributions of the embeddings belonging to normal data are not\nrequired to be as restrictive as other loss functions allowing a more detailed\nview on the data. In experiments conducted on the DCASE2022 and DCASE2023\nanomalous sound detection datasets, it is shown that using AdaProj to learn an\nembedding space significantly outperforms other commonly used loss functions.", "published": "2024-03-21 07:06:30", "link": "http://arxiv.org/abs/2403.14179v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "CATSE: A Context-Aware Framework for Causal Target Sound Extraction", "abstract": "Target Sound Extraction (TSE) focuses on the problem of separating sources of\ninterest, indicated by a user's cue, from the input mixture. Most existing\nsolutions operate in an offline fashion and are not suited to the low-latency\ncausal processing constraints imposed by applications in live-streamed content\nsuch as augmented hearing. We introduce a family of context-aware low-latency\ncausal TSE models suitable for real-time processing. First, we explore the\nutility of context by providing the TSE model with oracle information about\nwhat sound classes make up the input mixture, where the objective of the model\nis to extract one or more sources of interest indicated by the user. Since the\npractical applications of oracle models are limited due to their assumptions,\nwe introduce a composite multi-task training objective involving separation and\nclassification losses. Our evaluation involving single- and multi-source\nextraction shows the benefit of using context information in the model either\nby means of providing full context or via the proposed multi-task training loss\nwithout the need for full context information. Specifically, we show that our\nproposed model outperforms size- and latency-matched Waveformer, a\nstate-of-the-art model for real-time TSE.", "published": "2024-03-21 09:06:28", "link": "http://arxiv.org/abs/2403.14246v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Speech-Aware Neural Diarization with Encoder-Decoder Attractor Guided by\n  Attention Constraints", "abstract": "End-to-End Neural Diarization with Encoder-Decoder based Attractor (EEND-EDA)\nis an end-to-end neural model for automatic speaker segmentation and labeling.\nIt achieves the capability to handle flexible number of speakers by estimating\nthe number of attractors. EEND-EDA, however, struggles to accurately capture\nlocal speaker dynamics. This work proposes an auxiliary loss that aims to guide\nthe Transformer encoders at the lower layer of EEND-EDA model to enhance the\neffect of self-attention modules using speaker activity information. The\nresults evaluated on public dataset Mini LibriSpeech, demonstrates the\neffectiveness of the work, reducing Diarization Error Rate from 30.95% to\n28.17%. We will release the source code on GitHub to allow further research and\nreproducibility.", "published": "2024-03-21 10:09:46", "link": "http://arxiv.org/abs/2403.14268v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "emoDARTS: Joint Optimisation of CNN & Sequential Neural Network\n  Architectures for Superior Speech Emotion Recognition", "abstract": "Speech Emotion Recognition (SER) is crucial for enabling computers to\nunderstand the emotions conveyed in human communication. With recent\nadvancements in Deep Learning (DL), the performance of SER models has\nsignificantly improved. However, designing an optimal DL architecture requires\nspecialised knowledge and experimental assessments. Fortunately, Neural\nArchitecture Search (NAS) provides a potential solution for automatically\ndetermining the best DL model. The Differentiable Architecture Search (DARTS)\nis a particularly efficient method for discovering optimal models. This study\npresents emoDARTS, a DARTS-optimised joint CNN and Sequential Neural Network\n(SeqNN: LSTM, RNN) architecture that enhances SER performance. The literature\nsupports the selection of CNN and LSTM coupling to improve performance.\n  While DARTS has previously been used to choose CNN and LSTM operations\nindependently, our technique adds a novel mechanism for selecting CNN and SeqNN\noperations in conjunction using DARTS. Unlike earlier work, we do not impose\nlimits on the layer order of the CNN. Instead, we let DARTS choose the best\nlayer order inside the DARTS cell. We demonstrate that emoDARTS outperforms\nconventionally designed CNN-LSTM models and surpasses the best-reported SER\nresults achieved through DARTS on CNN-LSTM by evaluating our approach on the\nIEMOCAP, MSP-IMPROV, and MSP-Podcast datasets.", "published": "2024-03-21 02:26:30", "link": "http://arxiv.org/abs/2403.14083v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Assessing the Robustness of Spectral Clustering for Deep Speaker\n  Diarization", "abstract": "Clustering speaker embeddings is crucial in speaker diarization but hasn't\nreceived as much focus as other components. Moreover, the robustness of speaker\ndiarization across various datasets hasn't been explored when the development\nand evaluation data are from different domains. To bridge this gap, this study\nthoroughly examines spectral clustering for both same-domain and cross-domain\nspeaker diarization. Our extensive experiments on two widely used corpora, AMI\nand DIHARD, reveal the performance trend of speaker diarization in the presence\nof domain mismatch. We observe that the performance difference between two\ndifferent domain conditions can be attributed to the role of spectral\nclustering. In particular, keeping other modules unchanged, we show that\ndifferences in optimal tuning parameters as well as speaker count estimation\noriginates due to the mismatch. This study opens several future directions for\nspeaker diarization research.", "published": "2024-03-21 10:49:54", "link": "http://arxiv.org/abs/2403.14286v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Exploring Green AI for Audio Deepfake Detection", "abstract": "The state-of-the-art audio deepfake detectors leveraging deep neural networks\nexhibit impressive recognition performance. Nonetheless, this advantage is\naccompanied by a significant carbon footprint. This is mainly due to the use of\nhigh-performance computing with accelerators and high training time. Studies\nshow that average deep NLP model produces around 626k lbs of\nCO\\textsubscript{2} which is equivalent to five times of average US car\nemission at its lifetime. This is certainly a massive threat to the\nenvironment. To tackle this challenge, this study presents a novel framework\nfor audio deepfake detection that can be seamlessly trained using standard CPU\nresources. Our proposed framework utilizes off-the-shelve self-supervised\nlearning (SSL) based models which are pre-trained and available in public\nrepositories. In contrast to existing methods that fine-tune SSL models and\nemploy additional deep neural networks for downstream tasks, we exploit\nclassical machine learning algorithms such as logistic regression and shallow\nneural networks using the SSL embeddings extracted using the pre-trained model.\nOur approach shows competitive results compared to the commonly used\nhigh-carbon footprint approaches. In experiments with the ASVspoof 2019 LA\ndataset, we achieve a 0.90\\% equal error rate (EER) with less than 1k trainable\nmodel parameters. To encourage further research in this direction and support\nreproducible results, the Python code will be made publicly accessible\nfollowing acceptance. Github: https://github.com/sahasubhajit/Speech-Spoofing-", "published": "2024-03-21 10:54:21", "link": "http://arxiv.org/abs/2403.14290v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Crowdsourced Multilingual Speech Intelligibility Testing", "abstract": "With the advent of generative audio features, there is an increasing need for\nrapid evaluation of their impact on speech intelligibility. Beyond the existing\nlaboratory measures, which are expensive and do not scale well, there has been\ncomparatively little work on crowdsourced assessment of intelligibility.\nStandards and recommendations are yet to be defined, and publicly available\nmultilingual test materials are lacking. In response to this challenge, we\npropose an approach for a crowdsourced intelligibility assessment. We detail\nthe test design, the collection and public release of the multilingual speech\ndata, and the results of our early experiments.", "published": "2024-03-21 20:14:53", "link": "http://arxiv.org/abs/2403.14817v1", "categories": ["eess.AS", "cs.AI", "eess.SP"], "primary_category": "eess.AS"}
