{"title": "Mixed-Lingual Pre-training for Cross-lingual Summarization", "abstract": "Cross-lingual Summarization (CLS) aims at producing a summary in the target\nlanguage for an article in the source language. Traditional solutions employ a\ntwo-step approach, i.e. translate then summarize or summarize then translate.\nRecently, end-to-end models have achieved better results, but these approaches\nare mostly limited by their dependence on large-scale labeled data. We propose\na solution based on mixed-lingual pre-training that leverages both\ncross-lingual tasks such as translation and monolingual tasks like masked\nlanguage models. Thus, our model can leverage the massive monolingual data to\nenhance its modeling of language. Moreover, the architecture has no\ntask-specific components, which saves memory and increases optimization\nefficiency. We show in experiments that this pre-training scheme can\neffectively boost the performance of cross-lingual summarization. In Neural\nCross-Lingual Summarization (NCLS) dataset, our model achieves an improvement\nof 2.82 (English to Chinese) and 1.15 (Chinese to English) ROUGE-1 scores over\nstate-of-the-art results.", "published": "2020-10-18 00:21:53", "link": "http://arxiv.org/abs/2010.08892v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking Document-level Neural Machine Translation", "abstract": "This paper does not aim at introducing a novel model for document-level\nneural machine translation. Instead, we head back to the original Transformer\nmodel and hope to answer the following question: Is the capacity of current\nmodels strong enough for document-level translation? Interestingly, we observe\nthat the original Transformer with appropriate training techniques can achieve\nstrong results for document translation, even with a length of 2000 words. We\nevaluate this model and several recent approaches on nine document-level\ndatasets and two sentence-level datasets across six languages. Experiments show\nthat document-level Transformer models outperforms sentence-level ones and many\nprevious methods in a comprehensive set of metrics, including BLEU, four\nlexical indices, three newly proposed assistant linguistic indicators, and\nhuman evaluation.", "published": "2020-10-18 11:18:29", "link": "http://arxiv.org/abs/2010.08961v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "hinglishNorm -- A Corpus of Hindi-English Code Mixed Sentences for Text\n  Normalization", "abstract": "We present hinglishNorm -- a human annotated corpus of Hindi-English\ncode-mixed sentences for text normalization task. Each sentence in the corpus\nis aligned to its corresponding human annotated normalized form. To the best of\nour knowledge, there is no corpus of Hindi-English code-mixed sentences for\ntext normalization task that is publicly available. Our work is the first\nattempt in this direction. The corpus contains 13494 parallel segments.\nFurther, we present baseline normalization results on this corpus. We obtain a\nWord Error Rate (WER) of 15.55, BiLingual Evaluation Understudy (BLEU) score of\n71.2, and Metric for Evaluation of Translation with Explicit ORdering (METEOR)\nscore of 0.50.", "published": "2020-10-18 12:21:37", "link": "http://arxiv.org/abs/2010.08974v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Querent Intent in Multi-Sentence Questions", "abstract": "Multi-sentence questions (MSQs) are sequences of questions connected by\nrelations which, unlike sequences of standalone questions, need to be answered\nas a unit. Following Rhetorical Structure Theory (RST), we recognise that\ndifferent \"question discourse relations\" between the subparts of MSQs reflect\ndifferent speaker intents, and consequently elicit different answering\nstrategies. Correctly identifying these relations is therefore a crucial step\nin automatically answering MSQs. We identify five different types of MSQs in\nEnglish, and define five novel relations to describe them. We extract over\n162,000 MSQs from Stack Exchange to enable future research. Finally, we\nimplement a high-precision baseline classifier based on surface features.", "published": "2020-10-18 13:17:09", "link": "http://arxiv.org/abs/2010.08980v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UoB at SemEval-2020 Task 1: Automatic Identification of Novel Word\n  Senses", "abstract": "Much as the social landscape in which languages are spoken shifts, language\ntoo evolves to suit the needs of its users. Lexical semantic change analysis is\na burgeoning field of semantic analysis which aims to trace changes in the\nmeanings of words over time. This paper presents an approach to lexical\nsemantic change detection based on Bayesian word sense induction suitable for\nnovel word sense identification. This approach is used for a submission to\nSemEval-2020 Task 1, which shows the approach to be capable of the SemEval\ntask. The same approach is also applied to a corpus gleaned from 15 years of\nTwitter data, the results of which are then used to identify words which may be\ninstances of slang.", "published": "2020-10-18 19:27:06", "link": "http://arxiv.org/abs/2010.09072v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incorporating Count-Based Features into Pre-Trained Models for Improved\n  Stance Detection", "abstract": "The explosive growth and popularity of Social Media has revolutionised the\nway we communicate and collaborate. Unfortunately, this same ease of accessing\nand sharing information has led to an explosion of misinformation and\npropaganda. Given that stance detection can significantly aid in veracity\nprediction, this work focuses on boosting automated stance detection, a task on\nwhich pre-trained models have been extremely successful on, as on several other\ntasks. This work shows that the task of stance detection can benefit from\nfeature based information, especially on certain under performing classes,\nhowever, integrating such features into pre-trained models using ensembling is\nchallenging. We propose a novel architecture for integrating features with\npre-trained models that address these challenges and test our method on the\nRumourEval 2019 dataset. This method achieves state-of-the-art results with an\nF1-score of 63.94 on the test set.", "published": "2020-10-18 19:37:24", "link": "http://arxiv.org/abs/2010.09078v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Interpreting BERT for Reading Comprehension Based QA", "abstract": "BERT and its variants have achieved state-of-the-art performance in various\nNLP tasks. Since then, various works have been proposed to analyze the\nlinguistic information being captured in BERT. However, the current works do\nnot provide an insight into how BERT is able to achieve near human-level\nperformance on the task of Reading Comprehension based Question Answering. In\nthis work, we attempt to interpret BERT for RCQA. Since BERT layers do not have\npredefined roles, we define a layer's role or functionality using Integrated\nGradients. Based on the defined roles, we perform a preliminary analysis across\nall layers. We observed that the initial layers focus on query-passage\ninteraction, whereas later layers focus more on contextual understanding and\nenhancing the answer prediction. Specifically for quantifier questions (how\nmuch/how many), we notice that BERT focuses on confusing words (i.e., on other\nnumerical quantities in the passage) in the later layers, but still manages to\npredict the answer correctly. The fine-tuning and analysis scripts will be\npublicly available at https://github.com/iitmnlp/BERT-Analysis-RCQA .", "published": "2020-10-18 13:33:49", "link": "http://arxiv.org/abs/2010.08983v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Explaining and Improving Model Behavior with k Nearest Neighbor\n  Representations", "abstract": "Interpretability techniques in NLP have mainly focused on understanding\nindividual predictions using attention visualization or gradient-based saliency\nmaps over tokens. We propose using k nearest neighbor (kNN) representations to\nidentify training examples responsible for a model's predictions and obtain a\ncorpus-level understanding of the model's behavior. Apart from\ninterpretability, we show that kNN representations are effective at uncovering\nlearned spurious associations, identifying mislabeled examples, and improving\nthe fine-tuned model's performance. We focus on Natural Language Inference\n(NLI) as a case study and experiment with multiple datasets. Our method deploys\nbackoff to kNN for BERT and RoBERTa on examples with low model confidence\nwithout any update to the model parameters. Our results indicate that the kNN\napproach makes the finetuned model more robust to adversarial inputs.", "published": "2020-10-18 16:55:25", "link": "http://arxiv.org/abs/2010.09030v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Chart-to-Text: Generating Natural Language Descriptions for Charts by\n  Adapting the Transformer Model", "abstract": "Information visualizations such as bar charts and line charts are very\npopular for exploring data and communicating insights. Interpreting and making\nsense of such visualizations can be challenging for some people, such as those\nwho are visually impaired or have low visualization literacy. In this work, we\nintroduce a new dataset and present a neural model for automatically generating\nnatural language summaries for charts. The generated summaries provide an\ninterpretation of the chart and convey the key insights found within that\nchart. Our neural model is developed by extending the state-of-the-art model\nfor the data-to-text generation task, which utilizes a transformer-based\nencoder-decoder architecture. We found that our approach outperforms the base\nmodel on a content selection metric by a wide margin (55.42% vs. 8.49%) and\ngenerates more informative, concise, and coherent summaries.", "published": "2020-10-18 23:57:33", "link": "http://arxiv.org/abs/2010.09142v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Data Distillation for End-to-end Spoken Conversational Question\n  Answering", "abstract": "In spoken question answering, QA systems are designed to answer questions\nfrom contiguous text spans within the related speech transcripts. However, the\nmost natural way that human seek or test their knowledge is via human\nconversations. Therefore, we propose a new Spoken Conversational Question\nAnswering task (SCQA), aiming at enabling QA systems to model complex dialogues\nflow given the speech utterances and text corpora. In this task, our main\nobjective is to build a QA system to deal with conversational questions both in\nspoken and text forms, and to explore the plausibility of providing more cues\nin spoken documents with systems in information gathering. To this end, instead\nof adopting automatically generated speech transcripts with highly noisy data,\nwe propose a novel unified data distillation approach, DDNet, which directly\nfuse audio-text features to reduce the misalignment between automatic speech\nrecognition hypotheses and the reference transcriptions. In addition, to\nevaluate the capacity of QA systems in a dialogue-style interaction, we\nassemble a Spoken Conversational Question Answering (Spoken-CoQA) dataset with\nmore than 120k question-answer pairs. Experiments demonstrate that our proposed\nmethod achieves superior performance in spoken conversational question\nanswering.", "published": "2020-10-18 05:53:39", "link": "http://arxiv.org/abs/2010.08923v1", "categories": ["cs.CL", "cs.AI", "eess.AS", "eess.SP"], "primary_category": "cs.CL"}
{"title": "Construction and Application of Teaching System Based on Crowdsourcing\n  Knowledge Graph", "abstract": "Through the combination of crowdsourcing knowledge graph and teaching system,\nresearch methods to generate knowledge graph and its applications. Using two\ncrowdsourcing approaches, crowdsourcing task distribution and reverse captcha\ngeneration, to construct knowledge graph in the field of teaching system.\nGenerating a complete hierarchical knowledge graph of the teaching domain by\nnodes of school, student, teacher, course, knowledge point and exercise type.\nThe knowledge graph constructed in a crowdsourcing manner requires many users\nto participate collaboratively with fully consideration of teachers' guidance\nand users' mobilization issues. Based on the three subgraphs of knowledge\ngraph, prominent teacher, student learning situation and suitable learning\nroute could be visualized. Personalized exercises recommendation model is used\nto formulate the personalized exercise by algorithm based on the knowledge\ngraph. Collaborative creation model is developed to realize the crowdsourcing\nconstruction mechanism. Though unfamiliarity with the learning mode of\nknowledge graph and learners' less attention to the knowledge structure, system\nbased on Crowdsourcing Knowledge Graph can still get high acceptance around\nstudents and teachers", "published": "2020-10-18 14:26:10", "link": "http://arxiv.org/abs/2010.08995v1", "categories": ["cs.DB", "cs.AI", "cs.CL"], "primary_category": "cs.DB"}
{"title": "Unsupervised Neural Machine Translation for Low-Resource Domains via\n  Meta-Learning", "abstract": "Unsupervised machine translation, which utilizes unpaired monolingual corpora\nas training data, has achieved comparable performance against supervised\nmachine translation. However, it still suffers from data-scarce domains. To\naddress this issue, this paper presents a novel meta-learning algorithm for\nunsupervised neural machine translation (UNMT) that trains the model to adapt\nto another domain by utilizing only a small amount of training data. We assume\nthat domain-general knowledge is a significant factor in handling data-scarce\ndomains. Hence, we extend the meta-learning algorithm, which utilizes knowledge\nlearned from high-resource domains, to boost the performance of low-resource\nUNMT. Our model surpasses a transfer learning-based approach by up to 2-4 BLEU\nscores. Extensive experimental results show that our proposed algorithm is\npertinent for fast adaptation and consistently outperforms other baseline\nmodels.", "published": "2020-10-18 17:54:13", "link": "http://arxiv.org/abs/2010.09046v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Block Coordinate Descent Algorithms for Auxiliary-Function-Based\n  Independent Vector Extraction", "abstract": "In this paper, we address the problem of extracting all super-Gaussian source\nsignals from a linear mixture in which (i) the number of super-Gaussian sources\n$K$ is less than that of sensors $M$, and (ii) there are up to $M - K$\nstationary Gaussian noises that do not need to be extracted. To solve this\nproblem, independent vector extraction (IVE) using a majorization minimization\nand block coordinate descent (BCD) algorithms has been developed, attaining\nrobust source extraction and low computational cost. We here improve the\nconventional BCDs for IVE by carefully exploiting the stationarity of the\nGaussian noise components. We also newly develop a BCD for a semiblind IVE in\nwhich the transfer functions for several super-Gaussian sources are given a\npriori. Both algorithms consist of a closed-form formula and a generalized\neigenvalue decomposition. In a numerical experiment of extracting speech\nsignals from noisy mixtures, we show that when $K = 1$ in a blind case or at\nleast $K - 1$ transfer functions are given in a semiblind case, the convergence\nof our proposed BCDs is significantly faster than those of the conventional\nones.", "published": "2020-10-18 10:56:27", "link": "http://arxiv.org/abs/2010.08959v2", "categories": ["eess.SP", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Self-Attention Generative Adversarial Network for Speech Enhancement", "abstract": "Existing generative adversarial networks (GANs) for speech enhancement solely\nrely on the convolution operation, which may obscure temporal dependencies\nacross the sequence input. To remedy this issue, we propose a self-attention\nlayer adapted from non-local attention, coupled with the convolutional and\ndeconvolutional layers of a speech enhancement GAN (SEGAN) using raw signal\ninput. Further, we empirically study the effect of placing the self-attention\nlayer at the (de)convolutional layers with varying layer indices as well as at\nall of them when memory allows. Our experiments show that introducing\nself-attention to SEGAN leads to consistent improvement across the objective\nevaluation metrics of enhancement performance. Furthermore, applying at\ndifferent (de)convolutional layers does not significantly alter performance,\nsuggesting that it can be conveniently applied at the highest-level\n(de)convolutional layer with the smallest memory overhead.", "published": "2020-10-18 22:59:07", "link": "http://arxiv.org/abs/2010.09132v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
