{"title": "Learning to Predict Novel Noun-Noun Compounds", "abstract": "We introduce temporally and contextually-aware models for the novel task of\npredicting unseen but plausible concepts, as conveyed by noun-noun compounds in\na time-stamped corpus. We train compositional models on observed compounds,\nmore specifically the composed distributed representations of their\nconstituents across a time-stamped corpus, while giving it corrupted instances\n(where head or modifier are replaced by a random constituent) as negative\nevidence. The model captures generalisations over this data and learns what\ncombinations give rise to plausible compounds and which ones do not. After\ntraining, we query the model for the plausibility of automatically generated\nnovel combinations and verify whether the classifications are accurate. For our\nbest model, we find that in around 85% of the cases, the novel compounds\ngenerated are attested in previously unseen data. An additional estimated 5%\nare plausible despite not being attested in the recent corpus, based on\njudgments from independent human raters.", "published": "2019-06-09 13:12:45", "link": "http://arxiv.org/abs/1906.03634v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Encouraging Paragraph Embeddings to Remember Sentence Identity Improves\n  Classification", "abstract": "While paragraph embedding models are remarkably effective for downstream\nclassification tasks, what they learn and encode into a single vector remains\nopaque. In this paper, we investigate a state-of-the-art paragraph embedding\nmethod proposed by Zhang et al. (2017) and discover that it cannot reliably\ntell whether a given sentence occurs in the input paragraph or not. We\nformulate a sentence content task to probe for this basic linguistic property\nand find that even a much simpler bag-of-words method has no trouble solving\nit. This result motivates us to replace the reconstruction-based objective of\nZhang et al. (2017) with our sentence content probe objective in a\nsemi-supervised setting. Despite its simplicity, our objective improves over\nparagraph reconstruction in terms of (1) downstream classification accuracies\non benchmark datasets, (2) faster training, and (3) better generalization\nability.", "published": "2019-06-09 15:18:53", "link": "http://arxiv.org/abs/1906.03656v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Happy Together: Learning and Understanding Appraisal From Natural\n  Language", "abstract": "In this paper, we explore various approaches for learning two types of\nappraisal components from happy language. We focus on 'agency' of the author\nand the 'sociality' involved in happy moments based on the HappyDB dataset. We\ndevelop models based on deep neural networks for the task, including uni- and\nbi-directional long short-term memory networks, with and without attention. We\nalso experiment with a number of novel embedding methods, such as embedding\nfrom neural machine translation (as in CoVe) and embedding from language models\n(as in ELMo). We compare our results to those acquired by several traditional\nmachine learning methods. Our best models achieve 87.97% accuracy on agency and\n93.13% accuracy on sociality, both of which are significantly higher than our\nbaselines.", "published": "2019-06-09 17:28:37", "link": "http://arxiv.org/abs/1906.03677v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UBC-NLP at SemEval-2019 Task 6:Ensemble Learning of Offensive Content\n  With Enhanced Training Data", "abstract": "We examine learning offensive content on Twitter with limited, imbalanced\ndata. For the purpose, we investigate the utility of using various data\nenhancement methods with a host of classical ensemble classifiers. Among the 75\nparticipating teams in SemEval-2019 sub-task B, our system ranks 6th (with\n0.706 macro F1-score). For sub-task C, among the 65 participating teams, our\nsystem ranks 9th (with 0.587 macro F1-score).", "published": "2019-06-09 19:14:18", "link": "http://arxiv.org/abs/1906.03692v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Argument Generation with Retrieval, Planning, and Realization", "abstract": "Automatic argument generation is an appealing but challenging task. In this\npaper, we study the specific problem of counter-argument generation, and\npresent a novel framework, CANDELA. It consists of a powerful retrieval system\nand a novel two-step generation model, where a text planning decoder first\ndecides on the main talking points and a proper language style for each\nsentence, then a content realization decoder reflects the decisions and\nconstructs an informative paragraph-level argument. Furthermore, our generation\nmodel is empowered by a retrieval system indexed with 12 million articles\ncollected from Wikipedia and popular English news media, which provides access\nto high-quality content with diversity. Automatic evaluation on a large-scale\ndataset collected from Reddit shows that our model yields significantly higher\nBLEU, ROUGE, and METEOR scores than the state-of-the-art and non-trivial\ncomparisons. Human evaluation further indicates that our system arguments are\nmore appropriate for refutation and richer in content.", "published": "2019-06-09 21:39:46", "link": "http://arxiv.org/abs/1906.03717v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is Attention Interpretable?", "abstract": "Attention mechanisms have recently boosted performance on a range of NLP\ntasks. Because attention layers explicitly weight input components'\nrepresentations, it is also often assumed that attention can be used to\nidentify information that models found important (e.g., specific contextualized\nword tokens). We test whether that assumption holds by manipulating attention\nweights in already-trained text classification models and analyzing the\nresulting differences in their predictions. While we observe some ways in which\nhigher attention weights correlate with greater impact on model predictions, we\nalso find many ways in which this does not hold, i.e., where gradient-based\nrankings of attention weights better predict their effects than their\nmagnitudes. We conclude that while attention noisily predicts input components'\noverall importance to a model, it is by no means a fail-safe indicator.", "published": "2019-06-09 22:46:12", "link": "http://arxiv.org/abs/1906.03731v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Neural Network Language Models", "abstract": "As the core component of Natural Language Processing (NLP) system, Language\nModel (LM) can provide word representation and probability indication of word\nsequences. Neural Network Language Models (NNLMs) overcome the curse of\ndimensionality and improve the performance of traditional LMs. A survey on\nNNLMs is performed in this paper. The structure of classic NNLMs is described\nfirstly, and then some major improvements are introduced and analyzed. We\nsummarize and compare corpora and toolkits of NNLMs. Further, some research\ndirections of NNLMs are discussed.", "published": "2019-06-09 08:15:53", "link": "http://arxiv.org/abs/1906.03591v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Probing for Semantic Classes: Diagnosing the Meaning Content of Word\n  Embeddings", "abstract": "Word embeddings typically represent different meanings of a word in a single\nconflated vector. Empirical analysis of embeddings of ambiguous words is\ncurrently limited by the small size of manually annotated resources and by the\nfact that word senses are treated as unrelated individual concepts. We present\na large dataset based on manual Wikipedia annotations and word senses, where\nword senses from different words are related by semantic classes. This is the\nbasis for novel diagnostic tests for an embedding's content: we probe word\nembeddings for semantic classes and analyze the embedding space by classifying\nembeddings into semantic classes. Our main findings are: (i) Information about\na sense is generally represented well in a single-vector embedding - if the\nsense is frequent. (ii) A classifier can accurately predict whether a word is\nsingle-sense or multi-sense, based only on its embedding. (iii) Although rare\nsenses are not well represented in single-vector embeddings, this does not have\nnegative impact on an NLP application whose performance depends on frequent\nsenses.", "published": "2019-06-09 09:45:24", "link": "http://arxiv.org/abs/1906.03608v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Question Answering as Global Reasoning over Semantic Abstractions", "abstract": "We propose a novel method for exploiting the semantic structure of text to\nanswer multiple-choice questions. The approach is especially suitable for\ndomains that require reasoning over a diverse set of linguistic constructs but\nhave limited training data. To address these challenges, we present the first\nsystem, to the best of our knowledge, that reasons over a wide range of\nsemantic abstractions of the text, which are derived using off-the-shelf,\ngeneral-purpose, pre-trained natural language modules such as semantic role\nlabelers, coreference resolvers, and dependency parsers. Representing multiple\nabstractions as a family of graphs, we translate question answering (QA) into a\nsearch for an optimal subgraph that satisfies certain global and local\nproperties. This formulation generalizes several prior structured QA systems.\nOur system, SEMANTICILP, demonstrates strong performance on two domains\nsimultaneously. In particular, on a collection of challenging science QA\ndatasets, it outperforms various state-of-the-art approaches, including neural\nmodels, broad coverage information retrieval, and specialized techniques using\nstructured knowledge bases, by 2%-6%.", "published": "2019-06-09 16:56:31", "link": "http://arxiv.org/abs/1906.03672v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Gendered Pronoun Resolution using BERT and an extractive question\n  answering formulation", "abstract": "The resolution of ambiguous pronouns is a longstanding challenge in Natural\nLanguage Understanding. Recent studies have suggested gender bias among\nstate-of-the-art coreference resolution systems. As an example, Google AI\nLanguage team recently released a gender-balanced dataset and showed that\nperformance of these coreference resolvers is significantly limited on the\ndataset. In this paper, we propose an extractive question answering (QA)\nformulation of pronoun resolution task that overcomes this limitation and shows\nmuch lower gender bias (0.99) on their dataset. This system uses fine-tuned\nrepresentations from the pre-trained BERT model and outperforms the existing\nbaseline by a significant margin (22.2% absolute improvement in F1 score)\nwithout using any hand-engineered features. This QA framework is equally\nperformant even without the knowledge of the candidate antecedents of the\npronoun. An ensemble of QA and BERT-based multiple choice and sequence\nclassification models further improves the F1 (23.3% absolute improvement upon\nthe baseline). This ensemble model was submitted to the shared task for the 1st\nACL workshop on Gender Bias for Natural Language Processing. It ranked 9th on\nthe final official leaderboard. Source code is available at\nhttps://github.com/rakeshchada/corefqa", "published": "2019-06-09 19:25:27", "link": "http://arxiv.org/abs/1906.03695v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "There is no Artificial General Intelligence", "abstract": "The goal of creating Artificial General Intelligence (AGI) -- or in other\nwords of creating Turing machines (modern computers) that can behave in a way\nthat mimics human intelligence -- has occupied AI researchers ever since the\nidea of AI was first proposed. One common theme in these discussions is the\nthesis that the ability of a machine to conduct convincing dialogues with human\nbeings can serve as at least a sufficient criterion of AGI. We argue that this\nvery ability should be accepted also as a necessary condition of AGI, and we\nprovide a description of the nature of human dialogue in particular and of\nhuman language in general against this background. We then argue that it is for\nmathematical reasons impossible to program a machine in such a way that it\ncould master human dialogue behaviour in its full generality. This is (1)\nbecause there are no traditional explicitly designed mathematical models that\ncould be used as a starting point for creating such programs; and (2) because\neven the sorts of automated models generated by using machine learning, which\nhave been used successfully in areas such as machine translation, cannot be\nextended to cope with human dialogue. If this is so, then we can conclude that\na Turing machine also cannot possess AGI, because it fails to fulfil a\nnecessary condition thereof. At the same time, however, we acknowledge the\npotential of Turing machines to master dialogue behaviour in highly restricted\ncontexts, where what is called ``narrow'' AI can still be of considerable\nutility.", "published": "2019-06-09 12:42:23", "link": "http://arxiv.org/abs/1906.05833v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "rVAD: An Unsupervised Segment-Based Robust Voice Activity Detection\n  Method", "abstract": "This paper presents an unsupervised segment-based method for robust voice\nactivity detection (rVAD). The method consists of two passes of denoising\nfollowed by a voice activity detection (VAD) stage. In the first pass,\nhigh-energy segments in a speech signal are detected by using a posteriori\nsignal-to-noise ratio (SNR) weighted energy difference and if no pitch is\ndetected within a segment, the segment is considered as a high-energy noise\nsegment and set to zero. In the second pass, the speech signal is denoised by a\nspeech enhancement method, for which several methods are explored. Next,\nneighbouring frames with pitch are grouped together to form pitch segments, and\nbased on speech statistics, the pitch segments are further extended from both\nends in order to include both voiced and unvoiced sounds and likely non-speech\nparts as well. In the end, a posteriori SNR weighted energy difference is\napplied to the extended pitch segments of the denoised speech signal for\ndetecting voice activity. We evaluate the VAD performance of the proposed\nmethod using two databases, RATS and Aurora-2, which contain a large variety of\nnoise conditions. The rVAD method is further evaluated, in terms of speaker\nverification performance, on the RedDots 2016 challenge database and its\nnoise-corrupted versions. Experiment results show that rVAD is compared\nfavourably with a number of existing methods. In addition, we present a\nmodified version of rVAD where computationally intensive pitch extraction is\nreplaced by computationally efficient spectral flatness calculation. The\nmodified version significantly reduces the computational complexity at the cost\nof moderately inferior VAD performance, which is an advantage when processing a\nlarge amount of data and running on low resource devices. The source code of\nrVAD is made publicly available.", "published": "2019-06-09 07:51:23", "link": "http://arxiv.org/abs/1906.03588v2", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "LSTM Networks Can Perform Dynamic Counting", "abstract": "In this paper, we systematically assess the ability of standard recurrent\nnetworks to perform dynamic counting and to encode hierarchical\nrepresentations. All the neural models in our experiments are designed to be\nsmall-sized networks both to prevent them from memorizing the training sets and\nto visualize and interpret their behaviour at test time. Our results\ndemonstrate that the Long Short-Term Memory (LSTM) networks can learn to\nrecognize the well-balanced parenthesis language (Dyck-$1$) and the shuffles of\nmultiple Dyck-$1$ languages, each defined over different parenthesis-pairs, by\nemulating simple real-time $k$-counter machines. To the best of our knowledge,\nthis work is the first study to introduce the shuffle languages to analyze the\ncomputational power of neural networks. We also show that a single-layer LSTM\nwith only one hidden unit is practically sufficient for recognizing the\nDyck-$1$ language. However, none of our recurrent networks was able to yield a\ngood performance on the Dyck-$2$ language learning task, which requires a model\nto have a stack-like mechanism for recognition.", "published": "2019-06-09 14:30:00", "link": "http://arxiv.org/abs/1906.03648v1", "categories": ["cs.CL", "cs.FL", "cs.LG", "F.4.3; I.2.6; I.2.7"], "primary_category": "cs.CL"}
{"title": "Attention-based Conditioning Methods for External Knowledge Integration", "abstract": "In this paper, we present a novel approach for incorporating external\nknowledge in Recurrent Neural Networks (RNNs). We propose the integration of\nlexicon features into the self-attention mechanism of RNN-based architectures.\nThis form of conditioning on the attention distribution, enforces the\ncontribution of the most salient words for the task at hand. We introduce three\nmethods, namely attentional concatenation, feature-based gating and affine\ntransformation. Experiments on six benchmark datasets show the effectiveness of\nour methods. Attentional feature-based gating yields consistent performance\nimprovement across tasks. Our approach is implemented as a simple add-on module\nfor RNN-based models with minimal computational overhead and can be adapted to\nany deep neural architecture.", "published": "2019-06-09 17:06:28", "link": "http://arxiv.org/abs/1906.03674v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Fine-grained Event Categorization with Heterogeneous Graph Convolutional\n  Networks", "abstract": "Events are happening in real-world and real-time, which can be planned and\norganized occasions involving multiple people and objects. Social media\nplatforms publish a lot of text messages containing public events with\ncomprehensive topics. However, mining social events is challenging due to the\nheterogeneous event elements in texts and explicit and implicit social network\nstructures. In this paper, we design an event meta-schema to characterize the\nsemantic relatedness of social events and build an event-based heterogeneous\ninformation network (HIN) integrating information from external knowledge base,\nand propose a novel Pair-wise Popularity Graph Convolutional Network (PP-GCN)\nbased fine-grained social event categorization model. We propose a\nKnowledgeable meta-paths Instances based social Event Similarity (KIES) between\nevents and build a weighted adjacent matrix as input to the PP-GCN model.\nComprehensive experiments on real data collections are conducted to compare\nvarious social event detection and clustering tasks. Experimental results\ndemonstrate that our proposed framework outperforms other alternative social\nevent categorization techniques.", "published": "2019-06-09 07:08:20", "link": "http://arxiv.org/abs/1906.04580v1", "categories": ["cs.SI", "cs.CL", "stat.ML"], "primary_category": "cs.SI"}
{"title": "Deep Unsupervised Drum Transcription", "abstract": "We introduce DrummerNet, a drum transcription system that is trained in an\nunsupervised manner. DrummerNet does not require any ground-truth transcription\nand, with the data-scalability of deep neural networks, learns from a large\nunlabeled dataset. In DrummerNet, the target drum signal is first passed to a\n(trainable) transcriber, then reconstructed in a (fixed) synthesizer according\nto the transcription estimate. By training the system to minimize the distance\nbetween the input and the output audio signals, the transcriber learns to\ntranscribe without ground truth transcription. Our experiment shows that\nDrummerNet performs favorably compared to many other recent drum transcription\nsystems, both supervised and unsupervised.", "published": "2019-06-09 19:35:55", "link": "http://arxiv.org/abs/1906.03697v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Music Analogy Via Latent Representation Disentanglement", "abstract": "Analogy-making is a key method for computer algorithms to generate both\nnatural and creative music pieces. In general, an analogy is made by partially\ntransferring the music abstractions, i.e., high-level representations and their\nrelationships, from one piece to another; however, this procedure requires\ndisentangling music representations, which usually takes little effort for\nmusicians but is non-trivial for computers. Three sub-problems arise:\nextracting latent representations from the observation, disentangling the\nrepresentations so that each part has a unique semantic interpretation, and\nmapping the latent representations back to actual music. In this paper, we\ncontribute an explicitly-constrained variational autoencoder (EC$^2$-VAE) as a\nunified solution to all three sub-problems. We focus on disentangling the pitch\nand rhythm representations of 8-beat music clips conditioned on chords. In\nproducing music analogies, this model helps us to realize the imaginary\nsituation of \"what if\" a piece is composed using a different pitch contour,\nrhythm pattern, or chord progression by borrowing the representations from\nother pieces. Finally, we validate the proposed disentanglement method using\nobjective measurements and evaluate the analogy examples by a subjective study.", "published": "2019-06-09 12:22:06", "link": "http://arxiv.org/abs/1906.03626v4", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
