{"title": "Mitigating Hallucinations in Large Language Models via Causal Reasoning", "abstract": "Large language models (LLMs) exhibit logically inconsistent hallucinations\nthat appear coherent yet violate reasoning principles, with recent research\nsuggesting an inverse relationship between causal reasoning capabilities and\nsuch hallucinations. However, existing reasoning approaches in LLMs, such as\nChain-of-Thought (CoT) and its graph-based variants, operate at the linguistic\ntoken level rather than modeling the underlying causal relationships between\nvariables, lacking the ability to represent conditional independencies or\nsatisfy causal identification assumptions. To bridge this gap, we introduce\ncausal-DAG construction and reasoning (CDCR-SFT), a supervised fine-tuning\nframework that trains LLMs to explicitly construct variable-level directed\nacyclic graph (DAG) and then perform reasoning over it. Moreover, we present a\ndataset comprising 25,368 samples (CausalDR), where each sample includes an\ninput question, explicit causal DAG, graph-based reasoning trace, and validated\nanswer. Experiments on four LLMs across eight tasks show that CDCR-SFT improves\nthe causal reasoning capability with the state-of-the-art 95.33% accuracy on\nCLADDER (surpassing human performance of 94.8% for the first time) and reduces\nthe hallucination on HaluEval with 10% improvements. It demonstrates that\nexplicit causal structure modeling in LLMs can effectively mitigate logical\ninconsistencies in LLM outputs. Code is available at\nhttps://github.com/MrLYG/CDCR-SFT.", "published": "2025-08-17 20:51:06", "link": "http://arxiv.org/abs/2508.12495v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Structural Sources of Verb Meaning Revisited: Large Language Models Display Syntactic Bootstrapping", "abstract": "Syntactic bootstrapping (Gleitman, 1990) is the hypothesis that children use\nthe syntactic environments in which a verb occurs to learn its meaning. In this\npaper, we examine whether large language models exhibit a similar behavior. We\ndo this by training RoBERTa and GPT-2 on perturbed datasets where syntactic\ninformation is ablated. Our results show that models' verb representation\ndegrades more when syntactic cues are removed than when co-occurrence\ninformation is removed. Furthermore, the representation of mental verbs, for\nwhich syntactic bootstrapping has been shown to be particularly crucial in\nhuman verb learning, is more negatively impacted in such training regimes than\nphysical verbs. In contrast, models' representation of nouns is affected more\nwhen co-occurrences are distorted than when syntax is distorted. In addition to\nreinforcing the important role of syntactic bootstrapping in verb learning, our\nresults demonstrated the viability of testing developmental hypotheses on a\nlarger scale through manipulating the learning environments of large language\nmodels.", "published": "2025-08-17 19:43:49", "link": "http://arxiv.org/abs/2508.12482v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is GPT-OSS Good? A Comprehensive Evaluation of OpenAI's Latest Open Source Models", "abstract": "In August 2025, OpenAI released GPT-OSS models, its first open weight large\nlanguage models since GPT-2 in 2019, comprising two mixture of experts\narchitectures with 120B and 20B parameters. We evaluated both variants against\nsix contemporary open source large language models ranging from 14.7B to 235B\nparameters, representing both dense and sparse designs, across ten benchmarks\ncovering general knowledge, mathematical reasoning, code generation,\nmultilingual understanding, and conversational ability. All models were tested\nin unquantised form under standardised inference settings, with statistical\nvalidation using McNemars test and effect size analysis. Results show that\ngpt-oss-20B consistently outperforms gpt-oss-120B on several benchmarks, such\nas HumanEval and MMLU, despite requiring substantially less memory and energy\nper response. Both models demonstrate mid-tier overall performance within the\ncurrent open source landscape, with relative strength in code generation and\nnotable weaknesses in multilingual tasks. These findings provide empirical\nevidence that scaling in sparse architectures may not yield proportional\nperformance gains, underscoring the need for further investigation into\noptimisation strategies and informing more efficient model selection for future\nopen source deployments.", "published": "2025-08-17 18:25:37", "link": "http://arxiv.org/abs/2508.12461v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LoraxBench: A Multitask, Multilingual Benchmark Suite for 20 Indonesian Languages", "abstract": "As one of the world's most populous countries, with 700 languages spoken,\nIndonesia is behind in terms of NLP progress. We introduce LoraxBench, a\nbenchmark that focuses on low-resource languages of Indonesia and covers 6\ndiverse tasks: reading comprehension, open-domain QA, language inference,\ncausal reasoning, translation, and cultural QA. Our dataset covers 20\nlanguages, with the addition of two formality registers for three languages. We\nevaluate a diverse set of multilingual and region-focused LLMs and found that\nthis benchmark is challenging. We note a visible discrepancy between\nperformance in Indonesian and other languages, especially the low-resource\nones. There is no clear lead when using a region-specific model as opposed to\nthe general multilingual model. Lastly, we show that a change in register\naffects model performance, especially with registers not commonly found in\nsocial media, such as high-level politeness `Krama' Javanese.", "published": "2025-08-17 18:07:57", "link": "http://arxiv.org/abs/2508.12459v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "M3PO: Multimodal-Model-Guided Preference Optimization for Visual Instruction Following", "abstract": "Large Vision-Language Models (LVLMs) hold immense potential for complex\nmultimodal instruction following, yet their development is often hindered by\nthe high cost and inconsistency of human annotation required for effective\nfine-tuning and preference alignment. Traditional supervised fine-tuning (SFT)\nand existing preference optimization methods like RLHF and DPO frequently\nstruggle to efficiently leverage the model's own generation space to identify\nhighly informative \"hard negative\" samples. To address these challenges, we\npropose Multimodal-Model-Guided Preference Optimization (M3PO), a novel and\ndata-efficient method designed to enhance LVLMs' capabilities in visual\ninstruction following. M3PO intelligently selects the most \"learning-valuable\"\npreference sample pairs from a diverse pool of LVLM-generated candidates. This\nselection is driven by a sophisticated mechanism that integrates two crucial\nsignals: a Multimodal Alignment Score (MAS) to assess external quality and the\nmodel's Self-Consistency / Confidence (log-probability) to gauge internal\nbelief. These are combined into a novel M3P-Score, which specifically\nidentifies preferred responses and challenging dispreferred responses that the\nmodel might confidently generate despite being incorrect. These high-quality\npreference pairs are then used for efficient Direct Preference Optimization\n(DPO) fine-tuning on base LVLMs like LLaVA-1.5 (7B/13B) using LoRA. Our\nextensive experiments demonstrate that M3PO consistently outperforms strong\nbaselines, including SFT, simulated RLHF, vanilla DPO, and RM-DPO, across a\ncomprehensive suite of multimodal instruction following benchmarks (MME-Bench,\nPOPE, IFT, Human Pref. Score).", "published": "2025-08-17 18:07:55", "link": "http://arxiv.org/abs/2508.12458v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncovering Emergent Physics Representations Learned In-Context by Large Language Models", "abstract": "Large language models (LLMs) exhibit impressive in-context learning (ICL)\nabilities, enabling them to solve wide range of tasks via textual prompts\nalone. As these capabilities advance, the range of applicable domains continues\nto expand significantly. However, identifying the precise mechanisms or\ninternal structures within LLMs that allow successful ICL across diverse,\ndistinct classes of tasks remains elusive. Physics-based tasks offer a\npromising testbed for probing this challenge. Unlike synthetic sequences such\nas basic arithmetic or symbolic equations, physical systems provide\nexperimentally controllable, real-world data based on structured dynamics\ngrounded in fundamental principles. This makes them particularly suitable for\nstudying the emergent reasoning behaviors of LLMs in a realistic yet tractable\nsetting. Here, we mechanistically investigate the ICL ability of LLMs,\nespecially focusing on their ability to reason about physics. Using a dynamics\nforecasting task in physical systems as a proxy, we evaluate whether LLMs can\nlearn physics in context. We first show that the performance of dynamics\nforecasting in context improves with longer input contexts. To uncover how such\ncapability emerges in LLMs, we analyze the model's residual stream activations\nusing sparse autoencoders (SAEs). Our experiments reveal that the features\ncaptured by SAEs correlate with key physical variables, such as energy. These\nfindings demonstrate that meaningful physical concepts are encoded within LLMs\nduring in-context learning. In sum, our work provides a novel case study that\nbroadens our understanding of how LLMs learn in context.", "published": "2025-08-17 17:49:17", "link": "http://arxiv.org/abs/2508.12448v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adversarial Attacks on VQA-NLE: Exposing and Alleviating Inconsistencies in Visual Question Answering Explanations", "abstract": "Natural language explanations in visual question answering (VQA-NLE) aim to\nmake black-box models more transparent by elucidating their decision-making\nprocesses. However, we find that existing VQA-NLE systems can produce\ninconsistent explanations and reach conclusions without genuinely understanding\nthe underlying context, exposing weaknesses in either their inference pipeline\nor explanation-generation mechanism. To highlight these vulnerabilities, we not\nonly leverage an existing adversarial strategy to perturb questions but also\npropose a novel strategy that minimally alters images to induce contradictory\nor spurious outputs. We further introduce a mitigation method that leverages\nexternal knowledge to alleviate these inconsistencies, thereby bolstering model\nrobustness. Extensive evaluations on two standard benchmarks and two widely\nused VQA-NLE models underscore the effectiveness of our attacks and the\npotential of knowledge-based defenses, ultimately revealing pressing security\nand reliability concerns in current VQA-NLE systems.", "published": "2025-08-17 16:53:10", "link": "http://arxiv.org/abs/2508.12430v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Non-Iterative Symbolic-Aided Chain-of-Thought for Logical Reasoning", "abstract": "This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved\napproach to standard CoT, for logical reasoning in large language models\n(LLMs). The key idea is to integrate lightweight symbolic representations into\nfew-shot prompts, structuring the inference steps with a consistent strategy to\nmake reasoning patterns more explicit within a non-iterative reasoning process.\nBy incorporating these symbolic structures, our method preserves the\ngeneralizability of standard prompting techniques while enhancing the\ntransparency, interpretability, and analyzability of LLM logical reasoning.\nExtensive experiments on four well-known logical reasoning benchmarks --\nProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse\nreasoning scenarios -- demonstrate the effectiveness of the proposed approach,\nparticularly in complex reasoning tasks that require navigating multiple\nconstraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs'\nreasoning capabilities across various model sizes and significantly outperforms\nconventional CoT on three out of four datasets, ProofWriter, ProntoQA, and\nLogicalDeduction.", "published": "2025-08-17 16:32:05", "link": "http://arxiv.org/abs/2508.12425v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "The Cultural Gene of Large Language Models: A Study on the Impact of Cross-Corpus Training on Model Values and Biases", "abstract": "Large language models (LLMs) are deployed globally, yet their underlying\ncultural and ethical assumptions remain underexplored. We propose the notion of\na \"cultural gene\" -- a systematic value orientation that LLMs inherit from\ntheir training corpora -- and introduce a Cultural Probe Dataset (CPD) of 200\nprompts targeting two classic cross-cultural dimensions:\nIndividualism-Collectivism (IDV) and Power Distance (PDI). Using standardized\nzero-shot prompts, we compare a Western-centric model (GPT-4) and an\nEastern-centric model (ERNIE Bot). Human annotation shows significant and\nconsistent divergence across both dimensions. GPT-4 exhibits individualistic\nand low-power-distance tendencies (IDV score approx 1.21; PDI score approx\n-1.05), while ERNIE Bot shows collectivistic and higher-power-distance\ntendencies (IDV approx -0.89; PDI approx 0.76); differences are statistically\nsignificant (p < 0.001). We further compute a Cultural Alignment Index (CAI)\nagainst Hofstede's national scores and find GPT-4 aligns more closely with the\nUSA (e.g., IDV CAI approx 0.91; PDI CAI approx 0.88) whereas ERNIE Bot aligns\nmore closely with China (IDV CAI approx 0.85; PDI CAI approx 0.81). Qualitative\nanalyses of dilemma resolution and authority-related judgments illustrate how\nthese orientations surface in reasoning. Our results support the view that LLMs\nfunction as statistical mirrors of their cultural corpora and motivate\nculturally aware evaluation and deployment to avoid algorithmic cultural\nhegemony.", "published": "2025-08-17 15:54:14", "link": "http://arxiv.org/abs/2508.12411v1", "categories": ["cs.CL", "I.2.7; K.4.1; H.3.3"], "primary_category": "cs.CL"}
{"title": "ZigzagAttention: Efficient Long-Context Inference with Exclusive Retrieval and Streaming Heads", "abstract": "With the rapid development of large language models (LLMs), handling long\ncontext has become one of the vital abilities in LLMs. Such long-context\nability is accompanied by difficulties in deployment, especially due to the\nincreased consumption of KV cache. There is certain work aiming to optimize the\nmemory footprint of KV cache, inspired by the observation that attention heads\ncan be categorized into retrieval heads that are of great significance and\nstreaming heads that are of less significance. Typically, identifying the\nstreaming heads and and waiving the KV cache in the streaming heads would\nlargely reduce the overhead without hurting the performance that much. However,\nsince employing both retrieval and streaming heads in one layer decomposes one\nlarge round of attention computation into two small ones, it may unexpectedly\nbring extra latency on accessing and indexing tensors. Based on this intuition,\nwe impose an important improvement to the identification process of retrieval\nand streaming heads, in which we design a criterion that enforces exclusively\nretrieval or streaming heads gathered in one unique layer. In this way, we\nfurther eliminate the extra latency and only incur negligible performance\ndegradation. Our method named \\textsc{ZigzagAttention} is competitive among\nconsidered baselines owing to reduced latency and comparable performance.", "published": "2025-08-17 15:48:50", "link": "http://arxiv.org/abs/2508.12407v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting Post-Acute Sequelae of SARS-CoV-2 Infection Symptoms from Clinical Notes via Hybrid Natural Language Processing", "abstract": "Accurately and efficiently diagnosing Post-Acute Sequelae of COVID-19 (PASC)\nremains challenging due to its myriad symptoms that evolve over long- and\nvariable-time intervals. To address this issue, we developed a hybrid natural\nlanguage processing pipeline that integrates rule-based named entity\nrecognition with BERT-based assertion detection modules for PASC-symptom\nextraction and assertion detection from clinical notes. We developed a\ncomprehensive PASC lexicon with clinical specialists. From 11 health systems of\nthe RECOVER initiative network across the U.S., we curated 160 intake progress\nnotes for model development and evaluation, and collected 47,654 progress notes\nfor a population-level prevalence study. We achieved an average F1 score of\n0.82 in one-site internal validation and 0.76 in 10-site external validation\nfor assertion detection. Our pipeline processed each note at $2.448\\pm 0.812$\nseconds on average. Spearman correlation tests showed $\\rho >0.83$ for positive\nmentions and $\\rho >0.72$ for negative ones, both with $P <0.0001$. These\ndemonstrate the effectiveness and efficiency of our models and their potential\nfor improving PASC diagnosis.", "published": "2025-08-17 15:43:05", "link": "http://arxiv.org/abs/2508.12405v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Where to Start Alignment? Diffusion Large Language Model May Demand a Distinct Position", "abstract": "Diffusion Large Language Models (dLLMs) have recently emerged as a\ncompetitive non-autoregressive paradigm due to their unique training and\ninference approach. However, there is currently a lack of safety study on this\nnovel architecture. In this paper, we present the first analysis of dLLMs'\nsafety performance and propose a novel safety alignment method tailored to\ntheir unique generation characteristics. Specifically, we identify a critical\nasymmetry between the defender and attacker in terms of security. For the\ndefender, we reveal that the middle tokens of the response, rather than the\ninitial ones, are more critical to the overall safety of dLLM outputs; this\nseems to suggest that aligning middle tokens can be more beneficial to the\ndefender. The attacker, on the contrary, may have limited power to manipulate\nmiddle tokens, as we find dLLMs have a strong tendency towards a sequential\ngeneration order in practice, forcing the attack to meet this distribution and\ndiverting it from influencing the critical middle tokens. Building on this\nasymmetry, we introduce Middle-tOken Safety Alignment (MOSA), a novel method\nthat directly aligns the model's middle generation with safe refusals\nexploiting reinforcement learning. We implement MOSA and compare its security\nperformance against eight attack methods on two benchmarks. We also test the\nutility of MOSA-aligned dLLM on coding, math, and general reasoning. The\nresults strongly prove the superiority of MOSA.", "published": "2025-08-17 15:19:57", "link": "http://arxiv.org/abs/2508.12398v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "MedKGent: A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph", "abstract": "The rapid expansion of medical literature presents growing challenges for\nstructuring and integrating domain knowledge at scale. Knowledge Graphs (KGs)\noffer a promising solution by enabling efficient retrieval, automated\nreasoning, and knowledge discovery. However, current KG construction methods\noften rely on supervised pipelines with limited generalizability or naively\naggregate outputs from Large Language Models (LLMs), treating biomedical\ncorpora as static and ignoring the temporal dynamics and contextual uncertainty\nof evolving knowledge. To address these limitations, we introduce MedKGent, a\nLLM agent framework for constructing temporally evolving medical KGs.\nLeveraging over 10 million PubMed abstracts published between 1975 and 2023, we\nsimulate the emergence of biomedical knowledge via a fine-grained daily time\nseries. MedKGent incrementally builds the KG in a day-by-day manner using two\nspecialized agents powered by the Qwen2.5-32B-Instruct model. The Extractor\nAgent identifies knowledge triples and assigns confidence scores via\nsampling-based estimation, which are used to filter low-confidence extractions\nand inform downstream processing. The Constructor Agent incrementally\nintegrates the retained triples into a temporally evolving graph, guided by\nconfidence scores and timestamps to reinforce recurring knowledge and resolve\nconflicts. The resulting KG contains 156,275 entities and 2,971,384 relational\ntriples. Quality assessments by two SOTA LLMs and three domain experts\ndemonstrate an accuracy approaching 90\\%, with strong inter-rater agreement. To\nevaluate downstream utility, we conduct RAG across seven medical question\nanswering benchmarks using five leading LLMs, consistently observing\nsignificant improvements over non-augmented baselines. Case studies further\ndemonstrate the KG's value in literature-based drug repurposing via\nconfidence-aware causal inference.", "published": "2025-08-17 15:14:03", "link": "http://arxiv.org/abs/2508.12393v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ReaLM: Reflection-Enhanced Autonomous Reasoning with Small Language Models", "abstract": "Small Language Models (SLMs) are a cost-effective alternative to Large\nLanguage Models (LLMs), but often struggle with complex reasoning due to their\nlimited capacity and a tendency to produce mistakes or inconsistent answers\nduring multi-step reasoning. Existing efforts have improved SLM performance,\nbut typically at the cost of one or more of three key aspects: (1) reasoning\ncapability, due to biased supervision that filters out negative reasoning paths\nand limits learning from errors; (2) autonomy, due to over-reliance on\nexternally generated reasoning signals; and (3) generalization, which suffers\nwhen models overfit to teacher-specific patterns. In this paper, we introduce\nReaLM, a reinforcement learning framework for robust and self-sufficient\nreasoning in vertical domains. To enhance reasoning capability, we propose\nMulti-Route Process Verification (MRPV), which contrasts both positive and\nnegative reasoning paths to extract decisive patterns. To reduce reliance on\nexternal guidance and improve autonomy, we introduce Enabling Autonomy via\nAsymptotic Induction (EAAI), a training strategy that gradually fades external\nsignals. To improve generalization, we apply guided chain-of-thought\ndistillation to encode domain-specific rules and expert knowledge into SLM\nparameters, making them part of what the model has learned. Extensive\nexperiments on both vertical and general reasoning tasks demonstrate that ReaLM\nsignificantly improves SLM performance across aspects (1)-(3) above.", "published": "2025-08-17 14:50:23", "link": "http://arxiv.org/abs/2508.12387v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Consensus or Conflict? Fine-Grained Evaluation of Conflicting Answers in Question-Answering", "abstract": "Large Language Models (LLMs) have demonstrated strong performance in question\nanswering (QA) tasks. However, Multi-Answer Question Answering (MAQA), where a\nquestion may have several valid answers, remains challenging. Traditional QA\nsettings often assume consistency across evidences, but MAQA can involve\nconflicting answers. Constructing datasets that reflect such conflicts is\ncostly and labor-intensive, while existing benchmarks often rely on synthetic\ndata, restrict the task to yes/no questions, or apply unverified automated\nannotation. To advance research in this area, we extend the conflict-aware MAQA\nsetting to require models not only to identify all valid answers, but also to\ndetect specific conflicting answer pairs, if any. To support this task, we\nintroduce a novel cost-effective methodology for leveraging fact-checking\ndatasets to construct NATCONFQA, a new benchmark for realistic, conflict-aware\nMAQA, enriched with detailed conflict labels, for all answer pairs. We evaluate\neight high-end LLMs on NATCONFQA, revealing their fragility in handling various\ntypes of conflicts and the flawed strategies they employ to resolve them.", "published": "2025-08-17 12:58:48", "link": "http://arxiv.org/abs/2508.12355v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CarelessWhisper: Turning Whisper into a Causal Streaming Model", "abstract": "Automatic Speech Recognition (ASR) has seen remarkable progress, with models\nlike OpenAI Whisper and NVIDIA Canary achieving state-of-the-art (SOTA)\nperformance in offline transcription. However, these models are not designed\nfor streaming (online or real-time) transcription, due to limitations in their\narchitecture and training methodology. We propose a method to turn the\ntransformer encoder-decoder model into a low-latency streaming model that is\ncareless about future context. We present an analysis explaining why it is not\nstraightforward to convert an encoder-decoder transformer to a low-latency\nstreaming model. Our proposed method modifies the existing (non-causal) encoder\nto a causal encoder by fine-tuning both the encoder and decoder using Low-Rank\nAdaptation (LoRA) and a weakly aligned dataset. We then propose an updated\ninference mechanism that utilizes the fine-tune causal encoder and decoder to\nyield greedy and beam-search decoding, and is shown to be locally optimal.\nExperiments on low-latency chunk sizes (less than 300 msec) show that our\nfine-tuned model outperforms existing non-fine-tuned streaming approaches in\nmost cases, while using a lower complexity. Additionally, we observe that our\ntraining process yields better alignment, enabling a simple method for\nextracting word-level timestamps. We release our training and inference code,\nalong with the fine-tuned models, to support further research and development\nin streaming ASR.", "published": "2025-08-17 09:32:40", "link": "http://arxiv.org/abs/2508.12301v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Incorporating Legal Logic into Deep Learning: An Intelligent Approach to Probation Prediction", "abstract": "Probation is a crucial institution in modern criminal law, embodying the\nprinciples of fairness and justice while contributing to the harmonious\ndevelopment of society. Despite its importance, the current Intelligent\nJudicial Assistant System (IJAS) lacks dedicated methods for probation\nprediction, and research on the underlying factors influencing probation\neligibility remains limited. In addition, probation eligibility requires a\ncomprehensive analysis of both criminal circumstances and remorse. Much of the\nexisting research in IJAS relies primarily on data-driven methodologies, which\noften overlooks the legal logic underpinning judicial decision-making. To\naddress this gap, we propose a novel approach that integrates legal logic into\ndeep learning models for probation prediction, implemented in three distinct\nstages. First, we construct a specialized probation dataset that includes fact\ndescriptions and probation legal elements (PLEs). Second, we design a distinct\nprobation prediction model named the Multi-Task Dual-Theory Probation\nPrediction Model (MT-DT), which is grounded in the legal logic of probation and\nthe \\textit{Dual-Track Theory of Punishment}. Finally, our experiments on the\nprobation dataset demonstrate that the MT-DT model outperforms baseline models,\nand an analysis of the underlying legal logic further validates the\neffectiveness of the proposed approach.", "published": "2025-08-17 08:28:07", "link": "http://arxiv.org/abs/2508.12286v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Question Answering Dataset for Temporal-Sensitive Retrieval-Augmented Generation", "abstract": "We introduce ChronoQA, a large-scale benchmark dataset for Chinese question\nanswering, specifically designed to evaluate temporal reasoning in\nRetrieval-Augmented Generation (RAG) systems. ChronoQA is constructed from over\n300,000 news articles published between 2019 and 2024, and contains 5,176\nhigh-quality questions covering absolute, aggregate, and relative temporal\ntypes with both explicit and implicit time expressions. The dataset supports\nboth single- and multi-document scenarios, reflecting the real-world\nrequirements for temporal alignment and logical consistency. ChronoQA features\ncomprehensive structural annotations and has undergone multi-stage validation,\nincluding rule-based, LLM-based, and human evaluation, to ensure data quality.\nBy providing a dynamic, reliable, and scalable resource, ChronoQA enables\nstructured evaluation across a wide range of temporal tasks, and serves as a\nrobust benchmark for advancing time-sensitive retrieval-augmented question\nanswering systems.", "published": "2025-08-17 08:12:59", "link": "http://arxiv.org/abs/2508.12282v1", "categories": ["cs.CL", "cs.IR", "68T50, 68P20", "I.2.7; H.3.3"], "primary_category": "cs.CL"}
{"title": "Legal$\u0394$: Enhancing Legal Reasoning in LLMs via Reinforcement Learning with Chain-of-Thought Guided Information Gain", "abstract": "Legal Artificial Intelligence (LegalAI) has achieved notable advances in\nautomating judicial decision-making with the support of Large Language Models\n(LLMs). However, existing legal LLMs still struggle to generate reliable and\ninterpretable reasoning processes. They often default to fast-thinking behavior\nby producing direct answers without explicit multi-step reasoning, limiting\ntheir effectiveness in complex legal scenarios that demand rigorous\njustification. To address this challenge, we propose Legal$\\Delta$, a\nreinforcement learning framework designed to enhance legal reasoning through\nchain-of-thought guided information gain. During training, Legal$\\Delta$\nemploys a dual-mode input setup-comprising direct answer and\nreasoning-augmented modes-and maximizes the information gain between them. This\nencourages the model to acquire meaningful reasoning patterns rather than\ngenerating superficial or redundant explanations. Legal$\\Delta$ follows a\ntwo-stage approach: (1) distilling latent reasoning capabilities from a\npowerful Large Reasoning Model (LRM), DeepSeek-R1, and (2) refining reasoning\nquality via differential comparisons, combined with a multidimensional reward\nmechanism that assesses both structural coherence and legal-domain specificity.\nExperimental results on multiple legal reasoning tasks demonstrate that\nLegal$\\Delta$ outperforms strong baselines in both accuracy and\ninterpretability. It consistently produces more robust and trustworthy legal\njudgments without relying on labeled preference data. All code and data will be\nreleased at https://github.com/NEUIR/LegalDelta.", "published": "2025-08-17 08:10:08", "link": "http://arxiv.org/abs/2508.12281v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Self-Execution Benchmark: Measuring LLMs' Attempts to Overcome Their Lack of Self-Execution", "abstract": "Large language models (LLMs) are commonly evaluated on tasks that test their\nknowledge or reasoning abilities. In this paper, we explore a different type of\nevaluation: whether an LLM can predict aspects of its own responses. Since LLMs\nlack the ability to execute themselves, we introduce the Self-Execution\nBenchmark, which measures a model's ability to anticipate properties of its\noutput, such as whether a question will be difficult for it, whether it will\nrefuse to answer, or what kinds of associations it is likely to produce. Our\nexperiments show that models generally perform poorly on this benchmark, and\nthat increased model size or capability does not consistently lead to better\nperformance. These results suggest a fundamental limitation in how LLMs\nrepresent and reason about their own behavior.", "published": "2025-08-17 07:57:58", "link": "http://arxiv.org/abs/2508.12277v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fast, Slow, and Tool-augmented Thinking for LLMs: A Review", "abstract": "Large Language Models (LLMs) have demonstrated remarkable progress in\nreasoning across diverse domains. However, effective reasoning in real-world\ntasks requires adapting the reasoning strategy to the demands of the problem,\nranging from fast, intuitive responses to deliberate, step-by-step reasoning\nand tool-augmented thinking. Drawing inspiration from cognitive psychology, we\npropose a novel taxonomy of LLM reasoning strategies along two knowledge\nboundaries: a fast/slow boundary separating intuitive from deliberative\nprocesses, and an internal/external boundary distinguishing reasoning grounded\nin the model's parameters from reasoning augmented by external tools. We\nsystematically survey recent work on adaptive reasoning in LLMs and categorize\nmethods based on key decision factors. We conclude by highlighting open\nchallenges and future directions toward more adaptive, efficient, and reliable\nLLMs.", "published": "2025-08-17 07:20:32", "link": "http://arxiv.org/abs/2508.12265v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Structuring the Unstructured: A Systematic Review of Text-to-Structure Generation for Agentic AI with a Universal Evaluation Framework", "abstract": "The evolution of AI systems toward agentic operation and context-aware\nretrieval necessitates transforming unstructured text into structured formats\nlike tables, knowledge graphs, and charts. While such conversions enable\ncritical applications from summarization to data mining, current research lacks\na comprehensive synthesis of methodologies, datasets, and metrics. This\nsystematic review examines text-to-structure techniques and the encountered\nchallenges, evaluates current datasets and assessment criteria, and outlines\npotential directions for future research. We also introduce a universal\nevaluation framework for structured outputs, establishing text-to-structure as\nfoundational infrastructure for next-generation AI systems.", "published": "2025-08-17 06:41:40", "link": "http://arxiv.org/abs/2508.12257v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What do Speech Foundation Models Learn? Analysis and Applications", "abstract": "Speech foundation models (SFMs) are designed to serve as general-purpose\nrepresentations for a wide range of speech-processing tasks. The last five\nyears have seen an influx of increasingly successful self-supervised and\nsupervised pre-trained models with impressive performance on various downstream\ntasks.\n  Although the zoo of SFMs continues to grow, our understanding of the\nknowledge they acquire lags behind. This thesis presents a lightweight analysis\nframework using statistical tools and training-free tasks to investigate the\nacoustic and linguistic knowledge encoded in SFM layers. We conduct a\ncomparative study across multiple SFMs and statistical tools. Our study also\nshows that the analytical insights have concrete implications for downstream\ntask performance.\n  The effectiveness of an SFM is ultimately determined by its performance on\nspeech applications. Yet it remains unclear whether the benefits extend to\nspoken language understanding (SLU) tasks that require a deeper understanding\nthan widely studied ones, such as speech recognition. The limited exploration\nof SLU is primarily due to a lack of relevant datasets. To alleviate that, this\nthesis contributes tasks, specifically spoken named entity recognition (NER)\nand named entity localization (NEL), to the Spoken Language Understanding\nEvaluation benchmark. We develop SFM-based approaches for NER and NEL, and find\nthat end-to-end (E2E) models leveraging SFMs can surpass traditional cascaded\n(speech recognition followed by a text model) approaches. Further, we evaluate\nE2E SLU models across SFMs and adaptation strategies to assess the impact on\ntask performance.\n  Collectively, this thesis tackles previously unanswered questions about SFMs,\nproviding tools and datasets to further our understanding and to enable the\ncommunity to make informed design choices for future model development and\nadoption.", "published": "2025-08-17 06:31:34", "link": "http://arxiv.org/abs/2508.12255v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SEA-BED: Southeast Asia Embedding Benchmark", "abstract": "Sentence embeddings are essential for NLP tasks such as semantic search,\nre-ranking, and textual similarity. Although multilingual benchmarks like MMTEB\nbroaden coverage, Southeast Asia (SEA) datasets are scarce and often\nmachine-translated, missing native linguistic properties. With nearly 700\nmillion speakers, the SEA region lacks a region-specific embedding benchmark.\nWe introduce SEA-BED, the first large-scale SEA embedding benchmark with 169\ndatasets across 9 tasks and 10 languages, where 71% are formulated by humans,\nnot machine generation or translation. We address three research questions: (1)\nwhich SEA languages and tasks are challenging, (2) whether SEA languages show\nunique performance gaps globally, and (3) how human vs. machine translations\naffect evaluation. We evaluate 17 embedding models across six studies,\nanalyzing task and language challenges, cross-benchmark comparisons, and\ntranslation trade-offs. Results show sharp ranking shifts, inconsistent model\nperformance among SEA languages, and the importance of human-curated datasets\nfor low-resource languages like Burmese.", "published": "2025-08-17 05:10:40", "link": "http://arxiv.org/abs/2508.12243v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Arabic Multimodal Machine Learning: Datasets, Applications, Approaches, and Challenges", "abstract": "Multimodal Machine Learning (MML) aims to integrate and analyze information\nfrom diverse modalities, such as text, audio, and visuals, enabling machines to\naddress complex tasks like sentiment analysis, emotion recognition, and\nmultimedia retrieval. Recently, Arabic MML has reached a certain level of\nmaturity in its foundational development, making it time to conduct a\ncomprehensive survey. This paper explores Arabic MML by categorizing efforts\nthrough a novel taxonomy and analyzing existing research. Our taxonomy\norganizes these efforts into four key topics: datasets, applications,\napproaches, and challenges. By providing a structured overview, this survey\noffers insights into the current state of Arabic MML, highlighting areas that\nhave not been investigated and critical research gaps. Researchers will be\nempowered to build upon the identified opportunities and address challenges to\nadvance the field.", "published": "2025-08-17 03:59:27", "link": "http://arxiv.org/abs/2508.12227v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction", "abstract": "The construction of brain graphs from functional Magnetic Resonance Imaging\n(fMRI) data plays a crucial role in enabling graph machine learning for\nneuroimaging. However, current practices often rely on rigid pipelines that\noverlook critical data-centric choices in how brain graphs are constructed. In\nthis work, we adopt a Data-Centric AI perspective and systematically define and\nbenchmark a data-centric design space for brain graph construction,\nconstrasting with primarily model-centric prior work. We organize this design\nspace into three stages: temporal signal processing, topology extraction, and\ngraph featurization. Our contributions lie less in novel components and more in\nevaluating how combinations of existing and modified techniques influence\ndownstream performance. Specifically, we study high-amplitude BOLD signal\nfiltering, sparsification and unification strategies for connectivity,\nalternative correlation metrics, and multi-view node and edge features, such as\nincorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets\nshow that thoughtful data-centric configurations consistently improve\nclassification accuracy over standard pipelines. These findings highlight the\ncritical role of upstream data decisions and underscore the importance of\nsystematically exploring the data-centric design space for graph-based\nneuroimaging. Our code is available at\nhttps://github.com/GeQinwen/DataCentricBrainGraphs.", "published": "2025-08-17 23:53:29", "link": "http://arxiv.org/abs/2508.12533v1", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "primary_category": "cs.LG"}
{"title": "Rethinking Safety in LLM Fine-tuning: An Optimization Perspective", "abstract": "Fine-tuning language models is commonly believed to inevitably harm their\nsafety, i.e., refusing to respond to harmful user requests, even when using\nharmless datasets, thus requiring additional safety measures. We challenge this\nbelief through systematic testing, showing that poor optimization choices,\nrather than inherent trade-offs, often cause safety problems, measured as\nharmful responses to adversarial prompts. By properly selecting key training\nhyper-parameters, e.g., learning rate, batch size, and gradient steps, we\nreduce unsafe model responses from 16\\% to approximately 5\\%, as measured by\nkeyword matching, while maintaining utility performance. Based on this\nobservation, we propose a simple exponential moving average (EMA) momentum\ntechnique in parameter space that preserves safety performance by creating a\nstable optimization path and retains the original pre-trained model's safety\nproperties. Our experiments on the Llama families across multiple datasets\n(Dolly, Alpaca, ORCA) demonstrate that safety problems during fine-tuning can\nlargely be avoided without specialized interventions, outperforming existing\napproaches that require additional safety data while offering practical\nguidelines for maintaining both model performance and safety during adaptation.", "published": "2025-08-17 23:46:36", "link": "http://arxiv.org/abs/2508.12531v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "An Initial Study of Bird's-Eye View Generation for Autonomous Vehicles using Cross-View Transformers", "abstract": "Bird's-Eye View (BEV) maps provide a structured, top-down abstraction that is\ncrucial for autonomous-driving perception. In this work, we employ Cross-View\nTransformers (CVT) for learning to map camera images to three BEV's channels -\nroad, lane markings, and planned trajectory - using a realistic simulator for\nurban driving. Our study examines generalization to unseen towns, the effect of\ndifferent camera layouts, and two loss formulations (focal and L1). Using\ntraining data from only a town, a four-camera CVT trained with the L1 loss\ndelivers the most robust test performance, evaluated in a new town. Overall,\nour results underscore CVT's promise for mapping camera inputs to reasonably\naccurate BEV maps.", "published": "2025-08-17 23:05:00", "link": "http://arxiv.org/abs/2508.12520v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "An Introduction to Sliced Optimal Transport", "abstract": "Sliced Optimal Transport (SOT) is a rapidly developing branch of optimal\ntransport (OT) that exploits the tractability of one-dimensional OT problems.\nBy combining tools from OT, integral geometry, and computational statistics,\nSOT enables fast and scalable computation of distances, barycenters, and\nkernels for probability measures, while retaining rich geometric structure.\nThis paper provides a comprehensive review of SOT, covering its mathematical\nfoundations, methodological advances, computational methods, and applications.\nWe discuss key concepts of OT and one-dimensional OT, the role of tools from\nintegral geometry such as Radon transform in projecting measures, and\nstatistical techniques for estimating sliced distances. The paper further\nexplores recent methodological advances, including non-linear projections,\nimproved Monte Carlo approximations, statistical estimation techniques for\none-dimensional optimal transport, weighted slicing techniques, and\ntransportation plan estimation methods. Variational problems, such as minimum\nsliced Wasserstein estimation, barycenters, gradient flows, kernel\nconstructions, and embeddings are examined alongside extensions to unbalanced,\npartial, multi-marginal, and Gromov-Wasserstein settings. Applications span\nmachine learning, statistics, computer graphics and computer visions,\nhighlighting SOT's versatility as a practical computational tool. This work\nwill be of interest to researchers and practitioners in machine learning, data\nsciences, and computational disciplines seeking efficient alternatives to\nclassical OT.", "published": "2025-08-17 22:53:19", "link": "http://arxiv.org/abs/2508.12519v1", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.CO", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Design and Validation of a Responsible Artificial Intelligence-based System for the Referral of Diabetic Retinopathy Patients", "abstract": "Diabetic Retinopathy (DR) is a leading cause of vision loss in working-age\nindividuals. Early detection of DR can reduce the risk of vision loss by up to\n95%, but a shortage of retinologists and challenges in timely examination\ncomplicate detection. Artificial Intelligence (AI) models using retinal fundus\nphotographs (RFPs) offer a promising solution. However, adoption in clinical\nsettings is hindered by low-quality data and biases that may lead AI systems to\nlearn unintended features. To address these challenges, we developed RAIS-DR, a\nResponsible AI System for DR screening that incorporates ethical principles\nacross the AI lifecycle. RAIS-DR integrates efficient convolutional models for\npreprocessing, quality assessment, and three specialized DR classification\nmodels. We evaluated RAIS-DR against the FDA-approved EyeArt system on a local\ndataset of 1,046 patients, unseen by both systems. RAIS-DR demonstrated\nsignificant improvements, with F1 scores increasing by 5-12%, accuracy by\n6-19%, and specificity by 10-20%. Additionally, fairness metrics such as\nDisparate Impact and Equal Opportunity Difference indicated equitable\nperformance across demographic subgroups, underscoring RAIS-DR's potential to\nreduce healthcare disparities. These results highlight RAIS-DR as a robust and\nethically aligned solution for DR screening in clinical settings. The code,\nweights of RAIS-DR are available at\nhttps://gitlab.com/inteligencia-gubernamental-jalisco/jalisco-retinopathy with\nRAIL.", "published": "2025-08-17 21:54:11", "link": "http://arxiv.org/abs/2508.12506v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models", "abstract": "Molecular dynamics simulations (MDS) face challenges, including\nresource-heavy computations and the need to manually scan outputs to detect\n\"interesting events,\" such as the formation and persistence of hydrogen bonds\nbetween atoms of different molecules. A critical research gap lies in\nidentifying the underlying causes of hydrogen bond formation and separation\n-understanding which interactions or prior events contribute to their emergence\nover time. With this challenge in mind, we propose leveraging spatio-temporal\ndata analytics and machine learning models to enhance the detection of these\nphenomena. In this paper, our approach is inspired by causal modeling and aims\nto identify the root cause variables of hydrogen bond formation and separation\nevents. Specifically, we treat the separation of hydrogen bonds as an\n\"intervention\" occurring and represent the causal structure of the bonding and\nseparation events in the MDS as graphical causal models. These causal models\nare built using a variational autoencoder-inspired architecture that enables us\nto infer causal relationships across samples with diverse underlying causal\ngraphs while leveraging shared dynamic information. We further include a step\nto infer the root causes of changes in the joint distribution of the causal\nmodels. By constructing causal models that capture shifts in the conditional\ndistributions of molecular interactions during bond formation or separation,\nthis framework provides a novel perspective on root cause analysis in molecular\ndynamic systems. We validate the efficacy of our model empirically on the\natomic trajectories that used MDS for chiral separation, demonstrating that we\ncan predict many steps in the future and also find the variables driving the\nobserved changes in the system.", "published": "2025-08-17 21:23:12", "link": "http://arxiv.org/abs/2508.12500v1", "categories": ["cs.AI", "cs.LG", "q-bio.QM"], "primary_category": "cs.AI"}
{"title": "Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework", "abstract": "This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that\nuses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index\n(BIS), keeping it within the ideal range of forty to sixty. The FOFPID\ncontroller combines fuzzy logic for adapting to changes and fractional order\ndynamics for fine tuning. This allows it to adjust its control gains to handle\na person's unique physiology. The WOA helps fine tune the controller's\nparameters, including the fractional orders and the fuzzy membership functions,\nwhich boosts its performance. Tested on models of eight different patient\nprofiles, the FOFPID controller performed better than a standard Fractional\nOrder PID (FOPID) controller. It achieved faster settling times, at two and a\nhalf minutes versus three point two minutes, and had a lower steady state\nerror, at zero point five versus one point two. These outcomes show the\nFOFPID's excellent strength and accuracy. It offers a scalable, artificial\nintelligence driven solution for automated anesthesia delivery that could\nenhance clinical practice and improve patient results.", "published": "2025-08-17 20:01:49", "link": "http://arxiv.org/abs/2508.12487v1", "categories": ["cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX", "abstract": "Web proxies such as NGINX commonly rely on least-recently-used (LRU)\neviction, which is size agnostic and can thrash under periodic bursts and mixed\nobject sizes. We introduce Cold-RL, a learned eviction policy for NGINX that\nreplaces LRU's forced-expire path with a dueling Deep Q-Network served by an\nONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL\nsamples the K least-recently-used objects, extracts six lightweight features\n(age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT),\nand requests a bitmask of victims; a hard timeout of 500 microseconds triggers\nimmediate fallback to native LRU. Policies are trained offline by replaying\nNGINX access logs through a cache simulator with a simple reward: a retained\nobject earns one point if it is hit again before TTL expiry. We compare against\nLRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial\nworkloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538,\na 146 percent improvement over the best classical baseline; at 100 MB, from\n0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods\n(about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th\npercentile eviction latency within budget. To our knowledge, this is the first\nreinforcement learning eviction policy integrated into NGINX with strict SLOs.", "published": "2025-08-17 20:01:12", "link": "http://arxiv.org/abs/2508.12485v1", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.NI", "C.2.4; C.4; D.4.2; I.2.6"], "primary_category": "cs.LG"}
{"title": "The Yokai Learning Environment: Tracking Beliefs Over Space and Time", "abstract": "Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to\nreason about the beliefs of others to build and maintain common ground.\nExisting ToM benchmarks, however, are restricted to passive observer settings\nor lack an assessment of how agents establish and maintain common ground over\ntime. To address these gaps, we introduce the Yokai Learning Environment (YLE)\n- a multi-agent reinforcement learning (RL) environment based on the\ncooperative card game Yokai. In the YLE, agents take turns peeking at hidden\ncards and moving them to form clusters based on colour. Success requires\ntracking evolving beliefs, remembering past observations, using hints as\ngrounded communication, and maintaining common ground with teammates. Our\nevaluation yields two key findings: First, current RL agents struggle to solve\nthe YLE, even when given access to perfect memory. Second, while belief\nmodelling improves performance, agents are still unable to effectively\ngeneralise to unseen partners or form accurate beliefs over longer games,\nexposing a reliance on brittle conventions rather than robust belief tracking.\nWe use the YLE to investigate research questions in belief modelling, memory,\npartner generalisation, and scaling to higher-order ToM.", "published": "2025-08-17 19:42:17", "link": "http://arxiv.org/abs/2508.12480v1", "categories": ["cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "EXOTIC: An Exact, Optimistic, Tree-Based Algorithm for Min-Max Optimization", "abstract": "Min-max optimization arises in many domains such as game theory, adversarial\nmachine learning, etc., with gradient-based methods as a typical computational\ntool. Beyond convex-concave min-max optimization, the solutions found by\ngradient-based methods may be arbitrarily far from global optima. In this work,\nwe present an algorithmic apparatus for computing globally optimal solutions in\nconvex-non-concave and non-convex-concave min-max optimization. For former, we\nemploy a reformulation that transforms it into a non-concave-convex max-min\noptimization problem with suitably defined feasible sets and objective\nfunction. The new form can be viewed as a generalization of Sion's minimax\ntheorem. Next, we introduce EXOTIC-an Exact, Optimistic, Tree-based algorithm\nfor solving the reformulated max-min problem. EXOTIC employs an iterative\nconvex optimization solver to (approximately) solve the inner minimization and\na hierarchical tree search for the outer maximization to optimistically select\npromising regions to search based on the approximate solution returned by\nconvex optimization solver. We establish an upper bound on its optimality gap\nas a function of the number of calls to the inner solver, the solver's\nconvergence rate, and additional problem-dependent parameters. Both our\nalgorithmic apparatus along with its accompanying theoretical analysis can also\nbe applied for non-convex-concave min-max optimization. In addition, we propose\na class of benchmark convex-non-concave min-max problems along with their\nanalytical global solutions, providing a testbed for evaluating algorithms for\nmin-max optimization. Empirically, EXOTIC outperforms gradient-based methods on\nthis benchmark as well as on existing numerical benchmark problems from the\nliterature. Finally, we demonstrate the utility of EXOTIC by computing security\nstrategies in multi-player games with three or more players.", "published": "2025-08-17 19:39:19", "link": "http://arxiv.org/abs/2508.12479v1", "categories": ["math.OC", "cs.AI", "cs.GT", "cs.MA", "econ.GN", "q-fin.EC", "90C26, 90C47, 68Q32, 91A06, 65K05"], "primary_category": "math.OC"}
{"title": "Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System", "abstract": "Accurate assessment of neuromuscular reflexes, such as the H-reflex, plays a\ncritical role in sports science, rehabilitation, and clinical neurology.\nTraditional analysis of H-reflex EMG waveforms is subject to variability and\ninterpretation bias among clinicians and researchers, limiting reliability and\nstandardization. To address these challenges, we propose a Fine-Tuned\nVision-Language Model (VLM) Consortium and a reasoning Large-Language Model\n(LLM)-enabled Decision Support System for automated H-reflex waveform\ninterpretation and diagnosis. Our approach leverages multiple VLMs, each\nfine-tuned on curated datasets of H-reflex EMG waveform images annotated with\nclinical observations, recovery timelines, and athlete metadata. These models\nare capable of extracting key electrophysiological features and predicting\nneuromuscular states, including fatigue, injury, and recovery, directly from\nEMG images and contextual metadata. Diagnostic outputs from the VLM consortium\nare aggregated using a consensus-based method and refined by a specialized\nreasoning LLM, which ensures robust, transparent, and explainable decision\nsupport for clinicians and sports scientists. The end-to-end platform\norchestrates seamless communication between the VLM ensemble and the reasoning\nLLM, integrating prompt engineering strategies and automated reasoning\nworkflows using LLM Agents. Experimental results demonstrate that this hybrid\nsystem delivers highly accurate, consistent, and interpretable H-reflex\nassessments, significantly advancing the automation and standardization of\nneuromuscular diagnostics. To our knowledge, this work represents the first\nintegration of a fine-tuned VLM consortium with a reasoning LLM for image-based\nH-reflex analysis, laying the foundation for next-generation AI-assisted\nneuromuscular assessment and athlete monitoring platforms.", "published": "2025-08-17 19:13:27", "link": "http://arxiv.org/abs/2508.12473v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?", "abstract": "Root cause analysis (RCA) in microservice systems is challenging, requiring\non-call engineers to rapidly diagnose failures across heterogeneous telemetry\nsuch as metrics, logs, and traces. Traditional RCA methods often focus on\nsingle modalities or merely rank suspect services, falling short of providing\nactionable diagnostic insights with remediation guidance. This paper introduces\nGALA, a novel multi-modal framework that combines statistical causal inference\nwith LLM-driven iterative reasoning for enhanced RCA. Evaluated on an\nopen-source benchmark, GALA achieves substantial improvements over\nstate-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM\nevaluation score shows GALA generates significantly more causally sound and\nactionable diagnostic outputs than existing methods. Through comprehensive\nexperiments and a case study, we show that GALA bridges the gap between\nautomated failure diagnosis and practical incident resolution by providing both\naccurate root cause identification and human-interpretable remediation\nguidance.", "published": "2025-08-17 19:12:05", "link": "http://arxiv.org/abs/2508.12472v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Toward Architecture-Agnostic Local Control of Posterior Collapse in VAEs", "abstract": "Variational autoencoders (VAEs), one of the most widely used generative\nmodels, are known to suffer from posterior collapse, a phenomenon that reduces\nthe diversity of generated samples. To avoid posterior collapse, many prior\nworks have tried to control the influence of regularization loss. However, the\ntrade-off between reconstruction and regularization is not satisfactory. For\nthis reason, several methods have been proposed to guarantee latent\nidentifiability, which is the key to avoiding posterior collapse. However, they\nrequire structural constraints on the network architecture. For further\nclarification, we define local posterior collapse to reflect the importance of\nindividual sample points in the data space and to relax the network constraint.\nThen, we propose Latent Reconstruction(LR) loss, which is inspired by\nmathematical properties of injective and composite functions, to control\nposterior collapse without restriction to a specific architecture. We\nexperimentally evaluate our approach, which controls posterior collapse on\nvaried datasets such as MNIST, fashionMNIST, Omniglot, CelebA, and FFHQ.", "published": "2025-08-17 23:45:41", "link": "http://arxiv.org/abs/2508.12530v1", "categories": ["cs.LG", "cs.CV", "stat.ML", "I.2.6"], "primary_category": "cs.LG"}
{"title": "MuSACo: Multimodal Subject-Specific Selection and Adaptation for Expression Recognition with Co-Training", "abstract": "Personalized expression recognition (ER) involves adapting a machine learning\nmodel to subject-specific data for improved recognition of expressions with\nconsiderable interpersonal variability. Subject-specific ER can benefit\nsignificantly from multi-source domain adaptation (MSDA) methods, where each\ndomain corresponds to a specific subject, to improve model accuracy and\nrobustness. Despite promising results, state-of-the-art MSDA approaches often\noverlook multimodal information or blend sources into a single domain, limiting\nsubject diversity and failing to explicitly capture unique subject-specific\ncharacteristics. To address these limitations, we introduce MuSACo, a\nmulti-modal subject-specific selection and adaptation method for ER based on\nco-training. It leverages complementary information across multiple modalities\nand multiple source domains for subject-specific adaptation. This makes MuSACo\nparticularly relevant for affective computing applications in digital health,\nsuch as patient-specific assessment for stress or pain, where subject-level\nnuances are crucial. MuSACo selects source subjects relevant to the target and\ngenerates pseudo-labels using the dominant modality for class-aware learning,\nin conjunction with a class-agnostic loss to learn from less confident target\nsamples. Finally, source features from each modality are aligned, while only\nconfident target features are combined. Our experimental results on challenging\nmultimodal ER datasets: BioVid and StressID, show that MuSACo can outperform\nUDA (blending) and state-of-the-art MSDA methods.", "published": "2025-08-17 23:08:21", "link": "http://arxiv.org/abs/2508.12522v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LangVision-LoRA-NAS: Neural Architecture Search for Variable LoRA Rank in Vision Language Models", "abstract": "Vision Language Models (VLMs) integrate visual and text modalities to enable\nmultimodal understanding and generation. These models typically combine a\nVision Transformer (ViT) as an image encoder and a Large Language Model (LLM)\nfor text generation. LoRA (Low-Rank Adaptation) is an efficient fine-tuning\nmethod to adapt pre-trained models to new tasks by introducing low-rank updates\nto their weights. While LoRA has emerged as a powerful technique for\nfine-tuning large models by introducing low-rank updates, current\nimplementations assume a fixed rank, potentially limiting flexibility and\nefficiency across diverse tasks. This paper introduces\n\\textit{LangVision-LoRA-NAS}, a novel framework that integrates Neural\nArchitecture Search (NAS) with LoRA to optimize VLMs for variable-rank\nadaptation. Our approach leverages NAS to dynamically search for the optimal\nLoRA rank configuration tailored to specific multimodal tasks, balancing\nperformance and computational efficiency. Through extensive experiments using\nthe LLaMA-3.2-11B model on several datasets, LangVision-LoRA-NAS demonstrates\nnotable improvement in model performance while reducing fine-tuning costs. Our\nBase and searched fine-tuned models on LLaMA-3.2-11B-Vision-Instruct can be\nfound\n\\href{https://huggingface.co/collections/krishnateja95/llama-32-11b-vision-instruct-langvision-lora-nas-6786cac480357a6a6fcc59ee}{\\textcolor{blue}{here}}\nand the code for LangVision-LoRA-NAS can be found\n\\href{https://github.com/krishnateja95/LangVision-NAS}{\\textcolor{blue}{here}}.", "published": "2025-08-17 22:19:02", "link": "http://arxiv.org/abs/2508.12512v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Segmenting Thalamic Nuclei: T1 Maps Provide a Reliable and Efficient Solution", "abstract": "Accurate thalamic nuclei segmentation is crucial for understanding\nneurological diseases, brain functions, and guiding clinical interventions.\nHowever, the optimal inputs for segmentation remain unclear. This study\nsystematically evaluates multiple MRI contrasts, including MPRAGE and FGATIR\nsequences, quantitative PD and T1 maps, and multiple T1-weighted images at\ndifferent inversion times (multi-TI), to determine the most effective inputs.\nFor multi-TI images, we employ a gradient-based saliency analysis with Monte\nCarlo dropout and propose an Overall Importance Score to select the images\ncontributing most to segmentation. A 3D U-Net is trained on each of these\nconfigurations. Results show that T1 maps alone achieve strong quantitative\nperformance and superior qualitative outcomes, while PD maps offer no added\nvalue. These findings underscore the value of T1 maps as a reliable and\nefficient input among the evaluated options, providing valuable guidance for\noptimizing imaging protocols when thalamic structures are of clinical or\nresearch interest.", "published": "2025-08-17 21:59:28", "link": "http://arxiv.org/abs/2508.12508v1", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "primary_category": "eess.IV"}
{"title": "Skin Cancer Classification: Hybrid CNN-Transformer Models with KAN-Based Fusion", "abstract": "Skin cancer classification is a crucial task in medical image analysis, where\nprecise differentiation between malignant and non-malignant lesions is\nessential for early diagnosis and treatment. In this study, we explore\nSequential and Parallel Hybrid CNN-Transformer models with Convolutional\nKolmogorov-Arnold Network (CKAN). Our approach integrates transfer learning and\nextensive data augmentation, where CNNs extract local spatial features,\nTransformers model global dependencies, and CKAN facilitates nonlinear feature\nfusion for improved representation learning. To assess generalization, we\nevaluate our models on multiple benchmark datasets (HAM10000,BCN20000 and\nPAD-UFES) under varying data distributions and class imbalances. Experimental\nresults demonstrate that hybrid CNN-Transformer architectures effectively\ncapture both spatial and contextual features, leading to improved\nclassification performance. Additionally, the integration of CKAN enhances\nfeature fusion through learnable activation functions, yielding more\ndiscriminative representations. Our proposed approach achieves competitive\nperformance in skin cancer classification, demonstrating 92.81% accuracy and\n92.47% F1-score on the HAM10000 dataset, 97.83% accuracy and 97.83% F1-score on\nthe PAD-UFES dataset, and 91.17% accuracy with 91.79% F1- score on the BCN20000\ndataset highlighting the effectiveness and generalizability of our model across\ndiverse datasets. This study highlights the significance of feature\nrepresentation and model design in advancing robust and accurate medical image\nclassification.", "published": "2025-08-17 19:57:34", "link": "http://arxiv.org/abs/2508.12484v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mechanical Automation with Vision: A Design for Rubik's Cube Solver", "abstract": "The core mechanical system is built around three stepper motors for physical\nmanipulation, a microcontroller for hardware control, a camera and YOLO\ndetection model for real-time cube state detection. A significant software\ncomponent is the development of a user-friendly graphical user interface (GUI)\ndesigned in Unity. The initial state after detection from real-time YOLOv8\nmodel (Precision 0.98443, Recall 0.98419, Box Loss 0.42051, Class Loss 0.2611)\nis virtualized on GUI. To get the solution, the system employs the Kociemba's\nalgorithm while physical manipulation with a single degree of freedom is done\nby combination of stepper motors' interaction with the cube achieving the\naverage solving time of ~2.2 minutes.", "published": "2025-08-17 18:49:46", "link": "http://arxiv.org/abs/2508.12469v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping", "abstract": "Traditional multimodal learning approaches require expensive alignment\npre-training to bridge vision and language modalities, typically projecting\nvisual features into discrete text token spaces. We challenge both fundamental\nassumptions underlying this paradigm by proposing Inverse-LLaVA, a novel\napproach that eliminates alignment pre-training entirely while inverting the\nconventional mapping direction. Rather than projecting visual features to text\nspace, our method maps text embeddings into continuous visual representation\nspace and performs fusion within transformer intermediate layers. Through\nselective additive components in attention mechanisms, we enable dynamic\nintegration of visual and textual representations without requiring massive\nimage-text alignment datasets. Comprehensive experiments across nine multimodal\nbenchmarks demonstrate nuanced performance trade-offs: Inverse-LLaVA achieves\nnotable improvements on reasoning-intensive and cognitive tasks (MM-VET: +0.2%,\nVizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%), while showing\nexpected decreases in perception tasks requiring memorized visual-text\nassociations (celebrity recognition: -49.5%, OCR: -21.3%). These results\nprovide the first empirical evidence that alignment pre-training is not\nnecessary for effective multimodal learning, particularly for complex reasoning\ntasks. Our work establishes the feasibility of a new paradigm that reduces\ncomputational requirements by 45%, challenges conventional wisdom about\nmodality fusion, and opens new research directions for efficient multimodal\narchitectures that preserve modality-specific characteristics. Our project\nwebsite with code and additional resources is available at\nhttps://inverse-llava.github.io.", "published": "2025-08-17 18:36:04", "link": "http://arxiv.org/abs/2508.12466v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "X-Ray-CoT: Interpretable Chest X-ray Diagnosis with Vision-Language Models via Chain-of-Thought Reasoning", "abstract": "Chest X-ray imaging is crucial for diagnosing pulmonary and cardiac diseases,\nyet its interpretation demands extensive clinical experience and suffers from\ninter-observer variability. While deep learning models offer high diagnostic\naccuracy, their black-box nature hinders clinical adoption in high-stakes\nmedical settings. To address this, we propose X-Ray-CoT (Chest X-Ray\nChain-of-Thought), a novel framework leveraging Vision-Language Large Models\n(LVLMs) for intelligent chest X-ray diagnosis and interpretable report\ngeneration. X-Ray-CoT simulates human radiologists' \"chain-of-thought\" by first\nextracting multi-modal features and visual concepts, then employing an\nLLM-based component with a structured Chain-of-Thought prompting strategy to\nreason and produce detailed natural language diagnostic reports. Evaluated on\nthe CORDA dataset, X-Ray-CoT achieves competitive quantitative performance,\nwith a Balanced Accuracy of 80.52% and F1 score of 78.65% for disease\ndiagnosis, slightly surpassing existing black-box models. Crucially, it\nuniquely generates high-quality, explainable reports, as validated by\npreliminary human evaluations. Our ablation studies confirm the integral role\nof each proposed component, highlighting the necessity of multi-modal fusion\nand CoT reasoning for robust and transparent medical AI. This work represents a\nsignificant step towards trustworthy and clinically actionable AI systems in\nmedical imaging.", "published": "2025-08-17 18:00:41", "link": "http://arxiv.org/abs/2508.12455v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FractMorph: A Fractional Fourier-Based Multi-Domain Transformer for Deformable Image Registration", "abstract": "Deformable image registration (DIR) is a crucial and challenging technique\nfor aligning anatomical structures in medical images and is widely applied in\ndiverse clinical applications. However, existing approaches often struggle to\ncapture fine-grained local deformations and large-scale global deformations\nsimultaneously within a unified framework. We present FractMorph, a novel 3D\ndual-parallel transformer-based architecture that enhances cross-image feature\nmatching through multi-domain fractional Fourier transform (FrFT) branches.\nEach Fractional Cross-Attention (FCA) block applies parallel FrFTs at\nfractional angles of 0{\\deg}, 45{\\deg}, 90{\\deg}, along with a log-magnitude\nbranch, to effectively extract local, semi-global, and global features at the\nsame time. These features are fused via cross-attention between the fixed and\nmoving image streams. A lightweight U-Net style network then predicts a dense\ndeformation field from the transformer-enriched features. On the ACDC cardiac\nMRI dataset, FractMorph achieves state-of-the-art performance with an overall\nDice Similarity Coefficient (DSC) of 86.45%, an average per-structure DSC of\n75.15%, and a 95th-percentile Hausdorff distance (HD95) of 1.54 mm on our data\nsplit. We also introduce FractMorph-Light, a lightweight variant of our model\nwith only 29.6M parameters, which maintains the superior accuracy of the main\nmodel while using approximately half the memory. Our results demonstrate that\nmulti-domain spectral-spatial attention in transformers can robustly and\nefficiently model complex non-rigid deformations in medical images using a\nsingle end-to-end network, without the need for scenario-specific tuning or\nhierarchical multi-scale networks. The source code of our implementation is\navailable at https://github.com/shayankebriti/FractMorph.", "published": "2025-08-17 17:42:10", "link": "http://arxiv.org/abs/2508.12445v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Express4D: Expressive, Friendly, and Extensible 4D Facial Motion Generation Benchmark", "abstract": "Dynamic facial expression generation from natural language is a crucial task\nin Computer Graphics, with applications in Animation, Virtual Avatars, and\nHuman-Computer Interaction. However, current generative models suffer from\ndatasets that are either speech-driven or limited to coarse emotion labels,\nlacking the nuanced, expressive descriptions needed for fine-grained control,\nand were captured using elaborate and expensive equipment. We hence present a\nnew dataset of facial motion sequences featuring nuanced performances and\nsemantic annotation. The data is easily collected using commodity equipment and\nLLM-generated natural language instructions, in the popular ARKit blendshape\nformat. This provides riggable motion, rich with expressive performances and\nlabels. We accordingly train two baseline models, and evaluate their\nperformance for future benchmarking. Using our Express4D dataset, the trained\nmodels can learn meaningful text-to-expression motion generation and capture\nthe many-to-many mapping of the two modalities. The dataset, code, and video\nexamples are available on our webpage: https://jaron1990.github.io/Express4D/", "published": "2025-08-17 17:10:13", "link": "http://arxiv.org/abs/2508.12438v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Nucleation-free independent graphs with implied nonedges", "abstract": "We give inductive constructions of independent graphs that contain implied\nnonedges but do not contain any non-trivial rigid subgraphs, or\n\\emph{nucleations}: some of the constructions and proofs apply to 3-dimensional\nabstract rigidity matroids with their respective definitions of nucleations and\nimplied nonedges. The first motivation for the inductive constructions of this\npaper, which generate an especially intractable class of flexible circuits, is\nto illuminate further obstacles to settling Graver's maximality conjecture that\nthe 3-dimensional generic rigidity matroid is isomorphic to Whiteley's cofactor\nmatroid (the unique maximal matroid in which all graphs isomorphic to $K_5$ are\ncircuits). While none of the explicit examples we provide refutes the\nmaximality conjecture (since their properties hold in both matroids) the\nconstruction schemes are useful regardless whether the conjecture is true or\nfalse, e.g. for constructing larger (counter)examples from smaller ones. The\nsecond motivation is to make progress towards a polynomial-time algorithm for\ndeciding independence in the abovementioned maximal matroid. Nucleation-free\ngraphs with implied nonedges, such as the families constructed in this paper,\nare the key obstacles that must be dealt with for improving the current state\nof the art.", "published": "2025-08-17 16:04:16", "link": "http://arxiv.org/abs/2508.12417v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Contrastive Multi-View Graph Hashing", "abstract": "Multi-view graph data, which both captures node attributes and rich\nrelational information from diverse sources, is becoming increasingly prevalent\nin various domains. The effective and efficient retrieval of such data is an\nimportant task. Although multi-view hashing techniques have offered a paradigm\nfor fusing diverse information into compact binary codes, they typically assume\nattributes-based inputs per view. This makes them unsuitable for multi-view\ngraph data, where effectively encoding and fusing complex topological\ninformation from multiple heterogeneous graph views to generate unified binary\nembeddings remains a significant challenge. In this work, we propose\nContrastive Multi-view Graph Hashing (CMGHash), a novel end-to-end framework\ndesigned to learn unified and discriminative binary embeddings from multi-view\ngraph data. CMGHash learns a consensus node representation space using a\ncontrastive multi-view graph loss, which aims to pull $k$-nearest neighbors\nfrom all graphs closer while pushing away negative pairs, i.e., non-neighbor\nnodes. Moreover, we impose binarization constraints on this consensus space,\nenabling its conversion to a corresponding binary embedding space at minimal\ncost. Extensive experiments on several benchmark datasets demonstrate that\nCMGHash significantly outperforms existing approaches in terms of retrieval\naccuracy.", "published": "2025-08-17 14:27:20", "link": "http://arxiv.org/abs/2508.12377v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "TaoSR1: The Thinking Model for E-commerce Relevance Search", "abstract": "Query-product relevance prediction is a core task in e-commerce search.\nBERT-based models excel at semantic matching but lack complex reasoning\ncapabilities. While Large Language Models (LLMs) are explored, most still use\ndiscriminative fine-tuning or distill to smaller models for deployment. We\npropose a framework to directly deploy LLMs for this task, addressing key\nchallenges: Chain-of-Thought (CoT) error accumulation, discriminative\nhallucination, and deployment feasibility. Our framework, TaoSR1, involves\nthree stages: (1) Supervised Fine-Tuning (SFT) with CoT to instill reasoning;\n(2) Offline sampling with a pass@N strategy and Direct Preference Optimization\n(DPO) to improve generation quality; and (3) Difficulty-based dynamic sampling\nwith Group Relative Policy Optimization (GRPO) to mitigate discriminative\nhallucination. Additionally, post-CoT processing and a cumulative\nprobability-based partitioning method enable efficient online deployment.\nTaoSR1 significantly outperforms baselines on offline datasets and achieves\nsubstantial gains in online side-by-side human evaluations, introducing a novel\nparadigm for applying CoT reasoning to relevance classification.", "published": "2025-08-17 13:48:48", "link": "http://arxiv.org/abs/2508.12365v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Large-Scale Web Search Dataset for Federated Online Learning to Rank", "abstract": "The centralized collection of search interaction logs for training ranking\nmodels raises significant privacy concerns. Federated Online Learning to Rank\n(FOLTR) offers a privacy-preserving alternative by enabling collaborative model\ntraining without sharing raw user data. However, benchmarks in FOLTR are\nlargely based on random partitioning of classical learning-to-rank datasets,\nsimulated user clicks, and the assumption of synchronous client participation.\nThis oversimplifies real-world dynamics and undermines the realism of\nexperimental results. We present AOL4FOLTR, a large-scale web search dataset\nwith 2.6 million queries from 10,000 users. Our dataset addresses key\nlimitations of existing benchmarks by including user identifiers, real click\ndata, and query timestamps, enabling realistic user partitioning, behavior\nmodeling, and asynchronous federated learning scenarios.", "published": "2025-08-17 12:57:54", "link": "http://arxiv.org/abs/2508.12353v1", "categories": ["cs.IR", "cs.AI", "cs.DC"], "primary_category": "cs.IR"}
{"title": "The extended code for a class of generalized Roth-Lempel codes and their properties", "abstract": "As we all know, many interesting and important codes are obtained by\nmodifying or combining existing codes. In this paper, we focus on generalized\nRoth-Lempel (in short, GRL) codes and define a class of extended codes, i.e.,\nthe extended generalized Roth-Lempel (in short, EGRL) code. And then for a\nspecial class of EGRL codes, we give a parity-check matrix and establish a\nnecessary and sufficient condition for the EGRL code or its dual code to be MDS\nor AMDS, respectively. Finally, we construct a class of NMDS EGRL codes which\nis the generalization of the constructions given by Han et al. in 2023, and\nthen completely determine its weight distribution.", "published": "2025-08-17 09:34:15", "link": "http://arxiv.org/abs/2508.12302v1", "categories": ["cs.IT", "math.IT", "94A24, 94B05, 11T06, 12F05", "E.4"], "primary_category": "cs.IT"}
{"title": "Age of Semantic Information-Aware Wireless Transmission for Remote Monitoring Systems", "abstract": "Semantic communication is emerging as an effective means of facilitating\nintelligent and context-aware communication for next-generation communication\nsystems. In this paper, we propose a novel metric called Age of Incorrect\nSemantics (AoIS) for the transmission of video frames over multiple-input\nmultiple-output (MIMO) channels in a monitoring system. Different from the\nconventional age-based approaches, we jointly consider the information\nfreshness and the semantic importance, and then formulate a time-averaged AoIS\nminimization problem by jointly optimizing the semantic actuation indicator,\ntransceiver beamformer, and the semantic symbol design. We first transform the\noriginal problem into a low-complexity problem via the Lyapunov optimization.\nThen, we decompose the transformed problem into multiple subproblems and adopt\nthe alternative optimization (AO) method to solve each subproblem.\nSpecifically, we propose two efficient algorithms, i.e., the successive convex\napproximation (SCA) algorithm and the low-complexity zero-forcing (ZF)\nalgorithm for optimizing transceiver beamformer. We adopt exhaustive search\nmethods to solve the semantic actuation policy indicator optimization problem\nand the transmitted semantic symbol design problem. Experimental results\ndemonstrate that our scheme can preserve more than 50\\% of the original\ninformation under the same AoIS compared to the constrained baselines.", "published": "2025-08-17 05:34:44", "link": "http://arxiv.org/abs/2508.12248v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Cylindrical RIS-Assisted Low-Complexity Transmission with Differentiated Visible Regions Exploiting Statistical CSI", "abstract": "Reconfigurable intelligent surfaces (RIS), recognized as a critical enabler\nfor 6G networks, exhibit unprecedented capabilities in electromagnetic wave\nmanipulation and wireless channel reconfiguration. By leveraging existing\nnetwork infrastructure, RIS can cost-effectively create signal hotspots in\nlow-altitude environments, ensuring robust connectivity to support the\nsustainable development of the low-altitude economy. However, achieving optimal\nphase shift design in multi-user scenarios faces two major challenges: the\nhigh-dimensional optimization introduced by massive RIS elements, and the\npersistent coupling of multi-user signals caused by shared RIS reflections.\nThis paper utilize the visible region of an RIS arranged as the uniform\ncylindrical array (UCA) to reduce the complexity of phase shift design. Under\nthe UCA architecture, RIS elements are categorized into two types:\nuser-specific units and multi-user shared units. We then determine the optimal\nphase shifts by iteratively optimizing the phase shifts of multi-user shared\nunits while directly configuring those of user-specific units based on a\nderived closed-form solution. The proposed approach significantly reduces\noptimization complexity, which is further corroborated by numerical simulation\nresults demonstrating its substantial impact on both system performance and\ncomputational efficiency compared to the conventional RIS with uniform planar\narray.", "published": "2025-08-17 04:06:16", "link": "http://arxiv.org/abs/2508.12229v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Results of the NeurIPS 2023 Neural MMO Competition on Multi-task Reinforcement Learning", "abstract": "We present the results of the NeurIPS 2023 Neural MMO Competition, which\nattracted over 200 participants and submissions. Participants trained\ngoal-conditional policies that generalize to tasks, maps, and opponents never\nseen during training. The top solution achieved a score 4x higher than our\nbaseline within 8 hours of training on a single 4090 GPU. We open-source\neverything relating to Neural MMO and the competition under the MIT license,\nincluding the policy weights and training code for our baseline and for the top\nsubmissions.", "published": "2025-08-17 23:14:25", "link": "http://arxiv.org/abs/2508.12524v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference", "abstract": "Solving stochastic optimal control problems with quadratic control costs can\nbe viewed as approximating a target path space measure, e.g. via gradient-based\noptimization. In practice, however, this optimization is challenging in\nparticular if the target measure differs substantially from the prior. In this\nwork, we therefore approach the problem by iteratively solving constrained\nproblems incorporating trust regions that aim for approaching the target\nmeasure gradually in a systematic way. It turns out that this trust region\nbased strategy can be understood as a geometric annealing from the prior to the\ntarget measure, where, however, the incorporated trust regions lead to a\nprincipled and educated way of choosing the time steps in the annealing path.\nWe demonstrate in multiple optimal control applications that our novel method\ncan improve performance significantly, including tasks in diffusion-based\nsampling, transition path sampling, and fine-tuning of diffusion models.", "published": "2025-08-17 22:10:35", "link": "http://arxiv.org/abs/2508.12511v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Synchronization Dynamics of Heterogeneous, Collaborative Multi-Agent AI Systems", "abstract": "We present a novel interdisciplinary framework that bridges synchronization\ntheory and multi-agent AI systems by adapting the Kuramoto model to describe\nthe collective dynamics of heterogeneous AI agents engaged in complex task\nexecution. By representing AI agents as coupled oscillators with both phase and\namplitude dynamics, our model captures essential aspects of agent\nspecialization, influence, and communication within networked systems. We\nintroduce an order parameter to quantify the degree of coordination and\nsynchronization, providing insights into how coupling strength, agent\ndiversity, and network topology impact emergent collective behavior.\nFurthermore, we formalize a detailed correspondence between Chain-of-Thought\nprompting in AI reasoning and synchronization phenomena, unifying human-like\niterative problem solving with emergent group intelligence. Through extensive\nsimulations on all-to-all and deterministic scale-free networks, we demonstrate\nthat increased coupling promotes robust synchronization despite heterogeneous\nagent capabilities, reflecting realistic collaborative AI scenarios. Our\nphysics-informed approach establishes a rigorous mathematical foundation for\ndesigning, analyzing, and optimizing scalable, adaptive, and interpretable\nmulti-agent AI systems. This work opens pathways for principled orchestration\nof agentic AI and lays the groundwork for future incorporation of learning\ndynamics and adaptive network architectures to further enhance system\nresilience and efficiency.", "published": "2025-08-17 10:16:41", "link": "http://arxiv.org/abs/2508.12314v1", "categories": ["cs.MA", "cs.AI", "nlin.AO"], "primary_category": "cs.MA"}
{"title": "Anderson Acceleration For Perturbed Newton Methods", "abstract": "We present a convergence theory For Anderson acceleration (AA) applied to\nperturbed Newton methods (pNMs) For computing roots of nonlinear problems. Two\nimportant special cases are the classical Newton method and the\nLevenberg-Marquardt method. We prove that if a problem is 2-regular, then\nAnderson accelerated pNMs coupled with a safeguarding scheme, known as\n$\\gamma$-safeguarding, converge locally linearly in a starlike domain of\nconvergence, but with an improved rate of convergence compared to standard\nperturbed Newton methods. Since Levenberg-Marquardt methods are a special case\nof pNMs, we obtain a novel acceleration and local convergence result For\nAnderson accelerated Levenberg-Marquardt. We further show that the safeguarding\ntechnique can detect if the underlying perturbed Newton method is converging\nsuperlinearly, and respond by tuning the Anderson step down. We demonstrate the\nmethods on several benchmark problems in the literature.", "published": "2025-08-17 22:26:32", "link": "http://arxiv.org/abs/2508.12513v1", "categories": ["math.NA", "cs.NA", "65J15"], "primary_category": "math.NA"}
{"title": "Convergence analysis of Left-Right splitting surface scattering method", "abstract": "We study the convergence of the Left-Right splitting method (equivalent in\nkey respects to the Method of Multiple Ordered Interactions and\nForward-Backward method) for wave scattering by rough surfaces. This is an\noperator series method primarily designed for low grazing incidence and found\nin many cases to converge rapidly, often within one or two terms even for large\nincident angles. However, convergence is not guaranteed and semi-convergence\nmay be observed.\n  Our aims are two-fold: (1) To obtain theoretical and physical insight into\nthe regimes in which rapid convergence occurs and the mechanisms by which it\nfails, by examining and modifying eigenvalues of the operator; (2) provide a\nstrategy for increasing the speed of convergence or more crucially for\novercoming divergence, and providing a stopping criterion. The first is\naddressed by subtracting successive dominant eigenvectors from the incident\nfield, to examine the impact on divergence and on the incident spectrum. For\nthe second, we apply a generalisation of Shanks' transformation to the operator\nseries; this effectively improves convergence and (unlike eigenvalue\nsubtraction) readily generalises to 3D and composite problems. These results\nalso explain why the method converges so rapidly for much larger incident\nangles. Finally we ask and give an analytical solution to a key question: For a\ndivergent eigenvector of the iterating operator, what is the exact solution and\ncan it be deduced from the divergent series? We show that the exact solution is\nwell-behaved and can be found from the series in a way which is related to the\nShanks transformation.", "published": "2025-08-17 12:13:51", "link": "http://arxiv.org/abs/2508.12342v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Adaptive time-domain boundary element methods for the wave equation with Neumann boundary conditions", "abstract": "This article investigates adaptive mesh refinement procedures for the\ntime-domain wave equation with Neumann boundary conditions, formulated as an\nequivalent hypersingular boundary integral equation. Space-adaptive and\ntime-adaptive versions of a space-time boundary element method are presented,\nbased on a reliable a posteriori error estimate of residual type. Numerical\nexperiments illustrate the performance of the proposed approach.", "published": "2025-08-17 11:35:07", "link": "http://arxiv.org/abs/2508.12332v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Structure-preserving parametric finite element methods for two-phase Stokes flow based on Lagrange multiplier approaches", "abstract": "We present a novel formulation for parametric finite element methods to\napproximate two-phase Stokes flow. The new formulation is based on the\nclassical Stokes equation in the bulk and a novel choice of interface\nconditions with additional Lagrange multipliers. This new Lagrange multiplier\napproach ensures that the numerical methods exactly preserve two physical\nstructures of two-phase Stokes flow at the fully discrete level: (i) the\nenergy-decaying and (ii) the volume-preserving properties. Moreover, different\ntypes of higher-order time discretization methods are employed, including the\nCrank--Nicolson method and the second-order backward differentiation formula\napproach. The resulting schemes are nonlinear and can be efficiently solved by\nusing the Newton method with a decoupling technique. Extensive numerical\nexperiments demonstrate that our methods achieve the desired temporal accuracy\nwhile preserving the two physical structures of the two-phase Stokes system.", "published": "2025-08-17 10:50:32", "link": "http://arxiv.org/abs/2508.12326v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Implicit-Explicit Scheme with Multiscale Vanka Two-Grid Solver for Heterogeneous Unsaturated Poroelasticity", "abstract": "We consider a coupled nonlinear system of equations that describe unsaturated\nflow in heterogeneous poroelastic media. For the numerical solution, we use a\nfinite element approximation in space and present an efficient multiscale\ntwo-grid solver for solving the coupled system of equations. The proposed\ntwo-grid solver contains two main parts: (i) accurate coarse grid approximation\nbased on local spectral spaces and (ii) coupled smoothing iterations based on\nan overlapping multiscale Vanka method. A Vanka smoother and local spectral\ncoarse grids come with significant computational cost in the setup phase. To\navoid constructing a new solver for each time step and/or nonlinear iteration,\nwe utilize an implicit-explicit integration scheme in time, where we partition\nthe nonlinear operator as a sum of linear and nonlinear parts. In particular,\nwe construct an implicit linear approximation of the stiff components that\nremains fixed across all time, while treating the remaining nonlinear residual\nexplicitly. This allows us to construct a robust two-grid solver offline and\nutilize it for fast and efficient online time integration. A linear stability\nanalysis of the proposed novel coupled scheme is presented based on the\nrepresentation of the system as a two-step scheme. We show that the careful\ndecomposition of linear and nonlinear parts guarantees a linearly stable\nscheme. A numerical study is presented for a two-dimensional nonlinear coupled\ntest problem of unsaturated flow in heterogeneous poroelastic media. We\ndemonstrate the robustness of the two-grid solver, particularly the efficacy of\nblock smoothing compared with simple pointwise smoothing, and illustrate the\naccuracy and stability of implicit-explicit time integration.", "published": "2025-08-17 01:21:58", "link": "http://arxiv.org/abs/2508.12197v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Revisiting Stochastic Collocation with Exponential Splines for an Arbitrage-Free Interpolation of Option Prices", "abstract": "We revisit the stochastic collocation method using the exponential of a\nquadratic spline. In particular, we look in details whether it is more\nappropriate to fix the ordinates and optimize the abscissae of an interpolating\nspline or to fix the abscissae and optimize the parameters of a B-spline\nrepresentation.", "published": "2025-08-17 16:06:01", "link": "http://arxiv.org/abs/2508.12419v1", "categories": ["q-fin.PR", "q-fin.CP", "q-fin.MF"], "primary_category": "q-fin.PR"}
{"title": "Simultaneous estimation of connectivity and dimensionality in samples of networks", "abstract": "An overarching objective in contemporary statistical network analysis is\nextracting salient information from datasets consisting of multiple networks.\nTo date, considerable attention has been devoted to node and network\nclustering, while comparatively less attention has been devoted to downstream\nconnectivity estimation and parsimonious embedding dimension selection. Given a\nsample of potentially heterogeneous networks, this paper proposes a method to\nsimultaneously estimate a latent matrix of connectivity probabilities and its\nembedding dimensionality or rank after first pre-estimating the number of\ncommunities and the node community memberships. The method is formulated as a\nconvex optimization problem and solved using an alternating direction method of\nmultipliers algorithm. We establish estimation error bounds under the Frobenius\nnorm and nuclear norm for settings in which observable networks have blockmodel\nstructure, even when node memberships are imperfectly recovered. When perfect\nmembership recovery is possible and dimensionality is much smaller than the\nnumber of communities, the proposed method outperforms conventional\naveraging-based methods for estimating connectivity and dimensionality.\nNumerical studies empirically demonstrate the accuracy of our method across\nvarious scenarios. Additionally, analysis of a primate brain dataset\ndemonstrates that posited connectivity is not necessarily full rank in\npractice, illustrating the need for flexible methodology.", "published": "2025-08-17 19:52:08", "link": "http://arxiv.org/abs/2508.12483v1", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH", "62H12"], "primary_category": "stat.ME"}
{"title": "Asymptotic breakdown point analysis of the minimum density power divergence estimator under independent non-homogeneous setups", "abstract": "The minimum density power divergence estimator (MDPDE) has gained significant\nattention in the literature of robust inference due to its strong robustness\nproperties and high asymptotic efficiency; it is relatively easy to compute and\ncan be interpreted as a generalization of the classical maximum likelihood\nestimator. It has been successfully applied in various setups, including the\ncase of independent and non-homogeneous (INH) observations that cover both\nclassification and regression-type problems with a fixed design. While the\nlocal robustness of this estimator has been theoretically validated through the\nbounded influence function, no general result is known about the global\nreliability or the breakdown behavior of this estimator under the INH setup,\nexcept for the specific case of location-type models. In this paper, we extend\nthe notion of asymptotic breakdown point from the case of independent and\nidentically distributed data to the INH setup and derive a theoretical lower\nbound for the asymptotic breakdown point of the MDPDE, under some easily\nverifiable assumptions. These results are further illustrated with applications\nto some fixed design regression models and corroborated through extensive\nsimulation studies.", "published": "2025-08-17 16:33:58", "link": "http://arxiv.org/abs/2508.12426v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Does the Barron space really defy the curse of dimensionality?", "abstract": "The Barron space has become famous in the theory of (shallow) neural networks\nbecause it seemingly defies the curse of dimensionality. And while the Barron\nspace (and generalizations) indeed defies (defy) the curse of dimensionality\nfrom the POV of classical smoothness, we herein provide some evidence in favor\nof the idea that the Barron space (and generalizations) does (do) not defy the\ncurse of dimensionality with a nonclassical notion of smoothness which relates\nnaturally to \"infinitely wide\" shallow neural networks. Like how the Bessel\npotential spaces are defined via the Fourier transform, we define so-called ADZ\nspaces via the Mellin transform; these ADZ spaces encapsulate the nonclassical\nsmoothness we alluded to earlier.\n  38 pages, will appear in the dissertation of the author", "published": "2025-08-17 07:42:49", "link": "http://arxiv.org/abs/2508.12273v1", "categories": ["math.FA", "math.PR", "stat.ML"], "primary_category": "math.FA"}
{"title": "On the Extension of Differential Beamforming Theory to Arbitrary Planar Arrays of First-Order Elements", "abstract": "Small-size acoustic arrays exploit spatial diversity to achieve capabilities\nbeyond those of single-element devices, with applications ranging from\nteleconferencing to immersive multimedia. A key requirement for broadband array\nprocessing is a frequency-invariant spatial response, which ensures consistent\ndirectivity across wide bandwidths and prevents spectral coloration.\nDifferential beamforming offers an inherently frequency-invariant solution by\nleveraging pressure differences between closely spaced elements of small-size\narrays. Traditional approaches, however, assume the array elements to be\nomnidirectional, whereas real transducers exhibit frequency-dependent\ndirectivity that can degrade performance if not properly modeled. To address\nthis limitation, we propose a generalized modal matching framework for\nfrequency-invariant differential beamforming, applicable to unconstrained\nplanar arrays of first-order directional elements. By representing the desired\nbeampattern as a truncated circular harmonic expansion and fitting it to the\nactual element responses, our method accommodates arbitrary planar geometries\nand element orientations. This approach enables the synthesis of beampatterns\nof any order and steering direction without imposing rigid layout requirements.\nSimulations confirm that accounting for sensor directivity at the design stage\nyields accurate and robust performance across varying frequencies, geometries,\nand noise conditions.", "published": "2025-08-17 15:40:19", "link": "http://arxiv.org/abs/2508.12403v1", "categories": ["eess.SP", "eess.AS"], "primary_category": "eess.SP"}
{"title": "HuBERT-VIC: Improving Noise-Robust Automatic Speech Recognition of Speech Foundation Model via Variance-Invariance-Covariance Regularization", "abstract": "Noise robustness in speech foundation models (SFMs) has been a critical\nchallenge, as most models are primarily trained on clean data and experience\nperformance degradation when the models are exposed to noisy speech. To address\nthis issue, we propose HuBERT-VIC, a noise-robust SFM with variance,\nin-variance, and covariance regularization (VICReg) objectives. These\nobjectives adjust the statistics of noisy speech representations, enabling the\nmodel to capture diverse acoustic characteristics and improving the\ngeneralization ability across different types of noise. When applied to HuBERT,\nour model shows relative performance improvements of 23.3% on LibriSpeech\ntest-clean and 13.2% on test-other, compared to the baseline model pre-trained\non noisy speech.", "published": "2025-08-17 08:54:25", "link": "http://arxiv.org/abs/2508.12292v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection", "abstract": "Machine anomalous sound detection (ASD) is a valuable technique across\nvarious applications. However, its generalization performance is often limited\ndue to challenges in data collection and the complexity of acoustic\nenvironments. Inspired by the success of large pre-trained models in numerous\nfields, this paper introduces a robust ASD model that leverages self-supervised\npre-trained models trained on large-scale speech and audio datasets. Although\nthere are inconsistencies between the pre-training datasets and the ASD task,\nour findings indicate that pre-training still provides substantial benefits for\nASD. To mitigate overfitting and retain learned knowledge when fine-tuning with\nlimited data, we explore Fully-Connected Low-Rank Adaptation (LoRA) as an\nalternative to full fine-tuning. Additionally, we propose a Machine-aware Group\nAdapter module, which enables the model to capture differences between various\nmachines within a unified framework, thereby enhancing the generalization\nperformance of ASD systems. To address the challenge of missing attribute\nlabels, we design a novel objective function that dynamically clusters\nunattributed data using vector quantization and optimizes through a dual-level\ncontrastive learning loss. The proposed methods are evaluated on all benchmark\ndatasets, including the DCASE 2020-2024 five ASD challenges, and the\nexperimental results show significant improvements of our new approach and\ndemonstrate the effectiveness of our proposed strategies.", "published": "2025-08-17 04:06:45", "link": "http://arxiv.org/abs/2508.12230v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Coherent Compensation-Based Sensing for Long-Range Targets in Integrated Sensing and Communication System", "abstract": "Integrated sensing and communication (ISAC) is a promising candidate\ntechnology for 6G due to its improvement in spectral efficiency and energy\nefficiency. Orthogonal frequency division multiplexing (OFDM) signal is a\nmainstream candidate ISAC waveform. However, there are inter-symbol\ninterference (ISI) and inter-carrier interference (ICI) when the round-trip\ndelay exceeds the cyclic prefix (CP) duration for OFDM signals, which limits\nthe maximum sensing range of ISAC system. When detecting a long-range target,\nthe wide beam inevitably covers the close-range target, of which the echo's\npower is much larger than that of the long-range target. In order to tackle the\nabove problem, a multiple signal classification (MUSIC) and least squares\n(LS)-based spatial signal separation method is proposed to separate the echo\nsignals reflected from different targets. Moreover, a coherent\ncompensation-based sensing signal processing method at the receiver is proposed\nto enhance the signal to interference plus noise power ratio (SINR) of the OFDM\nblock for generating the range-Doppler map (RDM) with higher SINR. Simulation\nresults reveal that the proposed method greatly enhances the SINR of RDM by 10\ndB for a target at 500 m compared with two-dimensional fast Fourier transform\n(2D-FFT) method. Besides, the detection probability is also significantly\nimproved compared to the benchmarking method.", "published": "2025-08-17 14:08:10", "link": "http://arxiv.org/abs/2508.12371v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Jamming Identification with Differential Transformer for Low-Altitude Wireless Networks", "abstract": "Wireless jamming identification, which detects and classifies electromagnetic\njamming from non-cooperative devices, is crucial for emerging low-altitude\nwireless networks consisting of many drone terminals that are highly\nsusceptible to electromagnetic jamming. However, jamming identification schemes\nadopting deep learning (DL) are vulnerable to attacks involving carefully\ncrafted adversarial samples, resulting in inevitable robustness degradation. To\naddress this issue, we propose a differential transformer framework for\nwireless jamming identification. Firstly, we introduce a differential\ntransformer network in order to distinguish jamming signals, which overcomes\nthe attention noise when compared with its traditional counterpart by\nperforming self-attention operations in a differential manner. Secondly, we\npropose a randomized masking training strategy to improve network robustness,\nwhich leverages the patch partitioning mechanism inherent to transformer\narchitectures in order to create parallel feature extraction branches. Each\nbranch operates on a distinct, randomly masked subset of patches, which\nfundamentally constrains the propagation of adversarial perturbations across\nthe network. Additionally, the ensemble effect generated by fusing predictions\nfrom these diverse branches demonstrates superior resilience against\nadversarial attacks. Finally, we introduce a novel consistent training\nframework that significantly enhances adversarial robustness through dualbranch\nregularization. Simulation results demonstrate that our proposed methodology is\nsuperior to existing methods in boosting robustness to adversarial samples.", "published": "2025-08-17 10:23:31", "link": "http://arxiv.org/abs/2508.12320v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Polarization Reconfigurable Transmit-Receive Beam Alignment with Interpretable Transformer", "abstract": "Recent advancement in next generation reconfigurable antenna and fluid\nantenna technology has influenced the wireless system with polarization\nreconfigurable (PR) channels to attract significant attention for promoting\nbeneficial channel condition. We exploit the benefit of PR antennas by\nintegrating such technology into massive multiple-input-multiple-output (MIMO)\nsystem. In particular, we aim to jointly design the polarization and\nbeamforming vectors on both transceivers for simultaneous channel\nreconfiguration and beam alignment, which remarkably enhance the beamforming\ngain. However, joint optimization over polarization and beamforming vectors\nwithout channel state information (CSI) is a challenging task, since\ndepolarization increases the channel dimension; whereas massive MIMO systems\ntypically have low-dimensional pilot measurement from limited radio frequency\n(RF) chain. This leads to pilot overhead because the transceivers can only\nobserve low-dimensional measurement of the high-dimension channel. This paper\npursues the reduction of the pilot overhead in such systems by proposing to\nemploy \\emph{interpretable transformer}-based deep learning framework on both\ntransceivers to actively design the polarization and beamforming vectors for\npilot stage and transmission stage based on the sequence of accumulated\nreceived pilots. Numerical experiments demonstrate the significant performance\ngain of our proposed framework over the existing non-adaptive and active\ndata-driven methods. Furthermore, we exploit the interpretability of our\nproposed framework to analyze the learning capabilities of the model.", "published": "2025-08-17 09:25:44", "link": "http://arxiv.org/abs/2508.12298v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Communication-Efficient Distributed Asynchronous ADMM", "abstract": "In distributed optimization and federated learning, asynchronous alternating\ndirection method of multipliers (ADMM) serves as an attractive option for\nlarge-scale optimization, data privacy, straggler nodes and variety of\nobjective functions. However, communication costs can become a major bottleneck\nwhen the nodes have limited communication budgets or when the data to be\ncommunicated is prohibitively large. In this work, we propose introducing\ncoarse quantization to the data to be exchanged in aynchronous ADMM so as to\nreduce communication overhead for large-scale federated learning and\ndistributed optimization applications. We experimentally verify the convergence\nof the proposed method for several distributed learning tasks, including neural\nnetworks.", "published": "2025-08-17 04:22:36", "link": "http://arxiv.org/abs/2508.12233v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "A Novel Symbol Level Precoding based AFDM Transmission Framework: Offloading Equalization Burden to Transmitter Side", "abstract": "Affine Frequency Division Multiplexing (AFDM) has attracted considerable\nattention for its robustness to Doppler effects. However, its high\nreceiver-side computational complexity remains a major barrier to practical\ndeployment. To address this, we propose a novel symbol-level precoding\n(SLP)-based AFDM transmission framework, which shifts the signal processing\nburden in downlink communications from user side to the base station (BS),\nenabling direct symbol detection without requiring channel estimation or\nequalization at the receiver. Specifically, in the uplink phase, we propose a\nSparse Bayesian Learning (SBL) based channel estimation algorithm by exploiting\nthe inherent sparsity of affine frequency (AF) domain channels. In particular,\nthe sparse prior is modeled via a hierarchical Laplace distribution, and\nparameters are iteratively updated using the Expectation-Maximization (EM)\nalgorithm. We also derive the Bayesian Cramer-Rao Bound (BCRB) to characterize\nthe theoretical performance limit. In the downlink phase, the BS employs the\nSLP technology to design the transmitted waveform based on the estimated uplink\nchannel state information (CSI) and channel reciprocity. The resulting\noptimization problem is formulated as a second-order cone programming (SOCP)\nproblem, and its dual problem is investigated by Lagrangian function and\nKarush-Kuhn-Tucker conditions. Simulation results demonstrate that the proposed\nSBL estimator outperforms traditional orthogonal matching pursuit (OMP) in\naccuracy and robustness to off-grid effects, while the SLP-based waveform\ndesign scheme achieves performance comparable to conventional AFDM receivers\nwhile significantly reducing the computational complexity at receiver,\nvalidating the practicality of our approach.", "published": "2025-08-17 03:07:56", "link": "http://arxiv.org/abs/2508.12215v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Towards Generalizable Human Activity Recognition: A Survey", "abstract": "As a critical component of Wearable AI, IMU-based Human Activity Recognition\n(HAR) has attracted increasing attention from both academia and industry in\nrecent years. Although HAR performance has improved considerably in specific\nscenarios, its generalization capability remains a key barrier to widespread\nreal-world adoption. For example, domain shifts caused by variations in users,\nsensor positions, or environments can significantly decrease the performance in\npractice. As a result, in this survey, we explore the rapidly evolving field of\nIMU-based generalizable HAR, reviewing 229 research papers alongside 25\npublicly available datasets to provide a broad and insightful overview. We\nfirst present the background and overall framework of IMU-based HAR tasks, as\nwell as the generalization-oriented training settings. Then, we categorize\nrepresentative methodologies from two perspectives: (i) model-centric\napproaches, including pre-training method, end-to-end method, and large\nlanguage model (LLM)-based learning method; and (ii) data-centric approaches,\nincluding multi-modal learning and data augmentation techniques. In addition,\nwe summarize widely used datasets in this field, as well as relevant tools and\nbenchmarks. Building on these methodological advances, the broad applicability\nof IMU-based HAR is also reviewed and discussed. Finally, we discuss persistent\nchallenges (e.g., data scarcity, efficient training, and reliable evaluation)\nand also outline future directions for HAR, including the adoption of\nfoundation and large language models, physics-informed and context-aware\nreasoning, generative modeling, and resource-efficient training and inference.\nThe complete list of this survey is available at\nhttps://github.com/rh20624/Awesome-IMU-Sensing, which will be updated\ncontinuously.", "published": "2025-08-17 03:04:39", "link": "http://arxiv.org/abs/2508.12213v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Weighted Covariance Intersection for Range-based Distributed Cooperative Localization of Multi-Agent Systems", "abstract": "Precise localization of multi-agent systems (MAS) in harsh environments is a\ncritical challenge for swarm applications, and cooperative localization is\nconsidered a key solution to this issue. Among all solutions, distributed\ncooperative localization (DCL) has garnered widespread attention due to its\nrobustness and scalability. The main challenge of DCL lies in how to fuse\nrelative measurements between agents under unknown correlations. To address\nthis, covariance intersection (CI) was introduced to DCL. However, the\nclassical CI optimization criteria suffer from issues such as scale imbalance\nand correlation mismatch during the fusion process. These deficiencies are not\nas pronounced in 2D scenarios, where the state space is relatively simple and\nthe observability of each state component is well. However, in 3D scenarios,\nwhere the state space is more complex and there are significant disparities in\nthe scale and observability of state components, performance degradation\nbecomes severe. This necessitates the design of specialized mechanisms to\nimprove the data fusion process. In this paper, we identify three main\ndrawbacks of the classical CI optimization criteria in recursive filtering and\nintroduce a weighting mechanism, namely weighted covariance intersection (WCI),\nto improve its performance. We then introduce WCI into range-based distributed\ncooperative localization in 3D scenarios, developing a concurrent fusion\nstrategy for multiple distance measurements and designing a weighting matrix\nbased on the error propagation rule of the inertial navigation system (INS).\nSimulation results demonstrate that the proposed WCI significantly enhances\ncooperative localization performance compared to classical CI, while the\ndistributed approach outperforms the centralized approach in terms of\nrobustness, scalability, and is more suitable for large-scale swarms.", "published": "2025-08-17 02:21:19", "link": "http://arxiv.org/abs/2508.12207v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "ATLAS: AI-Native Receiver Test-and-Measurement by Leveraging AI-Guided Search", "abstract": "Industry adoption of Artificial Intelligence (AI)-native wireless receivers,\nor even modular, Machine Learning (ML)-aided wireless signal processing blocks,\nhas been slow. The main concern is the lack of explainability of these trained\nML models and the significant risks posed to network functionalities in case of\nfailures, especially since (i) testing on every exhaustive case is infeasible\nand (ii) the data used for model training may not be available. This paper\nproposes ATLAS, an AI-guided approach that generates a battery of tests for\npre-trained AI-native receiver models and benchmarks the performance against a\nclassical receiver architecture. Using gradient-based optimization, it avoids\nspanning the exhaustive set of all environment and channel conditions; instead,\nit generates the next test in an online manner to further probe specific\nconfigurations that offer the highest risk of failure. We implement and\nvalidate our approach by adopting the well-known DeepRx AI-native receiver\nmodel as well as a classical receiver using differentiable tensors in NVIDIA's\nSionna environment. ATLAS uncovers specific combinations of mobility, channel\ndelay spread, and noise, where fully and partially trained variants of\nAI-native DeepRx perform suboptimally compared to the classical receivers. Our\nproposed method reduces the number of tests required per failure found by 19%\ncompared to grid search for a 3-parameters input optimization problem,\ndemonstrating greater efficiency. In contrast, the computational cost of the\ngrid-based approach scales exponentially with the number of variables, making\nit increasingly impractical for high-dimensional problems.", "published": "2025-08-17 02:12:15", "link": "http://arxiv.org/abs/2508.12204v1", "categories": ["eess.SP", "cs.LG", "cs.NI"], "primary_category": "eess.SP"}
{"title": "MedKGent: A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph", "abstract": "The rapid expansion of medical literature presents growing challenges for\nstructuring and integrating domain knowledge at scale. Knowledge Graphs (KGs)\noffer a promising solution by enabling efficient retrieval, automated\nreasoning, and knowledge discovery. However, current KG construction methods\noften rely on supervised pipelines with limited generalizability or naively\naggregate outputs from Large Language Models (LLMs), treating biomedical\ncorpora as static and ignoring the temporal dynamics and contextual uncertainty\nof evolving knowledge. To address these limitations, we introduce MedKGent, a\nLLM agent framework for constructing temporally evolving medical KGs.\nLeveraging over 10 million PubMed abstracts published between 1975 and 2023, we\nsimulate the emergence of biomedical knowledge via a fine-grained daily time\nseries. MedKGent incrementally builds the KG in a day-by-day manner using two\nspecialized agents powered by the Qwen2.5-32B-Instruct model. The Extractor\nAgent identifies knowledge triples and assigns confidence scores via\nsampling-based estimation, which are used to filter low-confidence extractions\nand inform downstream processing. The Constructor Agent incrementally\nintegrates the retained triples into a temporally evolving graph, guided by\nconfidence scores and timestamps to reinforce recurring knowledge and resolve\nconflicts. The resulting KG contains 156,275 entities and 2,971,384 relational\ntriples. Quality assessments by two SOTA LLMs and three domain experts\ndemonstrate an accuracy approaching 90%, with strong inter-rater agreement. To\nevaluate downstream utility, we conduct RAG across seven medical question\nanswering benchmarks using five leading LLMs, consistently observing\nsignificant improvements over non-augmented baselines. Case studies further\ndemonstrate the KG's value in literature-based drug repurposing via\nconfidence-aware causal inference.", "published": "2025-08-17 15:14:03", "link": "http://arxiv.org/abs/2508.12393v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Legal$\u0394$: Enhancing Legal Reasoning in LLMs via Reinforcement Learning with Chain-of-Thought Guided Information Gain", "abstract": "Legal Artificial Intelligence (LegalAI) has achieved notable advances in\nautomating judicial decision-making with the support of Large Language Models\n(LLMs). However, existing legal LLMs still struggle to generate reliable and\ninterpretable reasoning processes. They often default to fast-thinking behavior\nby producing direct answers without explicit multi-step reasoning, limiting\ntheir effectiveness in complex legal scenarios that demand rigorous\njustification. To address this challenge, we propose Legal$\\Delta$, a\nreinforcement learning framework designed to enhance legal reasoning through\nchain-of-thought guided information gain. During training, Legal$\\Delta$\nemploys a dual-mode input setup-comprising direct answer and\nreasoning-augmented modes-and maximizes the information gain between them. This\nencourages the model to acquire meaningful reasoning patterns rather than\ngenerating superficial or redundant explanations. Legal$\\Delta$ follows a\ntwo-stage approach: (1) distilling latent reasoning capabilities from a\npowerful Large Reasoning Model (LRM), DeepSeek-R1, and (2) refining reasoning\nquality via differential comparisons, combined with a multidimensional reward\nmechanism that assesses both structural coherence and legal-domain specificity.\nExperimental results on multiple legal reasoning tasks demonstrate that\nLegal$\\Delta$ outperforms strong baselines in both accuracy and\ninterpretability. It consistently produces more robust and trustworthy legal\njudgments without relying on labeled preference data. All code and data will be\nreleased at https://github.com/NEUIR/LegalDelta.", "published": "2025-08-17 08:10:08", "link": "http://arxiv.org/abs/2508.12281v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Modeling and Solving the Boltzmann Equation", "abstract": "The Boltzmann equation has been a driving force behind significant\nmathematical research over the years. Its challenging theoretical complexity,\ncombined with a wide variety of current scientific and technological problems\nthat require numerical simulations based on this model, justifies such\ninterest. This work provides a brief overview of studies and advances related\nto the solution of the linear Boltzmann equation in one- and two-dimensional\nspatial dimensions. In particular, relevant aspects of the discrete ordinates\napproximation of the model are highlighted for neutron and photon transport\napplications, including nuclear safeguards, nuclear reactor shielding problems,\nand optical tomography. In addition, a short discussion on rarefied gas\ndynamics problems, which are relevant, for instance, in the studies of\nmicro-electro-mechanical systems, and their connection with the linearized\nBoltzmann equation, is presented. A primary goal of the work is to establish as\nmuch as possible the connections between the different phenomena described by\nthe model and the versatility of the analytical methodology, the ADO method, in\nproviding concise and accurate solutions, which are fundamental for numerical\nsimulations.", "published": "2025-08-17 21:11:39", "link": "http://arxiv.org/abs/2508.13232v1", "categories": ["math-ph", "cs.NA", "math.MP", "math.NA", "76P05, 76M22, 65N35"], "primary_category": "math-ph"}
{"title": "Age of Semantic Information-Aware Wireless Transmission for Remote Monitoring Systems", "abstract": "Semantic communication is emerging as an effective means of facilitating\nintelligent and context-aware communication for next-generation communication\nsystems. In this paper, we propose a novel metric called Age of Incorrect\nSemantics (AoIS) for the transmission of video frames over multiple-input\nmultiple-output (MIMO) channels in a monitoring system. Different from the\nconventional age-based approaches, we jointly consider the information\nfreshness and the semantic importance, and then formulate a time-averaged AoIS\nminimization problem by jointly optimizing the semantic actuation indicator,\ntransceiver beamformer, and the semantic symbol design. We first transform the\noriginal problem into a low-complexity problem via the Lyapunov optimization.\nThen, we decompose the transformed problem into multiple subproblems and adopt\nthe alternative optimization (AO) method to solve each subproblem.\nSpecifically, we propose two efficient algorithms, i.e., the successive convex\napproximation (SCA) algorithm and the low-complexity zero-forcing (ZF)\nalgorithm for optimizing transceiver beamformer. We adopt exhaustive search\nmethods to solve the semantic actuation policy indicator optimization problem\nand the transmitted semantic symbol design problem. Experimental results\ndemonstrate that our scheme can preserve more than 50\\% of the original\ninformation under the same AoIS compared to the constrained baselines.", "published": "2025-08-17 05:34:44", "link": "http://arxiv.org/abs/2508.12248v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "An Auditable Pipeline for Fuzzy Full-Text Screening in Systematic Reviews: Integrating Contrastive Semantic Highlighting and LLM Judgment", "abstract": "Full-text screening is the major bottleneck of systematic reviews (SRs), as\ndecisive evidence is dispersed across long, heterogeneous documents and rarely\nadmits static, binary rules. We present a scalable, auditable pipeline that\nreframes inclusion/exclusion as a fuzzy decision problem and benchmark it\nagainst statistical and crisp baselines in the context of the Population Health\nModelling Consensus Reporting Network for noncommunicable diseases (POPCORN).\nArticles are parsed into overlapping chunks and embedded with a domain-adapted\nmodel; for each criterion (Population, Intervention, Outcome, Study Approach),\nwe compute contrastive similarity (inclusion-exclusion cosine) and a vagueness\nmargin, which a Mamdani fuzzy controller maps into graded inclusion degrees\nwith dynamic thresholds in a multi-label setting. A large language model (LLM)\njudge adjudicates highlighted spans with tertiary labels, confidence scores,\nand criterion-referenced rationales; when evidence is insufficient, fuzzy\nmembership is attenuated rather than excluded. In a pilot on an all-positive\ngold set (16 full texts; 3,208 chunks), the fuzzy system achieved recall of\n81.3% (Population), 87.5% (Intervention), 87.5% (Outcome), and 75.0% (Study\nApproach), surpassing statistical (56.3-75.0%) and crisp baselines\n(43.8-81.3%). Strict \"all-criteria\" inclusion was reached for 50.0% of\narticles, compared to 25.0% and 12.5% under the baselines. Cross-model\nagreement on justifications was 98.3%, human-machine agreement 96.1%, and a\npilot review showed 91% inter-rater agreement (kappa = 0.82), with screening\ntime reduced from about 20 minutes to under 1 minute per article at\nsignificantly lower cost. These results show that fuzzy logic with contrastive\nhighlighting and LLM adjudication yields high recall, stable rationale, and\nend-to-end traceability.", "published": "2025-08-17 17:41:50", "link": "http://arxiv.org/abs/2508.15822v1", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Straggler-Resilient Federated Learning over A Hybrid Conventional and Pinching Antenna Network", "abstract": "Leveraging pinching antennas in wireless network enabled federated learning\n(FL) can effectively mitigate the common \"straggler\" issue in FL by dynamically\nestablishing strong line-of-sight (LoS) links on demand. This letter proposes a\nhybrid conventional and pinching antenna network (HCPAN) to significantly\nimprove communication efficiency in the non-orthogonal multiple access\n(NOMA)-enabled FL system. Within this framework, a fuzzy logic-based client\nclassification scheme is first proposed to effectively balance clients' data\ncontributions and communication conditions. Given this classification, we\nformulate a total time minimization problem to jointly optimize pinching\nantenna placement and resource allocation. Due to the complexity of variable\ncoupling and non-convexity, a deep reinforcement learning (DRL)-based algorithm\nis developed to effectively address this problem. Simulation results validate\nthe superiority of the proposed scheme in enhancing FL performance via the\noptimized deployment of pinching antenna.", "published": "2025-08-17 17:09:42", "link": "http://arxiv.org/abs/2508.15821v1", "categories": ["cs.IT", "cs.AI", "cs.NI", "math.IT"], "primary_category": "cs.IT"}
{"title": "Deep Learning and Matrix Completion-aided IoT Network Localization in the Outlier Scenarios", "abstract": "In this paper, we propose a deep learning and matrix completion aided\napproach for recovering an outlier contaminated Euclidean distance matrix D in\nIoT network localization. Unlike conventional localization techniques that\nsearch the solution over a whole set of matrices, the proposed technique\nrestricts the search to the set of Euclidean distance matrices. Specifically,\nwe express D as a function of the sensor coordinate matrix X that inherently\nsatisfies the unique properties of D, and then jointly recover D and X using a\ndeep neural network. To handle outliers effectively, we model them as a sparse\nmatrix L and add a regularization term of L into the optimization problem. We\nthen solve the problem by alternately updating X, D, and L. Numerical\nexperiments demonstrate that the proposed technique can recover the location\ninformation of sensors accurately even in the presence of outliers.", "published": "2025-08-17 03:54:14", "link": "http://arxiv.org/abs/2508.18225v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
