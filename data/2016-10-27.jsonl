{"title": "CogALex-V Shared Task: LexNET - Integrated Path-based and Distributional\n  Method for the Identification of Semantic Relations", "abstract": "We present a submission to the CogALex 2016 shared task on the corpus-based\nidentification of semantic relations, using LexNET (Shwartz and Dagan, 2016),\nan integrated path-based and distributional method for semantic relation\nclassification. The reported results in the shared task bring this submission\nto the third place on subtask 1 (word relatedness), and the first place on\nsubtask 2 (semantic relation classification), demonstrating the utility of\nintegrating the complementary path-based and distributional information sources\nin recognizing concrete semantic relations. Combined with a common similarity\nmeasure, LexNET performs fairly good on the word relatedness task (subtask 1).\nThe relatively low performance of LexNET and all other systems on subtask 2,\nhowever, confirms the difficulty of the semantic relation classification task,\nand stresses the need to develop additional methods for this task.", "published": "2016-10-27 10:49:00", "link": "http://arxiv.org/abs/1610.08694v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural\n  Networks", "abstract": "Sarcasm detection is a key task for many natural language processing tasks.\nIn sentiment analysis, for example, sarcasm can flip the polarity of an\n\"apparently positive\" sentence and, hence, negatively affect polarity detection\nperformance. To date, most approaches to sarcasm detection have treated the\ntask primarily as a text categorization problem. Sarcasm, however, can be\nexpressed in very subtle ways and requires a deeper understanding of natural\nlanguage that standard text categorization techniques cannot grasp. In this\nwork, we develop models based on a pre-trained convolutional neural network for\nextracting sentiment, emotion and personality features for sarcasm detection.\nSuch features, along with the network's baseline features, allow the proposed\nmodels to outperform the state of the art on benchmark datasets. We also\naddress the often ignored generalizability issue of classifying data that have\nnot been seen by the models at learning phase.", "published": "2016-10-27 14:50:43", "link": "http://arxiv.org/abs/1610.08815v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ex Machina: Personal Attacks Seen at Scale", "abstract": "The damage personal attacks cause to online discourse motivates many\nplatforms to try to curb the phenomenon. However, understanding the prevalence\nand impact of personal attacks in online platforms at scale remains\nsurprisingly difficult. The contribution of this paper is to develop and\nillustrate a method that combines crowdsourcing and machine learning to analyze\npersonal attacks at scale. We show an evaluation method for a classifier in\nterms of the aggregated number of crowd-workers it can approximate. We apply\nour methodology to English Wikipedia, generating a corpus of over 100k high\nquality human-labeled comments and 63M machine-labeled ones from a classifier\nthat is as good as the aggregate of 3 crowd-workers, as measured by the area\nunder the ROC curve and Spearman correlation. Using this corpus of\nmachine-labeled scores, our methodology allows us to explore some of the open\nquestions about the nature of online personal attacks. This reveals that the\nmajority of personal attacks on Wikipedia are not the result of a few malicious\nusers, nor primarily the consequence of allowing anonymous contributions from\nunregistered users.", "published": "2016-10-27 18:18:18", "link": "http://arxiv.org/abs/1610.08914v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Active Memory Replace Attention?", "abstract": "Several mechanisms to focus attention of a neural network on selected parts\nof its input or memory have been used successfully in deep learning models in\nrecent years. Attention has improved image classification, image captioning,\nspeech recognition, generative models, and learning algorithmic tasks, but it\nhad probably the largest impact on neural machine translation.\n  Recently, similar improvements have been obtained using alternative\nmechanisms that do not focus on a single part of a memory but operate on all of\nit in parallel, in a uniform way. Such mechanism, which we call active memory,\nimproved over attention in algorithmic tasks, image processing, and in\ngenerative modelling.\n  So far, however, active memory has not improved over attention for most\nnatural language processing tasks, in particular for machine translation. We\nanalyze this shortcoming in this paper and propose an extended model of active\nmemory that matches existing attention models on neural machine translation and\ngeneralizes better to longer sentences. We investigate this model and explain\nwhy previous active memory models did not succeed. Finally, we discuss when\nactive memory brings most benefits and where attention can be a better choice.", "published": "2016-10-27 04:28:29", "link": "http://arxiv.org/abs/1610.08613v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CoType: Joint Extraction of Typed Entities and Relations with Knowledge\n  Bases", "abstract": "Extracting entities and relations for types of interest from text is\nimportant for understanding massive text corpora. Traditionally, systems of\nentity relation extraction have relied on human-annotated corpora for training\nand adopted an incremental pipeline. Such systems require additional human\nexpertise to be ported to a new domain, and are vulnerable to errors cascading\ndown the pipeline. In this paper, we investigate joint extraction of typed\nentities and relations with labeled data heuristically obtained from knowledge\nbases (i.e., distant supervision). As our algorithm for type labeling via\ndistant supervision is context-agnostic, noisy training data poses unique\nchallenges for the task. We propose a novel domain-independent framework,\ncalled CoType, that runs a data-driven text segmentation algorithm to extract\nentity mentions, and jointly embeds entity mentions, relation mentions, text\nfeatures and type labels into two low-dimensional spaces (for entity and\nrelation mentions respectively), where, in each space, objects whose types are\nclose will also have similar representations. CoType, then using these learned\nembeddings, estimates the types of test (unlinkable) mentions. We formulate a\njoint optimization problem to learn embeddings from text corpora and knowledge\nbases, adopting a novel partial-label loss function for noisy labeled data and\nintroducing an object \"translation\" function to capture the cross-constraints\nof entities and relations on each other. Experiments on three public datasets\ndemonstrate the effectiveness of CoType across different domains (e.g., news,\nbiomedical), with an average of 25% improvement in F1 score compared to the\nnext best method.", "published": "2016-10-27 13:20:25", "link": "http://arxiv.org/abs/1610.08763v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Word Embeddings to Enhance Twitter Gang Member Profile Identification", "abstract": "Gang affiliates have joined the masses who use social media to share thoughts\nand actions publicly. Interestingly, they use this public medium to express\nrecent illegal actions, to intimidate others, and to share outrageous images\nand statements. Agencies able to unearth these profiles may thus be able to\nanticipate, stop, or hasten the investigation of gang-related crimes. This\npaper investigates the use of word embeddings to help identify gang members on\nTwitter. Building on our previous work, we generate word embeddings that\ntranslate what Twitter users post in their profile descriptions, tweets,\nprofile images, and linked YouTube content to a real vector format amenable for\nmachine learning classification. Our experimental results show that pre-trained\nword embeddings can boost the accuracy of supervised learning algorithms\ntrained over gang members social media posts.", "published": "2016-10-27 03:21:49", "link": "http://arxiv.org/abs/1610.08597v1", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.IR"], "primary_category": "cs.SI"}
