{"title": "An Overview on Language Models: Recent Developments and Outlook", "abstract": "Language modeling studies the probability distributions over strings of\ntexts. It is one of the most fundamental tasks in natural language processing\n(NLP). It has been widely used in text generation, speech recognition, machine\ntranslation, etc. Conventional language models (CLMs) aim to predict the\nprobability of linguistic sequences in a causal manner, while pre-trained\nlanguage models (PLMs) cover broader concepts and can be used in both causal\nsequential modeling and fine-tuning for downstream applications. PLMs have\ntheir own training paradigms (usually self-supervised) and serve as foundation\nmodels in modern NLP systems. This overview paper provides an introduction to\nboth CLMs and PLMs from five aspects, i.e., linguistic units, architectures,\ntraining methods, evaluation methods, and applications. Furthermore, we discuss\nthe relationship between CLMs and PLMs and shed light on the future directions\nof language modeling in the pre-trained era.", "published": "2023-03-10 07:55:00", "link": "http://arxiv.org/abs/2303.05759v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Creation and evaluation of timelines for longitudinal user posts", "abstract": "There is increasing interest to work with user generated content in social\nmedia, especially textual posts over time. Currently there is no consistent way\nof segmenting user posts into timelines in a meaningful way that improves the\nquality and cost of manual annotation. Here we propose a set of methods for\nsegmenting longitudinal user posts into timelines likely to contain interesting\nmoments of change in a user's behaviour, based on their online posting\nactivity. We also propose a novel framework for evaluating timelines and show\nits applicability in the context of two different social media datasets.\nFinally, we present a discussion of the linguistic content of highly ranked\ntimelines.", "published": "2023-03-10 12:58:34", "link": "http://arxiv.org/abs/2303.05891v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is In-hospital Meta-information Useful for Abstractive Discharge Summary\n  Generation?", "abstract": "During the patient's hospitalization, the physician must record daily\nobservations of the patient and summarize them into a brief document called\n\"discharge summary\" when the patient is discharged. Automated generation of\ndischarge summary can greatly relieve the physicians' burden, and has been\naddressed recently in the research community. Most previous studies of\ndischarge summary generation using the sequence-to-sequence architecture focus\non only inpatient notes for input. However, electric health records (EHR) also\nhave rich structured metadata (e.g., hospital, physician, disease, length of\nstay, etc.) that might be useful. This paper investigates the effectiveness of\nmedical meta-information for summarization tasks. We obtain four types of\nmeta-information from the EHR systems and encode each meta-information into a\nsequence-to-sequence model. Using Japanese EHRs, meta-information encoded\nmodels increased ROUGE-1 by up to 4.45 points and BERTScore by 3.77 points over\nthe vanilla Longformer. Also, we found that the encoded meta-information\nimproves the precisions of its related terms in the outputs. Our results showed\nthe benefit of the use of medical meta-information.", "published": "2023-03-10 16:03:19", "link": "http://arxiv.org/abs/2303.06002v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Susceptibility to Influence of Large Language Models", "abstract": "Two studies tested the hypothesis that a Large Language Model (LLM) can be\nused to model psychological change following exposure to influential input. The\nfirst study tested a generic mode of influence - the Illusory Truth Effect\n(ITE) - where earlier exposure to a statement (through, for example, rating its\ninterest) boosts a later truthfulness test rating. Data was collected from 1000\nhuman participants using an online experiment, and 1000 simulated participants\nusing engineered prompts and LLM completion. 64 ratings per participant were\ncollected, using all exposure-test combinations of the attributes: truth,\ninterest, sentiment and importance. The results for human participants\nreconfirmed the ITE, and demonstrated an absence of effect for attributes other\nthan truth, and when the same attribute is used for exposure and test. The same\npattern of effects was found for LLM-simulated participants. The second study\nconcerns a specific mode of influence - populist framing of news to increase\nits persuasion and political mobilization. Data from LLM-simulated participants\nwas collected and compared to previously published data from a 15-country\nexperiment on 7286 human participants. Several effects previously demonstrated\nfrom the human study were replicated by the simulated study, including effects\nthat surprised the authors of the human study by contradicting their\ntheoretical expectations (anti-immigrant framing of news decreases its\npersuasion and mobilization); but some significant relationships found in human\ndata (modulation of the effectiveness of populist framing according to relative\ndeprivation of the participant) were not present in the LLM data. Together the\ntwo studies support the view that LLMs have potential to act as models of the\neffect of influence.", "published": "2023-03-10 16:53:30", "link": "http://arxiv.org/abs/2303.06074v1", "categories": ["cs.CL", "J.4; I.2.m; I.2.7"], "primary_category": "cs.CL"}
{"title": "Generating Query Focused Summaries without Fine-tuning the\n  Transformer-based Pre-trained Models", "abstract": "Fine-tuning the Natural Language Processing (NLP) models for each new data\nset requires higher computational time associated with increased carbon\nfootprint and cost. However, fine-tuning helps the pre-trained models adapt to\nthe latest data sets; what if we avoid the fine-tuning steps and attempt to\ngenerate summaries using just the pre-trained models to reduce computational\ntime and cost. In this paper, we tried to omit the fine-tuning steps and\ninvestigate whether the Marginal Maximum Relevance (MMR)-based approach can\nhelp the pre-trained models to obtain query-focused summaries directly from a\nnew data set that was not used to pre-train the models. First, we used topic\nmodelling on Wikipedia Current Events Portal (WCEP) and Debatepedia datasets to\ngenerate queries for summarization tasks. Then, using MMR, we ranked the\nsentences of the documents according to the queries. Next, we passed the ranked\nsentences to seven transformer-based pre-trained models to perform the\nsummarization tasks. Finally, we used the MMR approach again to select the\nquery relevant sentences from the generated summaries of individual pre-trained\nmodels and constructed the final summary. As indicated by the experimental\nresults, our MMR-based approach successfully ranked and selected the most\nrelevant sentences as summaries and showed better performance than the\nindividual pre-trained models.", "published": "2023-03-10 22:40:15", "link": "http://arxiv.org/abs/2303.06230v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AUTODIAL: Efficient Asynchronous Task-Oriented Dialogue Model", "abstract": "As large dialogue models become commonplace in practice, the problems\nsurrounding high compute requirements for training, inference and larger memory\nfootprint still persists. In this work, we present AUTODIAL, a multi-task\ndialogue model that addresses the challenges of deploying dialogue model.\nAUTODIAL utilizes parallel decoders to perform tasks such as dialogue act\nprediction, domain prediction, intent prediction, and dialogue state tracking.\nUsing classification decoders over generative decoders allows AUTODIAL to\nsignificantly reduce memory footprint and achieve faster inference times\ncompared to existing generative approach namely SimpleTOD. We demonstrate that\nAUTODIAL provides 3-6x speedups during inference while having 11x fewer\nparameters on three dialogue tasks compared to SimpleTOD. Our results show that\nextending current dialogue models to have parallel decoders can be a viable\nalternative for deploying them in resource-constrained environments.", "published": "2023-03-10 23:34:14", "link": "http://arxiv.org/abs/2303.06245v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Algorithmic Ghost in the Research Shell: Large Language Models and\n  Academic Knowledge Creation in Management Research", "abstract": "The paper looks at the role of large language models in academic knowledge\ncreation based on a scoping review (2018 to January 2023) of how researchers\nhave previously used the language model GPT to assist in the performance of\nacademic knowledge creation tasks beyond data analysis. These tasks include\nwriting, editing, reviewing, dataset creation and curation, which have been\ndifficult to perform using earlier ML tools. Based on a synthesis of these\npapers, this study identifies pathways for a future academic research landscape\nthat incorporates wider usage of large language models based on the current\nmodes of adoption in published articles as a Co-Writer, Research Assistant and\nRespondent.", "published": "2023-03-10 14:25:29", "link": "http://arxiv.org/abs/2303.07304v1", "categories": ["cs.CL", "K.3; K.4; K.6"], "primary_category": "cs.CL"}
{"title": "Do large language models resemble humans in language use?", "abstract": "Large language models (LLMs) such as ChatGPT and Vicuna have shown remarkable\ncapacities in comprehending and producing language. However, their internal\nworkings remain a black box, and it is unclear whether LLMs and chatbots can\ndevelop humanlike characteristics in language use. Cognitive scientists have\ndevised many experiments that probe, and have made great progress in\nexplaining, how people comprehend and produce language. We subjected ChatGPT\nand Vicuna to 12 of these experiments ranging from sounds to dialogue,\npreregistered and with 1000 runs (i.e., iterations) per experiment. ChatGPT and\nVicuna replicated the human pattern of language use in 10 and 7 out of the 12\nexperiments, respectively. The models associated unfamiliar words with\ndifferent meanings depending on their forms, continued to access recently\nencountered meanings of ambiguous words, reused recent sentence structures,\nattributed causality as a function of verb semantics, and accessed different\nmeanings and retrieved different words depending on an interlocutor's identity.\nIn addition, ChatGPT, but not Vicuna, nonliterally interpreted implausible\nsentences that were likely to have been corrupted by noise, drew reasonable\ninferences, and overlooked semantic fallacies in a sentence. Finally, unlike\nhumans, neither model preferred using shorter words to convey less informative\ncontent, nor did they use context to resolve syntactic ambiguities. We discuss\nhow these convergences and divergences may result from the transformer\narchitecture. Overall, these experiments demonstrate that LLMs such as ChatGPT\n(and Vicuna to a lesser extent) are humanlike in many aspects of human language\nprocessing.", "published": "2023-03-10 10:47:59", "link": "http://arxiv.org/abs/2303.08014v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An algebraic approach to translating Japanese", "abstract": "We use Lambek's pregroups and the framework of compositional distributional\nmodels of language (\"DisCoCat\") to study translations from Japanese to English\nas pairs of functors. Adding decorations to pregroups we show how to handle\nword order changes between languages.", "published": "2023-03-10 10:21:20", "link": "http://arxiv.org/abs/2303.05834v1", "categories": ["cs.CL", "math.CT"], "primary_category": "cs.CL"}
{"title": "ChatGPT as the Transportation Equity Information Source for Scientific\n  Writing", "abstract": "Transportation equity is an interdisciplinary agenda that requires both\ntransportation and social inputs. Traditionally, transportation equity\ninformation are sources from public libraries, conferences, televisions, social\nmedia, among other. Artificial intelligence (AI) tools including advanced\nlanguage models such as ChatGPT are becoming favorite information sources.\nHowever, their credibility has not been well explored. This study explored the\ncontent and usefulness of ChatGPT-generated information related to\ntransportation equity. It utilized 152 papers retrieved through the Web of\nScience (WoS) repository. The prompt was crafted for ChatGPT to provide an\nabstract given the title of the paper. The ChatGPT-based abstracts were then\ncompared to human-written abstracts using statistical tools and unsupervised\ntext mining. The results indicate that a weak similarity between ChatGPT and\nhuman-written abstracts. On average, the human-written abstracts and ChatGPT\ngenerated abstracts were about 58% similar, with a maximum and minimum of 97%\nand 1.4%, respectively. The keywords from the abstracts of papers with over the\nmean similarity score were more likely to be similar whereas those from below\nthe average score were less likely to be similar. Themes with high similarity\nscores include access, public transit, and policy, among others. Further, clear\ndifferences in the key pattern of clusters for high and low similarity score\nabstracts was observed. Contrarily, the findings from collocated keywords were\ninconclusive. The study findings suggest that ChatGPT has the potential to be a\nsource of transportation equity information. However, currently, a great amount\nof attention is needed before a user can utilize materials from ChatGPT", "published": "2023-03-10 16:21:54", "link": "http://arxiv.org/abs/2303.11158v1", "categories": ["cs.IR", "cs.CL", "A.1"], "primary_category": "cs.IR"}
{"title": "Logic Against Bias: Textual Entailment Mitigates Stereotypical Sentence\n  Reasoning", "abstract": "Due to their similarity-based learning objectives, pretrained sentence\nencoders often internalize stereotypical assumptions that reflect the social\nbiases that exist within their training corpora. In this paper, we describe\nseveral kinds of stereotypes concerning different communities that are present\nin popular sentence representation models, including pretrained next sentence\nprediction and contrastive sentence representation models. We compare such\nmodels to textual entailment models that learn language logic for a variety of\ndownstream language understanding tasks. By comparing strong pretrained models\nbased on text similarity with textual entailment learning, we conclude that the\nexplicit logic learning with textual entailment can significantly reduce bias\nand improve the recognition of social communities, without an explicit\nde-biasing process", "published": "2023-03-10 02:52:13", "link": "http://arxiv.org/abs/2303.05670v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "MuLTI: Efficient Video-and-Language Understanding with Text-Guided\n  MultiWay-Sampler and Multiple Choice Modeling", "abstract": "Video-and-language understanding has a variety of applications in the\nindustry, such as video question answering, text-video retrieval, and\nmulti-label classification. Existing video-and-language understanding methods\ngenerally adopt heavy multi-modal encoders and feature fusion modules, which\nconsume high computational costs. Specially, they have difficulty dealing with\ndense video frames or long text prevalent in industrial applications. This\npaper proposes MuLTI, a highly accurate and efficient video-and-language\nunderstanding model that achieves efficient and effective feature fusion and\nrapid adaptation to downstream tasks. Specifically, we design a Text-Guided\nMultiWay-Sampler based on adapt-pooling residual mapping and self-attention\nmodules to sample long sequences and fuse multi-modal features, which reduces\nthe computational costs and addresses performance degradation caused by\nprevious samplers. Therefore, MuLTI can handle longer sequences with limited\ncomputational costs. Then, to further enhance the model's performance and fill\nin the lack of pretraining tasks in the video question answering, we propose a\nnew pretraining task named Multiple Choice Modeling. This task bridges the gap\nbetween pretraining and downstream tasks and improves the model's ability to\nalign video and text features. Benefiting from the efficient feature fusion\nmodule and the new pretraining task, MuLTI achieves state-of-the-art\nperformance on multiple datasets. Implementation and pretrained models will be\nreleased.", "published": "2023-03-10 05:22:39", "link": "http://arxiv.org/abs/2303.05707v2", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Clinical BERTScore: An Improved Measure of Automatic Speech Recognition\n  Performance in Clinical Settings", "abstract": "Automatic Speech Recognition (ASR) in medical contexts has the potential to\nsave time, cut costs, increase report accuracy, and reduce physician burnout.\nHowever, the healthcare industry has been slower to adopt this technology, in\npart due to the importance of avoiding medically-relevant transcription\nmistakes. In this work, we present the Clinical BERTScore (CBERTScore), an ASR\nmetric that penalizes clinically-relevant mistakes more than others. We\ndemonstrate that this metric more closely aligns with clinician preferences on\nmedical sentences as compared to other metrics (WER, BLUE, METEOR, etc),\nsometimes by wide margins. We collect a benchmark of 18 clinician preferences\non 149 realistic medical sentences called the Clinician Transcript Preference\nbenchmark (CTP) and make it publicly available for the community to further\ndevelop clinically-aware ASR metrics. To our knowledge, this is the first\npublic dataset of its kind. We demonstrate that CBERTScore more closely matches\nwhat clinicians prefer.", "published": "2023-03-10 06:46:23", "link": "http://arxiv.org/abs/2303.05737v4", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "MIXPGD: Hybrid Adversarial Training for Speech Recognition Systems", "abstract": "Automatic speech recognition (ASR) systems based on deep neural networks are\nweak against adversarial perturbations. We propose mixPGD adversarial training\nmethod to improve the robustness of the model for ASR systems. In standard\nadversarial training, adversarial samples are generated by leveraging\nsupervised or unsupervised methods. We merge the capabilities of both\nsupervised and unsupervised approaches in our method to generate new\nadversarial samples which aid in improving model robustness. Extensive\nexperiments and comparison across various state-of-the-art defense methods and\nadversarial attacks have been performed to show that mixPGD gains 4.1% WER of\nbetter performance than previous best performing models under white-box\nadversarial attack setting. We tested our proposed defense method against both\nwhite-box and transfer based black-box attack settings to ensure that our\ndefense strategy is robust against various types of attacks. Empirical results\non several adversarial attacks validate the effectiveness of our proposed\napproach.", "published": "2023-03-10 07:52:28", "link": "http://arxiv.org/abs/2303.05758v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Robust Knowledge Distillation from RNN-T Models With Noisy Training\n  Labels Using Full-Sum Loss", "abstract": "This work studies knowledge distillation (KD) and addresses its constraints\nfor recurrent neural network transducer (RNN-T) models. In hard distillation, a\nteacher model transcribes large amounts of unlabelled speech to train a student\nmodel. Soft distillation is another popular KD method that distills the output\nlogits of the teacher model. Due to the nature of RNN-T alignments, applying\nsoft distillation between RNN-T architectures having different posterior\ndistributions is challenging. In addition, bad teachers having high\nword-error-rate (WER) reduce the efficacy of KD. We investigate how to\neffectively distill knowledge from variable quality ASR teachers, which has not\nbeen studied before to the best of our knowledge. We show that a sequence-level\nKD, full-sum distillation, outperforms other distillation methods for RNN-T\nmodels, especially for bad teachers. We also propose a variant of full-sum\ndistillation that distills the sequence discriminative knowledge of the teacher\nleading to further improvement in WER. We conduct experiments on public\ndatasets namely SpeechStew and LibriSpeech, and on in-house production data.", "published": "2023-03-10 14:46:23", "link": "http://arxiv.org/abs/2303.05958v1", "categories": ["cs.CL", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Rewarding Chatbots for Real-World Engagement with Millions of Users", "abstract": "The emergence of pretrained large language models has led to the deployment\nof a range of social chatbots for chitchat. Although these chatbots demonstrate\nlanguage ability and fluency, they are not guaranteed to be engaging and can\nstruggle to retain users. This work investigates the development of social\nchatbots that prioritize user engagement to enhance retention, specifically\nexamining the use of human feedback to efficiently develop highly engaging\nchatbots. The proposed approach uses automatic pseudo-labels collected from\nuser interactions to train a reward model that can be used to reject\nlow-scoring sample responses generated by the chatbot model at inference time.\nIntuitive evaluation metrics, such as mean conversation length (MCL), are\nintroduced as proxies to measure the level of engagement of deployed chatbots.\nA/B testing on groups of 10,000 new daily chatbot users on the Chai Research\nplatform shows that this approach increases the MCL by up to 70%, which\ntranslates to a more than 30% increase in user retention for a GPT-J 6B model.\nFuture work aims to use the reward model to realise a data fly-wheel, where the\nlatest user conversations can be used to alternately fine-tune the language\nmodel and the reward model.", "published": "2023-03-10 18:53:52", "link": "http://arxiv.org/abs/2303.06135v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards MoE Deployment: Mitigating Inefficiencies in Mixture-of-Expert\n  (MoE) Inference", "abstract": "Mixture-of-Experts (MoE) models have gained popularity in achieving\nstate-of-the-art performance in a wide range of tasks in computer vision and\nnatural language processing. They effectively expand the model capacity while\nincurring a minimal increase in computation cost during training. However,\ndeploying such models for inference is difficult due to their large size and\ncomplex communication pattern. In this work, we provide a characterization of\ntwo MoE workloads, namely Language Modeling (LM) and Machine Translation (MT)\nand identify their sources of inefficiencies at deployment. We propose three\noptimization techniques to mitigate sources of inefficiencies, namely (1)\nDynamic gating, (2) Expert Buffering, and (3) Expert load balancing. We show\nthat dynamic gating improves maximum throughput by 6.21-11.23$\\times$ for LM,\n5.75-10.98$\\times$ for MT Encoder and 2.58-5.71$\\times$ for MT Decoder. It also\nreduces memory usage by up to 1.36$\\times$ for LM and up to 1.1$\\times$ for MT.\nWe further propose Expert Buffering, a new caching mechanism that only keeps\nhot, active experts in GPU memory while buffering the rest in CPU memory. This\nreduces static memory allocation by up to 1.47$\\times$. We finally propose a\nload balancing methodology that provides additional scalability to the\nworkload.", "published": "2023-03-10 19:30:15", "link": "http://arxiv.org/abs/2303.06182v2", "categories": ["cs.DC", "cs.AR", "cs.CL", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Detection of Abuse in Financial Transaction Descriptions Using Machine\n  Learning", "abstract": "Since introducing changes to the New Payments Platform (NPP) to include\nlonger messages as payment descriptions, it has been identified that people are\nnow using it for communication, and in some cases, the system was being used as\na targeted form of domestic and family violence. This type of tech-assisted\nabuse poses new challenges in terms of identification, actions and approaches\nto rectify this behaviour. Commonwealth Bank of Australia's Artificial\nIntelligence Labs team (CBA AI Labs) has developed a new system using advances\nin deep learning models for natural language processing (NLP) to create a\npowerful abuse detector that periodically scores all the transactions, and\nidentifies cases of high-risk abuse in millions of records. In this paper, we\ndescribe the problem of tech-assisted abuse in the context of banking services,\noutline the developed model and its performance, and the operating framework\nmore broadly.", "published": "2023-03-10 06:10:53", "link": "http://arxiv.org/abs/2303.08016v1", "categories": ["cs.CL", "cs.CY", "cs.LG", "I.2.7; J.4"], "primary_category": "cs.CL"}
{"title": "Exploring AI-Generated Text in Student Writing: How Does AI Help?", "abstract": "English as foreign language_EFL_students' use of text generated from\nartificial intelligence_AI_natural language generation_NLG_tools may improve\ntheir writing quality. However, it remains unclear to what extent AI-generated\ntext in these students' writing might lead to higher-quality writing. We\nexplored 23 Hong Kong secondary school students' attempts to write stories\ncomprising their own words and AI-generated text. Human experts scored the\nstories for dimensions of content, language and organization. We analyzed the\nbasic organization and structure and syntactic complexity of the stories'\nAI-generated text and performed multiple linear regression and cluster\nanalyses. The results show the number of human words and the number of\nAI-generated words contribute significantly to scores. Besides, students can be\ngrouped into competent and less competent writers who use more AI-generated\ntext or less AI-generated text compared to their peers. Comparisons of clusters\nreveal some benefit of AI-generated text in improving the quality of both\nhigh-scoring students' and low-scoring students' writing. The findings can\ninform pedagogical strategies to use AI-generated text for EFL students'\nwriting and to address digital divides. This study contributes designs of NLG\ntools and writing activities to implement AI-generated text in schools.", "published": "2023-03-10 14:36:47", "link": "http://arxiv.org/abs/2304.02478v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "J.5; K.3.1"], "primary_category": "cs.CL"}
{"title": "UNFUSED: UNsupervised Finetuning Using SElf supervised Distillation", "abstract": "In this paper, we introduce UnFuSeD, a novel approach to leverage\nself-supervised learning and reduce the need for large amounts of labeled data\nfor audio classification. Unlike prior works, which directly fine-tune a\nself-supervised pre-trained encoder on a target dataset, we use the encoder to\ngenerate pseudo-labels for unsupervised fine-tuning before the actual\nfine-tuning step. We first train an encoder using a novel self-supervised\nlearning algorithm (SSL) on an unlabeled audio dataset. Then, we use that\nencoder to generate pseudo-labels on our target task dataset via clustering the\nextracted representations. These pseudo-labels are then used to guide\nself-distillation on a randomly initialized model, which we call unsupervised\nfine-tuning. Finally, the resultant encoder is then fine-tuned on our target\ntask dataset. Through UnFuSeD, we propose the first system that moves away from\ngeneric SSL paradigms in literature, which pre-train and fine-tune the same\nencoder, and present a novel self-distillation-based system to leverage SSL\npre-training for low-resource audio classification. In practice, UnFuSeD\nachieves state-of-the-art results on the LAPE Benchmark, significantly\noutperforming all our baselines. Additionally, UnFuSeD allows us to achieve\nthis at a 40% reduction in the number of parameters over the previous\nstate-of-the-art system. We make all our codes publicly available.", "published": "2023-03-10 02:43:36", "link": "http://arxiv.org/abs/2303.05668v2", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Improving Text-Audio Retrieval by Text-aware Attention Pooling and Prior\n  Matrix Revised Loss", "abstract": "In text-audio retrieval (TAR) tasks, due to the heterogeneity of contents\nbetween text and audio, the semantic information contained in the text is only\nsimilar to certain frames within the audio. Yet, existing works aggregate the\nentire audio without considering the text, such as mean-pooling over the\nframes, which is likely to encode misleading audio information not described in\nthe given text. In this paper, we present a text-aware attention pooling (TAP)\nmodule for TAR, which is essentially a scaled dot product attention for a text\nto attend to its most semantically similar frames. Furthermore, previous\nmethods only conduct the softmax for every single-side retrieval, ignoring the\npotential cross-retrieval information. By exploring the intrinsic prior of each\ntext-audio pair, we introduce a prior matrix revised (PMR) loss to filter the\nhard case with high (or low) text-to-audio but low (or high) audio-to-text\nsimilarity scores, thus achieving the dual optimal match. Experiments show that\nour TAP significantly outperforms various text-agnostic pooling functions.\nMoreover, our PMR loss also shows stable performance gains on multiple\ndatasets.", "published": "2023-03-10 03:19:38", "link": "http://arxiv.org/abs/2303.05681v4", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Weakly Supervised Sound Event Detection with Causal\n  Intervention", "abstract": "Existing weakly supervised sound event detection (WSSED) work has not\nexplored both types of co-occurrences simultaneously, i.e., some sound events\noften co-occur, and their occurrences are usually accompanied by specific\nbackground sounds, so they would be inevitably entangled, causing\nmisclassification and biased localization results with only clip-level\nsupervision. To tackle this issue, we first establish a structural causal model\n(SCM) to reveal that the context is the main cause of co-occurrence confounders\nthat mislead the model to learn spurious correlations between frames and\nclip-level labels. Based on the causal analysis, we propose a causal\nintervention (CI) method for WSSED to remove the negative impact of\nco-occurrence confounders by iteratively accumulating every possible context of\neach class and then re-projecting the contexts to the frame-level features for\nmaking the event boundary clearer. Experiments show that our method effectively\nimproves the performance on multiple datasets and can generalize to various\nbaseline models.", "published": "2023-03-10 03:13:36", "link": "http://arxiv.org/abs/2303.05678v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Distribution Preserving Source Separation With Time Frequency Predictive\n  Models", "abstract": "We provide an example of a distribution preserving source separation method,\nwhich aims at addressing perceptual shortcomings of state-of-the-art methods.\nOur approach uses unconditioned generative models of signal sources.\nReconstruction is achieved by means of mix-consistent sampling from a\ndistribution conditioned on a realization of a mix. The separated signals\nfollow their respective source distributions, which provides an advantage when\nseparation results are evaluated in a listening test.", "published": "2023-03-10 13:05:30", "link": "http://arxiv.org/abs/2303.05896v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "An End-to-End Neural Network for Image-to-Audio Transformation", "abstract": "This paper describes an end-to-end (E2E) neural architecture for the audio\nrendering of small portions of display content on low resource personal\ncomputing devices. It is intended to address the problem of accessibility for\nvision-impaired or vision-distracted users at the hardware level. Neural\nimage-to-text (ITT) and text-to-speech (TTS) approaches are reviewed and a new\ntechnique is introduced to efficiently integrate them in a way that is both\nefficient and back-propagate-able, leading to a non-autoregressive E2E\nimage-to-speech (ITS) neural network that is efficient and trainable.\nExperimental results are presented showing that, compared with the non-E2E\napproach, the proposed E2E system is 29% faster and uses 19% fewer parameters\nwith a 2% reduction in phone accuracy. A future direction to address accuracy\nis presented.", "published": "2023-03-10 16:56:09", "link": "http://arxiv.org/abs/2303.06078v1", "categories": ["eess.AS", "cs.AI", "cs.NE"], "primary_category": "eess.AS"}
