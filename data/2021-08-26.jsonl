{"title": "LayoutReader: Pre-training of Text and Layout for Reading Order\n  Detection", "abstract": "Reading order detection is the cornerstone to understanding visually-rich\ndocuments (e.g., receipts and forms). Unfortunately, no existing work took\nadvantage of advanced deep learning models because it is too laborious to\nannotate a large enough dataset. We observe that the reading order of WORD\ndocuments is embedded in their XML metadata; meanwhile, it is easy to convert\nWORD documents to PDFs or images. Therefore, in an automated manner, we\nconstruct ReadingBank, a benchmark dataset that contains reading order, text,\nand layout information for 500,000 document images covering a wide spectrum of\ndocument types. This first-ever large-scale dataset unleashes the power of deep\nneural networks for reading order detection. Specifically, our proposed\nLayoutReader captures the text and layout information for reading order\nprediction using the seq2seq model. It performs almost perfectly in reading\norder detection and significantly improves both open-source and commercial OCR\nengines in ordering text lines in their results in our experiments. We will\nrelease the dataset and model at \\url{https://aka.ms/layoutreader}.", "published": "2021-08-26 05:52:32", "link": "http://arxiv.org/abs/2108.11591v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking Negative Sampling for Handling Missing Entity Annotations", "abstract": "Negative sampling is highly effective in handling missing annotations for\nnamed entity recognition (NER). One of our contributions is an analysis on how\nit makes sense through introducing two insightful concepts: missampling and\nuncertainty. Empirical studies show low missampling rate and high uncertainty\nare both essential for achieving promising performances with negative sampling.\nBased on the sparsity of named entities, we also theoretically derive a lower\nbound for the probability of zero missampling rate, which is only relevant to\nsentence length. The other contribution is an adaptive and weighted sampling\ndistribution that further improves negative sampling via our former analysis.\nExperiments on synthetic datasets and well-annotated datasets (e.g.,\nCoNLL-2003) show that our proposed approach benefits negative sampling in terms\nof F1 score and loss convergence. Besides, models with improved negative\nsampling have achieved new state-of-the-art results on real-world datasets\n(e.g., EC).", "published": "2021-08-26 07:02:57", "link": "http://arxiv.org/abs/2108.11607v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking Why Intermediate-Task Fine-Tuning Works", "abstract": "Supplementary Training on Intermediate Labeled-data Tasks (STILTs) is a\nwidely applied technique, which first fine-tunes the pretrained language models\non an intermediate task before on the target task of interest. While STILTs is\nable to further improve the performance of pretrained language models, it is\nstill unclear why and when it works. Previous research shows that those\nintermediate tasks involving complex inference, such as commonsense reasoning,\nwork especially well for RoBERTa. In this paper, we discover that the\nimprovement from an intermediate task could be orthogonal to it containing\nreasoning or other complex skills -- a simple real-fake discrimination task\nsynthesized by GPT2 can benefit diverse target tasks. We conduct extensive\nexperiments to study the impact of different factors on STILTs. These findings\nsuggest rethinking the role of intermediate fine-tuning in the STILTs pipeline.", "published": "2021-08-26 10:34:37", "link": "http://arxiv.org/abs/2108.11696v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Augmentation for Low-Resource Named Entity Recognition Using\n  Backtranslation", "abstract": "The state of art natural language processing systems relies on sizable\ntraining datasets to achieve high performance. Lack of such datasets in the\nspecialized low resource domains lead to suboptimal performance. In this work,\nwe adapt backtranslation to generate high quality and linguistically diverse\nsynthetic data for low-resource named entity recognition. We perform\nexperiments on two datasets from the materials science (MaSciP) and biomedical\ndomains (S800). The empirical results demonstrate the effectiveness of our\nproposed augmentation strategy, particularly in the low-resource scenario.", "published": "2021-08-26 10:56:39", "link": "http://arxiv.org/abs/2108.11703v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Statutory Article Retrieval Dataset in French", "abstract": "Statutory article retrieval is the task of automatically retrieving law\narticles relevant to a legal question. While recent advances in natural\nlanguage processing have sparked considerable interest in many legal tasks,\nstatutory article retrieval remains primarily untouched due to the scarcity of\nlarge-scale and high-quality annotated datasets. To address this bottleneck, we\nintroduce the Belgian Statutory Article Retrieval Dataset (BSARD), which\nconsists of 1,100+ French native legal questions labeled by experienced jurists\nwith relevant articles from a corpus of 22,600+ Belgian law articles. Using\nBSARD, we benchmark several state-of-the-art retrieval approaches, including\nlexical and dense architectures, both in zero-shot and supervised setups. We\nfind that fine-tuned dense retrieval models significantly outperform other\nsystems. Our best performing baseline achieves 74.8% R@100, which is promising\nfor the feasibility of the task and indicates there is still room for\nimprovement. By the specificity of the domain and addressed task, BSARD\npresents a unique challenge problem for future research on legal information\nretrieval. Our dataset and source code are publicly available.", "published": "2021-08-26 13:50:20", "link": "http://arxiv.org/abs/2108.11792v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Just Say No: Analyzing the Stance of Neural Dialogue Generation in\n  Offensive Contexts", "abstract": "Dialogue models trained on human conversations inadvertently learn to\ngenerate toxic responses. In addition to producing explicitly offensive\nutterances, these models can also implicitly insult a group or individual by\naligning themselves with an offensive statement. To better understand the\ndynamics of contextually offensive language, we investigate the stance of\ndialogue model responses in offensive Reddit conversations. Specifically, we\ncreate ToxiChat, a crowd-annotated dataset of 2,000 Reddit threads and model\nresponses labeled with offensive language and stance. Our analysis reveals that\n42% of human responses agree with toxic comments, whereas only 13% agree with\nsafe comments. This undesirable behavior is learned by neural dialogue models,\nsuch as DialoGPT, which we show are two times more likely to agree with\noffensive comments. To enable automatic detection of offensive language, we\nfine-tuned transformer-based classifiers on ToxiChat that achieve 0.71 F1 for\noffensive labels and 0.53 Macro-F1 for stance labels. Finally, we quantify the\neffectiveness of controllable text generation (CTG) methods to mitigate the\ntendency of neural dialogue models to agree with offensive comments. Compared\nto the baseline, our best CTG model achieves a 19% reduction in agreement with\noffensive comments and produces 29% fewer offensive replies. Our work\nhighlights the need for further efforts to characterize and analyze\ninappropriate behavior in dialogue models, in order to help make them safer.\nOur code and corpus are available at https://github.com/abaheti95/ToxiChat .", "published": "2021-08-26 14:58:05", "link": "http://arxiv.org/abs/2108.11830v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Alleviating Exposure Bias via Contrastive Learning for Abstractive Text\n  Summarization", "abstract": "Encoder-decoder models have achieved remarkable success in abstractive text\nsummarization, which aims to compress one or more documents into a shorter\nversion without the loss of the essential content. Unfortunately, these models\nmostly suffer a discrepancy between training and inference, i.e., the exposure\nbias problem. During the training stage, with teacher forcing these models are\noptimized to maximize the likelihood of the gold summary given the gold summary\ntokens as input to the decoder, while at inference the given tokens are\nreplaced by the generated tokens. Consequently, low-quality summaries are very\nlikely to be generated. To remedy this problem, we propose to leverage\ncontrastive learning to decrease the likelihood of these low-quality summaries,\nand meanwhile increase the likelihood of the gold summary. Since our solution\nexpands the states that the model perceives during training, we expect that the\nexposure bias problem can be alleviated. We experimentally demonstrate that our\nmethod effectively improves the performance of the state-of-the-art model on\ndifferent datasets.", "published": "2021-08-26 15:14:44", "link": "http://arxiv.org/abs/2108.11846v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing Pre-trained Auto-regressive Language Models for Named Entity\n  Typing and Recognition", "abstract": "Despite impressive results of language models for named entity recognition\n(NER), their generalization to varied textual genres, a growing entity type\nset, and new entities remains a challenge. Collecting thousands of annotations\nin each new case for training or fine-tuning is expensive and time-consuming.\nIn contrast, humans can easily identify named entities given some simple\ninstructions. Inspired by this, we challenge the reliance on large datasets and\nstudy pre-trained language models for NER in a meta-learning setup. First, we\ntest named entity typing (NET) in a zero-shot transfer scenario. Then, we\nperform NER by giving few examples at inference. We propose a method to select\nseen and rare / unseen names when having access only to the pre-trained model\nand report results on these groups. The results show: auto-regressive language\nmodels as meta-learners can perform NET and NER fairly well especially for\nregular or seen names; name irregularity when often present for a certain\nentity type can become an effective exploitable cue; names with words foreign\nto the model have the most negative impact on results; the model seems to rely\nmore on name than context cues in few-shot NER.", "published": "2021-08-26 15:29:00", "link": "http://arxiv.org/abs/2108.11857v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Automated Fact-Checking", "abstract": "Fact-checking has become increasingly important due to the speed with which\nboth information and misinformation can spread in the modern media ecosystem.\nTherefore, researchers have been exploring how fact-checking can be automated,\nusing techniques based on natural language processing, machine learning,\nknowledge representation, and databases to automatically predict the veracity\nof claims. In this paper, we survey automated fact-checking stemming from\nnatural language processing, and discuss its connections to related tasks and\ndisciplines. In this process, we present an overview of existing datasets and\nmodels, aiming to unify the various definitions given and identify common\nconcepts. Finally, we highlight challenges for future research.", "published": "2021-08-26 16:34:51", "link": "http://arxiv.org/abs/2108.11896v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HAN: Higher-order Attention Network for Spoken Language Understanding", "abstract": "Spoken Language Understanding (SLU), including intent detection and slot\nfilling, is a core component in human-computer interaction. The natural\nattributes of the relationship among the two subtasks make higher requirements\non fine-grained feature interaction, i.e., the token-level intent features and\nslot features. Previous works mainly focus on jointly modeling the relationship\nbetween the two subtasks with attention-based models, while ignoring the\nexploration of attention order. In this paper, we propose to replace the\nconventional attention with our proposed Bilinear attention block and show that\nthe introduced Higher-order Attention Network (HAN) brings improvement for the\nSLU task. Importantly, we conduct wide analysis to explore the effectiveness\nbrought from the higher-order attention.", "published": "2021-08-26 17:13:08", "link": "http://arxiv.org/abs/2108.11916v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Position-Invariant Truecasing with a Word-and-Character Hierarchical\n  Recurrent Neural Network", "abstract": "Truecasing is the task of restoring the correct case (uppercase or lowercase)\nof noisy text generated either by an automatic system for speech recognition or\nmachine translation or by humans. It improves the performance of downstream NLP\ntasks such as named entity recognition and language modeling. We propose a\nfast, accurate and compact two-level hierarchical word-and-character-based\nrecurrent neural network model, the first of its kind for this problem. Using\nsequence distillation, we also address the problem of truecasing while ignoring\ntoken positions in the sentence, i.e. in a position-invariant manner.", "published": "2021-08-26 17:54:35", "link": "http://arxiv.org/abs/2108.11943v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhanced Seq2Seq Autoencoder via Contrastive Learning for Abstractive\n  Text Summarization", "abstract": "In this paper, we present a denoising sequence-to-sequence (seq2seq)\nautoencoder via contrastive learning for abstractive text summarization. Our\nmodel adopts a standard Transformer-based architecture with a multi-layer\nbi-directional encoder and an auto-regressive decoder. To enhance its denoising\nability, we incorporate self-supervised contrastive learning along with various\nsentence-level document augmentation. These two components, seq2seq autoencoder\nand contrastive learning, are jointly trained through fine-tuning, which\nimproves the performance of text summarization with regard to ROUGE scores and\nhuman evaluation. We conduct experiments on two datasets and demonstrate that\nour model outperforms many existing benchmarks and even achieves comparable\nperformance to the state-of-the-art abstractive systems trained with more\ncomplex architecture and extensive computation resources.", "published": "2021-08-26 18:45:13", "link": "http://arxiv.org/abs/2108.11992v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EmoBERTa: Speaker-Aware Emotion Recognition in Conversation with RoBERTa", "abstract": "We present EmoBERTa: Speaker-Aware Emotion Recognition in Conversation with\nRoBERTa, a simple yet expressive scheme of solving the ERC (emotion recognition\nin conversation) task. By simply prepending speaker names to utterances and\ninserting separation tokens between the utterances in a dialogue, EmoBERTa can\nlearn intra- and inter- speaker states and context to predict the emotion of a\ncurrent speaker, in an end-to-end manner. Our experiments show that we reach a\nnew state of the art on the two popular ERC datasets using a basic and\nstraight-forward approach. We've open sourced our code and models at\nhttps://github.com/tae898/erc.", "published": "2021-08-26 19:34:26", "link": "http://arxiv.org/abs/2108.12009v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Multi-Aspect Explainability Analyses on Machine Reading\n  Comprehension Models", "abstract": "Achieving human-level performance on some of the Machine Reading\nComprehension (MRC) datasets is no longer challenging with the help of powerful\nPre-trained Language Models (PLMs). However, the internal mechanism of these\nartifacts remains unclear, placing an obstacle for further understanding these\nmodels. This paper focuses on conducting a series of analytical experiments to\nexamine the relations between the multi-head self-attention and the final MRC\nsystem performance, revealing the potential explainability in PLM-based MRC\nmodels. To ensure the robustness of the analyses, we perform our experiments in\na multilingual way on top of various PLMs. We discover that passage-to-question\nand passage understanding attentions are the most important ones in the\nquestion answering process, showing strong correlations to the final\nperformance than other parts. Through comprehensive visualizations and case\nstudies, we also observe several general findings on the attention maps, which\ncan be helpful to understand how these models solve the questions.", "published": "2021-08-26 04:23:57", "link": "http://arxiv.org/abs/2108.11574v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AVATAR: A Parallel Corpus for Java-Python Program Translation", "abstract": "Program translation refers to migrating source code from one programming\nlanguage to another. It has tremendous practical value in software development,\nas porting software across languages is time-consuming and costly. Automating\nprogram translation is of paramount importance in software migration, and\nrecently researchers explored unsupervised approaches due to the unavailability\nof parallel corpora. However, the availability of pre-trained language models\nfor programming languages enables supervised fine-tuning with a small number of\nlabeled examples. Therefore, we present AVATAR, a collection of 9,515\nprogramming problems and their solutions written in two popular languages, Java\nand Python. AVATAR is collected from competitive programming sites, online\nplatforms, and open-source repositories. Furthermore, AVATAR includes unit\ntests for 250 examples to facilitate functional correctness evaluation. We\nbenchmark several pre-trained language models fine-tuned on AVATAR. Experiment\nresults show that the models lack in generating functionally accurate code.", "published": "2021-08-26 05:44:20", "link": "http://arxiv.org/abs/2108.11590v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Retrieval Augmented Code Generation and Summarization", "abstract": "Software developers write a lot of source code and documentation during\nsoftware development. Intrinsically, developers often recall parts of source\ncode or code summaries that they had written in the past while implementing\nsoftware or documenting them. To mimic developers' code or summary generation\nbehavior, we propose a retrieval augmented framework, REDCODER, that retrieves\nrelevant code or summaries from a retrieval database and provides them as a\nsupplement to code generation or summarization models. REDCODER has a couple of\nuniqueness. First, it extends the state-of-the-art dense retrieval technique to\nsearch for relevant code or summaries. Second, it can work with retrieval\ndatabases that include unimodal (only code or natural language description) or\nbimodal instances (code-description pairs). We conduct experiments and\nextensive analysis on two benchmark datasets of code generation and\nsummarization in Java and Python, and the promising results endorse the\neffectiveness of our proposed retrieval augmented framework.", "published": "2021-08-26 06:48:13", "link": "http://arxiv.org/abs/2108.11601v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for\n  Emotion Recognition in Conversation", "abstract": "As the use of interactive machines grow, the task of Emotion Recognition in\nConversation (ERC) became more important. If the machine-generated sentences\nreflect emotion, more human-like sympathetic conversations are possible. Since\nemotion recognition in conversation is inaccurate if the previous utterances\nare not taken into account, many studies reflect the dialogue context to\nimprove the performances. Many recent approaches show performance improvement\nby combining knowledge into modules learned from external structured data.\nHowever, structured data is difficult to access in non-English languages,\nmaking it difficult to extend to other languages. Therefore, we extract the\npre-trained memory using the pre-trained language model as an extractor of\nexternal knowledge. We introduce CoMPM, which combines the speaker's\npre-trained memory with the context model, and find that the pre-trained memory\nsignificantly improves the performance of the context model. CoMPM achieves the\nfirst or second performance on all data and is state-of-the-art among systems\nthat do not leverage structured data. In addition, our method shows that it can\nbe extended to other languages because structured knowledge is not required,\nunlike previous methods. Our code is available on github\n(https://github.com/rungjoo/CoMPM).", "published": "2021-08-26 07:45:09", "link": "http://arxiv.org/abs/2108.11626v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AR-BERT: Aspect-relation enhanced Aspect-level Sentiment Classification\n  with Multi-modal Explanations", "abstract": "Aspect level sentiment classification (ALSC) is a difficult problem with\nstate-of-the-art models showing less than 80% macro-F1 score on benchmark\ndatasets. Existing models do not incorporate information on aspect-aspect\nrelations in knowledge graphs (KGs), e.g. DBpedia. Two main challenges stem\nfrom inaccurate disambiguation of aspects to KG entities, and the inability to\nlearn aspect representations from the large KGs in joint training with ALSC\nmodels. We propose AR-BERT, a novel two-level global-local entity embedding\nscheme that allows efficient joint training of KG-based aspect embeddings and\nALSC models. A novel incorrect disambiguation detection technique addresses the\nproblem of inaccuracy in aspect disambiguation. We also introduce the problem\nof determining mode significance in multi-modal explanation generation, and\npropose a two step solution. The proposed methods show a consistent improvement\nof 2.5 - 4.1 percentage points, over the recent BERT-based baselines on\nbenchmark datasets. The code is available at\nhttps://github.com/mainuliitkgp/AR-BERT.git.", "published": "2021-08-26 08:52:04", "link": "http://arxiv.org/abs/2108.11656v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Technological Approaches to Detecting Online Disinformation and\n  Manipulation", "abstract": "The move of propaganda and disinformation to the online environment is\npossible thanks to the fact that within the last decade, digital information\nchannels radically increased in popularity as a news source. The main advantage\nof such media lies in the speed of information creation and dissemination.\nThis, on the other hand, inevitably adds pressure, accelerating editorial work,\nfact-checking, and the scrutiny of source credibility. In this chapter, an\noverview of computer-supported approaches to detecting disinformation and\nmanipulative techniques based on several criteria is presented. We concentrate\non the technical aspects of automatic methods which support fact-checking,\ntopic identification, text style analysis, or message filtering on social media\nchannels. Most of the techniques employ artificial intelligence and machine\nlearning with feature extraction combining available information resources. The\nfollowing text firstly specifies the tasks related to computer detection of\nmanipulation and disinformation spreading. The second section presents concrete\nmethods of solving the tasks of the analysis, and the third sections enlists\ncurrent verification and benchmarking datasets published and used in this area\nfor evaluation and comparison.", "published": "2021-08-26 09:28:50", "link": "http://arxiv.org/abs/2108.11669v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Fine-Tuning Pretrained Language Models With Label Attention for\n  Biomedical Text Classification", "abstract": "The massive scale and growth of textual biomedical data have made its\nindexing and classification increasingly important. However, existing research\non this topic mainly utilized convolutional and recurrent neural networks,\nwhich generally achieve inferior performance than the novel transformers. On\nthe other hand, systems that apply transformers only focus on the target\ndocuments, overlooking the rich semantic information that label descriptions\ncontain. To address this gap, we develop a transformer-based biomedical text\nclassifier that considers label information. The system achieves this with a\nlabel attention module incorporated into the fine-tuning process of pretrained\nlanguage models (PTMs). Our results on two public medical datasets show that\nthe proposed fine-tuning scheme outperforms the vanilla PTMs and\nstate-of-the-art models.", "published": "2021-08-26 14:23:06", "link": "http://arxiv.org/abs/2108.11809v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Computational Approach to Measure Empathy and Theory-of-Mind from\n  Written Texts", "abstract": "Theory-of-mind (ToM), a human ability to infer the intentions and thoughts of\nothers, is an essential part of empathetic experiences. We provide here the\nframework for using NLP models to measure ToM expressed in written texts. For\nthis purpose, we introduce ToM-Diary, a crowdsourced 18,238 diaries with 74,014\nKorean sentences annotated with different ToM levels. Each diary was annotated\nwith ToM levels by trained psychology students and reviewed by selected\npsychology experts. The annotators first divided the diaries based on whether\nthey mentioned other people: self-focused and other-focused. Examples of\nself-focused sentences are \"I am feeling good\". The other-focused sentences\nwere further classified into different levels. These levels differ by whether\nthe writer 1) mentions the presence of others without inferring their mental\nstate(e.g., I saw a man walking down the street), 2) fails to take the\nperspective of others (e.g., I don't understand why they refuse to wear masks),\nor 3) successfully takes the perspective of others (It must have been hard for\nthem to continue working). We tested whether state-of-the-art transformer-based\nmodels (e.g., BERT) could predict underlying ToM levels in sentences. We found\nthat BERT more successfully detected self-focused sentences than other-focused\nones. Sentences that successfully take the perspective of others (the highest\nToM level) were the most difficult to predict. Our study suggests a promising\ndirection for large-scale and computational approaches for identifying the\nability of authors to empathize and take the perspective of others. The dataset\nis at [URL](https://github.com/humanfactorspsych/covid19-tom-empathy-diary)", "published": "2021-08-26 14:23:28", "link": "http://arxiv.org/abs/2108.11810v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "SAUCE: Truncated Sparse Document Signature Bit-Vectors for Fast\n  Web-Scale Corpus Expansion", "abstract": "Recent advances in text representation have shown that training on large\namounts of text is crucial for natural language understanding. However, models\ntrained without predefined notions of topical interest typically require\ncareful fine-tuning when transferred to specialized domains. When a sufficient\namount of within-domain text may not be available, expanding a seed corpus of\nrelevant documents from large-scale web data poses several challenges. First,\ncorpus expansion requires scoring and ranking each document in the collection,\nan operation that can quickly become computationally expensive as the web\ncorpora size grows. Relying on dense vector spaces and pairwise similarity adds\nto the computational expense. Secondly, as the domain concept becomes more\nnuanced, capturing the long tail of domain-specific rare terms becomes\nnon-trivial, especially under limited seed corpora scenarios.\n  In this paper, we consider the problem of fast approximate corpus expansion\ngiven a small seed corpus with a few relevant documents as a query, with the\ngoal of capturing the long tail of a domain-specific set of concept terms. To\nefficiently collect large-scale domain-specific corpora with limited relevance\nfeedback, we propose a novel truncated sparse document bit-vector\nrepresentation, termed Signature Assisted Unsupervised Corpus Expansion\n(SAUCE). Experimental results show that SAUCE can reduce the computational\nburden while ensuring high within-domain lexical coverage.", "published": "2021-08-26 17:58:51", "link": "http://arxiv.org/abs/2108.11948v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Weisfeiler-Leman in the BAMBOO: Novel AMR Graph Metrics and a Benchmark\n  for AMR Graph Similarity", "abstract": "Several metrics have been proposed for assessing the similarity of (abstract)\nmeaning representations (AMRs), but little is known about how they relate to\nhuman similarity ratings. Moreover, the current metrics have complementary\nstrengths and weaknesses: some emphasize speed, while others make the alignment\nof graph structures explicit, at the price of a costly alignment step.\n  In this work we propose new Weisfeiler-Leman AMR similarity metrics that\nunify the strengths of previous metrics, while mitigating their weaknesses.\nSpecifically, our new metrics are able to match contextualized substructures\nand induce n:m alignments between their nodes. Furthermore, we introduce a\nBenchmark for AMR Metrics based on Overt Objectives (BAMBOO), the first\nbenchmark to support empirical assessment of graph-based MR similarity metrics.\nBAMBOO maximizes the interpretability of results by defining multiple overt\nobjectives that range from sentence similarity objectives to stress tests that\nprobe a metric's robustness against meaning-altering and meaning-preserving\ngraph transformations. We show the benefits of BAMBOO by profiling previous\nmetrics and our own metrics. Results indicate that our novel metrics may serve\nas a strong baseline for future work.", "published": "2021-08-26 17:58:54", "link": "http://arxiv.org/abs/2108.11949v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LocTex: Learning Data-Efficient Visual Representations from Localized\n  Textual Supervision", "abstract": "Computer vision tasks such as object detection and semantic/instance\nsegmentation rely on the painstaking annotation of large training datasets. In\nthis paper, we propose LocTex that takes advantage of the low-cost localized\ntextual annotations (i.e., captions and synchronized mouse-over gestures) to\nreduce the annotation effort. We introduce a contrastive pre-training framework\nbetween images and captions and propose to supervise the cross-modal attention\nmap with rendered mouse traces to provide coarse localization signals. Our\nlearned visual features capture rich semantics (from free-form captions) and\naccurate localization (from mouse traces), which are very effective when\ntransferred to various downstream vision tasks. Compared with ImageNet\nsupervised pre-training, LocTex can reduce the size of the pre-training dataset\nby 10x or the target dataset by 2x while achieving comparable or even improved\nperformance on COCO instance segmentation. When provided with the same amount\nof annotations, LocTex achieves around 4% higher accuracy than the previous\nstate-of-the-art \"vision+language\" pre-training approach on the task of PASCAL\nVOC image classification.", "published": "2021-08-26 17:59:07", "link": "http://arxiv.org/abs/2108.11950v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A New Sentence Ordering Method Using BERT Pretrained Model", "abstract": "Building systems with capability of natural language understanding (NLU) has\nbeen one of the oldest areas of AI. An essential component of NLU is to detect\nlogical succession of events contained in a text. The task of sentence ordering\nis proposed to learn succession of events with applications in AI tasks. The\nperformance of previous works employing statistical methods is poor, while the\nneural networks-based approaches are in serious need of large corpora for model\nlearning. In this paper, we propose a method for sentence ordering which does\nnot need a training phase and consequently a large corpus for learning. To this\nend, we generate sentence embedding using BERT pre-trained model and measure\nsentence similarity using cosine similarity score. We suggest this score as an\nindicator of sequential events' level of coherence. We finally sort the\nsentences through brute-force search to maximize overall similarities of the\nsequenced sentences. Our proposed method outperformed other baselines on\nROCStories, a corpus of 5-sentence human-made stories. The method is\nspecifically more efficient than neural network-based methods when no huge\ncorpus is available. Among other advantages of this method are its\ninterpretability and needlessness to linguistic knowledge.", "published": "2021-08-26 18:47:15", "link": "http://arxiv.org/abs/2108.11994v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Semantic-Based Self-Critical Training For Question Generation", "abstract": "Question generation is a conditioned language generation task that consists\nin generating a context-aware question given a context and the targeted answer.\nTrain language modelling with a mere likelihood maximization has been widely\nused while suffering from exposure bias and the discordance between the\ntraining and the test metrics. In the way of addressing this issue, The\npresented work portrays a fully Transformer-based reinforcement learning\ngenerator-evaluation architecture for neural question generation. To edge the\nflexibility of the generation, a semantic-based reward score was externally\ninfused during the training to drive the training of the language model. The\nglobal architecture is laid out in a generator-evaluator fashion optimized\ndirectly to n-gram and semantic-based metrics. Evaluation metrics for language\nmodelling only based on n-gram overlapping do not consider semantic relations\nbetween reference and candidate sequences. To improve the evaluation step, a\ntwo-fold evaluation was carried out. On the one side, an n-gram overlapping\nevaluation using the BLEU score. On the other side, a semantic-based assessment\nusing BERTScore and NUBIA. The results were corroborated by a binary human\nevaluation of the semantic relatedness of the generated question and the ground\ntruth. The results obtained showed that use a semantic-based REINFORCE\nalgorithm for the question generation syntactically reshapes the generated\nquestions while preserving their underlying semantic meaning. Many downstream\napplications can be drawn from a successful question generation including the\nenlargement of question answering datasets, the improvement of conversational\nsystems, the enhancement of autonomous educational assessment systems, and so\nforth.", "published": "2021-08-26 20:33:35", "link": "http://arxiv.org/abs/2108.12026v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Using GAN-based models to sentimental analysis on imbalanced datasets in\n  education domain", "abstract": "While the whole world is still struggling with the COVID-19 pandemic, online\nlearning and home office become more common. Many schools transfer their\ncourses teaching to the online classroom. Therefore, it is significant to mine\nthe students' feedback and opinions from their reviews towards studies so that\nboth schools and teachers can know where they need to improve. This paper\ntrains machine learning and deep learning models using both balanced and\nimbalanced datasets for sentiment classification. Two SOTA category-aware text\ngeneration GAN models: CatGAN and SentiGAN, are utilized to synthesize text\nused to balance the highly imbalanced dataset. Results on three datasets with\ndifferent imbalance degree from distinct domains show that when using generated\ntext to balance the dataset, the F1-score of machine learning and deep learning\nmodel on sentiment classification increases 2.79% ~ 9.28%. Also, the results\nindicate that the average growth degree for CR100k is higher than CR23k, the\naverage growth degree for deep learning is more increased than machine learning\nalgorithms, and the average growth degree for more complex deep learning models\nis more increased than simpler deep learning models in experiments.", "published": "2021-08-26 23:00:27", "link": "http://arxiv.org/abs/2108.12061v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can the Transformer Be Used as a Drop-in Replacement for RNNs in\n  Text-Generating GANs?", "abstract": "In this paper we address the problem of fine-tuned text generation with a\nlimited computational budget. For that, we use a well-performing text\ngenerative adversarial network (GAN) architecture - Diversity-Promoting GAN\n(DPGAN), and attempted a drop-in replacement of the LSTM layer with a\nself-attention-based Transformer layer in order to leverage their efficiency.\nThe resulting Self-Attention DPGAN (SADPGAN) was evaluated for performance,\nquality and diversity of generated text and stability. Computational\nexperiments suggested that a transformer architecture is unable to drop-in\nreplace the LSTM layer, under-performing during the pre-training phase and\nundergoing a complete mode collapse during the GAN tuning phase. Our results\nsuggest that the transformer architecture need to be adapted before it can be\nused as a replacement for RNNs in text-generating GANs.", "published": "2021-08-26 14:15:36", "link": "http://arxiv.org/abs/2108.12275v1", "categories": ["cs.LG", "cs.CL", "68T50, 68T05", "I.2.7"], "primary_category": "cs.LG"}
{"title": "Similar Scenes arouse Similar Emotions: Parallel Data Augmentation for\n  Stylized Image Captioning", "abstract": "Stylized image captioning systems aim to generate a caption not only\nsemantically related to a given image but also consistent with a given style\ndescription. One of the biggest challenges with this task is the lack of\nsufficient paired stylized data. Many studies focus on unsupervised approaches,\nwithout considering from the perspective of data augmentation. We begin with\nthe observation that people may recall similar emotions when they are in\nsimilar scenes, and often express similar emotions with similar style phrases,\nwhich underpins our data augmentation idea. In this paper, we propose a novel\nExtract-Retrieve-Generate data augmentation framework to extract style phrases\nfrom small-scale stylized sentences and graft them to large-scale factual\ncaptions. First, we design the emotional signal extractor to extract style\nphrases from small-scale stylized sentences. Second, we construct the plugable\nmulti-modal scene retriever to retrieve scenes represented with pairs of an\nimage and its stylized caption, which are similar to the query image or caption\nin the large-scale factual data. In the end, based on the style phrases of\nsimilar scenes and the factual description of the current scene, we build the\nemotion-aware caption generator to generate fluent and diversified stylized\ncaptions for the current scene. Extensive experimental results show that our\nframework can alleviate the data scarcity problem effectively. It also\nsignificantly boosts the performance of several existing image captioning\nmodels in both supervised and unsupervised settings, which outperforms the\nstate-of-the-art stylized image captioning methods in terms of both sentence\nrelevance and stylishness by a substantial margin.", "published": "2021-08-26 17:08:58", "link": "http://arxiv.org/abs/2108.11912v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Machine Learning for Mediation in Armed Conflicts", "abstract": "Today's conflicts are becoming increasingly complex, fluid and fragmented,\noften involving a host of national and international actors with multiple and\noften divergent interests. This development poses significant challenges for\nconflict mediation, as mediators struggle to make sense of conflict dynamics,\nsuch as the range of conflict parties and the evolution of their political\npositions, the distinction between relevant and less relevant actors in peace\nmaking, or the identification of key conflict issues and their interdependence.\nInternational peace efforts appear increasingly ill-equipped to successfully\naddress these challenges. While technology is being increasingly used in a\nrange of conflict related fields, such as conflict predicting or information\ngathering, less attention has been given to how technology can contribute to\nconflict mediation. This case study is the first to apply state-of-the-art\nmachine learning technologies to data from an ongoing mediation process. Using\ndialogue transcripts from peace negotiations in Yemen, this study shows how\nmachine-learning tools can effectively support international mediators by\nmanaging knowledge and offering additional conflict analysis tools to assess\ncomplex information. Apart from illustrating the potential of machine learning\ntools in conflict mediation, the paper also emphasises the importance of\ninterdisciplinary and participatory research design for the development of\ncontext-sensitive and targeted tools and to ensure meaningful and responsible\nimplementation.", "published": "2021-08-26 17:53:37", "link": "http://arxiv.org/abs/2108.11942v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SASRA: Semantically-aware Spatio-temporal Reasoning Agent for\n  Vision-and-Language Navigation in Continuous Environments", "abstract": "This paper presents a novel approach for the Vision-and-Language Navigation\n(VLN) task in continuous 3D environments, which requires an autonomous agent to\nfollow natural language instructions in unseen environments. Existing\nend-to-end learning-based VLN methods struggle at this task as they focus\nmostly on utilizing raw visual observations and lack the semantic\nspatio-temporal reasoning capabilities which is crucial in generalizing to new\nenvironments. In this regard, we present a hybrid transformer-recurrence model\nwhich focuses on combining classical semantic mapping techniques with a\nlearning-based method. Our method creates a temporal semantic memory by\nbuilding a top-down local ego-centric semantic map and performs cross-modal\ngrounding to align map and language modalities to enable effective learning of\nVLN policy. Empirical results in a photo-realistic long-horizon simulation\nenvironment show that the proposed approach outperforms a variety of\nstate-of-the-art methods and baselines with over 22% relative improvement in\nSPL in prior unseen environments.", "published": "2021-08-26 17:57:02", "link": "http://arxiv.org/abs/2108.11945v1", "categories": ["cs.RO", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "A Deep Learning Loss Function based on Auditory Power Compression for\n  Speech Enhancement", "abstract": "Deep learning technology has been widely applied to speech enhancement. While\ntesting the effectiveness of various network structures, researchers are also\nexploring the improvement of the loss function used in network training.\nAlthough the existing methods have considered the auditory characteristics of\nspeech or the reasonable expression of signal-to-noise ratio, the correlation\nwith the auditory evaluation score and the applicability of the calculation for\ngradient optimization still need to be improved. In this paper, a\nsignal-to-noise ratio loss function based on auditory power compression is\nproposed. The experimental results show that the overall correlation between\nthe proposed function and the indexes of objective speech intelligibility,\nwhich is better than other loss functions. For the same speech enhancement\nmodel, the training effect of this method is also better than other comparison\nmethods.", "published": "2021-08-26 16:12:38", "link": "http://arxiv.org/abs/2108.11877v4", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Cross-domain Single-channel Speech Enhancement Model with Bi-projection\n  Fusion Module for Noise-robust ASR", "abstract": "In recent decades, many studies have suggested that phase information is\ncrucial for speech enhancement (SE), and time-domain single-channel speech\nenhancement techniques have shown promise in noise suppression and robust\nautomatic speech recognition (ASR). This paper presents a continuation of the\nabove lines of research and explores two effective SE methods that consider\nphase information in time domain and frequency domain of speech signals,\nrespectively. Going one step further, we put forward a novel cross-domain\nspeech enhancement model and a bi-projection fusion (BPF) mechanism for\nnoise-robust ASR. To evaluate the effectiveness of our proposed method, we\nconduct an extensive set of experiments on the publicly-available Aishell-1\nMandarin benchmark speech corpus. The evaluation results confirm the\nsuperiority of our proposed method in relation to a few current top-of-the-line\ntime-domain and frequency-domain SE methods in both enhancement and ASR\nevaluation metrics for the test set of scenarios contaminated with seen and\nunseen noise, respectively.", "published": "2021-08-26 06:29:17", "link": "http://arxiv.org/abs/2108.11598v1", "categories": ["eess.AS", "cs.MM", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Towards Robust Mispronunciation Detection and Diagnosis for L2 English\n  Learners with Accent-Modulating Methods", "abstract": "With the acceleration of globalization, more and more people are willing or\nrequired to learn second languages (L2). One of the major remaining challenges\nfacing current mispronunciation and diagnosis (MDD) models for use in\ncomputer-assisted pronunciation training (CAPT) is to handle speech from L2\nlearners with a diverse set of accents. In this paper, we set out to mitigate\nthe adverse effects of accent variety in building an L2 English MDD system with\nend-to-end (E2E) neural models. To this end, we first propose an effective\nmodeling framework that infuses accent features into an E2E MDD model, thereby\nmaking the model more accent-aware. Going a step further, we design and present\ndisparate accent-aware modules to perform accent-aware modulation of acoustic\nfeatures in a finer-grained manner, so as to enhance the discriminating\ncapability of the resulting MDD model. Extensive sets of experiments conducted\non the L2-ARCTIC benchmark dataset show the merits of our MDD model, in\ncomparison to some existing E2E-based strong baselines and the celebrated\npronunciation scoring based method.", "published": "2021-08-26 07:45:22", "link": "http://arxiv.org/abs/2108.11627v2", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Self-Attention for Audio Super-Resolution", "abstract": "Convolutions operate only locally, thus failing to model global interactions.\nSelf-attention is, however, able to learn representations that capture\nlong-range dependencies in sequences. We propose a network architecture for\naudio super-resolution that combines convolution and self-attention.\nAttention-based Feature-Wise Linear Modulation (AFiLM) uses self-attention\nmechanism instead of recurrent neural networks to modulate the activations of\nthe convolutional model. Extensive experiments show that our model outperforms\nexisting approaches on standard benchmarks. Moreover, it allows for more\nparallelization resulting in significantly faster training.", "published": "2021-08-26 08:05:07", "link": "http://arxiv.org/abs/2108.11637v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Classification of Emotions and Evaluation of Customer Satisfaction from\n  Speech in Real World Acoustic Environments", "abstract": "This paper focuses on finding suitable features to robustly recognize\nemotions and evaluate customer satisfaction from speech in real acoustic\nscenarios. The classification of emotions is based on standard and well-known\ncorpora and the evaluation of customer satisfaction is based on recordings of\nreal opinions given by customers about the received service during phone calls\nwith call-center agents. The feature sets considered in this study include two\nspeaker models, namely x-vectors and i-vectors, and also the well known feature\nset introduced in the Interspeech 2010 Paralinguistics Challenge (I2010PC).\nAdditionally, we introduce the use of phonation, articulation and prosody\nfeatures extracted with the DisVoice framework as alternative feature sets to\nrobustly model emotions and customer satisfaction from speech. The results\nindicate that the I2010PC feature set is the best approach to classify emotions\nin the standard databases typically used in the literature. When considering\nthe recordings collected in the call-center, without any control over the\nacoustic conditions, the best results are obtained with our articulation\nfeatures. The I2010PC feature set includes 1584 measures while the articulation\napproach only includes 488 measures. We think that the proposed approach is\nmore suitable for real-world applications where the acoustic conditions are not\ncontrolled and also it is potentially more convenient for industrial\napplications.", "published": "2021-08-26 18:23:56", "link": "http://arxiv.org/abs/2108.11981v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Bilateral Denoising Diffusion Models", "abstract": "Denoising diffusion probabilistic models (DDPMs) have emerged as competitive\ngenerative models yet brought challenges to efficient sampling. In this paper,\nwe propose novel bilateral denoising diffusion models (BDDMs), which take\nsignificantly fewer steps to generate high-quality samples. From a bilateral\nmodeling objective, BDDMs parameterize the forward and reverse processes with a\nscore network and a scheduling network, respectively. We show that a new lower\nbound tighter than the standard evidence lower bound can be derived as a\nsurrogate objective for training the two networks. In particular, BDDMs are\nefficient, simple-to-train, and capable of further improving any pre-trained\nDDPM by optimizing the inference noise schedules. Our experiments demonstrated\nthat BDDMs can generate high-fidelity samples with as few as 3 sampling steps\nand produce comparable or even higher quality samples than DDPMs using 1000\nsteps with only 16 sampling steps (a 62x speedup).", "published": "2021-08-26 13:23:41", "link": "http://arxiv.org/abs/2108.11514v3", "categories": ["cs.LG", "cs.AI", "cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.LG"}
