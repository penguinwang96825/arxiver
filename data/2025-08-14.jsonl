{"title": "Spirals and Beyond: Competitive Plane Search with Multi-Speed Agents", "abstract": "We consider the problem of minimizing the worst-case search time for a hidden\npoint target in the plane using multiple mobile agents of differing speeds, all\nstarting from a common origin. The search time is normalized by the target's\ndistance to the origin, following the standard convention in competitive\nanalysis. The goal is to minimize the maximum such normalized time over all\ntarget locations, the search cost. As a base case, we extend the known result\nfor a single unit-speed agent, which achieves an optimal cost of about\n$\\mathcal{U}_1 = 17.28935$ via a logarithmic spiral, to $n$ unit-speed agents.\nWe give a symmetric spiral-based algorithm where each agent follows a\nlogarithmic spiral offset by equal angular phases. This yields a search cost\nindependent of which agent finds the target. We provide a closed-form upper\nbound $\\mathcal{U}_n$ for this setting, which we use in our general result. Our\nmain contribution is an upper bound on the worst-case normalized search time\nfor $n$ agents with arbitrary speeds. We give a framework that selects a subset\nof agents and assigns spiral-type trajectories with speed-dependent angular\noffsets, again making the search cost independent of which agent reaches the\ntarget. A corollary shows that $n$ multi-speed agents (fastest speed 1) can\nbeat $k$ unit-speed agents (cost below $\\mathcal{U}_k$) if the geometric mean\nof their speeds exceeds $\\mathcal{U}_n / \\mathcal{U}_k$. This means slow agents\nmay be excluded if they lower the mean too much, motivating non-spiral\nalgorithms. We also give new upper bounds for point search in cones and conic\ncomplements using a single unit-speed agent. These are then used to design\nhybrid spiral-directional strategies, which outperform the spiral-based\nalgorithms when some agents are slow. This suggests that spiral-type\ntrajectories may not be optimal in the general multi-speed setting.", "published": "2025-08-14 16:16:37", "link": "http://arxiv.org/abs/2508.10793v1", "categories": ["cs.DS", "cs.DM"], "primary_category": "cs.DS"}
{"title": "Localization game capture time of trees and outerplanar graphs", "abstract": "The localization game is a variant of the game of Cops and Robber in which\nthe robber is invisible and moves between adjacent vertices, but the cops can\nprobe any $k$ vertices of the graph to obtain the distance between probed\nvertices and the robber. The localization number of a graph is the minimum $k$\nneeded for cops to be able to locate the robber in finite time. The\nlocalization capture time is the number of rounds needed for cops to win.\n  The localization capture time conjecture claims that there exists a constant\n$C$ such that the localization number of every connected graph on $n$ vertices\nis at most $Cn$. While it is known that the conjecture holds for trees, in this\npaper we significantly improve the known upper bound for the localization\ncapture time of trees. We also prove the conjecture for a subclass of\nouterplanar graphs and present a generalization of the localization game that\nappears useful for making further progress towards the conjecture.", "published": "2025-08-14 08:30:16", "link": "http://arxiv.org/abs/2508.10443v1", "categories": ["math.CO", "cs.DM", "05C57, 05C12, 05C05"], "primary_category": "math.CO"}
{"title": "An Iterative Algorithm for Differentially Private $k$-PCA with Adaptive Noise", "abstract": "Given $n$ i.i.d. random matrices $A_i \\in \\mathbb{R}^{d \\times d}$ that share\na common expectation $\\Sigma$, the objective of Differentially Private\nStochastic PCA is to identify a subspace of dimension $k$ that captures the\nlargest variance directions of $\\Sigma$, while preserving differential privacy\n(DP) of each individual $A_i$. Existing methods either (i) require the sample\nsize $n$ to scale super-linearly with dimension $d$, even under Gaussian\nassumptions on the $A_i$, or (ii) introduce excessive noise for DP even when\nthe intrinsic randomness within $A_i$ is small. Liu et al. (2022a) addressed\nthese issues for sub-Gaussian data but only for estimating the top eigenvector\n($k=1$) using their algorithm DP-PCA. We propose the first algorithm capable of\nestimating the top $k$ eigenvectors for arbitrary $k \\leq d$, whilst overcoming\nboth limitations above. For $k=1$ our algorithm matches the utility guarantees\nof DP-PCA, achieving near-optimal statistical error even when $n =\n\\tilde{\\!O}(d)$. We further provide a lower bound for general $k > 1$, matching\nour upper bound up to a factor of $k$, and experimentally demonstrate the\nadvantages of our algorithm over comparable baselines.", "published": "2025-08-14 17:48:45", "link": "http://arxiv.org/abs/2508.10879v1", "categories": ["stat.ML", "cs.CR", "cs.IT", "cs.LG", "math.IT", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "MapLibre Tile: A Next Generation Vector Tile Format", "abstract": "The Mapbox Vector Tile (MVT) format is widely considered the leading open\nstandard for large-scale map visualization, as evidenced by its widespread\nadoption by major technology companies such as AWS, Meta, and Microsoft for\ntheir products and services. However, MVT was developed nearly a decade ago\nand, consequently, does not fully align with the capabilities of new geospatial\ndata sources that are characterized by rapidly increasing data volumes due to\nadvancements in geospatial sensors and automated detection through artificial\nintelligence. In this paper, we introduce the MapLibre Tile (MLT) format, a\nnovel vector tile specification designed from the ground up to address the\nlimitations of MVT. Our experiments, simulating user sessions on widely used\nbasemap datasets, demonstrate that MLT achieves up to three times better\ncompression ratios compared to MVT on encoded tilesets, with over six times\nbetter on certain large tiles. Additionally, MLT offers decoding speeds that\nare up to three times faster and significantly enhances processing performance.\nMLT also introduces new functionalities and is specifically designed to lay the\nfoundation for the next generation of map renderers, which we expect to\nentirely offload processing to the GPU, thereby overcoming the stagnation of\nMoore`s law.", "published": "2025-08-14 16:16:04", "link": "http://arxiv.org/abs/2508.10791v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Predictive Position Control for Movable Antenna Arrays in UAV Communications: A Spatio-Temporal Transformer-LSTM Framework", "abstract": "In complex urban environments, dynamic obstacles and multipath effects lead\nto significant link attenuation and pervasive coverage blind spots.\nConventional approaches based on large-scale fixed antenna arrays and UAV\ntrajectory optimization struggle to balance energy efficiency, real-time\nadaptation, and spatial flexibility. The movable antenna (MA) technology has\nemerged as a promising solution, offering enhanced spatial flexibility and\nreduced energy consumption to overcome the bottlenecks of urban low-altitude\ncommunications. However, MA deployment faces a critical velocity mismatch\nbetween UAV mobility and mechanical repositioning latency, undermining\nreal-time link optimization and security assurance. To overcome this, we\npropose a predictive MA-UAV collaborative control framework. First, optimal\nantenna positions are derived via secrecy rate maximization. Second, a\nTransformer-enhanced long short-term memory (LSTM) network predicts future MA\npositions by capturing spatio-temporal correlations in antenna trajectories.\nExtensive simulations demonstrate superior prediction accuracy (NMSE reduction\nexceeds 49\\%) and communication reliability versus current popular benchmarks.", "published": "2025-08-14 15:00:51", "link": "http://arxiv.org/abs/2508.10720v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Novel Study on Intelligent Methods and Explainable AI for Dynamic Malware Analysis", "abstract": "Deep learning models are one of the security strategies, trained on extensive\ndatasets, and play a critical role in detecting and responding to these threats\nby recognizing complex patterns in malicious code. However, the opaque nature\nof these models-often described as \"black boxes\"-makes their decision-making\nprocesses difficult to understand, even for their creators. This research\naddresses these challenges by integrating Explainable AI (XAI) techniques to\nenhance the interpretability and trustworthiness of malware detection models.\nIn this research, the use of Multi-Layer Perceptrons (MLP) for dynamic malware\nanalysis has been considered, a less explored area, and its efficacy in\ndetecting Metamorphic Malware, and further the effectiveness and transparency\nof MLPs, CNNs, RNNs, and CNN-LSTM models in malware classification, evaluating\nthese models through the lens of Explainable AI (XAI). This comprehensive\napproach aims to demystify the internal workings of deep learning models,\npromoting a better understanding and trust in their predictive capabilities in\ncybersecurity contexts. Such in-depth analysis and implementation haven't been\ndone to the best of our knowledge.", "published": "2025-08-14 13:49:29", "link": "http://arxiv.org/abs/2508.10652v1", "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "cs.CR"}
{"title": "A Transformer-Based Approach for DDoS Attack Detection in IoT Networks", "abstract": "DDoS attacks have become a major threat to the security of IoT devices and\ncan cause severe damage to the network infrastructure. IoT devices suffer from\nthe inherent problem of resource constraints and are therefore susceptible to\nsuch resource-exhausting attacks. Traditional methods for detecting DDoS\nattacks are not efficient enough to cope with the dynamic nature of IoT\nnetworks, as well as the scalability of the attacks, diversity of protocols,\nhigh volume of traffic, and variability in device behavior, and variability of\nprotocols like MQTT, CoAP, making it hard to implement security across all the\nprotocols. In this paper, we propose a novel approach, i.e., the use of\nTransformer models, which have shown remarkable performance in natural language\nprocessing tasks, for detecting DDoS attacks on IoT devices. The proposed model\nextracts features from network traffic data and processes them using a\nself-attention mechanism. Experiments conducted on a real-world dataset\ndemonstrate that the proposed approach outperforms traditional machine learning\ntechniques, which can be validated by comparing both approaches' accuracy,\nprecision, recall, and F1-score. The results of this study show that the\nTransformer models can be an effective solution for detecting DDoS attacks on\nIoT devices and have the potential to be deployed in real-world IoT\nenvironments.", "published": "2025-08-14 13:33:49", "link": "http://arxiv.org/abs/2508.10636v1", "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "cs.CR"}
{"title": "Contrastive ECOC: Learning Output Codes for Adversarial Defense", "abstract": "Although one-hot encoding is commonly used for multiclass classification, it\nis not always the most effective encoding mechanism. Error Correcting Output\nCodes (ECOC) address multiclass classification by mapping each class to a\nunique codeword used as a label. Traditional ECOC methods rely on manually\ndesigned or randomly generated codebooks, which are labor-intensive and may\nyield suboptimal, dataset-agnostic results. This paper introduces three models\nfor automated codebook learning based on contrastive learning, allowing\ncodebooks to be learned directly and adaptively from data. Across four\ndatasets, our proposed models demonstrate superior robustness to adversarial\nattacks compared to two baselines. The source is available at\nhttps://github.com/YuChou20/Automated-Codebook-Learning-with-Error-Correcting-Output-Code-Technique.", "published": "2025-08-14 09:50:50", "link": "http://arxiv.org/abs/2508.10491v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Integrated Communication and Remote Sensing in LEO Satellite Systems: Protocol, Architecture and Prototype", "abstract": "In this paper, we explore the integration of communication and synthetic\naperture radar (SAR)-based remote sensing in low Earth orbit (LEO) satellite\nsystems to provide real-time SAR imaging and information transmission.\nConsidering the high-mobility characteristics of satellite channels and limited\nprocessing capabilities of satellite payloads, we propose an integrated\ncommunication and remote sensing architecture based on an orthogonal\ndelay-Doppler division multiplexing (ODDM) signal waveform. Both communication\nand SAR imaging functionalities are achieved with an integrated transceiver\nonboard the LEO satellite, utilizing the same waveform and radio frequency (RF)\nfront-end. Based on such an architecture, we propose a transmission protocol\ncompatible with the 5G NR standard using downlink pilots for joint channel\nestimation and SAR imaging. Furthermore, we design a unified signal processing\nframework for the integrated satellite receiver to simultaneously achieve\nhigh-performance channel sensing, low-complexity channel equalization and\ninterference-free SAR imaging. Finally, the performance of the proposed\nintegrated system is demonstrated through comprehensive analysis and extensive\nsimulations in the sub-6 GHz band. Moreover, a software-defined radio (SDR)\nprototype is presented to validate its effectiveness for real-time SAR imaging\nand information transmission in satellite direct-connect user equipment (UE)\nscenarios within the millimeter-wave (mmWave) band.", "published": "2025-08-14 03:44:45", "link": "http://arxiv.org/abs/2508.10317v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Energy-Efficient Index and Code Index Modulations for Spread CPM Signals in Internet of Things", "abstract": "The evolution of Internet of Things technologies is driven by four key\ndemands: ultra-low power consumption, high spectral efficiency, reduced\nimplementation cost, and support for massive connectivity. To address these\nchallenges, this paper proposes two novel modulation schemes that integrate\ncontinuous phase modulation (CPM) with spread spectrum (SS) techniques. We\nbegin by establishing the quasi-orthogonality properties of CPM-SS sequences.\nThe first scheme, termed IM-CPM-SS, employs index modulation (IM) to select\nspreading sequences from the CPM-SS set, thereby improving spectral efficiency\nwhile maintaining the constant-envelope property. The second scheme, referred\nto as CIM-CPM-SS, introduces code index modulation (CIM), which partitions the\ninput bits such that one subset is mapped to phase-shift keying symbols and the\nother to CPM-SS sequence indices. Both schemes are applied to downlink\nnon-orthogonal multiple access (NOMA) systems. We analyze their performance in\nterms of bit error rate (BER), spectral and energy efficiency, computational\ncomplexity, and peak-to-average power ratio characteristics under nonlinear\namplifier conditions. Simulation results demonstrate that both schemes\noutperform conventional approaches in BER while preserving the benefits of\nconstant-envelope, continuous-phase signaling. Furthermore, they achieve higher\nspectral and energy efficiency and exhibit strong resilience to nonlinear\ndistortions in downlink NOMA scenarios.", "published": "2025-08-14 02:37:15", "link": "http://arxiv.org/abs/2508.10290v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "The Conditional Regret-Capacity Theorem for Batch Universal Prediction", "abstract": "We derive a conditional version of the classical regret-capacity theorem.\nThis result can be used in universal prediction to find lower bounds on the\nminimal batch regret, which is a recently introduced generalization of the\naverage regret, when batches of training data are available to the predictor.\nAs an example, we apply this result to the class of binary memoryless sources.\nFinally, we generalize the theorem to R\\'enyi information measures, revealing a\ndeep connection between the conditional R\\'enyi divergence and the conditional\nSibson's mutual information.", "published": "2025-08-14 02:17:10", "link": "http://arxiv.org/abs/2508.10282v1", "categories": ["cs.IT", "cs.LG", "math.IT", "stat.ML"], "primary_category": "cs.IT"}
{"title": "Space-time Coded Differential Modulation for Reconfigurable Intelligent Surfaces", "abstract": "Reconfigurable Intelligent Surfaces (RIS) hold the promise of improving\nsignificantly coverage, as well as spectral and energy efficiency in wireless\ncommunication systems. Techniques based on RIS form a key technology for 6G\nsystems. An important issue in RIS technology is Channel State Information\n(CSI), which is much more difficult to acquire in such systems. This work\nintroduces a Differential Space-Time Modulation (DSTM) scheme integrated with\nDifferential Reflecting Modulation (DRM) to bypass the requirement for CSI in\nsuch systems, while providing error rate gains. The DSTM scheme is based on\nunitary group codes. We first consider uncoded DRM for RIS to serve as a\nreference point. Next we provide an overview of DSTM and outline the procedures\nfor its integration with DRM. Furthermore, we explore the extension of both the\noriginal DRM and the coded DRM-DSTM scheme to a larger number of RIS reflecting\npatterns $K$, and provide tables of codes for $K= 2, 3, 4$. Encoding and\ndecoding complexities are studied as well. Extensives simulation results over\nquasi-static Rayleigh fading channels confirm the effectiveness of the DRM-DSTM\ncoded system, illustrating its advantages over uncoded DRM with proper system\nparameters.", "published": "2025-08-14 00:16:35", "link": "http://arxiv.org/abs/2508.10244v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Agentic Design Review System", "abstract": "Evaluating graphic designs involves assessing it from multiple facets like\nalignment, composition, aesthetics and color choices. Evaluating designs in a\nholistic way involves aggregating feedback from individual expert reviewers.\nTowards this, we propose an Agentic Design Review System (AgenticDRS), where\nmultiple agents collaboratively analyze a design, orchestrated by a meta-agent.\nA novel in-context exemplar selection approach based on graph matching and a\nunique prompt expansion method plays central role towards making each agent\ndesign aware. Towards evaluating this framework, we propose DRS-BENCH\nbenchmark. Thorough experimental evaluation against state-of-the-art baselines\nadapted to the problem setup, backed-up with critical ablation experiments\nbrings out the efficacy of Agentic-DRS in evaluating graphic designs and\ngenerating actionable feedback. We hope that this work will attract attention\nto this pragmatic, yet under-explored research direction.", "published": "2025-08-14 15:29:24", "link": "http://arxiv.org/abs/2508.10745v1", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.MA", "cs.MM"], "primary_category": "cs.AI"}
{"title": "A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation", "abstract": "Real-world multimodal applications often require any-to-any capabilities,\nenabling both understanding and generation across modalities including text,\nimage, audio, and video. However, integrating the strengths of autoregressive\nlanguage models (LLMs) for reasoning and diffusion models for high-fidelity\ngeneration remains challenging. Existing approaches rely on rigid pipelines or\ntightly coupled architectures, limiting flexibility and scalability. We propose\nMAGUS (Multi-Agent Guided Unified Multimodal System), a modular framework that\nunifies multimodal understanding and generation via two decoupled phases:\nCognition and Deliberation. MAGUS enables symbolic multi-agent collaboration\nwithin a shared textual workspace. In the Cognition phase, three\nrole-conditioned multimodal LLM agents - Perceiver, Planner, and Reflector -\nengage in collaborative dialogue to perform structured understanding and\nplanning. The Deliberation phase incorporates a Growth-Aware Search mechanism\nthat orchestrates LLM-based reasoning and diffusion-based generation in a\nmutually reinforcing manner. MAGUS supports plug-and-play extensibility,\nscalable any-to-any modality conversion, and semantic alignment - all without\nthe need for joint training. Experiments across multiple benchmarks, including\nimage, video, and audio generation, as well as cross-modal instruction\nfollowing, demonstrate that MAGUS outperforms strong baselines and\nstate-of-the-art systems. Notably, on the MME benchmark, MAGUS surpasses the\npowerful closed-source model GPT-4o.", "published": "2025-08-14 09:52:51", "link": "http://arxiv.org/abs/2508.10494v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "The Hu-Zhang element for linear elasticity on curved domains", "abstract": "This paper extends the Hu-Zhang element for linear elasticity problems to\ncurved domains, preserving strong symmetry and H(div)-conformity. The\nnon-polynomial structure of the curved Hu-Zhang element makes it difficult to\nanalyze the stability result, which is overcome by establishing a novel inf-sup\ncondition. Optimal convergence rates are achieved for all variables except the\nstress $L^2$-error. This suboptimality originates from the fact that the\ndivergence space of the curved Hu-Zhang element is not contained in the\ndiscrete displacement space, which is rectified by local $p$-enrichment in the\nHu-Zhang space on curved boundary elements. Some numerical experiments validate\nthe theoretical results.", "published": "2025-08-14 14:18:04", "link": "http://arxiv.org/abs/2508.10674v1", "categories": ["math.NA", "cs.NA", "65N12, 65N30, 74S05"], "primary_category": "math.NA"}
{"title": "Isogeometric multi-patch shell analysis using the Geometry + Simulation Modules", "abstract": "Isogeometric Analysis (IGA) bridges Computer-Aided Design (CAD) and Finite\nElement Analysis (FEA) by employing splines as a common basis for geometry and\nanalysis. One of the advantages of IGA is in the realm of thin shell analysis:\ndue to the arbitrary continuity of the spline basis, Kirchhoff-Love shells can\nbe modeled without the need to introduce unknowns for the mid-plane rotations,\nleading to a reduction in the number of unknowns. In this paper, we provide the\nbackground of an implementation of Isogeometric Kirchhoff--Love shells within\nthe Geometry + Simulation Modules (G+Smo). This paper accompanies multiple\nprevious publications and elaborates on the design of the software used in\nthese papers, rather than the novelty of the methods presented therein. The\npresented implementation provides patch coupling via penalty methods and\nunstructured splines, goal-oriented error estimators, several algorithms for\nstructural analysis and advanced algorithms for the modeling of wrinkling in\nhyperelastic membranes. These methods are all contained in three new modules in\nG+Smo: a module for Kirchhoff-Love shells, a module for structural analysis,\nand a module for unstructured spline constructions. As motivated in this paper,\nthe modules are implemented to be compatible with future developments. For\nexample, by providing base implementations of material laws, by using black-box\nfunctions for the structural analysis module, or by providing a standardized\napproach for the implementation of unstructured spline constructions. Overall,\nthis paper demonstrates that the new modules contribute to a versatile\necosystem for the modeling of multi-patch shell problems through fast\noff-the-shelf solvers with a simple interface, designed to be extended in\nfuture research.", "published": "2025-08-14 13:44:48", "link": "http://arxiv.org/abs/2508.10648v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Nonlinear filtering based on density approximation and deep BSDE prediction", "abstract": "A novel approximate Bayesian filter based on backward stochastic differential\nequations is introduced. It uses a nonlinear Feynman--Kac representation of the\nfiltering problem and the approximation of an unnormalized filtering density\nusing the well-known deep BSDE method and neural networks. The method is\ntrained offline, which means that it can be applied online with new\nobservations. A mixed a priori-a posteriori error bound is proved under an\nelliptic condition. The theoretical convergence rate is confirmed in two\nnumerical examples.", "published": "2025-08-14 13:31:05", "link": "http://arxiv.org/abs/2508.10630v1", "categories": ["math.NA", "cs.NA", "stat.CO", "stat.ML", "60G25, 60G35, 62F15, 62G07, 62M20, 65C30, 65M75, 68T07"], "primary_category": "math.NA"}
{"title": "A Unified Framework from Boltzmann Transport to Proton Treatment Planning", "abstract": "This work develops a rigorous mathematical formulation of proton transport by\nintegrating both deterministic and stochastic perspectives. The deterministic\nframework is based on the Boltzmann-Fokker-Planck equation, formulated as an\noperator equation in a suitable functional setting. The stochastic approach\nmodels proton evolution via a track-length parameterised diffusion process,\nwhose infinitesimal generator provides an alternative description of transport.\n  A key result is the duality between the stochastic and deterministic\nformulations, established through the adjoint relationship between the\ntransport operator and the stochastic generator. We prove that the resolvent of\nthe stochastic process corresponds to the Green's function of the deterministic\nequation, providing a natural link between fluence-based and particle-based\ntransport descriptions. The theory is applied to dose computation, where we\nshow that the classical relation: dose = (fluence * mass stopping power) arises\nconsistently in both approaches.\n  Building on this foundation, we formulate a hybrid optimisation framework for\ntreatment planning, in which dose is computed using a stochastic model while\noptimisation proceeds via adjoint-based PDE methods. We prove existence and\ndifferentiability of the objective functional and derive the first-order\noptimality system. This framework bridges stochastic simulation with\ndeterministic control theory and provides a foundation for future work in\nconstrained, adaptive and uncertainty-aware optimisation in proton therapy.", "published": "2025-08-14 12:37:25", "link": "http://arxiv.org/abs/2508.10596v1", "categories": ["math.PR", "cs.NA", "math.NA", "math.OC", "physics.med-ph"], "primary_category": "math.PR"}
{"title": "Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer", "abstract": "To bridge the temporal granularity gap in energy network design and operation\nbased on Energy System Models, resampling of time series is required. While\nconventional upsampling methods are computationally efficient, they often\nresult in significant information loss or increased noise. Advanced models such\nas time series generation models, Super-Resolution models and imputation models\nshow potential, but also face fundamental challenges. The goal of time series\ngenerative models is to learn the distribution of the original data to generate\nhigh-resolution series with similar statistical characteristics. This is not\nentirely consistent with the definition of upsampling. Time series\nSuper-Resolution models or imputation models can degrade the accuracy of\nupsampling because the input low-resolution time series are sparse and may have\ninsufficient context. Moreover, such models usually rely on supervised learning\nparadigms. This presents a fundamental application paradox: their training\nrequires the high-resolution time series that is intrinsically absent in\nupsampling application scenarios. To address the mentioned upsampling issue,\nthis paper introduces a new method utilizing Generative Adversarial\nTransformers (GATs), which can be trained without access to any ground-truth\nhigh-resolution data. Compared with conventional interpolation methods, the\nintroduced method can reduce the root mean square error (RMSE) of upsampling\ntasks by 9%, and the accuracy of a model predictive control (MPC) application\nscenario is improved by 13%.", "published": "2025-08-14 12:25:39", "link": "http://arxiv.org/abs/2508.10587v1", "categories": ["cs.LG", "cs.NA", "eess.SP", "math.NA"], "primary_category": "cs.LG"}
{"title": "Efficient and Optimally Accurate Numerical Algorithms for Stochastic Turbulent Flow Problems", "abstract": "In this paper, we first propose a filter-based continuous Ensemble Eddy\nViscosity (EEV) model for stochastic turbulent flow problems. We then propose a\ngeneric algorithm for a family of fully discrete, grad-div regularized,\nefficient ensemble parameterized schemes for this model. The linearized\nImplicit-Explicit (IMEX) EEV generic algorithm shares a common coefficient\nmatrix for each realization per time-step, but with different right-hand-side\nvectors, which reduces the computational cost and memory requirements to the\norder of solving deterministic flow problems. Two family members of the\nproposed time-stepping algorithm are analyzed and proven to be stable. It is\nfound that one is first-order and the other is second-order accurate in time\nfor any stable finite element pairs. Avoiding the discrete inverse inequality,\nthe optimal convergence of both schemes is proven rigorously for both 2D and 3D\nproblems. For appropriately large grad-div parameters, both schemes are\nunconditionally stable and allow weakly divergence-free elements. Several\nnumerical tests are given for high expected Reynolds number ($\\textbf{E}[Re]$)\nproblems. The convergence rates are verified using manufactured solutions with\n$\\textbf{E}[Re]=10^{3},10^{4},\\;\\text{and}\\; 10^{5}$. For various high\n$\\textbf{E}[Re]$, the schemes are implemented on benchmark problems which\nincludes: A 2D channel flow over a unit step problem, a non-intrusive\nStochastic Collocation Method (SCM) is used to examine the performance of the\nschemes on a 2D Regularized Lid Driven Cavity (RLDC) problem, and a 3D RLDC\nproblem, and found them perform well.", "published": "2025-08-14 12:14:55", "link": "http://arxiv.org/abs/2508.10578v1", "categories": ["math.NA", "cs.NA", "65M12, 65M22, 65M60, 76W05"], "primary_category": "math.NA"}
{"title": "CutVEM: Conforming virtual element method on embedded domains with shape-agnostic element agglomeration", "abstract": "The virtual element method (VEM) is a stabilized Galerkin method that is\nrobust and accurate on general polygonal meshes. This feature makes it an\nappealing candidate for simulations involving meshes with embedded interfaces\nand evolving geometries. However, the method can yield poorly conditioned\nstiffness matrices in such scenarios due to meshes having cut cells. We propose\na novel element agglomeration algorithm for the virtual element method to\naddress this issue. The agglomeration algorithm renders the VEM robust over\nplanar polygonal meshes, particularly on finite element meshes cut by immersed\ngeometries. The algorithm relies on the element stability ratio, which we\ndefine using the extreme eigenvalues of the element stiffness matrix. The\nresulting element agglomeration criterion is free from nebulous polygon quality\nmetrics and is defined independently of polygon shapes. The algorithm proceeds\niteratively and element-wise to maximize the minimum element stability ratio,\neven at the expense of degrading elements with better ratios. Crucially,\nelement agglomeration alters the number of elements, not the degree of freedom\ncount. The resulting method, which we label as CutVEM, retains node locations\nof cut elements unchanged, and yields discretizations that conform to embedded\ninterfaces. This, in turn, facilitates straightforward imposition of boundary\nconditions and interfacial constraints. Through detailed numerical experiments\nthat sample varied element-interface intersections, we demonstrate that CutVEM\nenjoys dramatically improved condition numbers of global stiffness matrices\nover the VEM. Furthermore, simulations of prototypical heat conduction problems\nwith Dirichlet and Neumann boundary conditions on domains with immersed\ngeometries show that element agglomeration does not noticeably degrade solution\naccuracy and that CutVEM retains the VEM's optimal convergence rate.", "published": "2025-08-14 12:10:01", "link": "http://arxiv.org/abs/2508.10570v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "RBF-FD Method for Some Dispersive Wave Equations and Their Eventual Periodicity", "abstract": "In this paper, we approximate the solution and also discuss the periodic\nbehavior termed as eventual periodicity of solutions of (IBVPs) for some\ndispersive wave equations on a bounded domain corresponding to periodic\nforcing. The constructed numerical scheme is based on radial kernels and local\nin nature like finite difference method. The temporal variable is executed\nthrough RK4 scheme. Due to the local nature and sparse differentiation matrices\nour numerical scheme efficiently recovers the solution. The results achieved\nare validated and examined with other methods accessible in the literature.", "published": "2025-08-14 11:56:13", "link": "http://arxiv.org/abs/2508.10558v1", "categories": ["math.NA", "cs.NA", "33F05, 34K10, 34K13, 34K28, 35Q51, 35Q53"], "primary_category": "math.NA"}
{"title": "On The Eventual Periodicity of Fractional Order Dispersive Wave Equations Using RBFs and Transform", "abstract": "In this research work, let us focus on the construction of numerical scheme\nbased on radial basis functions finite difference (RBF-FD) method combined with\nthe Laplace transform for the solution of fractional order dispersive wave\nequations. The numerical scheme is then applied to examine the eventual\nperiodicity of the proposed model subject to the periodic boundary conditions.\nThe implementation of proposed technique for high order fractional and integer\ntype nonlinear partial differential equations (PDEs) is beneficial because this\nmethod is local in nature, therefore it yields and resulted in sparse\ndifferentiation matrices instead of full and dense matrices. Only small\ndimensions of linear systems of equations are to be solved for every center in\nthe domain and hence this procedure is more reliable and efficient to solve\nlarge scale physical and engineering problems in complex domain. Laplace\ntransform is utilized for obtaining the equivalent time-independent equation in\nLaplace space and also valuable to handle time-fractional derivatives in the\nCaputo sense. Application of Laplace transform avoids the time steeping\nprocedure which commonly encounters the time instability issues. The solution\nto the transformed model is then obtained by computing the inversion of Laplace\ntransform with an appropriate contour in a complex space, which is approximated\nby trapezoidal rule with high accuracy. Also since the Laplace transform\noperator is linear, it cannot be used to transform non-linear terms therefore\nlet us use a linearization approach and an appropriate iterative scheme. The\nproposed approach is tasted for some nonlinear fractional order KdV and Burgers\nequations. The capacity, high order accuracy and efficiency of our approach are\ndemonstrated using examples and results", "published": "2025-08-14 11:36:28", "link": "http://arxiv.org/abs/2508.10547v1", "categories": ["math.NA", "cs.NA", "34K28, 35G61, 35Q53, 34A08, 34K13"], "primary_category": "math.NA"}
{"title": "Product Of Exponentials (POE) Splines on Lie-Groups: Limitations, Extensions, and Application to SO(3) and SE(3)", "abstract": "Existing methods for constructing splines and Bezier curves on a Lie group G\ninvolve repeated products of exponentials deduced from local geodesics, w.r.t.\na Riemannian metric, or rely on general polynomials. Moreover, each of these\nlocal curves is supposed to start at the identity of $G$. Both assumptions may\nnot reflect the actual curve to be interpolated. This paper pursues a different\napproach to construct splines on $G$. Local curves are expressed as solutions\nof the Poisson equation on G. Therewith, the local interpolations satisfies the\nboundary conditions while respecting the geometry of $G$. A $k$th-order\napproximation of the solutions gives rise to a $k$th-order product of\nexponential (POE) spline. Algorithms for constructing 3rd- and 4th-order\nsplines are derived from closed form expressions for the approximate solutions.\nAdditionally, spline algorithms are introduced that allow prescribing a vector\nfield the curve must follow at the interpolation points. It is shown that the\nestablished algorithms, where $k$th-order POE-splines are constructed by\nconcatenating local curves starting at the identity, cannot exactly reconstruct\na $k$th-order motion. To tackle this issue, the formulations are extended by\nallowing for local curves between arbitrary points, rather than curves\nemanating from the identity. This gives rise to a global $k$th-order spline\nwith arbitrary initial conditions. Several examples are presented, in\nparticular the shape reconstruction of slender rods modeled as geometrically\nnon-linear Cosserat rods.", "published": "2025-08-14 10:31:54", "link": "http://arxiv.org/abs/2508.10513v1", "categories": ["math.NA", "cs.NA", "math.DG", "math.GR"], "primary_category": "math.NA"}
{"title": "Sum-of-Gaussians tensor neural networks for high-dimensional Schr\u00f6dinger equation", "abstract": "We propose an accurate, efficient, and low-memory sum-of-Gaussians tensor\nneural network (SOG-TNN) algorithm for solving the high-dimensional\nSchr\\\"odinger equation. The SOG-TNN utilizes a low-rank tensor product\nrepresentation of the solution to overcome the curse of dimensionality\nassociated with high-dimensional integration. To handle the Coulomb\ninteraction, we introduce an SOG decomposition to approximate the interaction\nkernel such that it is dimensionally separable, leading to a tensor\nrepresentation with rapid convergence. We further develop a range-splitting\nscheme that partitions the Gaussian terms into short-, long-, and mid-range\ncomponents. They are treated with the asymptotic expansion, the low-rank\nChebyshev expansion, and the model reduction with singular-value decomposition,\nrespectively, significantly reducing the number of two-dimensional integrals in\ncomputing electron-electron interactions. The SOG decomposition well resolves\nthe computational challenge due to the singularity of the Coulomb interaction,\nleading to an efficient algorithm for the high-dimensional problem under the\nTNN framework. Numerical results demonstrate the outstanding performance of the\nnew method, revealing that the SOG-TNN is a promising way for tackling large\nand complex quantum systems.", "published": "2025-08-14 08:46:02", "link": "http://arxiv.org/abs/2508.10454v1", "categories": ["physics.comp-ph", "cs.NA", "math.NA", "35Q40, 65D40, 65N25, 68W25, 68W40"], "primary_category": "physics.comp-ph"}
{"title": "New Lower Bounds for the Minimum Singular Value in Matrix Selection", "abstract": "The objective of the matrix selection problem is to select a submatrix\n$A_{S}\\in \\mathbb{R}^{n\\times k}$ from $A\\in \\mathbb{R}^{n\\times m}$ such that\nits minimum singular value is maximized. In this paper, we employ the\ninterlacing polynomial method to investigate this problem. This approach allows\nus to identify a submatrix $A_{S_0}\\in \\mathbb{R}^{n\\times k}$ and establish a\nlower bound for its minimum singular value. Specifically, unlike common\ninterlacing polynomial approaches that estimate the smallest root of the\nexpected characteristic polynomial via barrier functions, we leverage the\ndirect relationship between roots and coefficients. This leads to a tighter\nlower bound when $k$ is close to $n$. For the case where\n$AA^{\\top}=\\mathbb{I}_n$ and $k=n$, our result improves the well-known result\nby Hong-Pan, which involves extracting a basis from a tight frame and\nestablishing a lower bound for the minimum singular value of the basis matrix.", "published": "2025-08-14 08:41:28", "link": "http://arxiv.org/abs/2508.10452v1", "categories": ["math.FA", "cs.NA", "math.NA"], "primary_category": "math.FA"}
{"title": "A Semi-Lagrangian scheme on embedded manifolds using generalized local polynomial reproductions", "abstract": "We analyze rates of uniform convergence for a class of high-order\nsemi-Lagrangian schemes for first-order, time-dependent partial differential\nequations on embedded submanifolds of $\\mathbb{R}^d$ (including advection\nequations on surfaces) by extending the error analysis of Falcone and Ferretti.\nA central requirement in our analysis is a remapping operator that achieves\nboth high approximation orders and strong stability, a combination that is\nchallenging to obtain and of independent interest. For this task, we propose a\nnovel mesh-free remapping operator based on $\\ell_1$ minimizing generalized\npolynomial reproduction, which uses only point values and requires no\nadditional geometric information from the manifold (such as access to tangent\nspaces or curvature). Our framework also rigorously addresses the numerical\nsolution of ordinary differential equations on manifolds via projection\nmethods. We include numerical experiments that support the theoretical results\nand also suggest some new directions for future research.", "published": "2025-08-14 05:02:18", "link": "http://arxiv.org/abs/2508.10344v1", "categories": ["math.NA", "cs.NA", "65M12, 65M15, 65M25, 41A25, 41A63"], "primary_category": "math.NA"}
{"title": "SSBE-PINN: A Sobolev Boundary Scheme Boosting Stability and Accuracy in Elliptic/Parabolic PDE Learning", "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving partial differential equations (PDEs), yet they often fail to\nachieve accurate convergence in the H1 norm, especially in the presence of\nboundary approximation errors. In this work, we propose a novel method called\nSobolev-Stable Boundary Enforcement (SSBE), which redefines the boundary loss\nusing Sobolev norms to incorporate boundary regularity directly into the\ntraining process. We provide rigorous theoretical analysis demonstrating that\nSSBE ensures bounded H1 error via a stability guarantee and derive\ngeneralization bounds that characterize its robustness under finite-sample\nregimes. Extensive numerical experiments on linear and nonlinear PDEs,\nincluding Poisson, heat, and elliptic problems, show that SSBE consistently\noutperforms standard PINNs in terms of both relative L2 and H1 errors, even in\nhigh-dimensional settings. The proposed approach offers a principled and\npractical solution for improving gradient fidelity and overall solution\naccuracy in neural network based PDE solvers.", "published": "2025-08-14 03:51:44", "link": "http://arxiv.org/abs/2508.10322v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "TOBACO: Topology Optimization via Band-limited Coordinate Networks for Compositionally Graded Alloys", "abstract": "Compositionally Graded Alloys (CGAs) offer unprecedented design flexibility\nby enabling spatial variations in composition; tailoring material properties to\nlocal loading conditions. This flexibility leads to components that are\nstronger, lighter, and more cost-effective than traditional monolithic\ncounterparts. The fabrication of CGAs have become increasingly feasible owing\nto recent advancements in additive manufacturing (AM), particularly in\nmulti-material printing and improved precision in material deposition. However,\nAM of CGAs requires imposition of manufacturing constraints; in particular\nlimits on the maximum spatial gradation of composition.\n  This paper introduces a topology optimization (TO) based framework for\ndesigning optimized CGA components with controlled compositional gradation. In\nparticular, we represent the constrained composition distribution using a\nband-limited coordinate neural network. By regulating the network's bandwidth,\nwe ensure implicit compliance with gradation limits, eliminating the need for\nexplicit constraints. The proposed approach also benefits from the inherent\nadvantages of TO using coordinate networks, including mesh independence,\nhigh-resolution design extraction, and end-to-end differentiability. The\neffectiveness of our framework is demonstrated through various elastic and\nthermo-elastic TO examples.", "published": "2025-08-14 03:49:09", "link": "http://arxiv.org/abs/2508.10320v1", "categories": ["cs.CE", "cs.NA", "math.NA"], "primary_category": "cs.CE"}
{"title": "On data-driven robust distortion risk measures for non-negative risks with partial information", "abstract": "In this paper, by proposing two new kinds of distributional uncertainty sets,\nwe explore robustness of distortion risk measures against distributional\nuncertainty. To be precise, we first consider a distributional uncertainty set\nwhich is characterized solely by a ball determined by general Wasserstein\ndistance centered at certain empirical distribution function, and then further\nconsider additional constraints of known first moment and any other higher\nmoment of the underlying loss distribution function. Under the assumption that\nthe distortion function is strictly concave and twice differentiable, and that\nthe underlying loss random variable is non-negative and bounded, we derive\nclosed-form expressions for the distribution functions which maximize a given\ndistortion risk measure over the distributional uncertainty sets respectively.\nMoreover, we continue to study the general case of a concave distortion\nfunction and unbounded loss random variables. Comparisons with existing studies\nare also made. Finally, we provide a numerical study to illustrate the proposed\nmodels and results. Our work provides a novel generalization of several known\nachievements in the literature.", "published": "2025-08-14 14:25:24", "link": "http://arxiv.org/abs/2508.10682v1", "categories": ["q-fin.RM", "q-fin.MF", "91G70, 91G05", "G.3.3"], "primary_category": "q-fin.RM"}
{"title": "Higher-order Gini indices: An axiomatic approach", "abstract": "Via an axiomatic approach, we characterize the family of n-th order Gini\ndeviation, defined as the expected range over n independent draws from a\ndistribution, to quantify joint dispersion across multiple observations. This\nextends the classical Gini deviation, which relies solely on pairwise\ncomparisons. Our generalization grows increasingly sensitive to tail inequality\nas n increases, offering a more nuanced view of distributional extremes. We\nshow that these higher-order Gini deviations admit a Choquet integral\nrepresentation, inheriting the desirable properties of coherent deviation\nmeasures. Furthermore, we prove that both the n-th order Gini deviation and its\nnormalized version, the n-th order Gini coefficient, are n-observation\nelicitable, facilitating rigorous backtesting. Empirical analysis using World\nInequality Database data reveals that higher-order Gini coefficients detect\ndisparities obscured by the classical Gini coefficient, particularly in cases\nof extreme income or wealth concentration. Our results establish higher-order\nGini indices as valuable complementary tools for robust inequality assessment.", "published": "2025-08-14 14:03:37", "link": "http://arxiv.org/abs/2508.10663v1", "categories": ["q-fin.MF", "econ.EM", "math.ST", "stat.TH"], "primary_category": "q-fin.MF"}
{"title": "Dynamic Skewness in Stochastic Volatility Models: A Penalized Prior Approach", "abstract": "Financial time series often exhibit skewness and heavy tails, making it\nessential to use models that incorporate these characteristics to ensure\ngreater reliability in the results. Furthermore, allowing temporal variation in\nthe skewness parameter can bring significant gains in the analysis of this type\nof series. However, for more robustness, it is crucial to develop models that\nbalance flexibility and parsimony. In this paper, we propose dynamic skewness\nstochastic volatility models in the SMSN family (DynSSV-SMSN), using priors\nthat penalize model complexity. Parameter estimation was carried out using the\nHamiltonian Monte Carlo (HMC) method via the \\texttt{RStan} package. Simulation\nresults demonstrated that penalizing priors present superior performance in\nseveral scenarios compared to the classical choices. In the empirical\napplication to returns of cryptocurrencies, models with heavy tails and dynamic\nskewness provided a better fit to the data according to the DIC, WAIC, and\nLOO-CV information criteria.", "published": "2025-08-14 16:01:47", "link": "http://arxiv.org/abs/2508.10778v1", "categories": ["q-fin.ST", "stat.AP"], "primary_category": "q-fin.ST"}
{"title": "A 4% withdrawal rate for retirement spending, derived from a discrete-time model of stochastic returns on assets", "abstract": "What grounds the rule of thumb that a(n American) retiree can safely withdraw\n4% of their initial retirement wealth in their first year of retirement, then\nincrease that rate of consumption with inflation? I investigate that question\nwith a discrete-time model of returns to a retirement portfolio consumed at a\nrate that grows by $s$ per period. The model hinges on the parameter $\\gamma$,\nan $s$-adjusted rate of return to wealth, derived from the first 2-4 moments of\nthe portfolio's probability distribution of returns; for a retirement lasting\n$t$ periods the model recommends a rate of consumption of $\\gamma / (1 - (1 -\n\\gamma)^t)$. Estimation of $\\gamma$ (and hence of the implied rate of spending\ndown in retirement) reveals that the 4% rule emerges from adjusting high\nexpected rates of return down for: consumption growth, the variance in (and\nkurtosis of) returns to wealth, the longevity risk of a retiree potentially\nunderestimating $t$, and the inclusion of bonds in retirement portfolios\nwithout leverage. The model supports leverage of retirement portfolios\ndominated by the S&P 500, with leverage ratios $> 1.6$ having been historically\noptimal under the model's approximations. Historical simulations of 30-year\nretirements suggest that the model proposes withdrawal rates having roughly\neven odds of success, that leverage greatly improves those odds for\nstocks-heavy portfolios, and that investing on margin could have allowed safe\nwithdrawal rates $> 6$% per year.", "published": "2025-08-14 01:48:43", "link": "http://arxiv.org/abs/2508.10273v1", "categories": ["stat.AP", "q-fin.PM", "q-fin.ST"], "primary_category": "stat.AP"}
{"title": "Advances in Speech Separation: Techniques, Challenges, and Future Trends", "abstract": "The field of speech separation, addressing the \"cocktail party problem\", has\nseen revolutionary advances with DNNs. Speech separation enhances clarity in\ncomplex acoustic environments and serves as crucial pre-processing for speech\nrecognition and speaker recognition. However, current literature focuses\nnarrowly on specific architectures or isolated approaches, creating fragmented\nunderstanding. This survey addresses this gap by providing systematic\nexamination of DNN-based speech separation techniques. Our work differentiates\nitself through: (I) Comprehensive perspective: We systematically investigate\nlearning paradigms, separation scenarios with known/unknown speakers,\ncomparative analysis of supervised/self-supervised/unsupervised frameworks, and\narchitectural components from encoders to estimation strategies. (II)\nTimeliness: Coverage of cutting-edge developments ensures access to current\ninnovations and benchmarks. (III) Unique insights: Beyond summarization, we\nevaluate technological trajectories, identify emerging patterns, and highlight\npromising directions including domain-robust frameworks, efficient\narchitectures, multimodal integration, and novel self-supervised paradigms.\n(IV) Fair evaluation: We provide quantitative evaluations on standard datasets,\nrevealing true capabilities and limitations of different methods. This\ncomprehensive survey serves as an accessible reference for experienced\nresearchers and newcomers navigating speech separation's complex landscape.", "published": "2025-08-14 16:54:34", "link": "http://arxiv.org/abs/2508.10830v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Exploring Cross-Utterance Speech Contexts for Conformer-Transducer Speech Recognition Systems", "abstract": "This paper investigates four types of cross-utterance speech contexts\nmodeling approaches for streaming and non-streaming Conformer-Transformer (C-T)\nASR systems: i) input audio feature concatenation; ii) cross-utterance Encoder\nembedding concatenation; iii) cross-utterance Encoder embedding pooling\nprojection; or iv) a novel chunk-based approach applied to C-T models for the\nfirst time. An efficient batch-training scheme is proposed for contextual C-Ts\nthat uses spliced speech utterances within each minibatch to minimize the\nsynchronization overhead while preserving the sequential order of\ncross-utterance speech contexts. Experiments are conducted on four benchmark\nspeech datasets across three languages: the English GigaSpeech and Mandarin\nWenetspeech corpora used in contextual C-T models pre-training; and the English\nDementiaBank Pitt and Cantonese JCCOCC MoCA elderly speech datasets used in\ndomain fine-tuning. The best performing contextual C-T systems consistently\noutperform their respective baselines using no cross-utterance speech contexts\nin pre-training and fine-tuning stages with statistically significant average\nword error rate (WER) or character error rate (CER) reductions up to 0.9%,\n1.1%, 0.51%, and 0.98% absolute (6.0%, 5.4%, 2.0%, and 3.4% relative) on the\nfour tasks respectively. Their performance competitiveness against\nWav2vec2.0-Conformer, XLSR-128, and Whisper models highlights the potential\nbenefit of incorporating cross-utterance speech contexts into current speech\nfoundation models.", "published": "2025-08-14 08:54:01", "link": "http://arxiv.org/abs/2508.10456v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Alternating Approach-Putt Models for Multi-Stage Speech Enhancement", "abstract": "Speech enhancement using artificial neural networks aims to remove noise from\nnoisy speech signals while preserving the speech content. However, speech\nenhancement networks often introduce distortions to the speech signal, referred\nto as artifacts, which can degrade audio quality. In this work, we propose a\npost-processing neural network designed to mitigate artifacts introduced by\nspeech enhancement models. Inspired by the analogy of making a `Putt' after an\n`Approach' in golf, we name our model PuttNet. We demonstrate that alternating\nbetween a speech enhancement model and the proposed Putt model leads to\nimproved speech quality, as measured by perceptual quality scores (PESQ),\nobjective intelligibility (STOI), and background noise intrusiveness (CBAK)\nscores. Furthermore, we illustrate with graphical analysis why this alternating\nApproach outperforms repeated application of either model alone.", "published": "2025-08-14 08:18:42", "link": "http://arxiv.org/abs/2508.10436v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MCP2OSC: Parametric Control by Natural Language", "abstract": "Text prompts enable intuitive content creation but may fall short in\nachieving high precision for intricate tasks; knob or slider controls offer\nprecise adjustments at the cost of increased complexity. To address the gap\nbetween knobs and prompts, a new MCP (Model Context Protocol) server and a\nunique set of prompt design criteria are presented to enable exploring\nparametric OSC (OpenSoundControl) control by natural language prompts.\nDemonstrated by 14 practical QA examples with best practices and the\ngeneralized prompt templates, this study finds Claude integrated with the\nMCP2OSC server effective in generating OSC messages by natural language,\ninterpreting, searching, and visualizing OSC messages, validating and debugging\nOSC messages, and managing OSC address patterns. MCP2OSC enhances human-machine\ncollaboration by leveraging LLM (Large Language Model) to handle intricate OSC\ndevelopment tasks, and by empowering human creativity with an intuitive\nlanguage interface featuring flexible precision controls: a prompt-based OSC\ntool. This study provides a novel perspective on the creative MCP application\nat the network protocol level by utilizing LLM's strength in directly\nprocessing and generating human-readable OSC messages. The results suggest its\npotential for a LLM-based universal control mechanism for multimedia devices.", "published": "2025-08-14 07:38:01", "link": "http://arxiv.org/abs/2508.10414v1", "categories": ["cs.HC", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Towards Frame-level Quality Predictions of Synthetic Speech", "abstract": "While automatic subjective speech quality assessment has witnessed much\nprogress, an open question is whether an automatic quality assessment at frame\nresolution is possible. This would be highly desirable, as it adds\nexplainability to the assessment of speech synthesis systems. Here, we take\nfirst steps towards this goal by identifying issues of existing quality\npredictors that prevent sensible frame-level prediction. Further, we define\ncriteria that a frame-level predictor should fulfill. We also suggest a\nchunk-based processing that avoids the impact of a localized distortion on the\nscore of neighboring frames. Finally, we measure in experiments with localized\nartificial distortions the localization performance of a set of frame-level\nquality predictors and show that they can outperform detection performance of\nhuman annotations obtained from a crowd-sourced perception experiment.", "published": "2025-08-14 06:11:00", "link": "http://arxiv.org/abs/2508.10374v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A dataset and model for recognition of audiologically relevant environments for hearing aids: AHEAD-DS and YAMNet+", "abstract": "Scene recognition of audiologically relevant environments is important for\nhearing aids; however, it is challenging, in part because of the limitations of\nexisting datasets. Datasets often lack public accessibility, completeness, or\naudiologically relevant labels, hindering systematic comparison of machine\nlearning models. Deploying these models on resource-constrained edge devices\npresents another challenge. Our solution is two-fold: we leverage several open\nsource datasets to create AHEAD-DS, a dataset designed for scene recognition of\naudiologically relevant environments, and introduce YAMNet+, a sound\nrecognition model. AHEAD-DS aims to provide a standardised, publicly available\ndataset with consistent labels relevant to hearing aids, facilitating model\ncomparison. YAMNet+ is designed for deployment on edge devices like smartphones\nconnected to hearing devices, such as hearing aids and wireless earphones with\nhearing aid functionality; serving as a baseline model for sound-based scene\nrecognition. YAMNet+ achieved a mean average precision of 0.83 and accuracy of\n0.93 on the testing set of AHEAD-DS across fourteen categories of\naudiologically relevant environments. We found that applying transfer learning\nfrom the pretrained YAMNet model was essential. We demonstrated real-time\nsound-based scene recognition capabilities on edge devices by deploying YAMNet+\nto an Android smartphone. Even with a Google Pixel 3 (a phone with modest\nspecifications, released in 2018), the model processes audio with approximately\n50ms of latency to load the model, and an approximate linear increase of 30ms\nper 1 second of audio. Our website and code\nhttps://github.com/Australian-Future-Hearing-Initiative .", "published": "2025-08-14 05:59:21", "link": "http://arxiv.org/abs/2508.10360v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech", "abstract": "Children's speech presents challenges for age and gender classification due\nto high variability in pitch, articulation, and developmental traits. While\nself-supervised learning (SSL) models perform well on adult speech tasks, their\nability to encode speaker traits in children remains underexplored. This paper\npresents a detailed layer-wise analysis of four Wav2Vec2 variants using the\nPFSTAR and CMU Kids datasets. Results show that early layers (1-7) capture\nspeaker-specific cues more effectively than deeper layers, which increasingly\nfocus on linguistic information. Applying PCA further improves classification,\nreducing redundancy and highlighting the most informative components. The\nWav2Vec2-large-lv60 model achieves 97.14% (age) and 98.20% (gender) on CMU\nKids; base-100h and large-lv60 models reach 86.05% and 95.00% on PFSTAR. These\nresults reveal how speaker traits are structured across SSL model depth and\nsupport more targeted, adaptive strategies for child-aware speech interfaces.", "published": "2025-08-14 04:11:44", "link": "http://arxiv.org/abs/2508.10332v1", "categories": ["eess.AS", "cs.AI", "cs.HC", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Molecule Mixture Detection and Alphabet Design for Non-linear, Cross-reactive Receiver Arrays in MC", "abstract": "Air-based molecular communication (MC) has the potential to be one of the\nfirst MC systems to be deployed in real-world applications, enabled by existing\nsensor technologies such as metal-oxide semi-conductor (MOS) sensors. However,\ncommercially available sensors usually exhibit non-linear and cross-reactive\nbehavior, contrary to the idealizing assumptions about linear and perfectly\nmolecule type-specific sensing often made in the MC literature. To address this\ngap, we propose a detector for molecule mixture communication with a general\nnon-linear, cross-reactive receiver (RX) array that performs approximate\nmaximum likelihood detection on the sensor outputs. Additionally, we introduce\nan algorithm for the design of mixture alphabets that accounts for the RX\ncharacteristics. We evaluate our detector and alphabet design algorithm through\nsimulations that are based on measurements reported for two commercial MOS\nsensors. Our simulations demonstrate that the proposed detector achieves\nsimilar symbol error rates as data-driven methods without requiring large\nnumbers of training samples and that the alphabet design algorithm outperforms\nmethods that do not account for the RX characteristics. Since the proposed\ndetector and alphabet design algorithm are also applicable to other chemical\nsensors, they pave the way for reliable air-based MC.", "published": "2025-08-14 17:27:17", "link": "http://arxiv.org/abs/2508.10856v1", "categories": ["eess.SP", "cs.ET"], "primary_category": "eess.SP"}
{"title": "Scalable FAS: A New Paradigm for Array Signal Processing", "abstract": "Most existing antenna array-based source localization methods rely on\nfixed-position arrays (FPAs) and strict assumptions about source field\nconditions (near-field or far-field), which limits their effectiveness in\ncomplex, dynamic real-world scenarios where high-precision localization is\nrequired. In contrast, this paper introduces a novel scalable fluid antenna\nsystem (SFAS) that can dynamically adjust its aperture configuration to\noptimize performance for different localization tasks. Within this framework,\nwe develop a two-stage source localization strategy based on the exact spatial\ngeometry (ESG) model: the first stage uses a compact aperture configuration for\ninitial direction-of-arrival (DOA) estimation, while the second stage employs\nan expanded aperture for enhanced DOA and range estimation. The proposed\napproach eliminates the traditional need for signal separation or isolation to\nclassify source types and enables a single SFAS array to achieve high\nlocalization accuracy without field-specific assumptions, model\nsimplifications, or approximations, representing a new paradigm in array-based\nsource localization. Extensive simulations demonstrate the superiority of the\nproposed method in terms of localization accuracy, computational efficiency,\nand robustness to different source types.", "published": "2025-08-14 16:56:22", "link": "http://arxiv.org/abs/2508.10831v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "The Future is Fluid: Revolutionizing DOA Estimation with Sparse Fluid Antennas", "abstract": "This paper investigates a design framework for sparse fluid antenna systems\n(FAS) enabling high-performance direction-of-arrival (DOA) estimation,\nparticularly in challenging millimeter-wave (mmWave) environments. By\ningeniously harnessing the mobility of fluid antenna (FA) elements, the\nproposed architectures achieve an extended range of spatial degrees of freedom\n(DoF) compared to conventional fixed-position antenna (FPA) arrays. This\ninnovation not only facilitates the seamless application of super-resolution\nDOA estimators but also enables robust DOA estimation, accurately localizing\nmore sources than the number of physical antenna elements. We introduce two\nbespoke FA array structures and mobility strategies tailored to scenarios with\naligned and misaligned received signals, respectively, demonstrating a\nhardware-driven approach to overcoming complexities typically addressed by\nintricate algorithms. A key contribution is a light-of-sight (LoS)-centric,\nclosed-form DOA estimator, which first employs an eigenvalue-ratio test for\nprecise LoS path number detection, followed by a polynomial root-finding\nprocedure. This method distinctly showcases the unique advantages of FAS by\nsimplifying the estimation process while enhancing accuracy. Numerical results\ncompellingly verify that the proposed FA array designs and estimation\ntechniques yield an extended DoF range, deliver superior DOA accuracy, and\nmaintain robustness across diverse signal conditions.", "published": "2025-08-14 16:49:46", "link": "http://arxiv.org/abs/2508.10826v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fluid Antenna Enabled Direction-of-Arrival Estimation Under Time-Constrained Mobility", "abstract": "Fluid antenna (FA) technology has emerged as a promising approach in wireless\ncommunications due to its capability of providing increased degrees of freedom\n(DoFs) and exceptional design flexibility. This paper addresses the challenge\nof direction-of-arrival (DOA) estimation for aligned received signals (ARS) and\nnon-aligned received signals (NARS) by designing two specialized uniform FA\nstructures under time-constrained mobility. For ARS scenarios, we propose a\nfully movable antenna configuration that maximizes the virtual array aperture,\nwhereas for NARS scenarios, we design a structure incorporating a fixed\nreference antenna to reliably extract phase information from the signal\ncovariance. To overcome the limitations of large virtual arrays and limited\nsample data inherent in time-varying channels (TVC), we introduce two novel DOA\nestimation methods: TMRLS-MUSIC for ARS, combining Toeplitz matrix\nreconstruction (TMR) with linear shrinkage (LS) estimation, and TMR-MUSIC for\nNARS, utilizing sub-covariance matrices to construct virtual array responses.\nBoth methods employ Nystrom approximation to significantly reduce computational\ncomplexity while maintaining estimation accuracy. Theoretical analyses and\nextensive simulation results demonstrate that the proposed methods achieve\nunderdetermined DOA estimation using minimal FA elements, outperform\nconventional methods in estimation accuracy, and substantially reduce\ncomputational complexity.", "published": "2025-08-14 16:46:40", "link": "http://arxiv.org/abs/2508.10820v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Reduction of motion artifacts from photoplethysmography signals using learned convolutional sparse coding", "abstract": "Objective. Wearable devices with embedded photoplethysmography (PPG) enable\ncontinuous non-invasive monitoring of cardiac activity, offering a promising\nstrategy to reduce the global burden of cardiovascular diseases. However,\nmonitoring during daily life introduces motion artifacts that can compromise\nthe signals. Traditional signal decomposition techniques often fail with severe\nartifacts. Deep learning denoisers are more effective but have poorer\ninterpretability, which is critical for clinical acceptance. This study\nproposes a framework that combines the advantages of both signal decomposition\nand deep learning approaches. Approach. We leverage algorithm unfolding to\nintegrate prior knowledge about the PPG structure into a deep neural network,\nimproving its interpretability. A learned convolutional sparse coding model\nencodes the signal into a sparse representation using a learned dictionary of\nkernels that capture recurrent morphological patterns. The network is trained\nfor denoising using the PulseDB dataset and a synthetic motion artifact model\nfrom the literature. Performance is benchmarked with PPG during daily\nactivities using the PPG-DaLiA dataset and compared with two reference deep\nlearning methods. Main results. On the synthetic dataset, the proposed method,\non average, improved the signal-to-noise ratio (SNR) from -7.07 dB to 11.23 dB\nand reduced the heart rate mean absolute error (MAE) by 55%. On the PPG-DaLiA\ndataset, the MAE decreased by 23%. The proposed method obtained higher SNR and\ncomparable MAE to the reference methods. Significance. Our method effectively\nenhances the quality of PPG signals from wearable devices and enables the\nextraction of meaningful waveform features, which may inspire innovative tools\nfor monitoring cardiovascular diseases.", "published": "2025-08-14 16:26:00", "link": "http://arxiv.org/abs/2508.10805v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Affine Frequency Division Multiplexing with Subcarrier Power-Level Index Modulation for Integrated Sensing and Communications", "abstract": "This study proposes an index modulation (IM) technique for affine frequency\ndivision multiplexing (AFDM) signals and examines its communication and sensing\nperformance toward integrated sensing and communication (ISAC) systems. The\npower levels of subcarriers are utilized as modulation indices while also\ntransmitting data symbols within each subcarrier. Thus, the proposed AFDM with\nsubcarrier power-level index modulation (AFDM-PLIM) maintains all subcarriers\nactive at all times to achieve a higher spectral efficiency compared to other\nAFDM-IM techniques, where some of the subcarriers are turned off for IM. A low\ncomplexity estimator and subcarrier grouping are also proposed to reduce the\ncomputational complexity of the maximum likelihood estimator. Furthermore, this\nstudy also examines the delay and Doppler ambiguity functions of the proposed\nAFDM-PLIM and evaluates its range estimation performance. The results show that\nits sensing performance is better than AFDM-IM waveforms due to keeping all\nsubcarriers active at all times.", "published": "2025-08-14 16:10:51", "link": "http://arxiv.org/abs/2508.10783v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Towards Hybrid Lunar PNT: Error Models, Lower Bounds and Algorithms", "abstract": "Accurate positioning, navigation and timing (PNT) are crucial for upcoming\nlunar surface missions. Lunar satellite navigation systems are being developed,\nbut lack coverage during early deployment phases. Hybrid lunar PNT combining\ncooperative navigation, satellite systems, and an optional reference station\noffers improved accuracy and availability. This study develops realistic error\nmodels that incorporate temporal correlations often ignored in existing works.\nWe derive a cooperative navigation error model considering fading and\npseudorange bias from multipath propagation, and compare three error models for\nlunar satellite pseudorange and pseudorange rate signal-in-space error. These\ntemporal error correlation models integrate easily into Kalman filters and\nprovide realistic performance predictions essential for robust navigation\nengines. We perform case studies to demonstrate that hybrid navigation\nsignificantly improves accuracy, particularly with static users present. Most\nnotably, hybrid navigation enables optimal performance when using a lunar\nreference station, achieving sub-meter accuracy with only two visible\nsatellites.", "published": "2025-08-14 14:43:17", "link": "http://arxiv.org/abs/2508.10699v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Differential Physiological Responses to Proxemic and Facial Threats in Virtual Avatar Interactions", "abstract": "Proxemics, the study of spatial behavior, is fundamental to social\ninteraction and increasingly relevant for virtual reality (VR) applications.\nWhile previous research has established that users respond to personal space\nviolations in VR similarly as in real-world settings, phase-specific\nphysiological responses and the modulating effects of facial expressions remain\nunderstudied. We investigated physiological and subjective responses to\npersonal space violations by virtual avatars, to understand how threatening\nfacial expressions and interaction phases (approach vs. standing) influence\nthese responses. Sixteen participants experienced a 2x2 factorial design\nmanipulating Personal Space (intrusion vs. respect) and Facial Expression\n(neutral vs. angry) while we recorded skin conductance response (SCR), heart\nrate variability (HRV), and discomfort ratings. Personal space boundaries were\nindividually calibrated using a stop-distance procedure. Results show that SCR\nresponses are significantly higher during the standing phase compared to the\napproach phase when personal space was violated, indicating that prolonged\nproximity within personal space boundaries is more physiologically arousing\nthan the approach itself. Angry facial expressions significantly reduced HRV,\nreflecting decreased parasympathetic activity, and increased discomfort\nratings, but did not amplify SCR responses. These findings demonstrate that\ndifferent physiological modalities capture distinct aspects of proxemic\nresponses: SCR primarily reflects spatial boundary violations, while HRV\nresponds to facial threat cues. Our results provide insights for developing\ncomprehensive multi-modal assessments of social behavior in virtual\nenvironments and inform the design of more realistic avatar interactions.", "published": "2025-08-14 12:25:19", "link": "http://arxiv.org/abs/2508.10586v1", "categories": ["cs.HC", "eess.SP", "q-bio.NC"], "primary_category": "cs.HC"}
{"title": "Compressive Spectral Imaging in View of Earth Observation Applications", "abstract": "Earth observation from space is an important scientific and industrial\nactivity that has applications in many sectors. The instruments employed are\noften large, complex, and expensive. In addition, they generate large amounts\nof data, which is challenging for storage and transfer purposes. Compressive\nspectral imaging would be a cheaper, more efficient, and well-adapted technique\nto perform Earth observation. An interesting architecture is compressive\nspectral imaging with diffractive lenses, which is extremely compact. This work\ninvestigates the possibility of replacing the diffractive lens in this system\nwith a classical refractive lens. Taking advantage of the chromatic aberration\nof a lens makes the use of expensive diffractive lenses unnecessary.\nSimulations are performed to test the feasibility of the method. Signal\nrecovery is a basis pursuit solved using the Douglas-Rashford algorithm.", "published": "2025-08-14 12:08:59", "link": "http://arxiv.org/abs/2508.10569v1", "categories": ["eess.SP", "physics.optics"], "primary_category": "eess.SP"}
{"title": "Reproducible Physiological Features in Affective Computing: A Preliminary Analysis on Arousal Modeling", "abstract": "In Affective Computing, a key challenge lies in reliably linking subjective\nemotional experiences with objective physiological markers. This preliminary\nstudy addresses the issue of reproducibility by identifying physiological\nfeatures from cardiovascular and electrodermal signals that are associated with\ncontinuous self-reports of arousal levels. Using the Continuously Annotated\nSignal of Emotion dataset, we analyzed 164 features extracted from cardiac and\nelectrodermal signals of 30 participants exposed to short emotion-evoking\nvideos. Feature selection was performed using the Terminating-Random\nExperiments (T-Rex) method, which performs variable selection systematically\ncontrolling a user-defined target False Discovery Rate. Remarkably, among all\ncandidate features, only two electrodermal-derived features exhibited\nreproducible and statistically significant associations with arousal, achieving\na 100\\% confirmation rate. These results highlight the necessity of rigorous\nreproducibility assessments in physiological features selection, an aspect\noften overlooked in Affective Computing. Our approach is particularly promising\nfor applications in safety-critical environments requiring trustworthy and\nreliable white box models, such as mental disorder recognition and human-robot\ninteraction systems.", "published": "2025-08-14 11:58:36", "link": "http://arxiv.org/abs/2508.10561v1", "categories": ["cs.HC", "cs.LG", "eess.SP"], "primary_category": "cs.HC"}
{"title": "Unsupervised Deep Equilibrium Model Learning for Large-Scale Channel Estimation with Performance Guarantees", "abstract": "Supervised deep learning methods have shown promise for large-scale channel\nestimation (LCE), but their reliance on ground-truth channel labels greatly\nlimits their practicality in real-world systems. In this paper, we propose an\nunsupervised learning framework for LCE that does not require ground-truth\nchannels. The proposed approach leverages Generalized Stein's Unbiased Risk\nEstimate (GSURE) as a principled unsupervised loss function, which provides an\nunbiased estimate of the projected mean-squared error (PMSE) from compressed\nnoisy measurements. To ensure a guaranteed performance, we integrate a deep\nequilibrium (DEQ) model, which implicitly represents an infinite-depth network\nby directly learning the fixed point of a parameterized iterative process. We\ntheoretically prove that, under mild conditions, the proposed GSURE-based\nunsupervised DEQ learning can achieve oracle-level supervised performance. In\nparticular, we show that the DEQ architecture inherently enforces a\ncompressible solution. We then demonstrate that DEQ-induced compressibility\nensures that optimizing the projected error via GSURE suffices to guarantee a\ngood MSE performance, enabling a rigorous performance guarantee. Extensive\nsimulations validate the theoretical findings and demonstrate that the proposed\nframework significantly outperforms various baselines when ground-truth channel\nis unavailable.", "published": "2025-08-14 11:35:58", "link": "http://arxiv.org/abs/2508.10546v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Inverse Synthetic Aperture Radar, Radar Cross Section, and Iterative Smooth Reweighting $\\ell_1$-minimization", "abstract": "Radar Cross Section measurement data is often analyzed using Inverse\nSynthetic Aperture Radar images. This paper compares backprojection and\niterative smooth reweighted $\\ell_1$-minimization as methods to analyze radar\ncross section measurements and extract radar cross section for parts of the\nmeasured object. The main conclusion is that using backprojection images to\nextract RCS is robust and accurate but is more limited by the resolution than\niterative smooth reweighted $\\ell_1$-minimization. The latter method can be\nused for closely spaced scatterers but is limited in accuracy.", "published": "2025-08-14 11:17:52", "link": "http://arxiv.org/abs/2508.10536v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A 240 Elements Matrix Probe with Aberration Mask for 4D Carotid Artery Computational Ultrasound Imaging", "abstract": "Three-dimensional (3D) ultrasound provides enhanced visualization of the\ncarotid artery (CA) anatomy and volumetric flow, offering improved accuracy for\ncardiovascular diagnosis and monitoring. However, fully populated matrix\ntransducers with large apertures are complex and costly to implement.\nComputational ultrasound imaging (cUSi) offers a promising alternative by\nenabling simplified hardware design through model-based reconstruction and\nspatial field encoding. In this work, we present a 3D cUSi system tailored for\nCA imaging, consisting of a 240-element matrix probe with a 40 x 24 mm$^2$\nlarge aperture and a spatial encoding mask. We describe the system's design,\ncharacterization, and image reconstruction. Phantom experiments show that\ncomputational reconstruction using matched filtering (MF) significantly\nimproves volumetric image quality over delay-and-sum (DAS), with spatial\nencoding enhancing lateral resolution at the cost of reduced contrast ratio.\nLSQR-based reconstruction was demonstrated to further improve resolution and\nsuppress artifacts. Using both Hadamard and 16-angle plane wave transmission\nschemes, the system achieved high-resolution images with reasonable contrast,\nsupporting the feasibility of 4D CA imaging applications.", "published": "2025-08-14 11:02:21", "link": "http://arxiv.org/abs/2508.10527v1", "categories": ["physics.med-ph", "eess.SP"], "primary_category": "physics.med-ph"}
{"title": "High SNR Probabilities of Continuous Fluid Antenna Systems in Ricean Environments", "abstract": "We consider a single-user (SU) continuous fluid antenna system (CFAS)\nemploying matched filtering (MF) operating over a Ricean fading channel.\nFocusing on the upper tail of the received signal-to-noise ratio (SNR)\ndistribution (the high SNR probability (HSP)), we derive accurate\napproximations for the HSP in 1, 2, and 3 dimensions using the expected Euler\ncharacteristic (EEC), presenting the first analytical results for a CFAS in a\nRicean environment. In the process, we provide the first closed-form expression\nfor the Euler characteristic density of a non-central chi-squared random field.\nWe then examine the impact of the Ricean K-factor on the CFAS performance,\nemphasizing the critical role of channel variations in achieving a strong HSP.", "published": "2025-08-14 09:41:06", "link": "http://arxiv.org/abs/2508.10485v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Second Order Channel Statistics: An Analysis for Optimal Single-user RIS Systems", "abstract": "A key challenge facing reconfigurable intelligent surfaces (RISs) is channel\nstate information acquisition. Passive RISs cannot generate pilot signals or\nprocess data, making rapid temporal changes in the channel problematic.\nAdditionally, the impact of spatial changes in RIS channels has not been\nthoroughly investigated. Therefore, in this work, we use second order\nstatistics to investigate the spatio-temporal behaviour of a single-user (SU)\nRIS system. Assuming a line-of-sight (LoS) RIS to base station (BS) link, we\nderive an exact expression for the level crossing rate (LCR) of the RIS link\n(user equipment (UE)-RIS-BS path) and propose a numerically stable\napproximation for the LCR of the global UE-BS channel. Each LCR expression\nattained is then utilised to find the corresponding average fade duration\n(AFD). The temporal signal-to-noise ratio (SNR) correlation is also derived\nassuming an LoS RIS-BS link. Assuming a Ricean RIS-BS link, expressions for the\nspatial correlation matrix of the global channel and the mean SNR loss due to\nchannel ageing are derived. All of the analyses are verified by simulation, and\nthe impact of key system parameters is investigated. We show that the use of an\nRIS does not significantly amplify changes in the channel.", "published": "2025-08-14 09:27:22", "link": "http://arxiv.org/abs/2508.10476v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Interleaved Transceiver Design for a Continuous- Transmission MIMO-OFDM ISAC System", "abstract": "This paper proposes an interleaved transceiver design method for a\nmultiple-input multiple-output (MIMO) integrated sensing and communication\n(ISAC) system utilizing orthogonal frequency division multiplexing (OFDM)\nwaveforms. We consider a continuous transmission system and focus on the design\nof the transmission signal and a receiving filter in the time domain for an\ninterleaved transmission architecture. For communication performance,\nconstructive interference (CI) is integrated into the optimization problem. For\nradar sensing performance, the integrated mainlobe-to-sidelobe ratio (IMSR) of\nthe beampattern is considered to ensure desirable directivity. Additionally, we\ntackle the challenges of inter-block interference and eliminate the spurious\npeaks, which are crucial for accurate target detection. Regarding the hardware\nimplementation aspect, the power of each time sample is constrained to manage\nthe peak-to-average power ratio (PAPR). The design problem is addressed using\nan alternating optimization (AO) framework, with the subproblem for transmitted\nwaveform design being solved via the successive convex approximation (SCA)\nmethod. To further enhance computational efficiency, the alternate direction\npenalty method (ADPM) is employed to solve the subproblems within the SCA\niterations. The convergence of ADPM is established, with convergence of the\ncase of more than two auxiliary variables being established for the first time.\nNumerical simulations validate the effectiveness of our transceiver design in\nachieving desirable performance in both radar sensing and communication, with\nthe fast algorithm achieving comparable performance with greater computational\nefficiency.", "published": "2025-08-14 08:02:54", "link": "http://arxiv.org/abs/2508.10430v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Environment Reconstruction in Terahertz Monostatic Sensing: Joint Millimeter-level Geometry Mapping and Material Identification", "abstract": "Terahertz (THz) integrated sensing and communication (ISAC) offers high-speed\ncommunication alongside precise environmental sensing. This paper presents a\ncomputationally efficient framework for THz-based environment reconstruction by\nintegrating connected component analysis (CCA)-assisted multipath component\n(MPC) estimation with a sliding-window refinement strategy. To start with, a\nmonostatic sensing experiment is conducted in an indoor scenario using a vector\nnetwork analyzer (VNA)-based sounder operating from 290 to 310 GHz. On one\nhand, as for geometry mapping, a CCA-based region search is employed to\naccelerate parameter extraction, significantly reducing the search space for\nspace-alternating generalized expectation-maximization (SAGE)-based estimation\nand achieving an 8.4 times acceleration, while preserving resolution. Further\nanalysis of the connected component structure enables the identification of\nindoor features such as flat walls and corners. A sliding-window refinement\napplied to the identified regions improves geometric mapping, achieving the\nmean distance error of 4.9 mm, which is one order of magnitude better than the\nliterature. On the other hand, the deterministic and stochastic components of\nthe monostatic channel are classified through reflection loss analysis. Then,\nmaterial identification is performed by looking up the reflection loss in a THz\ntime-domain spectroscopy (THz-TDS) database, which comprises over 200 materials\nacross a 0-6 THz range. Experimental results validate millimeter-level accuracy\nin geometry mapping and reliable material classification, enhancing the\nenvironmental awareness capabilities of THz ISAC systems.", "published": "2025-08-14 06:09:28", "link": "http://arxiv.org/abs/2508.10372v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Quantum Wavefront Correction via Machine Learning for Satellite-to-Earth CV-QKD", "abstract": "State-of-the-art free-space continuous-variable quantum key distribution\n(CV-QKD) protocols use phase reference pulses to modulate the wavefront of a\nreal local oscillator at the receiver, thereby compensating for wavefront\ndistortions caused by atmospheric turbulence. It is normally assumed that the\nwavefront distortion in these phase reference pulses is identical to the\nwavefront distortion in the quantum signals, which are multiplexed during\ntransmission. However, in many real-world deployments, there can exist a\nrelative wavefront error (WFE) between the reference pulses and quantum\nsignals, which, among other deleterious effects, can severely limit secure key\ntransfer in satellite-to-Earth CV-QKD. In this work, we introduce novel machine\nlearning-based wavefront correction algorithms, which utilize multi-plane light\nconversion for decomposition of the reference pulses and quantum signals into\nthe Hermite-Gaussian (HG) basis, then estimate the difference in HG mode phase\nmeasurements, effectively eliminating this problem. Through detailed\nsimulations of the Earth-satellite channel, we demonstrate that our new\nalgorithm can rapidly identify and compensate for any relative WFEs that may\nexist, whilst causing no harm when WFEs are similar across both the reference\npulses and quantum signals. We quantify the gains available in our algorithm in\nterms of the CV-QKD secure key rate. We show channels where positive secure key\nrates are obtained using our algorithms, while information loss without\nwavefront correction would result in null key rates.", "published": "2025-08-14 04:03:07", "link": "http://arxiv.org/abs/2508.10326v1", "categories": ["quant-ph", "eess.SP", "physics.optics"], "primary_category": "quant-ph"}
{"title": "A Deep Learning based Signal Dimension Estimator with Single Snapshot Signal in Phased Array Radar Application", "abstract": "Signal dimension, defined here as the number of copies with different delays\nor angular shifts, is a prerequisite for many high-resolution delay estimation\nand direction-finding algorithms in sensing and communication systems. Thus,\ncorrectly estimating signal dimension itself becomes crucial. In this paper, we\npresent a deep learning-based signal dimension estimator (DLSDE) with\nsingle-snapshot observation in the example application of phased array radar.\nUnlike traditional model-based and existing deep learning-based signal\ndimension estimators relying on eigen-decomposition and information criterion,\nto which multiple data snapshots would be needed, the proposed DLSDE uses\ntwo-dimensional convolutional neural network (2D-CNN) to automatically develop\nfeatures corresponding to the dimension of the received signal. Our study shows\nthat DLSDE significantly outperforms traditional methods in terms of the\nsuccessful detection rate and resolution. In a phased array radar with 32\nantenna elements, DLSDE improves detection Signal to Noise Ratio (SNR) by >15dB\nand resolution by >1{\\deg}. This makes the proposed method suitable for\ndistinguishing multiple signals that are spatially correlated or have small\nangular separation. More importantly, our solution operates with a single\nsnapshot signal, which is incompatible with other existing deep learning-based\nmethods.", "published": "2025-08-14 01:12:35", "link": "http://arxiv.org/abs/2508.10263v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
