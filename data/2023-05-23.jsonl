{"title": "Latent Positional Information is in the Self-Attention Variance of\n  Transformer Language Models Without Positional Embeddings", "abstract": "The use of positional embeddings in transformer language models is widely\naccepted. However, recent research has called into question the necessity of\nsuch embeddings. We further extend this inquiry by demonstrating that a\nrandomly initialized and frozen transformer language model, devoid of\npositional embeddings, inherently encodes strong positional information through\nthe shrinkage of self-attention variance. To quantify this variance, we derive\nthe underlying distribution of each step within a transformer layer. Through\nempirical validation using a fully pretrained model, we show that the variance\nshrinkage effect still persists after extensive gradient updates. Our findings\nserve to justify the decision to discard positional embeddings and thus\nfacilitate more efficient pretraining of transformer language models.", "published": "2023-05-23 01:03:40", "link": "http://arxiv.org/abs/2305.13571v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Translation and Fusion Improves Zero-shot Cross-lingual Information\n  Extraction", "abstract": "Large language models (LLMs) combined with instruction tuning have shown\nsignificant progress in information extraction (IE) tasks, exhibiting strong\ngeneralization capabilities to unseen datasets by following annotation\nguidelines. However, their applicability to low-resource languages remains\nlimited due to lack of both labeled data for fine-tuning, and unlabeled text\nfor pre-training. In this paper, we propose TransFusion, a framework in which\nmodels are fine-tuned to use English translations of low-resource language\ndata, enabling more precise predictions through annotation fusion. Based on\nTransFusion, we introduce GoLLIE-TF, a cross-lingual instruction-tuned LLM for\nIE tasks, designed to close the performance gap between high and low-resource\nlanguages. Our experiments across twelve multilingual IE datasets spanning 50\nlanguages demonstrate that GoLLIE-TF achieves better zero-shot cross-lingual\ntransfer over the base model. In addition, we show that TransFusion\nsignificantly improves low-resource language named entity recognition when\napplied to proprietary models such as GPT-4 (+5 F1) with a prompting approach,\nor fine-tuning different language models including decoder-only (+14 F1) and\nencoder-only (+13 F1) architectures.", "published": "2023-05-23 01:23:22", "link": "http://arxiv.org/abs/2305.13582v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Query Structure Modeling for Inductive Logical Reasoning Over Knowledge\n  Graphs", "abstract": "Logical reasoning over incomplete knowledge graphs to answer complex logical\nqueries is a challenging task. With the emergence of new entities and relations\nin constantly evolving KGs, inductive logical reasoning over KGs has become a\ncrucial problem. However, previous PLMs-based methods struggle to model the\nlogical structures of complex queries, which limits their ability to generalize\nwithin the same structure. In this paper, we propose a structure-modeled\ntextual encoding framework for inductive logical reasoning over KGs. It encodes\nlinearized query structures and entities using pre-trained language models to\nfind answers. For structure modeling of complex queries, we design stepwise\ninstructions that implicitly prompt PLMs on the execution order of geometric\noperations in each query. We further separately model different geometric\noperations (i.e., projection, intersection, and union) on the representation\nspace using a pre-trained encoder with additional attention and maxout layers\nto enhance structured modeling. We conduct experiments on two inductive logical\nreasoning datasets and three transductive datasets. The results demonstrate the\neffectiveness of our method on logical reasoning over KGs in both inductive and\ntransductive settings.", "published": "2023-05-23 01:25:29", "link": "http://arxiv.org/abs/2305.13585v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BiasX: \"Thinking Slow\" in Toxic Content Moderation with Explanations of\n  Implied Social Biases", "abstract": "Toxicity annotators and content moderators often default to mental shortcuts\nwhen making decisions. This can lead to subtle toxicity being missed, and\nseemingly toxic but harmless content being over-detected. We introduce BiasX, a\nframework that enhances content moderation setups with free-text explanations\nof statements' implied social biases, and explore its effectiveness through a\nlarge-scale crowdsourced user study. We show that indeed, participants\nsubstantially benefit from explanations for correctly identifying subtly\n(non-)toxic content. The quality of explanations is critical: imperfect\nmachine-generated explanations (+2.4% on hard toxic examples) help less\ncompared to expert-written human explanations (+7.2%). Our results showcase the\npromise of using free-text explanations to encourage more thoughtful toxicity\nmoderation.", "published": "2023-05-23 01:45:18", "link": "http://arxiv.org/abs/2305.13589v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReSee: Responding through Seeing Fine-grained Visual Knowledge in\n  Open-domain Dialogue", "abstract": "Incorporating visual knowledge into text-only dialogue systems has become a\npotential direction to imitate the way humans think, imagine, and communicate.\nHowever, existing multimodal dialogue systems are either confined by the scale\nand quality of available datasets or the coarse concept of visual knowledge. To\naddress these issues, we provide a new paradigm of constructing multimodal\ndialogues as well as two datasets extended from text-only dialogues under such\nparadigm (ReSee-WoW, ReSee-DD). We propose to explicitly split the visual\nknowledge into finer granularity (``turn-level'' and ``entity-level''). To\nfurther boost the accuracy and diversity of augmented visual information, we\nretrieve them from the Internet or a large image dataset. To demonstrate the\nsuperiority and universality of the provided visual knowledge, we propose a\nsimple but effective framework ReSee to add visual representation into vanilla\ndialogue models by modality concatenations. We also conduct extensive\nexperiments and ablations w.r.t. different model configurations and visual\nknowledge settings. Empirical, encouraging results not only demonstrate the\neffectiveness of introducing visual knowledge at both entity and turn level but\nalso verify the proposed model ReSee outperforms several state-of-the-art\nmethods on automatic and human evaluations. By leveraging text and vision\nknowledge, ReSee can produce informative responses with real-world visual\nconcepts. Our code is available at https://github.com/ImKeTT/ReSee.", "published": "2023-05-23 02:08:56", "link": "http://arxiv.org/abs/2305.13602v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-empowered Chatbots for Psychiatrist and Patient Simulation:\n  Application and Evaluation", "abstract": "Empowering chatbots in the field of mental health is receiving increasing\namount of attention, while there still lacks exploration in developing and\nevaluating chatbots in psychiatric outpatient scenarios. In this work, we focus\non exploring the potential of ChatGPT in powering chatbots for psychiatrist and\npatient simulation. We collaborate with psychiatrists to identify objectives\nand iteratively develop the dialogue system to closely align with real-world\nscenarios. In the evaluation experiments, we recruit real psychiatrists and\npatients to engage in diagnostic conversations with the chatbots, collecting\ntheir ratings for assessment. Our findings demonstrate the feasibility of using\nChatGPT-powered chatbots in psychiatric scenarios and explore the impact of\nprompt designs on chatbot behavior and user experience.", "published": "2023-05-23 02:25:01", "link": "http://arxiv.org/abs/2305.13614v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompting and Evaluating Large Language Models for Proactive Dialogues:\n  Clarification, Target-guided, and Non-collaboration", "abstract": "Conversational systems based on Large Language Models (LLMs), such as\nChatGPT, show exceptional proficiency in context understanding and response\ngeneration. However, despite their impressive capabilities, they still possess\nlimitations, such as providing randomly-guessed answers to ambiguous queries or\nfailing to refuse users' requests, both of which are considered aspects of a\nconversational agent's proactivity. This raises the question of whether\nLLM-based conversational systems are equipped to handle proactive dialogue\nproblems. In this work, we conduct a comprehensive analysis of LLM-based\nconversational systems, specifically focusing on three aspects of proactive\ndialogue systems: clarification, target-guided, and non-collaborative\ndialogues. To trigger the proactivity of LLMs, we propose the Proactive\nChain-of-Thought prompting scheme, which augments LLMs with the goal planning\ncapability over descriptive reasoning chains. Empirical findings are discussed\nto promote future studies on LLM-based proactive dialogue systems.", "published": "2023-05-23 02:49:35", "link": "http://arxiv.org/abs/2305.13626v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Self-training for Cross-lingual Named Entity Recognition with\n  Contrastive and Prototype Learning", "abstract": "In cross-lingual named entity recognition (NER), self-training is commonly\nused to bridge the linguistic gap by training on pseudo-labeled target-language\ndata. However, due to sub-optimal performance on target languages, the pseudo\nlabels are often noisy and limit the overall performance. In this work, we aim\nto improve self-training for cross-lingual NER by combining representation\nlearning and pseudo label refinement in one coherent framework. Our proposed\nmethod, namely ContProto mainly comprises two components: (1) contrastive\nself-training and (2) prototype-based pseudo-labeling. Our contrastive\nself-training facilitates span classification by separating clusters of\ndifferent classes, and enhances cross-lingual transferability by producing\nclosely-aligned representations between the source and target language.\nMeanwhile, prototype-based pseudo-labeling effectively improves the accuracy of\npseudo labels during training. We evaluate ContProto on multiple transfer\npairs, and experimental results show our method brings in substantial\nimprovements over current state-of-the-art methods.", "published": "2023-05-23 02:52:16", "link": "http://arxiv.org/abs/2305.13628v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IdEALS: Idiomatic Expressions for Advancement of Language Skills", "abstract": "Although significant progress has been made in developing methods for\nGrammatical Error Correction (GEC), addressing word choice improvements has\nbeen notably lacking and enhancing sentence expressivity by replacing phrases\nwith advanced expressions is an understudied aspect. In this paper, we focus on\nthis area and present our investigation into the task of incorporating the\nusage of idiomatic expressions in student writing. To facilitate our study, we\ncurate extensive training sets and expert-annotated testing sets using\nreal-world data and evaluate various approaches and compare their performance\nagainst human experts.", "published": "2023-05-23 03:11:41", "link": "http://arxiv.org/abs/2305.13637v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AxomiyaBERTa: A Phonologically-aware Transformer Model for Assamese", "abstract": "Despite their successes in NLP, Transformer-based language models still\nrequire extensive computing resources and suffer in low-resource or low-compute\nsettings. In this paper, we present AxomiyaBERTa, a novel BERT model for\nAssamese, a morphologically-rich low-resource language (LRL) of Eastern India.\nAxomiyaBERTa is trained only on the masked language modeling (MLM) task,\nwithout the typical additional next sentence prediction (NSP) objective, and\nour results show that in resource-scarce settings for very low-resource\nlanguages like Assamese, MLM alone can be successfully leveraged for a range of\ntasks. AxomiyaBERTa achieves SOTA on token-level tasks like Named Entity\nRecognition and also performs well on \"longer-context\" tasks like Cloze-style\nQA and Wiki Title Prediction, with the assistance of a novel embedding\ndisperser and phonological signals respectively. Moreover, we show that\nAxomiyaBERTa can leverage phonological signals for even more challenging tasks,\nsuch as a novel cross-document coreference task on a translated version of the\nECB+ corpus, where we present a new SOTA result for an LRL. Our source code and\nevaluation scripts may be found at https://github.com/csu-signal/axomiyaberta.", "published": "2023-05-23 03:19:21", "link": "http://arxiv.org/abs/2305.13641v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "mPMR: A Multilingual Pre-trained Machine Reader at Scale", "abstract": "We present multilingual Pre-trained Machine Reader (mPMR), a novel method for\nmultilingual machine reading comprehension (MRC)-style pre-training. mPMR aims\nto guide multilingual pre-trained language models (mPLMs) to perform natural\nlanguage understanding (NLU) including both sequence classification and span\nextraction in multiple languages. To achieve cross-lingual generalization when\nonly source-language fine-tuning data is available, existing mPLMs solely\ntransfer NLU capability from a source language to target languages. In\ncontrast, mPMR allows the direct inheritance of multilingual NLU capability\nfrom the MRC-style pre-training to downstream tasks. Therefore, mPMR acquires\nbetter NLU capability for target languages. mPMR also provides a unified solver\nfor tackling cross-lingual span extraction and sequence classification, thereby\nenabling the extraction of rationales to explain the sentence-pair\nclassification process.", "published": "2023-05-23 03:40:36", "link": "http://arxiv.org/abs/2305.13645v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding and Mitigating Spurious Correlations in Text\n  Classification with Neighborhood Analysis", "abstract": "Recent research has revealed that machine learning models have a tendency to\nleverage spurious correlations that exist in the training set but may not hold\ntrue in general circumstances. For instance, a sentiment classifier may\nerroneously learn that the token \"performances\" is commonly associated with\npositive movie reviews. Relying on these spurious correlations degrades the\nclassifiers performance when it deploys on out-of-distribution data. In this\npaper, we examine the implications of spurious correlations through a novel\nperspective called neighborhood analysis. The analysis uncovers how spurious\ncorrelations lead unrelated words to erroneously cluster together in the\nembedding space. Driven by the analysis, we design a metric to detect spurious\ntokens and also propose a family of regularization methods, NFL (doN't Forget\nyour Language) to mitigate spurious correlations in text classification.\nExperiments show that NFL can effectively prevent erroneous clusters and\nsignificantly improve the robustness of classifiers without auxiliary data. The\ncode is publicly available at\nhttps://github.com/oscarchew/doNt-Forget-your-Language.", "published": "2023-05-23 03:55:50", "link": "http://arxiv.org/abs/2305.13654v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChatGPT as your Personal Data Scientist", "abstract": "The rise of big data has amplified the need for efficient, user-friendly\nautomated machine learning (AutoML) tools. However, the intricacy of\nunderstanding domain-specific data and defining prediction tasks necessitates\nhuman intervention making the process time-consuming while preventing full\nautomation. Instead, envision an intelligent agent capable of assisting users\nin conducting AutoML tasks through intuitive, natural conversations without\nrequiring in-depth knowledge of the underlying machine learning (ML) processes.\nThis agent's key challenge is to accurately comprehend the user's prediction\ngoals and, consequently, formulate precise ML tasks, adjust data sets and model\nparameters accordingly, and articulate results effectively. In this paper, we\ntake a pioneering step towards this ambitious goal by introducing a\nChatGPT-based conversational data-science framework to act as a \"personal data\nscientist\". Precisely, we utilize Large Language Models (ChatGPT) to build a\nnatural interface between the users and the ML models (Scikit-Learn), which in\nturn, allows us to approach this ambitious problem with a realistic solution.\n  Our model pivots around four dialogue states: Data Visualization, Task\nFormulation, Prediction Engineering, and Result Summary and Recommendation.\nEach state marks a unique conversation phase, impacting the overall user-system\ninteraction. Multiple LLM instances, serving as \"micro-agents\", ensure a\ncohesive conversation flow, granting us granular control over the\nconversation's progression. In summary, we developed an end-to-end system that\nnot only proves the viability of the novel concept of conversational data\nscience but also underscores the potency of LLMs in solving complex tasks.\nInterestingly, its development spotlighted several critical weaknesses in the\ncurrent LLMs (ChatGPT) and highlighted substantial opportunities for\nimprovement.", "published": "2023-05-23 04:00:16", "link": "http://arxiv.org/abs/2305.13657v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Compositional Data Augmentation in Typologically Diverse\n  Morphological Inflection", "abstract": "Data augmentation techniques are widely used in low-resource automatic\nmorphological inflection to overcome data sparsity. However, the full\nimplications of these techniques remain poorly understood. In this study, we\naim to shed light on the theoretical aspects of the prominent data augmentation\nstrategy StemCorrupt (Silfverberg et al., 2017; Anastasopoulos and Neubig,\n2019), a method that generates synthetic examples by randomly substituting stem\ncharacters in gold standard training examples. To begin, we conduct an\ninformation-theoretic analysis, arguing that StemCorrupt improves compositional\ngeneralization by eliminating spurious correlations between morphemes,\nspecifically between the stem and the affixes. Our theoretical analysis further\nleads us to study the sample efficiency with which StemCorrupt reduces these\nspurious correlations. Through evaluation across seven typologically distinct\nlanguages, we demonstrate that selecting a subset of datapoints with both high\ndiversity and high predictive uncertainty significantly enhances the\ndata-efficiency of StemCorrupt. However, we also explore the impact of\ntypological features on the choice of the data selection strategy and find that\nlanguages incorporating a high degree of allomorphy and phonological\nalternations derive less benefit from synthetic examples with high uncertainty.\nWe attribute this effect to phonotactic violations induced by StemCorrupt,\nemphasizing the need for further research to ensure optimal performance across\nthe entire spectrum of natural language morphology.", "published": "2023-05-23 04:02:54", "link": "http://arxiv.org/abs/2305.13658v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy\n  Planning", "abstract": "Planning for goal-oriented dialogue often requires simulating future dialogue\ninteractions and estimating task progress. Many approaches thus consider\ntraining neural networks to perform look-ahead search algorithms such as A*\nsearch and Monte Carlo Tree Search (MCTS). However, this training often\nrequires abundant annotated data, which creates challenges when faced with\nnoisy annotations or low-resource settings. We introduce GDP-Zero, an approach\nusing Open-Loop MCTS to perform goal-oriented dialogue policy planning without\nany model training. GDP-Zero prompts a large language model to act as a policy\nprior, value function, user simulator, and system model during the tree search.\nWe evaluate GDP-Zero on the goal-oriented task PersuasionForGood, and find that\nits responses are preferred over ChatGPT up to 59.32% of the time, and are\nrated more persuasive than ChatGPT during interactive evaluations.", "published": "2023-05-23 04:07:03", "link": "http://arxiv.org/abs/2305.13660v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optimizing Non-Autoregressive Transformers with Contrastive Learning", "abstract": "Non-autoregressive Transformers (NATs) reduce the inference latency of\nAutoregressive Transformers (ATs) by predicting words all at once rather than\nin sequential order. They have achieved remarkable progress in machine\ntranslation as well as many other applications. However, a long-standing\nchallenge for NATs is the learning of multi-modality data distribution, which\nis the main cause of the performance gap between NATs and ATs. In this paper,\nwe propose to ease the difficulty of modality learning via sampling from the\nmodel distribution instead of the data distribution. We derive contrastive\nconstraints to stabilize the training process and integrate this resulting\nobjective with the state-of-the-art NAT architecture DA-Transformer. Our model\n\\method is examined on 3 different tasks, including machine translation, text\nsummarization, and paraphrasing with 5 benchmarks. Results show that our\napproach outperforms previous non-autoregressive baselines by a significant\nmargin and establishes new state-of-the-art results for non-autoregressive\ntransformers on all the benchmarks.", "published": "2023-05-23 04:20:13", "link": "http://arxiv.org/abs/2305.13667v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge in\n  Foundation Models", "abstract": "In this work, we assess the ability of foundation models to recall\nencyclopedic knowledge across a wide range of linguistic contexts. To support\nthis, we: 1) produce a 20-language dataset that contains 303k factual\nassociations paired with counterfactuals, 2) evaluate 5 models in a\nmultilingual test, and 3) benchmark a diverse set of 24 models in an\nEnglish-only test. Meta's LLaMA achieves the highest scores in both\nmultilingual and English-only evaluations. Yet, an analysis of LLaMA's errors\nreveals significant limitations in its ability to recall facts in languages\nother than English, plus difficulties related to the location and gender of\nfact subjects. Overall, our findings suggest that today's foundation models are\nfar from polyglots.", "published": "2023-05-23 04:31:39", "link": "http://arxiv.org/abs/2305.13675v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Legally Enforceable Hate Speech Detection for Public Forums", "abstract": "Hate speech causes widespread and deep-seated societal issues. Proper\nenforcement of hate speech laws is key for protecting groups of people against\nharmful and discriminatory language. However, determining what constitutes hate\nspeech is a complex task that is highly open to subjective interpretations.\nExisting works do not align their systems with enforceable definitions of hate\nspeech, which can make their outputs inconsistent with the goals of regulators.\nThis research introduces a new perspective and task for enforceable hate speech\ndetection centred around legal definitions, and a dataset annotated on\nviolations of eleven possible definitions by legal experts. Given the challenge\nof identifying clear, legally enforceable instances of hate speech, we augment\nthe dataset with expert-generated samples and an automatically mined challenge\nset. We experiment with grounding the model decision in these definitions using\nzero-shot and few-shot prompting. We then report results on several large\nlanguage models (LLMs). With this task definition, automatic hate speech\ndetection can be more closely aligned to enforceable laws, and hence assist in\nmore rigorous enforcement of legal protections against harmful speech in public\nforums.", "published": "2023-05-23 04:34:41", "link": "http://arxiv.org/abs/2305.13677v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Error Detection for Text-to-SQL Semantic Parsing", "abstract": "Despite remarkable progress in text-to-SQL semantic parsing in recent years,\nthe performance of existing parsers is still far from perfect. Specifically,\nmodern text-to-SQL parsers based on deep learning are often over-confident,\nthus casting doubt on their trustworthiness when deployed for real use. In this\npaper, we propose a parser-independent error detection model for text-to-SQL\nsemantic parsing. Using a language model of code as its bedrock, we enhance our\nerror detection model with graph neural networks that learn structural features\nof both natural language questions and SQL queries. We train our model on\nrealistic parsing errors collected from a cross-domain setting, which leads to\nstronger generalization ability. Experiments with three strong text-to-SQL\nparsers featuring different decoding mechanisms show that our approach\noutperforms parser-dependent uncertainty metrics. Our model could also\neffectively improve the performance and usability of text-to-SQL semantic\nparsers regardless of their architectures. (Our implementation is available at\nhttps://github.com/OSU-NLP-Group/Text2SQL-Error-Detection)", "published": "2023-05-23 04:44:22", "link": "http://arxiv.org/abs/2305.13683v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "mPLM-Sim: Better Cross-Lingual Similarity and Transfer in Multilingual\n  Pretrained Language Models", "abstract": "Recent multilingual pretrained language models (mPLMs) have been shown to\nencode strong language-specific signals, which are not explicitly provided\nduring pretraining. It remains an open question whether it is feasible to\nemploy mPLMs to measure language similarity, and subsequently use the\nsimilarity results to select source languages for boosting cross-lingual\ntransfer. To investigate this, we propose mPLMSim, a language similarity\nmeasure that induces the similarities across languages from mPLMs using\nmulti-parallel corpora. Our study shows that mPLM-Sim exhibits moderately high\ncorrelations with linguistic similarity measures, such as lexicostatistics,\ngenealogical language family, and geographical sprachbund. We also conduct a\ncase study on languages with low correlation and observe that mPLM-Sim yields\nmore accurate similarity results. Additionally, we find that similarity results\nvary across different mPLMs and different layers within an mPLM. We further\ninvestigate whether mPLMSim is effective for zero-shot cross-lingual transfer\nby conducting experiments on both low-level syntactic tasks and high-level\nsemantic tasks. The experimental results demonstrate that mPLM-Sim is capable\nof selecting better source languages than linguistic measures, resulting in a\n1%-2% improvement in zero-shot cross-lingual transfer performance.", "published": "2023-05-23 04:44:26", "link": "http://arxiv.org/abs/2305.13684v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Causal Intervention for Abstractive Related Work Generation", "abstract": "Abstractive related work generation has attracted increasing attention in\ngenerating coherent related work that better helps readers grasp the background\nin the current research. However, most existing abstractive models ignore the\ninherent causality of related work generation, leading to low quality of\ngenerated related work and spurious correlations that affect the models'\ngeneralizability. In this study, we argue that causal intervention can address\nthese limitations and improve the quality and coherence of the generated\nrelated works. To this end, we propose a novel Causal Intervention Module for\nRelated Work Generation (CaM) to effectively capture causalities in the\ngeneration process and improve the quality and coherence of the generated\nrelated works. Specifically, we first model the relations among sentence order,\ndocument relation, and transitional content in related work generation using a\ncausal graph. Then, to implement the causal intervention and mitigate the\nnegative impact of spurious correlations, we use do-calculus to derive ordinary\nconditional probabilities and identify causal effects through CaM. Finally, we\nsubtly fuse CaM with Transformer to obtain an end-to-end generation model.\nExtensive experiments on two real-world datasets show that causal interventions\nin CaM can effectively promote the model to learn causal relations and produce\nrelated work of higher quality and coherence.", "published": "2023-05-23 04:48:30", "link": "http://arxiv.org/abs/2305.13685v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-Shot Data Synthesis for Open Domain Multi-Hop Question Answering", "abstract": "Few-shot learning for open domain multi-hop question answering typically\nrelies on the incontext learning capability of large language models (LLMs).\nWhile powerful, these LLMs usually contain tens or hundreds of billions of\nparameters, making them rather inefficient at inference time. To improve\nperformance of smaller language models, we propose a data synthesis framework\nfor multi-hop question answering that requires less than 10 human annotated\nquestion answer pairs. Our framework depends only on rich, naturally-occurring\nrelationships among documents and is built upon the data generation functions\nparameterized by LLMs and prompts. We synthesize millions of multi-hop\nquestions and claims to finetune language models, evaluated on popular\nbenchmarks for multi-hop question answering and fact verification. Empirically,\nour approach improves model performance significantly, allowing the finetuned\nmodels to be competitive with GPT-3.5 based approaches while being almost\none-third the size in parameter count.", "published": "2023-05-23 04:57:31", "link": "http://arxiv.org/abs/2305.13691v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Metrics for Medical Multi-Document Summarization Disagree with\n  Human Evaluations", "abstract": "Evaluating multi-document summarization (MDS) quality is difficult. This is\nespecially true in the case of MDS for biomedical literature reviews, where\nmodels must synthesize contradicting evidence reported across different\ndocuments. Prior work has shown that rather than performing the task, models\nmay exploit shortcuts that are difficult to detect using standard n-gram\nsimilarity metrics such as ROUGE. Better automated evaluation metrics are\nneeded, but few resources exist to assess metrics when they are proposed.\nTherefore, we introduce a dataset of human-assessed summary quality facets and\npairwise preferences to encourage and support the development of better\nautomated evaluation methods for literature review MDS. We take advantage of\ncommunity submissions to the Multi-document Summarization for Literature Review\n(MSLR) shared task to compile a diverse and representative sample of generated\nsummaries. We analyze how automated summarization evaluation metrics correlate\nwith lexical features of generated summaries, to other automated metrics\nincluding several we propose in this work, and to aspects of human-assessed\nsummary quality. We find that not only do automated metrics fail to capture\naspects of quality as assessed by humans, in many cases the system rankings\nproduced by these metrics are anti-correlated with rankings according to human\nannotators.", "published": "2023-05-23 05:00:59", "link": "http://arxiv.org/abs/2305.13693v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Abstractive Text Summarization Using the BRIO Training Paradigm", "abstract": "Summary sentences produced by abstractive summarization models may be\ncoherent and comprehensive, but they lack control and rely heavily on reference\nsummaries. The BRIO training paradigm assumes a non-deterministic distribution\nto reduce the model's dependence on reference summaries, and improve model\nperformance during inference. This paper presents a straightforward but\neffective technique to improve abstractive summaries by fine-tuning pre-trained\nlanguage models, and training them with the BRIO paradigm. We build a text\nsummarization dataset for Vietnamese, called VieSum. We perform experiments\nwith abstractive summarization models trained with the BRIO paradigm on the\nCNNDM and the VieSum datasets. The results show that the models, trained on\nbasic hardware, outperform all existing abstractive summarization models,\nespecially for Vietnamese.", "published": "2023-05-23 05:09:53", "link": "http://arxiv.org/abs/2305.13696v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UNIMO-3: Multi-granularity Interaction for Vision-Language\n  Representation Learning", "abstract": "Vision-and-language (VL) pre-training, which aims to learn a general\nrepresentation of image-text pairs that can be transferred to various\nvision-and-language tasks. Compared with modeling uni-modal data, the main\nchallenge of the VL model is: how to learn the cross-modal interaction from\nmultimodal data, especially the fine-grained interaction. Existing works have\nshown that fully transformer-based models that adopt attention mechanisms to\nlearn in-layer cross-model interaction can demonstrate impressive performance\non various cross-modal downstream tasks. However, they ignored that the\nsemantic information of the different modals at the same layer was not uniform,\nwhich leads to the cross-modal interaction collapsing into a limited\nmulti-modal semantic information interaction. In this work, we propose the\nUNIMO-3 model, which has the capacity to simultaneously learn the multimodal\nin-layer interaction and cross-layer interaction. UNIMO-3 model can establish\neffective connections between different layers in a cross-modal encoder, and\nadaptively capture the interaction between two modalities at different levels.\nThe experimental results show that our model achieves state-of-the-art\nperformance in various downstream tasks, and through ablation study can prove\nthat effective cross-layer learning improves the model's ability of multimodal\nrepresentation.", "published": "2023-05-23 05:11:34", "link": "http://arxiv.org/abs/2305.13697v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Large Language Models for Classical Philology", "abstract": "Recent advances in NLP have led to the creation of powerful language models\nfor many languages including Ancient Greek and Latin. While prior work on\nClassical languages unanimously uses BERT, in this work we create four language\nmodels for Ancient Greek that vary along two dimensions to study their\nversatility for tasks of interest for Classical languages: we explore (i)\nencoder-only and encoder-decoder architectures using RoBERTa and T5 as strong\nmodel types, and create for each of them (ii) a monolingual Ancient Greek and a\nmultilingual instance that includes Latin and English. We evaluate all models\non morphological and syntactic tasks, including lemmatization, which\ndemonstrates the added value of T5's decoding abilities. We further define two\nprobing tasks to investigate the knowledge acquired by models pre-trained on\nClassical texts. Our experiments provide the first benchmarking analysis of\nexisting models of Ancient Greek. Results show that our models provide\nsignificant improvements over the SoTA. The systematic analysis of model types\ncan inform future research in designing language models for Classical\nlanguages, including the development of novel generative tasks. We make all our\nmodels available as community resources, along with a large curated\npre-training corpus for Ancient Greek, to support the creation of a larger,\ncomparable model zoo for Classical Philology. Our models and resources are\navailable at https://github.com/Heidelberg-NLP/ancient-language-models.", "published": "2023-05-23 05:21:02", "link": "http://arxiv.org/abs/2305.13698v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MemeCap: A Dataset for Captioning and Interpreting Memes", "abstract": "Memes are a widely popular tool for web users to express their thoughts using\nvisual metaphors. Understanding memes requires recognizing and interpreting\nvisual metaphors with respect to the text inside or around the meme, often\nwhile employing background knowledge and reasoning abilities. We present the\ntask of meme captioning and release a new dataset, MemeCap. Our dataset\ncontains 6.3K memes along with the title of the post containing the meme, the\nmeme captions, the literal image caption, and the visual metaphors. Despite the\nrecent success of vision and language (VL) models on tasks such as image\ncaptioning and visual question answering, our extensive experiments using\nstate-of-the-art VL models show that they still struggle with visual metaphors,\nand perform substantially worse than humans.", "published": "2023-05-23 05:41:18", "link": "http://arxiv.org/abs/2305.13703v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do All Languages Cost the Same? Tokenization in the Era of Commercial\n  Language Models", "abstract": "Language models have graduated from being research prototypes to\ncommercialized products offered as web APIs, and recent works have highlighted\nthe multilingual capabilities of these products. The API vendors charge their\nusers based on usage, more specifically on the number of ``tokens'' processed\nor generated by the underlying language models. What constitutes a token,\nhowever, is training data and model dependent with a large variance in the\nnumber of tokens required to convey the same information in different\nlanguages. In this work, we analyze the effect of this non-uniformity on the\nfairness of an API's pricing policy across languages. We conduct a systematic\nanalysis of the cost and utility of OpenAI's language model API on multilingual\nbenchmarks in 22 typologically diverse languages. We show evidence that\nspeakers of a large number of the supported languages are overcharged while\nobtaining poorer results. These speakers tend to also come from regions where\nthe APIs are less affordable to begin with. Through these analyses, we aim to\nincrease transparency around language model APIs' pricing policies and\nencourage the vendors to make them more equitable.", "published": "2023-05-23 05:46:45", "link": "http://arxiv.org/abs/2305.13707v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Textual Interface to Align External Knowledge for End-to-End\n  Task-Oriented Dialogue Systems", "abstract": "Traditional end-to-end task-oriented dialogue systems have been built with a\nmodularized design. However, such design often causes misalignment between the\nagent response and external knowledge, due to inadequate representation of\ninformation. Furthermore, its evaluation metrics emphasize assessing the\nagent's pre-lexicalization response, neglecting the quality of the completed\nresponse. In this work, we propose a novel paradigm that uses a textual\ninterface to align external knowledge and eliminate redundant processes. We\ndemonstrate our paradigm in practice through MultiWOZ-Remake, including an\ninteractive textual interface built for the MultiWOZ database and a\ncorrespondingly re-processed dataset. We train an end-to-end dialogue system to\nevaluate this new dataset. The experimental results show that our approach\ngenerates more natural final responses and achieves a greater task success rate\ncompared to the previous models.", "published": "2023-05-23 05:48:21", "link": "http://arxiv.org/abs/2305.13710v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Self-supervised Logic-enhanced Training for Large Language\n  Models", "abstract": "Existing efforts to improve logical reasoning ability of language models have\npredominantly relied on supervised fine-tuning, hindering generalization to new\ndomains and/or tasks. The development of Large Langauge Models (LLMs) has\ndemonstrated the capacity of compressing abundant knowledge into a single\nproxy, enabling them to tackle multiple tasks effectively. Our preliminary\nexperiments, nevertheless, show that LLMs do not show capability on logical\nreasoning. The performance of LLMs on logical reasoning benchmarks is far\nbehind the existing state-of-the-art baselines. In this paper, we make the\nfirst attempt to investigate the feasibility of incorporating logical knowledge\nthrough self-supervised post-training, and activating it via in-context\nlearning, which we termed as LogicLLM. Specifically, we devise an\nauto-regressive objective variant of MERIt and integrate it with two LLM\nseries, i.e., FLAN-T5 and LLaMA, with parameter size ranging from 3 billion to\n13 billion. The results on two challenging logical reasoning benchmarks\ndemonstrate the effectiveness of LogicLLM. Besides, we conduct extensive\nablation studies to analyze the key factors in designing logic-oriented proxy\ntasks.", "published": "2023-05-23 06:13:10", "link": "http://arxiv.org/abs/2305.13718v7", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PIEClass: Weakly-Supervised Text Classification with Prompting and\n  Noise-Robust Iterative Ensemble Training", "abstract": "Weakly-supervised text classification trains a classifier using the label\nname of each target class as the only supervision, which largely reduces human\nannotation efforts. Most existing methods first use the label names as static\nkeyword-based features to generate pseudo labels, which are then used for final\nclassifier training. While reasonable, such a commonly adopted framework\nsuffers from two limitations: (1) keywords can have different meanings in\ndifferent contexts and some text may not have any keyword, so keyword matching\ncan induce noisy and inadequate pseudo labels; (2) the errors made in the\npseudo label generation stage will directly propagate to the classifier\ntraining stage without a chance of being corrected. In this paper, we propose a\nnew method, PIEClass, consisting of two modules: (1) a pseudo label acquisition\nmodule that uses zero-shot prompting of pre-trained language models (PLM) to\nget pseudo labels based on contextualized text understanding beyond static\nkeyword matching, and (2) a noise-robust iterative ensemble training module\nthat iteratively trains classifiers and updates pseudo labels by utilizing two\nPLM fine-tuning methods that regularize each other. Extensive experiments show\nthat PIEClass achieves overall better performance than existing strong\nbaselines on seven benchmark datasets and even achieves similar performance to\nfully-supervised classifiers on sentiment classification tasks.", "published": "2023-05-23 06:19:14", "link": "http://arxiv.org/abs/2305.13723v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Large Language Models Against Inductive Instructions with\n  Dual-critique Prompting", "abstract": "Numerous works are proposed to align large language models (LLMs) with human\nintents to better fulfill instructions, ensuring they are trustful and helpful.\nNevertheless, some human instructions are often malicious or misleading and\nfollowing them will lead to untruthful and unsafe responses. Previous work\nrarely focused on understanding how LLMs manage instructions based on\ncounterfactual premises, referred to here as \\textit{inductive instructions},\nwhich may stem from users' false beliefs or malicious intents. In this paper,\nwe aim to reveal the behaviors of LLMs towards \\textit{inductive instructions}\nand enhance their truthfulness and helpfulness accordingly. Specifically, we\nfirst introduce a benchmark of \\underline{\\textbf{Indu}}ctive\n{In\\underline{\\textbf{st}}ruct}ions (\\textsc{\\textbf{INDust}}), where the false\nknowledge is incorporated into instructions in multiple different styles. After\nextensive human and automatic evaluations, we uncovered a universal\nvulnerability among LLMs in processing inductive instructions. Additionally, we\nidentified that different inductive styles affect the models' ability to\nidentify the same underlying errors, and the complexity of the underlying\nassumptions also influences the model's performance. Motivated by these\nresults, we propose \\textsc{Dual-critique} prompting to improve LLM robustness\nagainst inductive instructions. Our experiments demonstrate that\n\\textsc{Dual-critique} prompting significantly bolsters the robustness of a\ndiverse array of LLMs, even when confronted with varying degrees of inductive\ninstruction complexity and differing inductive styles.", "published": "2023-05-23 06:38:20", "link": "http://arxiv.org/abs/2305.13733v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TeCS: A Dataset and Benchmark for Tense Consistency of Machine\n  Translation", "abstract": "Tense inconsistency frequently occurs in machine translation. However, there\nare few criteria to assess the model's mastery of tense prediction from a\nlinguistic perspective. In this paper, we present a parallel tense test set,\ncontaining French-English 552 utterances. We also introduce a corresponding\nbenchmark, tense prediction accuracy. With the tense test set and the\nbenchmark, researchers are able to measure the tense consistency performance of\nmachine translation systems for the first time.", "published": "2023-05-23 06:51:48", "link": "http://arxiv.org/abs/2305.13740v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Goal-Driven Explainable Clustering via Language Descriptions", "abstract": "Unsupervised clustering is widely used to explore large corpora, but existing\nformulations neither consider the users' goals nor explain clusters' meanings.\nWe propose a new task formulation, \"Goal-Driven Clustering with Explanations\"\n(GoalEx), which represents both the goal and the explanations as free-form\nlanguage descriptions. For example, to categorize the errors made by a\nsummarization system, the input to GoalEx is a corpus of annotator-written\ncomments for system-generated summaries and a goal description \"cluster the\ncomments based on why the annotators think the summary is imperfect.''; the\noutputs are text clusters each with an explanation (\"this cluster mentions that\nthe summary misses important context information.\"), which relates to the goal\nand precisely explain which comments should (not) belong to a cluster. To\ntackle GoalEx, we prompt a language model with \"[corpus subset] + [goal] +\nBrainstorm a list of explanations each representing a cluster.\"; then we\nclassify whether each sample belongs to a cluster based on its explanation;\nfinally, we use integer linear programming to select a subset of candidate\nclusters to cover most samples while minimizing overlaps. Under both automatic\nand human evaluation on corpora with or without labels, our method produces\nmore accurate and goal-related explanations than prior methods. We release our\ndata and implementation at https://github.com/ZihanWangKi/GoalEx.", "published": "2023-05-23 07:05:50", "link": "http://arxiv.org/abs/2305.13749v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Challenges in Context-Aware Neural Machine Translation", "abstract": "Context-aware neural machine translation involves leveraging information\nbeyond sentence-level context to resolve inter-sentential discourse\ndependencies and improve document-level translation quality, and has given rise\nto a number of recent techniques. However, despite well-reasoned intuitions,\nmost context-aware translation models show only modest improvements over\nsentence-level systems. In this work, we investigate several challenges that\nimpede progress within this field, relating to discourse phenomena, context\nusage, model architectures, and document-level evaluation. To address these\nproblems, we propose a more realistic setting for document-level translation,\ncalled paragraph-to-paragraph (para2para) translation, and collect a new\ndataset of Chinese-English novels to promote future research.", "published": "2023-05-23 07:08:18", "link": "http://arxiv.org/abs/2305.13751v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Images in Language Space: Exploring the Suitability of Large Language\n  Models for Vision & Language Tasks", "abstract": "Large language models have demonstrated robust performance on various\nlanguage tasks using zero-shot or few-shot learning paradigms. While being\nactively researched, multimodal models that can additionally handle images as\ninput have yet to catch up in size and generality with language-only models. In\nthis work, we ask whether language-only models can be utilised for tasks that\nrequire visual input -- but also, as we argue, often require a strong reasoning\ncomponent. Similar to some recent related work, we make visual information\naccessible to the language model using separate verbalisation models.\nSpecifically, we investigate the performance of open-source, open-access\nlanguage models against GPT-3 on five vision-language tasks when given\ntextually-encoded visual information. Our results suggest that language models\nare effective for solving vision-language tasks even with limited samples. This\napproach also enhances the interpretability of a model's output by providing a\nmeans of tracing the output back through the verbalised image content.", "published": "2023-05-23 07:50:36", "link": "http://arxiv.org/abs/2305.13782v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data\n  Augmentation", "abstract": "Training or finetuning large-scale language models (LLMs) such as GPT-3\nrequires substantial computation resources, motivating recent efforts to\nexplore parameter-efficient adaptation to downstream tasks. One practical area\nof research is to treat these models as black boxes and interact with them\nthrough their inference APIs. In this paper, we investigate how to optimize\nfew-shot text classification without accessing the gradients of the LLMs. To\nachieve this, we treat the black-box model as a feature extractor and train a\nclassifier with the augmented text data. Data augmentation is performed using\nprompt-based finetuning on an auxiliary language model with a much smaller\nparameter size than the black-box model. Through extensive experiments on eight\ntext classification datasets, we show that our approach, dubbed BT-Classifier,\nsignificantly outperforms state-of-the-art black-box few-shot learners and\nperforms on par with methods that rely on full-model tuning.", "published": "2023-05-23 07:54:34", "link": "http://arxiv.org/abs/2305.13785v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Zero-shot Relation Extraction in Web Mining: A Multimodal\n  Approach with Relative XML Path", "abstract": "The rapid growth of web pages and the increasing complexity of their\nstructure poses a challenge for web mining models. Web mining models are\nrequired to understand the semi-structured web pages, particularly when little\nis known about the subject or template of a new page. Current methods migrate\nlanguage models to the web mining by embedding the XML source code into the\ntransformer or encoding the rendered layout with graph neural networks.\nHowever, these approaches do not take into account the relationships between\ntext nodes within and across pages. In this paper, we propose a new approach,\nReXMiner, for zero-shot relation extraction in web mining. ReXMiner encodes the\nshortest relative paths in the Document Object Model (DOM) tree which is a more\naccurate and efficient signal for key-value pair extraction within a web page.\nIt also incorporates the popularity of each text node by counting the\noccurrence of the same text node across different web pages. We use the\ncontrastive learning to address the issue of sparsity in relation extraction.\nExtensive experiments on public benchmarks show that our method, ReXMiner,\noutperforms the state-of-the-art baselines in the task of zero-shot relation\nextraction in web mining.", "published": "2023-05-23 08:16:52", "link": "http://arxiv.org/abs/2305.13805v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Asking Clarification Questions to Handle Ambiguity in Open-Domain QA", "abstract": "Ambiguous questions persist in open-domain question answering, because\nformulating a precise question with a unique answer is often challenging.\nPreviously, Min et al. (2020) have tackled this issue by generating\ndisambiguated questions for all possible interpretations of the ambiguous\nquestion. This can be effective, but not ideal for providing an answer to the\nuser. Instead, we propose to ask a clarification question, where the user's\nresponse will help identify the interpretation that best aligns with the user's\nintention. We first present CAMBIGNQ, a dataset consisting of 5,654 ambiguous\nquestions, each with relevant passages, possible answers, and a clarification\nquestion. The clarification questions were efficiently created by generating\nthem using InstructGPT and manually revising them as necessary. We then define\na pipeline of tasks and design appropriate evaluation metrics. Lastly, we\nachieve 61.3 F1 on ambiguity detection and 40.5 F1 on clarification-based QA,\nproviding strong baselines for future work.", "published": "2023-05-23 08:20:01", "link": "http://arxiv.org/abs/2305.13808v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting automatically the layout of clinical documents to enhance the\n  performances of downstream natural language processing", "abstract": "Objective:Develop and validate an algorithm for analyzing the layout of PDF\nclinical documents to improve the performance of downstream natural language\nprocessing tasks. Materials and Methods: We designed an algorithm to process\nclinical PDF documents and extract only clinically relevant text. The algorithm\nconsists of several steps: initial text extraction using a PDF parser, followed\nby classification into categories such as body text, left notes, and footers\nusing a Transformer deep neural network architecture, and finally an\naggregation step to compile the lines of a given label in the text. We\nevaluated the technical performance of the body text extraction algorithm by\napplying it to a random sample of documents that were annotated. Medical\nperformance was evaluated by examining the extraction of medical concepts of\ninterest from the text in their respective sections. Finally, we tested an\nend-to-end system on a medical use case of automatic detection of acute\ninfection described in the hospital report. Results:Our algorithm achieved\nper-line precision, recall, and F1 score of 98.4, 97.0, and 97.7, respectively,\nfor body line extraction. The precision, recall, and F1 score per document for\nthe acute infection detection algorithm were 82.54 (95CI 72.86-91.60), 85.24\n(95CI 76.61-93.70), 83.87 (95CI 76, 92-90.08) with exploitation of the results\nof the advanced body extraction algorithm, respectively. Conclusion:We have\ndeveloped and validated a system for extracting body text from clinical\ndocuments in PDF format by identifying their layout. We were able to\ndemonstrate that this preprocessing allowed us to obtain better performances\nfor a common downstream task, i.e., the extraction of medical concepts in their\nrespective sections, thus proving the interest of this method on a clinical use\ncase.", "published": "2023-05-23 08:38:33", "link": "http://arxiv.org/abs/2305.13817v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Open Dataset and Model for Language Identification", "abstract": "Language identification (LID) is a fundamental step in many natural language\nprocessing pipelines. However, current LID systems are far from perfect,\nparticularly on lower-resource languages. We present a LID model which achieves\na macro-average F1 score of 0.93 and a false positive rate of 0.033 across 201\nlanguages, outperforming previous work. We achieve this by training on a\ncurated dataset of monolingual data, the reliability of which we ensure by\nauditing a sample from each source and each language manually. We make both the\nmodel and the dataset available to the research community. Finally, we carry\nout detailed analysis into our model's performance, both in comparison to\nexisting open models and by language class.", "published": "2023-05-23 08:43:42", "link": "http://arxiv.org/abs/2305.13820v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"Is the Pope Catholic?\" Applying Chain-of-Thought Reasoning to\n  Understanding Conversational Implicatures", "abstract": "Conversational implicatures are pragmatic inferences that require listeners\nto deduce the intended meaning conveyed by a speaker from their explicit\nutterances. Although such inferential reasoning is fundamental to human\ncommunication, recent research indicates that large language models struggle to\ncomprehend these implicatures as effectively as the average human. This paper\ndemonstrates that by incorporating Grice's Four Maxims into the model through\nchain-of-thought prompting, we can significantly enhance its performance,\nsurpassing even the average human performance on this task.", "published": "2023-05-23 08:49:50", "link": "http://arxiv.org/abs/2305.13826v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from Mistakes via Cooperative Study Assistant for Large\n  Language Models", "abstract": "Large language models (LLMs) have demonstrated their potential to refine\ntheir generation based on their own feedback. However, the feedback from LLM\nitself is often inaccurate, thereby limiting its benefits. In this paper, we\npropose Study Assistant for Large LAnguage Model (SALAM), a novel framework\nwith an auxiliary agent to assist the main LLM in learning from mistakes\nthrough interactive cooperation. In the gathering phase, the student assistant\nagent probes the main LLM, analyzes its errors, and collects the interaction in\na mistake memory. During the examination phase, the study assistant provides\nguidelines by retrieving relevant cases to help the main LLM anticipate and\navoid similar errors. We first investigate the effectiveness of a general study\nassistant and then customize it to provide LLM-specific guidance through\nimitation learning from successful guidance experiences. Our experiments on\nthree LLMs using two challenging frameworks demonstrate that SALAM can\nsignificantly boost LLMs by an accuracy margin of up to 6.6 on BBH and 12.6 on\nBBQ.", "published": "2023-05-23 08:51:08", "link": "http://arxiv.org/abs/2305.13829v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reducing Sensitivity on Speaker Names for Text Generation from Dialogues", "abstract": "Changing speaker names consistently throughout a dialogue should not affect\nits meaning and corresponding outputs for text generation from dialogues.\nHowever, pre-trained language models, serving as the backbone for\ndialogue-processing tasks, have shown to be sensitive to nuances. This may\nresult in unfairness in real-world applications. No comprehensive analysis of\nthis problem has been done in the past. In this work, we propose to\nquantitatively measure a model's sensitivity on speaker names, and\ncomprehensively evaluate a number of known methods for reducing speaker name\nsensitivity, including a novel approach of our own. Extensive experiments on\nmultiple datasets provide a benchmark for this problem and show the favorable\nperformance of our approach in sensitivity reduction and quality of generation.", "published": "2023-05-23 08:53:33", "link": "http://arxiv.org/abs/2305.13833v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Arukikata Travelogue Dataset with Geographic Entity Mention,\n  Coreference, and Link Annotation", "abstract": "Geoparsing is a fundamental technique for analyzing geo-entity information in\ntext. We focus on document-level geoparsing, which considers geographic\nrelatedness among geo-entity mentions, and presents a Japanese travelogue\ndataset designed for evaluating document-level geoparsing systems. Our dataset\ncomprises 200 travelogue documents with rich geo-entity information: 12,171\nmentions, 6,339 coreference clusters, and 2,551 geo-entities linked to\ngeo-database entries.", "published": "2023-05-23 09:07:42", "link": "http://arxiv.org/abs/2305.13844v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revealing User Familiarity Bias in Task-Oriented Dialogue via\n  Interactive Evaluation", "abstract": "Most task-oriented dialogue (TOD) benchmarks assume users that know exactly\nhow to use the system by constraining the user behaviors within the system's\ncapabilities via strict user goals, namely \"user familiarity\" bias. This data\nbias deepens when it combines with data-driven TOD systems, as it is impossible\nto fathom the effect of it with existing static evaluations. Hence, we conduct\nan interactive user study to unveil how vulnerable TOD systems are against\nrealistic scenarios. In particular, we compare users with 1) detailed goal\ninstructions that conform to the system boundaries (closed-goal) and 2) vague\ngoal instructions that are often unsupported but realistic (open-goal). Our\nstudy reveals that conversations in open-goal settings lead to catastrophic\nfailures of the system, in which 92% of the dialogues had significant issues.\nMoreover, we conduct a thorough analysis to identify distinctive features\nbetween the two settings through error annotation. From this, we discover a\nnovel \"pretending\" behavior, in which the system pretends to handle the user\nrequests even though they are beyond the system's capabilities. We discuss its\ncharacteristics and toxicity while showing recent large language models can\nalso suffer from this behavior.", "published": "2023-05-23 09:24:53", "link": "http://arxiv.org/abs/2305.13857v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Trip Towards Fairness: Bias and De-Biasing in Large Language Models", "abstract": "Cheap-to-Build Very Large-Language Models (CtB-LLMs) with affordable training\nare emerging as the next big revolution in natural language processing and\nunderstanding. These CtB-LLMs are democratizing access to trainable Very\nLarge-Language Models (VLLMs) and, thus, may represent the building blocks of\nmany NLP systems solving downstream tasks. Hence, a little or a large bias in\nCtB-LLMs may cause huge harm. In this paper, we performed a large investigation\nof the bias of three families of CtB-LLMs, and we showed that debiasing\ntechniques are effective and usable. Indeed, according to current tests, the\nLLaMA and the OPT families have an important bias in gender, race, religion,\nand profession. In contrast to the analysis for other LLMs, we discovered that\nbias depends not on the number of parameters but on the perplexity. Finally,\nthe debiasing of OPT using LoRA reduces bias up to 4.12 points in the\nnormalized stereotype score.", "published": "2023-05-23 09:35:37", "link": "http://arxiv.org/abs/2305.13862v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing Brain Context-Sensitivity with Masked-Attention Generation", "abstract": "Two fundamental questions in neurolinguistics concerns the brain regions that\nintegrate information beyond the lexical level, and the size of their window of\nintegration. To address these questions we introduce a new approach named\nmasked-attention generation. It uses GPT-2 transformers to generate word\nembeddings that capture a fixed amount of contextual information. We then\ntested whether these embeddings could predict fMRI brain activity in humans\nlistening to naturalistic text. The results showed that most of the cortex\nwithin the language network is sensitive to contextual information, and that\nthe right hemisphere is more sensitive to longer contexts than the left.\nMasked-attention generation supports previous analyses of context-sensitivity\nin the brain, and complements them by quantifying the window size of context\nintegration per voxel.", "published": "2023-05-23 09:36:21", "link": "http://arxiv.org/abs/2305.13863v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PaD: Program-aided Distillation Can Teach Small Models Reasoning Better\n  than Chain-of-thought Fine-tuning", "abstract": "While large language models (LLMs) excel in various natural language\nprocessing tasks, their huge size and the inaccessibility of parameters present\nchallenges for practical deployment. Previous studies try to distill\ntask-specific ability from LLMs to smaller models, using data synthesis and\nchain-of-thought (CoT) fine-tuning. However, synthetic CoT data often contains\nfaulty reasoning, which deteriorates the quality of distillation, especially in\nreasoning capabilities. In this work, we propose Program-aided Distillation\n(PaD), which introduces reasoning programs to suppress the errors in distilled\ndata, and thus achieves better distillation quality for reasoning tasks. In\nPaD, we utilize the reasoning program to substitute the CoT, allowing automated\nerror checking of synthetic data. Further, through error injecting and further\ntraining, the small distilling model could iteratively self-refine the\nreasoning. Moreover, we conduct a step-wise beam search by step-by-step\nverifying to acquire more exact reasoning chains. We evaluate PaD on arithmetic\nreasoning, symbolic reasoning, and general ability. Experimental results\ndemonstrate that smaller models using PaD can not only outperform certain\nLLMs~(e.g., LLaMA-1 13B) but also achieve strong improvement over baselines\nwith a significantly smaller scale of parameters and data. The source code is\npublicly available at https://github.com/Xuekai-Zhu/pad.", "published": "2023-05-23 10:11:56", "link": "http://arxiv.org/abs/2305.13888v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Acquiring Frame Element Knowledge with Deep Metric Learning for Semantic\n  Frame Induction", "abstract": "The semantic frame induction tasks are defined as a clustering of words into\nthe frames that they evoke, and a clustering of their arguments according to\nthe frame element roles that they should fill. In this paper, we address the\nlatter task of argument clustering, which aims to acquire frame element\nknowledge, and propose a method that applies deep metric learning. In this\nmethod, a pre-trained language model is fine-tuned to be suitable for\ndistinguishing frame element roles through the use of frame-annotated data, and\nargument clustering is performed with embeddings obtained from the fine-tuned\nmodel. Experimental results on FrameNet demonstrate that our method achieves\nsubstantially better performance than existing methods.", "published": "2023-05-23 11:02:28", "link": "http://arxiv.org/abs/2305.13944v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Make a Choice! Knowledge Base Question Answering with In-Context\n  Learning", "abstract": "Question answering over knowledge bases (KBQA) aims to answer factoid\nquestions with a given knowledge base (KB). Due to the large scale of KB,\nannotated data is impossible to cover all fact schemas in KB, which poses a\nchallenge to the generalization ability of methods that require a sufficient\namount of annotated data. Recently, LLMs have shown strong few-shot performance\nin many NLP tasks. We expect LLM can help existing methods improve their\ngeneralization ability, especially in low-resource situations. In this paper,\nwe present McL-KBQA, a framework that incorporates the few-shot ability of LLM\ninto the KBQA method via ICL-based multiple choice and then improves the\neffectiveness of the QA tasks. Experimental results on two KBQA datasets\ndemonstrate the competitive performance of McL-KBQA with strong improvements in\ngeneralization. We expect to explore a new way to QA tasks from KBQA in\nconjunction with LLM, how to generate answers normatively and correctly with\nstrong generalization.", "published": "2023-05-23 11:56:03", "link": "http://arxiv.org/abs/2305.13972v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Effortless Integration of Memory Management into Open-Domain\n  Conversation Systems", "abstract": "Open-domain conversation systems integrate multiple conversation skills into\na single system through a modular approach. One of the limitations of the\nsystem, however, is the absence of management capability for external memory.\nIn this paper, we propose a simple method to improve BlenderBot3 by integrating\nmemory management ability into it. Since no training data exists for this\npurpose, we propose an automating dataset creation for memory management. Our\nmethod 1) requires little cost for data construction, 2) does not affect\nperformance in other tasks, and 3) reduces external memory. We show that our\nproposed model BlenderBot3-M^3, which is multi-task trained with memory\nmanagement, outperforms BlenderBot3 with a relative 4% performance gain in\nterms of F1 score.", "published": "2023-05-23 11:56:17", "link": "http://arxiv.org/abs/2305.13973v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MasakhaPOS: Part-of-Speech Tagging for Typologically Diverse African\n  Languages", "abstract": "In this paper, we present MasakhaPOS, the largest part-of-speech (POS)\ndataset for 20 typologically diverse African languages. We discuss the\nchallenges in annotating POS for these languages using the UD (universal\ndependencies) guidelines. We conducted extensive POS baseline experiments using\nconditional random field and several multilingual pre-trained language models.\nWe applied various cross-lingual transfer models trained with data available in\nUD. Evaluating on the MasakhaPOS dataset, we show that choosing the best\ntransfer language(s) in both single-source and multi-source setups greatly\nimproves the POS tagging performance of the target languages, in particular\nwhen combined with cross-lingual parameter-efficient fine-tuning methods.\nCrucially, transferring knowledge from a language that matches the language\nfamily and morphosyntactic properties seems more effective for POS tagging in\nunseen languages.", "published": "2023-05-23 12:15:33", "link": "http://arxiv.org/abs/2305.13989v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Condensing Multilingual Knowledge with Lightweight Language-Specific\n  Modules", "abstract": "Incorporating language-specific (LS) modules is a proven method to boost\nperformance in multilingual machine translation. This approach bears similarity\nto Mixture-of-Experts (MoE) because it does not inflate FLOPs. However, the\nscalability of this approach to hundreds of languages (experts) tends to be\nunmanageable due to the prohibitive number of parameters introduced by\nfull-rank matrices in fully-connected layers. In this work, we introduce the\nLanguage-Specific Matrix Synthesis (LMS) method. This approach constructs LS\nmodules by generating low-rank matrices from two significantly smaller matrices\nto approximate the full-rank matrix. Furthermore, we condense multilingual\nknowledge from multiple LS modules into a single shared module with the Fuse\nDistillation (FD) technique to improve the efficiency of inference and model\nserialization. We show that our LMS method significantly outperforms previous\nLS methods and MoE methods with the same amount of extra parameters, e.g., 1.73\nBLEU points over the Switch Transformer on many-to-many multilingual machine\ntranslation. Importantly, LMS is able to have comparable translation\nperformance with much fewer parameters.", "published": "2023-05-23 12:21:38", "link": "http://arxiv.org/abs/2305.13993v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Language Models via Plug-and-Play Retrieval Feedback", "abstract": "Large language models (LLMs) exhibit remarkable performance across various\nNLP tasks. However, they often generate incorrect or hallucinated information,\nwhich hinders their practical applicability in real-world scenarios. Human\nfeedback has been shown to effectively enhance the factuality and quality of\ngenerated content, addressing some of these limitations. However, this approach\nis resource-intensive, involving manual input and supervision, which can be\ntime-consuming and expensive. Moreover, it cannot be provided during inference,\nfurther limiting its practical utility in dynamic and interactive applications.\nIn this paper, we introduce ReFeed, a novel pipeline designed to enhance LLMs\nby providing automatic retrieval feedback in a plug-and-play framework without\nthe need for expensive fine-tuning. ReFeed first generates initial outputs,\nthen utilizes a retrieval model to acquire relevant information from large\ndocument collections, and finally incorporates the retrieved information into\nthe in-context demonstration for output refinement, thereby addressing the\nlimitations of LLMs in a more efficient and cost-effective manner. Experiments\non four knowledge-intensive benchmark datasets demonstrate our proposed ReFeed\ncould improve over +6.0% under zero-shot setting and +2.5% under few-shot\nsetting, compared to baselines without using retrieval feedback.", "published": "2023-05-23 12:29:44", "link": "http://arxiv.org/abs/2305.14002v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "S\u0101mayik: A Benchmark and Dataset for English-Sanskrit Translation", "abstract": "We release S\\={a}mayik, a dataset of around 53,000 parallel English-Sanskrit\nsentences, written in contemporary prose. Sanskrit is a classical language\nstill in sustenance and has a rich documented heritage. However, due to the\nlimited availability of digitized content, it still remains a low-resource\nlanguage. Existing Sanskrit corpora, whether monolingual or bilingual, have\npredominantly focused on poetry and offer limited coverage of contemporary\nwritten materials. S\\={a}mayik is curated from a diverse range of domains,\nincluding language instruction material, textual teaching pedagogy, and online\ntutorials, among others. It stands out as a unique resource that specifically\ncaters to the contemporary usage of Sanskrit, with a primary emphasis on prose\nwriting. Translation models trained on our dataset demonstrate statistically\nsignificant improvements when translating out-of-domain contemporary corpora,\noutperforming models trained on older classical-era poetry datasets. Finally,\nwe also release benchmark models by adapting four multilingual pre-trained\nmodels, three of them have not been previously exposed to Sanskrit for\ntranslating between English and Sanskrit while one of them is multi-lingual\npre-trained translation model including English and Sanskrit. The dataset and\nsource code is present at https://github.com/ayushbits/saamayik.", "published": "2023-05-23 12:32:24", "link": "http://arxiv.org/abs/2305.14004v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Granularity Prompts for Topic Shift Detection in Dialogue", "abstract": "The goal of dialogue topic shift detection is to identify whether the current\ntopic in a conversation has changed or needs to change. Previous work focused\non detecting topic shifts using pre-trained models to encode the utterance,\nfailing to delve into the various levels of topic granularity in the dialogue\nand understand dialogue contents. To address the above issues, we take a\nprompt-based approach to fully extract topic information from dialogues at\nmultiple-granularity, i.e., label, turn, and topic. Experimental results on our\nannotated Chinese Natural Topic Dialogue dataset CNTD and the publicly\navailable English TIAGE dataset show that the proposed model outperforms the\nbaselines. Further experiments show that the information extracted at different\nlevels of granularity effectively helps the model comprehend the conversation\ntopics.", "published": "2023-05-23 12:35:49", "link": "http://arxiv.org/abs/2305.14006v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Does Aggregating Multiple Skills with Multi-Task Learning Work? A\n  Case Study in Financial NLP", "abstract": "Multi-task learning (MTL) aims at achieving a better model by leveraging data\nand knowledge from multiple tasks. However, MTL does not always work --\nsometimes negative transfer occurs between tasks, especially when aggregating\nloosely related skills, leaving it an open question when MTL works. Previous\nstudies show that MTL performance can be improved by algorithmic tricks.\nHowever, what tasks and skills should be included is less well explored. In\nthis work, we conduct a case study in Financial NLP where multiple datasets\nexist for skills relevant to the domain, such as numeric reasoning and\nsentiment analysis. Due to the task difficulty and data scarcity in the\nFinancial NLP domain, we explore when aggregating such diverse skills from\nmultiple datasets with MTL can work. Our findings suggest that the key to MTL\nsuccess lies in skill diversity, relatedness between tasks, and choice of\naggregation size and shared capacity. Specifically, MTL works well when tasks\nare diverse but related, and when the size of the task aggregation and the\nshared capacity of the model are balanced to avoid overwhelming certain tasks.", "published": "2023-05-23 12:37:14", "link": "http://arxiv.org/abs/2305.14007v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IfQA: A Dataset for Open-domain Question Answering under Counterfactual\n  Presuppositions", "abstract": "Although counterfactual reasoning is a fundamental aspect of intelligence,\nthe lack of large-scale counterfactual open-domain question-answering (QA)\nbenchmarks makes it difficult to evaluate and improve models on this ability.\nTo address this void, we introduce the first such dataset, named IfQA, where\neach question is based on a counterfactual presupposition via an \"if\" clause.\nFor example, if Los Angeles was on the east coast of the U.S., what would be\nthe time difference between Los Angeles and Paris? Such questions require\nmodels to go beyond retrieving direct factual knowledge from the Web: they must\nidentify the right information to retrieve and reason about an imagined\nsituation that may even go against the facts built into their parameters. The\nIfQA dataset contains over 3,800 questions that were annotated annotated by\ncrowdworkers on relevant Wikipedia passages. Empirical analysis reveals that\nthe IfQA dataset is highly challenging for existing open-domain QA methods,\nincluding supervised retrieve-then-read pipeline methods (EM score 36.2), as\nwell as recent few-shot approaches such as chain-of-thought prompting with\nGPT-3 (EM score 27.4). The unique challenges posed by the IfQA benchmark will\npush open-domain QA research on both retrieval and counterfactual reasoning\nfronts.", "published": "2023-05-23 12:43:19", "link": "http://arxiv.org/abs/2305.14010v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When your Cousin has the Right Connections: Unsupervised Bilingual\n  Lexicon Induction for Related Data-Imbalanced Languages", "abstract": "Most existing approaches for unsupervised bilingual lexicon induction (BLI)\ndepend on good quality static or contextual embeddings requiring large\nmonolingual corpora for both languages. However, unsupervised BLI is most\nlikely to be useful for low-resource languages (LRLs), where large datasets are\nnot available. Often we are interested in building bilingual resources for LRLs\nagainst related high-resource languages (HRLs), resulting in severely\nimbalanced data settings for BLI. We first show that state-of-the-art BLI\nmethods in the literature exhibit near-zero performance for severely\ndata-imbalanced language pairs, indicating that these settings require more\nrobust techniques. We then present a new method for unsupervised BLI between a\nrelated LRL and HRL that only requires inference on a masked language model of\nthe HRL, and demonstrate its effectiveness on truly low-resource languages\nBhojpuri and Magahi (with <5M monolingual tokens each), against Hindi. We\nfurther present experiments on (mid-resource) Marathi and Nepali to compare\napproach performances by resource range, and release our resulting lexicons for\nfive low-resource Indic languages: Bhojpuri, Magahi, Awadhi, Braj, and\nMaithili, against Hindi.", "published": "2023-05-23 12:49:21", "link": "http://arxiv.org/abs/2305.14012v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Target-Agnostic Gender-Aware Contrastive Learning for Mitigating Bias in\n  Multilingual Machine Translation", "abstract": "Gender bias is a significant issue in machine translation, leading to ongoing\nresearch efforts in developing bias mitigation techniques. However, most works\nfocus on debiasing bilingual models without much consideration for multilingual\nsystems. In this paper, we specifically target the gender bias issue of\nmultilingual machine translation models for unambiguous cases where there is a\nsingle correct translation, and propose a bias mitigation method based on a\nnovel approach. Specifically, we propose Gender-Aware Contrastive Learning,\nGACL, which encodes contextual gender information into the representations of\nnon-explicit gender words. Our method is target language-agnostic and is\napplicable to pre-trained multilingual machine translation models via\nfine-tuning. Through multilingual evaluation, we show that our approach\nimproves gender accuracy by a wide margin without hampering translation\nperformance. We also observe that incorporated gender information transfers and\nbenefits other target languages regarding gender accuracy. Finally, we\ndemonstrate that our method is applicable and beneficial to models of various\nsizes.", "published": "2023-05-23 12:53:39", "link": "http://arxiv.org/abs/2305.14016v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Process-To-Text: A Framework for the Quantitative Description of\n  Processes in Natural Language", "abstract": "In this paper we present the Process-To-Text (P2T) framework for the\nautomatic generation of textual descriptive explanations of processes. P2T\nintegrates three AI paradigms: process mining for extracting temporal and\nstructural information from a process, fuzzy linguistic protoforms for\nmodelling uncertain terms, and natural language generation for building the\nexplanations. A real use-case in the cardiology domain is presented, showing\nthe potential of P2T for providing natural language explanations addressed to\nspecialists.", "published": "2023-05-23 13:14:34", "link": "http://arxiv.org/abs/2305.14044v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "One-stop Training of Multiple Capacity Models", "abstract": "Training models with varying capacities can be advantageous for deploying\nthem in different scenarios. While high-capacity models offer better\nperformance, low-capacity models require fewer computing resources for training\nand inference. In this work, we propose a novel one-stop training framework to\njointly train high-capacity and low-capactiy models. This framework consists of\ntwo composite model architectures and a joint training algorithm called\nTwo-Stage Joint-Training (TSJT). Unlike knowledge distillation, where multiple\ncapacity models are trained from scratch separately, our approach integrates\nsupervisions from different capacity models simultaneously, leading to faster\nand more efficient convergence. Extensive experiments on the multilingual\nmachine translation benchmark WMT10 show that our method outperforms\nlow-capacity baseline models and achieves comparable or better performance on\nhigh-capacity models. Notably, the analysis demonstrates that our method\nsignificantly influences the initial training process, leading to more\nefficient convergence and superior solutions.", "published": "2023-05-23 13:44:09", "link": "http://arxiv.org/abs/2305.14066v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Factual Consistency of Summaries with Large Language Models", "abstract": "Detecting factual errors in summaries has been an important and challenging\nsubject in summarization research. Inspired by the emergent ability of large\nlanguage models (LLMs), we explore evaluating factual consistency of summaries\nby directly prompting LLMs. We present a comprehensive empirical study to\nassess the ability of LLMs as factual consistency evaluators, which consists of\n(1) analyzing different LLMs such as the GPT model series and Flan-T5; (2)\ninvestigating a variety of prompting methods including vanilla prompting,\nchain-of-thought prompting, and a sentence-by-sentence prompting method to\ntackle long summaries; and (3) evaluating on diverse summaries generated by\nmultiple summarization systems, ranging from pre-transformer methods to SOTA\npretrained models. Our experiments demonstrate that prompting LLMs is able to\noutperform the previous best factuality systems in all settings, by up to 12.2\nabsolute points in terms of the binary classification accuracy on inconsistency\ndetection.", "published": "2023-05-23 13:48:32", "link": "http://arxiv.org/abs/2305.14069v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing Linguistic Generalisation in Language Models: A Dataset for\n  Brazilian Portuguese", "abstract": "Much recent effort has been devoted to creating large-scale language models.\nNowadays, the most prominent approaches are based on deep neural networks, such\nas BERT. However, they lack transparency and interpretability, and are often\nseen as black boxes. This affects not only their applicability in downstream\ntasks but also the comparability of different architectures or even of the same\nmodel trained using different corpora or hyperparameters. In this paper, we\npropose a set of intrinsic evaluation tasks that inspect the linguistic\ninformation encoded in models developed for Brazilian Portuguese. These tasks\nare designed to evaluate how different language models generalise information\nrelated to grammatical structures and multiword expressions (MWEs), thus\nallowing for an assessment of whether the model has learned different\nlinguistic phenomena. The dataset that was developed for these tasks is\ncomposed of a series of sentences with a single masked word and a cue phrase\nthat helps in narrowing down the context. This dataset is divided into MWEs and\ngrammatical structures, and the latter is subdivided into 6 tasks: impersonal\nverbs, subject agreement, verb agreement, nominal agreement, passive and\nconnectors. The subset for MWEs was used to test BERTimbau Large, BERTimbau\nBase and mBERT. For the grammatical structures, we used only BERTimbau Large,\nbecause it yielded the best results in the MWE task.", "published": "2023-05-23 13:49:14", "link": "http://arxiv.org/abs/2305.14070v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How to Solve Few-Shot Abusive Content Detection Using the Data We\n  Actually Have", "abstract": "Due to the broad range of social media platforms, the requirements of abusive\nlanguage detection systems are varied and ever-changing. Already a large set of\nannotated corpora with different properties and label sets were created, such\nas hate or misogyny detection, but the form and targets of abusive speech are\nconstantly evolving. Since, the annotation of new corpora is expensive, in this\nwork we leverage datasets we already have, covering a wide range of tasks\nrelated to abusive language detection. Our goal is to build models cheaply for\na new target label set and/or language, using only a few training examples of\nthe target domain. We propose a two-step approach: first we train our model in\na multitask fashion. We then carry out few-shot adaptation to the target\nrequirements. Our experiments show that using already existing datasets and\nonly a few-shots of the target task the performance of models improve both\nmonolingually and across languages. Our analysis also shows that our models\nacquire a general understanding of abusive language, since they improve the\nprediction of labels which are present only in the target dataset and can\nbenefit from knowledge about labels which are not directly used for the target\ntask.", "published": "2023-05-23 14:04:12", "link": "http://arxiv.org/abs/2305.14081v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Does Monolingual Data Help Multilingual Translation: The Role of\n  Domain and Model Scale", "abstract": "Multilingual machine translation (MMT), trained on a mixture of parallel and\nmonolingual data, is key for improving translation in low-resource language\npairs. However, the literature offers conflicting results on the performance of\ndifferent methods of including monolingual data. To resolve this, we examine\nhow denoising autoencoding (DAE) and backtranslation (BT) impact MMT under\ndifferent data conditions and model scales. Unlike prior studies, we use a\nrealistic dataset of 100 translation directions and consider many domain\ncombinations of monolingual and test data. We find that monolingual data\ngenerally helps MMT, but models are surprisingly brittle to domain mismatches,\nespecially at smaller model scales. BT is beneficial when the parallel,\nmonolingual, and test data sources are similar but can be detrimental\notherwise, while DAE is less effective than previously reported. Next, we\nanalyze the impact of scale (from 90M to 1.6B parameters) and find it is\nimportant for both methods, particularly DAE. As scale increases, DAE\ntransitions from underperforming the parallel-only baseline at 90M to\nconverging with BT performance at 1.6B, and even surpassing it in low-resource.\nThese results offer new insights into how to best use monolingual data in MMT.", "published": "2023-05-23 14:48:42", "link": "http://arxiv.org/abs/2305.14124v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "In-Context Probing: Toward Building Robust Classifiers via Probing Large\n  Language Models", "abstract": "Large language models are able to learn new tasks in context, where they are\nprovided with instructions and a few annotated examples. However, the\neffectiveness of in-context learning is dependent on the provided context, and\nthe performance on a downstream task can vary considerably, depending on the\ninstruction. Importantly, such dependency on the context can surface in\nunpredictable ways, e.g., a seemingly more informative instruction might lead\nto a worse performance. In this paper, we propose an alternative approach,\nwhich we term In-Context Probing (ICP). Similar to in-context learning, we\ncontextualize the representation of the input with an instruction, but instead\nof decoding the output prediction, we probe the contextualized representation\nto predict the label. Through a series of experiments on a diverse set of\nclassification tasks, we show that in-context probing is significantly more\nrobust to changes in instructions. We further show that ICP performs\ncompetitive or superior to finetuning and can be particularly helpful to build\nclassifiers on top of smaller models, with less than a hundred training\nexamples.", "published": "2023-05-23 15:43:04", "link": "http://arxiv.org/abs/2305.14171v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-tuned LLMs Know More, Hallucinate Less with Few-Shot\n  Sequence-to-Sequence Semantic Parsing over Wikidata", "abstract": "While large language models (LLMs) can answer many questions correctly, they\ncan also hallucinate and give wrong answers. Wikidata, with its over 12 billion\nfacts, can be used to ground LLMs to improve their factuality. This paper\npresents WikiWebQuestions, a high-quality question answering benchmark for\nWikidata. Ported over from WebQuestions for Freebase, it consists of real-world\ndata with SPARQL annotation. This paper presents a few-shot\nsequence-to-sequence semantic parser for Wikidata. We modify SPARQL to use the\nunique domain and property names instead of their IDs. We train the parser to\nuse either the results from an entity linker or mentions in the query. We\nfine-tune LLaMA by adding the few-shot training data to that used to fine-tune\nAlpaca. Our experimental results demonstrate the effectiveness of this\nmethodology, establishing a strong baseline of 76% and 65% answer accuracy in\nthe dev and test sets of WikiWebQuestions, respectively. By pairing our\nsemantic parser with GPT-3, we combine verifiable results with qualified GPT-3\nguesses to provide useful answers to 96% of the questions in dev. We also show\nthat our method outperforms the state-of-the-art for the QALD-7 Wikidata\ndataset by 3.6% in F1 score.", "published": "2023-05-23 16:20:43", "link": "http://arxiv.org/abs/2305.14202v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "$\u03bc$PLAN: Summarizing using a Content Plan as Cross-Lingual Bridge", "abstract": "Cross-lingual summarization consists of generating a summary in one language\ngiven an input document in a different language, allowing for the dissemination\nof relevant content across speakers of other languages. The task is challenging\nmainly due to the paucity of cross-lingual datasets and the compounded\ndifficulty of summarizing and translating. This work presents $\\mu$PLAN, an\napproach to cross-lingual summarization that uses an intermediate planning step\nas a cross-lingual bridge. We formulate the plan as a sequence of entities\ncapturing the summary's content and the order in which it should be\ncommunicated. Importantly, our plans abstract from surface form: using a\nmultilingual knowledge base, we align entities to their canonical designation\nacross languages and generate the summary conditioned on this cross-lingual\nbridge and the input. Automatic and human evaluation on the XWikis dataset\n(across four language pairs) demonstrates that our planning objective achieves\nstate-of-the-art performance in terms of informativeness and faithfulness.\nMoreover, $\\mu$PLAN models improve the zero-shot transfer to new cross-lingual\nlanguage pairs compared to baselines without a planning component.", "published": "2023-05-23 16:25:21", "link": "http://arxiv.org/abs/2305.14205v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Graph-hop Retrieval and Reasoning in Complex Question Answering\n  over Textual Database", "abstract": "In Textual question answering (TQA) systems, complex questions often require\nretrieving multiple textual fact chains with multiple reasoning steps. While\nexisting benchmarks are limited to single-chain or single-hop retrieval\nscenarios. In this paper, we propose to conduct Graph-Hop -- a novel\nmulti-chains and multi-hops retrieval and reasoning paradigm in complex\nquestion answering. We construct a new benchmark called ReasonGraphQA, which\nprovides explicit and fine-grained evidence graphs for complex questions to\nsupport interpretable reasoning, comprehensive and detailed reasoning. And\nReasonGraphQA also shows an advantage in reasoning diversity and scale.\nMoreover, We propose a strong graph-hop baseline called Bidirectional Graph\nRetrieval (BGR) method for generating an explanation graph of textual evidence\nin knowledge reasoning and question answering. We have thoroughly evaluated\nexisting evidence retrieval and reasoning models on the ReasonGraphQA.\nExperiments highlight Graph-Hop is a promising direction for answering complex\nquestions, but it still has certain limitations. We have further studied\nmitigation strategies to meet these challenges and discuss future directions.", "published": "2023-05-23 16:28:42", "link": "http://arxiv.org/abs/2305.14211v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CompoundPiece: Evaluating and Improving Decompounding Performance of\n  Language Models", "abstract": "While many languages possess processes of joining two or more words to create\ncompound words, previous studies have been typically limited only to languages\nwith excessively productive compound formation (e.g., German, Dutch) and there\nis no public dataset containing compound and non-compound words across a large\nnumber of languages. In this work, we systematically study decompounding, the\ntask of splitting compound words into their constituents, at a wide scale. We\nfirst address the data gap by introducing a dataset of 255k compound and\nnon-compound words across 56 diverse languages obtained from Wiktionary. We\nthen use this dataset to evaluate an array of Large Language Models (LLMs) on\nthe decompounding task. We find that LLMs perform poorly, especially on words\nwhich are tokenized unfavorably by subword tokenization. We thus introduce a\nnovel methodology to train dedicated models for decompounding. The proposed\ntwo-stage procedure relies on a fully self-supervised objective in the first\nstage, while the second, supervised learning stage optionally fine-tunes the\nmodel on the annotated Wiktionary data. Our self-supervised models outperform\nthe prior best unsupervised decompounding models by 13.9% accuracy on average.\nOur fine-tuned models outperform all prior (language-specific) decompounding\ntools. Furthermore, we use our models to leverage decompounding during the\ncreation of a subword tokenizer, which we refer to as CompoundPiece.\nCompoundPiece tokenizes compound words more favorably on average, leading to\nimproved performance on decompounding over an otherwise equivalent model using\nSentencePiece tokenization.", "published": "2023-05-23 16:32:27", "link": "http://arxiv.org/abs/2305.14214v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Chain-of-Thought Style Prompting for Text-to-SQL", "abstract": "In-context learning with large language models (LLMs) has recently caught\nincreasing attention due to its superior few-shot performance on various tasks.\nHowever, its performance on text-to-SQL parsing still has much room for\nimprovement. In this paper, we hypothesize that a crucial aspect of LLMs to\nimprove for text-to-SQL parsing is their multi-step reasoning ability. Thus, we\nsystematically study how to enhance LLMs' reasoning ability through chain of\nthought (CoT) style prompting, including the original chain-of-thought\nprompting (Wei et al., 2022b) and least-to-most prompting (Zhou et al., 2023).\nOur experiments demonstrate that iterative prompting as in Zhou et al. (2023)\nmay be unnecessary for text-to-SQL parsing, and using detailed reasoning steps\ntends to have more error propagation issues. Based on these findings, we\npropose a new CoT-style prompting method for text-to-SQL parsing. It brings 5.2\nand 6.5 point absolute gains on the Spider development set and the Spider\nRealistic set, respectively, compared to the standard prompting method without\nreasoning steps; 2.4 and 1.5 point absolute gains, compared to the\nleast-to-most prompting method.", "published": "2023-05-23 16:32:36", "link": "http://arxiv.org/abs/2305.14215v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Question Answering as Programming for Solving Time-Sensitive Questions", "abstract": "Question answering plays a pivotal role in human daily life because it\ninvolves our acquisition of knowledge about the world. However, due to the\ndynamic and ever-changing nature of real-world facts, the answer can be\ncompletely different when the time constraint in the question changes.\nRecently, Large Language Models (LLMs) have shown remarkable intelligence in\nquestion answering, while our experiments reveal that the aforementioned\nproblems still pose a significant challenge to existing LLMs. This can be\nattributed to the LLMs' inability to perform rigorous reasoning based on\nsurface-level text semantics. To overcome this limitation, rather than\nrequiring LLMs to directly answer the question, we propose a novel approach\nwhere we reframe the $\\textbf{Q}$uestion $\\textbf{A}$nswering task\n$\\textbf{a}$s $\\textbf{P}$rogramming ($\\textbf{QAaP}$). Concretely, by\nleveraging modern LLMs' superior capability in understanding both natural\nlanguage and programming language, we endeavor to harness LLMs to represent\ndiversely expressed text as well-structured code and select the best matching\nanswer from multiple candidates through programming. We evaluate our QAaP\nframework on several time-sensitive question answering datasets and achieve\ndecent improvement, up to $14.5$% over strong baselines. Our codes and data are\navailable at https://github.com/TianHongZXY/qaap", "published": "2023-05-23 16:35:16", "link": "http://arxiv.org/abs/2305.14221v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "mmT5: Modular Multilingual Pre-Training Solves Source Language\n  Hallucinations", "abstract": "Multilingual sequence-to-sequence models perform poorly with increased\nlanguage coverage and fail to consistently generate text in the correct target\nlanguage in few-shot settings. To address these challenges, we propose mmT5, a\nmodular multilingual sequence-to-sequence model. mmT5 utilizes\nlanguage-specific modules during pre-training, which disentangle\nlanguage-specific information from language-agnostic information. We identify\nrepresentation drift during fine-tuning as a key limitation of modular\ngenerative models and develop strategies that enable effective zero-shot\ntransfer. Our model outperforms mT5 at the same parameter sizes by a large\nmargin on representative natural language understanding and generation tasks in\n40+ languages. Compared to mT5, mmT5 raises the rate of generating text in the\ncorrect language under zero-shot settings from 7% to 99%, thereby greatly\nalleviating the source language hallucination problem.", "published": "2023-05-23 16:38:01", "link": "http://arxiv.org/abs/2305.14224v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ManiTweet: A New Benchmark for Identifying Manipulation of News on\n  Social Media", "abstract": "Considerable advancements have been made to tackle the misrepresentation of\ninformation derived from reference articles in the domains of fact-checking and\nfaithful summarization. However, an unaddressed aspect remains - the\nidentification of social media posts that manipulate information within\nassociated news articles. This task presents a significant challenge, primarily\ndue to the prevalence of personal opinions in such posts. We present a novel\ntask, identifying manipulation of news on social media, which aims to detect\nmanipulation in social media posts and identify manipulated or inserted\ninformation. To study this task, we have proposed a data collection schema and\ncurated a dataset called ManiTweet, consisting of 3.6K pairs of tweets and\ncorresponding articles. Our analysis demonstrates that this task is highly\nchallenging, with large language models (LLMs) yielding unsatisfactory\nperformance. Additionally, we have developed a simple yet effective basic model\nthat outperforms LLMs significantly on the ManiTweet dataset. Finally, we have\nconducted an exploratory analysis of human-written tweets, unveiling intriguing\nconnections between manipulation and the domain and factuality of news\narticles, as well as revealing that manipulated sentences are more likely to\nencapsulate the main story or consequences of a news outlet.", "published": "2023-05-23 16:40:07", "link": "http://arxiv.org/abs/2305.14225v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Representational Disparities Between Multilingual and\n  Bilingual Translation Models", "abstract": "Multilingual machine translation has proven immensely useful for both\nparameter efficiency and overall performance across many language pairs via\ncomplete multilingual parameter sharing. However, some language pairs in\nmultilingual models can see worse performance than in bilingual models,\nespecially in the one-to-many translation setting. Motivated by their empirical\ndifferences, we examine the geometric differences in representations from\nbilingual models versus those from one-to-many multilingual models.\nSpecifically, we compute the isotropy of these representations using intrinsic\ndimensionality and IsoScore, in order to measure how the representations\nutilize the dimensions in their underlying vector space. Using the same\nevaluation data in both models, we find that for a given language pair, its\nmultilingual model decoder representations are consistently less isotropic and\noccupy fewer dimensions than comparable bilingual model decoder\nrepresentations. Additionally, we show that much of the anisotropy in\nmultilingual decoder representations can be attributed to modeling\nlanguage-specific information, therefore limiting remaining representational\ncapacity.", "published": "2023-05-23 16:46:18", "link": "http://arxiv.org/abs/2305.14230v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Learning to Summarize with Large Language Models as References", "abstract": "Recent studies have found that summaries generated by large language models\n(LLMs) are favored by human annotators over the original reference summaries in\ncommonly used summarization datasets. Therefore, we study an LLM-as-reference\nlearning setting for smaller text summarization models to investigate whether\ntheir performance can be substantially improved. To this end, we use LLMs as\nboth oracle summary generators for standard supervised fine-tuning and oracle\nsummary evaluators for efficient contrastive learning that leverages the LLMs'\nsupervision signals. We conduct comprehensive experiments with source news\narticles and find that (1) summarization models trained under the\nLLM-as-reference setting achieve significant performance improvement in both\nLLM and human evaluations; (2) contrastive learning outperforms standard\nsupervised fine-tuning under both low and high resource settings. Our\nexperimental results also enable a meta-analysis of LLMs' summary evaluation\ncapacities under a challenging setting, showing that LLMs are not well-aligned\nwith human evaluators. Particularly, our expert human evaluation reveals\nremaining nuanced performance gaps between LLMs and our fine-tuned models,\nwhich LLMs fail to capture. Thus, we call for further studies into both the\npotential and challenges of using LLMs in summarization model development.", "published": "2023-05-23 16:56:04", "link": "http://arxiv.org/abs/2305.14239v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Empathic Similarity in Personal Narratives", "abstract": "The most meaningful connections between people are often fostered through\nexpression of shared vulnerability and emotional experiences in personal\nnarratives. We introduce a new task of identifying similarity in personal\nstories based on empathic resonance, i.e., the extent to which two people\nempathize with each others' experiences, as opposed to raw semantic or lexical\nsimilarity, as has predominantly been studied in NLP. Using insights from\nsocial psychology, we craft a framework that operationalizes empathic\nsimilarity in terms of three key features of stories: main events, emotional\ntrajectories, and overall morals or takeaways. We create EmpathicStories, a\ndataset of 1,500 personal stories annotated with our empathic similarity\nfeatures, and 2,000 pairs of stories annotated with empathic similarity scores.\nUsing our dataset, we fine-tune a model to compute empathic similarity of story\npairs, and show that this outperforms semantic similarity models on automated\ncorrelation and retrieval metrics. Through a user study with 150 participants,\nwe also assess the effect our model has on retrieving stories that users\nempathize with, compared to naive semantic similarity-based retrieval, and find\nthat participants empathized significantly more with stories retrieved by our\nmodel. Our work has strong implications for the use of empathy-aware models to\nfoster human connection and empathy between people.", "published": "2023-05-23 17:00:45", "link": "http://arxiv.org/abs/2305.14246v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linear Cross-Lingual Mapping of Sentence Embeddings", "abstract": "Semantics of a sentence is defined with much less ambiguity than semantics of\na single word, and we assume that it should be better preserved by translation\nto another language. If multilingual sentence embeddings intend to represent\nsentence semantics, then the similarity between embeddings of any two sentences\nmust be invariant with respect to translation. Based on this suggestion, we\nconsider a simple linear cross-lingual mapping as a possible improvement of the\nmultilingual embeddings. We also consider deviation from orthogonality\nconditions as a measure of deficiency of the embeddings.", "published": "2023-05-23 17:10:37", "link": "http://arxiv.org/abs/2305.14256v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "R2H: Building Multimodal Navigation Helpers that Respond to Help\n  Requests", "abstract": "Intelligent navigation-helper agents are critical as they can navigate users\nin unknown areas through environmental awareness and conversational ability,\nserving as potential accessibility tools for individuals with disabilities. In\nthis work, we first introduce a novel benchmark, Respond to Help Requests\n(R2H), to promote the development of multi-modal navigation helpers capable of\nresponding to requests for help, utilizing existing dialog-based embodied\ndatasets. R2H mainly includes two tasks: (1) Respond to Dialog History (RDH),\nwhich assesses the helper agent's ability to generate informative responses\nbased on a given dialog history, and (2) Respond during Interaction (RdI),\nwhich evaluates the effectiveness and efficiency of the response during\nconsistent cooperation with a task performer. Furthermore, we explore two\napproaches to construct the navigation-helper agent, including fine-tuning a\nnovel task-oriented multi-modal response generation model that can see and\nrespond, named SeeRee, and employing a multi-modal large language model in a\nzero-shot manner. Analysis of the task and method was conducted based on both\nautomatic benchmarking and human evaluations. Project website:\nhttps://sites.google.com/view/response2helprequests/home.", "published": "2023-05-23 17:12:09", "link": "http://arxiv.org/abs/2305.14260v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs", "abstract": "Large language models (LLMs) have achieved widespread success on a variety of\nin-context few-shot tasks, but this success is typically evaluated via\ncorrectness rather than consistency. We argue that self-consistency is an\nimportant criteria for valid multi-step reasoning in tasks where the solution\nis composed of the answers to multiple sub-steps. We propose two types of\nself-consistency that are particularly important for multi-step reasoning --\nhypothetical consistency (a model's ability to predict what its output would be\nin a hypothetical other context) and compositional consistency (consistency of\na model's final outputs when intermediate sub-steps are replaced with the\nmodel's outputs for those steps). We demonstrate that multiple variants of the\nGPT-3/-4 models exhibit poor consistency rates across both types of consistency\non a variety of tasks.", "published": "2023-05-23 17:25:59", "link": "http://arxiv.org/abs/2305.14279v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Pixel Representations for Translation and Effective\n  Cross-lingual Transfer", "abstract": "We introduce and demonstrate how to effectively train multilingual machine\ntranslation models with pixel representations. We experiment with two different\ndata settings with a variety of language and script coverage, demonstrating\nimproved performance compared to subword embeddings. We explore various\nproperties of pixel representations such as parameter sharing within and across\nscripts to better understand where they lead to positive transfer. We observe\nthat these properties not only enable seamless cross-lingual transfer to unseen\nscripts, but make pixel representations more data-efficient than alternatives\nsuch as vocabulary expansion. We hope this work contributes to more extensible\nmultilingual models for all languages and scripts.", "published": "2023-05-23 17:26:50", "link": "http://arxiv.org/abs/2305.14280v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Query Rewriting for Retrieval-Augmented Large Language Models", "abstract": "Large Language Models (LLMs) play powerful, black-box readers in the\nretrieve-then-read pipeline, making remarkable progress in knowledge-intensive\ntasks. This work introduces a new framework, Rewrite-Retrieve-Read instead of\nthe previous retrieve-then-read for the retrieval-augmented LLMs from the\nperspective of the query rewriting. Unlike prior studies focusing on adapting\neither the retriever or the reader, our approach pays attention to the\nadaptation of the search query itself, for there is inevitably a gap between\nthe input text and the needed knowledge in retrieval. We first prompt an LLM to\ngenerate the query, then use a web search engine to retrieve contexts.\nFurthermore, to better align the query to the frozen modules, we propose a\ntrainable scheme for our pipeline. A small language model is adopted as a\ntrainable rewriter to cater to the black-box LLM reader. The rewriter is\ntrained using the feedback of the LLM reader by reinforcement learning.\nEvaluation is conducted on downstream tasks, open-domain QA and multiple-choice\nQA. Experiments results show consistent performance improvement, indicating\nthat our framework is proven effective and scalable, and brings a new framework\nfor retrieval-augmented LLM.", "published": "2023-05-23 17:27:50", "link": "http://arxiv.org/abs/2305.14283v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-powered Data Augmentation for Enhanced Cross-lingual Performance", "abstract": "This paper explores the potential of leveraging Large Language Models (LLMs)\nfor data augmentation in multilingual commonsense reasoning datasets where the\navailable training data is extremely limited. To achieve this, we utilise\nseveral LLMs, namely Dolly-v2, StableVicuna, ChatGPT, and GPT-4, to augment\nthree datasets: XCOPA, XWinograd, and XStoryCloze. Subsequently, we evaluate\nthe effectiveness of fine-tuning smaller multilingual models, mBERT and XLMR,\nusing the synthesised data. We compare the performance of training with data\ngenerated in English and target languages, as well as translated\nEnglish-generated data, revealing the overall advantages of incorporating data\ngenerated by LLMs, e.g. a notable 13.4 accuracy score improvement for the best\ncase. Furthermore, we conduct a human evaluation by asking native speakers to\nassess the naturalness and logical coherence of the generated examples across\ndifferent languages. The results of the evaluation indicate that LLMs such as\nChatGPT and GPT-4 excel at producing natural and coherent text in most\nlanguages, however, they struggle to generate meaningful text in certain\nlanguages like Tamil. We also observe that ChatGPT falls short in generating\nplausible alternatives compared to the original dataset, whereas examples from\nGPT-4 exhibit competitive logical consistency.", "published": "2023-05-23 17:33:27", "link": "http://arxiv.org/abs/2305.14288v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluation of African American Language Bias in Natural Language\n  Generation", "abstract": "We evaluate how well LLMs understand African American Language (AAL) in\ncomparison to their performance on White Mainstream English (WME), the\nencouraged \"standard\" form of English taught in American classrooms. We measure\nLLM performance using automatic metrics and human judgments for two tasks: a\ncounterpart generation task, where a model generates AAL (or WME) given WME (or\nAAL), and a masked span prediction (MSP) task, where models predict a phrase\nthat was removed from their input. Our contributions include: (1) evaluation of\nsix pre-trained, large language models on the two language generation tasks;\n(2) a novel dataset of AAL text from multiple contexts (social media, hip-hop\nlyrics, focus groups, and linguistic interviews) with human-annotated\ncounterparts in WME; and (3) documentation of model performance gaps that\nsuggest bias and identification of trends in lack of understanding of AAL\nfeatures.", "published": "2023-05-23 17:34:37", "link": "http://arxiv.org/abs/2305.14291v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WikiChat: Stopping the Hallucination of Large Language Model Chatbots by\n  Few-Shot Grounding on Wikipedia", "abstract": "This paper presents the first few-shot LLM-based chatbot that almost never\nhallucinates and has high conversationality and low latency. WikiChat is\ngrounded on the English Wikipedia, the largest curated free-text corpus.\n  WikiChat generates a response from an LLM, retains only the grounded facts,\nand combines them with additional information it retrieves from the corpus to\nform factual and engaging responses. We distill WikiChat based on GPT-4 into a\n7B-parameter LLaMA model with minimal loss of quality, to significantly improve\nits latency, cost and privacy, and facilitate research and deployment.\n  Using a novel hybrid human-and-LLM evaluation methodology, we show that our\nbest system achieves 97.3% factual accuracy in simulated conversations. It\nsignificantly outperforms all retrieval-based and LLM-based baselines, and by\n3.9%, 38.6% and 51.0% on head, tail and recent knowledge compared to GPT-4.\nCompared to previous state-of-the-art retrieval-based chatbots, WikiChat is\nalso significantly more informative and engaging, just like an LLM.\n  WikiChat achieves 97.9% factual accuracy in conversations with human users\nabout recent topics, 55.0% better than GPT-4, while receiving significantly\nhigher user ratings and more favorable comments.", "published": "2023-05-23 17:37:36", "link": "http://arxiv.org/abs/2305.14292v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WebIE: Faithful and Robust Information Extraction on the Web", "abstract": "Extracting structured and grounded fact triples from raw text is a\nfundamental task in Information Extraction (IE). Existing IE datasets are\ntypically collected from Wikipedia articles, using hyperlinks to link entities\nto the Wikidata knowledge base. However, models trained only on Wikipedia have\nlimitations when applied to web domains, which often contain noisy text or text\nthat does not have any factual information. We present WebIE, the first\nlarge-scale, entity-linked closed IE dataset consisting of 1.6M sentences\nautomatically collected from the English Common Crawl corpus. WebIE also\nincludes negative examples, i.e. sentences without fact triples, to better\nreflect the data on the web. We annotate ~21K triples from WebIE through\ncrowdsourcing and introduce mWebIE, a translation of the annotated set in four\nother languages: French, Spanish, Portuguese, and Hindi. We evaluate the\nin-domain, out-of-domain, and zero-shot cross-lingual performance of generative\nIE models and find models trained on WebIE show better generalisability. We\nalso propose three training strategies that use entity linking as an auxiliary\ntask. Our experiments show that adding Entity-Linking objectives improves the\nfaithfulness of our generative IE models.", "published": "2023-05-23 17:37:53", "link": "http://arxiv.org/abs/2305.14293v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QTSumm: Query-Focused Summarization over Tabular Data", "abstract": "People primarily consult tables to conduct data analysis or answer specific\nquestions. Text generation systems that can provide accurate table summaries\ntailored to users' information needs can facilitate more efficient access to\nrelevant data insights. Motivated by this, we define a new query-focused table\nsummarization task, where text generation models have to perform human-like\nreasoning and analysis over the given table to generate a tailored summary. We\nintroduce a new benchmark named QTSumm for this task, which contains 7,111\nhuman-annotated query-summary pairs over 2,934 tables covering diverse topics.\nWe investigate a set of strong baselines on QTSumm, including text generation,\ntable-to-text generation, and large language models. Experimental results and\nmanual analysis reveal that the new task presents significant challenges in\ntable-to-text generation for future research. Moreover, we propose a new\napproach named ReFactor, to retrieve and reason over query-relevant information\nfrom tabular data to generate several natural language facts. Experimental\nresults demonstrate that ReFactor can bring improvements to baselines by\nconcatenating the generated facts to the model input. Our data and code are\npublicly available at https://github.com/yale-nlp/QTSumm.", "published": "2023-05-23 17:43:51", "link": "http://arxiv.org/abs/2305.14303v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Navigating Prompt Complexity for Zero-Shot Classification: A Study of\n  Large Language Models in Computational Social Science", "abstract": "Instruction-tuned Large Language Models (LLMs) have exhibited impressive\nlanguage understanding and the capacity to generate responses that follow\nspecific prompts. However, due to the computational demands associated with\ntraining these models, their applications often adopt a zero-shot setting. In\nthis paper, we evaluate the zero-shot performance of two publicly accessible\nLLMs, ChatGPT and OpenAssistant, in the context of six Computational Social\nScience classification tasks, while also investigating the effects of various\nprompting strategies. Our experiments investigate the impact of prompt\ncomplexity, including the effect of incorporating label definitions into the\nprompt; use of synonyms for label names; and the influence of integrating past\nmemories during foundation model training. The findings indicate that in a\nzero-shot setting, current LLMs are unable to match the performance of smaller,\nfine-tuned baseline transformer models (such as BERT-large). Additionally, we\nfind that different prompting strategies can significantly affect\nclassification accuracy, with variations in accuracy and F1 scores exceeding\n10\\%.", "published": "2023-05-23 17:48:21", "link": "http://arxiv.org/abs/2305.14310v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasoning\n  of Large Language Models", "abstract": "Large Language Models (LLMs) have made significant progress in utilizing\ntools, but their ability is limited by API availability and the instability of\nimplicit reasoning, particularly when both planning and execution are involved.\nTo overcome these limitations, we propose CREATOR, a novel framework that\nenables LLMs to create their own tools using documentation and code\nrealization. CREATOR disentangles abstract tool creation and concrete decision\nexecution, resulting in improved performance. We evaluate CREATOR on MATH and\nTabMWP benchmarks, respectively consisting of challenging math competition\nproblems and diverse tabular contents. Remarkably, CREATOR outperforms existing\nchain-of-thought, program-of-thought, and tool-using baselines. Additionally,\nwe introduce the Creation Challenge dataset, featuring 2K diverse questions, to\nemphasize the necessity and benefits of LLMs' tool creation ability. Further\nresearch demonstrates that leveraging LLMs as tool creators facilitates\nknowledge transfer, and LLMs exhibit varying levels of tool creation abilities,\nenabling them to adapt to diverse situations. The tool creation ability\nrevolutionizes the LLM's problem-solving paradigm, driving us closer to the\nnext frontier of artificial intelligence. All the codes and data are released.", "published": "2023-05-23 17:51:52", "link": "http://arxiv.org/abs/2305.14318v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ConGraT: Self-Supervised Contrastive Pretraining for Joint Graph and\n  Text Embeddings", "abstract": "Learning on text-attributed graphs (TAGs), in which nodes are associated with\none or more texts, has been the subject of much recent work. However, most\napproaches tend to make strong assumptions about the downstream task of\ninterest, are reliant on hand-labeled data, or fail to equally balance the\nimportance of both text and graph representations. In this work, we propose\nContrastive Graph-Text pretraining (ConGraT), a general, self-supervised\napproach for jointly learning separate representations of texts and nodes in a\nTAG. Our method trains a language model (LM) and a graph neural network (GNN)\nto align their representations in a common latent space using a batch-wise\ncontrastive learning objective inspired by CLIP. We further propose an\nextension to the CLIP objective that leverages graph structure to incorporate\ninformation about inter-node similarity. Extensive experiments demonstrate that\nConGraT outperforms baselines on various downstream tasks, including node and\ntext category classification, link prediction, and language modeling. Finally,\nwe present an application of our method to community detection in social\ngraphs, which enables finding more textually grounded communities, rather than\npurely graph-based ones. Code and certain datasets are available at\nhttps://github.com/wwbrannon/congrat.", "published": "2023-05-23 17:53:30", "link": "http://arxiv.org/abs/2305.14321v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RET-LLM: Towards a General Read-Write Memory for Large Language Models", "abstract": "Large language models (LLMs) have significantly advanced the field of natural\nlanguage processing (NLP) through their extensive parameters and comprehensive\ndata utilization. However, existing LLMs lack a dedicated memory unit, limiting\ntheir ability to explicitly store and retrieve knowledge for various tasks. In\nthis paper, we propose RET-LLM a novel framework that equips LLMs with a\ngeneral write-read memory unit, allowing them to extract, store, and recall\nknowledge from the text as needed for task performance. Inspired by Davidsonian\nsemantics theory, we extract and save knowledge in the form of triplets. The\nmemory unit is designed to be scalable, aggregatable, updatable, and\ninterpretable. Through qualitative evaluations, we demonstrate the superiority\nof our proposed framework over baseline approaches in question answering tasks.\nMoreover, our framework exhibits robust performance in handling temporal-based\nquestion answering tasks, showcasing its ability to effectively manage\ntime-dependent information.", "published": "2023-05-23 17:53:38", "link": "http://arxiv.org/abs/2305.14322v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large\n  Language Models", "abstract": "Although large language models (LLMs) have achieved excellent performance in\na variety of evaluation benchmarks, they still struggle in complex reasoning\ntasks which require specific knowledge and multi-hop reasoning. To improve the\nreasoning abilities, we propose ChatCoT, a tool-augmented chain-of-thought\nreasoning framework for chat-based LLMs (e.g., ChatGPT). In ChatCoT, we model\nthe chain-of-thought (CoT) reasoning as multi-turn conversations, to utilize\ntools in a more natural way through chatting. At each turn, LLMs can either\ninteract with tools or perform the reasoning. Our approach can effectively\nleverage the multi-turn conversation ability of chat-based LLMs, and integrate\nthe thought chain following and tools manipulation in a unified way. Specially,\nwe initialize the early turns of the conversation by the knowledge about tools,\ntasks, and reasoning format, and propose an iterative tool-augmented reasoning\nstep to perform step-by-step tool-augmented reasoning. The experiment results\non two complex reasoning datasets (MATH and HotpotQA) have shown the\neffectiveness of ChatCoT on complex reasoning tasks, achieving a 7.9% relative\nimprovement over the state-of-the-art baseline. Our code and data are available\nat: \\url{https://github.com/RUCAIBOX/ChatCoT}.", "published": "2023-05-23 17:54:33", "link": "http://arxiv.org/abs/2305.14323v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ties Matter: Meta-Evaluating Modern Metrics with Pairwise Accuracy and\n  Tie Calibration", "abstract": "Kendall's tau is frequently used to meta-evaluate how well machine\ntranslation (MT) evaluation metrics score individual translations. Its focus on\npairwise score comparisons is intuitive but raises the question of how ties\nshould be handled, a gray area that has motivated different variants in the\nliterature. We demonstrate that, in settings like modern MT meta-evaluation,\nexisting variants have weaknesses arising from their handling of ties, and in\nsome situations can even be gamed. We propose instead to meta-evaluate metrics\nwith a version of pairwise accuracy that gives metrics credit for correctly\npredicting ties, in combination with a tie calibration procedure that\nautomatically introduces ties into metric scores, enabling fair comparison\nbetween metrics that do and do not predict ties. We argue and provide\nexperimental evidence that these modifications lead to fairer ranking-based\nassessments of metric performance.", "published": "2023-05-23 17:54:57", "link": "http://arxiv.org/abs/2305.14324v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TalkUp: Paving the Way for Understanding Empowering Language", "abstract": "Empowering language is important in many real-world contexts, from education\nto workplace dynamics to healthcare. Though language technologies are growing\nmore prevalent in these contexts, empowerment has seldom been studied in NLP,\nand moreover, it is inherently challenging to operationalize because of its\nimplicit nature. This work builds from linguistic and social psychology\nliterature to explore what characterizes empowering language. We then\ncrowdsource a novel dataset of Reddit posts labeled for empowerment, reasons\nwhy these posts are empowering to readers, and the social relationships between\nposters and readers. Our preliminary analyses show that this dataset, which we\ncall TalkUp, can be used to train language models that capture empowering and\ndisempowering language. More broadly, TalkUp provides an avenue to explore\nimplication, presuppositions, and how social context influences the meaning of\nlanguage.", "published": "2023-05-23 17:55:34", "link": "http://arxiv.org/abs/2305.14326v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking Machine Translation with Cultural Awareness", "abstract": "Translating culture-related content is vital for effective cross-cultural\ncommunication. However, many culture-specific items (CSIs) often lack viable\ntranslations across languages, making it challenging to collect high-quality,\ndiverse parallel corpora with CSI annotations. This difficulty hinders the\nanalysis of cultural awareness of machine translation (MT) systems, including\ntraditional neural MT and the emerging MT paradigm using large language models\n(LLM). To address this gap, we introduce a novel parallel corpus, enriched with\nCSI annotations in 6 language pairs for investigating Culturally-Aware Machine\nTranslation--CAMT. Furthermore, we design two evaluation metrics to assess CSI\ntranslations, focusing on their pragmatic translation quality. Our findings\nshow the superior ability of LLMs over neural MTs in leveraging external\ncultural knowledge for translating CSIs, especially those lacking translations\nin the target culture.", "published": "2023-05-23 17:56:33", "link": "http://arxiv.org/abs/2305.14328v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating and Modeling Attribution for Cross-Lingual Question Answering", "abstract": "Trustworthy answer content is abundant in many high-resource languages and is\ninstantly accessible through question answering systems, yet this content can\nbe hard to access for those that do not speak these languages. The leap forward\nin cross-lingual modeling quality offered by generative language models offers\nmuch promise, yet their raw generations often fall short in factuality. To\nimprove trustworthiness in these systems, a promising direction is to attribute\nthe answer to a retrieved source, possibly in a content-rich language different\nfrom the query. Our work is the first to study attribution for cross-lingual\nquestion answering. First, we collect data in 5 languages to assess the\nattribution level of a state-of-the-art cross-lingual QA system. To our\nsurprise, we find that a substantial portion of the answers is not attributable\nto any retrieved passages (up to 50% of answers exactly matching a gold\nreference) despite the system being able to attend directly to the retrieved\ntext. Second, to address this poor attribution level, we experiment with a wide\nrange of attribution detection techniques. We find that Natural Language\nInference models and PaLM 2 fine-tuned on a very small amount of attribution\ndata can accurately detect attribution. Based on these models, we improve the\nattribution level of a cross-lingual question-answering system. Overall, we\nshow that current academic generative cross-lingual QA systems have substantial\nshortcomings in attribution and we build tooling to mitigate these issues.", "published": "2023-05-23 17:57:46", "link": "http://arxiv.org/abs/2305.14332v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Schema-Driven Information Extraction from Heterogeneous Tables", "abstract": "In this paper, we explore the question of whether large language models can\nsupport cost-efficient information extraction from tables. We introduce\nschema-driven information extraction, a new task that transforms tabular data\ninto structured records following a human-authored schema. To assess various\nLLM's capabilities on this task, we present a benchmark comprised of tables\nfrom four diverse domains: machine learning papers, chemistry literature,\nmaterial science journals, and webpages. We use this collection of annotated\ntables to evaluate the ability of open-source and API-based language models to\nextract information from tables covering diverse domains and data formats. Our\nexperiments demonstrate that surprisingly competitive performance can be\nachieved without requiring task-specific pipelines or labels, achieving F1\nscores ranging from 74.2 to 96.1, while maintaining cost efficiency. Moreover,\nthrough detailed ablation studies and analyses, we investigate the factors\ncontributing to model success and validate the practicality of distilling\ncompact models to reduce API reliance.", "published": "2023-05-23 17:58:10", "link": "http://arxiv.org/abs/2305.14336v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "APPLS: Evaluating Evaluation Metrics for Plain Language Summarization", "abstract": "While there has been significant development of models for Plain Language\nSummarization (PLS), evaluation remains a challenge. PLS lacks a dedicated\nassessment metric, and the suitability of text generation evaluation metrics is\nunclear due to the unique transformations involved (e.g., adding background\nexplanations, removing jargon). To address these questions, our study\nintroduces a granular meta-evaluation testbed, APPLS, designed to evaluate\nmetrics for PLS. We identify four PLS criteria from previous work --\ninformativeness, simplification, coherence, and faithfulness -- and define a\nset of perturbations corresponding to these criteria that sensitive metrics\nshould be able to detect. We apply these perturbations to extractive hypotheses\nfor two PLS datasets to form our testbed. Using APPLS, we assess performance of\n14 metrics, including automated scores, lexical features, and LLM prompt-based\nevaluations. Our analysis reveals that while some current metrics show\nsensitivity to specific criteria, no single method captures all four criteria\nsimultaneously. We therefore recommend a suite of automated metrics be used to\ncapture PLS quality along all relevant criteria. This work contributes the\nfirst meta-evaluation testbed for PLS and a comprehensive evaluation of\nexisting metrics. APPLS and our evaluation code is available at\nhttps://github.com/LinguisticAnomalies/APPLS.", "published": "2023-05-23 17:59:19", "link": "http://arxiv.org/abs/2305.14341v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain-Expanded ASTE: Rethinking Generalization in Aspect Sentiment\n  Triplet Extraction", "abstract": "Aspect Sentiment Triplet Extraction (ASTE) is a challenging task in sentiment\nanalysis, aiming to provide fine-grained insights into human sentiments.\nHowever, existing benchmarks are limited to two domains and do not evaluate\nmodel performance on unseen domains, raising concerns about the generalization\nof proposed methods. Furthermore, it remains unclear if large language models\n(LLMs) can effectively handle complex sentiment tasks like ASTE. In this work,\nwe address the issue of generalization in ASTE from both a benchmarking and\nmodeling perspective. We introduce a domain-expanded benchmark by annotating\nsamples from diverse domains, enabling evaluation of models in both in-domain\nand out-of-domain settings. Additionally, we propose CASE, a simple and\neffective decoding strategy that enhances trustworthiness and performance of\nLLMs in ASTE. Through comprehensive experiments involving multiple tasks,\nsettings, and models, we demonstrate that CASE can serve as a general decoding\nstrategy for complex sentiment tasks. By expanding the scope of evaluation and\nproviding a more reliable decoding strategy, we aim to inspire the research\ncommunity to reevaluate the generalizability of benchmarks and models for ASTE.\nOur code, data, and models are available at\nhttps://github.com/DAMO-NLP-SG/domain-expanded-aste.", "published": "2023-05-23 18:01:49", "link": "http://arxiv.org/abs/2305.14434v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Contrast Consistency of Open-Domain Question Answering Systems\n  on Minimally Edited Questions", "abstract": "Contrast consistency, the ability of a model to make consistently correct\npredictions in the presence of perturbations, is an essential aspect in NLP.\nWhile studied in tasks such as sentiment analysis and reading comprehension, it\nremains unexplored in open-domain question answering (OpenQA) due to the\ndifficulty of collecting perturbed questions that satisfy factuality\nrequirements. In this work, we collect minimally edited questions as\nchallenging contrast sets to evaluate OpenQA models. Our collection approach\ncombines both human annotation and large language model generation. We find\nthat the widely used dense passage retriever (DPR) performs poorly on our\ncontrast sets, despite fitting the training set well and performing\ncompetitively on standard test sets. To address this issue, we introduce a\nsimple and effective query-side contrastive loss with the aid of data\naugmentation to improve DPR training. Our experiments on the contrast sets\ndemonstrate that DPR's contrast consistency is improved without sacrificing its\naccuracy on the standard test sets.", "published": "2023-05-23 18:07:04", "link": "http://arxiv.org/abs/2305.14441v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study on Information Extraction using Large Language Models", "abstract": "Human-like large language models (LLMs), especially the most powerful and\npopular ones in OpenAI's GPT family, have proven to be very helpful for many\nnatural language processing (NLP) related tasks. Therefore, various attempts\nhave been made to apply LLMs to information extraction (IE), which is a\nfundamental NLP task that involves extracting information from unstructured\nplain text. To demonstrate the latest representative progress in LLMs'\ninformation extraction ability, we assess the information extraction ability of\nGPT-4 (the latest version of GPT at the time of writing this paper) from four\nperspectives: Performance, Evaluation Criteria, Robustness, and Error Types.\nOur results suggest a visible performance gap between GPT-4 and\nstate-of-the-art (SOTA) IE methods. To alleviate this problem, considering the\nLLMs' human-like characteristics, we propose and analyze the effects of a\nseries of simple prompt-based methods, which can be generalized to other LLMs\nand NLP tasks. Rich experiments show our methods' effectiveness and some of\ntheir remaining issues in improving GPT-4's information extraction ability.", "published": "2023-05-23 18:17:43", "link": "http://arxiv.org/abs/2305.14450v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Robustness of Finetuned Transformer-based NLP Models", "abstract": "Transformer-based pretrained models like BERT, GPT-2 and T5 have been\nfinetuned for a large number of natural language processing (NLP) tasks, and\nhave been shown to be very effective. However, while finetuning, what changes\nacross layers in these models with respect to pretrained checkpoints is\nunder-studied. Further, how robust are these models to perturbations in input\ntext? Does the robustness vary depending on the NLP task for which the models\nhave been finetuned? While there exists some work on studying the robustness of\nBERT finetuned for a few NLP tasks, there is no rigorous study that compares\nthis robustness across encoder only, decoder only and encoder-decoder models.\nIn this paper, we characterize changes between pretrained and finetuned\nlanguage model representations across layers using two metrics: CKA and STIR.\nFurther, we study the robustness of three language models (BERT, GPT-2 and T5)\nwith eight different text perturbations on classification tasks from the\nGeneral Language Understanding Evaluation (GLUE) benchmark, and generation\ntasks like summarization, free-form generation and question generation. GPT-2\nrepresentations are more robust than BERT and T5 across multiple types of input\nperturbation. Although models exhibit good robustness broadly, dropping nouns,\nverbs or changing characters are the most impactful. Overall, this study\nprovides valuable insights into perturbation-specific weaknesses of popular\nTransformer-based models, which should be kept in mind when passing inputs. We\nmake the code and models publicly available\n[https://github.com/PavanNeerudu/Robustness-of-Transformers-models].", "published": "2023-05-23 18:25:18", "link": "http://arxiv.org/abs/2305.14453v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pre-training Language Models for Comparative Reasoning", "abstract": "Comparative reasoning is a process of comparing objects, concepts, or\nentities to draw conclusions, which constitutes a fundamental cognitive\nability. In this paper, we propose a novel framework to pre-train language\nmodels for enhancing their abilities of comparative reasoning over texts. While\nthere have been approaches for NLP tasks that require comparative reasoning,\nthey suffer from costly manual data labeling and limited generalizability to\ndifferent tasks. Our approach introduces a novel method of collecting scalable\ndata for text-based entity comparison, which leverages both structured and\nunstructured data. Moreover, we present a framework of pre-training language\nmodels via three novel objectives on comparative reasoning. Evaluation on\ndownstream tasks including comparative question answering, question generation,\nand summarization shows that our pre-training framework significantly improves\nthe comparative reasoning abilities of language models, especially under\nlow-resource conditions. This work also releases the first integrated benchmark\nfor comparative reasoning.", "published": "2023-05-23 18:28:42", "link": "http://arxiv.org/abs/2305.14457v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dancing Between Success and Failure: Edit-level Simplification\n  Evaluation using SALSA", "abstract": "Large language models (e.g., GPT-4) are uniquely capable of producing highly\nrated text simplification, yet current human evaluation methods fail to provide\na clear understanding of systems' specific strengths and weaknesses. To address\nthis limitation, we introduce SALSA, an edit-based human annotation framework\nthat enables holistic and fine-grained text simplification evaluation. We\ndevelop twenty one linguistically grounded edit types, covering the full\nspectrum of success and failure across dimensions of conceptual, syntactic and\nlexical simplicity. Using SALSA, we collect 19K edit annotations on 840\nsimplifications, revealing discrepancies in the distribution of simplification\nstrategies performed by fine-tuned models, prompted LLMs and humans, and find\nGPT-3.5 performs more quality edits than humans, but still exhibits frequent\nerrors. Using our fine-grained annotations, we develop LENS-SALSA, a\nreference-free automatic simplification metric, trained to predict sentence-\nand word-level quality simultaneously. Additionally, we introduce word-level\nquality estimation for simplification and report promising baseline results.\nOur data, new metric, and annotation toolkit are available at\nhttps://salsa-eval.com.", "published": "2023-05-23 18:30:49", "link": "http://arxiv.org/abs/2305.14458v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CGCE: A Chinese Generative Chat Evaluation Benchmark for General and\n  Financial Domains", "abstract": "Generative chat models, such as ChatGPT and GPT-4, have revolutionized\nnatural language generation (NLG) by incorporating instructions and human\nfeedback to achieve significant performance improvements. However, the lack of\nstandardized evaluation benchmarks for chat models, particularly for Chinese\nand domain-specific models, hinders their assessment and progress. To address\nthis gap, we introduce the Chinese Generative Chat Evaluation (CGCE) benchmark,\nfocusing on general and financial domains. The CGCE benchmark encompasses\ndiverse tasks, including 200 questions in the general domain and 150 specific\nprofessional questions in the financial domain. Manual scoring evaluates\nfactors such as accuracy, coherence, expression clarity, and completeness. The\nCGCE benchmark provides researchers with a standardized framework to assess and\ncompare Chinese generative chat models, fostering advancements in NLG research.", "published": "2023-05-23 18:54:15", "link": "http://arxiv.org/abs/2305.14471v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FOCUS: Effective Embedding Initialization for Monolingual Specialization\n  of Multilingual Models", "abstract": "Using model weights pretrained on a high-resource language as a warm start\ncan reduce the need for data and compute to obtain high-quality language models\nfor other, especially low-resource, languages. However, if we want to use a new\ntokenizer specialized for the target language, we cannot transfer the source\nmodel's embedding matrix. In this paper, we propose FOCUS - Fast Overlapping\nToken Combinations Using Sparsemax, a novel embedding initialization method\nthat initializes the embedding matrix effectively for a new tokenizer based on\ninformation in the source model's embedding matrix. FOCUS represents newly\nadded tokens as combinations of tokens in the overlap of the source and target\nvocabularies. The overlapping tokens are selected based on semantic similarity\nin an auxiliary static token embedding space. We focus our study on using the\nmultilingual XLM-R as a source model and empirically show that FOCUS\noutperforms random initialization and previous work in language modeling and on\na range of downstream tasks (NLI, QA, and NER).", "published": "2023-05-23 19:21:53", "link": "http://arxiv.org/abs/2305.14481v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is a Prestigious Job the same as a Prestigious Country? A Case Study on\n  Multilingual Sentence Embeddings and European Countries", "abstract": "We study how multilingual sentence representations capture European countries\nand occupations and how this differs across European languages. We prompt the\nmodels with templated sentences that we machine-translate into 12 European\nlanguages and analyze the most prominent dimensions in the embeddings.Our\nanalysis reveals that the most prominent feature in the embedding is the\ngeopolitical distinction between Eastern and Western Europe and the country's\neconomic strength in terms of GDP. When prompted specifically for job prestige,\nthe embedding space clearly distinguishes high and low-prestige jobs. The\noccupational dimension is uncorrelated with the most dominant country\ndimensions in three out of four studied models. The exception is a small\ndistilled model that exhibits a connection between occupational prestige and\ncountry of origin, which is a potential source of nationality-based\ndiscrimination. Our findings are consistent across languages.", "published": "2023-05-23 19:24:42", "link": "http://arxiv.org/abs/2305.14482v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Large Language Models Robust Coreference Resolvers?", "abstract": "Recent work on extending coreference resolution across domains and languages\nrelies on annotated data in both the target domain and language. At the same\ntime, pre-trained large language models (LMs) have been reported to exhibit\nstrong zero- and few-shot learning abilities across a wide range of NLP tasks.\nHowever, prior work mostly studied this ability using artificial sentence-level\ndatasets such as the Winograd Schema Challenge. In this paper, we assess the\nfeasibility of prompt-based coreference resolution by evaluating\ninstruction-tuned language models on difficult, linguistically-complex\ncoreference benchmarks (e.g., CoNLL-2012). We show that prompting for\ncoreference can outperform current unsupervised coreference systems, although\nthis approach appears to be reliant on high-quality mention detectors. Further\ninvestigations reveal that instruction-tuned LMs generalize surprisingly well\nacross domains, languages, and time periods; yet continued fine-tuning of\nneural models should still be preferred if small amounts of annotated examples\nare available.", "published": "2023-05-23 19:38:28", "link": "http://arxiv.org/abs/2305.14489v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sociocultural Norm Similarities and Differences via Situational\n  Alignment and Explainable Textual Entailment", "abstract": "Designing systems that can reason across cultures requires that they are\ngrounded in the norms of the contexts in which they operate. However, current\nresearch on developing computational models of social norms has primarily\nfocused on American society. Here, we propose a novel approach to discover and\ncompare descriptive social norms across Chinese and American cultures. We\ndemonstrate our approach by leveraging discussions on a Chinese Q&A platform\n(Zhihu) and the existing SocialChemistry dataset as proxies for contrasting\ncultural axes, align social situations cross-culturally, and extract social\nnorms from texts using in-context learning. Embedding Chain-of-Thought\nprompting in a human-AI collaborative framework, we build a high-quality\ndataset of 3,069 social norms aligned with social situations across Chinese and\nAmerican cultures alongside corresponding free-text explanations. To test the\nability of models to reason about social norms across cultures, we introduce\nthe task of explainable social norm entailment, showing that existing models\nunder 3B parameters have significant room for improvement in both automatic and\nhuman evaluation. Further analysis of cross-cultural norm differences based on\nour dataset shows empirical alignment with the social orientations framework,\nrevealing several situational and descriptive nuances in norms across these\ncultures.", "published": "2023-05-23 19:43:47", "link": "http://arxiv.org/abs/2305.14492v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do prompt positions really matter?", "abstract": "Prompt-based models have gathered a lot of attention from researchers due to\ntheir remarkable advancements in the fields of zero-shot and few-shot learning.\nDeveloping an effective prompt template plays a critical role. However, prior\nstudies have mainly focused on prompt vocabulary searching or embedding\ninitialization within a predefined template with the prompt position fixed. In\nthis empirical study, we conduct the most comprehensive analysis to date of\nprompt position for diverse Natural Language Processing (NLP) tasks. Our\nfindings quantify the substantial impact prompt position has on model\nperformance. We observe that the prompt positions used in prior studies are\noften sub-optimal, and this observation is consistent even in widely used\ninstruction-tuned models. These findings suggest prompt position optimisation\nas a valuable research direction to augment prompt engineering methodologies\nand prompt position-aware instruction tuning as a potential way to build more\nrobust models in the future.", "published": "2023-05-23 19:45:45", "link": "http://arxiv.org/abs/2305.14493v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deduction under Perturbed Evidence: Probing Student Simulation\n  Capabilities of Large Language Models", "abstract": "We explore whether Large Language Models (LLMs) are capable of logical\nreasoning with distorted facts, which we call Deduction under Perturbed\nEvidence (DUPE). DUPE presents a unique challenge to LLMs since they typically\nrely on their parameters, which encode mostly accurate information, to reason\nand make inferences. However, in DUPE, LLMs must reason over manipulated or\nfalsified evidence present in their prompts, which can result in false\nconclusions that are valid only under the manipulated evidence. Our goal with\nDUPE is to determine whether LLMs can arrive at these false conclusions and\nidentify whether the dominant factor influencing the deduction process is the\nencoded data in the parameters or the manipulated evidence in the prompts. To\nevaluate the DUPE capabilities of LLMs, we create a DUPEd version of the\nStrategyQA dataset, where facts are manipulated to reverse the answer to the\nquestion. Our findings show that even the most advanced GPT models struggle to\nreason on manipulated facts - showcasing poor DUPE skills - with accuracy\ndropping by 45% compared to the original dataset. We also investigate prompt\nsettings inspired from student simulation models, which mitigate the accuracy\ndrop to some extent. Our findings have practical implications for understanding\nthe performance of LLMs in real-world applications such as student simulation\nmodels that involve reasoning over inaccurate information.", "published": "2023-05-23 20:26:03", "link": "http://arxiv.org/abs/2305.14507v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How to Choose How to Choose Your Chatbot: A Massively Multi-System\n  MultiReference Data Set for Dialog Metric Evaluation", "abstract": "We release MMSMR, a Massively Multi-System MultiReference dataset to enable\nfuture work on metrics and evaluation for dialog. Automatic metrics for\ndialogue evaluation should be robust proxies for human judgments; however, the\nverification of robustness is currently far from satisfactory. To quantify the\nrobustness correlation and understand what is necessary in a test set, we\ncreate and release an 8-reference dialog dataset by extending single-reference\nevaluation sets and introduce this new language learning conversation dataset.\nWe then train 1750 systems and evaluate them on our novel test set and the\nDailyDialog dataset. We release the novel test set, and model hyper parameters,\ninference outputs, and metric scores for each system on a variety of datasets.", "published": "2023-05-23 21:33:43", "link": "http://arxiv.org/abs/2305.14533v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties\n  Grounded in Math Reasoning Problems", "abstract": "While automatic dialogue tutors hold great potential in making education\npersonalized and more accessible, research on such systems has been hampered by\na lack of sufficiently large and high-quality datasets. Collecting such\ndatasets remains challenging, as recording tutoring sessions raises privacy\nconcerns and crowdsourcing leads to insufficient data quality. To address this,\nwe propose a framework to generate such dialogues by pairing human teachers\nwith a Large Language Model (LLM) prompted to represent common student errors.\nWe describe how we use this framework to collect MathDial, a dataset of 3k\none-to-one teacher-student tutoring dialogues grounded in multi-step math\nreasoning problems. While models like GPT-3 are good problem solvers, they fail\nat tutoring because they generate factually incorrect feedback or are prone to\nrevealing solutions to students too early. To overcome this, we let teachers\nprovide learning opportunities to students by guiding them using various\nscaffolding questions according to a taxonomy of teacher moves. We demonstrate\nMathDial and its extensive annotations can be used to finetune models to be\nmore effective tutors (and not just solvers). We confirm this by automatic and\nhuman evaluation, notably in an interactive setting that measures the trade-off\nbetween student solving success and telling solutions. The dataset is released\npublicly.", "published": "2023-05-23 21:44:56", "link": "http://arxiv.org/abs/2305.14536v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond", "abstract": "With the recent appearance of LLMs in practical settings, having methods that\ncan effectively detect factual inconsistencies is crucial to reduce the\npropagation of misinformation and improve trust in model outputs. When testing\non existing factual consistency benchmarks, we find that a few large language\nmodels (LLMs) perform competitively on classification benchmarks for factual\ninconsistency detection compared to traditional non-LLM methods. However, a\ncloser analysis reveals that most LLMs fail on more complex formulations of the\ntask and exposes issues with existing evaluation benchmarks, affecting\nevaluation precision. To address this, we propose a new protocol for\ninconsistency detection benchmark creation and implement it in a 10-domain\nbenchmark called SummEdits. This new benchmark is 20 times more cost-effective\nper sample than previous benchmarks and highly reproducible, as we estimate\ninter-annotator agreement at about 0.9. Most LLMs struggle on SummEdits, with\nperformance close to random chance. The best-performing model, GPT-4, is still\n8\\% below estimated human performance, highlighting the gaps in LLMs' ability\nto reason about facts and detect inconsistencies when they occur.", "published": "2023-05-23 21:50:06", "link": "http://arxiv.org/abs/2305.14540v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpretable Automatic Fine-grained Inconsistency Detection in Text\n  Summarization", "abstract": "Existing factual consistency evaluation approaches for text summarization\nprovide binary predictions and limited insights into the weakness of\nsummarization systems. Therefore, we propose the task of fine-grained\ninconsistency detection, the goal of which is to predict the fine-grained types\nof factual errors in a summary. Motivated by how humans inspect factual\ninconsistency in summaries, we propose an interpretable fine-grained\ninconsistency detection model, FineGrainFact, which explicitly represents the\nfacts in the documents and summaries with semantic frames extracted by semantic\nrole labeling, and highlights the related semantic frames to predict\ninconsistency. The highlighted semantic frames help verify predicted error\ntypes and correct inconsistent summaries. Experiment results demonstrate that\nour model outperforms strong baselines and provides evidence to support or\nrefute the summary.", "published": "2023-05-23 22:11:47", "link": "http://arxiv.org/abs/2305.14548v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PEARL: Prompting Large Language Models to Plan and Execute Actions Over\n  Long Documents", "abstract": "Strategies such as chain-of-thought prompting improve the performance of\nlarge language models (LLMs) on complex reasoning tasks by decomposing input\nexamples into intermediate steps. However, it remains unclear how to apply such\nmethods to reason over long input documents, in which both the decomposition\nand the output of each intermediate step are non-trivial to obtain. In this\nwork, we propose PEARL, a prompting framework to improve reasoning over long\ndocuments, which consists of three stages: action mining, plan formulation, and\nplan execution. More specifically, given a question about a long document,\nPEARL decomposes the question into a sequence of actions (e.g., SUMMARIZE,\nFIND_EVENT, FIND_RELATION) and then executes them over the document to obtain\nthe answer. Each stage of PEARL is implemented via zero-shot or few-shot\nprompting of LLMs (in our work, GPT-4) with minimal human input. We evaluate\nPEARL on a challenging subset of the QuALITY dataset, which contains questions\nthat require complex reasoning over long narrative texts. PEARL outperforms\nzero-shot and chain-of-thought prompting on this dataset, and ablation\nexperiments show that each stage of PEARL is critical to its performance.\nOverall, PEARL is a first step towards leveraging LLMs to reason over long\ndocuments.", "published": "2023-05-23 23:06:04", "link": "http://arxiv.org/abs/2305.14564v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-shot Unified Question Answering: Tuning Models or Prompts?", "abstract": "Question-answering (QA) tasks often investigate specific question types,\nknowledge domains, or reasoning skills, leading to specialized models catering\nto specific categories of QA tasks. While recent research has explored the idea\nof unified QA models, such models are usually explored for high-resource\nscenarios and require re-training to extend their capabilities. To overcome\nthese drawbacks, the paper explores the potential of two paradigms of tuning,\nmodel, and prompts, for unified QA under a low-resource setting. The paper\nprovides an exhaustive analysis of their applicability using 16 QA datasets,\nrevealing that prompt tuning can perform as well as model tuning in a few-shot\nsetting with a good initialization. The study also shows that parameter-sharing\nresults in superior few-shot performance, simple knowledge transfer techniques\nfor prompt initialization can be effective, and prompt tuning achieves a\nsignificant performance boost from pre-training in a low-resource regime. The\nresearch offers insights into the advantages and limitations of prompt tuning\nfor unified QA in a few-shot setting, contributing to the development of\neffective and efficient systems in low-resource scenarios.", "published": "2023-05-23 23:14:38", "link": "http://arxiv.org/abs/2305.14569v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Characters to Words: Hierarchical Pre-trained Language Model for\n  Open-vocabulary Language Understanding", "abstract": "Current state-of-the-art models for natural language understanding require a\npreprocessing step to convert raw text into discrete tokens. This process known\nas tokenization relies on a pre-built vocabulary of words or sub-word\nmorphemes. This fixed vocabulary limits the model's robustness to spelling\nerrors and its capacity to adapt to new domains. In this work, we introduce a\nnovel open-vocabulary language model that adopts a hierarchical two-level\napproach: one at the word level and another at the sequence level. Concretely,\nwe design an intra-word module that uses a shallow Transformer architecture to\nlearn word representations from their characters, and a deep inter-word\nTransformer module that contextualizes each word representation by attending to\nthe entire word sequence. Our model thus directly operates on character\nsequences with explicit awareness of word boundaries, but without biased\nsub-word or word-level vocabulary. Experiments on various downstream tasks show\nthat our method outperforms strong baselines. We also demonstrate that our\nhierarchical model is robust to textual corruption and domain shift.", "published": "2023-05-23 23:22:20", "link": "http://arxiv.org/abs/2305.14571v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parameter-Efficient Language Model Tuning with Active Learning in\n  Low-Resource Settings", "abstract": "Pre-trained language models (PLMs) have ignited a surge in demand for\neffective fine-tuning techniques, particularly in low-resource domains and\nlanguages. Active learning (AL), a set of algorithms designed to decrease\nlabeling costs by minimizing label complexity, has shown promise in confronting\nthe labeling bottleneck. In parallel, adapter modules designed for\nparameter-efficient fine-tuning (PEFT) have demonstrated notable potential in\nlow-resource settings. However, the interplay between AL and adapter-based PEFT\nremains unexplored. We present an empirical study of PEFT behavior with AL in\nlow-resource settings for text classification tasks. Our findings affirm the\nsuperiority of PEFT over full-fine tuning (FFT) in low-resource settings and\ndemonstrate that this advantage persists in AL setups. We further examine the\nproperties of PEFT and FFT through the lens of forgetting dynamics and\ninstance-level representations, where we find that PEFT yields more stable\nrepresentations of early and middle layers compared to FFT. Our research\nunderscores the synergistic potential of AL and PEFT in low-resource settings,\npaving the way for advancements in efficient and effective fine-tuning.", "published": "2023-05-23 23:27:20", "link": "http://arxiv.org/abs/2305.14576v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Connecting the Dots: What Graph-Based Text Representations Work Best for\n  Text Classification Using Graph Neural Networks?", "abstract": "Given the success of Graph Neural Networks (GNNs) for structure-aware machine\nlearning, many studies have explored their use for text classification, but\nmostly in specific domains with limited data characteristics. Moreover, some\nstrategies prior to GNNs relied on graph mining and classical machine learning,\nmaking it difficult to assess their effectiveness in modern settings. This work\nextensively investigates graph representation methods for text classification,\nidentifying practical implications and open challenges. We compare different\ngraph construction schemes using a variety of GNN architectures and setups\nacross five datasets, encompassing short and long documents as well as\nunbalanced scenarios in diverse domains. Two Transformer-based large language\nmodels are also included to complement the study. The results show that i)\nalthough the effectiveness of graphs depends on the textual input features and\ndomain, simple graph constructions perform better the longer the documents are,\nii) graph representations are especially beneficial for longer documents,\noutperforming Transformer-based models, iii) graph methods are particularly\nefficient at solving the task.", "published": "2023-05-23 23:31:24", "link": "http://arxiv.org/abs/2305.14578v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural Language Decompositions of Implicit Content Enable Better Text\n  Representations", "abstract": "When people interpret text, they rely on inferences that go beyond the\nobserved language itself. Inspired by this observation, we introduce a method\nfor the analysis of text that takes implicitly communicated content explicitly\ninto account. We use a large language model to produce sets of propositions\nthat are inferentially related to the text that has been observed, then\nvalidate the plausibility of the generated content via human judgments.\nIncorporating these explicit representations of implicit content proves useful\nin multiple problem settings that involve the human interpretation of\nutterances: assessing the similarity of arguments, making sense of a body of\nopinion data, and modeling legislative behavior. Our results suggest that\nmodeling the meanings behind observed language, rather than the literal text\nalone, is a valuable direction for NLP and particularly its applications to\nsocial science.", "published": "2023-05-23 23:45:20", "link": "http://arxiv.org/abs/2305.14583v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CombLM: Adapting Black-Box Language Models through Small Fine-Tuned\n  Models", "abstract": "Methods for adapting language models (LMs) to new tasks and domains have\ntraditionally assumed white-box access to the model, and work by modifying its\nparameters. However, this is incompatible with a recent trend in the field,\nwhere the highest quality models are only available as black-boxes through\ninference APIs. Even when the model weights are available, the computational\ncost of fine-tuning large LMs can be prohibitive for most practitioners. In\nthis work, we present a lightweight method for adapting large LMs to new\ndomains and tasks, assuming no access to their weights or intermediate\nactivations. Our approach fine-tunes a small white-box LM and combines it with\nthe large black-box LM at the probability level through a small network,\nlearned on a small validation set. We validate our approach by adapting a large\nLM (OPT-30B) to several domains and a downstream task (machine translation),\nobserving improved performance in all cases, of up to 9%, while using a domain\nexpert 23x smaller.", "published": "2023-05-23 06:32:55", "link": "http://arxiv.org/abs/2305.16876v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decoupled Rationalization with Asymmetric Learning Rates: A Flexible\n  Lipschitz Restraint", "abstract": "A self-explaining rationalization model is generally constructed by a\ncooperative game where a generator selects the most human-intelligible pieces\nfrom the input text as rationales, followed by a predictor that makes\npredictions based on the selected rationales. However, such a cooperative game\nmay incur the degeneration problem where the predictor overfits to the\nuninformative pieces generated by a not yet well-trained generator and in turn,\nleads the generator to converge to a sub-optimal model that tends to select\nsenseless pieces. In this paper, we theoretically bridge degeneration with the\npredictor's Lipschitz continuity. Then, we empirically propose a simple but\neffective method named DR, which can naturally and flexibly restrain the\nLipschitz constant of the predictor, to address the problem of degeneration.\nThe main idea of DR is to decouple the generator and predictor to allocate them\nwith asymmetric learning rates. A series of experiments conducted on two widely\nused benchmarks have verified the effectiveness of the proposed method. Codes:\n\\href{https://github.com/jugechengzi/Rationalization-DR}{https://github.com/jugechengzi/Rationalization-DR}.", "published": "2023-05-23 02:01:13", "link": "http://arxiv.org/abs/2305.13599v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "InstructAlign: High-and-Low Resource Language Alignment via Continual\n  Crosslingual Instruction Tuning", "abstract": "Large language models (LLMs) that are tuned with instructions have\ndemonstrated remarkable capabilities in various tasks and languages. However,\ntheir ability to generalize to underrepresented languages is limited due to the\nscarcity of available data. Additionally, directly adapting new languages to\ninstruction-tuned LLMs can result in catastrophic forgetting, which leads to\nthe loss of multitasking ability. To address this issue, we propose\nInstructAlign which uses continual crosslingual instruction tuning to enable\nLLMs to align new unseen languages with previously learned high-resource\nlanguages. Our results demonstrate the effectiveness of InstructAlign in\nenabling the model to understand low-resource languages with limited parallel\ndata while preventing catastrophic forgetting. Our work contributes to the\nadvancement of language adaptation methods, particularly for adapting\ninstruction-tuned LLMs to underrepresented languages. Our code is released on\nhttps://github.com/HLTCHKUST/InstructAlign", "published": "2023-05-23 02:51:34", "link": "http://arxiv.org/abs/2305.13627v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine\n  Translation", "abstract": "Non-parametric, k-nearest-neighbor algorithms have recently made inroads to\nassist generative models such as language models and machine translation\ndecoders. We explore whether such non-parametric models can improve machine\ntranslation models at the fine-tuning stage by incorporating statistics from\nthe kNN predictions to inform the gradient updates for a baseline translation\nmodel. There are multiple methods which could be used to incorporate kNN\nstatistics and we investigate gradient scaling by a gating mechanism, the kNN's\nground truth probability, and reinforcement learning. For four standard\nin-domain machine translation datasets, compared with classic fine-tuning, we\nreport consistent improvements of all of the three methods by as much as 1.45\nBLEU and 1.28 BLEU for German-English and English-German translations\nrespectively. Through qualitative analysis, we found particular improvements\nwhen it comes to translating grammatical relations or function words, which\nresults in increased fluency of our model.", "published": "2023-05-23 03:44:06", "link": "http://arxiv.org/abs/2305.13648v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Knowledge Transfer and Iterative Pseudo-labeling for\n  Low-Resource Speech Recognition with Transducers", "abstract": "Voice technology has become ubiquitous recently. However, the accuracy, and\nhence experience, in different languages varies significantly, which makes the\ntechnology not equally inclusive. The availability of data for different\nlanguages is one of the key factors affecting accuracy, especially in training\nof all-neural end-to-end automatic speech recognition systems.\n  Cross-lingual knowledge transfer and iterative pseudo-labeling are two\ntechniques that have been shown to be successful for improving the accuracy of\nASR systems, in particular for low-resource languages, like Ukrainian.\n  Our goal is to train an all-neural Transducer-based ASR system to replace a\nDNN-HMM hybrid system with no manually annotated training data. We show that\nthe Transducer system trained using transcripts produced by the hybrid system\nachieves 18% reduction in terms of word error rate. However, using a\ncombination of cross-lingual knowledge transfer from related languages and\niterative pseudo-labeling, we are able to achieve 35% reduction of the error\nrate.", "published": "2023-05-23 03:50:35", "link": "http://arxiv.org/abs/2305.13652v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "On the Risk of Misinformation Pollution with Large Language Models", "abstract": "In this paper, we comprehensively investigate the potential misuse of modern\nLarge Language Models (LLMs) for generating credible-sounding misinformation\nand its subsequent impact on information-intensive applications, particularly\nOpen-Domain Question Answering (ODQA) systems. We establish a threat model and\nsimulate potential misuse scenarios, both unintentional and intentional, to\nassess the extent to which LLMs can be utilized to produce misinformation. Our\nstudy reveals that LLMs can act as effective misinformation generators, leading\nto a significant degradation in the performance of ODQA systems. To mitigate\nthe harm caused by LLM-generated misinformation, we explore three defense\nstrategies: prompting, misinformation detection, and majority voting. While\ninitial results show promising trends for these defensive strategies, much more\nwork needs to be done to address the challenge of misinformation pollution. Our\nwork highlights the need for further research and interdisciplinary\ncollaboration to address LLM-generated misinformation and to promote\nresponsible use of LLMs.", "published": "2023-05-23 04:10:26", "link": "http://arxiv.org/abs/2305.13661v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Grounding and Distinguishing Conceptual Vocabulary Through Similarity\n  Learning in Embodied Simulations", "abstract": "We present a novel method for using agent experiences gathered through an\nembodied simulation to ground contextualized word vectors to object\nrepresentations. We use similarity learning to make comparisons between\ndifferent object types based on their properties when interacted with, and to\nextract common features pertaining to the objects' behavior. We then use an\naffine transformation to calculate a projection matrix that transforms\ncontextualized word vectors from different transformer-based language models\ninto this learned space, and evaluate whether new test instances of transformed\ntoken vectors identify the correct concept in the object embedding space. Our\nresults expose properties of the embedding spaces of four different transformer\nmodels and show that grounding object token vectors is usually more helpful to\ngrounding verb and attribute token vectors than the reverse, which reflects\nearlier conclusions in the analogical reasoning and psycholinguistic\nliterature.", "published": "2023-05-23 04:22:00", "link": "http://arxiv.org/abs/2305.13668v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Knowledge Alignment Problem: Bridging Human and External Knowledge\n  for Large Language Models", "abstract": "Large language models often necessitate grounding on external knowledge to\ngenerate faithful and reliable answers. Yet even with the correct groundings in\nthe reference, they can ignore them and rely on wrong groundings or their\ninherent biases to hallucinate when users, being largely unaware of the\nspecifics of the stored information, pose questions that might not directly\ncorrelate with the retrieved groundings. In this work, we formulate this\nknowledge alignment problem and introduce MixAlign, a framework that interacts\nwith both the human user and the knowledge base to obtain and integrate\nclarifications on how the user question relates to the stored information.\nMixAlign employs a language model to achieve automatic knowledge alignment and,\nif necessary, further enhances this alignment through human user\nclarifications. Experimental results highlight the crucial role of knowledge\nalignment in boosting model performance and mitigating hallucination, with\nimprovements noted up to 22.2% and 27.1% respectively. We also demonstrate the\neffectiveness of MixAlign in improving knowledge alignment by producing\nhigh-quality, user-centered clarifications.", "published": "2023-05-23 04:22:50", "link": "http://arxiv.org/abs/2305.13669v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Asking Clarification Questions for Information Seeking on\n  Task-Oriented Dialogues", "abstract": "Task-oriented dialogue systems aim at providing users with task-specific\nservices. Users of such systems often do not know all the information about the\ntask they are trying to accomplish, requiring them to seek information about\nthe task. To provide accurate and personalized task-oriented information\nseeking results, task-oriented dialogue systems need to address two potential\nissues: 1) users' inability to describe their complex information needs in\ntheir requests; and 2) ambiguous/missing information the system has about the\nusers. In this paper, we propose a new Multi-Attention Seq2Seq Network, named\nMAS2S, which can ask questions to clarify the user's information needs and the\nuser's profile in task-oriented information seeking. We also extend an existing\ndataset for task-oriented information seeking, leading to the \\ourdataset which\ncontains about 100k task-oriented information seeking dialogues that are made\npublicly available\\footnote{Dataset and code is available at\n\\href{https://github.com/sweetalyssum/clarit}{https://github.com/sweetalyssum/clarit}.}.\nExperimental results on \\ourdataset show that MAS2S outperforms baselines on\nboth clarification question generation and answer prediction.", "published": "2023-05-23 04:56:04", "link": "http://arxiv.org/abs/2305.13690v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain\n  Conversations with Large Language Models", "abstract": "We propose LLM-Eval, a unified multi-dimensional automatic evaluation method\nfor open-domain conversations with large language models (LLMs). Existing\nevaluation methods often rely on human annotations, ground-truth responses, or\nmultiple LLM prompts, which can be expensive and time-consuming. To address\nthese issues, we design a single prompt-based evaluation method that leverages\na unified evaluation schema to cover multiple dimensions of conversation\nquality in a single model call. We extensively evaluate the performance of\nLLM-Eval on various benchmark datasets, demonstrating its effectiveness,\nefficiency, and adaptability compared to state-of-the-art evaluation methods.\nOur analysis also highlights the importance of choosing suitable LLMs and\ndecoding strategies for accurate evaluation results. LLM-Eval offers a\nversatile and robust solution for evaluating open-domain conversation systems,\nstreamlining the evaluation process and providing consistent performance across\ndiverse scenarios.", "published": "2023-05-23 05:57:09", "link": "http://arxiv.org/abs/2305.13711v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large\n  Language Models", "abstract": "This paper investigates the capabilities of Large Language Models (LLMs) in\nthe context of understanding their knowledge and uncertainty over questions.\nSpecifically, we focus on addressing known-unknown questions, characterized by\nhigh uncertainty due to the absence of definitive answers. To facilitate our\nstudy, we collect a new dataset with Known-Unknown Questions (KUQ) and\nestablish a categorization framework to clarify the origins of uncertainty in\nsuch queries. Subsequently, we examine the performance of open-source LLMs,\nfine-tuned using this dataset, in distinguishing between known and unknown\nqueries within open-ended question-answering scenarios. The fine-tuned models\ndemonstrated a significant improvement, achieving a considerable increase in\nF1-score relative to their pre-fine-tuning state. Through a comprehensive\nanalysis, we reveal insights into the models' improved uncertainty articulation\nand their consequent efficacy in multi-agent debates. These findings help us\nunderstand how LLMs can be trained to identify and express uncertainty,\nimproving our knowledge of how they understand and express complex or unclear\ninformation.", "published": "2023-05-23 05:59:21", "link": "http://arxiv.org/abs/2305.13712v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Continual Dialogue State Tracking via Example-Guided Question Answering", "abstract": "Dialogue systems are frequently updated to accommodate new services, but\nnaively updating them by continually training with data for new services in\ndiminishing performance on previously learnt services. Motivated by the insight\nthat dialogue state tracking (DST), a crucial component of dialogue systems\nthat estimates the user's goal as a conversation proceeds, is a simple natural\nlanguage understanding task, we propose reformulating it as a bundle of\ngranular example-guided question answering tasks to minimize the task shift\nbetween services and thus benefit continual learning. Our approach alleviates\nservice-specific memorization and teaches a model to contextualize the given\nquestion and example to extract the necessary information from the\nconversation. We find that a model with just 60M parameters can achieve a\nsignificant boost by learning to learn from in-context examples retrieved by a\nretriever trained to identify turns with similar dialogue state changes.\nCombining our method with dialogue-level memory replay, our approach attains\nstate of the art performance on DST continual learning metrics without relying\non any complex regularization or parameter expansion methods.", "published": "2023-05-23 06:15:43", "link": "http://arxiv.org/abs/2305.13721v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Conversational Recommendation as Retrieval: A Simple, Strong Baseline", "abstract": "Conversational recommendation systems (CRS) aim to recommend suitable items\nto users through natural language conversation. However, most CRS approaches do\nnot effectively utilize the signal provided by these conversations. They rely\nheavily on explicit external knowledge e.g., knowledge graphs to augment the\nmodels' understanding of the items and attributes, which is quite hard to\nscale. To alleviate this, we propose an alternative information retrieval\n(IR)-styled approach to the CRS item recommendation task, where we represent\nconversations as queries and items as documents to be retrieved. We expand the\ndocument representation used for retrieval with conversations from the training\nset. With a simple BM25-based retriever, we show that our task formulation\ncompares favorably with much more complex baselines using complex external\nknowledge on a popular CRS benchmark. We demonstrate further improvements using\nuser-centric modeling and data augmentation to counter the cold start problem\nfor CRSs.", "published": "2023-05-23 06:21:31", "link": "http://arxiv.org/abs/2305.13725v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Topic-driven Distant Supervision Framework for Macro-level Discourse\n  Parsing", "abstract": "Discourse parsing, the task of analyzing the internal rhetorical structure of\ntexts, is a challenging problem in natural language processing. Despite the\nrecent advances in neural models, the lack of large-scale, high-quality corpora\nfor training remains a major obstacle. Recent studies have attempted to\novercome this limitation by using distant supervision, which utilizes results\nfrom other NLP tasks (e.g., sentiment polarity, attention matrix, and\nsegmentation probability) to parse discourse trees. However, these methods do\nnot take into account the differences between in-domain and out-of-domain\ntasks, resulting in lower performance and inability to leverage the\nhigh-quality in-domain data for further improvement. To address these issues,\nwe propose a distant supervision framework that leverages the relations between\ntopic structure and rhetorical structure. Specifically, we propose two\ndistantly supervised methods, based on transfer learning and the\nteacher-student model, that narrow the gap between in-domain and out-of-domain\ntasks through label mapping and oracle annotation. Experimental results on the\nMCDTB and RST-DT datasets show that our methods achieve the best performance in\nboth distant-supervised and supervised scenarios.", "published": "2023-05-23 07:13:51", "link": "http://arxiv.org/abs/2305.13755v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Concept-aware Training Improves In-context Learning Ability of Language\n  Models", "abstract": "Many recent language models (LMs) of Transformers family exhibit so-called\nin-context learning (ICL) ability, manifested in the LMs' ability to modulate\ntheir function by a task described in a natural language input. Previous work\ncurating these models assumes that ICL emerges from vast over-parametrization\nor the scale of multi-task training. However, a complementary branch of recent\ntheoretical work attributes ICL emergence to specific properties of training\ndata and creates functional in-context learners in small-scale, synthetic\nsettings.\n  Inspired by recent findings on data properties driving the emergence of ICL,\nwe propose a method to create LMs able to better utilize the in-context\ninformation, by constructing training scenarios where it is beneficial for the\nLM to capture the analogical reasoning concepts. We measure that data sampling\nof Concept-aware Training (CoAT) consistently improves models' reasoning\nability. As a result, the in-context learners trained with CoAT on only two\ndatasets of a single (QA) task perform comparably to larger models trained on\n1600+ tasks.", "published": "2023-05-23 07:44:52", "link": "http://arxiv.org/abs/2305.13775v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Counterspeeches up my sleeve! Intent Distribution Learning and\n  Persistent Fusion for Intent-Conditioned Counterspeech Generation", "abstract": "Counterspeech has been demonstrated to be an efficacious approach for\ncombating hate speech. While various conventional and controlled approaches\nhave been studied in recent years to generate counterspeech, a counterspeech\nwith a certain intent may not be sufficient in every scenario. Due to the\ncomplex and multifaceted nature of hate speech, utilizing multiple forms of\ncounter-narratives with varying intents may be advantageous in different\ncircumstances. In this paper, we explore intent-conditioned counterspeech\ngeneration. At first, we develop IntentCONAN, a diversified intent-specific\ncounterspeech dataset with 6831 counterspeeches conditioned on five intents,\ni.e., informative, denouncing, question, positive, and humour. Subsequently, we\npropose QUARC, a two-stage framework for intent-conditioned counterspeech\ngeneration. QUARC leverages vector-quantized representations learned for each\nintent category along with PerFuMe, a novel fusion module to incorporate\nintent-specific information into the model. Our evaluation demonstrates that\nQUARC outperforms several baselines by an average of 10% across evaluation\nmetrics. An extensive human evaluation supplements our hypothesis of better and\nmore appropriate responses than comparative systems.", "published": "2023-05-23 07:45:17", "link": "http://arxiv.org/abs/2305.13776v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can Large Language Models Capture Dissenting Human Voices?", "abstract": "Large language models (LLMs) have shown impressive achievements in solving a\nbroad range of tasks. Augmented by instruction fine-tuning, LLMs have also been\nshown to generalize in zero-shot settings as well. However, whether LLMs\nclosely align with the human disagreement distribution has not been\nwell-studied, especially within the scope of natural language inference (NLI).\nIn this paper, we evaluate the performance and alignment of LLM distribution\nwith humans using two different techniques to estimate the multinomial\ndistribution: Monte Carlo Estimation (MCE) and Log Probability Estimation\n(LPE). As a result, we show LLMs exhibit limited ability in solving NLI tasks\nand simultaneously fail to capture human disagreement distribution. The\ninference and human alignment performances plunge even further on data samples\nwith high human disagreement levels, raising concerns about their natural\nlanguage understanding (NLU) ability and their representativeness to a larger\nhuman population. The source code for the experiments is available at\nhttps://github.com/xfactlab/emnlp2023-LLM-Disagreement", "published": "2023-05-23 07:55:34", "link": "http://arxiv.org/abs/2305.13788v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Personalized Predictive ASR for Latency Reduction in Voice Assistants", "abstract": "Streaming Automatic Speech Recognition (ASR) in voice assistants can utilize\nprefetching to partially hide the latency of response generation. Prefetching\ninvolves passing a preliminary ASR hypothesis to downstream systems in order to\nprefetch and cache a response. If the final ASR hypothesis after endpoint\ndetection matches the preliminary one, the cached response can be delivered to\nthe user, thus saving latency. In this paper, we extend this idea by\nintroducing predictive automatic speech recognition, where we predict the full\nutterance from a partially observed utterance, and prefetch the response based\non the predicted utterance. We introduce two personalization approaches and\ninvestigate the tradeoff between potential latency gains from successful\npredictions and the cost increase from failed predictions. We evaluate our\nmethods on an internal voice assistant dataset as well as the public SLURP\ndataset.", "published": "2023-05-23 08:05:43", "link": "http://arxiv.org/abs/2305.13794v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for\n  Improved Vision-Language Compositionality", "abstract": "Contrastively trained vision-language models have achieved remarkable\nprogress in vision and language representation learning, leading to\nstate-of-the-art models for various downstream multimodal tasks. However,\nrecent research has highlighted severe limitations of these models in their\nability to perform compositional reasoning over objects, attributes, and\nrelations. Scene graphs have emerged as an effective way to understand images\ncompositionally. These are graph-structured semantic representations of images\nthat contain objects, their attributes, and relations with other objects in a\nscene. In this work, we consider the scene graph parsed from text as a proxy\nfor the image scene graph and propose a graph decomposition and augmentation\nframework along with a coarse-to-fine contrastive learning objective between\nimages and text that aligns sentences of various complexities to the same\nimage. Along with this, we propose novel negative mining techniques in the\nscene graph space for improving attribute binding and relation understanding.\nThrough extensive experiments, we demonstrate the effectiveness of our approach\nthat significantly improves attribute binding, relation understanding,\nsystematic generalization, and productivity on multiple recently proposed\nbenchmarks (For example, improvements upto $18\\%$ for systematic\ngeneralization, $16.5\\%$ for relation understanding over a strong baseline),\nwhile achieving similar or better performance than CLIP on various general\nmultimodal tasks.", "published": "2023-05-23 08:28:38", "link": "http://arxiv.org/abs/2305.13812v3", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Global Structure Knowledge-Guided Relation Extraction Method for\n  Visually-Rich Document", "abstract": "Visual Relation Extraction (VRE) is a powerful means of discovering\nrelationships between entities within visually-rich documents. Existing methods\noften focus on manipulating entity features to find pairwise relations, yet\nneglect the more fundamental structural information that links disparate entity\npairs together. The absence of global structure information may make the model\nstruggle to learn long-range relations and easily predict conflicted results.\nTo alleviate such limitations, we propose a GlObal Structure knowledge-guided\nrelation Extraction (GOSE) framework. GOSE initiates by generating preliminary\nrelation predictions on entity pairs extracted from a scanned image of the\ndocument. Subsequently, global structural knowledge is captured from the\npreceding iterative predictions, which are then incorporated into the\nrepresentations of the entities. This \"generate-capture-incorporate\" cycle is\nrepeated multiple times, allowing entity representations and global structure\nknowledge to be mutually reinforced. Extensive experiments validate that GOSE\nnot only outperforms existing methods in the standard fine-tuning setting but\nalso reveals superior cross-lingual learning capabilities; indeed, even yields\nstronger data-efficient performance in the low-resource setting. The code for\nGOSE will be available at https://github.com/chenxn2020/GOSE.", "published": "2023-05-23 09:18:47", "link": "http://arxiv.org/abs/2305.13850v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NarrativeXL: A Large-scale Dataset For Long-Term Memory Models", "abstract": "We propose a new large-scale (nearly a million questions) ultra-long-context\n(more than 50,000 words average document length) reading comprehension dataset.\nUsing GPT 3.5, we summarized each scene in 1,500 hand-curated fiction books\nfrom Project Gutenberg, which resulted in approximately 150 scene-level\nsummaries per book. After that, we created a number of reading comprehension\nquestions based on these summaries, including three types of multiple-choice\nscene recognition questions, as well as free-form narrative reconstruction\nquestions. With 990,595 total questions, our dataset is an order of magnitude\nlarger than the closest alternatives. Crucially, most questions have a known\n``retention demand'', indicating how long-term of a memory is needed to answer\nthem, which should aid long-term memory performance evaluation. We validate our\ndata in four small-scale experiments: one with human labelers, and three with\nexisting language models. We show that our questions 1) adequately represent\nthe source material 2) can be used to diagnose a model's memory capacity 3) are\nnot trivial for modern language models even when the memory demand does not\nexceed those models' context lengths. Lastly, we provide our code which can be\nused to further expand the dataset with minimal human labor.", "published": "2023-05-23 09:55:32", "link": "http://arxiv.org/abs/2305.13877v2", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Sequence-Level Knowledge Distillation for Class-Incremental End-to-End\n  Spoken Language Understanding", "abstract": "The ability to learn new concepts sequentially is a major weakness for modern\nneural networks, which hinders their use in non-stationary environments. Their\npropensity to fit the current data distribution to the detriment of the past\nacquired knowledge leads to the catastrophic forgetting issue. In this work we\ntackle the problem of Spoken Language Understanding applied to a continual\nlearning setting. We first define a class-incremental scenario for the SLURP\ndataset. Then, we propose three knowledge distillation (KD) approaches to\nmitigate forgetting for a sequence-to-sequence transformer model: the first KD\nmethod is applied to the encoder output (audio-KD), and the other two work on\nthe decoder output, either directly on the token-level (tok-KD) or on the\nsequence-level (seq-KD) distributions. We show that the seq-KD substantially\nimproves all the performance metrics, and its combination with the audio-KD\nfurther decreases the average WER and enhances the entity prediction metric.", "published": "2023-05-23 10:24:07", "link": "http://arxiv.org/abs/2305.13899v2", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Let's Think Frame by Frame with VIP: A Video Infilling and Prediction\n  Dataset for Evaluating Video Chain-of-Thought", "abstract": "Despite exciting recent results showing vision-language systems' capacity to\nreason about images using natural language, their capacity for video reasoning\nremains under-explored. We motivate framing video reasoning as the sequential\nunderstanding of a small number of keyframes, thereby leveraging the power and\nrobustness of vision-language while alleviating the computational complexities\nof processing videos. To evaluate this novel application, we introduce VIP, an\ninference-time challenge dataset designed to explore models' reasoning\ncapabilities through video chain-of-thought. Inspired by visually descriptive\nscene plays, we propose two formats for keyframe description: unstructured\ndense captions and structured scene descriptions that identify the focus,\naction, mood, objects, and setting (FAMOuS) of the keyframe. To evaluate video\nreasoning, we propose two tasks: Video Infilling and Video Prediction, which\ntest abilities to generate multiple intermediate keyframes and predict future\nkeyframes, respectively. We benchmark GPT-4, GPT-3, and VICUNA on VIP,\ndemonstrate the performance gap in these complex video reasoning tasks, and\nencourage future work to prioritize language models for efficient and\ngeneralized video reasoning.", "published": "2023-05-23 10:26:42", "link": "http://arxiv.org/abs/2305.13903v3", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "DAPR: A Benchmark on Document-Aware Passage Retrieval", "abstract": "The work of neural retrieval so far focuses on ranking short texts and is\nchallenged with long documents. There are many cases where the users want to\nfind a relevant passage within a long document from a huge corpus, e.g.\nWikipedia articles, research papers, etc. We propose and name this task\n\\emph{Document-Aware Passage Retrieval} (DAPR). While analyzing the errors of\nthe State-of-The-Art (SoTA) passage retrievers, we find the major errors\n(53.5\\%) are due to missing document context. This drives us to build a\nbenchmark for this task including multiple datasets from heterogeneous domains.\nIn the experiments, we extend the SoTA passage retrievers with document context\nvia (1) hybrid retrieval with BM25 and (2) contextualized passage\nrepresentations, which inform the passage representation with document context.\nWe find despite that hybrid retrieval performs the strongest on the mixture of\nthe easy and the hard queries, it completely fails on the hard queries that\nrequire document-context understanding. On the other hand, contextualized\npassage representations (e.g. prepending document titles) achieve good\nimprovement on these hard queries, but overall they also perform rather poorly.\nOur created benchmark enables future research on developing and comparing\nretrieval systems for the new task. The code and the data are available at\nhttps://github.com/UKPLab/arxiv2023-dapr.", "published": "2023-05-23 10:39:57", "link": "http://arxiv.org/abs/2305.13915v4", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Generating Data for Symbolic Language with Large Language Models", "abstract": "While large language models (LLMs) bring not only performance but also\ncomplexity, recent work has started to turn LLMs into data generators rather\nthan task inferencers, where another affordable task model is trained for\nefficient deployment and inference. However, such an approach has primarily\nbeen applied to natural language tasks and has not yet been explored for\nsymbolic language tasks with complex structured outputs (e.g., semantic parsing\nand code generation). In this paper, we propose SymGen which utilizes LLMs for\ngenerating various annotation-expensive symbolic language data. SymGen consists\nof an informative prompt to steer generation and an agreement-based verifier to\nimprove data correctness. We conduct extensive experiments on six symbolic\nlanguage tasks across various settings. Compared with the LLMs, we demonstrate\nthe 1\\%-sized task model can achieve comparable or better performance, largely\ncutting inference and deployment costs. We also show that generated data with\nonly a few human demonstrations can be as effective as over 10 times the amount\nof human-annotated data when training the task model, saving a considerable\namount of annotation effort. SymGen sheds new light on data generation for\ncomplex tasks, and we release the code at\n\\href{https://github.com/HKUNLP/SymGen}{https://github.com/HKUNLP/SymGen}.", "published": "2023-05-23 10:44:00", "link": "http://arxiv.org/abs/2305.13917v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Robust Prompt Optimization for Large Language Models Against\n  Distribution Shifts", "abstract": "Large Language Model (LLM) has demonstrated significant ability in various\nNatural Language Processing tasks. However, their effectiveness is highly\ndependent on the phrasing of the task prompt, leading to research on automatic\nprompt optimization using labeled task data. We reveal that these prompt\noptimization techniques are vulnerable to distribution shifts such as\nsubpopulation shifts, which are common for LLMs in real-world scenarios such as\ncustomer reviews analysis. In this light, we propose a new problem of robust\nprompt optimization for LLMs against distribution shifts, which requires the\nprompt optimized over the labeled source group can simultaneously generalize to\nan unlabeled target group. To solve this problem, we propose Generalized Prompt\nOptimization framework, which incorporates the unlabeled data from the target\ngroup into prompt optimization. Extensive experimental results demonstrate the\neffectiveness of the proposed framework with significant performance\nimprovement on the target group and comparable performance on the source group.", "published": "2023-05-23 11:30:43", "link": "http://arxiv.org/abs/2305.13954v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Preserving Knowledge Invariance: Rethinking Robustness Evaluation of\n  Open Information Extraction", "abstract": "The robustness to distribution changes ensures that NLP models can be\nsuccessfully applied in the realistic world, especially for information\nextraction tasks. However, most prior evaluation benchmarks have been devoted\nto validating pairwise matching correctness, ignoring the crucial measurement\nof robustness. In this paper, we present the first benchmark that simulates the\nevaluation of open information extraction models in the real world, where the\nsyntactic and expressive distributions under the same knowledge meaning may\ndrift variously. We design and annotate a large-scale testbed in which each\nexample is a knowledge-invariant clique that consists of sentences with\nstructured knowledge of the same meaning but with different syntactic and\nexpressive forms. By further elaborating the robustness metric, a model is\njudged to be robust if its performance is consistently accurate on the overall\ncliques. We perform experiments on typical models published in the last decade\nas well as a popular large language model, the results show that the existing\nsuccessful models exhibit a frustrating degradation, with a maximum drop of\n23.43 F1 score. Our resources and code are available at\nhttps://github.com/qijimrc/ROBUST.", "published": "2023-05-23 12:05:09", "link": "http://arxiv.org/abs/2305.13981v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards A Unified View of Sparse Feed-Forward Network in Pretraining\n  Large Language Model", "abstract": "Large and sparse feed-forward layers (S-FFN) such as Mixture-of-Experts (MoE)\nhave proven effective in scaling up Transformers model size for\n\\textit{pretraining} large language models. By only activating part of the FFN\nparameters conditioning on input, S-FFN improves generalization performance\nwhile keeping training and inference costs (in FLOPs) fixed. In this work, we\nanalyzed two major design choices of S-FFN: the memory block (a.k.a. expert)\nsize and the memory block selection method under a general conceptual framework\nof sparse neural memory. Using this unified framework, we compare several S-FFN\narchitectures for language modeling and provide insights into their relative\nefficacy and efficiency. We found a simpler selection method --\n\\textbf{\\texttt{Avg-K}} that selects blocks through their mean aggregated\nhidden states, achieving lower perplexity in language model pretraining\ncompared to existing MoE architectures including Switch Transformer (Fedus et\nal., 2021) and HashLayer (Roller et al., 2021).", "published": "2023-05-23 12:28:37", "link": "http://arxiv.org/abs/2305.13999v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Does ChatGPT have Theory of Mind?", "abstract": "Theory of Mind (ToM) is the ability to understand human thinking and\ndecision-making, an ability that plays a crucial role in social interaction\nbetween people, including linguistic communication. This paper investigates to\nwhat extent recent Large Language Models in the ChatGPT tradition possess ToM.\nWe posed six well-known problems that address biases in human reasoning and\ndecision making to two versions of ChatGPT and we compared the results under a\nrange of prompting strategies. While the results concerning ChatGPT-3 were\nsomewhat inconclusive, ChatGPT-4 was shown to arrive at the correct answers\nmore often than would be expected based on chance, although correct answers\nwere often arrived at on the basis of false assumptions or invalid reasoning.", "published": "2023-05-23 12:55:21", "link": "http://arxiv.org/abs/2305.14020v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can Language Models Understand Physical Concepts?", "abstract": "Language models~(LMs) gradually become general-purpose interfaces in the\ninteractive and embodied world, where the understanding of physical concepts is\nan essential prerequisite. However, it is not yet clear whether LMs can\nunderstand physical concepts in the human world. To investigate this, we design\na benchmark VEC that covers the tasks of (i) Visual concepts, such as the shape\nand material of objects, and (ii) Embodied Concepts, learned from the\ninteraction with the world such as the temperature of objects. Our zero\n(few)-shot prompting results show that the understanding of certain visual\nconcepts emerges as scaling up LMs, but there are still basic concepts to which\nthe scaling law does not apply. For example, OPT-175B performs close to humans\nwith a zero-shot accuracy of 85\\% on the material concept, yet behaves like\nrandom guessing on the mass concept. Instead, vision-augmented LMs such as CLIP\nand BLIP achieve a human-level understanding of embodied concepts. Analysis\nindicates that the rich semantics in visual representation can serve as a\nvaluable source of embodied knowledge. Inspired by this, we propose a\ndistillation method to transfer embodied knowledge from VLMs to LMs, achieving\nperformance gain comparable with that by scaling up the parameters of LMs 134x.\nOur dataset is available at \\url{https://github.com/TobiasLee/VEC}", "published": "2023-05-23 13:36:55", "link": "http://arxiv.org/abs/2305.14057v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Counterfactual Augmentation for Multimodal Learning Under Presentation\n  Bias", "abstract": "In real-world machine learning systems, labels are often derived from user\nbehaviors that the system wishes to encourage. Over time, new models must be\ntrained as new training examples and features become available. However,\nfeedback loops between users and models can bias future user behavior, inducing\na presentation bias in the labels that compromises the ability to train new\nmodels. In this paper, we propose counterfactual augmentation, a novel causal\nmethod for correcting presentation bias using generated counterfactual labels.\nOur empirical evaluations demonstrate that counterfactual augmentation yields\nbetter downstream performance compared to both uncorrected models and existing\nbias-correction methods. Model analyses further indicate that the generated\ncounterfactuals align closely with true counterfactuals in an oracle setting.", "published": "2023-05-23 14:09:47", "link": "http://arxiv.org/abs/2305.14083v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "BM25 Query Augmentation Learned End-to-End", "abstract": "Given BM25's enduring competitiveness as an information retrieval baseline,\nwe investigate to what extent it can be even further improved by augmenting and\nre-weighting its sparse query-vector representation. We propose an approach to\nlearning an augmentation and a re-weighting end-to-end, and we find that our\napproach improves performance over BM25 while retaining its speed. We\nfurthermore find that the learned augmentations and re-weightings transfer well\nto unseen datasets.", "published": "2023-05-23 14:11:42", "link": "http://arxiv.org/abs/2305.14087v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Revisiting Acceptability Judgements", "abstract": "In this work, we revisit linguistic acceptability in the context of large\nlanguage models. We introduce CoLAC - Corpus of Linguistic Acceptability in\nChinese, the first large-scale acceptability dataset for a non-Indo-European\nlanguage. It is verified by native speakers and is the first acceptability\ndataset that comes with two sets of labels: a linguist label and a crowd label.\nOur experiments show that even the largest InstructGPT model performs only at\nchance level on CoLAC, while ChatGPT's performance (48.30 MCC) is also much\nbelow supervised models (59.03 MCC) and human (65.11 MCC). Through\ncross-lingual transfer experiments and fine-grained linguistic analysis, we\nprovide detailed analysis of the model predictions and demonstrate for the\nfirst time that knowledge of linguistic acceptability can be transferred across\ntypologically distinct languages, as well as be traced back to pre-training.\nOur dataset is publicly available at\n\\url{https://github.com/huhailinguist/CoLAC}.", "published": "2023-05-23 14:16:22", "link": "http://arxiv.org/abs/2305.14091v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Out-of-Distribution Generalization in Text Classification: Past,\n  Present, and Future", "abstract": "Machine learning (ML) systems in natural language processing (NLP) face\nsignificant challenges in generalizing to out-of-distribution (OOD) data, where\nthe test distribution differs from the training data distribution. This poses\nimportant questions about the robustness of NLP models and their high accuracy,\nwhich may be artificially inflated due to their underlying sensitivity to\nsystematic biases. Despite these challenges, there is a lack of comprehensive\nsurveys on the generalization challenge from an OOD perspective in text\nclassification. Therefore, this paper aims to fill this gap by presenting the\nfirst comprehensive review of recent progress, methods, and evaluations on this\ntopic. We furth discuss the challenges involved and potential future research\ndirections. By providing quick access to existing work, we hope this survey\nwill encourage future research in this area.", "published": "2023-05-23 14:26:11", "link": "http://arxiv.org/abs/2305.14104v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CTQScorer: Combining Multiple Features for In-context Example Selection\n  for Machine Translation", "abstract": "Large language models have demonstrated the capability to perform on machine\ntranslation when the input is prompted with a few examples (in-context\nlearning). Translation quality depends on various features of the selected\nexamples, such as their quality and relevance, but previous work has\npredominantly focused on individual features in isolation. In this paper, we\npropose a general framework for combining different features influencing\nexample selection. We learn a regression model, CTQ Scorer (Contextual\nTranslation Quality), that selects examples based on multiple features in order\nto maximize the translation quality. On multiple language pairs and language\nmodels, we show that CTQ Scorer helps significantly outperform random selection\nas well as strong single-factor baselines reported in the literature. We also\nsee an improvement of over 2.5 COMET points on average with respect to a strong\nBM25 retrieval-based baseline.", "published": "2023-05-23 14:26:17", "link": "http://arxiv.org/abs/2305.14105v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "To Copy Rather Than Memorize: A Vertical Learning Paradigm for Knowledge\n  Graph Completion", "abstract": "Embedding models have shown great power in knowledge graph completion (KGC)\ntask. By learning structural constraints for each training triple, these\nmethods implicitly memorize intrinsic relation rules to infer missing links.\nHowever, this paper points out that the multi-hop relation rules are hard to be\nreliably memorized due to the inherent deficiencies of such implicit\nmemorization strategy, making embedding models underperform in predicting links\nbetween distant entity pairs. To alleviate this problem, we present Vertical\nLearning Paradigm (VLP), which extends embedding models by allowing to\nexplicitly copy target information from related factual triples for more\naccurate prediction. Rather than solely relying on the implicit memory, VLP\ndirectly provides additional cues to improve the generalization ability of\nembedding models, especially making the distant link prediction significantly\neasier. Moreover, we also propose a novel relative distance based negative\nsampling technique (ReD) for more effective optimization. Experiments\ndemonstrate the validity and generality of our proposals on two standard\nbenchmarks. Our code is available at https://github.com/rui9812/VLP.", "published": "2023-05-23 14:53:20", "link": "http://arxiv.org/abs/2305.14126v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dr.ICL: Demonstration-Retrieved In-context Learning", "abstract": "In-context learning (ICL), teaching a large language model (LLM) to perform a\ntask with few-shot demonstrations rather than adjusting the model parameters,\nhas emerged as a strong paradigm for using LLMs. While early studies primarily\nused a fixed or random set of demonstrations for all test queries, recent\nresearch suggests that retrieving semantically similar demonstrations to the\ninput from a pool of available demonstrations results in better performance.\nThis work expands the applicability of retrieval-based ICL approaches by\ndemonstrating that even simple word-overlap similarity measures such as BM25\noutperform randomly selected demonstrations. Furthermore, we extend the success\nof retrieval-based ICL to instruction-finetuned LLMs as well as\nChain-of-Thought (CoT) prompting. For instruction-finetuned LLMs, we find that\nalthough a model has already seen the training data at training time,\nretrieving demonstrations from the training data at test time yields better\nresults compared to using no demonstrations or random demonstrations. Last but\nnot least, we train a task-specific demonstration retriever that outperforms\noff-the-shelf retrievers.", "published": "2023-05-23 14:55:25", "link": "http://arxiv.org/abs/2305.14128v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WYWEB: A NLP Evaluation Benchmark For Classical Chinese", "abstract": "To fully evaluate the overall performance of different NLP models in a given\ndomain, many evaluation benchmarks are proposed, such as GLUE, SuperGLUE and\nCLUE. The fi eld of natural language understanding has traditionally focused on\nbenchmarks for various tasks in languages such as Chinese, English, and\nmultilingua, however, there has been a lack of attention given to the area of\nclassical Chinese, also known as \"wen yan wen\", which has a rich history\nspanning thousands of years and holds signifi cant cultural and academic value.\nFor the prosperity of the NLP community, in this paper, we introduce the WYWEB\nevaluation benchmark, which consists of nine NLP tasks in classical Chinese,\nimplementing sentence classifi cation, sequence labeling, reading\ncomprehension, and machine translation. We evaluate the existing pre-trained\nlanguage models, which are all struggling with this benchmark. We also\nintroduce a number of supplementary datasets and additional tools to help\nfacilitate further progress on classical Chinese NLU. The github repository is\nhttps://github.com/baudzhou/WYWEB.", "published": "2023-05-23 15:15:11", "link": "http://arxiv.org/abs/2305.14150v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Label Words are Anchors: An Information Flow Perspective for\n  Understanding In-Context Learning", "abstract": "In-context learning (ICL) emerges as a promising capability of large language\nmodels (LLMs) by providing them with demonstration examples to perform diverse\ntasks. However, the underlying mechanism of how LLMs learn from the provided\ncontext remains under-explored. In this paper, we investigate the working\nmechanism of ICL through an information flow lens. Our findings reveal that\nlabel words in the demonstration examples function as anchors: (1) semantic\ninformation aggregates into label word representations during the shallow\ncomputation layers' processing; (2) the consolidated information in label words\nserves as a reference for LLMs' final predictions. Based on these insights, we\nintroduce an anchor re-weighting method to improve ICL performance, a\ndemonstration compression technique to expedite inference, and an analysis\nframework for diagnosing ICL errors in GPT2-XL. The promising applications of\nour findings again validate the uncovered ICL working mechanism and pave the\nway for future studies.", "published": "2023-05-23 15:26:20", "link": "http://arxiv.org/abs/2305.14160v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging Open Information Extraction for More Robust Domain Transfer\n  of Event Trigger Detection", "abstract": "Event detection is a crucial information extraction task in many domains,\nsuch as Wikipedia or news. The task typically relies on trigger detection (TD)\n-- identifying token spans in the text that evoke specific events. While the\nnotion of triggers should ideally be universal across domains, domain transfer\nfor TD from high- to low-resource domains results in significant performance\ndrops. We address the problem of negative transfer in TD by coupling triggers\nbetween domains using subject-object relations obtained from a rule-based open\ninformation extraction (OIE) system. We demonstrate that OIE relations injected\nthrough multi-task training can act as mediators between triggers in different\ndomains, enhancing zero- and few-shot TD domain transfer and reducing\nperformance drops, in particular when transferring from a high-resource source\ndomain (Wikipedia) to a low(er)-resource target domain (news). Additionally, we\ncombine this improved transfer with masked language modeling on the target\ndomain, observing further TD transfer gains. Finally, we demonstrate that the\ngains are robust to the choice of the OIE system.", "published": "2023-05-23 15:27:35", "link": "http://arxiv.org/abs/2305.14163v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EASE: An Easily-Customized Annotation System Powered by Efficiency\n  Enhancement Mechanisms", "abstract": "The performance of current supervised AI systems is tightly connected to the\navailability of annotated datasets. Annotations are usually collected through\nannotation tools, which are often designed for specific tasks and are difficult\nto customize. Moreover, existing annotation tools with an active learning\nmechanism often only support limited use cases. To address these limitations,\nwe present EASE, an Easily-Customized Annotation System Powered by Efficiency\nEnhancement Mechanisms. \\sysname provides modular annotation units for building\ncustomized annotation interfaces and also provides multiple back-end options\nthat suggest annotations using (1) multi-task active learning; (2) demographic\nfeature based active learning; (3) a prompt system that can query the API of\nlarge language models. We conduct multiple experiments and user studies to\nevaluate our system's flexibility and effectiveness. Our results show that our\nsystem can meet the diverse needs of NLP researchers and significantly\naccelerate the annotation process.", "published": "2023-05-23 15:38:37", "link": "http://arxiv.org/abs/2305.14169v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Beyond Shared Vocabulary: Increasing Representational Word Similarities\n  across Languages for Multilingual Machine Translation", "abstract": "Using a vocabulary that is shared across languages is common practice in\nMultilingual Neural Machine Translation (MNMT). In addition to its simple\ndesign, shared tokens play an important role in positive knowledge transfer,\nassuming that shared tokens refer to similar meanings across languages.\nHowever, when word overlap is small, especially due to different writing\nsystems, transfer is inhibited. In this paper, we define word-level information\ntransfer pathways via word equivalence classes and rely on graph networks to\nfuse word embeddings across languages. Our experiments demonstrate the\nadvantages of our approach: 1) embeddings of words with similar meanings are\nbetter aligned across languages, 2) our method achieves consistent BLEU\nimprovements of up to 2.3 points for high- and low-resource MNMT, and 3) less\nthan 1.0\\% additional trainable parameters are required with a limited increase\nin computational costs, while inference time remains identical to the baseline.\nWe release the codebase to the community.", "published": "2023-05-23 16:11:00", "link": "http://arxiv.org/abs/2305.14189v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HumBEL: A Human-in-the-Loop Approach for Evaluating Demographic Factors\n  of Language Models in Human-Machine Conversations", "abstract": "While demographic factors like age and gender change the way people talk, and\nin particular, the way people talk to machines, there is little investigation\ninto how large pre-trained language models (LMs) can adapt to these changes. To\nremedy this gap, we consider how demographic factors in LM language skills can\nbe measured to determine compatibility with a target demographic. We suggest\nclinical techniques from Speech Language Pathology, which has norms for\nacquisition of language skills in humans. We conduct evaluation with a domain\nexpert (i.e., a clinically licensed speech language pathologist), and also\npropose automated techniques to complement clinical evaluation at scale.\nEmpirically, we focus on age, finding LM capability varies widely depending on\ntask: GPT-3.5 mimics the ability of humans ranging from age 6-15 at tasks\nrequiring inference, and simultaneously, outperforms a typical 21 year old at\nmemorization. GPT-3.5 also has trouble with social language use, exhibiting\nless than 50% of the tested pragmatic skills. Findings affirm the importance of\nconsidering demographic alignment and conversational goals when using LMs as\npublic-facing tools. Code, data, and a package will be available.", "published": "2023-05-23 16:15:24", "link": "http://arxiv.org/abs/2305.14195v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Accessing Higher Dimensions for Unsupervised Word Translation", "abstract": "The striking ability of unsupervised word translation has been demonstrated\nwith the help of word vectors / pretraining; however, they require large\namounts of data and usually fails if the data come from different domains. We\npropose coocmap, a method that can use either high-dimensional co-occurrence\ncounts or their lower-dimensional approximations. Freed from the limits of low\ndimensions, we show that relying on low-dimensional vectors and their\nincidental properties miss out on better denoising methods and useful world\nknowledge in high dimensions, thus stunting the potential of the data. Our\nresults show that unsupervised translation can be achieved more easily and\nrobustly than previously thought -- less than 80MB and minutes of CPU time is\nrequired to achieve over 50\\% accuracy for English to Finnish, Hungarian, and\nChinese translations when trained on similar data; even under domain mismatch,\nwe show coocmap still works fully unsupervised on English NewsCrawl to Chinese\nWikipedia and English Europarl to Spanish Wikipedia, among others. These\nresults challenge prevailing assumptions on the necessity and superiority of\nlow-dimensional vectors, and suggest that similarly processed co-occurrences\ncan outperform dense vectors on other tasks too.", "published": "2023-05-23 16:19:30", "link": "http://arxiv.org/abs/2305.14200v1", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Domain Private Transformers for Multi-Domain Dialog Systems", "abstract": "Large, general purpose language models have demonstrated impressive\nperformance across many different conversational domains. While multi-domain\nlanguage models achieve low overall perplexity, their outputs are not\nguaranteed to stay within the domain of a given input prompt. This paper\nproposes domain privacy as a novel way to quantify how likely a conditional\nlanguage model will leak across domains. We also develop policy functions based\non token-level domain classification, and propose an efficient fine-tuning\nmethod to improve the trained model's domain privacy. Experiments on membership\ninference attacks show that our proposed method has comparable resiliency to\nmethods adapted from recent literature on differentially private language\nmodels.", "published": "2023-05-23 16:27:12", "link": "http://arxiv.org/abs/2305.14208v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Skill-Based Few-Shot Selection for In-Context Learning", "abstract": "In-context learning is the paradigm that adapts large language models to\ndownstream tasks by providing a few examples. Few-shot selection -- selecting\nappropriate examples for each test instance separately -- is important for\nin-context learning. In this paper, we propose Skill-KNN, a skill-based\nfew-shot selection method for in-context learning. The key advantages of\nSkill-KNN include: (1) it addresses the problem that existing methods based on\npre-trained embeddings can be easily biased by surface natural language\nfeatures that are not important for the target task; (2) it does not require\ntraining or fine-tuning of any models, making it suitable for frequently\nexpanding or changing example banks. The key insight is to optimize the inputs\nfed into the embedding model, rather than tuning the model itself. Technically,\nSkill-KNN generates the skill-based descriptions for each test case and\ncandidate example by utilizing a pre-processing few-shot prompting, thus\neliminating unimportant surface features. Experimental results across five\ncross-domain semantic parsing datasets and six backbone models show that\nSkill-KNN significantly outperforms existing methods.", "published": "2023-05-23 16:28:29", "link": "http://arxiv.org/abs/2305.14210v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Chat Language Models by Scaling High-quality Instructional\n  Conversations", "abstract": "Fine-tuning on instruction data has been widely validated as an effective\npractice for implementing chat language models like ChatGPT. Scaling the\ndiversity and quality of such data, although straightforward, stands a great\nchance of leading to improved performance. This paper aims to improve the upper\nbound of open-source models further. We first provide a systematically\ndesigned, diverse, informative, large-scale dataset of instructional\nconversations, UltraChat, which does not involve human queries. Our objective\nis to capture the breadth of interactions that a human might have with an AI\nassistant and employs a comprehensive framework to generate multi-turn\nconversation iteratively. UltraChat contains 1.5 million high-quality\nmulti-turn dialogues and covers a wide range of topics and instructions. Our\nstatistical analysis of UltraChat reveals its superiority in various key\nmetrics, including scale, average length, diversity, coherence, etc.,\nsolidifying its position as a leading open-source dataset. Building upon\nUltraChat, we fine-tune a LLaMA model to create a powerful conversational\nmodel, UltraLLaMA. Our evaluations indicate that UltraLLaMA consistently\noutperforms other open-source models, including Vicuna, the previously\nrecognized state-of-the-art open-source model. The dataset and the model will\nbe publicly released\\footnote{\\url{https://github.com/thunlp/UltraChat}}.", "published": "2023-05-23 16:49:14", "link": "http://arxiv.org/abs/2305.14233v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multilingual Large Language Models Are Not (Yet) Code-Switchers", "abstract": "Multilingual Large Language Models (LLMs) have recently shown great\ncapabilities in a wide range of tasks, exhibiting state-of-the-art performance\nthrough zero-shot or few-shot prompting methods. While there have been\nextensive studies on their abilities in monolingual tasks, the investigation of\ntheir potential in the context of code-switching (CSW), the practice of\nalternating languages within an utterance, remains relatively uncharted. In\nthis paper, we provide a comprehensive empirical analysis of various\nmultilingual LLMs, benchmarking their performance across four tasks: sentiment\nanalysis, machine translation, summarization and word-level language\nidentification. Our results indicate that despite multilingual LLMs exhibiting\npromising outcomes in certain tasks using zero or few-shot prompting, they\nstill underperform in comparison to fine-tuned models of much smaller scales.\nWe argue that current \"multilingualism\" in LLMs does not inherently imply\nproficiency with code-switching texts, calling for future research to bridge\nthis discrepancy.", "published": "2023-05-23 16:50:48", "link": "http://arxiv.org/abs/2305.14235v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HOP, UNION, GENERATE: Explainable Multi-hop Reasoning without Rationale\n  Supervision", "abstract": "Explainable multi-hop question answering (QA) not only predicts answers but\nalso identifies rationales, i. e. subsets of input sentences used to derive the\nanswers. This problem has been extensively studied under the supervised\nsetting, where both answer and rationale annotations are given. Because\nrationale annotations are expensive to collect and not always available, recent\nefforts have been devoted to developing methods that do not rely on supervision\nfor rationales. However, such methods have limited capacities in modeling\ninteractions between sentences, let alone reasoning across multiple documents.\nThis work proposes a principled, probabilistic approach for training\nexplainable multi-hop QA systems without rationale supervision. Our approach\nperforms multi-hop reasoning by explicitly modeling rationales as sets,\nenabling the model to capture interactions between documents and sentences\nwithin a document. Experimental results show that our approach is more accurate\nat selecting rationales than the previous methods, while maintaining similar\naccuracy in predicting answers.", "published": "2023-05-23 16:53:49", "link": "http://arxiv.org/abs/2305.14237v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language Models with Rationality", "abstract": "While large language models (LLMs) are proficient at question-answering (QA),\nit is not always clear how (or even if) an answer follows from their latent\n\"beliefs\". This lack of interpretability is a growing impediment to widespread\nuse of LLMs. To address this, our goals are to make model beliefs and their\ninferential relationships explicit, and to resolve inconsistencies that may\nexist, so that answers are supported by interpretable chains of reasoning drawn\nfrom a consistent network of beliefs. Our approach, which we call REFLEX, is to\nadd a rational, self-reflecting layer on top of the LLM. First, given a\nquestion, we construct a belief graph using a backward-chaining process to\nmaterialize relevant model beliefs (including beliefs about answer candidates)\nand their inferential relationships. Second, we identify and minimize\ncontradictions in that graph using a formal constraint reasoner. We find that\nREFLEX significantly improves consistency (by 8%-11% absolute) without harming\noverall answer accuracy, resulting in answers supported by faithful chains of\nreasoning drawn from a more consistent belief system. This suggests a new style\nof system architecture in which an LLM extended with a rational layer can\nprovide an interpretable window into system beliefs, add a systematic reasoning\ncapability, and repair latent inconsistencies present in the LLM.", "published": "2023-05-23 17:04:25", "link": "http://arxiv.org/abs/2305.14250v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LIMIT: Language Identification, Misidentification, and Translation using\n  Hierarchical Models in 350+ Languages", "abstract": "Knowing the language of an input text/audio is a necessary first step for\nusing almost every NLP tool such as taggers, parsers, or translation systems.\nLanguage identification is a well-studied problem, sometimes even considered\nsolved; in reality, due to lack of data and computational challenges, current\nsystems cannot accurately identify most of the world's 7000 languages. To\ntackle this bottleneck, we first compile a corpus, MCS-350, of 50K multilingual\nand parallel children's stories in 350+ languages. MCS-350 can serve as a\nbenchmark for language identification of short texts and for 1400+ new\ntranslation directions in low-resource Indian and African languages. Second, we\npropose a novel misprediction-resolution hierarchical model, LIMIt, for\nlanguage identification that reduces error by 55% (from 0.71 to 0.32) on our\ncompiled children's stories dataset and by 40% (from 0.23 to 0.14) on the\nFLORES-200 benchmark. Our method can expand language identification coverage\ninto low-resource languages by relying solely on systemic misprediction\npatterns, bypassing the need to retrain large models from scratch.", "published": "2023-05-23 17:15:43", "link": "http://arxiv.org/abs/2305.14263v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Active Learning Principles for In-Context Learning with Large Language\n  Models", "abstract": "The remarkable advancements in large language models (LLMs) have\nsignificantly enhanced the performance in few-shot learning settings. By using\nonly a small number of labeled examples, referred to as demonstrations, LLMs\ncan effectively grasp the task at hand through in-context learning. However,\nthe process of selecting appropriate demonstrations has received limited\nattention in prior work. This paper addresses the issue of identifying the most\ninformative demonstrations for few-shot learning by approaching it as a\npool-based Active Learning (AL) problem over a single iteration. Our objective\nis to investigate how AL algorithms can serve as effective demonstration\nselection methods for in-context learning. We compare various standard AL\nalgorithms based on uncertainty, diversity, and similarity, and consistently\nobserve that the latter outperforms all other methods, including random\nsampling. Notably, uncertainty sampling, despite its success in conventional\nsupervised learning scenarios, performs poorly in this context. Our extensive\nexperimentation involving a diverse range of GPT and OPT models across $24$\nclassification and multi-choice tasks, coupled with thorough analysis,\nunambiguously demonstrates that in-context example selection through AL\nprioritizes high-quality examples that exhibit low uncertainty and bear\nsimilarity to the test examples.", "published": "2023-05-23 17:16:04", "link": "http://arxiv.org/abs/2305.14264v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Masked Path Modeling for Vision-and-Language Navigation", "abstract": "Vision-and-language navigation (VLN) agents are trained to navigate in\nreal-world environments by following natural language instructions. A major\nchallenge in VLN is the limited availability of training data, which hinders\nthe models' ability to generalize effectively. Previous approaches have\nattempted to address this issue by introducing additional supervision during\ntraining, often requiring costly human-annotated data that restricts\nscalability. In this paper, we introduce a masked path modeling (MPM)\nobjective, which pretrains an agent using self-collected data for downstream\nnavigation tasks. Our proposed method involves allowing the agent to actively\nexplore navigation environments without a specific goal and collect the paths\nit traverses. Subsequently, we train the agent on this collected data to\nreconstruct the original path given a randomly masked subpath. This way, the\nagent can actively accumulate a diverse and substantial amount of data while\nlearning conditional action generation. To evaluate the effectiveness of our\ntechnique, we conduct experiments on various VLN datasets and demonstrate the\nversatility of MPM across different levels of instruction complexity. Our\nresults exhibit significant improvements in success rates, with enhancements of\n1.32\\%, 1.05\\%, and 1.19\\% on the val-unseen split of the Room-to-Room,\nRoom-for-Room, and Room-across-Room datasets, respectively. Furthermore, we\nconduct an analysis that highlights the potential for additional improvements\nwhen the agent is allowed to explore unseen environments prior to testing.", "published": "2023-05-23 17:20:20", "link": "http://arxiv.org/abs/2305.14268v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining", "abstract": "Recent work in vision-and-language pretraining has investigated supervised\nsignals from object detection data to learn better, fine-grained multimodal\nrepresentations. In this work, we take a step further and explore how we can\ntap into supervision from small-scale visual relation data. In particular, we\npropose two pretraining approaches to contextualise visual entities in a\nmultimodal setup. With verbalised scene graphs, we transform visual relation\ntriplets into structured captions, and treat them as additional image\ndescriptions. With masked relation prediction, we further encourage relating\nentities from image regions with visually masked contexts. When applied to\nstrong baselines pretrained on large amounts of Web data, zero-shot evaluations\non both coarse-grained and fine-grained tasks show the efficacy of our methods\nin learning multimodal representations from weakly-supervised relations data.", "published": "2023-05-23 17:27:12", "link": "http://arxiv.org/abs/2305.14281v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "INSTRUCTSCORE: Explainable Text Generation Evaluation with Finegrained\n  Feedback", "abstract": "Automatically evaluating the quality of language generation is critical.\nAlthough recent learned metrics show high correlation with human judgement,\nthese metrics can not explain their verdict or associate the scores with\ndefects in generated text. To address this limitation, we present\nInstructScore, an explainable evaluation metric for text generation. By\nharnessing both explicit human instruction and the implicit knowledge of GPT-4,\nwe fine-tune a text evaluation metric based on LLaMA, producing both a score\nfor generated text and a human readable diagnostic report. We evaluate\nInstructScore on a variety of generation tasks, including translation,\ncaptioning, data-to-text and commonsense generation. Experiments show that our\n7B model surpasses all other unsupervised metrics, including those based on\n175B GPT-3 and GPT-4. Surprisingly, our InstructScore, even without direct\nsupervision from human-rated data, achieves performance levels on par with\nstate-of-the-art metrics like COMET22, which were fine-tuned on human ratings.", "published": "2023-05-23 17:27:22", "link": "http://arxiv.org/abs/2305.14282v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "USB: A Unified Summarization Benchmark Across Tasks and Domains", "abstract": "While the NLP community has produced numerous summarization benchmarks, none\nprovide the rich annotations required to simultaneously address many important\nproblems related to control and reliability. We introduce a Wikipedia-derived\nbenchmark, complemented by a rich set of crowd-sourced annotations, that\nsupports $8$ interrelated tasks: (i) extractive summarization; (ii) abstractive\nsummarization; (iii) topic-based summarization; (iv) compressing selected\nsentences into a one-line summary; (v) surfacing evidence for a summary\nsentence; (vi) predicting the factual accuracy of a summary sentence; (vii)\nidentifying unsubstantiated spans in a summary sentence; (viii) correcting\nfactual errors in summaries. We compare various methods on this benchmark and\ndiscover that on multiple tasks, moderately-sized fine-tuned models\nconsistently outperform much larger few-shot prompted language models. For\nfactuality-related tasks, we also evaluate existing heuristics to create\ntraining data and find that training on them results in worse performance than\ntraining on $20\\times$ less human-labeled data. Our articles draw from $6$\ndomains, facilitating cross-domain analysis. On some tasks, the amount of\ntraining data matters more than the domain where it comes from, while for other\ntasks training specifically on data from the target domain, even if limited, is\nmore beneficial.", "published": "2023-05-23 17:39:54", "link": "http://arxiv.org/abs/2305.14296v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TaDSE: Template-aware Dialogue Sentence Embeddings", "abstract": "Learning high quality sentence embeddings from dialogues has drawn increasing\nattentions as it is essential to solve a variety of dialogue-oriented tasks\nwith low annotation cost. However, directly annotating and gathering utterance\nrelationships in conversations are difficult, while token-level annotations,\n\\eg, entities, slots and templates, are much easier to obtain. General sentence\nembedding methods are usually sentence-level self-supervised frameworks and\ncannot utilize token-level extra knowledge. In this paper, we introduce\nTemplate-aware Dialogue Sentence Embedding (TaDSE), a novel augmentation method\nthat utilizes template information to effectively learn utterance\nrepresentation via self-supervised contrastive learning framework. TaDSE\naugments each sentence with its corresponding template and then conducts\npairwise contrastive learning over both sentence and template. We further\nenhance the effect with a synthetically augmented dataset that enhances\nutterance-template relation, in which entity detection (slot-filling) is a\npreliminary step. We evaluate TaDSE performance on five downstream benchmark\ndatasets. The experiment results show that TaDSE achieves significant\nimprovements over previous SOTA methods, along with a consistent Intent\nClassification task performance improvement margin. We further introduce a\nnovel analytic instrument of Semantic Compression method, for which we discover\na correlation with uniformity and alignment. Our code will be released soon.", "published": "2023-05-23 17:40:41", "link": "http://arxiv.org/abs/2305.14299v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Debiasing should be Good and Bad: Measuring the Consistency of Debiasing\n  Techniques in Language Models", "abstract": "Debiasing methods that seek to mitigate the tendency of Language Models (LMs)\nto occasionally output toxic or inappropriate text have recently gained\ntraction. In this paper, we propose a standardized protocol which distinguishes\nmethods that yield not only desirable results, but are also consistent with\ntheir mechanisms and specifications. For example, we ask, given a debiasing\nmethod that is developed to reduce toxicity in LMs, if the definition of\ntoxicity used by the debiasing method is reversed, would the debiasing results\nalso be reversed? We used such considerations to devise three criteria for our\nnew protocol: Specification Polarity, Specification Importance, and Domain\nTransferability. As a case study, we apply our protocol to a popular debiasing\nmethod, Self-Debiasing, and compare it to one we propose, called Instructive\nDebiasing, and demonstrate that consistency is as important an aspect to\ndebiasing viability as is simply a desirable result. We show that our protocol\nprovides essential insights into the generalizability and interpretability of\ndebiasing methods that may otherwise go overlooked.", "published": "2023-05-23 17:45:54", "link": "http://arxiv.org/abs/2305.14307v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation", "abstract": "Instruction tuning has emerged to enhance the capabilities of large language\nmodels (LLMs) to comprehend instructions and generate appropriate responses.\nExisting methods either manually annotate or employ LLM (e.g., GPT-series) to\ngenerate data for instruction tuning. However, they often overlook associating\ninstructions with existing annotated datasets. In this paper, we propose\nDynosaur, a dynamic growth paradigm for the automatic curation of\ninstruction-tuning data. Based on the metadata of existing datasets, we use\nLLMs to automatically construct instruction-tuning data by identifying relevant\ndata fields and generating appropriate instructions.\n  By leveraging the existing annotated datasets, Dynosaur offers several\nadvantages: 1) it reduces the API cost for generating instructions (e.g., it\ncosts less than $12 USD by calling GPT-3.5-turbo for generating 800K\ninstruction tuning samples; 2) it provides high-quality data for instruction\ntuning (e.g., it performs better than Alpaca and Flan on Super-NI and Longform\nwith comparable data sizes); and 3) it supports the continuous improvement of\nmodels by generating instruction-tuning data when a new annotated dataset\nbecomes available. We further investigate a continual learning scheme for\nlearning with the ever-growing instruction-tuning dataset, and demonstrate that\nreplaying tasks with diverse instruction embeddings not only helps mitigate\nforgetting issues but generalizes to unseen tasks better.\n  Code and data are available at https://github.com/WadeYin9712/Dynosaur.", "published": "2023-05-23 17:56:26", "link": "http://arxiv.org/abs/2305.14327v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "What Else Do I Need to Know? The Effect of Background Information on\n  Users' Reliance on QA Systems", "abstract": "NLP systems have shown impressive performance at answering questions by\nretrieving relevant context. However, with the increasingly large models, it is\nimpossible and often undesirable to constrain models' knowledge or reasoning to\nonly the retrieved context. This leads to a mismatch between the information\nthat the models access to derive the answer and the information that is\navailable to the user to assess the model predicted answer. In this work, we\nstudy how users interact with QA systems in the absence of sufficient\ninformation to assess their predictions. Further, we ask whether adding the\nrequisite background helps mitigate users' over-reliance on predictions. Our\nstudy reveals that users rely on model predictions even in the absence of\nsufficient information needed to assess the model's correctness. Providing the\nrelevant background, however, helps users better catch model errors, reducing\nover-reliance on incorrect predictions. On the flip side, background\ninformation also increases users' confidence in their accurate as well as\ninaccurate judgments. Our work highlights that supporting users' verification\nof QA predictions is an important, yet challenging, problem.", "published": "2023-05-23 17:57:12", "link": "http://arxiv.org/abs/2305.14331v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automatic Model Selection with Large Language Models for Reasoning", "abstract": "Chain-of-Thought (CoT) and Program-Aided Language Models (PAL) represent two\ndistinct reasoning methods, each with its own strengths. CoT employs natural\nlanguage, offering flexibility and interpretability, while PAL utilizes\nprogramming language, yielding more structured and rigorous logic. We introduce\na model selection method to combine the best of both worlds by employing a\nlarge language model (LLM) to dynamically select between them. Our theoretical\nanalysis underscores the feasibility of this method, which is further\ncorroborated by empirical results. Our proposed method demonstrates significant\nperformance improvements across eight reasoning datasets with Codex, ChatGPT,\nand GPT-4. Additionally, our method is complementary to self-consistency; when\nintegrated, it can further enhance performance while significantly reducing\ncomputation costs. Moreover, we achieve new state-of-the-art results on GSM8K\nand SVAMP, with respective accuracies of 96.8% and 93.7%. Our code, data and\nprompts are available at https://github.com/XuZhao0/Model-Selection-Reasoning", "published": "2023-05-23 17:57:59", "link": "http://arxiv.org/abs/2305.14333v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Anchor Prediction: Automatic Refinement of Internet Links", "abstract": "Internet links enable users to deepen their understanding of a topic by\nproviding convenient access to related information. However, the majority of\nlinks are unanchored -- they link to a target webpage as a whole, and readers\nmay expend considerable effort localizing the specific parts of the target\nwebpage that enrich their understanding of the link's source context. To help\nreaders effectively find information in linked webpages, we introduce the task\nof anchor prediction, where the goal is to identify the specific part of the\nlinked target webpage that is most related to the source linking context. We\nrelease the AuthorAnchors dataset, a collection of 34K naturally-occurring\nanchored links, which reflect relevance judgments by the authors of the source\narticle. To model reader relevance judgments, we annotate and release\nReaderAnchors, an evaluation set of anchors that readers find useful. Our\nanalysis shows that effective anchor prediction often requires jointly\nreasoning over lengthy source and target webpages to determine their implicit\nrelations and identify parts of the target webpage that are related but not\nredundant. We benchmark a performant T5-based ranking approach to establish\nbaseline performance on the task, finding ample room for improvement.", "published": "2023-05-23 17:58:21", "link": "http://arxiv.org/abs/2305.14337v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Advancing Precise Outline-Conditioned Text Generation with Task Duality\n  and Explicit Outline Control", "abstract": "Existing works on outline-conditioned text generation typically aim to\ngenerate text using provided outlines as rough sketches, such as keywords and\nphrases. However, these approaches make it challenging to control the quality\nof text generation and assess consistency between outlines and generated texts\ndue to lack of clarity and rationality of the rough outlines. In this paper, we\nintroduce a novel text generation task called Precise Outline-conditioned\nGeneration, which requires generating stories based on specific, sentence-level\noutlines. To facilitate research on this task, we construct two new datasets,\nWPOG and CDM. We provide strong baselines based on fine-tuning models such as\nBART and GPT-2, and evaluating zero-shot performance of models such as ChatGPT\nand Vicuna. Furthermore, we identify an issue of imbalanced utilization of the\noutline information in the precise outline-conditioned generation, which is\nubiquitously observed across fine-tuned models and zero-shot inference models.\nTo address this issue, we propose an explicit outline utilization control\napproach and a novel framework that leverages the task duality between\nsummarization and generation. Experimental results show that the proposed\napproaches effectively alleviate the issue of imbalanced outline utilization\nand enhance the quality of precise outline-conditioned text generation for both\nfine-tuning and zero-shot settings.", "published": "2023-05-23 18:33:52", "link": "http://arxiv.org/abs/2305.14459v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Run Like a Girl! Sports-Related Gender Bias in Language and Vision", "abstract": "Gender bias in Language and Vision datasets and models has the potential to\nperpetuate harmful stereotypes and discrimination. We analyze gender bias in\ntwo Language and Vision datasets. Consistent with prior work, we find that both\ndatasets underrepresent women, which promotes their invisibilization. Moreover,\nwe hypothesize and find that a bias affects human naming choices for people\nplaying sports: speakers produce names indicating the sport (e.g. 'tennis\nplayer' or 'surfer') more often when it is a man or a boy participating in the\nsport than when it is a woman or a girl, with an average of 46% vs. 35% of\nsports-related names for each gender. A computational model trained on these\nnaming data reproduces the bias. We argue that both the data and the model\nresult in representational harm against women.", "published": "2023-05-23 18:52:11", "link": "http://arxiv.org/abs/2305.14468v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "BAND: Biomedical Alert News Dataset", "abstract": "Infectious disease outbreaks continue to pose a significant threat to human\nhealth and well-being. To improve disease surveillance and understanding of\ndisease spread, several surveillance systems have been developed to monitor\ndaily news alerts and social media. However, existing systems lack thorough\nepidemiological analysis in relation to corresponding alerts or news, largely\ndue to the scarcity of well-annotated reports data. To address this gap, we\nintroduce the Biomedical Alert News Dataset (BAND), which includes 1,508\nsamples from existing reported news articles, open emails, and alerts, as well\nas 30 epidemiology-related questions. These questions necessitate the model's\nexpert reasoning abilities, thereby offering valuable insights into the\noutbreak of the disease. The BAND dataset brings new challenges to the NLP\nworld, requiring better disguise capability of the content and the ability to\ninfer important information. We provide several benchmark tasks, including\nNamed Entity Recognition (NER), Question Answering (QA), and Event Extraction\n(EE), to show how existing models are capable of handling these tasks in the\nepidemiology domain. To the best of our knowledge, the BAND corpus is the\nlargest corpus of well-annotated biomedical outbreak alert news with\nelaborately designed questions, making it a valuable resource for\nepidemiologists and NLP researchers alike.", "published": "2023-05-23 19:21:00", "link": "http://arxiv.org/abs/2305.14480v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language Model Self-improvement by Reinforcement Learning Contemplation", "abstract": "Large Language Models (LLMs) have exhibited remarkable performance across\nvarious natural language processing (NLP) tasks. However, fine-tuning these\nmodels often necessitates substantial supervision, which can be expensive and\ntime-consuming to obtain. This paper introduces a novel unsupervised method\ncalled LanguageModel Self-Improvement by Reinforcement Learning Contemplation\n(SIRLC) that improves LLMs without reliance on external labels. Our approach is\ngrounded in the observation that it is simpler for language models to assess\ntext quality than to generate text. Building on this insight, SIRLC assigns\nLLMs dual roles as both student and teacher. As a student, the LLM generates\nanswers to unlabeled questions, while as a teacher, it evaluates the generated\ntext and assigns scores accordingly. The model parameters are updated using\nreinforcement learning to maximize the evaluation score. We demonstrate that\nSIRLC can be applied to various NLP tasks, such as reasoning problems, text\ngeneration, and machine translation. Our experiments show that SIRLC\neffectively improves LLM performance without external supervision, resulting in\na 5.6% increase in answering accuracy for reasoning tasks and a rise in\nBERTScore from 0.82 to 0.86 for translation tasks. Furthermore, SIRLC can be\napplied to models of different sizes, showcasing its broad applicability.", "published": "2023-05-23 19:25:52", "link": "http://arxiv.org/abs/2305.14483v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Self-Polish: Enhance Reasoning in Large Language Models via Problem\n  Refinement", "abstract": "To enhance the multi-step reasoning capabilities of large language models,\nresearchers have extensively explored prompting methods, notably the\nChain-of-Thought (CoT) method which explicitly elicits human-like rationales.\nHowever, they have inadvertently overlooked the potential of enhancing model\nreasoning performance by formulating higher-quality problems. In this work, we\nstart from the problem side and propose Self-Polish (SP), a novel method that\nfacilitates the model's reasoning by guiding it to progressively refine the\ngiven problems to be more comprehensible and solvable. We also explore several\nautomatic prompting varients and propose the Self-Polish prompt bank for the\ncommunity. SP is orthogonal to all other prompting methods of answer/reasoning\nside like CoT, allowing for seamless integration with state-of-the-art\ntechniques for further improvement. Thorough experiments show that the proposed\nmethod attains notable and consistent effectiveness on five reasoning\nbenchmarks across different models. Furthermore, our method also showcases\nimpressive performance on robustness evaluation. Codes and prompts are\navailable at https://github.com/WooooDyy/Self-Polish.", "published": "2023-05-23 19:58:30", "link": "http://arxiv.org/abs/2305.14497v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive\n  Decoders", "abstract": "Neural document rerankers are extremely effective in terms of accuracy.\nHowever, the best models require dedicated hardware for serving, which is\ncostly and often not feasible. To avoid this serving-time requirement, we\npresent a method of capturing up to 86% of the gains of a Transformer\ncross-attention model with a lexicalized scoring function that only requires\n10-6% of the Transformer's FLOPs per document and can be served using commodity\nCPUs. When combined with a BM25 retriever, this approach matches the quality of\na state-of-the art dual encoder retriever, that still requires an accelerator\nfor query encoding. We introduce NAIL (Non-Autoregressive Indexing with\nLanguage models) as a model architecture that is compatible with recent\nencoder-decoder and decoder-only large language models, such as T5, GPT-3 and\nPaLM. This model architecture can leverage existing pre-trained checkpoints and\ncan be fine-tuned for efficiently constructing document representations that do\nnot require neural processing of queries.", "published": "2023-05-23 20:09:52", "link": "http://arxiv.org/abs/2305.14499v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Detecting Propaganda Techniques in Code-Switched Social Media Text", "abstract": "Propaganda is a form of communication intended to influence the opinions and\nthe mindset of the public to promote a particular agenda. With the rise of\nsocial media, propaganda has spread rapidly, leading to the need for automatic\npropaganda detection systems. Most work on propaganda detection has focused on\nhigh-resource languages, such as English, and little effort has been made to\ndetect propaganda for low-resource languages. Yet, it is common to find a mix\nof multiple languages in social media communication, a phenomenon known as\ncode-switching. Code-switching combines different languages within the same\ntext, which poses a challenge for automatic systems. With this in mind, here we\npropose the novel task of detecting propaganda techniques in code-switched\ntext. To support this task, we create a corpus of 1,030 texts code-switching\nbetween English and Roman Urdu, annotated with 20 propaganda techniques, which\nwe make publicly available. We perform a number of experiments contrasting\ndifferent experimental setups, and we find that it is important to model the\nmultilinguality directly (rather than using translation) as well as to use the\nright fine-tuning strategy. The code and the dataset are publicly available at\nhttps://github.com/mbzuai-nlp/propaganda-codeswitched-text", "published": "2023-05-23 21:37:26", "link": "http://arxiv.org/abs/2305.14534v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cascaded Beam Search: Plug-and-Play Terminology-Forcing For Neural\n  Machine Translation", "abstract": "This paper presents a plug-and-play approach for translation with terminology\nconstraints. Terminology constraints are an important aspect of many modern\ntranslation pipelines. In both specialized domains and newly emerging domains\n(such as the COVID-19 pandemic), accurate translation of technical terms is\ncrucial. Recent approaches often train models to copy terminologies from the\ninput into the output sentence by feeding the target terminology along with the\ninput. But this requires expensive training whenever the underlying language\nmodel is changed or the system should specialize to a new domain. We propose\nCascade Beam Search, a plug-and-play terminology-forcing approach that requires\nno training. Cascade Beam Search has two parts: 1) logit manipulation to\nincrease the probability of target terminologies and 2) a cascading beam setup\nbased on grid beam search, where beams are grouped by the number of\nterminologies they contain. We evaluate the performance of our approach by\ncompeting against the top submissions of the WMT21 terminology translation\ntask. Our plug-and-play approach performs on par with the winning submissions\nwithout using a domain-specific language model and with no additional training.", "published": "2023-05-23 21:48:02", "link": "http://arxiv.org/abs/2305.14538v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sources of Hallucination by Large Language Models on Inference Tasks", "abstract": "Large Language Models (LLMs) are claimed to be capable of Natural Language\nInference (NLI), necessary for applied tasks like question answering and\nsummarization. We present a series of behavioral studies on several LLM\nfamilies (LLaMA, GPT-3.5, and PaLM) which probe their behavior using controlled\nexperiments. We establish two biases originating from pretraining which predict\nmuch of their behavior, and show that these are major sources of hallucination\nin generative LLMs. First, memorization at the level of sentences: we show\nthat, regardless of the premise, models falsely label NLI test samples as\nentailing when the hypothesis is attested in training data, and that entities\nare used as ``indices'' to access the memorized data. Second, statistical\npatterns of usage learned at the level of corpora: we further show a similar\neffect when the premise predicate is less frequent than that of the hypothesis\nin the training data, a bias following from previous studies. We demonstrate\nthat LLMs perform significantly worse on NLI test samples which do not conform\nto these biases than those which do, and we offer these as valuable controls\nfor future LLM evaluation.", "published": "2023-05-23 22:24:44", "link": "http://arxiv.org/abs/2305.14552v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unraveling ChatGPT: A Critical Analysis of AI-Generated Goal-Oriented\n  Dialogues and Annotations", "abstract": "Large pre-trained language models have exhibited unprecedented capabilities\nin producing high-quality text via prompting techniques. This fact introduces\nnew possibilities for data collection and annotation, particularly in\nsituations where such data is scarce, complex to gather, expensive, or even\nsensitive. In this paper, we explore the potential of these models to generate\nand annotate goal-oriented dialogues, and conduct an in-depth analysis to\nevaluate their quality. Our experiments employ ChatGPT, and encompass three\ncategories of goal-oriented dialogues (task-oriented, collaborative, and\nexplanatory), two generation modes (interactive and one-shot), and two\nlanguages (English and Italian). Based on extensive human-based evaluations, we\ndemonstrate that the quality of generated dialogues and annotations is on par\nwith those generated by humans.", "published": "2023-05-23 22:31:01", "link": "http://arxiv.org/abs/2305.14556v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Detecting and Mitigating Indirect Stereotypes in Word Embeddings", "abstract": "Societal biases in the usage of words, including harmful stereotypes, are\nfrequently learned by common word embedding methods. These biases manifest not\nonly between a word and an explicit marker of its stereotype, but also between\nwords that share related stereotypes. This latter phenomenon, sometimes called\n\"indirect bias,'' has resisted prior attempts at debiasing. In this paper, we\npropose a novel method called Biased Indirect Relationship Modification (BIRM)\nto mitigate indirect bias in distributional word embeddings by modifying biased\nrelationships between words before embeddings are learned. This is done by\nconsidering how the co-occurrence probability of a given pair of words changes\nin the presence of words marking an attribute of bias, and using this to\naverage out the effect of a bias attribute. To evaluate this method, we perform\na series of common tests and demonstrate that measures of bias in the word\nembeddings are reduced in exchange for minor reduction in the semantic quality\nof the embeddings. In addition, we conduct novel tests for measuring indirect\nstereotypes by extending the Word Embedding Association Test (WEAT) with new\ntest sets for indirect binary gender stereotypes. With these tests, we\ndemonstrate the presence of more subtle stereotypes not addressed by previous\nwork. The proposed method is able to reduce the presence of some of these new\nstereotypes, serving as a crucial next step towards non-stereotyped word\nembeddings.", "published": "2023-05-23 23:23:49", "link": "http://arxiv.org/abs/2305.14574v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Difference-Masking: Choosing What to Mask in Continued Pretraining", "abstract": "The self-supervised objective of masking-and-predicting has led to promising\nperformance gains on a variety of downstream tasks. However, while most\napproaches randomly mask tokens, there is strong intuition that deciding what\nto mask can substantially improve learning outcomes. We investigate this in\ncontinued pretraining setting in which pretrained models continue to pretrain\non domain-specific data before performing some downstream task. We introduce\nDifference-Masking, a masking strategy that automatically chooses what to mask\nduring continued pretraining by considering what makes a task domain different\nfrom the pretraining domain. Empirically, we find that Difference-Masking\noutperforms baselines on continued pretraining settings across four diverse\nlanguage-only and multimodal video tasks.", "published": "2023-05-23 23:31:02", "link": "http://arxiv.org/abs/2305.14577v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Evaluating OpenAI's Whisper ASR for Punctuation Prediction and Topic\n  Modeling of life histories of the Museum of the Person", "abstract": "Automatic speech recognition (ASR) systems play a key role in applications\ninvolving human-machine interactions. Despite their importance, ASR models for\nthe Portuguese language proposed in the last decade have limitations in\nrelation to the correct identification of punctuation marks in automatic\ntranscriptions, which hinder the use of transcriptions by other systems,\nmodels, and even by humans. However, recently Whisper ASR was proposed by\nOpenAI, a general-purpose speech recognition model that has generated great\nexpectations in dealing with such limitations. This chapter presents the first\nstudy on the performance of Whisper for punctuation prediction in the\nPortuguese language. We present an experimental evaluation considering both\ntheoretical aspects involving pausing points (comma) and complete ideas\n(exclamation, question, and fullstop), as well as practical aspects involving\ntranscript-based topic modeling - an application dependent on punctuation marks\nfor promising performance. We analyzed experimental results from videos of\nMuseum of the Person, a virtual museum that aims to tell and preserve people's\nlife histories, thus discussing the pros and cons of Whisper in a real-world\nscenario. Although our experiments indicate that Whisper achieves\nstate-of-the-art results, we conclude that some punctuation marks require\nimprovements, such as exclamation, semicolon and colon.", "published": "2023-05-23 23:37:29", "link": "http://arxiv.org/abs/2305.14580v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Contextualized Topic Coherence Metrics", "abstract": "The recent explosion in work on neural topic modeling has been criticized for\noptimizing automated topic evaluation metrics at the expense of actual\nmeaningful topic identification. But human annotation remains expensive and\ntime-consuming. We propose LLM-based methods inspired by standard human topic\nevaluations, in a family of metrics called Contextualized Topic Coherence\n(CTC). We evaluate both a fully automated version as well as a semi-automated\nCTC that allows human-centered evaluation of coherence while maintaining the\nefficiency of automated methods. We evaluate CTC relative to five other metrics\non six topic models and find that it outperforms automated topic coherence\nmethods, works well on short documents, and is not susceptible to meaningless\nbut high-scoring topics.", "published": "2023-05-23 23:53:29", "link": "http://arxiv.org/abs/2305.14587v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Evaluating end-to-end entity linking on domain-specific knowledge bases:\n  Learning about ancient technologies from museum collections", "abstract": "To study social, economic, and historical questions, researchers in the\nsocial sciences and humanities have started to use increasingly large\nunstructured textual datasets. While recent advances in NLP provide many tools\nto efficiently process such data, most existing approaches rely on generic\nsolutions whose performance and suitability for domain-specific tasks is not\nwell understood. This work presents an attempt to bridge this domain gap by\nexploring the use of modern Entity Linking approaches for the enrichment of\nmuseum collection data. We collect a dataset comprising of more than 1700 texts\nannotated with 7,510 mention-entity pairs, evaluate some off-the-shelf\nsolutions in detail using this dataset and finally fine-tune a recent\nend-to-end EL model on this data. We show that our fine-tuned model\nsignificantly outperforms other approaches currently available in this domain\nand present a proof-of-concept use case of this model. We release our dataset\nand our best model.", "published": "2023-05-23 23:53:58", "link": "http://arxiv.org/abs/2305.14588v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities", "abstract": "In most current research, large language models (LLMs) are able to perform\nreasoning tasks by generating chains of thought through the guidance of\nspecific prompts. However, there still exists a significant discrepancy between\ntheir capability in solving complex reasoning problems and that of humans. At\npresent, most approaches focus on chains of thought (COT) and tool use, without\nconsidering the adoption and application of human cognitive frameworks. It is\nwell-known that when confronting complex reasoning challenges, humans typically\nemploy various cognitive abilities, and necessitate interaction with all\naspects of tools, knowledge, and the external environment information to\naccomplish intricate tasks. This paper introduces a novel intelligent\nframework, referred to as OlaGPT. OlaGPT carefully studied a cognitive\narchitecture framework, and propose to simulate certain aspects of human\ncognition. The framework involves approximating different cognitive modules,\nincluding attention, memory, reasoning, learning, and corresponding scheduling\nand decision-making mechanisms. Inspired by the active learning mechanism of\nhuman beings, it proposes a learning unit to record previous mistakes and\nexpert opinions, and dynamically refer to them to strengthen their ability to\nsolve similar problems. The paper also outlines common effective reasoning\nframeworks for human problem-solving and designs Chain-of-Thought (COT)\ntemplates accordingly. A comprehensive decision-making mechanism is also\nproposed to maximize model accuracy. The efficacy of OlaGPT has been\nstringently evaluated on multiple reasoning datasets, and the experimental\noutcomes reveal that OlaGPT surpasses state-of-the-art benchmarks,\ndemonstrating its superior performance. Our implementation of OlaGPT is\navailable on GitHub: \\url{https://github.com/oladata-team/OlaGPT}.", "published": "2023-05-23 09:36:51", "link": "http://arxiv.org/abs/2305.16334v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Handling Realistic Label Noise in BERT Text Classification", "abstract": "Labels noise refers to errors in training labels caused by cheap data\nannotation methods, such as web scraping or crowd-sourcing, which can be\ndetrimental to the performance of supervised classifiers. Several methods have\nbeen proposed to counteract the effect of random label noise in supervised\nclassification, and some studies have shown that BERT is already robust against\nhigh rates of randomly injected label noise. However, real label noise is not\nrandom; rather, it is often correlated with input features or other\nannotator-specific factors. In this paper, we evaluate BERT in the presence of\ntwo types of realistic label noise: feature-dependent label noise, and\nsynthetic label noise from annotator disagreements. We show that the presence\nof these types of noise significantly degrades BERT classification performance.\nTo improve robustness, we evaluate different types of ensembles and\nnoise-cleaning methods and compare their effectiveness against label noise\nacross different datasets.", "published": "2023-05-23 18:30:31", "link": "http://arxiv.org/abs/2305.16337v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ReWOO: Decoupling Reasoning from Observations for Efficient Augmented\n  Language Models", "abstract": "Augmented Language Models (ALMs) blend the reasoning capabilities of Large\nLanguage Models (LLMs) with tools that allow for knowledge retrieval and action\nexecution. Existing ALM systems trigger LLM thought processes while pulling\nobservations from these tools in an interleaved fashion. Specifically, an LLM\nreasons to call an external tool, gets halted to fetch the tool's response, and\nthen decides the next action based on all preceding response tokens. Such a\nparadigm, though straightforward and easy to implement, often leads to huge\ncomputation complexity from redundant prompts and repeated execution. This\nstudy addresses such challenges for the first time, proposing a modular\nparadigm ReWOO (Reasoning WithOut Observation) that detaches the reasoning\nprocess from external observations, thus significantly reducing token\nconsumption. Comprehensive evaluations across six public NLP benchmarks and a\ncurated dataset reveal consistent performance enhancements with our proposed\nmethodology. Notably, ReWOO achieves 5x token efficiency and 4% accuracy\nimprovement on HotpotQA, a multi-step reasoning benchmark. Furthermore, ReWOO\ndemonstrates robustness under tool-failure scenarios. Beyond prompt efficiency,\ndecoupling parametric modules from non-parametric tool calls enables\ninstruction fine-tuning to offload LLMs into smaller language models, thus\nsubstantially reducing model parameters. Our illustrative work offloads\nreasoning ability from 175B GPT3.5 into 7B LLaMA, demonstrating the significant\npotential for truly efficient and scalable ALM systems.", "published": "2023-05-23 00:16:48", "link": "http://arxiv.org/abs/2305.18323v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Regex-augmented Domain Transfer Topic Classification based on a\n  Pre-trained Language Model: An application in Financial Domain", "abstract": "A common way to use large pre-trained language models for downstream tasks is\nto fine tune them using additional layers. This may not work well if downstream\ndomain is a specialized domain whereas the large language model has been\npre-trained on a generic corpus. In this paper, we discuss the use of regular\nexpression patterns employed as features for domain knowledge during the\nprocess of fine tuning, in addition to domain specific text. Our experiments on\nreal scenario production data show that this method of fine tuning improves the\ndownstream text classification tasks as compared to fine tuning only on domain\nspecific text. We also show that the use of attention network for fine tuning\nimproves results compared to simple linear layers.", "published": "2023-05-23 03:26:32", "link": "http://arxiv.org/abs/2305.18324v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DetectLLM: Leveraging Log Rank Information for Zero-Shot Detection of\n  Machine-Generated Text", "abstract": "With the rapid progress of large language models (LLMs) and the huge amount\nof text they generated, it becomes more and more impractical to manually\ndistinguish whether a text is machine-generated. Given the growing use of LLMs\nin social media and education, it prompts us to develop methods to detect\nmachine-generated text, preventing malicious usage such as plagiarism,\nmisinformation, and propaganda. Previous work has studied several zero-shot\nmethods, which require no training data. These methods achieve good\nperformance, but there is still a lot of room for improvement. In this paper,\nwe introduce two novel zero-shot methods for detecting machine-generated text\nby leveraging the log rank information. One is called DetectLLM-LRR, which is\nfast and efficient, and the other is called DetectLLM-NPR, which is more\naccurate, but slower due to the need for perturbations. Our experiments on\nthree datasets and seven language models show that our proposed methods improve\nover the state of the art by 3.9 and 1.75 AUROC points absolute. Moreover,\nDetectLLM-NPR needs fewer perturbations than previous work to achieve the same\nlevel of performance, which makes it more practical for real-world use. We also\ninvestigate the efficiency--performance trade-off based on users preference on\nthese two measures and we provide intuition for using them in practice\neffectively. We release the data and the code of both methods in\nhttps://github.com/mbzuai-nlp/DetectLLM", "published": "2023-05-23 11:18:30", "link": "http://arxiv.org/abs/2306.05540v1", "categories": ["cs.CL", "cs.AI", "68T50", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Cross-Attention is Not Enough: Incongruity-Aware Dynamic Hierarchical\n  Fusion for Multimodal Affect Recognition", "abstract": "Fusing multiple modalities has proven effective for multimodal information\nprocessing. However, the incongruity between modalities poses a challenge for\nmultimodal fusion, especially in affect recognition. In this study, we first\nanalyze how the salient affective information in one modality can be affected\nby the other, and demonstrate that inter-modal incongruity exists latently in\ncrossmodal attention. Based on this finding, we propose the Hierarchical\nCrossmodal Transformer with Dynamic Modality Gating (HCT-DMG), a lightweight\nincongruity-aware model, which dynamically chooses the primary modality in each\ntraining batch and reduces fusion times by leveraging the learned hierarchy in\nthe latent space to alleviate incongruity. The experimental evaluation on five\nbenchmark datasets: CMU-MOSI, CMU-MOSEI, and IEMOCAP (sentiment and emotion),\nwhere incongruity implicitly lies in hard samples, as well as UR-FUNNY (humour)\nand MUStaRD (sarcasm), where incongruity is common, verifies the efficacy of\nour approach, showing that HCT-DMG: 1) outperforms previous multimodal models\nwith a reduced size of approximately 0.8M parameters; 2) recognizes hard\nsamples where incongruity makes affect recognition difficult; 3) mitigates the\nincongruity at the latent level in crossmodal attention.", "published": "2023-05-23 01:24:15", "link": "http://arxiv.org/abs/2305.13583v4", "categories": ["cs.CL", "cs.MM", "eess.AS", "eess.IV"], "primary_category": "cs.CL"}
{"title": "SPEECH: Structured Prediction with Energy-Based Event-Centric\n  Hyperspheres", "abstract": "Event-centric structured prediction involves predicting structured outputs of\nevents. In most NLP cases, event structures are complex with manifold\ndependency, and it is challenging to effectively represent these complicated\nstructured events. To address these issues, we propose Structured Prediction\nwith Energy-based Event-Centric Hyperspheres (SPEECH). SPEECH models complex\ndependency among event structured components with energy-based modeling, and\nrepresents event classes with simple but effective hyperspheres. Experiments on\ntwo unified-annotated event datasets indicate that SPEECH is predominant in\nevent detection and event-relation extraction tasks.", "published": "2023-05-23 02:28:09", "link": "http://arxiv.org/abs/2305.13617v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EDIS: Entity-Driven Image Search over Multimodal Web Content", "abstract": "Making image retrieval methods practical for real-world search applications\nrequires significant progress in dataset scales, entity comprehension, and\nmultimodal information fusion. In this work, we introduce\n\\textbf{E}ntity-\\textbf{D}riven \\textbf{I}mage \\textbf{S}earch (EDIS), a\nchallenging dataset for cross-modal image search in the news domain. EDIS\nconsists of 1 million web images from actual search engine results and curated\ndatasets, with each image paired with a textual description. Unlike datasets\nthat assume a small set of single-modality candidates, EDIS reflects real-world\nweb image search scenarios by including a million multimodal image-text pairs\nas candidates. EDIS encourages the development of retrieval models that\nsimultaneously address cross-modal information fusion and matching. To achieve\naccurate ranking results, a model must: 1) understand named entities and events\nfrom text queries, 2) ground entities onto images or text descriptions, and 3)\neffectively fuse textual and visual representations. Our experimental results\nshow that EDIS challenges state-of-the-art methods with dense entities and a\nlarge-scale candidate set. The ablation study also proves that fusing textual\nfeatures with visual features is critical in improving retrieval results.", "published": "2023-05-23 02:59:19", "link": "http://arxiv.org/abs/2305.13631v2", "categories": ["cs.CL", "cs.CV", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Detecting and Mitigating Hallucinations in Multilingual Summarisation", "abstract": "Hallucinations pose a significant challenge to the reliability of neural\nmodels for abstractive summarisation. While automatically generated summaries\nmay be fluent, they often lack faithfulness to the original document. This\nissue becomes even more pronounced in low-resource settings, such as\ncross-lingual transfer. With the existing faithful metrics focusing on English,\neven measuring the extent of this phenomenon in cross-lingual settings is hard.\nTo address this, we first develop a novel metric, mFACT, evaluating the\nfaithfulness of non-English summaries, leveraging translation-based transfer\nfrom multiple English faithfulness metrics. We then propose a simple but\neffective method to reduce hallucinations with a cross-lingual transfer, which\nweighs the loss of each training example by its faithfulness score. Through\nextensive experiments in multiple languages, we demonstrate that mFACT is the\nmetric that is most suited to detect hallucinations. Moreover, we find that our\nproposed loss weighting method drastically increases both performance and\nfaithfulness according to both automatic and human evaluation when compared to\nstrong baselines for cross-lingual transfer such as MAD-X. Our code and dataset\nare available at https://github.com/yfqiu-nlp/mfact-summ.", "published": "2023-05-23 02:59:25", "link": "http://arxiv.org/abs/2305.13632v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Physics of Language Models: Part 1, Learning Hierarchical Language\n  Structures", "abstract": "Transformer-based language models are effective but complex, and\nunderstanding their inner workings is a significant challenge. Previous\nresearch has primarily explored how these models handle simple tasks like name\ncopying or selection, and we extend this by investigating how these models\ngrasp complex, recursive language structures defined by context-free grammars\n(CFGs). We introduce a family of synthetic CFGs that produce hierarchical\nrules, capable of generating lengthy sentences (e.g., hundreds of tokens) that\nare locally ambiguous and require dynamic programming to parse. Despite this\ncomplexity, we demonstrate that generative models like GPT can accurately learn\nthis CFG language and generate sentences based on it. We explore the model's\ninternals, revealing that its hidden states precisely capture the structure of\nCFGs, and its attention patterns resemble the information passing in a dynamic\nprogramming algorithm.\n  This paper also presents several corollaries, including showing why\npositional embedding is inferior to relative attention or rotary embedding;\ndemonstrating that encoder-based models (e.g., BERT, deBERTa) cannot learn very\ndeeply nested CFGs as effectively as generative models (e.g., GPT); and\nhighlighting the necessity of adding structural and syntactic errors to the\npretraining data to make the model more robust to corrupted language prefixes.", "published": "2023-05-23 04:28:16", "link": "http://arxiv.org/abs/2305.13673v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CALLS: Japanese Empathetic Dialogue Speech Corpus of Complaint Handling\n  and Attentive Listening in Customer Center", "abstract": "We present CALLS, a Japanese speech corpus that considers phone calls in a\ncustomer center as a new domain of empathetic spoken dialogue. The existing\nSTUDIES corpus covers only empathetic dialogue between a teacher and student in\na school. To extend the application range of empathetic dialogue speech\nsynthesis (EDSS), we designed our corpus to include the same female speaker as\nthe STUDIES teacher, acting as an operator in simulated phone calls. We\ndescribe a corpus construction methodology and analyze the recorded speech. We\nalso conduct EDSS experiments using the CALLS and STUDIES corpora to\ninvestigate the effect of domain differences. The results show that mixing the\ntwo corpora during training causes biased improvements in the quality of\nsynthetic speech due to the different degrees of expressiveness. Our project\npage of the corpus is http://sython.org/Corpus/STUDIES-2.", "published": "2023-05-23 06:04:50", "link": "http://arxiv.org/abs/2305.13713v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "BA-SOT: Boundary-Aware Serialized Output Training for Multi-Talker ASR", "abstract": "The recently proposed serialized output training (SOT) simplifies\nmulti-talker automatic speech recognition (ASR) by generating speaker\ntranscriptions separated by a special token. However, frequent speaker changes\ncan make speaker change prediction difficult. To address this, we propose\nboundary-aware serialized output training (BA-SOT), which explicitly\nincorporates boundary knowledge into the decoder via a speaker change detection\ntask and boundary constraint loss. We also introduce a two-stage connectionist\ntemporal classification (CTC) strategy that incorporates token-level SOT CTC to\nrestore temporal context information. Besides typical character error rate\n(CER), we introduce utterance-dependent character error rate (UD-CER) to\nfurther measure the precision of speaker change prediction. Compared to\noriginal SOT, BA-SOT reduces CER/UD-CER by 5.1%/14.0%, and leveraging a\npre-trained ASR model for BA-SOT model initialization further reduces\nCER/UD-CER by 8.4%/19.9%.", "published": "2023-05-23 06:08:13", "link": "http://arxiv.org/abs/2305.13716v3", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ChatGPT-EDSS: Empathetic Dialogue Speech Synthesis Trained from\n  ChatGPT-derived Context Word Embeddings", "abstract": "We propose ChatGPT-EDSS, an empathetic dialogue speech synthesis (EDSS)\nmethod using ChatGPT for extracting dialogue context. ChatGPT is a chatbot that\ncan deeply understand the content and purpose of an input prompt and\nappropriately respond to the user's request. We focus on ChatGPT's reading\ncomprehension and introduce it to EDSS, a task of synthesizing speech that can\nempathize with the interlocutor's emotion. Our method first gives chat history\nto ChatGPT and asks it to generate three words representing the intention,\nemotion, and speaking style for each line in the chat. Then, it trains an EDSS\nmodel using the embeddings of ChatGPT-derived context words as the conditioning\nfeatures. The experimental results demonstrate that our method performs\ncomparably to ones using emotion labels or neural network-derived context\nembeddings learned from chat histories. The collected ChatGPT-derived context\ninformation is available at\nhttps://sarulab-speech.github.io/demo_ChatGPT_EDSS/.", "published": "2023-05-23 06:19:37", "link": "http://arxiv.org/abs/2305.13724v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Discrete Prompt Optimization via Constrained Generation for Zero-shot\n  Re-ranker", "abstract": "Re-rankers, which order retrieved documents with respect to the relevance\nscore on the given query, have gained attention for the information retrieval\n(IR) task. Rather than fine-tuning the pre-trained language model (PLM), the\nlarge-scale language model (LLM) is utilized as a zero-shot re-ranker with\nexcellent results. While LLM is highly dependent on the prompts, the impact and\nthe optimization of the prompts for the zero-shot re-ranker are not explored\nyet. Along with highlighting the impact of optimization on the zero-shot\nre-ranker, we propose a novel discrete prompt optimization method, Constrained\nPrompt generation (Co-Prompt), with the metric estimating the optimum for\nre-ranking. Co-Prompt guides the generated texts from PLM toward optimal\nprompts based on the metric without parameter update. The experimental results\ndemonstrate that Co-Prompt leads to outstanding re-ranking performance against\nthe baselines. Also, Co-Prompt generates more interpretable prompts for humans\nagainst other prompt optimization methods.", "published": "2023-05-23 06:35:33", "link": "http://arxiv.org/abs/2305.13729v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Aligning Large Language Models through Synthetic Feedback", "abstract": "Aligning large language models (LLMs) to human values has become increasingly\nimportant as it enables sophisticated steering of LLMs. However, it requires\nsignificant human demonstrations and feedback or distillation from proprietary\nLLMs such as ChatGPT. In this work, we propose a novel alignment learning\nframework with synthetic feedback not dependent on extensive human annotations\nand proprietary LLMs. First, we perform reward modeling (RM) with synthetic\nfeedback by contrasting responses from vanilla LLMs with various sizes and\nprompts. Then, we use the RM to simulate high-quality demonstrations to train a\nsupervised policy and further optimize the model with reinforcement learning.\nOur resulting model, Aligned Language Model with Synthetic Training dataset\n(ALMoST), outperforms recent open-sourced models, which are trained on the\noutputs of InstructGPT or human-annotated demonstrations, in alignment\nbenchmarks. In human evaluation, our model is preferred to Alpaca and Dolly-v2,\n55.0% and 58.5% of the time, respectively. Further analyses demonstrate the\nefficacy and importance of synthetic feedback in our framework. The code is\navailable at https://github.com/naver-ai/almost", "published": "2023-05-23 06:41:16", "link": "http://arxiv.org/abs/2305.13735v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "i-Code Studio: A Configurable and Composable Framework for Integrative\n  AI", "abstract": "Artificial General Intelligence (AGI) requires comprehensive understanding\nand generation capabilities for a variety of tasks spanning different\nmodalities and functionalities. Integrative AI is one important direction to\napproach AGI, through combining multiple models to tackle complex multimodal\ntasks. However, there is a lack of a flexible and composable platform to\nfacilitate efficient and effective model composition and coordination. In this\npaper, we propose the i-Code Studio, a configurable and composable framework\nfor Integrative AI. The i-Code Studio orchestrates multiple pre-trained models\nin a finetuning-free fashion to conduct complex multimodal tasks. Instead of\nsimple model composition, the i-Code Studio provides an integrative, flexible,\nand composable setting for developers to quickly and easily compose\ncutting-edge services and technologies tailored to their specific requirements.\nThe i-Code Studio achieves impressive results on a variety of zero-shot\nmultimodal tasks, such as video-to-text retrieval, speech-to-speech\ntranslation, and visual question answering. We also demonstrate how to quickly\nbuild a multimodal agent based on the i-Code Studio that can communicate and\npersonalize for users.", "published": "2023-05-23 06:45:55", "link": "http://arxiv.org/abs/2305.13738v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "ZET-Speech: Zero-shot adaptive Emotion-controllable Text-to-Speech\n  Synthesis with Diffusion and Style-based Models", "abstract": "Emotional Text-To-Speech (TTS) is an important task in the development of\nsystems (e.g., human-like dialogue agents) that require natural and emotional\nspeech. Existing approaches, however, only aim to produce emotional TTS for\nseen speakers during training, without consideration of the generalization to\nunseen speakers. In this paper, we propose ZET-Speech, a zero-shot adaptive\nemotion-controllable TTS model that allows users to synthesize any speaker's\nemotional speech using only a short, neutral speech segment and the target\nemotion label. Specifically, to enable a zero-shot adaptive TTS model to\nsynthesize emotional speech, we propose domain adversarial learning and\nguidance methods on the diffusion model. Experimental results demonstrate that\nZET-Speech successfully synthesizes natural and emotional speech with the\ndesired emotion for both seen and unseen speakers. Samples are at\nhttps://ZET-Speech.github.io/ZET-Speech-Demo/.", "published": "2023-05-23 08:52:00", "link": "http://arxiv.org/abs/2305.13831v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study", "abstract": "Large Language Models (LLMs), like ChatGPT, have demonstrated vast potential\nbut also introduce challenges related to content constraints and potential\nmisuse. Our study investigates three key research questions: (1) the number of\ndifferent prompt types that can jailbreak LLMs, (2) the effectiveness of\njailbreak prompts in circumventing LLM constraints, and (3) the resilience of\nChatGPT against these jailbreak prompts. Initially, we develop a classification\nmodel to analyze the distribution of existing prompts, identifying ten distinct\npatterns and three categories of jailbreak prompts. Subsequently, we assess the\njailbreak capability of prompts with ChatGPT versions 3.5 and 4.0, utilizing a\ndataset of 3,120 jailbreak questions across eight prohibited scenarios.\nFinally, we evaluate the resistance of ChatGPT against jailbreak prompts,\nfinding that the prompts can consistently evade the restrictions in 40 use-case\nscenarios. The study underscores the importance of prompt structures in\njailbreaking LLMs and discusses the challenges of robust jailbreak prompt\ngeneration and prevention.", "published": "2023-05-23 09:33:38", "link": "http://arxiv.org/abs/2305.13860v2", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "EfficientSpeech: An On-Device Text to Speech Model", "abstract": "State of the art (SOTA) neural text to speech (TTS) models can generate\nnatural-sounding synthetic voices. These models are characterized by large\nmemory footprints and substantial number of operations due to the long-standing\nfocus on speech quality with cloud inference in mind. Neural TTS models are\ngenerally not designed to perform standalone speech syntheses on\nresource-constrained and no Internet access edge devices. In this work, an\nefficient neural TTS called EfficientSpeech that synthesizes speech on an ARM\nCPU in real-time is proposed. EfficientSpeech uses a shallow non-autoregressive\npyramid-structure transformer forming a U-Network. EfficientSpeech has 266k\nparameters and consumes 90 MFLOPS only or about 1% of the size and amount of\ncomputation in modern compact models such as Mixer-TTS. EfficientSpeech\nachieves an average mel generation real-time factor of 104.3 on an RPi4. Human\nevaluation shows only a slight degradation in audio quality as compared to\nFastSpeech2.", "published": "2023-05-23 10:28:41", "link": "http://arxiv.org/abs/2305.13905v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning", "abstract": "Despite their impressive performance, large language models (LMs) still\nstruggle with reliably generating complex output structures when not finetuned\nto follow the required output format exactly. To address this issue,\ngrammar-constrained decoding (GCD) can be used to control the generation of\nLMs, guaranteeing that the output follows a given structure. Most existing GCD\nmethods are, however, limited to specific tasks, such as parsing or code\ngeneration. In this work, we demonstrate that formal grammars can describe the\noutput space for a much wider range of tasks and argue that GCD can serve as a\nunified framework for structured NLP tasks in general. For increased\nflexibility, we introduce input-dependent grammars, which allow the grammar to\ndepend on the input and thus enable the generation of different output\nstructures for different inputs. We then empirically demonstrate the power and\nflexibility of GCD-enhanced LMs on (1) information extraction, (2) entity\ndisambiguation, and (3) constituency parsing. Our results indicate that\ngrammar-constrained LMs substantially outperform unconstrained LMs or even beat\ntask-specific finetuned models. Grammar constraints thus hold great promise for\nharnessing off-the-shelf LMs for a wide range of structured NLP tasks,\nespecially where training data is scarce or finetuning is expensive. Code and\ndata: https://github.com/epfl-dlab/GCD.", "published": "2023-05-23 11:54:37", "link": "http://arxiv.org/abs/2305.13971v6", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving speech translation by fusing speech and text", "abstract": "In speech translation, leveraging multimodal data to improve model\nperformance and address limitations of individual modalities has shown\nsignificant effectiveness. In this paper, we harness the complementary\nstrengths of speech and text, which are disparate modalities. We observe three\nlevels of modality gap between them, denoted by Modal input representation,\nModal semantic, and Modal hidden states. To tackle these gaps, we propose\n\\textbf{F}use-\\textbf{S}peech-\\textbf{T}ext (\\textbf{FST}), a cross-modal model\nwhich supports three distinct input modalities for translation: speech, text,\nand fused speech-text. We leverage multiple techniques for cross-modal\nalignment and conduct a comprehensive analysis to assess its impact on speech\ntranslation, machine translation, and fused speech-text translation. We\nevaluate FST on MuST-C, GigaST, and newstest benchmark. Experiments show that\nthe proposed FST achieves an average 34.0 BLEU on MuST-C\nEn$\\rightarrow$De/Es/Fr (vs SOTA +1.1 BLEU). Further experiments demonstrate\nthat FST does not degrade on MT task, as observed in prior works. Instead, it\nyields an average improvement of 3.2 BLEU over the pre-trained MT model.", "published": "2023-05-23 13:13:48", "link": "http://arxiv.org/abs/2305.14042v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of\n  Language Models via Chain-of-Thought Fine-Tuning", "abstract": "Language models (LMs) with less than 100B parameters are known to perform\npoorly on chain-of-thought (CoT) reasoning in contrast to large LMs when\nsolving unseen tasks. In this work, we aim to equip smaller LMs with the\nstep-by-step reasoning capability by instruction tuning with CoT rationales. In\norder to achieve this goal, we first introduce a new instruction-tuning dataset\ncalled the CoT Collection, which augments the existing Flan Collection\n(including only 9 CoT tasks) with additional 1.84 million rationales across\n1,060 tasks. We show that CoT fine-tuning Flan-T5 (3B & 11B) with CoT\nCollection enables smaller LMs to have better CoT capabilities on unseen tasks.\nOn the BIG-Bench-Hard (BBH) benchmark, we report an average improvement of\n+4.34% (Flan-T5 3B) and +2.60% (Flan-T5 11B), in terms of zero-shot task\naccuracy. Furthermore, we show that instruction tuning with CoT Collection\nallows LMs to possess stronger few-shot learning capabilities on 4\ndomain-specific tasks, resulting in an improvement of +2.24% (Flan-T5 3B) and\n+2.37% (Flan-T5 11B), even outperforming ChatGPT utilizing demonstrations until\nthe max length by a +13.98% margin. Our code, the CoT Collection data, and\nmodel checkpoints are publicly available.", "published": "2023-05-23 13:14:59", "link": "http://arxiv.org/abs/2305.14045v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rethinking Speech Recognition with A Multimodal Perspective via Acoustic\n  and Semantic Cooperative Decoding", "abstract": "Attention-based encoder-decoder (AED) models have shown impressive\nperformance in ASR. However, most existing AED methods neglect to\nsimultaneously leverage both acoustic and semantic features in decoder, which\nis crucial for generating more accurate and informative semantic states. In\nthis paper, we propose an Acoustic and Semantic Cooperative Decoder (ASCD) for\nASR. In particular, unlike vanilla decoders that process acoustic and semantic\nfeatures in two separate stages, ASCD integrates them cooperatively. To prevent\ninformation leakage during training, we design a Causal Multimodal Mask.\nMoreover, a variant Semi-ASCD is proposed to balance accuracy and computational\ncost. Our proposal is evaluated on the publicly available AISHELL-1 and\naidatatang_200zh datasets using Transformer, Conformer, and Branchformer as\nencoders, respectively. The experimental results show that ASCD significantly\nimproves the performance by leveraging both the acoustic and semantic\ninformation cooperatively.", "published": "2023-05-23 13:25:44", "link": "http://arxiv.org/abs/2305.14049v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Disentangled Variational Autoencoder for Emotion Recognition in\n  Conversations", "abstract": "In Emotion Recognition in Conversations (ERC), the emotions of target\nutterances are closely dependent on their context. Therefore, existing works\ntrain the model to generate the response of the target utterance, which aims to\nrecognise emotions leveraging contextual information. However, adjacent\nresponse generation ignores long-range dependencies and provides limited\naffective information in many cases. In addition, most ERC models learn a\nunified distributed representation for each utterance, which lacks\ninterpretability and robustness. To address these issues, we propose a\nVAD-disentangled Variational AutoEncoder (VAD-VAE), which first introduces a\ntarget utterance reconstruction task based on Variational Autoencoder, then\ndisentangles three affect representations Valence-Arousal-Dominance (VAD) from\nthe latent space. We also enhance the disentangled representations by\nintroducing VAD supervision signals from a sentiment lexicon and minimising the\nmutual information between VAD distributions. Experiments show that VAD-VAE\noutperforms the state-of-the-art model on two datasets. Further analysis proves\nthe effectiveness of each proposed module and the quality of disentangled VAD\nrepresentations. The code is available at\nhttps://github.com/SteveKGYang/VAD-VAE.", "published": "2023-05-23 13:50:06", "link": "http://arxiv.org/abs/2305.14071v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Better Zero-Shot Reasoning with Self-Adaptive Prompting", "abstract": "Modern large language models (LLMs) have demonstrated impressive capabilities\nat sophisticated tasks, often through step-by-step reasoning similar to humans.\nThis is made possible by their strong few and zero-shot abilities -- they can\neffectively learn from a handful of handcrafted, completed responses\n(\"in-context examples\"), or are prompted to reason spontaneously through\nspecially designed triggers. Nonetheless, some limitations have been observed.\nFirst, performance in the few-shot setting is sensitive to the choice of\nexamples, whose design requires significant human effort. Moreover, given the\ndiverse downstream tasks of LLMs, it may be difficult or laborious to handcraft\nper-task labels. Second, while the zero-shot setting does not require\nhandcrafting, its performance is limited due to the lack of guidance to the\nLLMs. To address these limitations, we propose Consistency-based Self-adaptive\nPrompting (COSP), a novel prompt design method for LLMs. Requiring neither\nhandcrafted responses nor ground-truth labels, COSP selects and builds the set\nof examples from the LLM zero-shot outputs via carefully designed criteria that\ncombine consistency, diversity and repetition. In the zero-shot setting for\nthree different LLMs, we show that using only LLM predictions, COSP improves\nperformance up to 15% compared to zero-shot baselines and matches or exceeds\nfew-shot baselines for a range of reasoning tasks.", "published": "2023-05-23 14:27:16", "link": "http://arxiv.org/abs/2305.14106v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding", "abstract": "We introduce ZeroSCROLLS, a zero-shot benchmark for natural language\nunderstanding over long texts, which contains only test and small validation\nsets, without training data. We adapt six tasks from the SCROLLS benchmark, and\nadd four new datasets, including two novel information fusing tasks, such as\naggregating the percentage of positive reviews. Using ZeroSCROLLS, we conduct a\ncomprehensive evaluation of both open-source and closed large language models,\nfinding that Claude outperforms ChatGPT, and that GPT-4 achieves the highest\naverage score. However, there is still room for improvement on multiple open\nchallenges in ZeroSCROLLS, such as aggregation tasks, where models struggle to\npass the naive baseline. As the state of the art is a moving target, we invite\nresearchers to evaluate their ideas on the live ZeroSCROLLS leaderboard.", "published": "2023-05-23 16:15:31", "link": "http://arxiv.org/abs/2305.14196v3", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks", "abstract": "We introduce Goat, a fine-tuned LLaMA model that significantly outperforms\nGPT-4 on a range of arithmetic tasks. Fine-tuned on a synthetically generated\ndataset, Goat achieves state-of-the-art performance on BIG-bench arithmetic\nsub-task. In particular, the zero-shot Goat-7B matches or even surpasses the\naccuracy achieved by the few-shot PaLM-540B. Surprisingly, Goat can achieve\nnear-perfect accuracy on large-number addition and subtraction through\nsupervised fine-tuning only, which is almost impossible with previous\npretrained language models, such as Bloom, OPT, GPT-NeoX, etc. We attribute\nGoat's exceptional performance to LLaMA's consistent tokenization of numbers.\nTo tackle more challenging tasks like large-number multiplication and division,\nwe propose an approach that classifies tasks based on their learnability, and\nsubsequently decomposes unlearnable tasks, such as multi-digit multiplication\nand division, into a series of learnable tasks by leveraging basic arithmetic\nprinciples. We thoroughly examine the performance of our model, offering a\ncomprehensive evaluation of the effectiveness of our proposed decomposition\nsteps. Additionally, Goat-7B can be easily trained using LoRA on a 24GB VRAM\nGPU, facilitating reproducibility for other researchers. We release our model,\ndataset, and the Python script for dataset generation.", "published": "2023-05-23 16:20:30", "link": "http://arxiv.org/abs/2305.14201v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Pre-training Multi-task Contrastive Learning Models for Scientific\n  Literature Understanding", "abstract": "Scientific literature understanding tasks have gained significant attention\ndue to their potential to accelerate scientific discovery. Pre-trained language\nmodels (LMs) have shown effectiveness in these tasks, especially when tuned via\ncontrastive learning. However, jointly utilizing pre-training data across\nmultiple heterogeneous tasks (e.g., extreme multi-label paper classification,\ncitation prediction, and literature search) remains largely unexplored. To\nbridge this gap, we propose a multi-task contrastive learning framework,\nSciMult, with a focus on facilitating common knowledge sharing across different\nscientific literature understanding tasks while preventing task-specific skills\nfrom interfering with each other. To be specific, we explore two techniques --\ntask-aware specialization and instruction tuning. The former adopts a\nMixture-of-Experts Transformer architecture with task-aware sub-layers; the\nlatter prepends task-specific instructions to the input text so as to produce\ntask-aware outputs. Extensive experiments on a comprehensive collection of\nbenchmark datasets verify the effectiveness of our task-aware specialization\nstrategy, where we outperform state-of-the-art scientific pre-trained LMs.\nCode, datasets, and pre-trained models can be found at\nhttps://scimult.github.io/.", "published": "2023-05-23 16:47:22", "link": "http://arxiv.org/abs/2305.14232v2", "categories": ["cs.CL", "cs.DL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Revisiting Machine Translation for Cross-lingual Classification", "abstract": "Machine Translation (MT) has been widely used for cross-lingual\nclassification, either by translating the test set into English and running\ninference with a monolingual model (translate-test), or translating the\ntraining set into the target languages and finetuning a multilingual model\n(translate-train). However, most research in the area focuses on the\nmultilingual models rather than the MT component. We show that, by using a\nstronger MT system and mitigating the mismatch between training on original\ntext and running inference on machine translated text, translate-test can do\nsubstantially better than previously assumed. The optimal approach, however, is\nhighly task dependent, as we identify various sources of cross-lingual transfer\ngap that affect different tasks and approaches differently. Our work calls into\nquestion the dominance of multilingual models for cross-lingual classification,\nand prompts to pay more attention to MT-based baselines.", "published": "2023-05-23 16:56:10", "link": "http://arxiv.org/abs/2305.14240v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long\n  Form Text Generation", "abstract": "Evaluating the factuality of long-form text generated by large language\nmodels (LMs) is non-trivial because (1) generations often contain a mixture of\nsupported and unsupported pieces of information, making binary judgments of\nquality inadequate, and (2) human evaluation is time-consuming and costly. In\nthis paper, we introduce FACTSCORE, a new evaluation that breaks a generation\ninto a series of atomic facts and computes the percentage of atomic facts\nsupported by a reliable knowledge source. We conduct an extensive human\nevaluation to obtain FACTSCOREs of people biographies generated by several\nstate-of-the-art commercial LMs -- InstructGPT, ChatGPT, and the\nretrieval-augmented PerplexityAI -- and report new analysis demonstrating the\nneed for such a fine-grained score (e.g., ChatGPT only achieves 58%). Since\nhuman evaluation is costly, we also introduce an automated model that estimates\nFACTSCORE using retrieval and a strong language model, with less than a 2%\nerror rate. Finally, we use this automated metric to evaluate 6,500 generations\nfrom a new set of 13 recent LMs that would have cost $26K if evaluated by\nhumans, with various findings: GPT-4 and ChatGPT are more factual than public\nmodels, and Vicuna and Alpaca are some of the best public models. FACTSCORE is\navailable for public use via `pip install factscore`.", "published": "2023-05-23 17:06:00", "link": "http://arxiv.org/abs/2305.14251v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hierarchical Prompting Assists Large Language Model on Web Navigation", "abstract": "Large language models (LLMs) struggle on processing complicated observations\nin interactive decision making tasks. To alleviate this issue, we propose a\nsimple hierarchical prompting approach. Diverging from previous prompting\napproaches that always put the full observation (e.g. a web page) to the\nprompt, we propose to first construct an action-aware observation which is more\ncondensed and relevant with a dedicated SUMMARIZER prompt. The ACTOR prompt\nthen predicts the next action based on the summarized observation. While our\nmethod has broad applicability, we particularly demonstrate its efficacy in the\ncomplex domain of web navigation where a full observation often contains\nredundant and irrelevant information. Our approach outperforms the previous\nstate-of-the-art prompting mechanics by 6.2% on task success rate,\ndemonstrating its potential on interactive decision making tasks with long\nobservation traces.", "published": "2023-05-23 17:10:39", "link": "http://arxiv.org/abs/2305.14257v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SciMON: Scientific Inspiration Machines Optimized for Novelty", "abstract": "We explore and enhance the ability of neural language models to generate\nnovel scientific directions grounded in literature. Work on literature-based\nhypothesis generation has traditionally focused on binary link\nprediction--severely limiting the expressivity of hypotheses. This line of work\nalso does not focus on optimizing novelty. We take a dramatic departure with a\nnovel setting in which models use as input background contexts (e.g., problems,\nexperimental settings, goals), and output natural language ideas grounded in\nliterature. We present SciMON, a modeling framework that uses retrieval of\n\"inspirations\" from past scientific papers, and explicitly optimizes for\nnovelty by iteratively comparing to prior papers and updating idea suggestions\nuntil sufficient novelty is achieved. Comprehensive evaluations reveal that\nGPT-4 tends to generate ideas with overall low technical depth and novelty,\nwhile our methods partially mitigate this issue. Our work represents a first\nstep toward evaluating and developing language models that generate new ideas\nderived from the scientific literature", "published": "2023-05-23 17:12:08", "link": "http://arxiv.org/abs/2305.14259v7", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Factuality and Reasoning in Language Models through Multiagent\n  Debate", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nlanguage generation, understanding, and few-shot learning in recent years. An\nextensive body of work has explored how their performance may be further\nimproved through the tools of prompting, ranging from verification,\nself-consistency, or intermediate scratchpads. In this paper, we present a\ncomplementary approach to improve language responses where multiple language\nmodel instances propose and debate their individual responses and reasoning\nprocesses over multiple rounds to arrive at a common final answer. Our findings\nindicate that this approach significantly enhances mathematical and strategic\nreasoning across a number of tasks. We also demonstrate that our approach\nimproves the factual validity of generated content, reducing fallacious answers\nand hallucinations that contemporary models are prone to. Our approach may be\ndirectly applied to existing black-box models and uses identical procedure and\nprompts for all tasks we investigate. Overall, our findings suggest that such\n\"society of minds\" approach has the potential to significantly advance the\ncapabilities of LLMs and pave the way for further breakthroughs in language\ngeneration and understanding.", "published": "2023-05-23 17:55:11", "link": "http://arxiv.org/abs/2305.14325v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DirecT2V: Large Language Models are Frame-Level Directors for Zero-Shot\n  Text-to-Video Generation", "abstract": "In the paradigm of AI-generated content (AIGC), there has been increasing\nattention to transferring knowledge from pre-trained text-to-image (T2I) models\nto text-to-video (T2V) generation. Despite their effectiveness, these\nframeworks face challenges in maintaining consistent narratives and handling\nshifts in scene composition or object placement from a single abstract user\nprompt. Exploring the ability of large language models (LLMs) to generate\ntime-dependent, frame-by-frame prompts, this paper introduces a new framework,\ndubbed DirecT2V. DirecT2V leverages instruction-tuned LLMs as directors,\nenabling the inclusion of time-varying content and facilitating consistent\nvideo generation. To maintain temporal consistency and prevent mapping the\nvalue to a different object, we equip a diffusion model with a novel value\nmapping method and dual-softmax filtering, which do not require any additional\ntraining. The experimental results validate the effectiveness of our framework\nin producing visually coherent and storyful videos from abstract user prompts,\nsuccessfully addressing the challenges of zero-shot video generation.", "published": "2023-05-23 17:57:09", "link": "http://arxiv.org/abs/2305.14330v3", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Sophia: A Scalable Stochastic Second-order Optimizer for Language Model\n  Pre-training", "abstract": "Given the massive cost of language model pre-training, a non-trivial\nimprovement of the optimization algorithm would lead to a material reduction on\nthe time and cost of training. Adam and its variants have been state-of-the-art\nfor years, and more sophisticated second-order (Hessian-based) optimizers often\nincur too much per-step overhead. In this paper, we propose Sophia,\nSecond-order Clipped Stochastic Optimization, a simple scalable second-order\noptimizer that uses a light-weight estimate of the diagonal Hessian as the\npre-conditioner. The update is the moving average of the gradients divided by\nthe moving average of the estimated Hessian, followed by element-wise clipping.\nThe clipping controls the worst-case update size and tames the negative impact\nof non-convexity and rapid change of Hessian along the trajectory. Sophia only\nestimates the diagonal Hessian every handful of iterations, which has\nnegligible average per-step time and memory overhead. On language modeling with\nGPT models of sizes ranging from 125M to 1.5B, Sophia achieves a 2x speed-up\ncompared to Adam in the number of steps, total compute, and wall-clock time,\nachieving the same perplexity with 50% fewer steps, less total compute, and\nreduced wall-clock time. Theoretically, we show that Sophia, in a much\nsimplified setting, adapts to the heterogeneous curvatures in different\nparameter dimensions, and thus has a run-time bound that does not depend on the\ncondition number of the loss.", "published": "2023-05-23 17:59:21", "link": "http://arxiv.org/abs/2305.14342v4", "categories": ["cs.LG", "cs.CL", "math.OC"], "primary_category": "cs.LG"}
{"title": "Image Manipulation via Multi-Hop Instructions -- A New Dataset and\n  Weakly-Supervised Neuro-Symbolic Approach", "abstract": "We are interested in image manipulation via natural language text -- a task\nthat is useful for multiple AI applications but requires complex reasoning over\nmulti-modal spaces. We extend recently proposed Neuro Symbolic Concept Learning\n(NSCL), which has been quite effective for the task of Visual Question\nAnswering (VQA), for the task of image manipulation. Our system referred to as\nNeuroSIM can perform complex multi-hop reasoning over multi-object scenes and\nonly requires weak supervision in the form of annotated data for VQA. NeuroSIM\nparses an instruction into a symbolic program, based on a Domain Specific\nLanguage (DSL) comprising of object attributes and manipulation operations,\nthat guides its execution. We create a new dataset for the task, and extensive\nexperiments demonstrate that NeuroSIM is highly competitive with or beats SOTA\nbaselines that make use of supervised data for manipulation.", "published": "2023-05-23 17:59:10", "link": "http://arxiv.org/abs/2305.14410v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Having Beer after Prayer? Measuring Cultural Bias in Large Language\n  Models", "abstract": "As the reach of large language models (LMs) expands globally, their ability\nto cater to diverse cultural contexts becomes crucial. Despite advancements in\nmultilingual capabilities, models are not designed with appropriate cultural\nnuances. In this paper, we show that multilingual and Arabic monolingual LMs\nexhibit bias towards entities associated with Western culture. We introduce\nCAMeL, a novel resource of 628 naturally-occurring prompts and 20,368 entities\nspanning eight types that contrast Arab and Western cultures. CAMeL provides a\nfoundation for measuring cultural biases in LMs through both extrinsic and\nintrinsic evaluations. Using CAMeL, we examine the cross-cultural performance\nin Arabic of 16 different LMs on tasks such as story generation, NER, and\nsentiment analysis, where we find concerning cases of stereotyping and cultural\nunfairness. We further test their text-infilling performance, revealing the\nincapability of appropriate adaptation to Arab cultural contexts. Finally, we\nanalyze 6 Arabic pre-training corpora and find that commonly used sources such\nas Wikipedia may not be best suited to build culturally aware LMs, if used as\nthey are without adjustment. We will make CAMeL publicly available at:\nhttps://github.com/tareknaous/camel", "published": "2023-05-23 18:27:51", "link": "http://arxiv.org/abs/2305.14456v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ReadMe++: Benchmarking Multilingual Language Models for Multi-Domain\n  Readability Assessment", "abstract": "We present a comprehensive evaluation of large language models for\nmultilingual readability assessment. Existing evaluation resources lack domain\nand language diversity, limiting the ability for cross-domain and cross-lingual\nanalyses. This paper introduces ReadMe++, a multilingual multi-domain dataset\nwith human annotations of 9757 sentences in Arabic, English, French, Hindi, and\nRussian, collected from 112 different data sources. This benchmark will\nencourage research on developing robust multilingual readability assessment\nmethods. Using ReadMe++, we benchmark multilingual and monolingual language\nmodels in the supervised, unsupervised, and few-shot prompting settings. The\ndomain and language diversity in ReadMe++ enable us to test more effective\nfew-shot prompting, and identify shortcomings in state-of-the-art unsupervised\nmethods. Our experiments also reveal exciting results of superior domain\ngeneralization and enhanced cross-lingual transfer capabilities by models\ntrained on ReadMe++. We will make our data publicly available and release a\npython package tool for multilingual sentence readability prediction using our\ntrained models at: https://github.com/tareknaous/readme", "published": "2023-05-23 18:37:30", "link": "http://arxiv.org/abs/2305.14463v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RetICL: Sequential Retrieval of In-Context Examples with Reinforcement\n  Learning", "abstract": "Recent developments in large pre-trained language models have enabled\nunprecedented performance on a variety of downstream tasks. Achieving best\nperformance with these models often leverages in-context learning, where a\nmodel performs a (possibly new) task given one or more examples. However,\nrecent work has shown that the choice of examples can have a large impact on\ntask performance and that finding an optimal set of examples is non-trivial.\nWhile there are many existing methods for selecting in-context examples, they\ngenerally score examples independently, ignoring the dependency between them\nand the order in which they are provided to the model. In this work, we propose\nRetrieval for In-Context Learning (RetICL), a learnable method for modeling and\noptimally selecting examples sequentially for in-context learning. We frame the\nproblem of sequential example selection as a Markov decision process and train\nan example retriever using reinforcement learning. We evaluate RetICL on math\nword problem solving and scientific question answering tasks and show that it\nconsistently outperforms or matches heuristic and learnable baselines. We also\nuse case studies to show that RetICL implicitly learns representations of\nproblem solving strategies.", "published": "2023-05-23 20:15:56", "link": "http://arxiv.org/abs/2305.14502v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Few-shot Adaptation to Distribution Shifts By Mixing Source and Target\n  Embeddings", "abstract": "Pretrained machine learning models need to be adapted to distribution shifts\nwhen deployed in new target environments. When obtaining labeled data from the\ntarget distribution is expensive, few-shot adaptation with only a few examples\nfrom the target distribution becomes essential. In this work, we propose\nMixPro, a lightweight and highly data-efficient approach for few-shot\nadaptation. MixPro first generates a relatively large dataset by mixing\n(linearly combining) pre-trained embeddings of large source data with those of\nthe few target examples. This process preserves important features of both\nsource and target distributions, while mitigating the specific noise in the\nsmall target data. Then, it trains a linear classifier on the mixed embeddings\nto effectively adapts the model to the target distribution without overfitting\nthe small target data. Theoretically, we demonstrate the advantages of MixPro\nover previous methods. Our experiments, conducted across various model\narchitectures on 8 datasets featuring different types of distribution shifts,\nreveal that MixPro can outperform baselines by up to 7\\%, with only 2-4 target\nexamples.", "published": "2023-05-23 20:49:45", "link": "http://arxiv.org/abs/2305.14521v3", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "On the Transferability of Whisper-based Representations for\n  \"In-the-Wild\" Cross-Task Downstream Speech Applications", "abstract": "Large self-supervised pre-trained speech models have achieved remarkable\nsuccess across various speech-processing tasks. The self-supervised training of\nthese models leads to universal speech representations that can be used for\ndifferent downstream tasks, ranging from automatic speech recognition (ASR) to\nspeaker identification. Recently, Whisper, a transformer-based model was\nproposed and trained on large amount of weakly supervised data for ASR; it\noutperformed several state-of-the-art self-supervised models. Given the\nsuperiority of Whisper for ASR, in this paper we explore the transferability of\nthe representation for four other speech tasks in SUPERB benchmark. Moreover,\nwe explore the robustness of Whisper representation for ``in the wild'' tasks\nwhere speech is corrupted by environment noise and room reverberation.\nExperimental results show Whisper achieves promising results across tasks and\nenvironmental conditions, thus showing potential for cross-task real-world\ndeployment.", "published": "2023-05-23 22:02:55", "link": "http://arxiv.org/abs/2305.14546v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "All Roads Lead to Rome? Exploring the Invariance of Transformers'\n  Representations", "abstract": "Transformer models bring propelling advances in various NLP tasks, thus\ninducing lots of interpretability research on the learned representations of\nthe models. However, we raise a fundamental question regarding the reliability\nof the representations. Specifically, we investigate whether transformers learn\nessentially isomorphic representation spaces, or those that are sensitive to\nthe random seeds in their pretraining process. In this work, we formulate the\nBijection Hypothesis, which suggests the use of bijective methods to align\ndifferent models' representation spaces. We propose a model based on invertible\nneural networks, BERT-INN, to learn the bijection more effectively than other\nexisting bijective methods such as the canonical correlation analysis (CCA). We\nshow the advantage of BERT-INN both theoretically and through extensive\nexperiments, and apply it to align the reproduced BERT embeddings to draw\ninsights that are meaningful to the interpretability research. Our code is at\nhttps://github.com/twinkle0331/BERT-similarity.", "published": "2023-05-23 22:30:43", "link": "http://arxiv.org/abs/2305.14555v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Robust Representation Learning with Reliable Pseudo-labels Generation\n  via Self-Adaptive Optimal Transport for Short Text Clustering", "abstract": "Short text clustering is challenging since it takes imbalanced and noisy data\nas inputs. Existing approaches cannot solve this problem well, since (1) they\nare prone to obtain degenerate solutions especially on heavy imbalanced\ndatasets, and (2) they are vulnerable to noises. To tackle the above issues, we\npropose a Robust Short Text Clustering (RSTC) model to improve robustness\nagainst imbalanced and noisy data. RSTC includes two modules, i.e.,\npseudo-label generation module and robust representation learning module. The\nformer generates pseudo-labels to provide supervision for the later, which\ncontributes to more robust representations and correctly separated clusters. To\nprovide robustness against the imbalance in data, we propose self-adaptive\noptimal transport in the pseudo-label generation module. To improve robustness\nagainst the noise in data, we further introduce both class-wise and\ninstance-wise contrastive learning in the robust representation learning\nmodule. Our empirical studies on eight short text clustering datasets\ndemonstrate that RSTC significantly outperforms the state-of-the-art models.\nThe code is available at: https://github.com/hmllmh/RSTC.", "published": "2023-05-23 12:43:40", "link": "http://arxiv.org/abs/2305.16335v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Training Priors Predict Text-To-Image Model Performance", "abstract": "Text-to-image models can often generate some relations, i.e., \"astronaut\nriding horse\", but fail to generate other relations composed of the same basic\nparts, i.e., \"horse riding astronaut\". These failures are often taken as\nevidence that models rely on training priors rather than constructing novel\nimages compositionally. This paper tests this intuition on the stablediffusion\n2.1 text-to-image model. By looking at the subject-verb-object (SVO) triads\nthat underlie these prompts (e.g., \"astronaut\", \"ride\", \"horse\"), we find that\nthe more often an SVO triad appears in the training data, the better the model\ncan generate an image aligned with that triad. Here, by aligned we mean that\neach of the terms appears in the generated image in the proper relation to each\nother. Surprisingly, this increased frequency also diminishes how well the\nmodel can generate an image aligned with the flipped triad. For example, if\n\"astronaut riding horse\" appears frequently in the training data, the image for\n\"horse riding astronaut\" will tend to be poorly aligned. Our results thus show\nthat current models are biased to generate images with relations seen in\ntraining, and provide new data to the ongoing debate on whether these\ntext-to-image models employ abstract compositional structure in a traditional\nsense, or rather, interpolate between relations explicitly seen in the training\ndata.", "published": "2023-05-23 04:54:26", "link": "http://arxiv.org/abs/2306.01755v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Understanding Programs by Exploiting (Fuzzing) Test Cases", "abstract": "Semantic understanding of programs has attracted great attention in the\ncommunity. Inspired by recent successes of large language models (LLMs) in\nnatural language understanding, tremendous progress has been made by treating\nprogramming language as another sort of natural language and training LLMs on\ncorpora of program code. However, programs are essentially different from texts\nafter all, in a sense that they are normally heavily structured and\nsyntax-strict. In particular, programs and their basic units (i.e., functions\nand subroutines) are designed to demonstrate a variety of behaviors and/or\nprovide possible outputs, given different inputs. The relationship between\ninputs and possible outputs/behaviors represents the functions/subroutines and\nprofiles the program as a whole. Therefore, we propose to incorporate such a\nrelationship into learning, for achieving a deeper semantic understanding of\nprograms. To obtain inputs that are representative enough to trigger the\nexecution of most part of the code, we resort to fuzz testing and propose fuzz\ntuning to boost the performance of program understanding and code\nrepresentation learning, given a pre-trained LLM. The effectiveness of the\nproposed method is verified on two program understanding tasks including code\nclone detection and code classification, and it outperforms current\nstate-of-the-arts by large margins. Code is available at\nhttps://github.com/rabbitjy/FuzzTuning.", "published": "2023-05-23 01:51:46", "link": "http://arxiv.org/abs/2305.13592v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Validating Multimedia Content Moderation Software via Semantic Fusion", "abstract": "The exponential growth of social media platforms, such as Facebook and\nTikTok, has revolutionized communication and content publication in human\nsociety. Users on these platforms can publish multimedia content that delivers\ninformation via the combination of text, audio, images, and video. Meanwhile,\nthe multimedia content release facility has been increasingly exploited to\npropagate toxic content, such as hate speech, malicious advertisements, and\npornography. To this end, content moderation software has been widely deployed\non these platforms to detect and blocks toxic content. However, due to the\ncomplexity of content moderation models and the difficulty of understanding\ninformation across multiple modalities, existing content moderation software\ncan fail to detect toxic content, which often leads to extremely negative\nimpacts.\n  We introduce Semantic Fusion, a general, effective methodology for validating\nmultimedia content moderation software. Our key idea is to fuse two or more\nexisting single-modal inputs (e.g., a textual sentence and an image) into a new\ninput that combines the semantics of its ancestors in a novel manner and has\ntoxic nature by construction. This fused input is then used for validating\nmultimedia content moderation software. We realized Semantic Fusion as DUO, a\npractical content moderation software testing tool. In our evaluation, we\nemploy DUO to test five commercial content moderation software and two\nstate-of-the-art models against three kinds of toxic content. The results show\nthat DUO achieves up to 100% error finding rate (EFR) when testing moderation\nsoftware. In addition, we leverage the test cases generated by DUO to retrain\nthe two models we explored, which largely improves model robustness while\nmaintaining the accuracy on the original test set.", "published": "2023-05-23 02:44:15", "link": "http://arxiv.org/abs/2305.13623v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.SE"}
{"title": "TranUSR: Phoneme-to-word Transcoder Based Unified Speech Representation\n  Learning for Cross-lingual Speech Recognition", "abstract": "UniSpeech has achieved superior performance in cross-lingual automatic speech\nrecognition (ASR) by explicitly aligning latent representations to phoneme\nunits using multi-task self-supervised learning. While the learned\nrepresentations transfer well from high-resource to low-resource languages,\npredicting words directly from these phonetic representations in downstream ASR\nis challenging. In this paper, we propose TranUSR, a two-stage model comprising\na pre-trained UniData2vec and a phoneme-to-word Transcoder. Different from\nUniSpeech, UniData2vec replaces the quantized discrete representations with\ncontinuous and contextual representations from a teacher model for\nphonetically-aware pre-training. Then, Transcoder learns to translate phonemes\nto words with the aid of extra texts, enabling direct word generation.\nExperiments on Common Voice show that UniData2vec reduces PER by 5.3% compared\nto UniSpeech, while Transcoder yields a 14.4% WER reduction compared to\ngrapheme fine-tuning.", "published": "2023-05-23 02:57:45", "link": "http://arxiv.org/abs/2305.13629v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "MP-SENet: A Speech Enhancement Model with Parallel Denoising of\n  Magnitude and Phase Spectra", "abstract": "This paper proposes MP-SENet, a novel Speech Enhancement Network which\ndirectly denoises Magnitude and Phase spectra in parallel. The proposed\nMP-SENet adopts a codec architecture in which the encoder and decoder are\nbridged by convolution-augmented transformers. The encoder aims to encode\ntime-frequency representations from the input noisy magnitude and phase\nspectra. The decoder is composed of parallel magnitude mask decoder and phase\ndecoder, directly recovering clean magnitude spectra and clean-wrapped phase\nspectra by incorporating learnable sigmoid activation and parallel phase\nestimation architecture, respectively. Multi-level losses defined on magnitude\nspectra, phase spectra, short-time complex spectra, and time-domain waveforms\nare used to train the MP-SENet model jointly. Experimental results show that\nour proposed MP-SENet achieves a PESQ of 3.50 on the public VoiceBank+DEMAND\ndataset and outperforms existing advanced speech enhancement methods.", "published": "2023-05-23 04:48:51", "link": "http://arxiv.org/abs/2305.13686v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Eeg2vec: Self-Supervised Electroencephalographic Representation Learning", "abstract": "Recently, many efforts have been made to explore how the brain processes\nspeech using electroencephalographic (EEG) signals, where deep learning-based\napproaches were shown to be applicable in this field. In order to decode speech\nsignals from EEG signals, linear networks, convolutional neural networks (CNN)\nand long short-term memory networks are often used in a supervised manner.\nRecording EEG-speech labeled data is rather time-consuming and laborious, while\nunlabeled EEG data is abundantly available. Whether self-supervised methods are\nhelpful to learn EEG representation to boost the performance of EEG\nauditory-related tasks has not been well explored. In this work, we first\npropose a self-supervised model based on contrastive loss and reconstruction\nloss to learn EEG representations, and then use the obtained pre-trained model\nas a feature extractor for downstream tasks. Second, for two considered\ndownstream tasks, we use CNNs and Transformer networks to learn local features\nand global features, respectively. Finally, the EEG data from other channels\nare mixed into the chosen EEG data for augmentation. The effectiveness of our\nmethod is verified on the EEG match-mismatch and EEG regression tasks of the\nICASSP2023 Auditory EEG Challenge.", "published": "2023-05-23 11:34:14", "link": "http://arxiv.org/abs/2305.13957v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Multi-Stream Extension of Variational Bayesian HMM Clustering (MS-VBx)\n  for Combined End-to-End and Vector Clustering-based Diarization", "abstract": "Combining end-to-end neural speaker diarization (EEND) with vector clustering\n(VC), known as EEND-VC, has gained interest for leveraging the strengths of\nboth methods. EEND-VC estimates activities and speaker embeddings for all\nspeakers within an audio chunk and uses VC to associate these activities with\nspeaker identities across different chunks. EEND-VC generates thus multiple\nstreams of embeddings, one for each speaker in a chunk. We can cluster these\nembeddings using constrained agglomerative hierarchical clustering (cAHC),\nensuring embeddings from the same chunk belong to different clusters. This\npaper introduces an alternative clustering approach, a multi-stream extension\nof the successful Bayesian HMM clustering of x-vectors (VBx), called MS-VBx.\nExperiments on three datasets demonstrate that MS-VBx outperforms cAHC in\ndiarization and speaker counting performance.", "published": "2023-05-23 01:19:28", "link": "http://arxiv.org/abs/2305.13580v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "FluentSpeech: Stutter-Oriented Automatic Speech Editing with\n  Context-Aware Diffusion Models", "abstract": "Stutter removal is an essential scenario in the field of speech editing.\nHowever, when the speech recording contains stutters, the existing text-based\nspeech editing approaches still suffer from: 1) the over-smoothing problem in\nthe edited speech; 2) lack of robustness due to the noise introduced by\nstutter; 3) to remove the stutters, users are required to determine the edited\nregion manually. To tackle the challenges in stutter removal, we propose\nFluentSpeech, a stutter-oriented automatic speech editing model. Specifically,\n1) we propose a context-aware diffusion model that iteratively refines the\nmodified mel-spectrogram with the guidance of context features; 2) we introduce\na stutter predictor module to inject the stutter information into the hidden\nsequence; 3) we also propose a stutter-oriented automatic speech editing (SASE)\ndataset that contains spontaneous speech recordings with time-aligned stutter\nlabels to train the automatic stutter localization model. Experimental results\non VCTK and LibriTTS datasets demonstrate that our model achieves\nstate-of-the-art performance on speech editing. Further experiments on our SASE\ndataset show that FluentSpeech can effectively improve the fluency of\nstuttering speech in terms of objective and subjective metrics. Code and audio\nsamples can be found at https://github.com/Zain-Jiang/Speech-Editing-Toolkit.", "published": "2023-05-23 02:20:47", "link": "http://arxiv.org/abs/2305.13612v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Detection of Cross-Dataset Fake Audio Based on Prosodic and\n  Pronunciation Features", "abstract": "Existing fake audio detection systems perform well in in-domain testing, but\nstill face many challenges in out-of-domain testing. This is due to the\nmismatch between the training and test data, as well as the poor\ngeneralizability of features extracted from limited views. To address this, we\npropose multi-view features for fake audio detection, which aim to capture more\ngeneralized features from prosodic, pronunciation, and wav2vec dimensions.\nSpecifically, the phoneme duration features are extracted from a pre-trained\nmodel based on a large amount of speech data. For the pronunciation features, a\nConformer-based phoneme recognition model is first trained, keeping the\nacoustic encoder part as a deeply embedded feature extractor. Furthermore, the\nprosodic and pronunciation features are fused with wav2vec features based on an\nattention mechanism to improve the generalization of fake audio detection\nmodels. Results show that the proposed approach achieves significant\nperformance gains in several cross-dataset experiments.", "published": "2023-05-23 05:27:39", "link": "http://arxiv.org/abs/2305.13700v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "TO-Rawnet: Improving RawNet with TCN and Orthogonal Regularization for\n  Fake Audio Detection", "abstract": "Current fake audio detection relies on hand-crafted features, which lose\ninformation during extraction. To overcome this, recent studies use direct\nfeature extraction from raw audio signals. For example, RawNet is one of the\nrepresentative works in end-to-end fake audio detection. However, existing work\non RawNet does not optimize the parameters of the Sinc-conv during training,\nwhich limited its performance. In this paper, we propose to incorporate\northogonal convolution into RawNet, which reduces the correlation between\nfilters when optimizing the parameters of Sinc-conv, thus improving\ndiscriminability. Additionally, we introduce temporal convolutional networks\n(TCN) to capture long-term dependencies in speech signals. Experiments on the\nASVspoof 2019 show that the Our TO-RawNet system can relatively reduce EER by\n66.09\\% on logical access scenario compared with the RawNet, demonstrating its\neffectiveness in detecting fake audio attacks.", "published": "2023-05-23 05:30:17", "link": "http://arxiv.org/abs/2305.13701v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A study of audio mixing methods for piano transcription in violin-piano\n  ensembles", "abstract": "While piano music transcription models have shown high performance for solo\npiano recordings, their performance degrades when applied to ensemble\nrecordings. This study aims to analyze the impact of different data\naugmentation methods on piano transcription performance, specifically focusing\non mixing techniques applied to violin-piano ensembles. We apply mixing methods\nthat consider both harmonic and temporal characteristics of the audio. To\ncreate datasets for this study, we generated the PFVN-synth dataset, which\ncontains 7 hours of violin-piano ensemble audio by rendering MIDI files and\ncorresponding labels, and also collected unaccompanied violin recordings and\nmixed them with the MAESTRO dataset. We evaluated the transcription results on\nboth synthesized and real audio recordings datasets.", "published": "2023-05-23 07:19:18", "link": "http://arxiv.org/abs/2305.13758v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ADD 2023: the Second Audio Deepfake Detection Challenge", "abstract": "Audio deepfake detection is an emerging topic in the artificial intelligence\ncommunity. The second Audio Deepfake Detection Challenge (ADD 2023) aims to\nspur researchers around the world to build new innovative technologies that can\nfurther accelerate and foster research on detecting and analyzing deepfake\nspeech utterances. Different from previous challenges (e.g. ADD 2022), ADD 2023\nfocuses on surpassing the constraints of binary real/fake classification, and\nactually localizing the manipulated intervals in a partially fake speech as\nwell as pinpointing the source responsible for generating any fake audio.\nFurthermore, ADD 2023 includes more rounds of evaluation for the fake audio\ngame sub-challenge. The ADD 2023 challenge includes three subchallenges: audio\nfake game (FG), manipulation region location (RL) and deepfake algorithm\nrecognition (AR). This paper describes the datasets, evaluation metrics, and\nprotocols. Some findings are also reported in audio deepfake detection tasks.", "published": "2023-05-23 07:42:52", "link": "http://arxiv.org/abs/2305.13774v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Happy or Evil Laughter? Analysing a Database of Natural Audio Samples", "abstract": "We conducted a data collection on the basis of the Google AudioSet database\nby selecting a subset of the samples annotated with \\textit{laughter}. The\nselection criterion was to be present a communicative act with clear\nconnotation of being either positive (laughing with) or negative (being laughed\nat). On the basis of this annotated data, we performed two experiments: on the\none hand, we manually extract and analyze phonetic features. On the other hand,\nwe conduct several machine learning experiments by systematically combining\nseveral automatically extracted acoustic feature sets with machine learning\nalgorithms. This shows that the best performing models can achieve and\nunweighted average recall of .7.", "published": "2023-05-23 12:56:35", "link": "http://arxiv.org/abs/2305.14023v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Masked Modeling Duo for Speech: Specializing General-Purpose Audio\n  Representation to Speech using Denoising Distillation", "abstract": "Self-supervised learning general-purpose audio representations have\ndemonstrated high performance in a variety of tasks. Although they can be\noptimized for application by fine-tuning, even higher performance can be\nexpected if they can be specialized to pre-train for an application. This paper\nexplores the challenges and solutions in specializing general-purpose audio\nrepresentations for a specific application using speech, a highly demanding\nfield, as an example. We enhance Masked Modeling Duo (M2D), a general-purpose\nmodel, to close the performance gap with state-of-the-art (SOTA) speech models.\nTo do so, we propose a new task, denoising distillation, to learn from\nfine-grained clustered features, and M2D for Speech (M2D-S), which jointly\nlearns the denoising distillation task and M2D masked prediction task.\nExperimental results show that M2D-S performs comparably to or outperforms SOTA\nspeech models on the SUPERB benchmark, demonstrating that M2D can specialize in\na demanding field. Our code is available at:\nhttps://github.com/nttcslab/m2d/tree/master/speech", "published": "2023-05-23 14:00:39", "link": "http://arxiv.org/abs/2305.14079v3", "categories": ["eess.AS", "cs.SD", "68T07"], "primary_category": "eess.AS"}
{"title": "Understanding Spoken Language Development of Children with ASD Using\n  Pre-trained Speech Embeddings", "abstract": "Speech processing techniques are useful for analyzing speech and language\ndevelopment in children with Autism Spectrum Disorder (ASD), who are often\nvaried and delayed in acquiring these skills. Early identification and\nintervention are crucial, but traditional assessment methodologies such as\ncaregiver reports are not adequate for the requisite behavioral phenotyping.\nNatural Language Sample (NLS) analysis has gained attention as a promising\ncomplement. Researchers have developed benchmarks for spoken language\ncapabilities in children with ASD, obtainable through the analysis of NLS. This\npaper proposes applications of speech processing technologies in support of\nautomated assessment of children's spoken language development by\nclassification between child and adult speech and between speech and nonverbal\nvocalization in NLS, with respective F1 macro scores of 82.6% and 67.8%,\nunderscoring the potential for accurate and scalable tools for ASD research and\nclinical use.", "published": "2023-05-23 14:39:49", "link": "http://arxiv.org/abs/2305.14117v2", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Improving the Gap in Visual Speech Recognition Between Normal and Silent\n  Speech Based on Metric Learning", "abstract": "This paper presents a novel metric learning approach to address the\nperformance gap between normal and silent speech in visual speech recognition\n(VSR). The difference in lip movements between the two poses a challenge for\nexisting VSR models, which exhibit degraded accuracy when applied to silent\nspeech. To solve this issue and tackle the scarcity of training data for silent\nspeech, we propose to leverage the shared literal content between normal and\nsilent speech and present a metric learning approach based on visemes.\nSpecifically, we aim to map the input of two speech types close to each other\nin a latent space if they have similar viseme representations. By minimizing\nthe Kullback-Leibler divergence of the predicted viseme probability\ndistributions between and within the two speech types, our model effectively\nlearns and predicts viseme identities. Our evaluation demonstrates that our\nmethod improves the accuracy of silent VSR, even when limited training data is\navailable.", "published": "2023-05-23 16:20:46", "link": "http://arxiv.org/abs/2305.14203v2", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Multimodal sensor fusion for real-time location-dependent defect\n  detection in laser-directed energy deposition", "abstract": "Real-time defect detection is crucial in laser-directed energy deposition\n(L-DED) additive manufacturing (AM). Traditional in-situ monitoring approach\nutilizes a single sensor (i.e., acoustic, visual, or thermal sensor) to capture\nthe complex process dynamic behaviors, which is insufficient for defect\ndetection with high accuracy and robustness. This paper proposes a novel\nmultimodal sensor fusion method for real-time location-dependent defect\ndetection in the robotic L-DED process. The multimodal fusion sources include a\nmicrophone sensor capturing the laser-material interaction sound and a visible\nspectrum CCD camera capturing the coaxial melt pool images. A hybrid\nconvolutional neural network (CNN) is proposed to fuse acoustic and visual\ndata. The key novelty in this study is that the traditional manual feature\nextraction procedures are no longer required, and the raw melt pool images and\nacoustic signals are fused directly by the hybrid CNN model, which achieved the\nhighest defect prediction accuracy (98.5 %) without the thermal sensing\nmodality. Moreover, unlike previous region-based quality prediction, the\nproposed hybrid CNN can detect the onset of defect occurrences. The defect\nprediction outcomes are synchronized and registered with in-situ acquired robot\ntool-center-point (TCP) data, which enables localized defect identification.\nThe proposed multimodal sensor fusion method offers a robust solution for\nin-situ defect detection.", "published": "2023-05-23 01:57:12", "link": "http://arxiv.org/abs/2305.13596v1", "categories": ["eess.IV", "eess.AS", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Patch-Mix Contrastive Learning with Audio Spectrogram Transformer on\n  Respiratory Sound Classification", "abstract": "Respiratory sound contains crucial information for the early diagnosis of\nfatal lung diseases. Since the COVID-19 pandemic, there has been a growing\ninterest in contact-free medical care based on electronic stethoscopes. To this\nend, cutting-edge deep learning models have been developed to diagnose lung\ndiseases; however, it is still challenging due to the scarcity of medical data.\nIn this study, we demonstrate that the pretrained model on large-scale visual\nand audio datasets can be generalized to the respiratory sound classification\ntask. In addition, we introduce a straightforward Patch-Mix augmentation, which\nrandomly mixes patches between different samples, with Audio Spectrogram\nTransformer (AST). We further propose a novel and effective Patch-Mix\nContrastive Learning to distinguish the mixed representations in the latent\nspace. Our method achieves state-of-the-art performance on the ICBHI dataset,\noutperforming the prior leading score by an improvement of 4.08%.", "published": "2023-05-23 13:04:07", "link": "http://arxiv.org/abs/2305.14032v5", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Can Self-Supervised Neural Representations Pre-Trained on Human Speech\n  distinguish Animal Callers?", "abstract": "Self-supervised learning (SSL) models use only the intrinsic structure of a\ngiven signal, independent of its acoustic domain, to extract essential\ninformation from the input to an embedding space. This implies that the utility\nof such representations is not limited to modeling human speech alone. Building\non this understanding, this paper explores the cross-transferability of SSL\nneural representations learned from human speech to analyze bio-acoustic\nsignals. We conduct a caller discrimination analysis and a caller detection\nstudy on Marmoset vocalizations using eleven SSL models pre-trained with\nvarious pretext tasks. The results show that the embedding spaces carry\nmeaningful caller information and can successfully distinguish the individual\nidentities of Marmoset callers without fine-tuning. This demonstrates that\nrepresentations pre-trained on human speech can be effectively applied to the\nbio-acoustics domain, providing valuable insights for future investigations in\nthis field.", "published": "2023-05-23 13:06:14", "link": "http://arxiv.org/abs/2305.14035v3", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Enhancing Speech Emotion Recognition Through Differentiable Architecture\n  Search", "abstract": "Speech Emotion Recognition (SER) is a critical enabler of emotion-aware\ncommunication in human-computer interactions. Recent advancements in Deep\nLearning (DL) have substantially enhanced the performance of SER models through\nincreased model complexity. However, designing optimal DL architectures\nrequires prior experience and experimental evaluations. Encouragingly, Neural\nArchitecture Search (NAS) offers a promising avenue to determine an optimal DL\nmodel automatically. In particular, Differentiable Architecture Search (DARTS)\nis an efficient method of using NAS to search for optimised models. This paper\nproposes a DARTS-optimised joint CNN and LSTM architecture, to improve SER\nperformance, where the literature informs the selection of CNN and LSTM\ncoupling to offer improved performance. While DARTS has previously been applied\nto CNN and LSTM combinations, our approach introduces a novel mechanism,\nparticularly in selecting CNN operations using DARTS. In contrast to previous\nstudies, we refrain from imposing constraints on the order of the layers for\nthe CNN within the DARTS cell; instead, we allow DARTS to determine the optimal\nlayer order autonomously. Experimenting with the IEMOCAP and MSP-IMPROV\ndatasets, we demonstrate that our proposed methodology achieves significantly\nhigher SER accuracy than hand-engineering the CNN-LSTM configuration. It also\noutperforms the best-reported SER results achieved using DARTS on CNN-LSTM.", "published": "2023-05-23 10:16:08", "link": "http://arxiv.org/abs/2305.14402v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "QFA2SR: Query-Free Adversarial Transfer Attacks to Speaker Recognition\n  Systems", "abstract": "Current adversarial attacks against speaker recognition systems (SRSs)\nrequire either white-box access or heavy black-box queries to the target SRS,\nthus still falling behind practical attacks against proprietary commercial APIs\nand voice-controlled devices. To fill this gap, we propose QFA2SR, an effective\nand imperceptible query-free black-box attack, by leveraging the\ntransferability of adversarial voices. To improve transferability, we present\nthree novel methods, tailored loss functions, SRS ensemble, and time-freq\ncorrosion. The first one tailors loss functions to different attack scenarios.\nThe latter two augment surrogate SRSs in two different ways. SRS ensemble\ncombines diverse surrogate SRSs with new strategies, amenable to the unique\nscoring characteristics of SRSs. Time-freq corrosion augments surrogate SRSs by\nincorporating well-designed time-/frequency-domain modification functions,\nwhich simulate and approximate the decision boundary of the target SRS and\ndistortions introduced during over-the-air attacks. QFA2SR boosts the targeted\ntransferability by 20.9%-70.7% on four popular commercial APIs (Microsoft\nAzure, iFlytek, Jingdong, and TalentedSoft), significantly outperforming\nexisting attacks in query-free setting, with negligible effect on the\nimperceptibility. QFA2SR is also highly effective when launched over the air\nagainst three wide-spread voice assistants (Google Assistant, Apple Siri, and\nTMall Genie) with 60%, 46%, and 70% targeted transferability, respectively.", "published": "2023-05-23 14:20:13", "link": "http://arxiv.org/abs/2305.14097v2", "categories": ["cs.CR", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
