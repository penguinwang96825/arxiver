{"title": "Data-Efficient Finetuning Using Cross-Task Nearest Neighbors", "abstract": "Obtaining labeled data to train a model for a task of interest is often\nexpensive. Prior work shows training models on multitask data augmented with\ntask descriptions (prompts) effectively transfers knowledge to new tasks.\nTowards efficiently building task-specific models, we assume access to a small\nnumber (32-1000) of unlabeled target-task examples and use those to retrieve\nthe most similar labeled examples from a large pool of multitask data augmented\nwith prompts. Compared to the current practice of finetuning models on\nuniformly sampled prompted multitask data (e.g.: FLAN, T0), our approach of\nfinetuning on cross-task nearest neighbors is significantly more\ndata-efficient. Using only 2% of the data from the P3 pool without any labeled\ntarget-task data, our models outperform strong baselines trained on all\navailable data by 3-30% on 12 out of 14 datasets representing held-out tasks\nincluding legal and scientific document QA. Similarly, models trained on\ncross-task nearest neighbors from SuperNaturalInstructions, representing about\n5% of the pool, obtain comparable performance to state-of-the-art models on 12\nheld-out tasks from that pool. Moreover, the models produced by our approach\nalso provide a better initialization than single multitask finetuned models for\nfew-shot finetuning on target-task data, as shown by a 2-23% relative\nimprovement over few-shot finetuned T0-3B models on 8 datasets.", "published": "2022-12-01 00:53:04", "link": "http://arxiv.org/abs/2212.00196v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Biomedical NER for the Enterprise with Distillated BERN2 and the Kazu\n  Framework", "abstract": "In order to assist the drug discovery/development process, pharmaceutical\ncompanies often apply biomedical NER and linking techniques over internal and\npublic corpora. Decades of study of the field of BioNLP has produced a plethora\nof algorithms, systems and datasets. However, our experience has been that no\nsingle open source system meets all the requirements of a modern pharmaceutical\ncompany. In this work, we describe these requirements according to our\nexperience of the industry, and present Kazu, a highly extensible, scalable\nopen source framework designed to support BioNLP for the pharmaceutical sector.\nKazu is a built around a computationally efficient version of the BERN2 NER\nmodel (TinyBERN2), and subsequently wraps several other BioNLP technologies\ninto one coherent system. KAZU framework is open-sourced:\nhttps://github.com/AstraZeneca/KAZU", "published": "2022-12-01 02:07:55", "link": "http://arxiv.org/abs/2212.00223v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Select from Multiple Options", "abstract": "Many NLP tasks can be regarded as a selection problem from a set of options,\nsuch as classification tasks, multi-choice question answering, etc. Textual\nentailment (TE) has been shown as the state-of-the-art (SOTA) approach to\ndealing with those selection problems. TE treats input texts as premises (P),\noptions as hypotheses (H), then handles the selection problem by modeling (P,\nH) pairwise. Two limitations: first, the pairwise modeling is unaware of other\noptions, which is less intuitive since humans often determine the best options\nby comparing competing candidates; second, the inference process of pairwise TE\nis time-consuming, especially when the option space is large. To deal with the\ntwo issues, this work first proposes a contextualized TE model (Context-TE) by\nappending other k options as the context of the current (P, H) modeling.\nContext-TE is able to learn more reliable decision for the H since it considers\nvarious context. Second, we speed up Context-TE by coming up with Parallel-TE,\nwhich learns the decisions of multiple options simultaneously. Parallel-TE\nsignificantly improves the inference speed while keeping comparable performance\nwith Context-TE. Our methods are evaluated on three tasks (ultra-fine entity\ntyping, intent detection and multi-choice QA) that are typical selection\nproblems with different sizes of options. Experiments show our models set new\nSOTA performance; particularly, Parallel-TE is faster than the pairwise TE by k\ntimes in inference. Our code is publicly available at\nhttps://github.com/jiangshdd/LearningToSelect.", "published": "2022-12-01 06:14:57", "link": "http://arxiv.org/abs/2212.00301v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Model Pre-training on True Negatives", "abstract": "Discriminative pre-trained language models (PLMs) learn to predict original\ntexts from intentionally corrupted ones. Taking the former text as positive and\nthe latter as negative samples, the PLM can be trained effectively for\ncontextualized representation. However, the training of such a type of PLMs\nhighly relies on the quality of the automatically constructed samples. Existing\nPLMs simply treat all corrupted texts as equal negative without any\nexamination, which actually lets the resulting model inevitably suffer from the\nfalse negative issue where training is carried out on pseudo-negative data and\nleads to less efficiency and less robustness in the resulting PLMs. In this\nwork, on the basis of defining the false negative issue in discriminative PLMs\nthat has been ignored for a long time, we design enhanced pre-training methods\nto counteract false negative predictions and encourage pre-training language\nmodels on true negatives by correcting the harmful gradient updates subject to\nfalse negative predictions. Experimental results on GLUE and SQuAD benchmarks\nshow that our counter-false-negative pre-training methods indeed bring about\nbetter performance together with stronger robustness.", "published": "2022-12-01 12:24:19", "link": "http://arxiv.org/abs/2212.00460v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CUNI Non-Autoregressive System for the WMT 22 Efficient Translation\n  Shared Task", "abstract": "We present a non-autoregressive system submission to the WMT 22 Efficient\nTranslation Shared Task. Our system was used by Helcl et al. (2022) in an\nattempt to provide fair comparison between non-autoregressive and\nautoregressive models. This submission is an effort to establish solid\nbaselines along with sound evaluation methodology, particularly in terms of\nmeasuring the decoding speed. The model itself is a 12-layer Transformer model\ntrained with connectionist temporal classification on knowledge-distilled\ndataset by a strong autoregressive teacher model.", "published": "2022-12-01 13:03:45", "link": "http://arxiv.org/abs/2212.00477v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IRRGN: An Implicit Relational Reasoning Graph Network for Multi-turn\n  Response Selection", "abstract": "The task of response selection in multi-turn dialogue is to find the best\noption from all candidates. In order to improve the reasoning ability of the\nmodel, previous studies pay more attention to using explicit algorithms to\nmodel the dependencies between utterances, which are deterministic, limited and\ninflexible. In addition, few studies consider differences between the options\nbefore and after reasoning. In this paper, we propose an Implicit Relational\nReasoning Graph Network to address these issues, which consists of the\nUtterance Relational Reasoner (URR) and the Option Dual Comparator (ODC). URR\naims to implicitly extract dependencies between utterances, as well as\nutterances and options, and make reasoning with relational graph convolutional\nnetworks. ODC focuses on perceiving the difference between the options through\ndual comparison, which can eliminate the interference of the noise options.\nExperimental results on two multi-turn dialogue reasoning benchmark datasets\nMuTual and MuTual+ show that our method significantly improves the baseline of\nfour pretrained language models and achieves state-of-the-art performance. The\nmodel surpasses human performance for the first time on the MuTual dataset.", "published": "2022-12-01 13:17:25", "link": "http://arxiv.org/abs/2212.00482v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CUNI Systems for the WMT22 Czech-Ukrainian Translation Task", "abstract": "We present Charles University submissions to the WMT22 General Translation\nShared Task on Czech-Ukrainian and Ukrainian-Czech machine translation. We\npresent two constrained submissions based on block back-translation and tagged\nback-translation and experiment with rule-based romanization of Ukrainian. Our\nresults show that the romanization only has a minor effect on the translation\nquality. Further, we describe Charles Translator, a system that was developed\nin March 2022 as a response to the migration from Ukraine to the Czech\nRepublic. Compared to our constrained systems, it did not use the romanization\nand used some proprietary data sources.", "published": "2022-12-01 13:25:10", "link": "http://arxiv.org/abs/2212.00486v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CultureBERT: Measuring Corporate Culture With Transformer-Based Language\n  Models", "abstract": "This paper introduces transformer-based language models to the literature\nmeasuring corporate culture from text documents. We compile a unique data set\nof employee reviews that were labeled by human evaluators with respect to the\ninformation the reviews reveal about the firms' corporate culture. Using this\ndata set, we fine-tune state-of-the-art transformer-based language models to\nperform the same classification task. In out-of-sample predictions, our\nlanguage models classify 17 to 30 percentage points more of employee reviews in\nline with human evaluators than traditional approaches of text classification.\nWe make our models publicly available.", "published": "2022-12-01 14:01:13", "link": "http://arxiv.org/abs/2212.00509v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Effective Deployment of Contrastive Learning in Multi-label Text\n  Classification", "abstract": "The effectiveness of contrastive learning technology in natural language\nprocessing tasks is yet to be explored and analyzed. How to construct positive\nand negative samples correctly and reasonably is the core challenge of\ncontrastive learning. It is even harder to discover contrastive objects in\nmulti-label text classification tasks. There are very few contrastive losses\nproposed previously. In this paper, we investigate the problem from a different\nangle by proposing five novel contrastive losses for multi-label text\nclassification tasks. These are Strict Contrastive Loss (SCL), Intra-label\nContrastive Loss (ICL), Jaccard Similarity Contrastive Loss (JSCL), Jaccard\nSimilarity Probability Contrastive Loss (JSPCL), and Stepwise Label Contrastive\nLoss (SLCL). We explore the effectiveness of contrastive learning for\nmulti-label text classification tasks by the employment of these novel losses\nand provide a set of baseline models for deploying contrastive learning\ntechniques on specific tasks. We further perform an interpretable analysis of\nour approach to show how different components of contrastive learning losses\nplay their roles. The experimental results show that our proposed contrastive\nlosses can bring improvement to multi-label text classification tasks. Our work\nalso explores how contrastive learning should be adapted for multi-label text\nclassification tasks.", "published": "2022-12-01 15:00:16", "link": "http://arxiv.org/abs/2212.00552v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extensible Prompts for Language Models on Zero-shot Language Style\n  Customization", "abstract": "We propose eXtensible Prompt (X-Prompt) for prompting a large language model\n(LLM) beyond natural language (NL). X-Prompt instructs an LLM with not only NL\nbut also an extensible vocabulary of imaginary words. Registering new imaginary\nwords allows us to instruct the LLM to comprehend concepts that are difficult\nto describe with NL words, thereby making a prompt more descriptive. Also,\nthese imaginary words are designed to be out-of-distribution (OOD) robust so\nthat they can be (re)used like NL words in various prompts, distinguishing\nX-Prompt from soft prompt that is for fitting in-distribution data. We propose\ncontext-augmented learning (CAL) to learn imaginary words for general\nusability, enabling them to work properly in OOD (unseen) prompts. We\nexperiment X-Prompt for zero-shot language style customization as a case study.\nThe promising results of X-Prompt demonstrate its potential to facilitate\nadvanced interaction beyond the natural language interface, bridging the\ncommunication gap between humans and LLMs.", "published": "2022-12-01 16:11:56", "link": "http://arxiv.org/abs/2212.00616v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CliMedBERT: A Pre-trained Language Model for Climate and Health-related\n  Text", "abstract": "Climate change is threatening human health in unprecedented orders and many\nways. These threats are expected to grow unless effective and evidence-based\npolicies are developed and acted upon to minimize or eliminate them. Attaining\nsuch a task requires the highest degree of the flow of knowledge from science\ninto policy. The multidisciplinary, location-specific, and vastness of\npublished science makes it challenging to keep track of novel work in this\narea, as well as making the traditional knowledge synthesis methods inefficient\nin infusing science into policy. To this end, we consider developing multiple\ndomain-specific language models (LMs) with different variations from Climate-\nand Health-related information, which can serve as a foundational step toward\ncapturing available knowledge to enable solving different tasks, such as\ndetecting similarities between climate- and health-related concepts,\nfact-checking, relation extraction, evidence of health effects to policy text\ngeneration, and more. To our knowledge, this is the first work that proposes\ndeveloping multiple domain-specific language models for the considered domains.\nWe will make the developed models, resources, and codebase available for the\nresearchers.", "published": "2022-12-01 17:44:09", "link": "http://arxiv.org/abs/2212.00689v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Towards Practical Few-shot Federated NLP", "abstract": "Transformer-based pre-trained models have emerged as the predominant solution\nfor natural language processing (NLP). Fine-tuning such pre-trained models for\ndownstream tasks often requires a considerable amount of labeled private data.\nIn practice, private data is often distributed across heterogeneous mobile\ndevices and may be prohibited from being uploaded. Moreover, well-curated\nlabeled data is often scarce, presenting an additional challenge. To address\nthese challenges, we first introduce a data generator for federated few-shot\nlearning tasks, which encompasses the quantity and skewness of scarce labeled\ndata in a realistic setting. Subsequently, we propose AUG-FedPrompt, a\nprompt-based federated learning system that exploits abundant unlabeled data\nfor data augmentation. Our experiments indicate that AUG-FedPrompt can perform\non par with full-set fine-tuning with a limited amount of labeled data.\nHowever, such competitive performance comes at a significant system cost.", "published": "2022-12-01 00:36:48", "link": "http://arxiv.org/abs/2212.00192v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distilling Reasoning Capabilities into Smaller Language Models", "abstract": "Step-by-step reasoning approaches like chain of thought (CoT) have proved to\nbe very effective in inducing reasoning capabilities in large language models.\nHowever, the success of the CoT approach is fundamentally tied to the model\nsize, and billion parameter-scale models are often needed to get CoT to work.\nIn this paper, we propose a knowledge distillation approach that leverages the\nstep-by-step CoT reasoning capabilities of larger models and distills these\nabilities into smaller models.\n  In this work, we propose an alternative reasoning scheme, Socratic CoT, that\nlearns a decomposition of the original problem into a sequence of subproblems\nand uses it to guide the intermediate reasoning steps. We use Socratic CoT to\ntrain a combination of two small distilled models: a problem decomposer and a\nsubproblem solver. In practice, given a new problem, the two distilled models\nwork in sync to decompose and solve complex problems. On multiple reasoning\ndatasets (GSM8K, StrategyQA, and SVAMP), our proposed distillation strategies\nboosts the performance of smaller models over 70% compared to the baselines.\nFinally, we investigate when Socratic CoT is an effective alternative to CoT,\ndemonstrating cases where a much smaller model (GPT-2 large) can outperform a\n10X larger model (GPT-3 6B). Our code is available here:\nhttps://github.com/kumar-shridhar/Distiiling-LM", "published": "2022-12-01 00:39:56", "link": "http://arxiv.org/abs/2212.00193v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Modeling Complex Dialogue Mappings via Sentence Semantic Segmentation\n  Guided Conditional Variational Auto-Encoder", "abstract": "Complex dialogue mappings (CDM), including one-to-many and many-to-one\nmappings, tend to make dialogue models generate incoherent or dull responses,\nand modeling these mappings remains a huge challenge for neural dialogue\nsystems. To alleviate these problems, methods like introducing external\ninformation, reconstructing the optimization function, and manipulating data\nsamples are proposed, while they primarily focus on avoiding training with CDM,\ninevitably weakening the model's ability of understanding CDM in human\nconversations and limiting further improvements in model performance. This\npaper proposes a Sentence Semantic \\textbf{Seg}mentation guided\n\\textbf{C}onditional \\textbf{V}ariational \\textbf{A}uto-\\textbf{E}ncoder\n(SegCVAE) method which can model and take advantages of the CDM data.\nSpecifically, to tackle the incoherent problem caused by one-to-many, SegCVAE\nuses response-related prominent semantics to constrained the latent variable.\nTo mitigate the non-diverse problem brought by many-to-one, SegCVAE segments\nmultiple prominent semantics to enrich the latent variables. Three novel\ncomponents, Internal Separation, External Guidance, and Semantic Norms, are\nproposed to achieve SegCVAE. On dialogue generation tasks, both the automatic\nand human evaluation results show that SegCVAE achieves new state-of-the-art\nperformance.", "published": "2022-12-01 02:31:10", "link": "http://arxiv.org/abs/2212.00231v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Super-CLEVR: A Virtual Benchmark to Diagnose Domain Robustness in Visual\n  Reasoning", "abstract": "Visual Question Answering (VQA) models often perform poorly on\nout-of-distribution data and struggle on domain generalization. Due to the\nmulti-modal nature of this task, multiple factors of variation are intertwined,\nmaking generalization difficult to analyze. This motivates us to introduce a\nvirtual benchmark, Super-CLEVR, where different factors in VQA domain shifts\ncan be isolated in order that their effects can be studied independently. Four\nfactors are considered: visual complexity, question redundancy, concept\ndistribution and concept compositionality. With controllably generated data,\nSuper-CLEVR enables us to test VQA methods in situations where the test data\ndiffers from the training data along each of these axes. We study four existing\nmethods, including two neural symbolic methods NSCL and NSVQA, and two\nnon-symbolic methods FiLM and mDETR; and our proposed method, probabilistic\nNSVQA (P-NSVQA), which extends NSVQA with uncertainty reasoning. P-NSVQA\noutperforms other methods on three of the four domain shift factors. Our\nresults suggest that disentangling reasoning and perception, combined with\nprobabilistic uncertainty, form a strong VQA model that is more robust to\ndomain shifts. The dataset and code are released at\nhttps://github.com/Lizw14/Super-CLEVR.", "published": "2022-12-01 03:53:24", "link": "http://arxiv.org/abs/2212.00259v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "PIZZA: A new benchmark for complex end-to-end task-oriented parsing", "abstract": "Much recent work in task-oriented parsing has focused on finding a middle\nground between flat slots and intents, which are inexpressive but easy to\nannotate, and powerful representations such as the lambda calculus, which are\nexpressive but costly to annotate. This paper continues the exploration of\ntask-oriented parsing by introducing a new dataset for parsing pizza and drink\norders, whose semantics cannot be captured by flat slots and intents. We\nperform an extensive evaluation of deep-learning techniques for task-oriented\nparsing on this dataset, including different flavors of seq2seq systems and\nRNNGs. The dataset comes in two main versions, one in a recently introduced\nutterance-level hierarchical notation that we call TOP, and one whose targets\nare executable representations (EXR). We demonstrate empirically that training\nthe parser to directly generate EXR notation not only solves the problem of\nentity resolution in one fell swoop and overcomes a number of expressive\nlimitations of TOP notation, but also results in significantly greater parsing\naccuracy.", "published": "2022-12-01 04:20:07", "link": "http://arxiv.org/abs/2212.00265v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Localization vs. Semantics: Visual Representations in Unimodal and\n  Multimodal Models", "abstract": "Despite the impressive advancements achieved through vision-and-language\npretraining, it remains unclear whether this joint learning paradigm can help\nunderstand each individual modality. In this work, we conduct a comparative\nanalysis of the visual representations in existing vision-and-language models\nand vision-only models by probing a broad range of tasks, aiming to assess the\nquality of the learned representations in a nuanced manner. Interestingly, our\nempirical observations suggest that vision-and-language models are better at\nlabel prediction tasks like object and attribute prediction, while vision-only\nmodels are stronger at dense prediction tasks that require more localized\ninformation. We hope our study sheds light on the role of language in visual\nlearning, and serves as an empirical guide for various pretrained models. Code\nwill be released at https://github.com/Lizw14/visual_probing", "published": "2022-12-01 05:00:18", "link": "http://arxiv.org/abs/2212.00281v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Commonsense-Infused Language-Agnostic Learning Framework for Enhancing\n  Prediction of Political Polarity in Multilingual News Headlines", "abstract": "Predicting the political polarity of news headlines is a challenging task\nthat becomes even more challenging in a multilingual setting with low-resource\nlanguages. To deal with this, we propose to utilise the Inferential Commonsense\nKnowledge via a Translate-Retrieve-Translate strategy to introduce a learning\nframework. To begin with, we use the method of translation and retrieval to\nacquire the inferential knowledge in the target language. We then employ an\nattention mechanism to emphasise important inferences. We finally integrate the\nattended inferences into a multilingual pre-trained language model for the task\nof bias prediction. To evaluate the effectiveness of our framework, we present\na dataset of over 62.6K multilingual news headlines in five European languages\nannotated with their respective political polarities. We evaluate several\nstate-of-the-art multilingual pre-trained language models since their\nperformance tends to vary across languages (low/high resource). Evaluation\nresults demonstrate that our proposed framework is effective regardless of the\nmodels employed. Overall, the best performing model trained with only headlines\nshow 0.90 accuracy and F1, and 0.83 jaccard score. With attended knowledge in\nour framework, the same model show an increase in 2.2% accuracy and F1, and\n3.6% jaccard score. Extending our experiments to individual languages reveals\nthat the models we analyze for Slovenian perform significantly worse than other\nlanguages in our dataset. To investigate this, we assess the effect of\ntranslation quality on prediction performance. It indicates that the disparity\nin performance is most likely due to poor translation quality. We release our\ndataset and scripts at: https://github.com/Swati17293/KG-Multi-Bias for future\nresearch. Our framework has the potential to benefit journalists, social\nscientists, news producers, and consumers.", "published": "2022-12-01 06:07:01", "link": "http://arxiv.org/abs/2212.00298v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Anger Breeds Controversy: Analyzing Controversy and Emotions on Reddit", "abstract": "Emotions play an important role in interpersonal interactions and social\nconflict, yet their function in the development of controversy and disagreement\nin online conversations has not been explored. To address this gap, we study\ncontroversy on Reddit, a popular network of online discussion forums. We\ncollect discussions from a wide variety of topical forums and use emotion\ndetection to recognize a range of emotions from text, including anger, fear,\njoy, admiration, etc. Our study has three main findings. First, controversial\ncomments express more anger and less admiration, joy and optimism than\nnon-controversial comments. Second, controversial comments affect emotions of\ndownstream comments in a discussion, usually resulting in long-term increase in\nanger and a decrease in positive emotions, although the magnitude and direction\nof emotional change depends on the forum. Finally, we show that emotions help\nbetter predict which comments will become controversial. Understanding\nemotional dynamics of online discussions can help communities to better manage\nconversations.", "published": "2022-12-01 07:57:54", "link": "http://arxiv.org/abs/2212.00339v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Long-Document Cross-Lingual Summarization", "abstract": "Cross-Lingual Summarization (CLS) aims at generating summaries in one\nlanguage for the given documents in another language. CLS has attracted wide\nresearch attention due to its practical significance in the multi-lingual\nworld. Though great contributions have been made, existing CLS works typically\nfocus on short documents, such as news articles, short dialogues and guides.\nDifferent from these short texts, long documents such as academic articles and\nbusiness reports usually discuss complicated subjects and consist of thousands\nof words, making them non-trivial to process and summarize. To promote CLS\nresearch on long documents, we construct Perseus, the first long-document CLS\ndataset which collects about 94K Chinese scientific documents paired with\nEnglish summaries. The average length of documents in Perseus is more than two\nthousand tokens. As a preliminary study on long-document CLS, we build and\nevaluate various CLS baselines, including pipeline and end-to-end methods.\nExperimental results on Perseus show the superiority of the end-to-end\nbaseline, outperforming the strong pipeline models equipped with sophisticated\nmachine translation systems. Furthermore, to provide a deeper understanding, we\nmanually analyze the model outputs and discuss specific challenges faced by\ncurrent approaches. We hope that our work could benchmark long-document CLS and\nbenefit future studies.", "published": "2022-12-01 15:24:16", "link": "http://arxiv.org/abs/2212.00586v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Embedding generation for text classification of Brazilian Portuguese\n  user reviews: from bag-of-words to transformers", "abstract": "Text classification is a natural language processing (NLP) task relevant to\nmany commercial applications, like e-commerce and customer service. Naturally,\nclassifying such excerpts accurately often represents a challenge, due to\nintrinsic language aspects, like irony and nuance. To accomplish this task, one\nmust provide a robust numerical representation for documents, a process known\nas embedding. Embedding represents a key NLP field nowadays, having faced a\nsignificant advance in the last decade, especially after the introduction of\nthe word-to-vector concept and the popularization of Deep Learning models for\nsolving NLP tasks, including Convolutional Neural Networks (CNNs), Recurrent\nNeural Networks (RNNs), and Transformer-based Language Models (TLMs). Despite\nthe impressive achievements in this field, the literature coverage regarding\ngenerating embeddings for Brazilian Portuguese texts is scarce, especially when\nconsidering commercial user reviews. Therefore, this work aims to provide a\ncomprehensive experimental study of embedding approaches targeting a binary\nsentiment classification of user reviews in Brazilian Portuguese. This study\nincludes from classical (Bag-of-Words) to state-of-the-art (Transformer-based)\nNLP models. The methods are evaluated with five open-source databases with\npre-defined data partitions made available in an open digital repository to\nencourage reproducibility. The Fine-tuned TLMs achieved the best results for\nall cases, being followed by the Feature-based TLM, LSTM, and CNN, with\nalternate ranks, depending on the database under analysis.", "published": "2022-12-01 15:24:19", "link": "http://arxiv.org/abs/2212.00587v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language models and brains align due to more than next-word prediction\n  and word-level information", "abstract": "Pretrained language models have been shown to significantly predict brain\nrecordings of people comprehending language. Recent work suggests that the\nprediction of the next word is a key mechanism that contributes to this\nalignment. What is not yet understood is whether prediction of the next word is\nnecessary for this observed alignment or simply sufficient, and whether there\nare other shared mechanisms or information that are similarly important. In\nthis work, we take a step towards understanding the reasons for brain alignment\nvia two simple perturbations in popular pretrained language models. These\nperturbations help us design contrasts that can control for different types of\ninformation. By contrasting the brain alignment of these differently perturbed\nmodels, we show that improvements in alignment with brain recordings are due to\nmore than improvements in next-word prediction and word-level information.", "published": "2022-12-01 15:48:51", "link": "http://arxiv.org/abs/2212.00596v2", "categories": ["cs.CL", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "Analyzing the State of Computer Science Research with the DBLP Discovery\n  Dataset", "abstract": "The number of scientific publications continues to rise exponentially,\nespecially in Computer Science (CS). However, current solutions to analyze\nthose publications restrict access behind a paywall, offer no features for\nvisual analysis, limit access to their data, only focus on niches or\nsub-fields, and/or are not flexible and modular enough to be transferred to\nother datasets. In this thesis, we conduct a scientometric analysis to uncover\nthe implicit patterns hidden in CS metadata and to determine the state of CS\nresearch. Specifically, we investigate trends of the quantity, impact, and\ntopics for authors, venues, document types (conferences vs. journals), and\nfields of study (compared to, e.g., medicine). To achieve this we introduce the\nCS-Insights system, an interactive web application to analyze CS publications\nwith various dashboards, filters, and visualizations. The data underlying this\nsystem is the DBLP Discovery Dataset (D3), which contains metadata from 5\nmillion CS publications. Both D3 and CS-Insights are open-access, and\nCS-Insights can be easily adapted to other datasets in the future. The most\ninteresting findings of our scientometric analysis include that i) there has\nbeen a stark increase in publications, authors, and venues in the last two\ndecades, ii) many authors only recently joined the field, iii) the most cited\nauthors and venues focus on computer vision and pattern recognition, while the\nmost productive prefer engineering-related topics, iv) the preference of\nresearchers to publish in conferences over journals dwindles, v) on average,\njournal articles receive twice as many citations compared to conference papers,\nbut the contrast is much smaller for the most cited conferences and journals,\nand vi) journals also get more citations in all other investigated fields of\nstudy, while only CS and engineering publish more in conferences than journals.", "published": "2022-12-01 16:27:42", "link": "http://arxiv.org/abs/2212.00629v1", "categories": ["cs.DL", "cs.CL", "H.3.7"], "primary_category": "cs.DL"}
{"title": "What do you MEME? Generating Explanations for Visual Semantic Role\n  Labelling in Memes", "abstract": "Memes are powerful means for effective communication on social media. Their\neffortless amalgamation of viral visuals and compelling messages can have\nfar-reaching implications with proper marketing. Previous research on memes has\nprimarily focused on characterizing their affective spectrum and detecting\nwhether the meme's message insinuates any intended harm, such as hate, offense,\nracism, etc. However, memes often use abstraction, which can be elusive. Here,\nwe introduce a novel task - EXCLAIM, generating explanations for visual\nsemantic role labeling in memes. To this end, we curate ExHVV, a novel dataset\nthat offers natural language explanations of connotative roles for three types\nof entities - heroes, villains, and victims, encompassing 4,680 entities\npresent in 3K memes. We also benchmark ExHVV with several strong unimodal and\nmultimodal baselines. Moreover, we posit LUMEN, a novel multimodal, multi-task\nlearning framework that endeavors to address EXCLAIM optimally by jointly\nlearning to predict the correct semantic roles and correspondingly to generate\nsuitable natural language explanations. LUMEN distinctly outperforms the best\nbaseline across 18 standard natural language generation evaluation metrics. Our\nsystematic evaluation and analyses demonstrate that characteristic multimodal\ncues required for adjudicating semantic roles are also helpful for generating\nsuitable explanations.", "published": "2022-12-01 18:21:36", "link": "http://arxiv.org/abs/2212.00715v2", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Simplifying and Understanding State Space Models with Diagonal Linear\n  RNNs", "abstract": "Sequence models based on linear state spaces (SSMs) have recently emerged as\na promising choice of architecture for modeling long range dependencies across\nvarious modalities. However, they invariably rely on discretization of a\ncontinuous state space, which complicates their presentation and understanding.\nIn this work, we dispose of the discretization step, and propose a model based\non vanilla Diagonal Linear RNNs ($\\mathrm{DLR}$). We empirically show that,\ndespite being conceptually much simpler, $\\mathrm{DLR}$ is as performant as\npreviously-proposed SSMs on a variety of tasks and benchmarks including Long\nRange Arena and raw speech classification. Moreover, we characterize the\nexpressivity of SSMs (including $\\mathrm{DLR}$) and attention-based models via\na suite of $13$ synthetic sequence-to-sequence tasks involving interactions\nover tens of thousands of tokens, ranging from simple operations, such as\nshifting an input sequence, to detecting co-dependent visual features over long\nspatial ranges in flattened images. We find that while SSMs report near-perfect\nperformance on tasks that can be modeled via $\\textit{few}$ convolutional\nkernels, they struggle on tasks requiring $\\textit{many}$ such kernels and\nespecially when the desired sequence manipulation is\n$\\textit{context-dependent}$. Despite these limitations, $\\mathrm{DLR}$ reaches\nhigh performance on two higher-order reasoning tasks $\\mathrm{ListOpsSubTrees}$\nand $\\mathrm{PathfinderSegmentation}\\text{-}\\mathrm{256}$ with input lengths\n$8K$ and $65K$ respectively, and gives encouraging performance on\n$\\mathrm{PathfinderSegmentation}\\text{-}\\mathrm{512}$ with input length $262K$\nfor which attention is not a viable choice.", "published": "2022-12-01 18:53:06", "link": "http://arxiv.org/abs/2212.00768v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Generalizing Math Word Problem Solvers via Solution Diversification", "abstract": "Current math word problem (MWP) solvers are usually Seq2Seq models trained by\nthe (one-problem; one-solution) pairs, each of which is made of a problem\ndescription and a solution showing reasoning flow to get the correct answer.\nHowever, one MWP problem naturally has multiple solution equations. The\ntraining of an MWP solver with (one-problem; one-solution) pairs excludes other\ncorrect solutions, and thus limits the generalizability of the MWP solver. One\nfeasible solution to this limitation is to augment multiple solutions to a\ngiven problem. However, it is difficult to collect diverse and accurate augment\nsolutions through human efforts. In this paper, we design a new training\nframework for an MWP solver by introducing a solution buffer and a solution\ndiscriminator. The buffer includes solutions generated by an MWP solver to\nencourage the training data diversity. The discriminator controls the quality\nof buffered solutions to participate in training. Our framework is flexibly\napplicable to a wide setting of fully, semi-weakly and weakly supervised\ntraining for all Seq2Seq MWP solvers. We conduct extensive experiments on a\nbenchmark dataset Math23k and a new dataset named Weak12k, and show that our\nframework improves the performance of various MWP solvers under different\nsettings by generating correct and diverse solutions.", "published": "2022-12-01 19:34:58", "link": "http://arxiv.org/abs/2212.00833v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Analogical Math Word Problems Solving with Enhanced Problem-Solution\n  Association", "abstract": "Math word problem (MWP) solving is an important task in question answering\nwhich requires human-like reasoning ability. Analogical reasoning has long been\nused in mathematical education, as it enables students to apply common\nrelational structures of mathematical situations to solve new problems. In this\npaper, we propose to build a novel MWP solver by leveraging analogical MWPs,\nwhich advance the solver's generalization ability across different kinds of\nMWPs. The key idea, named analogy identification, is to associate the\nanalogical MWP pairs in a latent space, i.e., encoding an MWP close to another\nanalogical MWP, while moving away from the non-analogical ones. Moreover, a\nsolution discriminator is integrated into the MWP solver to enhance the\nassociation between the representations of MWPs and their true solutions. The\nevaluation results verify that our proposed analogical learning strategy\npromotes the performance of MWP-BERT on Math23k over the state-of-the-art model\nGenerate2Rank, with 5 times fewer parameters in the encoder. We also find that\nour model has a stronger generalization ability in solving difficult MWPs due\nto the analogical learning from easy MWPs.", "published": "2022-12-01 19:50:30", "link": "http://arxiv.org/abs/2212.00837v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Focus! Relevant and Sufficient Context Selection for News Image\n  Captioning", "abstract": "News Image Captioning requires describing an image by leveraging additional\ncontext from a news article. Previous works only coarsely leverage the article\nto extract the necessary context, which makes it challenging for models to\nidentify relevant events and named entities. In our paper, we first demonstrate\nthat by combining more fine-grained context that captures the key named\nentities (obtained via an oracle) and the global context that summarizes the\nnews, we can dramatically improve the model's ability to generate accurate news\ncaptions. This begs the question, how to automatically extract such key\nentities from an image? We propose to use the pre-trained vision and language\nretrieval model CLIP to localize the visually grounded entities in the news\narticle and then capture the non-visual entities via an open relation\nextraction model. Our experiments demonstrate that by simply selecting a better\ncontext from the article, we can significantly improve the performance of\nexisting models and achieve new state-of-the-art performance on multiple\nbenchmarks.", "published": "2022-12-01 20:00:27", "link": "http://arxiv.org/abs/2212.00843v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "a survey on GPT-3", "abstract": "This paper provides an introductory survey to GPT-3. We cover some of the\nhistorical development behind this technology, some of the key features of\nGPT-3, and discuss the machine learning model and the datasets used. We survey\nboth academic and commercial efforts applying GPT-3 in diverse domains such as\ndeveloping conversational AI chatbots, software development, creative work,\ndomain knowledge, and business productivity. We discuss some of the challenges\nthat GPT-3 faces such as the problems of training complexity, bias, and\nhallucination/incorrect answers. We also discuss the future research\nopportunities in this area.", "published": "2022-12-01 20:24:19", "link": "http://arxiv.org/abs/2212.00857v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Inference of Media Bias and Content Quality Using Natural-Language\n  Processing", "abstract": "Media bias can significantly impact the formation and development of opinions\nand sentiments in a population. It is thus important to study the emergence and\ndevelopment of partisan media and political polarization. However, it is\nchallenging to quantitatively infer the ideological positions of media outlets.\nIn this paper, we present a quantitative framework to infer both political bias\nand content quality of media outlets from text, and we illustrate this\nframework with empirical experiments with real-world data. We apply a\nbidirectional long short-term memory (LSTM) neural network to a data set of\nmore than 1 million tweets to generate a two-dimensional ideological-bias and\ncontent-quality measurement for each tweet. We then infer a ``media-bias\nchart'' of (bias, quality) coordinates for the media outlets by integrating the\n(bias, quality) measurements of the tweets of the media outlets. We also apply\na variety of baseline machine-learning methods, such as a naive-Bayes method\nand a support-vector machine (SVM), to infer the bias and quality values for\neach tweet. All of these baseline approaches are based on a bag-of-words\napproach. We find that the LSTM-network approach has the best performance of\nthe examined methods. Our results illustrate the importance of leveraging word\norder into machine-learning methods in text analysis.", "published": "2022-12-01 03:04:55", "link": "http://arxiv.org/abs/2212.00237v1", "categories": ["physics.soc-ph", "cs.CL", "cs.LG", "cs.SI"], "primary_category": "physics.soc-ph"}
{"title": "Inconsistency Ranking-based Noisy Label Detection for High-quality Data", "abstract": "The success of deep learning requires high-quality annotated and massive\ndata. However, the size and the quality of a dataset are usually a trade-off in\npractice, as data collection and cleaning are expensive and time-consuming. In\nreal-world applications, especially those using crowdsourcing datasets, it is\nimportant to exclude noisy labels. To address this, this paper proposes an\nautomatic noisy label detection (NLD) technique with inconsistency ranking for\nhigh-quality data. We apply this technique to the automatic speaker\nverification (ASV) task as a proof of concept. We investigate both inter-class\nand intra-class inconsistency ranking and compare several metric learning loss\nfunctions under different noise settings. Experimental results confirm that the\nproposed solution could increase both the efficient and effective cleaning of\nlarge-scale speaker recognition datasets.", "published": "2022-12-01 03:09:33", "link": "http://arxiv.org/abs/2212.00239v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Adapted Multimodal BERT with Layer-wise Fusion for Sentiment Analysis", "abstract": "Multimodal learning pipelines have benefited from the success of pretrained\nlanguage models. However, this comes at the cost of increased model parameters.\nIn this work, we propose Adapted Multimodal BERT (AMB), a BERT-based\narchitecture for multimodal tasks that uses a combination of adapter modules\nand intermediate fusion layers. The adapter adjusts the pretrained language\nmodel for the task at hand, while the fusion layers perform task-specific,\nlayer-wise fusion of audio-visual information with textual BERT\nrepresentations. During the adaptation process the pre-trained language model\nparameters remain frozen, allowing for fast, parameter-efficient training. In\nour ablations we see that this approach leads to efficient models, that can\noutperform their fine-tuned counterparts and are robust to input noise. Our\nexperiments on sentiment analysis with CMU-MOSEI show that AMB outperforms the\ncurrent state-of-the-art across metrics, with 3.4% relative reduction in the\nresulting error and 2.1% relative improvement in 7-class classification\naccuracy.", "published": "2022-12-01 17:31:42", "link": "http://arxiv.org/abs/2212.00678v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SOLD: Sinhala Offensive Language Dataset", "abstract": "The widespread of offensive content online, such as hate speech and\ncyber-bullying, is a global phenomenon. This has sparked interest in the\nartificial intelligence (AI) and natural language processing (NLP) communities,\nmotivating the development of various systems trained to detect potentially\nharmful content automatically. These systems require annotated datasets to\ntrain the machine learning (ML) models. However, with a few notable exceptions,\nmost datasets on this topic have dealt with English and a few other\nhigh-resource languages. As a result, the research in offensive language\nidentification has been limited to these languages. This paper addresses this\ngap by tackling offensive language identification in Sinhala, a low-resource\nIndo-Aryan language spoken by over 17 million people in Sri Lanka. We introduce\nthe Sinhala Offensive Language Dataset (SOLD) and present multiple experiments\non this dataset. SOLD is a manually annotated dataset containing 10,000 posts\nfrom Twitter annotated as offensive and not offensive at both sentence-level\nand token-level, improving the explainability of the ML models. SOLD is the\nfirst large publicly available offensive language dataset compiled for Sinhala.\nWe also introduce SemiSOLD, a larger dataset containing more than 145,000\nSinhala tweets, annotated following a semi-supervised approach.", "published": "2022-12-01 20:18:21", "link": "http://arxiv.org/abs/2212.00851v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "CHAPTER: Exploiting Convolutional Neural Network Adapters for\n  Self-supervised Speech Models", "abstract": "Self-supervised learning (SSL) is a powerful technique for learning\nrepresentations from unlabeled data. Transformer based models such as HuBERT,\nwhich consist a feature extractor and transformer layers, are leading the field\nin the speech domain. SSL models are fine-tuned on a wide range of downstream\ntasks, which involves re-training the majority of the model for each task.\nPrevious studies have introduced applying adapters, which are small lightweight\nmodules commonly used in Natural Language Processing (NLP) to adapt pre-trained\nmodels to new tasks. However, such efficient tuning techniques only provide\nadaptation at the transformer layer, but failed to perform adaptation at the\nfeature extractor. In this paper, we propose CHAPTER, an efficient tuning\nmethod specifically designed for SSL speech model, by applying CNN adapters at\nthe feature extractor. Using this method, we can only fine-tune fewer than 5%\nof parameters per task compared to fully fine-tuning and achieve better and\nmore stable performance. We empirically found that adding CNN adapters to the\nfeature extractor can help the adaptation on emotion and speaker tasks. For\ninstance, the accuracy of SID is improved from 87.71 to 91.56, and the accuracy\nof ER is improved by 5%.", "published": "2022-12-01 08:50:12", "link": "http://arxiv.org/abs/2212.01282v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Surrogate Gradient Spiking Neural Networks as Encoders for Large\n  Vocabulary Continuous Speech Recognition", "abstract": "Compared to conventional artificial neurons that produce dense and\nreal-valued responses, biologically-inspired spiking neurons transmit sparse\nand binary information, which can also lead to energy-efficient\nimplementations. Recent research has shown that spiking neural networks can be\ntrained like standard recurrent neural networks using the surrogate gradient\nmethod. They have shown promising results on speech command recognition tasks.\nUsing the same technique, we show that they are scalable to large vocabulary\ncontinuous speech recognition, where they are capable of replacing LSTMs in the\nencoder with only minor loss of performance. This suggests that they may be\napplicable to more involved sequence-to-sequence tasks. Moreover, in contrast\nto their recurrent non-spiking counterparts, they show robustness to exploding\ngradient problems without the need to use gates.", "published": "2022-12-01 12:36:26", "link": "http://arxiv.org/abs/2212.01187v2", "categories": ["cs.CL", "cs.LG", "cs.NE", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Novel Speech Feature Fusion Algorithm for Text-Independent Speaker\n  Recognition", "abstract": "A novel speech feature fusion algorithm with independent vector analysis\n(IVA) and parallel convolutional neural network (PCNN) is proposed for\ntext-independent speaker recognition. Firstly, some different feature types,\nsuch as the time domain (TD) features and the frequency domain (FD) features,\ncan be extracted from a speaker's speech, and the TD and the FD features can be\nconsidered as the linear mixtures of independent feature components (IFCs) with\nan unknown mixing system. To estimate the IFCs, the TD and the FD features of\nthe speaker's speech are concatenated to build the TD and the FD feature\nmatrix, respectively. Then, a feature tensor of the speaker's speech is\nobtained by paralleling the TD and the FD feature matrix. To enhance the\ndependence on different feature types and remove the redundancies of the same\nfeature type, the independent vector analysis (IVA) can be used to estimate the\nIFC matrices of TD and FD features with the feature tensor. The IFC matrices\nare utilized as the input of the PCNN to extract the deep features of the TD\nand FD features, respectively. The deep features can be integrated to obtain\nthe fusion feature of the speaker's speech. Finally, the fusion feature of the\nspeaker's speech is employed as the input of a deep convolutional neural\nnetwork (DCNN) classifier for speaker recognition. The experimental results\nshow the effectiveness and performances of the proposed speaker recognition\nsystem.", "published": "2022-12-01 07:28:06", "link": "http://arxiv.org/abs/2212.00329v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "High Fidelity Speech Enhancement with Band-split RNN", "abstract": "Despite the rapid progress in speech enhancement (SE) research, enhancing the\nquality of desired speech in environments with strong noise and interfering\nspeakers remains challenging. In this paper, we extend the application of the\nrecently proposed band-split RNN (BSRNN) model to full-band SE and personalized\nSE (PSE) tasks. To mitigate the effects of unstable high-frequency components\nin full-band speech, we perform bi-directional and uni-directional band-level\nmodeling to low-frequency and high-frequency subbands, respectively. For PSE\ntask, we incorporate a speaker enrollment module into BSRNN to utilize target\nspeaker information. Moreover, we utilize a MetricGAN discriminator (MGD) and a\nmulti-resolution spectrogram discriminator (MRSD) to improve perceptual quality\nmetrics. Experimental results show that our system outperforms various\ntop-ranking SE systems, achieves state-of-the-art (SOTA) results on the\nDNS-2020 test set and ranks among the top 3 in the DNS-2023 challenge.", "published": "2022-12-01 10:18:54", "link": "http://arxiv.org/abs/2212.00406v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Deep neural network techniques for monaural speech enhancement: state of\n  the art analysis", "abstract": "Deep neural networks (DNN) techniques have become pervasive in domains such\nas natural language processing and computer vision. They have achieved great\nsuccess in these domains in task such as machine translation and image\ngeneration. Due to their success, these data driven techniques have been\napplied in audio domain. More specifically, DNN models have been applied in\nspeech enhancement domain to achieve denosing, dereverberation and\nmulti-speaker separation in monaural speech enhancement. In this paper, we\nreview some dominant DNN techniques being employed to achieve speech\nseparation. The review looks at the whole pipeline of speech enhancement from\nfeature extraction, how DNN based tools are modelling both global and local\nfeatures of speech and model training (supervised and unsupervised). We also\nreview the use of speech-enhancement pre-trained models to boost speech\nenhancement process. The review is geared towards covering the dominant trends\nwith regards to DNN application in speech enhancement in speech obtained via a\nsingle speaker.", "published": "2022-12-01 08:59:21", "link": "http://arxiv.org/abs/2212.00369v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
