{"title": "Assessing Reference-Free Peer Evaluation for Machine Translation", "abstract": "Reference-free evaluation has the potential to make machine translation\nevaluation substantially more scalable, allowing us to pivot easily to new\nlanguages or domains. It has been recently shown that the probabilities given\nby a large, multilingual model can achieve state of the art results when used\nas a reference-free metric. We experiment with various modifications to this\nmodel and demonstrate that by scaling it up we can match the performance of\nBLEU. We analyze various potential weaknesses of the approach and find that it\nis surprisingly robust and likely to offer reasonable performance across a\nbroad spectrum of domains and different system qualities.", "published": "2021-04-12 00:49:51", "link": "http://arxiv.org/abs/2104.05146v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Estimation of Summary-to-Text Inconsistency by Mismatched Embeddings", "abstract": "We propose a new reference-free summary quality evaluation measure, with\nemphasis on the faithfulness. The measure is designed to find and count all\npossible minute inconsistencies of the summary with respect to the source\ndocument. The proposed ESTIME, Estimator of Summary-to-Text Inconsistency by\nMismatched Embeddings, correlates with expert scores in summary-level SummEval\ndataset stronger than other common evaluation measures not only in Consistency\nbut also in Fluency. We also introduce a method of generating subtle factual\nerrors in human summaries. We show that ESTIME is more sensitive to subtle\nerrors than other common evaluation measures.", "published": "2021-04-12 01:58:21", "link": "http://arxiv.org/abs/2104.05156v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Estimating Subjective Crowd-Evaluations as an Additional Objective to\n  Improve Natural Language Generation", "abstract": "Human ratings are one of the most prevalent methods to evaluate the\nperformance of natural language processing algorithms. Similarly, it is common\nto measure the quality of sentences generated by a natural language generation\nmodel using human raters. In this paper, we argue for exploring the use of\nsubjective evaluations within the process of training language generation\nmodels in a multi-task learning setting. As a case study, we use a\ncrowd-authored dialogue corpus to fine-tune six different language generation\nmodels. Two of these models incorporate multi-task learning and use subjective\nratings of lines as part of an explicit learning goal. A human evaluation of\nthe generated dialogue lines reveals that utterances generated by the\nmulti-tasking models were subjectively rated as the most typical, most moving\nthe conversation forward, and least offensive. Based on these promising first\nresults, we discuss future research directions for incorporating subjective\nhuman evaluations into language model training and to hence keep the human user\nin the loop during the development process.", "published": "2021-04-12 06:33:16", "link": "http://arxiv.org/abs/2104.05224v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SuperSim: a test set for word similarity and relatedness in Swedish", "abstract": "Language models are notoriously difficult to evaluate. We release SuperSim, a\nlarge-scale similarity and relatedness test set for Swedish built with expert\nhuman judgments. The test set is composed of 1,360 word-pairs independently\njudged for both relatedness and similarity by five annotators. We evaluate\nthree different models (Word2Vec, fastText, and GloVe) trained on two separate\nSwedish datasets, namely the Swedish Gigaword corpus and a Swedish Wikipedia\ndump, to provide a baseline for future comparison. We release the fully\nannotated test set, code, baseline models, and data.", "published": "2021-04-12 06:47:27", "link": "http://arxiv.org/abs/2104.05228v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Factual Probing Is [MASK]: Learning vs. Learning to Recall", "abstract": "Petroni et al. (2019) demonstrated that it is possible to retrieve world\nfacts from a pre-trained language model by expressing them as cloze-style\nprompts and interpret the model's prediction accuracy as a lower bound on the\namount of factual information it encodes. Subsequent work has attempted to\ntighten the estimate by searching for better prompts, using a disjoint set of\nfacts as training data. In this work, we make two complementary contributions\nto better understand these factual probing techniques. First, we propose\nOptiPrompt, a novel and efficient method which directly optimizes in continuous\nembedding space. We find this simple method is able to predict an additional\n6.4% of facts in the LAMA benchmark. Second, we raise a more important\nquestion: Can we really interpret these probing results as a lower bound? Is it\npossible that these prompt-search methods learn from the training data too? We\nfind, somewhat surprisingly, that the training data used by these methods\ncontains certain regularities of the underlying fact distribution, and all the\nexisting prompt methods, including ours, are able to exploit them for better\nfact prediction. We conduct a set of control experiments to disentangle\n\"learning\" from \"learning to recall\", providing a more detailed picture of what\ndifferent prompts can reveal about pre-trained language models.", "published": "2021-04-12 07:11:40", "link": "http://arxiv.org/abs/2104.05240v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Remove: Towards Isotropic Pre-trained BERT Embedding", "abstract": "Pre-trained language models such as BERT have become a more common choice of\nnatural language processing (NLP) tasks. Research in word representation shows\nthat isotropic embeddings can significantly improve performance on downstream\ntasks. However, we measure and analyze the geometry of pre-trained BERT\nembedding and find that it is far from isotropic. We find that the word vectors\nare not centered around the origin, and the average cosine similarity between\ntwo random words is much higher than zero, which indicates that the word\nvectors are distributed in a narrow cone and deteriorate the representation\ncapacity of word embedding. We propose a simple, and yet effective method to\nfix this problem: remove several dominant directions of BERT embedding with a\nset of learnable weights. We train the weights on word similarity tasks and\nshow that processed embedding is more isotropic. Our method is evaluated on\nthree standardized tasks: word similarity, word analogy, and semantic textual\nsimilarity. In all tasks, the word embedding processed by our method\nconsistently outperforms the original embedding (with average improvement of\n13% on word analogy and 16% on semantic textual similarity) and two baseline\nmethods. Our method is also proven to be more robust to changes of\nhyperparameter.", "published": "2021-04-12 08:13:59", "link": "http://arxiv.org/abs/2104.05274v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Building a Swedish Open-Domain Conversational Language Model", "abstract": "We present on-going work of evaluating the, to our knowledge, first large\ngenerative language model trained to converse in Swedish, using data from the\nonline discussion forum Flashback. We conduct a human evaluation pilot study\nthat indicates the model is often able to respond to conversations in both a\nhuman-like and informative manner, on a diverse set of topics. While data from\nonline forums can be useful to build conversational systems, we reflect on the\nnegative consequences that incautious application might have, and the need for\ntaking active measures to safeguard against them.", "published": "2021-04-12 08:18:48", "link": "http://arxiv.org/abs/2104.05277v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stay Together: A System for Single and Split-antecedent Anaphora\n  Resolution", "abstract": "The state-of-the-art on basic, single-antecedent anaphora has greatly\nimproved in recent years. Researchers have therefore started to pay more\nattention to more complex cases of anaphora such as split-antecedent anaphora,\nas in Time-Warner is considering a legal challenge to Telecommunications Inc's\nplan to buy half of Showtime Networks Inc-a move that could lead to all-out war\nbetween the two powerful companies. Split-antecedent anaphora is rarer and more\ncomplex to resolve than single-antecedent anaphora; as a result, it is not\nannotated in many datasets designed to test coreference, and previous work on\nresolving this type of anaphora was carried out in unrealistic conditions that\nassume gold mentions and/or gold split-antecedent anaphors are available. These\nsystems also focus on split-antecedent anaphors only. In this work, we\nintroduce a system that resolves both single and split-antecedent anaphors, and\nevaluate it in a more realistic setting that uses predicted mentions. We also\nstart addressing the question of how to evaluate single and split-antecedent\nanaphors together using standard coreference evaluation metrics.", "published": "2021-04-12 10:01:08", "link": "http://arxiv.org/abs/2104.05320v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Great Misalignment Problem in Human Evaluation of NLP Methods", "abstract": "We outline the Great Misalignment Problem in natural language processing\nresearch, this means simply that the problem definition is not in line with the\nmethod proposed and the human evaluation is not in line with the definition nor\nthe method. We study this misalignment problem by surveying 10 randomly sampled\npapers published in ACL 2020 that report results with human evaluation. Our\nresults show that only one paper was fully in line in terms of problem\ndefinition, method and evaluation. Only two papers presented a human evaluation\nthat was in line with what was modeled in the method. These results highlight\nthat the Great Misalignment Problem is a major one and it affects the validity\nand reproducibility of results obtained by a human evaluation.", "published": "2021-04-12 11:26:15", "link": "http://arxiv.org/abs/2104.05361v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Language Models Predict Human Reading Behavior", "abstract": "We analyze if large language models are able to predict patterns of human\nreading behavior. We compare the performance of language-specific and\nmultilingual pretrained transformer models to predict reading time measures\nreflecting natural human sentence processing on Dutch, English, German, and\nRussian texts. This results in accurate models of human reading behavior, which\nindicates that transformer models implicitly encode relative importance in\nlanguage in a way that is comparable to human processing mechanisms. We find\nthat BERT and XLM models successfully predict a range of eye tracking features.\nIn a series of experiments, we analyze the cross-domain and cross-language\nabilities of these models and show how they reflect human sentence processing.", "published": "2021-04-12 13:03:49", "link": "http://arxiv.org/abs/2104.05433v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Developing Annotated Resources for Internal Displacement Monitoring", "abstract": "This paper describes in details the design and development of a novel\nannotation framework and of annotated resources for Internal Displacement, as\nthe outcome of a collaboration with the Internal Displacement Monitoring\nCentre, aimed at improving the accuracy of their monitoring platform IDETECT.\nThe schema includes multi-faceted description of the events, including cause,\nquantity of people displaced, location and date. Higher-order facets aimed at\nimproving the information extraction, such as document relevance and type, are\nproposed. We also report a case study of machine learning application to the\ndocument classification tasks. Finally, we discuss the importance of\nstandardized schema in dataset benchmark development and its impact on the\ndevelopment of reliable disaster monitoring infrastructure.", "published": "2021-04-12 13:30:11", "link": "http://arxiv.org/abs/2104.05459v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DATE: Detecting Anomalies in Text via Self-Supervision of Transformers", "abstract": "Leveraging deep learning models for Anomaly Detection (AD) has seen\nwidespread use in recent years due to superior performances over traditional\nmethods. Recent deep methods for anomalies in images learn better features of\nnormality in an end-to-end self-supervised setting. These methods train a model\nto discriminate between different transformations applied to visual data and\nthen use the output to compute an anomaly score. We use this approach for AD in\ntext, by introducing a novel pretext task on text sequences. We learn our DATE\nmodel end-to-end, enforcing two independent and complementary self-supervision\nsignals, one at the token-level and one at the sequence-level. Under this new\ntask formulation, we show strong quantitative and qualitative results on the\n20Newsgroups and AG News datasets. In the semi-supervised setting, we\noutperform state-of-the-art results by +13.5% and +6.9%, respectively (AUROC).\nIn the unsupervised configuration, DATE surpasses all other methods even when\n10% of its training data is contaminated with outliers (compared with 0% for\nthe others).", "published": "2021-04-12 16:08:05", "link": "http://arxiv.org/abs/2104.05591v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Samanantar: The Largest Publicly Available Parallel Corpora Collection\n  for 11 Indic Languages", "abstract": "We present Samanantar, the largest publicly available parallel corpora\ncollection for Indic languages. The collection contains a total of 49.7 million\nsentence pairs between English and 11 Indic languages (from two language\nfamilies). Specifically, we compile 12.4 million sentence pairs from existing,\npublicly-available parallel corpora, and additionally mine 37.4 million\nsentence pairs from the web, resulting in a 4x increase. We mine the parallel\nsentences from the web by combining many corpora, tools, and methods: (a)\nweb-crawled monolingual corpora, (b) document OCR for extracting sentences from\nscanned documents, (c) multilingual representation models for aligning\nsentences, and (d) approximate nearest neighbor search for searching in a large\ncollection of sentences. Human evaluation of samples from the newly mined\ncorpora validate the high quality of the parallel sentences across 11\nlanguages. Further, we extract 83.4 million sentence pairs between all 55 Indic\nlanguage pairs from the English-centric parallel corpus using English as the\npivot language. We trained multilingual NMT models spanning all these languages\non Samanantar, which outperform existing models and baselines on publicly\navailable benchmarks, such as FLORES, establishing the utility of Samanantar.\nOur data and models are available publicly at\nhttps://ai4bharat.iitm.ac.in/samanantar and we hope they will help advance\nresearch in NMT and multilingual NLP for Indic languages.", "published": "2021-04-12 16:18:20", "link": "http://arxiv.org/abs/2104.05596v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Frame Forecast", "abstract": "This paper introduces semantic frame forecast, a task that predicts the\nsemantic frames that will occur in the next 10, 100, or even 1,000 sentences in\na running story. Prior work focused on predicting the immediate future of a\nstory, such as one to a few sentences ahead. However, when novelists write long\nstories, generating a few sentences is not enough to help them gain high-level\ninsight to develop the follow-up story. In this paper, we formulate a long\nstory as a sequence of \"story blocks,\" where each block contains a fixed number\nof sentences (e.g., 10, 100, or 200). This formulation allows us to predict the\nfollow-up story arc beyond the scope of a few sentences. We represent a story\nblock using the term frequencies (TF) of semantic frames in it, normalized by\neach frame's inverse document frequency (IDF). We conduct semantic frame\nforecast experiments on 4,794 books from the Bookcorpus and 7,962 scientific\nabstracts from CODA-19, with block sizes ranging from 5 to 1,000 sentences. The\nresults show that automated models can forecast the follow-up story blocks\nbetter than the random, prior, and replay baselines, indicating the task's\nfeasibility. We also learn that the models using the frame representation as\nfeatures outperform all the existing approaches when the block size is over 150\nsentences. The human evaluation also shows that the proposed frame\nrepresentation, when visualized as word clouds, is comprehensible,\nrepresentative, and specific to humans. Our code is available at\nhttps://github.com/appleternity/FrameForecasting.", "published": "2021-04-12 16:23:17", "link": "http://arxiv.org/abs/2104.05604v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Universal Syntactic and Semantic Parsing", "abstract": "While numerous attempts have been made to jointly parse syntax and semantics,\nhigh performance in one domain typically comes at the price of performance in\nthe other. This trade-off contradicts the large body of research focusing on\nthe rich interactions at the syntax-semantics interface. We explore multiple\nmodel architectures which allow us to exploit the rich syntactic and semantic\nannotations contained in the Universal Decompositional Semantics (UDS) dataset,\njointly parsing Universal Dependencies and UDS to obtain state-of-the-art\nresults in both formalisms. We analyze the behaviour of a joint model of syntax\nand semantics, finding patterns supported by linguistic theory at the\nsyntax-semantics interface. We then investigate to what degree joint modeling\ngeneralizes to a multilingual setting, where we find similar trends across 8\nlanguages.", "published": "2021-04-12 17:56:34", "link": "http://arxiv.org/abs/2104.05696v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fighting the COVID-19 Infodemic with a Holistic BERT Ensemble", "abstract": "This paper describes the TOKOFOU system, an ensemble model for misinformation\ndetection tasks based on six different transformer-based pre-trained encoders,\nimplemented in the context of the COVID-19 Infodemic Shared Task for English.\nWe fine tune each model on each of the task's questions and aggregate their\nprediction scores using a majority voting approach. TOKOFOU obtains an overall\nF1 score of 89.7%, ranking first.", "published": "2021-04-12 18:13:40", "link": "http://arxiv.org/abs/2104.05745v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-shot Intent Classification and Slot Filling with Retrieved Examples", "abstract": "Few-shot learning arises in important practical scenarios, such as when a\nnatural language understanding system needs to learn new semantic labels for an\nemerging, resource-scarce domain. In this paper, we explore retrieval-based\nmethods for intent classification and slot filling tasks in few-shot settings.\nRetrieval-based methods make predictions based on labeled examples in the\nretrieval index that are similar to the input, and thus can adapt to new\ndomains simply by changing the index without having to retrain the model.\nHowever, it is non-trivial to apply such methods on tasks with a complex label\nspace like slot filling. To this end, we propose a span-level retrieval method\nthat learns similar contextualized representations for spans with the same\nlabel via a novel batch-softmax objective. At inference time, we use the labels\nof the retrieved spans to construct the final structure with the highest\naggregated score. Our method outperforms previous systems in various few-shot\nsettings on the CLINC and SNIPS benchmarks.", "published": "2021-04-12 18:50:34", "link": "http://arxiv.org/abs/2104.05763v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Paragraph-level Simplification of Medical Texts", "abstract": "We consider the problem of learning to simplify medical texts. This is\nimportant because most reliable, up-to-date information in biomedicine is dense\nwith jargon and thus practically inaccessible to the lay audience. Furthermore,\nmanual simplification does not scale to the rapidly growing body of biomedical\nliterature, motivating the need for automated approaches. Unfortunately, there\nare no large-scale resources available for this task. In this work we introduce\na new corpus of parallel texts in English comprising technical and lay\nsummaries of all published evidence pertaining to different clinical topics. We\nthen propose a new metric based on likelihood scores from a masked language\nmodel pretrained on scientific texts. We show that this automated measure\nbetter differentiates between technical and lay summaries than existing\nheuristics. We introduce and evaluate baseline encoder-decoder Transformer\nmodels for simplification and propose a novel augmentation to these in which we\nexplicitly penalize the decoder for producing \"jargon\" terms; we find that this\nyields improvements over baselines in terms of readability.", "published": "2021-04-12 18:56:05", "link": "http://arxiv.org/abs/2104.05767v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from Executions for Semantic Parsing", "abstract": "Semantic parsing aims at translating natural language (NL) utterances onto\nmachine-interpretable programs, which can be executed against a real-world\nenvironment. The expensive annotation of utterance-program pairs has long been\nacknowledged as a major bottleneck for the deployment of contemporary neural\nmodels to real-life applications. In this work, we focus on the task of\nsemi-supervised learning where a limited amount of annotated data is available\ntogether with many unlabeled NL utterances. Based on the observation that\nprograms which correspond to NL utterances must be always executable, we\npropose to encourage a parser to generate executable programs for unlabeled\nutterances. Due to the large search space of executable programs, conventional\nmethods that use approximations based on beam-search such as self-training and\ntop-k marginal likelihood training, do not perform as well. Instead, we view\nthe problem of learning from executions from the perspective of posterior\nregularization and propose a set of new training objectives. Experimental\nresults on Overnight and GeoQuery show that our new objectives outperform\nconventional methods, bridging the gap between semi-supervised and supervised\nlearning.", "published": "2021-04-12 21:07:53", "link": "http://arxiv.org/abs/2104.05819v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Saliency Methods for Neural Language Models", "abstract": "Saliency methods are widely used to interpret neural network predictions, but\ndifferent variants of saliency methods often disagree even on the\ninterpretations of the same prediction made by the same model. In these cases,\nhow do we identify when are these interpretations trustworthy enough to be used\nin analyses? To address this question, we conduct a comprehensive and\nquantitative evaluation of saliency methods on a fundamental category of NLP\nmodels: neural language models. We evaluate the quality of prediction\ninterpretations from two perspectives that each represents a desirable property\nof these interpretations: plausibility and faithfulness. Our evaluation is\nconducted on four different datasets constructed from the existing human\nannotation of syntactic and semantic agreements, on both sentence-level and\ndocument-level. Through our evaluation, we identified various ways saliency\nmethods could yield interpretations of low quality. We recommend that future\nwork deploying such methods to neural language models should carefully validate\ntheir interpretations before drawing insights.", "published": "2021-04-12 21:19:48", "link": "http://arxiv.org/abs/2104.05824v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Synthesize Data for Semantic Parsing", "abstract": "Synthesizing data for semantic parsing has gained increasing attention\nrecently. However, most methods require handcrafted (high-precision) rules in\ntheir generative process, hindering the exploration of diverse unseen data. In\nthis work, we propose a generative model which features a (non-neural) PCFG\nthat models the composition of programs (e.g., SQL), and a BART-based\ntranslation model that maps a program to an utterance. Due to the simplicity of\nPCFG and pre-trained BART, our generative model can be efficiently learned from\nexisting data at hand. Moreover, explicitly modeling compositions using PCFG\nleads to a better exploration of unseen programs, thus generate more diverse\ndata. We evaluate our method in both in-domain and out-of-domain settings of\ntext-to-SQL parsing on the standard benchmarks of GeoQuery and Spider,\nrespectively. Our empirical results show that the synthesized data generated\nfrom our model can substantially help a semantic parser achieve better\ncompositional and domain generalization.", "published": "2021-04-12 21:24:02", "link": "http://arxiv.org/abs/2104.05827v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Targeted Adversarial Training for Natural Language Understanding", "abstract": "We present a simple yet effective Targeted Adversarial Training (TAT)\nalgorithm to improve adversarial training for natural language understanding.\nThe key idea is to introspect current mistakes and prioritize adversarial\ntraining steps to where the model errs the most. Experiments show that TAT can\nsignificantly improve accuracy over standard adversarial training on GLUE and\nattain new state-of-the-art zero-shot results on XNLI. Our code will be\nreleased at: https://github.com/namisan/mt-dnn.", "published": "2021-04-12 22:31:41", "link": "http://arxiv.org/abs/2104.05847v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What's in a Summary? Laying the Groundwork for Advances in\n  Hospital-Course Summarization", "abstract": "Summarization of clinical narratives is a long-standing research problem.\nHere, we introduce the task of hospital-course summarization. Given the\ndocumentation authored throughout a patient's hospitalization, generate a\nparagraph that tells the story of the patient admission. We construct an\nEnglish, text-to-text dataset of 109,000 hospitalizations (2M source notes) and\ntheir corresponding summary proxy: the clinician-authored \"Brief Hospital\nCourse\" paragraph written as part of a discharge note. Exploratory analyses\nreveal that the BHC paragraphs are highly abstractive with some long extracted\nfragments; are concise yet comprehensive; differ in style and content\norganization from the source notes; exhibit minimal lexical cohesion; and\nrepresent silver-standard references. Our analysis identifies multiple\nimplications for modeling this complex, multi-document summarization task.", "published": "2021-04-12 19:31:48", "link": "http://arxiv.org/abs/2105.00816v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextualized Knowledge-aware Attentive Neural Network: Enhancing\n  Answer Selection with Knowledge", "abstract": "Answer selection, which is involved in many natural language processing\napplications such as dialog systems and question answering (QA), is an\nimportant yet challenging task in practice, since conventional methods\ntypically suffer from the issues of ignoring diverse real-world background\nknowledge. In this paper, we extensively investigate approaches to enhancing\nthe answer selection model with external knowledge from knowledge graph (KG).\nFirst, we present a context-knowledge interaction learning framework,\nKnowledge-aware Neural Network (KNN), which learns the QA sentence\nrepresentations by considering a tight interaction with the external knowledge\nfrom KG and the textual information. Then, we develop two kinds of\nknowledge-aware attention mechanism to summarize both the context-based and\nknowledge-based interactions between questions and answers. To handle the\ndiversity and complexity of KG information, we further propose a Contextualized\nKnowledge-aware Attentive Neural Network (CKANN), which improves the knowledge\nrepresentation learning with structure information via a customized Graph\nConvolutional Network (GCN) and comprehensively learns context-based and\nknowledge-based sentence representation via the multi-view knowledge-aware\nattention mechanism. We evaluate our method on four widely-used benchmark QA\ndatasets, including WikiQA, TREC QA, InsuranceQA and Yahoo QA. Results verify\nthe benefits of incorporating external knowledge from KG, and show the robust\nsuperiority and extensive applicability of our method.", "published": "2021-04-12 05:52:20", "link": "http://arxiv.org/abs/2104.05216v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "FUDGE: Controlled Text Generation With Future Discriminators", "abstract": "We propose Future Discriminators for Generation (FUDGE), a flexible and\nmodular method for controlled text generation. Given a pre-existing model G for\ngenerating text from a distribution of interest, FUDGE enables conditioning on\na desired attribute a (for example, formality) while requiring access only to\nG's output logits. FUDGE learns an attribute predictor operating on a partial\nsequence, and uses this predictor's outputs to adjust G's original\nprobabilities. We show that FUDGE models terms corresponding to a Bayesian\ndecomposition of the conditional distribution of G given attribute a. Moreover,\nFUDGE can easily compose predictors for multiple desired attributes. We\nevaluate FUDGE on three tasks -- couplet completion in poetry, topic control in\nlanguage generation, and formality change in machine translation -- and observe\ngains in all three tasks.", "published": "2021-04-12 05:59:53", "link": "http://arxiv.org/abs/2104.05218v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HTCInfoMax: A Global Model for Hierarchical Text Classification via\n  Information Maximization", "abstract": "The current state-of-the-art model HiAGM for hierarchical text classification\nhas two limitations. First, it correlates each text sample with all labels in\nthe dataset which contains irrelevant information. Second, it does not consider\nany statistical constraint on the label representations learned by the\nstructure encoder, while constraints for representation learning are proved to\nbe helpful in previous work. In this paper, we propose HTCInfoMax to address\nthese issues by introducing information maximization which includes two\nmodules: text-label mutual information maximization and label prior matching.\nThe first module can model the interaction between each text sample and its\nground truth labels explicitly which filters out irrelevant information. The\nsecond one encourages the structure encoder to learn better representations\nwith desired characteristics for all labels which can better handle label\nimbalance in hierarchical text classification. Experimental results on two\nbenchmark datasets demonstrate the effectiveness of the proposed HTCInfoMax.", "published": "2021-04-12 06:04:20", "link": "http://arxiv.org/abs/2104.05220v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Unifying Misinformation Detection", "abstract": "In this paper, we introduce UnifiedM2, a general-purpose misinformation model\nthat jointly models multiple domains of misinformation with a single, unified\nsetup. The model is trained to handle four tasks: detecting news bias,\nclickbait, fake news, and verifying rumors. By grouping these tasks together,\nUnifiedM2learns a richer representation of misinformation, which leads to\nstate-of-the-art or comparable performance across all tasks. Furthermore, we\ndemonstrate that UnifiedM2's learned representation is helpful for few-shot\nlearning of unseen misinformation tasks/datasets and model's generalizability\nto unseen events.", "published": "2021-04-12 07:25:49", "link": "http://arxiv.org/abs/2104.05243v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Better Feature Integration for Named Entity Recognition", "abstract": "It has been shown that named entity recognition (NER) could benefit from\nincorporating the long-distance structured information captured by dependency\ntrees. We believe this is because both types of features - the contextual\ninformation captured by the linear sequences and the structured information\ncaptured by the dependency trees may complement each other. However, existing\napproaches largely focused on stacking the LSTM and graph neural networks such\nas graph convolutional networks (GCNs) for building improved NER models, where\nthe exact interaction mechanism between the two types of features is not very\nclear, and the performance gain does not appear to be significant. In this\nwork, we propose a simple and robust solution to incorporate both types of\nfeatures with our Synergized-LSTM (Syn-LSTM), which clearly captures how the\ntwo types of features interact. We conduct extensive experiments on several\nstandard datasets across four languages. The results demonstrate that the\nproposed model achieves better performance than previous approaches while\nrequiring fewer parameters. Our further analysis demonstrates that our model\ncan capture longer dependencies compared with strong baselines.", "published": "2021-04-12 09:55:06", "link": "http://arxiv.org/abs/2104.05316v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Machine Translation Decoding beyond Beam Search", "abstract": "Beam search is the go-to method for decoding auto-regressive machine\ntranslation models. While it yields consistent improvements in terms of BLEU,\nit is only concerned with finding outputs with high model likelihood, and is\nthus agnostic to whatever end metric or score practitioners care about. Our aim\nis to establish whether beam search can be replaced by a more powerful\nmetric-driven search technique. To this end, we explore numerous decoding\nalgorithms, including some which rely on a value function parameterised by a\nneural network, and report results on a variety of metrics. Notably, we\nintroduce a Monte-Carlo Tree Search (MCTS) based method and showcase its\ncompetitiveness. We provide a blueprint for how to use MCTS fruitfully in\nlanguage applications, which opens promising future directions. We find that\nwhich algorithm is best heavily depends on the characteristics of the goal\nmetric; we believe that our extensive experiments and analysis will inform\nfurther research in this area.", "published": "2021-04-12 10:28:17", "link": "http://arxiv.org/abs/2104.05336v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Comparing the Benefit of Synthetic Training Data for Various Automatic\n  Speech Recognition Architectures", "abstract": "Recent publications on automatic-speech-recognition (ASR) have a strong focus\non attention encoder-decoder (AED) architectures which tend to suffer from\nover-fitting in low resource scenarios. One solution to tackle this issue is to\ngenerate synthetic data with a trained text-to-speech system (TTS) if\nadditional text is available. This was successfully applied in many\npublications with AED systems, but only very limited in the context of other\nASR architectures. We investigate the effect of varying pre-processing, the\nspeaker embedding and input encoding of the TTS system w.r.t. the effectiveness\nof the synthesized data for AED-ASR training. Additionally, we also consider\ninternal language model subtraction for the first time, resulting in up to 38%\nrelative improvement. We compare the AED results to a state-of-the-art hybrid\nASR system, a monophone based system using\nconnectionist-temporal-classification (CTC) and a monotonic transducer based\nsystem. We show that for the later systems the addition of synthetic data has\nno relevant effect, but they still outperform the AED systems on\nLibriSpeech-100h. We achieve a final word-error-rate of 3.3%/10.0% with a\nhybrid system on the clean/noisy test-sets, surpassing any previous\nstate-of-the-art systems on Librispeech-100h that do not include unlabeled\naudio data.", "published": "2021-04-12 11:59:23", "link": "http://arxiv.org/abs/2104.05379v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Breaking Community Boundary: Comparing Academic and Social Communication\n  Preferences regarding Global Pandemics", "abstract": "The global spread of COVID-19 has caused pandemics to be widely discussed.\nThis is evident in the large number of scientific articles and the amount of\nuser-generated content on social media. This paper aims to compare academic\ncommunication and social communication about the pandemic from the perspective\nof communication preference differences. It aims to provide information for the\nongoing research on global pandemics, thereby eliminating knowledge barriers\nand information inequalities between the academic and the social communities.\nFirst, we collected the full text and the metadata of pandemic-related articles\nand Twitter data mentioning the articles. Second, we extracted and analyzed the\ntopics and sentiment tendencies of the articles and related tweets. Finally, we\nconducted pandemic-related differential analysis on the academic community and\nthe social community. We mined the resulting data to generate pandemic\ncommunication preferences (e.g., information needs, attitude tendencies) of\nresearchers and the public, respectively. The research results from 50,338\narticles and 927,266 corresponding tweets mentioning the articles revealed\ncommunication differences about global pandemics between the academic and the\nsocial communities regarding the consistency of research recognition and the\npreferences for particular research topics. The analysis of large-scale\npandemic-related tweets also confirmed the communication preference differences\nbetween the two communities.", "published": "2021-04-12 12:44:22", "link": "http://arxiv.org/abs/2104.05409v1", "categories": ["cs.DL", "cs.CL", "H.3.7"], "primary_category": "cs.DL"}
{"title": "Continual Learning for Text Classification with Information\n  Disentanglement Based Regularization", "abstract": "Continual learning has become increasingly important as it enables NLP models\nto constantly learn and gain knowledge over time. Previous continual learning\nmethods are mainly designed to preserve knowledge from previous tasks, without\nmuch emphasis on how to well generalize models to new tasks. In this work, we\npropose an information disentanglement based regularization method for\ncontinual learning on text classification. Our proposed method first\ndisentangles text hidden spaces into representations that are generic to all\ntasks and representations specific to each individual task, and further\nregularizes these representations differently to better constrain the knowledge\nrequired to generalize. We also introduce two simple auxiliary tasks: next\nsentence prediction and task-id prediction, for learning better generic and\nspecific representation spaces. Experiments conducted on large-scale benchmarks\ndemonstrate the effectiveness of our method in continual text classification\ntasks with various sequences and lengths over state-of-the-art baselines. We\nhave publicly released our code at https://github.com/GT-SALT/IDBR.", "published": "2021-04-12 14:17:43", "link": "http://arxiv.org/abs/2104.05489v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fine-Tuning Transformers for Identifying Self-Reporting Potential Cases\n  and Symptoms of COVID-19 in Tweets", "abstract": "We describe our straight-forward approach for Tasks 5 and 6 of 2021 Social\nMedia Mining for Health Applications (SMM4H) shared tasks. Our system is based\non fine-tuning Distill- BERT on each task, as well as first fine-tuning the\nmodel on the other task. We explore how much fine-tuning is necessary for\naccurately classifying tweets as containing self-reported COVID-19 symptoms\n(Task 5) or whether a tweet related to COVID-19 is self-reporting, non-personal\nreporting, or a literature/news mention of the virus (Task 6).", "published": "2021-04-12 14:31:51", "link": "http://arxiv.org/abs/2104.05501v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Interpretable Methods for Identifying Product Variants", "abstract": "For e-commerce companies with large product selections, the organization and\ngrouping of products in meaningful ways is important for creating great\ncustomer shopping experiences and cultivating an authoritative brand image. One\nimportant way of grouping products is to identify a family of product variants,\nwhere the variants are mostly the same with slight and yet distinct differences\n(e.g. color or pack size). In this paper, we introduce a novel approach to\nidentifying product variants. It combines both constrained clustering and\ntailored NLP techniques (e.g. extraction of product family name from\nunstructured product title and identification of products with similar model\nnumbers) to achieve superior performance compared with an existing baseline\nusing a vanilla classification approach. In addition, we design the algorithm\nto meet certain business criteria, including meeting high accuracy requirements\non a wide range of categories (e.g. appliances, decor, tools, and building\nmaterials, etc.) as well as prioritizing the interpretability of the model to\nmake it accessible and understandable to all business partners.", "published": "2021-04-12 14:37:16", "link": "http://arxiv.org/abs/2104.05504v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Self-Training with Weak Supervision", "abstract": "State-of-the-art deep neural networks require large-scale labeled training\ndata that is often expensive to obtain or not available for many tasks. Weak\nsupervision in the form of domain-specific rules has been shown to be useful in\nsuch settings to automatically generate weakly labeled training data. However,\nlearning with weak rules is challenging due to their inherent heuristic and\nnoisy nature. An additional challenge is rule coverage and overlap, where prior\nwork on weak supervision only considers instances that are covered by weak\nrules, thus leaving valuable unlabeled data behind.\n  In this work, we develop a weak supervision framework (ASTRA) that leverages\nall the available data for a given task. To this end, we leverage task-specific\nunlabeled data through self-training with a model (student) that considers\ncontextualized representations and predicts pseudo-labels for instances that\nmay not be covered by weak rules. We further develop a rule attention network\n(teacher) that learns how to aggregate student pseudo-labels with weak rule\nlabels, conditioned on their fidelity and the underlying context of an\ninstance. Finally, we construct a semi-supervised learning objective for\nend-to-end training with unlabeled data, domain-specific rules, and a small\namount of labeled data. Extensive experiments on six benchmark datasets for\ntext classification demonstrate the effectiveness of our approach with\nsignificant improvements over state-of-the-art baselines.", "published": "2021-04-12 14:45:04", "link": "http://arxiv.org/abs/2104.05514v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "WHOSe Heritage: Classification of UNESCO World Heritage \"Outstanding\n  Universal Value\" Documents with Soft Labels", "abstract": "The UNESCO World Heritage List (WHL) includes the exceptionally valuable\ncultural and natural heritage to be preserved for mankind. Evaluating and\njustifying the Outstanding Universal Value (OUV) is essential for each site\ninscribed in the WHL, and yet a complex task, even for experts, since the\nselection criteria of OUV are not mutually exclusive. Furthermore, manual\nannotation of heritage values and attributes from multi-source textual data,\nwhich is currently dominant in heritage studies, is knowledge-demanding and\ntime-consuming, impeding systematic analysis of such authoritative documents in\nterms of their implications on heritage management. This study applies\nstate-of-the-art NLP models to build a classifier on a new dataset containing\nStatements of OUV, seeking an explainable and scalable automation tool to\nfacilitate the nomination, evaluation, research, and monitoring processes of\nWorld Heritage sites. Label smoothing is innovatively adapted to improve the\nmodel performance by adding prior inter-class relationship knowledge to\ngenerate soft labels. The study shows that the best models fine-tuned from BERT\nand ULMFiT can reach 94.3% top-3 accuracy. A human study with expert evaluation\non the model prediction shows that the models are sufficiently generalizable.\nThe study is promising to be further developed and applied in heritage research\nand practice.", "published": "2021-04-12 15:18:41", "link": "http://arxiv.org/abs/2104.05547v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Backtranslation Feedback Improves User Confidence in MT, Not Quality", "abstract": "Translating text into a language unknown to the text's author, dubbed\noutbound translation, is a modern need for which the user experience has\nsignificant room for improvement, beyond the basic machine translation\nfacility. We demonstrate this by showing three ways in which user confidence in\nthe outbound translation, as well as its overall final quality, can be\naffected: backward translation, quality estimation (with alignment) and source\nparaphrasing. In this paper, we describe an experiment on outbound translation\nfrom English to Czech and Estonian. We examine the effects of each proposed\nfeedback module and further focus on how the quality of machine translation\nsystems influence these findings and the user perception of success. We show\nthat backward translation feedback has a mixed effect on the whole process: it\nincreases user confidence in the produced translation, but not the objective\nquality.", "published": "2021-04-12 17:50:24", "link": "http://arxiv.org/abs/2104.05688v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "A Replication Study of Dense Passage Retriever", "abstract": "Text retrieval using learned dense representations has recently emerged as a\npromising alternative to \"traditional\" text retrieval using sparse bag-of-words\nrepresentations. One recent work that has garnered much attention is the dense\npassage retriever (DPR) technique proposed by Karpukhin et al. (2020) for\nend-to-end open-domain question answering. We present a replication study of\nthis work, starting with model checkpoints provided by the authors, but\notherwise from an independent implementation in our group's Pyserini IR toolkit\nand PyGaggle neural text ranking library. Although our experimental results\nlargely verify the claims of the original paper, we arrived at two important\nadditional findings that contribute to a better understanding of DPR: First, it\nappears that the original authors under-report the effectiveness of the BM25\nbaseline and hence also dense--sparse hybrid retrieval results. Second, by\nincorporating evidence from the retriever and an improved answer span scoring\ntechnique, we are able to improve end-to-end question answering effectiveness\nusing exactly the same models as in the original work.", "published": "2021-04-12 18:10:39", "link": "http://arxiv.org/abs/2104.05740v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Active learning for medical code assignment", "abstract": "Machine Learning (ML) is widely used to automatically extract meaningful\ninformation from Electronic Health Records (EHR) to support operational,\nclinical, and financial decision-making. However, ML models require a large\nnumber of annotated examples to provide satisfactory results, which is not\npossible in most healthcare scenarios due to the high cost of clinician-labeled\ndata. Active Learning (AL) is a process of selecting the most informative\ninstances to be labeled by an expert to further train a supervised algorithm.\nWe demonstrate the effectiveness of AL in multi-label text classification in\nthe clinical domain. In this context, we apply a set of well-known AL methods\nto help automatically assign ICD-9 codes on the MIMIC-III dataset. Our results\nshow that the selection of informative instances provides satisfactory\nclassification with a significantly reduced training set (8.3\\% of the total\ninstances). We conclude that AL methods can significantly reduce the manual\nannotation cost while preserving model performance.", "published": "2021-04-12 18:11:17", "link": "http://arxiv.org/abs/2104.05741v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Towards a parallel corpus of Portuguese and the Bantu language Emakhuwa\n  of Mozambique", "abstract": "Major advancement in the performance of machine translation models has been\nmade possible in part thanks to the availability of large-scale parallel\ncorpora. But for most languages in the world, the existence of such corpora is\nrare. Emakhuwa, a language spoken in Mozambique, is like most African languages\nlow-resource in NLP terms. It lacks both computational and linguistic resources\nand, to the best of our knowledge, few parallel corpora including Emakhuwa\nalready exist. In this paper we describe the creation of the\nEmakhuwa-Portuguese parallel corpus, which is a collection of texts from the\nJehovah's Witness website and a variety of other sources including the African\nStory Book website, the Universal Declaration of Human Rights and Mozambican\nlegal documents. The dataset contains 47,415 sentence pairs, amounting to\n699,976 word tokens of Emakhuwa and 877,595 word tokens in Portuguese. After\nnormalization processes which remain to be completed, the corpus will be made\nfreely available for research use.", "published": "2021-04-12 18:31:56", "link": "http://arxiv.org/abs/2104.05753v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Plot-guided Adversarial Example Construction for Evaluating Open-domain\n  Story Generation", "abstract": "With the recent advances of open-domain story generation, the lack of\nreliable automatic evaluation metrics becomes an increasingly imperative issue\nthat hinders the fast development of story generation. According to conducted\nresearches in this regard, learnable evaluation metrics have promised more\naccurate assessments by having higher correlations with human judgments. A\ncritical bottleneck of obtaining a reliable learnable evaluation metric is the\nlack of high-quality training data for classifiers to efficiently distinguish\nplausible and implausible machine-generated stories. Previous works relied on\n\\textit{heuristically manipulated} plausible examples to mimic possible system\ndrawbacks such as repetition, contradiction, or irrelevant content in the text\nlevel, which can be \\textit{unnatural} and \\textit{oversimplify} the\ncharacteristics of implausible machine-generated stories. We propose to tackle\nthese issues by generating a more comprehensive set of implausible stories\nusing {\\em plots}, which are structured representations of controllable factors\nused to generate stories. Since these plots are compact and structured, it is\neasier to manipulate them to generate text with targeted undesirable\nproperties, while at the same time maintain the grammatical correctness and\nnaturalness of the generated sentences. To improve the quality of generated\nimplausible stories, we further apply the adversarial filtering procedure\npresented by \\citet{zellers2018swag} to select a more nuanced set of\nimplausible texts. Experiments show that the evaluation metrics trained on our\ngenerated data result in more reliable automatic assessments that correlate\nremarkably better with human judgments compared to the baselines.", "published": "2021-04-12 20:19:24", "link": "http://arxiv.org/abs/2104.05801v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SpartQA: : A Textual Question Answering Benchmark for Spatial Reasoning", "abstract": "This paper proposes a question-answering (QA) benchmark for spatial reasoning\non natural language text which contains more realistic spatial phenomena not\ncovered by prior work and is challenging for state-of-the-art language models\n(LM). We propose a distant supervision method to improve on this task.\nSpecifically, we design grammar and reasoning rules to automatically generate a\nspatial description of visual scenes and corresponding QA pairs. Experiments\nshow that further pretraining LMs on these automatically generated data\nsignificantly improves LMs' capability on spatial understanding, which in turn\nhelps to better solve two external datasets, bAbI, and boolQ. We hope that this\nwork can foster investigations into more sophisticated models for spatial\nreasoning over text.", "published": "2021-04-12 21:37:18", "link": "http://arxiv.org/abs/2104.05832v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Family of Origin and Family of Choice: Massively Parallel Lexiconized\n  Iterative Pretraining for Severely Low Resource Machine Translation", "abstract": "We translate a closed text that is known in advance into a severely low\nresource language by leveraging massive source parallelism. In other words,\ngiven a text in 124 source languages, we translate it into a severely low\nresource language using only ~1,000 lines of low resource data without any\nexternal help. Firstly, we propose a systematic method to rank and choose\nsource languages that are close to the low resource language. We call the\nlinguistic definition of language family Family of Origin (FAMO), and we call\nthe empirical definition of higher-ranked languages using our metrics Family of\nChoice (FAMC). Secondly, we build an Iteratively Pretrained Multilingual\nOrder-preserving Lexiconized Transformer (IPML) to train on ~1,000 lines\n(~3.5%) of low resource data. To translate named entities correctly, we build a\nmassive lexicon table for 2,939 Bible named entities in 124 source languages,\nand include many that occur once and covers more than 66 severely low resource\nlanguages. Moreover, we also build a novel method of combining translations\nfrom different source languages into one. Using English as a hypothetical low\nresource language, we get a +23.9 BLEU increase over a multilingual baseline,\nand a +10.3 BLEU increase over our asymmetric baseline in the Bible dataset. We\nget a 42.8 BLEU score for Portuguese-English translation on the medical EMEA\ndataset. We also have good results for a real severely low resource Mayan\nlanguage, Eastern Pokomchi.", "published": "2021-04-12 22:32:58", "link": "http://arxiv.org/abs/2104.05848v7", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From partners to populations: A hierarchical Bayesian account of\n  coordination and convention", "abstract": "Languages are powerful solutions to coordination problems: they provide\nstable, shared expectations about how the words we say correspond to the\nbeliefs and intentions in our heads. Yet language use in a variable and\nnon-stationary social environment requires linguistic representations to be\nflexible: old words acquire new ad hoc or partner-specific meanings on the fly.\nIn this paper, we introduce CHAI (Continual Hierarchical Adaptation through\nInference), a hierarchical Bayesian theory of coordination and convention\nformation that aims to reconcile the long-standing tension between these two\nbasic observations. We argue that the central computational problem of\ncommunication is not simply transmission, as in classical formulations, but\ncontinual learning and adaptation over multiple timescales. Partner-specific\ncommon ground quickly emerges from social inferences within dyadic\ninteractions, while community-wide social conventions are stable priors that\nhave been abstracted away from interactions with multiple partners. We present\nnew empirical data alongside simulations showing how our model provides a\ncomputational foundation for several phenomena that have posed a challenge for\nprevious accounts: (1) the convergence to more efficient referring expressions\nacross repeated interaction with the same partner, (2) the gradual transfer of\npartner-specific common ground to strangers, and (3) the influence of\ncommunicative context on which conventions eventually form.", "published": "2021-04-12 23:00:40", "link": "http://arxiv.org/abs/2104.05857v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "StylePTB: A Compositional Benchmark for Fine-grained Controllable Text\n  Style Transfer", "abstract": "Text style transfer aims to controllably generate text with targeted\nstylistic changes while maintaining core meaning from the source sentence\nconstant. Many of the existing style transfer benchmarks primarily focus on\nindividual high-level semantic changes (e.g. positive to negative), which\nenable controllability at a high level but do not offer fine-grained control\ninvolving sentence structure, emphasis, and content of the sentence. In this\npaper, we introduce a large-scale benchmark, StylePTB, with (1) paired\nsentences undergoing 21 fine-grained stylistic changes spanning atomic lexical,\nsyntactic, semantic, and thematic transfers of text, as well as (2)\ncompositions of multiple transfers which allow modeling of fine-grained\nstylistic changes as building blocks for more complex, high-level transfers. By\nbenchmarking existing methods on StylePTB, we find that they struggle to model\nfine-grained changes and have an even more difficult time composing multiple\nstyles. As a result, StylePTB brings novel challenges that we hope will\nencourage future research in controllable text style transfer, compositional\nmodels, and learning disentangled representations. Solving these challenges\nwould present important steps towards controllable text generation.", "published": "2021-04-12 04:25:09", "link": "http://arxiv.org/abs/2104.05196v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual\n  Bias Evaluation", "abstract": "Robustness and counterfactual bias are usually evaluated on a test dataset.\nHowever, are these evaluations robust? If the test dataset is perturbed\nslightly, will the evaluation results keep the same? In this paper, we propose\na \"double perturbation\" framework to uncover model weaknesses beyond the test\ndataset. The framework first perturbs the test dataset to construct abundant\nnatural sentences similar to the test data, and then diagnoses the prediction\nchange regarding a single-word substitution. We apply this framework to study\ntwo perturbation-based approaches that are used to analyze models' robustness\nand counterfactual bias in English. (1) For robustness, we focus on synonym\nsubstitutions and identify vulnerable examples where prediction can be altered.\nOur proposed attack attains high success rates (96.0%-99.8%) in finding\nvulnerable examples on both original and robustly trained CNNs and\nTransformers. (2) For counterfactual bias, we focus on substituting demographic\ntokens (e.g., gender, race) and measure the shift of the expected prediction\namong constructed sentences. Our method is able to reveal the hidden model\nbiases not directly shown in the test dataset. Our code is available at\nhttps://github.com/chong-z/nlp-second-order-attack.", "published": "2021-04-12 06:57:36", "link": "http://arxiv.org/abs/2104.05232v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Hierarchical State-Machine-Based Framework for Platoon Manoeuvre\n  Descriptions", "abstract": "This paper introduces the SEAD framework that simplifies the process of\ndesigning and describing autonomous vehicle platooning manoeuvres. Although a\nlarge body of research has been formulating platooning manoeuvres, it is still\nchallenging to design, describe, read, and understand them. This difficulty\nlargely arises from missing formalisation. To fill this gap, we analysed\nexisting ways of describing manoeuvres, derived the causes of difficulty, and\ndesigned a framework that simplifies the manoeuvre design process. Alongside, a\nManoeuvre Design Language was developed to structurally describe manoeuvres in\na machine-readable format. Unlike state-of-the-art manoeuvre descriptions that\nrequire one state machine for every participating vehicle, the SEAD framework\nallows describing any manoeuvre from the single perspective of the platoon\nleader. %As a proof of concept, the proposed framework was implemented in the\nmixed traffic simulation environment BEHAVE for an autonomous highway scenario.\nUsing this framework, we implemented several manoeuvres as they were described\nin literature. To demonstrate the applicability of the framework, an experiment\nwas performed to evaluate the execution time performance of multiple\nalternatives of the Join-Middle manoeuvre. This proof-of-concept experiment\nrevealed that the manoeuvre execution time can be reduced by 28 \\% through\nparallelising various steps without considerable secondary effects. We hope\nthat the SEAD framework will pave the way for further research in the area of\nnew manoeuvre design and optimisation by largely simplifying and unifying\nplatooning manoeuvre representation.", "published": "2021-04-12 09:25:35", "link": "http://arxiv.org/abs/2104.05305v1", "categories": ["cs.MA", "cs.CL", "cs.SY", "eess.SY"], "primary_category": "cs.MA"}
{"title": "Combining exogenous and endogenous signals with a semi-supervised\n  co-attention network for early detection of COVID-19 fake tweets", "abstract": "Fake tweets are observed to be ever-increasing, demanding immediate\ncountermeasures to combat their spread. During COVID-19, tweets with\nmisinformation should be flagged and neutralized in their early stages to\nmitigate the damages. Most of the existing methods for early detection of fake\nnews assume to have enough propagation information for large labeled tweets --\nwhich may not be an ideal setting for cases like COVID-19 where both aspects\nare largely absent. In this work, we present ENDEMIC, a novel early detection\nmodel which leverages exogenous and endogenous signals related to tweets, while\nlearning on limited labeled data. We first develop a novel dataset, called CTF\nfor early COVID-19 Twitter fake news, with additional behavioral test sets to\nvalidate early detection. We build a heterogeneous graph with\nfollower-followee, user-tweet, and tweet-retweet connections and train a graph\nembedding model to aggregate propagation information. Graph embeddings and\ncontextual features constitute endogenous, while time-relative web-scraped\ninformation constitutes exogenous signals. ENDEMIC is trained in a\nsemi-supervised fashion, overcoming the challenge of limited labeled data. We\npropose a co-attention mechanism to fuse signal representations optimally.\nExperimental results on ECTF, PolitiFact, and GossipCop show that ENDEMIC is\nhighly reliable in detecting early fake tweets, outperforming nine\nstate-of-the-art methods significantly.", "published": "2021-04-12 10:01:44", "link": "http://arxiv.org/abs/2104.05321v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "CNN Encoding of Acoustic Parameters for Prominence Detection", "abstract": "Expressive reading, considered the defining attribute of oral reading\nfluency, comprises the prosodic realization of phrasing and prominence. In the\ncontext of evaluating oral reading, it helps to establish the speaker's\ncomprehension of the text. We consider a labeled dataset of children's reading\nrecordings for the speaker-independent detection of prominent words using\nacoustic-prosodic and lexico-syntactic features. A previous well-tuned random\nforest ensemble predictor is replaced by an RNN sequence classifier to exploit\npotential context dependency across the longer utterance. Further, deep\nlearning is applied to obtain word-level features from low-level acoustic\ncontours of fundamental frequency, intensity and spectral shape in an\nend-to-end fashion. Performance comparisons are presented across the different\nfeature types and across different feature learning architectures for prominent\nword prediction to draw insights wherever possible.", "published": "2021-04-12 14:15:08", "link": "http://arxiv.org/abs/2104.05488v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Updater-Extractor Architecture for Inductive World State Representations", "abstract": "Developing NLP models traditionally involves two stages - training and\napplication. Retention of information acquired after training (at application\ntime) is architecturally limited by the size of the model's context window (in\nthe case of transformers), or by the practical difficulties associated with\nlong sequences (in the case of RNNs). In this paper, we propose a novel\ntransformer-based Updater-Extractor architecture and a training procedure that\ncan work with sequences of arbitrary length and refine its knowledge about the\nworld based on linguistic inputs. We explicitly train the model to incorporate\nincoming information into its world state representation, obtaining strong\ninductive generalization and the ability to handle extremely long-range\ndependencies. We prove a lemma that provides a theoretical basis for our\napproach. The result also provides insight into success and failure modes of\nmodels trained with variants of Truncated Back-Propagation Through Time (such\nas Transformer XL). Empirically, we investigate the model performance on three\ndifferent tasks, demonstrating its promise. This preprint is still a work in\nprogress. At present, we focused on easily interpretable tasks, leaving the\napplication of the proposed ideas to practical NLP applications for the future.", "published": "2021-04-12 14:30:11", "link": "http://arxiv.org/abs/2104.05500v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Investigating Methods to Improve Language Model Integration for\n  Attention-based Encoder-Decoder ASR Models", "abstract": "Attention-based encoder-decoder (AED) models learn an implicit internal\nlanguage model (ILM) from the training transcriptions. The integration with an\nexternal LM trained on much more unpaired text usually leads to better\nperformance. A Bayesian interpretation as in the hybrid autoregressive\ntransducer (HAT) suggests dividing by the prior of the discriminative acoustic\nmodel, which corresponds to this implicit LM, similarly as in the hybrid hidden\nMarkov model approach. The implicit LM cannot be calculated efficiently in\ngeneral and it is yet unclear what are the best methods to estimate it. In this\nwork, we compare different approaches from the literature and propose several\nnovel methods to estimate the ILM directly from the AED model. Our proposed\nmethods outperform all previous approaches. We also investigate other methods\nto suppress the ILM mainly by decreasing the capacity of the AED model,\nlimiting the label context, and also by training the AED model together with a\npre-existing LM.", "published": "2021-04-12 15:16:03", "link": "http://arxiv.org/abs/2104.05544v2", "categories": ["cs.CL", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Survey on reinforcement learning for language processing", "abstract": "In recent years some researchers have explored the use of reinforcement\nlearning (RL) algorithms as key components in the solution of various natural\nlanguage processing tasks. For instance, some of these algorithms leveraging\ndeep neural learning have found their way into conversational systems. This\npaper reviews the state of the art of RL methods for their possible use for\ndifferent problems of natural language processing, focusing primarily on\nconversational systems, mainly due to their growing relevance. We provide\ndetailed descriptions of the problems as well as discussions of why RL is\nwell-suited to solve them. Also, we analyze the advantages and limitations of\nthese methods. Finally, we elaborate on promising research directions in\nnatural language processing that might benefit from reinforcement learning.", "published": "2021-04-12 15:33:11", "link": "http://arxiv.org/abs/2104.05565v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Inductive Bias of Masked Language Modeling: From Statistical to\n  Syntactic Dependencies", "abstract": "We study how masking and predicting tokens in an unsupervised fashion can\ngive rise to linguistic structures and downstream performance gains. Recent\ntheories have suggested that pretrained language models acquire useful\ninductive biases through masks that implicitly act as cloze reductions for\ndownstream tasks. While appealing, we show that the success of the random\nmasking strategy used in practice cannot be explained by such cloze-like masks\nalone. We construct cloze-like masks using task-specific lexicons for three\ndifferent classification datasets and show that the majority of pretrained\nperformance gains come from generic masks that are not associated with the\nlexicon. To explain the empirical success of these generic masks, we\ndemonstrate a correspondence between the Masked Language Model (MLM) objective\nand existing methods for learning statistical dependencies in graphical models.\nUsing this, we derive a method for extracting these learned statistical\ndependencies in MLMs and show that these dependencies encode useful inductive\nbiases in the form of syntactic structures. In an unsupervised parsing\nevaluation, simply forming a minimum spanning tree on the implied statistical\ndependence structure outperforms a classic method for unsupervised parsing\n(58.74 vs. 55.91 UUAS).", "published": "2021-04-12 17:55:27", "link": "http://arxiv.org/abs/2104.05694v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Macro-Average: Rare Types Are Important Too", "abstract": "While traditional corpus-level evaluation metrics for machine translation\n(MT) correlate well with fluency, they struggle to reflect adequacy.\nModel-based MT metrics trained on segment-level human judgments have emerged as\nan attractive replacement due to strong correlation results. These models,\nhowever, require potentially expensive re-training for new domains and\nlanguages. Furthermore, their decisions are inherently non-transparent and\nappear to reflect unwelcome biases. We explore the simple type-based classifier\nmetric, MacroF1, and study its applicability to MT evaluation. We find that\nMacroF1 is competitive on direct assessment, and outperforms others in\nindicating downstream cross-lingual information retrieval task performance.\nFurther, we show that MacroF1 can be used to effectively compare supervised and\nunsupervised neural machine translation, and reveal significant qualitative\ndifferences in the methods' outputs.", "published": "2021-04-12 17:57:42", "link": "http://arxiv.org/abs/2104.05700v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Does My Representation Capture X? Probe-Ably", "abstract": "Probing (or diagnostic classification) has become a popular strategy for\ninvestigating whether a given set of intermediate features is present in the\nrepresentations of neural models. Probing studies may have misleading results,\nbut various recent works have suggested more reliable methodologies that\ncompensate for the possible pitfalls of probing. However, these best practices\nare numerous and fast-evolving. To simplify the process of running a set of\nprobing experiments in line with suggested methodologies, we introduce\nProbe-Ably: an extendable probing framework which supports and automates the\napplication of probing methods to the user's inputs.", "published": "2021-04-12 20:43:10", "link": "http://arxiv.org/abs/2104.05807v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Relational World Knowledge Representation in Contextual Language Models:\n  A Review", "abstract": "Relational knowledge bases (KBs) are commonly used to represent world\nknowledge in machines. However, while advantageous for their high degree of\nprecision and interpretability, KBs are usually organized according to\nmanually-defined schemas, which limit their expressiveness and require\nsignificant human efforts to engineer and maintain. In this review, we take a\nnatural language processing perspective to these limitations, examining how\nthey may be addressed in part by training deep contextual language models (LMs)\nto internalize and express relational knowledge in more flexible forms. We\npropose to organize knowledge representation strategies in LMs by the level of\nKB supervision provided, from no KB supervision at all to entity- and\nrelation-level supervision. Our contributions are threefold: (1) We provide a\nhigh-level, extensible taxonomy for knowledge representation in LMs; (2) Within\nour taxonomy, we highlight notable models, evaluation tasks, and findings, in\norder to provide an up-to-date review of current knowledge representation\ncapabilities in LMs; and (3) We suggest future research directions that build\nupon the complementary aspects of LMs and KBs as knowledge representations.", "published": "2021-04-12 21:50:55", "link": "http://arxiv.org/abs/2104.05837v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BERT based freedom to operate patent analysis", "abstract": "In this paper we present a method to apply BERT to freedom to operate patent\nanalysis and patent searches. According to the method, BERT is fine-tuned by\ntraining patent descriptions to the independent claims. Each description\nrepresents an invention which is protected by the corresponding claims. Such a\ntrained BERT could be able to identify or order freedom to operate relevant\npatents based on a short description of an invention or product. We tested the\nmethod by training BERT on the patent class G06T1/00 and applied the trained\nBERT on five inventions classified in G06T1/60, described via DOCDB abstracts.\nThe DOCDB abstract are available on ESPACENET of the European Patent Office.", "published": "2021-04-12 18:30:46", "link": "http://arxiv.org/abs/2105.00817v2", "categories": ["cs.CL", "cs.LG", "econ.EM"], "primary_category": "cs.CL"}
{"title": "Visual Goal-Step Inference using wikiHow", "abstract": "Understanding what sequence of steps are needed to complete a goal can help\nartificial intelligence systems reason about human activities. Past work in NLP\nhas examined the task of goal-step inference for text. We introduce the visual\nanalogue. We propose the Visual Goal-Step Inference (VGSI) task, where a model\nis given a textual goal and must choose which of four images represents a\nplausible step towards that goal. With a new dataset harvested from wikiHow\nconsisting of 772,277 images representing human actions, we show that our task\nis challenging for state-of-the-art multimodal models. Moreover, the multimodal\nrepresentation learned from our data can be effectively transferred to other\ndatasets like HowTo100m, increasing the VGSI accuracy by 15 - 20%. Our task\nwill facilitate multimodal reasoning about procedural events.", "published": "2021-04-12 22:20:09", "link": "http://arxiv.org/abs/2104.05845v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Complex Spectral Mapping With Attention Based Convolution Recurrent\n  Neural Network for Speech Enhancement", "abstract": "Speech enhancement has benefited from the success of deep learning in terms\nof intelligibility and perceptual quality. Conventional time-frequency (TF)\ndomain methods focus on predicting TF-masks or speech spectrum,via a naive\nconvolution neural network or recurrent neural network.Some recent studies were\nbased on Complex spectral Mapping convolution recurrent neural network (CRN) .\nThese models skiped directly from encoder layers' output and decoder layers'\ninput ,which maybe thoughtless. We proposed an attention mechanism based skip\nconnection between encoder and decoder layers,namely Complex Spectral Mapping\nWith Attention Based Convolution Recurrent Neural Network (CARN).Compared with\nCRN model,the proposed CARN model improved more than 10% relatively at several\nmetrics such as PESQ,CBAK,COVL,CSIG and son,and outperformed the place 1st\nmodel in both real time and non-real time track of the DNS Challenge 2020 at\nthese metrics.", "published": "2021-04-12 07:59:44", "link": "http://arxiv.org/abs/2104.05267v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improved Conformer-based End-to-End Speech Recognition Using Neural\n  Architecture Search", "abstract": "Recently neural architecture search(NAS) has been successfully used in image\nclassification, natural language processing, and automatic speech\nrecognition(ASR) tasks for finding the state-of-the-art(SOTA) architectures\nthan those human-designed architectures. NAS can derive a SOTA and\ndata-specific architecture over validation data from a pre-defined search space\nwith a search algorithm. Inspired by the success of NAS in ASR tasks, we\npropose a NAS-based ASR framework containing one search space and one\ndifferentiable search algorithm called Differentiable Architecture\nSearch(DARTS). Our search space follows the convolution-augmented\ntransformer(Conformer) backbone, which is a more expressive ASR architecture\nthan those used in existing NAS-based ASR frameworks. To improve the\nperformance of our method, a regulation method called Dynamic Search\nSchedule(DSS) is employed. On a widely used Mandarin benchmark AISHELL-1, our\nbest-searched architecture outperforms the baseline Conform model significantly\nwith about 11% CER relative improvement, and our method is proved to be pretty\nefficient by the search cost comparisons.", "published": "2021-04-12 12:17:55", "link": "http://arxiv.org/abs/2104.05390v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improvement of Noise-Robust Single-Channel Voice Activity Detection with\n  Spatial Pre-processing", "abstract": "Voice activity detection (VAD) remains a challenge in noisy environments.\nWith access to multiple microphones, prior studies have attempted to improve\nthe noise robustness of VAD by creating multi-channel VAD (MVAD) methods.\nHowever, MVAD is relatively new compared to single-channel VAD (SVAD), which\nhas been thoroughly developed in the past. It might therefore be advantageous\nto improve SVAD methods with pre-processing to obtain superior VAD, which is\nunder-explored. This paper improves SVAD through two pre-processing methods, a\nbeamformer and a spatial target speaker detector. The spatial detector sets\nsignal frames to zero when no potential speaker is present within a target\ndirection. The detector may be implemented as a filter, meaning the input\nsignal for the SVAD is filtered according to the detector's output; or it may\nbe implemented as a spatial VAD to be combined with the SVAD output. The\nevaluation is made on a noisy reverberant speech database, with clean speech\nfrom the Aurora 2 database and with white and babble noise. The results show\nthat SVAD algorithms are significantly improved by the presented pre-processing\nmethods, especially the spatial detector, across all signal-to-noise ratios.\nThe SVAD algorithms with pre-processing significantly outperform a baseline\nMVAD in challenging noise conditions.", "published": "2021-04-12 14:04:42", "link": "http://arxiv.org/abs/2104.05481v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "L3DAS21 Challenge: Machine Learning for 3D Audio Signal Processing", "abstract": "The L3DAS21 Challenge is aimed at encouraging and fostering collaborative\nresearch on machine learning for 3D audio signal processing, with particular\nfocus on 3D speech enhancement (SE) and 3D sound localization and detection\n(SELD). Alongside with the challenge, we release the L3DAS21 dataset, a 65\nhours 3D audio corpus, accompanied with a Python API that facilitates the data\nusage and results submission stage. Usually, machine learning approaches to 3D\naudio tasks are based on single-perspective Ambisonics recordings or on arrays\nof single-capsule microphones. We propose, instead, a novel multichannel audio\nconfiguration based multiple-source and multiple-perspective Ambisonics\nrecordings, performed with an array of two first-order Ambisonics microphones.\nTo the best of our knowledge, it is the first time that a dual-mic Ambisonics\nconfiguration is used for these tasks. We provide baseline models and results\nfor both tasks, obtained with state-of-the-art architectures: FaSNet for SE and\nSELDNet for SELD. This report is aimed at providing all needed information to\nparticipate in the L3DAS21 Challenge, illustrating the details of the L3DAS21\ndataset, the challenge tasks and the baseline models.", "published": "2021-04-12 14:29:54", "link": "http://arxiv.org/abs/2104.05499v3", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "End-to-End Mandarin Tone Classification with Short Term Context\n  Information", "abstract": "In this paper, we propose an end-to-end Mandarin tone classification method\nfrom continuous speech utterances utilizing both the spectrogram and the\nshort-term context information as the input. Both spectrograms and context\nsegment features are used to train the tone classifier. We first divide the\nspectrogram frames into syllable segments using force alignment results\nproduced by an ASR model. Then we extract the short-term segment features to\ncapture the context information across multiple syllables. Feeding both the\nspectrogram and the short-term context segment features into an end-to-end\nmodel could significantly improve the performance. Experiments are performed on\na large-scale open-source Mandarin speech dataset to evaluate the proposed\nmethod. Results show that this method improves the classification accuracy from\n79.5% to 92.6% on the AISHELL3 database.", "published": "2021-04-12 17:27:39", "link": "http://arxiv.org/abs/2104.05657v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
