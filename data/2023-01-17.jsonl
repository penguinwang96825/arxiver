{"title": "VaxxHesitancy: A Dataset for Studying Hesitancy towards COVID-19\n  Vaccination on Twitter", "abstract": "Vaccine hesitancy has been a common concern, probably since vaccines were\ncreated and, with the popularisation of social media, people started to express\ntheir concerns about vaccines online alongside those posting pro- and\nanti-vaccine content. Predictably, since the first mentions of a COVID-19\nvaccine, social media users posted about their fears and concerns or about\ntheir support and belief into the effectiveness of these rapidly developing\nvaccines. Identifying and understanding the reasons behind public hesitancy\ntowards COVID-19 vaccines is important for policy markers that need to develop\nactions to better inform the population with the aim of increasing vaccine\ntake-up. In the case of COVID-19, where the fast development of the vaccines\nwas mirrored closely by growth in anti-vaxx disinformation, automatic means of\ndetecting citizen attitudes towards vaccination became necessary. This is an\nimportant computational social sciences task that requires data analysis in\norder to gain in-depth understanding of the phenomena at hand. Annotated data\nis also necessary for training data-driven models for more nuanced analysis of\nattitudes towards vaccination. To this end, we created a new collection of over\n3,101 tweets annotated with users' attitudes towards COVID-19 vaccination\n(stance). Besides, we also develop a domain-specific language model (VaxxBERT)\nthat achieves the best predictive performance (73.0 accuracy and 69.3 F1-score)\nas compared to a robust set of baselines. To the best of our knowledge, these\nare the first dataset and model that model vaccine hesitancy as a category\ndistinct from pro- and anti-vaccine stance.", "published": "2023-01-17 02:00:31", "link": "http://arxiv.org/abs/2301.06660v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syllable Subword Tokens for Open Vocabulary Speech Recognition in\n  Malayalam", "abstract": "In a hybrid automatic speech recognition (ASR) system, a pronunciation\nlexicon (PL) and a language model (LM) are essential to correctly retrieve\nspoken word sequences. Being a morphologically complex language, the vocabulary\nof Malayalam is so huge and it is impossible to build a PL and an LM that cover\nall diverse word forms. Usage of subword tokens to build PL and LM, and\ncombining them to form words after decoding, enables the recovery of many out\nof vocabulary words. In this work we investigate the impact of using syllables\nas subword tokens instead of words in Malayalam ASR, and evaluate the relative\nimprovement in lexicon size, model memory requirement and word error rate.", "published": "2023-01-17 07:29:47", "link": "http://arxiv.org/abs/2301.06736v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Recent Advances in Automatic Term Extraction: A survey", "abstract": "Automatic term extraction (ATE) is a Natural Language Processing (NLP) task\nthat eases the effort of manually identifying terms from domain-specific\ncorpora by providing a list of candidate terms. As units of knowledge in a\nspecific field of expertise, extracted terms are not only beneficial for\nseveral terminographical tasks, but also support and improve several complex\ndownstream tasks, e.g., information retrieval, machine translation, topic\ndetection, and sentiment analysis. ATE systems, along with annotated datasets,\nhave been studied and developed widely for decades, but recently we observed a\nsurge in novel neural systems for the task at hand. Despite a large amount of\nnew research on ATE, systematic survey studies covering novel neural approaches\nare lacking. We present a comprehensive survey of deep learning-based\napproaches to ATE, with a focus on Transformer-based neural models. The study\nalso offers a comparison between these systems and previous ATE approaches,\nwhich were based on feature engineering and non-neural supervised learning\nalgorithms.", "published": "2023-01-17 09:02:15", "link": "http://arxiv.org/abs/2301.06767v1", "categories": ["cs.CL", "A.1"], "primary_category": "cs.CL"}
{"title": "2nd Swiss German Speech to Standard German Text Shared Task at SwissText\n  2022", "abstract": "We present the results and findings of the 2nd Swiss German speech to\nStandard German text shared task at SwissText 2022. Participants were asked to\nbuild a sentence-level Swiss German speech to Standard German text system\nspecialized on the Grisons dialect. The objective was to maximize the BLEU\nscore on a test set of Grisons speech. 3 teams participated, with the\nbest-performing system achieving a BLEU score of 70.1.", "published": "2023-01-17 10:31:11", "link": "http://arxiv.org/abs/2301.06790v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HanoiT: Enhancing Context-aware Translation via Selective Context", "abstract": "Context-aware neural machine translation aims to use the document-level\ncontext to improve translation quality. However, not all words in the context\nare helpful. The irrelevant or trivial words may bring some noise and distract\nthe model from learning the relationship between the current sentence and the\nauxiliary context. To mitigate this problem, we propose a novel end-to-end\nencoder-decoder model with a layer-wise selection mechanism to sift and refine\nthe long document context. To verify the effectiveness of our method, extensive\nexperiments and extra quantitative analysis are conducted on four\ndocument-level machine translation benchmarks. The experimental results\ndemonstrate that our model significantly outperforms previous models on all\ndatasets via the soft selection mechanism.", "published": "2023-01-17 12:07:13", "link": "http://arxiv.org/abs/2301.06825v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Which Model Shall I Choose? Cost/Quality Trade-offs for Text\n  Classification Tasks", "abstract": "Industry practitioners always face the problem of choosing the appropriate\nmodel for deployment under different considerations, such as to maximize a\nmetric that is crucial for production, or to reduce the total cost given\nfinancial concerns. In this work, we focus on the text classification task and\npresent a quantitative analysis for this challenge. Using classification\naccuracy as the main metric, we evaluate the classifiers' performances for a\nvariety of models, including large language models, along with their associated\ncosts, including the annotation cost, training (fine-tuning) cost, and\ninference cost. We then discuss the model choices for situations like having a\nlarge number of samples needed for inference. We hope our work will help people\nbetter understand the cost/quality trade-offs for the text classification task.", "published": "2023-01-17 16:51:58", "link": "http://arxiv.org/abs/2301.07006v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the State of German (Abstractive) Text Summarization", "abstract": "With recent advancements in the area of Natural Language Processing, the\nfocus is slowly shifting from a purely English-centric view towards more\nlanguage-specific solutions, including German. Especially practical for\nbusinesses to analyze their growing amount of textual data are text\nsummarization systems, which transform long input documents into compressed and\nmore digestible summary texts. In this work, we assess the particular landscape\nof German abstractive text summarization and investigate the reasons why\npractically useful solutions for abstractive text summarization are still\nabsent in industry. Our focus is two-fold, analyzing a) training resources, and\nb) publicly available summarization systems. We are able to show that popular\nexisting datasets exhibit crucial flaws in their assumptions about the original\nsources, which frequently leads to detrimental effects on system generalization\nand evaluation biases. We confirm that for the most popular training dataset,\nMLSUM, over 50% of the training set is unsuitable for abstractive summarization\npurposes. Furthermore, available systems frequently fail to compare to simple\nbaselines, and ignore more effective and efficient extractive summarization\napproaches. We attribute poor evaluation quality to a variety of different\nfactors, which are investigated in more detail in this work: A lack of\nqualitative (and diverse) gold data considered for training, understudied (and\nuntreated) positional biases in some of the existing datasets, and the lack of\neasily accessible and streamlined pre-processing strategies or analysis tools.\nWe provide a comprehensive assessment of available models on the cleaned\ndatasets, and find that this can lead to a reduction of more than 20 ROUGE-1\npoints during evaluation. The code for dataset filtering and reproducing\nresults can be found online at https://github.com/dennlinger/summaries", "published": "2023-01-17 18:59:20", "link": "http://arxiv.org/abs/2301.07095v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Curriculum Script Distillation for Multilingual Visual Question\n  Answering", "abstract": "Pre-trained models with dual and cross encoders have shown remarkable success\nin propelling the landscape of several tasks in vision and language in Visual\nQuestion Answering (VQA). However, since they are limited by the requirements\nof gold annotated data, most of these advancements do not see the light of day\nin other languages beyond English. We aim to address this problem by\nintroducing a curriculum based on the source and target language translations\nto finetune the pre-trained models for the downstream task. Experimental\nresults demonstrate that script plays a vital role in the performance of these\nmodels. Specifically, we show that target languages that share the same script\nperform better (~6%) than other languages and mixed-script code-switched\nlanguages perform better than their counterparts (~5-12%).", "published": "2023-01-17 23:55:50", "link": "http://arxiv.org/abs/2301.07227v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BERT-ERC: Fine-tuning BERT is Enough for Emotion Recognition in\n  Conversation", "abstract": "Previous works on emotion recognition in conversation (ERC) follow a two-step\nparadigm, which can be summarized as first producing context-independent\nfeatures via fine-tuning pretrained language models (PLMs) and then analyzing\ncontextual information and dialogue structure information among the extracted\nfeatures. However, we discover that this paradigm has several limitations.\nAccordingly, we propose a novel paradigm, i.e., exploring contextual\ninformation and dialogue structure information in the fine-tuning step, and\nadapting the PLM to the ERC task in terms of input text, classification\nstructure, and training strategy. Furthermore, we develop our model BERT-ERC\naccording to the proposed paradigm, which improves ERC performance in three\naspects, namely suggestive text, fine-grained classification module, and\ntwo-stage training. Compared to existing methods, BERT-ERC achieves substantial\nimprovement on four datasets, indicating its effectiveness and generalization\ncapability. Besides, we also set up the limited resources scenario and the\nonline prediction scenario to approximate real-world scenarios. Extensive\nexperiments demonstrate that the proposed paradigm significantly outperforms\nthe previous one and can be adapted to various scenes.", "published": "2023-01-17 08:03:32", "link": "http://arxiv.org/abs/2301.06745v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Algorithms for Acyclic Weighted Finite-State Automata with Failure Arcs", "abstract": "Weighted finite-state automata (WSFAs) are commonly used in NLP. Failure\ntransitions are a useful extension for compactly representing backoffs or\ninterpolation in $n$-gram models and CRFs, which are special cases of WFSAs.\nThe pathsum in ordinary acyclic WFSAs is efficiently computed by the backward\nalgorithm in time $O(|E|)$, where $E$ is the set of transitions. However, this\ndoes not allow failure transitions, and preprocessing the WFSA to eliminate\nfailure transitions could greatly increase $|E|$. We extend the backward\nalgorithm to handle failure transitions directly. Our approach is efficient\nwhen the average state has outgoing arcs for only a small fraction $s \\ll 1$ of\nthe alphabet $\\Sigma$. We propose an algorithm for general acyclic WFSAs which\nruns in $O{\\left(|E| + s |\\Sigma| |Q| T_\\text{max} \\log{|\\Sigma|}\\right)}$,\nwhere $Q$ is the set of states and $T_\\text{max}$ is the size of the largest\nconnected component of failure transitions. When the failure transition\ntopology satisfies a condition exemplified by CRFs, the $T_\\text{max}$ factor\ncan be dropped, and when the weight semiring is a ring, the $\\log{|\\Sigma|}$\nfactor can be dropped. In the latter case (ring-weighted acyclic WFSAs), we\nalso give an alternative algorithm with complexity $\\displaystyle O{\\left(|E| +\n|\\Sigma| |Q| \\min(1,s\\pi_\\text{max}) \\right)}$, where $\\pi_\\text{max}$ is the\nsize of the longest failure path.", "published": "2023-01-17 13:15:44", "link": "http://arxiv.org/abs/2301.06862v2", "categories": ["cs.DS", "cs.CL"], "primary_category": "cs.DS"}
{"title": "Statistical analysis of word flow among five Indo-European languages", "abstract": "A recent increase in data availability has allowed the possibility to perform\ndifferent statistical linguistic studies. Here we use the Google Books Ngram\ndataset to analyze word flow among English, French, German, Italian, and\nSpanish. We study what we define as ``migrant words'', a type of loanwords that\ndo not change their spelling. We quantify migrant words from one language to\nanother for different decades, and notice that most migrant words can be\naggregated in semantic fields and associated to historic events. We also study\nthe statistical properties of accumulated migrant words and their rank\ndynamics. We propose a measure of use of migrant words that could be used as a\nproxy of cultural influence. Our methodology is not exempt of caveats, but our\nresults are encouraging to promote further studies in this direction.", "published": "2023-01-17 16:12:42", "link": "http://arxiv.org/abs/2301.06985v1", "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Prompting Large Language Model for Machine Translation: A Case Study", "abstract": "Research on prompting has shown excellent performance with little or even no\nsupervised training across many tasks. However, prompting for machine\ntranslation is still under-explored in the literature. We fill this gap by\noffering a systematic study on prompting strategies for translation, examining\nvarious factors for prompt template and demonstration example selection. We\nfurther explore the use of monolingual data and the feasibility of\ncross-lingual, cross-domain, and sentence-to-document transfer learning in\nprompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the\ntestbed show that 1) the number and the quality of prompt examples matter,\nwhere using suboptimal examples degenerates translation; 2) several features of\nprompt examples, such as semantic similarity, show significant Spearman\ncorrelation with their prompting performance; yet, none of the correlations are\nstrong enough; 3) using pseudo parallel prompt examples constructed from\nmonolingual data via zero-shot prompting could improve translation; and 4)\nimproved performance is achievable by transferring knowledge from prompt\nexamples selected in other settings. We finally provide an analysis on the\nmodel outputs and discuss several problems that prompting still suffers from.", "published": "2023-01-17 18:32:06", "link": "http://arxiv.org/abs/2301.07069v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Are Language Models Worse than Humans at Following Prompts? It's\n  Complicated", "abstract": "Prompts have been the center of progress in advancing language models'\nzero-shot and few-shot performance. However, recent work finds that models can\nperform surprisingly well when given intentionally irrelevant or misleading\nprompts. Such results may be interpreted as evidence that model behavior is not\n\"human like\". In this study, we challenge a central assumption in such work:\nthat humans would perform badly when given pathological instructions. We find\nthat humans are able to reliably ignore irrelevant instructions and thus, like\nmodels, perform well on the underlying task despite an apparent lack of signal\nregarding the task they are being asked to do. However, when given deliberately\nmisleading instructions, humans follow the instructions faithfully, whereas\nmodels do not. Our findings caution that future research should not idealize\nhuman behaviors as a monolith and should not train or evaluate models to mimic\nassumptions about these behaviors without first validating humans' behaviors\nempirically.", "published": "2023-01-17 18:51:19", "link": "http://arxiv.org/abs/2301.07085v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning a Formality-Aware Japanese Sentence Representation", "abstract": "While the way intermediate representations are generated in encoder-decoder\nsequence-to-sequence models typically allow them to preserve the semantics of\nthe input sentence, input features such as formality might be left out. On the\nother hand, downstream tasks such as translation would benefit from working\nwith a sentence representation that preserves formality in addition to\nsemantics, so as to generate sentences with the appropriate level of social\nformality -- the difference between speaking to a friend versus speaking with a\nsupervisor. We propose a sequence-to-sequence method for learning a\nformality-aware representation for Japanese sentences, where sentence\ngeneration is conditioned on both the original representation of the input\nsentence, and a side constraint which guides the sentence representation\ntowards preserving formality information. Additionally, we propose augmenting\nthe sentence representation with a learned representation of formality which\nfacilitates the extraction of formality in downstream tasks. We address the\nlack of formality-annotated parallel data by adapting previous works on\nprocedural formality classification of Japanese sentences. Experimental results\nsuggest that our techniques not only helps the decoder recover the formality of\nthe input sentence, but also slightly improves the preservation of input\nsentence semantics.", "published": "2023-01-17 22:16:58", "link": "http://arxiv.org/abs/2301.07209v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Two Stage Contextual Word Filtering for Context bias in Unified\n  Streaming and Non-streaming Transducer", "abstract": "It is difficult for an E2E ASR system to recognize words such as entities\nappearing infrequently in the training data. A widely used method to mitigate\nthis issue is feeding contextual information into the acoustic model. Previous\nworks have proven that a compact and accurate contextual list can boost the\nperformance significantly. In this paper, we propose an efficient approach to\nobtain a high quality contextual list for a unified streaming/non-streaming\nbased E2E model. Specifically, we make use of the phone-level streaming output\nto first filter the predefined contextual word list then fuse it into\nnon-casual encoder and decoder to generate the final recognition results. Our\napproach improve the accuracy of the contextual ASR system and speed up the\ninference process. Experiments on two datasets demonstrates over 20% CER\nreduction comparing to the baseline system. Meanwhile, the RTF of our system\ncan be stabilized within 0.15 when the size of the contextual word list grows\nover 6,000.", "published": "2023-01-17 07:29:26", "link": "http://arxiv.org/abs/2301.06735v3", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Tracing and Manipulating Intermediate Values in Neural Math Problem\n  Solvers", "abstract": "How language models process complex input that requires multiple steps of\ninference is not well understood. Previous research has shown that information\nabout intermediate values of these inputs can be extracted from the activations\nof the models, but it is unclear where that information is encoded and whether\nthat information is indeed used during inference. We introduce a method for\nanalyzing how a Transformer model processes these inputs by focusing on simple\narithmetic problems and their intermediate values. To trace where information\nabout intermediate values is encoded, we measure the correlation between\nintermediate values and the activations of the model using principal component\nanalysis (PCA). Then, we perform a causal intervention by manipulating model\nweights. This intervention shows that the weights identified via tracing are\nnot merely correlated with intermediate values, but causally related to model\npredictions. Our findings show that the model has a locality to certain\nintermediate values, and this is useful for enhancing the interpretability of\nthe models.", "published": "2023-01-17 08:46:50", "link": "http://arxiv.org/abs/2301.06758v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Temporal Dynamics of Coordinated Online Behavior: Stability, Archetypes,\n  and Influence", "abstract": "Large-scale online campaigns, malicious or otherwise, require a significant\ndegree of coordination among participants, which sparked interest in the study\nof coordinated online behavior. State-of-the-art methods for detecting\ncoordinated behavior perform static analyses, disregarding the temporal\ndynamics of coordination. Here, we carry out the first dynamic analysis of\ncoordinated behavior. To reach our goal we build a multiplex temporal network\nand we perform dynamic community detection to identify groups of users that\nexhibited coordinated behaviors in time. Thanks to our novel approach we find\nthat: (i) coordinated communities feature variable degrees of temporal\ninstability; (ii) dynamic analyses are needed to account for such instability,\nand results of static analyses can be unreliable and scarcely representative of\nunstable communities; (iii) some users exhibit distinct archetypal behaviors\nthat have important practical implications; (iv) content and network\ncharacteristics contribute to explaining why users leave and join coordinated\ncommunities. Our results demonstrate the advantages of dynamic analyses and\nopen up new directions of research on the unfolding of online debates, on the\nstrategies of coordinated communities, and on the patterns of online influence.", "published": "2023-01-17 09:52:54", "link": "http://arxiv.org/abs/2301.06774v2", "categories": ["cs.SI", "cs.CL", "cs.CY"], "primary_category": "cs.SI"}
{"title": "Syntactically Robust Training on Partially-Observed Data for Open\n  Information Extraction", "abstract": "Open Information Extraction models have shown promising results with\nsufficient supervision. However, these models face a fundamental challenge that\nthe syntactic distribution of training data is partially observable in\ncomparison to the real world. In this paper, we propose a syntactically robust\ntraining framework that enables models to be trained on a syntactic-abundant\ndistribution based on diverse paraphrase generation. To tackle the intrinsic\nproblem of knowledge deformation of paraphrasing, two algorithms based on\nsemantic similarity matching and syntactic tree walking are used to restore the\nexpressionally transformed knowledge. The training framework can be generally\napplied to other syntactic partial observable domains. Based on the proposed\nframework, we build a new evaluation set called CaRB-AutoPara, a syntactically\ndiverse dataset consistent with the real-world setting for validating the\nrobustness of the models. Experiments including a thorough analysis show that\nthe performance of the model degrades with the increase of the difference in\nsyntactic distribution, while our framework gives a robust boundary. The source\ncode is publicly available at https://github.com/qijimrc/RobustOIE.", "published": "2023-01-17 12:39:13", "link": "http://arxiv.org/abs/2301.06841v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Transformer Based Implementation for Automatic Book Summarization", "abstract": "Document Summarization is the procedure of generating a meaningful and\nconcise summary of a given document with the inclusion of relevant and\ntopic-important points. There are two approaches: one is picking up the most\nrelevant statements from the document itself and adding it to the Summary known\nas Extractive and the other is generating sentences for the Summary known as\nAbstractive Summarization. Training a machine learning model to perform tasks\nthat are time-consuming or very difficult for humans to evaluate is a major\nchallenge. Book Abstract generation is one of such complex tasks. Traditional\nmachine learning models are getting modified with pre-trained transformers.\nTransformer based language models trained in a self-supervised fashion are\ngaining a lot of attention; when fine-tuned for Natural Language\nProcessing(NLP) downstream task like text summarization. This work is an\nattempt to use Transformer based techniques for Abstract generation.", "published": "2023-01-17 18:18:51", "link": "http://arxiv.org/abs/2301.07057v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Transformers as Algorithms: Generalization and Stability in In-context\n  Learning", "abstract": "In-context learning (ICL) is a type of prompting where a transformer model\noperates on a sequence of (input, output) examples and performs inference\non-the-fly. In this work, we formalize in-context learning as an algorithm\nlearning problem where a transformer model implicitly constructs a hypothesis\nfunction at inference-time. We first explore the statistical aspects of this\nabstraction through the lens of multitask learning: We obtain generalization\nbounds for ICL when the input prompt is (1) a sequence of i.i.d. (input, label)\npairs or (2) a trajectory arising from a dynamical system. The crux of our\nanalysis is relating the excess risk to the stability of the algorithm\nimplemented by the transformer. We characterize when transformer/attention\narchitecture provably obeys the stability condition and also provide empirical\nverification. For generalization on unseen tasks, we identify an inductive bias\nphenomenon in which the transfer learning risk is governed by the task\ncomplexity and the number of MTL tasks in a highly predictable manner. Finally,\nwe provide numerical evaluations that (1) demonstrate transformers can indeed\nimplement near-optimal algorithms on classical regression problems with i.i.d.\nand dynamic data, (2) provide insights on stability, and (3) verify our\ntheoretical predictions.", "published": "2023-01-17 18:31:12", "link": "http://arxiv.org/abs/2301.07067v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MooseNet: A Trainable Metric for Synthesized Speech with a PLDA Module", "abstract": "We present MooseNet, a trainable speech metric that predicts the listeners'\nMean Opinion Score (MOS). We propose a novel approach where the Probabilistic\nLinear Discriminative Analysis (PLDA) generative model is used on top of an\nembedding obtained from a self-supervised learning (SSL) neural network (NN)\nmodel. We show that PLDA works well with a non-finetuned SSL model when trained\nonly on 136 utterances (ca. one minute training time) and that PLDA\nconsistently improves various neural MOS prediction models, even\nstate-of-the-art models with task-specific fine-tuning. Our ablation study\nshows PLDA training superiority over SSL model fine-tuning in a low-resource\nscenario. We also improve SSL model fine-tuning using a convenient optimizer\nchoice and additional contrastive and multi-task training objectives. The\nfine-tuned MooseNet NN with the PLDA module achieves the best results,\nsurpassing the SSL baseline on the VoiceMOS Challenge data.", "published": "2023-01-17 18:53:15", "link": "http://arxiv.org/abs/2301.07087v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Vision Learners Meet Web Image-Text Pairs", "abstract": "Many self-supervised learning methods are pre-trained on the well-curated\nImageNet-1K dataset. In this work, given the excellent scalability of web data,\nwe consider self-supervised pre-training on noisy web sourced image-text paired\ndata. First, we conduct a benchmark study of representative self-supervised\npre-training methods on large-scale web data in a like-for-like setting. We\ncompare a range of methods, including single-modal ones that use masked\ntraining objectives and multi-modal ones that use image-text constrastive\ntraining. We observe that existing multi-modal methods do not outperform their\nsingle-modal counterparts on vision transfer learning tasks. We derive an\ninformation-theoretical view to explain these benchmark results, which provides\ninsight into how to design a novel vision learner. Inspired by this insight, we\npresent a new visual representation pre-training method, MUlti-modal\nGenerator~(MUG), that learns from scalable web sourced image-text data. MUG\nachieves state-of-the-art transfer performance on a variety of tasks and\ndemonstrates promising scaling properties. Pre-trained models and code will be\nmade public upon acceptance.", "published": "2023-01-17 18:53:24", "link": "http://arxiv.org/abs/2301.07088v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Learning Customized Visual Models with Retrieval-Augmented Knowledge", "abstract": "Image-text contrastive learning models such as CLIP have demonstrated strong\ntask transfer ability. The high generality and usability of these visual models\nis achieved via a web-scale data collection process to ensure broad concept\ncoverage, followed by expensive pre-training to feed all the knowledge into\nmodel weights. Alternatively, we propose REACT, REtrieval-Augmented\nCusTomization, a framework to acquire the relevant web knowledge to build\ncustomized visual models for target domains. We retrieve the most relevant\nimage-text pairs (~3% of CLIP pre-training data) from the web-scale database as\nexternal knowledge, and propose to customize the model by only training new\nmodualized blocks while freezing all the original weights. The effectiveness of\nREACT is demonstrated via extensive experiments on classification, retrieval,\ndetection and segmentation tasks, including zero, few, and full-shot settings.\nParticularly, on the zero-shot classification task, compared with CLIP, it\nachieves up to 5.4% improvement on ImageNet and 3.7% on the ELEVATER benchmark\n(20 datasets).", "published": "2023-01-17 18:59:06", "link": "http://arxiv.org/abs/2301.07094v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Embodied Agents for Efficient Exploration and Smart Scene Description", "abstract": "The development of embodied agents that can communicate with humans in\nnatural language has gained increasing interest over the last years, as it\nfacilitates the diffusion of robotic platforms in human-populated environments.\nAs a step towards this objective, in this work, we tackle a setting for visual\nnavigation in which an autonomous agent needs to explore and map an unseen\nindoor environment while portraying interesting scenes with natural language\ndescriptions. To this end, we propose and evaluate an approach that combines\nrecent advances in visual robotic exploration and image captioning on images\ngenerated through agent-environment interaction. Our approach can generate\nsmart scene descriptions that maximize semantic knowledge of the environment\nand avoid repetitions. Further, such descriptions offer user-understandable\ninsights into the robot's representation of the environment by highlighting the\nprominent objects and the correlation between them as encountered during the\nexploration. To quantitatively assess the performance of the proposed approach,\nwe also devise a specific score that takes into account both exploration and\ndescription skills. The experiments carried out on both photorealistic\nsimulated environments and real-world ones demonstrate that our approach can\neffectively describe the robot's point of view during exploration, improving\nthe human-friendly interpretability of its observations.", "published": "2023-01-17 19:28:01", "link": "http://arxiv.org/abs/2301.07150v1", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "The Newsbridge -Telecom SudParis VoxCeleb Speaker Recognition Challenge\n  2022 System Description", "abstract": "We describe the system used by our team for the VoxCeleb Speaker Recognition\nChallenge 2022 (VoxSRC 2022) in the speaker diarization track. Our solution was\ndesigned around a new combination of voice activity detection algorithms that\nuses the strengths of several systems. We introduce a novel multi stream\napproach with a decision protocol based on classifiers entropy. We called this\nmethod a multi-stream voice activity detection and used it with standard\nbaseline diarization embeddings, clustering and resegmentation. With this work,\nwe successfully demonstrated that using a strong baseline and working only on\nvoice activity detection, one can achieved close to state-of-theart results.", "published": "2023-01-17 15:52:39", "link": "http://arxiv.org/abs/2301.07491v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Leveraging Vision-Language Models for Granular Market Change Prediction", "abstract": "Predicting future direction of stock markets using the historical data has\nbeen a fundamental component in financial forecasting. This historical data\ncontains the information of a stock in each specific time span, such as the\nopening, closing, lowest, and highest price. Leveraging this data, the future\ndirection of the market is commonly predicted using various time-series models\nsuch as Long-Short Term Memory networks. This work proposes modeling and\npredicting market movements with a fundamentally new approach, namely by\nutilizing image and byte-based number representation of the stock data\nprocessed with the recently introduced Vision-Language models. We conduct a\nlarge set of experiments on the hourly stock data of the German share index and\nevaluate various architectures on stock price prediction using historical stock\ndata. We conduct a comprehensive evaluation of the results with various metrics\nto accurately depict the actual performance of various approaches. Our\nevaluation results show that our novel approach based on representation of\nstock data as text (bytes) and image significantly outperforms strong deep\nlearning-based baselines.", "published": "2023-01-17 19:37:19", "link": "http://arxiv.org/abs/2301.10166v1", "categories": ["q-fin.ST", "cs.CL", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "Command Line Interface Risk Modeling", "abstract": "Protecting sensitive data is an essential part of security in cloud\ncomputing. However, only specific privileged individuals have access to view or\ninteract with this data; therefore, it is unscalable to depend on these\nindividuals also to maintain the software. A solution to this is to allow\nnon-privileged individuals access to maintain these systems but mask sensitive\ninformation from egressing. To this end, we have created a machine-learning\nmodel to predict and redact fields with sensitive data. This work concentrates\non Azure PowerShell, showing how it applies to other command-line interfaces\nand APIs. Using the F5-score as a weighted metric, we demonstrate different\ntransformation techniques to map this problem from an unknown field to the\nwell-researched area of natural language processing.", "published": "2023-01-17 17:10:38", "link": "http://arxiv.org/abs/2302.01749v1", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "GLIGEN: Open-Set Grounded Text-to-Image Generation", "abstract": "Large-scale text-to-image diffusion models have made amazing advances.\nHowever, the status quo is to use text input alone, which can impede\ncontrollability. In this work, we propose GLIGEN, Grounded-Language-to-Image\nGeneration, a novel approach that builds upon and extends the functionality of\nexisting pre-trained text-to-image diffusion models by enabling them to also be\nconditioned on grounding inputs. To preserve the vast concept knowledge of the\npre-trained model, we freeze all of its weights and inject the grounding\ninformation into new trainable layers via a gated mechanism. Our model achieves\nopen-world grounded text2img generation with caption and bounding box condition\ninputs, and the grounding ability generalizes well to novel spatial\nconfigurations and concepts. GLIGEN's zero-shot performance on COCO and LVIS\noutperforms that of existing supervised layout-to-image baselines by a large\nmargin.", "published": "2023-01-17 18:58:58", "link": "http://arxiv.org/abs/2301.07093v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.GR", "cs.LG"], "primary_category": "cs.CV"}
