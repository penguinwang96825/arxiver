{"title": "Streaming Voice Query Recognition using Causal Convolutional Recurrent\n  Neural Networks", "abstract": "Voice-enabled commercial products are ubiquitous, typically enabled by\nlightweight on-device keyword spotting (KWS) and full automatic speech\nrecognition (ASR) in the cloud. ASR systems require significant computational\nresources in training and for inference, not to mention copious amounts of\nannotated speech data. KWS systems, on the other hand, are less\nresource-intensive but have limited capabilities. On the Comcast Xfinity X1\nentertainment platform, we explore a middle ground between ASR and KWS: We\nintroduce a novel, resource-efficient neural network for voice query\nrecognition that is much more accurate than state-of-the-art CNNs for KWS, yet\ncan be easily trained and deployed with limited resources. On an evaluation\ndataset representing the top 200 voice queries, we achieve a low false alarm\nrate of 1% and a query error rate of 6%. Our model performs inference 8.24x\nfaster than the current ASR system.", "published": "2018-12-19 04:51:42", "link": "http://arxiv.org/abs/1812.07754v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DTMT: A Novel Deep Transition Architecture for Neural Machine\n  Translation", "abstract": "Past years have witnessed rapid developments in Neural Machine Translation\n(NMT). Most recently, with advanced modeling and training techniques, the\nRNN-based NMT (RNMT) has shown its potential strength, even compared with the\nwell-known Transformer (self-attentional) model. Although the RNMT model can\npossess very deep architectures through stacking layers, the transition depth\nbetween consecutive hidden states along the sequential axis is still shallow.\nIn this paper, we further enhance the RNN-based NMT through increasing the\ntransition depth between consecutive hidden states and build a novel Deep\nTransition RNN-based Architecture for Neural Machine Translation, named DTMT.\nThis model enhances the hidden-to-hidden transition with multiple non-linear\ntransformations, as well as maintains a linear transformation path throughout\nthis deep transition by the well-designed linear transformation mechanism to\nalleviate the gradient vanishing problem. Experiments show that with the\nspecially designed deep transition modules, our DTMT can achieve remarkable\nimprovements on translation quality. Experimental results on Chinese->English\ntranslation task show that DTMT can outperform the Transformer model by +2.09\nBLEU points and achieve the best results ever reported in the same dataset. On\nWMT14 English->German and English->French translation tasks, DTMT shows\nsuperior quality to the state-of-the-art NMT systems, including the Transformer\nand the RNMT+.", "published": "2018-12-19 08:35:38", "link": "http://arxiv.org/abs/1812.07807v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Attention: A Better Building Block for Sentiment Analysis Neural\n  Network Classifiers", "abstract": "Sentiment Analysis has seen much progress in the past two decades. For the\npast few years, neural network approaches, primarily RNNs and CNNs, have been\nthe most successful for this task. Recently, a new category of neural networks,\nself-attention networks (SANs), have been created which utilizes the attention\nmechanism as the basic building block. Self-attention networks have been shown\nto be effective for sequence modeling tasks, while having no recurrence or\nconvolutions. In this work we explore the effectiveness of the SANs for\nsentiment analysis. We demonstrate that SANs are superior in performance to\ntheir RNN and CNN counterparts by comparing their classification accuracy on\nsix datasets as well as their model characteristics such as training speed and\nmemory consumption. Finally, we explore the effects of various SAN\nmodifications such as multi-head attention as well as two methods of\nincorporating sequence position information into SANs.", "published": "2018-12-19 10:21:20", "link": "http://arxiv.org/abs/1812.07860v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Switch-LSTMs for Multi-Criteria Chinese Word Segmentation", "abstract": "Multi-criteria Chinese word segmentation is a promising but challenging task,\nwhich exploits several different segmentation criteria and mines their common\nunderlying knowledge. In this paper, we propose a flexible multi-criteria\nlearning for Chinese word segmentation. Usually, a segmentation criterion could\nbe decomposed into multiple sub-criteria, which are shareable with other\nsegmentation criteria. The process of word segmentation is a routing among\nthese sub-criteria. From this perspective, we present Switch-LSTMs to segment\nwords, which consist of several long short-term memory neural networks (LSTM),\nand a switcher to automatically switch the routing among these LSTMs. With\nthese auto-switched LSTMs, our model provides a more flexible solution for\nmulti-criteria CWS, which is also easy to transfer the learned knowledge to new\ncriteria. Experiments show that our model obtains significant improvements on\neight corpora with heterogeneous segmentation criteria, compared to the\nprevious method and single-criterion learning.", "published": "2018-12-19 15:48:01", "link": "http://arxiv.org/abs/1812.08033v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FrameNet automatic analysis : a study on a French corpus of encyclopedic\n  texts", "abstract": "This article presents an automatic frame analysis system evaluated on a\ncorpus of French encyclopedic history texts annotated according to the FrameNet\nformalism. The chosen approach relies on an integrated sequence labeling model\nwhich jointly optimizes frame identification and semantic role segmentation and\nidentification. The purpose of this study is to analyze the task complexity\nfrom several dimensions. Hence we provide detailed evaluations from a feature\nselection point of view and from the data point of view.", "published": "2018-12-19 15:59:31", "link": "http://arxiv.org/abs/1812.08044v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Frame Parsing for Information Extraction : the CALOR corpus", "abstract": "This paper presents a publicly available corpus of French encyclopedic\nhistory texts annotated according to the Berkeley FrameNet formalism. The main\ndifference in our approach compared to previous works on semantic parsing with\nFrameNet is that we are not interested here in full text parsing but rather on\npartial parsing. The goal is to select from the FrameNet resources the minimal\nset of frames that are going to be useful for the applicative framework\ntargeted, in our case Information Extraction from encyclopedic documents. Such\nan approach leverages the manual annotation of larger corpora than those\nobtained through full text parsing and therefore opens the door to alternative\nmethods for Frame parsing than those used so far on the FrameNet 1.5 benchmark\ncorpus. The approaches compared in this study rely on an integrated sequence\nlabeling model which jointly optimizes frame identification and semantic role\nsegmentation and identification. The models compared are CRFs and multitasks\nbi-LSTMs.", "published": "2018-12-19 15:54:41", "link": "http://arxiv.org/abs/1812.08039v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cyberbullying Detection in Social Networks Using Deep Learning Based\n  Models; A Reproducibility Study", "abstract": "Cyberbullying is a disturbing online misbehaviour with troubling\nconsequences. It appears in different forms, and in most of the social\nnetworks, it is in textual format. Automatic detection of such incidents\nrequires intelligent systems. Most of the existing studies have approached this\nproblem with conventional machine learning models and the majority of the\ndeveloped models in these studies are adaptable to a single social network at a\ntime. In recent studies, deep learning based models have found their way in the\ndetection of cyberbullying incidents, claiming that they can overcome the\nlimitations of the conventional models, and improve the detection performance.\nIn this paper, we investigate the findings of a recent literature in this\nregard. We successfully reproduced the findings of this literature and\nvalidated their findings using the same datasets, namely Wikipedia, Twitter,\nand Formspring, used by the authors. Then we expanded our work by applying the\ndeveloped methods on a new YouTube dataset (~54k posts by ~4k users) and\ninvestigated the performance of the models in new social media platforms. We\nalso transferred and evaluated the performance of the models trained on one\nplatform to another platform. Our findings show that the deep learning based\nmodels outperform the machine learning models previously applied to the same\nYouTube dataset. We believe that the deep learning based models can also\nbenefit from integrating other sources of information and looking into the\nimpact of profile information of the users in social networks.", "published": "2018-12-19 16:02:08", "link": "http://arxiv.org/abs/1812.08046v1", "categories": ["cs.CL", "cs.IR", "cs.SI"], "primary_category": "cs.CL"}
{"title": "A standardized Project Gutenberg corpus for statistical analysis of\n  natural language and quantitative linguistics", "abstract": "The use of Project Gutenberg (PG) as a text corpus has been extremely popular\nin statistical analysis of language for more than 25 years. However, in\ncontrast to other major linguistic datasets of similar importance, no\nconsensual full version of PG exists to date. In fact, most PG studies so far\neither consider only a small number of manually selected books, leading to\npotential biased subsets, or employ vastly different pre-processing strategies\n(often specified in insufficient details), raising concerns regarding the\nreproducibility of published results. In order to address these shortcomings,\nhere we present the Standardized Project Gutenberg Corpus (SPGC), an open\nscience approach to a curated version of the complete PG data containing more\nthan 50,000 books and more than $3 \\times 10^9$ word-tokens. Using different\nsources of annotated metadata, we not only provide a broad characterization of\nthe content of PG, but also show different examples highlighting the potential\nof SPGC for investigating language variability across time, subjects, and\nauthors. We publish our methodology in detail, the code to download and process\nthe data, as well as the obtained corpus itself on 3 different levels of\ngranularity (raw text, timeseries of word tokens, and counts of words). In this\nway, we provide a reproducible, pre-processed, full-size version of Project\nGutenberg as a new scientific resource for corpus linguistics, natural language\nprocessing, and information retrieval.", "published": "2018-12-19 17:10:14", "link": "http://arxiv.org/abs/1812.08092v1", "categories": ["cs.CL", "cs.DL", "cs.IR", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Generating Diverse and Meaningful Captions", "abstract": "Image Captioning is a task that requires models to acquire a multi-modal\nunderstanding of the world and to express this understanding in natural\nlanguage text. While the state-of-the-art for this task has rapidly improved in\nterms of n-gram metrics, these models tend to output the same generic captions\nfor similar images. In this work, we address this limitation and train a model\nthat generates more diverse and specific captions through an unsupervised\ntraining approach that incorporates a learning signal from an Image Retrieval\nmodel. We summarize previous results and improve the state-of-the-art on\ncaption diversity and novelty. We make our source code publicly available\nonline.", "published": "2018-12-19 18:10:18", "link": "http://arxiv.org/abs/1812.08126v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Unifying Topic, Sentiment & Preference in an HDP-Based Rating Regression\n  Model for Online Reviews", "abstract": "This paper proposes a new HDP based online review rating regression model\nnamed Topic-Sentiment-Preference Regression Analysis (TSPRA). TSPRA combines\ntopics (i.e. product aspects), word sentiment and user preference as regression\nfactors, and is able to perform topic clustering, review rating prediction,\nsentiment analysis and what we invent as \"critical aspect\" analysis altogether\nin one framework. TSPRA extends sentiment approaches by integrating the key\nconcept \"user preference\" in collaborative filtering (CF) models into\nconsideration, while it is distinct from current CF models by decoupling \"user\npreference\" and \"sentiment\" as independent factors. Our experiments conducted\non 22 Amazon datasets show overwhelming better performance in rating\npredication against a state-of-art model FLAME (2015) in terms of error,\nPearson's Correlation and number of inverted pairs. For sentiment analysis, we\ncompare the derived word sentiments against a public sentiment resource\nSenticNet3 and our sentiment estimations clearly make more sense in the context\nof online reviews. Last, as a result of the de-correlation of \"user preference\"\nfrom \"sentiment\", TSPRA is able to evaluate a new concept \"critical aspects\",\ndefined as the product aspects seriously concerned by users but negatively\ncommented in reviews. Improvement to such \"critical aspects\" could be most\neffective to enhance user experience.", "published": "2018-12-19 08:33:31", "link": "http://arxiv.org/abs/1812.07805v1", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.AP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Found in Translation: Learning Robust Joint Representations by Cyclic\n  Translations Between Modalities", "abstract": "Multimodal sentiment analysis is a core research area that studies speaker\nsentiment expressed from the language, visual, and acoustic modalities. The\ncentral challenge in multimodal learning involves inferring joint\nrepresentations that can process and relate information from these modalities.\nHowever, existing work learns joint representations by requiring all modalities\nas input and as a result, the learned representations may be sensitive to noisy\nor missing modalities at test time. With the recent success of sequence to\nsequence (Seq2Seq) models in machine translation, there is an opportunity to\nexplore new ways of learning joint representations that may not require all\ninput modalities at test time. In this paper, we propose a method to learn\nrobust joint representations by translating between modalities. Our method is\nbased on the key insight that translation from a source to a target modality\nprovides a method of learning joint representations using only the source\nmodality as input. We augment modality translations with a cycle consistency\nloss to ensure that our joint representations retain maximal information from\nall modalities. Once our translation model is trained with paired multimodal\ndata, we only need data from the source modality at test time for final\nsentiment prediction. This ensures that our model remains robust from\nperturbations or missing information in the other modalities. We train our\nmodel with a coupled translation-prediction objective and it achieves new\nstate-of-the-art results on multimodal sentiment analysis datasets: CMU-MOSI,\nICT-MMMO, and YouTube. Additional experiments show that our model learns\nincreasingly discriminative joint representations with more input modalities\nwhile maintaining robustness to missing or perturbed modalities.", "published": "2018-12-19 08:38:21", "link": "http://arxiv.org/abs/1812.07809v2", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.HC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Tracking Multiple Audio Sources with the von Mises Distribution and\n  Variational EM", "abstract": "In this paper we address the problem of simultaneously tracking several\nmoving audio sources, namely the problem of estimating source trajectories from\na sequence of observed features. We propose to use the von Mises distribution\nto model audio-source directions of arrival with circular random variables.\nThis leads to a Bayesian filtering formulation which is intractable because of\nthe combinatorial explosion of associating observed variables with latent\nvariables, over time. We propose a variational approximation of the filtering\ndistribution. We infer a variational expectation-maximization algorithm that is\nboth computationally tractable and time efficient. We propose an audio-source\nbirth method that favors smooth source trajectories and which is used both to\ninitialize the number of active sources and to detect new sources. We perform\nexperiments with the recently released LOCATA dataset comprising two moving\nsources and a moving microphone array mounted onto a robot.", "published": "2018-12-19 21:10:18", "link": "http://arxiv.org/abs/1812.08246v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Pathological Voice Classification Using Mel-Cepstrum Vectors and Support\n  Vector Machine", "abstract": "Vocal disorders have affected several patients all over the world. Due to the\ninherent difficulty of diagnosing vocal disorders without sophisticated\nequipment and trained personnel, a number of patients remain undiagnosed. To\nalleviate the monetary cost of diagnosis, there has been a recent growth in the\nuse of data analysis to accurately detect and diagnose individuals for a\nfraction of the cost. We propose a cheap, efficient and accurate model to\ndiagnose whether a patient suffers from one of three vocal disorders on the\nFEMH 2018 challenge.", "published": "2018-12-19 02:00:24", "link": "http://arxiv.org/abs/1812.07729v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Detecting the Trend in Musical Taste over the Decade -- A Novel Feature\n  Extraction Algorithm to Classify Musical Content with Simple Features", "abstract": "This work proposes a novel feature selection algorithm to classify Songs into\ndifferent groups. Classification of musical content is often a non-trivial job\nand still relatively less explored area. The main idea conveyed in this article\nis to come up with a new feature selection scheme that does the classification\njob elegantly and with high accuracy but with simpler but wisely chosen small\nnumber of features thus being less prone to over-fitting. This uses a very\nbasic general idea about the structure of the audio signal which is generally\nin the shape of a trapezium. So, using this general idea of the Musical\nCommunity we propose three frames to be considered and analyzed for feature\nextraction for each of the audio signal -- opening, stanzas and closing -- and\nit has been established with the help of a lot of experiments that this scheme\nleads to much efficient classification with less complex features in a low\ndimensional feature space thus is also a computationally less expensive method.\nStep by step analysis of feature extraction, feature ranking, dimensionality\nreduction using PCA has been carried in this article. Sequential Forward\nselection (SFS) algorithm is used to explore the most significant features both\nwith the raw Fisher Discriminant Ratio (FDR) and also with the significant\neigen-values after PCA. Also during classification extensive validation and\ncross validation has been done in a monte-carlo manner to ensure validity of\nthe claims.", "published": "2018-12-19 03:53:55", "link": "http://arxiv.org/abs/1901.02053v1", "categories": ["cs.IR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
