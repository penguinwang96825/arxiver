{"title": "What Level of Automation is \"Good Enough\"? A Benchmark of Large Language Models for Meta-Analysis Data Extraction", "abstract": "Automating data extraction from full-text randomised controlled trials (RCTs)\nfor meta-analysis remains a significant challenge. This study evaluates the\npractical performance of three LLMs (Gemini-2.0-flash, Grok-3, GPT-4o-mini)\nacross tasks involving statistical results, risk-of-bias assessments, and\nstudy-level characteristics in three medical domains: hypertension, diabetes,\nand orthopaedics. We tested four distinct prompting strategies (basic\nprompting, self-reflective prompting, model ensemble, and customised prompts)\nto determine how to improve extraction quality. All models demonstrate high\nprecision but consistently suffer from poor recall by omitting key information.\nWe found that customised prompts were the most effective, boosting recall by up\nto 15\\%. Based on this analysis, we propose a three-tiered set of guidelines\nfor using LLMs in data extraction, matching data types to appropriate levels of\nautomation based on task complexity and risk. Our study offers practical advice\nfor automating data extraction in real-world meta-analyses, balancing LLM\nefficiency with expert oversight through targeted, task-specific automation.", "published": "2025-07-20 23:09:04", "link": "http://arxiv.org/abs/2507.15152v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script", "abstract": "Homophone normalization, where characters that have the same sound in a\nwriting script are mapped to one character, is a pre-processing step applied in\nAmharic Natural Language Processing (NLP) literature. While this may improve\nperformance reported by automatic metrics, it also results in models that are\nnot able to understand different forms of writing in a single language.\nFurther, there might be impacts in transfer learning, where models trained on\nnormalized data do not generalize well to other languages. In this paper, we\nexperiment with monolingual training and cross-lingual transfer to understand\nthe impacts of normalization on languages that use the Ge'ez script. We then\npropose a post-inference intervention in which normalization is applied to\nmodel predictions instead of training data. With our simple scheme of\npost-inference normalization, we show that we can achieve an increase in BLEU\nscore of up to 1.03 while preserving language features in training. Our work\ncontributes to the broader discussion on technology-facilitated language change\nand calls for more language-aware interventions.", "published": "2025-07-20 22:35:08", "link": "http://arxiv.org/abs/2507.15142v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Disagreement to Understanding: The Case for Ambiguity Detection in NLI", "abstract": "This position paper argues that annotation disagreement in Natural Language\nInference (NLI) is not mere noise but often reflects meaningful interpretive\nvariation, especially when triggered by ambiguity in the premise or hypothesis.\nWhile underspecified guidelines and annotator behavior can contribute to\nvariation, content-based ambiguity offers a process-independent signal of\ndivergent human perspectives. We call for a shift toward ambiguity-aware NLI by\nsystematically identifying ambiguous input pairs and classifying ambiguity\ntypes. To support this, we present a unified framework that integrates existing\ntaxonomies and illustrate key ambiguity subtypes through concrete examples.\nThese examples reveal how ambiguity shapes annotator decisions and motivate the\nneed for targeted detection methods that better align models with human\ninterpretation. A key limitation is the lack of datasets annotated for\nambiguity and subtypes. We propose addressing this gap through new annotated\nresources and unsupervised approaches to ambiguity detection -- paving the way\nfor more robust, explainable, and human-aligned NLI systems.", "published": "2025-07-20 20:27:35", "link": "http://arxiv.org/abs/2507.15114v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Filling the Gap: Is Commonsense Knowledge Generation useful for Natural Language Inference?", "abstract": "Natural Language Inference (NLI) is the task of determining the semantic\nentailment of a premise for a given hypothesis. The task aims to develop\nsystems that emulate natural human inferential processes where commonsense\nknowledge plays a major role. However, existing commonsense resources lack\nsufficient coverage for a variety of premise-hypothesis pairs. This study\nexplores the potential of Large Language Models as commonsense knowledge\ngenerators for NLI along two key dimensions: their reliability in generating\nsuch knowledge and the impact of that knowledge on prediction accuracy. We\nadapt and modify existing metrics to assess LLM factuality and consistency in\ngenerating in this context. While explicitly incorporating commonsense\nknowledge does not consistently improve overall results, it effectively helps\ndistinguish entailing instances and moderately improves distinguishing\ncontradictory and neutral inferences.", "published": "2025-07-20 19:42:45", "link": "http://arxiv.org/abs/2507.15100v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Penalty Goes a Long Way: Measuring Lexical Diversity in Synthetic Texts Under Prompt-Influenced Length Variations", "abstract": "Synthetic text generated by Large Language Models (LLMs) is increasingly used\nfor further training and improvement of LLMs. Diversity is crucial for the\neffectiveness of synthetic data, and researchers rely on prompt engineering to\nimprove diversity. However, the impact of prompt variations on response text\nlength, and, more importantly, the consequential effect on lexical diversity\nmeasurements, remain underexplored. In this work, we propose Penalty-Adjusted\nType-Token Ratio (PATTR), a diversity metric robust to length variations. We\ngenerate a large synthetic corpus of over 20M words using seven models from the\nLLaMA, OLMo, and Phi families, focusing on a creative writing task of video\nscript generation, where diversity is crucial. We evaluate per-response lexical\ndiversity using PATTR and compare it against existing metrics of Moving-Average\nTTR (MATTR) and Compression Ratio (CR). Our analysis highlights how text length\nvariations introduce biases favoring shorter responses. Unlike existing\nmetrics, PATTR explicitly considers the task-specific target response length\n($L_T$) to effectively mitigate length biases. We further demonstrate the\nutility of PATTR in filtering the top-10/100/1,000 most lexically diverse\nresponses, showing that it consistently outperforms MATTR and CR by yielding on\npar or better diversity with high adherence to $L_T$.", "published": "2025-07-20 19:14:43", "link": "http://arxiv.org/abs/2507.15092v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling", "abstract": "Currently, many studies view DNA sequences as a special type of language and\nutilize Transformers to model them. These studies use fixed-length k-mer\nsegmentation and BPE subword tokenization but lack a systematic evaluation to\ndetermine which is superior. We compare k-mer segmentation with k=1,3,4,5,6, a\n4,096-token BPE vocabulary, and three positional encoding methods-sinusoidal,\nAliBi, and RoPE. Each configuration is trained from scratch in 3, 6, 12, and\n24-layer Transformer encoders and evaluated on GUE benchmark dataset. In\ngeneral, BPE delivers higher and more stable performance across tasks by\ncompressing frequent motifs into variable-length tokens, reducing sequence\nlength, and improving model generalization. RoPE excels at capturing periodic\nmotifs and extrapolating to long sequences, while AliBi also performs well on\ntasks driven by local dependencies. In terms of depth, we observe significant\ngains when increasing layers from 3 to 12, with only marginal improvements or\nslight overfitting at 24 layers. This study provides practical guidance for\ndesigning tokenization and positional encoding in DNA Transformer models.", "published": "2025-07-20 19:02:07", "link": "http://arxiv.org/abs/2507.15087v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization", "abstract": "The advent of Large Language Model (LLM)-powered agents has revolutionized\nartificial intelligence by enabling solutions to complex, open-ended tasks\nthrough web-based information-seeking (IS) capabilities. The scarcity of\nhigh-quality training data has limited the development of IS agents. Existing\napproaches typically adopt an information-driven paradigm that first collects\nweb data and then generates questions based on the retrieval. However, this may\nlead to inconsistency between information structure and reasoning structure,\nquestion and answer. To mitigate, we propose a formalization-driven IS data\nsynthesis framework WebShaper to construct a dataset. WebShaper systematically\nformalizes IS tasks through set theory. Central to the formalization is the\nconcept of Knowledge Projections (KP), which enables precise control over\nreasoning structure by KP operation compositions. During synthesis, we begin by\ncreating seed tasks, then use a multi-step expansion process. At each step, an\nagentic Expander expands the current formal question more complex with\nretrieval and validation tools based on our formalization. We train our model\non the synthesized dataset. Experiment results demonstrate that WebShaper\nachieves state-of-the-art performance among open-sourced IS agents on GAIA and\nWebWalkerQA benchmarks.", "published": "2025-07-20 17:53:37", "link": "http://arxiv.org/abs/2507.15061v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RefCritic: Training Long Chain-of-Thought Critic Models with Refinement Feedback", "abstract": "With the rapid advancement of Large Language Models (LLMs), developing\neffective critic modules for precise guidance has become crucial yet\nchallenging. In this paper, we initially demonstrate that supervised\nfine-tuning for building critic modules (which is widely adopted in current\nsolutions) fails to genuinely enhance models' critique abilities, producing\nsuperficial critiques with insufficient reflections and verifications. To\nunlock the unprecedented critique capabilities, we propose RefCritic, a\nlong-chain-of-thought critic module based on reinforcement learning with dual\nrule-based rewards: (1) instance-level correctness of solution judgments and\n(2) refinement accuracies of the policy model based on critiques, aiming to\ngenerate high-quality evaluations with actionable feedback that effectively\nguides model refinement. We evaluate RefCritic on Qwen2.5-14B-Instruct and\nDeepSeek-R1-Distill-Qwen-14B across five benchmarks. On critique and refinement\nsettings, RefCritic demonstrates consistent advantages across all benchmarks,\ne.g., 6.8\\% and 7.2\\% gains on AIME25 for the respective base models. Notably,\nunder majority voting, policy models filtered by RefCritic show superior\nscaling with increased voting numbers. Moreover, despite training on\nsolution-level supervision, RefCritic outperforms step-level supervised\napproaches on ProcessBench, a benchmark to identify erroneous steps in\nmathematical reasoning.", "published": "2025-07-20 16:19:51", "link": "http://arxiv.org/abs/2507.15024v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hear Your Code Fail, Voice-Assisted Debugging for Python", "abstract": "This research introduces an innovative voice-assisted debugging plugin for\nPython that transforms silent runtime errors into actionable audible\ndiagnostics. By implementing a global exception hook architecture with pyttsx3\ntext-to-speech conversion and Tkinter-based GUI visualization, the solution\ndelivers multimodal error feedback through parallel auditory and visual\nchannels. Empirical evaluation demonstrates 37% reduced cognitive load (p<0.01,\nn=50) compared to traditional stack-trace debugging, while enabling 78% faster\nerror identification through vocalized exception classification and\ncontextualization. The system achieves sub-1.2 second voice latency with under\n18% CPU overhead during exception handling, vocalizing error types and\nconsequences while displaying interactive tracebacks with documentation deep\nlinks. Criteria validate compatibility across Python 3.7+ environments on\nWindows, macOS, and Linux platforms. Needing only two lines of integration\ncode, the plugin significantly boosts availability for aesthetically impaired\ndesigners and supports multitasking workflows through hands-free error medical\ndiagnosis. Educational applications show particular promise, with pilot studies\nindicating 45% faster debugging skill acquisition among novice programmers.\nFuture development will incorporate GPT-based repair suggestions and real-time\nmultilingual translation to further advance auditory debugging paradigms. The\nsolution represents a fundamental shift toward human-centric error diagnostics,\nbridging critical gaps in programming accessibility while establishing new\nstandards for cognitive efficiency in software development workflows.", "published": "2025-07-20 15:24:35", "link": "http://arxiv.org/abs/2507.15007v1", "categories": ["cs.PL", "cs.CL"], "primary_category": "cs.PL"}
{"title": "MUR: Momentum Uncertainty guided Reasoning for Large Language Models", "abstract": "Large Language Models (LLMs) have achieved impressive performance on\nreasoning-intensive tasks, yet optimizing their reasoning efficiency remains an\nopen challenge. While Test-Time Scaling (TTS) improves reasoning quality, it\noften leads to overthinking, wasting tokens on redundant computations. This\nwork investigates how to efficiently and adaptively guide LLM test-time scaling\nwithout additional training. Inspired by the concept of momentum in physics, we\npropose Momentum Uncertainty-guided Reasoning (MUR), which dynamically\nallocates thinking budgets to critical reasoning steps by tracking and\naggregating stepwise uncertainty over time. To support flexible inference-time\ncontrol, we introduce gamma-control, a simple mechanism that tunes the\nreasoning budget via a single hyperparameter. We provide in-depth theoretical\nproof to support the superiority of MUR in terms of stability and biases. MUR\nis comprehensively evaluated against various TTS methods across four\nchallenging benchmarks (MATH-500, AIME24, AIME25, and GPQA-diamond) using\ndifferent sizes of recent Qwen3 models (1.7B, 4B, and 8B). Results demonstrate\nthat MUR reduces computation by over 50% on average while improving accuracy by\n0.62-3.37%.", "published": "2025-07-20 13:36:19", "link": "http://arxiv.org/abs/2507.14958v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SYNTHIA: Synthetic Yet Naturally Tailored Human-Inspired PersonAs", "abstract": "Persona-driven LLMs have emerged as powerful tools in computational social\nscience, yet existing approaches fall at opposite extremes, either relying on\ncostly human-curated data or producing synthetic personas that lack consistency\nand realism. We introduce SYNTHIA, a dataset of 30,000 backstories derived from\n10,000 real social media users from BlueSky open platform across three time\nwindows, bridging this spectrum by grounding synthetic generation in authentic\nuser activity. Our evaluation demonstrates that SYNTHIA achieves competitive\nperformance with state-of-the-art methods in demographic diversity and social\nsurvey alignment while significantly outperforming them in narrative\nconsistency. Uniquely, SYNTHIA incorporates temporal dimensionality and\nprovides rich social interaction metadata from the underlying network, enabling\nnew research directions in computational social science and persona-driven\nlanguage modeling.", "published": "2025-07-20 11:37:07", "link": "http://arxiv.org/abs/2507.14922v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "PromptSuite: A Task-Agnostic Framework for Multi-Prompt Generation", "abstract": "Evaluating LLMs with a single prompt has proven unreliable, with small\nchanges leading to significant performance differences. However, generating the\nprompt variations needed for a more robust multi-prompt evaluation is\nchallenging, limiting its adoption in practice. To address this, we introduce\nPromptSuite, a framework that enables the automatic generation of various\nprompts. PromptSuite is flexible - working out of the box on a wide range of\ntasks and benchmarks. It follows a modular prompt design, allowing controlled\nperturbations to each component, and is extensible, supporting the addition of\nnew components and perturbation types. Through a series of case studies, we\nshow that PromptSuite provides meaningful variations to support strong\nevaluation practices. It is available through both a Python API:\nhttps://github.com/eliyahabba/PromptSuite, and a user-friendly web interface:\nhttps://promptsuite.streamlit.app/", "published": "2025-07-20 10:55:29", "link": "http://arxiv.org/abs/2507.14913v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment", "abstract": "Large language models (LLMs) have demonstrated remarkable multilingual\ncapabilities, however, how to evaluate cross-lingual alignment remains\nunderexplored. Existing alignment benchmarks primarily focus on sentence\nembeddings, but prior research has shown that neural models tend to induce a\nnon-smooth representation space, which impact of semantic alignment evaluation\non low-resource languages. Inspired by neuroscientific findings that similar\ninformation activates overlapping neuronal regions, we propose a novel Neuron\nState-Based Cross-Lingual Alignment (NeuronXA) to assess the cross-lingual a\nlignment capabilities of LLMs, which offers a more semantically grounded\napproach to assess cross-lingual alignment. We evaluate NeuronXA on several\nprominent multilingual LLMs (LLaMA, Qwen, Mistral, GLM, and OLMo) across two\ntransfer tasks and three multilingual benchmarks. The results demonstrate that\nwith only 100 parallel sentence pairs, NeuronXA achieves a Pearson correlation\nof 0.9556 with downstream tasks performance and 0.8514 with transferability.\nThese findings demonstrate NeuronXA's effectiveness in assessing both\ncross-lingual alignment and transferability, even with a small dataset. This\nhighlights its potential to advance cross-lingual alignment research and to\nimprove the semantic understanding of multilingual LLMs.", "published": "2025-07-20 10:23:22", "link": "http://arxiv.org/abs/2507.14900v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sparse Autoencoder-guided Supervised Finetuning to Mitigate Unexpected Code-Switching in LLMs", "abstract": "Large Language Models (LLMs) have impressive multilingual capabilities, but\nthey suffer from unexpected code-switching, also known as language mixing,\nwhich involves switching to unexpected languages in the model response. This\nproblem leads to poor readability and degrades the usability of model\nresponses. However, existing work on this issue lacks a mechanistic analysis\nand shows limited effectiveness. In this paper, we first provide an in-depth\nanalysis of unexpected code-switching using sparse autoencoders and find that\nwhen LLMs switch to a language, the features of that language exhibit excessive\npre-activation values. Based on our findings, we propose $\\textbf{S}$parse\n$\\textbf{A}$utoencoder-guided $\\textbf{S}$upervised\n$\\textbf{F}$ine$\\textbf{t}$uning (SASFT), which teaches LLMs to maintain\nappropriate pre-activation values of specific language features during\ntraining. Experiments on five models across three languages demonstrate that\nSASFT consistently reduces unexpected code-switching by more than 50\\% compared\nto standard supervised fine-tuning, with complete elimination in four cases.\nMoreover, SASFT maintains or even improves the models' performance on six\nmultilingual benchmarks, showing its effectiveness in addressing code-switching\nwhile preserving multilingual capabilities.", "published": "2025-07-20 10:20:01", "link": "http://arxiv.org/abs/2507.14894v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MEKiT: Multi-source Heterogeneous Knowledge Injection Method via Instruction Tuning for Emotion-Cause Pair Extraction", "abstract": "Although large language models (LLMs) excel in text comprehension and\ngeneration, their performance on the Emotion-Cause Pair Extraction (ECPE) task,\nwhich requires reasoning ability, is often underperform smaller language model.\nThe main reason is the lack of auxiliary knowledge, which limits LLMs' ability\nto effectively perceive emotions and reason causes. To address this issue, we\npropose a novel \\textbf{M}ulti-source h\\textbf{E}terogeneous \\textbf{K}nowledge\n\\textbf{i}njection me\\textbf{T}hod, MEKiT, which integrates heterogeneous\ninternal emotional knowledge and external causal knowledge. Specifically, for\nthese two distinct aspects and structures of knowledge, we apply the approaches\nof incorporating instruction templates and mixing data for instruction-tuning,\nwhich respectively facilitate LLMs in more comprehensively identifying emotion\nand accurately reasoning causes. Experimental results demonstrate that MEKiT\nprovides a more effective and adaptable solution for the ECPE task, exhibiting\nan absolute performance advantage over compared baselines and dramatically\nimproving the performance of LLMs on the ECPE task.", "published": "2025-07-20 10:11:21", "link": "http://arxiv.org/abs/2507.14887v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tiny language models", "abstract": "A prominent achievement of natural language processing (NLP) is its ability\nto understand and generate meaningful human language. This capability relies on\ncomplex feedforward transformer block architectures pre-trained on large\nlanguage models (LLMs). However, LLM pre-training is currently feasible only\nfor a few dominant companies due to the immense computational resources\nrequired, limiting broader research participation. This creates a critical need\nfor more accessible alternatives. In this study, we explore whether tiny\nlanguage models (TLMs) exhibit the same key qualitative features of LLMs. We\ndemonstrate that TLMs exhibit a clear performance gap between pre-trained and\nnon-pre-trained models across classification tasks, indicating the\neffectiveness of pre-training, even at a tiny scale. The performance gap\nincreases with the size of the pre-training dataset and with greater overlap\nbetween tokens in the pre-training and classification datasets. Furthermore,\nthe classification accuracy achieved by a pre-trained deep TLM architecture can\nbe replicated through a soft committee of multiple, independently pre-trained\nshallow architectures, enabling low-latency TLMs without affecting\nclassification accuracy. Our results are based on pre-training BERT-6 and\nvariants of BERT-1 on subsets of the Wikipedia dataset and evaluating their\nperformance on FewRel, AGNews, and DBPedia classification tasks. Future\nresearch on TLM is expected to further illuminate the mechanisms underlying\nNLP, especially given that its biologically inspired models suggest that TLMs\nmay be sufficient for children or adolescents to develop language.", "published": "2025-07-20 08:49:57", "link": "http://arxiv.org/abs/2507.14871v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Isolated Capabilities: Bridging Long CoT Reasoning and Long-Context Understanding", "abstract": "Reasoning distillation has emerged as an effective approach to enhance the\nreasoning capabilities of smaller language models. However, the impact of\nlarge-scale reasoning distillation on other critical abilities, particularly\nin-context retrieval and reasoning, remains unexplored. This gap in\nunderstanding is particularly significant given the increasing importance of\nRetrieval-Augmented Generation (RAG) systems, where efficient acquisition and\nutilization of contextual information are paramount for generating reliable\nresponses. Motivated by the need to understand how the extended long-CoT\nprocess influences long-context comprehension, we conduct a comprehensive\ninvestigation using a series of open-source models distilled from Deepseek-R1,\nrenowned for its exceptional reasoning capabilities. Our study focuses on\nevaluating these models' performance in extracting and integrating relevant\ninformation from extended contexts through multi-document question and\nanswering tasks. Through rigorous experimentation, we demonstrate that\ndistilled reasoning patterns significantly improve long-context understanding.\nOur analysis reveals that distillation fosters greater long-context awareness\nby promoting more detailed and explicit reasoning processes during context\nanalysis and information parsing. This advancement effectively mitigates the\npersistent \"lost in the middle\" issue that has hindered long-context models.", "published": "2025-07-20 07:43:16", "link": "http://arxiv.org/abs/2507.14849v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Invisible Leash: Why RLVR May Not Escape Its Origin", "abstract": "Recent advances in large reasoning models highlight Reinforcement Learning\nwith Verifiable Rewards (RLVR) as a promising method for enhancing AI's\ncapabilities, particularly in solving complex logical tasks. However, it\nremains unclear whether RLVR truly expands a model's reasoning boundary or\nmerely amplifies high-reward outputs that the base model already knows for\nimproved precision. This study presents a theoretical and empirical\ninvestigation that provides fresh insights into the potential limits of RLVR.\nFirst, we offer a new theoretical perspective that RLVR is constrained by the\nbase model's support-unable to sample solutions with zero initial\nprobability-and operates as a conservative reweighting mechanism that may\nrestrict the discovery of entirely original solutions. We also identify an\nentropy-reward tradeoff: while RLVR reliably enhances precision, it may\nprogressively narrow exploration and potentially overlook correct yet\nunderrepresented solutions. Extensive empirical experiments validate that while\nRLVR consistently improves pass@1, the shrinkage of empirical support generally\noutweighs the expansion of empirical support under larger sampling budgets,\nfailing to recover correct answers that were previously accessible to the base\nmodel. Interestingly, we also observe that while RLVR sometimes increases\ntoken-level entropy, resulting in greater uncertainty at each generation step,\nanswer-level entropy declines, indicating that these seemingly more uncertain\npaths ultimately converge onto a smaller set of distinct answers. Taken\ntogether, these findings reveal potential limits of RLVR in extending reasoning\nhorizons. Breaking this invisible leash may require future algorithmic\ninnovations such as explicit exploration mechanisms or hybrid strategies that\nseed probability mass into underrepresented solution regions.", "published": "2025-07-20 07:04:08", "link": "http://arxiv.org/abs/2507.14843v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Doc2Chart: Intent-Driven Zero-Shot Chart Generation from Documents", "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in\ntransforming text descriptions or tables to data visualizations via\ninstruction-tuning methods. However, it is not straightforward to apply these\nmethods directly for a more real-world use case of visualizing data from long\ndocuments based on user-given intents, as opposed to the user pre-selecting the\nrelevant content manually. We introduce the task of intent-based chart\ngeneration from documents: given a user-specified intent and document(s), the\ngoal is to generate a chart adhering to the intent and grounded on the\ndocument(s) in a zero-shot setting. We propose an unsupervised, two-staged\nframework in which an LLM first extracts relevant information from the\ndocument(s) by decomposing the intent and iteratively validates and refines\nthis data. Next, a heuristic-guided module selects an appropriate chart type\nbefore final code generation. To assess the data accuracy of the generated\ncharts, we propose an attribution-based metric that uses a structured textual\nrepresentation of charts, instead of relying on visual decoding metrics that\noften fail to capture the chart data effectively. To validate our approach, we\ncurate a dataset comprising of 1,242 $<$intent, document, charts$>$ tuples from\ntwo domains, finance and scientific, in contrast to the existing datasets that\nare largely limited to parallel text descriptions/ tables and their\ncorresponding charts. We compare our approach with baselines using single-shot\nchart generation using LLMs and query-based retrieval methods; our method\noutperforms by upto $9$ points and $17$ points in terms of chart data accuracy\nand chart type respectively over the best baselines.", "published": "2025-07-20 04:34:59", "link": "http://arxiv.org/abs/2507.14819v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FastLongSpeech: Enhancing Large Speech-Language Models for Efficient Long-Speech Processing", "abstract": "The rapid advancement of Large Language Models (LLMs) has spurred significant\nprogress in Large Speech-Language Models (LSLMs), enhancing their capabilities\nin both speech understanding and generation. While existing LSLMs often\nconcentrate on augmenting speech generation or tackling a diverse array of\nshort-speech tasks, the efficient processing of long-form speech remains a\ncritical yet underexplored challenge. This gap is primarily attributed to the\nscarcity of long-speech training datasets and the high computational costs\nassociated with long sequences. To address these limitations, we introduce\nFastLongSpeech, a novel framework designed to extend LSLM capabilities for\nefficient long-speech processing without necessitating dedicated long-speech\ntraining data. FastLongSpeech incorporates an iterative fusion strategy that\ncan compress excessively long-speech sequences into manageable lengths. To\nadapt LSLMs for long-speech inputs, it introduces a dynamic compression\ntraining approach, which exposes the model to short-speech sequences at varying\ncompression ratios, thereby transferring the capabilities of LSLMs to\nlong-speech tasks. To assess the long-speech capabilities of LSLMs, we develop\na long-speech understanding benchmark called LongSpeech-Eval. Experiments show\nthat our method exhibits strong performance in both long-speech and\nshort-speech tasks, while greatly improving inference efficiency.", "published": "2025-07-20 04:11:06", "link": "http://arxiv.org/abs/2507.14815v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Performance Analysis of Post-Training Quantization for CNN-based Conjunctival Pallor Anemia Detection", "abstract": "Anemia is a widespread global health issue, particularly among young children\nin low-resource settings. Traditional methods for anemia detection often\nrequire expensive equipment and expert knowledge, creating barriers to early\nand accurate diagnosis. To address these challenges, we explore the use of deep\nlearning models for detecting anemia through conjunctival pallor, focusing on\nthe CP-AnemiC dataset, which includes 710 images from children aged 6-59\nmonths. The dataset is annotated with hemoglobin levels, gender, age and other\ndemographic data, enabling the development of machine learning models for\naccurate anemia detection. We use the MobileNet architecture as a backbone,\nknown for its efficiency in mobile and embedded vision applications, and\nfine-tune our model end-to-end using data augmentation techniques and a\ncross-validation strategy. Our model implementation achieved an accuracy of\n0.9313, a precision of 0.9374, and an F1 score of 0.9773 demonstrating strong\nperformance on the dataset. To optimize the model for deployment on edge\ndevices, we performed post-training quantization, evaluating the impact of\ndifferent bit-widths (FP32, FP16, INT8, and INT4) on model performance.\nPreliminary results suggest that while FP16 quantization maintains high\naccuracy (0.9250), precision (0.9370), and F1 Score (0.9377), more aggressive\nquantization (INT8 and INT4) leads to significant performance degradation.\nOverall, our study supports further exploration of quantization schemes and\nhardware optimizations to assess trade-offs between model size, inference time,\nand diagnostic accuracy in mobile healthcare applications.", "published": "2025-07-20 23:02:58", "link": "http://arxiv.org/abs/2507.15151v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Event-based Graph Representation with Spatial and Motion Vectors for Asynchronous Object Detection", "abstract": "Event-based sensors offer high temporal resolution and low latency by\ngenerating sparse, asynchronous data. However, converting this irregular data\ninto dense tensors for use in standard neural networks diminishes these\ninherent advantages, motivating research into graph representations. While such\nmethods preserve sparsity and support asynchronous inference, their performance\non downstream tasks remains limited due to suboptimal modeling of\nspatiotemporal dynamics. In this work, we propose a novel spatiotemporal\nmultigraph representation to better capture spatial structure and temporal\nchanges. Our approach constructs two decoupled graphs: a spatial graph\nleveraging B-spline basis functions to model global structure, and a temporal\ngraph utilizing motion vector-based attention for local dynamic changes. This\ndesign enables the use of efficient 2D kernels in place of computationally\nexpensive 3D kernels. We evaluate our method on the Gen1 automotive and eTraM\ndatasets for event-based object detection, achieving over a 6% improvement in\ndetection accuracy compared to previous graph-based works, with a 5x speedup,\nreduced parameter count, and no increase in computational cost. These results\nhighlight the effectiveness of structured graph modeling for asynchronous\nvision. Project page: eventbasedvision.github.io/eGSMV.", "published": "2025-07-20 23:02:23", "link": "http://arxiv.org/abs/2507.15150v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Design of an Edge-based Portable EHR System for Anemia Screening in Remote Health Applications", "abstract": "The design of medical systems for remote, resource-limited environments faces\npersistent challenges due to poor interoperability, lack of offline support,\nand dependency on costly infrastructure. Many existing digital health solutions\nneglect these constraints, limiting their effectiveness for frontline health\nworkers in underserved regions. This paper presents a portable, edge-enabled\nElectronic Health Record platform optimized for offline-first operation, secure\npatient data management, and modular diagnostic integration. Running on\nsmall-form factor embedded devices, it provides AES-256 encrypted local storage\nwith optional cloud synchronization for interoperability. As a use case, we\nintegrated a non-invasive anemia screening module leveraging fingernail pallor\nanalysis. Trained on 250 patient cases (27\\% anemia prevalence) with\nKDE-balanced data, the Random Forest model achieved a test RMSE of 1.969 g/dL\nand MAE of 1.490 g/dL. A severity-based model reached 79.2\\% sensitivity. To\noptimize performance, a YOLOv8n-based nail bed detector was quantized to INT8,\nreducing inference latency from 46.96 ms to 21.50 ms while maintaining mAP@0.5\nat 0.995. The system emphasizes low-cost deployment, modularity, and data\nprivacy compliance (HIPAA/GDPR), addressing critical barriers to digital health\nadoption in disconnected settings. Our work demonstrates a scalable approach to\nenhance portable health information systems and support frontline healthcare in\nunderserved regions.", "published": "2025-07-20 22:46:42", "link": "http://arxiv.org/abs/2507.15146v1", "categories": ["cs.ET", "cs.AI", "cs.CV", "cs.CY", "cs.LG", "cs.SE"], "primary_category": "cs.ET"}
{"title": "Enhancing Visual Planning with Auxiliary Tasks and Multi-token Prediction", "abstract": "Visual Planning for Assistance (VPA) aims to predict a sequence of user\nactions required to achieve a specified goal based on a video showing the\nuser's progress. Although recent advances in multimodal large language models\n(MLLMs) have shown promising results in video understanding, long-horizon\nvisual planning remains a challenging problem. We identify two challenges in\ntraining large MLLMs for video-based planning tasks: (1) scarcity of procedural\nannotations, limiting the model's ability to learn procedural task dynamics\neffectively, and (2) inefficiency of next-token prediction objective to\nexplicitly capture the structured action space for visual planning when\ncompared to free-form, natural language. To tackle data scarcity, we introduce\nAuxiliary Task Augmentation. We design and train our model on auxiliary tasks\nrelevant to long-horizon video-based planning (e.g., goal prediction) to\naugment the model's planning ability. To more explicitly model the structured\naction space unique to visual planning tasks, we leverage Multi-token\nPrediction, extending traditional next-token prediction by using multiple heads\nto predict multiple future tokens during training. Our approach, VideoPlan,\nachieves state-of-the-art VPA performance on the COIN and CrossTask datasets,\nsurpassing prior methods by 7.3% and 3.4%, respectively, when predicting 3\nfuture actions. We further extend our method to the challenging Ego4D Long-term\nAction Anticipation task, and show that it is on par with the state-of-the-art\napproaches despite not using specialized egocentric features. Code will be made\navailable.", "published": "2025-07-20 21:39:05", "link": "http://arxiv.org/abs/2507.15130v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM", "abstract": "One of the main challenges in the Simultaneous Localization and Mapping\n(SLAM) loop closure problem is the recognition of previously visited places. In\nthis work, we tackle the two main problems of real-time SLAM systems: 1) loop\nclosure detection accuracy and 2) real-time computation constraints on the\nembedded hardware. Our LoopNet method is based on a multitasking variant of the\nclassical ResNet architecture, adapted for online retraining on a dynamic\nvisual dataset and optimized for embedded devices. The online retraining is\ndesigned using a few-shot learning approach. The architecture provides both an\nindex into the queried visual dataset, and a measurement of the prediction\nquality. Moreover, by leveraging DISK (DIStinctive Keypoints) descriptors,\nLoopNet surpasses the limitations of handcrafted features and traditional deep\nlearning methods, offering better performance under varying conditions. Code is\navailable at https://github.com/RovisLab/LoopNet. Additinally, we introduce a\nnew loop closure benchmarking dataset, coined LoopDB, which is available at\nhttps://github.com/RovisLab/LoopDB.", "published": "2025-07-20 20:11:37", "link": "http://arxiv.org/abs/2507.15109v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "BleedOrigin: Dynamic Bleeding Source Localization in Endoscopic Submucosal Dissection via Dual-Stage Detection and Tracking", "abstract": "Intraoperative bleeding during Endoscopic Submucosal Dissection (ESD) poses\nsignificant risks, demanding precise, real-time localization and continuous\nmonitoring of the bleeding source for effective hemostatic intervention. In\nparticular, endoscopists have to repeatedly flush to clear blood, allowing only\nmilliseconds to identify bleeding sources, an inefficient process that prolongs\noperations and elevates patient risks. However, current Artificial Intelligence\n(AI) methods primarily focus on bleeding region segmentation, overlooking the\ncritical need for accurate bleeding source detection and temporal tracking in\nthe challenging ESD environment, which is marked by frequent visual\nobstructions and dynamic scene changes. This gap is widened by the lack of\nspecialized datasets, hindering the development of robust AI-assisted guidance\nsystems. To address these challenges, we introduce BleedOrigin-Bench, the first\ncomprehensive ESD bleeding source dataset, featuring 1,771 expert-annotated\nbleeding sources across 106,222 frames from 44 procedures, supplemented with\n39,755 pseudo-labeled frames. This benchmark covers 8 anatomical sites and 6\nchallenging clinical scenarios. We also present BleedOrigin-Net, a novel\ndual-stage detection-tracking framework for the bleeding source localization in\nESD procedures, addressing the complete workflow from bleeding onset detection\nto continuous spatial tracking. We compare with widely-used object detection\nmodels (YOLOv11/v12), multimodal large language models, and point tracking\nmethods. Extensive evaluation demonstrates state-of-the-art performance,\nachieving 96.85% frame-level accuracy ($\\pm\\leq8$ frames) for bleeding onset\ndetection, 70.24% pixel-level accuracy ($\\leq100$ px) for initial source\ndetection, and 96.11% pixel-level accuracy ($\\leq100$ px) for point tracking.", "published": "2025-07-20 19:19:42", "link": "http://arxiv.org/abs/2507.15094v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Visual Place Recognition for Large-Scale UAV Applications", "abstract": "Visual Place Recognition (vPR) plays a crucial role in Unmanned Aerial\nVehicle (UAV) navigation, enabling robust localization across diverse\nenvironments. Despite significant advancements, aerial vPR faces unique\nchallenges due to the limited availability of large-scale, high-altitude\ndatasets, which limits model generalization, along with the inherent rotational\nambiguity in UAV imagery. To address these challenges, we introduce LASED, a\nlarge-scale aerial dataset with approximately one million images,\nsystematically sampled from 170,000 unique locations throughout Estonia over a\ndecade, offering extensive geographic and temporal diversity. Its structured\ndesign ensures clear place separation significantly enhancing model training\nfor aerial scenarios. Furthermore, we propose the integration of steerable\nConvolutional Neural Networks (CNNs) to explicitly handle rotational variance,\nleveraging their inherent rotational equivariance to produce robust,\norientation-invariant feature representations. Our extensive benchmarking\ndemonstrates that models trained on LASED achieve significantly higher recall\ncompared to those trained on smaller, less diverse datasets, highlighting the\nbenefits of extensive geographic coverage and temporal diversity. Moreover,\nsteerable CNNs effectively address rotational ambiguity inherent in aerial\nimagery, consistently outperforming conventional convolutional architectures,\nachieving on average 12\\% recall improvement over the best-performing\nnon-steerable network. By combining structured, large-scale datasets with\nrotation-equivariant neural networks, our approach significantly enhances model\nrobustness and generalization for aerial vPR.", "published": "2025-07-20 19:02:15", "link": "http://arxiv.org/abs/2507.15089v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Aesthetics is Cheap, Show me the Text: An Empirical Evaluation of State-of-the-Art Generative Models for OCR", "abstract": "Text image is a unique and crucial information medium that integrates visual\naesthetics and linguistic semantics in modern e-society. Due to their subtlety\nand complexity, the generation of text images represents a challenging and\nevolving frontier in the image generation field. The recent surge of\nspecialized image generators (\\emph{e.g.}, Flux-series) and unified generative\nmodels (\\emph{e.g.}, GPT-4o), which demonstrate exceptional fidelity, raises a\nnatural question: can they master the intricacies of text image generation and\nediting? Motivated by this, we assess current state-of-the-art generative\nmodels' capabilities in terms of text image generation and editing. We\nincorporate various typical optical character recognition (OCR) tasks into our\nevaluation and broaden the concept of text-based generation tasks into OCR\ngenerative tasks. We select 33 representative tasks and categorize them into\nfive categories: document, handwritten text, scene text, artistic text, and\ncomplex \\& layout-rich text. For comprehensive evaluation, we examine six\nmodels across both closed-source and open-source domains, using tailored,\nhigh-quality image inputs and prompts. Through this evaluation, we draw crucial\nobservations and identify the weaknesses of current generative models for OCR\ntasks. We argue that photorealistic text image generation and editing should be\ninternalized as foundational skills into general-domain generative models,\nrather than being delegated to specialized solutions, and we hope this\nempirical analysis can provide valuable insights for the community to achieve\nthis goal. This evaluation is online and will be continuously updated at our\nGitHub repository.", "published": "2025-07-20 18:43:09", "link": "http://arxiv.org/abs/2507.15085v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PET Image Reconstruction Using Deep Diffusion Image Prior", "abstract": "Diffusion models have shown great promise in medical image denoising and\nreconstruction, but their application to Positron Emission Tomography (PET)\nimaging remains limited by tracer-specific contrast variability and high\ncomputational demands. In this work, we proposed an anatomical prior-guided PET\nimage reconstruction method based on diffusion models, inspired by the deep\ndiffusion image prior (DDIP) framework. The proposed method alternated between\ndiffusion sampling and model fine-tuning guided by the PET sinogram, enabling\nthe reconstruction of high-quality images from various PET tracers using a\nscore function pretrained on a dataset of another tracer. To improve\ncomputational efficiency, the half-quadratic splitting (HQS) algorithm was\nadopted to decouple network optimization from iterative PET reconstruction. The\nproposed method was evaluated using one simulation and two clinical datasets.\nFor the simulation study, a model pretrained on [$^{18}$F]FDG data was tested\non amyloid-negative PET data to assess out-of-distribution (OOD) performance.\nFor the clinical-data validation, ten low-dose [$^{18}$F]FDG datasets and one\n[$^{18}$F]Florbetapir dataset were tested on a model pretrained on data from\nanother tracer. Experiment results show that the proposed PET reconstruction\nmethod can generalize robustly across tracer distributions and scanner types,\nproviding an efficient and versatile reconstruction framework for low-dose PET\nimaging.", "published": "2025-07-20 18:25:29", "link": "http://arxiv.org/abs/2507.15078v1", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "primary_category": "eess.IV"}
{"title": "StableAnimator++: Overcoming Pose Misalignment and Face Distortion for Human Image Animation", "abstract": "Current diffusion models for human image animation often struggle to maintain\nidentity (ID) consistency, especially when the reference image and driving\nvideo differ significantly in body size or position. We introduce\nStableAnimator++, the first ID-preserving video diffusion framework with\nlearnable pose alignment, capable of generating high-quality videos conditioned\non a reference image and a pose sequence without any post-processing. Building\nupon a video diffusion model, StableAnimator++ contains carefully designed\nmodules for both training and inference, striving for identity consistency. In\nparticular, StableAnimator++ first uses learnable layers to predict the\nsimilarity transformation matrices between the reference image and the driven\nposes via injecting guidance from Singular Value Decomposition (SVD). These\nmatrices align the driven poses with the reference image, mitigating\nmisalignment to a great extent. StableAnimator++ then computes image and face\nembeddings using off-the-shelf encoders, refining the face embeddings via a\nglobal content-aware Face Encoder. To further maintain ID, we introduce a\ndistribution-aware ID Adapter that counteracts interference caused by temporal\nlayers while preserving ID via distribution alignment. During the inference\nstage, we propose a novel Hamilton-Jacobi-Bellman (HJB) based face optimization\nintegrated into the denoising process, guiding the diffusion trajectory for\nenhanced facial fidelity. Experiments on benchmarks show the effectiveness of\nStableAnimator++ both qualitatively and quantitatively.", "published": "2025-07-20 17:59:26", "link": "http://arxiv.org/abs/2507.15064v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Rethinking Pan-sharpening: Principled Design, Unified Training, and a Universal Loss Surpass Brute-Force Scaling", "abstract": "The field of pan-sharpening has recently seen a trend towards increasingly\nlarge and complex models, often trained on single, specific satellite datasets.\nThis approach, however, leads to high computational overhead and poor\ngeneralization on full resolution data, a paradigm we challenge in this paper.\nIn response to this issue, we propose PanTiny, a lightweight, single-step\npan-sharpening framework designed for both efficiency and robust performance.\nMore critically, we introduce multiple-in-one training paradigm, where a\nsingle, compact model is trained simultaneously on three distinct satellite\ndatasets (WV2, WV3, and GF2) with different resolution and spectral\ninformation. Our experiments show that this unified training strategy not only\nsimplifies deployment but also significantly boosts generalization on\nfull-resolution data. Further, we introduce a universally powerful composite\nloss function that elevates the performance of almost all of models for\npan-sharpening, pushing state-of-the-art metrics into a new era. Our PanTiny\nmodel, benefiting from these innovations, achieves a superior\nperformance-to-efficiency balance, outperforming most larger, specialized\nmodels. Through extensive ablation studies, we validate that principled\nengineering in model design, training paradigms, and loss functions can surpass\nbrute-force scaling. Our work advocates for a community-wide shift towards\ncreating efficient, generalizable, and data-conscious models for\npan-sharpening. The code is available at\nhttps://github.com/Zirconium233/PanTiny .", "published": "2025-07-20 17:50:49", "link": "http://arxiv.org/abs/2507.15059v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OmniVTON: Training-Free Universal Virtual Try-On", "abstract": "Image-based Virtual Try-On (VTON) techniques rely on either supervised\nin-shop approaches, which ensure high fidelity but struggle with cross-domain\ngeneralization, or unsupervised in-the-wild methods, which improve adaptability\nbut remain constrained by data biases and limited universality. A unified,\ntraining-free solution that works across both scenarios remains an open\nchallenge. We propose OmniVTON, the first training-free universal VTON\nframework that decouples garment and pose conditioning to achieve both texture\nfidelity and pose consistency across diverse settings. To preserve garment\ndetails, we introduce a garment prior generation mechanism that aligns clothing\nwith the body, followed by continuous boundary stitching technique to achieve\nfine-grained texture retention. For precise pose alignment, we utilize DDIM\ninversion to capture structural cues while suppressing texture interference,\nensuring accurate body alignment independent of the original image textures. By\ndisentangling garment and pose constraints, OmniVTON eliminates the bias\ninherent in diffusion models when handling multiple conditions simultaneously.\nExperimental results demonstrate that OmniVTON achieves superior performance\nacross diverse datasets, garment types, and application scenarios. Notably, it\nis the first framework capable of multi-human VTON, enabling realistic garment\ntransfer across multiple individuals in a single scene. Code is available at\nhttps://github.com/Jerome-Young/OmniVTON", "published": "2025-07-20 16:37:53", "link": "http://arxiv.org/abs/2507.15037v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EBA-AI: Ethics-Guided Bias-Aware AI for Efficient Underwater Image Enhancement and Coral Reef Monitoring", "abstract": "Underwater image enhancement is vital for marine conservation, particularly\ncoral reef monitoring. However, AI-based enhancement models often face dataset\nbias, high computational costs, and lack of transparency, leading to potential\nmisinterpretations. This paper introduces EBA-AI, an ethics-guided bias-aware\nAI framework to address these challenges. EBA-AI leverages CLIP embeddings to\ndetect and mitigate dataset bias, ensuring balanced representation across\nvaried underwater environments. It also integrates adaptive processing to\noptimize energy efficiency, significantly reducing GPU usage while maintaining\ncompetitive enhancement quality. Experiments on LSUI400, Oceanex, and UIEB100\nshow that while PSNR drops by a controlled 1.0 dB, computational savings enable\nreal-time feasibility for large-scale marine monitoring. Additionally,\nuncertainty estimation and explainability techniques enhance trust in AI-driven\nenvironmental decisions. Comparisons with CycleGAN, FunIEGAN, RAUNENet,\nWaterNet, UGAN, PUGAN, and UTUIE validate EBA-AI's effectiveness in balancing\nefficiency, fairness, and interpretability in underwater image processing. By\naddressing key limitations of AI-driven enhancement, this work contributes to\nsustainable, bias-aware, and computationally efficient marine conservation\nefforts. For interactive visualizations, animations, source code, and access to\nthe preprint, visit: https://lyessaadsaoud.github.io/EBA-AI/", "published": "2025-07-20 16:37:37", "link": "http://arxiv.org/abs/2507.15036v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "OpenBreastUS: Benchmarking Neural Operators for Wave Imaging Using Breast Ultrasound Computed Tomography", "abstract": "Accurate and efficient simulation of wave equations is crucial in\ncomputational wave imaging applications, such as ultrasound computed tomography\n(USCT), which reconstructs tissue material properties from observed scattered\nwaves. Traditional numerical solvers for wave equations are computationally\nintensive and often unstable, limiting their practical applications for\nquasi-real-time image reconstruction. Neural operators offer an innovative\napproach by accelerating PDE solving using neural networks; however, their\neffectiveness in realistic imaging is limited because existing datasets\noversimplify real-world complexity. In this paper, we present OpenBreastUS, a\nlarge-scale wave equation dataset designed to bridge the gap between\ntheoretical equations and practical imaging applications. OpenBreastUS includes\n8,000 anatomically realistic human breast phantoms and over 16 million\nfrequency-domain wave simulations using real USCT configurations. It enables a\ncomprehensive benchmarking of popular neural operators for both forward\nsimulation and inverse imaging tasks, allowing analysis of their performance,\nscalability, and generalization capabilities. By offering a realistic and\nextensive dataset, OpenBreastUS not only serves as a platform for developing\ninnovative neural PDE solvers but also facilitates their deployment in\nreal-world medical imaging problems. For the first time, we demonstrate\nefficient in vivo imaging of the human breast using neural operator solvers.", "published": "2025-07-20 16:36:24", "link": "http://arxiv.org/abs/2507.15035v1", "categories": ["cs.CV", "cs.LG", "35Q92, 68U10", "I.4.5; J.2; J.3"], "primary_category": "cs.CV"}
{"title": "Towards Video Thinking Test: A Holistic Benchmark for Advanced Video Reasoning and Understanding", "abstract": "Human intelligence requires correctness and robustness, with the former being\nfoundational for the latter. In video understanding, correctness ensures the\naccurate interpretation of visual content, and robustness maintains consistent\nperformance in challenging conditions. Despite advances in video large language\nmodels (video LLMs), existing benchmarks inadequately reflect the gap between\nthese models and human intelligence in maintaining correctness and robustness\nin video interpretation. We introduce the Video Thinking Test (Video-TT), to\nassess if video LLMs can interpret real-world videos as effectively as humans.\nVideo-TT reflects genuine gaps in understanding complex visual narratives, and\nevaluates robustness against natural adversarial questions. Video-TT comprises\n1,000 YouTube Shorts videos, each with one open-ended question and four\nadversarial questions that probe visual and narrative complexity. Our\nevaluation shows a significant gap between video LLMs and human performance.", "published": "2025-07-20 16:30:33", "link": "http://arxiv.org/abs/2507.15028v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FastSmoothSAM: A Fast Smooth Method For Segment Anything Model", "abstract": "Accurately identifying and representing object edges is a challenging task in\ncomputer vision and image processing. The Segment Anything Model (SAM) has\nsignificantly influenced the field of image segmentation, but suffers from high\nmemory consumption and long inference times, limiting its efficiency in\nreal-time applications. To address these limitations, Fast Segment Anything\n(FastSAM) was proposed, achieving real-time segmentation. However, FastSAM\noften generates jagged edges that deviate from the true object shapes.\nTherefore, this paper introduces a novel refinement approach using B-Spline\ncurve fitting techniques to enhance the edge quality in FastSAM. Leveraging the\nrobust shape control and flexible geometric construction of B-Splines, a\nfour-stage refining process involving two rounds of curve fitting is employed\nto effectively smooth jagged edges. This approach significantly improves the\nvisual quality and analytical accuracy of object edges without compromising\ncritical geometric information. The proposed method improves the practical\nutility of FastSAM by improving segmentation accuracy while maintaining\nreal-time processing capabilities. This advancement unlocks greater potential\nfor FastSAM technology in various real-world scenarios, such as industrial\nautomation, medical imaging, and autonomous systems, where precise and\nefficient edge recognition is crucial.", "published": "2025-07-20 15:35:16", "link": "http://arxiv.org/abs/2507.15008v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Axis-Aligned Document Dewarping", "abstract": "Document dewarping is crucial for many applications. However, existing\nlearning-based methods primarily rely on supervised regression with annotated\ndata without leveraging the inherent geometric properties in physical documents\nto the dewarping process. Our key insight is that a well-dewarped document is\ncharacterized by transforming distorted feature lines into axis-aligned ones.\nThis property aligns with the inherent axis-aligned nature of the discrete grid\ngeometry in planar documents. In the training phase, we propose an axis-aligned\ngeometric constraint to enhance document dewarping. In the inference phase, we\npropose an axis alignment preprocessing strategy to reduce the dewarping\ndifficulty. In the evaluation phase, we introduce a new metric, Axis-Aligned\nDistortion (AAD), that not only incorporates geometric meaning and aligns with\nhuman visual perception but also demonstrates greater robustness. As a result,\nour method achieves SOTA results on multiple existing benchmarks and achieves\n18.2%~34.5% improvements on the AAD metric.", "published": "2025-07-20 15:12:57", "link": "http://arxiv.org/abs/2507.15000v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Language Integration in Fine-Tuning Multimodal Large Language Models for Image-Based Regression", "abstract": "Multimodal Large Language Models (MLLMs) show promise for image-based\nregression tasks, but current approaches face key limitations. Recent methods\nfine-tune MLLMs using preset output vocabularies and generic task-level prompts\n(e.g., \"How would you rate this image?\"), assuming this mimics human rating\nbehavior. Our analysis reveals these approaches provide no benefit over\nimage-only training. Models using preset vocabularies and generic prompts\nperform equivalently to image-only models, failing to leverage semantic\nunderstanding from textual input. We propose Regression via Transformer-Based\nClassification (RvTC), which replaces vocabulary-constrained classification\nwith a flexible bin-based approach. Unlike approaches that address\ndiscretization errors through complex distributional modeling, RvTC eliminates\nmanual vocabulary crafting through straightforward bin increase, achieving\nstate-of-the-art performance on four image assessment datasets using only\nimages. More importantly, we demonstrate that data-specific prompts\ndramatically improve performance. Unlike generic task descriptions, prompts\ncontaining semantic information about specific images enable MLLMs to leverage\ncross-modal understanding. On the AVA dataset, adding challenge titles to\nprompts improves correlations from 0.83 to 0.90, a new state-of-the-art. We\ndemonstrate through empirical evidence from the AVA and AGIQA-3k datasets that\nMLLMs benefit from semantic prompt information surpassing mere statistical\nbiases. This underscores the importance of incorporating meaningful textual\ncontext in multimodal regression tasks.", "published": "2025-07-20 15:05:24", "link": "http://arxiv.org/abs/2507.14997v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Hierarchical Cross-modal Prompt Learning for Vision-Language Models", "abstract": "Pre-trained Vision-Language Models (VLMs) such as CLIP have shown excellent\ngeneralization abilities. However, adapting these large-scale models to\ndownstream tasks while preserving their generalization capabilities remains\nchallenging. Although prompt learning methods have shown promise, they suffer\nfrom two fundamental bottlenecks that limit generalization: (a) modality\nisolation, and (b) hierarchical semantic decay. To address these limitations,\nwe propose HiCroPL, a Hierarchical Cross-modal Prompt Learning framework that\nestablishes bidirectional knowledge flow between text and vision modalities,\nenabling them to refine their semantics mutually. HiCroPL routes knowledge\nflows by leveraging the complementary strengths of text and vision. In early\nlayers, text prompts inject relatively clear semantics into visual prompts\nthrough a hierarchical knowledge mapper, enhancing the representation of\nlow-level visual semantics. In later layers, visual prompts encoding specific\ntask-relevant objects flow back to refine text prompts, enabling deeper\nalignment. Crucially, our hierarchical knowledge mapper allows representations\nat multi-scales to be fused, ensuring that deeper representations retain\ntransferable shallow semantics thereby enhancing generalization. We further\nintroduce a lightweight layer-specific knowledge proxy to enable efficient\ncross-modal interactions. Extensive evaluations across four tasks demonstrate\nHiCroPL's superior performance, achieving state-of-the-art results on 11\nbenchmarks with significant improvements. Code is available at:\nhttps://github.com/zzeoZheng/HiCroPL.", "published": "2025-07-20 14:18:04", "link": "http://arxiv.org/abs/2507.14976v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Decision PCR: Decision version of the Point Cloud Registration task", "abstract": "Low-overlap point cloud registration (PCR) remains a significant challenge in\n3D vision. Traditional evaluation metrics, such as Maximum Inlier Count, become\nineffective under extremely low inlier ratios. In this paper, we revisit the\nregistration result evaluation problem and identify the Decision version of the\nPCR task as the fundamental problem. To address this Decision PCR task, we\npropose a data-driven approach. First, we construct a corresponding dataset\nbased on the 3DMatch dataset. Then, a deep learning-based classifier is trained\nto reliably assess registration quality, overcoming the limitations of\ntraditional metrics. To our knowledge, this is the first comprehensive study to\naddress this task through a deep learning framework. We incorporate this\nclassifier into standard PCR pipelines. When integrated with our approach,\nexisting state-of-the-art PCR methods exhibit significantly enhanced\nregistration performance. For example, combining our framework with\nGeoTransformer achieves a new SOTA registration recall of 86.97\\% on the\nchallenging 3DLoMatch benchmark. Our method also demonstrates strong\ngeneralization capabilities on the unseen outdoor ETH dataset.", "published": "2025-07-20 13:51:42", "link": "http://arxiv.org/abs/2507.14965v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Polymorph: Energy-Efficient Multi-Label Classification for Video Streams on Embedded Devices", "abstract": "Real-time multi-label video classification on embedded devices is constrained\nby limited compute and energy budgets. Yet, video streams exhibit structural\nproperties such as label sparsity, temporal continuity, and label co-occurrence\nthat can be leveraged for more efficient inference. We introduce Polymorph, a\ncontext-aware framework that activates a minimal set of lightweight Low Rank\nAdapters (LoRA) per frame. Each adapter specializes in a subset of classes\nderived from co-occurrence patterns and is implemented as a LoRA weight over a\nshared backbone. At runtime, Polymorph dynamically selects and composes only\nthe adapters needed to cover the active labels, avoiding full-model switching\nand weight merging. This modular strategy improves scalability while reducing\nlatency and energy overhead. Polymorph achieves 40% lower energy consumption\nand improves mAP by 9 points over strong baselines on the TAO dataset.\nPolymorph is open source at https://github.com/inference-serving/polymorph/.", "published": "2025-07-20 13:39:50", "link": "http://arxiv.org/abs/2507.14959v1", "categories": ["cs.CV", "cs.PF"], "primary_category": "cs.CV"}
{"title": "Open-set Cross Modal Generalization via Multimodal Unified Representation", "abstract": "This paper extends Cross Modal Generalization (CMG) to open-set environments\nby proposing the more challenging Open-set Cross Modal Generalization (OSCMG)\ntask. This task evaluates multimodal unified representations in open-set\nconditions, addressing the limitations of prior closed-set cross-modal\nevaluations. OSCMG requires not only cross-modal knowledge transfer but also\nrobust generalization to unseen classes within new modalities, a scenario\nfrequently encountered in real-world applications. Existing multimodal unified\nrepresentation work lacks consideration for open-set environments. To tackle\nthis, we propose MICU, comprising two key components: Fine-Coarse Masked\nmultimodal InfoNCE (FCMI) and Cross modal Unified Jigsaw Puzzles (CUJP). FCMI\nenhances multimodal alignment by applying contrastive learning at both holistic\nsemantic and temporal levels, incorporating masking to enhance generalization.\nCUJP enhances feature diversity and model uncertainty by integrating\nmodality-agnostic feature selection with self-supervised learning, thereby\nstrengthening the model's ability to handle unknown categories in open-set\ntasks. Extensive experiments on CMG and the newly proposed OSCMG validate the\neffectiveness of our approach. The code is available at\nhttps://github.com/haihuangcode/CMG.", "published": "2025-07-20 12:09:19", "link": "http://arxiv.org/abs/2507.14935v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Probabilistic smooth attention for deep multiple instance learning in medical imaging", "abstract": "The Multiple Instance Learning (MIL) paradigm is attracting plenty of\nattention in medical imaging classification, where labeled data is scarce. MIL\nmethods cast medical images as bags of instances (e.g. patches in whole slide\nimages, or slices in CT scans), and only bag labels are required for training.\nDeep MIL approaches have obtained promising results by aggregating\ninstance-level representations via an attention mechanism to compute the\nbag-level prediction. These methods typically capture both local interactions\namong adjacent instances and global, long-range dependencies through various\nmechanisms. However, they treat attention values deterministically, potentially\noverlooking uncertainty in the contribution of individual instances. In this\nwork we propose a novel probabilistic framework that estimates a probability\ndistribution over the attention values, and accounts for both global and local\ninteractions. In a comprehensive evaluation involving {\\color{review} eleven}\nstate-of-the-art baselines and three medical datasets, we show that our\napproach achieves top predictive performance in different metrics. Moreover,\nthe probabilistic treatment of the attention provides uncertainty maps that are\ninterpretable in terms of illness localization.", "published": "2025-07-20 11:58:17", "link": "http://arxiv.org/abs/2507.14932v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Click A, Buy B: Rethinking Conversion Attribution in E- Commerce Recommendations", "abstract": "User journeys in e-commerce routinely violate the one-to-one assumption that\na clicked item on an advertising platform is the same item later purchased on\nthe merchant's website/app. For a significant number of converting sessions on\nour platform, users click product A but buy product B -- the Click A, Buy B\n(CABB) phenomenon. Training recommendation models on raw click-conversion pairs\ntherefore rewards items that merely correlate with purchases, leading to biased\nlearning and sub-optimal conversion rates. We reframe conversion prediction as\na multi-task problem with separate heads for Click A Buy A (CABA) and Click A\nBuy B (CABB). To isolate informative CABB conversions from unrelated CABB\nconversions, we introduce a taxonomy-aware collaborative filtering weighting\nscheme where each product is first mapped to a leaf node in a product taxonomy,\nand a category-to-category similarity matrix is learned from large-scale\nco-engagement logs. This weighting amplifies pairs that reflect genuine\nsubstitutable or complementary relations while down-weighting coincidental\ncross-category purchases. Offline evaluation on e-commerce sessions reduces\nnormalized entropy by 13.9% versus a last-click attribution baseline. An online\nA/B test on live traffic shows +0.25% gains in the primary business metric.", "published": "2025-07-20 20:25:20", "link": "http://arxiv.org/abs/2507.15113v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection", "abstract": "Adversarial prompt attacks can significantly alter the reliability of\nRetrieval-Augmented Generation (RAG) systems by re-ranking them to produce\nincorrect outputs. In this paper, we present a novel method that applies\nDifferential Evolution (DE) to optimize adversarial prompt suffixes for\nRAG-based question answering. Our approach is gradient-free, treating the RAG\npipeline as a black box and evolving a population of candidate suffixes to\nmaximize the retrieval rank of a targeted incorrect document to be closer to\nreal world scenarios. We conducted experiments on the BEIR QA datasets to\nevaluate attack success at certain retrieval rank thresholds under multiple\nretrieving applications. Our results demonstrate that DE-based prompt\noptimization attains competitive (and in some cases higher) success rates\ncompared to GGPP to dense retrievers and PRADA to sparse retrievers, while\nusing only a small number of tokens (<=5 tokens) in the adversarial suffix.\nFurthermore, we introduce a readability-aware suffix construction strategy,\nvalidated by a statistically significant reduction in MLM negative\nlog-likelihood with Welch's t-test. Through evaluations with a BERT-based\nadversarial suffix detector, we show that DE-generated suffixes evade\ndetection, yielding near-chance detection accuracy.", "published": "2025-07-20 16:48:20", "link": "http://arxiv.org/abs/2507.15042v1", "categories": ["cs.AI", "cs.IR", "I.2.7; H.3.3; K.6.5"], "primary_category": "cs.AI"}
{"title": "FullRecall: A Semantic Search-Based Ranking Approach for Maximizing Recall in Patent Retrieval", "abstract": "Patent examiners and inventors face significant pressure to verify the\noriginality and non-obviousness of inventions, and the intricate nature of\npatent data intensifies the challenges of patent retrieval. Therefore, there is\na pressing need to devise cutting-edge retrieval strategies that can reliably\nachieve the desired recall. This study introduces FullRecall, a novel patent\nretrieval approach that effectively manages the complexity of patent data while\nmaintaining the reliability of relevance matching and maximising recall. It\nleverages IPC-guided knowledge to generate informative phrases, which are\nprocessed to extract key information in the form of noun phrases characterising\nthe query patent under observation. From these, the top k keyphrases are\nselected to construct a query for retrieving a focused subset of the dataset.\nThis initial retrieval step achieves complete recall, successfully capturing\nall relevant documents. To further refine the results, a ranking scheme is\napplied to the retrieved subset, reducing its size while maintaining 100%\nrecall. This multi-phase process demonstrates an effective strategy for\nbalancing precision and recall in patent retrieval tasks. Comprehensive\nexperiments were conducted, and the results were compared with baseline\nstudies, namely HRR2 [1] and ReQ-ReC [2]. The proposed approach yielded\nsuperior results, achieving 100% recall in all five test cases. However,\nHRR2[1] recall values across the five test cases were 10%, 25%, 33.3%, 0%, and\n14.29%, while ReQ-ReC [2] showed 50% for the first test case, 25% for the\nsecond test case, and 0% for the third, fourth, and fifth test cases. The 100%\nrecall ensures that no relevant prior art is overlooked, thereby strengthening\nthe patent pre-filing and examination processes, hence reducing potential legal\nrisks.", "published": "2025-07-20 12:52:58", "link": "http://arxiv.org/abs/2507.14946v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "User Invariant Preference Learning for Multi-Behavior Recommendation", "abstract": "In multi-behavior recommendation scenarios, analyzing users' diverse\nbehaviors, such as click, purchase, and rating, enables a more comprehensive\nunderstanding of their interests, facilitating personalized and accurate\nrecommendations. A fundamental assumption of multi-behavior recommendation\nmethods is the existence of shared user preferences across behaviors,\nrepresenting users' intrinsic interests. Based on this assumption, existing\napproaches aim to integrate information from various behaviors to enrich user\nrepresentations. However, they often overlook the presence of both\ncommonalities and individualities in users' multi-behavior preferences. These\nindividualities reflect distinct aspects of preferences captured by different\nbehaviors, where certain auxiliary behaviors may introduce noise, hindering the\nprediction of the target behavior. To address this issue, we propose a user\ninvariant preference learning for multi-behavior recommendation (UIPL for\nshort), aiming to capture users' intrinsic interests (referred to as invariant\npreferences) from multi-behavior interactions to mitigate the introduction of\nnoise. Specifically, UIPL leverages the paradigm of invariant risk minimization\nto learn invariant preferences. To implement this, we employ a variational\nautoencoder (VAE) to extract users' invariant preferences, replacing the\nstandard reconstruction loss with an invariant risk minimization constraint.\nAdditionally, we construct distinct environments by combining multi-behavior\ndata to enhance robustness in learning these preferences. Finally, the learned\ninvariant preferences are used to provide recommendations for the target\nbehavior. Extensive experiments on four real-world datasets demonstrate that\nUIPL significantly outperforms current state-of-the-art methods.", "published": "2025-07-20 11:47:36", "link": "http://arxiv.org/abs/2507.14925v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "U-MARVEL: Unveiling Key Factors for Universal Multimodal Retrieval via Embedding Learning with MLLMs", "abstract": "Universal multimodal retrieval (UMR), which aims to address complex retrieval\ntasks where both queries and candidates span diverse modalities, has been\nsignificantly advanced by the emergence of MLLMs. While state-of-the-art\nMLLM-based methods in the literature predominantly adopt contrastive learning\nprinciples, they often differ in their specific training recipes. Despite their\nsuccess, the mechanisms underlying their retrieval capabilities remain largely\nunexplored, potentially resulting in suboptimal performance and limited\ngeneralization ability. To address these issues, we present a comprehensive\nstudy aimed at uncovering the key factors that drive effective embedding\nlearning for UMR using MLLMs. We begin by implementing a general MLLM-based\nembedding learning pipeline, and systematically analyze the primary\ncontributors to high-performing universal retrieval systems. Based on this, we\nexplore various aspects of the details in embedding generation and training\nstrategies, including progressive transition, hard negative mining and\nre-ranker distillation. Notably, our findings reveal that often-overlooked\nfactors can have a substantial impact on model performance. Building on these\ndiscoveries, we introduce a unified framework termed U-MARVEL\n(\\textbf{U}niversal \\textbf{M}ultimod\\textbf{A}l \\textbf{R}etrie\\textbf{V}al\nvia \\textbf{E}mbedding \\textbf{L}earning), which outperforms state-of-the-art\ncompetitors on the M-BEIR benchmark by a large margin in supervised settings,\nand also exihibits strong zero-shot performance on several tasks such as\ncomposed image retrieval and text-to-video retrieval. These results underscore\nthe generalization potential of our framework across various embedding-based\nretrieval tasks. Code is available at https://github.com/chaxjli/U-MARVEL", "published": "2025-07-20 10:27:34", "link": "http://arxiv.org/abs/2507.14902v1", "categories": ["cs.IR", "cs.CV"], "primary_category": "cs.IR"}
{"title": "PAPR Analysis for MIMO FTN Signaling with Gaussian Symbols", "abstract": "Faster-than-Nyquist signaling serves as a promising solution for improving\nspectral efficiency in future generations of communications. However, its\nnature of fast acceleration brings highly overlapped pulses that lead to worse\npeak-to-average power ratio (PAPR) performance. In this paper, we investigate\nthe PAPR behavior of MIMO FTN using Gaussian symbols under optimal power\nallocation for two power constraints: fixed transmit power and fixed received\nsignal-to-noise-ratio (SNR). Our findings reveal that PAPR is mainly determined\nby the acceleration factor and the power constraint, but power allocation\noptimization does not change the PAPR behavior for Gaussian signaling.", "published": "2025-07-20 20:31:20", "link": "http://arxiv.org/abs/2507.15116v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Noise Quantification and Control in Circuits via Strong Data-Processing Inequalities", "abstract": "This essay explores strong data-processing inequalities (SPDI's) as they\nappear in the work of Evans and Schulman \\cite{ES} and von Neumann \\cite{vN} on\ncomputing with noisy circuits. We first develop the framework in \\cite{ES},\nwhich leads to lower bounds on depth and upper bounds on noise that permit\nreliable computation. We then introduce the $3$-majority gate, introduced by\n\\cite{vN} for the purpose of controlling noise, and obtain an upper bound on\nnoise necessary for its function. We end by generalizing von Neumann's analysis\nto majority gates of any order, proving an analogous noise threshold and giving\na sufficient upper bound for order given a desired level of reliability.\n  The presentation of material has been modified in a way deemed more natural\nby the author, occasionally leading to simplifications of existing proofs.\nFurthermore, many computations omitted from the original works have been worked\nout, and some new commentary added. The intended audience has a rudimentary\nunderstanding of information theory similar to that of the author.", "published": "2025-07-20 20:07:12", "link": "http://arxiv.org/abs/2507.15108v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Reconfigurable Antenna Arrays With Tunable Loads: Expanding Solution Space via Coupling Control", "abstract": "The emerging reconfigurable antenna (RA) array technology promises capacity\nenhancement through dynamic antenna positioning. Traditional approaches enforce\nhalf-wavelength or greater spacing among RA elements to avoid mutual coupling,\nlimiting the solution space. Additionally, achieving sufficient spatial channel\nsampling requires numerous discrete RA positions (ports), while high-frequency\nscenarios with hybrid processing demand many physical RAs to maintain array\ngains. This leads to exponential growth in the solution space. We propose two\ntechniques to address the former challenge: (1) surrounding a limited number of\nactive RAs with passive ones terminated to tunable analog loads to\n\\textit{exploit} mutual coupling and increase array gain, and (2) employing\ntunable loads on each RA in an all-active design to \\textit{eliminate} mutual\ncoupling in the analog domain. Both methods enable arbitrary RA spacing,\nunlocking the full solution space. Regarding the latter challenge, we develop\ngreedy and meta-heuristic port selection algorithms, alongside low-complexity\nheuristic variants, that efficiently handle over $10^{20}$ array\nconfigurations, and optimize the loading values to maximize the sum-rate in a\nmultiple-input single-output broadcast channel under transmission power\nconstraints, assuming a heuristic linear precoder. Furthermore, we analyze\nperformance degradation from quantized loads and propose corresponding robust\ndesigns. Numerical simulations reveal significant performance gains over\nbenchmarks and provide valuable insights.", "published": "2025-07-20 18:17:54", "link": "http://arxiv.org/abs/2507.15074v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Transversal non-Clifford gates on qLDPC codes breaking the $\\sqrt{N}$ distance barrier and quantum-inspired geometry with $\\mathbb{Z}_2$ systolic freedom", "abstract": "Historically, a $\\sqrt{N}log^{1/2}(N)$ distance barrier for quantum\nlow-density parity-check (LDPC) codes with $N$ qubits persisted for nearly two\ndecades, until the recent discovery of the fibre-bundle code. An open question\nis whether such a distance barrier can be broken while preserving the ability\nto perform transversal non-Clifford gates. In this direction, another\nlong-standing distance barrier of $N^{1/3}$ for LDPC stabilizer codes --\npresent since the discovery of the 3D color code -- was only recently overcome\nby a construction achieving an $\\Omega(\\sqrt{N})$ distance (arXiv:2501.19375).\nThe present work further breaks the $\\sqrt{N}$ distance barrier by taking a\nhomological product of three good qLDPC codes, combined with the\nFreedman-Hastings code-to-manifold mapping and the triple cup product to\nimplement transversal CCZ gates. The resulting code achieves an\n$\\Omega(N^{2/3})$ distance (a linear $X$-distance of $\\Theta(N)$) and a\ndimension of $\\Theta(N^{2/3})$, which enables fault-tolerant preparation of\n$\\Theta(N^{1/3})$ independent logical CCZ magic states in a single shot,\nwithout distillation (`magic state fountain'). This new quantum code also\ninspires the discovery of a family of exotic $3q$-dimensional manifolds\n$\\mathcal{M}$, which exhibit both a power-law $\\mathbb{Z}_2$-($q$,\n$2q$)-systolic freedom and $\\Theta(vol(\\mathcal{M}))$ triple intersection\npoints of $2q$-dimensional submanifolds.", "published": "2025-07-20 17:35:31", "link": "http://arxiv.org/abs/2507.15056v1", "categories": ["quant-ph", "cond-mat.str-el", "cs.IT", "hep-th", "math.GT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Variable Min-Cut Max-Flow Bounds and Algorithms in Finite Regime", "abstract": "The maximum achievable capacity from source to destination in a network is\nlimited by the min-cut max-flow bound; this serves as a converse limit. In\npractice, link capacities often fluctuate due to dynamic network conditions. In\nthis work, we introduce a novel analytical framework that leverages tools from\ncomputational geometry to analyze throughput in heterogeneous networks with\nvariable link capacities in a finite regime. Within this model, we derive new\nperformance bounds and demonstrate that increasing the number of links can\nreduce throughput variability by nearly $90\\%$. We formally define a notion of\nnetwork stability and show that an unstable graph can have an exponential\nnumber of different min-cut sets, up to $O(2^{|E|})$. To address this\ncomplexity, we propose an algorithm that enforces stability with time\ncomplexity $O(|E|^2 + |V|)$, and further suggest mitigating the\ndelay-throughput tradeoff using adaptive rateless random linear network coding\n(AR-RLNC).", "published": "2025-07-20 07:46:37", "link": "http://arxiv.org/abs/2507.14852v1", "categories": ["cs.IT", "cs.CG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Pinching-Antenna-based Communications: Spectral Efficiency Analysis and Deployment Strategies", "abstract": "A multiple-waveguide pinching-antenna (PA)-based multi-user communication\nsystem is investigated. With a given number of PAs, two deployment strategies\nare considered, namely the centralized PA deployment, where all PAs are\nswitched between waveguides to serve users in a time-division manner to avail\nof beamforming gain, and the distributed PA deployment, where a single PA is\ndeployed on each waveguide to simultaneously serve multiple users by leveraging\nthe multiplexing gain. The spectral efficiency (SE) achieved by each deployment\nstrategy is analyzed: i) For the centralized deployment, the positioning\nstrategy of PAs on each waveguide is determined first with the aim of\nmaximizing the channel gain of the corresponding nearest served user. Based on\nthis, the corresponding system SE is derived. ii) For the distributed\ndeployment, the system SE under the maximum ratio transmission (MRT) is first\nobtained. To obtain an analytically tractable form, the stationary phase method\nis utilized to approximate the system SE. The approximation result reveals that\nthe average inter-user interference can be negligible with a large waveguide\nspacing and thus the simple MRT is appealing for PA-based multi-user\ncommunications. Furthermore, the system SEs achieved by the two strategies are\ncompared in both the high and low signal-to-noise ratio (SNR) regimes. Our\nanalysis suggests that at high SNRs, the distributed deployment is superior to\nachieve the maximal system SE, while the centralized deployment is more\nsuitable for the low-SNR regime. Finally, the theoretical analysis is verified\nthrough simulations.", "published": "2025-07-20 06:00:00", "link": "http://arxiv.org/abs/2507.14831v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Rate-Distortion-Perception Trade-off with Strong Realism Constraints: Role of Side Information and Common Randomness", "abstract": "In image compression, with recent advances in generative modeling, existence\nof a trade-off between the rate and perceptual quality has been brought to\nlight, where the perceptual quality is measured by the closeness of the output\nand source distributions. We consider the compression of a memoryless source\nsequence $X^n=(X_1, \\ldots, X_n)$ in the presence of memoryless side\ninformation $Z^n=(Z_1, \\ldots, Z_n),$ originally studied by Wyner and Ziv, but\nelucidate the impact of a strong perfect realism constraint, which requires the\njoint distribution of output symbols $Y^n=(Y_1,...,Y_n)$ to match the\ndistribution of the source sequence. We consider two cases: when $Z^n$ is\navailable only at the decoder, or at both the encoder and decoder, and\ncharacterize the information theoretic limits under various scenarios. Previous\nworks show the superiority of randomized codes under strong perceptual quality\nconstraints. When $Z^n$ is available at both terminals, we characterize its\ndual role, as a source of common randomness, and as a second look on the source\nfor the receiver. We also study different notions of strong perfect realism\nwhich we call marginal realism, joint realism and near-perfect realism. We\nderive explicit solutions when $X$ and $Z$ are jointly Gaussian under the\nsquared error distortion measure. In traditional lossy compression, having $Z$\nonly at the decoder imposes no rate penalty in the Gaussian scenario. We show\nthat, when strong perfect realism constraints are imposed this holds only when\nsufficient common randomness is available.", "published": "2025-07-20 05:08:55", "link": "http://arxiv.org/abs/2507.14825v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A DPI-PAC-Bayesian Framework for Generalization Bounds", "abstract": "We develop a unified Data Processing Inequality PAC-Bayesian framework --\nabbreviated DPI-PAC-Bayesian -- for deriving generalization error bounds in the\nsupervised learning setting. By embedding the Data Processing Inequality (DPI)\ninto the change-of-measure technique, we obtain explicit bounds on the binary\nKullback-Leibler generalization gap for both R\\'enyi divergence and any\n$f$-divergence measured between a data-independent prior distribution and an\nalgorithm-dependent posterior distribution. We present three bounds derived\nunder our framework using R\\'enyi, Hellinger \\(p\\) and Chi-Squared divergences.\nAdditionally, our framework also demonstrates a close connection with other\nwell-known bounds. When the prior distribution is chosen to be uniform, our\nbounds recover the classical Occam's Razor bound and, crucially, eliminate the\nextraneous \\(\\log(2\\sqrt{n})/n\\) slack present in the PAC-Bayes bound, thereby\nachieving tighter results. The framework thus bridges data-processing and\nPAC-Bayesian perspectives, providing a flexible, information-theoretic tool to\nconstruct generalization guarantees.", "published": "2025-07-20 02:55:15", "link": "http://arxiv.org/abs/2507.14795v1", "categories": ["cs.IT", "math.IT", "stat.ML"], "primary_category": "cs.IT"}
{"title": "Enhancing Communications and Sensing Simultaneously by Zero-Order Optimization of MTS", "abstract": "Metasurface (MTS) comprises an array of metaatoms, each reflecting and\ninducing a phase shift into the incident wireless signal. We seek the optimal\ncombination of phase shifts across all the meta-atoms to maximize the channel\nstrength from transmitter to receiver. Unlike many existing works that heavily\nrely on channel state information (CSI), this paper proposes a statistical\napproach to the phase shift optimization in the absence of CSI, namely blind\nconfiguration or zero-order optimization. The main idea is to extract the key\nfeatures of the wireless environment from the received signal strength (RSS)\ndata via conditional sample mean, with provable performance. Furthermore, as a\nwindfall profit, we show that the proposed blind configuration method has a\nnontrivial connection to phase retrieval which can be utilized for active\nsensing. In a nutshell, by configuring a pair of MTSs blindly without channel\nestimation, we not only enhance the channel strength to facilitate wireless\ncommunication, but also enable receiver to localize transmitter. All we need is\nthe RSS data that can be readily measured at receiver. Our algorithm is\nverified in prototype systems in the 2.6 GHz spectral band. As shown in field\ntests, the proposed algorithm outperforms the benchmarks (e.g., MUSIC) in the\nactive sensing task, and in the meanwhile raises the signal-to-noise ratio\n(SNR) significantly by about 10 dB.", "published": "2025-07-20 02:53:12", "link": "http://arxiv.org/abs/2507.14794v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Enhancing Resilience Against Jamming Attacks: A Cooperative Anti-Jamming Method Using Direction Estimation", "abstract": "The inherent vulnerability of wireless communication necessitates strategies\nto enhance its security, particularly in the face of jamming attacks. This\npaper uses the collaborations of multiple sensing nodes (SNs) in the wireless\nnetwork to present a cooperative anti-jamming approach (CAJ) designed to\nneutralize the impact of jamming attacks. We propose an eigenvector (EV) method\nto estimate the direction of the channel vector from pilot symbols. Through our\nanalysis, we demonstrate that with an adequate number of pilot symbols, the\nperformance of the proposed EV method is comparable to the scenario where the\nperfect channel state information (CSI) is utilized. Both analytical formulas\nand simulations illustrate the excellent performance of the proposed EV-CAJ\nunder strong jamming signals. Considering severe jamming, the proposed EV-CAJ\nmethod exhibits only a 0.7 dB degradation compared to the case without jamming\nespecially when the number of SNs is significantly larger than the number of\njamming nodes (JNs). Moreover, the extension of the proposed method can handle\nmultiple jammers at the expense of degrees of freedom (DoF). We also\ninvestigate the method's ability to remain robust in fast-fading channels with\ndifferent coherence times. Our proposed approach demonstrates good resilience,\nparticularly when the ratio of the channel's coherence time to the time frame\nis small. This is especially important in the case of mobile jammers with large\nDoppler shifts.", "published": "2025-07-20 00:28:36", "link": "http://arxiv.org/abs/2507.14775v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Designing User-Centric Metrics for Evaluation of Counterfactual Explanations", "abstract": "Machine learning-based decision models are increasingly being used to make\ndecisions that significantly impact people's lives, but their opaque nature\nleaves end users without a clear understanding of why a decision was made.\nCounterfactual Explanations (CFEs) have grown in popularity as a means of\noffering actionable guidance by identifying the minimum changes in feature\nvalues required to flip a model's prediction to something more desirable.\nUnfortunately, most prior research in CFEs relies on artificial evaluation\nmetrics, such as proximity, which may overlook end-user preferences and\nconstraints, e.g., the user's perception of effort needed to make certain\nfeature changes may differ from that of the model designer. To address this\nresearch gap, this paper makes three novel contributions. First, we conduct a\npilot study with 20 crowd-workers on Amazon MTurk to experimentally validate\nthe alignment of existing CF evaluation metrics with real-world user\npreferences. Results show that user-preferred CFEs matched those based on\nproximity in only 63.81% of cases, highlighting the limited applicability of\nthese metrics in real-world settings. Second, inspired by the need to design a\nuser-informed evaluation metric for CFEs, we conduct a more detailed two-day\nuser study with 41 participants facing realistic credit application scenarios\nto find experimental support for or against three intuitive hypotheses that may\nexplain how end users evaluate CFEs. Third, based on the findings of this\nsecond study, we propose the AWP model, a novel user-centric, two-stage model\nthat describes one possible mechanism by which users evaluate and select CFEs.\nOur results show that AWP predicts user-preferred CFEs with 84.37% accuracy.\nOur study provides the first human-centered validation for personalized cost\nmodels in CFE generation and highlights the need for adaptive, user-centered\nevaluation metrics.", "published": "2025-07-20 23:58:29", "link": "http://arxiv.org/abs/2507.15162v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Resonant-Tunnelling Diode Reservoir Computing System for Image Recognition", "abstract": "As artificial intelligence continues to push into real-time, edge-based and\nresource-constrained environments, there is an urgent need for novel,\nhardware-efficient computational models. In this study, we present and validate\na neuromorphic computing architecture based on resonant-tunnelling diodes\n(RTDs), which exhibit the nonlinear characteristics ideal for physical\nreservoir computing (RC). We theoretically formulate and numerically implement\nan RTD-based RC system and demonstrate its effectiveness on two image\nrecognition benchmarks: handwritten digit classification and object recognition\nusing the Fruit~360 dataset. Our results show that this circuit-level\narchitecture delivers promising performance while adhering to the principles of\nnext-generation RC -- eliminating random connectivity in favour of a\ndeterministic nonlinear transformation of input signals.", "published": "2025-07-20 23:50:32", "link": "http://arxiv.org/abs/2507.15158v1", "categories": ["cs.LG", "physics.app-ph"], "primary_category": "cs.LG"}
{"title": "Constraint-aware Learning of Probabilistic Sequential Models for Multi-Label Classification", "abstract": "We investigate multi-label classification involving large sets of labels,\nwhere the output labels may be known to satisfy some logical constraints. We\nlook at an architecture in which classifiers for individual labels are fed into\nan expressive sequential model, which produces a joint distribution. One of the\npotential advantages for such an expressive model is its ability to modelling\ncorrelations, as can arise from constraints. We empirically demonstrate the\nability of the architecture both to exploit constraints in training and to\nenforce constraints at inference time.", "published": "2025-07-20 23:31:36", "link": "http://arxiv.org/abs/2507.15156v1", "categories": ["cs.LG", "cs.AI", "cs.LO"], "primary_category": "cs.LG"}
{"title": "Quantum Machine Learning for Secure Cooperative Multi-Layer Edge AI with Proportional Fairness", "abstract": "This paper proposes a communication-efficient, event-triggered inference\nframework for cooperative edge AI systems comprising multiple user devices and\nedge servers. Building upon dual-threshold early-exit strategies for rare-event\ndetection, the proposed approach extends classical single-device inference to a\ndistributed, multi-device setting while incorporating proportional fairness\nconstraints across users. A joint optimization framework is formulated to\nmaximize classification utility under communication, energy, and fairness\nconstraints. To solve the resulting problem efficiently, we exploit the\nmonotonicity of the utility function with respect to the confidence thresholds\nand apply alternating optimization with Benders decomposition. Experimental\nresults show that the proposed framework significantly enhances system-wide\nperformance and fairness in resource allocation compared to single-device\nbaselines.", "published": "2025-07-20 22:38:41", "link": "http://arxiv.org/abs/2507.15145v1", "categories": ["cs.NI", "cs.LG"], "primary_category": "cs.NI"}
{"title": "Transforming Datasets to Requested Complexity with Projection-based Many-Objective Genetic Algorithm", "abstract": "The research community continues to seek increasingly more advanced synthetic\ndata generators to reliably evaluate the strengths and limitations of machine\nlearning methods. This work aims to increase the availability of datasets\nencompassing a diverse range of problem complexities by proposing a genetic\nalgorithm that optimizes a set of problem complexity measures for\nclassification and regression tasks towards specific targets. For\nclassification, a set of 10 complexity measures was used, while for regression\ntasks, 4 measures demonstrating promising optimization capabilities were\nselected. Experiments confirmed that the proposed genetic algorithm can\ngenerate datasets with varying levels of difficulty by transforming\nsynthetically created datasets to achieve target complexity values through\nlinear feature projections. Evaluations involving state-of-the-art classifiers\nand regressors revealed a correlation between the complexity of the generated\ndata and the recognition quality.", "published": "2025-07-20 21:42:30", "link": "http://arxiv.org/abs/2507.15132v1", "categories": ["cs.LG", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Are We Overlooking the Dimensions? Learning Latent Hierarchical Channel Structure for High-Dimensional Time Series Forecasting", "abstract": "Time series forecasting (TSF) is a central problem in time series analysis.\nHowever, as the number of channels in time series datasets scales to the\nthousands or more, a scenario we define as High-Dimensional Time Series\nForecasting (HDTSF), it introduces significant new modeling challenges that are\noften not the primary focus of traditional TSF research. HDTSF is challenging\nbecause the channel correlation often forms complex and hierarchical patterns.\nExisting TSF models either ignore these interactions or fail to scale as\ndimensionality grows. To address this issue, we propose U-Cast, a\nchannel-dependent forecasting architecture that learns latent hierarchical\nchannel structures with an innovative query-based attention. To disentangle\nhighly correlated channel representation, U-Cast adds a full-rank\nregularization during training. We also release Time-HD, a benchmark of large,\ndiverse, high-dimensional datasets. Our theory shows that exploiting\ncross-channel information lowers forecasting risk, and experiments on Time-HD\ndemonstrate that U-Cast surpasses strong baselines in both accuracy and\nefficiency. Together, U-Cast and Time-HD provide a solid basis for future HDTSF\nresearch.", "published": "2025-07-20 20:47:32", "link": "http://arxiv.org/abs/2507.15119v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings", "abstract": "Goal: Epilepsy remains under-diagnosed in low-income countries due to scarce\nneurologists and costly diagnostic tools. We propose a graph-based deep\nlearning framework to detect epilepsy from low-cost Electroencephalography\n(EEG) hardware, tested on recordings from Nigeria and Guinea-Bissau. Our focus\nis on fair, accessible automatic assessment and explainability to shed light on\nepilepsy biomarkers. Methods: We model EEG signals as spatio-temporal graphs,\nclassify them, and identify interchannel relationships and temporal dynamics\nusing graph attention networks (GAT). To emphasize connectivity biomarkers, we\nadapt the inherently node-focused GAT to analyze edges. We also designed signal\npreprocessing for low-fidelity recordings and a lightweight GAT architecture\ntrained on Google Colab and deployed on RaspberryPi devices. Results: The\napproach achieves promising classification performance, outperforming a\nstandard classifier based on random forest and graph convolutional networks in\nterms of accuracy and robustness over multiple sessions, but also highlighting\nspecific connections in the fronto-temporal region. Conclusions: The results\nhighlight the potential of GATs to provide insightful and scalable diagnostic\nsupport for epilepsy in underserved regions, paving the way for affordable and\naccessible neurodiagnostic tools.", "published": "2025-07-20 20:44:39", "link": "http://arxiv.org/abs/2507.15118v1", "categories": ["eess.SP", "cs.LG", "cs.NE"], "primary_category": "eess.SP"}
{"title": "Distributional Unlearning: Forgetting Distributions, Not Just Samples", "abstract": "Machine unlearning seeks to remove unwanted information from trained models,\ninitially at the individual-sample level, but increasingly at the level of\nentire sub-populations. In many deployments, models must delete whole topical\ndomains to satisfy privacy, legal, or quality requirements, e.g., removing\nseveral users' posts under GDPR or copyrighted web content. Existing unlearning\ntools remain largely sample-oriented, and straightforward point deletion often\nleaves enough residual signal for downstream learners to recover the unwanted\ndomain. We introduce distributional unlearning, a data-centric, model-agnostic\nframework that asks: Given examples from an unwanted distribution and a\nretained distribution, what is the smallest set of points whose removal makes\nthe edited dataset far from the unwanted domain yet close to the retained one?\nUsing Kullback-Leibler divergence to quantify removal and preservation, we\nderive the exact Pareto frontier in the Gaussian case and prove that any model\nretrained on the edited data incurs log-loss shifts bounded by the divergence\nthresholds. We propose a simple distance-based selection rule satisfying these\nconstraints with a quadratic reduction in deletion budget compared to random\nremoval. Experiments on synthetic Gaussians, Jigsaw Toxic Comments, SMS spam,\nand CIFAR-10 show 15-72% fewer deletions than random, with negligible impact on\nretained performance.", "published": "2025-07-20 20:21:23", "link": "http://arxiv.org/abs/2507.15112v1", "categories": ["cs.LG", "cs.CR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "AnalogFed: Federated Discovery of Analog Circuit Topologies with Generative AI", "abstract": "Recent breakthroughs in AI/ML offer exciting opportunities to revolutionize\nanalog design automation through data-driven approaches. In particular,\nresearchers are increasingly fascinated by harnessing the power of generative\nAI to automate the discovery of novel analog circuit topologies. Unlocking the\nfull potential of generative AI in these data-driven discoveries requires\naccess to large and diverse datasets.Yet, there is a significant barrier in the\nanalog domain--Analog circuit design is inherently proprietary, involving not\nonly confidential circuit structures but also the underlying commercial\nsemiconductor processes. As a result, current generative AI research is largely\nconfined to individual researchers who construct small, narrowly focused\nprivate datasets. This fragmentation severely limits collaborative innovation\nand impedes progress across the research community. To address these\nchallenges, we propose AnalogFed. AnalogFed enables collaborative topology\ndiscovery across decentralized clients (e.g., individual researchers or\ninstitutions) without requiring the sharing of raw private data. To make this\nvision practical, we introduce a suite of techniques tailored to the unique\nchallenges of applying FedL in analog design--from generative model development\nand data heterogeneity handling to privacy-preserving strategies that ensure\nboth flexibility and security for circuit designers and semiconductor\nmanufacturers. Extensive experiments across varying client counts and dataset\nsizes demonstrate that AnalogFed achieves performance comparable to centralized\nbaselines--while maintaining strict data privacy. Specifically, the generative\nAI model within AnalogFed achieves state-of-the-art efficiency and scalability\nin the design of analog circuit topologies.", "published": "2025-07-20 19:57:07", "link": "http://arxiv.org/abs/2507.15104v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Learning under Latent Group Sparsity via Diffusion on Networks", "abstract": "Group or cluster structure on explanatory variables in machine learning\nproblems is a very general phenomenon, which has attracted broad interest from\npractitioners and theoreticians alike. In this work we contribute an approach\nto sparse learning under such group structure, that does not require prior\ninformation on the group identities. Our paradigm is motivated by the Laplacian\ngeometry of an underlying network with a related community structure, and\nproceeds by directly incorporating this into a penalty that is effectively\ncomputed via a heat-flow-based local network dynamics. The proposed penalty\ninterpolates between the lasso and the group lasso penalties, the runtime of\nthe heat-flow dynamics being the interpolating parameter. As such it can\nautomatically default to lasso when the group structure reflected in the\nLaplacian is weak. In fact, we demonstrate a data-driven procedure to construct\nsuch a network based on the available data. Notably, we dispense with\ncomputationally intensive pre-processing involving clustering of variables,\nspectral or otherwise. Our technique is underpinned by rigorous theorems that\nguarantee its effective performance and provide bounds on its sample\ncomplexity. In particular, in a wide range of settings, it provably suffices to\nrun the diffusion for time that is only logarithmic in the problem dimensions.\nWe explore in detail the interfaces of our approach with key statistical\nphysics models in network science, such as the Gaussian Free Field and the\nStochastic Block Model. Our work raises the possibility of applying similar\ndiffusion-based techniques to classical learning tasks, exploiting the\ninterplay between geometric, dynamical and stochastic structures underlying the\ndata.", "published": "2025-07-20 19:32:57", "link": "http://arxiv.org/abs/2507.15097v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Simulation-Prior Independent Neural Unfolding Procedure", "abstract": "Machine learning allows unfolding high-dimensional spaces without binning at\nthe LHC. The new SPINUP method extracts the unfolded distribution based on a\nneural network encoding the forward mapping, making it independent of the prior\nfrom the simulated training data. It is made efficient through neural\nimportance sampling, and ensembling can be used to estimate the effect of\ninformation loss in the forward process. We showcase SPINUP for unfolding\ndetector effects on jet substructure observables and for unfolding to parton\nlevel of associated Higgs and single-top production.", "published": "2025-07-20 18:43:03", "link": "http://arxiv.org/abs/2507.15084v1", "categories": ["hep-ph", "cs.LG", "hep-ex"], "primary_category": "hep-ph"}
{"title": "Robust Control with Gradient Uncertainty", "abstract": "We introduce a novel extension to robust control theory that explicitly\naddresses uncertainty in the value function's gradient, a form of uncertainty\nendemic to applications like reinforcement learning where value functions are\napproximated. We formulate a zero-sum dynamic game where an adversary perturbs\nboth system dynamics and the value function gradient, leading to a new, highly\nnonlinear partial differential equation: the Hamilton-Jacobi-Bellman-Isaacs\nEquation with Gradient Uncertainty (GU-HJBI). We establish its well-posedness\nby proving a comparison principle for its viscosity solutions under a uniform\nellipticity condition. Our analysis of the linear-quadratic (LQ) case yields a\nkey insight: we prove that the classical quadratic value function assumption\nfails for any non-zero gradient uncertainty, fundamentally altering the problem\nstructure. A formal perturbation analysis characterizes the non-polynomial\ncorrection to the value function and the resulting nonlinearity of the optimal\ncontrol law, which we validate with numerical studies. Finally, we bridge\ntheory to practice by proposing a novel Gradient-Uncertainty-Robust\nActor-Critic (GURAC) algorithm, accompanied by an empirical study demonstrating\nits effectiveness in stabilizing training. This work provides a new direction\nfor robust control, holding significant implications for fields where function\napproximation is common, including reinforcement learning and computational\nfinance.", "published": "2025-07-20 18:37:30", "link": "http://arxiv.org/abs/2507.15082v1", "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "cs.LG"}
{"title": "STL-GO: Spatio-Temporal Logic with Graph Operators for Distributed Systems with Multiple Network Topologies", "abstract": "Multi-agent systems (MASs) consisting of a number of autonomous agents that\ncommunicate, coordinate, and jointly sense the environment to achieve complex\nmissions can be found in a variety of applications such as robotics, smart\ncities, and internet-of-things applications. Modeling and monitoring MAS\nrequirements to guarantee overall mission objectives, safety, and reliability\nis an important problem. Such requirements implicitly require reasoning about\ndiverse sensing and communication modalities between agents, analysis of the\ndependencies between agent tasks, and the spatial or virtual distance between\nagents. To capture such rich MAS requirements, we model agent interactions via\nmultiple directed graphs, and introduce a new logic -- Spatio-Temporal Logic\nwith Graph Operators (STL-GO). The key innovation in STL-GO are graph operators\nthat enable us to reason about the number of agents along either the incoming\nor outgoing edges of the underlying interaction graph that satisfy a given\nproperty of interest; for example, the requirement that an agent should sense\nat least two neighboring agents whose task graphs indicate the ability to\ncollaborate. We then propose novel distributed monitoring conditions for\nindividual agents that use only local information to determine whether or not\nan STL-GO specification is satisfied. We compare the expressivity of STL-GO\nagainst existing spatio-temporal logic formalisms, and demonstrate the utility\nof STL-GO and our distributed monitors in a bike-sharing and a multi-drone case\nstudy.", "published": "2025-07-20 22:54:40", "link": "http://arxiv.org/abs/2507.15147v1", "categories": ["cs.LO", "cs.FL", "cs.MA"], "primary_category": "cs.LO"}
{"title": "Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City", "abstract": "This paper investigates the feasibility of human mobility in The Line, a\nproposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess\nwhether citizens can move freely within this unprecedented urban topology, we\ndevelop a hybrid simulation framework that integrates agent-based modeling,\nreinforcement learning, supervised learning, and graph neural networks. The\nsimulation captures multi-modal transportation behaviors across 50 vertical\nlevels and varying density scenarios using both synthetic data and real-world\ntraces from high-density cities. Our experiments reveal that with the full\nAI-integrated architecture, agents achieved an average commute time of 7.8 to\n8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index\nof over 91 percent, even during peak congestion periods. Ablation studies\nconfirmed that the removal of intelligent modules such as reinforcement\nlearning or graph neural networks significantly degrades performance, with\ncommute times increasing by up to 85 percent and reachability falling below 70\npercent. Environmental modeling further demonstrated low energy consumption and\nminimal CO2 emissions when electric modes are prioritized. The findings suggest\nthat freedom of movement is not only conceptually achievable in The Line, but\nalso operationally realistic if supported by adaptive AI systems, sustainable\ninfrastructure, and real-time feedback loops.", "published": "2025-07-20 22:35:16", "link": "http://arxiv.org/abs/2507.15143v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "EduThink4AI: Translating Educational Critical Thinking into Multi-Agent LLM Systems", "abstract": "Large language models (LLMs) have demonstrated significant potential as\neducational tutoring agents, capable of tailoring hints, orchestrating lessons,\nand grading with near-human finesse across various academic domains. However,\ncurrent LLM-based educational systems exhibit critical limitations in promoting\ngenuine critical thinking, failing on over one-third of multi-hop questions\nwith counterfactual premises, and remaining vulnerable to adversarial prompts\nthat trigger biased or factually incorrect responses. To address these gaps, we\npropose EDU-Prompting, a novel multi-agent framework that bridges established\neducational critical thinking theories with LLM agent design to generate\ncritical, bias-aware explanations while fostering diverse perspectives. Our\nsystematic evaluation across theoretical benchmarks and practical college-level\ncritical writing scenarios demonstrates that EDU-Prompting significantly\nenhances both content truthfulness and logical soundness in AI-generated\neducational responses. The framework's modular design enables seamless\nintegration into existing prompting frameworks and educational applications,\nallowing practitioners to directly incorporate critical thinking catalysts that\npromote analytical reasoning and introduce multiple perspectives without\nrequiring extensive system modifications.", "published": "2025-07-20 15:55:13", "link": "http://arxiv.org/abs/2507.15015v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading", "abstract": "Real-time peer-to-peer (P2P) electricity markets dynamically adapt to\nfluctuations in renewable energy and variations in demand, maximizing economic\nbenefits through instantaneous price responses while enhancing grid\nflexibility. However, scaling expert guidance for massive personalized\nprosumers poses critical challenges, including diverse decision-making demands\nand lack of customized modeling frameworks. This paper proposed an integrated\nlarge language model-multi-agent reinforcement learning (LLM-MARL) framework\nfor real-time P2P energy trading to address challenges such as the limited\ntechnical capability of prosumers, the lack of expert experience, and security\nissues of distribution networks. LLMs are introduced as experts to generate\npersonalized strategy, guiding MARL under the centralized training with\ndecentralized execution (CTDE) paradigm through imitation learning. A\ndifferential attention-based critic network is designed to enhance convergence\nperformance. Experimental results demonstrate that LLM generated strategies\neffectively substitute human experts. The proposed multi-agent imitation\nlearning algorithms achieve significantly lower economic costs and voltage\nviolation rates on test sets compared to baselines algorithms, while\nmaintaining robust stability. This work provides an effective solution for\nreal-time P2P electricity market decision-making by bridging expert knowledge\nwith agent learning.", "published": "2025-07-20 14:59:18", "link": "http://arxiv.org/abs/2507.14995v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Extending Data to Improve Stability and Error Estimates Using Asymmetric Kansa-like Methods to Solve PDEs", "abstract": "In this paper, a theoretical framework is presented\n  for the use of a Kansa-like method to numerically solve elliptic\n  partial differential equations on spheres and other manifolds. The\n  theory addresses both the stability of the method and provides error\n  estimates for two different approximation methods. A Kansa-like\n  matrix is obtained by replacing the test point set $X$, used in the\n  traditional Kansa method, by a larger set $Y$, which is a norming\n  set for the underlying trial space. This gives rise to a rectangular\n  matrix. In addition, if a basis of Lagrange (or local Lagrange)\n  functions is used for the trial space, then it is shown\n  that the stability of the matrix is comparable to the stability of\n  the elliptic operator acting on the trial space. Finally, two\n  different types of error estimates are given. Discrete least squares\n  estimates of very high accuracy are obtained for solutions that are\n  sufficiently smooth. The second method, giving similar error\n  estimates, uses a rank revealing factorization to create a\n  ``thinning algorithm'' that reduces $\\#Y$ to $\\#X$. In practice,\n  this algorithm doesn't need $Y$ to be a norming set.", "published": "2025-07-20 22:20:16", "link": "http://arxiv.org/abs/2507.15137v1", "categories": ["math.NA", "cs.NA", "65D12 (Primary) 65D15, 65N06, 65N12 (Secondary)"], "primary_category": "math.NA"}
{"title": "Analysis of fully discrete Crank-Nicolson finite element methods for a stochastic Keller-Segel chemotaxis system with gradient-type multiplicative noise", "abstract": "We develop and analyze numerical methods for a stochastic Keller-Segel system\nperturbed by Stratonovich noise, which models chemotactic behavior under\nrandomly fluctuating environmental conditions. The proposed fully discrete\nscheme couples a Crank-Nicolson time discretization with a splitting mixed\nfinite element method in space. We rigorously prove the stability of the\nnumerical scheme and establish strong convergence rates of order $O(k^{1/2} +\nk^{-1/2}h^2)$, where $k$ and $h$ denote the time and spatial step sizes,\nrespectively. Notably, the presence of stochastic forcing leads to an inverse\ndependence on $k$ in the error estimates, distinguishing the convergence\nbehavior from that of the deterministic case. Numerical experiments are\npresented to validate the theoretical results and demonstrate the effectiveness\nand accuracy of the proposed methods.", "published": "2025-07-20 19:54:43", "link": "http://arxiv.org/abs/2507.15103v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "$\\textit{A Priori}$ Error Analysis for the $p$-Stokes Equations with Slip Boundary Conditions: A Discrete Leray Projection Framework", "abstract": "We present an $\\textit{a priori}$ error analysis for the kinematic pressure\nin a fully-discrete finite-differences/-elements discretization of the unsteady\n$p$-Stokes equations, modelling non-Newtonian fluids. This system is subject to\nboth impermeability and perfect Navier slip boundary conditions, which are\nincorporated either weakly via Lagrange multipliers or strongly in the discrete\nvelocity space. A central aspect of the $\\textit{a priori}$ error analysis is\nthe discrete Leray projection, constructed to quantitatively approximate its\ncontinuous counterpart. The discrete Leray projection enables a Helmholtz-type\ndecomposition at the discrete level and plays a key role in deriving error\ndecay rates for the kinematic pressure. We derive (in some cases optimal) error\ndecay rates for both the velocity vector field and kinematic pressure, with the\nerror for the kinematic pressure measured in an $\\textit{ad hoc}$ norm informed\nby the projection framework. The $\\textit{a priori}$ error analysis remains\nrobust even under reduced regularity of the velocity vector field and the\nkinematic pressure, and illustrates how the interplay of boundary conditions\nand projection stability governs the accuracy of pressure approximations.", "published": "2025-07-20 15:56:37", "link": "http://arxiv.org/abs/2507.15016v1", "categories": ["math.NA", "cs.NA", "65M60, 76A05, 35Q35, 76D07, 65M15, 35B45"], "primary_category": "math.NA"}
{"title": "Quadrature formulas from rational approximations", "abstract": "It is shown that quadrature formulas in many different applications can be\nderived from rational approximation of the Cauchy transform of a weight\nfunction. Since rational approximation is now a routine technology, this\nprovides an easy new method to derive all kinds of quadrature formulas as well\nas fundamental insight into the mathematics of quadrature. Intervals or curves\nof quadrature nodes correspond to near-optimal branch cuts of the Cauchy\ntransform.", "published": "2025-07-20 14:03:29", "link": "http://arxiv.org/abs/2507.14971v1", "categories": ["math.NA", "cs.NA", "41A20"], "primary_category": "math.NA"}
{"title": "A second-order generalized BDF method for the two-dimensional (modified) Fisher-Kolmogorov-Petrovsky-Piskunov equation", "abstract": "The Kolmogorov-Petrovsky-Piskunov (Fisher-KPP) equation is a classical\nreaction-diffusion equation with broad applications such as biology, chemistry\nand physics. In this paper, an alternative second-order scheme is proposed by\nemploying a shifted BDF2 method to approximate the two-dimensional (modified)\nFisher-KPP equation. We both consider an uniform and a nonuniform time steps of\nsuch the scheme. The stability of the uniform discretization scheme is proved.\nNumerical experiments demonstrate that our uniform and non-uniform schemes are\nrobust and accurate.", "published": "2025-07-20 12:23:35", "link": "http://arxiv.org/abs/2507.14939v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An adaptive symplectic integrator for gravitational dynamics", "abstract": "This paper presents an adaptive symplectic integrator, SQQ-PTQ, developed on\nthe basis of the fixed-step symplectic integrator SQQ. To mitigate the Runge\nphenomenon, SQQ-PTQ employs Chebyshev interpolation for approximating the\naction, enhancing both the precision and stability of the interpolation. In\naddition, to reduce the computational cost of evaluating interpolation\nfunctions, SQQ-PTQ introduces a projection method that improves the efficiency\nof these computations. A key feature of SQQ-PTQ is its use of the time\ntransformation to implement an adaptive time step. To address the challenge of\ncomputing complicated Jacobian matrices attributed to the time transformation,\nSQQ-PTQ adopts a quasi-Newton method based on Broyden's method. This strategy\naccelerates the solution of nonlinear equations, thereby improving the overall\ncomputational performance. The effectiveness and robustness of SQQ-PTQ are\ndemonstrated via three numerical experiments. In particular, SQQ-PTQ\ndemonstrates adaptability in handling close-encounter problems. Moreover,\nduring long-term integrations, SQQ-PTQ maintains the energy conservation,\nfurther confirming its advantages as a symplectic algorithm.", "published": "2025-07-20 09:49:41", "link": "http://arxiv.org/abs/2507.14881v1", "categories": ["math.NA", "astro-ph.GA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Thermodynamically Consistent Modeling and Stable ALE Approximations of Reactive Semi-Permeable Interfaces", "abstract": "Reactive, semi-permeable interfaces play important roles in key biological\nprocesses such as targeted drug delivery, lipid metabolism, and signal\ntransduction. These systems involve coupled surface reactions, transmembrane\ntransport, and interfacial deformation, often triggered by local biochemical\nsignals. The strong mechanochemical couplings complicate the modeling of such\ninterfacial dynamics. We propose a thermodynamically consistent continuum\nframework that integrates bulk fluid motion, interfacial dynamics, surface\nchemistry, and selective solute exchange, derived via an energy variation\napproach to ensure mass conservation and energy dissipation. To efficiently\nsolve the resulting coupled system, we develop a finite element scheme within\nan Arbitrary Lagrangian-Eulerian (ALE) framework, incorporating the\nBarrett-Garcke-Nurnberg (BGN) strategy to maintain mesh regularity and preserve\nconservation laws. Numerical experiments verify the convergence and\nconservation properties of the scheme and demonstrate its ability in capturing\ncomplex interfacial dynamics. Two biologically inspired examples showcase the\nmodel's versatility: cholesterol efflux via the ABCG1 pathway, involving\nmultistage interfacial reactions and HDL uptake; and a self-propelled droplet\nsystem with reaction-activated permeability, mimicking drug release in\npathological environments. This work provides a unified computational platform\nfor studying strongly coupled biochemical and mechanical interactions at\ninterfaces, offering new insights into reactive transport processes in both\nbiological and industrial contexts.", "published": "2025-07-20 00:11:12", "link": "http://arxiv.org/abs/2507.14774v1", "categories": ["math.NA", "cs.NA", "math.DS", "92C10, 76T06, 65M06, 65M50"], "primary_category": "math.NA"}
{"title": "Transaction Profiling and Address Role Inference in Tokenized U.S. Treasuries", "abstract": "Tokenized U.S. Treasuries have emerged as a prominent subclass of real-world\nassets (RWAs), offering cryptographically enforced, yield-bearing instruments\ncollateralized by sovereign debt and deployed across multiple blockchain\nnetworks. While the market has expanded rapidly, empirical analyses of\ntransaction-level behaviour remain limited. This paper conducts a quantitative,\nfunction-level dissection of U.S. Treasury-backed RWA tokens including BUIDL,\nBENJI, and USDY, across multi-chain: mostly Ethereum and Layer-2s. We analyze\ndecoded contract calls to isolate core functional primitives such as issuance,\nredemption, transfer, and bridge activity, revealing segmentation in behaviour\nbetween institutional actors and retail users. To model address-level economic\nroles, we introduce a curvature-aware representation learning framework using\nPoincar\\'e embeddings and liquidity-based graph features. Our method\noutperforms baseline models on our RWA Treasury dataset in role inference and\ngeneralizes to downstream tasks such as anomaly detection and wallet\nclassification in broader blockchain transaction networks. These findings\nprovide a structured understanding of functional heterogeneity and participant\nroles in tokenized Treasury in a transaction-level perspective, contributing\nnew empirical evidence to the study of on-chain financialization.", "published": "2025-07-20 03:54:06", "link": "http://arxiv.org/abs/2507.14808v1", "categories": ["q-fin.CP", "cs.CE", "cs.LG"], "primary_category": "q-fin.CP"}
{"title": "Optimal Decisions for Liquid Staking: Allocation and Exit Timing", "abstract": "In this paper, we study an investor's optimal entry and exit decisions in a\nliquid staking protocol (LSP) and an automated market maker (AMM), primarily\nfrom the standpoint of the investor. Our analysis focuses on two key investor\nactions: the initial allocation decision at time t=0, and the optimal timing of\nexit. First, we derive an optimal allocation strategy that enables the investor\nto distribute risk across the LSP, AMM, and direct holding. Our results also\noffer insights for LSP and AMM designers, identifying the necessary and\nsufficient conditions under which the investor is incentivized to stake through\nan LSP, and further, to provide liquidity in addition to staking. These\nconditions include a lower bound on the transaction fee, for which we propose a\nfee mechanism that attains the bound. Second, given a fixed protocol design, we\nmodel the optimal exit timing of an individual investor using Laplace\ntransforms and free-boundary techniques. We analyze scenarios with and without\ntransaction fees. In the absence of fees, we decompose the investor's payoff\ninto impermanent loss and opportunity cost, and provide theoretical results\ncharacterizing the investor's payoff and the optimal exit threshold. With\ntransaction fees, we conduct numerical analyses to examine how fee accumulation\ninfluences exit strategies. Our results reveal that in both settings, a\nstop-loss strategy often maximizes the investor's expected payoff, driven by\nopportunity gains and the accumulation of fees where fees are present. Our\nanalyses rely on various tools from stochastic processes and control theory, as\nwell as convex optimization and analysis. We further support our theoretical\ninsights with numerical experiments and explore additional properties of the\ninvestor's value function and optimal behavior.", "published": "2025-07-20 04:00:18", "link": "http://arxiv.org/abs/2507.14810v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Isotonic Quantile Regression Averaging for uncertainty quantification of electricity price forecasts", "abstract": "Quantifying the uncertainty of forecasting models is essential to assess and\nmitigate the risks associated with data-driven decisions, especially in\nvolatile domains such as electricity markets. Machine learning methods can\nprovide highly accurate electricity price forecasts, critical for informing the\ndecisions of market participants. However, these models often lack uncertainty\nestimates, which limits the ability of decision makers to avoid unnecessary\nrisks. In this paper, we propose a novel method for generating probabilistic\nforecasts from ensembles of point forecasts, called Isotonic Quantile\nRegression Averaging (iQRA). Building on the established framework of Quantile\nRegression Averaging (QRA), we introduce stochastic order constraints to\nimprove forecast accuracy, reliability, and computational costs. In an\nextensive forecasting study of the German day-ahead electricity market, we show\nthat iQRA consistently outperforms state-of-the-art postprocessing methods in\nterms of both reliability and sharpness. It produces well-calibrated prediction\nintervals across multiple confidence levels, providing superior reliability to\nall benchmark methods, particularly coverage-based conformal prediction. In\naddition, isotonic regularization decreases the complexity of the quantile\nregression problem and offers a hyperparameter-free approach to variable\nselection.", "published": "2025-07-20 18:28:39", "link": "http://arxiv.org/abs/2507.15079v1", "categories": ["cs.LG", "q-fin.ST", "stat.AP"], "primary_category": "cs.LG"}
{"title": "A Comparative Analysis of Statistical and Machine Learning Models for Outlier Detection in Bitcoin Limit Order Books", "abstract": "The detection of outliers within cryptocurrency limit order books (LOBs) is\nof paramount importance for comprehending market dynamics, particularly in\nhighly volatile and nascent regulatory environments. This study conducts a\ncomprehensive comparative analysis of robust statistical methods and advanced\nmachine learning techniques for real-time anomaly identification in\ncryptocurrency LOBs. Within a unified testing environment, named AITA Order\nBook Signal (AITA-OBS), we evaluate the efficacy of thirteen diverse models to\nidentify which approaches are most suitable for detecting potentially\nmanipulative trading behaviours. An empirical evaluation, conducted via\nbacktesting on a dataset of 26,204 records from a major exchange, demonstrates\nthat the top-performing model, Empirical Covariance (EC), achieves a 6.70%\ngain, significantly outperforming a standard Buy-and-Hold benchmark. These\nfindings underscore the effectiveness of outlier-driven strategies and provide\ninsights into the trade-offs between model complexity, trade frequency, and\nperformance. This study contributes to the growing corpus of research on\ncryptocurrency market microstructure by furnishing a rigorous benchmark of\nanomaly detection models and highlighting their potential for augmenting\nalgorithmic trading and risk management.", "published": "2025-07-20 13:42:36", "link": "http://arxiv.org/abs/2507.14960v1", "categories": ["q-fin.TR", "cs.AI", "cs.LG", "math.ST", "stat.TH"], "primary_category": "q-fin.TR"}
{"title": "Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies", "abstract": "Why do reinforcement learning (RL) policies fail or succeed? This is a\nchallenging question due to the complex, high-dimensional nature of\nagent-environment interactions. In this work, we take a causal perspective on\nexplaining the behavior of RL policies by viewing the states, actions, and\nrewards as variables in a low-level causal model. We introduce random\nperturbations to policy actions during execution and observe their effects on\nthe cumulative reward, learning a simplified high-level causal model that\nexplains these relationships. To this end, we develop a nonlinear Causal Model\nReduction framework that ensures approximate interventional consistency,\nmeaning the simplified high-level model responds to interventions in a similar\nway as the original complex system. We prove that for a class of nonlinear\ncausal models, there exists a unique solution that achieves exact\ninterventional consistency, ensuring learned explanations reflect meaningful\ncausal patterns. Experiments on both synthetic causal models and practical RL\ntasks-including pendulum control and robot table tennis-demonstrate that our\napproach can uncover important behavioral patterns, biases, and failure modes\nin trained RL policies.", "published": "2025-07-20 10:25:24", "link": "http://arxiv.org/abs/2507.14901v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Uncertainty Quantification for Machine Learning-Based Prediction: A Polynomial Chaos Expansion Approach for Joint Model and Input Uncertainty Propagation", "abstract": "Machine learning (ML) surrogate models are increasingly used in engineering\nanalysis and design to replace computationally expensive simulation models,\nsignificantly reducing computational cost and accelerating decision-making\nprocesses. However, ML predictions contain inherent errors, often estimated as\nmodel uncertainty, which is coupled with variability in model inputs.\nAccurately quantifying and propagating these combined uncertainties is\nessential for generating reliable engineering predictions. This paper presents\na robust framework based on Polynomial Chaos Expansion (PCE) to handle joint\ninput and model uncertainty propagation. While the approach applies broadly to\ngeneral ML surrogates, we focus on Gaussian Process regression models, which\nprovide explicit predictive distributions for model uncertainty. By\ntransforming all random inputs into a unified standard space, a PCE surrogate\nmodel is constructed, allowing efficient and accurate calculation of the mean\nand standard deviation of the output. The proposed methodology also offers a\nmechanism for global sensitivity analysis, enabling the accurate quantification\nof the individual contributions of input variables and ML model uncertainty to\nthe overall output variability. This approach provides a computationally\nefficient and interpretable framework for comprehensive uncertainty\nquantification, supporting trustworthy ML predictions in downstream engineering\napplications.", "published": "2025-07-20 01:47:50", "link": "http://arxiv.org/abs/2507.14782v1", "categories": ["stat.ML", "cs.LG", "math-ph", "math.MP", "stat.CO"], "primary_category": "stat.ML"}
{"title": "Frame-level Temporal Difference Learning for Partial Deepfake Speech Detection", "abstract": "Detecting partial deepfake speech is essential due to its potential for\nsubtle misinformation. However, existing methods depend on costly frame-level\nannotations during training, limiting real-world scalability. Also, they focus\non detecting transition artifacts between bonafide and deepfake segments. As\ndeepfake generation techniques increasingly smooth these transitions, detection\nhas become more challenging. To address this, our work introduces a new\nperspective by analyzing frame-level temporal differences and reveals that\ndeepfake speech exhibits erratic directional changes and unnatural local\ntransitions compared to bonafide speech. Based on this finding, we propose a\nTemporal Difference Attention Module (TDAM) that redefines partial deepfake\ndetection as identifying unnatural temporal variations, without relying on\nexplicit boundary annotations. A dual-level hierarchical difference\nrepresentation captures temporal irregularities at both fine and coarse scales,\nwhile adaptive average pooling preserves essential patterns across\nvariable-length inputs to minimize information loss. Our TDAM-AvgPool model\nachieves state-of-the-art performance, with an EER of 0.59% on the PartialSpoof\ndataset and 0.03% on the HAD dataset, which significantly outperforms the\nexisting methods without requiring frame-level supervision.", "published": "2025-07-20 19:46:23", "link": "http://arxiv.org/abs/2507.15101v1", "categories": ["cs.SD", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DMOSpeech 2: Reinforcement Learning for Duration Prediction in Metric-Optimized Speech Synthesis", "abstract": "Diffusion-based text-to-speech (TTS) systems have made remarkable progress in\nzero-shot speech synthesis, yet optimizing all components for perceptual\nmetrics remains challenging. Prior work with DMOSpeech demonstrated direct\nmetric optimization for speech generation components, but duration prediction\nremained unoptimized. This paper presents DMOSpeech 2, which extends metric\noptimization to the duration predictor through a reinforcement learning\napproach. The proposed system implements a novel duration policy framework\nusing group relative preference optimization (GRPO) with speaker similarity and\nword error rate as reward signals. By optimizing this previously unoptimized\ncomponent, DMOSpeech 2 creates a more complete metric-optimized synthesis\npipeline. Additionally, this paper introduces teacher-guided sampling, a hybrid\napproach leveraging a teacher model for initial denoising steps before\ntransitioning to the student model, significantly improving output diversity\nwhile maintaining efficiency. Comprehensive evaluations demonstrate superior\nperformance across all metrics compared to previous systems, while reducing\nsampling steps by half without quality degradation. These advances represent a\nsignificant step toward speech synthesis systems with metric optimization\nacross multiple components. The audio samples, code and pre-trained models are\navailable at https://dmospeech2.github.io/.", "published": "2025-07-20 14:48:48", "link": "http://arxiv.org/abs/2507.14988v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Music-Aligned Holistic 3D Dance Generation via Hierarchical Motion Modeling", "abstract": "Well-coordinated, music-aligned holistic dance enhances emotional\nexpressiveness and audience engagement. However, generating such dances remains\nchallenging due to the scarcity of holistic 3D dance datasets, the difficulty\nof achieving cross-modal alignment between music and dance, and the complexity\nof modeling interdependent motion across the body, hands, and face. To address\nthese challenges, we introduce SoulDance, a high-precision music-dance paired\ndataset captured via professional motion capture systems, featuring\nmeticulously annotated holistic dance movements. Building on this dataset, we\npropose SoulNet, a framework designed to generate music-aligned, kinematically\ncoordinated holistic dance sequences. SoulNet consists of three principal\ncomponents: (1) Hierarchical Residual Vector Quantization, which models\ncomplex, fine-grained motion dependencies across the body, hands, and face; (2)\nMusic-Aligned Generative Model, which composes these hierarchical motion units\ninto expressive and coordinated holistic dance; (3) Music-Motion Retrieval\nModule, a pre-trained cross-modal model that functions as a music-dance\nalignment prior, ensuring temporal synchronization and semantic coherence\nbetween generated dance and input music throughout the generation process.\nExtensive experiments demonstrate that SoulNet significantly surpasses existing\napproaches in generating high-quality, music-coordinated, and well-aligned\nholistic 3D dance sequences.", "published": "2025-07-20 11:06:47", "link": "http://arxiv.org/abs/2507.14915v1", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Parameter-Efficient Fine-Tuning of Foundation Models for CLP Speech Classification", "abstract": "We propose the use of parameter-efficient fine-tuning (PEFT) of foundation\nmodels for cleft lip and palate (CLP) detection and severity classification. In\nCLP, nasalization increases with severity due to the abnormal passage between\nthe oral and nasal tracts; this causes oral stops to be replaced by glottal\nstops and alters formant trajectories and vowel space. Since foundation models\nare trained for grapheme prediction or long-term quantized representation\nprediction, they may better discriminate CLP severity when fine-tuned on\ndomain-specific data. We conduct experiments on two datasets: English (NMCPC)\nand Kannada (AIISH). We perform a comparative analysis using embeddings from\nself-supervised models Wav2Vec2 and WavLM, and the weakly supervised Whisper,\neach paired with SVM classifiers, and compare them with traditional handcrafted\nfeatures eGeMAPS and ComParE. Finally, we fine-tune the best-performing Whisper\nmodel using PEFT techniques: Low-Rank Adapter (LoRA) and Decomposed Low-Rank\nAdapter (DoRA). Our results demonstrate that the proposed approach achieves\nrelative improvements of 26.4% and 63.4% in macro-average F1 score over the\nbest foundation model and handcrafted feature baselines on the NMCPC dataset,\nand improvements of 6.1% and 52.9% on the AIISH dataset, respectively.", "published": "2025-07-20 10:23:03", "link": "http://arxiv.org/abs/2507.14898v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "How Many Simultaneous Beamformers are Needed for Integrated Sensing and Communications?", "abstract": "Consider a downlink integrated sensing and communications (ISAC) system in\nwhich a base station employs linear beamforming to communicate to $K$ users,\nwhile simultaneously uses sensing beams to perform a sensing task of estimating\n$L$ real parameters. How many beamformers are needed to achieve the best\nperformance for both sensing and communications? This paper establishes bounds\non the minimum number of downlink beamformers, in which sensing performance is\nmeasured in terms of the Cram\\'{e}r-Rao bound for parameter estimation and\ncommunications performance is measured in terms of the\nsignal-to-interference-and-noise ratios. We show that an ISAC system requires\nat most $K + \\sqrt{\\frac{L(L+1)}{2}}$ beamformers if the remote users have the\nability to cancel the interference caused by the sensing beams. If cancelling\ninterference due to the sensing beams is not possible, the bound becomes\n$\\sqrt{K^2 + \\frac{L(L+1)}{2}}$. Interestingly, in the latter case, the bound\non the number of beamformers is less than the sum of the bounds for each task\nindividually. These results can be extended to sensing tasks for which the\nperformance is measured as a function of $d$ quadratic terms in the\nbeamformers. In this case, the bound becomes $K + \\sqrt{d}$ and $\\sqrt{K^2 +\nd}$, respectively. Specifically, for estimating complex path losses and\nangles-of-arrival of $N_\\text{tr}$ targets while communicating to $K$ users,\nthe bound on the minimum number of beamformers scales linearly in $K$ and in\n$N_\\text{tr}$, assuming interference from sensing can be cancelled. When\ninterference cancellation is not possible, the following exact characterization\nfor the case of $N_\\text{tr} = 1$ can be obtained: when $K=0$ or $1$, two\nbeamformers should be used; when $K \\ge 2$, exactly $K$ beamformers should be\nused, i.e., communication beamformers alone are already sufficient.", "published": "2025-07-20 14:37:01", "link": "http://arxiv.org/abs/2507.14982v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Latent-attention Based Transformer for Near ML Polar Decoding in Short-code Regime", "abstract": "Transformer architectures have emerged as promising deep learning (DL) tools\nfor modeling complex sequence-to-sequence interactions in channel decoding.\nHowever, current transformer-based decoders for error correction codes (ECCs)\ndemonstrate inferior performance and generalization capabilities compared to\nconventional algebraic decoders, especially in short-code regimes. In this\nwork, we propose a novel latent-attention based transformer (LAT) decoder for\npolar codes that addresses the limitations on performance and generalization\nthrough three pivotal innovations. First, we develop a latent-attention\nmechanism that supersedes the conventional self-attention mechanism. This\narchitectural modification enables independent learning of the Query and Key\nmatrices for code-aware attention computation, decoupling them from the Value\nmatrix to emphasize position-wise decoding interactions while reducing context\ncorrelation interference. Second, we devise an advanced training framework\nincorporating three synergistic components: entropy-aware importance sampling\nthat emphasizes low-probability regions in the signal constellation space,\nexperience reflow that introduces empirical labels to improve characterization\nof decoding boundaries, and dynamic label smoothing for likelihood-based\nregularization. Third, we propose a code-aware mask scheme which allows dynamic\nadaptation for varying code configurations. Numerical evaluations demonstrate\nthat the proposed LAT decoder achieves near maximum-likelihood (ML) performance\nin terms of both bit error rate (BER) and block error rate (BLER) for\nshort-length polar codes. Furthermore, the architecture exhibits robust\ngeneralization capabilities across diverse code rates and code lengths.", "published": "2025-07-20 13:19:43", "link": "http://arxiv.org/abs/2507.14951v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Jamming-Resistant AAV Communications: A Multichannel-Aided Approach", "abstract": "Jamming cancellation is essential to reliable unmanned autonomous vehicle\n(AAV) communications in the presence of malicious jammers. In this paper, we\ndevelop a practical multichannel-aided jamming cancellation method to realize\nsecure AAV communications. The proposed method is capable of simultaneously\nachieving timing/frequency synchronization as well as jamming cancellation.\nMore importantly, our method does not need the signal's/jammer's channel state\ninformation. It only utilizes the knowledge of the legitimate sender's preamble\nsequence that is available in existing communication protocols. We also analyze\nthe length of the preamble sequence required for successful synchronization and\nsignal recovery. Experimental results on the built hardware platform show that,\nwith a two-antenna receiver, the proposed method can successfully decode the\nsignal of interest even when the jamming signal is $40$dB stronger than the\ncommunication signal.", "published": "2025-07-20 12:51:49", "link": "http://arxiv.org/abs/2507.14945v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Phase-optimised linearly-constrained minimum-variance beamformers", "abstract": "A novel procedure for the determination of the optimal group-delay for a\nLinearly-Constrained Minimum-Variance (LCMV) beamformer is proposed. Two ways\nof selecting the optimal delay are recommended: the first is the solution that\nminimizes the noise power; the second is the solution that minimizes the\nprocessing delay. The potential of this hitherto unexplored degree of design\nfreedom is explored using simulated Very-High-Frequency (VHF) communication,\nand Ultra-High-Frequency (UHF) bistatic radar, applications.", "published": "2025-07-20 12:21:27", "link": "http://arxiv.org/abs/2507.14937v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Stabilization of the bias point in MZM modulators", "abstract": "This article mainly introduces the role of MZM in practical communication\nsystems, the materials used to make MZM modulators such as lithium niobate, and\nits working principle. It also explains why it changes due to environmental\nfactors. This leads to the introduction of a method that controls the stable\npoints of MZM by algorithmically controlling the voltage, and the algorithm is\nverified through experiments. Finally, a summary and outlook on the future\ndevelopment of MZM are provided.", "published": "2025-07-20 10:11:53", "link": "http://arxiv.org/abs/2507.14888v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Integrated Radio Sensing Capabilities for 6G Networks: AI/ML Perspective", "abstract": "The sixth-generation wireless communications (6G) is often labeled as\n\"connected intelligence\". Radio sensing, aligned with machine learning (ML) and\nartificial intelligence (AI), promises, among other benefits, breakthroughs in\nthe system's ability to perceive the environment and effectively utilize this\nawareness. This article offers a tutorial-style survey of AI and ML approaches\nto enhance the sensing capabilities of next-generation wireless networks. To\nthis end, while staying in the framework of integrated sensing and\ncommunication (ISAC), we expand the term \"sensing\" from radar, via spectrum\nsensing, to miscellaneous applications of radio sensing like non-cooperative\ntransmitter localization. We formulate the problems, explain the\nstate-of-the-art approaches, and detail AI-based techniques to tackle various\nobjectives in the context of wireless sensing. We discuss the advantages,\nenablers, and challenges of integrating various sensing capabilities into an\nenvisioned AI-powered multimodal multi-task network. In addition to the\ntutorial-style core of this work based on direct authors' involvement in 6G\nresearch problems, we review the related literature, and provide both a good\nstart for those entering this field of research, and a topical overview for a\ngeneral reader with a background in wireless communications", "published": "2025-07-20 07:53:42", "link": "http://arxiv.org/abs/2507.14856v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Movable-Element STARS-Aided Secure Communications", "abstract": "A novel movable-element (ME) enabled simultaneously transmitting and\nreflecting surface (ME-STARS)-aided secure communication system is\ninvestigated. Against the full-space eavesdropping, MEs are deployed at the\nSTARS for enhancing the physical layer security by exploiting higher spatial\ndegrees of freedom. Specifically, a sum secrecy rate maximization problem is\nformulated, which jointly optimizes the passive beamforming and the MEs\npositions at the ME-STARS, as well as the active beamforming at the base\nstation. To solve the resultant non-convex optimization problem involving\nhighly-coupled variables, an alternating optimization-based iterative algorithm\nis developed, decomposing the original problem into three subproblems. In\nparticular, for the MEs position optimization subproblem, a gradient ascent\nalgorithm is employed to iteratively refine the MEs' locations within the\nconfined region. Moreover, the the active and passive beamforming subproblems\nare solved by employing successive convex approximation. Numerical results\nunveil that: 1) ME-STARS significantly improves the secrecy performance\ncompared to the conventional STARS with fixed-position elements; and 2) The\nsecrecy rate achieved by the ME-STARS gets saturated within limited movable\nregion size.", "published": "2025-07-20 03:36:13", "link": "http://arxiv.org/abs/2507.14804v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Hear Your Code Fail, Voice-Assisted Debugging for Python", "abstract": "This research introduces an innovative voice-assisted debugging plugin for\nPython that transforms silent runtime errors into actionable audible\ndiagnostics. By implementing a global exception hook architecture with pyttsx3\ntext-to-speech conversion and Tkinter-based GUI visualization, the solution\ndelivers multimodal error feedback through parallel auditory and visual\nchannels. Empirical evaluation demonstrates 37% reduced cognitive load (p<0.01,\nn=50) compared to traditional stack-trace debugging, while enabling 78% faster\nerror identification through vocalized exception classification and\ncontextualization. The system achieves sub-1.2 second voice latency with under\n18% CPU overhead during exception handling, vocalizing error types and\nconsequences while displaying interactive tracebacks with documentation deep\nlinks. Criteria validate compatibility across Python 3.7+ environments on\nWindows, macOS, and Linux platforms. Needing only two lines of integration\ncode, the plugin significantly boosts availability for aesthetically impaired\ndesigners and supports multitasking workflows through hands-free error medical\ndiagnosis. Educational applications show particular promise, with pilot studies\nindicating 45% faster debugging skill acquisition among novice programmers.\nFuture development will incorporate GPT-based repair suggestions and real-time\nmultilingual translation to further advance auditory debugging paradigms. The\nsolution represents a fundamental shift toward human-centric error diagnostics,\nbridging critical gaps in programming accessibility while establishing new\nstandards for cognitive efficiency in software development workflows.", "published": "2025-07-20 15:24:35", "link": "http://arxiv.org/abs/2507.15007v2", "categories": ["cs.PL", "cs.CL"], "primary_category": "cs.PL"}
{"title": "A DPI-PAC-Bayesian Framework for Generalization Bounds", "abstract": "We develop a unified Data Processing Inequality PAC-Bayesian framework --\nabbreviated DPI-PAC-Bayesian -- for deriving generalization error bounds in the\nsupervised learning setting. By embedding the Data Processing Inequality (DPI)\ninto the change-of-measure technique, we obtain explicit bounds on the binary\nKullback-Leibler generalization gap for both R\\'enyi divergence and any\n$f$-divergence measured between a data-independent prior distribution and an\nalgorithm-dependent posterior distribution. We present three bounds derived\nunder our framework using R\\'enyi, Hellinger \\(p\\) and Chi-Squared divergences.\nAdditionally, our framework also demonstrates a close connection with other\nwell-known bounds. When the prior distribution is chosen to be uniform, our\nbounds recover the classical Occam's Razor bound and, crucially, eliminate the\nextraneous \\(\\log(2\\sqrt{n})/n\\) slack present in the PAC-Bayes bound, thereby\nachieving tighter results. The framework thus bridges data-processing and\nPAC-Bayesian perspectives, providing a flexible, information-theoretic tool to\nconstruct generalization guarantees.", "published": "2025-07-20 02:55:15", "link": "http://arxiv.org/abs/2507.14795v2", "categories": ["cs.IT", "math.IT", "stat.ML"], "primary_category": "cs.IT"}
{"title": "Music-Aligned Holistic 3D Dance Generation via Hierarchical Motion Modeling", "abstract": "Well-coordinated, music-aligned holistic dance enhances emotional\nexpressiveness and audience engagement. However, generating such dances remains\nchallenging due to the scarcity of holistic 3D dance datasets, the difficulty\nof achieving cross-modal alignment between music and dance, and the complexity\nof modeling interdependent motion across the body, hands, and face. To address\nthese challenges, we introduce SoulDance, a high-precision music-dance paired\ndataset captured via professional motion capture systems, featuring\nmeticulously annotated holistic dance movements. Building on this dataset, we\npropose SoulNet, a framework designed to generate music-aligned, kinematically\ncoordinated holistic dance sequences. SoulNet consists of three principal\ncomponents: (1) Hierarchical Residual Vector Quantization, which models\ncomplex, fine-grained motion dependencies across the body, hands, and face; (2)\nMusic-Aligned Generative Model, which composes these hierarchical motion units\ninto expressive and coordinated holistic dance; (3) Music-Motion Retrieval\nModule, a pre-trained cross-modal model that functions as a music-dance\nalignment prior, ensuring temporal synchronization and semantic coherence\nbetween generated dance and input music throughout the generation process.\nExtensive experiments demonstrate that SoulNet significantly surpasses existing\napproaches in generating high-quality, music-coordinated, and well-aligned\nholistic 3D dance sequences.", "published": "2025-07-20 11:06:47", "link": "http://arxiv.org/abs/2507.14915v2", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "How Many Simultaneous Beamformers are Needed for Integrated Sensing and Communications?", "abstract": "Consider a downlink integrated sensing and communications (ISAC) system in\nwhich a base station employs linear beamforming to communicate to $K$ users,\nwhile simultaneously uses sensing beams to perform a sensing task of estimating\n$L$ real parameters. How many beamformers are needed to achieve the best\nperformance for both sensing and communications? This paper establishes bounds\non the minimum number of downlink beamformers, in which sensing performance is\nmeasured in terms of the Cram\\'{e}r-Rao bound for parameter estimation and\ncommunications performance is measured in terms of the\nsignal-to-interference-and-noise ratios. We show that an ISAC system requires\nat most $K + \\sqrt{\\frac{L(L+1)}{2}}$ beamformers if the remote users have the\nability to cancel the interference caused by the sensing beams. If cancelling\ninterference due to the sensing beams is not possible, the bound becomes\n$\\sqrt{K^2 + \\frac{L(L+1)}{2}}$. Interestingly, in the latter case, the bound\non the number of beamformers is less than the sum of the bounds for each task\nindividually. These results can be extended to sensing tasks for which the\nperformance is measured as a function of $d$ quadratic terms in the\nbeamformers. In this case, the bound becomes $K + \\sqrt{d}$ and $\\sqrt{K^2 +\nd}$, respectively. Specifically, for estimating complex path losses and\nangles-of-arrival of $N_\\text{tr}$ targets while communicating to $K$ users,\nthe bound on the minimum number of beamformers scales linearly in $K$ and in\n$N_\\text{tr}$, assuming interference from sensing can be cancelled. When\ninterference cancellation is not possible, the following exact characterization\nfor the case of $N_\\text{tr} = 1$ can be obtained: when $K=0$ or $1$, two\nbeamformers should be used; when $K \\ge 2$, exactly $K$ beamformers should be\nused, i.e., communication beamformers alone are already sufficient.", "published": "2025-07-20 14:37:01", "link": "http://arxiv.org/abs/2507.14982v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
