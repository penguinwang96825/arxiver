{"title": "Translating Terminological Expressions in Knowledge Bases with Neural\n  Machine Translation", "abstract": "Our work presented in this paper focuses on the translation of terminological\nexpressions represented in semantically structured resources, like ontologies\nor knowledge graphs. The challenge of translating ontology labels or\nterminological expressions documented in knowledge bases lies in the highly\nspecific vocabulary and the lack of contextual information, which can guide a\nmachine translation system to translate ambiguous words into the targeted\ndomain. Due to these challenges, we evaluate the translation quality of\ndomain-specific expressions in the medical and financial domain with\nstatistical as well as with neural machine translation methods and experiment\ndomain adaptation of the translation models with terminological expressions\nonly. Furthermore, we perform experiments on the injection of external\nterminological expressions into the translation systems. Through these\nexperiments, we observed a significant advantage in domain adaptation for the\ndomain-specific resource in the medical and financial domain and the benefit of\nsubword models over word-based neural machine translation models for\nterminology translation.", "published": "2017-09-07 11:31:09", "link": "http://arxiv.org/abs/1709.02184v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Discourse Information Effectively for Authorship Attribution", "abstract": "We explore techniques to maximize the effectiveness of discourse information\nin the task of authorship attribution. We present a novel method to embed\ndiscourse features in a Convolutional Neural Network text classifier, which\nachieves a state-of-the-art result by a substantial margin. We empirically\ninvestigate several featurization methods to understand the conditions under\nwhich discourse features contribute non-trivial performance gains, and analyze\ndiscourse embeddings.", "published": "2017-09-07 14:22:50", "link": "http://arxiv.org/abs/1709.02271v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cynical Selection of Language Model Training Data", "abstract": "The Moore-Lewis method of \"intelligent selection of language model training\ndata\" is very effective, cheap, efficient... and also has structural problems.\n(1) The method defines relevance by playing language models trained on the\nin-domain and the out-of-domain (or data pool) corpora against each other. This\npowerful idea-- which we set out to preserve-- treats the two corpora as the\nopposing ends of a single spectrum. This lack of nuance does not allow for the\ntwo corpora to be very similar. In the extreme case where the come from the\nsame distribution, all of the sentences have a Moore-Lewis score of zero, so\nthere is no resulting ranking. (2) The selected sentences are not guaranteed to\nbe able to model the in-domain data, nor to even cover the in-domain data. They\nare simply well-liked by the in-domain model; this is necessary, but not\nsufficient. (3) There is no way to tell what is the optimal number of sentences\nto select, short of picking various thresholds and building the systems.\n  We present a greedy, lazy, approximate, and generally efficient\ninformation-theoretic method of accomplishing the same goal using only\nvocabulary counts. The method has the following properties: (1) Is responsive\nto the extent to which two corpora differ. (2) Quickly reaches near-optimal\nvocabulary coverage. (3) Takes into account what has already been selected. (4)\nDoes not involve defining any kind of domain, nor any kind of classifier. (6)\nKnows approximately when to stop. This method can be used as an\ninherently-meaningful measure of similarity, as it measures the bits of\ninformation to be gained by adding one text to another.", "published": "2017-09-07 14:30:50", "link": "http://arxiv.org/abs/1709.02279v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Composition by Conversation", "abstract": "Most musical programming languages are developed purely for coding virtual\ninstruments or algorithmic compositions. Although there has been some work in\nthe domain of musical query languages for music information retrieval, there\nhas been little attempt to unify the principles of musical programming and\nquery languages with cognitive and natural language processing models that\nwould facilitate the activity of composition by conversation. We present a\nprototype framework, called MusECI, that merges these domains, permitting\nscore-level algorithmic composition in a text editor while also supporting\nconnectivity to existing natural language processing frameworks.", "published": "2017-09-07 05:39:00", "link": "http://arxiv.org/abs/1709.02076v1", "categories": ["cs.SD", "cs.CL", "cs.IR", "cs.PL", "H.5.1; H.5.5; I.2.4; I.2.5; I.2.7"], "primary_category": "cs.SD"}
{"title": "A Deep Reinforcement Learning Chatbot", "abstract": "We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including template-based\nmodels, bag-of-words models, sequence-to-sequence neural network and latent\nvariable neural network models. By applying reinforcement learning to\ncrowdsourced data and real-world user interactions, the system has been trained\nto select an appropriate response from the models in its ensemble. The system\nhas been evaluated through A/B testing with real-world users, where it\nperformed significantly better than many competing systems. Due to its machine\nlearning architecture, the system is likely to improve with additional data.", "published": "2017-09-07 16:51:09", "link": "http://arxiv.org/abs/1709.02349v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE", "stat.ML", "I.5.1; I.2.7"], "primary_category": "cs.CL"}
