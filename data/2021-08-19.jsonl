{"title": "MvSR-NAT: Multi-view Subset Regularization for Non-Autoregressive\n  Machine Translation", "abstract": "Conditional masked language models (CMLM) have shown impressive progress in\nnon-autoregressive machine translation (NAT). They learn the conditional\ntranslation model by predicting the random masked subset in the target\nsentence. Based on the CMLM framework, we introduce Multi-view Subset\nRegularization (MvSR), a novel regularization method to improve the performance\nof the NAT model. Specifically, MvSR consists of two parts: (1) \\textit{shared\nmask consistency}: we forward the same target with different mask strategies,\nand encourage the predictions of shared mask positions to be consistent with\neach other. (2) \\textit{model consistency}, we maintain an exponential moving\naverage of the model weights, and enforce the predictions to be consistent\nbetween the average model and the online model. Without changing the CMLM-based\narchitecture, our approach achieves remarkable performance on three public\nbenchmarks with 0.36-1.14 BLEU gains over previous NAT models. Moreover,\ncompared with the stronger Transformer baseline, we reduce the gap to 0.01-0.44\nBLEU scores on small datasets (WMT16 RO$\\leftrightarrow$EN and IWSLT\nDE$\\rightarrow$EN).", "published": "2021-08-19 02:30:38", "link": "http://arxiv.org/abs/2108.08447v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Augmenting Slot Values and Contexts for Spoken Language Understanding\n  with Pretrained Models", "abstract": "Spoken Language Understanding (SLU) is one essential step in building a\ndialogue system. Due to the expensive cost of obtaining the labeled data, SLU\nsuffers from the data scarcity problem. Therefore, in this paper, we focus on\ndata augmentation for slot filling task in SLU. To achieve that, we aim at\ngenerating more diverse data based on existing data. Specifically, we try to\nexploit the latent language knowledge from pretrained language models by\nfinetuning them. We propose two strategies for finetuning process: value-based\nand context-based augmentation. Experimental results on two public SLU datasets\nhave shown that compared with existing data augmentation methods, our proposed\nmethod can generate more diverse sentences and significantly improve the\nperformance on SLU.", "published": "2021-08-19 02:52:40", "link": "http://arxiv.org/abs/2108.08451v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attentive fine-tuning of Transformers for Translation of low-resourced\n  languages @LoResMT 2021", "abstract": "This paper reports the Machine Translation (MT) systems submitted by the\nIIITT team for the English->Marathi and English->Irish language pairs LoResMT\n2021 shared task. The task focuses on getting exceptional translations for\nrather low-resourced languages like Irish and Marathi. We fine-tune IndicTrans,\na pretrained multilingual NMT model for English->Marathi, using external\nparallel corpus as input for additional training. We have used a pretrained\nHelsinki-NLP Opus MT English->Irish model for the latter language pair. Our\napproaches yield relatively promising results on the BLEU metrics. Under the\nteam name IIITT, our systems ranked 1, 1, and 2 in English->Marathi,\nIrish->English, and English->Irish, respectively.", "published": "2021-08-19 08:46:14", "link": "http://arxiv.org/abs/2108.08556v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-Grained Element Identification in Complaint Text of Internet Fraud", "abstract": "Existing system dealing with online complaint provides a final decision\nwithout explanations. We propose to analyse the complaint text of internet\nfraud in a fine-grained manner. Considering the complaint text includes\nmultiple clauses with various functions, we propose to identify the role of\neach clause and classify them into different types of fraud element. We\nconstruct a large labeled dataset originated from a real finance service\nplatform. We build an element identification model on top of BERT and propose\nadditional two modules to utilize the context of complaint text for better\nelement label classification, namely, global context encoder and label refiner.\nExperimental results show the effectiveness of our model.", "published": "2021-08-19 13:33:09", "link": "http://arxiv.org/abs/2108.08676v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Legislative Recipe: Syntax for Machine-Readable Legislation", "abstract": "Legal interpretation is a linguistic venture. In judicial opinions, for\nexample, courts are often asked to interpret the text of statutes and\nlegislation. As time has shown, this is not always as easy as it sounds.\nMatters can hinge on vague or inconsistent language and, under the surface,\nhuman biases can impact the decision-making of judges. This raises an important\nquestion: what if there was a method of extracting the meaning of statutes\nconsistently? That is, what if it were possible to use machines to encode\nlegislation in a mathematically precise form that would permit clearer\nresponses to legal questions? This article attempts to unpack the notion of\nmachine-readability, providing an overview of both its historical and recent\ndevelopments. The paper will reflect on logic syntax and symbolic language to\nassess the capacity and limits of representing legal knowledge. In doing so,\nthe paper seeks to move beyond existing literature to discuss the implications\nof various approaches to machine-readable legislation. Importantly, this study\nhopes to highlight the challenges encountered in this burgeoning ecosystem of\nmachine-readable legislation against existing human-readable counterparts.", "published": "2021-08-19 13:40:35", "link": "http://arxiv.org/abs/2108.08678v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DESYR: Definition and Syntactic Representation Based Claim Detection on\n  the Web", "abstract": "The formulation of a claim rests at the core of argument mining. To demarcate\nbetween a claim and a non-claim is arduous for both humans and machines, owing\nto latent linguistic variance between the two and the inadequacy of extensive\ndefinition-based formalization. Furthermore, the increase in the usage of\nonline social media has resulted in an explosion of unsolicited information on\nthe web presented as informal text. To account for the aforementioned, in this\npaper, we proposed DESYR. It is a framework that intends on annulling the said\nissues for informal web-based text by leveraging a combination of hierarchical\nrepresentation learning (dependency-inspired Poincare embedding),\ndefinition-based alignment, and feature projection. We do away with fine-tuning\ncomputer-heavy language models in favor of fabricating a more domain-centric\nbut lighter approach. Experimental results indicate that DESYR builds upon the\nstate-of-the-art system across four benchmark claim datasets, most of which\nwere constructed with informal texts. We see an increase of 3 claim-F1 points\non the LESA-Twitter dataset, an increase of 1 claim-F1 point and 9 macro-F1\npoints on the Online Comments(OC) dataset, an increase of 24 claim-F1 points\nand 17 macro-F1 points on the Web Discourse(WD) dataset, and an increase of 8\nclaim-F1 points and 5 macro-F1 points on the Micro Texts(MT) dataset. We also\nperform an extensive analysis of the results. We make a 100-D pre-trained\nversion of our Poincare-variant along with the source code.", "published": "2021-08-19 16:00:13", "link": "http://arxiv.org/abs/2108.08759v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text\n  Models", "abstract": "We provide the first exploration of sentence embeddings from text-to-text\ntransformers (T5). Sentence embeddings are broadly useful for language\nprocessing tasks. While T5 achieves impressive performance on language tasks\ncast as sequence-to-sequence mapping problems, it is unclear how to produce\nsentence embeddings from encoder-decoder models. We investigate three methods\nfor extracting T5 sentence embeddings: two utilize only the T5 encoder and one\nuses the full T5 encoder-decoder model. To support our investigation, we\nestablish a new sentence representation transfer benchmark, SentGLUE, which\nextends the SentEval toolkit to nine tasks from the GLUE benchmark. Our\nencoder-only models outperforms Sentence-BERT and SimCSE sentence embeddings on\nboth SentEval and SentGLUE transfer tasks, including semantic textual\nsimilarity (STS). Scaling up T5 from millions to billions of parameters is\nfound to produce consistent further improvements. Finally, our encoder-decoder\nmethod achieves a new state-of-the-art on STS when using sentence embeddings.\nOur models are released at https://tfhub.dev/google/collections/sentence-t5/1.", "published": "2021-08-19 18:58:02", "link": "http://arxiv.org/abs/2108.08877v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Hateful are Movies? A Study and Prediction on Movie Subtitles", "abstract": "In this research, we investigate techniques to detect hate speech in movies.\nWe introduce a new dataset collected from the subtitles of six movies, where\neach utterance is annotated either as hate, offensive or normal. We apply\ntransfer learning techniques of domain adaptation and fine-tuning on existing\nsocial media datasets, namely from Twitter and Fox News. We evaluate different\nrepresentations, i.e., Bag of Words (BoW), Bi-directional Long short-term\nmemory (Bi-LSTM), and Bidirectional Encoder Representations from Transformers\n(BERT) on 11k movie subtitles. The BERT model obtained the best macro-averaged\nF1-score of 77%. Hence, we show that transfer learning from the social media\ndomain is efficacious in classifying hate and offensive speech in movies\nthrough subtitles.", "published": "2021-08-19 16:07:08", "link": "http://arxiv.org/abs/2108.10724v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Model Augmented Relevance Score", "abstract": "Although automated metrics are commonly used to evaluate NLG systems, they\noften correlate poorly with human judgements. Newer metrics such as BERTScore\nhave addressed many weaknesses in prior metrics such as BLEU and ROUGE, which\nrely on n-gram matching. These newer methods, however, are still limited in\nthat they do not consider the generation context, so they cannot properly\nreward generated text that is correct but deviates from the given reference.\n  In this paper, we propose Language Model Augmented Relevance Score (MARS), a\nnew context-aware metric for NLG evaluation. MARS leverages off-the-shelf\nlanguage models, guided by reinforcement learning, to create augmented\nreferences that consider both the generation context and available human\nreferences, which are then used as additional references to score generated\ntext. Compared with seven existing metrics in three common NLG tasks, MARS not\nonly achieves higher correlation with human reference judgements, but also\ndifferentiates well-formed candidates from adversarial samples to a larger\ndegree.", "published": "2021-08-19 03:59:23", "link": "http://arxiv.org/abs/2108.08485v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Beyond NED: Fast and Effective Search Space Reduction for Complex\n  Question Answering over Knowledge Bases", "abstract": "Answering complex questions over knowledge bases (KB-QA) faces huge input\ndata with billions of facts, involving millions of entities and thousands of\npredicates. For efficiency, QA systems first reduce the answer search space by\nidentifying a set of facts that is likely to contain all answers and relevant\ncues. The most common technique for doing this is to apply named entity\ndisambiguation (NED) systems to the question, and retrieve KB facts for the\ndisambiguated entities. This work presents CLOCQ, an efficient method that\nprunes irrelevant parts of the search space using KB-aware signals. CLOCQ uses\na top-k query processor over score-ordered lists of KB items that combine\nsignals about lexical matching, relevance to the question, coherence among\ncandidate items, and connectivity in the KB graph. Experiments with two recent\nQA benchmarks for complex questions demonstrate the superiority of CLOCQ over\nstate-of-the-art baselines with respect to answer presence, size of the search\nspace, and runtimes.", "published": "2021-08-19 10:06:14", "link": "http://arxiv.org/abs/2108.08597v9", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "UNIQORN: Unified Question Answering over RDF Knowledge Graphs and\n  Natural Language Text", "abstract": "Question answering over RDF data like knowledge graphs has been greatly\nadvanced, with a number of good systems providing crisp answers for natural\nlanguage questions or telegraphic queries. Some of these systems incorporate\ntextual sources as additional evidence for the answering process, but cannot\ncompute answers that are present in text alone. Conversely, the IR and NLP\ncommunities have addressed QA over text, but such systems barely utilize\nsemantic data and knowledge. This paper presents a method for complex questions\nthat can seamlessly operate over a mixture of RDF datasets and text corpora, or\nindividual sources, in a unified framework. Our method, called UNIQORN, builds\na context graph on-the-fly, by retrieving question-relevant evidences from the\nRDF data and/or a text corpus, using fine-tuned BERT models. The resulting\ngraph typically contains all question-relevant evidences but also a lot of\nnoise. UNIQORN copes with this input by a graph algorithm for Group Steiner\nTrees, that identifies the best answer candidates in the context graph.\nExperimental results on several benchmarks of complex questions with multiple\nentities and relations, show that UNIQORN significantly outperforms\nstate-of-the-art methods for heterogeneous QA - in a full training mode, as\nwell as in zero-shot settings. The graph-based methodology provides\nuser-interpretable evidence for the complete answering process.", "published": "2021-08-19 10:50:52", "link": "http://arxiv.org/abs/2108.08614v11", "categories": ["cs.IR", "cs.CL", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Contrastive Language-Image Pre-training for the Italian Language", "abstract": "CLIP (Contrastive Language-Image Pre-training) is a very recent multi-modal\nmodel that jointly learns representations of images and texts. The model is\ntrained on a massive amount of English data and shows impressive performance on\nzero-shot classification tasks. Training the same model on a different language\nis not trivial, since data in other languages might be not enough and the model\nneeds high-quality translations of the texts to guarantee a good performance.\nIn this paper, we present the first CLIP model for the Italian Language\n(CLIP-Italian), trained on more than 1.4 million image-text pairs. Results show\nthat CLIP-Italian outperforms the multilingual CLIP model on the tasks of image\nretrieval and zero-shot classification.", "published": "2021-08-19 13:53:47", "link": "http://arxiv.org/abs/2108.08688v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Mr. TyDi: A Multi-lingual Benchmark for Dense Retrieval", "abstract": "We present Mr. TyDi, a multi-lingual benchmark dataset for mono-lingual\nretrieval in eleven typologically diverse languages, designed to evaluate\nranking with learned dense representations. The goal of this resource is to\nspur research in dense retrieval techniques in non-English languages, motivated\nby recent observations that existing techniques for representation learning\nperform poorly when applied to out-of-distribution data. As a starting point,\nwe provide zero-shot baselines for this new dataset based on a multi-lingual\nadaptation of DPR that we call \"mDPR\". Experiments show that although the\neffectiveness of mDPR is much lower than BM25, dense representations\nnevertheless appear to provide valuable relevance signals, improving BM25\nresults in sparse-dense hybrids. In addition to analyses of our results, we\nalso discuss future challenges and present a research agenda in multi-lingual\ndense retrieval. Mr. TyDi can be downloaded at\nhttps://github.com/castorini/mr.tydi.", "published": "2021-08-19 16:53:43", "link": "http://arxiv.org/abs/2108.08787v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Framework for Neural Topic Modeling of Text Corpora", "abstract": "Topic Modeling refers to the problem of discovering the main topics that have\noccurred in corpora of textual data, with solutions finding crucial\napplications in numerous fields. In this work, inspired by the recent\nadvancements in the Natural Language Processing domain, we introduce FAME, an\nopen-source framework enabling an efficient mechanism of extracting and\nincorporating textual features and utilizing them in discovering topics and\nclustering text documents that are semantically similar in a corpus. These\nfeatures range from traditional approaches (e.g., frequency-based) to the most\nrecent auto-encoding embeddings from transformer-based language models such as\nBERT model family. To demonstrate the effectiveness of this library, we\nconducted experiments on the well-known News-Group dataset. The library is\navailable online.", "published": "2021-08-19 23:32:38", "link": "http://arxiv.org/abs/2108.08946v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "QUEACO: Borrowing Treasures from Weakly-labeled Behavior Data for Query\n  Attribute Value Extraction", "abstract": "We study the problem of query attribute value extraction, which aims to\nidentify named entities from user queries as diverse surface form attribute\nvalues and afterward transform them into formally canonical forms. Such a\nproblem consists of two phases: {named entity recognition (NER)} and {attribute\nvalue normalization (AVN)}. However, existing works only focus on the NER phase\nbut neglect equally important AVN. To bridge this gap, this paper proposes a\nunified query attribute value extraction system in e-commerce search named\nQUEACO, which involves both two phases. Moreover, by leveraging large-scale\nweakly-labeled behavior data, we further improve the extraction performance\nwith less supervision cost. Specifically, for the NER phase, QUEACO adopts a\nnovel teacher-student network, where a teacher network that is trained on the\nstrongly-labeled data generates pseudo-labels to refine the weakly-labeled data\nfor training a student network. Meanwhile, the teacher network can be\ndynamically adapted by the feedback of the student's performance on\nstrongly-labeled data to maximally denoise the noisy supervisions from the weak\nlabels. For the AVN phase, we also leverage the weakly-labeled\nquery-to-attribute behavior data to normalize surface form attribute values\nfrom queries into canonical forms from products. Extensive experiments on a\nreal-world large-scale E-commerce dataset demonstrate the effectiveness of\nQUEACO.", "published": "2021-08-19 03:24:23", "link": "http://arxiv.org/abs/2108.08468v3", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Czech News Dataset for Semantic Textual Similarity", "abstract": "This paper describes a novel dataset consisting of sentences with semantic\nsimilarity annotations. The data originate from the journalistic domain in the\nCzech language. We describe the process of collecting and annotating the data\nin detail. The dataset contains 138,556 human annotations divided into train\nand test sets. In total, 485 journalism students participated in the creation\nprocess. To increase the reliability of the test set, we compute the annotation\nas an average of 9 individual annotations. We evaluate the quality of the\ndataset by measuring inter and intra annotation annotators' agreements. Beside\nagreement numbers, we provide detailed statistics of the collected dataset. We\nconclude our paper with a baseline experiment of building a system for\npredicting the semantic similarity of sentences. Due to the massive number of\ntraining annotations (116 956), the model can perform significantly better than\nan average annotator (0,92 versus 0,86 of Person's correlation coefficients).", "published": "2021-08-19 14:20:17", "link": "http://arxiv.org/abs/2108.08708v3", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Unsupervised Cross-Lingual Speech Emotion Recognition Using Pseudo\n  Multilabel", "abstract": "Speech Emotion Recognition (SER) in a single language has achieved remarkable\nresults through deep learning approaches in the last decade. However,\ncross-lingual SER remains a challenge in real-world applications due to a great\ndifference between the source and target domain distributions. To address this\nissue, we propose an unsupervised cross-lingual Neural Network with Pseudo\nMultilabel (NNPM) that is trained to learn the emotion similarities between\nsource domain features inside an external memory adjusted to identify emotion\nin cross-lingual databases. NNPM introduces a novel approach that leverages\nexternal memory to store source domain features and generates pseudo multilabel\nfor each target domain data by computing the similarities between the external\nmemory and the target domain features. We evaluate our approach on multiple\ndifferent languages of speech emotion databases. Experimental results show our\nproposed approach significantly improves the weighted accuracy (WA) across\nmultiple low-resource languages on Urdu, Skropus, ShEMO, and EMO-DB corpus. To\nfacilitate further research, code is available at\nhttps://github.com/happyjin/NNPM", "published": "2021-08-19 12:49:35", "link": "http://arxiv.org/abs/2108.08663v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "More for Less: Non-Intrusive Speech Quality Assessment with Limited\n  Annotations", "abstract": "Non-intrusive speech quality assessment is a crucial operation in multimedia\napplications. The scarcity of annotated data and the lack of a reference signal\nrepresent some of the main challenges for designing efficient quality\nassessment metrics. In this paper, we propose two multi-task models to tackle\nthe problems above. In the first model, we first learn a feature representation\nwith a degradation classifier on a large dataset. Then we perform MOS\nprediction and degradation classification simultaneously on a small dataset\nannotated with MOS. In the second approach, the initial stage consists of\nlearning features with a deep clustering-based unsupervised feature\nrepresentation on the large dataset. Next, we perform MOS prediction and\ncluster label classification simultaneously on a small dataset. The results\nshow that the deep clustering-based model outperforms the degradation\nclassifier-based model and the 3 baselines (autoencoder features, P.563, and\nSRMRnorm) on TCD-VoIP. This paper indicates that multi-task learning combined\nwith feature representations from unlabelled data is a promising approach to\ndeal with the lack of large MOS annotated datasets.", "published": "2021-08-19 15:20:26", "link": "http://arxiv.org/abs/2108.08745v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ChMusic: A Traditional Chinese Music Dataset for Evaluation of\n  Instrument Recognition", "abstract": "Musical instruments recognition is a widely used application for music\ninformation retrieval. As most of previous musical instruments recognition\ndataset focus on western musical instruments, it is difficult for researcher to\nstudy and evaluate the area of traditional Chinese musical instrument\nrecognition. This paper propose a traditional Chinese music dataset for\ntraining model and performance evaluation, named ChMusic. This dataset is free\nand publicly available, 11 traditional Chinese musical instruments and 55\ntraditional Chinese music excerpts are recorded in this dataset. Then an\nevaluation standard is proposed based on ChMusic dataset. With this standard,\nresearchers can compare their results following the same rule, and results from\ndifferent researchers will become comparable.", "published": "2021-08-19 03:26:32", "link": "http://arxiv.org/abs/2108.08470v2", "categories": ["eess.AS", "cs.AI", "cs.MM", "eess.SP"], "primary_category": "eess.AS"}
