{"title": "A Review of Human Evaluation for Style Transfer", "abstract": "This paper reviews and summarizes human evaluation practices described in 97\nstyle transfer papers with respect to three main evaluation aspects: style\ntransfer, meaning preservation, and fluency. In principle, evaluations by human\nraters should be the most reliable. However, in style transfer papers, we find\nthat protocols for human evaluations are often underspecified and not\nstandardized, which hampers the reproducibility of research in this field and\nprogress toward better human and automatic evaluation methods.", "published": "2021-06-09 00:29:42", "link": "http://arxiv.org/abs/2106.04747v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Making Better Use of Bilingual Information for Cross-Lingual AMR Parsing", "abstract": "Abstract Meaning Representation (AMR) is a rooted, labeled, acyclic graph\nrepresenting the semantics of natural language. As previous works show,\nalthough AMR is designed for English at first, it can also represent semantics\nin other languages. However, they find that concepts in their predicted AMR\ngraphs are less specific. We argue that the misprediction of concepts is due to\nthe high relevance between English tokens and AMR concepts. In this work, we\nintroduce bilingual input, namely the translated texts as well as non-English\ntexts, in order to enable the model to predict more accurate concepts. Besides,\nwe also introduce an auxiliary task, requiring the decoder to predict the\nEnglish sequences at the same time. The auxiliary task can help the decoder\nunderstand what exactly the corresponding English tokens are. Our proposed\ncross-lingual AMR parser surpasses previous state-of-the-art parser by 10.6\npoints on Smatch F1 score. The ablation study also demonstrates the efficacy of\nour proposed modules.", "published": "2021-06-09 05:14:54", "link": "http://arxiv.org/abs/2106.04814v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Catchphrase: Automatic Detection of Cultural References", "abstract": "A snowclone is a customizable phrasal template that can be realized in\nmultiple, instantly recognized variants. For example, ``* is the new *\" (Orange\nis the new black, 40 is the new 30). Snowclones are extensively used in social\nmedia. In this paper, we study snowclones originating from pop-culture quotes;\nour goal is to automatically detect cultural references in text. We introduce a\nnew, publicly available data set of pop-culture quotes and their corresponding\nsnowclone usages and train models on them. We publish code for Catchphrase, an\ninternet browser plugin to automatically detect and mark references in\nreal-time, and examine its performance via a user study. Aside from assisting\npeople to better comprehend cultural references, we hope that detecting\nsnowclones can complement work on paraphrasing and help to tackle long-standing\nquestions in social science about the dynamics of information propagation.", "published": "2021-06-09 06:31:59", "link": "http://arxiv.org/abs/2106.04830v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MICE: A Crosslinguistic Emotion Corpus in Malay, Indonesian, Chinese and\n  English", "abstract": "MICE is a corpus of emotion words in four languages which is currently\nworking progress. There are two sections to this study, Part I: Emotion word\ncorpus and Part II: Emotion word survey. In Part 1, the method of how the\nemotion data is culled for each of the four languages will be described and\nvery preliminary data will be presented. In total, we identified 3,750 emotion\nexpressions in Malay, 6,657 in Indonesian, 3,347 in Mandarin Chinese and 8,683\nin English. We are currently evaluating and double checking the corpus and\ndoing further analysis on the distribution of these emotion expressions. Part\nII Emotion word survey involved an online language survey which collected\ninformation on how speakers assigned the emotion words into basic emotion\ncategories, the rating for valence and intensity as well as biographical\ninformation of all the respondents.", "published": "2021-06-09 06:33:30", "link": "http://arxiv.org/abs/2106.04831v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing Multilingual Language Models for Discourse", "abstract": "Pre-trained multilingual language models have become an important building\nblock in multilingual natural language processing. In the present paper, we\ninvestigate a range of such models to find out how well they transfer\ndiscourse-level knowledge across languages. This is done with a systematic\nevaluation on a broader set of discourse-level tasks than has been previously\nbeen assembled. We find that the XLM-RoBERTa family of models consistently show\nthe best performance, by simultaneously being good monolingual models and\ndegrading relatively little in a zero-shot setting. Our results also indicate\nthat model distillation may hurt the ability of cross-lingual transfer of\nsentence representations, while language dissimilarity at most has a modest\neffect. We hope that our test suite, covering 5 tasks with a total of 22\nlanguages in 10 distinct families, will serve as a useful evaluation platform\nfor multilingual performance at and beyond the sentence level.", "published": "2021-06-09 06:34:21", "link": "http://arxiv.org/abs/2106.04832v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UniKeyphrase: A Unified Extraction and Generation Framework for\n  Keyphrase Prediction", "abstract": "Keyphrase Prediction (KP) task aims at predicting several keyphrases that can\nsummarize the main idea of the given document. Mainstream KP methods can be\ncategorized into purely generative approaches and integrated models with\nextraction and generation. However, these methods either ignore the diversity\namong keyphrases or only weakly capture the relation across tasks implicitly.\nIn this paper, we propose UniKeyphrase, a novel end-to-end learning framework\nthat jointly learns to extract and generate keyphrases. In UniKeyphrase,\nstacked relation layer and bag-of-words constraint are proposed to fully\nexploit the latent semantic relation between extraction and generation in the\nview of model structure and training process, respectively. Experiments on KP\nbenchmarks demonstrate that our joint approach outperforms mainstream methods\nby a large margin.", "published": "2021-06-09 07:09:51", "link": "http://arxiv.org/abs/2106.04847v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DravidianMultiModality: A Dataset for Multi-modal Sentiment Analysis in\n  Tamil and Malayalam", "abstract": "Human communication is inherently multimodal and asynchronous. Analyzing\nhuman emotions and sentiment is an emerging field of artificial intelligence.\nWe are witnessing an increasing amount of multimodal content in local languages\non social media about products and other topics. However, there are not many\nmultimodal resources available for under-resourced Dravidian languages. Our\nstudy aims to create a multimodal sentiment analysis dataset for the\nunder-resourced Tamil and Malayalam languages. First, we downloaded product or\nmovies review videos from YouTube for Tamil and Malayalam. Next, we created\ncaptions for the videos with the help of annotators. Then we labelled the\nvideos for sentiment, and verified the inter-annotator agreement using Fleiss's\nKappa. This is the first multimodal sentiment analysis dataset for Tamil and\nMalayalam by volunteer annotators.", "published": "2021-06-09 07:25:26", "link": "http://arxiv.org/abs/2106.04853v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fragmented and Valuable: Following Sentiment Changes in Food Tweets", "abstract": "We analysed sentiment and frequencies related to smell, taste and temperature\nexpressed by food tweets in the Latvian language. To get a better understanding\nof the role of smell, taste and temperature in the mental map of food\nassociations, we looked at such categories as 'tasty' and 'healthy', which\nturned out to be mutually exclusive. By analysing the occurrence frequency of\nwords associated with these categories, we discovered that food discourse\noverall was permeated by `tasty' while the category of 'healthy' was relatively\nsmall. Finally, we used the analysis of temporal dynamics to see if we can\ntrace seasonality or other temporal aspects in smell, taste and temperature as\nreflected in food tweets. Understanding the composition of social media content\nwith relation to smell, taste and temperature in food tweets allows us to\ndevelop our work further - on food culture/seasonality and its relation to\ntemperature, on our limited capacity to express smell-related sentiments, and\nthe lack of the paradigm of taste in discussing food healthiness.", "published": "2021-06-09 08:42:14", "link": "http://arxiv.org/abs/2106.04903v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Auto-tagging of Short Conversational Sentences using Natural Language\n  Processing Methods", "abstract": "In this study, we aim to find a method to auto-tag sentences specific to a\ndomain. Our training data comprises short conversational sentences extracted\nfrom chat conversations between company's customer representatives and web site\nvisitors. We manually tagged approximately 14 thousand visitor inputs into ten\nbasic categories, which will later be used in a transformer-based language\nmodel with attention mechanisms for the ultimate goal of developing a chatbot\napplication that can produce meaningful dialogue. We considered three different\nstate-of-the-art models and reported their auto-tagging capabilities. We\nachieved the best performance with the bidirectional encoder representation\nfrom transformers (BERT) model. Implementation of the models used in these\nexperiments can be cloned from our GitHub repository and tested for similar\nauto-tagging problems without much effort.", "published": "2021-06-09 10:14:05", "link": "http://arxiv.org/abs/2106.04959v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Psycholinguistic Tripartite Graph Network for Personality Detection", "abstract": "Most of the recent work on personality detection from online posts adopts\nmultifarious deep neural networks to represent the posts and builds predictive\nmodels in a data-driven manner, without the exploitation of psycholinguistic\nknowledge that may unveil the connections between one's language usage and his\npsychological traits. In this paper, we propose a psycholinguistic\nknowledge-based tripartite graph network, TrigNet, which consists of a\ntripartite graph network and a BERT-based graph initializer. The graph network\ninjects structural psycholinguistic knowledge from LIWC, a computerized\ninstrument for psycholinguistic analysis, by constructing a heterogeneous\ntripartite graph. The graph initializer is employed to provide initial\nembeddings for the graph nodes. To reduce the computational cost in graph\nlearning, we further propose a novel flow graph attention network (GAT) that\nonly transmits messages between neighboring parties in the tripartite graph.\nBenefiting from the tripartite graph, TrigNet can aggregate post information\nfrom a psychological perspective, which is a novel way of exploiting domain\nknowledge. Extensive experiments on two datasets show that TrigNet outperforms\nthe existing state-of-art model by 3.47 and 2.10 points in average F1.\nMoreover, the flow GAT reduces the FLOPS and Memory measures by 38% and 32%,\nrespectively, in comparison to the original GAT in our setting.", "published": "2021-06-09 10:18:50", "link": "http://arxiv.org/abs/2106.04963v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack\n  Exchange Data", "abstract": "Most available semantic parsing datasets, comprising of pairs of natural\nutterances and logical forms, were collected solely for the purpose of training\nand evaluation of natural language understanding systems. As a result, they do\nnot contain any of the richness and variety of natural-occurring utterances,\nwhere humans ask about data they need or are curious about. In this work, we\nrelease SEDE, a dataset with 12,023 pairs of utterances and SQL queries\ncollected from real usage on the Stack Exchange website. We show that these\npairs contain a variety of real-world challenges which were rarely reflected so\nfar in any other semantic parsing dataset, propose an evaluation metric based\non comparison of partial query clauses that is more suitable for real-world\nqueries, and conduct experiments with strong baselines, showing a large gap\nbetween the performance on SEDE compared to other common datasets.", "published": "2021-06-09 12:09:51", "link": "http://arxiv.org/abs/2106.05006v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AUGVIC: Exploiting BiText Vicinity for Low-Resource NMT", "abstract": "The success of Neural Machine Translation (NMT) largely depends on the\navailability of large bitext training corpora. Due to the lack of such large\ncorpora in low-resource language pairs, NMT systems often exhibit poor\nperformance. Extra relevant monolingual data often helps, but acquiring it\ncould be quite expensive, especially for low-resource languages. Moreover,\ndomain mismatch between bitext (train/test) and monolingual data might degrade\nthe performance. To alleviate such issues, we propose AUGVIC, a novel data\naugmentation framework for low-resource NMT which exploits the vicinal samples\nof the given bitext without using any extra monolingual data explicitly. It can\ndiversify the in-domain bitext data with finer level control. Through extensive\nexperiments on four low-resource language pairs comprising data from different\ndomains, we have shown that our method is comparable to the traditional\nback-translation that uses extra in-domain monolingual data. When we combine\nthe synthetic parallel data generated from AUGVIC with the ones from the extra\nmonolingual data, we achieve further improvements. We show that AUGVIC helps to\nattenuate the discrepancies between relevant and distant-domain monolingual\ndata in traditional back-translation. To understand the contributions of\ndifferent components of AUGVIC, we perform an in-depth framework analysis.", "published": "2021-06-09 15:29:18", "link": "http://arxiv.org/abs/2106.05141v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Case Studies on using Natural Language Processing Techniques in Customer\n  Relationship Management Software", "abstract": "How can a text corpus stored in a customer relationship management (CRM)\ndatabase be used for data mining and segmentation? In order to answer this\nquestion we inherited the state of the art methods commonly used in natural\nlanguage processing (NLP) literature, such as word embeddings, and deep\nlearning literature, such as recurrent neural networks (RNN). We used the text\nnotes from a CRM system which are taken by customer representatives of an\ninternet ads consultancy agency between years 2009 and 2020. We trained word\nembeddings by using the corresponding text corpus and showed that these word\nembeddings can not only be used directly for data mining but also be used in\nRNN architectures, which are deep learning frameworks built with long short\nterm memory (LSTM) units, for more comprehensive segmentation objectives. The\nresults prove that structured text data in a CRM can be used to mine out very\nvaluable information and any CRM can be equipped with useful NLP features once\nthe problem definitions are properly built and the solution methods are\nconveniently implemented.", "published": "2021-06-09 16:07:07", "link": "http://arxiv.org/abs/2106.05160v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Multilingual Representation for Natural Language Understanding\n  with Enhanced Cross-Lingual Supervision", "abstract": "Recently, pre-training multilingual language models has shown great potential\nin learning multilingual representation, a crucial topic of natural language\nprocessing. Prior works generally use a single mixed attention (MA) module,\nfollowing TLM (Conneau and Lample, 2019), for attending to intra-lingual and\ncross-lingual contexts equivalently and simultaneously. In this paper, we\npropose a network named decomposed attention (DA) as a replacement of MA. The\nDA consists of an intra-lingual attention (IA) and a cross-lingual attention\n(CA), which model intralingual and cross-lingual supervisions respectively. In\naddition, we introduce a language-adaptive re-weighting strategy during\ntraining to further boost the model's performance. Experiments on various\ncross-lingual natural language understanding (NLU) tasks show that the proposed\narchitecture and learning strategy significantly improve the model's\ncross-lingual transferability.", "published": "2021-06-09 16:12:13", "link": "http://arxiv.org/abs/2106.05166v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Would a Teacher Do? Predicting Future Talk Moves", "abstract": "Recent advances in natural language processing (NLP) have the ability to\ntransform how classroom learning takes place. Combined with the increasing\nintegration of technology in today's classrooms, NLP systems leveraging\nquestion answering and dialog processing techniques can serve as private tutors\nor participants in classroom discussions to increase student engagement and\nlearning. To progress towards this goal, we use the classroom discourse\nframework of academically productive talk (APT) to learn strategies that make\nfor the best learning experience. In this paper, we introduce a new task,\ncalled future talk move prediction (FTMP): it consists of predicting the next\ntalk move -- an utterance strategy from APT -- given a conversation history\nwith its corresponding talk moves. We further introduce a neural network model\nfor this task, which outperforms multiple baselines by a large margin. Finally,\nwe compare our model's performance on FTMP to human performance and show\nseveral similarities between the two.", "published": "2021-06-09 17:45:16", "link": "http://arxiv.org/abs/2106.05249v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Key Information Extraction From Documents: Evaluation And Generator", "abstract": "Extracting information from documents usually relies on natural language\nprocessing methods working on one-dimensional sequences of text. In some cases,\nfor example, for the extraction of key information from semi-structured\ndocuments, such as invoice-documents, spatial and formatting information of\ntext are crucial to understand the contextual meaning. Convolutional neural\nnetworks are already common in computer vision models to process and extract\nrelationships in multidimensional data. Therefore, natural language processing\nmodels have already been combined with computer vision models in the past, to\nbenefit from e.g. positional information and to improve performance of these\nkey information extraction models. Existing models were either trained on\nunpublished data sets or on an annotated collection of receipts, which did not\nfocus on PDF-like documents. Hence, in this research project a template-based\ndocument generator was created to compare state-of-the-art models for\ninformation extraction. An existing information extraction model \"Chargrid\"\n(Katti et al., 2019) was reconstructed and the impact of a bounding box\nregression decoder, as well as the impact of an NLP pre-processing step was\nevaluated for information extraction from documents. The results have shown\nthat NLP based pre-processing is beneficial for model performance. However, the\nuse of a bounding box regression decoder increases the model performance only\nfor fields that do not follow a rectangular shape.", "published": "2021-06-09 16:12:21", "link": "http://arxiv.org/abs/2106.14624v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Sample Based Explanation Methods for NLP:Efficiency, Faithfulness,\n  and Semantic Evaluation", "abstract": "In the recent advances of natural language processing, the scale of the\nstate-of-the-art models and datasets is usually extensive, which challenges the\napplication of sample-based explanation methods in many aspects, such as\nexplanation interpretability, efficiency, and faithfulness. In this work, for\nthe first time, we can improve the interpretability of explanations by allowing\narbitrary text sequences as the explanation unit. On top of this, we implement\na hessian-free method with a model faithfulness guarantee. Finally, to compare\nour method with the others, we propose a semantic-based evaluation metric that\ncan better align with humans' judgment of explanations than the widely adopted\ndiagnostic or re-training measures. The empirical results on multiple real data\nsets demonstrate the proposed method's superior performance to popular\nexplanation techniques such as Influence Function or TracIn on semantic\nevaluation.", "published": "2021-06-09 00:49:56", "link": "http://arxiv.org/abs/2106.04753v1", "categories": ["cs.CL", "cs.AI", "I.2"], "primary_category": "cs.CL"}
{"title": "Sentence Embeddings using Supervised Contrastive Learning", "abstract": "Sentence embeddings encode sentences in fixed dense vectors and have played\nan important role in various NLP tasks and systems. Methods for building\nsentence embeddings include unsupervised learning such as Quick-Thoughts and\nsupervised learning such as InferSent. With the success of pretrained NLP\nmodels, recent research shows that fine-tuning pretrained BERT on SNLI and\nMulti-NLI data creates state-of-the-art sentence embeddings, outperforming\nprevious sentence embeddings methods on various evaluation benchmarks. In this\npaper, we propose a new method to build sentence embeddings by doing supervised\ncontrastive learning. Specifically our method fine-tunes pretrained BERT on\nSNLI data, incorporating both supervised crossentropy loss and supervised\ncontrastive loss. Compared with baseline where fine-tuning is only done with\nsupervised cross-entropy loss similar to current state-of-the-art method SBERT,\nour supervised contrastive method improves 2.8% in average on Semantic Textual\nSimilarity (STS) benchmarks and 1.05% in average on various sentence transfer\ntasks.", "published": "2021-06-09 03:30:29", "link": "http://arxiv.org/abs/2106.04791v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Joint System-Wise Optimization for Pipeline Goal-Oriented Dialog System", "abstract": "Recent work (Takanobu et al., 2020) proposed the system-wise evaluation on\ndialog systems and found that improvement on individual components (e.g., NLU,\npolicy) in prior work may not necessarily bring benefit to pipeline systems in\nsystem-wise evaluation. To improve the system-wise performance, in this paper,\nwe propose new joint system-wise optimization techniques for the pipeline\ndialog system. First, we propose a new data augmentation approach which\nautomates the labeling process for NLU training. Second, we propose a novel\nstochastic policy parameterization with Poisson distribution that enables\nbetter exploration and offers a principled way to compute policy gradient.\nThird, we propose a reward bonus to help policy explore successful dialogs. Our\napproaches outperform the competitive pipeline systems from Takanobu et al.\n(2020) by big margins of 12% success rate in automatic system-wise evaluation\nand of 16% success rate in human evaluation on the standard multi-domain\nbenchmark dataset MultiWOZ 2.1, and also outperform the recent state-of-the-art\nend-to-end trained model from DSTC9.", "published": "2021-06-09 06:44:57", "link": "http://arxiv.org/abs/2106.04835v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DGA-Net Dynamic Gaussian Attention Network for Sentence Semantic\n  Matching", "abstract": "Sentence semantic matching requires an agent to determine the semantic\nrelation between two sentences, where much recent progress has been made by the\nadvancement of representation learning techniques and inspiration of human\nbehaviors. Among all these methods, attention mechanism plays an essential role\nby selecting important parts effectively. However, current attention methods\neither focus on all the important parts in a static way or only select one\nimportant part at one attention step dynamically, which leaves a large space\nfor further improvement. To this end, in this paper, we design a novel Dynamic\nGaussian Attention Network (DGA-Net) to combine the advantages of current\nstatic and dynamic attention methods. More specifically, we first leverage\npre-trained language model to encode the input sentences and construct semantic\nrepresentations from a global perspective. Then, we develop a Dynamic Gaussian\nAttention (DGA) to dynamically capture the important parts and corresponding\nlocal contexts from a detailed perspective. Finally, we combine the global\ninformation and detailed local information together to decide the semantic\nrelation of sentences comprehensively and precisely. Extensive experiments on\ntwo popular sentence semantic matching tasks demonstrate that our proposed\nDGA-Net is effective in improving the ability of attention mechanism.", "published": "2021-06-09 08:43:04", "link": "http://arxiv.org/abs/2106.04905v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automatic Sexism Detection with Multilingual Transformer Models", "abstract": "Sexism has become an increasingly major problem on social networks during the\nlast years. The first shared task on sEXism Identification in Social neTworks\n(EXIST) at IberLEF 2021 is an international competition in the field of Natural\nLanguage Processing (NLP) with the aim to automatically identify sexism in\nsocial media content by applying machine learning methods. Thereby sexism\ndetection is formulated as a coarse (binary) classification problem and a\nfine-grained classification task that distinguishes multiple types of sexist\ncontent (e.g., dominance, stereotyping, and objectification). This paper\npresents the contribution of the AIT_FHSTP team at the EXIST2021 benchmark for\nboth tasks. To solve the tasks we applied two multilingual transformer models,\none based on multilingual BERT and one based on XLM-R. Our approach uses two\ndifferent strategies to adapt the transformers to the detection of sexist\ncontent: first, unsupervised pre-training with additional data and second,\nsupervised fine-tuning with additional and augmented data. For both tasks our\nbest model is XLM-R with unsupervised pre-training on the EXIST data and\nadditional datasets and fine-tuning on the provided dataset. The best run for\nthe binary classification (task 1) achieves a macro F1-score of 0.7752 and\nscores 5th rank in the benchmark; for the multiclass classification (task 2)\nour best submission scores 6th rank with a macro F1-score of 0.5589.", "published": "2021-06-09 08:45:51", "link": "http://arxiv.org/abs/2106.04908v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Instantaneous Grammatical Error Correction with Shallow Aggressive\n  Decoding", "abstract": "In this paper, we propose Shallow Aggressive Decoding (SAD) to improve the\nonline inference efficiency of the Transformer for instantaneous Grammatical\nError Correction (GEC). SAD optimizes the online inference efficiency for GEC\nby two innovations: 1) it aggressively decodes as many tokens as possible in\nparallel instead of always decoding only one token in each step to improve\ncomputational parallelism; 2) it uses a shallow decoder instead of the\nconventional Transformer architecture with balanced encoder-decoder depth to\nreduce the computational cost during inference. Experiments in both English and\nChinese GEC benchmarks show that aggressive decoding could yield the same\npredictions as greedy decoding but with a significant speedup for online\ninference. Its combination with the shallow decoder could offer an even higher\nonline inference speedup over the powerful Transformer baseline without quality\nloss. Not only does our approach allow a single model to achieve the\nstate-of-the-art results in English GEC benchmarks: 66.4 F0.5 in the CoNLL-14\nand 72.9 F0.5 in the BEA-19 test set with an almost 10x online inference\nspeedup over the Transformer-big model, but also it is easily adapted to other\nlanguages. Our code is available at\nhttps://github.com/AutoTemp/Shallow-Aggressive-Decoding.", "published": "2021-06-09 10:30:59", "link": "http://arxiv.org/abs/2106.04970v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Crosslingual Embeddings are Essential in UNMT for Distant Languages: An\n  English to IndoAryan Case Study", "abstract": "Recent advances in Unsupervised Neural Machine Translation (UNMT) have\nminimized the gap between supervised and unsupervised machine translation\nperformance for closely related language pairs. However, the situation is very\ndifferent for distant language pairs. Lack of lexical overlap and low syntactic\nsimilarities such as between English and Indo-Aryan languages leads to poor\ntranslation quality in existing UNMT systems. In this paper, we show that\ninitializing the embedding layer of UNMT models with cross-lingual embeddings\nshows significant improvements in BLEU score over existing approaches with\nembeddings randomly initialized. Further, static embeddings (freezing the\nembedding layer weights) lead to better gains compared to updating the\nembedding layer weights during training (non-static). We experimented using\nMasked Sequence to Sequence (MASS) and Denoising Autoencoder (DAE) UNMT\napproaches for three distant language pairs. The proposed cross-lingual\nembedding initialization yields BLEU score improvement of as much as ten times\nover the baseline for English-Hindi, English-Bengali, and English-Gujarati. Our\nanalysis shows the importance of cross-lingual embedding, comparisons between\napproaches, and the scope of improvements in these systems.", "published": "2021-06-09 11:31:27", "link": "http://arxiv.org/abs/2106.04995v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Grover's Algorithm for Question Answering", "abstract": "Grover's algorithm, a well-know quantum search algorithm, allows one to find\nthe correct item in a database, with quadratic speedup. In this paper we adapt\nGrover's algorithm to the problem of finding a correct answer to a natural\nlanguage question in English, thus contributing to the growing field of Quantum\nNatural Language Processing. Using a grammar that can be interpreted as tensor\ncontractions, each word is represented as a quantum state that serves as input\nto the quantum circuit. We here introduce a quantum measurement to contract the\nrepresentations of words, resulting in the representation of larger text\nfragments. Using this framework, a representation for the question is found\nthat contains all the possible answers in equal quantum superposition, and\nallows for the building of an oracle that can detect a correct answer, being\nagnostic to the specific question. Furthermore, we show that our construction\ncan deal with certain types of ambiguous phrases by keeping the various\ndifferent meanings in quantum superposition.", "published": "2021-06-09 18:00:13", "link": "http://arxiv.org/abs/2106.05299v3", "categories": ["quant-ph", "cs.CL"], "primary_category": "quant-ph"}
{"title": "DESCGEN: A Distantly Supervised Dataset for Generating Abstractive\n  Entity Descriptions", "abstract": "Short textual descriptions of entities provide summaries of their key\nattributes and have been shown to be useful sources of background knowledge for\ntasks such as entity linking and question answering. However, generating entity\ndescriptions, especially for new and long-tail entities, can be challenging\nsince relevant information is often scattered across multiple sources with\nvaried content and style. We introduce DESCGEN: given mentions spread over\nmultiple documents, the goal is to generate an entity summary description.\nDESCGEN consists of 37K entity descriptions from Wikipedia and Fandom, each\npaired with nine evidence documents on average. The documents were collected\nusing a combination of entity linking and hyperlinks to the Wikipedia and\nFandom entity pages, which together provide high-quality distant supervision.\nThe resulting summaries are more abstractive than those found in existing\ndatasets and provide a better proxy for the challenge of describing new and\nemerging entities. We also propose a two-stage extract-then-generate baseline\nand show that there exists a large gap (19.9% in ROUGE-L) between\nstate-of-the-art models and human performance, suggesting that the data will\nsupport significant future work.", "published": "2021-06-09 20:10:48", "link": "http://arxiv.org/abs/2106.05365v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Eye of the Beholder: Improved Relation Generalization for Text-based\n  Reinforcement Learning Agents", "abstract": "Text-based games (TBGs) have become a popular proving ground for the\ndemonstration of learning-based agents that make decisions in quasi real-world\nsettings. The crux of the problem for a reinforcement learning agent in such\nTBGs is identifying the objects in the world, and those objects' relations with\nthat world. While the recent use of text-based resources for increasing an\nagent's knowledge and improving its generalization have shown promise, we posit\nin this paper that there is much yet to be learned from visual representations\nof these same worlds. Specifically, we propose to retrieve images that\nrepresent specific instances of text observations from the world and train our\nagents on such images. This improves the agent's overall understanding of the\ngame 'scene' and objects' relationships to the world around them, and the\nvariety of visual representations on offer allow the agent to generate a better\ngeneralization of a relationship. We show that incorporating such images\nimproves the performance of agents in various TBG settings.", "published": "2021-06-09 21:02:07", "link": "http://arxiv.org/abs/2106.05387v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Low-Dimensional Structure in the Space of Language Representations is\n  Reflected in Brain Responses", "abstract": "How related are the representations learned by neural language models,\ntranslation models, and language tagging tasks? We answer this question by\nadapting an encoder-decoder transfer learning method from computer vision to\ninvestigate the structure among 100 different feature spaces extracted from\nhidden representations of various networks trained on language tasks. This\nmethod reveals a low-dimensional structure where language models and\ntranslation models smoothly interpolate between word embeddings, syntactic and\nsemantic tasks, and future word embeddings. We call this low-dimensional\nstructure a language representation embedding because it encodes the\nrelationships between representations needed to process language for a variety\nof NLP tasks. We find that this representation embedding can predict how well\neach individual feature space maps to human brain responses to natural language\nstimuli recorded using fMRI. Additionally, we find that the principal dimension\nof this structure can be used to create a metric which highlights the brain's\nnatural language processing hierarchy. This suggests that the embedding\ncaptures some part of the brain's natural language representation structure.", "published": "2021-06-09 22:59:12", "link": "http://arxiv.org/abs/2106.05426v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Timestamping Documents and Beliefs", "abstract": "Most of the textual information available to us are temporally variable. In a\nworld where information is dynamic, time-stamping them is a very important\ntask. Documents are a good source of information and are used for many tasks\nlike, sentiment analysis, classification of reviews etc. The knowledge of\ncreation date of documents facilitates several tasks like summarization, event\nextraction, temporally focused information extraction etc. Unfortunately, for\nmost of the documents on the web, the time-stamp meta-data is either erroneous\nor missing. Thus document dating is a challenging problem which requires\ninference over the temporal structure of the document alongside the contextual\ninformation of the document. Prior document dating systems have largely relied\non handcrafted features while ignoring such document-internal structures. In\nthis paper we propose NeuralDater, a Graph Convolutional Network (GCN) based\ndocument dating approach which jointly exploits syntactic and temporal graph\nstructures of document in a principled way. We also pointed out some\nlimitations of NeuralDater and tried to utilize both context and temporal\ninformation in documents in a more flexible and intuitive manner proposing AD3:\nAttentive Deep Document Dater, an attention-based document dating system. To\nthe best of our knowledge these are the first application of deep learning\nmethods for the task. Through extensive experiments on real-world datasets, we\nfind that our models significantly outperforms state-of-the-art baselines by a\nsignificant margin.", "published": "2021-06-09 02:12:18", "link": "http://arxiv.org/abs/2106.14622v1", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Meeting the SDGs : Enabling the Goals by Cooperation with Crowd using a\n  Conversational AI Platform", "abstract": "In this paper, we report about a large-scale online discussion with 1099\ncitizens on the Afghanistan Sustainable Development Goals.", "published": "2021-06-09 04:14:19", "link": "http://arxiv.org/abs/2107.04011v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "RealTranS: End-to-End Simultaneous Speech Translation with Convolutional\n  Weighted-Shrinking Transformer", "abstract": "End-to-end simultaneous speech translation (SST), which directly translates\nspeech in one language into text in another language in real-time, is useful in\nmany scenarios but has not been fully investigated. In this work, we propose\nRealTranS, an end-to-end model for SST. To bridge the modality gap between\nspeech and text, RealTranS gradually downsamples the input speech with\ninterleaved convolution and unidirectional Transformer layers for acoustic\nmodeling, and then maps speech features into text space with a\nweighted-shrinking operation and a semantic encoder. Besides, to improve the\nmodel performance in simultaneous scenarios, we propose a blank penalty to\nenhance the shrinking quality and a Wait-K-Stride-N strategy to allow local\nreranking during decoding. Experiments on public and widely-used datasets show\nthat RealTranS with the Wait-K-Stride-N strategy outperforms prior end-to-end\nmodels as well as cascaded models in diverse latency settings.", "published": "2021-06-09 06:35:46", "link": "http://arxiv.org/abs/2106.04833v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Unsupervised Automatic Speech Recognition: A Review", "abstract": "Automatic Speech Recognition (ASR) systems can be trained to achieve\nremarkable performance given large amounts of manually transcribed speech, but\nlarge labeled data sets can be difficult or expensive to acquire for all\nlanguages of interest. In this paper, we review the research literature to\nidentify models and ideas that could lead to fully unsupervised ASR, including\nunsupervised segmentation of the speech signal, unsupervised mapping from\nspeech segments to text, and semi-supervised models with nominal amounts of\nlabeled examples. The objective of the study is to identify the limitations of\nwhat can be learned from speech data alone and to understand the minimum\nrequirements for speech recognition. Identifying these limitations would help\noptimize the resources and efforts in ASR development for low-resource\nlanguages.", "published": "2021-06-09 08:33:20", "link": "http://arxiv.org/abs/2106.04897v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Neural Supervised Domain Adaptation by Augmenting Pre-trained Models\n  with Random Units", "abstract": "Neural Transfer Learning (TL) is becoming ubiquitous in Natural Language\nProcessing (NLP), thanks to its high performance on many tasks, especially in\nlow-resourced scenarios. Notably, TL is widely used for neural domain\nadaptation to transfer valuable knowledge from high-resource to low-resource\ndomains. In the standard fine-tuning scheme of TL, a model is initially\npre-trained on a source domain and subsequently fine-tuned on a target domain\nand, therefore, source and target domains are trained using the same\narchitecture. In this paper, we show through interpretation methods that such\nscheme, despite its efficiency, is suffering from a main limitation. Indeed,\nalthough capable of adapting to new domains, pre-trained neurons struggle with\nlearning certain patterns that are specific to the target domain. Moreover, we\nshed light on the hidden negative transfer occurring despite the high\nrelatedness between source and target domains, which may mitigate the final\ngain brought by transfer learning. To address these problems, we propose to\naugment the pre-trained model with normalised, weighted and randomly\ninitialised units that foster a better adaptation while maintaining the\nvaluable source knowledge. We show that our approach exhibits significant\nimprovements to the standard fine-tuning scheme for neural domain adaptation\nfrom the news domain to the social media domain on four NLP tasks:\npart-of-speech tagging, chunking, named entity recognition and morphosyntactic\ntagging.", "published": "2021-06-09 09:29:11", "link": "http://arxiv.org/abs/2106.04935v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Phraseformer: Multimodal Key-phrase Extraction using Transformer and\n  Graph Embedding", "abstract": "Background: Keyword extraction is a popular research topic in the field of\nnatural language processing. Keywords are terms that describe the most relevant\ninformation in a document. The main problem that researchers are facing is how\nto efficiently and accurately extract the core keywords from a document.\nHowever, previous keyword extraction approaches have utilized the text and\ngraph features, there is the lack of models that can properly learn and combine\nthese features in a best way.\n  Methods: In this paper, we develop a multimodal Key-phrase extraction\napproach, namely Phraseformer, using transformer and graph embedding\ntechniques. In Phraseformer, each keyword candidate is presented by a vector\nwhich is the concatenation of the text and structure learning representations.\nPhraseformer takes the advantages of recent researches such as BERT and ExEm to\npreserve both representations. Also, the Phraseformer treats the key-phrase\nextraction task as a sequence labeling problem solved using classification\ntask.\n  Results: We analyze the performance of Phraseformer on three datasets\nincluding Inspec, SemEval2010 and SemEval 2017 by F1-score. Also, we\ninvestigate the performance of different classifiers on Phraseformer method\nover Inspec dataset. Experimental results demonstrate the effectiveness of\nPhraseformer method over the three datasets used. Additionally, the Random\nForest classifier gain the highest F1-score among all classifiers.\n  Conclusions: Due to the fact that the combination of BERT and ExEm is more\nmeaningful and can better represent the semantic of words. Hence, Phraseformer\nsignificantly outperforms single-modality methods.", "published": "2021-06-09 09:32:17", "link": "http://arxiv.org/abs/2106.04939v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Energy-Based Models for Code Generation under Compilability Constraints", "abstract": "Neural language models can be successfully trained on source code, leading to\napplications such as code completion. However, their versatile autoregressive\nself-supervision objective overlooks important global sequence-level features\nthat are present in the data such as syntactic correctness or compilability. In\nthis work, we pose the problem of learning to generate compilable code as\nconstraint satisfaction. We define an Energy-Based Model (EBM) representing a\npre-trained generative model with an imposed constraint of generating only\ncompilable sequences. We then use the KL-Adaptive Distributional Policy\nGradient algorithm (Khalifa et al., 2021) to train a generative model\napproximating the EBM. We conduct experiments showing that our proposed\napproach is able to improve compilability rates without sacrificing diversity\nand complexity of the generated samples.", "published": "2021-06-09 11:06:32", "link": "http://arxiv.org/abs/2106.04985v1", "categories": ["cs.LG", "cs.CL", "cs.NE", "cs.SE", "I.2.2; I.2.7; I.2.6; I.5.1"], "primary_category": "cs.LG"}
{"title": "Order-Agnostic Cross Entropy for Non-Autoregressive Machine Translation", "abstract": "We propose a new training objective named order-agnostic cross entropy (OaXE)\nfor fully non-autoregressive translation (NAT) models. OaXE improves the\nstandard cross-entropy loss to ameliorate the effect of word reordering, which\nis a common source of the critical multimodality problem in NAT. Concretely,\nOaXE removes the penalty for word order errors, and computes the cross entropy\nloss based on the best possible alignment between model predictions and target\ntokens. Since the log loss is very sensitive to invalid references, we leverage\ncross entropy initialization and loss truncation to ensure the model focuses on\na good part of the search space. Extensive experiments on major WMT benchmarks\nshow that OaXE substantially improves translation performance, setting new\nstate of the art for fully NAT models. Further analyses show that OaXE\nalleviates the multimodality problem by reducing token repetitions and\nincreasing prediction confidence. Our code, data, and trained models are\navailable at https://github.com/tencent-ailab/ICML21_OAXE.", "published": "2021-06-09 14:15:12", "link": "http://arxiv.org/abs/2106.05093v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Comparative Study on Neural Architectures and Training Methods for\n  Japanese Speech Recognition", "abstract": "End-to-end (E2E) modeling is advantageous for automatic speech recognition\n(ASR) especially for Japanese since word-based tokenization of Japanese is not\ntrivial, and E2E modeling is able to model character sequences directly. This\npaper focuses on the latest E2E modeling techniques, and investigates their\nperformances on character-based Japanese ASR by conducting comparative\nexperiments. The results are analyzed and discussed in order to understand the\nrelative advantages of long short-term memory (LSTM), and Conformer models in\ncombination with connectionist temporal classification, transducer, and\nattention-based loss functions. Furthermore, the paper investigates on\neffectivity of the recent training techniques such as data augmentation\n(SpecAugment), variational noise injection, and exponential moving average. The\nbest configuration found in the paper achieved the state-of-the-art character\nerror rates of 4.1%, 3.2%, and 3.5% for Corpus of Spontaneous Japanese (CSJ)\neval1, eval2, and eval3 tasks, respectively. The system is also shown to be\ncomputationally efficient thanks to the efficiency of Conformer transducers.", "published": "2021-06-09 14:42:29", "link": "http://arxiv.org/abs/2106.05111v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Bayesian Attention Belief Networks", "abstract": "Attention-based neural networks have achieved state-of-the-art results on a\nwide range of tasks. Most such models use deterministic attention while\nstochastic attention is less explored due to the optimization difficulties or\ncomplicated model design. This paper introduces Bayesian attention belief\nnetworks, which construct a decoder network by modeling unnormalized attention\nweights with a hierarchy of gamma distributions, and an encoder network by\nstacking Weibull distributions with a deterministic-upward-stochastic-downward\nstructure to approximate the posterior. The resulting auto-encoding networks\ncan be optimized in a differentiable way with a variational lower bound. It is\nsimple to convert any models with deterministic attention, including pretrained\nones, to the proposed Bayesian attention belief networks. On a variety of\nlanguage understanding tasks, we show that our method outperforms deterministic\nattention and state-of-the-art stochastic attention in accuracy, uncertainty\nestimation, generalization across domains, and robustness to adversarial\nattacks. We further demonstrate the general applicability of our method on\nneural machine translation and visual question answering, showing great\npotential of incorporating our method into various attention-related tasks.", "published": "2021-06-09 17:46:22", "link": "http://arxiv.org/abs/2106.05251v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "End-to-End Training of Multi-Document Reader and Retriever for\n  Open-Domain Question Answering", "abstract": "We present an end-to-end differentiable training method for\nretrieval-augmented open-domain question answering systems that combine\ninformation from multiple retrieved documents when generating answers. We model\nretrieval decisions as latent variables over sets of relevant documents. Since\nmarginalizing over sets of retrieved documents is computationally hard, we\napproximate this using an expectation-maximization algorithm. We iteratively\nestimate the value of our latent variable (the set of relevant documents for a\ngiven question) and then use this estimate to update the retriever and reader\nparameters. We hypothesize that such end-to-end training allows training\nsignals to flow to the reader and then to the retriever better than staged-wise\ntraining. This results in a retriever that is able to select more relevant\ndocuments for a question and a reader that is trained on more accurate\ndocuments to generate an answer. Experiments on three benchmark datasets\ndemonstrate that our proposed method outperforms all existing approaches of\ncomparable size by 2-3% absolute exact match points, achieving new\nstate-of-the-art results. Our results also demonstrate the feasibility of\nlearning to retrieve to improve answer generation without explicit supervision\nof retrieval decisions.", "published": "2021-06-09 19:25:37", "link": "http://arxiv.org/abs/2106.05346v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Semi-Supervised Training with Pseudo-Labeling for End-to-End Neural\n  Diarization", "abstract": "In this paper, we present a semi-supervised training technique using\npseudo-labeling for end-to-end neural diarization (EEND). The EEND system has\nshown promising performance compared with traditional clustering-based methods,\nespecially in the case of overlapping speech. However, to get a well-tuned\nmodel, EEND requires labeled data for all the joint speech activities of every\nspeaker at each time frame in a recording. In this paper, we explore a\npseudo-labeling approach that employs unlabeled data. First, we propose an\niterative pseudo-label method for EEND, which trains the model using unlabeled\ndata of a target condition. Then, we also propose a committee-based training\nmethod to improve the performance of EEND. To evaluate our proposed method, we\nconduct the experiments of model adaptation using labeled and unlabeled data.\nExperimental results on the CALLHOME dataset show that our proposed\npseudo-label achieved a 37.4% relative diarization error rate reduction\ncompared to a seed model. Moreover, we analyzed the results of semi-supervised\nadaptation with pseudo-labeling. We also show the effectiveness of our approach\non the third DIHARD dataset.", "published": "2021-06-09 01:35:49", "link": "http://arxiv.org/abs/2106.04764v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep Interaction between Masking and Mapping Targets for Single-Channel\n  Speech Enhancement", "abstract": "The most recent deep neural network (DNN) models exhibit impressive denoising\nperformance in the time-frequency (T-F) magnitude domain. However, the phase is\nalso a critical component of the speech signal that is easily overlooked. In\nthis paper, we propose a multi-branch dilated convolutional network (DCN) to\nsimultaneously enhance the magnitude and phase of noisy speech. A causal and\nrobust monaural speech enhancement system is achieved based on the\nmulti-objective learning framework of the complex spectrum and the ideal ratio\nmask (IRM) targets. In the process of joint learning, the intermediate\nestimation of IRM targets is used as a way of generating feature attention\nfactors to realize the information interaction between the two targets.\nMoreover, the proposed multi-scale dilated convolution enables the DCN model to\nhave a more efficient temporal modeling capability. Experimental results show\nthat compared with other state-of-the-art models, this model achieves better\nspeech quality and intelligibility with less computation.", "published": "2021-06-09 07:59:22", "link": "http://arxiv.org/abs/2106.04878v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Time-Frequency Phase Retrieval for Audio -- The Effect of Transform\n  Parameters", "abstract": "In audio processing applications, phase retrieval (PR) is often performed\nfrom the magnitude of short-time Fourier transform (STFT) coefficients.\nAlthough PR performance has been observed to depend on the considered STFT\nparameters and audio data, the extent of this dependence has not been\nsystematically evaluated yet. To address this, we studied the performance of\nthree PR algorithms for various types of audio content and various STFT\nparameters such as redundancy, time-frequency ratio, and the type of window.\nThe quality of PR was studied in terms of objective difference grade and\nsignal-to-noise ratio of the STFT magnitude, to provide auditory- and\nsignal-based quality assessments. Our results show that PR quality improved\nwith increasing redundancy, with a strong relevance of the time-frequency\nratio. The effect of the audio content was smaller but still observable. The\neffect of the window was only significant for one of the PR algorithms.\nInterestingly, for a good PR quality, each of the three algorithms required a\ndifferent set of parameters, demonstrating the relevance of individual\nparameter sets for a fair comparison across PR algorithms. Based on these\nresults, we developed guidelines for optimizing STFT parameters for a given\napplication.", "published": "2021-06-09 15:43:05", "link": "http://arxiv.org/abs/2106.05148v1", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Speech Recovery for Real-World Self-powered Intermittent Devices", "abstract": "The incompleteness of speech inputs severely degrades the performance of all\nthe related speech signal processing applications. Although many researches\nhave been proposed to address this issue, they controlled the data missing\nconditions by simulation with self-defined masking lengths or sizes. Besides,\nthe masking definitions are different among all these experimental settings.\nThis paper presents a novel intermittent speech recovery (ISR) system for\nreal-world self-powered intermittent devices. Three contributive stages:\ninterpolation, enhancement, and combination are applied to the ISR system for\nspeech reconstruction. The experimental results show that our recovery system\nincreases speech quality by up to 591.7%, while increasing speech\nintelligibility by up to 80.5%. Most importantly, the proposed ISR system\nimproves the WER scores by up to 52.6%. The promising results not only confirm\nthe effectiveness of the reconstruction but also encourage the utilization of\nthese battery-free wearable/IoT devices.", "published": "2021-06-09 17:17:34", "link": "http://arxiv.org/abs/2106.05229v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audiovisual transfer learning for audio tagging and sound event\n  detection", "abstract": "We study the merit of transfer learning for two sound recognition problems,\ni.e., audio tagging and sound event detection. Employing feature fusion, we\nadapt a baseline system utilizing only spectral acoustic inputs to also make\nuse of pretrained auditory and visual features, extracted from networks built\nfor different tasks and trained with external data. We perform experiments with\nthese modified models on an audiovisual multi-label data set, of which the\ntraining partition contains a large number of unlabeled samples and a smaller\namount of clips with weak annotations, indicating the clip-level presence of 10\nsound categories without specifying the temporal boundaries of the active\nauditory events. For clip-based audio tagging, this transfer learning method\ngrants marked improvements. Addition of the visual modality on top of audio\nalso proves to be advantageous in this context. When it comes to generating\ntranscriptions of audio recordings, the benefit of pretrained features depends\non the requested temporal resolution: for coarse-grained sound event detection,\ntheir utility remains notable. But when more fine-grained predictions are\nrequired, performance gains are strongly reduced due to a mismatch between the\nproblem at hand and the goals of the models from which the pretrained vectors\nwere obtained.", "published": "2021-06-09 21:55:05", "link": "http://arxiv.org/abs/2106.05408v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
