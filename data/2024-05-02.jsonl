{"title": "Modeling Empathetic Alignment in Conversation", "abstract": "Empathy requires perspective-taking: empathetic responses require a person to\nreason about what another has experienced and communicate that understanding in\nlanguage. However, most NLP approaches to empathy do not explicitly model this\nalignment process. Here, we introduce a new approach to recognizing alignment\nin empathetic speech, grounded in Appraisal Theory. We introduce a new dataset\nof over 9.2K span-level annotations of different types of appraisals of a\nperson's experience and over 3K empathetic alignments between a speaker's and\nobserver's speech. Through computational experiments, we show that these\nappraisals and alignments can be accurately recognized. In experiments in over\n9.2M Reddit conversations, we find that appraisals capture meaningful groupings\nof behavior but that most responses have minimal alignment. However, we find\nthat mental health professionals engage with substantially more empathetic\nalignment.", "published": "2024-05-02 02:19:00", "link": "http://arxiv.org/abs/2405.00948v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The IgboAPI Dataset: Empowering Igbo Language Technologies through\n  Multi-dialectal Enrichment", "abstract": "The Igbo language is facing a risk of becoming endangered, as indicated by a\n2025 UNESCO study. This highlights the need to develop language technologies\nfor Igbo to foster communication, learning and preservation. To create robust,\nimpactful, and widely adopted language technologies for Igbo, it is essential\nto incorporate the multi-dialectal nature of the language. The primary obstacle\nin achieving dialectal-aware language technologies is the lack of comprehensive\ndialectal datasets. In response, we present the IgboAPI dataset, a\nmulti-dialectal Igbo-English dictionary dataset, developed with the aim of\nenhancing the representation of Igbo dialects. Furthermore, we illustrate the\npracticality of the IgboAPI dataset through two distinct studies: one focusing\non Igbo semantic lexicon and the other on machine translation. In the semantic\nlexicon project, we successfully establish an initial Igbo semantic lexicon for\nthe Igbo semantic tagger, while in the machine translation study, we\ndemonstrate that by finetuning existing machine translation systems using the\nIgboAPI dataset, we significantly improve their ability to handle dialectal\nvariations in sentences.", "published": "2024-05-02 04:27:35", "link": "http://arxiv.org/abs/2405.00997v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "It Couldn't Help But Overhear: On the Limits of Modelling\n  Meta-Communicative Grounding Acts with Supervised Learning", "abstract": "Active participation in a conversation is key to building common ground,\nsince understanding is jointly tailored by producers and recipients.\nOverhearers are deprived of the privilege of performing grounding acts and can\nonly conjecture about intended meanings. Still, data generation and annotation,\nmodelling, training and evaluation of NLP dialogue models place reliance on the\noverhearing paradigm. How much of the underlying grounding processes are\nthereby forfeited? As we show, there is evidence pointing to the impossibility\nof properly modelling human meta-communicative acts with data-driven learning\nmodels. In this paper, we discuss this issue and provide a preliminary analysis\non the variability of human decisions for requesting clarification. Most\nimportantly, we wish to bring this topic back to the community's table,\nencouraging discussion on the consequences of having models designed to only\n\"listen in\".", "published": "2024-05-02 09:55:19", "link": "http://arxiv.org/abs/2405.01139v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TartuNLP at EvaLatin 2024: Emotion Polarity Detection", "abstract": "This paper presents the TartuNLP team submission to EvaLatin 2024 shared task\nof the emotion polarity detection for historical Latin texts. Our system relies\non two distinct approaches to annotating training data for supervised learning:\n1) creating heuristics-based labels by adopting the polarity lexicon provided\nby the organizers and 2) generating labels with GPT4. We employed parameter\nefficient fine-tuning using the adapters framework and experimented with both\nmonolingual and cross-lingual knowledge transfer for training language and task\nadapters. Our submission with the LLM-generated labels achieved the overall\nfirst place in the emotion polarity detection task. Our results show that\nLLM-based annotations show promising results on texts in Latin.", "published": "2024-05-02 10:28:52", "link": "http://arxiv.org/abs/2405.01159v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine\n  Translation", "abstract": "Non-autoregressive (NAR) language models are known for their low latency in\nneural machine translation (NMT). However, a performance gap exists between NAR\nand autoregressive models due to the large decoding space and difficulty in\ncapturing dependency between target words accurately. Compounding this,\npreparing appropriate training data for NAR models is a non-trivial task, often\nexacerbating exposure bias. To address these challenges, we apply reinforcement\nlearning (RL) to Levenshtein Transformer, a representative edit-based NAR\nmodel, demonstrating that RL with self-generated data can enhance the\nperformance of edit-based NAR models. We explore two RL approaches: stepwise\nreward maximization and episodic reward maximization. We discuss the respective\npros and cons of these two approaches and empirically verify them. Moreover, we\nexperimentally investigate the impact of temperature setting on performance,\nconfirming the importance of proper temperature setting for NAR models'\ntraining.", "published": "2024-05-02 13:39:28", "link": "http://arxiv.org/abs/2405.01280v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Power of Question Translation Training in Multilingual Reasoning:\n  Broadened Scope and Deepened Insights", "abstract": "Bridging the significant gap between large language model's English and\nnon-English performance presents a great challenge. While some previous studies\nattempt to mitigate this gap with translated training data, the recently\nproposed question alignment framework leverages the model's English expertise\nto improve multilingual performance with minimum usage of expensive,\nerror-prone translation. In this paper, we explore how broadly this method can\nbe applied by examining its effects in reasoning with and without\nchain-of-thought, as well as with program-of-thought. We also explore applying\nthis framework to extremely large language models in an efficient manner, such\nas through proxy-tuning. Experiment results on multilingual reasoning\nbenchmarks mGSM, mSVAMP, xCSQA and xNLI demonstrate that we can extend question\nalignment framework to boost multilingual performance across diverse reasoning\nscenarios, model families, and sizes. For instance, when applied to the LLaMA2\nmodels, it brings an average accuracy improvements of 12.2% on mGSM even with\nthe 70B model. To understand the mechanism of its success, we analyze\nrepresentation space, generated response and data scales, and reveal how\nquestion translation training strengthens language alignment within LLMs and\nshapes their working patterns.", "published": "2024-05-02 14:49:50", "link": "http://arxiv.org/abs/2405.01345v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Topics in the Study of the Pragmatic Functions of Phonetic Reduction in\n  Dialog", "abstract": "Reduced articulatory precision is common in speech, but for dialog its\nacoustic properties and pragmatic functions have been little studied. We here\ntry to remedy this gap. This technical report contains content that was omitted\nfrom the journal article (Ward et al. 2024, submitted). Specifically, we here\nreport 1) lessons learned about annotating for perceived reduction, 2) the\nfinding that, unlike in read speech, the correlates of reduction in dialog\ninclude high pitch, wide pitch range, and intensity, and 3) a baseline model\nfor predicting reduction in dialog, using simple acoustic/prosodic features,\nthat achieves correlations with human perceptions of 0.24 for English, and 0.17\nfor Spanish. We also provide examples of additional possible pragmatic\nfunctions of reduction in English, and various discussion, observations and\nspeculations", "published": "2024-05-02 15:18:42", "link": "http://arxiv.org/abs/2405.01376v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Verification and Refinement of Natural Language Explanations through\n  LLM-Symbolic Theorem Proving", "abstract": "Natural language explanations represent a proxy for evaluating\nexplanation-based and multi-step Natural Language Inference (NLI) models.\nHowever, assessing the validity of explanations for NLI is challenging as it\ntypically involves the crowd-sourcing of apposite datasets, a process that is\ntime-consuming and prone to logical errors. To address existing limitations,\nthis paper investigates the verification and refinement of natural language\nexplanations through the integration of Large Language Models (LLMs) and\nTheorem Provers (TPs). Specifically, we present a neuro-symbolic framework,\nnamed Explanation-Refiner, that integrates TPs with LLMs to generate and\nformalise explanatory sentences and suggest potential inference strategies for\nNLI. In turn, the TP is employed to provide formal guarantees on the logical\nvalidity of the explanations and to generate feedback for subsequent\nimprovements. We demonstrate how Explanation-Refiner can be jointly used to\nevaluate explanatory reasoning, autoformalisation, and error correction\nmechanisms of state-of-the-art LLMs as well as to automatically enhance the\nquality of explanations of variable complexity in different domains.", "published": "2024-05-02 15:20:01", "link": "http://arxiv.org/abs/2405.01379v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WildChat: 1M ChatGPT Interaction Logs in the Wild", "abstract": "Chatbots such as GPT-4 and ChatGPT are now serving millions of users. Despite\ntheir widespread use, there remains a lack of public datasets showcasing how\nthese tools are used by a population of users in practice. To bridge this gap,\nwe offered free access to ChatGPT for online users in exchange for their\naffirmative, consensual opt-in to anonymously collect their chat transcripts\nand request headers. From this, we compiled WildChat, a corpus of 1 million\nuser-ChatGPT conversations, which consists of over 2.5 million interaction\nturns. We compare WildChat with other popular user-chatbot interaction\ndatasets, and find that our dataset offers the most diverse user prompts,\ncontains the largest number of languages, and presents the richest variety of\npotentially toxic use-cases for researchers to study. In addition to\ntimestamped chat transcripts, we enrich the dataset with demographic data,\nincluding state, country, and hashed IP addresses, alongside request headers.\nThis augmentation allows for more detailed analysis of user behaviors across\ndifferent geographical regions and temporal dimensions. Finally, because it\ncaptures a broad range of use cases, we demonstrate the dataset's potential\nutility in fine-tuning instruction-following models. WildChat is released at\nhttps://wildchat.allen.ai under AI2 ImpACT Licenses.", "published": "2024-05-02 17:00:02", "link": "http://arxiv.org/abs/2405.01470v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "D2PO: Discriminator-Guided DPO with Response Evaluation Models", "abstract": "Varied approaches for aligning language models have been proposed, including\nsupervised fine-tuning, RLHF, and direct optimization methods such as DPO.\nAlthough DPO has rapidly gained popularity due to its straightforward training\nprocess and competitive results, there is an open question of whether there\nremain practical advantages of using a discriminator, like a reward model, to\nevaluate responses. We propose D2PO, discriminator-guided DPO, an approach for\nthe online setting where preferences are being collected throughout learning.\nAs we collect gold preferences, we use these not only to train our policy, but\nto train a discriminative response evaluation model to silver-label even more\nsynthetic data for policy training. We explore this approach across a set of\ndiverse tasks, including a realistic chat setting, we find that our approach\nleads to higher-quality outputs compared to DPO with the same data budget, and\ngreater efficiency in terms of preference data requirements. Furthermore, we\nshow conditions under which silver labeling is most helpful: it is most\neffective when training the policy with DPO, outperforming traditional PPO, and\nbenefits from maintaining a separate discriminator from the policy model.", "published": "2024-05-02 17:44:41", "link": "http://arxiv.org/abs/2405.01511v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prometheus 2: An Open Source Language Model Specialized in Evaluating\n  Other Language Models", "abstract": "Proprietary LMs such as GPT-4 are often employed to assess the quality of\nresponses from various LMs. However, concerns including transparency,\ncontrollability, and affordability strongly motivate the development of\nopen-source LMs specialized in evaluations. On the other hand, existing open\nevaluator LMs exhibit critical shortcomings: 1) they issue scores that\nsignificantly diverge from those assigned by humans, and 2) they lack the\nflexibility to perform both direct assessment and pairwise ranking, the two\nmost prevalent forms of assessment. Additionally, they do not possess the\nability to evaluate based on custom evaluation criteria, focusing instead on\ngeneral attributes like helpfulness and harmlessness. To address these issues,\nwe introduce Prometheus 2, a more powerful evaluator LM than its predecessor\nthat closely mirrors human and GPT-4 judgements. Moreover, it is capable of\nprocessing both direct assessment and pair-wise ranking formats grouped with a\nuser-defined evaluation criteria. On four direct assessment benchmarks and four\npairwise ranking benchmarks, Prometheus 2 scores the highest correlation and\nagreement with humans and proprietary LM judges among all tested open evaluator\nLMs. Our models, code, and data are all publicly available at\nhttps://github.com/prometheus-eval/prometheus-eval.", "published": "2024-05-02 17:59:35", "link": "http://arxiv.org/abs/2405.01535v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Complex Reasoning over Knowledge Graph with Logic-Aware\n  Curriculum Tuning", "abstract": "Answering complex queries over incomplete knowledge graphs (KGs) is a\nchallenging job. Most previous works have focused on learning entity/relation\nembeddings and simulating first-order logic operators with various neural\nnetworks. However, they are bottlenecked by the inability to share world\nknowledge to improve logical reasoning, thus resulting in suboptimal\nperformance. In this paper, we propose a complex reasoning schema over KG upon\nlarge language models (LLMs), containing a curriculum-based logical-aware\ninstruction tuning framework, named LACT. Specifically, we augment the\narbitrary first-order logical queries via binary tree decomposition, to\nstimulate the reasoning capability of LLMs. To address the difficulty gap among\ndifferent types of complex queries, we design a simple and flexible logic-aware\ncurriculum learning framework. Experiments across widely used datasets\ndemonstrate that LACT has substantial improvements~(brings an average +5.5% MRR\nscore) over advanced methods, achieving the new state-of-the-art.", "published": "2024-05-02 18:12:08", "link": "http://arxiv.org/abs/2405.01649v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "1-Diffractor: Efficient and Utility-Preserving Text Obfuscation\n  Leveraging Word-Level Metric Differential Privacy", "abstract": "The study of privacy-preserving Natural Language Processing (NLP) has gained\nrising attention in recent years. One promising avenue studies the integration\nof Differential Privacy in NLP, which has brought about innovative methods in a\nvariety of application settings. Of particular note are $\\textit{word-level\nMetric Local Differential Privacy (MLDP)}$ mechanisms, which work to obfuscate\npotentially sensitive input text by performing word-by-word\n$\\textit{perturbations}$. Although these methods have shown promising results\nin empirical tests, there are two major drawbacks: (1) the inevitable loss of\nutility due to addition of noise, and (2) the computational expensiveness of\nrunning these mechanisms on high-dimensional word embeddings. In this work, we\naim to address these challenges by proposing $\\texttt{1-Diffractor}$, a new\nmechanism that boasts high speedups in comparison to previous mechanisms, while\nstill demonstrating strong utility- and privacy-preserving capabilities. We\nevaluate $\\texttt{1-Diffractor}$ for utility on several NLP tasks, for\ntheoretical and task-based privacy, and for efficiency in terms of speed and\nmemory. $\\texttt{1-Diffractor}$ shows significant improvements in efficiency,\nwhile still maintaining competitive utility and privacy scores across all\nconducted comparative tests against previous MLDP mechanisms. Our code is made\navailable at: https://github.com/sjmeis/Diffractor.", "published": "2024-05-02 19:07:32", "link": "http://arxiv.org/abs/2405.01678v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Question Suggestion for Conversational Shopping Assistants Using Product\n  Metadata", "abstract": "Digital assistants have become ubiquitous in e-commerce applications,\nfollowing the recent advancements in Information Retrieval (IR), Natural\nLanguage Processing (NLP) and Generative Artificial Intelligence (AI). However,\ncustomers are often unsure or unaware of how to effectively converse with these\nassistants to meet their shopping needs. In this work, we emphasize the\nimportance of providing customers a fast, easy to use, and natural way to\ninteract with conversational shopping assistants. We propose a framework that\nemploys Large Language Models (LLMs) to automatically generate contextual,\nuseful, answerable, fluent and diverse questions about products, via in-context\nlearning and supervised fine-tuning. Recommending these questions to customers\nas helpful suggestions or hints to both start and continue a conversation can\nresult in a smoother and faster shopping experience with reduced conversation\noverhead and friction. We perform extensive offline evaluations, and discuss in\ndetail about potential customer impact, and the type, length and latency of our\ngenerated product questions if incorporated into a real-world shopping\nassistant.", "published": "2024-05-02 21:16:19", "link": "http://arxiv.org/abs/2405.01738v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Psychosocial Impacts of Generative AI Harms", "abstract": "The rapid emergence of generative Language Models (LMs) has led to growing\nconcern about the impacts that their unexamined adoption may have on the social\nwell-being of diverse user groups. Meanwhile, LMs are increasingly being\nadopted in K-20 schools and one-on-one student settings with minimal\ninvestigation of potential harms associated with their deployment. Motivated in\npart by real-world/everyday use cases (e.g., an AI writing assistant) this\npaper explores the potential psychosocial harms of stories generated by five\nleading LMs in response to open-ended prompting. We extend findings of\nstereotyping harms analyzing a total of 150K 100-word stories related to\nstudent classroom interactions. Examining patterns in LM-generated character\ndemographics and representational harms (i.e., erasure, subordination, and\nstereotyping) we highlight particularly egregious vignettes, illustrating the\nways LM-generated outputs may influence the experiences of users with\nmarginalized and minoritized identities, and emphasizing the need for a\ncritical understanding of the psychosocial impacts of generative AI tools when\ndeployed and utilized in diverse social contexts.", "published": "2024-05-02 21:21:06", "link": "http://arxiv.org/abs/2405.01740v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Large Language Models for Critical Societal Domains:\n  Finance, Healthcare, and Law", "abstract": "In the fast-evolving domain of artificial intelligence, large language models\n(LLMs) such as GPT-3 and GPT-4 are revolutionizing the landscapes of finance,\nhealthcare, and law: domains characterized by their reliance on professional\nexpertise, challenging data acquisition, high-stakes, and stringent regulatory\ncompliance. This survey offers a detailed exploration of the methodologies,\napplications, challenges, and forward-looking opportunities of LLMs within\nthese high-stakes sectors. We highlight the instrumental role of LLMs in\nenhancing diagnostic and treatment methodologies in healthcare, innovating\nfinancial analytics, and refining legal interpretation and compliance\nstrategies. Moreover, we critically examine the ethics for LLM applications in\nthese fields, pointing out the existing ethical concerns and the need for\ntransparent, fair, and robust AI systems that respect regulatory norms. By\npresenting a thorough review of current literature and practical applications,\nwe showcase the transformative impact of LLMs, and outline the imperative for\ninterdisciplinary cooperation, methodological advancements, and ethical\nvigilance. Through this lens, we aim to spark dialogue and inspire future\nresearch dedicated to maximizing the benefits of LLMs while mitigating their\nrisks in these precision-dependent sectors. To facilitate future research on\nLLMs in these critical societal domains, we also initiate a reading list that\ntracks the latest advancements under this topic, which will be continually\nupdated: \\url{https://github.com/czyssrs/LLM_X_papers}.", "published": "2024-05-02 22:43:02", "link": "http://arxiv.org/abs/2405.01769v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Layers of technology in pluriversal design. Decolonising language\n  technology with the LiveLanguage initiative", "abstract": "Language technology has the potential to facilitate intercultural\ncommunication through meaningful translations. However, the current state of\nlanguage technology is deeply entangled with colonial knowledge due to path\ndependencies and neo-colonial tendencies in the global governance of artificial\nintelligence (AI). Language technology is a complex and emerging field that\npresents challenges for co-design interventions due to enfolding in assemblages\nof global scale and diverse sites and its knowledge intensity. This paper uses\nLiveLanguage, a lexical database, a set of services with particular emphasis on\nmodelling language diversity and integrating small and minority languages, as\nan example to discuss and close the gap from pluriversal design theory to\npractice. By diversifying the concept of emerging technology, we can better\napproach language technology in global contexts. The paper presents a model\ncomprising of five layers of technological activity. Each layer consists of\nspecific practices and stakeholders, thus provides distinctive spaces for\nco-design interventions as mode of inquiry for de-linking, re-thinking and\nre-building language technology towards pluriversality. In that way, the paper\ncontributes to reflecting the position of co-design in decolonising emergent\ntechnologies, and to integrating complex theoretical knowledge towards\ndecoloniality into language technology design.", "published": "2024-05-02 23:52:39", "link": "http://arxiv.org/abs/2405.01783v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Teaching Human Behavior Improves Content Understanding Abilities Of LLMs", "abstract": "Communication is defined as \"Who says what to whom with what effect\". A\nmessage from a communicator generates downstream receiver effects, also known\nas behavior. Receiver behavior, being a downstream effect of the message,\ncarries rich signals about it. Even after carrying signals about the message,\nthe behavior data is often ignored while training large language models. We\nshow that training LLMs on receiver behavior can actually help improve their\ncontent-understanding abilities. Specifically, we show that training LLMs to\npredict the receiver behavior of likes and comments improves the LLM's\nperformance on a wide variety of downstream content understanding tasks. We\nshow this performance increase over 46 video and image understanding tasks over\n26 benchmark datasets across both 0-shot and fine-tuning settings,\noutperforming many supervised baselines. Moreover, since receiver behavior,\nsuch as likes and comments, is collected by default on the internet and does\nnot need any human annotations to be useful, the performance improvement we get\nafter training on this data is essentially free-lunch. We release the receiver\nbehavior cleaned comments and likes of 750k images and videos collected from\nmultiple platforms along with our instruction-tuning data.", "published": "2024-05-02 02:04:01", "link": "http://arxiv.org/abs/2405.00942v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "PLAID SHIRTTT for Large-Scale Streaming Dense Retrieval", "abstract": "PLAID, an efficient implementation of the ColBERT late interaction bi-encoder\nusing pretrained language models for ranking, consistently achieves\nstate-of-the-art performance in monolingual, cross-language, and multilingual\nretrieval. PLAID differs from ColBERT by assigning terms to clusters and\nrepresenting those terms as cluster centroids plus compressed residual vectors.\nWhile PLAID is effective in batch experiments, its performance degrades in\nstreaming settings where documents arrive over time because representations of\nnew tokens may be poorly modeled by the earlier tokens used to select cluster\ncentroids. PLAID Streaming Hierarchical Indexing that Runs on Terabytes of\nTemporal Text (PLAID SHIRTTT) addresses this concern using multi-phase\nincremental indexing based on hierarchical sharding. Experiments on ClueWeb09\nand the multilingual NeuCLIR collection demonstrate the effectiveness of this\napproach both for the largest collection indexed to date by the ColBERT\narchitecture and in the multilingual setting, respectively.", "published": "2024-05-02 03:28:52", "link": "http://arxiv.org/abs/2405.00975v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Distillation for Multilingual Information Retrieval", "abstract": "Recent work in cross-language information retrieval (CLIR), where queries and\ndocuments are in different languages, has shown the benefit of the\nTranslate-Distill framework that trains a cross-language neural dual-encoder\nmodel using translation and distillation. However, Translate-Distill only\nsupports a single document language. Multilingual information retrieval (MLIR),\nwhich ranks a multilingual document collection, is harder to train than CLIR\nbecause the model must assign comparable relevance scores to documents in\ndifferent languages. This work extends Translate-Distill and propose\nMultilingual Translate-Distill (MTD) for MLIR. We show that ColBERT-X models\ntrained with MTD outperform their counterparts trained ith Multilingual\nTranslate-Train, which is the previous state-of-the-art training approach, by\n5% to 25% in nDCG@20 and 15% to 45% in MAP. We also show that the model is\nrobust to the way languages are mixed in training batches. Our implementation\nis available on GitHub.", "published": "2024-05-02 03:30:03", "link": "http://arxiv.org/abs/2405.00977v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Language Fairness in Multilingual Information Retrieval", "abstract": "Multilingual information retrieval (MLIR) considers the problem of ranking\ndocuments in several languages for a query expressed in a language that may\ndiffer from any of those languages. Recent work has observed that approaches\nsuch as combining ranked lists representing a single document language each or\nusing multilingual pretrained language models demonstrate a preference for one\nlanguage over others. This results in systematic unfair treatment of documents\nin different languages. This work proposes a language fairness metric to\nevaluate whether documents across different languages are fairly ranked through\nstatistical equivalence testing using the Kruskal-Wallis test. In contrast to\nmost prior work in group fairness, we do not consider any language to be an\nunprotected group. Thus our proposed measure, PEER (Probability of\nEqualExpected Rank), is the first fairness metric specifically designed to\ncapture the language fairness of MLIR systems. We demonstrate the behavior of\nPEER on artificial ranked lists. We also evaluate real MLIR systems on two\npublicly available benchmarks and show that the PEER scores align with prior\nanalytical findings on MLIR fairness. Our implementation is compatible with\nir-measures and is available at http://github.com/hltcoe/peer_measure.", "published": "2024-05-02 03:30:15", "link": "http://arxiv.org/abs/2405.00978v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "A Hong Kong Sign Language Corpus Collected from Sign-interpreted TV News", "abstract": "This paper introduces TVB-HKSL-News, a new Hong Kong sign language (HKSL)\ndataset collected from a TV news program over a period of 7 months. The dataset\nis collected to enrich resources for HKSL and support research in\nlarge-vocabulary continuous sign language recognition (SLR) and translation\n(SLT). It consists of 16.07 hours of sign videos of two signers with a\nvocabulary of 6,515 glosses (for SLR) and 2,850 Chinese characters or 18K\nChinese words (for SLT). One signer has 11.66 hours of sign videos and the\nother has 4.41 hours. One objective in building the dataset is to support the\ninvestigation of how well large-vocabulary continuous sign language\nrecognition/translation can be done for a single signer given a (relatively)\nlarge amount of his/her training data, which could potentially lead to the\ndevelopment of new modeling methods. Besides, most parts of the data collection\npipeline are automated with little human intervention; we believe that our\ncollection method can be scaled up to collect more sign language data easily\nfor SLT in the future for any sign languages if such sign-interpreted videos\nare available. We also run a SOTA SLR/SLT model on the dataset and get a\nbaseline SLR word error rate of 34.08% and a baseline SLT BLEU-4 score of 23.58\nfor benchmarking future research on the dataset.", "published": "2024-05-02 03:33:17", "link": "http://arxiv.org/abs/2405.00980v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Bayesian Optimization with LLM-Based Acquisition Functions for Natural\n  Language Preference Elicitation", "abstract": "Designing preference elicitation (PE) methodologies that can quickly\nascertain a user's top item preferences in a cold-start setting is a key\nchallenge for building effective and personalized conversational recommendation\n(ConvRec) systems. While large language models (LLMs) enable fully natural\nlanguage (NL) PE dialogues, we hypothesize that monolithic LLM NL-PE approaches\nlack the multi-turn, decision-theoretic reasoning required to effectively\nbalance the exploration and exploitation of user preferences towards an\narbitrary item set. In contrast, traditional Bayesian optimization PE methods\ndefine theoretically optimal PE strategies, but cannot generate arbitrary NL\nqueries or reason over content in NL item descriptions -- requiring users to\nexpress preferences via ratings or comparisons of unfamiliar items. To overcome\nthe limitations of both approaches, we formulate NL-PE in a Bayesian\nOptimization (BO) framework that seeks to actively elicit NL feedback to\nidentify the best recommendation. Key challenges in generalizing BO to deal\nwith natural language feedback include determining: (a) how to leverage LLMs to\nmodel the likelihood of NL preference feedback as a function of item utilities,\nand (b) how to design an acquisition function for NL BO that can elicit\npreferences in the infinite space of language. We demonstrate our framework in\na novel NL-PE algorithm, PEBOL, which uses: 1) Natural Language Inference (NLI)\nbetween user preference utterances and NL item descriptions to maintain\nBayesian preference beliefs, and 2) BO strategies such as Thompson Sampling\n(TS) and Upper Confidence Bound (UCB) to steer LLM query generation. We\nnumerically evaluate our methods in controlled simulations, finding that after\n10 turns of dialogue, PEBOL can achieve an MRR@10 of up to 0.27 compared to the\nbest monolithic LLM baseline's MRR@10 of 0.17, despite relying on earlier and\nsmaller LLMs.", "published": "2024-05-02 03:35:21", "link": "http://arxiv.org/abs/2405.00981v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "On the Evaluation of Machine-Generated Reports", "abstract": "Large Language Models (LLMs) have enabled new ways to satisfy information\nneeds. Although great strides have been made in applying them to settings like\ndocument ranking and short-form text generation, they still struggle to compose\ncomplete, accurate, and verifiable long-form reports. Reports with these\nqualities are necessary to satisfy the complex, nuanced, or multi-faceted\ninformation needs of users. In this perspective paper, we draw together\nopinions from industry and academia, and from a variety of related research\nareas, to present our vision for automatic report generation, and -- critically\n-- a flexible framework by which such reports can be evaluated. In contrast\nwith other summarization tasks, automatic report generation starts with a\ndetailed description of an information need, stating the necessary background,\nrequirements, and scope of the report. Further, the generated reports should be\ncomplete, accurate, and verifiable. These qualities, which are desirable -- if\nnot required -- in many analytic report-writing settings, require rethinking\nhow to build and evaluate systems that exhibit these qualities. To foster new\nefforts in building these systems, we present an evaluation framework that\ndraws on ideas found in various evaluations. To test completeness and accuracy,\nthe framework uses nuggets of information, expressed as questions and answers,\nthat need to be part of any high-quality generated report. Additionally,\nevaluation of citations that map claims made in the report to their source\ndocuments ensures verifiability.", "published": "2024-05-02 03:35:23", "link": "http://arxiv.org/abs/2405.00982v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Context-Aware Clustering using Large Language Models", "abstract": "Despite the remarkable success of Large Language Models (LLMs) in text\nunderstanding and generation, their potential for text clustering tasks remains\nunderexplored. We observed that powerful closed-source LLMs provide good\nquality clusterings of entity sets but are not scalable due to the massive\ncompute power required and the associated costs. Thus, we propose CACTUS\n(Context-Aware ClusTering with aUgmented triplet losS), a systematic approach\nthat leverages open-source LLMs for efficient and effective supervised\nclustering of entity subsets, particularly focusing on text-based entities.\nExisting text clustering methods fail to effectively capture the context\nprovided by the entity subset. Moreover, though there are several language\nmodeling based approaches for clustering, very few are designed for the task of\nsupervised clustering. This paper introduces a novel approach towards\nclustering entity subsets using LLMs by capturing context via a scalable\ninter-entity attention mechanism. We propose a novel augmented triplet loss\nfunction tailored for supervised clustering, which addresses the inherent\nchallenges of directly applying the triplet loss to this problem. Furthermore,\nwe introduce a self-supervised clustering task based on text augmentation\ntechniques to improve the generalization of our model. For evaluation, we\ncollect ground truth clusterings from a closed-source LLM and transfer this\nknowledge to an open-source LLM under the supervised clustering framework,\nallowing a faster and cheaper open-source model to perform the same task.\nExperiments on various e-commerce query and product clustering datasets\ndemonstrate that our proposed approach significantly outperforms existing\nunsupervised and supervised baselines under various external clustering\nevaluation metrics.", "published": "2024-05-02 03:50:31", "link": "http://arxiv.org/abs/2405.00988v1", "categories": ["cs.CL", "cs.LG", "I.2.7; I.2.m"], "primary_category": "cs.CL"}
{"title": "UniGen: Universal Domain Generalization for Sentiment Classification via\n  Zero-shot Dataset Generation", "abstract": "Although pre-trained language models have exhibited great flexibility and\nversatility with prompt-based few-shot learning, they suffer from the extensive\nparameter size and limited applicability for inference. Recent studies have\nsuggested that PLMs be used as dataset generators and a tiny task-specific\nmodel be trained to achieve efficient inference. However, their applicability\nto various domains is limited because they tend to generate domain-specific\ndatasets. In this work, we propose a novel approach to universal domain\ngeneralization that generates a dataset regardless of the target domain. This\nallows for generalization of the tiny task model to any domain that shares the\nlabel space, thus enhancing the real-world applicability of the dataset\ngeneration paradigm. Our experiments indicate that the proposed method\naccomplishes generalizability across various domains while using a parameter\nset that is orders of magnitude smaller than PLMs.", "published": "2024-05-02 05:46:13", "link": "http://arxiv.org/abs/2405.01022v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Efficient Data Generation for Source-grounded Information-seeking\n  Dialogs: A Use Case for Meeting Transcripts", "abstract": "Automating data generation with Large Language Models (LLMs) has become\nincreasingly popular. In this work, we investigate the feasibility and\neffectiveness of LLM-based data generation in the challenging setting of\nsource-grounded information-seeking dialogs, with response attribution, over\nlong documents. Our source texts consist of long and noisy meeting transcripts,\nadding to the task complexity. Since automating attribution remains difficult,\nwe propose a semi-automatic approach: dialog queries and responses are\ngenerated with LLMs, followed by human verification and identification of\nattribution spans. Using this approach, we created MISeD -- Meeting Information\nSeeking Dialogs dataset -- a dataset of information-seeking dialogs focused on\nmeeting transcripts. Models finetuned with MISeD demonstrate superior\nperformance compared to off-the-shelf models, even those of larger size.\nFinetuning on MISeD gives comparable response generation quality to finetuning\non fully manual data, while improving attribution quality and reducing time and\neffort.", "published": "2024-05-02 09:35:06", "link": "http://arxiv.org/abs/2405.01121v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DMON: A Simple yet Effective Approach for Argument Structure Learning", "abstract": "Argument structure learning~(ASL) entails predicting relations between\narguments. Because it can structure a document to facilitate its understanding,\nit has been widely applied in many fields~(medical, commercial, and scientific\ndomains). Despite its broad utilization, ASL remains a challenging task because\nit involves examining the complex relationships between the sentences in a\npotentially unstructured discourse. To resolve this problem, we have developed\na simple yet effective approach called Dual-tower Multi-scale cOnvolution\nneural Network~(DMON) for the ASL task. Specifically, we organize arguments\ninto a relationship matrix that together with the argument embeddings forms a\nrelationship tensor and design a mechanism to capture relations with contextual\narguments. Experimental results on three different-domain argument mining\ndatasets demonstrate that our framework outperforms state-of-the-art models.\nThe code is available at https://github.com/VRCMF/DMON.git .", "published": "2024-05-02 11:56:16", "link": "http://arxiv.org/abs/2405.01216v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prompt engineering paradigms for medical applications: scoping review\n  and recommendations for better practices", "abstract": "Prompt engineering is crucial for harnessing the potential of large language\nmodels (LLMs), especially in the medical domain where specialized terminology\nand phrasing is used. However, the efficacy of prompt engineering in the\nmedical domain remains to be explored. In this work, 114 recent studies\n(2022-2024) applying prompt engineering in medicine, covering prompt learning\n(PL), prompt tuning (PT), and prompt design (PD) are reviewed. PD is the most\nprevalent (78 articles). In 12 papers, PD, PL, and PT terms were used\ninterchangeably. ChatGPT is the most commonly used LLM, with seven papers using\nit for processing sensitive clinical data. Chain-of-Thought emerges as the most\ncommon prompt engineering technique. While PL and PT articles typically provide\na baseline for evaluating prompt-based approaches, 64% of PD studies lack\nnon-prompt-related baselines. We provide tables and figures summarizing\nexisting work, and reporting recommendations to guide future research\ncontributions.", "published": "2024-05-02 12:52:23", "link": "http://arxiv.org/abs/2405.01249v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Identification of Entailment and Contradiction Relations between Natural\n  Language Sentences: A Neurosymbolic Approach", "abstract": "Natural language inference (NLI), also known as Recognizing Textual\nEntailment (RTE), is an important aspect of natural language understanding.\nMost research now uses machine learning and deep learning to perform this task\non specific datasets, meaning their solution is not explainable nor explicit.\nTo address the need for an explainable approach to RTE, we propose a novel\npipeline that is based on translating text into an Abstract Meaning\nRepresentation (AMR) graph. For this we use a pre-trained AMR parser. We then\ntranslate the AMR graph into propositional logic and use a SAT solver for\nautomated reasoning. In text, often commonsense suggests that an entailment (or\ncontradiction) relationship holds between a premise and a claim, but because\ndifferent wordings are used, this is not identified from their logical\nrepresentations. To address this, we introduce relaxation methods to allow\nreplacement or forgetting of some propositions. Our experimental results show\nthis pipeline performs well on four RTE datasets.", "published": "2024-05-02 13:06:24", "link": "http://arxiv.org/abs/2405.01259v1", "categories": ["cs.AI", "cs.CL", "I.2"], "primary_category": "cs.AI"}
{"title": "Overcoming LLM Challenges using RAG-Driven Precision in Coffee Leaf\n  Disease Remediation", "abstract": "This research introduces an innovative AI-driven precision agriculture\nsystem, leveraging YOLOv8 for disease identification and Retrieval Augmented\nGeneration (RAG) for context-aware diagnosis. Focused on addressing the\nchallenges of diseases affecting the coffee production sector in Karnataka, The\nsystem integrates sophisticated object detection techniques with language\nmodels to address the inherent constraints associated with Large Language\nModels (LLMs). Our methodology not only tackles the issue of hallucinations in\nLLMs, but also introduces dynamic disease identification and remediation\nstrategies. Real-time monitoring, collaborative dataset expansion, and\norganizational involvement ensure the system's adaptability in diverse\nagricultural settings. The effect of the suggested system extends beyond\nautomation, aiming to secure food supplies, protect livelihoods, and promote\neco-friendly farming practices. By facilitating precise disease identification,\nthe system contributes to sustainable and environmentally conscious\nagriculture, reducing reliance on pesticides. Looking to the future, the\nproject envisions continuous development in RAG-integrated object detection\nsystems, emphasizing scalability, reliability, and usability. This research\nstrives to be a beacon for positive change in agriculture, aligning with global\nefforts toward sustainable and technologically enhanced food production.", "published": "2024-05-02 14:19:25", "link": "http://arxiv.org/abs/2405.01310v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "GAIA: A General AI Assistant for Intelligent Accelerator Operations", "abstract": "Large-scale machines like particle accelerators are usually run by a team of\nexperienced operators. In case of a particle accelerator, these operators\npossess suitable background knowledge on both accelerator physics and the\ntechnology comprising the machine. Due to the complexity of the machine,\nparticular subsystems of the machine are taken care of by experts, who the\noperators can turn to. In this work the reasoning and action (ReAct) prompting\nparadigm is used to couple an open-weights large language model (LLM) with a\nhigh-level machine control system framework and other tools, e.g. the\nelectronic logbook or machine design documentation. By doing so, a multi-expert\nretrieval augmented generation (RAG) system is implemented, which assists\noperators in knowledge retrieval tasks, interacts with the machine directly if\nneeded, or writes high level control system scripts. This consolidation of\nexpert knowledge and machine interaction can simplify and speed up machine\noperation tasks for both new and experienced human operators.", "published": "2024-05-02 15:06:18", "link": "http://arxiv.org/abs/2405.01359v1", "categories": ["cs.CL", "physics.acc-ph"], "primary_category": "cs.CL"}
{"title": "Unsupervised Flow Discovery from Task-oriented Dialogues", "abstract": "The design of dialogue flows is a critical but time-consuming task when\ndeveloping task-oriented dialogue (TOD) systems. We propose an approach for the\nunsupervised discovery of flows from dialogue history, thus making the process\napplicable to any domain for which such an history is available. Briefly,\nutterances are represented in a vector space and clustered according to their\nsemantic similarity. Clusters, which can be seen as dialogue states, are then\nused as the vertices of a transition graph for representing the flows visually.\nWe present concrete examples of flows, discovered from MultiWOZ, a public TOD\ndataset. We further elaborate on their significance and relevance for the\nunderlying conversations and introduce an automatic validation metric for their\nassessment. Experimental results demonstrate the potential of the proposed\napproach for extracting meaningful flows from task-oriented conversations.", "published": "2024-05-02 15:54:36", "link": "http://arxiv.org/abs/2405.01403v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Controllable Text Generation in the Instruction-Tuning Era", "abstract": "While most research on controllable text generation has focused on steering\nbase Language Models, the emerging instruction-tuning and prompting paradigm\noffers an alternate approach to controllability. We compile and release\nConGenBench, a testbed of 17 different controllable generation tasks, using a\nsubset of it to benchmark the performance of 9 different baselines and methods\non Instruction-tuned Language Models. To our surprise, we find that\nprompting-based approaches outperform controllable text generation methods on\nmost datasets and tasks, highlighting a need for research on controllable text\ngeneration with Instruction-tuned Language Models in specific. Prompt-based\napproaches match human performance on most stylistic tasks while lagging on\nstructural tasks, foregrounding a need to study more varied constraints and\nmore challenging stylistic tasks. To facilitate such research, we provide an\nalgorithm that uses only a task dataset and a Large Language Model with\nin-context capabilities to automatically generate a constraint dataset. This\nmethod eliminates the fields dependence on pre-curated constraint datasets,\nhence vastly expanding the range of constraints that can be studied in the\nfuture.", "published": "2024-05-02 17:24:30", "link": "http://arxiv.org/abs/2405.01490v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FLAME: Factuality-Aware Alignment for Large Language Models", "abstract": "Alignment is a standard procedure to fine-tune pre-trained large language\nmodels (LLMs) to follow natural language instructions and serve as helpful AI\nassistants. We have observed, however, that the conventional alignment process\nfails to enhance the factual accuracy of LLMs, and often leads to the\ngeneration of more false facts (i.e. hallucination). In this paper, we study\nhow to make the LLM alignment process more factual, by first identifying\nfactors that lead to hallucination in both alignment steps:\\ supervised\nfine-tuning (SFT) and reinforcement learning (RL). In particular, we find that\ntraining the LLM on new knowledge or unfamiliar texts can encourage\nhallucination. This makes SFT less factual as it trains on human labeled data\nthat may be novel to the LLM. Furthermore, reward functions used in standard RL\ncan also encourage hallucination, because it guides the LLM to provide more\nhelpful responses on a diverse set of instructions, often preferring longer and\nmore detailed responses. Based on these observations, we propose\nfactuality-aware alignment, comprised of factuality-aware SFT and\nfactuality-aware RL through direct preference optimization. Experiments show\nthat our proposed factuality-aware alignment guides LLMs to output more factual\nresponses while maintaining instruction-following capability.", "published": "2024-05-02 17:54:54", "link": "http://arxiv.org/abs/2405.01525v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automating the Analysis of Public Saliency and Attitudes towards\n  Biodiversity from Digital Media", "abstract": "Measuring public attitudes toward wildlife provides crucial insights into our\nrelationship with nature and helps monitor progress toward Global Biodiversity\nFramework targets. Yet, conducting such assessments at a global scale is\nchallenging. Manually curating search terms for querying news and social media\nis tedious, costly, and can lead to biased results. Raw news and social media\ndata returned from queries are often cluttered with irrelevant content and\nsyndicated articles. We aim to overcome these challenges by leveraging modern\nNatural Language Processing (NLP) tools. We introduce a folk taxonomy approach\nfor improved search term generation and employ cosine similarity on Term\nFrequency-Inverse Document Frequency vectors to filter syndicated articles. We\nalso introduce an extensible relevance filtering pipeline which uses\nunsupervised learning to reveal common topics, followed by an open-source\nzero-shot Large Language Model (LLM) to assign topics to news article titles,\nwhich are then used to assign relevance. Finally, we conduct sentiment, topic,\nand volume analyses on resulting data. We illustrate our methodology with a\ncase study of news and X (formerly Twitter) data before and during the COVID-19\npandemic for various mammal taxa, including bats, pangolins, elephants, and\ngorillas. During the data collection period, up to 62% of articles including\nkeywords pertaining to bats were deemed irrelevant to biodiversity,\nunderscoring the importance of relevance filtering. At the pandemic's onset, we\nobserved increased volume and a significant sentiment shift toward horseshoe\nbats, which were implicated in the pandemic, but not for other focal taxa. The\nproposed methods open the door to conservation practitioners applying modern\nand emerging NLP tools, including LLMs \"out of the box,\" to analyze public\nperceptions of biodiversity during current events or campaigns.", "published": "2024-05-02 08:28:25", "link": "http://arxiv.org/abs/2405.01610v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Investigating Wit, Creativity, and Detectability of Large Language\n  Models in Domain-Specific Writing Style Adaptation of Reddit's Showerthoughts", "abstract": "Recent Large Language Models (LLMs) have shown the ability to generate\ncontent that is difficult or impossible to distinguish from human writing. We\ninvestigate the ability of differently-sized LLMs to replicate human writing\nstyle in short, creative texts in the domain of Showerthoughts, thoughts that\nmay occur during mundane activities. We compare GPT-2 and GPT-Neo fine-tuned on\nReddit data as well as GPT-3.5 invoked in a zero-shot manner, against\nhuman-authored texts. We measure human preference on the texts across the\nspecific dimensions that account for the quality of creative, witty texts.\nAdditionally, we compare the ability of humans versus fine-tuned RoBERTa\nclassifiers to detect AI-generated texts. We conclude that human evaluators\nrate the generated texts slightly worse on average regarding their creative\nquality, but they are unable to reliably distinguish between human-written and\nAI-generated texts. We further provide a dataset for creative, witty text\ngeneration based on Reddit Showerthoughts posts.", "published": "2024-05-02 18:29:58", "link": "http://arxiv.org/abs/2405.01660v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Prompt-Learning for Structured Information Extraction from\n  Crohn's Disease Radiology Reports in a Low-Resource Language", "abstract": "Automatic conversion of free-text radiology reports into structured data\nusing Natural Language Processing (NLP) techniques is crucial for analyzing\ndiseases on a large scale. While effective for tasks in widely spoken languages\nlike English, generative large language models (LLMs) typically underperform\nwith less common languages and can pose potential risks to patient privacy.\nFine-tuning local NLP models is hindered by the skewed nature of real-world\nmedical datasets, where rare findings represent a significant data imbalance.\nWe introduce SMP-BERT, a novel prompt learning method that leverages the\nstructured nature of reports to overcome these challenges. In our studies\ninvolving a substantial collection of Crohn's disease radiology reports in\nHebrew (over 8,000 patients and 10,000 reports), SMP-BERT greatly surpassed\ntraditional fine-tuning methods in performance, notably in detecting infrequent\nconditions (AUC: 0.99 vs 0.94, F1: 0.84 vs 0.34). SMP-BERT empowers more\naccurate AI diagnostics available for low-resource languages.", "published": "2024-05-02 19:11:54", "link": "http://arxiv.org/abs/2405.01682v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automatically Extracting Numerical Results from Randomized Controlled\n  Trials with Large Language Models", "abstract": "Meta-analyses statistically aggregate the findings of different randomized\ncontrolled trials (RCTs) to assess treatment effectiveness. Because this yields\nrobust estimates of treatment effectiveness, results from meta-analyses are\nconsidered the strongest form of evidence. However, rigorous evidence syntheses\nare time-consuming and labor-intensive, requiring manual extraction of data\nfrom individual trials to be synthesized. Ideally, language technologies would\npermit fully automatic meta-analysis, on demand. This requires accurately\nextracting numerical results from individual trials, which has been beyond the\ncapabilities of natural language processing (NLP) models to date. In this work,\nwe evaluate whether modern large language models (LLMs) can reliably perform\nthis task. We annotate (and release) a modest but granular evaluation dataset\nof clinical trial reports with numerical findings attached to interventions,\ncomparators, and outcomes. Using this dataset, we evaluate the performance of\nseven LLMs applied zero-shot for the task of conditionally extracting numerical\nfindings from trial reports. We find that massive LLMs that can accommodate\nlengthy inputs are tantalizingly close to realizing fully automatic\nmeta-analysis, especially for dichotomous (binary) outcomes (e.g., mortality).\nHowever, LLMs -- including ones trained on biomedical texts -- perform poorly\nwhen the outcome measures are complex and tallying the results requires\ninference. This work charts a path toward fully automatic meta-analysis of RCTs\nvia LLMs, while also highlighting the limitations of existing models for this\naim.", "published": "2024-05-02 19:20:11", "link": "http://arxiv.org/abs/2405.01686v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models are Inconsistent and Biased Evaluators", "abstract": "The zero-shot capability of Large Language Models (LLMs) has enabled highly\nflexible, reference-free metrics for various tasks, making LLM evaluators\ncommon tools in NLP. However, the robustness of these LLM evaluators remains\nrelatively understudied; existing work mainly pursued optimal performance in\nterms of correlating LLM scores with human expert scores. In this paper, we\nconduct a series of analyses using the SummEval dataset and confirm that LLMs\nare biased evaluators as they: (1) exhibit familiarity bias-a preference for\ntext with lower perplexity, (2) show skewed and biased distributions of\nratings, and (3) experience anchoring effects for multi-attribute judgments. We\nalso found that LLMs are inconsistent evaluators, showing low \"inter-sample\"\nagreement and sensitivity to prompt differences that are insignificant to human\nunderstanding of text quality. Furthermore, we share recipes for configuring\nLLM evaluators to mitigate these limitations. Experimental results on the RoSE\ndataset demonstrate improvements over the state-of-the-art LLM evaluators.", "published": "2024-05-02 20:42:28", "link": "http://arxiv.org/abs/2405.01724v1", "categories": ["cs.CL", "cs.AI", "68T50 (Primary) 68T01, 68T37, 91F20 (Secondary)", "I.2; I.2.7; I.7"], "primary_category": "cs.CL"}
{"title": "Context Steering: Controllable Personalization at Inference Time", "abstract": "To deliver high-quality, personalized responses, large language models (LLMs)\nmust effectively incorporate context -- personal, demographic, and cultural\ninformation specific to an end-user. For example, asking the model to explain\nNewton's second law with the context \"I am a toddler\" should produce a response\ndifferent from when the context is \"I am a physics professor\". However,\nleveraging the context in practice is a nuanced and challenging task, and is\noften dependent on the specific situation or user base. The model must strike a\nbalance between providing specific, personalized responses and maintaining\ngeneral applicability. Current solutions, such as prompt-engineering and\nfine-tuning, require collection of contextually appropriate responses as\nexamples, making them time-consuming and less flexible to use across different\ncontexts. In this work, we introduce Context Steering (CoS) -- a simple,\ntraining-free decoding approach that amplifies the influence of the context in\nnext token predictions. CoS computes contextual influence by comparing the\noutput probabilities from two LLM forward passes: one that includes the context\nand one that does not. By linearly scaling the contextual influence, CoS allows\npractitioners to flexibly control the degree of personalization for different\nuse cases. We show that CoS can be applied to autoregressive LLMs, and\ndemonstrates strong performance in personalized recommendations. Additionally,\nwe show that CoS can function as a Bayesian Generative model to infer and\nquantify correlations between open-ended texts, broadening its potential\napplications.", "published": "2024-05-02 22:37:38", "link": "http://arxiv.org/abs/2405.01768v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Early Transformers: A study on Efficient Training of Transformer Models\n  through Early-Bird Lottery Tickets", "abstract": "The training of Transformer models has revolutionized natural language\nprocessing and computer vision, but it remains a resource-intensive and\ntime-consuming process. This paper investigates the applicability of the\nearly-bird ticket hypothesis to optimize the training efficiency of Transformer\nmodels. We propose a methodology that combines iterative pruning, masked\ndistance calculation, and selective retraining to identify early-bird tickets\nin various Transformer architectures, including ViT, Swin-T, GPT-2, and\nRoBERTa. Our experimental results demonstrate that early-bird tickets can be\nconsistently found within the first few epochs of training or fine-tuning,\nenabling significant resource optimization without compromising performance.\nThe pruned models obtained from early-bird tickets achieve comparable or even\nsuperior accuracy to their unpruned counterparts while substantially reducing\nmemory usage. Furthermore, our comparative analysis highlights the\ngeneralizability of the early-bird ticket phenomenon across different\nTransformer models and tasks. This research contributes to the development of\nefficient training strategies for Transformer models, making them more\naccessible and resource-friendly. By leveraging early-bird tickets,\npractitioners can accelerate the progress of natural language processing and\ncomputer vision applications while reducing the computational burden associated\nwith training Transformer models.", "published": "2024-05-02 23:03:45", "link": "http://arxiv.org/abs/2405.02353v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TextAge: A Curated and Diverse Text Dataset for Age Classification", "abstract": "Age-related language patterns play a crucial role in understanding linguistic\ndifferences and developing age-appropriate communication strategies. However,\nthe lack of comprehensive and diverse datasets has hindered the progress of\nresearch in this area. To address this issue, we present TextAge, a curated\ntext dataset that maps sentences to the age and age group of the producer, as\nwell as an underage (under 13) label. TextAge covers a wide range of ages and\nincludes both spoken and written data from various sources such as CHILDES,\nMeta, Poki Poems-by-kids, JUSThink, and the TV show \"Survivor.\" The dataset\nundergoes extensive cleaning and preprocessing to ensure data quality and\nconsistency. We demonstrate the utility of TextAge through two applications:\nUnderage Detection and Generational Classification. For Underage Detection, we\ntrain a Naive Bayes classifier, fine-tuned RoBERTa, and XLNet models to\ndifferentiate between language patterns of minors and young-adults and over.\nFor Generational Classification, the models classify language patterns into\ndifferent age groups (kids, teens, twenties, etc.). The models excel at\nclassifying the \"kids\" group but struggle with older age groups, particularly\n\"fifties,\" \"sixties,\" and \"seventies,\" likely due to limited data samples and\nless pronounced linguistic differences. TextAge offers a valuable resource for\nstudying age-related language patterns and developing age-sensitive language\nmodels. The dataset's diverse composition and the promising results of the\nclassification tasks highlight its potential for various applications, such as\ncontent moderation, targeted advertising, and age-appropriate communication.\nFuture work aims to expand the dataset further and explore advanced modeling\ntechniques to improve performance on older age groups.", "published": "2024-05-02 23:37:03", "link": "http://arxiv.org/abs/2406.16890v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Role of Model Architecture and Scale in Predicting Molecular\n  Properties: Insights from Fine-Tuning RoBERTa, BART, and LLaMA", "abstract": "This study introduces a systematic framework to compare the efficacy of Large\nLanguage Models (LLMs) for fine-tuning across various cheminformatics tasks.\nEmploying a uniform training methodology, we assessed three well-known\nmodels-RoBERTa, BART, and LLaMA-on their ability to predict molecular\nproperties using the Simplified Molecular Input Line Entry System (SMILES) as a\nuniversal molecular representation format. Our comparative analysis involved\npre-training 18 configurations of these models, with varying parameter sizes\nand dataset scales, followed by fine-tuning them on six benchmarking tasks from\nDeepChem. We maintained consistent training environments across models to\nensure reliable comparisons. This approach allowed us to assess the influence\nof model type, size, and training dataset size on model performance.\nSpecifically, we found that LLaMA-based models generally offered the lowest\nvalidation loss, suggesting their superior adaptability across tasks and\nscales. However, we observed that absolute validation loss is not a definitive\nindicator of model performance - contradicts previous research - at least for\nfine-tuning tasks: instead, model size plays a crucial role. Through rigorous\nreplication and validation, involving multiple training and fine-tuning cycles,\nour study not only delineates the strengths and limitations of each model type\nbut also provides a robust methodology for selecting the most suitable LLM for\nspecific cheminformatics applications. This research underscores the importance\nof considering model architecture and dataset characteristics in deploying AI\nfor molecular property prediction, paving the way for more informed and\neffective utilization of AI in drug discovery and related fields.", "published": "2024-05-02 02:20:12", "link": "http://arxiv.org/abs/2405.00949v1", "categories": ["cs.LG", "cs.CL", "physics.chem-ph", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "Efficient Compression of Multitask Multilingual Speech Models", "abstract": "Whisper is a multitask and multilingual speech model covering 99 languages.\nIt yields commendable automatic speech recognition (ASR) results in a subset of\nits covered languages, but the model still underperforms on a non-negligible\nnumber of under-represented languages, a problem exacerbated in smaller model\nversions. In this work, we examine its limitations, demonstrating the presence\nof speaker-related (gender, age) and model-related (resourcefulness and model\nsize) bias. Despite that, we show that only model-related bias are amplified by\nquantization, impacting more low-resource languages and smaller models.\nSearching for a better compression approach, we propose DistilWhisper, an\napproach that is able to bridge the performance gap in ASR for these languages\nwhile retaining the advantages of multitask and multilingual capabilities. Our\napproach involves two key strategies: lightweight modular ASR fine-tuning of\nwhisper-small using language-specific experts, and knowledge distillation from\nwhisper-large-v2. This dual approach allows us to effectively boost ASR\nperformance while keeping the robustness inherited from the multitask and\nmultilingual pre-training. Results demonstrate that our approach is more\neffective than standard fine-tuning or LoRA adapters, boosting performance in\nthe targeted languages for both in- and out-of-domain test sets, while\nintroducing only a negligible parameter overhead at inference.", "published": "2024-05-02 03:11:59", "link": "http://arxiv.org/abs/2405.00966v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee\n  Responses", "abstract": "One-on-one tutoring is widely acknowledged as an effective instructional\nmethod, conditioned on qualified tutors. However, the high demand for qualified\ntutors remains a challenge, often necessitating the training of novice tutors\n(i.e., trainees) to ensure effective tutoring. Research suggests that providing\ntimely explanatory feedback can facilitate the training process for trainees.\nHowever, it presents challenges due to the time-consuming nature of assessing\ntrainee performance by human experts. Inspired by the recent advancements of\nlarge language models (LLMs), our study employed the GPT-4 model to build an\nexplanatory feedback system. This system identifies trainees' responses in\nbinary form (i.e., correct/incorrect) and automatically provides template-based\nfeedback with responses appropriately rephrased by the GPT-4 model. We\nconducted our study on 410 responses from trainees across three training\nlessons: Giving Effective Praise, Reacting to Errors, and Determining What\nStudents Know. Our findings indicate that: 1) using a few-shot approach, the\nGPT-4 model effectively identifies correct/incorrect trainees' responses from\nthree training lessons with an average F1 score of 0.84 and an AUC score of\n0.85; and 2) using the few-shot approach, the GPT-4 model adeptly rephrases\nincorrect trainees' responses into desired responses, achieving performance\ncomparable to that of human experts.", "published": "2024-05-02 03:18:03", "link": "http://arxiv.org/abs/2405.00970v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Few Shot Class Incremental Learning using Vision-Language models", "abstract": "Recent advancements in deep learning have demonstrated remarkable performance\ncomparable to human capabilities across various supervised computer vision\ntasks. However, the prevalent assumption of having an extensive pool of\ntraining data encompassing all classes prior to model training often diverges\nfrom real-world scenarios, where limited data availability for novel classes is\nthe norm. The challenge emerges in seamlessly integrating new classes with few\nsamples into the training data, demanding the model to adeptly accommodate\nthese additions without compromising its performance on base classes. To\naddress this exigency, the research community has introduced several solutions\nunder the realm of few-shot class incremental learning (FSCIL).\n  In this study, we introduce an innovative FSCIL framework that utilizes\nlanguage regularizer and subspace regularizer. During base training, the\nlanguage regularizer helps incorporate semantic information extracted from a\nVision-Language model. The subspace regularizer helps in facilitating the\nmodel's acquisition of nuanced connections between image and text semantics\ninherent to base classes during incremental training. Our proposed framework\nnot only empowers the model to embrace novel classes with limited data, but\nalso ensures the preservation of performance on base classes. To substantiate\nthe efficacy of our approach, we conduct comprehensive experiments on three\ndistinct FSCIL benchmarks, where our framework attains state-of-the-art\nperformance.", "published": "2024-05-02 06:52:49", "link": "http://arxiv.org/abs/2405.01040v2", "categories": ["cs.CV", "cs.CL", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Low-resource speech recognition and dialect identification of Irish in a\n  multi-task framework", "abstract": "This paper explores the use of Hybrid CTC/Attention encoder-decoder models\ntrained with Intermediate CTC (InterCTC) for Irish (Gaelic) low-resource speech\nrecognition (ASR) and dialect identification (DID). Results are compared to the\ncurrent best performing models trained for ASR (TDNN-HMM) and DID (ECAPA-TDNN).\nAn optimal InterCTC setting is initially established using a Conformer encoder.\nThis setting is then used to train a model with an E-branchformer encoder and\nthe performance of both architectures are compared. A multi-task fine-tuning\napproach is adopted for language model (LM) shallow fusion. The experiments\nyielded an improvement in DID accuracy of 10.8% relative to a baseline\nECAPA-TDNN, and WER performance approaching the TDNN-HMM model. This multi-task\napproach emerges as a promising strategy for Irish low-resource ASR and DID.", "published": "2024-05-02 13:54:39", "link": "http://arxiv.org/abs/2405.01293v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "The Effectiveness of LLMs as Annotators: A Comparative Overview and\n  Empirical Analysis of Direct Representation", "abstract": "Large Language Models (LLMs) have emerged as powerful support tools across\nvarious natural language tasks and a range of application domains. Recent\nstudies focus on exploring their capabilities for data annotation. This paper\nprovides a comparative overview of twelve studies investigating the potential\nof LLMs in labelling data. While the models demonstrate promising cost and\ntime-saving benefits, there exist considerable limitations, such as\nrepresentativeness, bias, sensitivity to prompt variations and English language\npreference. Leveraging insights from these studies, our empirical analysis\nfurther examines the alignment between human and GPT-generated opinion\ndistributions across four subjective datasets. In contrast to the studies\nexamining representation, our methodology directly obtains the opinion\ndistribution from GPT. Our analysis thereby supports the minority of studies\nthat are considering diverse perspectives when evaluating data annotation tasks\nand highlights the need for further research in this direction.", "published": "2024-05-02 14:00:22", "link": "http://arxiv.org/abs/2405.01299v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language\n  Models using 2D Priors", "abstract": "Large 2D vision-language models (2D-LLMs) have gained significant attention\nby bridging Large Language Models (LLMs) with images using a simple projector.\nInspired by their success, large 3D point cloud-language models (3D-LLMs) also\nintegrate point clouds into LLMs. However, directly aligning point clouds with\nLLM requires expensive training costs, typically in hundreds of GPU-hours on\nA100, which hinders the development of 3D-LLMs. In this paper, we introduce\nMiniGPT-3D, an efficient and powerful 3D-LLM that achieves multiple SOTA\nresults while training for only 27 hours on one RTX 3090. Specifically, we\npropose to align 3D point clouds with LLMs using 2D priors from 2D-LLMs, which\ncan leverage the similarity between 2D and 3D visual information. We introduce\na novel four-stage training strategy for modality alignment in a cascaded way,\nand a mixture of query experts module to adaptively aggregate features with\nhigh efficiency. Moreover, we utilize parameter-efficient fine-tuning methods\nLoRA and Norm fine-tuning, resulting in only 47.8M learnable parameters, which\nis up to 260x fewer than existing methods. Extensive experiments show that\nMiniGPT-3D achieves SOTA on 3D object classification and captioning tasks, with\nsignificantly cheaper training costs. Notably, MiniGPT-3D gains an 8.12\nincrease on GPT-4 evaluation score for the challenging object captioning task\ncompared to ShapeLLM-13B, while the latter costs 160 total GPU-hours on 8 A800.\nWe are the first to explore the efficient 3D-LLM, offering new insights to the\ncommunity. Code and weights are available at\nhttps://github.com/TangYuan96/MiniGPT-3D.", "published": "2024-05-02 16:04:30", "link": "http://arxiv.org/abs/2405.01413v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "UQA: Corpus for Urdu Question Answering", "abstract": "This paper introduces UQA, a novel dataset for question answering and text\ncomprehension in Urdu, a low-resource language with over 70 million native\nspeakers. UQA is generated by translating the Stanford Question Answering\nDataset (SQuAD2.0), a large-scale English QA dataset, using a technique called\nEATS (Enclose to Anchor, Translate, Seek), which preserves the answer spans in\nthe translated context paragraphs. The paper describes the process of selecting\nand evaluating the best translation model among two candidates: Google\nTranslator and Seamless M4T. The paper also benchmarks several state-of-the-art\nmultilingual QA models on UQA, including mBERT, XLM-RoBERTa, and mT5, and\nreports promising results. For XLM-RoBERTa-XL, we have an F1 score of 85.99 and\n74.56 EM. UQA is a valuable resource for developing and testing multilingual\nNLP systems for Urdu and for enhancing the cross-lingual transferability of\nexisting models. Further, the paper demonstrates the effectiveness of EATS for\ncreating high-quality datasets for other languages and domains. The UQA dataset\nand the code are publicly available at www.github.com/sameearif/UQA.", "published": "2024-05-02 16:44:31", "link": "http://arxiv.org/abs/2405.01458v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Understanding Figurative Meaning through Explainable Visual Entailment", "abstract": "Large Vision-Language Models (VLMs) have demonstrated strong capabilities in\ntasks requiring a fine-grained understanding of literal meaning in images and\ntext, such as visual question-answering or visual entailment. However, there\nhas been little exploration of the capabilities of these models when presented\nwith images and captions containing figurative meaning, such as metaphors or\nhumor. To close this gap, we propose a new task framing the figurative meaning\nunderstanding problem as an explainable visual entailment task, where the model\nhas to predict whether the image (premise) entails a caption (hypothesis) and\njustify the predicted label with a textual explanation. The figurative\nphenomena can be present in the image, in the caption, or both. Using a\nhuman-AI collaboration approach, we build the accompanying expert-verified\ndataset V-FLUTE, containing 6,027 {image, caption, label, explanation}\ninstances spanning five diverse figurative phenomena: metaphors, similes,\nidioms, sarcasm, and humor. Through automatic evaluation, we find that VLMs\nstruggle to generalize from literal to figurative meaning, particularly when it\nis present in images. Further, we identify common types of errors in VLM\nreasoning (hallucination and incomplete or unsound reasoning) across classes of\nmodels via human evaluation.", "published": "2024-05-02 17:07:25", "link": "http://arxiv.org/abs/2405.01474v3", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment", "abstract": "Aligning Large Language Models (LLMs) with human values and preferences is\nessential for making them helpful and safe. However, building efficient tools\nto perform alignment can be challenging, especially for the largest and most\ncompetent LLMs which often contain tens or hundreds of billions of parameters.\nWe create NeMo-Aligner, a toolkit for model alignment that can efficiently\nscale to a thousand GPUs for training the largest open-source LLMs such as\nNemotron 4 340B and Llama 3.1 405B. NeMo-Aligner comes with highly optimized\nand scalable implementations for major paradigms of model alignment such as:\nReinforcement Learning from Human Feedback (RLHF), Direct Preference\nOptimization (DPO), SteerLM, and Self-Play Fine-Tuning (SPIN). Additionally,\nour toolkit supports running most of the alignment techniques in a Parameter\nEfficient Fine-Tuning (PEFT) setting. NeMo-Aligner is designed for\nextensibility, allowing support for other alignment techniques with minimal\neffort. It is open-sourced with Apache 2.0 License and we invite community\ncontributions at https://github.com/NVIDIA/NeMo-Aligner", "published": "2024-05-02 17:13:40", "link": "http://arxiv.org/abs/2405.01481v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MANTIS: Interleaved Multi-Image Instruction Tuning", "abstract": "Large multimodal models (LMMs) have shown great results in single-image\nvision language tasks. However, their abilities to solve multi-image visual\nlanguage tasks is yet to be improved. The existing LMMs like OpenFlamingo,\nEmu2, and Idefics gain their multi-image ability through pre-training on\nhundreds of millions of noisy interleaved image-text data from the web, which\nis neither efficient nor effective. In this paper, we aim to build strong\nmulti-image LMMs via instruction tuning with academic-level resources.\nTherefore, we meticulously construct Mantis-Instruct containing 721K\nmulti-image instruction data to train a family of Mantis models. The\ninstruction tuning empowers Mantis with different multi-image skills like\nco-reference, comparison, reasoning, and temporal understanding. We evaluate\nMantis on 8 multi-image benchmarks and 6 single-image benchmarks.\nMantis-Idefics2 can achieve SoTA results on all the multi-image benchmarks and\nbeat the strongest multi-image baseline, Idefics2-8B by an average of 13\nabsolute points. Notably, Idefics2-8B was pre-trained on 140M interleaved\nmulti-image data, which is 200x larger than Mantis-Instruct. We observe that\nMantis performs equivalently well on the held-in and held-out benchmarks, which\nshows its generalization ability. We further evaluate Mantis on single-image\nbenchmarks and demonstrate that Mantis also maintains a strong single-image\nperformance on par with CogVLM and Emu2. Our results show that multi-image\nabilities are not necessarily gained through massive pre-training, instead,\nthey can be gained by low-cost instruction tuning. The training and evaluation\nof Mantis has paved the road for future work to improve LMMs' multi-image\nabilities.", "published": "2024-05-02 17:14:57", "link": "http://arxiv.org/abs/2405.01483v3", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Analyzing the Role of Semantic Representations in the Era of Large\n  Language Models", "abstract": "Traditionally, natural language processing (NLP) models often use a rich set\nof features created by linguistic expertise, such as semantic representations.\nHowever, in the era of large language models (LLMs), more and more tasks are\nturned into generic, end-to-end sequence generation problems. In this paper, we\ninvestigate the question: what is the role of semantic representations in the\nera of LLMs? Specifically, we investigate the effect of Abstract Meaning\nRepresentation (AMR) across five diverse NLP tasks. We propose an AMR-driven\nchain-of-thought prompting method, which we call AMRCoT, and find that it\ngenerally hurts performance more than it helps. To investigate what AMR may\nhave to offer on these tasks, we conduct a series of analysis experiments. We\nfind that it is difficult to predict which input examples AMR may help or hurt\non, but errors tend to arise with multi-word expressions, named entities, and\nin the final inference step where the LLM must connect its reasoning over the\nAMR to its prediction. We recommend focusing on these areas for future work in\nsemantic representations for LLMs. Our code:\nhttps://github.com/causalNLP/amr_llm.", "published": "2024-05-02 17:32:59", "link": "http://arxiv.org/abs/2405.01502v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ALCM: Autonomous LLM-Augmented Causal Discovery Framework", "abstract": "To perform effective causal inference in high-dimensional datasets,\ninitiating the process with causal discovery is imperative, wherein a causal\ngraph is generated based on observational data. However, obtaining a complete\nand accurate causal graph poses a formidable challenge, recognized as an\nNP-hard problem. Recently, the advent of Large Language Models (LLMs) has\nushered in a new era, indicating their emergent capabilities and widespread\napplicability in facilitating causal reasoning across diverse domains, such as\nmedicine, finance, and science. The expansive knowledge base of LLMs holds the\npotential to elevate the field of causal reasoning by offering\ninterpretability, making inferences, generalizability, and uncovering novel\ncausal structures. In this paper, we introduce a new framework, named\nAutonomous LLM-Augmented Causal Discovery Framework (ALCM), to synergize\ndata-driven causal discovery algorithms and LLMs, automating the generation of\na more resilient, accurate, and explicable causal graph. The ALCM consists of\nthree integral components: causal structure learning, causal wrapper, and\nLLM-driven causal refiner. These components autonomously collaborate within a\ndynamic environment to address causal discovery questions and deliver plausible\ncausal graphs. We evaluate the ALCM framework by implementing two\ndemonstrations on seven well-known datasets. Experimental results demonstrate\nthat ALCM outperforms existing LLM methods and conventional data-driven causal\nreasoning mechanisms. This study not only shows the effectiveness of the ALCM\nbut also underscores new research directions in leveraging the causal reasoning\ncapabilities of LLMs.", "published": "2024-05-02 21:27:45", "link": "http://arxiv.org/abs/2405.01744v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ME"], "primary_category": "cs.LG"}
{"title": "COPAL: Continual Pruning in Large Language Generative Models", "abstract": "Adapting pre-trained large language models to different domains in natural\nlanguage processing requires two key considerations: high computational demands\nand model's inability to continual adaptation. To simultaneously address both\nissues, this paper presents COPAL (COntinual Pruning in Adaptive Language\nsettings), an algorithm developed for pruning large language generative models\nunder a continual model adaptation setting. While avoiding resource-heavy\nfinetuning or retraining, our pruning process is guided by the proposed\nsensitivity analysis. The sensitivity effectively measures model's ability to\nwithstand perturbations introduced by the new dataset and finds model's weights\nthat are relevant for all encountered datasets. As a result, COPAL allows\nseamless model adaptation to new domains while enhancing the resource\nefficiency. Our empirical evaluation on a various size of LLMs show that COPAL\noutperforms baseline models, demonstrating its efficacy in efficiency and\nadaptability.", "published": "2024-05-02 18:24:41", "link": "http://arxiv.org/abs/2405.02347v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Enhancing Language Models for Financial Relation Extraction with Named\n  Entities and Part-of-Speech", "abstract": "The Financial Relation Extraction (FinRE) task involves identifying the\nentities and their relation, given a piece of financial statement/text. To\nsolve this FinRE problem, we propose a simple but effective strategy that\nimproves the performance of pre-trained language models by augmenting them with\nNamed Entity Recognition (NER) and Part-Of-Speech (POS), as well as different\napproaches to combine these information. Experiments on a financial relations\ndataset show promising results and highlights the benefits of incorporating NER\nand POS in existing models. Our dataset and codes are available at\nhttps://github.com/kwanhui/FinRelExtract.", "published": "2024-05-02 14:33:05", "link": "http://arxiv.org/abs/2405.06665v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sequence-to-sequence models in peer-to-peer learning: A practical\n  application", "abstract": "This paper explores the applicability of sequence-to-sequence (Seq2Seq)\nmodels based on LSTM units for Automatic Speech Recognition (ASR) task within\npeer-to-peer learning environments. Leveraging two distinct peer-to-peer\nlearning methods, the study simulates the learning process of agents and\nevaluates their performance in ASR task using two different ASR datasets. In a\ncentralized training setting, utilizing a scaled-down variant of the Deep\nSpeech 2 model, a single model achieved a Word Error Rate (WER) of 84\\% when\ntrained on the UserLibri dataset, and 38\\% when trained on the LJ Speech\ndataset. Conversely, in a peer-to-peer learning scenario involving 55 agents,\nthe WER ranged from 87\\% to 92\\% for the UserLibri dataset, and from 52\\% to\n56\\% for the LJ Speech dataset. The findings demonstrate the feasibility of\nemploying Seq2Seq models in decentralized settings, albeit with slightly higher\nWord Error Rates (WER) compared to centralized training methods.", "published": "2024-05-02 14:44:06", "link": "http://arxiv.org/abs/2406.02565v1", "categories": ["cs.SD", "cs.CL", "cs.MA", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AI Governance and Accountability: An Analysis of Anthropic's Claude", "abstract": "As AI systems become increasingly prevalent and impactful, the need for\neffective AI governance and accountability measures is paramount. This paper\nexamines the AI governance landscape, focusing on Anthropic's Claude, a\nfoundational AI model. We analyze Claude through the lens of the NIST AI Risk\nManagement Framework and the EU AI Act, identifying potential threats and\nproposing mitigation strategies. The paper highlights the importance of\ntransparency, rigorous benchmarking, and comprehensive data handling processes\nin ensuring the responsible development and deployment of AI systems. We\nconclude by discussing the social impact of AI governance and the ethical\nconsiderations surrounding AI accountability.", "published": "2024-05-02 23:37:06", "link": "http://arxiv.org/abs/2407.01557v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "CACTUS: Chemistry Agent Connecting Tool-Usage to Science", "abstract": "Large language models (LLMs) have shown remarkable potential in various\ndomains, but they often lack the ability to access and reason over\ndomain-specific knowledge and tools. In this paper, we introduced CACTUS\n(Chemistry Agent Connecting Tool-Usage to Science), an LLM-based agent that\nintegrates cheminformatics tools to enable advanced reasoning and\nproblem-solving in chemistry and molecular discovery. We evaluate the\nperformance of CACTUS using a diverse set of open-source LLMs, including\nGemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, on a benchmark of\nthousands of chemistry questions. Our results demonstrate that CACTUS\nsignificantly outperforms baseline LLMs, with the Gemma-7b and Mistral-7b\nmodels achieving the highest accuracy regardless of the prompting strategy\nused. Moreover, we explore the impact of domain-specific prompting and hardware\nconfigurations on model performance, highlighting the importance of prompt\nengineering and the potential for deploying smaller models on consumer-grade\nhardware without significant loss in accuracy. By combining the cognitive\ncapabilities of open-source LLMs with domain-specific tools, CACTUS can assist\nresearchers in tasks such as molecular property prediction, similarity\nsearching, and drug-likeness assessment. Furthermore, CACTUS represents a\nsignificant milestone in the field of cheminformatics, offering an adaptable\ntool for researchers engaged in chemistry and molecular discovery. By\nintegrating the strengths of open-source LLMs with domain-specific tools,\nCACTUS has the potential to accelerate scientific advancement and unlock new\nfrontiers in the exploration of novel, effective, and safe therapeutic\ncandidates, catalysts, and materials. Moreover, CACTUS's ability to integrate\nwith automated experimentation platforms and make data-driven decisions in real\ntime opens up new possibilities for autonomous discovery.", "published": "2024-05-02 03:20:08", "link": "http://arxiv.org/abs/2405.00972v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "physics.chem-ph", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "Silencing the Risk, Not the Whistle: A Semi-automated Text Sanitization\n  Tool for Mitigating the Risk of Whistleblower Re-Identification", "abstract": "Whistleblowing is essential for ensuring transparency and accountability in\nboth public and private sectors. However, (potential) whistleblowers often fear\nor face retaliation, even when reporting anonymously. The specific content of\ntheir disclosures and their distinct writing style may re-identify them as the\nsource. Legal measures, such as the EU WBD, are limited in their scope and\neffectiveness. Therefore, computational methods to prevent re-identification\nare important complementary tools for encouraging whistleblowers to come\nforward. However, current text sanitization tools follow a one-size-fits-all\napproach and take an overly limited view of anonymity. They aim to mitigate\nidentification risk by replacing typical high-risk words (such as person names\nand other NE labels) and combinations thereof with placeholders. Such an\napproach, however, is inadequate for the whistleblowing scenario since it\nneglects further re-identification potential in textual features, including\nwriting style. Therefore, we propose, implement, and evaluate a novel\nclassification and mitigation strategy for rewriting texts that involves the\nwhistleblower in the assessment of the risk and utility. Our prototypical tool\nsemi-automatically evaluates risk at the word/term level and applies\nrisk-adapted anonymization techniques to produce a grammatically disjointed yet\nappropriately sanitized text. We then use a LLM that we fine-tuned for\nparaphrasing to render this text coherent and style-neutral. We evaluate our\ntool's effectiveness using court cases from the ECHR and excerpts from a\nreal-world whistleblower testimony and measure the protection against\nauthorship attribution (AA) attacks and utility loss statistically using the\npopular IMDb62 movie reviews dataset. Our method can significantly reduce AA\naccuracy from 98.81% to 31.22%, while preserving up to 73.1% of the original\ncontent's semantics.", "published": "2024-05-02 08:52:29", "link": "http://arxiv.org/abs/2405.01097v1", "categories": ["cs.CY", "cs.CL", "cs.HC", "cs.IR", "cs.SE", "H.3; K.4; H.5; K.5; D.2; J.4"], "primary_category": "cs.CY"}
{"title": "Boosting Jailbreak Attack with Momentum", "abstract": "Large Language Models (LLMs) have achieved remarkable success across diverse\ntasks, yet they remain vulnerable to adversarial attacks, notably the\nwell-known jailbreak attack. In particular, the Greedy Coordinate Gradient\n(GCG) attack has demonstrated efficacy in exploiting this vulnerability by\noptimizing adversarial prompts through a combination of gradient heuristics and\ngreedy search. However, the efficiency of this attack has become a bottleneck\nin the attacking process. To mitigate this limitation, in this paper we rethink\nthe generation of the adversarial prompts through an optimization lens, aiming\nto stabilize the optimization process and harness more heuristic insights from\nprevious optimization iterations. Specifically, we propose the\n\\textbf{M}omentum \\textbf{A}ccelerated G\\textbf{C}G (\\textbf{MAC}) attack,\nwhich integrates a momentum term into the gradient heuristic to boost and\nstabilize the random search for tokens in adversarial prompts. Experimental\nresults showcase the notable enhancement achieved by MAC over baselines in\nterms of attack success rate and optimization efficiency. Moreover, we\ndemonstrate that MAC can still exhibit superior performance for transfer\nattacks and models under defense mechanisms. Our code is available at\nhttps://github.com/weizeming/momentum-attack-llm.", "published": "2024-05-02 12:18:14", "link": "http://arxiv.org/abs/2405.01229v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR", "math.OC"], "primary_category": "cs.LG"}
{"title": "MAIN-VC: Lightweight Speech Representation Disentanglement for One-shot\n  Voice Conversion", "abstract": "One-shot voice conversion aims to change the timbre of any source speech to\nmatch that of the unseen target speaker with only one speech sample. Existing\nmethods face difficulties in satisfactory speech representation disentanglement\nand suffer from sizable networks as some of them leverage numerous complex\nmodules for disentanglement. In this paper, we propose a model named MAIN-VC to\neffectively disentangle via a concise neural network. The proposed model\nutilizes Siamese encoders to learn clean representations, further enhanced by\nthe designed mutual information estimator. The Siamese structure and the newly\ndesigned convolution module contribute to the lightweight of our model while\nensuring performance in diverse voice conversion tasks. The experimental\nresults show that the proposed model achieves comparable subjective scores and\nexhibits improvements in objective metrics compared to existing methods in a\none-shot voice conversion scenario.", "published": "2024-05-02 01:11:15", "link": "http://arxiv.org/abs/2405.00930v2", "categories": ["cs.SD", "eess.AS", "I.2.7; H.5.5"], "primary_category": "cs.SD"}
{"title": "Converting Anyone's Voice: End-to-End Expressive Voice Conversion with a\n  Conditional Diffusion Model", "abstract": "Expressive voice conversion (VC) conducts speaker identity conversion for\nemotional speakers by jointly converting speaker identity and emotional style.\nEmotional style modeling for arbitrary speakers in expressive VC has not been\nextensively explored. Previous approaches have relied on vocoders for speech\nreconstruction, which makes speech quality heavily dependent on the performance\nof vocoders. A major challenge of expressive VC lies in emotion prosody\nmodeling. To address these challenges, this paper proposes a fully end-to-end\nexpressive VC framework based on a conditional denoising diffusion\nprobabilistic model (DDPM). We utilize speech units derived from\nself-supervised speech models as content conditioning, along with deep features\nextracted from speech emotion recognition and speaker verification systems to\nmodel emotional style and speaker identity. Objective and subjective\nevaluations show the effectiveness of our framework. Codes and samples are\npublicly available.", "published": "2024-05-02 20:51:53", "link": "http://arxiv.org/abs/2405.01730v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Benchmarking Representations for Speech, Music, and Acoustic Events", "abstract": "Limited diversity in standardized benchmarks for evaluating audio\nrepresentation learning (ARL) methods may hinder systematic comparison of\ncurrent methods' capabilities. We present ARCH, a comprehensive benchmark for\nevaluating ARL methods on diverse audio classification domains, covering\nacoustic events, music, and speech. ARCH comprises 12 datasets, that allow us\nto thoroughly assess pre-trained SSL models of different sizes. ARCH\nstreamlines benchmarking of ARL techniques through its unified access to a wide\nrange of domains and its ability to readily incorporate new datasets and\nmodels. To address the current lack of open-source, pre-trained models for\nnon-speech audio, we also release new pre-trained models that demonstrate\nstrong performance on non-speech datasets. We argue that the presented\nwide-ranging evaluation provides valuable insights into state-of-the-art ARL\nmethods, and is useful to pinpoint promising research directions.", "published": "2024-05-02 01:24:53", "link": "http://arxiv.org/abs/2405.00934v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving Membership Inference in ASR Model Auditing with Perturbed Loss\n  Features", "abstract": "Membership Inference (MI) poses a substantial privacy threat to the training\ndata of Automatic Speech Recognition (ASR) systems, while also offering an\nopportunity to audit these models with regard to user data. This paper explores\nthe effectiveness of loss-based features in combination with Gaussian and\nadversarial perturbations to perform MI in ASR models. To the best of our\nknowledge, this approach has not yet been investigated. We compare our proposed\nfeatures with commonly used error-based features and find that the proposed\nfeatures greatly enhance performance for sample-level MI. For speaker-level MI,\nthese features improve results, though by a smaller margin, as error-based\nfeatures already obtained a high performance for this task. Our findings\nemphasise the importance of considering different feature sets and levels of\naccess to target models for effective MI in ASR systems, providing valuable\ninsights for auditing such models.", "published": "2024-05-02 11:48:30", "link": "http://arxiv.org/abs/2405.01207v1", "categories": ["cs.LG", "cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "TRAMBA: A Hybrid Transformer and Mamba Architecture for Practical Audio\n  and Bone Conduction Speech Super Resolution and Enhancement on Mobile and\n  Wearable Platforms", "abstract": "We propose TRAMBA, a hybrid transformer and Mamba architecture for acoustic\nand bone conduction speech enhancement, suitable for mobile and wearable\nplatforms. Bone conduction speech enhancement has been impractical to adopt in\nmobile and wearable platforms for several reasons: (i) data collection is\nlabor-intensive, resulting in scarcity; (ii) there exists a performance gap\nbetween state of-art models with memory footprints of hundreds of MBs and\nmethods better suited for resource-constrained systems. To adapt TRAMBA to\nvibration-based sensing modalities, we pre-train TRAMBA with audio speech\ndatasets that are widely available. Then, users fine-tune with a small amount\nof bone conduction data. TRAMBA outperforms state-of-art GANs by up to 7.3% in\nPESQ and 1.8% in STOI, with an order of magnitude smaller memory footprint and\nan inference speed up of up to 465 times. We integrate TRAMBA into real systems\nand show that TRAMBA (i) improves battery life of wearables by up to 160% by\nrequiring less data sampling and transmission; (ii) generates higher quality\nvoice in noisy environments than over-the-air speech; (iii) requires a memory\nfootprint of less than 20.0 MB.", "published": "2024-05-02 12:45:48", "link": "http://arxiv.org/abs/2405.01242v3", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Toolchain for Comprehensive Audio/Video Analysis Using Deep Learning\n  Based Multimodal Approach (A use case of riot or violent context detection)", "abstract": "In this paper, we present a toolchain for a comprehensive audio/video\nanalysis by leveraging deep learning based multimodal approach. To this end,\ndifferent specific tasks of Speech to Text (S2T), Acoustic Scene Classification\n(ASC), Acoustic Event Detection (AED), Visual Object Detection (VOD), Image\nCaptioning (IC), and Video Captioning (VC) are conducted and integrated into\nthe toolchain. By combining individual tasks and analyzing both audio \\& visual\ndata extracted from input video, the toolchain offers various audio/video-based\napplications: Two general applications of audio/video clustering, comprehensive\naudio/video summary and a specific application of riot or violent context\ndetection. Furthermore, the toolchain presents a flexible and adaptable\narchitecture that is effective to integrate new models for further\naudio/video-based applications.", "published": "2024-05-02 07:34:31", "link": "http://arxiv.org/abs/2407.03110v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Learning Models in Speech Recognition: Measuring GPU Energy\n  Consumption, Impact of Noise and Model Quantization for Edge Deployment", "abstract": "Recent transformer-based ASR models have achieved word-error rates (WER)\nbelow 4%, surpassing human annotator accuracy, yet they demand extensive server\nresources, contributing to significant carbon footprints. The traditional\nserver-based architecture of ASR also presents privacy concerns, alongside\nreliability and latency issues due to network dependencies. In contrast,\non-device (edge) ASR enhances privacy, boosts performance, and promotes\nsustainability by effectively balancing energy use and accuracy for specific\napplications. This study examines the effects of quantization, memory demands,\nand energy consumption on the performance of various ASR model inference on the\nNVIDIA Jetson Orin Nano. By analyzing WER and transcription speed across models\nusing FP32, FP16, and INT8 quantization on clean and noisy datasets, we\nhighlight the crucial trade-offs between accuracy, speeds, quantization, energy\nefficiency, and memory needs. We found that changing precision from fp32 to\nfp16 halves the energy consumption for audio transcription across different\nmodels, with minimal performance degradation. A larger model size and number of\nparameters neither guarantees better resilience to noise, nor predicts the\nenergy consumption for a given transcription load. These, along with several\nother findings offer novel insights for optimizing ASR systems within energy-\nand memory-limited environments, crucial for the development of efficient\non-device ASR solutions. The code and input data needed to reproduce the\nresults in this article are open sourced are available on\n[https://github.com/zzadiues3338/ASR-energy-jetson].", "published": "2024-05-02 05:09:07", "link": "http://arxiv.org/abs/2405.01004v1", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.HC", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
