{"title": "Synthetic Dataset for Evaluating Complex Compositional Knowledge for\n  Natural Language Inference", "abstract": "We introduce a synthetic dataset called Sentences Involving Complex\nCompositional Knowledge (SICCK) and a novel analysis that investigates the\nperformance of Natural Language Inference (NLI) models to understand\ncompositionality in logic. We produce 1,304 sentence pairs by modifying 15\nexamples from the SICK dataset (Marelli et al., 2014). To this end, we modify\nthe original texts using a set of phrases - modifiers that correspond to\nuniversal quantifiers, existential quantifiers, negation, and other concept\nmodifiers in Natural Logic (NL) (MacCartney, 2009). We use these phrases to\nmodify the subject, verb, and object parts of the premise and hypothesis.\nLastly, we annotate these modified texts with the corresponding entailment\nlabels following NL rules. We conduct a preliminary verification of how well\nthe change in the structural and semantic composition is captured by neural NLI\nmodels, in both zero-shot and fine-tuned scenarios. We found that the\nperformance of NLI models under the zero-shot setting is poor, especially for\nmodified sentences with negation and existential quantifiers. After fine-tuning\nthis dataset, we observe that models continue to perform poorly over negation,\nexistential and universal modifiers.", "published": "2023-07-11 06:18:07", "link": "http://arxiv.org/abs/2307.05034v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Argumentative Segmentation Enhancement for Legal Summarization", "abstract": "We use the combination of argumentative zoning [1] and a legal argumentative\nscheme to create legal argumentative segments. Based on the argumentative\nsegmentation, we propose a novel task of classifying argumentative segments of\nlegal case decisions. GPT-3.5 is used to generate summaries based on\nargumentative segments. In terms of automatic evaluation metrics, our method\ngenerates higher quality argumentative summaries while leaving out less\nrelevant context as compared to GPT-4 and non-GPT models.", "published": "2023-07-11 07:29:18", "link": "http://arxiv.org/abs/2307.05081v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vacaspati: A Diverse Corpus of Bangla Literature", "abstract": "Bangla (or Bengali) is the fifth most spoken language globally; yet, the\nstate-of-the-art NLP in Bangla is lagging for even simple tasks such as\nlemmatization, POS tagging, etc. This is partly due to lack of a varied quality\ncorpus. To alleviate this need, we build Vacaspati, a diverse corpus of Bangla\nliterature. The literary works are collected from various websites; only those\nworks that are publicly available without copyright violations or restrictions\nare collected. We believe that published literature captures the features of a\nlanguage much better than newspapers, blogs or social media posts which tend to\nfollow only a certain literary pattern and, therefore, miss out on language\nvariety. Our corpus Vacaspati is varied from multiple aspects, including type\nof composition, topic, author, time, space, etc. It contains more than 11\nmillion sentences and 115 million words. We also built a word embedding model,\nVac-FT, using FastText from Vacaspati as well as trained an Electra model,\nVac-BERT, using the corpus. Vac-BERT has far fewer parameters and requires only\na fraction of resources compared to other state-of-the-art transformer models\nand yet performs either better or similar on various downstream tasks. On\nmultiple downstream tasks, Vac-FT outperforms other FastText-based models. We\nalso demonstrate the efficacy of Vacaspati as a corpus by showing that similar\nmodels built from other corpora are not as effective. The models are available\nat https://bangla.iitk.ac.in/.", "published": "2023-07-11 07:32:12", "link": "http://arxiv.org/abs/2307.05083v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Piecing Together Clues: A Benchmark for Evaluating the Detective Skills\n  of Large Language Models", "abstract": "Detectives frequently engage in information detection and reasoning\nsimultaneously when making decisions across various cases, especially when\nconfronted with a vast amount of information. With the rapid development of\nlarge language models~(LLMs), evaluating how these models identify key\ninformation and reason to solve questions becomes increasingly relevant. We\nintroduces the DetectBench, a reading comprehension dataset designed to assess\na model's ability to jointly ability in key information detection and multi-hop\nreasoning when facing complex and implicit information. The DetectBench\ncomprises 3,928 questions, each paired with a paragraph averaging 190 tokens in\nlength. To enhance model's detective skills, we propose the Detective Thinking\nFramework. These methods encourage models to identify all possible clues within\nthe context before reasoning. Our experiments reveal that existing models\nperform poorly in both information detection and multi-hop reasoning. However,\nthe Detective Thinking Framework approach alleviates this issue.", "published": "2023-07-11 08:45:46", "link": "http://arxiv.org/abs/2307.05113v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overview of BioASQ 2023: The eleventh BioASQ challenge on Large-Scale\n  Biomedical Semantic Indexing and Question Answering", "abstract": "This is an overview of the eleventh edition of the BioASQ challenge in the\ncontext of the Conference and Labs of the Evaluation Forum (CLEF) 2023. BioASQ\nis a series of international challenges promoting advances in large-scale\nbiomedical semantic indexing and question answering. This year, BioASQ\nconsisted of new editions of the two established tasks b and Synergy, and a new\ntask (MedProcNER) on semantic annotation of clinical content in Spanish with\nmedical procedures, which have a critical role in medical practice. In this\nedition of BioASQ, 28 competing teams submitted the results of more than 150\ndistinct systems in total for the three different shared tasks of the\nchallenge. Similarly to previous editions, most of the participating systems\nachieved competitive performance, suggesting the continuous advancement of the\nstate-of-the-art in the field.", "published": "2023-07-11 09:20:33", "link": "http://arxiv.org/abs/2307.05131v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mao-Zedong At SemEval-2023 Task 4: Label Represention Multi-Head\n  Attention Model With Contrastive Learning-Enhanced Nearest Neighbor Mechanism\n  For Multi-Label Text Classification", "abstract": "The study of human values is essential in both practical and theoretical\ndomains. With the development of computational linguistics, the creation of\nlarge-scale datasets has made it possible to automatically recognize human\nvalues accurately. SemEval 2023 Task 4\\cite{kiesel:2023} provides a set of\narguments and 20 types of human values that are implicitly expressed in each\nargument. In this paper, we present our team's solution. We use the\nRoberta\\cite{liu_roberta_2019} model to obtain the word vector encoding of the\ndocument and propose a multi-head attention mechanism to establish connections\nbetween specific labels and semantic components. Furthermore, we use a\ncontrastive learning-enhanced K-nearest neighbor\nmechanism\\cite{su_contrastive_2022} to leverage existing instance information\nfor prediction. Our approach achieved an F1 score of 0.533 on the test set and\nranked fourth on the leaderboard.", "published": "2023-07-11 11:12:06", "link": "http://arxiv.org/abs/2307.05174v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explaining Competitive-Level Programming Solutions using LLMs", "abstract": "In this paper, we approach competitive-level programming problem-solving as a\ncomposite task of reasoning and code generation. We propose a novel method to\nautomatically annotate natural language explanations to \\textit{<problem,\nsolution>} pairs. We show that despite poor performance in solving\ncompetitive-level programming problems, state-of-the-art LLMs exhibit a strong\ncapacity in describing and explaining solutions. Our explanation generation\nmethodology can generate a structured solution explanation for the problem\ncontaining descriptions and analysis. To evaluate the quality of the annotated\nexplanations, we examine their effectiveness in two aspects: 1) satisfying the\nhuman programming expert who authored the oracle solution, and 2) aiding LLMs\nin solving problems more effectively. The experimental results on the\nCodeContests dataset demonstrate that while LLM GPT3.5's and GPT-4's abilities\nin describing the solution are comparable, GPT-4 shows a better understanding\nof the key idea behind the solution.", "published": "2023-07-11 15:26:49", "link": "http://arxiv.org/abs/2307.05337v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GujiBERT and GujiGPT: Construction of Intelligent Information Processing\n  Foundation Language Models for Ancient Texts", "abstract": "In the context of the rapid development of large language models, we have\nmeticulously trained and introduced the GujiBERT and GujiGPT language models,\nwhich are foundational models specifically designed for intelligent information\nprocessing of ancient texts. These models have been trained on an extensive\ndataset that encompasses both simplified and traditional Chinese characters,\nallowing them to effectively handle various natural language processing tasks\nrelated to ancient books, including but not limited to automatic sentence\nsegmentation, punctuation, word segmentation, part-of-speech tagging, entity\nrecognition, and automatic translation. Notably, these models have exhibited\nexceptional performance across a range of validation tasks using publicly\navailable datasets. Our research findings highlight the efficacy of employing\nself-supervised methods to further train the models using classical text\ncorpora, thus enhancing their capability to tackle downstream tasks. Moreover,\nit is worth emphasizing that the choice of font, the scale of the corpus, and\nthe initial model selection all exert significant influence over the ultimate\nexperimental outcomes. To cater to the diverse text processing preferences of\nresearchers in digital humanities and linguistics, we have developed three\ndistinct categories comprising a total of nine model variations. We believe\nthat by sharing these foundational language models specialized in the domain of\nancient texts, we can facilitate the intelligent processing and scholarly\nexploration of ancient literary works and, consequently, contribute to the\nglobal dissemination of China's rich and esteemed traditional culture in this\nnew era.", "published": "2023-07-11 15:44:01", "link": "http://arxiv.org/abs/2307.05354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BLUEX: A benchmark based on Brazilian Leading Universities Entrance\n  eXams", "abstract": "One common trend in recent studies of language models (LMs) is the use of\nstandardized tests for evaluation. However, despite being the fifth most spoken\nlanguage worldwide, few such evaluations have been conducted in Portuguese.\nThis is mainly due to the lack of high-quality datasets available to the\ncommunity for carrying out evaluations in Portuguese. To address this gap, we\nintroduce the Brazilian Leading Universities Entrance eXams (BLUEX), a dataset\nof entrance exams from the two leading universities in Brazil: UNICAMP and USP.\nThe dataset includes annotated metadata for evaluating the performance of NLP\nmodels on a variety of subjects. Furthermore, BLUEX includes a collection of\nrecently administered exams that are unlikely to be included in the training\ndata of many popular LMs as of 2023. The dataset is also annotated to indicate\nthe position of images in each question, providing a valuable resource for\nadvancing the state-of-the-art in multimodal language understanding and\nreasoning. We describe the creation and characteristics of BLUEX and establish\na benchmark through experiments with state-of-the-art LMs, demonstrating its\npotential for advancing the state-of-the-art in natural language understanding\nand reasoning in Portuguese. The data and relevant code can be found at\nhttps://github.com/Portuguese-Benchmark-Datasets/BLUEX", "published": "2023-07-11 16:25:09", "link": "http://arxiv.org/abs/2307.05410v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Separate-and-Aggregate: A Transformer-based Patch Refinement Model for\n  Knowledge Graph Completion", "abstract": "Knowledge graph completion (KGC) is the task of inferencing missing facts\nfrom any given knowledge graphs (KG). Previous KGC methods typically represent\nknowledge graph entities and relations as trainable continuous embeddings and\nfuse the embeddings of the entity $h$ (or $t$) and relation $r$ into hidden\nrepresentations of query $(h, r, ?)$ (or $(?, r, t$)) to approximate the\nmissing entities. To achieve this, they either use shallow linear\ntransformations or deep convolutional modules. However, the linear\ntransformations suffer from the expressiveness issue while the deep\nconvolutional modules introduce unnecessary inductive bias, which could\npotentially degrade the model performance. Thus, we propose a novel\nTransformer-based Patch Refinement Model (PatReFormer) for KGC. PatReFormer\nfirst segments the embedding into a sequence of patches and then employs\ncross-attention modules to allow bi-directional embedding feature interaction\nbetween the entities and relations, leading to a better understanding of the\nunderlying KG. We conduct experiments on four popular KGC benchmarks, WN18RR,\nFB15k-237, YAGO37 and DB100K. The experimental results show significant\nperformance improvement from existing KGC methods on standard KGC evaluation\nmetrics, e.g., MRR and H@n. Our analysis first verifies the effectiveness of\nour model design choices in PatReFormer. We then find that PatReFormer can\nbetter capture KG information from a large relation embedding dimension.\nFinally, we demonstrate that the strength of PatReFormer is at complex relation\ntypes, compared to other KGC models", "published": "2023-07-11 06:27:13", "link": "http://arxiv.org/abs/2307.05627v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Better Handling Coreference Resolution in Aspect Level Sentiment\n  Classification by Fine-Tuning Language Models", "abstract": "Customer feedback is invaluable to companies as they refine their products.\nMonitoring customer feedback can be automated with Aspect Level Sentiment\nClassification (ALSC) which allows us to analyse specific aspects of the\nproducts in reviews. Large Language Models (LLMs) are the heart of many\nstate-of-the-art ALSC solutions, but they perform poorly in some scenarios\nrequiring Coreference Resolution (CR). In this work, we propose a framework to\nimprove an LLM's performance on CR-containing reviews by fine tuning on highly\ninferential tasks. We show that the performance improvement is likely\nattributed to the improved model CR ability. We also release a new dataset that\nfocuses on CR in ALSC.", "published": "2023-07-11 12:43:28", "link": "http://arxiv.org/abs/2307.05646v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Robust and Efficient Continual Language Learning", "abstract": "As the application space of language models continues to evolve, a natural\nquestion to ask is how we can quickly adapt models to new tasks. We approach\nthis classic question from a continual learning perspective, in which we aim to\ncontinue fine-tuning models trained on past tasks on new tasks, with the goal\nof \"transferring\" relevant knowledge. However, this strategy also runs the risk\nof doing more harm than good, i.e., negative transfer. In this paper, we\nconstruct a new benchmark of task sequences that target different possible\ntransfer scenarios one might face, such as a sequence of tasks with high\npotential of positive transfer, high potential for negative transfer, no\nexpected effect, or a mixture of each. An ideal learner should be able to\nmaximally exploit information from all tasks that have any potential for\npositive transfer, while also avoiding the negative effects of any distracting\ntasks that may confuse it. We then propose a simple, yet effective, learner\nthat satisfies many of our desiderata simply by leveraging a selective strategy\nfor initializing new models from past task checkpoints. Still, limitations\nremain, and we hope this benchmark can help the community to further build and\nanalyze such learners.", "published": "2023-07-11 19:08:31", "link": "http://arxiv.org/abs/2307.05741v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Machine Translation Data Generation and Augmentation using\n  ChatGPT", "abstract": "Neural models have revolutionized the field of machine translation, but\ncreating parallel corpora is expensive and time-consuming. We investigate an\nalternative to manual parallel corpora - hallucinated parallel corpora created\nby generative language models. Although these models are themselves trained on\nparallel data, they can leverage a multilingual vector space to create data,\nand may be able to supplement small manually-procured corpora. Our experiments\nhighlight two key findings - despite a lack of diversity in their output, the\nhallucinated data improves the translation signal, even when the domain clashes\nwith the original dataset.", "published": "2023-07-11 20:15:47", "link": "http://arxiv.org/abs/2307.05779v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improved POS tagging for spontaneous, clinical speech using data\n  augmentation", "abstract": "This paper addresses the problem of improving POS tagging of transcripts of\nspeech from clinical populations. In contrast to prior work on parsing and POS\ntagging of transcribed speech, we do not make use of an in domain treebank for\ntraining. Instead, we train on an out of domain treebank of newswire using data\naugmentation techniques to make these structures resemble natural, spontaneous\nspeech. We trained a parser with and without the augmented data and tested its\nperformance using manually validated POS tags in clinical speech produced by\npatients with various types of neurodegenerative conditions.", "published": "2023-07-11 20:42:06", "link": "http://arxiv.org/abs/2307.05796v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Understanding In-Context Learning with Contrastive\n  Demonstrations and Saliency Maps", "abstract": "We investigate the role of various demonstration components in the in-context\nlearning (ICL) performance of large language models (LLMs). Specifically, we\nexplore the impacts of ground-truth labels, input distribution, and\ncomplementary explanations, particularly when these are altered or perturbed.\nWe build on previous work, which offers mixed findings on how these elements\ninfluence ICL. To probe these questions, we employ explainable NLP (XNLP)\nmethods and utilize saliency maps of contrastive demonstrations for both\nqualitative and quantitative analysis. Our findings reveal that flipping\nground-truth labels significantly affects the saliency, though it's more\nnoticeable in larger LLMs. Our analysis of the input distribution at a granular\nlevel reveals that changing sentiment-indicative terms in a sentiment analysis\ntask to neutral ones does not have as substantial an impact as altering\nground-truth labels. Finally, we find that the effectiveness of complementary\nexplanations in boosting ICL performance is task-dependent, with limited\nbenefits seen in sentiment analysis tasks compared to symbolic reasoning tasks.\nThese insights are critical for understanding the functionality of LLMs and\nguiding the development of effective demonstrations, which is increasingly\nrelevant in light of the growing use of LLMs in applications such as ChatGPT.\nOur research code is publicly available at https://github.com/paihengxu/XICL.", "published": "2023-07-11 07:03:29", "link": "http://arxiv.org/abs/2307.05052v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Attribute Controlled Dialogue Prompting", "abstract": "Prompt-tuning has become an increasingly popular parameter-efficient method\nfor adapting large pretrained language models to downstream tasks. However,\nboth discrete prompting and continuous prompting assume fixed prompts for all\ndata samples within a task, neglecting the fact that inputs vary greatly in\nsome tasks such as open-domain dialogue generation. In this paper, we present a\nnovel, instance-specific prompt-tuning algorithm for dialogue generation.\nSpecifically, we generate prompts based on instance-level control code, rather\nthan the conversation history, to explore their impact on controlled dialogue\ngeneration. Experiments on popular open-domain dialogue datasets, evaluated on\nboth automated metrics and human evaluation, demonstrate that our method is\nsuperior to prompting baselines and comparable to fine-tuning with only 5%-6%\nof total parameters.", "published": "2023-07-11 12:48:55", "link": "http://arxiv.org/abs/2307.05228v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unleashing the Emergent Cognitive Synergy in Large Language Models: A\n  Task-Solving Agent through Multi-Persona Self-Collaboration", "abstract": "Human intelligence thrives on cognitive synergy, where collaboration among\ndifferent minds yield superior outcomes compared to isolated individuals. In\nthis work, we propose Solo Performance Prompting (SPP), which transforms a\nsingle LLM into a cognitive synergist by engaging in multi-turn\nself-collaboration with multiple personas. A cognitive synergist is an\nintelligent agent that collaboratively combines multiple minds' strengths and\nknowledge to enhance problem-solving in complex tasks. By dynamically\nidentifying and simulating different personas based on task inputs, SPP\nunleashes the potential of cognitive synergy in LLMs. Our in-depth analysis\nshows that assigning multiple fine-grained personas in LLMs improves\nproblem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs,\nexperimental results demonstrate that SPP effectively reduces factual\nhallucination, and maintains strong reasoning capabilities. Additionally,\ncomparative experiments show that cognitive synergy only emerges in GPT-4 and\ndoes not appear in less capable models, such as GPT-3.5-turbo and\nLlama2-13b-chat, which draws an interesting analogy to human development. Code,\ndata, and prompts can be found at:\nhttps://github.com/MikeWangWZHL/Solo-Performance-Prompting.git.", "published": "2023-07-11 14:45:19", "link": "http://arxiv.org/abs/2307.05300v4", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Empowering Cross-lingual Behavioral Testing of NLP Models with\n  Typological Features", "abstract": "A challenge towards developing NLP systems for the world's languages is\nunderstanding how they generalize to typological differences relevant for\nreal-world applications. To this end, we propose M2C, a morphologically-aware\nframework for behavioral testing of NLP models. We use M2C to generate tests\nthat probe models' behavior in light of specific linguistic features in 12\ntypologically diverse languages. We evaluate state-of-the-art language models\non the generated tests. While models excel at most tests in English, we\nhighlight generalization failures to specific typological characteristics such\nas temporal expressions in Swahili and compounding possessives in Finish. Our\nfindings motivate the development of models that address these blind spots.", "published": "2023-07-11 17:33:03", "link": "http://arxiv.org/abs/2307.05454v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ReLoRA: High-Rank Training Through Low-Rank Updates", "abstract": "Despite the dominance and effectiveness of scaling, resulting in large\nnetworks with hundreds of billions of parameters, the necessity to train\noverparameterized models remains poorly understood, while training costs grow\nexponentially. In this paper, we explore parameter-efficient training\ntechniques as an approach to training large neural networks. We introduce a\nnovel method called ReLoRA, which utilizes low-rank updates to train high-rank\nnetworks. We apply ReLoRA to training transformer language models with up to\n1.3B parameters and demonstrate comparable performance to regular neural\nnetwork training. ReLoRA saves up to 5.5Gb of RAM per GPU and improves training\nspeed by 9-40% depending on the model size and hardware setup. Our findings\nshow the potential of parameter-efficient techniques for large-scale\npre-training.", "published": "2023-07-11 18:02:09", "link": "http://arxiv.org/abs/2307.05695v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RoPDA: Robust Prompt-based Data Augmentation for Low-Resource Named\n  Entity Recognition", "abstract": "Data augmentation has been widely used in low-resource NER tasks to tackle\nthe problem of data sparsity. However, previous data augmentation methods have\nthe disadvantages of disrupted syntactic structures, token-label mismatch, and\nrequirement for external knowledge or manual effort. To address these issues,\nwe propose Robust Prompt-based Data Augmentation (RoPDA) for low-resource NER.\nBased on pre-trained language models (PLMs) with continuous prompt, RoPDA\nperforms entity augmentation and context augmentation through five fundamental\naugmentation operations to generate label-flipping and label-preserving\nexamples. To optimize the utilization of the augmented samples, we present two\ntechniques: Self-Consistency Filtering and mixup. The former effectively\neliminates low-quality samples, while the latter prevents performance\ndegradation arising from the direct utilization of label-flipping samples.\nExtensive experiments on three benchmarks from different domains demonstrate\nthat RoPDA significantly improves upon strong baselines, and also outperforms\nstate-of-the-art semi-supervised learning methods when unlabeled data is\nincluded.", "published": "2023-07-11 14:44:14", "link": "http://arxiv.org/abs/2307.07417v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring the Emotional and Mental Well-Being of Individuals with Long\n  COVID Through Twitter Analysis", "abstract": "The COVID-19 pandemic has led to the emergence of Long COVID, a cluster of\nsymptoms that persist after infection. Long COVID patients may also experience\nmental health challenges, making it essential to understand individuals'\nemotional and mental well-being. This study aims to gain a deeper understanding\nof Long COVID individuals' emotional and mental well-being, identify the topics\nthat most concern them, and explore potential correlations between their\nemotions and social media activity. Specifically, we classify tweets into four\ncategories based on the content, detect the presence of six basic emotions, and\nextract prevalent topics. Our analyses reveal that negative emotions dominated\nthroughout the study period, with two peaks during critical periods, such as\nthe outbreak of new COVID variants. The findings of this study have\nimplications for policy and measures for addressing the mental health\nchallenges of individuals with Long COVID and provide a foundation for future\nwork.", "published": "2023-07-11 22:39:45", "link": "http://arxiv.org/abs/2307.07558v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Writer adaptation for offline text recognition: An exploration of neural\n  network-based methods", "abstract": "Handwriting recognition has seen significant success with the use of deep\nlearning. However, a persistent shortcoming of neural networks is that they are\nnot well-equipped to deal with shifting data distributions. In the field of\nhandwritten text recognition (HTR), this shows itself in poor recognition\naccuracy for writers that are not similar to those seen during training. An\nideal HTR model should be adaptive to new writing styles in order to handle the\nvast amount of possible writing styles. In this paper, we explore how HTR\nmodels can be made writer adaptive by using only a handful of examples from a\nnew writer (e.g., 16 examples) for adaptation. Two HTR architectures are used\nas base models, using a ResNet backbone along with either an LSTM or\nTransformer sequence decoder. Using these base models, two methods are\nconsidered to make them writer adaptive: 1) model-agnostic meta-learning\n(MAML), an algorithm commonly used for tasks such as few-shot classification,\nand 2) writer codes, an idea originating from automatic speech recognition.\nResults show that an HTR-specific version of MAML known as MetaHTR improves\nperformance compared to the baseline with a 1.4 to 2.0 improvement in word\nerror rate (WER). The improvement due to writer adaptation is between 0.2 and\n0.7 WER, where a deeper model seems to lend itself better to adaptation using\nMetaHTR than a shallower model. However, applying MetaHTR to larger HTR models\nor sentence-level HTR may become prohibitive due to its high computational and\nmemory requirements. Lastly, writer codes based on learned features or Hinge\nstatistical features did not lead to improved recognition performance.", "published": "2023-07-11 11:35:08", "link": "http://arxiv.org/abs/2307.15071v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "DyCL: Dynamic Neural Network Compilation Via Program Rewriting and Graph\n  Optimization", "abstract": "DL compiler's primary function is to translate DNN programs written in\nhigh-level DL frameworks such as PyTorch and TensorFlow into portable\nexecutables. These executables can then be flexibly executed by the deployed\nhost programs. However, existing DL compilers rely on a tracing mechanism,\nwhich involves feeding a runtime input to a neural network program and tracing\nthe program execution paths to generate the computational graph necessary for\ncompilation. Unfortunately, this mechanism falls short when dealing with modern\ndynamic neural networks (DyNNs) that possess varying computational graphs\ndepending on the inputs. Consequently, conventional DL compilers struggle to\naccurately compile DyNNs into executable code. To address this limitation, we\npropose \\tool, a general approach that enables any existing DL compiler to\nsuccessfully compile DyNNs. \\tool tackles the dynamic nature of DyNNs by\nintroducing a compilation mechanism that redistributes the control and data\nflow of the original DNN programs during the compilation process. Specifically,\n\\tool develops program analysis and program transformation techniques to\nconvert a dynamic neural network into multiple sub-neural networks. Each\nsub-neural network is devoid of conditional statements and is compiled\nindependently. Furthermore, \\tool synthesizes a host module that models the\ncontrol flow of the DyNNs and facilitates the invocation of the sub-neural\nnetworks. Our evaluation demonstrates the effectiveness of \\tool, achieving a\n100\\% success rate in compiling all dynamic neural networks. Moreover, the\ncompiled executables generated by \\tool exhibit significantly improved\nperformance, running between $1.12\\times$ and $20.21\\times$ faster than the\noriginal DyNNs executed on general-purpose DL frameworks.", "published": "2023-07-11 01:53:19", "link": "http://arxiv.org/abs/2307.04963v1", "categories": ["cs.CL", "cs.LG", "cs.PL"], "primary_category": "cs.CL"}
{"title": "Secrets of RLHF in Large Language Models Part I: PPO", "abstract": "Large language models (LLMs) have formulated a blueprint for the advancement\nof artificial general intelligence. Its primary objective is to function as a\nhuman-centric (helpful, honest, and harmless) assistant. Alignment with humans\nassumes paramount significance, and reinforcement learning with human feedback\n(RLHF) emerges as the pivotal technological paradigm underpinning this pursuit.\nCurrent technical routes usually include \\textbf{reward models} to measure\nhuman preferences, \\textbf{Proximal Policy Optimization} (PPO) to optimize\npolicy model outputs, and \\textbf{process supervision} to improve step-by-step\nreasoning capabilities. However, due to the challenges of reward design,\nenvironment interaction, and agent training, coupled with huge trial and error\ncost of large language models, there is a significant barrier for AI\nresearchers to motivate the development of technical alignment and safe landing\nof LLMs. The stable training of RLHF has still been a puzzle. In the first\nreport, we dissect the framework of RLHF, re-evaluate the inner workings of\nPPO, and explore how the parts comprising PPO algorithms impact policy agent\ntraining. We identify policy constraints being the key factor for the effective\nimplementation of the PPO algorithm. Therefore, we explore the PPO-max, an\nadvanced version of PPO algorithm, to efficiently improve the training\nstability of the policy model. Based on our main results, we perform a\ncomprehensive analysis of RLHF abilities compared with SFT models and ChatGPT.\nThe absence of open-source implementations has posed significant challenges to\nthe investigation of LLMs alignment. Therefore, we are eager to release\ntechnical reports, reward models and PPO codes, aiming to make modest\ncontributions to the advancement of LLMs.", "published": "2023-07-11 01:55:24", "link": "http://arxiv.org/abs/2307.04964v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving RNN-Transducers with Acoustic LookAhead", "abstract": "RNN-Transducers (RNN-Ts) have gained widespread acceptance as an end-to-end\nmodel for speech to text conversion because of their high accuracy and\nstreaming capabilities. A typical RNN-T independently encodes the input audio\nand the text context, and combines the two encodings by a thin joint network.\nWhile this architecture provides SOTA streaming accuracy, it also makes the\nmodel vulnerable to strong LM biasing which manifests as multi-step\nhallucination of text without acoustic evidence. In this paper we propose\nLookAhead that makes text representations more acoustically grounded by looking\nahead into the future within the audio input. This technique yields a\nsignificant 5%-20% relative reduction in word error rate on both in-domain and\nout-of-domain evaluation sets.", "published": "2023-07-11 03:57:00", "link": "http://arxiv.org/abs/2307.05006v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for\n  ChatGPT Meta-Learning", "abstract": "This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.", "published": "2023-07-11 07:31:58", "link": "http://arxiv.org/abs/2307.05082v1", "categories": ["cs.AI", "cs.CL", "cs.HC", "68T30, 68T50, 68T42", "H.4.2; H.1.0; I.2.4; I.2.1; I.2.7; E.1"], "primary_category": "cs.AI"}
{"title": "TIAM -- A Metric for Evaluating Alignment in Text-to-Image Generation", "abstract": "The progress in the generation of synthetic images has made it crucial to\nassess their quality. While several metrics have been proposed to assess the\nrendering of images, it is crucial for Text-to-Image (T2I) models, which\ngenerate images based on a prompt, to consider additional aspects such as to\nwhich extent the generated image matches the important content of the prompt.\nMoreover, although the generated images usually result from a random starting\npoint, the influence of this one is generally not considered. In this article,\nwe propose a new metric based on prompt templates to study the alignment\nbetween the content specified in the prompt and the corresponding generated\nimages. It allows us to better characterize the alignment in terms of the type\nof the specified objects, their number, and their color. We conducted a study\non several recent T2I models about various aspects. An additional interesting\nresult we obtained with our approach is that image quality can vary drastically\ndepending on the noise used as a seed for the images. We also quantify the\ninfluence of the number of concepts in the prompt, their order as well as their\n(color) attributes. Finally, our method allows us to identify some seeds that\nproduce better images than others, opening novel directions of research on this\nunderstudied topic.", "published": "2023-07-11 09:23:05", "link": "http://arxiv.org/abs/2307.05134v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SuryaKiran at MEDIQA-Sum 2023: Leveraging LoRA for Clinical Dialogue\n  Summarization", "abstract": "Finetuning Large Language Models helps improve the results for\ndomain-specific use cases. End-to-end finetuning of large language models is\ntime and resource intensive and has high storage requirements to store the\nfinetuned version of the large language model. Parameter Efficient Fine Tuning\n(PEFT) methods address the time and resource challenges by keeping the large\nlanguage model as a fixed base and add additional layers, which the PEFT\nmethods finetune. This paper demonstrates the evaluation results for one such\nPEFT method Low Rank Adaptation (LoRA), for Clinical Dialogue Summarization.\nThe evaluation results show that LoRA works at par with end-to-end finetuning\nfor a large language model. The paper presents the evaluations done for solving\nboth the Subtask A and B from ImageCLEFmedical\n{https://www.imageclef.org/2023/medical}", "published": "2023-07-11 10:38:58", "link": "http://arxiv.org/abs/2307.05162v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "U-CREAT: Unsupervised Case Retrieval using Events extrAcTion", "abstract": "The task of Prior Case Retrieval (PCR) in the legal domain is about\nautomatically citing relevant (based on facts and precedence) prior legal cases\nin a given query case. To further promote research in PCR, in this paper, we\npropose a new large benchmark (in English) for the PCR task: IL-PCR (Indian\nLegal Prior Case Retrieval) corpus. Given the complex nature of case relevance\nand the long size of legal documents, BM25 remains a strong baseline for\nranking the cited prior documents. In this work, we explore the role of events\nin legal case retrieval and propose an unsupervised retrieval method-based\npipeline U-CREAT (Unsupervised Case Retrieval using Events Extraction). We find\nthat the proposed unsupervised retrieval method significantly increases\nperformance compared to BM25 and makes retrieval faster by a considerable\nmargin, making it applicable to real-time case retrieval systems. Our proposed\nsystem is generic, we show that it generalizes across two different legal\nsystems (Indian and Canadian), and it shows state-of-the-art performance on the\nbenchmarks for both the legal systems (IL-PCR and COLIEE corpora).", "published": "2023-07-11 13:51:12", "link": "http://arxiv.org/abs/2307.05260v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Duncode Characters Shorter", "abstract": "This paper investigates the employment of various encoders in text\ntransformation, converting characters into bytes. It discusses local encoders\nsuch as ASCII and GB-2312, which encode specific characters into shorter bytes,\nand universal encoders like UTF-8 and UTF-16, which can encode the complete\nUnicode set with greater space requirements and are gaining widespread\nacceptance. Other encoders, including SCSU, BOCU-1, and binary encoders,\nhowever, lack self-synchronizing capabilities. Duncode is introduced as an\ninnovative encoding method that aims to encode the entire Unicode character set\nwith high space efficiency, akin to local encoders. It has the potential to\ncompress multiple characters of a string into a Duncode unit using fewer bytes.\nDespite offering less self-synchronizing identification information, Duncode\nsurpasses UTF8 in terms of space efficiency. The application is available at\n\\url{https://github.com/laohur/duncode}. Additionally, we have developed a\nbenchmark for evaluating character encoders across different languages. It\nencompasses 179 languages and can be accessed at\n\\url{https://github.com/laohur/wiki2txt}.", "published": "2023-07-11 16:30:45", "link": "http://arxiv.org/abs/2307.05414v1", "categories": ["cs.CL", "cs.DB", "cs.IR", "68P30, 68P20", "E.2"], "primary_category": "cs.CL"}
{"title": "ISLTranslate: Dataset for Translating Indian Sign Language", "abstract": "Sign languages are the primary means of communication for many\nhard-of-hearing people worldwide. Recently, to bridge the communication gap\nbetween the hard-of-hearing community and the rest of the population, several\nsign language translation datasets have been proposed to enable the development\nof statistical sign language translation systems. However, there is a dearth of\nsign language resources for the Indian sign language. This resource paper\nintroduces ISLTranslate, a translation dataset for continuous Indian Sign\nLanguage (ISL) consisting of 31k ISL-English sentence/phrase pairs. To the best\nof our knowledge, it is the largest translation dataset for continuous Indian\nSign Language. We provide a detailed analysis of the dataset. To validate the\nperformance of existing end-to-end Sign language to spoken language translation\nsystems, we benchmark the created dataset with a transformer-based model for\nISL translation.", "published": "2023-07-11 17:06:52", "link": "http://arxiv.org/abs/2307.05440v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Models", "abstract": "Artificial intelligence is making spectacular progress, and one of the best\nexamples is the development of large language models (LLMs) such as OpenAI's\nGPT series. In these lectures, written for readers with a background in\nmathematics or physics, we give a brief history and survey of the state of the\nart, and describe the underlying transformer architecture in detail. We then\nexplore some current ideas on how LLMs work and how models trained to predict\nthe next word in a text are able to perform other tasks displaying\nintelligence.", "published": "2023-07-11 20:21:02", "link": "http://arxiv.org/abs/2307.05782v2", "categories": ["cs.CL", "hep-th", "math.HO", "physics.comp-ph", "68T01", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Relational Extraction on Wikipedia Tables using Convolutional and Memory\n  Networks", "abstract": "Relation extraction (RE) is the task of extracting relations between entities\nin text. Most RE methods extract relations from free-form running text and\nleave out other rich data sources, such as tables. We explore RE from the\nperspective of applying neural methods on tabularly organized data. We\nintroduce a new model consisting of Convolutional Neural Network (CNN) and\nBidirectional-Long Short Term Memory (BiLSTM) network to encode entities and\nlearn dependencies among them, respectively. We evaluate our model on a large\nand recent dataset and compare results with previous neural methods.\nExperimental results show that our model consistently outperforms the previous\nmodel for the task of relation extraction on tabular data. We perform\ncomprehensive error analyses and ablation study to show the contribution of\nvarious components of our model. Finally, we discuss the usefulness and\ntrade-offs of our approach, and provide suggestions for fostering further\nresearch.", "published": "2023-07-11 22:36:47", "link": "http://arxiv.org/abs/2307.05827v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Lightweight reranking for language model generations", "abstract": "Large Language Models (LLMs) can exhibit considerable variation in the\nquality of their sampled outputs. Reranking and selecting the best generation\nfrom the sampled set is a popular way of obtaining strong gains in generation\nquality. In this paper, we present a novel approach for reranking LLM\ngenerations. Unlike other techniques that might involve additional inferences\nor training a specialized reranker, our approach relies on easy to compute\npairwise statistics between the generations that have minimal compute overhead.\nWe show that our approach can be formalized as an extension of self-consistency\nand analyze its performance in that framework, theoretically as well as via\nsimulations. We show strong improvements for selecting the best k generations\nfor code generation tasks as well as robust improvements for the best\ngeneration for the tasks of autoformalization, summarization, and translation.\nWhile our approach only assumes black-box access to LLMs, we show that\nadditional access to token probabilities can improve performance even further.", "published": "2023-07-11 17:51:48", "link": "http://arxiv.org/abs/2307.06857v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Named entity recognition using GPT for identifying comparable companies", "abstract": "For both public and private firms, comparable companies' analysis is widely\nused as a method for company valuation. In particular, the method is of great\nvalue for valuation of private equity companies. The several approaches to the\ncomparable companies' method usually rely on a qualitative approach to\nidentifying similar peer companies, which tend to use established industry\nclassification schemes and/or analyst intuition and knowledge. However, more\nquantitative methods have started being used in the literature and in the\nprivate equity industry, in particular, machine learning clustering, and\nnatural language processing (NLP). For NLP methods, the process consists of\nextracting product entities from e.g., the company's website or company\ndescriptions from some financial database system and then to perform similarity\nanalysis. Here, using companies' descriptions/summaries from publicly available\ncompanies' Wikipedia websites, we show that using large language models (LLMs),\nsuch as GPT from OpenAI, has a much higher precision and success rate than\nusing the standard named entity recognition (NER) methods which use manual\nannotation. We demonstrate quantitatively a higher precision rate, and show\nthat, qualitatively, it can be used to create appropriate comparable companies\npeer groups which could then be used for equity valuation.", "published": "2023-07-11 16:48:16", "link": "http://arxiv.org/abs/2307.07420v2", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
{"title": "The smarty4covid dataset and knowledge base: a framework enabling\n  interpretable analysis of audio signals", "abstract": "Harnessing the power of Artificial Intelligence (AI) and m-health towards\ndetecting new bio-markers indicative of the onset and progress of respiratory\nabnormalities/conditions has greatly attracted the scientific and research\ninterest especially during COVID-19 pandemic. The smarty4covid dataset contains\naudio signals of cough (4,676), regular breathing (4,665), deep breathing\n(4,695) and voice (4,291) as recorded by means of mobile devices following a\ncrowd-sourcing approach. Other self reported information is also included (e.g.\nCOVID-19 virus tests), thus providing a comprehensive dataset for the\ndevelopment of COVID-19 risk detection models. The smarty4covid dataset is\nreleased in the form of a web-ontology language (OWL) knowledge base enabling\ndata consolidation from other relevant datasets, complex queries and reasoning.\nIt has been utilized towards the development of models able to: (i) extract\nclinically informative respiratory indicators from regular breathing records,\nand (ii) identify cough, breath and voice segments in crowd-sourced audio\nrecordings. A new framework utilizing the smarty4covid OWL knowledge base\ntowards generating counterfactual explanations in opaque AI-based COVID-19 risk\ndetection models is proposed and validated.", "published": "2023-07-11 08:10:58", "link": "http://arxiv.org/abs/2307.05096v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ShredGP: Guitarist Style-Conditioned Tablature Generation", "abstract": "GuitarPro format tablatures are a type of digital music notation that\nencapsulates information about guitar playing techniques and fingerings. We\nintroduce ShredGP, a GuitarPro tablature generative Transformer-based model\nconditioned to imitate the style of four distinct iconic electric guitarists.\nIn order to assess the idiosyncrasies of each guitar player, we adopt a\ncomputational musicology methodology by analysing features computed from the\ntokens yielded by the DadaGP encoding scheme. Statistical analyses of the\nfeatures evidence significant differences between the four guitarists. We\ntrained two variants of the ShredGP model, one using a multi-instrument corpus,\nthe other using solo guitar data. We present a BERT-based model for guitar\nplayer classification and use it to evaluate the generated examples. Overall,\nresults from the classifier show that ShredGP is able to generate content\ncongruent with the style of the targeted guitar player. Finally, we reflect on\nprospective applications for ShredGP for human-AI music interaction.", "published": "2023-07-11 15:11:02", "link": "http://arxiv.org/abs/2307.05324v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Point to the Hidden: Exposing Speech Audio Splicing via Signal Pointer\n  Nets", "abstract": "Verifying the integrity of voice recording evidence for criminal\ninvestigations is an integral part of an audio forensic analyst's work. Here,\none focus is on detecting deletion or insertion operations, so called audio\nsplicing. While this is a rather easy approach to alter spoken statements,\ncareful editing can yield quite convincing results. For difficult cases or big\namounts of data, automated tools can support in detecting potential editing\nlocations. To this end, several analytical and deep learning methods have been\nproposed by now. Still, few address unconstrained splicing scenarios as\nexpected in practice. With SigPointer, we propose a pointer network framework\nfor continuous input that uncovers splice locations naturally and more\nefficiently than existing works. Extensive experiments on forensically\nchallenging data like strongly compressed and noisy signals quantify the\nbenefit of the pointer mechanism with performance increases between about 6 to\n10 percentage points.", "published": "2023-07-11 10:14:59", "link": "http://arxiv.org/abs/2307.05641v4", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Optimizing Feature Extraction for Symbolic Music", "abstract": "This paper presents a comprehensive investigation of existing feature\nextraction tools for symbolic music and contrasts their performance to\ndetermine the set of features that best characterizes the musical style of a\ngiven music score. In this regard, we propose a novel feature extraction tool,\nnamed musif, and evaluate its efficacy on various repertoires and file formats,\nincluding MIDI, MusicXML, and **kern. Musif approximates existing tools such as\njSymbolic and music21 in terms of computational efficiency while attempting to\nenhance the usability for custom feature development. The proposed tool also\nenhances classification accuracy when combined with other sets of features. We\ndemonstrate the contribution of each set of features and the computational\nresources they require. Our findings indicate that the optimal tool for feature\nextraction is a combination of the best features from each tool rather than\nthose of a single one. To facilitate future research in music information\nretrieval, we release the source code of the tool and benchmarks.", "published": "2023-07-11 08:34:11", "link": "http://arxiv.org/abs/2307.05107v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On the Use of Self-Supervised Speech Representations in Spontaneous\n  Speech Synthesis", "abstract": "Self-supervised learning (SSL) speech representations learned from large\namounts of diverse, mixed-quality speech data without transcriptions are\ngaining ground in many speech technology applications. Prior work has shown\nthat SSL is an effective intermediate representation in two-stage\ntext-to-speech (TTS) for both read and spontaneous speech. However, it is still\nnot clear which SSL and which layer from each SSL model is most suited for\nspontaneous TTS. We address this shortcoming by extending the scope of\ncomparison for SSL in spontaneous TTS to 6 different SSLs and 3 layers within\neach SSL. Furthermore, SSL has also shown potential in predicting the mean\nopinion scores (MOS) of synthesized speech, but this has only been done in\nread-speech MOS prediction. We extend an SSL-based MOS prediction framework\npreviously developed for scoring read speech synthesis and evaluate its\nperformance on synthesized spontaneous speech. All experiments are conducted\ntwice on two different spontaneous corpora in order to find generalizable\ntrends. Overall, we present comprehensive experimental results on the use of\nSSL in spontaneous TTS and MOS prediction to further quantify and understand\nhow SSL can be used in spontaneous TTS. Audios samples:\nhttps://www.speech.kth.se/tts-demos/sp_ssl_tts", "published": "2023-07-11 09:22:10", "link": "http://arxiv.org/abs/2307.05132v1", "categories": ["eess.AS", "cs.HC", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Aeroacoustic testing on a full aircraft model at high Reynolds numbers\n  in the European Transonic Windtunnel", "abstract": "This paper presents an end-to-end approach for the assessment of pressurized\nand cryogenic wind tunnel measurements of an EMBRAER scaled full model close to\nreal-world Reynolds numbers. The choice of microphones, measurement parameters,\nthe design of the array, and the selection of flow parameters are discussed.\nDifferent wind tunnel conditions are proposed which allow separating the\ninfluence of the Reynolds number from the Mach number, as well as the influence\nof slotted and closed test sections. The paper provides three-dimensional\nbeamforming results with CLEAN-SC deconvolution, the selection of regions of\ninterest, and the corresponding source spectra. The results suggest that\nslotted test sections have little influence on the beamforming results compared\nto closed test sections and that the Reynolds number has a profound, non-linear\nimpact on the aeroacoustic emission that lessens with increasing Reynolds\nnumber. Further, sources show a non-linear Mach number dependency at constant\nReynolds number but are self-similar in the observed Mach number range. The\nfindings suggest that it is possible to study real-world phenomena on\nsmall-scale full models at real-world Reynolds numbers, which enable further\ninvestigations in the future such as the directivity of sources.", "published": "2023-07-11 09:34:12", "link": "http://arxiv.org/abs/2307.05140v1", "categories": ["physics.flu-dyn", "cs.SD", "eess.AS"], "primary_category": "physics.flu-dyn"}
{"title": "On the Effectiveness of Speech Self-supervised Learning for Music", "abstract": "Self-supervised learning (SSL) has shown promising results in various speech\nand natural language processing applications. However, its efficacy in music\ninformation retrieval (MIR) still remains largely unexplored. While previous\nSSL models pre-trained on music recordings may have been mostly closed-sourced,\nrecent speech models such as wav2vec2.0 have shown promise in music modelling.\nNevertheless, research exploring the effectiveness of applying speech SSL\nmodels to music recordings has been limited. We explore the music adaption of\nSSL with two distinctive speech-related models, data2vec1.0 and Hubert, and\nrefer to them as music2vec and musicHuBERT, respectively. We train $12$ SSL\nmodels with 95M parameters under various pre-training configurations and\nsystematically evaluate the MIR task performances with 13 different MIR tasks.\nOur findings suggest that training with music data can generally improve\nperformance on MIR tasks, even when models are trained using paradigms designed\nfor speech. However, we identify the limitations of such existing\nspeech-oriented designs, especially in modelling polyphonic information. Based\non the experimental results, empirical suggestions are also given for designing\nfuture musical SSL strategies and paradigms.", "published": "2023-07-11 10:37:57", "link": "http://arxiv.org/abs/2307.05161v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ProgGP: From GuitarPro Tablature Neural Generation To Progressive Metal\n  Production", "abstract": "Recent work in the field of symbolic music generation has shown value in\nusing a tokenization based on the GuitarPro format, a symbolic representation\nsupporting guitar expressive attributes, as an input and output representation.\nWe extend this work by fine-tuning a pre-trained Transformer model on ProgGP, a\ncustom dataset of 173 progressive metal songs, for the purposes of creating\ncompositions from that genre through a human-AI partnership. Our model is able\nto generate multiple guitar, bass guitar, drums, piano and orchestral parts. We\nexamine the validity of the generated music using a mixed methods approach by\ncombining quantitative analyses following a computational musicology paradigm\nand qualitative analyses following a practice-based research paradigm. Finally,\nwe demonstrate the value of the model by using it as a tool to create a\nprogressive metal song, fully produced and mixed by a human metal producer\nbased on AI-generated music.", "published": "2023-07-11 15:19:47", "link": "http://arxiv.org/abs/2307.05328v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speech Diarization and ASR with GMM", "abstract": "In this research paper, we delve into the topics of Speech Diarization and\nAutomatic Speech Recognition (ASR). Speech diarization involves the separation\nof individual speakers within an audio stream. By employing the ASR transcript,\nthe diarization process aims to segregate each speaker's utterances, grouping\nthem based on their unique audio characteristics. On the other hand, Automatic\nSpeech Recognition refers to the capability of a machine or program to identify\nand convert spoken words and phrases into a machine-readable format. In our\nspeech diarization approach, we utilize the Gaussian Mixer Model (GMM) to\nrepresent speech segments. The inter-cluster distance is computed based on the\nGMM parameters, and the distance threshold serves as the stopping criterion.\nASR entails the conversion of an unknown speech waveform into a corresponding\nwritten transcription. The speech signal is analyzed using synchronized\nalgorithms, taking into account the pitch frequency. Our primary objective\ntypically revolves around developing a model that minimizes the Word Error Rate\n(WER) metric during speech transcription.", "published": "2023-07-11 09:25:39", "link": "http://arxiv.org/abs/2307.05637v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SnakeSynth: New Interactions for Generative Audio Synthesis", "abstract": "I present \"SnakeSynth,\" a web-based lightweight audio synthesizer that\ncombines audio generated by a deep generative model and real-time continuous\ntwo-dimensional (2D) input to create and control variable-length generative\nsounds through 2D interaction gestures. Interaction gestures are touch and\nmobile-compatible with analogies to strummed, bowed, and plucked musical\ninstrument controls. Point-and-click and drag-and-drop gestures directly\ncontrol audio playback length and I show that sound length and intensity are\nmodulated by interactions with a programmable 2D coordinate grid. Leveraging\nthe speed and ubiquity of browser-based audio and hardware acceleration in\nGoogle's TensorFlow.js we generate time-varying high-fidelity sounds with\nreal-time interactivity. SnakeSynth adaptively reproduces and interpolates\nbetween sounds encountered during model training, notably without long training\ntimes, and I briefly discuss possible futures for deep generative models as an\ninteractive paradigm for musical expression.", "published": "2023-07-11 22:51:54", "link": "http://arxiv.org/abs/2307.05830v1", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "AnuraSet: A dataset for benchmarking Neotropical anuran calls\n  identification in passive acoustic monitoring", "abstract": "Global change is predicted to induce shifts in anuran acoustic behavior,\nwhich can be studied through passive acoustic monitoring (PAM). Understanding\nchanges in calling behavior requires the identification of anuran species,\nwhich is challenging due to the particular characteristics of neotropical\nsoundscapes. In this paper, we introduce a large-scale multi-species dataset of\nanuran amphibians calls recorded by PAM, that comprises 27 hours of expert\nannotations for 42 different species from two Brazilian biomes. We provide open\naccess to the dataset, including the raw recordings, experimental setup code,\nand a benchmark with a baseline model of the fine-grained categorization\nproblem. Additionally, we highlight the challenges of the dataset to encourage\nmachine learning researchers to solve the problem of anuran call identification\ntowards conservation policy. All our experiments and resources can be found on\nour GitHub repository https://github.com/soundclim/anuraset.", "published": "2023-07-11 22:25:21", "link": "http://arxiv.org/abs/2307.06860v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Musical Excellence of Mridangam: an introductory review", "abstract": "This is an introductory review of Musical Excellence of Mridangam by Dr.\nUmayalpuram K Sivaraman, Dr. T Ramasami and Dr. Naresh, which is a scientific\ntreatise exploring the unique tonal properties of the ancient Indian classical\npercussive instrument -- the Mridangam. This review aims to bridge the gap\nbetween the primary intended audience of Musical Excellence of Mridangam -\nlisteners, artistes and makers -- and the scientific rigour with which the\noriginal treatise is written, by first introducing the concepts of musical\nanalysis and then presenting and explaining the discoveries made within this\ncontext. The first three chapters of this review introduce the basic scientific\nconcepts used in Musical Excellence of Mridangam and provides background to\nprevious scientific research into this instrument, starting from the seminal\nwork of Dr. CV Raman. This also includes brief discussions of the corresponding\nchapters in Musical Excellence of Mridangam. The next chapters all serve the\npurpose of explaining the main scientific results presented in Musical\nExcellence of Mridangam in each of the corresponding chapters in the treatise,\nand finally summarizing the relevance of the work.", "published": "2023-07-11 06:24:38", "link": "http://arxiv.org/abs/2307.09425v1", "categories": ["cs.SD", "eess.AS", "physics.pop-ph"], "primary_category": "cs.SD"}
