{"title": "KoParadigm: A Korean Conjugation Paradigm Generator", "abstract": "Korean is a morphologically rich language. Korean verbs change their forms in\na fickle manner depending on tense, mood, speech level, meaning, etc.\nTherefore, it is challenging to construct comprehensive conjugation paradigms\nof Korean verbs. In this paper we introduce a Korean (verb) conjugation\nparadigm generator, dubbed KoParadigm. To the best of our knowledge, it is the\nfirst Korean conjugation module that covers all contemporary Korean verbs and\nendings. KoParadigm is not only linguistically well established, but also\ncomputationally simple and efficient. We share it via PyPi.", "published": "2020-04-28 00:28:09", "link": "http://arxiv.org/abs/2004.13221v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conversational Word Embedding for Retrieval-Based Dialog System", "abstract": "Human conversations contain many types of information, e.g., knowledge,\ncommon sense, and language habits. In this paper, we propose a conversational\nword embedding method named PR-Embedding, which utilizes the conversation pairs\n$ \\left\\langle{post, reply} \\right\\rangle$ to learn word embedding. Different\nfrom previous works, PR-Embedding uses the vectors from two different semantic\nspaces to represent the words in post and reply. To catch the information among\nthe pair, we first introduce the word alignment model from statistical machine\ntranslation to generate the cross-sentence window, then train the embedding on\nword-level and sentence-level. We evaluate the method on single-turn and\nmulti-turn response selection tasks for retrieval-based dialog systems. The\nexperiment results show that PR-Embedding can improve the quality of the\nselected response. PR-Embedding source code is available at\nhttps://github.com/wtma/PR-Embedding", "published": "2020-04-28 02:43:36", "link": "http://arxiv.org/abs/2004.13249v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Learn Morphological Inflection for Resource-Poor Languages", "abstract": "We propose to cast the task of morphological inflection - mapping a lemma to\nan indicated inflected form - for resource-poor languages as a meta-learning\nproblem. Treating each language as a separate task, we use data from\nhigh-resource source languages to learn a set of model parameters that can\nserve as a strong initialization point for fine-tuning on a resource-poor\ntarget language. Experiments with two model architectures on 29 target\nlanguages from 3 families show that our suggested approach outperforms all\nbaselines. In particular, it obtains a 31.7% higher absolute accuracy than a\npreviously proposed cross-lingual transfer model and outperforms the previous\nstate of the art by 1.7% absolute accuracy on average over languages.", "published": "2020-04-28 05:13:17", "link": "http://arxiv.org/abs/2004.13304v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Weakly Supervised POS Taggers Perform Poorly on Truly Low-Resource\n  Languages", "abstract": "Part-of-speech (POS) taggers for low-resource languages which are exclusively\nbased on various forms of weak supervision - e.g., cross-lingual transfer,\ntype-level supervision, or a combination thereof - have been reported to\nperform almost as well as supervised ones. However, weakly supervised POS\ntaggers are commonly only evaluated on languages that are very different from\ntruly low-resource languages, and the taggers use sources of information, like\nhigh-coverage and almost error-free dictionaries, which are likely not\navailable for resource-poor languages. We train and evaluate state-of-the-art\nweakly supervised POS taggers for a typologically diverse set of 15 truly\nlow-resource languages. On these languages, given a realistic amount of\nresources, even our best model gets only less than half of the words right. Our\nresults highlight the need for new and different approaches to POS tagging for\ntruly low-resource languages.", "published": "2020-04-28 05:14:08", "link": "http://arxiv.org/abs/2004.13305v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Attention with Cross-Lingual Position Representation", "abstract": "Position encoding (PE), an essential part of self-attention networks (SANs),\nis used to preserve the word order information for natural language processing\ntasks, generating fixed position indices for input sequences. However, in\ncross-lingual scenarios, e.g. machine translation, the PEs of source and target\nsentences are modeled independently. Due to word order divergences in different\nlanguages, modeling the cross-lingual positional relationships might help SANs\ntackle this problem. In this paper, we augment SANs with \\emph{cross-lingual\nposition representations} to model the bilingually aware latent structure for\nthe input sentence. Specifically, we utilize bracketing transduction grammar\n(BTG)-based reordering information to encourage SANs to learn bilingual\ndiagonal alignments. Experimental results on WMT'14 English$\\Rightarrow$German,\nWAT'17 Japanese$\\Rightarrow$English, and WMT'17 Chinese$\\Leftrightarrow$English\ntranslation tasks demonstrate that our approach significantly and consistently\nimproves translation quality over strong baselines. Extensive analyses confirm\nthat the performance gains come from the cross-lingual information.", "published": "2020-04-28 05:23:43", "link": "http://arxiv.org/abs/2004.13310v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Let's be Humorous: Knowledge Enhanced Humor Generation", "abstract": "The generation of humor is an under-explored and challenging problem.\nPrevious works mainly utilize templates or replace phrases to generate humor.\nHowever, few works focus on freer forms and the background knowledge of humor.\nThe linguistic theory of humor defines the structure of a humor sentence as\nset-up and punchline. In this paper, we explore how to generate a punchline\ngiven the set-up with the relevant knowledge. We propose a framework that can\nfuse the knowledge to end-to-end models. To our knowledge, this is the first\nattempt to generate punchlines with knowledge enhanced model. Furthermore, we\ncreate the first humor-knowledge dataset. The experimental results demonstrate\nthat our method can make use of knowledge to generate fluent, funny punchlines,\nwhich outperforms several baselines.", "published": "2020-04-28 06:06:18", "link": "http://arxiv.org/abs/2004.13317v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantics-Aware Inferential Network for Natural Language Understanding", "abstract": "For natural language understanding tasks, either machine reading\ncomprehension or natural language inference, both semantics-aware and inference\nare favorable features of the concerned modeling for better understanding\nperformance. Thus we propose a Semantics-Aware Inferential Network (SAIN) to\nmeet such a motivation. Taking explicit contextualized semantics as a\ncomplementary input, the inferential module of SAIN enables a series of\nreasoning steps over semantic clues through an attention mechanism. By\nstringing these steps, the inferential network effectively learns to perform\niterative reasoning which incorporates both explicit semantics and\ncontextualized representations. In terms of well pre-trained language models as\nfront-end encoder, our model achieves significant improvement on 11 tasks\nincluding machine reading comprehension and natural language inference.", "published": "2020-04-28 07:24:43", "link": "http://arxiv.org/abs/2004.13338v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Effective Transition-based Model for Discontinuous NER", "abstract": "Unlike widely used Named Entity Recognition (NER) data sets in generic\ndomains, biomedical NER data sets often contain mentions consisting of\ndiscontinuous spans. Conventional sequence tagging techniques encode Markov\nassumptions that are efficient but preclude recovery of these mentions. We\npropose a simple, effective transition-based model with generic neural encoding\nfor discontinuous NER. Through extensive experiments on three biomedical data\nsets, we show that our model can effectively recognize discontinuous mentions\nwithout sacrificing the accuracy on continuous mentions.", "published": "2020-04-28 12:19:12", "link": "http://arxiv.org/abs/2004.13454v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Embarrassingly Simple Unsupervised Aspect Extraction", "abstract": "We present a simple but effective method for aspect identification in\nsentiment analysis. Our unsupervised method only requires word embeddings and a\nPOS tagger, and is therefore straightforward to apply to new domains and\nlanguages. We introduce Contrastive Attention (CAt), a novel single-head\nattention mechanism based on an RBF kernel, which gives a considerable boost in\nperformance and makes the model interpretable. Previous work relied on\nsyntactic features and complex neural models. We show that given the simplicity\nof current benchmark datasets for aspect extraction, such complex models are\nnot needed. The code to reproduce the experiments reported in this paper is\navailable at https://github.com/clips/cat", "published": "2020-04-28 15:09:51", "link": "http://arxiv.org/abs/2004.13580v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MAVEN: A Massive General Domain Event Detection Dataset", "abstract": "Event detection (ED), which means identifying event trigger words and\nclassifying event types, is the first and most fundamental step for extracting\nevent knowledge from plain text. Most existing datasets exhibit the following\nissues that limit further development of ED: (1) Data scarcity. Existing\nsmall-scale datasets are not sufficient for training and stably benchmarking\nincreasingly sophisticated modern neural methods. (2) Low coverage. Limited\nevent types of existing datasets cannot well cover general-domain events, which\nrestricts the applications of ED models. To alleviate these problems, we\npresent a MAssive eVENt detection dataset (MAVEN), which contains 4,480\nWikipedia documents, 118,732 event mention instances, and 168 event types.\nMAVEN alleviates the data scarcity problem and covers much more general event\ntypes. We reproduce the recent state-of-the-art ED models and conduct a\nthorough evaluation on MAVEN. The experimental results show that existing ED\nmethods cannot achieve promising results on MAVEN as on the small datasets,\nwhich suggests that ED in the real world remains a challenging task and\nrequires further research efforts. We also discuss further directions for\ngeneral domain ED with empirical analyses. The source code and dataset can be\nobtained from https://github.com/THU-KEG/MAVEN-dataset.", "published": "2020-04-28 15:25:19", "link": "http://arxiv.org/abs/2004.13590v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Event Extraction by Answering (Almost) Natural Questions", "abstract": "The problem of event extraction requires detecting the event trigger and\nextracting its corresponding arguments. Existing work in event argument\nextraction typically relies heavily on entity recognition as a\npreprocessing/concurrent step, causing the well-known problem of error\npropagation. To avoid this issue, we introduce a new paradigm for event\nextraction by formulating it as a question answering (QA) task that extracts\nthe event arguments in an end-to-end manner. Empirical results demonstrate that\nour framework outperforms prior methods substantially; in addition, it is\ncapable of extracting event arguments for roles not seen at training time\n(zero-shot learning setting).", "published": "2020-04-28 16:15:46", "link": "http://arxiv.org/abs/2004.13625v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Capturing Global Informativeness in Open Domain Keyphrase Extraction", "abstract": "Open-domain KeyPhrase Extraction (KPE) aims to extract keyphrases from\ndocuments without domain or quality restrictions, e.g., web pages with variant\ndomains and qualities. Recently, neural methods have shown promising results in\nmany KPE tasks due to their powerful capacity for modeling contextual semantics\nof the given documents. However, we empirically show that most neural KPE\nmethods prefer to extract keyphrases with good phraseness, such as short and\nentity-style n-grams, instead of globally informative keyphrases from\nopen-domain documents. This paper presents JointKPE, an open-domain KPE\narchitecture built on pre-trained language models, which can capture both local\nphraseness and global informativeness when extracting keyphrases. JointKPE\nlearns to rank keyphrases by estimating their informativeness in the entire\ndocument and is jointly trained on the keyphrase chunking task to guarantee the\nphraseness of keyphrase candidates. Experiments on two large KPE datasets with\ndiverse domains, OpenKP and KP20k, demonstrate the effectiveness of JointKPE on\ndifferent pre-trained variants in open-domain scenarios. Further analyses\nreveal the significant advantages of JointKPE in predicting long and non-entity\nkeyphrases, which are challenging for previous neural KPE methods. Our code is\npublicly available at https://github.com/thunlp/BERT-KPE.", "published": "2020-04-28 16:34:35", "link": "http://arxiv.org/abs/2004.13639v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extending Multilingual BERT to Low-Resource Languages", "abstract": "Multilingual BERT (M-BERT) has been a huge success in both supervised and\nzero-shot cross-lingual transfer learning. However, this success has focused\nonly on the top 104 languages in Wikipedia that it was trained on. In this\npaper, we propose a simple but effective approach to extend M-BERT (E-BERT) so\nthat it can benefit any new language, and show that our approach benefits\nlanguages that are already in M-BERT as well. We perform an extensive set of\nexperiments with Named Entity Recognition (NER) on 27 languages, only 16 of\nwhich are in M-BERT, and show an average increase of about 6% F1 on languages\nthat are already in M-BERT and 23% F1 increase on new languages.", "published": "2020-04-28 16:36:41", "link": "http://arxiv.org/abs/2004.13640v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unnatural Language Processing: Bridging the Gap Between Synthetic and\n  Natural Language Data", "abstract": "Large, human-annotated datasets are central to the development of natural\nlanguage processing models. Collecting these datasets can be the most\nchallenging part of the development process. We address this problem by\nintroducing a general purpose technique for ``simulation-to-real'' transfer in\nlanguage understanding problems with a delimited set of target behaviors,\nmaking it possible to develop models that can interpret natural utterances\nwithout natural training data. We begin with a synthetic data generation\nprocedure, and train a model that can accurately interpret utterances produced\nby the data generator. To generalize to natural utterances, we automatically\nfind projections of natural language utterances onto the support of the\nsynthetic language, using learned sentence embeddings to define a distance\nmetric. With only synthetic training data, our approach matches or outperforms\nstate-of-the-art models trained on natural language data in several domains.\nThese results suggest that simulation-to-real transfer is a practical framework\nfor developing NLP applications, and that improved models for transfer might\nprovide wide-ranging improvements in downstream tasks.", "published": "2020-04-28 16:41:00", "link": "http://arxiv.org/abs/2004.13645v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LogicalFactChecker: Leveraging Logical Operations for Fact Checking with\n  Graph Module Network", "abstract": "Verifying the correctness of a textual statement requires not only semantic\nreasoning about the meaning of words, but also symbolic reasoning about logical\noperations like count, superlative, aggregation, etc. In this work, we propose\nLogicalFactChecker, a neural network approach capable of leveraging logical\noperations for fact checking. It achieves the state-of-the-art performance on\nTABFACT, a large-scale, benchmark dataset built for verifying a textual\nstatement with semi-structured tables. This is achieved by a graph module\nnetwork built upon the Transformer-based architecture. With a textual statement\nand a table as the input, LogicalFactChecker automatically derives a program\n(a.k.a. logical form) of the statement in a semantic parsing manner. A\nheterogeneous graph is then constructed to capture not only the structures of\nthe table and the program, but also the connections between inputs with\ndifferent modalities. Such a graph reveals the related contexts of each word in\nthe statement, the table and the program. The graph is used to obtain\ngraph-enhanced contextual representations of words in Transformer-based\narchitecture. After that, a program-driven module network is further introduced\nto exploit the hierarchical structure of the program, where semantic\ncompositionality is dynamically modeled along the program structure with a set\nof function-specific modules. Ablation experiments suggest that both the\nheterogeneous graph and the module network are important to obtain strong\nresults.", "published": "2020-04-28 17:04:19", "link": "http://arxiv.org/abs/2004.13659v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Active Learning for Coreference Resolution using Discrete Annotation", "abstract": "We improve upon pairwise annotation for active learning in coreference\nresolution, by asking annotators to identify mention antecedents if a presented\nmention pair is deemed not coreferent. This simple modification, when combined\nwith a novel mention clustering algorithm for selecting which examples to\nlabel, is much more efficient in terms of the performance obtained per\nannotation budget. In experiments with existing benchmark coreference datasets,\nwe show that the signal from this additional question leads to significant\nperformance gains per human-annotation hour. Future work can use our annotation\nprotocol to effectively develop coreference models for new domains. Our code is\npublicly available at\nhttps://github.com/belindal/discrete-active-learning-coref .", "published": "2020-04-28 17:17:11", "link": "http://arxiv.org/abs/2004.13671v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Autoencoding Word Representations through Time for Semantic Change\n  Detection", "abstract": "Semantic change detection concerns the task of identifying words whose\nmeaning has changed over time. The current state-of-the-art detects the level\nof semantic change in a word by comparing its vector representation in two\ndistinct time periods, without considering its evolution through time. In this\nwork, we propose three variants of sequential models for detecting semantically\nshifted words, effectively accounting for the changes in the word\nrepresentations over time, in a temporally sensitive manner. Through extensive\nexperimentation under various settings with both synthetic and real data we\nshowcase the importance of sequential modelling of word vectors through time\nfor detecting the words whose semantics have changed the most. Finally, we take\na step towards comparing different approaches in a quantitative manner,\ndemonstrating that the temporal modelling of word representations yields a\nclear-cut advantage in performance.", "published": "2020-04-28 17:58:14", "link": "http://arxiv.org/abs/2004.13703v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DomBERT: Domain-oriented Language Model for Aspect-based Sentiment\n  Analysis", "abstract": "This paper focuses on learning domain-oriented language models driven by end\ntasks, which aims to combine the worlds of both general-purpose language models\n(such as ELMo and BERT) and domain-specific language understanding. We propose\nDomBERT, an extension of BERT to learn from both in-domain corpus and relevant\ndomain corpora. This helps in learning domain language models with\nlow-resources. Experiments are conducted on an assortment of tasks in\naspect-based sentiment analysis, demonstrating promising results.", "published": "2020-04-28 21:07:32", "link": "http://arxiv.org/abs/2004.13816v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Chaotic Are Recurrent Neural Networks?", "abstract": "Recurrent neural networks (RNNs) are non-linear dynamic systems. Previous\nwork believes that RNN may suffer from the phenomenon of chaos, where the\nsystem is sensitive to initial states and unpredictable in the long run. In\nthis paper, however, we perform a systematic empirical analysis, showing that a\nvanilla or long short term memory (LSTM) RNN does not exhibit chaotic behavior\nalong the training process in real applications such as text generation. Our\nfindings suggest that future work in this direction should address the other\nside of non-linear dynamics for RNN.", "published": "2020-04-28 21:14:38", "link": "http://arxiv.org/abs/2004.13838v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Explanation Game: Towards Prediction Explainability through Sparse\n  Communication", "abstract": "Explainability is a topic of growing importance in NLP. In this work, we\nprovide a unified perspective of explainability as a communication problem\nbetween an explainer and a layperson about a classifier's decision. We use this\nframework to compare several prior approaches for extracting explanations,\nincluding gradient methods, representation erasure, and attention mechanisms,\nin terms of their communication success. In addition, we reinterpret these\nmethods at the light of classical feature selection, and we use this as\ninspiration to propose new embedded methods for explainability, through the use\nof selective, sparse attention. Experiments in text classification, natural\nlanguage entailment, and machine translation, using different configurations of\nexplainers and laypeople (including both machines and humans), reveal an\nadvantage of attention-based explainers over gradient and erasure methods.\nFurthermore, human evaluation experiments show promising results with post-hoc\nexplainers trained to optimize communication success and faithfulness.", "published": "2020-04-28 22:27:19", "link": "http://arxiv.org/abs/2004.13876v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Political Parody in Social Media", "abstract": "Parody is a figurative device used to imitate an entity for comedic or\ncritical purposes and represents a widespread phenomenon in social media\nthrough many popular parody accounts. In this paper, we present the first\ncomputational study of parody. We introduce a new publicly available data set\nof tweets from real politicians and their corresponding parody accounts. We run\na battery of supervised machine learning models for automatically detecting\nparody tweets with an emphasis on robustness by testing on tweets from accounts\nunseen in training, across different genders and across countries. Our results\nshow that political parody tweets can be predicted with an accuracy up to 90%.\nFinally, we identify the markers of parody through a linguistic analysis.\nBeyond research in linguistics and political communication, accurately and\nautomatically detecting parody is important to improving fact checking for\njournalists and analytics such as sentiment analysis through filtering out\nparodical utterances.", "published": "2020-04-28 22:31:18", "link": "http://arxiv.org/abs/2004.13878v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synonymy = Translational Equivalence", "abstract": "Synonymy and translational equivalence are the relations of sameness of\nmeaning within and across languages. As the principal relations in wordnets and\nmulti-wordnets, they are vital to computational lexical semantics, yet the\nfield suffers from the absence of a common formal framework to define their\nproperties and relationship. This paper proposes a unifying treatment of these\ntwo relations, which is validated by experiments on existing resources. In our\nview, synonymy and translational equivalence are simply different types of\nsemantic identity. The theory establishes a solid foundation for critically\nre-evaluating prior work in cross-lingual semantics, and facilitating the\ncreation, verification, and amelioration of lexical resources.", "published": "2020-04-28 23:15:02", "link": "http://arxiv.org/abs/2004.13886v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UXLA: A Robust Unsupervised Data Augmentation Framework for\n  Zero-Resource Cross-Lingual NLP", "abstract": "Transfer learning has yielded state-of-the-art (SoTA) results in many\nsupervised NLP tasks. However, annotated data for every target task in every\ntarget language is rare, especially for low-resource languages. We propose\nUXLA, a novel unsupervised data augmentation framework for zero-resource\ntransfer learning scenarios. In particular, UXLA aims to solve cross-lingual\nadaptation problems from a source language task distribution to an unknown\ntarget language task distribution, assuming no training label in the target\nlanguage. At its core, UXLA performs simultaneous self-training with data\naugmentation and unsupervised sample selection. To show its effectiveness, we\nconduct extensive experiments on three diverse zero-resource cross-lingual\ntransfer tasks. UXLA achieves SoTA results in all the tasks, outperforming the\nbaselines by a good margin. With an in-depth framework dissection, we\ndemonstrate the cumulative contributions of different components to its\nsuccess.", "published": "2020-04-28 01:47:37", "link": "http://arxiv.org/abs/2004.13240v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Assessing the Bilingual Knowledge Learned by Neural Machine Translation\n  Models", "abstract": "Machine translation (MT) systems translate text between different languages\nby automatically learning in-depth knowledge of bilingual lexicons, grammar and\nsemantics from the training examples. Although neural machine translation (NMT)\nhas led the field of MT, we have a poor understanding on how and why it works.\nIn this paper, we bridge the gap by assessing the bilingual knowledge learned\nby NMT models with phrase table -- an interpretable table of bilingual\nlexicons. We extract the phrase table from the training examples that an NMT\nmodel correctly predicts. Extensive experiments on widely-used datasets show\nthat the phrase table is reasonable and consistent against language pairs and\nrandom seeds. Equipped with the interpretable phrase table, we find that NMT\nmodels learn patterns from simple to complex and distill essential bilingual\nknowledge from the training examples. We also revisit some advances that\npotentially affect the learning of bilingual knowledge (e.g.,\nback-translation), and report some interesting findings. We believe this work\nopens a new angle to interpret NMT with statistic models, and provides\nempirical supports for recent advances in improving NMT models.", "published": "2020-04-28 03:44:34", "link": "http://arxiv.org/abs/2004.13270v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VD-BERT: A Unified Vision and Dialog Transformer with BERT", "abstract": "Visual dialog is a challenging vision-language task, where a dialog agent\nneeds to answer a series of questions through reasoning on the image content\nand dialog history. Prior work has mostly focused on various attention\nmechanisms to model such intricate interactions. By contrast, in this work, we\npropose VD-BERT, a simple yet effective framework of unified vision-dialog\nTransformer that leverages the pretrained BERT language models for Visual\nDialog tasks. The model is unified in that (1) it captures all the interactions\nbetween the image and the multi-turn dialog using a single-stream Transformer\nencoder, and (2) it supports both answer ranking and answer generation\nseamlessly through the same architecture. More crucially, we adapt BERT for the\neffective fusion of vision and dialog contents via visually grounded training.\nWithout the need of pretraining on external vision-language data, our model\nyields new state of the art, achieving the top position in both single-model\nand ensemble settings (74.54 and 75.35 NDCG scores) on the visual dialog\nleaderboard. Our code and pretrained models are released at\nhttps://github.com/salesforce/VD-BERT.", "published": "2020-04-28 04:08:46", "link": "http://arxiv.org/abs/2004.13278v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Scheduled DropHead: A Regularization Method for Transformer Models", "abstract": "In this paper, we introduce DropHead, a structured dropout method\nspecifically designed for regularizing the multi-head attention mechanism,\nwhich is a key component of transformer, a state-of-the-art model for various\nNLP tasks. In contrast to the conventional dropout mechanisms which randomly\ndrop units or connections, the proposed DropHead is a structured dropout\nmethod. It drops entire attention-heads during training and It prevents the\nmulti-head attention model from being dominated by a small portion of attention\nheads while also reduces the risk of overfitting the training data, thus making\nuse of the multi-head attention mechanism more efficiently. Motivated by recent\nstudies about the learning dynamic of the multi-head attention mechanism, we\npropose a specific dropout rate schedule to adaptively adjust the dropout rate\nof DropHead and achieve better regularization effect. Experimental results on\nboth machine translation and text classification benchmark datasets demonstrate\nthe effectiveness of the proposed approach.", "published": "2020-04-28 07:33:14", "link": "http://arxiv.org/abs/2004.13342v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Kungfupanda at SemEval-2020 Task 12: BERT-Based Multi-Task Learning for\n  Offensive Language Detection", "abstract": "Nowadays, offensive content in social media has become a serious problem, and\nautomatically detecting offensive language is an essential task. In this paper,\nwe build an offensive language detection system, which combines multi-task\nlearning with BERT-based models. Using a pre-trained language model such as\nBERT, we can effectively learn the representations for noisy text in social\nmedia. Besides, to boost the performance of offensive language detection, we\nleverage the supervision signals from other related tasks. In the\nOffensEval-2020 competition, our model achieves 91.51% F1 score in English\nSub-task A, which is comparable to the first place (92.23%F1). An empirical\nanalysis is provided to explain the effectiveness of our approaches.", "published": "2020-04-28 11:27:24", "link": "http://arxiv.org/abs/2004.13432v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Introducing a framework to assess newly created questions with Natural\n  Language Processing", "abstract": "Statistical models such as those derived from Item Response Theory (IRT)\nenable the assessment of students on a specific subject, which can be useful\nfor several purposes (e.g., learning path customization, drop-out prediction).\nHowever, the questions have to be assessed as well and, although it is possible\nto estimate with IRT the characteristics of questions that have already been\nanswered by several students, this technique cannot be used on newly generated\nquestions. In this paper, we propose a framework to train and evaluate models\nfor estimating the difficulty and discrimination of newly created Multiple\nChoice Questions by extracting meaningful features from the text of the\nquestion and of the possible choices. We implement one model using this\nframework and test it on a real-world dataset provided by CloudAcademy, showing\nthat it outperforms previously proposed models, reducing by 6.7% the RMSE for\ndifficulty estimation and by 10.8% the RMSE for discrimination estimation. We\nalso present the results of an ablation study performed to support our features\nchoice and to show the effects of different characteristics of the questions'\ntext on difficulty and discrimination.", "published": "2020-04-28 13:57:21", "link": "http://arxiv.org/abs/2004.13530v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Curse of Performance Instability in Analysis Datasets: Consequences,\n  Source, and Suggestions", "abstract": "We find that the performance of state-of-the-art models on Natural Language\nInference (NLI) and Reading Comprehension (RC) analysis/stress sets can be\nhighly unstable. This raises three questions: (1) How will the instability\naffect the reliability of the conclusions drawn based on these analysis sets?\n(2) Where does this instability come from? (3) How should we handle this\ninstability and what are some potential solutions? For the first question, we\nconduct a thorough empirical study over analysis sets and find that in addition\nto the unstable final performance, the instability exists all along the\ntraining curve. We also observe lower-than-expected correlations between the\nanalysis validation set and standard validation set, questioning the\neffectiveness of the current model-selection routine. Next, to answer the\nsecond question, we give both theoretical explanations and empirical evidence\nregarding the source of the instability, demonstrating that the instability\nmainly comes from high inter-example correlations within analysis sets.\nFinally, for the third question, we discuss an initial attempt to mitigate the\ninstability and suggest guidelines for future work such as reporting the\ndecomposed variance for more interpretable results and fair comparison across\nmodels. Our code is publicly available at:\nhttps://github.com/owenzx/InstabilityAnalysis", "published": "2020-04-28 15:41:12", "link": "http://arxiv.org/abs/2004.13606v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Recipes for building an open-domain chatbot", "abstract": "Building open-domain chatbots is a challenging area for machine learning\nresearch. While prior work has shown that scaling neural models in the number\nof parameters and the size of the data they are trained on gives improved\nresults, we show that other ingredients are important for a high-performing\nchatbot. Good conversation requires a number of skills that an expert\nconversationalist blends in a seamless way: providing engaging talking points\nand listening to their partners, and displaying knowledge, empathy and\npersonality appropriately, while maintaining a consistent persona. We show that\nlarge scale models can learn these skills when given appropriate training data\nand choice of generation strategy. We build variants of these recipes with 90M,\n2.7B and 9.4B parameter models, and make our models and code publicly\navailable. Human evaluations show our best models are superior to existing\napproaches in multi-turn dialogue in terms of engagingness and humanness\nmeasurements. We then discuss the limitations of this work by analyzing failure\ncases of our models.", "published": "2020-04-28 16:33:25", "link": "http://arxiv.org/abs/2004.13637v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Entity Type Prediction in Knowledge Graphs using Embeddings", "abstract": "Open Knowledge Graphs (such as DBpedia, Wikidata, YAGO) have been recognized\nas the backbone of diverse applications in the field of data mining and\ninformation retrieval. Hence, the completeness and correctness of the Knowledge\nGraphs (KGs) are vital. Most of these KGs are mostly created either via an\nautomated information extraction from Wikipedia snapshots or information\naccumulation provided by the users or using heuristics. However, it has been\nobserved that the type information of these KGs is often noisy, incomplete, and\nincorrect. To deal with this problem a multi-label classification approach is\nproposed in this work for entity typing using KG embeddings. We compare our\napproach with the current state-of-the-art type prediction method and report on\nexperiments with the KGs.", "published": "2020-04-28 17:57:08", "link": "http://arxiv.org/abs/2004.13702v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Showing Your Work Doesn't Always Work", "abstract": "In natural language processing, a recently popular line of work explores how\nto best report the experimental results of neural networks. One exemplar\npublication, titled \"Show Your Work: Improved Reporting of Experimental\nResults,\" advocates for reporting the expected validation effectiveness of the\nbest-tuned model, with respect to the computational budget. In the present\nwork, we critically examine this paper. As far as statistical generalizability\nis concerned, we find unspoken pitfalls and caveats with this approach. We\nanalytically show that their estimator is biased and uses error-prone\nassumptions. We find that the estimator favors negative errors and yields poor\nbootstrapped confidence intervals. We derive an unbiased alternative and\nbolster our claims with empirical evidence from statistical simulation. Our\ncodebase is at http://github.com/castorini/meanmax.", "published": "2020-04-28 17:59:01", "link": "http://arxiv.org/abs/2004.13705v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Informational Space of Meaning for Scientific Texts", "abstract": "In Natural Language Processing, automatic extracting the meaning of texts\nconstitutes an important problem. Our focus is the computational analysis of\nmeaning of short scientific texts (abstracts or brief reports). In this paper,\na vector space model is developed for quantifying the meaning of words and\ntexts. We introduce the Meaning Space, in which the meaning of a word is\nrepresented by a vector of Relative Information Gain (RIG) about the subject\ncategories that the text belongs to, which can be obtained from observing the\nword in the text. This new approach is applied to construct the Meaning Space\nbased on Leicester Scientific Corpus (LSC) and Leicester Scientific\nDictionary-Core (LScDC). The LSC is a scientific corpus of 1,673,350 abstracts\nand the LScDC is a scientific dictionary which words are extracted from the\nLSC. Each text in the LSC belongs to at least one of 252 subject categories of\nWeb of Science (WoS). These categories are used in construction of vectors of\ninformation gains. The Meaning Space is described and statistically analysed\nfor the LSC with the LScDC. The usefulness of the proposed representation model\nis evaluated through top-ranked words in each category. The most informative n\nwords are ordered. We demonstrated that RIG-based word ranking is much more\nuseful than ranking based on raw word frequency in determining the\nscience-specific meaning and importance of a word. The proposed model based on\nRIG is shown to have ability to stand out topic-specific words in categories.\nThe most informative words are presented for 252 categories. The new scientific\ndictionary and the 103,998 x 252 Word-Category RIG Matrix are available online.\nAnalysis of the Meaning Space provides us with a tool to further explore\nquantifying the meaning of a text using more complex and context-dependent\nmeaning models that use co-occurrence of words and their combinations.", "published": "2020-04-28 14:26:12", "link": "http://arxiv.org/abs/2004.13717v1", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Conspiracy in the Time of Corona: Automatic detection of Covid-19\n  Conspiracy Theories in Social Media and the News", "abstract": "Rumors and conspiracy theories thrive in environments of low confidence and\nlow trust. Consequently, it is not surprising that ones related to the Covid-19\npandemic are proliferating given the lack of any authoritative scientific\nconsensus on the virus, its spread and containment, or on the long term social\nand economic ramifications of the pandemic. Among the stories currently\ncirculating are ones suggesting that the 5G network activates the virus, that\nthe pandemic is a hoax perpetrated by a global cabal, that the virus is a\nbio-weapon released deliberately by the Chinese, or that Bill Gates is using it\nas cover to launch a global surveillance regime. While some may be quick to\ndismiss these stories as having little impact on real-world behavior, recent\nevents including the destruction of property, racially fueled attacks against\nAsian Americans, and demonstrations espousing resistance to public health\norders countermand such conclusions. Inspired by narrative theory, we crawl\nsocial media sites and news reports and, through the application of automated\nmachine-learning methods, discover the underlying narrative frameworks\nsupporting the generation of these stories. We show how the various narrative\nframeworks fueling rumors and conspiracy theories rely on the alignment of\notherwise disparate domains of knowledge, and consider how they attach to the\nbroader reporting on the pandemic. These alignments and attachments, which can\nbe monitored in near real-time, may be useful for identifying areas in the news\nthat are particularly vulnerable to reinterpretation by conspiracy theorists.\nUnderstanding the dynamics of storytelling on social media and the narrative\nframeworks that provide the generative basis for these stories may also be\nhelpful for devising methods to disrupt their spread.", "published": "2020-04-28 19:27:48", "link": "http://arxiv.org/abs/2004.13783v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "LNMap: Departures from Isomorphic Assumption in Bilingual Lexicon\n  Induction Through Non-Linear Mapping in Latent Space", "abstract": "Most of the successful and predominant methods for bilingual lexicon\ninduction (BLI) are mapping-based, where a linear mapping function is learned\nwith the assumption that the word embedding spaces of different languages\nexhibit similar geometric structures (i.e., approximately isomorphic). However,\nseveral recent studies have criticized this simplified assumption showing that\nit does not hold in general even for closely related languages. In this work,\nwe propose a novel semi-supervised method to learn cross-lingual word\nembeddings for BLI. Our model is independent of the isomorphic assumption and\nuses nonlinear mapping in the latent space of two independently trained\nauto-encoders. Through extensive experiments on fifteen (15) different language\npairs (in both directions) comprising resource-rich and low-resource languages\nfrom two different datasets, we demonstrate that our method outperforms\nexisting models by a good margin. Ablation studies show the importance of\ndifferent model components and the necessity of non-linear mapping.", "published": "2020-04-28 23:28:26", "link": "http://arxiv.org/abs/2004.13889v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Unsupervised Semantic Sentence Ranking Scheme for Text Documents", "abstract": "This paper presents Semantic SentenceRank (SSR), an unsupervised scheme for\nautomatically ranking sentences in a single document according to their\nrelative importance. In particular, SSR extracts essential words and phrases\nfrom a text document, and uses semantic measures to construct, respectively, a\nsemantic phrase graph over phrases and words, and a semantic sentence graph\nover sentences. It applies two variants of article-structure-biased PageRank to\nscore phrases and words on the first graph and sentences on the second graph.\nIt then combines these scores to generate the final score for each sentence.\nFinally, SSR solves a multi-objective optimization problem for ranking\nsentences based on their final scores and topic diversity through semantic\nsubtopic clustering. An implementation of SSR that runs in quadratic time is\npresented, and it outperforms, on the SummBank benchmarks, each individual\njudge's ranking and compares favorably with the combined ranking of all judges.", "published": "2020-04-28 20:17:51", "link": "http://arxiv.org/abs/2005.02158v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML", "68T50", "H.4; I.2.7; J.6"], "primary_category": "cs.IR"}
{"title": "Out-of-Sample Representation Learning for Multi-Relational Graphs", "abstract": "Many important problems can be formulated as reasoning in knowledge graphs.\nRepresentation learning has proved extremely effective for transductive\nreasoning, in which one needs to make new predictions for already observed\nentities. This is true for both attributed graphs(where each entity has an\ninitial feature vector) and non-attributed graphs (where the only initial\ninformation derives from known relations with other entities). For\nout-of-sample reasoning, where one needs to make predictions for entities that\nwere unseen at training time, much prior work considers attributed graph.\nHowever, this problem is surprisingly under-explored for non-attributed graphs.\nIn this paper, we study the out-of-sample representation learning problem for\nnon-attributed knowledge graphs, create benchmark datasets for this task,\ndevelop several models and baselines, and provide empirical analyses and\ncomparisons of the proposed models and baselines.", "published": "2020-04-28 00:53:01", "link": "http://arxiv.org/abs/2004.13230v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Deep Conversational Recommender Systems: A New Frontier for\n  Goal-Oriented Dialogue Systems", "abstract": "In recent years, the emerging topics of recommender systems that take\nadvantage of natural language processing techniques have attracted much\nattention, and one of their applications is the Conversational Recommender\nSystem (CRS). Unlike traditional recommender systems with content-based and\ncollaborative filtering approaches, CRS learns and models user's preferences\nthrough interactive dialogue conversations. In this work, we provide a\nsummarization of the recent evolution of CRS, where deep learning approaches\nare applied to CRS and have produced fruitful results. We first analyze the\nresearch problems and present key challenges in the development of Deep\nConversational Recommender Systems (DCRS), then present the current state of\nthe field taken from the most recent researches, including the most common deep\nlearning models that benefit DCRS. Finally, we discuss future directions for\nthis vibrant area.", "published": "2020-04-28 02:20:42", "link": "http://arxiv.org/abs/2004.13245v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "$R^3$: Reverse, Retrieve, and Rank for Sarcasm Generation with\n  Commonsense Knowledge", "abstract": "We propose an unsupervised approach for sarcasm generation based on a\nnon-sarcastic input sentence. Our method employs a retrieve-and-edit framework\nto instantiate two major characteristics of sarcasm: reversal of valence and\nsemantic incongruity with the context which could include shared commonsense or\nworld knowledge between the speaker and the listener. While prior works on\nsarcasm generation predominantly focus on context incongruity, we show that\ncombining valence reversal and semantic incongruity based on the commonsense\nknowledge generates sarcasm of higher quality. Human evaluation shows that our\nsystem generates sarcasm better than human annotators 34% of the time, and\nbetter than a reinforced hybrid baseline 90% of the time.", "published": "2020-04-28 02:30:09", "link": "http://arxiv.org/abs/2004.13248v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Interpretable and Discrete Representations with Adversarial\n  Training for Unsupervised Text Classification", "abstract": "Learning continuous representations from unlabeled textual data has been\nincreasingly studied for benefiting semi-supervised learning. Although it is\nrelatively easier to interpret discrete representations, due to the difficulty\nof training, learning discrete representations for unlabeled textual data has\nnot been widely explored. This work proposes TIGAN that learns to encode texts\ninto two disentangled representations, including a discrete code and a\ncontinuous noise, where the discrete code represents interpretable topics, and\nthe noise controls the variance within the topics. The discrete code learned by\nTIGAN can be used for unsupervised text classification. Compared to other\nunsupervised baselines, the proposed TIGAN achieves superior performance on six\ndifferent corpora. Also, the performance is on par with a recently proposed\nweakly-supervised text classification method. The extracted topical words for\nrepresenting latent topics show that TIGAN learns coherent and highly\ninterpretable topics.", "published": "2020-04-28 02:53:59", "link": "http://arxiv.org/abs/2004.13255v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DTCA: Decision Tree-based Co-Attention Networks for Explainable Claim\n  Verification", "abstract": "Recently, many methods discover effective evidence from reliable sources by\nappropriate neural networks for explainable claim verification, which has been\nwidely recognized. However, in these methods, the discovery process of evidence\nis nontransparent and unexplained. Simultaneously, the discovered evidence only\nroughly aims at the interpretability of the whole sequence of claims but\ninsufficient to focus on the false parts of claims. In this paper, we propose a\nDecision Tree-based Co-Attention model (DTCA) to discover evidence for\nexplainable claim verification. Specifically, we first construct Decision\nTree-based Evidence model (DTE) to select comments with high credibility as\nevidence in a transparent and interpretable way. Then we design Co-attention\nSelf-attention networks (CaSa) to make the selected evidence interact with\nclaims, which is for 1) training DTE to determine the optimal decision\nthresholds and obtain more powerful evidence; and 2) utilizing the evidence to\nfind the false parts in the claim. Experiments on two public datasets,\nRumourEval and PHEME, demonstrate that DTCA not only provides explanations for\nthe results of claim verification but also achieves the state-of-the-art\nperformance, boosting the F1-score by 3.11%, 2.41%, respectively.", "published": "2020-04-28 12:19:46", "link": "http://arxiv.org/abs/2004.13455v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "On the Reliability of Test Collections for Evaluating Systems of\n  Different Types", "abstract": "As deep learning based models are increasingly being used for information\nretrieval (IR), a major challenge is to ensure the availability of test\ncollections for measuring their quality. Test collections are generated based\non pooling results of various retrieval systems, but until recently this did\nnot include deep learning systems. This raises a major challenge for reusable\nevaluation: Since deep learning based models use external resources (e.g. word\nembeddings) and advanced representations as opposed to traditional methods that\nare mainly based on lexical similarity, they may return different types of\nrelevant document that were not identified in the original pooling. If so, test\ncollections constructed using traditional methods are likely to lead to biased\nand unfair evaluation results for deep learning (neural) systems. This paper\nuses simulated pooling to test the fairness and reusability of test\ncollections, showing that pooling based on traditional systems only can lead to\nbiased evaluation of deep learning systems.", "published": "2020-04-28 13:22:26", "link": "http://arxiv.org/abs/2004.13486v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Don't Let Me Be Misunderstood: Comparing Intentions and Perceptions in\n  Online Discussions", "abstract": "Discourse involves two perspectives: a person's intention in making an\nutterance and others' perception of that utterance. The misalignment between\nthese perspectives can lead to undesirable outcomes, such as misunderstandings,\nlow productivity and even overt strife. In this work, we present a\ncomputational framework for exploring and comparing both perspectives in online\npublic discussions.\n  We combine logged data about public comments on Facebook with a survey of\nover 16,000 people about their intentions in writing these comments or about\ntheir perceptions of comments that others had written. Unlike previous studies\nof online discussions that have largely relied on third-party labels to\nquantify properties such as sentiment and subjectivity, our approach also\ndirectly captures what the speakers actually intended when writing their\ncomments. In particular, our analysis focuses on judgments of whether a comment\nis stating a fact or an opinion, since these concepts were shown to be often\nconfused.\n  We show that intentions and perceptions diverge in consequential ways. People\nare more likely to perceive opinions than to intend them, and linguistic cues\nthat signal how an utterance is intended can differ from those that signal how\nit will be perceived. Further, this misalignment between intentions and\nperceptions can be linked to the future health of a conversation: when a\ncomment whose author intended to share a fact is misperceived as sharing an\nopinion, the subsequent conversation is more likely to derail into uncivil\nbehavior than when the comment is perceived as intended. Altogether, these\nfindings may inform the design of discussion platforms that better promote\npositive interactions.", "published": "2020-04-28 15:43:46", "link": "http://arxiv.org/abs/2004.13609v1", "categories": ["cs.CY", "cs.CL", "cs.SI", "physics.soc-ph"], "primary_category": "cs.CY"}
{"title": "KACC: A Multi-task Benchmark for Knowledge Abstraction, Concretization\n  and Completion", "abstract": "A comprehensive knowledge graph (KG) contains an instance-level entity graph\nand an ontology-level concept graph. The two-view KG provides a testbed for\nmodels to \"simulate\" human's abilities on knowledge abstraction,\nconcretization, and completion (KACC), which are crucial for human to recognize\nthe world and manage learned knowledge. Existing studies mainly focus on\npartial aspects of KACC. In order to promote thorough analyses for KACC\nabilities of models, we propose a unified KG benchmark by improving existing\nbenchmarks in terms of dataset scale, task coverage, and difficulty.\nSpecifically, we collect new datasets that contain larger concept graphs,\nabundant cross-view links as well as dense entity graphs. Based on the\ndatasets, we propose novel tasks such as multi-hop knowledge abstraction (MKA),\nmulti-hop knowledge concretization (MKC) and then design a comprehensive\nbenchmark. For MKA and MKC tasks, we further annotate multi-hop hierarchical\ntriples as harder samples. The experimental results of existing methods\ndemonstrate the challenges of our benchmark. The resource is available at\nhttps://github.com/thunlp/KACC.", "published": "2020-04-28 16:21:57", "link": "http://arxiv.org/abs/2004.13631v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural Speech Separation Using Spatially Distributed Microphones", "abstract": "This paper proposes a neural network based speech separation method using\nspatially distributed microphones. Unlike with traditional microphone array\nsettings, neither the number of microphones nor their spatial arrangement is\nknown in advance, which hinders the use of conventional multi-channel speech\nseparation neural networks based on fixed size input. To overcome this, a novel\nnetwork architecture is proposed that interleaves inter-channel processing\nlayers and temporal processing layers. The inter-channel processing layers\napply a self-attention mechanism along the channel dimension to exploit the\ninformation obtained with a varying number of microphones. The temporal\nprocessing layers are based on a bidirectional long short term memory (BLSTM)\nmodel and applied to each channel independently. The proposed network leverages\ninformation across time and space by stacking these two kinds of layers\nalternately. Our network estimates time-frequency (TF) masks for each speaker,\nwhich are then used to generate enhanced speech signals either with TF masking\nor beamforming. Speech recognition experimental results show that the proposed\nmethod significantly outperforms baseline multi-channel speech separation\nsystems.", "published": "2020-04-28 17:16:31", "link": "http://arxiv.org/abs/2004.13670v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Cross-modal Speaker Verification and Recognition: A Multilingual\n  Perspective", "abstract": "Recent years have seen a surge in finding association between faces and\nvoices within a cross-modal biometric application along with speaker\nrecognition. Inspired from this, we introduce a challenging task in\nestablishing association between faces and voices across multiple languages\nspoken by the same set of persons. The aim of this paper is to answer two\nclosely related questions: \"Is face-voice association language independent?\"\nand \"Can a speaker be recognised irrespective of the spoken language?\". These\ntwo questions are very important to understand effectiveness and to boost\ndevelopment of multilingual biometric systems. To answer them, we collected a\nMultilingual Audio-Visual dataset, containing human speech clips of $154$\nidentities with $3$ language annotations extracted from various videos uploaded\nonline. Extensive experiments on the three splits of the proposed dataset have\nbeen performed to investigate and answer these novel research questions that\nclearly point out the relevance of the multilingual problem.", "published": "2020-04-28 19:15:23", "link": "http://arxiv.org/abs/2004.13780v2", "categories": ["cs.CV", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "A Practical Framework for Relation Extraction with Noisy Labels Based on\n  Doubly Transitional Loss", "abstract": "Either human annotation or rule based automatic labeling is an effective\nmethod to augment data for relation extraction. However, the inevitable wrong\nlabeling problem for example by distant supervision may deteriorate the\nperformance of many existing methods. To address this issue, we introduce a\npractical end-to-end deep learning framework, including a standard feature\nextractor and a novel noisy classifier with our proposed doubly transitional\nmechanism. One transition is basically parameterized by a non-linear\ntransformation between hidden layers that implicitly represents the conversion\nbetween the true and noisy labels, and it can be readily optimized together\nwith other model parameters. Another is an explicit probability transition\nmatrix that captures the direct conversion between labels but needs to be\nderived from an EM algorithm. We conduct experiments on the NYT dataset and\nSemEval 2018 Task 7. The empirical results show comparable or better\nperformance over state-of-the-art methods.", "published": "2020-04-28 19:38:20", "link": "http://arxiv.org/abs/2004.13786v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Conditional Spoken Digit Generation with StyleGAN", "abstract": "This paper adapts a StyleGAN model for speech generation with minimal or no\nconditioning on text. StyleGAN is a multi-scale convolutional GAN capable of\nhierarchically capturing data structure and latent variation on multiple\nspatial (or temporal) levels. The model has previously achieved impressive\nresults on facial image generation, and it is appealing to audio applications\ndue to similar multi-level structures present in the data. In this paper, we\ntrain a StyleGAN to generate mel-frequency spectrograms on the Speech Commands\ndataset, which contains spoken digits uttered by multiple speakers in varying\nacoustic conditions. In a conditional setting our model is conditioned on the\ndigit identity, while learning the remaining data variation remains an\nunsupervised task. We compare our model to the current unsupervised\nstate-of-the-art speech synthesis GAN architecture, the WaveGAN, and show that\nthe proposed model outperforms according to numerical measures and subjective\nevaluation by listening tests.", "published": "2020-04-28 18:28:58", "link": "http://arxiv.org/abs/2004.13764v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "The universality of skipping behaviours on music streaming platforms", "abstract": "A recent study of skipping behaviour on music streaming platforms has shown\nthat the skip profile for a given song -- i.e. the measure of the skipping rate\nas a function of the time in the song -- can be seen as some intrinsic\ncharacteristic of the song, in the sense that it is both very specific and\nhighly stable over time and geographical regions. In this paper, we take this\nanalysis one step further by introducing a simple model of skip behaviours, in\nwhich the skip profile for a given song is viewed as the response to a small\nnumber of events that happen within it. In particular, it allows us to identify\naccurately the timing of the events that trigger skip responses, as well as the\nfraction of users who skip following each these events. Strikingly, the\nresponses triggered by individual events appears to follow a temporal profile\nthat is consistent across songs, genres, devices and listening contexts,\nsuggesting that people react to musical surprises in a universal way.", "published": "2020-04-28 14:27:53", "link": "http://arxiv.org/abs/2005.06987v1", "categories": ["cs.SI", "cs.SD", "eess.AS", "q-bio.NC"], "primary_category": "cs.SI"}
{"title": "Adversarial Feature Learning and Unsupervised Clustering based Speech\n  Synthesis for Found Data with Acoustic and Textual Noise", "abstract": "Attention-based sequence-to-sequence (seq2seq) speech synthesis has achieved\nextraordinary performance. But a studio-quality corpus with manual\ntranscription is necessary to train such seq2seq systems. In this paper, we\npropose an approach to build high-quality and stable seq2seq based speech\nsynthesis system using challenging found data, where training speech contains\nnoisy interferences (acoustic noise) and texts are imperfect speech recognition\ntranscripts (textual noise). To deal with text-side noise, we propose a VQVAE\nbased heuristic method to compensate erroneous linguistic feature with phonetic\ninformation learned directly from speech. As for the speech-side noise, we\npropose to learn a noise-independent feature in the auto-regressive decoder\nthrough adversarial training and data augmentation, which does not need an\nextra speech enhancement model. Experiments show the effectiveness of the\nproposed approach in dealing with text-side and speech-side noise. Surpassing\nthe denoising approach based on a state-of-the-art speech enhancement model,\nour system built on noisy found data can synthesize clean and high-quality\nspeech with MOS close to the system built on the clean counterpart.", "published": "2020-04-28 15:32:45", "link": "http://arxiv.org/abs/2004.13595v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
