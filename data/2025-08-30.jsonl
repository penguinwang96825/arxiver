{"title": "Distance-based (and path-based) covering problems for graphs of given cyclomatic number", "abstract": "We study a large family of graph covering problems, whose definitions rely on\ndistances, for graphs of bounded cyclomatic number (that is, the minimum number\nof edges that need to be removed from the graph to destroy all cycles). These\nproblems include (but are not restricted to) three families of problems: (i)\nvariants of metric dimension, where one wants to choose a small set $S$ of\nvertices of the graph such that every vertex is uniquely determined by its\nordered vector of distances to the vertices of $S$; (ii) variants of geodetic\nsets, where one wants to select a small set $S$ of vertices such that any\nvertex lies on some shortest path between two vertices of $S$; (iii) variants\nof path covers, where one wants to select a small set of paths such that every\nvertex or edge belongs to one of the paths. We generalize and/or improve\nprevious results in the area which show that the optimal values for these\nproblems can be upper-bounded by a linear function of the cyclomatic number and\nthe degree~1-vertices of the graph. To this end, we develop and enhance a\ntechnique recently introduced in [C. Lu, Q. Ye, C. Zhu. Algorithmic aspect on\nthe minimum (weighted) doubly resolving set problem of graphs, Journal of\nCombinatorial Optimization 44:2029--2039, 2022] and give near-optimal bounds in\nseveral cases. This solves (in some cases fully, in some cases partially) some\nconjectures and open questions from the literature. The method, based on\nbreadth-first search, is of algorithmic nature and thus, all the constructions\ncan be computed in linear time. Our results also imply an algorithmic\nconsequence for the computation of the optimal solutions: for some of the\nproblems, they can be computed in polynomial time for graphs of bounded\ncyclomatic number.", "published": "2025-08-30 06:47:52", "link": "http://arxiv.org/abs/2509.00383v1", "categories": ["cs.DM", "math.CO"], "primary_category": "cs.DM"}
{"title": "BALM-TSF: Balanced Multimodal Alignment for LLM-Based Time Series Forecasting", "abstract": "Time series forecasting is a long-standing and highly challenging research\ntopic. Recently, driven by the rise of large language models (LLMs), research\nhas increasingly shifted from purely time series methods toward harnessing\ntextual modalities to enhance forecasting performance. However, the vast\ndiscrepancy between text and temporal data often leads current multimodal\narchitectures to over-emphasise one modality while neglecting the other,\nresulting in information loss that harms forecasting performance. To address\nthis modality imbalance, we introduce BALM-TSF (Balanced Multimodal Alignment\nfor LLM-Based Time Series Forecasting), a lightweight time series forecasting\nframework that maintains balance between the two modalities. Specifically, raw\ntime series are processed by the time series encoder, while descriptive\nstatistics of raw time series are fed to an LLM with learnable prompt,\nproducing compact textual embeddings. To ensure balanced cross-modal context\nalignment of time series and textual embeddings, a simple yet effective scaling\nstrategy combined with a contrastive objective then maps these textual\nembeddings into the latent space of the time series embeddings. Finally, the\naligned textual semantic embeddings and time series embeddings are together\nintegrated for forecasting. Extensive experiments on standard benchmarks show\nthat, with minimal trainable parameters, BALM-TSF achieves state-of-the-art\nperformance in both long-term and few-shot forecasting, confirming its ability\nto harness complementary information from text and time series. Code is\navailable at https://github.com/ShiqiaoZhou/BALM-TSF.", "published": "2025-08-30 22:31:55", "link": "http://arxiv.org/abs/2509.00622v1", "categories": ["cs.AI", "cs.IR", "H.3; I.2"], "primary_category": "cs.AI"}
{"title": "How to Make Museums More Interactive? Case Study of Artistic Chatbot", "abstract": "Conversational agents powered by Large Language Models (LLMs) are\nincreasingly utilized in educational settings, in particular in individual\nclosed digital environments, yet their potential adoption in the physical\nlearning environments like cultural heritage sites, museums, and art galleries\nremains relatively unexplored. In this study, we present Artistic Chatbot, a\nvoice-to-voice RAG-powered chat system to support informal learning and enhance\nvisitor engagement during a live art exhibition celebrating the 15th\nanniversary of the Faculty of Media Art at the Warsaw Academy of Fine Arts,\nPoland. The question answering (QA) chatbot responded to free-form spoken\nquestions in Polish using the context retrieved from a curated, domain-specific\nknowledge base consisting of 226 documents provided by the organizers,\nincluding faculty information, art magazines, books, and journals. We describe\nthe key aspects of the system architecture and user interaction design, as well\nas discuss the practical challenges associated with deploying chatbots at\npublic cultural sites. Our findings, based on interaction analysis, demonstrate\nthat chatbots such as Artistic Chatbot effectively maintain responses grounded\nin exhibition content (60\\% of responses directly relevant), even when faced\nwith unpredictable queries outside the target domain, showing their potential\nfor increasing interactivity in public cultural sites.\n  GitHub project page: https://github.com/cinekucia/artistic-chatbot-cikm2025", "published": "2025-08-30 17:41:22", "link": "http://arxiv.org/abs/2509.00572v1", "categories": ["cs.HC", "cs.IR"], "primary_category": "cs.HC"}
{"title": "ERank: Fusing Supervised Fine-Tuning and Reinforcement Learning for Effective and Efficient Text Reranking", "abstract": "Text reranking models are a crucial component in modern systems like\nRetrieval-Augmented Generation, tasked with selecting the most relevant\ndocuments prior to generation. However, current Large Language Models (LLMs)\npowered rerankers often face a fundamental trade-off. On one hand, Supervised\nFine-Tuning based pointwise methods that frame relevance as a binary\nclassification task lack the necessary scoring discrimination, particularly for\nthose built on reasoning LLMs. On the other hand, approaches designed for\ncomplex reasoning often employ powerful yet inefficient listwise formulations,\nrendering them impractical for low latency applications. To resolve this\ndilemma, we introduce ERank, a highly effective and efficient pointwise\nreranker built from a reasoning LLM that excels across diverse relevance\nscenarios. We propose a novel two-stage training pipeline that begins with\nSupervised Fine-Tuning (SFT). In this stage, we move beyond binary labels and\ntrain the model generatively to output fine grained integer scores, which\nsignificantly enhances relevance discrimination. The model is then further\nrefined using Reinforcement Learning (RL) with a novel, listwise derived\nreward. This technique instills global ranking awareness into the efficient\npointwise architecture. We evaluate the ERank reranker on the BRIGHT, FollowIR,\nTREC DL, and BEIR benchmarks, demonstrating superior effectiveness and\nrobustness compared to existing approaches. On the reasoning-intensive BRIGHT\nbenchmark, our ERank-4B achieves an nDCG@10 of 38.7, while a larger 32B variant\nreaches a state of the art nDCG@10 of 40.2.", "published": "2025-08-30 14:56:53", "link": "http://arxiv.org/abs/2509.00520v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "MedSEBA: Synthesizing Evidence-Based Answers Grounded in Evolving Medical Literature", "abstract": "In the digital age, people often turn to the Internet in search of medical\nadvice and recommendations. With the increasing volume of online content, it\nhas become difficult to distinguish reliable sources from misleading\ninformation. Similarly, millions of medical studies are published every year,\nmaking it challenging for researchers to keep track of the latest scientific\nfindings. These evolving studies can reach differing conclusions, which is not\nreflected in traditional search tools. To address these challenges, we\nintroduce MedSEBA, an interactive AI-powered system for synthesizing\nevidence-based answers to medical questions. It utilizes the power of Large\nLanguage Models to generate coherent and expressive answers, but grounds them\nin trustworthy medical studies dynamically retrieved from the research database\nPubMed. The answers consist of key points and arguments, which can be traced\nback to respective studies. Notably, the platform also provides an overview of\nthe extent to which the most relevant studies support or refute the given\nmedical claim, and a visualization of how the research consensus evolved\nthrough time. Our user study revealed that medical experts and lay users find\nthe system usable and helpful, and the provided answers trustworthy and\ninformative. This makes the system well-suited for both everyday health\nquestions and advanced research insights.", "published": "2025-08-30 08:43:09", "link": "http://arxiv.org/abs/2509.00414v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Beyond Negative Transfer: Disentangled Preference-Guided Diffusion for Cross-Domain Sequential Recommendation", "abstract": "Cross-Domain Sequential Recommendation (CDSR) leverages user behaviors across\ndomains to enhance recommendation quality. However, naive aggregation of\nsequential signals can introduce conflicting domain-specific preferences,\nleading to negative transfer. While Sequential Recommendation (SR) already\nsuffers from noisy behaviors such as misclicks and impulsive actions, CDSR\nfurther amplifies this issue due to domain heterogeneity arising from diverse\nitem types and user intents. The core challenge is disentangling three\nintertwined signals: domain-invariant preferences, domain-specific preferences,\nand noise. Diffusion Models (DMs) offer a generative denoising framework\nwell-suited for disentangling complex user preferences and enhancing robustness\nto noise. Their iterative refinement process enables gradual denoising, making\nthem effective at capturing subtle preference signals. However, existing\napplications in recommendation face notable limitations: sequential DMs often\nconflate shared and domain-specific preferences, while cross-domain\ncollaborative filtering DMs neglect temporal dynamics, limiting their ability\nto model evolving user preferences. To bridge these gaps, we propose\n\\textbf{DPG-Diff}, a novel Disentangled Preference-Guided Diffusion Model, the\nfirst diffusion-based approach tailored for CDSR, to or best knowledge.\nDPG-Diff decomposes user preferences into domain-invariant and domain-specific\ncomponents, which jointly guide the reverse diffusion process. This\ndisentangled guidance enables robust cross-domain knowledge transfer, mitigates\nnegative transfer, and filters sequential noise. Extensive experiments on\nreal-world datasets demonstrate that DPG-Diff consistently outperforms\nstate-of-the-art baselines across multiple metrics.", "published": "2025-08-30 06:56:56", "link": "http://arxiv.org/abs/2509.00389v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "CRouting: Reducing Expensive Distance Calls in Graph-Based Approximate Nearest Neighbor Search", "abstract": "Approximate nearest neighbor search (ANNS) is a crucial problem in\ninformation retrieval and AI applications. Recently, there has been a surge of\ninterest in graph-based ANNS algorithms due to their superior efficiency and\naccuracy. However, the repeated computation of distances in high-dimensional\nspaces constitutes the primary time cost of graph-based methods. To accelerate\nthe search, we propose a novel routing strategy named CRouting, which bypasses\nunnecessary distance computations by exploiting the angle distributions of\nhigh-dimensional vectors. CRouting is designed as a plugin to optimize existing\ngraph-based search with minimal code modifications. Our experiments show that\nCRouting reduces the number of distance computations by up to 41.5% and boosts\nqueries per second by up to 1.48$\\times$ on two predominant graph indexes, HNSW\nand NSG. Code is publicly available at https://github.com/ISCS-ZJU/CRouting.", "published": "2025-08-30 05:27:09", "link": "http://arxiv.org/abs/2509.00365v1", "categories": ["cs.DB", "cs.IR"], "primary_category": "cs.DB"}
{"title": "GIER: Gap-Driven Self-Refinement for Large Language Models", "abstract": "We introduce GIER (Gap-driven Iterative Enhancement of Responses), a general\nframework for improving large language model (LLM) outputs through\nself-reflection and revision based on conceptual quality criteria. Unlike\nprompting strategies that rely on demonstrations, examples, or chain-of-thought\ntemplates, GIER utilizes natural language descriptions of reasoning gaps, and\nprompts a model to iteratively critique and refine its own outputs to better\nsatisfy these criteria. Across three reasoning-intensive tasks (SciFact,\nPrivacyQA, and e-SNLI) and four LLMs (GPT-4.1, GPT-4o Mini, Gemini 1.5 Pro, and\nLlama 3.3 70B), GIER improves rationale quality, grounding, and reasoning\nalignment without degrading task accuracy. Our analysis demonstrates that\nmodels can not only interpret abstract conceptual gaps but also translate them\ninto concrete reasoning improvements.", "published": "2025-08-30 02:54:08", "link": "http://arxiv.org/abs/2509.00325v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Access Paths for Efficient Ordering with Large Language Models", "abstract": "We present the LLM ORDER BY operator as a logical abstraction and study its\nphysical implementations within a unified evaluation framework. Our experiments\nshow that no single approach is universally optimal, with effectiveness\ndepending on query characteristics and data. We introduce three new designs: an\nagreement-based batch-size policy, a majority voting mechanism for pairwise\nsorting, and a two-way external merge sort adapted for LLMs. With extensive\nexperiments, our agreement-based procedure is effective at determining batch\nsize for value-based methods, the majority-voting mechanism consistently\nstrengthens pairwise comparisons on GPT-4o, and external merge sort achieves\nhigh accuracy-efficiency trade-offs across datasets and models. We further\nobserve a log-linear scaling between compute cost and ordering quality,\noffering the first step toward principled cost models for LLM powered data\nsystems.", "published": "2025-08-30 01:44:36", "link": "http://arxiv.org/abs/2509.00303v1", "categories": ["cs.DB", "cs.AI", "cs.IR"], "primary_category": "cs.DB"}
{"title": "OpinioRAG: Towards Generating User-Centric Opinion Highlights from Large-scale Online Reviews", "abstract": "We study the problem of opinion highlights generation from large volumes of\nuser reviews, often exceeding thousands per entity, where existing methods\neither fail to scale or produce generic, one-size-fits-all summaries that\noverlook personalized needs. To tackle this, we introduce OpinioRAG, a\nscalable, training-free framework that combines RAG-based evidence retrieval\nwith LLMs to efficiently produce tailored summaries. Additionally, we propose\nnovel reference-free verification metrics designed for sentiment-rich domains,\nwhere accurately capturing opinions and sentiment alignment is essential. These\nmetrics offer a fine-grained, context-sensitive assessment of factual\nconsistency. To facilitate evaluation, we contribute the first large-scale\ndataset of long-form user reviews, comprising entities with over a thousand\nreviews each, paired with unbiased expert summaries and manually annotated\nqueries. Through extensive experiments, we identify key challenges, provide\nactionable insights into improving systems, pave the way for future research,\nand position OpinioRAG as a robust framework for generating accurate, relevant,\nand structured summaries at scale.", "published": "2025-08-30 00:00:34", "link": "http://arxiv.org/abs/2509.00285v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "QoS-Driven Satellite Constellation Design for LEO Satellite Internet of Things", "abstract": "Low Earth orbit (LEO) satellite Internet of Things (IoT) has been identified\nas one of the important components of the sixth-generation (6G) non-terrestrial\nnetworks (NTN) to provide ubiquitous connectivity. Due to the low orbit\naltitude and high mobility, a massive number of satellites are required to form\na global continuous coverage constellation, leading to a high construction\ncost. To this end, this paper proposes a LEO satellite IoT constellation design\nalgorithm with the goal of minimizing the total cost while satisfying quality\nof service (QoS) requirements in terms of coverage ratio and communication\nquality. Specifically, with a novel fitness function and efficient algorithm's\noperators, the proposed algorithm converges more quickly and achieves lower\nconstellation construction cost compared to baseline algorithms under the same\nQoS requirements. Theoretical analysis proves the global and fast convergence\nof the proposed algorithm due to a novel fitness function. Finally, extensive\nsimulation results confirm the effectiveness of the proposed algorithm in LEO\nsatellite IoT constellation design.", "published": "2025-08-30 03:53:44", "link": "http://arxiv.org/abs/2509.00345v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Deep Complex-valued Neural-Network Modeling and Optimization of Stacked Intelligent Surfaces", "abstract": "We propose a complex-valued neural-network (CV-NN) framework to optimally\nconfigure stacked intelligent surfaces (SIS) in next-generation multi-antenna\nsystems. Unlike conventional solutions that separately tune analog metasurface\nphases or rely strictly on SVD-based orthogonal decompositions, our method\nmodels each SIS element as a unit-modulus complex-velued neuron in an\nend-to-end differentiable pipeline. This approach avoids enforcing channel\northogonality and instead allows for richer wavefront designs that can target a\nwide range of system objectives, such as maximizing spectral efficiency and\nminimizing detection errors, all within a single optimization framework.\nMoreover, by exploiting a fully differentiable neural-network formulation and\nGPU-based auto-differentiation, our approach can rapidly train SIS\nconfigurations for realistic, high-dimensional channels, enabling near-online\nadaptation. Our framework also naturally accommodates hybrid analog-digital\nbeamforming and recovers classical SVD solutions as a special case. Numerical\nevaluations under Rician channels demonstrate that CV-NN SIS optimization\noutperforms state-of-the-art schemes in throughput, error performance, and\nrobustness to channel variation, opening the door to more flexible and powerful\nwave-domain control for future 6G networks.", "published": "2025-08-30 03:45:11", "link": "http://arxiv.org/abs/2509.00340v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "New Constructions of Optimal $(r,\u03b4)$-LRCs via Algebraic Function Fields", "abstract": "Constructing optimal $(r,\\delta)$-LRCs that attain the Singleton-type bound\nis an active and important research direction, particularly due to their\npractical applications in distributed storage systems. In this paper, we focus\non the construction of optimal $(r,\\delta)$-LRCs with flexible minimum\ndistances, especially for the case $\\delta \\geq 3$. We first extend a general\nframework -- originally proposed by Li \\textit{et al.} (IEEE Trans. Inf.\nTheory, vol. 65, no. 1, 2019) and Ma and Xing (J. Comb. Theory Ser. A., vol.\n193, 2023) -- for constructing optimal $r$-LRCs via automorphism groups of\nelliptic function fields to the case of $(r,\\delta)$-LRCs. This newly extended\ngeneral framework relies on certain conditions concerning the group law of\nelliptic curves. By carefully selecting elliptic function fields suitable for\nthis framework, we arrive at several families of explicit $q$-ary optimal\n$(r,3)$-LRCs and $(2,\\delta)$-LRCs with lengths slightly less than $q +\n2\\sqrt{q}$. Next, by employing automorphism groups of hyperelliptic function\nfields of genus $2$, we develop a framework for constructing optimal\n$(r,3)$-LRCs and obtain a family of explicit $q$-ary optimal $(4,3)$-LRCs with\ncode lengths slightly below $q+4\\sqrt{q}$. We then consider the construction of\noptimal $(r,\\delta)$-LRCs via hyperelliptic function fields of arbitrary genus\n$g \\geq 2$, yielding a class of explicit $q$-ary optimal $(g+1-g',g+1+g')$-LRCs\nfor $0 \\leq g' \\leq g-1$ with lengths up to $q + 2g\\sqrt{q}$. Finally, applying\ncertain superelliptic curves derived from modified Norm-Trace curves, we\nconstruct two families of explicit optimal $(r,\\delta)$-LRCs with even longer\ncode lengths and more flexible parameters. Notably, many of the newly\nconstructed optimal $(r,\\delta)$-LRCs attain the largest known lengths among\nexisting constructions with flexible minimum distances.", "published": "2025-08-30 01:42:36", "link": "http://arxiv.org/abs/2509.00302v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "MobiAgent: A Systematic Framework for Customizable Mobile Agents", "abstract": "With the rapid advancement of Vision-Language Models (VLMs), GUI-based mobile\nagents have emerged as a key development direction for intelligent mobile\nsystems. However, existing agent models continue to face significant challenges\nin real-world task execution, particularly in terms of accuracy and efficiency.\nTo address these limitations, we propose MobiAgent, a comprehensive mobile\nagent system comprising three core components: the MobiMind-series agent\nmodels, the AgentRR acceleration framework, and the MobiFlow benchmarking\nsuite. Furthermore, recognizing that the capabilities of current mobile agents\nare still limited by the availability of high-quality data, we have developed\nan AI-assisted agile data collection pipeline that significantly reduces the\ncost of manual annotation. Compared to both general-purpose LLMs and\nspecialized GUI agent models, MobiAgent achieves state-of-the-art performance\nin real-world mobile scenarios.", "published": "2025-08-30 15:24:47", "link": "http://arxiv.org/abs/2509.00531v1", "categories": ["cs.MA", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Mean-payoff and Energy Discrete Bidding Games", "abstract": "A \\emph{bidding} game is played on a graph as follows. A token is placed on\nan initial vertex and both players are allocated budgets. In each turn, the\nplayers simultaneously submit bids that do not exceed their available budgets,\nthe higher bidder moves the token, and pays the bid to the lower bidder. We\nfocus on \\emph{discrete}-bidding, which are motivated by practical applications\nand restrict the granularity of the players' bids, e.g, bids must be given in\ncents. We study, for the first time, discrete-bidding games with {\\em\nmean-payoff} and {\\em energy} objectives. In contrast, mean-payoff {\\em\ncontinuous}-bidding games (i.e., no granularity restrictions) are understood\nand exhibit a rich mathematical structure. The {\\em threshold} budget is a\nnecessary and sufficient initial budget for winning an energy game or\nguaranteeing a target payoff in a mean-payoff game. We first establish\nexistence of threshold budgets; a non-trivial property due to the concurrent\nmoves of the players. Moreover, we identify the structure of the thresholds,\nwhich is key in obtaining compact strategies, and in turn, showing that finding\nthreshold is in \\NP~and \\coNP even in succinctly-represented games.", "published": "2025-08-30 14:00:04", "link": "http://arxiv.org/abs/2509.00506v1", "categories": ["cs.GT", "cs.FL", "cs.MA"], "primary_category": "cs.GT"}
{"title": "KG-RAG: Enhancing GUI Agent Decision-Making via Knowledge Graph-Driven Retrieval-Augmented Generation", "abstract": "Despite recent progress, Graphic User Interface (GUI) agents powered by Large\nLanguage Models (LLMs) struggle with complex mobile tasks due to limited\napp-specific knowledge. While UI Transition Graphs (UTGs) offer structured\nnavigation representations, they are underutilized due to poor extraction and\ninefficient integration. We introduce KG-RAG, a Knowledge Graph-driven\nRetrieval-Augmented Generation framework that transforms fragmented UTGs into\nstructured vector databases for efficient real-time retrieval. By leveraging an\nintent-guided LLM search method, KG-RAG generates actionable navigation paths,\nenhancing agent decision-making. Experiments across diverse mobile apps show\nthat KG-RAG outperforms existing methods, achieving a 75.8% success rate (8.9%\nimprovement over AutoDroid), 84.6% decision accuracy (8.1% improvement), and\nreducing average task steps from 4.5 to 4.1. Additionally, we present\nKG-Android-Bench and KG-Harmony-Bench, two benchmarks tailored to the Chinese\nmobile ecosystem for future research. Finally, KG-RAG transfers to web/desktop\n(+40% SR on Weibo-web; +20% on QQ Music-desktop), and a UTG cost ablation shows\naccuracy saturates at ~4h per complex app, enabling practical deployment\ntrade-offs.", "published": "2025-08-30 05:32:32", "link": "http://arxiv.org/abs/2509.00366v1", "categories": ["cs.MA", "cs.CL", "cs.MM"], "primary_category": "cs.MA"}
{"title": "Numerical solution of 2D boundary value problems on merged Voronoi-Delaunay meshes", "abstract": "Computational technologies for the approximate solution of multidimensional\nboundary value problems often rely on irregular computational meshes and\nfinite-volume approximations. In this framework, the discrete problem\nrepresents the corresponding conservation law for control volumes associated\nwith the nodes of the mesh. This approach is most naturally and consistently\nimplemented using Delaunay triangulations together with Voronoi diagrams as\ncontrol volumes. In this paper, we employ meshes with nodes located both at the\nvertices of Delaunay triangulations and at the generators of Voronoi\npartitions. The cells of the merged Voronoi-Delaunay mesh are orthodiagonal\nquadrilaterals. On such meshes, scalar and vector functions, as well as\ninvariant gradient and divergence operators of vector calculus, can be\nconveniently approximated. We illustrate the capabilities of this approach by\nsolving a steady-state diffusion-reaction problem in an anisotropic medium.", "published": "2025-08-30 16:45:47", "link": "http://arxiv.org/abs/2509.00557v1", "categories": ["math.NA", "cs.NA", "35J25, 65N08, 65D18, 65N06"], "primary_category": "math.NA"}
{"title": "AS-BOX: Additional Sampling Method for Weighted Sum Problems with Box Constraints", "abstract": "A class of optimization problems characterized by a weighted finite-sum\nobjective function subject to box constraints is considered. We propose a novel\nstochastic optimization method, named AS-BOX (\\text{A}ddi\\-ti\\-onal\n\\text{S}ampling for \\text{BOX} constraints), that combines projected gradient\ndirections with adaptive variable sample size strategies and nonmonotone line\nsearch. The method dynamically adjusts the batch size based on progress with\nrespect to the additional sampling function and on structural consistency of\nthe projected direction, enabling practical adaptivity of AS-BOX, while\nensuring theoretical support. We establish almost sure convergence under\nstandard assumptions and provide complexity bounds. Numerical experiments\ndemonstrate the efficiency and competitiveness of the proposed method compared\nto state-of-the-art algorithms.", "published": "2025-08-30 16:09:04", "link": "http://arxiv.org/abs/2509.00547v1", "categories": ["math.OC", "cs.NA", "math.NA", "90C15, 90C26, 90C30, 65K05"], "primary_category": "math.OC"}
{"title": "Stabilization techniques for immersogeometric analysis of plate and shell problems in explicit dynamics", "abstract": "Finite element plate and shell formulations are ubiquitous in structural\nanalysis for modeling all kinds of slender structures, both for static and\ndynamic analyses. The latter are particularly challenging as the high order\nnature of the underlying partial differential equations and the slenderness of\nthe structures all impose a stringent constraint on the critical time step in\nexplicit dynamics. Unfortunately, badly cut elements in immersed finite element\ndiscretizations further aggravate the issue. While lumping the mass matrix\noften increases the critical time step, it might also trigger spurious\noscillations in the approximate solution thereby compromising the numerical\nsolution. In this article, we extend our previous work in\n\\cite{voet2025stabilization} to allow stable immersogeometric analysis of plate\nand shell problems with lumped mass matrices. This technique is based on\npolynomial extensions and restores a level of accuracy comparable to\nboundary-fitted discretizations.", "published": "2025-08-30 15:05:50", "link": "http://arxiv.org/abs/2509.00522v1", "categories": ["math.NA", "cs.CE", "cs.NA"], "primary_category": "math.NA"}
{"title": "The adaptive EM schemes for McKean-Vlasov SDEs with common noise in finite and infinite horizons", "abstract": "This paper is dedicated to investigating the adaptive Euler-Maruyama (EM)\nschemes for the approximation of McKean-Vlasov stochastic differential\nequations (SDEs) with common noise. When the drift and diffusion coefficients\nboth satisfy the superlinear growth conditions, the $L^p$ convergence rates in\nfinite and infinite horizons are revealed, which reacts to the particle number\nand step size. Subsequently, there is an illustration of the theory results by\nmeans of two numerical examples.", "published": "2025-08-30 14:57:59", "link": "http://arxiv.org/abs/2509.00521v1", "categories": ["math.NA", "cs.NA", "math.PR"], "primary_category": "math.NA"}
{"title": "On discrete Sobolev inequalities for nonconforming finite elements under a semi-regular mesh condition", "abstract": "We derive a discrete $ L^q-L^p$ Sobolev inequality tailored for the\nCrouzeix--Raviart and discontinuous Crouzeix--Raviart finite element spaces on\nanisotropic meshes in both two and three dimensions. Subject to a semi-regular\nmesh condition, this discrete Sobolev inequality is applicable to all pairs\n$(q,p)$ that align with the local Sobolev embedding, including scenarios where\n$q \\leq p$. Importantly, the constant is influenced solely by the domain and\nthe semi-regular parameter, ensuring robustness against variations in aspect\nratios and interior angles of the mesh. The proof employs an\nanisotropy-sensitive trace inequality that leverages the element height, a\ntwo-step affine/Piola mapping approach, the stability of the Raviart--Thomas\ninterpolation, and a discrete integration-by-parts identity augmented with\nweighted jump/trace terms on faces. This Sobolev inequality serves as a\nmesh-robust foundation for the stability and error analysis of nonconforming\nand discontinuous Galerkin methods on highly anisotropic meshes.", "published": "2025-08-30 13:56:18", "link": "http://arxiv.org/abs/2509.00505v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Mixed Precision Eigensolver Based on the Jacobi Algorithm", "abstract": "The classic method for computing the spectral decomposition of a real\nsymmetric matrix, the Jacobi algorithm, can be accelerated by using mixed\nprecision arithmetic. The Jacobi algorithm is aiming to reduce the off-diagonal\nentries iteratively using Givens rotations. We investigate how to use the low\nprecision to speed up this algorithm based on the approximate spectral\ndecomposition in low precision.\n  We first study two different index choosing techniques, classical and\ncyclic-by-row, for the Jacobi algorithm. Numerical testing suggests that\ncyclic-by-row is more efficient. Then we discuss two different methods of\northogonalizing an almost orthogonal matrix: the QR factorization and the polar\ndecomposition. For polar decomposition, we speed up the Newton iteration by\nusing the one-step Schulz iteration. Based on numerical testing, using the\npolar decomposition approach (Newton--Schulz iteration) is not only faster but\nalso more accurate than using the QR factorization.\n  A mixed precision algorithm for computing the spectral decomposition of a\nreal symmetric matrix at double precision is provided. In doing so we compute\nthe approximate eigenvector matrix $Q_\\ell$ of $A$ in single precision using\n$\\texttt{eig}$ and $\\texttt{single}$ in MATLAB. We then use the Newton--Schulz\niteration to orthogonalize the eigenvector matrix $Q_\\ell$ into an orthogonal\nmatrix $Q_d$ in double precision. Finally, we apply the cyclic-by-row Jacobi\nalgorithm on $Q_d^TAQ_d$ and obtain the spectral decomposition of $A$. At this\nstage, we will see, from the testings, the cyclic-by-row Jacobi algorithm only\nneed less than 10 iterations to converge by utilizing the quadratic\nconvergence. The new mixed precision algorithm requires roughly 30\\% of the\ntime used by the Jacobi algorithm on its own.", "published": "2025-08-30 13:37:17", "link": "http://arxiv.org/abs/2509.00495v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Development of numerical methods for nonlinear hybrid stochastic functional differential equations with infinite delay", "abstract": "This paper focuses on explicit numerical approximations for nonlinear hybrid\nstochastic functional differential equations with infinite delay. Precisely,\nexplicit truncated Euler-Maruyama schemes are proposed, $2p$th $(p \\ge 1)$\nmoment boundedness and strong convergence of the numerical solutions are\nobtained. Under slightly stronger conditions, the $1/2$ order convergence rate\nis established. Furthermore, the exponential stability, including moment and\nalmost sure exponential stability, is examined. Finally, an example is provided\nto illustrate our results.", "published": "2025-08-30 12:18:02", "link": "http://arxiv.org/abs/2509.00475v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Superconvergence Extraction of Upwind Discontinuous Galerkin Method Solving the Radiative Transfer Equation", "abstract": "We theoretically analyze the superconvergence of the upwind discontinuous\nGalerkin (DG) method for both the steady-state and time-dependent radiative\ntransfer equation (RTE), and apply the Smooth-Increasing Accuracy-Conserving\n(SIAC) filters to enhance the accuracy order. Direct application of SIAC\nfilters on low-dimensional macroscopic moments, often the quantities of\npractical interest, can effectively improve the approximation accuracy with\nmarginal computational overhead.\n  Using piecewise $k$-th order polynomials for the approximation and assuming\nconstant cross sections, we prove $(2k+2)$-th order superconvergence for the\nsteady-state problem at Radau points on each element and $(2k+1/2)$-th order\nsuperconvergence for the global $L^2$ and negative-order Sobolev norms for the\ntime-dependent problem.\n  Numerical experiments confirm the efficacy of the filtering, demonstrating\npost-filter convergence orders of $2k+2$ for steady-state and $2k+1$ for\ntime-dependent problems. More significantly, the SIAC filter delivers\nsubstantial gains in computational efficiency. For a time-dependent problem, we\nobserved an approximately $2.22 \\times$ accuracy improvement and a $19.94\n\\times$ reduction in computational time. For the steady-state problems, the\nfilter achieved a $4$--$9 \\times$ acceleration without any loss of accuracy.", "published": "2025-08-30 01:19:20", "link": "http://arxiv.org/abs/2509.00296v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Pricing American options with exogenous and endogenous transaction costs", "abstract": "We study an American option pricing problem with liquidity risks and\ntransaction fees. As endogenous transaction costs, liquidity risks of the\nunderlying asset are modeled by a mean-reverting process. Transaction fees are\nexogenous transaction costs and are assumed to be proportional to the trading\namount, with the long-run liquidity level depending on the proportional\ntransaction costs rate. Two nonlinear partial differential equations are\nestablished to characterize the option values for the holder and the writer,\nrespectively. To illustrate the impact of these transaction costs on option\nprices and optimal exercise prices, we apply the alternating direction implicit\nmethod to solve the linear complementarity problem numerically. Finally, we\nconduct model calibration from market data via maximum likelihood estimation,\nand find that our model incorporating liquidity risks outperforms the Leland\nmodel significantly.", "published": "2025-08-30 12:58:13", "link": "http://arxiv.org/abs/2509.00485v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Identifying Causal Direction via Dense Functional Classes", "abstract": "We address the problem of determining the causal direction between two\nunivariate, continuous-valued variables, X and Y, under the assumption of no\nhidden confounders. In general, it is not possible to make definitive\nstatements about causality without some assumptions on the underlying model. To\ndistinguish between cause and effect, we propose a bivariate causal score based\non the Minimum Description Length (MDL) principle, using functions that possess\nthe density property on a compact real interval. We prove the identifiability\nof these causal scores under specific conditions. These conditions can be\neasily tested. Gaussianity of the noise in the causal model equations is not\nassumed, only that the noise is low. The well-studied class of cubic splines\npossesses the density property on a compact real interval. We propose LCUBE as\nan instantiation of the MDL-based causal score utilizing cubic regression\nsplines. LCUBE is an identifiable method that is also interpretable, simple,\nand very fast. It has only one hyperparameter. Empirical evaluations compared\nto state-of-the-art methods demonstrate that LCUBE achieves superior precision\nin terms of AUDRC on the real-world Tuebingen cause-effect pairs dataset. It\nalso shows superior average precision across common 10 benchmark datasets and\nachieves above average precision on 13 datasets.", "published": "2025-08-30 15:42:31", "link": "http://arxiv.org/abs/2509.00538v1", "categories": ["stat.ML", "cs.LG", "stat.CO"], "primary_category": "stat.ML"}
{"title": "Partial Functional Dynamic Backdoor Diffusion-based Causal Model", "abstract": "We introduce a Partial Functional Dynamic Backdoor Diffusion-based Causal\nModel (PFD-BDCM), specifically designed for causal inference in the presence of\nunmeasured confounders with spatial heterogeneity and temporal dependency. The\nproposed PFD-BDCM framework addresses the restrictions of the existing\napproaches by uniquely integrating models for complex spatio-temporal dynamics\nwith the analysis of multi-resolution variables. Specifically, the framework\nsystematically mitigates confounding bias by integrating valid backdoor\nadjustment sets into a diffusion-based sampling mechanism. Moreover, it\naccounts for the intricate dynamics of unmeasured confounders through the\ndeployment of region-specific structural equations and conditional\nautoregressive processes, and accommodates variables observed at heterogeneous\nresolutions via basis expansions for functional data. Our theoretical analysis\nestablishes error bounds for counterfactual estimates of PFD-BDCM, formally\nlinking reconstruction accuracy to counterfactual fidelity under monotonicity\nassumptions of structural equation and invertibility assumptions of encoding\nfunction. Empirical evaluations on synthetic datasets and real-world air\npollution data demonstrate PFD-BDCM's superiority over existing methods.", "published": "2025-08-30 12:11:23", "link": "http://arxiv.org/abs/2509.00472v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH", "G.3; J.2"], "primary_category": "stat.ML"}
{"title": "Real-Time Piano Note Frequency Detection Using FPGA and FFT Core", "abstract": "Real-time frequency analysis of musical instruments, such as the piano, is an\nessential feature in areas like electronic tuners, music visualizers, and live\nsound monitoring. Traditional methods often rely on software-based digital\nsignal processing (DSP), which may introduce latency and require significant\ncomputational power. In contrast, hardware platforms such as FPGAs (Field\nProgrammable Gate Arrays) offer the ability to perform such analyses with\ngreater speed and determinism due to their parallel processing capabilities.\nThe primary objective of this project was to analyze analog audio signals from\na digital piano using an FPGA-based real-time Fast Fourier Transform (FFT)\nsystem.", "published": "2025-08-30 18:52:41", "link": "http://arxiv.org/abs/2509.00589v1", "categories": ["cs.AR", "cs.SD", "eess.AS"], "primary_category": "cs.AR"}
{"title": "Entropy-based Coarse and Compressed Semantic Speech Representation Learning", "abstract": "Discrete speech representation learning has recently attracted increasing\ninterest in both acoustic and semantic modeling. Existing approaches typically\nencode 16 kHz waveforms into discrete tokens at a rate of 25 or 50 tokens per\nsecond. However, given that speech generally conveys only 2 to 5 words per\nsecond, such fine-grained tokenization introduces redundancy and hinders\nefficiency in downstream training and inference. Moreover, semantic speech\nrepresentations at this frequency primarily capture phonetic-level information,\nwhile semantic understanding may not require such detailed token-level\nresolution. To address these limitations, we propose an entropy-based dynamic\naggregation framework for learning compressed semantic speech representations.\nA speech language model is first pre-trained via next-token prediction on\nlarge-scale unlabeled data to capture frequent token patterns. Predictive\nentropy is then used to adaptively determine aggregation boundaries, followed\nby a cross-attention module that fuses information within each segment. By\nadjusting the entropy threshold, the granularity and compression ratio of the\nrepresentations can be flexibly controlled. Experiments on ASR, speech-to-text\ntranslation, and voice conversion tasks demonstrate that the compressed\nrepresentations perform on par with or better than dense token sequences,\ndemonstrating the effectiveness of the proposed approach.", "published": "2025-08-30 13:50:58", "link": "http://arxiv.org/abs/2509.00503v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SaD: A Scenario-Aware Discriminator for Speech Enhancement", "abstract": "Generative adversarial network-based models have shown remarkable performance\nin the field of speech enhancement. However, the current optimization\nstrategies for these models predominantly focus on refining the architecture of\nthe generator or enhancing the quality evaluation metrics of the discriminator.\nThis approach often overlooks the rich contextual information inherent in\ndiverse scenarios. In this paper, we propose a scenario-aware discriminator\nthat captures scene-specific features and performs frequency-domain division,\nthereby enabling a more accurate quality assessment of the enhanced speech\ngenerated by the generator. We conducted comprehensive experiments on three\nrepresentative models using two publicly available datasets. The results\ndemonstrate that our method can effectively adapt to various generator\narchitectures without altering their structure, thereby unlocking further\nperformance gains in speech enhancement across different scenarios.", "published": "2025-08-30 08:29:38", "link": "http://arxiv.org/abs/2509.00405v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Learning for Personalized Binaural Audio Reproduction", "abstract": "Personalized binaural audio reproduction is the basis of realistic spatial\nlocalization, sound externalization, and immersive listening, directly shaping\nuser experience and listening effort. This survey reviews recent advances in\ndeep learning for this task and organizes them by generation mechanism into two\nparadigms: explicit personalized filtering and end-to-end rendering. Explicit\nmethods predict personalized head-related transfer functions (HRTFs) from\nsparse measurements, morphological features, or environmental cues, and then\nuse them in the conventional rendering pipeline. End-to-end methods map source\nsignals directly to binaural signals, aided by other inputs such as visual,\ntextual, or parametric guidance, and they learn personalization within the\nmodel. We also summarize the field's main datasets and evaluation metrics to\nsupport fair and repeatable comparison. Finally, we conclude with a discussion\nof key applications enabled by these technologies, current technical\nlimitations, and potential research directions for deep learning-based spatial\naudio systems.", "published": "2025-08-30 07:52:28", "link": "http://arxiv.org/abs/2509.00400v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards High-Fidelity and Controllable Bioacoustic Generation via Enhanced Diffusion Learning", "abstract": "Generative modeling offers new opportunities for bioacoustics, enabling the\nsynthesis of realistic animal vocalizations that could support biomonitoring\nefforts and supplement scarce data for endangered species. However, directly\ngenerating bird call waveforms from noisy field recordings remains a major\nchallenge.\n  We propose BirdDiff, a generative framework designed to synthesize bird calls\nfrom a noisy dataset of 12 wild bird species. The model incorporates a \"zeroth\nlayer\" stage for multi-scale adaptive bird-call enhancement, followed by a\ndiffusion-based generator conditioned on three modalities: Mel-frequency\ncepstral coefficients, species labels, and textual descriptions. The\nenhancement stage improves signal-to-noise ratio (SNR) while minimizing\nspectral distortion, achieving the highest SNR gain (+10.45 dB) and lowest\nItakura-Saito Distance (0.54) compared to three widely used non-training\nenhancement methods.\n  We evaluate BirdDiff against a baseline generative model, DiffWave. Our\nmethod yields substantial improvements in generative quality metrics: Fr\\'echet\nAudio Distance (0.590 to 0.213), Jensen-Shannon Divergence (0.259 to 0.226),\nand Number of Statistically-Different Bins (7.33 to 5.58). To assess\nspecies-specific detail preservation, we use a ResNet50 classifier trained on\nthe original dataset to identify generated samples. Classification accuracy\nimproves from 35.9% (DiffWave) to 70.1% (BirdDiff), with 8 of 12 species\nexceeding 70% accuracy.\n  These results demonstrate that BirdDiff enables high-fidelity, controllable\nbird call generation directly from noisy field recordings.", "published": "2025-08-30 02:30:10", "link": "http://arxiv.org/abs/2509.00318v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Realization of Precise Perforating Using Dynamic Threshold and Physical Plausibility Algorithm for Self-Locating Perforating in Oil and Gas Wells", "abstract": "Accurate depth measurement is essential for optimizing oil and gas resource\ndevelopment, as it directly impacts production efficiency. However, achieving\nprecise depth and perforating at the correct location remains a significant\nchallenge due to field operational constraints and equipment limitations. In\nthis work, we propose the Dynamic Threshold and Physical Plausibility Depth\nMeasurement and Perforation Control (DTPPMP) system, a solution integrated into\nperforating guns that enables real-time, precise depth measurement and\nperforation at designated perforating intervals. The system autonomously\nsamples, processes and identifies signals from a casing collar locator (CCL) in\nsitu within oil and gas wells. Casing collar identification is achieved using a\nlightweight dynamic threshold and physical plausibility algorithm deployed on\nan embedded platform, which serves as the system's processor. Field tests\nconducted in an actual oil well in Sichuan, China, demonstrated the DTPPMP's\nability to accurately identify casing collar signals, measure depths, and\neffectively perforate at designated perforating intervals in real-time. The\nsystem achieved a perforation variation of less than the length of a single\nperforating interval and a F1 score of 98.6% for casing collar identification.\nThese results provide valuable recommendations for advancing automation and\nintelligence in future perforation operations.", "published": "2025-08-30 21:08:20", "link": "http://arxiv.org/abs/2509.00608v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Robust Resource Allocation for LEO Satellite-Assisted Secure SWIPT via STAR-RIS under CSI Uncertainty", "abstract": "This paper proposes a robust resource allocation framework for a low Earth\norbit (LEO) satellite-enabled simultaneous wireless information and power\ntransfer (SWIPT) system, assisted by a ground-deployed simultaneously\ntransmitting and reflecting reconfigurable intelligent surface (STAR-RIS). We\nconsider a scenario where direct satellite-to-ground links are obstructed, and\nthe satellite serves multiple single-antenna energy receivers, information\nreceivers, and eavesdroppers exclusively via the STAR-RIS. A robust\noptimization problem is formulated to maximize the total harvested power,\nsubject to secrecy rate requirements, transmit power limits, and STAR-RIS\ncoefficient constraints, under a practical bounded channel state information\n(CSI) error model. To achieve optimal robust resource allocation, we address\nthe challenges posed by coupled optimization variables and bounded channel\nestimation errors by first applying the S-procedure to handle robustness\nagainst channel uncertainty. An alternating optimization (AO) framework is\nsubsequently proposed, where the active beamforming at the LEO satellite and\nthe passive beamforming at the STAR-RIS are jointly optimized, and a\npenalty-based strategy is incorporated to enforce the STAR-RIS beamforming\ndesign. Simulation results validate the effectiveness of the proposed algorithm\nand demonstrate that the STAR-RIS architecture achieves substantial performance\ngains in total harvested power over conventional RIS and other baseline\nschemes.", "published": "2025-08-30 17:24:42", "link": "http://arxiv.org/abs/2509.00568v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Distributed Deployment and Dual-Frequency Concepts to Strengthen Sub-THz Wireless Systems", "abstract": "The vast bandwidth available at sub-THz frequencies holds great promise for\nhigh-speed wireless access, precise localization, and advanced sensing\napplications. However, fundamental physical constraints and technological\nlimitations make the deployment of reliable sub-THz networks challenging. We\npropose a new paradigm for sub-THz coverage by transmitting the RF signals over\npolymer microwave fibers (PMFs) that interconnect low-complexity radio units\n(RUs) in a daisy-chain configuration. The distributed architecture ensures that\nuser equipments (UEs) connect to RUs in their proximity, reducing path loss and\nmitigating blocking. The RUs leverage low-complexity, compact integrated\nantenna modules. Additionally, dual-frequency tandem operation is proposed,\nintegrating the sub-THz system with a sub-10 GHz system that provides control\nsignalling and a robust fallback solution for the sub-THz system. This proposed\ntandem architecture can open up the full potential of sub-THz technology and\npaves the way to cost- and energy-efficient, high-performance, real-time\nconnectivity in dynamic environments.", "published": "2025-08-30 13:31:48", "link": "http://arxiv.org/abs/2509.00492v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pilot Allocation and Receiver Design for Cell-Free Massive MIMO ISAC Systems", "abstract": "This paper tackles two key challenges in cell-freemassive multiple input\nmultiple output (CF-mMIMO) systems:efficient pilot allocation and practical\nreceiver design. To thisend, we introduce a novel pilot allocation framework\nleveragingmanifold optimization to maximize the system sum rate, wherepilot\nsequences are designed as nearly orthogonal sequences. Theproposed pilot design\nenforces unimodularity constraints in thefrequency domain, ensuring pilots are\nsuitable for both communi-cation and sensing tasks. Additionally, a gaussian\nbelief propaga-tion (GaBP)-based receiver is introduced, providing\nnear-optimaldetection performance with substantially reduced\ncomputationalcomplexity. Simulation results demonstrate that the proposedpilot\nallocation method achieves communication performancecomparable to\nstate-of-the-art (SotA) algorithms, while deliveringsuperior sensing\ncapabilities due to its unimodular pilot design.The GaBP-based receiver\nachieves robust performance andlower complexity compared to conventional\napproaches. Thesecontributions advance the practical deployment of CF-mMIMOfor\nintegrated sensing and communications (ISAC).", "published": "2025-08-30 12:27:29", "link": "http://arxiv.org/abs/2509.00478v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "AN-Aided Secure Beamforming for ELAA-SWIPT in Mixed Near- and Far-Field", "abstract": "This letter investigates secure hybrid beamforming (HB) design for an\nextremely large-scale antenna array-aided simultaneous wireless information and\npower transfer (SWIPT) system operating in a mixed near-field (NF)/far-field\n(FF) environment. A base station (BS) employs HB to transmit information and\nartificial noise (AN) signals simultaneously to multiple FF information\nreceivers (IRs) and NF energy receivers (ERs). The objective is to maximize the\nweighted sum secrecy rate for the IRs, considering both Type-I (unable to\ncancel AN) and Type-II (capable of canceling AN) IRs, subject to minimum energy\nharvesting requirements at the ERs and a BS transmit power constraint. We\nformulate optimization problems for both IR types and develop an efficient\niterative algorithm based on successive convex approximation. Simulation\nresults validate the proposed scheme and provide crucial insights into the\nsecurity performance of mixed-field SWIPT systems, highlighting the influence\nof visibility regions and angular user separation.", "published": "2025-08-30 03:09:41", "link": "http://arxiv.org/abs/2509.00331v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Gait Analysis using 6DoF Magnetic Tracking", "abstract": "Gait analysis using wearable devices has advantages over non-wearable devices\nwhen it comes to portability and accessibility. However, non-wearable devices\nhave consistently shown superior performance in terms of the gait information\nthey can provide. This calls for the need to improve the performance of\nwearable device based gait analysis. To that end, we developed a 6\nDegrees-of-Freedom (6DoF) magnetic tracking based gait analysis system as a\nstep in this direction. The system is portable, minimally intrusive, wireless\nand power efficient. As a proof-of-concept, the system was used for the task of\nHuman Activity Recognition (HAR) to classify four tasks - walking (W), walking\nwith weight (WW), jogging (J) and marching on the spot (M). Gait data of 12\nparticipants was collected. The classification performance of two deep learning\n(DL) classifiers - Convolutional Neural Networks (CNN) and Long Short Term\nMemory (LSTM) - was compared. The performance of the magnetic tracking based\ngait analysis system was also compared with an Inertial Measurement Unit (IMU)\n+ magnetometer based system. The magnetic tracking based system showed an\noverall classification accuracy of 92\\% compared to 86.69\\% for the IMU +\nmagnetometer system. Moreover, the magnetic tracking system showed an\nimprovement of about 8\\% in being able to differentiate between W and WW. This\nhighlights the insufficiency in the information content in the data from IMU +\nmagnetometer, warranting the need for a complete 6DoF tracking. Our work, thus,\nproves the feasibility of using magnetic tracking systems for the purpose of\ngait analysis.", "published": "2025-08-30 02:53:04", "link": "http://arxiv.org/abs/2509.00323v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "CoMET: A Contrastive-Masked Brain Foundation Model for Universal EEG Representation", "abstract": "Electroencephalography (EEG) is a non-invasive technique for recording brain\nactivity, widely used in brain-computer interfaces, clinic, and healthcare.\nTraditional EEG deep models typically focus on specific dataset and task,\nlimiting model size and generalization. Recently, self-supervised brain\nfoundation models have emerged and been applied to various downstream tasks.\nNevertheless, these models still have limitations: current SOTA models\ntypically rely on masked reconstruction strategy; however, EEG features of\nadjacent channels are highly correlated, which causes the pre-training to\noverly focus on low-dimensional signal-similarity features in local regions and\nneglect the global discriminative patterns vital for downstream tasks. To\naddress these limitations, we propose a brain foundation model called CoMET.\nSpecifically, we employ the masked autoencoder with redesigned patching and\nembedding for EEG as backbone and devise a novel contrastive learning framework\nwith mirror-scale augmentation to strengthen the global discrimination ability.\nCoMET is pre-trained on mixed EEG datasets over 3000 subjects with over one\nmillion samples. It is evaluated on ten different downstream datasets, and the\nSOTA results demonstrate CoMET's superior ability in extracting universal EEG\nrepresentations and strong clinical potential.", "published": "2025-08-30 02:22:56", "link": "http://arxiv.org/abs/2509.00314v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pricing American options with exogenous and endogenous transaction costs", "abstract": "We study an American option pricing problem with liquidity risks and\ntransaction fees. As endogenous transaction costs, liquidity risks of the\nunderlying asset are modeled by a mean-reverting process. Transaction fees are\nexogenous transaction costs and are assumed to be proportional to the trading\namount, with the long-run liquidity level depending on the proportional\ntransaction costs rate. Two nonlinear partial differential equations are\nestablished to characterize the option values for the holder and the writer,\nrespectively. To illustrate the impact of these transaction costs on option\nprices and optimal exercise prices, we apply the alternating direction implicit\nmethod to solve the linear complementarity problem numerically. Finally, we\nconduct model calibration from market data via maximum likelihood estimation,\nand find that our model incorporating liquidity risks outperforms the Leland\nmodel significantly.", "published": "2025-08-30 12:58:13", "link": "http://arxiv.org/abs/2509.00485v2", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Pilot Allocation and Receiver Design for Cell-Free Massive MIMO ISAC Systems", "abstract": "This paper tackles two key challenges in cell-freemassive multiple input\nmultiple output (CF-mMIMO) systems:efficient pilot allocation and practical\nreceiver design. To thisend, we introduce a novel pilot allocation framework\nleveragingmanifold optimization to maximize the system sum rate, wherepilot\nsequences are designed as nearly orthogonal sequences. Theproposed pilot design\nenforces unimodularity constraints in thefrequency domain, ensuring pilots are\nsuitable for both communi-cation and sensing tasks. Additionally, a gaussian\nbelief propaga-tion (GaBP)-based receiver is introduced, providing\nnear-optimaldetection performance with substantially reduced\ncomputationalcomplexity. Simulation results demonstrate that the proposedpilot\nallocation method achieves communication performancecomparable to\nstate-of-the-art (SotA) algorithms, while deliveringsuperior sensing\ncapabilities due to its unimodular pilot design.The GaBP-based receiver\nachieves robust performance andlower complexity compared to conventional\napproaches. Thesecontributions advance the practical deployment of CF-mMIMOfor\nintegrated sensing and communications (ISAC).", "published": "2025-08-30 12:27:29", "link": "http://arxiv.org/abs/2509.00478v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
