{"title": "Pricing and Hedging Strategies for Cross-Currency Equity Protection Swaps", "abstract": "In this paper, we explore the pricing and hedging strategies for an\ninnovative insurance product called the equity protection swap(EPS). Notably,\nwe focus on the application of EPSs involving cross-currency reference\nportfolios, reflecting the realities of investor asset diversification across\ndifferent economies. The research examines key considerations regarding\nexchange rate fluctuations, pricing and hedging frameworks, in order to satisfy\ndynamic requirements from EPS buyers. We differentiate between two hedging\nparadigms: one where domestic and foreign equities are treated separately using\ntwo EPS products and another that integrates total returns across currencies.\nThrough detailed analysis, we propose various hedging strategies with\nconsideration of different types of returns - nominal, effective, and quanto -\nfor EPS products in both separate and aggregated contexts. The aggregated\nhedging portfolios contain basket options with cross-currency underlying asset,\nwhich only exists in the OTC market, thus we further consider a superhedging\nstrategy using single asset European options for aggregated returns. A\nnumerical study assesses hedging costs and performance metrics associated with\nthese hedging strategies, illuminating practical implications for EPS providers\nand investors engaged in international markets. We further employ Monte Carlo\nsimulations for the basket option pricing, together with two other\napproximation methods - geometric averaging and moment matching. This work\ncontributes to enhancing fair pricing mechanisms and risk management strategies\nin the evolving landscape of cross-currency financial derivatives.", "published": "2024-09-28 15:27:28", "link": "http://arxiv.org/abs/2409.19387v1", "categories": ["q-fin.MF", "91G20, 91G60", "G.1.10; G.1.8"], "primary_category": "q-fin.MF"}
{"title": "Time-Consistent Portfolio Selection for Rank-Dependent Utilities in an Incomplete Market", "abstract": "We investigate the portfolio selection problem for an agent with\nrank-dependent utility in an incomplete financial market. For a\nconstant-coefficient market and CRRA utilities, we characterize the\ndeterministic strict equilibrium strategies. In the case of time-invariant\nprobability weighting function, we provide a comprehensive characterization of\nthe deterministic strict equilibrium strategy. The unique non-zero equilibrium,\nif exists, can be determined by solving an autonomous ODE. In the case of\ntime-variant probability weighting functions, we observe that there may be\ninfinitely many non-zero deterministic strict equilibrium strategies, which are\nderived from the positive solutions to a nonlinear singular ODE. By specifying\nthe maximal solution to the singular ODE, we are able to identify all the\npositive solutions. In addition, we address the issue of selecting an optimal\nstrategy from the numerous equilibrium strategies available.", "published": "2024-09-28 06:28:06", "link": "http://arxiv.org/abs/2409.19259v1", "categories": ["q-fin.MF", "math.OC"], "primary_category": "q-fin.MF"}
{"title": "Evaluating Financial Relational Graphs: Interpretation Before Prediction", "abstract": "Accurate and robust stock trend forecasting has been a crucial and\nchallenging task, as stock price changes are influenced by multiple factors.\nGraph neural network-based methods have recently achieved remarkable success in\nthis domain by constructing stock relationship graphs that reflect internal\nfactors and relationships between stocks. However, most of these methods rely\non predefined factors to construct static stock relationship graphs due to the\nlack of suitable datasets, failing to capture the dynamic changes in stock\nrelationships. Moreover, the evaluation of relationship graphs in these methods\nis often tied to the performance of neural network models on downstream tasks,\nleading to confusion and imprecision. To address these issues, we introduce the\nSPNews dataset, collected based on S\\&P 500 Index stocks, to facilitate the\nconstruction of dynamic relationship graphs. Furthermore, we propose a novel\nset of financial relationship graph evaluation methods that are independent of\ndownstream tasks. By using the relationship graph to explain historical\nfinancial phenomena, we assess its validity before constructing a graph neural\nnetwork, ensuring the graph's effectiveness in capturing relevant financial\nrelationships. Experimental results demonstrate that our evaluation methods can\neffectively differentiate between various financial relationship graphs,\nyielding more interpretable results compared to traditional approaches. We make\nour source code publicly available on GitHub to promote reproducibility and\nfurther research in this area.", "published": "2024-09-28 22:43:00", "link": "http://arxiv.org/abs/2410.07216v1", "categories": ["q-fin.ST", "cs.AI", "cs.LG", "I.2.4"], "primary_category": "q-fin.ST"}
{"title": "Multi-Factor Polynomial Diffusion Models and Inter-Temporal Futures Dynamics", "abstract": "In stochastic multi-factor commodity models, it is often the case that\nfutures prices are explained by two latent state variables which represent the\nshort and long term stochastic factors. In this work, we develop the family of\nstochastic models using polynomial diffusion to obtain the unobservable spot\nprice to be used for modelling futures curve dynamics. The polynomial family of\ndiffusion models allows one to incorporate a variety of non-linear,\nhigher-order effects, into a multi-factor stochastic model, which is a\ngeneralisation of Schwartz and Smith (2000) two-factor model. Two filtering\nmethods are used for the parameter and the latent factor estimation to address\nthe non-linearity. We provide a comparative analysis of the performance of the\nestimation procedures. We discuss the parameter identification problem present\nin the polynomial diffusion case, regardless, the futures prices can still be\nestimated accurately. Moreover, we study the effects of different methods of\ncalculating matrix exponential in the polynomial diffusion model. As the\npolynomial order increases, accurately and efficiently approximating the\nhigh-dimensional matrix exponential becomes essential in the polynomial\ndiffusion model.", "published": "2024-09-28 15:25:12", "link": "http://arxiv.org/abs/2409.19386v1", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "PDSim: A Shiny App for Polynomial Diffusion Model Simulation and Estimation", "abstract": "PDSim is an R package that enables users to simulate commodity futures prices\nusing the polynomial diffusion model introduced in Filipovic and Larsson (2016)\nthrough both a Shiny web application and R scripts. It also provides state\nvariables and contract estimations via the Extended Kalman Filter (EKF) or\nUnscented Kalman Filter (UKF). With its user-friendly interface, PDSim makes\nthe features of simulations and estimations accessible to all users. To date,\nit is the only package specifically designed for the simulation and estimation\nof the polynomial diffusion model. Additionally, the package integrates the\nSchwartz and Smith two-factor model (Schwartz & Smith, 2000) as an alternative\napproach. PDSim offers versatile deployment options, including running locally,\nvia the Shiny server, or through Docker.", "published": "2024-09-28 15:20:53", "link": "http://arxiv.org/abs/2409.19385v1", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "Optimizing Time Series Forecasting: A Comparative Study of Adam and Nesterov Accelerated Gradient on LSTM and GRU networks Using Stock Market data", "abstract": "Several studies have discussed the impact different optimization techniques\nin the context of time series forecasting across different Neural network\narchitectures. This paper examines the effectiveness of Adam and Nesterov's\nAccelerated Gradient (NAG) optimization techniques on LSTM and GRU neural\nnetworks for time series prediction, specifically stock market time-series. Our\nstudy was done by training LSTM and GRU models with two different optimization\ntechniques - Adam and Nesterov Accelerated Gradient (NAG), comparing and\nevaluating their performance on Apple Inc's closing price data over the last\ndecade. The GRU model optimized with Adam produced the lowest RMSE,\noutperforming the other model-optimizer combinations in both accuracy and\nconvergence speed. The GRU models with both optimizers outperformed the LSTM\nmodels, whilst the Adam optimizer outperformed the NAG optimizer for both model\narchitectures. The results suggest that GRU models optimized with Adam are\nwell-suited for practitioners in time-series prediction, more specifically\nstock price time series prediction producing accurate and computationally\nefficient models. The code for the experiments in this project can be found at\nhttps://github.com/AhmadMak/Time-Series-Optimization-Research Keywords:\nTime-series Forecasting, Neural Network, LSTM, GRU, Adam Optimizer, Nesterov\nAccelerated Gradient (NAG) Optimizer", "published": "2024-09-28 08:35:19", "link": "http://arxiv.org/abs/2410.01843v1", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from\n  Documents guided by Multi-Aspect Feedback Refinement", "abstract": "Automating the creation of scientific diagrams from academic papers can\nsignificantly streamline the development of tutorials, presentations, and\nposters, thereby saving time and accelerating the process. Current\ntext-to-image models struggle with generating accurate and visually appealing\ndiagrams from long-context inputs. We propose SciDoc2Diagram, a task that\nextracts relevant information from scientific papers and generates diagrams,\nalong with a benchmarking dataset, SciDoc2DiagramBench. We develop a multi-step\npipeline SciDoc2Diagrammer that generates diagrams based on user intentions\nusing intermediate code generation. We observed that initial diagram drafts\nwere often incomplete or unfaithful to the source, leading us to develop\nSciDoc2Diagrammer-Multi-Aspect-Feedback (MAF), a refinement strategy that\nsignificantly enhances factual correctness and visual appeal and outperforms\nexisting models on both automatic and human judgement.", "published": "2024-09-28 05:10:39", "link": "http://arxiv.org/abs/2409.19242v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Perception Compressor: A Training-Free Prompt Compression Framework in\n  Long Context Scenarios", "abstract": "Large language models (LLMs) demonstrate exceptional capabilities in various\nscenarios. However, they suffer from much redundant information and are\nsensitive to the position of key information in long context scenarios. To\naddress these challenges, we present Perception Compressor, a training-free\nprompt compression framework. It includes a perception retriever that leverages\nguiding questions and instruction to retrieve the most relevant demonstrations,\na dual-slope ratio allocator to dynamically allocate compression ratios and\nopen-book ratios, and a semi-guided iterative compression that retains key\ninformation at the token level while removing tokens that distract the LLM. We\nconduct extensive experiments on long context benchmarks, i.e.,\nNaturalQuestions, LongBench, and MuSiQue. Experiment results show that\nPerception Compressor outperforms existing methods by a large margin, achieving\nstate-of-the-art performance.", "published": "2024-09-28 07:13:33", "link": "http://arxiv.org/abs/2409.19272v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HYBRIDMIND: Meta Selection of Natural Language and Symbolic Language for\n  Enhanced LLM Reasoning", "abstract": "LLMs approach logical and mathematical reasoning through natural or symbolic\nlanguages. While natural language offers human-accessible flexibility but\nsuffers from ambiguity, symbolic reasoning provides precise, machine-executable\ninferences at the cost of strict domain constraints. We introduce HYBRIDMIND,\nan adaptive strategy that selects the optimal reasoning approach for each\nreasoning problem. Through extensive experiments, we evaluate both\nprompting-based approaches with state-of-the-art LLMs and fine-tuned\nopen-source models. We find that fine-tuning LLaMA-3.1-8B-Instruct as a\nmeta-selector outperforms GPT-4o's natural language reasoning by 4.4\\% on FOLIO\nand 1.3\\% on MATH. More notably, using GPT-3.5-turbo as a prompted\nmeta-selector yields a 10\\% improvement on FOLIO's challenging subset compared\nto GPT-4o. We will release our code and data to support future research.", "published": "2024-09-28 15:12:55", "link": "http://arxiv.org/abs/2409.19381v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Multi-Hop Question Answering via Monte-Carlo Tree Search with\n  Large Language Models", "abstract": "Recent advances in large language models (LLMs) have significantly impacted\nthe domain of multi-hop question answering (MHQA), where systems are required\nto aggregate information and infer answers from disparate pieces of text.\nHowever, the autoregressive nature of LLMs inherently poses a challenge as\nerrors may accumulate if mistakes are made in the intermediate reasoning steps.\nThis paper introduces Monte-Carlo tree search for Zero-shot multi-hop Question\nAnswering (MZQA), a framework based on Monte-Carlo tree search (MCTS) to\nidentify optimal reasoning paths in MHQA tasks, mitigating the error\npropagation from sequential reasoning processes. Unlike previous works, we\npropose a zero-shot prompting method, which relies solely on instructions\nwithout the support of hand-crafted few-shot examples that typically require\ndomain expertise. We also introduce a behavioral cloning approach (MZQA-BC)\ntrained on self-generated MCTS inference trajectories, achieving an over\n10-fold increase in reasoning speed with bare compromise in performance. The\nefficacy of our method is validated on standard benchmarks such as HotpotQA,\n2WikiMultihopQA, and MuSiQue, demonstrating that it outperforms existing\nframeworks.", "published": "2024-09-28 15:13:04", "link": "http://arxiv.org/abs/2409.19382v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Performance Evaluation of Tokenizers in Large Language Models for the\n  Assamese Language", "abstract": "Training of a tokenizer plays an important role in the performance of deep\nlearning models. This research aims to understand the performance of tokenizers\nin five state-of-the-art (SOTA) large language models (LLMs) in the Assamese\nlanguage of India. The research is important to understand the multi-lingual\nsupport for a low-resourced language such as Assamese. Our research reveals\nthat the tokenizer of SUTRA from Two AI performs the best with an average\nNormalized Sequence Length (NSL) value of 0.45, closely followed by the\ntokenizer of GPT-4o from Open AI with an average NSL value of 0.54, followed by\nGemma 2, Meta Llama 3.1, and Mistral Large Instruct 2407 with an average NSL\nvalue of 0.82, 1.4, and 1.48 respectively.", "published": "2024-09-28 04:00:29", "link": "http://arxiv.org/abs/2410.03718v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating the Impact of Text Summarization on Topic Modeling", "abstract": "Topic models are used to identify and group similar themes in a set of\ndocuments. Recent advancements in deep learning based neural topic models has\nreceived significant research interest. In this paper, an approach is proposed\nthat further enhances topic modeling performance by utilizing a pre-trained\nlarge language model (LLM) to generate summaries of documents before inputting\nthem into the topic model. Few shot prompting is used to generate summaries of\ndifferent lengths to compare their impact on topic modeling. This approach is\nparticularly effective for larger documents because it helps capture the most\nessential information while reducing noise and irrelevant details that could\nobscure the overall theme. Additionally, it is observed that datasets exhibit\nan optimal summary length that leads to improved topic modeling performance.\nThe proposed method yields better topic diversity and comparable coherence\nvalues compared to previous models.", "published": "2024-09-28 19:45:45", "link": "http://arxiv.org/abs/2410.09063v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Jointly modelling the evolution of community structure and language in\n  online extremist groups", "abstract": "Group interactions take place within a particular socio-temporal context,\nwhich should be taken into account when modelling communities. We propose a\nmethod for jointly modelling community structure and language over time, and\napply it in the context of extremist anti-women online groups (collectively\nknown as the manosphere). Our model derives temporally grounded embeddings for\nwords and users, which evolve over the training window. We show that this\napproach outperforms prior models which lacked one of these components (i.e.\nnot incorporating social structure, or using static word embeddings). Using\nthese embeddings, we investigate the evolution of users and words within these\ncommunities in three ways: (i) we model a user as a sequence of embeddings and\nforecast their affinity groups beyond the training window, (ii) we illustrate\nhow word evolution is useful in the context of temporal events, and (iii) we\ncharacterise the propensity for violent language within subgroups of the\nmanosphere.", "published": "2024-09-28 05:19:51", "link": "http://arxiv.org/abs/2409.19243v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Edit-Constrained Decoding for Sentence Simplification", "abstract": "We propose edit operation based lexically constrained decoding for sentence\nsimplification. In sentence simplification, lexical paraphrasing is one of the\nprimary procedures for rewriting complex sentences into simpler\ncorrespondences. While previous studies have confirmed the efficacy of\nlexically constrained decoding on this task, their constraints can be loose and\nmay lead to sub-optimal generation. We address this problem by designing\nconstraints that replicate the edit operations conducted in simplification and\ndefining stricter satisfaction conditions. Our experiments indicate that the\nproposed method consistently outperforms the previous studies on three English\nsimplification corpora commonly used in this task.", "published": "2024-09-28 05:39:50", "link": "http://arxiv.org/abs/2409.19247v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LISTN: Lexicon induction with socio-temporal nuance", "abstract": "In-group language is an important signifier of group dynamics. This paper\nproposes a novel method for inducing lexicons of in-group language, which\nincorporates its socio-temporal context. Existing methods for lexicon induction\ndo not capture the evolving nature of in-group language, nor the social\nstructure of the community. Using dynamic word and user embeddings trained on\nconversations from online anti-women communities, our approach outperforms\nprior methods for lexicon induction. We develop a test set for the task of\nlexicon induction and a new lexicon of manosphere language, validated by human\nexperts, which quantifies the relevance of each term to a specific\nsub-community at a given point in time. Finally, we present novel insights on\nin-group language which illustrate the utility of this approach.", "published": "2024-09-28 06:20:20", "link": "http://arxiv.org/abs/2409.19257v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Designing Domain-Specific Large Language Models: The Critical Role of\n  Fine-Tuning in Public Opinion Simulation", "abstract": "Large language models (LLMs) have transformed natural language processing,\nyet face challenges in specialized tasks such as simulating opinions on\nenvironmental policies. This paper introduces a novel fine-tuning approach that\nintegrates socio-demographic data from the UK Household Longitudinal Study,\nuniquely using profiling factors, such as age, gender, income, education, and\nregion. This method enhances the accuracy and representation of generated\nviews. By emulating diverse synthetic profiles, the fine-tuned models\nsignificantly outperform pre-trained counterparts, achieving measurable\nimprovements in capturing demographic nuances. Evaluation metrics, including\nChi-Squared, Cosine Similarity, Jaccard Index, and KL-divergence, reveal a\nstrong alignment between synthetic and real-world opinions. This work\ndemonstrates the potential of fine-tuned LLMs tailored to societal contexts to\nenable more ethical and precise policy simulations. Its broader implications\ninclude deploying LLMs in domains like healthcare and education, fostering\ninclusive and data-driven decision-making in both research and practice.", "published": "2024-09-28 10:39:23", "link": "http://arxiv.org/abs/2409.19308v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Decoding Echo Chambers: LLM-Powered Simulations Revealing Polarization\n  in Social Networks", "abstract": "The impact of social media on critical issues such as echo chambers needs to\nbe addressed, as these phenomena can have disruptive consequences for our\nsociety. Traditional research often oversimplifies emotional tendencies and\nopinion evolution into numbers and formulas, neglecting that news and\ncommunication are conveyed through text, which limits these approaches. Hence,\nin this work, we propose an LLM-based simulation for the social opinion network\nto evaluate and counter polarization phenomena. We first construct three\ntypical network structures to simulate different characteristics of social\ninteractions. Then, agents interact based on recommendation algorithms and\nupdate their strategies through reasoning and analysis. By comparing these\ninteractions with the classic Bounded Confidence Model (BCM), the Friedkin\nJohnsen (FJ) model, and using echo chamber-related indices, we demonstrate the\neffectiveness of our framework in simulating opinion dynamics and reproducing\nphenomena such as opinion polarization and echo chambers. We propose two\nmitigation methods, active and passive nudges, that can help reduce echo\nchambers, specifically within language-based simulations. We hope our work will\noffer valuable insights and guidance for social polarization mitigation.", "published": "2024-09-28 12:49:02", "link": "http://arxiv.org/abs/2409.19338v2", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Crafting Personalized Agents through Retrieval-Augmented Generation on\n  Editable Memory Graphs", "abstract": "In the age of mobile internet, user data, often referred to as memories, is\ncontinuously generated on personal devices. Effectively managing and utilizing\nthis data to deliver services to users is a compelling research topic. In this\npaper, we introduce a novel task of crafting personalized agents powered by\nlarge language models (LLMs), which utilize a user's smartphone memories to\nenhance downstream applications with advanced LLM capabilities. To achieve this\ngoal, we introduce EMG-RAG, a solution that combines Retrieval-Augmented\nGeneration (RAG) techniques with an Editable Memory Graph (EMG). This approach\nis further optimized using Reinforcement Learning to address three distinct\nchallenges: data collection, editability, and selectability. Extensive\nexperiments on a real-world dataset validate the effectiveness of EMG-RAG,\nachieving an improvement of approximately 10% over the best existing approach.\nAdditionally, the personalized agents have been transferred into a real\nsmartphone AI assistant, which leads to enhanced usability.", "published": "2024-09-28 16:22:53", "link": "http://arxiv.org/abs/2409.19401v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Scalable Fine-tuning from Multiple Data Sources: A First-Order\n  Approximation Approach", "abstract": "We study the problem of fine-tuning a language model (LM) for a target task\nby optimally using the information from $n$ auxiliary tasks. This problem has\nbroad applications in NLP, such as targeted instruction tuning and data\nselection in chain-of-thought fine-tuning. The key challenge of this problem is\nthat not all auxiliary tasks are useful to improve the performance of the\ntarget task. Thus, choosing the right subset of auxiliary tasks is crucial.\nConventional subset selection methods, such as forward and backward stepwise\nselection, are unsuitable for LM fine-tuning because they require repeated\ntraining on subsets of auxiliary tasks. This paper introduces a new algorithm\nto estimate model fine-tuning performances without repeated training. Our\nalgorithm first performs multitask training using the data of all the tasks to\nobtain a meta initialization. Then, we approximate the model fine-tuning loss\nof a subset using functional values and gradients from the meta initialization.\nEmpirically, we find that this gradient-based approximation holds with\nremarkable accuracy for twelve transformer-based LMs. Thus, we can now estimate\nfine-tuning performances on CPUs within a few seconds. Finally, we fine-tune\nthe pretrained base model for once on the selected subset of tasks. We conduct\nextensive experiments to validate this approach, delivering a speedup of\n$30\\times$ over conventional subset selection while incurring only $1\\%$ error\nof the true fine-tuning performances. In downstream evaluations involving both\ninstruction tuning and chain-of-thought fine-tuning, this loss-based selection\napproach improves over prior gradient or representation similarity-based\nmethods for subset selection by up to $3.8\\%$.", "published": "2024-09-28 21:26:50", "link": "http://arxiv.org/abs/2409.19458v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large\n  Language Models and Ensemble Learning", "abstract": "Medication Extraction and Mining play an important role in healthcare NLP\nresearch due to its practical applications in hospital settings, such as their\nmapping into standard clinical knowledge bases (SNOMED-CT, BNF, etc.). In this\nwork, we investigate state-of-the-art LLMs in text mining tasks on medications\nand their related attributes such as dosage, route, strength, and adverse\neffects. In addition, we explore different ensemble learning methods\n(\\textsc{Stack-Ensemble} and \\textsc{Voting-Ensemble}) to augment the model\nperformances from individual LLMs. Our ensemble learning result demonstrated\nbetter performances than individually fine-tuned base models BERT, RoBERTa,\nRoBERTa-L, BioBERT, BioClinicalBERT, BioMedRoBERTa, ClinicalBERT, and\nPubMedBERT across general and specific domains. Finally, we build up an entity\nlinking function to map extracted medical terminologies into the SNOMED-CT\ncodes and the British National Formulary (BNF) codes, which are further mapped\nto the Dictionary of Medicines and Devices (dm+d), and ICD. Our model's toolkit\nand desktop applications are publicly available (at\n\\url{https://github.com/HECTA-UoM/ensemble-NER}).", "published": "2024-09-28 22:06:06", "link": "http://arxiv.org/abs/2409.19467v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Overriding Safety protections of Open-source Models", "abstract": "LLMs(Large Language Models) nowadays have widespread adoption as a tool for\nsolving issues across various domain/tasks. These models since are susceptible\nto produce harmful or toxic results, inference-time adversarial attacks,\ntherefore they do undergo safety alignment training and Red teaming for putting\nin safety guardrails. For using these models, usually fine-tuning is done for\nmodel alignment on the desired tasks, which can make model more aligned but\nalso make it more susceptible to produce unsafe responses, if fine-tuned with\nharmful data.In this paper, we study how much of impact introduction of harmful\ndata in fine-tuning can make, and if it can override the safety protection of\nthose models. Conversely,it was also explored that if model is fine-tuned on\nsafety data can make the model produce more safer responses. Further we explore\nif fine-tuning the model on harmful data makes it less helpful or less\ntrustworthy because of increase in model uncertainty leading to knowledge\ndrift. Our extensive experimental results shown that Safety protection in an\nopen-source can be overridden, when fine-tuned with harmful data as observed by\nASR increasing by 35% when compared to basemodel's ASR. Also, as observed,\nfine-tuning a model with harmful data made the harmful fine-tuned model highly\nuncertain with huge knowledge drift and less truthfulness in its responses.\nFurthermore, for the safe fine-tuned model, ASR decreases by 51.68% as compared\nto the basemodel, and Safe model also shown in minor drop in uncertainty and\ntruthfulness as compared to basemodel. This paper's code is available at:\nhttps://github.com/techsachinkr/Overriding_Model_Safety_Protections", "published": "2024-09-28 22:53:27", "link": "http://arxiv.org/abs/2409.19476v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "MedCLIP-SAMv2: Towards Universal Text-Driven Medical Image Segmentation", "abstract": "Segmentation of anatomical structures and pathological regions in medical\nimages is essential for modern clinical diagnosis, disease research, and\ntreatment planning. While significant advancements have been made in deep\nlearning-based segmentation techniques, many of these methods still suffer from\nlimitations in data efficiency, generalizability, and interactivity. As a\nresult, developing precise segmentation methods that require fewer labeled\ndatasets remains a critical challenge in medical image analysis. Recently, the\nintroduction of foundation models like CLIP and Segment-Anything-Model (SAM),\nwith robust cross-domain representations, has paved the way for interactive and\nuniversal image segmentation. However, further exploration of these models for\ndata-efficient segmentation in medical imaging is still needed and highly\nrelevant. In this paper, we introduce MedCLIP-SAMv2, a novel framework that\nintegrates the CLIP and SAM models to perform segmentation on clinical scans\nusing text prompts, in both zero-shot and weakly supervised settings. Our\napproach includes fine-tuning the BiomedCLIP model with a new Decoupled Hard\nNegative Noise Contrastive Estimation (DHN-NCE) loss, and leveraging the\nMulti-modal Information Bottleneck (M2IB) to create visual prompts for\ngenerating segmentation masks from SAM in the zero-shot setting. We also\ninvestigate using zero-shot segmentation labels within a weakly supervised\nparadigm to enhance segmentation quality further. Extensive testing across four\ndiverse segmentation tasks and medical imaging modalities (breast tumor\nultrasound, brain tumor MRI, lung X-ray, and lung CT) demonstrates the high\naccuracy of our proposed framework. Our code is available at\nhttps://github.com/HealthX-Lab/MedCLIP-SAMv2.", "published": "2024-09-28 23:10:37", "link": "http://arxiv.org/abs/2409.19483v4", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "HealthQ: Unveiling Questioning Capabilities of LLM Chains in Healthcare\n  Conversations", "abstract": "Effective patient care in digital healthcare requires large language models\n(LLMs) that not only answer questions but also actively gather critical\ninformation through well-crafted inquiries. This paper introduces HealthQ, a\nnovel framework for evaluating the questioning capabilities of LLM healthcare\nchains. By implementing advanced LLM chains, including Retrieval-Augmented\nGeneration (RAG), Chain of Thought (CoT), and reflective chains, HealthQ\nassesses how effectively these chains elicit comprehensive and relevant patient\ninformation. To achieve this, we integrate an LLM judge to evaluate generated\nquestions across metrics such as specificity, relevance, and usefulness, while\naligning these evaluations with traditional Natural Language Processing (NLP)\nmetrics like ROUGE and Named Entity Recognition (NER)-based set comparisons. We\nvalidate HealthQ using two custom datasets constructed from public medical\ndatasets, ChatDoctor and MTS-Dialog, and demonstrate its robustness across\nmultiple LLM judge models, including GPT-3.5, GPT-4, and Claude. Our\ncontributions are threefold: we present the first systematic framework for\nassessing questioning capabilities in healthcare conversations, establish a\nmodel-agnostic evaluation methodology, and provide empirical evidence linking\nhigh-quality questions to improved patient information elicitation.", "published": "2024-09-28 23:59:46", "link": "http://arxiv.org/abs/2409.19487v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DENEB: A Hallucination-Robust Automatic Evaluation Metric for Image\n  Captioning", "abstract": "In this work, we address the challenge of developing automatic evaluation\nmetrics for image captioning, with a particular focus on robustness against\nhallucinations. Existing metrics are often inadequate for handling\nhallucinations, primarily due to their limited ability to compare candidate\ncaptions with multifaceted reference captions. To address this shortcoming, we\npropose DENEB, a novel supervised automatic evaluation metric specifically\nrobust against hallucinations. DENEB incorporates the Sim-Vec Transformer, a\nmechanism that processes multiple references simultaneously, thereby\nefficiently capturing the similarity between an image, a candidate caption, and\nreference captions. To train DENEB, we construct the diverse and balanced\nNebula dataset comprising 32,978 images, paired with human judgments provided\nby 805 annotators. We demonstrated that DENEB achieves state-of-the-art\nperformance among existing LLM-free metrics on the FOIL, Composite,\nFlickr8K-Expert, Flickr8K-CF, Nebula, and PASCAL-50S datasets, validating its\neffectiveness and robustness against hallucinations.", "published": "2024-09-28 06:04:56", "link": "http://arxiv.org/abs/2409.19255v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Visual Question Decomposition on Multimodal Large Language Models", "abstract": "Question decomposition has emerged as an effective strategy for prompting\nLarge Language Models (LLMs) to answer complex questions. However, while\nexisting methods primarily focus on unimodal language models, the question\ndecomposition capability of Multimodal Large Language Models (MLLMs) has yet to\nbe explored. To this end, this paper explores visual question decomposition on\nMLLMs. Specifically, we introduce a systematic evaluation framework including a\ndataset and several evaluation criteria to assess the quality of the decomposed\nsub-questions, revealing that existing MLLMs struggle to produce high-quality\nsub-questions. To address this limitation, we propose a specific finetuning\ndataset, DecoVQA+, for enhancing the model's question decomposition capability.\nAiming at enabling models to perform appropriate selective decomposition, we\npropose an efficient finetuning pipeline. The finetuning pipeline consists of\nour proposed dataset and a training objective for selective decomposition.\nFinetuned MLLMs demonstrate significant improvements in the quality of\nsub-questions and the policy of selective question decomposition. Additionally,\nthe models also achieve higher accuracy with selective decomposition on VQA\nbenchmark datasets.", "published": "2024-09-28 12:49:16", "link": "http://arxiv.org/abs/2409.19339v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "'Simulacrum of Stories': Examining Large Language Models as Qualitative\n  Research Participants", "abstract": "The recent excitement around generative models has sparked a wave of\nproposals suggesting the replacement of human participation and labor in\nresearch and development--e.g., through surveys, experiments, and\ninterviews--with synthetic research data generated by large language models\n(LLMs). We conducted interviews with 19 qualitative researchers to understand\ntheir perspectives on this paradigm shift. Initially skeptical, researchers\nwere surprised to see similar narratives emerge in the LLM-generated data when\nusing the interview probe. However, over several conversational turns, they\nwent on to identify fundamental limitations, such as how LLMs foreclose\nparticipants' consent and agency, produce responses lacking in palpability and\ncontextual depth, and risk delegitimizing qualitative research methods. We\nargue that the use of LLMs as proxies for participants enacts the surrogate\neffect, raising ethical and epistemological concerns that extend beyond the\ntechnical limitations of current models to the core of whether LLMs fit within\nqualitative ways of knowing.", "published": "2024-09-28 18:28:47", "link": "http://arxiv.org/abs/2409.19430v1", "categories": ["cs.HC", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "SELP: Generating Safe and Efficient Task Plans for Robot Agents with\n  Large Language Models", "abstract": "Despite significant advancements in large language models (LLMs) that enhance\nrobot agents' understanding and execution of natural language (NL) commands,\nensuring the agents adhere to user-specified constraints remains challenging,\nparticularly for complex commands and long-horizon tasks. To address this\nchallenge, we present three key insights, equivalence voting, constrained\ndecoding, and domain-specific fine-tuning, which significantly enhance LLM\nplanners' capability in handling complex tasks. Equivalence voting ensures\nconsistency by generating and sampling multiple Linear Temporal Logic (LTL)\nformulas from NL commands, grouping equivalent LTL formulas, and selecting the\nmajority group of formulas as the final LTL formula. Constrained decoding then\nuses the generated LTL formula to enforce the autoregressive inference of\nplans, ensuring the generated plans conform to the LTL. Domain-specific\nfine-tuning customizes LLMs to produce safe and efficient plans within specific\ntask domains. Our approach, Safe Efficient LLM Planner (SELP), combines these\ninsights to create LLM planners to generate plans adhering to user commands\nwith high confidence. We demonstrate the effectiveness and generalizability of\nSELP across different robot agents and tasks, including drone navigation and\nrobot manipulation. For drone navigation tasks, SELP outperforms\nstate-of-the-art planners by 10.8% in safety rate (i.e., finishing tasks\nconforming to NL commands) and by 19.8% in plan efficiency. For robot\nmanipulation tasks, SELP achieves 20.4% improvement in safety rate. Our\ndatasets for evaluating NL-to-LTL and robot task planning will be released in\ngithub.com/lt-asset/selp.", "published": "2024-09-28 22:33:44", "link": "http://arxiv.org/abs/2409.19471v2", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.FL"], "primary_category": "cs.RO"}
{"title": "FluentEditor2: Text-based Speech Editing by Modeling Multi-Scale\n  Acoustic and Prosody Consistency", "abstract": "Text-based speech editing (TSE) allows users to edit speech by modifying the\ncorresponding text directly without altering the original recording. Current\nTSE techniques often focus on minimizing discrepancies between generated speech\nand reference within edited regions during training to achieve fluent TSE\nperformance. However, the generated speech in the edited region should maintain\nacoustic and prosodic consistency with the unedited region and the original\nspeech at both the local and global levels. To maintain speech fluency, we\npropose a new fluency speech editing scheme based on our previous\n\\textit{FluentEditor} model, termed \\textit{\\textbf{FluentEditor2}}, by\nmodeling the multi-scale acoustic and prosody consistency training criterion in\nTSE training. Specifically, for local acoustic consistency, we propose\n\\textit{hierarchical local acoustic smoothness constraint} to align the\nacoustic properties of speech frames, phonemes, and words at the boundary\nbetween the generated speech in the edited region and the speech in the\nunedited region. For global prosody consistency, we propose \\textit{contrastive\nglobal prosody consistency constraint} to keep the speech in the edited region\nconsistent with the prosody of the original utterance. Extensive experiments on\nthe VCTK and LibriTTS datasets show that \\textit{FluentEditor2} surpasses\nexisting neural networks-based TSE methods, including Editspeech, Campnet,\nA$^3$T, FluentSpeech, and our Fluenteditor, in both subjective and objective.\nAblation studies further highlight the contributions of each module to the\noverall effectiveness of the system. Speech demos are available at:\n\\url{https://github.com/Ai-S2-Lab/FluentEditor2}.", "published": "2024-09-28 10:18:35", "link": "http://arxiv.org/abs/2410.03719v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Thematic Analysis with Open-Source Generative AI and Machine Learning: A\n  New Method for Inductive Qualitative Codebook Development", "abstract": "This paper aims to answer one central question: to what extent can\nopen-source generative text models be used in a workflow to approximate\nthematic analysis in social science research? To answer this question, we\npresent the Generative AI-enabled Theme Organization and Structuring (GATOS)\nworkflow, which uses open-source machine learning techniques, natural language\nprocessing tools, and generative text models to facilitate thematic analysis.\nTo establish validity of the method, we present three case studies applying the\nGATOS workflow, leveraging these models and techniques to inductively create\ncodebooks similar to traditional procedures using thematic analysis.\nSpecifically, we investigate the extent to which a workflow comprising\nopen-source models and tools can inductively produce codebooks that approach\nthe known space of themes and sub-themes. To address the challenge of gleaning\ninsights from these texts, we combine open-source generative text models,\nretrieval-augmented generation, and prompt engineering to identify codes and\nthemes in large volumes of text, i.e., generate a qualitative codebook. The\nprocess mimics an inductive coding process that researchers might use in\ntraditional thematic analysis by reading text one unit of analysis at a time,\nconsidering existing codes already in the codebook, and then deciding whether\nor not to generate a new code based on whether the extant codebook provides\nadequate thematic coverage. We demonstrate this workflow using three synthetic\ndatasets from hypothetical organizational research settings: a study of\nteammate feedback in teamwork settings, a study of organizational cultures of\nethical behavior, and a study of employee perspectives about returning to their\noffices after the pandemic. We show that the GATOS workflow is able to identify\nthemes in the text that were used to generate the original synthetic datasets.", "published": "2024-09-28 18:52:16", "link": "http://arxiv.org/abs/2410.03721v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Test Case-Informed Knowledge Tracing for Open-ended Coding Tasks", "abstract": "Open-ended coding tasks, which ask students to construct programs according\nto certain specifications, are common in computer science education. Student\nmodeling can be challenging since their open-ended nature means that student\ncode can be diverse. Traditional knowledge tracing (KT) models that only\nanalyze response correctness may not fully capture nuances in student knowledge\nfrom student code. In this paper, we introduce Test case-Informed Knowledge\nTracing for Open-ended Coding (TIKTOC), a framework to simultaneously analyze\nand predict both open-ended student code and whether the code passes each test\ncase. We augment the existing CodeWorkout dataset with the test cases used for\na subset of the open-ended coding questions, and propose a multi-task learning\nKT method to simultaneously analyze and predict 1) whether a student's code\nsubmission passes each test case and 2) the student's open-ended code, using a\nlarge language model as the backbone. We quantitatively show that these methods\noutperform existing KT methods for coding that only use the overall score a\ncode submission receives. We also qualitatively demonstrate how test case\ninformation, combined with open-ended code, helps us gain fine-grained insights\ninto student knowledge.", "published": "2024-09-28 03:13:40", "link": "http://arxiv.org/abs/2410.10829v3", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "DOTA: Distributional Test-Time Adaptation of Vision-Language Models", "abstract": "Vision-language foundation models (e.g., CLIP) have shown remarkable\nperformance across a wide range of tasks. However, deploying these models may\nbe unreliable when significant distribution gaps exist between the training and\ntest data. The training-free test-time dynamic adapter (TDA) is a promising\napproach to address this issue by storing representative test samples to guide\nthe classification of subsequent ones. However, TDA only naively maintains a\nlimited number of reference samples in the cache, leading to severe test-time\ncatastrophic forgetting when the cache is updated by dropping samples. In this\npaper, we propose a simple yet effective method for DistributiOnal Test-time\nAdaptation (Dota). Instead of naively memorizing representative test samples,\nDota continually estimates the distributions of test samples, allowing the\nmodel to continually adapt to the deployment environment. The test-time\nposterior probabilities are then computed using the estimated distributions\nbased on Bayes' theorem for adaptation purposes. To further enhance the\nadaptability on the uncertain samples, we introduce a new human-in-the-loop\nparadigm which identifies uncertain samples, collects human-feedback, and\nincorporates it into the Dota framework. Extensive experiments validate that\nDota enables CLIP to continually learn, resulting in a significant improvement\ncompared to current state-of-the-art methods.", "published": "2024-09-28 15:03:28", "link": "http://arxiv.org/abs/2409.19375v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.LG"}
{"title": "A Generalized Model for Multidimensional Intransitivity", "abstract": "Intransitivity is a critical issue in pairwise preference modeling. It refers\nto the intransitive pairwise preferences between a group of players or objects\nthat potentially form a cyclic preference chain and has been long discussed in\nsocial choice theory in the context of the dominance relationship. However,\nsuch multifaceted intransitivity between players and the corresponding player\nrepresentations in high dimensions is difficult to capture. In this paper, we\npropose a probabilistic model that jointly learns each player's d-dimensional\nrepresentation (d>1) and a dataset-specific metric space that systematically\ncaptures the distance metric in Rd over the embedding space. Interestingly, by\nimposing additional constraints in the metric space, our proposed model\ndegenerates to former models used in intransitive representation learning.\nMoreover, we present an extensive quantitative investigation of the vast\nexistence of intransitive relationships between objects in various real-world\nbenchmark datasets. To our knowledge, this investigation is the first of this\ntype. The predictive performance of our proposed method on different real-world\ndatasets, including social choice, election, and online game datasets, shows\nthat our proposed method outperforms several competing methods in terms of\nprediction accuracy.", "published": "2024-09-28 11:48:34", "link": "http://arxiv.org/abs/2409.19325v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.GT", "econ.GN", "q-fin.EC"], "primary_category": "cs.LG"}
{"title": "Analyzing and Mitigating Inconsistency in Discrete Audio Tokens for\n  Neural Codec Language Models", "abstract": "Building upon advancements in Large Language Models (LLMs), the field of\naudio processing has seen increased interest in training audio generation tasks\nwith discrete audio token sequences. However, directly discretizing audio by\nneural audio codecs often results in sequences that fundamentally differ from\ntext sequences. Unlike text, where text token sequences are deterministic,\ndiscrete audio tokens can exhibit significant variability based on contextual\nfactors, while still producing perceptually identical audio segments. We refer\nto this phenomenon as \\textbf{Discrete Representation Inconsistency (DRI)}.\nThis inconsistency can lead to a single audio segment being represented by\nmultiple divergent sequences, which creates confusion in neural codec language\nmodels and results in omissions and repetitions during speech generation. In\nthis paper, we quantitatively analyze the DRI phenomenon within popular audio\ntokenizers such as EnCodec. Our approach effectively mitigates the DRI\nphenomenon of the neural audio codec. Furthermore, extensive experiments on the\nneural codec language model over LibriTTS and large-scale MLS datases (44,000\nhours) demonstrate the effectiveness and generality of our method. The demo of\naudio samples is available\nonline~\\footnote{\\url{https://consistencyinneuralcodec.github.io}}.", "published": "2024-09-28 08:36:44", "link": "http://arxiv.org/abs/2409.19283v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "OpenSep: Leveraging Large Language Models with Textual Inversion for\n  Open World Audio Separation", "abstract": "Audio separation in real-world scenarios, where mixtures contain a variable\nnumber of sources, presents significant challenges due to limitations of\nexisting models, such as over-separation, under-separation, and dependence on\npredefined training sources. We propose OpenSep, a novel framework that\nleverages large language models (LLMs) for automated audio separation,\neliminating the need for manual intervention and overcoming source limitations.\nOpenSep uses textual inversion to generate captions from audio mixtures with\noff-the-shelf audio captioning models, effectively parsing the sound sources\npresent. It then employs few-shot LLM prompting to extract detailed audio\nproperties of each parsed source, facilitating separation in unseen mixtures.\nAdditionally, we introduce a multi-level extension of the mix-and-separate\ntraining framework to enhance modality alignment by separating single source\nsounds and mixtures simultaneously. Extensive experiments demonstrate OpenSep's\nsuperiority in precisely separating new, unseen, and variable sources in\nchallenging mixtures, outperforming SOTA baseline methods. Code is released at\nhttps://github.com/tanvir-utexas/OpenSep.git", "published": "2024-09-28 06:59:52", "link": "http://arxiv.org/abs/2409.19270v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sustaining model performance for covid-19 detection from dynamic audio\n  data: Development and evaluation of a comprehensive drift-adaptive framework", "abstract": "Background: The COVID-19 pandemic has highlighted the need for robust\ndiagnostic tools capable of detecting the disease from diverse and evolving\ndata sources. Machine learning models, especially convolutional neural networks\n(CNNs), have shown promise. However, the dynamic nature of real-world data can\nlead to model drift, where performance degrades over time as the underlying\ndata distribution changes. Addressing this challenge is crucial to maintaining\naccuracy and reliability in diagnostic applications.\n  Objective: This study aims to develop a framework that monitors model drift\nand employs adaptation mechanisms to mitigate performance fluctuations in\nCOVID-19 detection models trained on dynamic audio data.\n  Methods: Two crowd-sourced COVID-19 audio datasets, COVID-19 Sounds and\nCOSWARA, were used. Each was divided into development and post-development\nperiods. A baseline CNN model was trained and evaluated using cough recordings\nfrom the development period. Maximum mean discrepancy (MMD) was used to detect\nchanges in data distributions and model performance between periods. Upon\ndetecting drift, retraining was triggered to update the baseline model. Two\nadaptation approaches were compared: unsupervised domain adaptation (UDA) and\nactive learning (AL).\n  Results: UDA improved balanced accuracy by up to 22% and 24% for the COVID-19\nSounds and COSWARA datasets, respectively. AL yielded even greater\nimprovements, with increases of up to 30% and 60%, respectively.\n  Conclusions: The proposed framework addresses model drift in COVID-19\ndetection, enabling continuous adaptation to evolving data. This approach\nensures sustained model performance, contributing to robust diagnostic tools\nfor COVID-19 and potentially other infectious diseases.", "published": "2024-09-28 10:06:30", "link": "http://arxiv.org/abs/2409.19300v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Advanced Clustering Techniques for Speech Signal Enhancement: A Review\n  and Metanalysis of Fuzzy C-Means, K-Means, and Kernel Fuzzy C-Means Methods", "abstract": "Speech signal processing is a cornerstone of modern communication\ntechnologies, tasked with improving the clarity and comprehensibility of audio\ndata in noisy environments. The primary challenge in this field is the\neffective separation and recognition of speech from background noise, crucial\nfor applications ranging from voice-activated assistants to automated\ntranscription services. The quality of speech recognition directly impacts user\nexperience and accessibility in technology-driven communication. This review\npaper explores advanced clustering techniques, particularly focusing on the\nKernel Fuzzy C-Means (KFCM) method, to address these challenges. Our findings\nindicate that KFCM, compared to traditional methods like K-Means (KM) and Fuzzy\nC-Means (FCM), provides superior performance in handling non-linear and\nnon-stationary noise conditions in speech signals. The most notable outcome of\nthis review is the adaptability of KFCM to various noisy environments, making\nit a robust choice for speech enhancement applications. Additionally, the paper\nidentifies gaps in current methodologies, such as the need for more dynamic\nclustering algorithms that can adapt in real time to changing noise conditions\nwithout compromising speech recognition quality. Key contributions include a\ndetailed comparative analysis of current clustering algorithms and suggestions\nfor further integrating hybrid models that combine KFCM with neural networks to\nenhance speech recognition accuracy. Through this review, we advocate for a\nshift towards more sophisticated, adaptive clustering techniques that can\nsignificantly improve speech enhancement and pave the way for more resilient\nspeech processing systems.", "published": "2024-09-28 20:21:05", "link": "http://arxiv.org/abs/2409.19448v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
