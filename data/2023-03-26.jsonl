{"title": "Natural Language Reasoning, A Survey", "abstract": "This survey paper proposes a clearer view of natural language reasoning in\nthe field of Natural Language Processing (NLP), both conceptually and\npractically. Conceptually, we provide a distinct definition for natural\nlanguage reasoning in NLP, based on both philosophy and NLP scenarios, discuss\nwhat types of tasks require reasoning, and introduce a taxonomy of reasoning.\nPractically, we conduct a comprehensive literature review on natural language\nreasoning in NLP, mainly covering classical logical reasoning, natural language\ninference, multi-hop question answering, and commonsense reasoning. The paper\nalso identifies and views backward reasoning, a powerful paradigm for\nmulti-step reasoning, and introduces defeasible reasoning as one of the most\nimportant future directions in natural language reasoning research. We focus on\nsingle-modality unstructured natural language text, excluding neuro-symbolic\ntechniques and mathematical reasoning.", "published": "2023-03-26 13:44:18", "link": "http://arxiv.org/abs/2303.14725v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring the Impact of Instruction Data Scaling on Large Language\n  Models: An Empirical Study on Real-World Use Cases", "abstract": "The success of ChatGPT has recently attracted numerous efforts to replicate\nit, with instruction-tuning strategies being a key factor in achieving\nremarkable results. Instruction-tuning not only significantly enhances the\nmodel's performance and generalization but also makes the model's generated\nresults more consistent with human speech patterns. However current research\nrarely studies the impact of different amounts of instruction data on model\nperformance, especially in the real-world use cases. In this paper we explore\nthe performance of large language models based on instruction tuning across\ndifferent scales of instruction data. An evaluation dataset consisting of 12\nmajor online use cases is constructed in the experiment. With Bloomz-7B1-mt as\nthe base model, the results show that 1) merely increasing the amount of\ninstruction data leads to continuous improvement in tasks such as open-ended\ngeneration, 2) in tasks such as math and code, the model performance curve\nremains quite flat while increasing data size. We further analyze the possible\ncauses of these phenomena and propose potential future research directions such\nas effectively selecting high-quality training data, scaling base models and\ntraining methods specialized for hard tasks. We will release our training and\nevaluation datasets, as well as model checkpoints.", "published": "2023-03-26 14:49:37", "link": "http://arxiv.org/abs/2303.14742v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Boosting Few-Shot Text Classification via Distribution Estimation", "abstract": "Distribution estimation has been demonstrated as one of the most effective\napproaches in dealing with few-shot image classification, as the low-level\npatterns and underlying representations can be easily transferred across\ndifferent tasks in computer vision domain. However, directly applying this\napproach to few-shot text classification is challenging, since leveraging the\nstatistics of known classes with sufficient samples to calibrate the\ndistributions of novel classes may cause negative effects due to serious\ncategory difference in text domain. To alleviate this issue, we propose two\nsimple yet effective strategies to estimate the distributions of the novel\nclasses by utilizing unlabeled query samples, thus avoiding the potential\nnegative transfer issue. Specifically, we first assume a class or sample\nfollows the Gaussian distribution, and use the original support set and the\nnearest few query samples to estimate the corresponding mean and covariance.\nThen, we augment the labeled samples by sampling from the estimated\ndistribution, which can provide sufficient supervision for training the\nclassification model. Extensive experiments on eight few-shot text\nclassification datasets show that the proposed method outperforms\nstate-of-the-art baselines significantly.", "published": "2023-03-26 05:58:39", "link": "http://arxiv.org/abs/2303.16764v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SASS: Data and Methods for Subject Aware Sentence Simplification", "abstract": "Sentence simplification tends to focus on the generic simplification of\nsentences by making them more readable and easier to understand. This paper\nprovides a dataset aimed at training models that perform subject aware sentence\nsimplifications rather than simplifying sentences as a whole. We also test\nmodels on that dataset which are inspired by model architecture used in\nabstractive summarization. We hand generated portions of the data and augment\nthe dataset by further manipulating those hand written simplifications. Our\nresults show that data-augmentation, data-masking, and model architecture\nchoices used in summarization provide a solid baseline for comparison on\nsubject aware simplification.", "published": "2023-03-26 00:02:25", "link": "http://arxiv.org/abs/2303.14589v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Farspredict: A benchmark dataset for link prediction", "abstract": "Link prediction with knowledge graph embedding (KGE) is a popular method for\nknowledge graph completion. Furthermore, training KGEs on non-English knowledge\ngraph promote knowledge extraction and knowledge graph reasoning in the context\nof these languages. However, many challenges in non-English KGEs pose to\nlearning a low-dimensional representation of a knowledge graph's entities and\nrelations. This paper proposes \"Farspredict\" a Persian knowledge graph based on\nFarsbase (the most comprehensive knowledge graph in Persian). It also explains\nhow the knowledge graph structure affects link prediction accuracy in KGE. To\nevaluate Farspredict, we implemented the popular models of KGE on it and\ncompared the results with Freebase. Given the analysis results, some\noptimizations on the knowledge graph are carried out to improve its\nfunctionality in the KGE. As a result, a new Persian knowledge graph is\nachieved. Implementation results in the KGE models on Farspredict outperforming\nFreebases in many cases. At last, we discuss what improvements could be\neffective in enhancing the quality of Farspredict and how much it improves.", "published": "2023-03-26 07:41:26", "link": "http://arxiv.org/abs/2303.14647v1", "categories": ["cs.AI", "cs.CL", "00Axx", "E.1; H.3"], "primary_category": "cs.AI"}
{"title": "Task-oriented Memory-efficient Pruning-Adapter", "abstract": "The Outstanding performance and growing size of Large Language Models has led\nto increased attention in parameter efficient learning. The two predominant\napproaches are Adapters and Pruning. Adapters are to freeze the model and give\nit a new weight matrix on the side, which can significantly reduce the time and\nmemory of training, but the cost is that the evaluation and testing will\nincrease the time and memory consumption. Pruning is to cut off some weight and\nre-distribute the remaining weight, which sacrifices the complexity of training\nat the cost of extremely high memory and training time, making the cost of\nevaluation and testing relatively low. So efficiency of training and inference\ncan't be obtained in the same time. In this work, we propose a task-oriented\nPruning-Adapter method that achieve a high memory efficiency of training and\nmemory, and speeds up training time and ensures no significant decrease in\naccuracy in GLUE tasks, achieving training and inference efficiency at the same\ntime.", "published": "2023-03-26 12:18:00", "link": "http://arxiv.org/abs/2303.14704v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Koala: An Index for Quantifying Overlaps with Pre-training Corpora", "abstract": "In very recent years more attention has been placed on probing the role of\npre-training data in Large Language Models (LLMs) downstream behaviour. Despite\nthe importance, there is no public tool that supports such analysis of\npre-training corpora at large scale. To help research in this space, we launch\nKoala, a searchable index over large pre-training corpora using compressed\nsuffix arrays with highly efficient compression rate and search support. In its\nfirst release we index the public proportion of OPT 175B pre-training data.\nKoala provides a framework to do forensic analysis on the current and future\nbenchmarks as well as to assess the degree of memorization in the output from\nthe LLMs. Koala is available for public use at\nhttps://koala-index.erc.monash.edu/.", "published": "2023-03-26 16:29:18", "link": "http://arxiv.org/abs/2303.14770v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GOAL: A Challenging Knowledge-grounded Video Captioning Benchmark for\n  Real-time Soccer Commentary Generation", "abstract": "Despite the recent emergence of video captioning models, how to generate\nvivid, fine-grained video descriptions based on the background knowledge (i.e.,\nlong and informative commentary about the domain-specific scenes with\nappropriate reasoning) is still far from being solved, which however has great\napplications such as automatic sports narrative. In this paper, we present\nGOAL, a benchmark of over 8.9k soccer video clips, 22k sentences, and 42k\nknowledge triples for proposing a challenging new task setting as\nKnowledge-grounded Video Captioning (KGVC). Moreover, we conduct experimental\nadaption of existing methods to show the difficulty and potential directions\nfor solving this valuable and applicable task. Our data and code are available\nat https://github.com/THU-KEG/goal.", "published": "2023-03-26 08:43:36", "link": "http://arxiv.org/abs/2303.14655v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "WinCLIP: Zero-/Few-Shot Anomaly Classification and Segmentation", "abstract": "Visual anomaly classification and segmentation are vital for automating\nindustrial quality inspection. The focus of prior research in the field has\nbeen on training custom models for each quality inspection task, which requires\ntask-specific images and annotation. In this paper we move away from this\nregime, addressing zero-shot and few-normal-shot anomaly classification and\nsegmentation. Recently CLIP, a vision-language model, has shown revolutionary\ngenerality with competitive zero-/few-shot performance in comparison to\nfull-supervision. But CLIP falls short on anomaly classification and\nsegmentation tasks. Hence, we propose window-based CLIP (WinCLIP) with (1) a\ncompositional ensemble on state words and prompt templates and (2) efficient\nextraction and aggregation of window/patch/image-level features aligned with\ntext. We also propose its few-normal-shot extension WinCLIP+, which uses\ncomplementary information from normal images. In MVTec-AD (and VisA), without\nfurther tuning, WinCLIP achieves 91.8%/85.1% (78.1%/79.6%) AUROC in zero-shot\nanomaly classification and segmentation while WinCLIP+ does 93.1%/95.2%\n(83.8%/96.4%) in 1-normal-shot, surpassing state-of-the-art by large margins.", "published": "2023-03-26 20:41:21", "link": "http://arxiv.org/abs/2303.14814v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Time-domain Speech Enhancement Assisted by Multi-resolution Frequency\n  Encoder and Decoder", "abstract": "Time-domain speech enhancement (SE) has recently been intensively\ninvestigated. Among recent works, DEMUCS introduces multi-resolution STFT loss\nto enhance performance. However, some resolutions used for STFT contain\nnon-stationary signals, and it is challenging to learn multi-resolution\nfrequency losses simultaneously with only one output. For better use of\nmulti-resolution frequency information, we supplement multiple spectrograms in\ndifferent frame lengths into the time-domain encoders. They extract stationary\nfrequency information in both narrowband and wideband. We also adopt multiple\ndecoder outputs, each of which computes its corresponding resolution frequency\nloss. Experimental results show that (1) it is more effective to fuse\nstationary frequency features than non-stationary features in the encoder, and\n(2) the multiple outputs consistent with the frequency loss improve\nperformance. Experiments on the Voice-Bank dataset show that the proposed\nmethod obtained a 0.14 PESQ improvement.", "published": "2023-03-26 00:30:06", "link": "http://arxiv.org/abs/2303.14593v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
