{"title": "SetKE: Knowledge Editing for Knowledge Elements Overlap", "abstract": "Large Language Models (LLMs) excel in tasks such as retrieval and question\nanswering but require updates to incorporate new knowledge and reduce\ninaccuracies and hallucinations. Traditional updating methods, like fine-tuning\nand incremental learning, face challenges such as overfitting and high\ncomputational costs. Knowledge Editing (KE) provides a promising alternative\nbut often overlooks the Knowledge Element Overlap (KEO) phenomenon, where\nmultiple triplets share common elements, leading to editing conflicts. We\nidentify the prevalence of KEO in existing KE datasets and show its significant\nimpact on current KE methods, causing performance degradation in handling such\ntriplets. To address this, we propose a new formulation, Knowledge Set Editing\n(KSE), and introduce SetKE, a method that edits sets of triplets\nsimultaneously. Experimental results demonstrate that SetKE outperforms\nexisting methods in KEO scenarios on mainstream LLMs. Additionally, we\nintroduce EditSet, a dataset containing KEO triplets, providing a comprehensive\nbenchmark.", "published": "2025-04-29 17:40:29", "link": "http://arxiv.org/abs/2504.20972v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OSVBench: Benchmarking LLMs on Specification Generation Tasks for Operating System Verification", "abstract": "We introduce OSVBench, a new benchmark for evaluating Large Language Models\n(LLMs) in generating complete specification code pertaining to operating system\nkernel verification tasks. The benchmark first defines the specification\ngeneration problem into a program synthesis problem within a confined scope of\nsyntax and semantics by providing LLMs with the programming model. The LLMs are\nrequired to understand the provided verification assumption and the potential\nsyntax and semantics space to search for, then generate the complete\nspecification for the potentially buggy operating system code implementation\nunder the guidance of the high-level functional description of the operating\nsystem. This benchmark is built upon a real-world operating system kernel,\nHyperkernel, and consists of 245 complex specification generation tasks in\ntotal, each is a long context task of about 20k-30k tokens. Our comprehensive\nevaluation of 12 LLMs exhibits the limited performance of the current LLMs on\nthe specification generation tasks for operating system verification.\nSignificant disparities in their performance on the benchmark highlight\ndifferences in their ability to handle long-context code generation tasks. The\nevaluation toolkit and benchmark are available at\nhttps://github.com/lishangyu-hkust/OSVBench.", "published": "2025-04-29 17:34:49", "link": "http://arxiv.org/abs/2504.20964v1", "categories": ["cs.CL", "cs.AI", "cs.OS", "cs.PL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Information Gravity: A Field-Theoretic Model for Token Selection in Large Language Models", "abstract": "We propose a theoretical model called \"information gravity\" to describe the\ntext generation process in large language models (LLMs). The model uses\nphysical apparatus from field theory and spacetime geometry to formalize the\ninteraction between user queries and the probability distribution of generated\ntokens. A query is viewed as an object with \"information mass\" that curves the\nsemantic space of the model, creating gravitational potential wells that\n\"attract\" tokens during generation. This model offers a mechanism to explain\nseveral observed phenomena in LLM behavior, including hallucinations (emerging\nfrom low-density semantic voids), sensitivity to query formulation (due to\nsemantic field curvature changes), and the influence of sampling temperature on\noutput diversity.", "published": "2025-04-29 17:21:20", "link": "http://arxiv.org/abs/2504.20951v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Trace-of-Thought: Enhanced Arithmetic Problem Solving via Reasoning Distillation From Large to Small Language Models", "abstract": "As Large Language Models (LLMs) continue to be leveraged for daily tasks,\nprompt engineering remains an active field of contribution within computational\nlinguistics, particularly in domains requiring specialized knowledge such as\narithmetic reasoning. While these LLMs are optimized for a variety of tasks,\ntheir exhaustive employment may become computationally or financially\ncumbersome for small teams. Additionally, complete reliance on proprietary,\nclosed-source models often limits customization and adaptability, posing\nsignificant challenges in research and application scalability. Instead, by\nleveraging open-source models at or below 7 billion parameters, we can optimize\nour resource usage while still observing remarkable gains over standard\nprompting approaches. To cultivate this notion, we introduce Trace-of-Thought\nPrompting, a simple, zero-shot prompt engineering method that instructs LLMs to\ncreate observable subproblems using critical problem-solving, specifically\ndesigned to enhance arithmetic reasoning capabilities. When applied to\nopen-source models in tandem with GPT-4, we observe that Trace-of-Thought not\nonly allows novel insight into the problem-solving process but also introduces\nperformance gains as large as 125% on language models at or below 7 billion\nparameters. This approach underscores the potential of open-source initiatives\nin democratizing AI research and improving the accessibility of high-quality\ncomputational linguistics applications.", "published": "2025-04-29 17:14:54", "link": "http://arxiv.org/abs/2504.20946v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Understanding the Nature of Attention with Low-Rank Sparse Decomposition", "abstract": "We propose Low-Rank Sparse Attention (Lorsa), a sparse replacement model of\nTransformer attention layers to disentangle original Multi Head Self Attention\n(MHSA) into individually comprehensible components. Lorsa is designed to\naddress the challenge of attention superposition to understand\nattention-mediated interaction between features in different token positions.\nWe show that Lorsa heads find cleaner and finer-grained versions of previously\ndiscovered MHSA behaviors like induction heads, successor heads and attention\nsink behavior (i.e., heavily attending to the first token). Lorsa and Sparse\nAutoencoder (SAE) are both sparse dictionary learning methods applied to\ndifferent Transformer components, and lead to consistent findings in many ways.\nFor instance, we discover a comprehensive family of arithmetic-specific Lorsa\nheads, each corresponding to an atomic operation in Llama-3.1-8B. Automated\ninterpretability analysis indicates that Lorsa achieves parity with SAE in\ninterpretability while Lorsa exhibits superior circuit discovery properties,\nespecially for features computed collectively by multiple MHSA heads. We also\nconduct extensive experiments on architectural design ablation, Lorsa scaling\nlaw and error analysis.", "published": "2025-04-29 17:03:03", "link": "http://arxiv.org/abs/2504.20938v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification", "abstract": "Recent advances in reasoning-enhanced large language models (LLMs) and\nmultimodal LLMs (MLLMs) have significantly improved performance in complex\ntasks, yet medical AI models often overlook the structured reasoning processes\ninherent in clinical practice. In this work, we present ChestX-Reasoner, a\nradiology diagnosis MLLM designed to leverage process supervision mined\ndirectly from clinical reports, reflecting the step-by-step reasoning followed\nby radiologists. We construct a large dataset by extracting and refining\nreasoning chains from routine radiology reports. Our two-stage training\nframework combines supervised fine-tuning and reinforcement learning guided by\nprocess rewards to better align model reasoning with clinical standards. We\nintroduce RadRBench-CXR, a comprehensive benchmark featuring 59K visual\nquestion answering samples with 301K clinically validated reasoning steps, and\npropose RadRScore, a metric evaluating reasoning factuality, completeness, and\neffectiveness. ChestX-Reasoner outperforms existing medical and general-domain\nMLLMs in both diagnostic accuracy and reasoning ability, achieving 16%, 5.9%,\nand 18% improvements in reasoning ability compared to the best medical MLLM,\nthe best general MLLM, and its base model, respectively, as well as 3.3%, 24%,\nand 27% improvements in outcome accuracy. All resources are open-sourced to\nfacilitate further research in medical reasoning MLLMs.", "published": "2025-04-29 16:48:23", "link": "http://arxiv.org/abs/2504.20930v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "DYNAMAX: Dynamic computing for Transformers and Mamba based architectures", "abstract": "Early exits (EEs) offer a promising approach to reducing computational costs\nand latency by dynamically terminating inference once a satisfactory prediction\nconfidence on a data sample is achieved. Although many works integrate EEs into\nencoder-only Transformers, their application to decoder-only architectures and,\nmore importantly, Mamba models, a novel family of state-space architectures in\nthe LLM realm, remains insufficiently explored. This work introduces DYNAMAX,\nthe first framework to exploit the unique properties of Mamba architectures for\nearly exit mechanisms. We not only integrate EEs into Mamba but also repurpose\nMamba as an efficient EE classifier for both Mamba-based and transformer-based\nLLMs, showcasing its versatility. Our experiments employ the Mistral 7B\ntransformer compared to the Codestral 7B Mamba model, using data sets such as\nTruthfulQA, CoQA, and TriviaQA to evaluate computational savings, accuracy, and\nconsistency. The results highlight the adaptability of Mamba as a powerful EE\nclassifier and its efficiency in balancing computational cost and performance\nquality across NLP tasks. By leveraging Mamba's inherent design for dynamic\nprocessing, we open pathways for scalable and efficient inference in embedded\napplications and resource-constrained environments. This study underscores the\ntransformative potential of Mamba in redefining dynamic computing paradigms for\nLLMs.", "published": "2025-04-29 16:38:15", "link": "http://arxiv.org/abs/2504.20922v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50 (Primary), 68T07 (Secondary)"], "primary_category": "cs.CL"}
{"title": "The Leaderboard Illusion", "abstract": "Measuring progress is fundamental to the advancement of any scientific field.\nAs benchmarks play an increasingly central role, they also grow more\nsusceptible to distortion. Chatbot Arena has emerged as the go-to leaderboard\nfor ranking the most capable AI systems. Yet, in this work we identify\nsystematic issues that have resulted in a distorted playing field. We find that\nundisclosed private testing practices benefit a handful of providers who are\nable to test multiple variants before public release and retract scores if\ndesired. We establish that the ability of these providers to choose the best\nscore leads to biased Arena scores due to selective disclosure of performance\nresults. At an extreme, we identify 27 private LLM variants tested by Meta in\nthe lead-up to the Llama-4 release. We also establish that proprietary closed\nmodels are sampled at higher rates (number of battles) and have fewer models\nremoved from the arena than open-weight and open-source alternatives. Both\nthese policies lead to large data access asymmetries over time. Providers like\nGoogle and OpenAI have received an estimated 19.2% and 20.4% of all data on the\narena, respectively. In contrast, a combined 83 open-weight models have only\nreceived an estimated 29.7% of the total data. We show that access to Chatbot\nArena data yields substantial benefits; even limited additional data can result\nin relative performance gains of up to 112% on the arena distribution, based on\nour conservative estimates. Together, these dynamics result in overfitting to\nArena-specific dynamics rather than general model quality. The Arena builds on\nthe substantial efforts of both the organizers and an open community that\nmaintains this valuable evaluation platform. We offer actionable\nrecommendations to reform the Chatbot Arena's evaluation framework and promote\nfairer, more transparent benchmarking for the field", "published": "2025-04-29 15:48:49", "link": "http://arxiv.org/abs/2504.20879v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ME"], "primary_category": "cs.AI"}
{"title": "X-Cross: Dynamic Integration of Language Models for Cross-Domain Sequential Recommendation", "abstract": "As new products are emerging daily, recommendation systems are required to\nquickly adapt to possible new domains without needing extensive retraining.\nThis work presents ``X-Cross'' -- a novel cross-domain\nsequential-recommendation model that recommends products in new domains by\nintegrating several domain-specific language models; each model is fine-tuned\nwith low-rank adapters (LoRA). Given a recommendation prompt, operating layer\nby layer, X-Cross dynamically refines the representation of each source\nlanguage model by integrating knowledge from all other models. These refined\nrepresentations are propagated from one layer to the next, leveraging the\nactivations from each domain adapter to ensure domain-specific nuances are\npreserved while enabling adaptability across domains. Using Amazon datasets for\nsequential recommendation, X-Cross achieves performance comparable to a model\nthat is fine-tuned with LoRA, while using only 25% of the additional\nparameters. In cross-domain tasks, such as adapting from Toys domain to Tools,\nElectronics or Sports, X-Cross demonstrates robust performance, while requiring\nabout 50%-75% less fine-tuning data than LoRA to make fine-tuning effective.\nFurthermore, X-Cross achieves significant improvement in accuracy over\nalternative cross-domain baselines. Overall, X-Cross enables scalable and\nadaptive cross-domain recommendations, reducing computational overhead and\nproviding an efficient solution for data-constrained environments.", "published": "2025-04-29 15:33:20", "link": "http://arxiv.org/abs/2504.20859v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "JaccDiv: A Metric and Benchmark for Quantifying Diversity of Generated Marketing Text in the Music Industry", "abstract": "Online platforms are increasingly interested in using Data-to-Text\ntechnologies to generate content and help their users. Unfortunately,\ntraditional generative methods often fall into repetitive patterns, resulting\nin monotonous galleries of texts after only a few iterations. In this paper, we\ninvestigate LLM-based data-to-text approaches to automatically generate\nmarketing texts that are of sufficient quality and diverse enough for broad\nadoption. We leverage Language Models such as T5, GPT-3.5, GPT-4, and LLaMa2 in\nconjunction with fine-tuning, few-shot, and zero-shot approaches to set a\nbaseline for diverse marketing texts. We also introduce a metric JaccDiv to\nevaluate the diversity of a set of texts. This research extends its relevance\nbeyond the music industry, proving beneficial in various fields where\nrepetitive automated content generation is prevalent.", "published": "2025-04-29 15:19:06", "link": "http://arxiv.org/abs/2504.20849v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Universal language model with the intervention of quantum theory", "abstract": "This paper examines language modeling based on the theory of quantum\nmechanics. It focuses on the introduction of quantum mechanics into the\nsymbol-meaning pairs of language in order to build a representation model of\nnatural language. At the same time, it is realized that word embedding, which\nis widely used as a basic technique for statistical language modeling, can be\nexplained and improved by the mathematical framework of quantum mechanics. On\nthis basis, this paper continues to try to use quantum statistics and other\nrelated theories to study the mathematical representation, natural evolution\nand statistical properties of natural language. It is also assumed that the\nsource of such quantum properties is the physicality of information. The\nfeasibility of using quantum theory to model natural language is pointed out\nthrough the construction of a experimental code. The paper discusses, in terms\nof applications, the possible help of the theory in constructing generative\nmodels that are popular nowadays. A preliminary discussion of future\napplications of the theory to quantum computers is also presented.", "published": "2025-04-29 15:02:30", "link": "http://arxiv.org/abs/2504.20839v1", "categories": ["cs.CL", "quant-ph"], "primary_category": "cs.CL"}
{"title": "Turing Machine Evaluation for Large Language Model", "abstract": "With the rapid development and widespread application of Large Language\nModels (LLMs), rigorous evaluation has become particularly crucial. This\nresearch adopts a novel perspective, focusing on evaluating the core\ncomputational reasoning ability of LLMs, defined as the capacity of model to\naccurately understand rules, and execute logically computing operations. This\ncapability assesses the reliability of LLMs as precise executors, and is\ncritical to advanced tasks such as complex code generation and multi-step\nproblem-solving. We propose an evaluation framework based on Universal Turing\nMachine (UTM) simulation. This framework requires LLMs to strictly follow\ninstructions and track dynamic states, such as tape content and read/write head\nposition, during multi-step computations. To enable standardized evaluation, we\ndeveloped TMBench, a benchmark for systematically studying the computational\nreasoning capabilities of LLMs. TMBench provides several key advantages,\nincluding knowledge-agnostic evaluation, adjustable difficulty, foundational\ncoverage through Turing machine encoding, and unlimited capacity for instance\ngeneration, ensuring scalability as models continue to evolve. We find that\nmodel performance on TMBench correlates strongly with performance on other\nrecognized reasoning benchmarks (Pearson correlation coefficient is 0.73),\nclearly demonstrating that computational reasoning is a significant dimension\nfor measuring the deep capabilities of LLMs. Code and data are available at\nhttps://github.com/HaitaoWuTJU/Turing-Machine-Bench.", "published": "2025-04-29 13:52:47", "link": "http://arxiv.org/abs/2504.20771v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption", "abstract": "Chain-of-thought prompting has demonstrated great success in facilitating the\nreasoning abilities of large language models. In this work, we explore how\nthese enhanced reasoning abilities can be exploited to improve the robustness\nof large language models in tasks that are not necessarily reasoning-focused.\nIn particular, we show how a wide range of large language models exhibit\nsignificantly improved robustness against reference corruption using a simple\nmethod called chain-of-defensive-thought, where only a few exemplars with\nstructured and defensive reasoning are provided as demonstrations. Empirically,\nthe improvements can be astounding, especially given the simplicity and\napplicability of the method. For example, in the Natural Questions task, the\naccuracy of GPT-4o degrades from 60% to as low as 3% with standard prompting\nwhen 1 out of 10 references provided is corrupted with prompt injection\nattacks. In contrast, GPT-4o using chain-of-defensive-thought prompting\nmaintains an accuracy of 50%.", "published": "2025-04-29 13:50:05", "link": "http://arxiv.org/abs/2504.20769v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers", "abstract": "Transformers have achieved great success in numerous NLP tasks but continue\nto exhibit notable gaps in multi-step factual reasoning, especially when\nreal-world knowledge is sparse. Recent advances in grokking have demonstrated\nthat neural networks can transition from memorizing to perfectly generalizing\nonce they detect underlying logical patterns - yet these studies have primarily\nused small, synthetic tasks. In this paper, for the first time, we extend\ngrokking to real-world factual data and address the challenge of dataset\nsparsity by augmenting existing knowledge graphs with carefully designed\nsynthetic data to raise the ratio $\\phi_r$ of inferred facts to atomic facts\nabove the threshold required for grokking. Surprisingly, we find that even\nfactually incorrect synthetic data can strengthen emergent reasoning circuits\nrather than degrade accuracy, as it forces the model to rely on relational\nstructure rather than memorization. When evaluated on multi-hop reasoning\nbenchmarks, our approach achieves up to 95-100% accuracy on 2WikiMultiHopQA -\nsubstantially improving over strong baselines and matching or exceeding current\nstate-of-the-art results. We further provide an in-depth analysis of how\nincreasing $\\phi_r$ drives the formation of generalizing circuits inside\nTransformers. Our findings suggest that grokking-based data augmentation can\nunlock implicit multi-hop reasoning capabilities, opening the door to more\nrobust and interpretable factual reasoning in large-scale language models.", "published": "2025-04-29 13:33:29", "link": "http://arxiv.org/abs/2504.20752v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; I.2.6; I.2.3; I.7"], "primary_category": "cs.CL"}
{"title": "UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities", "abstract": "Retrieval-Augmented Generation (RAG) has shown substantial promise in\nimproving factual accuracy by grounding model responses with external knowledge\nrelevant to queries. However, most existing RAG approaches are limited to a\ntext-only corpus, and while recent efforts have extended RAG to other\nmodalities such as images and videos, they typically operate over a single\nmodality-specific corpus. In contrast, real-world queries vary widely in the\ntype of knowledge they require, which a single type of knowledge source cannot\naddress. To address this, we introduce UniversalRAG, a novel RAG framework\ndesigned to retrieve and integrate knowledge from heterogeneous sources with\ndiverse modalities and granularities. Specifically, motivated by the\nobservation that forcing all modalities into a unified representation space\nderived from a single combined corpus causes a modality gap, where the\nretrieval tends to favor items from the same modality as the query, we propose\na modality-aware routing mechanism that dynamically identifies the most\nappropriate modality-specific corpus and performs targeted retrieval within it.\nAlso, beyond modality, we organize each modality into multiple granularity\nlevels, enabling fine-tuned retrieval tailored to the complexity and scope of\nthe query. We validate UniversalRAG on 8 benchmarks spanning multiple\nmodalities, showing its superiority over modality-specific and unified\nbaselines.", "published": "2025-04-29 13:18:58", "link": "http://arxiv.org/abs/2504.20734v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think", "abstract": "Large Language Models (LLMs) leverage step-by-step reasoning to solve complex\nproblems. Standard evaluation practice involves generating a complete reasoning\ntrace and assessing the correctness of the final answer presented at its\nconclusion. In this paper, we challenge the reliance on the final answer by\nposing the following two questions: Does the final answer reliably represent\nthe model's optimal conclusion? Can alternative reasoning paths yield different\nresults? To answer these questions, we analyze intermediate reasoning steps,\ntermed subthoughts, and propose a method based on our findings. Our approach\ninvolves segmenting a reasoning trace into sequential subthoughts based on\nlinguistic cues. We start by prompting the model to generate continuations from\nthe end-point of each intermediate subthought. We extract a potential answer\nfrom every completed continuation originating from different subthoughts. We\nfind that aggregating these answers by selecting the most frequent one (the\nmode) often yields significantly higher accuracy compared to relying solely on\nthe answer derived from the original complete trace. Analyzing the consistency\namong the answers derived from different subthoughts reveals characteristics\nthat correlate with the model's confidence and correctness, suggesting\npotential for identifying less reliable answers. Our experiments across various\nLLMs and challenging mathematical reasoning datasets (AIME2024 and AIME2025)\nshow consistent accuracy improvements, with gains reaching up to 13\\% and 10\\%\nrespectively. Implementation is available at:\nhttps://github.com/hammoudhasan/SubthoughtReasoner.", "published": "2025-04-29 12:39:07", "link": "http://arxiv.org/abs/2504.20708v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BrightCookies at SemEval-2025 Task 9: Exploring Data Augmentation for Food Hazard Classification", "abstract": "This paper presents our system developed for the SemEval-2025 Task 9: The\nFood Hazard Detection Challenge. The shared task's objective is to evaluate\nexplainable classification systems for classifying hazards and products in two\nlevels of granularity from food recall incident reports. In this work, we\npropose text augmentation techniques as a way to improve poor performance on\nminority classes and compare their effect for each category on various\ntransformer and machine learning models. We explore three word-level data\naugmentation techniques, namely synonym replacement, random word swapping, and\ncontextual word insertion. The results show that transformer models tend to\nhave a better overall performance. None of the three augmentation techniques\nconsistently improved overall performance for classifying hazards and products.\nWe observed a statistically significant improvement (P < 0.05) in the\nfine-grained categories when using the BERT model to compare the baseline with\neach augmented model. Compared to the baseline, the contextual words insertion\naugmentation improved the accuracy of predictions for the minority hazard\nclasses by 6%. This suggests that targeted augmentation of minority classes can\nimprove the performance of transformer models.", "published": "2025-04-29 12:34:28", "link": "http://arxiv.org/abs/2504.20703v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLMs Detect Intrinsic Hallucinations in Paraphrasing and Machine Translation?", "abstract": "A frequently observed problem with LLMs is their tendency to generate output\nthat is nonsensical, illogical, or factually incorrect, often referred to\nbroadly as hallucination. Building on the recently proposed HalluciGen task for\nhallucination detection and generation, we evaluate a suite of open-access LLMs\non their ability to detect intrinsic hallucinations in two conditional\ngeneration tasks: translation and paraphrasing. We study how model performance\nvaries across tasks and language and we investigate the impact of model size,\ninstruction tuning, and prompt choice. We find that performance varies across\nmodels but is consistent across prompts. Finally, we find that NLI models\nperform comparably well, suggesting that LLM-based detectors are not the only\nviable option for this specific task.", "published": "2025-04-29 12:30:05", "link": "http://arxiv.org/abs/2504.20699v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Are Information Retrieval Approaches Good at Harmonising Longitudinal Survey Questions in Social Science?", "abstract": "Automated detection of semantically equivalent questions in longitudinal\nsocial science surveys is crucial for long-term studies informing empirical\nresearch in the social, economic, and health sciences. Retrieving equivalent\nquestions faces dual challenges: inconsistent representation of theoretical\nconstructs (i.e. concept/sub-concept) across studies as well as between\nquestion and response options, and the evolution of vocabulary and structure in\nlongitudinal text. To address these challenges, our multi-disciplinary\ncollaboration of computer scientists and survey specialists presents a new\ninformation retrieval (IR) task of identifying concept (e.g. Housing, Job,\netc.) equivalence across question and response options to harmonise\nlongitudinal population studies. This paper investigates multiple unsupervised\napproaches on a survey dataset spanning 1946-2020, including probabilistic\nmodels, linear probing of language models, and pre-trained neural networks\nspecialised for IR. We show that IR-specialised neural models achieve the\nhighest overall performance with other approaches performing comparably.\nAdditionally, the re-ranking of the probabilistic model's results with neural\nmodels only introduces modest improvements of 0.07 at most in F1-score.\nQualitative post-hoc evaluation by survey specialists shows that models\ngenerally have a low sensitivity to questions with high lexical overlap,\nparticularly in cases where sub-concepts are mismatched. Altogether, our\nanalysis serves to further research on harmonising longitudinal studies in\nsocial science.", "published": "2025-04-29 12:00:33", "link": "http://arxiv.org/abs/2504.20679v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Non-native Children's Automatic Speech Assessment Challenge (NOCASA)", "abstract": "This paper presents the \"Non-native Children's Automatic Speech Assessment\"\n(NOCASA) - a data competition part of the IEEE MLSP 2025 conference. NOCASA\nchallenges participants to develop new systems that can assess single-word\npronunciations of young second language (L2) learners as part of a gamified\npronunciation training app. To achieve this, several issues must be addressed,\nmost notably the limited nature of available training data and the highly\nunbalanced distribution among the pronunciation level categories. To expedite\nthe development, we provide a pseudo-anonymized training data (TeflonNorL2),\ncontaining 10,334 recordings from 44 speakers attempting to pronounce 205\ndistinct Norwegian words, human-rated on a 1 to 5 scale (number of stars that\nshould be given in the game). In addition to the data, two already trained\nsystems are released as official baselines: an SVM classifier trained on the\nComParE_16 acoustic feature set and a multi-task wav2vec 2.0 model. The latter\nachieves the best performance on the challenge test set, with an unweighted\naverage recall (UAR) of 36.37%.", "published": "2025-04-29 11:59:08", "link": "http://arxiv.org/abs/2504.20678v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Generative-AI-Driven Claim Retrieval System Capable of Detecting and Retrieving Claims from Social Media Platforms in Multiple Languages", "abstract": "Online disinformation poses a global challenge, placing significant demands\non fact-checkers who must verify claims efficiently to prevent the spread of\nfalse information. A major issue in this process is the redundant verification\nof already fact-checked claims, which increases workload and delays responses\nto newly emerging claims. This research introduces an approach that retrieves\npreviously fact-checked claims, evaluates their relevance to a given input, and\nprovides supplementary information to support fact-checkers. Our method employs\nlarge language models (LLMs) to filter irrelevant fact-checks and generate\nconcise summaries and explanations, enabling fact-checkers to faster assess\nwhether a claim has been verified before. In addition, we evaluate our approach\nthrough both automatic and human assessments, where humans interact with the\ndeveloped tool to review its effectiveness. Our results demonstrate that LLMs\nare able to filter out many irrelevant fact-checks and, therefore, reduce\neffort and streamline the fact-checking process.", "published": "2025-04-29 11:49:05", "link": "http://arxiv.org/abs/2504.20668v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cooking Up Creativity: A Cognitively-Inspired Approach for Enhancing LLM Creativity through Structured Representations", "abstract": "Large Language Models (LLMs) excel at countless tasks, yet struggle with\ncreativity. In this paper, we introduce a novel approach that couples LLMs with\nstructured representations and cognitively inspired manipulations to generate\nmore creative and diverse ideas. Our notion of creativity goes beyond\nsuperficial token-level variations; rather, we explicitly recombine structured\nrepresentations of existing ideas, allowing our algorithm to effectively\nexplore the more abstract landscape of ideas. We demonstrate our approach in\nthe culinary domain with DishCOVER, a model that generates creative recipes.\nExperiments comparing our model's results to those of GPT-4o show greater\ndiversity. Domain expert evaluations reveal that our outputs, which are mostly\ncoherent and feasible culinary creations, significantly surpass GPT-4o in terms\nof novelty, thus outperforming it in creative generation. We hope our work\ninspires further research into structured creativity in AI.", "published": "2025-04-29 11:13:06", "link": "http://arxiv.org/abs/2504.20643v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "WenyanGPT: A Large Language Model for Classical Chinese Tasks", "abstract": "Classical Chinese, as the core carrier of Chinese culture, plays a crucial\nrole in the inheritance and study of ancient literature. However, existing\nnatural language processing models primarily optimize for Modern Chinese,\nresulting in inadequate performance on Classical Chinese. This paper presents a\ncomprehensive solution for Classical Chinese language processing. By continuing\npre-training and instruction fine-tuning on the LLaMA3-8B-Chinese model, we\nconstruct a large language model, WenyanGPT, which is specifically designed for\nClassical Chinese tasks. Additionally, we develop an evaluation benchmark\ndataset, WenyanBENCH. Experimental results on WenyanBENCH demonstrate that\nWenyanGPT significantly outperforms current advanced LLMs in various Classical\nChinese tasks. We make the model's training data, instruction fine-tuning\ndata\\footnote, and evaluation benchmark dataset publicly available to promote\nfurther research and development in the field of Classical Chinese processing.", "published": "2025-04-29 10:19:05", "link": "http://arxiv.org/abs/2504.20609v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TF1-EN-3M: Three Million Synthetic Moral Fables for Training Small, Open Language Models", "abstract": "Moral stories are a time-tested vehicle for transmitting values, yet modern\nNLP lacks a large, structured corpus that couples coherent narratives with\nexplicit ethical lessons. We close this gap with TF1-EN-3M, the first open\ndataset of three million English-language fables generated exclusively by\ninstruction-tuned models no larger than 8B parameters. Each story follows a\nsix-slot scaffold (character -> trait -> setting -> conflict -> resolution ->\nmoral), produced through a combinatorial prompt engine that guarantees genre\nfidelity while covering a broad thematic space.\n  A hybrid evaluation pipeline blends (i) a GPT-based critic that scores\ngrammar, creativity, moral clarity, and template adherence with (ii)\nreference-free diversity and readability metrics. Among ten open-weight\ncandidates, an 8B-parameter Llama-3 variant delivers the best quality-speed\ntrade-off, producing high-scoring fables on a single consumer GPU (<24 GB VRAM)\nat approximately 13.5 cents per 1,000 fables.\n  We release the dataset, generation code, evaluation scripts, and full\nmetadata under a permissive license, enabling exact reproducibility and cost\nbenchmarking. TF1-EN-3M opens avenues for research in instruction following,\nnarrative intelligence, value alignment, and child-friendly educational AI,\ndemonstrating that large-scale moral storytelling no longer requires\nproprietary giant models.", "published": "2025-04-29 10:15:28", "link": "http://arxiv.org/abs/2504.20605v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReasonIR: Training Retrievers for Reasoning Tasks", "abstract": "We present ReasonIR-8B, the first retriever specifically trained for general\nreasoning tasks. Existing retrievers have shown limited gains on reasoning\ntasks, in part because existing training datasets focus on short factual\nqueries tied to documents that straightforwardly answer them. We develop a\nsynthetic data generation pipeline that, for each document, our pipeline\ncreates a challenging and relevant query, along with a plausibly related but\nultimately unhelpful hard negative. By training on a mixture of our synthetic\ndata and existing public data, ReasonIR-8B achieves a new state-of-the-art of\n29.9 nDCG@10 without reranker and 36.9 nDCG@10 with reranker on BRIGHT, a\nwidely-used reasoning-intensive information retrieval (IR) benchmark. When\napplied to RAG tasks, ReasonIR-8B improves MMLU and GPQA performance by 6.4%\nand 22.6% respectively, relative to the closed-book baseline, outperforming\nother retrievers and search engines. In addition, ReasonIR-8B uses test-time\ncompute more effectively: on BRIGHT, its performance consistently increases\nwith longer and more information-rich rewritten queries; it continues to\noutperform other retrievers when combined with an LLM reranker. Our training\nrecipe is general and can be easily extended to future LLMs; to this end, we\nopen-source our code, data, and model.", "published": "2025-04-29 09:49:28", "link": "http://arxiv.org/abs/2504.20595v1", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "ClonEval: An Open Voice Cloning Benchmark", "abstract": "We present a novel benchmark for voice cloning text-to-speech models. The\nbenchmark consists of an evaluation protocol, an open-source library for\nassessing the performance of voice cloning models, and an accompanying\nleaderboard. The paper discusses design considerations and presents a detailed\ndescription of the evaluation procedure. The usage of the software library is\nexplained, along with the organization of results on the leaderboard.", "published": "2025-04-29 09:36:33", "link": "http://arxiv.org/abs/2504.20581v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reinforcement Learning for Reasoning in Large Language Models with One Training Example", "abstract": "We show that reinforcement learning with verifiable reward using one training\nexample (1-shot RLVR) is effective in incentivizing the math reasoning\ncapabilities of large language models (LLMs). Applying RLVR to the base model\nQwen2.5-Math-1.5B, we identify a single example that elevates model performance\non MATH500 from 36.0% to 73.6%, and improves the average performance across six\ncommon mathematical reasoning benchmarks from 17.6% to 35.7%. This result\nmatches the performance obtained using the 1.2k DeepScaleR subset (MATH500:\n73.6%, average: 35.9%), which includes the aforementioned example. Similar\nsubstantial improvements are observed across various models (Qwen2.5-Math-7B,\nLlama3.2-3B-Instruct, DeepSeek-R1-Distill-Qwen-1.5B), RL algorithms (GRPO and\nPPO), and different math examples (many of which yield approximately 30% or\ngreater improvement on MATH500 when employed as a single training example). In\naddition, we identify some interesting phenomena during 1-shot RLVR, including\ncross-domain generalization, increased frequency of self-reflection, and\nsustained test performance improvement even after the training accuracy has\nsaturated, a phenomenon we term post-saturation generalization. Moreover, we\nverify that the effectiveness of 1-shot RLVR primarily arises from the policy\ngradient loss, distinguishing it from the \"grokking\" phenomenon. We also show\nthe critical role of promoting exploration (e.g., by adding entropy loss with\nan appropriate coefficient) in 1-shot RLVR training. As a bonus, we observe\nthat applying entropy loss alone, without any outcome reward, significantly\nenhances Qwen2.5-Math-1.5B's performance on MATH500 by 27.4%. These findings\ncan inspire future work on RLVR data efficiency and encourage a re-examination\nof both recent progress and the underlying mechanisms in RLVR. Our code, model,\nand data are open source at https://github.com/ypwang61/One-Shot-RLVR", "published": "2025-04-29 09:24:30", "link": "http://arxiv.org/abs/2504.20571v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "BrAIcht, a theatrical agent that speaks like Bertolt Brecht's characters", "abstract": "This project introduces BrAIcht, an AI conversational agent that creates\ndialogues in the distinctive style of the famous German playwright Bertolt\nBrecht. BrAIcht is fine-tuned using German LeoLM, a large language model with 7\nbillion parameters and a modified version of the base Llama2 suitable for\nGerman language tasks. For fine-tuning, 29 plays of Bertolt Brecht and 907 of\nother German plays that are stylistically similar to Bertolt Brecht are used to\nform a more di-erse dataset. Due to the limited memory capacity, a\nparameterefficient fine-tuning technique called QLoRA is implemented to train\nthe large language model. The results, based on BLEU score and perplexity, show\nvery promising performance of BrAIcht in generating dialogues in the style of\nBertolt Brecht.", "published": "2025-04-29 08:55:12", "link": "http://arxiv.org/abs/2504.20552v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting the MIMIC-IV Benchmark: Experiments Using Language Models for Electronic Health Records", "abstract": "The lack of standardized evaluation benchmarks in the medical domain for text\ninputs can be a barrier to widely adopting and leveraging the potential of\nnatural language models for health-related downstream tasks. This paper\nrevisited an openly available MIMIC-IV benchmark for electronic health records\n(EHRs) to address this issue. First, we integrate the MIMIC-IV data within the\nHugging Face datasets library to allow an easy share and use of this\ncollection. Second, we investigate the application of templates to convert EHR\ntabular data to text. Experiments using fine-tuned and zero-shot LLMs on the\nmortality of patients task show that fine-tuned text-based models are\ncompetitive against robust tabular classifiers. In contrast, zero-shot LLMs\nstruggle to leverage EHR representations. This study underlines the potential\nof text-based approaches in the medical field and highlights areas for further\nimprovement.", "published": "2025-04-29 08:49:38", "link": "http://arxiv.org/abs/2504.20547v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UniDetox: Universal Detoxification of Large Language Models via Dataset Distillation", "abstract": "We present UniDetox, a universally applicable method designed to mitigate\ntoxicity across various large language models (LLMs). Previous detoxification\nmethods are typically model-specific, addressing only individual models or\nmodel families, and require careful hyperparameter tuning due to the trade-off\nbetween detoxification efficacy and language modeling performance. In contrast,\nUniDetox provides a detoxification technique that can be universally applied to\na wide range of LLMs without the need for separate model-specific tuning.\nSpecifically, we propose a novel and efficient dataset distillation technique\nfor detoxification using contrastive decoding. This approach distills\ndetoxifying representations in the form of synthetic text data, enabling\nuniversal detoxification of any LLM through fine-tuning with the distilled\ntext. Our experiments demonstrate that the detoxifying text distilled from\nGPT-2 can effectively detoxify larger models, including OPT, Falcon, and\nLLaMA-2. Furthermore, UniDetox eliminates the need for separate hyperparameter\ntuning for each model, as a single hyperparameter configuration can be\nseamlessly applied across different models. Additionally, analysis of the\ndetoxifying text reveals a reduction in politically biased content, providing\ninsights into the attributes necessary for effective detoxification of LLMs.", "published": "2025-04-29 07:40:00", "link": "http://arxiv.org/abs/2504.20500v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training", "abstract": "Large language models (LLMs) exhibit remarkable multilingual capabilities\ndespite English-dominated pre-training, attributed to cross-lingual mechanisms\nduring pre-training. Existing methods for enhancing cross-lingual transfer\nremain constrained by parallel resources, suffering from limited linguistic and\ndomain coverage. We propose Cross-lingual In-context Pre-training (CrossIC-PT),\na simple and scalable approach that enhances cross-lingual transfer by\nleveraging semantically related bilingual texts via simple next-word\nprediction. We construct CrossIC-PT samples by interleaving semantic-related\nbilingual Wikipedia documents into a single context window. To access window\nsize constraints, we implement a systematic segmentation policy to split long\nbilingual document pairs into chunks while adjusting the sliding window\nmechanism to preserve contextual coherence. We further extend data availability\nthrough a semantic retrieval framework to construct CrossIC-PT samples from\nweb-crawled corpus. Experimental results demonstrate that CrossIC-PT improves\nmultilingual performance on three models (Llama-3.1-8B, Qwen2.5-7B, and\nQwen2.5-1.5B) across six target languages, yielding performance gains of 3.79%,\n3.99%, and 1.95%, respectively, with additional improvements after data\naugmentation.", "published": "2025-04-29 07:24:25", "link": "http://arxiv.org/abs/2504.20484v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fane at SemEval-2025 Task 10: Zero-Shot Entity Framing with Large Language Models", "abstract": "Understanding how news narratives frame entities is crucial for studying\nmedia's impact on societal perceptions of events. In this paper, we evaluate\nthe zero-shot capabilities of large language models (LLMs) in classifying\nframing roles. Through systematic experimentation, we assess the effects of\ninput context, prompting strategies, and task decomposition. Our findings show\nthat a hierarchical approach of first identifying broad roles and then\nfine-grained roles, outperforms single-step classification. We also demonstrate\nthat optimal input contexts and prompts vary across task levels, highlighting\nthe need for subtask-specific strategies. We achieve a Main Role Accuracy of\n89.4% and an Exact Match Ratio of 34.5%, demonstrating the effectiveness of our\napproach. Our findings emphasize the importance of tailored prompt design and\ninput context optimization for improving LLM performance in entity framing.", "published": "2025-04-29 07:10:53", "link": "http://arxiv.org/abs/2504.20469v1", "categories": ["cs.CL", "cs.CY", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Search-Based Interaction For Conversation Recommendation via Generative Reward Model Based Simulated User", "abstract": "Conversational recommendation systems (CRSs) use multi-turn interaction to\ncapture user preferences and provide personalized recommendations. A\nfundamental challenge in CRSs lies in effectively understanding user\npreferences from conversations. User preferences can be multifaceted and\ncomplex, posing significant challenges for accurate recommendations even with\naccess to abundant external knowledge. While interaction with users can clarify\ntheir true preferences, frequent user involvement can lead to a degraded user\nexperience.\n  To address this problem, we propose a generative reward model based simulated\nuser, named GRSU, for automatic interaction with CRSs. The simulated user\nprovides feedback to the items recommended by CRSs, enabling them to better\ncapture intricate user preferences through multi-turn interaction. Inspired by\ngenerative reward models, we design two types of feedback actions for the\nsimulated user: i.e., generative item scoring, which offers coarse-grained\nfeedback, and attribute-based item critique, which provides fine-grained\nfeedback. To ensure seamless integration, these feedback actions are unified\ninto an instruction-based format, allowing the development of a unified\nsimulated user via instruction tuning on synthesized data. With this simulated\nuser, automatic multi-turn interaction with CRSs can be effectively conducted.\nFurthermore, to strike a balance between effectiveness and efficiency, we draw\ninspiration from the paradigm of reward-guided search in complex reasoning\ntasks and employ beam search for the interaction process. On top of this, we\npropose an efficient candidate ranking method to improve the recommendation\nresults derived from interaction. Extensive experiments on public datasets\ndemonstrate the effectiveness, efficiency, and transferability of our approach.", "published": "2025-04-29 06:37:30", "link": "http://arxiv.org/abs/2504.20458v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Reviving Any-Subset Autoregressive Models with Principled Parallel Sampling and Speculative Decoding", "abstract": "In arbitrary-order language models, it is an open question how to sample\ntokens in parallel from the correct joint distribution. With discrete diffusion\nmodels, the more tokens they generate in parallel, the less their predicted\ndistributions adhere to the originally learned data distribution, as they rely\non a conditional independence assumption that only works with infinitesimally\nsmall timesteps. We find that a different class of models, any-subset\nautoregressive models (AS-ARMs), holds the solution. As implied by the name,\nAS-ARMs can generate tokens in any order, and in parallel. Moreover, AS-ARMs\nsupport parallelized joint probability density estimation, allowing them to\ncorrect their own parallel-generated token distributions, via our Any-Subset\nSpeculative Decoding (ASSD) algorithm. ASSD provably enables generation of\ntokens from the correct joint distribution, with the number of neural network\ncalls upper bounded by the number of tokens predicted. We empirically verify\nthat ASSD speeds up language generation, without sacrificing quality.\nFurthermore, we provide a mathematically justified scheme for training AS-ARMs\nfor generation, and show that AS-ARMs achieve state-of-the-art performance\namong sub-200M parameter models on infilling benchmark tasks, and nearly match\nthe performance of models 50X larger on code generation. Our theoretical and\nempirical results indicate that the once-forgotten AS-ARMs are a promising\ndirection of language modeling.", "published": "2025-04-29 06:33:13", "link": "http://arxiv.org/abs/2504.20456v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Team ACK at SemEval-2025 Task 2: Beyond Word-for-Word Machine Translation for English-Korean Pairs", "abstract": "Translating knowledge-intensive and entity-rich text between English and\nKorean requires transcreation to preserve language-specific and cultural\nnuances beyond literal, phonetic or word-for-word conversion. We evaluate 13\nmodels (LLMs and MT models) using automatic metrics and human assessment by\nbilingual annotators. Our findings show LLMs outperform traditional MT systems\nbut struggle with entity translation requiring cultural adaptation. By\nconstructing an error taxonomy, we identify incorrect responses and entity name\nerrors as key issues, with performance varying by entity type and popularity\nlevel. This work exposes gaps in automatic evaluation metrics and hope to\nenable future work in completing culturally-nuanced machine translation.", "published": "2025-04-29 05:58:19", "link": "http://arxiv.org/abs/2504.20451v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "On Psychology of AI -- Does Primacy Effect Affect ChatGPT and Other LLMs?", "abstract": "We study the primacy effect in three commercial LLMs: ChatGPT, Gemini and\nClaude. We do this by repurposing the famous experiment Asch (1946) conducted\nusing human subjects. The experiment is simple, given two candidates with equal\ndescriptions which one is preferred if one description has positive adjectives\nfirst before negative ones and another description has negative adjectives\nfollowed by positive ones. We test this in two experiments. In one experiment,\nLLMs are given both candidates simultaneously in the same prompt, and in\nanother experiment, LLMs are given both candidates separately. We test all the\nmodels with 200 candidate pairs. We found that, in the first experiment,\nChatGPT preferred the candidate with positive adjectives listed first, while\nGemini preferred both equally often. Claude refused to make a choice. In the\nsecond experiment, ChatGPT and Claude were most likely to rank both candidates\nequally. In the case where they did not give an equal rating, both showed a\nclear preference to a candidate that had negative adjectives listed first.\nGemini was most likely to prefer a candidate with negative adjectives listed\nfirst.", "published": "2025-04-29 05:35:23", "link": "http://arxiv.org/abs/2504.20444v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DMDTEval: An Evaluation and Analysis of LLMs on Disambiguation in Multi-domain Translation", "abstract": "Currently, Large Language Models (LLMs) have achieved remarkable results in\nmachine translation. However, their performance in multi-domain translation\n(MDT) is less satisfactory; the meanings of words can vary across different\ndomains, highlighting the significant ambiguity inherent in MDT. Therefore,\nevaluating the disambiguation ability of LLMs in MDT remains an open problem.\nTo this end, we present an evaluation and analysis of LLMs on disambiguation in\nmulti-domain translation (DMDTEval), our systematic evaluation framework\nconsisting of three critical aspects: (1) we construct a translation test set\nwith multi-domain ambiguous word annotation, (2) we curate a diverse set of\ndisambiguation prompting templates, and (3) we design precise disambiguation\nmetrics, and study the efficacy of various prompting strategies on multiple\nstate-of-the-art LLMs. Our extensive experiments reveal a number of crucial\nfindings that we believe will pave the way and also facilitate further research\nin the critical area of improving the disambiguation of LLMs.", "published": "2025-04-29 02:27:36", "link": "http://arxiv.org/abs/2504.20371v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Causes Knowledge Loss in Multilingual Language Models?", "abstract": "Cross-lingual transfer in natural language processing (NLP) models enhances\nmultilingual performance by leveraging shared linguistic knowledge. However,\ntraditional methods that process all data simultaneously often fail to mimic\nreal-world scenarios, leading to challenges like catastrophic forgetting, where\nfine-tuning on new tasks degrades performance on previously learned ones. Our\nstudy explores this issue in multilingual contexts, focusing on linguistic\ndifferences affecting representational learning rather than just model\nparameters. We experiment with 52 languages using LoRA adapters of varying\nranks to evaluate non-shared, partially shared, and fully shared parameters.\nOur aim is to see if parameter sharing through adapters can mitigate forgetting\nwhile preserving prior knowledge. We find that languages using non-Latin\nscripts are more susceptible to catastrophic forgetting, whereas those written\nin Latin script facilitate more effective cross-lingual transfer.", "published": "2025-04-29 01:49:09", "link": "http://arxiv.org/abs/2504.20356v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Local Prompt Optimization", "abstract": "In recent years, the use of prompts to guide the output of Large Language\nModels have increased dramatically. However, even the best of experts struggle\nto choose the correct words to stitch up a prompt for the desired task. To\nsolve this, LLM driven prompt optimization emerged as an important problem.\nExisting prompt optimization methods optimize a prompt globally, where in all\nthe prompt tokens have to be optimized over a large vocabulary while solving a\ncomplex task. The large optimization space (tokens) leads to insufficient\nguidance for a better prompt. In this work, we introduce Local Prompt\nOptimization (LPO) that integrates with any general automatic prompt\nengineering method. We identify the optimization tokens in a prompt and nudge\nthe LLM to focus only on those tokens in its optimization step. We observe\nremarkable performance improvements on Math Reasoning (GSM8k and MultiArith)\nand BIG-bench Hard benchmarks across various automatic prompt engineering\nmethods. Further, we show that LPO converges to the optimal prompt faster than\nglobal methods.", "published": "2025-04-29 01:45:47", "link": "http://arxiv.org/abs/2504.20355v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Labeling Case Similarity based on Co-Citation of Legal Articles in Judgment Documents with Empirical Dispute-Based Evaluation", "abstract": "This report addresses the challenge of limited labeled datasets for\ndeveloping legal recommender systems, particularly in specialized domains like\nlabor disputes. We propose a new approach leveraging the co-citation of legal\narticles within cases to establish similarity and enable algorithmic\nannotation. This method draws a parallel to the concept of case co-citation,\nutilizing cited precedents as indicators of shared legal issues. To evaluate\nthe labeled results, we employ a system that recommends similar cases based on\nplaintiffs' accusations, defendants' rebuttals, and points of disputes. The\nevaluation demonstrates that the recommender, with finetuned text embedding\nmodels and a reasonable BiLSTM module can recommend labor cases whose\nsimilarity was measured by the co-citation of the legal articles. This research\ncontributes to the development of automated annotation techniques for legal\ndocuments, particularly in areas with limited access to comprehensive legal\ndatabases.", "published": "2025-04-29 00:26:37", "link": "http://arxiv.org/abs/2504.20323v1", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "YoChameleon: Personalized Vision and Language Generation", "abstract": "Large Multimodal Models (e.g., GPT-4, Gemini, Chameleon) have evolved into\npowerful tools with millions of users. However, they remain generic models and\nlack personalized knowledge of specific user concepts. Previous work has\nexplored personalization for text generation, yet it remains unclear how these\nmethods can be adapted to new modalities, such as image generation. In this\npaper, we introduce Yo'Chameleon, the first attempt to study personalization\nfor large multimodal models. Given 3-5 images of a particular concept,\nYo'Chameleon leverages soft-prompt tuning to embed subject-specific information\nto (i) answer questions about the subject and (ii) recreate pixel-level details\nto produce images of the subject in new contexts. Yo'Chameleon is trained with\n(i) a self-prompting optimization mechanism to balance performance across\nmultiple modalities, and (ii) a ``soft-positive\" image generation approach to\nenhance image quality in a few-shot setting.", "published": "2025-04-29 17:59:57", "link": "http://arxiv.org/abs/2504.20998v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Toward Efficient Exploration by Large Language Model Agents", "abstract": "A burgeoning area within reinforcement learning (RL) is the design of\nsequential decision-making agents centered around large language models (LLMs).\nWhile autonomous decision-making agents powered by modern LLMs could facilitate\nnumerous real-world applications, such successes demand agents that are capable\nof data-efficient RL. One key obstacle to achieving data efficiency in RL is\nexploration, a challenge that we demonstrate many recent proposals for LLM\nagent designs struggle to contend with. Meanwhile, classic algorithms from the\nRL literature known to gracefully address exploration require technical\nmachinery that can be challenging to operationalize in purely natural language\nsettings. In this work, rather than relying on finetuning or in-context\nlearning to coax LLMs into implicitly imitating a RL algorithm, we illustrate\nhow LLMs can be used to explicitly implement an existing RL algorithm\n(Posterior Sampling for Reinforcement Learning) whose capacity for\nstatistically-efficient exploration is already well-studied. We offer empirical\nresults demonstrating how our LLM-based implementation of a known,\ndata-efficient RL algorithm can be considerably more effective in natural\nlanguage tasks that demand prudent exploration.", "published": "2025-04-29 17:59:48", "link": "http://arxiv.org/abs/2504.20997v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Hubs and Spokes Learning: Efficient and Scalable Collaborative Machine Learning", "abstract": "We introduce the Hubs and Spokes Learning (HSL) framework, a novel paradigm\nfor collaborative machine learning that combines the strengths of Federated\nLearning (FL) and Decentralized Learning (P2PL). HSL employs a two-tier\ncommunication structure that avoids the single point of failure inherent in FL\nand outperforms the state-of-the-art P2PL framework, Epidemic Learning Local\n(ELL). At equal communication budgets (total edges), HSL achieves higher\nperformance than ELL, while at significantly lower communication budgets, it\ncan match ELL's performance. For instance, with only 400 edges, HSL reaches the\nsame test accuracy that ELL achieves with 1000 edges for 100 peers (spokes) on\nCIFAR-10, demonstrating its suitability for resource-constrained systems. HSL\nalso achieves stronger consensus among nodes after mixing, resulting in\nimproved performance with fewer training rounds. We substantiate these claims\nthrough rigorous theoretical analyses and extensive experimental results,\nshowcasing HSL's practicality for large-scale collaborative learning.", "published": "2025-04-29 17:56:55", "link": "http://arxiv.org/abs/2504.20988v1", "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "cs.LG"}
{"title": "LTLf Adaptive Synthesis for Multi-Tier Goals in Nondeterministic Domains", "abstract": "We study a variant of LTLf synthesis that synthesizes adaptive strategies for\nachieving a multi-tier goal, consisting of multiple increasingly challenging\nLTLf objectives in nondeterministic planning domains. Adaptive strategies are\nstrategies that at any point of their execution (i) enforce the satisfaction of\nas many objectives as possible in the multi-tier goal, and (ii) exploit\npossible cooperation from the environment to satisfy as many as possible of the\nremaining ones. This happens dynamically: if the environment cooperates (ii)\nand an objective becomes enforceable (i), then our strategies will enforce it.\nWe provide a game-theoretic technique to compute adaptive strategies that is\nsound and complete. Notably, our technique is polynomial, in fact quadratic, in\nthe number of objectives. In other words, it handles multi-tier goals with only\na minor overhead compared to standard LTLf synthesis.", "published": "2025-04-29 17:53:16", "link": "http://arxiv.org/abs/2504.20983v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Jekyll-and-Hyde Tipping Point in an AI's Behavior", "abstract": "Trust in AI is undermined by the fact that there is no science that predicts\n-- or that can explain to the public -- when an LLM's output (e.g. ChatGPT) is\nlikely to tip mid-response to become wrong, misleading, irrelevant or\ndangerous. With deaths and trauma already being blamed on LLMs, this\nuncertainty is even pushing people to treat their 'pet' LLM more politely to\n'dissuade' it (or its future Artificial General Intelligence offspring) from\nsuddenly turning on them. Here we address this acute need by deriving from\nfirst principles an exact formula for when a Jekyll-and-Hyde tipping point\noccurs at LLMs' most basic level. Requiring only secondary school mathematics,\nit shows the cause to be the AI's attention spreading so thin it suddenly\nsnaps. This exact formula provides quantitative predictions for how the\ntipping-point can be delayed or prevented by changing the prompt and the AI's\ntraining. Tailored generalizations will provide policymakers and the public\nwith a firm platform for discussing any of AI's broader uses and risks, e.g. as\na personal counselor, medical advisor, decision-maker for when to use force in\na conflict situation. It also meets the need for clear and transparent answers\nto questions like ''should I be polite to my LLM?''", "published": "2025-04-29 17:50:29", "link": "http://arxiv.org/abs/2504.20980v1", "categories": ["cs.AI", "cs.CY", "nlin.AO", "physics.comp-ph", "physics.soc-ph"], "primary_category": "cs.AI"}
{"title": "SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep Features", "abstract": "Accurate and early diagnosis of pneumonia through X-ray imaging is essential\nfor effective treatment and improved patient outcomes. Recent advancements in\nmachine learning have enabled automated diagnostic tools that assist\nradiologists in making more reliable and efficient decisions. In this work, we\npropose a Singular Value Decomposition-based Least Squares (SVD-LS) framework\nfor multi-class pneumonia classification, leveraging powerful feature\nrepresentations from state-of-the-art self-supervised and transfer learning\nmodels. Rather than relying on computationally expensive gradient based\nfine-tuning, we employ a closed-form, non-iterative classification approach\nthat ensures efficiency without compromising accuracy. Experimental results\ndemonstrate that SVD-LS achieves competitive performance while offering\nsignificantly reduced computational costs, making it a viable alternative for\nreal-time medical imaging applications.", "published": "2025-04-29 17:39:16", "link": "http://arxiv.org/abs/2504.20970v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Domain-Agnostic Scalable AI Safety Ensuring Framework", "abstract": "Ensuring the safety of AI systems has recently emerged as a critical priority\nfor real-world deployment, particularly in physical AI applications. Current\napproaches to AI safety typically address predefined domain-specific safety\nconditions, limiting their ability to generalize across contexts.\n  We propose a novel AI safety framework that ensures AI systems comply with\n\\textbf{any user-defined constraint}, with \\textbf{any desired probability},\nand across \\textbf{various domains}.\n  In this framework, we combine an AI component (e.g., neural network) with an\noptimization problem to produce responses that minimize objectives while\nsatisfying user-defined constraints with probabilities exceeding user-defined\nthresholds. For credibility assessment of the AI component, we propose\n\\textit{internal test data}, a supplementary set of safety-labeled data, and a\n\\textit{conservative testing} methodology that provides statistical validity of\nusing internal test data. We also present an approximation method of a loss\nfunction and how to compute its gradient for training.\n  We mathematically prove that probabilistic constraint satisfaction is\nguaranteed under specific, mild conditions and prove a scaling law between\nsafety and the number of internal test data. We demonstrate our framework's\neffectiveness through experiments in diverse domains: demand prediction for\nproduction decision, safe reinforcement learning within the SafetyGym\nsimulator, and guarding AI chatbot outputs. Through these experiments, we\ndemonstrate that our method guarantees safety for user-specified constraints,\noutperforms {for \\textbf{up to several order of magnitudes}} existing methods\nin low safety threshold regions, and scales effectively with respect to the\nsize of internal test data.", "published": "2025-04-29 16:38:35", "link": "http://arxiv.org/abs/2504.20924v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Leveraging Generative AI Through Prompt Engineering and Rigorous Validation to Create Comprehensive Synthetic Datasets for AI Training in Healthcare", "abstract": "Access to high-quality medical data is often restricted due to privacy\nconcerns, posing significant challenges for training artificial intelligence\n(AI) algorithms within Electronic Health Record (EHR) applications. In this\nstudy, prompt engineering with the GPT-4 API was employed to generate\nhigh-quality synthetic datasets aimed at overcoming this limitation. The\ngenerated data encompassed a comprehensive array of patient admission\ninformation, including healthcare provider details, hospital departments,\nwards, bed assignments, patient demographics, emergency contacts, vital signs,\nimmunizations, allergies, medical histories, appointments, hospital visits,\nlaboratory tests, diagnoses, treatment plans, medications, clinical notes,\nvisit logs, discharge summaries, and referrals. To ensure data quality and\nintegrity, advanced validation techniques were implemented utilizing models\nsuch as BERT's Next Sentence Prediction for sentence coherence, GPT-2 for\noverall plausibility, RoBERTa for logical consistency, autoencoders for anomaly\ndetection, and conducted diversity analysis. Synthetic data that met all\nvalidation criteria were integrated into a comprehensive PostgreSQL database,\nserving as the data management system for the EHR application. This approach\ndemonstrates that leveraging generative AI models with rigorous validation can\neffectively produce high-quality synthetic medical data, facilitating the\ntraining of AI algorithms while addressing privacy concerns associated with\nreal patient data.", "published": "2025-04-29 16:37:34", "link": "http://arxiv.org/abs/2504.20921v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "When Testing AI Tests Us: Safeguarding Mental Health on the Digital Frontlines", "abstract": "Red-teaming is a core part of the infrastructure that ensures that AI models\ndo not produce harmful content. Unlike past technologies, the black box nature\nof generative AI systems necessitates a uniquely interactional mode of testing,\none in which individuals on red teams actively interact with the system,\nleveraging natural language to simulate malicious actors and solicit harmful\noutputs. This interactional labor done by red teams can result in mental health\nharms that are uniquely tied to the adversarial engagement strategies necessary\nto effectively red team. The importance of ensuring that generative AI models\ndo not propagate societal or individual harm is widely recognized -- one less\nvisible foundation of end-to-end AI safety is also the protection of the mental\nhealth and wellbeing of those who work to keep model outputs safe. In this\npaper, we argue that the unmet mental health needs of AI red-teamers is a\ncritical workplace safety concern. Through analyzing the unique mental health\nimpacts associated with the labor done by red teams, we propose potential\nindividual and organizational strategies that could be used to meet these\nneeds, and safeguard the mental health of red-teamers. We develop our proposed\nstrategies through drawing parallels between common red-teaming practices and\ninteractional labor common to other professions (including actors, mental\nhealth professionals, conflict photographers, and content moderators),\ndescribing how individuals and organizations within these professional spaces\nsafeguard their mental health given similar psychological demands. Drawing on\nthese protective practices, we describe how safeguards could be adapted for the\ndistinct mental health challenges experienced by red teaming organizations as\nthey mitigate emerging technological risks on the new digital frontlines.", "published": "2025-04-29 16:27:20", "link": "http://arxiv.org/abs/2504.20910v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "Modeling AI-Human Collaboration as a Multi-Agent Adaptation", "abstract": "We develop an agent-based simulation to formalize AI-human collaboration as a\nfunction of task structure, advancing a generalizable framework for strategic\ndecision-making in organizations. Distinguishing between heuristic-based human\nadaptation and rule-based AI search, we model interactions across modular\n(parallel) and sequenced (interdependent) tasks using an NK model. Our results\nreveal that in modular tasks, AI often substitutes for humans - delivering\nhigher payoffs unless human expertise is very high, and the AI search space is\neither narrowly focused or extremely broad. In sequenced tasks, interesting\ncomplementarities emerge. When an expert human initiates the search and AI\nsubsequently refines it, aggregate performance is maximized. Conversely, when\nAI leads, excessive heuristic refinement by the human can reduce payoffs. We\nalso show that even \"hallucinatory\" AI - lacking memory or structure - can\nimprove outcomes when augmenting low-capability humans by helping escape local\noptima. These results yield a robust implication: the effectiveness of AI-human\ncollaboration depends less on context or industry, and more on the underlying\ntask structure. By elevating task decomposition as the central unit of\nanalysis, our model provides a transferable lens for strategic decision-making\ninvolving humans and an agentic AI across diverse organizational settings.", "published": "2025-04-29 16:19:53", "link": "http://arxiv.org/abs/2504.20903v1", "categories": ["cs.MA", "cs.AI", "cs.HC"], "primary_category": "cs.MA"}
{"title": "Classifier-to-Bias: Toward Unsupervised Automatic Bias Detection for Visual Classifiers", "abstract": "A person downloading a pre-trained model from the web should be aware of its\nbiases. Existing approaches for bias identification rely on datasets containing\nlabels for the task of interest, something that a non-expert may not have\naccess to, or may not have the necessary resources to collect: this greatly\nlimits the number of tasks where model biases can be identified. In this work,\nwe present Classifier-to-Bias (C2B), the first bias discovery framework that\nworks without access to any labeled data: it only relies on a textual\ndescription of the classification task to identify biases in the target\nclassification model. This description is fed to a large language model to\ngenerate bias proposals and corresponding captions depicting biases together\nwith task-specific target labels. A retrieval model collects images for those\ncaptions, which are then used to assess the accuracy of the model w.r.t. the\ngiven biases. C2B is training-free, does not require any annotations, has no\nconstraints on the list of biases, and can be applied to any pre-trained model\non any classification task. Experiments on two publicly available datasets show\nthat C2B discovers biases beyond those of the original datasets and outperforms\na recent state-of-the-art bias detection baseline that relies on task-specific\nannotations, being a promising first step toward addressing task-agnostic\nunsupervised bias detection.", "published": "2025-04-29 16:19:38", "link": "http://arxiv.org/abs/2504.20902v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report Generation with Multi-Agent RAG and Concept Bottleneck Models", "abstract": "Advancements in generative Artificial Intelligence (AI) hold great promise\nfor automating radiology workflows, yet challenges in interpretability and\nreliability hinder clinical adoption. This paper presents an automated\nradiology report generation framework that combines Concept Bottleneck Models\n(CBMs) with a Multi-Agent Retrieval-Augmented Generation (RAG) system to bridge\nAI performance with clinical explainability. CBMs map chest X-ray features to\nhuman-understandable clinical concepts, enabling transparent disease\nclassification. Meanwhile, the RAG system integrates multi-agent collaboration\nand external knowledge to produce contextually rich, evidence-based reports.\nOur demonstration showcases the system's ability to deliver interpretable\npredictions, mitigate hallucinations, and generate high-quality, tailored\nreports with an interactive interface addressing accuracy, trust, and usability\nchallenges. This framework provides a pathway to improving diagnostic\nconsistency and empowering radiologists with actionable insights.", "published": "2025-04-29 16:14:55", "link": "http://arxiv.org/abs/2504.20898v1", "categories": ["cs.AI", "cs.CV", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Return Capping: Sample-Efficient CVaR Policy Gradient Optimisation", "abstract": "When optimising for conditional value at risk (CVaR) using policy gradients\n(PG), current methods rely on discarding a large proportion of trajectories,\nresulting in poor sample efficiency. We propose a reformulation of the CVaR\noptimisation problem by capping the total return of trajectories used in\ntraining, rather than simply discarding them, and show that this is equivalent\nto the original problem if the cap is set appropriately. We show, with\nempirical results in an number of environments, that this reformulation of the\nproblem results in consistently improved performance compared to baselines.", "published": "2025-04-29 16:04:16", "link": "http://arxiv.org/abs/2504.20887v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Quantifying the Noise of Structural Perturbations on Graph Adversarial Attacks", "abstract": "Graph neural networks have been widely utilized to solve graph-related tasks\nbecause of their strong learning power in utilizing the local information of\nneighbors. However, recent studies on graph adversarial attacks have proven\nthat current graph neural networks are not robust against malicious attacks.\nYet much of the existing work has focused on the optimization objective based\non attack performance to obtain (near) optimal perturbations, but paid less\nattention to the strength quantification of each perturbation such as the\ninjection of a particular node/link, which makes the choice of perturbations a\nblack-box model that lacks interpretability. In this work, we propose the\nconcept of noise to quantify the attack strength of each adversarial link.\nFurthermore, we propose three attack strategies based on the defined noise and\nclassification margins in terms of single and multiple steps optimization.\nExtensive experiments conducted on benchmark datasets against three\nrepresentative graph neural networks demonstrate the effectiveness of the\nproposed attack strategies. Particularly, we also investigate the preferred\npatterns of effective adversarial perturbations by analyzing the corresponding\nproperties of the selected perturbation nodes.", "published": "2025-04-29 15:42:56", "link": "http://arxiv.org/abs/2504.20869v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Tabular Data Adapters: Improving Outlier Detection for Unlabeled Private Data", "abstract": "The remarkable success of Deep Learning approaches is often based and\ndemonstrated on large public datasets. However, when applying such approaches\nto internal, private datasets, one frequently faces challenges arising from\nstructural differences in the datasets, domain shift, and the lack of labels.\nIn this work, we introduce Tabular Data Adapters (TDA), a novel method for\ngenerating soft labels for unlabeled tabular data in outlier detection tasks.\nBy identifying statistically similar public datasets and transforming private\ndata (based on a shared autoencoder) into a format compatible with\nstate-of-the-art public models, our approach enables the generation of weak\nlabels. It thereby can help to mitigate the cold start problem of labeling by\nbasing on existing outlier detection models for public datasets. In experiments\non 50 tabular datasets across different domains, we demonstrate that our method\nis able to provide more accurate annotations than baseline approaches while\nreducing computational time. Our approach offers a scalable, efficient, and\ncost-effective solution, to bridge the gap between public research models and\nreal-world industrial applications.", "published": "2025-04-29 15:38:43", "link": "http://arxiv.org/abs/2504.20862v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards Easy and Realistic Network Infrastructure Testing for Large-scale Machine Learning", "abstract": "This paper lays the foundation for Genie, a testing framework that captures\nthe impact of real hardware network behavior on ML workload performance,\nwithout requiring expensive GPUs. Genie uses CPU-initiated traffic over a\nhardware testbed to emulate GPU to GPU communication, and adapts the ASTRA-sim\nsimulator to model interaction between the network and the ML workload.", "published": "2025-04-29 15:23:55", "link": "http://arxiv.org/abs/2504.20854v1", "categories": ["cs.NI", "cs.AI", "cs.DC", "cs.SY", "eess.SY"], "primary_category": "cs.NI"}
{"title": "Fostering Self-Directed Growth with Generative AI: Toward a New Learning Analytics Framework", "abstract": "In an era increasingly shaped by decentralized knowledge ecosystems and\npervasive AI technologies, fostering sustainable learner agency has become a\ncritical educational imperative. This study introduces a novel conceptual\nframework integrating Generative Artificial Intelligence and Learning Analytics\nto cultivate Self-Directed Growth, a dynamic competency that enables learners\nto iteratively drive their own developmental pathways across diverse\ncontexts.Building upon critical gaps in current research on Self Directed\nLearning and AI-mediated education, the proposed Aspire to Potentials for\nLearners (A2PL) model reconceptualizes the interplay of learner aspirations,\ncomplex thinking, and summative self-assessment within GAI supported\nenvironments.Methodological implications for future intervention design and\nlearning analytics applications are discussed, positioning Self-Directed Growth\nas a pivotal axis for developing equitable, adaptive, and sustainable learning\nsystems in the digital era.", "published": "2025-04-29 15:19:48", "link": "http://arxiv.org/abs/2504.20851v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Mitigating the Structural Bias in Graph Adversarial Defenses", "abstract": "In recent years, graph neural networks (GNNs) have shown great potential in\naddressing various graph structure-related downstream tasks. However, recent\nstudies have found that current GNNs are susceptible to malicious adversarial\nattacks. Given the inevitable presence of adversarial attacks in the real\nworld, a variety of defense methods have been proposed to counter these attacks\nand enhance the robustness of GNNs. Despite the commendable performance of\nthese defense methods, we have observed that they tend to exhibit a structural\nbias in terms of their defense capability on nodes with low degree (i.e., tail\nnodes), which is similar to the structural bias of traditional GNNs on nodes\nwith low degree in the clean graph. Therefore, in this work, we propose a\ndefense strategy by including hetero-homo augmented graph construction, $k$NN\naugmented graph construction, and multi-view node-wise attention modules to\nmitigate the structural bias of GNNs against adversarial attacks. Notably, the\nhetero-homo augmented graph consists of removing heterophilic links (i.e.,\nlinks connecting nodes with dissimilar features) globally and adding homophilic\nlinks (i.e., links connecting nodes with similar features) for nodes with low\ndegree. To further enhance the defense capability, an attention mechanism is\nadopted to adaptively combine the representations from the above two kinds of\ngraph views. We conduct extensive experiments to demonstrate the defense and\ndebiasing effect of the proposed strategy on benchmark datasets.", "published": "2025-04-29 15:19:05", "link": "http://arxiv.org/abs/2504.20848v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Disjunctive and Conjunctive Normal Form Explanations of Clusters Using Auxiliary Information", "abstract": "We consider generating post-hoc explanations of clusters generated from\nvarious datasets using auxiliary information which was not used by clustering\nalgorithms. Following terminology used in previous work, we refer to the\nauxiliary information as tags. Our focus is on two forms of explanations,\nnamely disjunctive form (where the explanation for a cluster consists of a set\nof tags) and a two-clause conjunctive normal form (CNF) explanation (where the\nexplanation consists of two sets of tags, combined through the AND operator).\nWe use integer linear programming (ILP) as well as heuristic methods to\ngenerate these explanations. We experiment with a variety of datasets and\ndiscuss the insights obtained from our explanations. We also present\nexperimental results regarding the scalability of our explanation methods.", "published": "2025-04-29 15:18:18", "link": "http://arxiv.org/abs/2504.20846v1", "categories": ["cs.AI", "I.2"], "primary_category": "cs.AI"}
{"title": "RadSAM: Segmenting 3D radiological images with a 2D promptable model", "abstract": "Medical image segmentation is a crucial and time-consuming task in clinical\ncare, where mask precision is extremely important. The Segment Anything Model\n(SAM) offers a promising approach, as it provides an interactive interface\nbased on visual prompting and edition to refine an initial segmentation. This\nmodel has strong generalization capabilities, does not rely on predefined\nclasses, and adapts to diverse objects; however, it is pre-trained on natural\nimages and lacks the ability to process medical data effectively. In addition,\nthis model is built for 2D images, whereas a whole medical domain is based on\n3D images, such as CT and MRI. Recent adaptations of SAM for medical imaging\nare based on 2D models, thus requiring one prompt per slice to segment 3D\nobjects, making the segmentation process tedious. They also lack important\nfeatures such as editing. To bridge this gap, we propose RadSAM, a novel method\nfor segmenting 3D objects with a 2D model from a single prompt. In practice, we\ntrain a 2D model using noisy masks as initial prompts, in addition to bounding\nboxes and points. We then use this novel prompt type with an iterative\ninference pipeline to reconstruct the 3D mask slice-by-slice. We introduce a\nbenchmark to evaluate the model's ability to segment 3D objects in CT images\nfrom a single prompt and evaluate the models' out-of-domain transfer and\nedition capabilities. We demonstrate the effectiveness of our approach against\nstate-of-the-art models on this benchmark using the AMOS abdominal organ\nsegmentation dataset.", "published": "2025-04-29 15:00:25", "link": "http://arxiv.org/abs/2504.20837v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Reinforcement Learning for LLM Reasoning Under Memory Constraints", "abstract": "We explore reinforcement learning (RL) techniques to enhance reasoning within\ntargeted problem spaces in large language models (LLMs) under memory and\ncompute constraints. Our focus is on critic-free methods compatible with LoRA\nfine-tuning on a single 40GB GPU, a common limitation in academic settings. We\nintroduce S-GRPO, a memory-efficient variant of Group Relative Policy\nOptimization, and T-SPMO, a token-level prefix matching strategy for\nfine-grained credit assignment. Despite limited resources, when used to\nfine-tune Qwen2-1.5B both methods significantly improve SVAMP benchmark\naccuracy from 46% to above 70% using LoRA training. T-SPMO also excels in\nmulti-digit multiplication tasks, underscoring the potential of RL fine-tuning\nunder hardware constraints. Additionally, we find that our full-token GRPO\nbaseline under LoRA fine-tuning did not improve model performance (compared to\nbase model) on either task, suggesting that our memory-efficient methods may\nact as a form of regularization that stabilizes training when only a small\nsubset of parameters are updated.", "published": "2025-04-29 14:58:43", "link": "http://arxiv.org/abs/2504.20834v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for Targeted Scene Confusion", "abstract": "As 3D Gaussian Splatting (3DGS) emerges as a breakthrough in scene\nrepresentation and novel view synthesis, its rapid adoption in safety-critical\ndomains (e.g., autonomous systems, AR/VR) urgently demands scrutiny of\npotential security vulnerabilities. This paper presents the first systematic\nstudy of backdoor threats in 3DGS pipelines. We identify that adversaries may\nimplant backdoor views to induce malicious scene confusion during inference,\npotentially leading to environmental misperception in autonomous navigation or\nspatial distortion in immersive environments. To uncover this risk, we propose\nGuassTrap, a novel poisoning attack method targeting 3DGS models. GuassTrap\ninjects malicious views at specific attack viewpoints while preserving\nhigh-quality rendering in non-target views, ensuring minimal detectability and\nmaximizing potential harm. Specifically, the proposed method consists of a\nthree-stage pipeline (attack, stabilization, and normal training) to implant\nstealthy, viewpoint-consistent poisoned renderings in 3DGS, jointly optimizing\nattack efficacy and perceptual realism to expose security risks in 3D\nrendering. Extensive experiments on both synthetic and real-world datasets\ndemonstrate that GuassTrap can effectively embed imperceptible yet harmful\nbackdoor views while maintaining high-quality rendering in normal views,\nvalidating its robustness, adaptability, and practical applicability.", "published": "2025-04-29 14:52:14", "link": "http://arxiv.org/abs/2504.20829v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Ascendra: Dynamic Request Prioritization for Efficient LLM Serving", "abstract": "The rapid advancement of Large Language Models (LLMs) has driven the need for\nmore efficient serving strategies. In this context, efficiency refers to the\nproportion of requests that meet their Service Level Objectives (SLOs),\nparticularly for Time To First Token (TTFT) and Time Between Tokens (TBT).\nHowever, existing systems often prioritize one metric at the cost of the other.\nWe present Ascendra, an LLM serving system designed to meet both TTFT and TBT\nSLOs simultaneously. The core insight behind Ascendra is that a request's\nurgency evolves as it approaches its deadline. To leverage this, Ascendra\npartitions GPU resources into two types of instances: low-priority and\nhigh-priority. Low-priority instances maximize throughput by processing\nrequests out of arrival order, but at the risk of request starvation. To\naddress this, Ascendra employs a performance model to predict requests at risk\nof missing their SLOs and proactively offloads them to high-priority instances.\nHigh-priority instances are optimized for low-latency execution and handle\nurgent requests nearing their deadlines. This partitioned architecture enables\nAscendra to effectively balance high throughput and low latency. Extensive\nevaluation shows that Ascendra improves system throughput by up to 1.7x\ncompared to vLLM and Sarathi-Serve while meeting both TTFT and TBT SLOs.", "published": "2025-04-29 14:51:26", "link": "http://arxiv.org/abs/2504.20828v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings", "abstract": "This paper introduces SoccerDiffusion, a transformer-based diffusion model\ndesigned to learn end-to-end control policies for humanoid robot soccer\ndirectly from real-world gameplay recordings. Using data collected from RoboCup\ncompetitions, the model predicts joint command trajectories from multi-modal\nsensor inputs, including vision, proprioception, and game state. We employ a\ndistillation technique to enable real-time inference on embedded platforms that\nreduces the multi-step diffusion process to a single step. Our results\ndemonstrate the model's ability to replicate complex motion behaviors such as\nwalking, kicking, and fall recovery both in simulation and on physical robots.\nAlthough high-level tactical behavior remains limited, this work provides a\nrobust foundation for subsequent reinforcement learning or preference\noptimization methods. We release the dataset, pretrained models, and code\nunder: https://bit-bots.github.io/SoccerDiffusion", "published": "2025-04-29 14:21:08", "link": "http://arxiv.org/abs/2504.20808v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges", "abstract": "Recent technical breakthroughs in large language models (LLMs) have enabled\nthem to fluently generate source code. Software developers often leverage both\ngeneral-purpose and code-specialized LLMs to revise existing code or even\ngenerate a whole function from scratch. These capabilities are also beneficial\nin no-code or low-code contexts, in which one can write programs without a\ntechnical background. However, due to their internal design, LLMs are prone to\ngenerating hallucinations, which are incorrect, nonsensical, and not\njustifiable information but difficult to identify its presence. This problem\nalso occurs when generating source code. Once hallucinated code is produced, it\nis often challenging for users to identify and fix it, especially when such\nhallucinations can be identified under specific execution paths. As a result,\nthe hallucinated code may remain unnoticed within the codebase. This survey\ninvestigates recent studies and techniques relevant to hallucinations generated\nby CodeLLMs. We categorize the types of hallucinations in the code generated by\nCodeLLMs, review existing benchmarks and mitigation strategies, and identify\nopen challenges. Based on these findings, this survey outlines further research\ndirections in the detection and removal of hallucinations produced by CodeLLMs.", "published": "2025-04-29 14:13:57", "link": "http://arxiv.org/abs/2504.20799v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Partitioned Memory Storage Inspired Few-Shot Class-Incremental learning", "abstract": "Current mainstream deep learning techniques exhibit an over-reliance on\nextensive training data and a lack of adaptability to the dynamic world,\nmarking a considerable disparity from human intelligence. To bridge this gap,\nFew-Shot Class-Incremental Learning (FSCIL) has emerged, focusing on continuous\nlearning of new categories with limited samples without forgetting old\nknowledge. Existing FSCIL studies typically use a single model to learn\nknowledge across all sessions, inevitably leading to the stability-plasticity\ndilemma. Unlike machines, humans store varied knowledge in different cerebral\ncortices. Inspired by this characteristic, our paper aims to develop a method\nthat learns independent models for each session. It can inherently prevent\ncatastrophic forgetting. During the testing stage, our method integrates\nUncertainty Quantification (UQ) for model deployment. Our method provides a\nfresh viewpoint for FSCIL and demonstrates the state-of-the-art performance on\nCIFAR-100 and mini-ImageNet datasets.", "published": "2025-04-29 14:11:06", "link": "http://arxiv.org/abs/2504.20797v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Approximate Lifted Model Construction", "abstract": "Probabilistic relational models such as parametric factor graphs enable\nefficient (lifted) inference by exploiting the indistinguishability of objects.\nIn lifted inference, a representative of indistinguishable objects is used for\ncomputations. To obtain a relational (i.e., lifted) representation, the\nAdvanced Colour Passing (ACP) algorithm is the state of the art. The ACP\nalgorithm, however, requires underlying distributions, encoded as\npotential-based factorisations, to exactly match to identify and exploit\nindistinguishabilities. Hence, ACP is unsuitable for practical applications\nwhere potentials learned from data inevitably deviate even if associated\nobjects are indistinguishable. To mitigate this problem, we introduce the\n$\\varepsilon$-Advanced Colour Passing ($\\varepsilon$-ACP) algorithm, which\nallows for a deviation of potentials depending on a hyperparameter\n$\\varepsilon$. $\\varepsilon$-ACP efficiently uncovers and exploits\nindistinguishabilities that are not exact. We prove that the approximation\nerror induced by $\\varepsilon$-ACP is strictly bounded and our experiments show\nthat the approximation error is close to zero in practice.", "published": "2025-04-29 14:01:10", "link": "http://arxiv.org/abs/2504.20784v1", "categories": ["cs.AI", "cs.DS", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Using LLMs in Generating Design Rationale for Software Architecture Decisions", "abstract": "Design Rationale (DR) for software architecture decisions refers to the\nreasoning underlying architectural choices, which provides valuable insights\ninto the different phases of the architecting process throughout software\ndevelopment. However, in practice, DR is often inadequately documented due to a\nlack of motivation and effort from developers. With the recent advancements in\nLarge Language Models (LLMs), their capabilities in text comprehension,\nreasoning, and generation may enable the generation and recovery of DR for\narchitecture decisions. In this study, we evaluated the performance of LLMs in\ngenerating DR for architecture decisions. First, we collected 50 Stack Overflow\n(SO) posts, 25 GitHub issues, and 25 GitHub discussions related to architecture\ndecisions to construct a dataset of 100 architecture-related problems. Then, we\nselected five LLMs to generate DR for the architecture decisions with three\nprompting strategies, including zero-shot, chain of thought (CoT), and\nLLM-based agents. With the DR provided by human experts as ground truth, the\nPrecision of LLM-generated DR with the three prompting strategies ranges from\n0.267 to 0.278, Recall from 0.627 to 0.715, and F1-score from 0.351 to 0.389.\nAdditionally, 64.45% to 69.42% of the arguments of DR not mentioned by human\nexperts are also helpful, 4.12% to 4.87% of the arguments have uncertain\ncorrectness, and 1.59% to 3.24% of the arguments are potentially misleading.\nBased on the results, we further discussed the pros and cons of the three\nprompting strategies and the strengths and limitations of the DR generated by\nLLMs.", "published": "2025-04-29 14:00:18", "link": "http://arxiv.org/abs/2504.20781v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "ECOSoundSet: a finely annotated dataset for the automated acoustic identification of Orthoptera and Cicadidae in North, Central and temperate Western Europe", "abstract": "Currently available tools for the automated acoustic recognition of European\ninsects in natural soundscapes are limited in scope. Large and ecologically\nheterogeneous acoustic datasets are currently needed for these algorithms to\ncross-contextually recognize the subtle and complex acoustic signatures\nproduced by each species, thus making the availability of such datasets a key\nrequisite for their development. Here we present ECOSoundSet (European\nCicadidae and Orthoptera Sound dataSet), a dataset containing 10,653 recordings\nof 200 orthopteran and 24 cicada species (217 and 26 respective taxa when\nincluding subspecies) present in North, Central, and temperate Western Europe\n(Andorra, Belgium, Denmark, mainland France and Corsica, Germany, Ireland,\nLuxembourg, Monaco, Netherlands, United Kingdom, Switzerland), collected partly\nthrough targeted fieldwork in South France and Catalonia and partly through\ncontributions from various European entomologists. The dataset is composed of a\ncombination of coarsely labeled recordings, for which we can only infer the\npresence, at some point, of their target species (weak labeling), and finely\nannotated recordings, for which we know the specific time and frequency range\nof each insect sound present in the recording (strong labeling). We also\nprovide a train/validation/test split of the strongly labeled recordings, with\nrespective approximate proportions of 0.8, 0.1 and 0.1, in order to facilitate\ntheir incorporation in the training and evaluation of deep learning algorithms.\nThis dataset could serve as a meaningful complement to recordings already\navailable online for the training of deep learning algorithms for the acoustic\nclassification of orthopterans and cicadas in North, Central, and temperate\nWestern Europe.", "published": "2025-04-29 13:53:33", "link": "http://arxiv.org/abs/2504.20776v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "JTreeformer: Graph-Transformer via Latent-Diffusion Model for Molecular Generation", "abstract": "The discovery of new molecules based on the original chemical molecule\ndistributions is of great importance in medicine. The graph transformer, with\nits advantages of high performance and scalability compared to traditional\ngraph networks, has been widely explored in recent research for applications of\ngraph structures. However, current transformer-based graph decoders struggle to\neffectively utilize graph information, which limits their capacity to leverage\nonly sequences of nodes rather than the complex topological structures of\nmolecule graphs. This paper focuses on building a graph transformer-based\nframework for molecular generation, which we call \\textbf{JTreeformer} as it\ntransforms graph generation into junction tree generation. It combines GCN\nparallel with multi-head attention as the encoder. It integrates a directed\nacyclic GCN into a graph-based Transformer to serve as a decoder, which can\niteratively synthesize the entire molecule by leveraging information from the\npartially constructed molecular structure at each step. In addition, a\ndiffusion model is inserted in the latent space generated by the encoder, to\nenhance the efficiency and effectiveness of sampling further. The empirical\nresults demonstrate that our novel framework outperforms existing molecule\ngeneration methods, thus offering a promising tool to advance drug discovery\n(https://anonymous.4open.science/r/JTreeformer-C74C).", "published": "2025-04-29 13:51:07", "link": "http://arxiv.org/abs/2504.20770v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Graph-Based Fault Diagnosis for Rotating Machinery: Adaptive Segmentation and Structural Feature Integration", "abstract": "This paper proposes a novel graph-based framework for robust and\ninterpretable multiclass fault diagnosis in rotating machinery. The method\nintegrates entropy-optimized signal segmentation, time-frequency feature\nextraction, and graph-theoretic modeling to transform vibration signals into\nstructured representations suitable for classification. Graph metrics, such as\naverage shortest path length, modularity, and spectral gap, are computed and\ncombined with local features to capture global and segment-level fault\ncharacteristics. The proposed method achieves high diagnostic accuracy when\nevaluated on two benchmark datasets, the CWRU bearing dataset (under 0-3 HP\nloads) and the SU gearbox and bearing datasets (under different speed-load\nconfigurations). Classification scores reach up to 99.8% accuracy on Case\nWestern Reserve University (CWRU) and 100% accuracy on the Southeast University\ndatasets using a logistic regression classifier. Furthermore, the model\nexhibits strong noise resilience, maintaining over 95.4% accuracy at high noise\nlevels (standard deviation = 0.5), and demonstrates excellent cross-domain\ntransferability with up to 99.7% F1-score in load-transfer scenarios. Compared\nto traditional techniques, this approach requires no deep learning\narchitecture, enabling lower complexity while ensuring interpretability. The\nresults confirm the method's scalability, reliability, and potential for\nreal-time deployment in industrial diagnostics.", "published": "2025-04-29 13:34:52", "link": "http://arxiv.org/abs/2504.20756v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "In defence of post-hoc explanations in medical AI", "abstract": "Since the early days of the Explainable AI movement, post-hoc explanations\nhave been praised for their potential to improve user understanding, promote\ntrust, and reduce patient safety risks in black box medical AI systems.\nRecently, however, critics have argued that the benefits of post-hoc\nexplanations are greatly exaggerated since they merely approximate, rather than\nreplicate, the actual reasoning processes that black box systems take to arrive\nat their outputs. In this article, we aim to defend the value of post-hoc\nexplanations against this recent critique. We argue that even if post-hoc\nexplanations do not replicate the exact reasoning processes of black box\nsystems, they can still improve users' functional understanding of black box\nsystems, increase the accuracy of clinician-AI teams, and assist clinicians in\njustifying their AI-informed decisions. While post-hoc explanations are not a\n\"silver bullet\" solution to the black box problem in medical AI, we conclude\nthat they remain a useful strategy for addressing the black box problem in\nmedical AI.", "published": "2025-04-29 13:24:21", "link": "http://arxiv.org/abs/2504.20741v1", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Unsupervised Surrogate Anomaly Detection", "abstract": "In this paper, we study unsupervised anomaly detection algorithms that learn\na neural network representation, i.e. regular patterns of normal data, which\nanomalies are deviating from. Inspired by a similar concept in engineering, we\nrefer to our methodology as surrogate anomaly detection. We formalize the\nconcept of surrogate anomaly detection into a set of axioms required for\noptimal surrogate models and propose a new algorithm, named DEAN (Deep Ensemble\nANomaly detection), designed to fulfill these criteria. We evaluate DEAN on 121\nbenchmark datasets, demonstrating its competitive performance against 19\nexisting methods, as well as the scalability and reliability of our method.", "published": "2025-04-29 13:15:55", "link": "http://arxiv.org/abs/2504.20733v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Enhancing Vulnerability Reports with Automated and Augmented Description Summarization", "abstract": "Public vulnerability databases, such as the National Vulnerability Database\n(NVD), document vulnerabilities and facilitate threat information sharing.\nHowever, they often suffer from short descriptions and outdated or insufficient\ninformation. In this paper, we introduce Zad, a system designed to enrich NVD\nvulnerability descriptions by leveraging external resources. Zad consists of\ntwo pipelines: one collects and filters supplementary data using two encoders\nto build a detailed dataset, while the other fine-tunes a pre-trained model on\nthis dataset to generate enriched descriptions. By addressing brevity and\nimproving content quality, Zad produces more comprehensive and cohesive\nvulnerability descriptions. We evaluate Zad using standard summarization\nmetrics and human assessments, demonstrating its effectiveness in enhancing\nvulnerability information.", "published": "2025-04-29 13:08:27", "link": "http://arxiv.org/abs/2504.20726v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "The Limits of AI Explainability: An Algorithmic Information Theory Approach", "abstract": "This paper establishes a theoretical foundation for understanding the\nfundamental limits of AI explainability through algorithmic information theory.\nWe formalize explainability as the approximation of complex models by simpler\nones, quantifying both approximation error and explanation complexity using\nKolmogorov complexity. Our key theoretical contributions include: (1) a\ncomplexity gap theorem proving that any explanation significantly simpler than\nthe original model must differ from it on some inputs; (2) precise bounds\nshowing that explanation complexity grows exponentially with input dimension\nbut polynomially with error tolerance for Lipschitz functions; and (3) a\ncharacterization of the gap between local and global explainability,\ndemonstrating that local explanations can be significantly simpler while\nmaintaining accuracy in relevant regions. We further establish a regulatory\nimpossibility theorem proving that no governance framework can simultaneously\npursue unrestricted AI capabilities, human-interpretable explanations, and\nnegligible error. These results highlight considerations likely to be relevant\nto the design, evaluation, and oversight of explainable AI systems.", "published": "2025-04-29 11:58:37", "link": "http://arxiv.org/abs/2504.20676v1", "categories": ["cs.AI", "cs.CY", "cs.IT", "math.IT", "68Q30, 68T01", "I.2.0; H.1.1; K.4.1"], "primary_category": "cs.AI"}
{"title": "CoCo-Bench: A Comprehensive Code Benchmark For Multi-task Large Language Model Evaluation", "abstract": "Large language models (LLMs) play a crucial role in software engineering,\nexcelling in tasks like code generation and maintenance. However, existing\nbenchmarks are often narrow in scope, focusing on a specific task and lack a\ncomprehensive evaluation framework that reflects real-world applications. To\naddress these gaps, we introduce CoCo-Bench (Comprehensive Code Benchmark),\ndesigned to evaluate LLMs across four critical dimensions: code understanding,\ncode generation, code modification, and code review. These dimensions capture\nessential developer needs, ensuring a more systematic and representative\nevaluation. CoCo-Bench includes multiple programming languages and varying task\ndifficulties, with rigorous manual review to ensure data quality and accuracy.\nEmpirical results show that CoCo-Bench aligns with existing benchmarks while\nuncovering significant variations in model performance, effectively\nhighlighting strengths and weaknesses. By offering a holistic and objective\nevaluation, CoCo-Bench provides valuable insights to guide future research and\ntechnological advancements in code-oriented LLMs, establishing a reliable\nbenchmark for the field.", "published": "2025-04-29 11:57:23", "link": "http://arxiv.org/abs/2504.20673v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Advance Fake Video Detection via Vision Transformers", "abstract": "Recent advancements in AI-based multimedia generation have enabled the\ncreation of hyper-realistic images and videos, raising concerns about their\npotential use in spreading misinformation. The widespread accessibility of\ngenerative techniques, which allow for the production of fake multimedia from\nprompts or existing media, along with their continuous refinement, underscores\nthe urgent need for highly accurate and generalizable AI-generated media\ndetection methods, underlined also by new regulations like the European Digital\nAI Act. In this paper, we draw inspiration from Vision Transformer (ViT)-based\nfake image detection and extend this idea to video. We propose an {original}\n%innovative framework that effectively integrates ViT embeddings over time to\nenhance detection performance. Our method shows promising accuracy,\ngeneralization, and few-shot learning capabilities across a new, large and\ndiverse dataset of videos generated using five open source generative\ntechniques from the state-of-the-art, as well as a separate dataset containing\nvideos produced by proprietary generative methods.", "published": "2025-04-29 11:51:07", "link": "http://arxiv.org/abs/2504.20669v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "TrueFake: A Real World Case Dataset of Last Generation Fake Images also Shared on Social Networks", "abstract": "AI-generated synthetic media are increasingly used in real-world scenarios,\noften with the purpose of spreading misinformation and propaganda through\nsocial media platforms, where compression and other processing can degrade fake\ndetection cues. Currently, many forensic tools fail to account for these\nin-the-wild challenges. In this work, we introduce TrueFake, a large-scale\nbenchmarking dataset of 600,000 images including top notch generative\ntechniques and sharing via three different social networks. This dataset allows\nfor rigorous evaluation of state-of-the-art fake image detectors under very\nrealistic and challenging conditions. Through extensive experimentation, we\nanalyze how social media sharing impacts detection performance, and identify\ncurrent most effective detection and training strategies. Our findings\nhighlight the need for evaluating forensic models in conditions that mirror\nreal-world use.", "published": "2025-04-29 11:33:52", "link": "http://arxiv.org/abs/2504.20658v1", "categories": ["cs.MM", "cs.AI", "cs.CV"], "primary_category": "cs.MM"}
{"title": "Federated learning, ethics, and the double black box problem in medical AI", "abstract": "Federated learning (FL) is a machine learning approach that allows multiple\ndevices or institutions to collaboratively train a model without sharing their\nlocal data with a third-party. FL is considered a promising way to address\npatient privacy concerns in medical artificial intelligence. The ethical risks\nof medical FL systems themselves, however, have thus far been underexamined.\nThis paper aims to address this gap. We argue that medical FL presents a new\nvariety of opacity -- federation opacity -- that, in turn, generates a\ndistinctive double black box problem in healthcare AI. We highlight several\ninstances in which the anticipated benefits of medical FL may be exaggerated,\nand conclude by highlighting key challenges that must be overcome to make FL\nethically feasible in medicine.", "published": "2025-04-29 11:31:48", "link": "http://arxiv.org/abs/2504.20656v1", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.LG"}
{"title": "SpaRE: Enhancing Spatial Reasoning in Vision-Language Models with Synthetic Data", "abstract": "Vision-language models (VLMs) work well in tasks ranging from image\ncaptioning to visual question answering (VQA), yet they struggle with spatial\nreasoning, a key skill for understanding our physical world that humans excel\nat. We find that spatial relations are generally rare in widely used VL\ndatasets, with only a few being well represented, while most form a long tail\nof underrepresented relations. This gap leaves VLMs ill-equipped to handle\ndiverse spatial relationships. To bridge it, we construct a synthetic VQA\ndataset focused on spatial reasoning generated from hyper-detailed image\ndescriptions in Localized Narratives, DOCCI, and PixMo-Cap. Our dataset\nconsists of 455k samples containing 3.4 million QA pairs. Trained on this\ndataset, our Spatial-Reasoning Enhanced (SpaRE) VLMs show strong improvements\non spatial reasoning benchmarks, achieving up to a 49% performance gain on the\nWhat's Up benchmark, while maintaining strong results on general tasks. Our\nwork narrows the gap between human and VLM spatial reasoning and makes VLMs\nmore capable in real-world tasks such as robotics and navigation.", "published": "2025-04-29 11:18:38", "link": "http://arxiv.org/abs/2504.20648v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "On Stochastic Rounding with Few Random Bits", "abstract": "Large-scale numerical computations make increasing use of low-precision (LP)\nfloating point formats and mixed precision arithmetic, which can be enhanced by\nthe technique of stochastic rounding (SR), that is, rounding an intermediate\nhigh-precision value up or down randomly as a function of the value's distance\nto the two rounding candidates. Stochastic rounding requires, in addition to\nthe high-precision input value, a source of random bits. As the provision of\nhigh-quality random bits is an additional computational cost, it is of interest\nto require as few bits as possible while maintaining the desirable properties\nof SR in a given computation, or computational domain. This paper examines a\nnumber of possible implementations of few-bit stochastic rounding (FBSR), and\nshows how several natural implementations can introduce sometimes significant\nbias into the rounding process, which are not present in the case of\ninfinite-bit, infinite-precision examinations of these implementations. The\npaper explores the impact of these biases in machine learning examples, and\nhence opens another class of configuration parameters of which practitioners\nshould be aware when developing or adopting low-precision floating point. Code\nis available at\nhttp://github.com/graphcore-research/arith25-stochastic-rounding.", "published": "2025-04-29 11:04:25", "link": "http://arxiv.org/abs/2504.20634v1", "categories": ["math.NA", "cs.AI", "cs.LG", "cs.MS", "cs.NA"], "primary_category": "math.NA"}
{"title": "AlignDiT: Multimodal Aligned Diffusion Transformer for Synchronized Speech Generation", "abstract": "In this paper, we address the task of multimodal-to-speech generation, which\naims to synthesize high-quality speech from multiple input modalities: text,\nvideo, and reference audio. This task has gained increasing attention due to\nits wide range of applications, such as film production, dubbing, and virtual\navatars. Despite recent progress, existing methods still suffer from\nlimitations in speech intelligibility, audio-video synchronization, speech\nnaturalness, and voice similarity to the reference speaker. To address these\nchallenges, we propose AlignDiT, a multimodal Aligned Diffusion Transformer\nthat generates accurate, synchronized, and natural-sounding speech from aligned\nmultimodal inputs. Built upon the in-context learning capability of the DiT\narchitecture, AlignDiT explores three effective strategies to align multimodal\nrepresentations. Furthermore, we introduce a novel multimodal classifier-free\nguidance mechanism that allows the model to adaptively balance information from\neach modality during speech synthesis. Extensive experiments demonstrate that\nAlignDiT significantly outperforms existing methods across multiple benchmarks\nin terms of quality, synchronization, and speaker similarity. Moreover,\nAlignDiT exhibits strong generalization capability across various multimodal\ntasks, such as video-to-speech synthesis and visual forced alignment,\nconsistently achieving state-of-the-art performance. The demo page is available\nat https://mm.kaist.ac.kr/projects/AlignDiT .", "published": "2025-04-29 10:56:24", "link": "http://arxiv.org/abs/2504.20629v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Cognitive maps are generative programs", "abstract": "Making sense of the world and acting in it relies on building simplified\nmental representations that abstract away aspects of reality. This principle of\ncognitive mapping is universal to agents with limited resources. Living\norganisms, people, and algorithms all face the problem of forming functional\nrepresentations of their world under various computing constraints. In this\nwork, we explore the hypothesis that human resource-efficient planning may\narise from representing the world as predictably structured. Building on the\nmetaphor of concepts as programs, we propose that cognitive maps can take the\nform of generative programs that exploit predictability and redundancy, in\ncontrast to directly encoding spatial layouts. We use a behavioral experiment\nto show that people who navigate in structured spaces rely on modular planning\nstrategies that align with programmatic map representations. We describe a\ncomputational model that predicts human behavior in a variety of structured\nscenarios. This model infers a small distribution over possible programmatic\ncognitive maps conditioned on human prior knowledge of the world, and uses this\ndistribution to generate resource-efficient plans. Our models leverages a Large\nLanguage Model as an embedding of human priors, implicitly learned through\ntraining on a vast corpus of human data. Our model demonstrates improved\ncomputational efficiency, requires drastically less memory, and outperforms\nunstructured planning algorithms with cognitive constraints at predicting human\nbehavior, suggesting that human planning strategies rely on programmatic\ncognitive maps.", "published": "2025-04-29 10:55:40", "link": "http://arxiv.org/abs/2504.20628v1", "categories": ["cs.AI", "cs.ET"], "primary_category": "cs.AI"}
{"title": "DiffusionRIR: Room Impulse Response Interpolation using Diffusion Models", "abstract": "Room Impulse Responses (RIRs) characterize acoustic environments and are\ncrucial in multiple audio signal processing tasks. High-quality RIR estimates\ndrive applications such as virtual microphones, sound source localization,\naugmented reality, and data augmentation. However, obtaining RIR measurements\nwith high spatial resolution is resource-intensive, making it impractical for\nlarge spaces or when dense sampling is required. This research addresses the\nchallenge of estimating RIRs at unmeasured locations within a room using\nDenoising Diffusion Probabilistic Models (DDPM). Our method leverages the\nanalogy between RIR matrices and image inpainting, transforming RIR data into a\nformat suitable for diffusion-based reconstruction.\n  Using simulated RIR data based on the image method, we demonstrate our\napproach's effectiveness on microphone arrays of different curvatures, from\nlinear to semi-circular. Our method successfully reconstructs missing RIRs,\neven in large gaps between microphones. Under these conditions, it achieves\naccurate reconstruction, significantly outperforming baseline Spline Cubic\nInterpolation in terms of Normalized Mean Square Error and Cosine Distance\nbetween actual and interpolated RIRs.\n  This research highlights the potential of using generative models for\neffective RIR interpolation, paving the way for generating additional data from\nlimited real-world measurements.", "published": "2025-04-29 10:52:07", "link": "http://arxiv.org/abs/2504.20625v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval", "abstract": "Social chatbots have become essential intelligent companions in daily\nscenarios ranging from emotional support to personal interaction. However,\nconventional chatbots with passive response mechanisms usually rely on users to\ninitiate or sustain dialogues by bringing up new topics, resulting in\ndiminished engagement and shortened dialogue duration. In this paper, we\npresent PaRT, a novel framework enabling context-aware proactive dialogues for\nsocial chatbots through personalized real-time retrieval and generation.\nSpecifically, PaRT first integrates user profiles and dialogue context into a\nlarge language model (LLM), which is initially prompted to refine user queries\nand recognize their underlying intents for the upcoming conversation. Guided by\nrefined intents, the LLM generates personalized dialogue topics, which then\nserve as targeted queries to retrieve relevant passages from RedNote. Finally,\nwe prompt LLMs with summarized passages to generate knowledge-grounded and\nengagement-optimized responses. Our approach has been running stably in a\nreal-world production environment for more than 30 days, achieving a 21.77\\%\nimprovement in the average duration of dialogues.", "published": "2025-04-29 10:51:58", "link": "http://arxiv.org/abs/2504.20624v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models", "abstract": "The rapid advancement of Large Language Models (LLMs) has enhanced software\ndevelopment processes, minimizing the time and effort required for coding and\nenhancing developer productivity. However, despite their potential benefits,\ncode generated by LLMs has been shown to generate insecure code in controlled\nenvironments, raising critical concerns about their reliability and security in\nreal-world applications. This paper uses predefined security parameters to\nevaluate the security compliance of LLM-generated code across multiple models,\nsuch as ChatGPT, DeepSeek, Claude, Gemini and Grok. The analysis reveals\ncritical vulnerabilities in authentication mechanisms, session management,\ninput validation and HTTP security headers. Although some models implement\nsecurity measures to a limited extent, none fully align with industry best\npractices, highlighting the associated risks in automated software development.\nOur findings underscore that human expertise is crucial to ensure secure\nsoftware deployment or review of LLM-generated code. Also, there is a need for\nrobust security assessment frameworks to enhance the reliability of\nLLM-generated code in real-world applications.", "published": "2025-04-29 10:23:11", "link": "http://arxiv.org/abs/2504.20612v1", "categories": ["cs.CR", "cs.AI", "cs.ET"], "primary_category": "cs.CR"}
{"title": "Information Retrieval in the Age of Generative AI: The RGB Model", "abstract": "The advent of Large Language Models (LLMs) and generative AI is fundamentally\ntransforming information retrieval and processing on the Internet, bringing\nboth great potential and significant concerns regarding content authenticity\nand reliability. This paper presents a novel quantitative approach to shed\nlight on the complex information dynamics arising from the growing use of\ngenerative AI tools. Despite their significant impact on the digital ecosystem,\nthese dynamics remain largely uncharted and poorly understood. We propose a\nstochastic model to characterize the generation, indexing, and dissemination of\ninformation in response to new topics. This scenario particularly challenges\ncurrent LLMs, which often rely on real-time Retrieval-Augmented Generation\n(RAG) techniques to overcome their static knowledge limitations. Our findings\nsuggest that the rapid pace of generative AI adoption, combined with increasing\nuser reliance, can outpace human verification, escalating the risk of\ninaccurate information proliferation across digital resources. An in-depth\nanalysis of Stack Exchange data confirms that high-quality answers inevitably\nrequire substantial time and human effort to emerge. This underscores the\nconsiderable risks associated with generating persuasive text in response to\nnew questions and highlights the critical need for responsible development and\ndeployment of future generative AI tools.", "published": "2025-04-29 10:21:40", "link": "http://arxiv.org/abs/2504.20610v1", "categories": ["cs.IR", "cs.AI", "cs.PF"], "primary_category": "cs.IR"}
{"title": "Inclusive Training Separation and Implicit Knowledge Interaction for Balanced Online Class-Incremental Learning", "abstract": "Online class-incremental learning (OCIL) focuses on gradually learning new\nclasses (called plasticity) from a stream of data in a single-pass, while\nconcurrently preserving knowledge of previously learned classes (called\nstability). The primary challenge in OCIL lies in maintaining a good balance\nbetween the knowledge of old and new classes within the continually updated\nmodel. Most existing methods rely on explicit knowledge interaction through\nexperience replay, and often employ exclusive training separation to address\nbias problems. Nevertheless, it still remains a big challenge to achieve a\nwell-balanced learner, as these methods often exhibit either reduced plasticity\nor limited stability due to difficulties in continually integrating knowledge\nin the OCIL setting. In this paper, we propose a novel replay-based method,\ncalled Balanced Online Incremental Learning (BOIL), which can achieve both high\nplasticity and stability, thus ensuring more balanced performance in OCIL. Our\nBOIL method proposes an inclusive training separation strategy using dual\nclassifiers so that knowledge from both old and new classes can effectively be\nintegrated into the model, while introducing implicit approaches for\ntransferring knowledge across the two classifiers. Extensive experimental\nevaluations over three widely-used OCIL benchmark datasets demonstrate the\nsuperiority of BOIL, showing more balanced yet better performance compared to\nstate-of-the-art replay-based OCIL methods.", "published": "2025-04-29 09:13:00", "link": "http://arxiv.org/abs/2504.20566v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Generate more than one child in your co-evolutionary semi-supervised learning GAN", "abstract": "Generative Adversarial Networks (GANs) are very useful methods to address\nsemi-supervised learning (SSL) datasets, thanks to their ability to generate\nsamples similar to real data. This approach, called SSL-GAN has attracted many\nresearchers in the last decade. Evolutionary algorithms have been used to guide\nthe evolution and training of SSL-GANs with great success. In particular,\nseveral co-evolutionary approaches have been applied where the two networks of\na GAN (the generator and the discriminator) are evolved in separate\npopulations. The co-evolutionary approaches published to date assume some\nspatial structure of the populations, based on the ideas of cellular\nevolutionary algorithms. They also create one single individual per generation\nand follow a generational replacement strategy in the evolution. In this paper,\nwe re-consider those algorithmic design decisions and propose a new\nco-evolutionary approach, called Co-evolutionary Elitist SSL-GAN (CE-SSLGAN),\nwith panmictic population, elitist replacement, and more than one individual in\nthe offspring. We evaluate the performance of our proposed method using three\nstandard benchmark datasets. The results show that creating more than one\noffspring per population and using elitism improves the results in comparison\nwith a classical SSL-GAN.", "published": "2025-04-29 09:04:22", "link": "http://arxiv.org/abs/2504.20560v1", "categories": ["cs.NE", "cs.AI", "cs.LG"], "primary_category": "cs.NE"}
{"title": "PRISM: Projection-based Reward Integration for Scene-Aware Real-to-Sim-to-Real Transfer with Few Demonstrations", "abstract": "Learning from few demonstrations to develop policies robust to variations in\nrobot initial positions and object poses is a problem of significant practical\ninterest in robotics. Compared to imitation learning, which often struggles to\ngeneralize from limited samples, reinforcement learning (RL) can autonomously\nexplore to obtain robust behaviors. Training RL agents through direct\ninteraction with the real world is often impractical and unsafe, while building\nsimulation environments requires extensive manual effort, such as designing\nscenes and crafting task-specific reward functions. To address these\nchallenges, we propose an integrated real-to-sim-to-real pipeline that\nconstructs simulation environments based on expert demonstrations by\nidentifying scene objects from images and retrieving their corresponding 3D\nmodels from existing libraries. We introduce a projection-based reward model\nfor RL policy training that is supervised by a vision-language model (VLM)\nusing human-guided object projection relationships as prompts, with the policy\nfurther fine-tuned using expert demonstrations. In general, our work focuses on\nthe construction of simulation environments and RL-based policy training,\nultimately enabling the deployment of reliable robotic control policies in\nreal-world scenarios.", "published": "2025-04-29 08:01:27", "link": "http://arxiv.org/abs/2504.20520v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "MuRAL: A Multi-Resident Ambient Sensor Dataset Annotated with Natural Language for Activities of Daily Living", "abstract": "Recent advances in Large Language Models (LLMs) have shown promising\npotential for human activity recognition (HAR) using ambient sensors,\nespecially through natural language reasoning and zero-shot learning. However,\nexisting datasets such as CASAS, ARAS, and MARBLE were not originally designed\nwith LLMs in mind and therefore lack the contextual richness, complexity, and\nannotation granularity required to fully exploit LLM capabilities. In this\npaper, we introduce MuRAL, the first Multi-Resident Ambient sensor dataset with\nnatural Language, comprising over 21 hours of multi-user sensor data collected\nfrom 21 sessions in a smart-home environment. MuRAL is annotated with\nfine-grained natural language descriptions, resident identities, and high-level\nactivity labels, all situated in dynamic, realistic multi-resident settings. We\nbenchmark MuRAL using state-of-the-art LLMs for three core tasks: subject\nassignment, action description, and activity classification. Our results\ndemonstrate that while LLMs can provide rich semantic interpretations of\nambient data, current models still face challenges in handling multi-user\nambiguity and under-specified sensor contexts. We release MuRAL to support\nfuture research on LLM-powered, explainable, and socially aware activity\nunderstanding in smart environments. For access to the dataset, please reach\nout to us via the provided contact information. A direct link for dataset\nretrieval will be made available at this location in due course.", "published": "2025-04-29 07:46:14", "link": "http://arxiv.org/abs/2504.20505v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression", "abstract": "While reasoning large language models (LLMs) demonstrate remarkable\nperformance across various tasks, they also contain notable security\nvulnerabilities. Recent research has uncovered a \"thinking-stopped\"\nvulnerability in DeepSeek-R1, where model-generated reasoning tokens can\nforcibly interrupt the inference process, resulting in empty responses that\ncompromise LLM-integrated applications. However, existing methods triggering\nthis vulnerability require complex mathematical word problems with long\nprompts--even exceeding 5,000 tokens. To reduce the token cost and formally\ndefine this vulnerability, we propose a novel prompt injection attack named\n\"Reasoning Interruption Attack\", based on adaptive token compression. We\ndemonstrate that simple standalone arithmetic tasks can effectively trigger\nthis vulnerability, and the prompts based on such tasks exhibit simpler logical\nstructures than mathematical word problems. We develop a systematic approach to\nefficiently collect attack prompts and an adaptive token compression framework\nthat utilizes LLMs to automatically compress these prompts. Experiments show\nour compression framework significantly reduces prompt length while maintaining\neffective attack capabilities. We further investigate the attack's performance\nvia output prefix and analyze the underlying causes of the vulnerability,\nproviding valuable insights for improving security in reasoning LLMs.", "published": "2025-04-29 07:34:22", "link": "http://arxiv.org/abs/2504.20493v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Group Relative Knowledge Distillation: Learning from Teacher's Relational Inductive Bias", "abstract": "Knowledge distillation typically transfers knowledge from a teacher model to\na student model by minimizing differences between their output distributions.\nHowever, existing distillation approaches largely focus on mimicking absolute\nprobabilities and neglect the valuable relational inductive biases embedded in\nthe teacher's relative predictions, leading to exposure bias. In this paper, we\npropose Group Relative Knowledge Distillation (GRKD), a novel framework that\ndistills teacher knowledge by learning the relative ranking among classes,\nrather than directly fitting the absolute distribution. Specifically, we\nintroduce a group relative loss that encourages the student model to preserve\nthe pairwise preference orderings provided by the teacher's outputs. Extensive\nexperiments on classification benchmarks demonstrate that GRKD achieves\nsuperior generalization compared to existing methods, especially in tasks\nrequiring fine-grained class differentiation. Our method provides a new\nperspective on exploiting teacher knowledge, focusing on relational structure\nrather than absolute likelihood.", "published": "2025-04-29 07:23:22", "link": "http://arxiv.org/abs/2504.20482v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "The Estimation of Continual Causal Effect for Dataset Shifting Streams", "abstract": "Causal effect estimation has been widely used in marketing optimization. The\nframework of an uplift model followed by a constrained optimization algorithm\nis popular in practice. To enhance performance in the online environment, the\nframework needs to be improved to address the complexities caused by temporal\ndataset shift. This paper focuses on capturing the dataset shift from user\nbehavior and domain distribution changing over time. We propose an Incremental\nCausal Effect with Proxy Knowledge Distillation (ICE-PKD) framework to tackle\nthis challenge. The ICE-PKD framework includes two components: (i) a\nmulti-treatment uplift network that eliminates confounding bias using\ncounterfactual regression; (ii) an incremental training strategy that adapts to\nthe temporal dataset shift by updating with the latest data and protects\ngeneralization via replay-based knowledge distillation. We also revisit the\nuplift modeling metrics and introduce a novel metric for more precise online\nevaluation in multiple treatment scenarios. Extensive experiments on both\nsimulated and online datasets show that the proposed framework achieves better\nperformance. The ICE-PKD framework has been deployed in the marketing system of\nHuaxiaozhu, a ride-hailing platform in China.", "published": "2025-04-29 07:13:28", "link": "http://arxiv.org/abs/2504.20471v1", "categories": ["cs.LG", "cs.AI", "stat.ME"], "primary_category": "cs.LG"}
{"title": "A Summary on GUI Agents with Foundation Models Enhanced by Reinforcement Learning", "abstract": "Graphical User Interface (GUI) agents, driven by Multi-modal Large Language\nModels (MLLMs), have emerged as a promising paradigm for enabling intelligent\ninteraction with digital systems. This paper provides a structured summary of\nrecent advances in GUI agents, focusing on architectures enhanced by\nReinforcement Learning (RL). We first formalize GUI agent tasks as Markov\nDecision Processes and discuss typical execution environments and evaluation\nmetrics. We then review the modular architecture of (M)LLM-based GUI agents,\ncovering Perception, Planning, and Acting modules, and trace their evolution\nthrough representative works. Furthermore, we categorize GUI agent training\nmethodologies into Prompt-based, Supervised Fine-Tuning (SFT)-based, and\nRL-based approaches, highlighting the progression from simple prompt\nengineering to dynamic policy learning via RL. Our summary illustrates how\nrecent innovations in multimodal perception, decision reasoning, and adaptive\naction generation have significantly improved the generalization and robustness\nof GUI agents in complex real-world environments. We conclude by identifying\nkey challenges and future directions for building more capable and reliable GUI\nagents.", "published": "2025-04-29 06:55:15", "link": "http://arxiv.org/abs/2504.20464v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with Multi-Modality Observation Data", "abstract": "With the development of distributed systems, microservices and cloud native\ntechnologies have become central to modern enterprise software development.\nDespite bringing significant advantages, these technologies also increase\nsystem complexity and operational challenges. Traditional root cause analysis\n(RCA) struggles to achieve automated fault response, heavily relying on manual\nintervention. In recent years, large language models (LLMs) have made\nbreakthroughs in contextual inference and domain knowledge integration,\nproviding new solutions for Artificial Intelligence for Operations (AIOps).\nHowever, Existing LLM-based approaches face three key challenges: text input\nconstraints, dynamic service dependency hallucinations, and context window\nlimitations. To address these issues, we propose a tool-assisted LLM agent with\nmulti-modality observation data, namely TAMO, for fine-grained RCA. It unifies\nmulti-modal observational data into time-aligned representations to extract\nconsistent features and employs specialized root cause localization and fault\nclassification tools for perceiving the contextual environment. This approach\novercomes the limitations of LLM in handling real-time changing service\ndependencies and raw observational data and guides LLM to generate repair\nstrategies aligned with system contexts by structuring key information into a\nprompt. Experimental results show that TAMO performs well in root cause\nanalysis when dealing with public datasets characterized by heterogeneity and\ncommon fault types, demonstrating its effectiveness.", "published": "2025-04-29 06:50:48", "link": "http://arxiv.org/abs/2504.20462v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Enhancing News Recommendation with Hierarchical LLM Prompting", "abstract": "Personalized news recommendation systems often struggle to effectively\ncapture the complexity of user preferences, as they rely heavily on shallow\nrepresentations, such as article titles and abstracts. To address this problem,\nwe introduce a novel method, namely PNR-LLM, for Large Language Models for\nPersonalized News Recommendation. Specifically, PNR-LLM harnesses the\ngeneration capabilities of LLMs to enrich news titles and abstracts, and\nconsequently improves recommendation quality. PNR-LLM contains a novel module,\nNews Enrichment via LLMs, which generates deeper semantic information and\nrelevant entities from articles, transforming shallow contents into richer\nrepresentations. We further propose an attention mechanism to aggregate\nenriched semantic- and entity-level data, forming unified user and news\nembeddings that reveal a more accurate user-news match. Extensive experiments\non MIND datasets show that PNR-LLM outperforms state-of-the-art baselines.\nMoreover, the proposed data enrichment module is model-agnostic, and we\nempirically show that applying our proposed module to multiple existing models\ncan further improve their performance, verifying the advantage of our design.", "published": "2025-04-29 06:02:16", "link": "http://arxiv.org/abs/2504.20452v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "APG-MOS: Auditory Perception Guided-MOS Predictor for Synthetic Speech", "abstract": "Automatic speech quality assessment aims to quantify subjective human\nperception of speech through computational models to reduce the need for\nlabor-consuming manual evaluations. While models based on deep learning have\nachieved progress in predicting mean opinion scores (MOS) to assess synthetic\nspeech, the neglect of fundamental auditory perception mechanisms limits\nconsistency with human judgments. To address this issue, we propose an auditory\nperception guided-MOS prediction model (APG-MOS) that synergistically\nintegrates auditory modeling with semantic analysis to enhance consistency with\nhuman judgments. Specifically, we first design a perceptual module, grounded in\nbiological auditory mechanisms, to simulate cochlear functions, which encodes\nacoustic signals into biologically aligned electrochemical representations.\nSecondly, we propose a residual vector quantization (RVQ)-based semantic\ndistortion modeling method to quantify the degradation of speech quality at the\nsemantic level. Finally, we design a residual cross-attention architecture,\ncoupled with a progressive learning strategy, to enable multimodal fusion of\nencoded electrochemical signals and semantic representations. Experiments\ndemonstrate that APG-MOS achieves superior performance on two primary\nbenchmarks. Our code and checkpoint will be available on a public repository\nupon publication.", "published": "2025-04-29 05:45:09", "link": "http://arxiv.org/abs/2504.20447v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Head-Tail-Aware KL Divergence in Knowledge Distillation for Spiking Neural Networks", "abstract": "Spiking Neural Networks (SNNs) have emerged as a promising approach for\nenergy-efficient and biologically plausible computation. However, due to\nlimitations in existing training methods and inherent model constraints, SNNs\noften exhibit a performance gap when compared to Artificial Neural Networks\n(ANNs). Knowledge distillation (KD) has been explored as a technique to\ntransfer knowledge from ANN teacher models to SNN student models to mitigate\nthis gap. Traditional KD methods typically use Kullback-Leibler (KL) divergence\nto align output distributions. However, conventional KL-based approaches fail\nto fully exploit the unique characteristics of SNNs, as they tend to\noveremphasize high-probability predictions while neglecting low-probability\nones, leading to suboptimal generalization. To address this, we propose\nHead-Tail Aware Kullback-Leibler (HTA-KL) divergence, a novel KD method for\nSNNs. HTA-KL introduces a cumulative probability-based mask to dynamically\ndistinguish between high- and low-probability regions. It assigns adaptive\nweights to ensure balanced knowledge transfer, enhancing the overall\nperformance. By integrating forward KL (FKL) and reverse KL (RKL) divergence,\nour method effectively align both head and tail regions of the distribution. We\nevaluate our methods on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets. Our\nmethod outperforms existing methods on most datasets with fewer timesteps.", "published": "2025-04-29 05:36:32", "link": "http://arxiv.org/abs/2504.20445v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "GaLore 2: Large-Scale LLM Pre-Training by Gradient Low-Rank Projection", "abstract": "Large language models (LLMs) have revolutionized natural language\nunderstanding and generation but face significant memory bottlenecks during\ntraining. GaLore, Gradient Low-Rank Projection, addresses this issue by\nleveraging the inherent low-rank structure of weight gradients, enabling\nsubstantial memory savings without sacrificing performance. Recent works\nfurther extend GaLore from various aspects, including low-bit quantization and\nhigher-order tensor structures. However, there are several remaining challenges\nfor GaLore, such as the computational overhead of SVD for subspace updates and\nthe integration with state-of-the-art training parallelization strategies\n(e.g., FSDP). In this paper, we present GaLore 2, an efficient and scalable\nGaLore framework that addresses these challenges and incorporates recent\nadvancements. In addition, we demonstrate the scalability of GaLore 2 by\npre-training Llama 7B from scratch using up to 500 billion training tokens,\nhighlighting its potential impact on real LLM pre-training scenarios.", "published": "2025-04-29 05:27:02", "link": "http://arxiv.org/abs/2504.20437v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ARCS: Agentic Retrieval-Augmented Code Synthesis with Iterative Refinement", "abstract": "In supercomputing, efficient and optimized code generation is essential to\nleverage high-performance systems effectively. We propose Agentic\nRetrieval-Augmented Code Synthesis (ARCS), an advanced framework for accurate,\nrobust, and efficient code generation, completion, and translation. ARCS\nintegrates Retrieval-Augmented Generation (RAG) with Chain-of-Thought (CoT)\nreasoning to systematically break down and iteratively refine complex\nprogramming tasks. An agent-based RAG mechanism retrieves relevant code\nsnippets, while real-time execution feedback drives the synthesis of candidate\nsolutions. This process is formalized as a state-action search tree\noptimization, balancing code correctness with editing efficiency. Evaluations\non the Geeks4Geeks and HumanEval benchmarks demonstrate that ARCS significantly\noutperforms traditional prompting methods in translation and generation\nquality. By enabling scalable and precise code synthesis, ARCS offers\ntransformative potential for automating and optimizing code development in\nsupercomputing applications, enhancing computational resource utilization.", "published": "2025-04-29 05:15:52", "link": "http://arxiv.org/abs/2504.20434v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "RV-Syn: Rational and Verifiable Mathematical Reasoning Data Synthesis based on Structured Function Library", "abstract": "The advancement of reasoning capabilities in Large Language Models (LLMs)\nrequires substantial amounts of high-quality reasoning data, particularly in\nmathematics. Existing data synthesis methods, such as data augmentation from\nannotated training sets or direct question generation based on relevant\nknowledge points and documents, have expanded datasets but face challenges in\nmastering the inner logic of the problem during generation and ensuring the\nverifiability of the solutions. To address these issues, we propose RV-Syn, a\nnovel Rational and Verifiable mathematical Synthesis approach. RV-Syn\nconstructs a structured mathematical operation function library based on\ninitial seed problems and generates computational graphs as solutions by\ncombining Python-formatted functions from this library. These graphs are then\nback-translated into complex problems. Based on the constructed computation\ngraph, we achieve solution-guided logic-aware problem generation. Furthermore,\nthe executability of the computational graph ensures the verifiability of the\nsolving process. Experimental results show that RV-Syn surpasses existing\nsynthesis methods, including those involving human-generated problems,\nachieving greater efficient data scaling. This approach provides a scalable\nframework for generating high-quality reasoning datasets.", "published": "2025-04-29 04:42:02", "link": "http://arxiv.org/abs/2504.20426v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "CrashFixer: A crash resolution agent for the Linux kernel", "abstract": "Code large language models (LLMs) have shown impressive capabilities on a\nmultitude of software engineering tasks. In particular, they have demonstrated\nremarkable utility in the task of code repair. However, common benchmarks used\nto evaluate the performance of code LLMs are often limited to small-scale\nsettings. In this work, we build upon kGym, which shares a benchmark for\nsystem-level Linux kernel bugs and a platform to run experiments on the Linux\nkernel.\n  This paper introduces CrashFixer, the first LLM-based software repair agent\nthat is applicable to Linux kernel bugs. Inspired by the typical workflow of a\nkernel developer, we identify the key capabilities an expert developer\nleverages to resolve a kernel crash. Using this as our guide, we revisit the\nkGym platform and identify key system improvements needed to practically run\nLLM-based agents at the scale of the Linux kernel (50K files and 20M lines of\ncode). We implement these changes by extending kGym to create an improved\nplatform - called kGymSuite, which will be open-sourced. Finally, the paper\npresents an evaluation of various repair strategies for such complex kernel\nbugs and showcases the value of explicitly generating a hypothesis before\nattempting to fix bugs in complex systems such as the Linux kernel. We also\nevaluated CrashFixer's capabilities on still open bugs, and found at least two\npatch suggestions considered plausible to resolve the reported bug.", "published": "2025-04-29 04:18:51", "link": "http://arxiv.org/abs/2504.20412v1", "categories": ["cs.SE", "cs.AI", "cs.OS"], "primary_category": "cs.SE"}
{"title": "FourierSpecNet: Neural Collision Operator Approximation Inspired by the Fourier Spectral Method for Solving the Boltzmann Equation", "abstract": "The Boltzmann equation, a fundamental model in kinetic theory, describes the\nevolution of particle distribution functions through a nonlinear,\nhigh-dimensional collision operator. However, its numerical solution remains\ncomputationally demanding, particularly for inelastic collisions and\nhigh-dimensional velocity domains. In this work, we propose the Fourier Neural\nSpectral Network (FourierSpecNet), a hybrid framework that integrates the\nFourier spectral method with deep learning to approximate the collision\noperator in Fourier space efficiently. FourierSpecNet achieves\nresolution-invariant learning and supports zero-shot super-resolution, enabling\naccurate predictions at unseen resolutions without retraining. Beyond empirical\nvalidation, we establish a consistency result showing that the trained operator\nconverges to the spectral solution as the discretization is refined. We\nevaluate our method on several benchmark cases, including Maxwellian and\nhard-sphere molecular models, as well as inelastic collision scenarios. The\nresults demonstrate that FourierSpecNet offers competitive accuracy while\nsignificantly reducing computational cost compared to traditional spectral\nsolvers. Our approach provides a robust and scalable alternative for solving\nthe Boltzmann equation across both elastic and inelastic regimes.", "published": "2025-04-29 04:07:03", "link": "http://arxiv.org/abs/2504.20408v1", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "physics.comp-ph", "68T20, 35Q20, 35B40, 82C40"], "primary_category": "cs.LG"}
{"title": "Skill Discovery for Software Scripting Automation via Offline Simulations with LLMs", "abstract": "Scripting interfaces enable users to automate tasks and customize software\nworkflows, but creating scripts traditionally requires programming expertise\nand familiarity with specific APIs, posing barriers for many users. While Large\nLanguage Models (LLMs) can generate code from natural language queries, runtime\ncode generation is severely limited due to unverified code, security risks,\nlonger response times, and higher computational costs. To bridge the gap, we\npropose an offline simulation framework to curate a software-specific skillset,\na collection of verified scripts, by exploiting LLMs and publicly available\nscripting guides. Our framework comprises two components: (1) task creation,\nusing top-down functionality guidance and bottom-up API synergy exploration to\ngenerate helpful tasks; and (2) skill generation with trials, refining and\nvalidating scripts based on execution feedback. To efficiently navigate the\nextensive API landscape, we introduce a Graph Neural Network (GNN)-based link\nprediction model to capture API synergy, enabling the generation of skills\ninvolving underutilized APIs and expanding the skillset's diversity.\nExperiments with Adobe Illustrator demonstrate that our framework significantly\nimproves automation success rates, reduces response time, and saves runtime\ntoken costs compared to traditional runtime code generation. This is the first\nattempt to use software scripting interfaces as a testbed for LLM-based\nsystems, highlighting the advantages of leveraging execution feedback in a\ncontrolled environment and offering valuable insights into aligning AI\ncapabilities with user needs in specialized software domains.", "published": "2025-04-29 04:03:37", "link": "http://arxiv.org/abs/2504.20406v1", "categories": ["cs.AI", "cs.SE"], "primary_category": "cs.AI"}
{"title": "SCOPE-MRI: Bankart Lesion Detection as a Case Study in Data Curation and Deep Learning for Challenging Diagnoses", "abstract": "While deep learning has shown strong performance in musculoskeletal imaging,\nexisting work has largely focused on pathologies where diagnosis is not a\nclinical challenge, leaving more difficult problems underexplored, such as\ndetecting Bankart lesions (anterior-inferior glenoid labral tears) on standard\nMRIs. Diagnosing these lesions is challenging due to their subtle imaging\nfeatures, often leading to reliance on invasive MRI arthrograms (MRAs). This\nstudy introduces ScopeMRI, the first publicly available, expert-annotated\ndataset for shoulder pathologies, and presents a deep learning (DL) framework\nfor detecting Bankart lesions on both standard MRIs and MRAs. ScopeMRI includes\n586 shoulder MRIs (335 standard, 251 MRAs) from 558 patients who underwent\narthroscopy. Ground truth labels were derived from intraoperative findings, the\ngold standard for diagnosis. Separate DL models for MRAs and standard MRIs were\ntrained using a combination of CNNs and transformers. Predictions from\nsagittal, axial, and coronal views were ensembled to optimize performance. The\nmodels were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71\nstandard MRIs). The models achieved an AUC of 0.91 and 0.93, sensitivity of 83%\nand 94%, and specificity of 91% and 86% for standard MRIs and MRAs,\nrespectively. Notably, model performance on non-invasive standard MRIs matched\nor surpassed radiologists interpreting MRAs. External validation demonstrated\ninitial generalizability across imaging protocols. This study demonstrates that\nDL models can achieve radiologist-level diagnostic performance on standard\nMRIs, reducing the need for invasive MRAs. By releasing ScopeMRI and a modular\ncodebase for training and evaluating deep learning models on 3D medical imaging\ndata, we aim to accelerate research in musculoskeletal imaging and support the\ndevelopment of new datasets for clinically challenging diagnostic tasks.", "published": "2025-04-29 04:02:44", "link": "http://arxiv.org/abs/2504.20405v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "AKIBoards: A Structure-Following Multiagent System for Predicting Acute Kidney Injury", "abstract": "Diagnostic reasoning entails a physician's local (mental) model based on an\nassumed or known shared perspective (global model) to explain patient\nobservations with evidence assigned towards a clinical assessment. But in\nseveral (complex) medical situations, multiple experts work together as a team\nto optimize health evaluation and decision-making by leveraging different\nperspectives. Such consensus-driven reasoning reflects individual knowledge\ncontributing toward a broader perspective on the patient. In this light, we\nintroduce STRUCture-following for Multiagent Systems (STRUC-MAS), a framework\nautomating the learning of these global models and their incorporation as prior\nbeliefs for agents in multiagent systems (MAS) to follow. We demonstrate proof\nof concept with a prosocial MAS application for predicting acute kidney\ninjuries (AKIs). In this case, we found that incorporating a global structure\nenabled multiple agents to achieve better performance (average precision, AP)\nin predicting AKI 48 hours before onset (structure-following-fine-tuned, SF-FT,\nAP=0.195; SF-FT-retrieval-augmented generation, SF-FT-RAG, AP=0.194) vs.\nbaseline (non-structure-following-FT, NSF-FT, AP=0.141; NSF-FT-RAG, AP=0.180)\nfor balanced precision-weighted-recall-weighted voting. Markedly, SF-FT agents\nwith higher recall scores reported lower confidence levels in the initial round\non true positive and false negative cases. But after explicit interactions,\ntheir confidence in their decisions increased (suggesting reinforced belief).\nIn contrast, the SF-FT agent with the lowest recall decreased its confidence in\ntrue positive and false negative cases (suggesting a new belief). This approach\nsuggests that learning and leveraging global structures in MAS is necessary\nprior to achieving competitive classification and diagnostic reasoning\nperformance.", "published": "2025-04-29 02:12:48", "link": "http://arxiv.org/abs/2504.20368v1", "categories": ["cs.MA", "cs.AI", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Automated Unit Test Case Generation: A Systematic Literature Review", "abstract": "Software is omnipresent within all factors of society. It is thus important\nto ensure that software are well tested to mitigate bad user experiences as\nwell as the potential for severe financial and human losses. Software testing\nis however expensive and absorbs valuable time and resources. As a result, the\nfield of automated software testing has grown of interest to researchers in\npast decades. In our review of present and past research papers, we have\nidentified an information gap in the areas of improvement for the Genetic\nAlgorithm and Particle Swarm Optimisation. A gap in knowledge in the current\nchallenges that face automated testing has also been identified. We therefore\npresent this systematic literature review in an effort to consolidate existing\nknowledge in regards to the evolutionary approaches as well as their\nimprovements and resulting limitations. These improvements include hybrid\nalgorithm combinations as well as interoperability with mutation testing and\nneural networks. We will also explore the main test criterion that are used in\nthese algorithms alongside the challenges currently faced in the field related\nto readability, mocking and more.", "published": "2025-04-29 01:50:06", "link": "http://arxiv.org/abs/2504.20357v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "CarbonCall: Sustainability-Aware Function Calling for Large Language Models on Edge Devices", "abstract": "Large Language Models (LLMs) enable real-time function calling in edge AI\nsystems but introduce significant computational overhead, leading to high power\nconsumption and carbon emissions. Existing methods optimize for performance\nwhile neglecting sustainability, making them inefficient for energy-constrained\nenvironments. We introduce CarbonCall, a sustainability-aware function-calling\nframework that integrates dynamic tool selection, carbon-aware execution, and\nquantized LLM adaptation. CarbonCall adjusts power thresholds based on\nreal-time carbon intensity forecasts and switches between model variants to\nsustain high tokens-per-second throughput under power constraints. Experiments\non an NVIDIA Jetson AGX Orin show that CarbonCall reduces carbon emissions by\nup to 52%, power consumption by 30%, and execution time by 30%, while\nmaintaining high efficiency.", "published": "2025-04-29 01:37:08", "link": "http://arxiv.org/abs/2504.20348v1", "categories": ["cs.PF", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.PF"}
{"title": "Narrative-Centered Emotional Reflection: Scaffolding Autonomous Emotional Literacy with AI", "abstract": "Reflexion is an AI-powered platform designed to enable structured emotional\nself-reflection at scale. By integrating real-time emotion detection, layered\nreflective prompting, and metaphorical storytelling generation, Reflexion\nempowers users to engage in autonomous emotional exploration beyond basic\nsentiment categorization. Grounded in theories of expressive writing, cognitive\nrestructuring, self-determination, and critical consciousness development, the\nsystem scaffolds a progressive journey from surface-level emotional recognition\ntoward value-aligned action planning. Initial pilot studies with diverse\nparticipants demonstrate positive outcomes in emotional articulation, cognitive\nreframing, and perceived psychological resilience. Reflexion represents a\npromising direction for scalable, theory-informed affective computing\ninterventions aimed at fostering emotional literacy and psychological growth\nacross educational, therapeutic, and public health contexts.", "published": "2025-04-29 01:24:46", "link": "http://arxiv.org/abs/2504.20342v1", "categories": ["cs.HC", "cs.AI", "cs.CY", "H.5.2; H.1.2"], "primary_category": "cs.HC"}
{"title": "A Picture is Worth a Thousand Prompts? Efficacy of Iterative Human-Driven Prompt Refinement in Image Regeneration Tasks", "abstract": "With AI-generated content becoming ubiquitous across the web, social media,\nand other digital platforms, it is vital to examine how such content are\ninspired and generated. The creation of AI-generated images often involves\nrefining the input prompt iteratively to achieve desired visual outcomes. This\nstudy focuses on the relatively underexplored concept of image regeneration\nusing AI, in which a human operator attempts to closely recreate a specific\ntarget image by iteratively refining their prompt. Image regeneration is\ndistinct from normal image generation, which lacks any predefined visual\nreference. A separate challenge lies in determining whether existing image\nsimilarity metrics (ISMs) can provide reliable, objective feedback in iterative\nworkflows, given that we do not fully understand if subjective human judgments\nof similarity align with these metrics. Consequently, we must first validate\ntheir alignment with human perception before assessing their potential as a\nfeedback mechanism in the iterative prompt refinement process. To address these\nresearch gaps, we present a structured user study evaluating how iterative\nprompt refinement affects the similarity of regenerated images relative to\ntheir targets, while also examining whether ISMs capture the same improvements\nperceived by human observers. Our findings suggest that incremental prompt\nadjustments substantially improve alignment, verified through both subjective\nevaluations and quantitative measures, underscoring the broader potential of\niterative workflows to enhance generative AI content creation across various\napplication domains.", "published": "2025-04-29 01:21:16", "link": "http://arxiv.org/abs/2504.20340v1", "categories": ["cs.AI", "cs.CV", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Leveraging Action Relational Structures for Integrated Learning and Planning", "abstract": "Recent advances in planning have explored using learning methods to help\nplanning. However, little attention has been given to adapting search\nalgorithms to work better with learning systems. In this paper, we introduce\npartial-space search, a new search space for classical planning that leverages\nthe relational structure of actions given by PDDL action schemas -- a structure\noverlooked by traditional planning approaches. Partial-space search provides a\nmore granular view of the search space and allows earlier pruning of poor\nactions compared to state-space search. To guide partial-space search, we\nintroduce action set heuristics that evaluate sets of actions in a state. We\ndescribe how to automatically convert existing heuristics into action set\nheuristics. We also train action set heuristics from scratch using large\ntraining datasets from partial-space search. Our new planner, LazyLifted,\nexploits our better integrated search and learning heuristics and outperforms\nthe state-of-the-art ML-based heuristic on IPC 2023 learning track (LT)\nbenchmarks. We also show the efficiency of LazyLifted on high-branching factor\ntasks and show that it surpasses LAMA in the combined IPC 2023 LT and\nhigh-branching factor benchmarks.", "published": "2025-04-29 00:10:14", "link": "http://arxiv.org/abs/2504.20318v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "X-Fusion: Introducing New Modality to Frozen Large Language Models", "abstract": "We propose X-Fusion, a framework that extends pretrained Large Language\nModels (LLMs) for multimodal tasks while preserving their language\ncapabilities. X-Fusion employs a dual-tower design with modality-specific\nweights, keeping the LLM's parameters frozen while integrating vision-specific\ninformation for both understanding and generation. Our experiments demonstrate\nthat X-Fusion consistently outperforms alternative architectures on both\nimage-to-text and text-to-image tasks. We find that incorporating\nunderstanding-focused data improves generation quality, reducing image data\nnoise enhances overall performance, and feature alignment accelerates\nconvergence for smaller models but has minimal impact on larger ones. Our\nfindings provide valuable insights into building efficient unified multimodal\nmodels.", "published": "2025-04-29 17:59:45", "link": "http://arxiv.org/abs/2504.20996v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TesserAct: Learning 4D Embodied World Models", "abstract": "This paper presents an effective approach for learning novel 4D embodied\nworld models, which predict the dynamic evolution of 3D scenes over time in\nresponse to an embodied agent's actions, providing both spatial and temporal\nconsistency. We propose to learn a 4D world model by training on RGB-DN (RGB,\nDepth, and Normal) videos. This not only surpasses traditional 2D models by\nincorporating detailed shape, configuration, and temporal changes into their\npredictions, but also allows us to effectively learn accurate inverse dynamic\nmodels for an embodied agent. Specifically, we first extend existing robotic\nmanipulation video datasets with depth and normal information leveraging\noff-the-shelf models. Next, we fine-tune a video generation model on this\nannotated dataset, which jointly predicts RGB-DN (RGB, Depth, and Normal) for\neach frame. We then present an algorithm to directly convert generated RGB,\nDepth, and Normal videos into a high-quality 4D scene of the world. Our method\nensures temporal and spatial coherence in 4D scene predictions from embodied\nscenarios, enables novel view synthesis for embodied environments, and\nfacilitates policy learning that significantly outperforms those derived from\nprior video-based world models.", "published": "2025-04-29 17:59:30", "link": "http://arxiv.org/abs/2504.20995v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "DS_FusionNet: Dynamic Dual-Stream Fusion with Bidirectional Knowledge Distillation for Plant Disease Recognition", "abstract": "Given the severe challenges confronting the global growth security of\neconomic crops, precise identification and prevention of plant diseases has\nemerged as a critical issue in artificial intelligence-enabled agricultural\ntechnology. To address the technical challenges in plant disease recognition,\nincluding small-sample learning, leaf occlusion, illumination variations, and\nhigh inter-class similarity, this study innovatively proposes a Dynamic\nDual-Stream Fusion Network (DS_FusionNet). The network integrates a\ndual-backbone architecture, deformable dynamic fusion modules, and\nbidirectional knowledge distillation strategy, significantly enhancing\nrecognition accuracy. Experimental results demonstrate that DS_FusionNet\nachieves classification accuracies exceeding 90% using only 10% of the\nPlantDisease and CIFAR-10 datasets, while maintaining 85% accuracy on the\ncomplex PlantWild dataset, exhibiting exceptional generalization capabilities.\nThis research not only provides novel technical insights for fine-grained image\nclassification but also establishes a robust foundation for precise\nidentification and management of agricultural diseases.", "published": "2025-04-29 17:15:02", "link": "http://arxiv.org/abs/2504.20948v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "End-to-end Audio Deepfake Detection from RAW Waveforms: a RawNet-Based Approach with Cross-Dataset Evaluation", "abstract": "Audio deepfakes represent a growing threat to digital security and trust,\nleveraging advanced generative models to produce synthetic speech that closely\nmimics real human voices. Detecting such manipulations is especially\nchallenging under open-world conditions, where spoofing methods encountered\nduring testing may differ from those seen during training. In this work, we\npropose an end-to-end deep learning framework for audio deepfake detection that\noperates directly on raw waveforms. Our model, RawNetLite, is a lightweight\nconvolutional-recurrent architecture designed to capture both spectral and\ntemporal features without handcrafted preprocessing. To enhance robustness, we\nintroduce a training strategy that combines data from multiple domains and\nadopts Focal Loss to emphasize difficult or ambiguous samples. We further\ndemonstrate that incorporating codec-based manipulations and applying\nwaveform-level audio augmentations (e.g., pitch shifting, noise, and time\nstretching) leads to significant generalization improvements under realistic\nacoustic conditions. The proposed model achieves over 99.7% F1 and 0.25% EER on\nin-domain data (FakeOrReal), and up to 83.4% F1 with 16.4% EER on a challenging\nout-of-distribution test set (AVSpoof2021 + CodecFake). These findings\nhighlight the importance of diverse training data, tailored objective functions\nand audio augmentations in building resilient and generalizable audio forgery\ndetectors. Code and pretrained models are available at\nhttps://iplab.dmi.unict.it/mfs/Deepfakes/PaperRawNet2025/.", "published": "2025-04-29 16:38:23", "link": "http://arxiv.org/abs/2504.20923v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FLIM-based Salient Object Detection Networks with Adaptive Decoders", "abstract": "Salient Object Detection (SOD) methods can locate objects that stand out in\nan image, assign higher values to their pixels in a saliency map, and binarize\nthe map outputting a predicted segmentation mask. A recent tendency is to\ninvestigate pre-trained lightweight models rather than deep neural networks in\nSOD tasks, coping with applications under limited computational resources. In\nthis context, we have investigated lightweight networks using a methodology\nnamed Feature Learning from Image Markers (FLIM), which assumes that the\nencoder's kernels can be estimated from marker pixels on discriminative regions\nof a few representative images. This work proposes flyweight networks, hundreds\nof times lighter than lightweight models, for SOD by combining a FLIM encoder\nwith an adaptive decoder, whose weights are estimated for each input image by a\ngiven heuristic function. Such FLIM networks are trained from three to four\nrepresentative images only and without backpropagation, making the models\nsuitable for applications under labeled data constraints as well. We study five\nadaptive decoders; two of them are introduced here. Differently from the\nprevious ones that rely on one neuron per pixel with shared weights, the\nheuristic functions of the new adaptive decoders estimate the weights of each\nneuron per pixel. We compare FLIM models with adaptive decoders for two\nchallenging SOD tasks with three lightweight networks from the\nstate-of-the-art, two FLIM networks with decoders trained by backpropagation,\nand one FLIM network whose labeled markers define the decoder's weights. The\nexperiments demonstrate the advantages of the proposed networks over the\nbaselines, revealing the importance of further investigating such methods in\nnew applications.", "published": "2025-04-29 15:44:02", "link": "http://arxiv.org/abs/2504.20872v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AI-GenBench: A New Ongoing Benchmark for AI-Generated Image Detection", "abstract": "The rapid advancement of generative AI has revolutionized image creation,\nenabling high-quality synthesis from text prompts while raising critical\nchallenges for media authenticity. We present Ai-GenBench, a novel benchmark\ndesigned to address the urgent need for robust detection of AI-generated images\nin real-world scenarios. Unlike existing solutions that evaluate models on\nstatic datasets, Ai-GenBench introduces a temporal evaluation framework where\ndetection methods are incrementally trained on synthetic images, historically\nordered by their generative models, to test their ability to generalize to new\ngenerative models, such as the transition from GANs to diffusion models. Our\nbenchmark focuses on high-quality, diverse visual content and overcomes key\nlimitations of current approaches, including arbitrary dataset splits, unfair\ncomparisons, and excessive computational demands. Ai-GenBench provides a\ncomprehensive dataset, a standardized evaluation protocol, and accessible tools\nfor both researchers and non-experts (e.g., journalists, fact-checkers),\nensuring reproducibility while maintaining practical training requirements. By\nestablishing clear evaluation rules and controlled augmentation strategies,\nAi-GenBench enables meaningful comparison of detection methods and scalable\nsolutions. Code and data are publicly available to ensure reproducibility and\nto support the development of robust forensic detectors to keep pace with the\nrise of new synthetic generators.", "published": "2025-04-29 15:41:13", "link": "http://arxiv.org/abs/2504.20865v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FedMVP: Federated Multi-modal Visual Prompt Tuning for Vision-Language Models", "abstract": "Textual prompt tuning adapts Vision-Language Models (e.g., CLIP) in federated\nlearning by tuning lightweight input tokens (or prompts) on local client data,\nwhile keeping network weights frozen. Post training, only the prompts are\nshared by the clients with the central server for aggregation. However, textual\nprompt tuning often struggles with overfitting to known concepts and may be\noverly reliant on memorized text features, limiting its adaptability to unseen\nconcepts. To address this limitation, we propose Federated Multimodal Visual\nPrompt Tuning (FedMVP) that conditions the prompts on comprehensive contextual\ninformation -- image-conditioned features and textual attribute features of a\nclass -- that is multimodal in nature. At the core of FedMVP is a PromptFormer\nmodule that synergistically aligns textual and visual features through\ncross-attention, enabling richer contexual integration. The dynamically\ngenerated multimodal visual prompts are then input to the frozen vision encoder\nof CLIP, and trained with a combination of CLIP similarity loss and a\nconsistency loss. Extensive evaluation on 20 datasets spanning three\ngeneralization settings demonstrates that FedMVP not only preserves performance\non in-distribution classes and domains, but also displays higher\ngeneralizability to unseen classes and domains when compared to\nstate-of-the-art methods. Codes will be released upon acceptance.", "published": "2025-04-29 15:36:51", "link": "http://arxiv.org/abs/2504.20860v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CMT: A Cascade MAR with Topology Predictor for Multimodal Conditional CAD Generation", "abstract": "While accurate and user-friendly Computer-Aided Design (CAD) is crucial for\nindustrial design and manufacturing, existing methods still struggle to achieve\nthis due to their over-simplified representations or architectures incapable of\nsupporting multimodal design requirements. In this paper, we attempt to tackle\nthis problem from both methods and datasets aspects. First, we propose a\ncascade MAR with topology predictor (CMT), the first multimodal framework for\nCAD generation based on Boundary Representation (B-Rep). Specifically, the\ncascade MAR can effectively capture the ``edge-counters-surface'' priors that\nare essential in B-Reps, while the topology predictor directly estimates\ntopology in B-Reps from the compact tokens in MAR. Second, to facilitate\nlarge-scale training, we develop a large-scale multimodal CAD dataset, mmABC,\nwhich includes over 1.3 million B-Rep models with multimodal annotations,\nincluding point clouds, text descriptions, and multi-view images. Extensive\nexperiments show the superior of CMT in both conditional and unconditional CAD\ngeneration tasks. For example, we improve Coverage and Valid ratio by +10.68%\nand +10.3%, respectively, compared to state-of-the-art methods on ABC in\nunconditional generation. CMT also improves +4.01 Chamfer on image conditioned\nCAD generation on mmABC. The dataset, code and pretrained network shall be\nreleased.", "published": "2025-04-29 14:52:28", "link": "http://arxiv.org/abs/2504.20830v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adept: Annotation-Denoising Auxiliary Tasks with Discrete Cosine Transform Map and Keypoint for Human-Centric Pretraining", "abstract": "Human-centric perception is the core of diverse computer vision tasks and has\nbeen a long-standing research focus. However, previous research studied these\nhuman-centric tasks individually, whose performance is largely limited to the\nsize of the public task-specific datasets. Recent human-centric methods\nleverage the additional modalities, e.g., depth, to learn fine-grained semantic\ninformation, which limits the benefit of pretraining models due to their\nsensitivity to camera views and the scarcity of RGB-D data on the Internet.\nThis paper improves the data scalability of human-centric pretraining methods\nby discarding depth information and exploring semantic information of RGB\nimages in the frequency space by Discrete Cosine Transform (DCT). We further\npropose new annotation denoising auxiliary tasks with keypoints and DCT maps to\nenforce the RGB image extractor to learn fine-grained semantic information of\nhuman bodies. Our extensive experiments show that when pretrained on\nlarge-scale datasets (COCO and AIC datasets) without depth annotation, our\nmodel achieves better performance than state-of-the-art methods by +0.5 mAP on\nCOCO, +1.4 PCKh on MPII and -0.51 EPE on Human3.6M for pose estimation, by\n+4.50 mIoU on Human3.6M for human parsing, by -3.14 MAE on SHA and -0.07 MAE on\nSHB for crowd counting, by +1.1 F1 score on SHA and +0.8 F1 score on SHA for\ncrowd localization, and by +0.1 mAP on Market1501 and +0.8 mAP on MSMT for\nperson ReID. We also validate the effectiveness of our method on MPII+NTURGBD\ndatasets", "published": "2025-04-29 14:14:29", "link": "http://arxiv.org/abs/2504.20800v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Survey on Event-based Optical Marker Systems", "abstract": "The advent of event-based cameras, with their low latency, high dynamic\nrange, and reduced power consumption, marked a significant change in robotic\nvision and machine perception. In particular, the combination of these\nneuromorphic sensors with widely-available passive or active optical markers\n(e.g. AprilTags, arrays of blinking LEDs), has recently opened up a wide field\nof possibilities. This survey paper provides a comprehensive review on\nEvent-Based Optical Marker Systems (EBOMS). We analyze the basic principles and\ntechnologies on which these systems are based, with a special focus on their\nasynchronous operation and robustness against adverse lighting conditions. We\nalso describe the most relevant applications of EBOMS, including object\ndetection and tracking, pose estimation, and optical communication. The article\nconcludes with a discussion of possible future research directions in this\nrapidly-emerging and multidisciplinary field.", "published": "2025-04-29 13:21:03", "link": "http://arxiv.org/abs/2504.20736v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Learning a General Model: Folding Clothing with Topological Dynamics", "abstract": "The high degrees of freedom and complex structure of garments present\nsignificant challenges for clothing manipulation. In this paper, we propose a\ngeneral topological dynamics model to fold complex clothing. By utilizing the\nvisible folding structure as the topological skeleton, we design a novel\ntopological graph to represent the clothing state. This topological graph is\nlow-dimensional and applied for complex clothing in various folding states. It\nindicates the constraints of clothing and enables predictions regarding\nclothing movement. To extract graphs from self-occlusion, we apply semantic\nsegmentation to analyze the occlusion relationships and decompose the clothing\nstructure. The decomposed structure is then combined with keypoint detection to\ngenerate the topological graph. To analyze the behavior of the topological\ngraph, we employ an improved Graph Neural Network (GNN) to learn the general\ndynamics. The GNN model can predict the deformation of clothing and is employed\nto calculate the deformation Jacobi matrix for control. Experiments using\njackets validate the algorithm's effectiveness to recognize and fold complex\nclothing with self-occlusion.", "published": "2025-04-29 13:00:32", "link": "http://arxiv.org/abs/2504.20720v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer", "abstract": "Instruction-based image editing enables robust image modification via natural\nlanguage prompts, yet current methods face a precision-efficiency tradeoff.\nFine-tuning methods demand significant computational resources and large\ndatasets, while training-free techniques struggle with instruction\ncomprehension and edit quality. We resolve this dilemma by leveraging\nlarge-scale Diffusion Transformer (DiT)' enhanced generation capacity and\nnative contextual awareness. Our solution introduces three contributions: (1)\nan in-context editing framework for zero-shot instruction compliance using\nin-context prompting, avoiding structural changes; (2) a LoRA-MoE hybrid tuning\nstrategy that enhances flexibility with efficient adaptation and dynamic expert\nrouting, without extensive retraining; and (3) an early filter inference-time\nscaling method using vision-language models (VLMs) to select better initial\nnoise early, improving edit quality. Extensive evaluations demonstrate our\nmethod's superiority: it outperforms state-of-the-art approaches while\nrequiring only 0.5% training data and 1% trainable parameters compared to\nconventional baselines. This work establishes a new paradigm that enables\nhigh-precision yet efficient instruction-guided editing. Codes and demos can be\nfound in https://river-zhang.github.io/ICEdit-gh-pages/.", "published": "2025-04-29 12:14:47", "link": "http://arxiv.org/abs/2504.20690v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient Listener: Dyadic Facial Motion Synthesis via Action Diffusion", "abstract": "Generating realistic listener facial motions in dyadic conversations remains\nchallenging due to the high-dimensional action space and temporal dependency\nrequirements. Existing approaches usually consider extracting 3D Morphable\nModel (3DMM) coefficients and modeling in the 3DMM space. However, this makes\nthe computational speed of the 3DMM a bottleneck, making it difficult to\nachieve real-time interactive responses. To tackle this problem, we propose\nFacial Action Diffusion (FAD), which introduces the diffusion methods from the\nfield of image generation to achieve efficient facial action generation. We\nfurther build the Efficient Listener Network (ELNet) specially designed to\naccommodate both the visual and audio information of the speaker as input.\nConsidering of FAD and ELNet, the proposed method learns effective listener\nfacial motion representations and leads to improvements of performance over the\nstate-of-the-art methods while reducing 99% computational time.", "published": "2025-04-29 12:08:02", "link": "http://arxiv.org/abs/2504.20685v1", "categories": ["cs.CV", "cs.HC"], "primary_category": "cs.CV"}
{"title": "OG-HFYOLO :Orientation gradient guidance and heterogeneous feature fusion for deformation table cell instance segmentation", "abstract": "Table structure recognition is a key task in document analysis. However, the\ngeometric deformation in deformed tables causes a weak correlation between\ncontent information and structure, resulting in downstream tasks not being able\nto obtain accurate content information. To obtain fine-grained spatial\ncoordinates of cells, we propose the OG-HFYOLO model, which enhances the edge\nresponse by Gradient Orientation-aware Extractor, combines a Heterogeneous\nKernel Cross Fusion module and a scale-aware loss function to adapt to\nmulti-scale objective features, and introduces mask-driven non-maximal\nsuppression in the post-processing, which replaces the traditional bounding box\nsuppression mechanism. Furthermore, we also propose a data generator, filling\nthe gap in the dataset for fine-grained deformation table cell spatial\ncoordinate localization, and derive a large-scale dataset named Deformation\nWired Table (DWTAL). Experiments show that our proposed model demonstrates\nexcellent segmentation accuracy on all mainstream instance segmentation models.\nThe dataset and the source code are open source:\nhttps://github.com/justliulong/OGHFYOLO.", "published": "2025-04-29 12:02:01", "link": "http://arxiv.org/abs/2504.20682v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Occlusion-aware Driver Monitoring System using the Driver Monitoring Dataset", "abstract": "This paper presents a robust, occlusion-aware driver monitoring system (DMS)\nutilizing the Driver Monitoring Dataset (DMD). The system performs driver\nidentification, gaze estimation by regions, and face occlusion detection under\nvarying lighting conditions, including challenging low-light scenarios. Aligned\nwith EuroNCAP recommendations, the inclusion of occlusion detection enhances\nsituational awareness and system trustworthiness by indicating when the\nsystem's performance may be degraded. The system employs separate algorithms\ntrained on RGB and infrared (IR) images to ensure reliable functioning. We\ndetail the development and integration of these algorithms into a cohesive\npipeline, addressing the challenges of working with different sensors and\nreal-car implementation. Evaluation on the DMD and in real-world scenarios\ndemonstrates the effectiveness of the proposed system, highlighting the\nsuperior performance of RGB-based models and the pioneering contribution of\nrobust occlusion detection in DMS.", "published": "2025-04-29 11:58:37", "link": "http://arxiv.org/abs/2504.20677v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FBRT-YOLO: Faster and Better for Real-Time Aerial Image Detection", "abstract": "Embedded flight devices with visual capabilities have become essential for a\nwide range of applications. In aerial image detection, while many existing\nmethods have partially addressed the issue of small target detection,\nchallenges remain in optimizing small target detection and balancing detection\naccuracy with efficiency. These issues are key obstacles to the advancement of\nreal-time aerial image detection. In this paper, we propose a new family of\nreal-time detectors for aerial image detection, named FBRT-YOLO, to address the\nimbalance between detection accuracy and efficiency. Our method comprises two\nlightweight modules: Feature Complementary Mapping Module (FCM) and\nMulti-Kernel Perception Unit(MKP), designed to enhance object perception for\nsmall targets in aerial images. FCM focuses on alleviating the problem of\ninformation imbalance caused by the loss of small target information in deep\nnetworks. It aims to integrate spatial positional information of targets more\ndeeply into the network,better aligning with semantic information in the deeper\nlayers to improve the localization of small targets. We introduce MKP, which\nleverages convolutions with kernels of different sizes to enhance the\nrelationships between targets of various scales and improve the perception of\ntargets at different scales. Extensive experimental results on three major\naerial image datasets, including Visdrone, UAVDT, and AI-TOD,demonstrate that\nFBRT-YOLO outperforms various real-time detectors in terms of performance and\nspeed.", "published": "2025-04-29 11:53:54", "link": "http://arxiv.org/abs/2504.20670v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Image deidentification in the XNAT ecosystem: use cases and solutions", "abstract": "XNAT is a server-based data management platform widely used in academia for\ncurating large databases of DICOM images for research projects. We describe in\ndetail a deidentification workflow for DICOM data using facilities in XNAT,\ntogether with independent tools in the XNAT \"ecosystem\". We list different\ncontexts in which deidentification might be needed, based on our prior\nexperience. The starting point for participation in the Medical Image\nDe-Identification Benchmark (MIDI-B) challenge was a set of pre-existing local\nmethodologies, which were adapted during the validation phase of the challenge.\nOur result in the test phase was 97.91\\%, considerably lower than our peers,\ndue largely to an arcane technical incompatibility of our methodology with the\nchallenge's Synapse platform, which prevented us receiving feedback during the\nvalidation phase. Post-submission, additional discrepancy reports from the\norganisers and via the MIDI-B Continuous Benchmarking facility, enabled us to\nimprove this score significantly to 99.61\\%. An entirely rule-based approach\nwas shown to be capable of removing all name-related information in the test\ncorpus, but exhibited failures in dealing fully with address data. Initial\nexperiments using published machine-learning models to remove addresses were\npartially successful but showed the models to be \"over-aggressive\" on other\ntypes of free-text data, leading to a slight overall degradation in performance\nto 99.54\\%. Future development will therefore focus on improving\naddress-recognition capabilities, but also on better removal of identifiable\ndata burned into the image pixels. Several technical aspects relating to the\n\"answer key\" are still under discussion with the challenge organisers, but we\nestimate that our percentage of genuine deidentification failures on the MIDI-B\ntest corpus currently stands at 0.19\\%. (Abridged from original for arXiv\nsubmission)", "published": "2025-04-29 11:33:51", "link": "http://arxiv.org/abs/2504.20657v1", "categories": ["cs.CV", "J.3"], "primary_category": "cs.CV"}
{"title": "LDPoly: Latent Diffusion for Polygonal Road Outline Extraction in Large-Scale Topographic Mapping", "abstract": "Polygonal road outline extraction from high-resolution aerial images is an\nimportant task in large-scale topographic mapping, where roads are represented\nas vectorized polygons, capturing essential geometric features with minimal\nvertex redundancy. Despite its importance, no existing method has been\nexplicitly designed for this task. While polygonal building outline extraction\nhas been extensively studied, the unique characteristics of roads, such as\nbranching structures and topological connectivity, pose challenges to these\nmethods. To address this gap, we introduce LDPoly, the first dedicated\nframework for extracting polygonal road outlines from high-resolution aerial\nimages. Our method leverages a novel Dual-Latent Diffusion Model with a\nChannel-Embedded Fusion Module, enabling the model to simultaneously generate\nroad masks and vertex heatmaps. A tailored polygonization method is then\napplied to obtain accurate vectorized road polygons with minimal vertex\nredundancy. We evaluate LDPoly on a new benchmark dataset, Map2ImLas, which\ncontains detailed polygonal annotations for various topographic objects in\nseveral Dutch regions. Our experiments include both in-region and cross-region\nevaluations, with the latter designed to assess the model's generalization\nperformance on unseen regions. Quantitative and qualitative results demonstrate\nthat LDPoly outperforms state-of-the-art polygon extraction methods across\nvarious metrics, including pixel-level coverage, vertex efficiency, polygon\nregularity, and road connectivity. We also design two new metrics to assess\npolygon simplicity and boundary smoothness. Moreover, this work represents the\nfirst application of diffusion models for extracting precise vectorized object\noutlines without redundant vertices from remote-sensing imagery, paving the way\nfor future advancements in this field.", "published": "2025-04-29 11:13:33", "link": "http://arxiv.org/abs/2504.20645v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EfficientHuman: Efficient Training and Reconstruction of Moving Human using Articulated 2D Gaussian", "abstract": "3D Gaussian Splatting (3DGS) has been recognized as a pioneering technique in\nscene reconstruction and novel view synthesis. Recent work on reconstructing\nthe 3D human body using 3DGS attempts to leverage prior information on human\npose to enhance rendering quality and improve training speed. However, it\nstruggles to effectively fit dynamic surface planes due to multi-view\ninconsistency and redundant Gaussians. This inconsistency arises because\nGaussian ellipsoids cannot accurately represent the surfaces of dynamic\nobjects, which hinders the rapid reconstruction of the dynamic human body.\nMeanwhile, the prevalence of redundant Gaussians means that the training time\nof these works is still not ideal for quickly fitting a dynamic human body. To\naddress these, we propose EfficientHuman, a model that quickly accomplishes the\ndynamic reconstruction of the human body using Articulated 2D Gaussian while\nensuring high rendering quality. The key innovation involves encoding Gaussian\nsplats as Articulated 2D Gaussian surfels in canonical space and then\ntransforming them to pose space via Linear Blend Skinning (LBS) to achieve\nefficient pose transformations. Unlike 3D Gaussians, Articulated 2D Gaussian\nsurfels can quickly conform to the dynamic human body while ensuring\nview-consistent geometries. Additionally, we introduce a pose calibration\nmodule and an LBS optimization module to achieve precise fitting of dynamic\nhuman poses, enhancing the model's performance. Extensive experiments on the\nZJU-MoCap dataset demonstrate that EfficientHuman achieves rapid 3D dynamic\nhuman reconstruction in less than a minute on average, which is 20 seconds\nfaster than the current state-of-the-art method, while also reducing the number\nof redundant Gaussians.", "published": "2025-04-29 10:15:43", "link": "http://arxiv.org/abs/2504.20607v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Purifying, Labeling, and Utilizing: A High-Quality Pipeline for Small Object Detection", "abstract": "Small object detection is a broadly investigated research task and is\ncommonly conceptualized as a \"pipeline-style\" engineering process. In the\nupstream, images serve as raw materials for processing in the detection\npipeline, where pre-trained models are employed to generate initial feature\nmaps. In the midstream, an assigner selects training positive and negative\nsamples. Subsequently, these samples and features are fed into the downstream\nfor classification and regression. Previous small object detection methods\noften focused on improving isolated stages of the pipeline, thereby neglecting\nholistic optimization and consequently constraining overall performance gains.\nTo address this issue, we have optimized three key aspects, namely Purifying,\nLabeling, and Utilizing, in this pipeline, proposing a high-quality Small\nobject detection framework termed PLUSNet. Specifically, PLUSNet comprises\nthree sequential components: the Hierarchical Feature Purifier (HFP) for\npurifying upstream features, the Multiple Criteria Label Assignment (MCLA) for\nimproving the quality of midstream training samples, and the Frequency\nDecoupled Head (FDHead) for more effectively exploiting information to\naccomplish downstream tasks. The proposed PLUS modules are readily integrable\ninto various object detectors, thus enhancing their detection capabilities in\nmulti-scale scenarios. Extensive experiments demonstrate the proposed PLUSNet\nconsistently achieves significant and consistent improvements across multiple\ndatasets for small object detection.", "published": "2025-04-29 10:11:03", "link": "http://arxiv.org/abs/2504.20602v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PartHOI: Part-based Hand-Object Interaction Transfer via Generalized Cylinders", "abstract": "Learning-based methods to understand and model hand-object interactions (HOI)\nrequire a large amount of high-quality HOI data. One way to create HOI data is\nto transfer hand poses from a source object to another based on the objects'\ngeometry. However, current methods for transferring hand poses between objects\nrely on shape matching, limiting the ability to transfer poses across different\ncategories due to differences in their shapes and sizes. We observe that HOI\noften involves specific semantic parts of objects, which often have more\nconsistent shapes across categories. In addition, constructing size-invariant\ncorrespondences between these parts is important for cross-category transfer.\nBased on these insights, we introduce a novel method PartHOI for part-based HOI\ntransfer. Using a generalized cylinder representation to parameterize an object\nparts' geometry, PartHOI establishes a robust geometric correspondence between\nobject parts, and enables the transfer of contact points. Given the transferred\npoints, we optimize a hand pose to fit the target object well. Qualitative and\nquantitative results demonstrate that our method can generalize HOI transfers\nwell even for cross-category objects, and produce high-fidelity results that\nare superior to the existing methods.", "published": "2025-04-29 09:56:29", "link": "http://arxiv.org/abs/2504.20599v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hydra: Marker-Free RGB-D Hand-Eye Calibration", "abstract": "This work presents an RGB-D imaging-based approach to marker-free hand-eye\ncalibration using a novel implementation of the iterative closest point (ICP)\nalgorithm with a robust point-to-plane (PTP) objective formulated on a Lie\nalgebra. Its applicability is demonstrated through comprehensive experiments\nusing three well known serial manipulators and two RGB-D cameras. With only\nthree randomly chosen robot configurations, our approach achieves approximately\n90% successful calibrations, demonstrating 2-3x higher convergence rates to the\nglobal optimum compared to both marker-based and marker-free baselines. We also\nreport 2 orders of magnitude faster convergence time (0.8 +/- 0.4 s) for 9\nrobot configurations over other marker-free methods. Our method exhibits\nsignificantly improved accuracy (5 mm in task space) over classical approaches\n(7 mm in task space) whilst being marker-free. The benchmarking dataset and\ncode are open sourced under Apache 2.0 License, and a ROS 2 integration with\nrobot abstraction is provided to facilitate deployment.", "published": "2025-04-29 09:39:59", "link": "http://arxiv.org/abs/2504.20584v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Autoencoder Models for Point Cloud Environmental Synthesis from WiFi Channel State Information: A Preliminary Study", "abstract": "This paper introduces a deep learning framework for generating point clouds\nfrom WiFi Channel State Information data. We employ a two-stage autoencoder\napproach: a PointNet autoencoder with convolutional layers for point cloud\ngeneration, and a Convolutional Neural Network autoencoder to map CSI data to a\nmatching latent space. By aligning these latent spaces, our method enables\naccurate environmental point cloud reconstruction from WiFi data. Experimental\nresults validate the effectiveness of our approach, highlighting its potential\nfor wireless sensing and environmental mapping applications.", "published": "2025-04-29 08:36:52", "link": "http://arxiv.org/abs/2504.20541v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Beyond the Horizon: Decoupling UAVs Multi-View Action Recognition via Partial Order Transfer", "abstract": "Action recognition in unmanned aerial vehicles (UAVs) poses unique challenges\ndue to significant view variations along the vertical spatial axis. Unlike\ntraditional ground-based settings, UAVs capture actions from a wide range of\naltitudes, resulting in considerable appearance discrepancies. We introduce a\nmulti-view formulation tailored to varying UAV altitudes and empirically\nobserve a partial order among views, where recognition accuracy consistently\ndecreases as the altitude increases. This motivates a novel approach that\nexplicitly models the hierarchical structure of UAV views to improve\nrecognition performance across altitudes. To this end, we propose the Partial\nOrder Guided Multi-View Network (POG-MVNet), designed to address drastic view\nvariations by effectively leveraging view-dependent information across\ndifferent altitude levels. The framework comprises three key components: a View\nPartition (VP) module, which uses the head-to-body ratio to group views by\naltitude; an Order-aware Feature Decoupling (OFD) module, which disentangles\naction-relevant and view-specific features under partial order guidance; and an\nAction Partial Order Guide (APOG), which leverages the partial order to\ntransfer informative knowledge from easier views to support learning in more\nchallenging ones. We conduct experiments on Drone-Action, MOD20, and UAV\ndatasets, demonstrating that POG-MVNet significantly outperforms competing\nmethods. For example, POG-MVNet achieves a 4.7% improvement on Drone-Action\ndataset and a 3.5% improvement on UAV dataset compared to state-of-the-art\nmethods ASAT and FAR. The code for POG-MVNet will be made available soon.", "published": "2025-04-29 08:22:13", "link": "http://arxiv.org/abs/2504.20530v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Geometry-aware Temporal Aggregation Network for Monocular 3D Lane Detection", "abstract": "Monocular 3D lane detection aims to estimate 3D position of lanes from\nfrontal-view (FV) images. However, current monocular 3D lane detection methods\nsuffer from two limitations, including inaccurate geometric information of the\npredicted 3D lanes and difficulties in maintaining lane integrity. To address\nthese issues, we seek to fully exploit the potential of multiple input frames.\nFirst, we aim at enhancing the ability to perceive the geometry of scenes by\nleveraging temporal geometric consistency. Second, we strive to improve the\nintegrity of lanes by revealing more instance information from temporal\nsequences. Therefore, we propose a novel Geometry-aware Temporal Aggregation\nNetwork (GTA-Net) for monocular 3D lane detection. On one hand, we develop the\nTemporal Geometry Enhancement Module (TGEM), which exploits geometric\nconsistency across successive frames, facilitating effective geometry\nperception. On the other hand, we present the Temporal Instance-aware Query\nGeneration (TIQG), which strategically incorporates temporal cues into query\ngeneration, thereby enabling the exploration of comprehensive instance\ninformation. Experiments demonstrate that our GTA-Net achieves SoTA results,\nsurpassing existing monocular 3D lane detection solutions.", "published": "2025-04-29 08:10:17", "link": "http://arxiv.org/abs/2504.20525v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dynamic Attention Analysis for Backdoor Detection in Text-to-Image Diffusion Models", "abstract": "Recent studies have revealed that text-to-image diffusion models are\nvulnerable to backdoor attacks, where attackers implant stealthy textual\ntriggers to manipulate model outputs. Previous backdoor detection methods\nprimarily focus on the static features of backdoor samples. However, a vital\nproperty of diffusion models is their inherent dynamism. This study introduces\na novel backdoor detection perspective named Dynamic Attention Analysis (DAA),\nshowing that these dynamic characteristics serve as better indicators for\nbackdoor detection. Specifically, by examining the dynamic evolution of\ncross-attention maps, we observe that backdoor samples exhibit distinct feature\nevolution patterns at the $<$EOS$>$ token compared to benign samples. To\nquantify these dynamic anomalies, we first introduce DAA-I, which treats the\ntokens' attention maps as spatially independent and measures dynamic feature\nusing the Frobenius norm. Furthermore, to better capture the interactions\nbetween attention maps and refine the feature, we propose a dynamical\nsystem-based approach, referred to as DAA-S. This model formulates the spatial\ncorrelations among attention maps using a graph-based state equation and we\ntheoretically analyze the global asymptotic stability of this method. Extensive\nexperiments across five representative backdoor attack scenarios demonstrate\nthat our approach significantly surpasses existing detection methods, achieving\nan average F1 Score of 79.49% and an AUC of 87.67%. The code is available at\nhttps://github.com/Robin-WZQ/DAA.", "published": "2025-04-29 07:59:35", "link": "http://arxiv.org/abs/2504.20518v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SteelBlastQC: Shot-blasted Steel Surface Dataset with Interpretable Detection of Surface Defects", "abstract": "Automating the quality control of shot-blasted steel surfaces is crucial for\nimproving manufacturing efficiency and consistency. This study presents a\ndataset of 1654 labeled RGB images (512x512) of steel surfaces, classified as\neither \"ready for paint\" or \"needs shot-blasting.\" The dataset captures\nreal-world surface defects, including discoloration, welding lines, scratches\nand corrosion, making it well-suited for training computer vision models.\nAdditionally, three classification approaches were evaluated: Compact\nConvolutional Transformers (CCT), Support Vector Machines (SVM) with ResNet-50\nfeature extraction, and a Convolutional Autoencoder (CAE). The supervised\nmethods (CCT and SVM) achieve 95% classification accuracy on the test set, with\nCCT leveraging transformer-based attention mechanisms and SVM offering a\ncomputationally efficient alternative. The CAE approach, while less effective,\nestablishes a baseline for unsupervised quality control. We present\ninterpretable decision-making by all three neural networks, allowing industry\nusers to visually pinpoint problematic regions and understand the model's\nrationale. By releasing the dataset and baseline codes, this work aims to\nsupport further research in defect detection, advance the development of\ninterpretable computer vision models for quality control, and encourage the\nadoption of automated inspection systems in industrial applications.", "published": "2025-04-29 07:51:58", "link": "http://arxiv.org/abs/2504.20510v1", "categories": ["cs.CV", "cs.NE"], "primary_category": "cs.CV"}
{"title": "MambaMoE: Mixture-of-Spectral-Spatial-Experts State Space Model for Hyperspectral Image Classification", "abstract": "The Mamba model has recently demonstrated strong potential in hyperspectral\nimage (HSI) classification, owing to its ability to perform context modeling\nwith linear computational complexity. However, existing Mamba-based methods\nusually neglect the spectral and spatial directional characteristics related to\nheterogeneous objects in hyperspectral scenes, leading to limited\nclassification performance. To address these issues, we propose MambaMoE, a\nnovel spectral-spatial mixture-of-experts framework, representing the first\nMoE-based approach in the HSI classification community. Specifically, we design\na Mixture of Mamba Expert Block (MoMEB) that leverages sparse expert activation\nto enable adaptive spectral-spatial modeling. Furthermore, we introduce an\nuncertainty-guided corrective learning (UGCL) strategy to encourage the model's\nattention toward complex regions prone to prediction ambiguity. Extensive\nexperiments on multiple public HSI benchmarks demonstrate that MambaMoE\nachieves state-of-the-art performance in both accuracy and efficiency compared\nto existing advanced approaches, especially for Mamba-based methods. Code will\nbe released.", "published": "2025-04-29 07:50:36", "link": "http://arxiv.org/abs/2504.20509v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SAM-Guided Robust Representation Learning for One-Shot 3D Medical Image Segmentation", "abstract": "One-shot medical image segmentation (MIS) is crucial for medical analysis due\nto the burden of medical experts on manual annotation. The recent emergence of\nthe segment anything model (SAM) has demonstrated remarkable adaptation in MIS\nbut cannot be directly applied to one-shot medical image segmentation (MIS) due\nto its reliance on labor-intensive user interactions and the high computational\ncost. To cope with these limitations, we propose a novel SAM-guided robust\nrepresentation learning framework, named RRL-MedSAM, to adapt SAM to one-shot\n3D MIS, which exploits the strong generalization capabilities of the SAM\nencoder to learn better feature representation. We devise a dual-stage\nknowledge distillation (DSKD) strategy to distill general knowledge between\nnatural and medical images from the foundation model to train a lightweight\nencoder, and then adopt a mutual exponential moving average (mutual-EMA) to\nupdate the weights of the general lightweight encoder and medical-specific\nencoder. Specifically, pseudo labels from the registration network are used to\nperform mutual supervision for such two encoders. Moreover, we introduce an\nauto-prompting (AP) segmentation decoder which adopts the mask generated from\nthe general lightweight model as a prompt to assist the medical-specific model\nin boosting the final segmentation performance. Extensive experiments conducted\non three public datasets, i.e., OASIS, CT-lung demonstrate that the proposed\nRRL-MedSAM outperforms state-of-the-art one-shot MIS methods for both\nsegmentation and registration tasks. Especially, our lightweight encoder uses\nonly 3\\% of the parameters compared to the encoder of SAM-Base.", "published": "2025-04-29 07:43:37", "link": "http://arxiv.org/abs/2504.20501v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection", "abstract": "Single-source Domain Generalization (SDG) in object detection aims to develop\na detector using only data from a source domain that can exhibit strong\ngeneralization capability when applied to unseen target domains. Existing\nmethods are built upon CNN-based detectors and primarily improve robustness by\nemploying carefully designed data augmentation strategies integrated with\nfeature alignment techniques. However, data augmentation methods have inherent\ndrawbacks; they are only effective when the augmented sample distribution\napproximates or covers the unseen scenarios, thus failing to enhance\ngeneralization across all unseen domains. Furthermore, while the recent\nDetection Transformer (DETR) has demonstrated superior generalization\ncapability in domain adaptation tasks due to its efficient global information\nextraction, its potential in SDG tasks remains unexplored. To this end, we\nintroduce a strong DETR-based detector named the Style-Adaptive Detection\nTransformer (SA-DETR) for SDG in object detection. Specifically, we present a\ndomain style adapter that projects the style representation of the unseen\ntarget domain into the training domain, enabling dynamic style adaptation.\nThen, we propose an object-aware contrastive learning module to guide the\ndetector in extracting domain-invariant features through contrastive learning.\nBy using object-aware gating masks to constrain feature aggregation in both\nspatial and semantic dimensions, this module achieves cross-domain contrast of\ninstance-level features, thereby enhancing generalization. Extensive\nexperiments demonstrate the superior performance and generalization capability\nof SA-DETR across five different weather scenarios. Code is released at\nhttps://github.com/h751410234/SA-DETR.", "published": "2025-04-29 07:38:37", "link": "http://arxiv.org/abs/2504.20498v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Large-scale visual SLAM for in-the-wild videos", "abstract": "Accurate and robust 3D scene reconstruction from casual, in-the-wild videos\ncan significantly simplify robot deployment to new environments. However,\nreliable camera pose estimation and scene reconstruction from such\nunconstrained videos remains an open challenge. Existing visual-only SLAM\nmethods perform well on benchmark datasets but struggle with real-world footage\nwhich often exhibits uncontrolled motion including rapid rotations and pure\nforward movements, textureless regions, and dynamic objects. We analyze the\nlimitations of current methods and introduce a robust pipeline designed to\nimprove 3D reconstruction from casual videos. We build upon recent deep visual\nodometry methods but increase robustness in several ways. Camera intrinsics are\nautomatically recovered from the first few frames using structure-from-motion.\nDynamic objects and less-constrained areas are masked with a predictive model.\nAdditionally, we leverage monocular depth estimates to regularize bundle\nadjustment, mitigating errors in low-parallax situations. Finally, we integrate\nplace recognition and loop closure to reduce long-term drift and refine both\nintrinsics and pose estimates through global bundle adjustment. We demonstrate\nlarge-scale contiguous 3D models from several online videos in various\nenvironments. In contrast, baseline methods typically produce locally\ninconsistent results at several points, producing separate segments or\ndistorted maps. In lieu of ground-truth pose data, we evaluate map consistency,\nexecution time and visual accuracy of re-rendered NeRF models. Our proposed\nsystem establishes a new baseline for visual reconstruction from casual\nuncontrolled videos found online, demonstrating more consistent reconstructions\nover longer sequences of in-the-wild videos than previously achieved.", "published": "2025-04-29 07:37:51", "link": "http://arxiv.org/abs/2504.20496v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Antidote: A Unified Framework for Mitigating LVLM Hallucinations in Counterfactual Presupposition and Object Perception", "abstract": "Large Vision-Language Models (LVLMs) have achieved impressive results across\nvarious cross-modal tasks. However, hallucinations, i.e., the models generating\ncounterfactual responses, remain a challenge. Though recent studies have\nattempted to alleviate object perception hallucinations, they focus on the\nmodels' response generation, and overlooking the task question itself. This\npaper discusses the vulnerability of LVLMs in solving counterfactual\npresupposition questions (CPQs), where the models are prone to accept the\npresuppositions of counterfactual objects and produce severe hallucinatory\nresponses. To this end, we introduce \"Antidote\", a unified, synthetic\ndata-driven post-training framework for mitigating both types of hallucination\nabove. It leverages synthetic data to incorporate factual priors into questions\nto achieve self-correction, and decouple the mitigation process into a\npreference optimization problem. Furthermore, we construct \"CP-Bench\", a novel\nbenchmark to evaluate LVLMs' ability to correctly handle CPQs and produce\nfactual responses. Applied to the LLaVA series, Antidote can simultaneously\nenhance performance on CP-Bench by over 50%, POPE by 1.8-3.3%, and CHAIR & SHR\nby 30-50%, all without relying on external supervision from stronger LVLMs or\nhuman feedback and introducing noticeable catastrophic forgetting issues.", "published": "2025-04-29 07:05:24", "link": "http://arxiv.org/abs/2504.20468v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LMM4Gen3DHF: Benchmarking and Evaluating Multimodal 3D Human Face Generation with LMMs", "abstract": "The rapid advancement in generative artificial intelligence have enabled the\ncreation of 3D human faces (HFs) for applications including media production,\nvirtual reality, security, healthcare, and game development, etc. However,\nassessing the quality and realism of these AI-generated 3D human faces remains\na significant challenge due to the subjective nature of human perception and\ninnate perceptual sensitivity to facial features. To this end, we conduct a\ncomprehensive study on the quality assessment of AI-generated 3D human faces.\nWe first introduce Gen3DHF, a large-scale benchmark comprising 2,000 videos of\nAI-Generated 3D Human Faces along with 4,000 Mean Opinion Scores (MOS)\ncollected across two dimensions, i.e., quality and authenticity, 2,000\ndistortion-aware saliency maps and distortion descriptions. Based on Gen3DHF,\nwe propose LMME3DHF, a Large Multimodal Model (LMM)-based metric for Evaluating\n3DHF capable of quality and authenticity score prediction, distortion-aware\nvisual question answering, and distortion-aware saliency prediction.\nExperimental results show that LMME3DHF achieves state-of-the-art performance,\nsurpassing existing methods in both accurately predicting quality scores for\nAI-generated 3D human faces and effectively identifying distortion-aware\nsalient regions and distortion types, while maintaining strong alignment with\nhuman perceptual judgments. Both the Gen3DHF database and the LMME3DHF will be\nreleased upon the publication.", "published": "2025-04-29 07:00:06", "link": "http://arxiv.org/abs/2504.20466v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LymphAtlas- A Unified Multimodal Lymphoma Imaging Repository Delivering AI-Enhanced Diagnostic Insight", "abstract": "This study integrates PET metabolic information with CT anatomical structures\nto establish a 3D multimodal segmentation dataset for lymphoma based on\nwhole-body FDG PET/CT examinations, which bridges the gap of the lack of\nstandardised multimodal segmentation datasets in the field of haematological\nmalignancies. We retrospectively collected 483 examination datasets acquired\nbetween March 2011 and May 2024, involving 220 patients (106 non-Hodgkin\nlymphoma, 42 Hodgkin lymphoma); all data underwent ethical review and were\nrigorously de-identified. Complete 3D structural information was preserved\nduring data acquisition, preprocessing and annotation, and a high-quality\ndataset was constructed based on the nnUNet format. By systematic technical\nvalidation and evaluation of the preprocessing process, annotation quality and\nautomatic segmentation algorithm, the deep learning model trained based on this\ndataset is verified to achieve accurate segmentation of lymphoma lesions in\nPET/CT images with high accuracy, good robustness and reproducibility, which\nproves the applicability and stability of this dataset in accurate segmentation\nand quantitative analysis. The deep fusion of PET/CT images achieved with this\ndataset not only significantly improves the accurate portrayal of the\nmorphology, location and metabolic features of tumour lesions, but also\nprovides solid data support for early diagnosis, clinical staging and\npersonalized treatment, and promotes the development of automated image\nsegmentation and precision medicine based on deep learning. The dataset and\nrelated resources are available at https://github.com/SuperD0122/LymphAtlas-.", "published": "2025-04-29 06:10:12", "link": "http://arxiv.org/abs/2504.20454v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "PixelHacker: Image Inpainting with Structural and Semantic Consistency", "abstract": "Image inpainting is a fundamental research area between image editing and\nimage generation. Recent state-of-the-art (SOTA) methods have explored novel\nattention mechanisms, lightweight architectures, and context-aware modeling,\ndemonstrating impressive performance. However, they often struggle with complex\nstructure (e.g., texture, shape, spatial relations) and semantics (e.g., color\nconsistency, object restoration, and logical correctness), leading to artifacts\nand inappropriate generation. To address this challenge, we design a simple yet\neffective inpainting paradigm called latent categories guidance, and further\npropose a diffusion-based model named PixelHacker. Specifically, we first\nconstruct a large dataset containing 14 million image-mask pairs by annotating\nforeground and background (potential 116 and 21 categories, respectively).\nThen, we encode potential foreground and background representations separately\nthrough two fixed-size embeddings, and intermittently inject these features\ninto the denoising process via linear attention. Finally, by pre-training on\nour dataset and fine-tuning on open-source benchmarks, we obtain PixelHacker.\nExtensive experiments show that PixelHacker comprehensively outperforms the\nSOTA on a wide range of datasets (Places2, CelebA-HQ, and FFHQ) and exhibits\nremarkable consistency in both structure and semantics. Project page at\nhttps://hustvl.github.io/projects/PixelHacker.", "published": "2025-04-29 05:28:36", "link": "http://arxiv.org/abs/2504.20438v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AI Assisted Cervical Cancer Screening for Cytology Samples in Developing Countries", "abstract": "Cervical cancer remains a significant health challenge, with high incidence\nand mortality rates, particularly in transitioning countries. Conventional\nLiquid-Based Cytology(LBC) is a labor-intensive process, requires expert\npathologists and is highly prone to errors, highlighting the need for more\nefficient screening methods. This paper introduces an innovative approach that\nintegrates low-cost biological microscopes with our simple and efficient AI\nalgorithms for automated whole-slide analysis. Our system uses a motorized\nmicroscope to capture cytology images, which are then processed through an AI\npipeline involving image stitching, cell segmentation, and classification. We\nutilize the lightweight UNet-based model involving human-in-the-loop approach\nto train our segmentation model with minimal ROIs. CvT-based classification\nmodel, trained on the SIPaKMeD dataset, accurately categorizes five cell types.\nOur framework offers enhanced accuracy and efficiency in cervical cancer\nscreening compared to various state-of-art methods, as demonstrated by\ndifferent evaluation metrics.", "published": "2025-04-29 05:18:59", "link": "http://arxiv.org/abs/2504.20435v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Plant Disease Detection through Multimodal Large Language Models and Convolutional Neural Networks", "abstract": "Automation in agriculture plays a vital role in addressing challenges related\nto crop monitoring and disease management, particularly through early detection\nsystems. This study investigates the effectiveness of combining multimodal\nLarge Language Models (LLMs), specifically GPT-4o, with Convolutional Neural\nNetworks (CNNs) for automated plant disease classification using leaf imagery.\nLeveraging the PlantVillage dataset, we systematically evaluate model\nperformance across zero-shot, few-shot, and progressive fine-tuning scenarios.\nA comparative analysis between GPT-4o and the widely used ResNet-50 model was\nconducted across three resolutions (100, 150, and 256 pixels) and two plant\nspecies (apple and corn). Results indicate that fine-tuned GPT-4o models\nachieved slightly better performance compared to the performance of ResNet-50,\nachieving up to 98.12% classification accuracy on apple leaf images, compared\nto 96.88% achieved by ResNet-50, with improved generalization and near-zero\ntraining loss. However, zero-shot performance of GPT-4o was significantly\nlower, underscoring the need for minimal training. Additional evaluations on\ncross-resolution and cross-plant generalization revealed the models'\nadaptability and limitations when applied to new domains. The findings\nhighlight the promise of integrating multimodal LLMs into automated disease\ndetection pipelines, enhancing the scalability and intelligence of precision\nagriculture systems while reducing the dependence on large, labeled datasets\nand high-resolution sensor infrastructure. Large Language Models, Vision\nLanguage Models, LLMs and CNNs, Disease Detection with Vision Language Models,\nVLMs", "published": "2025-04-29 04:31:58", "link": "http://arxiv.org/abs/2504.20419v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GarmentX: Autoregressive Parametric Representations for High-Fidelity 3D Garment Generation", "abstract": "This work presents GarmentX, a novel framework for generating diverse,\nhigh-fidelity, and wearable 3D garments from a single input image. Traditional\ngarment reconstruction methods directly predict 2D pattern edges and their\nconnectivity, an overly unconstrained approach that often leads to severe\nself-intersections and physically implausible garment structures. In contrast,\nGarmentX introduces a structured and editable parametric representation\ncompatible with GarmentCode, ensuring that the decoded sewing patterns always\nform valid, simulation-ready 3D garments while allowing for intuitive\nmodifications of garment shape and style. To achieve this, we employ a masked\nautoregressive model that sequentially predicts garment parameters, leveraging\nautoregressive modeling for structured generation while mitigating\ninconsistencies in direct pattern prediction. Additionally, we introduce\nGarmentX dataset, a large-scale dataset of 378,682 garment parameter-image\npairs, constructed through an automatic data generation pipeline that\nsynthesizes diverse and high-quality garment images conditioned on parametric\ngarment representations. Through integrating our method with GarmentX dataset,\nwe achieve state-of-the-art performance in geometric fidelity and input image\nalignment, significantly outperforming prior approaches. We will release\nGarmentX dataset upon publication.", "published": "2025-04-29 04:15:33", "link": "http://arxiv.org/abs/2504.20409v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Creating Your Editable 3D Photorealistic Avatar with Tetrahedron-constrained Gaussian Splatting", "abstract": "Personalized 3D avatar editing holds significant promise due to its\nuser-friendliness and availability to applications such as AR/VR and virtual\ntry-ons. Previous studies have explored the feasibility of 3D editing, but\noften struggle to generate visually pleasing results, possibly due to the\nunstable representation learning under mixed optimization of geometry and\ntexture in complicated reconstructed scenarios. In this paper, we aim to\nprovide an accessible solution for ordinary users to create their editable 3D\navatars with precise region localization, geometric adaptability, and\nphotorealistic renderings. To tackle this challenge, we introduce a\nmeticulously designed framework that decouples the editing process into local\nspatial adaptation and realistic appearance learning, utilizing a hybrid\nTetrahedron-constrained Gaussian Splatting (TetGS) as the underlying\nrepresentation. TetGS combines the controllable explicit structure of\ntetrahedral grids with the high-precision rendering capabilities of 3D Gaussian\nSplatting and is optimized in a progressive manner comprising three stages: 3D\navatar instantiation from real-world monocular videos to provide accurate\npriors for TetGS initialization; localized spatial adaptation with explicitly\npartitioned tetrahedrons to guide the redistribution of Gaussian kernels; and\ngeometry-based appearance generation with a coarse-to-fine activation strategy.\nBoth qualitative and quantitative experiments demonstrate the effectiveness and\nsuperiority of our approach in generating photorealistic 3D editable avatars.", "published": "2025-04-29 03:56:36", "link": "http://arxiv.org/abs/2504.20403v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "FiLA-Video: Spatio-Temporal Compression for Fine-Grained Long Video Understanding", "abstract": "Recent advancements in video understanding within visual large language\nmodels (VLLMs) have led to notable progress. However, the complexity of video\ndata and contextual processing limitations still hinder long-video\ncomprehension. A common approach is video feature compression to reduce token\ninput to large language models, yet many methods either fail to prioritize\nessential features, leading to redundant inter-frame information, or introduce\ncomputationally expensive modules.To address these issues, we propose\nFiLA(Fine-grained Vision Language Model)-Video, a novel framework that\nleverages a lightweight dynamic-weight multi-frame fusion strategy, which\nadaptively integrates multiple frames into a single representation while\npreserving key video information and reducing computational costs. To enhance\nframe selection for fusion, we introduce a keyframe selection strategy,\neffectively identifying informative frames from a larger pool for improved\nsummarization. Additionally, we present a simple yet effective long-video\ntraining data generation strategy, boosting model performance without extensive\nmanual annotation. Experimental results demonstrate that FiLA-Video achieves\nsuperior efficiency and accuracy in long-video comprehension compared to\nexisting methods.", "published": "2025-04-29 03:09:46", "link": "http://arxiv.org/abs/2504.20384v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Neural Stereo Video Compression with Hybrid Disparity Compensation", "abstract": "Disparity compensation represents the primary strategy in stereo video\ncompression (SVC) for exploiting cross-view redundancy. These mechanisms can be\nbroadly categorized into two types: one that employs explicit horizontal\nshifting, and another that utilizes an implicit cross-attention mechanism to\nreduce cross-view disparity redundancy. In this work, we propose a hybrid\ndisparity compensation (HDC) strategy that leverages explicit pixel\ndisplacement as a robust prior feature to simplify optimization and perform\nimplicit cross-attention mechanisms for subsequent warping operations, thereby\ncapturing a broader range of disparity information. Specifically, HDC first\ncomputes a similarity map by fusing the horizontally shifted cross-view\nfeatures to capture pixel displacement information. This similarity map is then\nnormalized into an \"explicit pixel-wise attention score\" to perform the\ncross-attention mechanism, implicitly aligning features from one view to\nanother. Building upon HDC, we introduce a novel end-to-end optimized neural\nstereo video compression framework, which integrates HDC-based modules into key\ncoding operations, including cross-view feature extraction and reconstruction\n(HDC-FER) and cross-view entropy modeling (HDC-EM). Extensive experiments on\nSVC benchmarks, including KITTI 2012, KITTI 2015, and Nagoya, which cover both\nautonomous driving and general scenes, demonstrate that our framework\noutperforms both neural and traditional SVC methodologies.", "published": "2025-04-29 03:04:09", "link": "http://arxiv.org/abs/2504.20383v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "GSFeatLoc: Visual Localization Using Feature Correspondence on 3D Gaussian Splatting", "abstract": "In this paper, we present a method for localizing a query image with respect\nto a precomputed 3D Gaussian Splatting (3DGS) scene representation. First, the\nmethod uses 3DGS to render a synthetic RGBD image at some initial pose\nestimate. Second, it establishes 2D-2D correspondences between the query image\nand this synthetic image. Third, it uses the depth map to lift the 2D-2D\ncorrespondences to 2D-3D correspondences and solves a perspective-n-point (PnP)\nproblem to produce a final pose estimate. Results from evaluation across three\nexisting datasets with 38 scenes and over 2,700 test images show that our\nmethod significantly reduces both inference time (by over two orders of\nmagnitude, from more than 10 seconds to as fast as 0.1 seconds) and estimation\nerror compared to baseline methods that use photometric loss minimization.\nResults also show that our method tolerates large errors in the initial pose\nestimate of up to 55{\\deg} in rotation and 1.1 units in translation (normalized\nby scene scale), achieving final pose errors of less than 5{\\deg} in rotation\nand 0.05 units in translation on 90% of images from the Synthetic NeRF and\nMip-NeRF360 datasets and on 42% of images from the more challenging Tanks and\nTemples dataset.", "published": "2025-04-29 02:48:24", "link": "http://arxiv.org/abs/2504.20379v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Sparse2DGS: Geometry-Prioritized Gaussian Splatting for Surface Reconstruction from Sparse Views", "abstract": "We present a Gaussian Splatting method for surface reconstruction using\nsparse input views. Previous methods relying on dense views struggle with\nextremely sparse Structure-from-Motion points for initialization. While\nlearning-based Multi-view Stereo (MVS) provides dense 3D points, directly\ncombining it with Gaussian Splatting leads to suboptimal results due to the\nill-posed nature of sparse-view geometric optimization. We propose Sparse2DGS,\nan MVS-initialized Gaussian Splatting pipeline for complete and accurate\nreconstruction. Our key insight is to incorporate the geometric-prioritized\nenhancement schemes, allowing for direct and robust geometric learning under\nill-posed conditions. Sparse2DGS outperforms existing methods by notable\nmargins while being ${2}\\times$ faster than the NeRF-based fine-tuning\napproach.", "published": "2025-04-29 02:47:02", "link": "http://arxiv.org/abs/2504.20378v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Inception: Jailbreak the Memory Mechanism of Text-to-Image Generation Systems", "abstract": "Currently, the memory mechanism has been widely and successfully exploited in\nonline text-to-image (T2I) generation systems ($e.g.$, DALL$\\cdot$E 3) for\nalleviating the growing tokenization burden and capturing key information in\nmulti-turn interactions. Despite its practicality, its security analyses have\nfallen far behind. In this paper, we reveal that this mechanism exacerbates the\nrisk of jailbreak attacks. Different from previous attacks that fuse the unsafe\ntarget prompt into one ultimate adversarial prompt, which can be easily\ndetected or may generate non-unsafe images due to under- or over-optimization,\nwe propose Inception, the first multi-turn jailbreak attack against the memory\nmechanism in real-world text-to-image generation systems. Inception embeds the\nmalice at the inception of the chat session turn by turn, leveraging the\nmechanism that T2I generation systems retrieve key information in their memory.\nSpecifically, Inception mainly consists of two modules. It first segments the\nunsafe prompt into chunks, which are subsequently fed to the system in multiple\nturns, serving as pseudo-gradients for directive optimization. Specifically, we\ndevelop a series of segmentation policies that ensure the images generated are\nsemantically consistent with the target prompt. Secondly, after segmentation,\nto overcome the challenge of the inseparability of minimum unsafe words, we\npropose recursion, a strategy that makes minimum unsafe words subdivisible.\nCollectively, segmentation and recursion ensure that all the request prompts\nare benign but can lead to malicious outcomes. We conduct experiments on the\nreal-world text-to-image generation system ($i.e.$, DALL$\\cdot$E 3) to validate\nthe effectiveness of Inception. The results indicate that Inception surpasses\nthe state-of-the-art by a 14\\% margin in attack success rate.", "published": "2025-04-29 02:40:36", "link": "http://arxiv.org/abs/2504.20376v1", "categories": ["cs.CV", "cs.CR"], "primary_category": "cs.CV"}
{"title": "TTTFusion: A Test-Time Training-Based Strategy for Multimodal Medical Image Fusion in Surgical Robots", "abstract": "With the increasing use of surgical robots in clinical practice, enhancing\ntheir ability to process multimodal medical images has become a key research\nchallenge. Although traditional medical image fusion methods have made progress\nin improving fusion accuracy, they still face significant challenges in\nreal-time performance, fine-grained feature extraction, and edge\npreservation.In this paper, we introduce TTTFusion, a Test-Time Training\n(TTT)-based image fusion strategy that dynamically adjusts model parameters\nduring inference to efficiently fuse multimodal medical images. By adapting the\nmodel during the test phase, our method optimizes the parameters based on the\ninput image data, leading to improved accuracy and better detail preservation\nin the fusion results.Experimental results demonstrate that TTTFusion\nsignificantly enhances the fusion quality of multimodal images compared to\ntraditional fusion methods, particularly in fine-grained feature extraction and\nedge preservation. This approach not only improves image fusion accuracy but\nalso offers a novel technical solution for real-time image processing in\nsurgical robots.", "published": "2025-04-29 02:00:08", "link": "http://arxiv.org/abs/2504.20362v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MicarVLMoE: A Modern Gated Cross-Aligned Vision-Language Mixture of Experts Model for Medical Image Captioning and Report Generation", "abstract": "Medical image reporting (MIR) aims to generate structured clinical\ndescriptions from radiological images. Existing methods struggle with\nfine-grained feature extraction, multimodal alignment, and generalization\nacross diverse imaging types, often relying on vanilla transformers and\nfocusing primarily on chest X-rays. We propose MicarVLMoE, a vision-language\nmixture-of-experts model with gated cross-aligned fusion, designed to address\nthese limitations. Our architecture includes: (i) a multiscale vision encoder\n(MSVE) for capturing anatomical details at varying resolutions, (ii) a\nmultihead dual-branch latent attention (MDLA) module for vision-language\nalignment through latent bottleneck representations, and (iii) a modulated\nmixture-of-experts (MoE) decoder for adaptive expert specialization. We extend\nMIR to CT scans, retinal imaging, MRI scans, and gross pathology images,\nreporting state-of-the-art results on COVCTR, MMR, PGROSS, and ROCO datasets.\nExtensive experiments and ablations confirm improved clinical accuracy,\ncross-modal alignment, and model interpretability. Code is available at\nhttps://github.com/AI-14/micar-vl-moe.", "published": "2025-04-29 01:26:02", "link": "http://arxiv.org/abs/2504.20343v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DRO: Doppler-Aware Direct Radar Odometry", "abstract": "A renaissance in radar-based sensing for mobile robotic applications is\nunderway. Compared to cameras or lidars, millimetre-wave radars have the\nability to `see' through thin walls, vegetation, and adversarial weather\nconditions such as heavy rain, fog, snow, and dust. In this paper, we propose a\nnovel SE(2) odometry approach for spinning frequency-modulated continuous-wave\nradars. Our method performs scan-to-local-map registration of the incoming\nradar data in a direct manner using all the radar intensity information without\nthe need for feature or point cloud extraction. The method performs locally\ncontinuous trajectory estimation and accounts for both motion and Doppler\ndistortion of the radar scans. If the radar possesses a specific frequency\nmodulation pattern that makes radial Doppler velocities observable, an\nadditional Doppler-based constraint is formulated to improve the velocity\nestimate and enable odometry in geometrically feature-deprived scenarios (e.g.,\nfeatureless tunnels). Our method has been validated on over 250km of on-road\ndata sourced from public datasets (Boreas and MulRan) and collected using our\nautomotive platform. With the aid of a gyroscope, it outperforms\nstate-of-the-art methods and achieves an average relative translation error of\n0.26% on the Boreas leaderboard. When using data with the appropriate\nDoppler-enabling frequency modulation pattern, the translation error is reduced\nto 0.18% in similar environments. We also benchmarked our algorithm using 1.5\nhours of data collected with a mobile robot in off-road environments with\nvarious levels of structure to demonstrate its versatility. Our real-time\nimplementation is publicly available: https://github.com/utiasASRL/dro.", "published": "2025-04-29 01:20:30", "link": "http://arxiv.org/abs/2504.20339v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Fine Grain Classification: Connecting Meta using Cross-Contrastive pre-training", "abstract": "Fine-grained visual classification aims to recognize objects belonging to\nmultiple subordinate categories within a super-category. However, this remains\na challenging problem, as appearance information alone is often insufficient to\naccurately differentiate between fine-grained visual categories. To address\nthis, we propose a novel and unified framework that leverages meta-information\nto assist fine-grained identification. We tackle the joint learning of visual\nand meta-information through cross-contrastive pre-training. In the first\nstage, we employ three encoders for images, text, and meta-information,\naligning their projected embeddings to achieve better representations. We then\nfine-tune the image and meta-information encoders for the classification task.\nExperiments on the NABirds dataset demonstrate that our framework effectively\nutilizes meta-information to enhance fine-grained recognition performance. With\nthe addition of meta-information, our framework surpasses the current baseline\non NABirds by 7.83%. Furthermore, it achieves an accuracy of 84.44% on the\nNABirds dataset, outperforming many existing state-of-the-art approaches that\nutilize meta-information.", "published": "2025-04-29 00:23:41", "link": "http://arxiv.org/abs/2504.20322v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Note about the complexity of the acyclic orientation with parity constraint problem", "abstract": "Let $G = (V, E)$ be a connected graph, and let $T$ in $V$ be a subset of\nvertices. An orientation of $G$ is called $T$-odd if any vertex $v \\in V$ has\nodd in-degree if and only if it is in $T$. Finding a T -odd orientation of G\ncan be solved in polynomial time as shown by Chevalier, Jaeger, Payan and Xuong\n(1983). Since then, $T$-odd orientations have continued to attract interest,\nparticularly in the context of global constraints on the orientation. For\ninstance, Frank and Kir\\'aly (2002) investigated $k$-connected $T$-odd\norientations and raised questions about acyclic $T$-odd orientations. This\nproblem is now recognized as an Egres problem and is known as the \"Acyclic\norientation with parity constraints\" problem. Szegedy ( 005) proposed a\nrandomized polynomial algorithm to address this problem. An easy consequence of\nhis work provides a polynomial time algorithm for planar graphs whenever $|T |\n= |V | - 1$. Nevertheless, it remains unknown whether it exists in general. In\nthis paper we contribute to the understanding of the complexity of this problem\nby studying a more general one. We prove that finding a $T$-odd acyclic\norientation on graphs having some directed edges is NP-complete.", "published": "2025-04-29 16:56:48", "link": "http://arxiv.org/abs/2504.20935v1", "categories": ["cs.DM", "math.CO"], "primary_category": "cs.DM"}
{"title": "Periodicity and local complexity of Delone sets", "abstract": "We study complexity and periodicity of Delone sets by applying an algebraic\napproach to multidimensional symbolic dynamics. In this algebraic approach,\n$\\mathbb{Z}^d$-configurations $c: \\mathbb{Z}^d \\to \\mathcal{A}$ for a finite\nset $\\mathcal{A} \\subseteq \\mathbb{C}$ and finite $\\mathbb{Z}^d$-patterns are\nregarded as formal power series and Laurent polynomials, respectively. In this\npaper we study also functions $c: \\mathbb{R}^d \\to \\mathcal{A}$ where\n$\\mathcal{A}$ is as above. These functions are called\n$\\mathbb{R}^d$-configurations. Any Delone set may be regarded as an\n$\\mathbb{R}^d$-configuration by simply presenting it as its indicator function.\nConversely, any $\\mathbb{R}^d$-configuration whose support (that is, the set of\ncells for which the configuration gets non-zero values) is a Delone set can be\nseen as a colored Delone set. We generalize the concept of annihilators and\nperiodizers of $\\mathbb{Z}^d$-configurations for $\\mathbb{R}^d$-configurations.\nWe show that if an $\\mathbb{R}^d$-configuration has a non-trivial annihilator,\nthat is, if a linear combination of some finitely many of its translations is\nthe zero function, then it has an annihilator of a particular form. Moreover,\nwe show that $\\mathbb{R}^d$-configurations with integer coefficients that have\nnon-trivial annihilators are sums of finitely many periodic functions\n$c_1,\\ldots,c_m: \\mathbb{R}^d \\to \\mathbb{Z}$. Also, $\\mathbb{R}^d$-pattern\ncomplexity is studied alongside with the classical patch-complexity of Delone\nsets. We point out the fact that sufficiently low $\\mathbb{R}^d$-pattern\ncomplexity of an $\\mathbb{R}^d$-configuration implies the existence of\nnon-trivial annihilators. Moreover, it is shown that if a Meyer set has\nsufficiently slow patch-complexity growth, then it has a non-trivial\nannihilator. Finally, a condition for forced periodicity of colored Delone sets\nof finite local complexity is provided.", "published": "2025-04-29 12:41:01", "link": "http://arxiv.org/abs/2504.20709v1", "categories": ["math.DS", "cs.DM", "math.CO"], "primary_category": "math.DS"}
{"title": "On the structure of (dart, odd hole)-free graphs", "abstract": "A hole is a chordless cycle with at least four vertices. A hole is odd if it\nhas an odd number of vertices. A dart is a graph which vertices $a, b, c, d, e$\nand edges $ab, bc, bd, be, cd, de$. Dart-free graphs have been actively studied\nin the literature. We prove that a (dart, odd hole)-free graph is perfect, or\ndoes not contain a stable set on three vertices, or is the join or co-join of\ntwo smaller graphs. Using this structure result, we design a polynomial-time\nalgorithm for finding an optimal colouring of (dart, odd hole)-free graphs. A\ngraph $G$ is perfectly divisible if every induced subgraph $H$ of $G$ contains\na set $X$ of vertices such that $X$ meets all largest cliques of $H$, and $X$\ninduces a perfect graph. The chromatic number of a perfectly divisible graph\n$G$ is bounded by $\\omega^2$ where $\\omega$ denotes the number of vertices in a\nlargest clique of $G$. We prove that (dart, odd hole)-free graphs are perfectly\ndivisible.", "published": "2025-04-29 04:33:46", "link": "http://arxiv.org/abs/2504.20422v1", "categories": ["math.CO", "cs.DM", "05C15, 05C85"], "primary_category": "math.CO"}
{"title": "Approximately Dominating Sets in Elections", "abstract": "Condorcet's paradox is a fundamental result in social choice theory which\nstates that there exist elections in which, no matter which candidate wins, a\nmajority of voters prefer a different candidate. In fact, even if we can select\nany $k$ winners, there still may exist another candidate that would beat each\nof the winners in a majority vote. That is, elections may require arbitrarily\nlarge dominating sets.\n  We show that approximately dominating sets of constant size always exist. In\nparticular, for every $\\varepsilon > 0$, every election (irrespective of the\nnumber of voters or candidates) can select $O(\\frac{1}{\\varepsilon ^2})$\nwinners such that no other candidate beats each of the winners by a margin of\nmore than $\\varepsilon$ fraction of voters.\n  Our proof uses a simple probabilistic construction using samples from a\nmaximal lottery, a well-studied distribution over candidates derived from the\nNash equilibrium of a two-player game. In stark contrast to general approximate\nequilibria, which may require support logarithmic in the number of pure\nstrategies, we show that maximal lotteries can be approximated with constant\nsupport size. These approximate maximal lotteries may be of independent\ninterest.", "published": "2025-04-29 02:30:00", "link": "http://arxiv.org/abs/2504.20372v1", "categories": ["cs.GT", "cs.DM", "cs.DS", "math.CO"], "primary_category": "cs.GT"}
{"title": "RecGaze: The First Eye Tracking and User Interaction Dataset for Carousel Interfaces", "abstract": "Carousel interfaces are widely used in e-commerce and streaming services, but\nlittle research has been devoted to them. Previous studies of interfaces for\npresenting search and recommendation results have focused on single ranked\nlists, but it appears their results cannot be extrapolated to carousels due to\nthe added complexity. Eye tracking is a highly informative approach to\nunderstanding how users click, yet there are no eye tracking studies concerning\ncarousels. There are very few interaction datasets on recommenders with\ncarousel interfaces and none that contain gaze data.\n  We introduce the RecGaze dataset: the first comprehensive feedback dataset on\ncarousels that includes eye tracking results, clicks, cursor movements, and\nselection explanations. The dataset comprises of interactions from 3 movie\nselection tasks with 40 different carousel interfaces per user. In total, 87\nusers and 3,477 interactions are logged. In addition to the dataset, its\ndescription and possible use cases, we provide results of a survey on carousel\ndesign and the first analysis of gaze data on carousels, which reveals a golden\ntriangle or F-pattern browsing behavior.\n  Our work seeks to advance the field of carousel interfaces by providing the\nfirst dataset with eye tracking results on carousels. In this manner, we\nprovide and encourage an empirical understanding of interactions with carousel\ninterfaces, for building better recommender systems through gaze information,\nand also encourage the development of gaze-based recommenders.", "published": "2025-04-29 14:09:20", "link": "http://arxiv.org/abs/2504.20792v1", "categories": ["cs.IR", "cs.HC"], "primary_category": "cs.IR"}
{"title": "Natural Language Processing tools for Pharmaceutical Manufacturing Information Extraction from Patents Natural Language Processing (NLP) tools for Pharmaceutical Manufacturing Information Extraction from Patents", "abstract": "Abundant and diverse data on medicines manufacturing and other lifecycle\ncomponents has been made easily accessible in the last decades. However, a\nsignificant proportion of this information is characterised by not being\ntabulated and usable for machine learning purposes. Thus, natural language\nprocessing tools have been used to build databases in domains such as\nbiomedical and chemical to address this limitation. This has allowed the\ndevelopment of artificial intelligence applications, which have improved drug\ndiscovery and treatments. In the pharmaceutical manufacturing context, some\ninitiatives and datasets for primary processing can be found, but the\nmanufacturing of drug products is an area which is still lacking, to the best\nof our knowledge. This works aims to explore and adapt NLP tools used in other\ndomains to extract information on both primary and secondary manufacturing,\nemploying patents as the main source of data. Thus, two independent, but\ncomplementary, models were developed comprising a method to select fragments of\ntext that contain manufacturing data, and a named entity recognition system\nthat enables extracting information on operations, materials, and conditions of\na process. For the first model, the identification of relevant sections was\nachieved using an unsupervised approach combining Latent Dirichlet Allocation\nand k-Means clustering. The performance of this model measured as a Cohen's\nkappa between model output and manual revision was higher than 90%. NER model\nconsisted of a deep neural network, and an f1-score micro average of 84.2% was\nobtained which is comparable to other works. Some considerations for these\ntools to be used in data extraction are discussed throughout this document.", "published": "2025-04-29 09:56:23", "link": "http://arxiv.org/abs/2504.20598v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Quantum Hypothesis Testing Lemma for Deterministic Identification over Quantum Channels", "abstract": "In our previous work, we presented the Hypothesis Testing Lemma, a key tool\nthat establishes sufficient conditions for the existence of good deterministic\nidentification (DI) codes for memoryless channels with finite output, but\narbitrary input alphabets. In this work, we provide a full quantum analogue of\nthis lemma, which shows that the existence of a DI code in the quantum setting\nfollows from a suitable packing in a modified space of output quantum states.\nSpecifically, we demonstrate that such a code can be constructed using product\nstates derived from this packing. This result enables us to tighten the\ncapacity lower bound for DI over quantum channels beyond the simultaneous\ndecoding approach. In particular, we can now express these bounds solely in\nterms of the Minkowski dimension of a certain state space, giving us new\ninsights to better understand the nature of the protocol, and the separation\nbetween simultaneous and non-simultaneous codes. We extend the discussion with\na particular channel example for which we can construct an optimum code.", "published": "2025-04-29 17:57:36", "link": "http://arxiv.org/abs/2504.20991v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Simple Finite-Length Achievability and Converse Bounds for the Deletion Channel and the Insertion Channel", "abstract": "We develop upper bounds on code size for independent and identically\ndistributed deletion (insertion) channel for given code length and target frame\nerror probability. The bounds are obtained as a variation of a general converse\nbound, which, though available for any channel, is inefficient and not easily\ncomputable without a good reference distribution over the output alphabet. We\nobtain a reference output distribution for a general finite-input finite-output\nchannel and provide a simple formula for the converse bound on the capacity\nemploying this distribution. We then evaluate the bound for the deletion\nchannel with a finite block length and show that the resulting upper bound on\nthe code side is tighter than that for a binary erasure channel, which is the\nonly alternative converse bound for this finite-length setting. Also, we\nprovide the similar results for the insertion channel.", "published": "2025-04-29 17:32:27", "link": "http://arxiv.org/abs/2504.20961v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Secrecy-Sensing Optimization of RIS-assisted Full-Duplex Integrated Sensing and Communication Network", "abstract": "Integrated sensing and communication (ISAC) has recently emerged as a viable\ntechnique for establishing sensing and communication using the same resources.\nNonetheless, the operation of ISAC networks is often challenged by the absence\nof a direct link between the sensing node and the targets, and by the risk of\ndisclosing confidential data to malicious targets when using the same signal\nfor both tasks. In this paper, a robust reconfigurable intelligent surface\n(RIS)-aided scheme for securing a full-duplex (FD) ISAC network is proposed.\nThe considered network consists of uplink and downlink users served in FD\nthrough a multi-antenna dual-functional radar communication base station (BS),\nwhich employs co-located multi-antenna communication-radar arrays to detect\nmultiple malicious targets while preserving communication secrecy in their\npresence. Additionally, the BS utilizes an optimized artificial noise (AN) that\nserves to disrupt the malicious targets' reception and increase the sensing\npower. By optimally designing the RIS phase shifts, transmit beamforming, AN\ncovariance, and uplink users' transmit power and combining vectors using an\nalternating optimization-based algorithm, the network's sensing performance is\nmaximized under secrecy and total power constraints. Numerical results present\nthe proposed scheme's efficacy, particularly when a direct link between the BS\nand the various nodes/targets is absent.", "published": "2025-04-29 16:32:22", "link": "http://arxiv.org/abs/2504.20912v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "New Capacity Bounds for PIR on Graph and Multigraph-Based Replicated Storage", "abstract": "In this paper, we study the problem of private information retrieval (PIR) in\nboth graph-based and multigraph-based replication systems, where each file is\nstored on exactly two servers, and any pair of servers shares at most $r$\nfiles. We derive upper bounds on the PIR capacity for such systems and\nconstruct PIR schemes that approach these bounds. For graph-based systems, we\ndetermine the exact PIR capacity for path graphs and improve upon existing\nresults for complete bipartite graphs and complete graphs. For multigraph-based\nsystems, we propose a PIR scheme that leverages the symmetry of the underlying\ngraph-based construction, yielding a capacity lower bound for such multigraphs.\nFurthermore, we establish several general upper and lower bounds on the PIR\ncapacity of multigraphs, which are tight in certain cases.", "published": "2025-04-29 16:05:42", "link": "http://arxiv.org/abs/2504.20888v1", "categories": ["cs.IT", "cs.CR", "math.CO", "math.IT", "68P20, 68P27", "H.3.3"], "primary_category": "cs.IT"}
{"title": "The relative entropy of primes in arithmetic progressions is really small", "abstract": "Fix a modulus $q$. One would expect the number of primes in each invertible\nresidue class mod $q$ to be multinomially distributed, i.e. for each $p\n\\,\\mathrm{mod}\\, q$ to behave like an independent random variable uniform on\n$(\\mathbb{Z}/q\\mathbb{Z})^\\times$. Using techniques from data science, we\ndiscover overwhelming evidence to the contrary: primes are much more uniformly\ndistributed than iid uniform random variables. This phenomenon was previously\nunknown, and there is no clear theoretical explanation for it.\n  To demonstrate that our test statistic of choice, the KL divergence, is\nindeed extreme, we prove new bounds for the left tail of the relative entropy\nof the uniform multinomial using the method of types.", "published": "2025-04-29 12:15:00", "link": "http://arxiv.org/abs/2504.20691v1", "categories": ["math.NT", "cs.IT", "math.IT", "math.PR", "math.ST", "stat.TH"], "primary_category": "math.NT"}
{"title": "On the Optimal Source Key Size of Secure Gradient Coding", "abstract": "With gradient coding, a user node can efficiently aggregate gradients from\nserver nodes processing local datasets, achieving low communication costs and\nmaintaining resilience against straggling servers. This paper considers a\nsecure gradient coding problem, where a user aims to compute the sum of the\ngradients from $K$ datasets with the assistance of $N$ distributed servers. The\nuser should recover the sum of gradients by receiving transmissions from any\n$N_r$ servers, and each dataset is assigned to $N - N_r + m$ servers. The\nsecurity constraint guarantees that even if the user receives transmissions\nfrom all servers, it cannot obtain any additional information about the\ndatasets beyond the sum of gradients.\n  It has been shown in the literature that this security constraint does not\nincrease the optimal communication cost of the gradient coding problem,\nprovided enough source keys are shared among the servers. However, the minimum\nrequired source key size that ensures security while maintaining this optimal\ncommunication cost has only been studied for the special case $m = 1$. In this\npaper, we focus on the more general case $m \\geq 1$ and aim to determine the\nminimum required source key size for this purpose.\n  We propose a new information-theoretic converse bound on the source key size,\nas well as a new achievable scheme with carefully designed data assignments.\nOur scheme outperforms the existing optimal scheme based on the widely used\ncyclic data assignment and coincides with the converse bound under certain\nsystem parameters.", "published": "2025-04-29 11:37:31", "link": "http://arxiv.org/abs/2504.20662v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Quantum-Enhanced Hybrid Reinforcement Learning Framework for Dynamic Path Planning in Autonomous Systems", "abstract": "In this paper, a novel quantum classical hybrid framework is proposed that\nsynergizes quantum with Classical Reinforcement Learning. By leveraging the\ninherent parallelism of quantum computing, the proposed approach generates\nrobust Q tables and specialized turn cost estimations, which are then\nintegrated with a classical Reinforcement Learning pipeline. The Classical\nQuantum fusion results in rapid convergence of training, reducing the training\ntime significantly and improved adaptability in scenarios featuring static,\ndynamic, and moving obstacles. Simulator based evaluations demonstrate\nsignificant enhancements in path efficiency, trajectory smoothness, and mission\nsuccess rates, underscoring the potential of framework for real time,\nautonomous navigation in complex and unpredictable environments. Furthermore,\nthe proposed framework was tested beyond simulations on practical scenarios,\nincluding real world map data such as the IIT Delhi campus, reinforcing its\npotential for real time, autonomous navigation in complex and unpredictable\nenvironments.", "published": "2025-04-29 11:36:08", "link": "http://arxiv.org/abs/2504.20660v1", "categories": ["cs.LG", "cs.ET", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Multi-Message Secure Aggregation with Demand Privacy", "abstract": "This paper considers a multi-message secure aggregation with privacy problem,\nin which a server aims to compute $\\sf K_c\\geq 1$ linear combinations of local\ninputs from $\\sf K$ distributed users. The problem addresses two tasks: (1)\nsecurity, ensuring that the server can only obtain the desired linear\ncombinations without any else information about the users' inputs, and (2)\nprivacy, preventing users from learning about the server's computation task. In\naddition, the effect of user dropouts is considered, where at most $\\sf{K-U}$\nusers can drop out and the identity of these users cannot be predicted in\nadvance. We propose two schemes for $\\sf K_c$ is equal to (1) and $\\sf 2\\leq\nK_c\\leq U-1$, respectively. For $\\sf K_c$ is equal to (1), we introduce\nmultiplicative encryption of the server's demand using a random variable, where\nusers share coded keys offline and transmit masked models in the first round,\nfollowed by aggregated coded keys in the second round for task recovery. For\n$\\sf{2\\leq K_c \\leq U-1}$, we use robust symmetric private computation to\nrecover linear combinations of keys in the second round. The objective is to\nminimize the number of symbols sent by each user during the two rounds. Our\nproposed schemes have achieved the optimal rate region when $ \\sf K_c $ is\nequal to (1) and the order optimal rate (within 2) when $\\sf{2\\leq K_c \\leq\nU-1}$.", "published": "2025-04-29 11:11:27", "link": "http://arxiv.org/abs/2504.20639v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Statistical Channel Based Low-Complexity Rotation and Position Optimization for 6D Movable Antennas Enabled Wireless Communication", "abstract": "Six-dimensional movable antenna (6DMA) is a promising technology to fully\nexploit spatial variation in wireless channels by allowing flexible adjustment\nof three-dimensional (3D) positions and rotations of antennas at the\ntransceiver. In this paper, we investigate the practical low-complexity design\nof 6DMA-enabled communication systems, including transmission protocol,\nstatistical channel information (SCI) acquisition, and joint position and\nrotation optimization of 6DMA surfaces based on the SCI of users. Specifically,\nan orthogonal matching pursuit (OMP)-based algorithm is proposed for the\nestimation of SCI of users at all possible position-rotation pairs of 6DMA\nsurfaces based on the channel measurements at a small subset of\nposition-rotation pairs. Then, the average sum logarithmic rate of all users is\nmaximized by jointly designing the positions and rotations of 6DMA surfaces\nbased on their SCI acquired. Different from prior works on 6DMA which adopt\nalternating optimization to design 6DMA positions/rotations with iterations, we\npropose a new sequential optimization approach that first determines 6DMA\nrotations and then finds their feasible positions to realize the optimized\nrotations subject to practical antenna placement constraints. Simulation\nresults show that the proposed sequential optimization significantly reduces\nthe computational complexity of conventional alternating optimization, while\nachieving comparable communication performance. It is also shown that the\nproposed SCI-based 6DMA design can effectively enhance the communication\nthroughput of wireless networks over existing fixed (position and rotation)\nantenna arrays, yet with a practically appealing low-complexity implementation.", "published": "2025-04-29 10:37:34", "link": "http://arxiv.org/abs/2504.20618v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "SNR-aware Semantic Image Transmission with Deep Learning-based Channel Estimation in Fading Channels", "abstract": "Semantic communications (SCs) play a central role in shaping the future of\nthe sixth generation (6G) wireless systems, which leverage rapid advances in\ndeep learning (DL). In this regard, end-to-end optimized DL-based joint\nsource-channel coding (JSCC) has been adopted to achieve SCs, particularly in\nimage transmission. Utilizing vision transformers in the encoder/decoder design\nhas enabled significant advancements in image semantic extraction, surpassing\ntraditional convolutional neural networks (CNNs). In this paper, we propose a\nnew JSCC paradigm for image transmission, namely Swin semantic image\ntransmission (SwinSIT), based on the Swin transformer. The Swin transformer is\nemployed to construct both the semantic encoder and decoder for efficient image\nsemantic extraction and reconstruction. Inspired by the\nsqueezing-and-excitation (SE) network, we introduce a signal-to-noise-ratio\n(SNR)-aware module that utilizes SNR feedback to adaptively perform a\ndouble-phase enhancement for the encoder-extracted semantic map and its noisy\nversion at the decoder. Additionally, a CNN-based channel estimator and\ncompensator (CEAC) module repurposes an image-denoising CNN to mitigate fading\nchannel effects. To optimize deployment in resource-constrained IoT devices, a\njoint pruning and quantization scheme compresses the SwinSIT model. Simulations\nevaluate the SwinSIT performance against conventional benchmarks demonstrating\nits effectiveness. Moreover, the model's compressed version substantially\nreduces its size while maintaining favorable PSNR performance.", "published": "2025-04-29 08:57:47", "link": "http://arxiv.org/abs/2504.20557v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Identification over Poisson ISI Channels: Feedback and Molecular Applications", "abstract": "Molecular communication (MC) enables information transfer via molecules,\nmaking it ideal for biomedical applications where traditional methods fall\nshort. In many such scenarios, identifying specific events is more critical\nthan decoding full messages, motivating the use of deterministic identification\n(DI). This paper investigates DI over discrete-time Poisson channels (DTPCs)\nwith inter-symbol interference (ISI), a realistic setting due to channel memory\neffects. We improve the known upper bound on DI capacity under power\nconstraints from $\\frac{3}{2} + \\kappa$ to $\\frac{1 + \\kappa}{2}$.\nAdditionally, we present the first results on deterministic identification with\nfeedback (DIF) in this context, providing a constructive lower bound. These\nfindings enhance the theoretical understanding of MC and support more\nefficient, feedback-driven biomedical systems.", "published": "2025-04-29 08:53:27", "link": "http://arxiv.org/abs/2504.20550v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Randomstrasse101: Open Problems of 2024", "abstract": "$\\texttt{Randomstrasse101}$ is a blog dedicated to Open Problems in\nMathematics, with a focus on Probability Theory, Computation, Combinatorics,\nStatistics, and related topics. This manuscript serves as a stable record of\nthe Open Problems posted in 2024, with the goal of easing academic referencing.\nThe blog can currently be accessed at $\\texttt{randomstrasse101.math.ethz.ch}$.", "published": "2025-04-29 08:32:59", "link": "http://arxiv.org/abs/2504.20539v1", "categories": ["math.PR", "cs.IT", "math.CO", "math.IT", "math.OC", "math.ST", "stat.TH"], "primary_category": "math.PR"}
{"title": "Enhancing Binary Search via Overlapping Partitions", "abstract": "This paper considers the task of performing binary search under noisy\ndecisions, focusing on the application of target area localization. In the\npresence of noise, the classical partitioning approach of binary search is\nprone to error propagation due to the use of strictly disjoint splits. While\nexisting works on noisy binary search propose techniques such as query\nrepetition or probabilistic updates to mitigate errors, they often lack\nexplicit mechanisms to manage the trade-off between error probability and\nsearch complexity, with some providing only asymptotic guarantees. To address\nthis gap, we propose a binary search framework with tunable overlapping\npartitions, which introduces controlled redundancy into the search process to\nenhance robustness against noise. We analyze the performance of the proposed\nalgorithm in both discrete and continuous domains for the problem of area\nlocalization, quantifying how the overlap parameter impacts the trade-off\nbetween search tree depth and error probability. Unlike previous methods, this\napproach allows for direct control over the balance between reliability and\nefficiency. Our results emphasize the versatility and effectiveness of the\nproposed method, providing a principled extension to existing noisy search\nparadigms and enabling new insights into the interplay between partitioning\nstrategies and measurement reliability.", "published": "2025-04-29 07:56:02", "link": "http://arxiv.org/abs/2504.20513v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Sequence Reconstruction under Channels with Multiple Bursts of Insertions or Deletions", "abstract": "The sequence reconstruction problem involves a model where a sequence is\ntransmitted over several identical channels. This model investigates the\nminimum number of channels required for the unique reconstruction of the\ntransmitted sequence. Levenshtein established that this number exceeds the\nmaximum size of the intersection between the error balls of any two distinct\ntransmitted sequences by one. In this paper, we consider channels subject to\nmultiple bursts of insertions and multiple bursts of deletions, respectively,\nwhere each burst has an exact length of value b. We provide a complete solution\nfor the insertion case while partially addressing the deletion case.", "published": "2025-04-29 06:47:12", "link": "http://arxiv.org/abs/2504.20460v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Metaheuristic Optimization of Trajectory and Dynamic Time Splitting for UAV Communication Systems", "abstract": "The integration of unmanned aerial vehicles (UAVs) into wireless\ncommunication systems has emerged as a transformative approach, promising\ncost-efficient connectivity. This paper addresses the optimization of the\ndynamic time-splitting ratio and flight trajectory for a communication system\nlinking a ground base station to the UAV equipped with backscatter devices\n(referred to as UB), and from UB to an end user. Given the inherent\nnon-convexity of the problem, we develop two meta-heuristic-based approaches\ninspired by genetic algorithm and particle swarm optimization to enhance the\ntotal achievable rate while reducing computational complexity. Numerical\nresults demonstrate the effectiveness of these meta-heuristic solutions,\nshowcasing significant improvements in the achievable rate and computation time\ncompared to existing benchmarks.", "published": "2025-04-29 04:39:29", "link": "http://arxiv.org/abs/2504.20425v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Geography-Inspired and Self-Adaptive Clustering Algorithm: A Study in Channel Measurement", "abstract": "The phenomenon that multi-path components (MPCs) arrive in clusters has been\nverified by channel measurements, and is widely adopted by cluster-based\nchannel models. As a crucial intermediate processing step, MPC clustering\nbridges raw data in channel measurement and cluster characteristics for channel\nmodeling. In this paper, a physical-interpretable and self-adaptive MPC\nclustering algorithm is proposed, which can locate both single-point and\nwide-spread scatterers without prior knowledge. Inspired by the concept in\ngeography, a novel metaphor that interprets features of MPC attributes in the\npower-delay-angle profile (PDAP) as topographic concepts is developed. In light\nof the interpretation, the proposed algorithm disassembles the PDAP by\nconstructing contour lines and identifying characteristic points that indicate\nthe skeleton of MPC clusters, which are fitted by analytical models that\nassociate MPCs with physical scatterer locations. Besides, a new clustering\nperformance index, the power gradient consistency index, is proposed.\nCalculated as the weighted Spearman correlation coefficient between the power\nand the distance to the center, the index captures the intrinsic property of\nMPC clusters that the dominant high-power path is surrounded by lower-power\npaths. The performance of the proposed algorithm is analyzed and compared with\nthe counterparts of conventional clustering algorithms based on the channel\nmeasurement conducted in an outdoor scenario. The proposed algorithm performs\nbetter in average Silhouette index and weighted Spearman correlation\ncoefficient, and the average root mean square error (RMSE) of the estimated\nscatterer location is 0.1 m.", "published": "2025-04-29 04:32:03", "link": "http://arxiv.org/abs/2504.20420v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Terahertz Wireless Data Center: Gaussian Beam or Airy Beam?", "abstract": "Terahertz (THz) communication is emerging as a pivotal enabler for 6G and\nbeyond wireless systems owing to its multi-GHz bandwidth. One of its novel\napplications is in wireless data centers, where it enables ultra-high data\nrates while enhancing network reconfigurability and scalability. However, due\nto numerous racks, supporting walls, and densely deployed antennas, the\nline-of-sight (LoS) path in data centers is often instead of fully obstructed,\nresulting in quasi-LoS propagation and degradation of spectral efficiency. To\naddress this issue, Airy beam-based hybrid beamforming is investigated in this\npaper as a promising technique to mitigate quasi-LoS propagation and enhance\nspectral efficiency in THz wireless data centers. Specifically, a cascaded\ngeometrical and wave-based channel model (CGWCM) is proposed for quasi-LoS\nscenarios, which accounts for diffraction effects while being more simplified\nthan conventional wave-based model. Then, the characteristics and generation of\nthe Airy beam are analyzed, and beam search methods for quasi-LoS scenarios are\nproposed, including hierarchical focusing-Airy beam search, and low-complexity\nbeam search. Simulation results validate the effectiveness of the CGWCM and\ndemonstrate the superiority of the Airy beam over Gaussian beams in mitigating\nblockages, verifying its potential for practical THz wireless communication in\ndata centers.", "published": "2025-04-29 04:15:52", "link": "http://arxiv.org/abs/2504.20410v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "List Decoding Expander-Based Codes up to Capacity in Near-Linear Time", "abstract": "We give a new framework based on graph regularity lemmas, for list decoding\nand list recovery of codes based on spectral expanders. Using existing\nalgorithms for computing regularity decompositions of sparse graphs in\n(randomized) near-linear time, and appropriate choices for the constant-sized\ninner/base codes, we prove the following:\n  - Expander-based codes constructed using the distance amplification technique\nof Alon, Edmonds and Luby [FOCS 1995] with rate $\\rho$, can be list decoded to\na radius $1 - \\rho - \\epsilon$ in near-linear time. By known results, the\noutput list has size $O(1/\\epsilon)$.\n  - The above codes of Alon, Edmonds and Luby, with rate $\\rho$, can also be\nlist recovered to radius $1 - \\rho - \\epsilon$ in near-linear time, with\nconstant-sized output lists.\n  - The Tanner code construction of Sipser and Spielman [IEEE Trans. Inf.\nTheory 1996] with distance $\\delta$, can be list decoded to radius $\\delta -\n\\epsilon$ in near-linear time, with constant-sized output lists.\n  Our results imply novel combinatorial as well as algorithmic bounds for each\nof the above explicit constructions. All of these bounds are obtained via\ncombinatorial rigidity phenomena, proved using (weak) graph regularity. The\nregularity framework allows us to lift the list decoding and list recovery\nproperties for the local base codes, to the global codes obtained via the above\nconstructions.", "published": "2025-04-29 00:53:34", "link": "http://arxiv.org/abs/2504.20333v1", "categories": ["cs.DS", "cs.CC", "cs.IT", "math.IT"], "primary_category": "cs.DS"}
{"title": "ACE: A Security Architecture for LLM-Integrated App Systems", "abstract": "LLM-integrated app systems extend the utility of Large Language Models (LLMs)\nwith third-party apps that are invoked by a system LLM using interleaved\nplanning and execution phases to answer user queries. These systems introduce\nnew attack vectors where malicious apps can cause integrity violation of\nplanning or execution, availability breakdown, or privacy compromise during\nexecution.\n  In this work, we identify new attacks impacting the integrity of planning, as\nwell as the integrity and availability of execution in LLM-integrated apps, and\ndemonstrate them against IsolateGPT, a recent solution designed to mitigate\nattacks from malicious apps. We propose Abstract-Concrete-Execute (ACE), a new\nsecure architecture for LLM-integrated app systems that provides security\nguarantees for system planning and execution. Specifically, ACE decouples\nplanning into two phases by first creating an abstract execution plan using\nonly trusted information, and then mapping the abstract plan to a concrete plan\nusing installed system apps. We verify that the plans generated by our system\nsatisfy user-specified secure information flow constraints via static analysis\non the structured plan output. During execution, ACE enforces data and\ncapability barriers between apps, and ensures that the execution is conducted\naccording to the trusted abstract plan. We show experimentally that our system\nis secure against attacks from the INJECAGENT benchmark, a standard benchmark\nfor control flow integrity in the face of indirect prompt injection attacks,\nand our newly introduced attacks. Our architecture represents a significant\nadvancement towards hardening LLM-based systems containing system facilities of\nvarying levels of trustworthiness.", "published": "2025-04-29 17:55:52", "link": "http://arxiv.org/abs/2504.20984v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Provably faster randomized and quantum algorithms for k-means clustering via uniform sampling", "abstract": "The $k$-means algorithm (Lloyd's algorithm) is a widely used method for\nclustering unlabeled data. A key bottleneck of the $k$-means algorithm is that\neach iteration requires time linear in the number of data points, which can be\nexpensive in big data applications. This was improved in recent works proposing\nquantum and quantum-inspired classical algorithms to approximate the $k$-means\nalgorithm locally, in time depending only logarithmically on the number of data\npoints (along with data dependent parameters) [$q$-means: A quantum algorithm\nfor unsupervised machine learning; Kerenidis, Landman, Luongo, and Prakash,\nNeurIPS 2019; Do you know what $q$-means?, Doriguello, Luongo, Tang]. In this\nwork, we describe a simple randomized mini-batch $k$-means algorithm and a\nquantum algorithm inspired by the classical algorithm. We prove worse-case\nguarantees that significantly improve upon the bounds for previous algorithms.\nOur improvements are due to a careful use of uniform sampling, which preserves\ncertain symmetries of the $k$-means problem that are not preserved in previous\nalgorithms that use data norm-based sampling.", "published": "2025-04-29 17:51:29", "link": "http://arxiv.org/abs/2504.20982v1", "categories": ["quant-ph", "cs.DS", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Equivariant non-linear maps for neural networks on homogeneous spaces", "abstract": "This paper presents a novel framework for non-linear equivariant neural\nnetwork layers on homogeneous spaces. The seminal work of Cohen et al. on\nequivariant $G$-CNNs on homogeneous spaces characterized the representation\ntheory of such layers in the linear setting, finding that they are given by\nconvolutions with kernels satisfying so-called steerability constraints.\nMotivated by the empirical success of non-linear layers, such as self-attention\nor input dependent kernels, we set out to generalize these insights to the\nnon-linear setting. We derive generalized steerability constraints that any\nsuch layer needs to satisfy and prove the universality of our construction. The\ninsights gained into the symmetry-constrained functional dependence of\nequivariant operators on feature maps and group elements informs the design of\nfuture equivariant neural network layers. We demonstrate how several common\nequivariant network architectures - $G$-CNNs, implicit steerable kernel\nnetworks, conventional and relative position embedded attention based\ntransformers, and LieTransformers - may be derived from our framework.", "published": "2025-04-29 17:42:56", "link": "http://arxiv.org/abs/2504.20974v1", "categories": ["cs.LG", "math.RT", "stat.ML"], "primary_category": "cs.LG"}
{"title": "XPG-RL: Reinforcement Learning with Explainable Priority Guidance for Efficiency-Boosted Mechanical Search", "abstract": "Mechanical search (MS) in cluttered environments remains a significant\nchallenge for autonomous manipulators, requiring long-horizon planning and\nrobust state estimation under occlusions and partial observability. In this\nwork, we introduce XPG-RL, a reinforcement learning framework that enables\nagents to efficiently perform MS tasks through explainable, priority-guided\ndecision-making based on raw sensory inputs. XPG-RL integrates a task-driven\naction prioritization mechanism with a learned context-aware switching strategy\nthat dynamically selects from a discrete set of action primitives such as\ntarget grasping, occlusion removal, and viewpoint adjustment. Within this\nstrategy, a policy is optimized to output adaptive threshold values that govern\nthe discrete selection among action primitives. The perception module fuses\nRGB-D inputs with semantic and geometric features to produce a structured scene\nrepresentation for downstream decision-making. Extensive experiments in both\nsimulation and real-world settings demonstrate that XPG-RL consistently\noutperforms baseline methods in task success rates and motion efficiency,\nachieving up to 4.5$\\times$ higher efficiency in long-horizon tasks. These\nresults underscore the benefits of integrating domain knowledge with learnable\ndecision-making policies for robust and efficient robotic manipulation.", "published": "2025-04-29 17:37:45", "link": "http://arxiv.org/abs/2504.20969v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Softpick: No Attention Sink, No Massive Activations with Rectified Softmax", "abstract": "We introduce softpick, a rectified, not sum-to-one, drop-in replacement for\nsoftmax in transformer attention mechanisms that eliminates attention sink and\nmassive activations. Our experiments with 340M parameter models demonstrate\nthat softpick maintains performance parity with softmax on standard benchmarks\nwhile achieving 0% sink rate. The softpick transformer produces hidden states\nwith significantly lower kurtosis (340 vs 33,510) and creates sparse attention\nmaps (46.97% sparsity). Models using softpick consistently outperform softmax\nwhen quantized, with particularly pronounced advantages at lower bit\nprecisions. Our analysis and discussion shows how softpick has the potential to\nopen new possibilities for quantization, low-precision training, sparsity\noptimization, pruning, and interpretability. Our code is available at\nhttps://github.com/zaydzuhri/softpick-attention.", "published": "2025-04-29 17:36:18", "link": "http://arxiv.org/abs/2504.20966v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM Security", "abstract": "We introduce AegisLLM, a cooperative multi-agent defense against adversarial\nattacks and information leakage. In AegisLLM, a structured workflow of\nautonomous agents - orchestrator, deflector, responder, and evaluator -\ncollaborate to ensure safe and compliant LLM outputs, while self-improving over\ntime through prompt optimization. We show that scaling agentic reasoning system\nat test-time - both by incorporating additional agent roles and by leveraging\nautomated prompt optimization (such as DSPy)- substantially enhances robustness\nwithout compromising model utility. This test-time defense enables real-time\nadaptability to evolving attacks, without requiring model retraining.\nComprehensive evaluations across key threat scenarios, including unlearning and\njailbreaking, demonstrate the effectiveness of AegisLLM. On the WMDP unlearning\nbenchmark, AegisLLM achieves near-perfect unlearning with only 20 training\nexamples and fewer than 300 LM calls. For jailbreaking benchmarks, we achieve\n51% improvement compared to the base model on StrongReject, with false refusal\nrates of only 7.9% on PHTest compared to 18-55% for comparable methods. Our\nresults highlight the advantages of adaptive, agentic reasoning over static\ndefenses, establishing AegisLLM as a strong runtime alternative to traditional\napproaches based on model modifications. Code is available at\nhttps://github.com/zikuicai/aegisllm", "published": "2025-04-29 17:36:05", "link": "http://arxiv.org/abs/2504.20965v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Deep Learning Characterizes Depression and Suicidal Ideation from Eye Movements", "abstract": "Identifying physiological and behavioral markers for mental health conditions\nis a longstanding challenge in psychiatry. Depression and suicidal ideation, in\nparticular, lack objective biomarkers, with screening and diagnosis primarily\nrelying on self-reports and clinical interviews. Here, we investigate eye\ntracking as a potential marker modality for screening purposes. Eye movements\nare directly modulated by neuronal networks and have been associated with\nattentional and mood-related patterns; however, their predictive value for\ndepression and suicidality remains unclear. We recorded eye-tracking sequences\nfrom 126 young adults as they read and responded to affective sentences, and\nsubsequently developed a deep learning framework to predict their clinical\nstatus. The proposed model included separate branches for trials of positive\nand negative sentiment, and used 2D time-series representations to account for\nboth intra-trial and inter-trial variations. We were able to identify\ndepression and suicidal ideation with an area under the receiver operating\ncurve (AUC) of 0.793 (95% CI: 0.765-0.819) against healthy controls, and\nsuicidality specifically with 0.826 AUC (95% CI: 0.797-0.852). The model also\nexhibited moderate, yet significant, accuracy in differentiating depressed from\nsuicidal participants, with 0.609 AUC (95% CI 0.571-0.646). Discriminative\npatterns emerge more strongly when assessing the data relative to response\ngeneration than relative to the onset time of the final word of the sentences.\nThe most pronounced effects were observed for negative-sentiment sentences,\nthat are congruent to depressed and suicidal participants. Our findings\nhighlight eye tracking as an objective tool for mental health assessment and\nunderscore the modulatory impact of emotional stimuli on cognitive processes\naffecting oculomotor control.", "published": "2025-04-29 17:11:13", "link": "http://arxiv.org/abs/2504.20944v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Scenario-based Compositional Verification of Autonomous Systems with Neural Perception", "abstract": "Recent advances in deep learning have enabled the development of autonomous\nsystems that use deep neural networks for perception. Formal verification of\nthese systems is challenging due to the size and complexity of the perception\nDNNs as well as hard-to-quantify, changing environment conditions. To address\nthese challenges, we propose a probabilistic verification framework for\nautonomous systems based on the following key concepts: (1) Scenario-based\nModeling: We decompose the task (e.g., car navigation) into a composition of\nscenarios, each representing a different environment condition. (2)\nProbabilistic Abstractions: For each scenario, we build a compact abstraction\nof perception based on the DNN's performance on an offline dataset that\nrepresents the scenario's environment condition. (3) Symbolic Reasoning and\nAcceleration: The abstractions enable efficient compositional verification of\nthe autonomous system via symbolic reasoning and a novel acceleration proof\nrule that bounds the error probability of the system under arbitrary variations\nof environment conditions. We illustrate our approach on two case studies: an\nexperimental autonomous system that guides airplanes on taxiways using\nhigh-dimensional perception DNNs and a simulation model of an F1Tenth\nautonomous car using LiDAR observations.", "published": "2025-04-29 17:06:22", "link": "http://arxiv.org/abs/2504.20942v1", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Energy-Based Coarse-Graining in Molecular Dynamics: A Flow-Based Framework Without Data", "abstract": "Coarse-grained (CG) models offer an effective route to reducing the\ncomplexity of molecular simulations, yet conventional approaches depend heavily\non long all-atom molecular dynamics (MD) trajectories to adequately sample\nconfigurational space. This data-driven dependence limits their accuracy and\ngeneralizability, as unvisited configurations remain excluded from the\nresulting CG model. We introduce a data-free generative framework for\ncoarse-graining that directly targets the all-atom Boltzmann distribution. Our\nmodel defines a structured latent space comprising slow collective variables,\nwhich are statistically associated with multimodal marginal densities capturing\nmetastable states, and fast variables, which represent the remaining degrees of\nfreedom with simple, unimodal conditional distributions. A potentially\nlearnable, bijective map from the full latent space to the all-atom\nconfiguration space enables automatic and accurate reconstruction of molecular\nstructures. The model is trained using an energy-based objective that minimizes\nthe reverse Kullback-Leibler divergence, relying solely on the interatomic\npotential rather than sampled trajectories. A tempering scheme is used to\nstabilize training and promote exploration of diverse configurations. Once\ntrained, the model can generate unbiased, one-shot equilibrium all-atom\nsamples. We validate the method on two synthetic systems-a double-well\npotential and a Gaussian mixture-as well as on the benchmark alanine dipeptide.\nThe model captures all relevant modes of the Boltzmann distribution, accurately\nreconstructs atomic configurations, and learns physically meaningful\ncoarse-grained representations, all without any simulation data.", "published": "2025-04-29 17:05:27", "link": "http://arxiv.org/abs/2504.20940v1", "categories": ["physics.chem-ph", "cs.LG", "physics.comp-ph"], "primary_category": "physics.chem-ph"}
{"title": "Improvements of Dark Experience Replay and Reservoir Sampling towards Better Balance between Consolidation and Plasticity", "abstract": "Continual learning is the one of the most essential abilities for autonomous\nagents, which can incrementally learn daily-life skills. For this ultimate\ngoal, a simple but powerful method, dark experience replay (DER), has been\nproposed recently. DER mitigates catastrophic forgetting, in which the skills\nacquired in the past are unintentionally forgotten, by stochastically storing\nthe streaming data in a reservoir sampling (RS) buffer and by relearning them\nor retaining the past outputs for them. However, since DER considers multiple\nobjectives, it will not function properly without appropriate weighting of\nthem. In addition, the ability to retain past outputs inhibits learning if the\npast outputs are incorrect due to distribution shift or other effects. This is\ndue to a tradeoff between memory consolidation and plasticity. The tradeoff is\nhidden even in the RS buffer, which gradually stops storing new data for new\nskills in it as data is continuously passed to it. To alleviate the tradeoff\nand achieve better balance, this paper proposes improvement strategies to each\nof DER and RS. Specifically, DER is improved with automatic adaptation of\nweights, block of replaying erroneous data, and correction of past outputs. RS\nis also improved with generalization of acceptance probability, stratification\nof plural buffers, and intentional omission of unnecessary data. These\nimprovements are verified through multiple benchmarks including regression,\nclassification, and reinforcement learning problems. As a result, the proposed\nmethods achieve steady improvements in learning performance by balancing the\nmemory consolidation and plasticity.", "published": "2025-04-29 16:50:05", "link": "http://arxiv.org/abs/2504.20932v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Exploiting inter-agent coupling information for efficient reinforcement learning of cooperative LQR", "abstract": "Developing scalable and efficient reinforcement learning algorithms for\ncooperative multi-agent control has received significant attention over the\npast years. Existing literature has proposed inexact decompositions of local\nQ-functions based on empirical information structures between the agents. In\nthis paper, we exploit inter-agent coupling information and propose a\nsystematic approach to exactly decompose the local Q-function of each agent. We\ndevelop an approximate least square policy iteration algorithm based on the\nproposed decomposition and identify two architectures to learn the local\nQ-function for each agent. We establish that the worst-case sample complexity\nof the decomposition is equal to the centralized case and derive necessary and\nsufficient graphical conditions on the inter-agent couplings to achieve better\nsample efficiency. We demonstrate the improved sample efficiency and\ncomputational efficiency on numerical examples.", "published": "2025-04-29 16:42:13", "link": "http://arxiv.org/abs/2504.20927v1", "categories": ["eess.SY", "cs.LG", "cs.MA", "cs.SY", "math.OC"], "primary_category": "eess.SY"}
{"title": "Statistical and Predictive Analysis to Identify Risk Factors and Effects of Post COVID-19 Syndrome", "abstract": "Based on recent studies, some COVID-19 symptoms can persist for months after\ninfection, leading to what is termed long COVID. Factors such as vaccination\ntiming, patient characteristics, and symptoms during the acute phase of\ninfection may contribute to the prolonged effects and intensity of long COVID.\nEach patient, based on their unique combination of factors, develops a specific\nrisk or intensity of long COVID. In this work, we aim to achieve two\nobjectives: (1) conduct a statistical analysis to identify relationships\nbetween various factors and long COVID, and (2) perform predictive analysis of\nlong COVID intensity using these factors. We benchmark and interpret various\ndata-driven approaches, including linear models, random forests, gradient\nboosting, and neural networks, using data from the Lifelines COVID-19 cohort.\nOur results show that Neural Networks (NN) achieve the best performance in\nterms of MAPE, with predictions averaging 19\\% error. Additionally,\ninterpretability analysis reveals key factors such as loss of smell, headache,\nmuscle pain, and vaccination timing as significant predictors, while chronic\ndisease and gender are critical risk factors. These insights provide valuable\nguidance for understanding long COVID and developing targeted interventions.", "published": "2025-04-29 16:34:06", "link": "http://arxiv.org/abs/2504.20915v1", "categories": ["cs.LG", "68T01", "I.2.1; G.3"], "primary_category": "cs.LG"}
{"title": "MOSIC: Model-Agnostic Optimal Subgroup Identification with Multi-Constraint for Improved Reliability", "abstract": "Identifying subgroups that benefit from specific treatments using\nobservational data is a critical challenge in personalized medicine. Most\nexisting approaches solely focus on identifying a subgroup with an improved\ntreatment effect. However, practical considerations, such as ensuring a minimum\nsubgroup size for representativeness or achieving sufficient confounder balance\nfor reliability, are also important for making findings clinically meaningful\nand actionable. While some studies address these constraints individually, none\noffer a unified approach to handle them simultaneously. To bridge this gap, we\npropose a model-agnostic framework for optimal subgroup identification under\nmultiple constraints. We reformulate this combinatorial problem as an\nunconstrained min-max optimization problem with novel modifications and solve\nit by a gradient descent ascent algorithm. We further prove its convergence to\na feasible and locally optimal solution. Our method is stable and highly\nflexible, supporting various models and techniques for estimating and\noptimizing treatment effectiveness with observational data. Extensive\nexperiments on both synthetic and real-world datasets demonstrate its\neffectiveness in identifying subgroups that satisfy multiple constraints,\nachieving higher treatment effects and better confounder balancing results\nacross different group sizes.", "published": "2025-04-29 16:25:23", "link": "http://arxiv.org/abs/2504.20908v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "GiBy: A Giant-Step Baby-Step Classifier For Anomaly Detection In Industrial Control Systems", "abstract": "The continuous monitoring of the interactions between cyber-physical\ncomponents of any industrial control system (ICS) is required to secure\nautomation of the system controls, and to guarantee plant processes are\nfail-safe and remain in an acceptably safe state. Safety is achieved by\nmanaging actuation (where electric signals are used to trigger physical\nmovement), dependent on corresponding sensor readings; used as ground truth in\ndecision making. Timely detection of anomalies (attacks, faults and\nunascertained states) in ICSs is crucial for the safe running of a plant, the\nsafety of its personnel, and for the safe provision of any services provided.\nWe propose an anomaly detection method that involves accurate linearization of\nthe non-linear forms arising from sensor-actuator(s) relationships, primarily\nbecause solving linear models is easier and well understood. Further, the time\ncomplexity of the anomaly detection scenario/problem at hand is lowered using\ndimensionality reduction of the actuator(s) in relationship with a sensor. We\naccomplish this by using a well-known water treatment testbed as a use case.\nOur experiments show millisecond time response to detect anomalies and provide\nexplainability; that are not simultaneously achieved by other state of the art\nAI/ML models with eXplainable AI (XAI) used for the same purpose. Further, we\npin-point the sensor(s) and its actuation state for which anomaly was detected.", "published": "2025-04-29 16:24:11", "link": "http://arxiv.org/abs/2504.20906v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Dual Explanations via Subgraph Matching for Malware Detection", "abstract": "Interpretable malware detection is crucial for understanding harmful\nbehaviors and building trust in automated security systems. Traditional\nexplainable methods for Graph Neural Networks (GNNs) often highlight important\nregions within a graph but fail to associate them with known benign or\nmalicious behavioral patterns. This limitation reduces their utility in\nsecurity contexts, where alignment with verified prototypes is essential. In\nthis work, we introduce a novel dual prototype-driven explainable framework\nthat interprets GNN-based malware detection decisions. This dual explainable\nframework integrates a base explainer (a state-of-the-art explainer) with a\nnovel second-level explainer which is designed by subgraph matching technique,\ncalled SubMatch explainer. The proposed explainer assigns interpretable scores\nto nodes based on their association with matched subgraphs, offering a\nfine-grained distinction between benign and malicious regions. This\nprototype-guided scoring mechanism enables more interpretable, behavior-aligned\nexplanations. Experimental results demonstrate that our method preserves high\ndetection performance while significantly improving interpretability in malware\nanalysis.", "published": "2025-04-29 16:20:28", "link": "http://arxiv.org/abs/2504.20904v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Evaluating Generative Models for Tabular Data: Novel Metrics and Benchmarking", "abstract": "Generative models have revolutionized multiple domains, yet their application\nto tabular data remains underexplored. Evaluating generative models for tabular\ndata presents unique challenges due to structural complexity, large-scale\nvariability, and mixed data types, making it difficult to intuitively capture\nintricate patterns. Existing evaluation metrics offer only partial insights,\nlacking a comprehensive measure of generative performance. To address this\nlimitation, we propose three novel evaluation metrics: FAED, FPCAD, and RFIS.\nOur extensive experimental analysis, conducted on three standard network\nintrusion detection datasets, compares these metrics with established\nevaluation methods such as Fidelity, Utility, TSTR, and TRTS. Our results\ndemonstrate that FAED effectively captures generative modeling issues\noverlooked by existing metrics. While FPCAD exhibits promising performance,\nfurther refinements are necessary to enhance its reliability. Our proposed\nframework provides a robust and practical approach for assessing generative\nmodels in tabular data applications.", "published": "2025-04-29 16:16:51", "link": "http://arxiv.org/abs/2504.20900v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Does Feedback Help in Bandits with Arm Erasures?", "abstract": "We study a distributed multi-armed bandit (MAB) problem over arm erasure\nchannels, motivated by the increasing adoption of MAB algorithms over\ncommunication-constrained networks. In this setup, the learner communicates the\nchosen arm to play to an agent over an erasure channel with probability\n$\\epsilon \\in [0,1)$; if an erasure occurs, the agent continues pulling the\nlast successfully received arm; the learner always observes the reward of the\narm pulled. In past work, we considered the case where the agent cannot convey\nfeedback to the learner, and thus the learner does not know whether the arm\nplayed is the requested or the last successfully received one. In this paper,\nwe instead consider the case where the agent can send feedback to the learner\non whether the arm request was received, and thus the learner exactly knows\nwhich arm was played. Surprisingly, we prove that erasure feedback does not\nimprove the worst-case regret upper bound order over the previously studied\nno-feedback setting. In particular, we prove a regret lower bound of\n$\\Omega(\\sqrt{KT} + K / (1 - \\epsilon))$, where $K$ is the number of arms and\n$T$ the time horizon, that matches no-feedback upper bounds up to logarithmic\nfactors. We note however that the availability of feedback enables simpler\nalgorithm designs that may achieve better constants (albeit not better order)\nregret bounds; we design one such algorithm and evaluate its performance\nnumerically.", "published": "2025-04-29 16:10:05", "link": "http://arxiv.org/abs/2504.20894v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Guessing Efficiently for Constrained Subspace Approximation", "abstract": "In this paper we study constrained subspace approximation problem. Given a\nset of $n$ points $\\{a_1,\\ldots,a_n\\}$ in $\\mathbb{R}^d$, the goal of the {\\em\nsubspace approximation} problem is to find a $k$ dimensional subspace that best\napproximates the input points. More precisely, for a given $p\\geq 1$, we aim to\nminimize the $p$th power of the $\\ell_p$ norm of the error vector\n$(\\|a_1-\\bm{P}a_1\\|,\\ldots,\\|a_n-\\bm{P}a_n\\|)$, where $\\bm{P}$ denotes the\nprojection matrix onto the subspace and the norms are Euclidean. In\n\\emph{constrained} subspace approximation (CSA), we additionally have\nconstraints on the projection matrix $\\bm{P}$. In its most general form, we\nrequire $\\bm{P}$ to belong to a given subset $\\mathcal{S}$ that is described\nexplicitly or implicitly.\n  We introduce a general framework for constrained subspace approximation. Our\napproach, that we term coreset-guess-solve, yields either\n$(1+\\varepsilon)$-multiplicative or $\\varepsilon$-additive approximations for a\nvariety of constraints. We show that it provides new algorithms for\npartition-constrained subspace approximation with applications to {\\it fair}\nsubspace approximation, $k$-means clustering, and projected non-negative matrix\nfactorization, among others. Specifically, while we reconstruct the best known\nbounds for $k$-means clustering in Euclidean spaces, we improve the known\nresults for the remainder of the problems.", "published": "2025-04-29 15:56:48", "link": "http://arxiv.org/abs/2504.20883v1", "categories": ["cs.DS", "cs.LG"], "primary_category": "cs.DS"}
{"title": "Preference-centric Bandits: Optimality of Mixtures and Regret-efficient Algorithms", "abstract": "The objective of canonical multi-armed bandits is to identify and repeatedly\nselect an arm with the largest reward, often in the form of the expected value\nof the arm's probability distribution. Such a utilitarian perspective and focus\non the probability models' first moments, however, is agnostic to the\ndistributions' tail behavior and their implications for variability and risks\nin decision-making. This paper introduces a principled framework for shifting\nfrom expectation-based evaluation to an alternative reward formulation, termed\na preference metric (PM). The PMs can place the desired emphasis on different\nreward realization and can encode a richer modeling of preferences that\nincorporate risk aversion, robustness, or other desired attitudes toward\nuncertainty. A fundamentally distinct observation in such a PM-centric\nperspective is that designing bandit algorithms will have a significantly\ndifferent principle: as opposed to the reward-based models in which the optimal\nsampling policy converges to repeatedly sampling from the single best arm, in\nthe PM-centric framework the optimal policy converges to selecting a mix of\narms based on specific mixing weights. Designing such mixture policies departs\nfrom the principles for designing bandit algorithms in significant ways,\nprimarily because of uncountable mixture possibilities. The paper formalizes\nthe PM-centric framework and presents two algorithm classes (horizon-dependent\nand anytime) that learn and track mixtures in a regret-efficient fashion. These\nalgorithms have two distinctions from their canonical counterparts: (i) they\ninvolve an estimation routine to form reliable estimates of optimal mixtures,\nand (ii) they are equipped with tracking mechanisms to navigate arm selection\nfractions to track the optimal mixtures. These algorithms' regret guarantees\nare investigated under various algebraic forms of the PMs.", "published": "2025-04-29 15:46:59", "link": "http://arxiv.org/abs/2504.20877v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Hybrid Quantum Recurrent Neural Network For Remaining Useful Life Prediction", "abstract": "Predictive maintenance in aerospace heavily relies on accurate estimation of\nthe remaining useful life of jet engines. In this paper, we introduce a Hybrid\nQuantum Recurrent Neural Network framework, combining Quantum Long Short-Term\nMemory layers with classical dense layers for Remaining Useful Life forecasting\non NASA's Commercial Modular Aero-Propulsion System Simulation dataset. Each\nQuantum Long Short-Term Memory gate replaces conventional linear\ntransformations with Quantum Depth-Infused circuits, allowing the network to\nlearn high-frequency components more effectively. Experimental results\ndemonstrate that, despite having fewer trainable parameters, the Hybrid Quantum\nRecurrent Neural Network achieves up to a 5% improvement over a Recurrent\nNeural Network based on stacked Long Short-Term Memory layers in terms of mean\nroot mean squared error and mean absolute error. Moreover, a thorough\ncomparison of our method with established techniques, including Random Forest,\nConvolutional Neural Network, and Multilayer Perceptron, demonstrates that our\napproach, which achieves a Root Mean Squared Error of 15.46, surpasses these\nbaselines by approximately 13.68%, 16.21%, and 7.87%, respectively.\nNevertheless, it remains outperformed by certain advanced joint architectures.\nOur findings highlight the potential of hybrid quantum-classical approaches for\nrobust time-series forecasting under limited data conditions, offering new\navenues for enhancing reliability in predictive maintenance tasks.", "published": "2025-04-29 14:41:41", "link": "http://arxiv.org/abs/2504.20823v1", "categories": ["cs.LG", "quant-ph"], "primary_category": "cs.LG"}
{"title": "An approach to melodic segmentation and classification based on filtering with the Haar-wavelet", "abstract": "We present a novel method of classification and segmentation of melodies in\nsymbolic representation. The method is based on filtering pitch as a signal\nover time with the Haar-wavelet, and we evaluate it on two tasks. The filtered\nsignal corresponds to a single-scale signal ws from the continuous Haar wavelet\ntransform. The melodies are first segmented using local maxima or\nzero-crossings of w_s. The segments of w_s are then classified using the\nk-nearest neighbour algorithm with Euclidian and city-block distances. The\nmethod proves more effective than using unfiltered pitch signals and\nGestalt-based segmentation when used to recognize the parent works of segments\nfrom Bach's Two-Part Inventions (BWV 772-786). When used to classify 360 Dutch\nfolk tunes into 26 tune families, the performance of the method is comparable\nto the use of pitch signals, but not as good as that of string-matching methods\nbased on multiple features.", "published": "2025-04-29 14:41:03", "link": "http://arxiv.org/abs/2504.20822v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "The When and How of Target Variable Transformations", "abstract": "The machine learning pipeline typically involves the iterative process of (1)\ncollecting the data, (2) preparing the data, (3) learning a model, and (4)\nevaluating a model. Practitioners recognize the importance of the data\npreparation phase in terms of its impact on the ability to learn accurate\nmodels. In this regard, significant attention is often paid to manipulating the\nfeature set (e.g., selection, transformations, dimensionality reduction). A\npoint that is less well appreciated is that transformations on the target\nvariable can also have a large impact on whether it is possible to learn a\nsuitable model. These transformations may include accounting for\nsubject-specific biases (e.g., in how someone uses a rating scale), contexts\n(e.g., population size effects), and general trends (e.g., inflation). However,\nthis point has received a much more cursory treatment in the existing\nliterature. The goal of this paper is three-fold. First, we aim to highlight\nthe importance of this problem by showing when transforming the target variable\nhas been useful in practice. Second, we will provide a set of generic ``rules\nof thumb'' that indicate situations when transforming the target variable may\nbe needed. Third, we will discuss which transformations should be considered in\na given situation.", "published": "2025-04-29 14:40:21", "link": "http://arxiv.org/abs/2504.20821v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Q-Fusion: Diffusing Quantum Circuits", "abstract": "Quantum computing holds great potential for solving socially relevant and\ncomputationally complex problems. Furthermore, quantum machine learning (QML)\npromises to rapidly improve our current machine learning capabilities. However,\ncurrent noisy intermediate-scale quantum (NISQ) devices are constrained by\nlimitations in the number of qubits and gate counts, which hinder their full\ncapabilities. Furthermore, the design of quantum algorithms remains a laborious\ntask, requiring significant domain expertise and time. Quantum Architecture\nSearch (QAS) aims to streamline this process by automatically generating novel\nquantum circuits, reducing the need for manual intervention. In this paper, we\npropose a diffusion-based algorithm leveraging the LayerDAG framework to\ngenerate new quantum circuits. This method contrasts with other approaches that\nutilize large language models (LLMs), reinforcement learning (RL), variational\nautoencoders (VAE), and similar techniques. Our results demonstrate that the\nproposed model consistently generates 100% valid quantum circuit outputs.", "published": "2025-04-29 14:10:10", "link": "http://arxiv.org/abs/2504.20794v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Evaluating Effects of Augmented SELFIES for Molecular Understanding Using QK-LSTM", "abstract": "Identifying molecular properties, including side effects, is a critical yet\ntime-consuming step in drug development. Failing to detect these side effects\nbefore regulatory submission can result in significant financial losses and\nproduction delays, and overlooking them during the regulatory review can lead\nto catastrophic consequences. This challenge presents an opportunity for\ninnovative machine learning approaches, particularly hybrid quantum-classical\nmodels like the Quantum Kernel-Based Long Short-Term Memory (QK-LSTM) network.\nThe QK-LSTM integrates quantum kernel functions into the classical LSTM\nframework, enabling the capture of complex, non-linear patterns in sequential\ndata. By mapping input data into a high-dimensional quantum feature space, the\nQK-LSTM model reduces the need for large parameter sets, allowing for model\ncompression without sacrificing accuracy in sequence-based tasks. Recent\nadvancements have been made in the classical domain using augmented variations\nof the Simplified Molecular Line-Entry System (SMILES). However, to the best of\nour knowledge, no research has explored the impact of augmented SMILES in the\nquantum domain, nor the role of augmented Self-Referencing Embedded Strings\n(SELFIES) in either classical or hybrid quantum-classical settings. This study\npresents the first analysis of these approaches, providing novel insights into\ntheir potential for enhancing molecular property prediction and side effect\nidentification. Results reveal that augmenting SELFIES yields in statistically\nsignificant improvements from SMILES by a 5.97% improvement for the classical\ndomain and a 5.91% improvement for the hybrid quantum-classical domain.", "published": "2025-04-29 14:03:31", "link": "http://arxiv.org/abs/2504.20789v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DDPS: Discrete Diffusion Posterior Sampling for Paths in Layered Graphs", "abstract": "Diffusion models form an important class of generative models today,\naccounting for much of the state of the art in cutting edge AI research. While\nnumerous extensions beyond image and video generation exist, few of such\napproaches address the issue of explicit constraints in the samples generated.\nIn this paper, we study the problem of generating paths in a layered graph (a\nvariant of a directed acyclic graph) using discrete diffusion models, while\nguaranteeing that our generated samples are indeed paths. Our approach utilizes\na simple yet effective representation for paths which we call the padded\nadjacency-list matrix (PALM). In addition, we show how to effectively perform\nclassifier guidance, which helps steer the sampled paths to specific preferred\nedges without any retraining of the diffusion model. Our preliminary results\nshow that empirically, our method outperforms alternatives which do not\nexplicitly account for path constraints.", "published": "2025-04-29 13:34:17", "link": "http://arxiv.org/abs/2504.20754v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Intelligent Task Offloading in VANETs: A Hybrid AI-Driven Approach for Low-Latency and Energy Efficiency", "abstract": "Vehicular Ad-hoc Networks (VANETs) are integral to intelligent transportation\nsystems, enabling vehicles to offload computational tasks to nearby roadside\nunits (RSUs) and mobile edge computing (MEC) servers for real-time processing.\nHowever, the highly dynamic nature of VANETs introduces challenges, such as\nunpredictable network conditions, high latency, energy inefficiency, and task\nfailure. This research addresses these issues by proposing a hybrid AI\nframework that integrates supervised learning, reinforcement learning, and\nParticle Swarm Optimization (PSO) for intelligent task offloading and resource\nallocation. The framework leverages supervised models for predicting optimal\noffloading strategies, reinforcement learning for adaptive decision-making, and\nPSO for optimizing latency and energy consumption. Extensive simulations\ndemonstrate that the proposed framework achieves significant reductions in\nlatency and energy usage while improving task success rates and network\nthroughput. By offering an efficient, and scalable solution, this framework\nsets the foundation for enhancing real-time applications in dynamic vehicular\nenvironments.", "published": "2025-04-29 13:20:02", "link": "http://arxiv.org/abs/2504.20735v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "What's Wrong with Your Synthetic Tabular Data? Using Explainable AI to Evaluate Generative Models", "abstract": "Evaluating synthetic tabular data is challenging, since they can differ from\nthe real data in so many ways. There exist numerous metrics of synthetic data\nquality, ranging from statistical distances to predictive performance, often\nproviding conflicting results. Moreover, they fail to explain or pinpoint the\nspecific weaknesses in the synthetic data. To address this, we apply\nexplainable AI (XAI) techniques to a binary detection classifier trained to\ndistinguish real from synthetic data. While the classifier identifies\ndistributional differences, XAI concepts such as feature importance and feature\neffects, analyzed through methods like permutation feature importance, partial\ndependence plots, Shapley values and counterfactual explanations, reveal why\nsynthetic data are distinguishable, highlighting inconsistencies, unrealistic\ndependencies, or missing patterns. This interpretability increases transparency\nin synthetic data evaluation and provides deeper insights beyond conventional\nmetrics, helping diagnose and improve synthetic data quality. We apply our\napproach to two tabular datasets and generative models, showing that it\nuncovers issues overlooked by standard evaluation techniques.", "published": "2025-04-29 12:10:52", "link": "http://arxiv.org/abs/2504.20687v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Explanations Go Linear: Interpretable and Individual Latent Encoding for Post-hoc Explainability", "abstract": "Post-hoc explainability is essential for understanding black-box machine\nlearning models. Surrogate-based techniques are widely used for local and\nglobal model-agnostic explanations but have significant limitations. Local\nsurrogates capture non-linearities but are computationally expensive and\nsensitive to parameters, while global surrogates are more efficient but\nstruggle with complex local behaviors. In this paper, we present ILLUME, a\nflexible and interpretable framework grounded in representation learning, that\ncan be integrated with various surrogate models to provide explanations for any\nblack-box classifier. Specifically, our approach combines a globally trained\nsurrogate with instance-specific linear transformations learned with a\nmeta-encoder to generate both local and global explanations. Through extensive\nempirical evaluations, we demonstrate the effectiveness of ILLUME in producing\nfeature attributions and decision rules that are not only accurate but also\nrobust and faithful to the black-box, thus providing a unified explanation\nframework that effectively addresses the limitations of traditional surrogate\nmethods.", "published": "2025-04-29 11:46:48", "link": "http://arxiv.org/abs/2504.20667v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SFi-Former: Sparse Flow Induced Attention for Graph Transformer", "abstract": "Graph Transformers (GTs) have demonstrated superior performance compared to\ntraditional message-passing graph neural networks in many studies, especially\nin processing graph data with long-range dependencies. However, GTs tend to\nsuffer from weak inductive bias, overfitting and over-globalizing problems due\nto the dense attention. In this paper, we introduce SFi-attention, a novel\nattention mechanism designed to learn sparse pattern by minimizing an energy\nfunction based on network flows with l1-norm regularization, to relieve those\nissues caused by dense attention. Furthermore, SFi-Former is accordingly\ndevised which can leverage the sparse attention pattern of SFi-attention to\ngenerate sparse network flows beyond adjacency matrix of graph data.\nSpecifically, SFi-Former aggregates features selectively from other nodes\nthrough flexible adaptation of the sparse attention, leading to a more robust\nmodel. We validate our SFi-Former on various graph datasets, especially those\ngraph data exhibiting long-range dependencies. Experimental results show that\nour SFi-Former obtains competitive performance on GNN Benchmark datasets and\nSOTA performance on LongRange Graph Benchmark (LRGB) datasets. Additionally,\nour model gives rise to smaller generalization gaps, which indicates that it is\nless prone to over-fitting. Click here for codes.", "published": "2025-04-29 11:45:24", "link": "http://arxiv.org/abs/2504.20666v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning and Generalization with Mixture Data", "abstract": "In many, if not most, machine learning applications the training data is\nnaturally heterogeneous (e.g. federated learning, adversarial attacks and\ndomain adaptation in neural net training). Data heterogeneity is identified as\none of the major challenges in modern day large-scale learning. A classical way\nto represent heterogeneous data is via a mixture model. In this paper, we study\ngeneralization performance and statistical rates when data is sampled from a\nmixture distribution. We first characterize the heterogeneity of the mixture in\nterms of the pairwise total variation distance of the sub-population\ndistributions. Thereafter, as a central theme of this paper, we characterize\nthe range where the mixture may be treated as a single (homogeneous)\ndistribution for learning. In particular, we study the generalization\nperformance under the classical PAC framework and the statistical error rates\nfor parametric (linear regression, mixture of hyperplanes) as well as\nnon-parametric (Lipschitz, convex and H\\\"older-smooth) regression problems. In\norder to do this, we obtain Rademacher complexity and (local) Gaussian\ncomplexity bounds with mixture data, and apply them to get the generalization\nand convergence rates respectively. We observe that as the (regression)\nfunction classes get more complex, the requirement on the pairwise total\nvariation distance gets stringent, which matches our intuition. We also do a\nfiner analysis for the case of mixed linear regression and provide a tight\nbound on the generalization error in terms of heterogeneity.", "published": "2025-04-29 11:21:15", "link": "http://arxiv.org/abs/2504.20651v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "RuleKit 2: Faster and simpler rule learning", "abstract": "Rules offer an invaluable combination of predictive and descriptive\ncapabilities. Our package for rule-based data analysis, RuleKit, has proven its\neffectiveness in classification, regression, and survival problems. Here we\npresent its second version. New algorithms and optimized implementations of\nthose previously included, significantly improved the computational performance\nof our suite, reducing the analysis time of some data sets by two orders of\nmagnitude. The usability of RuleKit 2 is provided by two new components: Python\npackage and browser application with a graphical user interface. The former\ncomplies with scikit-learn, the most popular data mining library for Python,\nallowing RuleKit 2 to be straightforwardly integrated into existing data\nanalysis pipelines. RuleKit 2 is available at GitHub under GNU AGPL 3 license\n(https://github.com/adaa-polsl/RuleKit)", "published": "2025-04-29 11:21:11", "link": "http://arxiv.org/abs/2504.20650v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Combatting Dimensional Collapse in LLM Pre-Training Data via Diversified File Selection", "abstract": "Selecting high-quality pre-training data for large language models (LLMs) is\ncrucial for enhancing their overall performance under limited computation\nbudget, improving both training and sample efficiency. Recent advancements in\nfile selection primarily rely on using an existing or trained proxy model to\nassess the similarity of samples to a target domain, such as high quality\nsources BookCorpus and Wikipedia. However, upon revisiting these methods, the\ndomain-similarity selection criteria demonstrates a diversity dilemma,\ni.e.dimensional collapse in the feature space, improving performance on the\ndomain-related tasks but causing severe degradation on generic performance. To\nprevent collapse and enhance diversity, we propose a DiverSified File selection\nalgorithm (DiSF), which selects the most decorrelated text files in the feature\nspace. We approach this with a classical greedy algorithm to achieve more\nuniform eigenvalues in the feature covariance matrix of the selected texts,\nanalyzing its approximation to the optimal solution under a formulation of\n$\\gamma$-weakly submodular optimization problem. Empirically, we establish a\nbenchmark and conduct extensive experiments on the TinyLlama architecture with\nmodels from 120M to 1.1B parameters. Evaluating across nine tasks from the\nHarness framework, DiSF demonstrates a significant improvement on overall\nperformance. Specifically, DiSF saves 98.5% of 590M training files in\nSlimPajama, outperforming the full-data pre-training within a 50B training\nbudget, and achieving about 1.5x training efficiency and 5x data efficiency.", "published": "2025-04-29 11:13:18", "link": "http://arxiv.org/abs/2504.20644v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Decision-centric fairness: Evaluation and optimization for resource allocation problems", "abstract": "Data-driven decision support tools play an increasingly central role in\ndecision-making across various domains. In this work, we focus on binary\nclassification models for predicting positive-outcome scores and deciding on\nresource allocation, e.g., credit scores for granting loans or churn propensity\nscores for targeting customers with a retention campaign. Such models may\nexhibit discriminatory behavior toward specific demographic groups through\ntheir predicted scores, potentially leading to unfair resource allocation. We\nfocus on demographic parity as a fairness metric to compare the proportions of\ninstances that are selected based on their positive outcome scores across\ngroups. In this work, we propose a decision-centric fairness methodology that\ninduces fairness only within the decision-making region -- the range of\nrelevant decision thresholds on the score that may be used to decide on\nresource allocation -- as an alternative to a global fairness approach that\nseeks to enforce parity across the entire score distribution. By restricting\nthe induction of fairness to the decision-making region, the proposed\ndecision-centric approach avoids imposing overly restrictive constraints on the\nmodel, which may unnecessarily degrade the quality of the predicted scores. We\nempirically compare our approach to a global fairness approach on multiple\n(semi-synthetic) datasets to identify scenarios in which focusing on fairness\nwhere it truly matters, i.e., decision-centric fairness, proves beneficial.", "published": "2025-04-29 11:12:36", "link": "http://arxiv.org/abs/2504.20642v1", "categories": ["cs.LG", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Bridging the Generalisation Gap: Synthetic Data Generation for Multi-Site Clinical Model Validation", "abstract": "Ensuring the generalisability of clinical machine learning (ML) models across\ndiverse healthcare settings remains a significant challenge due to variability\nin patient demographics, disease prevalence, and institutional practices.\nExisting model evaluation approaches often rely on real-world datasets, which\nare limited in availability, embed confounding biases, and lack the flexibility\nneeded for systematic experimentation. Furthermore, while generative models aim\nfor statistical realism, they often lack transparency and explicit control over\nfactors driving distributional shifts. In this work, we propose a novel\nstructured synthetic data framework designed for the controlled benchmarking of\nmodel robustness, fairness, and generalisability. Unlike approaches focused\nsolely on mimicking observed data, our framework provides explicit control over\nthe data generating process, including site-specific prevalence variations,\nhierarchical subgroup effects, and structured feature interactions. This\nenables targeted investigation into how models respond to specific\ndistributional shifts and potential biases. Through controlled experiments, we\ndemonstrate the framework's ability to isolate the impact of site variations,\nsupport fairness-aware audits, and reveal generalisation failures, particularly\nhighlighting how model complexity interacts with site-specific effects. This\nwork contributes a reproducible, interpretable, and configurable tool designed\nto advance the reliable deployment of ML in clinical settings.", "published": "2025-04-29 11:04:28", "link": "http://arxiv.org/abs/2504.20635v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Data Driven Deep Learning for Correcting Global Climate Model Projections of SST and DSL in the Bay of Bengal", "abstract": "Climate change alters ocean conditions, notably temperature and sea level. In\nthe Bay of Bengal, these changes influence monsoon precipitation and marine\nproductivity, critical to the Indian economy. In Phase 6 of the Coupled Model\nIntercomparison Project (CMIP6), Global Climate Models (GCMs) use different\nshared socioeconomic pathways (SSPs) to obtain future climate projections.\nHowever, significant discrepancies are observed between these models and the\nreanalysis data in the Bay of Bengal for 2015-2024. Specifically, the root mean\nsquare error (RMSE) between the climate model output and the Ocean Reanalysis\nSystem (ORAS5) is 1.2C for the sea surface temperature (SST) and 1.1 m for the\ndynamic sea level (DSL). We introduce a new data-driven deep learning model to\ncorrect for this bias. The deep neural model for each variable is trained using\npairs of climatology-removed monthly climate projections as input and the\ncorresponding month's ORAS5 as output. This model is trained with historical\ndata (1950 to 2014), validated with future projection data from 2015 to 2020,\nand tested with future projections from 2021 to 2023. Compared to the\nconventional EquiDistant Cumulative Distribution Function (EDCDF) statistical\nmethod for bias correction in climate models, our approach decreases RMSE by\n0.15C for SST and 0.3 m for DSL. The trained model subsequently corrects the\nprojections for 2024-2100. A detailed analysis of the monthly, seasonal, and\ndecadal means and variability is performed to underscore the implications of\nthe novel dynamics uncovered in our corrected projections.", "published": "2025-04-29 10:40:37", "link": "http://arxiv.org/abs/2504.20620v1", "categories": ["physics.ao-ph", "cs.LG"], "primary_category": "physics.ao-ph"}
{"title": "Sobolev norm inconsistency of kernel interpolation", "abstract": "We study the consistency of minimum-norm interpolation in reproducing kernel\nHilbert spaces corresponding to bounded kernels. Our main result give lower\nbounds for the generalization error of the kernel interpolation measured in a\ncontinuous scale of norms that interpolate between $L^2$ and the hypothesis\nspace. These lower bounds imply that kernel interpolation is always\ninconsistent, when the smoothness index of the norm is larger than a constant\nthat depends only on the embedding index of the hypothesis space and the decay\nrate of the eigenvalues.", "published": "2025-04-29 10:35:12", "link": "http://arxiv.org/abs/2504.20617v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Independent Learning in Performative Markov Potential Games", "abstract": "Performative Reinforcement Learning (PRL) refers to a scenario in which the\ndeployed policy changes the reward and transition dynamics of the underlying\nenvironment. In this work, we study multi-agent PRL by incorporating\nperformative effects into Markov Potential Games (MPGs). We introduce the\nnotion of a performatively stable equilibrium (PSE) and show that it always\nexists under a reasonable sensitivity assumption. We then provide convergence\nresults for state-of-the-art algorithms used to solve MPGs. Specifically, we\nshow that independent policy gradient ascent (IPGA) and independent natural\npolicy gradient (INPG) converge to an approximate PSE in the best-iterate\nsense, with an additional term that accounts for the performative effects.\nFurthermore, we show that INPG asymptotically converges to a PSE in the\nlast-iterate sense. As the performative effects vanish, we recover the\nconvergence rates from prior work. For a special case of our game, we provide\nfinite-time last-iterate convergence results for a repeated retraining\napproach, in which agents independently optimize a surrogate objective. We\nconduct extensive experiments to validate our theoretical findings.", "published": "2025-04-29 09:46:16", "link": "http://arxiv.org/abs/2504.20593v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Representation Learning Preserving Ignorability and Covariate Matching for Treatment Effects", "abstract": "Estimating treatment effects from observational data is challenging due to\ntwo main reasons: (a) hidden confounding, and (b) covariate mismatch (control\nand treatment groups not having identical distributions). Long lines of works\nexist that address only either of these issues. To address the former,\nconventional techniques that require detailed knowledge in the form of causal\ngraphs have been proposed. For the latter, covariate matching and importance\nweighting methods have been used. Recently, there has been progress in\ncombining testable independencies with partial side information for tackling\nhidden confounding. A common framework to address both hidden confounding and\nselection bias is missing. We propose neural architectures that aim to learn a\nrepresentation of pre-treatment covariates that is a valid adjustment and also\nsatisfies covariate matching constraints. We combine two different neural\narchitectures: one based on gradient matching across domains created by\nsubsampling a suitable anchor variable that assumes causal side information,\nfollowed by the other, a covariate matching transformation. We prove that\napproximately invariant representations yield approximate valid adjustment sets\nwhich would enable an interval around the true causal effect. In contrast to\nusual sensitivity analysis, where an unknown nuisance parameter is varied, we\nhave a testable approximation yielding a bound on the effect estimate. We also\noutperform various baselines with respect to ATE and PEHE errors on causal\nbenchmarks that include IHDP, Jobs, Cattaneo, and an image-based Crowd\nManagement dataset.", "published": "2025-04-29 09:33:56", "link": "http://arxiv.org/abs/2504.20579v1", "categories": ["cs.LG", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Digital Shielding for Cross-Domain Wi-Fi Signal Adaptation using Relativistic Average Generative Adversarial Network", "abstract": "Wi-Fi sensing uses radio-frequency signals from Wi-Fi devices to analyze\nenvironments, enabling tasks such as tracking people, detecting intrusions, and\nrecognizing gestures. The rise of this technology is driven by the IEEE\n802.11bf standard and growing demand for tools that can ensure privacy and\noperate through obstacles. However, the performance of Wi-Fi sensing is heavily\ninfluenced by environmental conditions, especially when extracting spatial and\ntemporal features from the surrounding scene. A key challenge is achieving\nrobust generalization across domains, ensuring stable performance even when the\nsensing environment changes significantly. This paper introduces a novel deep\nlearning model for cross-domain adaptation of Wi-Fi signals, inspired by\nphysical signal shielding. The model uses a Relativistic average Generative\nAdversarial Network (RaGAN) with Bidirectional Long Short-Term Memory (Bi-LSTM)\narchitectures for both the generator and discriminator. To simulate physical\nshielding, an acrylic box lined with electromagnetic shielding fabric was\nconstructed, mimicking a Faraday cage. Wi-Fi signal spectra were collected from\nvarious materials both inside (domain-free) and outside (domain-dependent) the\nbox to train the model. A multi-class Support Vector Machine (SVM) was trained\non domain-free spectra and tested on signals denoised by the RaGAN. The system\nachieved 96% accuracy and demonstrated strong material discrimination\ncapabilities, offering potential for use in security applications to identify\nconcealed objects based on their composition.", "published": "2025-04-29 09:18:02", "link": "http://arxiv.org/abs/2504.20568v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DeeP-Mod: Deep Dynamic Programming based Environment Modelling using Feature Extraction", "abstract": "The DeeP-Mod framework builds an environment model using features from a Deep\nDynamic Programming Network (DDPN), trained via a Deep Q-Network (DQN). While\nDeep Q-Learning is effective in decision-making, state information is lost in\ndeeper DQN layers due to mixed state-action representations. We address this by\nusing Dynamic Programming (DP) to train a DDPN, where Value Iteration ensures\nthe output represents state values, not state-action pairs. Extracting features\nfrom the DDPN preserves state information, enabling task and action set\nindependence. We show that a reduced DDPN can be trained using features\nextracted from the original DDPN trained on an identical problem. This reduced\nDDPN achieves faster convergence under noise and outperforms the original DDPN.\nFinally, we introduce the DeeP-Mod framework, which creates an environment\nmodel using the evolution of features extracted from a DDPN in response to\nactions. A second DDPN, which learns directly from this feature model rather\nthan raw states, can learn an effective feature-value representation and thus\noptimal policy. A key advantage of DeeP-Mod is that an externally defined\nenvironment model is not needed at any stage, making DDPN applicable to a wide\nrange of environments.", "published": "2025-04-29 08:30:11", "link": "http://arxiv.org/abs/2504.20535v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Wavelet-Filtering of Symbolic Music Representations for Folk Tune Segmentation and Classification", "abstract": "The aim of this study is to evaluate a machine-learning method in which\nsymbolic representations of folk songs are segmented and classified into tune\nfamilies with Haar-wavelet filtering. The method is compared with previously\nproposed Gestalt-based method. Melodies are represented as discrete symbolic\npitch-time signals. We apply the continuous wavelet transform (CWT) with the\nHaar wavelet at specific scales, obtaining filtered versions of melodies\nemphasizing their information at particular time-scales. We use the filtered\nsignal for representation and segmentation, using the wavelet coefficients'\nlocal maxima to indicate local boundaries and classify segments by means of\nk-nearest neighbours based on standard vector-metrics (Euclidean, cityblock),\nand compare the results to a Gestalt-based segmentation method and metrics\napplied directly to the pitch signal. We found that the wavelet based\nsegmentation and wavelet-filtering of the pitch signal lead to better\nclassification accuracy in cross-validated evaluation when the time-scale and\nother parameters are optimized.", "published": "2025-04-29 08:02:37", "link": "http://arxiv.org/abs/2504.20522v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Quality-factor inspired deep neural network solver for solving inverse scattering problems", "abstract": "Deep neural networks have been applied to address electromagnetic inverse\nscattering problems (ISPs) and shown superior imaging performances, which can\nbe affected by the training dataset, the network architecture and the applied\nloss function. Here, the quality of data samples is cared and valued by the\ndefined quality factor. Based on the quality factor, the composition of the\ntraining dataset is optimized. The network architecture is integrated with the\nresidual connections and channel attention mechanism to improve feature\nextraction. A loss function that incorporates data-fitting error,\nphysical-information constraints and the desired feature of the solution is\ndesigned and analyzed to suppress the background artifacts and improve the\nreconstruction accuracy. Various numerical analysis are performed to\ndemonstrate the superiority of the proposed quality-factor inspired deep neural\nnetwork (QuaDNN) solver and the imaging performance is finally verified by\nexperimental imaging test.", "published": "2025-04-29 07:45:48", "link": "http://arxiv.org/abs/2504.20504v1", "categories": ["eess.IV", "cs.LG", "physics.comp-ph"], "primary_category": "eess.IV"}
{"title": "Full-field surrogate modeling of cardiac function encoding geometric variability", "abstract": "Combining physics-based modeling with data-driven methods is critical to\nenabling the translation of computational methods to clinical use in\ncardiology. The use of rigorous differential equations combined with machine\nlearning tools allows for model personalization with uncertainty quantification\nin time frames compatible with clinical practice. However, accurate and\nefficient surrogate models of cardiac function, built from physics-based\nnumerical simulation, are still mostly geometry-specific and require retraining\nfor different patients and pathological conditions. We propose a novel\ncomputational pipeline to embed cardiac anatomies into full-field surrogate\nmodels. We generate a dataset of electrophysiology simulations using a complex\nmulti-scale mathematical model coupling partial and ordinary differential\nequations. We adopt Branched Latent Neural Maps (BLNMs) as an effective\nscientific machine learning method to encode activation maps extracted from\nphysics-based numerical simulations into a neural network. Leveraging large\ndeformation diffeomorphic metric mappings, we build a biventricular anatomical\natlas and parametrize the anatomical variability of a small and challenging\ncohort of 13 pediatric patients affected by Tetralogy of Fallot. We propose a\nnovel statistical shape modeling based z-score sampling approach to generate a\nnew synthetic cohort of 52 biventricular geometries that are compatible with\nthe original geometrical variability. This synthetic cohort acts as the\ntraining set for BLNMs. Our surrogate model demonstrates robustness and great\ngeneralization across the complex original patient cohort, achieving an average\nadimensional mean squared error of 0.0034. The Python implementation of our\nBLNM model is publicly available under MIT License at\nhttps://github.com/StanfordCBCL/BLNM.", "published": "2025-04-29 07:22:06", "link": "http://arxiv.org/abs/2504.20479v1", "categories": ["eess.IV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "FT-MoE: Sustainable-learning Mixture of Experts Model for Fault-Tolerant Computing with Multiple Tasks", "abstract": "Intelligent fault-tolerant (FT) computing has recently demonstrated\nsignificant advantages of predicting and diagnosing faults in advance, enabling\nreliable service delivery. However, due to heterogeneity of fault knowledge and\ncomplex dependence relationships of time series log data, existing deep\nlearning-based FT algorithms further improve detection performance relying on\nsingle neural network model with difficulty. To this end, we propose FT-MoE, a\nsustainable-learning mixture-of-experts model for fault-tolerant computing with\nmultiple tasks, which enables different parameters learning distinct fault\nknowledge to achieve high-reliability for service system. Firstly, we use\ndecoder-based transformer models to obtain fault prototype vectors of\ndecoupling long-distance dependencies. Followed by, we present a dual mixture\nof experts networks for high-accurate prediction for both fault detection and\nclassification tasks. Then, we design a two-stage optimization scheme of\noffline training and online tuning, which allows that in operation FT-MoE can\nalso keep learning to adapt to dynamic service environments. Finally, to verify\nthe effectiveness of FT-MoE, we conduct extensive experiments on the FT\nbenchmark. Experimental results show that FT-MoE achieves superior performance\ncompared to the state-of-the-art methods. Code will be available upon\npublication.", "published": "2025-04-29 05:44:59", "link": "http://arxiv.org/abs/2504.20446v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multidimensional precipitation index prediction based on CNN-LSTM hybrid framework", "abstract": "With the intensification of global climate change, accurate prediction of\nweather indicators is of great significance in disaster prevention and\nmitigation, agricultural production, and transportation. Precipitation, as one\nof the key meteorological indicators, plays a crucial role in water resource\nmanagement, agricultural production, and urban flood control. This study\nproposes a multidimensional precipitation index prediction model based on a\nCNN- LSTM hybrid framework, aiming to improve the accuracy of precipitation\nforecasts. The dataset is sourced from Pune, Maharashtra, India, covering\nmonthly mean precipitation data from 1972 to 2002. This dataset includes nearly\n31 years (1972-2002) of monthly average precipitation, reflecting the long-term\nfluctuations and seasonal variations of precipitation in the region. By\nanalyzing these time series data, the CNN-LSTM model effectively captures local\nfeatures and long-term dependencies. Experimental results show that the model\nachieves a root mean square error (RMSE) of 6.752, which demonstrates a\nsignificant advantage over traditional time series prediction methods in terms\nof prediction accuracy and generalization ability. Furthermore, this study\nprovides new research ideas for precipitation prediction. However, the model\nrequires high computational resources when dealing with large-scale datasets,\nand its predictive ability for multidimensional precipitation data still needs\nimprovement. Future research could extend the model to support and predict\nmultidimensional precipitation data, thereby promoting the development of more\naccurate and efficient meteorological prediction technologies.", "published": "2025-04-29 05:32:43", "link": "http://arxiv.org/abs/2504.20442v1", "categories": ["cs.LG", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Learning Laplacian Positional Encodings for Heterophilous Graphs", "abstract": "In this work, we theoretically demonstrate that current graph positional\nencodings (PEs) are not beneficial and could potentially hurt performance in\ntasks involving heterophilous graphs, where nodes that are close tend to have\ndifferent labels. This limitation is critical as many real-world networks\nexhibit heterophily, and even highly homophilous graphs can contain local\nregions of strong heterophily. To address this limitation, we propose Learnable\nLaplacian Positional Encodings (LLPE), a new PE that leverages the full\nspectrum of the graph Laplacian, enabling them to capture graph structure on\nboth homophilous and heterophilous graphs. Theoretically, we prove LLPE's\nability to approximate a general class of graph distances and demonstrate its\ngeneralization properties. Empirically, our evaluation on 12 benchmarks\ndemonstrates that LLPE improves accuracy across a variety of GNNs, including\ngraph transformers, by up to 35% and 14% on synthetic and real-world graphs,\nrespectively. Going forward, our work represents a significant step towards\ndeveloping PEs that effectively capture complex structures in heterophilous\ngraphs.", "published": "2025-04-29 04:58:13", "link": "http://arxiv.org/abs/2504.20430v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Understanding GNNs and Homophily in Dynamic Node Classification", "abstract": "Homophily, as a measure, has been critical to increasing our understanding of\ngraph neural networks (GNNs). However, to date this measure has only been\nanalyzed in the context of static graphs. In our work, we explore homophily in\ndynamic settings. Focusing on graph convolutional networks (GCNs), we\ndemonstrate theoretically that in dynamic settings, current GCN discriminative\nperformance is characterized by the probability that a node's future label is\nthe same as its neighbors' current labels. Based on this insight, we propose\ndynamic homophily, a new measure of homophily that applies in the dynamic\nsetting. This new measure correlates with GNN discriminative performance and\nsheds light on how to potentially design more powerful GNNs for dynamic graphs.\nLeveraging a variety of dynamic node classification datasets, we demonstrate\nthat popular GNNs are not robust to low dynamic homophily. Going forward, our\nwork represents an important step towards understanding homophily and GNN\nperformance in dynamic node classification.", "published": "2025-04-29 04:32:29", "link": "http://arxiv.org/abs/2504.20421v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ADiff4TPP: Asynchronous Diffusion Models for Temporal Point Processes", "abstract": "This work introduces a novel approach to modeling temporal point processes\nusing diffusion models with an asynchronous noise schedule. At each step of the\ndiffusion process, the noise schedule injects noise of varying scales into\ndifferent parts of the data. With a careful design of the noise schedules,\nearlier events are generated faster than later ones, thus providing stronger\nconditioning for forecasting the more distant future. We derive an objective to\neffectively train these models for a general family of noise schedules based on\nconditional flow matching. Our method models the joint distribution of the\nlatent representations of events in a sequence and achieves state-of-the-art\nresults in predicting both the next inter-event time and event type on\nbenchmark datasets. Additionally, it flexibly accommodates varying lengths of\nobservation and prediction windows in different forecasting settings by\nadjusting the starting and ending points of the generation process. Finally,\nour method shows superior performance in long-horizon prediction tasks,\noutperforming existing baseline methods.", "published": "2025-04-29 04:17:39", "link": "http://arxiv.org/abs/2504.20411v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Nonlinear Computation with Linear Optics via Source-Position Encoding", "abstract": "Optical computing systems provide an alternate hardware model which appears\nto be aligned with the demands of neural network workloads. However, the\nchallenge of implementing energy efficient nonlinearities in optics -- a key\nrequirement for realizing neural networks -- is a conspicuous missing link. In\nthis work we introduce a novel method to achieve nonlinear computation in fully\nlinear media. Our method can operate at low power and requires only the ability\nto drive the optical system at a data-dependent spatial position. Leveraging\nthis positional encoding, we formulate a fully automated,\ntopology-optimization-based hardware design framework for extremely specialized\noptical neural networks, drawing on modern advancements in optimization and\nmachine learning. We evaluate our optical designs on machine learning\nclassification tasks: demonstrating significant improvements over linear\nmethods, and competitive performance when compared to standard artificial\nneural networks.", "published": "2025-04-29 03:55:05", "link": "http://arxiv.org/abs/2504.20401v1", "categories": ["physics.optics", "cs.AR", "cs.LG"], "primary_category": "physics.optics"}
{"title": "Partial Answer of How Transformers Learn Automata", "abstract": "We introduce a novel framework for simulating finite automata using\nrepresentation-theoretic semidirect products and Fourier modules, achieving\nmore efficient Transformer-based implementations.", "published": "2025-04-29 03:35:40", "link": "http://arxiv.org/abs/2504.20395v1", "categories": ["cs.FL", "cs.LG"], "primary_category": "cs.FL"}
{"title": "Manifold Clustering with Schatten p-norm Maximization", "abstract": "Manifold clustering, with its exceptional ability to capture complex data\nstructures, holds a pivotal position in cluster analysis. However, existing\nmethods often focus only on finding the optimal combination between K-means and\nmanifold learning, and overlooking the consistency between the data structure\nand labels. To address this issue, we deeply explore the relationship between\nK-means and manifold learning, and on this basis, fuse them to develop a new\nclustering framework. Specifically, the algorithm uses labels to guide the\nmanifold structure and perform clustering on it, which ensures the consistency\nbetween the data structure and labels. Furthermore, in order to naturally\nmaintain the class balance in the clustering process, we maximize the Schatten\np-norm of labels, and provide a theoretical proof to support this.\nAdditionally, our clustering framework is designed to be flexible and\ncompatible with many types of distance functions, which facilitates efficient\nprocessing of nonlinear separable data. The experimental results of several\ndatabases confirm the superiority of our proposed model.", "published": "2025-04-29 03:23:06", "link": "http://arxiv.org/abs/2504.20390v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Generative Learning for Slow Manifolds and Bifurcation Diagrams", "abstract": "In dynamical systems characterized by separation of time scales, the\napproximation of so called ``slow manifolds'', on which the long term dynamics\nlie, is a useful step for model reduction. Initializing on such slow manifolds\nis a useful step in modeling, since it circumvents fast transients, and is\ncrucial in multiscale algorithms alternating between fine scale (fast) and\ncoarser scale (slow) simulations. In a similar spirit, when one studies the\ninfinite time dynamics of systems depending on parameters, the system\nattractors (e.g., its steady states) lie on bifurcation diagrams. Sampling\nthese manifolds gives us representative attractors (here, steady states of ODEs\nor PDEs) at different parameter values. Algorithms for the systematic\nconstruction of these manifolds are required parts of the ``traditional''\nnumerical nonlinear dynamics toolkit.\n  In more recent years, as the field of Machine Learning develops, conditional\nscore-based generative models (cSGMs) have demonstrated capabilities in\ngenerating plausible data from target distributions that are conditioned on\nsome given label. It is tempting to exploit such generative models to produce\nsamples of data distributions conditioned on some quantity of interest (QoI).\nIn this work, we present a framework for using cSGMs to quickly (a) initialize\non a low-dimensional (reduced-order) slow manifold of a multi-time-scale system\nconsistent with desired value(s) of a QoI (a ``label'') on the manifold, and\n(b) approximate steady states in a bifurcation diagram consistent with a (new,\nout-of-sample) parameter value. This conditional sampling can help uncover the\ngeometry of the reduced slow-manifold and/or approximately ``fill in'' missing\nsegments of steady states in a bifurcation diagram.", "published": "2025-04-29 02:38:44", "link": "http://arxiv.org/abs/2504.20375v1", "categories": ["cs.LG", "math.DS", "37M20, 37M21, 68T07, 35B32"], "primary_category": "cs.LG"}
{"title": "Bayesian Experimental Design for Model Discrepancy Calibration: An Auto-Differentiable Ensemble Kalman Inversion Approach", "abstract": "Bayesian experimental design (BED) offers a principled framework for\noptimizing data acquisition by leveraging probabilistic inference. However,\npractical implementations of BED are often compromised by model discrepancy,\ni.e., the mismatch between predictive models and true physical systems, which\ncan potentially lead to biased parameter estimates. While data-driven\napproaches have been recently explored to characterize the model discrepancy,\nthe resulting high-dimensional parameter space poses severe challenges for both\nBayesian updating and design optimization. In this work, we propose a hybrid\nBED framework enabled by auto-differentiable ensemble Kalman inversion (AD-EKI)\nthat addresses these challenges by providing a computationally efficient,\ngradient-free alternative to estimate the information gain for high-dimensional\nnetwork parameters. The AD-EKI allows a differentiable evaluation of the\nutility function in BED and thus facilitates the use of standard gradient-based\nmethods for design optimization. In the proposed hybrid framework, we\niteratively optimize experimental designs, decoupling the inference of\nlow-dimensional physical parameters handled by standard BED methods, from the\nhigh-dimensional model discrepancy handled by AD-EKI. The identified optimal\ndesigns for the model discrepancy enable us to systematically collect\ninformative data for its calibration. The performance of the proposed method is\nstudied by a classical convection-diffusion BED example, and the hybrid\nframework enabled by AD-EKI efficiently identifies informative data to\ncalibrate the model discrepancy and robustly infers the unknown physical\nparameters in the modeled system. Besides addressing the challenges of BED with\nmodel discrepancy, AD-EKI also potentially fosters efficient and scalable\nframeworks in many other areas with bilevel optimization, such as meta-learning\nand structure optimization.", "published": "2025-04-29 00:10:45", "link": "http://arxiv.org/abs/2504.20319v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Opinion-Driven Decision-Making for Multi-Robot Navigation through Narrow Corridors", "abstract": "We propose an opinion-driven navigation framework for multi-robot traversal\nthrough a narrow corridor. Our approach leverages a multi-agent decision-making\nmodel known as the Nonlinear Opinion Dynamics (NOD) to address the narrow\ncorridor passage problem, formulated as a multi-robot navigation game. By\nintegrating the NOD model with a multi-robot path planning algorithm, we\ndemonstrate that the framework effectively reduces the likelihood of deadlocks\nduring corridor traversal. To ensure scalability with an increasing number of\nrobots, we introduce a game reduction technique that enables efficient\ncoordination in larger groups. Extensive simulation studies are conducted to\nvalidate the effectiveness of the proposed approach.", "published": "2025-04-29 17:14:55", "link": "http://arxiv.org/abs/2504.20947v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "A high-order energy-conserving semi-Lagrangian discontinuous Galerkin method for the Vlasov-Ampere system", "abstract": "In this paper, we propose a high-order energy-conserving semi-Lagrangian\ndiscontinuous Galerkin(ECSLDG) method for the Vlasov-Ampere system. The method\nemploys a semi-Lagrangian discontinuous Galerkin scheme for spatial\ndiscretization of the Vlasov equation, achieving high-order accuracy while\nremoving the Courant-Friedrichs-Lewy (CFL) constraint. To ensure energy\nconservation and eliminate the need to resolve the plasma period, we adopt an\nenergy-conserving time discretization introduced by Liu et al. [J. Comput.\nPhys., 492 (2023), 112412]. Temporal accuracy is further enhanced through a\nhigh-order operator splitting strategy, yielding a method that is high-order\naccurate in both space and time. The resulting ECSLDG scheme is unconditionally\nstable and conserves both mass and energy at the fully discrete level,\nregardless of spatial or temporal resolution. Numerical experiments demonstrate\nthe accuracy, stability, and conservation properties of the proposed method. In\nparticular, the method achieves more accurate enforcement of Gauss's law and\nimproved numerical fidelity over low-order schemes, especially when using a\nlarge CFL number.", "published": "2025-04-29 14:28:01", "link": "http://arxiv.org/abs/2504.20813v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Avoided-crossings, degeneracies and Berry phases in the spectrum of quantum noise through analytic Bloch-Messiah decomposition", "abstract": "The Bloch-Messiah decomposition (BMD) is a fundamental tool in quantum\noptics, enabling the analysis and tailoring of multimode Gaussian states by\ndecomposing linear optical transformations into passive interferometers and\nsingle-mode squeezers. Its extension to frequency-dependent matrix-valued\nfunctions, recently introduced as the ``analytic Bloch-Messiah decomposition\"\n(ABMD), provides the most general approach for characterizing the\ndriven-dissipative dynamics of quantum optical systems governed by quadratic\nHamiltonians. In this work, we present a detailed study of the ABMD, focusing\non the typical behavior of parameter-dependent singular values and of their\ncorresponding singular vectors. In particular, we analyze the hitherto\nunexplored occurrence of avoided and genuine crossings in the spectrum of\nquantum noise, the latter being manifested by nontrivial topological Berry\nphases of the singular vectors. We demonstrate that avoided crossings arise\nnaturally when a single parameter is varied, leading to hypersensitivity of the\nsingular vectors and suggesting the presence of genuine crossings in nearby\nsystems. We highlight the possibility of programming the spectral response of\nphotonic systems through the deliberate design of avoided crossings. As a\nnotable example, we show that such control can be exploited to generate broad,\nflat-band squeezing spectra -- a desirable feature for enhancing\ndegaussification protocols. This study provides new insights into the structure\nof multimode quantum correlations and offers a theoretical framework for\nexperimental exploitation of complex quantum optical systems.", "published": "2025-04-29 13:14:15", "link": "http://arxiv.org/abs/2504.20730v1", "categories": ["quant-ph", "cs.NA", "math.NA"], "primary_category": "quant-ph"}
{"title": "On optimal error rates for strong approximation of SDEs with a H\u00f6lder continuous drift coefficient", "abstract": "In the present article we study strong approximation of solutions of scalar\nstochastic differential equations (SDEs) with bounded and $\\alpha$-H\\\"older\ncontinuous drift coefficient and constant diffusion coefficient at time point\n$1$. Recently, it was shown in [arXiv:1909.07961v4 (2021)] that for such SDEs\nthe equidistant Euler scheme achieves an $L^p$-error rate of at least\n$(1+\\alpha)/2$, up to an arbitrary small $\\varepsilon$, for all $p\\geq 1$ and\nall $\\alpha\\in(0, 1]$ in terms of the number of evaluations of the driving\nBrownian motion $W$. In this article we prove a matching lower error bound for\n$\\alpha\\in(0, 1)$. More precisely, we show that for every $\\alpha\\in(0, 1)$,\nthe $L^p$-error rate $(1+\\alpha)/2$ of the Euler scheme in [arXiv:1909.07961v4\n(2021)] can not be improved in general by no numerical method based on finitely\nmany evaluations of $W$ at fixed time points. Up to now, this result was known\nin the literature only for $\\alpha=1$.\n  Additionally, we extend a result from [arXiv:2402.13732v2 (2024)] on sharp\nlower errror bounds for strong approximation of SDEs with a bounded drift\ncoefficient of fractional Sobolev regularity $\\alpha\\in (0,1)$ and constant\ndiffusion coefficient at time point $1$. We prove that for every $\\alpha\\in\n(0,1)$, the $L^p$-error rate $ (1 + \\alpha)/2$ that was shown in\n[arXiv:2101.12185v2 (2022)] for the equidistant Euler scheme can, up to a\nlogarithmic term, not be improved in general by no numerical method based on\nfinitely many evaluations of W at fixed time points. This result was known from\n[arXiv:2402.13732v2 (2024)] only for $\\alpha\\in (1/2,1)$ and $p=2$.\n  For the proof of these lower bounds we use variants of the Weierstrass\nfunction as a drift coefficient and we employ the coupling of noise technique\nrecently introduced in [arXiv:2010.00915v1 (2020)].", "published": "2025-04-29 13:11:46", "link": "http://arxiv.org/abs/2504.20728v1", "categories": ["math.PR", "cs.NA", "math.NA", "65C30, 65C20 (Primary), 60H10 (Secondary)"], "primary_category": "math.PR"}
{"title": "Neural semi-Lagrangian method for high-dimensional advection-diffusion problems", "abstract": "This work is devoted to the numerical approximation of high-dimensional\nadvection-diffusion equations. It is well-known that classical methods, such as\nthe finite volume method, suffer from the curse of dimensionality, and that\ntheir time step is constrained by a stability condition. The semi-Lagrangian\nmethod is known to overcome the stability issue, while recent time-discrete\nneural network-based approaches overcome the curse of dimensionality. In this\nwork, we propose a novel neural semi-Lagrangian method that combines these last\ntwo approaches. It relies on projecting the initial condition onto a\nfinite-dimensional neural space, and then solving an optimization problem,\ninvolving the backwards characteristic equation, at each time step. It is\nparticularly well-suited for implementation on GPUs, as it is fully\nparallelizable and does not require a mesh. We provide rough error estimates,\nand present several high-dimensional numerical experiments to assess the\nperformance of our approach, and compare it to other neural methods.", "published": "2025-04-29 12:52:55", "link": "http://arxiv.org/abs/2504.20715v1", "categories": ["math.NA", "cs.NA", "2020 MSC: 65M25, 76R05, 65M15, 68T07"], "primary_category": "math.NA"}
{"title": "Finite element method with Gr\u00fcnwald-Letnikov type approximation in time for a constant time delay subdiffusion equation", "abstract": "In this work, a subdiffusion equation with constant time delay $\\tau$ is\nconsidered. First, the regularity of the solution to the considered problem is\ninvestigated, finding that its first-order time derivative exhibits singularity\nat $t=0^+$ and its second-order time derivative shows singularity at both\n$t=0^+$ and $\\tau^+$, while the solution can be decomposed into its singular\nand regular components. Then, we derive a fully discrete finite element scheme\nto solve the considered problem based on the standard Galerkin finite element\nmethod in space and the Gr\\\"unwald-Letnikov type approximation in time. The\nanalysis shows that the developed numerical scheme is stable. In order to\ndiscuss the error estimate, a new discrete Gronwall inequality is established.\nUnder the above decomposition of the solution, we obtain a local error estimate\nin time for the developed numerical scheme. Finally, some numerical tests are\nprovided to support our theoretical analysis.", "published": "2025-04-29 08:09:56", "link": "http://arxiv.org/abs/2504.20524v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An energy-stable minimal deformation rate scheme for mean curvature flow and surface diffusion", "abstract": "We propose a new parametric finite element method, referred to as the BGN-MDR\nmethod, for simulating both mean curvature flow and surface diffusion for\nclosed hypersurfaces, as well as open hypersurfaces with moving contact lines\nin three dimensions. The method is also applicable to closed and open curves\nwith moving contact points in two dimensions. The proposed scheme inherits the\nenergy stability from the BGN scheme proposed by Barrett, Garcke, and\nN\\\"urnberg in 2008, and offers improved mesh quality similar to the minimal\ndeformation rate (MDR) method proposed by Hu and Li in 2022, especially for\nsmall time step sizes where the BGN scheme may become unstable and result in\ndeteriorated meshes.", "published": "2025-04-29 07:35:49", "link": "http://arxiv.org/abs/2504.20494v1", "categories": ["math.NA", "cs.NA", "65M12, 65M60, 35K55, 35R01, 53C44"], "primary_category": "math.NA"}
{"title": "Scaling and shape of financial returns distributions modeled as conditionally independent random variables", "abstract": "We show that assuming that the returns are independent when conditioned on\nthe value of their variance (volatility), which itself varies in time randomly,\nthen the distribution of returns is well described by the statistics of the sum\nof conditionally independent random variables. In particular, we show that the\ndistribution of returns can be cast in a simple scaling form, and that its\nfunctional form is directly related to the distribution of the volatilities.\nThis approach explains the presence of power-law tails in the returns as a\ndirect consequence of the presence of a power law tail in the distribution of\nvolatilities. It also provides the form of the distribution of Bitcoin returns,\nwhich behaves as a stretched exponential, as a consequence of the fact that the\nBitcoin volatilities distribution is also closely described by a stretched\nexponential. We test our predictions with data from the S\\&P 500 index, Apple\nand Paramount stocks; and Bitcoin.", "published": "2025-04-29 07:26:20", "link": "http://arxiv.org/abs/2504.20488v1", "categories": ["q-fin.ST", "stat.AP"], "primary_category": "q-fin.ST"}
{"title": "ClusterLOB: Enhancing Trading Strategies by Clustering Orders in Limit Order Books", "abstract": "In the rapidly evolving world of financial markets, understanding the\ndynamics of limit order book (LOB) is crucial for unraveling market\nmicrostructure and participant behavior. We introduce ClusterLOB as a method to\ncluster individual market events in a stream of market-by-order (MBO) data into\ndifferent groups. To do so, each market event is augmented with six\ntime-dependent features. By applying the K-means++ clustering algorithm to the\nresulting order features, we are then able to assign each new order to one of\nthree distinct clusters, which we identify as directional, opportunistic, and\nmarket-making participants, each capturing unique trading behaviors. Our\nexperimental results are performed on one year of MBO data containing\nsmall-tick, medium-tick, and large-tick stocks from NASDAQ. To validate the\nusefulness of our clustering, we compute order flow imbalances across each\ncluster within 30-minute buckets during the trading day. We treat each\ncluster's imbalance as a signal that provides insights into trading strategies\nand participants' responses to varying market conditions. To assess the\neffectiveness of these signals, we identify the trading strategy with the\nhighest Sharpe ratio in the training dataset, and demonstrate that its\nperformance in the test dataset is superior to benchmark trading strategies\nthat do not incorporate clustering. We also evaluate trading strategies based\non order flow imbalance decompositions across different market event types,\nincluding add, cancel, and trade events, to assess their robustness in various\nmarket conditions. This work establishes a robust framework for clustering\nmarket participant behavior, which helps us to better understand market\nmicrostructure, and inform the development of more effective predictive trading\nsignals with practical applications in algorithmic trading and quantitative\nfinance.", "published": "2025-04-29 01:37:33", "link": "http://arxiv.org/abs/2504.20349v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Adaptive Replication Strategies in Trust-Region-Based Bayesian Optimization of Stochastic Functions", "abstract": "We develop and analyze a method for stochastic simulation optimization\nrelying on Gaussian process models within a trust-region framework. We are\ninterested in the case when the variance of the objective function is large. We\npropose to rely on replication and local modeling to cope with this\nhigh-throughput regime, where the number of evaluations may become large to get\naccurate results while still keeping good performance. We propose several\nschemes to encourage replication, from the choice of the acquisition function\nto setup evaluation costs. Compared with existing methods, our results indicate\ngood scaling, in terms of both accuracy (several orders of magnitude better\nthan existing methods) and speed (taking into account evaluation costs).", "published": "2025-04-29 08:13:16", "link": "http://arxiv.org/abs/2504.20527v1", "categories": ["math.OC", "stat.ML"], "primary_category": "math.OC"}
{"title": "Evolution of Gaussians in the Hellinger-Kantorovich-Boltzmann gradient flow", "abstract": "This study leverages the basic insight that the gradient-flow equation\nassociated with the relative Boltzmann entropy, in relation to a Gaussian\nreference measure within the Hellinger-Kantorovich (HK) geometry, preserves the\nclass of Gaussian measures. This invariance serves as the foundation for\nconstructing a reduced gradient structure on the parameter space characterizing\nGaussian densities. We derive explicit ordinary differential equations that\ngovern the evolution of mean, covariance, and mass under the HK-Boltzmann\ngradient flow. The reduced structure retains the additive form of the HK\nmetric, facilitating a comprehensive analysis of the dynamics involved.\n  We explore the geodesic convexity of the reduced system, revealing that\nglobal convexity is confined to the pure transport scenario, while a variant of\nsublevel semi-convexity is observed in the general case. Furthermore, we\ndemonstrate exponential convergence to equilibrium through\nPolyak-Lojasiewicz-type inequalities, applicable both globally and on sublevel\nsets. By monitoring the evolution of covariance eigenvalues, we refine the\ndecay rates associated with convergence. Additionally, we extend our analysis\nto non-Gaussian targets exhibiting strong log-lambda-concavity, corroborating\nour theoretical results with numerical experiments that encompass a\nGaussian-target gradient flow and a Bayesian logistic regression application.", "published": "2025-04-29 03:54:56", "link": "http://arxiv.org/abs/2504.20400v1", "categories": ["math.AP", "math.PR", "stat.ML", "49Q22 (Primary) 35Q49 (Secondary)"], "primary_category": "math.AP"}
{"title": "Sparse mixed linear modeling with anchor-based guidance for high-entropy alloy discovery", "abstract": "High-entropy alloys have attracted attention for their exceptional mechanical\nproperties and thermal stability. However, the combinatorial explosion in the\nnumber of possible elemental compositions renders traditional trial-and-error\nexperimental approaches highly inefficient for materials discovery. To solve\nthis problem, machine learning techniques have been increasingly employed for\nproperty prediction and high-throughput screening. Nevertheless, highly\naccurate nonlinear models often suffer from a lack of interpretability, which\nis a major limitation. In this study, we focus on local data structures that\nemerge from the greedy search behavior inherent to experimental data\nacquisition. By introducing a linear and low-dimensional mixture regression\nmodel, we strike a balance between predictive performance and model\ninterpretability. In addition, we develop an algorithm that simultaneously\nperforms prediction and feature selection by considering multiple candidate\ndescriptors. Through a case study on high-entropy alloys, this study introduces\na method that combines anchor-guided clustering and sparse linear modeling to\naddress biased data structures arising from greedy exploration in materials\nscience.", "published": "2025-04-29 01:44:15", "link": "http://arxiv.org/abs/2504.20354v1", "categories": ["cond-mat.mtrl-sci", "stat.AP", "stat.ME", "stat.ML"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Enhancing Non-Core Language Instruction-Following in Speech LLMs via Semi-Implicit Cross-Lingual CoT Reasoning", "abstract": "Large language models have been extended to the speech domain, leading to the\ndevelopment of speech large language models (SLLMs). While existing SLLMs\ndemonstrate strong performance in speech instruction-following for core\nlanguages (e.g., English), they often struggle with non-core languages due to\nthe scarcity of paired speech-text data and limited multilingual semantic\nreasoning capabilities. To address this, we propose the semi-implicit\nCross-lingual Speech Chain-of-Thought (XS-CoT) framework, which integrates\nspeech-to-text translation into the reasoning process of SLLMs. The XS-CoT\ngenerates four types of tokens: instruction and response tokens in both core\nand non-core languages, enabling cross-lingual transfer of reasoning\ncapabilities. To mitigate inference latency in generating target non-core\nresponse tokens, we incorporate a semi-implicit CoT scheme into XS-CoT, which\nprogressively compresses the first three types of intermediate reasoning tokens\nwhile retaining global reasoning logic during training. By leveraging the\nrobust reasoning capabilities of the core language, XS-CoT improves responses\nfor non-core languages by up to 45\\% in GPT-4 score when compared to direct\nsupervised fine-tuning on two representative SLLMs, Qwen2-Audio and SALMONN.\nMoreover, the semi-implicit XS-CoT reduces token delay by more than 50\\% with a\nslight drop in GPT-4 scores. Importantly, XS-CoT requires only a small amount\nof high-quality training data for non-core languages by leveraging the\nreasoning capabilities of core languages. To support training, we also develop\na data pipeline and open-source speech instruction-following datasets in\nJapanese, German, and French.", "published": "2025-04-29 14:59:42", "link": "http://arxiv.org/abs/2504.20835v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ISDrama: Immersive Spatial Drama Generation through Multimodal Prompting", "abstract": "Multimodal immersive spatial drama generation focuses on creating continuous\nmulti-speaker binaural speech with dramatic prosody based on multimodal\nprompts, with potential applications in AR, VR, and others. This task requires\nsimultaneous modeling of spatial information and dramatic prosody based on\nmultimodal inputs, with high data collection costs. To the best of our\nknowledge, our work is the first attempt to address these challenges. We\nconstruct MRSDrama, the first multimodal recorded spatial drama dataset,\ncontaining binaural drama audios, scripts, videos, geometric poses, and textual\nprompts. Then, we propose ISDrama, the first immersive spatial drama generation\nmodel through multimodal prompting. ISDrama comprises these primary components:\n1) Multimodal Pose Encoder, based on contrastive learning, considering the\nDoppler effect caused by moving speakers to extract unified pose information\nfrom multimodal prompts. 2) Immersive Drama Transformer, a flow-based\nmamba-transformer model that generates high-quality drama, incorporating\nDrama-MOE to select proper experts for enhanced prosody and pose control. We\nalso design a context-consistent classifier-free guidance strategy to\ncoherently generate complete drama. Experimental results show that ISDrama\noutperforms baseline models on objective and subjective metrics. The demos and\ndataset are available at https://aaronz345.github.io/ISDramaDemo.", "published": "2025-04-29 10:56:44", "link": "http://arxiv.org/abs/2504.20630v1", "categories": ["eess.AS", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "TriniMark: A Robust Generative Speech Watermarking Method for Trinity-Level Attribution", "abstract": "The emergence of diffusion models has facilitated the generation of speech\nwith reinforced fidelity and naturalness. While deepfake detection technologies\nhave manifested the ability to identify AI-generated content, their efficacy\ndecreases as generative models become increasingly sophisticated. Furthermore,\ncurrent research in the field has not adequately addressed the necessity for\nrobust watermarking to safeguard the intellectual property rights associated\nwith synthetic speech and generative models. To remedy this deficiency, we\npropose a \\textbf{ro}bust generative \\textbf{s}peech wat\\textbf{e}rmarking\nmethod (TriniMark) for authenticating the generated content and safeguarding\nthe copyrights by enabling the traceability of the diffusion model. We first\ndesign a structure-lightweight watermark encoder that embeds watermarks into\nthe time-domain features of speech and reconstructs the waveform directly. A\ntemporal-aware gated convolutional network is meticulously designed in the\nwatermark decoder for bit-wise watermark recovery. Subsequently, the\nwaveform-guided fine-tuning strategy is proposed for fine-tuning the diffusion\nmodel, which leverages the transferability of watermarks and enables the\ndiffusion model to incorporate watermark knowledge effectively. When an\nattacker trains a surrogate model using the outputs of the target model, the\nembedded watermark can still be learned by the surrogate model and correctly\nextracted. Comparative experiments with state-of-the-art methods demonstrate\nthe superior robustness of our method, particularly in countering compound\nattacks.", "published": "2025-04-29 08:23:28", "link": "http://arxiv.org/abs/2504.20532v1", "categories": ["cs.MM", "cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Towards Flow-Matching-based TTS without Classifier-Free Guidance", "abstract": "Flow matching has demonstrated strong generative capabilities and has become\na core component in modern Text-to-Speech (TTS) systems. To ensure high-quality\nspeech synthesis, Classifier-Free Guidance (CFG) is widely used during the\ninference of flow-matching-based TTS models. However, CFG incurs substantial\ncomputational cost as it requires two forward passes, which hinders its\napplicability in real-time scenarios. In this paper, we explore removing CFG\nfrom flow-matching-based TTS models to improve inference efficiency, while\nmaintaining performance. Specifically, we reformulated the flow matching\ntraining target to directly approximate the CFG optimization trajectory. This\ntraining method eliminates the need for unconditional model evaluation and\nguided tuning during inference, effectively cutting the computational overhead\nin half. Furthermore, It can be seamlessly integrated with existing optimized\nsampling strategies. We validate our approach using the F5-TTS model on the\nLibriTTS dataset. Experimental results show that our method achieves a\n9$\\times$ inference speed-up compared to the baseline F5-TTS, while preserving\ncomparable speech quality. We will release the code and models to support\nreproducibility and foster further research in this area.", "published": "2025-04-29 00:54:15", "link": "http://arxiv.org/abs/2504.20334v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Flexible Semantic-Aware Resource Allocation: Serving More Users Through Similarity Range Constraints", "abstract": "Semantic communication (SemCom) aims to enhance the resource efficiency of\nnext-generation networks by transmitting the underlying meaning of messages,\nfocusing on information relevant to the end user. Existing literature on SemCom\nprimarily emphasizes learning the encoder and decoder through end-to-end deep\nlearning frameworks, with the objective of minimizing a task-specific semantic\nloss function. Beyond its influence on the physical and application layer\ndesign, semantic variability across users in multi-user systems enables the\ndesign of resource allocation schemes that incorporate user-specific semantic\nrequirements. To this end, \\emph{a semantic-aware resource allocation} scheme\nis proposed with the objective of maximizing transmission and semantic\nreliability, ultimately increasing the number of users whose semantic\nrequirements are met. The resulting resource allocation problem is a non-convex\nmixed-integer nonlinear program (MINLP), which is known to be NP-hard. To make\nthe problem tractable, it is decomposed into a set of sub-problems, each of\nwhich is efficiently solved via geometric programming techniques. Finally,\nsimulations demonstrate that the proposed method improves user satisfaction by\nup to $17.1\\%$ compared to state of the art methods based on quality of\nexperience-aware SemCom methods.", "published": "2025-04-29 17:04:48", "link": "http://arxiv.org/abs/2504.20939v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Bayesian Deep End-to-End Learning for MIMO-OFDM System with Delay-Domain Sparse Precoder", "abstract": "This paper introduces a novel precoder design aimed at reducing pilot\noverhead for effective channel estimation in multiple-input multiple-output\northogonal frequency division multiplexing (MIMO-OFDM) applications utilizing\nhigh-order modulation. We propose an innovative demodulation reference signal\nscheme that achieves up to an 8x reduction in overhead by implementing a\ndelay-domain sparsity constraint on the precoder. Furthermore, we present a\ndeep neural network (DNN)-based end-to-end architecture that integrates a\npropagation channel estimation module, a precoder design module, and an\neffective channel estimation module. Additionally, we propose a Bayesian\nmodel-assisted training framework that incorporates domain knowledge, resulting\nin an interpretable datapath design. Simulation results demonstrate that our\nproposed solution significantly outperforms various baseline schemes while\nexhibiting substantially lower computational complexity.", "published": "2025-04-29 13:54:19", "link": "http://arxiv.org/abs/2504.20777v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Performance Evaluation of Efficient Hybrid Compression Methods For Devanagiri-Encoded Hindi Text Using Lossless Algorithms", "abstract": "This research paper provides a comprehensive performance analysis of five\nstandard lossless compression algorithms-LZMA, Zstd, Brotli, Bzip2, and\nLZ4HC-alongside sixty hybrid combinations on UTF-8 encoded Hindi text datasets,\nwritten in the Devanagari script, across varying sizes-small, medium, and\nlarge. The evaluation covers compression ratio, compression speed,\ndecompression speed, and a derived weighted normalized efficiency score. Hybrid\nalgorithms-especially those combining Zstd with LZ4HC or Brotli-demonstrate\nsuperior performance across all individual parameters. Independent Zstd\nachieves the highest efficiency score for the medium-sized dataset,\nillustrating how a well-balanced algorithm can excel in overall efficiency\ndespite not leading in any single metric. However, in terms of compression\nratio, speed, and decompression speed, hybrid methods consistently outperform\nstandalone approaches. Notably, the hybrid combination Zstd + LZ4HC achieves\nthe highest efficiency, with scores of 0.6764 for small files and 0.8597 for\nlarge files. Independent algorithms such as Zstd and Bzip2 perform well but are\nconsistently surpassed by strategic hybrid pairings. The analysis underscores\nthe significance of combining fast and high-ratio compression techniques,\nparticularly for language-specific data. However, not all hybrids yielded\nsignificant improvements, with some introducing computational overhead. This\ncomparative analysis highlights the potential of hybrid compression in\napplications such as cloud storage, mobile messaging, and NLP-based Hindi text\nprocessing.", "published": "2025-04-29 13:27:32", "link": "http://arxiv.org/abs/2504.20747v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Parametrized Stacked Intelligent Metasurfaces for Bistatic Integrated Sensing and Communications", "abstract": "We consider stacked intelligent metasurfaces (SIMs) as a tool to improve the\nperformance of bistatic integrated sensing and communications (ISAC) schemes.\nTo that end, we optimize the SIMs and design a radar parameter estimation (RPE)\nscheme aimed at enhancing radar sensing capabilities as well as communication\nperformance under ISAC-enabling waveforms known to perform well in\ndoubly-dispersive (DD) channels. The SIM optimization is done via a min-max\nproblem formulation solved via steepest ascent with closed-form gradients,\nwhile the RPE is carried out via a compressed sensing-based probabilistic data\nassociation (PDA) algorithm. Our numerical results indicate that the design of\nwaveforms suitable to mitigating the effects of DD channels is significantly\nimpacted by the emerging SIM technology.", "published": "2025-04-29 11:36:40", "link": "http://arxiv.org/abs/2504.20661v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Disjoint Delay-Doppler Estimation in OTFS ISAC with Deep Learning-aided Path Detection", "abstract": "In this work, the problem of communication and radar sensing in orthogonal\ntime frequency space (OTFS) with reduced cyclic prefix (RCP) is addressed. A\nmonostatic integrated sensing and communications (ISAC) system is developed\nand, it is demonstrated that by leveraging the cyclic shift property inherent\nin the RCP, a delay-Doppler (DD) channel matrix that encapsulates the effects\nof propagation delays and Doppler shifts through unitary matrices can be\nderived. Consequently, a novel low-complexity correlation-based algorithm\nperforming disjoint delay-Doppler estimation is proposed for channel\nestimation. Subsequently, this estimation approach is adapted to perform radar\nsensing on backscattered data frames. Moreover, channel estimation is\ncomplemented by a deep learning (DL) architecture that improves path detection\nand accuracy under low signal-to-noise ratio (SNR) conditions, compared to\nstopping criterion (SC) based multipath detection. Simulation results indicate\nthat the proposed estimation scheme achieves lower normalized mean squared\nerror (NMSE) compared to conventional channel estimation algorithms and sensing\nperformance close to the Cramer-Rao lower bound (CRLB). Furthermore, an\niterative data detection algorithm based on matched filter (MF) and combining\nis developed by exploiting the unitary property of delay-Doppler parameterized\nmatrices. Simulation results reveal that this iterative scheme achieves\nperformance comparable to that of the linear minimum mean squared error (LMMSE)\nestimator while significantly reducing computational complexity.", "published": "2025-04-29 11:34:47", "link": "http://arxiv.org/abs/2504.20659v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Cell-free Fluid Antenna Multiple Access Networks", "abstract": "Fluid antenna enables position reconfigurability that gives transceiver\naccess to a high-resolution spatial signal and the ability to avoid\ninterference through the ups and downs of fading channels. Previous studies\ninvestigated this fluid antenna multiple access (FAMA) approach in a\nsingle-cell setup only. In this paper, we consider a cell-free network\narchitecture in which users are associated with the nearest base stations (BSs)\nand all users share the same physical channel. Each BS has multiple fixed\nantennas that employ maximum ratio transmission (MRT) to beam to its associated\nusers while each user relies on its fluid antenna system (FAS) on one radio\nfrequency (RF) chain to overcome the inter-user interference. Our aim is to\nanalyze the outage probability performance of such cell-free FAMA network when\nboth large- and small-scale fading effects are considered. To do so, we derive\nthe distribution of the received \\textcolor{black}{magnitude} for a typical\nuser and then the interference distribution under both fast and slow port\nswitching techniques. The outage probability is finally obtained in integral\nform in each case. Numerical results demonstrate that in an\ninterference-limited situation, although fast port switching is typically\nunderstood as the superior method for FAMA, slow port switching emerges as a\nmore effective solution when there is a large antenna array at the BS.\nMoreover, it is revealed that FAS at each user can serve to greatly reduce the\nburden of BS in terms of both antenna costs and CSI estimation overhead,\nthereby enhancing the scalability of cell-free networks.", "published": "2025-04-29 10:50:10", "link": "http://arxiv.org/abs/2504.20623v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Communications-Centric Secure ISAC with Hybrid Reconfigurable Intelligent Surfaces", "abstract": "Hybrid reconfigurable intelligent surfaces (HRISs) constitute an emerging\nparadigm of metasurfaces that empowers the concept of smart wireless\nenvironments, inherently supporting simultaneously communications and sensing.\nVery recently, some preliminary HRIS designs for Integrated Sensing And\nCommunications (ISAC) have appeared, however, secure ISAC schemes are still\nlacking. In this paper, we present a novel communications-centric secure ISAC\nframework capitalizing on the dual-functional capability of HRISs to realize\nbistatic sensing simultaneously with secure downlink communications. In\nparticular, we jointly optimize the BS precoding vector and the HRIS reflection\nand analog combining configurations to enable simultaneous accurate estimation\nof both a legitimate user and an eavesdropper, while guaranteeing a predefined\nthreshold for the secrecy spectral efficiency, with both operations focused\nwithin an area of interest. The presented simulation results validate the\neffectiveness of the proposed secure ISAC design, highlighting the interplay\namong key system design parameters as well as quantifying the trade-offs\nbetween the HRIS's absorption and reflection coeffcients.", "published": "2025-04-29 10:18:15", "link": "http://arxiv.org/abs/2504.20608v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Sense-then-Charge: Wireless Power Transfer to Unresponsive Devices with Unknown Location", "abstract": "This paper explores a multi-antenna dual-functional radio frequency (RF)\nwireless power transfer (WPT) and radar system to charge multiple unresponsive\ndevices. We formulate a beamforming problem to maximize the minimum received\npower at the devices without prior location and channel state information (CSI)\nknowledge. We propose dividing transmission blocks into sensing and charging\nphases. First, the location of the devices is estimated by sending sensing\nsignals and performing multiple signal classification and least square\nestimation on the received echo. Then, the estimations are used for CSI\nprediction and RF-WPT beamforming. Simulation results reveal that there is an\noptimal number of blocks allocated for sensing and charging depending on the\nsystem setup. Our sense-then-charge (STC) protocol can outperform CSI-free\nbenchmarks and achieve near-optimal performance with a sufficient number of\nreceive antennas and transmit power. However, STC struggles if using\ninsufficient antennas or power as device numbers grow.", "published": "2025-04-29 09:36:24", "link": "http://arxiv.org/abs/2504.20580v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Physics-Informed Neural Network for Parameter Identification: a Buck Converter Case Study", "abstract": "System-level condition monitoring methods estimate the electrical parameters\nof multiple components in a converter to assess their health status. The\nestimation accuracy and variation can differ significantly across parameters.\nFor instance, inductance estimations are generally more accurate and stable\nthan inductor resistance in a buck converter. However, these performance\ndifferences remain to be analyzed with a more systematic approach otherwise the\ncondition monitoring results can be unreliable. Therefore, this paper analyzes\nthe training loss landscape against multiple parameters of a buck converter to\nprovide a systematic explanation of different performances. If the training\nloss is high and smooth, the estimated circuit parameter typically is accurate\nand has low variation. Furthermore, a novel physics-informed neural network\n(PINN) is proposed, offering faster convergence and lower computation\nrequirements compared to an existing PINN method. The proposed method is\nvalidated through simulations, where the loss landscape identifies the\nunreliable parameter estimations, and the PINN can estimate the remaining\nparameters.", "published": "2025-04-29 08:15:09", "link": "http://arxiv.org/abs/2504.20528v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Histogram-Probabilistic Multi-Hypothesis Tracking with Integrated Target Existence", "abstract": "The histogram-probabilistic multi-hypothesis tracker (H-PMHT) is a parametric\napproach to solving the multi-target track-before-detect (TBD) problem, using\nexpectation maximisation (EM). A key limitation of this method is the\nassumption of a known and constant number of targets. In this paper, we propose\nthe integrated existence Poisson histogram probabilistic multi-hypothesis\ntracker (IE-PHPMHT), for TBD of multiple targets. It extends the H-PMHT\nframework by adding a probability of existence to each potential target. For\nthe derivation, we utilise a Poisson point process (PPP) measurement model and\nBernoulli targets, allowing for a multi-Bernoulli birth process and an unknown,\ntime-varying number of targets. Hence, integrated track management is achieved\nthrough the discrimination of track quality assessments based on existence\nprobabilities. The algorithm is evaluated in a simulation study of two\nscenarios and is compared with several other algorithms, demonstrating its\nperformance.", "published": "2025-04-29 08:12:07", "link": "http://arxiv.org/abs/2504.20526v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Distributed U6G ELAA Communication Systems: Channel Measurement and Small-Scale Fading Characterization", "abstract": "The distributed upper 6 GHz (U6G) extra-large scale antenna array (ELAA) is a\nkey enabler for future wireless communication systems, offering higher\nthroughput and wider coverage, similar to existing ELAA systems, while\neffectively mitigating unaffordable complexity and hardware overhead. Uncertain\nchannel characteristics, however, present significant bottleneck problems that\nhinder the hardware structure and algorithm design of the distributed U6G ELAA\nsystem. In response, we construct a U6G channel sounder and carry out extensive\nmeasurement campaigns across various typical scenarios. Initially, U6G channel\ncharacteristics, particularly small-scale fading characteristics, are unveiled\nand compared across different scenarios. Subsequently, the U6G ELAA channel\ncharacteristics are analyzed using a virtual array comprising 64 elements.\nFurthermore, inspired by the potential for distributed processing, we\ninvestigate U6G ELAA channel characteristics from the perspectives of subarrays\nand sub-bands, including subarray-wise nonstationarities, consistencies,\nfar-field approximations, and sub-band characteristics. Through a combination\nof analysis and measurement validation, several insights and benefits,\nparticularly suitable for distributed processing in U6G ELAA systems, are\nrevealed, which provides practical validation for the deployment of U6G ELAA\nsystems.", "published": "2025-04-29 07:57:08", "link": "http://arxiv.org/abs/2504.20514v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Task-Oriented Semantic Communication with Importance-Aware Rate Control", "abstract": "Semantic communication is recognized for its high compression efficiency and\nrobust resistance to noise. However, utilizing a fixed transmission rate in\nenvironments with dynamic signal-to-noise ratios (SNR) often results in\ninefficient use of communication resources. To address this challenge, this\nletter proposes an importance-aware rate control semantic communication (IRCSC)\nscheme, which dynamically adjusts transmission rates in response to both\nchannel conditions and semantic importance. The scheme employs a\ncontribution-based importance analyzer to rank semantic importance.\nAdditionaly, a novel metric, the semantic transmission integrity index (STII),\nis proposed to quantify the amount of correctly transmitted information and to\ncorrelate it with inference performance. Simulations indicate that, with low\ncomputational complexity, IRCSC guarantees a controllable trade-off between\nperformance and rate, delivering higher compression efficiency and improved\ntask performance in high-SNR scenarios.", "published": "2025-04-29 05:32:18", "link": "http://arxiv.org/abs/2504.20441v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A High-Resolution Transmission Line Model with De-embedding Structure for Ultralow Contact Resistivity Extraction", "abstract": "In this article, we present a contact resistivity extraction method\ncalibrated using a de-embedding structure, called High-Resolution Transmission\nLine Model (HR-TLM). HR-TLM has the similar infrastructure with Refined TLM\n(RTLM) or Refined-Ladder TLM(R-LTLM), but is optimized for calibration methods.\nIts advantage lies in maintaining low \\r{ho}_c extraction accuracy while\nsignificantly reducing the impact of structural process errors. According to\nthe error analysis model, we verify that the extraction accuracy of HR-TLM\nbased on R-LTLM can reach 10-9 {\\Omega}cm2 at micron scale lithography\nprecision.", "published": "2025-04-29 05:29:47", "link": "http://arxiv.org/abs/2504.20439v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "The Mean of Multi-Object Trajectories", "abstract": "This paper introduces the concept of a mean for trajectories and multi-object\ntrajectories--sets or multi-sets of trajectories--along with algorithms for\ncomputing them. Specifically, we use the Fr\\'{e}chet mean, and metrics based on\nthe optimal sub-pattern assignment (OSPA) construct, to extend the notion of\naverage from vectors to trajectories and multi-object trajectories. Further, we\ndevelop efficient algorithms to compute these means using greedy search and\nGibbs sampling. Using distributed multi-object tracking as an application, we\ndemonstrate that the Fr\\'{e}chet mean approach to multi-object trajectory\nconsensus significantly outperforms state-of-the-art distributed multi-object\ntracking methods.", "published": "2025-04-29 03:25:39", "link": "http://arxiv.org/abs/2504.20391v1", "categories": ["eess.SP", "cs.RO"], "primary_category": "eess.SP"}
{"title": "Quantifying the Noise of Structural Perturbations on Graph Adversarial Attacks", "abstract": "Graph neural networks have been widely utilized to solve graph-related tasks\nbecause of their strong learning power in utilizing the local information of\nneighbors. However, recent studies on graph adversarial attacks have proven\nthat current graph neural networks are not robust against malicious attacks.\nYet much of the existing work has focused on the optimization objective based\non attack performance to obtain (near) optimal perturbations, but paid less\nattention to the strength quantification of each perturbation such as the\ninjection of a particular node/link, which makes the choice of perturbations a\nblack-box model that lacks interpretability. In this work, we propose the\nconcept of noise to quantify the attack strength of each adversarial link.\nFurthermore, we propose three attack strategies based on the defined noise and\nclassification margins in terms of single and multiple steps optimization.\nExtensive experiments conducted on benchmark datasets against three\nrepresentative graph neural networks demonstrate the effectiveness of the\nproposed attack strategies. Particularly, we also investigate the preferred\npatterns of effective adversarial perturbations by analyzing the corresponding\nproperties of the selected perturbation nodes.", "published": "2025-04-29 15:42:56", "link": "http://arxiv.org/abs/2504.20869v2", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Ascendra: Dynamic Request Prioritization for Efficient LLM Serving", "abstract": "The rapid advancement of Large Language Models (LLMs) has driven the need for\nmore efficient serving strategies. In this context, efficiency refers to the\nproportion of requests that meet their Service Level Objectives (SLOs),\nparticularly for Time To First Token (TTFT) and Time Between Tokens (TBT).\nHowever, existing systems often prioritize one metric at the cost of the other.\nWe present Ascendra, an LLM serving system designed to meet both TTFT and TBT\nSLOs simultaneously. The core insight behind Ascendra is that a request's\nurgency evolves as it approaches its deadline. To leverage this, Ascendra\npartitions GPU resources into two types of instances: low-priority and\nhigh-priority. Low-priority instances maximize throughput by processing\nrequests out of arrival order, but at the risk of request starvation. To\naddress this, Ascendra employs a performance model to predict requests at risk\nof missing their SLOs and proactively offloads them to high-priority instances.\nHigh-priority instances are optimized for low-latency execution and handle\nurgent requests nearing their deadlines. This partitioned architecture enables\nAscendra to effectively balance high throughput and low latency. Extensive\nevaluation shows that Ascendra improves system throughput by up to 1.7x\ncompared to vLLM and Sarathi-Serve while meeting both TTFT and TBT SLOs.", "published": "2025-04-29 14:51:26", "link": "http://arxiv.org/abs/2504.20828v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with Multi-Modality Observation Data", "abstract": "With the development of distributed systems, microservices and cloud native\ntechnologies have become central to modern enterprise software development.\nDespite bringing significant advantages, these technologies also increase\nsystem complexity and operational challenges. Traditional root cause analysis\n(RCA) struggles to achieve automated fault response, heavily relying on manual\nintervention. In recent years, large language models (LLMs) have made\nbreakthroughs in contextual inference and domain knowledge integration,\nproviding new solutions for Artificial Intelligence for Operations (AIOps).\nHowever, Existing LLM-based approaches face three key challenges: text input\nconstraints, dynamic service dependency hallucinations, and context window\nlimitations. To address these issues, we propose a tool-assisted LLM agent with\nmulti-modality observation data, namely TAMO, for fine-grained RCA. It unifies\nmulti-modal observational data into time-aligned representations to extract\nconsistent features and employs specialized root cause localization and fault\nclassification tools for perceiving the contextual environment. This approach\novercomes the limitations of LLM in handling real-time changing service\ndependencies and raw observational data and guides LLM to generate repair\nstrategies aligned with system contexts by structuring key information into a\nprompt. Experimental results show that TAMO performs well in root cause\nanalysis when dealing with public datasets characterized by heterogeneity and\ncommon fault types, demonstrating its effectiveness.", "published": "2025-04-29 06:50:48", "link": "http://arxiv.org/abs/2504.20462v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DS_FusionNet: Dynamic Dual-Stream Fusion with Bidirectional Knowledge Distillation for Plant Disease Recognition", "abstract": "Given the severe challenges confronting the global growth security of\neconomic crops, precise identification and prevention of plant diseases has\nemerged as a critical issue in artificial intelligence-enabled agricultural\ntechnology. To address the technical challenges in plant disease recognition,\nincluding small-sample learning, leaf occlusion, illumination variations, and\nhigh inter-class similarity, this study innovatively proposes a Dynamic\nDual-Stream Fusion Network (DS_FusionNet). The network integrates a\ndual-backbone architecture, deformable dynamic fusion modules, and\nbidirectional knowledge distillation strategy, significantly enhancing\nrecognition accuracy. Experimental results demonstrate that DS_FusionNet\nachieves classification accuracies exceeding 90% using only 10% of the\nPlantDisease and CIFAR-10 datasets, while maintaining 85% accuracy on the\ncomplex PlantWild dataset, exhibiting exceptional generalization capabilities.\nThis research not only provides novel technical insights for fine-grained image\nclassification but also establishes a robust foundation for precise\nidentification and management of agricultural diseases.", "published": "2025-04-29 17:15:02", "link": "http://arxiv.org/abs/2504.20948v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "End-to-end Audio Deepfake Detection from RAW Waveforms: a RawNet-Based Approach with Cross-Dataset Evaluation", "abstract": "Audio deepfakes represent a growing threat to digital security and trust,\nleveraging advanced generative models to produce synthetic speech that closely\nmimics real human voices. Detecting such manipulations is especially\nchallenging under open-world conditions, where spoofing methods encountered\nduring testing may differ from those seen during training. In this work, we\npropose an end-to-end deep learning framework for audio deepfake detection that\noperates directly on raw waveforms. Our model, RawNetLite, is a lightweight\nconvolutional-recurrent architecture designed to capture both spectral and\ntemporal features without handcrafted preprocessing. To enhance robustness, we\nintroduce a training strategy that combines data from multiple domains and\nadopts Focal Loss to emphasize difficult or ambiguous samples. We further\ndemonstrate that incorporating codec-based manipulations and applying\nwaveform-level audio augmentations (e.g., pitch shifting, noise, and time\nstretching) leads to significant generalization improvements under realistic\nacoustic conditions. The proposed model achieves over 99.7% F1 and 0.25% EER on\nin-domain data (FakeOrReal), and up to 83.4% F1 with 16.4% EER on a challenging\nout-of-distribution test set (AVSpoof2021 + CodecFake). These findings\nhighlight the importance of diverse training data, tailored objective functions\nand audio augmentations in building resilient and generalizable audio forgery\ndetectors. Code and pretrained models are available at\nhttps://iplab.dmi.unict.it/mfs/Deepfakes/PaperRawNet2025/.", "published": "2025-04-29 16:38:23", "link": "http://arxiv.org/abs/2504.20923v2", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PixelHacker: Image Inpainting with Structural and Semantic Consistency", "abstract": "Image inpainting is a fundamental research area between image editing and\nimage generation. Recent state-of-the-art (SOTA) methods have explored novel\nattention mechanisms, lightweight architectures, and context-aware modeling,\ndemonstrating impressive performance. However, they often struggle with complex\nstructure (e.g., texture, shape, spatial relations) and semantics (e.g., color\nconsistency, object restoration, and logical correctness), leading to artifacts\nand inappropriate generation. To address this challenge, we design a simple yet\neffective inpainting paradigm called latent categories guidance, and further\npropose a diffusion-based model named PixelHacker. Specifically, we first\nconstruct a large dataset containing 14 million image-mask pairs by annotating\nforeground and background (potential 116 and 21 categories, respectively).\nThen, we encode potential foreground and background representations separately\nthrough two fixed-size embeddings, and intermittently inject these features\ninto the denoising process via linear attention. Finally, by pre-training on\nour dataset and fine-tuning on open-source benchmarks, we obtain PixelHacker.\nExtensive experiments show that PixelHacker comprehensively outperforms the\nSOTA on a wide range of datasets (Places2, CelebA-HQ, and FFHQ) and exhibits\nremarkable consistency in both structure and semantics. Project page at\nhttps://hustvl.github.io/PixelHacker.", "published": "2025-04-29 05:28:36", "link": "http://arxiv.org/abs/2504.20438v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Binary Search via Overlapping Partitions", "abstract": "This paper considers the task of performing binary search under noisy\ndecisions, focusing on the application of target area localization. In the\npresence of noise, the classical partitioning approach of binary search is\nprone to error propagation due to the use of strictly disjoint splits. While\nexisting works on noisy binary search propose techniques such as query\nrepetition or probabilistic updates to mitigate errors, they often lack\nexplicit mechanisms to manage the trade-off between error probability and\nsearch complexity, with some providing only asymptotic guarantees. To address\nthis gap, we propose a binary search framework with tunable overlapping\npartitions, which introduces controlled redundancy into the search process to\nenhance robustness against noise. We analyze the performance of the proposed\nalgorithm in both discrete and continuous domains for the problem of area\nlocalization, quantifying how the overlap parameter impacts the trade-off\nbetween search tree depth and error probability. Unlike previous methods, this\napproach allows for direct control over the balance between reliability and\nefficiency. Our results emphasize the versatility and effectiveness of the\nproposed method, providing a principled extension to existing noisy search\nparadigms and enabling new insights into the interplay between partitioning\nstrategies and measurement reliability.", "published": "2025-04-29 07:56:02", "link": "http://arxiv.org/abs/2504.20513v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Preference-centric Bandits: Optimality of Mixtures and Regret-efficient Algorithms", "abstract": "The objective of canonical multi-armed bandits is to identify and repeatedly\nselect an arm with the largest reward, often in the form of the expected value\nof the arm's probability distribution. Such a utilitarian perspective and focus\non the probability models' first moments, however, is agnostic to the\ndistributions' tail behavior and their implications for variability and risks\nin decision-making. This paper introduces a principled framework for shifting\nfrom expectation-based evaluation to an alternative reward formulation, termed\na preference metric (PM). The PMs can place the desired emphasis on different\nreward realization and can encode a richer modeling of preferences that\nincorporate risk aversion, robustness, or other desired attitudes toward\nuncertainty. A fundamentally distinct observation in such a PM-centric\nperspective is that designing bandit algorithms will have a significantly\ndifferent principle: as opposed to the reward-based models in which the optimal\nsampling policy converges to repeatedly sampling from the single best arm, in\nthe PM-centric framework the optimal policy converges to selecting a mix of\narms based on specific mixing weights. Designing such mixture policies departs\nfrom the principles for designing bandit algorithms in significant ways,\nprimarily because of uncountable mixture possibilities. The paper formalizes\nthe PM-centric framework and presents two algorithm classes (horizon-dependent\nand anytime) that learn and track mixtures in a regret-efficient fashion. These\nalgorithms have two distinctions from their canonical counterparts: (i) they\ninvolve an estimation routine to form reliable estimates of optimal mixtures,\nand (ii) they are equipped with tracking mechanisms to navigate arm selection\nfractions to track the optimal mixtures. These algorithms' regret guarantees\nare investigated under various algebraic forms of the PMs.", "published": "2025-04-29 15:46:59", "link": "http://arxiv.org/abs/2504.20877v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Avoided-crossings, degeneracies and Berry phases in the spectrum of quantum noise through analytic Bloch-Messiah decomposition", "abstract": "The Bloch-Messiah decomposition (BMD) is a fundamental tool in quantum\noptics, enabling the analysis and tailoring of multimode Gaussian states by\ndecomposing linear optical transformations into passive interferometers and\nsingle-mode squeezers. Its extension to frequency-dependent matrix-valued\nfunctions, recently introduced as the \"analytic Bloch-Messiah decomposition\"\n(ABMD), provides the most general approach for characterizing the\ndriven-dissipative dynamics of quantum optical systems governed by quadratic\nHamiltonians. In this work, we present a detailed study of the ABMD, focusing\non the typical behavior of parameter-dependent singular values and of their\ncorresponding singular vectors. In particular, we analyze the hitherto\nunexplored occurrence of avoided and genuine crossings in the spectrum of\nquantum noise, the latter being manifested by nontrivial topological Berry\nphases of the singular vectors. We demonstrate that avoided crossings arise\nnaturally when a single parameter is varied, leading to hypersensitivity of the\nsingular vectors and suggesting the presence of genuine crossings in nearby\nsystems. We highlight the possibility of programming the spectral response of\nphotonic systems through the deliberate design of avoided crossings. As a\nnotable example, we show that such control can be exploited to generate broad,\nflat-band squeezing spectra -- a desirable feature for enhancing\ndegaussification protocols. This study provides new insights into the structure\nof multimode quantum correlations and offers a theoretical framework for\nexperimental exploitation of complex quantum optical systems.", "published": "2025-04-29 13:14:15", "link": "http://arxiv.org/abs/2504.20730v2", "categories": ["quant-ph", "cs.NA", "math.NA"], "primary_category": "quant-ph"}
{"title": "ClusterLOB: Enhancing Trading Strategies by Clustering Orders in Limit Order Books", "abstract": "In the rapidly evolving world of financial markets, understanding the\ndynamics of limit order book (LOB) is crucial for unraveling market\nmicrostructure and participant behavior. We introduce ClusterLOB as a method to\ncluster individual market events in a stream of market-by-order (MBO) data into\ndifferent groups. To do so, each market event is augmented with six\ntime-dependent features. By applying the K-means++ clustering algorithm to the\nresulting order features, we are then able to assign each new order to one of\nthree distinct clusters, which we identify as directional, opportunistic, and\nmarket-making participants, each capturing unique trading behaviors. Our\nexperimental results are performed on one year of MBO data containing\nsmall-tick, medium-tick, and large-tick stocks from NASDAQ. To validate the\nusefulness of our clustering, we compute order flow imbalances across each\ncluster within 30-minute buckets during the trading day. We treat each\ncluster's imbalance as a signal that provides insights into trading strategies\nand participants' responses to varying market conditions. To assess the\neffectiveness of these signals, we identify the trading strategy with the\nhighest Sharpe ratio in the training dataset, and demonstrate that its\nperformance in the test dataset is superior to benchmark trading strategies\nthat do not incorporate clustering. We also evaluate trading strategies based\non order flow imbalance decompositions across different market event types,\nincluding add, cancel, and trade events, to assess their robustness in various\nmarket conditions. This work establishes a robust framework for clustering\nmarket participant behavior, which helps us to better understand market\nmicrostructure, and inform the development of more effective predictive trading\nsignals with practical applications in algorithmic trading and quantitative\nfinance.", "published": "2025-04-29 01:37:33", "link": "http://arxiv.org/abs/2504.20349v2", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Pretraining Large Brain Language Model for Active BCI: Silent Speech", "abstract": "This paper explores silent speech decoding in active brain-computer interface\n(BCI) systems, which offer more natural and flexible communication than\ntraditional BCI applications. We collected a new silent speech dataset of over\n120 hours of electroencephalogram (EEG) recordings from 12 subjects, capturing\n24 commonly used English words for language model pretraining and decoding.\nFollowing the recent success of pretraining large models with self-supervised\nparadigms to enhance EEG classification performance, we propose Large Brain\nLanguage Model (LBLM) pretrained to decode silent speech for active BCI. To\npretrain LBLM, we propose Future Spectro-Temporal Prediction (FSTP) pretraining\nparadigm to learn effective representations from unlabeled EEG data. Unlike\nexisting EEG pretraining methods that mainly follow a masked-reconstruction\nparadigm, our proposed FSTP method employs autoregressive modeling in temporal\nand frequency domains to capture both temporal and spectral dependencies from\nEEG signals. After pretraining, we finetune our LBLM on downstream tasks,\nincluding word-level and semantic-level classification. Extensive experiments\ndemonstrate significant performance gains of the LBLM over fully-supervised and\npretrained baseline models. For instance, in the difficult cross-session\nsetting, our model achieves 47.0\\% accuracy on semantic-level classification\nand 39.6\\% in word-level classification, outperforming baseline methods by\n5.4\\% and 7.3\\%, respectively. Our research advances silent speech decoding in\nactive BCI systems, offering an innovative solution for EEG language model\npretraining and a new dataset for fundamental research.", "published": "2025-04-29 22:48:27", "link": "http://arxiv.org/abs/2504.21214v1", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Automatic Legal Writing Evaluation of LLMs", "abstract": "Despite the recent advances in Large Language Models, benchmarks for\nevaluating legal writing remain scarce due to the inherent complexity of\nassessing open-ended responses in this domain. One of the key challenges in\nevaluating language models on domain-specific tasks is finding test datasets\nthat are public, frequently updated, and contain comprehensive evaluation\nguidelines. The Brazilian Bar Examination meets these requirements. We\nintroduce oab-bench, a benchmark comprising 105 questions across seven areas of\nlaw from recent editions of the exam. The benchmark includes comprehensive\nevaluation guidelines and reference materials used by human examiners to ensure\nconsistent grading. We evaluate the performance of four LLMs on oab-bench,\nfinding that Claude-3.5 Sonnet achieves the best results with an average score\nof 7.93 out of 10, passing all 21 exams. We also investigated whether LLMs can\nserve as reliable automated judges for evaluating legal writing. Our\nexperiments show that frontier models like OpenAI's o1 achieve a strong\ncorrelation with human scores when evaluating approved exams, suggesting their\npotential as reliable automated evaluators despite the inherently subjective\nnature of legal writing assessment. The source code and the benchmark --\ncontaining questions, evaluation guidelines, model-generated responses, and\ntheir respective automated evaluations -- are publicly available.", "published": "2025-04-29 22:16:39", "link": "http://arxiv.org/abs/2504.21202v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare", "abstract": "This study aims to guide language model selection by investigating: 1) the\nnecessity of finetuning versus zero-shot usage, 2) the benefits of\ndomain-adjacent versus generic pretrained models, 3) the value of further\ndomain-specific pretraining, and 4) the continued relevance of Small Language\nModels (SLMs) compared to Large Language Models (LLMs) for specific tasks.\nUsing electronic pathology reports from the British Columbia Cancer Registry\n(BCCR), three classification scenarios with varying difficulty and data size\nare evaluated. Models include various SLMs and an LLM. SLMs are evaluated both\nzero-shot and finetuned; the LLM is evaluated zero-shot only. Finetuning\nsignificantly improved SLM performance across all scenarios compared to their\nzero-shot results. The zero-shot LLM outperformed zero-shot SLMs but was\nconsistently outperformed by finetuned SLMs. Domain-adjacent SLMs generally\nperformed better than the generic SLM after finetuning, especially on harder\ntasks. Further domain-specific pretraining yielded modest gains on easier tasks\nbut significant improvements on the complex, data-scarce task. The results\nhighlight the critical role of finetuning for SLMs in specialized domains,\nenabling them to surpass zero-shot LLM performance on targeted classification\ntasks. Pretraining on domain-adjacent or domain-specific data provides further\nadvantages, particularly for complex problems or limited finetuning data. While\nLLMs offer strong zero-shot capabilities, their performance on these specific\ntasks did not match that of appropriately finetuned SLMs. In the era of LLMs,\nSLMs remain relevant and effective, offering a potentially superior\nperformance-resource trade-off compared to LLMs.", "published": "2025-04-29 21:50:06", "link": "http://arxiv.org/abs/2504.21191v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Detecting Manipulated Contents Using Knowledge-Grounded Inference", "abstract": "The detection of manipulated content, a prevalent form of fake news, has been\nwidely studied in recent years. While existing solutions have been proven\neffective in fact-checking and analyzing fake news based on historical events,\nthe reliance on either intrinsic knowledge obtained during training or manually\ncurated context hinders them from tackling zero-day manipulated content, which\ncan only be recognized with real-time contextual information. In this work, we\npropose Manicod, a tool designed for detecting zero-day manipulated content.\nManicod first sources contextual information about the input claim from\nmainstream search engines, and subsequently vectorizes the context for the\nlarge language model (LLM) through retrieval-augmented generation (RAG). The\nLLM-based inference can produce a \"truthful\" or \"manipulated\" decision and\noffer a textual explanation for the decision. To validate the effectiveness of\nManicod, we also propose a dataset comprising 4270 pieces of manipulated fake\nnews derived from 2500 recent real-world news headlines. Manicod achieves an\noverall F1 score of 0.856 on this dataset and outperforms existing methods by\nup to 1.9x in F1 score on their benchmarks on fact-checking and claim\nverification.", "published": "2025-04-29 20:33:54", "link": "http://arxiv.org/abs/2504.21165v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "LLM Enhancer: Merged Approach using Vector Embedding for Reducing Large Language Model Hallucinations with External Knowledge", "abstract": "Large Language Models (LLMs), such as ChatGPT, have demonstrated the\ncapability to generate human like, natural responses across a range of tasks,\nincluding task oriented dialogue and question answering. However, their\napplication in real world, critical scenarios is often hindered by a tendency\nto produce inaccurate information and a limited ability to leverage external\nknowledge sources. This paper introduces the LLM ENHANCER system, designed to\nintegrate multiple online sources such as Google, Wikipedia, and DuckDuckGo to\nenhance data accuracy. The LLMs employed within this system are open source.\nThe data acquisition process for the LLM ENHANCER system operates in parallel,\nutilizing custom agent tools to manage the flow of information. Vector\nembeddings are used to identify the most pertinent information, which is\nsubsequently supplied to the LLM for user interaction. The LLM ENHANCER system\nmitigates hallucinations in chat based LLMs while preserving response\nnaturalness and accuracy.", "published": "2025-04-29 19:27:04", "link": "http://arxiv.org/abs/2504.21132v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Beyond One-Size-Fits-All: Inversion Learning for Highly Effective NLG Evaluation Prompts", "abstract": "Evaluating natural language generation (NLG) systems is challenging due to\nthe diversity of valid outputs. While human evaluation is the gold standard, it\nsuffers from inconsistencies, lack of standardisation, and demographic biases,\nlimiting reproducibility. LLM-based evaluation offers a scalable alternative\nbut is highly sensitive to prompt design, where small variations can lead to\nsignificant discrepancies. In this work, we propose an inversion learning\nmethod that learns effective reverse mappings from model outputs back to their\ninput instructions, enabling the automatic generation of highly effective,\nmodel-specific evaluation prompts. Our method requires only a single evaluation\nsample and eliminates the need for time-consuming manual prompt engineering,\nthereby improving both efficiency and robustness. Our work contributes toward a\nnew direction for more robust and efficient LLM-based evaluation.", "published": "2025-04-29 18:56:12", "link": "http://arxiv.org/abs/2504.21117v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Large Language Models for Medicine: A Comprehensive Survey", "abstract": "MLLMs have recently become a focal point in the field of artificial\nintelligence research. Building on the strong capabilities of LLMs, MLLMs are\nadept at addressing complex multi-modal tasks. With the release of GPT-4, MLLMs\nhave gained substantial attention from different domains. Researchers have\nbegun to explore the potential of MLLMs in the medical and healthcare domain.\nIn this paper, we first introduce the background and fundamental concepts\nrelated to LLMs and MLLMs, while emphasizing the working principles of MLLMs.\nSubsequently, we summarize three main directions of application within\nhealthcare: medical reporting, medical diagnosis, and medical treatment. Our\nfindings are based on a comprehensive review of 330 recent papers in this area.\nWe illustrate the remarkable capabilities of MLLMs in these domains by\nproviding specific examples. For data, we present six mainstream modes of data\nalong with their corresponding evaluation benchmarks. At the end of the survey,\nwe discuss the challenges faced by MLLMs in the medical and healthcare domain\nand propose feasible methods to mitigate or overcome these issues.", "published": "2025-04-29 03:07:38", "link": "http://arxiv.org/abs/2504.21051v1", "categories": ["cs.LG", "cs.CL", "cs.MM"], "primary_category": "cs.LG"}
{"title": "T2ID-CAS: Diffusion Model and Class Aware Sampling to Mitigate Class Imbalance in Neck Ultrasound Anatomical Landmark Detection", "abstract": "Neck ultrasound (US) plays a vital role in airway management by providing\nnon-invasive, real-time imaging that enables rapid and precise interventions.\nDeep learning-based anatomical landmark detection in neck US can further\nfacilitate procedural efficiency. However, class imbalance within datasets,\nwhere key structures like tracheal rings and vocal folds are underrepresented,\npresents significant challenges for object detection models. To address this,\nwe propose T2ID-CAS, a hybrid approach that combines a text-to-image latent\ndiffusion model with class-aware sampling to generate high-quality synthetic\nsamples for underrepresented classes. This approach, rarely explored in the\nultrasound domain, improves the representation of minority classes.\nExperimental results using YOLOv9 for anatomical landmark detection in neck US\ndemonstrated that T2ID-CAS achieved a mean Average Precision of 88.2,\nsignificantly surpassing the baseline of 66. This highlights its potential as a\ncomputationally efficient and scalable solution for mitigating class imbalance\nin AI-assisted ultrasound-guided interventions.", "published": "2025-04-29 23:46:21", "link": "http://arxiv.org/abs/2504.21231v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "CachePrune: Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks", "abstract": "Large Language Models (LLMs) are identified as being susceptible to indirect\nprompt injection attack, where the model undesirably deviates from\nuser-provided instructions by executing tasks injected in the prompt context.\nThis vulnerability stems from LLMs' inability to distinguish between data and\ninstructions within a prompt. In this paper, we propose CachePrune that defends\nagainst this attack by identifying and pruning task-triggering neurons from the\nKV cache of the input prompt context. By pruning such neurons, we encourage the\nLLM to treat the text spans of input prompt context as only pure data, instead\nof any indicator of instruction following. These neurons are identified via\nfeature attribution with a loss function induced from an upperbound of the\nDirect Preference Optimization (DPO) objective. We show that such a loss\nfunction enables effective feature attribution with only a few samples. We\nfurther improve on the quality of feature attribution, by exploiting an\nobserved triggering effect in instruction following. Our approach does not\nimpose any formatting on the original prompt or introduce extra test-time LLM\ncalls. Experiments show that CachePrune significantly reduces attack success\nrates without compromising the response quality. Note: This paper aims to\ndefend against indirect prompt injection attacks, with the goal of developing\nmore secure and robust AI systems.", "published": "2025-04-29 23:42:21", "link": "http://arxiv.org/abs/2504.21228v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "MemeBLIP2: A novel lightweight multimodal system to detect harmful memes", "abstract": "Memes often merge visuals with brief text to share humor or opinions, yet\nsome memes contain harmful messages such as hate speech. In this paper, we\nintroduces MemeBLIP2, a light weight multimodal system that detects harmful\nmemes by combining image and text features effectively. We build on previous\nstudies by adding modules that align image and text representations into a\nshared space and fuse them for better classification. Using BLIP-2 as the core\nvision-language model, our system is evaluated on the PrideMM datasets. The\nresults show that MemeBLIP2 can capture subtle cues in both modalities, even in\ncases with ironic or culturally specific content, thereby improving the\ndetection of harmful material.", "published": "2025-04-29 23:41:06", "link": "http://arxiv.org/abs/2504.21226v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Theoretical Foundations for Semantic Cognition in Artificial Intelligence", "abstract": "This monograph presents a modular cognitive architecture for artificial\nintelligence grounded in the formal modeling of belief as structured semantic\nstate. Belief states are defined as dynamic ensembles of linguistic expressions\nembedded within a navigable manifold, where operators enable assimilation,\nabstraction, nullification, memory, and introspection. Drawing from philosophy,\ncognitive science, and neuroscience, we develop a layered framework that\nenables self-regulating epistemic agents capable of reflective, goal-directed\nthought. At the core of this framework is the epistemic vacuum: a class of\nsemantically inert cognitive states that serves as the conceptual origin of\nbelief space. From this foundation, the Null Tower arises as a generative\nstructure recursively built through internal representational capacities. The\ntheoretical constructs are designed to be implementable in both symbolic and\nneural systems, including large language models, hybrid agents, and adaptive\nmemory architectures. This work offers a foundational substrate for\nconstructing agents that reason, remember, and regulate their beliefs in\nstructured, interpretable ways.", "published": "2025-04-29 23:10:07", "link": "http://arxiv.org/abs/2504.21218v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Cost-Effective LLM-based Approach to Identify Wildlife Trafficking in Online Marketplaces", "abstract": "Wildlife trafficking remains a critical global issue, significantly impacting\nbiodiversity, ecological stability, and public health. Despite efforts to\ncombat this illicit trade, the rise of e-commerce platforms has made it easier\nto sell wildlife products, putting new pressure on wild populations of\nendangered and threatened species. The use of these platforms also opens a new\nopportunity: as criminals sell wildlife products online, they leave digital\ntraces of their activity that can provide insights into trafficking activities\nas well as how they can be disrupted. The challenge lies in finding these\ntraces. Online marketplaces publish ads for a plethora of products, and\nidentifying ads for wildlife-related products is like finding a needle in a\nhaystack. Learning classifiers can automate ad identification, but creating\nthem requires costly, time-consuming data labeling that hinders support for\ndiverse ads and research questions. This paper addresses a critical challenge\nin the data science pipeline for wildlife trafficking analytics: generating\nquality labeled data for classifiers that select relevant data. While large\nlanguage models (LLMs) can directly label advertisements, doing so at scale is\nprohibitively expensive. We propose a cost-effective strategy that leverages\nLLMs to generate pseudo labels for a small sample of the data and uses these\nlabels to create specialized classification models. Our novel method\nautomatically gathers diverse and representative samples to be labeled while\nminimizing the labeling costs. Our experimental evaluation shows that our\nclassifiers achieve up to 95% F1 score, outperforming LLMs at a lower cost. We\npresent real use cases that demonstrate the effectiveness of our approach in\nenabling analyses of different aspects of wildlife trafficking.", "published": "2025-04-29 22:34:42", "link": "http://arxiv.org/abs/2504.21211v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FedHERO: A Federated Learning Approach for Node Classification Task on Heterophilic Graphs", "abstract": "Federated Graph Learning (FGL) empowers clients to collaboratively train\nGraph neural networks (GNNs) in a distributed manner while preserving data\nprivacy. However, FGL methods usually require that the graph data owned by all\nclients is homophilic to ensure similar neighbor distribution patterns of\nnodes. Such an assumption ensures that the learned knowledge is consistent\nacross the local models from all clients. Therefore, these local models can be\nproperly aggregated as a global model without undermining the overall\nperformance. Nevertheless, when the neighbor distribution patterns of nodes\nvary across different clients (e.g., when clients hold graphs with different\nlevels of heterophily), their local models may gain different and even conflict\nknowledge from their node-level predictive tasks. Consequently, aggregating\nthese local models usually leads to catastrophic performance deterioration on\nthe global model. To address this challenge, we propose FedHERO, an FGL\nframework designed to harness and share insights from heterophilic graphs\neffectively. At the heart of FedHERO is a dual-channel GNN equipped with a\nstructure learner, engineered to discern the structural knowledge encoded in\nthe local graphs. With this specialized component, FedHERO enables the local\nmodel for each client to identify and learn patterns that are universally\napplicable across graphs with different patterns of node neighbor\ndistributions. FedHERO not only enhances the performance of individual client\nmodels by leveraging both local and shared structural insights but also sets a\nnew precedent in this field to effectively handle graph data with various node\nneighbor distribution patterns. We conduct extensive experiments to validate\nthe superior performance of FedHERO against existing alternatives.", "published": "2025-04-29 22:23:35", "link": "http://arxiv.org/abs/2504.21206v1", "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "cs.LG"}
{"title": "SecRepoBench: Benchmarking LLMs for Secure Code Generation in Real-World Repositories", "abstract": "This paper introduces SecRepoBench, a benchmark to evaluate LLMs on secure\ncode generation in real-world repositories. SecRepoBench has 318 code\ngeneration tasks in 27 C/C++ repositories, covering 15 CWEs. We evaluate 19\nstate-of-the-art LLMs using our benchmark and find that the models struggle\nwith generating correct and secure code. In addition, the performance of LLMs\nto generate self-contained programs as measured by prior benchmarks do not\ntranslate to comparative performance at generating secure and correct code at\nthe repository level in SecRepoBench. We show that the state-of-the-art prompt\nengineering techniques become less effective when applied to the repository\nlevel secure code generation problem. We conduct extensive experiments,\nincluding an agentic technique to generate secure code, to demonstrate that our\nbenchmark is currently the most difficult secure coding benchmark, compared to\nprevious state-of-the-art benchmarks. Finally, our comprehensive analysis\nprovides insights into potential directions for enhancing the ability of LLMs\nto generate correct and secure code in real-world repositories.", "published": "2025-04-29 22:22:44", "link": "http://arxiv.org/abs/2504.21205v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Turning Up the Heat: Assessing 2-m Temperature Forecast Errors in AI Weather Prediction Models During Heat Waves", "abstract": "Extreme heat is the deadliest weather-related hazard in the United States.\nFurthermore, it is increasing in intensity, frequency, and duration, making\nskillful forecasts vital to protecting life and property. Traditional numerical\nweather prediction (NWP) models struggle with extreme heat for medium-range and\nsubseasonal-to-seasonal (S2S) timescales. Meanwhile, artificial\nintelligence-based weather prediction (AIWP) models are progressing rapidly.\nHowever, it is largely unknown how well AIWP models forecast extremes,\nespecially for medium-range and S2S timescales. This study investigates 2-m\ntemperature forecasts for 60 heat waves across the four boreal seasons and over\nfour CONUS regions at lead times up to 20 days, using two AIWP models (Google\nGraphCast and Pangu-Weather) and one traditional NWP model (NOAA United\nForecast System Global Ensemble Forecast System (UFS GEFS)). First, case study\nanalyses show that both AIWP models and the UFS GEFS exhibit consistent cold\nbiases on regional scales in the 5-10 days of lead time before heat wave onset.\nGraphCast is the more skillful AIWP model, outperforming UFS GEFS and\nPangu-Weather in most locations. Next, the two AIWP models are isolated and\nanalyzed across all heat waves and seasons, with events split among the model's\ntesting (2018-2023) and training (1979-2017) periods. There are cold biases\nbefore and during the heat waves in both models and all seasons, except\nPangu-Weather in winter, which exhibits a mean warm bias before heat wave\nonset. Overall, results offer encouragement that AIWP models may be useful for\nmedium-range and S2S predictability of extreme heat.", "published": "2025-04-29 22:02:32", "link": "http://arxiv.org/abs/2504.21195v1", "categories": ["physics.ao-ph", "cs.AI", "cs.LG"], "primary_category": "physics.ao-ph"}
{"title": "Geolocating Earth Imagery from ISS: Integrating Machine Learning with Astronaut Photography for Enhanced Geographic Mapping", "abstract": "This paper presents a novel approach to geolocating images captured from the\nInternational Space Station (ISS) using advanced machine learning algorithms.\nDespite having precise ISS coordinates, the specific Earth locations depicted\nin astronaut-taken photographs often remain unidentified. Our research\naddresses this gap by employing three distinct image processing pipelines: a\nNeural Network based approach, a SIFT based method, and GPT-4 model. Each\npipeline is tailored to process high-resolution ISS imagery, identifying both\nnatural and man-made geographical features. Through extensive evaluation on a\ndiverse dataset of over 140 ISS images, our methods demonstrate significant\npromise in automated geolocation with varied levels of success. The NN approach\nshowed a high success rate in accurately matching geographical features, while\nthe SIFT pipeline excelled in processing zoomed-in images. GPT-4 model provided\nenriched geographical descriptions alongside location predictions. This\nresearch contributes to the fields of remote sensing and Earth observation by\nenhancing the accuracy and efficiency of geolocating space-based imagery,\nthereby aiding environmental monitoring and global mapping efforts.", "published": "2025-04-29 22:00:02", "link": "http://arxiv.org/abs/2504.21194v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "TT-LoRA MoE: Unifying Parameter-Efficient Fine-Tuning and Sparse Mixture-of-Experts", "abstract": "We propose Tensor-Trained Low-Rank Adaptation Mixture of Experts (TT-LoRA\nMoE), a novel computational framework integrating Parameter-Efficient\nFine-Tuning (PEFT) with sparse MoE routing to address scalability challenges in\nlarge model deployments. Unlike traditional MoE approaches, which face\nsubstantial computational overhead as expert counts grow, TT-LoRA MoE\ndecomposes training into two distinct, optimized stages. First, we\nindependently train lightweight, tensorized low-rank adapters (TT-LoRA\nexperts), each specialized for specific tasks. Subsequently, these expert\nadapters remain frozen, eliminating inter-task interference and catastrophic\nforgetting in multi-task setting. A sparse MoE router, trained separately,\ndynamically leverages base model representations to select exactly one\nspecialized adapter per input at inference time, automating expert selection\nwithout explicit task specification. Comprehensive experiments confirm our\narchitecture retains the memory efficiency of low-rank adapters, seamlessly\nscales to large expert pools, and achieves robust task-level optimization. This\nstructured decoupling significantly enhances computational efficiency and\nflexibility: uses only 2% of LoRA, 0.3% of Adapters and 0.03% of AdapterFusion\nparameters and outperforms AdapterFusion by 4 value in multi-tasking, enabling\npractical and scalable multi-task inference deployments.", "published": "2025-04-29 21:46:43", "link": "http://arxiv.org/abs/2504.21190v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Artificial Intelligence for Personalized Prediction of Alzheimer's Disease Progression: A Survey of Methods, Data Challenges, and Future Directions", "abstract": "Alzheimer's Disease (AD) is marked by significant inter-individual\nvariability in its progression, complicating accurate prognosis and\npersonalized care planning. This heterogeneity underscores the critical need\nfor predictive models capable of forecasting patient-specific disease\ntrajectories. Artificial Intelligence (AI) offers powerful tools to address\nthis challenge by analyzing complex, multi-modal, and longitudinal patient\ndata. This paper provides a comprehensive survey of AI methodologies applied to\npersonalized AD progression prediction. We review key approaches including\nstate-space models for capturing temporal dynamics, deep learning techniques\nlike Recurrent Neural Networks for sequence modeling, Graph Neural Networks\n(GNNs) for leveraging network structures, and the emerging concept of AI-driven\ndigital twins for individualized simulation. Recognizing that data limitations\noften impede progress, we examine common challenges such as high\ndimensionality, missing data, and dataset imbalance. We further discuss\nAI-driven mitigation strategies, with a specific focus on synthetic data\ngeneration using Variational Autoencoders (VAEs) and Generative Adversarial\nNetworks (GANs) to augment and balance datasets. The survey synthesizes the\nstrengths and limitations of current approaches, emphasizing the trend towards\nmultimodal integration and the persistent need for model interpretability and\ngeneralizability. Finally, we identify critical open challenges, including\nrobust external validation, clinical integration, and ethical considerations,\nand outline promising future research directions such as hybrid models, causal\ninference, and federated learning. This review aims to consolidate current\nknowledge and guide future efforts in developing clinically relevant AI tools\nfor personalized AD prognostication.", "published": "2025-04-29 21:45:28", "link": "http://arxiv.org/abs/2504.21189v1", "categories": ["cs.LG", "cs.AI", "cs.ET"], "primary_category": "cs.LG"}
{"title": "Light Weight CNN for classification of Brain Tumors from MRI Images", "abstract": "This study presents a convolutional neural network (CNN)-based approach for\nthe multi-class classification of brain tumors using magnetic resonance imaging\n(MRI) scans. We utilize a publicly available dataset containing MRI images\ncategorized into four classes: glioma, meningioma, pituitary tumor, and no\ntumor. Our primary objective is to build a light weight deep learning model\nthat can automatically classify brain tumor types with high accuracy. To\nachieve this goal, we incorporate image preprocessing steps, including\nnormalization, data augmentation, and a cropping technique designed to reduce\nbackground noise and emphasize relevant regions. The CNN architecture is\noptimized through hyperparameter tuning using Keras Tuner, enabling systematic\nexploration of network parameters. To ensure reliable evaluation, we apply\n5-fold cross-validation, where each hyperparameter configuration is evaluated\nacross multiple data splits to mitigate overfitting. Experimental results\ndemonstrate that the proposed model achieves a classification accuracy of\n98.78%, indicating its potential as a diagnostic aid in clinical settings. The\nproposed method offers a low-complexity yet effective solution for assisting in\nearly brain tumor diagnosis.", "published": "2025-04-29 21:45:11", "link": "http://arxiv.org/abs/2504.21188v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "AffectEval: A Modular and Customizable Framework for Affective Computing", "abstract": "The field of affective computing focuses on recognizing, interpreting, and\nresponding to human emotions, and has broad applications across education,\nchild development, and human health and wellness. However, developing affective\ncomputing pipelines remains labor-intensive due to the lack of software\nframeworks that support multimodal, multi-domain emotion recognition\napplications. This often results in redundant effort when building pipelines\nfor different applications. While recent frameworks attempt to address these\nchallenges, they remain limited in reducing manual effort and ensuring\ncross-domain generalizability. We introduce AffectEval, a modular and\ncustomizable framework to facilitate the development of affective computing\npipelines while reducing the manual effort and duplicate work involved in\ndeveloping such pipelines. We validate AffectEval by replicating prior\naffective computing experiments, and we demonstrate that our framework reduces\nprogramming effort by up to 90%, as measured by the reduction in raw lines of\ncode.", "published": "2025-04-29 21:40:49", "link": "http://arxiv.org/abs/2504.21184v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Dance Style Recognition Using Laban Movement Analysis", "abstract": "The growing interest in automated movement analysis has presented new\nchallenges in recognition of complex human activities including dance. This\nstudy focuses on dance style recognition using features extracted using Laban\nMovement Analysis. Previous studies for dance style recognition often focus on\ncross-frame movement analysis, which limits the ability to capture temporal\ncontext and dynamic transitions between movements. This gap highlights the need\nfor a method that can add temporal context to LMA features. For this, we\nintroduce a novel pipeline which combines 3D pose estimation, 3D human mesh\nreconstruction, and floor aware body modeling to effectively extract LMA\nfeatures. To address the temporal limitation, we propose a sliding window\napproach that captures movement evolution across time in features. These\nfeatures are then used to train various machine learning methods for\nclassification, and their explainability explainable AI methods to evaluate the\ncontribution of each feature to classification performance. Our proposed method\nachieves a highest classification accuracy of 99.18\\% which shows that the\naddition of temporal context significantly improves dance style recognition\nperformance.", "published": "2025-04-29 20:35:01", "link": "http://arxiv.org/abs/2504.21166v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Evaluation and Verification of Physics-Informed Neural Models of the Grad-Shafranov Equation", "abstract": "Our contributions are motivated by fusion reactors that rely on maintaining\nmagnetohydrodynamic (MHD) equilibrium, where the balance between plasma\npressure and confining magnetic fields is required for stable operation. In\naxisymmetric tokamak reactors in particular, and under the assumption of\ntoroidal symmetry, this equilibrium can be mathematically modelled using the\nGrad-Shafranov Equation (GSE). Recent works have demonstrated the potential of\nusing Physics-Informed Neural Networks (PINNs) to model the GSE. Existing\nstudies did not examine realistic scenarios in which a single network\ngeneralizes to a variety of boundary conditions. Addressing that limitation, we\nevaluate a PINN architecture that incorporates boundary points as network\ninputs. Additionally, we compare PINN model accuracy and inference speeds with\na Fourier Neural Operator (FNO) model. Finding the PINN model to be the most\nperformant, and accurate in our setting, we use the network verification tool\nMarabou to perform a range of verification tasks. Although we find some\ndiscrepancies between evaluations of the networks natively in PyTorch, compared\nto via Marabou, we are able to demonstrate useful and practical verification\nworkflows. Our study is the first investigation of verification of such\nnetworks.", "published": "2025-04-29 20:17:43", "link": "http://arxiv.org/abs/2504.21155v1", "categories": ["physics.plasm-ph", "cs.AI", "cs.NE"], "primary_category": "physics.plasm-ph"}
{"title": "Emotion Recognition in Contemporary Dance Performances Using Laban Movement Analysis", "abstract": "This paper presents a novel framework for emotion recognition in contemporary\ndance by improving existing Laban Movement Analysis (LMA) feature descriptors\nand introducing robust, novel descriptors that capture both quantitative and\nqualitative aspects of the movement. Our approach extracts expressive\ncharacteristics from 3D keypoints data of professional dancers performing\ncontemporary dance under various emotional states, and trains multiple\nclassifiers, including Random Forests and Support Vector Machines.\nAdditionally, we provide in-depth explanation of features and their impact on\nmodel predictions using explainable machine learning methods. Overall, our\nstudy improves emotion recognition in contemporary dance and offers promising\napplications in performance analysis, dance training, and human--computer\ninteraction, with a highest accuracy of 96.85\\%.", "published": "2025-04-29 20:17:27", "link": "http://arxiv.org/abs/2504.21154v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SMOGAN: Synthetic Minority Oversampling with GAN Refinement for Imbalanced Regression", "abstract": "Imbalanced regression refers to prediction tasks where the target variable is\nskewed. This skewness hinders machine learning models, especially neural\nnetworks, which concentrate on dense regions and therefore perform poorly on\nunderrepresented (minority) samples. Despite the importance of this problem,\nonly a few methods have been proposed for imbalanced regression. Many of the\navailable solutions for imbalanced regression adapt techniques from the class\nimbalance domain, such as linear interpolation and the addition of Gaussian\nnoise, to create synthetic data in sparse regions. However, in many cases, the\nunderlying distribution of the data is complex and non-linear. Consequently,\nthese approaches generate synthetic samples that do not accurately represent\nthe true feature-target relationship. To overcome these limitations, we propose\nSMOGAN, a two-step oversampling framework for imbalanced regression. In Stage\n1, an existing oversampler generates initial synthetic samples in sparse target\nregions. In Stage 2, we introduce DistGAN, a distribution-aware GAN that serves\nas SMOGAN's filtering layer and refines these samples via adversarial loss\naugmented with a Maximum Mean Discrepancy objective, aligning them with the\ntrue joint feature-target distribution. Extensive experiments on 23 imbalanced\ndatasets show that SMOGAN consistently outperforms the default oversampling\nmethod without the DistGAN filtering layer.", "published": "2025-04-29 20:15:25", "link": "http://arxiv.org/abs/2504.21152v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Formalism for Optimal Search with Dynamic Heuristics", "abstract": "While most heuristics studied in heuristic search depend only on the state,\nsome accumulate information during search and thus also depend on the search\nhistory. Various existing approaches use such dynamic heuristics in\n$\\mathrm{A}^*$-like algorithms and appeal to classic results for $\\mathrm{A}^*$\nto show optimality. However, doing so ignores the complexities of searching\nwith a mutable heuristic. In this paper we formalize the idea of dynamic\nheuristics and use them in a generic algorithm framework. We study a particular\ninstantiation that models $\\mathrm{A}^*$ with dynamic heuristics and show\ngeneral optimality results. Finally we show how existing approaches from\nclassical planning can be viewed as special cases of this instantiation, making\nit possible to directly apply our optimality results.", "published": "2025-04-29 19:25:31", "link": "http://arxiv.org/abs/2504.21131v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Survey on Parameter-Efficient Fine-Tuning for Foundation Models in Federated Learning", "abstract": "Foundation models have revolutionized artificial intelligence by providing\nrobust, versatile architectures pre-trained on large-scale datasets. However,\nadapting these massive models to specific downstream tasks requires\nfine-tuning, which can be prohibitively expensive in computational resources.\nParameter-Efficient Fine-Tuning (PEFT) methods address this challenge by\nselectively updating only a small subset of parameters. Meanwhile, Federated\nLearning (FL) enables collaborative model training across distributed clients\nwithout sharing raw data, making it ideal for privacy-sensitive applications.\nThis survey provides a comprehensive review of the integration of PEFT\ntechniques within federated learning environments. We systematically categorize\nexisting approaches into three main groups: Additive PEFT (which introduces new\ntrainable parameters), Selective PEFT (which fine-tunes only subsets of\nexisting parameters), and Reparameterized PEFT (which transforms model\narchitectures to enable efficient updates). For each category, we analyze how\nthese methods address the unique challenges of federated settings, including\ndata heterogeneity, communication efficiency, computational constraints, and\nprivacy concerns. We further organize the literature based on application\ndomains, covering both natural language processing and computer vision tasks.\nFinally, we discuss promising research directions, including scaling to larger\nfoundation models, theoretical analysis of federated PEFT methods, and\nsustainable approaches for resource-constrained environments.", "published": "2025-04-29 18:18:39", "link": "http://arxiv.org/abs/2504.21099v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Gradient Attention Map Based Verification of Deep Convolutional Neural Networks with Application to X-ray Image Datasets", "abstract": "Deep learning models have great potential in medical imaging, including\northodontics and skeletal maturity assessment. However, applying a model to\ndata different from its training set can lead to unreliable predictions that\nmay impact patient care. To address this, we propose a comprehensive\nverification framework that evaluates model suitability through multiple\ncomplementary strategies. First, we introduce a Gradient Attention Map\n(GAM)-based approach that analyzes attention patterns using Grad-CAM and\ncompares them via similarity metrics such as IoU, Dice Similarity, SSIM, Cosine\nSimilarity, Pearson Correlation, KL Divergence, and Wasserstein Distance.\nSecond, we extend verification to early convolutional feature maps, capturing\nstructural mis-alignments missed by attention alone. Finally, we incorporate an\nadditional garbage class into the classification model to explicitly reject\nout-of-distribution inputs. Experimental results demonstrate that these\ncombined methods effectively identify unsuitable models and inputs, promoting\nsafer and more reliable deployment of deep learning in medical imaging.", "published": "2025-04-29 23:41:37", "link": "http://arxiv.org/abs/2504.21227v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Legilimens: Performant Video Analytics on the System-on-Chip Edge", "abstract": "Continually retraining models has emerged as a primary technique to enable\nhigh-accuracy video analytics on edge devices. Yet, existing systems employ\nsuch adaptation by relying on the spare compute resources that traditional\n(memory-constrained) edge servers afford. In contrast, mobile edge devices such\nas drones and dashcams offer a fundamentally different resource profile:\nweak(er) compute with abundant unified memory pools. We present Legilimens, a\ncontinuous learning system for the mobile edge's System-on-Chip GPUs. Our\ndriving insight is that visually distinct scenes that require retraining\nexhibit substantial overlap in model embeddings; if captured into a base model\non device memory, specializing to each new scene can become lightweight,\nrequiring very few samples. To practically realize this approach, Legilimens\npresents new, compute-efficient techniques to (1) select high-utility data\nsamples for retraining specialized models, (2) update the base model without\ncomplete retraining, and (3) time-share compute resources between retraining\nand live inference for maximal accuracy. Across diverse workloads, Legilimens\nlowers retraining costs by 2.8-10x compared to existing systems, resulting in\n18-45% higher accuracies.", "published": "2025-04-29 19:45:33", "link": "http://arxiv.org/abs/2504.21136v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "GauSS-MI: Gaussian Splatting Shannon Mutual Information for Active 3D Reconstruction", "abstract": "This research tackles the challenge of real-time active view selection and\nuncertainty quantification on visual quality for active 3D reconstruction.\nVisual quality is a critical aspect of 3D reconstruction. Recent advancements\nsuch as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have\nnotably enhanced the image rendering quality of reconstruction models.\nNonetheless, the efficient and effective acquisition of input images for\nreconstruction-specifically, the selection of the most informative\nviewpoint-remains an open challenge, which is crucial for active\nreconstruction. Existing studies have primarily focused on evaluating geometric\ncompleteness and exploring unobserved or unknown regions, without direct\nevaluation of the visual uncertainty within the reconstruction model. To\naddress this gap, this paper introduces a probabilistic model that quantifies\nvisual uncertainty for each Gaussian. Leveraging Shannon Mutual Information, we\nformulate a criterion, Gaussian Splatting Shannon Mutual Information\n(GauSS-MI), for real-time assessment of visual mutual information from novel\nviewpoints, facilitating the selection of next best view. GauSS-MI is\nimplemented within an active reconstruction system integrated with a view and\nmotion planner. Extensive experiments across various simulated and real-world\nscenes showcase the superior visual quality and reconstruction efficiency\nperformance of the proposed system.", "published": "2025-04-29 13:47:14", "link": "http://arxiv.org/abs/2504.21067v1", "categories": ["cs.GR", "cs.CV", "cs.RO"], "primary_category": "cs.GR"}
{"title": "Induced Minors and Region Intersection Graphs", "abstract": "We show that for any positive integers $g$ and $t$, there is a\n$K_{6}^{(1)}$-induced-minor-free graph of girth at least $g$ that is not a\nregion intersection graph over the class of $K_t$-minor-free graphs. This\nanswers in a strong form the recently raised question of whether for every\ngraph $H$ there is a graph $H'$ such that $H$-induced-minor-free graphs are\nregion intersection graphs over $H'$-minor-free graphs.", "published": "2025-04-29 18:55:03", "link": "http://arxiv.org/abs/2504.21115v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Federated One-Shot Learning with Data Privacy and Objective-Hiding", "abstract": "Privacy in federated learning is crucial, encompassing two key aspects:\nsafeguarding the privacy of clients' data and maintaining the privacy of the\nfederator's objective from the clients. While the first aspect has been\nextensively studied, the second has received much less attention.\n  We present a novel approach that addresses both concerns simultaneously,\ndrawing inspiration from techniques in knowledge distillation and private\ninformation retrieval to provide strong information-theoretic privacy\nguarantees.\n  Traditional private function computation methods could be used here; however,\nthey are typically limited to linear or polynomial functions. To overcome these\nconstraints, our approach unfolds in three stages. In stage 0, clients perform\nthe necessary computations locally. In stage 1, these results are shared among\nthe clients, and in stage 2, the federator retrieves its desired objective\nwithout compromising the privacy of the clients' data. The crux of the method\nis a carefully designed protocol that combines secret-sharing-based multi-party\ncomputation and a graph-based private information retrieval scheme. We show\nthat our method outperforms existing tools from the literature when properly\nadapted to this setting.", "published": "2025-04-29 21:25:34", "link": "http://arxiv.org/abs/2504.21182v1", "categories": ["cs.CR", "cs.DC", "cs.IT", "cs.LG", "math.IT", "stat.ML"], "primary_category": "cs.CR"}
{"title": "Differentially Private Secure Multiplication with Erasures and Adversaries", "abstract": "We consider a private distributed multiplication problem involving N\ncomputation nodes and T colluding nodes. Shamir's secret sharing algorithm\nprovides perfect information-theoretic privacy, while requiring an honest\nmajority, i.e., N \\ge 2T + 1. Recent work has investigated approximate\ncomputation and characterized privacy-accuracy trade-offs for the honest\nminority setting N \\le 2T for real-valued data, quantifying privacy leakage via\nthe differential privacy (DP) framework and accuracy via the mean squared\nerror. However, it does not incorporate the error correction capabilities of\nShamir's secret-sharing algorithm. This paper develops a new polynomial-based\ncoding scheme for secure multiplication with an honest minority, and\ncharacterizes its achievable privacy-utility tradeoff, showing that the\ntradeoff can approach the converse bound as closely as desired. Unlike previous\nschemes, the proposed scheme inherits the capability of the Reed-Solomon (RS)\ncode to tolerate erasures and adversaries. We utilize a modified\nBerlekamp-Welch algorithm over the real number field to detect adversarial\nnodes.", "published": "2025-04-29 20:59:25", "link": "http://arxiv.org/abs/2504.21178v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Generalised Label-free Artefact Cleaning for Real-time Medical Pulsatile Time Series", "abstract": "Artefacts compromise clinical decision-making in the use of medical time\nseries. Pulsatile waveforms offer probabilities for accurate artefact\ndetection, yet most approaches rely on supervised manners and overlook\npatient-level distribution shifts. To address these issues, we introduce a\ngeneralised label-free framework, GenClean, for real-time artefact cleaning and\nleverage an in-house dataset of 180,000 ten-second arterial blood pressure\n(ABP) samples for training. We first investigate patient-level generalisation,\ndemonstrating robust performances under both intra- and inter-patient\ndistribution shifts. We further validate its effectiveness through challenging\ncross-disease cohort experiments on the MIMIC-III database. Additionally, we\nextend our method to photoplethysmography (PPG), highlighting its applicability\nto diverse medical pulsatile signals. Finally, its integration into ICM+, a\nclinical research monitoring software, confirms the real-time feasibility of\nour framework, emphasising its practical utility in continuous physiological\nmonitoring. This work provides a foundational step toward precision medicine in\nimproving the reliability of high-resolution medical time series analysis", "published": "2025-04-29 22:28:06", "link": "http://arxiv.org/abs/2504.21209v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Generate-then-Verify: Reconstructing Data from Limited Published Statistics", "abstract": "We study the problem of reconstructing tabular data from aggregate\nstatistics, in which the attacker aims to identify interesting claims about the\nsensitive data that can be verified with 100% certainty given the aggregates.\nSuccessful attempts in prior work have conducted studies in settings where the\nset of published statistics is rich enough that entire datasets can be\nreconstructed with certainty. In our work, we instead focus on the regime where\nmany possible datasets match the published statistics, making it impossible to\nreconstruct the entire private dataset perfectly (i.e., when approaches in\nprior work fail). We propose the problem of partial data reconstruction, in\nwhich the goal of the adversary is to instead output a $\\textit{subset}$ of\nrows and/or columns that are $\\textit{guaranteed to be correct}$. We introduce\na novel integer programming approach that first $\\textbf{generates}$ a set of\nclaims and then $\\textbf{verifies}$ whether each claim holds for all possible\ndatasets consistent with the published aggregates. We evaluate our approach on\nthe housing-level microdata from the U.S. Decennial Census release,\ndemonstrating that privacy violations can still persist even when information\npublished about such data is relatively sparse.", "published": "2025-04-29 22:06:04", "link": "http://arxiv.org/abs/2504.21199v1", "categories": ["stat.ML", "cs.CR", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Graph Synthetic Out-of-Distribution Exposure with Large Language Models", "abstract": "Out-of-distribution (OOD) detection in graphs is critical for ensuring model\nrobustness in open-world and safety-sensitive applications. Existing approaches\nto graph OOD detection typically involve training an in-distribution (ID)\nclassifier using only ID data, followed by the application of post-hoc OOD\nscoring techniques. Although OOD exposure - introducing auxiliary OOD samples\nduring training - has proven to be an effective strategy for enhancing\ndetection performance, current methods in the graph domain generally assume\naccess to a set of real OOD nodes. This assumption, however, is often\nimpractical due to the difficulty and cost of acquiring representative OOD\nsamples. In this paper, we introduce GOE-LLM, a novel framework that leverages\nLarge Language Models (LLMs) for OOD exposure in graph OOD detection without\nrequiring real OOD nodes. GOE-LLM introduces two pipelines: (1) identifying\npseudo-OOD nodes from the initially unlabeled graph using zero-shot LLM\nannotations, and (2) generating semantically informative synthetic OOD nodes\nvia LLM-prompted text generation. These pseudo-OOD nodes are then used to\nregularize the training of the ID classifier for improved OOD awareness. We\nevaluate our approach across multiple benchmark datasets, showing that GOE-LLM\nsignificantly outperforms state-of-the-art graph OOD detection methods that do\nnot use OOD exposure and achieves comparable performance to those relying on\nreal OOD data.", "published": "2025-04-29 22:04:30", "link": "http://arxiv.org/abs/2504.21198v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "LIFT: LLM-Based Pragma Insertion for HLS via GNN Supervised Fine-Tuning", "abstract": "FPGAs are increasingly adopted in datacenter environments for their\nreconfigurability and energy efficiency. High-Level Synthesis (HLS) tools have\neased FPGA programming by raising the abstraction level from RTL to untimed\nC/C++, yet attaining high performance still demands expert knowledge and\niterative manual insertion of optimization pragmas to modify the\nmicroarchitecture. To address this challenge, we propose LIFT, a large language\nmodel (LLM)-based coding assistant for HLS that automatically generates\nperformance-critical pragmas given a C/C++ design. We fine-tune the LLM by\ntightly integrating and supervising the training process with a graph neural\nnetwork (GNN), combining the sequential modeling capabilities of LLMs with the\nstructural and semantic understanding of GNNs necessary for reasoning over code\nand its control/data dependencies. On average, LIFT produces designs that\nimprove performance by 3.52x and 2.16x than prior state-of the art AutoDSE and\nHARP respectively, and 66x than GPT-4o.", "published": "2025-04-29 21:42:59", "link": "http://arxiv.org/abs/2504.21187v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "GLIP-OOD: Zero-Shot Graph OOD Detection with Foundation Model", "abstract": "Out-of-distribution (OOD) detection is critical for ensuring the safety and\nreliability of machine learning systems, particularly in dynamic and open-world\nenvironments. In the vision and text domains, zero-shot OOD detection - which\nrequires no training on in-distribution (ID) data - has made significant\nprogress through the use of large-scale pretrained models such as\nvision-language models (VLMs) and large language models (LLMs). However,\nzero-shot OOD detection in graph-structured data remains largely unexplored,\nprimarily due to the challenges posed by complex relational structures and the\nabsence of powerful, large-scale pretrained models for graphs. In this work, we\ntake the first step toward enabling zero-shot graph OOD detection by leveraging\na graph foundation model (GFM). We show that, when provided only with class\nlabel names, the GFM can perform OOD detection without any node-level\nsupervision - outperforming existing supervised methods across multiple\ndatasets. To address the more practical setting where OOD label names are\nunavailable, we introduce GLIP-OOD, a novel framework that employs LLMs to\ngenerate semantically informative pseudo-OOD labels from unlabeled data. These\nlabels enable the GFM to capture nuanced semantic boundaries between ID and OOD\nclasses and perform fine-grained OOD detection - without requiring any labeled\nnodes. Our approach is the first to enable node-level graph OOD detection in a\nfully zero-shot setting, and achieves state-of-the-art performance on four\nbenchmark text-attributed graph datasets.", "published": "2025-04-29 21:42:54", "link": "http://arxiv.org/abs/2504.21186v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Efficient LLMs with AMP: Attention Heads and MLP Pruning", "abstract": "Deep learning drives a new wave in computing systems and triggers the\nautomation of increasingly complex problems. In particular, Large Language\nModels (LLMs) have significantly advanced cognitive tasks, often matching or\neven surpassing human-level performance. However, their extensive parameters\nresult in high computational costs and slow inference, posing challenges for\ndeployment in resource-limited settings. Among the strategies to overcome the\naforementioned challenges, pruning emerges as a successful mechanism since it\nreduces model size while maintaining predictive ability. In this paper, we\nintroduce AMP: Attention Heads and MLP Pruning, a novel structured pruning\nmethod that efficiently compresses LLMs by removing less critical structures\nwithin Multi-Head Attention (MHA) and Multilayer Perceptron (MLP). By\nprojecting the input data onto weights, AMP assesses structural importance and\novercomes the limitations of existing techniques, which often fall short in\nflexibility or efficiency. In particular, AMP surpasses the current\nstate-of-the-art on commonsense reasoning tasks by up to 1.49 percentage\npoints, achieving a 30% pruning ratio with minimal impact on zero-shot task\nperformance. Moreover, AMP also improves inference speeds, making it\nwell-suited for deployment in resource-constrained environments. We confirm the\nflexibility of AMP on different families of LLMs, including LLaMA and Phi.", "published": "2025-04-29 20:50:08", "link": "http://arxiv.org/abs/2504.21174v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "QAOA Parameter Transferability for Maximum Independent Set using Graph Attention Networks", "abstract": "The quantum approximate optimization algorithm (QAOA) is one of the promising\nvariational approaches of quantum computing to solve combinatorial optimization\nproblems. In QAOA, variational parameters need to be optimized by solving a\nseries of nonlinear, nonconvex optimization programs. In this work, we propose\na QAOA parameter transfer scheme using Graph Attention Networks (GAT) to solve\nMaximum Independent Set (MIS) problems. We prepare optimized parameters for\ngraphs of 12 and 14 vertices and use GATs to transfer their parameters to\nlarger graphs. Additionally, we design a hybrid distributed resource-aware\nalgorithm for MIS (HyDRA-MIS), which decomposes large problems into smaller\nones that can fit onto noisy intermediate-scale quantum (NISQ) computers. We\nintegrate our GAT-based parameter transfer approach to HyDRA-MIS and\ndemonstrate competitive results compared to KaMIS, a state-of-the-art classical\nMIS solver, on graphs with several thousands vertices.", "published": "2025-04-29 19:41:05", "link": "http://arxiv.org/abs/2504.21135v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Erased but Not Forgotten: How Backdoors Compromise Concept Erasure", "abstract": "The expansion of large-scale text-to-image diffusion models has raised\ngrowing concerns about their potential to generate undesirable or harmful\ncontent, ranging from fabricated depictions of public figures to sexually\nexplicit images. To mitigate these risks, prior work has devised machine\nunlearning techniques that attempt to erase unwanted concepts through\nfine-tuning. However, in this paper, we introduce a new threat model, Toxic\nErasure (ToxE), and demonstrate how recent unlearning algorithms, including\nthose explicitly designed for robustness, can be circumvented through targeted\nbackdoor attacks. The threat is realized by establishing a link between a\ntrigger and the undesired content. Subsequent unlearning attempts fail to erase\nthis link, allowing adversaries to produce harmful content. We instantiate ToxE\nvia two established backdoor attacks: one targeting the text encoder and\nanother manipulating the cross-attention layers. Further, we introduce Deep\nIntervention Score-based Attack (DISA), a novel, deeper backdoor attack that\noptimizes the entire U-Net using a score-based objective, improving the\nattack's persistence across different erasure methods. We evaluate five recent\nconcept erasure methods against our threat model. For celebrity identity\nerasure, our deep attack circumvents erasure with up to 82% success, averaging\n57% across all erasure methods. For explicit content erasure, ToxE attacks can\nelicit up to 9 times more exposed body parts, with DISA yielding an average\nincrease by a factor of 2.9. These results highlight a critical security gap in\ncurrent unlearning strategies.", "published": "2025-04-29 16:13:06", "link": "http://arxiv.org/abs/2504.21072v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Learning Large-Scale Competitive Team Behaviors with Mean-Field Interactions", "abstract": "State-of-the-art multi-agent reinforcement learning (MARL) algorithms such as\nMADDPG and MAAC fail to scale in situations where the number of agents becomes\nlarge. Mean-field theory has shown encouraging results in modeling macroscopic\nagent behavior for teams with a large number of agents through a continuum\napproximation of the agent population and its interaction with the environment.\nIn this work, we extend proximal policy optimization (PPO) to the mean-field\ndomain by introducing the Mean-Field Multi-Agent Proximal Policy Optimization\n(MF-MAPPO), a novel algorithm that utilizes the effectiveness of the\nfinite-population mean-field approximation in the context of zero-sum\ncompetitive multi-agent games between two teams. The proposed algorithm can be\neasily scaled to hundreds and thousands of agents in each team as shown through\nnumerical experiments. In particular, the algorithm is applied to realistic\napplications such as large-scale offense-defense battlefield scenarios.", "published": "2025-04-29 20:31:59", "link": "http://arxiv.org/abs/2504.21164v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "NavEX: A Multi-Agent Coverage in Non-Convex and Uneven Environments via Exemplar-Clustering", "abstract": "This paper addresses multi-agent deployment in non-convex and uneven\nenvironments. To overcome the limitations of traditional approaches, we\nintroduce Navigable Exemplar-Based Dispatch Coverage (NavEX), a novel dispatch\ncoverage framework that combines exemplar-clustering with obstacle-aware and\ntraversability-aware shortest distances, offering a deployment framework based\non submodular optimization. NavEX provides a unified approach to solve two\ncritical coverage tasks: (a) fair-access deployment, aiming to provide\nequitable service by minimizing agent-target distances, and (b) hotspot\ndeployment, prioritizing high-density target regions. A key feature of NavEX is\nthe use of exemplar-clustering for the coverage utility measure, which provides\nthe flexibility to employ non-Euclidean distance metrics that do not\nnecessarily conform to the triangle inequality. This allows NavEX to\nincorporate visibility graphs for shortest-path computation in environments\nwith planar obstacles, and traversability-aware RRT* for complex, rugged\nterrains. By leveraging submodular optimization, the NavEX framework enables\nefficient, near-optimal solutions with provable performance guarantees for\nmulti-agent deployment in realistic and complex settings, as demonstrated by\nour simulations.", "published": "2025-04-29 18:50:49", "link": "http://arxiv.org/abs/2504.21113v1", "categories": ["cs.MA", "cs.RO"], "primary_category": "cs.MA"}
{"title": "Multi-Agent Reinforcement Learning for Resources Allocation Optimization: A Survey", "abstract": "Multi-Agent Reinforcement Learning (MARL) has become a powerful framework for\nnumerous real-world applications, modeling distributed decision-making and\nlearning from interactions with complex environments. Resource Allocation\nOptimization (RAO) benefits significantly from MARL's ability to tackle dynamic\nand decentralized contexts. MARL-based approaches are increasingly applied to\nRAO challenges across sectors playing pivotal roles to Industry 4.0\ndevelopments. This survey provides a comprehensive review of recent MARL\nalgorithms for RAO, encompassing core concepts, classifications, and a\nstructured taxonomy. By outlining the current research landscape and\nidentifying primary challenges and future directions, this survey aims to\nsupport researchers and practitioners in leveraging MARL's potential to advance\nresource allocation solutions.", "published": "2025-04-29 00:18:31", "link": "http://arxiv.org/abs/2504.21048v1", "categories": ["cs.MA", "cs.AI", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Spectral Methods via FFTs in Emerging Machine Number Formats: OFP8, Bfloat16, Posit, and Takum Arithmetics", "abstract": "The Fast Fourier Transform (FFT) is one of the most widely used algorithms in\nhigh performance computing, with critical applications in spectral analysis for\nboth signal processing and the numerical solution of partial differential\nequations (PDEs). These data-intensive workloads are primarily constrained by\nthe memory wall, motivating the exploration of emerging number formats -- such\nas OFP8 (E4M3 and E5M2), bfloat16, and the tapered-precision posit and takum\nformats -- as potential alternatives to conventional IEEE 754 floating-point\nrepresentations.\n  This paper evaluates the accuracy and stability of FFT-based computations\nacross a range of formats, from 8 to 64 bits. Round-trip FFT is applied to a\ndiverse set of images, and short-time Fourier transform (STFT) to audio\nsignals. The results confirm posit arithmetic's strong performance at low\nprecision, with takum following closely behind. Posits show stability issues at\nhigher precisions, while OFP8 formats are unsuitable and bfloat16 underperforms\ncompared to float16 and takum.", "published": "2025-04-29 22:04:16", "link": "http://arxiv.org/abs/2504.21197v1", "categories": ["math.NA", "cs.NA", "B.2; G.1.0; G.1.10"], "primary_category": "math.NA"}
{"title": "A Summation-Based Algorithm For Integer Factorization", "abstract": "Numerous methods have been considered to create a fast integer factorization\nalgorithm. Despite its apparent simplicity, the difficulty to find such an\nalgorithm plays a crucial role in modern cryptography, notably, in the security\nof RSA encryption. Some approaches to factoring integers quickly include the\nTrial Division method, Pollard's Rho and p-1 methods, and various Sieve\nalgorithms.\n  This paper introduces a new method that converts an integer into a sum in\nbase-2. By combining a base-10 and base-2 representation of the integer, an\nalgorithm on the order of $\\sqrt{n}$ time complexity can convert that sum to a\nproduct of two integers, thus factoring the original number.", "published": "2025-04-29 20:35:43", "link": "http://arxiv.org/abs/2504.21168v1", "categories": ["math.NA", "cs.CR", "cs.NA"], "primary_category": "math.NA"}
{"title": "An $r$-adaptive finite element method using neural networks for parametric self-adjoint elliptic problem", "abstract": "This work proposes an $r$-adaptive finite element method (FEM) using neural\nnetworks (NNs). The method employs the Ritz energy functional as the loss\nfunction, currently limiting its applicability to symmetric and coercive\nproblems, such as those arising from self-adjoint elliptic problems. The\nobjective of the NN optimization is to determine the mesh node locations. For\nsimplicity in two-dimensional problems, these locations are assumed to form a\ntensor product structure. The method is designed to solve parametric partial\ndifferential equations (PDEs). For each PDE parameter instance, the optimal\n$r$-adapted mesh generated by the NN is then solved with a standard FEM. The\nconstruction of FEM matrices and load vectors is implemented such that their\nderivatives with respect to mesh node locations, required for NN training, can\nbe efficiently computed using automatic differentiation. However, the linear\nequation solver does not need to be differentiable, enabling the use of\nefficient, readily available `out-of-the-box' solvers. Consequently, the\nproposed approach retains the robustness and reliability guarantees of the FEM\nfor each parameter instance, while the NN optimization adaptively adjusts the\nmesh node locations. The method's performance is demonstrated on parametric\nPoisson problems using one- and two-dimensional tensor product meshes.", "published": "2025-04-29 20:23:44", "link": "http://arxiv.org/abs/2504.21160v1", "categories": ["math.NA", "cs.NA", "65N50, 68T07"], "primary_category": "math.NA"}
{"title": "On feedback stabilisation for the Cahn-Hilliard equation and its numerical approximation", "abstract": "We consider the stabilisation of solutions to the Cahn-Hilliard equation\ntowards a given trajectory by means of a finite-dimensional static output\nfeedback mechanism. Exponential stabilisation of the controlled state around\nthe target trajectory is proven using careful energy estimates and a spectral\ncondition which characterizes the strength of the feedback. The analysis is\ngeneral enough to allow for pointwise and distributed measurements and\nactuation. The main results are derived via arguments that carry over to\nappropriate discretisation schemes which allows us to establish corresponding\nexponential stabilisation results also on the discrete level. The validity of\nour results and the importance of some of our assumptions are illustrated by\nnumerical tests.", "published": "2025-04-29 20:07:43", "link": "http://arxiv.org/abs/2504.21150v1", "categories": ["math.OC", "cs.NA", "math.AP", "math.NA"], "primary_category": "math.OC"}
{"title": "Numerical Performance of the Implicitly Restarted Arnoldi Method in OFP8, Bfloat16, Posit, and Takum Arithmetics", "abstract": "The computation of select eigenvalues and eigenvectors of large, sparse\nmatrices is fundamental to a wide range of applications. Accordingly,\nevaluating the numerical performance of emerging alternatives to the IEEE 754\nfloating-point standard -- such as OFP8 (E4M3 and E5M2), bfloat16, and the\ntapered-precision posit and takum formats -- is of significant interest. Among\nthe most widely used methods for this task is the implicitly restarted Arnoldi\nmethod, as implemented in ARPACK.\n  This paper presents a comprehensive and untailored evaluation based on two\nreal-world datasets: the SuiteSparse Matrix Collection, which includes matrices\nof varying sizes and condition numbers, and the Network Repository, a large\ncollection of graphs from practical applications. The results demonstrate that\nthe tapered-precision posit and takum formats provide improved numerical\nperformance, with takum arithmetic avoiding several weaknesses observed in\nposits. While bfloat16 performs consistently better than float16, the OFP8\ntypes are generally unsuitable for general-purpose computations.", "published": "2025-04-29 19:24:50", "link": "http://arxiv.org/abs/2504.21130v1", "categories": ["math.NA", "cs.NA", "B.2; G.1.3; G.1.10"], "primary_category": "math.NA"}
{"title": "A Hybrid Mixture of $t$-Factor Analyzers for Clustering High-dimensional Data", "abstract": "This paper develops a novel hybrid approach for estimating the mixture model\nof $t$-factor analyzers (MtFA) that employs multivariate $t$-distribution and\nfactor model to cluster and characterize grouped data. The traditional\nestimation method for MtFA faces computational challenges, particularly in\nhigh-dimensional settings, where the eigendecomposition of large covariance\nmatrices and the iterative nature of Expectation-Maximization (EM) algorithms\nlead to scalability issues. We propose a computational scheme that integrates a\nprofile likelihood method into the EM framework to efficiently obtain the model\nparameter estimates. The effectiveness of our approach is demonstrated through\nsimulations showcasing its superior computational efficiency compared to the\nexisting method, while preserving clustering accuracy and resilience against\noutliers. Our method is applied to cluster the Gamma-ray bursts, reinforcing\nseveral claims in the literature that Gamma-ray bursts have heterogeneous\nsubpopulations and providing characterizations of the estimated groups.", "published": "2025-04-29 18:59:58", "link": "http://arxiv.org/abs/2504.21120v1", "categories": ["stat.ME", "astro-ph.HE", "stat.AP", "stat.CO", "stat.ML", "62H05, 62H12, 62H20, 62H25, 62H30, 62P35", "G.3; I.2; I.5; I.6; J.2"], "primary_category": "stat.ME"}
{"title": "Design, analysis, and experimental validation of a stepped plate parametric array loudspeaker", "abstract": "This study investigates the design and analysis of a stepped plate parametric\narray loudspeaker (SPPAL) as an alternative to conventional array-based\nparametric loudspeakers. The SPPAL utilizes a single Langevin-type ultrasonic\ntransducer coupled with a flexural stepped plate to generate narrow-beam\naudible sound via nonlinear acoustic interaction. To evaluate and optimize the\nperformance of the SPPAL, an integrated modeling framework is developed,\nconsisting of an approximate analytical 3D model for transducer dynamics, an\nequivalence ratio formulation to relate stepped plate and rigid piston\nbehavior, and a spherical wave expansion method for nonlinear sound field\nsimulation. The dual-resonance behavior of the transducer is optimized through\nmulti-objective analysis to enhance low-frequency audio performance.\nExperimental validation includes frequency response and modal analysis of the\ntransducer, as well as sound field measurements. The analytical methods are\nfurther verified through comparison with experimental data. Furthermore,\ncombination resonance--an unintended structural excitation resulting from\nintermodulation--is identified as an inherent phenomenon in SPPAL operation.\nThe findings offer practical guidance for the development of efficient,\ncompact, and manufacturable parametric array loudspeakers employing plate-based\nflexural vibration.", "published": "2025-04-29 20:46:46", "link": "http://arxiv.org/abs/2504.21171v1", "categories": ["cs.SD", "eess.AS", "physics.app-ph"], "primary_category": "cs.SD"}
{"title": "Green Satellite Networks Using Segment Routing and Software-Defined Networking", "abstract": "This paper presents a comprehensive evaluation of network performance in\nsoftware defined networking (SDN)-based low Earth orbit (LEO) satellite\nnetworks, focusing on the Telesat Lightspeed constellation. We propose a green\ntraffic engineering (TE) approach leveraging segment routing IPv6 (SRv6) to\nenhance energy efficiency. Through simulations, we analyze the impact of SRv6,\nmulti-protocol label switching (MPLS), IPv4, and IPv6 with open shortest path\nfirst (OSPF) on key network performance metrics, including peak and average CPU\nusage, memory consumption, packet delivery rate (PDR), and packet overhead\nunder varying traffic loads. Results show that the proposed green TE approach\nusing SRv6 achieves notable energy efficiency, maintaining lower CPU usage and\nhigh PDR compared to traditional protocols. While SRv6 and MPLS introduce\nslightly higher memory usage and overhead due to their advanced configurations,\nthese trade-offs remain manageable. Our findings highlight SRv6 with green TE\nas a promising solution for optimizing energy efficiency in LEO satellite\nnetworks, contributing to the development of more sustainable and efficient\nsatellite communications.", "published": "2025-04-29 21:23:19", "link": "http://arxiv.org/abs/2504.21181v1", "categories": ["cs.NI", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "cs.NI"}
{"title": "Feasibility assessment of optical communications between ground and satellite on Mars through the simulation of atmospheric effects on signal quality leading to a proposal for a new communications network architecture during extreme weather", "abstract": "Mars is the next milestone in human exploration. However, there are still\nseveral challenges that must be assessed to ensure appropriate conditions in a\nfuture settlement. Communications services will be essential for this task,\nproviding not only a link between Earth and Mars but also supporting Martian\nweather forecasting and any potential rescue missions. These applications\nrequire a robust, high data rate communications network that allows for rapid\nresponse, remote sensing and public engagement. This research aims to study the\nfeasibility of ground-to-satellite (and vice versa) optical communications\nduring extreme Martian weather conditions, focusing on the link between a\nground station on the surface of Mars and a satellite orbiting the planet.\nLong-lasting and expansive Martian dust storms, particularly common in the\nsouthern hemisphere, pose a considerable challenge when considering the\nfeasibility of optical communications with Mars due to their significant impact\nin terms of signal attenuation and scattering. The methodology of this study is\nbased on a computer simulation of the system featuring the characterisation of\nthe Martian atmosphere and optical link to measure the attenuation and\nundesired effects suffered by the data signal when applying different\nenvironmental configuration parameters. The flexibility of the approach allows\nfor the prediction of communications link quality in extreme cases such as\nglobal dust storms. The simulation is based on atmospheric data from the Mars\nReconnaissance Orbiter's Mars Climate Sounder instrument and considers the\nrecently launched Laser Communication Relay Demonstration (LCRD). The extreme\nconditions during dust storms in the southern polar-hood region lead to the\nproposal of a new communications network architecture to ensure connectivity\nduring these events.", "published": "2025-04-29 20:05:46", "link": "http://arxiv.org/abs/2504.21148v1", "categories": ["astro-ph.EP", "astro-ph.IM", "eess.SP", "physics.space-ph"], "primary_category": "astro-ph.EP"}
{"title": "Energy Efficient Wireless Communications by Harnessing Huygens' Metasurfaces", "abstract": "Ambitions for the next generation of wireless communication include high data\nrates, low latency, ubiquitous access, ensuring sustainability (in terms of\nconsumption of energy and natural resources), all while maintaining a\nreasonable level of implementation complexity. Achieving these goals\nnecessitates reforms in cellular networks, specifically in the physical layer\nand antenna design. The deployment of transmissive metasurfaces at basestations\n(BSs) presents an appealing solution, enabling beamforming in the radiated wave\ndomain, minimizing the need for energy-hungry RF chains. Among various\nmetasurface-based antenna designs, we propose using Huygens' metasurface-based\nantennas (HMAs) at BSs. Huygens' metasurfaces offer an attractive solution for\nantennas because, by utilizing Huygens' equivalence principle, they allow\nindependent control over both the amplitude and phase of the transmitted\nelectromagnetic wave. In this paper, we investigate the fundamental limits of\nHMAs in wireless networks by integrating electromagnetic theory and information\ntheory within a unified analytical framework. Specifically, we model the unique\nelectromagnetic characteristics of HMAs and incorporate them into an\ninformation-theoretic optimization framework to determine their maximum\nachievable sum rate. By formulating an optimization problem that captures the\nimpact of HMA's hardware constraints and electromagnetic properties, we\nquantify the channel capacity of HMA-assisted systems. We then compare the\nperformance of HMAs against phased arrays and other metasurface-based antennas\nin both rich scattering and realistic 3GPP channels, highlighting their\npotential in improving spectral and energy efficiency.", "published": "2025-04-29 19:21:17", "link": "http://arxiv.org/abs/2504.21128v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Trace-of-Thought Prompting: Investigating Prompt-Based Knowledge Distillation Through Question Decomposition", "abstract": "Knowledge distillation allows smaller neural networks to emulate the\nperformance of larger, teacher models with reduced computational demands.\nTraditional methods for Large Language Models (LLMs) often necessitate\nextensive fine-tuning, which limits their accessibility. To address this, we\nintroduce Trace-of-Thought Prompting, a novel framework designed to distill\ncritical reasoning capabilities from high-resource teacher models (over 8\nbillion parameters) to low-resource student models (up to 8 billion\nparameters). This approach leverages problem decomposition to enhance\ninterpretability and facilitate human-in-the-loop interventions. Empirical\nevaluations on the GSM8K and MATH datasets show that student models achieve\naccuracy gains of up to 113% on GSM8K and 21% on MATH, with significant\nimprovements particularly notable in smaller models like Llama 2 and Zephyr.\nOur results suggest a promising pathway for open-source, low-resource models to\neventually serve both as both students and teachers, potentially reducing our\nreliance on high-resource, proprietary models.", "published": "2025-04-29 17:14:54", "link": "http://arxiv.org/abs/2504.20946v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluation and Verification of Physics-Informed Neural Models of the Grad-Shafranov Equation", "abstract": "Our contributions are motivated by fusion reactors that rely on maintaining\nmagnetohydrodynamic (MHD) equilibrium, where the balance between plasma\npressure and confining magnetic fields is required for stable operation. In\naxisymmetric tokamak reactors in particular, and under the assumption of\ntoroidal symmetry, this equilibrium can be mathematically modelled using the\nGrad-Shafranov Equation (GSE). Recent works have demonstrated the potential of\nusing Physics-Informed Neural Networks (PINNs) to model the GSE. Existing\nstudies did not examine realistic scenarios in which a single network\ngeneralizes to a variety of boundary conditions. Addressing that limitation, we\nevaluate a PINN architecture that incorporates boundary points as network\ninputs. Additionally, we compare PINN model accuracy and inference speeds with\na Fourier Neural Operator (FNO) model. Finding the PINN model to be the most\nperformant, and accurate in our setting, we use the network verification tool\nMarabou to perform a range of verification tasks. Although we find some\ndiscrepancies between evaluations of the networks natively in PyTorch, compared\nto via Marabou, we are able to demonstrate useful and practical verification\nworkflows. Our study is the first investigation of verification of such\nnetworks.", "published": "2025-04-29 20:17:43", "link": "http://arxiv.org/abs/2504.21155v2", "categories": ["physics.plasm-ph", "cs.AI", "cs.NE"], "primary_category": "physics.plasm-ph"}
{"title": "Natural Language Processing tools for Pharmaceutical Manufacturing Information Extraction from Patents", "abstract": "Abundant and diverse data on medicines manufacturing and other lifecycle\ncomponents has been made easily accessible in the last decades. However, a\nsignificant proportion of this information is characterised by not being\ntabulated and usable for machine learning purposes. Thus, natural language\nprocessing tools have been used to build databases in domains such as\nbiomedical and chemical to address this limitation. This has allowed the\ndevelopment of artificial intelligence applications, which have improved drug\ndiscovery and treatments. In the pharmaceutical manufacturing context, some\ninitiatives and datasets for primary processing can be found, but the\nmanufacturing of drug products is an area which is still lacking, to the best\nof our knowledge. This works aims to explore and adapt NLP tools used in other\ndomains to extract information on both primary and secondary manufacturing,\nemploying patents as the main source of data. Thus, two independent, but\ncomplementary, models were developed comprising a method to select fragments of\ntext that contain manufacturing data, and a named entity recognition system\nthat enables extracting information on operations, materials, and conditions of\na process. For the first model, the identification of relevant sections was\nachieved using an unsupervised approach combining Latent Dirichlet Allocation\nand k-Means clustering. The performance of this model measured as a Cohen's\nkappa between model output and manual revision was higher than 90%. NER model\nconsisted of a deep neural network, and an f1-score micro average of 84.2% was\nobtained which is comparable to other works. Some considerations for these\ntools to be used in data extraction are discussed throughout this document.", "published": "2025-04-29 09:56:23", "link": "http://arxiv.org/abs/2504.20598v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "SNR-aware Semantic Image Transmission with Deep Learning-based Channel Estimation in Fading Channels", "abstract": "Semantic communications (SCs) play a central role in shaping the future of\nthe sixth generation (6G) wireless systems, which leverage rapid advances in\ndeep learning (DL). In this regard, end-to-end optimized DL-based joint\nsource-channel coding (JSCC) has been adopted to achieve SCs, particularly in\nimage transmission. Utilizing vision transformers in the encoder/decoder design\nhas enabled significant advancements in image semantic extraction, surpassing\ntraditional convolutional neural networks (CNNs). In this paper, we propose a\nnew JSCC paradigm for image transmission, namely Swin semantic image\ntransmission (SwinSIT), based on the Swin transformer. The Swin transformer is\nemployed to construct both the semantic encoder and decoder for efficient image\nsemantic extraction and reconstruction. Inspired by the\nsqueezing-and-excitation (SE) network, we introduce a signal-to-noise-ratio\n(SNR)-aware module that utilizes SNR feedback to adaptively perform a\ndouble-phase enhancement for the encoder-extracted semantic map and its noisy\nversion at the decoder. Additionally, a CNN-based channel estimator and\ncompensator (CEAC) module repurposes an image-denoising CNN to mitigate fading\nchannel effects. To optimize deployment in resource-constrained IoT devices, a\njoint pruning and quantization scheme compresses the SwinSIT model. Simulations\nevaluate the SwinSIT performance against conventional benchmarks demonstrating\nits effectiveness. Moreover, the model's compressed version substantially\nreduces its size while maintaining favorable PSNR performance.", "published": "2025-04-29 08:57:47", "link": "http://arxiv.org/abs/2504.20557v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Graph RAG for Legal Norms: A Hierarchical and Temporal Approach", "abstract": "This article proposes an adaptation of Graph Retrieval Augmented Generation\n(Graph RAG) specifically designed for the analysis and comprehension of legal\nnorms, which are characterized by their predefined hierarchical structure,\nextensive network of internal and external references and multiple temporal\nversions. By combining structured knowledge graphs with contextually enriched\ntext segments, Graph RAG offers a promising solution to address the inherent\ncomplexity and vast volume of legal data. The integration of hierarchical\nstructure and temporal evolution into knowledge graphs - along with the concept\nof comprehensive Text Units - facilitates the construction of richer,\ninterconnected representations of legal knowledge. Through a detailed analysis\nof Graph RAG and its application to legal norm datasets, this article aims to\nsignificantly advance the field of Artificial Intelligence applied to Law,\ncreating opportunities for more effective systems in legal research,\nlegislative analysis, and decision support.", "published": "2025-04-29 18:36:57", "link": "http://arxiv.org/abs/2505.00039v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "HyPerAlign: Hypotheses-driven Personalized Alignment", "abstract": "Alignment algorithms are widely used to align large language models (LLMs) to\nhuman users based on preference annotations that reflect their intended\nreal-world use cases. Typically these (often divergent) preferences are\naggregated over a diverse set of users, resulting in fine-tuned models that are\naligned to the ``average-user'' preference. Nevertheless, current models are\nused by individual users in very specific contexts and situations, emphasizing\nthe need for user-dependent preference control. In this work we address the\nproblem of personalizing LLM outputs to their users, aiming to generate\ncustomized responses tailored to individual users, instead of generic outputs\nthat emulate the collective voices of diverse populations. We propose a novel\ninterpretable and sample-efficient hypotheses-driven personalization approach\n(HyPerAlign) where given few-shot examples written by a particular user, we\nfirst infer hypotheses about their communication strategies, personality and\nwriting style, then prompt LLM models with these hypotheses and user specific\nattributes to generate customized outputs. We conduct experiments on two\ndifferent personalization tasks, authorship attribution and deliberative\nalignment, with datasets from diverse domains (news articles, blog posts,\nemails, jailbreaking benchmarks), and demonstrate the superiority of\nhypotheses-driven personalization approach when compared to preference-based\nfine-tuning methods. For deliberative alignment, the helpfulness of LLM models\nis improved by up to $70\\%$ on average. For authorship attribution, results\nindicate consistently high win-rates (commonly $>90\\%$) against\nstate-of-the-art preference fine-tuning approaches for LLM personalization\nacross diverse user profiles and LLM models. Overall, our approach represents\nan interpretable and sample-efficient strategy for the personalization of LLM\nmodels to individual users.", "published": "2025-04-29 18:01:46", "link": "http://arxiv.org/abs/2505.00038v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Framework to Assess the Persuasion Risks Large Language Model Chatbots Pose to Democratic Societies", "abstract": "In recent years, significant concern has emerged regarding the potential\nthreat that Large Language Models (LLMs) pose to democratic societies through\ntheir persuasive capabilities. We expand upon existing research by conducting\ntwo survey experiments and a real-world simulation exercise to determine\nwhether it is more cost effective to persuade a large number of voters using\nLLM chatbots compared to standard political campaign practice, taking into\naccount both the \"receive\" and \"accept\" steps in the persuasion process (Zaller\n1992). These experiments improve upon previous work by assessing extended\ninteractions between humans and LLMs (instead of using single-shot\ninteractions) and by assessing both short- and long-run persuasive effects\n(rather than simply asking users to rate the persuasiveness of LLM-produced\ncontent). In two survey experiments (N = 10,417) across three distinct\npolitical domains, we find that while LLMs are about as persuasive as actual\ncampaign ads once voters are exposed to them, political persuasion in the\nreal-world depends on both exposure to a persuasive message and its impact\nconditional on exposure. Through simulations based on real-world parameters, we\nestimate that LLM-based persuasion costs between \\$48-\\$74 per persuaded voter\ncompared to \\$100 for traditional campaign methods, when accounting for the\ncosts of exposure. However, it is currently much easier to scale traditional\ncampaign persuasion methods than LLM-based persuasion. While LLMs do not\ncurrently appear to have substantially greater potential for large-scale\npolitical persuasion than existing non-LLM methods, this may change as LLM\ncapabilities continue to improve and it becomes easier to scalably encourage\nexposure to persuasive LLMs.", "published": "2025-04-29 16:02:51", "link": "http://arxiv.org/abs/2505.00036v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Simple Finite-Length Achievability and Converse Bounds for the Deletion Channel and the Insertion Channel", "abstract": "We develop upper bounds on code size for independent and identically\ndistributed deletion (insertion) channel for given code length and target frame\nerror probability. The bounds are obtained as a variation of a general converse\nbound, which, though available for any channel, is inefficient and not easily\ncomputable without a good reference distribution over the output alphabet. We\nobtain a reference output distribution for a general finite-input finite-output\nchannel and provide a simple formula for the converse bound on the capacity\nemploying this distribution. We then evaluate the bound for the deletion\nchannel with a finite block length and show that the resulting upper bound on\nthe code side is tighter than that for a binary erasure channel, which is the\nonly alternative converse bound for this finite-length setting. Also, we\nprovide the similar results for the insertion channel.", "published": "2025-04-29 17:32:27", "link": "http://arxiv.org/abs/2504.20961v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Towards Flow-Matching-based TTS without Classifier-Free Guidance", "abstract": "Flow matching has demonstrated strong generative capabilities and has become\na core component in modern Text-to-Speech (TTS) systems. To ensure high-quality\nspeech synthesis, Classifier-Free Guidance (CFG) is widely used during the\ninference of flow-matching-based TTS models. However, CFG incurs substantial\ncomputational cost as it requires two forward passes, which hinders its\napplicability in real-time scenarios. In this paper, we explore removing CFG\nfrom flow-matching-based TTS models to improve inference efficiency, while\nmaintaining performance. Specifically, we reformulated the flow matching\ntraining target to directly approximate the CFG optimization trajectory. This\ntraining method eliminates the need for unconditional model evaluation and\nguided tuning during inference, effectively cutting the computational overhead\nin half. Furthermore, It can be seamlessly integrated with existing optimized\nsampling strategies. We validate our approach using the F5-TTS model on the\nLibriTTS dataset. Experimental results show that our method achieves a\n9$\\times$ inference speed-up compared to the baseline F5-TTS, while preserving\ncomparable speech quality. We will release the code and models to support\nreproducibility and foster further research in this area.", "published": "2025-04-29 00:54:15", "link": "http://arxiv.org/abs/2504.20334v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Approximately Dominating Sets in Elections", "abstract": "Condorcet's paradox is a fundamental result in social choice theory which\nstates that there exist elections in which, no matter which candidate wins, a\nmajority of voters prefer a different candidate. In fact, even if we can select\nany $k$ winners, there still may exist another candidate that would beat each\nof the winners in a majority vote. That is, elections may require arbitrarily\nlarge dominating sets.\n  We show that approximately dominating sets of constant size always exist. In\nparticular, for every $\\varepsilon > 0$, every election (irrespective of the\nnumber of voters or candidates) can select $O(\\frac{1}{\\varepsilon ^2})$\nwinners such that no other candidate beats each of the winners by a margin of\nmore than $\\varepsilon$ fraction of voters.\n  Our proof uses a simple probabilistic construction using samples from a\nmaximal lottery, a well-studied distribution over candidates derived from the\nNash equilibrium of a two-player game. In stark contrast to general approximate\nequilibria, which may require support logarithmic in the number of pure\nstrategies, we show that maximal lotteries can be approximated with constant\nsupport size. These approximate maximal lotteries may be of independent\ninterest.", "published": "2025-04-29 02:30:00", "link": "http://arxiv.org/abs/2504.20372v2", "categories": ["cs.GT", "cs.DM", "cs.DS", "math.CO"], "primary_category": "cs.GT"}
{"title": "LLM-Enabled EV Charging Stations Recommendation", "abstract": "Charging infrastructure is not expanding quickly enough to accommodate the\nincreasing usage of Electric Vehicles (EVs). For this reason, EV owners\nexperience extended waiting periods, range anxiety, and overall\ndissatisfaction. Challenges, such as fragmented data and the complexity of\nintegrating factors like location, energy pricing, and user preferences, make\nthe current recommendation systems ineffective. To overcome these limitations,\nwe propose RecomBot, which is a Large Language Model (LLM)-powered prompt-based\nrecommender system that dynamically suggests optimal Charging Stations (CSs)\nusing real-time heterogeneous data. By leveraging natural language reasoning\nand fine-tuning EV-specific datasets, RecomBot enhances personalization,\nimproves charging efficiency, and adapts to various EV types, offering a\nscalable solution for intelligent EV recommendation systems. Through testing\nacross various prompt engineering scenarios, the results obtained underline the\ncapability and efficiency of the proposed model.", "published": "2025-04-29 19:57:05", "link": "http://arxiv.org/abs/2505.01447v1", "categories": ["cs.IR", "cs.ET"], "primary_category": "cs.IR"}
{"title": "CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report Generation with Multi-Agent RAG and Concept Bottleneck Models", "abstract": "Advancements in generative Artificial Intelligence (AI) hold great promise\nfor automating radiology workflows, yet challenges in interpretability and\nreliability hinder clinical adoption. This paper presents an automated\nradiology report generation framework that combines Concept Bottleneck Models\n(CBMs) with a Multi-Agent Retrieval-Augmented Generation (RAG) system to bridge\nAI performance with clinical explainability. CBMs map chest X-ray features to\nhuman-understandable clinical concepts, enabling transparent disease\nclassification. Meanwhile, the RAG system integrates multi-agent collaboration\nand external knowledge to produce contextually rich, evidence-based reports.\nOur demonstration showcases the system's ability to deliver interpretable\npredictions, mitigate hallucinations, and generate high-quality, tailored\nreports with an interactive interface addressing accuracy, trust, and usability\nchallenges. This framework provides a pathway to improving diagnostic\nconsistency and empowering radiologists with actionable insights.", "published": "2025-04-29 16:14:55", "link": "http://arxiv.org/abs/2504.20898v2", "categories": ["cs.AI", "cs.CV", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Algorithm Performance Spaces for Strategic Dataset Selection", "abstract": "The evaluation of new algorithms in recommender systems frequently depends on\npublicly available datasets, such as those from MovieLens or Amazon. Some of\nthese datasets are being disproportionately utilized primarily due to their\nhistorical popularity as baselines rather than their suitability for specific\nresearch contexts. This thesis addresses this issue by introducing the\nAlgorithm Performance Space, a novel framework designed to differentiate\ndatasets based on the measured performance of algorithms applied to them. An\nexperimental study proposes three metrics to quantify and justify dataset\nselection to evaluate new algorithms. These metrics also validate assumptions\nabout datasets, such as the similarity between MovieLens datasets of varying\nsizes. By creating an Algorithm Performance Space and using the proposed\nmetrics, differentiating datasets was made possible, and diverse dataset\nselections could be found. While the results demonstrate the framework's\npotential, further research proposals and implications are discussed to develop\nAlgorithm Performance Spaces tailored to diverse use cases.", "published": "2025-04-29 12:29:52", "link": "http://arxiv.org/abs/2505.01442v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Modeling AI-Human Collaboration as a Multi-Agent Adaptation", "abstract": "We develop an agent-based simulation to formalize AI-human collaboration as a\nfunction of task structure, advancing a generalizable framework for strategic\ndecision-making in organizations. Distinguishing between heuristic-based human\nadaptation and rule-based AI search, we model interactions across modular\n(parallel) and sequenced (interdependent) tasks using an NK model. Our results\nreveal that in modular tasks, AI often substitutes for humans - delivering\nhigher payoffs unless human expertise is very high, and the AI search space is\neither narrowly focused or extremely broad. In sequenced tasks, interesting\ncomplementarities emerge. When an expert human initiates the search and AI\nsubsequently refines it, aggregate performance is maximized. Conversely, when\nAI leads, excessive heuristic refinement by the human can reduce payoffs. We\nalso show that even \"hallucinatory\" AI - lacking memory or structure - can\nimprove outcomes when augmenting low-capability humans by helping escape local\noptima. These results yield a robust implication: the effectiveness of AI-human\ncollaboration depends less on context or industry, and more on the underlying\ntask structure. By elevating task decomposition as the central unit of\nanalysis, our model provides a transferable lens for strategic decision-making\ninvolving humans and an agentic AI across diverse organizational settings.", "published": "2025-04-29 16:19:53", "link": "http://arxiv.org/abs/2504.20903v2", "categories": ["cs.MA", "cs.AI", "cs.HC"], "primary_category": "cs.MA"}
{"title": "Pretraining Large Brain Language Model for Active BCI: Silent Speech", "abstract": "This paper explores silent speech decoding in active brain-computer interface\n(BCI) systems, which offer more natural and flexible communication than\ntraditional BCI applications. We collected a new silent speech dataset of over\n120 hours of electroencephalogram (EEG) recordings from 12 subjects, capturing\n24 commonly used English words for language model pretraining and decoding.\nFollowing the recent success of pretraining large models with self-supervised\nparadigms to enhance EEG classification performance, we propose Large Brain\nLanguage Model (LBLM) pretrained to decode silent speech for active BCI. To\npretrain LBLM, we propose Future Spectro-Temporal Prediction (FSTP) pretraining\nparadigm to learn effective representations from unlabeled EEG data. Unlike\nexisting EEG pretraining methods that mainly follow a masked-reconstruction\nparadigm, our proposed FSTP method employs autoregressive modeling in temporal\nand frequency domains to capture both temporal and spectral dependencies from\nEEG signals. After pretraining, we finetune our LBLM on downstream tasks,\nincluding word-level and semantic-level classification. Extensive experiments\ndemonstrate significant performance gains of the LBLM over fully-supervised and\npretrained baseline models. For instance, in the difficult cross-session\nsetting, our model achieves 47.0\\% accuracy on semantic-level classification\nand 39.6\\% in word-level classification, outperforming baseline methods by\n5.4\\% and 7.3\\%, respectively. Our research advances silent speech decoding in\nactive BCI systems, offering an innovative solution for EEG language model\npretraining and a new dataset for fundamental research.", "published": "2025-04-29 22:48:27", "link": "http://arxiv.org/abs/2504.21214v2", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Feature Staleness Aware Incremental Learning for CTR Prediction", "abstract": "Click-through Rate (CTR) prediction in real-world recommender systems often\ndeals with billions of user interactions every day. To improve the training\nefficiency, it is common to update the CTR prediction model incrementally using\nthe new incremental data and a subset of historical data. However, the feature\nembeddings of a CTR prediction model often get stale when the corresponding\nfeatures do not appear in current incremental data. In the next period, the\nmodel would have a performance degradation on samples containing stale\nfeatures, which we call the feature staleness problem. To mitigate this\nproblem, we propose a Feature Staleness Aware Incremental Learning method for\nCTR prediction (FeSAIL) which adaptively replays samples containing stale\nfeatures. We first introduce a staleness aware sampling algorithm (SAS) to\nsample a fixed number of stale samples with high sampling efficiency. We then\nintroduce a staleness aware regularization mechanism (SAR) for a fine-grained\ncontrol of the feature embedding updating. We instantiate FeSAIL with a general\ndeep learning-based CTR prediction model and the experimental results\ndemonstrate FeSAIL outperforms various state-of-the-art methods on four\nbenchmark datasets.", "published": "2025-04-29 09:05:47", "link": "http://arxiv.org/abs/2505.02844v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "OneDSE: A Unified Microprocessor Metric Prediction and Design Space Exploration Framework", "abstract": "With the diminishing returns of Moore Law scaling and as power constraints\nbecome more impactful, processor designs rely on architectural innovation to\nachieve differentiating performance. Innovation complexity has increased the\ndesign space of modern high-performance processors. This work offers an\nefficient and novel design space exploration (DSE) solution to these challenges\nof modern CPU design. We identify three key challenges in past DSE approaches:\n(a) Metric prediction is slow and inaccurate for unseen workloads,\nmicroarchitectures, (b) Search is slow and inaccurate in CPU parameter space,\nand (c) A Single model is unable to learn the huge design space. We present\nOneDSE, a unified metric predictor and CPU parameter explorer to mitigate these\nchallenges with three key techniques: (a) Transformer-based workload-Aware CPU\nDSE (TrACE) predictor that outperforms state-of-the-art ANN-based prediction\nmethods by 2.75x and 6.12x with and without fine-tuning, respectively, on\nseveral benchmarks; (b) a novel metric space search approach that outperforms\noptimized metaheuristics by 1.19x while reducing search time by an order of\nmagnitude; (c) MARL-based multi-agent framework that achieves a 10.6% reduction\nin prediction error compared to its non-MARL counterpart, enabling more\naccurate and efficient exploration of the CPU design space.", "published": "2025-04-29 19:19:52", "link": "http://arxiv.org/abs/2505.03771v1", "categories": ["cs.AR", "cs.MA"], "primary_category": "cs.AR"}
{"title": "ClusterLOB: Enhancing Trading Strategies by Clustering Orders in Limit Order Books", "abstract": "In the rapidly evolving world of financial markets, understanding the\ndynamics of limit order book (LOB) is crucial for unraveling market\nmicrostructure and participant behavior. We introduce ClusterLOB as a method to\ncluster individual market events in a stream of market-by-order (MBO) data into\ndifferent groups. To do so, each market event is augmented with six\ntime-dependent features. By applying the K-means++ clustering algorithm to the\nresulting order features, we are then able to assign each new order to one of\nthree distinct clusters, which we identify as directional, opportunistic, and\nmarket-making participants, each capturing unique trading behaviors. Our\nexperimental results are performed on one year of MBO data containing\nsmall-tick, medium-tick, and large-tick stocks from NASDAQ. To validate the\nusefulness of our clustering, we compute order flow imbalances across each\ncluster within 30-minute buckets during the trading day. We treat each\ncluster's imbalance as a signal that provides insights into trading strategies\nand participants' responses to varying market conditions. To assess the\neffectiveness of these signals, we identify the trading strategy with the\nhighest Sharpe ratio in the training dataset, and demonstrate that its\nperformance in the test dataset is superior to benchmark trading strategies\nthat do not incorporate clustering. We also evaluate trading strategies based\non order flow imbalance decompositions across different market event types,\nincluding add, cancel, and trade events, to assess their robustness in various\nmarket conditions. This work establishes a robust framework for clustering\nmarket participant behavior, which helps us to better understand market\nmicrostructure, and inform the development of more effective predictive trading\nsignals with practical applications in algorithmic trading and quantitative\nfinance.", "published": "2025-04-29 01:37:33", "link": "http://arxiv.org/abs/2504.20349v3", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "MACH: Multi-Agent Coordination for RSU-centric Handovers", "abstract": "This paper introduces MACH, a novel approach for optimizing task handover in\nvehicular computing scenarios. To ensure fast and latency-aware placement of\ntasks, the decision-making -- where and when should tasks be offloaded -- is\ncarried out decentralized at the Road Side Units (RSUs) who also execute the\ntasks. By shifting control to the network edge, MACH moves away from the\ntraditional centralized or vehicle-based handover method. Still, it focuses on\ncontextual factors, such as the current RSU load and vehicle trajectories.\nThus, MACH improves the overall Quality of Service (QoS) while fairly balancing\ncomputational loads between RSUs. To evaluate the effectiveness of our\napproach, we develop a robust simulation environment composed of real-world\ntraffic data, dynamic network conditions, and different infrastructure\ncapacities. For scenarios that demand low latency and high reliability, our\nexperimental results demonstrate how MACH significantly improves the\nadaptability and efficiency of vehicular computations. By decentralizing\ncontrol to the network edge, MACH effectively reduces communication overhead\nand optimizes resource utilization, offering a robust framework for task\nhandover management.", "published": "2025-04-29 13:37:12", "link": "http://arxiv.org/abs/2505.07827v1", "categories": ["cs.NI", "cs.MA"], "primary_category": "cs.NI"}
{"title": "An $\\mathcal{O}(n)$ Space Construction of Superpermutations", "abstract": "A superpermutation is a sequence that contains every permutation of $n$\ndistinct symbols as a contiguous substring. For instance, a valid example for\nthree symbols is a sequence that contains all six permutations. This paper\nintroduces a new algorithm that constructs such sequences more efficiently than\nexisting recursive and graph-theoretic methods. Unlike traditional techniques\nthat suffer from scalability and factorial memory demands, the proposed\napproach builds superpermutations directly and compactly. This improves memory\nusage, enabling the construction of larger sequences previously considered\nimpractical.", "published": "2025-04-29 21:38:30", "link": "http://arxiv.org/abs/2505.09628v1", "categories": ["cs.DM", "cs.CC", "cs.DS", "math.CO"], "primary_category": "cs.DM"}
