{"title": "Towards Automated Customer Support", "abstract": "Recent years have seen growing interest in conversational agents, such as\nchatbots, which are a very good fit for automated customer support because the\ndomain in which they need to operate is narrow. This interest was in part\ninspired by recent advances in neural machine translation, esp. the rise of\nsequence-to-sequence (seq2seq) and attention-based models such as the\nTransformer, which have been applied to various other tasks and have opened new\nresearch directions in question answering, chatbots, and conversational\nsystems. Still, in many cases, it might be feasible and even preferable to use\nsimple information retrieval techniques. Thus, here we compare three different\nmodels:(i) a retrieval model, (ii) a sequence-to-sequence model with attention,\nand (iii) Transformer. Our experiments with the Twitter Customer Support\nDataset, which contains over two million posts from customer support services\nof twenty major brands, show that the seq2seq model outperforms the other two\nin terms of semantics and word overlap.", "published": "2018-09-02 06:22:39", "link": "http://arxiv.org/abs/1809.00303v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Gap Filling as a Cheaper Alternative to Reading Comprehension\n  Questionnaires when Evaluating Machine Translation for Gisting", "abstract": "A popular application of machine translation (MT) is gisting: MT is consumed\nas is to make sense of text in a foreign language. Evaluation of the usefulness\nof MT for gisting is surprisingly uncommon. The classical method uses reading\ncomprehension questionnaires (RCQ), in which informants are asked to answer\nprofessionally-written questions in their language about a foreign text that\nhas been machine-translated into their language. Recently, gap-filling (GF), a\nform of cloze testing, has been proposed as a cheaper alternative to RCQ. In\nGF, certain words are removed from reference translations and readers are asked\nto fill the gaps left using the machine-translated text as a hint. This paper\nreports, for thefirst time, a comparative evaluation, using both RCQ and GF, of\ntranslations from multiple MT systems for the same foreign texts, and a\nsystematic study on the effect of variables such as gap density, gap-selection\nstrategies, and document context in GF. The main findings of the study are: (a)\nboth RCQ and GF clearly identify MT to be useful, (b) global RCQ and GF\nrankings for the MT systems are mostly in agreement, (c) GF scores vary very\nwidely across informants, making comparisons among MT systems hard, and (d)\nunlike RCQ, which is framed around documents, GF evaluation can be framed at\nthe sentence level. These findings support the use of GF as a cheaper\nalternative to RCQ.", "published": "2018-09-02 09:16:18", "link": "http://arxiv.org/abs/1809.00315v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Future-Prediction-Based Model for Neural Machine Translation", "abstract": "We propose a novel model for Neural Machine Translation (NMT). Different from\nthe conventional method, our model can predict the future text length and words\nat each decoding time step so that the generation can be helped with the\ninformation from the future prediction. With such information, the model does\nnot stop generation without having translated enough content. Experimental\nresults demonstrate that our model can significantly outperform the baseline\nmodels. Besides, our analysis reflects that our model is effective in the\nprediction of the length and words of the untranslated content.", "published": "2018-09-02 13:47:03", "link": "http://arxiv.org/abs/1809.00336v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextual Neural Model for Translating Bilingual Multi-Speaker\n  Conversations", "abstract": "Recent works in neural machine translation have begun to explore document\ntranslation. However, translating online multi-speaker conversations is still\nan open problem. In this work, we propose the task of translating Bilingual\nMulti-Speaker Conversations, and explore neural architectures which exploit\nboth source and target-side conversation histories for this task. To initiate\nan evaluation for this task, we introduce datasets extracted from Europarl v7\nand OpenSubtitles2016. Our experiments on four language-pairs confirm the\nsignificance of leveraging conversation history, both in terms of BLEU and\nmanual evaluation.", "published": "2018-09-02 14:26:44", "link": "http://arxiv.org/abs/1809.00344v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Trivial Transfer Learning for Low-Resource Neural Machine Translation", "abstract": "Transfer learning has been proven as an effective technique for neural\nmachine translation under low-resource conditions. Existing methods require a\ncommon target language, language relatedness, or specific training tricks and\nregimes. We present a simple transfer learning method, where we first train a\n\"parent\" model for a high-resource language pair and then continue the training\non a lowresource pair only by replacing the training corpus. This \"child\" model\nperforms significantly better than the baseline trained for lowresource pair\nonly. We are the first to show this for targeting different languages, and we\nobserve the improvements even for unrelated languages with different alphabets.", "published": "2018-09-02 15:24:15", "link": "http://arxiv.org/abs/1809.00357v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Ranking Models for Temporal Dependency Structure Parsing", "abstract": "We design and build the first neural temporal dependency parser. It utilizes\na neural ranking model with minimal feature engineering, and parses time\nexpressions and events in a text into a temporal dependency tree structure. We\nevaluate our parser on two domains: news reports and narrative stories. In a\nparsing-only evaluation setup where gold time expressions and events are\nprovided, our parser reaches 0.81 and 0.70 f-score on unlabeled and labeled\nparsing respectively, a result that is very competitive against alternative\napproaches. In an end-to-end evaluation setup where time expressions and events\nare automatically recognized, our parser beats two strong baselines on both\ndata domains. Our experimental results and discussions shed light on the nature\nof temporal dependency structures in different domains and provide insights\nthat we believe will be valuable to future research in this area.", "published": "2018-09-02 17:36:51", "link": "http://arxiv.org/abs/1809.00370v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Character-based Composition Models for Abuse Detection", "abstract": "The advent of social media in recent years has fed into some highly\nundesirable phenomena such as proliferation of offensive language, hate speech,\nsexist remarks, etc. on the Internet. In light of this, there have been several\nefforts to automate the detection and moderation of such abusive content.\nHowever, deliberate obfuscation of words by users to evade detection poses a\nserious challenge to the effectiveness of these efforts. The current state of\nthe art approaches to abusive language detection, based on recurrent neural\nnetworks, do not explicitly address this problem and resort to a generic OOV\n(out of vocabulary) embedding for unseen words. However, in using a single\nembedding for all unseen words we lose the ability to distinguish between\nobfuscated and non-obfuscated or rare words. In this paper, we address this\nproblem by designing a model that can compose embeddings for unseen words. We\nexperimentally demonstrate that our approach significantly advances the current\nstate of the art in abuse detection on datasets from two different domains,\nnamely Twitter and Wikipedia talk page.", "published": "2018-09-02 19:36:03", "link": "http://arxiv.org/abs/1809.00378v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MTNT: A Testbed for Machine Translation of Noisy Text", "abstract": "Noisy or non-standard input text can cause disastrous mistranslations in most\nmodern Machine Translation (MT) systems, and there has been growing research\ninterest in creating noise-robust MT systems. However, as of yet there are no\npublicly available parallel corpora of with naturally occurring noisy inputs\nand translations, and thus previous work has resorted to evaluating on\nsynthetically created datasets. In this paper, we propose a benchmark dataset\nfor Machine Translation of Noisy Text (MTNT), consisting of noisy comments on\nReddit (www.reddit.com) and professionally sourced translations. We\ncommissioned translations of English comments into French and Japanese, as well\nas French and Japanese comments into English, on the order of 7k-37k sentences\nper language pair. We qualitatively and quantitatively examine the types of\nnoise included in this dataset, then demonstrate that existing MT models fail\nbadly on a number of noise-related phenomena, even after performing adaptation\non a small training set of in-domain data. This indicates that this dataset can\nprovide an attractive testbed for methods tailored to handling noisy text in\nMT. The data is publicly available at www.cs.cmu.edu/~pmichel1/mtnt/.", "published": "2018-09-02 20:43:09", "link": "http://arxiv.org/abs/1809.00388v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chinese Pinyin Aided IME, Input What You Have Not Keystroked Yet", "abstract": "Chinese pinyin input method engine (IME) converts pinyin into character so\nthat Chinese characters can be conveniently inputted into computer through\ncommon keyboard. IMEs work relying on its core component, pinyin-to-character\nconversion (P2C). Usually Chinese IMEs simply predict a list of character\nsequences for user choice only according to user pinyin input at each turn.\nHowever, Chinese inputting is a multi-turn online procedure, which can be\nsupposed to be exploited for further user experience promoting. This paper thus\nfor the first time introduces a sequence-to-sequence model with gated-attention\nmechanism for the core task in IMEs. The proposed neural P2C model is learned\nby encoding previous input utterance as extra context to enable our IME capable\nof predicting character sequence with incomplete pinyin input. Our model is\nevaluated in different benchmark datasets showing great user experience\nimprovement compared to traditional models, which demonstrates the first\nengineering practice of building Chinese aided IME.", "published": "2018-09-02 12:01:27", "link": "http://arxiv.org/abs/1809.00329v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Chittron: An Automatic Bangla Image Captioning System", "abstract": "Automatic image caption generation aims to produce an accurate description of\nan image in natural language automatically. However, Bangla, the fifth most\nwidely spoken language in the world, is lagging considerably in the research\nand development of such domain. Besides, while there are many established data\nsets to related to image annotation in English, no such resource exists for\nBangla yet. Hence, this paper outlines the development of \"Chittron\", an\nautomatic image captioning system in Bangla. Moreover, to address the data set\navailability issue, a collection of 16,000 Bangladeshi contextual images has\nbeen accumulated and manually annotated in Bangla. This data set is then used\nto train a model which integrates a pre-trained VGG16 image embedding model\nwith stacked LSTM layers. The model is trained to predict the caption when the\ninput is an image, one word at a time. The results show that the model has\nsuccessfully been able to learn a working language model and to generate\ncaptions of images quite accurately in many cases. The results are evaluated\nmainly qualitatively. However, BLEU scores are also reported. It is expected\nthat a better result can be obtained with a bigger and more varied data set.", "published": "2018-09-02 14:03:30", "link": "http://arxiv.org/abs/1809.00339v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Zero-shot User Intent Detection via Capsule Neural Networks", "abstract": "User intent detection plays a critical role in question-answering and dialog\nsystems. Most previous works treat intent detection as a classification problem\nwhere utterances are labeled with predefined intents. However, it is\nlabor-intensive and time-consuming to label users' utterances as intents are\ndiversely expressed and novel intents will continually be involved. Instead, we\nstudy the zero-shot intent detection problem, which aims to detect emerging\nuser intents where no labeled utterances are currently available. We propose\ntwo capsule-based architectures: INTENT-CAPSNET that extracts semantic features\nfrom utterances and aggregates them to discriminate existing intents, and\nINTENTCAPSNET-ZSL which gives INTENTCAPSNET the zero-shot learning ability to\ndiscriminate emerging intents via knowledge transfer from existing intents.\nExperiments on two real-world datasets show that our model not only can better\ndiscriminate diversely expressed existing intents, but is also able to\ndiscriminate emerging intents when no labeled utterances are available.", "published": "2018-09-02 20:22:48", "link": "http://arxiv.org/abs/1809.00385v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "IntentsKB: A Knowledge Base of Entity-Oriented Search Intents", "abstract": "We address the problem of constructing a knowledge base of entity-oriented\nsearch intents. Search intents are defined on the level of entity types, each\ncomprising of a high-level intent category (property, website, service, or\nother), along with a cluster of query terms used to express that intent. These\nmachine-readable statements can be leveraged in various applications, e.g., for\ngenerating entity cards or query recommendations. By structuring\nservice-oriented search intents, we take one step towards making entities\nactionable. The main contribution of this paper is a pipeline of components we\ndevelop to construct a knowledge base of entity intents. We evaluate\nperformance both component-wise and end-to-end, and demonstrate that our\napproach is able to generate high-quality data.", "published": "2018-09-02 14:29:05", "link": "http://arxiv.org/abs/1809.00345v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Modeling Topical Coherence in Discourse without Supervision", "abstract": "Coherence of text is an important attribute to be measured for both manually\nand automatically generated discourse; but well-defined quantitative metrics\nfor it are still elusive. In this paper, we present a metric for scoring\ntopical coherence of an input paragraph on a real-valued scale by analyzing its\nunderlying topical structure. We first extract all possible topics that the\nsentences of a paragraph of text are related to. Coherence of this text is then\nmeasured by computing: (a) the degree of uncertainty of the topics with respect\nto the paragraph, and (b) the relatedness between these topics. All components\nof our modular framework rely only on unlabeled data and WordNet, thus making\nit completely unsupervised, which is an important feature for general-purpose\nusage of any metric. Experiments are conducted on two datasets - a publicly\navailable dataset for essay grading (representing human discourse), and a\nsynthetic dataset constructed by mixing content from multiple paragraphs\ncovering diverse topics. Our evaluation shows that the measured coherence\nscores are positively correlated with the ground truth for both the datasets.\nFurther validation to our coherence scores is provided by conducting human\nevaluation on the synthetic data, showing a significant agreement of 79.3%", "published": "2018-09-02 23:49:31", "link": "http://arxiv.org/abs/1809.00410v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Weakly-Supervised Neural Text Classification", "abstract": "Deep neural networks are gaining increasing popularity for the classic text\nclassification task, due to their strong expressive power and less requirement\nfor feature engineering. Despite such attractiveness, neural text\nclassification models suffer from the lack of training data in many real-world\napplications. Although many semi-supervised and weakly-supervised text\nclassification models exist, they cannot be easily applied to deep neural\nmodels and meanwhile support limited supervision types. In this paper, we\npropose a weakly-supervised method that addresses the lack of training data in\nneural text classification. Our method consists of two modules: (1) a\npseudo-document generator that leverages seed information to generate\npseudo-labeled documents for model pre-training, and (2) a self-training module\nthat bootstraps on real unlabeled data for model refinement. Our method has the\nflexibility to handle different types of weak supervision and can be easily\nintegrated into existing deep neural models for text classification. We have\nperformed extensive experiments on three real-world datasets from different\ndomains. The results demonstrate that our proposed method achieves inspiring\nperformance without requiring excessive training data and outperforms baseline\nmethods significantly.", "published": "2018-09-02 02:56:25", "link": "http://arxiv.org/abs/1809.01478v2", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Multitask Learning for Fundamental Frequency Estimation in Music", "abstract": "Fundamental frequency (f0) estimation from polyphonic music includes the\ntasks of multiple-f0, melody, vocal, and bass line estimation. Historically\nthese problems have been approached separately, and only recently, using\nlearning-based approaches. We present a multitask deep learning architecture\nthat jointly estimates outputs for various tasks including multiple-f0, melody,\nvocal and bass line estimation, and is trained using a large,\nsemi-automatically annotated dataset. We show that the multitask model\noutperforms its single-task counterparts, and explore the effect of various\ndesign decisions in our approach, and show that it performs better or at least\ncompetitively when compared against strong baseline methods.", "published": "2018-09-02 20:03:09", "link": "http://arxiv.org/abs/1809.00381v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
